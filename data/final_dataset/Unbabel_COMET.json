{"home.repos.pwc.inspect_result.Unbabel_COMET.source.conf.setup": [[97, 99], ["app.add_css_file"], "function", ["None"], ["def", "setup", "(", "app", ")", ":", "\n", "    ", "app", ".", "add_css_file", "(", "\"css/comet.css\"", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.Unbabel_COMET.modules.test_feedforward.TestFeedForward.test_MNIST": [[14, 116], ["pytorch_lightning.seed_everything", "sklearn.datasets.load_digits", "torch.tensor", "sklearn.model_selection.train_test_split", "list", "list", "int", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "comet.modules.feedforward.FeedForward", "torch.nn.CrossEntropyLoss", "torch.optim.SGD", "range", "test_feedforward.TestFeedForward.assertGreaterEqual", "torch.Tensor", "zip", "zip", "comet.modules.feedforward.FeedForward.parameters", "enumerate", "range", "len", "images.view().requires_grad_.view().requires_grad_.view().requires_grad_", "torch.optim.SGD.zero_grad", "comet.modules.feedforward.FeedForward.", "torch.nn.CrossEntropyLoss.", "nn.CrossEntropyLoss.backward", "torch.optim.SGD.step", "images.view().requires_grad_.view().requires_grad_.view", "images.view().requires_grad_.view().requires_grad_.view().requires_grad_", "comet.modules.feedforward.FeedForward.", "torch.max", "torch.tensor.size", "images.view().requires_grad_.view().requires_grad_.view"], "methods", ["None"], ["    ", "def", "test_MNIST", "(", "self", ")", ":", "\n", "        ", "seed_everything", "(", "3", ")", "\n", "\"\"\"\n        STEP 1: LOADING DATASET\n        \"\"\"", "\n", "images", ",", "labels", "=", "load_digits", "(", "return_X_y", "=", "True", ")", "\n", "images", "=", "[", "torch", ".", "Tensor", "(", "images", "[", "i", ",", ":", "]", ")", "for", "i", "in", "range", "(", "images", ".", "shape", "[", "0", "]", ")", "]", "\n", "labels", "=", "torch", ".", "tensor", "(", "labels", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "\n", "train_images", ",", "test_images", ",", "train_labels", ",", "test_labels", "=", "train_test_split", "(", "\n", "images", ",", "labels", ",", "test_size", "=", "0.2", ",", "random_state", "=", "42", "\n", ")", "\n", "\n", "train_dataset", "=", "list", "(", "zip", "(", "train_images", ",", "train_labels", ")", ")", "\n", "test_dataset", "=", "list", "(", "zip", "(", "test_images", ",", "test_labels", ")", ")", "\n", "\n", "\"\"\"\n        STEP 2: MAKING DATASET ITERABLE\n        \"\"\"", "\n", "batch_size", "=", "256", "\n", "n_iters", "=", "80", "\n", "num_epochs", "=", "n_iters", "/", "(", "len", "(", "train_dataset", ")", "/", "batch_size", ")", "\n", "num_epochs", "=", "int", "(", "num_epochs", ")", "\n", "\n", "train_loader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "\n", "dataset", "=", "train_dataset", ",", "batch_size", "=", "batch_size", ",", "shuffle", "=", "True", "\n", ")", "\n", "\n", "test_loader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "\n", "dataset", "=", "test_dataset", ",", "batch_size", "=", "batch_size", ",", "shuffle", "=", "False", "\n", ")", "\n", "\n", "\"\"\"\n        STEP 3: INSTANTIATE MODEL CLASS\n        \"\"\"", "\n", "model", "=", "FeedForward", "(", "\n", "in_dim", "=", "8", "*", "8", ",", "\n", "out_dim", "=", "10", ",", "\n", "hidden_sizes", "=", "[", "100", "]", ",", "\n", "activations", "=", "\"Tanh\"", ",", "\n", ")", "\n", "\n", "\"\"\"\n        STEP 4: INSTANTIATE LOSS CLASS\n        \"\"\"", "\n", "criterion", "=", "nn", ".", "CrossEntropyLoss", "(", ")", "\n", "\n", "\"\"\"\n        STEP 5: INSTANTIATE OPTIMIZER CLASS\n        \"\"\"", "\n", "learning_rate", "=", "0.1", "\n", "optimizer", "=", "torch", ".", "optim", ".", "SGD", "(", "model", ".", "parameters", "(", ")", ",", "lr", "=", "learning_rate", ")", "\n", "\n", "\"\"\"\n        STEP 7: TRAIN THE MODEL\n        \"\"\"", "\n", "iter", "=", "0", "\n", "for", "epoch", "in", "range", "(", "num_epochs", ")", ":", "\n", "            ", "for", "i", ",", "(", "images", ",", "labels", ")", "in", "enumerate", "(", "train_loader", ")", ":", "\n", "# Load images with gradient accumulation capabilities", "\n", "                ", "images", "=", "images", ".", "view", "(", "-", "1", ",", "8", "*", "8", ")", ".", "requires_grad_", "(", ")", "\n", "\n", "# Clear gradients w.r.t. parameters", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "\n", "# Forward pass to get output/logits", "\n", "outputs", "=", "model", "(", "images", ")", "\n", "\n", "# Calculate Loss: softmax --> cross entropy loss", "\n", "loss", "=", "criterion", "(", "outputs", ",", "labels", ")", "\n", "\n", "# Getting gradients w.r.t. parameters", "\n", "loss", ".", "backward", "(", ")", "\n", "\n", "# Updating parameters", "\n", "optimizer", ".", "step", "(", ")", "\n", "\n", "iter", "+=", "1", "\n", "\n", "if", "iter", "%", "10", "==", "0", ":", "\n", "# Calculate Accuracy", "\n", "                    ", "correct", "=", "0", "\n", "total", "=", "0", "\n", "# Iterate through test dataset", "\n", "for", "images", ",", "labels", "in", "test_loader", ":", "\n", "# Load images with gradient accumulation capabilities", "\n", "                        ", "images", "=", "images", ".", "view", "(", "-", "1", ",", "8", "*", "8", ")", ".", "requires_grad_", "(", ")", "\n", "\n", "# Forward pass only to get logits/output", "\n", "outputs", "=", "model", "(", "images", ")", "\n", "\n", "# Get predictions from the maximum value", "\n", "_", ",", "predicted", "=", "torch", ".", "max", "(", "outputs", ".", "data", ",", "1", ")", "\n", "\n", "# Total number of labels", "\n", "total", "+=", "labels", ".", "size", "(", "0", ")", "\n", "\n", "# Total correct predictions", "\n", "correct", "+=", "(", "predicted", "==", "labels", ")", ".", "sum", "(", ")", "\n", "\n", "", "accuracy", "=", "100", "*", "correct", "//", "total", "\n", "", "", "", "self", ".", "assertGreaterEqual", "(", "accuracy", ",", "95", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Unbabel_COMET.modules.layerwise_attention.LayerwiseAttention.__init__": [[39, 78], ["super().__init__", "torch.nn.ParameterList", "torch.nn.Parameter", "torch.FloatTensor", "torch.zeros", "torch.empty().fill_", "layerwise_attention.LayerwiseAttention.register_buffer", "layerwise_attention.LayerwiseAttention.register_buffer", "len", "Exception", "torch.nn.Parameter", "len", "torch.FloatTensor", "range", "torch.empty", "len"], "methods", ["home.repos.pwc.inspect_result.Unbabel_COMET.regression.referenceless.ReferencelessRegression.__init__"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "num_layers", ":", "int", ",", "\n", "layer_norm", ":", "bool", "=", "False", ",", "\n", "layer_weights", ":", "Optional", "[", "List", "[", "int", "]", "]", "=", "None", ",", "\n", "dropout", ":", "float", "=", "None", ",", "\n", ")", "->", "None", ":", "\n", "        ", "super", "(", "LayerwiseAttention", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "num_layers", "=", "num_layers", "\n", "self", ".", "layer_norm", "=", "layer_norm", "\n", "self", ".", "dropout", "=", "dropout", "\n", "\n", "if", "layer_weights", "is", "None", ":", "\n", "            ", "layer_weights", "=", "[", "0.0", "]", "*", "num_layers", "\n", "", "elif", "len", "(", "layer_weights", ")", "!=", "num_layers", ":", "\n", "            ", "raise", "Exception", "(", "\n", "\"Length of layer_weights {} differs \\\n                from num_layers {}\"", ".", "format", "(", "\n", "layer_weights", ",", "num_layers", "\n", ")", "\n", ")", "\n", "\n", "", "self", ".", "scalar_parameters", "=", "ParameterList", "(", "\n", "[", "\n", "Parameter", "(", "\n", "torch", ".", "FloatTensor", "(", "[", "layer_weights", "[", "i", "]", "]", ")", ",", "\n", "requires_grad", "=", "True", ",", "\n", ")", "\n", "for", "i", "in", "range", "(", "num_layers", ")", "\n", "]", "\n", ")", "\n", "\n", "self", ".", "gamma", "=", "Parameter", "(", "torch", ".", "FloatTensor", "(", "[", "1.0", "]", ")", ",", "requires_grad", "=", "True", ")", "\n", "\n", "if", "self", ".", "dropout", ":", "\n", "            ", "dropout_mask", "=", "torch", ".", "zeros", "(", "len", "(", "self", ".", "scalar_parameters", ")", ")", "\n", "dropout_fill", "=", "torch", ".", "empty", "(", "len", "(", "self", ".", "scalar_parameters", ")", ")", ".", "fill_", "(", "-", "1e20", ")", "\n", "self", ".", "register_buffer", "(", "\"dropout_mask\"", ",", "dropout_mask", ")", "\n", "self", ".", "register_buffer", "(", "\"dropout_fill\"", ",", "dropout_fill", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Unbabel_COMET.modules.layerwise_attention.LayerwiseAttention.forward": [[79, 138], ["torch.nn.functional.softmax", "torch.split", "len", "Exception", "len", "torch.tensor", "torch.tensor", "torch.cat", "torch.where", "zip", "mask.float", "mask.float.unsqueeze", "tensors[].size", "zip", "torch.sum", "torch.sum", "torch.sqrt", "pieces.append", "sum", "torch.sum", "pieces.append", "sum", "len", "layerwise_attention.LayerwiseAttention.dropout_mask.uniform_", "layerwise_attention.LayerwiseAttention.forward._layer_norm"], "methods", ["None"], ["", "", "def", "forward", "(", "\n", "self", ",", "\n", "tensors", ":", "List", "[", "torch", ".", "Tensor", "]", ",", "# pylint: disable=arguments-differ", "\n", "mask", ":", "torch", ".", "Tensor", "=", "None", ",", "\n", ")", "->", "torch", ".", "Tensor", ":", "\n", "\n", "        ", "if", "len", "(", "tensors", ")", "!=", "self", ".", "num_layers", ":", "\n", "            ", "raise", "Exception", "(", "\n", "\"{} tensors were passed, but the module was initialized to \\\n                mix {} tensors.\"", ".", "format", "(", "\n", "len", "(", "tensors", ")", ",", "self", ".", "num_layers", "\n", ")", "\n", ")", "\n", "\n", "", "def", "_layer_norm", "(", "tensor", ",", "broadcast_mask", ",", "num_elements_not_masked", ")", ":", "\n", "            ", "tensor_masked", "=", "tensor", "*", "broadcast_mask", "\n", "mean", "=", "torch", ".", "sum", "(", "tensor_masked", ")", "/", "num_elements_not_masked", "\n", "variance", "=", "(", "\n", "torch", ".", "sum", "(", "(", "(", "tensor_masked", "-", "mean", ")", "*", "broadcast_mask", ")", "**", "2", ")", "\n", "/", "num_elements_not_masked", "\n", ")", "\n", "return", "(", "tensor", "-", "mean", ")", "/", "torch", ".", "sqrt", "(", "variance", "+", "1e-12", ")", "\n", "\n", "# BUG: Pytorch bug fix when Parameters are not well copied across GPUs", "\n", "# https://github.com/pytorch/pytorch/issues/36035", "\n", "", "if", "len", "(", "[", "parameter", "for", "parameter", "in", "self", ".", "scalar_parameters", "]", ")", "!=", "self", ".", "num_layers", ":", "\n", "            ", "weights", "=", "torch", ".", "tensor", "(", "self", ".", "weights", ",", "device", "=", "tensors", "[", "0", "]", ".", "device", ")", "\n", "gamma", "=", "torch", ".", "tensor", "(", "self", ".", "gamma_value", ",", "device", "=", "tensors", "[", "0", "]", ".", "device", ")", "\n", "", "else", ":", "\n", "            ", "weights", "=", "torch", ".", "cat", "(", "[", "parameter", "for", "parameter", "in", "self", ".", "scalar_parameters", "]", ")", "\n", "gamma", "=", "self", ".", "gamma", "\n", "\n", "", "if", "self", ".", "training", "and", "self", ".", "dropout", ":", "\n", "            ", "weights", "=", "torch", ".", "where", "(", "\n", "self", ".", "dropout_mask", ".", "uniform_", "(", ")", ">", "self", ".", "dropout", ",", "weights", ",", "self", ".", "dropout_fill", "\n", ")", "\n", "\n", "", "normed_weights", "=", "torch", ".", "nn", ".", "functional", ".", "softmax", "(", "weights", ",", "dim", "=", "0", ")", "\n", "normed_weights", "=", "torch", ".", "split", "(", "normed_weights", ",", "split_size_or_sections", "=", "1", ")", "\n", "\n", "if", "not", "self", ".", "layer_norm", ":", "\n", "            ", "pieces", "=", "[", "]", "\n", "for", "weight", ",", "tensor", "in", "zip", "(", "normed_weights", ",", "tensors", ")", ":", "\n", "                ", "pieces", ".", "append", "(", "weight", "*", "tensor", ")", "\n", "", "return", "gamma", "*", "sum", "(", "pieces", ")", "\n", "\n", "", "else", ":", "\n", "            ", "mask_float", "=", "mask", ".", "float", "(", ")", "\n", "broadcast_mask", "=", "mask_float", ".", "unsqueeze", "(", "-", "1", ")", "\n", "input_dim", "=", "tensors", "[", "0", "]", ".", "size", "(", "-", "1", ")", "\n", "num_elements_not_masked", "=", "torch", ".", "sum", "(", "mask_float", ")", "*", "input_dim", "\n", "\n", "pieces", "=", "[", "]", "\n", "for", "weight", ",", "tensor", "in", "zip", "(", "normed_weights", ",", "tensors", ")", ":", "\n", "                ", "pieces", ".", "append", "(", "\n", "weight", "\n", "*", "_layer_norm", "(", "tensor", ",", "broadcast_mask", ",", "num_elements_not_masked", ")", "\n", ")", "\n", "", "return", "gamma", "*", "sum", "(", "pieces", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.Unbabel_COMET.modules.feedforward.FeedForward.__init__": [[38, 63], ["torch.nn.Module.__init__", "modules.append", "modules.append", "modules.append", "range", "modules.append", "torch.nn.Sequential", "torch.nn.Linear", "feedforward.FeedForward.build_activation", "torch.nn.Dropout", "len", "modules.append", "modules.append", "modules.append", "torch.nn.Linear", "modules.append", "torch.nn.Linear", "feedforward.FeedForward.build_activation", "torch.nn.Dropout", "int", "feedforward.FeedForward.build_activation"], "methods", ["home.repos.pwc.inspect_result.Unbabel_COMET.regression.referenceless.ReferencelessRegression.__init__", "home.repos.pwc.inspect_result.Unbabel_COMET.modules.feedforward.FeedForward.build_activation", "home.repos.pwc.inspect_result.Unbabel_COMET.modules.feedforward.FeedForward.build_activation", "home.repos.pwc.inspect_result.Unbabel_COMET.modules.feedforward.FeedForward.build_activation"], ["def", "__init__", "(", "\n", "self", ",", "\n", "in_dim", ":", "int", ",", "\n", "out_dim", ":", "int", "=", "1", ",", "\n", "hidden_sizes", ":", "List", "[", "int", "]", "=", "[", "3072", ",", "768", "]", ",", "\n", "activations", ":", "str", "=", "\"Sigmoid\"", ",", "\n", "final_activation", ":", "Optional", "[", "str", "]", "=", "None", ",", "\n", "dropout", ":", "float", "=", "0.1", ",", "\n", ")", "->", "None", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "modules", "=", "[", "]", "\n", "modules", ".", "append", "(", "nn", ".", "Linear", "(", "in_dim", ",", "hidden_sizes", "[", "0", "]", ")", ")", "\n", "modules", ".", "append", "(", "self", ".", "build_activation", "(", "activations", ")", ")", "\n", "modules", ".", "append", "(", "nn", ".", "Dropout", "(", "dropout", ")", ")", "\n", "\n", "for", "i", "in", "range", "(", "1", ",", "len", "(", "hidden_sizes", ")", ")", ":", "\n", "            ", "modules", ".", "append", "(", "nn", ".", "Linear", "(", "hidden_sizes", "[", "i", "-", "1", "]", ",", "hidden_sizes", "[", "i", "]", ")", ")", "\n", "modules", ".", "append", "(", "self", ".", "build_activation", "(", "activations", ")", ")", "\n", "modules", ".", "append", "(", "nn", ".", "Dropout", "(", "dropout", ")", ")", "\n", "\n", "", "modules", ".", "append", "(", "nn", ".", "Linear", "(", "hidden_sizes", "[", "-", "1", "]", ",", "int", "(", "out_dim", ")", ")", ")", "\n", "if", "final_activation", "is", "not", "None", ":", "\n", "            ", "modules", ".", "append", "(", "self", ".", "build_activation", "(", "final_activation", ")", ")", "\n", "\n", "", "self", ".", "ff", "=", "nn", ".", "Sequential", "(", "*", "modules", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Unbabel_COMET.modules.feedforward.FeedForward.build_activation": [[64, 69], ["hasattr", "activation.title", "Exception", "getattr", "activation.title"], "methods", ["None"], ["", "def", "build_activation", "(", "self", ",", "activation", ":", "str", ")", "->", "nn", ".", "Module", ":", "\n", "        ", "if", "hasattr", "(", "nn", ",", "activation", ".", "title", "(", ")", ")", ":", "\n", "            ", "return", "getattr", "(", "nn", ",", "activation", ".", "title", "(", ")", ")", "(", ")", "\n", "", "else", ":", "\n", "            ", "raise", "Exception", "(", "f\"{activation} is not a valid activation function!\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Unbabel_COMET.modules.feedforward.FeedForward.forward": [[70, 72], ["feedforward.FeedForward.ff"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "in_features", ":", "torch", ".", "Tensor", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "return", "self", ".", "ff", "(", "in_features", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Unbabel_COMET.models.test_ranking_metric.TestRankingMetric.tearDownClass": [[20, 23], ["shutil.rmtree", "os.path.join"], "methods", ["None"], ["    ", "@", "classmethod", "\n", "def", "tearDownClass", "(", "cls", ")", ":", "\n", "        ", "shutil", ".", "rmtree", "(", "os", ".", "path", ".", "join", "(", "DATA_PATH", ",", "\"checkpoints\"", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Unbabel_COMET.models.test_ranking_metric.TestRankingMetric.test_training": [[24, 86], ["pytorch_lightning.seed_everything", "warnings.filterwarnings", "pytorch_lightning.trainer.trainer.Trainer", "comet.models.RankingMetric", "warnings.filterwarnings", "pytorch_lightning.trainer.trainer.Trainer.fit", "test_ranking_metric.TestRankingMetric.assertTrue", "comet.models.RankingMetric.load_from_checkpoint", "comet.models.RankingMetric.load_from_checkpoint.read_csv", "torch.utils.data.DataLoader", "torch.cat().cpu().tolist", "os.path.exists", "os.path.join", "os.path.join", "scipy.stats.pearsonr", "os.path.join", "os.path.join", "os.path.join", "torch.cat().cpu", "comet.models.RankingMetric.load_from_checkpoint.prepare_sample", "torch.cat", "pytorch_lightning.trainer.trainer.Trainer.predict"], "methods", ["home.repos.pwc.inspect_result.Unbabel_COMET.models.__init__.load_from_checkpoint", "home.repos.pwc.inspect_result.Unbabel_COMET.regression.referenceless.ReferencelessRegression.read_csv", "home.repos.pwc.inspect_result.Unbabel_COMET.regression.referenceless.ReferencelessRegression.prepare_sample", "home.repos.pwc.inspect_result.Unbabel_COMET.models.base.CometModel.predict"], ["", "def", "test_training", "(", "self", ")", ":", "\n", "        ", "seed_everything", "(", "12", ")", "\n", "warnings", ".", "filterwarnings", "(", "\n", "\"ignore\"", ",", "\n", "#category=PossibleUserWarning,", "\n", "message", "=", "\"GPU available but not used.*\"", ",", "\n", ")", "\n", "trainer", "=", "Trainer", "(", "\n", "accelerator", "=", "\"cpu\"", ",", "\n", "max_epochs", "=", "4", ",", "\n", "deterministic", "=", "True", ",", "\n", "enable_checkpointing", "=", "True", ",", "\n", "default_root_dir", "=", "DATA_PATH", ",", "\n", "logger", "=", "False", ",", "\n", "enable_progress_bar", "=", "False", ",", "\n", ")", "\n", "model", "=", "RankingMetric", "(", "\n", "encoder_model", "=", "\"BERT\"", ",", "\n", "pretrained_model", "=", "\"google/bert_uncased_L-2_H-128_A-2\"", ",", "\n", "train_data", "=", "os", ".", "path", ".", "join", "(", "DATA_PATH", ",", "\"test_ranking_data.csv\"", ")", ",", "\n", "validation_data", "=", "os", ".", "path", ".", "join", "(", "DATA_PATH", ",", "\"test_ranking_data.csv\"", ")", ",", "\n", "layerwise_decay", "=", "0.95", ",", "\n", "batch_size", "=", "32", ",", "\n", "learning_rate", "=", "1e-04", ",", "\n", "encoder_learning_rate", "=", "1e-04", ",", "\n", ")", "\n", "warnings", ".", "filterwarnings", "(", "\n", "\"ignore\"", ",", "\n", "category", "=", "UserWarning", ",", "\n", "message", "=", "\".*Consider increasing the value of the `num_workers` argument` .*\"", ",", "\n", ")", "\n", "trainer", ".", "fit", "(", "model", ")", "\n", "self", ".", "assertTrue", "(", "\n", "os", ".", "path", ".", "exists", "(", "\n", "os", ".", "path", ".", "join", "(", "DATA_PATH", ",", "\"checkpoints\"", ",", "\"epoch=3-step=16.ckpt\"", ")", "\n", ")", "\n", ")", "\n", "saved_model", "=", "RankingMetric", ".", "load_from_checkpoint", "(", "\n", "os", ".", "path", ".", "join", "(", "DATA_PATH", ",", "\"checkpoints\"", ",", "\"epoch=3-step=16.ckpt\"", ")", "\n", ")", "\n", "dataset", "=", "saved_model", ".", "read_csv", "(", "\n", "os", ".", "path", ".", "join", "(", "DATA_PATH", ",", "\"test_regression_data.csv\"", ")", ",", "regression", "=", "True", "\n", ")", "\n", "y", "=", "[", "s", "[", "\"score\"", "]", "for", "s", "in", "dataset", "]", "\n", "dataloader", "=", "DataLoader", "(", "\n", "dataset", "=", "dataset", ",", "\n", "batch_size", "=", "256", ",", "\n", "collate_fn", "=", "lambda", "x", ":", "saved_model", ".", "prepare_sample", "(", "x", ",", "inference", "=", "True", ")", ",", "\n", "num_workers", "=", "2", ",", "\n", ")", "\n", "y_hat", "=", "(", "\n", "torch", ".", "cat", "(", "\n", "trainer", ".", "predict", "(", "\n", "ckpt_path", "=", "\"best\"", ",", "dataloaders", "=", "dataloader", ",", "return_predictions", "=", "True", "\n", ")", ",", "\n", "dim", "=", "0", ",", "\n", ")", "\n", ".", "cpu", "(", ")", "\n", ".", "tolist", "(", ")", "\n", ")", "\n", "# This shouldn't break!", "\n", "pearsonr", "(", "y_hat", ",", "y", ")", "[", "0", "]", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Unbabel_COMET.models.test_referenceless_regression.TestReferencelessRegression.tearDownClass": [[20, 23], ["shutil.rmtree", "os.path.join"], "methods", ["None"], ["    ", "@", "classmethod", "\n", "def", "tearDownClass", "(", "cls", ")", ":", "\n", "        ", "shutil", ".", "rmtree", "(", "os", ".", "path", ".", "join", "(", "DATA_PATH", ",", "\"checkpoints\"", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Unbabel_COMET.models.test_referenceless_regression.TestReferencelessRegression.test_training": [[24, 87], ["pytorch_lightning.seed_everything", "warnings.filterwarnings", "pytorch_lightning.trainer.trainer.Trainer", "comet.models.ReferencelessRegression", "warnings.filterwarnings", "pytorch_lightning.trainer.trainer.Trainer.fit", "test_referenceless_regression.TestReferencelessRegression.assertTrue", "comet.models.ReferencelessRegression.load_from_checkpoint", "comet.models.ReferencelessRegression.load_from_checkpoint.read_csv", "torch.utils.data.DataLoader", "torch.cat().cpu().tolist", "os.path.exists", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "torch.cat().cpu", "scipy.stats.pearsonr", "comet.models.ReferencelessRegression.load_from_checkpoint.prepare_sample", "torch.cat", "pytorch_lightning.trainer.trainer.Trainer.predict"], "methods", ["home.repos.pwc.inspect_result.Unbabel_COMET.models.__init__.load_from_checkpoint", "home.repos.pwc.inspect_result.Unbabel_COMET.regression.referenceless.ReferencelessRegression.read_csv", "home.repos.pwc.inspect_result.Unbabel_COMET.regression.referenceless.ReferencelessRegression.prepare_sample", "home.repos.pwc.inspect_result.Unbabel_COMET.models.base.CometModel.predict"], ["", "def", "test_training", "(", "self", ")", ":", "\n", "        ", "seed_everything", "(", "12", ")", "\n", "warnings", ".", "filterwarnings", "(", "\n", "\"ignore\"", ",", "\n", "#category=PossibleUserWarning,", "\n", "message", "=", "\"GPU available but not used.*\"", ",", "\n", ")", "\n", "trainer", "=", "Trainer", "(", "\n", "accelerator", "=", "\"cpu\"", ",", "\n", "max_epochs", "=", "10", ",", "\n", "deterministic", "=", "True", ",", "\n", "enable_checkpointing", "=", "True", ",", "\n", "default_root_dir", "=", "DATA_PATH", ",", "\n", "logger", "=", "False", ",", "\n", "enable_progress_bar", "=", "False", ",", "\n", ")", "\n", "model", "=", "ReferencelessRegression", "(", "\n", "encoder_model", "=", "\"BERT\"", ",", "\n", "pretrained_model", "=", "\"google/bert_uncased_L-2_H-128_A-2\"", ",", "\n", "train_data", "=", "os", ".", "path", ".", "join", "(", "DATA_PATH", ",", "\"test_regression_data.csv\"", ")", ",", "\n", "validation_data", "=", "os", ".", "path", ".", "join", "(", "DATA_PATH", ",", "\"test_regression_data.csv\"", ")", ",", "\n", "hidden_sizes", "=", "[", "256", "]", ",", "\n", "layerwise_decay", "=", "0.95", ",", "\n", "batch_size", "=", "32", ",", "\n", "learning_rate", "=", "1e-04", ",", "\n", "encoder_learning_rate", "=", "1e-04", ",", "\n", ")", "\n", "warnings", ".", "filterwarnings", "(", "\n", "\"ignore\"", ",", "\n", "category", "=", "UserWarning", ",", "\n", "message", "=", "\".*Consider increasing the value of the `num_workers` argument` .*\"", ",", "\n", ")", "\n", "trainer", ".", "fit", "(", "model", ")", "\n", "self", ".", "assertTrue", "(", "\n", "os", ".", "path", ".", "exists", "(", "\n", "os", ".", "path", ".", "join", "(", "DATA_PATH", ",", "\"checkpoints\"", ",", "\"epoch=9-step=160.ckpt\"", ")", "\n", ")", "\n", ")", "\n", "\n", "saved_model", "=", "ReferencelessRegression", ".", "load_from_checkpoint", "(", "\n", "os", ".", "path", ".", "join", "(", "DATA_PATH", ",", "\"checkpoints\"", ",", "\"epoch=9-step=160.ckpt\"", ")", "\n", ")", "\n", "dataset", "=", "saved_model", ".", "read_csv", "(", "\n", "os", ".", "path", ".", "join", "(", "DATA_PATH", ",", "\"test_regression_data.csv\"", ")", "\n", ")", "\n", "y", "=", "[", "s", "[", "\"score\"", "]", "for", "s", "in", "dataset", "]", "\n", "dataloader", "=", "DataLoader", "(", "\n", "dataset", "=", "dataset", ",", "\n", "batch_size", "=", "256", ",", "\n", "collate_fn", "=", "lambda", "x", ":", "saved_model", ".", "prepare_sample", "(", "x", ",", "inference", "=", "True", ")", ",", "\n", "num_workers", "=", "2", ",", "\n", ")", "\n", "y_hat", "=", "(", "\n", "torch", ".", "cat", "(", "\n", "trainer", ".", "predict", "(", "\n", "ckpt_path", "=", "\"best\"", ",", "dataloaders", "=", "dataloader", ",", "return_predictions", "=", "True", "\n", ")", ",", "\n", "dim", "=", "0", ",", "\n", ")", "\n", ".", "cpu", "(", ")", "\n", ".", "tolist", "(", ")", "\n", ")", "\n", "assert", "pearsonr", "(", "y_hat", ",", "y", ")", "[", "0", "]", ">", "0.77", "", "", "", ""]], "home.repos.pwc.inspect_result.Unbabel_COMET.models.test_regression_metric.TestRegressionMetric.tearDownClass": [[20, 23], ["shutil.rmtree", "os.path.join"], "methods", ["None"], ["    ", "@", "classmethod", "\n", "def", "tearDownClass", "(", "cls", ")", ":", "\n", "        ", "shutil", ".", "rmtree", "(", "os", ".", "path", ".", "join", "(", "DATA_PATH", ",", "\"checkpoints\"", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Unbabel_COMET.models.test_regression_metric.TestRegressionMetric.test_training": [[24, 87], ["pytorch_lightning.seed_everything", "warnings.filterwarnings", "pytorch_lightning.trainer.trainer.Trainer", "comet.models.RegressionMetric", "warnings.filterwarnings", "pytorch_lightning.trainer.trainer.Trainer.fit", "test_regression_metric.TestRegressionMetric.assertTrue", "comet.models.RegressionMetric.load_from_checkpoint", "comet.models.RegressionMetric.load_from_checkpoint.read_csv", "torch.utils.data.DataLoader", "torch.cat().cpu().tolist", "os.path.exists", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "torch.cat().cpu", "scipy.stats.pearsonr", "comet.models.RegressionMetric.load_from_checkpoint.prepare_sample", "torch.cat", "pytorch_lightning.trainer.trainer.Trainer.predict"], "methods", ["home.repos.pwc.inspect_result.Unbabel_COMET.models.__init__.load_from_checkpoint", "home.repos.pwc.inspect_result.Unbabel_COMET.regression.referenceless.ReferencelessRegression.read_csv", "home.repos.pwc.inspect_result.Unbabel_COMET.regression.referenceless.ReferencelessRegression.prepare_sample", "home.repos.pwc.inspect_result.Unbabel_COMET.models.base.CometModel.predict"], ["", "def", "test_training", "(", "self", ")", ":", "\n", "        ", "seed_everything", "(", "12", ")", "\n", "warnings", ".", "filterwarnings", "(", "\n", "\"ignore\"", ",", "\n", "#category=PossibleUserWarning,", "\n", "message", "=", "\"GPU available but not used.*\"", ",", "\n", ")", "\n", "trainer", "=", "Trainer", "(", "\n", "accelerator", "=", "\"cpu\"", ",", "\n", "max_epochs", "=", "10", ",", "\n", "deterministic", "=", "True", ",", "\n", "enable_checkpointing", "=", "True", ",", "\n", "default_root_dir", "=", "DATA_PATH", ",", "\n", "logger", "=", "False", ",", "\n", "enable_progress_bar", "=", "False", ",", "\n", ")", "\n", "model", "=", "RegressionMetric", "(", "\n", "encoder_model", "=", "\"BERT\"", ",", "\n", "pretrained_model", "=", "\"google/bert_uncased_L-2_H-128_A-2\"", ",", "\n", "train_data", "=", "os", ".", "path", ".", "join", "(", "DATA_PATH", ",", "\"test_regression_data.csv\"", ")", ",", "\n", "validation_data", "=", "os", ".", "path", ".", "join", "(", "DATA_PATH", ",", "\"test_regression_data.csv\"", ")", ",", "\n", "hidden_sizes", "=", "[", "384", "]", ",", "\n", "layerwise_decay", "=", "0.95", ",", "\n", "batch_size", "=", "32", ",", "\n", "learning_rate", "=", "1e-04", ",", "\n", "encoder_learning_rate", "=", "1e-04", ",", "\n", ")", "\n", "warnings", ".", "filterwarnings", "(", "\n", "\"ignore\"", ",", "\n", "category", "=", "UserWarning", ",", "\n", "message", "=", "\".*Consider increasing the value of the `num_workers` argument` .*\"", ",", "\n", ")", "\n", "trainer", ".", "fit", "(", "model", ")", "\n", "self", ".", "assertTrue", "(", "\n", "os", ".", "path", ".", "exists", "(", "\n", "os", ".", "path", ".", "join", "(", "DATA_PATH", ",", "\"checkpoints\"", ",", "\"epoch=9-step=160.ckpt\"", ")", "\n", ")", "\n", ")", "\n", "\n", "saved_model", "=", "RegressionMetric", ".", "load_from_checkpoint", "(", "\n", "os", ".", "path", ".", "join", "(", "DATA_PATH", ",", "\"checkpoints\"", ",", "\"epoch=9-step=160.ckpt\"", ")", "\n", ")", "\n", "dataset", "=", "saved_model", ".", "read_csv", "(", "\n", "os", ".", "path", ".", "join", "(", "DATA_PATH", ",", "\"test_regression_data.csv\"", ")", "\n", ")", "\n", "y", "=", "[", "s", "[", "\"score\"", "]", "for", "s", "in", "dataset", "]", "\n", "dataloader", "=", "DataLoader", "(", "\n", "dataset", "=", "dataset", ",", "\n", "batch_size", "=", "256", ",", "\n", "collate_fn", "=", "lambda", "x", ":", "saved_model", ".", "prepare_sample", "(", "x", ",", "inference", "=", "True", ")", ",", "\n", "num_workers", "=", "2", ",", "\n", ")", "\n", "y_hat", "=", "(", "\n", "torch", ".", "cat", "(", "\n", "trainer", ".", "predict", "(", "\n", "ckpt_path", "=", "\"best\"", ",", "dataloaders", "=", "dataloader", ",", "return_predictions", "=", "True", "\n", ")", ",", "\n", "dim", "=", "0", ",", "\n", ")", "\n", ".", "cpu", "(", ")", "\n", ".", "tolist", "(", ")", "\n", ")", "\n", "assert", "pearsonr", "(", "y_hat", ",", "y", ")", "[", "0", "]", ">", "0.77", "", "", "", ""]], "home.repos.pwc.inspect_result.Unbabel_COMET.models.base.OrderedSampler.__init__": [[47, 49], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "indices", ":", "List", "[", "int", "]", ")", ":", "\n", "        ", "self", ".", "indices", "=", "indices", "\n", "\n"]], "home.repos.pwc.inspect_result.Unbabel_COMET.models.base.OrderedSampler.__iter__": [[50, 52], ["iter"], "methods", ["None"], ["", "def", "__iter__", "(", "self", ")", ":", "\n", "        ", "return", "iter", "(", "self", ".", "indices", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Unbabel_COMET.models.base.OrderedSampler.__len__": [[53, 55], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "indices", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Unbabel_COMET.models.base.CometModel.__init__": [[87, 153], ["pytorch_lightning.LightningModule.__init__", "base.CometModel.save_hyperparameters", "str2encoder[].from_pretrained", "comet.modules.LayerwiseAttention", "base.CometModel.freeze_encoder", "base.CometModel.encoder.freeze_embeddings", "os.path.exists", "packaging.version.parse", "packaging.version.parse", "Exception", "base.CometModel.load_weights", "logger.warning"], "methods", ["home.repos.pwc.inspect_result.Unbabel_COMET.regression.referenceless.ReferencelessRegression.__init__", "home.repos.pwc.inspect_result.Unbabel_COMET.encoders.xlmr.XLMREncoder.from_pretrained", "home.repos.pwc.inspect_result.Unbabel_COMET.models.base.CometModel.freeze_encoder", "home.repos.pwc.inspect_result.Unbabel_COMET.encoders.bert.BERTEncoder.freeze_embeddings", "home.repos.pwc.inspect_result.Unbabel_COMET.models.base.CometModel.load_weights"], ["def", "__init__", "(", "\n", "self", ",", "\n", "nr_frozen_epochs", ":", "Union", "[", "float", ",", "int", "]", "=", "0.3", ",", "\n", "keep_embeddings_frozen", ":", "bool", "=", "False", ",", "\n", "optimizer", ":", "str", "=", "\"AdamW\"", ",", "\n", "encoder_learning_rate", ":", "float", "=", "1e-05", ",", "\n", "learning_rate", ":", "float", "=", "3e-05", ",", "\n", "layerwise_decay", ":", "float", "=", "0.95", ",", "\n", "encoder_model", ":", "str", "=", "\"XLM-RoBERTa\"", ",", "\n", "pretrained_model", ":", "str", "=", "\"xlm-roberta-large\"", ",", "\n", "pool", ":", "str", "=", "\"avg\"", ",", "\n", "layer", ":", "Union", "[", "str", ",", "int", "]", "=", "\"mix\"", ",", "\n", "dropout", ":", "float", "=", "0.1", ",", "\n", "batch_size", ":", "int", "=", "4", ",", "\n", "train_data", ":", "Optional", "[", "str", "]", "=", "None", ",", "\n", "validation_data", ":", "Optional", "[", "str", "]", "=", "None", ",", "\n", "load_weights_from_checkpoint", ":", "Optional", "[", "str", "]", "=", "None", ",", "\n", "class_identifier", ":", "Optional", "[", "str", "]", "=", "None", ",", "\n", ")", "->", "None", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "save_hyperparameters", "(", "\n", "ignore", "=", "[", "\"train_data\"", ",", "\"validation_data\"", ",", "\"load_weights_from_checkpoint\"", "]", "\n", ")", "\n", "\n", "if", "self", ".", "hparams", ".", "encoder_model", "==", "\"XLM-RoBERTa-XL\"", ":", "\n", "# Ensure backwards compatibility with transformer versions", "\n", "            ", "if", "version", ".", "parse", "(", "transformers", ".", "__version__", ")", "<", "version", ".", "parse", "(", "\"4.17.0\"", ")", ":", "\n", "                ", "raise", "Exception", "(", "\n", "\"XLM-RoBERTa-XL requires transformers>=4.17.0. Your current version is {}\"", ".", "format", "(", "\n", "transformers", ".", "__version__", "\n", ")", "\n", ")", "\n", "\n", "", "", "self", ".", "encoder", "=", "str2encoder", "[", "self", ".", "hparams", ".", "encoder_model", "]", ".", "from_pretrained", "(", "\n", "self", ".", "hparams", ".", "pretrained_model", "\n", ")", "\n", "\n", "self", ".", "epoch_nr", "=", "0", "\n", "if", "self", ".", "hparams", ".", "layer", "==", "\"mix\"", ":", "\n", "            ", "self", ".", "layerwise_attention", "=", "LayerwiseAttention", "(", "\n", "num_layers", "=", "self", ".", "encoder", ".", "num_layers", ",", "\n", "dropout", "=", "self", ".", "hparams", ".", "dropout", ",", "\n", "layer_norm", "=", "True", ",", "\n", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "layerwise_attention", "=", "None", "\n", "\n", "", "if", "self", ".", "hparams", ".", "nr_frozen_epochs", ">", "0", ":", "\n", "            ", "self", ".", "_frozen", "=", "True", "\n", "self", ".", "freeze_encoder", "(", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "_frozen", "=", "False", "\n", "\n", "", "if", "self", ".", "hparams", ".", "keep_embeddings_frozen", ":", "\n", "            ", "self", ".", "encoder", ".", "freeze_embeddings", "(", ")", "\n", "\n", "", "self", ".", "nr_frozen_epochs", "=", "self", ".", "hparams", ".", "nr_frozen_epochs", "\n", "\n", "if", "load_weights_from_checkpoint", "is", "not", "None", ":", "\n", "            ", "if", "os", ".", "path", ".", "exists", "(", "load_weights_from_checkpoint", ")", ":", "\n", "                ", "self", ".", "load_weights", "(", "load_weights_from_checkpoint", ")", "\n", "", "else", ":", "\n", "                ", "logger", ".", "warning", "(", "f\"Path {load_weights_from_checkpoint} does not exist!\"", ")", "\n", "\n", "", "", "self", ".", "mc_dropout", "=", "False", "# Flag used to control usage of MC Dropout", "\n", "self", ".", "caching", "=", "False", "# Flag used to control Embedding Caching", "\n", "\n"]], "home.repos.pwc.inspect_result.Unbabel_COMET.models.base.CometModel.set_mc_dropout": [[154, 156], ["None"], "methods", ["None"], ["", "def", "set_mc_dropout", "(", "self", ",", "value", ":", "bool", ")", ":", "\n", "        ", "self", ".", "mc_dropout", "=", "value", "\n", "\n"]], "home.repos.pwc.inspect_result.Unbabel_COMET.models.base.CometModel.load_weights": [[157, 175], ["logger.info", "torch.load", "base.CometModel.state_dict", "base.CometModel.update", "base.CometModel.load_state_dict", "pretrained_dict.items"], "methods", ["home.repos.pwc.inspect_result.Unbabel_COMET.models.metrics.WMTKendall.update"], ["", "def", "load_weights", "(", "self", ",", "checkpoint", ":", "str", ")", "->", "None", ":", "\n", "        ", "\"\"\"Function that loads the weights from a given checkpoint file.\n        Note:\n            If the checkpoint model architecture is different then `self`, only\n            the common parts will be loaded.\n\n        :param checkpoint: Path to the checkpoint containing the weights to be loaded.\n        \"\"\"", "\n", "logger", ".", "info", "(", "f\"Loading weights from {checkpoint}.\"", ")", "\n", "checkpoint", "=", "torch", ".", "load", "(", "checkpoint", ",", "map_location", "=", "lambda", "storage", ",", "loc", ":", "storage", ")", "\n", "pretrained_dict", "=", "checkpoint", "[", "\"state_dict\"", "]", "\n", "model_dict", "=", "self", ".", "state_dict", "(", ")", "\n", "# 1. filter out unnecessary keys", "\n", "pretrained_dict", "=", "{", "k", ":", "v", "for", "k", ",", "v", "in", "pretrained_dict", ".", "items", "(", ")", "if", "k", "in", "model_dict", "}", "\n", "# 2. overwrite entries in the existing state dict", "\n", "model_dict", ".", "update", "(", "pretrained_dict", ")", "\n", "# 3. load the new state dict", "\n", "self", ".", "load_state_dict", "(", "model_dict", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Unbabel_COMET.models.base.CometModel.read_csv": [[176, 179], ["None"], "methods", ["None"], ["", "@", "abc", ".", "abstractmethod", "\n", "def", "read_csv", "(", "self", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.Unbabel_COMET.models.base.CometModel.prepare_sample": [[180, 185], ["None"], "methods", ["None"], ["", "@", "abc", ".", "abstractmethod", "\n", "def", "prepare_sample", "(", "\n", "self", ",", "sample", ":", "List", "[", "Dict", "[", "str", ",", "Union", "[", "str", ",", "float", "]", "]", "]", ",", "*", "args", ",", "**", "kwargs", "\n", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.Unbabel_COMET.models.base.CometModel.configure_optimizers": [[186, 189], ["None"], "methods", ["None"], ["", "@", "abc", ".", "abstractmethod", "\n", "def", "configure_optimizers", "(", "self", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.Unbabel_COMET.models.base.CometModel.init_metrics": [[190, 193], ["None"], "methods", ["None"], ["", "@", "abc", ".", "abstractmethod", "\n", "def", "init_metrics", "(", "self", ")", "->", "None", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.Unbabel_COMET.models.base.CometModel.forward": [[194, 197], ["None"], "methods", ["None"], ["", "@", "abc", ".", "abstractmethod", "\n", "def", "forward", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", "->", "Dict", "[", "str", ",", "torch", ".", "Tensor", "]", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.Unbabel_COMET.models.base.CometModel.is_referenceless": [[198, 201], ["None"], "methods", ["None"], ["", "@", "abc", ".", "abstractmethod", "\n", "def", "is_referenceless", "(", "self", ")", "->", "bool", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.Unbabel_COMET.models.base.CometModel.freeze_encoder": [[202, 205], ["logger.info", "base.CometModel.encoder.freeze"], "methods", ["home.repos.pwc.inspect_result.Unbabel_COMET.encoders.base.Encoder.freeze"], ["", "def", "freeze_encoder", "(", "self", ")", "->", "None", ":", "\n", "        ", "logger", ".", "info", "(", "\"Encoder model frozen.\"", ")", "\n", "self", ".", "encoder", ".", "freeze", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Unbabel_COMET.models.base.CometModel.loss": [[206, 209], ["torch.nn.MSELoss"], "methods", ["None"], ["", "@", "property", "\n", "def", "loss", "(", "self", ")", "->", "None", ":", "\n", "        ", "return", "nn", ".", "MSELoss", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Unbabel_COMET.models.base.CometModel.compute_loss": [[210, 214], ["base.CometModel.loss", "predictions[].view"], "methods", ["home.repos.pwc.inspect_result.Unbabel_COMET.ranking.ranking_metric.RankingMetric.loss"], ["", "def", "compute_loss", "(", "\n", "self", ",", "predictions", ":", "Dict", "[", "str", ",", "torch", ".", "Tensor", "]", ",", "targets", ":", "Dict", "[", "str", ",", "torch", ".", "Tensor", "]", "\n", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "return", "self", ".", "loss", "(", "predictions", "[", "\"score\"", "]", ".", "view", "(", "-", "1", ")", ",", "targets", "[", "\"score\"", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Unbabel_COMET.models.base.CometModel.unfreeze_encoder": [[215, 224], ["base.CometModel.encoder.unfreeze", "logger.info", "base.CometModel.encoder.freeze_embeddings"], "methods", ["home.repos.pwc.inspect_result.Unbabel_COMET.encoders.base.Encoder.unfreeze", "home.repos.pwc.inspect_result.Unbabel_COMET.encoders.bert.BERTEncoder.freeze_embeddings"], ["", "def", "unfreeze_encoder", "(", "self", ")", "->", "None", ":", "\n", "        ", "if", "self", ".", "_frozen", ":", "\n", "            ", "if", "self", ".", "trainer", ".", "is_global_zero", ":", "\n", "                ", "logger", ".", "info", "(", "\"Encoder model fine-tuning\"", ")", "\n", "\n", "", "self", ".", "encoder", ".", "unfreeze", "(", ")", "\n", "self", ".", "_frozen", "=", "False", "\n", "if", "self", ".", "hparams", ".", "keep_embeddings_frozen", ":", "\n", "                ", "self", ".", "encoder", ".", "freeze_embeddings", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Unbabel_COMET.models.base.CometModel.on_train_epoch_end": [[225, 231], ["base.CometModel.unfreeze_encoder"], "methods", ["home.repos.pwc.inspect_result.Unbabel_COMET.models.base.CometModel.unfreeze_encoder"], ["", "", "", "def", "on_train_epoch_end", "(", "self", ")", "->", "None", ":", "\n", "        ", "\"\"\"Hook used to unfreeze encoder during training.\"\"\"", "\n", "self", ".", "epoch_nr", "+=", "1", "\n", "if", "self", ".", "epoch_nr", ">=", "self", ".", "nr_frozen_epochs", "and", "self", ".", "_frozen", ":", "\n", "            ", "self", ".", "unfreeze_encoder", "(", ")", "\n", "self", ".", "_frozen", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.Unbabel_COMET.models.base.CometModel.set_embedding_cache": [[232, 235], ["None"], "methods", ["None"], ["", "", "def", "set_embedding_cache", "(", "self", ")", ":", "\n", "        ", "\"\"\"Function that when called turns embedding caching on.\"\"\"", "\n", "self", ".", "caching", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.Unbabel_COMET.models.base.CometModel.get_sentence_embedding": [[236, 251], ["base.CometModel.retrieve_sentence_embedding", "base.CometModel.compute_sentence_embedding"], "methods", ["home.repos.pwc.inspect_result.Unbabel_COMET.models.base.CometModel.retrieve_sentence_embedding", "home.repos.pwc.inspect_result.Unbabel_COMET.models.base.CometModel.compute_sentence_embedding"], ["", "def", "get_sentence_embedding", "(", "\n", "self", ",", "input_ids", ":", "torch", ".", "Tensor", ",", "attention_mask", ":", "torch", ".", "Tensor", "\n", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\"Function that extracts sentence embeddings for\n            a single sentence.\n\n        :param tokens: sequences [batch_size x seq_len]\n        :param lengths: lengths [batch_size]\n\n        :return: torch.Tensor [batch_size x hidden_size]\n        \"\"\"", "\n", "if", "self", ".", "caching", ":", "\n", "            ", "return", "self", ".", "retrieve_sentence_embedding", "(", "input_ids", ",", "attention_mask", ")", "\n", "", "else", ":", "\n", "            ", "return", "self", ".", "compute_sentence_embedding", "(", "input_ids", ",", "attention_mask", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Unbabel_COMET.models.base.CometModel.retrieve_sentence_embedding": [[252, 258], ["lru_cache.tensor_lru_cache", "base.CometModel.compute_sentence_embedding"], "methods", ["home.repos.pwc.inspect_result.Unbabel_COMET.models.lru_cache.tensor_lru_cache", "home.repos.pwc.inspect_result.Unbabel_COMET.models.base.CometModel.compute_sentence_embedding"], ["", "", "@", "tensor_lru_cache", "(", "maxsize", "=", "CACHE_SIZE", ")", "\n", "def", "retrieve_sentence_embedding", "(", "\n", "self", ",", "input_ids", ":", "torch", ".", "Tensor", ",", "attention_mask", ":", "torch", ".", "Tensor", "\n", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\"Wrapper for `get_sentence_embedding` function that caches results.\"\"\"", "\n", "return", "self", ".", "compute_sentence_embedding", "(", "input_ids", ",", "attention_mask", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Unbabel_COMET.models.base.CometModel.compute_sentence_embedding": [[259, 313], ["base.CometModel.encoder", "len", "range", "torch.cat", "base.CometModel.layerwise_attention", "Exception", "pooling_utils.max_pooling", "torch.split", "range", "base.CometModel.append", "pooling_utils.average_pooling", "len", "torch.split", "all_layers.append", "torch.split", "base.CometModel.layerwise_attention", "Exception"], "methods", ["home.repos.pwc.inspect_result.Unbabel_COMET.models.pooling_utils.max_pooling", "home.repos.pwc.inspect_result.Unbabel_COMET.models.pooling_utils.average_pooling"], ["", "def", "compute_sentence_embedding", "(", "\n", "self", ",", "input_ids", ":", "torch", ".", "Tensor", ",", "attention_mask", ":", "torch", ".", "Tensor", "\n", ")", "->", "torch", ".", "Tensor", ":", "\n", "\n", "        ", "encoder_out", "=", "self", ".", "encoder", "(", "input_ids", ",", "attention_mask", ")", "\n", "if", "self", ".", "layerwise_attention", ":", "\n", "# HACK: LayerNorm is applied at the MiniBatch. This means that for big batch sizes the variance", "\n", "# and norm within the batch will create small differences in the final score", "\n", "# If we are predicting we split the data into equal size batches to minimize this variance.", "\n", "            ", "if", "not", "self", ".", "training", ":", "\n", "                ", "n_splits", "=", "len", "(", "torch", ".", "split", "(", "encoder_out", "[", "\"all_layers\"", "]", "[", "-", "1", "]", ",", "8", ")", ")", "\n", "embeddings", "=", "[", "]", "\n", "for", "split", "in", "range", "(", "n_splits", ")", ":", "\n", "                    ", "all_layers", "=", "[", "]", "\n", "for", "layer", "in", "range", "(", "len", "(", "encoder_out", "[", "\"all_layers\"", "]", ")", ")", ":", "\n", "                        ", "layer_embs", "=", "torch", ".", "split", "(", "encoder_out", "[", "\"all_layers\"", "]", "[", "layer", "]", ",", "8", ")", "\n", "all_layers", ".", "append", "(", "layer_embs", "[", "split", "]", ")", "\n", "", "split_attn", "=", "torch", ".", "split", "(", "attention_mask", ",", "8", ")", "[", "split", "]", "\n", "embeddings", ".", "append", "(", "self", ".", "layerwise_attention", "(", "all_layers", ",", "split_attn", ")", ")", "\n", "", "embeddings", "=", "torch", ".", "cat", "(", "embeddings", ",", "dim", "=", "0", ")", "\n", "", "else", ":", "\n", "                ", "embeddings", "=", "self", ".", "layerwise_attention", "(", "\n", "encoder_out", "[", "\"all_layers\"", "]", ",", "attention_mask", "\n", ")", "\n", "\n", "", "", "elif", "self", ".", "hparams", ".", "layer", ">=", "0", "and", "self", ".", "hparams", ".", "layer", "<", "self", ".", "encoder", ".", "num_layers", ":", "\n", "            ", "embeddings", "=", "encoder_out", "[", "\"all_layers\"", "]", "[", "self", ".", "hparams", ".", "layer", "]", "\n", "\n", "", "else", ":", "\n", "            ", "raise", "Exception", "(", "\"Invalid model layer {}.\"", ".", "format", "(", "self", ".", "hparams", ".", "layer", ")", ")", "\n", "\n", "", "if", "self", ".", "hparams", ".", "pool", "==", "\"default\"", ":", "\n", "            ", "sentemb", "=", "encoder_out", "[", "\"sentemb\"", "]", "\n", "\n", "", "elif", "self", ".", "hparams", ".", "pool", "==", "\"max\"", ":", "\n", "            ", "sentemb", "=", "max_pooling", "(", "\n", "input_ids", ",", "embeddings", ",", "self", ".", "encoder", ".", "tokenizer", ".", "pad_token_id", "\n", ")", "\n", "\n", "", "elif", "self", ".", "hparams", ".", "pool", "==", "\"avg\"", ":", "\n", "            ", "sentemb", "=", "average_pooling", "(", "\n", "input_ids", ",", "\n", "embeddings", ",", "\n", "attention_mask", ",", "\n", "self", ".", "encoder", ".", "tokenizer", ".", "pad_token_id", ",", "\n", ")", "\n", "\n", "", "elif", "self", ".", "hparams", ".", "pool", "==", "\"cls\"", ":", "\n", "            ", "sentemb", "=", "embeddings", "[", ":", ",", "0", ",", ":", "]", "\n", "\n", "", "else", ":", "\n", "            ", "raise", "Exception", "(", "\"Invalid pooling technique.\"", ")", "\n", "\n", "", "return", "sentemb", "\n", "\n"]], "home.repos.pwc.inspect_result.Unbabel_COMET.models.base.CometModel.training_step": [[314, 341], ["base.CometModel.forward", "base.CometModel.compute_loss", "base.CometModel.log", "base.CometModel.unfreeze_encoder"], "methods", ["home.repos.pwc.inspect_result.Unbabel_COMET.regression.referenceless.ReferencelessRegression.forward", "home.repos.pwc.inspect_result.Unbabel_COMET.models.base.CometModel.compute_loss", "home.repos.pwc.inspect_result.Unbabel_COMET.models.base.CometModel.unfreeze_encoder"], ["", "def", "training_step", "(", "\n", "self", ",", "\n", "batch", ":", "Tuple", "[", "Dict", "[", "str", ",", "torch", ".", "Tensor", "]", ",", "Dict", "[", "str", ",", "torch", ".", "Tensor", "]", "]", ",", "\n", "batch_nb", ":", "int", ",", "\n", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\"\n        Runs one training step and logs the training loss.\n\n        :param batch: The output of your prepare_sample function.\n        :param batch_nb: Integer displaying which batch this is.\n\n        :returns: Loss value\n        \"\"\"", "\n", "batch_input", ",", "batch_target", "=", "batch", "\n", "batch_prediction", "=", "self", ".", "forward", "(", "**", "batch_input", ")", "\n", "loss_value", "=", "self", ".", "compute_loss", "(", "batch_prediction", ",", "batch_target", ")", "\n", "\n", "if", "(", "\n", "self", ".", "nr_frozen_epochs", "<", "1.0", "\n", "and", "self", ".", "nr_frozen_epochs", ">", "0.0", "\n", "and", "batch_nb", ">", "self", ".", "epoch_total_steps", "*", "self", ".", "nr_frozen_epochs", "\n", ")", ":", "\n", "            ", "self", ".", "unfreeze_encoder", "(", ")", "\n", "self", ".", "_frozen", "=", "False", "\n", "\n", "", "self", ".", "log", "(", "\"train_loss\"", ",", "loss_value", ",", "on_step", "=", "True", ",", "on_epoch", "=", "True", ")", "\n", "return", "loss_value", "\n", "\n"]], "home.repos.pwc.inspect_result.Unbabel_COMET.models.base.CometModel.validation_step": [[342, 370], ["base.CometModel.forward", "base.CometModel.compute_loss", "base.CometModel.log", "batch_prediction[].view().size", "torch.Size", "base.CometModel.train_metrics.update", "batch_prediction[].view", "batch_prediction[].view", "base.CometModel.val_metrics.update", "batch_prediction[].view"], "methods", ["home.repos.pwc.inspect_result.Unbabel_COMET.regression.referenceless.ReferencelessRegression.forward", "home.repos.pwc.inspect_result.Unbabel_COMET.models.base.CometModel.compute_loss", "home.repos.pwc.inspect_result.Unbabel_COMET.models.metrics.WMTKendall.update", "home.repos.pwc.inspect_result.Unbabel_COMET.models.metrics.WMTKendall.update"], ["", "def", "validation_step", "(", "\n", "self", ",", "\n", "batch", ":", "Tuple", "[", "Dict", "[", "str", ",", "torch", ".", "Tensor", "]", ",", "Dict", "[", "str", ",", "torch", ".", "Tensor", "]", "]", ",", "\n", "batch_nb", ":", "int", ",", "\n", "dataloader_idx", ":", "int", ",", "\n", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Runs one validation step and logs metrics.\n\n        :param batch: The output of your prepare_sample function.\n        :param batch_nb: Integer displaying which batch this is.\n        :param dataloader_idx: Integer displaying which dataloader this is.\n        \"\"\"", "\n", "batch_input", ",", "batch_target", "=", "batch", "\n", "batch_prediction", "=", "self", ".", "forward", "(", "**", "batch_input", ")", "\n", "loss_value", "=", "self", ".", "compute_loss", "(", "batch_prediction", ",", "batch_target", ")", "\n", "\n", "self", ".", "log", "(", "\"val_loss\"", ",", "loss_value", ",", "on_step", "=", "True", ",", "on_epoch", "=", "True", ")", "\n", "\n", "# TODO: REMOVE if condition after torchmetrics bug fix", "\n", "if", "batch_prediction", "[", "\"score\"", "]", ".", "view", "(", "-", "1", ")", ".", "size", "(", ")", "!=", "torch", ".", "Size", "(", "[", "1", "]", ")", ":", "\n", "            ", "if", "dataloader_idx", "==", "0", ":", "\n", "                ", "self", ".", "train_metrics", ".", "update", "(", "\n", "batch_prediction", "[", "\"score\"", "]", ".", "view", "(", "-", "1", ")", ",", "batch_target", "[", "\"score\"", "]", "\n", ")", "\n", "", "elif", "dataloader_idx", "==", "1", ":", "\n", "                ", "self", ".", "val_metrics", ".", "update", "(", "\n", "batch_prediction", "[", "\"score\"", "]", ".", "view", "(", "-", "1", ")", ",", "batch_target", "[", "\"score\"", "]", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.Unbabel_COMET.models.base.CometModel.on_predict_start": [[372, 378], ["base.CometModel.train", "base.CometModel.eval"], "methods", ["None"], ["", "", "", "def", "on_predict_start", "(", "self", ")", "->", "None", ":", "\n", "        ", "\"\"\"Called when predict begins.\"\"\"", "\n", "if", "self", ".", "mc_dropout", ":", "\n", "            ", "self", ".", "train", "(", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "eval", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Unbabel_COMET.models.base.CometModel.predict_step": [[379, 401], ["[].view", "torch.stack", "torch.stack.mean", "torch.stack.std", "[].view", "base.CometModel.", "range", "base.CometModel."], "methods", ["None"], ["", "", "def", "predict_step", "(", "\n", "self", ",", "\n", "batch", ":", "Dict", "[", "str", ",", "torch", ".", "Tensor", "]", ",", "\n", "batch_idx", ":", "Optional", "[", "int", "]", "=", "None", ",", "\n", "dataloader_idx", ":", "Optional", "[", "int", "]", "=", "None", ",", "\n", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\"\n        Runs one prediction step and returns the predicted values.\n\n        :param batch: The output of your prepare_sample function.\n        :param batch_nb: Integer displaying which batch this is.\n        :param dataloader_idx: Integer displaying which dataloader this is.\n        \"\"\"", "\n", "if", "self", ".", "mc_dropout", ":", "\n", "            ", "mcd_outputs", "=", "torch", ".", "stack", "(", "\n", "[", "self", "(", "**", "batch", ")", "[", "\"score\"", "]", ".", "view", "(", "-", "1", ")", "for", "_", "in", "range", "(", "self", ".", "mc_dropout", ")", "]", "\n", ")", "\n", "mcd_mean", "=", "mcd_outputs", ".", "mean", "(", "dim", "=", "0", ")", "\n", "mcd_std", "=", "mcd_outputs", ".", "std", "(", "dim", "=", "0", ")", "\n", "return", "mcd_mean", ",", "mcd_std", "\n", "\n", "", "return", "self", "(", "**", "batch", ")", "[", "\"score\"", "]", ".", "view", "(", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Unbabel_COMET.models.base.CometModel.validation_epoch_end": [[402, 408], ["base.CometModel.log_dict", "base.CometModel.log_dict", "base.CometModel.train_metrics.reset", "base.CometModel.val_metrics.reset", "base.CometModel.train_metrics.compute", "base.CometModel.val_metrics.compute"], "methods", ["home.repos.pwc.inspect_result.Unbabel_COMET.models.metrics.WMTKendall.compute", "home.repos.pwc.inspect_result.Unbabel_COMET.models.metrics.WMTKendall.compute"], ["", "def", "validation_epoch_end", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", "->", "None", ":", "\n", "        ", "\"\"\"Computes and logs metrics.\"\"\"", "\n", "self", ".", "log_dict", "(", "self", ".", "train_metrics", ".", "compute", "(", ")", ",", "prog_bar", "=", "True", ")", "\n", "self", ".", "log_dict", "(", "self", ".", "val_metrics", ".", "compute", "(", ")", ",", "prog_bar", "=", "True", ")", "\n", "self", ".", "train_metrics", ".", "reset", "(", ")", "\n", "self", ".", "val_metrics", ".", "reset", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Unbabel_COMET.models.base.CometModel.setup": [[410, 428], ["base.CometModel.read_csv", "base.CometModel.read_csv", "numpy.random.choice", "torch.utils.data.Subset", "base.CometModel.init_metrics", "len", "float", "max", "len"], "methods", ["home.repos.pwc.inspect_result.Unbabel_COMET.regression.referenceless.ReferencelessRegression.read_csv", "home.repos.pwc.inspect_result.Unbabel_COMET.regression.referenceless.ReferencelessRegression.read_csv", "home.repos.pwc.inspect_result.Unbabel_COMET.regression.regression_metric.RegressionMetric.init_metrics"], ["", "def", "setup", "(", "self", ",", "stage", ")", "->", "None", ":", "\n", "        ", "\"\"\"Data preparation function called before training by Lightning.\n\n        :param stage: either 'fit', 'validate', 'test', or 'predict'\n        \"\"\"", "\n", "if", "stage", "in", "(", "None", ",", "\"fit\"", ")", ":", "\n", "            ", "self", ".", "train_dataset", "=", "self", ".", "read_csv", "(", "self", ".", "hparams", ".", "train_data", ")", "\n", "self", ".", "validation_dataset", "=", "self", ".", "read_csv", "(", "self", ".", "hparams", ".", "validation_data", ")", "\n", "\n", "self", ".", "epoch_total_steps", "=", "len", "(", "self", ".", "train_dataset", ")", "//", "(", "\n", "self", ".", "hparams", ".", "batch_size", "*", "max", "(", "1", ",", "self", ".", "trainer", ".", "num_devices", ")", "\n", ")", "\n", "self", ".", "total_steps", "=", "self", ".", "epoch_total_steps", "*", "float", "(", "self", ".", "trainer", ".", "max_epochs", ")", "\n", "\n", "# Always validate the model with 2k examples to control overfit.", "\n", "train_subset", "=", "np", ".", "random", ".", "choice", "(", "a", "=", "len", "(", "self", ".", "train_dataset", ")", ",", "size", "=", "2000", ")", "\n", "self", ".", "train_subset", "=", "Subset", "(", "self", ".", "train_dataset", ",", "train_subset", ")", "\n", "self", ".", "init_metrics", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Unbabel_COMET.models.base.CometModel.train_dataloader": [[429, 437], ["torch.utils.data.DataLoader", "torch.utils.data.RandomSampler"], "methods", ["None"], ["", "", "def", "train_dataloader", "(", "self", ")", "->", "DataLoader", ":", "\n", "        ", "\"\"\"Function that loads the train set.\"\"\"", "\n", "return", "DataLoader", "(", "\n", "dataset", "=", "self", ".", "train_dataset", ",", "\n", "sampler", "=", "RandomSampler", "(", "self", ".", "train_dataset", ")", ",", "\n", "batch_size", "=", "self", ".", "hparams", ".", "batch_size", ",", "\n", "collate_fn", "=", "self", ".", "prepare_sample", ",", "\n", "num_workers", "=", "2", "*", "self", ".", "trainer", ".", "num_devices", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.Unbabel_COMET.models.base.CometModel.val_dataloader": [[439, 453], ["torch.utils.data.DataLoader", "torch.utils.data.DataLoader"], "methods", ["None"], ["", "def", "val_dataloader", "(", "self", ")", "->", "DataLoader", ":", "\n", "        ", "\"\"\"Function that loads the validation set.\"\"\"", "\n", "return", "[", "\n", "DataLoader", "(", "\n", "dataset", "=", "self", ".", "train_subset", ",", "\n", "batch_size", "=", "self", ".", "hparams", ".", "batch_size", ",", "\n", "collate_fn", "=", "self", ".", "prepare_sample", ",", "\n", "num_workers", "=", "2", "*", "self", ".", "trainer", ".", "num_devices", ",", "\n", ")", ",", "\n", "DataLoader", "(", "\n", "dataset", "=", "self", ".", "validation_dataset", ",", "\n", "batch_size", "=", "self", ".", "hparams", ".", "batch_size", ",", "\n", "collate_fn", "=", "self", ".", "prepare_sample", ",", "\n", "num_workers", "=", "2", "*", "self", ".", "trainer", ".", "num_devices", ",", "\n", ")", ",", "\n"]], "home.repos.pwc.inspect_result.Unbabel_COMET.models.base.CometModel.prepare_for_inference": [[456, 461], ["base.CometModel.prepare_sample"], "methods", ["home.repos.pwc.inspect_result.Unbabel_COMET.regression.referenceless.ReferencelessRegression.prepare_sample"], ["", "def", "prepare_for_inference", "(", "self", ",", "sample", ")", ":", "\n", "        ", "\"\"\"Ideally this should be a lamba function but for some reason python does not copy local lambda functions.\n        This functions replaces `collate_fn=lambda x: self.prepare_sample(x, inference=True)` from line 434.\n        \"\"\"", "\n", "return", "self", ".", "prepare_sample", "(", "sample", ",", "inference", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Unbabel_COMET.models.base.CometModel.predict": [[462, 588], ["base.CometModel.eval", "torch.utils.data.DataLoader", "warnings.filterwarnings", "warnings.filterwarnings", "float", "numpy.argsort", "base.OrderedSampler", "pytorch_lightning.Trainer", "pytorch_lightning.Trainer", "base.CometModel.set_mc_dropout", "pytorch_lightning.Trainer.predict", "torch.cat().tolist", "torch.cat().tolist", "pytorch_lightning.Trainer.predict", "torch.cat().tolist", "float", "zip", "zip", "len", "torch.cat", "torch.cat", "sum", "len", "torch.cat", "sum", "len", "predict_pbar.PredictProgressBar", "range", "range", "range", "len", "len", "len"], "methods", ["home.repos.pwc.inspect_result.Unbabel_COMET.models.base.CometModel.set_mc_dropout", "home.repos.pwc.inspect_result.Unbabel_COMET.models.base.CometModel.predict", "home.repos.pwc.inspect_result.Unbabel_COMET.models.base.CometModel.predict"], ["", "def", "predict", "(", "\n", "self", ",", "\n", "samples", ":", "List", "[", "Dict", "[", "str", ",", "str", "]", "]", ",", "\n", "batch_size", ":", "int", "=", "8", ",", "\n", "gpus", ":", "int", "=", "1", ",", "\n", "mc_dropout", ":", "Union", "[", "int", ",", "bool", "]", "=", "False", ",", "\n", "progress_bar", ":", "bool", "=", "True", ",", "\n", "accelerator", ":", "str", "=", "\"ddp\"", ",", "\n", "num_workers", ":", "int", "=", "None", ",", "\n", "length_batching", ":", "bool", "=", "True", ",", "\n", ")", "->", "Union", "[", "Tuple", "[", "List", "[", "float", "]", ",", "float", "]", ",", "Tuple", "[", "List", "[", "float", "]", ",", "List", "[", "float", "]", ",", "float", "]", "]", ":", "\n", "        ", "\"\"\"Function that receives a list of samples (dictionaries with translations, sources and/or references)\n        and returns segment level scores and a system level score. If `mc_dropout` is set, it also returns for each\n        segment score, a confidence value.\n\n        :param samples: List with dictionaries with source, translations and/or references.\n        :param batch_size: Batch size used during inference.\n        :param gpus: Number of GPUs to be used.\n        :param mc_dropout: Number of inference steps to run using MCD. Its disabled by default!\n        :param progress_bar: Flag that turns on and off the predict progress bar.\n        :param accelarator: Pytorch Lightning accelerator (e.g: dp, ddp).\n        :param num_workers: Number of workers to use when loading data from dataloaders.\n        :param length_batching: If set to true, reduces padding by sorting samples by MT length.\n\n        :return: List with segment-level scores and a system-score or segment-level scores, segment-level\n            confidence and a system-score.\n        \"\"\"", "\n", "# HACK: Workaround pytorch bug that prevents ParameterList to be used in DP", "\n", "# https://github.com/pytorch/pytorch/issues/36035", "\n", "if", "self", ".", "layerwise_attention", "is", "not", "None", "and", "gpus", ">", "1", ":", "\n", "            ", "self", ".", "layerwise_attention", ".", "gamma_value", "=", "float", "(", "\n", "self", ".", "layerwise_attention", ".", "gamma", "[", "0", "]", "\n", ")", "\n", "self", ".", "layerwise_attention", ".", "weights", "=", "[", "\n", "float", "(", "parameter", "[", "0", "]", ")", "\n", "for", "parameter", "in", "self", ".", "layerwise_attention", ".", "scalar_parameters", "\n", "]", "\n", "\n", "# TODO: ideally this should be based on the actual token_ids", "\n", "# but that would require fundamentally changing the way dataloader is", "\n", "# setup, so currently raw chars are used as an approximation", "\n", "", "sampler", "=", "None", "\n", "if", "length_batching", "and", "gpus", "<", "2", ":", "\n", "            ", "sort_ids", "=", "np", ".", "argsort", "(", "[", "len", "(", "sample", "[", "\"src\"", "]", ")", "for", "sample", "in", "samples", "]", ")", "\n", "sampler", "=", "OrderedSampler", "(", "sort_ids", ")", "\n", "\n", "", "if", "num_workers", "is", "None", ":", "\n", "            ", "num_workers", "=", "2", "*", "gpus", "\n", "\n", "", "self", ".", "eval", "(", ")", "\n", "dataloader", "=", "DataLoader", "(", "\n", "dataset", "=", "samples", ",", "\n", "batch_size", "=", "batch_size", ",", "\n", "sampler", "=", "sampler", ",", "\n", "collate_fn", "=", "self", ".", "prepare_for_inference", ",", "\n", "num_workers", "=", "num_workers", ",", "\n", ")", "\n", "accelerator", "=", "accelerator", "if", "gpus", ">", "1", "else", "None", "\n", "\n", "warnings", ".", "filterwarnings", "(", "\n", "\"ignore\"", ",", "\n", "category", "=", "UserWarning", ",", "\n", "message", "=", "\".*Consider increasing the value of the `num_workers` argument` .*\"", ",", "\n", ")", "\n", "if", "progress_bar", ":", "\n", "            ", "trainer", "=", "ptl", ".", "Trainer", "(", "\n", "gpus", "=", "gpus", ",", "\n", "deterministic", "=", "True", ",", "\n", "logger", "=", "False", ",", "\n", "callbacks", "=", "[", "PredictProgressBar", "(", ")", "]", ",", "\n", "accelerator", "=", "accelerator", ",", "\n", "max_epochs", "=", "-", "1", "\n", ")", "\n", "", "else", ":", "\n", "            ", "trainer", "=", "ptl", ".", "Trainer", "(", "\n", "gpus", "=", "gpus", ",", "\n", "deterministic", "=", "True", ",", "\n", "logger", "=", "False", ",", "\n", "progress_bar_refresh_rate", "=", "0", ",", "\n", "accelerator", "=", "accelerator", ",", "\n", "max_epochs", "=", "-", "1", "\n", ")", "\n", "\n", "# TODO:", "\n", "# Remove this upon resolution of:", "\n", "# https://github.com/PyTorchLightning/pytorch-lightning/discussions/11392", "\n", "", "warnings", ".", "filterwarnings", "(", "\n", "\"ignore\"", ",", "\n", "category", "=", "UserWarning", ",", "\n", "message", "=", "\"Your `predict_dataloader`'s sampler has shuffling enabled.*\"", ",", "\n", ")", "\n", "\n", "if", "mc_dropout", ":", "\n", "            ", "self", ".", "set_mc_dropout", "(", "mc_dropout", ")", "\n", "predictions", "=", "trainer", ".", "predict", "(", "\n", "self", ",", "dataloaders", "=", "dataloader", ",", "return_predictions", "=", "True", "\n", ")", "\n", "mean_scores", "=", "[", "out", "[", "0", "]", "for", "out", "in", "predictions", "]", "\n", "std_scores", "=", "[", "out", "[", "1", "]", "for", "out", "in", "predictions", "]", "\n", "mean_scores", "=", "torch", ".", "cat", "(", "mean_scores", ",", "dim", "=", "0", ")", ".", "tolist", "(", ")", "\n", "std_scores", "=", "torch", ".", "cat", "(", "std_scores", ",", "dim", "=", "0", ")", ".", "tolist", "(", ")", "\n", "if", "length_batching", "and", "gpus", "<", "2", ":", "\n", "                ", "unsorted_mean_scores", "=", "[", "None", "for", "_", "in", "range", "(", "len", "(", "samples", ")", ")", "]", "\n", "unsorted_std_scores", "=", "[", "None", "for", "_", "in", "range", "(", "len", "(", "samples", ")", ")", "]", "\n", "for", "idx", ",", "mean_score", ",", "std_score", "in", "zip", "(", "\n", "sort_ids", ",", "mean_scores", ",", "std_scores", "\n", ")", ":", "\n", "                    ", "unsorted_mean_scores", "[", "idx", "]", "=", "mean_score", "\n", "unsorted_std_scores", "[", "idx", "]", "=", "std_score", "\n", "", "mean_scores", "=", "unsorted_mean_scores", "\n", "std_scores", "=", "unsorted_std_scores", "\n", "\n", "", "return", "mean_scores", ",", "std_scores", ",", "sum", "(", "mean_scores", ")", "/", "len", "(", "mean_scores", ")", "\n", "\n", "", "else", ":", "\n", "            ", "predictions", "=", "trainer", ".", "predict", "(", "\n", "self", ",", "dataloaders", "=", "dataloader", ",", "return_predictions", "=", "True", "\n", ")", "\n", "predictions", "=", "torch", ".", "cat", "(", "predictions", ",", "dim", "=", "0", ")", ".", "tolist", "(", ")", "\n", "if", "length_batching", "and", "gpus", "<", "2", ":", "\n", "                ", "unsorted_predictions", "=", "[", "None", "for", "_", "in", "range", "(", "len", "(", "samples", ")", ")", "]", "\n", "for", "idx", ",", "prediction", "in", "zip", "(", "sort_ids", ",", "predictions", ")", ":", "\n", "                    ", "unsorted_predictions", "[", "idx", "]", "=", "prediction", "\n", "", "predictions", "=", "unsorted_predictions", "\n", "\n", "", "return", "predictions", ",", "sum", "(", "predictions", ")", "/", "len", "(", "predictions", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.Unbabel_COMET.models.metrics.RegressionMetrics.__init__": [[36, 53], ["torchmetrics.Metric.__init__", "metrics.RegressionMetrics.add_state", "metrics.RegressionMetrics.add_state"], "methods", ["home.repos.pwc.inspect_result.Unbabel_COMET.regression.referenceless.ReferencelessRegression.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "prefix", ":", "str", "=", "\"\"", ",", "\n", "compute_on_step", ":", "bool", "=", "False", ",", "\n", "dist_sync_on_step", ":", "bool", "=", "False", ",", "\n", "process_group", ":", "Optional", "[", "Any", "]", "=", "None", ",", "\n", "dist_sync_fn", ":", "Optional", "[", "Callable", "]", "=", "None", ",", "\n", ")", "->", "None", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "\n", "compute_on_step", "=", "compute_on_step", ",", "\n", "dist_sync_on_step", "=", "dist_sync_on_step", ",", "\n", "process_group", "=", "process_group", ",", "\n", "dist_sync_fn", "=", "dist_sync_fn", ",", "\n", ")", "\n", "self", ".", "add_state", "(", "\"preds\"", ",", "default", "=", "[", "]", ",", "dist_reduce_fx", "=", "\"cat\"", ")", "\n", "self", ".", "add_state", "(", "\"target\"", ",", "default", "=", "[", "]", ",", "dist_reduce_fx", "=", "\"cat\"", ")", "\n", "self", ".", "prefix", "=", "prefix", "\n", "\n"]], "home.repos.pwc.inspect_result.Unbabel_COMET.models.metrics.RegressionMetrics.update": [[55, 63], ["metrics.RegressionMetrics.preds.append", "metrics.RegressionMetrics.target.append"], "methods", ["None"], ["", "def", "update", "(", "self", ",", "preds", ":", "Tensor", ",", "target", ":", "Tensor", ")", "->", "None", ":", "# type: ignore", "\n", "        ", "\"\"\"Update state with predictions and targets.\n        Args:\n            preds: Predictions from model\n            target: Ground truth values\n        \"\"\"", "\n", "self", ".", "preds", ".", "append", "(", "preds", ")", "\n", "self", ".", "target", ".", "append", "(", "target", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Unbabel_COMET.models.metrics.RegressionMetrics.compute": [[64, 75], ["torch.cat", "torch.cat", "scipy.kendalltau", "scipy.spearmanr", "scipy.pearsonr", "torch.cat.tolist", "torch.cat.tolist", "torch.cat.tolist", "torch.cat.tolist", "torch.cat.tolist", "torch.cat.tolist"], "methods", ["None"], ["", "def", "compute", "(", "self", ")", "->", "Tensor", ":", "\n", "        ", "\"\"\" Computes spearmans correlation coefficient. \"\"\"", "\n", "preds", "=", "torch", ".", "cat", "(", "self", ".", "preds", ",", "dim", "=", "0", ")", "\n", "target", "=", "torch", ".", "cat", "(", "self", ".", "target", ",", "dim", "=", "0", ")", "\n", "kendall", ",", "_", "=", "stats", ".", "kendalltau", "(", "preds", ".", "tolist", "(", ")", ",", "target", ".", "tolist", "(", ")", ")", "\n", "spearman", ",", "_", "=", "stats", ".", "spearmanr", "(", "preds", ".", "tolist", "(", ")", ",", "target", ".", "tolist", "(", ")", ")", "\n", "pearson", ",", "_", "=", "stats", ".", "pearsonr", "(", "preds", ".", "tolist", "(", ")", ",", "target", ".", "tolist", "(", ")", ")", "\n", "return", "{", "\n", "self", ".", "prefix", "+", "\"_kendall\"", ":", "kendall", ",", "\n", "self", ".", "prefix", "+", "\"_spearman\"", ":", "spearman", ",", "\n", "self", ".", "prefix", "+", "\"_pearson\"", ":", "pearson", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.Unbabel_COMET.models.metrics.WMTKendall.__init__": [[78, 95], ["torchmetrics.Metric.__init__", "metrics.WMTKendall.add_state", "metrics.WMTKendall.add_state", "torch.tensor", "torch.tensor"], "methods", ["home.repos.pwc.inspect_result.Unbabel_COMET.regression.referenceless.ReferencelessRegression.__init__"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "prefix", ":", "str", "=", "\"\"", ",", "\n", "compute_on_step", ":", "bool", "=", "False", ",", "\n", "dist_sync_on_step", ":", "bool", "=", "False", ",", "\n", "process_group", ":", "Optional", "[", "Any", "]", "=", "None", ",", "\n", "dist_sync_fn", ":", "Optional", "[", "Callable", "]", "=", "None", ",", "\n", ")", "->", "None", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "\n", "compute_on_step", "=", "compute_on_step", ",", "\n", "dist_sync_on_step", "=", "dist_sync_on_step", ",", "\n", "process_group", "=", "process_group", ",", "\n", "dist_sync_fn", "=", "dist_sync_fn", ",", "\n", ")", "\n", "self", ".", "add_state", "(", "\"concordance\"", ",", "default", "=", "torch", ".", "tensor", "(", "0", ")", ",", "dist_reduce_fx", "=", "\"sum\"", ")", "\n", "self", ".", "add_state", "(", "\"discordance\"", ",", "default", "=", "torch", ".", "tensor", "(", "0", ")", ",", "dist_reduce_fx", "=", "\"sum\"", ")", "\n", "self", ".", "prefix", "=", "prefix", "\n", "\n"]], "home.repos.pwc.inspect_result.Unbabel_COMET.models.metrics.WMTKendall.update": [[96, 100], ["torch.sum", "torch.sum"], "methods", ["None"], ["", "def", "update", "(", "self", ",", "distance_pos", ":", "torch", ".", "Tensor", ",", "distance_neg", ":", "torch", ".", "Tensor", ")", ":", "\n", "        ", "assert", "distance_pos", ".", "shape", "==", "distance_neg", ".", "shape", "\n", "self", ".", "concordance", "=", "torch", ".", "sum", "(", "(", "distance_pos", "<", "distance_neg", ")", ".", "float", "(", ")", ")", "\n", "self", ".", "discordance", "=", "torch", ".", "sum", "(", "(", "distance_pos", ">=", "distance_neg", ")", ".", "float", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Unbabel_COMET.models.metrics.WMTKendall.compute": [[101, 106], ["None"], "methods", ["None"], ["", "def", "compute", "(", "self", ")", ":", "\n", "        ", "return", "{", "\n", "self", ".", "prefix", "\n", "+", "\"_kendall\"", ":", "(", "self", ".", "concordance", "-", "self", ".", "discordance", ")", "\n", "/", "(", "self", ".", "concordance", "+", "self", ".", "discordance", ")", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.Unbabel_COMET.models.predict_pbar.PredictProgressBar.init_predict_tqdm": [[10, 22], ["tqdm.tqdm.tqdm"], "methods", ["None"], ["def", "init_predict_tqdm", "(", "self", ")", "->", "tqdm", ":", "\n", "        ", "bar", "=", "tqdm", "(", "\n", "desc", "=", "\"Predicting\"", ",", "\n", "initial", "=", "self", ".", "train_batch_idx", ",", "\n", "position", "=", "(", "2", "*", "self", ".", "process_position", ")", ",", "\n", "disable", "=", "self", ".", "is_disabled", ",", "\n", "leave", "=", "True", ",", "\n", "dynamic_ncols", "=", "True", ",", "\n", "file", "=", "sys", ".", "stderr", ",", "\n", "smoothing", "=", "0", ",", "\n", ")", "\n", "return", "bar", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Unbabel_COMET.models.__init__.load_from_checkpoint": [[52, 70], ["os.path.exists", "os.path.exists", "Exception", "model_class.load_from_checkpoint", "Exception", "open", "yaml.load", "checkpoint_path.split", "yaml_file.read"], "function", ["home.repos.pwc.inspect_result.Unbabel_COMET.models.__init__.load_from_checkpoint"], []], "home.repos.pwc.inspect_result.Unbabel_COMET.models.pooling_utils.average_pooling": [[18, 34], ["pooling_utils.mask_fill", "torch.sum", "mask.unsqueeze().expand().float().sum", "mask.unsqueeze().expand().float", "mask.unsqueeze().expand", "embeddings.size", "mask.unsqueeze"], "function", ["home.repos.pwc.inspect_result.Unbabel_COMET.models.pooling_utils.mask_fill"], ["def", "average_pooling", "(", "\n", "tokens", ":", "torch", ".", "Tensor", ",", "\n", "embeddings", ":", "torch", ".", "Tensor", ",", "\n", "mask", ":", "torch", ".", "Tensor", ",", "\n", "padding_index", ":", "int", ",", "\n", ")", "->", "torch", ".", "Tensor", ":", "\n", "    ", "\"\"\"Average pooling function.\n    :param tokens: Word ids [batch_size x seq_length]\n    :param embeddings: Word embeddings [batch_size x seq_length x hidden_size]\n    :param mask: Padding mask [batch_size x seq_length]\n    :param padding_index: Padding value.\n    \"\"\"", "\n", "wordemb", "=", "mask_fill", "(", "0.0", ",", "tokens", ",", "embeddings", ",", "padding_index", ")", "\n", "sentemb", "=", "torch", ".", "sum", "(", "wordemb", ",", "1", ")", "\n", "sum_mask", "=", "mask", ".", "unsqueeze", "(", "-", "1", ")", ".", "expand", "(", "embeddings", ".", "size", "(", ")", ")", ".", "float", "(", ")", ".", "sum", "(", "1", ")", "\n", "return", "sentemb", "/", "sum_mask", "\n", "\n"]], "home.repos.pwc.inspect_result.Unbabel_COMET.models.pooling_utils.max_pooling": [[36, 45], ["mask_fill().max", "pooling_utils.mask_fill", "float"], "function", ["home.repos.pwc.inspect_result.Unbabel_COMET.models.pooling_utils.mask_fill"], ["", "def", "max_pooling", "(", "\n", "tokens", ":", "torch", ".", "Tensor", ",", "embeddings", ":", "torch", ".", "Tensor", ",", "padding_index", ":", "int", "\n", ")", "->", "torch", ".", "Tensor", ":", "\n", "    ", "\"\"\"Max pooling function.\n    :param tokens: Word ids [batch_size x seq_length]\n    :param embeddings: Word embeddings [batch_size x seq_length x hidden_size]\n    :param padding_index: Padding value.\n    \"\"\"", "\n", "return", "mask_fill", "(", "float", "(", "\"-inf\"", ")", ",", "tokens", ",", "embeddings", ",", "padding_index", ")", ".", "max", "(", "dim", "=", "1", ")", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.Unbabel_COMET.models.pooling_utils.mask_fill": [[47, 62], ["tokens.eq().unsqueeze", "embeddings.float().masked_fill_().type_as", "tokens.eq", "embeddings.float().masked_fill_", "embeddings.float"], "function", ["None"], ["", "def", "mask_fill", "(", "\n", "fill_value", ":", "float", ",", "\n", "tokens", ":", "torch", ".", "Tensor", ",", "\n", "embeddings", ":", "torch", ".", "Tensor", ",", "\n", "padding_index", ":", "int", ",", "\n", ")", "->", "torch", ".", "Tensor", ":", "\n", "    ", "\"\"\"\n    Function that masks embeddings representing padded elements.\n    :param fill_value: the value to fill the embeddings belonging to padded tokens.\n    :param tokens: The input sequences [bsz x seq_len].\n    :param embeddings: word embeddings [bsz x seq_len x hiddens].\n    :param padding_index: Index of the padding token.\n    \"\"\"", "\n", "padding_mask", "=", "tokens", ".", "eq", "(", "padding_index", ")", ".", "unsqueeze", "(", "-", "1", ")", "\n", "return", "embeddings", ".", "float", "(", ")", ".", "masked_fill_", "(", "padding_mask", ",", "fill_value", ")", ".", "type_as", "(", "embeddings", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.Unbabel_COMET.models.lru_cache._make_key": [[30, 80], ["tuple", "functools._HashedSeq", "object", "torch.is_tensor", "kwds.items", "tuple", "new_args.append", "new_args.append", "tuple", "type", "len", "type", "x.shape.__repr__", "type", "kwds.values", "x.diagonal().__repr__", "x.__repr__", "x.diagonal"], "function", ["None"], ["def", "_make_key", "(", "\n", "args", ",", "\n", "kwds", ",", "\n", "typed", ",", "\n", "kwd_mark", "=", "(", "object", "(", ")", ",", ")", ",", "\n", "fasttypes", "=", "{", "int", ",", "str", "}", ",", "\n", "tuple", "=", "tuple", ",", "\n", "type", "=", "type", ",", "\n", "len", "=", "len", ",", "\n", ")", ":", "\n", "    ", "\"\"\"Make a cache key from optionally typed positional and keyword arguments\n    The key is constructed in a way that is flat as possible rather than\n    as a nested structure that would take more memory.\n    If there is only a single argument and its data type is known to cache\n    its hash value, then that argument is returned without a wrapper.  This\n    saves space and improves lookup speed.\n    \"\"\"", "\n", "# All of code below relies on kwds preserving the order input by the user.", "\n", "# Formerly, we sorted() the kwds before looping.  The new way is *much*", "\n", "# faster; however, it means that f(x=1, y=2) will now be treated as a", "\n", "# distinct call from f(y=2, x=1) which will be cached separately.", "\n", "new_args", "=", "[", "]", "\n", "for", "x", "in", "args", ":", "\n", "        ", "if", "torch", ".", "is_tensor", "(", "x", ")", ":", "\n", "            ", "new_args", ".", "append", "(", "\n", "# HACK: Tensor representations omit some tensor content.", "\n", "# Nonetheless converting the tensor into a tuple is too slow.", "\n", "# The current solution is an approximation to the actual tensor", "\n", "# full representation. This can still lead to `false` cache hits!", "\n", "x", ".", "__repr__", "(", ")", "\n", "+", "\"\\n\"", "\n", "+", "x", ".", "diagonal", "(", ")", ".", "__repr__", "(", ")", "\n", "+", "\"\\n\"", "\n", "+", "x", ".", "shape", ".", "__repr__", "(", ")", "\n", ")", "\n", "", "else", ":", "\n", "            ", "new_args", ".", "append", "(", "x", ")", "\n", "\n", "", "", "key", "=", "tuple", "(", "new_args", ")", "\n", "if", "kwds", ":", "\n", "        ", "key", "+=", "kwd_mark", "\n", "for", "item", "in", "kwds", ".", "items", "(", ")", ":", "\n", "            ", "key", "+=", "item", "\n", "", "", "if", "typed", ":", "\n", "        ", "key", "+=", "tuple", "(", "type", "(", "v", ")", "for", "v", "in", "args", ")", "\n", "if", "kwds", ":", "\n", "            ", "key", "+=", "tuple", "(", "type", "(", "v", ")", "for", "v", "in", "kwds", ".", "values", "(", ")", ")", "\n", "", "", "elif", "len", "(", "key", ")", "==", "1", "and", "type", "(", "key", "[", "0", "]", ")", "in", "fasttypes", ":", "\n", "        ", "return", "key", "[", "0", "]", "\n", "", "return", "_HashedSeq", "(", "key", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Unbabel_COMET.models.lru_cache.tensor_lru_cache": [[82, 107], ["isinstance", "lru_cache._lru_cache_wrapper", "functools.update_wrapper", "callable", "isinstance", "lru_cache._lru_cache_wrapper", "functools.update_wrapper", "TypeError"], "function", ["home.repos.pwc.inspect_result.Unbabel_COMET.models.lru_cache._lru_cache_wrapper", "home.repos.pwc.inspect_result.Unbabel_COMET.models.lru_cache._lru_cache_wrapper"], ["", "def", "tensor_lru_cache", "(", "maxsize", "=", "128", ",", "typed", "=", "False", ")", ":", "\n", "# Users should only access the lru_cache through its public API:", "\n", "#       cache_info, cache_clear, and f.__wrapped__", "\n", "# The internals of the lru_cache are encapsulated for thread safety and", "\n", "# to allow the implementation to change (including a possible C version).", "\n", "\n", "    ", "if", "isinstance", "(", "maxsize", ",", "int", ")", ":", "\n", "# Negative maxsize is treated as 0", "\n", "        ", "if", "maxsize", "<", "0", ":", "\n", "            ", "maxsize", "=", "0", "\n", "", "", "elif", "callable", "(", "maxsize", ")", "and", "isinstance", "(", "typed", ",", "bool", ")", ":", "\n", "# The user_function was passed in directly via the maxsize argument", "\n", "        ", "user_function", ",", "maxsize", "=", "maxsize", ",", "128", "\n", "wrapper", "=", "_lru_cache_wrapper", "(", "user_function", ",", "maxsize", ",", "typed", ",", "_CacheInfo", ")", "\n", "wrapper", ".", "cache_parameters", "=", "lambda", ":", "{", "\"maxsize\"", ":", "maxsize", ",", "\"typed\"", ":", "typed", "}", "\n", "return", "update_wrapper", "(", "wrapper", ",", "user_function", ")", "\n", "", "elif", "maxsize", "is", "not", "None", ":", "\n", "        ", "raise", "TypeError", "(", "\"Expected first argument to be an integer, a callable, or None\"", ")", "\n", "\n", "", "def", "decorating_function", "(", "user_function", ")", ":", "\n", "        ", "wrapper", "=", "_lru_cache_wrapper", "(", "user_function", ",", "maxsize", ",", "typed", ",", "_CacheInfo", ")", "\n", "wrapper", ".", "cache_parameters", "=", "lambda", ":", "{", "\"maxsize\"", ":", "maxsize", ",", "\"typed\"", ":", "typed", "}", "\n", "return", "update_wrapper", "(", "wrapper", ",", "user_function", ")", "\n", "\n", "", "return", "decorating_function", "\n", "\n"]], "home.repos.pwc.inspect_result.Unbabel_COMET.models.lru_cache._lru_cache_wrapper": [[109, 228], ["object", "_thread.RLock", "user_function", "functools._CacheInfo", "cache.clear", "make_key", "cache_get", "user_function", "make_key", "user_function", "cache_len", "cache_get", "cache_len", "functools._CacheInfo", "functools._CacheInfo"], "function", ["None"], ["", "def", "_lru_cache_wrapper", "(", "user_function", ",", "maxsize", ",", "typed", ",", "_CacheInfo", ")", ":", "\n", "# Constants shared by all lru cache instances:", "\n", "    ", "sentinel", "=", "object", "(", ")", "# unique object used to signal cache misses", "\n", "make_key", "=", "_make_key", "# build a key from the function arguments", "\n", "PREV", ",", "NEXT", ",", "KEY", ",", "RESULT", "=", "0", ",", "1", ",", "2", ",", "3", "# names for the link fields", "\n", "\n", "cache", "=", "{", "}", "\n", "hits", "=", "misses", "=", "0", "\n", "full", "=", "False", "\n", "cache_get", "=", "cache", ".", "get", "# bound method to lookup a key or return None", "\n", "cache_len", "=", "cache", ".", "__len__", "# get cache size without calling len()", "\n", "lock", "=", "RLock", "(", ")", "# because linkedlist updates aren't threadsafe", "\n", "root", "=", "[", "]", "# root of the circular doubly linked list", "\n", "root", "[", ":", "]", "=", "[", "root", ",", "root", ",", "None", ",", "None", "]", "# initialize by pointing to self", "\n", "\n", "if", "maxsize", "==", "0", ":", "\n", "\n", "        ", "def", "wrapper", "(", "*", "args", ",", "**", "kwds", ")", ":", "\n", "# No caching -- just a statistics update", "\n", "            ", "nonlocal", "misses", "\n", "misses", "+=", "1", "\n", "result", "=", "user_function", "(", "*", "args", ",", "**", "kwds", ")", "\n", "return", "result", "\n", "\n", "", "", "elif", "maxsize", "is", "None", ":", "\n", "\n", "        ", "def", "wrapper", "(", "*", "args", ",", "**", "kwds", ")", ":", "\n", "# Simple caching without ordering or size limit", "\n", "            ", "nonlocal", "hits", ",", "misses", "\n", "key", "=", "make_key", "(", "args", ",", "kwds", ",", "typed", ")", "\n", "result", "=", "cache_get", "(", "key", ",", "sentinel", ")", "\n", "if", "result", "is", "not", "sentinel", ":", "\n", "                ", "hits", "+=", "1", "\n", "return", "result", "\n", "", "misses", "+=", "1", "\n", "result", "=", "user_function", "(", "*", "args", ",", "**", "kwds", ")", "\n", "cache", "[", "key", "]", "=", "result", "\n", "return", "result", "\n", "\n", "", "", "else", ":", "\n", "\n", "        ", "def", "wrapper", "(", "*", "args", ",", "**", "kwds", ")", ":", "\n", "# Size limited caching that tracks accesses by recency", "\n", "            ", "nonlocal", "root", ",", "hits", ",", "misses", ",", "full", "\n", "key", "=", "make_key", "(", "args", ",", "kwds", ",", "typed", ")", "\n", "with", "lock", ":", "\n", "                ", "link", "=", "cache_get", "(", "key", ")", "\n", "if", "link", "is", "not", "None", ":", "\n", "# Move the link to the front of the circular queue", "\n", "                    ", "link_prev", ",", "link_next", ",", "_key", ",", "result", "=", "link", "\n", "link_prev", "[", "NEXT", "]", "=", "link_next", "\n", "link_next", "[", "PREV", "]", "=", "link_prev", "\n", "last", "=", "root", "[", "PREV", "]", "\n", "last", "[", "NEXT", "]", "=", "root", "[", "PREV", "]", "=", "link", "\n", "link", "[", "PREV", "]", "=", "last", "\n", "link", "[", "NEXT", "]", "=", "root", "\n", "hits", "+=", "1", "\n", "return", "result", "\n", "", "misses", "+=", "1", "\n", "", "result", "=", "user_function", "(", "*", "args", ",", "**", "kwds", ")", "\n", "with", "lock", ":", "\n", "                ", "if", "key", "in", "cache", ":", "\n", "# Getting here means that this same key was added to the", "\n", "# cache while the lock was released.  Since the link", "\n", "# update is already done, we need only return the", "\n", "# computed result and update the count of misses.", "\n", "                    ", "pass", "\n", "", "elif", "full", ":", "\n", "# Use the old root to store the new key and result.", "\n", "                    ", "oldroot", "=", "root", "\n", "oldroot", "[", "KEY", "]", "=", "key", "\n", "oldroot", "[", "RESULT", "]", "=", "result", "\n", "# Empty the oldest link and make it the new root.", "\n", "# Keep a reference to the old key and old result to", "\n", "# prevent their ref counts from going to zero during the", "\n", "# update. That will prevent potentially arbitrary object", "\n", "# clean-up code (i.e. __del__) from running while we're", "\n", "# still adjusting the links.", "\n", "root", "=", "oldroot", "[", "NEXT", "]", "\n", "oldkey", "=", "root", "[", "KEY", "]", "\n", "oldresult", "=", "root", "[", "RESULT", "]", "\n", "root", "[", "KEY", "]", "=", "root", "[", "RESULT", "]", "=", "None", "\n", "# Now update the cache dictionary.", "\n", "del", "cache", "[", "oldkey", "]", "\n", "# Save the potentially reentrant cache[key] assignment", "\n", "# for last, after the root and links have been put in", "\n", "# a consistent state.", "\n", "cache", "[", "key", "]", "=", "oldroot", "\n", "", "else", ":", "\n", "# Put result in a new link at the front of the queue.", "\n", "                    ", "last", "=", "root", "[", "PREV", "]", "\n", "link", "=", "[", "last", ",", "root", ",", "key", ",", "result", "]", "\n", "last", "[", "NEXT", "]", "=", "root", "[", "PREV", "]", "=", "cache", "[", "key", "]", "=", "link", "\n", "# Use the cache_len bound method instead of the len() function", "\n", "# which could potentially be wrapped in an lru_cache itself.", "\n", "full", "=", "cache_len", "(", ")", ">=", "maxsize", "\n", "", "", "return", "result", "\n", "\n", "", "", "def", "get_cache", "(", ")", ":", "\n", "        ", "with", "lock", ":", "\n", "            ", "return", "\n", "\n", "", "", "def", "cache_info", "(", ")", ":", "\n", "        ", "\"\"\"Report cache statistics\"\"\"", "\n", "with", "lock", ":", "\n", "            ", "return", "_CacheInfo", "(", "hits", ",", "misses", ",", "maxsize", ",", "cache_len", "(", ")", ")", "\n", "\n", "", "", "def", "cache_clear", "(", ")", ":", "\n", "        ", "\"\"\"Clear the cache and cache statistics\"\"\"", "\n", "nonlocal", "hits", ",", "misses", ",", "full", "\n", "with", "lock", ":", "\n", "            ", "cache", ".", "clear", "(", ")", "\n", "root", "[", ":", "]", "=", "[", "root", ",", "root", ",", "None", ",", "None", "]", "\n", "hits", "=", "misses", "=", "0", "\n", "full", "=", "False", "\n", "\n", "", "", "wrapper", ".", "cache_info", "=", "cache_info", "\n", "wrapper", ".", "cache_clear", "=", "cache_clear", "\n", "return", "wrapper", "\n", "", ""]], "home.repos.pwc.inspect_result.Unbabel_COMET.unit.test_download_utils.TestDownloadModel.tearDownClass": [[11, 14], ["shutil.rmtree", "os.path.join"], "methods", ["None"], ["    ", "@", "classmethod", "\n", "def", "tearDownClass", "(", "cls", ")", ":", "\n", "        ", "shutil", ".", "rmtree", "(", "os", ".", "path", ".", "join", "(", "DATA_PATH", ",", "\"wmt21-cometinho-da\"", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Unbabel_COMET.unit.test_download_utils.TestDownloadModel.test_download_from_s3": [[15, 24], ["comet.download_utils.download_model", "test_download_utils.TestDownloadModel.assertTrue", "test_download_utils.TestDownloadModel.assertTrue", "comet.models.load_from_checkpoint", "os.path.exists", "os.path.exists", "os.path.join", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.Unbabel_COMET.comet.download_utils.download_model", "home.repos.pwc.inspect_result.Unbabel_COMET.models.__init__.load_from_checkpoint"], ["", "def", "test_download_from_s3", "(", "self", ")", ":", "\n", "        ", "data_path", "=", "download_model", "(", "\"wmt21-cometinho-da\"", ",", "saving_directory", "=", "DATA_PATH", ")", "\n", "self", ".", "assertTrue", "(", "\n", "os", ".", "path", ".", "exists", "(", "os", ".", "path", ".", "join", "(", "DATA_PATH", ",", "\"wmt21-cometinho-da/hparams.yaml\"", ")", ")", "\n", ")", "\n", "self", ".", "assertTrue", "(", "\n", "os", ".", "path", ".", "exists", "(", "os", ".", "path", ".", "join", "(", "DATA_PATH", ",", "\"wmt21-cometinho-da/checkpoints/\"", ")", ")", "\n", ")", "\n", "load_from_checkpoint", "(", "data_path", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Unbabel_COMET.encoders.test_bert.TestBERTEncoder.test_num_layers": [[11, 13], ["test_bert.TestBERTEncoder.assertEqual"], "methods", ["None"], ["def", "test_num_layers", "(", "self", ")", ":", "\n", "        ", "self", ".", "assertEqual", "(", "self", ".", "bert", ".", "num_layers", ",", "3", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Unbabel_COMET.encoders.test_bert.TestBERTEncoder.test_output_units": [[14, 16], ["test_bert.TestBERTEncoder.assertEqual"], "methods", ["None"], ["", "def", "test_output_units", "(", "self", ")", ":", "\n", "        ", "self", ".", "assertEqual", "(", "self", ".", "bert", ".", "output_units", ",", "128", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Unbabel_COMET.encoders.test_bert.TestBERTEncoder.test_max_positions": [[17, 19], ["test_bert.TestBERTEncoder.assertEqual"], "methods", ["None"], ["", "def", "test_max_positions", "(", "self", ")", ":", "\n", "        ", "self", ".", "assertEqual", "(", "self", ".", "bert", ".", "max_positions", ",", "512", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Unbabel_COMET.encoders.test_bert.TestBERTEncoder.test_prepare_sample": [[20, 25], ["test_bert.TestBERTEncoder.bert.prepare_sample", "test_bert.TestBERTEncoder.assertIn", "test_bert.TestBERTEncoder.assertIn"], "methods", ["home.repos.pwc.inspect_result.Unbabel_COMET.regression.referenceless.ReferencelessRegression.prepare_sample"], ["", "def", "test_prepare_sample", "(", "self", ")", ":", "\n", "        ", "sample", "=", "[", "\"hello world, welcome to COMET!\"", ",", "\"This is a batch\"", "]", "\n", "model_input", "=", "self", ".", "bert", ".", "prepare_sample", "(", "sample", ")", "\n", "self", ".", "assertIn", "(", "\"input_ids\"", ",", "model_input", ")", "\n", "self", ".", "assertIn", "(", "\"attention_mask\"", ",", "model_input", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Unbabel_COMET.encoders.test_bert.TestBERTEncoder.test_forward": [[26, 34], ["test_bert.TestBERTEncoder.bert.prepare_sample", "test_bert.TestBERTEncoder.bert", "test_bert.TestBERTEncoder.assertIn", "test_bert.TestBERTEncoder.assertIn", "test_bert.TestBERTEncoder.assertIn", "test_bert.TestBERTEncoder.assertIn"], "methods", ["home.repos.pwc.inspect_result.Unbabel_COMET.regression.referenceless.ReferencelessRegression.prepare_sample"], ["", "def", "test_forward", "(", "self", ")", ":", "\n", "        ", "sample", "=", "[", "\"hello world, welcome to COMET!\"", ",", "\"This is a batch\"", "]", "\n", "model_input", "=", "self", ".", "bert", ".", "prepare_sample", "(", "sample", ")", "\n", "model_output", "=", "self", ".", "bert", "(", "**", "model_input", ")", "\n", "self", ".", "assertIn", "(", "\"wordemb\"", ",", "model_output", ")", "\n", "self", ".", "assertIn", "(", "\"sentemb\"", ",", "model_output", ")", "\n", "self", ".", "assertIn", "(", "\"all_layers\"", ",", "model_output", ")", "\n", "self", ".", "assertIn", "(", "\"attention_mask\"", ",", "model_output", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Unbabel_COMET.encoders.test_xlmr.TestXLMREncoder.test_num_layers": [[11, 13], ["test_xlmr.TestXLMREncoder.assertEqual"], "methods", ["None"], ["def", "test_num_layers", "(", "self", ")", ":", "\n", "        ", "self", ".", "assertEqual", "(", "self", ".", "xlmr", ".", "num_layers", ",", "7", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Unbabel_COMET.encoders.test_xlmr.TestXLMREncoder.test_output_units": [[14, 16], ["test_xlmr.TestXLMREncoder.assertEqual"], "methods", ["None"], ["", "def", "test_output_units", "(", "self", ")", ":", "\n", "        ", "self", ".", "assertEqual", "(", "self", ".", "xlmr", ".", "output_units", ",", "384", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Unbabel_COMET.encoders.test_xlmr.TestXLMREncoder.test_max_positions": [[17, 19], ["test_xlmr.TestXLMREncoder.assertEqual"], "methods", ["None"], ["", "def", "test_max_positions", "(", "self", ")", ":", "\n", "        ", "self", ".", "assertEqual", "(", "self", ".", "xlmr", ".", "max_positions", ",", "514", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Unbabel_COMET.encoders.test_xlmr.TestXLMREncoder.test_prepare_sample": [[20, 25], ["test_xlmr.TestXLMREncoder.xlmr.prepare_sample", "test_xlmr.TestXLMREncoder.assertIn", "test_xlmr.TestXLMREncoder.assertIn"], "methods", ["home.repos.pwc.inspect_result.Unbabel_COMET.regression.referenceless.ReferencelessRegression.prepare_sample"], ["", "def", "test_prepare_sample", "(", "self", ")", ":", "\n", "        ", "sample", "=", "[", "\"hello world, welcome to COMET!\"", ",", "\"This is a batch\"", "]", "\n", "model_input", "=", "self", ".", "xlmr", ".", "prepare_sample", "(", "sample", ")", "\n", "self", ".", "assertIn", "(", "\"input_ids\"", ",", "model_input", ")", "\n", "self", ".", "assertIn", "(", "\"attention_mask\"", ",", "model_input", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Unbabel_COMET.encoders.test_xlmr.TestXLMREncoder.test_forward": [[26, 34], ["test_xlmr.TestXLMREncoder.xlmr.prepare_sample", "test_xlmr.TestXLMREncoder.xlmr", "test_xlmr.TestXLMREncoder.assertIn", "test_xlmr.TestXLMREncoder.assertIn", "test_xlmr.TestXLMREncoder.assertIn", "test_xlmr.TestXLMREncoder.assertIn"], "methods", ["home.repos.pwc.inspect_result.Unbabel_COMET.regression.referenceless.ReferencelessRegression.prepare_sample"], ["", "def", "test_forward", "(", "self", ")", ":", "\n", "        ", "sample", "=", "[", "\"hello world, welcome to COMET!\"", ",", "\"This is a batch\"", "]", "\n", "model_input", "=", "self", ".", "xlmr", ".", "prepare_sample", "(", "sample", ")", "\n", "model_output", "=", "self", ".", "xlmr", "(", "**", "model_input", ")", "\n", "self", ".", "assertIn", "(", "\"wordemb\"", ",", "model_output", ")", "\n", "self", ".", "assertIn", "(", "\"sentemb\"", ",", "model_output", ")", "\n", "self", ".", "assertIn", "(", "\"all_layers\"", ",", "model_output", ")", "\n", "self", ".", "assertIn", "(", "\"attention_mask\"", ",", "model_output", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Unbabel_COMET.encoders.xlmr_xl.XLMRXLEncoder.__init__": [[31, 38], ["comet.encoders.xlmr.XLMREncoder.__init__", "transformers.XLMRobertaTokenizer.from_pretrained", "transformers.XLMRobertaXLModel.from_pretrained"], "methods", ["home.repos.pwc.inspect_result.Unbabel_COMET.regression.referenceless.ReferencelessRegression.__init__", "home.repos.pwc.inspect_result.Unbabel_COMET.encoders.xlmr.XLMREncoder.from_pretrained", "home.repos.pwc.inspect_result.Unbabel_COMET.encoders.xlmr.XLMREncoder.from_pretrained"], ["def", "__init__", "(", "self", ",", "pretrained_model", ":", "str", ")", "->", "None", ":", "\n", "        ", "super", "(", "Encoder", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "tokenizer", "=", "XLMRobertaTokenizer", ".", "from_pretrained", "(", "\"xlm-roberta-large\"", ")", "\n", "self", ".", "model", "=", "XLMRobertaXLModel", ".", "from_pretrained", "(", "\n", "pretrained_model", ",", "add_pooling_layer", "=", "False", "\n", ")", "\n", "self", ".", "model", ".", "encoder", ".", "output_hidden_states", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.Unbabel_COMET.encoders.xlmr_xl.XLMRXLEncoder.from_pretrained": [[39, 47], ["xlmr_xl.XLMRXLEncoder"], "methods", ["None"], ["", "@", "classmethod", "\n", "def", "from_pretrained", "(", "cls", ",", "pretrained_model", ":", "str", ")", "->", "Encoder", ":", "\n", "        ", "\"\"\"Function that loads a pretrained encoder from Hugging Face.\n        :param pretrained_model: Name of the pretrain model to be loaded.\n\n        :return: Encoder model\n        \"\"\"", "\n", "return", "XLMRXLEncoder", "(", "pretrained_model", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Unbabel_COMET.encoders.minilm.MiniLMEncoder.__init__": [[31, 38], ["comet.encoders.bert.BERTEncoder.__init__", "transformers.XLMRobertaTokenizer.from_pretrained", "transformers.BertModel.from_pretrained"], "methods", ["home.repos.pwc.inspect_result.Unbabel_COMET.regression.referenceless.ReferencelessRegression.__init__", "home.repos.pwc.inspect_result.Unbabel_COMET.encoders.xlmr.XLMREncoder.from_pretrained", "home.repos.pwc.inspect_result.Unbabel_COMET.encoders.xlmr.XLMREncoder.from_pretrained"], ["def", "__init__", "(", "self", ",", "pretrained_model", ":", "str", ")", "->", "None", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "tokenizer", "=", "XLMRobertaTokenizer", ".", "from_pretrained", "(", "\n", "pretrained_model", ",", "use_fast", "=", "True", "\n", ")", "\n", "self", ".", "model", "=", "BertModel", ".", "from_pretrained", "(", "pretrained_model", ")", "\n", "self", ".", "model", ".", "encoder", ".", "output_hidden_states", "=", "True", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Unbabel_COMET.encoders.base.Encoder.output_units": [[29, 34], ["None"], "methods", ["None"], ["import", "torch", "\n", "import", "transformers", "\n", "from", "comet", ".", "encoders", "import", "str2encoder", "\n", "from", "comet", ".", "modules", "import", "LayerwiseAttention", "\n", "from", "packaging", "import", "version", "\n", "from", "torch", "import", "nn", "\n"]], "home.repos.pwc.inspect_result.Unbabel_COMET.encoders.base.Encoder.max_positions": [[35, 40], ["None"], "methods", ["None"], ["from", "torch", ".", "utils", ".", "data", "import", "DataLoader", ",", "RandomSampler", ",", "Sampler", ",", "Subset", "\n", "\n", "from", ".", "lru_cache", "import", "tensor_lru_cache", "\n", "from", ".", "pooling_utils", "import", "average_pooling", ",", "max_pooling", "\n", "from", ".", "predict_pbar", "import", "PredictProgressBar", "\n", "\n"]], "home.repos.pwc.inspect_result.Unbabel_COMET.encoders.base.Encoder.num_layers": [[41, 46], ["None"], "methods", ["None"], ["\n", "class", "OrderedSampler", "(", "Sampler", "[", "int", "]", ")", ":", "\n", "    ", "\"\"\"\n    Sampler that returns the indices in a deterministic order.\n    \"\"\"", "\n", "\n"]], "home.repos.pwc.inspect_result.Unbabel_COMET.encoders.base.Encoder.from_pretrained": [[47, 55], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "indices", ":", "List", "[", "int", "]", ")", ":", "\n", "        ", "self", ".", "indices", "=", "indices", "\n", "\n", "", "def", "__iter__", "(", "self", ")", ":", "\n", "        ", "return", "iter", "(", "self", ".", "indices", ")", "\n", "\n", "", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "indices", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Unbabel_COMET.encoders.base.Encoder.prepare_sample": [[56, 71], ["base.Encoder.tokenizer"], "methods", ["None"], ["\n", "", "", "if", "\"COMET_EMBEDDINGS_CACHE\"", "in", "os", ".", "environ", ":", "\n", "    ", "CACHE_SIZE", "=", "int", "(", "os", ".", "environ", "[", "\"COMET_EMBEDDINGS_CACHE\"", "]", ")", "\n", "", "else", ":", "\n", "    ", "CACHE_SIZE", "=", "1024", "\n", "\n", "\n", "", "logger", "=", "logging", ".", "getLogger", "(", "__name__", ")", "\n", "\n", "\n", "class", "CometModel", "(", "ptl", ".", "LightningModule", ",", "metaclass", "=", "abc", ".", "ABCMeta", ")", ":", "\n", "    "]], "home.repos.pwc.inspect_result.Unbabel_COMET.encoders.base.Encoder.freeze": [[72, 76], ["base.Encoder.parameters"], "methods", ["None"], []], "home.repos.pwc.inspect_result.Unbabel_COMET.encoders.base.Encoder.unfreeze": [[77, 81], ["base.Encoder.parameters"], "methods", ["None"], []], "home.repos.pwc.inspect_result.Unbabel_COMET.encoders.base.Encoder.freeze_embeddings": [[82, 86], ["None"], "methods", ["None"], ["\n", "\n"]], "home.repos.pwc.inspect_result.Unbabel_COMET.encoders.base.Encoder.layerwise_lr": [[87, 96], ["None"], "methods", ["None"], ["def", "__init__", "(", "\n", "self", ",", "\n", "nr_frozen_epochs", ":", "Union", "[", "float", ",", "int", "]", "=", "0.3", ",", "\n", "keep_embeddings_frozen", ":", "bool", "=", "False", ",", "\n", "optimizer", ":", "str", "=", "\"AdamW\"", ",", "\n", "encoder_learning_rate", ":", "float", "=", "1e-05", ",", "\n", "learning_rate", ":", "float", "=", "3e-05", ",", "\n", "layerwise_decay", ":", "float", "=", "0.95", ",", "\n", "encoder_model", ":", "str", "=", "\"XLM-RoBERTa\"", ",", "\n", "pretrained_model", ":", "str", "=", "\"xlm-roberta-large\"", ",", "\n"]], "home.repos.pwc.inspect_result.Unbabel_COMET.encoders.base.Encoder.forward": [[97, 102], ["None"], "methods", ["None"], ["pool", ":", "str", "=", "\"avg\"", ",", "\n", "layer", ":", "Union", "[", "str", ",", "int", "]", "=", "\"mix\"", ",", "\n", "dropout", ":", "float", "=", "0.1", ",", "\n", "batch_size", ":", "int", "=", "4", ",", "\n", "train_data", ":", "Optional", "[", "str", "]", "=", "None", ",", "\n", "validation_data", ":", "Optional", "[", "str", "]", "=", "None", ",", "\n"]], "home.repos.pwc.inspect_result.Unbabel_COMET.encoders.bert.BERTEncoder.__init__": [[33, 38], ["comet.encoders.base.Encoder.__init__", "transformers.AutoTokenizer.from_pretrained", "transformers.AutoModel.from_pretrained"], "methods", ["home.repos.pwc.inspect_result.Unbabel_COMET.regression.referenceless.ReferencelessRegression.__init__", "home.repos.pwc.inspect_result.Unbabel_COMET.encoders.xlmr.XLMREncoder.from_pretrained", "home.repos.pwc.inspect_result.Unbabel_COMET.encoders.xlmr.XLMREncoder.from_pretrained"], ["def", "__init__", "(", "self", ",", "pretrained_model", ":", "str", ")", "->", "None", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "tokenizer", "=", "AutoTokenizer", ".", "from_pretrained", "(", "pretrained_model", ",", "use_fast", "=", "True", ")", "\n", "self", ".", "model", "=", "AutoModel", ".", "from_pretrained", "(", "pretrained_model", ")", "\n", "self", ".", "model", ".", "encoder", ".", "output_hidden_states", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.Unbabel_COMET.encoders.bert.BERTEncoder.output_units": [[39, 43], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "output_units", "(", "self", ")", ":", "\n", "        ", "\"\"\"Max number of tokens the encoder handles.\"\"\"", "\n", "return", "self", ".", "model", ".", "config", ".", "hidden_size", "\n", "\n"]], "home.repos.pwc.inspect_result.Unbabel_COMET.encoders.bert.BERTEncoder.max_positions": [[44, 48], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "max_positions", "(", "self", ")", ":", "\n", "        ", "\"\"\"Max number of tokens the encoder handles.\"\"\"", "\n", "return", "self", ".", "model", ".", "config", ".", "max_position_embeddings", "\n", "\n"]], "home.repos.pwc.inspect_result.Unbabel_COMET.encoders.bert.BERTEncoder.num_layers": [[49, 53], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "num_layers", "(", "self", ")", ":", "\n", "        ", "\"\"\"Number of model layers available.\"\"\"", "\n", "return", "self", ".", "model", ".", "config", ".", "num_hidden_layers", "+", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.Unbabel_COMET.encoders.bert.BERTEncoder.from_pretrained": [[54, 62], ["bert.BERTEncoder"], "methods", ["None"], ["", "@", "classmethod", "\n", "def", "from_pretrained", "(", "cls", ",", "pretrained_model", ":", "str", ")", "->", "Encoder", ":", "\n", "        ", "\"\"\"Function that loads a pretrained encoder from Hugging Face.\n        :param pretrained_model: Name of the pretrain model to be loaded.\n\n        :return: Encoder model\n        \"\"\"", "\n", "return", "BERTEncoder", "(", "pretrained_model", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Unbabel_COMET.encoders.bert.BERTEncoder.freeze_embeddings": [[63, 67], ["bert.BERTEncoder.model.embeddings.parameters"], "methods", ["None"], ["", "def", "freeze_embeddings", "(", "self", ")", "->", "None", ":", "\n", "        ", "\"\"\"Frezees the embedding layer.\"\"\"", "\n", "for", "param", "in", "self", ".", "model", ".", "embeddings", ".", "parameters", "(", ")", ":", "\n", "            ", "param", ".", "requires_grad", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.Unbabel_COMET.encoders.bert.BERTEncoder.layerwise_lr": [[68, 91], ["bert.BERTEncoder.model.embeddings.parameters", "bert.BERTEncoder.model.encoder.layer[].parameters", "range"], "methods", ["None"], ["", "", "def", "layerwise_lr", "(", "self", ",", "lr", ":", "float", ",", "decay", ":", "float", ")", ":", "\n", "        ", "\"\"\"\n        :param lr: Learning rate for the highest encoder layer.\n        :param decay: decay percentage for the lower layers.\n\n        :return: List of model parameters with layer-wise decay learning rate\n        \"\"\"", "\n", "# Embedding Layer", "\n", "opt_parameters", "=", "[", "\n", "{", "\n", "\"params\"", ":", "self", ".", "model", ".", "embeddings", ".", "parameters", "(", ")", ",", "\n", "\"lr\"", ":", "lr", "*", "decay", "**", "(", "self", ".", "num_layers", ")", ",", "\n", "}", "\n", "]", "\n", "# All layers", "\n", "opt_parameters", "+=", "[", "\n", "{", "\n", "\"params\"", ":", "self", ".", "model", ".", "encoder", ".", "layer", "[", "i", "]", ".", "parameters", "(", ")", ",", "\n", "\"lr\"", ":", "lr", "*", "decay", "**", "i", ",", "\n", "}", "\n", "for", "i", "in", "range", "(", "self", ".", "num_layers", "-", "2", ",", "0", ",", "-", "1", ")", "\n", "]", "\n", "return", "opt_parameters", "\n", "\n"]], "home.repos.pwc.inspect_result.Unbabel_COMET.encoders.bert.BERTEncoder.forward": [[92, 106], ["bert.BERTEncoder.model"], "methods", ["None"], ["", "def", "forward", "(", "\n", "self", ",", "input_ids", ":", "torch", ".", "Tensor", ",", "attention_mask", ":", "torch", ".", "Tensor", ",", "**", "kwargs", "\n", ")", "->", "Dict", "[", "str", ",", "torch", ".", "Tensor", "]", ":", "\n", "        ", "last_hidden_states", ",", "pooler_output", ",", "all_layers", "=", "self", ".", "model", "(", "\n", "input_ids", "=", "input_ids", ",", "\n", "attention_mask", "=", "attention_mask", ",", "\n", "output_hidden_states", "=", "True", ",", "\n", "return_dict", "=", "False", ",", "\n", ")", "\n", "return", "{", "\n", "\"sentemb\"", ":", "pooler_output", ",", "\n", "\"wordemb\"", ":", "last_hidden_states", ",", "\n", "\"all_layers\"", ":", "all_layers", ",", "\n", "\"attention_mask\"", ":", "attention_mask", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.Unbabel_COMET.encoders.xlmr.XLMREncoder.__init__": [[34, 41], ["comet.encoders.bert.BERTEncoder.__init__", "transformers.XLMRobertaTokenizer.from_pretrained", "transformers.XLMRobertaModel.from_pretrained"], "methods", ["home.repos.pwc.inspect_result.Unbabel_COMET.regression.referenceless.ReferencelessRegression.__init__", "home.repos.pwc.inspect_result.Unbabel_COMET.encoders.xlmr.XLMREncoder.from_pretrained", "home.repos.pwc.inspect_result.Unbabel_COMET.encoders.xlmr.XLMREncoder.from_pretrained"], ["def", "__init__", "(", "self", ",", "pretrained_model", ":", "str", ")", "->", "None", ":", "\n", "        ", "super", "(", "Encoder", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "tokenizer", "=", "XLMRobertaTokenizer", ".", "from_pretrained", "(", "pretrained_model", ")", "\n", "self", ".", "model", "=", "XLMRobertaModel", ".", "from_pretrained", "(", "\n", "pretrained_model", ",", "add_pooling_layer", "=", "False", "\n", ")", "\n", "self", ".", "model", ".", "encoder", ".", "output_hidden_states", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.Unbabel_COMET.encoders.xlmr.XLMREncoder.from_pretrained": [[42, 50], ["xlmr.XLMREncoder"], "methods", ["None"], ["", "@", "classmethod", "\n", "def", "from_pretrained", "(", "cls", ",", "pretrained_model", ":", "str", ")", "->", "Encoder", ":", "\n", "        ", "\"\"\"Function that loads a pretrained encoder from Hugging Face.\n        :param pretrained_model: Name of the pretrain model to be loaded.\n\n        :return: Encoder model\n        \"\"\"", "\n", "return", "XLMREncoder", "(", "pretrained_model", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Unbabel_COMET.encoders.xlmr.XLMREncoder.forward": [[51, 65], ["xlmr.XLMREncoder.model"], "methods", ["None"], ["", "def", "forward", "(", "\n", "self", ",", "input_ids", ":", "torch", ".", "Tensor", ",", "attention_mask", ":", "torch", ".", "Tensor", ",", "**", "kwargs", "\n", ")", "->", "Dict", "[", "str", ",", "torch", ".", "Tensor", "]", ":", "\n", "        ", "last_hidden_states", ",", "_", ",", "all_layers", "=", "self", ".", "model", "(", "\n", "input_ids", "=", "input_ids", ",", "\n", "attention_mask", "=", "attention_mask", ",", "\n", "output_hidden_states", "=", "True", ",", "\n", "return_dict", "=", "False", ",", "\n", ")", "\n", "return", "{", "\n", "\"sentemb\"", ":", "last_hidden_states", "[", ":", ",", "0", ",", ":", "]", ",", "\n", "\"wordemb\"", ":", "last_hidden_states", ",", "\n", "\"all_layers\"", ":", "all_layers", ",", "\n", "\"attention_mask\"", ":", "attention_mask", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.Unbabel_COMET.comet.download_utils.get_cache_folder": [[31, 39], ["Exception", "os.path.exists", "os.makedirs"], "function", ["None"], ["def", "get_cache_folder", "(", ")", ":", "\n", "    ", "if", "\"HOME\"", "in", "os", ".", "environ", ":", "\n", "        ", "cache_directory", "=", "os", ".", "environ", "[", "\"HOME\"", "]", "+", "\"/.cache/torch/unbabel_comet/\"", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "cache_directory", ")", ":", "\n", "            ", "os", ".", "makedirs", "(", "cache_directory", ")", "\n", "", "return", "cache_directory", "\n", "", "else", ":", "\n", "        ", "raise", "Exception", "(", "\"HOME environment variable is not defined.\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Unbabel_COMET.comet.download_utils._reporthook": [[41, 66], ["t.update"], "function", ["home.repos.pwc.inspect_result.Unbabel_COMET.models.metrics.WMTKendall.update"], ["", "", "def", "_reporthook", "(", "t", ")", ":", "\n", "    ", "\"\"\"``reporthook`` to use with ``urllib.request`` that prints the\n        process of the download.\n\n    Uses ``tqdm`` for progress bar.\n\n    **Reference:**\n    https://github.com/tqdm/tqdm\n\n    \"\"\"", "\n", "last_b", "=", "[", "0", "]", "\n", "\n", "def", "inner", "(", "b", ":", "int", "=", "1", ",", "bsize", ":", "int", "=", "1", ",", "tsize", ":", "int", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        :param b: Number of blocks just transferred [default: 1].\n        :param bsize: Size of each block (in tqdm units) [default: 1].\n        :param tsize: Total size (in tqdm units).\n            If [default: None] remains unchanged.\n        \"\"\"", "\n", "if", "tsize", "is", "not", "None", ":", "\n", "            ", "t", ".", "total", "=", "tsize", "\n", "", "t", ".", "update", "(", "(", "b", "-", "last_b", "[", "0", "]", ")", "*", "bsize", ")", "\n", "last_b", "[", "0", "]", "=", "b", "\n", "\n", "", "return", "inner", "\n", "\n"]], "home.repos.pwc.inspect_result.Unbabel_COMET.comet.download_utils._maybe_extract": [[68, 100], ["logger.info", "logger.info", "os.path.basename", "os.path.basename.split", "zipfile.ZipFile", "zip_.extractall", "open", "subprocess.call", "open", "subprocess.call"], "function", ["None"], ["", "def", "_maybe_extract", "(", "compressed_filename", ":", "str", ",", "directory", ":", "str", ",", "extension", ":", "str", "=", "None", ")", ":", "\n", "    ", "\"\"\"Extract a compressed file to ``directory``.\n\n    :param compressed_filename: Compressed file.\n    :param directory: Extract to directory.\n    :param extension: Extension of the file; Otherwise, attempts to\n        extract extension from the filename.\n    \"\"\"", "\n", "logger", ".", "info", "(", "\"Extracting {}\"", ".", "format", "(", "compressed_filename", ")", ")", "\n", "\n", "if", "extension", "is", "None", ":", "\n", "        ", "basename", "=", "os", ".", "path", ".", "basename", "(", "compressed_filename", ")", "\n", "extension", "=", "basename", ".", "split", "(", "\".\"", ",", "1", ")", "[", "1", "]", "\n", "\n", "", "if", "\"zip\"", "in", "extension", ":", "\n", "        ", "with", "zipfile", ".", "ZipFile", "(", "compressed_filename", ",", "\"r\"", ")", "as", "zip_", ":", "\n", "            ", "zip_", ".", "extractall", "(", "directory", ")", "\n", "\n", "", "", "elif", "\"tar.gz\"", "in", "extension", "or", "\"tgz\"", "in", "extension", ":", "\n", "# `tar` is much faster than python's `tarfile` implementation", "\n", "        ", "with", "open", "(", "os", ".", "devnull", ",", "\"w\"", ")", "as", "devnull", ":", "\n", "            ", "subprocess", ".", "call", "(", "\n", "[", "\"tar\"", ",", "\"-C\"", ",", "directory", ",", "\"-zxvf\"", ",", "compressed_filename", "]", ",", "stdout", "=", "devnull", "\n", ")", "\n", "\n", "", "", "elif", "\"tar\"", "in", "extension", ":", "\n", "        ", "with", "open", "(", "os", ".", "devnull", ",", "\"w\"", ")", "as", "devnull", ":", "\n", "            ", "subprocess", ".", "call", "(", "\n", "[", "\"tar\"", ",", "\"-C\"", ",", "directory", ",", "\"-xvf\"", ",", "compressed_filename", "]", ",", "stdout", "=", "devnull", "\n", ")", "\n", "\n", "", "", "logger", ".", "info", "(", "\"Extracted {}\"", ".", "format", "(", "compressed_filename", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Unbabel_COMET.comet.download_utils._get_filename_from_url": [[102, 113], ["urllib.parse.urlparse", "os.path.basename"], "function", ["None"], ["", "def", "_get_filename_from_url", "(", "url", ")", ":", "\n", "    ", "\"\"\"Return a filename from a URL\n\n    Args:\n        url (str): URL to extract filename from\n\n    Returns:\n        (str): Filename in URL\n    \"\"\"", "\n", "parse", "=", "urlparse", "(", "url", ")", "\n", "return", "os", ".", "path", ".", "basename", "(", "parse", ".", "path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Unbabel_COMET.comet.download_utils._check_download": [[115, 125], ["all", "os.path.isfile"], "function", ["None"], ["", "def", "_check_download", "(", "*", "filepaths", ")", ":", "\n", "    ", "\"\"\"Check if the downloaded files are found.\n\n    Args:\n        filepaths (list of str): Check if these filepaths exist\n\n    Returns:\n        (bool): Returns True if all filepaths exist\n    \"\"\"", "\n", "return", "all", "(", "[", "os", ".", "path", ".", "isfile", "(", "filepath", ")", "for", "filepath", "in", "filepaths", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Unbabel_COMET.comet.download_utils.download_file_maybe_extract": [[127, 175], ["str", "os.path.join", "logger.info", "download_utils._maybe_extract", "download_utils._get_filename_from_url", "os.path.join", "download_utils._check_download", "os.path.isdir", "os.makedirs", "tqdm.tqdm", "urllib.request.urlretrieve", "download_utils._check_download", "ValueError", "str", "len", "download_utils._reporthook"], "function", ["home.repos.pwc.inspect_result.Unbabel_COMET.comet.download_utils._maybe_extract", "home.repos.pwc.inspect_result.Unbabel_COMET.comet.download_utils._get_filename_from_url", "home.repos.pwc.inspect_result.Unbabel_COMET.comet.download_utils._check_download", "home.repos.pwc.inspect_result.Unbabel_COMET.comet.download_utils._check_download", "home.repos.pwc.inspect_result.Unbabel_COMET.comet.download_utils._reporthook"], ["", "def", "download_file_maybe_extract", "(", "\n", "url", ":", "str", ",", "\n", "directory", ":", "str", ",", "\n", "filename", ":", "str", "=", "None", ",", "\n", "extension", ":", "str", "=", "None", ",", "\n", "check_files", ":", "List", "[", "str", "]", "=", "[", "]", ",", "\n", ")", ":", "\n", "    ", "\"\"\"Download the file at ``url`` to ``directory``.\n        Extract to ``directory`` if tar or zip.\n\n    :param url: Url of file (str or Path).\n    :param directory: Directory to download to.\n    :param filename: Name of the file to download; Otherwise, a filename is extracted\n        from the url.\n    :param extension: Extension of the file; Otherwise, attempts to extract extension\n        from the filename.\n    :param check_files: Check if these files exist, ensuring the download\n        succeeded. If these files exist before the download, the download is skipped.\n\n    :return: Filename of download file.\n    \"\"\"", "\n", "if", "filename", "is", "None", ":", "\n", "        ", "filename", "=", "_get_filename_from_url", "(", "url", ")", "\n", "\n", "", "directory", "=", "str", "(", "directory", ")", "\n", "filepath", "=", "os", ".", "path", ".", "join", "(", "directory", ",", "filename", ")", "\n", "check_files", "=", "[", "os", ".", "path", ".", "join", "(", "directory", ",", "str", "(", "f", ")", ")", "for", "f", "in", "check_files", "]", "\n", "\n", "if", "len", "(", "check_files", ")", ">", "0", "and", "_check_download", "(", "*", "check_files", ")", ":", "\n", "        ", "return", "filepath", "\n", "\n", "", "if", "not", "os", ".", "path", ".", "isdir", "(", "directory", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "directory", ")", "\n", "\n", "", "logger", ".", "info", "(", "\"Downloading {}\"", ".", "format", "(", "filename", ")", ")", "\n", "\n", "# Download", "\n", "with", "tqdm", "(", "unit", "=", "\"B\"", ",", "unit_scale", "=", "True", ",", "miniters", "=", "1", ",", "desc", "=", "filename", ")", "as", "t", ":", "\n", "        ", "urllib", ".", "request", ".", "urlretrieve", "(", "url", ",", "filename", "=", "filepath", ",", "reporthook", "=", "_reporthook", "(", "t", ")", ")", "\n", "\n", "", "_maybe_extract", "(", "\n", "compressed_filename", "=", "filepath", ",", "directory", "=", "directory", ",", "extension", "=", "extension", "\n", ")", "\n", "\n", "if", "not", "_check_download", "(", "*", "check_files", ")", ":", "\n", "        ", "raise", "ValueError", "(", "\"[DOWNLOAD FAILED] `*check_files` not found\"", ")", "\n", "\n", "", "return", "filepath", "\n", "\n"]], "home.repos.pwc.inspect_result.Unbabel_COMET.comet.download_utils.download_model": [[177, 230], ["os.path.isdir", "os.path.exists", "os.path.exists", "os.path.exists", "download_utils.get_cache_folder", "get_cache_folder.endswith", "os.path.exists", "os.makedirs", "logger.info", "os.remove", "os.remove", "os.remove", "model.endswith", "comet.models.available_metrics.keys", "Exception", "available_metrics[].startswith", "os.listdir", "file.endswith", "download_utils.download_file_maybe_extract", "Exception"], "function", ["home.repos.pwc.inspect_result.Unbabel_COMET.comet.download_utils.get_cache_folder", "home.repos.pwc.inspect_result.Unbabel_COMET.comet.download_utils.download_file_maybe_extract"], ["", "def", "download_model", "(", "model", ":", "str", ",", "saving_directory", ":", "str", "=", "None", ")", "->", "str", ":", "\n", "    ", "\"\"\"\n    Function that loads pretrained models from AWS.\n\n    :param model: Name of the model to be loaded.\n    :param saving_directory: RELATIVE path to the saving folder (must end with /).\n\n    Return:\n        - Path to model checkpoint.\n    \"\"\"", "\n", "\n", "if", "saving_directory", "is", "None", ":", "\n", "        ", "saving_directory", "=", "get_cache_folder", "(", ")", "\n", "\n", "", "if", "not", "saving_directory", ".", "endswith", "(", "\"/\"", ")", ":", "\n", "        ", "saving_directory", "+=", "\"/\"", "\n", "\n", "", "if", "not", "os", ".", "path", ".", "exists", "(", "saving_directory", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "saving_directory", ")", "\n", "\n", "", "if", "os", ".", "path", ".", "isdir", "(", "saving_directory", "+", "model", ")", ":", "\n", "        ", "logger", ".", "info", "(", "f\"{model} is already in cache.\"", ")", "\n", "if", "not", "model", ".", "endswith", "(", "\"/\"", ")", ":", "\n", "            ", "model", "+=", "\"/\"", "\n", "\n", "", "", "elif", "model", "not", "in", "available_metrics", ".", "keys", "(", ")", ":", "\n", "        ", "raise", "Exception", "(", "\n", "f\"{model} is not in the `available_metrics` or is a valid checkpoint folder.\"", "\n", ")", "\n", "\n", "", "elif", "available_metrics", "[", "model", "]", ".", "startswith", "(", "\"https://\"", ")", ":", "\n", "        ", "download_file_maybe_extract", "(", "\n", "available_metrics", "[", "model", "]", ",", "directory", "=", "saving_directory", "\n", ")", "\n", "\n", "", "else", ":", "\n", "        ", "raise", "Exception", "(", "\"Invalid model name!\"", ")", "\n", "\n", "# CLEAN Cache", "\n", "", "if", "os", ".", "path", ".", "exists", "(", "saving_directory", "+", "model", "+", "\".zip\"", ")", ":", "\n", "        ", "os", ".", "remove", "(", "saving_directory", "+", "model", "+", "\".zip\"", ")", "\n", "", "if", "os", ".", "path", ".", "exists", "(", "saving_directory", "+", "model", "+", "\".tar.gz\"", ")", ":", "\n", "        ", "os", ".", "remove", "(", "saving_directory", "+", "model", "+", "\".tar.gz\"", ")", "\n", "", "if", "os", ".", "path", ".", "exists", "(", "saving_directory", "+", "model", "+", "\".tar\"", ")", ":", "\n", "        ", "os", ".", "remove", "(", "saving_directory", "+", "model", "+", "\".tar\"", ")", "\n", "\n", "", "checkpoints_folder", "=", "saving_directory", "+", "model", "+", "\"/checkpoints\"", "\n", "checkpoints", "=", "[", "\n", "file", "for", "file", "in", "os", ".", "listdir", "(", "checkpoints_folder", ")", "if", "file", ".", "endswith", "(", "\".ckpt\"", ")", "\n", "]", "\n", "checkpoint", "=", "checkpoints", "[", "-", "1", "]", "\n", "checkpoint_path", "=", "checkpoints_folder", "+", "\"/\"", "+", "checkpoint", "\n", "return", "checkpoint_path", "\n", "", ""]], "home.repos.pwc.inspect_result.Unbabel_COMET.cli.mbr.build_embeddings": [[50, 98], ["torch.vstack", "torch.vstack", "model.encoder.prepare_sample", "model.encoder.prepare_sample", "torch.no_grad", "torch.no_grad", "tqdm.tqdm", "range", "range", "batch[].to", "batch[].to", "torch.vstack.append", "batch[].to", "batch[].to", "torch.vstack.append", "len", "len", "model.get_sentence_embedding", "model.get_sentence_embedding"], "function", ["home.repos.pwc.inspect_result.Unbabel_COMET.regression.referenceless.ReferencelessRegression.prepare_sample", "home.repos.pwc.inspect_result.Unbabel_COMET.regression.referenceless.ReferencelessRegression.prepare_sample", "home.repos.pwc.inspect_result.Unbabel_COMET.models.base.CometModel.get_sentence_embedding", "home.repos.pwc.inspect_result.Unbabel_COMET.models.base.CometModel.get_sentence_embedding"], ["def", "build_embeddings", "(", "\n", "sources", ":", "List", "[", "str", "]", ",", "\n", "translations", ":", "List", "[", "str", "]", ",", "\n", "model", ":", "RegressionMetric", ",", "\n", "batch_size", ":", "int", ",", "\n", ")", "->", "Tuple", "[", "torch", ".", "Tensor", "]", ":", "\n", "    ", "\"\"\"Tokenization and respective encoding of source and translation sentences using\n    a RegressionMetric model.\n\n    :param sources: List of source sentences.\n    :param translations: List of translation sentences.\n    :param model: RegressionMetric model that will be used to embed sentences.\n    :param batch_size: batch size used during encoding.\n\n    :return: source and MT embeddings.\n    \"\"\"", "\n", "# TODO: Optimize this function to have faster MBR decoding!", "\n", "src_batches", "=", "[", "\n", "sources", "[", "i", ":", "i", "+", "batch_size", "]", "for", "i", "in", "range", "(", "0", ",", "len", "(", "sources", ")", ",", "batch_size", ")", "\n", "]", "\n", "src_inputs", "=", "[", "model", ".", "encoder", ".", "prepare_sample", "(", "batch", ")", "for", "batch", "in", "src_batches", "]", "\n", "mt_batches", "=", "[", "\n", "translations", "[", "i", ":", "i", "+", "batch_size", "]", "\n", "for", "i", "in", "range", "(", "0", ",", "len", "(", "translations", ")", ",", "batch_size", ")", "\n", "]", "\n", "mt_inputs", "=", "[", "model", ".", "encoder", ".", "prepare_sample", "(", "batch", ")", "for", "batch", "in", "mt_batches", "]", "\n", "\n", "src_embeddings", "=", "[", "]", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "for", "batch", "in", "src_inputs", ":", "\n", "            ", "input_ids", "=", "batch", "[", "\"input_ids\"", "]", ".", "to", "(", "model", ".", "device", ")", "\n", "attention_mask", "=", "batch", "[", "\"attention_mask\"", "]", ".", "to", "(", "model", ".", "device", ")", "\n", "src_embeddings", ".", "append", "(", "\n", "model", ".", "get_sentence_embedding", "(", "input_ids", ",", "attention_mask", ")", "\n", ")", "\n", "", "", "src_embeddings", "=", "torch", ".", "vstack", "(", "src_embeddings", ")", "\n", "\n", "mt_embeddings", "=", "[", "]", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "for", "batch", "in", "tqdm", "(", "mt_inputs", ",", "desc", "=", "\"Encoding sentences...\"", ",", "dynamic_ncols", "=", "True", ")", ":", "\n", "            ", "input_ids", "=", "batch", "[", "\"input_ids\"", "]", ".", "to", "(", "model", ".", "device", ")", "\n", "attention_mask", "=", "batch", "[", "\"attention_mask\"", "]", ".", "to", "(", "model", ".", "device", ")", "\n", "mt_embeddings", ".", "append", "(", "\n", "model", ".", "get_sentence_embedding", "(", "input_ids", ",", "attention_mask", ")", "\n", ")", "\n", "", "", "mt_embeddings", "=", "torch", ".", "vstack", "(", "mt_embeddings", ")", "\n", "\n", "return", "src_embeddings", ",", "mt_embeddings", "\n", "\n"]], "home.repos.pwc.inspect_result.Unbabel_COMET.cli.mbr.mbr_decoding": [[100, 134], ["torch.zeros", "torch.no_grad", "tqdm.tqdm", "range", "src_embeddings[].repeat", "range", "mt_embeddings[].repeat", "[].squeeze", "torch.cat", "torch.cat.mean", "model.estimate"], "function", ["home.repos.pwc.inspect_result.Unbabel_COMET.regression.regression_metric.RegressionMetric.estimate"], ["", "def", "mbr_decoding", "(", "\n", "src_embeddings", ":", "torch", ".", "Tensor", ",", "mt_embeddings", ":", "torch", ".", "Tensor", ",", "model", ":", "RegressionMetric", "\n", ")", "->", "torch", ".", "Tensor", ":", "\n", "    ", "\"\"\"Performs MBR Decoding for each translation for a given source.\n\n    :param src_embeddings: Embeddings of source sentences.\n    :param mt_embeddings: Embeddings of MT sentences.\n    :param model: RegressionMetric Model.\n\n    :return:\n        Returns a [n_sent x num_samples] matrix M where each line represents a source sentence\n        and each column a given sample.\n        M[i][j] is the MBR score of sample j for source i.\n    \"\"\"", "\n", "n_sent", ",", "num_samples", ",", "_", "=", "mt_embeddings", ".", "shape", "\n", "mbr_matrix", "=", "torch", ".", "zeros", "(", "n_sent", ",", "num_samples", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "# Loop over all source sentences", "\n", "        ", "for", "i", "in", "tqdm", "(", "\n", "range", "(", "mbr_matrix", ".", "shape", "[", "0", "]", ")", ",", "desc", "=", "\"MBR Scores...\"", ",", "dynamic_ncols", "=", "True", "\n", ")", ":", "\n", "            ", "source", "=", "src_embeddings", "[", "i", ",", ":", "]", ".", "repeat", "(", "num_samples", ",", "1", ")", "\n", "# Loop over all hypothesis", "\n", "for", "j", "in", "range", "(", "mbr_matrix", ".", "shape", "[", "1", "]", ")", ":", "\n", "                ", "translation", "=", "mt_embeddings", "[", "i", ",", "j", ",", ":", "]", ".", "repeat", "(", "num_samples", ",", "1", ")", "\n", "# Score current hypothesis against all others", "\n", "pseudo_refs", "=", "mt_embeddings", "[", "i", ",", ":", "]", "\n", "scores", "=", "model", ".", "estimate", "(", "source", ",", "translation", ",", "pseudo_refs", ")", "[", "\n", "\"score\"", "\n", "]", ".", "squeeze", "(", "1", ")", "\n", "scores", "=", "torch", ".", "cat", "(", "[", "scores", "[", "0", ":", "j", "]", ",", "scores", "[", "j", "+", "1", ":", "]", "]", ")", "\n", "mbr_matrix", "[", "i", ",", "j", "]", "=", "scores", ".", "mean", "(", ")", "\n", "\n", "", "", "", "return", "mbr_matrix", "\n", "\n"]], "home.repos.pwc.inspect_result.Unbabel_COMET.cli.mbr.mbr_command": [[136, 213], ["jsonargparse.ArgumentParser", "jsonargparse.ArgumentParser.add_argument", "jsonargparse.ArgumentParser.add_argument", "jsonargparse.ArgumentParser.add_argument", "jsonargparse.ArgumentParser.add_argument", "jsonargparse.ArgumentParser.add_argument", "jsonargparse.ArgumentParser.add_argument", "jsonargparse.ArgumentParser.add_argument", "jsonargparse.ArgumentParser.parse_args", "comet.models.load_from_checkpoint", "comet.models.load_from_checkpoint.eval", "comet.models.load_from_checkpoint.cuda", "mbr.build_embeddings", "mt_embeddings.reshape.reshape", "mbr.mbr_decoding", "enumerate", "parser.parse_args.model.endswith", "os.path.exists", "comet.models.load_from_checkpoint.is_referenceless", "Exception", "open", "open", "len", "len", "len", "torch.argmax", "best_candidates.append", "open", "comet.download_utils.download_model", "jsonargparse.ArgumentParser.error", "isinstance", "parser.parse_args.sources", "line.strip", "parser.parse_args.translations", "line.strip", "range", "fp.write", "fp.readlines", "fp.readlines", "len", "comet.models.available_metrics.keys"], "function", ["home.repos.pwc.inspect_result.Unbabel_COMET.models.__init__.load_from_checkpoint", "home.repos.pwc.inspect_result.Unbabel_COMET.cli.mbr.build_embeddings", "home.repos.pwc.inspect_result.Unbabel_COMET.cli.mbr.mbr_decoding", "home.repos.pwc.inspect_result.Unbabel_COMET.regression.referenceless.ReferencelessRegression.is_referenceless", "home.repos.pwc.inspect_result.Unbabel_COMET.comet.download_utils.download_model"], ["", "def", "mbr_command", "(", ")", "->", "None", ":", "\n", "    ", "parser", "=", "ArgumentParser", "(", "description", "=", "\"Command for Minimum Bayes Risk Decoding.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"-s\"", ",", "\"--sources\"", ",", "type", "=", "Path_fr", ",", "required", "=", "True", ")", "\n", "parser", ".", "add_argument", "(", "\"-t\"", ",", "\"--translations\"", ",", "type", "=", "Path_fr", ",", "required", "=", "True", ")", "\n", "parser", ".", "add_argument", "(", "\"--batch_size\"", ",", "type", "=", "int", ",", "default", "=", "8", ")", "\n", "parser", ".", "add_argument", "(", "\"--num_samples\"", ",", "type", "=", "int", ",", "required", "=", "True", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--model\"", ",", "\n", "type", "=", "str", ",", "\n", "required", "=", "False", ",", "\n", "default", "=", "\"wmt20-comet-da\"", ",", "\n", "help", "=", "\"COMET model to be used.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--model_storage_path\"", ",", "\n", "help", "=", "(", "\n", "\"Path to the directory where models will be stored. \"", "\n", "+", "\"By default its saved in ~/.cache/torch/unbabel_comet/\"", "\n", ")", ",", "\n", "default", "=", "None", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"-o\"", ",", "\n", "\"--output\"", ",", "\n", "type", "=", "str", ",", "\n", "required", "=", "True", ",", "\n", "help", "=", "\"Best candidates after running MBR decoding.\"", ",", "\n", ")", "\n", "cfg", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "if", "cfg", ".", "model", ".", "endswith", "(", "\".ckpt\"", ")", "and", "os", ".", "path", ".", "exists", "(", "cfg", ".", "model", ")", ":", "\n", "        ", "model_path", "=", "cfg", ".", "model", "\n", "", "elif", "cfg", ".", "model", "in", "available_metrics", ":", "\n", "        ", "model_path", "=", "download_model", "(", "cfg", ".", "model", ",", "saving_directory", "=", "cfg", ".", "model_storage_path", ")", "\n", "", "else", ":", "\n", "        ", "parser", ".", "error", "(", "\n", "\"{} is not a valid checkpoint path or model choice. Choose from {}\"", ".", "format", "(", "\n", "cfg", ".", "model", ",", "available_metrics", ".", "keys", "(", ")", "\n", ")", "\n", ")", "\n", "", "model", "=", "load_from_checkpoint", "(", "model_path", ")", "\n", "\n", "if", "not", "isinstance", "(", "model", ",", "RegressionMetric", ")", "or", "model", ".", "is_referenceless", "(", ")", ":", "\n", "        ", "raise", "Exception", "(", "\n", "\"Incorrect model ({}). MBR command only works with Reference-based Regression models!\"", ".", "format", "(", "\n", "model", ".", "__class__", ".", "__name__", "\n", ")", "\n", ")", "\n", "\n", "", "model", ".", "eval", "(", ")", "\n", "model", ".", "cuda", "(", ")", "\n", "\n", "with", "open", "(", "cfg", ".", "sources", "(", ")", ")", "as", "fp", ":", "\n", "        ", "sources", "=", "[", "line", ".", "strip", "(", ")", "for", "line", "in", "fp", ".", "readlines", "(", ")", "]", "\n", "\n", "", "with", "open", "(", "cfg", ".", "translations", "(", ")", ")", "as", "fp", ":", "\n", "        ", "translations", "=", "[", "line", ".", "strip", "(", ")", "for", "line", "in", "fp", ".", "readlines", "(", ")", "]", "\n", "\n", "", "src_embeddings", ",", "mt_embeddings", "=", "build_embeddings", "(", "\n", "sources", ",", "translations", ",", "model", ",", "cfg", ".", "batch_size", "\n", ")", "\n", "mt_embeddings", "=", "mt_embeddings", ".", "reshape", "(", "len", "(", "sources", ")", ",", "cfg", ".", "num_samples", ",", "-", "1", ")", "\n", "mbr_matrix", "=", "mbr_decoding", "(", "src_embeddings", ",", "mt_embeddings", ",", "model", ")", "\n", "translations", "=", "[", "\n", "translations", "[", "i", ":", "i", "+", "cfg", ".", "num_samples", "]", "\n", "for", "i", "in", "range", "(", "0", ",", "len", "(", "translations", ")", ",", "cfg", ".", "num_samples", ")", "\n", "]", "\n", "assert", "len", "(", "sources", ")", "==", "len", "(", "translations", ")", "\n", "\n", "best_candidates", "=", "[", "]", "\n", "for", "i", ",", "samples", "in", "enumerate", "(", "translations", ")", ":", "\n", "        ", "best_cand_idx", "=", "torch", ".", "argmax", "(", "mbr_matrix", "[", "i", ",", ":", "]", ")", "\n", "best_candidates", ".", "append", "(", "samples", "[", "best_cand_idx", "]", ")", "\n", "\n", "", "with", "open", "(", "cfg", ".", "output", ",", "\"w\"", ")", "as", "fp", ":", "\n", "        ", "for", "sample", "in", "best_candidates", ":", "\n", "            ", "fp", ".", "write", "(", "sample", "+", "\"\\n\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Unbabel_COMET.cli.train.train_command": [[47, 118], ["jsonargparse.ArgumentParser", "jsonargparse.ArgumentParser.add_argument", "jsonargparse.ArgumentParser.add_argument", "jsonargparse.ArgumentParser.add_class_arguments", "jsonargparse.ArgumentParser.add_subclass_arguments", "jsonargparse.ArgumentParser.add_subclass_arguments", "jsonargparse.ArgumentParser.add_subclass_arguments", "jsonargparse.ArgumentParser.add_subclass_arguments", "jsonargparse.ArgumentParser.add_subclass_arguments", "jsonargparse.ArgumentParser.add_subclass_arguments", "jsonargparse.ArgumentParser.parse_args", "pytorch_lightning.seed_everything", "pytorch_lightning.callbacks.ModelCheckpoint", "pytorch_lightning.callbacks.EarlyStopping", "jsonargparse.namespace_to_dict", "print", "print", "pytorch_lightning.trainer.trainer.Trainer", "print", "warnings.filterwarnings", "pytorch_lightning.trainer.trainer.Trainer.fit", "json.dumps", "print", "comet.models.RegressionMetric", "jsonargparse.namespace_to_dict", "jsonargparse.namespace_to_dict", "json.dumps", "print", "comet.models.ReferencelessRegression", "jsonargparse.namespace_to_dict", "json.dumps", "print", "comet.models.RankingMetric", "Exception", "jsonargparse.namespace_to_dict", "json.dumps", "jsonargparse.namespace_to_dict"], "function", ["None"], ["def", "train_command", "(", ")", "->", "None", ":", "\n", "    ", "parser", "=", "ArgumentParser", "(", "description", "=", "\"Command for training COMET models.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--seed_everything\"", ",", "\n", "type", "=", "int", ",", "\n", "default", "=", "12", ",", "\n", "help", "=", "\"Training Seed.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\"--cfg\"", ",", "action", "=", "ActionConfigFile", ")", "\n", "parser", ".", "add_class_arguments", "(", "CometModel", ",", "\"model\"", ")", "\n", "parser", ".", "add_subclass_arguments", "(", "RegressionMetric", ",", "\"regression_metric\"", ")", "\n", "parser", ".", "add_subclass_arguments", "(", "\n", "ReferencelessRegression", ",", "\"referenceless_regression_metric\"", "\n", ")", "\n", "parser", ".", "add_subclass_arguments", "(", "RankingMetric", ",", "\"ranking_metric\"", ")", "\n", "parser", ".", "add_subclass_arguments", "(", "EarlyStopping", ",", "\"early_stopping\"", ")", "\n", "parser", ".", "add_subclass_arguments", "(", "ModelCheckpoint", ",", "\"model_checkpoint\"", ")", "\n", "parser", ".", "add_subclass_arguments", "(", "Trainer", ",", "\"trainer\"", ")", "\n", "cfg", "=", "parser", ".", "parse_args", "(", ")", "\n", "seed_everything", "(", "cfg", ".", "seed_everything", ")", "\n", "\n", "checkpoint_callback", "=", "ModelCheckpoint", "(", "\n", "**", "namespace_to_dict", "(", "cfg", ".", "model_checkpoint", ".", "init_args", ")", "\n", ")", "\n", "early_stop_callback", "=", "EarlyStopping", "(", "\n", "**", "namespace_to_dict", "(", "cfg", ".", "early_stopping", ".", "init_args", ")", "\n", ")", "\n", "trainer_args", "=", "namespace_to_dict", "(", "cfg", ".", "trainer", ".", "init_args", ")", "\n", "trainer_args", "[", "\"callbacks\"", "]", "=", "[", "early_stop_callback", ",", "checkpoint_callback", "]", "\n", "print", "(", "\"TRAINER ARGUMENTS: \"", ")", "\n", "print", "(", "json", ".", "dumps", "(", "trainer_args", ",", "indent", "=", "4", ",", "default", "=", "lambda", "x", ":", "x", ".", "__dict__", ")", ")", "\n", "trainer", "=", "Trainer", "(", "**", "trainer_args", ")", "\n", "\n", "print", "(", "\"MODEL ARGUMENTS: \"", ")", "\n", "if", "cfg", ".", "regression_metric", "is", "not", "None", ":", "\n", "        ", "print", "(", "\n", "json", ".", "dumps", "(", "\n", "cfg", ".", "regression_metric", ".", "init_args", ",", "indent", "=", "4", ",", "default", "=", "lambda", "x", ":", "x", ".", "__dict__", "\n", ")", "\n", ")", "\n", "model", "=", "RegressionMetric", "(", "**", "namespace_to_dict", "(", "cfg", ".", "regression_metric", ".", "init_args", ")", ")", "\n", "", "elif", "cfg", ".", "referenceless_regression_metric", "is", "not", "None", ":", "\n", "        ", "print", "(", "\n", "json", ".", "dumps", "(", "\n", "cfg", ".", "referenceless_regression_metric", ".", "init_args", ",", "\n", "indent", "=", "4", ",", "\n", "default", "=", "lambda", "x", ":", "x", ".", "__dict__", ",", "\n", ")", "\n", ")", "\n", "model", "=", "ReferencelessRegression", "(", "\n", "**", "namespace_to_dict", "(", "cfg", ".", "referenceless_regression_metric", ".", "init_args", ")", "\n", ")", "\n", "", "elif", "cfg", ".", "ranking_metric", "is", "not", "None", ":", "\n", "        ", "print", "(", "\n", "json", ".", "dumps", "(", "\n", "cfg", ".", "ranking_metric", ".", "init_args", ",", "indent", "=", "4", ",", "default", "=", "lambda", "x", ":", "x", ".", "__dict__", "\n", ")", "\n", ")", "\n", "model", "=", "RankingMetric", "(", "**", "namespace_to_dict", "(", "cfg", ".", "ranking_metric", ".", "init_args", ")", ")", "\n", "", "else", ":", "\n", "        ", "raise", "Exception", "(", "\"Model configurations missing!\"", ")", "\n", "# Related to train/val_dataloaders:", "\n", "\n", "# 2 workers per gpu is enough! If set to the number of cpus on this machine", "\n", "# it throws another exception saying its too many workers.", "\n", "", "warnings", ".", "filterwarnings", "(", "\n", "\"ignore\"", ",", "\n", "category", "=", "UserWarning", ",", "\n", "message", "=", "\".*Consider increasing the value of the `num_workers` argument` .*\"", ",", "\n", ")", "\n", "trainer", ".", "fit", "(", "model", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Unbabel_COMET.cli.compare.display_statistical_results": [[77, 111], ["print", "print", "print", "print", "data[].items", "print", "data[].items", "print", "print", "print", "print", "print", "print"], "function", ["None"], ["def", "display_statistical_results", "(", "data", ":", "Statistical_test_info", ")", "->", "None", ":", "\n", "    ", "\"\"\"\n    Print out the T-test results for a system pair.\n    \"\"\"", "\n", "print", "(", "\"==========================\"", ")", "\n", "print", "(", "\"x_name:\"", ",", "data", "[", "\"x_name\"", "]", ".", "rel_path", ")", "\n", "print", "(", "\"y_name:\"", ",", "data", "[", "\"y_name\"", "]", ".", "rel_path", ")", "\n", "\n", "print", "(", "\"\\nBootstrap Resampling Results:\"", ")", "\n", "for", "k", ",", "v", "in", "data", "[", "\"bootstrap_resampling\"", "]", ".", "items", "(", ")", ":", "\n", "        ", "print", "(", "\"{}:\\t{:.4f}\"", ".", "format", "(", "k", ",", "v", ")", ")", "\n", "\n", "", "print", "(", "\"\\nPaired T-Test Results:\"", ")", "\n", "for", "k", ",", "v", "in", "data", "[", "\"paired_t-test\"", "]", ".", "items", "(", ")", ":", "\n", "        ", "print", "(", "\"{}:\\t{:.4f}\"", ".", "format", "(", "k", ",", "v", ")", ")", "\n", "\n", "", "x_seg_scores", "=", "data", "[", "\"bootstrap_resampling\"", "]", "[", "\"x-mean\"", "]", "\n", "y_seg_scores", "=", "data", "[", "\"bootstrap_resampling\"", "]", "[", "\"y-mean\"", "]", "\n", "best_system", "=", "(", "\n", "data", "[", "\"x_name\"", "]", ".", "rel_path", "\n", "if", "x_seg_scores", ">", "y_seg_scores", "\n", "else", "data", "[", "\"y_name\"", "]", ".", "rel_path", "\n", ")", "\n", "worse_system", "=", "(", "\n", "data", "[", "\"x_name\"", "]", ".", "rel_path", "\n", "if", "x_seg_scores", "<", "y_seg_scores", "\n", "else", "data", "[", "\"y_name\"", "]", ".", "rel_path", "\n", ")", "\n", "if", "data", "[", "\"paired_t-test\"", "]", "[", "\"p_value\"", "]", "<=", "0.05", ":", "\n", "        ", "print", "(", "\"Null hypothesis rejected according to t-test.\"", ")", "\n", "print", "(", "\"Scores differ significantly across samples.\"", ")", "\n", "print", "(", "f\"{best_system} outperforms {worse_system}.\"", ")", "\n", "", "else", ":", "\n", "        ", "print", "(", "\"Null hypothesis can't be rejected.\\nBoth systems have equal averages.\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Unbabel_COMET.cli.compare.t_tests_summary": [[113, 148], ["len", "print", "print", "print", "print", "print", "tabulate.tabulate", "enumerate", "tuple", "zip"], "function", ["None"], ["", "", "def", "t_tests_summary", "(", "\n", "t_test_results", ":", "List", "[", "Statistical_test_info", "]", ",", "\n", "translations", ":", "Tuple", "[", "Path_fr", "]", ",", "\n", "threshold_p_value", ":", "float", "=", "0.05", ",", "\n", ")", "->", "None", ":", "\n", "    ", "\"\"\"\n    T-tests Summary\n    \"\"\"", "\n", "n", "=", "len", "(", "translations", ")", "\n", "name2id", "=", "{", "name", ":", "i", "for", "i", ",", "name", "in", "enumerate", "(", "translations", ")", "}", "\n", "grid", "=", "[", "[", "None", "]", "*", "n", "for", "name", "in", "translations", "]", "\n", "for", "t_test", "in", "t_test_results", ":", "\n", "        ", "p_value", "=", "t_test", "[", "\"paired_t-test\"", "]", "[", "\"p_value\"", "]", "\n", "x_id", "=", "name2id", "[", "t_test", "[", "\"x_name\"", "]", "]", "\n", "y_id", "=", "name2id", "[", "t_test", "[", "\"y_name\"", "]", "]", "\n", "grid", "[", "x_id", "]", "[", "y_id", "]", "=", "False", "\n", "grid", "[", "y_id", "]", "[", "x_id", "]", "=", "False", "\n", "if", "p_value", "<", "threshold_p_value", ":", "\n", "            ", "x_seg_scores", "=", "t_test", "[", "\"bootstrap_resampling\"", "]", "[", "\"x-mean\"", "]", "\n", "y_seg_scores", "=", "t_test", "[", "\"bootstrap_resampling\"", "]", "[", "\"y-mean\"", "]", "\n", "if", "x_seg_scores", ">", "y_seg_scores", ":", "\n", "                ", "grid", "[", "x_id", "]", "[", "y_id", "]", "=", "True", "\n", "", "else", ":", "\n", "                ", "grid", "[", "y_id", "]", "[", "x_id", "]", "=", "True", "\n", "\n", "# Add the row's name aka the system's name.", "\n", "", "", "", "grid", "=", "[", "(", "name", ",", ")", "+", "tuple", "(", "row", ")", "for", "name", ",", "row", "in", "zip", "(", "translations", ",", "grid", ")", "]", "\n", "\n", "print", "(", "\"Summary\"", ")", "\n", "print", "(", "\"If system_x is better than system_y then:\"", ")", "\n", "print", "(", "\n", "f\"Null hypothesis rejected according to t-test with p_value={threshold_p_value}.\"", "\n", ")", "\n", "print", "(", "\"Scores differ significantly across samples.\"", ")", "\n", "print", "(", "tabulate", "(", "grid", ",", "headers", "=", "(", "\"system_x \\ system_y\"", ",", ")", "+", "translations", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Unbabel_COMET.cli.compare.calculate_bootstrap": [[150, 176], ["numpy.absolute", "float", "float", "float", "len", "len", "len", "float", "float", "numpy.mean", "numpy.mean"], "function", ["None"], ["", "def", "calculate_bootstrap", "(", "\n", "x_sys_scores", ":", "np", ".", "ndarray", ",", "y_sys_scores", ":", "np", ".", "ndarray", ",", "x_name", ":", "Path_fr", ",", "y_name", ":", "Path_fr", "\n", ")", "->", "Statistical_test_info", ":", "\n", "    ", "\"\"\"\n    Calculate bootstrap score, wins and ties for a system pair.\n    x_sys_scores: array of num_splits comet scores for system x\n    y_sys_scores: array of num_splits comet scores for system y\n    x_name: system x's name\n    y_name: system y's name\n    num_split: number of splits\n    \"\"\"", "\n", "num_splits", "=", "x_sys_scores", ".", "shape", "[", "0", "]", "\n", "delta", "=", "x_sys_scores", "-", "y_sys_scores", "\n", "ties", "=", "np", ".", "absolute", "(", "delta", ")", "\n", "ties", "=", "float", "(", "len", "(", "ties", "[", "ties", "<", "EPS", "]", ")", ")", "\n", "x_wins", "=", "float", "(", "len", "(", "delta", "[", "delta", ">=", "EPS", "]", ")", ")", "\n", "y_wins", "=", "float", "(", "len", "(", "delta", "[", "delta", "<=", "-", "EPS", "]", ")", ")", "\n", "return", "{", "\n", "\"x_name\"", ":", "x_name", ",", "\n", "\"y_name\"", ":", "y_name", ",", "\n", "\"bootstrap_resampling\"", ":", "{", "\n", "\"x-mean\"", ":", "float", "(", "np", ".", "mean", "(", "x_sys_scores", ")", ")", ",", "\n", "\"y-mean\"", ":", "float", "(", "np", ".", "mean", "(", "y_sys_scores", ")", ")", ",", "\n", "\"ties (%)\"", ":", "ties", "/", "num_splits", ",", "\n", "\"x_wins (%)\"", ":", "x_wins", "/", "num_splits", ",", "\n", "\"y_wins (%)\"", ":", "y_wins", "/", "num_splits", ",", "\n", "}", ",", "\n"]], "home.repos.pwc.inspect_result.Unbabel_COMET.cli.compare.pairwise_bootstrap": [[180, 192], ["itertools.combinations", "len", "zip", "compare.calculate_bootstrap"], "function", ["home.repos.pwc.inspect_result.Unbabel_COMET.cli.compare.calculate_bootstrap"], ["", "def", "pairwise_bootstrap", "(", "\n", "sys_scores", ":", "np", ".", "ndarray", ",", "systems", ":", "List", "[", "Path_fr", "]", "\n", ")", "->", "Generator", "[", "Statistical_test_info", ",", "None", ",", "None", "]", ":", "\n", "    ", "\"\"\"\n    Calculates the bootstrap resampling between all systems' permutations.\n    sys_scores: comet scores [num_systems x num_splits]\n    \"\"\"", "\n", "assert", "sys_scores", ".", "shape", "[", "0", "]", "==", "len", "(", "systems", ")", ",", "\"Each system should have its sys_score.\"", "\n", "\n", "pairs", "=", "combinations", "(", "zip", "(", "systems", ",", "sys_scores", ")", ",", "2", ")", "\n", "for", "(", "x_name", ",", "x_sys_scores", ")", ",", "(", "y_name", ",", "y_sys_scores", ")", "in", "pairs", ":", "\n", "        ", "yield", "calculate_bootstrap", "(", "x_sys_scores", ",", "y_sys_scores", ",", "x_name", ",", "y_name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Unbabel_COMET.cli.compare.bootstrap_resampling": [[194, 211], ["numpy.random.choice", "numpy.take", "numpy.mean"], "function", ["None"], ["", "", "def", "bootstrap_resampling", "(", "seg_scores", ":", "np", ".", "ndarray", ",", "sample_size", ":", "int", ",", "num_splits", ":", "int", ")", ":", "\n", "    ", "\"\"\"\n    seg_scores: comet scores for each systems' translation, aka a comet score matrix [num_systems X num_sentences]\n    sample_size:\n    num_splits:\n    Returns a comet score matrix [num_systems X num_splits]\n    \"\"\"", "\n", "population_size", "=", "seg_scores", ".", "shape", "[", "1", "]", "\n", "# Subsample the gold and system outputs (with replacement)", "\n", "subsample_ids", "=", "np", ".", "random", ".", "choice", "(", "\n", "population_size", ",", "size", "=", "(", "sample_size", ",", "num_splits", ")", ",", "replace", "=", "True", "\n", ")", "\n", "subsamples", "=", "np", ".", "take", "(", "\n", "seg_scores", ",", "subsample_ids", ",", "axis", "=", "1", "\n", ")", "# num_systems x sample_size x num_splits", "\n", "sys_scores", "=", "np", ".", "mean", "(", "subsamples", ",", "axis", "=", "1", ")", "# num_systems x num_splits", "\n", "return", "sys_scores", "\n", "\n"]], "home.repos.pwc.inspect_result.Unbabel_COMET.cli.compare.score": [[213, 279], ["comet.models.load_from_checkpoint", "comet.models.load_from_checkpoint.eval", "len", "list", "numpy.array", "comet.models.load_from_checkpoint.set_embedding_cache", "print", "comet.models.load_from_checkpoint.predict", "torch.distributed.all_gather_object", "torch.distributed.barrier", "zip", "comet.models.load_from_checkpoint.retrieve_sentence_embedding.cache_info", "dict", "torch.distributed.get_rank", "comet.models.load_from_checkpoint.predict", "zip", "zip", "range", "dict", "system.keys", "range", "zip", "zip", "system.values", "len", "iter", "system.values"], "function", ["home.repos.pwc.inspect_result.Unbabel_COMET.models.__init__.load_from_checkpoint", "home.repos.pwc.inspect_result.Unbabel_COMET.models.base.CometModel.set_embedding_cache", "home.repos.pwc.inspect_result.Unbabel_COMET.models.base.CometModel.predict", "home.repos.pwc.inspect_result.Unbabel_COMET.models.base.CometModel.predict"], ["", "def", "score", "(", "cfg", ":", "Namespace", ",", "systems", ":", "List", "[", "Dict", "[", "str", ",", "List", "[", "str", "]", "]", "]", ")", "->", "np", ".", "ndarray", ":", "\n", "    ", "\"\"\"\n    Scores each systems with a given model.\n    Returns a comet score matrix [num_systems X num_sentences]\n    \"\"\"", "\n", "model", "=", "load_from_checkpoint", "(", "cfg", ".", "model_path", ")", "\n", "model", ".", "eval", "(", ")", "\n", "\n", "if", "not", "cfg", ".", "disable_cache", ":", "\n", "        ", "model", ".", "set_embedding_cache", "(", ")", "\n", "\n", "", "if", "cfg", ".", "print_cache_info", ":", "\n", "        ", "print", "(", "model", ".", "retrieve_sentence_embedding", ".", "cache_info", "(", ")", ")", "\n", "\n", "", "if", "cfg", ".", "gpus", ">", "1", "and", "cfg", ".", "accelerator", "==", "\"ddp\"", ":", "\n", "# Create a single list that contains all systems' source, reference & translation.", "\n", "        ", "samples", "=", "[", "\n", "dict", "(", "zip", "(", "system", ".", "keys", "(", ")", ",", "values", ")", ")", "\n", "for", "system", "in", "systems", "\n", "for", "values", "in", "zip", "(", "*", "system", ".", "values", "(", ")", ")", "\n", "]", "\n", "# raise NotImplementedError()", "\n", "gather_outputs", "=", "[", "\n", "None", "for", "_", "in", "range", "(", "cfg", ".", "gpus", ")", "\n", "]", "# Only necessary for multigpu DDP", "\n", "outputs", "=", "model", ".", "predict", "(", "\n", "samples", "=", "samples", ",", "\n", "batch_size", "=", "cfg", ".", "batch_size", ",", "\n", "gpus", "=", "cfg", ".", "gpus", ",", "\n", "progress_bar", "=", "(", "not", "cfg", ".", "disable_bar", ")", ",", "\n", "accelerator", "=", "cfg", ".", "accelerator", ",", "\n", "num_workers", "=", "cfg", ".", "num_workers", ",", "\n", "length_batching", "=", "(", "not", "cfg", ".", "disable_length_batching", ")", ",", "\n", ")", "\n", "seg_scores", "=", "outputs", "[", "0", "]", "\n", "torch", ".", "distributed", ".", "all_gather_object", "(", "gather_outputs", ",", "seg_scores", ")", "\n", "torch", ".", "distributed", ".", "barrier", "(", ")", "# Waits for all processes", "\n", "if", "torch", ".", "distributed", ".", "get_rank", "(", ")", "==", "0", ":", "\n", "            ", "seg_scores", "=", "[", "\n", "o", "[", "i", "]", "for", "i", "in", "range", "(", "len", "(", "gather_outputs", "[", "0", "]", ")", ")", "for", "o", "in", "gather_outputs", "\n", "]", "\n", "", "else", ":", "\n", "# TODO: what should be return here?", "\n", "            ", "return", "0", "\n", "\n", "", "", "else", ":", "\n", "# This maximizes cache hits because batches will be equal!", "\n", "        ", "seg_scores", "=", "[", "]", "\n", "for", "system", "in", "systems", ":", "\n", "            ", "samples", "=", "[", "dict", "(", "zip", "(", "system", ",", "t", ")", ")", "for", "t", "in", "zip", "(", "*", "system", ".", "values", "(", ")", ")", "]", "\n", "system_scores", ",", "_", "=", "model", ".", "predict", "(", "\n", "samples", "=", "samples", ",", "\n", "batch_size", "=", "cfg", ".", "batch_size", ",", "\n", "gpus", "=", "cfg", ".", "gpus", ",", "\n", "progress_bar", "=", "(", "not", "cfg", ".", "disable_bar", ")", ",", "\n", "accelerator", "=", "cfg", ".", "accelerator", ",", "\n", "num_workers", "=", "cfg", ".", "num_workers", ",", "\n", "length_batching", "=", "(", "not", "cfg", ".", "disable_length_batching", ")", ",", "\n", ")", "\n", "seg_scores", "+=", "system_scores", "\n", "\n", "", "", "n", "=", "len", "(", "systems", "[", "0", "]", "[", "\"src\"", "]", ")", "\n", "# [grouper](https://docs.python.org/3/library/itertools.html#itertools-recipes)", "\n", "seg_scores", "=", "list", "(", "zip", "(", "*", "[", "iter", "(", "seg_scores", ")", "]", "*", "n", ")", ")", "\n", "seg_scores", "=", "np", ".", "array", "(", "seg_scores", ",", "dtype", "=", "\"float32\"", ")", "# num_systems x num_translations", "\n", "return", "seg_scores", "\n", "\n"]], "home.repos.pwc.inspect_result.Unbabel_COMET.cli.compare.get_cfg": [[281, 409], ["jsonargparse.ArgumentParser", "jsonargparse.ArgumentParser.add_argument", "jsonargparse.ArgumentParser.add_argument", "jsonargparse.ArgumentParser.add_argument", "jsonargparse.ArgumentParser.add_argument", "jsonargparse.ArgumentParser.add_argument", "jsonargparse.ArgumentParser.add_argument", "jsonargparse.ArgumentParser.add_argument", "jsonargparse.ArgumentParser.add_argument", "jsonargparse.ArgumentParser.add_argument", "jsonargparse.ArgumentParser.add_argument", "jsonargparse.ArgumentParser.add_argument", "jsonargparse.ArgumentParser.add_argument", "jsonargparse.ArgumentParser.add_argument", "jsonargparse.ArgumentParser.add_argument", "jsonargparse.ArgumentParser.add_argument", "jsonargparse.ArgumentParser.add_argument", "jsonargparse.ArgumentParser.add_argument", "jsonargparse.ArgumentParser.add_argument", "jsonargparse.ArgumentParser.add_argument", "jsonargparse.ArgumentParser.parse_args", "jsonargparse.ArgumentParser.error", "parser.parse_args.model.endswith", "os.path.exists", "jsonargparse.ArgumentParser.error", "parser.parse_args.sacrebleu_dataset.rsplit", "jsonargparse.typing.Path_fr", "jsonargparse.typing.Path_fr", "comet.download_utils.download_model", "jsonargparse.ArgumentParser.error", "sacrebleu.utils.get_source_file", "jsonargparse.ArgumentParser.error", "print", "sys.exit", "sacrebleu.utils.get_reference_files", "list", "comet.models.available_metrics.keys"], "function", ["home.repos.pwc.inspect_result.Unbabel_COMET.comet.download_utils.download_model"], ["", "def", "get_cfg", "(", ")", "->", "Namespace", ":", "\n", "    ", "\"\"\"\n    Parse the CLI options and arguments.\n    \"\"\"", "\n", "parser", "=", "ArgumentParser", "(", "\n", "description", "=", "\"Command for comparing multiple MT systems' translations.\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\"-s\"", ",", "\"--sources\"", ",", "type", "=", "Path_fr", ")", "\n", "parser", ".", "add_argument", "(", "\"-r\"", ",", "\"--references\"", ",", "type", "=", "Path_fr", ")", "\n", "parser", ".", "add_argument", "(", "\"-t\"", ",", "\"--translations\"", ",", "nargs", "=", "\"*\"", ",", "type", "=", "Path_fr", ")", "\n", "parser", ".", "add_argument", "(", "\"-d\"", ",", "\"--sacrebleu_dataset\"", ",", "type", "=", "str", ")", "\n", "parser", ".", "add_argument", "(", "\"--batch_size\"", ",", "type", "=", "int", ",", "default", "=", "8", ")", "\n", "parser", ".", "add_argument", "(", "\"--gpus\"", ",", "type", "=", "int", ",", "default", "=", "1", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--quiet\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "\"Prints only the final system score.\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--num_splits\"", ",", "\n", "type", "=", "int", ",", "\n", "default", "=", "300", ",", "\n", "help", "=", "\"Number of random partitions used in Bootstrap resampling.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--sample_ratio\"", ",", "\n", "type", "=", "float", ",", "\n", "default", "=", "0.4", ",", "\n", "help", "=", "\"Percentage of the testset to use in each split.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--accelerator\"", ",", "\n", "type", "=", "str", ",", "\n", "default", "=", "\"ddp\"", ",", "\n", "choices", "=", "[", "\"dp\"", ",", "\"ddp\"", "]", ",", "\n", "help", "=", "\"Pytorch Lightnining accelerator for multi-GPU.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--to_json\"", ",", "\n", "type", "=", "Union", "[", "bool", ",", "str", "]", ",", "\n", "default", "=", "False", ",", "\n", "help", "=", "\"Exports results to a json file.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--model\"", ",", "\n", "type", "=", "str", ",", "\n", "required", "=", "False", ",", "\n", "default", "=", "\"wmt20-comet-da\"", ",", "\n", "help", "=", "\"COMET model to be used.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--model_storage_path\"", ",", "\n", "help", "=", "(", "\n", "\"Path to the directory where models will be stored. \"", "\n", "+", "\"By default its saved in ~/.cache/torch/unbabel_comet/\"", "\n", ")", ",", "\n", "default", "=", "None", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--seed_everything\"", ",", "\n", "help", "=", "\"Prediction seed.\"", ",", "\n", "type", "=", "int", ",", "\n", "default", "=", "12", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--num_workers\"", ",", "\n", "help", "=", "\"Number of workers to use when loading data.\"", ",", "\n", "type", "=", "int", ",", "\n", "default", "=", "2", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--disable_bar\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "\"Disables progress bar.\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--disable_cache\"", ",", "\n", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"Disables sentence embeddings caching. This makes inference slower but saves memory.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--disable_length_batching\"", ",", "\n", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"Disables length batching. This makes inference slower.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--print_cache_info\"", ",", "\n", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"Print information about COMET cache.\"", ",", "\n", ")", "\n", "cfg", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "if", "cfg", ".", "sources", "is", "None", "and", "cfg", ".", "sacrebleu_dataset", "is", "None", ":", "\n", "        ", "parser", ".", "error", "(", "f\"You must specify a source (-s) or a sacrebleu dataset (-d)\"", ")", "\n", "\n", "", "if", "cfg", ".", "sacrebleu_dataset", "is", "not", "None", ":", "\n", "        ", "if", "cfg", ".", "references", "is", "not", "None", "or", "cfg", ".", "sources", "is", "not", "None", ":", "\n", "            ", "parser", ".", "error", "(", "\n", "f\"Cannot use sacrebleu datasets (-d) with manually-specified datasets (-s and -r)\"", "\n", ")", "\n", "\n", "", "try", ":", "\n", "            ", "testset", ",", "langpair", "=", "cfg", ".", "sacrebleu_dataset", ".", "rsplit", "(", "\":\"", ",", "maxsplit", "=", "1", ")", "\n", "cfg", ".", "sources", "=", "Path_fr", "(", "get_source_file", "(", "testset", ",", "langpair", ")", ")", "\n", "cfg", ".", "references", "=", "Path_fr", "(", "get_reference_files", "(", "testset", ",", "langpair", ")", "[", "0", "]", ")", "\n", "\n", "", "except", "ValueError", ":", "\n", "            ", "parser", ".", "error", "(", "\n", "\"SacreBLEU testset format must be TESTSET:LANGPAIR, e.g., wmt20:de-en\"", "\n", ")", "\n", "", "except", "Exception", "as", "e", ":", "\n", "            ", "import", "sys", "\n", "\n", "print", "(", "\"SacreBLEU error:\"", ",", "e", ",", "file", "=", "sys", ".", "stderr", ")", "\n", "sys", ".", "exit", "(", "1", ")", "\n", "\n", "", "", "if", "cfg", ".", "model", ".", "endswith", "(", "\".ckpt\"", ")", "and", "os", ".", "path", ".", "exists", "(", "cfg", ".", "model", ")", ":", "\n", "        ", "cfg", ".", "model_path", "=", "cfg", ".", "model", "\n", "\n", "", "elif", "cfg", ".", "model", "in", "available_metrics", ":", "\n", "        ", "cfg", ".", "model_path", "=", "download_model", "(", "\n", "cfg", ".", "model", ",", "saving_directory", "=", "cfg", ".", "model_storage_path", "\n", ")", "\n", "\n", "", "else", ":", "\n", "        ", "parser", ".", "error", "(", "\n", "\"{} is not a valid checkpoint path or model choice. Choose from {}\"", ".", "format", "(", "\n", "cfg", ".", "model", ",", "list", "(", "available_metrics", ".", "keys", "(", ")", ")", "\n", ")", "\n", ")", "\n", "\n", "", "return", "cfg", ",", "parser", "\n", "\n"]], "home.repos.pwc.inspect_result.Unbabel_COMET.cli.compare.compare_command": [[411, 500], ["compare.get_cfg", "pytorch_lightning.seed_everything", "comet.models.load_from_checkpoint", "comet.models.load_from_checkpoint.eval", "comet.models.load_from_checkpoint.is_referenceless", "compare.score", "compare.bootstrap_resampling", "list", "itertools.combinations", "print", "compare.t_tests_summary", "isinstance", "parser.error", "comet.models.load_from_checkpoint.set_embedding_cache", "print", "len", "open", "compare.pairwise_bootstrap", "zip", "scipy.stats.ttest_rel", "compare.display_statistical_results", "tuple", "print", "comet.models.load_from_checkpoint.is_referenceless", "comet.models.load_from_checkpoint.retrieve_sentence_embedding.cache_info", "cfg.sources", "line.strip", "open", "translations.append", "open", "max", "open", "json.dump", "fp.readlines", "cfg.references", "line.strip", "int", "scores.tolist", "zip", "line.strip", "fp.readlines", "fp.readlines"], "function", ["home.repos.pwc.inspect_result.Unbabel_COMET.cli.compare.get_cfg", "home.repos.pwc.inspect_result.Unbabel_COMET.models.__init__.load_from_checkpoint", "home.repos.pwc.inspect_result.Unbabel_COMET.regression.referenceless.ReferencelessRegression.is_referenceless", "home.repos.pwc.inspect_result.Unbabel_COMET.cli.compare.score", "home.repos.pwc.inspect_result.Unbabel_COMET.cli.compare.bootstrap_resampling", "home.repos.pwc.inspect_result.Unbabel_COMET.cli.compare.t_tests_summary", "home.repos.pwc.inspect_result.Unbabel_COMET.models.base.CometModel.set_embedding_cache", "home.repos.pwc.inspect_result.Unbabel_COMET.cli.compare.pairwise_bootstrap", "home.repos.pwc.inspect_result.Unbabel_COMET.cli.compare.display_statistical_results", "home.repos.pwc.inspect_result.Unbabel_COMET.regression.referenceless.ReferencelessRegression.is_referenceless"], ["", "def", "compare_command", "(", ")", "->", "None", ":", "\n", "    ", "\"\"\"\n    CLI that uses comet to compare multiple systems in a pairwise manner.\n    \"\"\"", "\n", "cfg", ",", "parser", "=", "get_cfg", "(", ")", "\n", "seed_everything", "(", "cfg", ".", "seed_everything", ")", "\n", "\n", "model", "=", "load_from_checkpoint", "(", "cfg", ".", "model_path", ")", "\n", "model", ".", "eval", "(", ")", "\n", "\n", "if", "(", "cfg", ".", "references", "is", "None", ")", "and", "(", "not", "model", ".", "is_referenceless", "(", ")", ")", ":", "\n", "        ", "parser", ".", "error", "(", "\n", "\"{} requires -r/--references or -d/--sacrebleu_dataset.\"", ".", "format", "(", "cfg", ".", "model", ")", "\n", ")", "\n", "\n", "", "if", "not", "cfg", ".", "disable_cache", ":", "\n", "        ", "model", ".", "set_embedding_cache", "(", ")", "\n", "\n", "", "if", "cfg", ".", "print_cache_info", ":", "\n", "        ", "print", "(", "model", ".", "retrieve_sentence_embedding", ".", "cache_info", "(", ")", ")", "\n", "\n", "", "assert", "len", "(", "cfg", ".", "translations", ")", ">", "1", ",", "\"You must provide at least 2 translation files\"", "\n", "\n", "with", "open", "(", "cfg", ".", "sources", "(", ")", ")", "as", "fp", ":", "\n", "        ", "sources", "=", "[", "line", ".", "strip", "(", ")", "for", "line", "in", "fp", ".", "readlines", "(", ")", "]", "\n", "\n", "", "translations", "=", "[", "]", "\n", "for", "system", "in", "cfg", ".", "translations", ":", "\n", "        ", "with", "open", "(", "system", ",", "mode", "=", "\"r\"", ",", "encoding", "=", "\"UTF-8\"", ")", "as", "fp", ":", "\n", "            ", "translations", ".", "append", "(", "[", "line", ".", "strip", "(", ")", "for", "line", "in", "fp", ".", "readlines", "(", ")", "]", ")", "\n", "\n", "", "", "references", "=", "None", "\n", "if", "model", ".", "is_referenceless", "(", ")", ":", "\n", "        ", "systems", "=", "[", "{", "\"src\"", ":", "sources", ",", "\"mt\"", ":", "system", "}", "for", "system", "in", "translations", "]", "\n", "", "else", ":", "\n", "        ", "with", "open", "(", "cfg", ".", "references", "(", ")", ")", "as", "fp", ":", "\n", "            ", "references", "=", "[", "line", ".", "strip", "(", ")", "for", "line", "in", "fp", ".", "readlines", "(", ")", "]", "\n", "", "systems", "=", "[", "\n", "{", "\"src\"", ":", "sources", ",", "\"mt\"", ":", "system", ",", "\"ref\"", ":", "references", "}", "for", "system", "in", "translations", "\n", "]", "\n", "\n", "", "seg_scores", "=", "score", "(", "cfg", ",", "systems", ")", "\n", "\n", "population_size", "=", "seg_scores", ".", "shape", "[", "1", "]", "\n", "sys_scores", "=", "bootstrap_resampling", "(", "\n", "seg_scores", ",", "\n", "sample_size", "=", "max", "(", "int", "(", "population_size", "*", "cfg", ".", "sample_ratio", ")", ",", "1", ")", ",", "\n", "num_splits", "=", "cfg", ".", "num_splits", ",", "\n", ")", "\n", "results", "=", "list", "(", "pairwise_bootstrap", "(", "sys_scores", ",", "cfg", ".", "translations", ")", ")", "\n", "\n", "# Paired T_Test Results:", "\n", "pairs", "=", "combinations", "(", "zip", "(", "cfg", ".", "translations", ",", "seg_scores", ")", ",", "2", ")", "\n", "for", "(", "x_name", ",", "x_seg_scores", ")", ",", "(", "y_name", ",", "y_seg_scores", ")", "in", "pairs", ":", "\n", "        ", "ttest_result", "=", "stats", ".", "ttest_rel", "(", "x_seg_scores", ",", "y_seg_scores", ")", "\n", "for", "res", "in", "results", ":", "\n", "            ", "if", "res", "[", "\"x_name\"", "]", "==", "x_name", "and", "res", "[", "\"y_name\"", "]", "==", "y_name", ":", "\n", "                ", "res", "[", "\"paired_t-test\"", "]", "=", "{", "\n", "\"statistic\"", ":", "ttest_result", ".", "statistic", ",", "\n", "\"p_value\"", ":", "ttest_result", ".", "pvalue", ",", "\n", "}", "\n", "\n", "", "", "", "info", "=", "{", "\n", "\"model\"", ":", "cfg", ".", "model", ",", "\n", "\"statistical_results\"", ":", "results", ",", "\n", "\"source\"", ":", "sources", ",", "\n", "\"translations\"", ":", "[", "\n", "{", "\n", "\"name\"", ":", "name", ",", "\n", "\"mt\"", ":", "trans", ",", "\n", "\"scores\"", ":", "scores", ".", "tolist", "(", ")", ",", "\n", "}", "\n", "for", "name", ",", "trans", ",", "scores", "in", "zip", "(", "cfg", ".", "translations", ",", "translations", ",", "seg_scores", ")", "\n", "]", ",", "\n", "}", "\n", "\n", "if", "references", "is", "not", "None", ":", "\n", "        ", "info", "[", "\"reference\"", "]", "=", "references", "\n", "\n", "", "for", "data", "in", "results", ":", "\n", "        ", "display_statistical_results", "(", "data", ")", "\n", "\n", "", "print", "(", ")", "\n", "t_tests_summary", "(", "results", ",", "tuple", "(", "cfg", ".", "translations", ")", ")", "\n", "\n", "if", "isinstance", "(", "cfg", ".", "to_json", ",", "str", ")", ":", "\n", "        ", "with", "open", "(", "cfg", ".", "to_json", ",", "\"w\"", ")", "as", "outfile", ":", "\n", "            ", "json", ".", "dump", "(", "info", ",", "outfile", ",", "ensure_ascii", "=", "False", ",", "indent", "=", "4", ")", "\n", "", "print", "(", "\"Predictions saved in: {}.\"", ".", "format", "(", "cfg", ".", "to_json", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Unbabel_COMET.cli.score.score_command": [[67, 324], ["jsonargparse.ArgumentParser", "jsonargparse.ArgumentParser.add_argument", "jsonargparse.ArgumentParser.add_argument", "jsonargparse.ArgumentParser.add_argument", "jsonargparse.ArgumentParser.add_argument", "jsonargparse.ArgumentParser.add_argument", "jsonargparse.ArgumentParser.add_argument", "jsonargparse.ArgumentParser.add_argument", "jsonargparse.ArgumentParser.add_argument", "jsonargparse.ArgumentParser.add_argument", "jsonargparse.ArgumentParser.add_argument", "jsonargparse.ArgumentParser.add_argument", "jsonargparse.ArgumentParser.add_argument", "jsonargparse.ArgumentParser.add_argument", "jsonargparse.ArgumentParser.add_argument", "jsonargparse.ArgumentParser.add_argument", "jsonargparse.ArgumentParser.add_argument", "jsonargparse.ArgumentParser.add_argument", "jsonargparse.ArgumentParser.add_argument", "jsonargparse.ArgumentParser.parse_args", "pytorch_lightning.seed_everything", "comet.models.load_from_checkpoint", "comet.models.load_from_checkpoint.eval", "comet.models.load_from_checkpoint.is_referenceless", "range", "range", "isinstance", "jsonargparse.ArgumentParser.error", "parser.parse_args.model.endswith", "os.path.exists", "jsonargparse.ArgumentParser.error", "comet.models.load_from_checkpoint.set_embedding_cache", "open", "np.array_split.items", "comet.models.load_from_checkpoint.predict", "torch.distributed.all_gather_object", "torch.distributed.barrier", "range", "system_data.tolist", "len", "range", "len", "print", "print", "print", "jsonargparse.ArgumentParser.error", "parser.parse_args.sacrebleu_dataset.rsplit", "jsonargparse.typing.Path_fr", "jsonargparse.typing.Path_fr", "comet.download_utils.download_model", "jsonargparse.ArgumentParser.error", "comet.models.load_from_checkpoint.is_referenceless", "parser.parse_args.sources", "line.strip", "open", "translations.append", "open", "list", "dict", "len", "torch.distributed.all_gather_object", "torch.distributed.get_rank", "list", "len", "numpy.array_split", "numpy.array_split", "len", "new_data.append", "comet.models.load_from_checkpoint.predict", "sys_scores.append", "zip", "len", "open", "json.dump", "comet.models.load_from_checkpoint.retrieve_sentence_embedding.cache_info", "sacrebleu.utils.get_source_file", "jsonargparse.ArgumentParser.error", "print", "sys.exit", "fp.readlines", "path_fr", "parser.parse_args.references", "line.strip", "itertools.chain", "zip", "zip", "range", "range", "len", "itertools.chain", "len", "list", "len", "numpy.array_split", "len", "numpy.array", "dict", "numpy.array", "len", "np.array_split.append", "list.append", "np.array_split.append", "list.append", "sacrebleu.utils.get_reference_files", "comet.models.available_metrics.keys", "line.strip", "fp.readlines", "itertools.chain", "sum", "len", "len", "len", "sum", "len", "np.array_split.items", "zip", "zip", "sum", "len", "print", "print", "fp.readlines", "np.array_split.values", "sys_data.values"], "function", ["home.repos.pwc.inspect_result.Unbabel_COMET.models.__init__.load_from_checkpoint", "home.repos.pwc.inspect_result.Unbabel_COMET.regression.referenceless.ReferencelessRegression.is_referenceless", "home.repos.pwc.inspect_result.Unbabel_COMET.models.base.CometModel.set_embedding_cache", "home.repos.pwc.inspect_result.Unbabel_COMET.models.base.CometModel.predict", "home.repos.pwc.inspect_result.Unbabel_COMET.comet.download_utils.download_model", "home.repos.pwc.inspect_result.Unbabel_COMET.regression.referenceless.ReferencelessRegression.is_referenceless", "home.repos.pwc.inspect_result.Unbabel_COMET.models.base.CometModel.predict"], ["def", "score_command", "(", ")", "->", "None", ":", "\n", "    ", "parser", "=", "ArgumentParser", "(", "description", "=", "\"Command for scoring MT systems.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"-s\"", ",", "\"--sources\"", ",", "type", "=", "Path_fr", ")", "\n", "parser", ".", "add_argument", "(", "\"-t\"", ",", "\"--translations\"", ",", "type", "=", "Path_fr", ",", "nargs", "=", "\"+\"", ")", "\n", "parser", ".", "add_argument", "(", "\"-r\"", ",", "\"--references\"", ",", "type", "=", "Path_fr", ")", "\n", "parser", ".", "add_argument", "(", "\"-d\"", ",", "\"--sacrebleu_dataset\"", ",", "type", "=", "str", ")", "\n", "parser", ".", "add_argument", "(", "\"--batch_size\"", ",", "type", "=", "int", ",", "default", "=", "8", ")", "\n", "parser", ".", "add_argument", "(", "\"--gpus\"", ",", "type", "=", "int", ",", "default", "=", "1", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--quiet\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "\"Prints only the final system score.\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--accelerator\"", ",", "\n", "type", "=", "str", ",", "\n", "default", "=", "\"ddp\"", ",", "\n", "choices", "=", "[", "\"dp\"", ",", "\"ddp\"", "]", ",", "\n", "help", "=", "\"Pytorch Lightnining accelerator for multi-GPU.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--to_json\"", ",", "\n", "type", "=", "Union", "[", "bool", ",", "str", "]", ",", "\n", "default", "=", "False", ",", "\n", "help", "=", "\"Exports results to a json file.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--model\"", ",", "\n", "type", "=", "str", ",", "\n", "required", "=", "False", ",", "\n", "default", "=", "\"wmt20-comet-da\"", ",", "\n", "help", "=", "\"COMET model to be used.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--model_storage_path\"", ",", "\n", "help", "=", "(", "\n", "\"Path to the directory where models will be stored. \"", "\n", "+", "\"By default its saved in ~/.cache/torch/unbabel_comet/\"", "\n", ")", ",", "\n", "default", "=", "None", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--mc_dropout\"", ",", "\n", "type", "=", "Union", "[", "bool", ",", "int", "]", ",", "\n", "default", "=", "False", ",", "\n", "help", "=", "\"Number of inference runs for each sample in MC Dropout.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--seed_everything\"", ",", "\n", "help", "=", "\"Prediction seed.\"", ",", "\n", "type", "=", "int", ",", "\n", "default", "=", "12", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--num_workers\"", ",", "\n", "help", "=", "\"Number of workers to use when loading data.\"", ",", "\n", "type", "=", "int", ",", "\n", "default", "=", "2", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--disable_bar\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "\"Disables progress bar.\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--disable_cache\"", ",", "\n", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"Disables sentence embeddings caching. This makes inference slower but saves memory.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--disable_length_batching\"", ",", "\n", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"Disables length batching. This makes inference slower.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--print_cache_info\"", ",", "\n", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"Print information about COMET cache.\"", ",", "\n", ")", "\n", "cfg", "=", "parser", ".", "parse_args", "(", ")", "\n", "seed_everything", "(", "cfg", ".", "seed_everything", ")", "\n", "if", "cfg", ".", "sources", "is", "None", "and", "cfg", ".", "sacrebleu_dataset", "is", "None", ":", "\n", "        ", "parser", ".", "error", "(", "f\"You must specify a source (-s) or a sacrebleu dataset (-d)\"", ")", "\n", "\n", "", "if", "cfg", ".", "sacrebleu_dataset", "is", "not", "None", ":", "\n", "        ", "if", "cfg", ".", "references", "is", "not", "None", "or", "cfg", ".", "sources", "is", "not", "None", ":", "\n", "            ", "parser", ".", "error", "(", "\n", "f\"Cannot use sacrebleu datasets (-d) with manually-specified datasets (-s and -r)\"", "\n", ")", "\n", "\n", "", "try", ":", "\n", "            ", "testset", ",", "langpair", "=", "cfg", ".", "sacrebleu_dataset", ".", "rsplit", "(", "\":\"", ",", "maxsplit", "=", "1", ")", "\n", "cfg", ".", "sources", "=", "Path_fr", "(", "get_source_file", "(", "testset", ",", "langpair", ")", ")", "\n", "cfg", ".", "references", "=", "Path_fr", "(", "get_reference_files", "(", "testset", ",", "langpair", ")", "[", "0", "]", ")", "\n", "", "except", "ValueError", ":", "\n", "            ", "parser", ".", "error", "(", "\n", "\"SacreBLEU testset format must be TESTSET:LANGPAIR, e.g., wmt20:de-en\"", "\n", ")", "\n", "", "except", "Exception", "as", "e", ":", "\n", "            ", "import", "sys", "\n", "\n", "print", "(", "\"SacreBLEU error:\"", ",", "e", ",", "file", "=", "sys", ".", "stderr", ")", "\n", "sys", ".", "exit", "(", "1", ")", "\n", "\n", "", "", "if", "cfg", ".", "model", ".", "endswith", "(", "\".ckpt\"", ")", "and", "os", ".", "path", ".", "exists", "(", "cfg", ".", "model", ")", ":", "\n", "        ", "model_path", "=", "cfg", ".", "model", "\n", "", "elif", "cfg", ".", "model", "in", "available_metrics", ":", "\n", "        ", "model_path", "=", "download_model", "(", "cfg", ".", "model", ",", "saving_directory", "=", "cfg", ".", "model_storage_path", ")", "\n", "", "else", ":", "\n", "        ", "parser", ".", "error", "(", "\n", "\"{} is not a valid checkpoint path or model choice. Choose from {}\"", ".", "format", "(", "\n", "cfg", ".", "model", ",", "available_metrics", ".", "keys", "(", ")", "\n", ")", "\n", ")", "\n", "", "model", "=", "load_from_checkpoint", "(", "model_path", ")", "\n", "model", ".", "eval", "(", ")", "\n", "\n", "if", "(", "cfg", ".", "references", "is", "None", ")", "and", "(", "not", "model", ".", "is_referenceless", "(", ")", ")", ":", "\n", "        ", "parser", ".", "error", "(", "\n", "\"{} requires -r/--references or -d/--sacrebleu_dataset.\"", ".", "format", "(", "cfg", ".", "model", ")", "\n", ")", "\n", "\n", "", "if", "not", "cfg", ".", "disable_cache", ":", "\n", "        ", "model", ".", "set_embedding_cache", "(", ")", "\n", "\n", "", "with", "open", "(", "cfg", ".", "sources", "(", ")", ",", "encoding", "=", "\"utf-8\"", ")", "as", "fp", ":", "\n", "        ", "sources", "=", "[", "line", ".", "strip", "(", ")", "for", "line", "in", "fp", ".", "readlines", "(", ")", "]", "\n", "\n", "", "translations", "=", "[", "]", "\n", "for", "path_fr", "in", "cfg", ".", "translations", ":", "\n", "        ", "with", "open", "(", "path_fr", "(", ")", ",", "encoding", "=", "\"utf-8\"", ")", "as", "fp", ":", "\n", "            ", "translations", ".", "append", "(", "[", "line", ".", "strip", "(", ")", "for", "line", "in", "fp", ".", "readlines", "(", ")", "]", ")", "\n", "\n", "", "", "if", "model", ".", "is_referenceless", "(", ")", ":", "\n", "        ", "data", "=", "{", "\"src\"", ":", "[", "sources", "for", "_", "in", "translations", "]", ",", "\"mt\"", ":", "translations", "}", "\n", "", "else", ":", "\n", "        ", "with", "open", "(", "cfg", ".", "references", "(", ")", ",", "encoding", "=", "\"utf-8\"", ")", "as", "fp", ":", "\n", "            ", "references", "=", "[", "line", ".", "strip", "(", ")", "for", "line", "in", "fp", ".", "readlines", "(", ")", "]", "\n", "", "data", "=", "{", "\n", "\"src\"", ":", "[", "sources", "for", "_", "in", "translations", "]", ",", "\n", "\"mt\"", ":", "translations", ",", "\n", "\"ref\"", ":", "[", "references", "for", "_", "in", "translations", "]", ",", "\n", "}", "\n", "\n", "", "if", "cfg", ".", "gpus", ">", "1", "and", "cfg", ".", "accelerator", "==", "\"ddp\"", ":", "\n", "# Flatten all data to score across multiple GPUs", "\n", "        ", "for", "k", ",", "v", "in", "data", ".", "items", "(", ")", ":", "\n", "            ", "data", "[", "k", "]", "=", "list", "(", "itertools", ".", "chain", "(", "*", "v", ")", ")", "\n", "", "data", "=", "[", "dict", "(", "zip", "(", "data", ",", "t", ")", ")", "for", "t", "in", "zip", "(", "*", "data", ".", "values", "(", ")", ")", "]", "\n", "\n", "gather_mean", "=", "[", "None", "for", "_", "in", "range", "(", "cfg", ".", "gpus", ")", "]", "# Only necessary for multigpu DDP", "\n", "gather_std", "=", "[", "None", "for", "_", "in", "range", "(", "cfg", ".", "gpus", ")", "]", "# Only necessary for multigpu DDP", "\n", "outputs", "=", "model", ".", "predict", "(", "\n", "samples", "=", "data", ",", "\n", "batch_size", "=", "cfg", ".", "batch_size", ",", "\n", "gpus", "=", "cfg", ".", "gpus", ",", "\n", "mc_dropout", "=", "cfg", ".", "mc_dropout", ",", "\n", "progress_bar", "=", "(", "not", "cfg", ".", "disable_bar", ")", ",", "\n", "accelerator", "=", "cfg", ".", "accelerator", ",", "\n", "num_workers", "=", "cfg", ".", "num_workers", ",", "\n", "length_batching", "=", "(", "not", "cfg", ".", "disable_length_batching", ")", ",", "\n", ")", "\n", "seg_scores", "=", "outputs", "[", "0", "]", "\n", "std_scores", "=", "None", "if", "len", "(", "outputs", ")", "==", "2", "else", "outputs", "[", "1", "]", "\n", "torch", ".", "distributed", ".", "all_gather_object", "(", "gather_mean", ",", "outputs", "[", "0", "]", ")", "\n", "if", "len", "(", "outputs", ")", "==", "3", ":", "\n", "            ", "torch", ".", "distributed", ".", "all_gather_object", "(", "gather_std", ",", "outputs", "[", "1", "]", ")", "\n", "\n", "", "torch", ".", "distributed", ".", "barrier", "(", ")", "# Waits for all processes", "\n", "if", "torch", ".", "distributed", ".", "get_rank", "(", ")", "==", "0", ":", "\n", "            ", "seg_scores", "=", "list", "(", "itertools", ".", "chain", "(", "*", "gather_mean", ")", ")", "\n", "if", "len", "(", "outputs", ")", "==", "3", ":", "\n", "                ", "std_scores", "=", "list", "(", "itertools", ".", "chain", "(", "*", "gather_std", ")", ")", "\n", "", "else", ":", "\n", "                ", "std_scores", "=", "None", "\n", "", "", "else", ":", "\n", "            ", "return", "\n", "\n", "", "if", "len", "(", "cfg", ".", "translations", ")", ">", "1", ":", "\n", "            ", "seg_scores", "=", "np", ".", "array_split", "(", "seg_scores", ",", "len", "(", "cfg", ".", "translations", ")", ")", "\n", "sys_scores", "=", "[", "sum", "(", "split", ")", "/", "len", "(", "split", ")", "for", "split", "in", "seg_scores", "]", "\n", "std_scores", "=", "(", "\n", "np", ".", "array_split", "(", "std_scores", ",", "len", "(", "cfg", ".", "translations", ")", ")", "\n", "if", "std_scores", "\n", "else", "[", "None", "]", "*", "len", "(", "seg_scores", ")", "\n", ")", "\n", "data", "=", "np", ".", "array_split", "(", "data", ",", "len", "(", "cfg", ".", "translations", ")", ")", "\n", "", "else", ":", "\n", "            ", "sys_scores", "=", "[", "\n", "sum", "(", "seg_scores", ")", "/", "len", "(", "seg_scores", ")", ",", "\n", "]", "\n", "seg_scores", "=", "[", "\n", "seg_scores", ",", "\n", "]", "\n", "data", "=", "[", "\n", "np", ".", "array", "(", "data", ")", ",", "\n", "]", "\n", "std_scores", "=", "[", "\n", "std_scores", ",", "\n", "]", "\n", "", "", "else", ":", "\n", "# If not using Multiple GPUs we will score each system independently", "\n", "# to maximize cache hits!", "\n", "        ", "seg_scores", ",", "std_scores", ",", "sys_scores", "=", "[", "]", ",", "[", "]", ",", "[", "]", "\n", "new_data", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "cfg", ".", "translations", ")", ")", ":", "\n", "            ", "sys_data", "=", "{", "k", ":", "v", "[", "i", "]", "for", "k", ",", "v", "in", "data", ".", "items", "(", ")", "}", "\n", "sys_data", "=", "[", "dict", "(", "zip", "(", "sys_data", ",", "t", ")", ")", "for", "t", "in", "zip", "(", "*", "sys_data", ".", "values", "(", ")", ")", "]", "\n", "new_data", ".", "append", "(", "np", ".", "array", "(", "sys_data", ")", ")", "\n", "outputs", "=", "model", ".", "predict", "(", "\n", "samples", "=", "sys_data", ",", "\n", "batch_size", "=", "cfg", ".", "batch_size", ",", "\n", "gpus", "=", "cfg", ".", "gpus", ",", "\n", "mc_dropout", "=", "cfg", ".", "mc_dropout", ",", "\n", "progress_bar", "=", "(", "not", "cfg", ".", "disable_bar", ")", ",", "\n", "accelerator", "=", "cfg", ".", "accelerator", ",", "\n", "num_workers", "=", "cfg", ".", "num_workers", ",", "\n", "length_batching", "=", "(", "not", "cfg", ".", "disable_length_batching", ")", ",", "\n", ")", "\n", "if", "len", "(", "outputs", ")", "==", "3", ":", "\n", "                ", "seg_scores", ".", "append", "(", "outputs", "[", "0", "]", ")", "\n", "std_scores", ".", "append", "(", "outputs", "[", "1", "]", ")", "\n", "", "else", ":", "\n", "                ", "seg_scores", ".", "append", "(", "outputs", "[", "0", "]", ")", "\n", "std_scores", ".", "append", "(", "None", ")", "\n", "\n", "", "sys_scores", ".", "append", "(", "sum", "(", "outputs", "[", "0", "]", ")", "/", "len", "(", "outputs", "[", "0", "]", ")", ")", "\n", "", "data", "=", "new_data", "\n", "\n", "", "files", "=", "[", "path_fr", ".", "rel_path", "for", "path_fr", "in", "cfg", ".", "translations", "]", "\n", "data", "=", "{", "file", ":", "system_data", ".", "tolist", "(", ")", "for", "file", ",", "system_data", "in", "zip", "(", "files", ",", "data", ")", "}", "\n", "\n", "for", "i", "in", "range", "(", "len", "(", "data", "[", "files", "[", "0", "]", "]", ")", ")", ":", "# loop over (src, ref)", "\n", "        ", "for", "j", "in", "range", "(", "len", "(", "files", ")", ")", ":", "# loop of system", "\n", "            ", "data", "[", "files", "[", "j", "]", "]", "[", "i", "]", "[", "\"COMET\"", "]", "=", "seg_scores", "[", "j", "]", "[", "i", "]", "\n", "if", "cfg", ".", "mc_dropout", ":", "\n", "                ", "data", "[", "files", "[", "j", "]", "]", "[", "i", "]", "[", "\"variance\"", "]", "=", "std_scores", "[", "j", "]", "[", "i", "]", "\n", "if", "not", "cfg", ".", "quiet", ":", "\n", "                    ", "print", "(", "\n", "\"{}\\tSegment {}\\tscore: {:.4f}\\tvariance: {:.4f}\"", ".", "format", "(", "\n", "files", "[", "j", "]", ",", "i", ",", "seg_scores", "[", "j", "]", "[", "i", "]", ",", "std_scores", "[", "j", "]", "[", "i", "]", "\n", ")", "\n", ")", "\n", "", "", "else", ":", "\n", "                ", "if", "not", "cfg", ".", "quiet", ":", "\n", "                    ", "print", "(", "\n", "\"{}\\tSegment {}\\tscore: {:.4f}\"", ".", "format", "(", "\n", "files", "[", "j", "]", ",", "i", ",", "seg_scores", "[", "j", "]", "[", "i", "]", "\n", ")", "\n", ")", "\n", "\n", "", "", "", "", "for", "j", "in", "range", "(", "len", "(", "files", ")", ")", ":", "\n", "        ", "print", "(", "\"{}\\tscore: {:.4f}\"", ".", "format", "(", "files", "[", "j", "]", ",", "sys_scores", "[", "j", "]", ")", ")", "\n", "\n", "", "if", "isinstance", "(", "cfg", ".", "to_json", ",", "str", ")", ":", "\n", "        ", "with", "open", "(", "cfg", ".", "to_json", ",", "\"w\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "outfile", ":", "\n", "            ", "json", ".", "dump", "(", "data", ",", "outfile", ",", "ensure_ascii", "=", "False", ",", "indent", "=", "4", ")", "\n", "", "print", "(", "\"Predictions saved in: {}.\"", ".", "format", "(", "cfg", ".", "to_json", ")", ")", "\n", "\n", "", "if", "cfg", ".", "print_cache_info", ":", "\n", "        ", "print", "(", "model", ".", "retrieve_sentence_embedding", ".", "cache_info", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Unbabel_COMET.ranking.ranking_metric.RankingMetric.__init__": [[55, 92], ["comet.models.base.CometModel.__init__", "ranking_metric.RankingMetric.save_hyperparameters"], "methods", ["home.repos.pwc.inspect_result.Unbabel_COMET.regression.referenceless.ReferencelessRegression.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "nr_frozen_epochs", ":", "Union", "[", "float", ",", "int", "]", "=", "0.05", ",", "\n", "keep_embeddings_frozen", ":", "bool", "=", "False", ",", "\n", "optimizer", ":", "str", "=", "\"AdamW\"", ",", "\n", "encoder_learning_rate", ":", "float", "=", "1e-05", ",", "\n", "learning_rate", ":", "float", "=", "3e-05", ",", "\n", "layerwise_decay", ":", "float", "=", "0.95", ",", "\n", "encoder_model", ":", "str", "=", "\"XLM-RoBERTa\"", ",", "\n", "pretrained_model", ":", "str", "=", "\"xlm-roberta-base\"", ",", "\n", "pool", ":", "str", "=", "\"avg\"", ",", "\n", "layer", ":", "Union", "[", "str", ",", "int", "]", "=", "\"mix\"", ",", "\n", "dropout", ":", "float", "=", "0.1", ",", "\n", "batch_size", ":", "int", "=", "8", ",", "\n", "train_data", ":", "Optional", "[", "str", "]", "=", "None", ",", "\n", "validation_data", ":", "Optional", "[", "str", "]", "=", "None", ",", "\n", "load_weights_from_checkpoint", ":", "Optional", "[", "str", "]", "=", "None", ",", "\n", ")", "->", "None", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "\n", "nr_frozen_epochs", ",", "\n", "keep_embeddings_frozen", ",", "\n", "optimizer", ",", "\n", "encoder_learning_rate", ",", "\n", "learning_rate", ",", "\n", "layerwise_decay", ",", "\n", "encoder_model", ",", "\n", "pretrained_model", ",", "\n", "pool", ",", "\n", "layer", ",", "\n", "dropout", ",", "\n", "batch_size", ",", "\n", "train_data", ",", "\n", "validation_data", ",", "\n", "load_weights_from_checkpoint", ",", "\n", "\"ranking_metric\"", ",", "\n", ")", "\n", "self", ".", "save_hyperparameters", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Unbabel_COMET.ranking.ranking_metric.RankingMetric.init_metrics": [[93, 96], ["comet.models.metrics.WMTKendall", "comet.models.metrics.WMTKendall"], "methods", ["None"], ["", "def", "init_metrics", "(", "self", ")", ":", "\n", "        ", "self", ".", "train_metrics", "=", "WMTKendall", "(", "prefix", "=", "\"train\"", ")", "\n", "self", ".", "val_metrics", "=", "WMTKendall", "(", "prefix", "=", "\"val\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Unbabel_COMET.ranking.ranking_metric.RankingMetric.is_referenceless": [[97, 99], ["None"], "methods", ["None"], ["", "def", "is_referenceless", "(", "self", ")", "->", "bool", ":", "\n", "        ", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.Unbabel_COMET.ranking.ranking_metric.RankingMetric.loss": [[100, 103], ["torch.nn.TripletMarginLoss", "torch.nn.TripletMarginLoss", "torch.nn.TripletMarginLoss", "torch.nn.TripletMarginLoss"], "methods", ["None"], ["", "@", "property", "\n", "def", "loss", "(", "self", ")", ":", "\n", "        ", "return", "torch", ".", "nn", ".", "TripletMarginLoss", "(", "margin", "=", "1.0", ",", "p", "=", "2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Unbabel_COMET.ranking.ranking_metric.RankingMetric.configure_optimizers": [[104, 133], ["ranking_metric.RankingMetric.encoder.layerwise_lr", "transformers.optimization.Adafactor", "torch.optim.AdamW", "torch.optim.AdamW", "torch.optim.AdamW", "torch.optim.AdamW", "ranking_metric.RankingMetric.layerwise_attention.parameters"], "methods", ["home.repos.pwc.inspect_result.Unbabel_COMET.encoders.bert.BERTEncoder.layerwise_lr"], ["", "def", "configure_optimizers", "(", "\n", "self", ",", "\n", ")", "->", "Tuple", "[", "List", "[", "torch", ".", "optim", ".", "Optimizer", "]", ",", "List", "[", "torch", ".", "optim", ".", "lr_scheduler", ".", "LambdaLR", "]", "]", ":", "\n", "        ", "\"\"\"Sets the optimizers to be used during training.\"\"\"", "\n", "layer_parameters", "=", "self", ".", "encoder", ".", "layerwise_lr", "(", "\n", "self", ".", "hparams", ".", "encoder_learning_rate", ",", "self", ".", "hparams", ".", "layerwise_decay", "\n", ")", "\n", "if", "self", ".", "layerwise_attention", ":", "\n", "            ", "layerwise_attn_params", "=", "[", "\n", "{", "\n", "\"params\"", ":", "self", ".", "layerwise_attention", ".", "parameters", "(", ")", ",", "\n", "\"lr\"", ":", "self", ".", "hparams", ".", "learning_rate", ",", "\n", "}", "\n", "]", "\n", "params", "=", "layer_parameters", "+", "layerwise_attn_params", "\n", "", "else", ":", "\n", "            ", "params", "=", "layer_parameters", "\n", "\n", "", "if", "self", ".", "hparams", ".", "optimizer", "==", "\"Adafactor\"", ":", "\n", "            ", "optimizer", "=", "Adafactor", "(", "\n", "params", ",", "\n", "lr", "=", "self", ".", "hparams", ".", "learning_rate", ",", "\n", "relative_step", "=", "False", ",", "\n", "scale_parameter", "=", "False", ",", "\n", ")", "\n", "", "else", ":", "\n", "            ", "optimizer", "=", "torch", ".", "optim", ".", "AdamW", "(", "params", ",", "lr", "=", "self", ".", "hparams", ".", "learning_rate", ")", "\n", "# scheduler = self._build_scheduler(optimizer)", "\n", "", "return", "[", "optimizer", "]", ",", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.Unbabel_COMET.ranking.ranking_metric.RankingMetric.prepare_sample": [[134, 162], ["ranking_metric.RankingMetric.encoder.prepare_sample", "ranking_metric.RankingMetric.encoder.prepare_sample", "ranking_metric.RankingMetric.encoder.prepare_sample", "ranking_metric.RankingMetric.encoder.prepare_sample", "ranking_metric.RankingMetric.encoder.prepare_sample", "ranking_metric.RankingMetric.encoder.prepare_sample", "ranking_metric.RankingMetric.encoder.prepare_sample", "ranking_metric.RankingMetric.items", "ranking_metric.RankingMetric.items", "ranking_metric.RankingMetric.items", "ranking_metric.RankingMetric.items", "ranking_metric.RankingMetric.items", "ranking_metric.RankingMetric.items", "ranking_metric.RankingMetric.items"], "methods", ["home.repos.pwc.inspect_result.Unbabel_COMET.regression.referenceless.ReferencelessRegression.prepare_sample", "home.repos.pwc.inspect_result.Unbabel_COMET.regression.referenceless.ReferencelessRegression.prepare_sample", "home.repos.pwc.inspect_result.Unbabel_COMET.regression.referenceless.ReferencelessRegression.prepare_sample", "home.repos.pwc.inspect_result.Unbabel_COMET.regression.referenceless.ReferencelessRegression.prepare_sample", "home.repos.pwc.inspect_result.Unbabel_COMET.regression.referenceless.ReferencelessRegression.prepare_sample", "home.repos.pwc.inspect_result.Unbabel_COMET.regression.referenceless.ReferencelessRegression.prepare_sample", "home.repos.pwc.inspect_result.Unbabel_COMET.regression.referenceless.ReferencelessRegression.prepare_sample"], ["", "def", "prepare_sample", "(", "\n", "self", ",", "sample", ":", "List", "[", "Dict", "[", "str", ",", "Union", "[", "str", ",", "float", "]", "]", "]", ",", "inference", ":", "bool", "=", "False", "\n", ")", "->", "Dict", "[", "str", ",", "torch", ".", "Tensor", "]", ":", "\n", "\n", "        ", "sample", "=", "{", "k", ":", "[", "dic", "[", "k", "]", "for", "dic", "in", "sample", "]", "for", "k", "in", "sample", "[", "0", "]", "}", "\n", "\n", "if", "inference", ":", "\n", "            ", "src_inputs", "=", "self", ".", "encoder", ".", "prepare_sample", "(", "sample", "[", "\"src\"", "]", ")", "\n", "mt_inputs", "=", "self", ".", "encoder", ".", "prepare_sample", "(", "sample", "[", "\"mt\"", "]", ")", "\n", "ref_inputs", "=", "self", ".", "encoder", ".", "prepare_sample", "(", "sample", "[", "\"ref\"", "]", ")", "\n", "\n", "ref_inputs", "=", "{", "\"ref_\"", "+", "k", ":", "v", "for", "k", ",", "v", "in", "ref_inputs", ".", "items", "(", ")", "}", "\n", "src_inputs", "=", "{", "\"src_\"", "+", "k", ":", "v", "for", "k", ",", "v", "in", "src_inputs", ".", "items", "(", ")", "}", "\n", "mt_inputs", "=", "{", "\"mt_\"", "+", "k", ":", "v", "for", "k", ",", "v", "in", "mt_inputs", ".", "items", "(", ")", "}", "\n", "\n", "return", "{", "**", "ref_inputs", ",", "**", "src_inputs", ",", "**", "mt_inputs", "}", "\n", "\n", "", "ref_inputs", "=", "self", ".", "encoder", ".", "prepare_sample", "(", "sample", "[", "\"ref\"", "]", ")", "\n", "src_inputs", "=", "self", ".", "encoder", ".", "prepare_sample", "(", "sample", "[", "\"src\"", "]", ")", "\n", "pos_inputs", "=", "self", ".", "encoder", ".", "prepare_sample", "(", "sample", "[", "\"pos\"", "]", ")", "\n", "neg_inputs", "=", "self", ".", "encoder", ".", "prepare_sample", "(", "sample", "[", "\"neg\"", "]", ")", "\n", "\n", "ref_inputs", "=", "{", "\"ref_\"", "+", "k", ":", "v", "for", "k", ",", "v", "in", "ref_inputs", ".", "items", "(", ")", "}", "\n", "src_inputs", "=", "{", "\"src_\"", "+", "k", ":", "v", "for", "k", ",", "v", "in", "src_inputs", ".", "items", "(", ")", "}", "\n", "pos_inputs", "=", "{", "\"pos_\"", "+", "k", ":", "v", "for", "k", ",", "v", "in", "pos_inputs", ".", "items", "(", ")", "}", "\n", "neg_inputs", "=", "{", "\"neg_\"", "+", "k", ":", "v", "for", "k", ",", "v", "in", "neg_inputs", ".", "items", "(", ")", "}", "\n", "\n", "return", "{", "**", "ref_inputs", ",", "**", "src_inputs", ",", "**", "pos_inputs", ",", "**", "neg_inputs", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.Unbabel_COMET.ranking.ranking_metric.RankingMetric.forward": [[163, 202], ["ranking_metric.RankingMetric.get_sentence_embedding", "ranking_metric.RankingMetric.get_sentence_embedding", "ranking_metric.RankingMetric.get_sentence_embedding", "ranking_metric.RankingMetric.get_sentence_embedding", "torch.pairwise_distance", "torch.pairwise_distance", "torch.pairwise_distance", "torch.pairwise_distance", "torch.pairwise_distance", "torch.pairwise_distance", "torch.pairwise_distance", "torch.pairwise_distance", "ranking_metric.RankingMetric.loss", "ranking_metric.RankingMetric.loss"], "methods", ["home.repos.pwc.inspect_result.Unbabel_COMET.models.base.CometModel.get_sentence_embedding", "home.repos.pwc.inspect_result.Unbabel_COMET.models.base.CometModel.get_sentence_embedding", "home.repos.pwc.inspect_result.Unbabel_COMET.models.base.CometModel.get_sentence_embedding", "home.repos.pwc.inspect_result.Unbabel_COMET.models.base.CometModel.get_sentence_embedding", "home.repos.pwc.inspect_result.Unbabel_COMET.ranking.ranking_metric.RankingMetric.loss", "home.repos.pwc.inspect_result.Unbabel_COMET.ranking.ranking_metric.RankingMetric.loss"], ["", "def", "forward", "(", "\n", "self", ",", "\n", "src_input_ids", ":", "torch", ".", "tensor", ",", "\n", "ref_input_ids", ":", "torch", ".", "tensor", ",", "\n", "pos_input_ids", ":", "torch", ".", "tensor", ",", "\n", "neg_input_ids", ":", "torch", ".", "tensor", ",", "\n", "src_attention_mask", ":", "torch", ".", "tensor", ",", "\n", "ref_attention_mask", ":", "torch", ".", "tensor", ",", "\n", "pos_attention_mask", ":", "torch", ".", "tensor", ",", "\n", "neg_attention_mask", ":", "torch", ".", "tensor", ",", "\n", "**", "kwargs", "\n", ")", "->", "Dict", "[", "str", ",", "torch", ".", "Tensor", "]", ":", "\n", "        ", "src_sentemb", "=", "self", ".", "get_sentence_embedding", "(", "src_input_ids", ",", "src_attention_mask", ")", "\n", "ref_sentemb", "=", "self", ".", "get_sentence_embedding", "(", "ref_input_ids", ",", "ref_attention_mask", ")", "\n", "pos_sentemb", "=", "self", ".", "get_sentence_embedding", "(", "pos_input_ids", ",", "pos_attention_mask", ")", "\n", "neg_sentemb", "=", "self", ".", "get_sentence_embedding", "(", "neg_input_ids", ",", "neg_attention_mask", ")", "\n", "\n", "loss", "=", "self", ".", "loss", "(", "src_sentemb", ",", "pos_sentemb", ",", "neg_sentemb", ")", "+", "self", ".", "loss", "(", "\n", "ref_sentemb", ",", "pos_sentemb", ",", "neg_sentemb", "\n", ")", "\n", "\n", "distance_src_pos", "=", "F", ".", "pairwise_distance", "(", "pos_sentemb", ",", "src_sentemb", ")", "\n", "distance_ref_pos", "=", "F", ".", "pairwise_distance", "(", "pos_sentemb", ",", "ref_sentemb", ")", "\n", "# Harmonic mean between anchors and the positive example", "\n", "distance_pos", "=", "(", "2", "*", "distance_src_pos", "*", "distance_ref_pos", ")", "/", "(", "\n", "distance_src_pos", "+", "distance_ref_pos", "\n", ")", "\n", "\n", "# Harmonic mean between anchors and the negative example", "\n", "distance_src_neg", "=", "F", ".", "pairwise_distance", "(", "neg_sentemb", ",", "src_sentemb", ")", "\n", "distance_ref_neg", "=", "F", ".", "pairwise_distance", "(", "neg_sentemb", ",", "ref_sentemb", ")", "\n", "distance_neg", "=", "(", "2", "*", "distance_src_neg", "*", "distance_ref_neg", ")", "/", "(", "\n", "distance_src_neg", "+", "distance_ref_neg", "\n", ")", "\n", "\n", "return", "{", "\n", "\"loss\"", ":", "loss", ",", "\n", "\"distance_pos\"", ":", "distance_pos", ",", "\n", "\"distance_neg\"", ":", "distance_neg", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.Unbabel_COMET.ranking.ranking_metric.RankingMetric.read_csv": [[204, 227], ["pandas.read_csv", "df[].astype", "df[].astype", "df[].astype", "df[].astype", "pandas.read_csv.to_dict", "df[].astype", "df[].astype", "df[].astype", "df[].astype", "pandas.read_csv.to_dict"], "methods", ["home.repos.pwc.inspect_result.Unbabel_COMET.regression.referenceless.ReferencelessRegression.read_csv"], ["", "def", "read_csv", "(", "self", ",", "path", ":", "str", ",", "regression", ":", "bool", "=", "False", ")", "->", "List", "[", "dict", "]", ":", "\n", "        ", "\"\"\"Reads a comma separated value file.\n\n        :param path: path to a csv file.\n\n        :return: List of records as dictionaries\n        \"\"\"", "\n", "df", "=", "pd", ".", "read_csv", "(", "path", ")", "\n", "\n", "if", "regression", ":", "\n", "            ", "df", "=", "df", "[", "[", "\"src\"", ",", "\"mt\"", ",", "\"ref\"", ",", "\"score\"", "]", "]", "\n", "df", "[", "\"src\"", "]", "=", "df", "[", "\"src\"", "]", ".", "astype", "(", "str", ")", "\n", "df", "[", "\"mt\"", "]", "=", "df", "[", "\"mt\"", "]", ".", "astype", "(", "str", ")", "\n", "df", "[", "\"ref\"", "]", "=", "df", "[", "\"ref\"", "]", ".", "astype", "(", "str", ")", "\n", "df", "[", "\"score\"", "]", "=", "df", "[", "\"score\"", "]", ".", "astype", "(", "float", ")", "\n", "return", "df", ".", "to_dict", "(", "\"records\"", ")", "\n", "\n", "", "df", "=", "df", "[", "[", "\"src\"", ",", "\"pos\"", ",", "\"neg\"", ",", "\"ref\"", "]", "]", "\n", "df", "[", "\"src\"", "]", "=", "df", "[", "\"src\"", "]", ".", "astype", "(", "str", ")", "\n", "df", "[", "\"pos\"", "]", "=", "df", "[", "\"pos\"", "]", ".", "astype", "(", "str", ")", "\n", "df", "[", "\"neg\"", "]", "=", "df", "[", "\"neg\"", "]", ".", "astype", "(", "str", ")", "\n", "df", "[", "\"ref\"", "]", "=", "df", "[", "\"ref\"", "]", ".", "astype", "(", "str", ")", "\n", "return", "df", ".", "to_dict", "(", "\"records\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Unbabel_COMET.ranking.ranking_metric.RankingMetric.training_step": [[228, 256], ["ranking_metric.RankingMetric.forward", "ranking_metric.RankingMetric.log", "ranking_metric.RankingMetric.unfreeze_encoder"], "methods", ["home.repos.pwc.inspect_result.Unbabel_COMET.regression.referenceless.ReferencelessRegression.forward", "home.repos.pwc.inspect_result.Unbabel_COMET.models.base.CometModel.unfreeze_encoder"], ["", "def", "training_step", "(", "\n", "self", ",", "\n", "batch", ":", "Tuple", "[", "Dict", "[", "str", ",", "torch", ".", "Tensor", "]", ",", "Dict", "[", "str", ",", "torch", ".", "Tensor", "]", "]", ",", "\n", "batch_nb", ":", "int", ",", "\n", ")", "->", "Dict", "[", "str", ",", "torch", ".", "Tensor", "]", ":", "\n", "        ", "\"\"\"\n        Runs one training step.\n        This usually consists in the forward function followed by the loss function.\n\n        :param batch: The output of your prepare_sample function.\n        :param batch_nb: Integer displaying which batch this is.\n\n        :returns: dictionary containing the loss and the metrics to be added to the\n            lightning logger.\n        \"\"\"", "\n", "batch_prediction", "=", "self", ".", "forward", "(", "**", "batch", ")", "\n", "loss_value", "=", "batch_prediction", "[", "\"loss\"", "]", "\n", "\n", "if", "(", "\n", "self", ".", "nr_frozen_epochs", "<", "1.0", "\n", "and", "self", ".", "nr_frozen_epochs", ">", "0.0", "\n", "and", "batch_nb", ">", "self", ".", "epoch_total_steps", "*", "self", ".", "nr_frozen_epochs", "\n", ")", ":", "\n", "            ", "self", ".", "unfreeze_encoder", "(", ")", "\n", "self", ".", "_frozen", "=", "False", "\n", "\n", "", "self", ".", "log", "(", "\"train_loss\"", ",", "loss_value", ",", "on_step", "=", "True", ",", "on_epoch", "=", "True", ")", "\n", "return", "loss_value", "\n", "\n"]], "home.repos.pwc.inspect_result.Unbabel_COMET.ranking.ranking_metric.RankingMetric.validation_step": [[257, 284], ["ranking_metric.RankingMetric.forward", "ranking_metric.RankingMetric.log", "ranking_metric.RankingMetric.train_metrics.update", "ranking_metric.RankingMetric.val_metrics.update"], "methods", ["home.repos.pwc.inspect_result.Unbabel_COMET.regression.referenceless.ReferencelessRegression.forward", "home.repos.pwc.inspect_result.Unbabel_COMET.models.metrics.WMTKendall.update", "home.repos.pwc.inspect_result.Unbabel_COMET.models.metrics.WMTKendall.update"], ["", "def", "validation_step", "(", "\n", "self", ",", "\n", "batch", ":", "Tuple", "[", "Dict", "[", "str", ",", "torch", ".", "Tensor", "]", ",", "Dict", "[", "str", ",", "torch", ".", "Tensor", "]", "]", ",", "\n", "batch_nb", ":", "int", ",", "\n", "dataloader_idx", ":", "int", ",", "\n", ")", "->", "Dict", "[", "str", ",", "torch", ".", "Tensor", "]", ":", "\n", "        ", "\"\"\"\n        Similar to the training step but with the model in eval mode.\n\n        :param batch: The output of your prepare_sample function.\n        :param batch_nb: Integer displaying which batch this is.\n        :param dataloader_idx: Integer displaying which dataloader this is.\n\n        :returns: dictionary passed to the validation_end function.\n        \"\"\"", "\n", "batch_prediction", "=", "self", ".", "forward", "(", "**", "batch", ")", "\n", "loss_value", "=", "batch_prediction", "[", "\"loss\"", "]", "\n", "self", ".", "log", "(", "\"val_loss\"", ",", "loss_value", ",", "on_step", "=", "True", ",", "on_epoch", "=", "True", ")", "\n", "\n", "# TODO: REMOVE if condition after torchmetrics bug fix", "\n", "if", "dataloader_idx", "==", "0", ":", "\n", "            ", "self", ".", "train_metrics", ".", "update", "(", "\n", "batch_prediction", "[", "\"distance_pos\"", "]", ",", "batch_prediction", "[", "\"distance_neg\"", "]", "\n", ")", "\n", "", "elif", "dataloader_idx", "==", "1", ":", "\n", "            ", "self", ".", "val_metrics", ".", "update", "(", "\n", "batch_prediction", "[", "\"distance_pos\"", "]", ",", "batch_prediction", "[", "\"distance_neg\"", "]", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.Unbabel_COMET.ranking.ranking_metric.RankingMetric.predict_step": [[286, 307], ["ranking_metric.RankingMetric.get_sentence_embedding", "ranking_metric.RankingMetric.get_sentence_embedding", "ranking_metric.RankingMetric.get_sentence_embedding", "torch.pairwise_distance", "torch.pairwise_distance", "torch.pairwise_distance", "torch.pairwise_distance", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like"], "methods", ["home.repos.pwc.inspect_result.Unbabel_COMET.models.base.CometModel.get_sentence_embedding", "home.repos.pwc.inspect_result.Unbabel_COMET.models.base.CometModel.get_sentence_embedding", "home.repos.pwc.inspect_result.Unbabel_COMET.models.base.CometModel.get_sentence_embedding"], ["", "", "def", "predict_step", "(", "\n", "self", ",", "\n", "batch", ":", "Dict", "[", "str", ",", "torch", ".", "Tensor", "]", ",", "\n", "batch_idx", ":", "Optional", "[", "int", "]", "=", "None", ",", "\n", "dataloader_idx", ":", "Optional", "[", "int", "]", "=", "None", ",", "\n", ")", "->", "List", "[", "float", "]", ":", "\n", "        ", "src_sentemb", "=", "self", ".", "get_sentence_embedding", "(", "\n", "batch", "[", "\"src_input_ids\"", "]", ",", "batch", "[", "\"src_attention_mask\"", "]", "\n", ")", "\n", "ref_sentemb", "=", "self", ".", "get_sentence_embedding", "(", "\n", "batch", "[", "\"ref_input_ids\"", "]", ",", "batch", "[", "\"ref_attention_mask\"", "]", "\n", ")", "\n", "mt_sentemb", "=", "self", ".", "get_sentence_embedding", "(", "\n", "batch", "[", "\"mt_input_ids\"", "]", ",", "batch", "[", "\"mt_attention_mask\"", "]", "\n", ")", "\n", "\n", "src_distance", "=", "F", ".", "pairwise_distance", "(", "mt_sentemb", ",", "src_sentemb", ")", "\n", "ref_distance", "=", "F", ".", "pairwise_distance", "(", "mt_sentemb", ",", "ref_sentemb", ")", "\n", "\n", "distances", "=", "(", "2", "*", "ref_distance", "*", "src_distance", ")", "/", "(", "ref_distance", "+", "src_distance", ")", "\n", "return", "torch", ".", "ones_like", "(", "distances", ")", "/", "(", "1", "+", "distances", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Unbabel_COMET.regression.regression_metric.RegressionMetric.__init__": [[54, 101], ["comet.models.base.CometModel.__init__", "regression_metric.RegressionMetric.save_hyperparameters", "comet.modules.FeedForward"], "methods", ["home.repos.pwc.inspect_result.Unbabel_COMET.regression.referenceless.ReferencelessRegression.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "nr_frozen_epochs", ":", "Union", "[", "float", ",", "int", "]", "=", "0.3", ",", "\n", "keep_embeddings_frozen", ":", "bool", "=", "False", ",", "\n", "optimizer", ":", "str", "=", "\"AdamW\"", ",", "\n", "encoder_learning_rate", ":", "float", "=", "1e-05", ",", "\n", "learning_rate", ":", "float", "=", "3e-05", ",", "\n", "layerwise_decay", ":", "float", "=", "0.95", ",", "\n", "encoder_model", ":", "str", "=", "\"XLM-RoBERTa\"", ",", "\n", "pretrained_model", ":", "str", "=", "\"xlm-roberta-base\"", ",", "\n", "pool", ":", "str", "=", "\"avg\"", ",", "\n", "layer", ":", "Union", "[", "str", ",", "int", "]", "=", "\"mix\"", ",", "\n", "dropout", ":", "float", "=", "0.1", ",", "\n", "batch_size", ":", "int", "=", "4", ",", "\n", "train_data", ":", "Optional", "[", "str", "]", "=", "None", ",", "\n", "validation_data", ":", "Optional", "[", "str", "]", "=", "None", ",", "\n", "hidden_sizes", ":", "List", "[", "int", "]", "=", "[", "2304", ",", "768", "]", ",", "\n", "activations", ":", "str", "=", "\"Tanh\"", ",", "\n", "final_activation", ":", "Optional", "[", "str", "]", "=", "None", ",", "\n", "load_weights_from_checkpoint", ":", "Optional", "[", "str", "]", "=", "None", ",", "\n", ")", "->", "None", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "\n", "nr_frozen_epochs", ",", "\n", "keep_embeddings_frozen", ",", "\n", "optimizer", ",", "\n", "encoder_learning_rate", ",", "\n", "learning_rate", ",", "\n", "layerwise_decay", ",", "\n", "encoder_model", ",", "\n", "pretrained_model", ",", "\n", "pool", ",", "\n", "layer", ",", "\n", "dropout", ",", "\n", "batch_size", ",", "\n", "train_data", ",", "\n", "validation_data", ",", "\n", "load_weights_from_checkpoint", ",", "\n", "\"regression_metric\"", ",", "\n", ")", "\n", "self", ".", "save_hyperparameters", "(", ")", "\n", "\n", "self", ".", "estimator", "=", "FeedForward", "(", "\n", "in_dim", "=", "self", ".", "encoder", ".", "output_units", "*", "6", ",", "\n", "hidden_sizes", "=", "self", ".", "hparams", ".", "hidden_sizes", ",", "\n", "activations", "=", "self", ".", "hparams", ".", "activations", ",", "\n", "dropout", "=", "self", ".", "hparams", ".", "dropout", ",", "\n", "final_activation", "=", "self", ".", "hparams", ".", "final_activation", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.Unbabel_COMET.regression.regression_metric.RegressionMetric.init_metrics": [[103, 106], ["comet.models.metrics.RegressionMetrics", "comet.models.metrics.RegressionMetrics"], "methods", ["None"], ["", "def", "init_metrics", "(", "self", ")", ":", "\n", "        ", "self", ".", "train_metrics", "=", "RegressionMetrics", "(", "prefix", "=", "\"train\"", ")", "\n", "self", ".", "val_metrics", "=", "RegressionMetrics", "(", "prefix", "=", "\"val\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Unbabel_COMET.regression.regression_metric.RegressionMetric.is_referenceless": [[107, 109], ["None"], "methods", ["None"], ["", "def", "is_referenceless", "(", "self", ")", "->", "bool", ":", "\n", "        ", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.Unbabel_COMET.regression.regression_metric.RegressionMetric.configure_optimizers": [[110, 142], ["regression_metric.RegressionMetric.encoder.layerwise_lr", "transformers.optimization.Adafactor", "torch.optim.AdamW", "regression_metric.RegressionMetric.estimator.parameters", "regression_metric.RegressionMetric.layerwise_attention.parameters"], "methods", ["home.repos.pwc.inspect_result.Unbabel_COMET.encoders.bert.BERTEncoder.layerwise_lr"], ["", "def", "configure_optimizers", "(", "\n", "self", ",", "\n", ")", "->", "Tuple", "[", "List", "[", "torch", ".", "optim", ".", "Optimizer", "]", ",", "List", "[", "torch", ".", "optim", ".", "lr_scheduler", ".", "LambdaLR", "]", "]", ":", "\n", "        ", "\"\"\"Sets the optimizers to be used during training.\"\"\"", "\n", "layer_parameters", "=", "self", ".", "encoder", ".", "layerwise_lr", "(", "\n", "self", ".", "hparams", ".", "encoder_learning_rate", ",", "self", ".", "hparams", ".", "layerwise_decay", "\n", ")", "\n", "top_layers_parameters", "=", "[", "\n", "{", "\"params\"", ":", "self", ".", "estimator", ".", "parameters", "(", ")", ",", "\"lr\"", ":", "self", ".", "hparams", ".", "learning_rate", "}", "\n", "]", "\n", "if", "self", ".", "layerwise_attention", ":", "\n", "            ", "layerwise_attn_params", "=", "[", "\n", "{", "\n", "\"params\"", ":", "self", ".", "layerwise_attention", ".", "parameters", "(", ")", ",", "\n", "\"lr\"", ":", "self", ".", "hparams", ".", "learning_rate", ",", "\n", "}", "\n", "]", "\n", "params", "=", "layer_parameters", "+", "top_layers_parameters", "+", "layerwise_attn_params", "\n", "", "else", ":", "\n", "            ", "params", "=", "layer_parameters", "+", "top_layers_parameters", "\n", "\n", "", "if", "self", ".", "hparams", ".", "optimizer", "==", "\"Adafactor\"", ":", "\n", "            ", "optimizer", "=", "Adafactor", "(", "\n", "params", ",", "\n", "lr", "=", "self", ".", "hparams", ".", "learning_rate", ",", "\n", "relative_step", "=", "False", ",", "\n", "scale_parameter", "=", "False", ",", "\n", ")", "\n", "", "else", ":", "\n", "            ", "optimizer", "=", "torch", ".", "optim", ".", "AdamW", "(", "params", ",", "lr", "=", "self", ".", "hparams", ".", "learning_rate", ")", "\n", "# scheduler = self._build_scheduler(optimizer)", "\n", "", "return", "[", "optimizer", "]", ",", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.Unbabel_COMET.regression.regression_metric.RegressionMetric.prepare_sample": [[143, 172], ["regression_metric.RegressionMetric.encoder.prepare_sample", "regression_metric.RegressionMetric.encoder.prepare_sample", "regression_metric.RegressionMetric.encoder.prepare_sample", "torch.tensor", "regression_metric.RegressionMetric.items", "regression_metric.RegressionMetric.items", "regression_metric.RegressionMetric.items"], "methods", ["home.repos.pwc.inspect_result.Unbabel_COMET.regression.referenceless.ReferencelessRegression.prepare_sample", "home.repos.pwc.inspect_result.Unbabel_COMET.regression.referenceless.ReferencelessRegression.prepare_sample", "home.repos.pwc.inspect_result.Unbabel_COMET.regression.referenceless.ReferencelessRegression.prepare_sample"], ["", "def", "prepare_sample", "(", "\n", "self", ",", "sample", ":", "List", "[", "Dict", "[", "str", ",", "Union", "[", "str", ",", "float", "]", "]", "]", ",", "inference", ":", "bool", "=", "False", "\n", ")", "->", "Union", "[", "\n", "Tuple", "[", "Dict", "[", "str", ",", "torch", ".", "Tensor", "]", ",", "Dict", "[", "str", ",", "torch", ".", "Tensor", "]", "]", ",", "Dict", "[", "str", ",", "torch", ".", "Tensor", "]", "\n", "]", ":", "\n", "        ", "\"\"\"\n        Function that prepares a sample to input the model.\n\n        :param sample: list of dictionaries.\n        :param inference: If set to true prepares only the model inputs.\n\n        :returns: Tuple with 2 dictionaries (model inputs and targets).\n            If `inference=True` returns only the model inputs.\n        \"\"\"", "\n", "sample", "=", "{", "k", ":", "[", "dic", "[", "k", "]", "for", "dic", "in", "sample", "]", "for", "k", "in", "sample", "[", "0", "]", "}", "\n", "src_inputs", "=", "self", ".", "encoder", ".", "prepare_sample", "(", "sample", "[", "\"src\"", "]", ")", "\n", "mt_inputs", "=", "self", ".", "encoder", ".", "prepare_sample", "(", "sample", "[", "\"mt\"", "]", ")", "\n", "ref_inputs", "=", "self", ".", "encoder", ".", "prepare_sample", "(", "sample", "[", "\"ref\"", "]", ")", "\n", "\n", "src_inputs", "=", "{", "\"src_\"", "+", "k", ":", "v", "for", "k", ",", "v", "in", "src_inputs", ".", "items", "(", ")", "}", "\n", "mt_inputs", "=", "{", "\"mt_\"", "+", "k", ":", "v", "for", "k", ",", "v", "in", "mt_inputs", ".", "items", "(", ")", "}", "\n", "ref_inputs", "=", "{", "\"ref_\"", "+", "k", ":", "v", "for", "k", ",", "v", "in", "ref_inputs", ".", "items", "(", ")", "}", "\n", "inputs", "=", "{", "**", "src_inputs", ",", "**", "mt_inputs", ",", "**", "ref_inputs", "}", "\n", "\n", "if", "inference", ":", "\n", "            ", "return", "inputs", "\n", "\n", "", "targets", "=", "{", "\"score\"", ":", "torch", ".", "tensor", "(", "sample", "[", "\"score\"", "]", ",", "dtype", "=", "torch", ".", "float", ")", "}", "\n", "return", "inputs", ",", "targets", "\n", "\n"]], "home.repos.pwc.inspect_result.Unbabel_COMET.regression.regression_metric.RegressionMetric.estimate": [[173, 190], ["torch.abs", "torch.abs", "torch.cat", "regression_metric.RegressionMetric.estimator"], "methods", ["None"], ["", "def", "estimate", "(", "\n", "self", ",", "\n", "src_sentemb", ":", "torch", ".", "Tensor", ",", "\n", "mt_sentemb", ":", "torch", ".", "Tensor", ",", "\n", "ref_sentemb", ":", "torch", ".", "Tensor", ",", "\n", ")", "->", "Dict", "[", "str", ",", "torch", ".", "Tensor", "]", ":", "\n", "        ", "diff_ref", "=", "torch", ".", "abs", "(", "mt_sentemb", "-", "ref_sentemb", ")", "\n", "diff_src", "=", "torch", ".", "abs", "(", "mt_sentemb", "-", "src_sentemb", ")", "\n", "\n", "prod_ref", "=", "mt_sentemb", "*", "ref_sentemb", "\n", "prod_src", "=", "mt_sentemb", "*", "src_sentemb", "\n", "\n", "embedded_sequences", "=", "torch", ".", "cat", "(", "\n", "(", "mt_sentemb", ",", "ref_sentemb", ",", "prod_ref", ",", "diff_ref", ",", "prod_src", ",", "diff_src", ")", ",", "\n", "dim", "=", "1", ",", "\n", ")", "\n", "return", "{", "\"score\"", ":", "self", ".", "estimator", "(", "embedded_sequences", ")", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.Unbabel_COMET.regression.regression_metric.RegressionMetric.forward": [[191, 205], ["regression_metric.RegressionMetric.get_sentence_embedding", "regression_metric.RegressionMetric.get_sentence_embedding", "regression_metric.RegressionMetric.get_sentence_embedding", "regression_metric.RegressionMetric.estimate"], "methods", ["home.repos.pwc.inspect_result.Unbabel_COMET.models.base.CometModel.get_sentence_embedding", "home.repos.pwc.inspect_result.Unbabel_COMET.models.base.CometModel.get_sentence_embedding", "home.repos.pwc.inspect_result.Unbabel_COMET.models.base.CometModel.get_sentence_embedding", "home.repos.pwc.inspect_result.Unbabel_COMET.regression.regression_metric.RegressionMetric.estimate"], ["", "def", "forward", "(", "\n", "self", ",", "\n", "src_input_ids", ":", "torch", ".", "tensor", ",", "\n", "src_attention_mask", ":", "torch", ".", "tensor", ",", "\n", "mt_input_ids", ":", "torch", ".", "tensor", ",", "\n", "mt_attention_mask", ":", "torch", ".", "tensor", ",", "\n", "ref_input_ids", ":", "torch", ".", "tensor", ",", "\n", "ref_attention_mask", ":", "torch", ".", "tensor", ",", "\n", "**", "kwargs", "\n", ")", "->", "Dict", "[", "str", ",", "torch", ".", "Tensor", "]", ":", "\n", "        ", "src_sentemb", "=", "self", ".", "get_sentence_embedding", "(", "src_input_ids", ",", "src_attention_mask", ")", "\n", "mt_sentemb", "=", "self", ".", "get_sentence_embedding", "(", "mt_input_ids", ",", "mt_attention_mask", ")", "\n", "ref_sentemb", "=", "self", ".", "get_sentence_embedding", "(", "ref_input_ids", ",", "ref_attention_mask", ")", "\n", "return", "self", ".", "estimate", "(", "src_sentemb", ",", "mt_sentemb", ",", "ref_sentemb", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Unbabel_COMET.regression.regression_metric.RegressionMetric.read_csv": [[206, 220], ["pandas.read_csv", "df[].astype", "df[].astype", "df[].astype", "df[].astype", "pandas.read_csv.to_dict"], "methods", ["home.repos.pwc.inspect_result.Unbabel_COMET.regression.referenceless.ReferencelessRegression.read_csv"], ["", "def", "read_csv", "(", "self", ",", "path", ":", "str", ")", "->", "List", "[", "dict", "]", ":", "\n", "        ", "\"\"\"Reads a comma separated value file.\n\n        :param path: path to a csv file.\n\n        :return: List of records as dictionaries\n        \"\"\"", "\n", "df", "=", "pd", ".", "read_csv", "(", "path", ")", "\n", "df", "=", "df", "[", "[", "\"src\"", ",", "\"mt\"", ",", "\"ref\"", ",", "\"score\"", "]", "]", "\n", "df", "[", "\"src\"", "]", "=", "df", "[", "\"src\"", "]", ".", "astype", "(", "str", ")", "\n", "df", "[", "\"mt\"", "]", "=", "df", "[", "\"mt\"", "]", ".", "astype", "(", "str", ")", "\n", "df", "[", "\"ref\"", "]", "=", "df", "[", "\"ref\"", "]", ".", "astype", "(", "str", ")", "\n", "df", "[", "\"score\"", "]", "=", "df", "[", "\"score\"", "]", ".", "astype", "(", "\"float16\"", ")", "\n", "return", "df", ".", "to_dict", "(", "\"records\"", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Unbabel_COMET.regression.referenceless.ReferencelessRegression.__init__": [[52, 99], ["comet.models.regression.regression_metric.RegressionMetric.__init__", "referenceless.ReferencelessRegression.save_hyperparameters", "comet.modules.FeedForward"], "methods", ["home.repos.pwc.inspect_result.Unbabel_COMET.regression.referenceless.ReferencelessRegression.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "nr_frozen_epochs", ":", "Union", "[", "float", ",", "int", "]", "=", "0.3", ",", "\n", "keep_embeddings_frozen", ":", "bool", "=", "False", ",", "\n", "optimizer", ":", "str", "=", "\"AdamW\"", ",", "\n", "encoder_learning_rate", ":", "float", "=", "1e-05", ",", "\n", "learning_rate", ":", "float", "=", "3e-05", ",", "\n", "layerwise_decay", ":", "float", "=", "0.95", ",", "\n", "encoder_model", ":", "str", "=", "\"XLM-RoBERTa\"", ",", "\n", "pretrained_model", ":", "str", "=", "\"xlm-roberta-base\"", ",", "\n", "pool", ":", "str", "=", "\"avg\"", ",", "\n", "layer", ":", "Union", "[", "str", ",", "int", "]", "=", "\"mix\"", ",", "\n", "dropout", ":", "float", "=", "0.1", ",", "\n", "batch_size", ":", "int", "=", "4", ",", "\n", "train_data", ":", "Optional", "[", "str", "]", "=", "None", ",", "\n", "validation_data", ":", "Optional", "[", "str", "]", "=", "None", ",", "\n", "hidden_sizes", ":", "List", "[", "int", "]", "=", "[", "1024", "]", ",", "\n", "activations", ":", "str", "=", "\"Tanh\"", ",", "\n", "final_activation", ":", "Optional", "[", "str", "]", "=", "None", ",", "\n", "load_weights_from_checkpoint", ":", "Optional", "[", "str", "]", "=", "None", ",", "\n", ")", "->", "None", ":", "\n", "        ", "super", "(", "RegressionMetric", ",", "self", ")", ".", "__init__", "(", "\n", "nr_frozen_epochs", ",", "\n", "keep_embeddings_frozen", ",", "\n", "optimizer", ",", "\n", "encoder_learning_rate", ",", "\n", "learning_rate", ",", "\n", "layerwise_decay", ",", "\n", "encoder_model", ",", "\n", "pretrained_model", ",", "\n", "pool", ",", "\n", "layer", ",", "\n", "dropout", ",", "\n", "batch_size", ",", "\n", "train_data", ",", "\n", "validation_data", ",", "\n", "load_weights_from_checkpoint", ",", "\n", "\"referenceless_regression_metric\"", ",", "\n", ")", "\n", "self", ".", "save_hyperparameters", "(", ")", "\n", "\n", "self", ".", "estimator", "=", "FeedForward", "(", "\n", "in_dim", "=", "self", ".", "encoder", ".", "output_units", "*", "4", ",", "\n", "hidden_sizes", "=", "self", ".", "hparams", ".", "hidden_sizes", ",", "\n", "activations", "=", "self", ".", "hparams", ".", "activations", ",", "\n", "dropout", "=", "self", ".", "hparams", ".", "dropout", ",", "\n", "final_activation", "=", "self", ".", "hparams", ".", "final_activation", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.Unbabel_COMET.regression.referenceless.ReferencelessRegression.is_referenceless": [[101, 103], ["None"], "methods", ["None"], ["", "def", "is_referenceless", "(", "self", ")", "->", "bool", ":", "\n", "        ", "return", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.Unbabel_COMET.regression.referenceless.ReferencelessRegression.prepare_sample": [[104, 131], ["referenceless.ReferencelessRegression.encoder.prepare_sample", "referenceless.ReferencelessRegression.encoder.prepare_sample", "torch.tensor", "referenceless.ReferencelessRegression.items", "referenceless.ReferencelessRegression.items"], "methods", ["home.repos.pwc.inspect_result.Unbabel_COMET.regression.referenceless.ReferencelessRegression.prepare_sample", "home.repos.pwc.inspect_result.Unbabel_COMET.regression.referenceless.ReferencelessRegression.prepare_sample"], ["", "def", "prepare_sample", "(", "\n", "self", ",", "sample", ":", "List", "[", "Dict", "[", "str", ",", "Union", "[", "str", ",", "float", "]", "]", "]", ",", "inference", ":", "bool", "=", "False", "\n", ")", "->", "Union", "[", "\n", "Tuple", "[", "Dict", "[", "str", ",", "torch", ".", "Tensor", "]", ",", "Dict", "[", "str", ",", "torch", ".", "Tensor", "]", "]", ",", "Dict", "[", "str", ",", "torch", ".", "Tensor", "]", "\n", "]", ":", "\n", "        ", "\"\"\"\n        Function that prepares a sample to input the model.\n\n        :param sample: list of dictionaries.\n        :param inference: If set to true prepares only the model inputs.\n\n        :returns: Tuple with 2 dictionaries (model inputs and targets).\n            If `inference=True` returns only the model inputs.\n        \"\"\"", "\n", "sample", "=", "{", "k", ":", "[", "dic", "[", "k", "]", "for", "dic", "in", "sample", "]", "for", "k", "in", "sample", "[", "0", "]", "}", "\n", "src_inputs", "=", "self", ".", "encoder", ".", "prepare_sample", "(", "sample", "[", "\"src\"", "]", ")", "\n", "mt_inputs", "=", "self", ".", "encoder", ".", "prepare_sample", "(", "sample", "[", "\"mt\"", "]", ")", "\n", "\n", "src_inputs", "=", "{", "\"src_\"", "+", "k", ":", "v", "for", "k", ",", "v", "in", "src_inputs", ".", "items", "(", ")", "}", "\n", "mt_inputs", "=", "{", "\"mt_\"", "+", "k", ":", "v", "for", "k", ",", "v", "in", "mt_inputs", ".", "items", "(", ")", "}", "\n", "inputs", "=", "{", "**", "src_inputs", ",", "**", "mt_inputs", "}", "\n", "\n", "if", "inference", ":", "\n", "            ", "return", "inputs", "\n", "\n", "", "targets", "=", "{", "\"score\"", ":", "torch", ".", "tensor", "(", "sample", "[", "\"score\"", "]", ",", "dtype", "=", "torch", ".", "float", ")", "}", "\n", "return", "inputs", ",", "targets", "\n", "\n"]], "home.repos.pwc.inspect_result.Unbabel_COMET.regression.referenceless.ReferencelessRegression.forward": [[132, 150], ["referenceless.ReferencelessRegression.get_sentence_embedding", "referenceless.ReferencelessRegression.get_sentence_embedding", "torch.abs", "torch.cat", "referenceless.ReferencelessRegression.estimator"], "methods", ["home.repos.pwc.inspect_result.Unbabel_COMET.models.base.CometModel.get_sentence_embedding", "home.repos.pwc.inspect_result.Unbabel_COMET.models.base.CometModel.get_sentence_embedding"], ["", "def", "forward", "(", "\n", "self", ",", "\n", "src_input_ids", ":", "torch", ".", "tensor", ",", "\n", "src_attention_mask", ":", "torch", ".", "tensor", ",", "\n", "mt_input_ids", ":", "torch", ".", "tensor", ",", "\n", "mt_attention_mask", ":", "torch", ".", "tensor", ",", "\n", "**", "kwargs", "\n", ")", "->", "Dict", "[", "str", ",", "torch", ".", "Tensor", "]", ":", "\n", "        ", "src_sentemb", "=", "self", ".", "get_sentence_embedding", "(", "src_input_ids", ",", "src_attention_mask", ")", "\n", "mt_sentemb", "=", "self", ".", "get_sentence_embedding", "(", "mt_input_ids", ",", "mt_attention_mask", ")", "\n", "\n", "diff_src", "=", "torch", ".", "abs", "(", "mt_sentemb", "-", "src_sentemb", ")", "\n", "prod_src", "=", "mt_sentemb", "*", "src_sentemb", "\n", "\n", "embedded_sequences", "=", "torch", ".", "cat", "(", "\n", "(", "mt_sentemb", ",", "src_sentemb", ",", "prod_src", ",", "diff_src", ")", ",", "dim", "=", "1", "\n", ")", "\n", "return", "{", "\"score\"", ":", "self", ".", "estimator", "(", "embedded_sequences", ")", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.Unbabel_COMET.regression.referenceless.ReferencelessRegression.read_csv": [[151, 164], ["pandas.read_csv", "df[].astype", "df[].astype", "df[].astype", "pandas.read_csv.to_dict"], "methods", ["home.repos.pwc.inspect_result.Unbabel_COMET.regression.referenceless.ReferencelessRegression.read_csv"], ["", "def", "read_csv", "(", "self", ",", "path", ":", "str", ")", "->", "List", "[", "dict", "]", ":", "\n", "        ", "\"\"\"Reads a comma separated value file.\n\n        :param path: path to a csv file.\n\n        :return: List of records as dictionaries\n        \"\"\"", "\n", "df", "=", "pd", ".", "read_csv", "(", "path", ")", "\n", "df", "=", "df", "[", "[", "\"src\"", ",", "\"mt\"", ",", "\"score\"", "]", "]", "\n", "df", "[", "\"src\"", "]", "=", "df", "[", "\"src\"", "]", ".", "astype", "(", "str", ")", "\n", "df", "[", "\"mt\"", "]", "=", "df", "[", "\"mt\"", "]", ".", "astype", "(", "str", ")", "\n", "df", "[", "\"score\"", "]", "=", "df", "[", "\"score\"", "]", ".", "astype", "(", "float", ")", "\n", "return", "df", ".", "to_dict", "(", "\"records\"", ")", "\n", "", "", ""]]}