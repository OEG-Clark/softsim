{"home.repos.pwc.inspect_result.lr94_abas.None.model_selection.ModelCriterion.__init__": [[81, 114], ["re.match", "enumerate", "re.match.group", "open", "pickle.load", "pickle.load.get"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "name", ")", ":", "\n", "# Regression?", "\n", "        ", "m", "=", "re", ".", "match", "(", "r'regression\\((.+)\\)'", ",", "name", ")", "\n", "if", "m", "is", "not", "None", ":", "\n", "# If yes, get the file name", "\n", "            ", "self", ".", "name", "=", "'regression'", "\n", "regression_pickle_file", "=", "m", ".", "group", "(", "1", ")", "\n", "\n", "# Import regressor classes", "\n", "from", "sklearn", ".", "linear_model", "import", "LinearRegression", "\n", "from", "sklearn", ".", "preprocessing", "import", "StandardScaler", "\n", "# Load the model", "\n", "with", "open", "(", "regression_pickle_file", ",", "'rb'", ")", "as", "fp", ":", "\n", "                ", "criterion_dict", "=", "pickle", ".", "load", "(", "fp", ")", "\n", "self", ".", "file_name", "=", "regression_pickle_file", "\n", "self", ".", "metric_names", "=", "criterion_dict", "[", "'info'", "]", "[", "'metric_names'", "]", "\n", "self", ".", "info", "=", "criterion_dict", "[", "'info'", "]", "\n", "self", ".", "regressor", "=", "criterion_dict", "[", "'regressor'", "]", "\n", "self", ".", "scaler", "=", "criterion_dict", ".", "get", "(", "'scaler'", ",", "None", ")", "\n", "", "", "else", ":", "\n", "# Simple \"monodimensional\" metric", "\n", "            ", "self", ".", "name", "=", "name", "\n", "self", ".", "info", "=", "None", "\n", "self", ".", "metric_names", "=", "[", "name", "]", "\n", "\n", "# Convert shorthands in full metric names", "\n", "", "for", "i", ",", "n", "in", "enumerate", "(", "self", ".", "metric_names", ")", ":", "\n", "            ", "if", "n", "==", "'ss'", ":", "\n", "                ", "self", ".", "metric_names", "[", "i", "]", "=", "'target_silhouette_score'", "\n", "", "elif", "n", "==", "'ch'", ":", "\n", "                ", "self", ".", "metric_names", "[", "i", "]", "=", "'target_calinski_harabasz_score'", "\n", "", "elif", "n", "==", "'pseudolabels'", ":", "\n", "                ", "self", ".", "metric_names", "[", "i", "]", "=", "'target_pseudolabels'", "\n", "\n"]], "home.repos.pwc.inspect_result.lr94_abas.None.model_selection.ModelCriterion.__call__": [[115, 143], ["data[].to_numpy", "pandas.DataFrame", "data[].to_numpy.reshape", "model_selection.ModelCriterion.regressor.predict", "isinstance", "isinstance", "pandas.DataFrame", "len", "model_selection.ModelCriterion.metric_names[].endswith", "model_selection.ModelCriterion.scaler.transform"], "methods", ["None"], ["", "", "", "def", "__call__", "(", "self", ",", "data", "=", "None", ",", "**", "kwargs", ")", "->", "np", ".", "ndarray", ":", "\n", "# Argument: dataframe or something similar (lists, dicts...)", "\n", "# Convert it to dataframe", "\n", "        ", "if", "data", "is", "None", ":", "\n", "            ", "data", "=", "pd", ".", "DataFrame", "(", "[", "kwargs", "]", ")", "\n", "", "elif", "isinstance", "(", "data", ",", "dict", ")", "or", "isinstance", "(", "data", ",", "list", ")", ":", "\n", "            ", "data", "=", "pd", ".", "DataFrame", "(", "data", ")", "\n", "\n", "# Convert the dataframe to a numpy matrix containing the selected metrics (one for single-metric, more for", "\n", "# regression)", "\n", "", "metrics", "=", "data", "[", "self", ".", "metric_names", "]", ".", "to_numpy", "(", ")", "\n", "\n", "# If the model selection method uses a single metric (no regression)", "\n", "if", "self", ".", "name", "!=", "'regression'", ":", "\n", "            ", "assert", "len", "(", "self", ".", "metric_names", ")", "==", "1", "\n", "# if the metric doesn't end with \"loss\" it must be maximized!", "\n", "if", "not", "self", ".", "metric_names", "[", "0", "]", ".", "endswith", "(", "'_loss'", ")", ":", "\n", "                ", "metrics", "*=", "-", "1", "\n", "# Flatten and return", "\n", "", "return", "metrics", ".", "reshape", "(", "-", "1", ")", "\n", "", "else", ":", "\n", "# If the model selection method uses regression, just use the model to predict a value", "\n", "            ", "scaled_metrics", "=", "metrics", "if", "self", ".", "scaler", "is", "None", "else", "self", ".", "scaler", ".", "transform", "(", "metrics", ")", "\n", "score", "=", "self", ".", "regressor", ".", "predict", "(", "scaled_metrics", ")", "\n", "# Infinite loss where source loss is too high", "\n", "score", "[", "data", "[", "'source_class_loss'", "]", ">", "SOURCE_LOSS_THRESHOLD", "]", "=", "-", "1000", "\n", "# The model was trained with accuracy, so it's a score and not a loss. Convert into a loss", "\n", "return", "-", "score", "\n", "\n"]], "home.repos.pwc.inspect_result.lr94_abas.None.model_selection.ModelCriterion.get_best": [[144, 151], ["model_selection.ModelCriterion.", "model_selection.ModelCriterion.argmin", "losses[].item"], "methods", ["None"], ["", "", "def", "get_best", "(", "self", ",", "all_metrics", ":", "pd", ".", "DataFrame", ")", ":", "\n", "# Find best model", "\n", "        ", "losses", "=", "self", "(", "all_metrics", ")", "\n", "\n", "best_index", "=", "losses", ".", "argmin", "(", ")", "\n", "\n", "return", "best_index", ",", "losses", "[", "best_index", "]", ".", "item", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.lr94_abas.None.model_selection.ModelCriterion.__repr__": [[152, 154], ["None"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "name", "\n", "", "", ""]], "home.repos.pwc.inspect_result.lr94_abas.None.model_selection.get_centroids": [[14, 24], ["numpy.zeros", "range", "data[].mean"], "function", ["None"], ["def", "get_centroids", "(", "data", ",", "labels", ",", "num_classes", ")", ":", "\n", "    ", "centroids", "=", "np", ".", "zeros", "(", "(", "num_classes", ",", "data", ".", "shape", "[", "1", "]", ")", ")", "\n", "for", "cid", "in", "range", "(", "num_classes", ")", ":", "\n", "# Since we are using pseudolabels to compute centroids, some classes might not have instances according to the", "\n", "# pseudolabels assigned by the current model. In that case .mean() would return NaN causing KMeans to fail.", "\n", "# We set to 0 the missing centroids", "\n", "        ", "if", "(", "labels", "==", "cid", ")", ".", "any", "(", ")", ":", "\n", "            ", "centroids", "[", "cid", "]", "=", "data", "[", "labels", "==", "cid", "]", ".", "mean", "(", "0", ")", "\n", "\n", "", "", "return", "centroids", "\n", "\n"]], "home.repos.pwc.inspect_result.lr94_abas.None.model_selection.get_clustering_performance": [[26, 54], ["sklearn.decomposition.PCA", "numpy.concatenate", "model_selection.get_centroids", "sklearn.cluster.KMeans", "sklearn.cluster.KMeans.fit", "sklearn.decomposition.PCA.fit_transform", "sklearn.metrics.silhouette_score", "sklearn.metrics.calinski_harabasz_score", "float", "float"], "function", ["home.repos.pwc.inspect_result.lr94_abas.None.model_selection.get_centroids"], ["", "def", "get_clustering_performance", "(", "feats", ",", "plabels", ",", "num_classes", ",", "source_feats", "=", "None", ",", "pca_size", "=", "64", ")", ":", "\n", "    ", "\"\"\"\n    :param feats: N x out numpy vector\n    :param plabels:  N numpy vector\n    :param num_classes: int\n    :param source_feats\n    :param pca_size\n    :return: silhouette and calinski harabasz scores\n    \"\"\"", "\n", "pca", "=", "PCA", "(", "pca_size", ")", "\n", "n_samples", "=", "feats", ".", "shape", "[", "0", "]", "\n", "\n", "if", "source_feats", "is", "not", "None", ":", "\n", "        ", "feats", "=", "np", ".", "concatenate", "(", "(", "feats", ",", "source_feats", ")", ")", "\n", "\n", "", "try", ":", "\n", "        ", "x", "=", "pca", ".", "fit_transform", "(", "feats", ")", "[", ":", "n_samples", "]", "\n", "centroids", "=", "get_centroids", "(", "x", ",", "plabels", ",", "num_classes", ")", "\n", "\n", "clustering", "=", "KMeans", "(", "n_clusters", "=", "num_classes", ",", "init", "=", "centroids", ",", "n_init", "=", "1", ")", "\n", "\n", "clustering", ".", "fit", "(", "x", ")", "\n", "clabels", "=", "clustering", ".", "labels_", "\n", "ss", ",", "ch", ",", "=", "silhouette_score", "(", "x", ",", "clabels", ")", ",", "calinski_harabasz_score", "(", "x", ",", "clabels", ")", "\n", "", "except", "ValueError", ":", "\n", "        ", "ss", ",", "ch", "=", "float", "(", "'nan'", ")", ",", "float", "(", "'nan'", ")", "\n", "\n", "", "return", "ss", ",", "ch", "\n", "\n"]], "home.repos.pwc.inspect_result.lr94_abas.None.model_selection.compute_time_consistent_pseudolabels": [[56, 69], ["numpy.zeros", "range", "global_pseudolabels.argmax.argmax", "pseudolabels_per_epoch[].astype", "range"], "function", ["None"], ["", "def", "compute_time_consistent_pseudolabels", "(", "pseudolabels_per_epoch", ":", "np", ".", "ndarray", ",", "num_classes", ":", "int", ")", "->", "np", ".", "ndarray", ":", "\n", "    ", "epochs", "=", "pseudolabels_per_epoch", ".", "shape", "[", "0", "]", "\n", "\n", "# TODO this should be done in a numpy-oompy way", "\n", "global_pseudolabels", "=", "np", ".", "zeros", "(", "(", "pseudolabels_per_epoch", ".", "shape", "[", "1", "]", ",", "num_classes", ")", ",", "dtype", "=", "int", ")", "\n", "for", "i", "in", "range", "(", "epochs", ")", ":", "\n", "        ", "pseudolabels", "=", "pseudolabels_per_epoch", "[", "i", ",", ":", "]", ".", "astype", "(", "int", ")", "\n", "\n", "for", "j", "in", "range", "(", "pseudolabels", ".", "shape", "[", "0", "]", ")", ":", "\n", "            ", "global_pseudolabels", "[", "j", ",", "pseudolabels", "[", "j", "]", "]", "+=", "1", "\n", "\n", "", "", "global_pseudolabels", "=", "global_pseudolabels", ".", "argmax", "(", "axis", "=", "1", ")", "\n", "return", "global_pseudolabels", "\n", "\n"]], "home.repos.pwc.inspect_result.lr94_abas.None.train_model.get_default_run_name": [[20, 35], ["re.sub", "map", "train_model.get_default_run_name.shorten"], "function", ["None"], ["def", "get_default_run_name", "(", "args", ")", ":", "\n", "    ", "def", "shorten", "(", "domain", ")", ":", "\n", "        ", "return", "re", ".", "sub", "(", "r'-.*'", ",", "''", ",", "domain", ")", "\n", "\n", "", "params", "=", "(", "\n", "args", ".", "da", ",", "\n", "\"{}-{}\"", ".", "format", "(", "shorten", "(", "args", ".", "source", ")", ",", "shorten", "(", "args", ".", "target", ")", ")", ",", "\n", "args", ".", "net", ",", "\n", "'fc'", ",", "\n", "args", ".", "max_iter", ",", "\n", "args", ".", "bs", ",", "\n", "args", ".", "lr", "\n", ")", "\n", "\n", "return", "\"_\"", ".", "join", "(", "map", "(", "lambda", "v", ":", "str", "(", "v", ")", ",", "params", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.lr94_abas.None.train_model.test": [[37, 97], ["model.eval", "model.output_size", "get_class_count", "torch.empty", "torch.empty", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.empty", "torch.empty", "torch.CrossEntropyLoss", "torch.nn.functional.softmax().sum", "torch.nn.functional.softmax().sum", "feats.numpy.numpy", "pseudo_labels.numpy.numpy", "model_selection.get_clustering_performance", "len", "len", "len", "len", "torch.no_grad", "torch.no_grad", "torch.nn.functional.softmax().sum.sum", "torch.sum().item", "torch.sum().item", "utils.map_to_device", "model", "f.cpu", "outputs.argmax().cpu", "outputs.cpu", "labels.cpu", "torch.argmax", "torch.argmax", "loss.entropy_loss().item", "torch.sum().item", "torch.sum().item", "torch.nn.functional.softmax", "torch.nn.functional.softmax", "nn.CrossEntropyLoss.item", "inputs.size", "torch.sum", "torch.sum", "outputs.argmax", "loss.entropy_loss", "torch.sum", "torch.sum", "nn.CrossEntropyLoss.", "torch.log", "torch.log"], "function", ["home.repos.pwc.inspect_result.lr94_abas.net.resnet.ResNetFc.output_size", "home.repos.pwc.inspect_result.lr94_abas.datasets.utils.get_class_count", "home.repos.pwc.inspect_result.lr94_abas.None.model_selection.get_clustering_performance", "home.repos.pwc.inspect_result.lr94_abas.None.utils.map_to_device", "home.repos.pwc.inspect_result.lr94_abas.None.loss.entropy_loss"], ["", "def", "test", "(", "loader", ",", "model", ",", "device", ",", "source_feats", "=", "None", ")", ":", "\n", "    ", "tot_correct", "=", "0", "\n", "tot", "=", "0", "\n", "model", ".", "eval", "(", ")", "# just to be sure", "\n", "feat_size", "=", "model", ".", "output_size", "(", ")", "\n", "\n", "num_classes", "=", "get_class_count", "(", "loader", ".", "dataset", ")", "\n", "\n", "feats", "=", "torch", ".", "empty", "(", "len", "(", "loader", ".", "dataset", ")", ",", "feat_size", ")", "\n", "pseudo_labels", "=", "torch", ".", "zeros", "(", "len", "(", "loader", ".", "dataset", ")", ",", "dtype", "=", "torch", ".", "int64", ")", "\n", "all_labels", "=", "torch", ".", "zeros", "(", "len", "(", "loader", ".", "dataset", ")", ",", "dtype", "=", "torch", ".", "int64", ")", "\n", "all_outputs", "=", "torch", ".", "empty", "(", "len", "(", "loader", ".", "dataset", ")", ",", "num_classes", ")", "\n", "\n", "entropy", "=", "0", "\n", "class_loss", "=", "0", "\n", "ce_loss", "=", "nn", ".", "CrossEntropyLoss", "(", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "for", "inputs", ",", "labels", "in", "loader", ":", "\n", "            ", "inputs", ",", "labels", "=", "map_to_device", "(", "device", ",", "(", "inputs", ",", "labels", ")", ")", "\n", "outputs", ",", "f", "=", "model", "(", "inputs", ")", "\n", "\n", "# save features for later", "\n", "s", "=", "inputs", ".", "shape", "[", "0", "]", "\n", "feats", "[", "tot", ":", "tot", "+", "s", "]", "=", "f", ".", "cpu", "(", ")", "\n", "pseudo_labels", "[", "tot", ":", "tot", "+", "s", "]", "=", "outputs", ".", "argmax", "(", "1", ")", ".", "cpu", "(", ")", "\n", "all_outputs", "[", "tot", ":", "tot", "+", "s", "]", "=", "outputs", ".", "cpu", "(", ")", "\n", "all_labels", "[", "tot", ":", "tot", "+", "s", "]", "=", "labels", ".", "cpu", "(", ")", "\n", "\n", "# entropy, accuracy and class loss", "\n", "preds", "=", "torch", ".", "argmax", "(", "outputs", ",", "dim", "=", "1", ")", "\n", "entropy", "+=", "loss", ".", "entropy_loss", "(", "outputs", ")", ".", "item", "(", ")", "\n", "class_loss", "+=", "ce_loss", "(", "outputs", ",", "labels", ")", ".", "item", "(", ")", "*", "inputs", ".", "size", "(", "0", ")", "\n", "\n", "tot_correct", "+=", "torch", ".", "sum", "(", "preds", "==", "labels", ")", ".", "item", "(", ")", "\n", "tot", "+=", "s", "\n", "\n", "# Diversity loss (computed on full dataset)", "\n", "", "", "pb_pred_tgt", "=", "torch", ".", "nn", ".", "functional", ".", "softmax", "(", "all_outputs", ",", "dim", "=", "1", ")", ".", "sum", "(", "dim", "=", "0", ")", "\n", "pb_pred_tgt", "=", "pb_pred_tgt", "/", "pb_pred_tgt", ".", "sum", "(", ")", "\n", "target_div_loss_full", "=", "-", "torch", ".", "sum", "(", "(", "pb_pred_tgt", "*", "torch", ".", "log", "(", "pb_pred_tgt", "+", "1e-6", ")", ")", ")", ".", "item", "(", ")", "\n", "target_div_loss_full", "/=", "num_classes", "\n", "\n", "feats", "=", "feats", ".", "numpy", "(", ")", "\n", "pseudo_labels", "=", "pseudo_labels", ".", "numpy", "(", ")", "\n", "sil", ",", "cal", "=", "get_clustering_performance", "(", "feats", ",", "pseudo_labels", ",", "num_classes", ",", "source_feats", "=", "source_feats", ")", "\n", "accuracy", "=", "tot_correct", "/", "tot", "\n", "entropy", "/=", "tot", "\n", "class_loss", "/=", "tot", "\n", "metrics", "=", "{", "\n", "'accuracy'", ":", "accuracy", ",", "\n", "'entropy_loss'", ":", "entropy", ",", "\n", "\n", "# Diversity loss (on full dataset as one big batch)", "\n", "'div_loss'", ":", "target_div_loss_full", ",", "\n", "\n", "'class_loss'", ":", "class_loss", ",", "\n", "'silhouette_score'", ":", "sil", ",", "\n", "'calinski_harabasz_score'", ":", "cal", "\n", "}", "\n", "return", "metrics", ",", "pseudo_labels", ",", "feats", "\n", "\n"]], "home.repos.pwc.inspect_result.lr94_abas.None.train_model.run_training": [[99, 344], ["torch.device", "torch.device", "utils.split_dict", "net_args.update", "utils.remove_log_hps", "print", "prepare_datasets", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "print", "print", "print", "net.resnet.ResNetFc().to", "resnet.ResNetFc().to.get_parameters", "torch.SGD", "torch.optim.lr_scheduler.LambdaLR", "logger.Logger", "torch.CrossEntropyLoss", "len", "len", "pandas.DataFrame", "np.array", "model_selection.compute_time_consistent_pseudolabels", "range", "disc_args.update", "utils.remove_log_hps", "print", "utils.split_dict.get", "net.resnet.Discriminator().to", "resnet.Discriminator().to.get_parameters", "logger.Logger.progress", "range", "np.equal().sum", "open", "pickle.dump", "len", "logger.Logger.add_scalar", "utils.split_dict.get", "net.resnet.ResNetFc", "resnet.ResNetFc().to.train", "opt.SGD.zero_grad", "iter.next", "utils.map_to_device", "resnet.ResNetFc().to.", "nn.CrossEntropyLoss.", "total_loss.backward", "opt.SGD.step", "torch.optim.lr_scheduler.LambdaLR.step", "pb.update", "os.path.join", "float", "len", "len", "net.resnet.Discriminator", "print", "print", "resnet.ResNetFc().to.train", "train_model.test", "np.array.append", "print", "logger.Logger.add_scalar", "logger.Logger.add_scalar", "new_metrics.update", "utils.add_scalars", "new_metrics.update", "pd.DataFrame.append", "resnet.Discriminator().to.train", "iter", "iter", "iter.next", "inputs_target.to.to", "resnet.ResNetFc().to.", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "logger.Logger.add_scalar", "np.equal", "train_model.test", "print", "new_metrics.update", "torch.Softmax", "float", "resnet.Discriminator().to.", "loss.DANN_loss", "transfer_loss.item", "resnet.ResNetFc().to.output_size", "torch.optim.lr_scheduler.LambdaLR.get_last_lr", "print", "print", "float", "resnet.Discriminator().to.", "loss.ALDA_loss", "test_result.items", "len", "print", "resnet.ResNetFc().to.freeze", "reg_loss.backward", "test_result.items", "np.exp", "transfer_loss.item", "np.exp", "transfer_loss.item", "reg_loss.item"], "function", ["home.repos.pwc.inspect_result.lr94_abas.None.utils.split_dict", "home.repos.pwc.inspect_result.lr94_abas.None.utils.remove_log_hps", "home.repos.pwc.inspect_result.lr94_abas.datasets.utils.prepare_datasets", "home.repos.pwc.inspect_result.lr94_abas.net.resnet.Discriminator.get_parameters", "home.repos.pwc.inspect_result.lr94_abas.None.model_selection.compute_time_consistent_pseudolabels", "home.repos.pwc.inspect_result.lr94_abas.None.utils.remove_log_hps", "home.repos.pwc.inspect_result.lr94_abas.net.resnet.Discriminator.get_parameters", "home.repos.pwc.inspect_result.lr94_abas.None.logger.Logger.progress", "home.repos.pwc.inspect_result.lr94_abas.None.logger.Logger.add_scalar", "home.repos.pwc.inspect_result.lr94_abas.None.utils.map_to_device", "home.repos.pwc.inspect_result.lr94_abas.None.train_model.test", "home.repos.pwc.inspect_result.lr94_abas.None.logger.Logger.add_scalar", "home.repos.pwc.inspect_result.lr94_abas.None.logger.Logger.add_scalar", "home.repos.pwc.inspect_result.lr94_abas.None.utils.add_scalars", "home.repos.pwc.inspect_result.lr94_abas.None.logger.Logger.add_scalar", "home.repos.pwc.inspect_result.lr94_abas.None.train_model.test", "home.repos.pwc.inspect_result.lr94_abas.None.loss.DANN_loss", "home.repos.pwc.inspect_result.lr94_abas.net.resnet.ResNetFc.output_size", "home.repos.pwc.inspect_result.lr94_abas.None.loss.ALDA_loss", "home.repos.pwc.inspect_result.lr94_abas.net.resnet.ResNetFc.freeze"], ["", "def", "run_training", "(", "\n", "source", ",", "\n", "target", ",", "\n", "dataset_root", ",", "\n", "net_name", ",", "\n", "da_method", ",", "\n", "max_iter", ",", "\n", "stop_iter", ",", "\n", "test_iter", ",", "\n", "logdir", ",", "\n", "run_name", ",", "\n", "gpu_id", ",", "\n", "load_workers", ",", "\n", "config", ",", "\n", "test_src", ":", "bool", "=", "False", ",", "\n", "use_tqdm", ":", "bool", "=", "True", ",", "\n", "kill_diverging", ":", "bool", "=", "False", ")", ":", "\n", "    ", "dev", "=", "torch", ".", "device", "(", "f'cuda:{gpu_id}'", ")", "\n", "\n", "if", "kill_diverging", ":", "\n", "        ", "assert", "test_src", "\n", "\n", "# Get config", "\n", "# Config arrives here (from BOHB or direct cli invocation) as a dictionary like", "\n", "# {'disc.dropout': 0.5, 'net.bottleneck_size_log': 9}", "\n", "# We separate it in something like", "\n", "# {'disc': {'dropout': 0.5'}, 'net': {'bottleneck_size_log': 9}}", "\n", "", "config", "=", "split_dict", "(", "config", ")", "\n", "# Disc args are not meaningful without DA", "\n", "if", "da_method", "!=", "'so'", ":", "\n", "# Default disc args", "\n", "        ", "disc_args", "=", "{", "\n", "'dropout'", ":", "0.5", ",", "\n", "'num_fc_layers'", ":", "3", ",", "\n", "'hidden_size_log'", ":", "10", "\n", "}", "\n", "# Update with the ones coming from config (if any)", "\n", "disc_args", ".", "update", "(", "config", ".", "get", "(", "'disc'", ",", "{", "}", ")", ")", "\n", "# Some args might be defined as log2. Replace them (bottleneck_size_log -> bottleneck_size)", "\n", "remove_log_hps", "(", "disc_args", ")", "\n", "# Print disc args", "\n", "print", "(", "f\"Discriminator config: {disc_args}\"", ")", "\n", "# Very similar, but for the backbone", "\n", "", "net_args", "=", "{", "\n", "'use_bottleneck'", ":", "da_method", "!=", "'so'", ",", "\n", "'bottleneck_size_log'", ":", "9", "\n", "}", "\n", "net_args", ".", "update", "(", "config", ".", "get", "(", "'net'", ",", "{", "}", ")", ")", "\n", "remove_log_hps", "(", "net_args", ")", "\n", "print", "(", "f\"Backbone config: {net_args}\"", ")", "\n", "# Now net_args and disc_args are ready to be passed to the network constructors as **kwargs :)", "\n", "bs", ",", "lr", ",", "wd", "=", "config", "[", "'base'", "]", "[", "'bs'", "]", ",", "config", "[", "'base'", "]", "[", "'lr'", "]", ",", "config", "[", "'base'", "]", "[", "'wd'", "]", "\n", "\n", "# Load datasets and their number o classes", "\n", "dset_src_train", ",", "dset_src_test", ",", "dset_trg_train", ",", "dset_trg_test", ",", "num_classes", "=", "prepare_datasets", "(", "source", ",", "target", ",", "dataset_root", ")", "\n", "\n", "dload_src_train", "=", "DataLoader", "(", "dset_src_train", ",", "batch_size", "=", "bs", ",", "shuffle", "=", "True", ",", "num_workers", "=", "load_workers", ",", "drop_last", "=", "True", ")", "\n", "dload_src_test", "=", "DataLoader", "(", "dset_src_test", ",", "batch_size", "=", "bs", ",", "shuffle", "=", "False", ",", "num_workers", "=", "load_workers", ")", "\n", "dload_trg_train", "=", "DataLoader", "(", "dset_trg_train", ",", "batch_size", "=", "bs", ",", "shuffle", "=", "True", ",", "num_workers", "=", "load_workers", ",", "drop_last", "=", "True", ")", "\n", "dload_trg_test", "=", "DataLoader", "(", "dset_trg_test", ",", "batch_size", "=", "bs", ",", "shuffle", "=", "False", ",", "num_workers", "=", "load_workers", ")", "\n", "\n", "print", "(", "f\"Source samples: {len(dset_src_train)}\"", ")", "\n", "print", "(", "f\"Target samples: {len(dset_trg_train)}\"", ")", "\n", "print", "(", "f\"Num classes: {num_classes}\"", ")", "\n", "\n", "# Build network", "\n", "base_network", "=", "resnet", ".", "ResNetFc", "(", "\n", "resnet_name", "=", "net_name", ",", "\n", "num_classes", "=", "num_classes", ",", "\n", "plug_position", "=", "7", ",", "\n", "**", "net_args", "\n", ")", ".", "to", "(", "dev", ")", "\n", "params", "=", "base_network", ".", "get_parameters", "(", "lr", ",", "wd", ")", "\n", "# Source only has no secondary branches", "\n", "if", "da_method", "!=", "'so'", ":", "\n", "        ", "disc_classes", "=", "{", "\n", "# ( -> confusion matrix)", "\n", "'alda'", ":", "num_classes", ",", "\n", "# ( -> binary domain classifier)", "\n", "'dann'", ":", "2", "\n", "}", "[", "da_method", "]", "\n", "discriminator", "=", "resnet", ".", "Discriminator", "(", "in_feature", "=", "base_network", ".", "output_size", "(", ")", ",", "num_classes", "=", "disc_classes", ",", "\n", "**", "disc_args", ")", ".", "to", "(", "dev", ")", "\n", "params", "+=", "discriminator", ".", "get_parameters", "(", "lr", ",", "wd", ")", "\n", "\n", "# Define optimizer", "\n", "", "optimizer", "=", "opt", ".", "SGD", "(", "\n", "params", "=", "params", ",", "\n", "lr", "=", "lr", ",", "\n", "momentum", "=", "0.9", ",", "\n", "weight_decay", "=", "wd", ",", "\n", "nesterov", "=", "True", "\n", ")", "\n", "\n", "# Lr policy", "\n", "lr_schedule", "=", "LambdaLR", "(", "optimizer", ",", "lr_lambda", "=", "lambda", "it", ":", "(", "1", "+", "0.001", "*", "it", ")", "**", "(", "-", "0.75", ")", ")", "\n", "\n", "# Logger", "\n", "writer", "=", "Logger", "(", "logdir", "=", "logdir", ",", "run_name", "=", "run_name", ",", "use_tb", "=", "True", ",", "use_tqdm", "=", "use_tqdm", ")", "\n", "\n", "# Classification loss", "\n", "ce_loss", "=", "nn", ".", "CrossEntropyLoss", "(", ")", "\n", "\n", "# Train loop", "\n", "len_train_source", "=", "len", "(", "dload_src_train", ")", "\n", "len_train_target", "=", "len", "(", "dload_trg_train", ")", "\n", "lambda_val", "=", "0.", "\n", "\n", "# We store all the metrics here", "\n", "metrics", "=", "[", "]", "\n", "\n", "all_pseudolabels", "=", "[", "]", "\n", "\n", "with", "writer", ".", "progress", "(", "total", "=", "stop_iter", ",", "desc", "=", "\"Training\"", ")", "as", "pb", ":", "\n", "        ", "for", "i", "in", "range", "(", "stop_iter", ")", ":", "\n", "            ", "if", "(", "i", "+", "1", ")", "%", "test_iter", "==", "0", ":", "\n", "                ", "print", "(", "f\"Iteration: {i + 1} / {stop_iter} (max: {max_iter})\"", ")", "\n", "print", "(", "\"Testing...\"", ")", "\n", "base_network", ".", "train", "(", "False", ")", "\n", "# This dict contains metric-name -> value pairs for the current epoch", "\n", "new_metrics", "=", "{", "}", "\n", "if", "test_src", ":", "\n", "                    ", "test_result", ",", "_", ",", "src_test_feats", "=", "test", "(", "dload_src_test", ",", "base_network", ",", "device", "=", "dev", ")", "\n", "# Print accuracy", "\n", "print", "(", "\"Source accuracy: {:.3f} %\"", ".", "format", "(", "test_result", "[", "'accuracy'", "]", "*", "100", ")", ")", "\n", "# Add the source metrics to the dict (with the source_ prefix)", "\n", "new_metrics", ".", "update", "(", "{", "f'source_{k}'", ":", "v", "for", "k", ",", "v", "in", "test_result", ".", "items", "(", ")", "}", ")", "\n", "\n", "", "test_result", ",", "epoch_pseudolabels", ",", "_", "=", "test", "(", "dload_trg_test", ",", "base_network", ",", "device", "=", "dev", ",", "\n", "source_feats", "=", "src_test_feats", ")", "\n", "all_pseudolabels", ".", "append", "(", "epoch_pseudolabels", ")", "\n", "print", "(", "f\"Target accuracy: {test_result['accuracy'] * 100:.3f} %\"", ")", "\n", "\n", "writer", ".", "add_scalar", "(", "'train/base_lr'", ",", "lr_schedule", ".", "get_last_lr", "(", ")", "[", "0", "]", ",", "i", ")", "\n", "writer", ".", "add_scalar", "(", "'train/lambda'", ",", "lambda_val", ",", "i", ")", "\n", "\n", "new_metrics", ".", "update", "(", "{", "f'target_{k}'", ":", "v", "for", "k", ",", "v", "in", "test_result", ".", "items", "(", ")", "}", ")", "\n", "\n", "# Add all the new metrics to tensorboard logs", "\n", "add_scalars", "(", "writer", ",", "new_metrics", ",", "global_step", "=", "i", ",", "prefix", "=", "'test/'", ")", "\n", "# Add a column with iteration number", "\n", "new_metrics", ".", "update", "(", "{", "'iter'", ":", "i", "}", ")", "\n", "# Concatenate to older epoch metrics", "\n", "metrics", ".", "append", "(", "new_metrics", ")", "\n", "\n", "# Kill this training if source loss goes too high", "\n", "if", "kill_diverging", "and", "new_metrics", "[", "'source_class_loss'", "]", ">", "SOURCE_LOSS_THRESHOLD", ":", "\n", "                    ", "if", "len", "(", "metrics", ")", ">", "0", "and", "new_metrics", "[", "'source_class_loss'", "]", ">", "metrics", "[", "-", "1", "]", "[", "'source_class_loss'", "]", ":", "\n", "                        ", "print", "(", "f\"Increasing source_class_loss exceeds maximum allowed source loss ({new_metrics['source_class_loss']} > {SOURCE_LOSS_THRESHOLD})\"", ")", "\n", "break", "\n", "\n", "# Train one iteration", "\n", "", "", "", "base_network", ".", "train", "(", "True", ")", "\n", "if", "da_method", "!=", "'so'", ":", "\n", "                ", "discriminator", ".", "train", "(", "True", ")", "\n", "\n", "", "optimizer", ".", "zero_grad", "(", ")", "\n", "\n", "# Reset data loops if required", "\n", "if", "i", "%", "len_train_source", "==", "0", ":", "\n", "                ", "iter_source", "=", "iter", "(", "dload_src_train", ")", "\n", "", "if", "i", "%", "len_train_target", "==", "0", ":", "\n", "                ", "iter_target", "=", "iter", "(", "dload_trg_train", ")", "\n", "\n", "# Load source", "\n", "", "inputs_source", ",", "labels_source", "=", "iter_source", ".", "next", "(", ")", "\n", "inputs_source", ",", "labels_source", "=", "map_to_device", "(", "dev", ",", "(", "inputs_source", ",", "labels_source", ")", ")", "\n", "\n", "# Compute source features and classification output", "\n", "outputs_source", ",", "features_source", "=", "base_network", "(", "inputs_source", ")", "\n", "\n", "# Classification loss", "\n", "classifier_loss", "=", "ce_loss", "(", "outputs_source", ",", "labels_source", ")", "\n", "\n", "# Actual DA part", "\n", "if", "da_method", "!=", "'so'", ":", "\n", "# Load target samples without target labels", "\n", "                ", "inputs_target", ",", "_", "=", "iter_target", ".", "next", "(", ")", "\n", "inputs_target", "=", "inputs_target", ".", "to", "(", "dev", ")", "\n", "\n", "# Compute target features and classification output", "\n", "outputs_target", ",", "features_target", "=", "base_network", "(", "inputs_target", ")", "\n", "\n", "# Source and target features", "\n", "features", "=", "torch", ".", "cat", "(", "(", "features_source", ",", "features_target", ")", ",", "dim", "=", "0", ")", "\n", "# Source and target classification outputs (-> softmax)", "\n", "outputs", "=", "torch", ".", "cat", "(", "(", "outputs_source", ",", "outputs_target", ")", ",", "dim", "=", "0", ")", "\n", "softmax_out", "=", "nn", ".", "Softmax", "(", "dim", "=", "1", ")", "(", "outputs", ")", "\n", "\n", "# CORE", "\n", "if", "da_method", "==", "'dann'", ":", "\n", "                    ", "p", "=", "float", "(", "i", "/", "max_iter", ")", "\n", "lambda_val", "=", "2.", "/", "(", "1", "+", "np", ".", "exp", "(", "-", "10", "*", "p", ")", ")", "-", "1", "\n", "ad_out", "=", "discriminator", "(", "features", ",", "lambda_val", ")", "\n", "adv_loss", "=", "loss", ".", "DANN_loss", "(", "ad_out", ")", "\n", "transfer_loss", "=", "adv_loss", "\n", "if", "(", "i", "+", "1", ")", "%", "test_iter", "==", "0", ":", "\n", "                        ", "print", "(", "\"Transfer loss: {:.3f}\"", ".", "format", "(", "transfer_loss", ".", "item", "(", ")", ")", ")", "\n", "", "", "elif", "da_method", "==", "'alda'", ":", "\n", "                    ", "p", "=", "float", "(", "i", "/", "max_iter", ")", "\n", "lambda_val", "=", "2.", "/", "(", "1", "+", "np", ".", "exp", "(", "-", "10", "*", "p", ")", ")", "-", "1", "\n", "ad_out", "=", "discriminator", "(", "features", ",", "lambda_val", ")", "\n", "adv_loss", ",", "reg_loss", ",", "correct_loss", "=", "loss", ".", "ALDA_loss", "(", "ad_out", ",", "labels_source", ",", "softmax_out", ",", "threshold", "=", "0.9", ")", "\n", "\n", "transfer_loss", "=", "adv_loss", "+", "lambda_val", "*", "correct_loss", "\n", "if", "(", "i", "+", "1", ")", "%", "test_iter", "==", "0", ":", "\n", "                        ", "print", "(", "\"Transfer loss: {:.3f}, reg loss  {:.3f}%\"", ".", "format", "(", "transfer_loss", ".", "item", "(", ")", ",", "\n", "reg_loss", ".", "item", "(", ")", ")", ")", "\n", "# Backpropagate reg_loss only through the discriminator", "\n", "", "with", "base_network", ".", "freeze", "(", ")", ":", "\n", "                        ", "reg_loss", ".", "backward", "(", "retain_graph", "=", "True", ")", "\n", "# END CORE", "\n", "", "", "", "else", ":", "\n", "                ", "transfer_loss", "=", "0", "\n", "\n", "", "total_loss", "=", "classifier_loss", "+", "config", "[", "'base'", "]", "[", "'weight_da'", "]", "*", "transfer_loss", "\n", "total_loss", ".", "backward", "(", ")", "\n", "\n", "optimizer", ".", "step", "(", ")", "\n", "lr_schedule", ".", "step", "(", ")", "\n", "\n", "if", "(", "i", "+", "1", ")", "%", "test_iter", "==", "0", "and", "da_method", "!=", "'so'", ":", "\n", "                ", "writer", ".", "add_scalar", "(", "'train/transfer_loss'", ",", "transfer_loss", ".", "item", "(", ")", ",", "i", ")", "\n", "", "pb", ".", "update", "(", "1", ")", "\n", "\n", "# Convert list of dicts to dataframe containing metrics", "\n", "", "", "metrics", "=", "pd", ".", "DataFrame", "(", "metrics", ")", "\n", "\n", "# Compute global-pseudolabel accuracy", "\n", "all_pseudolabels", "=", "np", ".", "array", "(", "all_pseudolabels", ")", "\n", "global_pseudolabels", "=", "compute_time_consistent_pseudolabels", "(", "all_pseudolabels", ",", "num_classes", ")", "\n", "pseudolabel_acc", "=", "np", ".", "equal", "(", "all_pseudolabels", ",", "global_pseudolabels", ")", ".", "sum", "(", "axis", "=", "1", ")", "/", "global_pseudolabels", ".", "shape", "[", "0", "]", "\n", "# Add it to the metrics dataframe", "\n", "metrics", "[", "'target_pseudolabels'", "]", "=", "pseudolabel_acc", "\n", "\n", "# Save the metrics", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "logdir", ",", "run_name", ",", "\"metrics.pkl\"", ")", ",", "\"wb\"", ")", "as", "fp", ":", "\n", "        ", "pickle", ".", "dump", "(", "metrics", ",", "fp", ")", "\n", "\n", "# Log global pseudolabel accuracy to tensorboard", "\n", "", "for", "i", "in", "range", "(", "len", "(", "all_pseudolabels", ")", ")", ":", "\n", "        ", "writer", ".", "add_scalar", "(", "'test/target_pseudolabels'", ",", "float", "(", "pseudolabel_acc", "[", "i", "]", ")", ",", "i", "*", "test_iter", ")", "\n", "\n", "", "return", "metrics", "\n", "\n"]], "home.repos.pwc.inspect_result.lr94_abas.None.train_model.main": [[346, 400], ["argparse.ArgumentParser", "utils.add_base_args", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "print", "print", "utils.print_args", "config.update", "train_model.run_training", "train_model.get_default_run_name"], "function", ["home.repos.pwc.inspect_result.lr94_abas.None.utils.add_base_args", "home.repos.pwc.inspect_result.lr94_abas.None.abas.parse_args", "home.repos.pwc.inspect_result.lr94_abas.None.utils.print_args", "home.repos.pwc.inspect_result.lr94_abas.None.train_model.run_training", "home.repos.pwc.inspect_result.lr94_abas.None.train_model.get_default_run_name"], ["", "def", "main", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "\n", "add_base_args", "(", "parser", ")", "\n", "parser", ".", "add_argument", "(", "'--stop-iter'", ",", "type", "=", "int", ",", "default", "=", "None", ",", "help", "=", "\"Stop after n iterations\"", ")", "\n", "parser", ".", "add_argument", "(", "'--run-name'", ",", "type", "=", "str", ",", "default", "=", "None", ",", "help", "=", "\"Experiment name\"", ")", "\n", "parser", ".", "add_argument", "(", "'--run-suffix'", ",", "type", "=", "str", ",", "default", "=", "''", ")", "\n", "parser", ".", "add_argument", "(", "'--weight-da'", ",", "type", "=", "float", ",", "default", "=", "1.", ",", "help", "=", "\"Weight for Domain Adaptation loss\"", ")", "\n", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "args", ".", "stop_iter", "=", "args", ".", "stop_iter", "or", "args", ".", "max_iter", "\n", "\n", "run_name", "=", "(", "args", ".", "run_name", "or", "get_default_run_name", "(", "args", ")", ")", "+", "(", "\n", "(", "'_'", "+", "args", ".", "run_suffix", ")", "if", "args", ".", "run_suffix", "!=", "''", "else", "''", ")", "\n", "print", "(", "\"Starting {}\"", ".", "format", "(", "run_name", ")", ")", "\n", "\n", "print", "(", "f\"{args.source} -> {args.target}\"", ")", "\n", "print_args", "(", "args", ",", "(", "\n", "'net'", ",", "\n", "'bs'", ",", "\n", "'lr'", ",", "\n", "'wd'", ",", "\n", "'stop_iter'", ",", "\n", "'max_iter'", ",", "\n", "'gpu'", "\n", ")", ")", "\n", "\n", "config", "=", "{", "\n", "'base.bs'", ":", "args", ".", "bs", ",", "\n", "'base.lr'", ":", "args", ".", "lr", ",", "\n", "'base.wd'", ":", "args", ".", "wd", ",", "\n", "'base.weight_da'", ":", "args", ".", "weight_da", ",", "\n", "}", "\n", "config", ".", "update", "(", "args", ".", "config", ")", "\n", "\n", "run_training", "(", "\n", "source", "=", "args", ".", "source", ",", "\n", "target", "=", "args", ".", "target", ",", "\n", "dataset_root", "=", "args", ".", "data_root", ",", "\n", "net_name", "=", "args", ".", "net", ",", "\n", "da_method", "=", "args", ".", "da", ",", "\n", "config", "=", "config", ",", "\n", "max_iter", "=", "args", ".", "max_iter", ",", "\n", "stop_iter", "=", "args", ".", "stop_iter", ",", "\n", "test_iter", "=", "args", ".", "test_iter", ",", "\n", "logdir", "=", "args", ".", "logdir", ",", "\n", "run_name", "=", "run_name", ",", "\n", "gpu_id", "=", "args", ".", "gpu", ",", "\n", "load_workers", "=", "args", ".", "load_workers", ",", "\n", "\n", "use_tqdm", "=", "not", "args", ".", "no_tqdm", ",", "\n", "test_src", "=", "not", "args", ".", "no_test_source", ",", "\n", "kill_diverging", "=", "args", ".", "kill_diverging", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.lr94_abas.None.analysis.nice_print": [[15, 17], ["print"], "function", ["None"], ["def", "nice_print", "(", "left", ",", "right", ")", ":", "\n", "    ", "print", "(", "\"{:>30} : {}\"", ".", "format", "(", "left", ",", "right", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.lr94_abas.None.analysis.sensitivity_plot": [[19, 44], ["matplotlib.get_cmap", "matplotlib.figure", "enumerate", "matplotlib.legend", "matplotlib.tight_layout", "matplotlib.Patch", "matplotlib.subplot", "matplotlib.title", "enumerate", "budget_map.keys", "[].mean().mean", "matplotlib.scatter", "set", "cmap", "warnings.warn", "len", "[].mean", "cmap", "numpy.array"], "function", ["None"], ["", "def", "sensitivity_plot", "(", "runs", ",", "id2conf", ",", "cvars", ",", "cmap", "=", "plt", ".", "get_cmap", "(", "'tab10'", ")", ",", "min_budget", "=", "0", ")", ":", "\n", "    ", "budget_map", "=", "{", "b", ":", "i", "for", "i", ",", "b", "in", "enumerate", "(", "set", "(", "[", "r", ".", "budget", "for", "r", "in", "runs", "]", ")", ")", "}", "\n", "handles", "=", "[", "mpatches", ".", "Patch", "(", "color", "=", "cmap", "(", "budget_map", "[", "b", "]", ")", ",", "label", "=", "f'{b}'", ")", "for", "b", "in", "budget_map", ".", "keys", "(", ")", "]", "\n", "\n", "fig", "=", "plt", ".", "figure", "(", "figsize", "=", "(", "8", ",", "8", ")", ")", "\n", "\n", "for", "i", ",", "var", "in", "enumerate", "(", "cvars", ")", ":", "\n", "        ", "plt", ".", "subplot", "(", "len", "(", "cvars", ")", "//", "2", "+", "1", ",", "2", ",", "i", "+", "1", ")", "\n", "\n", "for", "run", "in", "runs", ":", "\n", "            ", "if", "run", ".", "info", "is", "None", ":", "\n", "                ", "warnings", ".", "warn", "(", "\"Found run with null info! Ignoring it.\"", ")", "\n", "continue", "\n", "", "if", "run", ".", "budget", "<", "min_budget", ":", "\n", "                ", "continue", "\n", "", "conf", "=", "id2conf", "[", "run", ".", "config_id", "]", "[", "'config'", "]", "\n", "acc", "=", "np", ".", "array", "(", "[", "x", "[", "'target_accuracy'", "]", "for", "x", "in", "run", ".", "info", "[", "'single_info'", "]", "]", ")", "[", ":", ",", "-", "2", ":", "]", ".", "mean", "(", "axis", "=", "1", ")", ".", "mean", "(", "axis", "=", "0", ")", "\n", "plt", ".", "scatter", "(", "conf", "[", "var", "]", ",", "acc", ",", "\n", "color", "=", "cmap", "(", "budget_map", "[", "run", ".", "budget", "]", ")", ",", "alpha", "=", "0.9", ")", "\n", "\n", "", "plt", ".", "title", "(", "var", ")", "\n", "\n", "", "plt", ".", "legend", "(", "handles", "=", "handles", ")", "\n", "plt", ".", "tight_layout", "(", ")", "\n", "return", "fig", "\n", "\n"]], "home.repos.pwc.inspect_result.lr94_abas.None.analysis.main": [[46, 186], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "os.path.isfile", "hpres.logged_results_to_HBS_result.get_all_runs", "hpres.logged_results_to_HBS_result.get_id2config_mapping", "hpres.logged_results_to_HBS_result.get_incumbent_id", "hpres.logged_results_to_HBS_result.get_runs_by_id", "numpy.array().mean", "numpy.array", "print", "analysis.nice_print", "print", "print", "analysis.nice_print", "analysis.nice_print", "analysis.nice_print", "print", "print", "analysis.nice_print", "list", "analysis.nice_print", "analysis.nice_print", "analysis.nice_print", "sum", "analysis.nice_print", "print", "print", "hpbandster.losses_over_time", "hpbandster.concurrent_runs_over_time", "hpbandster.finished_runs_over_time", "hpbandster.correlation_across_budgets", "hpbandster.performance_histogram_model_vs_random", "analysis.sensitivity_plot", "os.path.dirname", "os.path.isdir", "numpy.array", "np.array.argmin", "chosen_accs.append", "np.array.append", "analysis.nice_print", "criterion_names.get", "datetime.timedelta", "map", "len", "datetime.timedelta", "datetime.timedelta", "datetime.timedelta", "matplotlib.savefig", "matplotlib.savefig", "matplotlib.savefig", "matplotlib.savefig", "matplotlib.savefig", "matplotlib.savefig", "matplotlib.show", "os.path.abspath", "os.path.splitext", "open", "pickle.load", "hpbandster.logged_results_to_HBS_result", "print", "numpy.array", "map", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.basename", "max", "min", "np.array.max"], "function", ["home.repos.pwc.inspect_result.lr94_abas.None.abas.parse_args", "home.repos.pwc.inspect_result.lr94_abas.None.analysis.nice_print", "home.repos.pwc.inspect_result.lr94_abas.None.analysis.nice_print", "home.repos.pwc.inspect_result.lr94_abas.None.analysis.nice_print", "home.repos.pwc.inspect_result.lr94_abas.None.analysis.nice_print", "home.repos.pwc.inspect_result.lr94_abas.None.analysis.nice_print", "home.repos.pwc.inspect_result.lr94_abas.None.analysis.nice_print", "home.repos.pwc.inspect_result.lr94_abas.None.analysis.nice_print", "home.repos.pwc.inspect_result.lr94_abas.None.analysis.nice_print", "home.repos.pwc.inspect_result.lr94_abas.None.analysis.nice_print", "home.repos.pwc.inspect_result.lr94_abas.None.analysis.sensitivity_plot", "home.repos.pwc.inspect_result.lr94_abas.None.analysis.nice_print"], ["", "def", "main", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "parser", ".", "add_argument", "(", "'--result'", ",", "type", "=", "str", ",", "required", "=", "True", ",", "help", "=", "\"Final result Pickle file or master directory (for running experiments)\"", ")", "\n", "parser", ".", "add_argument", "(", "'--mode'", ",", "type", "=", "str", ",", "choices", "=", "(", "'save'", ",", "'show'", ",", "'disable'", ")", ",", "default", "=", "'disable'", ",", "help", "=", "\"Plot mode\"", ")", "\n", "parser", ".", "add_argument", "(", "'--out-path'", ",", "type", "=", "str", ",", "default", "=", "None", ",", "help", "=", "\"Default output path for plots\"", ")", "\n", "parser", ".", "add_argument", "(", "'--dpi'", ",", "type", "=", "int", ",", "default", "=", "150", ",", "help", "=", "\"Plot resolution\"", ")", "\n", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "# load run results", "\n", "if", "os", ".", "path", ".", "isfile", "(", "args", ".", "result", ")", ":", "\n", "        ", "default_out_path", "=", "os", ".", "path", ".", "dirname", "(", "os", ".", "path", ".", "abspath", "(", "args", ".", "result", ")", ")", "\n", "exp_name", "=", "os", ".", "path", ".", "splitext", "(", "os", ".", "path", ".", "basename", "(", "args", ".", "result", ")", ")", "[", "0", "]", "\n", "with", "open", "(", "args", ".", "result", ",", "'rb'", ")", "as", "fp", ":", "\n", "            ", "result", "=", "pickle", ".", "load", "(", "fp", ")", "\n", "", "", "elif", "os", ".", "path", ".", "isdir", "(", "args", ".", "result", ")", ":", "\n", "        ", "default_out_path", "=", "args", ".", "result", "\n", "exp_name", "=", "'exp'", "\n", "result", "=", "hpres", ".", "logged_results_to_HBS_result", "(", "args", ".", "result", ")", "\n", "", "else", ":", "\n", "        ", "print", "(", "\"No input specified. Use --result\"", ")", "\n", "return", "\n", "\n", "", "save_figs", "=", "args", ".", "mode", "is", "None", "or", "args", ".", "mode", "==", "'save'", "\n", "show_figs", "=", "args", ".", "mode", "is", "None", "or", "args", ".", "mode", "==", "'show'", "\n", "\n", "# File path", "\n", "out_path", "=", "args", ".", "out_path", "or", "default_out_path", "\n", "\n", "# Get all executed runs", "\n", "all_runs", "=", "result", ".", "get_all_runs", "(", ")", "\n", "\n", "# Get the 'dict' that translates config ids to the actual configurations", "\n", "id2conf", "=", "result", ".", "get_id2config_mapping", "(", ")", "\n", "\n", "# Here is how you get he incumbent (best configuration)", "\n", "inc_id", "=", "result", ".", "get_incumbent_id", "(", ")", "\n", "\n", "# let's grab the run on the highest budget", "\n", "inc_runs", "=", "result", ".", "get_runs_by_id", "(", "inc_id", ")", "\n", "inc_run", "=", "inc_runs", "[", "-", "1", "]", "\n", "\n", "# We have access to all information: the config, the loss observed during", "\n", "# optimization, and all the additional information", "\n", "inc_loss", "=", "inc_run", ".", "loss", "\n", "inc_config", "=", "id2conf", "[", "inc_id", "]", "[", "'config'", "]", "\n", "\n", "# Each run contains one or more trainings", "\n", "# chosen_accs: list of the chosen best model accuracy (according to the bohb loss) for each single training", "\n", "chosen_accs", "=", "[", "]", "\n", "\n", "all_accs", "=", "[", "]", "\n", "for", "single_info", "in", "inc_run", ".", "info", "[", "'single_info'", "]", ":", "\n", "# All the BOHB losses of this training (one per epoch)", "\n", "        ", "bohb_losses", "=", "np", ".", "array", "(", "single_info", "[", "'bohb_losses'", "]", ")", "\n", "# Let's find the best one", "\n", "best_index", "=", "bohb_losses", ".", "argmin", "(", ")", "\n", "# Add the best model (according to the bohb loss) accuracy to chosen_accs", "\n", "chosen_accs", ".", "append", "(", "single_info", "[", "'target_accuracy'", "]", "[", "best_index", "]", ")", "\n", "# Add all the accuracies of all the epochs of this training", "\n", "all_accs", ".", "append", "(", "single_info", "[", "'target_accuracy'", "]", ")", "\n", "# Get mean accuracy for this run (average the selected models for each training)", "\n", "", "acc", "=", "np", ".", "array", "(", "chosen_accs", ")", ".", "mean", "(", ")", "\n", "# Matrix containing ALL the target accuracies of all the epochs of all the trainings of this run", "\n", "all_accs", "=", "np", ".", "array", "(", "all_accs", ")", "\n", "\n", "# Print best configuration", "\n", "print", "(", "'Best found configuration:'", ")", "\n", "for", "k", "in", "inc_config", ":", "\n", "        ", "nice_print", "(", "k", ",", "inc_config", "[", "k", "]", ")", "\n", "", "nice_print", "(", "'inc_id'", ",", "'-'", ".", "join", "(", "map", "(", "str", ",", "inc_id", ")", ")", ")", "\n", "\n", "print", "(", ")", "\n", "print", "(", "\"Performance:\"", ")", "\n", "criterion_names", "=", "{", "\n", "'regression'", ":", "'Regression'", ",", "\n", "'target_accuracy'", ":", "'Trg accuracy'", ",", "\n", "'target_entropy_loss'", ":", "'Trg entropy'", ",", "\n", "'target_div_loss'", ":", "'Trg diversity'", ",", "\n", "'target_class_loss'", ":", "'Trg class. loss'", ",", "\n", "'target_silhouette_score'", ":", "'Trg Silhouette'", ",", "\n", "'target_calinski_harabasz_score'", ":", "'Trg Calinski-Harabasz'", "\n", "}", "\n", "# Print info", "\n", "cname", "=", "inc_run", ".", "info", "[", "'criterion'", "]", "\n", "nice_print", "(", "criterion_names", ".", "get", "(", "cname", ",", "cname", ")", ",", "f\"{inc_loss:.10f}\"", ")", "\n", "nice_print", "(", "\"Accuracy\"", ",", "f\"{acc * 100:.4f} % (mean of each selected model in selected conf run trainings)\"", ")", "\n", "nice_print", "(", "\"Accuracy\"", ",", "f\"{all_accs.max(initial=-1) * 100:.4f} % (best in selected run, you shouldn't know this)\"", ")", "\n", "\n", "print", "(", ")", "\n", "print", "(", "\"Resources:\"", ")", "\n", "nice_print", "(", "\"Total time\"", ",", "datetime", ".", "timedelta", "(", "seconds", "=", "all_runs", "[", "-", "1", "]", ".", "time_stamps", "[", "'finished'", "]", "-", "all_runs", "[", "0", "]", ".", "time_stamps", "[", "'started'", "]", ")", ")", "\n", "durations", "=", "list", "(", "map", "(", "lambda", "r", ":", "r", ".", "time_stamps", "[", "'finished'", "]", "-", "r", ".", "time_stamps", "[", "'started'", "]", ",", "all_runs", ")", ")", "\n", "nice_print", "(", "\"Number of runs\"", ",", "len", "(", "all_runs", ")", ")", "\n", "nice_print", "(", "\"Longest run\"", ",", "datetime", ".", "timedelta", "(", "seconds", "=", "max", "(", "durations", ")", ")", ")", "\n", "nice_print", "(", "\"Shortest run\"", ",", "datetime", ".", "timedelta", "(", "seconds", "=", "min", "(", "durations", ")", ")", ")", "\n", "\n", "gpu_seconds", "=", "sum", "(", "[", "r", ".", "time_stamps", "[", "'finished'", "]", "-", "r", ".", "time_stamps", "[", "'started'", "]", "for", "r", "in", "all_runs", "]", ")", "\n", "nice_print", "(", "\"GPU time\"", ",", "datetime", ".", "timedelta", "(", "seconds", "=", "gpu_seconds", ")", ")", "\n", "\n", "if", "not", "(", "save_figs", "or", "show_figs", ")", ":", "\n", "        ", "return", "\n", "\n", "", "print", "(", ")", "\n", "print", "(", "\"Generating plots\"", ")", "\n", "\n", "# Let's plot the observed losses grouped by budget,", "\n", "hpvis", ".", "losses_over_time", "(", "all_runs", ")", "\n", "if", "save_figs", ":", "\n", "        ", "plt", ".", "savefig", "(", "os", ".", "path", ".", "join", "(", "out_path", ",", "'loss-over-time_{}.png'", ".", "format", "(", "exp_name", ")", ")", ",", "dpi", "=", "args", ".", "dpi", ")", "\n", "\n", "# the number of concurrent runs,", "\n", "", "hpvis", ".", "concurrent_runs_over_time", "(", "all_runs", ")", "\n", "if", "save_figs", ":", "\n", "        ", "plt", ".", "savefig", "(", "os", ".", "path", ".", "join", "(", "out_path", ",", "'concurrent-runs_{}.png'", ".", "format", "(", "exp_name", ")", ")", ",", "dpi", "=", "args", ".", "dpi", ")", "\n", "\n", "# and the number of finished runs.", "\n", "", "hpvis", ".", "finished_runs_over_time", "(", "all_runs", ")", "\n", "if", "save_figs", ":", "\n", "        ", "plt", ".", "savefig", "(", "os", ".", "path", ".", "join", "(", "out_path", ",", "'finished-runs_{}.png'", ".", "format", "(", "exp_name", ")", ")", ",", "dpi", "=", "args", ".", "dpi", ")", "\n", "\n", "# This one visualizes the spearman rank correlation coefficients of the losses", "\n", "# between different budgets.", "\n", "", "hpvis", ".", "correlation_across_budgets", "(", "result", ")", "\n", "if", "save_figs", ":", "\n", "        ", "plt", ".", "savefig", "(", "os", ".", "path", ".", "join", "(", "out_path", ",", "'correlation_{}.png'", ".", "format", "(", "exp_name", ")", ")", ",", "dpi", "=", "args", ".", "dpi", ")", "\n", "\n", "# For model based optimizers, one might wonder how much the model actually helped.", "\n", "# The next plot compares the performance of configs picked by the model vs. random ones", "\n", "", "hpvis", ".", "performance_histogram_model_vs_random", "(", "all_runs", ",", "id2conf", ")", "\n", "if", "save_figs", ":", "\n", "        ", "plt", ".", "savefig", "(", "os", ".", "path", ".", "join", "(", "out_path", ",", "'model-vs-random_{}.png'", ".", "format", "(", "exp_name", ")", ")", ",", "dpi", "=", "args", ".", "dpi", ")", "\n", "\n", "", "sensitivity_plot", "(", "all_runs", ",", "id2conf", ",", "cvars", "=", "(", "'disc.num_fc_layers'", ",", "'disc.hidden_size_log'", ",", "'disc.dropout'", ",", "\n", "'net.bottleneck_size_log'", ",", "'base.weight_da'", ")", ")", "\n", "if", "save_figs", ":", "\n", "        ", "plt", ".", "savefig", "(", "os", ".", "path", ".", "join", "(", "out_path", ",", "'sensitivity_{}.png'", ".", "format", "(", "exp_name", ")", ")", ",", "dpi", "=", "args", ".", "dpi", ")", "\n", "\n", "", "if", "show_figs", ":", "\n", "        ", "plt", ".", "show", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.lr94_abas.None.logger.Logger.__init__": [[8, 17], ["torch.utils.tensorboard.SummaryWriter", "os.path.join"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "logdir", ":", "str", "=", "'tensorboard'", ",", "run_name", "=", "None", ",", "use_tb", ":", "bool", "=", "True", ",", "use_tqdm", ":", "bool", "=", "True", ",", "\n", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "self", ".", "use_tb", "=", "use_tb", "\n", "self", ".", "use_tqdm", "=", "use_tqdm", "\n", "self", ".", "epoch", "=", "0", "\n", "\n", "if", "use_tb", ":", "\n", "            ", "log_path", "=", "logdir", "if", "run_name", "is", "None", "else", "os", ".", "path", ".", "join", "(", "logdir", ",", "run_name", ")", "\n", "self", ".", "summary_writer", "=", "SummaryWriter", "(", "log_dir", "=", "log_path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.lr94_abas.None.logger.Logger.progress": [[18, 46], ["tqdm.tqdm.tqdm", "ProgressIndicator", "print", "print", "int", "print"], "methods", ["None"], ["", "", "def", "progress", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "if", "self", ".", "use_tqdm", ":", "\n", "            ", "return", "tqdm", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "", "else", ":", "\n", "# Alternative output if tqdm is not enabled", "\n", "            ", "class", "ProgressIndicator", ":", "\n", "                ", "def", "__init__", "(", "self", ",", "total", ":", "int", ",", "desc", ":", "str", "=", "\"\"", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "                    ", "self", ".", "total", "=", "total", "\n", "self", ".", "desc", "=", "desc", "\n", "self", ".", "counter", "=", "0", "\n", "self", ".", "old_line", "=", "''", "\n", "\n", "", "def", "__enter__", "(", "self", ")", ":", "\n", "                    ", "print", "(", "\"Starting {}\"", ".", "format", "(", "self", ".", "desc", ")", ")", "\n", "return", "self", "\n", "\n", "", "def", "__exit__", "(", "self", ",", "exc_type", ",", "exc_val", ",", "exc_tb", ")", ":", "\n", "                    ", "print", "(", "\"Done {}\"", ".", "format", "(", "self", ".", "desc", ")", ")", "\n", "\n", "", "def", "update", "(", "self", ",", "n", ":", "int", ")", ":", "\n", "                    ", "self", ".", "counter", "+=", "n", "\n", "line", "=", "\"{} ({} %)\"", ".", "format", "(", "self", ".", "desc", ",", "\n", "int", "(", "self", ".", "counter", "/", "self", ".", "total", "*", "100", ")", ")", "\n", "if", "line", "!=", "self", ".", "old_line", ":", "\n", "                        ", "print", "(", "line", ")", "\n", "self", ".", "old_line", "=", "line", "\n", "\n", "", "", "", "return", "ProgressIndicator", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.lr94_abas.None.logger.Logger.add_scalar": [[47, 50], ["logger.Logger.summary_writer.add_scalar"], "methods", ["home.repos.pwc.inspect_result.lr94_abas.None.logger.Logger.add_scalar"], ["", "", "def", "add_scalar", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "if", "self", ".", "use_tb", ":", "\n", "            ", "self", ".", "summary_writer", ".", "add_scalar", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.lr94_abas.None.abas.AbasWorker.__init__": [[22, 42], ["hpbandster.core.worker.Worker.__init__"], "methods", ["home.repos.pwc.inspect_result.lr94_abas.net.resnet.Discriminator.__init__"], ["    ", "def", "__init__", "(", "self", ",", "run_id", ":", "str", ",", "gpu", ":", "int", ",", "source", ",", "target", ",", "net", ",", "load_workers", ",", "max_iter", ",", "logdir", ",", "ds_root", ",", "\n", "run_n_avg", ",", "no_tqdm", ",", "da_method", ",", "model_criterion", ":", "ModelCriterion", ",", "run_model_criterion", ":", "ModelCriterion", ",", "\n", "kill_diverging", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "run_id", ",", "args", ",", "**", "kwargs", ")", "\n", "self", ".", "run_id", "=", "run_id", "\n", "self", ".", "gpu", "=", "gpu", "\n", "self", ".", "source", "=", "source", "\n", "self", ".", "target", "=", "target", "\n", "self", ".", "net", "=", "net", "\n", "self", ".", "load_workers", "=", "load_workers", "\n", "self", ".", "max_iter", "=", "max_iter", "\n", "self", ".", "logdir", "=", "logdir", "\n", "self", ".", "ds_root", "=", "ds_root", "\n", "self", ".", "run_n_avg", "=", "run_n_avg", "\n", "self", ".", "da_method", "=", "da_method", "\n", "self", ".", "model_criterion", "=", "model_criterion", "\n", "self", ".", "run_model_criterion", "=", "run_model_criterion", "\n", "self", ".", "kill_diverging", "=", "kill_diverging", "\n", "\n", "self", ".", "no_tqdm", "=", "no_tqdm", "\n", "\n"]], "home.repos.pwc.inspect_result.lr94_abas.None.abas.AbasWorker.get_configspace": [[43, 61], ["ConfigSpace.ConfigurationSpace", "ConfigSpace.ConfigurationSpace.add_hyperparameter", "ConfigSpace.ConfigurationSpace.add_hyperparameter", "ConfigSpace.ConfigurationSpace.add_hyperparameter", "ConfigSpace.ConfigurationSpace.add_hyperparameter", "ConfigSpace.ConfigurationSpace.add_hyperparameter", "ConfigSpace.ConfigurationSpace.add_hyperparameter", "ConfigSpace.UniformIntegerHyperparameter", "ConfigSpace.UniformIntegerHyperparameter", "ConfigSpace.UniformFloatHyperparameter", "ConfigSpace.UniformIntegerHyperparameter", "ConfigSpace.UniformFloatHyperparameter", "ConfigSpace.Constant"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "get_configspace", "(", "hp", ":", "dict", ")", ":", "\n", "        ", "config_space", "=", "ConfigurationSpace", "(", ")", "\n", "\n", "# Add fixed hyperparameters (they are not going to be optimised by ABAS)", "\n", "for", "hp_name", "in", "hp", ":", "\n", "            ", "config_space", ".", "add_hyperparameter", "(", "csh", ".", "Constant", "(", "hp_name", ",", "hp", "[", "hp_name", "]", ")", ")", "\n", "\n", "# Discriminator HPs (to be optimised)", "\n", "", "config_space", ".", "add_hyperparameter", "(", "csh", ".", "UniformIntegerHyperparameter", "(", "'disc.num_fc_layers'", ",", "lower", "=", "2", ",", "upper", "=", "7", ")", ")", "\n", "config_space", ".", "add_hyperparameter", "(", "csh", ".", "UniformIntegerHyperparameter", "(", "'disc.hidden_size_log'", ",", "lower", "=", "6", ",", "upper", "=", "12", ")", ")", "\n", "config_space", ".", "add_hyperparameter", "(", "csh", ".", "UniformFloatHyperparameter", "(", "'disc.dropout'", ",", "lower", "=", "0.", ",", "upper", "=", "1.", ")", ")", "\n", "\n", "# Other HPSs (to be optimised)", "\n", "config_space", ".", "add_hyperparameter", "(", "csh", ".", "UniformIntegerHyperparameter", "(", "'net.bottleneck_size_log'", ",", "lower", "=", "6", ",", "upper", "=", "10", ")", ")", "\n", "config_space", ".", "add_hyperparameter", "(", "csh", ".", "UniformFloatHyperparameter", "(", "'base.weight_da'", ",", "lower", "=", "0.", ",", "upper", "=", "2.", ")", ")", "\n", "\n", "return", "config_space", "\n", "\n"]], "home.repos.pwc.inspect_result.lr94_abas.None.abas.AbasWorker.compute": [[62, 138], ["range", "numpy.array", "numpy.array.mean().item", "numpy.array.var().item", "print", "print", "print", "print", "utils.dict_shortened_summary", "print", "train_model.run_training", "abas.AbasWorker.model_criterion", "abas.AbasWorker.run_model_criterion", "print", "abas.AbasWorker.argmin", "print", "print", "numpy.array.append", "abas.AbasWorker.tolist", "abas.AbasWorker.tolist", "single_training_infos.append", "map", "train_model.run_training.to_dict", "numpy.array.mean", "numpy.array.var", "str", "str", "int", "int", "os.path.join", "str"], "methods", ["home.repos.pwc.inspect_result.lr94_abas.None.utils.dict_shortened_summary", "home.repos.pwc.inspect_result.lr94_abas.None.train_model.run_training"], ["", "def", "compute", "(", "self", ",", "config_id", ",", "config", ",", "budget", ",", "working_directory", ")", ":", "\n", "# This \"run name\" refers to an actual single training.", "\n", "        ", "run_name_base", "=", "'cfg{}_bdg{:.3f}_{}'", ".", "format", "(", "'-'", ".", "join", "(", "map", "(", "lambda", "x", ":", "str", "(", "x", ")", ",", "config_id", ")", ")", ",", "budget", ",", "\n", "dict_shortened_summary", "(", "config", ")", ")", "\n", "\n", "single_training_losses", "=", "[", "]", "\n", "single_training_infos", "=", "[", "]", "\n", "# We *might* want to run multiple trainings for each configuration and average them.", "\n", "# we are not doing so in the paper, run_n_avg is left to 1", "\n", "for", "run_i", "in", "range", "(", "self", ".", "run_n_avg", ")", ":", "\n", "            ", "run_name", "=", "f\"{run_name_base}_run{run_i}\"", "if", "self", ".", "run_n_avg", ">", "1", "else", "run_name_base", "\n", "print", "(", "f\"Starting run {run_name}\"", ")", "\n", "\n", "# Run the actual model training", "\n", "metrics", "=", "run_training", "(", "\n", "source", "=", "self", ".", "source", ",", "\n", "target", "=", "self", ".", "target", ",", "\n", "dataset_root", "=", "self", ".", "ds_root", ",", "\n", "net_name", "=", "self", ".", "net", ",", "\n", "da_method", "=", "self", ".", "da_method", ",", "\n", "config", "=", "config", ",", "\n", "max_iter", "=", "int", "(", "self", ".", "max_iter", ")", ",", "\n", "stop_iter", "=", "int", "(", "budget", ")", ",", "\n", "test_iter", "=", "100", ",", "\n", "run_name", "=", "run_name", ",", "\n", "gpu_id", "=", "self", ".", "gpu", ",", "\n", "load_workers", "=", "self", ".", "load_workers", ",", "\n", "test_src", "=", "True", ",", "\n", "use_tqdm", "=", "not", "self", ".", "no_tqdm", ",", "\n", "logdir", "=", "os", ".", "path", ".", "join", "(", "self", ".", "logdir", ",", "self", ".", "run_id", ")", ",", "\n", "kill_diverging", "=", "self", ".", "kill_diverging", "\n", ")", "\n", "\n", "# Compute BOHB losses according to the selected criterion. These are to compare across different runs", "\n", "bohb_losses", "=", "self", ".", "model_criterion", "(", "metrics", ")", "\n", "# This criterion is to compare snapshots within a single run, and it could be different from the other", "\n", "# criterion (in the paper it is)", "\n", "run_modsel_losses", "=", "self", ".", "run_model_criterion", "(", "metrics", ")", "\n", "\n", "# Print info", "\n", "print", "(", "\"Run Model Selection losses: \"", ",", "run_modsel_losses", ")", "\n", "# Select the best model of this training according to run model selection", "\n", "best_index", "=", "run_modsel_losses", ".", "argmin", "(", ")", "\n", "best_loss", "=", "run_modsel_losses", "[", "best_index", "]", "\n", "best_bohb_loss", "=", "bohb_losses", "[", "best_index", "]", "\n", "best_iter", "=", "metrics", "[", "'iter'", "]", "[", "best_index", "]", "\n", "print", "(", "f\"Best run modsel loss: {best_loss} at iteration {best_iter} (position {best_index})\"", ")", "\n", "print", "(", "f\"BOHB loss: {best_bohb_loss}\"", ")", "\n", "\n", "# BOHB Losses for each training of this run", "\n", "single_training_losses", ".", "append", "(", "best_bohb_loss", ")", "\n", "# Add model selection losses to the DataFrame", "\n", "metrics", "[", "'run_modsel_losses'", "]", "=", "run_modsel_losses", ".", "tolist", "(", ")", "\n", "metrics", "[", "'bohb_losses'", "]", "=", "bohb_losses", ".", "tolist", "(", ")", "\n", "single_training_infos", ".", "append", "(", "metrics", ".", "to_dict", "(", "orient", "=", "'list'", ")", ")", "\n", "\n", "# Average BOHB losses for trainings in this run (meaningles if run_n_avg is 1)", "\n", "", "single_training_losses", "=", "np", ".", "array", "(", "single_training_losses", ")", "\n", "bohb_loss", "=", "single_training_losses", ".", "mean", "(", ")", ".", "item", "(", ")", "\n", "var", "=", "single_training_losses", ".", "var", "(", ")", ".", "item", "(", ")", "\n", "\n", "print", "(", "f\"BOHB Losses of {self.run_n_avg} runs: {single_training_losses}\"", ")", "\n", "print", "(", "f\"Mean: {bohb_loss}\"", ")", "\n", "print", "(", "f\"Variance: {var}\"", ")", "\n", "\n", "print", "(", ")", "\n", "\n", "return", "(", "{", "\n", "'loss'", ":", "bohb_loss", ",", "\n", "'info'", ":", "{", "\n", "'criterion'", ":", "str", "(", "self", ".", "model_criterion", ")", ",", "\n", "'criterion_info'", ":", "self", ".", "model_criterion", ".", "info", ",", "\n", "'run_criterion'", ":", "str", "(", "self", ".", "run_model_criterion", ")", ",", "\n", "'run_criterion_info'", ":", "self", ".", "run_model_criterion", ".", "info", ",", "\n", "'var'", ":", "var", ",", "\n", "'single_info'", ":", "single_training_infos", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.lr94_abas.None.abas.parse_args": [[142, 175], ["argparse.ArgumentParser", "utils.add_base_args", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args"], "function", ["home.repos.pwc.inspect_result.lr94_abas.None.utils.add_base_args", "home.repos.pwc.inspect_result.lr94_abas.None.abas.parse_args"], ["", "", "def", "parse_args", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "\n", "add_base_args", "(", "parser", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--exp-name'", ",", "default", "=", "None", ",", "type", "=", "str", ",", "help", "=", "\"Name of the experiment\"", ")", "\n", "parser", ".", "add_argument", "(", "'--exp-suffix'", ",", "default", "=", "None", ",", "type", "=", "str", ",", "help", "=", "\"Suffix to experiment name\"", ")", "\n", "\n", "# BOHB", "\n", "parser", ".", "add_argument", "(", "'--min-budget'", ",", "default", "=", "2000", ",", "type", "=", "int", ",", "help", "=", "\"Minimum budget (iterations)\"", ")", "\n", "parser", ".", "add_argument", "(", "'--max-budget'", ",", "default", "=", "6000", ",", "type", "=", "int", ",", "help", "=", "\"Maximum budget (iterations)\"", ")", "\n", "parser", ".", "add_argument", "(", "'--eta'", ",", "default", "=", "3.", ",", "type", "=", "float", ",", "help", "=", "\"Eta value for BOHB\"", ")", "\n", "parser", ".", "add_argument", "(", "'--run-n-avg'", ",", "default", "=", "1", ",", "type", "=", "int", ",", "\n", "help", "=", "\"A configuration should be evaluated training a model N times and averaging the metric\"", ")", "\n", "parser", ".", "add_argument", "(", "'--criterion'", ",", "type", "=", "ModelCriterion", ",", "required", "=", "True", ",", "help", "=", "\"Model selection criterion for BOHB (across runs)\"", ")", "\n", "parser", ".", "add_argument", "(", "'--run-criterion'", ",", "type", "=", "ModelCriterion", ",", "required", "=", "False", ",", "default", "=", "None", ",", "help", "=", "\"Model selection criterion to select best epoch (within training). If not specified is the same as the BOHB criterion\"", ")", "\n", "\n", "# Hyperparameters (the non-optimized ones)", "\n", "# (none BOHB-specific)", "\n", "\n", "# Distributed optimization", "\n", "parser", ".", "add_argument", "(", "'--worker'", ",", "action", "=", "'store_true'", ",", "help", "=", "\"Launch this process as a worker\"", ")", "\n", "parser", ".", "add_argument", "(", "'--master'", ",", "action", "=", "'store_true'", ",", "help", "=", "\"Launch this process as a master\"", ")", "\n", "parser", ".", "add_argument", "(", "'--num-workers'", ",", "default", "=", "1", ",", "type", "=", "int", ",", "help", "=", "\"Minimum number of parallel optimization worker processes\"", ")", "\n", "parser", ".", "add_argument", "(", "'--num-iterations'", ",", "default", "=", "24", ",", "type", "=", "int", ",", "help", "=", "\"Number of optimizer iterations\"", ")", "\n", "parser", ".", "add_argument", "(", "'--nic-name'", ",", "type", "=", "str", ",", "help", "=", "\"Network interface\"", ")", "\n", "parser", ".", "add_argument", "(", "'--loglevel'", ",", "type", "=", "str", ",", "default", "=", "'info'", ",", "choices", "=", "(", "'critical'", ",", "'warning'", ",", "'info'", ",", "'debug'", ")", ")", "\n", "parser", ".", "add_argument", "(", "'--timeout'", ",", "type", "=", "int", ",", "default", "=", "1200", ",", "help", "=", "\"Worker timeout\"", ")", "\n", "parser", ".", "add_argument", "(", "'--previous'", ",", "type", "=", "str", ",", "default", "=", "''", ")", "\n", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "return", "args", "\n", "\n"]], "home.repos.pwc.inspect_result.lr94_abas.None.abas.get_default_exp_name": [[177, 202], ["re.sub", "map", "map", "abas.get_default_exp_name.shorten_domain"], "function", ["None"], ["", "def", "get_default_exp_name", "(", "args", ")", ":", "\n", "    ", "def", "shorten_domain", "(", "domain", ")", ":", "\n", "        ", "return", "re", ".", "sub", "(", "r'-.*'", ",", "''", ",", "domain", ")", "\n", "\n", "", "params", "=", "(", "\n", "# ABAS and DA method (ALDA or DANN)", "\n", "f'abas-{args.da}'", ",", "\n", "# Optimization metric (abbreviated. \"target_accuracy\" -> \"ta\", \"target_calinski_harabasz_score\" -> \"tchs\")", "\n", "''", ".", "join", "(", "map", "(", "lambda", "s", ":", "s", "[", "0", "]", ",", "re", ".", "split", "(", "r'[\\s_-]+'", ",", "str", "(", "args", ".", "criterion", ")", ")", ")", ")", ",", "\n", "# Domains (\"clipart-oh\" is shortened into \"clipart\")", "\n", "\"{}-{}\"", ".", "format", "(", "shorten_domain", "(", "args", ".", "source", ")", ",", "shorten_domain", "(", "args", ".", "target", ")", ")", ",", "\n", "# Backbone", "\n", "args", ".", "net", ",", "\n", "# Discriminator type", "\n", "'fc'", ",", "\n", "# Budgets", "\n", "args", ".", "min_budget", ",", "\n", "args", ".", "max_budget", ",", "\n", "# Eta value", "\n", "args", ".", "eta", ",", "\n", "# Number of iterations", "\n", "args", ".", "num_iterations", "\n", ")", "\n", "\n", "return", "\"_\"", ".", "join", "(", "map", "(", "lambda", "v", ":", "str", "(", "v", ")", ",", "params", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.lr94_abas.None.abas.main": [[204, 322], ["abas.parse_args", "logging.basicConfig", "os.path.join", "os.path.join", "os.makedirs", "hpbandster.nic_name_to_host", "logger.Logger", "hpbandster.NameServer", "hpns.NameServer.start", "print", "utils.remove_file", "utils.remove_file", "hpbandster.json_result_logger", "hpbandster.optimizers.bohb.BOHB", "hpbandster.optimizers.bohb.BOHB.run", "hpbandster.optimizers.bohb.BOHB.shutdown", "hpns.NameServer.shutdown", "bohb.run.get_id2config_mapping", "bohb.run.get_incumbent_id", "bohb.run.get_all_runs", "print", "print", "print", "print", "abas.AbasWorker", "AbasWorker.load_nameserver_credentials", "AbasWorker.run", "print", "exit", "print", "exit", "os.path.isdir", "os.path.join", "os.path.join", "open", "pickle.dump", "abas.get_default_exp_name", "hpbandster.logged_results_to_HBS_result", "abas.AbasWorker.get_configspace", "os.path.join", "open", "pickle.load", "len", "len", "res.get_id2config_mapping.keys", "bohb.run.get_all_runs"], "function", ["home.repos.pwc.inspect_result.lr94_abas.None.abas.parse_args", "home.repos.pwc.inspect_result.lr94_abas.None.utils.remove_file", "home.repos.pwc.inspect_result.lr94_abas.None.utils.remove_file", "home.repos.pwc.inspect_result.lr94_abas.None.abas.get_default_exp_name", "home.repos.pwc.inspect_result.lr94_abas.None.abas.AbasWorker.get_configspace"], ["", "def", "main", "(", ")", ":", "\n", "    ", "args", "=", "parse_args", "(", ")", "\n", "\n", "# Set log level", "\n", "logging", ".", "basicConfig", "(", "level", "=", "{", "\n", "'critical'", ":", "logging", ".", "CRITICAL", ",", "\n", "'warning'", ":", "logging", ".", "WARNING", ",", "\n", "'info'", ":", "logging", ".", "INFO", ",", "\n", "'debug'", ":", "logging", ".", "DEBUG", "\n", "}", "[", "args", ".", "loglevel", "]", ")", "\n", "\n", "# Name for the current experiment (optimization, not single training)", "\n", "exp_name", "=", "args", ".", "exp_name", "or", "get_default_exp_name", "(", "args", ")", "+", "(", "(", "'_'", "+", "args", ".", "exp_suffix", ")", "if", "args", ".", "exp_suffix", "else", "''", ")", "\n", "\n", "logdir", "=", "os", ".", "path", ".", "join", "(", "args", ".", "logdir", ",", "exp_name", ")", "\n", "shared_dir", "=", "os", ".", "path", ".", "join", "(", "logdir", ",", "'master'", ")", "\n", "os", ".", "makedirs", "(", "shared_dir", ",", "exist_ok", "=", "True", ")", "# Also creates logdir if it does not exist", "\n", "\n", "host", "=", "hpns", ".", "nic_name_to_host", "(", "args", ".", "nic_name", ")", "\n", "\n", "# If this is meant to be a worker process, launch it", "\n", "if", "args", ".", "worker", ":", "\n", "        ", "w", "=", "AbasWorker", "(", "run_id", "=", "exp_name", ",", "\n", "source", "=", "args", ".", "source", ",", "\n", "target", "=", "args", ".", "target", ",", "\n", "net", "=", "args", ".", "net", ",", "\n", "load_workers", "=", "args", ".", "load_workers", ",", "\n", "max_iter", "=", "args", ".", "max_iter", ",", "\n", "logdir", "=", "args", ".", "logdir", ",", "\n", "ds_root", "=", "args", ".", "data_root", ",", "\n", "no_tqdm", "=", "args", ".", "no_tqdm", ",", "\n", "gpu", "=", "args", ".", "gpu", ",", "\n", "run_n_avg", "=", "args", ".", "run_n_avg", ",", "\n", "da_method", "=", "args", ".", "da", ",", "\n", "model_criterion", "=", "args", ".", "criterion", ",", "\n", "run_model_criterion", "=", "args", ".", "run_criterion", "or", "args", ".", "criterion", ",", "\n", "kill_diverging", "=", "args", ".", "kill_diverging", ",", "\n", "\n", "host", "=", "host", ",", "\n", "timeout", "=", "args", ".", "timeout", ")", "\n", "w", ".", "load_nameserver_credentials", "(", "working_directory", "=", "shared_dir", ")", "\n", "w", ".", "run", "(", "background", "=", "False", ")", "\n", "# Nothing to do, exit", "\n", "print", "(", "\"Done\"", ")", "\n", "exit", "(", "0", ")", "\n", "\n", "# If we are here we expect to be a master", "\n", "", "if", "not", "args", ".", "master", ":", "\n", "        ", "print", "(", "\"Nothing to do (not a master nor a worker process)\"", ")", "\n", "exit", "(", "1", ")", "\n", "\n", "# Running as master!", "\n", "\n", "# Log info", "\n", "", "Logger", "(", "logdir", "=", "logdir", ",", "run_name", "=", "'master'", ",", "use_tqdm", "=", "False", ",", "use_tb", "=", "False", ")", "\n", "\n", "# Init the nameserver (random port)", "\n", "ns", "=", "hpns", ".", "NameServer", "(", "run_id", "=", "exp_name", ",", "host", "=", "host", ",", "port", "=", "0", ",", "working_directory", "=", "shared_dir", ")", "\n", "ns_host", ",", "ns_port", "=", "ns", ".", "start", "(", ")", "\n", "print", "(", "\"Nameserver on {}:{}\"", ".", "format", "(", "ns_host", ",", "ns_port", ")", ")", "\n", "\n", "# These hyperparameters are passed through the command line and are not optimized", "\n", "hp", "=", "{", "\n", "'base.lr'", ":", "args", ".", "lr", ",", "\n", "'base.bs'", ":", "args", ".", "bs", ",", "\n", "'base.wd'", ":", "args", ".", "wd", ",", "\n", "}", "\n", "\n", "# Load previous runs", "\n", "previous_res", "=", "None", "\n", "if", "args", ".", "previous", "!=", "''", ":", "\n", "        ", "if", "os", ".", "path", ".", "isdir", "(", "args", ".", "previous", ")", ":", "\n", "            ", "previous_res", "=", "hpres", ".", "logged_results_to_HBS_result", "(", "args", ".", "previous", ")", "\n", "", "else", ":", "\n", "            ", "with", "open", "(", "args", ".", "previous", ",", "'rb'", ")", "as", "fp", ":", "\n", "                ", "previous_res", "=", "pickle", ".", "load", "(", "fp", ")", "\n", "\n", "# Safe file removal", "\n", "", "", "", "remove_file", "(", "os", ".", "path", ".", "join", "(", "shared_dir", ",", "'config.json'", ")", ")", "\n", "remove_file", "(", "os", ".", "path", ".", "join", "(", "shared_dir", ",", "'results.json'", ")", ")", "\n", "\n", "# Launch BOHB", "\n", "opt_logger", "=", "hpres", ".", "json_result_logger", "(", "directory", "=", "shared_dir", ",", "overwrite", "=", "False", ")", "\n", "bohb", "=", "BOHB", "(", "\n", "configspace", "=", "AbasWorker", ".", "get_configspace", "(", "hp", ")", ",", "\n", "previous_result", "=", "previous_res", ",", "\n", "run_id", "=", "exp_name", ",", "\n", "\n", "min_budget", "=", "args", ".", "min_budget", ",", "max_budget", "=", "args", ".", "max_budget", ",", "\n", "eta", "=", "args", ".", "eta", ",", "\n", "\n", "host", "=", "host", ",", "\n", "nameserver", "=", "ns_host", ",", "nameserver_port", "=", "ns_port", ",", "\n", "ping_interval", "=", "15", ",", "\n", "\n", "result_logger", "=", "opt_logger", "\n", ")", "\n", "\n", "res", "=", "bohb", ".", "run", "(", "n_iterations", "=", "args", ".", "num_iterations", ",", "min_n_workers", "=", "args", ".", "num_workers", ")", "\n", "\n", "# Done", "\n", "bohb", ".", "shutdown", "(", "shutdown_workers", "=", "True", ")", "\n", "ns", ".", "shutdown", "(", ")", "\n", "\n", "# Save results", "\n", "id2config", "=", "res", ".", "get_id2config_mapping", "(", ")", "\n", "incumbent", "=", "res", ".", "get_incumbent_id", "(", ")", "\n", "\n", "all_runs", "=", "res", ".", "get_all_runs", "(", ")", "\n", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "logdir", ",", "'result_{}.pkl'", ".", "format", "(", "exp_name", ")", ")", ",", "'wb'", ")", "as", "fp", ":", "\n", "        ", "pickle", ".", "dump", "(", "res", ",", "fp", ")", "\n", "\n", "", "print", "(", "f\"Best found configuration: {id2config[incumbent]['config']}\"", ")", "\n", "print", "(", "f\"Total number of sampled unique configurations: {len(id2config.keys())}\"", ")", "\n", "print", "(", "f\"Total runs {len(res.get_all_runs())}\"", ")", "\n", "print", "(", "\"ABAS run took {:.1f} seconds\"", ".", "format", "(", "\n", "all_runs", "[", "-", "1", "]", ".", "time_stamps", "[", "'finished'", "]", "-", "all_runs", "[", "0", "]", ".", "time_stamps", "[", "'started'", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.lr94_abas.None.loss.entropy_loss": [[6, 12], ["torch.nn.functional.softmax", "torch.nn.functional.softmax", "torch.nn.functional.softmax.ge", "torch.masked_select", "torch.masked_select", "torch.sum", "torch.sum", "float", "torch.nn.functional.softmax.size", "torch.log", "torch.log"], "function", ["None"], ["def", "entropy_loss", "(", "logits", ")", ":", "\n", "    ", "p_softmax", "=", "torch", ".", "nn", ".", "functional", ".", "softmax", "(", "logits", ",", "dim", "=", "1", ")", "\n", "mask", "=", "p_softmax", ".", "ge", "(", "0.000001", ")", "# greater or equal to; to avoid explosion when computing logarithm", "\n", "mask_out", "=", "torch", ".", "masked_select", "(", "p_softmax", ",", "mask", ")", "\n", "entropy", "=", "-", "(", "torch", ".", "sum", "(", "mask_out", "*", "torch", ".", "log", "(", "mask_out", ")", ")", ")", "\n", "return", "entropy", "/", "float", "(", "p_softmax", ".", "size", "(", "0", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.lr94_abas.None.loss.DANN_loss": [[14, 29], ["ad_out.size", "torch.cat", "torch.cat", "torch.CrossEntropyLoss", "torch.zeros", "torch.zeros", "torch.ones", "torch.ones"], "function", ["None"], ["", "def", "DANN_loss", "(", "ad_out", ")", ":", "\n", "    ", "\"\"\"\n    Domain-adversarial training of neural networks, Ganin et al., 2016\n    \"\"\"", "\n", "dev", "=", "ad_out", ".", "device", "\n", "bs", "=", "ad_out", ".", "size", "(", "0", ")", "\n", "assert", "bs", "%", "2", "==", "0", "\n", "bs", "//=", "2", "\n", "\n", "domain_labels", "=", "torch", ".", "cat", "(", "(", "\n", "torch", ".", "zeros", "(", "size", "=", "(", "bs", ",", ")", ",", "device", "=", "dev", ",", "dtype", "=", "torch", ".", "long", ")", ",", "\n", "torch", ".", "ones", "(", "size", "=", "(", "bs", ",", ")", ",", "device", "=", "dev", ",", "dtype", "=", "torch", ".", "long", ")", "\n", ")", ",", "dim", "=", "0", ")", "\n", "\n", "return", "nn", ".", "CrossEntropyLoss", "(", ")", "(", "ad_out", ",", "domain_labels", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.lr94_abas.None.loss.create_matrix": [[31, 44], ["torch.eye", "torch.eye", "torch.ones", "torch.ones"], "function", ["None"], ["", "def", "create_matrix", "(", "n", ",", "device", ")", ":", "\n", "    ", "\"\"\"\n    :param n: matrix size (class num)\n    :param device:\n    :return a matrix with torch.tensor type:\n    for example n=3:\n    1     -1/2  -1/2\n    -1/2    1   -1/2\n    -1/2  -1/2    1\n    \"\"\"", "\n", "\n", "eye", "=", "torch", ".", "eye", "(", "n", ",", "device", "=", "device", ")", "\n", "return", "eye", "-", "(", "torch", ".", "ones", "(", "(", "n", ",", "n", ")", ",", "device", "=", "device", ")", "-", "eye", ")", "/", "(", "n", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.lr94_abas.None.loss.ALDA_loss": [[46, 103], ["torch.sigmoid", "torch.sigmoid", "torch.sigmoid.size", "torch.zeros().to().scatter_", "torch.zeros().to().scatter_", "softmax_out[].detach", "softmax_out[].detach", "torch.max", "torch.max", "torch.zeros().to().scatter_", "torch.zeros().to().scatter_", "torch.max", "torch.max", "torch.zeros().to().scatter_", "torch.zeros().to().scatter_", "torch.where", "torch.where", "loss.create_matrix", "torch.cat", "torch.cat", "torch.mul().sum", "torch.mul().sum", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.mul().sum", "torch.mul().sum", "torch.mean", "torch.mean", "torch.sigmoid.size", "labels_source.unsqueeze", "argpred.unsqueeze", "argpred.unsqueeze", "target_mask.unsqueeze", "torch.zeros().to", "torch.zeros().to", "torch.mul", "torch.mul", "float", "torch.tensor", "torch.tensor", "torch.sum", "torch.sum", "torch.cat.float().sum", "torch.CrossEntropyLoss", "torch.mul", "torch.mul", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "create_matrix.unsqueeze", "torch.sigmoid.unsqueeze", "torch.mul", "torch.mul", "torch.tensor.clone", "torch.tensor.clone", "torch.BCELoss", "torch.mul", "torch.mul", "torch.zeros", "torch.zeros", "torch.cat.unsqueeze", "torch.cat.float", "torch.where.unsqueeze", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "create_matrix.detach", "torch.eye", "torch.eye"], "function", ["home.repos.pwc.inspect_result.lr94_abas.None.loss.create_matrix"], ["", "def", "ALDA_loss", "(", "ad_out_score", ",", "labels_source", ",", "softmax_out", ",", "threshold", "=", "0.9", ")", ":", "\n", "    ", "\"\"\"\n    :param ad_out_score: the discriminator output (N, C, H, W)\n    :param labels_source: the source ground truth (N, H, W)\n    :param softmax_out: the model prediction probability (N, C, H, W)\n    :return:\n    adv_loss: adversarial learning loss\n    reg_loss: regularization term for the discriminator\n    correct_loss: corrected self-training loss\n\n    Adversarial-Learned Loss for Domain Adaptation, Chen et al., 2020\n    https://github.com/ZJULearning/ALDA\n    \"\"\"", "\n", "ad_out", "=", "torch", ".", "sigmoid", "(", "ad_out_score", ")", "\n", "dev", "=", "ad_out", ".", "device", "\n", "\n", "batch_size", "=", "ad_out", ".", "size", "(", "0", ")", "//", "2", "\n", "class_num", "=", "ad_out", ".", "size", "(", "1", ")", "\n", "\n", "labels_source_mask", "=", "torch", ".", "zeros", "(", "batch_size", ",", "class_num", ")", ".", "to", "(", "dev", ")", ".", "scatter_", "(", "1", ",", "labels_source", ".", "unsqueeze", "(", "1", ")", ",", "1", ")", "\n", "probs_source", "=", "softmax_out", "[", ":", "batch_size", "]", ".", "detach", "(", ")", "\n", "probs_target", "=", "softmax_out", "[", "batch_size", ":", "]", ".", "detach", "(", ")", "\n", "maxpred", ",", "argpred", "=", "torch", ".", "max", "(", "probs_source", ",", "dim", "=", "1", ")", "\n", "preds_source_mask", "=", "torch", ".", "zeros", "(", "batch_size", ",", "class_num", ")", ".", "to", "(", "dev", ")", ".", "scatter_", "(", "1", ",", "argpred", ".", "unsqueeze", "(", "1", ")", ",", "1", ")", "\n", "maxpred", ",", "argpred", "=", "torch", ".", "max", "(", "probs_target", ",", "dim", "=", "1", ")", "\n", "preds_target_mask", "=", "torch", ".", "zeros", "(", "batch_size", ",", "class_num", ")", ".", "to", "(", "dev", ")", ".", "scatter_", "(", "1", ",", "argpred", ".", "unsqueeze", "(", "1", ")", ",", "1", ")", "\n", "\n", "# filter out those low confidence samples", "\n", "target_mask", "=", "(", "maxpred", ">", "threshold", ")", "\n", "preds_target_mask", "=", "torch", ".", "where", "(", "target_mask", ".", "unsqueeze", "(", "1", ")", ",", "preds_target_mask", ",", "torch", ".", "zeros", "(", "1", ")", ".", "to", "(", "dev", ")", ")", "\n", "# construct the confusion matrix from ad_out. See the paper for more details.", "\n", "confusion_matrix", "=", "create_matrix", "(", "class_num", ",", "device", "=", "dev", ")", "\n", "ant_eye", "=", "(", "1", "-", "torch", ".", "eye", "(", "class_num", ")", ")", ".", "to", "(", "dev", ")", ".", "unsqueeze", "(", "0", ")", "\n", "confusion_matrix", "=", "ant_eye", "/", "(", "class_num", "-", "1", ")", "+", "torch", ".", "mul", "(", "confusion_matrix", ".", "unsqueeze", "(", "0", ")", ",", "ad_out", ".", "unsqueeze", "(", "\n", "1", ")", ")", "# (2*batch_size, class_num, class_num)", "\n", "preds_mask", "=", "torch", ".", "cat", "(", "[", "preds_source_mask", ",", "preds_target_mask", "]", ",", "dim", "=", "0", ")", "# labels_source_mask", "\n", "loss_pred", "=", "torch", ".", "mul", "(", "confusion_matrix", ",", "preds_mask", ".", "unsqueeze", "(", "1", ")", ")", ".", "sum", "(", "dim", "=", "2", ")", "\n", "# different correction targets for different domains", "\n", "loss_target", "=", "(", "1", "-", "preds_target_mask", ")", "/", "(", "class_num", "-", "1", ")", "\n", "loss_target", "=", "torch", ".", "cat", "(", "[", "labels_source_mask", ",", "loss_target", "]", ",", "dim", "=", "0", ")", "\n", "if", "not", "(", "(", "loss_pred", ">=", "0", ")", ".", "all", "(", ")", "and", "(", "loss_pred", "<=", "1", ")", ".", "all", "(", ")", ")", ":", "\n", "        ", "nan", "=", "float", "(", "'nan'", ")", "\n", "nan", "=", "torch", ".", "tensor", "(", "nan", ",", "device", "=", "dev", ",", "requires_grad", "=", "True", ")", "\n", "return", "nan", ",", "nan", ".", "clone", "(", ")", ",", "nan", ".", "clone", "(", ")", "\n", "", "mask", "=", "torch", ".", "cat", "(", "[", "(", "maxpred", ">=", "0", ")", ",", "target_mask", "]", ",", "dim", "=", "0", ")", "\n", "adv_loss", "=", "nn", ".", "BCELoss", "(", "reduction", "=", "'none'", ")", "(", "loss_pred", ",", "loss_target", ")", "[", "mask", "]", "\n", "adv_loss", "=", "torch", ".", "sum", "(", "adv_loss", ")", "/", "mask", ".", "float", "(", ")", ".", "sum", "(", ")", "\n", "\n", "# reg_loss", "\n", "reg_loss", "=", "nn", ".", "CrossEntropyLoss", "(", ")", "(", "ad_out_score", "[", ":", "batch_size", "]", ",", "labels_source", ")", "\n", "\n", "# corrected target loss function", "\n", "target_probs", "=", "1.0", "*", "softmax_out", "[", "batch_size", ":", "]", "\n", "correct_target", "=", "torch", ".", "mul", "(", "confusion_matrix", ".", "detach", "(", ")", "[", "batch_size", ":", "]", ",", "preds_target_mask", ".", "unsqueeze", "(", "1", ")", ")", ".", "sum", "(", "dim", "=", "2", ")", "\n", "correct_loss", "=", "-", "torch", ".", "mul", "(", "target_probs", ",", "correct_target", ")", "\n", "correct_loss", "=", "torch", ".", "mean", "(", "correct_loss", "[", "target_mask", "]", ")", "\n", "return", "adv_loss", ",", "reg_loss", ",", "correct_loss", "\n", "", ""]], "home.repos.pwc.inspect_result.lr94_abas.None.utils.map_to_device": [[12, 20], ["tuple", "map", "x.to"], "function", ["None"], ["def", "map_to_device", "(", "device", ",", "t", ")", ":", "\n", "    ", "\"\"\"\n    Simple helper function to move to a device multiple tensors or networks at once\n    :param device:      target device\n    :param t:           iterable containing tensors / networks\n    :return:            tuple of moved tensors / networks\n    \"\"\"", "\n", "return", "tuple", "(", "map", "(", "lambda", "x", ":", "x", ".", "to", "(", "device", ")", ",", "t", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.lr94_abas.None.utils.get_default_dataset_root": [[22, 34], ["platform.node().lower", "known_systems.get", "print", "platform.node"], "function", ["None"], ["", "def", "get_default_dataset_root", "(", ")", ":", "\n", "    ", "node", "=", "platform", ".", "node", "(", ")", ".", "lower", "(", ")", "\n", "\n", "# node = get_cluster_name(node) or node", "\n", "\n", "known_systems", "=", "{", "\n", "# 'my-hostname': '/my/data/path'", "\n", "}", "\n", "\n", "path", "=", "known_systems", ".", "get", "(", "node", ",", "'data'", ")", "\n", "print", "(", "\"Loading data from {}\"", ".", "format", "(", "path", ")", ")", "\n", "return", "path", "\n", "\n"]], "home.repos.pwc.inspect_result.lr94_abas.None.utils.print_args": [[36, 45], ["print", "getattr", "str", "max", "map"], "function", ["None"], ["", "def", "print_args", "(", "args", ",", "fields", ")", ":", "\n", "    ", "\"\"\"\n    Print recap of a selection of args\n    :param args:\n    :param fields:\n    :return:\n    \"\"\"", "\n", "for", "f", "in", "fields", ":", "\n", "        ", "print", "(", "(", "\"{:>\"", "+", "str", "(", "1", "+", "max", "(", "map", "(", "len", ",", "fields", ")", ")", ")", "+", "\"} : {:<25}\"", ")", ".", "format", "(", "f", ",", "getattr", "(", "args", ",", "f", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.lr94_abas.None.utils.dict_shortened_summary": [[47, 59], ["list", "list.sort", "config.items", "isinstance", "map", "str", "utils.dict_shortened_summary.val2str"], "function", ["None"], ["", "", "def", "dict_shortened_summary", "(", "config", ":", "dict", ")", "->", "str", ":", "\n", "    ", "pairs", "=", "list", "(", "config", ".", "items", "(", ")", ")", "\n", "pairs", ".", "sort", "(", "key", "=", "lambda", "p", ":", "p", "[", "0", "]", ")", "\n", "\n", "def", "val2str", "(", "val", ")", ":", "\n", "        ", "if", "isinstance", "(", "val", ",", "float", ")", ":", "\n", "            ", "return", "'{:.3f}'", ".", "format", "(", "val", ")", "\n", "", "else", ":", "\n", "            ", "return", "str", "(", "val", ")", "\n", "\n", "", "", "return", "'_'", ".", "join", "(", "map", "(", "lambda", "p", ":", "'{}{}'", ".", "format", "(", "''", ".", "join", "(", "map", "(", "lambda", "s", ":", "s", "[", "0", "]", "+", "(", "s", "[", "1", "]", "if", "len", "(", "s", ")", "==", "2", "else", "''", ")", ",", "\n", "re", ".", "split", "(", "r'[.\\-_\\s]+'", ",", "p", "[", "0", "]", ")", ")", ")", ",", "val2str", "(", "p", "[", "1", "]", ")", ")", ",", "pairs", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.lr94_abas.None.utils.parse_cli_dict": [[61, 90], ["re.match", "re.match", "re.match", "re.match", "utils.parse_cli_dict.parse_val"], "function", ["None"], ["", "def", "parse_cli_dict", "(", "txt", ":", "str", ")", "->", "dict", ":", "\n", "    ", "\"\"\"\n    Parse a string like\n    var1=abc,var2=4,var3=false\n    into a dict.\n    Keys without values are interpreted as \"True\":\n    bs=64,use_bottleneck,lr=0.001 is read as\n    {bs: 64, use_bottleneck: True, lr: 0.001}\n    :param txt:\n    :return:\n    \"\"\"", "\n", "if", "txt", "==", "''", "or", "str", "is", "None", ":", "\n", "        ", "return", "{", "}", "\n", "\n", "", "def", "parse_val", "(", "v", ":", "str", ")", ":", "\n", "        ", "if", "type", "(", "v", ")", "!=", "str", ":", "\n", "            ", "return", "v", "\n", "", "if", "re", ".", "match", "(", "r'^[+-]?\\d+$'", ",", "v", ")", ":", "\n", "            ", "return", "int", "(", "v", ")", "\n", "", "if", "re", ".", "match", "(", "r'^[+-]?\\d+(?:\\.\\d*)?(?:e[+-]?\\d+)?$'", ",", "v", ",", "re", ".", "IGNORECASE", ")", ":", "\n", "            ", "return", "float", "(", "v", ")", "\n", "", "if", "re", ".", "match", "(", "'^y(?:es)?|t|(?:rue)|1|on$'", ",", "v", ",", "re", ".", "IGNORECASE", ")", ":", "\n", "            ", "return", "True", "\n", "", "if", "re", ".", "match", "(", "'^n(?:o)?|f|(?:alse)|0|off$'", ",", "v", ",", "re", ".", "IGNORECASE", ")", ":", "\n", "            ", "return", "False", "\n", "", "return", "v", "\n", "\n", "", "return", "{", "k", ":", "parse_val", "(", "v", ")", "for", "k", ",", "v", "in", "\n", "map", "(", "lambda", "p", ":", "p", "if", "len", "(", "p", ")", "==", "2", "else", "(", "p", "[", "0", "]", ",", "str", "(", "True", ")", ")", ",", "map", "(", "lambda", "p", ":", "p", ".", "split", "(", "'='", ")", ",", "txt", ".", "split", "(", "','", ")", ")", ")", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.lr94_abas.None.utils.split_dict": [[92, 113], ["k.split", "len", "result.get", "result.get.update"], "function", ["None"], ["", "def", "split_dict", "(", "config", ":", "dict", ")", ":", "\n", "    ", "\"\"\"\n    {'disc.num_layers': 3, 'disc.dropout': 0.5, 'net.bottleneck_size': 512}\n    to\n    {'disc': {'num_layers': 3, 'dropout': 0.5}, 'net': {'bottleneck_size': 512}}\n    :param config:\n    :return:\n    \"\"\"", "\n", "result", "=", "{", "}", "\n", "for", "k", "in", "config", ":", "\n", "        ", "path", "=", "k", ".", "split", "(", "'.'", ")", "\n", "parent", "=", "path", "[", "0", "]", "\n", "value", "=", "config", "[", "k", "]", "\n", "if", "len", "(", "path", ")", "==", "1", ":", "\n", "            ", "result", "[", "parent", "]", "=", "value", "\n", "", "else", ":", "\n", "            ", "child", "=", "path", "[", "1", "]", "\n", "tmp", "=", "result", ".", "get", "(", "parent", ",", "{", "}", ")", "\n", "tmp", ".", "update", "(", "{", "child", ":", "value", "}", ")", "\n", "result", "[", "parent", "]", "=", "tmp", "\n", "", "", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.lr94_abas.None.utils.remove_log_hps": [[115, 124], ["list", "config.keys", "k.endswith", "re.sub", "config.pop", "config.pop"], "function", ["None"], ["", "def", "remove_log_hps", "(", "config", ":", "dict", ")", ":", "\n", "    ", "keys", "=", "list", "(", "config", ".", "keys", "(", ")", ")", "\n", "for", "k", "in", "keys", ":", "\n", "        ", "if", "k", ".", "endswith", "(", "'_log'", ")", ":", "\n", "            ", "no_log_k", "=", "re", ".", "sub", "(", "r'_log$'", ",", "''", ",", "k", ")", "\n", "if", "no_log_k", "in", "config", ":", "\n", "                ", "config", ".", "pop", "(", "k", ")", "\n", "", "else", ":", "\n", "                ", "config", "[", "no_log_k", "]", "=", "2", "**", "config", ".", "pop", "(", "k", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.lr94_abas.None.utils.remove_file": [[126, 131], ["os.remove"], "function", ["None"], ["", "", "", "", "def", "remove_file", "(", "path", ":", "str", ")", ":", "\n", "    ", "try", ":", "\n", "        ", "os", ".", "remove", "(", "path", ")", "\n", "", "except", "FileNotFoundError", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.lr94_abas.None.utils.add_base_args": [[133, 172], ["parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "utils.get_default_dataset_root"], "function", ["home.repos.pwc.inspect_result.lr94_abas.None.utils.get_default_dataset_root"], ["", "", "def", "add_base_args", "(", "parser", ":", "ArgumentParser", ")", ":", "\n", "    ", "\"\"\"\n    Add to an ArgumentParser the arguments needed for all our settings (source, target, etc)\n    :param parser:\n    :return:\n    \"\"\"", "\n", "\n", "# Datasets", "\n", "known_datasets", "=", "(", "\n", "# Office-31", "\n", "'amazon'", ",", "'dslr'", ",", "'webcam'", ",", "\n", "# PACS", "\n", "'art-pacs'", ",", "'cartoon'", ",", "'photo'", ",", "'sketch-pacs'", ",", "\n", "# OfficeHome", "\n", "'art-oh'", ",", "'clipart-oh'", ",", "'realworld'", ",", "'product'", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--source'", ",", "type", "=", "str", ",", "default", "=", "'amazon'", ",", "choices", "=", "known_datasets", ",", "help", "=", "\"Source domain / dataset\"", ")", "\n", "parser", ".", "add_argument", "(", "'--target'", ",", "type", "=", "str", ",", "default", "=", "'webcam'", ",", "choices", "=", "known_datasets", ",", "help", "=", "\"Target domain / dataset\"", ")", "\n", "parser", ".", "add_argument", "(", "'--data-root'", ",", "type", "=", "str", ",", "default", "=", "get_default_dataset_root", "(", ")", "or", "'data'", ",", "help", "=", "\"Dataset root\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--net'", ",", "type", "=", "str", ",", "default", "=", "'resnet50'", ",", "choices", "=", "backbones", ",", "help", "=", "\"Backbone\"", ")", "\n", "parser", ".", "add_argument", "(", "'--bs'", ",", "type", "=", "int", ",", "default", "=", "36", ",", "help", "=", "\"Batch size\"", ")", "\n", "parser", ".", "add_argument", "(", "'--lr'", ",", "type", "=", "float", ",", "default", "=", "0.001", ",", "help", "=", "\"Initial learning rate\"", ")", "\n", "parser", ".", "add_argument", "(", "'--wd'", ",", "type", "=", "float", ",", "default", "=", "0.0005", ",", "help", "=", "\"Weight decay\"", ")", "\n", "parser", ".", "add_argument", "(", "'--da'", ",", "type", "=", "str", ",", "default", "=", "'alda'", ",", "choices", "=", "(", "'so'", ",", "'dann'", ",", "'alda'", ")", ",", "\n", "help", "=", "\"Domain Adaptation method. SO is Source Only (none)\"", ")", "\n", "parser", ".", "add_argument", "(", "'--config'", ",", "type", "=", "parse_cli_dict", ",", "default", "=", "''", ",", "help", "=", "\"Manual config\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--gpu'", ",", "type", "=", "int", ",", "default", "=", "0", ",", "help", "=", "\"CUDA device to be used\"", ")", "\n", "parser", ".", "add_argument", "(", "'--load-workers'", ",", "type", "=", "int", ",", "default", "=", "4", ",", "help", "=", "\"Load workers\"", ")", "\n", "parser", ".", "add_argument", "(", "'--logdir'", ",", "type", "=", "str", ",", "default", "=", "'experiments'", ",", "help", "=", "\"Log root\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--max-iter'", ",", "type", "=", "int", ",", "default", "=", "10000", ",", "help", "=", "\"Full training length\"", ")", "\n", "parser", ".", "add_argument", "(", "'--test-iter'", ",", "type", "=", "int", ",", "default", "=", "100", ",", "help", "=", "\"Test interval\"", ")", "\n", "parser", ".", "add_argument", "(", "'--no-test-source'", ",", "action", "=", "'store_true'", ",", "help", "=", "\"Don't test on source\"", ")", "\n", "parser", ".", "add_argument", "(", "'--kill-diverging'", ",", "action", "=", "'store_true'", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--no-tqdm'", ",", "action", "=", "'store_true'", ",", "help", "=", "\"Do not show progress bar\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.lr94_abas.None.utils.add_scalars": [[174, 178], ["writer.add_scalar"], "function", ["home.repos.pwc.inspect_result.lr94_abas.None.logger.Logger.add_scalar"], ["", "def", "add_scalars", "(", "writer", ":", "Logger", ",", "dictionary", ":", "dict", ",", "global_step", ":", "int", ",", "prefix", "=", "''", ",", "suffix", "=", "''", ")", ":", "\n", "    ", "for", "k", "in", "dictionary", ":", "\n", "        ", "label", "=", "f'{prefix}{k}{suffix}'", "\n", "writer", ".", "add_scalar", "(", "label", ",", "dictionary", "[", "k", "]", ",", "global_step", "=", "global_step", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.lr94_abas.datasets.utils.get_dataset_by_name": [[8, 73], ["utils.get_dataset_by_name.create_picture_transform_chain"], "function", ["None"], ["\n", "from", "net", "import", "backbones", "\n", "\n", "\n", "def", "map_to_device", "(", "device", ",", "t", ")", ":", "\n", "    ", "\"\"\"\n    Simple helper function to move to a device multiple tensors or networks at once\n    :param device:      target device\n    :param t:           iterable containing tensors / networks\n    :return:            tuple of moved tensors / networks\n    \"\"\"", "\n", "return", "tuple", "(", "map", "(", "lambda", "x", ":", "x", ".", "to", "(", "device", ")", ",", "t", ")", ")", "\n", "\n", "\n", "", "def", "get_default_dataset_root", "(", ")", ":", "\n", "    ", "node", "=", "platform", ".", "node", "(", ")", ".", "lower", "(", ")", "\n", "\n", "# node = get_cluster_name(node) or node", "\n", "\n", "known_systems", "=", "{", "\n", "# 'my-hostname': '/my/data/path'", "\n", "}", "\n", "\n", "path", "=", "known_systems", ".", "get", "(", "node", ",", "'data'", ")", "\n", "print", "(", "\"Loading data from {}\"", ".", "format", "(", "path", ")", ")", "\n", "return", "path", "\n", "\n", "\n", "", "def", "print_args", "(", "args", ",", "fields", ")", ":", "\n", "    ", "\"\"\"\n    Print recap of a selection of args\n    :param args:\n    :param fields:\n    :return:\n    \"\"\"", "\n", "for", "f", "in", "fields", ":", "\n", "        ", "print", "(", "(", "\"{:>\"", "+", "str", "(", "1", "+", "max", "(", "map", "(", "len", ",", "fields", ")", ")", ")", "+", "\"} : {:<25}\"", ")", ".", "format", "(", "f", ",", "getattr", "(", "args", ",", "f", ")", ")", ")", "\n", "\n", "\n", "", "", "def", "dict_shortened_summary", "(", "config", ":", "dict", ")", "->", "str", ":", "\n", "    ", "pairs", "=", "list", "(", "config", ".", "items", "(", ")", ")", "\n", "pairs", ".", "sort", "(", "key", "=", "lambda", "p", ":", "p", "[", "0", "]", ")", "\n", "\n", "def", "val2str", "(", "val", ")", ":", "\n", "        ", "if", "isinstance", "(", "val", ",", "float", ")", ":", "\n", "            ", "return", "'{:.3f}'", ".", "format", "(", "val", ")", "\n", "", "else", ":", "\n", "            ", "return", "str", "(", "val", ")", "\n", "\n", "", "", "return", "'_'", ".", "join", "(", "map", "(", "lambda", "p", ":", "'{}{}'", ".", "format", "(", "''", ".", "join", "(", "map", "(", "lambda", "s", ":", "s", "[", "0", "]", "+", "(", "s", "[", "1", "]", "if", "len", "(", "s", ")", "==", "2", "else", "''", ")", ",", "\n", "re", ".", "split", "(", "r'[.\\-_\\s]+'", ",", "p", "[", "0", "]", ")", ")", ")", ",", "val2str", "(", "p", "[", "1", "]", ")", ")", ",", "pairs", ")", ")", "\n", "\n", "\n", "", "def", "parse_cli_dict", "(", "txt", ":", "str", ")", "->", "dict", ":", "\n", "    ", "\"\"\"\n    Parse a string like\n    var1=abc,var2=4,var3=false\n    into a dict.\n    Keys without values are interpreted as \"True\":\n    bs=64,use_bottleneck,lr=0.001 is read as\n    {bs: 64, use_bottleneck: True, lr: 0.001}\n    :param txt:\n    :return:\n    \"\"\"", "\n", "if", "txt", "==", "''", "or", "str", "is", "None", ":", "\n", "        ", "return", "{", "}", "\n"]], "home.repos.pwc.inspect_result.lr94_abas.datasets.utils.get_class_count": [[75, 80], ["isinstance", "ValueError", "len"], "function", ["None"], ["", "def", "parse_val", "(", "v", ":", "str", ")", ":", "\n", "        ", "if", "type", "(", "v", ")", "!=", "str", ":", "\n", "            ", "return", "v", "\n", "", "if", "re", ".", "match", "(", "r'^[+-]?\\d+$'", ",", "v", ")", ":", "\n", "            ", "return", "int", "(", "v", ")", "\n", "", "if", "re", ".", "match", "(", "r'^[+-]?\\d+(?:\\.\\d*)?(?:e[+-]?\\d+)?$'", ",", "v", ",", "re", ".", "IGNORECASE", ")", ":", "\n"]], "home.repos.pwc.inspect_result.lr94_abas.datasets.utils.prepare_datasets": [[82, 90], ["utils.get_class_count", "utils.get_class_count", "utils.get_dataset_by_name", "utils.get_dataset_by_name"], "function", ["home.repos.pwc.inspect_result.lr94_abas.datasets.utils.get_class_count", "home.repos.pwc.inspect_result.lr94_abas.datasets.utils.get_class_count", "home.repos.pwc.inspect_result.lr94_abas.datasets.utils.get_dataset_by_name", "home.repos.pwc.inspect_result.lr94_abas.datasets.utils.get_dataset_by_name"], ["", "if", "re", ".", "match", "(", "'^y(?:es)?|t|(?:rue)|1|on$'", ",", "v", ",", "re", ".", "IGNORECASE", ")", ":", "\n", "            ", "return", "True", "\n", "", "if", "re", ".", "match", "(", "'^n(?:o)?|f|(?:alse)|0|off$'", ",", "v", ",", "re", ".", "IGNORECASE", ")", ":", "\n", "            ", "return", "False", "\n", "", "return", "v", "\n", "\n", "", "return", "{", "k", ":", "parse_val", "(", "v", ")", "for", "k", ",", "v", "in", "\n", "map", "(", "lambda", "p", ":", "p", "if", "len", "(", "p", ")", "==", "2", "else", "(", "p", "[", "0", "]", ",", "str", "(", "True", ")", ")", ",", "map", "(", "lambda", "p", ":", "p", ".", "split", "(", "'='", ")", ",", "txt", ".", "split", "(", "','", ")", ")", ")", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.lr94_abas.net.common.FrozenContext.__init__": [[22, 24], ["list", "itertools.chain"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "*", "params", ")", ":", "\n", "        ", "self", ".", "params", "=", "list", "(", "itertools", ".", "chain", "(", "*", "params", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.lr94_abas.net.common.FrozenContext.__enter__": [[25, 28], ["None"], "methods", ["None"], ["", "def", "__enter__", "(", "self", ")", ":", "\n", "        ", "for", "p", "in", "self", ".", "params", ":", "\n", "            ", "p", ".", "requires_grad", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.lr94_abas.net.common.FrozenContext.__exit__": [[29, 32], ["None"], "methods", ["None"], ["", "", "def", "__exit__", "(", "self", ",", "exc_type", ",", "exc_val", ",", "exc_tb", ")", ":", "\n", "        ", "for", "p", "in", "self", ".", "params", ":", "\n", "            ", "p", ".", "requires_grad", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.lr94_abas.net.common.GradientReversalLayer.__init__": [[57, 60], ["GradientReversalLayer._GRL", "torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.lr94_abas.net.resnet.Discriminator.__init__"], ["", "", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "self", ".", "grl", "=", "GradientReversalLayer", ".", "_GRL", "(", ")", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.lr94_abas.net.common.GradientReversalLayer.forward": [[61, 65], ["common.GradientReversalLayer.grl.apply"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ":", "torch", ".", "Tensor", ",", "lambda_val", "=", "0", ")", ":", "\n", "# If training lambda_val must not be None", "\n", "# assert (lambda_val is None and not self.training) or (lambda_val is not None and self.training)", "\n", "        ", "return", "self", ".", "grl", ".", "apply", "(", "x", ",", "lambda_val", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.lr94_abas.net.common.Identity.__init__": [[69, 71], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.lr94_abas.net.resnet.Discriminator.__init__"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.lr94_abas.net.common.Identity.forward": [[72, 74], ["None"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.lr94_abas.net.common.PluggableSequential.__init__": [[78, 90], ["torch.Sequential.__init__"], "methods", ["home.repos.pwc.inspect_result.lr94_abas.net.resnet.Discriminator.__init__"], ["    ", "def", "__init__", "(", "self", ",", "*", "args", ",", "plug_position", ":", "int", "=", "0", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"\n        Like Sequential but you can plug a secondary branch\n        :param args: Submodules\n        :param plug_position: Secondary branch position.\n        0 1 2 3 4 5 6\n         M M M M M M\n        :param kwargs:\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n", "self", ".", "plug_position", "=", "plug_position", "\n", "\n"]], "home.repos.pwc.inspect_result.lr94_abas.net.common.PluggableSequential.forward": [[91, 105], ["isinstance", "enumerate", "len", "module", "len"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "assert", "isinstance", "(", "self", ".", "plug_position", ",", "int", ")", "\n", "assert", "0", "<=", "self", ".", "plug_position", "<=", "len", "(", "self", ")", "\n", "\n", "plug_output", "=", "None", "\n", "for", "i", ",", "module", "in", "enumerate", "(", "self", ")", ":", "\n", "            ", "if", "i", "==", "self", ".", "plug_position", ":", "\n", "                ", "plug_output", "=", "x", "\n", "", "x", "=", "module", "(", "x", ")", "\n", "\n", "", "if", "self", ".", "plug_position", "==", "len", "(", "self", ")", ":", "\n", "            ", "plug_output", "=", "x", "\n", "\n", "", "return", "x", ",", "plug_output", "\n", "", "", ""]], "home.repos.pwc.inspect_result.lr94_abas.net.common.init_weights": [[7, 19], ["torch.init.kaiming_uniform_", "torch.init.zeros_", "classname.find", "classname.find", "classname.find", "torch.init.normal_", "torch.init.zeros_", "classname.find", "torch.init.xavier_normal_", "torch.init.zeros_"], "function", ["None"], ["def", "init_weights", "(", "m", ")", ":", "\n", "    ", "classname", "=", "m", ".", "__class__", ".", "__name__", "\n", "if", "classname", ".", "find", "(", "'Conv2d'", ")", "!=", "-", "1", "or", "classname", ".", "find", "(", "'ConvTranspose2d'", ")", "!=", "-", "1", ":", "\n", "        ", "nn", ".", "init", ".", "kaiming_uniform_", "(", "m", ".", "weight", ")", "\n", "nn", ".", "init", ".", "zeros_", "(", "m", ".", "bias", ")", "\n", "", "elif", "classname", ".", "find", "(", "'BatchNorm'", ")", "!=", "-", "1", ":", "\n", "        ", "nn", ".", "init", ".", "normal_", "(", "m", ".", "weight", ",", "1.0", ",", "0.02", ")", "\n", "nn", ".", "init", ".", "zeros_", "(", "m", ".", "bias", ")", "\n", "", "elif", "classname", ".", "find", "(", "'Linear'", ")", "!=", "-", "1", ":", "\n", "        ", "nn", ".", "init", ".", "xavier_normal_", "(", "m", ".", "weight", ")", "\n", "if", "m", ".", "bias", "is", "not", "None", ":", "\n", "            ", "nn", ".", "init", ".", "zeros_", "(", "m", ".", "bias", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.lr94_abas.net.resnet.ResNetFc.__init__": [[15, 70], ["nn.Module.__init__", "resnet.ResNetFc.bottleneck.apply", "resnet.ResNetFc.fc.apply", "common.PluggableSequential", "nn.Linear", "common.Identity", "nn.Linear", "nn.Linear", "nn.Sequential", "nn.Sequential", "nn.Flatten"], "methods", ["home.repos.pwc.inspect_result.lr94_abas.net.resnet.Discriminator.__init__"], ["    ", "def", "__init__", "(", "self", ",", "resnet_name", ",", "bottleneck_size", "=", "256", ",", "use_bottleneck", "=", "True", ",", "num_classes", "=", "1000", ",", "plug_position", "=", "7", ")", ":", "\n", "        ", "super", "(", "ResNetFc", ",", "self", ")", ".", "__init__", "(", ")", "\n", "model_resnet", "=", "resnet_dict", "[", "resnet_name", "]", "(", "pretrained", "=", "True", ")", "\n", "self", ".", "conv1", "=", "model_resnet", ".", "conv1", "\n", "self", ".", "bn1", "=", "model_resnet", ".", "bn1", "\n", "self", ".", "relu", "=", "model_resnet", ".", "relu", "\n", "self", ".", "maxpool", "=", "model_resnet", ".", "maxpool", "\n", "self", ".", "layer1", "=", "model_resnet", ".", "layer1", "\n", "self", ".", "layer2", "=", "model_resnet", ".", "layer2", "\n", "self", ".", "layer3", "=", "model_resnet", ".", "layer3", "\n", "self", ".", "layer4", "=", "model_resnet", ".", "layer4", "\n", "self", ".", "avgpool", "=", "model_resnet", ".", "avgpool", "\n", "\n", "self", ".", "bottleneck", "=", "nn", ".", "Linear", "(", "model_resnet", ".", "fc", ".", "in_features", ",", "bottleneck_size", ")", "if", "use_bottleneck", "else", "Identity", "(", ")", "\n", "self", ".", "bottleneck", ".", "apply", "(", "init_weights", ")", "\n", "\n", "self", ".", "num_classes", "=", "num_classes", "\n", "\n", "if", "use_bottleneck", ":", "\n", "            ", "self", ".", "fc", "=", "nn", ".", "Linear", "(", "bottleneck_size", ",", "num_classes", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "fc", "=", "nn", ".", "Linear", "(", "model_resnet", ".", "fc", ".", "in_features", ",", "num_classes", ")", "\n", "", "self", ".", "fc", ".", "apply", "(", "init_weights", ")", "\n", "\n", "self", ".", "layers", "=", "PluggableSequential", "(", "\n", "# 0", "\n", "nn", ".", "Sequential", "(", "\n", "self", ".", "conv1", ",", "\n", "self", ".", "bn1", ",", "\n", "self", ".", "relu", ",", "\n", "self", ".", "maxpool", "\n", ")", ",", "\n", "# 1", "\n", "self", ".", "layer1", ",", "\n", "# 2", "\n", "self", ".", "layer2", ",", "\n", "# 3", "\n", "self", ".", "layer3", ",", "\n", "# 4", "\n", "self", ".", "layer4", ",", "\n", "# 5", "\n", "nn", ".", "Sequential", "(", "\n", "self", ".", "avgpool", ",", "\n", "nn", ".", "Flatten", "(", ")", "\n", ")", ",", "\n", "# 6", "\n", "self", ".", "bottleneck", ",", "# Might be Identity if bottleneck is disabled", "\n", "# 7", "\n", "self", ".", "fc", ",", "\n", "# 8", "\n", "plug_position", "=", "plug_position", "\n", ")", "\n", "\n", "self", ".", "plug_position", "=", "plug_position", "\n", "self", ".", "__in_features", "=", "bottleneck_size", "\n", "\n"]], "home.repos.pwc.inspect_result.lr94_abas.net.resnet.ResNetFc.forward": [[71, 75], ["resnet.ResNetFc.layers"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", ",", "features", "=", "self", ".", "layers", "(", "x", ")", "\n", "\n", "return", "x", ",", "features", "\n", "\n"]], "home.repos.pwc.inspect_result.lr94_abas.net.resnet.ResNetFc.output_size": [[76, 80], ["None"], "methods", ["None"], ["", "def", "output_size", "(", "self", ")", ":", "\n", "# TODO change if changing plug_position!!!", "\n", "        ", "assert", "self", ".", "plug_position", "==", "7", "\n", "return", "self", ".", "fc", ".", "in_features", "\n", "\n"]], "home.repos.pwc.inspect_result.lr94_abas.net.resnet.ResNetFc.get_parameters": [[81, 110], ["itertools.chain", "resnet.ResNetFc.bottleneck.parameters", "resnet.ResNetFc.fc.parameters", "resnet.ResNetFc.conv1.parameters", "resnet.ResNetFc.bn1.parameters", "resnet.ResNetFc.maxpool.parameters", "resnet.ResNetFc.layer1.parameters", "resnet.ResNetFc.layer2.parameters", "resnet.ResNetFc.layer3.parameters", "resnet.ResNetFc.layer4.parameters", "resnet.ResNetFc.avgpool.parameters"], "methods", ["None"], ["", "def", "get_parameters", "(", "self", ",", "base_lr", ",", "base_wd", ")", ":", "\n", "        ", "parameter_list", "=", "[", "\n", "{", "\n", "\"params\"", ":", "itertools", ".", "chain", "(", "\n", "self", ".", "conv1", ".", "parameters", "(", ")", ",", "\n", "self", ".", "bn1", ".", "parameters", "(", ")", ",", "\n", "self", ".", "maxpool", ".", "parameters", "(", ")", ",", "\n", "self", ".", "layer1", ".", "parameters", "(", ")", ",", "\n", "self", ".", "layer2", ".", "parameters", "(", ")", ",", "\n", "self", ".", "layer3", ".", "parameters", "(", ")", ",", "\n", "self", ".", "layer4", ".", "parameters", "(", ")", ",", "\n", "self", ".", "avgpool", ".", "parameters", "(", ")", "\n", ")", ",", "\n", "\"lr\"", ":", "base_lr", ",", "\n", "'weight_decay'", ":", "base_wd", "*", "2", "\n", "}", ",", "\n", "{", "\n", "\"params\"", ":", "self", ".", "bottleneck", ".", "parameters", "(", ")", ",", "\n", "\"lr\"", ":", "base_lr", "*", "10", ",", "\n", "'weight_decay'", ":", "base_wd", "*", "2", "\n", "}", ",", "\n", "{", "\n", "\"params\"", ":", "self", ".", "fc", ".", "parameters", "(", ")", ",", "\n", "\"lr\"", ":", "base_lr", "*", "10", ",", "\n", "'weight_decay'", ":", "base_wd", "*", "2", "\n", "}", "\n", "]", "\n", "\n", "return", "parameter_list", "\n", "\n"]], "home.repos.pwc.inspect_result.lr94_abas.net.resnet.ResNetFc.freeze": [[111, 113], ["common.FrozenContext", "resnet.ResNetFc.parameters"], "methods", ["None"], ["", "def", "freeze", "(", "self", ")", "->", "FrozenContext", ":", "\n", "        ", "return", "FrozenContext", "(", "self", ".", "parameters", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.lr94_abas.net.resnet.Discriminator.__init__": [[155, 165], ["nn.Module.__init__", "resnet.generate_fc_stack", "resnet.Discriminator.layers.apply", "common.GradientReversalLayer"], "methods", ["home.repos.pwc.inspect_result.lr94_abas.net.resnet.Discriminator.__init__", "home.repos.pwc.inspect_result.lr94_abas.net.resnet.generate_fc_stack"], ["    ", "def", "__init__", "(", "self", ",", "in_feature", ",", "num_classes", ",", "hidden_size", "=", "1024", ",", "num_fc_layers", "=", "3", ",", "dropout", "=", "0.5", ")", ":", "\n", "        ", "super", "(", "Discriminator", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "layers", "=", "generate_fc_stack", "(", "in_features", "=", "in_feature", ",", "\n", "out_features", "=", "num_classes", ",", "\n", "num_fc_layers", "=", "num_fc_layers", ",", "\n", "num_units", "=", "hidden_size", ",", "\n", "dropout", "=", "dropout", ")", "\n", "\n", "self", ".", "layers", ".", "apply", "(", "init_weights", ")", "\n", "self", ".", "grl_module", "=", "GradientReversalLayer", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.lr94_abas.net.resnet.Discriminator.forward": [[166, 170], ["resnet.Discriminator.grl_module", "resnet.Discriminator.layers"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "lambda_v", ")", ":", "\n", "        ", "x", "=", "self", ".", "grl_module", "(", "x", ",", "lambda_v", ")", "\n", "y", "=", "self", ".", "layers", "(", "x", ")", "\n", "return", "y", "\n", "\n"]], "home.repos.pwc.inspect_result.lr94_abas.net.resnet.Discriminator.get_parameters": [[171, 176], ["resnet.Discriminator.layers.parameters"], "methods", ["None"], ["", "def", "get_parameters", "(", "self", ",", "base_lr", ",", "base_wd", ")", ":", "\n", "        ", "return", "[", "{", "\n", "\"params\"", ":", "self", ".", "layers", ".", "parameters", "(", ")", ",", "\n", "\"lr\"", ":", "base_lr", "*", "10", ",", "\n", "'weight_decay'", ":", "base_wd", "*", "2", "\n", "}", "]", "\n"]], "home.repos.pwc.inspect_result.lr94_abas.net.resnet.generate_fc_stack": [[115, 152], ["range", "fc_layers.append", "nn.Sequential", "fc_layers.append", "nn.Linear", "nn.Linear", "nn.ReLU", "modules.append", "nn.Sequential", "nn.Dropout", "len"], "function", ["None"], ["", "", "def", "generate_fc_stack", "(", "in_features", ":", "int", ",", "out_features", ":", "int", ",", "num_fc_layers", ":", "int", ",", "num_units", ":", "int", ",", "\n", "dropout", ":", "float", "=", "0", ")", "->", "nn", ".", "Module", ":", "\n", "    ", "\"\"\"\n    Generate a variable-size fully connected block\n    :param in_features:\n    :param out_features:\n    :param num_fc_layers:\n    :param num_units:\n    :param dropout:\n    :return:\n    \"\"\"", "\n", "assert", "num_fc_layers", ">=", "1", "\n", "\n", "# List of layers", "\n", "fc_layers", "=", "[", "]", "\n", "# -1 because the final layer will be added separately", "\n", "for", "i", "in", "range", "(", "num_fc_layers", "-", "1", ")", ":", "\n", "# If this is the first layer, its input size is bound to match in_features", "\n", "        ", "fc_in_features", "=", "in_features", "if", "i", "==", "0", "else", "num_units", "\n", "# Output size is fixed (for now)", "\n", "fc_out_features", "=", "num_units", "\n", "# Add the layer with its activation (ReLU) and Dropout if required", "\n", "modules", "=", "[", "\n", "nn", ".", "Linear", "(", "in_features", "=", "fc_in_features", ",", "out_features", "=", "fc_out_features", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", "\n", "]", "\n", "if", "dropout", "!=", "0.", ":", "\n", "            ", "modules", ".", "append", "(", "nn", ".", "Dropout", "(", "p", "=", "dropout", ")", ")", "\n", "", "fc_layers", ".", "append", "(", "nn", ".", "Sequential", "(", "*", "modules", ")", ")", "\n", "\n", "# Add the final layer", "\n", "", "fc_layers", ".", "append", "(", "\n", "# in_features if there are not previous layers (this is the only one)", "\n", "nn", ".", "Linear", "(", "in_features", "=", "in_features", "if", "len", "(", "fc_layers", ")", "==", "0", "else", "num_units", ",", "out_features", "=", "out_features", ")", "\n", ")", "\n", "\n", "return", "nn", ".", "Sequential", "(", "*", "fc_layers", ")", "\n", "\n"]]}