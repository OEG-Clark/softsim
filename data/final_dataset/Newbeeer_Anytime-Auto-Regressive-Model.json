{"home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.None.test_functions.test_vq_shape": [[8, 16], ["torch.rand", "torch.rand", "functions.vq", "functions.vq.size"], "function", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.fairseq_dataset.FairseqDataset.size"], ["def", "test_vq_shape", "(", ")", ":", "\n", "    ", "inputs", "=", "torch", ".", "rand", "(", "(", "2", ",", "3", ",", "5", ",", "7", ")", ",", "dtype", "=", "torch", ".", "float32", ",", "requires_grad", "=", "True", ")", "\n", "codebook", "=", "torch", ".", "rand", "(", "(", "11", ",", "7", ")", ",", "dtype", "=", "torch", ".", "float32", ",", "requires_grad", "=", "True", ")", "\n", "indices", "=", "vq", "(", "inputs", ",", "codebook", ")", "\n", "\n", "assert", "indices", ".", "size", "(", ")", "==", "(", "2", ",", "3", ",", "5", ")", "\n", "assert", "not", "indices", ".", "requires_grad", "\n", "assert", "indices", ".", "dtype", "==", "torch", ".", "int64", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.None.test_functions.test_vq": [[17, 28], ["torch.rand", "torch.rand", "functions.vq", "torch.norm", "torch.min", "numpy.allclose", "torch.rand.unsqueeze", "functions.vq.numpy", "indices_torch.numpy"], "function", ["None"], ["", "def", "test_vq", "(", ")", ":", "\n", "    ", "inputs", "=", "torch", ".", "rand", "(", "(", "2", ",", "3", ",", "5", ",", "7", ")", ",", "dtype", "=", "torch", ".", "float32", ",", "requires_grad", "=", "True", ")", "\n", "codebook", "=", "torch", ".", "rand", "(", "(", "11", ",", "7", ")", ",", "dtype", "=", "torch", ".", "float32", ",", "requires_grad", "=", "True", ")", "\n", "indices", "=", "vq", "(", "inputs", ",", "codebook", ")", "\n", "\n", "differences", "=", "inputs", ".", "unsqueeze", "(", "3", ")", "-", "codebook", "\n", "distances", "=", "torch", ".", "norm", "(", "differences", ",", "p", "=", "2", ",", "dim", "=", "4", ")", "\n", "\n", "_", ",", "indices_torch", "=", "torch", ".", "min", "(", "distances", ",", "dim", "=", "3", ")", "\n", "\n", "assert", "np", ".", "allclose", "(", "indices", ".", "numpy", "(", ")", ",", "indices_torch", ".", "numpy", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.None.test_functions.test_vq_st_shape": [[29, 41], ["torch.rand", "torch.rand", "functions.vq_st", "codes.size", "indices.size"], "function", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.fairseq_dataset.FairseqDataset.size", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.fairseq_dataset.FairseqDataset.size"], ["", "def", "test_vq_st_shape", "(", ")", ":", "\n", "    ", "inputs", "=", "torch", ".", "rand", "(", "(", "2", ",", "3", ",", "5", ",", "7", ")", ",", "dtype", "=", "torch", ".", "float32", ",", "requires_grad", "=", "True", ")", "\n", "codebook", "=", "torch", ".", "rand", "(", "(", "11", ",", "7", ")", ",", "dtype", "=", "torch", ".", "float32", ",", "requires_grad", "=", "True", ")", "\n", "codes", ",", "indices", "=", "vq_st", "(", "inputs", ",", "codebook", ")", "\n", "\n", "assert", "codes", ".", "size", "(", ")", "==", "(", "2", ",", "3", ",", "5", ",", "7", ")", "\n", "assert", "codes", ".", "requires_grad", "\n", "assert", "codes", ".", "dtype", "==", "torch", ".", "float32", "\n", "\n", "assert", "indices", ".", "size", "(", ")", "==", "(", "2", "*", "3", "*", "5", ",", ")", "\n", "assert", "not", "indices", ".", "requires_grad", "\n", "assert", "indices", ".", "dtype", "==", "torch", ".", "int64", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.None.test_functions.test_vq_st_gradient1": [[42, 54], ["torch.rand", "torch.rand", "functions.vq_st", "torch.rand", "torch.autograd.grad", "numpy.allclose", "grad_inputs.size", "torch.rand.numpy", "grad_inputs.numpy"], "function", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.fairseq_dataset.FairseqDataset.size"], ["", "def", "test_vq_st_gradient1", "(", ")", ":", "\n", "    ", "inputs", "=", "torch", ".", "rand", "(", "(", "2", ",", "3", ",", "5", ",", "7", ")", ",", "dtype", "=", "torch", ".", "float32", ",", "requires_grad", "=", "True", ")", "\n", "codebook", "=", "torch", ".", "rand", "(", "(", "11", ",", "7", ")", ",", "dtype", "=", "torch", ".", "float32", ",", "requires_grad", "=", "True", ")", "\n", "codes", ",", "_", "=", "vq_st", "(", "inputs", ",", "codebook", ")", "\n", "\n", "grad_output", "=", "torch", ".", "rand", "(", "(", "2", ",", "3", ",", "5", ",", "7", ")", ")", "\n", "grad_inputs", ",", "=", "torch", ".", "autograd", ".", "grad", "(", "codes", ",", "inputs", ",", "\n", "grad_outputs", "=", "[", "grad_output", "]", ")", "\n", "\n", "# Straight-through estimator", "\n", "assert", "grad_inputs", ".", "size", "(", ")", "==", "(", "2", ",", "3", ",", "5", ",", "7", ")", "\n", "assert", "np", ".", "allclose", "(", "grad_output", ".", "numpy", "(", ")", ",", "grad_inputs", ".", "numpy", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.None.test_functions.test_vq_st_gradient2": [[55, 73], ["torch.rand", "torch.rand", "functions.vq_st", "functions.vq", "torch.embedding", "torch.rand", "torch.autograd.grad", "torch.autograd.grad", "numpy.allclose", "grad_codebook.size", "grad_codebook.numpy", "grad_codebook_torch.numpy"], "function", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.fairseq_dataset.FairseqDataset.size"], ["", "def", "test_vq_st_gradient2", "(", ")", ":", "\n", "    ", "inputs", "=", "torch", ".", "rand", "(", "(", "2", ",", "3", ",", "5", ",", "7", ")", ",", "dtype", "=", "torch", ".", "float32", ",", "requires_grad", "=", "True", ")", "\n", "codebook", "=", "torch", ".", "rand", "(", "(", "11", ",", "7", ")", ",", "dtype", "=", "torch", ".", "float32", ",", "requires_grad", "=", "True", ")", "\n", "codes", ",", "_", "=", "vq_st", "(", "inputs", ",", "codebook", ")", "\n", "\n", "indices", "=", "vq", "(", "inputs", ",", "codebook", ")", "\n", "codes_torch", "=", "torch", ".", "embedding", "(", "codebook", ",", "indices", ",", "padding_idx", "=", "-", "1", ",", "\n", "scale_grad_by_freq", "=", "False", ",", "sparse", "=", "False", ")", "\n", "\n", "grad_output", "=", "torch", ".", "rand", "(", "(", "2", ",", "3", ",", "5", ",", "7", ")", ",", "dtype", "=", "torch", ".", "float32", ")", "\n", "grad_codebook", ",", "=", "torch", ".", "autograd", ".", "grad", "(", "codes", ",", "codebook", ",", "\n", "grad_outputs", "=", "[", "grad_output", "]", ")", "\n", "grad_codebook_torch", ",", "=", "torch", ".", "autograd", ".", "grad", "(", "codes_torch", ",", "codebook", ",", "\n", "grad_outputs", "=", "[", "grad_output", "]", ")", "\n", "\n", "# Gradient is the same as torch.embedding function", "\n", "assert", "grad_codebook", ".", "size", "(", ")", "==", "(", "11", ",", "7", ")", "\n", "assert", "np", ".", "allclose", "(", "grad_codebook", ".", "numpy", "(", ")", ",", "grad_codebook_torch", ".", "numpy", "(", ")", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.None.pixelcnn_prior.train": [[13, 35], ["tqdm.tqdm", "labels.to.to", "prior", "logits.permute().contiguous.permute().contiguous", "optimizer.zero_grad", "torch.cross_entropy", "F.cross_entropy.backward", "writer.add_scalar", "optimizer.step", "torch.no_grad", "torch.no_grad", "images.to.to", "model.encode", "latents.detach.detach", "logits.permute().contiguous.view", "latents.detach.view", "F.cross_entropy.item", "logits.permute().contiguous.permute"], "function", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.optim.fp16_optimizer._MemoryEfficientFP16OptimizerMixin.zero_grad", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.optim.fp16_optimizer._MemoryEfficientFP16OptimizerMixin.backward", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.lr_scheduler.polynomial_decay_schedule.PolynomialDecaySchedule.step", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq._hub_utils.TokenizerHubInterface.encode", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.utils.item"], ["def", "train", "(", "data_loader", ",", "model", ",", "prior", ",", "optimizer", ",", "args", ",", "writer", ")", ":", "\n", "\n", "    ", "for", "images", ",", "labels", "in", "tqdm", "(", "data_loader", ")", ":", "\n", "        ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "images", "=", "images", ".", "to", "(", "args", ".", "device", ")", "\n", "latents", "=", "model", ".", "encode", "(", "images", ")", "\n", "latents", "=", "latents", ".", "detach", "(", ")", "\n", "\n", "", "labels", "=", "labels", ".", "to", "(", "args", ".", "device", ")", "\n", "logits", "=", "prior", "(", "latents", ",", "labels", ")", "\n", "logits", "=", "logits", ".", "permute", "(", "0", ",", "2", ",", "3", ",", "1", ")", ".", "contiguous", "(", ")", "\n", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "loss", "=", "F", ".", "cross_entropy", "(", "logits", ".", "view", "(", "-", "1", ",", "args", ".", "k", ")", ",", "\n", "latents", ".", "view", "(", "-", "1", ")", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "\n", "# Logs", "\n", "writer", ".", "add_scalar", "(", "'loss/train'", ",", "loss", ".", "item", "(", ")", ",", "args", ".", "steps", ")", "\n", "\n", "optimizer", ".", "step", "(", ")", "\n", "args", ".", "steps", "+=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.None.pixelcnn_prior.test": [[36, 56], ["writer.add_scalar", "loss.item", "torch.no_grad", "torch.no_grad", "len", "loss.item", "images.to.to", "labels.to.to", "model.encode", "latents.detach.detach", "prior", "logits.permute().contiguous.permute().contiguous", "torch.cross_entropy", "logits.permute().contiguous.view", "latents.detach.view", "logits.permute().contiguous.permute"], "function", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.utils.item", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.utils.item", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq._hub_utils.TokenizerHubInterface.encode"], ["", "", "def", "test", "(", "data_loader", ",", "model", ",", "prior", ",", "args", ",", "writer", ")", ":", "\n", "    ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "loss", "=", "0.", "\n", "for", "images", ",", "labels", "in", "data_loader", ":", "\n", "            ", "images", "=", "images", ".", "to", "(", "args", ".", "device", ")", "\n", "labels", "=", "labels", ".", "to", "(", "args", ".", "device", ")", "\n", "\n", "latents", "=", "model", ".", "encode", "(", "images", ")", "\n", "latents", "=", "latents", ".", "detach", "(", ")", "\n", "logits", "=", "prior", "(", "latents", ",", "labels", ")", "\n", "logits", "=", "logits", ".", "permute", "(", "0", ",", "2", ",", "3", ",", "1", ")", ".", "contiguous", "(", ")", "\n", "loss", "+=", "F", ".", "cross_entropy", "(", "logits", ".", "view", "(", "-", "1", ",", "args", ".", "k", ")", ",", "\n", "latents", ".", "view", "(", "-", "1", ")", ")", "\n", "\n", "", "loss", "/=", "len", "(", "data_loader", ")", "\n", "\n", "# Logs", "\n", "", "writer", ".", "add_scalar", "(", "'loss/valid'", ",", "loss", ".", "item", "(", ")", ",", "args", ".", "steps", ")", "\n", "\n", "return", "loss", ".", "item", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.None.pixelcnn_prior.main": [[57, 149], ["tensorboardX.SummaryWriter", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "next", "torchvision.utils.make_grid", "tensorboardX.SummaryWriter.add_image", "modules.VectorQuantizedVAE_Dim().to", "VectorQuantizedVAE_Dim().to.load_state_dict", "VectorQuantizedVAE_Dim().to.eval", "modules.GatedPixelCNN().to", "torch.optim.Adam", "torch.optim.Adam", "range", "torchvision.transforms.Compose", "iter", "torch.load", "torch.load", "GatedPixelCNN().to.parameters", "pixelcnn_prior.train", "pixelcnn_prior.test", "torch.tensor().cuda", "torch.tensor().cuda", "VectorQuantizedVAE_Dim().to.decode", "torchvision.utils.make_grid", "tensorboardX.SummaryWriter.add_image", "torchvision.datasets.MNIST", "torchvision.datasets.MNIST", "torchvision.transforms.Compose", "datasets.MiniImagenet", "datasets.MiniImagenet", "datasets.MiniImagenet", "modules.VectorQuantizedVAE_Dim", "modules.GatedPixelCNN", "int", "GatedPixelCNN().to.generate", "model.decode.cpu", "torchvision.transforms.ToTensor", "torchvision.transforms.Normalize", "torchvision.datasets.FashionMNIST", "torchvision.datasets.FashionMNIST", "range", "torch.tensor", "torch.tensor", "open", "torch.save", "torch.save", "torchvision.transforms.Compose", "torchvision.datasets.CIFAR10", "torchvision.datasets.CIFAR10", "torchvision.transforms.RandomResizedCrop", "torchvision.transforms.ToTensor", "torchvision.transforms.Normalize", "GatedPixelCNN().to.state_dict", "torchvision.transforms.ToTensor", "torchvision.transforms.Normalize"], "function", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.iterators.EpochBatchIterator.load_state_dict", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.utils.eval", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.None.train_ar.train", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.None.prior_sampler.test", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq._hub_utils.TokenizerHubInterface.decode", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.sequence_generator.SequenceGenerator.generate", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.iterators.EpochBatchIterator.state_dict"], ["", "def", "main", "(", "args", ")", ":", "\n", "    ", "writer", "=", "SummaryWriter", "(", "'./logs/{0}'", ".", "format", "(", "args", ".", "output_folder", ")", ")", "\n", "save_filename", "=", "'./models/{0}/prior.pt'", ".", "format", "(", "args", ".", "output_folder", ")", "\n", "\n", "if", "args", ".", "dataset", "in", "[", "'mnist'", ",", "'fashion-mnist'", ",", "'cifar10'", "]", ":", "\n", "        ", "transform", "=", "transforms", ".", "Compose", "(", "[", "\n", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "transforms", ".", "Normalize", "(", "(", "0.1307", ",", ")", ",", "(", "0.3081", ",", ")", ")", "\n", "]", ")", "\n", "if", "args", ".", "dataset", "==", "'mnist'", ":", "\n", "# Define the train & test datasets", "\n", "            ", "train_dataset", "=", "datasets", ".", "MNIST", "(", "args", ".", "data_folder", ",", "train", "=", "True", ",", "\n", "download", "=", "True", ",", "transform", "=", "transform", ")", "\n", "test_dataset", "=", "datasets", ".", "MNIST", "(", "args", ".", "data_folder", ",", "train", "=", "False", ",", "\n", "transform", "=", "transform", ")", "\n", "num_channels", "=", "1", "\n", "", "elif", "args", ".", "dataset", "==", "'fashion-mnist'", ":", "\n", "# Define the train & test datasets", "\n", "            ", "train_dataset", "=", "datasets", ".", "FashionMNIST", "(", "args", ".", "data_folder", ",", "\n", "train", "=", "True", ",", "download", "=", "True", ",", "transform", "=", "transform", ")", "\n", "test_dataset", "=", "datasets", ".", "FashionMNIST", "(", "args", ".", "data_folder", ",", "\n", "train", "=", "False", ",", "transform", "=", "transform", ")", "\n", "num_channels", "=", "1", "\n", "", "elif", "args", ".", "dataset", "==", "'cifar10'", ":", "\n", "            ", "transform", "=", "transforms", ".", "Compose", "(", "\n", "[", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "transforms", ".", "Normalize", "(", "(", "0.5", ",", "0.5", ",", "0.5", ")", ",", "(", "0.5", ",", "0.5", ",", "0.5", ")", ")", "]", ")", "\n", "# Define the train & test datasets", "\n", "train_dataset", "=", "datasets", ".", "CIFAR10", "(", "args", ".", "data_folder", ",", "\n", "train", "=", "True", ",", "download", "=", "True", ",", "transform", "=", "transform", ")", "\n", "test_dataset", "=", "datasets", ".", "CIFAR10", "(", "args", ".", "data_folder", ",", "\n", "train", "=", "False", ",", "transform", "=", "transform", ")", "\n", "num_channels", "=", "3", "\n", "", "valid_dataset", "=", "test_dataset", "\n", "", "elif", "args", ".", "dataset", "==", "'miniimagenet'", ":", "\n", "        ", "transform", "=", "transforms", ".", "Compose", "(", "[", "\n", "transforms", ".", "RandomResizedCrop", "(", "128", ")", ",", "\n", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "transforms", ".", "Normalize", "(", "(", "0.5", ",", "0.5", ",", "0.5", ")", ",", "(", "0.5", ",", "0.5", ",", "0.5", ")", ")", "\n", "]", ")", "\n", "# Define the train, valid & test datasets", "\n", "train_dataset", "=", "MiniImagenet", "(", "args", ".", "data_folder", ",", "train", "=", "True", ",", "\n", "download", "=", "True", ",", "transform", "=", "transform", ")", "\n", "valid_dataset", "=", "MiniImagenet", "(", "args", ".", "data_folder", ",", "valid", "=", "True", ",", "\n", "download", "=", "True", ",", "transform", "=", "transform", ")", "\n", "test_dataset", "=", "MiniImagenet", "(", "args", ".", "data_folder", ",", "test", "=", "True", ",", "\n", "download", "=", "True", ",", "transform", "=", "transform", ")", "\n", "num_channels", "=", "3", "\n", "\n", "# Define the data loaders", "\n", "", "train_loader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "train_dataset", ",", "\n", "batch_size", "=", "args", ".", "batch_size", ",", "shuffle", "=", "False", ",", "\n", "num_workers", "=", "args", ".", "num_workers", ",", "pin_memory", "=", "True", ")", "\n", "valid_loader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "valid_dataset", ",", "\n", "batch_size", "=", "args", ".", "batch_size", ",", "shuffle", "=", "False", ",", "drop_last", "=", "True", ",", "\n", "num_workers", "=", "args", ".", "num_workers", ",", "pin_memory", "=", "True", ")", "\n", "test_loader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "test_dataset", ",", "\n", "batch_size", "=", "16", ",", "shuffle", "=", "True", ")", "\n", "\n", "# Save the label encoder", "\n", "# with open('./models/{0}/labels.json'.format(args.output_folder), 'w') as f:", "\n", "#     json.dump(train_dataset._label_encoder, f)", "\n", "\n", "# Fixed images for Tensorboard", "\n", "fixed_images", ",", "_", "=", "next", "(", "iter", "(", "test_loader", ")", ")", "\n", "fixed_grid", "=", "make_grid", "(", "fixed_images", ",", "nrow", "=", "8", ",", "range", "=", "(", "-", "1", ",", "1", ")", ",", "normalize", "=", "True", ")", "\n", "writer", ".", "add_image", "(", "'original'", ",", "fixed_grid", ",", "0", ")", "\n", "\n", "model", "=", "VectorQuantizedVAE_Dim", "(", "num_channels", ",", "args", ".", "hidden_size_vae", ",", "args", ".", "k", ")", ".", "to", "(", "args", ".", "device", ")", "\n", "model", ".", "load_state_dict", "(", "torch", ".", "load", "(", "'models/vqvae-h100k500-factor2-946012/best.pt'", ")", ")", "\n", "model", ".", "eval", "(", ")", "\n", "\n", "prior", "=", "GatedPixelCNN", "(", "args", ".", "k", ",", "args", ".", "hidden_size_prior", ",", "\n", "args", ".", "num_layers", ",", "n_classes", "=", "10", ")", ".", "to", "(", "args", ".", "device", ")", "\n", "optimizer", "=", "torch", ".", "optim", ".", "Adam", "(", "prior", ".", "parameters", "(", ")", ",", "lr", "=", "args", ".", "lr", ")", "\n", "\n", "best_loss", "=", "-", "1.", "\n", "for", "epoch", "in", "range", "(", "args", ".", "num_epochs", ")", ":", "\n", "        ", "train", "(", "train_loader", ",", "model", ",", "prior", ",", "optimizer", ",", "args", ",", "writer", ")", "\n", "# The validation loss is not properly computed since", "\n", "# the classes in the train and valid splits of Mini-Imagenet", "\n", "# do not overlap.", "\n", "loss", "=", "test", "(", "valid_loader", ",", "model", ",", "prior", ",", "args", ",", "writer", ")", "\n", "label_", "=", "[", "int", "(", "i", "%", "10", ")", "for", "i", "in", "range", "(", "16", ")", "]", "\n", "label_", "=", "torch", ".", "tensor", "(", "label_", ")", ".", "cuda", "(", ")", "\n", "reconstruction", "=", "model", ".", "decode", "(", "prior", ".", "generate", "(", "label", "=", "label_", ",", "batch_size", "=", "16", ")", ")", "\n", "grid", "=", "make_grid", "(", "reconstruction", ".", "cpu", "(", ")", ",", "nrow", "=", "8", ",", "range", "=", "(", "-", "1", ",", "1", ")", ",", "normalize", "=", "True", ")", "\n", "writer", ".", "add_image", "(", "'Full sampling result'", ",", "grid", ",", "epoch", "+", "1", ")", "\n", "if", "(", "epoch", "==", "0", ")", "or", "(", "loss", "<", "best_loss", ")", ":", "\n", "            ", "best_loss", "=", "loss", "\n", "with", "open", "(", "save_filename", ",", "'wb'", ")", "as", "f", ":", "\n", "                ", "torch", ".", "save", "(", "prior", ".", "state_dict", "(", ")", ",", "f", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.None.pixelcnn_baseline.train": [[45, 73], ["enumerate", "time.time", "label.cuda.cuda", "model", "logits.permute().contiguous.permute().contiguous", "criterion", "opt.zero_grad", "criterion.backward", "opt.step", "train_loss.append", "logits.permute().contiguous.view", "x.view", "criterion.item", "print", "logits.permute().contiguous.permute", "len", "[].mean", "len", "len", "time.time", "numpy.asarray"], "function", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.trainer.Trainer.model", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.trainer.Trainer.criterion", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.optim.fp16_optimizer._MemoryEfficientFP16OptimizerMixin.zero_grad", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.optim.fp16_optimizer._MemoryEfficientFP16OptimizerMixin.backward", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.lr_scheduler.polynomial_decay_schedule.PolynomialDecaySchedule.step", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.utils.item", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.progress_bar.tensorboard_log_wrapper.print"], ["def", "train", "(", ")", ":", "\n", "    ", "train_loss", "=", "[", "]", "\n", "for", "batch_idx", ",", "(", "x", ",", "label", ")", "in", "enumerate", "(", "train_loader", ")", ":", "\n", "        ", "start_time", "=", "time", ".", "time", "(", ")", "\n", "x", "=", "(", "x", "[", ":", ",", "0", "]", "*", "(", "K", "-", "1", ")", ")", ".", "long", "(", ")", ".", "cuda", "(", ")", "\n", "label", "=", "label", ".", "cuda", "(", ")", "\n", "\n", "# Train PixelCNN with images", "\n", "logits", "=", "model", "(", "x", ",", "label", ")", "\n", "logits", "=", "logits", ".", "permute", "(", "0", ",", "2", ",", "3", ",", "1", ")", ".", "contiguous", "(", ")", "\n", "\n", "loss", "=", "criterion", "(", "\n", "logits", ".", "view", "(", "-", "1", ",", "K", ")", ",", "\n", "x", ".", "view", "(", "-", "1", ")", "\n", ")", "\n", "\n", "opt", ".", "zero_grad", "(", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "opt", ".", "step", "(", ")", "\n", "\n", "train_loss", ".", "append", "(", "loss", ".", "item", "(", ")", ")", "\n", "\n", "if", "(", "batch_idx", "+", "1", ")", "%", "PRINT_INTERVAL", "==", "0", ":", "\n", "            ", "print", "(", "'\\tIter: [{}/{} ({:.0f}%)]\\tLoss: {} Time: {}'", ".", "format", "(", "\n", "batch_idx", "*", "len", "(", "x", ")", ",", "len", "(", "train_loader", ".", "dataset", ")", ",", "\n", "PRINT_INTERVAL", "*", "batch_idx", "/", "len", "(", "train_loader", ")", ",", "\n", "np", ".", "asarray", "(", "train_loss", ")", "[", "-", "PRINT_INTERVAL", ":", "]", ".", "mean", "(", "0", ")", ",", "\n", "time", ".", "time", "(", ")", "-", "start_time", "\n", ")", ")", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.None.pixelcnn_baseline.test": [[76, 97], ["time.time", "print", "numpy.asarray().mean", "torch.no_grad", "torch.no_grad", "enumerate", "label.cuda.cuda", "model", "logits.permute().contiguous.permute().contiguous", "criterion", "val_loss.append", "numpy.asarray().mean", "numpy.asarray", "logits.permute().contiguous.view", "x.view", "criterion.item", "time.time", "logits.permute().contiguous.permute", "numpy.asarray"], "function", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.progress_bar.tensorboard_log_wrapper.print", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.trainer.Trainer.model", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.trainer.Trainer.criterion", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.utils.item"], ["", "", "", "def", "test", "(", ")", ":", "\n", "    ", "start_time", "=", "time", ".", "time", "(", ")", "\n", "val_loss", "=", "[", "]", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "for", "batch_idx", ",", "(", "x", ",", "label", ")", "in", "enumerate", "(", "test_loader", ")", ":", "\n", "            ", "x", "=", "(", "x", "[", ":", ",", "0", "]", "*", "(", "K", "-", "1", ")", ")", ".", "long", "(", ")", ".", "cuda", "(", ")", "\n", "label", "=", "label", ".", "cuda", "(", ")", "\n", "\n", "logits", "=", "model", "(", "x", ",", "label", ")", "\n", "logits", "=", "logits", ".", "permute", "(", "0", ",", "2", ",", "3", ",", "1", ")", ".", "contiguous", "(", ")", "\n", "loss", "=", "criterion", "(", "\n", "logits", ".", "view", "(", "-", "1", ",", "K", ")", ",", "\n", "x", ".", "view", "(", "-", "1", ")", "\n", ")", "\n", "val_loss", ".", "append", "(", "loss", ".", "item", "(", ")", ")", "\n", "\n", "", "", "print", "(", "'Validation Completed!\\tLoss: {} Time: {}'", ".", "format", "(", "\n", "np", ".", "asarray", "(", "val_loss", ")", ".", "mean", "(", "0", ")", ",", "\n", "time", ".", "time", "(", ")", "-", "start_time", "\n", ")", ")", "\n", "return", "np", ".", "asarray", "(", "val_loss", ")", ".", "mean", "(", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.None.pixelcnn_baseline.generate_samples": [[99, 110], ["torch.arange().expand().contiguous().view", "torch.arange().expand().contiguous().view", "label.long().cuda.long().cuda", "model.generate", "torchvision.utils.save_image", "model.generate.cpu().data.float", "torch.arange().expand().contiguous", "torch.arange().expand().contiguous", "label.long().cuda.long", "torch.arange().expand", "torch.arange().expand", "model.generate.cpu", "torch.arange", "torch.arange"], "function", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.sequence_generator.SequenceGenerator.generate"], ["", "def", "generate_samples", "(", ")", ":", "\n", "    ", "label", "=", "torch", ".", "arange", "(", "10", ")", ".", "expand", "(", "10", ",", "10", ")", ".", "contiguous", "(", ")", ".", "view", "(", "-", "1", ")", "\n", "label", "=", "label", ".", "long", "(", ")", ".", "cuda", "(", ")", "\n", "\n", "x_tilde", "=", "model", ".", "generate", "(", "label", ",", "shape", "=", "IMAGE_SHAPE", ",", "batch_size", "=", "100", ")", "\n", "images", "=", "x_tilde", ".", "cpu", "(", ")", ".", "data", ".", "float", "(", ")", "/", "(", "K", "-", "1", ")", "\n", "\n", "save_image", "(", "\n", "images", "[", ":", ",", "None", "]", ",", "\n", "'samples/pixelcnn_baseline_samples_{}.png'", ".", "format", "(", "DATASET", ")", ",", "\n", "nrow", "=", "10", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.None.modules.VQEmbedding_Original.__init__": [[26, 31], ["torch.Module.__init__", "torch.Embedding", "torch.Embedding", "torch.Embedding", "modules.VQEmbedding_Original.embedding.weight.data.uniform_"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.dummy_dictionary.DummyDictionary.__init__", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.transformer.Embedding", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.transformer.Embedding", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.transformer.Embedding"], ["    ", "def", "__init__", "(", "self", ",", "K", ",", "D", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "D", "=", "D", "\n", "self", ".", "embedding", "=", "nn", ".", "Embedding", "(", "K", ",", "D", ")", "\n", "self", ".", "embedding", ".", "weight", ".", "data", ".", "uniform_", "(", "-", "1.", "/", "K", ",", "1.", "/", "K", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.None.modules.VQEmbedding_Original.forward": [[32, 36], ["z_e_x.permute().contiguous", "functions.vq", "z_e_x.permute"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "z_e_x", ")", ":", "\n", "        ", "z_e_x_", "=", "z_e_x", ".", "permute", "(", "0", ",", "2", ",", "3", ",", "1", ")", ".", "contiguous", "(", ")", "\n", "latents", "=", "vq", "(", "z_e_x_", ",", "self", ".", "embedding", ".", "weight", ")", "\n", "return", "latents", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.None.modules.VQEmbedding_Original.straight_through": [[37, 53], ["z_e_x.permute().contiguous", "z_q_x_.permute().contiguous", "torch.index_select", "torch.index_select", "torch.index_select", "torch.index_select", "torch.index_select", "torch.index_select", "torch.index_select", "torch.index_select", "torch.index_select", "torch.index_select.view_as", "torch.index_select.view_as", "torch.index_select.view_as", "torch.index_select.view_as.permute().contiguous", "functions.vq_st_i_ori", "functions.vq_st_ori", "z_e_x.permute", "modules.VQEmbedding_Original.embedding.weight.detach", "modules.VQEmbedding_Original.embedding.weight.detach", "z_q_x_.permute", "torch.index_select.view_as.permute"], "methods", ["None"], ["", "def", "straight_through", "(", "self", ",", "z_e_x", ",", "index", "=", "False", ")", ":", "\n", "\n", "        ", "z_e_x_", "=", "z_e_x", ".", "permute", "(", "0", ",", "2", ",", "3", ",", "1", ")", ".", "contiguous", "(", ")", "\n", "\n", "if", "index", ":", "\n", "            ", "z_q_x_", ",", "indices", ",", "indices_not_flatten", "=", "vq_st_i_ori", "(", "z_e_x_", ",", "self", ".", "embedding", ".", "weight", ".", "detach", "(", ")", ")", "\n", "", "else", ":", "\n", "            ", "z_q_x_", ",", "indices", "=", "vq_st_ori", "(", "z_e_x_", ",", "self", ".", "embedding", ".", "weight", ".", "detach", "(", ")", ")", "\n", "", "z_q_x", "=", "z_q_x_", ".", "permute", "(", "0", ",", "3", ",", "1", ",", "2", ")", ".", "contiguous", "(", ")", "\n", "z_q_x_bar_flatten", "=", "torch", ".", "index_select", "(", "self", ".", "embedding", ".", "weight", ",", "dim", "=", "0", ",", "index", "=", "indices", ")", "\n", "z_q_x_bar_", "=", "z_q_x_bar_flatten", ".", "view_as", "(", "z_e_x_", ")", "\n", "z_q_x_bar", "=", "z_q_x_bar_", ".", "permute", "(", "0", ",", "3", ",", "1", ",", "2", ")", ".", "contiguous", "(", ")", "\n", "if", "index", ":", "\n", "            ", "return", "z_q_x", ",", "z_q_x_bar", ",", "indices_not_flatten", "\n", "", "else", ":", "\n", "            ", "return", "z_q_x", ",", "z_q_x_bar", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.None.modules.VQEmbedding_Original.indices_fetch": [[54, 59], ["indices.reshape", "torch.index_select().view", "torch.index_select().view", "torch.index_select().view", "torch.index_select().view", "torch.index_select().view", "torch.index_select().view", "torch.index_select().view", "torch.index_select().view", "torch.index_select().view", "indices.size", "indices.size", "indices.size", "indices.size", "torch.index_select", "torch.index_select", "torch.index_select", "torch.index_select", "torch.index_select", "torch.index_select", "torch.index_select", "torch.index_select", "torch.index_select", "indices.size", "indices.size"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.fairseq_dataset.FairseqDataset.size", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.fairseq_dataset.FairseqDataset.size", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.fairseq_dataset.FairseqDataset.size", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.fairseq_dataset.FairseqDataset.size", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.fairseq_dataset.FairseqDataset.size", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.fairseq_dataset.FairseqDataset.size"], ["", "", "def", "indices_fetch", "(", "self", ",", "indices", ")", ":", "\n", "        ", "indices_flatten", "=", "indices", ".", "reshape", "(", "indices", ".", "size", "(", "0", ")", "*", "indices", ".", "size", "(", "1", ")", "*", "indices", ".", "size", "(", "2", ")", ")", "\n", "z_q_x_fetch", "=", "torch", ".", "index_select", "(", "self", ".", "embedding", ".", "weight", ",", "dim", "=", "0", ",", "index", "=", "indices_flatten", ")", ".", "view", "(", "indices", ".", "size", "(", "0", ")", ",", "self", ".", "D", ",", "indices", ".", "size", "(", "1", ")", ",", "indices", ".", "size", "(", "1", ")", ")", "# B*C*H*W", "\n", "\n", "return", "z_q_x_fetch", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.None.modules.VQEmbedding.__init__": [[62, 67], ["torch.Module.__init__", "torch.Embedding", "torch.Embedding", "torch.Embedding", "modules.VQEmbedding.embedding.weight.data.uniform_"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.dummy_dictionary.DummyDictionary.__init__", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.transformer.Embedding", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.transformer.Embedding", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.transformer.Embedding"], ["    ", "def", "__init__", "(", "self", ",", "K", ",", "H", ",", "W", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "H", "=", "H", "\n", "self", ".", "embedding", "=", "nn", ".", "Embedding", "(", "K", ",", "H", "*", "W", ")", "\n", "self", ".", "embedding", ".", "weight", ".", "data", ".", "uniform_", "(", "-", "1.", "/", "K", ",", "1.", "/", "K", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.None.modules.VQEmbedding.forward": [[68, 72], ["z_e_x.contiguous", "functions.vq"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "z_e_x", ")", ":", "\n", "        ", "z_e_x_", "=", "z_e_x", ".", "contiguous", "(", ")", "\n", "latents", "=", "vq", "(", "z_e_x_", ",", "self", ".", "embedding", ".", "weight", ")", "\n", "return", "latents", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.None.modules.VQEmbedding.straight_through": [[73, 90], ["z_e_x.contiguous", "z_q_x_.contiguous", "torch.index_select", "torch.index_select", "torch.index_select", "torch.index_select", "torch.index_select", "torch.index_select", "torch.index_select", "torch.index_select", "torch.index_select", "torch.index_select.view_as", "torch.index_select.view_as", "torch.index_select.view_as", "torch.index_select.view_as.contiguous", "functions.vq_st_i", "functions.vq_st", "modules.VQEmbedding.embedding.weight.detach", "modules.VQEmbedding.embedding.weight.detach"], "methods", ["None"], ["", "def", "straight_through", "(", "self", ",", "z_e_x", ",", "index", "=", "False", ")", ":", "\n", "\n", "        ", "z_e_x_", "=", "z_e_x", ".", "contiguous", "(", ")", "\n", "\n", "if", "index", ":", "\n", "            ", "z_q_x_", ",", "indices", ",", "indices_not_flatten", "=", "vq_st_i", "(", "z_e_x_", ",", "self", ".", "embedding", ".", "weight", ".", "detach", "(", ")", ")", "\n", "", "else", ":", "\n", "            ", "z_q_x_", ",", "indices", "=", "vq_st", "(", "z_e_x_", ",", "self", ".", "embedding", ".", "weight", ".", "detach", "(", ")", ")", "\n", "\n", "", "z_q_x", "=", "z_q_x_", ".", "contiguous", "(", ")", "\n", "z_q_x_bar_flatten", "=", "torch", ".", "index_select", "(", "self", ".", "embedding", ".", "weight", ",", "dim", "=", "0", ",", "index", "=", "indices", ")", "\n", "z_q_x_bar_", "=", "z_q_x_bar_flatten", ".", "view_as", "(", "z_e_x_", ")", "\n", "z_q_x_bar", "=", "z_q_x_bar_", ".", "contiguous", "(", ")", "\n", "if", "index", ":", "\n", "            ", "return", "z_q_x", ",", "z_q_x_bar", ",", "indices_not_flatten", "\n", "", "else", ":", "\n", "            ", "return", "z_q_x", ",", "z_q_x_bar", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.None.modules.VQEmbedding.indices_fetch": [[91, 96], ["indices.reshape", "torch.index_select().view", "torch.index_select().view", "torch.index_select().view", "torch.index_select().view", "torch.index_select().view", "torch.index_select().view", "torch.index_select().view", "torch.index_select().view", "torch.index_select().view", "indices.size", "indices.size", "indices.size", "indices.size", "torch.index_select", "torch.index_select", "torch.index_select", "torch.index_select", "torch.index_select", "torch.index_select", "torch.index_select", "torch.index_select", "torch.index_select"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.fairseq_dataset.FairseqDataset.size", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.fairseq_dataset.FairseqDataset.size", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.fairseq_dataset.FairseqDataset.size", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.fairseq_dataset.FairseqDataset.size"], ["", "", "def", "indices_fetch", "(", "self", ",", "indices", ")", ":", "\n", "        ", "indices_flatten", "=", "indices", ".", "reshape", "(", "indices", ".", "size", "(", "0", ")", "*", "indices", ".", "size", "(", "1", ")", ")", "\n", "z_q_x_fetch", "=", "torch", ".", "index_select", "(", "self", ".", "embedding", ".", "weight", ",", "dim", "=", "0", ",", "index", "=", "indices_flatten", ")", ".", "view", "(", "indices", ".", "size", "(", "0", ")", ",", "indices", ".", "size", "(", "1", ")", ",", "self", ".", "H", ",", "self", ".", "H", ")", "# B*C*H*W", "\n", "\n", "return", "z_q_x_fetch", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.None.modules.ResBlock.__init__": [[98, 107], ["torch.Module.__init__", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.dummy_dictionary.DummyDictionary.__init__"], ["    ", "def", "__init__", "(", "self", ",", "dim", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "block", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "ReLU", "(", "True", ")", ",", "\n", "nn", ".", "Conv2d", "(", "dim", ",", "2", "*", "dim", ",", "3", ",", "1", ",", "1", ")", ",", "\n", "nn", ".", "BatchNorm2d", "(", "2", "*", "dim", ")", ",", "\n", "nn", ".", "ReLU", "(", "True", ")", ",", "\n", "nn", ".", "Conv2d", "(", "2", "*", "dim", ",", "dim", ",", "1", ")", ",", "\n", "nn", ".", "BatchNorm2d", "(", "dim", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.None.modules.ResBlock.forward": [[109, 111], ["modules.ResBlock.block"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "x", "+", "self", ".", "block", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.None.modules.VectorQuantizedVAE_Dim.__init__": [[113, 148], ["torch.Module.__init__", "torch.Sequential", "torch.Sequential", "torch.Sequential", "modules.VQEmbedding", "torch.Sequential", "torch.Sequential", "torch.Sequential", "modules.VectorQuantizedVAE_Dim.apply", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.Tanh", "torch.Tanh", "torch.Tanh"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.dummy_dictionary.DummyDictionary.__init__"], ["    ", "def", "__init__", "(", "self", ",", "input_dim", ",", "dim", ",", "K", "=", "512", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dim", "=", "dim", "\n", "self", ".", "factor", "=", "2", "\n", "self", ".", "encoder", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Conv2d", "(", "input_dim", ",", "64", "*", "self", ".", "factor", ",", "4", ",", "2", ",", "1", ")", ",", "\n", "nn", ".", "BatchNorm2d", "(", "64", "*", "self", ".", "factor", ")", ",", "\n", "nn", ".", "ReLU", "(", "True", ")", ",", "\n", "nn", ".", "Conv2d", "(", "64", "*", "self", ".", "factor", ",", "128", "*", "self", ".", "factor", ",", "4", ",", "2", ",", "1", ")", ",", "\n", "nn", ".", "BatchNorm2d", "(", "128", "*", "self", ".", "factor", ")", ",", "\n", "nn", ".", "ReLU", "(", "True", ")", ",", "\n", "nn", ".", "Conv2d", "(", "128", "*", "self", ".", "factor", ",", "256", "*", "self", ".", "factor", ",", "4", ",", "2", ",", "1", ")", ",", "\n", "nn", ".", "BatchNorm2d", "(", "256", "*", "self", ".", "factor", ")", ",", "\n", "nn", ".", "ReLU", "(", "True", ")", ",", "\n", "nn", ".", "Conv2d", "(", "256", "*", "self", ".", "factor", ",", "dim", ",", "3", ",", "1", ",", "1", ")", ",", "\n", "\n", ")", "\n", "\n", "self", ".", "codebook", "=", "VQEmbedding", "(", "K", ",", "4", ",", "4", ")", "\n", "self", ".", "decoder", "=", "nn", ".", "Sequential", "(", "\n", "\n", "nn", ".", "ConvTranspose2d", "(", "dim", ",", "256", "*", "self", ".", "factor", ",", "3", ",", "1", ",", "1", ")", ",", "\n", "nn", ".", "BatchNorm2d", "(", "256", "*", "self", ".", "factor", ")", ",", "\n", "nn", ".", "ReLU", "(", "True", ")", ",", "\n", "nn", ".", "ConvTranspose2d", "(", "256", "*", "self", ".", "factor", ",", "128", "*", "self", ".", "factor", ",", "4", ",", "2", ",", "1", ")", ",", "\n", "nn", ".", "BatchNorm2d", "(", "128", "*", "self", ".", "factor", ")", ",", "\n", "nn", ".", "ReLU", "(", "True", ")", ",", "\n", "nn", ".", "ConvTranspose2d", "(", "128", "*", "self", ".", "factor", ",", "64", "*", "self", ".", "factor", ",", "4", ",", "2", ",", "1", ")", ",", "\n", "nn", ".", "BatchNorm2d", "(", "64", "*", "self", ".", "factor", ")", ",", "\n", "nn", ".", "ReLU", "(", "True", ")", ",", "\n", "nn", ".", "ConvTranspose2d", "(", "64", "*", "self", ".", "factor", ",", "input_dim", ",", "4", ",", "2", ",", "1", ")", ",", "\n", "nn", ".", "Tanh", "(", ")", "\n", ")", "\n", "\n", "self", ".", "apply", "(", "weights_init", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.None.modules.VectorQuantizedVAE_Dim.encode": [[149, 153], ["modules.VectorQuantizedVAE_Dim.encoder", "modules.VectorQuantizedVAE_Dim.codebook"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.fairseq_model.FairseqMultiModel.encoder"], ["", "def", "encode", "(", "self", ",", "x", ")", ":", "\n", "        ", "z_e_x", "=", "self", ".", "encoder", "(", "x", ")", "\n", "latents", "=", "self", ".", "codebook", "(", "z_e_x", ")", "\n", "return", "latents", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.None.modules.VectorQuantizedVAE_Dim.decode": [[154, 159], ["int", "modules.VectorQuantizedVAE_Dim.codebook.embedding().resize", "modules.VectorQuantizedVAE_Dim.decoder", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "latents.size", "latents.size", "latents.size", "modules.VectorQuantizedVAE_Dim.codebook.embedding"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.fairseq_model.FairseqMultiModel.decoder", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.fairseq_dataset.FairseqDataset.size", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.fairseq_dataset.FairseqDataset.size", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.fairseq_dataset.FairseqDataset.size"], ["", "def", "decode", "(", "self", ",", "latents", ")", ":", "\n", "        ", "h", "=", "int", "(", "torch", ".", "sqrt", "(", "latents", ".", "size", "(", "2", ")", ")", ")", "\n", "z_q_x", "=", "self", ".", "codebook", ".", "embedding", "(", "latents", ")", ".", "resize", "(", "latents", ".", "size", "(", "0", ")", ",", "latents", ".", "size", "(", "1", ")", ",", "h", ",", "h", ")", "# (B, D, H, W)", "\n", "x_tilde", "=", "self", ".", "decoder", "(", "z_q_x", ")", "\n", "return", "x_tilde", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.None.modules.VectorQuantizedVAE_Dim.forward": [[160, 185], ["modules.VectorQuantizedVAE_Dim.encoder", "modules.VectorQuantizedVAE_Dim.size", "modules.VectorQuantizedVAE_Dim.codebook.straight_through", "modules.VectorQuantizedVAE_Dim.codebook.straight_through", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "modules.VectorQuantizedVAE_Dim.decoder", "modules.VectorQuantizedVAE_Dim.decoder", "int", "torch.cat.new_zeros", "torch.cat.new_zeros", "torch.cat.new_zeros", "numpy.random.randint", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.cat.size"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.fairseq_model.FairseqMultiModel.encoder", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.fairseq_dataset.FairseqDataset.size", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.None.modules.VQEmbedding.straight_through", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.None.modules.VQEmbedding.straight_through", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.fairseq_model.FairseqMultiModel.decoder", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.fairseq_model.FairseqMultiModel.decoder", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.fairseq_dataset.FairseqDataset.size", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.fairseq_dataset.FairseqDataset.size", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.fairseq_dataset.FairseqDataset.size", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.fairseq_dataset.FairseqDataset.size", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.fairseq_dataset.FairseqDataset.size", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.fairseq_dataset.FairseqDataset.size", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.fairseq_dataset.FairseqDataset.size", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.fairseq_dataset.FairseqDataset.size", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.fairseq_dataset.FairseqDataset.size"], ["", "def", "forward", "(", "self", ",", "x", ",", "full_sample", "=", "True", ",", "designate", "=", "None", ",", "index", "=", "False", ",", "interval", "=", "1", ")", ":", "\n", "        ", "z_e_x", "=", "self", ".", "encoder", "(", "x", ")", "\n", "if", "not", "index", ":", "\n", "            ", "z_q_x_st", ",", "z_q_x", "=", "self", ".", "codebook", ".", "straight_through", "(", "z_e_x", ")", "\n", "", "else", ":", "\n", "            ", "z_q_x_st", ",", "z_q_x", ",", "indices", "=", "self", ".", "codebook", ".", "straight_through", "(", "z_e_x", ",", "index", ")", "\n", "", "area", "=", "z_e_x", ".", "size", "(", "1", ")", "\n", "if", "not", "full_sample", ":", "\n", "            ", "if", "designate", "is", "not", "None", ":", "\n", "                ", "sample_index", "=", "designate", "\n", "", "else", ":", "\n", "                ", "interval", "=", "int", "(", "interval", ")", "\n", "sample_index", "=", "(", "np", ".", "random", ".", "randint", "(", "area", "//", "interval", ")", "+", "1", ")", "*", "interval", "\n", "", "z_q_x_st", "=", "torch", ".", "cat", "(", "[", "\n", "z_q_x_st", "[", ":", ",", ":", "sample_index", ",", ":", ",", ":", "]", ",", "\n", "z_q_x_st", ".", "new_zeros", "(", "(", "z_q_x_st", ".", "size", "(", "0", ")", ",", "area", "-", "sample_index", ",", "z_q_x_st", ".", "size", "(", "2", ")", ",", "z_q_x_st", ".", "size", "(", "3", ")", ")", ")", "\n", "]", ",", "dim", "=", "1", ")", "\n", "x_tilde", "=", "self", ".", "decoder", "(", "z_q_x_st", ")", "\n", "return", "x_tilde", ",", "z_e_x", ",", "z_q_x", ",", "sample_index", "\n", "", "else", ":", "\n", "            ", "x_tilde", "=", "self", ".", "decoder", "(", "z_q_x_st", ")", "\n", "if", "not", "index", ":", "\n", "                ", "return", "x_tilde", ",", "z_e_x", ",", "z_q_x", "\n", "", "else", ":", "\n", "                ", "return", "x_tilde", ",", "z_e_x", ",", "z_q_x", ",", "indices", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.None.modules.VectorQuantizedVAE_Dim.indices_fetch": [[186, 193], ["modules.VectorQuantizedVAE_Dim.codebook.indices_fetch", "modules.VectorQuantizedVAE_Dim.decoder", "indices.size", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "indices.size", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.cat.size", "indices.size"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.None.modules.VectorQuantizedVAE_Bigger.indices_fetch", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.fairseq_model.FairseqMultiModel.decoder", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.fairseq_dataset.FairseqDataset.size", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.fairseq_dataset.FairseqDataset.size", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.fairseq_dataset.FairseqDataset.size", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.fairseq_dataset.FairseqDataset.size", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.fairseq_dataset.FairseqDataset.size", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.fairseq_dataset.FairseqDataset.size", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.fairseq_dataset.FairseqDataset.size", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.fairseq_dataset.FairseqDataset.size", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.fairseq_dataset.FairseqDataset.size"], ["", "", "", "def", "indices_fetch", "(", "self", ",", "indices", ")", ":", "\n", "        ", "z", "=", "self", ".", "codebook", ".", "indices_fetch", "(", "indices", ")", "\n", "if", "indices", ".", "size", "(", "1", ")", "<", "self", ".", "dim", ":", "\n", "            ", "zero_out", "=", "torch", ".", "zeros", "(", "(", "indices", ".", "size", "(", "0", ")", ",", "self", ".", "dim", "-", "indices", ".", "size", "(", "1", ")", ",", "z", ".", "size", "(", "2", ")", ",", "z", ".", "size", "(", "3", ")", ")", ")", ".", "cuda", "(", ")", "\n", "z", "=", "torch", ".", "cat", "(", "(", "z", ",", "zero_out", ")", ",", "dim", "=", "1", ")", "\n", "", "x", "=", "self", ".", "decoder", "(", "z", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.None.modules.VectorQuantizedVAE_CelebA.__init__": [[196, 229], ["torch.Module.__init__", "torch.Sequential", "torch.Sequential", "torch.Sequential", "modules.VQEmbedding", "torch.Sequential", "torch.Sequential", "torch.Sequential", "modules.VectorQuantizedVAE_CelebA.apply", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.Tanh", "torch.Tanh", "torch.Tanh"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.dummy_dictionary.DummyDictionary.__init__"], ["    ", "def", "__init__", "(", "self", ",", "input_dim", ",", "dim", ",", "K", "=", "512", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dim", "=", "dim", "\n", "self", ".", "factor", "=", "2", "\n", "self", ".", "encoder", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Conv2d", "(", "input_dim", ",", "64", "*", "self", ".", "factor", ",", "4", ",", "2", ",", "1", ")", ",", "\n", "nn", ".", "BatchNorm2d", "(", "64", "*", "self", ".", "factor", ")", ",", "\n", "nn", ".", "ReLU", "(", "True", ")", ",", "\n", "nn", ".", "Conv2d", "(", "64", "*", "self", ".", "factor", ",", "128", "*", "self", ".", "factor", ",", "4", ",", "2", ",", "1", ")", ",", "\n", "nn", ".", "BatchNorm2d", "(", "128", "*", "self", ".", "factor", ")", ",", "\n", "nn", ".", "ReLU", "(", "True", ")", ",", "\n", "nn", ".", "Conv2d", "(", "128", "*", "self", ".", "factor", ",", "256", "*", "self", ".", "factor", ",", "4", ",", "2", ",", "1", ")", ",", "\n", "nn", ".", "BatchNorm2d", "(", "256", "*", "self", ".", "factor", ")", ",", "\n", "nn", ".", "ReLU", "(", "True", ")", ",", "\n", "nn", ".", "Conv2d", "(", "256", "*", "self", ".", "factor", ",", "dim", ",", "3", ",", "1", ",", "1", ")", ",", "\n", ")", "\n", "\n", "self", ".", "codebook", "=", "VQEmbedding", "(", "K", ",", "8", ",", "8", ")", "\n", "self", ".", "decoder", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "ConvTranspose2d", "(", "dim", ",", "256", "*", "self", ".", "factor", ",", "3", ",", "1", ",", "1", ")", ",", "\n", "nn", ".", "BatchNorm2d", "(", "256", "*", "self", ".", "factor", ")", ",", "\n", "nn", ".", "ReLU", "(", "True", ")", ",", "\n", "nn", ".", "ConvTranspose2d", "(", "256", "*", "self", ".", "factor", ",", "128", "*", "self", ".", "factor", ",", "4", ",", "2", ",", "1", ")", ",", "\n", "nn", ".", "BatchNorm2d", "(", "128", "*", "self", ".", "factor", ")", ",", "\n", "nn", ".", "ReLU", "(", "True", ")", ",", "\n", "nn", ".", "ConvTranspose2d", "(", "128", "*", "self", ".", "factor", ",", "64", "*", "self", ".", "factor", ",", "4", ",", "2", ",", "1", ")", ",", "\n", "nn", ".", "BatchNorm2d", "(", "64", "*", "self", ".", "factor", ")", ",", "\n", "nn", ".", "ReLU", "(", "True", ")", ",", "\n", "nn", ".", "ConvTranspose2d", "(", "64", "*", "self", ".", "factor", ",", "input_dim", ",", "4", ",", "2", ",", "1", ")", ",", "\n", "nn", ".", "Tanh", "(", ")", "\n", ")", "\n", "\n", "self", ".", "apply", "(", "weights_init", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.None.modules.VectorQuantizedVAE_CelebA.encode": [[230, 234], ["modules.VectorQuantizedVAE_CelebA.encoder", "modules.VectorQuantizedVAE_CelebA.codebook"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.fairseq_model.FairseqMultiModel.encoder"], ["", "def", "encode", "(", "self", ",", "x", ")", ":", "\n", "        ", "z_e_x", "=", "self", ".", "encoder", "(", "x", ")", "\n", "latents", "=", "self", ".", "codebook", "(", "z_e_x", ")", "\n", "return", "latents", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.None.modules.VectorQuantizedVAE_CelebA.decode": [[235, 240], ["int", "modules.VectorQuantizedVAE_CelebA.codebook.embedding().resize", "modules.VectorQuantizedVAE_CelebA.decoder", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "latents.size", "latents.size", "latents.size", "modules.VectorQuantizedVAE_CelebA.codebook.embedding"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.fairseq_model.FairseqMultiModel.decoder", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.fairseq_dataset.FairseqDataset.size", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.fairseq_dataset.FairseqDataset.size", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.fairseq_dataset.FairseqDataset.size"], ["", "def", "decode", "(", "self", ",", "latents", ")", ":", "\n", "        ", "h", "=", "int", "(", "torch", ".", "sqrt", "(", "latents", ".", "size", "(", "2", ")", ")", ")", "\n", "z_q_x", "=", "self", ".", "codebook", ".", "embedding", "(", "latents", ")", ".", "resize", "(", "latents", ".", "size", "(", "0", ")", ",", "latents", ".", "size", "(", "1", ")", ",", "h", ",", "h", ")", "# (B, D, H, W)", "\n", "x_tilde", "=", "self", ".", "decoder", "(", "z_q_x", ")", "\n", "return", "x_tilde", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.None.modules.VectorQuantizedVAE_CelebA.forward": [[241, 265], ["modules.VectorQuantizedVAE_CelebA.encoder", "modules.VectorQuantizedVAE_CelebA.size", "modules.VectorQuantizedVAE_CelebA.codebook.straight_through", "modules.VectorQuantizedVAE_CelebA.codebook.straight_through", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "modules.VectorQuantizedVAE_CelebA.decoder", "modules.VectorQuantizedVAE_CelebA.decoder", "int", "numpy.array", "sample_index.clip.clip.clip", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.cat.size", "numpy.random.randint"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.fairseq_model.FairseqMultiModel.encoder", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.fairseq_dataset.FairseqDataset.size", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.None.modules.VQEmbedding.straight_through", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.None.modules.VQEmbedding.straight_through", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.fairseq_model.FairseqMultiModel.decoder", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.fairseq_model.FairseqMultiModel.decoder", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.fairseq_dataset.FairseqDataset.size", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.fairseq_dataset.FairseqDataset.size", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.fairseq_dataset.FairseqDataset.size", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.fairseq_dataset.FairseqDataset.size", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.fairseq_dataset.FairseqDataset.size", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.fairseq_dataset.FairseqDataset.size", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.fairseq_dataset.FairseqDataset.size", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.fairseq_dataset.FairseqDataset.size", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.fairseq_dataset.FairseqDataset.size"], ["", "def", "forward", "(", "self", ",", "x", ",", "full_sample", "=", "True", ",", "designate", "=", "None", ",", "index", "=", "False", ",", "interval", "=", "1", ")", ":", "\n", "        ", "z_e_x", "=", "self", ".", "encoder", "(", "x", ")", "\n", "if", "not", "index", ":", "\n", "            ", "z_q_x_st", ",", "z_q_x", "=", "self", ".", "codebook", ".", "straight_through", "(", "z_e_x", ")", "\n", "", "else", ":", "\n", "            ", "z_q_x_st", ",", "z_q_x", ",", "indices", "=", "self", ".", "codebook", ".", "straight_through", "(", "z_e_x", ",", "index", ")", "\n", "", "area", "=", "z_e_x", ".", "size", "(", "1", ")", "\n", "if", "not", "full_sample", ":", "\n", "            ", "if", "designate", "!=", "None", ":", "\n", "                ", "sample_index", "=", "designate", "\n", "", "else", ":", "\n", "                ", "interval", "=", "int", "(", "interval", ")", "\n", "sample_index", "=", "np", ".", "array", "(", "(", "np", ".", "random", ".", "randint", "(", "area", ")", "//", "interval", "+", "1", ")", "*", "interval", ")", "\n", "sample_index", "=", "sample_index", ".", "clip", "(", "1", ",", "area", ")", "\n", "", "zero_out", "=", "torch", ".", "zeros", "(", "(", "z_q_x_st", ".", "size", "(", "0", ")", ",", "area", "-", "sample_index", ",", "z_q_x_st", ".", "size", "(", "2", ")", ",", "z_q_x_st", ".", "size", "(", "3", ")", ")", ")", ".", "cuda", "(", ")", "\n", "z_q_x_st", "=", "torch", ".", "cat", "(", "(", "z_q_x_st", "[", ":", ",", ":", "sample_index", "]", ",", "zero_out", ")", ",", "dim", "=", "1", ")", "\n", "x_tilde", "=", "self", ".", "decoder", "(", "z_q_x_st", ")", "\n", "return", "x_tilde", ",", "z_e_x", ",", "z_q_x", ",", "sample_index", "\n", "", "else", ":", "\n", "            ", "x_tilde", "=", "self", ".", "decoder", "(", "z_q_x_st", ")", "\n", "if", "not", "index", ":", "\n", "                ", "return", "x_tilde", ",", "z_e_x", ",", "z_q_x", "\n", "", "else", ":", "\n", "                ", "return", "x_tilde", ",", "z_e_x", ",", "z_q_x", ",", "indices", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.None.modules.VectorQuantizedVAE_CelebA.indices_fetch": [[266, 273], ["modules.VectorQuantizedVAE_CelebA.codebook.indices_fetch", "modules.VectorQuantizedVAE_CelebA.decoder", "indices.size", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "indices.size", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.cat.size", "indices.size"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.None.modules.VectorQuantizedVAE_Bigger.indices_fetch", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.fairseq_model.FairseqMultiModel.decoder", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.fairseq_dataset.FairseqDataset.size", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.fairseq_dataset.FairseqDataset.size", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.fairseq_dataset.FairseqDataset.size", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.fairseq_dataset.FairseqDataset.size", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.fairseq_dataset.FairseqDataset.size", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.fairseq_dataset.FairseqDataset.size", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.fairseq_dataset.FairseqDataset.size", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.fairseq_dataset.FairseqDataset.size", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.fairseq_dataset.FairseqDataset.size"], ["", "", "", "def", "indices_fetch", "(", "self", ",", "indices", ")", ":", "\n", "        ", "z", "=", "self", ".", "codebook", ".", "indices_fetch", "(", "indices", ")", "\n", "if", "indices", ".", "size", "(", "1", ")", "<", "self", ".", "dim", ":", "\n", "            ", "zero_out", "=", "torch", ".", "zeros", "(", "(", "indices", ".", "size", "(", "0", ")", ",", "self", ".", "dim", "-", "indices", ".", "size", "(", "1", ")", ",", "z", ".", "size", "(", "2", ")", ",", "z", ".", "size", "(", "3", ")", ")", ")", ".", "cuda", "(", ")", "\n", "z", "=", "torch", ".", "cat", "(", "(", "z", ",", "zero_out", ")", ",", "dim", "=", "1", ")", "\n", "", "x", "=", "self", ".", "decoder", "(", "z", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.None.modules.VectorQuantizedVAE_mnist.__init__": [[275, 304], ["torch.Module.__init__", "torch.Sequential", "torch.Sequential", "torch.Sequential", "modules.VQEmbedding", "torch.Sequential", "torch.Sequential", "torch.Sequential", "modules.VectorQuantizedVAE_mnist.apply", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.Tanh", "torch.Tanh", "torch.Tanh"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.dummy_dictionary.DummyDictionary.__init__"], ["    ", "def", "__init__", "(", "self", ",", "input_dim", ",", "dim", ",", "K", "=", "512", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dim", "=", "dim", "\n", "self", ".", "factor", "=", "1", "\n", "self", ".", "encoder", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Conv2d", "(", "input_dim", ",", "16", "*", "self", ".", "factor", ",", "4", ",", "2", ",", "1", ")", ",", "\n", "nn", ".", "BatchNorm2d", "(", "16", "*", "self", ".", "factor", ")", ",", "\n", "nn", ".", "ReLU", "(", "True", ")", ",", "\n", "nn", ".", "Conv2d", "(", "16", "*", "self", ".", "factor", ",", "32", "*", "self", ".", "factor", ",", "4", ",", "2", ",", "1", ")", ",", "\n", "nn", ".", "BatchNorm2d", "(", "32", "*", "self", ".", "factor", ")", ",", "\n", "nn", ".", "ReLU", "(", "True", ")", ",", "\n", "nn", ".", "Conv2d", "(", "32", "*", "self", ".", "factor", ",", "dim", ",", "3", ",", "1", ",", "1", ")", ",", "\n", "\n", ")", "\n", "\n", "self", ".", "codebook", "=", "VQEmbedding", "(", "K", ",", "7", ",", "7", ")", "\n", "self", ".", "decoder", "=", "nn", ".", "Sequential", "(", "\n", "\n", "nn", ".", "ConvTranspose2d", "(", "dim", ",", "32", "*", "self", ".", "factor", ",", "3", ",", "1", ",", "1", ")", ",", "\n", "nn", ".", "BatchNorm2d", "(", "32", "*", "self", ".", "factor", ")", ",", "\n", "nn", ".", "ReLU", "(", "True", ")", ",", "\n", "nn", ".", "ConvTranspose2d", "(", "32", "*", "self", ".", "factor", ",", "16", "*", "self", ".", "factor", ",", "4", ",", "2", ",", "1", ")", ",", "\n", "nn", ".", "BatchNorm2d", "(", "16", "*", "self", ".", "factor", ")", ",", "\n", "nn", ".", "ReLU", "(", "True", ")", ",", "\n", "nn", ".", "ConvTranspose2d", "(", "16", "*", "self", ".", "factor", ",", "input_dim", ",", "4", ",", "2", ",", "1", ")", ",", "\n", "nn", ".", "Tanh", "(", ")", "\n", ")", "\n", "\n", "self", ".", "apply", "(", "weights_init", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.None.modules.VectorQuantizedVAE_mnist.encode": [[305, 309], ["modules.VectorQuantizedVAE_mnist.encoder", "modules.VectorQuantizedVAE_mnist.codebook"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.fairseq_model.FairseqMultiModel.encoder"], ["", "def", "encode", "(", "self", ",", "x", ")", ":", "\n", "        ", "z_e_x", "=", "self", ".", "encoder", "(", "x", ")", "\n", "latents", "=", "self", ".", "codebook", "(", "z_e_x", ")", "\n", "return", "latents", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.None.modules.VectorQuantizedVAE_mnist.decode": [[310, 315], ["int", "modules.VectorQuantizedVAE_mnist.codebook.embedding().resize", "modules.VectorQuantizedVAE_mnist.decoder", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "latents.size", "latents.size", "latents.size", "modules.VectorQuantizedVAE_mnist.codebook.embedding"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.fairseq_model.FairseqMultiModel.decoder", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.fairseq_dataset.FairseqDataset.size", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.fairseq_dataset.FairseqDataset.size", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.fairseq_dataset.FairseqDataset.size"], ["", "def", "decode", "(", "self", ",", "latents", ")", ":", "\n", "        ", "h", "=", "int", "(", "torch", ".", "sqrt", "(", "latents", ".", "size", "(", "2", ")", ")", ")", "\n", "z_q_x", "=", "self", ".", "codebook", ".", "embedding", "(", "latents", ")", ".", "resize", "(", "latents", ".", "size", "(", "0", ")", ",", "latents", ".", "size", "(", "1", ")", ",", "h", ",", "h", ")", "# (B, D, H, W)", "\n", "x_tilde", "=", "self", ".", "decoder", "(", "z_q_x", ")", "\n", "return", "x_tilde", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.None.modules.VectorQuantizedVAE_mnist.forward": [[316, 340], ["modules.VectorQuantizedVAE_mnist.encoder", "modules.VectorQuantizedVAE_mnist.size", "modules.VectorQuantizedVAE_mnist.codebook.straight_through", "modules.VectorQuantizedVAE_mnist.codebook.straight_through", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "modules.VectorQuantizedVAE_mnist.decoder", "modules.VectorQuantizedVAE_mnist.decoder", "int", "numpy.array", "sample_index.clip.clip.clip", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.cat.size", "numpy.random.randint"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.fairseq_model.FairseqMultiModel.encoder", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.fairseq_dataset.FairseqDataset.size", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.None.modules.VQEmbedding.straight_through", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.None.modules.VQEmbedding.straight_through", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.fairseq_model.FairseqMultiModel.decoder", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.fairseq_model.FairseqMultiModel.decoder", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.fairseq_dataset.FairseqDataset.size", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.fairseq_dataset.FairseqDataset.size", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.fairseq_dataset.FairseqDataset.size", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.fairseq_dataset.FairseqDataset.size", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.fairseq_dataset.FairseqDataset.size", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.fairseq_dataset.FairseqDataset.size", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.fairseq_dataset.FairseqDataset.size", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.fairseq_dataset.FairseqDataset.size", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.fairseq_dataset.FairseqDataset.size"], ["", "def", "forward", "(", "self", ",", "x", ",", "full_sample", "=", "True", ",", "designate", "=", "None", ",", "index", "=", "False", ",", "interval", "=", "1", ")", ":", "\n", "        ", "z_e_x", "=", "self", ".", "encoder", "(", "x", ")", "\n", "if", "not", "index", ":", "\n", "            ", "z_q_x_st", ",", "z_q_x", "=", "self", ".", "codebook", ".", "straight_through", "(", "z_e_x", ")", "\n", "", "else", ":", "\n", "            ", "z_q_x_st", ",", "z_q_x", ",", "indices", "=", "self", ".", "codebook", ".", "straight_through", "(", "z_e_x", ",", "index", ")", "\n", "", "area", "=", "z_e_x", ".", "size", "(", "1", ")", "\n", "if", "not", "full_sample", ":", "\n", "            ", "if", "designate", "!=", "None", ":", "\n", "                ", "sample_index", "=", "designate", "\n", "", "else", ":", "\n", "                ", "interval", "=", "int", "(", "interval", ")", "\n", "sample_index", "=", "np", ".", "array", "(", "(", "np", ".", "random", ".", "randint", "(", "area", ")", "//", "interval", "+", "1", ")", "*", "interval", ")", "\n", "sample_index", "=", "sample_index", ".", "clip", "(", "10", ",", "area", ")", "\n", "", "zero_out", "=", "torch", ".", "zeros", "(", "(", "z_q_x_st", ".", "size", "(", "0", ")", ",", "area", "-", "sample_index", ",", "z_q_x_st", ".", "size", "(", "2", ")", ",", "z_q_x_st", ".", "size", "(", "2", ")", ")", ")", ".", "cuda", "(", ")", "\n", "z_q_x_st", "=", "torch", ".", "cat", "(", "(", "z_q_x_st", "[", ":", ",", ":", "sample_index", "]", ",", "zero_out", ")", ",", "dim", "=", "1", ")", "\n", "x_tilde", "=", "self", ".", "decoder", "(", "z_q_x_st", ")", "\n", "return", "x_tilde", ",", "z_e_x", ",", "z_q_x", ",", "sample_index", "\n", "", "else", ":", "\n", "            ", "x_tilde", "=", "self", ".", "decoder", "(", "z_q_x_st", ")", "\n", "if", "not", "index", ":", "\n", "                ", "return", "x_tilde", ",", "z_e_x", ",", "z_q_x", "\n", "", "else", ":", "\n", "                ", "return", "x_tilde", ",", "z_e_x", ",", "z_q_x", ",", "indices", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.None.modules.VectorQuantizedVAE_mnist.indices_fetch": [[341, 348], ["modules.VectorQuantizedVAE_mnist.codebook.indices_fetch", "modules.VectorQuantizedVAE_mnist.decoder", "indices.size", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "indices.size", "indices.size"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.None.modules.VectorQuantizedVAE_Bigger.indices_fetch", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.fairseq_model.FairseqMultiModel.decoder", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.fairseq_dataset.FairseqDataset.size", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.fairseq_dataset.FairseqDataset.size", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.fairseq_dataset.FairseqDataset.size"], ["", "", "", "def", "indices_fetch", "(", "self", ",", "indices", ")", ":", "\n", "        ", "z", "=", "self", ".", "codebook", ".", "indices_fetch", "(", "indices", ")", "\n", "if", "indices", ".", "size", "(", "1", ")", "<", "self", ".", "dim", ":", "\n", "            ", "zero_out", "=", "torch", ".", "zeros", "(", "(", "indices", ".", "size", "(", "0", ")", ",", "self", ".", "dim", "-", "indices", ".", "size", "(", "1", ")", ",", "7", ",", "7", ")", ")", ".", "cuda", "(", ")", "\n", "z", "=", "torch", ".", "cat", "(", "(", "z", ",", "zero_out", ")", ",", "dim", "=", "1", ")", "\n", "", "x", "=", "self", ".", "decoder", "(", "z", ")", "\n", "return", "x", "\n", "", "", "class", "GatedActivation", "(", "nn", ".", "Module", ")", ":", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.None.modules.GatedActivation.__init__": [[349, 351], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.dummy_dictionary.DummyDictionary.__init__"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.None.modules.GatedActivation.forward": [[352, 355], ["x.chunk", "torch.tanh", "torch.tanh", "torch.tanh", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", ",", "y", "=", "x", ".", "chunk", "(", "2", ",", "dim", "=", "1", ")", "\n", "return", "F", ".", "tanh", "(", "x", ")", "*", "F", ".", "sigmoid", "(", "y", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.None.modules.GatedMaskedConv2d.__init__": [[357, 386], ["torch.Module.__init__", "print", "torch.Embedding", "torch.Embedding", "torch.Embedding", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "modules.GatedActivation"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.dummy_dictionary.DummyDictionary.__init__", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.progress_bar.tensorboard_log_wrapper.print", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.transformer.Embedding", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.transformer.Embedding", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.transformer.Embedding"], ["    ", "def", "__init__", "(", "self", ",", "mask_type", ",", "dim", ",", "kernel", ",", "residual", "=", "True", ",", "n_classes", "=", "10", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "assert", "kernel", "%", "2", "==", "1", ",", "print", "(", "\"Kernel size must be odd\"", ")", "\n", "self", ".", "mask_type", "=", "mask_type", "\n", "self", ".", "residual", "=", "residual", "\n", "\n", "self", ".", "class_cond_embedding", "=", "nn", ".", "Embedding", "(", "\n", "n_classes", ",", "2", "*", "dim", "\n", ")", "\n", "\n", "kernel_shp", "=", "(", "kernel", "//", "2", "+", "1", ",", "kernel", ")", "# (ceil(n/2), n)", "\n", "padding_shp", "=", "(", "kernel", "//", "2", ",", "kernel", "//", "2", ")", "\n", "self", ".", "vert_stack", "=", "nn", ".", "Conv2d", "(", "\n", "dim", ",", "dim", "*", "2", ",", "\n", "kernel_shp", ",", "1", ",", "padding_shp", "\n", ")", "\n", "\n", "self", ".", "vert_to_horiz", "=", "nn", ".", "Conv2d", "(", "2", "*", "dim", ",", "2", "*", "dim", ",", "1", ")", "\n", "\n", "kernel_shp", "=", "(", "1", ",", "kernel", "//", "2", "+", "1", ")", "\n", "padding_shp", "=", "(", "0", ",", "kernel", "//", "2", ")", "\n", "self", ".", "horiz_stack", "=", "nn", ".", "Conv2d", "(", "\n", "dim", ",", "dim", "*", "2", ",", "\n", "kernel_shp", ",", "1", ",", "padding_shp", "\n", ")", "\n", "\n", "self", ".", "horiz_resid", "=", "nn", ".", "Conv2d", "(", "dim", ",", "dim", ",", "1", ")", "\n", "\n", "self", ".", "gate", "=", "GatedActivation", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.None.modules.GatedMaskedConv2d.make_causal": [[387, 390], ["modules.GatedMaskedConv2d.vert_stack.weight.data[].zero_", "modules.GatedMaskedConv2d.horiz_stack.weight.data[].zero_"], "methods", ["None"], ["", "def", "make_causal", "(", "self", ")", ":", "\n", "        ", "self", ".", "vert_stack", ".", "weight", ".", "data", "[", ":", ",", ":", ",", "-", "1", "]", ".", "zero_", "(", ")", "# Mask final row", "\n", "self", ".", "horiz_stack", ".", "weight", ".", "data", "[", ":", ",", ":", ",", ":", ",", "-", "1", "]", ".", "zero_", "(", ")", "# Mask final column", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.None.modules.GatedMaskedConv2d.forward": [[391, 411], ["modules.GatedMaskedConv2d.class_cond_embedding", "modules.GatedMaskedConv2d.vert_stack", "modules.GatedMaskedConv2d.gate", "modules.GatedMaskedConv2d.horiz_stack", "modules.GatedMaskedConv2d.vert_to_horiz", "modules.GatedMaskedConv2d.gate", "modules.GatedMaskedConv2d.make_causal", "modules.GatedMaskedConv2d.horiz_resid", "modules.GatedMaskedConv2d.horiz_resid", "x_v.size", "x_h.size"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.None.modules.GatedMaskedConv2d.make_causal", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.fairseq_dataset.FairseqDataset.size", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.fairseq_dataset.FairseqDataset.size"], ["", "def", "forward", "(", "self", ",", "x_v", ",", "x_h", ",", "h", ")", ":", "\n", "        ", "if", "self", ".", "mask_type", "==", "'A'", ":", "\n", "            ", "self", ".", "make_causal", "(", ")", "\n", "\n", "", "h", "=", "self", ".", "class_cond_embedding", "(", "h", ")", "\n", "h_vert", "=", "self", ".", "vert_stack", "(", "x_v", ")", "\n", "h_vert", "=", "h_vert", "[", ":", ",", ":", ",", ":", "x_v", ".", "size", "(", "-", "1", ")", ",", ":", "]", "\n", "out_v", "=", "self", ".", "gate", "(", "h_vert", "+", "h", "[", ":", ",", ":", ",", "None", ",", "None", "]", ")", "\n", "\n", "h_horiz", "=", "self", ".", "horiz_stack", "(", "x_h", ")", "\n", "h_horiz", "=", "h_horiz", "[", ":", ",", ":", ",", ":", ",", ":", "x_h", ".", "size", "(", "-", "2", ")", "]", "\n", "v2h", "=", "self", ".", "vert_to_horiz", "(", "h_vert", ")", "\n", "\n", "out", "=", "self", ".", "gate", "(", "v2h", "+", "h_horiz", "+", "h", "[", ":", ",", ":", ",", "None", ",", "None", "]", ")", "\n", "if", "self", ".", "residual", ":", "\n", "            ", "out_h", "=", "self", ".", "horiz_resid", "(", "out", ")", "+", "x_h", "\n", "", "else", ":", "\n", "            ", "out_h", "=", "self", ".", "horiz_resid", "(", "out", ")", "\n", "\n", "", "return", "out_v", ",", "out_h", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.None.modules.GatedPixelCNN.__init__": [[413, 442], ["torch.Module.__init__", "torch.Embedding", "torch.Embedding", "torch.Embedding", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "range", "torch.Sequential", "torch.Sequential", "torch.Sequential", "modules.GatedPixelCNN.apply", "modules.GatedPixelCNN.layers.append", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "modules.GatedMaskedConv2d"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.dummy_dictionary.DummyDictionary.__init__", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.transformer.Embedding", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.transformer.Embedding", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.transformer.Embedding"], ["    ", "def", "__init__", "(", "self", ",", "input_dim", "=", "256", ",", "dim", "=", "64", ",", "n_layers", "=", "15", ",", "n_classes", "=", "10", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dim", "=", "dim", "\n", "\n", "# Create embedding layer to embed input", "\n", "self", ".", "embedding", "=", "nn", ".", "Embedding", "(", "input_dim", ",", "dim", ")", "\n", "\n", "# Building the PixelCNN layer by layer", "\n", "self", ".", "layers", "=", "nn", ".", "ModuleList", "(", ")", "\n", "\n", "# Initial block with Mask-A convolution", "\n", "# Rest with Mask-B convolutions", "\n", "for", "i", "in", "range", "(", "n_layers", ")", ":", "\n", "            ", "mask_type", "=", "'A'", "if", "i", "==", "0", "else", "'B'", "\n", "kernel", "=", "7", "if", "i", "==", "0", "else", "3", "\n", "residual", "=", "False", "if", "i", "==", "0", "else", "True", "\n", "\n", "self", ".", "layers", ".", "append", "(", "\n", "GatedMaskedConv2d", "(", "mask_type", ",", "dim", ",", "kernel", ",", "residual", ",", "n_classes", ")", "\n", ")", "\n", "\n", "# Add the output layer", "\n", "", "self", ".", "output_conv", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Conv2d", "(", "dim", ",", "512", ",", "1", ")", ",", "\n", "nn", ".", "ReLU", "(", "True", ")", ",", "\n", "nn", ".", "Conv2d", "(", "512", ",", "input_dim", ",", "1", ")", "\n", ")", "\n", "\n", "self", ".", "apply", "(", "weights_init", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.None.modules.GatedPixelCNN.forward": [[443, 453], ["modules.GatedPixelCNN.embedding().view", "x.permute.permute.permute", "enumerate", "modules.GatedPixelCNN.output_conv", "x.permute.permute.size", "layer", "modules.GatedPixelCNN.embedding", "x.permute.permute.view"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.fairseq_dataset.FairseqDataset.size"], ["", "def", "forward", "(", "self", ",", "x", ",", "label", ")", ":", "\n", "        ", "shp", "=", "x", ".", "size", "(", ")", "+", "(", "-", "1", ",", ")", "\n", "x", "=", "self", ".", "embedding", "(", "x", ".", "view", "(", "-", "1", ")", ")", ".", "view", "(", "shp", ")", "# (B, H, W, C)", "\n", "x", "=", "x", ".", "permute", "(", "0", ",", "3", ",", "1", ",", "2", ")", "# (B, C, W, W)", "\n", "\n", "x_v", ",", "x_h", "=", "(", "x", ",", "x", ")", "\n", "for", "i", ",", "layer", "in", "enumerate", "(", "self", ".", "layers", ")", ":", "\n", "            ", "x_v", ",", "x_h", "=", "layer", "(", "x_v", ",", "x_h", ",", "label", ")", "\n", "\n", "", "return", "self", ".", "output_conv", "(", "x_h", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.None.modules.GatedPixelCNN.generate": [[454, 479], ["next", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "range", "modules.GatedPixelCNN.parameters", "range", "range", "modules.GatedPixelCNN.forward", "torch.softmax", "torch.softmax", "torch.softmax", "torch.zeros.data[].copy_", "torch.zeros.data[].copy_", "torch.zeros.data[].copy_", "modules.GatedPixelCNN.forward", "torch.softmax", "torch.softmax", "torch.softmax", "torch.zeros.data[].copy_", "torch.zeros.data[].copy_", "torch.zeros.data[].copy_", "torch.softmax.multinomial().squeeze", "torch.softmax.multinomial().squeeze", "torch.softmax.multinomial", "torch.softmax.multinomial"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.criterions.label_smoothed_cross_entropy.LabelSmoothedCrossEntropyCriterion.forward", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.utils.softmax", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.utils.softmax", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.utils.softmax", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.criterions.label_smoothed_cross_entropy.LabelSmoothedCrossEntropyCriterion.forward", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.utils.softmax", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.utils.softmax", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.utils.softmax"], ["", "def", "generate", "(", "self", ",", "label", ",", "shape", "=", "(", "7", ",", "7", ")", ",", "batch_size", "=", "64", ",", "sample_index", "=", "48", ")", ":", "\n", "        ", "param", "=", "next", "(", "self", ".", "parameters", "(", ")", ")", "\n", "x", "=", "torch", ".", "zeros", "(", "\n", "(", "batch_size", ",", "*", "shape", ")", ",", "\n", "dtype", "=", "torch", ".", "int64", ",", "device", "=", "param", ".", "device", "\n", ")", "\n", "index_i", "=", "(", "sample_index", "//", "7", ")", "+", "1", "\n", "index_j", "=", "(", "sample_index", "%", "7", ")", "+", "1", "\n", "\n", "for", "i", "in", "range", "(", "index_i", ")", ":", "\n", "            ", "if", "i", "<", "index_i", "-", "1", ":", "\n", "                ", "for", "j", "in", "range", "(", "shape", "[", "1", "]", ")", ":", "\n", "                    ", "logits", "=", "self", ".", "forward", "(", "x", ",", "label", ")", "\n", "probs", "=", "F", ".", "softmax", "(", "logits", "[", ":", ",", ":", ",", "i", ",", "j", "]", ",", "-", "1", ")", "\n", "x", ".", "data", "[", ":", ",", "i", ",", "j", "]", ".", "copy_", "(", "\n", "probs", ".", "multinomial", "(", "1", ")", ".", "squeeze", "(", ")", ".", "data", "\n", ")", "\n", "", "", "else", ":", "\n", "                ", "for", "j", "in", "range", "(", "index_j", ")", ":", "\n", "                    ", "logits", "=", "self", ".", "forward", "(", "x", ",", "label", ")", "\n", "probs", "=", "F", ".", "softmax", "(", "logits", "[", ":", ",", ":", ",", "i", ",", "j", "]", ",", "-", "1", ")", "\n", "x", ".", "data", "[", ":", ",", "i", ",", "j", "]", ".", "copy_", "(", "\n", "probs", ".", "multinomial", "(", "1", ")", ".", "squeeze", "(", ")", ".", "data", "\n", ")", "\n", "", "", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.None.modules.VectorQuantizedVAE_Bigger.__init__": [[482, 515], ["torch.Module.__init__", "torch.Sequential", "torch.Sequential", "torch.Sequential", "modules.VQEmbedding_Original", "torch.Sequential", "torch.Sequential", "torch.Sequential", "modules.VectorQuantizedVAE_Bigger.apply", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "modules.ResBlock", "modules.ResBlock", "modules.ResBlock", "modules.ResBlock", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.Tanh", "torch.Tanh", "torch.Tanh"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.dummy_dictionary.DummyDictionary.__init__"], ["    ", "def", "__init__", "(", "self", ",", "input_dim", ",", "dim", ",", "K", "=", "512", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "factor", "=", "2", "\n", "self", ".", "encoder", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Conv2d", "(", "input_dim", ",", "self", ".", "factor", "*", "64", ",", "4", ",", "2", ",", "1", ")", ",", "\n", "nn", ".", "BatchNorm2d", "(", "self", ".", "factor", "*", "64", ")", ",", "\n", "nn", ".", "ReLU", "(", "True", ")", ",", "\n", "nn", ".", "Conv2d", "(", "self", ".", "factor", "*", "64", ",", "self", ".", "factor", "*", "128", ",", "4", ",", "2", ",", "1", ")", ",", "\n", "# nn.BatchNorm2d(self.factor * 128),", "\n", "# nn.ReLU(True),", "\n", "# nn.Conv2d(self.factor * 128, self.factor * 256, 4, 2, 1),", "\n", "ResBlock", "(", "self", ".", "factor", "*", "128", ")", ",", "\n", "ResBlock", "(", "self", ".", "factor", "*", "128", ")", ",", "\n", "#ResBlock(self.factor * 256)", "\n", ")", "\n", "\n", "self", ".", "codebook", "=", "VQEmbedding_Original", "(", "K", ",", "self", ".", "factor", "*", "128", ")", "\n", "#self.codebook = VQEmbedding(K, self.factor * 256)", "\n", "self", ".", "decoder", "=", "nn", ".", "Sequential", "(", "\n", "ResBlock", "(", "self", ".", "factor", "*", "128", ")", ",", "\n", "ResBlock", "(", "self", ".", "factor", "*", "128", ")", ",", "\n", "#ResBlock(self.factor * 256),", "\n", "# nn.ConvTranspose2d(self.factor * 256, self.factor * 128, 4, 2, 1),", "\n", "# nn.BatchNorm2d(self.factor * 128),", "\n", "nn", ".", "ReLU", "(", "True", ")", ",", "\n", "nn", ".", "ConvTranspose2d", "(", "self", ".", "factor", "*", "128", ",", "self", ".", "factor", "*", "64", ",", "4", ",", "2", ",", "1", ")", ",", "\n", "nn", ".", "BatchNorm2d", "(", "self", ".", "factor", "*", "64", ")", ",", "\n", "nn", ".", "ReLU", "(", "True", ")", ",", "\n", "nn", ".", "ConvTranspose2d", "(", "self", ".", "factor", "*", "64", ",", "input_dim", ",", "4", ",", "2", ",", "1", ")", ",", "\n", "nn", ".", "Tanh", "(", ")", "\n", ")", "\n", "\n", "self", ".", "apply", "(", "weights_init", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.None.modules.VectorQuantizedVAE_Bigger.encode": [[516, 520], ["modules.VectorQuantizedVAE_Bigger.encoder", "modules.VectorQuantizedVAE_Bigger.codebook"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.fairseq_model.FairseqMultiModel.encoder"], ["", "def", "encode", "(", "self", ",", "x", ")", ":", "\n", "        ", "z_e_x", "=", "self", ".", "encoder", "(", "x", ")", "\n", "latents", "=", "self", ".", "codebook", "(", "z_e_x", ")", "\n", "return", "latents", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.None.modules.VectorQuantizedVAE_Bigger.decode": [[521, 525], ["modules.VectorQuantizedVAE_Bigger.codebook.embedding().permute", "modules.VectorQuantizedVAE_Bigger.decoder", "modules.VectorQuantizedVAE_Bigger.codebook.embedding"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.fairseq_model.FairseqMultiModel.decoder"], ["", "def", "decode", "(", "self", ",", "latents", ")", ":", "\n", "        ", "z_q_x", "=", "self", ".", "codebook", ".", "embedding", "(", "latents", ")", ".", "permute", "(", "0", ",", "3", ",", "1", ",", "2", ")", "# (B, D, H, W)", "\n", "x_tilde", "=", "self", ".", "decoder", "(", "z_q_x", ")", "\n", "return", "x_tilde", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.None.modules.VectorQuantizedVAE_Bigger.forward": [[526, 536], ["modules.VectorQuantizedVAE_Bigger.encoder", "modules.VectorQuantizedVAE_Bigger.codebook.straight_through", "modules.VectorQuantizedVAE_Bigger.decoder", "modules.VectorQuantizedVAE_Bigger.codebook.straight_through", "modules.VectorQuantizedVAE_Bigger.decoder"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.fairseq_model.FairseqMultiModel.encoder", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.None.modules.VQEmbedding.straight_through", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.fairseq_model.FairseqMultiModel.decoder", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.None.modules.VQEmbedding.straight_through", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.fairseq_model.FairseqMultiModel.decoder"], ["", "def", "forward", "(", "self", ",", "x", ",", "index", "=", "False", ")", ":", "\n", "        ", "z_e_x", "=", "self", ".", "encoder", "(", "x", ")", "\n", "if", "not", "index", ":", "\n", "            ", "z_q_x_st", ",", "z_q_x", "=", "self", ".", "codebook", ".", "straight_through", "(", "z_e_x", ")", "\n", "x_tilde", "=", "self", ".", "decoder", "(", "z_q_x_st", ")", "\n", "return", "x_tilde", ",", "z_e_x", ",", "z_q_x", "\n", "", "else", ":", "\n", "            ", "z_q_x_st", ",", "z_q_x", ",", "indices", "=", "self", ".", "codebook", ".", "straight_through", "(", "z_e_x", ",", "index", ")", "\n", "x_tilde", "=", "self", ".", "decoder", "(", "z_q_x_st", ")", "\n", "return", "x_tilde", ",", "z_e_x", ",", "z_q_x", ",", "indices", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.None.modules.VectorQuantizedVAE_Bigger.indices_fetch": [[537, 544], ["modules.VectorQuantizedVAE_Bigger.codebook.indices_fetch", "modules.VectorQuantizedVAE_Bigger.decoder", "indices.size", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "indices.size", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.cat.size", "indices.size"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.None.modules.VectorQuantizedVAE_Bigger.indices_fetch", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.fairseq_model.FairseqMultiModel.decoder", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.fairseq_dataset.FairseqDataset.size", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.fairseq_dataset.FairseqDataset.size", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.fairseq_dataset.FairseqDataset.size", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.fairseq_dataset.FairseqDataset.size", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.fairseq_dataset.FairseqDataset.size", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.fairseq_dataset.FairseqDataset.size", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.fairseq_dataset.FairseqDataset.size", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.fairseq_dataset.FairseqDataset.size", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.fairseq_dataset.FairseqDataset.size"], ["", "", "def", "indices_fetch", "(", "self", ",", "indices", ")", ":", "\n", "        ", "z", "=", "self", ".", "codebook", ".", "indices_fetch", "(", "indices", ")", "\n", "if", "indices", ".", "size", "(", "1", ")", "<", "self", ".", "dim", ":", "\n", "            ", "zero_out", "=", "torch", ".", "zeros", "(", "(", "indices", ".", "size", "(", "0", ")", ",", "self", ".", "dim", "-", "indices", ".", "size", "(", "1", ")", ",", "z", ".", "size", "(", "2", ")", ",", "z", ".", "size", "(", "3", ")", ")", ")", ".", "cuda", "(", ")", "\n", "z", "=", "torch", ".", "cat", "(", "(", "z", ",", "zero_out", ")", ",", "dim", "=", "1", ")", "\n", "", "x", "=", "self", ".", "decoder", "(", "z", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.None.modules.LSTM.__init__": [[547, 556], ["torch.Module.__init__", "torch.Embedding", "torch.Embedding", "torch.Embedding", "torch.LSTM", "torch.LSTM", "torch.LSTM", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.dummy_dictionary.DummyDictionary.__init__", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.transformer.Embedding", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.transformer.Embedding", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.transformer.Embedding", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.lstm.LSTM", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.lstm.LSTM", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.lstm.LSTM", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.modules.transformer_layer.Linear", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.modules.transformer_layer.Linear", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.modules.transformer_layer.Linear"], ["    ", "def", "__init__", "(", "self", ",", "k", ",", "embedding_dim", "=", "5000", ",", "hidden_size", "=", "2000", ",", "label_size", "=", "100", ")", ":", "\n", "        ", "super", "(", "LSTM", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "embedding", "=", "nn", ".", "Embedding", "(", "\n", "num_embeddings", "=", "k", ",", "\n", "embedding_dim", "=", "embedding_dim", "\n", ")", "\n", "self", ".", "lstm", "=", "nn", ".", "LSTM", "(", "input_size", "=", "embedding_dim", ",", "hidden_size", "=", "hidden_size", ",", "num_layers", "=", "3", ",", "bias", "=", "True", ",", "batch_first", "=", "True", ")", "\n", "self", ".", "code_size", "=", "k", "\n", "self", ".", "fc", "=", "nn", ".", "Linear", "(", "hidden_size", ",", "self", ".", "code_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.None.modules.LSTM.forward": [[557, 569], ["modules.LSTM.embedding", "lstm.contiguous().view.contiguous().view.contiguous().view", "modules.LSTM.fc", "input.long", "modules.LSTM.lstm", "modules.LSTM.lstm", "lstm.contiguous().view.contiguous().view.contiguous", "h.detach", "c.detach"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input", ",", "label", ",", "hidden", "=", "None", ")", ":", "\n", "        ", "embeddings", "=", "self", ".", "embedding", "(", "input", ".", "long", "(", ")", ")", "\n", "#label = label.unsqueeze(1).unsqueeze(2)", "\n", "#label = label.expand(embeddings.size(0), embeddings.size(1),1000).float()", "\n", "#embeddings = torch.cat((embeddings,label),dim=2)", "\n", "if", "hidden", "is", "None", ":", "\n", "            ", "lstm", ",", "(", "h", ",", "c", ")", "=", "self", ".", "lstm", "(", "embeddings", ")", "\n", "", "else", ":", "\n", "            ", "lstm", ",", "(", "h", ",", "c", ")", "=", "self", ".", "lstm", "(", "embeddings", ",", "hidden", ")", "\n", "", "lstm", "=", "lstm", ".", "contiguous", "(", ")", ".", "view", "(", "-", "1", ",", "lstm", ".", "shape", "[", "2", "]", ")", "\n", "logits", "=", "self", ".", "fc", "(", "lstm", ")", "\n", "return", "logits", ",", "(", "h", ".", "detach", "(", ")", ",", "c", ".", "detach", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.None.modules.LSTM.sample": [[570, 597], ["torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.multinomial().type().cuda", "torch.multinomial().type().cuda", "torch.multinomial().type().cuda", "torch.multinomial().type().cuda", "torch.multinomial().type().cuda", "torch.multinomial().type().cuda", "torch.multinomial().type().cuda", "torch.multinomial().type().cuda", "torch.multinomial().type().cuda", "torch.multinomial().type().cuda.unsqueeze", "torch.multinomial().type().cuda.unsqueeze", "torch.multinomial().type().cuda.unsqueeze", "output.append", "range", "torch.multinomial().type().cuda.squeeze", "torch.multinomial().type().cuda.squeeze", "torch.multinomial().type().cuda.squeeze", "modules.LSTM.forward", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.multinomial().type().cuda", "torch.multinomial().type().cuda", "torch.multinomial().type().cuda", "torch.multinomial().type().cuda", "torch.multinomial().type().cuda", "torch.multinomial().type().cuda", "torch.multinomial().type().cuda", "torch.multinomial().type().cuda", "torch.multinomial().type().cuda", "output.append", "torch.multinomial().type", "torch.multinomial().type", "torch.multinomial().type", "torch.multinomial().type", "torch.multinomial().type", "torch.multinomial().type", "torch.multinomial().type", "torch.multinomial().type", "torch.multinomial().type", "torch.multinomial().type().cuda.squeeze", "torch.multinomial().type().cuda.squeeze", "torch.multinomial().type().cuda.squeeze", "torch.multinomial().type", "torch.multinomial().type", "torch.multinomial().type", "torch.multinomial().type", "torch.multinomial().type", "torch.multinomial().type", "torch.multinomial().type", "torch.multinomial().type", "torch.multinomial().type", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.criterions.label_smoothed_cross_entropy.LabelSmoothedCrossEntropyCriterion.forward"], ["", "def", "sample", "(", "self", ",", "prior", ",", "seq_len", ",", "label", ")", ":", "\n", "        ", "\"\"\"\n        Sample a string of length `seq_len` from the model.\n        :param seq_len [int]: String length\n        :param prior[tensor]: Prior of the first element\n        :return [list]: A list of length `seq_len` that contains the index of each generated character.\n        \"\"\"", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "h_prev", "=", "None", "\n", "output", "=", "[", "]", "\n", "x", "=", "torch", ".", "multinomial", "(", "prior", ",", "1", ",", "replacement", "=", "True", ")", ".", "type", "(", "torch", ".", "int64", ")", ".", "cuda", "(", ")", "\n", "x", "=", "x", ".", "unsqueeze", "(", "1", ")", "\n", "output", ".", "append", "(", "x", ".", "squeeze", "(", ")", ")", "\n", "for", "i", "in", "range", "(", "1", ",", "seq_len", ")", ":", "\n", "\n", "                ", "logits", ",", "h_prev", "=", "self", ".", "forward", "(", "x", ",", "label", ",", "h_prev", ")", "\n", "np_logits", "=", "logits", "\n", "probs", "=", "torch", ".", "exp", "(", "np_logits", ")", "\n", "probs", "=", "torch", ".", "clamp", "(", "probs", ",", "0", ",", "1e30", ")", "\n", "x", "=", "torch", ".", "multinomial", "(", "probs", ",", "1", ")", ".", "type", "(", "torch", ".", "int64", ")", ".", "cuda", "(", ")", "\n", "# np_logits = logits[-1, :].to('cpu').numpy()", "\n", "# probs = np.exp(np_logits) / np.sum(np.exp(np_logits))", "\n", "# ix = np.random.choice(self.code_size, p=probs.ravel())", "\n", "# x = torch.tensor(ix, dtype=torch.int64)[None, None].cuda()", "\n", "output", ".", "append", "(", "x", ".", "squeeze", "(", ")", ")", "\n", "", "", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.None.modules.LSTM.sample_batch": [[598, 619], ["torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.multinomial().type().cuda", "torch.multinomial().type().cuda", "torch.multinomial().type().cuda", "torch.multinomial().type().cuda", "torch.multinomial().type().cuda", "torch.multinomial().type().cuda", "torch.multinomial().type().cuda", "torch.multinomial().type().cuda", "torch.multinomial().type().cuda", "torch.multinomial().type().cuda.unsqueeze", "torch.multinomial().type().cuda.unsqueeze", "torch.multinomial().type().cuda.unsqueeze", "torch.multinomial().type().cuda.squeeze", "torch.multinomial().type().cuda.squeeze", "torch.multinomial().type().cuda.squeeze", "range", "modules.LSTM.forward", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.multinomial().type().cuda", "torch.multinomial().type().cuda", "torch.multinomial().type().cuda", "torch.multinomial().type().cuda", "torch.multinomial().type().cuda", "torch.multinomial().type().cuda", "torch.multinomial().type().cuda", "torch.multinomial().type().cuda", "torch.multinomial().type().cuda", "torch.multinomial().type().cuda.squeeze", "torch.multinomial().type().cuda.squeeze", "torch.multinomial().type().cuda.squeeze", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.multinomial().type", "torch.multinomial().type", "torch.multinomial().type", "torch.multinomial().type", "torch.multinomial().type", "torch.multinomial().type", "torch.multinomial().type", "torch.multinomial().type", "torch.multinomial().type", "torch.multinomial().type", "torch.multinomial().type", "torch.multinomial().type", "torch.multinomial().type", "torch.multinomial().type", "torch.multinomial().type", "torch.multinomial().type", "torch.multinomial().type", "torch.multinomial().type", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.criterions.label_smoothed_cross_entropy.LabelSmoothedCrossEntropyCriterion.forward"], ["", "def", "sample_batch", "(", "self", ",", "prior", ",", "seq_len", ",", "batch_size", ",", "label", ")", ":", "\n", "        ", "\"\"\"\n        Sample a string of length `seq_len` from the model.\n        :param seq_len [int]: String length\n        :return [list]: A list of length `seq_len` that contains the index of each generated character.\n        \"\"\"", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "h_prev", "=", "None", "\n", "output", "=", "torch", ".", "zeros", "(", "(", "batch_size", ",", "seq_len", ")", ")", ".", "cuda", "(", ")", "\n", "x", "=", "torch", ".", "multinomial", "(", "prior", ",", "batch_size", ",", "replacement", "=", "True", ")", ".", "type", "(", "torch", ".", "int64", ")", ".", "cuda", "(", ")", "\n", "x", "=", "x", ".", "unsqueeze", "(", "1", ")", "\n", "output", "[", ":", ",", "0", "]", "=", "x", ".", "squeeze", "(", ")", "\n", "for", "i", "in", "range", "(", "1", ",", "seq_len", ")", ":", "\n", "                ", "logits", ",", "h_prev", "=", "self", ".", "forward", "(", "x", ",", "label", ",", "h_prev", ")", "\n", "np_logits", "=", "logits", "\n", "probs", "=", "torch", ".", "exp", "(", "np_logits", ")", "\n", "probs", "=", "torch", ".", "clamp", "(", "probs", ",", "0", ",", "1e30", ")", "\n", "x", "=", "torch", ".", "multinomial", "(", "probs", ",", "1", ")", ".", "type", "(", "torch", ".", "int64", ")", ".", "cuda", "(", ")", "\n", "output", "[", ":", ",", "i", "]", "=", "x", ".", "squeeze", "(", ")", "\n", "", "", "return", "output", "", "", "", ""]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.None.modules.to_scalar": [[9, 14], ["type", "arr.item", "x.item"], "function", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.utils.item", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.utils.item"], ["def", "to_scalar", "(", "arr", ")", ":", "\n", "    ", "if", "type", "(", "arr", ")", "==", "list", ":", "\n", "        ", "return", "[", "x", ".", "item", "(", ")", "for", "x", "in", "arr", "]", "\n", "", "else", ":", "\n", "        ", "return", "arr", ".", "item", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.None.modules.weights_init": [[15, 23], ["classname.find", "torch.init.xavier_uniform_", "m.bias.data.fill_", "print"], "function", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.progress_bar.tensorboard_log_wrapper.print"], ["", "", "def", "weights_init", "(", "m", ")", ":", "\n", "    ", "classname", "=", "m", ".", "__class__", ".", "__name__", "\n", "if", "classname", ".", "find", "(", "'Conv'", ")", "!=", "-", "1", ":", "\n", "        ", "try", ":", "\n", "            ", "nn", ".", "init", ".", "xavier_uniform_", "(", "m", ".", "weight", ".", "data", ")", "\n", "m", ".", "bias", ".", "data", ".", "fill_", "(", "0", ")", "\n", "", "except", "AttributeError", ":", "\n", "            ", "print", "(", "\"Skipping initialization of \"", ",", "classname", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.None.vqvae.train": [[11, 46], ["tqdm.tqdm", "images.to.to", "writer.add_scalar", "writer.add_scalar", "optimizer.zero_grad", "model", "torch.mse_loss", "torch.mse_loss", "torch.mse_loss", "loss.backward", "optimizer.step", "optimizer.zero_grad", "model", "torch.mse_loss", "torch.mse_loss", "torch.mse_loss", "loss.backward", "optimizer.step", "F.mse_loss.item", "F.mse_loss.item", "z_e_x.detach", "z_q_x.detach", "z_e_x.detach", "z_q_x.detach"], "function", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.optim.fp16_optimizer._MemoryEfficientFP16OptimizerMixin.zero_grad", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.trainer.Trainer.model", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.optim.fp16_optimizer._MemoryEfficientFP16OptimizerMixin.backward", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.lr_scheduler.polynomial_decay_schedule.PolynomialDecaySchedule.step", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.optim.fp16_optimizer._MemoryEfficientFP16OptimizerMixin.zero_grad", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.trainer.Trainer.model", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.optim.fp16_optimizer._MemoryEfficientFP16OptimizerMixin.backward", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.lr_scheduler.polynomial_decay_schedule.PolynomialDecaySchedule.step", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.utils.item", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.utils.item"], ["def", "train", "(", "epoch", ",", "data_loader", ",", "model", ",", "optimizer", ",", "args", ",", "writer", ")", ":", "\n", "    ", "for", "images", ",", "_", "in", "tqdm", "(", "data_loader", ")", ":", "\n", "        ", "images", "=", "images", ".", "to", "(", "args", ".", "device", ")", "\n", "\n", "if", "args", ".", "pretrain", ":", "\n", "            ", "optimizer", ".", "zero_grad", "(", ")", "\n", "x_tilde", ",", "z_e_x", ",", "z_q_x", "=", "model", "(", "images", ",", "full_sample", "=", "True", ")", "\n", "# Reconstruction loss", "\n", "loss_recons", "=", "F", ".", "mse_loss", "(", "x_tilde", ",", "images", ")", "\n", "# Vector quantization objective", "\n", "loss_vq", "=", "F", ".", "mse_loss", "(", "z_q_x", ",", "z_e_x", ".", "detach", "(", ")", ")", "\n", "# Commitment objective", "\n", "loss_commit", "=", "F", ".", "mse_loss", "(", "z_e_x", ",", "z_q_x", ".", "detach", "(", ")", ")", "\n", "loss", "=", "loss_recons", "+", "loss_vq", "+", "loss_commit", "\n", "loss", ".", "backward", "(", ")", "\n", "optimizer", ".", "step", "(", ")", "\n", "", "else", ":", "\n", "            ", "optimizer", ".", "zero_grad", "(", ")", "\n", "x_tilde", ",", "z_e_x", ",", "z_q_x", ",", "index", "=", "model", "(", "images", ",", "full_sample", "=", "False", ")", "\n", "# Reconstruction loss", "\n", "loss_recons", "=", "F", ".", "mse_loss", "(", "x_tilde", ",", "images", ")", "\n", "# Vector quantization objective", "\n", "loss_vq", "=", "F", ".", "mse_loss", "(", "z_q_x", "[", ":", ",", ":", "index", "]", ",", "z_e_x", ".", "detach", "(", ")", "[", ":", ",", ":", "index", "]", ")", "\n", "# Commitment objective", "\n", "loss_commit", "=", "F", ".", "mse_loss", "(", "z_e_x", "[", ":", ",", ":", "index", "]", ",", "z_q_x", ".", "detach", "(", ")", "[", ":", ",", ":", "index", "]", ")", "\n", "loss", "=", "loss_recons", "+", "loss_vq", "+", "loss_commit", "\n", "loss", ".", "backward", "(", ")", "\n", "optimizer", ".", "step", "(", ")", "\n", "\n", "# Logs", "\n", "", "writer", ".", "add_scalar", "(", "'loss/train/reconstruction'", ",", "\n", "loss_recons", ".", "item", "(", ")", ",", "args", ".", "steps", ")", "\n", "writer", ".", "add_scalar", "(", "'loss/train/quantization'", ",", "\n", "loss_vq", ".", "item", "(", ")", ",", "args", ".", "steps", ")", "\n", "args", ".", "steps", "+=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.None.vqvae.test": [[48, 74], ["writer.add_scalar", "writer.add_scalar", "torch.no_grad", "torch.no_grad", "len", "len", "loss_recons_designate.keys", "loss_recons.item", "loss_vq.item", "loss_recons.item", "loss_vq.item", "images.to.to", "model", "torch.mse_loss", "torch.mse_loss", "loss_recons_designate.keys", "len", "writer.add_scalar", "range", "model", "torch.mse_loss", "loss_recons_designate[].item", "str"], "function", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.utils.item", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.utils.item", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.utils.item", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.utils.item", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.trainer.Trainer.model", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.trainer.Trainer.model", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.utils.item"], ["", "", "def", "test", "(", "data_loader", ",", "model", ",", "args", ",", "writer", ")", ":", "\n", "    ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "loss_recons", ",", "loss_vq", "=", "0.", ",", "0.", "\n", "loss_recons_designate", "=", "{", "\n", "args", ".", "hidden_size", "//", "5", "*", "(", "i", "+", "1", ")", ":", "0", "\n", "for", "i", "in", "range", "(", "5", "-", "1", ")", "\n", "}", "\n", "for", "images", ",", "_", "in", "data_loader", ":", "\n", "            ", "images", "=", "images", ".", "to", "(", "args", ".", "device", ")", "\n", "x_tilde", ",", "z_e_x", ",", "z_q_x", "=", "model", "(", "images", ")", "\n", "loss_recons", "+=", "F", ".", "mse_loss", "(", "x_tilde", ",", "images", ")", "\n", "loss_vq", "+=", "F", ".", "mse_loss", "(", "z_q_x", ",", "z_e_x", ")", "\n", "for", "i", "in", "loss_recons_designate", ".", "keys", "(", ")", ":", "\n", "                ", "x_tilde", ",", "z_e_x", ",", "z_q_x", ",", "_", "=", "model", "(", "images", ",", "full_sample", "=", "False", ",", "designate", "=", "i", ")", "\n", "loss_recons_designate", "[", "i", "]", "+=", "F", ".", "mse_loss", "(", "x_tilde", ",", "images", ")", "\n", "\n", "", "", "loss_recons", "/=", "len", "(", "data_loader", ")", "\n", "loss_vq", "/=", "len", "(", "data_loader", ")", "\n", "for", "i", "in", "loss_recons_designate", ".", "keys", "(", ")", ":", "\n", "            ", "loss_recons_designate", "[", "i", "]", "/=", "len", "(", "data_loader", ")", "\n", "writer", ".", "add_scalar", "(", "'loss/test/reconstruction_'", "+", "str", "(", "i", ")", ",", "loss_recons_designate", "[", "i", "]", ".", "item", "(", ")", ",", "args", ".", "steps", ")", "\n", "# Logs", "\n", "", "", "writer", ".", "add_scalar", "(", "'loss/test/reconstruction'", ",", "loss_recons", ".", "item", "(", ")", ",", "args", ".", "steps", ")", "\n", "writer", ".", "add_scalar", "(", "'loss/test/quantization'", ",", "loss_vq", ".", "item", "(", ")", ",", "args", ".", "steps", ")", "\n", "\n", "return", "loss_recons", ".", "item", "(", ")", ",", "loss_vq", ".", "item", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.None.vqvae.generate_samples": [[76, 84], ["torch.no_grad", "torch.no_grad", "images.to.to", "model", "model"], "function", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.trainer.Trainer.model", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.trainer.Trainer.model"], ["", "def", "generate_samples", "(", "images", ",", "model", ",", "args", ",", "full", ",", "designate", ")", ":", "\n", "    ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "images", "=", "images", ".", "to", "(", "args", ".", "device", ")", "\n", "if", "not", "full", ":", "\n", "            ", "x_tilde", ",", "_", ",", "_", ",", "_", "=", "model", "(", "images", ",", "full", ",", "designate", ")", "\n", "", "else", ":", "\n", "            ", "x_tilde", ",", "_", ",", "_", "=", "model", "(", "images", ",", "full", ",", "designate", ")", "\n", "", "", "return", "x_tilde", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.None.vqvae.generate_samples_train": [[86, 102], ["print", "model.eval", "len", "torch.no_grad", "torch.no_grad", "tqdm.tqdm", "images.to.to", "torch.mse_loss", "model", "model"], "function", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.progress_bar.tensorboard_log_wrapper.print", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.utils.eval", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.trainer.Trainer.model", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.trainer.Trainer.model"], ["", "def", "generate_samples_train", "(", "data_loader", ",", "model", ",", "args", ",", "full", ",", "designate", "=", "None", ")", ":", "\n", "    ", "print", "(", "\"Current designate:\"", ",", "designate", ")", "\n", "loss", "=", "0.0", "\n", "model", ".", "eval", "(", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "for", "images", ",", "_", "in", "tqdm", "(", "data_loader", ")", ":", "\n", "            ", "images", "=", "images", ".", "to", "(", "args", ".", "device", ")", "\n", "if", "not", "full", ":", "\n", "                ", "x_tilde", ",", "_", ",", "_", ",", "_", "=", "model", "(", "images", ",", "full", ",", "designate", ")", "\n", "", "else", ":", "\n", "                ", "x_tilde", ",", "_", ",", "_", "=", "model", "(", "images", ",", "full", ",", "designate", ")", "\n", "\n", "", "loss", "+=", "F", ".", "mse_loss", "(", "x_tilde", ",", "images", ",", "reduction", "=", "'sum'", ")", "\n", "\n", "", "", "loss", "/=", "len", "(", "data_loader", ".", "dataset", ")", "\n", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.None.vqvae.plot_reconstructed_images": [[104, 114], ["range", "vqvae.generate_samples", "torchvision.utils.make_grid", "writer.add_image", "vqvae.generate_samples", "torchvision.utils.make_grid", "writer.add_image", "generate_samples.cpu", "generate_samples.cpu"], "function", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.None.vqvae.generate_samples", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.None.vqvae.generate_samples"], ["", "def", "plot_reconstructed_images", "(", "fixed_images", ",", "model", ",", "epoch", ",", "writer", ")", ":", "\n", "    ", "for", "i", "in", "range", "(", "5", "-", "1", ")", ":", "\n", "        ", "hidden_step", "=", "args", ".", "hidden_size", "//", "5", "*", "(", "i", "+", "1", ")", "\n", "reconstruction", "=", "generate_samples", "(", "fixed_images", ",", "model", ",", "args", ",", "False", ",", "hidden_step", ")", "\n", "grid", "=", "make_grid", "(", "reconstruction", ".", "cpu", "(", ")", ",", "nrow", "=", "8", ",", "range", "=", "(", "-", "1", ",", "1", ")", ",", "normalize", "=", "True", ")", "\n", "writer", ".", "add_image", "(", "f'reconstruction_{hidden_step}'", ",", "grid", ",", "epoch", ")", "\n", "\n", "", "reconstruction", "=", "generate_samples", "(", "fixed_images", ",", "model", ",", "args", ",", "True", ",", "None", ")", "\n", "grid", "=", "make_grid", "(", "reconstruction", ".", "cpu", "(", ")", ",", "nrow", "=", "8", ",", "range", "=", "(", "-", "1", ",", "1", ")", ",", "normalize", "=", "True", ")", "\n", "writer", ".", "add_image", "(", "'reconstruction_full'", ",", "grid", ",", "epoch", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.None.vqvae.main": [[116, 162], ["tensorboardX.SummaryWriter", "os.path.join", "datasets.load_data", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "next", "torchvision.utils.make_grid", "tensorboardX.SummaryWriter.add_image", "torch.optim.Adam", "torch.optim.Adam", "vqvae.plot_reconstructed_images", "vqvae.test", "range", "iter", "modules.VectorQuantizedVAE_CelebA().to", "VectorQuantizedVAE_Dim().to.load_state_dict", "VectorQuantizedVAE_Dim().to.parameters", "vqvae.train", "vqvae.test", "vqvae.plot_reconstructed_images", "modules.VectorQuantizedVAE_mnist().to", "modules.VectorQuantizedVAE_Dim().to", "torch.load", "torch.load", "open", "torch.save", "torch.save", "modules.VectorQuantizedVAE_CelebA", "open", "torch.save", "torch.save", "VectorQuantizedVAE_Dim().to.state_dict", "modules.VectorQuantizedVAE_mnist", "modules.VectorQuantizedVAE_Dim", "VectorQuantizedVAE_Dim().to.state_dict"], "function", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.None.datasets.load_data", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.None.vqvae.plot_reconstructed_images", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.None.prior_sampler.test", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.iterators.EpochBatchIterator.load_state_dict", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.None.train_ar.train", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.None.prior_sampler.test", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.None.vqvae.plot_reconstructed_images", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.iterators.EpochBatchIterator.state_dict", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.iterators.EpochBatchIterator.state_dict"], ["", "def", "main", "(", "args", ")", ":", "\n", "    ", "writer", "=", "SummaryWriter", "(", "'./logs/{0}'", ".", "format", "(", "args", ".", "out_path", ")", ")", "\n", "save_filename", "=", "os", ".", "path", ".", "join", "(", "'/data1/xuyilun'", ",", "args", ".", "out_path", ",", "'model'", ")", "\n", "\n", "train_dataset", ",", "valid_dataset", ",", "test_dataset", ",", "num_channels", "=", "datasets", ".", "load_data", "(", "args", ".", "dataset", ",", "args", ".", "data_folder", ")", "\n", "\n", "# Define the data loaders", "\n", "train_loader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "train_dataset", ",", "batch_size", "=", "args", ".", "batch_size", ",", "shuffle", "=", "True", ",", "\n", "num_workers", "=", "args", ".", "num_workers", ",", "pin_memory", "=", "True", ")", "\n", "valid_loader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "valid_dataset", ",", "batch_size", "=", "args", ".", "batch_size", ",", "shuffle", "=", "False", ",", "\n", "num_workers", "=", "args", ".", "num_workers", ",", "pin_memory", "=", "True", ")", "\n", "test_loader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "test_dataset", ",", "batch_size", "=", "16", ",", "shuffle", "=", "False", ")", "\n", "\n", "# Fixed images for Tensorboard", "\n", "fixed_images", ",", "_", "=", "next", "(", "iter", "(", "test_loader", ")", ")", "\n", "fixed_grid", "=", "make_grid", "(", "fixed_images", ",", "nrow", "=", "8", ",", "range", "=", "(", "-", "1", ",", "1", ")", ",", "normalize", "=", "True", ")", "\n", "writer", ".", "add_image", "(", "'original'", ",", "fixed_grid", ",", "0", ")", "\n", "if", "args", ".", "dataset", "==", "'celeba'", ":", "\n", "        ", "model", "=", "VectorQuantizedVAE_CelebA", "(", "num_channels", ",", "args", ".", "hidden_size", ",", "args", ".", "k", ")", ".", "to", "(", "args", ".", "device", ")", "\n", "", "elif", "args", ".", "dataaset", "==", "'mnist'", ":", "\n", "        ", "model", "=", "VectorQuantizedVAE_mnist", "(", "num_channels", ",", "args", ".", "hidden_size", ",", "args", ".", "k", ")", ".", "to", "(", "args", ".", "device", ")", "\n", "", "else", ":", "\n", "        ", "model", "=", "VectorQuantizedVAE_Dim", "(", "num_channels", ",", "args", ".", "hidden_size", ",", "args", ".", "k", ")", ".", "to", "(", "args", ".", "device", ")", "\n", "\n", "", "if", "args", ".", "restore_checkpoint", ":", "\n", "        ", "assert", "not", "args", ".", "pretrain", "\n", "model", ".", "load_state_dict", "(", "torch", ".", "load", "(", "args", ".", "restore_checkpoint", ")", ")", "\n", "", "optimizer", "=", "torch", ".", "optim", ".", "Adam", "(", "model", ".", "parameters", "(", ")", ",", "lr", "=", "args", ".", "lr", ",", "betas", "=", "(", "0.9", ",", "args", ".", "adam_beta2", ")", ",", "\n", "eps", "=", "args", ".", "adam_eps", ",", "amsgrad", "=", "args", ".", "amsgrad", ")", "\n", "\n", "plot_reconstructed_images", "(", "fixed_images", ",", "model", ",", "0", ",", "writer", ")", "\n", "\n", "best_loss", "=", "-", "1.", "\n", "loss", ",", "_", "=", "test", "(", "valid_loader", ",", "model", ",", "args", ",", "writer", ")", "\n", "for", "epoch", "in", "range", "(", "args", ".", "num_epochs", ")", ":", "\n", "        ", "train", "(", "epoch", ",", "train_loader", ",", "model", ",", "optimizer", ",", "args", ",", "writer", ")", "\n", "loss", ",", "_", "=", "test", "(", "valid_loader", ",", "model", ",", "args", ",", "writer", ")", "\n", "\n", "plot_reconstructed_images", "(", "fixed_images", ",", "model", ",", "epoch", "+", "1", ",", "writer", ")", "\n", "\n", "if", "(", "epoch", "==", "0", ")", "or", "(", "loss", "<", "best_loss", ")", ":", "\n", "            ", "best_loss", "=", "loss", "\n", "with", "open", "(", "'{0}/best.pt'", ".", "format", "(", "save_filename", ")", ",", "'wb'", ")", "as", "f", ":", "\n", "                ", "torch", ".", "save", "(", "model", ".", "state_dict", "(", ")", ",", "f", ")", "\n", "", "", "with", "open", "(", "'{0}/model_{1}.pt'", ".", "format", "(", "save_filename", ",", "epoch", "+", "1", ")", ",", "'wb'", ")", "as", "f", ":", "\n", "            ", "torch", ".", "save", "(", "model", ".", "state_dict", "(", ")", ",", "f", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.None.prior_sampler.train": [[15, 37], ["tqdm.tqdm", "labels.to.to", "prior", "logits.permute().contiguous.permute().contiguous", "optimizer.zero_grad", "torch.cross_entropy", "F.cross_entropy.backward", "writer.add_scalar", "optimizer.step", "torch.no_grad", "torch.no_grad", "images.to.to", "model.encode", "latents.detach.detach", "logits.permute().contiguous.view", "latents.detach.view", "F.cross_entropy.item", "logits.permute().contiguous.permute"], "function", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.optim.fp16_optimizer._MemoryEfficientFP16OptimizerMixin.zero_grad", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.optim.fp16_optimizer._MemoryEfficientFP16OptimizerMixin.backward", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.lr_scheduler.polynomial_decay_schedule.PolynomialDecaySchedule.step", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq._hub_utils.TokenizerHubInterface.encode", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.utils.item"], ["def", "train", "(", "data_loader", ",", "model", ",", "prior", ",", "optimizer", ",", "args", ",", "writer", ")", ":", "\n", "\n", "    ", "for", "images", ",", "labels", "in", "tqdm", "(", "data_loader", ")", ":", "\n", "        ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "images", "=", "images", ".", "to", "(", "args", ".", "device", ")", "\n", "latents", "=", "model", ".", "encode", "(", "images", ")", "\n", "latents", "=", "latents", ".", "detach", "(", ")", "\n", "\n", "", "labels", "=", "labels", ".", "to", "(", "args", ".", "device", ")", "\n", "logits", "=", "prior", "(", "latents", ",", "labels", ")", "\n", "logits", "=", "logits", ".", "permute", "(", "0", ",", "2", ",", "3", ",", "1", ")", ".", "contiguous", "(", ")", "\n", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "loss", "=", "F", ".", "cross_entropy", "(", "logits", ".", "view", "(", "-", "1", ",", "args", ".", "k", ")", ",", "\n", "latents", ".", "view", "(", "-", "1", ")", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "\n", "# Logs", "\n", "writer", ".", "add_scalar", "(", "'loss/train'", ",", "loss", ".", "item", "(", ")", ",", "args", ".", "steps", ")", "\n", "\n", "optimizer", ".", "step", "(", ")", "\n", "args", ".", "steps", "+=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.None.prior_sampler.test": [[39, 59], ["writer.add_scalar", "loss.item", "torch.no_grad", "torch.no_grad", "len", "loss.item", "images.to.to", "labels.to.to", "model.encode", "latents.detach.detach", "prior", "logits.permute().contiguous.permute().contiguous", "torch.cross_entropy", "logits.permute().contiguous.view", "latents.detach.view", "logits.permute().contiguous.permute"], "function", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.utils.item", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.utils.item", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq._hub_utils.TokenizerHubInterface.encode"], ["", "", "def", "test", "(", "data_loader", ",", "model", ",", "prior", ",", "args", ",", "writer", ")", ":", "\n", "    ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "loss", "=", "0.", "\n", "for", "images", ",", "labels", "in", "data_loader", ":", "\n", "            ", "images", "=", "images", ".", "to", "(", "args", ".", "device", ")", "\n", "labels", "=", "labels", ".", "to", "(", "args", ".", "device", ")", "\n", "\n", "latents", "=", "model", ".", "encode", "(", "images", ")", "\n", "latents", "=", "latents", ".", "detach", "(", ")", "\n", "logits", "=", "prior", "(", "latents", ",", "labels", ")", "\n", "logits", "=", "logits", ".", "permute", "(", "0", ",", "2", ",", "3", ",", "1", ")", ".", "contiguous", "(", ")", "\n", "loss", "+=", "F", ".", "cross_entropy", "(", "logits", ".", "view", "(", "-", "1", ",", "args", ".", "k", ")", ",", "\n", "latents", ".", "view", "(", "-", "1", ")", ")", "\n", "\n", "", "loss", "/=", "len", "(", "data_loader", ")", "\n", "\n", "# Logs", "\n", "", "writer", ".", "add_scalar", "(", "'loss/valid'", ",", "loss", ".", "item", "(", ")", ",", "args", ".", "steps", ")", "\n", "\n", "return", "loss", ".", "item", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.None.prior_sampler.main": [[61, 149], ["tensorboardX.SummaryWriter", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "next", "torchvision.utils.make_grid", "tensorboardX.SummaryWriter.add_image", "modules.VectorQuantizedVAE().to", "VectorQuantizedVAE().to.eval", "modules.GatedPixelCNN().to", "torch.load", "torch.load", "GatedPixelCNN().to.load_state_dict", "range", "torchvision.transforms.Compose", "iter", "open", "torch.load", "torch.load", "VectorQuantizedVAE().to.load_state_dict", "torch.tensor().cuda", "torch.tensor().cuda", "VectorQuantizedVAE().to.decode", "torchvision.utils.make_grid", "tensorboardX.SummaryWriter.add_image", "torchvision.datasets.MNIST", "torchvision.datasets.MNIST", "torchvision.transforms.Compose", "datasets.MiniImagenet", "datasets.MiniImagenet", "datasets.MiniImagenet", "modules.VectorQuantizedVAE", "modules.GatedPixelCNN", "int", "GatedPixelCNN().to.generate", "model.decode.cpu", "torchvision.transforms.ToTensor", "torchvision.transforms.Normalize", "torchvision.datasets.FashionMNIST", "torchvision.datasets.FashionMNIST", "range", "torch.tensor", "torch.tensor", "torchvision.datasets.CIFAR10", "torchvision.datasets.CIFAR10", "torchvision.transforms.RandomResizedCrop", "torchvision.transforms.ToTensor", "torchvision.transforms.Normalize"], "function", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.utils.eval", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.iterators.EpochBatchIterator.load_state_dict", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.iterators.EpochBatchIterator.load_state_dict", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq._hub_utils.TokenizerHubInterface.decode", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.sequence_generator.SequenceGenerator.generate"], ["", "def", "main", "(", "args", ")", ":", "\n", "    ", "writer", "=", "SummaryWriter", "(", "'./logs/{0}'", ".", "format", "(", "args", ".", "output_folder", ")", ")", "\n", "save_filename", "=", "'./models/{0}/prior.pt'", ".", "format", "(", "args", ".", "output_folder", ")", "\n", "\n", "if", "args", ".", "dataset", "in", "[", "'mnist'", ",", "'fashion-mnist'", ",", "'cifar10'", "]", ":", "\n", "        ", "transform", "=", "transforms", ".", "Compose", "(", "[", "\n", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "transforms", ".", "Normalize", "(", "(", "0.1307", ",", ")", ",", "(", "0.3081", ",", ")", ")", "\n", "]", ")", "\n", "if", "args", ".", "dataset", "==", "'mnist'", ":", "\n", "# Define the train & test datasets", "\n", "            ", "train_dataset", "=", "datasets", ".", "MNIST", "(", "args", ".", "data_folder", ",", "train", "=", "True", ",", "\n", "download", "=", "True", ",", "transform", "=", "transform", ")", "\n", "test_dataset", "=", "datasets", ".", "MNIST", "(", "args", ".", "data_folder", ",", "train", "=", "False", ",", "\n", "transform", "=", "transform", ")", "\n", "num_channels", "=", "1", "\n", "", "elif", "args", ".", "dataset", "==", "'fashion-mnist'", ":", "\n", "# Define the train & test datasets", "\n", "            ", "train_dataset", "=", "datasets", ".", "FashionMNIST", "(", "args", ".", "data_folder", ",", "\n", "train", "=", "True", ",", "download", "=", "True", ",", "transform", "=", "transform", ")", "\n", "test_dataset", "=", "datasets", ".", "FashionMNIST", "(", "args", ".", "data_folder", ",", "\n", "train", "=", "False", ",", "transform", "=", "transform", ")", "\n", "num_channels", "=", "1", "\n", "", "elif", "args", ".", "dataset", "==", "'cifar10'", ":", "\n", "# Define the train & test datasets", "\n", "            ", "train_dataset", "=", "datasets", ".", "CIFAR10", "(", "args", ".", "data_folder", ",", "\n", "train", "=", "True", ",", "download", "=", "True", ",", "transform", "=", "transform", ")", "\n", "test_dataset", "=", "datasets", ".", "CIFAR10", "(", "args", ".", "data_folder", ",", "\n", "train", "=", "False", ",", "transform", "=", "transform", ")", "\n", "num_channels", "=", "3", "\n", "", "valid_dataset", "=", "test_dataset", "\n", "", "elif", "args", ".", "dataset", "==", "'miniimagenet'", ":", "\n", "        ", "transform", "=", "transforms", ".", "Compose", "(", "[", "\n", "transforms", ".", "RandomResizedCrop", "(", "128", ")", ",", "\n", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "transforms", ".", "Normalize", "(", "(", "0.5", ",", "0.5", ",", "0.5", ")", ",", "(", "0.5", ",", "0.5", ",", "0.5", ")", ")", "\n", "]", ")", "\n", "# Define the train, valid & test datasets", "\n", "train_dataset", "=", "MiniImagenet", "(", "args", ".", "data_folder", ",", "train", "=", "True", ",", "\n", "download", "=", "True", ",", "transform", "=", "transform", ")", "\n", "valid_dataset", "=", "MiniImagenet", "(", "args", ".", "data_folder", ",", "valid", "=", "True", ",", "\n", "download", "=", "True", ",", "transform", "=", "transform", ")", "\n", "test_dataset", "=", "MiniImagenet", "(", "args", ".", "data_folder", ",", "test", "=", "True", ",", "\n", "download", "=", "True", ",", "transform", "=", "transform", ")", "\n", "num_channels", "=", "3", "\n", "\n", "# Define the data loaders", "\n", "", "train_loader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "train_dataset", ",", "\n", "batch_size", "=", "args", ".", "batch_size", ",", "shuffle", "=", "False", ",", "\n", "num_workers", "=", "args", ".", "num_workers", ",", "pin_memory", "=", "True", ")", "\n", "valid_loader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "valid_dataset", ",", "\n", "batch_size", "=", "args", ".", "batch_size", ",", "shuffle", "=", "False", ",", "drop_last", "=", "True", ",", "\n", "num_workers", "=", "args", ".", "num_workers", ",", "pin_memory", "=", "True", ")", "\n", "test_loader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "test_dataset", ",", "\n", "batch_size", "=", "16", ",", "shuffle", "=", "True", ")", "\n", "\n", "# Save the label encoder", "\n", "# with open('./models/{0}/labels.json'.format(args.output_folder), 'w') as f:", "\n", "#     json.dump(train_dataset._label_encoder, f)", "\n", "\n", "# Fixed images for Tensorboard", "\n", "fixed_images", ",", "_", "=", "next", "(", "iter", "(", "test_loader", ")", ")", "\n", "fixed_grid", "=", "make_grid", "(", "fixed_images", ",", "nrow", "=", "8", ",", "range", "=", "(", "-", "1", ",", "1", ")", ",", "normalize", "=", "True", ")", "\n", "writer", ".", "add_image", "(", "'original'", ",", "fixed_grid", ",", "0", ")", "\n", "\n", "model", "=", "VectorQuantizedVAE", "(", "num_channels", ",", "args", ".", "hidden_size_vae", ",", "args", ".", "k", ")", ".", "to", "(", "args", ".", "device", ")", "\n", "with", "open", "(", "args", ".", "model", ",", "'rb'", ")", "as", "f", ":", "\n", "        ", "state_dict", "=", "torch", ".", "load", "(", "f", ")", "\n", "model", ".", "load_state_dict", "(", "state_dict", ")", "\n", "", "model", ".", "eval", "(", ")", "\n", "\n", "prior", "=", "GatedPixelCNN", "(", "args", ".", "k", ",", "args", ".", "hidden_size_prior", ",", "\n", "args", ".", "num_layers", ",", "n_classes", "=", "10", ")", ".", "to", "(", "args", ".", "device", ")", "\n", "state_dict", "=", "torch", ".", "load", "(", "'models/mnist-10-prior/prior.pt'", ")", "\n", "prior", ".", "load_state_dict", "(", "state_dict", ")", "\n", "\n", "# label_ = [int(i%10) for i in range(16)]", "\n", "# label_ = torch.tensor(label_).cuda()", "\n", "# reconstruction = model.decode(prior.generate(label=label_, batch_size=16,sample_index=10))", "\n", "# grid = make_grid(reconstruction.cpu(), nrow=8, range=(-1, 1), normalize=True)", "\n", "# writer.add_image('Partial sampling result', grid, 0)", "\n", "for", "epoch", "in", "range", "(", "args", ".", "num_epochs", ")", ":", "\n", "\n", "        ", "label_", "=", "[", "int", "(", "i", "%", "10", ")", "for", "i", "in", "range", "(", "16", ")", "]", "\n", "label_", "=", "torch", ".", "tensor", "(", "label_", ")", ".", "cuda", "(", ")", "\n", "reconstruction", "=", "model", ".", "decode", "(", "prior", ".", "generate", "(", "label", "=", "label_", ",", "batch_size", "=", "16", ",", "sample_index", "=", "20", ")", ")", "\n", "grid", "=", "make_grid", "(", "reconstruction", ".", "cpu", "(", ")", ",", "nrow", "=", "8", ",", "range", "=", "(", "-", "1", ",", "1", ")", ",", "normalize", "=", "True", ")", "\n", "writer", ".", "add_image", "(", "'Full sampling result'", ",", "grid", ",", "epoch", "+", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.None.setup.NumpyExtension.__init__": [[25, 28], ["setuptools.Extension.__init__"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.dummy_dictionary.DummyDictionary.__init__"], ["def", "__init__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "self", ".", "__include_dirs", "=", "[", "]", "\n", "super", "(", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.None.setup.NumpyExtension.include_dirs": [[34, 37], ["None"], "methods", ["None"], ["", "@", "include_dirs", ".", "setter", "\n", "def", "include_dirs", "(", "self", ",", "dirs", ")", ":", "\n", "        ", "self", ".", "__include_dirs", "=", "dirs", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.None.transfomer_sample.sample": [[5, 12], ["torch.tensor", "transfomer_sample.generate"], "function", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.sequence_generator.SequenceGenerator.generate"], ["def", "sample", "(", "beam", ":", "int", "=", "1", ",", "verbose", ":", "bool", "=", "False", ",", "**", "kwargs", ")", "->", "str", ":", "\n", "# input = self.encode(sentence)", "\n", "\n", "# prior sample", "\n", "    ", "input", "=", "torch", ".", "tensor", "(", "[", "4", "]", ")", "\n", "hypo", "=", "generate", "(", "input", ",", "beam", ",", "verbose", ",", "**", "kwargs", ")", "[", "0", "]", "[", "'tokens'", "]", "\n", "return", "hypo", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.None.transfomer_sample.generate": [[13, 33], ["transfomer_sample.._build_sample", "transfomer_sample..task.inference_step", "transfomer_sample..string", "print"], "function", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq._hub_utils.GeneratorHubInterface._build_sample", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.tasks.integer_sequence_modeling.IntegerSequenceModelingTask.inference_step", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq._hub_utils.GeneratorHubInterface.string", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.progress_bar.tensorboard_log_wrapper.print"], ["", "def", "generate", "(", "self", ",", "tokens", ":", "torch", ".", "LongTensor", ",", "beam", ":", "int", "=", "5", ",", "verbose", ":", "bool", "=", "False", ",", "**", "kwargs", ")", "->", "torch", ".", "LongTensor", ":", "\n", "    ", "sample", "=", "self", ".", "_build_sample", "(", "tokens", ")", "\n", "\n", "# build generator using current args as well as any kwargs", "\n", "# gen_args = copy.copy(self.args)", "\n", "# gen_args.beam = beam", "\n", "# for k, v in kwargs.items():", "\n", "#     setattr(gen_args, k, v)", "\n", "# generator = self.task.build_generator(gen_args)", "\n", "\n", "translations", "=", "self", ".", "task", ".", "inference_step", "(", "generator", ",", "self", ".", "models", ",", "sample", ")", "\n", "\n", "if", "verbose", ":", "\n", "        ", "src_str_with_unk", "=", "self", ".", "string", "(", "tokens", ")", "\n", "print", "(", "'S\\t{}'", ".", "format", "(", "src_str_with_unk", ")", ")", "\n", "\n", "# Process top predictions", "\n", "", "hypos", "=", "translations", "[", "0", "]", "\n", "\n", "return", "hypos", "", "", ""]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.None.functions.VectorQuantization.forward": [[6, 25], ["torch.no_grad", "codebook.size", "inputs.size", "inputs.view", "torch.sum", "torch.sum", "torch.addmm", "torch.min", "indices_flatten.view", "ctx.mark_non_differentiable", "codebook.t"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.fairseq_dataset.FairseqDataset.size", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.fairseq_dataset.FairseqDataset.size"], ["    ", "@", "staticmethod", "\n", "def", "forward", "(", "ctx", ",", "inputs", ",", "codebook", ")", ":", "\n", "        ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "embedding_size", "=", "codebook", ".", "size", "(", "1", ")", "\n", "inputs_size", "=", "inputs", ".", "size", "(", ")", "\n", "inputs_flatten", "=", "inputs", ".", "view", "(", "-", "1", ",", "embedding_size", ")", "\n", "codebook_sqr", "=", "torch", ".", "sum", "(", "codebook", "**", "2", ",", "dim", "=", "1", ")", "\n", "inputs_sqr", "=", "torch", ".", "sum", "(", "inputs_flatten", "**", "2", ",", "dim", "=", "1", ",", "keepdim", "=", "True", ")", "\n", "\n", "# Compute the distances to the codebook", "\n", "distances", "=", "torch", ".", "addmm", "(", "codebook_sqr", "+", "inputs_sqr", ",", "\n", "inputs_flatten", ",", "codebook", ".", "t", "(", ")", ",", "alpha", "=", "-", "2.0", ",", "beta", "=", "1.0", ")", "\n", "\n", "_", ",", "indices_flatten", "=", "torch", ".", "min", "(", "distances", ",", "dim", "=", "1", ")", "\n", "#print(indices_flatten.size(),inputs.size())", "\n", "indices", "=", "indices_flatten", ".", "view", "(", "inputs_size", "[", "0", "]", ",", "inputs_size", "[", "1", "]", ")", "\n", "ctx", ".", "mark_non_differentiable", "(", "indices", ")", "\n", "\n", "return", "indices", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.None.functions.VectorQuantization.backward": [[26, 29], ["RuntimeError"], "methods", ["None"], ["", "", "@", "staticmethod", "\n", "def", "backward", "(", "ctx", ",", "grad_output", ")", ":", "\n", "        ", "raise", "RuntimeError", "(", "'Trying to call `.grad()` on graph containing '", "\n", "'`VectorQuantization`. The function `VectorQuantization` '", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.None.functions.VectorQuantizationStraightThrough.forward": [[35, 46], ["vq", "vq.view", "ctx.save_for_backward", "ctx.mark_non_differentiable", "torch.index_select", "torch.index_select.view_as"], "methods", ["None"], ["    ", "@", "staticmethod", "\n", "def", "forward", "(", "ctx", ",", "inputs", ",", "codebook", ")", ":", "\n", "        ", "indices", "=", "vq", "(", "inputs", ",", "codebook", ")", "\n", "indices_flatten", "=", "indices", ".", "view", "(", "-", "1", ")", "\n", "ctx", ".", "save_for_backward", "(", "indices_flatten", ",", "codebook", ")", "\n", "ctx", ".", "mark_non_differentiable", "(", "indices_flatten", ")", "\n", "\n", "codes_flatten", "=", "torch", ".", "index_select", "(", "codebook", ",", "dim", "=", "0", ",", "index", "=", "indices_flatten", ")", "\n", "codes", "=", "codes_flatten", ".", "view_as", "(", "inputs", ")", "\n", "\n", "return", "codes", ",", "indices_flatten", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.None.functions.VectorQuantizationStraightThrough.backward": [[47, 65], ["grad_output.clone", "codebook.size", "grad_output.contiguous().view", "torch.zeros_like", "torch.zeros_like.index_add_", "grad_output.contiguous"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.fairseq_dataset.FairseqDataset.size"], ["", "@", "staticmethod", "\n", "def", "backward", "(", "ctx", ",", "grad_output", ",", "grad_indices", ")", ":", "\n", "        ", "grad_inputs", ",", "grad_codebook", "=", "None", ",", "None", "\n", "\n", "if", "ctx", ".", "needs_input_grad", "[", "0", "]", ":", "\n", "# Straight-through estimator", "\n", "            ", "grad_inputs", "=", "grad_output", ".", "clone", "(", ")", "\n", "", "if", "ctx", ".", "needs_input_grad", "[", "1", "]", ":", "\n", "# Gradient wrt. the codebook", "\n", "            ", "indices", ",", "codebook", "=", "ctx", ".", "saved_tensors", "\n", "embedding_size", "=", "codebook", ".", "size", "(", "1", ")", "\n", "\n", "grad_output_flatten", "=", "(", "grad_output", ".", "contiguous", "(", ")", "\n", ".", "view", "(", "-", "1", ",", "embedding_size", ")", ")", "\n", "grad_codebook", "=", "torch", ".", "zeros_like", "(", "codebook", ")", "\n", "grad_codebook", ".", "index_add_", "(", "0", ",", "indices", ",", "grad_output_flatten", ")", "\n", "\n", "", "return", "(", "grad_inputs", ",", "grad_codebook", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.None.functions.VectorQuantizationStraightThroughWithIndices.forward": [[68, 79], ["vq", "vq.view", "ctx.save_for_backward", "ctx.mark_non_differentiable", "torch.index_select", "torch.index_select.view_as"], "methods", ["None"], ["    ", "@", "staticmethod", "\n", "def", "forward", "(", "ctx", ",", "inputs", ",", "codebook", ")", ":", "\n", "        ", "indices", "=", "vq", "(", "inputs", ",", "codebook", ")", "\n", "indices_flatten", "=", "indices", ".", "view", "(", "-", "1", ")", "\n", "ctx", ".", "save_for_backward", "(", "indices_flatten", ",", "codebook", ")", "\n", "ctx", ".", "mark_non_differentiable", "(", "indices_flatten", ")", "\n", "\n", "codes_flatten", "=", "torch", ".", "index_select", "(", "codebook", ",", "dim", "=", "0", ",", "index", "=", "indices_flatten", ")", "\n", "codes", "=", "codes_flatten", ".", "view_as", "(", "inputs", ")", "\n", "\n", "return", "codes", ",", "indices_flatten", ",", "indices", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.None.functions.VectorQuantizationStraightThroughWithIndices.backward": [[80, 83], ["NotImplementedError"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "backward", "(", "ctx", ",", "grad_output", ",", "grad_indices", ")", ":", "\n", "        ", "return", "NotImplementedError", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.None.functions.VectorQuantization_Ori.forward": [[85, 103], ["torch.no_grad", "codebook.size", "inputs.size", "inputs.view", "torch.sum", "torch.sum", "torch.addmm", "torch.min", "indices_flatten.view", "ctx.mark_non_differentiable", "codebook.t"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.fairseq_dataset.FairseqDataset.size", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.fairseq_dataset.FairseqDataset.size"], ["    ", "@", "staticmethod", "\n", "def", "forward", "(", "ctx", ",", "inputs", ",", "codebook", ")", ":", "\n", "        ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "embedding_size", "=", "codebook", ".", "size", "(", "1", ")", "\n", "inputs_size", "=", "inputs", ".", "size", "(", ")", "\n", "inputs_flatten", "=", "inputs", ".", "view", "(", "-", "1", ",", "embedding_size", ")", "\n", "codebook_sqr", "=", "torch", ".", "sum", "(", "codebook", "**", "2", ",", "dim", "=", "1", ")", "\n", "inputs_sqr", "=", "torch", ".", "sum", "(", "inputs_flatten", "**", "2", ",", "dim", "=", "1", ",", "keepdim", "=", "True", ")", "\n", "\n", "# Compute the distances to the codebook", "\n", "distances", "=", "torch", ".", "addmm", "(", "codebook_sqr", "+", "inputs_sqr", ",", "\n", "inputs_flatten", ",", "codebook", ".", "t", "(", ")", ",", "alpha", "=", "-", "2.0", ",", "beta", "=", "1.0", ")", "\n", "\n", "_", ",", "indices_flatten", "=", "torch", ".", "min", "(", "distances", ",", "dim", "=", "1", ")", "\n", "indices", "=", "indices_flatten", ".", "view", "(", "*", "inputs_size", "[", ":", "-", "1", "]", ")", "\n", "ctx", ".", "mark_non_differentiable", "(", "indices", ")", "\n", "\n", "return", "indices", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.None.functions.VectorQuantization_Ori.backward": [[104, 107], ["RuntimeError"], "methods", ["None"], ["", "", "@", "staticmethod", "\n", "def", "backward", "(", "ctx", ",", "grad_output", ")", ":", "\n", "        ", "raise", "RuntimeError", "(", "'Trying to call `.grad()` on graph containing '", "\n", "'`VectorQuantization`. The function `VectorQuantization` '", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.None.functions.VectorQuantizationStraightThrough_Ori.forward": [[112, 123], ["vq_ori", "vq_ori.view", "ctx.save_for_backward", "ctx.mark_non_differentiable", "torch.index_select", "torch.index_select.view_as"], "methods", ["None"], ["    ", "@", "staticmethod", "\n", "def", "forward", "(", "ctx", ",", "inputs", ",", "codebook", ")", ":", "\n", "        ", "indices", "=", "vq_ori", "(", "inputs", ",", "codebook", ")", "\n", "indices_flatten", "=", "indices", ".", "view", "(", "-", "1", ")", "\n", "ctx", ".", "save_for_backward", "(", "indices_flatten", ",", "codebook", ")", "\n", "ctx", ".", "mark_non_differentiable", "(", "indices_flatten", ")", "\n", "\n", "codes_flatten", "=", "torch", ".", "index_select", "(", "codebook", ",", "dim", "=", "0", ",", "\n", "index", "=", "indices_flatten", ")", "\n", "codes", "=", "codes_flatten", ".", "view_as", "(", "inputs", ")", "\n", "return", "(", "codes", ",", "indices_flatten", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.None.functions.VectorQuantizationStraightThrough_Ori.backward": [[124, 142], ["grad_output.clone", "codebook.size", "grad_output.contiguous().view", "torch.zeros_like", "torch.zeros_like.index_add_", "grad_output.contiguous"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.fairseq_dataset.FairseqDataset.size"], ["", "@", "staticmethod", "\n", "def", "backward", "(", "ctx", ",", "grad_output", ",", "grad_indices", ")", ":", "\n", "        ", "grad_inputs", ",", "grad_codebook", "=", "None", ",", "None", "\n", "\n", "if", "ctx", ".", "needs_input_grad", "[", "0", "]", ":", "\n", "# Straight-through estimator", "\n", "            ", "grad_inputs", "=", "grad_output", ".", "clone", "(", ")", "\n", "", "if", "ctx", ".", "needs_input_grad", "[", "1", "]", ":", "\n", "# Gradient wrt. the codebook", "\n", "            ", "indices", ",", "codebook", "=", "ctx", ".", "saved_tensors", "\n", "embedding_size", "=", "codebook", ".", "size", "(", "1", ")", "\n", "\n", "grad_output_flatten", "=", "(", "grad_output", ".", "contiguous", "(", ")", "\n", ".", "view", "(", "-", "1", ",", "embedding_size", ")", ")", "\n", "grad_codebook", "=", "torch", ".", "zeros_like", "(", "codebook", ")", "\n", "grad_codebook", ".", "index_add_", "(", "0", ",", "indices", ",", "grad_output_flatten", ")", "\n", "\n", "", "return", "(", "grad_inputs", ",", "grad_codebook", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.None.functions.VectorQuantizationStraightThroughWithIndices_Ori.forward": [[144, 155], ["vq_ori", "vq_ori.view", "ctx.save_for_backward", "ctx.mark_non_differentiable", "torch.index_select", "torch.index_select.view_as"], "methods", ["None"], ["    ", "@", "staticmethod", "\n", "def", "forward", "(", "ctx", ",", "inputs", ",", "codebook", ")", ":", "\n", "        ", "indices", "=", "vq_ori", "(", "inputs", ",", "codebook", ")", "\n", "indices_flatten", "=", "indices", ".", "view", "(", "-", "1", ")", "\n", "ctx", ".", "save_for_backward", "(", "indices_flatten", ",", "codebook", ")", "\n", "ctx", ".", "mark_non_differentiable", "(", "indices_flatten", ")", "\n", "\n", "codes_flatten", "=", "torch", ".", "index_select", "(", "codebook", ",", "dim", "=", "0", ",", "\n", "index", "=", "indices_flatten", ")", "\n", "codes", "=", "codes_flatten", ".", "view_as", "(", "inputs", ")", "\n", "return", "(", "codes", ",", "indices_flatten", ",", "indices", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.None.functions.VectorQuantizationStraightThroughWithIndices_Ori.backward": [[156, 174], ["grad_output.clone", "codebook.size", "grad_output.contiguous().view", "torch.zeros_like", "torch.zeros_like.index_add_", "grad_output.contiguous"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.fairseq_dataset.FairseqDataset.size"], ["", "@", "staticmethod", "\n", "def", "backward", "(", "ctx", ",", "grad_output", ",", "grad_indices", ")", ":", "\n", "        ", "grad_inputs", ",", "grad_codebook", "=", "None", ",", "None", "\n", "\n", "if", "ctx", ".", "needs_input_grad", "[", "0", "]", ":", "\n", "# Straight-through estimator", "\n", "            ", "grad_inputs", "=", "grad_output", ".", "clone", "(", ")", "\n", "", "if", "ctx", ".", "needs_input_grad", "[", "1", "]", ":", "\n", "# Gradient wrt. the codebook", "\n", "            ", "indices", ",", "codebook", "=", "ctx", ".", "saved_tensors", "\n", "embedding_size", "=", "codebook", ".", "size", "(", "1", ")", "\n", "\n", "grad_output_flatten", "=", "(", "grad_output", ".", "contiguous", "(", ")", "\n", ".", "view", "(", "-", "1", ",", "embedding_size", ")", ")", "\n", "grad_codebook", "=", "torch", ".", "zeros_like", "(", "codebook", ")", "\n", "grad_codebook", ".", "index_add_", "(", "0", ",", "indices", ",", "grad_output_flatten", ")", "\n", "\n", "", "return", "(", "grad_inputs", ",", "grad_codebook", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.None.transformer_lm.TransformerLanguageModel.hub_models": [[23, 39], ["transformer_lm.TransformerLanguageModel.hub_models.moses_fastbpe"], "methods", ["None"], ["    ", "@", "classmethod", "\n", "def", "hub_models", "(", "cls", ")", ":", "\n", "\n", "        ", "def", "moses_fastbpe", "(", "path", ")", ":", "\n", "            ", "return", "{", "\n", "'path'", ":", "path", ",", "\n", "'tokenizer'", ":", "'moses'", ",", "\n", "'bpe'", ":", "'fastbpe'", ",", "\n", "}", "\n", "\n", "", "return", "{", "\n", "'transformer_lm.gbw.adaptive_huge'", ":", "'https://dl.fbaipublicfiles.com/fairseq/models/lm/adaptive_lm_gbw_huge.tar.bz2'", ",", "\n", "'transformer_lm.wiki103.adaptive'", ":", "'https://dl.fbaipublicfiles.com/fairseq/models/lm/adaptive_lm_wiki103.tar.bz2'", ",", "\n", "'transformer_lm.wmt19.en'", ":", "moses_fastbpe", "(", "'https://dl.fbaipublicfiles.com/fairseq/models/lm/wmt19.en.tar.bz2'", ")", ",", "\n", "'transformer_lm.wmt19.de'", ":", "moses_fastbpe", "(", "'https://dl.fbaipublicfiles.com/fairseq/models/lm/wmt19.de.tar.bz2'", ")", ",", "\n", "'transformer_lm.wmt19.ru'", ":", "moses_fastbpe", "(", "'https://dl.fbaipublicfiles.com/fairseq/models/lm/wmt19.ru.tar.bz2'", ")", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.None.transformer_lm.TransformerLanguageModel.__init__": [[41, 43], ["fairseq.models.FairseqLanguageModel.__init__"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.dummy_dictionary.DummyDictionary.__init__"], ["", "def", "__init__", "(", "self", ",", "decoder", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "decoder", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.None.transformer_lm.TransformerLanguageModel.add_args": [[44, 79], ["parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "fairseq.utils.get_available_activation_fns"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.utils.get_available_activation_fns"], ["", "@", "staticmethod", "\n", "def", "add_args", "(", "parser", ")", ":", "\n", "        ", "\"\"\"Add model-specific arguments to the parser.\"\"\"", "\n", "# fmt: off", "\n", "parser", ".", "add_argument", "(", "'--activation-fn'", ",", "\n", "choices", "=", "utils", ".", "get_available_activation_fns", "(", ")", ",", "\n", "help", "=", "'activation function to use'", ")", "\n", "parser", ".", "add_argument", "(", "'--dropout'", ",", "type", "=", "float", ",", "metavar", "=", "'D'", ",", "\n", "help", "=", "'dropout probability'", ")", "\n", "parser", ".", "add_argument", "(", "'--attention-dropout'", ",", "type", "=", "float", ",", "metavar", "=", "'D'", ",", "\n", "help", "=", "'dropout probability for attention weights'", ")", "\n", "parser", ".", "add_argument", "(", "'--activation-dropout'", ",", "'--relu-dropout'", ",", "type", "=", "float", ",", "metavar", "=", "'D'", ",", "\n", "help", "=", "'dropout probability after activation in FFN.'", ")", "\n", "parser", ".", "add_argument", "(", "'--decoder-embed-dim'", ",", "type", "=", "int", ",", "metavar", "=", "'N'", ",", "\n", "help", "=", "'decoder embedding dimension'", ")", "\n", "parser", ".", "add_argument", "(", "'--decoder-output-dim'", ",", "type", "=", "int", ",", "metavar", "=", "'N'", ",", "\n", "help", "=", "'decoder output dimension'", ")", "\n", "parser", ".", "add_argument", "(", "'--decoder-input-dim'", ",", "type", "=", "int", ",", "metavar", "=", "'N'", ",", "\n", "help", "=", "'decoder input dimension'", ")", "\n", "parser", ".", "add_argument", "(", "'--decoder-ffn-embed-dim'", ",", "type", "=", "int", ",", "metavar", "=", "'N'", ",", "\n", "help", "=", "'decoder embedding dimension for FFN'", ")", "\n", "parser", ".", "add_argument", "(", "'--decoder-layers'", ",", "type", "=", "int", ",", "metavar", "=", "'N'", ",", "\n", "help", "=", "'num decoder layers'", ")", "\n", "parser", ".", "add_argument", "(", "'--decoder-attention-heads'", ",", "type", "=", "int", ",", "metavar", "=", "'N'", ",", "\n", "help", "=", "'num decoder attention heads'", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--no-decoder-final-norm'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "'don\\'t add an extra layernorm after the last decoder block'", ")", "\n", "parser", ".", "add_argument", "(", "'--share-decoder-input-output-embed'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "'share decoder input and output embeddings'", ")", "\n", "parser", ".", "add_argument", "(", "'--decoder-learned-pos'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "'use learned positional embeddings in the decoder'", ")", "\n", "# args for \"Reducing Transformer Depth on Demand with Structured Dropout\" (Fan et al., 2019)", "\n", "parser", ".", "add_argument", "(", "'--layernorm-embedding'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "'add layernorm to embedding'", ")", "\n", "# fmt: on", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.None.transformer_lm.TransformerLanguageModel.build_model": [[81, 92], ["transformer_lm.base_lm_architecture", "fairseq.models.transformer.Embedding", "fairseq.models.transformer.TransformerDecoder", "transformer_lm.TransformerLanguageModel"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.transformer_lm.base_lm_architecture", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.transformer.Embedding"], ["", "@", "classmethod", "\n", "def", "build_model", "(", "cls", ",", "args", ",", "vocab_size", ")", ":", "\n", "        ", "\"\"\"Build a new model instance.\"\"\"", "\n", "\n", "# make sure all arguments are present in older models", "\n", "base_lm_architecture", "(", "args", ")", "\n", "embed_tokens", "=", "Embedding", "(", "vocab_size", ",", "args", ".", "decoder_input_dim", ")", "\n", "decoder", "=", "TransformerDecoder", "(", "\n", "args", ",", "None", ",", "embed_tokens", ",", "no_encoder_attn", "=", "True", ",", "\n", ")", "\n", "return", "TransformerLanguageModel", "(", "decoder", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.None.transformer_lm.base_lm_architecture": [[94, 121], ["hasattr"], "function", ["None"], ["", "", "def", "base_lm_architecture", "(", "args", ")", ":", "\n", "# backward compatibility for older model checkpoints", "\n", "    ", "if", "hasattr", "(", "args", ",", "'decoder_final_norm'", ")", ":", "\n", "        ", "args", ".", "no_decoder_final_norm", "=", "not", "args", ".", "decoder_final_norm", "\n", "\n", "", "args", ".", "dropout", "=", "0.1", "\n", "args", ".", "attention_dropout", "=", "0.0", "\n", "args", ".", "activation_dropout", "=", "0.0", "\n", "args", ".", "decoder_embed_dim", "=", "512", "\n", "args", ".", "decoder_ffn_embed_dim", "=", "2048", "\n", "args", ".", "decoder_layers", "=", "6", "\n", "args", ".", "decoder_attention_heads", "=", "8", "\n", "args", ".", "decoder_learned_pos", "=", "False", "\n", "args", ".", "activation_fn", "=", "'relu'", "\n", "\n", "args", ".", "add_bos_token", "=", "False", "\n", "args", ".", "no_token_positional_embeddings", "=", "False", "\n", "args", ".", "share_decoder_input_output_embed", "=", "True", "\n", "args", ".", "decoder_output_dim", "=", "512", "\n", "args", ".", "decoder_input_dim", "=", "512", "\n", "\n", "# Model training is not stable without this", "\n", "args", ".", "decoder_normalize_before", "=", "True", "\n", "args", ".", "no_decoder_final_norm", "=", "False", "\n", "args", ".", "no_scale_embedding", "=", "False", "\n", "args", ".", "layernorm_embedding", "=", "False", "\n", "args", ".", "max_target_positions", "=", "100", "\n", "", ""]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.None.train_ar.main": [[26, 108], ["fairseq.utils.import_user_module", "numpy.random.seed", "torch.manual_seed", "fairseq.distributed_utils.is_master", "print", "fairseq.tasks.setup_task", "args.valid_subset.split", "tasks.setup_task.build_model", "tasks.setup_task.build_criterion", "print", "print", "print", "fairseq.trainer.Trainer", "print", "print", "fairseq.checkpoint_utils.load_checkpoint", "fairseq.trainer.Trainer.get_lr", "fairseq.meters.StopwatchMeter", "fairseq.meters.StopwatchMeter.start", "args.valid_subset.split", "fairseq.meters.StopwatchMeter.stop", "print", "torch.cuda.is_available", "torch.cuda.set_device", "fairseq.distributed_utils.distributed_init", "fairseq.checkpoint_utils.verify_checkpoint_directory", "tasks.setup_task.load_dataset", "train_ar.train", "fairseq.trainer.Trainer.lr_step", "fairseq.trainer.Trainer.get_train_iterator", "sum", "sum", "fairseq.trainer.Trainer.get_num_updates", "train_ar.validate", "fairseq.checkpoint_utils.save_checkpoint", "getattr", "p.numel", "p.numel", "task.build_model.parameters", "task.build_model.parameters"], "function", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.utils.import_user_module", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.distributed_utils.is_master", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.progress_bar.tensorboard_log_wrapper.print", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.tasks.integer_sequence_modeling.IntegerSequenceModelingTask.setup_task", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.tasks.integer_sequence_modeling.IntegerSequenceModelingTask.build_model", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.criterions.fairseq_criterion.FairseqCriterion.build_criterion", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.progress_bar.tensorboard_log_wrapper.print", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.progress_bar.tensorboard_log_wrapper.print", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.progress_bar.tensorboard_log_wrapper.print", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.progress_bar.tensorboard_log_wrapper.print", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.progress_bar.tensorboard_log_wrapper.print", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.checkpoint_utils.load_checkpoint", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.optim.fp16_optimizer.MemoryEfficientFP16Optimizer.get_lr", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.meters.StopwatchMeter.start", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.meters.StopwatchMeter.stop", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.progress_bar.tensorboard_log_wrapper.print", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.distributed_utils.distributed_init", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.checkpoint_utils.verify_checkpoint_directory", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.tasks.integer_sequence_modeling.IntegerSequenceModelingTask.load_dataset", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.None.train_ar.train", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.trainer.Trainer.lr_step", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.trainer.Trainer.get_train_iterator", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.optim.bmuf.FairseqBMUF.get_num_updates", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.None.train_ar.validate", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.checkpoint_utils.save_checkpoint"], ["def", "main", "(", "args", ",", "init_distributed", "=", "False", ")", ":", "\n", "    ", "utils", ".", "import_user_module", "(", "args", ")", "\n", "\n", "assert", "args", ".", "max_tokens", "is", "not", "None", "or", "args", ".", "max_sentences", "is", "not", "None", ",", "'Must specify batch size either with --max-tokens or --max-sentences'", "\n", "\n", "# Initialize CUDA and distributed training", "\n", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "and", "not", "args", ".", "cpu", ":", "\n", "        ", "torch", ".", "cuda", ".", "set_device", "(", "args", ".", "device_id", ")", "\n", "", "np", ".", "random", ".", "seed", "(", "args", ".", "seed", ")", "\n", "torch", ".", "manual_seed", "(", "args", ".", "seed", ")", "\n", "if", "init_distributed", ":", "\n", "        ", "args", ".", "distributed_rank", "=", "distributed_utils", ".", "distributed_init", "(", "args", ")", "\n", "\n", "", "if", "distributed_utils", ".", "is_master", "(", "args", ")", ":", "\n", "        ", "checkpoint_utils", ".", "verify_checkpoint_directory", "(", "args", ".", "save_dir", ")", "\n", "\n", "# Print args", "\n", "", "print", "(", "args", ")", "\n", "\n", "# Setup task, e.g., translation, language modeling, etc.", "\n", "task", "=", "tasks", ".", "setup_task", "(", "args", ")", "\n", "\n", "# Load valid dataset (we load training data below, based on the latest checkpoint)", "\n", "for", "valid_sub_split", "in", "args", ".", "valid_subset", ".", "split", "(", "','", ")", ":", "\n", "        ", "task", ".", "load_dataset", "(", "valid_sub_split", ",", "combine", "=", "False", ",", "epoch", "=", "0", ")", "\n", "\n", "# Build model and criterion", "\n", "", "model", "=", "task", ".", "build_model", "(", "args", ")", "\n", "criterion", "=", "task", ".", "build_criterion", "(", "args", ")", "\n", "print", "(", "model", ")", "\n", "print", "(", "'| model {}, criterion {}'", ".", "format", "(", "args", ".", "arch", ",", "criterion", ".", "__class__", ".", "__name__", ")", ")", "\n", "print", "(", "'| num. model params: {} (num. trained: {})'", ".", "format", "(", "\n", "sum", "(", "p", ".", "numel", "(", ")", "for", "p", "in", "model", ".", "parameters", "(", ")", ")", ",", "\n", "sum", "(", "p", ".", "numel", "(", ")", "for", "p", "in", "model", ".", "parameters", "(", ")", "if", "p", ".", "requires_grad", ")", ",", "\n", ")", ")", "\n", "\n", "# Build trainer", "\n", "trainer", "=", "Trainer", "(", "args", ",", "task", ",", "model", ",", "criterion", ")", "\n", "print", "(", "'| training on {} GPUs'", ".", "format", "(", "args", ".", "distributed_world_size", ")", ")", "\n", "print", "(", "'| max tokens per GPU = {} and max sentences per GPU = {}'", ".", "format", "(", "\n", "args", ".", "max_tokens", ",", "\n", "args", ".", "max_sentences", ",", "\n", ")", ")", "\n", "\n", "# Load the latest checkpoint if one is available and restore the", "\n", "# corresponding train iterator", "\n", "extra_state", ",", "epoch_itr", "=", "checkpoint_utils", ".", "load_checkpoint", "(", "args", ",", "trainer", ")", "\n", "\n", "# Train until the learning rate gets too small", "\n", "max_epoch", "=", "args", ".", "max_epoch", "or", "math", ".", "inf", "\n", "max_update", "=", "args", ".", "max_update", "or", "math", ".", "inf", "\n", "lr", "=", "trainer", ".", "get_lr", "(", ")", "\n", "train_meter", "=", "StopwatchMeter", "(", ")", "\n", "train_meter", ".", "start", "(", ")", "\n", "valid_subsets", "=", "args", ".", "valid_subset", ".", "split", "(", "','", ")", "\n", "while", "(", "\n", "lr", ">", "args", ".", "min_lr", "\n", "and", "(", "epoch_itr", ".", "epoch", "<", "max_epoch", "or", "(", "epoch_itr", ".", "epoch", "==", "max_epoch", "\n", "and", "epoch_itr", ".", "_next_epoch_itr", "is", "not", "None", ")", ")", "\n", "and", "trainer", ".", "get_num_updates", "(", ")", "<", "max_update", "\n", ")", ":", "\n", "# train for one epoch", "\n", "        ", "train", "(", "args", ",", "trainer", ",", "task", ",", "epoch_itr", ")", "\n", "\n", "if", "not", "args", ".", "disable_validation", "and", "epoch_itr", ".", "epoch", "%", "args", ".", "validate_interval", "==", "0", ":", "\n", "            ", "valid_losses", "=", "validate", "(", "args", ",", "trainer", ",", "task", ",", "epoch_itr", ",", "valid_subsets", ")", "\n", "", "else", ":", "\n", "            ", "valid_losses", "=", "[", "None", "]", "\n", "\n", "# only use first validation loss to update the learning rate", "\n", "", "lr", "=", "trainer", ".", "lr_step", "(", "epoch_itr", ".", "epoch", ",", "valid_losses", "[", "0", "]", ")", "\n", "\n", "# save checkpoint", "\n", "if", "epoch_itr", ".", "epoch", "%", "args", ".", "save_interval", "==", "0", ":", "\n", "            ", "checkpoint_utils", ".", "save_checkpoint", "(", "args", ",", "trainer", ",", "epoch_itr", ",", "valid_losses", "[", "0", "]", ")", "\n", "\n", "", "reload_dataset", "=", "':'", "in", "getattr", "(", "args", ",", "'data'", ",", "''", ")", "\n", "# sharded data: get train iterator for next epoch", "\n", "epoch_itr", "=", "trainer", ".", "get_train_iterator", "(", "epoch_itr", ".", "epoch", ",", "load_dataset", "=", "reload_dataset", ")", "\n", "", "train_meter", ".", "stop", "(", ")", "\n", "print", "(", "'| done training in {:.1f} seconds'", ".", "format", "(", "train_meter", ".", "sum", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.None.train_ar.train": [[110, 177], ["epoch_itr.next_epoch_itr", "fairseq.data.iterators.GroupedIterator", "fairseq.progress_bar.build_progress_bar", "collections.defaultdict", "args.valid_subset.split", "enumerate", "train_ar.get_training_stats", "collections.defaultdict.items", "progress_bar.build_progress_bar.print", "trainer.train_step", "train_ar.get_training_stats", "trainer.train_step.items", "progress_bar.build_progress_bar.log", "trainer.get_num_updates", "trainer.get_meter", "len", "fairseq.meters.AverageMeter", "trainer.get_meter().reset", "trainer.get_meter().reset", "train_ar.validate", "fairseq.checkpoint_utils.save_checkpoint", "trainer.get_meter.reset", "extra_meters[].update", "extra_meters[].update", "trainer.get_meter", "trainer.get_meter"], "function", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.iterators.EpochBatchIterator.next_epoch_itr", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.progress_bar.build_progress_bar", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.None.train_ar.get_training_stats", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.progress_bar.tensorboard_log_wrapper.print", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.tasks.fairseq_task.FairseqTask.train_step", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.None.train_ar.get_training_stats", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.progress_bar.tensorboard_log_wrapper.log", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.optim.bmuf.FairseqBMUF.get_num_updates", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.trainer.Trainer.get_meter", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.meters.StopwatchMeter.reset", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.meters.StopwatchMeter.reset", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.None.train_ar.validate", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.checkpoint_utils.save_checkpoint", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.meters.StopwatchMeter.reset", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.meters.TimeMeter.update", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.meters.TimeMeter.update", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.trainer.Trainer.get_meter", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.trainer.Trainer.get_meter"], ["", "def", "train", "(", "args", ",", "trainer", ",", "task", ",", "epoch_itr", ")", ":", "\n", "    ", "\"\"\"Train the model for one epoch.\"\"\"", "\n", "# Update parameters every N batches", "\n", "update_freq", "=", "args", ".", "update_freq", "[", "epoch_itr", ".", "epoch", "-", "1", "]", "if", "epoch_itr", ".", "epoch", "<=", "len", "(", "args", ".", "update_freq", ")", "else", "args", ".", "update_freq", "[", "-", "1", "]", "\n", "\n", "# Initialize data iterator", "\n", "itr", "=", "epoch_itr", ".", "next_epoch_itr", "(", "\n", "fix_batches_to_gpus", "=", "args", ".", "fix_batches_to_gpus", ",", "\n", "shuffle", "=", "(", "epoch_itr", ".", "epoch", ">=", "args", ".", "curriculum", ")", ",", "\n", ")", "\n", "itr", "=", "iterators", ".", "GroupedIterator", "(", "itr", ",", "update_freq", ")", "\n", "progress", "=", "progress_bar", ".", "build_progress_bar", "(", "\n", "args", ",", "itr", ",", "epoch_itr", ".", "epoch", ",", "no_progress_bar", "=", "'simple'", ",", "\n", ")", "\n", "\n", "extra_meters", "=", "collections", ".", "defaultdict", "(", "lambda", ":", "AverageMeter", "(", ")", ")", "\n", "valid_subsets", "=", "args", ".", "valid_subset", ".", "split", "(", "','", ")", "\n", "max_update", "=", "args", ".", "max_update", "or", "math", ".", "inf", "\n", "for", "i", ",", "samples", "in", "enumerate", "(", "progress", ",", "start", "=", "epoch_itr", ".", "iterations_in_epoch", ")", ":", "\n", "        ", "log_output", "=", "trainer", ".", "train_step", "(", "samples", ")", "\n", "if", "log_output", "is", "None", ":", "\n", "            ", "continue", "\n", "\n", "# log mid-epoch stats", "\n", "", "stats", "=", "get_training_stats", "(", "trainer", ")", "\n", "for", "k", ",", "v", "in", "log_output", ".", "items", "(", ")", ":", "\n", "            ", "if", "k", "in", "[", "'loss'", ",", "'nll_loss'", ",", "'ntokens'", ",", "'nsentences'", ",", "'sample_size'", "]", ":", "\n", "                ", "continue", "# these are already logged above", "\n", "", "if", "'loss'", "in", "k", "or", "k", "==", "'accuracy'", ":", "\n", "                ", "extra_meters", "[", "k", "]", ".", "update", "(", "v", ",", "log_output", "[", "'sample_size'", "]", ")", "\n", "", "else", ":", "\n", "                ", "extra_meters", "[", "k", "]", ".", "update", "(", "v", ")", "\n", "", "stats", "[", "k", "]", "=", "extra_meters", "[", "k", "]", ".", "avg", "\n", "", "progress", ".", "log", "(", "stats", ",", "tag", "=", "'train'", ",", "step", "=", "stats", "[", "'num_updates'", "]", ")", "\n", "\n", "# ignore the first mini-batch in words-per-second and updates-per-second calculation", "\n", "if", "i", "==", "0", ":", "\n", "            ", "trainer", ".", "get_meter", "(", "'wps'", ")", ".", "reset", "(", ")", "\n", "trainer", ".", "get_meter", "(", "'ups'", ")", ".", "reset", "(", ")", "\n", "\n", "", "num_updates", "=", "trainer", ".", "get_num_updates", "(", ")", "\n", "if", "(", "\n", "not", "args", ".", "disable_validation", "\n", "and", "args", ".", "save_interval_updates", ">", "0", "\n", "and", "num_updates", "%", "args", ".", "save_interval_updates", "==", "0", "\n", "and", "num_updates", ">", "0", "\n", ")", ":", "\n", "            ", "valid_losses", "=", "validate", "(", "args", ",", "trainer", ",", "task", ",", "epoch_itr", ",", "valid_subsets", ")", "\n", "checkpoint_utils", ".", "save_checkpoint", "(", "args", ",", "trainer", ",", "epoch_itr", ",", "valid_losses", "[", "0", "]", ")", "\n", "\n", "", "if", "num_updates", ">=", "max_update", ":", "\n", "            ", "break", "\n", "\n", "# log end-of-epoch stats", "\n", "", "", "stats", "=", "get_training_stats", "(", "trainer", ")", "\n", "for", "k", ",", "meter", "in", "extra_meters", ".", "items", "(", ")", ":", "\n", "        ", "stats", "[", "k", "]", "=", "meter", ".", "avg", "\n", "", "progress", ".", "print", "(", "stats", ",", "tag", "=", "'train'", ",", "step", "=", "stats", "[", "'num_updates'", "]", ")", "\n", "\n", "# reset training meters", "\n", "for", "k", "in", "[", "\n", "'train_loss'", ",", "'train_nll_loss'", ",", "'wps'", ",", "'ups'", ",", "'wpb'", ",", "'bsz'", ",", "'gnorm'", ",", "'clip'", ",", "\n", "]", ":", "\n", "        ", "meter", "=", "trainer", ".", "get_meter", "(", "k", ")", "\n", "if", "meter", "is", "not", "None", ":", "\n", "            ", "meter", ".", "reset", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.None.train_ar.get_training_stats": [[179, 202], ["collections.OrderedDict", "trainer.get_meter", "fairseq.utils.get_perplexity", "trainer.get_meter", "trainer.get_meter", "trainer.get_meter", "trainer.get_meter", "trainer.get_num_updates", "trainer.get_lr", "trainer.get_meter", "trainer.get_meter", "trainer.get_meter", "round", "trainer.get_meter", "trainer.get_meter", "trainer.get_meter", "trainer.get_meter", "trainer.get_meter", "trainer.get_meter", "trainer.get_meter"], "function", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.trainer.Trainer.get_meter", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.utils.get_perplexity", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.trainer.Trainer.get_meter", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.trainer.Trainer.get_meter", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.trainer.Trainer.get_meter", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.trainer.Trainer.get_meter", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.optim.bmuf.FairseqBMUF.get_num_updates", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.optim.fp16_optimizer.MemoryEfficientFP16Optimizer.get_lr", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.trainer.Trainer.get_meter", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.trainer.Trainer.get_meter", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.trainer.Trainer.get_meter", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.trainer.Trainer.get_meter", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.trainer.Trainer.get_meter", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.trainer.Trainer.get_meter", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.trainer.Trainer.get_meter", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.trainer.Trainer.get_meter", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.trainer.Trainer.get_meter", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.trainer.Trainer.get_meter"], ["", "", "", "def", "get_training_stats", "(", "trainer", ")", ":", "\n", "    ", "stats", "=", "collections", ".", "OrderedDict", "(", ")", "\n", "stats", "[", "'loss'", "]", "=", "trainer", ".", "get_meter", "(", "'train_loss'", ")", "\n", "if", "trainer", ".", "get_meter", "(", "'train_nll_loss'", ")", ".", "count", ">", "0", ":", "\n", "        ", "nll_loss", "=", "trainer", ".", "get_meter", "(", "'train_nll_loss'", ")", "\n", "stats", "[", "'nll_loss'", "]", "=", "nll_loss", "\n", "", "else", ":", "\n", "        ", "nll_loss", "=", "trainer", ".", "get_meter", "(", "'train_loss'", ")", "\n", "", "stats", "[", "'ppl'", "]", "=", "utils", ".", "get_perplexity", "(", "nll_loss", ".", "avg", ")", "\n", "stats", "[", "'wps'", "]", "=", "trainer", ".", "get_meter", "(", "'wps'", ")", "\n", "stats", "[", "'ups'", "]", "=", "trainer", ".", "get_meter", "(", "'ups'", ")", "\n", "stats", "[", "'wpb'", "]", "=", "trainer", ".", "get_meter", "(", "'wpb'", ")", "\n", "stats", "[", "'bsz'", "]", "=", "trainer", ".", "get_meter", "(", "'bsz'", ")", "\n", "stats", "[", "'num_updates'", "]", "=", "trainer", ".", "get_num_updates", "(", ")", "\n", "stats", "[", "'lr'", "]", "=", "trainer", ".", "get_lr", "(", ")", "\n", "stats", "[", "'gnorm'", "]", "=", "trainer", ".", "get_meter", "(", "'gnorm'", ")", "\n", "stats", "[", "'clip'", "]", "=", "trainer", ".", "get_meter", "(", "'clip'", ")", "\n", "stats", "[", "'oom'", "]", "=", "trainer", ".", "get_meter", "(", "'oom'", ")", "\n", "if", "trainer", ".", "get_meter", "(", "'loss_scale'", ")", "is", "not", "None", ":", "\n", "        ", "stats", "[", "'loss_scale'", "]", "=", "trainer", ".", "get_meter", "(", "'loss_scale'", ")", "\n", "", "stats", "[", "'wall'", "]", "=", "round", "(", "trainer", ".", "get_meter", "(", "'wall'", ")", ".", "elapsed_time", ")", "\n", "stats", "[", "'train_wall'", "]", "=", "trainer", ".", "get_meter", "(", "'train_wall'", ")", "\n", "return", "stats", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.None.train_ar.validate": [[204, 262], ["fairseq.utils.set_torch_seed", "task.get_batch_iterator().next_epoch_itr", "fairseq.progress_bar.build_progress_bar", "collections.defaultdict", "train_ar.get_valid_stats", "collections.defaultdict.items", "progress_bar.build_progress_bar.print", "valid_losses.append", "trainer.get_meter", "trainer.valid_step", "trainer.valid_step.items", "task.get_batch_iterator", "trainer.get_meter.reset", "fairseq.meters.AverageMeter", "extra_meters[].update", "trainer.get_num_updates", "task.dataset", "fairseq.utils.resolve_max_positions", "task.max_positions", "trainer.get_model().max_positions", "trainer.get_model"], "function", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.utils.set_torch_seed", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.iterators.EpochBatchIterator.next_epoch_itr", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.progress_bar.build_progress_bar", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.None.train_ar.get_valid_stats", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.progress_bar.tensorboard_log_wrapper.print", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.trainer.Trainer.get_meter", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.tasks.fairseq_task.FairseqTask.valid_step", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.tasks.fairseq_task.FairseqTask.get_batch_iterator", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.meters.StopwatchMeter.reset", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.meters.TimeMeter.update", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.optim.bmuf.FairseqBMUF.get_num_updates", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.tasks.fairseq_task.FairseqTask.dataset", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.utils.resolve_max_positions", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.tasks.fairseq_task.FairseqTask.max_positions", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.tasks.fairseq_task.FairseqTask.max_positions", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.trainer.Trainer.get_model"], ["", "def", "validate", "(", "args", ",", "trainer", ",", "task", ",", "epoch_itr", ",", "subsets", ")", ":", "\n", "    ", "\"\"\"Evaluate the model on the validation set(s) and return the losses.\"\"\"", "\n", "\n", "if", "args", ".", "fixed_validation_seed", "is", "not", "None", ":", "\n", "# set fixed seed for every validation", "\n", "        ", "utils", ".", "set_torch_seed", "(", "args", ".", "fixed_validation_seed", ")", "\n", "\n", "", "valid_losses", "=", "[", "]", "\n", "for", "subset", "in", "subsets", ":", "\n", "# Initialize data iterator", "\n", "        ", "itr", "=", "task", ".", "get_batch_iterator", "(", "\n", "dataset", "=", "task", ".", "dataset", "(", "subset", ")", ",", "\n", "max_tokens", "=", "args", ".", "max_tokens_valid", ",", "\n", "max_sentences", "=", "args", ".", "max_sentences_valid", ",", "\n", "max_positions", "=", "utils", ".", "resolve_max_positions", "(", "\n", "task", ".", "max_positions", "(", ")", ",", "\n", "trainer", ".", "get_model", "(", ")", ".", "max_positions", "(", ")", ",", "\n", ")", ",", "\n", "ignore_invalid_inputs", "=", "args", ".", "skip_invalid_size_inputs_valid_test", ",", "\n", "required_batch_size_multiple", "=", "args", ".", "required_batch_size_multiple", ",", "\n", "seed", "=", "args", ".", "seed", ",", "\n", "num_shards", "=", "args", ".", "distributed_world_size", ",", "\n", "shard_id", "=", "args", ".", "distributed_rank", ",", "\n", "num_workers", "=", "args", ".", "num_workers", ",", "\n", ")", ".", "next_epoch_itr", "(", "shuffle", "=", "False", ")", "\n", "progress", "=", "progress_bar", ".", "build_progress_bar", "(", "\n", "args", ",", "itr", ",", "epoch_itr", ".", "epoch", ",", "\n", "prefix", "=", "'valid on \\'{}\\' subset'", ".", "format", "(", "subset", ")", ",", "\n", "no_progress_bar", "=", "'simple'", "\n", ")", "\n", "\n", "# reset validation loss meters", "\n", "for", "k", "in", "[", "'valid_loss'", ",", "'valid_nll_loss'", "]", ":", "\n", "            ", "meter", "=", "trainer", ".", "get_meter", "(", "k", ")", "\n", "if", "meter", "is", "not", "None", ":", "\n", "                ", "meter", ".", "reset", "(", ")", "\n", "", "", "extra_meters", "=", "collections", ".", "defaultdict", "(", "lambda", ":", "AverageMeter", "(", ")", ")", "\n", "\n", "for", "sample", "in", "progress", ":", "\n", "            ", "log_output", "=", "trainer", ".", "valid_step", "(", "sample", ")", "\n", "\n", "for", "k", ",", "v", "in", "log_output", ".", "items", "(", ")", ":", "\n", "                ", "if", "k", "in", "[", "'loss'", ",", "'nll_loss'", ",", "'ntokens'", ",", "'nsentences'", ",", "'sample_size'", "]", ":", "\n", "                    ", "continue", "\n", "", "extra_meters", "[", "k", "]", ".", "update", "(", "v", ")", "\n", "\n", "# log validation stats", "\n", "", "", "stats", "=", "get_valid_stats", "(", "trainer", ",", "args", ",", "extra_meters", ")", "\n", "for", "k", ",", "meter", "in", "extra_meters", ".", "items", "(", ")", ":", "\n", "            ", "stats", "[", "k", "]", "=", "meter", ".", "avg", "\n", "", "progress", ".", "print", "(", "stats", ",", "tag", "=", "subset", ",", "step", "=", "trainer", ".", "get_num_updates", "(", ")", ")", "\n", "\n", "valid_losses", ".", "append", "(", "\n", "stats", "[", "args", ".", "best_checkpoint_metric", "]", ".", "avg", "\n", "if", "args", ".", "best_checkpoint_metric", "==", "'loss'", "\n", "else", "stats", "[", "args", ".", "best_checkpoint_metric", "]", "\n", ")", "\n", "", "return", "valid_losses", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.None.train_ar.get_valid_stats": [[264, 293], ["collections.OrderedDict", "trainer.get_meter", "fairseq.utils.get_perplexity", "trainer.get_num_updates", "hasattr", "trainer.get_meter", "best_function", "trainer.get_meter", "ValueError"], "function", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.trainer.Trainer.get_meter", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.utils.get_perplexity", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.optim.bmuf.FairseqBMUF.get_num_updates", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.trainer.Trainer.get_meter", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.trainer.Trainer.get_meter"], ["", "def", "get_valid_stats", "(", "trainer", ",", "args", ",", "extra_meters", "=", "None", ")", ":", "\n", "    ", "stats", "=", "collections", ".", "OrderedDict", "(", ")", "\n", "stats", "[", "'loss'", "]", "=", "trainer", ".", "get_meter", "(", "'valid_loss'", ")", "\n", "if", "trainer", ".", "get_meter", "(", "'valid_nll_loss'", ")", ".", "count", ">", "0", ":", "\n", "        ", "nll_loss", "=", "trainer", ".", "get_meter", "(", "'valid_nll_loss'", ")", "\n", "stats", "[", "'nll_loss'", "]", "=", "nll_loss", "\n", "", "else", ":", "\n", "        ", "nll_loss", "=", "stats", "[", "'loss'", "]", "\n", "", "stats", "[", "'ppl'", "]", "=", "utils", ".", "get_perplexity", "(", "nll_loss", ".", "avg", ")", "\n", "stats", "[", "'num_updates'", "]", "=", "trainer", ".", "get_num_updates", "(", ")", "\n", "if", "hasattr", "(", "checkpoint_utils", ".", "save_checkpoint", ",", "'best'", ")", ":", "\n", "        ", "key", "=", "'best_{0}'", ".", "format", "(", "args", ".", "best_checkpoint_metric", ")", "\n", "best_function", "=", "max", "if", "args", ".", "maximize_best_checkpoint_metric", "else", "min", "\n", "\n", "current_metric", "=", "None", "\n", "if", "args", ".", "best_checkpoint_metric", "==", "'loss'", ":", "\n", "            ", "current_metric", "=", "stats", "[", "'loss'", "]", ".", "avg", "\n", "", "elif", "args", ".", "best_checkpoint_metric", "in", "extra_meters", ":", "\n", "            ", "current_metric", "=", "extra_meters", "[", "args", ".", "best_checkpoint_metric", "]", ".", "avg", "\n", "", "elif", "args", ".", "best_checkpoint_metric", "in", "stats", ":", "\n", "            ", "current_metric", "=", "stats", "[", "args", ".", "best_checkpoint_metric", "]", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\"best_checkpoint_metric not found in logs\"", ")", "\n", "\n", "", "stats", "[", "key", "]", "=", "best_function", "(", "\n", "checkpoint_utils", ".", "save_checkpoint", ".", "best", ",", "\n", "current_metric", ",", "\n", ")", "\n", "", "return", "stats", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.None.train_ar.distributed_main": [[295, 300], ["train_ar.main"], "function", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.None.train_ar.main"], ["", "def", "distributed_main", "(", "i", ",", "args", ",", "start_rank", "=", "0", ")", ":", "\n", "    ", "args", ".", "device_id", "=", "i", "\n", "if", "args", ".", "distributed_rank", "is", "None", ":", "# torch.multiprocessing.spawn", "\n", "        ", "args", ".", "distributed_rank", "=", "start_rank", "+", "i", "\n", "", "main", "(", "args", ",", "init_distributed", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.None.train_ar.ae_dump_codebook": [[302, 314], ["model.eval", "print", "print", "torch.cat", "images.cuda.cuda", "model", "lst.append", "indices.view.view", "indices.view.cpu", "indices.view.size"], "function", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.utils.eval", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.progress_bar.tensorboard_log_wrapper.print", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.progress_bar.tensorboard_log_wrapper.print", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.trainer.Trainer.model", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.fairseq_dataset.FairseqDataset.size"], ["", "def", "ae_dump_codebook", "(", "data_loader", ",", "model", ",", "original", ")", ":", "\n", "    ", "model", ".", "eval", "(", ")", "\n", "print", "(", "'Dumping Codebook'", ")", "\n", "lst", "=", "[", "]", "\n", "for", "images", ",", "label", "in", "data_loader", ":", "\n", "        ", "images", "=", "images", ".", "cuda", "(", ")", "\n", "x_tilde", ",", "z_e_x", ",", "z_q_x", ",", "indices", "=", "model", "(", "images", ",", "index", "=", "True", ")", "\n", "if", "original", ":", "\n", "            ", "indices", "=", "indices", ".", "view", "(", "indices", ".", "size", "(", "0", ")", ",", "-", "1", ")", "\n", "", "lst", ".", "append", "(", "indices", ".", "cpu", "(", ")", ")", "\n", "", "print", "(", "'Dumped Codebook'", ")", "\n", "return", "torch", ".", "cat", "(", "lst", ",", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.None.train_ar.cli_main": [[316, 372], ["fairseq.options.get_training_parser", "fairseq.options.parse_args_and_arch", "datasets.load_data", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "VectorQuantizedVAE_Dim().cuda.load_state_dict", "os.makedirs", "torch.save", "torch.save", "torch.cuda.empty_cache", "fairseq.distributed_utils.infer_init_method", "modules.VectorQuantizedVAE_CelebA().cuda", "torch.load", "train_ar.ae_dump_codebook", "os.path.join", "train_ar.ae_dump_codebook", "os.path.join", "torch.multiprocessing.spawn", "train_ar.distributed_main", "random.randint", "torch.multiprocessing.spawn", "train_ar.main", "modules.VectorQuantizedVAE_Bigger().cuda", "modules.VectorQuantizedVAE_Dim().cuda", "torch.cuda.device_count", "torch.cuda.device_count", "print", "modules.VectorQuantizedVAE_CelebA", "torch.cuda.device_count", "max", "modules.VectorQuantizedVAE_Bigger", "modules.VectorQuantizedVAE_Dim"], "function", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.options.get_training_parser", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.options.parse_args_and_arch", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.None.datasets.load_data", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.iterators.EpochBatchIterator.load_state_dict", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.distributed_utils.infer_init_method", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.None.train_ar.ae_dump_codebook", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.None.train_ar.ae_dump_codebook", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.None.train_ar.distributed_main", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.None.train_ar.main", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.progress_bar.tensorboard_log_wrapper.print"], ["", "def", "cli_main", "(", ")", ":", "\n", "    ", "parser", "=", "options", ".", "get_training_parser", "(", ")", "\n", "args", "=", "options", ".", "parse_args_and_arch", "(", "parser", ")", "\n", "\n", "if", "args", ".", "ae_dataset", "and", "args", ".", "ae_data_path", "and", "args", ".", "ae_checkpoint", ":", "\n", "        ", "train_dataset", ",", "valid_dataset", ",", "_", ",", "num_channels", "=", "datasets", ".", "load_data", "(", "args", ".", "ae_dataset", ",", "args", ".", "ae_data_path", ")", "\n", "train_loader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "train_dataset", ",", "\n", "batch_size", "=", "args", ".", "ae_batch_size", ",", "shuffle", "=", "True", ",", "\n", "num_workers", "=", "args", ".", "num_workers", ",", "pin_memory", "=", "True", ")", "\n", "valid_loader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "valid_dataset", ",", "\n", "batch_size", "=", "args", ".", "ae_batch_size", ",", "shuffle", "=", "False", ",", "\n", "num_workers", "=", "args", ".", "num_workers", ",", "pin_memory", "=", "True", ")", "\n", "if", "args", ".", "ae_dataset", "==", "'celeba'", ":", "\n", "            ", "model", "=", "VectorQuantizedVAE_CelebA", "(", "num_channels", ",", "args", ".", "tokens_per_sample", ",", "args", ".", "vocab_size", ")", ".", "cuda", "(", ")", "\n", "", "elif", "args", ".", "original", ":", "\n", "            ", "model", "=", "VectorQuantizedVAE_Bigger", "(", "num_channels", ",", "args", ".", "tokens_per_sample", ",", "args", ".", "vocab_size", ")", ".", "cuda", "(", ")", "\n", "", "else", ":", "\n", "            ", "model", "=", "VectorQuantizedVAE_Dim", "(", "num_channels", ",", "args", ".", "tokens_per_sample", ",", "args", ".", "vocab_size", ")", ".", "cuda", "(", ")", "\n", "", "model", ".", "load_state_dict", "(", "torch", ".", "load", "(", "args", ".", "ae_checkpoint", ")", ")", "\n", "os", ".", "makedirs", "(", "args", ".", "data", ",", "exist_ok", "=", "True", ")", "\n", "torch", ".", "save", "(", "ae_dump_codebook", "(", "train_loader", ",", "model", ",", "args", ".", "original", ")", ",", "os", ".", "path", ".", "join", "(", "args", ".", "data", ",", "'train.pt'", ")", ")", "\n", "torch", ".", "save", "(", "ae_dump_codebook", "(", "valid_loader", ",", "model", ",", "args", ".", "original", ")", ",", "os", ".", "path", ".", "join", "(", "args", ".", "data", ",", "'valid.pt'", ")", ")", "\n", "del", "model", "\n", "torch", ".", "cuda", ".", "empty_cache", "(", ")", "\n", "\n", "", "if", "args", ".", "distributed_init_method", "is", "None", ":", "\n", "        ", "distributed_utils", ".", "infer_init_method", "(", "args", ")", "\n", "\n", "", "if", "args", ".", "distributed_init_method", "is", "not", "None", ":", "\n", "# distributed training", "\n", "        ", "if", "torch", ".", "cuda", ".", "device_count", "(", ")", ">", "1", "and", "not", "args", ".", "distributed_no_spawn", ":", "\n", "            ", "start_rank", "=", "args", ".", "distributed_rank", "\n", "args", ".", "distributed_rank", "=", "None", "# assign automatically", "\n", "torch", ".", "multiprocessing", ".", "spawn", "(", "\n", "fn", "=", "distributed_main", ",", "\n", "args", "=", "(", "args", ",", "start_rank", ")", ",", "\n", "nprocs", "=", "torch", ".", "cuda", ".", "device_count", "(", ")", ",", "\n", ")", "\n", "", "else", ":", "\n", "            ", "distributed_main", "(", "args", ".", "device_id", ",", "args", ")", "\n", "", "", "elif", "args", ".", "distributed_world_size", ">", "1", ":", "\n", "# fallback for single node with multiple GPUs", "\n", "        ", "assert", "args", ".", "distributed_world_size", "<=", "torch", ".", "cuda", ".", "device_count", "(", ")", "\n", "port", "=", "random", ".", "randint", "(", "10000", ",", "20000", ")", "\n", "args", ".", "distributed_init_method", "=", "'tcp://localhost:{port}'", ".", "format", "(", "port", "=", "port", ")", "\n", "args", ".", "distributed_rank", "=", "None", "# set based on device id", "\n", "if", "max", "(", "args", ".", "update_freq", ")", ">", "1", "and", "args", ".", "ddp_backend", "!=", "'no_c10d'", ":", "\n", "            ", "print", "(", "'| NOTE: you may get better performance with: --ddp-backend=no_c10d'", ")", "\n", "", "torch", ".", "multiprocessing", ".", "spawn", "(", "\n", "fn", "=", "distributed_main", ",", "\n", "args", "=", "(", "args", ",", ")", ",", "\n", "nprocs", "=", "args", ".", "distributed_world_size", ",", "\n", ")", "\n", "", "else", ":", "\n", "# single GPU training", "\n", "        ", "main", "(", "args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.None.utils.dict2namespace": [[12, 21], ["argparse.Namespace", "config.items", "isinstance", "setattr", "utils.dict2namespace"], "function", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.None.utils.dict2namespace"], ["def", "dict2namespace", "(", "config", ")", ":", "\n", "    ", "namespace", "=", "argparse", ".", "Namespace", "(", ")", "\n", "for", "key", ",", "value", "in", "config", ".", "items", "(", ")", ":", "\n", "        ", "if", "isinstance", "(", "value", ",", "dict", ")", ":", "\n", "            ", "new_value", "=", "dict2namespace", "(", "value", ")", "\n", "", "else", ":", "\n", "            ", "new_value", "=", "value", "\n", "", "setattr", "(", "namespace", ",", "key", ",", "new_value", ")", "\n", "", "return", "namespace", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.None.utils.parse_args_and_config": [[22, 71], ["os.path.join", "getattr", "logging.StreamHandler", "logging.FileHandler", "logging.Formatter", "logging.StreamHandler.setFormatter", "logging.FileHandler.setFormatter", "logging.getLogger", "logging.getLogger.addHandler", "logging.getLogger.addHandler", "logging.getLogger.setLevel", "logging.info", "torch.manual_seed", "torch.manual_seed", "torch.cuda.manual_seed_all", "torch.cuda.manual_seed_all", "numpy.random.seed", "logging.info", "utils.dict2namespace", "utils.dict2namespace", "torch.cuda.is_available", "torch.cuda.is_available", "torch.device", "torch.device", "torch.device", "torch.device", "os.path.exists", "os.makedirs", "args.verbose.upper", "isinstance", "ValueError", "os.path.join", "open", "yaml.load", "open", "yaml.load", "shutil.rmtree", "open", "yaml.dump", "os.path.join", "vars", "os.path.join", "vars", "vars", "os.path.join"], "function", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.None.utils.dict2namespace", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.None.utils.dict2namespace", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq._hub_utils.GeneratorHubInterface.device", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq._hub_utils.GeneratorHubInterface.device", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq._hub_utils.GeneratorHubInterface.device", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq._hub_utils.GeneratorHubInterface.device"], ["", "def", "parse_args_and_config", "(", "args", ",", "config_dir", "=", "\"../configs\"", ",", "logdir", "=", "\"../logs\"", ",", "resume", "=", "False", ")", ":", "\n", "    ", "\"\"\"\n    :return args, config: namespace objects that stores information in args and config files.\n    \"\"\"", "\n", "args", ".", "log", "=", "os", ".", "path", ".", "join", "(", "logdir", ",", "args", ".", "doc", ")", "\n", "# parse config file", "\n", "if", "not", "resume", ":", "\n", "        ", "with", "open", "(", "os", ".", "path", ".", "join", "(", "config_dir", ",", "args", ".", "config", ")", ",", "'r'", ")", "as", "f", ":", "\n", "            ", "config", "=", "yaml", ".", "load", "(", "f", ")", "\n", "", "new_config", "=", "dict2namespace", "(", "{", "**", "config", ",", "**", "vars", "(", "args", ")", "}", ")", "\n", "", "else", ":", "\n", "        ", "with", "open", "(", "os", ".", "path", ".", "join", "(", "args", ".", "log", ",", "'config.yml'", ")", ",", "'r'", ")", "as", "f", ":", "\n", "            ", "config", "=", "yaml", ".", "load", "(", "f", ")", "\n", "", "new_config", "=", "dict2namespace", "(", "{", "**", "vars", "(", "config", ")", ",", "**", "vars", "(", "args", ")", "}", ")", "\n", "\n", "# add device information to config", "\n", "", "device", "=", "torch", ".", "device", "(", "'cuda'", ")", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "else", "torch", ".", "device", "(", "'cpu'", ")", "\n", "new_config", ".", "device", "=", "device", "\n", "\n", "if", "not", "resume", ":", "\n", "        ", "if", "os", ".", "path", ".", "exists", "(", "args", ".", "log", ")", ":", "\n", "            ", "shutil", ".", "rmtree", "(", "args", ".", "log", ")", "\n", "", "os", ".", "makedirs", "(", "args", ".", "log", ")", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "args", ".", "log", ",", "'config.yml'", ")", ",", "'w'", ")", "as", "f", ":", "\n", "            ", "yaml", ".", "dump", "(", "new_config", ",", "f", ",", "default_flow_style", "=", "False", ")", "\n", "\n", "# setup logger", "\n", "", "", "level", "=", "getattr", "(", "logging", ",", "args", ".", "verbose", ".", "upper", "(", ")", ",", "None", ")", "\n", "if", "not", "isinstance", "(", "level", ",", "int", ")", ":", "\n", "        ", "raise", "ValueError", "(", "'level {} not supported'", ".", "format", "(", "args", ".", "verbose", ")", ")", "\n", "\n", "", "handler1", "=", "logging", ".", "StreamHandler", "(", ")", "\n", "handler2", "=", "logging", ".", "FileHandler", "(", "os", ".", "path", ".", "join", "(", "args", ".", "log", ",", "'stdout.txt'", ")", ")", "\n", "formatter", "=", "logging", ".", "Formatter", "(", "'%(levelname)s - %(filename)s - %(asctime)s - %(message)s'", ")", "\n", "handler1", ".", "setFormatter", "(", "formatter", ")", "\n", "handler2", ".", "setFormatter", "(", "formatter", ")", "\n", "logger", "=", "logging", ".", "getLogger", "(", ")", "\n", "logger", ".", "addHandler", "(", "handler1", ")", "\n", "logger", ".", "addHandler", "(", "handler2", ")", "\n", "logger", ".", "setLevel", "(", "level", ")", "\n", "logging", ".", "info", "(", "\"Using device: {}\"", ".", "format", "(", "device", ")", ")", "\n", "\n", "# set random seed", "\n", "torch", ".", "manual_seed", "(", "new_config", ".", "seed", ")", "\n", "torch", ".", "cuda", ".", "manual_seed_all", "(", "new_config", ".", "seed", ")", "\n", "np", ".", "random", ".", "seed", "(", "new_config", ".", "seed", ")", "\n", "logging", ".", "info", "(", "\"Run name: {}\"", ".", "format", "(", "args", ".", "doc", ")", ")", "\n", "\n", "return", "args", ",", "new_config", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.None.utils.get_optimizer": [[72, 85], ["logging.info", "torch.Adam", "torch.RMSprop", "torch.SGD", "NotImplementedError"], "function", ["None"], ["", "def", "get_optimizer", "(", "parameters", ",", "config", ")", ":", "\n", "    ", "if", "config", ".", "optim", ".", "weight_decay", ">", "0", ":", "\n", "        ", "logging", ".", "info", "(", "\"Using weight decay\"", "+", "\"!\"", "*", "80", ")", "\n", "\n", "", "if", "config", ".", "optim", ".", "optimizer", "==", "'Adam'", ":", "\n", "        ", "return", "optim", ".", "Adam", "(", "parameters", ",", "lr", "=", "config", ".", "optim", ".", "lr", ",", "weight_decay", "=", "config", ".", "optim", ".", "weight_decay", ",", "\n", "betas", "=", "(", "0.9", ",", "0.999", ")", ")", "\n", "", "elif", "config", ".", "optim", ".", "optimizer", "==", "'RMSProp'", ":", "\n", "        ", "return", "optim", ".", "RMSprop", "(", "parameters", ",", "lr", "=", "config", ".", "optim", ".", "lr", ",", "weight_decay", "=", "config", ".", "optim", ".", "weight_decay", ")", "\n", "", "elif", "config", ".", "optim", ".", "optimizer", "==", "'SGD'", ":", "\n", "        ", "return", "optim", ".", "SGD", "(", "parameters", ",", "lr", "=", "config", ".", "optim", ".", "lr", ",", "momentum", "=", "0.9", ")", "\n", "", "else", ":", "\n", "        ", "raise", "NotImplementedError", "(", "'Optimizer {} not understood.'", ".", "format", "(", "config", ".", "optim", ".", "optimizer", ")", ")", "", "", "", ""]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.None.warmup_scheduler.GradualWarmupScheduler.__init__": [[15, 23], ["torch.optim.lr_scheduler._LRScheduler.__init__", "ValueError"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.dummy_dictionary.DummyDictionary.__init__"], ["def", "__init__", "(", "self", ",", "optimizer", ",", "multiplier", ",", "total_epoch", ",", "after_scheduler", "=", "None", ")", ":", "\n", "        ", "self", ".", "multiplier", "=", "multiplier", "\n", "if", "self", ".", "multiplier", "<", "1.", ":", "\n", "            ", "raise", "ValueError", "(", "'multiplier should be greater thant or equal to 1.'", ")", "\n", "", "self", ".", "total_epoch", "=", "total_epoch", "\n", "self", ".", "after_scheduler", "=", "after_scheduler", "\n", "self", ".", "finished", "=", "False", "\n", "super", "(", "GradualWarmupScheduler", ",", "self", ")", ".", "__init__", "(", "optimizer", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.None.warmup_scheduler.GradualWarmupScheduler.get_lr": [[24, 37], ["warmup_scheduler.GradualWarmupScheduler.after_scheduler.get_lr", "float"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.optim.fp16_optimizer.MemoryEfficientFP16Optimizer.get_lr"], ["", "def", "get_lr", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "last_epoch", ">", "self", ".", "total_epoch", ":", "\n", "            ", "if", "self", ".", "after_scheduler", ":", "\n", "                ", "if", "not", "self", ".", "finished", ":", "\n", "                    ", "self", ".", "after_scheduler", ".", "base_lrs", "=", "[", "base_lr", "*", "self", ".", "multiplier", "for", "base_lr", "in", "self", ".", "base_lrs", "]", "\n", "self", ".", "finished", "=", "True", "\n", "", "return", "self", ".", "after_scheduler", ".", "get_lr", "(", ")", "\n", "", "return", "[", "base_lr", "*", "self", ".", "multiplier", "for", "base_lr", "in", "self", ".", "base_lrs", "]", "\n", "\n", "", "if", "self", ".", "multiplier", "==", "1.0", ":", "\n", "            ", "return", "[", "base_lr", "*", "(", "float", "(", "self", ".", "last_epoch", ")", "/", "self", ".", "total_epoch", ")", "for", "base_lr", "in", "self", ".", "base_lrs", "]", "\n", "", "else", ":", "\n", "            ", "return", "[", "base_lr", "*", "(", "(", "self", ".", "multiplier", "-", "1.", ")", "*", "self", ".", "last_epoch", "/", "self", ".", "total_epoch", "+", "1.", ")", "for", "base_lr", "in", "self", ".", "base_lrs", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.None.warmup_scheduler.GradualWarmupScheduler.step_ReduceLROnPlateau": [[38, 51], ["zip", "warmup_scheduler.GradualWarmupScheduler.after_scheduler.step", "warmup_scheduler.GradualWarmupScheduler.after_scheduler.step"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.lr_scheduler.polynomial_decay_schedule.PolynomialDecaySchedule.step", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.lr_scheduler.polynomial_decay_schedule.PolynomialDecaySchedule.step"], ["", "", "def", "step_ReduceLROnPlateau", "(", "self", ",", "metrics", ",", "epoch", "=", "None", ")", ":", "\n", "        ", "if", "epoch", "is", "None", ":", "\n", "            ", "epoch", "=", "self", ".", "last_epoch", "+", "1", "\n", "", "self", ".", "last_epoch", "=", "epoch", "if", "epoch", "!=", "0", "else", "1", "# ReduceLROnPlateau is called at the end of epoch, whereas others are called at beginning", "\n", "if", "self", ".", "last_epoch", "<=", "self", ".", "total_epoch", ":", "\n", "            ", "warmup_lr", "=", "[", "base_lr", "*", "(", "(", "self", ".", "multiplier", "-", "1.", ")", "*", "self", ".", "last_epoch", "/", "self", ".", "total_epoch", "+", "1.", ")", "for", "base_lr", "in", "self", ".", "base_lrs", "]", "\n", "for", "param_group", ",", "lr", "in", "zip", "(", "self", ".", "optimizer", ".", "param_groups", ",", "warmup_lr", ")", ":", "\n", "                ", "param_group", "[", "'lr'", "]", "=", "lr", "\n", "", "", "else", ":", "\n", "            ", "if", "epoch", "is", "None", ":", "\n", "                ", "self", ".", "after_scheduler", ".", "step", "(", "metrics", ",", "None", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "after_scheduler", ".", "step", "(", "metrics", ",", "epoch", "-", "self", ".", "total_epoch", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.None.warmup_scheduler.GradualWarmupScheduler.step": [[52, 63], ["type", "warmup_scheduler.GradualWarmupScheduler.step_ReduceLROnPlateau", "super().step", "warmup_scheduler.GradualWarmupScheduler.after_scheduler.step", "warmup_scheduler.GradualWarmupScheduler.after_scheduler.step"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.None.warmup_scheduler.GradualWarmupScheduler.step_ReduceLROnPlateau", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.lr_scheduler.polynomial_decay_schedule.PolynomialDecaySchedule.step", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.lr_scheduler.polynomial_decay_schedule.PolynomialDecaySchedule.step", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.lr_scheduler.polynomial_decay_schedule.PolynomialDecaySchedule.step"], ["", "", "", "def", "step", "(", "self", ",", "epoch", "=", "None", ",", "metrics", "=", "None", ")", ":", "\n", "        ", "if", "type", "(", "self", ".", "after_scheduler", ")", "!=", "ReduceLROnPlateau", ":", "\n", "            ", "if", "self", ".", "finished", "and", "self", ".", "after_scheduler", ":", "\n", "                ", "if", "epoch", "is", "None", ":", "\n", "                    ", "self", ".", "after_scheduler", ".", "step", "(", "None", ")", "\n", "", "else", ":", "\n", "                    ", "self", ".", "after_scheduler", ".", "step", "(", "epoch", "-", "self", ".", "total_epoch", ")", "\n", "", "", "else", ":", "\n", "                ", "return", "super", "(", "GradualWarmupScheduler", ",", "self", ")", ".", "step", "(", "epoch", ")", "\n", "", "", "else", ":", "\n", "            ", "self", ".", "step_ReduceLROnPlateau", "(", "metrics", ",", "epoch", ")", "", "", "", "", ""]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.None.datasets.MiniImagenet.__init__": [[26, 65], ["torch.Dataset.__init__", "os.path.join", "os.path.join", "torchvision.datasets.MiniImagenet._fit_label_encoding", "ValueError", "os.path.expanduser", "os.path.expanduser", "torchvision.datasets.MiniImagenet.download", "torchvision.datasets.MiniImagenet._check_exists", "RuntimeError", "open", "csv.reader", "next", "torchvision.datasets.MiniImagenet._data.append", "ValueError", "tuple"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.dummy_dictionary.DummyDictionary.__init__", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.None.datasets.MiniImagenet._fit_label_encoding", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.None.datasets.MiniImagenet.download", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.None.datasets.MiniImagenet._check_exists"], ["def", "__init__", "(", "self", ",", "root", ",", "train", "=", "False", ",", "valid", "=", "False", ",", "test", "=", "False", ",", "\n", "transform", "=", "None", ",", "target_transform", "=", "None", ",", "download", "=", "False", ")", ":", "\n", "        ", "super", "(", "MiniImagenet", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "root", "=", "root", "\n", "self", ".", "train", "=", "train", "\n", "self", ".", "valid", "=", "valid", "\n", "self", ".", "test", "=", "test", "\n", "self", ".", "transform", "=", "transform", "\n", "self", ".", "target_transform", "=", "target_transform", "\n", "\n", "if", "not", "(", "(", "(", "train", "^", "valid", "^", "test", ")", "^", "(", "train", "&", "valid", "&", "test", ")", ")", ")", ":", "\n", "            ", "raise", "ValueError", "(", "'One and only one of `train`, `valid` or `test` '", "\n", "'must be True (train={0}, valid={1}, test={2}).'", ".", "format", "(", "train", ",", "\n", "valid", ",", "test", ")", ")", "\n", "\n", "", "self", ".", "image_folder", "=", "os", ".", "path", ".", "join", "(", "os", ".", "path", ".", "expanduser", "(", "root", ")", ",", "'images'", ")", "\n", "if", "train", ":", "\n", "            ", "split", "=", "self", ".", "splits", "[", "'train'", "]", "\n", "", "elif", "valid", ":", "\n", "            ", "split", "=", "self", ".", "splits", "[", "'valid'", "]", "\n", "", "elif", "test", ":", "\n", "            ", "split", "=", "self", ".", "splits", "[", "'test'", "]", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "'Unknown split.'", ")", "\n", "", "self", ".", "split_filename", "=", "os", ".", "path", ".", "join", "(", "os", ".", "path", ".", "expanduser", "(", "root", ")", ",", "split", ")", "\n", "if", "download", ":", "\n", "            ", "self", ".", "download", "(", ")", "\n", "", "if", "not", "self", ".", "_check_exists", "(", ")", ":", "\n", "            ", "raise", "RuntimeError", "(", "'Dataset not found. You can use `download=True` '", "\n", "'to download it'", ")", "\n", "\n", "# Extract filenames and labels", "\n", "", "self", ".", "_data", "=", "[", "]", "\n", "with", "open", "(", "self", ".", "split_filename", ",", "'r'", ")", "as", "f", ":", "\n", "            ", "reader", "=", "csv", ".", "reader", "(", "f", ")", "\n", "next", "(", "reader", ")", "# Skip the header", "\n", "for", "line", "in", "reader", ":", "\n", "                ", "self", ".", "_data", ".", "append", "(", "tuple", "(", "line", ")", ")", "\n", "", "", "self", ".", "_fit_label_encoding", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.None.datasets.MiniImagenet.__getitem__": [[66, 76], ["datasets.pil_loader", "os.path.join", "torchvision.datasets.MiniImagenet.transform", "torchvision.datasets.MiniImagenet.target_transform"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.None.datasets.pil_loader"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "filename", ",", "label", "=", "self", ".", "_data", "[", "index", "]", "\n", "image", "=", "pil_loader", "(", "os", ".", "path", ".", "join", "(", "self", ".", "image_folder", ",", "filename", ")", ")", "\n", "label", "=", "self", ".", "_label_encoder", "[", "label", "]", "\n", "if", "self", ".", "transform", "is", "not", "None", ":", "\n", "            ", "image", "=", "self", ".", "transform", "(", "image", ")", "\n", "", "if", "self", ".", "target_transform", "is", "not", "None", ":", "\n", "            ", "label", "=", "self", ".", "target_transform", "(", "label", ")", "\n", "\n", "", "return", "image", ",", "label", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.None.datasets.MiniImagenet._fit_label_encoding": [[77, 82], ["zip", "set", "dict", "enumerate"], "methods", ["None"], ["", "def", "_fit_label_encoding", "(", "self", ")", ":", "\n", "        ", "_", ",", "labels", "=", "zip", "(", "*", "self", ".", "_data", ")", "\n", "unique_labels", "=", "set", "(", "labels", ")", "\n", "self", ".", "_label_encoder", "=", "dict", "(", "(", "label", ",", "idx", ")", "\n", "for", "(", "idx", ",", "label", ")", "in", "enumerate", "(", "unique_labels", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.None.datasets.MiniImagenet._check_exists": [[83, 86], ["os.path.exists", "os.path.exists"], "methods", ["None"], ["", "def", "_check_exists", "(", "self", ")", ":", "\n", "        ", "return", "(", "os", ".", "path", ".", "exists", "(", "self", ".", "image_folder", ")", "\n", "and", "os", ".", "path", ".", "exists", "(", "self", ".", "split_filename", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.None.datasets.MiniImagenet.download": [[87, 118], ["torchvision.datasets.MiniImagenet._check_exists", "os.path.expanduser", "os.path.join", "os.path.join", "print", "copyfile", "print", "print", "os.path.exists", "os.makedirs", "ZipFile", "f.extractall", "os.path.join", "os.path.join", "print", "copyfile"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.None.datasets.MiniImagenet._check_exists", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.progress_bar.tensorboard_log_wrapper.print", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.progress_bar.tensorboard_log_wrapper.print", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.progress_bar.tensorboard_log_wrapper.print", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.progress_bar.tensorboard_log_wrapper.print"], ["", "def", "download", "(", "self", ")", ":", "\n", "        ", "from", "shutil", "import", "copyfile", "\n", "from", "zipfile", "import", "ZipFile", "\n", "\n", "# If the image folder already exists, break", "\n", "if", "self", ".", "_check_exists", "(", ")", ":", "\n", "            ", "return", "True", "\n", "\n", "# Create folder if it does not exist", "\n", "", "root", "=", "os", ".", "path", ".", "expanduser", "(", "self", ".", "root", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "root", ")", ":", "\n", "            ", "os", ".", "makedirs", "(", "root", ")", "\n", "\n", "# Copy the file to root", "\n", "", "path_source", "=", "os", ".", "path", ".", "join", "(", "self", ".", "base_folder", ",", "self", ".", "filename", ")", "\n", "path_dest", "=", "os", ".", "path", ".", "join", "(", "root", ",", "self", ".", "filename", ")", "\n", "print", "(", "'Copy file `{0}` to `{1}`...'", ".", "format", "(", "path_source", ",", "path_dest", ")", ")", "\n", "copyfile", "(", "path_source", ",", "path_dest", ")", "\n", "\n", "# Extract the dataset", "\n", "print", "(", "'Extract files from `{0}`...'", ".", "format", "(", "path_dest", ")", ")", "\n", "with", "ZipFile", "(", "path_dest", ",", "'r'", ")", "as", "f", ":", "\n", "            ", "f", ".", "extractall", "(", "root", ")", "\n", "\n", "# Copy CSV files", "\n", "", "for", "split", "in", "self", ".", "splits", ":", "\n", "            ", "path_source", "=", "os", ".", "path", ".", "join", "(", "self", ".", "base_folder", ",", "self", ".", "splits", "[", "split", "]", ")", "\n", "path_dest", "=", "os", ".", "path", ".", "join", "(", "root", ",", "self", ".", "splits", "[", "split", "]", ")", "\n", "print", "(", "'Copy file `{0}` to `{1}`...'", ".", "format", "(", "path_source", ",", "path_dest", ")", ")", "\n", "copyfile", "(", "path_source", ",", "path_dest", ")", "\n", "", "print", "(", "'Done!'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.None.datasets.MiniImagenet.__len__": [[119, 121], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "_data", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.None.datasets.pil_loader": [[9, 15], ["open", "PIL.Image.open", "Image.open.convert"], "function", ["None"], ["def", "pil_loader", "(", "path", ")", ":", "\n", "# open path as file to avoid ResourceWarning (https://github.com/python-pillow/Pillow/issues/835)", "\n", "# Borrowed from https://github.com/pytorch/vision/blob/master/torchvision/datasets/folder.py", "\n", "    ", "with", "open", "(", "path", ",", "'rb'", ")", "as", "f", ":", "\n", "        ", "img", "=", "Image", ".", "open", "(", "f", ")", "\n", "return", "img", ".", "convert", "(", "'RGB'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.None.datasets.load_data": [[123, 182], ["torchvision.transforms.Compose", "torchvision.datasets.MNIST", "torchvision.datasets.MNIST", "torchvision.transforms.Compose", "datasets.MiniImagenet", "datasets.MiniImagenet", "datasets.MiniImagenet", "torchvision.transforms.Compose", "torchvision.datasets.FashionMNIST", "torchvision.datasets.FashionMNIST", "torchvision.transforms.Compose", "torchvision.datasets.CelebA", "torchvision.datasets.CelebA", "ValueError", "torchvision.transforms.ToTensor", "torchvision.transforms.Normalize", "torchvision.transforms.Compose", "torchvision.datasets.CIFAR10", "torchvision.datasets.CIFAR10", "ValueError", "torchvision.transforms.RandomResizedCrop", "torchvision.transforms.ToTensor", "torchvision.transforms.Normalize", "torchvision.transforms.ToTensor", "torchvision.transforms.Normalize", "torchvision.transforms.Resize", "torchvision.transforms.CenterCrop", "torchvision.transforms.ToTensor", "torchvision.transforms.Normalize", "torchvision.transforms.ToTensor", "torchvision.transforms.Normalize"], "function", ["None"], ["", "", "def", "load_data", "(", "dataset_name", ",", "data_path", ")", ":", "\n", "    ", "if", "dataset_name", "in", "[", "'mnist'", ",", "'fashion-mnist'", ",", "'cifar10'", "]", ":", "\n", "        ", "if", "dataset_name", "==", "'mnist'", ":", "\n", "            ", "transform", "=", "transforms", ".", "Compose", "(", "[", "\n", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "transforms", ".", "Normalize", "(", "(", "0.5", ",", ")", ",", "(", "0.5", ",", ")", ")", "\n", "]", ")", "\n", "train_dataset", "=", "datasets", ".", "MNIST", "(", "data_path", ",", "train", "=", "True", ",", "download", "=", "True", ",", "transform", "=", "transform", ")", "\n", "test_dataset", "=", "datasets", ".", "MNIST", "(", "data_path", ",", "train", "=", "False", ",", "transform", "=", "transform", ")", "\n", "num_channels", "=", "1", "\n", "", "elif", "dataset_name", "==", "'fashion-mnist'", ":", "\n", "            ", "transform", "=", "transforms", ".", "Compose", "(", "[", "\n", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "transforms", ".", "Normalize", "(", "(", "0.5", ",", "0.5", ",", "0.5", ")", ",", "(", "0.5", ",", "0.5", ",", "0.5", ")", ")", "\n", "]", ")", "\n", "train_dataset", "=", "datasets", ".", "FashionMNIST", "(", "data_path", ",", "train", "=", "True", ",", "download", "=", "True", ",", "transform", "=", "transform", ")", "\n", "test_dataset", "=", "datasets", ".", "FashionMNIST", "(", "data_path", ",", "train", "=", "False", ",", "transform", "=", "transform", ")", "\n", "num_channels", "=", "1", "\n", "", "elif", "dataset_name", "==", "'cifar10'", ":", "\n", "            ", "transform", "=", "transforms", ".", "Compose", "(", "[", "\n", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "transforms", ".", "Normalize", "(", "(", "0.5", ",", "0.5", ",", "0.5", ")", ",", "(", "0.5", ",", "0.5", ",", "0.5", ")", ")", "\n", "]", ")", "\n", "train_dataset", "=", "datasets", ".", "CIFAR10", "(", "data_path", ",", "train", "=", "True", ",", "download", "=", "True", ",", "transform", "=", "transform", ")", "\n", "test_dataset", "=", "datasets", ".", "CIFAR10", "(", "data_path", ",", "train", "=", "False", ",", "transform", "=", "transform", ")", "\n", "num_channels", "=", "3", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "dataset_name", ")", "\n", "", "valid_dataset", "=", "test_dataset", "\n", "", "elif", "dataset_name", "==", "'miniimagenet'", ":", "\n", "        ", "transform", "=", "transforms", ".", "Compose", "(", "[", "\n", "transforms", ".", "RandomResizedCrop", "(", "128", ")", ",", "\n", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "transforms", ".", "Normalize", "(", "(", "0.5", ",", "0.5", ",", "0.5", ")", ",", "(", "0.5", ",", "0.5", ",", "0.5", ")", ")", "\n", "]", ")", "\n", "train_dataset", "=", "MiniImagenet", "(", "data_path", ",", "train", "=", "True", ",", "download", "=", "True", ",", "transform", "=", "transform", ")", "\n", "valid_dataset", "=", "MiniImagenet", "(", "data_path", ",", "valid", "=", "True", ",", "download", "=", "True", ",", "transform", "=", "transform", ")", "\n", "test_dataset", "=", "MiniImagenet", "(", "data_path", ",", "test", "=", "True", ",", "download", "=", "True", ",", "transform", "=", "transform", ")", "\n", "num_channels", "=", "3", "\n", "", "elif", "dataset_name", "==", "'celeba'", ":", "\n", "        ", "image_size", "=", "64", "\n", "transform", "=", "transforms", ".", "Compose", "(", "\n", "[", "transforms", ".", "Resize", "(", "image_size", ")", ",", "\n", "transforms", ".", "CenterCrop", "(", "image_size", ")", ",", "\n", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "transforms", ".", "Normalize", "(", "(", "0.5", ",", "0.5", ",", "0.5", ")", ",", "(", "0.5", ",", "0.5", ",", "0.5", ")", ")", "]", ")", "\n", "\n", "# Define the train & test datasets", "\n", "train_dataset", "=", "datasets", ".", "CelebA", "(", "root", "=", "data_path", ",", "\n", "split", "=", "'train'", ",", "target_type", "=", "\"\"", ",", "download", "=", "True", ",", "transform", "=", "transform", ")", "\n", "test_dataset", "=", "datasets", ".", "CelebA", "(", "root", "=", "data_path", ",", "\n", "split", "=", "'test'", ",", "target_type", "=", "\"\"", ",", "download", "=", "True", ",", "transform", "=", "transform", ")", "\n", "num_channels", "=", "3", "\n", "valid_dataset", "=", "test_dataset", "\n", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", ")", "\n", "\n", "", "return", "train_dataset", ",", "valid_dataset", ",", "test_dataset", ",", "num_channels", "\n", "", ""]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.None.transfomer.PositionalEncoding.__init__": [[25, 36], ["torch.Module.__init__", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.sin", "torch.sin", "torch.sin", "torch.sin", "torch.sin", "torch.sin", "torch.sin", "torch.sin", "torch.sin", "torch.cos", "torch.cos", "torch.cos", "torch.cos", "torch.cos", "torch.cos", "torch.cos", "torch.cos", "torch.cos", "pe.unsqueeze().transpose.unsqueeze().transpose.unsqueeze().transpose", "transfomer.PositionalEncoding.register_buffer", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange().float", "torch.arange().float", "torch.arange().float", "torch.arange().float", "torch.arange().float", "torch.arange().float", "torch.arange().float", "torch.arange().float", "torch.arange().float", "pe.unsqueeze().transpose.unsqueeze().transpose.unsqueeze", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "math.log"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.dummy_dictionary.DummyDictionary.__init__", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.progress_bar.tensorboard_log_wrapper.log"], ["def", "__init__", "(", "self", ",", "d_model", ",", "dropout", "=", "0.1", ",", "max_len", "=", "100", ")", ":", "\n", "        ", "super", "(", "PositionalEncoding", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "p", "=", "dropout", ")", "\n", "\n", "pe", "=", "torch", ".", "zeros", "(", "max_len", ",", "d_model", ")", "\n", "position", "=", "torch", ".", "arange", "(", "0", ",", "max_len", ",", "dtype", "=", "torch", ".", "float", ")", ".", "unsqueeze", "(", "1", ")", "\n", "div_term", "=", "torch", ".", "exp", "(", "torch", ".", "arange", "(", "0", ",", "d_model", ",", "2", ")", ".", "float", "(", ")", "*", "(", "-", "math", ".", "log", "(", "10000.0", ")", "/", "d_model", ")", ")", "\n", "pe", "[", ":", ",", "0", ":", ":", "2", "]", "=", "torch", ".", "sin", "(", "position", "*", "div_term", ")", "\n", "pe", "[", ":", ",", "1", ":", ":", "2", "]", "=", "torch", ".", "cos", "(", "position", "*", "div_term", ")", "\n", "pe", "=", "pe", ".", "unsqueeze", "(", "0", ")", ".", "transpose", "(", "0", ",", "1", ")", "\n", "self", ".", "register_buffer", "(", "'pe'", ",", "pe", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.None.transfomer.PositionalEncoding.forward": [[37, 50], ["transfomer.PositionalEncoding.dropout", "x.size"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.fairseq_dataset.FairseqDataset.size"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "r\"\"\"Inputs of forward function\n        Args:\n            x: the sequence fed to the positional encoder model (required).\n        Shape:\n            x: [sequence length, batch size, embed dim]\n            output: [sequence length, batch size, embed dim]\n        Examples:\n            >>> output = pos_encoder(x)\n        \"\"\"", "\n", "\n", "x", "=", "x", "+", "self", ".", "pe", "[", ":", "x", ".", "size", "(", "0", ")", ",", ":", "]", "\n", "return", "self", ".", "dropout", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.None.transfomer.TransformerModel.__init__": [[55, 75], ["torch.Module.__init__", "transfomer.PositionalEncoding", "TransformerEncoderLayer", "TransformerEncoder", "torch.Embedding", "torch.Embedding", "torch.Embedding", "torch.Linear", "torch.Linear", "torch.Linear", "transfomer.TransformerModel.init_weights", "ImportError"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.dummy_dictionary.DummyDictionary.__init__", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.transformer.Embedding", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.transformer.Embedding", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.transformer.Embedding", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.modules.transformer_layer.Linear", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.modules.transformer_layer.Linear", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.modules.transformer_layer.Linear", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.None.transfomer.TransformerModel.init_weights"], ["def", "__init__", "(", "self", ",", "ntoken", ",", "ninp", ",", "nhead", ",", "nhid", ",", "nlayers", ",", "dropout", "=", "0", ")", ":", "\n", "        ", "super", "(", "TransformerModel", ",", "self", ")", ".", "__init__", "(", ")", "\n", "try", ":", "\n", "            ", "from", "torch", ".", "nn", "import", "TransformerEncoder", ",", "TransformerEncoderLayer", "\n", "", "except", ":", "\n", "            ", "raise", "ImportError", "(", "'TransformerEncoder module does not exist in PyTorch 1.1 or lower.'", ")", "\n", "", "self", ".", "model_type", "=", "'Transformer'", "\n", "self", ".", "src_mask", "=", "None", "\n", "self", ".", "pos_encoder", "=", "PositionalEncoding", "(", "ninp", ",", "dropout", ")", "\n", "# self.list_layer = nn.ModuleList(", "\n", "#     [TransformerEncoderLayer(ninp, nhead, nhid, dropout) for i in range(nlayers)]", "\n", "# )", "\n", "\n", "encoder_layers", "=", "TransformerEncoderLayer", "(", "ninp", ",", "nhead", ",", "nhid", ",", "dropout", ")", "\n", "self", ".", "transformer_encoder", "=", "TransformerEncoder", "(", "encoder_layers", ",", "nlayers", ")", "\n", "self", ".", "encoder", "=", "nn", ".", "Embedding", "(", "ntoken", ",", "ninp", ")", "\n", "self", ".", "ninp", "=", "ninp", "\n", "self", ".", "decoder", "=", "nn", ".", "Linear", "(", "ninp", ",", "ntoken", ")", "\n", "\n", "self", ".", "init_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.None.transfomer.TransformerModel._generate_square_subsequent_mask": [[76, 85], ["mask.float().masked_fill().masked_fill.float().masked_fill().masked_fill.float().masked_fill().masked_fill", "float", "mask.float().masked_fill().masked_fill.float().masked_fill().masked_fill.float().masked_fill", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "float", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "mask.float().masked_fill().masked_fill.float().masked_fill().masked_fill.float"], "methods", ["None"], ["", "def", "_generate_square_subsequent_mask", "(", "self", ",", "sz", ")", ":", "\n", "        ", "'''\n\n        :param sz:\n        :return: mask : mask[i,j]:\n        '''", "\n", "mask", "=", "(", "torch", ".", "triu", "(", "torch", ".", "ones", "(", "sz", ",", "sz", ")", ")", "==", "1", ")", ".", "transpose", "(", "0", ",", "1", ")", "\n", "mask", "=", "mask", ".", "float", "(", ")", ".", "masked_fill", "(", "mask", "==", "0", ",", "float", "(", "'-inf'", ")", ")", ".", "masked_fill", "(", "mask", "==", "1", ",", "float", "(", "0.0", ")", ")", "\n", "return", "mask", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.None.transfomer.TransformerModel.init_weights": [[86, 91], ["transfomer.TransformerModel.encoder.weight.data.uniform_", "transfomer.TransformerModel.decoder.bias.data.zero_", "transfomer.TransformerModel.decoder.weight.data.uniform_"], "methods", ["None"], ["", "def", "init_weights", "(", "self", ")", ":", "\n", "        ", "initrange", "=", "0.1", "\n", "self", ".", "encoder", ".", "weight", ".", "data", ".", "uniform_", "(", "-", "initrange", ",", "initrange", ")", "\n", "self", ".", "decoder", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "self", ".", "decoder", ".", "weight", ".", "data", ".", "uniform_", "(", "-", "initrange", ",", "initrange", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.None.transfomer.TransformerModel.forward": [[92, 106], ["transfomer.TransformerModel.pos_encoder", "transfomer.TransformerModel.transformer_encoder", "transfomer.TransformerModel.decoder", "transfomer.TransformerModel.encoder", "math.sqrt", "transfomer.TransformerModel._generate_square_subsequent_mask().to", "transfomer.TransformerModel.src_mask.size", "len", "transfomer.TransformerModel._generate_square_subsequent_mask", "len"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.fairseq_model.FairseqMultiModel.decoder", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.fairseq_model.FairseqMultiModel.encoder", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.fairseq_dataset.FairseqDataset.size", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.None.transfomer.TransformerModel._generate_square_subsequent_mask"], ["", "def", "forward", "(", "self", ",", "src", ",", "has_mask", "=", "True", ")", ":", "\n", "        ", "if", "has_mask", ":", "\n", "            ", "device", "=", "src", ".", "device", "\n", "if", "self", ".", "src_mask", "is", "None", "or", "self", ".", "src_mask", ".", "size", "(", "0", ")", "!=", "len", "(", "src", ")", ":", "\n", "                ", "mask", "=", "self", ".", "_generate_square_subsequent_mask", "(", "len", "(", "src", ")", ")", ".", "to", "(", "device", ")", "\n", "self", ".", "src_mask", "=", "mask", "\n", "", "", "else", ":", "\n", "            ", "self", ".", "src_mask", "=", "None", "\n", "\n", "", "src", "=", "self", ".", "encoder", "(", "src", ")", "*", "math", ".", "sqrt", "(", "self", ".", "ninp", ")", "\n", "src", "=", "self", ".", "pos_encoder", "(", "src", ")", "\n", "output", "=", "self", ".", "transformer_encoder", "(", "src", ",", "self", ".", "src_mask", ")", "\n", "output", "=", "self", ".", "decoder", "(", "output", ")", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.None.transfomer.TransformerModel.sample": [[107, 121], ["torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.multinomial().type().cuda", "torch.multinomial().type().cuda", "torch.multinomial().type().cuda", "torch.multinomial().type().cuda", "torch.multinomial().type().cuda", "torch.multinomial().type().cuda", "torch.multinomial().type().cuda", "torch.multinomial().type().cuda", "torch.multinomial().type().cuda", "torch.cat.unsqueeze", "torch.cat.unsqueeze", "torch.cat.unsqueeze", "output.append", "range", "torch.cat.squeeze", "torch.cat.squeeze", "torch.cat.squeeze", "[].squeeze", "logits.exp.exp.exp", "torch.multinomial().type().cuda", "torch.multinomial().type().cuda", "torch.multinomial().type().cuda", "torch.multinomial().type().cuda", "torch.multinomial().type().cuda", "torch.multinomial().type().cuda", "torch.multinomial().type().cuda", "torch.multinomial().type().cuda", "torch.multinomial().type().cuda", "output.append", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.multinomial().type", "torch.multinomial().type", "torch.multinomial().type", "torch.multinomial().type", "torch.multinomial().type", "torch.multinomial().type", "torch.multinomial().type", "torch.multinomial().type", "torch.multinomial().type", "torch.multinomial().type().cuda.squeeze", "torch.multinomial().type().cuda.squeeze", "torch.multinomial().type().cuda.squeeze", "torch.multinomial().type", "torch.multinomial().type", "torch.multinomial().type", "torch.multinomial().type", "torch.multinomial().type", "torch.multinomial().type", "torch.multinomial().type", "torch.multinomial().type", "torch.multinomial().type", "torch.multinomial().type().cuda.unsqueeze", "torch.multinomial().type().cuda.unsqueeze", "torch.multinomial().type().cuda.unsqueeze", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "transfomer.TransformerModel.forward", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.criterions.label_smoothed_cross_entropy.LabelSmoothedCrossEntropyCriterion.forward"], ["", "def", "sample", "(", "self", ",", "prior", ",", "seq_len", ",", "label", ")", ":", "\n", "\n", "        ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "output", "=", "[", "]", "\n", "input", "=", "torch", ".", "multinomial", "(", "prior", ",", "1", ",", "replacement", "=", "True", ")", ".", "type", "(", "torch", ".", "int64", ")", ".", "cuda", "(", ")", "\n", "input", "=", "input", ".", "unsqueeze", "(", "0", ")", "# (1, batch_size)", "\n", "output", ".", "append", "(", "input", ".", "squeeze", "(", ")", ")", "\n", "for", "i", "in", "range", "(", "1", ",", "seq_len", ")", ":", "\n", "                ", "logits", "=", "self", ".", "forward", "(", "input", ")", "[", "-", "1", "]", ".", "squeeze", "(", ")", "# last entry in the sequence : (Batch_size * Class)", "\n", "logits", "=", "logits", ".", "exp", "(", ")", "\n", "x", "=", "torch", ".", "multinomial", "(", "logits", ",", "1", ")", ".", "type", "(", "torch", ".", "int64", ")", ".", "cuda", "(", ")", "\n", "output", ".", "append", "(", "x", ".", "squeeze", "(", ")", ")", "\n", "input", "=", "torch", ".", "cat", "(", "[", "input", ",", "x", ".", "unsqueeze", "(", "0", ")", "]", ",", "0", ")", "# Enlarge the seq_len (first dimenstion)", "\n", "", "", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.None.transfomer.TransformerModel.sample_batch": [[122, 137], ["torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.multinomial().type().cuda", "torch.multinomial().type().cuda", "torch.multinomial().type().cuda", "torch.multinomial().type().cuda", "torch.multinomial().type().cuda", "torch.multinomial().type().cuda", "torch.multinomial().type().cuda", "torch.multinomial().type().cuda", "torch.multinomial().type().cuda", "torch.cat.unsqueeze", "torch.cat.unsqueeze", "torch.cat.unsqueeze", "torch.cat.squeeze", "torch.cat.squeeze", "torch.cat.squeeze", "range", "[].squeeze", "logits.exp.exp.exp", "torch.multinomial().type().cuda", "torch.multinomial().type().cuda", "torch.multinomial().type().cuda", "torch.multinomial().type().cuda", "torch.multinomial().type().cuda", "torch.multinomial().type().cuda", "torch.multinomial().type().cuda", "torch.multinomial().type().cuda", "torch.multinomial().type().cuda", "torch.multinomial().type().cuda.squeeze", "torch.multinomial().type().cuda.squeeze", "torch.multinomial().type().cuda.squeeze", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.multinomial().type", "torch.multinomial().type", "torch.multinomial().type", "torch.multinomial().type", "torch.multinomial().type", "torch.multinomial().type", "torch.multinomial().type", "torch.multinomial().type", "torch.multinomial().type", "torch.multinomial().type", "torch.multinomial().type", "torch.multinomial().type", "torch.multinomial().type", "torch.multinomial().type", "torch.multinomial().type", "torch.multinomial().type", "torch.multinomial().type", "torch.multinomial().type", "torch.multinomial().type().cuda.transpose", "torch.multinomial().type().cuda.transpose", "torch.multinomial().type().cuda.transpose", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "transfomer.TransformerModel.forward", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.criterions.label_smoothed_cross_entropy.LabelSmoothedCrossEntropyCriterion.forward"], ["", "def", "sample_batch", "(", "self", ",", "prior", ",", "seq_len", ",", "batch_size", ",", "label", ")", ":", "\n", "\n", "        ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "output", "=", "torch", ".", "zeros", "(", "(", "batch_size", ",", "seq_len", ")", ")", ".", "cuda", "(", ")", "\n", "input", "=", "torch", ".", "multinomial", "(", "prior", ",", "batch_size", ",", "replacement", "=", "True", ")", ".", "type", "(", "torch", ".", "int64", ")", ".", "cuda", "(", ")", "\n", "input", "=", "input", ".", "unsqueeze", "(", "0", ")", "#(1, batch_size)", "\n", "output", "[", ":", ",", "0", "]", "=", "input", ".", "squeeze", "(", ")", "\n", "for", "i", "in", "range", "(", "1", ",", "seq_len", ")", ":", "\n", "                ", "logits", "=", "self", ".", "forward", "(", "input", ")", "[", "-", "1", "]", ".", "squeeze", "(", ")", "# last entry in the sequence : (Batch_size * Class)", "\n", "logits", "=", "logits", ".", "exp", "(", ")", "\n", "x", "=", "torch", ".", "multinomial", "(", "logits", ",", "1", ")", ".", "type", "(", "torch", ".", "int64", ")", ".", "cuda", "(", ")", "\n", "output", "[", ":", ",", "i", "]", "=", "x", ".", "squeeze", "(", ")", "\n", "input", "=", "torch", ".", "cat", "(", "[", "input", ",", "x", ".", "transpose", "(", "0", ",", "1", ")", "]", ",", "0", ")", "# Enlarge the seq_len (first dimenstion)", "\n", "\n", "", "", "return", "output", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.image_transformer.ImageTransformer.__init__": [[27, 61], ["torch.nn.Module.__init__", "torch.nn.ModuleList", "torch.nn.Dropout", "torch.nn.Conv2d", "torch.nn.Linear", "torch.nn.Parameter", "image_transformer.DecoderLayer", "torch.nn.Embedding", "torch.nn.Linear", "range", "torch.nn.Sequential", "torch.nn.Linear", "ValueError", "torch.randn", "torch.nn.Linear", "torch.nn.ReLU", "torch.nn.Linear", "torch.nn.ReLU", "torch.nn.Linear"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.dummy_dictionary.DummyDictionary.__init__", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.modules.transformer_layer.Linear", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.transformer.Embedding", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.modules.transformer_layer.Linear", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.modules.transformer_layer.Linear", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.modules.transformer_layer.Linear", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.modules.transformer_layer.Linear", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.modules.transformer_layer.Linear"], ["def", "__init__", "(", "self", ",", "hparams", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "hparams", "=", "hparams", "\n", "self", ".", "layers", "=", "nn", ".", "ModuleList", "(", "[", "DecoderLayer", "(", "hparams", ")", "for", "_", "in", "range", "(", "hparams", ".", "nlayers", ")", "]", ")", "\n", "self", ".", "input_dropout", "=", "nn", ".", "Dropout", "(", "p", "=", "hparams", ".", "dropout", ")", "\n", "if", "self", ".", "hparams", ".", "distr", "==", "\"dmol\"", ":", "# Discretized mixture of logistic, for ordinal valued inputs", "\n", "            ", "assert", "self", ".", "hparams", ".", "channels", "==", "3", ",", "\"Only supports 3 channels for DML\"", "\n", "size", "=", "(", "1", ",", "self", ".", "hparams", ".", "channels", ")", "\n", "self", ".", "embedding_conv", "=", "nn", ".", "Conv2d", "(", "1", ",", "self", ".", "hparams", ".", "hidden_size", ",", "\n", "kernel_size", "=", "size", ",", "stride", "=", "size", ")", "\n", "# 10 = 1 + 2c + c(c-1)/2; if only 1 channel, then 3 total", "\n", "depth", "=", "self", ".", "hparams", ".", "num_mixtures", "*", "10", "\n", "self", ".", "output_dense", "=", "nn", ".", "Linear", "(", "self", ".", "hparams", ".", "hidden_size", ",", "depth", ",", "bias", "=", "False", ")", "\n", "", "elif", "self", ".", "hparams", ".", "distr", "==", "\"cat\"", ":", "# Categorical", "\n", "            ", "self", ".", "embeds", "=", "nn", ".", "Embedding", "(", "NUM_PIXELS", "*", "self", ".", "hparams", ".", "channels", ",", "self", ".", "hparams", ".", "hidden_size", ")", "\n", "self", ".", "output_dense", "=", "nn", ".", "Linear", "(", "self", ".", "hparams", ".", "hidden_size", ",", "NUM_PIXELS", ",", "bias", "=", "True", ")", "\n", "", "elif", "self", ".", "hparams", ".", "distr", "in", "[", "\"mol\"", ",", "\"mog\"", "]", ":", "\n", "            ", "self", ".", "embedding_net", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "1", ",", "self", ".", "hparams", ".", "hidden_size", "//", "4", ",", "bias", "=", "True", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "Linear", "(", "self", ".", "hparams", ".", "hidden_size", "//", "4", ",", "self", ".", "hparams", ".", "hidden_size", "//", "2", ",", "bias", "=", "True", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "Linear", "(", "self", ".", "hparams", ".", "hidden_size", "//", "2", ",", "self", ".", "hparams", ".", "hidden_size", ",", "bias", "=", "True", ")", ",", "\n", ")", "\n", "depth", "=", "self", ".", "hparams", ".", "num_mixtures", "*", "3", "\n", "self", ".", "output_dense", "=", "nn", ".", "Linear", "(", "self", ".", "hparams", ".", "hidden_size", ",", "depth", ",", "bias", "=", "False", ")", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\"Only dmol, categorical, mol, or mog distributions\"", ")", "\n", "\n", "", "if", "self", ".", "hparams", ".", "pos_embeddings", ":", "\n", "# TODO: look into how they initialize pos embeddings.", "\n", "# NOTE: this init is probably overridden by Xavier.", "\n", "            ", "self", ".", "pos_embeddings", "=", "nn", ".", "Parameter", "(", "0.05", "*", "torch", ".", "randn", "(", "self", ".", "hparams", ".", "image_size", "**", "2", "*", "self", ".", "hparams", ".", "channels", ",", "\n", "self", ".", "hparams", ".", "hidden_size", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.image_transformer.ImageTransformer.add_timing_signal": [[63, 85], ["inv_timescales.to.to.to", "torch.zeros_like", "range", "len", "numpy.log", "torch.exp", "torch.arange().float().to", "torch.cat", "torch.nn.functional.pad", "range", "range", "torch.arange().float().to.view", "inv_timescales.to.to.view", "signal.unsqueeze.unsqueeze.unsqueeze", "signal.unsqueeze.unsqueeze.unsqueeze", "torch.arange().float", "torch.arange().float", "torch.sin", "torch.cos", "torch.arange", "torch.arange"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.progress_bar.tensorboard_log_wrapper.log", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.dummy_dictionary.DummyDictionary.pad"], ["", "", "def", "add_timing_signal", "(", "self", ",", "X", ",", "min_timescale", "=", "1.0", ",", "max_timescale", "=", "1.0e4", ")", ":", "\n", "        ", "num_dims", "=", "len", "(", "X", ".", "shape", ")", "-", "2", "# 2 corresponds to batch and hidden_size dimensions", "\n", "num_timescales", "=", "self", ".", "hparams", ".", "hidden_size", "//", "(", "num_dims", "*", "2", ")", "\n", "log_timescale_increment", "=", "np", ".", "log", "(", "max_timescale", "/", "min_timescale", ")", "/", "(", "num_timescales", "-", "1", ")", "\n", "inv_timescales", "=", "min_timescale", "*", "torch", ".", "exp", "(", "(", "torch", ".", "arange", "(", "num_timescales", ")", ".", "float", "(", ")", "*", "-", "log_timescale_increment", ")", ")", "\n", "inv_timescales", "=", "inv_timescales", ".", "to", "(", "X", ".", "device", ")", "\n", "total_signal", "=", "torch", ".", "zeros_like", "(", "X", ")", "# Only for debugging purposes", "\n", "for", "dim", "in", "range", "(", "num_dims", ")", ":", "\n", "            ", "length", "=", "X", ".", "shape", "[", "dim", "+", "1", "]", "# add 1 to exclude batch dim", "\n", "position", "=", "torch", ".", "arange", "(", "length", ")", ".", "float", "(", ")", ".", "to", "(", "X", ".", "device", ")", "\n", "scaled_time", "=", "position", ".", "view", "(", "-", "1", ",", "1", ")", "*", "inv_timescales", ".", "view", "(", "1", ",", "-", "1", ")", "\n", "signal", "=", "torch", ".", "cat", "(", "[", "torch", ".", "sin", "(", "scaled_time", ")", ",", "torch", ".", "cos", "(", "scaled_time", ")", "]", ",", "1", ")", "\n", "prepad", "=", "dim", "*", "2", "*", "num_timescales", "\n", "postpad", "=", "self", ".", "hparams", ".", "hidden_size", "-", "(", "dim", "+", "1", ")", "*", "2", "*", "num_timescales", "\n", "signal", "=", "F", ".", "pad", "(", "signal", ",", "(", "prepad", ",", "postpad", ")", ")", "\n", "for", "_", "in", "range", "(", "1", "+", "dim", ")", ":", "\n", "                ", "signal", "=", "signal", ".", "unsqueeze", "(", "0", ")", "\n", "", "for", "_", "in", "range", "(", "num_dims", "-", "1", "-", "dim", ")", ":", "\n", "                ", "signal", "=", "signal", ".", "unsqueeze", "(", "-", "2", ")", "\n", "", "X", "+=", "signal", "\n", "total_signal", "+=", "signal", "\n", "", "return", "X", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.image_transformer.ImageTransformer.shift_and_pad_": [[86, 94], ["X.view.view.view", "torch.nn.functional.pad", "X.view.view.view"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.dummy_dictionary.DummyDictionary.pad"], ["", "def", "shift_and_pad_", "(", "self", ",", "X", ")", ":", "\n", "# Shift inputs over by 1 and pad", "\n", "        ", "shape", "=", "X", ".", "shape", "\n", "X", "=", "X", ".", "view", "(", "shape", "[", "0", "]", ",", "-", "1", ",", "shape", "[", "-", "1", "]", ")", "\n", "X", "=", "X", "[", ":", ",", ":", "-", "1", ",", ":", "]", "\n", "X", "=", "F", ".", "pad", "(", "X", ",", "(", "0", ",", "0", ",", "1", ",", "0", ")", ")", "# Pad second to last dimension", "\n", "X", "=", "X", ".", "view", "(", "shape", ")", "\n", "return", "X", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.image_transformer.ImageTransformer.forward": [[95, 156], ["image_transformer.ImageTransformer.shift_and_pad_", "image_transformer.ImageTransformer.view", "image_transformer.ImageTransformer.input_dropout", "image_transformer.ImageTransformer.layers[].preprocess_", "image_transformer.ImageTransformer.output_dense().view", "image_transformer.ImageTransformer.unsqueeze", "torch.nn.functional.relu", "image_transformer.ImageTransformer.permute", "image_transformer.ImageTransformer.view", "image_transformer.ImageTransformer.pos_embeddings[].unsqueeze", "image_transformer.ImageTransformer.view", "image_transformer.ImageTransformer.add_timing_signal", "layer", "len", "torch.nn.functional.pad", "image_transformer.ImageTransformer.view", "torch.nn.functional.pad", "image_transformer.ImageTransformer.permute().contiguous", "image_transformer.ImageTransformer.view", "image_transformer.ImageTransformer.embedding_conv", "image_transformer.ImageTransformer.output_dense", "image_transformer.ImageTransformer.view", "image_transformer.ImageTransformer.permute", "image_transformer.ImageTransformer.embeds", "image_transformer.ImageTransformer.unsqueeze", "image_transformer.ImageTransformer.embedding_net", "image_transformer.ImageTransformer.permute", "torch.tensor", "range"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.image_transformer.ImageTransformer.shift_and_pad_", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.image_transformer.DecoderLayer.preprocess_", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.image_transformer.ImageTransformer.add_timing_signal", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.dummy_dictionary.DummyDictionary.pad", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.dummy_dictionary.DummyDictionary.pad"], ["", "def", "forward", "(", "self", ",", "X", ",", "sampling", "=", "False", ")", ":", "\n", "        ", "if", "not", "self", ".", "hparams", ".", "image", ":", "\n", "            ", "assert", "len", "(", "X", ".", "shape", ")", "==", "2", "\n", "\n", "# Reshape inputs", "\n", "", "if", "sampling", ":", "\n", "            ", "if", "self", ".", "hparams", ".", "image", ":", "\n", "                ", "curr_infer_length", "=", "X", ".", "shape", "[", "1", "]", "\n", "row_size", "=", "self", ".", "hparams", ".", "image_size", "*", "self", ".", "hparams", ".", "channels", "\n", "nrows", "=", "curr_infer_length", "//", "row_size", "+", "1", "\n", "X", "=", "F", ".", "pad", "(", "X", ",", "(", "0", ",", "nrows", "*", "row_size", "-", "curr_infer_length", ")", ")", "\n", "X", "=", "X", ".", "view", "(", "X", ".", "shape", "[", "0", "]", ",", "-", "1", ",", "row_size", ")", "\n", "", "else", ":", "\n", "                ", "X", "=", "F", ".", "pad", "(", "X", ",", "(", "0", ",", "1", ")", ")", "# Pad a single dimension for when shifting", "\n", "", "", "else", ":", "\n", "            ", "if", "self", ".", "hparams", ".", "image", ":", "\n", "                ", "X", "=", "X", ".", "permute", "(", "[", "0", ",", "2", ",", "3", ",", "1", "]", ")", ".", "contiguous", "(", ")", "\n", "X", "=", "X", ".", "view", "(", "X", ".", "shape", "[", "0", "]", ",", "X", ".", "shape", "[", "1", "]", ",", "X", ".", "shape", "[", "2", "]", "*", "X", ".", "shape", "[", "3", "]", ")", "# Flatten channels into width", "\n", "\n", "# Inputs -> embeddings", "\n", "", "", "if", "self", ".", "hparams", ".", "distr", "==", "\"dmol\"", ":", "\n", "# Create a \"channel\" dimension for the 1x3 convolution", "\n", "# (NOTE: can apply a 1x1 convolution and not reshape, this is for consistency)", "\n", "            ", "X", "=", "X", ".", "unsqueeze", "(", "1", ")", "\n", "X", "=", "F", ".", "relu", "(", "self", ".", "embedding_conv", "(", "X", ")", ")", "\n", "X", "=", "X", ".", "permute", "(", "[", "0", ",", "2", ",", "3", ",", "1", "]", ")", "# move channels to the end", "\n", "", "elif", "self", ".", "hparams", ".", "distr", "==", "\"cat\"", ":", "\n", "# Convert to indexes, and use separate embeddings for different channels", "\n", "            ", "X", "=", "(", "X", "*", "(", "NUM_PIXELS", "-", "1", ")", ")", ".", "long", "(", ")", "\n", "channel_addition", "=", "(", "torch", ".", "tensor", "(", "range", "(", "self", ".", "hparams", ".", "channels", ")", ")", "*", "NUM_PIXELS", ")", ".", "to", "(", "X", ".", "device", ")", ".", "repeat", "(", "X", ".", "shape", "[", "2", "]", "//", "self", ".", "hparams", ".", "channels", ")", ".", "view", "(", "1", ",", "1", ",", "-", "1", ")", "\n", "X", "+=", "channel_addition", "\n", "X", "=", "self", ".", "embeds", "(", "X", ")", "*", "(", "self", ".", "hparams", ".", "hidden_size", "**", "0.5", ")", "\n", "", "elif", "self", ".", "hparams", ".", "distr", "in", "[", "\"mol\"", ",", "\"mog\"", "]", ":", "\n", "            ", "X", "=", "X", ".", "unsqueeze", "(", "-", "1", ")", "\n", "X", "=", "self", ".", "embedding_net", "(", "X", ")", "\n", "\n", "", "X", "=", "self", ".", "shift_and_pad_", "(", "X", ")", "\n", "if", "self", ".", "hparams", ".", "pos_embeddings", ":", "\n", "            ", "shape", "=", "X", ".", "shape", "\n", "X", "=", "X", ".", "view", "(", "X", ".", "shape", "[", "0", "]", ",", "-", "1", ",", "X", ".", "shape", "[", "-", "1", "]", ")", "\n", "X", "+=", "self", ".", "pos_embeddings", "[", ":", "X", ".", "shape", "[", "1", "]", "]", ".", "unsqueeze", "(", "0", ")", "\n", "X", "=", "X", ".", "view", "(", "shape", ")", "\n", "", "else", ":", "\n", "            ", "X", "=", "self", ".", "add_timing_signal", "(", "X", ")", "\n", "", "shape", "=", "X", ".", "shape", "\n", "X", "=", "X", ".", "view", "(", "shape", "[", "0", "]", ",", "-", "1", ",", "shape", "[", "-", "1", "]", ")", "\n", "\n", "X", "=", "self", ".", "input_dropout", "(", "X", ")", "\n", "for", "layer", "in", "self", ".", "layers", ":", "\n", "            ", "X", "=", "layer", "(", "X", ")", "\n", "", "X", "=", "self", ".", "layers", "[", "-", "1", "]", ".", "preprocess_", "(", "X", ")", "# NOTE: this is identity (exists to replicate tensorflow code)", "\n", "X", "=", "self", ".", "output_dense", "(", "X", ")", ".", "view", "(", "shape", "[", ":", "-", "1", "]", "+", "(", "-", "1", ",", ")", ")", "\n", "\n", "if", "not", "sampling", ":", "\n", "# Unpack the channels", "\n", "            ", "if", "self", ".", "hparams", ".", "distr", "==", "\"cat\"", "or", "(", "self", ".", "hparams", ".", "distr", "in", "[", "\"mol\"", ",", "\"mog\"", "]", "and", "self", ".", "hparams", ".", "image", ")", ":", "\n", "                ", "X", "=", "X", ".", "view", "(", "X", ".", "shape", "[", "0", "]", ",", "X", ".", "shape", "[", "1", "]", ",", "X", ".", "shape", "[", "2", "]", "//", "self", ".", "hparams", ".", "channels", ",", "self", ".", "hparams", ".", "channels", ",", "X", ".", "shape", "[", "3", "]", ")", "\n", "X", "=", "X", ".", "permute", "(", "[", "0", ",", "3", ",", "1", ",", "2", ",", "4", "]", ")", "\n", "\n", "", "", "return", "X", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.image_transformer.ImageTransformer.split_to_dml_params": [[157, 172], ["torch.split", "torch.stack.view", "torch.tanh", "torch.clamp", "torch.tanh.view", "torch.clamp.view", "targets.unsqueeze.unsqueeze.unsqueeze", "torch.stack"], "methods", ["None"], ["", "def", "split_to_dml_params", "(", "self", ",", "preds", ",", "targets", "=", "None", ",", "sampling", "=", "False", ")", ":", "\n", "        ", "nm", "=", "self", ".", "hparams", ".", "num_mixtures", "\n", "mix_logits", ",", "locs", ",", "log_scales", ",", "coeffs", "=", "torch", ".", "split", "(", "preds", ",", "[", "nm", ",", "nm", "*", "3", ",", "nm", "*", "3", ",", "nm", "*", "3", "]", ",", "dim", "=", "-", "1", ")", "\n", "new_shape", "=", "preds", ".", "shape", "[", ":", "-", "1", "]", "+", "(", "3", ",", "nm", ")", "\n", "locs", "=", "locs", ".", "view", "(", "new_shape", ")", "\n", "coeffs", "=", "torch", ".", "tanh", "(", "coeffs", ".", "view", "(", "new_shape", ")", ")", "\n", "log_scales", "=", "torch", ".", "clamp", "(", "log_scales", ".", "view", "(", "new_shape", ")", ",", "min", "=", "-", "7.", ")", "\n", "if", "not", "sampling", ":", "\n", "            ", "targets", "=", "targets", ".", "unsqueeze", "(", "-", "1", ")", "\n", "locs1", "=", "locs", "[", "...", ",", "1", ",", ":", "]", "+", "coeffs", "[", "...", ",", "0", ",", ":", "]", "*", "targets", "[", ":", ",", "0", ",", "...", "]", "\n", "locs2", "=", "locs", "[", "...", ",", "2", ",", ":", "]", "+", "coeffs", "[", "...", ",", "1", ",", ":", "]", "*", "targets", "[", ":", ",", "0", ",", "...", "]", "+", "coeffs", "[", "...", ",", "2", ",", ":", "]", "*", "targets", "[", ":", ",", "1", ",", "...", "]", "\n", "locs", "=", "torch", ".", "stack", "(", "[", "locs", "[", "...", ",", "0", ",", ":", "]", ",", "locs1", ",", "locs2", "]", ",", "dim", "=", "-", "2", ")", "\n", "return", "mix_logits", ",", "locs", ",", "log_scales", "\n", "", "else", ":", "\n", "            ", "return", "mix_logits", ",", "locs", ",", "log_scales", ",", "coeffs", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.image_transformer.ImageTransformer.dmol_logp": [[174, 198], ["targets.unsqueeze.unsqueeze.unsqueeze", "torch.exp", "torch.sigmoid", "torch.sigmoid", "torch.where", "image_transformer.logsumexp", "torch.nn.functional.softplus", "torch.nn.functional.softplus", "torch.where", "logsumexp.sum", "image_transformer.logsoftmax", "torch.nn.functional.softplus", "torch.where", "torch.log", "torch.clamp", "numpy.log"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.image_transformer.logsumexp", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.image_transformer.logsoftmax", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.progress_bar.tensorboard_log_wrapper.log", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.progress_bar.tensorboard_log_wrapper.log"], ["", "", "def", "dmol_logp", "(", "self", ",", "logits", ",", "means", ",", "log_scales", ",", "targets", ")", ":", "\n", "        ", "targets", "=", "targets", ".", "unsqueeze", "(", "-", "1", ")", "\n", "centered_x", "=", "targets", "-", "means", "\n", "inv_stdv", "=", "torch", ".", "exp", "(", "-", "log_scales", ")", "\n", "plus_in", "=", "inv_stdv", "*", "(", "centered_x", "+", "1.", "/", "255.", ")", "\n", "cdf_plus", "=", "torch", ".", "sigmoid", "(", "plus_in", ")", "\n", "min_in", "=", "inv_stdv", "*", "(", "centered_x", "-", "1.", "/", "255.", ")", "\n", "cdf_min", "=", "torch", ".", "sigmoid", "(", "min_in", ")", "\n", "log_cdf_plus", "=", "plus_in", "-", "F", ".", "softplus", "(", "plus_in", ")", "# log probability for edge case of 0 (before scaling)", "\n", "log_one_minus_cdf_min", "=", "-", "F", ".", "softplus", "(", "min_in", ")", "# log probability for edge case of 255 (before scaling)", "\n", "cdf_delta", "=", "cdf_plus", "-", "cdf_min", "# probability for all other cases", "\n", "mid_in", "=", "inv_stdv", "*", "centered_x", "\n", "log_pdf_mid", "=", "mid_in", "-", "log_scales", "-", "2.", "*", "F", ".", "softplus", "(", "\n", "mid_in", ")", "# log probability in the center of the bin, to be used in extreme cases (not actually used in our code)", "\n", "\n", "# now select the right output: left edge case, right edge case, normal case, extremely low prob case (doesn't actually happen for us)", "\n", "log_probs", "=", "torch", ".", "where", "(", "targets", "<", "-", "0.999", ",", "log_cdf_plus", ",", "torch", ".", "where", "(", "targets", ">", "0.999", ",", "log_one_minus_cdf_min", ",", "\n", "torch", ".", "where", "(", "cdf_delta", ">", "1e-5", ",", "\n", "torch", ".", "log", "(", "torch", ".", "clamp", "(", "cdf_delta", ",", "\n", "min", "=", "1e-12", ")", ")", ",", "\n", "log_pdf_mid", "-", "np", ".", "log", "(", "127.5", ")", ")", ")", ")", "\n", "log_probs", "=", "log_probs", ".", "sum", "(", "3", ")", "+", "logsoftmax", "(", "logits", ")", "\n", "log_probs", "=", "logsumexp", "(", "log_probs", ")", "\n", "return", "log_probs", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.image_transformer.ImageTransformer.mol_logp": [[199, 208], ["targets.unsqueeze.unsqueeze.unsqueeze", "torch.exp", "image_transformer.logsumexp", "image_transformer.logsoftmax", "torch.nn.functional.softplus"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.image_transformer.logsumexp", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.image_transformer.logsoftmax"], ["", "def", "mol_logp", "(", "self", ",", "logits", ",", "means", ",", "log_scales", ",", "targets", ")", ":", "\n", "        ", "targets", "=", "targets", ".", "unsqueeze", "(", "-", "1", ")", "\n", "centered_x", "=", "targets", "-", "means", "\n", "inv_stdv", "=", "torch", ".", "exp", "(", "-", "log_scales", ")", "\n", "input", "=", "inv_stdv", "*", "centered_x", "# Maybe this should techincally be negated, but it's symmetric", "\n", "log_probs", "=", "input", "-", "log_scales", "-", "2.", "*", "F", ".", "softplus", "(", "input", ")", "\n", "log_probs", "=", "log_probs", "+", "logsoftmax", "(", "logits", ")", "\n", "log_probs", "=", "logsumexp", "(", "log_probs", ")", "\n", "return", "log_probs", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.image_transformer.ImageTransformer.mog_logp": [[209, 217], ["targets.unsqueeze.unsqueeze.unsqueeze", "image_transformer.logsumexp", "image_transformer.logsoftmax", "numpy.log", "torch.exp"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.image_transformer.logsumexp", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.image_transformer.logsoftmax", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.progress_bar.tensorboard_log_wrapper.log"], ["", "def", "mog_logp", "(", "self", ",", "logits", ",", "means", ",", "log_scales", ",", "targets", ")", ":", "\n", "        ", "targets", "=", "targets", ".", "unsqueeze", "(", "-", "1", ")", "\n", "log_pdf", "=", "-", "(", "means", "-", "targets", ")", "**", "2", "/", "(", "2.", "*", "torch", ".", "exp", "(", "log_scales", ")", "**", "2.", ")", "\n", "log_norm_const", "=", "-", "0.5", "*", "np", ".", "log", "(", "2", "*", "np", ".", "pi", ")", "-", "log_scales", "\n", "log_probs", "=", "log_pdf", "+", "log_norm_const", "\n", "log_probs", "=", "log_probs", "+", "logsoftmax", "(", "logits", ")", "\n", "log_probs", "=", "logsumexp", "(", "log_probs", ")", "\n", "return", "log_probs", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.image_transformer.ImageTransformer.loss": [[219, 238], ["image_transformer.ImageTransformer.split_to_dml_params", "targets.permute.permute.permute", "image_transformer.ImageTransformer.dmol_logp", "torch.chunk", "image_transformer.ImageTransformer.mol_logp", "torch.chunk", "image_transformer.ImageTransformer.mog_logp", "torch.nn.functional.cross_entropy", "preds.permute"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.image_transformer.ImageTransformer.split_to_dml_params", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.image_transformer.ImageTransformer.dmol_logp", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.image_transformer.ImageTransformer.mol_logp", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.image_transformer.ImageTransformer.mog_logp"], ["", "def", "loss", "(", "self", ",", "preds", ",", "targets", ")", ":", "\n", "        ", "if", "self", ".", "hparams", ".", "distr", "==", "\"dmol\"", ":", "\n", "# Assumes 3 channels. Input: [batch_size, height, width, 10 * 10]", "\n", "            ", "logits", ",", "locs", ",", "log_scales", "=", "self", ".", "split_to_dml_params", "(", "preds", ",", "targets", ")", "\n", "targets", "=", "targets", ".", "permute", "(", "[", "0", ",", "2", ",", "3", ",", "1", "]", ")", "\n", "log_probs", "=", "self", ".", "dmol_logp", "(", "logits", ",", "locs", ",", "log_scales", ",", "targets", ")", "\n", "return", "-", "log_probs", "\n", "", "elif", "self", ".", "hparams", ".", "distr", "==", "\"mol\"", ":", "\n", "            ", "logits", ",", "locs", ",", "log_scales", "=", "torch", ".", "chunk", "(", "preds", ",", "3", ",", "dim", "=", "-", "1", ")", "\n", "log_probs", "=", "self", ".", "mol_logp", "(", "logits", ",", "locs", ",", "log_scales", ",", "targets", ")", "\n", "return", "-", "log_probs", "\n", "", "elif", "self", ".", "hparams", ".", "distr", "==", "\"mog\"", ":", "\n", "            ", "logits", ",", "locs", ",", "log_scales", "=", "torch", ".", "chunk", "(", "preds", ",", "3", ",", "dim", "=", "-", "1", ")", "\n", "log_probs", "=", "self", ".", "mog_logp", "(", "logits", ",", "locs", ",", "log_scales", ",", "targets", ")", "\n", "return", "-", "log_probs", "\n", "", "elif", "self", ".", "hparams", ".", "distr", "==", "\"cat\"", ":", "\n", "            ", "targets", "=", "(", "targets", "*", "(", "NUM_PIXELS", "-", "1", ")", ")", ".", "long", "(", ")", "\n", "ce", "=", "F", ".", "cross_entropy", "(", "preds", ".", "permute", "(", "0", ",", "4", ",", "1", ",", "2", ",", "3", ")", ",", "targets", ",", "reduction", "=", "'none'", ")", "\n", "return", "ce", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.image_transformer.ImageTransformer.accuracy": [[239, 248], ["torch.argmax", "torch.zeros", "torch.eq().float().sum", "numpy.prod", "torch.eq().float", "torch.eq"], "methods", ["None"], ["", "", "def", "accuracy", "(", "self", ",", "preds", ",", "targets", ")", ":", "\n", "        ", "if", "self", ".", "hparams", ".", "distr", "==", "\"cat\"", ":", "\n", "            ", "targets", "=", "(", "targets", "*", "(", "NUM_PIXELS", "-", "1", ")", ")", ".", "long", "(", ")", "\n", "argmax_preds", "=", "torch", ".", "argmax", "(", "preds", ",", "dim", "=", "-", "1", ")", "\n", "acc", "=", "torch", ".", "eq", "(", "argmax_preds", ",", "targets", ")", ".", "float", "(", ")", ".", "sum", "(", ")", "/", "np", ".", "prod", "(", "argmax_preds", ".", "shape", ")", "\n", "return", "acc", "\n", "", "else", ":", "\n", "# Computing accuracy for dmol is more computationally intensive, so we skip it", "\n", "            ", "return", "torch", ".", "zeros", "(", "(", "1", ",", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.image_transformer.ImageTransformer.sample_from_mol": [[249, 260], ["torch.chunk", "torch.argmax", "torch.zeros_like().scatter_", "torch.log", "torch.log", "torch.log1p", "torch.zeros_like", "torch.rand_like", "torch.exp", "torch.log", "torch.rand_like"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.progress_bar.tensorboard_log_wrapper.log", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.progress_bar.tensorboard_log_wrapper.log", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.progress_bar.tensorboard_log_wrapper.log"], ["", "", "def", "sample_from_mol", "(", "self", ",", "outputs", ")", ":", "\n", "        ", "logits", ",", "locs", ",", "log_scales", "=", "torch", ".", "chunk", "(", "outputs", ",", "3", ",", "dim", "=", "-", "1", ")", "\n", "gumbel_noise", "=", "-", "torch", ".", "log", "(", "-", "torch", ".", "log", "(", "torch", ".", "rand_like", "(", "logits", ")", "*", "(", "1.", "-", "2", "*", "1e-5", ")", "+", "1e-5", ")", ")", "\n", "sel", "=", "torch", ".", "argmax", "(", "logits", "+", "gumbel_noise", ",", "-", "1", ",", "keepdim", "=", "True", ")", "\n", "one_hot", "=", "torch", ".", "zeros_like", "(", "logits", ")", ".", "scatter_", "(", "-", "1", ",", "sel", ",", "1", ")", "\n", "locs", "=", "(", "locs", "*", "one_hot", ")", ".", "sum", "(", "-", "1", ")", "\n", "log_scales", "=", "(", "log_scales", "*", "one_hot", ")", ".", "sum", "(", "-", "1", ")", "\n", "unif", "=", "torch", ".", "rand_like", "(", "log_scales", ")", "*", "(", "1.", "-", "2", "*", "1e-5", ")", "+", "1e-5", "\n", "logistic_noise", "=", "torch", ".", "log", "(", "unif", ")", "-", "torch", ".", "log1p", "(", "-", "unif", ")", "\n", "x", "=", "locs", "+", "torch", ".", "exp", "(", "log_scales", ")", "*", "logistic_noise", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.image_transformer.ImageTransformer.sample_from_mog": [[261, 271], ["torch.chunk", "torch.argmax", "torch.zeros_like().scatter_", "torch.randn_like", "torch.log", "torch.zeros_like", "torch.exp", "torch.log", "torch.rand_like"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.progress_bar.tensorboard_log_wrapper.log", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.progress_bar.tensorboard_log_wrapper.log"], ["", "def", "sample_from_mog", "(", "self", ",", "outputs", ")", ":", "\n", "        ", "logits", ",", "locs", ",", "log_scales", "=", "torch", ".", "chunk", "(", "outputs", ",", "3", ",", "dim", "=", "-", "1", ")", "\n", "gumbel_noise", "=", "-", "torch", ".", "log", "(", "-", "torch", ".", "log", "(", "torch", ".", "rand_like", "(", "logits", ")", "*", "(", "1.", "-", "2", "*", "1e-5", ")", "+", "1e-5", ")", ")", "\n", "sel", "=", "torch", ".", "argmax", "(", "logits", "+", "gumbel_noise", ",", "-", "1", ",", "keepdim", "=", "True", ")", "\n", "one_hot", "=", "torch", ".", "zeros_like", "(", "logits", ")", ".", "scatter_", "(", "-", "1", ",", "sel", ",", "1", ")", "\n", "locs", "=", "(", "locs", "*", "one_hot", ")", ".", "sum", "(", "-", "1", ")", "\n", "log_scales", "=", "(", "log_scales", "*", "one_hot", ")", ".", "sum", "(", "-", "1", ")", "\n", "norm", "=", "torch", ".", "randn_like", "(", "log_scales", ")", "\n", "x", "=", "locs", "+", "torch", ".", "exp", "(", "log_scales", ")", "*", "norm", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.image_transformer.ImageTransformer.sample_from_dmol": [[273, 290], ["image_transformer.ImageTransformer.split_to_dml_params", "torch.argmax", "torch.zeros_like().scatter_().unsqueeze", "torch.clamp", "torch.clamp", "torch.clamp", "torch.stack", "torch.log", "torch.log", "torch.log1p", "torch.zeros_like().scatter_", "torch.rand_like", "torch.exp", "torch.log", "torch.zeros_like", "torch.rand_like"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.image_transformer.ImageTransformer.split_to_dml_params", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.progress_bar.tensorboard_log_wrapper.log", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.progress_bar.tensorboard_log_wrapper.log", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.progress_bar.tensorboard_log_wrapper.log"], ["", "def", "sample_from_dmol", "(", "self", ",", "outputs", ")", ":", "\n", "        ", "logits", ",", "locs", ",", "log_scales", ",", "coeffs", "=", "self", ".", "split_to_dml_params", "(", "outputs", ",", "sampling", "=", "True", ")", "\n", "gumbel_noise", "=", "-", "torch", ".", "log", "(", "-", "torch", ".", "log", "(", "torch", ".", "rand_like", "(", "logits", ")", "*", "(", "1.", "-", "2", "*", "1e-5", ")", "+", "1e-5", ")", ")", "\n", "sel", "=", "torch", ".", "argmax", "(", "logits", "+", "gumbel_noise", ",", "-", "1", ",", "keepdim", "=", "True", ")", "\n", "one_hot", "=", "torch", ".", "zeros_like", "(", "logits", ")", ".", "scatter_", "(", "-", "1", ",", "sel", ",", "1", ")", ".", "unsqueeze", "(", "-", "2", ")", "\n", "locs", "=", "(", "locs", "*", "one_hot", ")", ".", "sum", "(", "-", "1", ")", "\n", "log_scales", "=", "(", "log_scales", "*", "one_hot", ")", ".", "sum", "(", "-", "1", ")", "\n", "coeffs", "=", "(", "coeffs", "*", "one_hot", ")", ".", "sum", "(", "-", "1", ")", "\n", "unif", "=", "torch", ".", "rand_like", "(", "log_scales", ")", "*", "(", "1.", "-", "2", "*", "1e-5", ")", "+", "1e-5", "\n", "logistic_noise", "=", "torch", ".", "log", "(", "unif", ")", "-", "torch", ".", "log1p", "(", "-", "unif", ")", "\n", "x", "=", "locs", "+", "torch", ".", "exp", "(", "log_scales", ")", "*", "logistic_noise", "\n", "# NOTE: sampling analogously to pixcnn++, which clamps first, unlike image transformer", "\n", "x0", "=", "torch", ".", "clamp", "(", "x", "[", "...", ",", "0", "]", ",", "-", "1.", ",", "1.", ")", "\n", "x1", "=", "torch", ".", "clamp", "(", "x", "[", "...", ",", "1", "]", "+", "coeffs", "[", "...", ",", "0", "]", "*", "x0", ",", "-", "1.", ",", "1.", ")", "\n", "x2", "=", "torch", ".", "clamp", "(", "x", "[", "...", ",", "2", "]", "+", "coeffs", "[", "...", ",", "1", "]", "*", "x0", "+", "coeffs", "[", "...", ",", "2", "]", "*", "x1", ",", "-", "1.", ",", "1.", ")", "\n", "x", "=", "torch", ".", "stack", "(", "[", "x0", ",", "x1", ",", "x2", "]", ",", "-", "1", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.image_transformer.ImageTransformer.sample_from_cat": [[292, 299], ["torch.argmax().float", "torch.log", "torch.argmax().float", "torch.argmax", "torch.log", "torch.argmax", "torch.rand_like"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.progress_bar.tensorboard_log_wrapper.log", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.progress_bar.tensorboard_log_wrapper.log"], ["", "def", "sample_from_cat", "(", "self", ",", "logits", ",", "argmax", "=", "False", ")", ":", "\n", "        ", "if", "argmax", ":", "\n", "            ", "sel", "=", "torch", ".", "argmax", "(", "logits", ",", "-", "1", ",", "keepdim", "=", "False", ")", ".", "float", "(", ")", "/", "255.", "\n", "", "else", ":", "\n", "            ", "gumbel_noise", "=", "-", "torch", ".", "log", "(", "-", "torch", ".", "log", "(", "torch", ".", "rand_like", "(", "logits", ")", "*", "(", "1.", "-", "2", "*", "1e-5", ")", "+", "1e-5", ")", ")", "\n", "sel", "=", "torch", ".", "argmax", "(", "logits", "+", "gumbel_noise", ",", "-", "1", ",", "keepdim", "=", "False", ")", ".", "float", "(", ")", "/", "255.", "\n", "", "return", "sel", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.image_transformer.ImageTransformer.sample": [[300, 325], ["torch.zeros().to", "tqdm.tqdm.tqdm", "range", "image_transformer.ImageTransformer.forward", "torch.cat.view", "torch.cat.permute", "torch.zeros", "image_transformer.ImageTransformer.view", "image_transformer.ImageTransformer.sample_from_dmol().squeeze", "torch.cat", "image_transformer.ImageTransformer.sample_from_cat", "image_transformer.ImageTransformer.sample_from_dmol", "image_transformer.ImageTransformer.sample_from_mol", "image_transformer.ImageTransformer.sample_from_mog"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.criterions.label_smoothed_cross_entropy.LabelSmoothedCrossEntropyCriterion.forward", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.image_transformer.ImageTransformer.sample_from_cat", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.image_transformer.ImageTransformer.sample_from_dmol", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.image_transformer.ImageTransformer.sample_from_mol", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.image_transformer.ImageTransformer.sample_from_mog"], ["", "def", "sample", "(", "self", ",", "n", ",", "device", ",", "argmax", "=", "False", ")", ":", "\n", "        ", "total_len", "=", "(", "self", ".", "hparams", ".", "image_size", "**", "2", ")", "\n", "if", "self", ".", "hparams", ".", "distr", "in", "[", "\"cat\"", ",", "\"mol\"", "]", ":", "\n", "            ", "total_len", "*=", "self", ".", "hparams", ".", "channels", "\n", "", "samples", "=", "torch", ".", "zeros", "(", "(", "n", ",", "3", ")", ")", ".", "to", "(", "device", ")", "\n", "for", "curr_infer_length", "in", "tqdm", "(", "range", "(", "total_len", ")", ")", ":", "\n", "            ", "outputs", "=", "self", ".", "forward", "(", "samples", ",", "sampling", "=", "True", ")", "\n", "outputs", "=", "outputs", ".", "view", "(", "n", ",", "-", "1", ",", "outputs", ".", "shape", "[", "-", "1", "]", ")", "[", ":", ",", "curr_infer_length", ":", "curr_infer_length", "+", "1", ",", ":", "]", "\n", "if", "self", ".", "hparams", ".", "distr", "==", "\"dmol\"", ":", "\n", "                ", "x", "=", "self", ".", "sample_from_dmol", "(", "outputs", ")", ".", "squeeze", "(", ")", "\n", "", "elif", "self", ".", "hparams", ".", "distr", "==", "\"cat\"", ":", "\n", "                ", "x", "=", "self", ".", "sample_from_cat", "(", "outputs", ",", "argmax", "=", "argmax", ")", "\n", "", "elif", "self", ".", "hparams", ".", "distr", "==", "\"mol\"", ":", "\n", "                ", "x", "=", "self", ".", "sample_from_mol", "(", "outputs", ")", "\n", "", "elif", "self", ".", "hparams", ".", "distr", "==", "\"mog\"", ":", "\n", "                ", "x", "=", "self", ".", "sample_from_mog", "(", "outputs", ")", "\n", "\n", "", "if", "curr_infer_length", "==", "0", ":", "\n", "                ", "samples", "=", "x", "\n", "", "else", ":", "\n", "                ", "samples", "=", "torch", ".", "cat", "(", "[", "samples", ",", "x", "]", ",", "1", ")", "\n", "", "", "if", "self", ".", "hparams", ".", "image", ":", "\n", "            ", "samples", "=", "samples", ".", "view", "(", "n", ",", "self", ".", "hparams", ".", "image_size", ",", "self", ".", "hparams", ".", "image_size", ",", "self", ".", "hparams", ".", "channels", ")", "\n", "samples", "=", "samples", ".", "permute", "(", "0", ",", "3", ",", "1", ",", "2", ")", "\n", "", "return", "samples", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.image_transformer.ImageTransformer.sample_from_preds": [[326, 337], ["image_transformer.ImageTransformer.sample_from_dmol", "image_transformer.ImageTransformer.permute", "image_transformer.ImageTransformer.sample_from_cat", "image_transformer.ImageTransformer.sample_from_mol", "image_transformer.ImageTransformer.sample_from_mog"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.image_transformer.ImageTransformer.sample_from_dmol", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.image_transformer.ImageTransformer.sample_from_cat", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.image_transformer.ImageTransformer.sample_from_mol", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.image_transformer.ImageTransformer.sample_from_mog"], ["", "def", "sample_from_preds", "(", "self", ",", "preds", ",", "argmax", "=", "False", ")", ":", "\n", "        ", "if", "self", ".", "hparams", ".", "distr", "==", "\"dmol\"", ":", "\n", "            ", "samples", "=", "self", ".", "sample_from_dmol", "(", "preds", ")", "\n", "samples", "=", "samples", ".", "permute", "(", "0", ",", "3", ",", "1", ",", "2", ")", "\n", "", "elif", "self", ".", "hparams", ".", "distr", "==", "\"cat\"", ":", "\n", "            ", "samples", "=", "self", ".", "sample_from_cat", "(", "preds", ",", "argmax", "=", "argmax", ")", "\n", "", "elif", "self", ".", "hparams", ".", "distr", "==", "\"mol\"", ":", "\n", "            ", "samples", "=", "self", ".", "sample_from_mol", "(", "preds", ")", "\n", "", "elif", "self", ".", "hparams", ".", "distr", "==", "\"mog\"", ":", "\n", "            ", "samples", "=", "self", ".", "sample_from_mog", "(", "preds", ")", "\n", "", "return", "samples", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.image_transformer.DecoderLayer.__init__": [[342, 352], ["torch.nn.Module.__init__", "image_transformer.Attn", "torch.nn.Dropout", "torch.nn.LayerNorm", "torch.nn.LayerNorm", "torch.nn.Sequential", "torch.nn.Linear", "torch.nn.ReLU", "torch.nn.Linear"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.dummy_dictionary.DummyDictionary.__init__", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.modules.layer_norm.LayerNorm", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.modules.layer_norm.LayerNorm", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.modules.transformer_layer.Linear", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.modules.transformer_layer.Linear"], ["def", "__init__", "(", "self", ",", "hparams", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "attn", "=", "Attn", "(", "hparams", ")", "\n", "self", ".", "hparams", "=", "hparams", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "p", "=", "hparams", ".", "dropout", ")", "\n", "self", ".", "layernorm_attn", "=", "nn", ".", "LayerNorm", "(", "[", "self", ".", "hparams", ".", "hidden_size", "]", ",", "eps", "=", "1e-6", ",", "elementwise_affine", "=", "True", ")", "\n", "self", ".", "layernorm_ffn", "=", "nn", ".", "LayerNorm", "(", "[", "self", ".", "hparams", ".", "hidden_size", "]", ",", "eps", "=", "1e-6", ",", "elementwise_affine", "=", "True", ")", "\n", "self", ".", "ffn", "=", "nn", ".", "Sequential", "(", "nn", ".", "Linear", "(", "self", ".", "hparams", ".", "hidden_size", ",", "self", ".", "hparams", ".", "filter_size", ",", "bias", "=", "True", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "Linear", "(", "self", ".", "hparams", ".", "filter_size", ",", "self", ".", "hparams", ".", "hidden_size", ",", "bias", "=", "True", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.image_transformer.DecoderLayer.preprocess_": [[353, 355], ["None"], "methods", ["None"], ["", "def", "preprocess_", "(", "self", ",", "X", ")", ":", "\n", "        ", "return", "X", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.image_transformer.DecoderLayer.forward": [[357, 364], ["image_transformer.DecoderLayer.preprocess_", "image_transformer.DecoderLayer.attn", "image_transformer.DecoderLayer.layernorm_attn", "image_transformer.DecoderLayer.ffn", "image_transformer.DecoderLayer.layernorm_ffn", "image_transformer.DecoderLayer.preprocess_", "image_transformer.DecoderLayer.dropout", "image_transformer.DecoderLayer.dropout"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.image_transformer.DecoderLayer.preprocess_", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.image_transformer.DecoderLayer.preprocess_"], ["", "def", "forward", "(", "self", ",", "X", ")", ":", "\n", "        ", "X", "=", "self", ".", "preprocess_", "(", "X", ")", "\n", "y", "=", "self", ".", "attn", "(", "X", ")", "\n", "X", "=", "self", ".", "layernorm_attn", "(", "self", ".", "dropout", "(", "y", ")", "+", "X", ")", "\n", "y", "=", "self", ".", "ffn", "(", "self", ".", "preprocess_", "(", "X", ")", ")", "\n", "X", "=", "self", ".", "layernorm_ffn", "(", "self", ".", "dropout", "(", "y", ")", "+", "X", ")", "\n", "return", "X", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.image_transformer.Attn.__init__": [[367, 378], ["torch.nn.Module.__init__", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.dummy_dictionary.DummyDictionary.__init__", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.modules.transformer_layer.Linear", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.modules.transformer_layer.Linear", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.modules.transformer_layer.Linear", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.modules.transformer_layer.Linear"], ["    ", "def", "__init__", "(", "self", ",", "hparams", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "hparams", "=", "hparams", "\n", "self", ".", "kd", "=", "self", ".", "hparams", ".", "total_key_depth", "or", "self", ".", "hparams", ".", "hidden_size", "\n", "self", ".", "vd", "=", "self", ".", "hparams", ".", "total_value_depth", "or", "self", ".", "hparams", ".", "hidden_size", "\n", "self", ".", "q_dense", "=", "nn", ".", "Linear", "(", "self", ".", "hparams", ".", "hidden_size", ",", "self", ".", "kd", ",", "bias", "=", "False", ")", "\n", "self", ".", "k_dense", "=", "nn", ".", "Linear", "(", "self", ".", "hparams", ".", "hidden_size", ",", "self", ".", "kd", ",", "bias", "=", "False", ")", "\n", "self", ".", "v_dense", "=", "nn", ".", "Linear", "(", "self", ".", "hparams", ".", "hidden_size", ",", "self", ".", "vd", ",", "bias", "=", "False", ")", "\n", "self", ".", "output_dense", "=", "nn", ".", "Linear", "(", "self", ".", "vd", ",", "self", ".", "hparams", ".", "hidden_size", ",", "bias", "=", "False", ")", "\n", "assert", "self", ".", "kd", "%", "self", ".", "hparams", ".", "num_heads", "==", "0", "\n", "assert", "self", ".", "vd", "%", "self", ".", "hparams", ".", "num_heads", "==", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.image_transformer.Attn.dot_product_attention": [[379, 385], ["torch.einsum", "torch.nn.functional.softmax"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.utils.softmax"], ["", "def", "dot_product_attention", "(", "self", ",", "q", ",", "k", ",", "v", ",", "bias", "=", "None", ")", ":", "\n", "        ", "logits", "=", "torch", ".", "einsum", "(", "\"...kd,...qd->...qk\"", ",", "k", ",", "q", ")", "\n", "if", "bias", "is", "not", "None", ":", "\n", "            ", "logits", "+=", "bias", "\n", "", "weights", "=", "F", ".", "softmax", "(", "logits", ",", "dim", "=", "-", "1", ")", "\n", "return", "weights", "@", "v", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.image_transformer.Attn.forward": [[386, 430], ["image_transformer.Attn.q_dense", "image_transformer.Attn.k_dense", "image_transformer.Attn.v_dense", "q.view.view.view().permute", "k.view.view.view().permute", "v.view.view.view().permute", "torch.cat.permute().contiguous", "torch.cat.view", "image_transformer.Attn.output_dense", "image_transformer.Attn.dot_product_attention", "q.view.view.view", "k.view.view.view", "v.view.view.view", "torch.triu().to", "torch.nn.functional.pad", "torch.nn.functional.pad", "torch.nn.functional.pad", "image_transformer.Attn.dot_product_attention", "torch.cat.permute", "torch.triu().to", "q.view.view.view", "k.view.view.view", "v.view.view.view", "torch.cat", "torch.cat", "image_transformer.Attn.dot_product_attention", "tail_output.view.view.view", "torch.cat", "torch.triu", "torch.triu().to", "torch.ones", "torch.triu", "torch.ones", "torch.triu", "torch.ones"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.image_transformer.Attn.dot_product_attention", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.dummy_dictionary.DummyDictionary.pad", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.dummy_dictionary.DummyDictionary.pad", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.dummy_dictionary.DummyDictionary.pad", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.image_transformer.Attn.dot_product_attention", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.image_transformer.Attn.dot_product_attention"], ["", "def", "forward", "(", "self", ",", "X", ")", ":", "\n", "        ", "q", "=", "self", ".", "q_dense", "(", "X", ")", "\n", "k", "=", "self", ".", "k_dense", "(", "X", ")", "\n", "v", "=", "self", ".", "v_dense", "(", "X", ")", "\n", "# Split to shape [batch_size, num_heads, len, depth / num_heads]", "\n", "q", "=", "q", ".", "view", "(", "q", ".", "shape", "[", ":", "-", "1", "]", "+", "(", "self", ".", "hparams", ".", "num_heads", ",", "self", ".", "kd", "//", "self", ".", "hparams", ".", "num_heads", ")", ")", ".", "permute", "(", "[", "0", ",", "2", ",", "1", ",", "3", "]", ")", "\n", "k", "=", "k", ".", "view", "(", "k", ".", "shape", "[", ":", "-", "1", "]", "+", "(", "self", ".", "hparams", ".", "num_heads", ",", "self", ".", "kd", "//", "self", ".", "hparams", ".", "num_heads", ")", ")", ".", "permute", "(", "[", "0", ",", "2", ",", "1", ",", "3", "]", ")", "\n", "v", "=", "v", ".", "view", "(", "v", ".", "shape", "[", ":", "-", "1", "]", "+", "(", "self", ".", "hparams", ".", "num_heads", ",", "self", ".", "vd", "//", "self", ".", "hparams", ".", "num_heads", ")", ")", ".", "permute", "(", "[", "0", ",", "2", ",", "1", ",", "3", "]", ")", "\n", "q", "*=", "(", "self", ".", "kd", "//", "self", ".", "hparams", ".", "num_heads", ")", "**", "(", "-", "0.5", ")", "\n", "\n", "if", "self", ".", "hparams", ".", "attn_type", "==", "\"global\"", ":", "\n", "            ", "bias", "=", "-", "1e9", "*", "torch", ".", "triu", "(", "torch", ".", "ones", "(", "X", ".", "shape", "[", "1", "]", ",", "X", ".", "shape", "[", "1", "]", ")", ",", "1", ")", ".", "to", "(", "X", ".", "device", ")", "\n", "result", "=", "self", ".", "dot_product_attention", "(", "q", ",", "k", ",", "v", ",", "bias", "=", "bias", ")", "\n", "", "elif", "self", ".", "hparams", ".", "attn_type", "==", "\"local_1d\"", ":", "\n", "            ", "len", "=", "X", ".", "shape", "[", "1", "]", "\n", "blen", "=", "self", ".", "hparams", ".", "block_length", "\n", "pad", "=", "(", "0", ",", "0", ",", "0", ",", "(", "-", "len", ")", "%", "self", ".", "hparams", ".", "block_length", ")", "# Append to multiple of block length", "\n", "q", "=", "F", ".", "pad", "(", "q", ",", "pad", ")", "\n", "k", "=", "F", ".", "pad", "(", "k", ",", "pad", ")", "\n", "v", "=", "F", ".", "pad", "(", "v", ",", "pad", ")", "\n", "\n", "bias", "=", "-", "1e9", "*", "torch", ".", "triu", "(", "torch", ".", "ones", "(", "blen", ",", "blen", ")", ",", "1", ")", ".", "to", "(", "X", ".", "device", ")", "\n", "first_output", "=", "self", ".", "dot_product_attention", "(", "\n", "q", "[", ":", ",", ":", ",", ":", "blen", ",", ":", "]", ",", "k", "[", ":", ",", ":", ",", ":", "blen", ",", ":", "]", ",", "v", "[", ":", ",", ":", ",", ":", "blen", ",", ":", "]", ",", "bias", "=", "bias", ")", "\n", "\n", "if", "q", ".", "shape", "[", "2", "]", ">", "blen", ":", "\n", "                ", "q", "=", "q", ".", "view", "(", "q", ".", "shape", "[", "0", "]", ",", "q", ".", "shape", "[", "1", "]", ",", "-", "1", ",", "blen", ",", "q", ".", "shape", "[", "3", "]", ")", "\n", "k", "=", "k", ".", "view", "(", "k", ".", "shape", "[", "0", "]", ",", "k", ".", "shape", "[", "1", "]", ",", "-", "1", ",", "blen", ",", "k", ".", "shape", "[", "3", "]", ")", "\n", "v", "=", "v", ".", "view", "(", "v", ".", "shape", "[", "0", "]", ",", "v", ".", "shape", "[", "1", "]", ",", "-", "1", ",", "blen", ",", "v", ".", "shape", "[", "3", "]", ")", "\n", "local_k", "=", "torch", ".", "cat", "(", "[", "k", "[", ":", ",", ":", ",", ":", "-", "1", "]", ",", "k", "[", ":", ",", ":", ",", "1", ":", "]", "]", ",", "3", ")", "# [batch, nheads, (nblocks - 1), blen * 2, depth]", "\n", "local_v", "=", "torch", ".", "cat", "(", "[", "v", "[", ":", ",", ":", ",", ":", "-", "1", "]", ",", "v", "[", ":", ",", ":", ",", "1", ":", "]", "]", ",", "3", ")", "\n", "tail_q", "=", "q", "[", ":", ",", ":", ",", "1", ":", "]", "\n", "bias", "=", "-", "1e9", "*", "torch", ".", "triu", "(", "torch", ".", "ones", "(", "blen", ",", "2", "*", "blen", ")", ",", "blen", "+", "1", ")", ".", "to", "(", "X", ".", "device", ")", "\n", "tail_output", "=", "self", ".", "dot_product_attention", "(", "tail_q", ",", "local_k", ",", "local_v", ",", "bias", "=", "bias", ")", "\n", "tail_output", "=", "tail_output", ".", "view", "(", "tail_output", ".", "shape", "[", "0", "]", ",", "tail_output", ".", "shape", "[", "1", "]", ",", "-", "1", ",", "tail_output", ".", "shape", "[", "4", "]", ")", "\n", "result", "=", "torch", ".", "cat", "(", "[", "first_output", ",", "tail_output", "]", ",", "2", ")", "\n", "result", "=", "result", "[", ":", ",", ":", ",", ":", "X", ".", "shape", "[", "1", "]", ",", ":", "]", "\n", "", "else", ":", "\n", "                ", "result", "=", "first_output", "[", ":", ",", ":", ",", ":", "X", ".", "shape", "[", "1", "]", ",", ":", "]", "\n", "\n", "", "", "result", "=", "result", ".", "permute", "(", "[", "0", ",", "2", ",", "1", ",", "3", "]", ")", ".", "contiguous", "(", ")", "\n", "result", "=", "result", ".", "view", "(", "result", ".", "shape", "[", "0", ":", "2", "]", "+", "(", "-", "1", ",", ")", ")", "\n", "result", "=", "self", ".", "output_dense", "(", "result", ")", "\n", "return", "result", "", "", "", ""]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.image_transformer.logsoftmax": [[14, 17], ["torch.max", "torch.log", "torch.exp().sum", "torch.exp"], "function", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.progress_bar.tensorboard_log_wrapper.log"], ["def", "logsoftmax", "(", "x", ")", ":", "\n", "    ", "m", "=", "torch", ".", "max", "(", "x", ",", "-", "1", ",", "keepdim", "=", "True", ")", ".", "values", "\n", "return", "x", "-", "m", "-", "torch", ".", "log", "(", "torch", ".", "exp", "(", "x", "-", "m", ")", ".", "sum", "(", "-", "1", ",", "keepdim", "=", "True", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.image_transformer.logsumexp": [[19, 22], ["x.max", "torch.log", "torch.exp().sum", "torch.exp"], "function", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.progress_bar.tensorboard_log_wrapper.log"], ["", "def", "logsumexp", "(", "x", ")", ":", "\n", "    ", "m", "=", "x", ".", "max", "(", "-", "1", ")", ".", "values", "\n", "return", "m", "+", "torch", ".", "log", "(", "torch", ".", "exp", "(", "x", "-", "m", "[", "...", ",", "None", "]", ")", ".", "sum", "(", "-", "1", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.fairseq_encoder.FairseqEncoder.__init__": [[12, 15], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.dummy_dictionary.DummyDictionary.__init__"], ["def", "__init__", "(", "self", ",", "dictionary", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dictionary", "=", "dictionary", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.fairseq_encoder.FairseqEncoder.forward": [[16, 25], ["None"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "src_tokens", ",", "src_lengths", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            src_tokens (LongTensor): tokens in the source language of shape\n                `(batch, src_len)`\n            src_lengths (LongTensor): lengths of each source sentence of shape\n                `(batch)`\n        \"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.fairseq_encoder.FairseqEncoder.reorder_encoder_out": [[26, 38], ["None"], "methods", ["None"], ["", "def", "reorder_encoder_out", "(", "self", ",", "encoder_out", ",", "new_order", ")", ":", "\n", "        ", "\"\"\"\n        Reorder encoder output according to `new_order`.\n\n        Args:\n            encoder_out: output from the ``forward()`` method\n            new_order (LongTensor): desired order\n\n        Returns:\n            `encoder_out` rearranged according to `new_order`\n        \"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.fairseq_encoder.FairseqEncoder.max_positions": [[39, 42], ["None"], "methods", ["None"], ["", "def", "max_positions", "(", "self", ")", ":", "\n", "        ", "\"\"\"Maximum input length supported by the encoder.\"\"\"", "\n", "return", "1e6", "# an arbitrary large number", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.fairseq_encoder.FairseqEncoder.upgrade_state_dict": [[43, 46], ["None"], "methods", ["None"], ["", "def", "upgrade_state_dict", "(", "self", ",", "state_dict", ")", ":", "\n", "        ", "\"\"\"Upgrade a (possibly old) state dict for new versions of fairseq.\"\"\"", "\n", "return", "state_dict", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.model_utils.script_skip_tensor_list": [[12, 22], ["enumerate", "t.numel", "outputs.append", "outputs.append", "xi.size", "mask.size"], "function", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.fairseq_dataset.FairseqDataset.size", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.fairseq_dataset.FairseqDataset.size"], ["@", "torch", ".", "jit", ".", "script", "\n", "def", "script_skip_tensor_list", "(", "x", ":", "List", "[", "Tensor", "]", ",", "mask", ")", ":", "\n", "    ", "res", "=", "[", "xi", "[", "mask", "]", "if", "xi", ".", "size", "(", "0", ")", "==", "mask", ".", "size", "(", "0", ")", "else", "xi", "[", ":", ",", "mask", "]", "for", "xi", "in", "x", "]", "\n", "outputs", "=", "[", "]", "\n", "for", "i", ",", "t", "in", "enumerate", "(", "res", ")", ":", "\n", "        ", "if", "t", ".", "numel", "(", ")", "!=", "0", ":", "\n", "            ", "outputs", ".", "append", "(", "t", ")", "\n", "", "else", ":", "\n", "            ", "outputs", ".", "append", "(", "x", "[", "i", "]", ")", "\n", "", "", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.model_utils.script_skip_tensor": [[24, 34], ["x.size", "res.numel", "x.size", "mask.size"], "function", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.fairseq_dataset.FairseqDataset.size", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.fairseq_dataset.FairseqDataset.size", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.fairseq_dataset.FairseqDataset.size"], ["", "@", "torch", ".", "jit", ".", "script", "\n", "def", "script_skip_tensor", "(", "x", ":", "Tensor", ",", "mask", ")", ":", "\n", "# None case", "\n", "    ", "if", "x", ".", "size", "(", "0", ")", "==", "0", ":", "\n", "        ", "return", "x", "\n", "", "res", "=", "x", "[", "mask", "]", "if", "x", ".", "size", "(", "0", ")", "==", "mask", ".", "size", "(", "0", ")", "else", "x", "[", ":", ",", "mask", "]", "\n", "if", "res", ".", "numel", "(", ")", "==", "0", ":", "\n", "        ", "return", "x", "\n", "", "else", ":", "\n", "        ", "return", "res", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.model_utils.expand_2d_or_3d_tensor": [[36, 55], ["torch.cat", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.cat.dim", "dims.append", "torch.cat.dim", "torch.cat.dim", "torch.cat.size", "torch.cat.size", "torch.zeros().to().fill_", "torch.zeros().to", "torch.zeros"], "function", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.fairseq_dataset.FairseqDataset.size", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.fairseq_dataset.FairseqDataset.size", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.fairseq_dataset.FairseqDataset.size", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.fairseq_dataset.FairseqDataset.size", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.fairseq_dataset.FairseqDataset.size", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.fairseq_dataset.FairseqDataset.size"], ["", "", "@", "torch", ".", "jit", ".", "script", "\n", "def", "expand_2d_or_3d_tensor", "(", "x", ",", "trg_dim", ":", "int", ",", "padding_idx", ":", "int", ")", ":", "\n", "    ", "\"\"\"\n    Expand 2D/3D tensor on dim=1\n    \"\"\"", "\n", "if", "x", "is", "None", ":", "\n", "        ", "return", "None", "\n", "\n", "", "assert", "x", ".", "dim", "(", ")", "==", "2", "or", "x", ".", "dim", "(", ")", "==", "3", "\n", "assert", "trg_dim", ">=", "x", ".", "size", "(", "1", ")", ",", "(", "trg_dim", ",", "x", ".", "size", "(", ")", ")", "\n", "if", "trg_dim", "==", "x", ".", "size", "(", "1", ")", ":", "\n", "        ", "return", "x", "\n", "\n", "", "dims", "=", "[", "x", ".", "size", "(", "0", ")", ",", "trg_dim", "-", "x", ".", "size", "(", "1", ")", "]", "\n", "if", "x", ".", "dim", "(", ")", "==", "3", ":", "\n", "        ", "dims", ".", "append", "(", "x", ".", "size", "(", "2", ")", ")", "\n", "", "x", "=", "torch", ".", "cat", "(", "[", "x", ",", "torch", ".", "zeros", "(", "dims", ")", ".", "to", "(", "x", ")", ".", "fill_", "(", "padding_idx", ")", "]", ",", "1", ")", "\n", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.model_utils.coalesce": [[57, 60], ["None"], "function", ["None"], ["", "@", "torch", ".", "jit", ".", "script", "\n", "def", "coalesce", "(", "x", ":", "Optional", "[", "Tensor", "]", ",", "y", ":", "Tensor", ")", "->", "Tensor", ":", "\n", "    ", "return", "x", "if", "x", "is", "not", "None", "else", "y", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.model_utils.fill_tensors": [[62, 91], ["mask.sum", "y.size", "expand_2d_or_3d_tensor.size", "expand_2d_or_3d_tensor.size", "y.size", "model_utils.expand_2d_or_3d_tensor", "expand_2d_or_3d_tensor.dim", "y.dim", "mask.size", "expand_2d_or_3d_tensor.size", "expand_2d_or_3d_tensor.dim", "y.size", "expand_2d_or_3d_tensor.size", "y.size", "torch.tensor().type_as", "expand_2d_or_3d_tensor.size", "expand_2d_or_3d_tensor.dim", "expand_2d_or_3d_tensor.size", "y.size", "expand_2d_or_3d_tensor.dim", "torch.tensor", "y.size", "y.size"], "function", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.fairseq_dataset.FairseqDataset.size", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.fairseq_dataset.FairseqDataset.size", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.fairseq_dataset.FairseqDataset.size", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.fairseq_dataset.FairseqDataset.size", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.model_utils.expand_2d_or_3d_tensor", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.fairseq_dataset.FairseqDataset.size", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.fairseq_dataset.FairseqDataset.size", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.fairseq_dataset.FairseqDataset.size", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.fairseq_dataset.FairseqDataset.size", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.fairseq_dataset.FairseqDataset.size", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.fairseq_dataset.FairseqDataset.size", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.fairseq_dataset.FairseqDataset.size", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.fairseq_dataset.FairseqDataset.size", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.fairseq_dataset.FairseqDataset.size", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.fairseq_dataset.FairseqDataset.size"], ["", "@", "torch", ".", "jit", ".", "script", "\n", "def", "fill_tensors", "(", "x", ":", "Optional", "[", "Tensor", "]", ",", "mask", ",", "y", ":", "Optional", "[", "Tensor", "]", ",", "padding_idx", ":", "int", ")", "->", "Optional", "[", "Tensor", "]", ":", "\n", "    ", "\"\"\"\n    Filling tensor x with y at masked positions (dim=0).\n    \"\"\"", "\n", "if", "x", "is", "None", "or", "x", ".", "size", "(", ")", "[", "0", "]", "==", "0", "or", "y", "is", "None", ":", "\n", "        ", "return", "x", "\n", "", "assert", "x", ".", "dim", "(", ")", "==", "y", ".", "dim", "(", ")", "and", "mask", ".", "size", "(", "0", ")", "==", "x", ".", "size", "(", "0", ")", "\n", "assert", "x", ".", "dim", "(", ")", "==", "2", "or", "(", "x", ".", "dim", "(", ")", "==", "3", "and", "x", ".", "size", "(", "2", ")", "==", "y", ".", "size", "(", "2", ")", ")", "\n", "\n", "n_selected", "=", "mask", ".", "sum", "(", ")", "\n", "if", "n_selected", "==", "0", ":", "\n", "        ", "return", "x", "\n", "", "assert", "n_selected", "==", "y", ".", "size", "(", "0", ")", "\n", "if", "n_selected", "==", "x", ".", "size", "(", "0", ")", ":", "\n", "        ", "return", "y", "\n", "\n", "", "if", "x", ".", "size", "(", "1", ")", "<", "y", ".", "size", "(", "1", ")", ":", "\n", "        ", "x", "=", "expand_2d_or_3d_tensor", "(", "x", ",", "y", ".", "size", "(", "1", ")", ",", "padding_idx", ")", "\n", "x", "[", "mask", "]", "=", "y", "\n", "", "elif", "x", ".", "size", "(", "1", ")", ">", "y", ".", "size", "(", "1", ")", ":", "\n", "        ", "x", "[", "mask", "]", "=", "torch", ".", "tensor", "(", "padding_idx", ")", ".", "type_as", "(", "x", ")", "\n", "if", "x", ".", "dim", "(", ")", "==", "2", ":", "\n", "            ", "x", "[", "mask", ",", ":", "y", ".", "size", "(", "1", ")", "]", "=", "y", "\n", "", "else", ":", "\n", "            ", "x", "[", "mask", ",", ":", "y", ".", "size", "(", "1", ")", ",", ":", "]", "=", "y", "\n", "", "", "else", ":", "\n", "        ", "x", "[", "mask", "]", "=", "y", "\n", "", "return", "x", "\n", "", ""]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.fairseq_incremental_decoder.FairseqIncrementalDecoder.__init__": [[31, 33], ["fairseq.models.FairseqDecoder.__init__"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.dummy_dictionary.DummyDictionary.__init__"], ["def", "__init__", "(", "self", ",", "dictionary", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "dictionary", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.fairseq_incremental_decoder.FairseqIncrementalDecoder.forward": [[34, 50], ["None"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "prev_output_tokens", ",", "encoder_out", "=", "None", ",", "incremental_state", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            prev_output_tokens (LongTensor): shifted output tokens of shape\n                `(batch, tgt_len)`, for teacher forcing\n            encoder_out (dict, optional): output from the encoder, used for\n                encoder-side attention\n            incremental_state (dict, optional): dictionary used for storing\n                state during :ref:`Incremental decoding`\n\n        Returns:\n            tuple:\n                - the decoder's output of shape `(batch, tgt_len, vocab)`\n                - a dictionary with any model-specific outputs\n        \"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.fairseq_incremental_decoder.FairseqIncrementalDecoder.extract_features": [[51, 59], ["None"], "methods", ["None"], ["", "def", "extract_features", "(", "self", ",", "prev_output_tokens", ",", "encoder_out", "=", "None", ",", "incremental_state", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"\n        Returns:\n            tuple:\n                - the decoder's features of shape `(batch, tgt_len, embed_dim)`\n                - a dictionary with any model-specific outputs\n        \"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.fairseq_incremental_decoder.FairseqIncrementalDecoder.reorder_incremental_state": [[60, 76], ["set", "fairseq_incremental_decoder.FairseqIncrementalDecoder.apply", "hasattr", "set.add", "module.reorder_incremental_state"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.modules.multihead_attention.MultiheadAttention.reorder_incremental_state"], ["", "def", "reorder_incremental_state", "(", "self", ",", "incremental_state", ",", "new_order", ")", ":", "\n", "        ", "\"\"\"Reorder incremental state.\n\n        This should be called when the order of the input has changed from the\n        previous time step. A typical use case is beam search, where the input\n        order changes between time steps based on the selection of beams.\n        \"\"\"", "\n", "seen", "=", "set", "(", ")", "\n", "\n", "def", "apply_reorder_incremental_state", "(", "module", ")", ":", "\n", "            ", "if", "module", "!=", "self", "and", "hasattr", "(", "module", ",", "'reorder_incremental_state'", ")", "and", "module", "not", "in", "seen", ":", "\n", "                ", "seen", ".", "add", "(", "module", ")", "\n", "module", ".", "reorder_incremental_state", "(", "incremental_state", ",", "new_order", ")", "\n", "\n", "", "", "self", ".", "apply", "(", "apply_reorder_incremental_state", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.fairseq_incremental_decoder.FairseqIncrementalDecoder.set_beam_size": [[77, 90], ["getattr", "set", "fairseq_incremental_decoder.FairseqIncrementalDecoder.apply", "hasattr", "set.add", "module.set_beam_size"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.modules.beamable_mm.BeamableMM.set_beam_size"], ["", "def", "set_beam_size", "(", "self", ",", "beam_size", ")", ":", "\n", "        ", "\"\"\"Sets the beam size in the decoder and all children.\"\"\"", "\n", "if", "getattr", "(", "self", ",", "'_beam_size'", ",", "-", "1", ")", "!=", "beam_size", ":", "\n", "            ", "seen", "=", "set", "(", ")", "\n", "\n", "def", "apply_set_beam_size", "(", "module", ")", ":", "\n", "                ", "if", "module", "!=", "self", "and", "hasattr", "(", "module", ",", "'set_beam_size'", ")", "and", "module", "not", "in", "seen", ":", "\n", "                    ", "seen", ".", "add", "(", "module", ")", "\n", "module", ".", "set_beam_size", "(", "beam_size", ")", "\n", "\n", "", "", "self", ".", "apply", "(", "apply_set_beam_size", ")", "\n", "self", ".", "_beam_size", "=", "beam_size", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.lstm.LSTMModel.__init__": [[22, 24], ["fairseq.models.FairseqEncoderDecoderModel.__init__"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.dummy_dictionary.DummyDictionary.__init__"], ["    ", "def", "__init__", "(", "self", ",", "encoder", ",", "decoder", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "encoder", ",", "decoder", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.lstm.LSTMModel.add_args": [[25, 73], ["parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "add_args", "(", "parser", ")", ":", "\n", "        ", "\"\"\"Add model-specific arguments to the parser.\"\"\"", "\n", "# fmt: off", "\n", "parser", ".", "add_argument", "(", "'--dropout'", ",", "type", "=", "float", ",", "metavar", "=", "'D'", ",", "\n", "help", "=", "'dropout probability'", ")", "\n", "parser", ".", "add_argument", "(", "'--encoder-embed-dim'", ",", "type", "=", "int", ",", "metavar", "=", "'N'", ",", "\n", "help", "=", "'encoder embedding dimension'", ")", "\n", "parser", ".", "add_argument", "(", "'--encoder-embed-path'", ",", "type", "=", "str", ",", "metavar", "=", "'STR'", ",", "\n", "help", "=", "'path to pre-trained encoder embedding'", ")", "\n", "parser", ".", "add_argument", "(", "'--encoder-freeze-embed'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "'freeze encoder embeddings'", ")", "\n", "parser", ".", "add_argument", "(", "'--encoder-hidden-size'", ",", "type", "=", "int", ",", "metavar", "=", "'N'", ",", "\n", "help", "=", "'encoder hidden size'", ")", "\n", "parser", ".", "add_argument", "(", "'--encoder-layers'", ",", "type", "=", "int", ",", "metavar", "=", "'N'", ",", "\n", "help", "=", "'number of encoder layers'", ")", "\n", "parser", ".", "add_argument", "(", "'--encoder-bidirectional'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "'make all layers of encoder bidirectional'", ")", "\n", "parser", ".", "add_argument", "(", "'--decoder-embed-dim'", ",", "type", "=", "int", ",", "metavar", "=", "'N'", ",", "\n", "help", "=", "'decoder embedding dimension'", ")", "\n", "parser", ".", "add_argument", "(", "'--decoder-embed-path'", ",", "type", "=", "str", ",", "metavar", "=", "'STR'", ",", "\n", "help", "=", "'path to pre-trained decoder embedding'", ")", "\n", "parser", ".", "add_argument", "(", "'--decoder-freeze-embed'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "'freeze decoder embeddings'", ")", "\n", "parser", ".", "add_argument", "(", "'--decoder-hidden-size'", ",", "type", "=", "int", ",", "metavar", "=", "'N'", ",", "\n", "help", "=", "'decoder hidden size'", ")", "\n", "parser", ".", "add_argument", "(", "'--decoder-layers'", ",", "type", "=", "int", ",", "metavar", "=", "'N'", ",", "\n", "help", "=", "'number of decoder layers'", ")", "\n", "parser", ".", "add_argument", "(", "'--decoder-out-embed-dim'", ",", "type", "=", "int", ",", "metavar", "=", "'N'", ",", "\n", "help", "=", "'decoder output embedding dimension'", ")", "\n", "parser", ".", "add_argument", "(", "'--decoder-attention'", ",", "type", "=", "str", ",", "metavar", "=", "'BOOL'", ",", "\n", "help", "=", "'decoder attention'", ")", "\n", "parser", ".", "add_argument", "(", "'--share-decoder-input-output-embed'", ",", "default", "=", "False", ",", "\n", "action", "=", "'store_true'", ",", "\n", "help", "=", "'share decoder input and output embeddings'", ")", "\n", "parser", ".", "add_argument", "(", "'--share-all-embeddings'", ",", "default", "=", "False", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "'share encoder, decoder and output embeddings'", "\n", "' (requires shared dictionary and embed dim)'", ")", "\n", "\n", "# Granular dropout settings (if not specified these default to --dropout)", "\n", "parser", ".", "add_argument", "(", "'--encoder-dropout-in'", ",", "type", "=", "float", ",", "metavar", "=", "'D'", ",", "\n", "help", "=", "'dropout probability for encoder input embedding'", ")", "\n", "parser", ".", "add_argument", "(", "'--encoder-dropout-out'", ",", "type", "=", "float", ",", "metavar", "=", "'D'", ",", "\n", "help", "=", "'dropout probability for encoder output'", ")", "\n", "parser", ".", "add_argument", "(", "'--decoder-dropout-in'", ",", "type", "=", "float", ",", "metavar", "=", "'D'", ",", "\n", "help", "=", "'dropout probability for decoder input embedding'", ")", "\n", "parser", ".", "add_argument", "(", "'--decoder-dropout-out'", ",", "type", "=", "float", ",", "metavar", "=", "'D'", ",", "\n", "help", "=", "'dropout probability for decoder output'", ")", "\n", "# fmt: on", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.lstm.LSTMModel.build_model": [[75, 163], ["lstm.base_architecture", "lstm.LSTMEncoder", "lstm.LSTMDecoder", "cls", "ValueError", "len", "dictionary.pad", "lstm.Embedding", "fairseq.utils.parse_embedding", "fairseq.utils.print_embed_overlap", "fairseq.utils.load_embedding", "lstm.LSTMModel.build_model.load_pretrained_embedding_from_file"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.lstm.base_architecture", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.dummy_dictionary.DummyDictionary.pad", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.transformer.Embedding", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.utils.parse_embedding", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.utils.print_embed_overlap", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.utils.load_embedding"], ["", "@", "classmethod", "\n", "def", "build_model", "(", "cls", ",", "args", ",", "task", ")", ":", "\n", "        ", "\"\"\"Build a new model instance.\"\"\"", "\n", "# make sure that all args are properly defaulted (in case there are any new ones)", "\n", "base_architecture", "(", "args", ")", "\n", "\n", "if", "args", ".", "encoder_layers", "!=", "args", ".", "decoder_layers", ":", "\n", "            ", "raise", "ValueError", "(", "'--encoder-layers must match --decoder-layers'", ")", "\n", "\n", "", "def", "load_pretrained_embedding_from_file", "(", "embed_path", ",", "dictionary", ",", "embed_dim", ")", ":", "\n", "            ", "num_embeddings", "=", "len", "(", "dictionary", ")", "\n", "padding_idx", "=", "dictionary", ".", "pad", "(", ")", "\n", "embed_tokens", "=", "Embedding", "(", "num_embeddings", ",", "embed_dim", ",", "padding_idx", ")", "\n", "embed_dict", "=", "utils", ".", "parse_embedding", "(", "embed_path", ")", "\n", "utils", ".", "print_embed_overlap", "(", "embed_dict", ",", "dictionary", ")", "\n", "return", "utils", ".", "load_embedding", "(", "embed_dict", ",", "dictionary", ",", "embed_tokens", ")", "\n", "\n", "", "if", "args", ".", "encoder_embed_path", ":", "\n", "            ", "pretrained_encoder_embed", "=", "load_pretrained_embedding_from_file", "(", "\n", "args", ".", "encoder_embed_path", ",", "task", ".", "source_dictionary", ",", "args", ".", "encoder_embed_dim", ")", "\n", "", "else", ":", "\n", "            ", "num_embeddings", "=", "len", "(", "task", ".", "source_dictionary", ")", "\n", "pretrained_encoder_embed", "=", "Embedding", "(", "\n", "num_embeddings", ",", "args", ".", "encoder_embed_dim", ",", "task", ".", "source_dictionary", ".", "pad", "(", ")", "\n", ")", "\n", "\n", "", "if", "args", ".", "share_all_embeddings", ":", "\n", "# double check all parameters combinations are valid", "\n", "            ", "if", "task", ".", "source_dictionary", "!=", "task", ".", "target_dictionary", ":", "\n", "                ", "raise", "ValueError", "(", "'--share-all-embeddings requires a joint dictionary'", ")", "\n", "", "if", "args", ".", "decoder_embed_path", "and", "(", "\n", "args", ".", "decoder_embed_path", "!=", "args", ".", "encoder_embed_path", ")", ":", "\n", "                ", "raise", "ValueError", "(", "\n", "'--share-all-embed not compatible with --decoder-embed-path'", "\n", ")", "\n", "", "if", "args", ".", "encoder_embed_dim", "!=", "args", ".", "decoder_embed_dim", ":", "\n", "                ", "raise", "ValueError", "(", "\n", "'--share-all-embeddings requires --encoder-embed-dim to '", "\n", "'match --decoder-embed-dim'", "\n", ")", "\n", "", "pretrained_decoder_embed", "=", "pretrained_encoder_embed", "\n", "args", ".", "share_decoder_input_output_embed", "=", "True", "\n", "", "else", ":", "\n", "# separate decoder input embeddings", "\n", "            ", "pretrained_decoder_embed", "=", "None", "\n", "if", "args", ".", "decoder_embed_path", ":", "\n", "                ", "pretrained_decoder_embed", "=", "load_pretrained_embedding_from_file", "(", "\n", "args", ".", "decoder_embed_path", ",", "\n", "task", ".", "target_dictionary", ",", "\n", "args", ".", "decoder_embed_dim", "\n", ")", "\n", "# one last double check of parameter combinations", "\n", "", "", "if", "args", ".", "share_decoder_input_output_embed", "and", "(", "\n", "args", ".", "decoder_embed_dim", "!=", "args", ".", "decoder_out_embed_dim", ")", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "'--share-decoder-input-output-embeddings requires '", "\n", "'--decoder-embed-dim to match --decoder-out-embed-dim'", "\n", ")", "\n", "\n", "", "if", "args", ".", "encoder_freeze_embed", ":", "\n", "            ", "pretrained_encoder_embed", ".", "weight", ".", "requires_grad", "=", "False", "\n", "", "if", "args", ".", "decoder_freeze_embed", ":", "\n", "            ", "pretrained_decoder_embed", ".", "weight", ".", "requires_grad", "=", "False", "\n", "\n", "", "encoder", "=", "LSTMEncoder", "(", "\n", "dictionary", "=", "task", ".", "source_dictionary", ",", "\n", "embed_dim", "=", "args", ".", "encoder_embed_dim", ",", "\n", "hidden_size", "=", "args", ".", "encoder_hidden_size", ",", "\n", "num_layers", "=", "args", ".", "encoder_layers", ",", "\n", "dropout_in", "=", "args", ".", "encoder_dropout_in", ",", "\n", "dropout_out", "=", "args", ".", "encoder_dropout_out", ",", "\n", "bidirectional", "=", "args", ".", "encoder_bidirectional", ",", "\n", "pretrained_embed", "=", "pretrained_encoder_embed", ",", "\n", ")", "\n", "decoder", "=", "LSTMDecoder", "(", "\n", "dictionary", "=", "task", ".", "target_dictionary", ",", "\n", "embed_dim", "=", "args", ".", "decoder_embed_dim", ",", "\n", "hidden_size", "=", "args", ".", "decoder_hidden_size", ",", "\n", "out_embed_dim", "=", "args", ".", "decoder_out_embed_dim", ",", "\n", "num_layers", "=", "args", ".", "decoder_layers", ",", "\n", "dropout_in", "=", "args", ".", "decoder_dropout_in", ",", "\n", "dropout_out", "=", "args", ".", "decoder_dropout_out", ",", "\n", "attention", "=", "options", ".", "eval_bool", "(", "args", ".", "decoder_attention", ")", ",", "\n", "encoder_output_units", "=", "encoder", ".", "output_units", ",", "\n", "pretrained_embed", "=", "pretrained_decoder_embed", ",", "\n", "share_input_output_embed", "=", "args", ".", "share_decoder_input_output_embed", ",", "\n", ")", "\n", "return", "cls", "(", "encoder", ",", "decoder", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.lstm.LSTMEncoder.__init__": [[167, 199], ["fairseq.models.FairseqEncoder.__init__", "len", "dictionary.pad", "lstm.LSTM", "lstm.Embedding"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.dummy_dictionary.DummyDictionary.__init__", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.dummy_dictionary.DummyDictionary.pad", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.lstm.LSTM", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.transformer.Embedding"], ["def", "__init__", "(", "\n", "self", ",", "dictionary", ",", "embed_dim", "=", "512", ",", "hidden_size", "=", "512", ",", "num_layers", "=", "1", ",", "\n", "dropout_in", "=", "0.1", ",", "dropout_out", "=", "0.1", ",", "bidirectional", "=", "False", ",", "\n", "left_pad", "=", "True", ",", "pretrained_embed", "=", "None", ",", "padding_value", "=", "0.", ",", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "dictionary", ")", "\n", "self", ".", "num_layers", "=", "num_layers", "\n", "self", ".", "dropout_in", "=", "dropout_in", "\n", "self", ".", "dropout_out", "=", "dropout_out", "\n", "self", ".", "bidirectional", "=", "bidirectional", "\n", "self", ".", "hidden_size", "=", "hidden_size", "\n", "\n", "num_embeddings", "=", "len", "(", "dictionary", ")", "\n", "self", ".", "padding_idx", "=", "dictionary", ".", "pad", "(", ")", "\n", "if", "pretrained_embed", "is", "None", ":", "\n", "            ", "self", ".", "embed_tokens", "=", "Embedding", "(", "num_embeddings", ",", "embed_dim", ",", "self", ".", "padding_idx", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "embed_tokens", "=", "pretrained_embed", "\n", "\n", "", "self", ".", "lstm", "=", "LSTM", "(", "\n", "input_size", "=", "embed_dim", ",", "\n", "hidden_size", "=", "hidden_size", ",", "\n", "num_layers", "=", "num_layers", ",", "\n", "dropout", "=", "self", ".", "dropout_out", "if", "num_layers", ">", "1", "else", "0.", ",", "\n", "bidirectional", "=", "bidirectional", ",", "\n", ")", "\n", "self", ".", "left_pad", "=", "left_pad", "\n", "self", ".", "padding_value", "=", "padding_value", "\n", "\n", "self", ".", "output_units", "=", "hidden_size", "\n", "if", "bidirectional", ":", "\n", "            ", "self", ".", "output_units", "*=", "2", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.lstm.LSTMEncoder.forward": [[200, 250], ["fairseq.utils.convert_padding_direction.size", "lstm.LSTMEncoder.embed_tokens", "torch.dropout", "torch.dropout", "torch.dropout", "torch.dropout.transpose", "torch.utils.rnn.pack_padded_sequence", "torch.utils.rnn.pack_padded_sequence", "torch.utils.rnn.pack_padded_sequence", "torch.dropout.new_zeros", "torch.dropout.new_zeros", "lstm.LSTMEncoder.lstm", "torch.utils.rnn.pad_packed_sequence", "torch.utils.rnn.pad_packed_sequence", "torch.utils.rnn.pad_packed_sequence", "torch.dropout", "torch.dropout", "torch.dropout", "fairseq.utils.convert_padding_direction.eq().t", "fairseq.utils.convert_padding_direction", "src_lengths.data.tolist", "list", "lstm.LSTMEncoder.forward.combine_bidir"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.fairseq_dataset.FairseqDataset.size", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.utils.convert_padding_direction"], ["", "", "def", "forward", "(", "self", ",", "src_tokens", ",", "src_lengths", ")", ":", "\n", "        ", "if", "self", ".", "left_pad", ":", "\n", "# nn.utils.rnn.pack_padded_sequence requires right-padding;", "\n", "# convert left-padding to right-padding", "\n", "            ", "src_tokens", "=", "utils", ".", "convert_padding_direction", "(", "\n", "src_tokens", ",", "\n", "self", ".", "padding_idx", ",", "\n", "left_to_right", "=", "True", ",", "\n", ")", "\n", "\n", "", "bsz", ",", "seqlen", "=", "src_tokens", ".", "size", "(", ")", "\n", "\n", "# embed tokens", "\n", "x", "=", "self", ".", "embed_tokens", "(", "src_tokens", ")", "\n", "x", "=", "F", ".", "dropout", "(", "x", ",", "p", "=", "self", ".", "dropout_in", ",", "training", "=", "self", ".", "training", ")", "\n", "\n", "# B x T x C -> T x B x C", "\n", "x", "=", "x", ".", "transpose", "(", "0", ",", "1", ")", "\n", "\n", "# pack embedded source tokens into a PackedSequence", "\n", "packed_x", "=", "nn", ".", "utils", ".", "rnn", ".", "pack_padded_sequence", "(", "x", ",", "src_lengths", ".", "data", ".", "tolist", "(", ")", ")", "\n", "\n", "# apply LSTM", "\n", "if", "self", ".", "bidirectional", ":", "\n", "            ", "state_size", "=", "2", "*", "self", ".", "num_layers", ",", "bsz", ",", "self", ".", "hidden_size", "\n", "", "else", ":", "\n", "            ", "state_size", "=", "self", ".", "num_layers", ",", "bsz", ",", "self", ".", "hidden_size", "\n", "", "h0", "=", "x", ".", "new_zeros", "(", "*", "state_size", ")", "\n", "c0", "=", "x", ".", "new_zeros", "(", "*", "state_size", ")", "\n", "packed_outs", ",", "(", "final_hiddens", ",", "final_cells", ")", "=", "self", ".", "lstm", "(", "packed_x", ",", "(", "h0", ",", "c0", ")", ")", "\n", "\n", "# unpack outputs and apply dropout", "\n", "x", ",", "_", "=", "nn", ".", "utils", ".", "rnn", ".", "pad_packed_sequence", "(", "packed_outs", ",", "padding_value", "=", "self", ".", "padding_value", ")", "\n", "x", "=", "F", ".", "dropout", "(", "x", ",", "p", "=", "self", ".", "dropout_out", ",", "training", "=", "self", ".", "training", ")", "\n", "assert", "list", "(", "x", ".", "size", "(", ")", ")", "==", "[", "seqlen", ",", "bsz", ",", "self", ".", "output_units", "]", "\n", "\n", "if", "self", ".", "bidirectional", ":", "\n", "\n", "            ", "def", "combine_bidir", "(", "outs", ")", ":", "\n", "                ", "out", "=", "outs", ".", "view", "(", "self", ".", "num_layers", ",", "2", ",", "bsz", ",", "-", "1", ")", ".", "transpose", "(", "1", ",", "2", ")", ".", "contiguous", "(", ")", "\n", "return", "out", ".", "view", "(", "self", ".", "num_layers", ",", "bsz", ",", "-", "1", ")", "\n", "\n", "", "final_hiddens", "=", "combine_bidir", "(", "final_hiddens", ")", "\n", "final_cells", "=", "combine_bidir", "(", "final_cells", ")", "\n", "\n", "", "encoder_padding_mask", "=", "src_tokens", ".", "eq", "(", "self", ".", "padding_idx", ")", ".", "t", "(", ")", "\n", "\n", "return", "{", "\n", "'encoder_out'", ":", "(", "x", ",", "final_hiddens", ",", "final_cells", ")", ",", "\n", "'encoder_padding_mask'", ":", "encoder_padding_mask", "if", "encoder_padding_mask", ".", "any", "(", ")", "else", "None", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.lstm.LSTMEncoder.reorder_encoder_out": [[252, 261], ["tuple", "encoder_out[].index_select", "eo.index_select"], "methods", ["None"], ["", "def", "reorder_encoder_out", "(", "self", ",", "encoder_out", ",", "new_order", ")", ":", "\n", "        ", "encoder_out", "[", "'encoder_out'", "]", "=", "tuple", "(", "\n", "eo", ".", "index_select", "(", "1", ",", "new_order", ")", "\n", "for", "eo", "in", "encoder_out", "[", "'encoder_out'", "]", "\n", ")", "\n", "if", "encoder_out", "[", "'encoder_padding_mask'", "]", "is", "not", "None", ":", "\n", "            ", "encoder_out", "[", "'encoder_padding_mask'", "]", "=", "encoder_out", "[", "'encoder_padding_mask'", "]", ".", "index_select", "(", "1", ",", "new_order", ")", "\n", "", "return", "encoder_out", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.lstm.LSTMEncoder.max_positions": [[262, 265], ["int"], "methods", ["None"], ["", "def", "max_positions", "(", "self", ")", ":", "\n", "        ", "\"\"\"Maximum input length supported by the encoder.\"\"\"", "\n", "return", "int", "(", "1e5", ")", "# an arbitrary large number", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.lstm.AttentionLayer.__init__": [[268, 273], ["torch.Module.__init__", "lstm.Linear", "lstm.Linear"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.dummy_dictionary.DummyDictionary.__init__", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.modules.transformer_layer.Linear", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.modules.transformer_layer.Linear"], ["    ", "def", "__init__", "(", "self", ",", "input_embed_dim", ",", "source_embed_dim", ",", "output_embed_dim", ",", "bias", "=", "False", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "input_proj", "=", "Linear", "(", "input_embed_dim", ",", "source_embed_dim", ",", "bias", "=", "bias", ")", "\n", "self", ".", "output_proj", "=", "Linear", "(", "input_embed_dim", "+", "source_embed_dim", ",", "output_embed_dim", ",", "bias", "=", "bias", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.lstm.AttentionLayer.forward": [[274, 298], ["lstm.AttentionLayer.input_proj", "torch.softmax", "torch.softmax", "torch.softmax", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "attn_scores.float().masked_fill_().type_as.float().masked_fill_().type_as.float().masked_fill_().type_as", "lstm.AttentionLayer.output_proj", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.tanh.unsqueeze", "torch.tanh.unsqueeze", "torch.tanh.unsqueeze", "attn_scores.float().masked_fill_().type_as.float().masked_fill_().type_as.float().masked_fill_", "attn_scores.float().masked_fill_().type_as.float().masked_fill_().type_as.unsqueeze", "float", "attn_scores.float().masked_fill_().type_as.float().masked_fill_().type_as.float"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.utils.softmax", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.utils.softmax", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.utils.softmax"], ["", "def", "forward", "(", "self", ",", "input", ",", "source_hids", ",", "encoder_padding_mask", ")", ":", "\n", "# input: bsz x input_embed_dim", "\n", "# source_hids: srclen x bsz x source_embed_dim", "\n", "\n", "# x: bsz x source_embed_dim", "\n", "        ", "x", "=", "self", ".", "input_proj", "(", "input", ")", "\n", "\n", "# compute attention", "\n", "attn_scores", "=", "(", "source_hids", "*", "x", ".", "unsqueeze", "(", "0", ")", ")", ".", "sum", "(", "dim", "=", "2", ")", "\n", "\n", "# don't attend over padding", "\n", "if", "encoder_padding_mask", "is", "not", "None", ":", "\n", "            ", "attn_scores", "=", "attn_scores", ".", "float", "(", ")", ".", "masked_fill_", "(", "\n", "encoder_padding_mask", ",", "\n", "float", "(", "'-inf'", ")", "\n", ")", ".", "type_as", "(", "attn_scores", ")", "# FP16 support: cast to float and back", "\n", "\n", "", "attn_scores", "=", "F", ".", "softmax", "(", "attn_scores", ",", "dim", "=", "0", ")", "# srclen x bsz", "\n", "\n", "# sum weighted sources", "\n", "x", "=", "(", "attn_scores", ".", "unsqueeze", "(", "2", ")", "*", "source_hids", ")", ".", "sum", "(", "dim", "=", "0", ")", "\n", "\n", "x", "=", "torch", ".", "tanh", "(", "self", ".", "output_proj", "(", "torch", ".", "cat", "(", "(", "x", ",", "input", ")", ",", "dim", "=", "1", ")", ")", ")", "\n", "return", "x", ",", "attn_scores", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.lstm.LSTMDecoder.__init__": [[302, 344], ["fairseq.models.FairseqIncrementalDecoder.__init__", "len", "dictionary.pad", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "lstm.Embedding", "lstm.Linear", "lstm.Linear", "lstm.AttentionLayer", "lstm.Linear", "lstm.LSTMCell", "lstm.Linear", "range"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.dummy_dictionary.DummyDictionary.__init__", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.dummy_dictionary.DummyDictionary.pad", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.transformer.Embedding", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.modules.transformer_layer.Linear", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.modules.transformer_layer.Linear", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.modules.transformer_layer.Linear", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.lstm.LSTMCell", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.modules.transformer_layer.Linear"], ["def", "__init__", "(", "\n", "self", ",", "dictionary", ",", "embed_dim", "=", "512", ",", "hidden_size", "=", "512", ",", "out_embed_dim", "=", "512", ",", "\n", "num_layers", "=", "1", ",", "dropout_in", "=", "0.1", ",", "dropout_out", "=", "0.1", ",", "attention", "=", "True", ",", "\n", "encoder_output_units", "=", "512", ",", "pretrained_embed", "=", "None", ",", "\n", "share_input_output_embed", "=", "False", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "dictionary", ")", "\n", "self", ".", "dropout_in", "=", "dropout_in", "\n", "self", ".", "dropout_out", "=", "dropout_out", "\n", "self", ".", "hidden_size", "=", "hidden_size", "\n", "self", ".", "share_input_output_embed", "=", "share_input_output_embed", "\n", "self", ".", "need_attn", "=", "True", "\n", "\n", "num_embeddings", "=", "len", "(", "dictionary", ")", "\n", "padding_idx", "=", "dictionary", ".", "pad", "(", ")", "\n", "if", "pretrained_embed", "is", "None", ":", "\n", "            ", "self", ".", "embed_tokens", "=", "Embedding", "(", "num_embeddings", ",", "embed_dim", ",", "padding_idx", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "embed_tokens", "=", "pretrained_embed", "\n", "\n", "", "self", ".", "encoder_output_units", "=", "encoder_output_units", "\n", "if", "encoder_output_units", "!=", "hidden_size", ":", "\n", "            ", "self", ".", "encoder_hidden_proj", "=", "Linear", "(", "encoder_output_units", ",", "hidden_size", ")", "\n", "self", ".", "encoder_cell_proj", "=", "Linear", "(", "encoder_output_units", ",", "hidden_size", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "encoder_hidden_proj", "=", "self", ".", "encoder_cell_proj", "=", "None", "\n", "", "self", ".", "layers", "=", "nn", ".", "ModuleList", "(", "[", "\n", "LSTMCell", "(", "\n", "input_size", "=", "hidden_size", "+", "embed_dim", "if", "layer", "==", "0", "else", "hidden_size", ",", "\n", "hidden_size", "=", "hidden_size", ",", "\n", ")", "\n", "for", "layer", "in", "range", "(", "num_layers", ")", "\n", "]", ")", "\n", "if", "attention", ":", "\n", "# TODO make bias configurable", "\n", "            ", "self", ".", "attention", "=", "AttentionLayer", "(", "hidden_size", ",", "encoder_output_units", ",", "hidden_size", ",", "bias", "=", "False", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "attention", "=", "None", "\n", "", "if", "hidden_size", "!=", "out_embed_dim", ":", "\n", "            ", "self", ".", "additional_fc", "=", "Linear", "(", "hidden_size", ",", "out_embed_dim", ")", "\n", "", "elif", "not", "self", ".", "share_input_output_embed", ":", "\n", "            ", "self", ".", "fc_out", "=", "Linear", "(", "out_embed_dim", ",", "num_embeddings", ",", "dropout", "=", "dropout_out", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.lstm.LSTMDecoder.forward": [[345, 350], ["lstm.LSTMDecoder.extract_features", "lstm.LSTMDecoder.output_layer"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.transformer.TransformerDecoder.extract_features", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.transformer.TransformerDecoder.output_layer"], ["", "", "def", "forward", "(", "self", ",", "prev_output_tokens", ",", "encoder_out", ",", "incremental_state", "=", "None", ")", ":", "\n", "        ", "x", ",", "attn_scores", "=", "self", ".", "extract_features", "(", "\n", "prev_output_tokens", ",", "encoder_out", ",", "incremental_state", "\n", ")", "\n", "return", "self", ".", "output_layer", "(", "x", ")", ",", "attn_scores", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.lstm.LSTMDecoder.extract_features": [[351, 440], ["prev_output_tokens.size", "encoder_outs.size", "lstm.LSTMDecoder.embed_tokens", "torch.dropout", "torch.dropout", "torch.dropout", "torch.dropout.transpose", "fairseq.utils.get_incremental_state", "torch.dropout.new_zeros", "range", "fairseq.utils.set_incremental_state", "torch.cat().view", "torch.cat().view", "torch.cat().view", "torch.cat().view", "torch.cat().view", "torch.cat().view", "torch.cat().view", "torch.cat().view", "torch.cat().view", "torch.dropout.transpose", "hasattr", "len", "torch.dropout.new_zeros", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "enumerate", "torch.dropout", "torch.dropout", "torch.dropout", "outs.append", "lstm.LSTMDecoder.additional_fc", "torch.dropout", "torch.dropout", "torch.dropout", "attn_scores.transpose.transpose.transpose", "rnn", "torch.dropout", "torch.dropout", "torch.dropout", "lstm.LSTMDecoder.attention", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "range", "range", "lstm.LSTMDecoder.encoder_hidden_proj", "lstm.LSTMDecoder.encoder_cell_proj"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.fairseq_dataset.FairseqDataset.size", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.fairseq_dataset.FairseqDataset.size", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.utils.get_incremental_state", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.utils.set_incremental_state"], ["", "def", "extract_features", "(", "\n", "self", ",", "prev_output_tokens", ",", "encoder_out", ",", "incremental_state", "=", "None", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Similar to *forward* but only return features.\n        \"\"\"", "\n", "encoder_padding_mask", "=", "encoder_out", "[", "'encoder_padding_mask'", "]", "\n", "encoder_out", "=", "encoder_out", "[", "'encoder_out'", "]", "\n", "\n", "if", "incremental_state", "is", "not", "None", ":", "\n", "            ", "prev_output_tokens", "=", "prev_output_tokens", "[", ":", ",", "-", "1", ":", "]", "\n", "", "bsz", ",", "seqlen", "=", "prev_output_tokens", ".", "size", "(", ")", "\n", "\n", "# get outputs from encoder", "\n", "encoder_outs", ",", "encoder_hiddens", ",", "encoder_cells", "=", "encoder_out", "[", ":", "3", "]", "\n", "srclen", "=", "encoder_outs", ".", "size", "(", "0", ")", "\n", "\n", "# embed tokens", "\n", "x", "=", "self", ".", "embed_tokens", "(", "prev_output_tokens", ")", "\n", "x", "=", "F", ".", "dropout", "(", "x", ",", "p", "=", "self", ".", "dropout_in", ",", "training", "=", "self", ".", "training", ")", "\n", "\n", "# B x T x C -> T x B x C", "\n", "x", "=", "x", ".", "transpose", "(", "0", ",", "1", ")", "\n", "\n", "# initialize previous states (or get from cache during incremental generation)", "\n", "cached_state", "=", "utils", ".", "get_incremental_state", "(", "self", ",", "incremental_state", ",", "'cached_state'", ")", "\n", "if", "cached_state", "is", "not", "None", ":", "\n", "            ", "prev_hiddens", ",", "prev_cells", ",", "input_feed", "=", "cached_state", "\n", "", "else", ":", "\n", "            ", "num_layers", "=", "len", "(", "self", ".", "layers", ")", "\n", "prev_hiddens", "=", "[", "encoder_hiddens", "[", "i", "]", "for", "i", "in", "range", "(", "num_layers", ")", "]", "\n", "prev_cells", "=", "[", "encoder_cells", "[", "i", "]", "for", "i", "in", "range", "(", "num_layers", ")", "]", "\n", "if", "self", ".", "encoder_hidden_proj", "is", "not", "None", ":", "\n", "                ", "prev_hiddens", "=", "[", "self", ".", "encoder_hidden_proj", "(", "x", ")", "for", "x", "in", "prev_hiddens", "]", "\n", "prev_cells", "=", "[", "self", ".", "encoder_cell_proj", "(", "x", ")", "for", "x", "in", "prev_cells", "]", "\n", "", "input_feed", "=", "x", ".", "new_zeros", "(", "bsz", ",", "self", ".", "hidden_size", ")", "\n", "\n", "", "attn_scores", "=", "x", ".", "new_zeros", "(", "srclen", ",", "seqlen", ",", "bsz", ")", "\n", "outs", "=", "[", "]", "\n", "for", "j", "in", "range", "(", "seqlen", ")", ":", "\n", "# input feeding: concatenate context vector from previous time step", "\n", "            ", "input", "=", "torch", ".", "cat", "(", "(", "x", "[", "j", ",", ":", ",", ":", "]", ",", "input_feed", ")", ",", "dim", "=", "1", ")", "\n", "\n", "for", "i", ",", "rnn", "in", "enumerate", "(", "self", ".", "layers", ")", ":", "\n", "# recurrent cell", "\n", "                ", "hidden", ",", "cell", "=", "rnn", "(", "input", ",", "(", "prev_hiddens", "[", "i", "]", ",", "prev_cells", "[", "i", "]", ")", ")", "\n", "\n", "# hidden state becomes the input to the next layer", "\n", "input", "=", "F", ".", "dropout", "(", "hidden", ",", "p", "=", "self", ".", "dropout_out", ",", "training", "=", "self", ".", "training", ")", "\n", "\n", "# save state for next time step", "\n", "prev_hiddens", "[", "i", "]", "=", "hidden", "\n", "prev_cells", "[", "i", "]", "=", "cell", "\n", "\n", "# apply attention using the last layer's hidden state", "\n", "", "if", "self", ".", "attention", "is", "not", "None", ":", "\n", "                ", "out", ",", "attn_scores", "[", ":", ",", "j", ",", ":", "]", "=", "self", ".", "attention", "(", "hidden", ",", "encoder_outs", ",", "encoder_padding_mask", ")", "\n", "", "else", ":", "\n", "                ", "out", "=", "hidden", "\n", "", "out", "=", "F", ".", "dropout", "(", "out", ",", "p", "=", "self", ".", "dropout_out", ",", "training", "=", "self", ".", "training", ")", "\n", "\n", "# input feeding", "\n", "input_feed", "=", "out", "\n", "\n", "# save final output", "\n", "outs", ".", "append", "(", "out", ")", "\n", "\n", "# cache previous states (no-op except during incremental generation)", "\n", "", "utils", ".", "set_incremental_state", "(", "\n", "self", ",", "incremental_state", ",", "'cached_state'", ",", "\n", "(", "prev_hiddens", ",", "prev_cells", ",", "input_feed", ")", ",", "\n", ")", "\n", "\n", "# collect outputs across time steps", "\n", "x", "=", "torch", ".", "cat", "(", "outs", ",", "dim", "=", "0", ")", ".", "view", "(", "seqlen", ",", "bsz", ",", "self", ".", "hidden_size", ")", "\n", "\n", "# T x B x C -> B x T x C", "\n", "x", "=", "x", ".", "transpose", "(", "1", ",", "0", ")", "\n", "\n", "if", "hasattr", "(", "self", ",", "'additional_fc'", ")", ":", "\n", "            ", "x", "=", "self", ".", "additional_fc", "(", "x", ")", "\n", "x", "=", "F", ".", "dropout", "(", "x", ",", "p", "=", "self", ".", "dropout_out", ",", "training", "=", "self", ".", "training", ")", "\n", "\n", "# srclen x tgtlen x bsz -> bsz x tgtlen x srclen", "\n", "", "if", "not", "self", ".", "training", "and", "self", ".", "need_attn", ":", "\n", "            ", "attn_scores", "=", "attn_scores", ".", "transpose", "(", "0", ",", "2", ")", "\n", "", "else", ":", "\n", "            ", "attn_scores", "=", "None", "\n", "", "return", "x", ",", "attn_scores", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.lstm.LSTMDecoder.output_layer": [[441, 448], ["torch.linear", "torch.linear", "torch.linear", "lstm.LSTMDecoder.fc_out"], "methods", ["None"], ["", "def", "output_layer", "(", "self", ",", "x", ")", ":", "\n", "        ", "\"\"\"Project features to the vocabulary size.\"\"\"", "\n", "if", "self", ".", "share_input_output_embed", ":", "\n", "            ", "x", "=", "F", ".", "linear", "(", "x", ",", "self", ".", "embed_tokens", ".", "weight", ")", "\n", "", "else", ":", "\n", "            ", "x", "=", "self", ".", "fc_out", "(", "x", ")", "\n", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.lstm.LSTMDecoder.reorder_incremental_state": [[449, 462], ["super().reorder_incremental_state", "fairseq.utils.get_incremental_state", "tuple", "fairseq.utils.set_incremental_state", "isinstance", "state.index_select", "map", "lstm.LSTMDecoder.reorder_incremental_state.reorder_state"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.modules.multihead_attention.MultiheadAttention.reorder_incremental_state", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.utils.get_incremental_state", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.utils.set_incremental_state"], ["", "def", "reorder_incremental_state", "(", "self", ",", "incremental_state", ",", "new_order", ")", ":", "\n", "        ", "super", "(", ")", ".", "reorder_incremental_state", "(", "incremental_state", ",", "new_order", ")", "\n", "cached_state", "=", "utils", ".", "get_incremental_state", "(", "self", ",", "incremental_state", ",", "'cached_state'", ")", "\n", "if", "cached_state", "is", "None", ":", "\n", "            ", "return", "\n", "\n", "", "def", "reorder_state", "(", "state", ")", ":", "\n", "            ", "if", "isinstance", "(", "state", ",", "list", ")", ":", "\n", "                ", "return", "[", "reorder_state", "(", "state_i", ")", "for", "state_i", "in", "state", "]", "\n", "", "return", "state", ".", "index_select", "(", "0", ",", "new_order", ")", "\n", "\n", "", "new_state", "=", "tuple", "(", "map", "(", "reorder_state", ",", "cached_state", ")", ")", "\n", "utils", ".", "set_incremental_state", "(", "self", ",", "incremental_state", ",", "'cached_state'", ",", "new_state", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.lstm.LSTMDecoder.max_positions": [[463, 466], ["int"], "methods", ["None"], ["", "def", "max_positions", "(", "self", ")", ":", "\n", "        ", "\"\"\"Maximum output length supported by the decoder.\"\"\"", "\n", "return", "int", "(", "1e5", ")", "# an arbitrary large number", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.lstm.LSTMDecoder.make_generation_fast_": [[467, 469], ["None"], "methods", ["None"], ["", "def", "make_generation_fast_", "(", "self", ",", "need_attn", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "        ", "self", ".", "need_attn", "=", "need_attn", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.lstm.Embedding": [[471, 476], ["torch.Embedding", "torch.init.uniform_", "torch.init.constant_"], "function", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.transformer.Embedding"], ["", "", "def", "Embedding", "(", "num_embeddings", ",", "embedding_dim", ",", "padding_idx", ")", ":", "\n", "    ", "m", "=", "nn", ".", "Embedding", "(", "num_embeddings", ",", "embedding_dim", ",", "padding_idx", "=", "padding_idx", ")", "\n", "nn", ".", "init", ".", "uniform_", "(", "m", ".", "weight", ",", "-", "0.1", ",", "0.1", ")", "\n", "nn", ".", "init", ".", "constant_", "(", "m", ".", "weight", "[", "padding_idx", "]", ",", "0", ")", "\n", "return", "m", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.lstm.LSTM": [[478, 484], ["torch.LSTM", "nn.LSTM.named_parameters", "param.data.uniform_"], "function", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.lstm.LSTM"], ["", "def", "LSTM", "(", "input_size", ",", "hidden_size", ",", "**", "kwargs", ")", ":", "\n", "    ", "m", "=", "nn", ".", "LSTM", "(", "input_size", ",", "hidden_size", ",", "**", "kwargs", ")", "\n", "for", "name", ",", "param", "in", "m", ".", "named_parameters", "(", ")", ":", "\n", "        ", "if", "'weight'", "in", "name", "or", "'bias'", "in", "name", ":", "\n", "            ", "param", ".", "data", ".", "uniform_", "(", "-", "0.1", ",", "0.1", ")", "\n", "", "", "return", "m", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.lstm.LSTMCell": [[486, 492], ["torch.LSTMCell", "nn.LSTMCell.named_parameters", "param.data.uniform_"], "function", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.lstm.LSTMCell"], ["", "def", "LSTMCell", "(", "input_size", ",", "hidden_size", ",", "**", "kwargs", ")", ":", "\n", "    ", "m", "=", "nn", ".", "LSTMCell", "(", "input_size", ",", "hidden_size", ",", "**", "kwargs", ")", "\n", "for", "name", ",", "param", "in", "m", ".", "named_parameters", "(", ")", ":", "\n", "        ", "if", "'weight'", "in", "name", "or", "'bias'", "in", "name", ":", "\n", "            ", "param", ".", "data", ".", "uniform_", "(", "-", "0.1", ",", "0.1", ")", "\n", "", "", "return", "m", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.lstm.Linear": [[494, 501], ["torch.Linear", "nn.Linear.weight.data.uniform_", "nn.Linear.bias.data.uniform_"], "function", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.modules.transformer_layer.Linear"], ["", "def", "Linear", "(", "in_features", ",", "out_features", ",", "bias", "=", "True", ",", "dropout", "=", "0", ")", ":", "\n", "    ", "\"\"\"Linear layer (input: N x T x C)\"\"\"", "\n", "m", "=", "nn", ".", "Linear", "(", "in_features", ",", "out_features", ",", "bias", "=", "bias", ")", "\n", "m", ".", "weight", ".", "data", ".", "uniform_", "(", "-", "0.1", ",", "0.1", ")", "\n", "if", "bias", ":", "\n", "        ", "m", ".", "bias", ".", "data", ".", "uniform_", "(", "-", "0.1", ",", "0.1", ")", "\n", "", "return", "m", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.lstm.base_architecture": [[503, 525], ["fairseq.models.register_model_architecture", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr"], "function", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.__init__.register_model_architecture"], ["", "@", "register_model_architecture", "(", "'lstm'", ",", "'lstm'", ")", "\n", "def", "base_architecture", "(", "args", ")", ":", "\n", "    ", "args", ".", "dropout", "=", "getattr", "(", "args", ",", "'dropout'", ",", "0.1", ")", "\n", "args", ".", "encoder_embed_dim", "=", "getattr", "(", "args", ",", "'encoder_embed_dim'", ",", "512", ")", "\n", "args", ".", "encoder_embed_path", "=", "getattr", "(", "args", ",", "'encoder_embed_path'", ",", "None", ")", "\n", "args", ".", "encoder_freeze_embed", "=", "getattr", "(", "args", ",", "'encoder_freeze_embed'", ",", "False", ")", "\n", "args", ".", "encoder_hidden_size", "=", "getattr", "(", "args", ",", "'encoder_hidden_size'", ",", "args", ".", "encoder_embed_dim", ")", "\n", "args", ".", "encoder_layers", "=", "getattr", "(", "args", ",", "'encoder_layers'", ",", "1", ")", "\n", "args", ".", "encoder_bidirectional", "=", "getattr", "(", "args", ",", "'encoder_bidirectional'", ",", "False", ")", "\n", "args", ".", "encoder_dropout_in", "=", "getattr", "(", "args", ",", "'encoder_dropout_in'", ",", "args", ".", "dropout", ")", "\n", "args", ".", "encoder_dropout_out", "=", "getattr", "(", "args", ",", "'encoder_dropout_out'", ",", "args", ".", "dropout", ")", "\n", "args", ".", "decoder_embed_dim", "=", "getattr", "(", "args", ",", "'decoder_embed_dim'", ",", "512", ")", "\n", "args", ".", "decoder_embed_path", "=", "getattr", "(", "args", ",", "'decoder_embed_path'", ",", "None", ")", "\n", "args", ".", "decoder_freeze_embed", "=", "getattr", "(", "args", ",", "'decoder_freeze_embed'", ",", "False", ")", "\n", "args", ".", "decoder_hidden_size", "=", "getattr", "(", "args", ",", "'decoder_hidden_size'", ",", "args", ".", "decoder_embed_dim", ")", "\n", "args", ".", "decoder_layers", "=", "getattr", "(", "args", ",", "'decoder_layers'", ",", "1", ")", "\n", "args", ".", "decoder_out_embed_dim", "=", "getattr", "(", "args", ",", "'decoder_out_embed_dim'", ",", "512", ")", "\n", "args", ".", "decoder_attention", "=", "getattr", "(", "args", ",", "'decoder_attention'", ",", "'1'", ")", "\n", "args", ".", "decoder_dropout_in", "=", "getattr", "(", "args", ",", "'decoder_dropout_in'", ",", "args", ".", "dropout", ")", "\n", "args", ".", "decoder_dropout_out", "=", "getattr", "(", "args", ",", "'decoder_dropout_out'", ",", "args", ".", "dropout", ")", "\n", "args", ".", "share_decoder_input_output_embed", "=", "getattr", "(", "args", ",", "'share_decoder_input_output_embed'", ",", "False", ")", "\n", "args", ".", "share_all_embeddings", "=", "getattr", "(", "args", ",", "'share_all_embeddings'", ",", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.lstm.lstm_wiseman_iwslt_de_en": [[527, 538], ["fairseq.models.register_model_architecture", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "lstm.base_architecture"], "function", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.__init__.register_model_architecture", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.lstm.base_architecture"], ["", "@", "register_model_architecture", "(", "'lstm'", ",", "'lstm_wiseman_iwslt_de_en'", ")", "\n", "def", "lstm_wiseman_iwslt_de_en", "(", "args", ")", ":", "\n", "    ", "args", ".", "dropout", "=", "getattr", "(", "args", ",", "'dropout'", ",", "0.1", ")", "\n", "args", ".", "encoder_embed_dim", "=", "getattr", "(", "args", ",", "'encoder_embed_dim'", ",", "256", ")", "\n", "args", ".", "encoder_dropout_in", "=", "getattr", "(", "args", ",", "'encoder_dropout_in'", ",", "0", ")", "\n", "args", ".", "encoder_dropout_out", "=", "getattr", "(", "args", ",", "'encoder_dropout_out'", ",", "0", ")", "\n", "args", ".", "decoder_embed_dim", "=", "getattr", "(", "args", ",", "'decoder_embed_dim'", ",", "256", ")", "\n", "args", ".", "decoder_out_embed_dim", "=", "getattr", "(", "args", ",", "'decoder_out_embed_dim'", ",", "256", ")", "\n", "args", ".", "decoder_dropout_in", "=", "getattr", "(", "args", ",", "'decoder_dropout_in'", ",", "0", ")", "\n", "args", ".", "decoder_dropout_out", "=", "getattr", "(", "args", ",", "'decoder_dropout_out'", ",", "args", ".", "dropout", ")", "\n", "base_architecture", "(", "args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.lstm.lstm_luong_wmt_en_de": [[540, 550], ["fairseq.models.register_model_architecture", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "lstm.base_architecture"], "function", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.__init__.register_model_architecture", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.lstm.base_architecture"], ["", "@", "register_model_architecture", "(", "'lstm'", ",", "'lstm_luong_wmt_en_de'", ")", "\n", "def", "lstm_luong_wmt_en_de", "(", "args", ")", ":", "\n", "    ", "args", ".", "encoder_embed_dim", "=", "getattr", "(", "args", ",", "'encoder_embed_dim'", ",", "1000", ")", "\n", "args", ".", "encoder_layers", "=", "getattr", "(", "args", ",", "'encoder_layers'", ",", "4", ")", "\n", "args", ".", "encoder_dropout_out", "=", "getattr", "(", "args", ",", "'encoder_dropout_out'", ",", "0", ")", "\n", "args", ".", "decoder_embed_dim", "=", "getattr", "(", "args", ",", "'decoder_embed_dim'", ",", "1000", ")", "\n", "args", ".", "decoder_layers", "=", "getattr", "(", "args", ",", "'decoder_layers'", ",", "4", ")", "\n", "args", ".", "decoder_out_embed_dim", "=", "getattr", "(", "args", ",", "'decoder_out_embed_dim'", ",", "1000", ")", "\n", "args", ".", "decoder_dropout_out", "=", "getattr", "(", "args", ",", "'decoder_dropout_out'", ",", "0", ")", "\n", "base_architecture", "(", "args", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.fairseq_model.BaseFairseqModel.__init__": [[24, 27], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.dummy_dictionary.DummyDictionary.__init__"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "_is_generation_fast", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.fairseq_model.BaseFairseqModel.add_args": [[28, 32], ["None"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "add_args", "(", "parser", ")", ":", "\n", "        ", "\"\"\"Add model-specific arguments to the parser.\"\"\"", "\n", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.fairseq_model.BaseFairseqModel.build_model": [[33, 37], ["NotImplementedError"], "methods", ["None"], ["", "@", "classmethod", "\n", "def", "build_model", "(", "cls", ",", "args", ",", "task", ")", ":", "\n", "        ", "\"\"\"Build a new model instance.\"\"\"", "\n", "raise", "NotImplementedError", "(", "'Model must implement the build_model method'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.fairseq_model.BaseFairseqModel.get_targets": [[38, 41], ["None"], "methods", ["None"], ["", "def", "get_targets", "(", "self", ",", "sample", ",", "net_output", ")", ":", "\n", "        ", "\"\"\"Get targets from either the sample or the net's output.\"\"\"", "\n", "return", "sample", "[", "'target'", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.fairseq_model.BaseFairseqModel.get_normalized_probs": [[42, 53], ["hasattr", "fairseq_model.BaseFairseqModel.decoder.get_normalized_probs", "torch.is_tensor", "torch.is_tensor", "torch.is_tensor", "torch.is_tensor", "torch.is_tensor", "torch.is_tensor", "torch.is_tensor", "torch.is_tensor", "torch.is_tensor", "net_output.float", "torch.log_softmax", "torch.log_softmax", "torch.log_softmax", "torch.softmax", "torch.softmax", "torch.softmax"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.fairseq_decoder.FairseqDecoder.get_normalized_probs", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.utils.log_softmax", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.utils.log_softmax", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.utils.log_softmax", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.utils.softmax", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.utils.softmax", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.utils.softmax"], ["", "def", "get_normalized_probs", "(", "self", ",", "net_output", ",", "log_probs", ",", "sample", "=", "None", ")", ":", "\n", "        ", "\"\"\"Get normalized probabilities (or log probs) from a net's output.\"\"\"", "\n", "if", "hasattr", "(", "self", ",", "'decoder'", ")", ":", "\n", "            ", "return", "self", ".", "decoder", ".", "get_normalized_probs", "(", "net_output", ",", "log_probs", ",", "sample", ")", "\n", "", "elif", "torch", ".", "is_tensor", "(", "net_output", ")", ":", "\n", "            ", "logits", "=", "net_output", ".", "float", "(", ")", "\n", "if", "log_probs", ":", "\n", "                ", "return", "F", ".", "log_softmax", "(", "logits", ",", "dim", "=", "-", "1", ")", "\n", "", "else", ":", "\n", "                ", "return", "F", ".", "softmax", "(", "logits", ",", "dim", "=", "-", "1", ")", "\n", "", "", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.fairseq_model.BaseFairseqModel.extract_features": [[54, 57], ["fairseq_model.BaseFairseqModel."], "methods", ["None"], ["", "def", "extract_features", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"Similar to *forward* but only return features.\"\"\"", "\n", "return", "self", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.fairseq_model.BaseFairseqModel.max_positions": [[58, 61], ["None"], "methods", ["None"], ["", "def", "max_positions", "(", "self", ")", ":", "\n", "        ", "\"\"\"Maximum length supported by the model.\"\"\"", "\n", "return", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.fairseq_model.BaseFairseqModel.load_state_dict": [[62, 72], ["fairseq_model.BaseFairseqModel.upgrade_state_dict", "fairseq.checkpoint_utils.prune_state_dict", "super().load_state_dict"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.fairseq_decoder.FairseqDecoder.upgrade_state_dict", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.checkpoint_utils.prune_state_dict", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.iterators.EpochBatchIterator.load_state_dict"], ["", "def", "load_state_dict", "(", "self", ",", "state_dict", ",", "strict", "=", "True", ",", "args", "=", "None", ")", ":", "\n", "        ", "\"\"\"Copies parameters and buffers from *state_dict* into this module and\n        its descendants.\n\n        Overrides the method in :class:`nn.Module`. Compared with that method\n        this additionally \"upgrades\" *state_dicts* from old checkpoints.\n        \"\"\"", "\n", "self", ".", "upgrade_state_dict", "(", "state_dict", ")", "\n", "new_state_dict", "=", "prune_state_dict", "(", "state_dict", ",", "args", ")", "\n", "return", "super", "(", ")", ".", "load_state_dict", "(", "new_state_dict", ",", "strict", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.fairseq_model.BaseFairseqModel.upgrade_state_dict": [[73, 76], ["fairseq_model.BaseFairseqModel.upgrade_state_dict_named"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.modules.transformer_layer.TransformerEncoderLayer.upgrade_state_dict_named"], ["", "def", "upgrade_state_dict", "(", "self", ",", "state_dict", ")", ":", "\n", "        ", "\"\"\"Upgrade old state dicts to work with newer code.\"\"\"", "\n", "self", ".", "upgrade_state_dict_named", "(", "state_dict", ",", "''", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.fairseq_model.BaseFairseqModel.upgrade_state_dict_named": [[77, 99], ["fairseq_model.BaseFairseqModel.upgrade_state_dict_named.do_upgrade"], "methods", ["None"], ["", "def", "upgrade_state_dict_named", "(", "self", ",", "state_dict", ",", "name", ")", ":", "\n", "        ", "\"\"\"Upgrade old state dicts to work with newer code.\n\n        Args:\n            state_dict (dict): state dictionary to upgrade, in place\n            name (str): the state dict key corresponding to the current module\n        \"\"\"", "\n", "assert", "state_dict", "is", "not", "None", "\n", "\n", "def", "do_upgrade", "(", "m", ",", "prefix", ")", ":", "\n", "            ", "if", "len", "(", "prefix", ")", ">", "0", ":", "\n", "                ", "prefix", "+=", "'.'", "\n", "\n", "", "for", "n", ",", "c", "in", "m", ".", "named_children", "(", ")", ":", "\n", "                ", "name", "=", "prefix", "+", "n", "\n", "if", "hasattr", "(", "c", ",", "'upgrade_state_dict_named'", ")", ":", "\n", "                    ", "c", ".", "upgrade_state_dict_named", "(", "state_dict", ",", "name", ")", "\n", "", "elif", "hasattr", "(", "c", ",", "'upgrade_state_dict'", ")", ":", "\n", "                    ", "c", ".", "upgrade_state_dict", "(", "state_dict", ")", "\n", "", "do_upgrade", "(", "c", ",", "name", ")", "\n", "\n", "", "", "do_upgrade", "(", "self", ",", "name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.fairseq_model.BaseFairseqModel.make_generation_fast_": [[100, 132], ["fairseq_model.BaseFairseqModel.apply", "set", "fairseq_model.BaseFairseqModel.apply", "fairseq_model.BaseFairseqModel.eval", "torch.utils.remove_weight_norm", "torch.utils.remove_weight_norm", "torch.utils.remove_weight_norm", "hasattr", "set.add", "module.make_generation_fast_", "RuntimeError"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.utils.eval", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.modules.transformer_layer.TransformerDecoderLayer.make_generation_fast_"], ["", "def", "make_generation_fast_", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"Optimize model for faster generation.\"\"\"", "\n", "if", "self", ".", "_is_generation_fast", ":", "\n", "            ", "return", "# only apply once", "\n", "", "self", ".", "_is_generation_fast", "=", "True", "\n", "\n", "# remove weight norm from all modules in the network", "\n", "def", "apply_remove_weight_norm", "(", "module", ")", ":", "\n", "            ", "try", ":", "\n", "                ", "nn", ".", "utils", ".", "remove_weight_norm", "(", "module", ")", "\n", "", "except", "ValueError", ":", "# this module didn't have weight norm", "\n", "                ", "return", "\n", "\n", "", "", "self", ".", "apply", "(", "apply_remove_weight_norm", ")", "\n", "\n", "seen", "=", "set", "(", ")", "\n", "\n", "def", "apply_make_generation_fast_", "(", "module", ")", ":", "\n", "            ", "if", "module", "!=", "self", "and", "hasattr", "(", "module", ",", "'make_generation_fast_'", ")", "and", "module", "not", "in", "seen", ":", "\n", "                ", "seen", ".", "add", "(", "module", ")", "\n", "module", ".", "make_generation_fast_", "(", "**", "kwargs", ")", "\n", "\n", "", "", "self", ".", "apply", "(", "apply_make_generation_fast_", ")", "\n", "\n", "def", "train", "(", "mode", "=", "True", ")", ":", "\n", "            ", "if", "mode", ":", "\n", "                ", "raise", "RuntimeError", "(", "'cannot train after make_generation_fast'", ")", "\n", "\n", "# this model should no longer be used for training", "\n", "", "", "self", ".", "eval", "(", ")", "\n", "self", ".", "train", "=", "train", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.fairseq_model.BaseFairseqModel.prepare_for_onnx_export_": [[133, 144], ["set", "fairseq_model.BaseFairseqModel.apply", "hasattr", "set.add", "module.prepare_for_onnx_export_"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.modules.transformer_layer.TransformerDecoderLayer.prepare_for_onnx_export_"], ["", "def", "prepare_for_onnx_export_", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"Make model exportable via ONNX trace.\"\"\"", "\n", "seen", "=", "set", "(", ")", "\n", "\n", "def", "apply_prepare_for_onnx_export_", "(", "module", ")", ":", "\n", "            ", "if", "module", "!=", "self", "and", "hasattr", "(", "module", ",", "'prepare_for_onnx_export_'", ")", "and", "module", "not", "in", "seen", ":", "\n", "                ", "seen", ".", "add", "(", "module", ")", "\n", "module", ".", "prepare_for_onnx_export_", "(", "**", "kwargs", ")", "\n", "\n", "", "", "self", ".", "apply", "(", "apply_prepare_for_onnx_export_", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.fairseq_model.BaseFairseqModel.hub_models": [[145, 148], ["None"], "methods", ["None"], ["", "@", "classmethod", "\n", "def", "hub_models", "(", "cls", ")", ":", "\n", "        ", "return", "{", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.fairseq_model.FairseqEncoderDecoderModel.__init__": [[158, 165], ["fairseq_model.BaseFairseqModel.__init__", "isinstance", "isinstance"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.dummy_dictionary.DummyDictionary.__init__"], ["def", "__init__", "(", "self", ",", "encoder", ",", "decoder", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "encoder", "=", "encoder", "\n", "self", ".", "decoder", "=", "decoder", "\n", "assert", "isinstance", "(", "self", ".", "encoder", ",", "FairseqEncoder", ")", "\n", "assert", "isinstance", "(", "self", ".", "decoder", ",", "FairseqDecoder", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.fairseq_model.FairseqEncoderDecoderModel.forward": [[166, 192], ["fairseq_model.FairseqEncoderDecoderModel.encoder", "fairseq_model.FairseqEncoderDecoderModel.decoder"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.fairseq_model.FairseqMultiModel.encoder", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.fairseq_model.FairseqMultiModel.decoder"], ["", "def", "forward", "(", "self", ",", "src_tokens", ",", "src_lengths", ",", "prev_output_tokens", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"\n        Run the forward pass for an encoder-decoder model.\n\n        First feed a batch of source tokens through the encoder. Then, feed the\n        encoder output and previous decoder outputs (i.e., teacher forcing) to\n        the decoder to produce the next outputs::\n\n            encoder_out = self.encoder(src_tokens, src_lengths)\n            return self.decoder(prev_output_tokens, encoder_out)\n\n        Args:\n            src_tokens (LongTensor): tokens in the source language of shape\n                `(batch, src_len)`\n            src_lengths (LongTensor): source sentence lengths of shape `(batch)`\n            prev_output_tokens (LongTensor): previous decoder outputs of shape\n                `(batch, tgt_len)`, for teacher forcing\n\n        Returns:\n            tuple:\n                - the decoder's output of shape `(batch, tgt_len, vocab)`\n                - a dictionary with any model-specific outputs\n        \"\"\"", "\n", "encoder_out", "=", "self", ".", "encoder", "(", "src_tokens", ",", "src_lengths", "=", "src_lengths", ",", "**", "kwargs", ")", "\n", "decoder_out", "=", "self", ".", "decoder", "(", "prev_output_tokens", ",", "encoder_out", "=", "encoder_out", ",", "**", "kwargs", ")", "\n", "return", "decoder_out", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.fairseq_model.FairseqEncoderDecoderModel.forward_decoder": [[193, 195], ["fairseq_model.FairseqEncoderDecoderModel.decoder"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.fairseq_model.FairseqMultiModel.decoder"], ["", "def", "forward_decoder", "(", "self", ",", "prev_output_tokens", ",", "**", "kwargs", ")", ":", "\n", "        ", "return", "self", ".", "decoder", "(", "prev_output_tokens", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.fairseq_model.FairseqEncoderDecoderModel.extract_features": [[196, 208], ["fairseq_model.FairseqEncoderDecoderModel.encoder", "fairseq_model.FairseqEncoderDecoderModel.decoder.extract_features"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.fairseq_model.FairseqMultiModel.encoder", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.transformer.TransformerDecoder.extract_features"], ["", "def", "extract_features", "(", "self", ",", "src_tokens", ",", "src_lengths", ",", "prev_output_tokens", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"\n        Similar to *forward* but only return features.\n\n        Returns:\n            tuple:\n                - the decoder's features of shape `(batch, tgt_len, embed_dim)`\n                - a dictionary with any model-specific outputs\n        \"\"\"", "\n", "encoder_out", "=", "self", ".", "encoder", "(", "src_tokens", ",", "src_lengths", "=", "src_lengths", ",", "**", "kwargs", ")", "\n", "features", "=", "self", ".", "decoder", ".", "extract_features", "(", "prev_output_tokens", ",", "encoder_out", "=", "encoder_out", ",", "**", "kwargs", ")", "\n", "return", "features", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.fairseq_model.FairseqEncoderDecoderModel.output_layer": [[209, 212], ["fairseq_model.FairseqEncoderDecoderModel.decoder.output_layer"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.transformer.TransformerDecoder.output_layer"], ["", "def", "output_layer", "(", "self", ",", "features", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"Project features to the default output size (typically vocabulary size).\"\"\"", "\n", "return", "self", ".", "decoder", ".", "output_layer", "(", "features", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.fairseq_model.FairseqEncoderDecoderModel.max_positions": [[213, 216], ["fairseq_model.FairseqEncoderDecoderModel.encoder.max_positions", "fairseq_model.FairseqEncoderDecoderModel.decoder.max_positions"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.tasks.fairseq_task.FairseqTask.max_positions", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.tasks.fairseq_task.FairseqTask.max_positions"], ["", "def", "max_positions", "(", "self", ")", ":", "\n", "        ", "\"\"\"Maximum length supported by the model.\"\"\"", "\n", "return", "(", "self", ".", "encoder", ".", "max_positions", "(", ")", ",", "self", ".", "decoder", ".", "max_positions", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.fairseq_model.FairseqEncoderDecoderModel.max_decoder_positions": [[217, 220], ["fairseq_model.FairseqEncoderDecoderModel.decoder.max_positions"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.tasks.fairseq_task.FairseqTask.max_positions"], ["", "def", "max_decoder_positions", "(", "self", ")", ":", "\n", "        ", "\"\"\"Maximum length supported by the decoder.\"\"\"", "\n", "return", "self", ".", "decoder", ".", "max_positions", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.fairseq_model.FairseqModel.__init__": [[224, 230], ["fairseq_model.FairseqEncoderDecoderModel.__init__", "fairseq.utils.deprecation_warning"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.dummy_dictionary.DummyDictionary.__init__", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.utils.deprecation_warning"], ["    ", "def", "__init__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "utils", ".", "deprecation_warning", "(", "\n", "'FairseqModel is deprecated, please use FairseqEncoderDecoderModel '", "\n", "'or BaseFairseqModel instead'", ",", "\n", "stacklevel", "=", "4", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.fairseq_model.FairseqMultiModel.__init__": [[236, 247], ["fairseq_model.BaseFairseqModel.__init__", "list", "torch.ModuleDict", "torch.ModuleDict", "torch.ModuleDict", "encoders.keys", "decoders.keys", "encoders.keys", "isinstance", "isinstance", "fairseq_model.FairseqModel"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.dummy_dictionary.DummyDictionary.__init__"], ["def", "__init__", "(", "self", ",", "encoders", ",", "decoders", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "assert", "encoders", ".", "keys", "(", ")", "==", "decoders", ".", "keys", "(", ")", "\n", "self", ".", "keys", "=", "list", "(", "encoders", ".", "keys", "(", ")", ")", "\n", "for", "key", "in", "self", ".", "keys", ":", "\n", "            ", "assert", "isinstance", "(", "encoders", "[", "key", "]", ",", "FairseqEncoder", ")", "\n", "assert", "isinstance", "(", "decoders", "[", "key", "]", ",", "FairseqDecoder", ")", "\n", "\n", "", "self", ".", "models", "=", "nn", ".", "ModuleDict", "(", "{", "\n", "key", ":", "FairseqModel", "(", "encoders", "[", "key", "]", ",", "decoders", "[", "key", "]", ")", "\n", "for", "key", "in", "self", ".", "keys", "\n", "}", ")", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.fairseq_model.FairseqMultiModel.build_shared_embeddings": [[249, 279], ["any", "build_embedding", "ValueError"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "build_shared_embeddings", "(", "\n", "dicts", ":", "Dict", "[", "str", ",", "DummyDictionary", "]", ",", "\n", "langs", ":", "List", "[", "str", "]", ",", "\n", "embed_dim", ":", "int", ",", "\n", "build_embedding", ":", "callable", ",", "\n", "pretrained_embed_path", ":", "Optional", "[", "str", "]", "=", "None", ",", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Helper function to build shared embeddings for a set of languages after\n        checking that all dicts corresponding to those languages are equivalent.\n\n        Args:\n            dicts: Dict of lang_id to its corresponding Dictionary\n            langs: languages that we want to share embeddings for\n            embed_dim: embedding dimension\n            build_embedding: callable function to actually build the embedding\n            pretrained_embed_path: Optional path to load pretrained embeddings\n        \"\"\"", "\n", "shared_dict", "=", "dicts", "[", "langs", "[", "0", "]", "]", "\n", "if", "any", "(", "dicts", "[", "lang", "]", "!=", "shared_dict", "for", "lang", "in", "langs", ")", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "'--share-*-embeddings requires a joined dictionary: '", "\n", "'--share-encoder-embeddings requires a joined source '", "\n", "'dictionary, --share-decoder-embeddings requires a joined '", "\n", "'target dictionary, and --share-all-embeddings requires a '", "\n", "'joint source + target dictionary.'", "\n", ")", "\n", "", "return", "build_embedding", "(", "\n", "shared_dict", ",", "embed_dim", ",", "pretrained_embed_path", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.fairseq_model.FairseqMultiModel.forward": [[281, 289], ["fairseq_model.FairseqMultiModel.models[].encoder", "fairseq_model.FairseqMultiModel.models[].decoder"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.fairseq_model.FairseqMultiModel.encoder", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.fairseq_model.FairseqMultiModel.decoder"], ["", "def", "forward", "(", "self", ",", "src_tokens", ",", "src_lengths", ",", "prev_output_tokens", ",", "**", "kwargs", ")", ":", "\n", "        ", "decoder_outs", "=", "{", "}", "\n", "for", "key", "in", "self", ".", "keys", ":", "\n", "            ", "encoder_out", "=", "self", ".", "models", "[", "key", "]", ".", "encoder", "(", "src_tokens", ",", "src_lengths", ",", "**", "kwargs", ")", "\n", "decoder_outs", "[", "key", "]", "=", "self", ".", "models", "[", "key", "]", ".", "decoder", "(", "\n", "prev_output_tokens", ",", "encoder_out", ",", "**", "kwargs", ",", "\n", ")", "\n", "", "return", "decoder_outs", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.fairseq_model.FairseqMultiModel.max_positions": [[290, 295], ["fairseq_model.FairseqMultiModel.models[].encoder.max_positions", "fairseq_model.FairseqMultiModel.models[].decoder.max_positions"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.tasks.fairseq_task.FairseqTask.max_positions", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.tasks.fairseq_task.FairseqTask.max_positions"], ["", "def", "max_positions", "(", "self", ")", ":", "\n", "        ", "\"\"\"Maximum length supported by the model.\"\"\"", "\n", "return", "{", "\n", "key", ":", "(", "self", ".", "models", "[", "key", "]", ".", "encoder", ".", "max_positions", "(", ")", ",", "self", ".", "models", "[", "key", "]", ".", "decoder", ".", "max_positions", "(", ")", ")", "\n", "for", "key", "in", "self", ".", "keys", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.fairseq_model.FairseqMultiModel.max_decoder_positions": [[297, 300], ["min", "model.decoder.max_positions", "fairseq_model.FairseqMultiModel.models.values"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.tasks.fairseq_task.FairseqTask.max_positions"], ["", "def", "max_decoder_positions", "(", "self", ")", ":", "\n", "        ", "\"\"\"Maximum length supported by the decoder.\"\"\"", "\n", "return", "min", "(", "model", ".", "decoder", ".", "max_positions", "(", ")", "for", "model", "in", "self", ".", "models", ".", "values", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.fairseq_model.FairseqMultiModel.encoder": [[301, 304], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "encoder", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "models", "[", "self", ".", "keys", "[", "0", "]", "]", ".", "encoder", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.fairseq_model.FairseqMultiModel.decoder": [[305, 308], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "decoder", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "models", "[", "self", ".", "keys", "[", "0", "]", "]", ".", "decoder", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.fairseq_model.FairseqLanguageModel.__init__": [[317, 321], ["fairseq_model.BaseFairseqModel.__init__", "isinstance"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.dummy_dictionary.DummyDictionary.__init__"], ["def", "__init__", "(", "self", ",", "decoder", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "decoder", "=", "decoder", "\n", "assert", "isinstance", "(", "self", ".", "decoder", ",", "FairseqDecoder", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.fairseq_model.FairseqLanguageModel.forward": [[322, 339], ["fairseq_model.FairseqLanguageModel.decoder"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.fairseq_model.FairseqMultiModel.decoder"], ["", "def", "forward", "(", "self", ",", "src_tokens", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"\n        Run the forward pass for a decoder-only model.\n\n        Feeds a batch of tokens through the decoder to predict the next tokens.\n\n        Args:\n            src_tokens (LongTensor): tokens on which to condition the decoder,\n                of shape `(batch, tgt_len)`\n            src_lengths (LongTensor): source sentence lengths of shape `(batch)`\n\n        Returns:\n            tuple:\n                - the decoder's output of shape `(batch, seq_len, vocab)`\n                - a dictionary with any model-specific outputs\n        \"\"\"", "\n", "return", "self", ".", "decoder", "(", "src_tokens", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.fairseq_model.FairseqLanguageModel.forward_decoder": [[340, 342], ["fairseq_model.FairseqLanguageModel.decoder"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.fairseq_model.FairseqMultiModel.decoder"], ["", "def", "forward_decoder", "(", "self", ",", "prev_output_tokens", ",", "**", "kwargs", ")", ":", "\n", "        ", "return", "self", ".", "decoder", "(", "prev_output_tokens", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.fairseq_model.FairseqLanguageModel.extract_features": [[343, 353], ["fairseq_model.FairseqLanguageModel.decoder.extract_features"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.transformer.TransformerDecoder.extract_features"], ["", "def", "extract_features", "(", "self", ",", "src_tokens", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"\n        Similar to *forward* but only return features.\n\n        Returns:\n            tuple:\n                - the decoder's features of shape `(batch, seq_len, embed_dim)`\n                - a dictionary with any model-specific outputs\n        \"\"\"", "\n", "return", "self", ".", "decoder", ".", "extract_features", "(", "src_tokens", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.fairseq_model.FairseqLanguageModel.output_layer": [[354, 357], ["fairseq_model.FairseqLanguageModel.decoder.output_layer"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.transformer.TransformerDecoder.output_layer"], ["", "def", "output_layer", "(", "self", ",", "features", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"Project features to the default output size (typically vocabulary size).\"\"\"", "\n", "return", "self", ".", "decoder", ".", "output_layer", "(", "features", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.fairseq_model.FairseqLanguageModel.max_positions": [[358, 361], ["fairseq_model.FairseqLanguageModel.decoder.max_positions"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.tasks.fairseq_task.FairseqTask.max_positions"], ["", "def", "max_positions", "(", "self", ")", ":", "\n", "        ", "\"\"\"Maximum length supported by the model.\"\"\"", "\n", "return", "self", ".", "decoder", ".", "max_positions", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.fairseq_model.FairseqLanguageModel.max_decoder_positions": [[362, 365], ["fairseq_model.FairseqLanguageModel.decoder.max_positions"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.tasks.fairseq_task.FairseqTask.max_positions"], ["", "def", "max_decoder_positions", "(", "self", ")", ":", "\n", "        ", "\"\"\"Maximum length supported by the decoder.\"\"\"", "\n", "return", "self", ".", "decoder", ".", "max_positions", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.fairseq_model.FairseqLanguageModel.supported_targets": [[366, 369], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "supported_targets", "(", "self", ")", ":", "\n", "        ", "return", "{", "'future'", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.fairseq_model.FairseqEncoderModel.__init__": [[378, 382], ["fairseq_model.BaseFairseqModel.__init__", "isinstance"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.dummy_dictionary.DummyDictionary.__init__"], ["def", "__init__", "(", "self", ",", "encoder", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "encoder", "=", "encoder", "\n", "assert", "isinstance", "(", "self", ".", "encoder", ",", "FairseqEncoder", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.fairseq_model.FairseqEncoderModel.forward": [[383, 397], ["fairseq_model.FairseqEncoderModel.encoder"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.fairseq_model.FairseqMultiModel.encoder"], ["", "def", "forward", "(", "self", ",", "src_tokens", ",", "src_lengths", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"\n        Run the forward pass for a encoder-only model.\n\n        Feeds a batch of tokens through the encoder to generate features.\n\n        Args:\n            src_tokens (LongTensor): input tokens of shape `(batch, src_len)`\n            src_lengths (LongTensor): source sentence lengths of shape `(batch)`\n\n        Returns:\n            the encoder's output, typically of shape `(batch, src_len, features)`\n        \"\"\"", "\n", "return", "self", ".", "encoder", "(", "src_tokens", ",", "src_lengths", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.fairseq_model.FairseqEncoderModel.get_normalized_probs": [[398, 408], ["torch.is_tensor", "torch.is_tensor", "torch.is_tensor", "torch.is_tensor", "torch.is_tensor", "torch.is_tensor", "torch.is_tensor", "torch.is_tensor", "torch.is_tensor", "encoder_out.float", "torch.log_softmax", "torch.log_softmax", "torch.log_softmax", "torch.softmax", "torch.softmax", "torch.softmax"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.utils.log_softmax", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.utils.log_softmax", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.utils.log_softmax", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.utils.softmax", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.utils.softmax", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.utils.softmax"], ["", "def", "get_normalized_probs", "(", "self", ",", "net_output", ",", "log_probs", ",", "sample", "=", "None", ")", ":", "\n", "        ", "\"\"\"Get normalized probabilities (or log probs) from a net's output.\"\"\"", "\n", "encoder_out", "=", "net_output", "[", "'encoder_out'", "]", "\n", "if", "torch", ".", "is_tensor", "(", "encoder_out", ")", ":", "\n", "            ", "logits", "=", "encoder_out", ".", "float", "(", ")", "\n", "if", "log_probs", ":", "\n", "                ", "return", "F", ".", "log_softmax", "(", "logits", ",", "dim", "=", "-", "1", ")", "\n", "", "else", ":", "\n", "                ", "return", "F", ".", "softmax", "(", "logits", ",", "dim", "=", "-", "1", ")", "\n", "", "", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.fairseq_model.FairseqEncoderModel.max_positions": [[409, 412], ["fairseq_model.FairseqEncoderModel.encoder.max_positions"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.tasks.fairseq_task.FairseqTask.max_positions"], ["", "def", "max_positions", "(", "self", ")", ":", "\n", "        ", "\"\"\"Maximum length supported by the model.\"\"\"", "\n", "return", "self", ".", "encoder", ".", "max_positions", "(", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.transformer_lm.TransformerLanguageModel.hub_models": [[23, 37], ["transformer_lm.TransformerLanguageModel.hub_models.moses_fastbpe"], "methods", ["None"], ["    ", "@", "classmethod", "\n", "def", "hub_models", "(", "cls", ")", ":", "\n", "\n", "        ", "def", "moses_fastbpe", "(", "path", ")", ":", "\n", "            ", "return", "{", "\n", "'path'", ":", "path", ",", "\n", "'tokenizer'", ":", "'moses'", ",", "\n", "'bpe'", ":", "'fastbpe'", ",", "\n", "}", "\n", "\n", "", "return", "{", "\n", "'transformer_lm.gbw.adaptive_huge'", ":", "'https://dl.fbaipublicfiles.com/fairseq/models/lm/adaptive_lm_gbw_huge.tar.bz2'", ",", "\n", "'transformer_lm.wiki103.adaptive'", ":", "'https://dl.fbaipublicfiles.com/fairseq/models/lm/adaptive_lm_wiki103.tar.bz2'", ",", "\n", "'transformer_lm.wmt19.en'", ":", "moses_fastbpe", "(", "'https://dl.fbaipublicfiles.com/fairseq/models/lm/wmt19.en.tar.bz2'", ")", ",", "\n", "'transformer_lm.wmt19.de'", ":", "moses_fastbpe", "(", "'https://dl.fbaipublicfiles.com/fairseq/models/lm/wmt19.de.tar.bz2'", ")", ",", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.transformer_lm.TransformerLanguageModel.__init__": [[39, 41], ["fairseq.models.FairseqLanguageModel.__init__"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.dummy_dictionary.DummyDictionary.__init__"], ["}", "\n", "\n", "", "def", "__init__", "(", "self", ",", "decoder", ")", ":", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.transformer_lm.TransformerLanguageModel.add_args": [[42, 86], ["parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "fairseq.utils.get_available_activation_fns"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.utils.get_available_activation_fns"], ["        ", "super", "(", ")", ".", "__init__", "(", "decoder", ")", "\n", "\n", "", "@", "staticmethod", "\n", "def", "add_args", "(", "parser", ")", ":", "\n", "        ", "\"\"\"Add model-specific arguments to the parser.\"\"\"", "\n", "# fmt: off", "\n", "parser", ".", "add_argument", "(", "'--activation-fn'", ",", "\n", "choices", "=", "utils", ".", "get_available_activation_fns", "(", ")", ",", "\n", "help", "=", "'activation function to use'", ")", "\n", "parser", ".", "add_argument", "(", "'--dropout'", ",", "type", "=", "float", ",", "metavar", "=", "'D'", ",", "\n", "help", "=", "'dropout probability'", ")", "\n", "parser", ".", "add_argument", "(", "'--attention-dropout'", ",", "type", "=", "float", ",", "metavar", "=", "'D'", ",", "\n", "help", "=", "'dropout probability for attention weights'", ")", "\n", "parser", ".", "add_argument", "(", "'--activation-dropout'", ",", "'--relu-dropout'", ",", "type", "=", "float", ",", "metavar", "=", "'D'", ",", "\n", "help", "=", "'dropout probability after activation in FFN.'", ")", "\n", "parser", ".", "add_argument", "(", "'--decoder-embed-dim'", ",", "type", "=", "int", ",", "metavar", "=", "'N'", ",", "\n", "help", "=", "'decoder embedding dimension'", ")", "\n", "parser", ".", "add_argument", "(", "'--decoder-output-dim'", ",", "type", "=", "int", ",", "metavar", "=", "'N'", ",", "\n", "help", "=", "'decoder output dimension'", ")", "\n", "parser", ".", "add_argument", "(", "'--decoder-input-dim'", ",", "type", "=", "int", ",", "metavar", "=", "'N'", ",", "\n", "help", "=", "'decoder input dimension'", ")", "\n", "parser", ".", "add_argument", "(", "'--decoder-ffn-embed-dim'", ",", "type", "=", "int", ",", "metavar", "=", "'N'", ",", "\n", "help", "=", "'decoder embedding dimension for FFN'", ")", "\n", "parser", ".", "add_argument", "(", "'--decoder-layers'", ",", "type", "=", "int", ",", "metavar", "=", "'N'", ",", "\n", "help", "=", "'num decoder layers'", ")", "\n", "parser", ".", "add_argument", "(", "'--decoder-attention-heads'", ",", "type", "=", "int", ",", "metavar", "=", "'N'", ",", "\n", "help", "=", "'num decoder attention heads'", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--no-decoder-final-norm'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "'don\\'t add an extra layernorm after the last decoder block'", ")", "\n", "parser", ".", "add_argument", "(", "'--share-decoder-input-output-embed'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "'share decoder input and output embeddings'", ")", "\n", "parser", ".", "add_argument", "(", "'--decoder-learned-pos'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "'use learned positional embeddings in the decoder'", ")", "\n", "# args for \"Reducing Transformer Depth on Demand with Structured Dropout\" (Fan et al., 2019)", "\n", "parser", ".", "add_argument", "(", "'--layernorm-embedding'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "'add layernorm to embedding'", ")", "\n", "# fmt: on", "\n", "\n", "", "@", "classmethod", "\n", "def", "build_model", "(", "cls", ",", "args", ",", "vocab_size", ")", ":", "\n", "        ", "\"\"\"Build a new model instance.\"\"\"", "\n", "\n", "# make sure all arguments are present in older models", "\n", "base_lm_architecture", "(", "args", ")", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.transformer_lm.TransformerLanguageModel.build_model": [[88, 107], ["transformer_lm.base_lm_architecture", "fairseq.models.transformer.Embedding", "fairseq.models.transformer.TransformerDecoder", "transformer_lm.TransformerLanguageModel", "len", "getattr", "getattr", "len", "task.source_dictionary.pad", "args.decoder_layers_to_keep.split"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.transformer_lm.base_lm_architecture", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.transformer.Embedding", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.dummy_dictionary.DummyDictionary.pad"], ["decoder", "=", "TransformerDecoder", "(", "\n", "args", ",", "None", ",", "embed_tokens", ",", "no_encoder_attn", "=", "True", ",", "\n", ")", "\n", "return", "TransformerLanguageModel", "(", "decoder", ")", "\n", "\n", "#@register_model_architecture('transformer_lm', 'transformer_lm')", "\n", "", "", "def", "base_lm_architecture", "(", "args", ")", ":", "\n", "# backward compatibility for older model checkpoints", "\n", "    ", "if", "hasattr", "(", "args", ",", "'decoder_final_norm'", ")", ":", "\n", "        ", "args", ".", "no_decoder_final_norm", "=", "not", "args", ".", "decoder_final_norm", "\n", "\n", "", "args", ".", "dropout", "=", "0.1", "\n", "args", ".", "attention_dropout", "=", "0.0", "\n", "args", ".", "activation_dropout", "=", "0.0", "\n", "args", ".", "decoder_embed_dim", "=", "512", "\n", "args", ".", "decoder_ffn_embed_dim", "=", "2048", "\n", "args", ".", "decoder_layers", "=", "6", "\n", "args", ".", "decoder_attention_heads", "=", "8", "\n", "args", ".", "decoder_learned_pos", "=", "False", "\n", "args", ".", "activation_fn", "=", "'relu'", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.transformer_lm.base_lm_architecture": [[109, 135], ["fairseq.models.register_model_architecture", "hasattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr"], "function", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.__init__.register_model_architecture"], ["args", ".", "add_bos_token", "=", "False", "\n", "args", ".", "no_token_positional_embeddings", "=", "False", "\n", "args", ".", "share_decoder_input_output_embed", "=", "True", "\n", "args", ".", "decoder_output_dim", "=", "512", "\n", "args", ".", "decoder_input_dim", "=", "512", "\n", "\n", "# Model training is not stable without this", "\n", "args", ".", "decoder_normalize_before", "=", "True", "\n", "args", ".", "no_decoder_final_norm", "=", "False", "\n", "args", ".", "no_scale_embedding", "=", "False", "\n", "args", ".", "layernorm_embedding", "=", "False", "\n", "args", ".", "max_target_positions", "=", "100", "\n", "", ""]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.transformer_lm.transformer_lm_l6a12": [[137, 144], ["fairseq.models.register_model_architecture", "getattr", "getattr", "getattr", "getattr", "transformer_lm.base_lm_architecture"], "function", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.__init__.register_model_architecture", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.transformer_lm.base_lm_architecture"], []], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.transformer_lm.transformer_lm_l5a12": [[146, 153], ["fairseq.models.register_model_architecture", "getattr", "getattr", "getattr", "getattr", "transformer_lm.base_lm_architecture"], "function", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.__init__.register_model_architecture", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.transformer_lm.base_lm_architecture"], []], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.transformer_lm.transformer_lm_l4a12": [[155, 162], ["fairseq.models.register_model_architecture", "getattr", "getattr", "getattr", "getattr", "transformer_lm.base_lm_architecture"], "function", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.__init__.register_model_architecture", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.transformer_lm.base_lm_architecture"], []], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.transformer_lm.transformer_lm_l3a12": [[164, 171], ["fairseq.models.register_model_architecture", "getattr", "getattr", "getattr", "getattr", "transformer_lm.base_lm_architecture"], "function", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.__init__.register_model_architecture", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.transformer_lm.base_lm_architecture"], []], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.transformer_lm.transformer_lm_l5a8": [[173, 180], ["fairseq.models.register_model_architecture", "getattr", "getattr", "getattr", "getattr", "transformer_lm.base_lm_architecture"], "function", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.__init__.register_model_architecture", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.transformer_lm.base_lm_architecture"], []], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.transformer_lm.transformer_lm_l4a8": [[182, 189], ["fairseq.models.register_model_architecture", "getattr", "getattr", "getattr", "getattr", "transformer_lm.base_lm_architecture"], "function", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.__init__.register_model_architecture", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.transformer_lm.base_lm_architecture"], []], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.transformer_lm.transformer_lm_l6a10": [[191, 198], ["fairseq.models.register_model_architecture", "getattr", "getattr", "getattr", "getattr", "transformer_lm.base_lm_architecture"], "function", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.__init__.register_model_architecture", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.transformer_lm.base_lm_architecture"], []], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.transformer_lm.transformer_lm_l5a10": [[200, 207], ["fairseq.models.register_model_architecture", "getattr", "getattr", "getattr", "getattr", "transformer_lm.base_lm_architecture"], "function", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.__init__.register_model_architecture", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.transformer_lm.base_lm_architecture"], []], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.__init__.build_model": [[45, 47], ["ARCH_MODEL_REGISTRY[].build_model"], "function", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.tasks.integer_sequence_modeling.IntegerSequenceModelingTask.build_model"], []], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.__init__.register_model": [[49, 78], ["ValueError", "issubclass", "ValueError"], "function", ["None"], []], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.__init__.register_model_architecture": [[80, 118], ["ARCH_MODEL_INV_REGISTRY.setdefault().append", "ValueError", "ValueError", "callable", "ValueError", "ARCH_MODEL_INV_REGISTRY.setdefault"], "function", ["None"], []], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.fairseq_decoder.FairseqDecoder.__init__": [[14, 18], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.dummy_dictionary.DummyDictionary.__init__"], ["def", "__init__", "(", "self", ",", "dictionary", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dictionary", "=", "dictionary", "\n", "self", ".", "onnx_trace", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.fairseq_decoder.FairseqDecoder.forward": [[19, 35], ["fairseq_decoder.FairseqDecoder.extract_features", "fairseq_decoder.FairseqDecoder.output_layer"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.transformer.TransformerDecoder.extract_features", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.transformer.TransformerDecoder.output_layer"], ["", "def", "forward", "(", "self", ",", "prev_output_tokens", ",", "encoder_out", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            prev_output_tokens (LongTensor): shifted output tokens of shape\n                `(batch, tgt_len)`, for teacher forcing\n            encoder_out (dict, optional): output from the encoder, used for\n                encoder-side attention\n\n        Returns:\n            tuple:\n                - the decoder's output of shape `(batch, tgt_len, vocab)`\n                - a dictionary with any model-specific outputs\n        \"\"\"", "\n", "x", ",", "extra", "=", "self", ".", "extract_features", "(", "prev_output_tokens", ",", "encoder_out", "=", "encoder_out", ",", "**", "kwargs", ")", "\n", "x", "=", "self", ".", "output_layer", "(", "x", ")", "\n", "return", "x", ",", "extra", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.fairseq_decoder.FairseqDecoder.extract_features": [[36, 44], ["None"], "methods", ["None"], ["", "def", "extract_features", "(", "self", ",", "prev_output_tokens", ",", "encoder_out", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"\n        Returns:\n            tuple:\n                - the decoder's features of shape `(batch, tgt_len, embed_dim)`\n                - a dictionary with any model-specific outputs\n        \"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.fairseq_decoder.FairseqDecoder.output_layer": [[45, 53], ["None"], "methods", ["None"], ["", "def", "output_layer", "(", "self", ",", "features", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"\n        Project features to the default output size, e.g., vocabulary size.\n\n        Args:\n            features (Tensor): features returned by *extract_features*.\n        \"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.fairseq_decoder.FairseqDecoder.get_normalized_probs": [[54, 62], ["fairseq.utils.log_softmax", "fairseq.utils.softmax"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.utils.log_softmax", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.utils.softmax"], ["", "def", "get_normalized_probs", "(", "self", ",", "net_output", ",", "log_probs", ",", "sample", ")", ":", "\n", "        ", "\"\"\"Get normalized probabilities (or log probs) from a net's output.\"\"\"", "\n", "\n", "logits", "=", "net_output", "[", "0", "]", "\n", "if", "log_probs", ":", "\n", "            ", "return", "utils", ".", "log_softmax", "(", "logits", ",", "dim", "=", "-", "1", ",", "onnx_trace", "=", "self", ".", "onnx_trace", ")", "\n", "", "else", ":", "\n", "            ", "return", "utils", ".", "softmax", "(", "logits", ",", "dim", "=", "-", "1", ",", "onnx_trace", "=", "self", ".", "onnx_trace", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.fairseq_decoder.FairseqDecoder.max_positions": [[63, 66], ["None"], "methods", ["None"], ["", "", "def", "max_positions", "(", "self", ")", ":", "\n", "        ", "\"\"\"Maximum input length supported by the decoder.\"\"\"", "\n", "return", "1e6", "# an arbitrary large number", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.fairseq_decoder.FairseqDecoder.upgrade_state_dict": [[67, 70], ["None"], "methods", ["None"], ["", "def", "upgrade_state_dict", "(", "self", ",", "state_dict", ")", ":", "\n", "        ", "\"\"\"Upgrade a (possibly old) state dict for new versions of fairseq.\"\"\"", "\n", "return", "state_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.fairseq_decoder.FairseqDecoder.prepare_for_onnx_export_": [[71, 73], ["None"], "methods", ["None"], ["", "def", "prepare_for_onnx_export_", "(", "self", ")", ":", "\n", "        ", "self", ".", "onnx_trace", "=", "True", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.transformer.TransformerDecoder.__init__": [[49, 99], ["fairseq.models.FairseqIncrementalDecoder.__init__", "transformer.TransformerDecoder.register_buffer", "getattr", "getattr", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "transformer.TransformerDecoder.layers.extend", "getattr", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "math.sqrt", "transformer.Linear", "fairseq.modules.PositionalEmbedding", "transformer.Linear", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.init.normal_", "torch.init.normal_", "torch.init.normal_", "fairseq.modules.LayerNorm", "fairseq.modules.LayerNorm", "fairseq.modules.TransformerDecoderLayer", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "getattr", "range", "len"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.dummy_dictionary.DummyDictionary.__init__", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.modules.transformer_layer.Linear", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.modules.positional_embedding.PositionalEmbedding", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.modules.transformer_layer.Linear", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.modules.layer_norm.LayerNorm", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.modules.layer_norm.LayerNorm"], ["def", "__init__", "(", "self", ",", "args", ",", "dictionary", ",", "embed_tokens", ",", "no_encoder_attn", "=", "False", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "dictionary", ")", "\n", "self", ".", "register_buffer", "(", "'version'", ",", "torch", ".", "Tensor", "(", "[", "3", "]", ")", ")", "\n", "\n", "self", ".", "dropout", "=", "args", ".", "dropout", "\n", "self", ".", "decoder_layerdrop", "=", "args", ".", "decoder_layerdrop", "\n", "self", ".", "share_input_output_embed", "=", "args", ".", "share_decoder_input_output_embed", "\n", "\n", "input_embed_dim", "=", "embed_tokens", ".", "embedding_dim", "\n", "embed_dim", "=", "args", ".", "decoder_embed_dim", "\n", "self", ".", "output_embed_dim", "=", "args", ".", "decoder_output_dim", "\n", "\n", "self", ".", "padding_idx", "=", "embed_tokens", ".", "padding_idx", "\n", "self", ".", "max_target_positions", "=", "args", ".", "max_target_positions", "\n", "\n", "self", ".", "embed_tokens", "=", "embed_tokens", "\n", "\n", "self", ".", "embed_scale", "=", "1.0", "if", "args", ".", "no_scale_embedding", "else", "math", ".", "sqrt", "(", "embed_dim", ")", "\n", "\n", "self", ".", "project_in_dim", "=", "Linear", "(", "input_embed_dim", ",", "embed_dim", ",", "bias", "=", "False", ")", "if", "embed_dim", "!=", "input_embed_dim", "else", "None", "\n", "\n", "self", ".", "embed_positions", "=", "PositionalEmbedding", "(", "\n", "args", ".", "max_target_positions", ",", "embed_dim", ",", "self", ".", "padding_idx", ",", "\n", "learned", "=", "args", ".", "decoder_learned_pos", ",", "\n", ")", "if", "not", "args", ".", "no_token_positional_embeddings", "else", "None", "\n", "\n", "self", ".", "cross_self_attention", "=", "getattr", "(", "args", ",", "'cross_self_attention'", ",", "False", ")", "\n", "self", ".", "layer_wise_attention", "=", "getattr", "(", "args", ",", "'layer_wise_attention'", ",", "False", ")", "\n", "\n", "self", ".", "layers", "=", "nn", ".", "ModuleList", "(", "[", "]", ")", "\n", "self", ".", "layers", ".", "extend", "(", "[", "\n", "TransformerDecoderLayer", "(", "args", ",", "no_encoder_attn", ")", "\n", "for", "_", "in", "range", "(", "args", ".", "decoder_layers", ")", "\n", "]", ")", "\n", "\n", "self", ".", "project_out_dim", "=", "Linear", "(", "embed_dim", ",", "self", ".", "output_embed_dim", ",", "bias", "=", "False", ")", "if", "embed_dim", "!=", "self", ".", "output_embed_dim", "else", "None", "\n", "\n", "if", "not", "self", ".", "share_input_output_embed", ":", "\n", "            ", "self", ".", "embed_out", "=", "nn", ".", "Parameter", "(", "torch", ".", "Tensor", "(", "len", "(", "dictionary", ")", ",", "self", ".", "output_embed_dim", ")", ")", "\n", "nn", ".", "init", ".", "normal_", "(", "self", ".", "embed_out", ",", "mean", "=", "0", ",", "std", "=", "self", ".", "output_embed_dim", "**", "-", "0.5", ")", "\n", "\n", "", "if", "args", ".", "decoder_normalize_before", "and", "not", "getattr", "(", "args", ",", "'no_decoder_final_norm'", ",", "False", ")", ":", "\n", "            ", "self", ".", "layer_norm", "=", "LayerNorm", "(", "embed_dim", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "layer_norm", "=", "None", "\n", "", "if", "getattr", "(", "args", ",", "'layernorm_embedding'", ",", "False", ")", ":", "\n", "            ", "self", ".", "layernorm_embedding", "=", "LayerNorm", "(", "embed_dim", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "layernorm_embedding", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.transformer.TransformerDecoder.forward": [[100, 133], ["transformer.TransformerDecoder.extract_features", "transformer.TransformerDecoder.output_layer"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.transformer.TransformerDecoder.extract_features", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.transformer.TransformerDecoder.output_layer"], ["", "", "def", "forward", "(", "\n", "self", ",", "\n", "prev_output_tokens", ",", "\n", "encoder_out", "=", "None", ",", "\n", "incremental_state", "=", "None", ",", "\n", "features_only", "=", "False", ",", "\n", "**", "extra_args", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            prev_output_tokens (LongTensor): previous decoder outputs of shape\n                `(batch, tgt_len)`, for teacher forcing\n            encoder_out (optional): output from the encoder, used for\n                encoder-side attention\n            incremental_state (dict): dictionary used for storing state during\n                :ref:`Incremental decoding`\n            features_only (bool, optional): only return features without\n                applying output layer (default: False).\n\n        Returns:\n            tuple:\n                - the decoder's output of shape `(batch, tgt_len, vocab)`\n                - a dictionary with any model-specific outputs\n        \"\"\"", "\n", "x", ",", "extra", "=", "self", ".", "extract_features", "(", "\n", "prev_output_tokens", ",", "\n", "encoder_out", "=", "encoder_out", ",", "\n", "incremental_state", "=", "incremental_state", ",", "\n", "**", "extra_args", "\n", ")", "\n", "if", "not", "features_only", ":", "\n", "            ", "x", "=", "self", ".", "output_layer", "(", "x", ")", "\n", "", "return", "x", ",", "extra", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.transformer.TransformerDecoder.extract_features": [[134, 248], ["torch.dropout", "torch.dropout", "torch.dropout", "transformer.TransformerDecoder.transpose", "enumerate", "transformer.TransformerDecoder.transpose", "transformer.TransformerDecoder.embed_positions", "transformer.TransformerDecoder.embed_tokens", "transformer.TransformerDecoder.project_in_dim", "transformer.TransformerDecoder.layernorm_embedding", "prev_output_tokens.eq().any", "prev_output_tokens.eq", "random.uniform", "layer_attn.float.mean", "transformer.TransformerDecoder.layer_norm", "transformer.TransformerDecoder.project_out_dim", "len", "transformer.TransformerDecoder.buffered_future_mask", "layer", "inner_states.append", "prev_output_tokens.eq", "layer_attn.float"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.transformer.TransformerDecoder.buffered_future_mask"], ["", "def", "extract_features", "(", "\n", "self", ",", "\n", "prev_output_tokens", ",", "\n", "encoder_out", "=", "None", ",", "\n", "incremental_state", "=", "None", ",", "\n", "full_context_alignment", "=", "False", ",", "\n", "alignment_layer", "=", "None", ",", "\n", "alignment_heads", "=", "None", ",", "\n", "**", "unused", ",", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Similar to *forward* but only return features.\n\n        Includes several features from \"Jointly Learning to Align and\n        Translate with Transformer Models\" (Garg et al., EMNLP 2019).\n\n        Args:\n            full_context_alignment (bool, optional): don't apply\n                auto-regressive mask to self-attention (default: False).\n            alignment_layer (int, optional): return mean alignment over\n                heads at this layer (default: last layer).\n            alignment_heads (int, optional): only average alignment over\n                this many heads (default: all heads).\n\n        Returns:\n            tuple:\n                - the decoder's features of shape `(batch, tgt_len, embed_dim)`\n                - a dictionary with any model-specific outputs\n        \"\"\"", "\n", "if", "alignment_layer", "is", "None", ":", "\n", "            ", "alignment_layer", "=", "len", "(", "self", ".", "layers", ")", "-", "1", "\n", "\n", "# embed positions", "\n", "", "positions", "=", "self", ".", "embed_positions", "(", "\n", "prev_output_tokens", ",", "\n", "incremental_state", "=", "incremental_state", ",", "\n", ")", "if", "self", ".", "embed_positions", "is", "not", "None", "else", "None", "\n", "\n", "if", "incremental_state", "is", "not", "None", ":", "\n", "            ", "prev_output_tokens", "=", "prev_output_tokens", "[", ":", ",", "-", "1", ":", "]", "\n", "if", "positions", "is", "not", "None", ":", "\n", "                ", "positions", "=", "positions", "[", ":", ",", "-", "1", ":", "]", "\n", "\n", "# embed tokens and positions", "\n", "", "", "x", "=", "self", ".", "embed_scale", "*", "self", ".", "embed_tokens", "(", "prev_output_tokens", ")", "\n", "\n", "if", "self", ".", "project_in_dim", "is", "not", "None", ":", "\n", "            ", "x", "=", "self", ".", "project_in_dim", "(", "x", ")", "\n", "\n", "", "if", "positions", "is", "not", "None", ":", "\n", "            ", "x", "+=", "positions", "\n", "\n", "", "if", "self", ".", "layernorm_embedding", ":", "\n", "            ", "x", "=", "self", ".", "layernorm_embedding", "(", "x", ")", "\n", "\n", "", "x", "=", "F", ".", "dropout", "(", "x", ",", "p", "=", "self", ".", "dropout", ",", "training", "=", "self", ".", "training", ")", "\n", "\n", "# B x T x C -> T x B x C", "\n", "x", "=", "x", ".", "transpose", "(", "0", ",", "1", ")", "\n", "\n", "self_attn_padding_mask", "=", "None", "\n", "if", "self", ".", "cross_self_attention", "or", "prev_output_tokens", ".", "eq", "(", "self", ".", "padding_idx", ")", ".", "any", "(", ")", ":", "\n", "            ", "self_attn_padding_mask", "=", "prev_output_tokens", ".", "eq", "(", "self", ".", "padding_idx", ")", "\n", "\n", "# decoder layers", "\n", "", "attn", "=", "None", "\n", "inner_states", "=", "[", "x", "]", "\n", "for", "idx", ",", "layer", "in", "enumerate", "(", "self", ".", "layers", ")", ":", "\n", "            ", "encoder_state", "=", "None", "\n", "if", "encoder_out", "is", "not", "None", ":", "\n", "                ", "if", "self", ".", "layer_wise_attention", ":", "\n", "                    ", "encoder_state", "=", "encoder_out", ".", "encoder_states", "[", "idx", "]", "\n", "", "else", ":", "\n", "                    ", "encoder_state", "=", "encoder_out", ".", "encoder_out", "\n", "\n", "", "", "if", "incremental_state", "is", "None", "and", "not", "full_context_alignment", ":", "\n", "                ", "self_attn_mask", "=", "self", ".", "buffered_future_mask", "(", "x", ")", "\n", "", "else", ":", "\n", "                ", "self_attn_mask", "=", "None", "\n", "\n", "# add LayerDrop (see https://arxiv.org/abs/1909.11556 for description)", "\n", "", "dropout_probability", "=", "random", ".", "uniform", "(", "0", ",", "1", ")", "\n", "if", "not", "self", ".", "training", "or", "(", "dropout_probability", ">", "self", ".", "decoder_layerdrop", ")", ":", "\n", "                ", "x", ",", "layer_attn", "=", "layer", "(", "\n", "x", ",", "\n", "encoder_state", ",", "\n", "encoder_out", ".", "encoder_padding_mask", "if", "encoder_out", "is", "not", "None", "else", "None", ",", "\n", "incremental_state", ",", "\n", "self_attn_mask", "=", "self_attn_mask", ",", "\n", "self_attn_padding_mask", "=", "self_attn_padding_mask", ",", "\n", "need_attn", "=", "(", "idx", "==", "alignment_layer", ")", ",", "\n", "need_head_weights", "=", "(", "idx", "==", "alignment_layer", ")", ",", "\n", ")", "\n", "inner_states", ".", "append", "(", "x", ")", "\n", "if", "layer_attn", "is", "not", "None", "and", "idx", "==", "alignment_layer", ":", "\n", "                    ", "attn", "=", "layer_attn", ".", "float", "(", ")", "\n", "\n", "", "", "", "if", "attn", "is", "not", "None", ":", "\n", "            ", "if", "alignment_heads", "is", "not", "None", ":", "\n", "                ", "attn", "=", "attn", "[", ":", "alignment_heads", "]", "\n", "\n", "# average probabilities over heads", "\n", "", "attn", "=", "attn", ".", "mean", "(", "dim", "=", "0", ")", "\n", "\n", "", "if", "self", ".", "layer_norm", ":", "\n", "            ", "x", "=", "self", ".", "layer_norm", "(", "x", ")", "\n", "\n", "# T x B x C -> B x T x C", "\n", "", "x", "=", "x", ".", "transpose", "(", "0", ",", "1", ")", "\n", "\n", "if", "self", ".", "project_out_dim", "is", "not", "None", ":", "\n", "            ", "x", "=", "self", ".", "project_out_dim", "(", "x", ")", "\n", "\n", "", "return", "x", ",", "{", "'attn'", ":", "attn", ",", "'inner_states'", ":", "inner_states", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.transformer.TransformerDecoder.output_layer": [[249, 256], ["torch.linear", "torch.linear", "torch.linear", "torch.linear", "torch.linear", "torch.linear"], "methods", ["None"], ["", "def", "output_layer", "(", "self", ",", "features", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"Project features to the vocabulary size.\"\"\"", "\n", "# project back to size of vocabulary", "\n", "if", "self", ".", "share_input_output_embed", ":", "\n", "            ", "return", "F", ".", "linear", "(", "features", ",", "self", ".", "embed_tokens", ".", "weight", ")", "\n", "", "else", ":", "\n", "            ", "return", "F", ".", "linear", "(", "features", ",", "self", ".", "embed_out", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.transformer.TransformerDecoder.max_positions": [[257, 262], ["min", "transformer.TransformerDecoder.embed_positions.max_positions"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.tasks.fairseq_task.FairseqTask.max_positions"], ["", "", "def", "max_positions", "(", "self", ")", ":", "\n", "        ", "\"\"\"Maximum output length supported by the decoder.\"\"\"", "\n", "if", "self", ".", "embed_positions", "is", "None", ":", "\n", "            ", "return", "self", ".", "max_target_positions", "\n", "", "return", "min", "(", "self", ".", "max_target_positions", ",", "self", ".", "embed_positions", ".", "max_positions", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.transformer.TransformerDecoder.buffered_future_mask": [[263, 273], ["tensor.size", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "hasattr", "transformer.TransformerDecoder._future_mask.size", "fairseq.utils.fill_with_neg_inf", "tensor.new"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.fairseq_dataset.FairseqDataset.size", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.fairseq_dataset.FairseqDataset.size", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.utils.fill_with_neg_inf"], ["", "def", "buffered_future_mask", "(", "self", ",", "tensor", ")", ":", "\n", "        ", "dim", "=", "tensor", ".", "size", "(", "0", ")", "\n", "if", "(", "\n", "not", "hasattr", "(", "self", ",", "'_future_mask'", ")", "\n", "or", "self", ".", "_future_mask", "is", "None", "\n", "or", "self", ".", "_future_mask", ".", "device", "!=", "tensor", ".", "device", "\n", "or", "self", ".", "_future_mask", ".", "size", "(", "0", ")", "<", "dim", "\n", ")", ":", "\n", "            ", "self", ".", "_future_mask", "=", "torch", ".", "triu", "(", "utils", ".", "fill_with_neg_inf", "(", "tensor", ".", "new", "(", "dim", ",", "dim", ")", ")", ",", "1", ")", "\n", "", "return", "self", ".", "_future_mask", "[", ":", "dim", ",", ":", "dim", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.transformer.TransformerDecoder.upgrade_state_dict_named": [[274, 304], ["isinstance", "range", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "len", "layer_norm_map.items", "fairseq.utils.item", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "state_dict.get", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.utils.item"], ["", "def", "upgrade_state_dict_named", "(", "self", ",", "state_dict", ",", "name", ")", ":", "\n", "        ", "\"\"\"Upgrade a (possibly old) state dict for new versions of fairseq.\"\"\"", "\n", "if", "isinstance", "(", "self", ".", "embed_positions", ",", "SinusoidalPositionalEmbedding", ")", ":", "\n", "            ", "weights_key", "=", "'{}.embed_positions.weights'", ".", "format", "(", "name", ")", "\n", "if", "weights_key", "in", "state_dict", ":", "\n", "                ", "del", "state_dict", "[", "weights_key", "]", "\n", "", "state_dict", "[", "'{}.embed_positions._float_tensor'", ".", "format", "(", "name", ")", "]", "=", "torch", ".", "FloatTensor", "(", "1", ")", "\n", "\n", "", "for", "i", "in", "range", "(", "len", "(", "self", ".", "layers", ")", ")", ":", "\n", "# update layer norms", "\n", "            ", "layer_norm_map", "=", "{", "\n", "'0'", ":", "'self_attn_layer_norm'", ",", "\n", "'1'", ":", "'encoder_attn_layer_norm'", ",", "\n", "'2'", ":", "'final_layer_norm'", "\n", "}", "\n", "for", "old", ",", "new", "in", "layer_norm_map", ".", "items", "(", ")", ":", "\n", "                ", "for", "m", "in", "(", "'weight'", ",", "'bias'", ")", ":", "\n", "                    ", "k", "=", "'{}.layers.{}.layer_norms.{}.{}'", ".", "format", "(", "name", ",", "i", ",", "old", ",", "m", ")", "\n", "if", "k", "in", "state_dict", ":", "\n", "                        ", "state_dict", "[", "'{}.layers.{}.{}.{}'", ".", "format", "(", "name", ",", "i", ",", "new", ",", "m", ")", "]", "=", "state_dict", "[", "k", "]", "\n", "del", "state_dict", "[", "k", "]", "\n", "\n", "", "", "", "", "version_key", "=", "'{}.version'", ".", "format", "(", "name", ")", "\n", "if", "utils", ".", "item", "(", "state_dict", ".", "get", "(", "version_key", ",", "torch", ".", "Tensor", "(", "[", "1", "]", ")", ")", "[", "0", "]", ")", "<=", "2", ":", "\n", "# earlier checkpoints did not normalize after the stack of layers", "\n", "            ", "self", ".", "layer_norm", "=", "None", "\n", "self", ".", "normalize", "=", "False", "\n", "state_dict", "[", "version_key", "]", "=", "torch", ".", "Tensor", "(", "[", "1", "]", ")", "\n", "\n", "", "return", "state_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.transformer.Embedding": [[306, 311], ["torch.Embedding", "torch.init.normal_", "torch.init.constant_"], "function", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.transformer.Embedding"], ["", "", "def", "Embedding", "(", "num_embeddings", ",", "embedding_dim", ",", "padding_idx", ")", ":", "\n", "    ", "m", "=", "nn", ".", "Embedding", "(", "num_embeddings", ",", "embedding_dim", ",", "padding_idx", "=", "padding_idx", ")", "\n", "nn", ".", "init", ".", "normal_", "(", "m", ".", "weight", ",", "mean", "=", "0", ",", "std", "=", "embedding_dim", "**", "-", "0.5", ")", "\n", "nn", ".", "init", ".", "constant_", "(", "m", ".", "weight", "[", "padding_idx", "]", ",", "0", ")", "\n", "return", "m", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.transformer.Linear": [[313, 319], ["torch.Linear", "torch.init.xavier_uniform_", "torch.init.constant_"], "function", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.modules.transformer_layer.Linear"], ["", "def", "Linear", "(", "in_features", ",", "out_features", ",", "bias", "=", "True", ")", ":", "\n", "    ", "m", "=", "nn", ".", "Linear", "(", "in_features", ",", "out_features", ",", "bias", ")", "\n", "nn", ".", "init", ".", "xavier_uniform_", "(", "m", ".", "weight", ")", "\n", "if", "bias", ":", "\n", "        ", "nn", ".", "init", ".", "constant_", "(", "m", ".", "bias", ",", "0.", ")", "\n", "", "return", "m", "\n", "", ""]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.distributed_fairseq_model.DistributedFairseqModel": [[14, 67], ["isinstance", "_DistributedFairseqModel", "dict", "dict", "ValueError", "super().__init__", "super().__getattr__", "hasattr", "super().__getattr__", "inspect.getargspec", "inspect.getargspec", "getattr"], "function", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.dummy_dictionary.DummyDictionary.__init__"], ["def", "DistributedFairseqModel", "(", "args", ",", "model", ")", ":", "\n", "    ", "\"\"\"\n    Wrap a *model* to support distributed data parallel training.\n\n    This is similar to the built-in DistributedDataParallel, but allows\n    additional configuration of the DistributedDataParallel class to\n    use, and also provides easier access to the wrapped model by\n    forwarding requests for missing attributes to the wrapped model.\n\n    Args:\n        args (argparse.Namespace): fairseq args\n        model (BaseFairseqModel): model to wrap\n    \"\"\"", "\n", "# determine which DDP class to extend", "\n", "assert", "isinstance", "(", "model", ",", "nn", ".", "Module", ")", "\n", "if", "args", ".", "ddp_backend", "==", "'c10d'", ":", "\n", "        ", "ddp_class", "=", "nn", ".", "parallel", ".", "DistributedDataParallel", "\n", "init_kwargs", "=", "dict", "(", "\n", "module", "=", "model", ",", "\n", "device_ids", "=", "[", "args", ".", "device_id", "]", ",", "\n", "output_device", "=", "args", ".", "device_id", ",", "\n", "broadcast_buffers", "=", "False", ",", "\n", "bucket_cap_mb", "=", "args", ".", "bucket_cap_mb", ",", "\n", ")", "\n", "# Maintain backward compatibility", "\n", "if", "'check_reduction'", "in", "inspect", ".", "getargspec", "(", "ddp_class", ")", "[", "0", "]", ":", "\n", "            ", "init_kwargs", "[", "'check_reduction'", "]", "=", "True", "\n", "", "if", "'find_unused_parameters'", "in", "inspect", ".", "getargspec", "(", "ddp_class", ")", "[", "0", "]", ":", "\n", "            ", "init_kwargs", "[", "'find_unused_parameters'", "]", "=", "args", ".", "find_unused_parameters", "\n", "", "", "elif", "args", ".", "ddp_backend", "==", "'no_c10d'", ":", "\n", "        ", "ddp_class", "=", "LegacyDistributedDataParallel", "\n", "init_kwargs", "=", "dict", "(", "\n", "module", "=", "model", ",", "\n", "world_size", "=", "args", ".", "distributed_world_size", ",", "\n", "buffer_size", "=", "2", "**", "28", ",", "\n", ")", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "'Unknown --ddp-backend: '", "+", "args", ".", "ddp_backend", ")", "\n", "\n", "", "class", "_DistributedFairseqModel", "(", "ddp_class", ")", ":", "\n", "        ", "\"\"\"Extend DistributedDataParallel to check for missing\n        attributes in the wrapped module.\"\"\"", "\n", "\n", "def", "__init__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "            ", "super", "(", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n", "", "def", "__getattr__", "(", "self", ",", "name", ")", ":", "\n", "            ", "wrapped_module", "=", "super", "(", ")", ".", "__getattr__", "(", "'module'", ")", "\n", "if", "hasattr", "(", "wrapped_module", ",", "name", ")", ":", "\n", "                ", "return", "getattr", "(", "wrapped_module", ",", "name", ")", "\n", "", "return", "super", "(", ")", ".", "__getattr__", "(", "name", ")", "\n", "\n", "", "", "return", "_DistributedFairseqModel", "(", "**", "init_kwargs", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.options.get_training_parser": [[14, 22], ["options.get_parser", "options.add_dataset_args", "options.add_distributed_training_args", "options.add_model_args", "options.add_optimization_args", "options.add_checkpoint_args"], "function", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.options.get_parser", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.options.add_dataset_args", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.options.add_distributed_training_args", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.options.add_model_args", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.options.add_optimization_args", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.options.add_checkpoint_args"], ["def", "get_training_parser", "(", "default_task", "=", "'translation'", ")", ":", "\n", "    ", "parser", "=", "get_parser", "(", "'Trainer'", ",", "default_task", ")", "\n", "add_dataset_args", "(", "parser", ",", "train", "=", "True", ")", "\n", "add_distributed_training_args", "(", "parser", ")", "\n", "add_model_args", "(", "parser", ")", "\n", "add_optimization_args", "(", "parser", ")", "\n", "add_checkpoint_args", "(", "parser", ")", "\n", "return", "parser", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.options.get_validation_parser": [[24, 30], ["options.get_parser", "options.add_dataset_args", "get_parser.add_argument_group", "options.add_common_eval_args"], "function", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.options.get_parser", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.options.add_dataset_args", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.options.add_common_eval_args"], ["", "def", "get_validation_parser", "(", "default_task", "=", "None", ")", ":", "\n", "    ", "parser", "=", "get_parser", "(", "'Validation'", ",", "default_task", ")", "\n", "add_dataset_args", "(", "parser", ",", "train", "=", "True", ")", "\n", "group", "=", "parser", ".", "add_argument_group", "(", "'Evaluation'", ")", "\n", "add_common_eval_args", "(", "group", ")", "\n", "return", "parser", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.options.eval_str_list": [[32, 41], ["isinstance", "eval", "list", "map", "type"], "function", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.utils.eval"], ["", "def", "eval_str_list", "(", "x", ",", "type", "=", "float", ")", ":", "\n", "    ", "if", "x", "is", "None", ":", "\n", "        ", "return", "None", "\n", "", "if", "isinstance", "(", "x", ",", "str", ")", ":", "\n", "        ", "x", "=", "eval", "(", "x", ")", "\n", "", "try", ":", "\n", "        ", "return", "list", "(", "map", "(", "type", ",", "x", ")", ")", "\n", "", "except", "TypeError", ":", "\n", "        ", "return", "[", "type", "(", "x", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.options.eval_bool": [[43, 50], ["bool", "eval"], "function", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.utils.eval"], ["", "", "def", "eval_bool", "(", "x", ",", "default", "=", "False", ")", ":", "\n", "    ", "if", "x", "is", "None", ":", "\n", "        ", "return", "default", "\n", "", "try", ":", "\n", "        ", "return", "bool", "(", "eval", "(", "x", ")", ")", "\n", "", "except", "TypeError", ":", "\n", "        ", "return", "default", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.options.parse_args_and_arch": [[52, 129], ["parser.parse_known_args", "hasattr", "REGISTRIES.items", "hasattr", "getattr", "getattr", "hasattr", "options.parse_args_and_arch", "argparse.ArgumentParser", "argparse.ArgumentParser.set_defaults", "argparse.ArgumentParser.parse_args", "argparse.Namespace", "parser.add_argument_group", "ARCH_MODEL_REGISTRY[].add_args", "getattr", "TASK_REGISTRY[].add_args", "FairseqBMUF.add_args", "parser.parse_known_args", "parser.parse_args", "hasattr", "hasattr", "hasattr", "cls.add_args", "vars().items", "vars().items", "vars", "vars"], "function", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.options.parse_args_and_arch", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.registry.set_defaults", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.criterions.label_smoothed_cross_entropy.LabelSmoothedCrossEntropyCriterion.add_args", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.criterions.label_smoothed_cross_entropy.LabelSmoothedCrossEntropyCriterion.add_args", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.criterions.label_smoothed_cross_entropy.LabelSmoothedCrossEntropyCriterion.add_args", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.criterions.label_smoothed_cross_entropy.LabelSmoothedCrossEntropyCriterion.add_args"], ["", "", "def", "parse_args_and_arch", "(", "parser", ",", "input_args", "=", "None", ",", "parse_known", "=", "False", ",", "suppress_defaults", "=", "False", ")", ":", "\n", "    ", "if", "suppress_defaults", ":", "\n", "# Parse args without any default values. This requires us to parse", "\n", "# twice, once to identify all the necessary task/model args, and a second", "\n", "# time with all defaults set to None.", "\n", "        ", "args", "=", "parse_args_and_arch", "(", "\n", "parser", ",", "\n", "input_args", "=", "input_args", ",", "\n", "parse_known", "=", "parse_known", ",", "\n", "suppress_defaults", "=", "False", ",", "\n", ")", "\n", "suppressed_parser", "=", "argparse", ".", "ArgumentParser", "(", "add_help", "=", "False", ",", "parents", "=", "[", "parser", "]", ")", "\n", "suppressed_parser", ".", "set_defaults", "(", "**", "{", "k", ":", "None", "for", "k", ",", "v", "in", "vars", "(", "args", ")", ".", "items", "(", ")", "}", ")", "\n", "args", "=", "suppressed_parser", ".", "parse_args", "(", "input_args", ")", "\n", "return", "argparse", ".", "Namespace", "(", "**", "{", "\n", "k", ":", "v", "\n", "for", "k", ",", "v", "in", "vars", "(", "args", ")", ".", "items", "(", ")", "\n", "if", "v", "is", "not", "None", "\n", "}", ")", "\n", "\n", "", "from", "fairseq", ".", "models", "import", "ARCH_MODEL_REGISTRY", ",", "ARCH_CONFIG_REGISTRY", "\n", "\n", "# The parser doesn't know about model/criterion/optimizer-specific args, so", "\n", "# we parse twice. First we parse the model/criterion/optimizer, then we", "\n", "# parse a second time after adding the *-specific arguments.", "\n", "# If input_args is given, we will parse those args instead of sys.argv.", "\n", "args", ",", "_", "=", "parser", ".", "parse_known_args", "(", "input_args", ")", "\n", "\n", "# Add model-specific args to parser.", "\n", "if", "hasattr", "(", "args", ",", "'arch'", ")", ":", "\n", "        ", "model_specific_group", "=", "parser", ".", "add_argument_group", "(", "\n", "'Model-specific configuration'", ",", "\n", "# Only include attributes which are explicitly given as command-line", "\n", "# arguments or which have default values.", "\n", "argument_default", "=", "argparse", ".", "SUPPRESS", ",", "\n", ")", "\n", "ARCH_MODEL_REGISTRY", "[", "args", ".", "arch", "]", ".", "add_args", "(", "model_specific_group", ")", "\n", "\n", "# Add *-specific args to parser.", "\n", "", "from", "fairseq", ".", "registry", "import", "REGISTRIES", "\n", "for", "registry_name", ",", "REGISTRY", "in", "REGISTRIES", ".", "items", "(", ")", ":", "\n", "        ", "choice", "=", "getattr", "(", "args", ",", "registry_name", ",", "None", ")", "\n", "if", "choice", "is", "not", "None", ":", "\n", "            ", "cls", "=", "REGISTRY", "[", "'registry'", "]", "[", "choice", "]", "\n", "if", "hasattr", "(", "cls", ",", "'add_args'", ")", ":", "\n", "                ", "cls", ".", "add_args", "(", "parser", ")", "\n", "", "", "", "if", "hasattr", "(", "args", ",", "'task'", ")", ":", "\n", "        ", "from", "fairseq", ".", "tasks", "import", "TASK_REGISTRY", "\n", "TASK_REGISTRY", "[", "args", ".", "task", "]", ".", "add_args", "(", "parser", ")", "\n", "", "if", "getattr", "(", "args", ",", "'use_bmuf'", ",", "False", ")", ":", "\n", "# hack to support extra args for block distributed data parallelism", "\n", "        ", "from", "fairseq", ".", "optim", ".", "bmuf", "import", "FairseqBMUF", "\n", "FairseqBMUF", ".", "add_args", "(", "parser", ")", "\n", "\n", "# Parse a second time.", "\n", "", "if", "parse_known", ":", "\n", "        ", "args", ",", "extra", "=", "parser", ".", "parse_known_args", "(", "input_args", ")", "\n", "", "else", ":", "\n", "        ", "args", "=", "parser", ".", "parse_args", "(", "input_args", ")", "\n", "extra", "=", "None", "\n", "\n", "# Post-process args.", "\n", "", "if", "hasattr", "(", "args", ",", "'max_sentences_valid'", ")", "and", "args", ".", "max_sentences_valid", "is", "None", ":", "\n", "        ", "args", ".", "max_sentences_valid", "=", "args", ".", "max_sentences", "\n", "", "if", "hasattr", "(", "args", ",", "'max_tokens_valid'", ")", "and", "args", ".", "max_tokens_valid", "is", "None", ":", "\n", "        ", "args", ".", "max_tokens_valid", "=", "args", ".", "max_tokens", "\n", "", "if", "getattr", "(", "args", ",", "'memory_efficient_fp16'", ",", "False", ")", ":", "\n", "        ", "args", ".", "fp16", "=", "True", "\n", "\n", "# Apply architecture configuration.", "\n", "", "if", "hasattr", "(", "args", ",", "'arch'", ")", ":", "\n", "        ", "ARCH_CONFIG_REGISTRY", "[", "args", ".", "arch", "]", "(", "args", ")", "\n", "\n", "", "if", "parse_known", ":", "\n", "        ", "return", "args", ",", "extra", "\n", "", "else", ":", "\n", "        ", "return", "args", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.options.get_parser": [[131, 185], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_known_args", "fairseq.utils.import_user_module", "argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "REGISTRIES.items", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "TASK_REGISTRY.keys", "registry_name.replace", "REGISTRY[].keys"], "function", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.utils.import_user_module"], ["", "", "def", "get_parser", "(", "desc", ",", "default_task", "=", "'integer_sequence_modeling'", ")", ":", "\n", "# Before creating the true parser, we need to import optional user module", "\n", "# in order to eagerly import custom tasks, optimizers, architectures, etc.", "\n", "    ", "usr_parser", "=", "argparse", ".", "ArgumentParser", "(", "add_help", "=", "False", ",", "allow_abbrev", "=", "False", ")", "\n", "usr_parser", ".", "add_argument", "(", "'--user-dir'", ",", "default", "=", "None", ")", "\n", "usr_args", ",", "_", "=", "usr_parser", ".", "parse_known_args", "(", ")", "\n", "utils", ".", "import_user_module", "(", "usr_args", ")", "\n", "\n", "parser", "=", "argparse", ".", "ArgumentParser", "(", "allow_abbrev", "=", "False", ")", "\n", "# fmt: off", "\n", "parser", ".", "add_argument", "(", "'--no-progress-bar'", ",", "action", "=", "'store_true'", ",", "help", "=", "'disable progress bar'", ")", "\n", "parser", ".", "add_argument", "(", "'--log-interval'", ",", "type", "=", "int", ",", "default", "=", "1000", ",", "metavar", "=", "'N'", ",", "\n", "help", "=", "'log progress every N batches (when progress bar is disabled)'", ")", "\n", "parser", ".", "add_argument", "(", "'--log-format'", ",", "default", "=", "None", ",", "help", "=", "'log format to use'", ",", "\n", "choices", "=", "[", "'json'", ",", "'none'", ",", "'simple'", ",", "'tqdm'", "]", ")", "\n", "parser", ".", "add_argument", "(", "'--tensorboard-logdir'", ",", "metavar", "=", "'DIR'", ",", "default", "=", "''", ",", "\n", "help", "=", "'path to save logs for tensorboard, should match --logdir '", "\n", "'of running tensorboard (default: no tensorboard logging)'", ")", "\n", "parser", ".", "add_argument", "(", "'--seed'", ",", "default", "=", "1", ",", "type", "=", "int", ",", "metavar", "=", "'N'", ",", "\n", "help", "=", "'pseudo random number generator seed'", ")", "\n", "parser", ".", "add_argument", "(", "'--cpu'", ",", "action", "=", "'store_true'", ",", "help", "=", "'use CPU instead of CUDA'", ")", "\n", "parser", ".", "add_argument", "(", "'--fp16'", ",", "action", "=", "'store_true'", ",", "help", "=", "'use FP16'", ")", "\n", "parser", ".", "add_argument", "(", "'--memory-efficient-fp16'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "'use a memory-efficient version of FP16 training; implies --fp16'", ")", "\n", "parser", ".", "add_argument", "(", "'--fp16-init-scale'", ",", "default", "=", "2", "**", "7", ",", "type", "=", "int", ",", "\n", "help", "=", "'default FP16 loss scale'", ")", "\n", "parser", ".", "add_argument", "(", "'--fp16-scale-window'", ",", "type", "=", "int", ",", "\n", "help", "=", "'number of updates before increasing loss scale'", ")", "\n", "parser", ".", "add_argument", "(", "'--fp16-scale-tolerance'", ",", "default", "=", "0.0", ",", "type", "=", "float", ",", "\n", "help", "=", "'pct of updates that can overflow before decreasing the loss scale'", ")", "\n", "parser", ".", "add_argument", "(", "'--min-loss-scale'", ",", "default", "=", "1e-4", ",", "type", "=", "float", ",", "metavar", "=", "'D'", ",", "\n", "help", "=", "'minimum FP16 loss scale, after which training is stopped'", ")", "\n", "parser", ".", "add_argument", "(", "'--threshold-loss-scale'", ",", "type", "=", "float", ",", "\n", "help", "=", "'threshold FP16 loss scale from below'", ")", "\n", "parser", ".", "add_argument", "(", "'--user-dir'", ",", "default", "=", "None", ",", "\n", "help", "=", "'path to a python module containing custom extensions (tasks and/or architectures)'", ")", "\n", "parser", ".", "add_argument", "(", "'--empty-cache-freq'", ",", "default", "=", "0", ",", "type", "=", "int", ",", "\n", "help", "=", "'how often to clear the PyTorch CUDA cache (0 to disable)'", ")", "\n", "\n", "from", "fairseq", ".", "registry", "import", "REGISTRIES", "\n", "for", "registry_name", ",", "REGISTRY", "in", "REGISTRIES", ".", "items", "(", ")", ":", "\n", "        ", "parser", ".", "add_argument", "(", "\n", "'--'", "+", "registry_name", ".", "replace", "(", "'_'", ",", "'-'", ")", ",", "\n", "default", "=", "REGISTRY", "[", "'default'", "]", ",", "\n", "choices", "=", "REGISTRY", "[", "'registry'", "]", ".", "keys", "(", ")", ",", "\n", ")", "\n", "\n", "# Task definitions can be found under fairseq/tasks/", "\n", "", "from", "fairseq", ".", "tasks", "import", "TASK_REGISTRY", "\n", "parser", ".", "add_argument", "(", "'--task'", ",", "metavar", "=", "'TASK'", ",", "default", "=", "default_task", ",", "\n", "choices", "=", "TASK_REGISTRY", ".", "keys", "(", ")", ",", "\n", "help", "=", "'task'", ")", "\n", "# fmt: on", "\n", "return", "parser", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.options.add_dataset_args": [[187, 240], ["parser.add_argument_group", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument"], "function", ["None"], ["", "def", "add_dataset_args", "(", "parser", ",", "train", "=", "False", ",", "gen", "=", "False", ")", ":", "\n", "    ", "group", "=", "parser", ".", "add_argument_group", "(", "'Dataset and data loading'", ")", "\n", "# fmt: off", "\n", "group", ".", "add_argument", "(", "'--num-workers'", ",", "default", "=", "1", ",", "type", "=", "int", ",", "metavar", "=", "'N'", ",", "\n", "help", "=", "'how many subprocesses to use for data loading'", ")", "\n", "group", ".", "add_argument", "(", "'--skip-invalid-size-inputs-valid-test'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "'ignore too long or too short lines in valid and test set'", ")", "\n", "group", ".", "add_argument", "(", "'--max-tokens'", ",", "type", "=", "int", ",", "metavar", "=", "'N'", ",", "\n", "help", "=", "'maximum number of tokens in a batch'", ")", "\n", "group", ".", "add_argument", "(", "'--max-sentences'", ",", "'--batch-size'", ",", "type", "=", "int", ",", "metavar", "=", "'N'", ",", "\n", "help", "=", "'maximum number of sentences in a batch'", ")", "\n", "group", ".", "add_argument", "(", "'--required-batch-size-multiple'", ",", "default", "=", "8", ",", "type", "=", "int", ",", "metavar", "=", "'N'", ",", "\n", "help", "=", "'batch size will be a multiplier of this value'", ")", "\n", "if", "train", ":", "\n", "        ", "group", ".", "add_argument", "(", "'--train-subset'", ",", "default", "=", "'train'", ",", "metavar", "=", "'SPLIT'", ",", "\n", "choices", "=", "[", "'train'", ",", "'valid'", ",", "'test'", "]", ",", "\n", "help", "=", "'data subset to use for training (train, valid, test)'", ")", "\n", "group", ".", "add_argument", "(", "'--valid-subset'", ",", "default", "=", "'valid'", ",", "metavar", "=", "'SPLIT'", ",", "\n", "help", "=", "'comma separated list of data subsets to use for validation'", "\n", "' (train, valid, valid1, test, test1)'", ")", "\n", "group", ".", "add_argument", "(", "'--validate-interval'", ",", "type", "=", "int", ",", "default", "=", "1", ",", "metavar", "=", "'N'", ",", "\n", "help", "=", "'validate every N epochs'", ")", "\n", "group", ".", "add_argument", "(", "'--fixed-validation-seed'", ",", "default", "=", "None", ",", "type", "=", "int", ",", "metavar", "=", "'N'", ",", "\n", "help", "=", "'specified random seed for validation'", ")", "\n", "group", ".", "add_argument", "(", "'--disable-validation'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "'disable validation'", ")", "\n", "group", ".", "add_argument", "(", "'--max-tokens-valid'", ",", "type", "=", "int", ",", "metavar", "=", "'N'", ",", "\n", "help", "=", "'maximum number of tokens in a validation batch'", "\n", "' (defaults to --max-tokens)'", ")", "\n", "group", ".", "add_argument", "(", "'--max-sentences-valid'", ",", "type", "=", "int", ",", "metavar", "=", "'N'", ",", "\n", "help", "=", "'maximum number of sentences in a validation batch'", "\n", "' (defaults to --max-sentences)'", ")", "\n", "group", ".", "add_argument", "(", "'--curriculum'", ",", "default", "=", "0", ",", "type", "=", "int", ",", "metavar", "=", "'N'", ",", "\n", "help", "=", "'don\\'t shuffle batches for first N epochs'", ")", "\n", "\n", "group", ".", "add_argument", "(", "'--ae-dataset'", ",", "default", "=", "None", ",", "type", "=", "str", ",", "\n", "help", "=", "'name of ae dataset'", ")", "\n", "group", ".", "add_argument", "(", "'--ae-data-path'", ",", "default", "=", "None", ",", "type", "=", "str", ",", "\n", "help", "=", "'path to the ae dataset'", ")", "\n", "group", ".", "add_argument", "(", "'--ae-checkpoint'", ",", "default", "=", "None", ",", "type", "=", "str", ",", "\n", "help", "=", "'path to the auto encoder checkpoint'", ")", "\n", "group", ".", "add_argument", "(", "'--ae-batch-size'", ",", "default", "=", "512", ",", "type", "=", "int", ",", "\n", "help", "=", "'batch size of auto encoder'", ")", "\n", "group", ".", "add_argument", "(", "'--original'", ",", "action", "=", "'store_true'", ",", "help", "=", "'VQ-VAE'", ")", "\n", "", "if", "gen", ":", "\n", "        ", "group", ".", "add_argument", "(", "'--gen-subset'", ",", "default", "=", "'test'", ",", "metavar", "=", "'SPLIT'", ",", "\n", "help", "=", "'data subset to generate (train, valid, test)'", ")", "\n", "group", ".", "add_argument", "(", "'--num-shards'", ",", "default", "=", "1", ",", "type", "=", "int", ",", "metavar", "=", "'N'", ",", "\n", "help", "=", "'shard generation over N shards'", ")", "\n", "group", ".", "add_argument", "(", "'--shard-id'", ",", "default", "=", "0", ",", "type", "=", "int", ",", "metavar", "=", "'ID'", ",", "\n", "help", "=", "'id of the shard to generate (id < num_shards)'", ")", "\n", "# fmt: on", "\n", "", "return", "group", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.options.add_distributed_training_args": [[242, 278], ["parser.add_argument_group", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "max", "torch.cuda.device_count"], "function", ["None"], ["", "def", "add_distributed_training_args", "(", "parser", ")", ":", "\n", "    ", "group", "=", "parser", ".", "add_argument_group", "(", "'Distributed training'", ")", "\n", "# fmt: off", "\n", "group", ".", "add_argument", "(", "'--distributed-world-size'", ",", "type", "=", "int", ",", "metavar", "=", "'N'", ",", "\n", "default", "=", "max", "(", "1", ",", "torch", ".", "cuda", ".", "device_count", "(", ")", ")", ",", "\n", "help", "=", "'total number of GPUs across all nodes (default: all visible GPUs)'", ")", "\n", "group", ".", "add_argument", "(", "'--distributed-rank'", ",", "default", "=", "0", ",", "type", "=", "int", ",", "\n", "help", "=", "'rank of the current worker'", ")", "\n", "group", ".", "add_argument", "(", "'--distributed-backend'", ",", "default", "=", "'nccl'", ",", "type", "=", "str", ",", "\n", "help", "=", "'distributed backend'", ")", "\n", "group", ".", "add_argument", "(", "'--distributed-init-method'", ",", "default", "=", "None", ",", "type", "=", "str", ",", "\n", "help", "=", "'typically tcp://hostname:port that will be used to '", "\n", "'establish initial connetion'", ")", "\n", "group", ".", "add_argument", "(", "'--distributed-port'", ",", "default", "=", "-", "1", ",", "type", "=", "int", ",", "\n", "help", "=", "'port number (not required if using --distributed-init-method)'", ")", "\n", "group", ".", "add_argument", "(", "'--device-id'", ",", "'--local_rank'", ",", "default", "=", "0", ",", "type", "=", "int", ",", "\n", "help", "=", "'which GPU to use (usually configured automatically)'", ")", "\n", "group", ".", "add_argument", "(", "'--distributed-no-spawn'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "'do not spawn multiple processes even if multiple GPUs are visible'", ")", "\n", "group", ".", "add_argument", "(", "'--ddp-backend'", ",", "default", "=", "'c10d'", ",", "type", "=", "str", ",", "\n", "choices", "=", "[", "'c10d'", ",", "'no_c10d'", "]", ",", "\n", "help", "=", "'DistributedDataParallel backend'", ")", "\n", "group", ".", "add_argument", "(", "'--bucket-cap-mb'", ",", "default", "=", "25", ",", "type", "=", "int", ",", "metavar", "=", "'MB'", ",", "\n", "help", "=", "'bucket size for reduction'", ")", "\n", "group", ".", "add_argument", "(", "'--fix-batches-to-gpus'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "'don\\'t shuffle batches between GPUs; this reduces overall '", "\n", "'randomness and may affect precision but avoids the cost of '", "\n", "'re-reading the data'", ")", "\n", "group", ".", "add_argument", "(", "'--find-unused-parameters'", ",", "default", "=", "False", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "'disable unused parameter detection (not applicable to '", "\n", "'no_c10d ddp-backend'", ")", "\n", "group", ".", "add_argument", "(", "'--fast-stat-sync'", ",", "default", "=", "False", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "'Enable fast sync of stats between nodes, this hardcodes to '", "\n", "'sync only some default stats from logging_output.'", ")", "\n", "# fmt: on", "\n", "return", "group", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.options.add_optimization_args": [[280, 305], ["parser.add_argument_group", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "options.eval_str_list"], "function", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.options.eval_str_list"], ["", "def", "add_optimization_args", "(", "parser", ")", ":", "\n", "    ", "group", "=", "parser", ".", "add_argument_group", "(", "'Optimization'", ")", "\n", "# fmt: off", "\n", "group", ".", "add_argument", "(", "'--max-epoch'", ",", "'--me'", ",", "default", "=", "0", ",", "type", "=", "int", ",", "metavar", "=", "'N'", ",", "\n", "help", "=", "'force stop training at specified epoch'", ")", "\n", "group", ".", "add_argument", "(", "'--max-update'", ",", "'--mu'", ",", "default", "=", "0", ",", "type", "=", "int", ",", "metavar", "=", "'N'", ",", "\n", "help", "=", "'force stop training at specified update'", ")", "\n", "group", ".", "add_argument", "(", "'--clip-norm'", ",", "default", "=", "25", ",", "type", "=", "float", ",", "metavar", "=", "'NORM'", ",", "\n", "help", "=", "'clip threshold of gradients'", ")", "\n", "group", ".", "add_argument", "(", "'--sentence-avg'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "'normalize gradients by the number of sentences in a batch'", "\n", "' (default is to normalize by number of tokens)'", ")", "\n", "group", ".", "add_argument", "(", "'--update-freq'", ",", "default", "=", "'1'", ",", "metavar", "=", "'N1,N2,...,N_K'", ",", "\n", "type", "=", "lambda", "uf", ":", "eval_str_list", "(", "uf", ",", "type", "=", "int", ")", ",", "\n", "help", "=", "'update parameters every N_i batches, when in epoch i'", ")", "\n", "group", ".", "add_argument", "(", "'--lr'", ",", "'--learning-rate'", ",", "default", "=", "'0.25'", ",", "type", "=", "eval_str_list", ",", "\n", "metavar", "=", "'LR_1,LR_2,...,LR_N'", ",", "\n", "help", "=", "'learning rate for the first N epochs; all epochs >N using LR_N'", "\n", "' (note: this may be interpreted differently depending on --lr-scheduler)'", ")", "\n", "group", ".", "add_argument", "(", "'--min-lr'", ",", "default", "=", "-", "1", ",", "type", "=", "float", ",", "metavar", "=", "'LR'", ",", "\n", "help", "=", "'stop training when the learning rate reaches this minimum'", ")", "\n", "group", ".", "add_argument", "(", "'--use-bmuf'", ",", "default", "=", "False", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "'specify global optimizer for syncing models on different GPUs/shards'", ")", "\n", "# fmt: on", "\n", "return", "group", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.options.add_checkpoint_args": [[307, 347], ["parser.add_argument_group", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument"], "function", ["None"], ["", "def", "add_checkpoint_args", "(", "parser", ")", ":", "\n", "    ", "group", "=", "parser", ".", "add_argument_group", "(", "'Checkpointing'", ")", "\n", "# fmt: off", "\n", "group", ".", "add_argument", "(", "'--save-dir'", ",", "metavar", "=", "'DIR'", ",", "default", "=", "'checkpoints'", ",", "\n", "help", "=", "'path to save checkpoints'", ")", "\n", "group", ".", "add_argument", "(", "'--restore-file'", ",", "default", "=", "'checkpoint_last.pt'", ",", "\n", "help", "=", "'filename from which to load checkpoint '", "\n", "'(default: <save-dir>/checkpoint_last.pt'", ")", "\n", "group", ".", "add_argument", "(", "'--reset-dataloader'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "'if set, does not reload dataloader state from the checkpoint'", ")", "\n", "group", ".", "add_argument", "(", "'--reset-lr-scheduler'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "'if set, does not load lr scheduler state from the checkpoint'", ")", "\n", "group", ".", "add_argument", "(", "'--reset-meters'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "'if set, does not load meters from the checkpoint'", ")", "\n", "group", ".", "add_argument", "(", "'--reset-optimizer'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "'if set, does not load optimizer state from the checkpoint'", ")", "\n", "group", ".", "add_argument", "(", "'--optimizer-overrides'", ",", "default", "=", "\"{}\"", ",", "type", "=", "str", ",", "metavar", "=", "'DICT'", ",", "\n", "help", "=", "'a dictionary used to override optimizer args when loading a checkpoint'", ")", "\n", "group", ".", "add_argument", "(", "'--save-interval'", ",", "type", "=", "int", ",", "default", "=", "1", ",", "metavar", "=", "'N'", ",", "\n", "help", "=", "'save a checkpoint every N epochs'", ")", "\n", "group", ".", "add_argument", "(", "'--save-interval-updates'", ",", "type", "=", "int", ",", "default", "=", "0", ",", "metavar", "=", "'N'", ",", "\n", "help", "=", "'save a checkpoint (and validate) every N updates'", ")", "\n", "group", ".", "add_argument", "(", "'--keep-interval-updates'", ",", "type", "=", "int", ",", "default", "=", "-", "1", ",", "metavar", "=", "'N'", ",", "\n", "help", "=", "'keep the last N checkpoints saved with --save-interval-updates'", ")", "\n", "group", ".", "add_argument", "(", "'--keep-last-epochs'", ",", "type", "=", "int", ",", "default", "=", "-", "1", ",", "metavar", "=", "'N'", ",", "\n", "help", "=", "'keep last N epoch checkpoints'", ")", "\n", "group", ".", "add_argument", "(", "'--no-save'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "'don\\'t save models or checkpoints'", ")", "\n", "group", ".", "add_argument", "(", "'--no-epoch-checkpoints'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "'only store last and best checkpoints'", ")", "\n", "group", ".", "add_argument", "(", "'--no-last-checkpoints'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "'don\\'t store last checkpoints'", ")", "\n", "group", ".", "add_argument", "(", "'--no-save-optimizer-state'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "'don\\'t save optimizer-state as part of checkpoint'", ")", "\n", "group", ".", "add_argument", "(", "'--best-checkpoint-metric'", ",", "type", "=", "str", ",", "default", "=", "'loss'", ",", "\n", "help", "=", "'metric to use for saving \"best\" checkpoints'", ")", "\n", "group", ".", "add_argument", "(", "'--maximize-best-checkpoint-metric'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "'select the largest metric value for saving \"best\" checkpoints'", ")", "\n", "# fmt: on", "\n", "return", "group", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.options.add_common_eval_args": [[349, 362], ["group.add_argument", "group.add_argument", "group.add_argument", "group.add_argument", "group.add_argument"], "function", ["None"], ["", "def", "add_common_eval_args", "(", "group", ")", ":", "\n", "# fmt: off", "\n", "    ", "group", ".", "add_argument", "(", "'--path'", ",", "metavar", "=", "'FILE'", ",", "\n", "help", "=", "'path(s) to model file(s), colon separated'", ")", "\n", "group", ".", "add_argument", "(", "'--remove-bpe'", ",", "nargs", "=", "'?'", ",", "const", "=", "'@@ '", ",", "default", "=", "None", ",", "\n", "help", "=", "'remove BPE tokens before scoring (can be set to sentencepiece)'", ")", "\n", "group", ".", "add_argument", "(", "'--quiet'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "'only print final scores'", ")", "\n", "group", ".", "add_argument", "(", "'--model-overrides'", ",", "default", "=", "\"{}\"", ",", "type", "=", "str", ",", "metavar", "=", "'DICT'", ",", "\n", "help", "=", "'a dictionary used to override model args at generation '", "\n", "'that were used during model training'", ")", "\n", "group", ".", "add_argument", "(", "'--results-path'", ",", "metavar", "=", "'RESDIR'", ",", "type", "=", "str", ",", "default", "=", "None", ",", "\n", "help", "=", "'path to save eval results (optional)\"'", ")", "\n", "# fmt: on", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.options.add_generation_args": [[365, 409], ["parser.add_argument_group", "options.add_common_eval_args", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument"], "function", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.options.add_common_eval_args"], ["", "def", "add_generation_args", "(", "parser", ")", ":", "\n", "    ", "group", "=", "parser", ".", "add_argument_group", "(", "'Generation'", ")", "\n", "add_common_eval_args", "(", "group", ")", "\n", "# fmt: off", "\n", "group", ".", "add_argument", "(", "'--beam'", ",", "default", "=", "5", ",", "type", "=", "int", ",", "metavar", "=", "'N'", ",", "\n", "help", "=", "'beam size'", ")", "\n", "group", ".", "add_argument", "(", "'--nbest'", ",", "default", "=", "1", ",", "type", "=", "int", ",", "metavar", "=", "'N'", ",", "\n", "help", "=", "'number of hypotheses to output'", ")", "\n", "group", ".", "add_argument", "(", "'--no-early-stop'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "'deprecated'", ")", "\n", "group", ".", "add_argument", "(", "'--no-beamable-mm'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "'don\\'t use BeamableMM in attention layers'", ")", "\n", "group", ".", "add_argument", "(", "'--replace-unk'", ",", "nargs", "=", "'?'", ",", "const", "=", "True", ",", "default", "=", "None", ",", "\n", "help", "=", "'perform unknown replacement (optionally with alignment dictionary)'", ")", "\n", "group", ".", "add_argument", "(", "'--prefix-size'", ",", "default", "=", "0", ",", "type", "=", "int", ",", "metavar", "=", "'PS'", ",", "\n", "help", "=", "'initialize generation by target prefix of given length'", ")", "\n", "group", ".", "add_argument", "(", "'--sampling'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "'sample hypotheses instead of using beam search'", ")", "\n", "group", ".", "add_argument", "(", "'--sampling-topk'", ",", "default", "=", "-", "1", ",", "type", "=", "int", ",", "metavar", "=", "'PS'", ",", "\n", "help", "=", "'sample from top K likely next words instead of all words'", ")", "\n", "group", ".", "add_argument", "(", "'--sampling-topp'", ",", "default", "=", "-", "1.0", ",", "type", "=", "float", ",", "metavar", "=", "'PS'", ",", "\n", "help", "=", "'sample from the smallest set whose cumulative probability mass exceeds p for next words'", ")", "\n", "group", ".", "add_argument", "(", "'--temperature'", ",", "default", "=", "1.", ",", "type", "=", "float", ",", "metavar", "=", "'N'", ",", "\n", "help", "=", "'temperature for generation'", ")", "\n", "group", ".", "add_argument", "(", "'--diverse-beam-groups'", ",", "default", "=", "-", "1", ",", "type", "=", "int", ",", "metavar", "=", "'N'", ",", "\n", "help", "=", "'number of groups for Diverse Beam Search'", ")", "\n", "group", ".", "add_argument", "(", "'--diverse-beam-strength'", ",", "default", "=", "0.5", ",", "type", "=", "float", ",", "metavar", "=", "'N'", ",", "\n", "help", "=", "'strength of diversity penalty for Diverse Beam Search'", ")", "\n", "group", ".", "add_argument", "(", "'--print-step'", ",", "action", "=", "'store_true'", ")", "\n", "\n", "# arguments for iterative refinement generator", "\n", "group", ".", "add_argument", "(", "'--iter-decode-eos-penalty'", ",", "default", "=", "0.0", ",", "type", "=", "float", ",", "metavar", "=", "'N'", ",", "\n", "help", "=", "'if > 0.0, it penalized early-stopping in decoding.'", ")", "\n", "group", ".", "add_argument", "(", "'--iter-decode-max-iter'", ",", "default", "=", "10", ",", "type", "=", "int", ",", "metavar", "=", "'N'", ",", "\n", "help", "=", "'maximum iterations for iterative refinement.'", ")", "\n", "group", ".", "add_argument", "(", "'--iter-decode-force-max-iter'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "'if set, run exact the maximum number of iterations without early stop'", ")", "\n", "group", ".", "add_argument", "(", "'--retain-iter-history'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "'if set, decoding returns the whole history of iterative refinement'", ")", "\n", "\n", "# special decoding format for advanced decoding.", "\n", "group", ".", "add_argument", "(", "'--decoding-format'", ",", "default", "=", "None", ",", "type", "=", "str", ",", "choices", "=", "[", "'unigram'", ",", "'ensemble'", ",", "'vote'", ",", "'dp'", ",", "'bs'", "]", ")", "\n", "# fmt: on", "\n", "return", "group", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.options.add_model_args": [[411, 428], ["parser.add_argument_group", "parser.add_argument_group.add_argument", "ARCH_MODEL_REGISTRY.keys"], "function", ["None"], ["", "def", "add_model_args", "(", "parser", ")", ":", "\n", "    ", "group", "=", "parser", ".", "add_argument_group", "(", "'Model configuration'", ")", "\n", "# fmt: off", "\n", "\n", "# Model definitions can be found under fairseq/models/", "\n", "#", "\n", "# The model architecture can be specified in several ways.", "\n", "# In increasing order of priority:", "\n", "# 1) model defaults (lowest priority)", "\n", "# 2) --arch argument", "\n", "# 3) --encoder/decoder-* arguments (highest priority)", "\n", "from", "fairseq", ".", "models", "import", "ARCH_MODEL_REGISTRY", "\n", "group", ".", "add_argument", "(", "'--arch'", ",", "'-a'", ",", "default", "=", "'fconv'", ",", "metavar", "=", "'ARCH'", ",", "required", "=", "True", ",", "\n", "choices", "=", "ARCH_MODEL_REGISTRY", ".", "keys", "(", ")", ",", "\n", "help", "=", "'Model Architecture'", ")", "\n", "# fmt: on", "\n", "return", "group", "\n", "", ""]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.distributed_utils.is_master": [[18, 20], ["None"], "function", ["None"], ["def", "is_master", "(", "args", ")", ":", "\n", "    ", "return", "args", ".", "distributed_rank", "==", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.distributed_utils.infer_init_method": [[22, 69], ["all", "int", "int", "os.environ.get", "os.environ.get", "subprocess.check_output", "int", "os.environ.get", "os.environ.get", "int", "int", "int", "int", "int", "int", "int", "[].decode", "os.environ.get", "os.environ.get", "os.environ.get", "os.environ.get", "os.environ.get", "subprocess.check_output.split"], "function", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq._hub_utils.TokenizerHubInterface.decode"], ["", "def", "infer_init_method", "(", "args", ")", ":", "\n", "    ", "if", "args", ".", "distributed_init_method", "is", "not", "None", ":", "\n", "        ", "return", "\n", "\n", "# support torch.distributed.launch", "\n", "", "if", "all", "(", "key", "in", "os", ".", "environ", "for", "key", "in", "[", "\n", "'MASTER_ADDR'", ",", "'MASTER_PORT'", ",", "'WORLD_SIZE'", ",", "'RANK'", "\n", "]", ")", ":", "\n", "        ", "args", ".", "distributed_init_method", "=", "'env://'", "\n", "args", ".", "distributed_world_size", "=", "int", "(", "os", ".", "environ", "[", "'WORLD_SIZE'", "]", ")", "\n", "args", ".", "distributed_rank", "=", "int", "(", "os", ".", "environ", "[", "'RANK'", "]", ")", "\n", "\n", "# we can determine the init method automatically for Slurm", "\n", "", "elif", "args", ".", "distributed_port", ">", "0", ":", "\n", "        ", "node_list", "=", "os", ".", "environ", ".", "get", "(", "'SLURM_STEP_NODELIST'", ")", "\n", "if", "node_list", "is", "None", ":", "\n", "            ", "node_list", "=", "os", ".", "environ", ".", "get", "(", "'SLURM_JOB_NODELIST'", ")", "\n", "", "if", "node_list", "is", "not", "None", ":", "\n", "            ", "try", ":", "\n", "                ", "hostnames", "=", "subprocess", ".", "check_output", "(", "[", "'scontrol'", ",", "'show'", ",", "'hostnames'", ",", "node_list", "]", ")", "\n", "args", ".", "distributed_init_method", "=", "'tcp://{host}:{port}'", ".", "format", "(", "\n", "host", "=", "hostnames", ".", "split", "(", ")", "[", "0", "]", ".", "decode", "(", "'utf-8'", ")", ",", "\n", "port", "=", "args", ".", "distributed_port", ",", "\n", ")", "\n", "nnodes", "=", "int", "(", "os", ".", "environ", ".", "get", "(", "'SLURM_NNODES'", ")", ")", "\n", "ntasks_per_node", "=", "os", ".", "environ", ".", "get", "(", "'SLURM_NTASKS_PER_NODE'", ")", "\n", "if", "ntasks_per_node", "is", "not", "None", ":", "\n", "                    ", "ntasks_per_node", "=", "int", "(", "ntasks_per_node", ")", "\n", "", "else", ":", "\n", "                    ", "ntasks", "=", "int", "(", "os", ".", "environ", ".", "get", "(", "'SLURM_NTASKS'", ")", ")", "\n", "nnodes", "=", "int", "(", "os", ".", "environ", ".", "get", "(", "'SLURM_NNODES'", ")", ")", "\n", "assert", "ntasks", "%", "nnodes", "==", "0", "\n", "ntasks_per_node", "=", "int", "(", "ntasks", "/", "nnodes", ")", "\n", "", "if", "ntasks_per_node", "==", "1", ":", "\n", "                    ", "assert", "args", ".", "distributed_world_size", "%", "nnodes", "==", "0", "\n", "gpus_per_node", "=", "args", ".", "distributed_world_size", "//", "nnodes", "\n", "node_id", "=", "int", "(", "os", ".", "environ", ".", "get", "(", "'SLURM_NODEID'", ")", ")", "\n", "args", ".", "distributed_rank", "=", "node_id", "*", "gpus_per_node", "\n", "", "else", ":", "\n", "                    ", "assert", "ntasks_per_node", "==", "args", ".", "distributed_world_size", "//", "nnodes", "\n", "args", ".", "distributed_no_spawn", "=", "True", "\n", "args", ".", "distributed_rank", "=", "int", "(", "os", ".", "environ", ".", "get", "(", "'SLURM_PROCID'", ")", ")", "\n", "args", ".", "device_id", "=", "int", "(", "os", ".", "environ", ".", "get", "(", "'SLURM_LOCALID'", ")", ")", "\n", "", "", "except", "subprocess", ".", "CalledProcessError", "as", "e", ":", "# scontrol failed", "\n", "                ", "raise", "e", "\n", "", "except", "FileNotFoundError", ":", "# Slurm is not installed", "\n", "                ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.distributed_utils.distributed_init": [[71, 99], ["torch.distributed.is_initialized", "torch.distributed.is_initialized", "torch.distributed.get_rank", "torch.distributed.get_rank", "ValueError", "warnings.warn", "distributed_utils.suppress_output.print", "torch.init_process_group", "distributed_utils.suppress_output.print", "torch.cuda.is_available", "torch.cuda.is_available", "distributed_utils.suppress_output", "torch.all_reduce", "torch.all_reduce", "distributed_utils.is_master", "socket.gethostname", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros"], "function", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.distributed_utils.get_rank", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.distributed_utils.get_rank", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.progress_bar.tensorboard_log_wrapper.print", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.progress_bar.tensorboard_log_wrapper.print", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.distributed_utils.suppress_output", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.distributed_utils.all_reduce", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.distributed_utils.all_reduce", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.distributed_utils.is_master"], ["", "", "", "", "def", "distributed_init", "(", "args", ")", ":", "\n", "    ", "if", "args", ".", "distributed_world_size", "==", "1", ":", "\n", "        ", "raise", "ValueError", "(", "'Cannot initialize distributed with distributed_world_size=1'", ")", "\n", "\n", "", "if", "torch", ".", "distributed", ".", "is_initialized", "(", ")", ":", "\n", "        ", "warnings", ".", "warn", "(", "'Distributed is already initialized, cannot initialize twice!'", ")", "\n", "", "else", ":", "\n", "        ", "print", "(", "'| distributed init (rank {}): {}'", ".", "format", "(", "\n", "args", ".", "distributed_rank", ",", "args", ".", "distributed_init_method", ")", ",", "flush", "=", "True", ")", "\n", "dist", ".", "init_process_group", "(", "\n", "backend", "=", "args", ".", "distributed_backend", ",", "\n", "init_method", "=", "args", ".", "distributed_init_method", ",", "\n", "world_size", "=", "args", ".", "distributed_world_size", ",", "\n", "rank", "=", "args", ".", "distributed_rank", ",", "\n", ")", "\n", "print", "(", "'| initialized host {} as rank {}'", ".", "format", "(", "\n", "socket", ".", "gethostname", "(", ")", ",", "args", ".", "distributed_rank", ")", ",", "flush", "=", "True", ")", "\n", "\n", "# perform a dummy all-reduce to initialize the NCCL communicator", "\n", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "            ", "dist", ".", "all_reduce", "(", "torch", ".", "zeros", "(", "1", ")", ".", "cuda", "(", ")", ")", "\n", "", "else", ":", "\n", "            ", "dist", ".", "all_reduce", "(", "torch", ".", "zeros", "(", "1", ")", ")", "\n", "\n", "", "suppress_output", "(", "is_master", "(", "args", ")", ")", "\n", "\n", "", "args", ".", "distributed_rank", "=", "torch", ".", "distributed", ".", "get_rank", "(", ")", "\n", "return", "args", ".", "distributed_rank", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.distributed_utils.suppress_output": [[101, 112], ["kwargs.pop", "builtin_print"], "function", ["None"], ["", "def", "suppress_output", "(", "is_master", ")", ":", "\n", "    ", "\"\"\"Suppress printing on the current device. Force printing with `force=True`.\"\"\"", "\n", "import", "builtins", "as", "__builtin__", "\n", "builtin_print", "=", "__builtin__", ".", "print", "\n", "\n", "def", "print", "(", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "force", "=", "kwargs", ".", "pop", "(", "'force'", ",", "False", ")", "\n", "if", "is_master", "or", "force", ":", "\n", "            ", "builtin_print", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n", "", "", "__builtin__", ".", "print", "=", "print", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.distributed_utils.get_rank": [[114, 116], ["torch.get_rank"], "function", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.distributed_utils.get_rank"], ["", "def", "get_rank", "(", ")", ":", "\n", "    ", "return", "dist", ".", "get_rank", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.distributed_utils.get_world_size": [[118, 120], ["torch.get_world_size"], "function", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.distributed_utils.get_world_size"], ["", "def", "get_world_size", "(", ")", ":", "\n", "    ", "return", "dist", ".", "get_world_size", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.distributed_utils.get_default_group": [[122, 124], ["None"], "function", ["None"], ["", "def", "get_default_group", "(", ")", ":", "\n", "    ", "return", "dist", ".", "group", ".", "WORLD", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.distributed_utils.all_reduce": [[126, 130], ["torch.all_reduce", "distributed_utils.get_default_group"], "function", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.distributed_utils.all_reduce", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.distributed_utils.get_default_group"], ["", "def", "all_reduce", "(", "tensor", ",", "group", "=", "None", ")", ":", "\n", "    ", "if", "group", "is", "None", ":", "\n", "        ", "group", "=", "get_default_group", "(", ")", "\n", "", "return", "dist", ".", "all_reduce", "(", "tensor", ",", "group", "=", "group", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.distributed_utils.all_gather_list": [[132, 182], ["distributed_utils.get_rank", "distributed_utils.get_world_size", "buffer.zero_", "pickle.dumps", "len", "torch.ByteTensor", "torch.ByteTensor", "buffer[].copy_", "distributed_utils.all_reduce", "torch.cuda.ByteTensor", "torch.cuda.ByteTensor", "torch.ByteTensor().pin_memory", "torch.ByteTensor().pin_memory", "ValueError", "list", "range", "hasattr", "all_gather_list._buffer.numel", "Exception", "torch.ByteTensor", "torch.ByteTensor", "fairseq.utils.item", "result.append", "fairseq.utils.item", "pickle.loads", "bytes", "out_buffer[].tolist"], "function", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.distributed_utils.get_rank", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.distributed_utils.get_world_size", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.distributed_utils.all_reduce", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.utils.item", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.utils.item"], ["", "def", "all_gather_list", "(", "data", ",", "group", "=", "None", ",", "max_size", "=", "16384", ")", ":", "\n", "    ", "\"\"\"Gathers arbitrary data from all nodes into a list.\n\n    Similar to :func:`~torch.distributed.all_gather` but for arbitrary Python\n    data. Note that *data* must be picklable.\n\n    Args:\n        data (Any): data from the local worker to be gathered on other workers\n        group (optional): group of the collective\n        max_size (int, optional): maximum size of the data to be gathered\n            across workers\n    \"\"\"", "\n", "rank", "=", "get_rank", "(", ")", "\n", "world_size", "=", "get_world_size", "(", ")", "\n", "\n", "buffer_size", "=", "max_size", "*", "world_size", "\n", "if", "not", "hasattr", "(", "all_gather_list", ",", "'_buffer'", ")", "or", "all_gather_list", ".", "_buffer", ".", "numel", "(", ")", "<", "buffer_size", ":", "\n", "        ", "all_gather_list", ".", "_buffer", "=", "torch", ".", "cuda", ".", "ByteTensor", "(", "buffer_size", ")", "\n", "all_gather_list", ".", "_cpu_buffer", "=", "torch", ".", "ByteTensor", "(", "max_size", ")", ".", "pin_memory", "(", ")", "\n", "", "buffer", "=", "all_gather_list", ".", "_buffer", "\n", "buffer", ".", "zero_", "(", ")", "\n", "cpu_buffer", "=", "all_gather_list", ".", "_cpu_buffer", "\n", "\n", "enc", "=", "pickle", ".", "dumps", "(", "data", ")", "\n", "enc_size", "=", "len", "(", "enc", ")", "\n", "if", "enc_size", "+", "2", ">", "max_size", ":", "\n", "        ", "raise", "ValueError", "(", "'encoded data exceeds max_size: {}'", ".", "format", "(", "enc_size", "+", "2", ")", ")", "\n", "", "assert", "max_size", "<", "255", "*", "256", "\n", "\n", "cpu_buffer", "[", "0", "]", "=", "enc_size", "//", "255", "# this encoding works for max_size < 65k", "\n", "cpu_buffer", "[", "1", "]", "=", "enc_size", "%", "255", "\n", "cpu_buffer", "[", "2", ":", "enc_size", "+", "2", "]", "=", "torch", ".", "ByteTensor", "(", "list", "(", "enc", ")", ")", "\n", "start", "=", "rank", "*", "max_size", "\n", "size", "=", "enc_size", "+", "2", "\n", "buffer", "[", "start", ":", "start", "+", "size", "]", ".", "copy_", "(", "cpu_buffer", "[", ":", "size", "]", ")", "\n", "\n", "all_reduce", "(", "buffer", ",", "group", "=", "group", ")", "\n", "\n", "try", ":", "\n", "        ", "result", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "world_size", ")", ":", "\n", "            ", "out_buffer", "=", "buffer", "[", "i", "*", "max_size", ":", "(", "i", "+", "1", ")", "*", "max_size", "]", "\n", "size", "=", "(", "255", "*", "utils", ".", "item", "(", "out_buffer", "[", "0", "]", ")", ")", "+", "utils", ".", "item", "(", "out_buffer", "[", "1", "]", ")", "\n", "if", "size", ">", "0", ":", "\n", "                ", "result", ".", "append", "(", "pickle", ".", "loads", "(", "bytes", "(", "out_buffer", "[", "2", ":", "size", "+", "2", "]", ".", "tolist", "(", ")", ")", ")", ")", "\n", "", "", "return", "result", "\n", "", "except", "pickle", ".", "UnpicklingError", ":", "\n", "        ", "raise", "Exception", "(", "\n", "'Unable to unpickle data from other workers. all_gather_list requires all '", "\n", "'workers to enter the function together, so this error usually indicates '", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.legacy_distributed_data_parallel.LegacyDistributedDataParallel.__init__": [[44, 68], ["torch.nn.Module.__init__", "min", "legacy_distributed_data_parallel.LegacyDistributedDataParallel._register_grad_hook", "sum", "p.numel", "module.parameters"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.dummy_dictionary.DummyDictionary.__init__", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.legacy_distributed_data_parallel.LegacyDistributedDataParallel._register_grad_hook"], ["def", "__init__", "(", "self", ",", "module", ",", "world_size", ",", "process_group", "=", "None", ",", "buffer_size", "=", "2", "**", "28", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "module", "=", "module", "\n", "self", ".", "world_size", "=", "world_size", "\n", "self", ".", "process_group", "=", "process_group", "\n", "\n", "# Never use a bigger buffer than the number of model params", "\n", "self", ".", "buffer_size", "=", "min", "(", "buffer_size", ",", "sum", "(", "p", ".", "numel", "(", ")", "for", "p", "in", "module", ".", "parameters", "(", ")", ")", ")", "\n", "self", ".", "buffer", "=", "None", "\n", "\n", "# Flag used by the NCCL backend to make sure we only reduce gradients", "\n", "# one time in the execution engine", "\n", "self", ".", "need_reduction", "=", "False", "\n", "\n", "# We can also forcibly accumulate grads locally and only do the", "\n", "# all-reduce at some later time", "\n", "self", ".", "accumulate_grads", "=", "False", "\n", "\n", "# For NCCL backend, since every single NCCL call is asynchoronous, we", "\n", "# therefore directly enqueue all the NCCL reduction calls to the", "\n", "# default CUDA stream without spawning up other reduction threads.", "\n", "# This achieves the best performance.", "\n", "self", ".", "_register_grad_hook", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.legacy_distributed_data_parallel.LegacyDistributedDataParallel.__getstate__": [[69, 72], ["copy.copy"], "methods", ["None"], ["", "def", "__getstate__", "(", "self", ")", ":", "\n", "        ", "attrs", "=", "copy", ".", "copy", "(", "self", ".", "__dict__", ")", "\n", "return", "attrs", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.legacy_distributed_data_parallel.LegacyDistributedDataParallel.__setstate__": [[73, 76], ["super().__setstate__", "legacy_distributed_data_parallel.LegacyDistributedDataParallel._register_grad_hook"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.legacy_distributed_data_parallel.LegacyDistributedDataParallel.__setstate__", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.legacy_distributed_data_parallel.LegacyDistributedDataParallel._register_grad_hook"], ["", "def", "__setstate__", "(", "self", ",", "state", ")", ":", "\n", "        ", "super", "(", ")", ".", "__setstate__", "(", "state", ")", "\n", "self", ".", "_register_grad_hook", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.legacy_distributed_data_parallel.LegacyDistributedDataParallel.no_sync": [[77, 84], ["None"], "methods", ["None"], ["", "@", "contextmanager", "\n", "def", "no_sync", "(", "self", ")", ":", "\n", "        ", "\"\"\"A context manager to disable gradient synchronization.\"\"\"", "\n", "old_accumulate_grads", "=", "self", ".", "accumulate_grads", "\n", "self", ".", "accumulate_grads", "=", "True", "\n", "yield", "\n", "self", ".", "accumulate_grads", "=", "old_accumulate_grads", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.legacy_distributed_data_parallel.LegacyDistributedDataParallel.forward": [[85, 87], ["legacy_distributed_data_parallel.LegacyDistributedDataParallel.module"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "*", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "return", "self", ".", "module", "(", "*", "inputs", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.legacy_distributed_data_parallel.LegacyDistributedDataParallel._register_grad_hook": [[88, 181], ["legacy_distributed_data_parallel.LegacyDistributedDataParallel.module.parameters", "distributed_utils.all_reduce", "legacy_distributed_data_parallel.LegacyDistributedDataParallel.module.parameters", "len", "torch.zeros_like.div_", "p.numel", "next().new", "param.numel", "len", "legacy_distributed_data_parallel.LegacyDistributedDataParallel._register_grad_hook.all_reduce"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.distributed_utils.all_reduce", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.distributed_utils.all_reduce"], ["", "def", "_register_grad_hook", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        This function registers the callback all-reduction function for the\n        NCCL backend. All gradients will be all reduced in one single step.\n        The NCCL reduction will directly be enqueued into the default CUDA\n        stream. Therefore, no synchronization is needed.\n        \"\"\"", "\n", "\n", "def", "all_reduce", "(", "params", ")", ":", "\n", "            ", "buffer", "=", "self", ".", "buffer", "\n", "nonzero_buffer", "=", "False", "\n", "if", "len", "(", "params", ")", ">", "1", ":", "\n", "                ", "offset", "=", "0", "\n", "for", "p", "in", "params", ":", "\n", "                    ", "sz", "=", "p", ".", "numel", "(", ")", "\n", "if", "p", ".", "grad", "is", "not", "None", ":", "\n", "                        ", "buffer", "[", "offset", ":", "offset", "+", "sz", "]", ".", "copy_", "(", "p", ".", "grad", ".", "data", ".", "view", "(", "-", "1", ")", ")", "\n", "nonzero_buffer", "=", "True", "\n", "", "else", ":", "\n", "                        ", "buffer", "[", "offset", ":", "offset", "+", "sz", "]", ".", "zero_", "(", ")", "\n", "", "offset", "+=", "sz", "\n", "", "", "else", ":", "\n", "# we only have a single grad to all-reduce", "\n", "                ", "p", "=", "params", "[", "0", "]", "\n", "if", "p", ".", "grad", "is", "not", "None", ":", "\n", "                    ", "buffer", "=", "p", ".", "grad", ".", "data", "\n", "nonzero_buffer", "=", "True", "\n", "", "elif", "p", ".", "numel", "(", ")", "<=", "self", ".", "buffer", ".", "numel", "(", ")", ":", "\n", "                    ", "buffer", "=", "buffer", "[", ":", "p", ".", "numel", "(", ")", "]", "\n", "buffer", ".", "zero_", "(", ")", "\n", "", "else", ":", "\n", "                    ", "buffer", "=", "torch", ".", "zeros_like", "(", "p", ")", "\n", "\n", "", "", "if", "nonzero_buffer", ":", "\n", "                ", "buffer", ".", "div_", "(", "self", ".", "world_size", ")", "\n", "\n", "", "distributed_utils", ".", "all_reduce", "(", "buffer", ",", "self", ".", "process_group", ")", "\n", "\n", "# copy all-reduced grads back into their original place", "\n", "offset", "=", "0", "\n", "for", "p", "in", "params", ":", "\n", "                ", "sz", "=", "p", ".", "numel", "(", ")", "\n", "if", "p", ".", "grad", "is", "not", "None", ":", "\n", "                    ", "p", ".", "grad", ".", "data", ".", "copy_", "(", "buffer", "[", "offset", ":", "offset", "+", "sz", "]", ".", "view_as", "(", "p", ")", ")", "\n", "", "else", ":", "\n", "                    ", "p", ".", "grad", "=", "buffer", "[", "offset", ":", "offset", "+", "sz", "]", ".", "view_as", "(", "p", ")", ".", "clone", "(", ")", "\n", "", "offset", "+=", "sz", "\n", "\n", "", "", "def", "reduction_fn", "(", ")", ":", "\n", "# This function only needs to be called once", "\n", "            ", "if", "not", "self", ".", "need_reduction", "or", "self", ".", "accumulate_grads", ":", "\n", "                ", "return", "\n", "", "self", ".", "need_reduction", "=", "False", "\n", "\n", "if", "self", ".", "buffer", "is", "None", ":", "\n", "                ", "self", ".", "buffer", "=", "next", "(", "self", ".", "module", ".", "parameters", "(", ")", ")", ".", "new", "(", "self", ".", "buffer_size", ")", "\n", "\n", "# All-reduce the gradients in buckets", "\n", "", "offset", "=", "0", "\n", "buffered_params", "=", "[", "]", "\n", "for", "param", "in", "self", ".", "module", ".", "parameters", "(", ")", ":", "\n", "                ", "if", "not", "param", ".", "requires_grad", ":", "\n", "                    ", "continue", "\n", "", "if", "param", ".", "grad", "is", "None", ":", "\n", "                    ", "param", ".", "grad", "=", "torch", ".", "zeros_like", "(", "param", ")", "\n", "", "if", "param", ".", "grad", ".", "requires_grad", ":", "\n", "                    ", "raise", "RuntimeError", "(", "\"DistributedDataParallel only works \"", "\n", "\"with gradients that don't require \"", "\n", "\"grad\"", ")", "\n", "", "sz", "=", "param", ".", "numel", "(", ")", "\n", "if", "sz", ">", "self", ".", "buffer", ".", "numel", "(", ")", ":", "\n", "# all-reduce big params directly", "\n", "                    ", "all_reduce", "(", "[", "param", "]", ")", "\n", "", "else", ":", "\n", "                    ", "if", "offset", "+", "sz", ">", "self", ".", "buffer", ".", "numel", "(", ")", ":", "\n", "                        ", "all_reduce", "(", "buffered_params", ")", "\n", "offset", "=", "0", "\n", "buffered_params", ".", "clear", "(", ")", "\n", "", "buffered_params", ".", "append", "(", "param", ")", "\n", "offset", "+=", "sz", "\n", "\n", "", "", "if", "len", "(", "buffered_params", ")", ">", "0", ":", "\n", "                ", "all_reduce", "(", "buffered_params", ")", "\n", "\n", "# Now register the reduction hook on the parameters", "\n", "", "", "for", "p", "in", "self", ".", "module", ".", "parameters", "(", ")", ":", "\n", "\n", "            ", "def", "allreduce_hook", "(", "*", "unused", ")", ":", "\n", "                ", "self", ".", "need_reduction", "=", "True", "\n", "Variable", ".", "_execution_engine", ".", "queue_callback", "(", "reduction_fn", ")", "\n", "\n", "", "if", "p", ".", "requires_grad", ":", "\n", "                ", "p", ".", "register_hook", "(", "allreduce_hook", ")", "\n", "", "", "", "", ""]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.progress_bar.progress_bar.__init__": [[64, 73], ["getattr"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "iterable", ",", "epoch", "=", "None", ",", "prefix", "=", "None", ")", ":", "\n", "        ", "self", ".", "iterable", "=", "iterable", "\n", "self", ".", "offset", "=", "getattr", "(", "iterable", ",", "'offset'", ",", "0", ")", "\n", "self", ".", "epoch", "=", "epoch", "\n", "self", ".", "prefix", "=", "''", "\n", "if", "epoch", "is", "not", "None", ":", "\n", "            ", "self", ".", "prefix", "+=", "'| epoch {:03d}'", ".", "format", "(", "epoch", ")", "\n", "", "if", "prefix", "is", "not", "None", ":", "\n", "            ", "self", ".", "prefix", "+=", "' | {}'", ".", "format", "(", "prefix", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.progress_bar.progress_bar.__len__": [[74, 76], ["len"], "methods", ["None"], ["", "", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "iterable", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.progress_bar.progress_bar.__enter__": [[77, 79], ["None"], "methods", ["None"], ["", "def", "__enter__", "(", "self", ")", ":", "\n", "        ", "return", "self", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.progress_bar.progress_bar.__exit__": [[80, 82], ["None"], "methods", ["None"], ["", "def", "__exit__", "(", "self", ",", "*", "exc", ")", ":", "\n", "        ", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.progress_bar.progress_bar.__iter__": [[83, 85], ["None"], "methods", ["None"], ["", "def", "__iter__", "(", "self", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.progress_bar.progress_bar.log": [[86, 89], ["None"], "methods", ["None"], ["", "def", "log", "(", "self", ",", "stats", ",", "tag", "=", "''", ",", "step", "=", "None", ")", ":", "\n", "        ", "\"\"\"Log intermediate stats according to log_interval.\"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.progress_bar.progress_bar.print": [[90, 93], ["None"], "methods", ["None"], ["", "def", "print", "(", "self", ",", "stats", ",", "tag", "=", "''", ",", "step", "=", "None", ")", ":", "\n", "        ", "\"\"\"Print end-of-epoch stats.\"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.progress_bar.progress_bar._str_commas": [[94, 97], ["stats[].strip", "stats.keys"], "methods", ["None"], ["", "def", "_str_commas", "(", "self", ",", "stats", ")", ":", "\n", "        ", "return", "', '", ".", "join", "(", "key", "+", "'='", "+", "stats", "[", "key", "]", ".", "strip", "(", ")", "\n", "for", "key", "in", "stats", ".", "keys", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.progress_bar.progress_bar._str_pipes": [[98, 101], ["stats[].strip", "stats.keys"], "methods", ["None"], ["", "def", "_str_pipes", "(", "self", ",", "stats", ")", ":", "\n", "        ", "return", "' | '", ".", "join", "(", "key", "+", "' '", "+", "stats", "[", "key", "]", ".", "strip", "(", ")", "\n", "for", "key", "in", "stats", ".", "keys", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.progress_bar.progress_bar._format_stats": [[102, 108], ["collections.OrderedDict", "collections.OrderedDict.keys", "str", "progress_bar.format_stat"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.progress_bar.format_stat"], ["", "def", "_format_stats", "(", "self", ",", "stats", ")", ":", "\n", "        ", "postfix", "=", "OrderedDict", "(", "stats", ")", "\n", "# Preprocess stats according to datatype", "\n", "for", "key", "in", "postfix", ".", "keys", "(", ")", ":", "\n", "            ", "postfix", "[", "key", "]", "=", "str", "(", "format_stat", "(", "postfix", "[", "key", "]", ")", ")", "\n", "", "return", "postfix", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.progress_bar.json_progress_bar.__init__": [[113, 117], ["progress_bar.progress_bar.__init__"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.dummy_dictionary.DummyDictionary.__init__"], ["def", "__init__", "(", "self", ",", "iterable", ",", "epoch", "=", "None", ",", "prefix", "=", "None", ",", "log_interval", "=", "1000", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "iterable", ",", "epoch", ",", "prefix", ")", "\n", "self", ".", "log_interval", "=", "log_interval", "\n", "self", ".", "stats", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.progress_bar.json_progress_bar.__iter__": [[118, 127], ["float", "enumerate", "len", "progress_bar.json_progress_bar._format_stats", "progress_bar.json_progress_bar.print"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.progress_bar.json_progress_bar._format_stats", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.progress_bar.tensorboard_log_wrapper.print"], ["", "def", "__iter__", "(", "self", ")", ":", "\n", "        ", "size", "=", "float", "(", "len", "(", "self", ".", "iterable", ")", ")", "\n", "for", "i", ",", "obj", "in", "enumerate", "(", "self", ".", "iterable", ",", "start", "=", "self", ".", "offset", ")", ":", "\n", "            ", "yield", "obj", "\n", "if", "self", ".", "stats", "is", "not", "None", "and", "i", ">", "0", "and", "self", ".", "log_interval", "is", "not", "None", "and", "i", "%", "self", ".", "log_interval", "==", "0", ":", "\n", "                ", "update", "=", "self", ".", "epoch", "-", "1", "+", "float", "(", "i", "/", "size", ")", "if", "self", ".", "epoch", "is", "not", "None", "else", "None", "\n", "stats", "=", "self", ".", "_format_stats", "(", "self", ".", "stats", ",", "epoch", "=", "self", ".", "epoch", ",", "update", "=", "update", ")", "\n", "print", "(", "json", ".", "dumps", "(", "stats", ")", ",", "flush", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.progress_bar.json_progress_bar.log": [[128, 131], ["None"], "methods", ["None"], ["", "", "", "def", "log", "(", "self", ",", "stats", ",", "tag", "=", "''", ",", "step", "=", "None", ")", ":", "\n", "        ", "\"\"\"Log intermediate stats according to log_interval.\"\"\"", "\n", "self", ".", "stats", "=", "stats", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.progress_bar.json_progress_bar.print": [[132, 139], ["progress_bar.json_progress_bar._format_stats", "progress_bar.json_progress_bar.print"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.progress_bar.json_progress_bar._format_stats", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.progress_bar.tensorboard_log_wrapper.print"], ["", "def", "print", "(", "self", ",", "stats", ",", "tag", "=", "''", ",", "step", "=", "None", ")", ":", "\n", "        ", "\"\"\"Print end-of-epoch stats.\"\"\"", "\n", "self", ".", "stats", "=", "stats", "\n", "if", "tag", "!=", "''", ":", "\n", "            ", "self", ".", "stats", "=", "OrderedDict", "(", "[", "(", "tag", "+", "'_'", "+", "k", ",", "v", ")", "for", "k", ",", "v", "in", "self", ".", "stats", ".", "items", "(", ")", "]", ")", "\n", "", "stats", "=", "self", ".", "_format_stats", "(", "self", ".", "stats", ",", "epoch", "=", "self", ".", "epoch", ")", "\n", "print", "(", "json", ".", "dumps", "(", "stats", ")", ",", "flush", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.progress_bar.json_progress_bar._format_stats": [[140, 150], ["collections.OrderedDict", "stats.keys", "round", "progress_bar.format_stat"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.progress_bar.format_stat"], ["", "def", "_format_stats", "(", "self", ",", "stats", ",", "epoch", "=", "None", ",", "update", "=", "None", ")", ":", "\n", "        ", "postfix", "=", "OrderedDict", "(", ")", "\n", "if", "epoch", "is", "not", "None", ":", "\n", "            ", "postfix", "[", "'epoch'", "]", "=", "epoch", "\n", "", "if", "update", "is", "not", "None", ":", "\n", "            ", "postfix", "[", "'update'", "]", "=", "round", "(", "update", ",", "3", ")", "\n", "# Preprocess stats according to datatype", "\n", "", "for", "key", "in", "stats", ".", "keys", "(", ")", ":", "\n", "            ", "postfix", "[", "key", "]", "=", "format_stat", "(", "stats", "[", "key", "]", ")", "\n", "", "return", "postfix", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.progress_bar.noop_progress_bar.__init__": [[155, 157], ["progress_bar.progress_bar.__init__"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.dummy_dictionary.DummyDictionary.__init__"], ["def", "__init__", "(", "self", ",", "iterable", ",", "epoch", "=", "None", ",", "prefix", "=", "None", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "iterable", ",", "epoch", ",", "prefix", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.progress_bar.noop_progress_bar.__iter__": [[158, 161], ["None"], "methods", ["None"], ["", "def", "__iter__", "(", "self", ")", ":", "\n", "        ", "for", "obj", "in", "self", ".", "iterable", ":", "\n", "            ", "yield", "obj", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.progress_bar.noop_progress_bar.log": [[162, 165], ["None"], "methods", ["None"], ["", "", "def", "log", "(", "self", ",", "stats", ",", "tag", "=", "''", ",", "step", "=", "None", ")", ":", "\n", "        ", "\"\"\"Log intermediate stats according to log_interval.\"\"\"", "\n", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.progress_bar.noop_progress_bar.print": [[166, 169], ["None"], "methods", ["None"], ["", "def", "print", "(", "self", ",", "stats", ",", "tag", "=", "''", ",", "step", "=", "None", ")", ":", "\n", "        ", "\"\"\"Print end-of-epoch stats.\"\"\"", "\n", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.progress_bar.simple_progress_bar.__init__": [[174, 178], ["progress_bar.progress_bar.__init__"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.dummy_dictionary.DummyDictionary.__init__"], ["def", "__init__", "(", "self", ",", "iterable", ",", "epoch", "=", "None", ",", "prefix", "=", "None", ",", "log_interval", "=", "1000", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "iterable", ",", "epoch", ",", "prefix", ")", "\n", "self", ".", "log_interval", "=", "log_interval", "\n", "self", ".", "stats", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.progress_bar.simple_progress_bar.__iter__": [[179, 188], ["len", "enumerate", "progress_bar.simple_progress_bar._str_commas", "progress_bar.simple_progress_bar.print"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.progress_bar.progress_bar._str_commas", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.progress_bar.tensorboard_log_wrapper.print"], ["", "def", "__iter__", "(", "self", ")", ":", "\n", "        ", "size", "=", "len", "(", "self", ".", "iterable", ")", "\n", "for", "i", ",", "obj", "in", "enumerate", "(", "self", ".", "iterable", ",", "start", "=", "self", ".", "offset", ")", ":", "\n", "            ", "yield", "obj", "\n", "if", "self", ".", "stats", "is", "not", "None", "and", "i", ">", "0", "and", "self", ".", "log_interval", "is", "not", "None", "and", "i", "%", "self", ".", "log_interval", "==", "0", ":", "\n", "                ", "postfix", "=", "self", ".", "_str_commas", "(", "self", ".", "stats", ")", "\n", "print", "(", "'{}:  {:5d} / {:d} {}'", ".", "format", "(", "self", ".", "prefix", ",", "i", ",", "size", ",", "postfix", ")", ",", "\n", "flush", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.progress_bar.simple_progress_bar.log": [[189, 192], ["progress_bar.simple_progress_bar._format_stats"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.progress_bar.json_progress_bar._format_stats"], ["", "", "", "def", "log", "(", "self", ",", "stats", ",", "tag", "=", "''", ",", "step", "=", "None", ")", ":", "\n", "        ", "\"\"\"Log intermediate stats according to log_interval.\"\"\"", "\n", "self", ".", "stats", "=", "self", ".", "_format_stats", "(", "stats", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.progress_bar.simple_progress_bar.print": [[193, 197], ["progress_bar.simple_progress_bar._str_pipes", "progress_bar.simple_progress_bar.print"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.progress_bar.progress_bar._str_pipes", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.progress_bar.tensorboard_log_wrapper.print"], ["", "def", "print", "(", "self", ",", "stats", ",", "tag", "=", "''", ",", "step", "=", "None", ")", ":", "\n", "        ", "\"\"\"Print end-of-epoch stats.\"\"\"", "\n", "postfix", "=", "self", ".", "_str_pipes", "(", "self", ".", "_format_stats", "(", "stats", ")", ")", "\n", "print", "(", "'{} | {}'", ".", "format", "(", "self", ".", "prefix", ",", "postfix", ")", ",", "flush", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.progress_bar.tqdm_progress_bar.__init__": [[202, 206], ["progress_bar.progress_bar.__init__", "tqdm"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.dummy_dictionary.DummyDictionary.__init__"], ["def", "__init__", "(", "self", ",", "iterable", ",", "epoch", "=", "None", ",", "prefix", "=", "None", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "iterable", ",", "epoch", ",", "prefix", ")", "\n", "from", "tqdm", "import", "tqdm", "\n", "self", ".", "tqdm", "=", "tqdm", "(", "iterable", ",", "self", ".", "prefix", ",", "leave", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.progress_bar.tqdm_progress_bar.__iter__": [[207, 209], ["iter"], "methods", ["None"], ["", "def", "__iter__", "(", "self", ")", ":", "\n", "        ", "return", "iter", "(", "self", ".", "tqdm", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.progress_bar.tqdm_progress_bar.log": [[210, 213], ["progress_bar.tqdm_progress_bar.tqdm.set_postfix", "progress_bar.tqdm_progress_bar._format_stats"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.progress_bar.json_progress_bar._format_stats"], ["", "def", "log", "(", "self", ",", "stats", ",", "tag", "=", "''", ",", "step", "=", "None", ")", ":", "\n", "        ", "\"\"\"Log intermediate stats according to log_interval.\"\"\"", "\n", "self", ".", "tqdm", ".", "set_postfix", "(", "self", ".", "_format_stats", "(", "stats", ")", ",", "refresh", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.progress_bar.tqdm_progress_bar.print": [[214, 218], ["progress_bar.tqdm_progress_bar._str_pipes", "progress_bar.tqdm_progress_bar.tqdm.write", "progress_bar.tqdm_progress_bar._format_stats"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.progress_bar.progress_bar._str_pipes", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.progress_bar.json_progress_bar._format_stats"], ["", "def", "print", "(", "self", ",", "stats", ",", "tag", "=", "''", ",", "step", "=", "None", ")", ":", "\n", "        ", "\"\"\"Print end-of-epoch stats.\"\"\"", "\n", "postfix", "=", "self", ".", "_str_pipes", "(", "self", ".", "_format_stats", "(", "stats", ")", ")", "\n", "self", ".", "tqdm", ".", "write", "(", "'{} | {}'", ".", "format", "(", "self", ".", "tqdm", ".", "desc", ",", "postfix", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.progress_bar.tensorboard_log_wrapper.__init__": [[223, 236], ["progress_bar.tensorboard_log_wrapper.print"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.progress_bar.tensorboard_log_wrapper.print"], ["def", "__init__", "(", "self", ",", "wrapped_bar", ",", "tensorboard_logdir", ",", "args", ")", ":", "\n", "        ", "self", ".", "wrapped_bar", "=", "wrapped_bar", "\n", "self", ".", "tensorboard_logdir", "=", "tensorboard_logdir", "\n", "self", ".", "args", "=", "args", "\n", "\n", "try", ":", "\n", "            ", "from", "tensorboardX", "import", "SummaryWriter", "\n", "self", ".", "SummaryWriter", "=", "SummaryWriter", "\n", "self", ".", "_writers", "=", "{", "}", "\n", "", "except", "ImportError", ":", "\n", "            ", "print", "(", "\"tensorboard or required dependencies not found, \"", "\n", "\"please see README for using tensorboard. (e.g. pip install tensorboardX)\"", ")", "\n", "self", ".", "SummaryWriter", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.progress_bar.tensorboard_log_wrapper._writer": [[237, 247], ["progress_bar.tensorboard_log_wrapper.SummaryWriter", "progress_bar.tensorboard_log_wrapper._writers[].add_text", "progress_bar.tensorboard_log_wrapper._writers[].add_text", "os.path.join", "str", "vars"], "methods", ["None"], ["", "", "def", "_writer", "(", "self", ",", "key", ")", ":", "\n", "        ", "if", "self", ".", "SummaryWriter", "is", "None", ":", "\n", "            ", "return", "None", "\n", "", "if", "key", "not", "in", "self", ".", "_writers", ":", "\n", "            ", "self", ".", "_writers", "[", "key", "]", "=", "self", ".", "SummaryWriter", "(", "\n", "os", ".", "path", ".", "join", "(", "self", ".", "tensorboard_logdir", ",", "key", ")", ",", "\n", ")", "\n", "self", ".", "_writers", "[", "key", "]", ".", "add_text", "(", "'args'", ",", "str", "(", "vars", "(", "self", ".", "args", ")", ")", ")", "\n", "self", ".", "_writers", "[", "key", "]", ".", "add_text", "(", "'sys.argv'", ",", "\" \"", ".", "join", "(", "sys", ".", "argv", ")", ")", "\n", "", "return", "self", ".", "_writers", "[", "key", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.progress_bar.tensorboard_log_wrapper.__iter__": [[248, 250], ["iter"], "methods", ["None"], ["", "def", "__iter__", "(", "self", ")", ":", "\n", "        ", "return", "iter", "(", "self", ".", "wrapped_bar", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.progress_bar.tensorboard_log_wrapper.log": [[251, 255], ["progress_bar.tensorboard_log_wrapper._log_to_tensorboard", "progress_bar.tensorboard_log_wrapper.wrapped_bar.log"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.progress_bar.tensorboard_log_wrapper._log_to_tensorboard", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.progress_bar.tensorboard_log_wrapper.log"], ["", "def", "log", "(", "self", ",", "stats", ",", "tag", "=", "''", ",", "step", "=", "None", ")", ":", "\n", "        ", "\"\"\"Log intermediate stats to tensorboard.\"\"\"", "\n", "self", ".", "_log_to_tensorboard", "(", "stats", ",", "tag", ",", "step", ")", "\n", "self", ".", "wrapped_bar", ".", "log", "(", "stats", ",", "tag", "=", "tag", ",", "step", "=", "step", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.progress_bar.tensorboard_log_wrapper.print": [[256, 260], ["progress_bar.tensorboard_log_wrapper._log_to_tensorboard", "progress_bar.tensorboard_log_wrapper.wrapped_bar.print"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.progress_bar.tensorboard_log_wrapper._log_to_tensorboard", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.progress_bar.tensorboard_log_wrapper.print"], ["", "def", "print", "(", "self", ",", "stats", ",", "tag", "=", "''", ",", "step", "=", "None", ")", ":", "\n", "        ", "\"\"\"Print end-of-epoch stats.\"\"\"", "\n", "self", ".", "_log_to_tensorboard", "(", "stats", ",", "tag", ",", "step", ")", "\n", "self", ".", "wrapped_bar", ".", "print", "(", "stats", ",", "tag", "=", "tag", ",", "step", "=", "step", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.progress_bar.tensorboard_log_wrapper.__exit__": [[261, 265], ["getattr().values", "writer.close", "getattr"], "methods", ["None"], ["", "def", "__exit__", "(", "self", ",", "*", "exc", ")", ":", "\n", "        ", "for", "writer", "in", "getattr", "(", "self", ",", "'_writers'", ",", "{", "}", ")", ".", "values", "(", ")", ":", "\n", "            ", "writer", ".", "close", "(", ")", "\n", "", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.progress_bar.tensorboard_log_wrapper._log_to_tensorboard": [[266, 277], ["progress_bar.tensorboard_log_wrapper._writer", "stats.keys", "isinstance", "progress_bar.tensorboard_log_wrapper.add_scalar", "isinstance", "progress_bar.tensorboard_log_wrapper.add_scalar"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.progress_bar.tensorboard_log_wrapper._writer"], ["", "def", "_log_to_tensorboard", "(", "self", ",", "stats", ",", "tag", "=", "''", ",", "step", "=", "None", ")", ":", "\n", "        ", "writer", "=", "self", ".", "_writer", "(", "tag", ")", "\n", "if", "writer", "is", "None", ":", "\n", "            ", "return", "\n", "", "if", "step", "is", "None", ":", "\n", "            ", "step", "=", "stats", "[", "'num_updates'", "]", "\n", "", "for", "key", "in", "stats", ".", "keys", "(", ")", "-", "{", "'num_updates'", "}", ":", "\n", "            ", "if", "isinstance", "(", "stats", "[", "key", "]", ",", "AverageMeter", ")", ":", "\n", "                ", "writer", ".", "add_scalar", "(", "key", ",", "stats", "[", "key", "]", ".", "val", ",", "step", ")", "\n", "", "elif", "isinstance", "(", "stats", "[", "key", "]", ",", "Number", ")", ":", "\n", "                ", "writer", ".", "add_scalar", "(", "key", ",", "stats", "[", "key", "]", ",", "step", ")", "\n", "", "", "", "", ""]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.progress_bar.build_progress_bar": [[20, 48], ["progress_bar.json_progress_bar", "fairseq.distributed_utils.is_master", "sys.stderr.isatty", "progress_bar.noop_progress_bar", "fb_tbmf_wrapper", "progress_bar.simple_progress_bar", "progress_bar.tensorboard_log_wrapper", "progress_bar.tqdm_progress_bar", "ValueError"], "function", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.distributed_utils.is_master"], ["def", "build_progress_bar", "(", "args", ",", "iterator", ",", "epoch", "=", "None", ",", "prefix", "=", "None", ",", "default", "=", "'tqdm'", ",", "no_progress_bar", "=", "'none'", ")", ":", "\n", "    ", "if", "args", ".", "log_format", "is", "None", ":", "\n", "        ", "args", ".", "log_format", "=", "no_progress_bar", "if", "args", ".", "no_progress_bar", "else", "default", "\n", "\n", "", "if", "args", ".", "log_format", "==", "'tqdm'", "and", "not", "sys", ".", "stderr", ".", "isatty", "(", ")", ":", "\n", "        ", "args", ".", "log_format", "=", "'simple'", "\n", "\n", "", "if", "args", ".", "log_format", "==", "'json'", ":", "\n", "        ", "bar", "=", "json_progress_bar", "(", "iterator", ",", "epoch", ",", "prefix", ",", "args", ".", "log_interval", ")", "\n", "", "elif", "args", ".", "log_format", "==", "'none'", ":", "\n", "        ", "bar", "=", "noop_progress_bar", "(", "iterator", ",", "epoch", ",", "prefix", ")", "\n", "", "elif", "args", ".", "log_format", "==", "'simple'", ":", "\n", "        ", "bar", "=", "simple_progress_bar", "(", "iterator", ",", "epoch", ",", "prefix", ",", "args", ".", "log_interval", ")", "\n", "", "elif", "args", ".", "log_format", "==", "'tqdm'", ":", "\n", "        ", "bar", "=", "tqdm_progress_bar", "(", "iterator", ",", "epoch", ",", "prefix", ")", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "'Unknown log format: {}'", ".", "format", "(", "args", ".", "log_format", ")", ")", "\n", "\n", "", "if", "args", ".", "tensorboard_logdir", "and", "distributed_utils", ".", "is_master", "(", "args", ")", ":", "\n", "        ", "try", ":", "\n", "# [FB only] custom wrapper for TensorBoard", "\n", "            ", "import", "palaas", "# noqa", "\n", "from", "fairseq", ".", "fb_tbmf_wrapper", "import", "fb_tbmf_wrapper", "\n", "bar", "=", "fb_tbmf_wrapper", "(", "bar", ",", "args", ",", "args", ".", "log_interval", ")", "\n", "", "except", "ImportError", ":", "\n", "            ", "bar", "=", "tensorboard_log_wrapper", "(", "bar", ",", "args", ".", "tensorboard_logdir", ",", "args", ")", "\n", "\n", "", "", "return", "bar", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.progress_bar.format_stat": [[50, 60], ["isinstance", "isinstance", "isinstance", "isinstance", "round", "round"], "function", ["None"], ["", "def", "format_stat", "(", "stat", ")", ":", "\n", "    ", "if", "isinstance", "(", "stat", ",", "Number", ")", ":", "\n", "        ", "stat", "=", "'{:g}'", ".", "format", "(", "stat", ")", "\n", "", "elif", "isinstance", "(", "stat", ",", "AverageMeter", ")", ":", "\n", "        ", "stat", "=", "'{:.3f}'", ".", "format", "(", "stat", ".", "avg", ")", "\n", "", "elif", "isinstance", "(", "stat", ",", "TimeMeter", ")", ":", "\n", "        ", "stat", "=", "'{:g}'", ".", "format", "(", "round", "(", "stat", ".", "avg", ")", ")", "\n", "", "elif", "isinstance", "(", "stat", ",", "StopwatchMeter", ")", ":", "\n", "        ", "stat", "=", "'{:g}'", ".", "format", "(", "round", "(", "stat", ".", "sum", ")", ")", "\n", "", "return", "stat", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.tokenizer.tokenize_line": [[11, 15], ["SPACE_NORMALIZER.sub", "line.strip.strip", "line.strip.split"], "function", ["None"], ["def", "tokenize_line", "(", "line", ")", ":", "\n", "    ", "line", "=", "SPACE_NORMALIZER", ".", "sub", "(", "\" \"", ",", "line", ")", "\n", "line", "=", "line", ".", "strip", "(", ")", "\n", "return", "line", ".", "split", "(", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq._hub_utils.GeneratorHubInterface.__init__": [[84, 111], ["torch.nn.Module.__init__", "torch.nn.ModuleList", "fairseq.utils.load_align_dict", "fairseq.data.encoders.build_tokenizer", "fairseq.data.encoders.build_bpe", "_hub_utils.GeneratorHubInterface.register_buffer", "model.make_generation_fast_", "getattr", "torch.tensor", "getattr", "getattr"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.dummy_dictionary.DummyDictionary.__init__", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.modules.transformer_layer.TransformerDecoderLayer.make_generation_fast_"], ["def", "__init__", "(", "self", ",", "args", ",", "task", ",", "models", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "args", "=", "args", "\n", "self", ".", "task", "=", "task", "\n", "self", ".", "models", "=", "nn", ".", "ModuleList", "(", "models", ")", "\n", "self", ".", "src_dict", "=", "task", ".", "source_dictionary", "\n", "self", ".", "tgt_dict", "=", "task", ".", "target_dictionary", "\n", "\n", "# optimize model for generation", "\n", "for", "model", "in", "self", ".", "models", ":", "\n", "            ", "model", ".", "make_generation_fast_", "(", "\n", "beamable_mm_beam_size", "=", "(", "\n", "None", "if", "getattr", "(", "args", ",", "'no_beamable_mm'", ",", "False", ")", "\n", "else", "getattr", "(", "args", ",", "'beam'", ",", "5", ")", "\n", ")", ",", "\n", "need_attn", "=", "False", ",", "\n", ")", "\n", "\n", "# Load alignment dictionary for unknown word replacement", "\n", "# (None if no unknown word replacement, empty if no path to align dictionary)", "\n", "", "self", ".", "align_dict", "=", "utils", ".", "load_align_dict", "(", "getattr", "(", "args", ",", "'replace_unk'", ",", "None", ")", ")", "\n", "\n", "self", ".", "tokenizer", "=", "encoders", ".", "build_tokenizer", "(", "args", ")", "\n", "self", ".", "bpe", "=", "encoders", ".", "build_bpe", "(", "args", ")", "\n", "\n", "# this is useful for determining the device", "\n", "self", ".", "register_buffer", "(", "'_float_tensor'", ",", "torch", ".", "tensor", "(", "[", "0", "]", ",", "dtype", "=", "torch", ".", "float", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq._hub_utils.GeneratorHubInterface.device": [[112, 115], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "device", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_float_tensor", ".", "device", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq._hub_utils.GeneratorHubInterface.translate": [[116, 118], ["_hub_utils.GeneratorHubInterface.sample"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq._hub_utils.GeneratorHubInterface.sample"], ["", "def", "translate", "(", "self", ",", "sentence", ":", "str", ",", "beam", ":", "int", "=", "5", ",", "verbose", ":", "bool", "=", "False", ",", "**", "kwargs", ")", "->", "str", ":", "\n", "        ", "return", "self", ".", "sample", "(", "sentence", ",", "beam", ",", "verbose", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq._hub_utils.GeneratorHubInterface.sample": [[119, 123], ["_hub_utils.GeneratorHubInterface.encode", "_hub_utils.GeneratorHubInterface.decode", "_hub_utils.GeneratorHubInterface.generate"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq._hub_utils.TokenizerHubInterface.encode", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq._hub_utils.TokenizerHubInterface.decode", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.sequence_generator.SequenceGenerator.generate"], ["", "def", "sample", "(", "self", ",", "sentence", ":", "str", ",", "beam", ":", "int", "=", "1", ",", "verbose", ":", "bool", "=", "False", ",", "**", "kwargs", ")", "->", "str", ":", "\n", "        ", "input", "=", "self", ".", "encode", "(", "sentence", ")", "\n", "hypo", "=", "self", ".", "generate", "(", "input", ",", "beam", ",", "verbose", ",", "**", "kwargs", ")", "[", "0", "]", "[", "'tokens'", "]", "\n", "return", "self", ".", "decode", "(", "hypo", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq._hub_utils.GeneratorHubInterface.generate": [[124, 154], ["_hub_utils.GeneratorHubInterface._build_sample", "copy.copy", "kwargs.items", "_hub_utils.GeneratorHubInterface.task.build_generator", "_hub_utils.GeneratorHubInterface.task.inference_step", "setattr", "_hub_utils.GeneratorHubInterface.string", "print", "getattr", "getattr", "_hub_utils.GeneratorHubInterface.decode", "print", "print", "map", "hypo[].tolist"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq._hub_utils.GeneratorHubInterface._build_sample", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.tasks.fairseq_task.FairseqTask.build_generator", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.tasks.integer_sequence_modeling.IntegerSequenceModelingTask.inference_step", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq._hub_utils.GeneratorHubInterface.string", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.progress_bar.tensorboard_log_wrapper.print", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq._hub_utils.TokenizerHubInterface.decode", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.progress_bar.tensorboard_log_wrapper.print", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.progress_bar.tensorboard_log_wrapper.print"], ["", "def", "generate", "(", "self", ",", "tokens", ":", "torch", ".", "LongTensor", ",", "beam", ":", "int", "=", "5", ",", "verbose", ":", "bool", "=", "False", ",", "**", "kwargs", ")", "->", "torch", ".", "LongTensor", ":", "\n", "        ", "sample", "=", "self", ".", "_build_sample", "(", "tokens", ")", "\n", "\n", "# build generator using current args as well as any kwargs", "\n", "gen_args", "=", "copy", ".", "copy", "(", "self", ".", "args", ")", "\n", "gen_args", ".", "beam", "=", "beam", "\n", "for", "k", ",", "v", "in", "kwargs", ".", "items", "(", ")", ":", "\n", "            ", "setattr", "(", "gen_args", ",", "k", ",", "v", ")", "\n", "", "generator", "=", "self", ".", "task", ".", "build_generator", "(", "gen_args", ")", "\n", "\n", "translations", "=", "self", ".", "task", ".", "inference_step", "(", "generator", ",", "self", ".", "models", ",", "sample", ")", "\n", "\n", "if", "verbose", ":", "\n", "            ", "src_str_with_unk", "=", "self", ".", "string", "(", "tokens", ")", "\n", "print", "(", "'S\\t{}'", ".", "format", "(", "src_str_with_unk", ")", ")", "\n", "\n", "", "def", "getarg", "(", "name", ",", "default", ")", ":", "\n", "            ", "return", "getattr", "(", "gen_args", ",", "name", ",", "getattr", "(", "self", ".", "args", ",", "name", ",", "default", ")", ")", "\n", "\n", "# Process top predictions", "\n", "", "hypos", "=", "translations", "[", "0", "]", "\n", "if", "verbose", ":", "\n", "            ", "for", "hypo", "in", "hypos", ":", "\n", "                ", "hypo_str", "=", "self", ".", "decode", "(", "hypo", "[", "'tokens'", "]", ")", "\n", "print", "(", "'H\\t{}\\t{}'", ".", "format", "(", "hypo", "[", "'score'", "]", ",", "hypo_str", ")", ")", "\n", "print", "(", "'P\\t{}'", ".", "format", "(", "\n", "' '", ".", "join", "(", "map", "(", "lambda", "x", ":", "'{:.4f}'", ".", "format", "(", "x", ")", ",", "hypo", "[", "'positional_scores'", "]", ".", "tolist", "(", ")", ")", ")", "\n", ")", ")", "\n", "\n", "", "", "return", "hypos", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq._hub_utils.GeneratorHubInterface.encode": [[155, 159], ["_hub_utils.GeneratorHubInterface.tokenize", "_hub_utils.GeneratorHubInterface.apply_bpe", "_hub_utils.GeneratorHubInterface.binarize"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq._hub_utils.GeneratorHubInterface.tokenize", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq._hub_utils.GeneratorHubInterface.apply_bpe", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq._hub_utils.GeneratorHubInterface.binarize"], ["", "def", "encode", "(", "self", ",", "sentence", ":", "str", ")", "->", "torch", ".", "LongTensor", ":", "\n", "        ", "sentence", "=", "self", ".", "tokenize", "(", "sentence", ")", "\n", "sentence", "=", "self", ".", "apply_bpe", "(", "sentence", ")", "\n", "return", "self", ".", "binarize", "(", "sentence", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq._hub_utils.GeneratorHubInterface.decode": [[160, 164], ["_hub_utils.GeneratorHubInterface.string", "_hub_utils.GeneratorHubInterface.remove_bpe", "_hub_utils.GeneratorHubInterface.detokenize"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq._hub_utils.GeneratorHubInterface.string", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq._hub_utils.GeneratorHubInterface.remove_bpe", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq._hub_utils.GeneratorHubInterface.detokenize"], ["", "def", "decode", "(", "self", ",", "tokens", ":", "torch", ".", "LongTensor", ")", "->", "str", ":", "\n", "        ", "sentence", "=", "self", ".", "string", "(", "tokens", ")", "\n", "sentence", "=", "self", ".", "remove_bpe", "(", "sentence", ")", "\n", "return", "self", ".", "detokenize", "(", "sentence", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq._hub_utils.GeneratorHubInterface.tokenize": [[165, 169], ["_hub_utils.GeneratorHubInterface.tokenizer.encode"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq._hub_utils.TokenizerHubInterface.encode"], ["", "def", "tokenize", "(", "self", ",", "sentence", ":", "str", ")", "->", "str", ":", "\n", "        ", "if", "self", ".", "tokenizer", "is", "not", "None", ":", "\n", "            ", "sentence", "=", "self", ".", "tokenizer", ".", "encode", "(", "sentence", ")", "\n", "", "return", "sentence", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq._hub_utils.GeneratorHubInterface.detokenize": [[170, 174], ["_hub_utils.GeneratorHubInterface.tokenizer.decode"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq._hub_utils.TokenizerHubInterface.decode"], ["", "def", "detokenize", "(", "self", ",", "sentence", ":", "str", ")", "->", "str", ":", "\n", "        ", "if", "self", ".", "tokenizer", "is", "not", "None", ":", "\n", "            ", "sentence", "=", "self", ".", "tokenizer", ".", "decode", "(", "sentence", ")", "\n", "", "return", "sentence", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq._hub_utils.GeneratorHubInterface.apply_bpe": [[175, 179], ["_hub_utils.GeneratorHubInterface.bpe.encode"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq._hub_utils.TokenizerHubInterface.encode"], ["", "def", "apply_bpe", "(", "self", ",", "sentence", ":", "str", ")", "->", "str", ":", "\n", "        ", "if", "self", ".", "bpe", "is", "not", "None", ":", "\n", "            ", "sentence", "=", "self", ".", "bpe", ".", "encode", "(", "sentence", ")", "\n", "", "return", "sentence", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq._hub_utils.GeneratorHubInterface.remove_bpe": [[180, 184], ["_hub_utils.GeneratorHubInterface.bpe.decode"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq._hub_utils.TokenizerHubInterface.decode"], ["", "def", "remove_bpe", "(", "self", ",", "sentence", ":", "str", ")", "->", "str", ":", "\n", "        ", "if", "self", ".", "bpe", "is", "not", "None", ":", "\n", "            ", "sentence", "=", "self", ".", "bpe", ".", "decode", "(", "sentence", ")", "\n", "", "return", "sentence", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq._hub_utils.GeneratorHubInterface.binarize": [[185, 187], ["_hub_utils.GeneratorHubInterface.src_dict.encode_line().long", "_hub_utils.GeneratorHubInterface.src_dict.encode_line"], "methods", ["None"], ["", "def", "binarize", "(", "self", ",", "sentence", ":", "str", ")", "->", "torch", ".", "LongTensor", ":", "\n", "        ", "return", "self", ".", "src_dict", ".", "encode_line", "(", "sentence", ",", "add_if_not_exist", "=", "False", ")", ".", "long", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq._hub_utils.GeneratorHubInterface.string": [[188, 190], ["_hub_utils.GeneratorHubInterface.tgt_dict.string"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq._hub_utils.GeneratorHubInterface.string"], ["", "def", "string", "(", "self", ",", "tokens", ":", "torch", ".", "LongTensor", ")", "->", "str", ":", "\n", "        ", "return", "self", ".", "tgt_dict", ".", "string", "(", "tokens", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq._hub_utils.GeneratorHubInterface._build_sample": [[191, 200], ["torch.is_tensor", "_hub_utils.GeneratorHubInterface.task.build_dataset_for_inference", "_hub_utils.GeneratorHubInterface.collater", "fairseq.utils.apply_to_sample", "src_tokens.numel", "tensor.to"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.tasks.integer_sequence_modeling.IntegerSequenceModelingTask.build_dataset_for_inference", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.fairseq_dataset.FairseqDataset.collater", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.utils.apply_to_sample"], ["", "def", "_build_sample", "(", "self", ",", "src_tokens", ":", "torch", ".", "LongTensor", ")", ":", "\n", "        ", "assert", "torch", ".", "is_tensor", "(", "src_tokens", ")", "\n", "dataset", "=", "self", ".", "task", ".", "build_dataset_for_inference", "(", "[", "src_tokens", "]", ",", "[", "src_tokens", ".", "numel", "(", ")", "]", ")", "\n", "sample", "=", "dataset", ".", "collater", "(", "[", "dataset", "[", "0", "]", "]", ")", "\n", "sample", "=", "utils", ".", "apply_to_sample", "(", "\n", "lambda", "tensor", ":", "tensor", ".", "to", "(", "self", ".", "device", ")", ",", "\n", "sample", "\n", ")", "\n", "return", "sample", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq._hub_utils.BPEHubInterface.__init__": [[205, 210], ["object.__init__", "argparse.Namespace", "fairseq.data.encoders.build_bpe"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.dummy_dictionary.DummyDictionary.__init__"], ["def", "__init__", "(", "self", ",", "bpe", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "args", "=", "argparse", ".", "Namespace", "(", "bpe", "=", "bpe", ",", "**", "kwargs", ")", "\n", "self", ".", "bpe", "=", "encoders", ".", "build_bpe", "(", "args", ")", "\n", "assert", "self", ".", "bpe", "is", "not", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq._hub_utils.BPEHubInterface.encode": [[211, 213], ["_hub_utils.BPEHubInterface.bpe.encode"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq._hub_utils.TokenizerHubInterface.encode"], ["", "def", "encode", "(", "self", ",", "sentence", ":", "str", ")", "->", "str", ":", "\n", "        ", "return", "self", ".", "bpe", ".", "encode", "(", "sentence", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq._hub_utils.BPEHubInterface.decode": [[214, 216], ["_hub_utils.BPEHubInterface.bpe.decode"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq._hub_utils.TokenizerHubInterface.decode"], ["", "def", "decode", "(", "self", ",", "sentence", ":", "str", ")", "->", "str", ":", "\n", "        ", "return", "self", ".", "bpe", ".", "decode", "(", "sentence", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq._hub_utils.TokenizerHubInterface.__init__": [[221, 226], ["object.__init__", "argparse.Namespace", "fairseq.data.encoders.build_tokenizer"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.dummy_dictionary.DummyDictionary.__init__"], ["def", "__init__", "(", "self", ",", "tokenizer", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "args", "=", "argparse", ".", "Namespace", "(", "tokenizer", "=", "tokenizer", ",", "**", "kwargs", ")", "\n", "self", ".", "tokenizer", "=", "encoders", ".", "build_tokenizer", "(", "args", ")", "\n", "assert", "self", ".", "tokenizer", "is", "not", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq._hub_utils.TokenizerHubInterface.encode": [[227, 229], ["_hub_utils.TokenizerHubInterface.tokenizer.encode"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq._hub_utils.TokenizerHubInterface.encode"], ["", "def", "encode", "(", "self", ",", "sentence", ":", "str", ")", "->", "str", ":", "\n", "        ", "return", "self", ".", "tokenizer", ".", "encode", "(", "sentence", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq._hub_utils.TokenizerHubInterface.decode": [[230, 232], ["_hub_utils.TokenizerHubInterface.tokenizer.decode"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq._hub_utils.TokenizerHubInterface.decode"], ["", "def", "decode", "(", "self", ",", "sentence", ":", "str", ")", "->", "str", ":", "\n", "        ", "return", "self", ".", "tokenizer", ".", "decode", "(", "sentence", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq._hub_utils.from_pretrained": [[18, 75], ["file_utils.load_archive_file", "data_name_or_path.startswith", "checkpoint_utils.load_model_ensemble_and_task", "isinstance", "os.path.abspath", "file_utils.load_archive_file", "os.path.join", "os.path.exists", "fairseq.utils.import_user_module", "model_name_or_path.items", "os.path.join", "argparse.Namespace", "os.path.join", "checkpoint_file.split"], "function", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.file_utils.load_archive_file", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.checkpoint_utils.load_model_ensemble_and_task", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.file_utils.load_archive_file", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.utils.import_user_module"], ["def", "from_pretrained", "(", "\n", "model_name_or_path", ",", "\n", "checkpoint_file", "=", "'model.pt'", ",", "\n", "data_name_or_path", "=", "'.'", ",", "\n", "archive_map", "=", "None", ",", "\n", "**", "kwargs", "\n", ")", ":", "\n", "    ", "from", "fairseq", "import", "checkpoint_utils", ",", "file_utils", "\n", "\n", "if", "archive_map", "is", "not", "None", ":", "\n", "        ", "if", "model_name_or_path", "in", "archive_map", ":", "\n", "            ", "model_name_or_path", "=", "archive_map", "[", "model_name_or_path", "]", "\n", "", "if", "data_name_or_path", "is", "not", "None", "and", "data_name_or_path", "in", "archive_map", ":", "\n", "            ", "data_name_or_path", "=", "archive_map", "[", "data_name_or_path", "]", "\n", "\n", "# allow archive_map to set default arg_overrides (e.g., tokenizer, bpe)", "\n", "# for each model", "\n", "", "if", "isinstance", "(", "model_name_or_path", ",", "dict", ")", ":", "\n", "            ", "for", "k", ",", "v", "in", "model_name_or_path", ".", "items", "(", ")", ":", "\n", "                ", "if", "k", "==", "'checkpoint_file'", ":", "\n", "                    ", "checkpoint_file", "=", "v", "\n", "", "elif", "(", "\n", "k", "!=", "'path'", "\n", "# only set kwargs that don't already have overrides", "\n", "and", "k", "not", "in", "kwargs", "\n", ")", ":", "\n", "                    ", "kwargs", "[", "k", "]", "=", "v", "\n", "", "", "model_name_or_path", "=", "model_name_or_path", "[", "'path'", "]", "\n", "\n", "", "", "model_path", "=", "file_utils", ".", "load_archive_file", "(", "model_name_or_path", ")", "\n", "\n", "# convenience hack for loading data and BPE codes from model archive", "\n", "if", "data_name_or_path", ".", "startswith", "(", "'.'", ")", ":", "\n", "        ", "kwargs", "[", "'data'", "]", "=", "os", ".", "path", ".", "abspath", "(", "os", ".", "path", ".", "join", "(", "model_path", ",", "data_name_or_path", ")", ")", "\n", "", "else", ":", "\n", "        ", "kwargs", "[", "'data'", "]", "=", "file_utils", ".", "load_archive_file", "(", "data_name_or_path", ")", "\n", "", "for", "file", ",", "arg", "in", "{", "\n", "'code'", ":", "'bpe_codes'", ",", "\n", "'bpecodes'", ":", "'bpe_codes'", ",", "\n", "'sentencepiece.bpe.model'", ":", "'sentencepiece_vocab'", ",", "\n", "}", ".", "items", "(", ")", ":", "\n", "        ", "path", "=", "os", ".", "path", ".", "join", "(", "model_path", ",", "file", ")", "\n", "if", "os", ".", "path", ".", "exists", "(", "path", ")", ":", "\n", "            ", "kwargs", "[", "arg", "]", "=", "path", "\n", "\n", "", "", "if", "'user_dir'", "in", "kwargs", ":", "\n", "        ", "utils", ".", "import_user_module", "(", "argparse", ".", "Namespace", "(", "user_dir", "=", "kwargs", "[", "'user_dir'", "]", ")", ")", "\n", "\n", "", "models", ",", "args", ",", "task", "=", "checkpoint_utils", ".", "load_model_ensemble_and_task", "(", "\n", "[", "os", ".", "path", ".", "join", "(", "model_path", ",", "cpt", ")", "for", "cpt", "in", "checkpoint_file", ".", "split", "(", "':'", ")", "]", ",", "\n", "arg_overrides", "=", "kwargs", ",", "\n", ")", "\n", "\n", "return", "{", "\n", "'args'", ":", "args", ",", "\n", "'task'", ":", "task", ",", "\n", "'models'", ":", "models", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.file_utils.load_archive_file": [[52, 88], ["file_utils.cached_path", "print", "print", "os.path.isdir", "tempfile.mkdtemp", "print", "os.remove", "shutil.move", "shutil.rmtree", "print", "tarfile.open", "os.path.commonprefix", "archive.extractall", "os.path.join", "os.path.splitext", "archive.getnames"], "function", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.file_utils.cached_path", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.progress_bar.tensorboard_log_wrapper.print", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.progress_bar.tensorboard_log_wrapper.print", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.progress_bar.tensorboard_log_wrapper.print", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.progress_bar.tensorboard_log_wrapper.print"], ["def", "load_archive_file", "(", "archive_file", ")", ":", "\n", "# redirect to the cache, if necessary", "\n", "    ", "try", ":", "\n", "        ", "resolved_archive_file", "=", "cached_path", "(", "archive_file", ",", "cache_dir", "=", "None", ")", "\n", "", "except", "EnvironmentError", ":", "\n", "        ", "print", "(", "\n", "\"Archive name '{}' was not found in archive name list. \"", "\n", "\"We assumed '{}' was a path or URL but couldn't find any file \"", "\n", "\"associated to this path or URL.\"", ".", "format", "(", "\n", "archive_file", ",", "\n", "archive_file", ",", "\n", ")", "\n", ")", "\n", "return", "None", "\n", "\n", "", "if", "resolved_archive_file", "==", "archive_file", ":", "\n", "        ", "print", "(", "\"loading archive file {}\"", ".", "format", "(", "archive_file", ")", ")", "\n", "", "else", ":", "\n", "        ", "print", "(", "\"loading archive file {} from cache at {}\"", ".", "format", "(", "\n", "archive_file", ",", "resolved_archive_file", ")", ")", "\n", "\n", "# Extract archive to temp dir and replace .tar.bz2 if necessary", "\n", "", "tempdir", "=", "None", "\n", "if", "not", "os", ".", "path", ".", "isdir", "(", "resolved_archive_file", ")", ":", "\n", "        ", "tempdir", "=", "tempfile", ".", "mkdtemp", "(", ")", "\n", "print", "(", "\"extracting archive file {} to temp dir {}\"", ".", "format", "(", "\n", "resolved_archive_file", ",", "tempdir", ")", ")", "\n", "ext", "=", "os", ".", "path", ".", "splitext", "(", "archive_file", ")", "[", "1", "]", "[", "1", ":", "]", "\n", "with", "tarfile", ".", "open", "(", "resolved_archive_file", ",", "'r:'", "+", "ext", ")", "as", "archive", ":", "\n", "            ", "top_dir", "=", "os", ".", "path", ".", "commonprefix", "(", "archive", ".", "getnames", "(", ")", ")", "\n", "archive", ".", "extractall", "(", "tempdir", ")", "\n", "", "os", ".", "remove", "(", "resolved_archive_file", ")", "\n", "shutil", ".", "move", "(", "os", ".", "path", ".", "join", "(", "tempdir", ",", "top_dir", ")", ",", "resolved_archive_file", ")", "\n", "shutil", ".", "rmtree", "(", "tempdir", ")", "\n", "\n", "", "return", "resolved_archive_file", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.file_utils.url_to_filename": [[90, 106], ["url.encode", "hashlib.sha256", "hashlib.sha256.hexdigest", "etag.encode", "hashlib.sha256", "hashlib.sha256.hexdigest"], "function", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq._hub_utils.TokenizerHubInterface.encode", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq._hub_utils.TokenizerHubInterface.encode"], ["", "def", "url_to_filename", "(", "url", ",", "etag", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    Convert `url` into a hashed filename in a repeatable way.\n    If `etag` is specified, append its hash to the URL's, delimited\n    by a period.\n    \"\"\"", "\n", "url_bytes", "=", "url", ".", "encode", "(", "'utf-8'", ")", "\n", "url_hash", "=", "sha256", "(", "url_bytes", ")", "\n", "filename", "=", "url_hash", ".", "hexdigest", "(", ")", "\n", "\n", "if", "etag", ":", "\n", "        ", "etag_bytes", "=", "etag", ".", "encode", "(", "'utf-8'", ")", "\n", "etag_hash", "=", "sha256", "(", "etag_bytes", ")", "\n", "filename", "+=", "'.'", "+", "etag_hash", ".", "hexdigest", "(", ")", "\n", "\n", "", "return", "filename", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.file_utils.filename_to_url": [[108, 132], ["isinstance", "os.path.join", "str", "os.path.exists", "EnvironmentError", "os.path.exists", "EnvironmentError", "io.open", "json.load"], "function", ["None"], ["", "def", "filename_to_url", "(", "filename", ",", "cache_dir", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    Return the url and etag (which may be ``None``) stored for `filename`.\n    Raise ``EnvironmentError`` if `filename` or its stored metadata do not exist.\n    \"\"\"", "\n", "if", "cache_dir", "is", "None", ":", "\n", "        ", "cache_dir", "=", "PYTORCH_FAIRSEQ_CACHE", "\n", "", "if", "isinstance", "(", "cache_dir", ",", "Path", ")", ":", "\n", "        ", "cache_dir", "=", "str", "(", "cache_dir", ")", "\n", "\n", "", "cache_path", "=", "os", ".", "path", ".", "join", "(", "cache_dir", ",", "filename", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "cache_path", ")", ":", "\n", "        ", "raise", "EnvironmentError", "(", "\"file {} not found\"", ".", "format", "(", "cache_path", ")", ")", "\n", "\n", "", "meta_path", "=", "cache_path", "+", "'.json'", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "meta_path", ")", ":", "\n", "        ", "raise", "EnvironmentError", "(", "\"file {} not found\"", ".", "format", "(", "meta_path", ")", ")", "\n", "\n", "", "with", "open", "(", "meta_path", ",", "encoding", "=", "\"utf-8\"", ")", "as", "meta_file", ":", "\n", "        ", "metadata", "=", "json", ".", "load", "(", "meta_file", ")", "\n", "", "url", "=", "metadata", "[", "'url'", "]", "\n", "etag", "=", "metadata", "[", "'etag'", "]", "\n", "\n", "return", "url", ",", "etag", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.file_utils.cached_path": [[134, 162], ["isinstance", "isinstance", "urlparse", "str", "str", "file_utils.get_from_cache", "os.path.exists", "EnvironmentError", "ValueError"], "function", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.file_utils.get_from_cache"], ["", "def", "cached_path", "(", "url_or_filename", ",", "cache_dir", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    Given something that might be a URL (or might be a local path),\n    determine which. If it's a URL, download the file and cache it, and\n    return the path to the cached file. If it's already a local path,\n    make sure the file exists and then return the path.\n    \"\"\"", "\n", "if", "cache_dir", "is", "None", ":", "\n", "        ", "cache_dir", "=", "PYTORCH_FAIRSEQ_CACHE", "\n", "", "if", "isinstance", "(", "url_or_filename", ",", "Path", ")", ":", "\n", "        ", "url_or_filename", "=", "str", "(", "url_or_filename", ")", "\n", "", "if", "isinstance", "(", "cache_dir", ",", "Path", ")", ":", "\n", "        ", "cache_dir", "=", "str", "(", "cache_dir", ")", "\n", "\n", "", "parsed", "=", "urlparse", "(", "url_or_filename", ")", "\n", "\n", "if", "parsed", ".", "scheme", "in", "(", "'http'", ",", "'https'", ",", "'s3'", ")", ":", "\n", "# URL, so get it from the cache (downloading if necessary)", "\n", "        ", "return", "get_from_cache", "(", "url_or_filename", ",", "cache_dir", ")", "\n", "", "elif", "os", ".", "path", ".", "exists", "(", "url_or_filename", ")", ":", "\n", "# File, and it exists.", "\n", "        ", "return", "url_or_filename", "\n", "", "elif", "parsed", ".", "scheme", "==", "''", ":", "\n", "# File, but it doesn't exist.", "\n", "        ", "raise", "EnvironmentError", "(", "\"file {} not found\"", ".", "format", "(", "url_or_filename", ")", ")", "\n", "", "else", ":", "\n", "# Something unknown", "\n", "        ", "raise", "ValueError", "(", "\"unable to parse {} as a URL or as a local path\"", ".", "format", "(", "url_or_filename", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.file_utils.split_s3_path": [[164, 175], ["urlparse", "s3_path.startswith", "ValueError"], "function", ["None"], ["", "", "def", "split_s3_path", "(", "url", ")", ":", "\n", "    ", "\"\"\"Split a full s3 path into the bucket name and path.\"\"\"", "\n", "parsed", "=", "urlparse", "(", "url", ")", "\n", "if", "not", "parsed", ".", "netloc", "or", "not", "parsed", ".", "path", ":", "\n", "        ", "raise", "ValueError", "(", "\"bad s3 path {}\"", ".", "format", "(", "url", ")", ")", "\n", "", "bucket_name", "=", "parsed", ".", "netloc", "\n", "s3_path", "=", "parsed", ".", "path", "\n", "# Remove '/' at beginning of path.", "\n", "if", "s3_path", ".", "startswith", "(", "\"/\"", ")", ":", "\n", "        ", "s3_path", "=", "s3_path", "[", "1", ":", "]", "\n", "", "return", "bucket_name", ",", "s3_path", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.file_utils.s3_request": [[177, 195], ["functools.wraps", "func", "int", "EnvironmentError"], "function", ["None"], ["", "def", "s3_request", "(", "func", ")", ":", "\n", "    ", "\"\"\"\n    Wrapper function for s3 requests in order to create more helpful error\n    messages.\n    \"\"\"", "\n", "\n", "@", "wraps", "(", "func", ")", "\n", "def", "wrapper", "(", "url", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "from", "botocore", ".", "exceptions", "import", "ClientError", "\n", "try", ":", "\n", "            ", "return", "func", "(", "url", ",", "*", "args", ",", "**", "kwargs", ")", "\n", "", "except", "ClientError", "as", "exc", ":", "\n", "            ", "if", "int", "(", "exc", ".", "response", "[", "\"Error\"", "]", "[", "\"Code\"", "]", ")", "==", "404", ":", "\n", "                ", "raise", "EnvironmentError", "(", "\"file {} not found\"", ".", "format", "(", "url", ")", ")", "\n", "", "else", ":", "\n", "                ", "raise", "\n", "\n", "", "", "", "return", "wrapper", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.file_utils.s3_etag": [[197, 205], ["boto3.resource", "file_utils.split_s3_path", "boto3.resource.Object"], "function", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.file_utils.split_s3_path"], ["", "@", "s3_request", "\n", "def", "s3_etag", "(", "url", ")", ":", "\n", "    ", "\"\"\"Check ETag on S3 object.\"\"\"", "\n", "import", "boto3", "\n", "s3_resource", "=", "boto3", ".", "resource", "(", "\"s3\"", ")", "\n", "bucket_name", ",", "s3_path", "=", "split_s3_path", "(", "url", ")", "\n", "s3_object", "=", "s3_resource", ".", "Object", "(", "bucket_name", ",", "s3_path", ")", "\n", "return", "s3_object", ".", "e_tag", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.file_utils.s3_get": [[207, 214], ["boto3.resource", "file_utils.split_s3_path", "boto3.resource.Bucket().download_fileobj", "boto3.resource.Bucket"], "function", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.file_utils.split_s3_path"], ["", "@", "s3_request", "\n", "def", "s3_get", "(", "url", ",", "temp_file", ")", ":", "\n", "    ", "\"\"\"Pull a file directly from S3.\"\"\"", "\n", "import", "boto3", "\n", "s3_resource", "=", "boto3", ".", "resource", "(", "\"s3\"", ")", "\n", "bucket_name", ",", "s3_path", "=", "split_s3_path", "(", "url", ")", "\n", "s3_resource", ".", "Bucket", "(", "bucket_name", ")", ".", "download_fileobj", "(", "s3_path", ",", "temp_file", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.file_utils.http_get": [[216, 228], ["requests.get", "requests.get.headers.get", "tqdm", "requests.get.iter_content", "tqdm.close", "int", "tqdm.update", "temp_file.write", "len"], "function", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.meters.TimeMeter.update"], ["", "def", "http_get", "(", "url", ",", "temp_file", ")", ":", "\n", "    ", "import", "requests", "\n", "from", "tqdm", "import", "tqdm", "\n", "req", "=", "requests", ".", "get", "(", "url", ",", "stream", "=", "True", ")", "\n", "content_length", "=", "req", ".", "headers", ".", "get", "(", "'Content-Length'", ")", "\n", "total", "=", "int", "(", "content_length", ")", "if", "content_length", "is", "not", "None", "else", "None", "\n", "progress", "=", "tqdm", "(", "unit", "=", "\"B\"", ",", "total", "=", "total", ")", "\n", "for", "chunk", "in", "req", ".", "iter_content", "(", "chunk_size", "=", "1024", ")", ":", "\n", "        ", "if", "chunk", ":", "# filter out keep-alive new chunks", "\n", "            ", "progress", ".", "update", "(", "len", "(", "chunk", ")", ")", "\n", "temp_file", ".", "write", "(", "chunk", ")", "\n", "", "", "progress", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.file_utils.get_from_cache": [[230, 301], ["isinstance", "url.startswith", "file_utils.url_to_filename", "os.path.join", "str", "os.path.exists", "os.makedirs", "file_utils.s3_etag", "fnmatch.filter", "list", "os.path.exists", "requests.head", "os.path.exists", "os.listdir", "filter", "os.path.join", "tempfile.NamedTemporaryFile", "logger.info", "url.startswith", "temp_file.flush", "temp_file.seek", "logger.info", "logger.info", "logger.info", "requests.head.headers.get", "file_utils.s3_get", "file_utils.http_get", "io.open", "shutil.copyfileobj", "io.open", "json.dumps", "meta_file.write", "s.endswith"], "function", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.file_utils.url_to_filename", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.file_utils.s3_etag", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.file_utils.s3_get", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.file_utils.http_get"], ["", "def", "get_from_cache", "(", "url", ",", "cache_dir", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    Given a URL, look for the corresponding dataset in the local cache.\n    If it's not there, download it. Then return the path to the cached file.\n    \"\"\"", "\n", "if", "cache_dir", "is", "None", ":", "\n", "        ", "cache_dir", "=", "PYTORCH_FAIRSEQ_CACHE", "\n", "", "if", "isinstance", "(", "cache_dir", ",", "Path", ")", ":", "\n", "        ", "cache_dir", "=", "str", "(", "cache_dir", ")", "\n", "\n", "", "if", "not", "os", ".", "path", ".", "exists", "(", "cache_dir", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "cache_dir", ")", "\n", "\n", "# Get eTag to add to filename, if it exists.", "\n", "", "if", "url", ".", "startswith", "(", "\"s3://\"", ")", ":", "\n", "        ", "etag", "=", "s3_etag", "(", "url", ")", "\n", "", "else", ":", "\n", "        ", "try", ":", "\n", "            ", "import", "requests", "\n", "response", "=", "requests", ".", "head", "(", "url", ",", "allow_redirects", "=", "True", ")", "\n", "if", "response", ".", "status_code", "!=", "200", ":", "\n", "                ", "etag", "=", "None", "\n", "", "else", ":", "\n", "                ", "etag", "=", "response", ".", "headers", ".", "get", "(", "\"ETag\"", ")", "\n", "", "", "except", "EnvironmentError", ":", "\n", "            ", "etag", "=", "None", "\n", "\n", "", "", "filename", "=", "url_to_filename", "(", "url", ",", "etag", ")", "\n", "\n", "# get cache path to put the file", "\n", "cache_path", "=", "os", ".", "path", ".", "join", "(", "cache_dir", ",", "filename", ")", "\n", "\n", "# If we don't have a connection (etag is None) and can't identify the file", "\n", "# try to get the last downloaded one", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "cache_path", ")", "and", "etag", "is", "None", ":", "\n", "        ", "matching_files", "=", "fnmatch", ".", "filter", "(", "os", ".", "listdir", "(", "cache_dir", ")", ",", "filename", "+", "'.*'", ")", "\n", "matching_files", "=", "list", "(", "filter", "(", "lambda", "s", ":", "not", "s", ".", "endswith", "(", "'.json'", ")", ",", "matching_files", ")", ")", "\n", "if", "matching_files", ":", "\n", "            ", "cache_path", "=", "os", ".", "path", ".", "join", "(", "cache_dir", ",", "matching_files", "[", "-", "1", "]", ")", "\n", "\n", "", "", "if", "not", "os", ".", "path", ".", "exists", "(", "cache_path", ")", ":", "\n", "# Download to temporary file, then copy to cache dir once finished.", "\n", "# Otherwise you get corrupt cache entries if the download gets interrupted.", "\n", "        ", "with", "tempfile", ".", "NamedTemporaryFile", "(", ")", "as", "temp_file", ":", "\n", "            ", "logger", ".", "info", "(", "\"%s not found in cache, downloading to %s\"", ",", "url", ",", "temp_file", ".", "name", ")", "\n", "\n", "# GET file object", "\n", "if", "url", ".", "startswith", "(", "\"s3://\"", ")", ":", "\n", "                ", "s3_get", "(", "url", ",", "temp_file", ")", "\n", "", "else", ":", "\n", "                ", "http_get", "(", "url", ",", "temp_file", ")", "\n", "\n", "# we are copying the file before closing it, so flush to avoid truncation", "\n", "", "temp_file", ".", "flush", "(", ")", "\n", "# shutil.copyfileobj() starts at the current position, so go to the start", "\n", "temp_file", ".", "seek", "(", "0", ")", "\n", "\n", "logger", ".", "info", "(", "\"copying %s to cache at %s\"", ",", "temp_file", ".", "name", ",", "cache_path", ")", "\n", "with", "open", "(", "cache_path", ",", "'wb'", ")", "as", "cache_file", ":", "\n", "                ", "shutil", ".", "copyfileobj", "(", "temp_file", ",", "cache_file", ")", "\n", "\n", "", "logger", ".", "info", "(", "\"creating metadata file for %s\"", ",", "cache_path", ")", "\n", "meta", "=", "{", "'url'", ":", "url", ",", "'etag'", ":", "etag", "}", "\n", "meta_path", "=", "cache_path", "+", "'.json'", "\n", "with", "open", "(", "meta_path", ",", "'w'", ")", "as", "meta_file", ":", "\n", "                ", "output_string", "=", "json", ".", "dumps", "(", "meta", ")", "\n", "meta_file", ".", "write", "(", "output_string", ")", "\n", "\n", "", "logger", ".", "info", "(", "\"removing temp file %s\"", ",", "temp_file", ".", "name", ")", "\n", "\n", "", "", "return", "cache_path", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.file_utils.read_set_from_file": [[303, 313], ["set", "io.open", "set.add", "line.rstrip"], "function", ["None"], ["", "def", "read_set_from_file", "(", "filename", ")", ":", "\n", "    ", "'''\n    Extract a de-duped collection (set) of text from a file.\n    Expected file format is one item per line.\n    '''", "\n", "collection", "=", "set", "(", ")", "\n", "with", "open", "(", "filename", ",", "'r'", ",", "encoding", "=", "'utf-8'", ")", "as", "file_", ":", "\n", "        ", "for", "line", "in", "file_", ":", "\n", "            ", "collection", ".", "add", "(", "line", ".", "rstrip", "(", ")", ")", "\n", "", "", "return", "collection", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.file_utils.get_file_extension": [[315, 319], ["os.path.splitext", "ext.lower"], "function", ["None"], ["", "def", "get_file_extension", "(", "path", ",", "dot", "=", "True", ",", "lower", "=", "True", ")", ":", "\n", "    ", "ext", "=", "os", ".", "path", ".", "splitext", "(", "path", ")", "[", "1", "]", "\n", "ext", "=", "ext", "if", "dot", "else", "ext", "[", "1", ":", "]", "\n", "return", "ext", ".", "lower", "(", ")", "if", "lower", "else", "ext", "\n", "", ""]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.trainer.Trainer.__init__": [[33, 65], ["trainer.Trainer.init_meters", "torch.cuda.is_available", "trainer.Trainer._criterion.half", "trainer.Trainer._model.half", "trainer.Trainer._criterion.cuda", "trainer.Trainer._model.cuda"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.trainer.Trainer.init_meters"], ["def", "__init__", "(", "self", ",", "args", ",", "task", ",", "model", ",", "criterion", ",", "dummy_batch", "=", "None", ",", "oom_batch", "=", "None", ")", ":", "\n", "        ", "self", ".", "args", "=", "args", "\n", "self", ".", "task", "=", "task", "\n", "\n", "# copy model and criterion to current device", "\n", "self", ".", "_criterion", "=", "criterion", "\n", "self", ".", "_model", "=", "model", "\n", "self", ".", "cuda", "=", "torch", ".", "cuda", ".", "is_available", "(", ")", "and", "not", "args", ".", "cpu", "\n", "if", "args", ".", "fp16", ":", "\n", "            ", "self", ".", "_criterion", "=", "self", ".", "_criterion", ".", "half", "(", ")", "\n", "self", ".", "_model", "=", "self", ".", "_model", ".", "half", "(", ")", "\n", "", "if", "self", ".", "cuda", ":", "\n", "            ", "self", ".", "_criterion", "=", "self", ".", "_criterion", ".", "cuda", "(", ")", "\n", "self", ".", "_model", "=", "self", ".", "_model", ".", "cuda", "(", ")", "\n", "\n", "", "self", ".", "_dummy_batch", "=", "dummy_batch", "\n", "self", ".", "_oom_batch", "=", "oom_batch", "or", "dummy_batch", "\n", "\n", "self", ".", "_lr_scheduler", "=", "None", "\n", "self", ".", "_num_updates", "=", "0", "\n", "self", ".", "_optim_history", "=", "None", "\n", "self", ".", "_optimizer", "=", "None", "\n", "self", ".", "_prev_grad_norm", "=", "None", "\n", "self", ".", "_wrapped_criterion", "=", "None", "\n", "self", ".", "_wrapped_model", "=", "None", "\n", "\n", "# Fast stats sync avoids memcpy and is 7% faster when tested on 16 nodes.", "\n", "# It is less flexible and syncs only the default stats.", "\n", "self", ".", "_all_reduce_list", "=", "[", "0.0", "]", "*", "6", "\n", "self", ".", "fast_stat_sync", "=", "args", ".", "fast_stat_sync", "\n", "\n", "self", ".", "init_meters", "(", "args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.trainer.Trainer.init_meters": [[66, 83], ["collections.OrderedDict", "fairseq.meters.AverageMeter", "fairseq.meters.AverageMeter", "fairseq.meters.AverageMeter", "fairseq.meters.AverageMeter", "fairseq.meters.TimeMeter", "fairseq.meters.TimeMeter", "fairseq.meters.AverageMeter", "fairseq.meters.AverageMeter", "fairseq.meters.AverageMeter", "fairseq.meters.AverageMeter", "fairseq.meters.AverageMeter", "fairseq.meters.TimeMeter", "fairseq.meters.StopwatchMeter", "fairseq.meters.AverageMeter"], "methods", ["None"], ["", "def", "init_meters", "(", "self", ",", "args", ")", ":", "\n", "        ", "self", ".", "meters", "=", "OrderedDict", "(", ")", "\n", "self", ".", "meters", "[", "\"train_loss\"", "]", "=", "AverageMeter", "(", ")", "\n", "self", ".", "meters", "[", "\"train_nll_loss\"", "]", "=", "AverageMeter", "(", ")", "\n", "self", ".", "meters", "[", "\"valid_loss\"", "]", "=", "AverageMeter", "(", ")", "\n", "self", ".", "meters", "[", "\"valid_nll_loss\"", "]", "=", "AverageMeter", "(", ")", "\n", "self", ".", "meters", "[", "\"wps\"", "]", "=", "TimeMeter", "(", ")", "# words per second", "\n", "self", ".", "meters", "[", "\"ups\"", "]", "=", "TimeMeter", "(", ")", "# updates per second", "\n", "self", ".", "meters", "[", "\"wpb\"", "]", "=", "AverageMeter", "(", ")", "# words per batch", "\n", "self", ".", "meters", "[", "\"bsz\"", "]", "=", "AverageMeter", "(", ")", "# sentences per batch", "\n", "self", ".", "meters", "[", "\"gnorm\"", "]", "=", "AverageMeter", "(", ")", "# gradient norm", "\n", "self", ".", "meters", "[", "\"clip\"", "]", "=", "AverageMeter", "(", ")", "# % of updates clipped", "\n", "self", ".", "meters", "[", "\"oom\"", "]", "=", "AverageMeter", "(", ")", "# out of memory", "\n", "if", "args", ".", "fp16", ":", "\n", "            ", "self", ".", "meters", "[", "\"loss_scale\"", "]", "=", "AverageMeter", "(", ")", "# dynamic loss scale", "\n", "", "self", ".", "meters", "[", "\"wall\"", "]", "=", "TimeMeter", "(", ")", "# wall time in seconds", "\n", "self", ".", "meters", "[", "\"train_wall\"", "]", "=", "StopwatchMeter", "(", ")", "# train wall time in seconds", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.trainer.Trainer.criterion": [[84, 98], ["fairseq.utils.has_parameters", "fairseq.models.DistributedFairseqModel"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.utils.has_parameters", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.distributed_fairseq_model.DistributedFairseqModel"], ["", "@", "property", "\n", "def", "criterion", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "_wrapped_criterion", "is", "None", ":", "\n", "            ", "if", "(", "\n", "utils", ".", "has_parameters", "(", "self", ".", "_criterion", ")", "\n", "and", "self", ".", "args", ".", "distributed_world_size", ">", "1", "\n", "and", "not", "self", ".", "args", ".", "use_bmuf", "\n", ")", ":", "\n", "                ", "self", ".", "_wrapped_criterion", "=", "models", ".", "DistributedFairseqModel", "(", "\n", "self", ".", "args", ",", "self", ".", "_criterion", "\n", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "_wrapped_criterion", "=", "self", ".", "_criterion", "\n", "", "", "return", "self", ".", "_wrapped_criterion", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.trainer.Trainer.model": [[99, 109], ["fairseq.models.DistributedFairseqModel"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.distributed_fairseq_model.DistributedFairseqModel"], ["", "@", "property", "\n", "def", "model", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "_wrapped_model", "is", "None", ":", "\n", "            ", "if", "self", ".", "args", ".", "distributed_world_size", ">", "1", "and", "not", "self", ".", "args", ".", "use_bmuf", ":", "\n", "                ", "self", ".", "_wrapped_model", "=", "models", ".", "DistributedFairseqModel", "(", "\n", "self", ".", "args", ",", "self", ".", "_model", "\n", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "_wrapped_model", "=", "self", ".", "_model", "\n", "", "", "return", "self", ".", "_wrapped_model", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.trainer.Trainer.optimizer": [[110, 115], ["trainer.Trainer._build_optimizer"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.trainer.Trainer._build_optimizer"], ["", "@", "property", "\n", "def", "optimizer", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "_optimizer", "is", "None", ":", "\n", "            ", "self", ".", "_build_optimizer", "(", ")", "\n", "", "return", "self", ".", "_optimizer", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.trainer.Trainer.lr_scheduler": [[116, 121], ["trainer.Trainer._build_optimizer"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.trainer.Trainer._build_optimizer"], ["", "@", "property", "\n", "def", "lr_scheduler", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "_lr_scheduler", "is", "None", ":", "\n", "            ", "self", ".", "_build_optimizer", "(", ")", "# this will initialize self._lr_scheduler", "\n", "", "return", "self", ".", "_lr_scheduler", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.trainer.Trainer._build_optimizer": [[122, 154], ["list", "fairseq.optim.lr_scheduler.build_lr_scheduler", "trainer.Trainer._lr_scheduler.step_update", "filter", "fairseq.optim.build_optimizer", "fairseq.optim.FairseqBMUF", "itertools.chain", "print", "fairseq.optim.MemoryEfficientFP16Optimizer.build_optimizer", "fairseq.optim.FP16Optimizer.build_optimizer", "print", "trainer.Trainer.model.parameters", "trainer.Trainer.criterion.parameters", "torch.cuda.get_device_capability", "torch.cuda.get_device_capability"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.lr_scheduler.polynomial_decay_schedule.PolynomialDecaySchedule.step_update", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.optim.fp16_optimizer.MemoryEfficientFP16Optimizer.build_optimizer", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.progress_bar.tensorboard_log_wrapper.print", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.optim.fp16_optimizer.MemoryEfficientFP16Optimizer.build_optimizer", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.optim.fp16_optimizer.MemoryEfficientFP16Optimizer.build_optimizer", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.progress_bar.tensorboard_log_wrapper.print"], ["", "def", "_build_optimizer", "(", "self", ")", ":", "\n", "        ", "params", "=", "list", "(", "\n", "filter", "(", "\n", "lambda", "p", ":", "p", ".", "requires_grad", ",", "\n", "chain", "(", "self", ".", "model", ".", "parameters", "(", ")", ",", "self", ".", "criterion", ".", "parameters", "(", ")", ")", ",", "\n", ")", "\n", ")", "\n", "\n", "if", "self", ".", "args", ".", "fp16", ":", "\n", "            ", "if", "self", ".", "cuda", "and", "torch", ".", "cuda", ".", "get_device_capability", "(", "0", ")", "[", "0", "]", "<", "7", ":", "\n", "                ", "print", "(", "\n", "\"| WARNING: your device does NOT support faster training with --fp16, \"", "\n", "\"please switch to FP32 which is likely to be faster\"", "\n", ")", "\n", "", "if", "self", ".", "args", ".", "memory_efficient_fp16", ":", "\n", "                ", "self", ".", "_optimizer", "=", "optim", ".", "MemoryEfficientFP16Optimizer", ".", "build_optimizer", "(", "\n", "self", ".", "args", ",", "params", "\n", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "_optimizer", "=", "optim", ".", "FP16Optimizer", ".", "build_optimizer", "(", "self", ".", "args", ",", "params", ")", "\n", "", "", "else", ":", "\n", "            ", "if", "self", ".", "cuda", "and", "torch", ".", "cuda", ".", "get_device_capability", "(", "0", ")", "[", "0", "]", ">=", "7", ":", "\n", "                ", "print", "(", "\"| NOTICE: your device may support faster training with --fp16\"", ")", "\n", "", "self", ".", "_optimizer", "=", "optim", ".", "build_optimizer", "(", "self", ".", "args", ",", "params", ")", "\n", "\n", "", "if", "self", ".", "args", ".", "use_bmuf", ":", "\n", "            ", "self", ".", "_optimizer", "=", "optim", ".", "FairseqBMUF", "(", "self", ".", "args", ",", "self", ".", "_optimizer", ")", "\n", "\n", "# We should initialize the learning rate scheduler immediately after", "\n", "# building the optimizer, so that the initial learning rate is set.", "\n", "", "self", ".", "_lr_scheduler", "=", "lr_scheduler", ".", "build_lr_scheduler", "(", "self", ".", "args", ",", "self", ".", "optimizer", ")", "\n", "self", ".", "_lr_scheduler", ".", "step_update", "(", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.trainer.Trainer.save_checkpoint": [[155, 169], ["fairseq.distributed_utils.is_master", "fairseq.checkpoint_utils.save_state", "trainer.Trainer.get_model().state_dict", "trainer.Trainer.get_criterion", "trainer.Trainer.get_num_updates", "trainer.Trainer.get_model"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.distributed_utils.is_master", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.checkpoint_utils.save_state", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.iterators.EpochBatchIterator.state_dict", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.trainer.Trainer.get_criterion", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.optim.bmuf.FairseqBMUF.get_num_updates", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.trainer.Trainer.get_model"], ["", "def", "save_checkpoint", "(", "self", ",", "filename", ",", "extra_state", ")", ":", "\n", "        ", "\"\"\"Save all training state in a checkpoint file.\"\"\"", "\n", "if", "distributed_utils", ".", "is_master", "(", "self", ".", "args", ")", ":", "# only save one checkpoint", "\n", "            ", "extra_state", "[", "\"train_meters\"", "]", "=", "self", ".", "meters", "\n", "checkpoint_utils", ".", "save_state", "(", "\n", "filename", ",", "\n", "self", ".", "args", ",", "\n", "self", ".", "get_model", "(", ")", ".", "state_dict", "(", ")", ",", "\n", "self", ".", "get_criterion", "(", ")", ",", "\n", "self", ".", "optimizer", ",", "\n", "self", ".", "lr_scheduler", ",", "\n", "self", ".", "get_num_updates", "(", ")", ",", "\n", "self", ".", "_optim_history", ",", "\n", "extra_state", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.trainer.Trainer.load_checkpoint": [[171, 252], ["fb_pathmgr.isfile", "fairseq.checkpoint_utils.load_checkpoint_to_cpu", "fairseq.checkpoint_utils.load_checkpoint_to_cpu.get", "trainer.Trainer._build_optimizer", "trainer.Trainer.optimizer.load_state_dict", "trainer.Trainer.set_num_updates", "print", "trainer.Trainer.lr_step", "print", "os.path.exists", "trainer.Trainer.get_model().load_state_dict", "fairseq.utils.has_parameters", "trainer.Trainer.lr_scheduler.load_state_dict", "trainer.Trainer.meters.update", "trainer.Trainer.meters.values", "trainer.Trainer.get_criterion", "trainer.Trainer.get_criterion().load_state_dict", "Exception", "trainer.Trainer.get_num_updates", "isinstance", "trainer.Trainer.get_model", "trainer.Trainer.get_criterion", "meter.reset", "trainer.Trainer.get_criterion"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.checkpoint_utils.load_checkpoint_to_cpu", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.trainer.Trainer._build_optimizer", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.iterators.EpochBatchIterator.load_state_dict", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.optim.bmuf.FairseqBMUF.set_num_updates", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.progress_bar.tensorboard_log_wrapper.print", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.trainer.Trainer.lr_step", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.progress_bar.tensorboard_log_wrapper.print", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.iterators.EpochBatchIterator.load_state_dict", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.utils.has_parameters", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.iterators.EpochBatchIterator.load_state_dict", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.meters.TimeMeter.update", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.trainer.Trainer.get_criterion", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.iterators.EpochBatchIterator.load_state_dict", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.optim.bmuf.FairseqBMUF.get_num_updates", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.trainer.Trainer.get_model", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.trainer.Trainer.get_criterion", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.meters.StopwatchMeter.reset", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.trainer.Trainer.get_criterion"], ["", "", "def", "load_checkpoint", "(", "\n", "self", ",", "\n", "filename", ",", "\n", "reset_optimizer", "=", "False", ",", "\n", "reset_lr_scheduler", "=", "False", ",", "\n", "optimizer_overrides", "=", "None", ",", "\n", "reset_meters", "=", "False", ",", "\n", ")", ":", "\n", "        ", "\"\"\"Load all training state from a checkpoint file.\"\"\"", "\n", "extra_state", ",", "self", ".", "_optim_history", ",", "last_optim_state", "=", "None", ",", "[", "]", ",", "None", "\n", "\n", "try", ":", "\n", "            ", "from", "fairseq", ".", "fb_pathmgr", "import", "fb_pathmgr", "\n", "\n", "bexists", "=", "fb_pathmgr", ".", "isfile", "(", "filename", ")", "\n", "", "except", "(", "ModuleNotFoundError", ",", "ImportError", ")", ":", "\n", "            ", "bexists", "=", "os", ".", "path", ".", "exists", "(", "filename", ")", "\n", "\n", "", "if", "bexists", ":", "\n", "            ", "state", "=", "checkpoint_utils", ".", "load_checkpoint_to_cpu", "(", "filename", ")", "\n", "\n", "# load model parameters", "\n", "try", ":", "\n", "                ", "self", ".", "get_model", "(", ")", ".", "load_state_dict", "(", "\n", "state", "[", "\"model\"", "]", ",", "strict", "=", "True", ",", "args", "=", "self", ".", "args", "\n", ")", "\n", "if", "utils", ".", "has_parameters", "(", "self", ".", "get_criterion", "(", ")", ")", ":", "\n", "                    ", "self", ".", "get_criterion", "(", ")", ".", "load_state_dict", "(", "\n", "state", "[", "\"criterion\"", "]", ",", "strict", "=", "True", "\n", ")", "\n", "", "", "except", "Exception", ":", "\n", "                ", "raise", "Exception", "(", "\n", "\"Cannot load model parameters from checkpoint {}; \"", "\n", "\"please ensure that the architectures match.\"", ".", "format", "(", "filename", ")", "\n", ")", "\n", "\n", "", "extra_state", "=", "state", "[", "\"extra_state\"", "]", "\n", "self", ".", "_optim_history", "=", "state", "[", "\"optimizer_history\"", "]", "\n", "last_optim_state", "=", "state", ".", "get", "(", "\"last_optimizer_state\"", ",", "None", ")", "\n", "\n", "", "if", "last_optim_state", "is", "not", "None", "and", "not", "reset_optimizer", ":", "\n", "# rebuild optimizer after loading model, since params may have changed", "\n", "            ", "self", ".", "_build_optimizer", "(", ")", "\n", "\n", "# only reload optimizer and lr_scheduler if they match", "\n", "last_optim", "=", "self", ".", "_optim_history", "[", "-", "1", "]", "\n", "assert", "(", "\n", "last_optim", "[", "\"criterion_name\"", "]", "==", "self", ".", "get_criterion", "(", ")", ".", "__class__", ".", "__name__", "\n", ")", ",", "\"Criterion does not match; please reset the optimizer (--reset-optimizer).\"", "\n", "assert", "(", "\n", "last_optim", "[", "\"optimizer_name\"", "]", "==", "self", ".", "optimizer", ".", "__class__", ".", "__name__", "\n", ")", ",", "\"Optimizer does not match; please reset the optimizer (--reset-optimizer).\"", "\n", "\n", "if", "not", "reset_lr_scheduler", ":", "\n", "                ", "self", ".", "lr_scheduler", ".", "load_state_dict", "(", "last_optim", "[", "\"lr_scheduler_state\"", "]", ")", "\n", "", "self", ".", "optimizer", ".", "load_state_dict", "(", "last_optim_state", ",", "optimizer_overrides", ")", "\n", "\n", "self", ".", "set_num_updates", "(", "last_optim", "[", "\"num_updates\"", "]", ")", "\n", "\n", "", "if", "extra_state", "is", "not", "None", ":", "\n", "            ", "epoch", "=", "extra_state", "[", "\"train_iterator\"", "]", "[", "\"epoch\"", "]", "\n", "print", "(", "\n", "\"| loaded checkpoint {} (epoch {} @ {} updates)\"", ".", "format", "(", "\n", "filename", ",", "epoch", ",", "self", ".", "get_num_updates", "(", ")", "\n", ")", "\n", ")", "\n", "\n", "self", ".", "lr_step", "(", "epoch", ")", "\n", "\n", "if", "\"train_meters\"", "in", "extra_state", "and", "not", "reset_meters", ":", "\n", "                ", "self", ".", "meters", ".", "update", "(", "extra_state", "[", "\"train_meters\"", "]", ")", "\n", "del", "extra_state", "[", "\"train_meters\"", "]", "\n", "\n", "# reset TimeMeters, since their start times don't make sense anymore", "\n", "for", "meter", "in", "self", ".", "meters", ".", "values", "(", ")", ":", "\n", "                    ", "if", "isinstance", "(", "meter", ",", "TimeMeter", ")", ":", "\n", "                        ", "meter", ".", "reset", "(", ")", "\n", "", "", "", "", "else", ":", "\n", "            ", "print", "(", "\"| no existing checkpoint found {}\"", ".", "format", "(", "filename", ")", ")", "\n", "\n", "", "return", "extra_state", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.trainer.Trainer.get_train_iterator": [[253, 284], ["trainer.Trainer.task.get_batch_iterator", "print", "trainer.Trainer.task.load_dataset", "trainer.Trainer.task.dataset", "fairseq.utils.resolve_max_positions", "trainer.Trainer.task.max_positions", "trainer.Trainer.model.max_positions"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.tasks.fairseq_task.FairseqTask.get_batch_iterator", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.progress_bar.tensorboard_log_wrapper.print", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.tasks.integer_sequence_modeling.IntegerSequenceModelingTask.load_dataset", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.tasks.fairseq_task.FairseqTask.dataset", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.utils.resolve_max_positions", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.tasks.fairseq_task.FairseqTask.max_positions", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.tasks.fairseq_task.FairseqTask.max_positions"], ["", "def", "get_train_iterator", "(", "\n", "self", ",", "\n", "epoch", ",", "\n", "combine", "=", "True", ",", "\n", "load_dataset", "=", "True", ",", "\n", "data_selector", "=", "None", ",", "\n", "shard_batch_itr", "=", "True", ",", "\n", ")", ":", "\n", "        ", "\"\"\"Return an EpochBatchIterator over the training set for a given epoch.\"\"\"", "\n", "if", "load_dataset", ":", "\n", "            ", "print", "(", "\"| loading train data for epoch {}\"", ".", "format", "(", "epoch", ")", ")", "\n", "self", ".", "task", ".", "load_dataset", "(", "\n", "self", ".", "args", ".", "train_subset", ",", "\n", "epoch", "=", "epoch", ",", "\n", "combine", "=", "combine", ",", "\n", "data_selector", "=", "data_selector", ",", "\n", ")", "\n", "", "return", "self", ".", "task", ".", "get_batch_iterator", "(", "\n", "dataset", "=", "self", ".", "task", ".", "dataset", "(", "self", ".", "args", ".", "train_subset", ")", ",", "\n", "max_tokens", "=", "self", ".", "args", ".", "max_tokens", ",", "\n", "max_sentences", "=", "self", ".", "args", ".", "max_sentences", ",", "\n", "max_positions", "=", "utils", ".", "resolve_max_positions", "(", "\n", "self", ".", "task", ".", "max_positions", "(", ")", ",", "self", ".", "model", ".", "max_positions", "(", ")", "\n", ")", ",", "\n", "ignore_invalid_inputs", "=", "True", ",", "\n", "required_batch_size_multiple", "=", "self", ".", "args", ".", "required_batch_size_multiple", ",", "\n", "seed", "=", "self", ".", "args", ".", "seed", ",", "\n", "num_shards", "=", "self", ".", "args", ".", "distributed_world_size", "if", "shard_batch_itr", "else", "1", ",", "\n", "shard_id", "=", "self", ".", "args", ".", "distributed_rank", "if", "shard_batch_itr", "else", "0", ",", "\n", "num_workers", "=", "self", ".", "args", ".", "num_workers", ",", "\n", "epoch", "=", "epoch", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.trainer.Trainer.train_step": [[286, 497], ["trainer.Trainer._set_seed", "trainer.Trainer.model.train", "trainer.Trainer.criterion.train", "trainer.Trainer.zero_grad", "enumerate", "trainer.Trainer.meters[].update", "trainer.Trainer.clear_buffered_stats", "trainer.Trainer.meters[].stop", "trainer.Trainer.meters[].start", "trainer.Trainer._prepare_sample", "trainer.Trainer.handle_ooms", "torch.cuda.DoubleTensor", "trainer.Trainer._sync_stats", "all_reduce_list_tensor[].div_", "torch.cuda.DoubleTensor.tolist", "trainer.Trainer._sync_stats", "len", "print", "trainer.Trainer.zero_grad", "trainer.Trainer.task.aggregate_logging_outputs", "trainer.Trainer.task.grad_denom", "all", "Exception", "trainer.Trainer.optimizer.clip_grad_norm", "trainer.Trainer.optimizer.step", "trainer.Trainer.set_num_updates", "trainer.Trainer.task.update_step", "trainer.Trainer.get", "trainer.Trainer.get", "trainer.Trainer.meters[].update", "trainer.Trainer.meters[].update", "trainer.Trainer.meters[].update", "trainer.Trainer.meters[].update", "trainer.Trainer.meters[].update", "trainer.Trainer.meters[].update", "trainer.Trainer.meters[].update", "trainer.Trainer.meters[].reset", "trainer.Trainer.meters[].update", "trainer.Trainer._prepare_sample", "torch.distributed.all_reduce", "zip", "list", "list", "sum", "len", "trainer.Trainer.get_criterion", "trainer.Trainer.get_criterion", "trainer.Trainer.optimizer.multiply_grads", "trainer.Trainer.get", "trainer.Trainer.meters[].update", "trainer.Trainer.meters[].update", "torch.cuda.is_available", "torch.cuda.empty_cache", "print", "trainer.Trainer.zero_grad", "hasattr", "trainer.Trainer.model.no_sync", "contextlib.ExitStack", "trainer.Trainer.train_step.maybe_no_sync"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.trainer.Trainer._set_seed", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.None.train_ar.train", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.None.train_ar.train", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.optim.fp16_optimizer._MemoryEfficientFP16OptimizerMixin.zero_grad", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.meters.TimeMeter.update", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.trainer.Trainer.clear_buffered_stats", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.meters.StopwatchMeter.stop", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.meters.StopwatchMeter.start", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.trainer.Trainer._prepare_sample", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.trainer.Trainer.handle_ooms", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.trainer.Trainer._sync_stats", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.trainer.Trainer._sync_stats", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.progress_bar.tensorboard_log_wrapper.print", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.optim.fp16_optimizer._MemoryEfficientFP16OptimizerMixin.zero_grad", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.criterions.label_smoothed_cross_entropy.LabelSmoothedCrossEntropyCriterion.aggregate_logging_outputs", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.criterions.fairseq_criterion.FairseqCriterion.grad_denom", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.optim.fp16_optimizer._MemoryEfficientFP16OptimizerMixin.clip_grad_norm", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.lr_scheduler.polynomial_decay_schedule.PolynomialDecaySchedule.step", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.optim.bmuf.FairseqBMUF.set_num_updates", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.tasks.fairseq_task.FairseqTask.update_step", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.meters.TimeMeter.update", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.meters.TimeMeter.update", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.meters.TimeMeter.update", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.meters.TimeMeter.update", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.meters.TimeMeter.update", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.meters.TimeMeter.update", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.meters.TimeMeter.update", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.meters.StopwatchMeter.reset", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.meters.TimeMeter.update", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.trainer.Trainer._prepare_sample", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.distributed_utils.all_reduce", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.trainer.Trainer.get_criterion", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.trainer.Trainer.get_criterion", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.optim.fp16_optimizer._MemoryEfficientFP16OptimizerMixin.multiply_grads", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.meters.TimeMeter.update", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.meters.TimeMeter.update", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.progress_bar.tensorboard_log_wrapper.print", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.optim.fp16_optimizer._MemoryEfficientFP16OptimizerMixin.zero_grad", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.legacy_distributed_data_parallel.LegacyDistributedDataParallel.no_sync"], ["", "def", "train_step", "(", "self", ",", "samples", ",", "dummy_batch", "=", "False", ",", "raise_oom", "=", "False", ")", ":", "\n", "        ", "\"\"\"Do forward, backward and parameter update.\"\"\"", "\n", "if", "self", ".", "_dummy_batch", "is", "None", ":", "\n", "            ", "self", ".", "_dummy_batch", "=", "samples", "[", "0", "]", "\n", "\n", "", "self", ".", "_set_seed", "(", ")", "\n", "self", ".", "model", ".", "train", "(", ")", "\n", "self", ".", "criterion", ".", "train", "(", ")", "\n", "self", ".", "zero_grad", "(", ")", "\n", "\n", "if", "not", "dummy_batch", ":", "\n", "            ", "self", ".", "meters", "[", "\"train_wall\"", "]", ".", "start", "(", ")", "\n", "\n", "# forward and backward pass", "\n", "", "logging_outputs", ",", "sample_sizes", ",", "ooms", "=", "[", "]", ",", "[", "]", ",", "0", "\n", "for", "i", ",", "sample", "in", "enumerate", "(", "samples", ")", ":", "\n", "            ", "sample", "=", "self", ".", "_prepare_sample", "(", "sample", ")", "\n", "if", "sample", "is", "None", ":", "\n", "# when sample is None, run forward/backward on a dummy batch", "\n", "# and ignore the resulting gradients", "\n", "                ", "sample", "=", "self", ".", "_prepare_sample", "(", "self", ".", "_dummy_batch", ")", "\n", "ignore_grad", "=", "True", "\n", "", "else", ":", "\n", "                ", "ignore_grad", "=", "False", "\n", "\n", "", "def", "maybe_no_sync", "(", ")", ":", "\n", "                ", "\"\"\"\n                Whenever *samples* contains more than one mini-batch, we\n                want to accumulate gradients locally and only call\n                all-reduce in the last backwards pass.\n                \"\"\"", "\n", "if", "(", "\n", "self", ".", "args", ".", "distributed_world_size", ">", "1", "\n", "and", "hasattr", "(", "self", ".", "model", ",", "\"no_sync\"", ")", "\n", "and", "i", "<", "len", "(", "samples", ")", "-", "1", "\n", ")", ":", "\n", "                    ", "return", "self", ".", "model", ".", "no_sync", "(", ")", "\n", "", "else", ":", "\n", "                    ", "return", "contextlib", ".", "ExitStack", "(", ")", "# dummy contextmanager", "\n", "\n", "", "", "try", ":", "\n", "                ", "with", "maybe_no_sync", "(", ")", ":", "\n", "# forward and backward", "\n", "                    ", "loss", ",", "sample_size", ",", "logging_output", "=", "self", ".", "task", ".", "train_step", "(", "\n", "sample", ",", "self", ".", "model", ",", "self", ".", "criterion", ",", "self", ".", "optimizer", ",", "ignore_grad", "\n", ")", "\n", "\n", "", "if", "not", "ignore_grad", ":", "\n", "                    ", "logging_outputs", ".", "append", "(", "logging_output", ")", "\n", "sample_sizes", ".", "append", "(", "sample_size", ")", "\n", "\n", "if", "self", ".", "fast_stat_sync", ":", "\n", "                        ", "self", ".", "_all_reduce_list", "[", "0", "]", "+=", "sample_size", "\n", "self", ".", "_all_reduce_list", "[", "1", "]", "+=", "logging_output", ".", "get", "(", "\n", "\"nsentences\"", ",", "0.0", "\n", ")", "\n", "self", ".", "_all_reduce_list", "[", "2", "]", "+=", "logging_output", ".", "get", "(", "\"loss\"", ",", "0.0", ")", "\n", "self", ".", "_all_reduce_list", "[", "3", "]", "+=", "logging_output", ".", "get", "(", "\"nll_loss\"", ",", "0.0", ")", "\n", "self", ".", "_all_reduce_list", "[", "4", "]", "+=", "logging_output", ".", "get", "(", "\"ntokens\"", ",", "0.0", ")", "\n", "", "", "", "except", "RuntimeError", "as", "e", ":", "\n", "                ", "if", "\"out of memory\"", "in", "str", "(", "e", ")", ":", "\n", "                    ", "self", ".", "_log_oom", "(", "e", ")", "\n", "if", "raise_oom", ":", "\n", "                        ", "raise", "e", "\n", "", "print", "(", "\n", "\"| WARNING: attempting to recover from OOM in forward/backward pass\"", ",", "\n", "file", "=", "sys", ".", "stderr", ",", "\n", ")", "\n", "ooms", "+=", "1", "\n", "self", ".", "zero_grad", "(", ")", "\n", "", "else", ":", "\n", "                    ", "raise", "e", "\n", "\n", "", "", "if", "self", ".", "fast_stat_sync", ":", "\n", "                ", "self", ".", "_all_reduce_list", "[", "5", "]", "+=", "ooms", "\n", "\n", "", "", "if", "ooms", ">", "0", "and", "self", ".", "_oom_batch", "is", "not", "None", ":", "\n", "            ", "self", ".", "handle_ooms", "(", "ooms", ")", "\n", "\n", "", "if", "dummy_batch", ":", "\n", "            ", "return", "None", "\n", "\n", "# gather logging outputs from all replicas", "\n", "", "if", "self", ".", "fast_stat_sync", ":", "\n", "# rework all_gather_list", "\n", "            ", "all_reduce_list_tensor", "=", "torch", ".", "cuda", ".", "DoubleTensor", "(", "self", ".", "_all_reduce_list", ")", "\n", "if", "self", ".", "_sync_stats", "(", ")", ":", "\n", "                ", "torch", ".", "distributed", ".", "all_reduce", "(", "all_reduce_list_tensor", ")", "\n", "# Normalize loss and nll_loss by \"sample_size\"", "\n", "# and convert to log base 2", "\n", "", "all_reduce_list_tensor", "[", "2", ":", "4", "]", ".", "div_", "(", "\n", "(", "all_reduce_list_tensor", "[", "0", ":", "1", "]", "*", "torch", ".", "log", "(", "torch", ".", "cuda", ".", "DoubleTensor", "(", "[", "2", "]", ")", ")", ")", "\n", ")", "\n", "self", ".", "_all_reduce_list", "=", "all_reduce_list_tensor", ".", "tolist", "(", ")", "\n", "logging_output", "=", "{", "}", "\n", "[", "\n", "sample_size", ",", "\n", "logging_output", "[", "\"nsentences\"", "]", ",", "\n", "logging_output", "[", "\"loss\"", "]", ",", "\n", "logging_output", "[", "\"nll_loss\"", "]", ",", "\n", "logging_output", "[", "\"ntokens\"", "]", ",", "\n", "ooms", ",", "\n", "]", "=", "self", ".", "_all_reduce_list", "\n", "", "elif", "self", ".", "_sync_stats", "(", ")", ":", "\n", "            ", "logging_outputs", ",", "sample_sizes", ",", "ooms", ",", "prev_norms", "=", "zip", "(", "\n", "*", "distributed_utils", ".", "all_gather_list", "(", "\n", "[", "logging_outputs", ",", "sample_sizes", ",", "ooms", ",", "self", ".", "_prev_grad_norm", "]", "\n", ")", "\n", ")", "\n", "logging_outputs", "=", "list", "(", "chain", ".", "from_iterable", "(", "logging_outputs", ")", ")", "\n", "sample_sizes", "=", "list", "(", "chain", ".", "from_iterable", "(", "sample_sizes", ")", ")", "\n", "ooms", "=", "sum", "(", "ooms", ")", "\n", "\n", "if", "not", "self", ".", "args", ".", "use_bmuf", ":", "\n", "                ", "assert", "all", "(", "norm", "==", "prev_norms", "[", "0", "]", "for", "norm", "in", "prev_norms", ")", "or", "all", "(", "\n", "math", ".", "isnan", "(", "norm", ")", "or", "math", ".", "isinf", "(", "norm", ")", "for", "norm", "in", "prev_norms", "\n", ")", ",", "\"Fatal error: gradients are inconsistent between workers\"", "\n", "\n", "", "", "self", ".", "meters", "[", "\"oom\"", "]", ".", "update", "(", "ooms", ",", "len", "(", "samples", ")", ")", "\n", "if", "ooms", "==", "self", ".", "args", ".", "distributed_world_size", "*", "len", "(", "samples", ")", ":", "\n", "            ", "print", "(", "\"| WARNING: OOM in all workers, skipping update\"", ")", "\n", "self", ".", "zero_grad", "(", ")", "\n", "return", "None", "\n", "\n", "", "if", "not", "self", ".", "fast_stat_sync", ":", "\n", "# aggregate logging outputs and sample sizes", "\n", "            ", "logging_output", "=", "self", ".", "task", ".", "aggregate_logging_outputs", "(", "\n", "logging_outputs", ",", "self", ".", "get_criterion", "(", ")", "\n", ")", "\n", "sample_size", "=", "self", ".", "task", ".", "grad_denom", "(", "sample_sizes", ",", "self", ".", "get_criterion", "(", ")", ")", "\n", "\n", "", "if", "not", "all", "(", "k", "in", "logging_output", "for", "k", "in", "[", "\"ntokens\"", ",", "\"nsentences\"", "]", ")", ":", "\n", "            ", "raise", "Exception", "(", "\n", "(", "\n", "\"Please update the {}.aggregate_logging_outputs() method to \"", "\n", "\"return ntokens and nsentences\"", "\n", ")", ".", "format", "(", "self", ".", "task", ".", "__class__", ".", "__name__", ")", "\n", ")", "\n", "\n", "", "try", ":", "\n", "# normalize grads by sample size", "\n", "            ", "if", "sample_size", ">", "0", ":", "\n", "                ", "self", ".", "optimizer", ".", "multiply_grads", "(", "\n", "self", ".", "args", ".", "distributed_world_size", "/", "float", "(", "sample_size", ")", "\n", ")", "\n", "\n", "# clip grads", "\n", "", "grad_norm", "=", "self", ".", "optimizer", ".", "clip_grad_norm", "(", "self", ".", "args", ".", "clip_norm", ")", "\n", "self", ".", "_prev_grad_norm", "=", "grad_norm", "\n", "\n", "# take an optimization step", "\n", "self", ".", "optimizer", ".", "step", "(", ")", "\n", "self", ".", "set_num_updates", "(", "self", ".", "get_num_updates", "(", ")", "+", "1", ")", "\n", "\n", "# task specific update per step", "\n", "self", ".", "task", ".", "update_step", "(", "self", ".", "_num_updates", ")", "\n", "\n", "# update meters", "\n", "ntokens", "=", "logging_output", ".", "get", "(", "\"ntokens\"", ",", "0", ")", "\n", "nsentences", "=", "logging_output", ".", "get", "(", "\"nsentences\"", ",", "0", ")", "\n", "self", ".", "meters", "[", "\"wps\"", "]", ".", "update", "(", "ntokens", ")", "\n", "self", ".", "meters", "[", "\"ups\"", "]", ".", "update", "(", "1.0", ")", "\n", "self", ".", "meters", "[", "\"wpb\"", "]", ".", "update", "(", "ntokens", ")", "\n", "self", ".", "meters", "[", "\"bsz\"", "]", ".", "update", "(", "nsentences", ")", "\n", "self", ".", "meters", "[", "\"gnorm\"", "]", ".", "update", "(", "grad_norm", ")", "\n", "self", ".", "meters", "[", "\"clip\"", "]", ".", "update", "(", "\n", "1.0", "\n", "if", "grad_norm", ">", "self", ".", "args", ".", "clip_norm", "and", "self", ".", "args", ".", "clip_norm", ">", "0", "\n", "else", "0.0", "\n", ")", "\n", "self", ".", "meters", "[", "\"train_loss\"", "]", ".", "update", "(", "logging_output", ".", "get", "(", "\"loss\"", ",", "0", ")", ",", "sample_size", ")", "\n", "if", "\"train_acc\"", "in", "self", ".", "meters", ":", "\n", "                ", "self", ".", "meters", "[", "\"train_acc\"", "]", ".", "update", "(", "\n", "logging_output", ".", "get", "(", "\"acc\"", ",", "0", ")", ",", "sample_size", "\n", ")", "\n", "\n", "", "if", "\"nll_loss\"", "in", "logging_output", ":", "\n", "                ", "self", ".", "meters", "[", "\"train_nll_loss\"", "]", ".", "update", "(", "\n", "logging_output", ".", "get", "(", "\"nll_loss\"", ",", "0", ")", ",", "ntokens", "\n", ")", "\n", "\n", "# clear CUDA cache to reduce memory fragmentation", "\n", "", "if", "(", "\n", "self", ".", "args", ".", "empty_cache_freq", ">", "0", "\n", "and", "(", "\n", "(", "self", ".", "get_num_updates", "(", ")", "+", "self", ".", "args", ".", "empty_cache_freq", "-", "1", ")", "\n", "%", "self", ".", "args", ".", "empty_cache_freq", "\n", ")", "\n", "==", "0", "\n", "and", "torch", ".", "cuda", ".", "is_available", "(", ")", "\n", "and", "not", "self", ".", "args", ".", "cpu", "\n", ")", ":", "\n", "                ", "torch", ".", "cuda", ".", "empty_cache", "(", ")", "\n", "", "", "except", "OverflowError", "as", "e", ":", "\n", "            ", "print", "(", "\"| WARNING: overflow detected, \"", "+", "str", "(", "e", ")", ")", "\n", "self", ".", "zero_grad", "(", ")", "\n", "logging_output", "=", "None", "\n", "", "except", "RuntimeError", "as", "e", ":", "\n", "            ", "if", "\"out of memory\"", "in", "str", "(", "e", ")", ":", "\n", "                ", "self", ".", "_log_oom", "(", "e", ")", "\n", "print", "(", "\"| ERROR: OOM during optimization, irrecoverable\"", ")", "\n", "", "raise", "e", "\n", "\n", "", "if", "self", ".", "args", ".", "fp16", ":", "\n", "            ", "self", ".", "meters", "[", "\"loss_scale\"", "]", ".", "reset", "(", ")", "\n", "self", ".", "meters", "[", "\"loss_scale\"", "]", ".", "update", "(", "self", ".", "optimizer", ".", "scaler", ".", "loss_scale", ")", "\n", "\n", "", "self", ".", "clear_buffered_stats", "(", ")", "\n", "self", ".", "meters", "[", "\"train_wall\"", "]", ".", "stop", "(", ")", "\n", "\n", "return", "logging_output", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.trainer.Trainer.valid_step": [[498, 562], ["trainer.Trainer.task.aggregate_logging_outputs", "trainer.Trainer.task.grad_denom", "list.get", "trainer.Trainer.meters[].update", "torch.no_grad", "trainer.Trainer.model.eval", "trainer.Trainer.criterion.eval", "trainer.Trainer._prepare_sample", "zip", "list", "list", "trainer.Trainer.get_criterion", "trainer.Trainer.get_criterion", "list.get", "trainer.Trainer.meters[].update", "trainer.Trainer.meters[].update", "trainer.Trainer._prepare_sample", "trainer.Trainer.task.valid_step", "list.get", "list.get", "fairseq.distributed_utils.all_gather_list", "str", "trainer.Trainer._log_oom", "print", "trainer.Trainer.model.parameters", "trainer.Trainer.valid_step", "torch.cuda.empty_cache"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.criterions.label_smoothed_cross_entropy.LabelSmoothedCrossEntropyCriterion.aggregate_logging_outputs", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.criterions.fairseq_criterion.FairseqCriterion.grad_denom", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.meters.TimeMeter.update", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.utils.eval", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.utils.eval", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.trainer.Trainer._prepare_sample", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.trainer.Trainer.get_criterion", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.trainer.Trainer.get_criterion", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.meters.TimeMeter.update", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.meters.TimeMeter.update", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.trainer.Trainer._prepare_sample", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.tasks.fairseq_task.FairseqTask.valid_step", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.distributed_utils.all_gather_list", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.trainer.Trainer._log_oom", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.progress_bar.tensorboard_log_wrapper.print", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.tasks.fairseq_task.FairseqTask.valid_step"], ["", "def", "valid_step", "(", "self", ",", "sample", ",", "raise_oom", "=", "False", ")", ":", "\n", "        ", "\"\"\"Do forward pass in evaluation mode.\"\"\"", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "self", ".", "model", ".", "eval", "(", ")", "\n", "self", ".", "criterion", ".", "eval", "(", ")", "\n", "\n", "sample", "=", "self", ".", "_prepare_sample", "(", "sample", ")", "\n", "if", "sample", "is", "None", ":", "\n", "                ", "sample", "=", "self", ".", "_prepare_sample", "(", "self", ".", "_dummy_batch", ")", "\n", "ignore_results", "=", "True", "\n", "", "else", ":", "\n", "                ", "ignore_results", "=", "False", "\n", "\n", "", "try", ":", "\n", "                ", "_loss", ",", "sample_size", ",", "logging_output", "=", "self", ".", "task", ".", "valid_step", "(", "\n", "sample", ",", "self", ".", "model", ",", "self", ".", "criterion", "\n", ")", "\n", "", "except", "RuntimeError", "as", "e", ":", "\n", "                ", "if", "\"out of memory\"", "in", "str", "(", "e", ")", ":", "\n", "                    ", "self", ".", "_log_oom", "(", "e", ")", "\n", "if", "not", "raise_oom", ":", "\n", "                        ", "print", "(", "\n", "\"| WARNING: ran out of memory in validation step, retrying batch\"", "\n", ")", "\n", "for", "p", "in", "self", ".", "model", ".", "parameters", "(", ")", ":", "\n", "                            ", "if", "p", ".", "grad", "is", "not", "None", ":", "\n", "                                ", "p", ".", "grad", "=", "None", "# free some memory", "\n", "", "", "if", "self", ".", "cuda", ":", "\n", "                            ", "torch", ".", "cuda", ".", "empty_cache", "(", ")", "\n", "", "return", "self", ".", "valid_step", "(", "sample", ",", "raise_oom", "=", "True", ")", "\n", "", "", "raise", "e", "\n", "\n", "", "if", "ignore_results", ":", "\n", "                ", "logging_output", ",", "sample_size", "=", "{", "}", ",", "0", "\n", "\n", "# gather logging outputs from all replicas", "\n", "", "", "if", "self", ".", "args", ".", "distributed_world_size", ">", "1", ":", "\n", "            ", "logging_output", ",", "sample_size", "=", "zip", "(", "\n", "*", "distributed_utils", ".", "all_gather_list", "(", "[", "logging_output", ",", "sample_size", "]", ")", "\n", ")", "\n", "logging_output", "=", "list", "(", "logging_output", ")", "\n", "sample_size", "=", "list", "(", "sample_size", ")", "\n", "", "else", ":", "\n", "            ", "logging_output", "=", "[", "logging_output", "]", "\n", "sample_size", "=", "[", "sample_size", "]", "\n", "\n", "# aggregate logging outputs and sample sizes", "\n", "", "logging_output", "=", "self", ".", "task", ".", "aggregate_logging_outputs", "(", "\n", "logging_output", ",", "self", ".", "get_criterion", "(", ")", "\n", ")", "\n", "sample_size", "=", "self", ".", "task", ".", "grad_denom", "(", "sample_size", ",", "self", ".", "get_criterion", "(", ")", ")", "\n", "\n", "# update meters for validation", "\n", "ntokens", "=", "logging_output", ".", "get", "(", "\"ntokens\"", ",", "0", ")", "\n", "self", ".", "meters", "[", "\"valid_loss\"", "]", ".", "update", "(", "logging_output", ".", "get", "(", "\"loss\"", ",", "0", ")", ",", "sample_size", ")", "\n", "if", "\"valid_acc\"", "in", "self", ".", "meters", ":", "\n", "            ", "self", ".", "meters", "[", "\"valid_acc\"", "]", ".", "update", "(", "logging_output", ".", "get", "(", "\"acc\"", ",", "0", ")", ",", "sample_size", ")", "\n", "\n", "", "if", "\"nll_loss\"", "in", "logging_output", ":", "\n", "            ", "self", ".", "meters", "[", "\"valid_nll_loss\"", "]", ".", "update", "(", "\n", "logging_output", ".", "get", "(", "\"nll_loss\"", ",", "0", ")", ",", "ntokens", "\n", ")", "\n", "\n", "", "return", "logging_output", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.trainer.Trainer.dummy_train_step": [[563, 567], ["trainer.Trainer.train_step", "trainer.Trainer.zero_grad"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.tasks.fairseq_task.FairseqTask.train_step", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.optim.fp16_optimizer._MemoryEfficientFP16OptimizerMixin.zero_grad"], ["", "def", "dummy_train_step", "(", "self", ",", "dummy_batch", ")", ":", "\n", "        ", "\"\"\"Dummy training step for warming caching allocator.\"\"\"", "\n", "self", ".", "train_step", "(", "dummy_batch", ",", "dummy_batch", "=", "True", ")", "\n", "self", ".", "zero_grad", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.trainer.Trainer.handle_ooms": [[568, 576], ["range", "trainer.Trainer.train_step"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.tasks.fairseq_task.FairseqTask.train_step"], ["", "def", "handle_ooms", "(", "self", ",", "number_of_ooms", ")", ":", "\n", "        ", "\"\"\"\n        c10d accumulates/syncs gradients between gpus during backward pass.\n        In case of OOMs, gpus may fail to sync, so we manually iterate\n        extra to make sure each gpu makes same number of iterations.\n        \"\"\"", "\n", "for", "_", "in", "range", "(", "number_of_ooms", ")", ":", "\n", "            ", "self", ".", "train_step", "(", "[", "self", ".", "_oom_batch", "]", ",", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.trainer.Trainer.zero_grad": [[577, 579], ["trainer.Trainer.optimizer.zero_grad"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.optim.fp16_optimizer._MemoryEfficientFP16OptimizerMixin.zero_grad"], ["", "", "def", "zero_grad", "(", "self", ")", ":", "\n", "        ", "self", ".", "optimizer", ".", "zero_grad", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.trainer.Trainer.clear_buffered_stats": [[580, 582], ["None"], "methods", ["None"], ["", "def", "clear_buffered_stats", "(", "self", ")", ":", "\n", "        ", "self", ".", "_all_reduce_list", "=", "[", "0.0", "]", "*", "6", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.trainer.Trainer.lr_step": [[583, 588], ["trainer.Trainer.lr_scheduler.step", "trainer.Trainer.lr_step_update"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.lr_scheduler.polynomial_decay_schedule.PolynomialDecaySchedule.step", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.trainer.Trainer.lr_step_update"], ["", "def", "lr_step", "(", "self", ",", "epoch", ",", "val_loss", "=", "None", ")", ":", "\n", "        ", "\"\"\"Adjust the learning rate based on the validation loss.\"\"\"", "\n", "self", ".", "lr_scheduler", ".", "step", "(", "epoch", ",", "val_loss", ")", "\n", "# prefer updating the LR based on the number of steps", "\n", "return", "self", ".", "lr_step_update", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.trainer.Trainer.lr_step_update": [[589, 592], ["trainer.Trainer.lr_scheduler.step_update", "trainer.Trainer.get_num_updates"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.lr_scheduler.polynomial_decay_schedule.PolynomialDecaySchedule.step_update", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.optim.bmuf.FairseqBMUF.get_num_updates"], ["", "def", "lr_step_update", "(", "self", ")", ":", "\n", "        ", "\"\"\"Update the learning rate after each update.\"\"\"", "\n", "return", "self", ".", "lr_scheduler", ".", "step_update", "(", "self", ".", "get_num_updates", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.trainer.Trainer.get_lr": [[593, 596], ["trainer.Trainer.optimizer.get_lr"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.optim.fp16_optimizer.MemoryEfficientFP16Optimizer.get_lr"], ["", "def", "get_lr", "(", "self", ")", ":", "\n", "        ", "\"\"\"Get the current learning rate.\"\"\"", "\n", "return", "self", ".", "optimizer", ".", "get_lr", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.trainer.Trainer.get_model": [[597, 600], ["None"], "methods", ["None"], ["", "def", "get_model", "(", "self", ")", ":", "\n", "        ", "\"\"\"Get the (non-wrapped) model instance.\"\"\"", "\n", "return", "self", ".", "_model", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.trainer.Trainer.get_criterion": [[601, 604], ["None"], "methods", ["None"], ["", "def", "get_criterion", "(", "self", ")", ":", "\n", "        ", "\"\"\"Get the (non-wrapped) criterion instance.\"\"\"", "\n", "return", "self", ".", "_criterion", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.trainer.Trainer.get_meter": [[605, 610], ["None"], "methods", ["None"], ["", "def", "get_meter", "(", "self", ",", "name", ")", ":", "\n", "        ", "\"\"\"Get a specific meter by name.\"\"\"", "\n", "if", "name", "not", "in", "self", ".", "meters", ":", "\n", "            ", "return", "None", "\n", "", "return", "self", ".", "meters", "[", "name", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.trainer.Trainer.get_num_updates": [[611, 614], ["None"], "methods", ["None"], ["", "def", "get_num_updates", "(", "self", ")", ":", "\n", "        ", "\"\"\"Get the number of parameters updates.\"\"\"", "\n", "return", "self", ".", "_num_updates", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.trainer.Trainer.set_num_updates": [[615, 619], ["trainer.Trainer.lr_step_update"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.trainer.Trainer.lr_step_update"], ["", "def", "set_num_updates", "(", "self", ",", "num_updates", ")", ":", "\n", "        ", "\"\"\"Set the number of parameters updates.\"\"\"", "\n", "self", ".", "_num_updates", "=", "num_updates", "\n", "self", ".", "lr_step_update", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.trainer.Trainer._prepare_sample": [[620, 636], ["fairseq.utils.move_to_cuda", "fairseq.utils.apply_to_sample", "len", "t.half"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.utils.move_to_cuda", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.utils.apply_to_sample"], ["", "def", "_prepare_sample", "(", "self", ",", "sample", ")", ":", "\n", "        ", "if", "sample", "is", "None", "or", "len", "(", "sample", ")", "==", "0", ":", "\n", "            ", "return", "None", "\n", "\n", "", "if", "self", ".", "cuda", ":", "\n", "            ", "sample", "=", "utils", ".", "move_to_cuda", "(", "sample", ")", "\n", "\n", "", "def", "apply_half", "(", "t", ")", ":", "\n", "            ", "if", "t", ".", "dtype", "is", "torch", ".", "float32", ":", "\n", "                ", "return", "t", ".", "half", "(", ")", "\n", "", "return", "t", "\n", "\n", "", "if", "self", ".", "args", ".", "fp16", ":", "\n", "            ", "sample", "=", "utils", ".", "apply_to_sample", "(", "apply_half", ",", "sample", ")", "\n", "\n", "", "return", "sample", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.trainer.Trainer._set_seed": [[637, 644], ["torch.manual_seed", "trainer.Trainer.get_num_updates", "torch.cuda.manual_seed"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.optim.bmuf.FairseqBMUF.get_num_updates"], ["", "def", "_set_seed", "(", "self", ")", ":", "\n", "# Set seed based on args.seed and the update number so that we get", "\n", "# reproducible results when resuming from checkpoints", "\n", "        ", "seed", "=", "self", ".", "args", ".", "seed", "+", "self", ".", "get_num_updates", "(", ")", "\n", "torch", ".", "manual_seed", "(", "seed", ")", "\n", "if", "self", ".", "cuda", ":", "\n", "            ", "torch", ".", "cuda", ".", "manual_seed", "(", "seed", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.trainer.Trainer._sync_stats": [[645, 651], ["trainer.Trainer.get_num_updates"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.optim.bmuf.FairseqBMUF.get_num_updates"], ["", "", "def", "_sync_stats", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "args", ".", "distributed_world_size", ">", "1", "and", "(", "\n", "(", "not", "self", ".", "args", ".", "use_bmuf", ")", "\n", "or", "(", "\n", "self", ".", "args", ".", "use_bmuf", "\n", "and", "(", "self", ".", "get_num_updates", "(", ")", "+", "1", ")", "%", "self", ".", "args", ".", "global_sync_iter", "==", "0", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.trainer.Trainer._log_oom": [[654, 665], ["print", "sys.stderr.flush", "torch.cuda.is_available", "hasattr", "range", "torch.cuda.device_count", "print", "torch.cuda.memory_summary"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.progress_bar.tensorboard_log_wrapper.print", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.progress_bar.tensorboard_log_wrapper.print"], ["", "def", "_log_oom", "(", "self", ",", "exc", ")", ":", "\n", "        ", "msg", "=", "\"| OOM: Ran out of memory with exception: {}\"", ".", "format", "(", "exc", ")", "\n", "# TODO: print should really go to logger, this print goes", "\n", "# to stderr, which is buffered, which in many cases is not", "\n", "# printed out if another exception happens.", "\n", "# NB(jerry): added a flush to mitigate this", "\n", "print", "(", "msg", ",", "file", "=", "sys", ".", "stderr", ")", "\n", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "and", "hasattr", "(", "torch", ".", "cuda", ",", "\"memory_summary\"", ")", ":", "\n", "            ", "for", "device_idx", "in", "range", "(", "torch", ".", "cuda", ".", "device_count", "(", ")", ")", ":", "\n", "                ", "print", "(", "torch", ".", "cuda", ".", "memory_summary", "(", "device", "=", "device_idx", ")", ",", "file", "=", "sys", ".", "stderr", ")", "\n", "", "", "sys", ".", "stderr", ".", "flush", "(", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.pdb.MultiprocessingPdb.__init__": [[29, 31], ["pdb.Pdb.__init__"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.dummy_dictionary.DummyDictionary.__init__"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "pdb", ".", "Pdb", ".", "__init__", "(", "self", ",", "nosigint", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.pdb.MultiprocessingPdb._cmdloop": [[32, 43], ["pdb.MultiprocessingPdb.cmdloop", "os.fdopen"], "methods", ["None"], ["", "def", "_cmdloop", "(", "self", ")", ":", "\n", "        ", "stdin_bak", "=", "sys", ".", "stdin", "\n", "with", "_stdin_lock", ":", "\n", "            ", "try", ":", "\n", "                ", "if", "_stdin_fd", "is", "not", "None", ":", "\n", "                    ", "if", "not", "_stdin", "[", "0", "]", ":", "\n", "                        ", "_stdin", "[", "0", "]", "=", "os", ".", "fdopen", "(", "_stdin_fd", ")", "\n", "", "sys", ".", "stdin", "=", "_stdin", "[", "0", "]", "\n", "", "self", ".", "cmdloop", "(", ")", "\n", "", "finally", ":", "\n", "                ", "sys", ".", "stdin", "=", "stdin_bak", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.pdb.set_trace": [[45, 48], ["pdb.MultiprocessingPdb", "MultiprocessingPdb.set_trace", "sys._getframe"], "function", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.pdb.set_trace"], ["", "", "", "", "def", "set_trace", "(", ")", ":", "\n", "    ", "pdb", "=", "MultiprocessingPdb", "(", ")", "\n", "pdb", ".", "set_trace", "(", "sys", ".", "_getframe", "(", ")", ".", "f_back", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.registry.setup_registry": [[12, 63], ["registry_name[].replace.startswith", "registry_name[].replace", "set", "getattr", "hasattr", "registry.set_defaults", "getattr.", "getattr", "set.add", "ValueError", "ValueError", "ValueError", "issubclass"], "function", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.registry.set_defaults"], ["def", "setup_registry", "(", "\n", "registry_name", ":", "str", ",", "\n", "base_class", "=", "None", ",", "\n", "default", "=", "None", ",", "\n", ")", ":", "\n", "    ", "assert", "registry_name", ".", "startswith", "(", "'--'", ")", "\n", "registry_name", "=", "registry_name", "[", "2", ":", "]", ".", "replace", "(", "'-'", ",", "'_'", ")", "\n", "\n", "REGISTRY", "=", "{", "}", "\n", "REGISTRY_CLASS_NAMES", "=", "set", "(", ")", "\n", "\n", "# maintain a registry of all registries", "\n", "if", "registry_name", "in", "REGISTRIES", ":", "\n", "        ", "return", "# registry already exists", "\n", "", "REGISTRIES", "[", "registry_name", "]", "=", "{", "\n", "'registry'", ":", "REGISTRY", ",", "\n", "'default'", ":", "default", ",", "\n", "}", "\n", "\n", "def", "build_x", "(", "args", ",", "*", "extra_args", ",", "**", "extra_kwargs", ")", ":", "\n", "        ", "choice", "=", "getattr", "(", "args", ",", "registry_name", ",", "None", ")", "\n", "if", "choice", "is", "None", ":", "\n", "            ", "return", "None", "\n", "", "cls", "=", "REGISTRY", "[", "choice", "]", "\n", "if", "hasattr", "(", "cls", ",", "'build_'", "+", "registry_name", ")", ":", "\n", "            ", "builder", "=", "getattr", "(", "cls", ",", "'build_'", "+", "registry_name", ")", "\n", "", "else", ":", "\n", "            ", "builder", "=", "cls", "\n", "", "set_defaults", "(", "args", ",", "cls", ")", "\n", "return", "builder", "(", "args", ",", "*", "extra_args", ",", "**", "extra_kwargs", ")", "\n", "\n", "", "def", "register_x", "(", "name", ")", ":", "\n", "\n", "        ", "def", "register_x_cls", "(", "cls", ")", ":", "\n", "            ", "if", "name", "in", "REGISTRY", ":", "\n", "                ", "raise", "ValueError", "(", "'Cannot register duplicate {} ({})'", ".", "format", "(", "registry_name", ",", "name", ")", ")", "\n", "", "if", "cls", ".", "__name__", "in", "REGISTRY_CLASS_NAMES", ":", "\n", "                ", "raise", "ValueError", "(", "\n", "'Cannot register {} with duplicate class name ({})'", ".", "format", "(", "\n", "registry_name", ",", "cls", ".", "__name__", ",", "\n", ")", "\n", ")", "\n", "", "if", "base_class", "is", "not", "None", "and", "not", "issubclass", "(", "cls", ",", "base_class", ")", ":", "\n", "                ", "raise", "ValueError", "(", "'{} must extend {}'", ".", "format", "(", "cls", ".", "__name__", ",", "base_class", ".", "__name__", ")", ")", "\n", "", "REGISTRY", "[", "name", "]", "=", "cls", "\n", "REGISTRY_CLASS_NAMES", ".", "add", "(", "cls", ".", "__name__", ")", "\n", "return", "cls", "\n", "\n", "", "return", "register_x_cls", "\n", "\n", "", "return", "build_x", ",", "register_x", ",", "REGISTRY", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.registry.set_defaults": [[65, 81], ["argparse.ArgumentParser", "cls.add_args", "argparse.Namespace", "vars().items", "hasattr", "vars", "hasattr", "setattr", "hasattr", "setattr"], "function", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.criterions.label_smoothed_cross_entropy.LabelSmoothedCrossEntropyCriterion.add_args"], ["", "def", "set_defaults", "(", "args", ",", "cls", ")", ":", "\n", "    ", "\"\"\"Helper to set default arguments based on *add_args*.\"\"\"", "\n", "if", "not", "hasattr", "(", "cls", ",", "'add_args'", ")", ":", "\n", "        ", "return", "\n", "", "parser", "=", "argparse", ".", "ArgumentParser", "(", "argument_default", "=", "argparse", ".", "SUPPRESS", ",", "allow_abbrev", "=", "False", ")", "\n", "cls", ".", "add_args", "(", "parser", ")", "\n", "# copied from argparse.py:", "\n", "defaults", "=", "argparse", ".", "Namespace", "(", ")", "\n", "for", "action", "in", "parser", ".", "_actions", ":", "\n", "        ", "if", "action", ".", "dest", "is", "not", "argparse", ".", "SUPPRESS", ":", "\n", "            ", "if", "not", "hasattr", "(", "defaults", ",", "action", ".", "dest", ")", ":", "\n", "                ", "if", "action", ".", "default", "is", "not", "argparse", ".", "SUPPRESS", ":", "\n", "                    ", "setattr", "(", "defaults", ",", "action", ".", "dest", ",", "action", ".", "default", ")", "\n", "", "", "", "", "for", "key", ",", "default_value", "in", "vars", "(", "defaults", ")", ".", "items", "(", ")", ":", "\n", "        ", "if", "not", "hasattr", "(", "args", ",", "key", ")", ":", "\n", "            ", "setattr", "(", "args", ",", "key", ",", "default_value", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.meters.AverageMeter.__init__": [[11, 13], ["meters.AverageMeter.reset"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.meters.StopwatchMeter.reset"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "self", ".", "reset", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.meters.AverageMeter.reset": [[14, 19], ["None"], "methods", ["None"], ["", "def", "reset", "(", "self", ")", ":", "\n", "        ", "self", ".", "val", "=", "0", "\n", "self", ".", "avg", "=", "0", "\n", "self", ".", "sum", "=", "0", "\n", "self", ".", "count", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.meters.AverageMeter.update": [[20, 25], ["None"], "methods", ["None"], ["", "def", "update", "(", "self", ",", "val", ",", "n", "=", "1", ")", ":", "\n", "        ", "self", ".", "val", "=", "val", "\n", "self", ".", "sum", "+=", "val", "*", "n", "\n", "self", ".", "count", "+=", "n", "\n", "self", ".", "avg", "=", "self", ".", "sum", "/", "self", ".", "count", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.meters.TimeMeter.__init__": [[29, 31], ["meters.TimeMeter.reset"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.meters.StopwatchMeter.reset"], ["def", "__init__", "(", "self", ",", "init", "=", "0", ")", ":", "\n", "        ", "self", ".", "reset", "(", "init", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.meters.TimeMeter.reset": [[32, 36], ["time.time"], "methods", ["None"], ["", "def", "reset", "(", "self", ",", "init", "=", "0", ")", ":", "\n", "        ", "self", ".", "init", "=", "init", "\n", "self", ".", "start", "=", "time", ".", "time", "(", ")", "\n", "self", ".", "n", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.meters.TimeMeter.update": [[37, 39], ["None"], "methods", ["None"], ["", "def", "update", "(", "self", ",", "val", "=", "1", ")", ":", "\n", "        ", "self", ".", "n", "+=", "val", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.meters.TimeMeter.avg": [[40, 43], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "avg", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "n", "/", "self", ".", "elapsed_time", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.meters.TimeMeter.elapsed_time": [[44, 47], ["time.time"], "methods", ["None"], ["", "@", "property", "\n", "def", "elapsed_time", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "init", "+", "(", "time", ".", "time", "(", ")", "-", "self", ".", "start", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.meters.StopwatchMeter.__init__": [[51, 53], ["meters.StopwatchMeter.reset"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.meters.StopwatchMeter.reset"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "self", ".", "reset", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.meters.StopwatchMeter.start": [[54, 56], ["time.time"], "methods", ["None"], ["", "def", "start", "(", "self", ")", ":", "\n", "        ", "self", ".", "start_time", "=", "time", ".", "time", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.meters.StopwatchMeter.stop": [[57, 63], ["time.time"], "methods", ["None"], ["", "def", "stop", "(", "self", ",", "n", "=", "1", ")", ":", "\n", "        ", "if", "self", ".", "start_time", "is", "not", "None", ":", "\n", "            ", "delta", "=", "time", ".", "time", "(", ")", "-", "self", ".", "start_time", "\n", "self", ".", "sum", "+=", "delta", "\n", "self", ".", "n", "+=", "n", "\n", "self", ".", "start_time", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.meters.StopwatchMeter.reset": [[64, 68], ["None"], "methods", ["None"], ["", "", "def", "reset", "(", "self", ")", ":", "\n", "        ", "self", ".", "sum", "=", "0", "\n", "self", ".", "n", "=", "0", "\n", "self", ".", "start_time", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.meters.StopwatchMeter.avg": [[69, 72], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "avg", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "sum", "/", "self", ".", "n", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.search.Search.__init__": [[13, 19], ["tgt_dict.pad", "len"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.dummy_dictionary.DummyDictionary.pad"], ["    ", "def", "__init__", "(", "self", ",", "tgt_dict", ")", ":", "\n", "        ", "self", ".", "pad", "=", "tgt_dict", ".", "pad", "(", ")", "\n", "self", ".", "vocab_size", "=", "len", "(", "tgt_dict", ")", "\n", "self", ".", "scores_buf", "=", "None", "\n", "self", ".", "indices_buf", "=", "None", "\n", "self", ".", "beams_buf", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.search.Search._init_buffers": [[20, 25], ["t.new", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor", "torch.LongTensor"], "methods", ["None"], ["", "def", "_init_buffers", "(", "self", ",", "t", ")", ":", "\n", "        ", "if", "self", ".", "scores_buf", "is", "None", ":", "\n", "            ", "self", ".", "scores_buf", "=", "t", ".", "new", "(", ")", "\n", "self", ".", "indices_buf", "=", "torch", ".", "LongTensor", "(", ")", ".", "to", "(", "device", "=", "t", ".", "device", ")", "\n", "self", ".", "beams_buf", "=", "torch", ".", "LongTensor", "(", ")", ".", "to", "(", "device", "=", "t", ".", "device", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.search.Search.step": [[26, 47], ["None"], "methods", ["None"], ["", "", "def", "step", "(", "self", ",", "step", ",", "lprobs", ",", "scores", ")", ":", "\n", "        ", "\"\"\"Take a single search step.\n\n        Args:\n            step: the current search step, starting at 0\n            lprobs: (bsz x input_beam_size x vocab_size)\n                the model's log-probabilities over the vocabulary at the current step\n            scores: (bsz x input_beam_size x step)\n                the historical model scores of each hypothesis up to this point\n\n        Return: A tuple of (scores, indices, beams) where:\n            scores: (bsz x output_beam_size)\n                the scores of the chosen elements; output_beam_size can be\n                larger than input_beam_size, e.g., we may return\n                2*input_beam_size to account for EOS\n            indices: (bsz x output_beam_size)\n                the indices of the chosen elements\n            beams: (bsz x output_beam_size)\n                the hypothesis ids of the chosen elements, in the range [0, input_beam_size)\n        \"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.search.Search.set_src_lengths": [[48, 50], ["None"], "methods", ["None"], ["", "def", "set_src_lengths", "(", "self", ",", "src_lengths", ")", ":", "\n", "        ", "self", ".", "src_lengths", "=", "src_lengths", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.search.BeamSearch.__init__": [[54, 56], ["search.Search.__init__"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.dummy_dictionary.DummyDictionary.__init__"], ["    ", "def", "__init__", "(", "self", ",", "tgt_dict", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "tgt_dict", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.search.BeamSearch.step": [[57, 82], ["search.Search._init_buffers", "lprobs[].contiguous.size", "torch.topk", "torch.div", "search.BeamSearch.indices_buf.fmod_", "lprobs[].contiguous", "lprobs[].contiguous.add_", "lprobs[].contiguous.view", "scores[].unsqueeze", "min", "lprobs[].contiguous.view().size", "lprobs[].contiguous.view"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.search.Search._init_buffers", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.fairseq_dataset.FairseqDataset.size", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.fairseq_dataset.FairseqDataset.size"], ["", "def", "step", "(", "self", ",", "step", ",", "lprobs", ",", "scores", ")", ":", "\n", "        ", "super", "(", ")", ".", "_init_buffers", "(", "lprobs", ")", "\n", "bsz", ",", "beam_size", ",", "vocab_size", "=", "lprobs", ".", "size", "(", ")", "\n", "\n", "if", "step", "==", "0", ":", "\n", "# at the first step all hypotheses are equally likely, so use", "\n", "# only the first beam", "\n", "            ", "lprobs", "=", "lprobs", "[", ":", ",", ":", ":", "beam_size", ",", ":", "]", ".", "contiguous", "(", ")", "\n", "", "else", ":", "\n", "# make probs contain cumulative scores for each hypothesis", "\n", "            ", "lprobs", ".", "add_", "(", "scores", "[", ":", ",", ":", ",", "step", "-", "1", "]", ".", "unsqueeze", "(", "-", "1", ")", ")", "\n", "\n", "", "torch", ".", "topk", "(", "\n", "lprobs", ".", "view", "(", "bsz", ",", "-", "1", ")", ",", "\n", "k", "=", "min", "(", "\n", "# Take the best 2 x beam_size predictions. We'll choose the first", "\n", "# beam_size of these which don't predict eos to continue with.", "\n", "beam_size", "*", "2", ",", "\n", "lprobs", ".", "view", "(", "bsz", ",", "-", "1", ")", ".", "size", "(", "1", ")", "-", "1", ",", "# -1 so we never select pad", "\n", ")", ",", "\n", "out", "=", "(", "self", ".", "scores_buf", ",", "self", ".", "indices_buf", ")", ",", "\n", ")", "\n", "torch", ".", "div", "(", "self", ".", "indices_buf", ",", "vocab_size", ",", "out", "=", "self", ".", "beams_buf", ")", "\n", "self", ".", "indices_buf", ".", "fmod_", "(", "vocab_size", ")", "\n", "return", "self", ".", "scores_buf", ",", "self", ".", "indices_buf", ",", "self", ".", "beams_buf", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.search.DiverseBeamSearch.__init__": [[94, 100], ["search.Search.__init__", "search.BeamSearch"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.dummy_dictionary.DummyDictionary.__init__"], ["def", "__init__", "(", "self", ",", "tgt_dict", ",", "num_groups", ",", "diversity_strength", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "tgt_dict", ")", "\n", "self", ".", "num_groups", "=", "num_groups", "\n", "self", ".", "diversity_strength", "=", "-", "diversity_strength", "\n", "self", ".", "diversity_buf", "=", "None", "\n", "self", ".", "beam", "=", "BeamSearch", "(", "tgt_dict", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.search.DiverseBeamSearch.step": [[101, 144], ["search.Search._init_buffers", "lprobs.size", "torch.zeros", "range", "torch.stack().view", "torch.stack().view", "torch.stack().view", "ValueError", "lprobs.new", "lprobs[].size", "search.DiverseBeamSearch.beam.step", "beams_buf.mul_().add_", "scores_G.append", "indices_G.append", "beams_G.append", "search.DiverseBeamSearch.diversity_buf.scatter_add_", "torch.add", "lprobs_g.contiguous.contiguous.contiguous", "scores_buf.clone", "indices_buf.clone", "beams_buf.clone", "search.DiverseBeamSearch.diversity_buf.new_ones", "torch.stack", "torch.stack", "torch.stack", "search.DiverseBeamSearch.diversity_buf.unsqueeze", "beams_buf.mul_", "indices_buf.size"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.search.Search._init_buffers", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.fairseq_dataset.FairseqDataset.size", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.fairseq_dataset.FairseqDataset.size", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.lr_scheduler.polynomial_decay_schedule.PolynomialDecaySchedule.step", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.fairseq_dataset.FairseqDataset.size"], ["", "def", "step", "(", "self", ",", "step", ",", "lprobs", ",", "scores", ")", ":", "\n", "        ", "super", "(", ")", ".", "_init_buffers", "(", "lprobs", ")", "\n", "bsz", ",", "beam_size", ",", "vocab_size", "=", "lprobs", ".", "size", "(", ")", "\n", "if", "beam_size", "%", "self", ".", "num_groups", "!=", "0", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "'DiverseBeamSearch requires --beam to be divisible by the number of groups'", "\n", ")", "\n", "\n", "# initialize diversity penalty", "\n", "", "if", "self", ".", "diversity_buf", "is", "None", ":", "\n", "            ", "self", ".", "diversity_buf", "=", "lprobs", ".", "new", "(", ")", "\n", "", "torch", ".", "zeros", "(", "lprobs", "[", ":", ",", "0", ",", ":", "]", ".", "size", "(", ")", ",", "out", "=", "self", ".", "diversity_buf", ")", "\n", "\n", "scores_G", ",", "indices_G", ",", "beams_G", "=", "[", "]", ",", "[", "]", ",", "[", "]", "\n", "for", "g", "in", "range", "(", "self", ".", "num_groups", ")", ":", "\n", "            ", "lprobs_g", "=", "lprobs", "[", ":", ",", "g", ":", ":", "self", ".", "num_groups", ",", ":", "]", "\n", "scores_g", "=", "scores", "[", ":", ",", "g", ":", ":", "self", ".", "num_groups", ",", ":", "]", "if", "step", ">", "0", "else", "None", "\n", "\n", "# apply diversity penalty", "\n", "if", "g", ">", "0", ":", "\n", "                ", "lprobs_g", "=", "torch", ".", "add", "(", "lprobs_g", ",", "self", ".", "diversity_strength", ",", "self", ".", "diversity_buf", ".", "unsqueeze", "(", "1", ")", ")", "\n", "", "else", ":", "\n", "                ", "lprobs_g", "=", "lprobs_g", ".", "contiguous", "(", ")", "\n", "\n", "", "scores_buf", ",", "indices_buf", ",", "beams_buf", "=", "self", ".", "beam", ".", "step", "(", "step", ",", "lprobs_g", ",", "scores_g", ")", "\n", "beams_buf", ".", "mul_", "(", "self", ".", "num_groups", ")", ".", "add_", "(", "g", ")", "\n", "\n", "scores_G", ".", "append", "(", "scores_buf", ".", "clone", "(", ")", ")", "\n", "indices_G", ".", "append", "(", "indices_buf", ".", "clone", "(", ")", ")", "\n", "beams_G", ".", "append", "(", "beams_buf", ".", "clone", "(", ")", ")", "\n", "\n", "# update diversity penalty", "\n", "self", ".", "diversity_buf", ".", "scatter_add_", "(", "\n", "1", ",", "\n", "indices_buf", ",", "\n", "self", ".", "diversity_buf", ".", "new_ones", "(", "indices_buf", ".", "size", "(", ")", ")", "\n", ")", "\n", "\n", "# interleave results from different groups", "\n", "", "self", ".", "scores_buf", "=", "torch", ".", "stack", "(", "scores_G", ",", "dim", "=", "2", ",", "out", "=", "self", ".", "scores_buf", ")", ".", "view", "(", "bsz", ",", "-", "1", ")", "\n", "self", ".", "indices_buf", "=", "torch", ".", "stack", "(", "indices_G", ",", "dim", "=", "2", ",", "out", "=", "self", ".", "indices_buf", ")", ".", "view", "(", "bsz", ",", "-", "1", ")", "\n", "self", ".", "beams_buf", "=", "torch", ".", "stack", "(", "beams_G", ",", "dim", "=", "2", ",", "out", "=", "self", ".", "beams_buf", ")", ".", "view", "(", "bsz", ",", "-", "1", ")", "\n", "return", "self", ".", "scores_buf", ",", "self", ".", "indices_buf", ",", "self", ".", "beams_buf", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.search.Sampling.__init__": [[148, 152], ["search.Search.__init__"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.dummy_dictionary.DummyDictionary.__init__"], ["    ", "def", "__init__", "(", "self", ",", "tgt_dict", ",", "sampling_topk", "=", "-", "1", ",", "sampling_topp", "=", "-", "1.0", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "tgt_dict", ")", "\n", "self", ".", "sampling_topk", "=", "sampling_topk", "\n", "self", ".", "sampling_topp", "=", "sampling_topp", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.search.Sampling._sample_topp": [[153, 197], ["lprobs.exp_", "lprobs.exp_.sort", "sorted_probs.cumsum", "sorted_probs.cumsum.lt", "mask.scatter_.scatter_.cumsum", "last_included.clamp_", "mask.scatter_.scatter_.scatter_", "last_included.max", "truncated_probs.masked_fill_", "mask.scatter_.scatter_.size"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.fairseq_dataset.FairseqDataset.size"], ["", "def", "_sample_topp", "(", "self", ",", "lprobs", ")", ":", "\n", "        ", "\"\"\"Sample among the smallest set of elements whose cumulative probability mass exceeds p.\n\n        See `\"The Curious Case of Neural Text Degeneration\"\n        (Holtzman et al., 2019) <https://arxiv.org/abs/1904.09751>`_.\n\n        Args:\n            lprobs: (bsz x input_beam_size x vocab_size)\n                the model's log-probabilities over the vocabulary at the current step\n\n        Return: A tuple of (trimed_probs, truncated_indices) where:\n            trimed_probs: (bsz x input_beam_size x ?)\n                the model's probabilities over the elements selected to sample from. The\n                width of the third dimension is determined by top-P.\n            truncated_indices: (bsz x input_beam_size x ?)\n                the indices of the chosen elements.\n        \"\"\"", "\n", "probs", "=", "lprobs", ".", "exp_", "(", ")", "\n", "\n", "# sort the last dimension (vocab dimension) in descending order", "\n", "sorted_probs", ",", "sorted_indices", "=", "probs", ".", "sort", "(", "descending", "=", "True", ")", "\n", "\n", "# compute a mask to indicate the words to be included in the top-P set.", "\n", "cumsum_probs", "=", "sorted_probs", ".", "cumsum", "(", "dim", "=", "2", ")", "\n", "mask", "=", "cumsum_probs", ".", "lt", "(", "self", ".", "sampling_topp", ")", "\n", "\n", "# note that mask was computed by 'lt'. One more word needs to be included", "\n", "# so that the cumulative probability mass can exceed p.", "\n", "cumsum_mask", "=", "mask", ".", "cumsum", "(", "dim", "=", "2", ")", "\n", "last_included", "=", "cumsum_mask", "[", ":", ",", ":", ",", "-", "1", ":", "]", "\n", "last_included", ".", "clamp_", "(", "0", ",", "mask", ".", "size", "(", ")", "[", "2", "]", "-", "1", ")", "\n", "mask", "=", "mask", ".", "scatter_", "(", "2", ",", "last_included", ",", "1", ")", "\n", "\n", "# truncate unnecessary dims.", "\n", "max_dim", "=", "last_included", ".", "max", "(", ")", "\n", "truncated_mask", "=", "mask", "[", ":", ",", ":", ",", ":", "max_dim", "+", "1", "]", "\n", "truncated_probs", "=", "sorted_probs", "[", ":", ",", ":", ",", ":", "max_dim", "+", "1", "]", "\n", "truncated_indices", "=", "sorted_indices", "[", ":", ",", ":", ",", ":", "max_dim", "+", "1", "]", "\n", "\n", "# trim the words that are not in top-P by setting their probabilities", "\n", "# to 0, so that they would not be sampled later.", "\n", "trim_mask", "=", "(", "~", "truncated_mask", ")", "\n", "trimed_probs", "=", "truncated_probs", ".", "masked_fill_", "(", "trim_mask", ",", "0", ")", "\n", "return", "trimed_probs", ",", "truncated_indices", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.search.Sampling.step": [[198, 272], ["search.Search._init_buffers", "lprobs[].contiguous.size", "torch.gather", "search.Sampling.scores_buf.log_().view", "lprobs[].contiguous", "search.Sampling._sample_topp", "torch.multinomial().view", "torch.multinomial().view", "lprobs_nopad.exp_.expand", "torch.gather().squeeze", "search.Sampling.indices_buf.new_zeros", "torch.arange().repeat", "search.Sampling.scores_buf.add_", "lprobs_nopad.topk", "lprobs_nopad.exp_", "lprobs_nopad.exp_", "search.Sampling.indices_buf.unsqueeze", "search.Sampling.scores_buf.log_", "torch.gather", "torch.multinomial", "torch.multinomial", "torch.gather", "torch.arange", "lprobs_nopad.exp_.view", "lprobs_nopad.exp_.view", "top_indices.expand", "search.Sampling.indices_buf.unsqueeze"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.search.Search._init_buffers", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.fairseq_dataset.FairseqDataset.size", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.search.Sampling._sample_topp"], ["", "def", "step", "(", "self", ",", "step", ",", "lprobs", ",", "scores", ")", ":", "\n", "        ", "super", "(", ")", ".", "_init_buffers", "(", "lprobs", ")", "\n", "bsz", ",", "beam_size", ",", "vocab_size", "=", "lprobs", ".", "size", "(", ")", "\n", "\n", "if", "step", "==", "0", ":", "\n", "# at the first step all hypotheses are equally likely, so use", "\n", "# only the first beam", "\n", "            ", "lprobs", "=", "lprobs", "[", ":", ",", ":", ":", "beam_size", ",", ":", "]", ".", "contiguous", "(", ")", "\n", "\n", "# we exclude the last two vocab items, one of which is pad", "\n", "", "assert", "self", ".", "pad", ">=", "self", ".", "vocab_size", "-", "2", ",", "'sampling assumes the last two symbols can be ignored'", "\n", "lprobs_nopad", "=", "lprobs", "[", ":", ",", ":", ",", ":", "-", "2", "]", "\n", "\n", "if", "self", ".", "sampling_topp", ">", "0", ":", "\n", "# only sample from the smallest set of words whose cumulative probability mass exceeds p", "\n", "            ", "probs_nopad", ",", "top_indices", "=", "self", ".", "_sample_topp", "(", "lprobs_nopad", ")", "\n", "", "elif", "self", ".", "sampling_topk", ">", "0", ":", "\n", "# only sample from top-k candidates", "\n", "            ", "lprobs_nopad", ",", "top_indices", "=", "lprobs_nopad", ".", "topk", "(", "self", ".", "sampling_topk", ")", "\n", "probs_nopad", "=", "lprobs_nopad", ".", "exp_", "(", ")", "\n", "", "else", ":", "\n", "            ", "probs_nopad", "=", "lprobs_nopad", ".", "exp_", "(", ")", "\n", "\n", "# sample", "\n", "", "if", "step", "==", "0", ":", "\n", "            ", "self", ".", "indices_buf", "=", "torch", ".", "multinomial", "(", "\n", "probs_nopad", ".", "view", "(", "bsz", ",", "-", "1", ")", ",", "\n", "beam_size", ",", "\n", "replacement", "=", "True", ",", "\n", "out", "=", "self", ".", "indices_buf", ",", "\n", ")", ".", "view", "(", "bsz", ",", "beam_size", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "indices_buf", "=", "torch", ".", "multinomial", "(", "\n", "probs_nopad", ".", "view", "(", "bsz", "*", "beam_size", ",", "-", "1", ")", ",", "\n", "1", ",", "\n", "replacement", "=", "True", ",", "\n", "out", "=", "self", ".", "indices_buf", ",", "\n", ")", ".", "view", "(", "bsz", ",", "beam_size", ")", "\n", "\n", "", "if", "step", "==", "0", ":", "\n", "# expand to beam size", "\n", "            ", "probs_nopad", "=", "probs_nopad", ".", "expand", "(", "bsz", ",", "beam_size", ",", "-", "1", ")", "\n", "\n", "# gather scores", "\n", "", "torch", ".", "gather", "(", "\n", "probs_nopad", ",", "\n", "dim", "=", "2", ",", "\n", "index", "=", "self", ".", "indices_buf", ".", "unsqueeze", "(", "-", "1", ")", ",", "\n", "out", "=", "self", ".", "scores_buf", ",", "\n", ")", "\n", "self", ".", "scores_buf", "=", "self", ".", "scores_buf", ".", "log_", "(", ")", ".", "view", "(", "bsz", ",", "-", "1", ")", "\n", "\n", "# remap indices if using top-k or top-P sampling", "\n", "if", "self", ".", "sampling_topk", ">", "0", "or", "self", ".", "sampling_topp", ">", "0", ":", "\n", "            ", "self", ".", "indices_buf", "=", "torch", ".", "gather", "(", "\n", "top_indices", ".", "expand", "(", "bsz", ",", "beam_size", ",", "-", "1", ")", ",", "\n", "dim", "=", "2", ",", "\n", "index", "=", "self", ".", "indices_buf", ".", "unsqueeze", "(", "-", "1", ")", ",", "\n", ")", ".", "squeeze", "(", "2", ")", "\n", "\n", "", "if", "step", "==", "0", ":", "\n", "            ", "self", ".", "beams_buf", "=", "self", ".", "indices_buf", ".", "new_zeros", "(", "bsz", ",", "beam_size", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "beams_buf", "=", "torch", ".", "arange", "(", "0", ",", "beam_size", ",", "out", "=", "self", ".", "beams_buf", ")", ".", "repeat", "(", "bsz", ",", "1", ")", "\n", "# make scores cumulative", "\n", "self", ".", "scores_buf", ".", "add_", "(", "\n", "torch", ".", "gather", "(", "\n", "scores", "[", ":", ",", ":", ",", "step", "-", "1", "]", ",", "\n", "dim", "=", "1", ",", "\n", "index", "=", "self", ".", "beams_buf", ",", "\n", ")", "\n", ")", "\n", "\n", "", "return", "self", ".", "scores_buf", ",", "self", ".", "indices_buf", ",", "self", ".", "beams_buf", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.checkpoint_utils.save_checkpoint": [[20, 97], ["getattr", "meters.StopwatchMeter", "meters.StopwatchMeter.start", "epoch_itr.end_of_epoch", "trainer.get_num_updates", "collections.OrderedDict", "hasattr", "best_function", "epoch_itr.state_dict", "extra_state.update", "os.path.join", "len", "trainer.save_checkpoint", "meters.StopwatchMeter.stop", "print", "checkpoint_utils.checkpoint_paths", "checkpoint_utils.checkpoint_paths", "distributed_utils.is_master", "checkpoint_utils.save_checkpoint.is_better"], "function", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.meters.StopwatchMeter.start", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.iterators.EpochBatchIterator.end_of_epoch", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.optim.bmuf.FairseqBMUF.get_num_updates", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.iterators.EpochBatchIterator.state_dict", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.meters.TimeMeter.update", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.checkpoint_utils.save_checkpoint", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.meters.StopwatchMeter.stop", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.progress_bar.tensorboard_log_wrapper.print", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.checkpoint_utils.checkpoint_paths", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.checkpoint_utils.checkpoint_paths", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.distributed_utils.is_master"], ["def", "save_checkpoint", "(", "args", ",", "trainer", ",", "epoch_itr", ",", "val_loss", ")", ":", "\n", "    ", "from", "fairseq", "import", "distributed_utils", ",", "meters", "\n", "\n", "prev_best", "=", "getattr", "(", "save_checkpoint", ",", "\"best\"", ",", "val_loss", ")", "\n", "if", "val_loss", "is", "not", "None", ":", "\n", "        ", "best_function", "=", "max", "if", "args", ".", "maximize_best_checkpoint_metric", "else", "min", "\n", "save_checkpoint", ".", "best", "=", "best_function", "(", "val_loss", ",", "prev_best", ")", "\n", "\n", "", "if", "args", ".", "no_save", "or", "not", "distributed_utils", ".", "is_master", "(", "args", ")", ":", "\n", "        ", "return", "\n", "\n", "", "def", "is_better", "(", "a", ",", "b", ")", ":", "\n", "        ", "return", "a", ">=", "b", "if", "args", ".", "maximize_best_checkpoint_metric", "else", "a", "<=", "b", "\n", "\n", "", "write_timer", "=", "meters", ".", "StopwatchMeter", "(", ")", "\n", "write_timer", ".", "start", "(", ")", "\n", "\n", "epoch", "=", "epoch_itr", ".", "epoch", "\n", "end_of_epoch", "=", "epoch_itr", ".", "end_of_epoch", "(", ")", "\n", "updates", "=", "trainer", ".", "get_num_updates", "(", ")", "\n", "\n", "checkpoint_conds", "=", "collections", ".", "OrderedDict", "(", ")", "\n", "checkpoint_conds", "[", "\"checkpoint{}.pt\"", ".", "format", "(", "epoch", ")", "]", "=", "(", "\n", "end_of_epoch", "\n", "and", "not", "args", ".", "no_epoch_checkpoints", "\n", "and", "epoch", "%", "args", ".", "save_interval", "==", "0", "\n", ")", "\n", "checkpoint_conds", "[", "\"checkpoint_{}_{}.pt\"", ".", "format", "(", "epoch", ",", "updates", ")", "]", "=", "(", "\n", "not", "end_of_epoch", "\n", "and", "args", ".", "save_interval_updates", ">", "0", "\n", "and", "updates", "%", "args", ".", "save_interval_updates", "==", "0", "\n", ")", "\n", "checkpoint_conds", "[", "\"checkpoint_best.pt\"", "]", "=", "val_loss", "is", "not", "None", "and", "(", "\n", "not", "hasattr", "(", "save_checkpoint", ",", "\"best\"", ")", "\n", "or", "is_better", "(", "val_loss", ",", "save_checkpoint", ".", "best", ")", "\n", ")", "\n", "checkpoint_conds", "[", "\"checkpoint_last.pt\"", "]", "=", "not", "args", ".", "no_last_checkpoints", "\n", "\n", "extra_state", "=", "{", "\"train_iterator\"", ":", "epoch_itr", ".", "state_dict", "(", ")", ",", "\"val_loss\"", ":", "val_loss", "}", "\n", "if", "hasattr", "(", "save_checkpoint", ",", "\"best\"", ")", ":", "\n", "        ", "extra_state", ".", "update", "(", "{", "\"best\"", ":", "save_checkpoint", ".", "best", "}", ")", "\n", "\n", "", "checkpoints", "=", "[", "\n", "os", ".", "path", ".", "join", "(", "args", ".", "save_dir", ",", "fn", ")", "for", "fn", ",", "cond", "in", "checkpoint_conds", ".", "items", "(", ")", "if", "cond", "\n", "]", "\n", "if", "len", "(", "checkpoints", ")", ">", "0", ":", "\n", "        ", "trainer", ".", "save_checkpoint", "(", "checkpoints", "[", "0", "]", ",", "extra_state", ")", "\n", "for", "cp", "in", "checkpoints", "[", "1", ":", "]", ":", "\n", "            ", "try", ":", "\n", "                ", "from", "fairseq", ".", "fb_pathmgr", "import", "fb_pathmgr", "\n", "\n", "fb_pathmgr", ".", "copy", "(", "checkpoints", "[", "0", "]", ",", "cp", ",", "True", ")", "\n", "", "except", "(", "ModuleNotFoundError", ",", "ImportError", ")", ":", "\n", "                ", "shutil", ".", "copyfile", "(", "checkpoints", "[", "0", "]", ",", "cp", ")", "\n", "\n", "", "", "write_timer", ".", "stop", "(", ")", "\n", "print", "(", "\n", "\"| saved checkpoint {} (epoch {} @ {} updates) (writing took {} seconds)\"", ".", "format", "(", "\n", "checkpoints", "[", "0", "]", ",", "epoch", ",", "updates", ",", "write_timer", ".", "sum", "\n", ")", "\n", ")", "\n", "\n", "", "if", "not", "end_of_epoch", "and", "args", ".", "keep_interval_updates", ">", "0", ":", "\n", "# remove old checkpoints; checkpoints are sorted in descending order", "\n", "        ", "checkpoints", "=", "checkpoint_paths", "(", "\n", "args", ".", "save_dir", ",", "pattern", "=", "r\"checkpoint_\\d+_(\\d+)\\.pt\"", "\n", ")", "\n", "for", "old_chk", "in", "checkpoints", "[", "args", ".", "keep_interval_updates", ":", "]", ":", "\n", "            ", "if", "os", ".", "path", ".", "lexists", "(", "old_chk", ")", ":", "\n", "                ", "os", ".", "remove", "(", "old_chk", ")", "\n", "\n", "", "", "", "if", "args", ".", "keep_last_epochs", ">", "0", ":", "\n", "# remove old epoch checkpoints; checkpoints are sorted in descending order", "\n", "        ", "checkpoints", "=", "checkpoint_paths", "(", "args", ".", "save_dir", ",", "pattern", "=", "r\"checkpoint(\\d+)\\.pt\"", ")", "\n", "for", "old_chk", "in", "checkpoints", "[", "args", ".", "keep_last_epochs", ":", "]", ":", "\n", "            ", "if", "os", ".", "path", ".", "lexists", "(", "old_chk", ")", ":", "\n", "                ", "os", ".", "remove", "(", "old_chk", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.checkpoint_utils.load_checkpoint": [[99, 146], ["trainer.load_checkpoint", "trainer.lr_step", "os.makedirs", "os.path.join", "eval", "trainer.get_train_iterator", "trainer.get_train_iterator.load_state_dict", "trainer.get_train_iterator"], "function", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.checkpoint_utils.load_checkpoint", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.trainer.Trainer.lr_step", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.utils.eval", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.trainer.Trainer.get_train_iterator", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.iterators.EpochBatchIterator.load_state_dict", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.trainer.Trainer.get_train_iterator"], ["", "", "", "", "def", "load_checkpoint", "(", "args", ",", "trainer", ",", "**", "passthrough_args", ")", ":", "\n", "    ", "\"\"\"\n    Load a checkpoint and restore the training iterator.\n\n    *passthrough_args* will be passed through to\n    ``trainer.get_train_iterator``.\n    \"\"\"", "\n", "# only one worker should attempt to create the required dir", "\n", "if", "args", ".", "distributed_rank", "==", "0", ":", "\n", "        ", "os", ".", "makedirs", "(", "args", ".", "save_dir", ",", "exist_ok", "=", "True", ")", "\n", "\n", "", "if", "args", ".", "restore_file", "==", "\"checkpoint_last.pt\"", ":", "\n", "        ", "checkpoint_path", "=", "os", ".", "path", ".", "join", "(", "args", ".", "save_dir", ",", "\"checkpoint_last.pt\"", ")", "\n", "", "else", ":", "\n", "        ", "checkpoint_path", "=", "args", ".", "restore_file", "\n", "\n", "", "extra_state", "=", "trainer", ".", "load_checkpoint", "(", "\n", "checkpoint_path", ",", "\n", "args", ".", "reset_optimizer", ",", "\n", "args", ".", "reset_lr_scheduler", ",", "\n", "eval", "(", "args", ".", "optimizer_overrides", ")", ",", "\n", "reset_meters", "=", "args", ".", "reset_meters", ",", "\n", ")", "\n", "\n", "if", "(", "\n", "extra_state", "is", "not", "None", "\n", "and", "\"best\"", "in", "extra_state", "\n", "and", "not", "args", ".", "reset_optimizer", "\n", "and", "not", "args", ".", "reset_meters", "\n", ")", ":", "\n", "        ", "save_checkpoint", ".", "best", "=", "extra_state", "[", "\"best\"", "]", "\n", "\n", "", "if", "extra_state", "is", "not", "None", "and", "not", "args", ".", "reset_dataloader", ":", "\n", "# restore iterator from checkpoint", "\n", "        ", "itr_state", "=", "extra_state", "[", "\"train_iterator\"", "]", "\n", "epoch_itr", "=", "trainer", ".", "get_train_iterator", "(", "\n", "epoch", "=", "itr_state", "[", "\"epoch\"", "]", ",", "load_dataset", "=", "True", ",", "**", "passthrough_args", "\n", ")", "\n", "epoch_itr", ".", "load_state_dict", "(", "itr_state", ")", "\n", "", "else", ":", "\n", "        ", "epoch_itr", "=", "trainer", ".", "get_train_iterator", "(", "\n", "epoch", "=", "0", ",", "load_dataset", "=", "True", ",", "**", "passthrough_args", "\n", ")", "\n", "\n", "", "trainer", ".", "lr_step", "(", "epoch_itr", ".", "epoch", ")", "\n", "\n", "return", "extra_state", ",", "epoch_itr", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.checkpoint_utils.load_checkpoint_to_cpu": [[148, 168], ["checkpoint_utils._upgrade_state_dict", "arg_overrides.items", "fb_pathmgr.open", "torch.load", "torch.load", "setattr", "torch.serialization.default_restore_location", "torch.serialization.default_restore_location"], "function", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.checkpoint_utils._upgrade_state_dict"], ["", "def", "load_checkpoint_to_cpu", "(", "path", ",", "arg_overrides", "=", "None", ")", ":", "\n", "    ", "\"\"\"Loads a checkpoint to CPU (with upgrading for backward compatibility).\"\"\"", "\n", "try", ":", "\n", "        ", "from", "fairseq", ".", "fb_pathmgr", "import", "fb_pathmgr", "\n", "\n", "with", "fb_pathmgr", ".", "open", "(", "path", ",", "\"rb\"", ")", "as", "f", ":", "\n", "            ", "state", "=", "torch", ".", "load", "(", "\n", "f", ",", "map_location", "=", "lambda", "s", ",", "l", ":", "default_restore_location", "(", "s", ",", "\"cpu\"", ")", "\n", ")", "\n", "", "", "except", "(", "ModuleNotFoundError", ",", "ImportError", ")", ":", "\n", "# if path manager not found, continue with local file.", "\n", "        ", "state", "=", "torch", ".", "load", "(", "\n", "path", ",", "map_location", "=", "lambda", "s", ",", "l", ":", "default_restore_location", "(", "s", ",", "\"cpu\"", ")", "\n", ")", "\n", "", "args", "=", "state", "[", "\"args\"", "]", "\n", "if", "arg_overrides", "is", "not", "None", ":", "\n", "        ", "for", "arg_name", ",", "arg_val", "in", "arg_overrides", ".", "items", "(", ")", ":", "\n", "            ", "setattr", "(", "args", ",", "arg_name", ",", "arg_val", ")", "\n", "", "", "state", "=", "_upgrade_state_dict", "(", "state", ")", "\n", "return", "state", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.checkpoint_utils.load_model_ensemble": [[170, 181], ["checkpoint_utils.load_model_ensemble_and_task"], "function", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.checkpoint_utils.load_model_ensemble_and_task"], ["", "def", "load_model_ensemble", "(", "filenames", ",", "arg_overrides", "=", "None", ",", "task", "=", "None", ")", ":", "\n", "    ", "\"\"\"Loads an ensemble of models.\n\n    Args:\n        filenames (List[str]): checkpoint files to load\n        arg_overrides (Dict[str,Any], optional): override model args that\n            were used during model training\n        task (fairseq.tasks.FairseqTask, optional): task to use for loading\n    \"\"\"", "\n", "ensemble", ",", "args", ",", "_task", "=", "load_model_ensemble_and_task", "(", "filenames", ",", "arg_overrides", ",", "task", ")", "\n", "return", "ensemble", ",", "args", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.checkpoint_utils.load_model_ensemble_and_task": [[183, 201], ["checkpoint_utils.load_checkpoint_to_cpu", "tasks.setup_task.build_model", "task.build_model.load_state_dict", "ensemble.append", "os.path.exists", "IOError", "tasks.setup_task"], "function", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.checkpoint_utils.load_checkpoint_to_cpu", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.tasks.integer_sequence_modeling.IntegerSequenceModelingTask.build_model", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.iterators.EpochBatchIterator.load_state_dict", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.tasks.integer_sequence_modeling.IntegerSequenceModelingTask.setup_task"], ["", "def", "load_model_ensemble_and_task", "(", "filenames", ",", "arg_overrides", "=", "None", ",", "task", "=", "None", ")", ":", "\n", "    ", "from", "fairseq", "import", "tasks", "\n", "\n", "ensemble", "=", "[", "]", "\n", "for", "filename", "in", "filenames", ":", "\n", "        ", "if", "not", "os", ".", "path", ".", "exists", "(", "filename", ")", ":", "\n", "            ", "raise", "IOError", "(", "\"Model file not found: {}\"", ".", "format", "(", "filename", ")", ")", "\n", "", "state", "=", "load_checkpoint_to_cpu", "(", "filename", ",", "arg_overrides", ")", "\n", "\n", "args", "=", "state", "[", "\"args\"", "]", "\n", "if", "task", "is", "None", ":", "\n", "            ", "task", "=", "tasks", ".", "setup_task", "(", "args", ")", "\n", "\n", "# build model for ensemble", "\n", "", "model", "=", "task", ".", "build_model", "(", "args", ")", "\n", "model", ".", "load_state_dict", "(", "state", "[", "\"model\"", "]", ",", "strict", "=", "True", ",", "args", "=", "args", ")", "\n", "ensemble", ".", "append", "(", "model", ")", "\n", "", "return", "ensemble", ",", "args", ",", "task", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.checkpoint_utils.checkpoint_paths": [[203, 220], ["re.compile", "os.listdir", "enumerate", "re.compile.fullmatch", "os.path.join", "entries.append", "sorted", "int", "len", "pt_regexp.fullmatch.group", "pt_regexp.fullmatch.group", "pt_regexp.fullmatch.groups"], "function", ["None"], ["", "def", "checkpoint_paths", "(", "path", ",", "pattern", "=", "r\"checkpoint(\\d+)\\.pt\"", ")", ":", "\n", "    ", "\"\"\"Retrieves all checkpoints found in `path` directory.\n\n    Checkpoints are identified by matching filename to the specified pattern. If\n    the pattern contains groups, the result will be sorted by the first group in\n    descending order.\n    \"\"\"", "\n", "pt_regexp", "=", "re", ".", "compile", "(", "pattern", ")", "\n", "files", "=", "os", ".", "listdir", "(", "path", ")", "\n", "\n", "entries", "=", "[", "]", "\n", "for", "i", ",", "f", "in", "enumerate", "(", "files", ")", ":", "\n", "        ", "m", "=", "pt_regexp", ".", "fullmatch", "(", "f", ")", "\n", "if", "m", "is", "not", "None", ":", "\n", "            ", "idx", "=", "int", "(", "m", ".", "group", "(", "1", ")", ")", "if", "len", "(", "m", ".", "groups", "(", ")", ")", ">", "0", "else", "i", "\n", "entries", ".", "append", "(", "(", "idx", ",", "m", ".", "group", "(", "0", ")", ")", ")", "\n", "", "", "return", "[", "os", ".", "path", ".", "join", "(", "path", ",", "x", "[", "1", "]", ")", "for", "x", "in", "sorted", "(", "entries", ",", "reverse", "=", "True", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.checkpoint_utils.torch_persistent_save": [[222, 229], ["range", "torch.save", "logging.error", "traceback.format_exc"], "function", ["None"], ["", "def", "torch_persistent_save", "(", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "    ", "for", "i", "in", "range", "(", "3", ")", ":", "\n", "        ", "try", ":", "\n", "            ", "return", "torch", ".", "save", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "", "except", "Exception", ":", "\n", "            ", "if", "i", "==", "2", ":", "\n", "                ", "logging", ".", "error", "(", "traceback", ".", "format_exc", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.checkpoint_utils.convert_state_dict_type": [[231, 243], ["isinstance", "collections.OrderedDict", "state_dict.items", "isinstance", "checkpoint_utils.convert_state_dict_type", "torch.is_tensor", "checkpoint_utils.convert_state_dict_type", "state_dict.type"], "function", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.checkpoint_utils.convert_state_dict_type", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.checkpoint_utils.convert_state_dict_type"], ["", "", "", "", "def", "convert_state_dict_type", "(", "state_dict", ",", "ttype", "=", "torch", ".", "FloatTensor", ")", ":", "\n", "    ", "if", "isinstance", "(", "state_dict", ",", "dict", ")", ":", "\n", "        ", "cpu_dict", "=", "OrderedDict", "(", ")", "\n", "for", "k", ",", "v", "in", "state_dict", ".", "items", "(", ")", ":", "\n", "            ", "cpu_dict", "[", "k", "]", "=", "convert_state_dict_type", "(", "v", ")", "\n", "", "return", "cpu_dict", "\n", "", "elif", "isinstance", "(", "state_dict", ",", "list", ")", ":", "\n", "        ", "return", "[", "convert_state_dict_type", "(", "v", ")", "for", "v", "in", "state_dict", "]", "\n", "", "elif", "torch", ".", "is_tensor", "(", "state_dict", ")", ":", "\n", "        ", "return", "state_dict", ".", "type", "(", "ttype", ")", "\n", "", "else", ":", "\n", "        ", "return", "state_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.checkpoint_utils.save_state": [[245, 291], ["utils.has_parameters", "criterion.state_dict", "checkpoint_utils.convert_state_dict_type", "optimizer.state_dict", "fb_pathmgr.open", "checkpoint_utils.torch_persistent_save", "checkpoint_utils.torch_persistent_save", "lr_scheduler.state_dict"], "function", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.utils.has_parameters", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.iterators.EpochBatchIterator.state_dict", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.checkpoint_utils.convert_state_dict_type", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.iterators.EpochBatchIterator.state_dict", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.checkpoint_utils.torch_persistent_save", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.checkpoint_utils.torch_persistent_save", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.iterators.EpochBatchIterator.state_dict"], ["", "", "def", "save_state", "(", "\n", "filename", ",", "\n", "args", ",", "\n", "model_state_dict", ",", "\n", "criterion", ",", "\n", "optimizer", ",", "\n", "lr_scheduler", ",", "\n", "num_updates", ",", "\n", "optim_history", "=", "None", ",", "\n", "extra_state", "=", "None", ",", "\n", ")", ":", "\n", "    ", "from", "fairseq", "import", "utils", "\n", "\n", "if", "optim_history", "is", "None", ":", "\n", "        ", "optim_history", "=", "[", "]", "\n", "", "if", "extra_state", "is", "None", ":", "\n", "        ", "extra_state", "=", "{", "}", "\n", "", "state_dict", "=", "{", "\n", "\"args\"", ":", "args", ",", "\n", "\"model\"", ":", "model_state_dict", "if", "model_state_dict", "else", "{", "}", ",", "\n", "\"optimizer_history\"", ":", "optim_history", "\n", "+", "[", "\n", "{", "\n", "\"criterion_name\"", ":", "criterion", ".", "__class__", ".", "__name__", ",", "\n", "\"optimizer_name\"", ":", "optimizer", ".", "__class__", ".", "__name__", ",", "\n", "\"lr_scheduler_state\"", ":", "lr_scheduler", ".", "state_dict", "(", ")", ",", "\n", "\"num_updates\"", ":", "num_updates", ",", "\n", "}", "\n", "]", ",", "\n", "\"extra_state\"", ":", "extra_state", ",", "\n", "}", "\n", "if", "utils", ".", "has_parameters", "(", "criterion", ")", ":", "\n", "        ", "state_dict", "[", "\"criterion\"", "]", "=", "criterion", ".", "state_dict", "(", ")", "\n", "", "if", "not", "args", ".", "no_save_optimizer_state", ":", "\n", "        ", "state_dict", "[", "\"last_optimizer_state\"", "]", "=", "convert_state_dict_type", "(", "\n", "optimizer", ".", "state_dict", "(", ")", "\n", ")", "\n", "\n", "", "try", ":", "\n", "        ", "from", "fairseq", ".", "fb_pathmgr", "import", "fb_pathmgr", "\n", "\n", "with", "fb_pathmgr", ".", "open", "(", "filename", ",", "\"wb\"", ")", "as", "f", ":", "\n", "            ", "torch_persistent_save", "(", "state_dict", ",", "f", ")", "\n", "", "", "except", "(", "ModuleNotFoundError", ",", "ImportError", ")", ":", "\n", "# if path manager not found, continue with local file.", "\n", "        ", "torch_persistent_save", "(", "state_dict", ",", "filename", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.checkpoint_utils._upgrade_state_dict": [[293, 358], ["registry.set_defaults", "registry.set_defaults", "registry.REGISTRIES.items", "hasattr", "hasattr", "getattr", "hasattr", "state[].get", "registry.set_defaults"], "function", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.registry.set_defaults", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.registry.set_defaults", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.registry.set_defaults"], ["", "", "def", "_upgrade_state_dict", "(", "state", ")", ":", "\n", "    ", "\"\"\"Helper for upgrading old model checkpoints.\"\"\"", "\n", "from", "fairseq", "import", "models", ",", "registry", ",", "tasks", "\n", "\n", "# add optimizer_history", "\n", "if", "\"optimizer_history\"", "not", "in", "state", ":", "\n", "        ", "state", "[", "\"optimizer_history\"", "]", "=", "[", "\n", "{", "\"criterion_name\"", ":", "\"CrossEntropyCriterion\"", ",", "\"best_loss\"", ":", "state", "[", "\"best_loss\"", "]", "}", "\n", "]", "\n", "state", "[", "\"last_optimizer_state\"", "]", "=", "state", "[", "\"optimizer\"", "]", "\n", "del", "state", "[", "\"optimizer\"", "]", "\n", "del", "state", "[", "\"best_loss\"", "]", "\n", "# move extra_state into sub-dictionary", "\n", "", "if", "\"epoch\"", "in", "state", "and", "\"extra_state\"", "not", "in", "state", ":", "\n", "        ", "state", "[", "\"extra_state\"", "]", "=", "{", "\n", "\"epoch\"", ":", "state", "[", "\"epoch\"", "]", ",", "\n", "\"batch_offset\"", ":", "state", "[", "\"batch_offset\"", "]", ",", "\n", "\"val_loss\"", ":", "state", "[", "\"val_loss\"", "]", ",", "\n", "}", "\n", "del", "state", "[", "\"epoch\"", "]", "\n", "del", "state", "[", "\"batch_offset\"", "]", "\n", "del", "state", "[", "\"val_loss\"", "]", "\n", "# reduce optimizer history's memory usage (only keep the last state)", "\n", "", "if", "\"optimizer\"", "in", "state", "[", "\"optimizer_history\"", "]", "[", "-", "1", "]", ":", "\n", "        ", "state", "[", "\"last_optimizer_state\"", "]", "=", "state", "[", "\"optimizer_history\"", "]", "[", "-", "1", "]", "[", "\"optimizer\"", "]", "\n", "for", "optim_hist", "in", "state", "[", "\"optimizer_history\"", "]", ":", "\n", "            ", "del", "optim_hist", "[", "\"optimizer\"", "]", "\n", "# record the optimizer class name", "\n", "", "", "if", "\"optimizer_name\"", "not", "in", "state", "[", "\"optimizer_history\"", "]", "[", "-", "1", "]", ":", "\n", "        ", "state", "[", "\"optimizer_history\"", "]", "[", "-", "1", "]", "[", "\"optimizer_name\"", "]", "=", "\"FairseqNAG\"", "\n", "# move best_loss into lr_scheduler_state", "\n", "", "if", "\"lr_scheduler_state\"", "not", "in", "state", "[", "\"optimizer_history\"", "]", "[", "-", "1", "]", ":", "\n", "        ", "state", "[", "\"optimizer_history\"", "]", "[", "-", "1", "]", "[", "\"lr_scheduler_state\"", "]", "=", "{", "\n", "\"best\"", ":", "state", "[", "\"optimizer_history\"", "]", "[", "-", "1", "]", "[", "\"best_loss\"", "]", "\n", "}", "\n", "del", "state", "[", "\"optimizer_history\"", "]", "[", "-", "1", "]", "[", "\"best_loss\"", "]", "\n", "# keep track of number of updates", "\n", "", "if", "\"num_updates\"", "not", "in", "state", "[", "\"optimizer_history\"", "]", "[", "-", "1", "]", ":", "\n", "        ", "state", "[", "\"optimizer_history\"", "]", "[", "-", "1", "]", "[", "\"num_updates\"", "]", "=", "0", "\n", "# old model checkpoints may not have separate source/target positions", "\n", "", "if", "hasattr", "(", "state", "[", "\"args\"", "]", ",", "\"max_positions\"", ")", "and", "not", "hasattr", "(", "\n", "state", "[", "\"args\"", "]", ",", "\"max_source_positions\"", "\n", ")", ":", "\n", "        ", "state", "[", "\"args\"", "]", ".", "max_source_positions", "=", "state", "[", "\"args\"", "]", ".", "max_positions", "\n", "state", "[", "\"args\"", "]", ".", "max_target_positions", "=", "state", "[", "\"args\"", "]", ".", "max_positions", "\n", "# use stateful training data iterator", "\n", "", "if", "\"train_iterator\"", "not", "in", "state", "[", "\"extra_state\"", "]", ":", "\n", "        ", "state", "[", "\"extra_state\"", "]", "[", "\"train_iterator\"", "]", "=", "{", "\n", "\"epoch\"", ":", "state", "[", "\"extra_state\"", "]", "[", "\"epoch\"", "]", ",", "\n", "\"iterations_in_epoch\"", ":", "state", "[", "\"extra_state\"", "]", ".", "get", "(", "\"batch_offset\"", ",", "0", ")", ",", "\n", "}", "\n", "# default to translation task", "\n", "", "if", "not", "hasattr", "(", "state", "[", "\"args\"", "]", ",", "\"task\"", ")", ":", "\n", "        ", "state", "[", "\"args\"", "]", ".", "task", "=", "\"translation\"", "\n", "\n", "# set any missing default values in the task, model or other registries", "\n", "", "registry", ".", "set_defaults", "(", "state", "[", "\"args\"", "]", ",", "tasks", ".", "TASK_REGISTRY", "[", "state", "[", "\"args\"", "]", ".", "task", "]", ")", "\n", "registry", ".", "set_defaults", "(", "state", "[", "\"args\"", "]", ",", "models", ".", "ARCH_MODEL_REGISTRY", "[", "state", "[", "\"args\"", "]", ".", "arch", "]", ")", "\n", "for", "registry_name", ",", "REGISTRY", "in", "registry", ".", "REGISTRIES", ".", "items", "(", ")", ":", "\n", "        ", "choice", "=", "getattr", "(", "state", "[", "\"args\"", "]", ",", "registry_name", ",", "None", ")", "\n", "if", "choice", "is", "not", "None", ":", "\n", "            ", "cls", "=", "REGISTRY", "[", "\"registry\"", "]", "[", "choice", "]", "\n", "registry", ".", "set_defaults", "(", "state", "[", "\"args\"", "]", ",", "cls", ")", "\n", "\n", "", "", "return", "state", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.checkpoint_utils.prune_state_dict": [[360, 442], ["print", "state_dict.keys", "sorted", "range", "re.compile", "pruning_passes.append", "pruning_passes.append", "re.search", "re.search.group", "vars", "vars", "vars", "vars", "len", "str", "checkpoint_utils.prune_state_dict.create_pruning_pass"], "function", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.progress_bar.tensorboard_log_wrapper.print"], ["", "def", "prune_state_dict", "(", "state_dict", ",", "args", ")", ":", "\n", "    ", "\"\"\"Prune the given state_dict if desired for LayerDrop\n    (https://arxiv.org/abs/1909.11556).\n\n    Training with LayerDrop allows models to be robust to pruning at inference\n    time. This function prunes state_dict to allow smaller models to be loaded\n    from a larger model and re-maps the existing state_dict for this to occur.\n\n    It's called by functions that load models from checkpoints and does not\n    need to be called directly.\n    \"\"\"", "\n", "if", "not", "args", "or", "args", ".", "arch", "==", "\"ptt_transformer\"", ":", "\n", "# args should not be none, but don't crash if it is.", "\n", "        ", "return", "state_dict", "\n", "\n", "", "encoder_layers_to_keep", "=", "(", "\n", "args", ".", "encoder_layers_to_keep", "if", "\"encoder_layers_to_keep\"", "in", "vars", "(", "args", ")", "else", "None", "\n", ")", "\n", "decoder_layers_to_keep", "=", "(", "\n", "args", ".", "decoder_layers_to_keep", "if", "\"decoder_layers_to_keep\"", "in", "vars", "(", "args", ")", "else", "None", "\n", ")", "\n", "\n", "if", "not", "encoder_layers_to_keep", "and", "not", "decoder_layers_to_keep", ":", "\n", "        ", "return", "state_dict", "\n", "\n", "# apply pruning", "\n", "", "print", "(", "\n", "\"| Pruning model to specified layer configuration - this works best if the model was trained with LayerDrop\"", "\n", ")", "\n", "\n", "def", "create_pruning_pass", "(", "layers_to_keep", ",", "layer_name", ")", ":", "\n", "        ", "keep_layers", "=", "sorted", "(", "\n", "[", "int", "(", "layer_string", ")", "for", "layer_string", "in", "layers_to_keep", ".", "split", "(", "\",\"", ")", "]", "\n", ")", "\n", "mapping_dict", "=", "{", "}", "\n", "for", "i", "in", "range", "(", "len", "(", "keep_layers", ")", ")", ":", "\n", "            ", "mapping_dict", "[", "str", "(", "keep_layers", "[", "i", "]", ")", "]", "=", "str", "(", "i", ")", "\n", "\n", "", "regex", "=", "re", ".", "compile", "(", "\"^{layer}.*\\.layers\\.(\\d+)\"", ".", "format", "(", "layer", "=", "layer_name", ")", ")", "\n", "return", "{", "\"substitution_regex\"", ":", "regex", ",", "\"mapping_dict\"", ":", "mapping_dict", "}", "\n", "\n", "", "pruning_passes", "=", "[", "]", "\n", "if", "encoder_layers_to_keep", ":", "\n", "        ", "pruning_passes", ".", "append", "(", "create_pruning_pass", "(", "encoder_layers_to_keep", ",", "\"encoder\"", ")", ")", "\n", "", "if", "decoder_layers_to_keep", ":", "\n", "        ", "pruning_passes", ".", "append", "(", "create_pruning_pass", "(", "decoder_layers_to_keep", ",", "\"decoder\"", ")", ")", "\n", "\n", "", "new_state_dict", "=", "{", "}", "\n", "for", "layer_name", "in", "state_dict", ".", "keys", "(", ")", ":", "\n", "        ", "match", "=", "re", ".", "search", "(", "\"\\.layers\\.(\\d+)\\.\"", ",", "layer_name", ")", "\n", "# if layer has no number in it, it is a supporting layer, such as an", "\n", "# embedding", "\n", "if", "not", "match", ":", "\n", "            ", "new_state_dict", "[", "layer_name", "]", "=", "state_dict", "[", "layer_name", "]", "\n", "continue", "\n", "\n", "# otherwise, layer should be pruned.", "\n", "", "original_layer_number", "=", "match", ".", "group", "(", "1", ")", "\n", "# figure out which mapping dict to replace from", "\n", "for", "pruning_pass", "in", "pruning_passes", ":", "\n", "            ", "if", "original_layer_number", "in", "pruning_pass", "[", "\"mapping_dict\"", "]", "and", "pruning_pass", "[", "\n", "\"substitution_regex\"", "\n", "]", ".", "search", "(", "layer_name", ")", ":", "\n", "                ", "new_layer_number", "=", "pruning_pass", "[", "\"mapping_dict\"", "]", "[", "original_layer_number", "]", "\n", "substitution_match", "=", "pruning_pass", "[", "\"substitution_regex\"", "]", ".", "search", "(", "\n", "layer_name", "\n", ")", "\n", "new_state_key", "=", "(", "\n", "layer_name", "[", ":", "substitution_match", ".", "start", "(", "1", ")", "]", "\n", "+", "new_layer_number", "\n", "+", "layer_name", "[", "substitution_match", ".", "end", "(", "1", ")", ":", "]", "\n", ")", "\n", "new_state_dict", "[", "new_state_key", "]", "=", "state_dict", "[", "layer_name", "]", "\n", "\n", "# Since layers are now pruned, *_layers_to_keep are no longer needed.", "\n", "# This is more of \"It would make it work fix\" rather than a proper fix.", "\n", "", "", "", "if", "\"encoder_layers_to_keep\"", "in", "vars", "(", "args", ")", ":", "\n", "        ", "args", ".", "encoder_layers_to_keep", "=", "None", "\n", "", "if", "\"decoder_layers_to_keep\"", "in", "vars", "(", "args", ")", ":", "\n", "        ", "args", ".", "decoder_layers_to_keep", "=", "None", "\n", "\n", "", "return", "new_state_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.checkpoint_utils.load_pretrained_component_from_model": [[444, 473], ["checkpoint_utils.load_checkpoint_to_cpu", "isinstance", "collections.OrderedDict", "state[].keys", "component.load_state_dict", "os.path.exists", "IOError", "isinstance", "key.startswith", "ValueError", "len"], "function", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.checkpoint_utils.load_checkpoint_to_cpu", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.iterators.EpochBatchIterator.load_state_dict"], ["", "def", "load_pretrained_component_from_model", "(", "\n", "component", ":", "Union", "[", "FairseqEncoder", ",", "FairseqDecoder", "]", ",", "checkpoint", ":", "str", "\n", ")", ":", "\n", "    ", "\"\"\"\n    Load a pretrained FairseqEncoder or FairseqDecoder from checkpoint into the\n    provided `component` object. If state_dict fails to load, there may be a\n    mismatch in the architecture of the corresponding `component` found in the\n    `checkpoint` file.\n    \"\"\"", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "checkpoint", ")", ":", "\n", "        ", "raise", "IOError", "(", "\"Model file not found: {}\"", ".", "format", "(", "checkpoint", ")", ")", "\n", "", "state", "=", "load_checkpoint_to_cpu", "(", "checkpoint", ")", "\n", "if", "isinstance", "(", "component", ",", "FairseqEncoder", ")", ":", "\n", "        ", "component_type", "=", "\"encoder\"", "\n", "", "elif", "isinstance", "(", "component", ",", "FairseqDecoder", ")", ":", "\n", "        ", "component_type", "=", "\"decoder\"", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "\n", "\"component to load must be either a FairseqEncoder or \"", "\n", "\"FairseqDecoder. Loading other component types are not supported.\"", "\n", ")", "\n", "", "component_state_dict", "=", "OrderedDict", "(", ")", "\n", "for", "key", "in", "state", "[", "\"model\"", "]", ".", "keys", "(", ")", ":", "\n", "        ", "if", "key", ".", "startswith", "(", "component_type", ")", ":", "\n", "# encoder.input_layers.0.0.weight --> input_layers.0.0.weight", "\n", "            ", "component_subkey", "=", "key", "[", "len", "(", "component_type", ")", "+", "1", ":", "]", "\n", "component_state_dict", "[", "component_subkey", "]", "=", "state", "[", "\"model\"", "]", "[", "key", "]", "\n", "", "", "component", ".", "load_state_dict", "(", "component_state_dict", ",", "strict", "=", "True", ")", "\n", "return", "component", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.checkpoint_utils.verify_checkpoint_directory": [[475, 487], ["os.path.join", "os.path.exists", "os.makedirs", "os.remove", "open", "print"], "function", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.progress_bar.tensorboard_log_wrapper.print"], ["", "def", "verify_checkpoint_directory", "(", "save_dir", ":", "str", ")", "->", "None", ":", "\n", "    ", "if", "not", "os", ".", "path", ".", "exists", "(", "save_dir", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "save_dir", ",", "exist_ok", "=", "True", ")", "\n", "", "temp_file_path", "=", "os", ".", "path", ".", "join", "(", "save_dir", ",", "\"dummy\"", ")", "\n", "try", ":", "\n", "        ", "with", "open", "(", "temp_file_path", ",", "\"w\"", ")", ":", "\n", "            ", "pass", "\n", "", "", "except", "OSError", "as", "e", ":", "\n", "        ", "print", "(", "\"| Unable to access checkpoint save directory: {}\"", ".", "format", "(", "save_dir", ")", ")", "\n", "raise", "e", "\n", "", "else", ":", "\n", "        ", "os", ".", "remove", "(", "temp_file_path", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.sequence_generator.SequenceGenerator.__init__": [[15, 70], ["tgt_dict.pad", "tgt_dict.bos", "len", "min", "fairseq.search.Sampling", "fairseq.search.DiverseBeamSearch", "fairseq.search.BeamSearch"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.dummy_dictionary.DummyDictionary.pad", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.dummy_dictionary.DummyDictionary.bos"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "tgt_dict", ",", "\n", "beam_size", "=", "1", ",", "\n", "tgt_len", "=", "200", ",", "\n", "retain_dropout", "=", "False", ",", "\n", "sampling", "=", "False", ",", "\n", "sampling_topk", "=", "-", "1", ",", "\n", "sampling_topp", "=", "-", "1.0", ",", "\n", "temperature", "=", "1.", ",", "\n", "diverse_beam_groups", "=", "-", "1", ",", "\n", "diverse_beam_strength", "=", "0.5", "\n", ")", ":", "\n", "        ", "\"\"\"Generates translations of a given source sentence.\n\n        Args:\n            tgt_dict (~fairseq.data.Dictionary): target dictionary\n            beam_size (int, optional): beam width (default: 1)\n            normalize_scores (bool, optional): normalize scores by the length\n                of the output (default: True)\n            retain_dropout (bool, optional): use dropout when generating\n                (default: False)\n            sampling (bool, optional): sample outputs instead of beam search\n                (default: False)\n            sampling_topk (int, optional): only sample among the top-k choices\n                at each step (default: -1)\n            sampling_topp (float, optional): only sample among the smallest set\n                of words whose cumulative probability mass exceeds p\n                at each step (default: -1.0)\n            temperature (float, optional): temperature, where values\n                >1.0 produce more uniform samples and values <1.0 produce\n                sharper samples (default: 1.0)\n            diverse_beam_groups/strength (float, optional): parameters for\n                Diverse Beam Search sampling\n        \"\"\"", "\n", "self", ".", "pad", "=", "tgt_dict", ".", "pad", "(", ")", "\n", "self", ".", "bos", "=", "tgt_dict", ".", "bos", "(", ")", "\n", "self", ".", "vocab_size", "=", "len", "(", "tgt_dict", ")", "\n", "assert", "beam_size", "==", "1", ",", "\"Only support beam_size=1 currently\"", "\n", "self", ".", "beam_size", "=", "beam_size", "\n", "# the max beam size is the dictionary size - 1, since we never select pad", "\n", "self", ".", "beam_size", "=", "min", "(", "beam_size", ",", "self", ".", "vocab_size", "-", "1", ")", "\n", "self", ".", "tgt_len", "=", "tgt_len", "\n", "self", ".", "retain_dropout", "=", "retain_dropout", "\n", "self", ".", "temperature", "=", "temperature", "\n", "assert", "sampling_topk", "<", "0", "or", "sampling", ",", "'--sampling-topk requires --sampling'", "\n", "assert", "sampling_topp", "<", "0", "or", "sampling", ",", "'--sampling-topp requires --sampling'", "\n", "assert", "temperature", ">", "0", ",", "'--temperature must be greater than 0'", "\n", "\n", "if", "sampling", ":", "\n", "            ", "self", ".", "search", "=", "search", ".", "Sampling", "(", "tgt_dict", ",", "sampling_topk", ",", "sampling_topp", ")", "\n", "", "elif", "diverse_beam_groups", ">", "0", ":", "\n", "            ", "self", ".", "search", "=", "search", ".", "DiverseBeamSearch", "(", "tgt_dict", ",", "diverse_beam_groups", ",", "diverse_beam_strength", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "search", "=", "search", ".", "BeamSearch", "(", "tgt_dict", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.sequence_generator.SequenceGenerator.generate": [[71, 85], ["torch.no_grad", "sequence_generator.EnsembleModel", "sequence_generator.SequenceGenerator._generate"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.sequence_generator.SequenceGenerator._generate"], ["", "", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "generate", "(", "self", ",", "models", ",", "sample", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"Generate a batch of translations.\n\n        Args:\n            models (List[~fairseq.models.FairseqModel]): ensemble of models\n            sample (dict): batch\n            prefix_tokens (torch.LongTensor, optional): force decoder to begin\n                with these tokens\n            bos_token (int, optional): beginning of sentence token\n                (default: self.eos)\n        \"\"\"", "\n", "model", "=", "EnsembleModel", "(", "models", ")", "\n", "return", "self", ".", "_generate", "(", "model", ",", "sample", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.sequence_generator.SequenceGenerator._generate": [[86, 139], ["torch.no_grad", "src_tokens.size", "model.forward_encoder", "src_tokens.new().float().fill_", "src_tokens.new().long().fill_", "range", "model.eval", "model.max_decoder_positions", "model.forward_decoder", "sequence_generator.SequenceGenerator.search.step", "tokens[].cpu().numpy", "src_tokens.new().float().fill_.cpu().numpy", "sample[].items", "src_tokens.new().float", "src_tokens.new().long", "lprobs.view", "src_tokens.new().float().fill_.view", "tokens[].cpu", "src_tokens.new().float().fill_.cpu", "src_tokens.new", "src_tokens.new"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.fairseq_dataset.FairseqDataset.size", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.sequence_generator.EnsembleModel.forward_encoder", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.utils.eval", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.sequence_generator.EnsembleModel.max_decoder_positions", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.sequence_generator.EnsembleModel.forward_decoder", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.lr_scheduler.polynomial_decay_schedule.PolynomialDecaySchedule.step"], ["", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "_generate", "(", "\n", "self", ",", "\n", "model", ",", "\n", "sample", ",", "\n", "prefix_tokens", "=", "None", "\n", ")", ":", "\n", "        ", "assert", "prefix_tokens", "is", "None", ",", "\"Currently only supports unconditional generation\"", "\n", "\n", "if", "not", "self", ".", "retain_dropout", ":", "\n", "            ", "model", ".", "eval", "(", ")", "\n", "\n", "# model.forward normally channels prev_output_tokens into the decoder", "\n", "# separately, but SequenceGenerator directly calls model.encoder", "\n", "", "encoder_input", "=", "{", "\n", "k", ":", "v", "for", "k", ",", "v", "in", "sample", "[", "'net_input'", "]", ".", "items", "(", ")", "\n", "if", "k", "!=", "'prev_output_tokens'", "\n", "}", "\n", "\n", "src_tokens", "=", "encoder_input", "[", "'src_tokens'", "]", "\n", "input_size", "=", "src_tokens", ".", "size", "(", ")", "\n", "# batch dimension goes first followed by source lengths", "\n", "bsz", "=", "input_size", "[", "0", "]", "\n", "beam_size", "=", "self", ".", "beam_size", "\n", "\n", "assert", "self", ".", "tgt_len", "<=", "model", ".", "max_decoder_positions", "(", ")", "\n", "\n", "# compute the encoder output for each beam", "\n", "encoder_outs", "=", "model", ".", "forward_encoder", "(", "encoder_input", ")", "\n", "\n", "# initialize buffers", "\n", "scores", "=", "src_tokens", ".", "new", "(", "bsz", "*", "beam_size", ",", "self", ".", "tgt_len", ")", ".", "float", "(", ")", ".", "fill_", "(", "0", ")", "\n", "tokens", "=", "src_tokens", ".", "new", "(", "bsz", "*", "beam_size", ",", "self", ".", "tgt_len", "+", "1", ")", ".", "long", "(", ")", ".", "fill_", "(", "self", ".", "pad", ")", "\n", "tokens", "[", ":", ",", "0", "]", "=", "self", ".", "bos", "\n", "\n", "for", "step", "in", "range", "(", "self", ".", "tgt_len", ")", ":", "\n", "            ", "lprobs", ",", "_", "=", "model", ".", "forward_decoder", "(", "\n", "tokens", "[", ":", ",", ":", "step", "+", "1", "]", ",", "encoder_outs", ",", "temperature", "=", "self", ".", "temperature", ",", "\n", ")", "\n", "\n", "lprobs", "[", ":", ",", "self", ".", "pad", "]", "=", "-", "math", ".", "inf", "# never select pad", "\n", "lprobs", "[", ":", ",", "self", ".", "bos", "]", "=", "-", "math", ".", "inf", "# never select bos", "\n", "\n", "cand_scores", ",", "cand_indices", ",", "_", "=", "self", ".", "search", ".", "step", "(", "\n", "step", ",", "\n", "lprobs", ".", "view", "(", "bsz", ",", "-", "1", ",", "self", ".", "vocab_size", ")", ",", "\n", "scores", ".", "view", "(", "bsz", ",", "beam_size", ",", "-", "1", ")", "[", ":", ",", ":", ",", ":", "step", "]", ",", "\n", ")", "\n", "\n", "scores", "[", ":", ",", "step", "]", "=", "cand_scores", "[", ":", ",", "0", "]", "\n", "tokens", "[", ":", ",", "step", "+", "1", "]", "=", "cand_indices", "[", ":", ",", "0", "]", "\n", "\n", "", "return", "tokens", "[", ":", ",", "1", ":", "]", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ",", "scores", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.sequence_generator.EnsembleModel.__init__": [[144, 150], ["super().__init__", "torch.nn.ModuleList", "all", "isinstance"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.dummy_dictionary.DummyDictionary.__init__"], ["def", "__init__", "(", "self", ",", "models", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "models", "=", "torch", ".", "nn", ".", "ModuleList", "(", "models", ")", "\n", "self", ".", "incremental_states", "=", "None", "\n", "if", "all", "(", "isinstance", "(", "m", ".", "decoder", ",", "FairseqIncrementalDecoder", ")", "for", "m", "in", "models", ")", ":", "\n", "            ", "self", ".", "incremental_states", "=", "{", "m", ":", "{", "}", "for", "m", "in", "models", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.sequence_generator.EnsembleModel.has_encoder": [[151, 153], ["hasattr"], "methods", ["None"], ["", "", "def", "has_encoder", "(", "self", ")", ":", "\n", "        ", "return", "hasattr", "(", "self", ".", "models", "[", "0", "]", ",", "'encoder'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.sequence_generator.EnsembleModel.max_decoder_positions": [[154, 156], ["min", "m.max_decoder_positions"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.sequence_generator.EnsembleModel.max_decoder_positions"], ["", "def", "max_decoder_positions", "(", "self", ")", ":", "\n", "        ", "return", "min", "(", "m", ".", "max_decoder_positions", "(", ")", "for", "m", "in", "self", ".", "models", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.sequence_generator.EnsembleModel.forward_encoder": [[157, 162], ["torch.no_grad", "sequence_generator.EnsembleModel.has_encoder", "model.encoder"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.sequence_generator.EnsembleModel.has_encoder", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.fairseq_model.FairseqMultiModel.encoder"], ["", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "forward_encoder", "(", "self", ",", "encoder_input", ")", ":", "\n", "        ", "if", "not", "self", ".", "has_encoder", "(", ")", ":", "\n", "            ", "return", "None", "\n", "", "return", "[", "model", ".", "encoder", "(", "**", "encoder_input", ")", "for", "model", "in", "self", ".", "models", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.sequence_generator.EnsembleModel.forward_decoder": [[163, 196], ["torch.no_grad", "zip", "len", "sequence_generator.EnsembleModel._decode_one", "sequence_generator.EnsembleModel._decode_one", "log_probs.append", "torch.logsumexp", "math.log", "avg_attn.div_", "torch.stack", "len", "len", "sequence_generator.EnsembleModel.has_encoder", "avg_attn.add_"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.sequence_generator.EnsembleModel._decode_one", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.sequence_generator.EnsembleModel._decode_one", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.image_transformer.logsumexp", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.progress_bar.tensorboard_log_wrapper.log", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.sequence_generator.EnsembleModel.has_encoder"], ["", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "forward_decoder", "(", "self", ",", "tokens", ",", "encoder_outs", ",", "temperature", "=", "1.", ")", ":", "\n", "        ", "if", "len", "(", "self", ".", "models", ")", "==", "1", ":", "\n", "            ", "return", "self", ".", "_decode_one", "(", "\n", "tokens", ",", "\n", "self", ".", "models", "[", "0", "]", ",", "\n", "encoder_outs", "[", "0", "]", "if", "self", ".", "has_encoder", "(", ")", "else", "None", ",", "\n", "self", ".", "incremental_states", ",", "\n", "log_probs", "=", "True", ",", "\n", "temperature", "=", "temperature", ",", "\n", ")", "\n", "\n", "", "log_probs", "=", "[", "]", "\n", "avg_attn", "=", "None", "\n", "for", "model", ",", "encoder_out", "in", "zip", "(", "self", ".", "models", ",", "encoder_outs", ")", ":", "\n", "            ", "probs", ",", "attn", "=", "self", ".", "_decode_one", "(", "\n", "tokens", ",", "\n", "model", ",", "\n", "encoder_out", ",", "\n", "self", ".", "incremental_states", ",", "\n", "log_probs", "=", "True", ",", "\n", "temperature", "=", "temperature", ",", "\n", ")", "\n", "log_probs", ".", "append", "(", "probs", ")", "\n", "if", "attn", "is", "not", "None", ":", "\n", "                ", "if", "avg_attn", "is", "None", ":", "\n", "                    ", "avg_attn", "=", "attn", "\n", "", "else", ":", "\n", "                    ", "avg_attn", ".", "add_", "(", "attn", ")", "\n", "", "", "", "avg_probs", "=", "torch", ".", "logsumexp", "(", "torch", ".", "stack", "(", "log_probs", ",", "dim", "=", "0", ")", ",", "dim", "=", "0", ")", "-", "math", ".", "log", "(", "len", "(", "self", ".", "models", ")", ")", "\n", "if", "avg_attn", "is", "not", "None", ":", "\n", "            ", "avg_attn", ".", "div_", "(", "len", "(", "self", ".", "models", ")", ")", "\n", "", "return", "avg_probs", ",", "avg_attn", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.sequence_generator.EnsembleModel._decode_one": [[197, 218], ["model.get_normalized_probs", "list", "list", "decoder_out[].div_", "type", "attn.get.get.get", "model.forward_decoder", "model.forward_decoder"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.fairseq_decoder.FairseqDecoder.get_normalized_probs", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.sequence_generator.EnsembleModel.forward_decoder", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.sequence_generator.EnsembleModel.forward_decoder"], ["", "def", "_decode_one", "(", "\n", "self", ",", "tokens", ",", "model", ",", "encoder_out", ",", "incremental_states", ",", "log_probs", ",", "\n", "temperature", "=", "1.", ",", "\n", ")", ":", "\n", "        ", "if", "self", ".", "incremental_states", "is", "not", "None", ":", "\n", "            ", "decoder_out", "=", "list", "(", "model", ".", "forward_decoder", "(", "\n", "tokens", ",", "encoder_out", "=", "encoder_out", ",", "incremental_state", "=", "self", ".", "incremental_states", "[", "model", "]", ",", "\n", ")", ")", "\n", "", "else", ":", "\n", "            ", "decoder_out", "=", "list", "(", "model", ".", "forward_decoder", "(", "tokens", ",", "encoder_out", "=", "encoder_out", ")", ")", "\n", "", "decoder_out", "[", "0", "]", "=", "decoder_out", "[", "0", "]", "[", ":", ",", "-", "1", ":", ",", ":", "]", "\n", "if", "temperature", "!=", "1.", ":", "\n", "            ", "decoder_out", "[", "0", "]", ".", "div_", "(", "temperature", ")", "\n", "", "attn", "=", "decoder_out", "[", "1", "]", "\n", "if", "type", "(", "attn", ")", "is", "dict", ":", "\n", "            ", "attn", "=", "attn", ".", "get", "(", "'attn'", ",", "None", ")", "\n", "", "if", "attn", "is", "not", "None", ":", "\n", "            ", "attn", "=", "attn", "[", ":", ",", "-", "1", ",", ":", "]", "\n", "", "probs", "=", "model", ".", "get_normalized_probs", "(", "decoder_out", ",", "log_probs", "=", "log_probs", ")", "\n", "probs", "=", "probs", "[", ":", ",", "-", "1", ",", ":", "]", "\n", "return", "probs", ",", "attn", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.sequence_generator.EnsembleModel.reorder_encoder_out": [[219, 225], ["sequence_generator.EnsembleModel.has_encoder", "model.encoder.reorder_encoder_out", "zip"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.sequence_generator.EnsembleModel.has_encoder", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.sequence_generator.EnsembleModel.reorder_encoder_out"], ["", "def", "reorder_encoder_out", "(", "self", ",", "encoder_outs", ",", "new_order", ")", ":", "\n", "        ", "if", "not", "self", ".", "has_encoder", "(", ")", ":", "\n", "            ", "return", "\n", "", "return", "[", "\n", "model", ".", "encoder", ".", "reorder_encoder_out", "(", "encoder_out", ",", "new_order", ")", "\n", "for", "model", ",", "encoder_out", "in", "zip", "(", "self", ".", "models", ",", "encoder_outs", ")", "\n", "]", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.sequence_generator.EnsembleModel.reorder_incremental_state": [[227, 232], ["model.decoder.reorder_incremental_state"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.modules.multihead_attention.MultiheadAttention.reorder_incremental_state"], ["", "def", "reorder_incremental_state", "(", "self", ",", "new_order", ")", ":", "\n", "        ", "if", "self", ".", "incremental_states", "is", "None", ":", "\n", "            ", "return", "\n", "", "for", "model", "in", "self", ".", "models", ":", "\n", "            ", "model", ".", "decoder", ".", "reorder_incremental_state", "(", "self", ".", "incremental_states", "[", "model", "]", ",", "new_order", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.utils.apply_to_sample": [[22, 40], ["utils.apply_to_sample._apply"], "function", ["None"], ["", "def", "parse_args_and_config", "(", "args", ",", "config_dir", "=", "\"../configs\"", ",", "logdir", "=", "\"../logs\"", ",", "resume", "=", "False", ")", ":", "\n", "    ", "\"\"\"\n    :return args, config: namespace objects that stores information in args and config files.\n    \"\"\"", "\n", "args", ".", "log", "=", "os", ".", "path", ".", "join", "(", "logdir", ",", "args", ".", "doc", ")", "\n", "# parse config file", "\n", "if", "not", "resume", ":", "\n", "        ", "with", "open", "(", "os", ".", "path", ".", "join", "(", "config_dir", ",", "args", ".", "config", ")", ",", "'r'", ")", "as", "f", ":", "\n", "            ", "config", "=", "yaml", ".", "load", "(", "f", ")", "\n", "", "new_config", "=", "dict2namespace", "(", "{", "**", "config", ",", "**", "vars", "(", "args", ")", "}", ")", "\n", "", "else", ":", "\n", "        ", "with", "open", "(", "os", ".", "path", ".", "join", "(", "args", ".", "log", ",", "'config.yml'", ")", ",", "'r'", ")", "as", "f", ":", "\n", "            ", "config", "=", "yaml", ".", "load", "(", "f", ")", "\n", "", "new_config", "=", "dict2namespace", "(", "{", "**", "vars", "(", "config", ")", ",", "**", "vars", "(", "args", ")", "}", ")", "\n", "\n", "# add device information to config", "\n", "", "device", "=", "torch", ".", "device", "(", "'cuda'", ")", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "else", "torch", ".", "device", "(", "'cpu'", ")", "\n", "new_config", ".", "device", "=", "device", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.utils.move_to_cuda": [[42, 48], ["utils.apply_to_sample", "tensor.cuda"], "function", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.utils.apply_to_sample"], ["        ", "if", "os", ".", "path", ".", "exists", "(", "args", ".", "log", ")", ":", "\n", "            ", "shutil", ".", "rmtree", "(", "args", ".", "log", ")", "\n", "", "os", ".", "makedirs", "(", "args", ".", "log", ")", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "args", ".", "log", ",", "'config.yml'", ")", ",", "'w'", ")", "as", "f", ":", "\n", "            ", "yaml", ".", "dump", "(", "new_config", ",", "f", ",", "default_flow_style", "=", "False", ")", "\n", "\n", "# setup logger", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.utils._get_full_incremental_state_key": [[53, 63], ["hasattr"], "function", ["None"], ["", "handler1", "=", "logging", ".", "StreamHandler", "(", ")", "\n", "handler2", "=", "logging", ".", "FileHandler", "(", "os", ".", "path", ".", "join", "(", "args", ".", "log", ",", "'stdout.txt'", ")", ")", "\n", "formatter", "=", "logging", ".", "Formatter", "(", "'%(levelname)s - %(filename)s - %(asctime)s - %(message)s'", ")", "\n", "handler1", ".", "setFormatter", "(", "formatter", ")", "\n", "handler2", ".", "setFormatter", "(", "formatter", ")", "\n", "logger", "=", "logging", ".", "getLogger", "(", ")", "\n", "logger", ".", "addHandler", "(", "handler1", ")", "\n", "logger", ".", "addHandler", "(", "handler2", ")", "\n", "logger", ".", "setLevel", "(", "level", ")", "\n", "logging", ".", "info", "(", "\"Using device: {}\"", ".", "format", "(", "device", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.utils.get_incremental_state": [[65, 71], ["utils._get_full_incremental_state_key"], "function", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.utils._get_full_incremental_state_key"], ["torch", ".", "manual_seed", "(", "new_config", ".", "seed", ")", "\n", "torch", ".", "cuda", ".", "manual_seed_all", "(", "new_config", ".", "seed", ")", "\n", "np", ".", "random", ".", "seed", "(", "new_config", ".", "seed", ")", "\n", "logging", ".", "info", "(", "\"Run name: {}\"", ".", "format", "(", "args", ".", "doc", ")", ")", "\n", "\n", "return", "args", ",", "new_config", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.utils.set_incremental_state": [[73, 78], ["utils._get_full_incremental_state_key"], "function", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.utils._get_full_incremental_state_key"], ["    ", "if", "config", ".", "optim", ".", "weight_decay", ">", "0", ":", "\n", "        ", "logging", ".", "info", "(", "\"Using weight decay\"", "+", "\"!\"", "*", "80", ")", "\n", "\n", "", "if", "config", ".", "optim", ".", "optimizer", "==", "'Adam'", ":", "\n", "        ", "return", "optim", ".", "Adam", "(", "parameters", ",", "lr", "=", "config", ".", "optim", ".", "lr", ",", "weight_decay", "=", "config", ".", "optim", ".", "weight_decay", ",", "\n", "betas", "=", "(", "0.9", ",", "0.999", ")", ")", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.utils.print_embed_overlap": [[80, 85], ["set", "set", "len", "print", "embed_dict.keys", "len"], "function", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.progress_bar.tensorboard_log_wrapper.print"], ["        ", "return", "optim", ".", "RMSprop", "(", "parameters", ",", "lr", "=", "config", ".", "optim", ".", "lr", ",", "weight_decay", "=", "config", ".", "optim", ".", "weight_decay", ")", "\n", "", "elif", "config", ".", "optim", ".", "optimizer", "==", "'SGD'", ":", "\n", "        ", "return", "optim", ".", "SGD", "(", "parameters", ",", "lr", "=", "config", ".", "optim", ".", "lr", ",", "momentum", "=", "0.9", ")", "\n", "", "else", ":", "\n", "        ", "raise", "NotImplementedError", "(", "'Optimizer {} not understood.'", ".", "format", "(", "config", ".", "optim", ".", "optimizer", ")", ")", "", "", "", ""]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.utils.parse_embedding": [[87, 105], ["open", "next", "line.rstrip().split", "torch.Tensor", "torch.Tensor", "line.rstrip", "float"], "function", ["None"], []], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.utils.load_embedding": [[107, 113], ["range", "len"], "function", ["None"], []], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.utils.make_positions": [[115, 128], ["tensor.ne().int", "tensor.ne", "torch.cumsum().type_as", "torch.cumsum().type_as", "torch.cumsum", "torch.cumsum"], "function", ["None"], []], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.utils.buffered_arange": [[130, 136], ["hasattr", "torch.LongTensor", "torch.LongTensor", "buffered_arange.buf.numel", "torch.arange", "torch.arange"], "function", ["None"], []], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.utils.convert_padding_direction": [[138, 158], ["src_tokens.eq", "src_tokens.size", "buffered_arange().type_as().expand_as", "src_tokens.eq.long().sum", "src_tokens.gather", "src_tokens.eq.any", "torch.remainder", "torch.remainder", "torch.remainder", "torch.remainder", "pad_mask[].any", "pad_mask[].any", "buffered_arange().type_as", "src_tokens.eq.long", "utils.buffered_arange"], "function", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.fairseq_dataset.FairseqDataset.size", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.utils.buffered_arange"], []], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.utils.item": [[160, 166], ["hasattr", "hasattr", "tensor.item"], "function", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.utils.item"], []], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.utils.clip_grad_norm_": [[168, 174], ["utils.item", "torch.norm", "torch.norm", "tensor.mul_"], "function", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.utils.item"], []], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.utils.fill_with_neg_inf": [[176, 179], ["t.float().fill_().type_as", "t.float().fill_", "float", "t.float"], "function", ["None"], []], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.utils.resolve_max_positions": [[181, 217], ["copy.deepcopy", "min", "isinstance", "isinstance", "min", "isinstance", "utils.resolve_max_positions.map_value_update"], "function", ["None"], []], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.utils.import_user_module": [[219, 233], ["getattr", "os.path.abspath", "os.path.split", "os.path.exists", "os.path.join", "os.path.exists", "sys.path.insert", "importlib.import_module", "sys.path.pop", "os.path.dirname"], "function", ["None"], []], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.utils.softmax": [[235, 240], ["torch.softmax", "torch.softmax", "x.float"], "function", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.utils.softmax", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.utils.softmax"], []], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.utils.log_softmax": [[242, 247], ["torch.log_softmax", "torch.log_softmax", "x.float"], "function", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.utils.log_softmax", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.utils.log_softmax"], []], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.utils.get_perplexity": [[249, 254], ["float", "float", "math.pow"], "function", ["None"], []], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.utils.deprecation_warning": [[256, 259], ["warnings.warn"], "function", ["None"], []], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.utils.get_activation_fn": [[261, 278], ["utils.deprecation_warning", "RuntimeError"], "function", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.utils.deprecation_warning"], []], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.utils.get_available_activation_fns": [[280, 288], ["None"], "function", ["None"], []], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.utils.eval": [[291, 297], ["model.eval", "model.train"], "function", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.utils.eval", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.None.train_ar.train"], []], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.utils.has_parameters": [[299, 305], ["next", "module.parameters"], "function", ["None"], []], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.utils.set_torch_seed": [[307, 313], ["isinstance", "torch.manual_seed", "torch.manual_seed", "torch.cuda.manual_seed", "torch.cuda.manual_seed"], "function", ["None"], []], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.optim.fairseq_optimizer.FairseqOptimizer.__init__": [[13, 16], ["object.__init__"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.dummy_dictionary.DummyDictionary.__init__"], ["    ", "def", "__init__", "(", "self", ",", "args", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "args", "=", "args", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.optim.fairseq_optimizer.FairseqOptimizer.add_args": [[17, 21], ["None"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "add_args", "(", "parser", ")", ":", "\n", "        ", "\"\"\"Add optimizer-specific arguments to the parser.\"\"\"", "\n", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.optim.fairseq_optimizer.FairseqOptimizer.optimizer": [[22, 30], ["hasattr", "isinstance", "ValueError"], "methods", ["None"], ["", "@", "property", "\n", "def", "optimizer", "(", "self", ")", ":", "\n", "        ", "\"\"\"Return a torch.optim.optimizer.Optimizer instance.\"\"\"", "\n", "if", "not", "hasattr", "(", "self", ",", "'_optimizer'", ")", ":", "\n", "            ", "raise", "NotImplementedError", "\n", "", "if", "not", "isinstance", "(", "self", ".", "_optimizer", ",", "torch", ".", "optim", ".", "Optimizer", ")", ":", "\n", "            ", "raise", "ValueError", "(", "'_optimizer must be an instance of torch.optim.Optimizer'", ")", "\n", "", "return", "self", ".", "_optimizer", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.optim.fairseq_optimizer.FairseqOptimizer.optimizer_config": [[31, 40], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "optimizer_config", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Return a kwarg dictionary that will be used to override optimizer\n        args stored in checkpoints. This allows us to load a checkpoint and\n        resume training using a different set of optimizer args, e.g., with a\n        different learning rate.\n        \"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.optim.fairseq_optimizer.FairseqOptimizer.params": [[41, 47], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "params", "(", "self", ")", ":", "\n", "        ", "\"\"\"Return an iterable of the parameters held by the optimizer.\"\"\"", "\n", "for", "param_group", "in", "self", ".", "optimizer", ".", "param_groups", ":", "\n", "            ", "for", "p", "in", "param_group", "[", "'params'", "]", ":", "\n", "                ", "yield", "p", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.optim.fairseq_optimizer.FairseqOptimizer.__getstate__": [[48, 50], ["fairseq_optimizer.FairseqOptimizer._optimizer.__getstate__"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.optim.fairseq_optimizer.FairseqOptimizer.__getstate__"], ["", "", "", "def", "__getstate__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_optimizer", ".", "__getstate__", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.optim.fairseq_optimizer.FairseqOptimizer.get_lr": [[51, 54], ["None"], "methods", ["None"], ["", "def", "get_lr", "(", "self", ")", ":", "\n", "        ", "\"\"\"Return the current learning rate.\"\"\"", "\n", "return", "self", ".", "optimizer", ".", "param_groups", "[", "0", "]", "[", "'lr'", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.optim.fairseq_optimizer.FairseqOptimizer.set_lr": [[55, 59], ["None"], "methods", ["None"], ["", "def", "set_lr", "(", "self", ",", "lr", ")", ":", "\n", "        ", "\"\"\"Set the learning rate.\"\"\"", "\n", "for", "param_group", "in", "self", ".", "optimizer", ".", "param_groups", ":", "\n", "            ", "param_group", "[", "'lr'", "]", "=", "lr", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.optim.fairseq_optimizer.FairseqOptimizer.state_dict": [[60, 63], ["fairseq_optimizer.FairseqOptimizer.optimizer.state_dict"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.iterators.EpochBatchIterator.state_dict"], ["", "", "def", "state_dict", "(", "self", ")", ":", "\n", "        ", "\"\"\"Return the optimizer's state dict.\"\"\"", "\n", "return", "self", ".", "optimizer", ".", "state_dict", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.optim.fairseq_optimizer.FairseqOptimizer.load_state_dict": [[64, 78], ["fairseq_optimizer.FairseqOptimizer.optimizer.load_state_dict", "len", "group.update"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.iterators.EpochBatchIterator.load_state_dict", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.meters.TimeMeter.update"], ["", "def", "load_state_dict", "(", "self", ",", "state_dict", ",", "optimizer_overrides", "=", "None", ")", ":", "\n", "        ", "\"\"\"Load an optimizer state dict.\n\n        In general we should prefer the configuration of the existing optimizer\n        instance (e.g., learning rate) over that found in the state_dict. This\n        allows us to resume training from a checkpoint using a new set of\n        optimizer args.\n        \"\"\"", "\n", "self", ".", "optimizer", ".", "load_state_dict", "(", "state_dict", ")", "\n", "\n", "if", "optimizer_overrides", "is", "not", "None", "and", "len", "(", "optimizer_overrides", ")", ">", "0", ":", "\n", "# override learning rate, momentum, etc. with latest values", "\n", "            ", "for", "group", "in", "self", ".", "optimizer", ".", "param_groups", ":", "\n", "                ", "group", ".", "update", "(", "optimizer_overrides", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.optim.fairseq_optimizer.FairseqOptimizer.backward": [[79, 82], ["loss.backward"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.optim.fp16_optimizer._MemoryEfficientFP16OptimizerMixin.backward"], ["", "", "", "def", "backward", "(", "self", ",", "loss", ")", ":", "\n", "        ", "\"\"\"Computes the sum of gradients of the given tensor w.r.t. graph leaves.\"\"\"", "\n", "loss", ".", "backward", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.optim.fairseq_optimizer.FairseqOptimizer.multiply_grads": [[83, 88], ["p.grad.data.mul_"], "methods", ["None"], ["", "def", "multiply_grads", "(", "self", ",", "c", ")", ":", "\n", "        ", "\"\"\"Multiplies grads by a constant *c*.\"\"\"", "\n", "for", "p", "in", "self", ".", "params", ":", "\n", "            ", "if", "p", ".", "grad", "is", "not", "None", ":", "\n", "                ", "p", ".", "grad", ".", "data", ".", "mul_", "(", "c", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.optim.fairseq_optimizer.FairseqOptimizer.clip_grad_norm": [[89, 95], ["torch.nn.utils.clip_grad_norm_", "math.sqrt", "sum", "p.grad.data.norm"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.utils.clip_grad_norm_"], ["", "", "", "def", "clip_grad_norm", "(", "self", ",", "max_norm", ")", ":", "\n", "        ", "\"\"\"Clips gradient norm.\"\"\"", "\n", "if", "max_norm", ">", "0", ":", "\n", "            ", "return", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "self", ".", "params", ",", "max_norm", ")", "\n", "", "else", ":", "\n", "            ", "return", "math", ".", "sqrt", "(", "sum", "(", "p", ".", "grad", ".", "data", ".", "norm", "(", ")", "**", "2", "for", "p", "in", "self", ".", "params", "if", "p", ".", "grad", "is", "not", "None", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.optim.fairseq_optimizer.FairseqOptimizer.step": [[96, 99], ["fairseq_optimizer.FairseqOptimizer.optimizer.step"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.lr_scheduler.polynomial_decay_schedule.PolynomialDecaySchedule.step"], ["", "", "def", "step", "(", "self", ",", "closure", "=", "None", ")", ":", "\n", "        ", "\"\"\"Performs a single optimization step.\"\"\"", "\n", "self", ".", "optimizer", ".", "step", "(", "closure", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.optim.fairseq_optimizer.FairseqOptimizer.zero_grad": [[100, 105], ["fairseq_optimizer.FairseqOptimizer.optimizer.zero_grad"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.optim.fp16_optimizer._MemoryEfficientFP16OptimizerMixin.zero_grad"], ["", "def", "zero_grad", "(", "self", ")", ":", "\n", "        ", "\"\"\"Clears the gradients of all optimized parameters.\"\"\"", "\n", "for", "p", "in", "self", ".", "params", ":", "\n", "            ", "p", ".", "grad", "=", "None", "\n", "", "self", ".", "optimizer", ".", "zero_grad", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.optim.fairseq_optimizer.FairseqOptimizer.supports_memory_efficient_fp16": [[106, 111], ["hasattr"], "methods", ["None"], ["", "@", "property", "\n", "def", "supports_memory_efficient_fp16", "(", "self", ")", ":", "\n", "        ", "if", "hasattr", "(", "self", ".", "optimizer", ",", "'supports_memory_efficient_fp16'", ")", ":", "\n", "            ", "return", "self", ".", "optimizer", ".", "supports_memory_efficient_fp16", "\n", "", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.optim.fairseq_optimizer.FairseqOptimizer.average_params": [[112, 114], ["None"], "methods", ["None"], ["", "def", "average_params", "(", "self", ")", ":", "\n", "        ", "pass", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.optim.bmuf.FairseqBMUF.__init__": [[22, 35], ["FairseqOptimizer.__init__", "bmuf.FairseqBMUF._reset_local_data", "bmuf.FairseqBMUF._optimizer.state_dict"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.dummy_dictionary.DummyDictionary.__init__", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.optim.bmuf.FairseqBMUF._reset_local_data", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.iterators.EpochBatchIterator.state_dict"], ["def", "__init__", "(", "self", ",", "args", ",", "optimizer", ")", ":", "\n", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "args", ")", "\n", "self", ".", "_optimizer", "=", "optimizer", "\n", "self", ".", "_num_updates", "=", "0", "\n", "self", ".", "sync_iter", "=", "self", ".", "args", ".", "global_sync_iter", "\n", "self", ".", "block_momentum", "=", "self", ".", "args", ".", "block_momentum", "\n", "self", ".", "block_lr", "=", "self", ".", "args", ".", "block_lr", "\n", "self", ".", "_reset_local_data", "(", ")", "\n", "self", ".", "warmup_iteration", "=", "self", ".", "args", ".", "warmup_iterations", "\n", "self", ".", "use_nbm", "=", "self", ".", "args", ".", "use_nbm", "\n", "self", ".", "initial_state", "=", "self", ".", "_optimizer", ".", "state_dict", "(", ")", "\n", "self", ".", "average_sync", "=", "self", ".", "args", ".", "average_sync", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.optim.bmuf.FairseqBMUF.add_args": [[36, 71], ["parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "add_args", "(", "parser", ")", ":", "\n", "        ", "\"\"\"Add optimizer-specific arguments to the parser.\"\"\"", "\n", "parser", ".", "add_argument", "(", "\n", "\"--block-lr\"", ",", "default", "=", "1", ",", "type", "=", "float", ",", "help", "=", "\"block learning rate for bmuf\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--block-momentum\"", ",", "\n", "default", "=", "0.875", ",", "\n", "type", "=", "float", ",", "\n", "help", "=", "\"block momentum for bmuf\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--global-sync-iter\"", ",", "\n", "default", "=", "50", ",", "\n", "type", "=", "int", ",", "\n", "help", "=", "\"Iteration for syncing global model\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--warmup-iterations\"", ",", "\n", "default", "=", "500", ",", "\n", "type", "=", "int", ",", "\n", "help", "=", "\"warmup iterations for model to broadcast\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--use-nbm\"", ",", "\n", "default", "=", "True", ",", "\n", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"Specify whether you want to use classical BM / Nesterov BM\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--average-sync\"", ",", "\n", "default", "=", "True", ",", "\n", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"Specify whether you want to average the local momentum after each sync\"", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.optim.bmuf.FairseqBMUF.optimizer": [[73, 76], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "optimizer", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_optimizer", ".", "optimizer", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.optim.bmuf.FairseqBMUF.optimizer_config": [[77, 80], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "optimizer_config", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_optimizer", ".", "optimizer_config", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.optim.bmuf.FairseqBMUF.get_lr": [[81, 83], ["bmuf.FairseqBMUF._optimizer.get_lr"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.optim.fp16_optimizer.MemoryEfficientFP16Optimizer.get_lr"], ["", "def", "get_lr", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_optimizer", ".", "get_lr", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.optim.bmuf.FairseqBMUF.set_lr": [[84, 86], ["bmuf.FairseqBMUF._optimizer.set_lr"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.optim.fp16_optimizer.MemoryEfficientFP16Optimizer.set_lr"], ["", "def", "set_lr", "(", "self", ",", "lr", ")", ":", "\n", "        ", "self", ".", "_optimizer", ".", "set_lr", "(", "lr", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.optim.bmuf.FairseqBMUF.state_dict": [[87, 89], ["bmuf.FairseqBMUF._optimizer.state_dict"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.iterators.EpochBatchIterator.state_dict"], ["", "def", "state_dict", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_optimizer", ".", "state_dict", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.optim.bmuf.FairseqBMUF.load_state_dict": [[90, 92], ["bmuf.FairseqBMUF._optimizer.load_state_dict"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.iterators.EpochBatchIterator.load_state_dict"], ["", "def", "load_state_dict", "(", "self", ",", "state_dict", ",", "optimizer_overrides", "=", "None", ")", ":", "\n", "        ", "self", ".", "_optimizer", ".", "load_state_dict", "(", "state_dict", ",", "optimizer_overrides", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.optim.bmuf.FairseqBMUF.multiply_grads": [[93, 96], ["bmuf.FairseqBMUF._optimizer.multiply_grads"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.optim.fp16_optimizer._MemoryEfficientFP16OptimizerMixin.multiply_grads"], ["", "def", "multiply_grads", "(", "self", ",", "c", ")", ":", "\n", "        ", "\"\"\"Multiplies grads by a constant *c*.\"\"\"", "\n", "self", ".", "_optimizer", ".", "multiply_grads", "(", "c", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.optim.bmuf.FairseqBMUF.clip_grad_norm": [[97, 100], ["bmuf.FairseqBMUF._optimizer.clip_grad_norm"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.optim.fp16_optimizer._MemoryEfficientFP16OptimizerMixin.clip_grad_norm"], ["", "def", "clip_grad_norm", "(", "self", ",", "max_norm", ")", ":", "\n", "        ", "\"\"\"Clips gradient norm.\"\"\"", "\n", "return", "self", ".", "_optimizer", ".", "clip_grad_norm", "(", "max_norm", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.optim.bmuf.FairseqBMUF.average_params": [[101, 103], ["bmuf.FairseqBMUF._optimizer.average_params"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.optim.adam.FairseqAdam.average_params"], ["", "def", "average_params", "(", "self", ")", ":", "\n", "        ", "self", ".", "_optimizer", ".", "average_params", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.optim.bmuf.FairseqBMUF._block_sync": [[104, 121], ["bmuf.FairseqBMUF._avg_grad_from_all_gpus", "bmuf.FairseqBMUF._calc_grad", "bmuf.FairseqBMUF._update_global_model", "bmuf.FairseqBMUF.average_params"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.optim.bmuf.FairseqBMUF._avg_grad_from_all_gpus", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.optim.bmuf.FairseqBMUF._calc_grad", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.optim.bmuf.FairseqBMUF._update_global_model", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.optim.adam.FairseqAdam.average_params"], ["", "def", "_block_sync", "(", "self", ")", ":", "\n", "# Update the global model using local models from all GPUs", "\n", "# (Step-1) Calculate grad between previously synced model and", "\n", "# currrent local model", "\n", "        ", "if", "self", ".", "block_momentum", "!=", "0", ":", "\n", "            ", "self", ".", "_calc_grad", "(", ")", "\n", "\n", "# (Step-2) Average gradient from all GPUs", "\n", "", "self", ".", "_avg_grad_from_all_gpus", "(", ")", "\n", "\n", "# (Step-3) Calculate global momentum and update the global model", "\n", "if", "self", ".", "block_momentum", "!=", "0", ":", "\n", "            ", "self", ".", "_update_global_model", "(", ")", "\n", "\n", "# (Step-4) Average local optimizer params", "\n", "", "if", "self", ".", "average_sync", ":", "\n", "            ", "self", ".", "average_params", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.optim.bmuf.FairseqBMUF._is_warmup_end": [[122, 127], ["bmuf.FairseqBMUF.get_num_updates"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.optim.bmuf.FairseqBMUF.get_num_updates"], ["", "", "def", "_is_warmup_end", "(", "self", ")", ":", "\n", "# Check whether train iterations is equal to warmup iter", "\n", "        ", "if", "self", ".", "get_num_updates", "(", ")", "==", "self", ".", "warmup_iteration", ":", "\n", "            ", "return", "True", "\n", "", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.optim.bmuf.FairseqBMUF._is_bmuf_iter": [[128, 135], ["bmuf.FairseqBMUF.get_num_updates", "bmuf.FairseqBMUF.get_num_updates"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.optim.bmuf.FairseqBMUF.get_num_updates", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.optim.bmuf.FairseqBMUF.get_num_updates"], ["", "def", "_is_bmuf_iter", "(", "self", ")", ":", "\n", "# Check whether train iterations is equal to bmuf sync iter", "\n", "        ", "if", "(", "self", ".", "get_num_updates", "(", ")", ">", "self", ".", "warmup_iteration", ")", "and", "(", "\n", "self", ".", "get_num_updates", "(", ")", "%", "self", ".", "sync_iter", "==", "0", "\n", ")", ":", "\n", "            ", "return", "True", "\n", "", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.optim.bmuf.FairseqBMUF._warmup_sync": [[136, 148], ["bmuf.FairseqBMUF._reset_local_data", "torch.broadcast", "torch.broadcast", "bmuf.FairseqBMUF._optimizer.average_params", "bmuf.FairseqBMUF._optimizer.load_state_dict"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.optim.bmuf.FairseqBMUF._reset_local_data", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.optim.adam.FairseqAdam.average_params", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.iterators.EpochBatchIterator.load_state_dict"], ["", "def", "_warmup_sync", "(", "self", ",", "root_rank", "=", "0", ")", ":", "\n", "# Broadcast the local model to all gpus", "\n", "        ", "for", "param", "in", "self", ".", "params", ":", "\n", "            ", "dist", ".", "broadcast", "(", "param", ".", "data", ",", "src", "=", "root_rank", ")", "\n", "\n", "# Update local optimizer state", "\n", "", "if", "self", ".", "average_sync", ":", "\n", "            ", "self", ".", "_optimizer", ".", "average_params", "(", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "_optimizer", ".", "load_state_dict", "(", "self", ".", "initial_state", ")", "\n", "\n", "", "self", ".", "_reset_local_data", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.optim.bmuf.FairseqBMUF.step": [[149, 157], ["bmuf.FairseqBMUF._optimizer.step", "bmuf.FairseqBMUF.set_num_updates", "bmuf.FairseqBMUF._is_warmup_end", "bmuf.FairseqBMUF._warmup_sync", "bmuf.FairseqBMUF._is_bmuf_iter", "bmuf.FairseqBMUF.get_num_updates", "bmuf.FairseqBMUF._block_sync"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.lr_scheduler.polynomial_decay_schedule.PolynomialDecaySchedule.step", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.optim.bmuf.FairseqBMUF.set_num_updates", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.optim.bmuf.FairseqBMUF._is_warmup_end", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.optim.bmuf.FairseqBMUF._warmup_sync", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.optim.bmuf.FairseqBMUF._is_bmuf_iter", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.optim.bmuf.FairseqBMUF.get_num_updates", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.optim.bmuf.FairseqBMUF._block_sync"], ["", "def", "step", "(", "self", ",", "closure", "=", "None", ")", ":", "\n", "        ", "\"\"\"Performs a single optimization step.\"\"\"", "\n", "self", ".", "_optimizer", ".", "step", "(", "closure", ")", "\n", "self", ".", "set_num_updates", "(", "self", ".", "get_num_updates", "(", ")", "+", "1", ")", "\n", "if", "self", ".", "_is_warmup_end", "(", ")", ":", "\n", "            ", "self", ".", "_warmup_sync", "(", ")", "\n", "", "elif", "self", ".", "_is_bmuf_iter", "(", ")", ":", "\n", "            ", "self", ".", "_block_sync", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.optim.bmuf.FairseqBMUF.zero_grad": [[158, 161], ["bmuf.FairseqBMUF._optimizer.zero_grad"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.optim.fp16_optimizer._MemoryEfficientFP16OptimizerMixin.zero_grad"], ["", "", "def", "zero_grad", "(", "self", ")", ":", "\n", "        ", "\"\"\"Clears the gradients of all optimized parameters.\"\"\"", "\n", "self", ".", "_optimizer", ".", "zero_grad", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.optim.bmuf.FairseqBMUF.get_num_updates": [[162, 165], ["None"], "methods", ["None"], ["", "def", "get_num_updates", "(", "self", ")", ":", "\n", "        ", "\"\"\"Get the number of parameters updates.\"\"\"", "\n", "return", "self", ".", "_num_updates", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.optim.bmuf.FairseqBMUF.set_num_updates": [[166, 169], ["None"], "methods", ["None"], ["", "def", "set_num_updates", "(", "self", ",", "num_updates", ")", ":", "\n", "        ", "\"\"\"Set the number of parameters updates.\"\"\"", "\n", "self", ".", "_num_updates", "=", "num_updates", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.optim.bmuf.FairseqBMUF._reset_local_data": [[170, 180], ["torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "zip", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "p.data.new_zeros", "p.data.new_zeros", "global_param.copy_", "p.data.size", "p.data.size"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.fairseq_dataset.FairseqDataset.size", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.fairseq_dataset.FairseqDataset.size"], ["", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "_reset_local_data", "(", "self", ")", ":", "\n", "# (Step-0) Initialize global momentum parameters and store global copy on each gpu", "\n", "        ", "self", ".", "global_params", "=", "[", "torch", ".", "zeros_like", "(", "p", ".", "data", ")", "for", "p", "in", "self", ".", "params", "]", "\n", "self", ".", "smoothed_grads", "=", "[", "p", ".", "data", ".", "new_zeros", "(", "p", ".", "data", ".", "size", "(", ")", ")", "for", "p", "in", "self", ".", "params", "]", "\n", "self", ".", "grads", "=", "[", "p", ".", "data", ".", "new_zeros", "(", "p", ".", "data", ".", "size", "(", ")", ")", "for", "p", "in", "self", ".", "params", "]", "\n", "\n", "# saving the global model locally for calculating gradient during bmuf sync", "\n", "for", "param", ",", "global_param", "in", "zip", "(", "self", ".", "params", ",", "self", ".", "global_params", ")", ":", "\n", "            ", "global_param", ".", "copy_", "(", "param", ".", "data", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.optim.bmuf.FairseqBMUF._calc_grad": [[181, 191], ["torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "enumerate", "zip"], "methods", ["None"], ["", "", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "_calc_grad", "(", "self", ")", ":", "\n", "# global_params is basically the global copy from the previously finished", "\n", "# synchronisation. param.data is local parameter after block_sync_freq", "\n", "# for the local gpu. so grad is difference between previously synced", "\n", "# model and currrent local model.", "\n", "        ", "for", "index", ",", "(", "param", ",", "global_param", ")", "in", "enumerate", "(", "\n", "zip", "(", "self", ".", "params", ",", "self", ".", "global_params", ")", "\n", ")", ":", "\n", "            ", "self", ".", "grads", "[", "index", "]", "=", "global_param", "-", "param", ".", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.optim.bmuf.FairseqBMUF._avg_grad_from_all_gpus": [[192, 197], ["enumerate", "float", "torch.all_reduce", "torch.all_reduce", "torch.get_world_size", "torch.get_world_size"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.distributed_utils.all_reduce", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.distributed_utils.all_reduce", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.distributed_utils.get_world_size", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.distributed_utils.get_world_size"], ["", "", "def", "_avg_grad_from_all_gpus", "(", "self", ")", ":", "\n", "        ", "for", "index", ",", "param", "in", "enumerate", "(", "self", ".", "params", ")", ":", "\n", "            ", "sync_para", "=", "param", ".", "data", "if", "self", ".", "block_momentum", "==", "0", "else", "self", ".", "grads", "[", "index", "]", "\n", "sync_para", "/=", "float", "(", "dist", ".", "get_world_size", "(", ")", ")", "\n", "dist", ".", "all_reduce", "(", "sync_para", ",", "op", "=", "dist", ".", "ReduceOp", ".", "SUM", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.optim.bmuf.FairseqBMUF._update_global_model": [[198, 225], ["torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "enumerate", "zip", "param.data.copy_", "global_param.copy_", "param.data.copy_"], "methods", ["None"], ["", "", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "_update_global_model", "(", "self", ")", ":", "\n", "        ", "for", "index", ",", "(", "param", ",", "global_param", ",", "smoothed_grad", ",", "grad", ")", "in", "enumerate", "(", "\n", "zip", "(", "\n", "self", ".", "params", ",", "\n", "self", ".", "global_params", ",", "\n", "self", ".", "smoothed_grads", ",", "\n", "# all gpus would share the same value of smoothed_grad, since it is", "\n", "# always computed on synchronized gradients.", "\n", "self", ".", "grads", ",", "\n", ")", "\n", ")", ":", "\n", "# global_param is basically last syncrhornized parameter. though", "\n", "# smoothed_grad is local, all processes will have same value of", "\n", "# smoothed_grad and hence param is globally synchronized copy.", "\n", "# smoothed_grad(t) = BM * smoothed_grad(t-1) + BM_lr * grad(t)", "\n", "            ", "smoothed_grad", "=", "self", ".", "block_momentum", "*", "smoothed_grad", "+", "self", ".", "block_lr", "*", "grad", "\n", "param", ".", "data", ".", "copy_", "(", "global_param", "-", "smoothed_grad", ")", "\n", "\n", "# A Nesterov momentum here is to do a partial weight update before", "\n", "# calculating the gradient", "\n", "if", "self", ".", "use_nbm", ":", "\n", "                ", "param", ".", "data", ".", "copy_", "(", "param", ".", "data", "-", "self", ".", "block_momentum", "*", "smoothed_grad", ")", "\n", "\n", "# backup for the next synchronization.", "\n", "", "self", ".", "smoothed_grads", "[", "index", "]", "=", "smoothed_grad", "\n", "global_param", ".", "copy_", "(", "param", ".", "data", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.optim.fp16_optimizer.DynamicLossScaler.__init__": [[15, 28], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "\n", "self", ",", "init_scale", "=", "2.", "**", "15", ",", "scale_factor", "=", "2.", ",", "scale_window", "=", "2000", ",", "\n", "tolerance", "=", "0.05", ",", "threshold", "=", "None", ",", "\n", ")", ":", "\n", "        ", "self", ".", "loss_scale", "=", "init_scale", "\n", "self", ".", "scale_factor", "=", "scale_factor", "\n", "self", ".", "scale_window", "=", "scale_window", "\n", "self", ".", "tolerance", "=", "tolerance", "\n", "self", ".", "threshold", "=", "threshold", "\n", "self", ".", "_iter", "=", "0", "\n", "self", ".", "_last_overflow_iter", "=", "-", "1", "\n", "self", ".", "_last_rescale_iter", "=", "-", "1", "\n", "self", ".", "_overflows_since_rescale", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.optim.fp16_optimizer.DynamicLossScaler.update_scale": [[29, 43], ["float", "fp16_optimizer.DynamicLossScaler._decrease_loss_scale"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.optim.fp16_optimizer.DynamicLossScaler._decrease_loss_scale"], ["", "def", "update_scale", "(", "self", ",", "overflow", ")", ":", "\n", "        ", "iter_since_rescale", "=", "self", ".", "_iter", "-", "self", ".", "_last_rescale_iter", "\n", "if", "overflow", ":", "\n", "            ", "self", ".", "_last_overflow_iter", "=", "self", ".", "_iter", "\n", "self", ".", "_overflows_since_rescale", "+=", "1", "\n", "pct_overflow", "=", "self", ".", "_overflows_since_rescale", "/", "float", "(", "iter_since_rescale", ")", "\n", "if", "pct_overflow", ">=", "self", ".", "tolerance", ":", "\n", "                ", "self", ".", "_decrease_loss_scale", "(", ")", "\n", "self", ".", "_last_rescale_iter", "=", "self", ".", "_iter", "\n", "self", ".", "_overflows_since_rescale", "=", "0", "\n", "", "", "elif", "(", "self", ".", "_iter", "-", "self", ".", "_last_overflow_iter", ")", "%", "self", ".", "scale_window", "==", "0", ":", "\n", "            ", "self", ".", "loss_scale", "*=", "self", ".", "scale_factor", "\n", "self", ".", "_last_rescale_iter", "=", "self", ".", "_iter", "\n", "", "self", ".", "_iter", "+=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.optim.fp16_optimizer.DynamicLossScaler._decrease_loss_scale": [[44, 48], ["max"], "methods", ["None"], ["", "def", "_decrease_loss_scale", "(", "self", ")", ":", "\n", "        ", "self", ".", "loss_scale", "/=", "self", ".", "scale_factor", "\n", "if", "self", ".", "threshold", "is", "not", "None", ":", "\n", "            ", "self", ".", "loss_scale", "=", "max", "(", "self", ".", "loss_scale", ",", "self", ".", "threshold", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.optim.fp16_optimizer.DynamicLossScaler.has_overflow": [[49, 55], ["float"], "methods", ["None"], ["", "", "@", "staticmethod", "\n", "def", "has_overflow", "(", "grad_norm", ")", ":", "\n", "# detect inf and nan", "\n", "        ", "if", "grad_norm", "==", "float", "(", "'inf'", ")", "or", "grad_norm", "!=", "grad_norm", ":", "\n", "            ", "return", "True", "\n", "", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.optim.fp16_optimizer._FP16OptimizerMixin.__init__": [[59, 62], ["object.__init__"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.dummy_dictionary.DummyDictionary.__init__"], ["    ", "def", "__init__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "# forward __init__ call to the next class in mro(method resolution order)", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.optim.fp16_optimizer._FP16OptimizerMixin.build_fp32_params": [[63, 76], ["sum", "params[].new().float().new", "torch.nn.Parameter", "torch.nn.Parameter.data.new", "p.data.numel", "fp32_params[].copy_", "p.data.numel", "params[].new().float", "p.data.view", "params[].new"], "methods", ["None"], ["", "@", "classmethod", "\n", "def", "build_fp32_params", "(", "cls", ",", "params", ")", ":", "\n", "# create FP32 copy of parameters and grads", "\n", "        ", "total_param_size", "=", "sum", "(", "p", ".", "data", ".", "numel", "(", ")", "for", "p", "in", "params", ")", "\n", "fp32_params", "=", "params", "[", "0", "]", ".", "new", "(", "0", ")", ".", "float", "(", ")", ".", "new", "(", "total_param_size", ")", "\n", "offset", "=", "0", "\n", "for", "p", "in", "params", ":", "\n", "            ", "numel", "=", "p", ".", "data", ".", "numel", "(", ")", "\n", "fp32_params", "[", "offset", ":", "offset", "+", "numel", "]", ".", "copy_", "(", "p", ".", "data", ".", "view", "(", "-", "1", ")", ")", "\n", "offset", "+=", "numel", "\n", "", "fp32_params", "=", "torch", ".", "nn", ".", "Parameter", "(", "fp32_params", ")", "\n", "fp32_params", ".", "grad", "=", "fp32_params", ".", "data", ".", "new", "(", "total_param_size", ")", "\n", "return", "fp32_params", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.optim.fp16_optimizer._FP16OptimizerMixin.state_dict": [[77, 82], ["fp16_optimizer._FP16OptimizerMixin.fp32_optimizer.state_dict"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.iterators.EpochBatchIterator.state_dict"], ["", "def", "state_dict", "(", "self", ")", ":", "\n", "        ", "\"\"\"Return the optimizer's state dict.\"\"\"", "\n", "state_dict", "=", "self", ".", "fp32_optimizer", ".", "state_dict", "(", ")", "\n", "state_dict", "[", "'loss_scale'", "]", "=", "self", ".", "scaler", ".", "loss_scale", "\n", "return", "state_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.optim.fp16_optimizer._FP16OptimizerMixin.load_state_dict": [[83, 94], ["fp16_optimizer._FP16OptimizerMixin.fp32_optimizer.load_state_dict"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.iterators.EpochBatchIterator.load_state_dict"], ["", "def", "load_state_dict", "(", "self", ",", "state_dict", ",", "optimizer_overrides", "=", "None", ")", ":", "\n", "        ", "\"\"\"Load an optimizer state dict.\n\n        In general we should prefer the configuration of the existing optimizer\n        instance (e.g., learning rate) over that found in the state_dict. This\n        allows us to resume training from a checkpoint using a new set of\n        optimizer args.\n        \"\"\"", "\n", "if", "'loss_scale'", "in", "state_dict", ":", "\n", "            ", "self", ".", "scaler", ".", "loss_scale", "=", "state_dict", "[", "'loss_scale'", "]", "\n", "", "self", ".", "fp32_optimizer", ".", "load_state_dict", "(", "state_dict", ",", "optimizer_overrides", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.optim.fp16_optimizer._FP16OptimizerMixin.backward": [[95, 105], ["loss.backward"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.optim.fp16_optimizer._MemoryEfficientFP16OptimizerMixin.backward"], ["", "def", "backward", "(", "self", ",", "loss", ")", ":", "\n", "        ", "\"\"\"Computes the sum of gradients of the given tensor w.r.t. graph leaves.\n\n        Compared to :func:`fairseq.optim.FairseqOptimizer.backward`, this\n        function additionally dynamically scales the loss to avoid gradient\n        underflow.\n        \"\"\"", "\n", "loss", "=", "loss", "*", "self", ".", "scaler", ".", "loss_scale", "\n", "loss", ".", "backward", "(", ")", "\n", "self", ".", "_needs_sync", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.optim.fp16_optimizer._FP16OptimizerMixin._sync_fp16_grads_to_fp32": [[106, 122], ["fp16_optimizer._FP16OptimizerMixin.fp32_params.grad.data.mul_", "grad_data.numel", "fp16_optimizer._FP16OptimizerMixin.fp32_params.grad.data[].copy_", "p.data.new_zeros", "grad_data.view"], "methods", ["None"], ["", "def", "_sync_fp16_grads_to_fp32", "(", "self", ",", "multiply_grads", "=", "1.", ")", ":", "\n", "        ", "if", "self", ".", "_needs_sync", ":", "\n", "# copy FP16 grads to FP32", "\n", "            ", "offset", "=", "0", "\n", "for", "p", "in", "self", ".", "fp16_params", ":", "\n", "                ", "if", "not", "p", ".", "requires_grad", ":", "\n", "                    ", "continue", "\n", "", "grad_data", "=", "p", ".", "grad", ".", "data", "if", "p", ".", "grad", "is", "not", "None", "else", "p", ".", "data", ".", "new_zeros", "(", "p", ".", "data", ".", "shape", ")", "\n", "numel", "=", "grad_data", ".", "numel", "(", ")", "\n", "self", ".", "fp32_params", ".", "grad", ".", "data", "[", "offset", ":", "offset", "+", "numel", "]", ".", "copy_", "(", "grad_data", ".", "view", "(", "-", "1", ")", ")", "\n", "offset", "+=", "numel", "\n", "\n", "# correct for dynamic loss scaler", "\n", "", "self", ".", "fp32_params", ".", "grad", ".", "data", ".", "mul_", "(", "multiply_grads", "/", "self", ".", "scaler", ".", "loss_scale", ")", "\n", "\n", "self", ".", "_needs_sync", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.optim.fp16_optimizer._FP16OptimizerMixin.multiply_grads": [[123, 129], ["fp16_optimizer._FP16OptimizerMixin._sync_fp16_grads_to_fp32", "fp16_optimizer._FP16OptimizerMixin.fp32_params.grad.data.mul_"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.optim.fp16_optimizer._FP16OptimizerMixin._sync_fp16_grads_to_fp32"], ["", "", "def", "multiply_grads", "(", "self", ",", "c", ")", ":", "\n", "        ", "\"\"\"Multiplies grads by a constant ``c``.\"\"\"", "\n", "if", "self", ".", "_needs_sync", ":", "\n", "            ", "self", ".", "_sync_fp16_grads_to_fp32", "(", "c", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "fp32_params", ".", "grad", ".", "data", ".", "mul_", "(", "c", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.optim.fp16_optimizer._FP16OptimizerMixin.clip_grad_norm": [[130, 149], ["fp16_optimizer._FP16OptimizerMixin._sync_fp16_grads_to_fp32", "fairseq.utils.clip_grad_norm_", "fp16_optimizer.DynamicLossScaler.has_overflow", "fp16_optimizer._FP16OptimizerMixin.scaler.update_scale", "OverflowError", "FloatingPointError", "str"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.optim.fp16_optimizer._FP16OptimizerMixin._sync_fp16_grads_to_fp32", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.utils.clip_grad_norm_", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.optim.fp16_optimizer.DynamicLossScaler.has_overflow", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.optim.fp16_optimizer.DynamicLossScaler.update_scale"], ["", "", "def", "clip_grad_norm", "(", "self", ",", "max_norm", ")", ":", "\n", "        ", "\"\"\"Clips gradient norm and updates dynamic loss scaler.\"\"\"", "\n", "self", ".", "_sync_fp16_grads_to_fp32", "(", ")", "\n", "grad_norm", "=", "utils", ".", "clip_grad_norm_", "(", "self", ".", "fp32_params", ".", "grad", ".", "data", ",", "max_norm", ")", "\n", "\n", "# detect overflow and adjust loss scale", "\n", "overflow", "=", "DynamicLossScaler", ".", "has_overflow", "(", "grad_norm", ")", "\n", "self", ".", "scaler", ".", "update_scale", "(", "overflow", ")", "\n", "if", "overflow", ":", "\n", "            ", "if", "self", ".", "scaler", ".", "loss_scale", "<=", "self", ".", "min_loss_scale", ":", "\n", "# Use FloatingPointError as an uncommon error that parent", "\n", "# functions can safely catch to stop training.", "\n", "                ", "raise", "FloatingPointError", "(", "(", "\n", "'Minimum loss scale reached ({}). Your loss is probably exploding. '", "\n", "'Try lowering the learning rate, using gradient clipping or '", "\n", "'increasing the batch size.'", "\n", ")", ".", "format", "(", "self", ".", "min_loss_scale", ")", ")", "\n", "", "raise", "OverflowError", "(", "'setting loss scale to: '", "+", "str", "(", "self", ".", "scaler", ".", "loss_scale", ")", ")", "\n", "", "return", "grad_norm", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.optim.fp16_optimizer._FP16OptimizerMixin.step": [[150, 163], ["fp16_optimizer._FP16OptimizerMixin._sync_fp16_grads_to_fp32", "fp16_optimizer._FP16OptimizerMixin.fp32_optimizer.step", "p.data.numel", "p.data.copy_", "fp16_optimizer._FP16OptimizerMixin.fp32_params.data[].view_as"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.optim.fp16_optimizer._FP16OptimizerMixin._sync_fp16_grads_to_fp32", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.lr_scheduler.polynomial_decay_schedule.PolynomialDecaySchedule.step"], ["", "def", "step", "(", "self", ",", "closure", "=", "None", ")", ":", "\n", "        ", "\"\"\"Performs a single optimization step.\"\"\"", "\n", "self", ".", "_sync_fp16_grads_to_fp32", "(", ")", "\n", "self", ".", "fp32_optimizer", ".", "step", "(", "closure", ")", "\n", "\n", "# copy FP32 params back into FP16 model", "\n", "offset", "=", "0", "\n", "for", "p", "in", "self", ".", "fp16_params", ":", "\n", "            ", "if", "not", "p", ".", "requires_grad", ":", "\n", "                ", "continue", "\n", "", "numel", "=", "p", ".", "data", ".", "numel", "(", ")", "\n", "p", ".", "data", ".", "copy_", "(", "self", ".", "fp32_params", ".", "data", "[", "offset", ":", "offset", "+", "numel", "]", ".", "view_as", "(", "p", ".", "data", ")", ")", "\n", "offset", "+=", "numel", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.optim.fp16_optimizer._FP16OptimizerMixin.zero_grad": [[164, 169], ["None"], "methods", ["None"], ["", "", "def", "zero_grad", "(", "self", ")", ":", "\n", "        ", "\"\"\"Clears the gradients of all optimized parameters.\"\"\"", "\n", "for", "p", "in", "self", ".", "fp16_params", ":", "\n", "            ", "p", ".", "grad", "=", "None", "\n", "", "self", ".", "_needs_sync", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.optim.fp16_optimizer.FP16Optimizer.__init__": [[176, 199], ["super().__init__", "fp16_optimizer.DynamicLossScaler", "getattr", "len", "ValueError"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.dummy_dictionary.DummyDictionary.__init__"], ["def", "__init__", "(", "self", ",", "args", ",", "params", ",", "fp32_optimizer", ",", "fp32_params", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "args", ")", "\n", "self", ".", "fp16_params", "=", "params", "\n", "self", ".", "fp32_optimizer", "=", "fp32_optimizer", "\n", "self", ".", "fp32_params", "=", "fp32_params", "\n", "\n", "if", "getattr", "(", "args", ",", "'fp16_scale_window'", ",", "None", ")", "is", "None", ":", "\n", "            ", "if", "len", "(", "args", ".", "update_freq", ")", ">", "1", ":", "\n", "                ", "raise", "ValueError", "(", "\n", "'--fp16-scale-window must be given explicitly when using a '", "\n", "'custom --update-freq schedule'", "\n", ")", "\n", "", "scale_window", "=", "2", "**", "14", "/", "args", ".", "distributed_world_size", "/", "args", ".", "update_freq", "[", "0", "]", "\n", "", "else", ":", "\n", "            ", "scale_window", "=", "args", ".", "fp16_scale_window", "\n", "\n", "", "self", ".", "scaler", "=", "DynamicLossScaler", "(", "\n", "init_scale", "=", "args", ".", "fp16_init_scale", ",", "\n", "scale_window", "=", "scale_window", ",", "\n", "tolerance", "=", "args", ".", "fp16_scale_tolerance", ",", "\n", "threshold", "=", "args", ".", "threshold_loss_scale", ",", "\n", ")", "\n", "self", ".", "min_loss_scale", "=", "self", ".", "args", ".", "min_loss_scale", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.optim.fp16_optimizer.FP16Optimizer.build_optimizer": [[200, 210], ["cls.build_fp32_params", "fairseq.optim.build_optimizer", "cls"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.optim.fp16_optimizer._FP16OptimizerMixin.build_fp32_params", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.optim.fp16_optimizer.MemoryEfficientFP16Optimizer.build_optimizer"], ["", "@", "classmethod", "\n", "def", "build_optimizer", "(", "cls", ",", "args", ",", "params", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            args (argparse.Namespace): fairseq args\n            params (iterable): iterable of parameters to optimize\n        \"\"\"", "\n", "fp32_params", "=", "cls", ".", "build_fp32_params", "(", "params", ")", "\n", "fp32_optimizer", "=", "optim", ".", "build_optimizer", "(", "args", ",", "[", "fp32_params", "]", ")", "\n", "return", "cls", "(", "args", ",", "params", ",", "fp32_optimizer", ",", "fp32_params", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.optim.fp16_optimizer.FP16Optimizer.optimizer": [[211, 214], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "optimizer", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "fp32_optimizer", ".", "optimizer", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.optim.fp16_optimizer.FP16Optimizer.optimizer_config": [[215, 218], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "optimizer_config", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "fp32_optimizer", ".", "optimizer_config", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.optim.fp16_optimizer.FP16Optimizer.get_lr": [[219, 221], ["fp16_optimizer.FP16Optimizer.fp32_optimizer.get_lr"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.optim.fp16_optimizer.MemoryEfficientFP16Optimizer.get_lr"], ["", "def", "get_lr", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "fp32_optimizer", ".", "get_lr", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.optim.fp16_optimizer.FP16Optimizer.set_lr": [[222, 224], ["fp16_optimizer.FP16Optimizer.fp32_optimizer.set_lr"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.optim.fp16_optimizer.MemoryEfficientFP16Optimizer.set_lr"], ["", "def", "set_lr", "(", "self", ",", "lr", ")", ":", "\n", "        ", "self", ".", "fp32_optimizer", ".", "set_lr", "(", "lr", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.optim.fp16_optimizer._MemoryEfficientFP16OptimizerMixin.__init__": [[228, 231], ["object.__init__"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.dummy_dictionary.DummyDictionary.__init__"], ["    ", "def", "__init__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "# forward __init__ call to the next class in mro(method resolution order)", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.optim.fp16_optimizer._MemoryEfficientFP16OptimizerMixin.state_dict": [[232, 237], ["fp16_optimizer._MemoryEfficientFP16OptimizerMixin.wrapped_optimizer.state_dict"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.iterators.EpochBatchIterator.state_dict"], ["", "def", "state_dict", "(", "self", ")", ":", "\n", "        ", "\"\"\"Return the optimizer's state dict.\"\"\"", "\n", "state_dict", "=", "self", ".", "wrapped_optimizer", ".", "state_dict", "(", ")", "\n", "state_dict", "[", "'loss_scale'", "]", "=", "self", ".", "scaler", ".", "loss_scale", "\n", "return", "state_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.optim.fp16_optimizer._MemoryEfficientFP16OptimizerMixin.load_state_dict": [[238, 269], ["fp16_optimizer._MemoryEfficientFP16OptimizerMixin.wrapped_optimizer.load_state_dict", "state_dict[].items", "zip", "itertools.chain", "itertools.chain"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.iterators.EpochBatchIterator.load_state_dict"], ["", "def", "load_state_dict", "(", "self", ",", "state_dict", ",", "optimizer_overrides", "=", "None", ")", ":", "\n", "        ", "\"\"\"Load an optimizer state dict.\n\n        In general we should prefer the configuration of the existing optimizer\n        instance (e.g., learning rate) over that found in the state_dict. This\n        allows us to resume training from a checkpoint using a new set of\n        optimizer args.\n        \"\"\"", "\n", "if", "'loss_scale'", "in", "state_dict", ":", "\n", "            ", "self", ".", "scaler", ".", "loss_scale", "=", "state_dict", "[", "'loss_scale'", "]", "\n", "\n", "", "self", ".", "wrapped_optimizer", ".", "load_state_dict", "(", "state_dict", ",", "optimizer_overrides", ")", "\n", "\n", "# Hack: PyTorch automatically casts the optimizer state to match the", "\n", "# type of the current parameters. But with --memory-efficient-fp16 the", "\n", "# params are FP16 while the optimizer state is FP32 and we don't want", "\n", "# to cast. A workaround is to manually copy back the original state", "\n", "# after the optimizer has been loaded.", "\n", "groups", "=", "self", ".", "optimizer", ".", "param_groups", "\n", "saved_groups", "=", "state_dict", "[", "'param_groups'", "]", "\n", "id_map", "=", "{", "\n", "old_id", ":", "p", "\n", "for", "old_id", ",", "p", "in", "zip", "(", "\n", "chain", "(", "*", "(", "g", "[", "'params'", "]", "for", "g", "in", "saved_groups", ")", ")", ",", "\n", "chain", "(", "*", "(", "g", "[", "'params'", "]", "for", "g", "in", "groups", ")", ")", "\n", ")", "\n", "}", "\n", "for", "k", ",", "v", "in", "state_dict", "[", "'state'", "]", ".", "items", "(", ")", ":", "\n", "            ", "if", "k", "in", "id_map", ":", "\n", "                ", "param", "=", "id_map", "[", "k", "]", "\n", "self", ".", "optimizer", ".", "state", "[", "param", "]", "=", "v", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.optim.fp16_optimizer._MemoryEfficientFP16OptimizerMixin.backward": [[270, 280], ["loss.backward"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.optim.fp16_optimizer._MemoryEfficientFP16OptimizerMixin.backward"], ["", "", "", "def", "backward", "(", "self", ",", "loss", ")", ":", "\n", "        ", "\"\"\"Computes the sum of gradients of the given tensor w.r.t. graph leaves.\n\n        Compared to :func:`fairseq.optim.FairseqOptimizer.backward`, this\n        function additionally dynamically scales the loss to avoid gradient\n        underflow.\n        \"\"\"", "\n", "loss", "=", "loss", "*", "self", ".", "scaler", ".", "loss_scale", "\n", "loss", ".", "backward", "(", ")", "\n", "self", ".", "_grads_are_scaled", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.optim.fp16_optimizer._MemoryEfficientFP16OptimizerMixin._unscale_grads": [[281, 289], ["fp16_optimizer._MemoryEfficientFP16OptimizerMixin.wrapped_optimizer.multiply_grads"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.optim.fp16_optimizer._MemoryEfficientFP16OptimizerMixin.multiply_grads"], ["", "def", "_unscale_grads", "(", "self", ",", "multiply_grads", "=", "1.", ")", ":", "\n", "        ", "if", "self", ".", "_grads_are_scaled", ":", "\n", "            ", "self", ".", "_grads_are_scaled", "=", "False", "\n", "\n", "# correct for dynamic loss scaler", "\n", "self", ".", "wrapped_optimizer", ".", "multiply_grads", "(", "multiply_grads", "/", "self", ".", "scaler", ".", "loss_scale", ")", "\n", "", "else", ":", "\n", "            ", "assert", "multiply_grads", "==", "1.", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.optim.fp16_optimizer._MemoryEfficientFP16OptimizerMixin.multiply_grads": [[290, 296], ["fp16_optimizer._MemoryEfficientFP16OptimizerMixin._unscale_grads", "fp16_optimizer._MemoryEfficientFP16OptimizerMixin.wrapped_optimizer.multiply_grads"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.optim.fp16_optimizer._MemoryEfficientFP16OptimizerMixin._unscale_grads", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.optim.fp16_optimizer._MemoryEfficientFP16OptimizerMixin.multiply_grads"], ["", "", "def", "multiply_grads", "(", "self", ",", "c", ")", ":", "\n", "        ", "\"\"\"Multiplies grads by a constant *c*.\"\"\"", "\n", "if", "self", ".", "_grads_are_scaled", ":", "\n", "            ", "self", ".", "_unscale_grads", "(", "c", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "wrapped_optimizer", ".", "multiply_grads", "(", "c", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.optim.fp16_optimizer._MemoryEfficientFP16OptimizerMixin.clip_grad_norm": [[297, 317], ["fp16_optimizer._MemoryEfficientFP16OptimizerMixin._unscale_grads", "fp16_optimizer._MemoryEfficientFP16OptimizerMixin.wrapped_optimizer.clip_grad_norm", "fp16_optimizer.DynamicLossScaler.has_overflow", "fp16_optimizer._MemoryEfficientFP16OptimizerMixin.scaler.update_scale", "OverflowError", "FloatingPointError", "str"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.optim.fp16_optimizer._MemoryEfficientFP16OptimizerMixin._unscale_grads", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.optim.fp16_optimizer._MemoryEfficientFP16OptimizerMixin.clip_grad_norm", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.optim.fp16_optimizer.DynamicLossScaler.has_overflow", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.optim.fp16_optimizer.DynamicLossScaler.update_scale"], ["", "", "def", "clip_grad_norm", "(", "self", ",", "max_norm", ")", ":", "\n", "        ", "\"\"\"Clips gradient norm and updates dynamic loss scaler.\"\"\"", "\n", "self", ".", "_unscale_grads", "(", ")", "\n", "grad_norm", "=", "self", ".", "wrapped_optimizer", ".", "clip_grad_norm", "(", "max_norm", ")", "\n", "\n", "# detect overflow and adjust loss scale", "\n", "overflow", "=", "DynamicLossScaler", ".", "has_overflow", "(", "grad_norm", ")", "\n", "self", ".", "scaler", ".", "update_scale", "(", "overflow", ")", "\n", "if", "overflow", ":", "\n", "            ", "if", "self", ".", "scaler", ".", "loss_scale", "<=", "self", ".", "min_loss_scale", ":", "\n", "# Use FloatingPointError as an uncommon error that parent", "\n", "# functions can safely catch to stop training.", "\n", "                ", "raise", "FloatingPointError", "(", "(", "\n", "'Minimum loss scale reached ({}). Your loss is probably exploding. '", "\n", "'Try lowering the learning rate, using gradient clipping or '", "\n", "'increasing the batch size.'", "\n", ")", ".", "format", "(", "self", ".", "min_loss_scale", ")", ")", "\n", "", "raise", "OverflowError", "(", "'setting loss scale to: '", "+", "str", "(", "self", ".", "scaler", ".", "loss_scale", ")", ")", "\n", "\n", "", "return", "grad_norm", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.optim.fp16_optimizer._MemoryEfficientFP16OptimizerMixin.step": [[318, 322], ["fp16_optimizer._MemoryEfficientFP16OptimizerMixin._unscale_grads", "fp16_optimizer._MemoryEfficientFP16OptimizerMixin.wrapped_optimizer.step"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.optim.fp16_optimizer._MemoryEfficientFP16OptimizerMixin._unscale_grads", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.lr_scheduler.polynomial_decay_schedule.PolynomialDecaySchedule.step"], ["", "def", "step", "(", "self", ",", "closure", "=", "None", ")", ":", "\n", "        ", "\"\"\"Performs a single optimization step.\"\"\"", "\n", "self", ".", "_unscale_grads", "(", ")", "\n", "self", ".", "wrapped_optimizer", ".", "step", "(", "closure", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.optim.fp16_optimizer._MemoryEfficientFP16OptimizerMixin.zero_grad": [[323, 327], ["fp16_optimizer._MemoryEfficientFP16OptimizerMixin.wrapped_optimizer.zero_grad"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.optim.fp16_optimizer._MemoryEfficientFP16OptimizerMixin.zero_grad"], ["", "def", "zero_grad", "(", "self", ")", ":", "\n", "        ", "\"\"\"Clears the gradients of all optimized parameters.\"\"\"", "\n", "self", ".", "wrapped_optimizer", ".", "zero_grad", "(", ")", "\n", "self", ".", "_grads_are_scaled", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.optim.fp16_optimizer.MemoryEfficientFP16Optimizer.__init__": [[345, 371], ["super().__init__", "fp16_optimizer.DynamicLossScaler", "ValueError", "getattr", "len", "ValueError"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.dummy_dictionary.DummyDictionary.__init__"], ["def", "__init__", "(", "self", ",", "args", ",", "params", ",", "optimizer", ")", ":", "\n", "        ", "if", "not", "optimizer", ".", "supports_memory_efficient_fp16", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "'Unsupported optimizer: {}'", ".", "format", "(", "optimizer", ".", "__class__", ".", "__name__", ")", "\n", ")", "\n", "\n", "", "super", "(", ")", ".", "__init__", "(", "args", ")", "\n", "self", ".", "wrapped_optimizer", "=", "optimizer", "\n", "\n", "if", "getattr", "(", "args", ",", "'fp16_scale_window'", ",", "None", ")", "is", "None", ":", "\n", "            ", "if", "len", "(", "args", ".", "update_freq", ")", ">", "1", ":", "\n", "                ", "raise", "ValueError", "(", "\n", "'--fp16-scale-window must be given explicitly when using a '", "\n", "'custom --update-freq schedule'", "\n", ")", "\n", "", "scale_window", "=", "2", "**", "14", "/", "args", ".", "distributed_world_size", "/", "args", ".", "update_freq", "[", "0", "]", "\n", "", "else", ":", "\n", "            ", "scale_window", "=", "args", ".", "fp16_scale_window", "\n", "\n", "", "self", ".", "scaler", "=", "DynamicLossScaler", "(", "\n", "init_scale", "=", "args", ".", "fp16_init_scale", ",", "\n", "scale_window", "=", "scale_window", ",", "\n", "tolerance", "=", "args", ".", "fp16_scale_tolerance", ",", "\n", "threshold", "=", "args", ".", "threshold_loss_scale", ",", "\n", ")", "\n", "self", ".", "min_loss_scale", "=", "self", ".", "args", ".", "min_loss_scale", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.optim.fp16_optimizer.MemoryEfficientFP16Optimizer.build_optimizer": [[372, 381], ["fairseq.optim.build_optimizer", "cls"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.optim.fp16_optimizer.MemoryEfficientFP16Optimizer.build_optimizer"], ["", "@", "classmethod", "\n", "def", "build_optimizer", "(", "cls", ",", "args", ",", "params", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            args (argparse.Namespace): fairseq args\n            params (iterable): iterable of parameters to optimize\n        \"\"\"", "\n", "fp16_optimizer", "=", "optim", ".", "build_optimizer", "(", "args", ",", "params", ")", "\n", "return", "cls", "(", "args", ",", "params", ",", "fp16_optimizer", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.optim.fp16_optimizer.MemoryEfficientFP16Optimizer.optimizer": [[382, 385], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "optimizer", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "wrapped_optimizer", ".", "optimizer", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.optim.fp16_optimizer.MemoryEfficientFP16Optimizer.optimizer_config": [[386, 389], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "optimizer_config", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "wrapped_optimizer", ".", "optimizer_config", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.optim.fp16_optimizer.MemoryEfficientFP16Optimizer.get_lr": [[390, 392], ["fp16_optimizer.MemoryEfficientFP16Optimizer.wrapped_optimizer.get_lr"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.optim.fp16_optimizer.MemoryEfficientFP16Optimizer.get_lr"], ["", "def", "get_lr", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "wrapped_optimizer", ".", "get_lr", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.optim.fp16_optimizer.MemoryEfficientFP16Optimizer.set_lr": [[393, 395], ["fp16_optimizer.MemoryEfficientFP16Optimizer.wrapped_optimizer.set_lr"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.optim.fp16_optimizer.MemoryEfficientFP16Optimizer.set_lr"], ["", "def", "set_lr", "(", "self", ",", "lr", ")", ":", "\n", "        ", "self", ".", "wrapped_optimizer", ".", "set_lr", "(", "lr", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.optim.adam.FairseqAdam.__init__": [[25, 35], ["FairseqOptimizer.__init__", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "adam.Adam", "adam.FusedAdam", "adam.Adam"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.dummy_dictionary.DummyDictionary.__init__"], ["def", "__init__", "(", "self", ",", "args", ",", "params", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "args", ")", "\n", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "            ", "try", ":", "\n", "                ", "from", "apex", ".", "optimizers", "import", "FusedAdam", "as", "_FusedAdam", "# noqa", "\n", "self", ".", "_optimizer", "=", "FusedAdam", "(", "params", ",", "**", "self", ".", "optimizer_config", ")", "\n", "", "except", "ImportError", ":", "\n", "                ", "self", ".", "_optimizer", "=", "Adam", "(", "params", ",", "**", "self", ".", "optimizer_config", ")", "\n", "", "", "else", ":", "\n", "            ", "self", ".", "_optimizer", "=", "Adam", "(", "params", ",", "**", "self", ".", "optimizer_config", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.optim.adam.FairseqAdam.add_args": [[36, 46], ["parser.add_argument", "parser.add_argument", "parser.add_argument"], "methods", ["None"], ["", "", "@", "staticmethod", "\n", "def", "add_args", "(", "parser", ")", ":", "\n", "        ", "\"\"\"Add optimizer-specific arguments to the parser.\"\"\"", "\n", "# fmt: off", "\n", "parser", ".", "add_argument", "(", "'--adam-betas'", ",", "default", "=", "'(0.9, 0.999)'", ",", "metavar", "=", "'B'", ",", "\n", "help", "=", "'betas for Adam optimizer'", ")", "\n", "parser", ".", "add_argument", "(", "'--adam-eps'", ",", "type", "=", "float", ",", "default", "=", "1e-8", ",", "metavar", "=", "'D'", ",", "\n", "help", "=", "'epsilon for Adam optimizer'", ")", "\n", "parser", ".", "add_argument", "(", "'--weight-decay'", ",", "'--wd'", ",", "default", "=", "0.0", ",", "type", "=", "float", ",", "metavar", "=", "'WD'", ",", "\n", "help", "=", "'weight decay'", ")", "\n", "# fmt: on", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.optim.adam.FairseqAdam.optimizer_config": [[48, 61], ["eval"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.utils.eval"], ["", "@", "property", "\n", "def", "optimizer_config", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Return a kwarg dictionary that will be used to override optimizer\n        args stored in checkpoints. This allows us to load a checkpoint and\n        resume training using a different set of optimizer args, e.g., with a\n        different learning rate.\n        \"\"\"", "\n", "return", "{", "\n", "'lr'", ":", "self", ".", "args", ".", "lr", "[", "0", "]", ",", "\n", "'betas'", ":", "eval", "(", "self", ".", "args", ".", "adam_betas", ")", ",", "\n", "'eps'", ":", "self", ".", "args", ".", "adam_eps", ",", "\n", "'weight_decay'", ":", "self", ".", "args", ".", "weight_decay", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.optim.adam.FairseqAdam.average_params": [[63, 73], ["adam.FairseqAdam.optimizer.state_dict", "float", "state_dict[].items", "torch.get_world_size", "torch.get_world_size", "torch.get_world_size", "torch.all_reduce", "torch.all_reduce", "torch.all_reduce", "torch.all_reduce", "torch.all_reduce", "torch.all_reduce"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.iterators.EpochBatchIterator.state_dict", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.distributed_utils.get_world_size", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.distributed_utils.get_world_size", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.distributed_utils.get_world_size", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.distributed_utils.all_reduce", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.distributed_utils.all_reduce", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.distributed_utils.all_reduce", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.distributed_utils.all_reduce", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.distributed_utils.all_reduce", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.distributed_utils.all_reduce"], ["", "def", "average_params", "(", "self", ")", ":", "\n", "        ", "\"\"\"Reduce Params is only used during BMUF distributed training.\"\"\"", "\n", "state_dict", "=", "self", ".", "optimizer", ".", "state_dict", "(", ")", "\n", "total_gpus", "=", "float", "(", "dist", ".", "get_world_size", "(", ")", ")", "\n", "\n", "for", "_", ",", "value", "in", "state_dict", "[", "\"state\"", "]", ".", "items", "(", ")", ":", "\n", "            ", "value", "[", "\"exp_avg\"", "]", "/=", "total_gpus", "\n", "value", "[", "\"exp_avg_sq\"", "]", "/=", "total_gpus", "\n", "dist", ".", "all_reduce", "(", "value", "[", "\"exp_avg\"", "]", ",", "op", "=", "dist", ".", "ReduceOp", ".", "SUM", ")", "\n", "dist", ".", "all_reduce", "(", "value", "[", "\"exp_avg_sq\"", "]", ",", "op", "=", "dist", ".", "ReduceOp", ".", "SUM", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.optim.adam.Adam.__init__": [[102, 107], ["dict", "super().__init__"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.dummy_dictionary.DummyDictionary.__init__"], ["def", "__init__", "(", "self", ",", "params", ",", "lr", "=", "1e-3", ",", "betas", "=", "(", "0.9", ",", "0.999", ")", ",", "eps", "=", "1e-8", ",", "\n", "weight_decay", "=", "0", ",", "amsgrad", "=", "False", ")", ":", "\n", "        ", "defaults", "=", "dict", "(", "lr", "=", "lr", ",", "betas", "=", "betas", ",", "eps", "=", "eps", ",", "\n", "weight_decay", "=", "weight_decay", ",", "amsgrad", "=", "amsgrad", ")", "\n", "super", "(", "Adam", ",", "self", ")", ".", "__init__", "(", "params", ",", "defaults", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.optim.adam.Adam.supports_memory_efficient_fp16": [[108, 111], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "supports_memory_efficient_fp16", "(", "self", ")", ":", "\n", "        ", "return", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.optim.adam.Adam.step": [[112, 182], ["closure", "p.grad.data.float", "p.data.float", "exp_avg.mul_().add_", "exp_avg_sq.mul_().addcmul_", "p.data.float.addcdiv_", "p.data.copy_", "RuntimeError", "len", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "state[].type_as", "state[].type_as", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "max_exp_avg_sq.sqrt().add_", "exp_avg_sq.sqrt().add_", "p.data.float.add_", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "state[].type_as", "exp_avg.mul_", "exp_avg_sq.mul_", "math.sqrt", "max_exp_avg_sq.sqrt", "exp_avg_sq.sqrt"], "methods", ["None"], ["", "def", "step", "(", "self", ",", "closure", "=", "None", ")", ":", "\n", "        ", "\"\"\"Performs a single optimization step.\n\n        Arguments:\n            closure (callable, optional): A closure that reevaluates the model\n                and returns the loss.\n        \"\"\"", "\n", "loss", "=", "None", "\n", "if", "closure", "is", "not", "None", ":", "\n", "            ", "loss", "=", "closure", "(", ")", "\n", "\n", "", "for", "group", "in", "self", ".", "param_groups", ":", "\n", "            ", "for", "p", "in", "group", "[", "'params'", "]", ":", "\n", "                ", "if", "p", ".", "grad", "is", "None", ":", "\n", "                    ", "continue", "\n", "", "grad", "=", "p", ".", "grad", ".", "data", ".", "float", "(", ")", "\n", "if", "grad", ".", "is_sparse", ":", "\n", "                    ", "raise", "RuntimeError", "(", "'Adam does not support sparse gradients, please consider SparseAdam instead'", ")", "\n", "", "amsgrad", "=", "group", "[", "'amsgrad'", "]", "\n", "\n", "p_data_fp32", "=", "p", ".", "data", ".", "float", "(", ")", "\n", "\n", "state", "=", "self", ".", "state", "[", "p", "]", "\n", "\n", "# State initialization", "\n", "if", "len", "(", "state", ")", "==", "0", ":", "\n", "                    ", "state", "[", "'step'", "]", "=", "0", "\n", "# Exponential moving average of gradient values", "\n", "state", "[", "'exp_avg'", "]", "=", "torch", ".", "zeros_like", "(", "p_data_fp32", ")", "\n", "# Exponential moving average of squared gradient values", "\n", "state", "[", "'exp_avg_sq'", "]", "=", "torch", ".", "zeros_like", "(", "p_data_fp32", ")", "\n", "if", "amsgrad", ":", "\n", "# Maintains max of all exp. moving avg. of sq. grad. values", "\n", "                        ", "state", "[", "'max_exp_avg_sq'", "]", "=", "torch", ".", "zeros_like", "(", "p_data_fp32", ")", "\n", "", "", "else", ":", "\n", "                    ", "state", "[", "'exp_avg'", "]", "=", "state", "[", "'exp_avg'", "]", ".", "type_as", "(", "p_data_fp32", ")", "\n", "state", "[", "'exp_avg_sq'", "]", "=", "state", "[", "'exp_avg_sq'", "]", ".", "type_as", "(", "p_data_fp32", ")", "\n", "if", "amsgrad", ":", "\n", "                        ", "state", "[", "'max_exp_avg_sq'", "]", "=", "state", "[", "'max_exp_avg_sq'", "]", ".", "type_as", "(", "p_data_fp32", ")", "\n", "\n", "", "", "exp_avg", ",", "exp_avg_sq", "=", "state", "[", "'exp_avg'", "]", ",", "state", "[", "'exp_avg_sq'", "]", "\n", "if", "amsgrad", ":", "\n", "                    ", "max_exp_avg_sq", "=", "state", "[", "'max_exp_avg_sq'", "]", "\n", "", "beta1", ",", "beta2", "=", "group", "[", "'betas'", "]", "\n", "\n", "state", "[", "'step'", "]", "+=", "1", "\n", "\n", "# Decay the first and second moment running average coefficient", "\n", "exp_avg", ".", "mul_", "(", "beta1", ")", ".", "add_", "(", "1", "-", "beta1", ",", "grad", ")", "\n", "exp_avg_sq", ".", "mul_", "(", "beta2", ")", ".", "addcmul_", "(", "1", "-", "beta2", ",", "grad", ",", "grad", ")", "\n", "if", "amsgrad", ":", "\n", "# Maintains the maximum of all 2nd moment running avg. till now", "\n", "                    ", "torch", ".", "max", "(", "max_exp_avg_sq", ",", "exp_avg_sq", ",", "out", "=", "max_exp_avg_sq", ")", "\n", "# Use the max. for normalizing running avg. of gradient", "\n", "denom", "=", "max_exp_avg_sq", ".", "sqrt", "(", ")", ".", "add_", "(", "group", "[", "'eps'", "]", ")", "\n", "", "else", ":", "\n", "                    ", "denom", "=", "exp_avg_sq", ".", "sqrt", "(", ")", ".", "add_", "(", "group", "[", "'eps'", "]", ")", "\n", "\n", "", "bias_correction1", "=", "1", "-", "beta1", "**", "state", "[", "'step'", "]", "\n", "bias_correction2", "=", "1", "-", "beta2", "**", "state", "[", "'step'", "]", "\n", "step_size", "=", "group", "[", "'lr'", "]", "*", "math", ".", "sqrt", "(", "bias_correction2", ")", "/", "bias_correction1", "\n", "\n", "if", "group", "[", "'weight_decay'", "]", "!=", "0", ":", "\n", "                    ", "p_data_fp32", ".", "add_", "(", "-", "group", "[", "'weight_decay'", "]", "*", "group", "[", "'lr'", "]", ",", "p_data_fp32", ")", "\n", "\n", "", "p_data_fp32", ".", "addcdiv_", "(", "-", "step_size", ",", "exp_avg", ",", "denom", ")", "\n", "\n", "p", ".", "data", ".", "copy_", "(", "p_data_fp32", ")", "\n", "\n", "", "", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.optim.adam.FusedAdam.__init__": [[216, 231], ["importlib.import_module", "dict", "super().__init__", "RuntimeError"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.dummy_dictionary.DummyDictionary.__init__"], ["def", "__init__", "(", "self", ",", "params", ",", "\n", "lr", "=", "1e-3", ",", "bias_correction", "=", "True", ",", "\n", "betas", "=", "(", "0.9", ",", "0.999", ")", ",", "eps", "=", "1e-8", ",", "eps_inside_sqrt", "=", "False", ",", "\n", "weight_decay", "=", "0.", ",", "max_grad_norm", "=", "0.", ",", "amsgrad", "=", "False", ")", ":", "\n", "        ", "global", "fused_adam_cuda", "\n", "import", "importlib", "\n", "fused_adam_cuda", "=", "importlib", ".", "import_module", "(", "\"fused_adam_cuda\"", ")", "\n", "\n", "if", "amsgrad", ":", "\n", "            ", "raise", "RuntimeError", "(", "'FusedAdam does not support the AMSGrad variant.'", ")", "\n", "", "defaults", "=", "dict", "(", "lr", "=", "lr", ",", "bias_correction", "=", "bias_correction", ",", "\n", "betas", "=", "betas", ",", "eps", "=", "eps", ",", "weight_decay", "=", "weight_decay", ",", "\n", "max_grad_norm", "=", "max_grad_norm", ")", "\n", "super", "(", "FusedAdam", ",", "self", ")", ".", "__init__", "(", "params", ",", "defaults", ")", "\n", "self", ".", "eps_mode", "=", "0", "if", "eps_inside_sqrt", "else", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.optim.adam.FusedAdam.supports_memory_efficient_fp16": [[232, 235], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "supports_memory_efficient_fp16", "(", "self", ")", ":", "\n", "        ", "return", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.optim.adam.FusedAdam.step": [[236, 329], ["zip", "closure", "isinstance", "zip", "len", "len", "p.data.float", "fused_adam_cuda.adam", "type", "len", "RuntimeError", "len", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "state[].type_as", "state[].type_as"], "methods", ["None"], ["", "def", "step", "(", "self", ",", "closure", "=", "None", ",", "grads", "=", "None", ",", "scale", "=", "1.", ",", "grad_norms", "=", "None", ")", ":", "\n", "        ", "\"\"\"Performs a single optimization step.\n        Arguments:\n            closure (callable, optional): A closure that reevaluates the model\n                and returns the loss.\n            grads (list of tensors, optional): weight gradient to use for the\n                optimizer update. If gradients have type torch.half, parameters\n                are expected to be in type torch.float. (default: None)\n            output params (list of tensors, optional): A reduced precision copy\n                of the updated weights written out in addition to the regular\n                updated weights. Have to be of same type as gradients. (default: None)\n            scale (float, optional): factor to divide gradient tensor values\n                by before applying to weights. (default: 1)\n        \"\"\"", "\n", "loss", "=", "None", "\n", "if", "closure", "is", "not", "None", ":", "\n", "            ", "loss", "=", "closure", "(", ")", "\n", "\n", "", "if", "grads", "is", "None", ":", "\n", "            ", "grads_group", "=", "[", "None", "]", "*", "len", "(", "self", ".", "param_groups", ")", "\n", "# backward compatibility", "\n", "# assuming a list/generator of parameter means single group", "\n", "", "elif", "isinstance", "(", "grads", ",", "types", ".", "GeneratorType", ")", ":", "\n", "            ", "grads_group", "=", "[", "grads", "]", "\n", "", "elif", "type", "(", "grads", "[", "0", "]", ")", "!=", "list", ":", "\n", "            ", "grads_group", "=", "[", "grads", "]", "\n", "", "else", ":", "\n", "            ", "grads_group", "=", "grads", "\n", "\n", "", "if", "grad_norms", "is", "None", ":", "\n", "            ", "grad_norms", "=", "[", "None", "]", "*", "len", "(", "self", ".", "param_groups", ")", "\n", "\n", "", "for", "group", ",", "grads_this_group", ",", "grad_norm", "in", "zip", "(", "self", ".", "param_groups", ",", "grads_group", ",", "grad_norms", ")", ":", "\n", "            ", "if", "grads_this_group", "is", "None", ":", "\n", "               ", "grads_this_group", "=", "[", "None", "]", "*", "len", "(", "group", "[", "'params'", "]", ")", "\n", "\n", "# compute combined scale factor for this group", "\n", "", "combined_scale", "=", "scale", "\n", "if", "group", "[", "'max_grad_norm'", "]", ">", "0", ":", "\n", "# norm is in fact norm*scale", "\n", "                ", "clip", "=", "(", "(", "grad_norm", "/", "scale", ")", "+", "1e-6", ")", "/", "group", "[", "'max_grad_norm'", "]", "\n", "if", "clip", ">", "1", ":", "\n", "                    ", "combined_scale", "=", "clip", "*", "scale", "\n", "\n", "", "", "bias_correction", "=", "1", "if", "group", "[", "'bias_correction'", "]", "else", "0", "\n", "\n", "for", "p", ",", "grad", "in", "zip", "(", "group", "[", "'params'", "]", ",", "grads_this_group", ")", ":", "\n", "#note: p.grad should not ever be set for correct operation of mixed precision optimizer that sometimes sends None gradients", "\n", "                ", "if", "p", ".", "grad", "is", "None", "and", "grad", "is", "None", ":", "\n", "                    ", "continue", "\n", "", "if", "grad", "is", "None", ":", "\n", "                    ", "grad", "=", "p", ".", "grad", ".", "data", "\n", "", "if", "grad", ".", "is_sparse", ":", "\n", "                    ", "raise", "RuntimeError", "(", "'FusedAdam does not support sparse gradients, please consider SparseAdam instead'", ")", "\n", "\n", "", "p_data_fp32", "=", "p", ".", "data", ".", "float", "(", ")", "\n", "\n", "state", "=", "self", ".", "state", "[", "p", "]", "\n", "\n", "# State initialization", "\n", "if", "len", "(", "state", ")", "==", "0", ":", "\n", "                    ", "state", "[", "'step'", "]", "=", "0", "\n", "# Exponential moving average of gradient values", "\n", "state", "[", "'exp_avg'", "]", "=", "torch", ".", "zeros_like", "(", "p_data_fp32", ")", "\n", "# Exponential moving average of squared gradient values", "\n", "state", "[", "'exp_avg_sq'", "]", "=", "torch", ".", "zeros_like", "(", "p_data_fp32", ")", "\n", "", "else", ":", "\n", "                    ", "state", "[", "'exp_avg'", "]", "=", "state", "[", "'exp_avg'", "]", ".", "type_as", "(", "p_data_fp32", ")", "\n", "state", "[", "'exp_avg_sq'", "]", "=", "state", "[", "'exp_avg_sq'", "]", ".", "type_as", "(", "p_data_fp32", ")", "\n", "\n", "", "exp_avg", "=", "state", "[", "'exp_avg'", "]", "\n", "exp_avg_sq", "=", "state", "[", "'exp_avg_sq'", "]", "\n", "beta1", ",", "beta2", "=", "group", "[", "'betas'", "]", "\n", "\n", "state", "[", "'step'", "]", "+=", "1", "\n", "\n", "out_p", "=", "p", ".", "data", "\n", "fused_adam_cuda", ".", "adam", "(", "p_data_fp32", ",", "\n", "out_p", ",", "\n", "exp_avg", ",", "\n", "exp_avg_sq", ",", "\n", "grad", ",", "\n", "group", "[", "'lr'", "]", ",", "\n", "beta1", ",", "\n", "beta2", ",", "\n", "group", "[", "'eps'", "]", ",", "\n", "combined_scale", ",", "\n", "state", "[", "'step'", "]", ",", "\n", "self", ".", "eps_mode", ",", "\n", "bias_correction", ",", "\n", "group", "[", "'weight_decay'", "]", ")", "\n", "\n", "", "", "return", "loss", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.optim.sgd.SGD.__init__": [[13, 16], ["FairseqOptimizer.__init__", "torch.optim.SGD"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.dummy_dictionary.DummyDictionary.__init__"], ["    ", "def", "__init__", "(", "self", ",", "args", ",", "params", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "args", ")", "\n", "self", ".", "_optimizer", "=", "torch", ".", "optim", ".", "SGD", "(", "params", ",", "**", "self", ".", "optimizer_config", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.optim.sgd.SGD.add_args": [[17, 25], ["parser.add_argument", "parser.add_argument"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "add_args", "(", "parser", ")", ":", "\n", "        ", "\"\"\"Add optimizer-specific arguments to the parser.\"\"\"", "\n", "# fmt: off", "\n", "parser", ".", "add_argument", "(", "'--momentum'", ",", "default", "=", "0.0", ",", "type", "=", "float", ",", "metavar", "=", "'M'", ",", "\n", "help", "=", "'momentum factor'", ")", "\n", "parser", ".", "add_argument", "(", "'--weight-decay'", ",", "'--wd'", ",", "default", "=", "0.0", ",", "type", "=", "float", ",", "metavar", "=", "'WD'", ",", "\n", "help", "=", "'weight decay'", ")", "\n", "# fmt: on", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.optim.sgd.SGD.optimizer_config": [[27, 39], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "optimizer_config", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Return a kwarg dictionary that will be used to override optimizer\n        args stored in checkpoints. This allows us to load a checkpoint and\n        resume training using a different set of optimizer args, e.g., with a\n        different learning rate.\n        \"\"\"", "\n", "return", "{", "\n", "'lr'", ":", "self", ".", "args", ".", "lr", "[", "0", "]", ",", "\n", "'momentum'", ":", "self", ".", "args", ".", "momentum", ",", "\n", "'weight_decay'", ":", "self", ".", "args", ".", "weight_decay", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.lr_scheduler.inverse_square_root_schedule.InverseSquareRootSchedule.__init__": [[29, 49], ["FairseqLRScheduler.__init__", "inverse_square_root_schedule.InverseSquareRootSchedule.optimizer.set_lr", "len", "ValueError"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.dummy_dictionary.DummyDictionary.__init__", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.optim.fp16_optimizer.MemoryEfficientFP16Optimizer.set_lr"], ["def", "__init__", "(", "self", ",", "args", ",", "optimizer", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "args", ",", "optimizer", ")", "\n", "if", "len", "(", "args", ".", "lr", ")", ">", "1", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "'Cannot use a fixed learning rate schedule with inverse_sqrt.'", "\n", "' Consider --lr-scheduler=fixed instead.'", "\n", ")", "\n", "", "warmup_end_lr", "=", "args", ".", "lr", "[", "0", "]", "\n", "if", "args", ".", "warmup_init_lr", "<", "0", ":", "\n", "            ", "args", ".", "warmup_init_lr", "=", "0", "if", "args", ".", "warmup_updates", ">", "0", "else", "warmup_end_lr", "\n", "\n", "# linearly warmup for the first args.warmup_updates", "\n", "", "self", ".", "lr_step", "=", "(", "warmup_end_lr", "-", "args", ".", "warmup_init_lr", ")", "/", "args", ".", "warmup_updates", "\n", "\n", "# then, decay prop. to the inverse square root of the update number", "\n", "self", ".", "decay_factor", "=", "warmup_end_lr", "*", "args", ".", "warmup_updates", "**", "0.5", "\n", "\n", "# initial learning rate", "\n", "self", ".", "lr", "=", "args", ".", "warmup_init_lr", "\n", "self", ".", "optimizer", ".", "set_lr", "(", "self", ".", "lr", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.lr_scheduler.inverse_square_root_schedule.InverseSquareRootSchedule.add_args": [[50, 58], ["parser.add_argument", "parser.add_argument"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "add_args", "(", "parser", ")", ":", "\n", "        ", "\"\"\"Add arguments to the parser for this LR scheduler.\"\"\"", "\n", "# fmt: off", "\n", "parser", ".", "add_argument", "(", "'--warmup-updates'", ",", "default", "=", "4000", ",", "type", "=", "int", ",", "metavar", "=", "'N'", ",", "\n", "help", "=", "'warmup the learning rate linearly for the first N updates'", ")", "\n", "parser", ".", "add_argument", "(", "'--warmup-init-lr'", ",", "default", "=", "-", "1", ",", "type", "=", "float", ",", "metavar", "=", "'LR'", ",", "\n", "help", "=", "'initial learning rate during warmup phase; default is args.lr'", ")", "\n", "# fmt: on", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.lr_scheduler.inverse_square_root_schedule.InverseSquareRootSchedule.step": [[60, 65], ["super().step", "inverse_square_root_schedule.InverseSquareRootSchedule.optimizer.get_lr"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.lr_scheduler.polynomial_decay_schedule.PolynomialDecaySchedule.step", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.optim.fp16_optimizer.MemoryEfficientFP16Optimizer.get_lr"], ["", "def", "step", "(", "self", ",", "epoch", ",", "val_loss", "=", "None", ")", ":", "\n", "        ", "\"\"\"Update the learning rate at the end of the given epoch.\"\"\"", "\n", "super", "(", ")", ".", "step", "(", "epoch", ",", "val_loss", ")", "\n", "# we don't change the learning rate at epoch boundaries", "\n", "return", "self", ".", "optimizer", ".", "get_lr", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.lr_scheduler.inverse_square_root_schedule.InverseSquareRootSchedule.step_update": [[66, 74], ["inverse_square_root_schedule.InverseSquareRootSchedule.optimizer.set_lr"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.optim.fp16_optimizer.MemoryEfficientFP16Optimizer.set_lr"], ["", "def", "step_update", "(", "self", ",", "num_updates", ")", ":", "\n", "        ", "\"\"\"Update the learning rate after each update.\"\"\"", "\n", "if", "num_updates", "<", "self", ".", "args", ".", "warmup_updates", ":", "\n", "            ", "self", ".", "lr", "=", "self", ".", "args", ".", "warmup_init_lr", "+", "num_updates", "*", "self", ".", "lr_step", "\n", "", "else", ":", "\n", "            ", "self", ".", "lr", "=", "self", ".", "decay_factor", "*", "num_updates", "**", "-", "0.5", "\n", "", "self", ".", "optimizer", ".", "set_lr", "(", "self", ".", "lr", ")", "\n", "return", "self", ".", "lr", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.lr_scheduler.fairseq_lr_scheduler.FairseqLRScheduler.__init__": [[11, 18], ["object.__init__", "isinstance", "ValueError"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.dummy_dictionary.DummyDictionary.__init__"], ["    ", "def", "__init__", "(", "self", ",", "args", ",", "optimizer", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "if", "not", "isinstance", "(", "optimizer", ",", "FairseqOptimizer", ")", ":", "\n", "            ", "raise", "ValueError", "(", "'optimizer must be an instance of FairseqOptimizer'", ")", "\n", "", "self", ".", "args", "=", "args", "\n", "self", ".", "optimizer", "=", "optimizer", "\n", "self", ".", "best", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.lr_scheduler.fairseq_lr_scheduler.FairseqLRScheduler.add_args": [[19, 23], ["None"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "add_args", "(", "parser", ")", ":", "\n", "        ", "\"\"\"Add arguments to the parser for this LR scheduler.\"\"\"", "\n", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.lr_scheduler.fairseq_lr_scheduler.FairseqLRScheduler.state_dict": [[24, 27], ["None"], "methods", ["None"], ["", "def", "state_dict", "(", "self", ")", ":", "\n", "        ", "\"\"\"Return the LR scheduler state dict.\"\"\"", "\n", "return", "{", "'best'", ":", "self", ".", "best", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.lr_scheduler.fairseq_lr_scheduler.FairseqLRScheduler.load_state_dict": [[28, 31], ["None"], "methods", ["None"], ["", "def", "load_state_dict", "(", "self", ",", "state_dict", ")", ":", "\n", "        ", "\"\"\"Load an LR scheduler state dict.\"\"\"", "\n", "self", ".", "best", "=", "state_dict", "[", "'best'", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.lr_scheduler.fairseq_lr_scheduler.FairseqLRScheduler.step": [[32, 39], ["min"], "methods", ["None"], ["", "def", "step", "(", "self", ",", "epoch", ",", "val_loss", "=", "None", ")", ":", "\n", "        ", "\"\"\"Update the learning rate at the end of the given epoch.\"\"\"", "\n", "if", "val_loss", "is", "not", "None", ":", "\n", "            ", "if", "self", ".", "best", "is", "None", ":", "\n", "                ", "self", ".", "best", "=", "val_loss", "\n", "", "else", ":", "\n", "                ", "self", ".", "best", "=", "min", "(", "self", ".", "best", ",", "val_loss", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.lr_scheduler.fairseq_lr_scheduler.FairseqLRScheduler.step_update": [[40, 43], ["fairseq_lr_scheduler.FairseqLRScheduler.optimizer.get_lr"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.optim.fp16_optimizer.MemoryEfficientFP16Optimizer.get_lr"], ["", "", "", "def", "step_update", "(", "self", ",", "num_updates", ")", ":", "\n", "        ", "\"\"\"Update the learning rate after each update.\"\"\"", "\n", "return", "self", ".", "optimizer", ".", "get_lr", "(", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.lr_scheduler.fixed_schedule.FixedSchedule.__init__": [[13, 24], ["FairseqLRScheduler.__init__", "getattr"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.dummy_dictionary.DummyDictionary.__init__"], ["def", "__init__", "(", "self", ",", "args", ",", "optimizer", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "args", ",", "optimizer", ")", "\n", "\n", "# set defaults", "\n", "args", ".", "warmup_updates", "=", "getattr", "(", "args", ",", "'warmup_updates'", ",", "0", ")", "or", "0", "\n", "\n", "self", ".", "lr", "=", "args", ".", "lr", "[", "0", "]", "\n", "if", "args", ".", "warmup_updates", ">", "0", ":", "\n", "            ", "self", ".", "warmup_factor", "=", "1.", "/", "args", ".", "warmup_updates", "\n", "", "else", ":", "\n", "            ", "self", ".", "warmup_factor", "=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.lr_scheduler.fixed_schedule.FixedSchedule.add_args": [[25, 35], ["parser.add_argument", "parser.add_argument", "parser.add_argument"], "methods", ["None"], ["", "", "@", "staticmethod", "\n", "def", "add_args", "(", "parser", ")", ":", "\n", "        ", "\"\"\"Add arguments to the parser for this LR scheduler.\"\"\"", "\n", "# fmt: off", "\n", "parser", ".", "add_argument", "(", "'--force-anneal'", ",", "'--fa'", ",", "type", "=", "int", ",", "metavar", "=", "'N'", ",", "\n", "help", "=", "'force annealing at specified epoch'", ")", "\n", "parser", ".", "add_argument", "(", "'--lr-shrink'", ",", "default", "=", "0.1", ",", "type", "=", "float", ",", "metavar", "=", "'LS'", ",", "\n", "help", "=", "'shrink factor for annealing, lr_new = (lr * lr_shrink)'", ")", "\n", "parser", ".", "add_argument", "(", "'--warmup-updates'", ",", "default", "=", "0", ",", "type", "=", "int", ",", "metavar", "=", "'N'", ",", "\n", "help", "=", "'warmup the learning rate linearly for the first N updates'", ")", "\n", "# fmt: on", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.lr_scheduler.fixed_schedule.FixedSchedule.get_next_lr": [[37, 46], ["min", "len"], "methods", ["None"], ["", "def", "get_next_lr", "(", "self", ",", "epoch", ")", ":", "\n", "        ", "lrs", "=", "self", ".", "args", ".", "lr", "\n", "if", "self", ".", "args", ".", "force_anneal", "is", "None", "or", "epoch", "<", "self", ".", "args", ".", "force_anneal", ":", "\n", "# use fixed LR schedule", "\n", "            ", "next_lr", "=", "lrs", "[", "min", "(", "epoch", ",", "len", "(", "lrs", ")", "-", "1", ")", "]", "\n", "", "else", ":", "\n", "# annneal based on lr_shrink", "\n", "            ", "next_lr", "=", "lrs", "[", "-", "1", "]", "*", "self", ".", "args", ".", "lr_shrink", "**", "(", "epoch", "+", "1", "-", "self", ".", "args", ".", "force_anneal", ")", "\n", "", "return", "next_lr", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.lr_scheduler.fixed_schedule.FixedSchedule.step": [[47, 53], ["super().step", "fixed_schedule.FixedSchedule.get_next_lr", "fixed_schedule.FixedSchedule.optimizer.set_lr", "fixed_schedule.FixedSchedule.optimizer.get_lr"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.lr_scheduler.polynomial_decay_schedule.PolynomialDecaySchedule.step", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.lr_scheduler.polynomial_decay_schedule.PolynomialDecaySchedule.get_next_lr", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.optim.fp16_optimizer.MemoryEfficientFP16Optimizer.set_lr", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.optim.fp16_optimizer.MemoryEfficientFP16Optimizer.get_lr"], ["", "def", "step", "(", "self", ",", "epoch", ",", "val_loss", "=", "None", ")", ":", "\n", "        ", "\"\"\"Update the learning rate at the end of the given epoch.\"\"\"", "\n", "super", "(", ")", ".", "step", "(", "epoch", ",", "val_loss", ")", "\n", "self", ".", "lr", "=", "self", ".", "get_next_lr", "(", "epoch", ")", "\n", "self", ".", "optimizer", ".", "set_lr", "(", "self", ".", "warmup_factor", "*", "self", ".", "lr", ")", "\n", "return", "self", ".", "optimizer", ".", "get_lr", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.lr_scheduler.fixed_schedule.FixedSchedule.step_update": [[54, 60], ["fixed_schedule.FixedSchedule.optimizer.get_lr", "fixed_schedule.FixedSchedule.optimizer.set_lr", "float"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.optim.fp16_optimizer.MemoryEfficientFP16Optimizer.get_lr", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.optim.fp16_optimizer.MemoryEfficientFP16Optimizer.set_lr"], ["", "def", "step_update", "(", "self", ",", "num_updates", ")", ":", "\n", "        ", "\"\"\"Update the learning rate after each update.\"\"\"", "\n", "if", "self", ".", "args", ".", "warmup_updates", ">", "0", "and", "num_updates", "<", "self", ".", "args", ".", "warmup_updates", ":", "\n", "            ", "self", ".", "warmup_factor", "=", "(", "num_updates", "+", "1", ")", "/", "float", "(", "self", ".", "args", ".", "warmup_updates", ")", "\n", "self", ".", "optimizer", ".", "set_lr", "(", "self", ".", "warmup_factor", "*", "self", ".", "lr", ")", "\n", "", "return", "self", ".", "optimizer", ".", "get_lr", "(", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.lr_scheduler.polynomial_decay_schedule.PolynomialDecaySchedule.__init__": [[13, 28], ["FairseqLRScheduler.__init__", "polynomial_decay_schedule.PolynomialDecaySchedule.optimizer.set_lr", "getattr"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.dummy_dictionary.DummyDictionary.__init__", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.optim.fp16_optimizer.MemoryEfficientFP16Optimizer.set_lr"], ["def", "__init__", "(", "self", ",", "args", ",", "optimizer", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "args", ",", "optimizer", ")", "\n", "\n", "# set defaults", "\n", "args", ".", "warmup_updates", "=", "getattr", "(", "args", ",", "'warmup_updates'", ",", "0", ")", "or", "0", "\n", "\n", "self", ".", "lr", "=", "args", ".", "lr", "[", "0", "]", "\n", "if", "args", ".", "warmup_updates", ">", "0", ":", "\n", "            ", "self", ".", "warmup_factor", "=", "1.", "/", "args", ".", "warmup_updates", "\n", "", "else", ":", "\n", "            ", "self", ".", "warmup_factor", "=", "1", "\n", "", "self", ".", "end_learning_rate", "=", "args", ".", "end_learning_rate", "\n", "self", ".", "total_num_update", "=", "args", ".", "total_num_update", "\n", "self", ".", "power", "=", "args", ".", "power", "\n", "self", ".", "optimizer", ".", "set_lr", "(", "self", ".", "warmup_factor", "*", "self", ".", "lr", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.lr_scheduler.polynomial_decay_schedule.PolynomialDecaySchedule.add_args": [[29, 39], ["parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "add_args", "(", "parser", ")", ":", "\n", "        ", "\"\"\"Add arguments to the parser for this LR scheduler.\"\"\"", "\n", "parser", ".", "add_argument", "(", "'--force-anneal'", ",", "'--fa'", ",", "type", "=", "int", ",", "metavar", "=", "'N'", ",", "\n", "help", "=", "'force annealing at specified epoch'", ")", "\n", "parser", ".", "add_argument", "(", "'--warmup-updates'", ",", "default", "=", "0", ",", "type", "=", "int", ",", "metavar", "=", "'N'", ",", "\n", "help", "=", "'warmup the learning rate linearly for the first N updates'", ")", "\n", "parser", ".", "add_argument", "(", "'--end-learning-rate'", ",", "default", "=", "0.0", ",", "type", "=", "float", ")", "\n", "parser", ".", "add_argument", "(", "'--power'", ",", "default", "=", "1.0", ",", "type", "=", "float", ")", "\n", "parser", ".", "add_argument", "(", "'--total-num-update'", ",", "default", "=", "1000000", ",", "type", "=", "int", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.lr_scheduler.polynomial_decay_schedule.PolynomialDecaySchedule.get_next_lr": [[40, 49], ["polynomial_decay_schedule.PolynomialDecaySchedule.optimizer.get_lr", "min", "len"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.optim.fp16_optimizer.MemoryEfficientFP16Optimizer.get_lr"], ["", "def", "get_next_lr", "(", "self", ",", "epoch", ")", ":", "\n", "        ", "lrs", "=", "self", ".", "args", ".", "lr", "\n", "if", "self", ".", "args", ".", "force_anneal", "is", "None", "or", "epoch", "<", "self", ".", "args", ".", "force_anneal", ":", "\n", "# use fixed LR schedule", "\n", "            ", "next_lr", "=", "lrs", "[", "min", "(", "epoch", ",", "len", "(", "lrs", ")", "-", "1", ")", "]", "\n", "", "else", ":", "\n", "# annneal based on lr_shrink", "\n", "            ", "next_lr", "=", "self", ".", "optimizer", ".", "get_lr", "(", ")", "\n", "", "return", "next_lr", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.lr_scheduler.polynomial_decay_schedule.PolynomialDecaySchedule.step": [[50, 56], ["super().step", "polynomial_decay_schedule.PolynomialDecaySchedule.get_next_lr", "polynomial_decay_schedule.PolynomialDecaySchedule.optimizer.set_lr", "polynomial_decay_schedule.PolynomialDecaySchedule.optimizer.get_lr"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.lr_scheduler.polynomial_decay_schedule.PolynomialDecaySchedule.step", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.lr_scheduler.polynomial_decay_schedule.PolynomialDecaySchedule.get_next_lr", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.optim.fp16_optimizer.MemoryEfficientFP16Optimizer.set_lr", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.optim.fp16_optimizer.MemoryEfficientFP16Optimizer.get_lr"], ["", "def", "step", "(", "self", ",", "epoch", ",", "val_loss", "=", "None", ")", ":", "\n", "        ", "\"\"\"Update the learning rate at the end of the given epoch.\"\"\"", "\n", "super", "(", ")", ".", "step", "(", "epoch", ",", "val_loss", ")", "\n", "self", ".", "lr", "=", "self", ".", "get_next_lr", "(", "epoch", ")", "\n", "self", ".", "optimizer", ".", "set_lr", "(", "self", ".", "warmup_factor", "*", "self", ".", "lr", ")", "\n", "return", "self", ".", "optimizer", ".", "get_lr", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.lr_scheduler.polynomial_decay_schedule.PolynomialDecaySchedule.step_update": [[57, 71], ["polynomial_decay_schedule.PolynomialDecaySchedule.optimizer.set_lr", "polynomial_decay_schedule.PolynomialDecaySchedule.optimizer.get_lr", "float"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.optim.fp16_optimizer.MemoryEfficientFP16Optimizer.set_lr", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.optim.fp16_optimizer.MemoryEfficientFP16Optimizer.get_lr"], ["", "def", "step_update", "(", "self", ",", "num_updates", ")", ":", "\n", "        ", "\"\"\"Update the learning rate after each update.\"\"\"", "\n", "if", "self", ".", "args", ".", "warmup_updates", ">", "0", "and", "num_updates", "<=", "self", ".", "args", ".", "warmup_updates", ":", "\n", "            ", "self", ".", "warmup_factor", "=", "num_updates", "/", "float", "(", "self", ".", "args", ".", "warmup_updates", ")", "\n", "lr", "=", "self", ".", "warmup_factor", "*", "self", ".", "lr", "\n", "", "elif", "num_updates", ">=", "self", ".", "total_num_update", ":", "\n", "            ", "lr", "=", "self", ".", "end_learning_rate", "\n", "", "else", ":", "\n", "            ", "warmup", "=", "self", ".", "args", ".", "warmup_updates", "\n", "lr_range", "=", "self", ".", "lr", "-", "self", ".", "end_learning_rate", "\n", "pct_remaining", "=", "1", "-", "(", "num_updates", "-", "warmup", ")", "/", "(", "self", ".", "total_num_update", "-", "warmup", ")", "\n", "lr", "=", "lr_range", "*", "pct_remaining", "**", "(", "self", ".", "power", ")", "+", "self", ".", "end_learning_rate", "\n", "", "self", ".", "optimizer", ".", "set_lr", "(", "lr", ")", "\n", "return", "self", ".", "optimizer", ".", "get_lr", "(", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.modules.positional_embedding.PositionalEmbedding": [[12, 34], ["learned_positional_embedding.LearnedPositionalEmbedding", "torch.init.normal_", "sinusoidal_positional_embedding.SinusoidalPositionalEmbedding", "torch.init.constant_"], "function", ["None"], ["def", "PositionalEmbedding", "(", "\n", "num_embeddings", ":", "int", ",", "\n", "embedding_dim", ":", "int", ",", "\n", "padding_idx", ":", "int", ",", "\n", "learned", ":", "bool", "=", "False", ",", "\n", ")", ":", "\n", "    ", "if", "learned", ":", "\n", "# if padding_idx is specified then offset the embedding ids by", "\n", "# this index and adjust num_embeddings appropriately", "\n", "# TODO: The right place for this offset would be inside", "\n", "# LearnedPositionalEmbedding. Move this there for a cleaner implementation.", "\n", "        ", "if", "padding_idx", "is", "not", "None", ":", "\n", "            ", "num_embeddings", "=", "num_embeddings", "+", "padding_idx", "+", "1", "\n", "", "m", "=", "LearnedPositionalEmbedding", "(", "num_embeddings", ",", "embedding_dim", ",", "padding_idx", ")", "\n", "nn", ".", "init", ".", "normal_", "(", "m", ".", "weight", ",", "mean", "=", "0", ",", "std", "=", "embedding_dim", "**", "-", "0.5", ")", "\n", "if", "padding_idx", "is", "not", "None", ":", "\n", "            ", "nn", ".", "init", ".", "constant_", "(", "m", ".", "weight", "[", "padding_idx", "]", ",", "0", ")", "\n", "", "", "else", ":", "\n", "        ", "m", "=", "SinusoidalPositionalEmbedding", "(", "\n", "embedding_dim", ",", "padding_idx", ",", "init_size", "=", "num_embeddings", "+", "padding_idx", "+", "1", ",", "\n", ")", "\n", "", "return", "m", "\n", "", ""]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.modules.learned_positional_embedding.LearnedPositionalEmbedding.__init__": [[19, 27], ["torch.Embedding.__init__"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.dummy_dictionary.DummyDictionary.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "num_embeddings", ":", "int", ",", "\n", "embedding_dim", ":", "int", ",", "\n", "padding_idx", ":", "int", ",", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "num_embeddings", ",", "embedding_dim", ",", "padding_idx", ")", "\n", "self", ".", "onnx_trace", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.modules.learned_positional_embedding.LearnedPositionalEmbedding.forward": [[28, 44], ["super().forward", "input.data.new().fill_", "fairseq.utils.make_positions", "int", "input.data.new", "input.size"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.criterions.label_smoothed_cross_entropy.LabelSmoothedCrossEntropyCriterion.forward", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.utils.make_positions", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.fairseq_dataset.FairseqDataset.size"], ["", "def", "forward", "(", "self", ",", "input", ",", "incremental_state", "=", "None", ",", "positions", "=", "None", ")", ":", "\n", "        ", "\"\"\"Input is expected to be of size [bsz x seqlen].\"\"\"", "\n", "assert", "(", "\n", "(", "positions", "is", "None", ")", "or", "(", "self", ".", "padding_idx", "is", "None", ")", "\n", ")", ",", "\"If positions is pre-computed then padding_idx should not be set.\"", "\n", "\n", "if", "positions", "is", "None", ":", "\n", "            ", "if", "incremental_state", "is", "not", "None", ":", "\n", "# positions is the same for every token when decoding a single step", "\n", "# Without the int() cast, it doesn't work in some cases when exporting to ONNX", "\n", "                ", "positions", "=", "input", ".", "data", ".", "new", "(", "1", ",", "1", ")", ".", "fill_", "(", "int", "(", "self", ".", "padding_idx", "+", "input", ".", "size", "(", "1", ")", ")", ")", "\n", "", "else", ":", "\n", "                ", "positions", "=", "utils", ".", "make_positions", "(", "\n", "input", ",", "self", ".", "padding_idx", ",", "onnx_trace", "=", "self", ".", "onnx_trace", ",", "\n", ")", "\n", "", "", "return", "super", "(", ")", ".", "forward", "(", "positions", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.modules.learned_positional_embedding.LearnedPositionalEmbedding.max_positions": [[45, 51], ["None"], "methods", ["None"], ["", "def", "max_positions", "(", "self", ")", ":", "\n", "        ", "\"\"\"Maximum number of supported positions.\"\"\"", "\n", "if", "self", ".", "padding_idx", "is", "not", "None", ":", "\n", "            ", "return", "self", ".", "num_embeddings", "-", "self", ".", "padding_idx", "-", "1", "\n", "", "else", ":", "\n", "            ", "return", "self", ".", "num_embeddings", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.modules.multihead_attention.MultiheadAttention.__init__": [[21, 65], ["torch.nn.Module.__init__", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "multihead_attention.MultiheadAttention.reset_parameters", "hasattr", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.dummy_dictionary.DummyDictionary.__init__", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.modules.transformer_layer.Linear", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.modules.transformer_layer.Linear", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.modules.transformer_layer.Linear", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.modules.transformer_layer.Linear", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.modules.transformer_layer.Linear", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.modules.transformer_layer.Linear", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.modules.transformer_layer.Linear", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.modules.transformer_layer.Linear", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.modules.multihead_attention.MultiheadAttention.reset_parameters"], ["def", "__init__", "(", "self", ",", "embed_dim", ",", "num_heads", ",", "kdim", "=", "None", ",", "vdim", "=", "None", ",", "dropout", "=", "0.", ",", "bias", "=", "True", ",", "\n", "add_bias_kv", "=", "False", ",", "add_zero_attn", "=", "False", ",", "self_attention", "=", "False", ",", "\n", "encoder_decoder_attention", "=", "False", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "embed_dim", "=", "embed_dim", "\n", "self", ".", "kdim", "=", "kdim", "if", "kdim", "is", "not", "None", "else", "embed_dim", "\n", "self", ".", "vdim", "=", "vdim", "if", "vdim", "is", "not", "None", "else", "embed_dim", "\n", "self", ".", "qkv_same_dim", "=", "self", ".", "kdim", "==", "embed_dim", "and", "self", ".", "vdim", "==", "embed_dim", "\n", "\n", "self", ".", "num_heads", "=", "num_heads", "\n", "self", ".", "dropout", "=", "dropout", "\n", "self", ".", "head_dim", "=", "embed_dim", "//", "num_heads", "\n", "assert", "self", ".", "head_dim", "*", "num_heads", "==", "self", ".", "embed_dim", ",", "\"embed_dim must be divisible by num_heads\"", "\n", "self", ".", "scaling", "=", "self", ".", "head_dim", "**", "-", "0.5", "\n", "\n", "self", ".", "self_attention", "=", "self_attention", "\n", "self", ".", "encoder_decoder_attention", "=", "encoder_decoder_attention", "\n", "\n", "assert", "not", "self", ".", "self_attention", "or", "self", ".", "qkv_same_dim", ",", "'Self-attention requires query, key and '", "'value to be of the same size'", "\n", "\n", "self", ".", "k_proj", "=", "nn", ".", "Linear", "(", "self", ".", "kdim", ",", "embed_dim", ",", "bias", "=", "bias", ")", "\n", "self", ".", "v_proj", "=", "nn", ".", "Linear", "(", "self", ".", "vdim", ",", "embed_dim", ",", "bias", "=", "bias", ")", "\n", "self", ".", "q_proj", "=", "nn", ".", "Linear", "(", "embed_dim", ",", "embed_dim", ",", "bias", "=", "bias", ")", "\n", "\n", "self", ".", "out_proj", "=", "nn", ".", "Linear", "(", "embed_dim", ",", "embed_dim", ",", "bias", "=", "bias", ")", "\n", "\n", "if", "add_bias_kv", ":", "\n", "            ", "self", ".", "bias_k", "=", "Parameter", "(", "torch", ".", "Tensor", "(", "1", ",", "1", ",", "embed_dim", ")", ")", "\n", "self", ".", "bias_v", "=", "Parameter", "(", "torch", ".", "Tensor", "(", "1", ",", "1", ",", "embed_dim", ")", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "bias_k", "=", "self", ".", "bias_v", "=", "None", "\n", "\n", "", "self", ".", "add_zero_attn", "=", "add_zero_attn", "\n", "\n", "self", ".", "reset_parameters", "(", ")", "\n", "\n", "self", ".", "onnx_trace", "=", "False", "\n", "\n", "self", ".", "enable_torch_version", "=", "False", "\n", "if", "hasattr", "(", "F", ",", "\"multi_head_attention_forward\"", ")", ":", "\n", "            ", "self", ".", "enable_torch_version", "=", "True", "\n", "", "else", ":", "\n", "            ", "self", ".", "enable_torch_version", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.modules.multihead_attention.MultiheadAttention.prepare_for_onnx_export_": [[66, 68], ["None"], "methods", ["None"], ["", "", "def", "prepare_for_onnx_export_", "(", "self", ")", ":", "\n", "        ", "self", ".", "onnx_trace", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.modules.multihead_attention.MultiheadAttention.reset_parameters": [[69, 87], ["torch.nn.init.xavier_uniform_", "torch.nn.init.xavier_uniform_", "torch.nn.init.constant_", "torch.nn.init.constant_", "torch.nn.init.xavier_uniform_", "torch.nn.init.xavier_uniform_", "torch.nn.init.xavier_uniform_", "torch.nn.init.xavier_uniform_", "torch.nn.init.xavier_uniform_", "torch.nn.init.xavier_uniform_", "torch.nn.init.xavier_uniform_", "torch.nn.init.xavier_uniform_", "torch.nn.init.xavier_uniform_", "torch.nn.init.xavier_uniform_", "torch.nn.init.xavier_uniform_", "torch.nn.init.xavier_uniform_", "torch.nn.init.xavier_normal_", "torch.nn.init.xavier_normal_", "torch.nn.init.xavier_normal_", "torch.nn.init.xavier_normal_", "math.sqrt", "math.sqrt", "math.sqrt"], "methods", ["None"], ["", "def", "reset_parameters", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "qkv_same_dim", ":", "\n", "# Empirically observed the convergence to be much better with", "\n", "# the scaled initialization", "\n", "            ", "nn", ".", "init", ".", "xavier_uniform_", "(", "self", ".", "k_proj", ".", "weight", ",", "gain", "=", "1", "/", "math", ".", "sqrt", "(", "2", ")", ")", "\n", "nn", ".", "init", ".", "xavier_uniform_", "(", "self", ".", "v_proj", ".", "weight", ",", "gain", "=", "1", "/", "math", ".", "sqrt", "(", "2", ")", ")", "\n", "nn", ".", "init", ".", "xavier_uniform_", "(", "self", ".", "q_proj", ".", "weight", ",", "gain", "=", "1", "/", "math", ".", "sqrt", "(", "2", ")", ")", "\n", "", "else", ":", "\n", "            ", "nn", ".", "init", ".", "xavier_uniform_", "(", "self", ".", "k_proj", ".", "weight", ")", "\n", "nn", ".", "init", ".", "xavier_uniform_", "(", "self", ".", "v_proj", ".", "weight", ")", "\n", "nn", ".", "init", ".", "xavier_uniform_", "(", "self", ".", "q_proj", ".", "weight", ")", "\n", "\n", "", "nn", ".", "init", ".", "xavier_uniform_", "(", "self", ".", "out_proj", ".", "weight", ")", "\n", "nn", ".", "init", ".", "constant_", "(", "self", ".", "out_proj", ".", "bias", ",", "0.", ")", "\n", "if", "self", ".", "bias_k", "is", "not", "None", ":", "\n", "            ", "nn", ".", "init", ".", "xavier_normal_", "(", "self", ".", "bias_k", ")", "\n", "", "if", "self", ".", "bias_v", "is", "not", "None", ":", "\n", "            ", "nn", ".", "init", ".", "xavier_normal_", "(", "self", ".", "bias_v", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.modules.multihead_attention.MultiheadAttention.forward": [[88, 279], ["query.size", "multihead_attention.MultiheadAttention.contiguous().view().transpose", "torch.cat.size", "torch.cat.size", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "multihead_attention.MultiheadAttention.apply_sparse_mask", "fairseq.utils.softmax", "fairseq.utils.softmax.type_as", "torch.dropout", "torch.dropout", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "multihead_attention.MultiheadAttention.out_proj", "list", "torch.multi_head_attention_forward", "torch.multi_head_attention_forward", "multihead_attention.MultiheadAttention._get_input_buffer", "multihead_attention.MultiheadAttention.q_proj", "multihead_attention.MultiheadAttention.k_proj", "multihead_attention.MultiheadAttention.v_proj", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat.contiguous().view().transpose", "torch.cat.contiguous().view().transpose", "torch.cat.contiguous().view().transpose", "torch.cat.contiguous().view().transpose", "multihead_attention.MultiheadAttention._append_prev_key_padding_mask", "torch.cat.view", "torch.cat.view", "torch.cat.view", "torch.cat.view", "multihead_attention.MultiheadAttention._set_input_buffer", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat.transpose", "torch.cat.transpose", "list", "attn_mask.repeat.repeat.unsqueeze", "attn_weights.mean.mean.view", "attn_weights.mean.mean.masked_fill", "attn_weights.mean.mean.view", "fairseq.utils.softmax.type_as", "list", "attn.transpose().contiguous().view.transpose().contiguous().view.contiguous().view", "attn.transpose().contiguous().view.transpose().contiguous().view.transpose().contiguous().view", "fairseq.utils.softmax.view().transpose", "query.size", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "multihead_attention.MultiheadAttention.q_proj", "multihead_attention.MultiheadAttention.q_proj", "multihead_attention.MultiheadAttention.k_proj", "multihead_attention.MultiheadAttention.v_proj", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "multihead_attention.MultiheadAttention.contiguous().view", "saved_state[].view", "saved_state[].view", "torch.Size", "torch.Size", "torch.Size", "torch.Size", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "attn_weights.mean.mean.size", "attn_mask.repeat.repeat.repeat", "torch.cat.unsqueeze().unsqueeze", "torch.cat.unsqueeze().unsqueeze", "float", "attn.transpose().contiguous().view.transpose().contiguous().view.size", "attn.transpose().contiguous().view.transpose().contiguous().view.size", "attn_weights.mean.mean.mean", "multihead_attention.MultiheadAttention.k_proj", "multihead_attention.MultiheadAttention.v_proj", "multihead_attention.MultiheadAttention.bias_k.repeat", "multihead_attention.MultiheadAttention.bias_v.repeat", "torch.cat.contiguous().view", "torch.cat.contiguous().view", "torch.cat.contiguous().view", "torch.cat.contiguous().view", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "multihead_attention.MultiheadAttention.get", "torch.cat.size", "torch.cat.size", "torch.cat.new_zeros", "torch.cat.new_zeros", "torch.cat.new_zeros", "torch.cat.new_zeros", "attn_weights.mean.mean.size", "attn.transpose().contiguous().view.transpose().contiguous().view.contiguous", "attn.transpose().contiguous().view.transpose().contiguous().view.transpose().contiguous", "fairseq.utils.softmax.view", "attn_mask.repeat.repeat.new_zeros", "torch.cat.new_zeros", "torch.cat.new_zeros", "multihead_attention.MultiheadAttention.contiguous", "attn_mask.repeat.repeat.new_zeros", "torch.zeros().type_as", "torch.zeros().type_as", "torch.zeros().type_as", "torch.zeros().type_as", "torch.cat.unsqueeze", "torch.cat.unsqueeze", "attn_mask.repeat.repeat.size", "torch.cat.size", "torch.cat.size", "torch.cat.contiguous", "torch.cat.contiguous", "torch.cat.contiguous", "torch.cat.contiguous", "attn_mask.repeat.repeat.size", "attn.transpose().contiguous().view.transpose().contiguous().view.transpose", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.cat.size", "torch.cat.size"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.fairseq_dataset.FairseqDataset.size", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.fairseq_dataset.FairseqDataset.size", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.fairseq_dataset.FairseqDataset.size", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.modules.multihead_attention.MultiheadAttention.apply_sparse_mask", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.utils.softmax", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.modules.multihead_attention.MultiheadAttention._get_input_buffer", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.modules.multihead_attention.MultiheadAttention._append_prev_key_padding_mask", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.modules.multihead_attention.MultiheadAttention._set_input_buffer", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.fairseq_dataset.FairseqDataset.size", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.fairseq_dataset.FairseqDataset.size", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.fairseq_dataset.FairseqDataset.size", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.fairseq_dataset.FairseqDataset.size", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.fairseq_dataset.FairseqDataset.size", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.fairseq_dataset.FairseqDataset.size", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.fairseq_dataset.FairseqDataset.size", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.fairseq_dataset.FairseqDataset.size", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.fairseq_dataset.FairseqDataset.size", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.fairseq_dataset.FairseqDataset.size", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.fairseq_dataset.FairseqDataset.size", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.fairseq_dataset.FairseqDataset.size", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.fairseq_dataset.FairseqDataset.size", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.fairseq_dataset.FairseqDataset.size", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.fairseq_dataset.FairseqDataset.size", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.fairseq_dataset.FairseqDataset.size", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.fairseq_dataset.FairseqDataset.size", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.fairseq_dataset.FairseqDataset.size", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.fairseq_dataset.FairseqDataset.size", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.fairseq_dataset.FairseqDataset.size", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.fairseq_dataset.FairseqDataset.size", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.fairseq_dataset.FairseqDataset.size", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.fairseq_dataset.FairseqDataset.size", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.fairseq_dataset.FairseqDataset.size", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.fairseq_dataset.FairseqDataset.size"], ["", "", "def", "forward", "(", "\n", "self", ",", "\n", "query", ",", "key", ",", "value", ",", "\n", "key_padding_mask", "=", "None", ",", "\n", "incremental_state", "=", "None", ",", "\n", "need_weights", "=", "True", ",", "\n", "static_kv", "=", "False", ",", "\n", "attn_mask", "=", "None", ",", "\n", "before_softmax", "=", "False", ",", "\n", "need_head_weights", "=", "False", ",", "\n", ")", ":", "\n", "        ", "\"\"\"Input shape: Time x Batch x Channel\n\n        Args:\n            key_padding_mask (ByteTensor, optional): mask to exclude\n                keys that are pads, of shape `(batch, src_len)`, where\n                padding elements are indicated by 1s.\n            need_weights (bool, optional): return the attention weights,\n                averaged over heads (default: False).\n            attn_mask (ByteTensor, optional): typically used to\n                implement causal attention, where the mask prevents the\n                attention from looking forward in time (default: None).\n            before_softmax (bool, optional): return the raw attention\n                weights and values before the attention softmax.\n            need_head_weights (bool, optional): return the attention\n                weights for each head. Implies *need_weights*. Default:\n                return the average attention weights over all heads.\n        \"\"\"", "\n", "if", "need_head_weights", ":", "\n", "            ", "need_weights", "=", "True", "\n", "\n", "", "tgt_len", ",", "bsz", ",", "embed_dim", "=", "query", ".", "size", "(", ")", "\n", "assert", "embed_dim", "==", "self", ".", "embed_dim", "\n", "assert", "list", "(", "query", ".", "size", "(", ")", ")", "==", "[", "tgt_len", ",", "bsz", ",", "embed_dim", "]", "\n", "\n", "if", "self", ".", "enable_torch_version", "and", "not", "self", ".", "onnx_trace", "and", "incremental_state", "is", "None", "and", "not", "static_kv", ":", "\n", "            ", "return", "F", ".", "multi_head_attention_forward", "(", "query", ",", "key", ",", "value", ",", "\n", "self", ".", "embed_dim", ",", "self", ".", "num_heads", ",", "\n", "torch", ".", "empty", "(", "[", "0", "]", ")", ",", "\n", "torch", ".", "cat", "(", "(", "self", ".", "q_proj", ".", "bias", ",", "self", ".", "k_proj", ".", "bias", ",", "self", ".", "v_proj", ".", "bias", ")", ")", ",", "\n", "self", ".", "bias_k", ",", "self", ".", "bias_v", ",", "\n", "self", ".", "add_zero_attn", ",", "self", ".", "dropout", ",", "\n", "self", ".", "out_proj", ".", "weight", ",", "self", ".", "out_proj", ".", "bias", ",", "\n", "self", ".", "training", ",", "key_padding_mask", ",", "need_weights", ",", "\n", "attn_mask", ",", "use_separate_proj_weight", "=", "True", ",", "\n", "q_proj_weight", "=", "self", ".", "q_proj", ".", "weight", ",", "\n", "k_proj_weight", "=", "self", ".", "k_proj", ".", "weight", ",", "\n", "v_proj_weight", "=", "self", ".", "v_proj", ".", "weight", ")", "\n", "\n", "", "if", "incremental_state", "is", "not", "None", ":", "\n", "            ", "saved_state", "=", "self", ".", "_get_input_buffer", "(", "incremental_state", ")", "\n", "if", "'prev_key'", "in", "saved_state", ":", "\n", "# previous time steps are cached - no need to recompute", "\n", "# key and value if they are static", "\n", "                ", "if", "static_kv", ":", "\n", "                    ", "assert", "self", ".", "encoder_decoder_attention", "and", "not", "self", ".", "self_attention", "\n", "key", "=", "value", "=", "None", "\n", "", "", "", "else", ":", "\n", "            ", "saved_state", "=", "None", "\n", "\n", "", "if", "self", ".", "self_attention", ":", "\n", "            ", "q", "=", "self", ".", "q_proj", "(", "query", ")", "\n", "k", "=", "self", ".", "k_proj", "(", "query", ")", "\n", "v", "=", "self", ".", "v_proj", "(", "query", ")", "\n", "", "elif", "self", ".", "encoder_decoder_attention", ":", "\n", "# encoder-decoder attention", "\n", "            ", "q", "=", "self", ".", "q_proj", "(", "query", ")", "\n", "if", "key", "is", "None", ":", "\n", "                ", "assert", "value", "is", "None", "\n", "k", "=", "v", "=", "None", "\n", "", "else", ":", "\n", "                ", "k", "=", "self", ".", "k_proj", "(", "key", ")", "\n", "v", "=", "self", ".", "v_proj", "(", "key", ")", "\n", "\n", "", "", "else", ":", "\n", "            ", "q", "=", "self", ".", "q_proj", "(", "query", ")", "\n", "k", "=", "self", ".", "k_proj", "(", "key", ")", "\n", "v", "=", "self", ".", "v_proj", "(", "value", ")", "\n", "", "q", "*=", "self", ".", "scaling", "\n", "\n", "if", "self", ".", "bias_k", "is", "not", "None", ":", "\n", "            ", "assert", "self", ".", "bias_v", "is", "not", "None", "\n", "k", "=", "torch", ".", "cat", "(", "[", "k", ",", "self", ".", "bias_k", ".", "repeat", "(", "1", ",", "bsz", ",", "1", ")", "]", ")", "\n", "v", "=", "torch", ".", "cat", "(", "[", "v", ",", "self", ".", "bias_v", ".", "repeat", "(", "1", ",", "bsz", ",", "1", ")", "]", ")", "\n", "if", "attn_mask", "is", "not", "None", ":", "\n", "                ", "attn_mask", "=", "torch", ".", "cat", "(", "[", "attn_mask", ",", "attn_mask", ".", "new_zeros", "(", "attn_mask", ".", "size", "(", "0", ")", ",", "1", ")", "]", ",", "dim", "=", "1", ")", "\n", "", "if", "key_padding_mask", "is", "not", "None", ":", "\n", "                ", "key_padding_mask", "=", "torch", ".", "cat", "(", "\n", "[", "key_padding_mask", ",", "key_padding_mask", ".", "new_zeros", "(", "key_padding_mask", ".", "size", "(", "0", ")", ",", "1", ")", "]", ",", "dim", "=", "1", ")", "\n", "\n", "", "", "q", "=", "q", ".", "contiguous", "(", ")", ".", "view", "(", "tgt_len", ",", "bsz", "*", "self", ".", "num_heads", ",", "self", ".", "head_dim", ")", ".", "transpose", "(", "0", ",", "1", ")", "\n", "if", "k", "is", "not", "None", ":", "\n", "            ", "k", "=", "k", ".", "contiguous", "(", ")", ".", "view", "(", "-", "1", ",", "bsz", "*", "self", ".", "num_heads", ",", "self", ".", "head_dim", ")", ".", "transpose", "(", "0", ",", "1", ")", "\n", "", "if", "v", "is", "not", "None", ":", "\n", "            ", "v", "=", "v", ".", "contiguous", "(", ")", ".", "view", "(", "-", "1", ",", "bsz", "*", "self", ".", "num_heads", ",", "self", ".", "head_dim", ")", ".", "transpose", "(", "0", ",", "1", ")", "\n", "\n", "", "if", "saved_state", "is", "not", "None", ":", "\n", "# saved states are stored with shape (bsz, num_heads, seq_len, head_dim)", "\n", "            ", "if", "'prev_key'", "in", "saved_state", ":", "\n", "                ", "prev_key", "=", "saved_state", "[", "'prev_key'", "]", ".", "view", "(", "bsz", "*", "self", ".", "num_heads", ",", "-", "1", ",", "self", ".", "head_dim", ")", "\n", "if", "static_kv", ":", "\n", "                    ", "k", "=", "prev_key", "\n", "", "else", ":", "\n", "                    ", "k", "=", "torch", ".", "cat", "(", "(", "prev_key", ",", "k", ")", ",", "dim", "=", "1", ")", "\n", "", "", "if", "'prev_value'", "in", "saved_state", ":", "\n", "                ", "prev_value", "=", "saved_state", "[", "'prev_value'", "]", ".", "view", "(", "bsz", "*", "self", ".", "num_heads", ",", "-", "1", ",", "self", ".", "head_dim", ")", "\n", "if", "static_kv", ":", "\n", "                    ", "v", "=", "prev_value", "\n", "", "else", ":", "\n", "                    ", "v", "=", "torch", ".", "cat", "(", "(", "prev_value", ",", "v", ")", ",", "dim", "=", "1", ")", "\n", "", "", "key_padding_mask", "=", "self", ".", "_append_prev_key_padding_mask", "(", "\n", "key_padding_mask", "=", "key_padding_mask", ",", "\n", "prev_key_padding_mask", "=", "saved_state", ".", "get", "(", "'prev_key_padding_mask'", ",", "None", ")", ",", "\n", "batch_size", "=", "bsz", ",", "\n", "src_len", "=", "k", ".", "size", "(", "1", ")", ",", "\n", "static_kv", "=", "static_kv", ",", "\n", ")", "\n", "\n", "saved_state", "[", "'prev_key'", "]", "=", "k", ".", "view", "(", "bsz", ",", "self", ".", "num_heads", ",", "-", "1", ",", "self", ".", "head_dim", ")", "\n", "saved_state", "[", "'prev_value'", "]", "=", "v", ".", "view", "(", "bsz", ",", "self", ".", "num_heads", ",", "-", "1", ",", "self", ".", "head_dim", ")", "\n", "saved_state", "[", "'prev_key_padding_mask'", "]", "=", "key_padding_mask", "\n", "\n", "self", ".", "_set_input_buffer", "(", "incremental_state", ",", "saved_state", ")", "\n", "\n", "", "src_len", "=", "k", ".", "size", "(", "1", ")", "\n", "\n", "# This is part of a workaround to get around fork/join parallelism", "\n", "# not supporting Optional types.", "\n", "if", "key_padding_mask", "is", "not", "None", "and", "key_padding_mask", ".", "shape", "==", "torch", ".", "Size", "(", "[", "]", ")", ":", "\n", "            ", "key_padding_mask", "=", "None", "\n", "\n", "", "if", "key_padding_mask", "is", "not", "None", ":", "\n", "            ", "assert", "key_padding_mask", ".", "size", "(", "0", ")", "==", "bsz", "\n", "assert", "key_padding_mask", ".", "size", "(", "1", ")", "==", "src_len", "\n", "\n", "", "if", "self", ".", "add_zero_attn", ":", "\n", "            ", "src_len", "+=", "1", "\n", "k", "=", "torch", ".", "cat", "(", "[", "k", ",", "k", ".", "new_zeros", "(", "(", "k", ".", "size", "(", "0", ")", ",", "1", ")", "+", "k", ".", "size", "(", ")", "[", "2", ":", "]", ")", "]", ",", "dim", "=", "1", ")", "\n", "v", "=", "torch", ".", "cat", "(", "[", "v", ",", "v", ".", "new_zeros", "(", "(", "v", ".", "size", "(", "0", ")", ",", "1", ")", "+", "v", ".", "size", "(", ")", "[", "2", ":", "]", ")", "]", ",", "dim", "=", "1", ")", "\n", "if", "attn_mask", "is", "not", "None", ":", "\n", "                ", "attn_mask", "=", "torch", ".", "cat", "(", "[", "attn_mask", ",", "attn_mask", ".", "new_zeros", "(", "attn_mask", ".", "size", "(", "0", ")", ",", "1", ")", "]", ",", "dim", "=", "1", ")", "\n", "", "if", "key_padding_mask", "is", "not", "None", ":", "\n", "                ", "key_padding_mask", "=", "torch", ".", "cat", "(", "\n", "[", "key_padding_mask", ",", "torch", ".", "zeros", "(", "key_padding_mask", ".", "size", "(", "0", ")", ",", "1", ")", ".", "type_as", "(", "key_padding_mask", ")", "]", ",", "dim", "=", "1", ")", "\n", "\n", "", "", "attn_weights", "=", "torch", ".", "bmm", "(", "q", ",", "k", ".", "transpose", "(", "1", ",", "2", ")", ")", "\n", "attn_weights", "=", "self", ".", "apply_sparse_mask", "(", "attn_weights", ",", "tgt_len", ",", "src_len", ",", "bsz", ")", "\n", "\n", "assert", "list", "(", "attn_weights", ".", "size", "(", ")", ")", "==", "[", "bsz", "*", "self", ".", "num_heads", ",", "tgt_len", ",", "src_len", "]", "\n", "\n", "if", "attn_mask", "is", "not", "None", ":", "\n", "            ", "attn_mask", "=", "attn_mask", ".", "unsqueeze", "(", "0", ")", "\n", "if", "self", ".", "onnx_trace", ":", "\n", "                ", "attn_mask", "=", "attn_mask", ".", "repeat", "(", "attn_weights", ".", "size", "(", "0", ")", ",", "1", ",", "1", ")", "\n", "", "attn_weights", "+=", "attn_mask", "\n", "\n", "", "if", "key_padding_mask", "is", "not", "None", ":", "\n", "# don't attend to padding symbols", "\n", "            ", "attn_weights", "=", "attn_weights", ".", "view", "(", "bsz", ",", "self", ".", "num_heads", ",", "tgt_len", ",", "src_len", ")", "\n", "attn_weights", "=", "attn_weights", ".", "masked_fill", "(", "\n", "key_padding_mask", ".", "unsqueeze", "(", "1", ")", ".", "unsqueeze", "(", "2", ")", ",", "\n", "float", "(", "'-inf'", ")", ",", "\n", ")", "\n", "attn_weights", "=", "attn_weights", ".", "view", "(", "bsz", "*", "self", ".", "num_heads", ",", "tgt_len", ",", "src_len", ")", "\n", "\n", "", "if", "before_softmax", ":", "\n", "            ", "return", "attn_weights", ",", "v", "\n", "\n", "", "attn_weights_float", "=", "utils", ".", "softmax", "(", "attn_weights", ",", "dim", "=", "-", "1", ",", "onnx_trace", "=", "self", ".", "onnx_trace", ")", "\n", "attn_weights", "=", "attn_weights_float", ".", "type_as", "(", "attn_weights", ")", "\n", "attn_probs", "=", "F", ".", "dropout", "(", "attn_weights_float", ".", "type_as", "(", "attn_weights", ")", ",", "p", "=", "self", ".", "dropout", ",", "training", "=", "self", ".", "training", ")", "\n", "\n", "attn", "=", "torch", ".", "bmm", "(", "attn_probs", ",", "v", ")", "\n", "assert", "list", "(", "attn", ".", "size", "(", ")", ")", "==", "[", "bsz", "*", "self", ".", "num_heads", ",", "tgt_len", ",", "self", ".", "head_dim", "]", "\n", "if", "(", "self", ".", "onnx_trace", "and", "attn", ".", "size", "(", "1", ")", "==", "1", ")", ":", "\n", "# when ONNX tracing a single decoder step (sequence length == 1)", "\n", "# the transpose is a no-op copy before view, thus unnecessary", "\n", "            ", "attn", "=", "attn", ".", "contiguous", "(", ")", ".", "view", "(", "tgt_len", ",", "bsz", ",", "embed_dim", ")", "\n", "", "else", ":", "\n", "            ", "attn", "=", "attn", ".", "transpose", "(", "0", ",", "1", ")", ".", "contiguous", "(", ")", ".", "view", "(", "tgt_len", ",", "bsz", ",", "embed_dim", ")", "\n", "", "attn", "=", "self", ".", "out_proj", "(", "attn", ")", "\n", "\n", "if", "need_weights", ":", "\n", "            ", "attn_weights", "=", "attn_weights_float", ".", "view", "(", "bsz", ",", "self", ".", "num_heads", ",", "tgt_len", ",", "src_len", ")", ".", "transpose", "(", "1", ",", "0", ")", "\n", "if", "not", "need_head_weights", ":", "\n", "# average attention weights over heads", "\n", "                ", "attn_weights", "=", "attn_weights", ".", "mean", "(", "dim", "=", "0", ")", "\n", "", "", "else", ":", "\n", "            ", "attn_weights", "=", "None", "\n", "\n", "", "return", "attn", ",", "attn_weights", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.modules.multihead_attention.MultiheadAttention._append_prev_key_padding_mask": [[280, 307], ["torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.zeros().bool", "torch.zeros().bool", "torch.zeros().bool", "torch.zeros().bool", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "filler.cuda.cuda.cuda", "torch.zeros().bool", "torch.zeros().bool", "torch.zeros().bool", "torch.zeros().bool", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "filler.cuda.cuda.cuda", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "prev_key_padding_mask.size", "torch.cat.size", "torch.cat.size"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.fairseq_dataset.FairseqDataset.size", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.fairseq_dataset.FairseqDataset.size", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.fairseq_dataset.FairseqDataset.size"], ["", "@", "staticmethod", "\n", "def", "_append_prev_key_padding_mask", "(", "\n", "key_padding_mask", ",", "\n", "prev_key_padding_mask", ",", "\n", "batch_size", ",", "\n", "src_len", ",", "\n", "static_kv", ",", "\n", ")", ":", "\n", "# saved key padding masks have shape (bsz, seq_len)", "\n", "        ", "if", "prev_key_padding_mask", "is", "not", "None", "and", "static_kv", ":", "\n", "            ", "key_padding_mask", "=", "prev_key_padding_mask", "\n", "", "elif", "prev_key_padding_mask", "is", "not", "None", "and", "key_padding_mask", "is", "not", "None", ":", "\n", "            ", "key_padding_mask", "=", "torch", ".", "cat", "(", "(", "prev_key_padding_mask", ",", "key_padding_mask", ")", ",", "dim", "=", "1", ")", "\n", "# During incremental decoding, as the padding token enters and", "\n", "# leaves the frame, there will be a time when prev or current", "\n", "# is None", "\n", "", "elif", "prev_key_padding_mask", "is", "not", "None", ":", "\n", "            ", "filler", "=", "torch", ".", "zeros", "(", "batch_size", ",", "src_len", "-", "prev_key_padding_mask", ".", "size", "(", "1", ")", ")", ".", "bool", "(", ")", "\n", "if", "prev_key_padding_mask", ".", "is_cuda", ":", "\n", "                ", "filler", "=", "filler", ".", "cuda", "(", ")", "\n", "", "key_padding_mask", "=", "torch", ".", "cat", "(", "(", "prev_key_padding_mask", ",", "filler", ")", ",", "dim", "=", "1", ")", "\n", "", "elif", "key_padding_mask", "is", "not", "None", ":", "\n", "            ", "filler", "=", "torch", ".", "zeros", "(", "batch_size", ",", "src_len", "-", "key_padding_mask", ".", "size", "(", "1", ")", ")", ".", "bool", "(", ")", "\n", "if", "key_padding_mask", ".", "is_cuda", ":", "\n", "                ", "filler", "=", "filler", ".", "cuda", "(", ")", "\n", "", "key_padding_mask", "=", "torch", ".", "cat", "(", "(", "filler", ",", "key_padding_mask", ")", ",", "dim", "=", "1", ")", "\n", "", "return", "key_padding_mask", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.modules.multihead_attention.MultiheadAttention.reorder_incremental_state": [[308, 316], ["multihead_attention.MultiheadAttention._get_input_buffer", "multihead_attention.MultiheadAttention.keys", "multihead_attention.MultiheadAttention._set_input_buffer", "input_buffer[].index_select"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.modules.multihead_attention.MultiheadAttention._get_input_buffer", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.modules.multihead_attention.MultiheadAttention._set_input_buffer"], ["", "def", "reorder_incremental_state", "(", "self", ",", "incremental_state", ",", "new_order", ")", ":", "\n", "        ", "\"\"\"Reorder buffered internal state (for incremental generation).\"\"\"", "\n", "input_buffer", "=", "self", ".", "_get_input_buffer", "(", "incremental_state", ")", "\n", "if", "input_buffer", "is", "not", "None", ":", "\n", "            ", "for", "k", "in", "input_buffer", ".", "keys", "(", ")", ":", "\n", "                ", "if", "input_buffer", "[", "k", "]", "is", "not", "None", ":", "\n", "                    ", "input_buffer", "[", "k", "]", "=", "input_buffer", "[", "k", "]", ".", "index_select", "(", "0", ",", "new_order", ")", "\n", "", "", "self", ".", "_set_input_buffer", "(", "incremental_state", ",", "input_buffer", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.modules.multihead_attention.MultiheadAttention._get_input_buffer": [[317, 323], ["fairseq.utils.get_incremental_state"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.utils.get_incremental_state"], ["", "", "def", "_get_input_buffer", "(", "self", ",", "incremental_state", ")", ":", "\n", "        ", "return", "utils", ".", "get_incremental_state", "(", "\n", "self", ",", "\n", "incremental_state", ",", "\n", "'attn_state'", ",", "\n", ")", "or", "{", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.modules.multihead_attention.MultiheadAttention._set_input_buffer": [[324, 330], ["fairseq.utils.set_incremental_state"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.utils.set_incremental_state"], ["", "def", "_set_input_buffer", "(", "self", ",", "incremental_state", ",", "buffer", ")", ":", "\n", "        ", "utils", ".", "set_incremental_state", "(", "\n", "self", ",", "\n", "incremental_state", ",", "\n", "'attn_state'", ",", "\n", "buffer", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.modules.multihead_attention.MultiheadAttention.apply_sparse_mask": [[332, 334], ["None"], "methods", ["None"], ["", "def", "apply_sparse_mask", "(", "self", ",", "attn_weights", ",", "tgt_len", ",", "src_len", ",", "bsz", ")", ":", "\n", "        ", "return", "attn_weights", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.modules.multihead_attention.MultiheadAttention.upgrade_state_dict_named": [[335, 363], ["state_dict.keys", "items_to_add.items", "k.endswith", "int", "keys_to_remove.append", "state_dict.keys", "int", "keys_to_remove.append"], "methods", ["None"], ["", "def", "upgrade_state_dict_named", "(", "self", ",", "state_dict", ",", "name", ")", ":", "\n", "        ", "prefix", "=", "name", "+", "'.'", "if", "name", "!=", "''", "else", "''", "\n", "items_to_add", "=", "{", "}", "\n", "keys_to_remove", "=", "[", "]", "\n", "for", "k", "in", "state_dict", ".", "keys", "(", ")", ":", "\n", "            ", "if", "k", ".", "endswith", "(", "prefix", "+", "'in_proj_weight'", ")", ":", "\n", "# in_proj_weight used to be q + k + v with same dimensions", "\n", "                ", "dim", "=", "int", "(", "state_dict", "[", "k", "]", ".", "shape", "[", "0", "]", "/", "3", ")", "\n", "items_to_add", "[", "prefix", "+", "'q_proj.weight'", "]", "=", "state_dict", "[", "k", "]", "[", ":", "dim", "]", "\n", "items_to_add", "[", "prefix", "+", "'k_proj.weight'", "]", "=", "state_dict", "[", "k", "]", "[", "dim", ":", "2", "*", "dim", "]", "\n", "items_to_add", "[", "prefix", "+", "'v_proj.weight'", "]", "=", "state_dict", "[", "k", "]", "[", "2", "*", "dim", ":", "]", "\n", "\n", "keys_to_remove", ".", "append", "(", "k", ")", "\n", "\n", "k_bias", "=", "prefix", "+", "'in_proj_bias'", "\n", "if", "k_bias", "in", "state_dict", ".", "keys", "(", ")", ":", "\n", "                    ", "dim", "=", "int", "(", "state_dict", "[", "k", "]", ".", "shape", "[", "0", "]", "/", "3", ")", "\n", "items_to_add", "[", "prefix", "+", "'q_proj.bias'", "]", "=", "state_dict", "[", "k_bias", "]", "[", ":", "dim", "]", "\n", "items_to_add", "[", "prefix", "+", "'k_proj.bias'", "]", "=", "state_dict", "[", "k_bias", "]", "[", "dim", ":", "2", "*", "dim", "]", "\n", "items_to_add", "[", "prefix", "+", "'v_proj.bias'", "]", "=", "state_dict", "[", "k_bias", "]", "[", "2", "*", "dim", ":", "]", "\n", "\n", "keys_to_remove", ".", "append", "(", "prefix", "+", "'in_proj_bias'", ")", "\n", "\n", "", "", "", "for", "k", "in", "keys_to_remove", ":", "\n", "            ", "del", "state_dict", "[", "k", "]", "\n", "\n", "", "for", "key", ",", "value", "in", "items_to_add", ".", "items", "(", ")", ":", "\n", "            ", "state_dict", "[", "key", "]", "=", "value", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.modules.beamable_mm.BeamableMM.__init__": [[18, 21], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.dummy_dictionary.DummyDictionary.__init__"], ["def", "__init__", "(", "self", ",", "beam_size", "=", "None", ")", ":", "\n", "        ", "super", "(", "BeamableMM", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "beam_size", "=", "beam_size", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.modules.beamable_mm.BeamableMM.forward": [[22, 45], ["input1[].unfold().transpose", "input1[].unfold().transpose.bmm.view", "input1[].unfold().transpose.bmm", "input1[].unfold().transpose.dim", "input1[].unfold().transpose.size", "input1[].unfold().transpose.size", "input2.unfold", "input1[].unfold().transpose.size", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "input1[].unfold().transpose.bmm", "input1[].unfold"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.fairseq_dataset.FairseqDataset.size", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.fairseq_dataset.FairseqDataset.size", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.fairseq_dataset.FairseqDataset.size"], ["", "def", "forward", "(", "self", ",", "input1", ",", "input2", ")", ":", "\n", "        ", "if", "(", "\n", "not", "self", ".", "training", "and", "# test mode", "\n", "self", ".", "beam_size", "is", "not", "None", "and", "# beam size is set", "\n", "input1", ".", "dim", "(", ")", "==", "3", "and", "# only support batched input", "\n", "input1", ".", "size", "(", "1", ")", "==", "1", "# single time step update", "\n", ")", ":", "\n", "            ", "bsz", ",", "beam", "=", "input1", ".", "size", "(", "0", ")", ",", "self", ".", "beam_size", "\n", "\n", "# bsz x 1 x nhu --> bsz/beam x beam x nhu", "\n", "input1", "=", "input1", "[", ":", ",", "0", ",", ":", "]", ".", "unfold", "(", "0", ",", "beam", ",", "beam", ")", ".", "transpose", "(", "2", ",", "1", ")", "\n", "\n", "# bsz x sz2 x nhu --> bsz/beam x sz2 x nhu", "\n", "input2", "=", "input2", ".", "unfold", "(", "0", ",", "beam", ",", "beam", ")", "[", ":", ",", ":", ",", ":", ",", "0", "]", "\n", "\n", "# use non batched operation if bsz = beam", "\n", "if", "input1", ".", "size", "(", "0", ")", "==", "1", ":", "\n", "                ", "output", "=", "torch", ".", "mm", "(", "input1", "[", "0", ",", ":", ",", ":", "]", ",", "input2", "[", "0", ",", ":", ",", ":", "]", ")", "\n", "", "else", ":", "\n", "                ", "output", "=", "input1", ".", "bmm", "(", "input2", ")", "\n", "", "return", "output", ".", "view", "(", "bsz", ",", "1", ",", "-", "1", ")", "\n", "", "else", ":", "\n", "            ", "return", "input1", ".", "bmm", "(", "input2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.modules.beamable_mm.BeamableMM.set_beam_size": [[46, 48], ["None"], "methods", ["None"], ["", "", "def", "set_beam_size", "(", "self", ",", "beam_size", ")", ":", "\n", "        ", "self", ".", "beam_size", "=", "beam_size", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.modules.sinusoidal_positional_embedding.SinusoidalPositionalEmbedding.__init__": [[21, 32], ["torch.Module.__init__", "sinusoidal_positional_embedding.SinusoidalPositionalEmbedding.get_embedding", "sinusoidal_positional_embedding.SinusoidalPositionalEmbedding.register_buffer", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.dummy_dictionary.DummyDictionary.__init__", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.modules.sinusoidal_positional_embedding.SinusoidalPositionalEmbedding.get_embedding"], ["def", "__init__", "(", "self", ",", "embedding_dim", ",", "padding_idx", ",", "init_size", "=", "1024", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "embedding_dim", "=", "embedding_dim", "\n", "self", ".", "padding_idx", "=", "padding_idx", "\n", "self", ".", "weights", "=", "SinusoidalPositionalEmbedding", ".", "get_embedding", "(", "\n", "init_size", ",", "\n", "embedding_dim", ",", "\n", "padding_idx", ",", "\n", ")", "\n", "self", ".", "onnx_trace", "=", "False", "\n", "self", ".", "register_buffer", "(", "'_float_tensor'", ",", "torch", ".", "FloatTensor", "(", "1", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.modules.sinusoidal_positional_embedding.SinusoidalPositionalEmbedding.prepare_for_onnx_export_": [[33, 35], ["None"], "methods", ["None"], ["", "def", "prepare_for_onnx_export_", "(", "self", ")", ":", "\n", "        ", "self", ".", "onnx_trace", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.modules.sinusoidal_positional_embedding.SinusoidalPositionalEmbedding.get_embedding": [[36, 54], ["torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.cat().view", "torch.cat().view", "torch.cat().view", "torch.cat().view", "torch.cat().view", "torch.cat().view", "torch.cat().view", "torch.cat().view", "torch.cat().view", "math.log", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.cat.unsqueeze", "torch.cat.unsqueeze", "torch.cat.unsqueeze", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.sin", "torch.sin", "torch.sin", "torch.sin", "torch.sin", "torch.sin", "torch.sin", "torch.sin", "torch.sin", "torch.cos", "torch.cos", "torch.cos", "torch.cos", "torch.cos", "torch.cos", "torch.cos", "torch.cos", "torch.cos"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.progress_bar.tensorboard_log_wrapper.log"], ["", "@", "staticmethod", "\n", "def", "get_embedding", "(", "num_embeddings", ",", "embedding_dim", ",", "padding_idx", "=", "None", ")", ":", "\n", "        ", "\"\"\"Build sinusoidal embeddings.\n\n        This matches the implementation in tensor2tensor, but differs slightly\n        from the description in Section 3.5 of \"Attention Is All You Need\".\n        \"\"\"", "\n", "half_dim", "=", "embedding_dim", "//", "2", "\n", "emb", "=", "math", ".", "log", "(", "10000", ")", "/", "(", "half_dim", "-", "1", ")", "\n", "emb", "=", "torch", ".", "exp", "(", "torch", ".", "arange", "(", "half_dim", ",", "dtype", "=", "torch", ".", "float", ")", "*", "-", "emb", ")", "\n", "emb", "=", "torch", ".", "arange", "(", "num_embeddings", ",", "dtype", "=", "torch", ".", "float", ")", ".", "unsqueeze", "(", "1", ")", "*", "emb", ".", "unsqueeze", "(", "0", ")", "\n", "emb", "=", "torch", ".", "cat", "(", "[", "torch", ".", "sin", "(", "emb", ")", ",", "torch", ".", "cos", "(", "emb", ")", "]", ",", "dim", "=", "1", ")", ".", "view", "(", "num_embeddings", ",", "-", "1", ")", "\n", "if", "embedding_dim", "%", "2", "==", "1", ":", "\n", "# zero pad", "\n", "            ", "emb", "=", "torch", ".", "cat", "(", "[", "emb", ",", "torch", ".", "zeros", "(", "num_embeddings", ",", "1", ")", "]", ",", "dim", "=", "1", ")", "\n", "", "if", "padding_idx", "is", "not", "None", ":", "\n", "            ", "emb", "[", "padding_idx", ",", ":", "]", "=", "0", "\n", "", "return", "emb", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.modules.sinusoidal_positional_embedding.SinusoidalPositionalEmbedding.forward": [[55, 82], ["torch.onnx.operators.shape_as_tensor", "torch.onnx.operators.shape_as_tensor", "torch.onnx.operators.shape_as_tensor", "torch.onnx.operators.shape_as_tensor", "torch.onnx.operators.shape_as_tensor", "torch.onnx.operators.shape_as_tensor", "torch.onnx.operators.shape_as_tensor", "torch.onnx.operators.shape_as_tensor", "torch.onnx.operators.shape_as_tensor", "sinusoidal_positional_embedding.SinusoidalPositionalEmbedding.weights.to", "fairseq.utils.make_positions", "sinusoidal_positional_embedding.SinusoidalPositionalEmbedding.weights.index_select().view().detach", "sinusoidal_positional_embedding.SinusoidalPositionalEmbedding.get_embedding", "sinusoidal_positional_embedding.SinusoidalPositionalEmbedding.weights[].expand", "sinusoidal_positional_embedding.SinusoidalPositionalEmbedding.weights.detach().index_select", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.onnx.operators.reshape_from_tensor_shape", "torch.onnx.operators.reshape_from_tensor_shape", "torch.onnx.operators.reshape_from_tensor_shape", "torch.onnx.operators.reshape_from_tensor_shape", "torch.onnx.operators.reshape_from_tensor_shape", "torch.onnx.operators.reshape_from_tensor_shape", "torch.onnx.operators.reshape_from_tensor_shape", "torch.onnx.operators.reshape_from_tensor_shape", "torch.onnx.operators.reshape_from_tensor_shape", "sinusoidal_positional_embedding.SinusoidalPositionalEmbedding.weights.size", "sinusoidal_positional_embedding.SinusoidalPositionalEmbedding.weights.index_select().unsqueeze().repeat", "fairseq.utils.make_positions.view", "sinusoidal_positional_embedding.SinusoidalPositionalEmbedding.weights.index_select().view", "sinusoidal_positional_embedding.SinusoidalPositionalEmbedding.weights.detach", "bsz.view", "seq_len.view", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "timestep.view", "sinusoidal_positional_embedding.SinusoidalPositionalEmbedding.weights.index_select().unsqueeze", "sinusoidal_positional_embedding.SinusoidalPositionalEmbedding.weights.index_select", "fairseq.utils.make_positions.view", "sinusoidal_positional_embedding.SinusoidalPositionalEmbedding.weights.index_select"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.utils.make_positions", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.modules.sinusoidal_positional_embedding.SinusoidalPositionalEmbedding.get_embedding", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.fairseq_dataset.FairseqDataset.size"], ["", "def", "forward", "(", "self", ",", "input", ",", "incremental_state", "=", "None", ",", "timestep", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"Input is expected to be of size [bsz x seqlen].\"\"\"", "\n", "bsz", ",", "seq_len", "=", "torch", ".", "onnx", ".", "operators", ".", "shape_as_tensor", "(", "input", ")", "\n", "max_pos", "=", "self", ".", "padding_idx", "+", "1", "+", "seq_len", "\n", "if", "self", ".", "weights", "is", "None", "or", "max_pos", ">", "self", ".", "weights", ".", "size", "(", "0", ")", ":", "\n", "# recompute/expand embeddings if needed", "\n", "            ", "self", ".", "weights", "=", "SinusoidalPositionalEmbedding", ".", "get_embedding", "(", "\n", "max_pos", ",", "\n", "self", ".", "embedding_dim", ",", "\n", "self", ".", "padding_idx", ",", "\n", ")", "\n", "", "self", ".", "weights", "=", "self", ".", "weights", ".", "to", "(", "self", ".", "_float_tensor", ")", "\n", "\n", "if", "incremental_state", "is", "not", "None", ":", "\n", "# positions is the same for every token when decoding a single step", "\n", "            ", "pos", "=", "timestep", ".", "view", "(", "-", "1", ")", "[", "0", "]", "+", "1", "if", "timestep", "is", "not", "None", "else", "seq_len", "\n", "if", "self", ".", "onnx_trace", ":", "\n", "                ", "return", "self", ".", "weights", ".", "index_select", "(", "index", "=", "self", ".", "padding_idx", "+", "pos", ",", "dim", "=", "0", ")", ".", "unsqueeze", "(", "1", ")", ".", "repeat", "(", "bsz", ",", "1", ",", "1", ")", "\n", "", "return", "self", ".", "weights", "[", "self", ".", "padding_idx", "+", "pos", ",", ":", "]", ".", "expand", "(", "bsz", ",", "1", ",", "-", "1", ")", "\n", "\n", "", "positions", "=", "utils", ".", "make_positions", "(", "input", ",", "self", ".", "padding_idx", ",", "onnx_trace", "=", "self", ".", "onnx_trace", ")", "\n", "if", "self", ".", "onnx_trace", ":", "\n", "            ", "flat_embeddings", "=", "self", ".", "weights", ".", "detach", "(", ")", ".", "index_select", "(", "0", ",", "positions", ".", "view", "(", "-", "1", ")", ")", "\n", "embedding_shape", "=", "torch", ".", "cat", "(", "(", "bsz", ".", "view", "(", "1", ")", ",", "seq_len", ".", "view", "(", "1", ")", ",", "torch", ".", "LongTensor", "(", "[", "-", "1", "]", ")", ")", ")", "\n", "embeddings", "=", "torch", ".", "onnx", ".", "operators", ".", "reshape_from_tensor_shape", "(", "flat_embeddings", ",", "embedding_shape", ")", "\n", "return", "embeddings", "\n", "", "return", "self", ".", "weights", ".", "index_select", "(", "0", ",", "positions", ".", "view", "(", "-", "1", ")", ")", ".", "view", "(", "bsz", ",", "seq_len", ",", "-", "1", ")", ".", "detach", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.modules.sinusoidal_positional_embedding.SinusoidalPositionalEmbedding.max_positions": [[83, 86], ["int"], "methods", ["None"], ["", "def", "max_positions", "(", "self", ")", ":", "\n", "        ", "\"\"\"Maximum number of supported positions.\"\"\"", "\n", "return", "int", "(", "1e5", ")", "# an arbitrary large number", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.modules.layer_norm.LayerNorm": [[9, 17], ["torch.nn.LayerNorm", "torch.cuda.is_available", "FusedLayerNorm"], "function", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.modules.layer_norm.LayerNorm"], ["def", "LayerNorm", "(", "normalized_shape", ",", "eps", "=", "1e-5", ",", "elementwise_affine", "=", "True", ",", "export", "=", "False", ")", ":", "\n", "    ", "if", "not", "export", "and", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "        ", "try", ":", "\n", "            ", "from", "apex", ".", "normalization", "import", "FusedLayerNorm", "\n", "return", "FusedLayerNorm", "(", "normalized_shape", ",", "eps", ",", "elementwise_affine", ")", "\n", "", "except", "ImportError", ":", "\n", "            ", "pass", "\n", "", "", "return", "torch", ".", "nn", ".", "LayerNorm", "(", "normalized_shape", ",", "eps", ",", "elementwise_affine", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.modules.transformer_layer.TransformerEncoderLayer.__init__": [[28, 48], ["torch.Module.__init__", "fairseq.modules.MultiheadAttention", "fairseq.modules.LayerNorm", "fairseq.utils.get_activation_fn", "getattr", "transformer_layer.Linear", "transformer_layer.Linear", "fairseq.modules.LayerNorm", "getattr", "getattr"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.dummy_dictionary.DummyDictionary.__init__", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.modules.layer_norm.LayerNorm", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.utils.get_activation_fn", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.modules.transformer_layer.Linear", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.modules.transformer_layer.Linear", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.modules.layer_norm.LayerNorm"], ["def", "__init__", "(", "self", ",", "args", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "embed_dim", "=", "args", ".", "encoder_embed_dim", "\n", "self", ".", "self_attn", "=", "MultiheadAttention", "(", "\n", "self", ".", "embed_dim", ",", "args", ".", "encoder_attention_heads", ",", "\n", "dropout", "=", "args", ".", "attention_dropout", ",", "self_attention", "=", "True", "\n", ")", "\n", "self", ".", "self_attn_layer_norm", "=", "LayerNorm", "(", "self", ".", "embed_dim", ")", "\n", "self", ".", "dropout", "=", "args", ".", "dropout", "\n", "self", ".", "activation_fn", "=", "utils", ".", "get_activation_fn", "(", "\n", "activation", "=", "getattr", "(", "args", ",", "'activation_fn'", ",", "'relu'", ")", "\n", ")", "\n", "self", ".", "activation_dropout", "=", "getattr", "(", "args", ",", "'activation_dropout'", ",", "0", ")", "\n", "if", "self", ".", "activation_dropout", "==", "0", ":", "\n", "# for backwards compatibility with models that use args.relu_dropout", "\n", "            ", "self", ".", "activation_dropout", "=", "getattr", "(", "args", ",", "'relu_dropout'", ",", "0", ")", "\n", "", "self", ".", "normalize_before", "=", "args", ".", "encoder_normalize_before", "\n", "self", ".", "fc1", "=", "Linear", "(", "self", ".", "embed_dim", ",", "args", ".", "encoder_ffn_embed_dim", ")", "\n", "self", ".", "fc2", "=", "Linear", "(", "args", ".", "encoder_ffn_embed_dim", ",", "self", ".", "embed_dim", ")", "\n", "self", ".", "final_layer_norm", "=", "LayerNorm", "(", "self", ".", "embed_dim", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.modules.transformer_layer.TransformerEncoderLayer.upgrade_state_dict_named": [[49, 67], ["layer_norm_map.items"], "methods", ["None"], ["", "def", "upgrade_state_dict_named", "(", "self", ",", "state_dict", ",", "name", ")", ":", "\n", "        ", "\"\"\"\n        Rename layer norm states from `...layer_norms.0.weight` to\n        `...self_attn_layer_norm.weight` and `...layer_norms.1.weight` to\n        `...final_layer_norm.weight`\n        \"\"\"", "\n", "layer_norm_map", "=", "{", "\n", "'0'", ":", "'self_attn_layer_norm'", ",", "\n", "'1'", ":", "'final_layer_norm'", "\n", "}", "\n", "for", "old", ",", "new", "in", "layer_norm_map", ".", "items", "(", ")", ":", "\n", "            ", "for", "m", "in", "(", "'weight'", ",", "'bias'", ")", ":", "\n", "                ", "k", "=", "'{}.layer_norms.{}.{}'", ".", "format", "(", "name", ",", "old", ",", "m", ")", "\n", "if", "k", "in", "state_dict", ":", "\n", "                    ", "state_dict", "[", "\n", "'{}.{}.{}'", ".", "format", "(", "name", ",", "new", ",", "m", ")", "\n", "]", "=", "state_dict", "[", "k", "]", "\n", "del", "state_dict", "[", "k", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.modules.transformer_layer.TransformerEncoderLayer.forward": [[68, 109], ["transformer_layer.TransformerEncoderLayer.maybe_layer_norm", "transformer_layer.TransformerEncoderLayer.self_attn", "torch.dropout", "torch.dropout", "torch.dropout", "transformer_layer.TransformerEncoderLayer.maybe_layer_norm", "transformer_layer.TransformerEncoderLayer.maybe_layer_norm", "transformer_layer.TransformerEncoderLayer.activation_fn", "torch.dropout", "torch.dropout", "torch.dropout", "transformer_layer.TransformerEncoderLayer.fc2", "torch.dropout", "torch.dropout", "torch.dropout", "transformer_layer.TransformerEncoderLayer.maybe_layer_norm", "attn_mask.masked_fill.masked_fill.masked_fill", "transformer_layer.TransformerEncoderLayer.fc1", "attn_mask.masked_fill.masked_fill.bool"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.modules.transformer_layer.TransformerDecoderLayer.maybe_layer_norm", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.modules.transformer_layer.TransformerDecoderLayer.maybe_layer_norm", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.modules.transformer_layer.TransformerDecoderLayer.maybe_layer_norm", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.modules.transformer_layer.TransformerDecoderLayer.maybe_layer_norm"], ["", "", "", "", "def", "forward", "(", "self", ",", "x", ",", "encoder_padding_mask", ",", "attn_mask", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            x (Tensor): input to the layer of shape `(seq_len, batch, embed_dim)`\n            encoder_padding_mask (ByteTensor): binary ByteTensor of shape\n                `(batch, src_len)` where padding elements are indicated by ``1``.\n            attn_mask (ByteTensor): binary tensor of shape (T_tgt, T_src), where\n            T_tgt is the length of query, while T_src is the length of key,\n            though here both query and key is x here,\n            attn_mask[t_tgt, t_src] = 1 means when calculating embedding\n            for t_tgt, t_src is excluded (or masked out), =0 means it is\n            included in attention\n\n        Returns:\n            encoded output of shape `(seq_len, batch, embed_dim)`\n        \"\"\"", "\n", "residual", "=", "x", "\n", "x", "=", "self", ".", "maybe_layer_norm", "(", "self", ".", "self_attn_layer_norm", ",", "x", ",", "before", "=", "True", ")", "\n", "if", "attn_mask", "is", "not", "None", ":", "\n", "            ", "attn_mask", "=", "attn_mask", ".", "masked_fill", "(", "attn_mask", ".", "bool", "(", ")", ",", "-", "1e8", ")", "\n", "# anything in original attn_mask = 1, becomes -1e8", "\n", "# anything in original attn_mask = 0, becomes 0", "\n", "# Note that we cannot use -inf here, because at some edge cases,", "\n", "# the attention weight (before softmax) for some padded element in query", "\n", "# will become -inf, which results in NaN in model parameters", "\n", "# TODO: to formally solve this problem, we need to change fairseq's", "\n", "# MultiheadAttention. We will do this later on.", "\n", "", "x", ",", "_", "=", "self", ".", "self_attn", "(", "query", "=", "x", ",", "key", "=", "x", ",", "value", "=", "x", ",", "key_padding_mask", "=", "encoder_padding_mask", ")", "\n", "x", "=", "F", ".", "dropout", "(", "x", ",", "p", "=", "self", ".", "dropout", ",", "training", "=", "self", ".", "training", ")", "\n", "x", "=", "residual", "+", "x", "\n", "x", "=", "self", ".", "maybe_layer_norm", "(", "self", ".", "self_attn_layer_norm", ",", "x", ",", "after", "=", "True", ")", "\n", "\n", "residual", "=", "x", "\n", "x", "=", "self", ".", "maybe_layer_norm", "(", "self", ".", "final_layer_norm", ",", "x", ",", "before", "=", "True", ")", "\n", "x", "=", "self", ".", "activation_fn", "(", "self", ".", "fc1", "(", "x", ")", ")", "\n", "x", "=", "F", ".", "dropout", "(", "x", ",", "p", "=", "self", ".", "activation_dropout", ",", "training", "=", "self", ".", "training", ")", "\n", "x", "=", "self", ".", "fc2", "(", "x", ")", "\n", "x", "=", "F", ".", "dropout", "(", "x", ",", "p", "=", "self", ".", "dropout", ",", "training", "=", "self", ".", "training", ")", "\n", "x", "=", "residual", "+", "x", "\n", "x", "=", "self", ".", "maybe_layer_norm", "(", "self", ".", "final_layer_norm", ",", "x", ",", "after", "=", "True", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.modules.transformer_layer.TransformerEncoderLayer.maybe_layer_norm": [[110, 116], ["layer_norm"], "methods", ["None"], ["", "def", "maybe_layer_norm", "(", "self", ",", "layer_norm", ",", "x", ",", "before", "=", "False", ",", "after", "=", "False", ")", ":", "\n", "        ", "assert", "before", "^", "after", "\n", "if", "after", "^", "self", ".", "normalize_before", ":", "\n", "            ", "return", "layer_norm", "(", "x", ")", "\n", "", "else", ":", "\n", "            ", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.modules.transformer_layer.TransformerDecoderLayer.__init__": [[135, 184], ["torch.Module.__init__", "getattr", "fairseq.modules.MultiheadAttention", "fairseq.utils.get_activation_fn", "getattr", "getattr", "fairseq.modules.LayerNorm", "transformer_layer.Linear", "transformer_layer.Linear", "fairseq.modules.LayerNorm", "getattr", "fairseq.modules.MultiheadAttention", "fairseq.modules.LayerNorm", "getattr", "getattr", "getattr"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.dummy_dictionary.DummyDictionary.__init__", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.utils.get_activation_fn", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.modules.layer_norm.LayerNorm", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.modules.transformer_layer.Linear", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.modules.transformer_layer.Linear", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.modules.layer_norm.LayerNorm", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.modules.layer_norm.LayerNorm"], ["def", "__init__", "(", "self", ",", "args", ",", "no_encoder_attn", "=", "False", ",", "add_bias_kv", "=", "False", ",", "add_zero_attn", "=", "False", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "embed_dim", "=", "args", ".", "decoder_embed_dim", "\n", "self", ".", "cross_self_attention", "=", "getattr", "(", "args", ",", "'cross_self_attention'", ",", "False", ")", "\n", "self", ".", "self_attn", "=", "MultiheadAttention", "(", "\n", "embed_dim", "=", "self", ".", "embed_dim", ",", "\n", "num_heads", "=", "args", ".", "decoder_attention_heads", ",", "\n", "dropout", "=", "args", ".", "attention_dropout", ",", "\n", "add_bias_kv", "=", "add_bias_kv", ",", "\n", "add_zero_attn", "=", "add_zero_attn", ",", "\n", "self_attention", "=", "not", "self", ".", "cross_self_attention", ",", "\n", ")", "\n", "self", ".", "dropout", "=", "args", ".", "dropout", "\n", "self", ".", "activation_fn", "=", "utils", ".", "get_activation_fn", "(", "\n", "activation", "=", "getattr", "(", "args", ",", "'activation_fn'", ",", "'relu'", ")", "\n", ")", "\n", "self", ".", "activation_dropout", "=", "getattr", "(", "args", ",", "'activation_dropout'", ",", "0", ")", "\n", "if", "self", ".", "activation_dropout", "==", "0", ":", "\n", "# for backwards compatibility with models that use args.relu_dropout", "\n", "            ", "self", ".", "activation_dropout", "=", "getattr", "(", "args", ",", "'relu_dropout'", ",", "0", ")", "\n", "", "self", ".", "normalize_before", "=", "args", ".", "decoder_normalize_before", "\n", "\n", "# use layerNorm rather than FusedLayerNorm for exporting.", "\n", "# char_inputs can be used to determint this.", "\n", "# TODO  remove this once we update apex with the fix", "\n", "export", "=", "getattr", "(", "args", ",", "'char_inputs'", ",", "False", ")", "\n", "self", ".", "self_attn_layer_norm", "=", "LayerNorm", "(", "self", ".", "embed_dim", ",", "export", "=", "export", ")", "\n", "\n", "if", "no_encoder_attn", ":", "\n", "            ", "self", ".", "encoder_attn", "=", "None", "\n", "self", ".", "encoder_attn_layer_norm", "=", "None", "\n", "", "else", ":", "\n", "            ", "self", ".", "encoder_attn", "=", "MultiheadAttention", "(", "\n", "self", ".", "embed_dim", ",", "\n", "args", ".", "decoder_attention_heads", ",", "\n", "kdim", "=", "getattr", "(", "args", ",", "'encoder_embed_dim'", ",", "None", ")", ",", "\n", "vdim", "=", "getattr", "(", "args", ",", "'encoder_embed_dim'", ",", "None", ")", ",", "\n", "dropout", "=", "args", ".", "attention_dropout", ",", "\n", "encoder_decoder_attention", "=", "True", ",", "\n", ")", "\n", "self", ".", "encoder_attn_layer_norm", "=", "LayerNorm", "(", "self", ".", "embed_dim", ",", "export", "=", "export", ")", "\n", "\n", "", "self", ".", "fc1", "=", "Linear", "(", "self", ".", "embed_dim", ",", "args", ".", "decoder_ffn_embed_dim", ")", "\n", "self", ".", "fc2", "=", "Linear", "(", "args", ".", "decoder_ffn_embed_dim", ",", "self", ".", "embed_dim", ")", "\n", "\n", "self", ".", "final_layer_norm", "=", "LayerNorm", "(", "self", ".", "embed_dim", ",", "export", "=", "export", ")", "\n", "self", ".", "need_attn", "=", "True", "\n", "\n", "self", ".", "onnx_trace", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.modules.transformer_layer.TransformerDecoderLayer.prepare_for_onnx_export_": [[185, 187], ["None"], "methods", ["None"], ["", "def", "prepare_for_onnx_export_", "(", "self", ")", ":", "\n", "        ", "self", ".", "onnx_trace", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.modules.transformer_layer.TransformerDecoderLayer.forward": [[188, 294], ["transformer_layer.TransformerDecoderLayer.maybe_layer_norm", "transformer_layer.TransformerDecoderLayer.self_attn", "torch.dropout", "torch.dropout", "torch.dropout", "transformer_layer.TransformerDecoderLayer.maybe_layer_norm", "transformer_layer.TransformerDecoderLayer.maybe_layer_norm", "transformer_layer.TransformerDecoderLayer.activation_fn", "torch.dropout", "torch.dropout", "torch.dropout", "transformer_layer.TransformerDecoderLayer.fc2", "torch.dropout", "torch.dropout", "torch.dropout", "transformer_layer.TransformerDecoderLayer.maybe_layer_norm", "transformer_layer.TransformerDecoderLayer.self_attn._set_input_buffer", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "transformer_layer.TransformerDecoderLayer.maybe_layer_norm", "transformer_layer.TransformerDecoderLayer.encoder_attn", "torch.dropout", "torch.dropout", "torch.dropout", "transformer_layer.TransformerDecoderLayer.maybe_layer_norm", "transformer_layer.TransformerDecoderLayer.fc1", "transformer_layer.TransformerDecoderLayer.self_attn._get_input_buffer", "len", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "transformer_layer.TransformerDecoderLayer.encoder_attn._set_input_buffer", "torch.cat.new().zero_", "torch.cat.new().zero_", "torch.cat.new().zero_", "len", "transformer_layer.TransformerDecoderLayer.self_attn._get_input_buffer", "transformer_layer.TransformerDecoderLayer.new().zero_", "torch.cat.new", "torch.cat.new", "torch.cat.new", "transformer_layer.TransformerDecoderLayer.new", "encoder_out.size", "encoder_out.size", "transformer_layer.TransformerDecoderLayer.size", "encoder_out.size"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.modules.transformer_layer.TransformerDecoderLayer.maybe_layer_norm", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.modules.transformer_layer.TransformerDecoderLayer.maybe_layer_norm", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.modules.transformer_layer.TransformerDecoderLayer.maybe_layer_norm", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.modules.transformer_layer.TransformerDecoderLayer.maybe_layer_norm", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.modules.multihead_attention.MultiheadAttention._set_input_buffer", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.modules.transformer_layer.TransformerDecoderLayer.maybe_layer_norm", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.modules.transformer_layer.TransformerDecoderLayer.maybe_layer_norm", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.modules.multihead_attention.MultiheadAttention._get_input_buffer", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.modules.multihead_attention.MultiheadAttention._set_input_buffer", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.modules.multihead_attention.MultiheadAttention._get_input_buffer", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.fairseq_dataset.FairseqDataset.size", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.fairseq_dataset.FairseqDataset.size", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.fairseq_dataset.FairseqDataset.size", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.fairseq_dataset.FairseqDataset.size"], ["", "def", "forward", "(", "\n", "self", ",", "\n", "x", ",", "\n", "encoder_out", "=", "None", ",", "\n", "encoder_padding_mask", "=", "None", ",", "\n", "incremental_state", "=", "None", ",", "\n", "prev_self_attn_state", "=", "None", ",", "\n", "prev_attn_state", "=", "None", ",", "\n", "self_attn_mask", "=", "None", ",", "\n", "self_attn_padding_mask", "=", "None", ",", "\n", "need_attn", "=", "False", ",", "\n", "need_head_weights", "=", "False", ",", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            x (Tensor): input to the layer of shape `(seq_len, batch, embed_dim)`\n            encoder_padding_mask (ByteTensor, optional): binary\n                ByteTensor of shape `(batch, src_len)` where padding\n                elements are indicated by ``1``.\n            need_attn (bool, optional): return attention weights\n            need_head_weights (bool, optional): return attention weights\n                for each head (default: return average over heads).\n\n        Returns:\n            encoded output of shape `(seq_len, batch, embed_dim)`\n        \"\"\"", "\n", "if", "need_head_weights", ":", "\n", "            ", "need_attn", "=", "True", "\n", "\n", "", "residual", "=", "x", "\n", "x", "=", "self", ".", "maybe_layer_norm", "(", "self", ".", "self_attn_layer_norm", ",", "x", ",", "before", "=", "True", ")", "\n", "if", "prev_self_attn_state", "is", "not", "None", ":", "\n", "            ", "if", "incremental_state", "is", "None", ":", "\n", "                ", "incremental_state", "=", "{", "}", "\n", "", "prev_key", ",", "prev_value", "=", "prev_self_attn_state", "[", ":", "2", "]", "\n", "saved_state", "=", "{", "\"prev_key\"", ":", "prev_key", ",", "\"prev_value\"", ":", "prev_value", "}", "\n", "if", "len", "(", "prev_self_attn_state", ")", ">=", "3", ":", "\n", "                ", "saved_state", "[", "\"prev_key_padding_mask\"", "]", "=", "prev_self_attn_state", "[", "2", "]", "\n", "", "self", ".", "self_attn", ".", "_set_input_buffer", "(", "incremental_state", ",", "saved_state", ")", "\n", "\n", "", "if", "self", ".", "cross_self_attention", "and", "not", "(", "incremental_state", "is", "not", "None", "and", "\"prev_key\"", "in", "self", ".", "self_attn", ".", "_get_input_buffer", "(", "incremental_state", ")", ")", ":", "\n", "            ", "if", "self_attn_mask", "is", "not", "None", ":", "\n", "                ", "self_attn_mask", "=", "torch", ".", "cat", "(", "(", "x", ".", "new", "(", "x", ".", "size", "(", "0", ")", ",", "encoder_out", ".", "size", "(", "0", ")", ")", ".", "zero_", "(", ")", ",", "self_attn_mask", ")", ",", "dim", "=", "1", ")", "\n", "", "if", "self_attn_padding_mask", "is", "not", "None", ":", "\n", "                ", "if", "encoder_padding_mask", "is", "None", ":", "\n", "                    ", "encoder_padding_mask", "=", "self_attn_padding_mask", ".", "new", "(", "encoder_out", ".", "size", "(", "1", ")", ",", "encoder_out", ".", "size", "(", "0", ")", ")", ".", "zero_", "(", ")", "\n", "", "self_attn_padding_mask", "=", "torch", ".", "cat", "(", "(", "encoder_padding_mask", ",", "self_attn_padding_mask", ")", ",", "dim", "=", "1", ")", "\n", "", "y", "=", "torch", ".", "cat", "(", "(", "encoder_out", ",", "x", ")", ",", "dim", "=", "0", ")", "\n", "", "else", ":", "\n", "            ", "y", "=", "x", "\n", "\n", "", "x", ",", "attn", "=", "self", ".", "self_attn", "(", "\n", "query", "=", "x", ",", "\n", "key", "=", "y", ",", "\n", "value", "=", "y", ",", "\n", "key_padding_mask", "=", "self_attn_padding_mask", ",", "\n", "incremental_state", "=", "incremental_state", ",", "\n", "need_weights", "=", "False", ",", "\n", "attn_mask", "=", "self_attn_mask", ",", "\n", ")", "\n", "x", "=", "F", ".", "dropout", "(", "x", ",", "p", "=", "self", ".", "dropout", ",", "training", "=", "self", ".", "training", ")", "\n", "x", "=", "residual", "+", "x", "\n", "x", "=", "self", ".", "maybe_layer_norm", "(", "self", ".", "self_attn_layer_norm", ",", "x", ",", "after", "=", "True", ")", "\n", "\n", "if", "self", ".", "encoder_attn", "is", "not", "None", ":", "\n", "            ", "residual", "=", "x", "\n", "x", "=", "self", ".", "maybe_layer_norm", "(", "self", ".", "encoder_attn_layer_norm", ",", "x", ",", "before", "=", "True", ")", "\n", "if", "prev_attn_state", "is", "not", "None", ":", "\n", "                ", "if", "incremental_state", "is", "None", ":", "\n", "                    ", "incremental_state", "=", "{", "}", "\n", "", "prev_key", ",", "prev_value", "=", "prev_attn_state", "[", ":", "2", "]", "\n", "saved_state", "=", "{", "\"prev_key\"", ":", "prev_key", ",", "\"prev_value\"", ":", "prev_value", "}", "\n", "if", "len", "(", "prev_attn_state", ")", ">=", "3", ":", "\n", "                    ", "saved_state", "[", "\"prev_key_padding_mask\"", "]", "=", "prev_attn_state", "[", "2", "]", "\n", "", "self", ".", "encoder_attn", ".", "_set_input_buffer", "(", "incremental_state", ",", "saved_state", ")", "\n", "\n", "", "x", ",", "attn", "=", "self", ".", "encoder_attn", "(", "\n", "query", "=", "x", ",", "\n", "key", "=", "encoder_out", ",", "\n", "value", "=", "encoder_out", ",", "\n", "key_padding_mask", "=", "encoder_padding_mask", ",", "\n", "incremental_state", "=", "incremental_state", ",", "\n", "static_kv", "=", "True", ",", "\n", "need_weights", "=", "need_attn", "or", "(", "not", "self", ".", "training", "and", "self", ".", "need_attn", ")", ",", "\n", "need_head_weights", "=", "need_head_weights", ",", "\n", ")", "\n", "x", "=", "F", ".", "dropout", "(", "x", ",", "p", "=", "self", ".", "dropout", ",", "training", "=", "self", ".", "training", ")", "\n", "x", "=", "residual", "+", "x", "\n", "x", "=", "self", ".", "maybe_layer_norm", "(", "self", ".", "encoder_attn_layer_norm", ",", "x", ",", "after", "=", "True", ")", "\n", "\n", "", "residual", "=", "x", "\n", "x", "=", "self", ".", "maybe_layer_norm", "(", "self", ".", "final_layer_norm", ",", "x", ",", "before", "=", "True", ")", "\n", "x", "=", "self", ".", "activation_fn", "(", "self", ".", "fc1", "(", "x", ")", ")", "\n", "x", "=", "F", ".", "dropout", "(", "x", ",", "p", "=", "self", ".", "activation_dropout", ",", "training", "=", "self", ".", "training", ")", "\n", "x", "=", "self", ".", "fc2", "(", "x", ")", "\n", "x", "=", "F", ".", "dropout", "(", "x", ",", "p", "=", "self", ".", "dropout", ",", "training", "=", "self", ".", "training", ")", "\n", "x", "=", "residual", "+", "x", "\n", "x", "=", "self", ".", "maybe_layer_norm", "(", "self", ".", "final_layer_norm", ",", "x", ",", "after", "=", "True", ")", "\n", "if", "self", ".", "onnx_trace", "and", "incremental_state", "is", "not", "None", ":", "\n", "            ", "saved_state", "=", "self", ".", "self_attn", ".", "_get_input_buffer", "(", "incremental_state", ")", "\n", "if", "self_attn_padding_mask", "is", "not", "None", ":", "\n", "                ", "self_attn_state", "=", "saved_state", "[", "\"prev_key\"", "]", ",", "saved_state", "[", "\"prev_value\"", "]", ",", "saved_state", "[", "\"prev_key_padding_mask\"", "]", "\n", "", "else", ":", "\n", "                ", "self_attn_state", "=", "saved_state", "[", "\"prev_key\"", "]", ",", "saved_state", "[", "\"prev_value\"", "]", "\n", "", "return", "x", ",", "attn", ",", "self_attn_state", "\n", "", "return", "x", ",", "attn", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.modules.transformer_layer.TransformerDecoderLayer.maybe_layer_norm": [[295, 301], ["layer_norm"], "methods", ["None"], ["", "def", "maybe_layer_norm", "(", "self", ",", "layer_norm", ",", "x", ",", "before", "=", "False", ",", "after", "=", "False", ")", ":", "\n", "        ", "assert", "before", "^", "after", "\n", "if", "after", "^", "self", ".", "normalize_before", ":", "\n", "            ", "return", "layer_norm", "(", "x", ")", "\n", "", "else", ":", "\n", "            ", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.modules.transformer_layer.TransformerDecoderLayer.make_generation_fast_": [[302, 304], ["None"], "methods", ["None"], ["", "", "def", "make_generation_fast_", "(", "self", ",", "need_attn", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "        ", "self", ".", "need_attn", "=", "need_attn", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.modules.transformer_layer.Linear": [[306, 312], ["torch.Linear", "torch.init.xavier_uniform_", "torch.init.constant_"], "function", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.modules.transformer_layer.Linear"], ["", "", "def", "Linear", "(", "in_features", ",", "out_features", ",", "bias", "=", "True", ")", ":", "\n", "    ", "m", "=", "nn", ".", "Linear", "(", "in_features", ",", "out_features", ",", "bias", ")", "\n", "nn", ".", "init", ".", "xavier_uniform_", "(", "m", ".", "weight", ")", "\n", "if", "bias", ":", "\n", "        ", "nn", ".", "init", ".", "constant_", "(", "m", ".", "bias", ",", "0.", ")", "\n", "", "return", "m", "\n", "", ""]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.modules.gelu.gelu_accurate": [[15, 19], ["hasattr", "math.sqrt", "torch.tanh", "torch.pow"], "function", ["None"], ["def", "gelu_accurate", "(", "x", ")", ":", "\n", "    ", "if", "not", "hasattr", "(", "gelu_accurate", ",", "\"_a\"", ")", ":", "\n", "        ", "gelu_accurate", ".", "_a", "=", "math", ".", "sqrt", "(", "2", "/", "math", ".", "pi", ")", "\n", "", "return", "0.5", "*", "x", "*", "(", "1", "+", "torch", ".", "tanh", "(", "gelu_accurate", ".", "_a", "*", "(", "x", "+", "0.044715", "*", "torch", ".", "pow", "(", "x", ",", "3", ")", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.modules.gelu.gelu": [[21, 26], ["hasattr", "torch.nn.functional.gelu().type_as", "torch.nn.functional.gelu", "torch.erf", "x.float", "math.sqrt"], "function", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.modules.gelu.gelu"], ["", "def", "gelu", "(", "x", ":", "torch", ".", "Tensor", ")", "->", "torch", ".", "Tensor", ":", "\n", "    ", "if", "hasattr", "(", "torch", ".", "nn", ".", "functional", ",", "'gelu'", ")", ":", "\n", "        ", "return", "torch", ".", "nn", ".", "functional", ".", "gelu", "(", "x", ".", "float", "(", ")", ")", ".", "type_as", "(", "x", ")", "\n", "", "else", ":", "\n", "        ", "return", "x", "*", "0.5", "*", "(", "1.0", "+", "torch", ".", "erf", "(", "x", "/", "math", ".", "sqrt", "(", "2.0", ")", ")", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.tasks._language_modeling.LanguageModelingTask.add_args": [[52, 82], ["parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument"], "methods", ["None"], ["@", "staticmethod", "\n", "def", "add_args", "(", "parser", ")", ":", "\n", "        ", "\"\"\"Add task-specific arguments to the parser.\"\"\"", "\n", "# fmt: off", "\n", "parser", ".", "add_argument", "(", "'data'", ",", "help", "=", "'path to data directory'", ")", "\n", "parser", ".", "add_argument", "(", "'--sample-break-mode'", ",", "default", "=", "'none'", ",", "\n", "choices", "=", "[", "'none'", ",", "'complete'", ",", "'complete_doc'", ",", "'eos'", "]", ",", "\n", "help", "=", "'If omitted or \"none\", fills each sample with tokens-per-sample '", "\n", "'tokens. If set to \"complete\", splits samples only at the end '", "\n", "'of sentence, but may include multiple sentences per sample. '", "\n", "'\"complete_doc\" is similar but respects doc boundaries. '", "\n", "'If set to \"eos\", includes only one sentence per sample.'", ")", "\n", "parser", ".", "add_argument", "(", "'--tokens-per-sample'", ",", "default", "=", "1024", ",", "type", "=", "int", ",", "\n", "help", "=", "'max number of tokens per sample for LM dataset'", ")", "\n", "parser", ".", "add_argument", "(", "'--lazy-load'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "'load the dataset lazily'", ")", "\n", "parser", ".", "add_argument", "(", "'--raw-text'", ",", "default", "=", "False", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "'load raw text dataset'", ")", "\n", "parser", ".", "add_argument", "(", "'--output-dictionary-size'", ",", "default", "=", "-", "1", ",", "type", "=", "int", ",", "\n", "help", "=", "'limit the size of output dictionary'", ")", "\n", "parser", ".", "add_argument", "(", "'--self-target'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "'include self target'", ")", "\n", "parser", ".", "add_argument", "(", "'--future-target'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "'include future target'", ")", "\n", "parser", ".", "add_argument", "(", "'--past-target'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "'include past target'", ")", "\n", "parser", ".", "add_argument", "(", "'--add-bos-token'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "'prepend beginning of sentence token (<s>)'", ")", "\n", "parser", ".", "add_argument", "(", "'--max-target-positions'", ",", "type", "=", "int", ",", "metavar", "=", "'N'", ",", "\n", "help", "=", "'max number of tokens in the target sequence'", ")", "\n", "# fmt: on", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.tasks._language_modeling.LanguageModelingTask.__init__": [[84, 92], ["fairseq.tasks.FairseqTask.__init__"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.dummy_dictionary.DummyDictionary.__init__"], ["", "def", "__init__", "(", "self", ",", "args", ",", "dictionary", ",", "output_dictionary", "=", "None", ",", "targets", "=", "None", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "args", ")", "\n", "self", ".", "dictionary", "=", "dictionary", "\n", "self", ".", "output_dictionary", "=", "output_dictionary", "or", "dictionary", "\n", "\n", "if", "targets", "is", "None", ":", "\n", "            ", "targets", "=", "[", "\"future\"", "]", "\n", "", "self", ".", "targets", "=", "targets", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.tasks._language_modeling.LanguageModelingTask.setup_task": [[93, 140], ["getattr", "hasattr", "getattr", "getattr", "getattr", "cls", "fairseq.utils.deprecation_warning", "getattr", "args.data.split", "fairseq.data.Dictionary.load", "print", "targets.append", "targets.append", "targets.append", "len", "fairseq.utils.deprecation_warning", "len", "os.path.join", "fairseq.data.TruncatedDictionary", "len"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.utils.deprecation_warning", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.progress_bar.tensorboard_log_wrapper.print", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.utils.deprecation_warning"], ["", "@", "classmethod", "\n", "def", "setup_task", "(", "cls", ",", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"Setup the task (e.g., load dictionaries).\n\n        Args:\n            args (argparse.Namespace): parsed command-line arguments\n        \"\"\"", "\n", "if", "getattr", "(", "args", ",", "\"raw_text\"", ",", "False", ")", ":", "\n", "            ", "utils", ".", "deprecation_warning", "(", "\n", "\"--raw-text is deprecated, please use --dataset-impl=raw\"", "\n", ")", "\n", "args", ".", "dataset_impl", "=", "\"raw\"", "\n", "", "elif", "getattr", "(", "args", ",", "\"lazy_load\"", ",", "False", ")", ":", "\n", "            ", "utils", ".", "deprecation_warning", "(", "\n", "\"--lazy-load is deprecated, please use --dataset-impl=lazy\"", "\n", ")", "\n", "args", ".", "dataset_impl", "=", "\"lazy\"", "\n", "\n", "", "dictionary", "=", "None", "\n", "output_dictionary", "=", "None", "\n", "if", "args", ".", "data", ":", "\n", "            ", "paths", "=", "args", ".", "data", ".", "split", "(", "\":\"", ")", "\n", "assert", "len", "(", "paths", ")", ">", "0", "\n", "dictionary", "=", "Dictionary", ".", "load", "(", "os", ".", "path", ".", "join", "(", "paths", "[", "0", "]", ",", "\"dict.txt\"", ")", ")", "\n", "print", "(", "\"| dictionary: {} types\"", ".", "format", "(", "len", "(", "dictionary", ")", ")", ")", "\n", "output_dictionary", "=", "dictionary", "\n", "if", "args", ".", "output_dictionary_size", ">=", "0", ":", "\n", "                ", "output_dictionary", "=", "TruncatedDictionary", "(", "\n", "dictionary", ",", "args", ".", "output_dictionary_size", "\n", ")", "\n", "\n", "# upgrade old checkpoints", "\n", "", "", "if", "hasattr", "(", "args", ",", "\"exclude_self_target\"", ")", ":", "\n", "            ", "args", ".", "self_target", "=", "not", "args", ".", "exclude_self_target", "\n", "\n", "", "targets", "=", "[", "]", "\n", "if", "getattr", "(", "args", ",", "\"self_target\"", ",", "False", ")", ":", "\n", "            ", "targets", ".", "append", "(", "\"self\"", ")", "\n", "", "if", "getattr", "(", "args", ",", "\"future_target\"", ",", "False", ")", ":", "\n", "            ", "targets", ".", "append", "(", "\"future\"", ")", "\n", "", "if", "getattr", "(", "args", ",", "\"past_target\"", ",", "False", ")", ":", "\n", "            ", "targets", ".", "append", "(", "\"past\"", ")", "\n", "", "if", "len", "(", "targets", ")", "==", "0", ":", "\n", "# standard language modeling", "\n", "            ", "targets", "=", "[", "\"future\"", "]", "\n", "\n", "", "return", "cls", "(", "args", ",", "dictionary", ",", "output_dictionary", ",", "targets", "=", "targets", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.tasks._language_modeling.LanguageModelingTask.build_model": [[141, 151], ["super().build_model", "ValueError"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.tasks.integer_sequence_modeling.IntegerSequenceModelingTask.build_model"], ["", "def", "build_model", "(", "self", ",", "args", ")", ":", "\n", "        ", "model", "=", "super", "(", ")", ".", "build_model", "(", "args", ")", "\n", "\n", "for", "target", "in", "self", ".", "targets", ":", "\n", "            ", "if", "target", "not", "in", "model", ".", "supported_targets", ":", "\n", "                ", "raise", "ValueError", "(", "\n", "\"Unsupported language modeling target: {}\"", ".", "format", "(", "target", ")", "\n", ")", "\n", "\n", "", "", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.tasks._language_modeling.LanguageModelingTask.load_dataset": [[152, 196], ["_language_modeling.LanguageModelingTask.args.data.split", "os.path.join", "fairseq.data.data_utils.load_indexed_dataset", "fairseq.data.TokenBlockDataset", "fairseq.data.MonolingualDataset", "len", "FileNotFoundError", "_language_modeling.LanguageModelingTask.dictionary.pad", "_language_modeling.LanguageModelingTask.dictionary.eos", "len"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.dummy_dictionary.DummyDictionary.pad"], ["", "def", "load_dataset", "(", "self", ",", "split", ",", "epoch", "=", "0", ",", "combine", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"Load a given dataset split.\n\n        Args:\n            split (str): name of the split (e.g., train, valid, test)\n        \"\"\"", "\n", "paths", "=", "self", ".", "args", ".", "data", ".", "split", "(", "\":\"", ")", "\n", "assert", "len", "(", "paths", ")", ">", "0", "\n", "\n", "data_path", "=", "paths", "[", "epoch", "%", "len", "(", "paths", ")", "]", "\n", "split_path", "=", "os", ".", "path", ".", "join", "(", "data_path", ",", "split", ")", "\n", "\n", "dataset", "=", "data_utils", ".", "load_indexed_dataset", "(", "\n", "split_path", ",", "self", ".", "dictionary", ",", "self", ".", "args", ".", "dataset_impl", ",", "combine", "=", "combine", "\n", ")", "\n", "if", "dataset", "is", "None", ":", "\n", "            ", "raise", "FileNotFoundError", "(", "\n", "\"Dataset not found: {} ({})\"", ".", "format", "(", "split", ",", "split_path", ")", "\n", ")", "\n", "\n", "", "dataset", "=", "TokenBlockDataset", "(", "\n", "dataset", ",", "\n", "dataset", ".", "sizes", ",", "\n", "self", ".", "args", ".", "tokens_per_sample", ",", "\n", "pad", "=", "self", ".", "dictionary", ".", "pad", "(", ")", ",", "\n", "eos", "=", "self", ".", "dictionary", ".", "eos", "(", ")", ",", "\n", "break_mode", "=", "self", ".", "args", ".", "sample_break_mode", ",", "\n", "include_targets", "=", "True", ",", "\n", ")", "\n", "\n", "add_eos_for_other_targets", "=", "(", "\n", "self", ".", "args", ".", "sample_break_mode", "is", "not", "None", "\n", "and", "self", ".", "args", ".", "sample_break_mode", "!=", "\"none\"", "\n", ")", "\n", "\n", "self", ".", "datasets", "[", "split", "]", "=", "MonolingualDataset", "(", "\n", "dataset", ",", "\n", "dataset", ".", "sizes", ",", "\n", "self", ".", "dictionary", ",", "\n", "self", ".", "output_dictionary", ",", "\n", "add_eos_for_other_targets", "=", "add_eos_for_other_targets", ",", "\n", "shuffle", "=", "True", ",", "\n", "targets", "=", "self", ".", "targets", ",", "\n", "add_bos_token", "=", "self", ".", "args", ".", "add_bos_token", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.tasks._language_modeling.LanguageModelingTask.build_dataset_for_inference": [[198, 221], ["fairseq.data.TransformEosDataset", "fairseq.data.MonolingualDataset", "fairseq.data.TokenBlockDataset", "_language_modeling.LanguageModelingTask.source_dictionary.eos", "_language_modeling.LanguageModelingTask.source_dictionary.pad", "_language_modeling.LanguageModelingTask.source_dictionary.eos"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.dummy_dictionary.DummyDictionary.pad"], ["", "def", "build_dataset_for_inference", "(", "self", ",", "src_tokens", ",", "src_lengths", ")", ":", "\n", "        ", "return", "TransformEosDataset", "(", "\n", "MonolingualDataset", "(", "\n", "TokenBlockDataset", "(", "\n", "src_tokens", ",", "\n", "src_lengths", ",", "\n", "block_size", "=", "None", ",", "\n", "pad", "=", "self", ".", "source_dictionary", ".", "pad", "(", ")", ",", "\n", "eos", "=", "self", ".", "source_dictionary", ".", "eos", "(", ")", ",", "\n", "break_mode", "=", "\"eos\"", ",", "\n", "include_targets", "=", "False", ",", "\n", ")", ",", "\n", "src_lengths", ",", "\n", "self", ".", "source_dictionary", ",", "\n", "self", ".", "target_dictionary", ",", "\n", "add_eos_for_other_targets", "=", "False", ",", "\n", "shuffle", "=", "False", ",", "\n", "add_bos_token", "=", "self", ".", "args", ".", "add_bos_token", ",", "\n", ")", ",", "\n", "eos", "=", "self", ".", "source_dictionary", ".", "eos", "(", ")", ",", "\n", "# remove EOS since this will be used as a prefix for generation", "\n", "remove_eos_from_src", "=", "True", ",", "\n", "has_target", "=", "False", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.tasks._language_modeling.LanguageModelingTask.inference_step": [[223, 230], ["torch.no_grad", "generator.generate", "[].nelement", "prefix_tokens[].eq().all", "prefix_tokens[].eq", "_language_modeling.LanguageModelingTask.source_dictionary.eos"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.sequence_generator.SequenceGenerator.generate"], ["", "def", "inference_step", "(", "self", ",", "generator", ",", "models", ",", "sample", ",", "prefix_tokens", "=", "None", ")", ":", "\n", "        ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "if", "prefix_tokens", "is", "None", "and", "sample", "[", "\"net_input\"", "]", "[", "\"src_tokens\"", "]", ".", "nelement", "(", ")", ":", "\n", "                ", "prefix_tokens", "=", "sample", "[", "\"net_input\"", "]", "[", "\"src_tokens\"", "]", "\n", "if", "prefix_tokens", "[", ":", ",", "0", "]", ".", "eq", "(", "self", ".", "source_dictionary", ".", "eos", "(", ")", ")", ".", "all", "(", ")", ":", "\n", "                    ", "prefix_tokens", "=", "prefix_tokens", "[", ":", ",", "1", ":", "]", "\n", "", "", "return", "generator", ".", "generate", "(", "models", ",", "sample", ",", "prefix_tokens", "=", "prefix_tokens", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.tasks._language_modeling.LanguageModelingTask.source_dictionary": [[231, 236], ["None"], "methods", ["None"], ["", "", "@", "property", "\n", "def", "source_dictionary", "(", "self", ")", ":", "\n", "        ", "\"\"\"Return the :class:`~fairseq.data.Dictionary` for the language\n        model.\"\"\"", "\n", "return", "self", ".", "dictionary", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.tasks._language_modeling.LanguageModelingTask.target_dictionary": [[237, 242], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "target_dictionary", "(", "self", ")", ":", "\n", "        ", "\"\"\"Return the :class:`~fairseq.data.Dictionary` for the language\n        model.\"\"\"", "\n", "return", "self", ".", "output_dictionary", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.tasks.fairseq_task.FairseqTask.add_args": [[21, 25], ["None"], "methods", ["None"], ["@", "staticmethod", "\n", "def", "add_args", "(", "parser", ")", ":", "\n", "        ", "\"\"\"Add task-specific arguments to the parser.\"\"\"", "\n", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.tasks.fairseq_task.FairseqTask.__init__": [[26, 30], ["None"], "methods", ["None"], ["", "def", "__init__", "(", "self", ",", "args", ")", ":", "\n", "        ", "self", ".", "args", "=", "args", "\n", "self", ".", "datasets", "=", "{", "}", "\n", "self", ".", "dataset_to_epoch_iter", "=", "{", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.tasks.fairseq_task.FairseqTask.setup_task": [[31, 39], ["cls"], "methods", ["None"], ["", "@", "classmethod", "\n", "def", "setup_task", "(", "cls", ",", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"Setup the task (e.g., load dictionaries).\n\n        Args:\n            args (argparse.Namespace): parsed command-line arguments\n        \"\"\"", "\n", "return", "cls", "(", "args", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.tasks.fairseq_task.FairseqTask.load_dataset": [[40, 47], ["None"], "methods", ["None"], ["", "def", "load_dataset", "(", "self", ",", "split", ",", "combine", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"Load a given dataset split.\n\n        Args:\n            split (str): name of the split (e.g., train, valid, test)\n        \"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.tasks.fairseq_task.FairseqTask.dataset": [[48, 64], ["KeyError", "isinstance", "TypeError"], "methods", ["None"], ["", "def", "dataset", "(", "self", ",", "split", ")", ":", "\n", "        ", "\"\"\"\n        Return a loaded dataset split.\n\n        Args:\n            split (str): name of the split (e.g., train, valid, test)\n\n        Returns:\n            a :class:`~fairseq.data.FairseqDataset` corresponding to *split*\n        \"\"\"", "\n", "from", "fairseq", ".", "data", "import", "FairseqDataset", "\n", "if", "split", "not", "in", "self", ".", "datasets", ":", "\n", "            ", "raise", "KeyError", "(", "'Dataset not loaded: '", "+", "split", ")", "\n", "", "if", "not", "isinstance", "(", "self", ".", "datasets", "[", "split", "]", ",", "FairseqDataset", ")", ":", "\n", "            ", "raise", "TypeError", "(", "'Datasets are expected to be of type FairseqDataset'", ")", "\n", "", "return", "self", ".", "datasets", "[", "split", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.tasks.fairseq_task.FairseqTask.get_batch_iterator": [[65, 140], ["isinstance", "dataset.set_epoch", "fairseq.data.data_utils.batch_by_size", "fairseq.data.iterators.EpochBatchIterator", "fairseq.data.data_utils.numpy_seed", "dataset.ordered_indices", "fairseq.data.data_utils.filter_by_size"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.fairseq_dataset.EpochListening.set_epoch", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.data_utils.batch_by_size", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.data_utils.numpy_seed", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.fairseq_dataset.FairseqDataset.ordered_indices", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.data_utils.filter_by_size"], ["", "def", "get_batch_iterator", "(", "\n", "self", ",", "dataset", ",", "max_tokens", "=", "None", ",", "max_sentences", "=", "None", ",", "max_positions", "=", "None", ",", "\n", "ignore_invalid_inputs", "=", "False", ",", "required_batch_size_multiple", "=", "1", ",", "\n", "seed", "=", "1", ",", "num_shards", "=", "1", ",", "shard_id", "=", "0", ",", "num_workers", "=", "0", ",", "epoch", "=", "0", ",", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Get an iterator that yields batches of data from the given dataset.\n\n        Args:\n            dataset (~fairseq.data.FairseqDataset): dataset to batch\n            max_tokens (int, optional): max number of tokens in each batch\n                (default: None).\n            max_sentences (int, optional): max number of sentences in each\n                batch (default: None).\n            max_positions (optional): max sentence length supported by the\n                model (default: None).\n            ignore_invalid_inputs (bool, optional): don't raise Exception for\n                sentences that are too long (default: False).\n            required_batch_size_multiple (int, optional): require batch size to\n                be a multiple of N (default: 1).\n            seed (int, optional): seed for random number generator for\n                reproducibility (default: 1).\n            num_shards (int, optional): shard the data iterator into N\n                shards (default: 1).\n            shard_id (int, optional): which shard of the data iterator to\n                return (default: 0).\n            num_workers (int, optional): how many subprocesses to use for data\n                loading. 0 means the data will be loaded in the main process\n                (default: 0).\n            epoch (int, optional): the epoch to start the iterator from\n                (default: 0).\n        Returns:\n            ~fairseq.iterators.EpochBatchIterator: a batched iterator over the\n                given dataset split\n        \"\"\"", "\n", "# For default fairseq task, return same iterator across epochs", "\n", "# as datasets are not dynamic, can be overridden in task specific", "\n", "# setting.", "\n", "if", "dataset", "in", "self", ".", "dataset_to_epoch_iter", ":", "\n", "            ", "return", "self", ".", "dataset_to_epoch_iter", "[", "dataset", "]", "\n", "\n", "", "assert", "isinstance", "(", "dataset", ",", "FairseqDataset", ")", "\n", "\n", "# initialize the dataset with the correct starting epoch", "\n", "dataset", ".", "set_epoch", "(", "epoch", ")", "\n", "\n", "# get indices ordered by example size", "\n", "with", "data_utils", ".", "numpy_seed", "(", "seed", ")", ":", "\n", "            ", "indices", "=", "dataset", ".", "ordered_indices", "(", ")", "\n", "\n", "# filter examples that are too large", "\n", "", "if", "max_positions", "is", "not", "None", ":", "\n", "            ", "indices", "=", "data_utils", ".", "filter_by_size", "(", "\n", "indices", ",", "dataset", ",", "max_positions", ",", "raise_exception", "=", "(", "not", "ignore_invalid_inputs", ")", ",", "\n", ")", "\n", "\n", "# create mini-batches with given size constraints", "\n", "", "batch_sampler", "=", "data_utils", ".", "batch_by_size", "(", "\n", "indices", ",", "dataset", ".", "num_tokens", ",", "max_tokens", "=", "max_tokens", ",", "max_sentences", "=", "max_sentences", ",", "\n", "required_batch_size_multiple", "=", "required_batch_size_multiple", ",", "\n", ")", "\n", "\n", "# return a reusable, sharded iterator", "\n", "epoch_iter", "=", "iterators", ".", "EpochBatchIterator", "(", "\n", "dataset", "=", "dataset", ",", "\n", "collate_fn", "=", "dataset", ".", "collater", ",", "\n", "batch_sampler", "=", "batch_sampler", ",", "\n", "seed", "=", "seed", ",", "\n", "num_shards", "=", "num_shards", ",", "\n", "shard_id", "=", "shard_id", ",", "\n", "num_workers", "=", "num_workers", ",", "\n", "epoch", "=", "epoch", ",", "\n", ")", "\n", "self", ".", "dataset_to_epoch_iter", "[", "dataset", "]", "=", "epoch_iter", "\n", "return", "epoch_iter", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.tasks.fairseq_task.FairseqTask.build_model": [[141, 154], ["models.build_model"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.tasks.integer_sequence_modeling.IntegerSequenceModelingTask.build_model"], ["", "def", "build_model", "(", "self", ",", "args", ")", ":", "\n", "        ", "\"\"\"\n        Build the :class:`~fairseq.models.BaseFairseqModel` instance for this\n        task.\n\n        Args:\n            args (argparse.Namespace): parsed command-line arguments\n\n        Returns:\n            a :class:`~fairseq.models.BaseFairseqModel` instance\n        \"\"\"", "\n", "from", "fairseq", "import", "models", "\n", "return", "models", ".", "build_model", "(", "args", ",", "self", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.tasks.fairseq_task.FairseqTask.build_criterion": [[155, 168], ["criterions.build_criterion"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.criterions.fairseq_criterion.FairseqCriterion.build_criterion"], ["", "def", "build_criterion", "(", "self", ",", "args", ")", ":", "\n", "        ", "\"\"\"\n        Build the :class:`~fairseq.criterions.FairseqCriterion` instance for\n        this task.\n\n        Args:\n            args (argparse.Namespace): parsed command-line arguments\n\n        Returns:\n            a :class:`~fairseq.criterions.FairseqCriterion` instance\n        \"\"\"", "\n", "from", "fairseq", "import", "criterions", "\n", "return", "criterions", ".", "build_criterion", "(", "args", ",", "self", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.tasks.fairseq_task.FairseqTask.build_generator": [[169, 182], ["seq_gen_cls", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr"], "methods", ["None"], ["", "def", "build_generator", "(", "self", ",", "args", ")", ":", "\n", "        ", "from", "fairseq", ".", "sequence_generator", "import", "SequenceGenerator", "\n", "seq_gen_cls", "=", "SequenceGenerator", "\n", "return", "seq_gen_cls", "(", "\n", "self", ".", "target_dictionary", ",", "\n", "beam_size", "=", "getattr", "(", "args", ",", "'beam'", ",", "5", ")", ",", "\n", "tgt_len", "=", "getattr", "(", "args", ",", "'tokens_per_target'", ",", "200", ")", ",", "\n", "sampling", "=", "getattr", "(", "args", ",", "'sampling'", ",", "False", ")", ",", "\n", "sampling_topk", "=", "getattr", "(", "args", ",", "'sampling_topk'", ",", "-", "1", ")", ",", "\n", "sampling_topp", "=", "getattr", "(", "args", ",", "'sampling_topp'", ",", "-", "1.0", ")", ",", "\n", "temperature", "=", "getattr", "(", "args", ",", "'temperature'", ",", "1.", ")", ",", "\n", "diverse_beam_groups", "=", "getattr", "(", "args", ",", "'diverse_beam_groups'", ",", "-", "1", ")", ",", "\n", "diverse_beam_strength", "=", "getattr", "(", "args", ",", "'diverse_beam_strength'", ",", "0.5", ")", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.tasks.fairseq_task.FairseqTask.train_step": [[184, 210], ["model.train", "criterion", "optimizer.backward"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.None.train_ar.train", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.trainer.Trainer.criterion", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.optim.fp16_optimizer._MemoryEfficientFP16OptimizerMixin.backward"], ["", "def", "train_step", "(", "self", ",", "sample", ",", "model", ",", "criterion", ",", "optimizer", ",", "ignore_grad", "=", "False", ")", ":", "\n", "        ", "\"\"\"\n        Do forward and backward, and return the loss as computed by *criterion*\n        for the given *model* and *sample*.\n\n        Args:\n            sample (dict): the mini-batch. The format is defined by the\n                :class:`~fairseq.data.FairseqDataset`.\n            model (~fairseq.models.BaseFairseqModel): the model\n            criterion (~fairseq.criterions.FairseqCriterion): the criterion\n            optimizer (~fairseq.optim.FairseqOptimizer): the optimizer\n            ignore_grad (bool): multiply loss by 0 if this is set to True\n\n        Returns:\n            tuple:\n                - the loss\n                - the sample size, which is used as the denominator for the\n                  gradient\n                - logging outputs to display while training\n        \"\"\"", "\n", "model", ".", "train", "(", ")", "\n", "loss", ",", "sample_size", ",", "logging_output", "=", "criterion", "(", "model", ",", "sample", ")", "\n", "if", "ignore_grad", ":", "\n", "            ", "loss", "*=", "0", "\n", "", "optimizer", ".", "backward", "(", "loss", ")", "\n", "return", "loss", ",", "sample_size", ",", "logging_output", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.tasks.fairseq_task.FairseqTask.valid_step": [[211, 216], ["model.eval", "torch.no_grad", "criterion"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.utils.eval", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.trainer.Trainer.criterion"], ["", "def", "valid_step", "(", "self", ",", "sample", ",", "model", ",", "criterion", ")", ":", "\n", "        ", "model", ".", "eval", "(", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "loss", ",", "sample_size", ",", "logging_output", "=", "criterion", "(", "model", ",", "sample", ")", "\n", "", "return", "loss", ",", "sample_size", ",", "logging_output", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.tasks.fairseq_task.FairseqTask.inference_step": [[217, 220], ["torch.no_grad", "generator.generate"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.sequence_generator.SequenceGenerator.generate"], ["", "def", "inference_step", "(", "self", ",", "generator", ",", "models", ",", "sample", ",", "prefix_tokens", "=", "None", ")", ":", "\n", "        ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "return", "generator", ".", "generate", "(", "models", ",", "sample", ",", "prefix_tokens", "=", "prefix_tokens", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.tasks.fairseq_task.FairseqTask.update_step": [[221, 225], ["None"], "methods", ["None"], ["", "", "def", "update_step", "(", "self", ",", "num_updates", ")", ":", "\n", "        ", "\"\"\"Task level update when number of update increases. This is called after optimization step and\n           learning rate update of each step\"\"\"", "\n", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.tasks.fairseq_task.FairseqTask.grad_denom": [[226, 228], ["criterion.__class__.grad_denom"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.criterions.fairseq_criterion.FairseqCriterion.grad_denom"], ["", "def", "grad_denom", "(", "self", ",", "sample_sizes", ",", "criterion", ")", ":", "\n", "        ", "return", "criterion", ".", "__class__", ".", "grad_denom", "(", "sample_sizes", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.tasks.fairseq_task.FairseqTask.aggregate_logging_outputs": [[229, 231], ["criterion.__class__.aggregate_logging_outputs"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.criterions.label_smoothed_cross_entropy.LabelSmoothedCrossEntropyCriterion.aggregate_logging_outputs"], ["", "def", "aggregate_logging_outputs", "(", "self", ",", "logging_outputs", ",", "criterion", ")", ":", "\n", "        ", "return", "criterion", ".", "__class__", ".", "aggregate_logging_outputs", "(", "logging_outputs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.tasks.fairseq_task.FairseqTask.max_positions": [[232, 235], ["None"], "methods", ["None"], ["", "def", "max_positions", "(", "self", ")", ":", "\n", "        ", "\"\"\"Return the max input length allowed by the task.\"\"\"", "\n", "return", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.tasks.fairseq_task.FairseqTask.source_dictionary": [[236, 241], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "source_dictionary", "(", "self", ")", ":", "\n", "        ", "\"\"\"Return the source :class:`~fairseq.data.Dictionary` (if applicable\n        for this task).\"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.tasks.fairseq_task.FairseqTask.target_dictionary": [[242, 247], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "target_dictionary", "(", "self", ")", ":", "\n", "        ", "\"\"\"Return the target :class:`~fairseq.data.Dictionary` (if applicable\n        for this task).\"\"\"", "\n", "raise", "NotImplementedError", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.tasks.__init__.setup_task": [[16, 18], ["TASK_REGISTRY[].setup_task"], "function", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.tasks.integer_sequence_modeling.IntegerSequenceModelingTask.setup_task"], []], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.tasks.__init__.register_task": [[20, 54], ["TASK_CLASS_NAMES.add", "ValueError", "issubclass", "ValueError", "ValueError"], "function", ["None"], []], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.tasks.__init__.get_task": [[75, 77], ["None"], "function", ["None"], []], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.tasks.integer_sequence_modeling.IntegerSequenceModelingTask.add_args": [[12, 20], ["parser.add_argument", "parser.add_argument", "parser.add_argument"], "methods", ["None"], ["    ", "@", "staticmethod", "\n", "def", "add_args", "(", "parser", ")", ":", "\n", "        ", "\"\"\"Add task-specific arguments to the parser.\"\"\"", "\n", "# fmt: off", "\n", "parser", ".", "add_argument", "(", "'data'", ",", "help", "=", "'path to data directory'", ")", "\n", "parser", ".", "add_argument", "(", "'--vocab-size'", ",", "type", "=", "int", ",", "help", "=", "'size of the vocabulary'", ")", "\n", "parser", ".", "add_argument", "(", "'--tokens-per-sample'", ",", "default", "=", "1024", ",", "type", "=", "int", ",", "\n", "help", "=", "'max number of tokens per sample for LM dataset'", ")", "\n", "# fmt: on", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.tasks.integer_sequence_modeling.IntegerSequenceModelingTask.__init__": [[22, 25], ["fairseq.tasks.FairseqTask.__init__", "fairseq.data.DummyDictionary"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.dummy_dictionary.DummyDictionary.__init__"], ["", "def", "__init__", "(", "self", ",", "args", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "args", ")", "\n", "self", ".", "dictionary", "=", "DummyDictionary", "(", "self", ".", "args", ".", "vocab_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.tasks.integer_sequence_modeling.IntegerSequenceModelingTask.setup_task": [[26, 29], ["cls"], "methods", ["None"], ["", "@", "classmethod", "\n", "def", "setup_task", "(", "cls", ",", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "return", "cls", "(", "args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.tasks.integer_sequence_modeling.IntegerSequenceModelingTask.build_model": [[30, 33], ["super().build_model"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.tasks.integer_sequence_modeling.IntegerSequenceModelingTask.build_model"], ["", "def", "build_model", "(", "self", ",", "args", ")", ":", "\n", "        ", "model", "=", "super", "(", ")", ".", "build_model", "(", "args", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.tasks.integer_sequence_modeling.IntegerSequenceModelingTask.load_dataset": [[34, 42], ["os.path.join", "fairseq.data.IntegerSequenceDataset", "FileNotFoundError"], "methods", ["None"], ["", "def", "load_dataset", "(", "self", ",", "split", ",", "combine", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "        ", "split_path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "args", ".", "data", ",", "split", "+", "'.pt'", ")", "\n", "dataset", "=", "IntegerSequenceDataset", "(", "split_path", ",", "shuffle", "=", "True", ",", "bos_idx", "=", "self", ".", "dictionary", ".", "bos_index", ")", "\n", "if", "dataset", "is", "None", ":", "\n", "            ", "raise", "FileNotFoundError", "(", "\n", "\"Dataset not found: {} ({})\"", ".", "format", "(", "split", ",", "split_path", ")", "\n", ")", "\n", "", "self", ".", "datasets", "[", "split", "]", "=", "dataset", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.tasks.integer_sequence_modeling.IntegerSequenceModelingTask.build_dataset_for_inference": [[43, 49], ["fairseq.data.IntegerSequenceDataset"], "methods", ["None"], ["", "def", "build_dataset_for_inference", "(", "self", ",", "src_matrix", ")", ":", "\n", "        ", "return", "IntegerSequenceDataset", "(", "\n", "src_matrix", ",", "\n", "shuffle", "=", "False", ",", "\n", "bos_idx", "=", "self", ".", "dictionary", ".", "bos_index", ",", "\n", "source_only", "=", "True", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.tasks.integer_sequence_modeling.IntegerSequenceModelingTask.inference_step": [[51, 58], ["torch.no_grad", "generator.generate", "[].nelement", "prefix_tokens[].eq().all", "prefix_tokens[].eq"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.sequence_generator.SequenceGenerator.generate"], ["", "def", "inference_step", "(", "self", ",", "generator", ",", "models", ",", "sample", ",", "prefix_tokens", "=", "None", ")", ":", "\n", "        ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "if", "prefix_tokens", "is", "None", "and", "sample", "[", "\"net_input\"", "]", "[", "\"src_tokens\"", "]", ".", "nelement", "(", ")", ":", "\n", "                ", "prefix_tokens", "=", "sample", "[", "\"net_input\"", "]", "[", "\"src_tokens\"", "]", "\n", "if", "prefix_tokens", "[", ":", ",", "0", "]", ".", "eq", "(", "self", ".", "dictionary", ".", "bos_index", ")", ".", "all", "(", ")", ":", "\n", "                    ", "prefix_tokens", "=", "prefix_tokens", "[", ":", ",", "1", ":", "]", "\n", "", "", "return", "generator", ".", "generate", "(", "models", ",", "sample", ",", "prefix_tokens", "=", "prefix_tokens", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.tasks.integer_sequence_modeling.IntegerSequenceModelingTask.source_dictionary": [[59, 62], ["None"], "methods", ["None"], ["", "", "@", "property", "\n", "def", "source_dictionary", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "dictionary", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.tasks.integer_sequence_modeling.IntegerSequenceModelingTask.target_dictionary": [[63, 66], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "target_dictionary", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "dictionary", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.criterions.fairseq_criterion.FairseqCriterion.__init__": [[11, 16], ["torch.nn.modules.loss._Loss.__init__", "task.target_dictionary.pad"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.dummy_dictionary.DummyDictionary.__init__", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.dummy_dictionary.DummyDictionary.pad"], ["    ", "def", "__init__", "(", "self", ",", "args", ",", "task", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "args", "=", "args", "\n", "self", ".", "task", "=", "task", "\n", "self", ".", "padding_idx", "=", "task", ".", "target_dictionary", ".", "pad", "(", ")", "if", "task", ".", "target_dictionary", "is", "not", "None", "else", "-", "100", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.criterions.fairseq_criterion.FairseqCriterion.add_args": [[17, 21], ["None"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "add_args", "(", "parser", ")", ":", "\n", "        ", "\"\"\"Add criterion-specific arguments to the parser.\"\"\"", "\n", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.criterions.fairseq_criterion.FairseqCriterion.build_criterion": [[22, 25], ["cls"], "methods", ["None"], ["", "@", "classmethod", "\n", "def", "build_criterion", "(", "cls", ",", "args", ",", "task", ")", ":", "\n", "        ", "return", "cls", "(", "args", ",", "task", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.criterions.fairseq_criterion.FairseqCriterion.forward": [[26, 35], ["None"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "model", ",", "sample", ",", "reduce", "=", "True", ")", ":", "\n", "        ", "\"\"\"Compute the loss for the given sample.\n\n        Returns a tuple with three elements:\n        1) the loss\n        2) the sample size, which is used as the denominator for the gradient\n        3) logging outputs to display while training\n        \"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.criterions.fairseq_criterion.FairseqCriterion.aggregate_logging_outputs": [[36, 40], ["None"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "aggregate_logging_outputs", "(", "logging_outputs", ")", ":", "\n", "        ", "\"\"\"Aggregate logging outputs from data parallel training.\"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.criterions.fairseq_criterion.FairseqCriterion.grad_denom": [[41, 45], ["sum"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "grad_denom", "(", "sample_sizes", ")", ":", "\n", "        ", "\"\"\"Compute the gradient denominator for a set of sample sizes.\"\"\"", "\n", "return", "sum", "(", "sample_sizes", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.criterions.cross_entropy.CrossEntropyCriterion.__init__": [[17, 19], ["FairseqCriterion.__init__"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.dummy_dictionary.DummyDictionary.__init__"], ["    ", "def", "__init__", "(", "self", ",", "args", ",", "task", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "args", ",", "task", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.criterions.cross_entropy.CrossEntropyCriterion.forward": [[20, 39], ["model", "cross_entropy.CrossEntropyCriterion.compute_loss", "sample[].size", "sample[].size", "fairseq.utils.item", "fairseq.utils.item"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.trainer.Trainer.model", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.criterions.label_smoothed_cross_entropy.LabelSmoothedCrossEntropyCriterion.compute_loss", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.fairseq_dataset.FairseqDataset.size", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.fairseq_dataset.FairseqDataset.size", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.utils.item", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.utils.item"], ["", "def", "forward", "(", "self", ",", "model", ",", "sample", ",", "reduce", "=", "True", ")", ":", "\n", "        ", "\"\"\"Compute the loss for the given sample.\n\n        Returns a tuple with three elements:\n        1) the loss\n        2) the sample size, which is used as the denominator for the gradient\n        3) logging outputs to display while training\n        \"\"\"", "\n", "net_output", "=", "model", "(", "**", "sample", "[", "'net_input'", "]", ")", "\n", "loss", ",", "_", "=", "self", ".", "compute_loss", "(", "model", ",", "net_output", ",", "sample", ",", "reduce", "=", "reduce", ")", "\n", "sample_size", "=", "sample", "[", "'target'", "]", ".", "size", "(", "0", ")", "if", "self", ".", "args", ".", "sentence_avg", "else", "sample", "[", "'ntokens'", "]", "\n", "logging_output", "=", "{", "\n", "'loss'", ":", "utils", ".", "item", "(", "loss", ".", "data", ")", "if", "reduce", "else", "loss", ".", "data", ",", "\n", "'nll_loss'", ":", "utils", ".", "item", "(", "loss", ".", "data", ")", "if", "reduce", "else", "loss", ".", "data", ",", "\n", "'ntokens'", ":", "sample", "[", "'ntokens'", "]", ",", "\n", "'nsentences'", ":", "sample", "[", "'target'", "]", ".", "size", "(", "0", ")", ",", "\n", "'sample_size'", ":", "sample_size", ",", "\n", "}", "\n", "return", "loss", ",", "sample_size", ",", "logging_output", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.criterions.cross_entropy.CrossEntropyCriterion.compute_loss": [[40, 51], ["model.get_normalized_probs", "lprobs.view.view.view", "model.get_targets().view", "torch.nll_loss", "lprobs.view.view.size", "model.get_targets"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.fairseq_decoder.FairseqDecoder.get_normalized_probs", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.fairseq_dataset.FairseqDataset.size", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.fairseq_model.BaseFairseqModel.get_targets"], ["", "def", "compute_loss", "(", "self", ",", "model", ",", "net_output", ",", "sample", ",", "reduce", "=", "True", ")", ":", "\n", "        ", "lprobs", "=", "model", ".", "get_normalized_probs", "(", "net_output", ",", "log_probs", "=", "True", ")", "\n", "lprobs", "=", "lprobs", ".", "view", "(", "-", "1", ",", "lprobs", ".", "size", "(", "-", "1", ")", ")", "\n", "target", "=", "model", ".", "get_targets", "(", "sample", ",", "net_output", ")", ".", "view", "(", "-", "1", ")", "\n", "loss", "=", "F", ".", "nll_loss", "(", "\n", "lprobs", ",", "\n", "target", ",", "\n", "ignore_index", "=", "self", ".", "padding_idx", ",", "\n", "reduction", "=", "'sum'", "if", "reduce", "else", "'none'", ",", "\n", ")", "\n", "return", "loss", ",", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.criterions.cross_entropy.CrossEntropyCriterion.aggregate_logging_outputs": [[52, 68], ["sum", "sum", "sum", "sum", "log.get", "log.get", "log.get", "log.get", "math.log", "math.log"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.progress_bar.tensorboard_log_wrapper.log", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.progress_bar.tensorboard_log_wrapper.log"], ["", "@", "staticmethod", "\n", "def", "aggregate_logging_outputs", "(", "logging_outputs", ")", ":", "\n", "        ", "\"\"\"Aggregate logging outputs from data parallel training.\"\"\"", "\n", "loss_sum", "=", "sum", "(", "log", ".", "get", "(", "'loss'", ",", "0", ")", "for", "log", "in", "logging_outputs", ")", "\n", "ntokens", "=", "sum", "(", "log", ".", "get", "(", "'ntokens'", ",", "0", ")", "for", "log", "in", "logging_outputs", ")", "\n", "nsentences", "=", "sum", "(", "log", ".", "get", "(", "'nsentences'", ",", "0", ")", "for", "log", "in", "logging_outputs", ")", "\n", "sample_size", "=", "sum", "(", "log", ".", "get", "(", "'sample_size'", ",", "0", ")", "for", "log", "in", "logging_outputs", ")", "\n", "agg_output", "=", "{", "\n", "'loss'", ":", "loss_sum", "/", "sample_size", "/", "math", ".", "log", "(", "2", ")", "if", "sample_size", ">", "0", "else", "0.", ",", "\n", "'ntokens'", ":", "ntokens", ",", "\n", "'nsentences'", ":", "nsentences", ",", "\n", "'sample_size'", ":", "sample_size", ",", "\n", "}", "\n", "if", "sample_size", "!=", "ntokens", ":", "\n", "            ", "agg_output", "[", "'nll_loss'", "]", "=", "loss_sum", "/", "ntokens", "/", "math", ".", "log", "(", "2", ")", "\n", "", "return", "agg_output", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.criterions.label_smoothed_cross_entropy.LabelSmoothedCrossEntropyCriterion.__init__": [[36, 39], ["FairseqCriterion.__init__"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.dummy_dictionary.DummyDictionary.__init__"], ["    ", "def", "__init__", "(", "self", ",", "args", ",", "task", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "args", ",", "task", ")", "\n", "self", ".", "eps", "=", "args", ".", "label_smoothing", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.criterions.label_smoothed_cross_entropy.LabelSmoothedCrossEntropyCriterion.add_args": [[40, 46], ["parser.add_argument"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "add_args", "(", "parser", ")", ":", "\n", "        ", "\"\"\"Add criterion-specific arguments to the parser.\"\"\"", "\n", "# fmt: off", "\n", "parser", ".", "add_argument", "(", "'--label-smoothing'", ",", "default", "=", "0.", ",", "type", "=", "float", ",", "metavar", "=", "'D'", ",", "\n", "help", "=", "'epsilon for label smoothing, 0 means no label smoothing'", ")", "\n", "# fmt: on", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.criterions.label_smoothed_cross_entropy.LabelSmoothedCrossEntropyCriterion.forward": [[48, 67], ["model", "label_smoothed_cross_entropy.LabelSmoothedCrossEntropyCriterion.compute_loss", "sample[].size", "sample[].size", "fairseq.utils.item", "fairseq.utils.item"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.trainer.Trainer.model", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.criterions.label_smoothed_cross_entropy.LabelSmoothedCrossEntropyCriterion.compute_loss", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.fairseq_dataset.FairseqDataset.size", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.fairseq_dataset.FairseqDataset.size", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.utils.item", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.utils.item"], ["", "def", "forward", "(", "self", ",", "model", ",", "sample", ",", "reduce", "=", "True", ")", ":", "\n", "        ", "\"\"\"Compute the loss for the given sample.\n\n        Returns a tuple with three elements:\n        1) the loss\n        2) the sample size, which is used as the denominator for the gradient\n        3) logging outputs to display while training\n        \"\"\"", "\n", "net_output", "=", "model", "(", "**", "sample", "[", "'net_input'", "]", ")", "\n", "loss", ",", "nll_loss", "=", "self", ".", "compute_loss", "(", "model", ",", "net_output", ",", "sample", ",", "reduce", "=", "reduce", ")", "\n", "sample_size", "=", "sample", "[", "'target'", "]", ".", "size", "(", "0", ")", "if", "self", ".", "args", ".", "sentence_avg", "else", "sample", "[", "'ntokens'", "]", "\n", "logging_output", "=", "{", "\n", "'loss'", ":", "utils", ".", "item", "(", "loss", ".", "data", ")", "if", "reduce", "else", "loss", ".", "data", ",", "\n", "'nll_loss'", ":", "utils", ".", "item", "(", "nll_loss", ".", "data", ")", "if", "reduce", "else", "nll_loss", ".", "data", ",", "\n", "'ntokens'", ":", "sample", "[", "'ntokens'", "]", ",", "\n", "'nsentences'", ":", "sample", "[", "'target'", "]", ".", "size", "(", "0", ")", ",", "\n", "'sample_size'", ":", "sample_size", ",", "\n", "}", "\n", "return", "loss", ",", "sample_size", ",", "logging_output", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.criterions.label_smoothed_cross_entropy.LabelSmoothedCrossEntropyCriterion.compute_loss": [[68, 76], ["model.get_normalized_probs", "lprobs.view.view.view", "model.get_targets().view", "label_smoothed_cross_entropy.label_smoothed_nll_loss", "lprobs.view.view.size", "model.get_targets"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.fairseq_decoder.FairseqDecoder.get_normalized_probs", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.criterions.label_smoothed_cross_entropy.label_smoothed_nll_loss", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.fairseq_dataset.FairseqDataset.size", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.models.fairseq_model.BaseFairseqModel.get_targets"], ["", "def", "compute_loss", "(", "self", ",", "model", ",", "net_output", ",", "sample", ",", "reduce", "=", "True", ")", ":", "\n", "        ", "lprobs", "=", "model", ".", "get_normalized_probs", "(", "net_output", ",", "log_probs", "=", "True", ")", "\n", "lprobs", "=", "lprobs", ".", "view", "(", "-", "1", ",", "lprobs", ".", "size", "(", "-", "1", ")", ")", "\n", "target", "=", "model", ".", "get_targets", "(", "sample", ",", "net_output", ")", ".", "view", "(", "-", "1", ",", "1", ")", "\n", "loss", ",", "nll_loss", "=", "label_smoothed_nll_loss", "(", "\n", "lprobs", ",", "target", ",", "self", ".", "eps", ",", "ignore_index", "=", "self", ".", "padding_idx", ",", "reduce", "=", "reduce", ",", "\n", ")", "\n", "return", "loss", ",", "nll_loss", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.criterions.label_smoothed_cross_entropy.LabelSmoothedCrossEntropyCriterion.aggregate_logging_outputs": [[77, 89], ["sum", "sum", "sum", "log.get", "log.get", "log.get", "math.log", "math.log", "sum", "sum", "log.get", "log.get"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.progress_bar.tensorboard_log_wrapper.log", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.progress_bar.tensorboard_log_wrapper.log"], ["", "@", "staticmethod", "\n", "def", "aggregate_logging_outputs", "(", "logging_outputs", ")", ":", "\n", "        ", "\"\"\"Aggregate logging outputs from data parallel training.\"\"\"", "\n", "ntokens", "=", "sum", "(", "log", ".", "get", "(", "'ntokens'", ",", "0", ")", "for", "log", "in", "logging_outputs", ")", "\n", "nsentences", "=", "sum", "(", "log", ".", "get", "(", "'nsentences'", ",", "0", ")", "for", "log", "in", "logging_outputs", ")", "\n", "sample_size", "=", "sum", "(", "log", ".", "get", "(", "'sample_size'", ",", "0", ")", "for", "log", "in", "logging_outputs", ")", "\n", "return", "{", "\n", "'loss'", ":", "sum", "(", "log", ".", "get", "(", "'loss'", ",", "0", ")", "for", "log", "in", "logging_outputs", ")", "/", "sample_size", "/", "math", ".", "log", "(", "2", ")", "if", "sample_size", ">", "0", "else", "0.", ",", "\n", "'nll_loss'", ":", "sum", "(", "log", ".", "get", "(", "'nll_loss'", ",", "0", ")", "for", "log", "in", "logging_outputs", ")", "/", "ntokens", "/", "math", ".", "log", "(", "2", ")", "if", "ntokens", ">", "0", "else", "0.", ",", "\n", "'ntokens'", ":", "ntokens", ",", "\n", "'nsentences'", ":", "nsentences", ",", "\n", "'sample_size'", ":", "sample_size", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.criterions.label_smoothed_cross_entropy.label_smoothed_nll_loss": [[13, 31], ["target.unsqueeze.dim", "target.unsqueeze.unsqueeze", "lprobs.gather", "lprobs.sum", "target.unsqueeze.ne", "nll_loss.sum.squeeze", "smooth_loss.sum.squeeze", "nll_loss.sum.sum", "smooth_loss.sum.sum", "lprobs.size", "lprobs.dim"], "function", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.fairseq_dataset.FairseqDataset.size"], ["def", "label_smoothed_nll_loss", "(", "lprobs", ",", "target", ",", "epsilon", ",", "ignore_index", "=", "None", ",", "reduce", "=", "True", ")", ":", "\n", "    ", "if", "target", ".", "dim", "(", ")", "==", "lprobs", ".", "dim", "(", ")", "-", "1", ":", "\n", "        ", "target", "=", "target", ".", "unsqueeze", "(", "-", "1", ")", "\n", "", "nll_loss", "=", "-", "lprobs", ".", "gather", "(", "dim", "=", "-", "1", ",", "index", "=", "target", ")", "\n", "smooth_loss", "=", "-", "lprobs", ".", "sum", "(", "dim", "=", "-", "1", ",", "keepdim", "=", "True", ")", "\n", "if", "ignore_index", "is", "not", "None", ":", "\n", "        ", "non_pad_mask", "=", "target", ".", "ne", "(", "ignore_index", ")", "\n", "nll_loss", "=", "nll_loss", "[", "non_pad_mask", "]", "\n", "smooth_loss", "=", "smooth_loss", "[", "non_pad_mask", "]", "\n", "", "else", ":", "\n", "        ", "nll_loss", "=", "nll_loss", ".", "squeeze", "(", "-", "1", ")", "\n", "smooth_loss", "=", "smooth_loss", ".", "squeeze", "(", "-", "1", ")", "\n", "", "if", "reduce", ":", "\n", "        ", "nll_loss", "=", "nll_loss", ".", "sum", "(", ")", "\n", "smooth_loss", "=", "smooth_loss", ".", "sum", "(", ")", "\n", "", "eps_i", "=", "epsilon", "/", "lprobs", ".", "size", "(", "-", "1", ")", "\n", "loss", "=", "(", "1.", "-", "epsilon", ")", "*", "nll_loss", "+", "eps_i", "*", "smooth_loss", "\n", "return", "loss", ",", "nll_loss", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.integer_sequence_dataset.IntegerSequenceDataset.__init__": [[33, 41], ["isinstance", "torch.load", "torch.serialization.default_restore_location"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "path_or_matrix", ",", "shuffle", ",", "bos_idx", ",", "source_only", "=", "False", ")", ":", "\n", "        ", "if", "isinstance", "(", "path_or_matrix", ",", "str", ")", ":", "\n", "            ", "path_or_matrix", "=", "torch", ".", "load", "(", "\n", "path_or_matrix", ",", "map_location", "=", "(", "lambda", "s", ",", "_", ":", "torch", ".", "serialization", ".", "default_restore_location", "(", "s", ",", "'cpu'", ")", ")", ")", "\n", "", "self", ".", "matrix", "=", "path_or_matrix", "\n", "self", ".", "shuffle", "=", "shuffle", "\n", "self", ".", "bos_idx", "=", "bos_idx", "\n", "self", ".", "source_only", "=", "source_only", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.integer_sequence_dataset.IntegerSequenceDataset.__getitem__": [[42, 52], ["torch.cat", "integer_sequence_dataset.IntegerSequenceDataset.matrix.new_tensor"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "source", "=", "torch", ".", "cat", "(", "[", "\n", "self", ".", "matrix", ".", "new_tensor", "(", "[", "self", ".", "bos_idx", "]", ")", ",", "\n", "self", ".", "matrix", "[", "index", "]", "[", ":", "-", "1", "]", "\n", "]", ")", "\n", "if", "self", ".", "source_only", ":", "\n", "            ", "target", "=", "None", "\n", "", "else", ":", "\n", "            ", "target", "=", "self", ".", "matrix", "[", "index", "]", "\n", "", "return", "{", "'id'", ":", "index", ",", "'source'", ":", "source", ",", "'target'", ":", "target", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.integer_sequence_dataset.IntegerSequenceDataset.__len__": [[53, 55], ["integer_sequence_dataset.IntegerSequenceDataset.matrix.size"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.fairseq_dataset.FairseqDataset.size"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "matrix", ".", "size", "(", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.integer_sequence_dataset.IntegerSequenceDataset.get_empty_batch": [[56, 67], ["torch.arange", "torch.empty().long", "torch.empty().long", "torch.zeros().long", "torch.empty", "torch.empty", "torch.zeros"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "get_empty_batch", "(", "bsz", ")", ":", "\n", "        ", "return", "{", "\n", "'id'", ":", "torch", ".", "arange", "(", "bsz", ")", ",", "\n", "'nsentences'", ":", "bsz", ",", "\n", "'ntokens'", ":", "0", ",", "\n", "'net_input'", ":", "{", "\n", "'src_tokens'", ":", "torch", ".", "empty", "(", "(", "bsz", ",", "0", ")", ")", ".", "long", "(", ")", ",", "\n", "'src_lengths'", ":", "torch", ".", "zeros", "(", "bsz", ")", ".", "long", "(", ")", "\n", "}", ",", "\n", "'target'", ":", "torch", ".", "empty", "(", "(", "bsz", ",", "0", ")", ")", ".", "long", "(", ")", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.integer_sequence_dataset.IntegerSequenceDataset.collater": [[69, 71], ["integer_sequence_dataset.collate"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.integer_sequence_dataset.collate"], ["", "def", "collater", "(", "self", ",", "samples", ")", ":", "\n", "        ", "return", "collate", "(", "samples", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.integer_sequence_dataset.IntegerSequenceDataset.num_tokens": [[72, 74], ["integer_sequence_dataset.IntegerSequenceDataset.matrix.size"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.fairseq_dataset.FairseqDataset.size"], ["", "def", "num_tokens", "(", "self", ",", "index", ")", ":", "\n", "        ", "return", "self", ".", "matrix", ".", "size", "(", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.integer_sequence_dataset.IntegerSequenceDataset.size": [[75, 77], ["integer_sequence_dataset.IntegerSequenceDataset.matrix.size"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.fairseq_dataset.FairseqDataset.size"], ["", "def", "size", "(", "self", ",", "index", ")", ":", "\n", "        ", "return", "self", ".", "matrix", ".", "size", "(", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.integer_sequence_dataset.IntegerSequenceDataset.ordered_indices": [[78, 83], ["numpy.random.permutation", "numpy.arange", "len", "len"], "methods", ["None"], ["", "def", "ordered_indices", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "shuffle", ":", "\n", "            ", "return", "np", ".", "random", ".", "permutation", "(", "len", "(", "self", ")", ")", "\n", "", "else", ":", "\n", "            ", "return", "np", ".", "arange", "(", "len", "(", "self", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.integer_sequence_dataset.IntegerSequenceDataset.supports_prefetch": [[84, 87], ["None"], "methods", ["None"], ["", "", "@", "property", "\n", "def", "supports_prefetch", "(", "self", ")", ":", "\n", "        ", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.integer_sequence_dataset.IntegerSequenceDataset.prefetch": [[88, 90], ["None"], "methods", ["None"], ["", "def", "prefetch", "(", "self", ",", "indices", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.integer_sequence_dataset.collate": [[7, 28], ["torch.stack", "len", "torch.stack", "torch.LongTensor", "len", "sum", "torch.LongTensor", "len", "s[].numel"], "function", ["None"], ["def", "collate", "(", "samples", ")", ":", "\n", "    ", "if", "len", "(", "samples", ")", "==", "0", ":", "\n", "        ", "return", "{", "}", "\n", "\n", "", "src_tokens", "=", "torch", ".", "stack", "(", "[", "s", "[", "'source'", "]", "for", "s", "in", "samples", "]", ")", "\n", "if", "samples", "[", "0", "]", "[", "'target'", "]", "is", "None", ":", "\n", "        ", "target", "=", "None", "\n", "", "else", ":", "\n", "        ", "target", "=", "torch", ".", "stack", "(", "[", "s", "[", "'target'", "]", "for", "s", "in", "samples", "]", ")", "\n", "\n", "", "return", "{", "\n", "'id'", ":", "torch", ".", "LongTensor", "(", "[", "s", "[", "'id'", "]", "for", "s", "in", "samples", "]", ")", ",", "\n", "'nsentences'", ":", "len", "(", "samples", ")", ",", "\n", "'ntokens'", ":", "sum", "(", "len", "(", "s", "[", "'source'", "]", ")", "for", "s", "in", "samples", ")", ",", "\n", "'net_input'", ":", "{", "\n", "'src_tokens'", ":", "src_tokens", ",", "\n", "'src_lengths'", ":", "torch", ".", "LongTensor", "(", "[", "\n", "s", "[", "'source'", "]", ".", "numel", "(", ")", "for", "s", "in", "samples", "\n", "]", ")", ",", "\n", "}", ",", "\n", "'target'", ":", "target", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.fairseq_dataset.EpochListening.set_epoch": [[12, 16], ["None"], "methods", ["None"], ["def", "set_epoch", "(", "self", ",", "epoch", ")", ":", "\n", "        ", "\"\"\"Will receive the updated epoch number at the beginning of the epoch.\n        \"\"\"", "\n", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.fairseq_dataset.FairseqDataset.__getitem__": [[21, 23], ["None"], "methods", ["None"], ["def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.fairseq_dataset.FairseqDataset.__len__": [[24, 26], ["None"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.fairseq_dataset.FairseqDataset.collater": [[27, 37], ["None"], "methods", ["None"], ["", "def", "collater", "(", "self", ",", "samples", ")", ":", "\n", "        ", "\"\"\"Merge a list of samples to form a mini-batch.\n\n        Args:\n            samples (List[dict]): samples to collate\n\n        Returns:\n            dict: a mini-batch suitable for forwarding with a Model\n        \"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.fairseq_dataset.FairseqDataset.num_tokens": [[38, 42], ["None"], "methods", ["None"], ["", "def", "num_tokens", "(", "self", ",", "index", ")", ":", "\n", "        ", "\"\"\"Return the number of tokens in a sample. This value is used to\n        enforce ``--max-tokens`` during batching.\"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.fairseq_dataset.FairseqDataset.size": [[43, 47], ["None"], "methods", ["None"], ["", "def", "size", "(", "self", ",", "index", ")", ":", "\n", "        ", "\"\"\"Return an example's size as a float or tuple. This value is used when\n        filtering a dataset with ``--max-positions``.\"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.fairseq_dataset.FairseqDataset.ordered_indices": [[48, 52], ["numpy.arange", "len"], "methods", ["None"], ["", "def", "ordered_indices", "(", "self", ")", ":", "\n", "        ", "\"\"\"Return an ordered list of indices. Batches will be constructed based\n        on this order.\"\"\"", "\n", "return", "np", ".", "arange", "(", "len", "(", "self", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.fairseq_dataset.FairseqDataset.supports_prefetch": [[53, 57], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "supports_prefetch", "(", "self", ")", ":", "\n", "        ", "\"\"\"Whether this dataset supports prefetching.\"\"\"", "\n", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.fairseq_dataset.FairseqDataset.attr": [[58, 60], ["getattr"], "methods", ["None"], ["", "def", "attr", "(", "self", ",", "attr", ":", "str", ",", "index", ":", "int", ")", ":", "\n", "        ", "return", "getattr", "(", "self", ",", "attr", ",", "None", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.fairseq_dataset.FairseqDataset.prefetch": [[61, 64], ["None"], "methods", ["None"], ["", "def", "prefetch", "(", "self", ",", "indices", ")", ":", "\n", "        ", "\"\"\"Prefetch the data required for this epoch.\"\"\"", "\n", "raise", "NotImplementedError", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.iterators.CountingIterator.__init__": [[26, 31], ["iter", "len"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "iterable", ",", "start", "=", "0", ")", ":", "\n", "        ", "self", ".", "iterable", "=", "iterable", "\n", "self", ".", "count", "=", "start", "\n", "self", ".", "itr", "=", "iter", "(", "self", ")", "\n", "self", ".", "len", "=", "start", "+", "len", "(", "iterable", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.iterators.CountingIterator.__len__": [[32, 34], ["None"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "len", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.iterators.CountingIterator.__iter__": [[35, 41], ["None"], "methods", ["None"], ["", "def", "__iter__", "(", "self", ")", ":", "\n", "        ", "for", "x", "in", "self", ".", "iterable", ":", "\n", "            ", "if", "self", ".", "count", ">=", "self", ".", "len", ":", "\n", "                ", "return", "\n", "", "self", ".", "count", "+=", "1", "\n", "yield", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.iterators.CountingIterator.__next__": [[42, 44], ["next"], "methods", ["None"], ["", "", "def", "__next__", "(", "self", ")", ":", "\n", "        ", "return", "next", "(", "self", ".", "itr", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.iterators.CountingIterator.has_next": [[45, 48], ["len"], "methods", ["None"], ["", "def", "has_next", "(", "self", ")", ":", "\n", "        ", "\"\"\"Whether the iterator has been exhausted.\"\"\"", "\n", "return", "self", ".", "count", "<", "len", "(", "self", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.iterators.CountingIterator.skip": [[49, 53], ["next", "itertools.islice"], "methods", ["None"], ["", "def", "skip", "(", "self", ",", "num_to_skip", ")", ":", "\n", "        ", "\"\"\"Fast-forward the iterator by skipping *num_to_skip* elements.\"\"\"", "\n", "next", "(", "itertools", ".", "islice", "(", "self", ".", "itr", ",", "num_to_skip", ",", "num_to_skip", ")", ",", "None", ")", "\n", "return", "self", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.iterators.CountingIterator.take": [[54, 59], ["min"], "methods", ["None"], ["", "def", "take", "(", "self", ",", "n", ")", ":", "\n", "        ", "\"\"\"\n        Truncates the iterator to n elements at most.\n        \"\"\"", "\n", "self", ".", "len", "=", "min", "(", "self", ".", "len", ",", "n", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.iterators.EpochBatchIterating.__len__": [[62, 64], ["None"], "methods", ["None"], ["    ", "def", "__len__", "(", "self", ")", "->", "int", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.iterators.EpochBatchIterating.next_epoch_itr": [[65, 76], ["None"], "methods", ["None"], ["", "def", "next_epoch_itr", "(", "self", ",", "shuffle", "=", "True", ",", "fix_batches_to_gpus", "=", "False", ")", ":", "\n", "        ", "\"\"\"Return a new iterator over the dataset.\n\n        Args:\n            shuffle (bool, optional): shuffle batches before returning the\n                iterator (default: True).\n            fix_batches_to_gpus: ensure that batches are always\n                allocated to the same shards across epochs. Requires\n                that :attr:`dataset` supports prefetching (default: False).\n        \"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.iterators.EpochBatchIterating.end_of_epoch": [[77, 80], ["None"], "methods", ["None"], ["", "def", "end_of_epoch", "(", "self", ")", "->", "bool", ":", "\n", "        ", "\"\"\"Returns whether the most recent epoch iterator has been exhausted\"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.iterators.EpochBatchIterating.iterations_in_epoch": [[81, 85], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "iterations_in_epoch", "(", "self", ")", "->", "int", ":", "\n", "        ", "\"\"\"The number of consumed batches in the current epoch.\"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.iterators.EpochBatchIterating.state_dict": [[86, 89], ["None"], "methods", ["None"], ["", "def", "state_dict", "(", "self", ")", ":", "\n", "        ", "\"\"\"Returns a dictionary containing a whole state of the iterator.\"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.iterators.EpochBatchIterating.load_state_dict": [[90, 93], ["None"], "methods", ["None"], ["", "def", "load_state_dict", "(", "self", ",", "state_dict", ")", ":", "\n", "        ", "\"\"\"Copies the state of the iterator from the given *state_dict*.\"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.iterators.StreamingEpochBatchIterator.__init__": [[96, 105], ["isinstance"], "methods", ["None"], ["    ", "def", "__init__", "(", "\n", "self", ",", "dataset", ",", "epoch", "=", "0", ",", "num_shards", "=", "1", ",", "shard_id", "=", "0", ",", "\n", ")", ":", "\n", "        ", "assert", "isinstance", "(", "dataset", ",", "torch", ".", "utils", ".", "data", ".", "IterableDataset", ")", "\n", "self", ".", "dataset", "=", "dataset", "\n", "self", ".", "epoch", "=", "epoch", "\n", "self", ".", "_current_epoch_iterator", "=", "None", "\n", "self", ".", "num_shards", "=", "num_shards", "\n", "self", ".", "shard_id", "=", "shard_id", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.iterators.StreamingEpochBatchIterator.next_epoch_itr": [[106, 117], ["iterators.StreamingEpochBatchIterator.dataset.set_epoch", "iterators.CountingIterator", "iterators.ShardedIterator"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.fairseq_dataset.EpochListening.set_epoch"], ["", "def", "next_epoch_itr", "(", "self", ",", "shuffle", "=", "True", ",", "fix_batches_to_gpus", "=", "False", ")", ":", "\n", "        ", "self", ".", "epoch", "+=", "1", "\n", "self", ".", "dataset", ".", "set_epoch", "(", "self", ".", "epoch", ")", "\n", "self", ".", "_current_epoch_iterator", "=", "CountingIterator", "(", "\n", "iterable", "=", "ShardedIterator", "(", "\n", "iterable", "=", "self", ".", "dataset", ",", "\n", "num_shards", "=", "self", ".", "num_shards", ",", "\n", "shard_id", "=", "self", ".", "shard_id", ",", "\n", ")", ",", "\n", ")", "\n", "return", "self", ".", "_current_epoch_iterator", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.iterators.StreamingEpochBatchIterator.end_of_epoch": [[118, 120], ["iterators.StreamingEpochBatchIterator._current_epoch_iterator.has_next"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.iterators.CountingIterator.has_next"], ["", "def", "end_of_epoch", "(", "self", ")", "->", "bool", ":", "\n", "        ", "return", "not", "self", ".", "_current_epoch_iterator", ".", "has_next", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.iterators.StreamingEpochBatchIterator.iterations_in_epoch": [[121, 126], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "iterations_in_epoch", "(", "self", ")", "->", "int", ":", "\n", "        ", "if", "self", ".", "_current_epoch_iterator", "is", "not", "None", ":", "\n", "            ", "return", "self", ".", "_current_epoch_iterator", ".", "count", "\n", "", "return", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.iterators.StreamingEpochBatchIterator.state_dict": [[127, 130], ["None"], "methods", ["None"], ["", "def", "state_dict", "(", "self", ")", ":", "\n", "        ", "return", "{", "\n", "'epoch'", ":", "self", ".", "epoch", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.iterators.StreamingEpochBatchIterator.load_state_dict": [[132, 134], ["None"], "methods", ["None"], ["", "def", "load_state_dict", "(", "self", ",", "state_dict", ")", ":", "\n", "        ", "self", ".", "epoch", "=", "state_dict", "[", "'epoch'", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.iterators.EpochBatchIterator.__init__": [[165, 183], ["isinstance", "tuple", "getattr"], "methods", ["None"], ["def", "__init__", "(", "\n", "self", ",", "dataset", ",", "collate_fn", ",", "batch_sampler", ",", "seed", "=", "1", ",", "num_shards", "=", "1", ",", "shard_id", "=", "0", ",", "\n", "num_workers", "=", "0", ",", "epoch", "=", "0", ",", "\n", ")", ":", "\n", "        ", "assert", "isinstance", "(", "dataset", ",", "torch", ".", "utils", ".", "data", ".", "Dataset", ")", "\n", "self", ".", "dataset", "=", "dataset", "\n", "self", ".", "collate_fn", "=", "collate_fn", "\n", "self", ".", "frozen_batches", "=", "tuple", "(", "batch_sampler", ")", "\n", "self", ".", "seed", "=", "seed", "\n", "self", ".", "num_shards", "=", "num_shards", "\n", "self", ".", "shard_id", "=", "shard_id", "\n", "self", ".", "num_workers", "=", "num_workers", "\n", "\n", "self", ".", "epoch", "=", "epoch", "\n", "self", ".", "shuffle", "=", "True", "\n", "self", ".", "_cur_epoch_itr", "=", "None", "\n", "self", ".", "_next_epoch_itr", "=", "None", "\n", "self", ".", "_supports_prefetch", "=", "getattr", "(", "dataset", ",", "'supports_prefetch'", ",", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.iterators.EpochBatchIterator.__len__": [[184, 186], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "frozen_batches", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.iterators.EpochBatchIterator.next_epoch_itr": [[187, 208], ["iterators.EpochBatchIterator.dataset.set_epoch", "iterators.EpochBatchIterator._get_iterator_for_epoch"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.fairseq_dataset.EpochListening.set_epoch", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.iterators.EpochBatchIterator._get_iterator_for_epoch"], ["", "def", "next_epoch_itr", "(", "self", ",", "shuffle", "=", "True", ",", "fix_batches_to_gpus", "=", "False", ")", ":", "\n", "        ", "\"\"\"Return a new iterator over the dataset.\n\n        Args:\n            shuffle (bool, optional): shuffle batches before returning the\n                iterator (default: True).\n            fix_batches_to_gpus: ensure that batches are always\n                allocated to the same shards across epochs. Requires\n                that :attr:`dataset` supports prefetching (default: False).\n        \"\"\"", "\n", "if", "self", ".", "_next_epoch_itr", "is", "not", "None", ":", "\n", "            ", "self", ".", "_cur_epoch_itr", "=", "self", ".", "_next_epoch_itr", "\n", "self", ".", "_next_epoch_itr", "=", "None", "\n", "", "else", ":", "\n", "            ", "self", ".", "epoch", "+=", "1", "\n", "self", ".", "_cur_epoch_itr", "=", "self", ".", "_get_iterator_for_epoch", "(", "\n", "self", ".", "epoch", ",", "shuffle", ",", "fix_batches_to_gpus", "=", "fix_batches_to_gpus", ",", "\n", ")", "\n", "", "self", ".", "dataset", ".", "set_epoch", "(", "self", ".", "epoch", ")", "\n", "self", ".", "shuffle", "=", "shuffle", "\n", "return", "self", ".", "_cur_epoch_itr", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.iterators.EpochBatchIterator.end_of_epoch": [[209, 212], ["iterators.EpochBatchIterator._cur_epoch_itr.has_next"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.iterators.CountingIterator.has_next"], ["", "def", "end_of_epoch", "(", "self", ")", "->", "bool", ":", "\n", "        ", "\"\"\"Returns whether the most recent epoch iterator has been exhausted\"\"\"", "\n", "return", "not", "self", ".", "_cur_epoch_itr", ".", "has_next", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.iterators.EpochBatchIterator.iterations_in_epoch": [[213, 221], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "iterations_in_epoch", "(", "self", ")", ":", "\n", "        ", "\"\"\"The number of consumed batches in the current epoch.\"\"\"", "\n", "if", "self", ".", "_cur_epoch_itr", "is", "not", "None", ":", "\n", "            ", "return", "self", ".", "_cur_epoch_itr", ".", "count", "\n", "", "elif", "self", ".", "_next_epoch_itr", "is", "not", "None", ":", "\n", "            ", "return", "self", ".", "_next_epoch_itr", ".", "count", "\n", "", "return", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.iterators.EpochBatchIterator.state_dict": [[222, 228], ["None"], "methods", ["None"], ["", "def", "state_dict", "(", "self", ")", ":", "\n", "        ", "\"\"\"Returns a dictionary containing a whole state of the iterator.\"\"\"", "\n", "return", "{", "\n", "'epoch'", ":", "self", ".", "epoch", ",", "\n", "'iterations_in_epoch'", ":", "self", ".", "iterations_in_epoch", ",", "\n", "'shuffle'", ":", "self", ".", "shuffle", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.iterators.EpochBatchIterator.load_state_dict": [[230, 240], ["state_dict.get", "iterators.EpochBatchIterator._get_iterator_for_epoch", "state_dict.get"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.iterators.EpochBatchIterator._get_iterator_for_epoch"], ["", "def", "load_state_dict", "(", "self", ",", "state_dict", ")", ":", "\n", "        ", "\"\"\"Copies the state of the iterator from the given *state_dict*.\"\"\"", "\n", "self", ".", "epoch", "=", "state_dict", "[", "'epoch'", "]", "\n", "itr_pos", "=", "state_dict", ".", "get", "(", "'iterations_in_epoch'", ",", "0", ")", "\n", "if", "itr_pos", ">", "0", ":", "\n", "# fast-forward epoch iterator", "\n", "            ", "self", ".", "_next_epoch_itr", "=", "self", ".", "_get_iterator_for_epoch", "(", "\n", "self", ".", "epoch", ",", "\n", "shuffle", "=", "state_dict", ".", "get", "(", "'shuffle'", ",", "True", ")", ",", "\n", "offset", "=", "itr_pos", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.iterators.EpochBatchIterator._get_iterator_for_epoch": [[242, 287], ["iterators.CountingIterator", "list", "iterators.EpochBatchIterator.dataset.prefetch", "list", "torch.utils.data.DataLoader", "data_utils.numpy_seed", "numpy.random.shuffle", "iterators.EpochBatchIterator._get_iterator_for_epoch.shuffle_batches"], "methods", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.fairseq_dataset.FairseqDataset.prefetch", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.data_utils.numpy_seed"], ["", "", "def", "_get_iterator_for_epoch", "(", "self", ",", "epoch", ",", "shuffle", ",", "fix_batches_to_gpus", "=", "False", ",", "offset", "=", "0", ")", ":", "\n", "\n", "        ", "def", "shuffle_batches", "(", "batches", ",", "seed", ")", ":", "\n", "# set seed based on the seed and epoch number so that we get", "\n", "# reproducible results when resuming from checkpoints", "\n", "            ", "with", "data_utils", ".", "numpy_seed", "(", "seed", ")", ":", "\n", "                ", "np", ".", "random", ".", "shuffle", "(", "batches", ")", "\n", "", "return", "batches", "\n", "\n", "", "if", "self", ".", "_supports_prefetch", ":", "\n", "            ", "batches", "=", "self", ".", "frozen_batches", "\n", "\n", "if", "shuffle", "and", "not", "fix_batches_to_gpus", ":", "\n", "                ", "batches", "=", "shuffle_batches", "(", "list", "(", "batches", ")", ",", "self", ".", "seed", "+", "epoch", ")", "\n", "\n", "", "batches", "=", "list", "(", "ShardedIterator", "(", "\n", "batches", ",", "self", ".", "num_shards", ",", "self", ".", "shard_id", ",", "fill_value", "=", "[", "]", "\n", ")", ")", "\n", "self", ".", "dataset", ".", "prefetch", "(", "[", "i", "for", "s", "in", "batches", "for", "i", "in", "s", "]", ")", "\n", "\n", "if", "shuffle", "and", "fix_batches_to_gpus", ":", "\n", "                ", "batches", "=", "shuffle_batches", "(", "batches", ",", "self", ".", "seed", "+", "epoch", "+", "self", ".", "shard_id", ")", "\n", "", "", "else", ":", "\n", "            ", "if", "shuffle", ":", "\n", "                ", "batches", "=", "shuffle_batches", "(", "list", "(", "self", ".", "frozen_batches", ")", ",", "self", ".", "seed", "+", "epoch", ")", "\n", "", "else", ":", "\n", "                ", "batches", "=", "self", ".", "frozen_batches", "\n", "", "batches", "=", "list", "(", "ShardedIterator", "(", "\n", "batches", ",", "self", ".", "num_shards", ",", "self", ".", "shard_id", ",", "fill_value", "=", "[", "]", "\n", ")", ")", "\n", "\n", "", "if", "offset", ">", "0", "and", "offset", ">=", "len", "(", "batches", ")", ":", "\n", "            ", "return", "None", "\n", "\n", "", "if", "self", ".", "num_workers", ">", "0", ":", "\n", "            ", "os", ".", "environ", "[", "'PYTHONWARNINGS'", "]", "=", "'ignore:semaphore_tracker:UserWarning'", "\n", "\n", "", "return", "CountingIterator", "(", "\n", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "\n", "self", ".", "dataset", ",", "\n", "collate_fn", "=", "self", ".", "collate_fn", ",", "\n", "batch_sampler", "=", "batches", "[", "offset", ":", "]", ",", "\n", "num_workers", "=", "self", ".", "num_workers", ",", "\n", ")", ",", "\n", "start", "=", "offset", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.iterators.GroupedIterator.__init__": [[298, 303], ["int", "int", "math.ceil", "math.ceil", "len", "float", "getattr", "float"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "iterable", ",", "chunk_size", ")", ":", "\n", "        ", "self", ".", "_len", "=", "int", "(", "math", ".", "ceil", "(", "len", "(", "iterable", ")", "/", "float", "(", "chunk_size", ")", ")", ")", "\n", "self", ".", "offset", "=", "int", "(", "math", ".", "ceil", "(", "getattr", "(", "iterable", ",", "'count'", ",", "0", ")", "/", "float", "(", "chunk_size", ")", ")", ")", "\n", "self", ".", "itr", "=", "iterable", "\n", "self", ".", "chunk_size", "=", "chunk_size", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.iterators.GroupedIterator.__len__": [[304, 306], ["None"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_len", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.iterators.GroupedIterator.__iter__": [[307, 309], ["None"], "methods", ["None"], ["", "def", "__iter__", "(", "self", ")", ":", "\n", "        ", "return", "self", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.iterators.GroupedIterator.__next__": [[310, 319], ["range", "chunk.append", "next", "len"], "methods", ["None"], ["", "def", "__next__", "(", "self", ")", ":", "\n", "        ", "chunk", "=", "[", "]", "\n", "try", ":", "\n", "            ", "for", "_", "in", "range", "(", "self", ".", "chunk_size", ")", ":", "\n", "                ", "chunk", ".", "append", "(", "next", "(", "self", ".", "itr", ")", ")", "\n", "", "", "except", "StopIteration", "as", "e", ":", "\n", "            ", "if", "len", "(", "chunk", ")", "==", "0", ":", "\n", "                ", "raise", "e", "\n", "", "", "return", "chunk", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.iterators.ShardedIterator.__init__": [[332, 344], ["itertools.zip_longest", "ValueError", "len", "range", "itertools.islice", "len", "len"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "iterable", ",", "num_shards", ",", "shard_id", ",", "fill_value", "=", "None", ")", ":", "\n", "        ", "if", "shard_id", "<", "0", "or", "shard_id", ">=", "num_shards", ":", "\n", "            ", "raise", "ValueError", "(", "'shard_id must be between 0 and num_shards'", ")", "\n", "\n", "", "self", ".", "_sharded_len", "=", "len", "(", "iterable", ")", "//", "num_shards", "\n", "if", "len", "(", "iterable", ")", "%", "num_shards", ">", "0", ":", "\n", "            ", "self", ".", "_sharded_len", "+=", "1", "\n", "\n", "", "self", ".", "itr", "=", "itertools", ".", "zip_longest", "(", "\n", "range", "(", "self", ".", "_sharded_len", ")", ",", "\n", "itertools", ".", "islice", "(", "iterable", ",", "shard_id", ",", "len", "(", "iterable", ")", ",", "num_shards", ")", ",", "\n", "fillvalue", "=", "fill_value", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.iterators.ShardedIterator.__len__": [[346, 348], ["None"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_sharded_len", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.iterators.ShardedIterator.__iter__": [[349, 351], ["None"], "methods", ["None"], ["", "def", "__iter__", "(", "self", ")", ":", "\n", "        ", "return", "self", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.iterators.ShardedIterator.__next__": [[352, 354], ["next"], "methods", ["None"], ["", "def", "__next__", "(", "self", ")", ":", "\n", "        ", "return", "next", "(", "self", ".", "itr", ")", "[", "1", "]", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.data_utils.numpy_seed": [[16, 31], ["numpy.random.get_state", "numpy.random.seed", "len", "int", "numpy.random.set_state", "hash"], "function", ["None"], ["@", "contextlib", ".", "contextmanager", "\n", "def", "numpy_seed", "(", "seed", ",", "*", "addl_seeds", ")", ":", "\n", "    ", "\"\"\"Context manager which seeds the NumPy PRNG with the specified seed and\n    restores the state afterward\"\"\"", "\n", "if", "seed", "is", "None", ":", "\n", "        ", "yield", "\n", "return", "\n", "", "if", "len", "(", "addl_seeds", ")", ">", "0", ":", "\n", "        ", "seed", "=", "int", "(", "hash", "(", "(", "seed", ",", "*", "addl_seeds", ")", ")", "%", "1e6", ")", "\n", "", "state", "=", "np", ".", "random", ".", "get_state", "(", ")", "\n", "np", ".", "random", ".", "seed", "(", "seed", ")", "\n", "try", ":", "\n", "        ", "yield", "\n", "", "finally", ":", "\n", "        ", "np", ".", "random", ".", "set_state", "(", "state", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.data_utils.collect_filtered": [[33, 48], ["function", "filtered.append"], "function", ["None"], ["", "", "def", "collect_filtered", "(", "function", ",", "iterable", ",", "filtered", ")", ":", "\n", "    ", "\"\"\"\n    Similar to :func:`filter` but collects filtered elements in ``filtered``.\n\n    Args:\n        function (callable): function that returns ``False`` for elements that\n            should be filtered\n        iterable (iterable): iterable to filter\n        filtered (list): list to store filtered elements\n    \"\"\"", "\n", "for", "el", "in", "iterable", ":", "\n", "        ", "if", "function", "(", "el", ")", ":", "\n", "            ", "yield", "el", "\n", "", "else", ":", "\n", "            ", "filtered", ".", "append", "(", "el", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.data_utils._filter_by_size_dynamic": [[50, 81], ["data_utils.collect_filtered", "numpy.fromiter", "isinstance", "isinstance", "isinstance", "size_fn", "size_fn", "isinstance", "all", "all", "set", "set", "isinstance", "isinstance", "all", "isinstance", "all", "max_positions.keys", "size_fn.keys", "all", "size_fn", "size_fn", "zip", "zip", "size_fn", "size_fn", "zip", "size_fn().values", "size_fn"], "function", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.data_utils.collect_filtered"], ["", "", "", "def", "_filter_by_size_dynamic", "(", "indices", ",", "size_fn", ",", "max_positions", ",", "raise_exception", "=", "False", ")", ":", "\n", "    ", "def", "check_size", "(", "idx", ")", ":", "\n", "        ", "if", "isinstance", "(", "max_positions", ",", "float", ")", "or", "isinstance", "(", "max_positions", ",", "int", ")", ":", "\n", "            ", "return", "size_fn", "(", "idx", ")", "<=", "max_positions", "\n", "", "elif", "isinstance", "(", "max_positions", ",", "dict", ")", ":", "\n", "            ", "idx_size", "=", "size_fn", "(", "idx", ")", "\n", "assert", "isinstance", "(", "idx_size", ",", "dict", ")", "\n", "intersect_keys", "=", "set", "(", "max_positions", ".", "keys", "(", ")", ")", "&", "set", "(", "idx_size", ".", "keys", "(", ")", ")", "\n", "return", "all", "(", "\n", "all", "(", "a", "is", "None", "or", "b", "is", "None", "or", "a", "<=", "b", "\n", "for", "a", ",", "b", "in", "zip", "(", "idx_size", "[", "key", "]", ",", "max_positions", "[", "key", "]", ")", ")", "\n", "for", "key", "in", "intersect_keys", "\n", ")", "\n", "", "else", ":", "\n", "# Hacky as heck, for the specific case of multilingual training with RoundRobin.", "\n", "            ", "if", "isinstance", "(", "size_fn", "(", "idx", ")", ",", "dict", ")", "and", "isinstance", "(", "max_positions", ",", "tuple", ")", ":", "\n", "                ", "return", "all", "(", "\n", "a", "is", "None", "or", "b", "is", "None", "or", "a", "<=", "b", "\n", "for", "a", ",", "b", "in", "zip", "(", "size_fn", "(", "idx", ")", ".", "values", "(", ")", ",", "max_positions", ")", "\n", ")", "\n", "# For MultiCorpusSampledDataset, will generalize it later", "\n", "", "if", "not", "isinstance", "(", "size_fn", "(", "idx", ")", ",", "Iterable", ")", ":", "\n", "                ", "return", "all", "(", "size_fn", "(", "idx", ")", "<=", "b", "for", "b", "in", "max_positions", ")", "\n", "", "return", "all", "(", "\n", "a", "is", "None", "or", "b", "is", "None", "or", "a", "<=", "b", "\n", "for", "a", ",", "b", "in", "zip", "(", "size_fn", "(", "idx", ")", ",", "max_positions", ")", "\n", ")", "\n", "", "", "ignored", "=", "[", "]", "\n", "itr", "=", "collect_filtered", "(", "check_size", ",", "indices", ",", "ignored", ")", "\n", "indices", "=", "np", ".", "fromiter", "(", "itr", ",", "dtype", "=", "np", ".", "int64", ",", "count", "=", "-", "1", ")", "\n", "return", "indices", ",", "ignored", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.data_utils.filter_by_size": [[83, 118], ["isinstance", "isinstance", "data_utils._filter_by_size_dynamic", "Exception", "len", "print", "hasattr", "isinstance", "indices[].tolist", "len", "hasattr", "isinstance", "indices[].tolist", "data_utils._filter_by_size_dynamic", "dataset.size", "len", "len"], "function", ["home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.data_utils._filter_by_size_dynamic", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.fairseq.progress_bar.tensorboard_log_wrapper.print", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.data_utils._filter_by_size_dynamic", "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.fairseq_dataset.FairseqDataset.size"], ["", "def", "filter_by_size", "(", "indices", ",", "dataset", ",", "max_positions", ",", "raise_exception", "=", "False", ")", ":", "\n", "    ", "\"\"\"\n    Filter indices based on their size.\n\n    Args:\n        indices (List[int]): ordered list of dataset indices\n        dataset (FairseqDataset): fairseq dataset instance\n        max_positions (tuple): filter elements larger than this size.\n            Comparisons are done component-wise.\n        raise_exception (bool, optional): if ``True``, raise an exception if\n            any elements are filtered (default: False).\n    \"\"\"", "\n", "if", "isinstance", "(", "max_positions", ",", "float", ")", "or", "isinstance", "(", "max_positions", ",", "int", ")", ":", "\n", "        ", "if", "hasattr", "(", "dataset", ",", "'sizes'", ")", "and", "isinstance", "(", "dataset", ".", "sizes", ",", "np", ".", "ndarray", ")", ":", "\n", "            ", "ignored", "=", "indices", "[", "dataset", ".", "sizes", "[", "indices", "]", ">", "max_positions", "]", ".", "tolist", "(", ")", "\n", "indices", "=", "indices", "[", "dataset", ".", "sizes", "[", "indices", "]", "<=", "max_positions", "]", "\n", "", "elif", "hasattr", "(", "dataset", ",", "'sizes'", ")", "and", "isinstance", "(", "dataset", ".", "sizes", ",", "list", ")", "and", "len", "(", "dataset", ".", "sizes", ")", "==", "1", ":", "\n", "            ", "ignored", "=", "indices", "[", "dataset", ".", "sizes", "[", "0", "]", "[", "indices", "]", ">", "max_positions", "]", ".", "tolist", "(", ")", "\n", "indices", "=", "indices", "[", "dataset", ".", "sizes", "[", "0", "]", "[", "indices", "]", "<=", "max_positions", "]", "\n", "", "else", ":", "\n", "            ", "indices", ",", "ignored", "=", "_filter_by_size_dynamic", "(", "indices", ",", "dataset", ".", "size", ",", "max_positions", ")", "\n", "", "", "else", ":", "\n", "        ", "indices", ",", "ignored", "=", "_filter_by_size_dynamic", "(", "indices", ",", "dataset", ".", "size", ",", "max_positions", ")", "\n", "\n", "", "if", "len", "(", "ignored", ")", ">", "0", "and", "raise_exception", ":", "\n", "        ", "raise", "Exception", "(", "(", "\n", "'Size of sample #{} is invalid (={}) since max_positions={}, '", "\n", "'skip this example with --skip-invalid-size-inputs-valid-test'", "\n", ")", ".", "format", "(", "ignored", "[", "0", "]", ",", "dataset", ".", "size", "(", "ignored", "[", "0", "]", ")", ",", "max_positions", ")", ")", "\n", "", "if", "len", "(", "ignored", ")", ">", "0", ":", "\n", "        ", "print", "(", "(", "\n", "'| WARNING: {} samples have invalid sizes and will be skipped, '", "\n", "'max_positions={}, first few sample ids={}'", "\n", ")", ".", "format", "(", "len", "(", "ignored", ")", ",", "max_positions", ",", "ignored", "[", ":", "10", "]", ")", ")", "\n", "", "return", "indices", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.data_utils.batch_by_size": [[120, 155], ["isinstance", "batch_by_size_fast", "numpy.fromiter", "ImportError"], "function", ["None"], ["", "def", "batch_by_size", "(", "\n", "indices", ",", "num_tokens_fn", ",", "max_tokens", "=", "None", ",", "max_sentences", "=", "None", ",", "\n", "required_batch_size_multiple", "=", "1", ",", "\n", ")", ":", "\n", "    ", "\"\"\"\n    Yield mini-batches of indices bucketed by size. Batches may contain\n    sequences of different lengths.\n\n    Args:\n        indices (List[int]): ordered list of dataset indices\n        num_tokens_fn (callable): function that returns the number of tokens at\n            a given index\n        max_tokens (int, optional): max number of tokens in each batch\n            (default: None).\n        max_sentences (int, optional): max number of sentences in each\n            batch (default: None).\n        required_batch_size_multiple (int, optional): require batch size to\n            be a multiple of N (default: 1).\n    \"\"\"", "\n", "try", ":", "\n", "        ", "from", "fairseq", ".", "data", ".", "data_utils_fast", "import", "batch_by_size_fast", "\n", "", "except", "ImportError", ":", "\n", "        ", "raise", "ImportError", "(", "\n", "'Please build Cython components with: `pip install --editable .` '", "\n", "'or `python setup.py build_ext --inplace`'", "\n", ")", "\n", "\n", "", "max_tokens", "=", "max_tokens", "if", "max_tokens", "is", "not", "None", "else", "-", "1", "\n", "max_sentences", "=", "max_sentences", "if", "max_sentences", "is", "not", "None", "else", "-", "1", "\n", "bsz_mult", "=", "required_batch_size_multiple", "\n", "\n", "if", "isinstance", "(", "indices", ",", "types", ".", "GeneratorType", ")", ":", "\n", "        ", "indices", "=", "np", ".", "fromiter", "(", "indices", ",", "dtype", "=", "np", ".", "int64", ",", "count", "=", "-", "1", ")", "\n", "\n", "", "return", "batch_by_size_fast", "(", "indices", ",", "num_tokens_fn", ",", "max_tokens", ",", "max_sentences", ",", "bsz_mult", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.dummy_dictionary.DummyDictionary.__init__": [[2, 18], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "size", ",", "\n", "pad", "=", "'<pad>'", ",", "\n", "bos", "=", "'<s>'", "\n", ")", ":", "\n", "        ", "self", ".", "pad_word", ",", "self", ".", "bos_word", "=", "pad", ",", "bos", "\n", "self", ".", "size", "=", "size", "\n", "self", ".", "nspecial", "=", "0", "\n", "\n", "self", ".", "pad_index", "=", "self", ".", "size", "\n", "self", ".", "nspecial", "+=", "1", "\n", "self", ".", "size", "+=", "1", "\n", "self", ".", "bos_index", "=", "self", ".", "size", "\n", "self", ".", "nspecial", "+=", "1", "\n", "self", ".", "size", "+=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.dummy_dictionary.DummyDictionary.__len__": [[19, 21], ["None"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "size", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.dummy_dictionary.DummyDictionary.bos": [[22, 24], ["None"], "methods", ["None"], ["", "def", "bos", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "bos_index", "\n", "\n"]], "home.repos.pwc.inspect_result.Newbeeer_Anytime-Auto-Regressive-Model.data.dummy_dictionary.DummyDictionary.pad": [[25, 27], ["None"], "methods", ["None"], ["", "def", "pad", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "pad_index", "\n", "", "", ""]]}