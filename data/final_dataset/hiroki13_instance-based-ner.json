{"home.repos.pwc.inspect_result.hiroki13_instance-based-ner.None.run_knn_models.set_config": [[16, 45], ["os.path.join"], "function", ["None"], ["def", "set_config", "(", "args", ",", "config", ")", ":", "\n", "  ", "if", "args", ".", "raw_path", ":", "\n", "    ", "config", "[", "\"raw_path\"", "]", "=", "args", ".", "raw_path", "\n", "", "if", "args", ".", "save_path", ":", "\n", "    ", "config", "[", "\"save_path\"", "]", "=", "args", ".", "save_path", "\n", "", "if", "args", ".", "data_path", ":", "\n", "    ", "config", "[", "\"data_path\"", "]", "=", "args", ".", "data_path", "\n", "", "if", "args", ".", "checkpoint_path", ":", "\n", "    ", "config", "[", "\"checkpoint_path\"", "]", "=", "args", ".", "checkpoint_path", "\n", "config", "[", "\"summary_path\"", "]", "=", "os", ".", "path", ".", "join", "(", "args", ".", "checkpoint_path", ",", "\"summary\"", ")", "\n", "", "if", "args", ".", "summary_path", ":", "\n", "    ", "config", "[", "\"summary_path\"", "]", "=", "args", ".", "summary_path", "\n", "", "if", "args", ".", "model_name", ":", "\n", "    ", "config", "[", "\"model_name\"", "]", "=", "args", ".", "model_name", "\n", "", "if", "args", ".", "batch_size", ":", "\n", "    ", "config", "[", "\"batch_size\"", "]", "=", "args", ".", "batch_size", "\n", "", "if", "args", ".", "data_size", ":", "\n", "    ", "config", "[", "\"data_size\"", "]", "=", "args", ".", "data_size", "\n", "", "if", "args", ".", "bilstm_type", ":", "\n", "    ", "config", "[", "\"bilstm_type\"", "]", "=", "args", ".", "bilstm_type", "\n", "", "if", "args", ".", "k", ":", "\n", "    ", "config", "[", "\"k\"", "]", "=", "args", ".", "k", "\n", "", "if", "args", ".", "predict", ":", "\n", "    ", "config", "[", "\"predict\"", "]", "=", "args", ".", "predict", "\n", "", "if", "args", ".", "max_span_len", ":", "\n", "    ", "config", "[", "\"max_span_len\"", "]", "=", "args", ".", "max_span_len", "\n", "", "if", "args", ".", "knn_sampling", ":", "\n", "    ", "config", "[", "\"knn_sampling\"", "]", "=", "args", ".", "knn_sampling", "\n", "", "return", "config", "\n", "\n"]], "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.None.run_knn_models.main": [[47, 69], ["json.load", "run_knn_models.set_config", "os.makedirs", "print", "models.knn_models.KnnModel", "utils.preprocessors.knn_preprocessors.KnnPreprocessor", "models.knn_models.KnnModel.restore_last_session", "open", "utils.batchers.knn_batchers.BaseKnnBatcher", "models.knn_models.KnnModel.eval", "models.knn_models.KnnModel.save_predicted_spans", "models.knn_models.KnnModel.save_predicted_bio_tags", "models.knn_models.KnnModel.save_nearest_spans", "models.knn_models.KnnModel.predict_on_command_line", "models.knn_models.KnnModel.save_span_representation"], "function", ["home.repos.pwc.inspect_result.hiroki13_instance-based-ner.scripts.convert_genia_to_json.load", "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.None.train_knn_models.set_config", "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.models.base_model.BaseModel.restore_last_session", "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.models.span_models.SpanModel.eval", "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.models.span_models.SpanModel.save_predicted_spans", "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.models.span_models.SpanModel.save_predicted_bio_tags", "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.models.knn_models.KnnModel.save_nearest_spans", "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.models.knn_models.KnnModel.predict_on_command_line", "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.models.span_models.SpanModel.save_span_representation"], ["", "def", "main", "(", "args", ")", ":", "\n", "  ", "config", "=", "json", ".", "load", "(", "open", "(", "args", ".", "config_file", ")", ")", "\n", "config", "=", "set_config", "(", "args", ",", "config", ")", "\n", "os", ".", "makedirs", "(", "config", "[", "\"save_path\"", "]", ",", "exist_ok", "=", "True", ")", "\n", "\n", "print", "(", "\"Build a knn span model...\"", ")", "\n", "model", "=", "KnnModel", "(", "config", ",", "BaseKnnBatcher", "(", "config", ")", ",", "is_train", "=", "False", ")", "\n", "preprocessor", "=", "KnnPreprocessor", "(", "config", ")", "\n", "model", ".", "restore_last_session", "(", "config", "[", "\"checkpoint_path\"", "]", ")", "\n", "\n", "if", "args", ".", "mode", "==", "\"eval\"", ":", "\n", "    ", "model", ".", "eval", "(", "preprocessor", ")", "\n", "", "elif", "args", ".", "mode", "==", "\"span\"", ":", "\n", "    ", "model", ".", "save_predicted_spans", "(", "args", ".", "data_name", ",", "preprocessor", ")", "\n", "", "elif", "args", ".", "mode", "==", "\"bio\"", ":", "\n", "    ", "model", ".", "save_predicted_bio_tags", "(", "args", ".", "data_name", ",", "preprocessor", ")", "\n", "", "elif", "args", ".", "mode", "==", "\"nearest_span\"", ":", "\n", "    ", "model", ".", "save_nearest_spans", "(", "args", ".", "data_name", ",", "preprocessor", ",", "args", ".", "print_knn", ")", "\n", "", "elif", "args", ".", "mode", "==", "\"cmd\"", ":", "\n", "    ", "model", ".", "predict_on_command_line", "(", "preprocessor", ")", "\n", "", "else", ":", "\n", "    ", "model", ".", "save_span_representation", "(", "args", ".", "data_name", ",", "preprocessor", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.None.run_span_models.set_config": [[10, 33], ["os.path.join"], "function", ["None"], ["def", "set_config", "(", "args", ",", "config", ")", ":", "\n", "    ", "if", "args", ".", "raw_path", ":", "\n", "        ", "config", "[", "\"raw_path\"", "]", "=", "args", ".", "raw_path", "\n", "", "if", "args", ".", "save_path", ":", "\n", "        ", "config", "[", "\"save_path\"", "]", "=", "args", ".", "save_path", "\n", "", "if", "args", ".", "data_path", ":", "\n", "      ", "config", "[", "\"data_path\"", "]", "=", "args", ".", "data_path", "\n", "", "if", "args", ".", "checkpoint_path", ":", "\n", "        ", "config", "[", "\"checkpoint_path\"", "]", "=", "args", ".", "checkpoint_path", "\n", "config", "[", "\"summary_path\"", "]", "=", "os", ".", "path", ".", "join", "(", "args", ".", "checkpoint_path", ",", "\"summary\"", ")", "\n", "", "if", "args", ".", "summary_path", ":", "\n", "        ", "config", "[", "\"summary_path\"", "]", "=", "args", ".", "summary_path", "\n", "", "if", "args", ".", "model_name", ":", "\n", "        ", "config", "[", "\"model_name\"", "]", "=", "args", ".", "model_name", "\n", "", "if", "args", ".", "batch_size", ":", "\n", "        ", "config", "[", "\"batch_size\"", "]", "=", "args", ".", "batch_size", "\n", "", "if", "args", ".", "data_size", ":", "\n", "        ", "config", "[", "\"data_size\"", "]", "=", "args", ".", "data_size", "\n", "", "if", "args", ".", "bilstm_type", ":", "\n", "        ", "config", "[", "\"bilstm_type\"", "]", "=", "args", ".", "bilstm_type", "\n", "", "if", "args", ".", "max_span_len", ":", "\n", "        ", "config", "[", "\"max_span_len\"", "]", "=", "args", ".", "max_span_len", "\n", "", "return", "config", "\n", "\n"]], "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.None.run_span_models.main": [[35, 54], ["json.load", "run_span_models.set_config", "os.makedirs", "print", "models.span_models.SpanModel", "utils.preprocessors.span_preprocessors.SpanPreprocessor", "models.span_models.SpanModel.restore_last_session", "open", "utils.batchers.span_batchers.BaseSpanBatcher", "models.span_models.SpanModel.eval", "models.span_models.SpanModel.save_predicted_spans", "models.span_models.SpanModel.build_proba_op", "models.span_models.SpanModel.save_predicted_bio_tags", "models.span_models.SpanModel.save_span_representation"], "function", ["home.repos.pwc.inspect_result.hiroki13_instance-based-ner.scripts.convert_genia_to_json.load", "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.None.train_knn_models.set_config", "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.models.base_model.BaseModel.restore_last_session", "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.models.span_models.SpanModel.eval", "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.models.span_models.SpanModel.save_predicted_spans", "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.models.span_models.SpanModel.build_proba_op", "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.models.span_models.SpanModel.save_predicted_bio_tags", "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.models.span_models.SpanModel.save_span_representation"], ["", "def", "main", "(", "args", ")", ":", "\n", "    ", "config", "=", "json", ".", "load", "(", "open", "(", "args", ".", "config_file", ")", ")", "\n", "config", "=", "set_config", "(", "args", ",", "config", ")", "\n", "os", ".", "makedirs", "(", "config", "[", "\"save_path\"", "]", ",", "exist_ok", "=", "True", ")", "\n", "\n", "print", "(", "\"Build models...\"", ")", "\n", "model", "=", "SpanModel", "(", "config", ",", "BaseSpanBatcher", "(", "config", ")", ",", "is_train", "=", "False", ")", "\n", "preprocessor", "=", "SpanPreprocessor", "(", "config", ")", "\n", "model", ".", "restore_last_session", "(", "config", "[", "\"checkpoint_path\"", "]", ")", "\n", "\n", "if", "args", ".", "mode", "==", "\"eval\"", ":", "\n", "        ", "model", ".", "eval", "(", "preprocessor", ")", "\n", "", "elif", "args", ".", "mode", "==", "\"span\"", ":", "\n", "        ", "model", ".", "save_predicted_spans", "(", "args", ".", "data_name", ",", "preprocessor", ")", "\n", "", "elif", "args", ".", "mode", "==", "\"bio\"", ":", "\n", "        ", "model", ".", "build_proba_op", "(", ")", "\n", "model", ".", "save_predicted_bio_tags", "(", "args", ".", "data_name", ",", "preprocessor", ")", "\n", "", "else", ":", "\n", "      ", "model", ".", "save_span_representation", "(", "args", ".", "data_name", ",", "preprocessor", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.None.train_span_models.set_config": [[16, 53], ["os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join"], "function", ["None"], ["def", "set_config", "(", "args", ",", "config", ")", ":", "\n", "  ", "if", "args", ".", "raw_path", ":", "\n", "    ", "config", "[", "\"raw_path\"", "]", "=", "args", ".", "raw_path", "\n", "", "if", "args", ".", "save_path", ":", "\n", "    ", "config", "[", "\"save_path\"", "]", "=", "args", ".", "save_path", "\n", "config", "[", "\"train_set\"", "]", "=", "os", ".", "path", ".", "join", "(", "args", ".", "save_path", ",", "\"train.json\"", ")", "\n", "config", "[", "\"valid_set\"", "]", "=", "os", ".", "path", ".", "join", "(", "args", ".", "save_path", ",", "\"valid.json\"", ")", "\n", "config", "[", "\"vocab\"", "]", "=", "os", ".", "path", ".", "join", "(", "args", ".", "save_path", ",", "\"vocab.json\"", ")", "\n", "config", "[", "\"pretrained_emb\"", "]", "=", "os", ".", "path", ".", "join", "(", "args", ".", "save_path", ",", "\"glove_emb.npz\"", ")", "\n", "", "if", "args", ".", "train_set", ":", "\n", "    ", "config", "[", "\"train_set\"", "]", "=", "args", ".", "train_set", "\n", "", "if", "args", ".", "valid_set", ":", "\n", "    ", "config", "[", "\"valid_set\"", "]", "=", "args", ".", "valid_set", "\n", "", "if", "args", ".", "pretrained_emb", ":", "\n", "    ", "config", "[", "\"pretrained_emb\"", "]", "=", "args", ".", "pretrained_emb", "\n", "", "if", "args", ".", "vocab", ":", "\n", "    ", "config", "[", "\"vocab\"", "]", "=", "args", ".", "vocab", "\n", "", "if", "args", ".", "checkpoint_path", ":", "\n", "    ", "config", "[", "\"checkpoint_path\"", "]", "=", "args", ".", "checkpoint_path", "\n", "config", "[", "\"summary_path\"", "]", "=", "os", ".", "path", ".", "join", "(", "args", ".", "checkpoint_path", ",", "\"summary\"", ")", "\n", "", "if", "args", ".", "summary_path", ":", "\n", "    ", "config", "[", "\"summary_path\"", "]", "=", "args", ".", "summary_path", "\n", "", "if", "args", ".", "model_name", ":", "\n", "    ", "config", "[", "\"model_name\"", "]", "=", "args", ".", "model_name", "\n", "", "if", "args", ".", "batch_size", ":", "\n", "    ", "config", "[", "\"batch_size\"", "]", "=", "args", ".", "batch_size", "\n", "", "if", "args", ".", "data_size", ":", "\n", "    ", "config", "[", "\"data_size\"", "]", "=", "args", ".", "data_size", "\n", "", "if", "args", ".", "bilstm_type", ":", "\n", "    ", "config", "[", "\"bilstm_type\"", "]", "=", "args", ".", "bilstm_type", "\n", "", "if", "args", ".", "keep_prob", ":", "\n", "    ", "config", "[", "\"keep_prob\"", "]", "=", "args", ".", "keep_prob", "\n", "", "if", "args", ".", "max_span_len", ":", "\n", "    ", "config", "[", "\"max_span_len\"", "]", "=", "args", ".", "max_span_len", "\n", "", "if", "args", ".", "max_n_spans", ":", "\n", "    ", "config", "[", "\"max_n_spans\"", "]", "=", "args", ".", "max_n_spans", "\n", "", "return", "config", "\n", "\n"]], "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.None.train_span_models.main": [[55, 68], ["json.load", "train_span_models.set_config", "utils.preprocessors.span_preprocessors.SpanPreprocessor", "print", "models.span_models.SpanModel", "models.span_models.SpanModel.train", "open", "os.path.exists", "utils.preprocessors.span_preprocessors.SpanPreprocessor.preprocess", "utils.batchers.span_batchers.BaseSpanBatcher"], "function", ["home.repos.pwc.inspect_result.hiroki13_instance-based-ner.scripts.convert_genia_to_json.load", "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.None.train_knn_models.set_config", "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.models.base_model.BaseModel.train", "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.preprocessors.span_preprocessors.SpanPreprocessor.preprocess"], ["", "def", "main", "(", "args", ")", ":", "\n", "  ", "config", "=", "json", ".", "load", "(", "open", "(", "args", ".", "config_file", ")", ")", "\n", "config", "=", "set_config", "(", "args", ",", "config", ")", "\n", "\n", "preprocessor", "=", "SpanPreprocessor", "(", "config", ")", "\n", "\n", "# create dataset from raw data files", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "config", "[", "\"save_path\"", "]", ")", ":", "\n", "    ", "preprocessor", ".", "preprocess", "(", ")", "\n", "\n", "", "print", "(", "\"Build a span model...\"", ")", "\n", "model", "=", "SpanModel", "(", "config", ",", "BaseSpanBatcher", "(", "config", ")", ")", "\n", "model", ".", "train", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.None.train_knn_models.set_config": [[16, 59], ["os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join"], "function", ["None"], ["def", "set_config", "(", "args", ",", "config", ")", ":", "\n", "  ", "if", "args", ".", "raw_path", ":", "\n", "    ", "config", "[", "\"raw_path\"", "]", "=", "args", ".", "raw_path", "\n", "", "if", "args", ".", "save_path", ":", "\n", "    ", "config", "[", "\"save_path\"", "]", "=", "args", ".", "save_path", "\n", "config", "[", "\"train_set\"", "]", "=", "os", ".", "path", ".", "join", "(", "args", ".", "save_path", ",", "\"train.json\"", ")", "\n", "config", "[", "\"valid_set\"", "]", "=", "os", ".", "path", ".", "join", "(", "args", ".", "save_path", ",", "\"valid.json\"", ")", "\n", "config", "[", "\"vocab\"", "]", "=", "os", ".", "path", ".", "join", "(", "args", ".", "save_path", ",", "\"vocab.json\"", ")", "\n", "config", "[", "\"pretrained_emb\"", "]", "=", "os", ".", "path", ".", "join", "(", "args", ".", "save_path", ",", "\"glove_emb.npz\"", ")", "\n", "", "if", "args", ".", "train_set", ":", "\n", "    ", "config", "[", "\"train_set\"", "]", "=", "args", ".", "train_set", "\n", "", "if", "args", ".", "valid_set", ":", "\n", "    ", "config", "[", "\"valid_set\"", "]", "=", "args", ".", "valid_set", "\n", "", "if", "args", ".", "pretrained_emb", ":", "\n", "    ", "config", "[", "\"pretrained_emb\"", "]", "=", "args", ".", "pretrained_emb", "\n", "", "if", "args", ".", "vocab", ":", "\n", "    ", "config", "[", "\"vocab\"", "]", "=", "args", ".", "vocab", "\n", "", "if", "args", ".", "checkpoint_path", ":", "\n", "    ", "config", "[", "\"checkpoint_path\"", "]", "=", "args", ".", "checkpoint_path", "\n", "config", "[", "\"summary_path\"", "]", "=", "os", ".", "path", ".", "join", "(", "args", ".", "checkpoint_path", ",", "\"summary\"", ")", "\n", "", "if", "args", ".", "summary_path", ":", "\n", "    ", "config", "[", "\"summary_path\"", "]", "=", "args", ".", "summary_path", "\n", "", "if", "args", ".", "model_name", ":", "\n", "    ", "config", "[", "\"model_name\"", "]", "=", "args", ".", "model_name", "\n", "", "if", "args", ".", "batch_size", ":", "\n", "    ", "config", "[", "\"batch_size\"", "]", "=", "args", ".", "batch_size", "\n", "", "if", "args", ".", "data_size", ":", "\n", "    ", "config", "[", "\"data_size\"", "]", "=", "args", ".", "data_size", "\n", "", "if", "args", ".", "bilstm_type", ":", "\n", "    ", "config", "[", "\"bilstm_type\"", "]", "=", "args", ".", "bilstm_type", "\n", "", "if", "args", ".", "keep_prob", ":", "\n", "    ", "config", "[", "\"keep_prob\"", "]", "=", "args", ".", "keep_prob", "\n", "", "if", "args", ".", "k", ":", "\n", "    ", "config", "[", "\"k\"", "]", "=", "args", ".", "k", "\n", "", "if", "args", ".", "predict", ":", "\n", "    ", "config", "[", "\"predict\"", "]", "=", "args", ".", "predict", "\n", "", "if", "args", ".", "max_span_len", ":", "\n", "    ", "config", "[", "\"max_span_len\"", "]", "=", "args", ".", "max_span_len", "\n", "", "if", "args", ".", "max_n_spans", ":", "\n", "    ", "config", "[", "\"max_n_spans\"", "]", "=", "args", ".", "max_n_spans", "\n", "", "if", "args", ".", "knn_sampling", ":", "\n", "    ", "config", "[", "\"knn_sampling\"", "]", "=", "args", ".", "knn_sampling", "\n", "", "return", "config", "\n", "\n"]], "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.None.train_knn_models.main": [[61, 73], ["json.load", "train_knn_models.set_config", "utils.preprocessors.knn_preprocessors.KnnPreprocessor", "models.knn_models.KnnModel", "models.knn_models.KnnModel.train", "open", "os.path.exists", "utils.preprocessors.knn_preprocessors.KnnPreprocessor.preprocess", "utils.batchers.knn_batchers.BaseKnnBatcher"], "function", ["home.repos.pwc.inspect_result.hiroki13_instance-based-ner.scripts.convert_genia_to_json.load", "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.None.train_knn_models.set_config", "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.models.base_model.BaseModel.train", "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.preprocessors.span_preprocessors.SpanPreprocessor.preprocess"], ["", "def", "main", "(", "args", ")", ":", "\n", "  ", "config", "=", "json", ".", "load", "(", "open", "(", "args", ".", "config_file", ")", ")", "\n", "config", "=", "set_config", "(", "args", ",", "config", ")", "\n", "\n", "preprocessor", "=", "KnnPreprocessor", "(", "config", ")", "\n", "\n", "# create dataset from raw data files", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "config", "[", "\"save_path\"", "]", ")", ":", "\n", "    ", "preprocessor", ".", "preprocess", "(", ")", "\n", "\n", "", "model", "=", "KnnModel", "(", "config", ",", "BaseKnnBatcher", "(", "config", ")", ")", "\n", "model", ".", "train", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.utils.data_utils.metrics_for_multi_class_spans": [[10, 22], ["zip", "sum", "sum", "sum", "len", "len", "zip"], "function", ["None"], ["def", "metrics_for_multi_class_spans", "(", "batch_gold_spans", ",", "batch_pred_spans", ",", "\n", "null_label_id", "=", "0", ")", ":", "\n", "  ", "correct", "=", "0", "\n", "p_total", "=", "0", "\n", "r_total", "=", "0", "\n", "for", "gold_spans", ",", "pred_spans", "in", "zip", "(", "batch_gold_spans", ",", "batch_pred_spans", ")", ":", "\n", "    ", "assert", "len", "(", "gold_spans", ")", "==", "len", "(", "pred_spans", ")", "\n", "r_total", "+=", "sum", "(", "[", "1", "for", "e", "in", "gold_spans", "if", "e", ">", "null_label_id", "]", ")", "\n", "p_total", "+=", "sum", "(", "[", "1", "for", "e", "in", "pred_spans", "if", "e", ">", "null_label_id", "]", ")", "\n", "correct", "+=", "sum", "(", "\n", "[", "1", "for", "t", ",", "p", "in", "zip", "(", "gold_spans", ",", "pred_spans", ")", "if", "t", "==", "p", ">", "null_label_id", "]", ")", "\n", "", "return", "correct", ",", "p_total", ",", "r_total", "\n", "\n"]], "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.utils.data_utils.count_gold_and_system_outputs": [[24, 34], ["zip", "sum", "sum", "len", "len", "zip"], "function", ["None"], ["", "def", "count_gold_and_system_outputs", "(", "batch_gold_spans", ",", "batch_pred_spans", ",", "\n", "null_label_id", "=", "0", ")", ":", "\n", "  ", "correct", "=", "0", "\n", "p_total", "=", "0", "\n", "for", "gold_spans", ",", "pred_spans", "in", "zip", "(", "batch_gold_spans", ",", "batch_pred_spans", ")", ":", "\n", "    ", "assert", "len", "(", "gold_spans", ")", "==", "len", "(", "pred_spans", ")", "\n", "p_total", "+=", "sum", "(", "[", "1", "for", "e", "in", "pred_spans", "if", "e", ">", "null_label_id", "]", ")", "\n", "correct", "+=", "sum", "(", "\n", "[", "1", "for", "t", ",", "p", "in", "zip", "(", "gold_spans", ",", "pred_spans", ")", "if", "t", "==", "p", ">", "null_label_id", "]", ")", "\n", "", "return", "correct", ",", "p_total", "\n", "\n"]], "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.utils.data_utils.count_gold_spans": [[36, 41], ["utils.common.load_json", "len"], "function", ["home.repos.pwc.inspect_result.hiroki13_instance-based-ner.scripts.retrieve_knn_sents_with_glove.load_json"], ["", "def", "count_gold_spans", "(", "path", ")", ":", "\n", "  ", "n_gold_spans", "=", "0", "\n", "for", "record", "in", "load_json", "(", "path", ")", ":", "\n", "    ", "n_gold_spans", "+=", "len", "(", "record", "[", "\"tags\"", "]", ")", "\n", "", "return", "n_gold_spans", "\n", "\n"]], "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.utils.data_utils.f_score": [[43, 49], ["None"], "function", ["None"], ["", "def", "f_score", "(", "correct", ",", "p_total", ",", "r_total", ")", ":", "\n", "  ", "precision", "=", "correct", "/", "p_total", "if", "p_total", ">", "0", "else", "0.", "\n", "recall", "=", "correct", "/", "r_total", "if", "r_total", ">", "0", "else", "0.", "\n", "f1", "=", "(", "2", "*", "precision", "*", "recall", ")", "/", "(", "\n", "precision", "+", "recall", ")", "if", "precision", "+", "recall", ">", "0", "else", "0.", "\n", "return", "precision", ",", "recall", ",", "f1", "\n", "\n"]], "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.utils.data_utils.align_data": [[51, 70], ["dict", "data.items", "max", "zip", "range", "len", "len", "data.values", "len", "list", "data.keys"], "function", ["None"], ["", "def", "align_data", "(", "data", ")", ":", "\n", "  ", "\"\"\"Given dict with lists, creates aligned strings\n  Args:\n      data: (dict) data[\"x\"] = [\"I\", \"love\", \"you\"]\n            (dict) data[\"y\"] = [\"O\", \"O\", \"O\"]\n  Returns:\n      data_aligned: (dict) data_align[\"x\"] = \"I love you\"\n                           data_align[\"y\"] = \"O O    O  \"\n  \"\"\"", "\n", "spacings", "=", "[", "max", "(", "[", "len", "(", "seq", "[", "i", "]", ")", "for", "seq", "in", "data", ".", "values", "(", ")", "]", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "data", "[", "list", "(", "data", ".", "keys", "(", ")", ")", "[", "0", "]", "]", ")", ")", "]", "\n", "data_aligned", "=", "dict", "(", ")", "\n", "# for each entry, create aligned string", "\n", "for", "key", ",", "seq", "in", "data", ".", "items", "(", ")", ":", "\n", "    ", "str_aligned", "=", "''", "\n", "for", "token", ",", "spacing", "in", "zip", "(", "seq", ",", "spacings", ")", ":", "\n", "      ", "str_aligned", "+=", "token", "+", "' '", "*", "(", "spacing", "-", "len", "(", "token", ")", "+", "1", ")", "\n", "", "data_aligned", "[", "key", "]", "=", "str_aligned", "\n", "", "return", "data_aligned", "\n", "\n"]], "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.utils.data_utils.span2bio": [[72, 83], ["range", "range", "str"], "function", ["None"], ["", "def", "span2bio", "(", "spans", ",", "n_words", ",", "tag_dict", "=", "None", ")", ":", "\n", "  ", "bio_tags", "=", "[", "'O'", "for", "_", "in", "range", "(", "n_words", ")", "]", "\n", "for", "(", "label_id", ",", "pre_index", ",", "post_index", ")", "in", "spans", ":", "\n", "    ", "if", "tag_dict", ":", "\n", "      ", "label", "=", "tag_dict", "[", "label_id", "]", "\n", "", "else", ":", "\n", "      ", "label", "=", "str", "(", "label_id", ")", "\n", "", "bio_tags", "[", "pre_index", "]", "=", "'B-%s'", "%", "label", "\n", "for", "index", "in", "range", "(", "pre_index", "+", "1", ",", "post_index", "+", "1", ")", ":", "\n", "      ", "bio_tags", "[", "index", "]", "=", "'I-%s'", "%", "label", "\n", "", "", "return", "bio_tags", "\n", "\n"]], "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.utils.data_utils.bio2triple": [[85, 94], ["enumerate", "tag.startswith", "triples.append", "tag.startswith"], "function", ["None"], ["", "def", "bio2triple", "(", "tags", ")", ":", "\n", "  ", "triples", "=", "[", "]", "\n", "for", "i", ",", "tag", "in", "enumerate", "(", "tags", ")", ":", "\n", "    ", "if", "tag", ".", "startswith", "(", "'B-'", ")", ":", "\n", "      ", "label", "=", "tag", "[", "2", ":", "]", "\n", "triples", ".", "append", "(", "[", "label", ",", "i", ",", "i", "]", ")", "\n", "", "elif", "tag", ".", "startswith", "(", "'I-'", ")", ":", "\n", "      ", "triples", "[", "-", "1", "]", "=", "triples", "[", "-", "1", "]", "[", ":", "-", "1", "]", "+", "[", "i", "]", "\n", "", "", "return", "triples", "\n", "\n"]], "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.utils.data_utils.bio_to_span": [[96, 103], ["data_utils.bio2triple"], "function", ["home.repos.pwc.inspect_result.hiroki13_instance-based-ner.utils.data_utils.bio2triple"], ["", "def", "bio_to_span", "(", "datasets", ")", ":", "\n", "  ", "for", "dataset", "in", "datasets", ":", "\n", "    ", "for", "record", "in", "dataset", ":", "\n", "      ", "bio_tags", "=", "record", "[", "\"tags\"", "]", "\n", "triples", "=", "bio2triple", "(", "bio_tags", ")", "\n", "record", "[", "\"tags\"", "]", "=", "triples", "\n", "", "", "return", "datasets", "\n", "", ""]], "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.utils.common.load_json": [[22, 26], ["codecs.open", "ujson.load"], "function", ["home.repos.pwc.inspect_result.hiroki13_instance-based-ner.scripts.convert_genia_to_json.load"], ["def", "load_json", "(", "filename", ")", ":", "\n", "  ", "with", "codecs", ".", "open", "(", "filename", ",", "mode", "=", "'r'", ",", "encoding", "=", "'utf-8'", ")", "as", "f", ":", "\n", "    ", "dataset", "=", "ujson", ".", "load", "(", "f", ")", "\n", "", "return", "dataset", "\n", "\n"]], "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.utils.common.write_json": [[28, 31], ["codecs.open", "ujson.dump"], "function", ["None"], ["", "def", "write_json", "(", "filename", ",", "data", ")", ":", "\n", "  ", "with", "codecs", ".", "open", "(", "filename", ",", "mode", "=", "\"w\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "f", ":", "\n", "    ", "ujson", ".", "dump", "(", "data", ",", "f", ",", "ensure_ascii", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.utils.common.load_pickle": [[33, 36], ["gzip.open", "pickle.load"], "function", ["home.repos.pwc.inspect_result.hiroki13_instance-based-ner.scripts.convert_genia_to_json.load"], ["", "", "def", "load_pickle", "(", "filename", ")", ":", "\n", "  ", "with", "gzip", ".", "open", "(", "filename", ",", "'rb'", ")", "as", "gf", ":", "\n", "    ", "return", "pickle", ".", "load", "(", "gf", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.utils.common.write_pickle": [[38, 41], ["gzip.open", "pickle.dump"], "function", ["None"], ["", "", "def", "write_pickle", "(", "filename", ",", "data", ")", ":", "\n", "  ", "with", "gzip", ".", "open", "(", "filename", "+", "'.pkl.gz'", ",", "'wb'", ")", "as", "gf", ":", "\n", "    ", "pickle", ".", "dump", "(", "data", ",", "gf", ",", "pickle", ".", "HIGHEST_PROTOCOL", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.utils.common.word_convert": [[43, 50], ["common.is_digit", "word.lower.lower"], "function", ["home.repos.pwc.inspect_result.hiroki13_instance-based-ner.utils.common.is_digit"], ["", "", "def", "word_convert", "(", "word", ",", "keep_number", "=", "True", ",", "lowercase", "=", "True", ")", ":", "\n", "  ", "if", "not", "keep_number", ":", "\n", "    ", "if", "is_digit", "(", "word", ")", ":", "\n", "      ", "return", "NUM", "\n", "", "", "if", "lowercase", ":", "\n", "    ", "word", "=", "word", ".", "lower", "(", ")", "\n", "", "return", "word", "\n", "\n"]], "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.utils.common.is_digit": [[52, 67], ["re.compile().match", "float", "unicodedata.numeric", "re.compile"], "function", ["None"], ["", "def", "is_digit", "(", "word", ")", ":", "\n", "  ", "try", ":", "\n", "    ", "float", "(", "word", ")", "\n", "return", "True", "\n", "", "except", "ValueError", ":", "\n", "    ", "pass", "\n", "", "try", ":", "\n", "    ", "unicodedata", ".", "numeric", "(", "word", ")", "\n", "return", "True", "\n", "", "except", "(", "TypeError", ",", "ValueError", ")", ":", "\n", "    ", "pass", "\n", "", "result", "=", "re", ".", "compile", "(", "r'^[-+]?[0-9]+,[0-9]+$'", ")", ".", "match", "(", "word", ")", "\n", "if", "result", ":", "\n", "    ", "return", "True", "\n", "", "return", "False", "\n", "", ""]], "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.utils.logger.Progbar.__init__": [[34, 43], ["time.time"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "target", ",", "width", "=", "30", ",", "verbose", "=", "1", ")", ":", "\n", "    ", "self", ".", "width", "=", "width", "\n", "self", ".", "target", "=", "target", "\n", "self", ".", "sum_values", "=", "{", "}", "\n", "self", ".", "unique_values", "=", "[", "]", "\n", "self", ".", "start", "=", "time", ".", "time", "(", ")", "\n", "self", ".", "total_width", "=", "0", "\n", "self", ".", "seen_so_far", "=", "0", "\n", "self", ".", "verbose", "=", "verbose", "\n", "\n"]], "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.utils.logger.Progbar.update": [[44, 136], ["time.time", "sys.stdout.write", "sys.stdout.write", "int", "sys.stdout.write", "len", "len", "sys.stdout.write", "sys.stdout.flush", "type", "logger.Progbar.unique_values.append", "logger.Progbar.unique_values.append", "int", "float", "sys.stdout.write", "sys.stdout.write", "logger.Progbar.unique_values.append", "logger.Progbar.unique_values.append", "numpy.floor", "type", "numpy.log10", "max", "max"], "methods", ["None"], ["", "def", "update", "(", "self", ",", "current", ",", "values", "=", "None", ",", "exact", "=", "None", ",", "strict", "=", "None", ")", ":", "\n", "    ", "\"\"\"Updates the progress bar.\n        Arguments\n            current: Index of current step.\n            values: List of tuples (name, value_for_last_step).\n                The progress bar will display averages for these values.\n            exact: List of tuples (name, value_for_last_step).\n                The progress bar will display these values directly.\n        \"\"\"", "\n", "if", "strict", "is", "None", ":", "\n", "      ", "strict", "=", "[", "]", "\n", "", "if", "exact", "is", "None", ":", "\n", "      ", "exact", "=", "[", "]", "\n", "", "if", "values", "is", "None", ":", "\n", "      ", "values", "=", "[", "]", "\n", "", "for", "k", ",", "v", "in", "values", ":", "\n", "      ", "if", "type", "(", "v", ")", "==", "int", ":", "# for global steps", "\n", "        ", "if", "k", "not", "in", "self", ".", "sum_values", ":", "\n", "          ", "self", ".", "unique_values", ".", "append", "(", "k", ")", "\n", "self", ".", "sum_values", "[", "k", "]", "=", "v", "\n", "", "else", ":", "\n", "          ", "self", ".", "sum_values", "[", "k", "]", "=", "v", "\n", "", "", "else", ":", "\n", "        ", "if", "k", "not", "in", "self", ".", "sum_values", ":", "\n", "          ", "self", ".", "sum_values", "[", "k", "]", "=", "[", "v", "*", "(", "current", "-", "self", ".", "seen_so_far", ")", ",", "\n", "current", "-", "self", ".", "seen_so_far", "]", "\n", "self", ".", "unique_values", ".", "append", "(", "k", ")", "\n", "", "else", ":", "\n", "          ", "self", ".", "sum_values", "[", "k", "]", "[", "0", "]", "+=", "v", "*", "(", "current", "-", "self", ".", "seen_so_far", ")", "\n", "self", ".", "sum_values", "[", "k", "]", "[", "1", "]", "+=", "(", "current", "-", "self", ".", "seen_so_far", ")", "\n", "", "", "", "for", "k", ",", "v", "in", "exact", ":", "\n", "      ", "if", "k", "not", "in", "self", ".", "sum_values", ":", "\n", "        ", "self", ".", "unique_values", ".", "append", "(", "k", ")", "\n", "", "self", ".", "sum_values", "[", "k", "]", "=", "[", "v", ",", "1", "]", "\n", "\n", "", "for", "k", ",", "v", "in", "strict", ":", "\n", "      ", "if", "k", "not", "in", "self", ".", "sum_values", ":", "\n", "        ", "self", ".", "unique_values", ".", "append", "(", "k", ")", "\n", "", "self", ".", "sum_values", "[", "k", "]", "=", "v", "\n", "\n", "", "self", ".", "seen_so_far", "=", "current", "\n", "\n", "now", "=", "time", ".", "time", "(", ")", "\n", "if", "self", ".", "verbose", "==", "1", ":", "\n", "      ", "prev_total_width", "=", "self", ".", "total_width", "\n", "sys", ".", "stdout", ".", "write", "(", "\"\\b\"", "*", "prev_total_width", ")", "\n", "sys", ".", "stdout", ".", "write", "(", "\"\\r\"", ")", "\n", "numdigits", "=", "int", "(", "np", ".", "floor", "(", "np", ".", "log10", "(", "self", ".", "target", ")", ")", ")", "+", "1", "\n", "barstr", "=", "'%%%dd/%%%dd ['", "%", "(", "numdigits", ",", "numdigits", ")", "\n", "bar", "=", "barstr", "%", "(", "current", ",", "self", ".", "target", ")", "\n", "prog", "=", "float", "(", "current", ")", "/", "self", ".", "target", "\n", "prog_width", "=", "int", "(", "self", ".", "width", "*", "prog", ")", "\n", "if", "prog_width", ">", "0", ":", "\n", "        ", "bar", "+=", "(", "'='", "*", "(", "prog_width", "-", "1", ")", ")", "\n", "if", "current", "<", "self", ".", "target", ":", "\n", "          ", "bar", "+=", "'>'", "\n", "", "else", ":", "\n", "          ", "bar", "+=", "'='", "\n", "", "", "bar", "+=", "(", "'.'", "*", "(", "self", ".", "width", "-", "prog_width", ")", ")", "\n", "bar", "+=", "']'", "\n", "sys", ".", "stdout", ".", "write", "(", "bar", ")", "\n", "self", ".", "total_width", "=", "len", "(", "bar", ")", "\n", "if", "current", ":", "\n", "        ", "time_per_unit", "=", "(", "now", "-", "self", ".", "start", ")", "/", "current", "\n", "", "else", ":", "\n", "        ", "time_per_unit", "=", "0", "\n", "", "eta", "=", "time_per_unit", "*", "(", "self", ".", "target", "-", "current", ")", "\n", "info", "=", "''", "\n", "if", "current", "<", "self", ".", "target", ":", "\n", "        ", "info", "+=", "' - ETA: %ds'", "%", "eta", "\n", "", "else", ":", "\n", "        ", "info", "+=", "' - %ds'", "%", "(", "now", "-", "self", ".", "start", ")", "\n", "", "for", "k", "in", "self", ".", "unique_values", ":", "\n", "        ", "if", "type", "(", "self", ".", "sum_values", "[", "k", "]", ")", "is", "list", ":", "\n", "          ", "info", "+=", "' - %s: %.4f'", "%", "(", "\n", "k", ",", "self", ".", "sum_values", "[", "k", "]", "[", "0", "]", "/", "max", "(", "1", ",", "self", ".", "sum_values", "[", "k", "]", "[", "1", "]", ")", ")", "\n", "", "else", ":", "\n", "          ", "info", "+=", "' - %s: %s'", "%", "(", "k", ",", "self", ".", "sum_values", "[", "k", "]", ")", "\n", "", "", "self", ".", "total_width", "+=", "len", "(", "info", ")", "\n", "if", "prev_total_width", ">", "self", ".", "total_width", ":", "\n", "        ", "info", "+=", "(", "(", "prev_total_width", "-", "self", ".", "total_width", ")", "*", "' '", ")", "\n", "", "sys", ".", "stdout", ".", "write", "(", "info", ")", "\n", "sys", ".", "stdout", ".", "flush", "(", ")", "\n", "if", "current", ">=", "self", ".", "target", ":", "\n", "        ", "sys", ".", "stdout", ".", "write", "(", "\"\\n\"", ")", "\n", "", "", "if", "self", ".", "verbose", "==", "2", ":", "\n", "      ", "if", "current", ">=", "self", ".", "target", ":", "\n", "        ", "info", "=", "'%ds'", "%", "(", "now", "-", "self", ".", "start", ")", "\n", "for", "k", "in", "self", ".", "unique_values", ":", "\n", "          ", "info", "+=", "' - %s: %.4f'", "%", "(", "\n", "k", ",", "self", ".", "sum_values", "[", "k", "]", "[", "0", "]", "/", "max", "(", "1", ",", "self", ".", "sum_values", "[", "k", "]", "[", "1", "]", ")", ")", "\n", "", "sys", ".", "stdout", ".", "write", "(", "info", "+", "\"\\n\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.utils.logger.Progbar.add": [[137, 141], ["logger.Progbar.update"], "methods", ["home.repos.pwc.inspect_result.hiroki13_instance-based-ner.utils.logger.Progbar.update"], ["", "", "", "def", "add", "(", "self", ",", "n", ",", "values", "=", "None", ")", ":", "\n", "    ", "if", "values", "is", "None", ":", "\n", "      ", "values", "=", "[", "]", "\n", "", "self", ".", "update", "(", "self", ".", "seen_so_far", "+", "n", ",", "values", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.utils.logger.get_logger": [[7, 23], ["logging.getLogger", "logging.getLogger.setLevel", "logging.basicConfig", "logging.FileHandler", "logging.FileHandler.setLevel", "logging.FileHandler.setFormatter", "logging.getLogger().addHandler", "logging.Formatter", "logging.getLogger"], "function", ["None"], ["def", "get_logger", "(", "filename", ")", ":", "\n", "  ", "\"\"\"Return a logger instance that writes in filename\n  Args:\n    filename: (string) path to log.txt\n  Returns:\n    logger: (instance of logger)\n  \"\"\"", "\n", "logger", "=", "logging", ".", "getLogger", "(", "'logger'", ")", "\n", "logger", ".", "setLevel", "(", "logging", ".", "DEBUG", ")", "\n", "logging", ".", "basicConfig", "(", "format", "=", "'%(message)s'", ",", "level", "=", "logging", ".", "DEBUG", ")", "\n", "handler", "=", "logging", ".", "FileHandler", "(", "filename", ")", "\n", "handler", ".", "setLevel", "(", "logging", ".", "DEBUG", ")", "\n", "handler", ".", "setFormatter", "(", "\n", "logging", ".", "Formatter", "(", "'%(asctime)s:%(levelname)s: %(message)s'", ")", ")", "\n", "logging", ".", "getLogger", "(", ")", ".", "addHandler", "(", "handler", ")", "\n", "return", "logger", "\n", "\n"]], "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.preprocessors.base_preprocessors.Preprocessor.__init__": [[20, 22], ["None"], "methods", ["None"], ["  ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "    ", "self", ".", "config", "=", "config", "\n", "\n"]], "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.preprocessors.base_preprocessors.Preprocessor.raw_dataset_iter": [[23, 43], ["codecs.open", "line.split.split.lstrip().rstrip", "line.split.split.startswith", "len", "line.split.split.split", "utils.common.word_convert", "words.append", "tags.append", "line.split.split.lstrip", "len"], "methods", ["home.repos.pwc.inspect_result.hiroki13_instance-based-ner.utils.common.word_convert"], ["", "@", "staticmethod", "\n", "def", "raw_dataset_iter", "(", "filename", ",", "keep_number", ",", "lowercase", ")", ":", "\n", "    ", "with", "codecs", ".", "open", "(", "filename", ",", "mode", "=", "\"r\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "f", ":", "\n", "      ", "words", ",", "tags", "=", "[", "]", ",", "[", "]", "\n", "for", "line", "in", "f", ":", "\n", "        ", "line", "=", "line", ".", "lstrip", "(", ")", ".", "rstrip", "(", ")", "\n", "if", "line", ".", "startswith", "(", "\"-DOCSTART-\"", ")", ":", "\n", "          ", "continue", "\n", "", "if", "len", "(", "line", ")", "==", "0", ":", "\n", "          ", "if", "len", "(", "words", ")", "!=", "0", ":", "\n", "            ", "yield", "words", ",", "tags", "\n", "words", ",", "tags", "=", "[", "]", ",", "[", "]", "\n", "", "", "else", ":", "\n", "          ", "line", "=", "line", ".", "split", "(", ")", "\n", "word", "=", "line", "[", "0", "]", "\n", "tag", "=", "line", "[", "-", "1", "]", "\n", "word", "=", "word_convert", "(", "word", ",", "keep_number", "=", "keep_number", ",", "\n", "lowercase", "=", "lowercase", ")", "\n", "words", ".", "append", "(", "word", ")", "\n", "tags", ".", "append", "(", "tag", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.preprocessors.base_preprocessors.Preprocessor.load_dataset": [[44, 49], ["base_preprocessors.Preprocessor.raw_dataset_iter", "dataset.append"], "methods", ["home.repos.pwc.inspect_result.hiroki13_instance-based-ner.preprocessors.base_preprocessors.Preprocessor.raw_dataset_iter"], ["", "", "", "", "def", "load_dataset", "(", "self", ",", "filename", ",", "keep_number", "=", "False", ",", "lowercase", "=", "True", ")", ":", "\n", "    ", "dataset", "=", "[", "]", "\n", "for", "words", ",", "tags", "in", "self", ".", "raw_dataset_iter", "(", "filename", ",", "keep_number", ",", "lowercase", ")", ":", "\n", "      ", "dataset", ".", "append", "(", "{", "\"words\"", ":", "words", ",", "\"tags\"", ":", "tags", "}", ")", "\n", "", "return", "dataset", "\n", "\n"]], "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.preprocessors.base_preprocessors.Preprocessor.load_glove_vocab": [[50, 59], ["set", "codecs.open", "tqdm.tqdm.tqdm", "line.lstrip().rstrip().split.lstrip().rstrip().split.lstrip().rstrip().split", "set.add", "line.lstrip().rstrip().split.lstrip().rstrip().split.lstrip().rstrip", "line.lstrip().rstrip().split.lstrip().rstrip().split.lstrip"], "methods", ["home.repos.pwc.inspect_result.hiroki13_instance-based-ner.utils.logger.Progbar.add"], ["", "@", "staticmethod", "\n", "def", "load_glove_vocab", "(", "glove_path", ",", "glove_name", ")", ":", "\n", "    ", "vocab", "=", "set", "(", ")", "\n", "total", "=", "glove_sizes", "[", "glove_name", "]", "\n", "with", "codecs", ".", "open", "(", "glove_path", ",", "mode", "=", "'r'", ",", "encoding", "=", "'utf-8'", ")", "as", "f", ":", "\n", "      ", "for", "line", "in", "tqdm", "(", "f", ",", "total", "=", "total", ",", "desc", "=", "\"Load glove vocabulary\"", ")", ":", "\n", "        ", "line", "=", "line", ".", "lstrip", "(", ")", ".", "rstrip", "(", ")", ".", "split", "(", "\" \"", ")", "\n", "vocab", ".", "add", "(", "line", "[", "0", "]", ")", "\n", "", "", "return", "vocab", "\n", "\n"]], "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.preprocessors.base_preprocessors.Preprocessor.build_word_vocab": [[60, 73], ["collections.Counter", "dict", "collections.Counter.most_common", "enumerate"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "build_word_vocab", "(", "datasets", ")", ":", "\n", "    ", "word_counter", "=", "Counter", "(", ")", "\n", "for", "dataset", "in", "datasets", ":", "\n", "      ", "for", "record", "in", "dataset", ":", "\n", "        ", "words", "=", "record", "[", "\"words\"", "]", "\n", "for", "word", "in", "words", ":", "\n", "          ", "word_counter", "[", "word", "]", "+=", "1", "\n", "", "", "", "word_vocab", "=", "[", "PAD", ",", "UNK", ",", "NUM", "]", "+", "[", "word", "for", "word", ",", "_", "in", "\n", "word_counter", ".", "most_common", "(", "10000", ")", "if", "\n", "word", "!=", "NUM", "]", "\n", "word_dict", "=", "dict", "(", "[", "(", "word", ",", "idx", ")", "for", "idx", ",", "word", "in", "enumerate", "(", "word_vocab", ")", "]", ")", "\n", "return", "word_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.preprocessors.base_preprocessors.Preprocessor.build_char_vocab": [[74, 86], ["collections.Counter", "dict", "sorted", "enumerate", "collections.Counter.most_common"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "build_char_vocab", "(", "datasets", ")", ":", "\n", "    ", "char_counter", "=", "Counter", "(", ")", "\n", "for", "dataset", "in", "datasets", ":", "\n", "      ", "for", "record", "in", "dataset", ":", "\n", "        ", "for", "word", "in", "record", "[", "\"words\"", "]", ":", "\n", "          ", "for", "char", "in", "word", ":", "\n", "            ", "char_counter", "[", "char", "]", "+=", "1", "\n", "", "", "", "", "word_vocab", "=", "[", "PAD", ",", "UNK", "]", "+", "sorted", "(", "\n", "[", "char", "for", "char", ",", "_", "in", "char_counter", ".", "most_common", "(", ")", "]", ")", "\n", "word_dict", "=", "dict", "(", "[", "(", "word", ",", "idx", ")", "for", "idx", ",", "word", "in", "enumerate", "(", "word_vocab", ")", "]", ")", "\n", "return", "word_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.preprocessors.base_preprocessors.Preprocessor.build_word_vocab_pretrained": [[87, 99], ["collections.Counter", "dict", "sorted", "list", "enumerate"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "build_word_vocab_pretrained", "(", "datasets", ",", "glove_vocab", ")", ":", "\n", "    ", "word_counter", "=", "Counter", "(", ")", "\n", "for", "dataset", "in", "datasets", ":", "\n", "      ", "for", "record", "in", "dataset", ":", "\n", "        ", "words", "=", "record", "[", "\"words\"", "]", "\n", "for", "word", "in", "words", ":", "\n", "          ", "word_counter", "[", "word", "]", "+=", "1", "\n", "# build word dict", "\n", "", "", "", "word_vocab", "=", "[", "PAD", ",", "UNK", ",", "NUM", "]", "+", "sorted", "(", "list", "(", "glove_vocab", ")", ")", "\n", "word_dict", "=", "dict", "(", "[", "(", "word", ",", "idx", ")", "for", "idx", ",", "word", "in", "enumerate", "(", "word_vocab", ")", "]", ")", "\n", "return", "word_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.preprocessors.base_preprocessors.Preprocessor.filter_glove_emb": [[100, 113], ["numpy.zeros", "codecs.open", "tqdm.tqdm.tqdm", "line.lstrip().rstrip().split.lstrip().rstrip().split.lstrip().rstrip().split", "len", "float", "numpy.asarray", "line.lstrip().rstrip().split.lstrip().rstrip().split.lstrip().rstrip", "line.lstrip().rstrip().split.lstrip().rstrip().split.lstrip"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "filter_glove_emb", "(", "word_dict", ",", "glove_path", ",", "glove_name", ",", "dim", ")", ":", "\n", "    ", "vectors", "=", "np", ".", "zeros", "(", "[", "len", "(", "word_dict", ")", "-", "3", ",", "dim", "]", ")", "\n", "with", "codecs", ".", "open", "(", "glove_path", ",", "mode", "=", "'r'", ",", "encoding", "=", "'utf-8'", ")", "as", "f", ":", "\n", "      ", "for", "line", "in", "tqdm", "(", "f", ",", "total", "=", "glove_sizes", "[", "glove_name", "]", ",", "\n", "desc", "=", "\"Filter glove embeddings\"", ")", ":", "\n", "        ", "line", "=", "line", ".", "lstrip", "(", ")", ".", "rstrip", "(", ")", ".", "split", "(", "\" \"", ")", "\n", "word", "=", "line", "[", "0", "]", "\n", "vector", "=", "[", "float", "(", "x", ")", "for", "x", "in", "line", "[", "1", ":", "]", "]", "\n", "if", "word", "in", "word_dict", ":", "\n", "          ", "word_idx", "=", "word_dict", "[", "word", "]", "-", "3", "\n", "vectors", "[", "word_idx", "]", "=", "np", ".", "asarray", "(", "vector", ")", "\n", "", "", "", "return", "vectors", "\n", "\n"]], "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.preprocessors.base_preprocessors.Preprocessor.build_tag_vocab": [[114, 117], ["None"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "build_tag_vocab", "(", "datasets", ")", ":", "\n", "    ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.preprocessors.base_preprocessors.Preprocessor.build_dataset": [[118, 121], ["None"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "build_dataset", "(", "data", ",", "word_dict", ",", "char_dict", ",", "tag_dict", ")", ":", "\n", "    ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.preprocessors.base_preprocessors.Preprocessor.preprocess": [[122, 124], ["None"], "methods", ["None"], ["", "def", "preprocess", "(", "self", ")", ":", "\n", "    ", "raise", "NotImplementedError", "\n", "", "", ""]], "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.preprocessors.knn_preprocessors.KnnPreprocessor.load_dataset": [[16, 31], ["utils.common.load_json", "utils.common.word_convert", "dataset.append", "dataset.append"], "methods", ["home.repos.pwc.inspect_result.hiroki13_instance-based-ner.scripts.retrieve_knn_sents_with_glove.load_json", "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.utils.common.word_convert"], ["  ", "def", "load_dataset", "(", "self", ",", "filename", ",", "keep_number", "=", "False", ",", "lowercase", "=", "True", ")", ":", "\n", "    ", "dataset", "=", "[", "]", "\n", "for", "record", "in", "load_json", "(", "filename", ")", ":", "\n", "      ", "words", "=", "[", "word_convert", "(", "word", ",", "keep_number", "=", "keep_number", ",", "lowercase", "=", "lowercase", ")", "\n", "for", "word", "in", "record", "[", "\"words\"", "]", "]", "\n", "if", "\"train_sent_ids\"", "in", "record", ":", "\n", "        ", "dataset", ".", "append", "(", "{", "\"sent_id\"", ":", "record", "[", "\"sent_id\"", "]", ",", "\n", "\"words\"", ":", "words", ",", "\n", "\"tags\"", ":", "record", "[", "\"spans\"", "]", ",", "\n", "\"train_sent_ids\"", ":", "record", "[", "\"train_sent_ids\"", "]", "}", ")", "\n", "", "else", ":", "\n", "        ", "dataset", ".", "append", "(", "{", "\"sent_id\"", ":", "record", "[", "\"sent_id\"", "]", ",", "\n", "\"words\"", ":", "words", ",", "\n", "\"tags\"", ":", "record", "[", "\"spans\"", "]", "}", ")", "\n", "", "", "return", "dataset", "\n", "\n"]], "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.preprocessors.knn_preprocessors.KnnPreprocessor.preprocess": [[32, 96], ["os.makedirs", "knn_preprocessors.KnnPreprocessor.load_dataset", "knn_preprocessors.KnnPreprocessor.load_dataset", "knn_preprocessors.KnnPreprocessor.build_tag_vocab", "knn_preprocessors.KnnPreprocessor.load_dataset", "knn_preprocessors.KnnPreprocessor.load_dataset", "knn_preprocessors.KnnPreprocessor.build_char_vocab", "knn_preprocessors.KnnPreprocessor.build_dataset", "knn_preprocessors.KnnPreprocessor.build_dataset", "print", "print", "utils.common.write_json", "utils.common.write_json", "utils.common.write_json", "os.path.join", "os.path.join", "knn_preprocessors.KnnPreprocessor.config[].format", "knn_preprocessors.KnnPreprocessor.load_glove_vocab", "knn_preprocessors.KnnPreprocessor.build_word_vocab_pretrained", "knn_preprocessors.KnnPreprocessor.filter_glove_emb", "numpy.savez_compressed", "knn_preprocessors.KnnPreprocessor.build_word_vocab", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "len", "len"], "methods", ["home.repos.pwc.inspect_result.hiroki13_instance-based-ner.preprocessors.span_preprocessors.SpanPreprocessor.load_dataset", "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.preprocessors.span_preprocessors.SpanPreprocessor.load_dataset", "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.preprocessors.span_preprocessors.SpanPreprocessor.build_tag_vocab", "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.preprocessors.span_preprocessors.SpanPreprocessor.load_dataset", "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.preprocessors.span_preprocessors.SpanPreprocessor.load_dataset", "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.preprocessors.base_preprocessors.Preprocessor.build_char_vocab", "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.preprocessors.span_preprocessors.SpanPreprocessor.build_dataset", "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.preprocessors.span_preprocessors.SpanPreprocessor.build_dataset", "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.scripts.retrieve_knn_sents_with_glove.write_json", "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.scripts.retrieve_knn_sents_with_glove.write_json", "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.scripts.retrieve_knn_sents_with_glove.write_json", "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.preprocessors.base_preprocessors.Preprocessor.load_glove_vocab", "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.preprocessors.base_preprocessors.Preprocessor.build_word_vocab_pretrained", "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.preprocessors.base_preprocessors.Preprocessor.filter_glove_emb", "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.preprocessors.base_preprocessors.Preprocessor.build_word_vocab"], ["", "def", "preprocess", "(", "self", ")", ":", "\n", "    ", "config", "=", "self", ".", "config", "\n", "os", ".", "makedirs", "(", "config", "[", "\"save_path\"", "]", ",", "exist_ok", "=", "True", ")", "\n", "\n", "# List[{'words': List[str], 'tags': List[str]}]", "\n", "train_data", "=", "self", ".", "load_dataset", "(", "\n", "os", ".", "path", ".", "join", "(", "config", "[", "\"raw_path\"", "]", ",", "\"train.json\"", ")", ",", "\n", "keep_number", "=", "False", ",", "\n", "lowercase", "=", "True", ")", "\n", "valid_data", "=", "self", ".", "load_dataset", "(", "\n", "os", ".", "path", ".", "join", "(", "config", "[", "\"raw_path\"", "]", ",", "\"valid.json\"", ")", ",", "\n", "keep_number", "=", "False", ",", "\n", "lowercase", "=", "True", ")", "\n", "train_data", "=", "train_data", "[", ":", "config", "[", "\"data_size\"", "]", "]", "\n", "valid_data", "=", "valid_data", "[", ":", "config", "[", "\"data_size\"", "]", "]", "\n", "\n", "# build vocabulary", "\n", "if", "config", "[", "\"use_pretrained\"", "]", ":", "\n", "      ", "glove_path", "=", "self", ".", "config", "[", "\"glove_path\"", "]", ".", "format", "(", "config", "[", "\"glove_name\"", "]", ",", "\n", "config", "[", "\"emb_dim\"", "]", ")", "\n", "glove_vocab", "=", "self", ".", "load_glove_vocab", "(", "glove_path", ",", "config", "[", "\"glove_name\"", "]", ")", "\n", "word_dict", "=", "self", ".", "build_word_vocab_pretrained", "(", "[", "train_data", ",", "valid_data", "]", ",", "\n", "glove_vocab", ")", "\n", "vectors", "=", "self", ".", "filter_glove_emb", "(", "word_dict", ",", "\n", "glove_path", ",", "\n", "config", "[", "\"glove_name\"", "]", ",", "\n", "config", "[", "\"emb_dim\"", "]", ")", "\n", "np", ".", "savez_compressed", "(", "config", "[", "\"pretrained_emb\"", "]", ",", "embeddings", "=", "vectors", ")", "\n", "", "else", ":", "\n", "      ", "word_dict", "=", "self", ".", "build_word_vocab", "(", "[", "train_data", ",", "valid_data", "]", ")", "\n", "\n", "# build tag dict", "\n", "", "tag_dict", "=", "self", ".", "build_tag_vocab", "(", "[", "train_data", ",", "valid_data", "]", ")", "\n", "\n", "# build char dict", "\n", "train_data", "=", "self", ".", "load_dataset", "(", "\n", "os", ".", "path", ".", "join", "(", "config", "[", "\"raw_path\"", "]", ",", "\"train.json\"", ")", ",", "\n", "keep_number", "=", "True", ",", "\n", "lowercase", "=", "config", "[", "\"char_lowercase\"", "]", ")", "\n", "valid_data", "=", "self", ".", "load_dataset", "(", "\n", "os", ".", "path", ".", "join", "(", "config", "[", "\"raw_path\"", "]", ",", "\"valid.json\"", ")", ",", "\n", "keep_number", "=", "True", ",", "\n", "lowercase", "=", "config", "[", "\"char_lowercase\"", "]", ")", "\n", "\n", "train_data", "=", "train_data", "[", ":", "config", "[", "\"data_size\"", "]", "]", "\n", "valid_data", "=", "valid_data", "[", ":", "config", "[", "\"data_size\"", "]", "]", "\n", "\n", "char_dict", "=", "self", ".", "build_char_vocab", "(", "[", "train_data", "]", ")", "\n", "\n", "# create indices dataset", "\n", "# List[{'words': List[str], 'chars': List[List[str]], 'tags': List[str]}]", "\n", "train_set", "=", "self", ".", "build_dataset", "(", "train_data", ",", "word_dict", ",", "char_dict", ",", "tag_dict", ")", "\n", "valid_set", "=", "self", ".", "build_dataset", "(", "valid_data", ",", "word_dict", ",", "char_dict", ",", "tag_dict", ")", "\n", "vocab", "=", "{", "\"word_dict\"", ":", "word_dict", ",", "\n", "\"char_dict\"", ":", "char_dict", ",", "\n", "\"tag_dict\"", ":", "tag_dict", "}", "\n", "\n", "print", "(", "\"Train Sents: %d\"", "%", "len", "(", "train_set", ")", ")", "\n", "print", "(", "\"Valid Sents: %d\"", "%", "len", "(", "valid_set", ")", ")", "\n", "\n", "# write to file", "\n", "write_json", "(", "os", ".", "path", ".", "join", "(", "config", "[", "\"save_path\"", "]", ",", "\"vocab.json\"", ")", ",", "vocab", ")", "\n", "write_json", "(", "os", ".", "path", ".", "join", "(", "config", "[", "\"save_path\"", "]", ",", "\"train.json\"", ")", ",", "train_set", ")", "\n", "write_json", "(", "os", ".", "path", ".", "join", "(", "config", "[", "\"save_path\"", "]", ",", "\"valid.json\"", ")", ",", "valid_set", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.preprocessors.span_preprocessors.SpanPreprocessor.load_dataset": [[17, 26], ["utils.common.load_json", "dataset.append", "utils.common.word_convert"], "methods", ["home.repos.pwc.inspect_result.hiroki13_instance-based-ner.scripts.retrieve_knn_sents_with_glove.load_json", "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.utils.common.word_convert"], ["  ", "def", "load_dataset", "(", "self", ",", "filename", ",", "keep_number", "=", "False", ",", "lowercase", "=", "True", ")", ":", "\n", "    ", "dataset", "=", "[", "]", "\n", "for", "record", "in", "load_json", "(", "filename", ")", ":", "\n", "      ", "words", "=", "[", "word_convert", "(", "word", ",", "keep_number", "=", "keep_number", ",", "lowercase", "=", "lowercase", ")", "\n", "for", "word", "in", "record", "[", "\"words\"", "]", "]", "\n", "dataset", ".", "append", "(", "{", "\"sent_id\"", ":", "record", "[", "\"sent_id\"", "]", ",", "\n", "\"words\"", ":", "words", ",", "\n", "\"tags\"", ":", "record", "[", "\"spans\"", "]", "}", ")", "\n", "", "return", "dataset", "\n", "\n"]], "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.preprocessors.span_preprocessors.SpanPreprocessor.build_tag_vocab": [[27, 37], ["collections.Counter", "dict", "collections.Counter.most_common", "enumerate"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "build_tag_vocab", "(", "datasets", ")", ":", "\n", "    ", "tag_counter", "=", "Counter", "(", ")", "\n", "for", "dataset", "in", "datasets", ":", "\n", "      ", "for", "record", "in", "dataset", ":", "\n", "        ", "for", "(", "tag", ",", "_", ",", "_", ")", "in", "record", "[", "\"tags\"", "]", ":", "\n", "          ", "tag_counter", "[", "tag", "]", "+=", "1", "\n", "", "", "", "tag_vocab", "=", "[", "\"O\"", "]", "+", "[", "tag", "for", "tag", ",", "_", "in", "tag_counter", ".", "most_common", "(", ")", "]", "\n", "tag_dict", "=", "dict", "(", "[", "(", "ner", ",", "idx", ")", "for", "idx", ",", "ner", "in", "enumerate", "(", "tag_vocab", ")", "]", ")", "\n", "return", "tag_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.preprocessors.span_preprocessors.SpanPreprocessor.build_dataset": [[38, 53], ["dataset.append", "chars_list.append", "utils.common.word_convert", "words.append"], "methods", ["home.repos.pwc.inspect_result.hiroki13_instance-based-ner.utils.common.word_convert"], ["", "@", "staticmethod", "\n", "def", "build_dataset", "(", "data", ",", "word_dict", ",", "char_dict", ",", "tag_dict", ")", ":", "\n", "    ", "dataset", "=", "[", "]", "\n", "for", "record", "in", "data", ":", "\n", "      ", "chars_list", "=", "[", "]", "\n", "words", "=", "[", "]", "\n", "for", "word", "in", "record", "[", "\"words\"", "]", ":", "\n", "        ", "chars", "=", "[", "char_dict", "[", "char", "]", "if", "char", "in", "char_dict", "else", "char_dict", "[", "UNK", "]", "for", "\n", "char", "in", "word", "]", "\n", "chars_list", ".", "append", "(", "chars", ")", "\n", "word", "=", "word_convert", "(", "word", ",", "keep_number", "=", "False", ",", "lowercase", "=", "True", ")", "\n", "words", ".", "append", "(", "word_dict", "[", "word", "]", "if", "word", "in", "word_dict", "else", "word_dict", "[", "UNK", "]", ")", "\n", "", "tags", "=", "[", "(", "tag_dict", "[", "tag", "]", ",", "i", ",", "j", ")", "for", "(", "tag", ",", "i", ",", "j", ")", "in", "record", "[", "\"tags\"", "]", "]", "\n", "dataset", ".", "append", "(", "{", "\"words\"", ":", "words", ",", "\"chars\"", ":", "chars_list", ",", "\"tags\"", ":", "tags", "}", ")", "\n", "", "return", "dataset", "\n", "\n"]], "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.preprocessors.span_preprocessors.SpanPreprocessor.preprocess": [[54, 125], ["os.makedirs", "span_preprocessors.SpanPreprocessor.load_dataset", "span_preprocessors.SpanPreprocessor.load_dataset", "span_preprocessors.SpanPreprocessor.build_tag_vocab", "span_preprocessors.SpanPreprocessor.load_dataset", "span_preprocessors.SpanPreprocessor.load_dataset", "span_preprocessors.SpanPreprocessor.build_char_vocab", "span_preprocessors.SpanPreprocessor.build_dataset", "span_preprocessors.SpanPreprocessor.build_dataset", "print", "print", "utils.common.write_json", "utils.common.write_json", "utils.common.write_json", "os.path.join", "os.path.join", "span_preprocessors.SpanPreprocessor.config[].format", "span_preprocessors.SpanPreprocessor.load_glove_vocab", "span_preprocessors.SpanPreprocessor.build_word_vocab_pretrained", "span_preprocessors.SpanPreprocessor.filter_glove_emb", "numpy.savez_compressed", "span_preprocessors.SpanPreprocessor.build_word_vocab", "os.path.join", "os.path.join", "print", "os.path.join", "os.path.join", "os.path.join", "len", "len", "len", "len"], "methods", ["home.repos.pwc.inspect_result.hiroki13_instance-based-ner.preprocessors.span_preprocessors.SpanPreprocessor.load_dataset", "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.preprocessors.span_preprocessors.SpanPreprocessor.load_dataset", "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.preprocessors.span_preprocessors.SpanPreprocessor.build_tag_vocab", "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.preprocessors.span_preprocessors.SpanPreprocessor.load_dataset", "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.preprocessors.span_preprocessors.SpanPreprocessor.load_dataset", "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.preprocessors.base_preprocessors.Preprocessor.build_char_vocab", "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.preprocessors.span_preprocessors.SpanPreprocessor.build_dataset", "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.preprocessors.span_preprocessors.SpanPreprocessor.build_dataset", "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.scripts.retrieve_knn_sents_with_glove.write_json", "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.scripts.retrieve_knn_sents_with_glove.write_json", "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.scripts.retrieve_knn_sents_with_glove.write_json", "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.preprocessors.base_preprocessors.Preprocessor.load_glove_vocab", "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.preprocessors.base_preprocessors.Preprocessor.build_word_vocab_pretrained", "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.preprocessors.base_preprocessors.Preprocessor.filter_glove_emb", "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.preprocessors.base_preprocessors.Preprocessor.build_word_vocab"], ["", "def", "preprocess", "(", "self", ")", ":", "\n", "    ", "config", "=", "self", ".", "config", "\n", "os", ".", "makedirs", "(", "config", "[", "\"save_path\"", "]", ",", "exist_ok", "=", "True", ")", "\n", "\n", "# List[{'words': List[str], 'tags': List[str]}]", "\n", "train_data", "=", "self", ".", "load_dataset", "(", "\n", "os", ".", "path", ".", "join", "(", "config", "[", "\"raw_path\"", "]", ",", "\"train.json\"", ")", ",", "\n", "keep_number", "=", "False", ",", "\n", "lowercase", "=", "True", ")", "\n", "valid_data", "=", "self", ".", "load_dataset", "(", "\n", "os", ".", "path", ".", "join", "(", "config", "[", "\"raw_path\"", "]", ",", "\"valid.json\"", ")", ",", "\n", "keep_number", "=", "False", ",", "\n", "lowercase", "=", "True", ")", "\n", "train_data", "=", "train_data", "[", ":", "config", "[", "\"data_size\"", "]", "]", "\n", "valid_data", "=", "valid_data", "[", ":", "config", "[", "\"data_size\"", "]", "]", "\n", "\n", "# build vocabulary", "\n", "if", "config", "[", "\"use_pretrained\"", "]", ":", "\n", "      ", "glove_path", "=", "self", ".", "config", "[", "\"glove_path\"", "]", ".", "format", "(", "config", "[", "\"glove_name\"", "]", ",", "\n", "config", "[", "\"emb_dim\"", "]", ")", "\n", "glove_vocab", "=", "self", ".", "load_glove_vocab", "(", "glove_path", ",", "config", "[", "\"glove_name\"", "]", ")", "\n", "word_dict", "=", "self", ".", "build_word_vocab_pretrained", "(", "[", "train_data", ",", "valid_data", "]", ",", "\n", "glove_vocab", ")", "\n", "vectors", "=", "self", ".", "filter_glove_emb", "(", "word_dict", ",", "\n", "glove_path", ",", "\n", "config", "[", "\"glove_name\"", "]", ",", "\n", "config", "[", "\"emb_dim\"", "]", ")", "\n", "np", ".", "savez_compressed", "(", "config", "[", "\"pretrained_emb\"", "]", ",", "embeddings", "=", "vectors", ")", "\n", "", "else", ":", "\n", "      ", "word_dict", "=", "self", ".", "build_word_vocab", "(", "[", "train_data", ",", "valid_data", "]", ")", "\n", "\n", "# build tag dict", "\n", "", "tag_dict", "=", "self", ".", "build_tag_vocab", "(", "[", "train_data", ",", "valid_data", "]", ")", "\n", "\n", "# build char dict", "\n", "train_data", "=", "self", ".", "load_dataset", "(", "\n", "os", ".", "path", ".", "join", "(", "config", "[", "\"raw_path\"", "]", ",", "\"train.json\"", ")", ",", "\n", "keep_number", "=", "True", ",", "\n", "lowercase", "=", "config", "[", "\"char_lowercase\"", "]", ")", "\n", "valid_data", "=", "self", ".", "load_dataset", "(", "\n", "os", ".", "path", ".", "join", "(", "config", "[", "\"raw_path\"", "]", ",", "\"valid.json\"", ")", ",", "\n", "keep_number", "=", "True", ",", "\n", "lowercase", "=", "config", "[", "\"char_lowercase\"", "]", ")", "\n", "\n", "train_data", "=", "train_data", "[", ":", "config", "[", "\"data_size\"", "]", "]", "\n", "valid_data", "=", "valid_data", "[", ":", "config", "[", "\"data_size\"", "]", "]", "\n", "\n", "if", "config", "[", "\"max_sent_len\"", "]", ">", "0", ":", "\n", "      ", "train_data", "=", "[", "record", "for", "record", "in", "train_data", "\n", "if", "len", "(", "record", "[", "\"words\"", "]", ")", "<=", "config", "[", "\"max_sent_len\"", "]", "]", "\n", "print", "(", "\n", "\"Train Sents (remove max_sent_len: %d): %d\"", "%", "(", "config", "[", "\"max_sent_len\"", "]", ",", "\n", "len", "(", "train_data", ")", ")", ")", "\n", "\n", "", "char_dict", "=", "self", ".", "build_char_vocab", "(", "[", "train_data", "]", ")", "\n", "\n", "# create indices dataset", "\n", "# List[{'words': List[str], 'chars': List[List[str]], 'tags': List[str]}]", "\n", "train_set", "=", "self", ".", "build_dataset", "(", "train_data", ",", "word_dict", ",", "char_dict", ",", "tag_dict", ")", "\n", "valid_set", "=", "self", ".", "build_dataset", "(", "valid_data", ",", "word_dict", ",", "char_dict", ",", "tag_dict", ")", "\n", "vocab", "=", "{", "\"word_dict\"", ":", "word_dict", ",", "\n", "\"char_dict\"", ":", "char_dict", ",", "\n", "\"tag_dict\"", ":", "tag_dict", "}", "\n", "\n", "print", "(", "\"Train Sents: %d\"", "%", "len", "(", "train_set", ")", ")", "\n", "print", "(", "\"Valid Sents: %d\"", "%", "len", "(", "valid_set", ")", ")", "\n", "\n", "# write to file", "\n", "write_json", "(", "os", ".", "path", ".", "join", "(", "config", "[", "\"save_path\"", "]", ",", "\"vocab.json\"", ")", ",", "vocab", ")", "\n", "write_json", "(", "os", ".", "path", ".", "join", "(", "config", "[", "\"save_path\"", "]", ",", "\"train.json\"", ")", ",", "train_set", ")", "\n", "write_json", "(", "os", ".", "path", ".", "join", "(", "config", "[", "\"save_path\"", "]", ",", "\"valid.json\"", ")", ",", "valid_set", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.batchers.knn_batchers.KnnBatcher.make_each_batch_for_targets": [[17, 19], ["None"], "methods", ["None"], ["  ", "def", "make_each_batch_for_targets", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "    ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.batchers.knn_batchers.KnnBatcher.make_each_batch_for_neighbors": [[20, 22], ["None"], "methods", ["None"], ["", "def", "make_each_batch_for_neighbors", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "    ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.batchers.knn_batchers.KnnBatcher.batchnize_neighbor_train_sents": [[23, 25], ["None"], "methods", ["None"], ["", "def", "batchnize_neighbor_train_sents", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "    ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.batchers.knn_batchers.KnnBatcher.make_batch_from_sent_ids": [[26, 28], ["None"], "methods", ["None"], ["", "def", "make_batch_from_sent_ids", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "    ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.batchers.knn_batchers.KnnBatcher.batchnize_span_reps_and_tags": [[29, 48], ["zip", "zip", "rep_list.append", "tag_list.append"], "methods", ["None"], ["", "def", "batchnize_span_reps_and_tags", "(", "self", ",", "train_batch_reps", ",", "train_batch_tags", ",", "\n", "train_batch_masks", ")", ":", "\n", "    ", "\"\"\"\n    :param train_batch_reps: 1D: num_sents, 2D: max_num_spans, 3D: dim\n    :param train_batch_tags: 1D: num_sents, 2D: max_num_spans\n    :param train_batch_masks: 1D: num_sents, 2D: max_num_spans\n    :return: batch_span_rep_list: 1D: num_instances, 2D: dim\n    :return: batch_tag_one_hot_list: 1D: num_instances, 2D: num_tags\n    \"\"\"", "\n", "rep_list", "=", "[", "]", "\n", "tag_list", "=", "[", "]", "\n", "for", "reps", ",", "tags", ",", "masks", "in", "zip", "(", "train_batch_reps", ",", "\n", "train_batch_tags", ",", "\n", "train_batch_masks", ")", ":", "\n", "      ", "for", "rep", ",", "tag", ",", "mask", "in", "zip", "(", "reps", ",", "tags", ",", "masks", ")", ":", "\n", "        ", "if", "mask", ":", "\n", "          ", "rep_list", ".", "append", "(", "rep", ")", "\n", "tag_list", ".", "append", "(", "tag", ")", "\n", "", "", "", "return", "rep_list", ",", "tag_list", "\n", "\n"]], "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.batchers.knn_batchers.KnnBatcher.batchnize_span_reps_and_tag_one_hots": [[49, 77], ["zip", "numpy.zeros", "enumerate", "zip", "rep_list.append", "tag_list.append", "len"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "batchnize_span_reps_and_tag_one_hots", "(", "train_batch_reps", ",", "\n", "train_batch_tags", ",", "\n", "train_batch_masks", ",", "\n", "num_tags", ")", ":", "\n", "    ", "\"\"\"\n    :param train_batch_reps: 1D: num_sents, 2D: max_num_spans, 3D: dim\n    :param train_batch_tags: 1D: num_sents, 2D: max_num_spans\n    :param train_batch_masks: 1D: num_sents, 2D: max_num_spans\n    :param num_tags; the number of possible tags\n    :return: batch_span_rep_list: 1D: num_instances, 2D: dim\n    :return: batch_tag_one_hot_list: 1D: num_instances, 2D: num_tags\n    \"\"\"", "\n", "rep_list", "=", "[", "]", "\n", "tag_list", "=", "[", "]", "\n", "for", "reps", ",", "tags", ",", "masks", "in", "zip", "(", "train_batch_reps", ",", "\n", "train_batch_tags", ",", "\n", "train_batch_masks", ")", ":", "\n", "      ", "for", "rep", ",", "tag", ",", "mask", "in", "zip", "(", "reps", ",", "tags", ",", "masks", ")", ":", "\n", "        ", "if", "mask", ":", "\n", "          ", "rep_list", ".", "append", "(", "rep", ")", "\n", "tag_list", ".", "append", "(", "tag", ")", "\n", "\n", "", "", "", "tag_one_hot_list", "=", "np", ".", "zeros", "(", "shape", "=", "(", "len", "(", "tag_list", ")", ",", "num_tags", ")", ")", "\n", "for", "i", ",", "tag_id", "in", "enumerate", "(", "tag_list", ")", ":", "\n", "      ", "tag_one_hot_list", "[", "i", "]", "[", "tag_id", "]", "=", "1", "\n", "\n", "", "return", "rep_list", ",", "tag_one_hot_list", "\n", "\n"]], "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.batchers.knn_batchers.BaseKnnBatcher.make_each_batch_for_targets": [[81, 100], ["knn_batchers.BaseKnnBatcher.pad_sequences", "knn_batchers.BaseKnnBatcher.pad_char_sequences", "knn_batchers.BaseKnnBatcher._make_span_indices", "knn_batchers.BaseKnnBatcher._make_tag_sequences"], "methods", ["home.repos.pwc.inspect_result.hiroki13_instance-based-ner.batchers.base_batchers.Batcher.pad_sequences", "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.batchers.base_batchers.Batcher.pad_char_sequences", "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.models.span_models.SpanModel._make_span_indices", "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.batchers.span_batchers.SpanBatcher._make_tag_sequences"], ["  ", "def", "make_each_batch_for_targets", "(", "self", ",", "batch_words", ",", "batch_chars", ",", "batch_ids", ",", "\n", "max_span_len", ",", "max_n_spans", ",", "batch_tags", "=", "None", ")", ":", "\n", "    ", "b_words", ",", "b_words_len", "=", "self", ".", "pad_sequences", "(", "batch_words", ")", "\n", "b_chars", ",", "_", "=", "self", ".", "pad_char_sequences", "(", "batch_chars", ",", "max_token_length", "=", "20", ")", "\n", "batch", "=", "{", "\"words\"", ":", "b_words", ",", "\n", "\"chars\"", ":", "b_chars", ",", "\n", "\"seq_len\"", ":", "b_words_len", ",", "\n", "\"instance_ids\"", ":", "batch_ids", "}", "\n", "n_words", "=", "b_words_len", "[", "0", "]", "\n", "span_indices", "=", "self", ".", "_make_span_indices", "(", "n_words", "=", "n_words", ",", "\n", "max_span_len", "=", "max_span_len", ",", "\n", "max_n_spans", "=", "max_n_spans", ")", "\n", "if", "max_n_spans", ":", "\n", "      ", "batch", "[", "\"span_indices\"", "]", "=", "span_indices", "\n", "", "if", "batch_tags", "is", "not", "None", ":", "\n", "      ", "batch", "[", "\"tags\"", "]", "=", "self", ".", "_make_tag_sequences", "(", "batch_triples", "=", "batch_tags", ",", "\n", "indices", "=", "span_indices", ",", "\n", "n_words", "=", "n_words", ")", "\n", "", "return", "batch", "\n", "\n"]], "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.batchers.knn_batchers.BaseKnnBatcher.make_each_batch_for_neighbors": [[101, 124], ["knn_batchers.BaseKnnBatcher.pad_sequences", "knn_batchers.BaseKnnBatcher.pad_char_sequences", "max", "knn_batchers.BaseKnnBatcher._make_span_indices", "knn_batchers.BaseKnnBatcher._make_masks", "knn_batchers.BaseKnnBatcher._make_tag_sequences"], "methods", ["home.repos.pwc.inspect_result.hiroki13_instance-based-ner.batchers.base_batchers.Batcher.pad_sequences", "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.batchers.base_batchers.Batcher.pad_char_sequences", "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.models.span_models.SpanModel._make_span_indices", "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.batchers.span_batchers.MaskSpanBatcher._make_masks", "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.batchers.span_batchers.SpanBatcher._make_tag_sequences"], ["", "def", "make_each_batch_for_neighbors", "(", "self", ",", "batch_words", ",", "batch_chars", ",", "\n", "max_span_len", ",", "max_n_spans", ",", "\n", "batch_tags", "=", "None", ")", ":", "\n", "    ", "b_words", ",", "b_words_len", "=", "self", ".", "pad_sequences", "(", "batch_words", ")", "\n", "b_chars", ",", "_", "=", "self", ".", "pad_char_sequences", "(", "batch_chars", ",", "max_token_length", "=", "20", ")", "\n", "max_n_words", "=", "max", "(", "b_words_len", ")", "\n", "span_indices", "=", "self", ".", "_make_span_indices", "(", "n_words", "=", "max_n_words", ",", "\n", "max_span_len", "=", "max_span_len", ",", "\n", "max_n_spans", "=", "max_n_spans", ")", "\n", "b_masks", "=", "self", ".", "_make_masks", "(", "lengths", "=", "b_words_len", ",", "\n", "indices", "=", "span_indices", ",", "\n", "max_n_words", "=", "max_n_words", ")", "\n", "batch", "=", "{", "\"words\"", ":", "b_words", ",", "\n", "\"chars\"", ":", "b_chars", ",", "\n", "\"seq_len\"", ":", "b_words_len", ",", "\n", "\"masks\"", ":", "b_masks", "}", "\n", "if", "max_n_spans", ":", "\n", "      ", "batch", "[", "\"span_indices\"", "]", "=", "span_indices", "\n", "", "if", "batch_tags", "is", "not", "None", ":", "\n", "      ", "batch", "[", "\"tags\"", "]", "=", "self", ".", "_make_tag_sequences", "(", "batch_triples", "=", "batch_tags", ",", "\n", "indices", "=", "span_indices", ",", "\n", "n_words", "=", "max_n_words", ")", "\n", "", "return", "batch", "\n", "\n"]], "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.batchers.knn_batchers.BaseKnnBatcher.batchnize_dataset": [[125, 177], ["utils.common.load_json", "enumerate", "len", "random.shuffle", "utils.common.load_json.sort", "len", "batch_words.append", "batch_chars.append", "batch_tags.append", "batch_ids.append", "len", "batches.append", "random.shuffle", "batches.append", "knn_batchers.BaseKnnBatcher.make_each_batch_for_targets", "len", "knn_batchers.BaseKnnBatcher.make_each_batch_for_targets", "len"], "methods", ["home.repos.pwc.inspect_result.hiroki13_instance-based-ner.scripts.retrieve_knn_sents_with_glove.load_json", "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.batchers.knn_batchers.BaseKnnBatcher.make_each_batch_for_targets", "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.batchers.knn_batchers.BaseKnnBatcher.make_each_batch_for_targets"], ["", "def", "batchnize_dataset", "(", "self", ",", "data", ",", "data_name", "=", "None", ",", "batch_size", "=", "None", ",", "\n", "shuffle", "=", "True", ")", ":", "\n", "    ", "max_span_len", "=", "self", ".", "config", "[", "\"max_span_len\"", "]", "\n", "if", "data_name", "==", "\"train\"", ":", "\n", "      ", "max_n_spans", "=", "self", ".", "config", "[", "\"max_n_spans\"", "]", "\n", "", "else", ":", "\n", "      ", "if", "self", ".", "config", "[", "\"max_n_spans\"", "]", ">", "0", ":", "\n", "        ", "max_n_spans", "=", "1000000", "\n", "", "else", ":", "\n", "        ", "max_n_spans", "=", "0", "\n", "\n", "", "", "dataset", "=", "load_json", "(", "data", ")", "\n", "for", "instance_id", ",", "record", "in", "enumerate", "(", "dataset", ")", ":", "\n", "      ", "record", "[", "\"instance_id\"", "]", "=", "instance_id", "\n", "\n", "", "if", "shuffle", ":", "\n", "      ", "random", ".", "shuffle", "(", "dataset", ")", "\n", "dataset", ".", "sort", "(", "key", "=", "lambda", "record", ":", "len", "(", "record", "[", "\"words\"", "]", ")", ")", "\n", "\n", "", "batches", "=", "[", "]", "\n", "batch_words", ",", "batch_chars", ",", "batch_tags", ",", "batch_ids", "=", "[", "]", ",", "[", "]", ",", "[", "]", ",", "[", "]", "\n", "prev_seq_len", "=", "len", "(", "dataset", "[", "0", "]", "[", "\"words\"", "]", ")", "\n", "\n", "for", "record", "in", "dataset", ":", "\n", "      ", "seq_len", "=", "len", "(", "record", "[", "\"words\"", "]", ")", "\n", "\n", "if", "len", "(", "batch_words", ")", "==", "batch_size", "or", "prev_seq_len", "!=", "seq_len", ":", "\n", "        ", "batches", ".", "append", "(", "self", ".", "make_each_batch_for_targets", "(", "batch_words", ",", "\n", "batch_chars", ",", "\n", "batch_ids", ",", "\n", "max_span_len", ",", "\n", "max_n_spans", ",", "\n", "batch_tags", ")", ")", "\n", "batch_words", ",", "batch_chars", ",", "batch_tags", ",", "batch_ids", "=", "[", "]", ",", "[", "]", ",", "[", "]", ",", "[", "]", "\n", "prev_seq_len", "=", "seq_len", "\n", "\n", "", "batch_words", ".", "append", "(", "record", "[", "\"words\"", "]", ")", "\n", "batch_chars", ".", "append", "(", "record", "[", "\"chars\"", "]", ")", "\n", "batch_tags", ".", "append", "(", "record", "[", "\"tags\"", "]", ")", "\n", "batch_ids", ".", "append", "(", "record", "[", "\"instance_id\"", "]", ")", "\n", "\n", "", "if", "len", "(", "batch_words", ")", ">", "0", ":", "\n", "      ", "batches", ".", "append", "(", "self", ".", "make_each_batch_for_targets", "(", "batch_words", ",", "\n", "batch_chars", ",", "\n", "batch_ids", ",", "\n", "max_span_len", ",", "\n", "max_n_spans", ",", "\n", "batch_tags", ")", ")", "\n", "", "if", "shuffle", ":", "\n", "      ", "random", ".", "shuffle", "(", "batches", ")", "\n", "", "for", "batch", "in", "batches", ":", "\n", "      ", "yield", "batch", "\n", "\n"]], "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.batchers.knn_batchers.BaseKnnBatcher.batchnize_neighbor_train_sents": [[178, 190], ["knn_batchers.BaseKnnBatcher.make_each_batch_for_neighbors", "batch_words.append", "batch_chars.append", "batch_tags.append"], "methods", ["home.repos.pwc.inspect_result.hiroki13_instance-based-ner.batchers.knn_batchers.BaseKnnBatcher.make_each_batch_for_neighbors"], ["", "", "def", "batchnize_neighbor_train_sents", "(", "self", ",", "train_sents", ",", "train_sent_ids", ",", "\n", "max_span_len", ",", "max_n_spans", ")", ":", "\n", "    ", "batch_words", ",", "batch_chars", ",", "batch_tags", "=", "[", "]", ",", "[", "]", ",", "[", "]", "\n", "for", "sent_id", "in", "train_sent_ids", ":", "\n", "      ", "batch_words", ".", "append", "(", "train_sents", "[", "sent_id", "]", "[", "\"words\"", "]", ")", "\n", "batch_chars", ".", "append", "(", "train_sents", "[", "sent_id", "]", "[", "\"chars\"", "]", ")", "\n", "batch_tags", ".", "append", "(", "train_sents", "[", "sent_id", "]", "[", "\"tags\"", "]", ")", "\n", "", "return", "self", ".", "make_each_batch_for_neighbors", "(", "batch_words", ",", "\n", "batch_chars", ",", "\n", "max_span_len", ",", "\n", "max_n_spans", ",", "\n", "batch_tags", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.batchers.knn_batchers.BaseKnnBatcher.make_batch_from_sent_ids": [[191, 203], ["knn_batchers.BaseKnnBatcher.make_each_batch_for_neighbors", "batch_words.append", "batch_chars.append", "batch_tags.append"], "methods", ["home.repos.pwc.inspect_result.hiroki13_instance-based-ner.batchers.knn_batchers.BaseKnnBatcher.make_each_batch_for_neighbors"], ["", "def", "make_batch_from_sent_ids", "(", "self", ",", "train_sents", ",", "sent_ids", ")", ":", "\n", "    ", "batch_words", ",", "batch_chars", ",", "batch_tags", "=", "[", "]", ",", "[", "]", ",", "[", "]", "\n", "max_n_spans", "=", "0", "\n", "for", "sent_id", "in", "sent_ids", ":", "\n", "      ", "batch_words", ".", "append", "(", "train_sents", "[", "sent_id", "]", "[", "\"words\"", "]", ")", "\n", "batch_chars", ".", "append", "(", "train_sents", "[", "sent_id", "]", "[", "\"chars\"", "]", ")", "\n", "batch_tags", ".", "append", "(", "train_sents", "[", "sent_id", "]", "[", "\"tags\"", "]", ")", "\n", "", "return", "self", ".", "make_each_batch_for_neighbors", "(", "batch_words", ",", "\n", "batch_chars", ",", "\n", "self", ".", "config", "[", "\"max_span_len\"", "]", ",", "\n", "max_n_spans", ",", "\n", "batch_tags", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.batchers.base_batchers.Batcher.__init__": [[10, 12], ["None"], "methods", ["None"], ["  ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "    ", "self", ".", "config", "=", "config", "\n", "\n"]], "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.batchers.base_batchers.Batcher.pad_sequences": [[13, 26], ["max", "sequence_padded.append", "sequence_length.append", "min", "len", "max", "len", "len"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "pad_sequences", "(", "sequences", ",", "pad_tok", "=", "None", ",", "max_length", "=", "None", ")", ":", "\n", "    ", "if", "pad_tok", "is", "None", ":", "\n", "# 0: \"PAD\" for words and chars, \"O\" for tags", "\n", "      ", "pad_tok", "=", "0", "\n", "", "if", "max_length", "is", "None", ":", "\n", "      ", "max_length", "=", "max", "(", "[", "len", "(", "seq", ")", "for", "seq", "in", "sequences", "]", ")", "\n", "", "sequence_padded", ",", "sequence_length", "=", "[", "]", ",", "[", "]", "\n", "for", "seq", "in", "sequences", ":", "\n", "      ", "seq_", "=", "seq", "[", ":", "max_length", "]", "+", "[", "pad_tok", "]", "*", "max", "(", "max_length", "-", "len", "(", "seq", ")", ",", "0", ")", "\n", "sequence_padded", ".", "append", "(", "seq_", ")", "\n", "sequence_length", ".", "append", "(", "min", "(", "len", "(", "seq", ")", ",", "max_length", ")", ")", "\n", "", "return", "sequence_padded", ",", "sequence_length", "\n", "\n"]], "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.batchers.base_batchers.Batcher.pad_char_sequences": [[27, 45], ["base_batchers.Batcher.pad_sequences", "base_batchers.Batcher.pad_sequences", "max", "max", "base_batchers.Batcher.pad_sequences", "sequence_padded.append", "sequence_length.append", "map", "max", "len", "map", "len"], "methods", ["home.repos.pwc.inspect_result.hiroki13_instance-based-ner.batchers.base_batchers.Batcher.pad_sequences", "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.batchers.base_batchers.Batcher.pad_sequences", "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.batchers.base_batchers.Batcher.pad_sequences"], ["", "def", "pad_char_sequences", "(", "self", ",", "sequences", ",", "max_length", "=", "None", ",", "\n", "max_token_length", "=", "None", ")", ":", "\n", "    ", "sequence_padded", ",", "sequence_length", "=", "[", "]", ",", "[", "]", "\n", "if", "max_length", "is", "None", ":", "\n", "      ", "max_length", "=", "max", "(", "map", "(", "lambda", "x", ":", "len", "(", "x", ")", ",", "sequences", ")", ")", "\n", "", "if", "max_token_length", "is", "None", ":", "\n", "      ", "max_token_length", "=", "max", "(", "\n", "[", "max", "(", "map", "(", "lambda", "x", ":", "len", "(", "x", ")", ",", "seq", ")", ")", "for", "seq", "in", "sequences", "]", ")", "\n", "", "for", "seq", "in", "sequences", ":", "\n", "      ", "sp", ",", "sl", "=", "self", ".", "pad_sequences", "(", "seq", ",", "max_length", "=", "max_token_length", ")", "\n", "sequence_padded", ".", "append", "(", "sp", ")", "\n", "sequence_length", ".", "append", "(", "sl", ")", "\n", "", "sequence_padded", ",", "_", "=", "self", ".", "pad_sequences", "(", "sequence_padded", ",", "\n", "pad_tok", "=", "[", "0", "]", "*", "max_token_length", ",", "\n", "max_length", "=", "max_length", ")", "\n", "sequence_length", ",", "_", "=", "self", ".", "pad_sequences", "(", "sequence_length", ",", "\n", "max_length", "=", "max_length", ")", "\n", "return", "sequence_padded", ",", "sequence_length", "\n", "\n"]], "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.batchers.base_batchers.Batcher.make_each_batch": [[46, 48], ["None"], "methods", ["None"], ["", "def", "make_each_batch", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "    ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.batchers.base_batchers.Batcher.batchnize_dataset": [[49, 51], ["None"], "methods", ["None"], ["", "def", "batchnize_dataset", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "    ", "raise", "NotImplementedError", "\n", "", "", ""]], "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.batchers.span_batchers.SpanBatcher._make_span_indices": [[17, 29], ["numpy.triu", "numpy.triu", "numpy.nonzero", "numpy.ones", "numpy.ones", "random.shuffle", "numpy.asarray", "list", "zip", "zip"], "methods", ["None"], ["  ", "@", "staticmethod", "\n", "def", "_make_span_indices", "(", "n_words", ",", "max_span_len", ",", "max_n_spans", "=", "0", ")", ":", "\n", "    ", "indices", "=", "np", ".", "triu", "(", "np", ".", "ones", "(", "shape", "=", "(", "n_words", ",", "n_words", ")", ",", "dtype", "=", "'int32'", ")", ")", "\n", "mask", "=", "np", ".", "triu", "(", "np", ".", "ones", "(", "shape", "=", "(", "n_words", ",", "n_words", ")", ",", "dtype", "=", "'int32'", ")", ",", "\n", "k", "=", "max_span_len", ")", "\n", "indices", "=", "np", ".", "nonzero", "(", "indices", "-", "mask", ")", "\n", "\n", "if", "max_n_spans", ">", "0", ":", "\n", "      ", "indices", "=", "[", "(", "i", ",", "j", ")", "for", "i", ",", "j", "in", "zip", "(", "*", "indices", ")", "]", "\n", "random", ".", "shuffle", "(", "indices", ")", "\n", "return", "np", ".", "asarray", "(", "list", "(", "zip", "(", "*", "indices", "[", ":", "max_n_spans", "]", ")", ")", ",", "dtype", "=", "'int32'", ")", "\n", "", "return", "indices", "\n", "\n"]], "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.batchers.span_batchers.SpanBatcher._make_tag_sequences": [[30, 40], ["numpy.asarray", "numpy.zeros", "span_batchers.SpanBatcher._make_tag_sequences._gen_tag_sequence"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_make_tag_sequences", "(", "batch_triples", ",", "indices", ",", "n_words", ")", ":", "\n", "    ", "def", "_gen_tag_sequence", "(", "triples", ")", ":", "\n", "      ", "matrix", "=", "np", ".", "zeros", "(", "shape", "=", "(", "n_words", ",", "n_words", ")", ",", "dtype", "=", "'int32'", ")", "\n", "for", "(", "r", ",", "i", ",", "j", ")", "in", "triples", ":", "\n", "        ", "matrix", "[", "i", "]", "[", "j", "]", "=", "r", "\n", "", "return", "[", "matrix", "[", "i", "]", "[", "j", "]", "for", "(", "i", ",", "j", ")", "in", "zip", "(", "*", "indices", ")", "]", "\n", "\n", "", "return", "np", ".", "asarray", "(", "[", "_gen_tag_sequence", "(", "triples", ")", "\n", "for", "triples", "in", "batch_triples", "]", ",", "dtype", "=", "'int32'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.batchers.span_batchers.SpanBatcher.make_each_batch": [[41, 43], ["None"], "methods", ["None"], ["", "def", "make_each_batch", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "    ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.batchers.span_batchers.SpanBatcher.batchnize_dataset": [[44, 46], ["None"], "methods", ["None"], ["", "def", "batchnize_dataset", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "    ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.batchers.span_batchers.BaseSpanBatcher.make_each_batch": [[50, 66], ["span_batchers.BaseSpanBatcher.pad_sequences", "span_batchers.BaseSpanBatcher.pad_char_sequences", "span_batchers.BaseSpanBatcher._make_span_indices", "span_batchers.BaseSpanBatcher._make_tag_sequences"], "methods", ["home.repos.pwc.inspect_result.hiroki13_instance-based-ner.batchers.base_batchers.Batcher.pad_sequences", "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.batchers.base_batchers.Batcher.pad_char_sequences", "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.models.span_models.SpanModel._make_span_indices", "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.batchers.span_batchers.SpanBatcher._make_tag_sequences"], ["  ", "def", "make_each_batch", "(", "self", ",", "batch_words", ",", "batch_chars", ",", "max_span_len", "=", "None", ",", "\n", "batch_tags", "=", "None", ")", ":", "\n", "    ", "b_words", ",", "b_words_len", "=", "self", ".", "pad_sequences", "(", "batch_words", ")", "\n", "b_chars", ",", "_", "=", "self", ".", "pad_char_sequences", "(", "batch_chars", ",", "max_token_length", "=", "20", ")", "\n", "n_words", "=", "b_words_len", "[", "0", "]", "\n", "span_indices", "=", "self", ".", "_make_span_indices", "(", "n_words", ",", "max_span_len", ")", "\n", "if", "batch_tags", "is", "None", ":", "\n", "      ", "return", "{", "\"words\"", ":", "b_words", ",", "\n", "\"chars\"", ":", "b_chars", ",", "\n", "\"seq_len\"", ":", "b_words_len", "}", "\n", "", "else", ":", "\n", "      ", "b_tags", "=", "self", ".", "_make_tag_sequences", "(", "batch_tags", ",", "span_indices", ",", "n_words", ")", "\n", "return", "{", "\"words\"", ":", "b_words", ",", "\n", "\"chars\"", ":", "b_chars", ",", "\n", "\"tags\"", ":", "b_tags", ",", "\n", "\"seq_len\"", ":", "b_words_len", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.batchers.span_batchers.BaseSpanBatcher.batchnize_dataset": [[67, 103], ["utils.common.load_json", "len", "random.shuffle", "utils.common.load_json.sort", "len", "batch_words.append", "batch_chars.append", "batch_tags.append", "len", "batches.append", "random.shuffle", "batches.append", "span_batchers.BaseSpanBatcher.make_each_batch", "len", "span_batchers.BaseSpanBatcher.make_each_batch", "len"], "methods", ["home.repos.pwc.inspect_result.hiroki13_instance-based-ner.scripts.retrieve_knn_sents_with_glove.load_json", "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.batchers.span_batchers.MaskSpanBatcher.make_each_batch", "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.batchers.span_batchers.MaskSpanBatcher.make_each_batch"], ["", "", "def", "batchnize_dataset", "(", "self", ",", "data", ",", "batch_size", "=", "None", ",", "shuffle", "=", "True", ")", ":", "\n", "    ", "batches", "=", "[", "]", "\n", "max_span_len", "=", "self", ".", "config", "[", "\"max_span_len\"", "]", "\n", "dataset", "=", "load_json", "(", "data", ")", "\n", "\n", "if", "shuffle", ":", "\n", "      ", "random", ".", "shuffle", "(", "dataset", ")", "\n", "dataset", ".", "sort", "(", "key", "=", "lambda", "record", ":", "len", "(", "record", "[", "\"words\"", "]", ")", ")", "\n", "\n", "", "prev_seq_len", "=", "len", "(", "dataset", "[", "0", "]", "[", "\"words\"", "]", ")", "\n", "batch_words", ",", "batch_chars", ",", "batch_tags", "=", "[", "]", ",", "[", "]", ",", "[", "]", "\n", "\n", "for", "record", "in", "dataset", ":", "\n", "      ", "seq_len", "=", "len", "(", "record", "[", "\"words\"", "]", ")", "\n", "\n", "if", "len", "(", "batch_words", ")", "==", "batch_size", "or", "prev_seq_len", "!=", "seq_len", ":", "\n", "        ", "batches", ".", "append", "(", "self", ".", "make_each_batch", "(", "batch_words", ",", "\n", "batch_chars", ",", "\n", "max_span_len", ",", "\n", "batch_tags", ")", ")", "\n", "batch_words", ",", "batch_chars", ",", "batch_tags", "=", "[", "]", ",", "[", "]", ",", "[", "]", "\n", "prev_seq_len", "=", "seq_len", "\n", "\n", "", "batch_words", ".", "append", "(", "record", "[", "\"words\"", "]", ")", "\n", "batch_chars", ".", "append", "(", "record", "[", "\"chars\"", "]", ")", "\n", "batch_tags", ".", "append", "(", "record", "[", "\"tags\"", "]", ")", "\n", "\n", "", "if", "len", "(", "batch_words", ")", ">", "0", ":", "\n", "      ", "batches", ".", "append", "(", "self", ".", "make_each_batch", "(", "batch_words", ",", "\n", "batch_chars", ",", "\n", "max_span_len", ",", "\n", "batch_tags", ")", ")", "\n", "", "if", "shuffle", ":", "\n", "      ", "random", ".", "shuffle", "(", "batches", ")", "\n", "", "for", "batch", "in", "batches", ":", "\n", "      ", "yield", "batch", "\n", "\n"]], "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.batchers.span_batchers.MaskSpanBatcher._make_masks": [[107, 116], ["numpy.asarray", "numpy.zeros", "span_batchers.MaskSpanBatcher._make_masks._gen_mask"], "methods", ["None"], ["  ", "@", "staticmethod", "\n", "def", "_make_masks", "(", "lengths", ",", "indices", ",", "max_n_words", ")", ":", "\n", "    ", "def", "_gen_mask", "(", "n_words", ")", ":", "\n", "      ", "matrix", "=", "np", ".", "zeros", "(", "shape", "=", "(", "max_n_words", ",", "max_n_words", ")", ",", "dtype", "=", "'float32'", ")", "\n", "matrix", "[", ":", "n_words", ",", ":", "n_words", "]", "=", "1.0", "\n", "return", "[", "matrix", "[", "i", "]", "[", "j", "]", "for", "(", "i", ",", "j", ")", "in", "zip", "(", "*", "indices", ")", "]", "\n", "\n", "", "return", "np", ".", "asarray", "(", "[", "_gen_mask", "(", "n_words", ")", "for", "n_words", "in", "lengths", "]", ",", "\n", "dtype", "=", "'float32'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.batchers.span_batchers.MaskSpanBatcher.make_each_batch": [[117, 136], ["span_batchers.MaskSpanBatcher.pad_sequences", "span_batchers.MaskSpanBatcher.pad_char_sequences", "max", "span_batchers.MaskSpanBatcher._make_span_indices", "span_batchers.MaskSpanBatcher._make_masks", "span_batchers.MaskSpanBatcher._make_tag_sequences"], "methods", ["home.repos.pwc.inspect_result.hiroki13_instance-based-ner.batchers.base_batchers.Batcher.pad_sequences", "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.batchers.base_batchers.Batcher.pad_char_sequences", "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.models.span_models.SpanModel._make_span_indices", "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.batchers.span_batchers.MaskSpanBatcher._make_masks", "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.batchers.span_batchers.SpanBatcher._make_tag_sequences"], ["", "def", "make_each_batch", "(", "self", ",", "batch_words", ",", "batch_chars", ",", "max_span_len", "=", "None", ",", "\n", "max_n_spans", "=", "None", ",", "batch_tags", "=", "None", ")", ":", "\n", "    ", "b_words", ",", "b_words_len", "=", "self", ".", "pad_sequences", "(", "batch_words", ")", "\n", "b_chars", ",", "_", "=", "self", ".", "pad_char_sequences", "(", "batch_chars", ",", "max_token_length", "=", "20", ")", "\n", "max_n_words", "=", "max", "(", "b_words_len", ")", "\n", "span_indices", "=", "self", ".", "_make_span_indices", "(", "max_n_words", ",", "max_span_len", ")", "\n", "b_masks", "=", "self", ".", "_make_masks", "(", "b_words_len", ",", "span_indices", ",", "max_n_words", ")", "\n", "if", "batch_tags", "is", "None", ":", "\n", "      ", "return", "{", "\"words\"", ":", "b_words", ",", "\n", "\"chars\"", ":", "b_chars", ",", "\n", "\"masks\"", ":", "b_masks", ",", "\n", "\"seq_len\"", ":", "b_words_len", "}", "\n", "", "else", ":", "\n", "      ", "b_tags", "=", "self", ".", "_make_tag_sequences", "(", "batch_tags", ",", "span_indices", ",", "max_n_words", ")", "\n", "return", "{", "\"words\"", ":", "b_words", ",", "\n", "\"chars\"", ":", "b_chars", ",", "\n", "\"tags\"", ":", "b_tags", ",", "\n", "\"masks\"", ":", "b_masks", ",", "\n", "\"seq_len\"", ":", "b_words_len", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.batchers.span_batchers.MaskSpanBatcher.batchnize_dataset": [[137, 160], ["utils.common.load_json", "random.shuffle", "batch_words.append", "batch_chars.append", "batch_tags.append", "len", "len", "span_batchers.MaskSpanBatcher.make_each_batch", "span_batchers.MaskSpanBatcher.make_each_batch"], "methods", ["home.repos.pwc.inspect_result.hiroki13_instance-based-ner.scripts.retrieve_knn_sents_with_glove.load_json", "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.batchers.span_batchers.MaskSpanBatcher.make_each_batch", "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.batchers.span_batchers.MaskSpanBatcher.make_each_batch"], ["", "", "def", "batchnize_dataset", "(", "self", ",", "data", ",", "batch_size", "=", "None", ",", "shuffle", "=", "True", ")", ":", "\n", "    ", "max_span_len", "=", "self", ".", "config", "[", "\"max_span_len\"", "]", "\n", "max_n_spans", "=", "None", "\n", "dataset", "=", "load_json", "(", "data", ")", "\n", "\n", "if", "shuffle", ":", "\n", "      ", "random", ".", "shuffle", "(", "dataset", ")", "\n", "\n", "", "batch_words", ",", "batch_chars", ",", "batch_tags", "=", "[", "]", ",", "[", "]", ",", "[", "]", "\n", "\n", "for", "record", "in", "dataset", ":", "\n", "      ", "if", "len", "(", "batch_words", ")", "==", "batch_size", ":", "\n", "        ", "yield", "self", ".", "make_each_batch", "(", "batch_words", ",", "batch_chars", ",", "max_span_len", ",", "\n", "max_n_spans", ",", "batch_tags", ")", "\n", "batch_words", ",", "batch_chars", ",", "batch_tags", "=", "[", "]", ",", "[", "]", ",", "[", "]", "\n", "\n", "", "batch_words", ".", "append", "(", "record", "[", "\"words\"", "]", ")", "\n", "batch_chars", ".", "append", "(", "record", "[", "\"chars\"", "]", ")", "\n", "batch_tags", ".", "append", "(", "record", "[", "\"tags\"", "]", ")", "\n", "\n", "", "if", "len", "(", "batch_words", ")", ">", "0", ":", "\n", "      ", "yield", "self", ".", "make_each_batch", "(", "batch_words", ",", "batch_chars", ",", "max_span_len", ",", "\n", "max_n_spans", ",", "batch_tags", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.scripts.convert_conll03_to_json.load": [[13, 28], ["codecs.open", "line.split.lstrip().rstrip", "line.split.startswith", "len", "line.split.split", "words.append", "tags.append", "line.split.lstrip", "len"], "function", ["None"], ["def", "load", "(", "filename", ")", ":", "\n", "  ", "with", "codecs", ".", "open", "(", "filename", ",", "mode", "=", "\"r\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "f", ":", "\n", "    ", "words", ",", "tags", "=", "[", "]", ",", "[", "]", "\n", "for", "line", "in", "f", ":", "\n", "      ", "line", "=", "line", ".", "lstrip", "(", ")", ".", "rstrip", "(", ")", "\n", "if", "line", ".", "startswith", "(", "\"-DOCSTART-\"", ")", ":", "\n", "        ", "continue", "\n", "", "if", "len", "(", "line", ")", "==", "0", ":", "\n", "        ", "if", "len", "(", "words", ")", "!=", "0", ":", "\n", "          ", "yield", "words", ",", "tags", "\n", "words", ",", "tags", "=", "[", "]", ",", "[", "]", "\n", "", "", "else", ":", "\n", "        ", "line", "=", "line", ".", "split", "(", ")", "\n", "words", ".", "append", "(", "line", "[", "0", "]", ")", "\n", "tags", ".", "append", "(", "line", "[", "-", "1", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.scripts.convert_conll03_to_json.write_json": [[30, 33], ["codecs.open", "ujson.dump"], "function", ["None"], ["", "", "", "", "def", "write_json", "(", "filename", ",", "data", ")", ":", "\n", "  ", "with", "codecs", ".", "open", "(", "filename", ",", "mode", "=", "\"w\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "f", ":", "\n", "    ", "ujson", ".", "dump", "(", "data", ",", "f", ",", "ensure_ascii", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.scripts.convert_conll03_to_json.remove_duplicate_sents": [[35, 44], ["enumerate", "new_sents.append"], "function", ["None"], ["", "", "def", "remove_duplicate_sents", "(", "sents", ")", ":", "\n", "  ", "new_sents", "=", "[", "]", "\n", "for", "i", ",", "(", "words1", ",", "tags1", ")", "in", "enumerate", "(", "sents", ")", ":", "\n", "    ", "for", "(", "words2", ",", "_", ")", "in", "sents", "[", "i", "+", "1", ":", "]", ":", "\n", "      ", "if", "words1", "==", "words2", ":", "\n", "        ", "break", "\n", "", "", "else", ":", "\n", "      ", "new_sents", ".", "append", "(", "(", "words1", ",", "tags1", ")", ")", "\n", "", "", "return", "new_sents", "\n", "\n"]], "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.scripts.convert_conll03_to_json.bio2span": [[46, 70], ["enumerate", "label.startswith", "spans.append", "label.startswith", "spans.append", "spans.append", "spans.append"], "function", ["None"], ["", "def", "bio2span", "(", "labels", ")", ":", "\n", "  ", "spans", "=", "[", "]", "\n", "span", "=", "[", "]", "\n", "for", "w_i", ",", "label", "in", "enumerate", "(", "labels", ")", ":", "\n", "    ", "if", "label", ".", "startswith", "(", "'B-'", ")", ":", "\n", "      ", "if", "span", ":", "\n", "        ", "spans", ".", "append", "(", "span", ")", "\n", "", "span", "=", "[", "label", "[", "2", ":", "]", ",", "w_i", ",", "w_i", "]", "\n", "", "elif", "label", ".", "startswith", "(", "'I-'", ")", ":", "\n", "      ", "if", "span", ":", "\n", "        ", "if", "label", "[", "2", ":", "]", "==", "span", "[", "0", "]", ":", "\n", "          ", "span", "[", "2", "]", "=", "w_i", "\n", "", "else", ":", "\n", "          ", "spans", ".", "append", "(", "span", ")", "\n", "span", "=", "[", "label", "[", "2", ":", "]", ",", "w_i", ",", "w_i", "]", "\n", "", "", "else", ":", "\n", "        ", "span", "=", "[", "label", "[", "2", ":", "]", ",", "w_i", ",", "w_i", "]", "\n", "", "", "else", ":", "\n", "      ", "if", "span", ":", "\n", "        ", "spans", ".", "append", "(", "span", ")", "\n", "", "span", "=", "[", "]", "\n", "", "", "if", "span", ":", "\n", "    ", "spans", ".", "append", "(", "span", ")", "\n", "", "return", "spans", "\n", "\n"]], "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.scripts.convert_conll03_to_json.main": [[72, 110], ["list", "print", "argv.output_file.endswith", "convert_conll03_to_json.write_json", "print", "convert_conll03_to_json.load", "convert_conll03_to_json.remove_duplicate_sents", "print", "convert_conll03_to_json.bio2span", "data.append", "len", "len", "int", "random.shuffle", "len", "len", "len", "len", "len", "len"], "function", ["home.repos.pwc.inspect_result.hiroki13_instance-based-ner.scripts.retrieve_knn_sents_with_glove.write_json", "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.scripts.convert_genia_to_json.load", "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.scripts.convert_genia_to_json.remove_duplicate_sents", "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.scripts.convert_genia_to_json.bio2span"], ["", "def", "main", "(", "argv", ")", ":", "\n", "  ", "sents", "=", "list", "(", "load", "(", "argv", ".", "input_file", ")", ")", "\n", "print", "(", "\"Sents:%d\"", "%", "len", "(", "sents", ")", ")", "\n", "if", "argv", ".", "remove_duplicates", ":", "\n", "    ", "sents", "=", "remove_duplicate_sents", "(", "sents", ")", "\n", "print", "(", "\"Sents (removed duplicates): %d\"", "%", "len", "(", "sents", ")", ")", "\n", "\n", "", "data", "=", "[", "]", "\n", "n_sents", "=", "0", "\n", "n_words", "=", "0", "\n", "n_spans", "=", "0", "\n", "for", "words", ",", "bio_labels", "in", "sents", ":", "\n", "    ", "spans", "=", "bio2span", "(", "bio_labels", ")", "\n", "data", ".", "append", "(", "{", "\"sent_id\"", ":", "n_sents", ",", "\n", "\"words\"", ":", "words", ",", "\n", "\"bio_labels\"", ":", "bio_labels", ",", "\n", "\"spans\"", ":", "spans", "}", ")", "\n", "n_sents", "+=", "1", "\n", "n_words", "+=", "len", "(", "words", ")", "\n", "n_spans", "+=", "len", "(", "spans", ")", "\n", "\n", "", "if", "argv", ".", "split", ">", "1", ":", "\n", "    ", "split_size", "=", "int", "(", "len", "(", "data", ")", "/", "argv", ".", "split", ")", "\n", "random", ".", "shuffle", "(", "data", ")", "\n", "data", "=", "data", "[", ":", "split_size", "]", "\n", "n_sents", "=", "len", "(", "data", ")", "\n", "n_words", "=", "0", "\n", "n_spans", "=", "0", "\n", "for", "record", "in", "data", ":", "\n", "      ", "n_words", "+=", "len", "(", "record", "[", "\"words\"", "]", ")", "\n", "n_spans", "+=", "len", "(", "record", "[", "\"spans\"", "]", ")", "\n", "\n", "", "", "if", "argv", ".", "output_file", ".", "endswith", "(", "\".json\"", ")", ":", "\n", "    ", "path", "=", "argv", ".", "output_file", "\n", "", "else", ":", "\n", "    ", "path", "=", "argv", ".", "output_file", "+", "\".json\"", "\n", "", "write_json", "(", "path", ",", "data", ")", "\n", "print", "(", "\"Sents:%d\\tWords:%d\\tEntities:%d\"", "%", "(", "n_sents", ",", "n_words", ",", "n_spans", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.scripts.convert_genia_to_json.load": [[7, 20], ["codecs.open", "line.split.lstrip().rstrip", "len", "line.split.split", "words.append", "tags.append", "line.split.lstrip", "len"], "function", ["None"], ["def", "load", "(", "filename", ")", ":", "\n", "  ", "with", "codecs", ".", "open", "(", "filename", ",", "mode", "=", "\"r\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "f", ":", "\n", "    ", "words", ",", "tags", "=", "[", "]", ",", "[", "]", "\n", "for", "line", "in", "f", ":", "\n", "      ", "line", "=", "line", ".", "lstrip", "(", ")", ".", "rstrip", "(", ")", "\n", "if", "len", "(", "line", ")", "==", "0", ":", "\n", "        ", "if", "len", "(", "words", ")", "!=", "0", ":", "\n", "          ", "yield", "words", ",", "tags", "\n", "words", ",", "tags", "=", "[", "]", ",", "[", "]", "\n", "", "", "else", ":", "\n", "        ", "line", "=", "line", ".", "split", "(", "\"\\t\"", ")", "\n", "words", ".", "append", "(", "line", "[", "0", "]", ")", "\n", "tags", ".", "append", "(", "line", "[", "1", ":", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.scripts.convert_genia_to_json.write_json": [[22, 25], ["codecs.open", "ujson.dump"], "function", ["None"], ["", "", "", "", "def", "write_json", "(", "filename", ",", "data", ")", ":", "\n", "  ", "with", "codecs", ".", "open", "(", "filename", ",", "mode", "=", "\"w\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "f", ":", "\n", "    ", "ujson", ".", "dump", "(", "data", ",", "f", ",", "ensure_ascii", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.scripts.convert_genia_to_json.remove_duplicate_sents": [[27, 36], ["enumerate", "new_sents.append"], "function", ["None"], ["", "", "def", "remove_duplicate_sents", "(", "sents", ")", ":", "\n", "  ", "new_sents", "=", "[", "]", "\n", "for", "i", ",", "(", "words1", ",", "tags1", ")", "in", "enumerate", "(", "sents", ")", ":", "\n", "    ", "for", "(", "words2", ",", "_", ")", "in", "sents", "[", "i", "+", "1", ":", "]", ":", "\n", "      ", "if", "words1", "==", "words2", ":", "\n", "        ", "break", "\n", "", "", "else", ":", "\n", "      ", "new_sents", ".", "append", "(", "(", "words1", ",", "tags1", ")", ")", "\n", "", "", "return", "new_sents", "\n", "\n"]], "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.scripts.convert_genia_to_json.bio2span": [[38, 62], ["enumerate", "label.startswith", "spans.append", "label.startswith", "spans.append", "spans.append", "spans.append"], "function", ["None"], ["", "def", "bio2span", "(", "labels", ")", ":", "\n", "  ", "spans", "=", "[", "]", "\n", "span", "=", "[", "]", "\n", "for", "w_i", ",", "label", "in", "enumerate", "(", "labels", ")", ":", "\n", "    ", "if", "label", ".", "startswith", "(", "'B-'", ")", ":", "\n", "      ", "if", "span", ":", "\n", "        ", "spans", ".", "append", "(", "span", ")", "\n", "", "span", "=", "[", "label", "[", "2", ":", "]", ",", "w_i", ",", "w_i", "]", "\n", "", "elif", "label", ".", "startswith", "(", "'I-'", ")", ":", "\n", "      ", "if", "span", ":", "\n", "        ", "if", "label", "[", "2", ":", "]", "==", "span", "[", "0", "]", ":", "\n", "          ", "span", "[", "2", "]", "=", "w_i", "\n", "", "else", ":", "\n", "          ", "spans", ".", "append", "(", "span", ")", "\n", "span", "=", "[", "label", "[", "2", ":", "]", ",", "w_i", ",", "w_i", "]", "\n", "", "", "else", ":", "\n", "        ", "span", "=", "[", "label", "[", "2", ":", "]", ",", "w_i", ",", "w_i", "]", "\n", "", "", "else", ":", "\n", "      ", "if", "span", ":", "\n", "        ", "spans", ".", "append", "(", "span", ")", "\n", "", "span", "=", "[", "]", "\n", "", "", "if", "span", ":", "\n", "    ", "spans", ".", "append", "(", "span", ")", "\n", "", "return", "spans", "\n", "\n"]], "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.scripts.convert_genia_to_json.main": [[64, 92], ["list", "print", "argv.output_file.endswith", "convert_genia_to_json.write_json", "print", "convert_genia_to_json.load", "convert_genia_to_json.remove_duplicate_sents", "print", "zip", "data.append", "len", "len", "len", "convert_genia_to_json.bio2span", "len"], "function", ["home.repos.pwc.inspect_result.hiroki13_instance-based-ner.scripts.retrieve_knn_sents_with_glove.write_json", "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.scripts.convert_genia_to_json.load", "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.scripts.convert_genia_to_json.remove_duplicate_sents", "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.scripts.convert_genia_to_json.bio2span"], ["", "def", "main", "(", "argv", ")", ":", "\n", "  ", "sents", "=", "list", "(", "load", "(", "argv", ".", "input_file", ")", ")", "\n", "print", "(", "\"Sents: %d\"", "%", "len", "(", "sents", ")", ")", "\n", "if", "argv", ".", "remove_duplicates", ":", "\n", "    ", "sents", "=", "remove_duplicate_sents", "(", "sents", ")", "\n", "print", "(", "\"Sents (removed duplicates): %d\"", "%", "len", "(", "sents", ")", ")", "\n", "\n", "", "data", "=", "[", "]", "\n", "n_sents", "=", "0", "\n", "n_words", "=", "0", "\n", "n_spans", "=", "0", "\n", "for", "words", ",", "multi_layered_labels", "in", "sents", ":", "\n", "    ", "spans", "=", "[", "]", "\n", "for", "bio_labels", "in", "zip", "(", "*", "multi_layered_labels", ")", ":", "\n", "      ", "spans", "+=", "bio2span", "(", "bio_labels", ")", "\n", "", "data", ".", "append", "(", "{", "\"sent_id\"", ":", "n_sents", ",", "\n", "\"words\"", ":", "words", ",", "\n", "\"spans\"", ":", "spans", "}", ")", "\n", "n_sents", "+=", "1", "\n", "n_words", "+=", "len", "(", "words", ")", "\n", "n_spans", "+=", "len", "(", "spans", ")", "\n", "\n", "", "if", "argv", ".", "output_file", ".", "endswith", "(", "\".json\"", ")", ":", "\n", "    ", "path", "=", "argv", ".", "output_file", "\n", "", "else", ":", "\n", "    ", "path", "=", "argv", ".", "output_file", "+", "\".json\"", "\n", "", "write_json", "(", "path", ",", "data", ")", "\n", "print", "(", "\"Sents:%d\\tWords:%d\\tEntities:%d\"", "%", "(", "n_sents", ",", "n_words", ",", "n_spans", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.scripts.retrieve_knn_sents_with_glove.load_json": [[17, 21], ["codecs.open", "ujson.load"], "function", ["home.repos.pwc.inspect_result.hiroki13_instance-based-ner.scripts.convert_genia_to_json.load"], ["def", "load_json", "(", "filename", ")", ":", "\n", "  ", "with", "codecs", ".", "open", "(", "filename", ",", "mode", "=", "'r'", ",", "encoding", "=", "'utf-8'", ")", "as", "f", ":", "\n", "    ", "dataset", "=", "ujson", ".", "load", "(", "f", ")", "\n", "", "return", "dataset", "\n", "\n"]], "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.scripts.retrieve_knn_sents_with_glove.write_json": [[23, 26], ["codecs.open", "ujson.dump"], "function", ["None"], ["", "def", "write_json", "(", "filename", ",", "data", ")", ":", "\n", "  ", "with", "codecs", ".", "open", "(", "filename", ",", "mode", "=", "\"w\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "f", ":", "\n", "    ", "ujson", ".", "dump", "(", "data", ",", "f", ",", "ensure_ascii", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.scripts.retrieve_knn_sents_with_glove.load_glove": [[28, 39], ["codecs.open", "tqdm.tqdm", "len", "len", "numpy.asarray", "line.lstrip().rstrip().split.lstrip().rstrip().split", "len", "vectors.append", "line.lstrip().rstrip().split.lstrip().rstrip", "float", "line.lstrip().rstrip().split.lstrip"], "function", ["None"], ["", "", "def", "load_glove", "(", "glove_path", ",", "glove_name", "=", "\"6B\"", ")", ":", "\n", "  ", "vocab", "=", "{", "}", "\n", "vectors", "=", "[", "]", "\n", "total", "=", "glove_sizes", "[", "glove_name", "]", "\n", "with", "codecs", ".", "open", "(", "glove_path", ",", "mode", "=", "'r'", ",", "encoding", "=", "'utf-8'", ")", "as", "f", ":", "\n", "    ", "for", "line", "in", "tqdm", "(", "f", ",", "total", "=", "total", ",", "desc", "=", "\"Load glove\"", ")", ":", "\n", "      ", "line", "=", "line", ".", "lstrip", "(", ")", ".", "rstrip", "(", ")", ".", "split", "(", "\" \"", ")", "\n", "vocab", "[", "line", "[", "0", "]", "]", "=", "len", "(", "vocab", ")", "\n", "vectors", ".", "append", "(", "[", "float", "(", "x", ")", "for", "x", "in", "line", "[", "1", ":", "]", "]", ")", "\n", "", "", "assert", "len", "(", "vocab", ")", "==", "len", "(", "vectors", ")", "\n", "return", "vocab", ",", "np", ".", "asarray", "(", "vectors", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.scripts.retrieve_knn_sents_with_glove.mean_vectors": [[41, 55], ["numpy.zeros", "mean_vecs.append", "word.lower.lower", "vecs.append", "numpy.mean"], "function", ["None"], ["", "def", "mean_vectors", "(", "data", ",", "emb", ",", "vocab", ")", ":", "\n", "  ", "unk_vec", "=", "np", ".", "zeros", "(", "emb", ".", "shape", "[", "1", "]", ")", "\n", "mean_vecs", "=", "[", "]", "\n", "for", "record", "in", "data", ":", "\n", "    ", "vecs", "=", "[", "]", "\n", "for", "word", "in", "record", "[", "\"words\"", "]", ":", "\n", "      ", "word", "=", "word", ".", "lower", "(", ")", "\n", "if", "word", "in", "vocab", ":", "\n", "        ", "vec", "=", "emb", "[", "vocab", "[", "word", "]", "]", "\n", "", "else", ":", "\n", "        ", "vec", "=", "unk_vec", "\n", "", "vecs", ".", "append", "(", "vec", ")", "\n", "", "mean_vecs", ".", "append", "(", "np", ".", "mean", "(", "vecs", ",", "axis", "=", "0", ")", ")", "\n", "", "return", "mean_vecs", "\n", "\n"]], "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.scripts.retrieve_knn_sents_with_glove.cosine_similarity": [[57, 62], ["numpy.linalg.norm", "numpy.linalg.norm", "numpy.dot"], "function", ["None"], ["", "def", "cosine_similarity", "(", "p0", ",", "p1", ")", ":", "\n", "  ", "d", "=", "(", "norm", "(", "p0", ")", "*", "norm", "(", "p1", ")", ")", "\n", "if", "d", ">", "0", ":", "\n", "    ", "return", "np", ".", "dot", "(", "p0", ",", "p1", ")", "/", "d", "\n", "", "return", "0.0", "\n", "\n"]], "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.scripts.retrieve_knn_sents_with_glove.knn": [[64, 73], ["enumerate", "retrieve_knn_sents_with_glove.write_json", "zip", "print", "retrieve_knn_sents_with_glove.cosine_similarity", "int", "numpy.argsort"], "function", ["home.repos.pwc.inspect_result.hiroki13_instance-based-ner.scripts.retrieve_knn_sents_with_glove.write_json", "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.scripts.retrieve_knn_sents_with_glove.cosine_similarity"], ["", "def", "knn", "(", "test_sents", ",", "train_embs", ",", "test_embs", ",", "k", ",", "path", ")", ":", "\n", "  ", "for", "index", ",", "(", "sent", ",", "vec", ")", "in", "enumerate", "(", "zip", "(", "test_sents", ",", "test_embs", ")", ")", ":", "\n", "    ", "assert", "index", "==", "sent", "[", "\"sent_id\"", "]", "\n", "if", "(", "index", "+", "1", ")", "%", "100", "==", "0", ":", "\n", "      ", "print", "(", "\"%d\"", "%", "(", "index", "+", "1", ")", ",", "flush", "=", "True", ",", "end", "=", "\" \"", ")", "\n", "", "sim", "=", "[", "cosine_similarity", "(", "train_vec", ",", "vec", ")", "for", "train_vec", "in", "train_embs", "]", "\n", "arg_sort", "=", "np", ".", "argsort", "(", "sim", ")", "[", ":", ":", "-", "1", "]", "[", ":", "k", "]", "\n", "sent", "[", "\"train_sent_ids\"", "]", "=", "[", "int", "(", "arg", ")", "for", "arg", "in", "arg_sort", "]", "\n", "", "write_json", "(", "path", ",", "test_sents", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.scripts.retrieve_knn_sents_with_glove.main": [[75, 88], ["retrieve_knn_sents_with_glove.load_glove", "print", "print", "retrieve_knn_sents_with_glove.mean_vectors", "retrieve_knn_sents_with_glove.mean_vectors", "args.output_file.endswith", "retrieve_knn_sents_with_glove.knn", "retrieve_knn_sents_with_glove.load_json", "retrieve_knn_sents_with_glove.load_json", "len", "len"], "function", ["home.repos.pwc.inspect_result.hiroki13_instance-based-ner.scripts.retrieve_knn_sents_with_glove.load_glove", "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.scripts.retrieve_knn_sents_with_glove.mean_vectors", "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.scripts.retrieve_knn_sents_with_glove.mean_vectors", "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.scripts.retrieve_knn_sents_with_glove.knn", "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.scripts.retrieve_knn_sents_with_glove.load_json", "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.scripts.retrieve_knn_sents_with_glove.load_json"], ["", "def", "main", "(", "args", ")", ":", "\n", "  ", "train_sents", "=", "load_json", "(", "args", ".", "train_json", ")", "[", ":", "args", ".", "data_size", "]", "\n", "test_sents", "=", "load_json", "(", "args", ".", "test_json", ")", "[", ":", "args", ".", "data_size", "]", "\n", "vocab", ",", "glove", "=", "load_glove", "(", "args", ".", "glove", ")", "\n", "print", "(", "\"Train sents: {:>7}\"", ".", "format", "(", "len", "(", "train_sents", ")", ")", ")", "\n", "print", "(", "\"Test  sents: {:>7}\"", ".", "format", "(", "len", "(", "test_sents", ")", ")", ")", "\n", "train_embs", "=", "mean_vectors", "(", "train_sents", ",", "glove", ",", "vocab", ")", "\n", "test_embs", "=", "mean_vectors", "(", "test_sents", ",", "glove", ",", "vocab", ")", "\n", "if", "args", ".", "output_file", ".", "endswith", "(", "\".json\"", ")", ":", "\n", "    ", "path", "=", "args", ".", "output_file", "\n", "", "else", ":", "\n", "    ", "path", "=", "args", ".", "output_file", "+", "\".json\"", "\n", "", "knn", "(", "test_sents", ",", "train_embs", ",", "test_embs", ",", "args", ".", "k", ",", "path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.models.decoders.get_span_indices": [[5, 10], ["numpy.ones", "numpy.triu", "numpy.nonzero", "numpy.triu", "numpy.minimum"], "function", ["None"], ["def", "get_span_indices", "(", "n_words", ",", "max_span_len", ")", ":", "\n", "  ", "ones", "=", "np", ".", "ones", "(", "shape", "=", "(", "n_words", ",", "n_words", ")", ",", "dtype", "=", "'int32'", ")", "\n", "mask", "=", "np", ".", "triu", "(", "ones", ",", "k", "=", "np", ".", "minimum", "(", "n_words", ",", "max_span_len", ")", ")", "\n", "indices", "=", "np", ".", "triu", "(", "ones", ")", "-", "mask", "\n", "return", "np", ".", "nonzero", "(", "indices", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.models.decoders.get_scored_spans": [[12, 22], ["decoders.get_span_indices", "zip", "len", "len", "len", "spans.append", "len", "len", "len", "enumerate"], "function", ["home.repos.pwc.inspect_result.hiroki13_instance-based-ner.models.decoders.get_span_indices"], ["", "def", "get_scored_spans", "(", "scores", ",", "n_words", ",", "max_span_len", ")", "->", "List", "[", "List", "[", "tuple", "]", "]", ":", "\n", "  ", "indx_i", ",", "indx_j", "=", "get_span_indices", "(", "n_words", ",", "max_span_len", ")", "\n", "assert", "len", "(", "scores", ")", "==", "len", "(", "indx_i", ")", "==", "len", "(", "indx_j", ")", ",", "\"%d %d %d\"", "%", "(", "len", "(", "scores", ")", ",", "\n", "len", "(", "indx_i", ")", ",", "\n", "len", "(", "indx_j", ")", ")", "\n", "spans", "=", "[", "]", "\n", "for", "scores_each_span", ",", "i", ",", "j", "in", "zip", "(", "scores", ",", "indx_i", ",", "indx_j", ")", ":", "\n", "    ", "spans", ".", "append", "(", "\n", "[", "(", "r", ",", "i", ",", "j", ",", "score", ")", "for", "r", ",", "score", "in", "enumerate", "(", "scores_each_span", ")", "]", ")", "\n", "", "return", "spans", "\n", "\n"]], "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.models.decoders.get_labeled_spans": [[24, 32], ["decoders.get_span_indices", "len", "len", "len", "len", "len", "len", "zip"], "function", ["home.repos.pwc.inspect_result.hiroki13_instance-based-ner.models.decoders.get_span_indices"], ["", "def", "get_labeled_spans", "(", "labels", ",", "n_words", ",", "max_span_len", ",", "\n", "null_label_id", ")", "->", "List", "[", "tuple", "]", ":", "\n", "  ", "indx_i", ",", "indx_j", "=", "get_span_indices", "(", "n_words", ",", "max_span_len", ")", "\n", "assert", "len", "(", "labels", ")", "==", "len", "(", "indx_i", ")", "==", "len", "(", "indx_j", ")", ",", "\"%d %d %d\"", "%", "(", "len", "(", "labels", ")", ",", "\n", "len", "(", "indx_i", ")", ",", "\n", "len", "(", "indx_j", ")", ")", "\n", "return", "[", "(", "r", ",", "i", ",", "j", ")", "for", "r", ",", "i", ",", "j", "in", "zip", "(", "labels", ",", "indx_i", ",", "indx_j", ")", "\n", "if", "r", "!=", "null_label_id", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.models.decoders.get_scores_and_spans": [[34, 45], ["zip", "scored_spans.append", "span_boundaries.index"], "function", ["None"], ["", "def", "get_scores_and_spans", "(", "spans", ",", "scores", ",", "sent_id", ",", "indx_i", ",", "indx_j", ")", "->", "List", "[", "List", "]", ":", "\n", "  ", "scored_spans", "=", "[", "]", "\n", "span_boundaries", "=", "[", "(", "i", ",", "j", ")", "for", "(", "_", ",", "i", ",", "j", ")", "in", "spans", "]", "\n", "for", "i", ",", "j", ",", "score", "in", "zip", "(", "indx_i", ",", "indx_j", ",", "scores", ")", ":", "\n", "    ", "if", "(", "i", ",", "j", ")", "in", "span_boundaries", ":", "\n", "      ", "index", "=", "span_boundaries", ".", "index", "(", "(", "i", ",", "j", ")", ")", "\n", "r", "=", "spans", "[", "index", "]", "[", "0", "]", "\n", "", "else", ":", "\n", "      ", "r", "=", "\"O\"", "\n", "", "scored_spans", ".", "append", "(", "[", "r", ",", "sent_id", ",", "i", ",", "j", ",", "score", "]", ")", "\n", "", "return", "scored_spans", "\n", "\n"]], "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.models.decoders.get_batch_labeled_spans": [[47, 53], ["decoders.get_span_indices", "zip"], "function", ["home.repos.pwc.inspect_result.hiroki13_instance-based-ner.models.decoders.get_span_indices"], ["", "def", "get_batch_labeled_spans", "(", "batch_labels", ",", "n_words", ",", "max_span_len", ",", "\n", "null_label_id", ")", "->", "List", "[", "List", "[", "List", "[", "int", "]", "]", "]", ":", "\n", "  ", "indx_i", ",", "indx_j", "=", "get_span_indices", "(", "n_words", ",", "max_span_len", ")", "\n", "return", "[", "[", "[", "r", ",", "i", ",", "j", "]", "for", "r", ",", "i", ",", "j", "in", "zip", "(", "labels", ",", "indx_i", ",", "indx_j", ")", "if", "\n", "r", "!=", "null_label_id", "]", "\n", "for", "labels", "in", "batch_labels", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.models.decoders.get_pred_spans_with_proba": [[55, 64], ["decoders.get_span_indices", "zip", "len", "len", "len", "len", "len", "len", "float"], "function", ["home.repos.pwc.inspect_result.hiroki13_instance-based-ner.models.decoders.get_span_indices"], ["", "def", "get_pred_spans_with_proba", "(", "scores", ",", "n_words", ",", "max_span_len", ")", "->", "dict", ":", "\n", "  ", "indx_i", ",", "indx_j", "=", "get_span_indices", "(", "n_words", ",", "max_span_len", ")", "\n", "assert", "len", "(", "scores", ")", "==", "len", "(", "indx_i", ")", "==", "len", "(", "indx_j", ")", ",", "\"%d %d %d\"", "%", "(", "len", "(", "scores", ")", ",", "\n", "len", "(", "indx_i", ")", ",", "\n", "len", "(", "indx_j", ")", ")", "\n", "spans", "=", "{", "}", "\n", "for", "label_scores", ",", "i", ",", "j", "in", "zip", "(", "scores", ",", "indx_i", ",", "indx_j", ")", ":", "\n", "    ", "spans", "[", "'%d,%d'", "%", "(", "i", ",", "j", ")", "]", "=", "[", "float", "(", "score", ")", "for", "score", "in", "label_scores", "]", "\n", "", "return", "spans", "\n", "\n"]], "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.models.decoders.sort_scored_spans": [[66, 75], ["sorted_spans.sort", "sorted_spans.append"], "function", ["None"], ["", "def", "sort_scored_spans", "(", "scored_spans", ",", "null_label_id", ")", "->", "List", "[", "tuple", "]", ":", "\n", "  ", "sorted_spans", "=", "[", "]", "\n", "for", "spans", "in", "scored_spans", ":", "\n", "    ", "r", ",", "i", ",", "j", ",", "null_score", "=", "spans", "[", "null_label_id", "]", "\n", "for", "(", "r", ",", "i", ",", "j", ",", "score", ")", "in", "spans", ":", "\n", "      ", "if", "null_score", "<", "score", ":", "\n", "        ", "sorted_spans", ".", "append", "(", "(", "r", ",", "i", ",", "j", ",", "score", ")", ")", "\n", "", "", "", "sorted_spans", ".", "sort", "(", "key", "=", "lambda", "span", ":", "span", "[", "-", "1", "]", ",", "reverse", "=", "True", ")", "\n", "return", "sorted_spans", "\n", "\n"]], "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.models.decoders.greedy_search": [[77, 90], ["numpy.zeros", "decoders.get_scored_spans", "decoders.sort_scored_spans", "triples.append", "sum"], "function", ["home.repos.pwc.inspect_result.hiroki13_instance-based-ner.models.decoders.get_scored_spans", "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.models.decoders.sort_scored_spans"], ["", "def", "greedy_search", "(", "scores", ",", "n_words", ",", "max_span_len", ",", "\n", "null_label_id", ")", "->", "List", "[", "List", "[", "int", "]", "]", ":", "\n", "  ", "triples", "=", "[", "]", "\n", "used_words", "=", "np", ".", "zeros", "(", "n_words", ",", "'int32'", ")", "\n", "scored_spans", "=", "get_scored_spans", "(", "scores", ",", "n_words", ",", "max_span_len", ")", "\n", "sorted_spans", "=", "sort_scored_spans", "(", "scored_spans", ",", "null_label_id", ")", "\n", "\n", "for", "(", "r", ",", "i", ",", "j", ",", "_", ")", "in", "sorted_spans", ":", "\n", "    ", "if", "sum", "(", "used_words", "[", "i", ":", "j", "+", "1", "]", ")", ">", "0", ":", "\n", "      ", "continue", "\n", "", "triples", ".", "append", "(", "[", "r", ",", "i", ",", "j", "]", ")", "\n", "used_words", "[", "i", ":", "j", "+", "1", "]", "=", "1", "\n", "", "return", "triples", "\n", "", ""]], "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.models.knn_models.KnnModel.__init__": [[31, 36], ["models.span_models.MaskSpanModel.__init__"], "methods", ["home.repos.pwc.inspect_result.hiroki13_instance-based-ner.models.base_model.BaseModel.__init__"], ["  ", "def", "__init__", "(", "self", ",", "config", ",", "batcher", ",", "is_train", "=", "True", ")", ":", "\n", "    ", "self", ".", "knn_ids", "=", "None", "\n", "self", ".", "gold_label_proba", "=", "None", "\n", "self", ".", "max_n_spans", "=", "config", "[", "\"max_n_spans\"", "]", "\n", "super", "(", "KnnModel", ",", "self", ")", ".", "__init__", "(", "config", ",", "batcher", ",", "is_train", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.models.knn_models.KnnModel._add_placeholders": [[37, 55], ["tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder"], "methods", ["None"], ["", "def", "_add_placeholders", "(", "self", ")", ":", "\n", "    ", "self", ".", "words", "=", "tf", ".", "placeholder", "(", "tf", ".", "int32", ",", "shape", "=", "[", "None", ",", "None", "]", ",", "name", "=", "\"words\"", ")", "\n", "self", ".", "tags", "=", "tf", ".", "placeholder", "(", "tf", ".", "int32", ",", "shape", "=", "[", "None", ",", "None", "]", ",", "name", "=", "\"tags\"", ")", "\n", "self", ".", "seq_len", "=", "tf", ".", "placeholder", "(", "tf", ".", "int32", ",", "shape", "=", "[", "None", "]", ",", "name", "=", "\"seq_len\"", ")", "\n", "self", ".", "neighbor_reps", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "shape", "=", "[", "None", ",", "None", "]", ",", "\n", "name", "=", "\"neighbor_reps\"", ")", "\n", "self", ".", "neighbor_tags", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "shape", "=", "[", "None", "]", ",", "\n", "name", "=", "\"neighbor_tags\"", ")", "\n", "self", ".", "neighbor_tag_one_hots", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "shape", "=", "[", "None", ",", "None", "]", ",", "\n", "name", "=", "\"neighbor_tag_one_hots\"", ")", "\n", "if", "self", ".", "cfg", "[", "\"use_chars\"", "]", ":", "\n", "      ", "self", ".", "chars", "=", "tf", ".", "placeholder", "(", "tf", ".", "int32", ",", "shape", "=", "[", "None", ",", "None", ",", "None", "]", ",", "\n", "name", "=", "\"chars\"", ")", "\n", "# hyperparameters", "\n", "", "self", ".", "is_train", "=", "tf", ".", "placeholder", "(", "tf", ".", "bool", ",", "name", "=", "\"is_train\"", ")", "\n", "self", ".", "keep_prob", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "name", "=", "\"rnn_keep_probability\"", ")", "\n", "self", ".", "drop_rate", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "name", "=", "\"dropout_rate\"", ")", "\n", "self", ".", "lr", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "name", "=", "\"learning_rate\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.models.knn_models.KnnModel._get_feed_dict": [[56, 74], ["None"], "methods", ["None"], ["", "def", "_get_feed_dict", "(", "self", ",", "batch", ",", "keep_prob", "=", "1.0", ",", "is_train", "=", "False", ",", "lr", "=", "None", ")", ":", "\n", "    ", "feed_dict", "=", "{", "self", ".", "words", ":", "batch", "[", "\"words\"", "]", ",", "self", ".", "seq_len", ":", "batch", "[", "\"seq_len\"", "]", "}", "\n", "if", "\"tags\"", "in", "batch", ":", "\n", "      ", "feed_dict", "[", "self", ".", "tags", "]", "=", "batch", "[", "\"tags\"", "]", "\n", "", "if", "self", ".", "cfg", "[", "\"use_chars\"", "]", ":", "\n", "      ", "feed_dict", "[", "self", ".", "chars", "]", "=", "batch", "[", "\"chars\"", "]", "\n", "", "if", "\"neighbor_reps\"", "in", "batch", ":", "\n", "      ", "feed_dict", "[", "self", ".", "neighbor_reps", "]", "=", "batch", "[", "\"neighbor_reps\"", "]", "\n", "", "if", "\"neighbor_tags\"", "in", "batch", ":", "\n", "      ", "feed_dict", "[", "self", ".", "neighbor_tags", "]", "=", "batch", "[", "\"neighbor_tags\"", "]", "\n", "", "if", "\"neighbor_tag_one_hots\"", "in", "batch", ":", "\n", "      ", "feed_dict", "[", "self", ".", "neighbor_tag_one_hots", "]", "=", "batch", "[", "\"neighbor_tag_one_hots\"", "]", "\n", "", "feed_dict", "[", "self", ".", "keep_prob", "]", "=", "keep_prob", "\n", "feed_dict", "[", "self", ".", "drop_rate", "]", "=", "1.0", "-", "keep_prob", "\n", "feed_dict", "[", "self", ".", "is_train", "]", "=", "is_train", "\n", "if", "lr", "is", "not", "None", ":", "\n", "      ", "feed_dict", "[", "self", ".", "lr", "]", "=", "lr", "\n", "", "return", "feed_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.models.knn_models.KnnModel._build_neighbor_similarity_op": [[75, 80], ["tensorflow.name_scope", "tensorflow.tensordot"], "methods", ["None"], ["", "def", "_build_neighbor_similarity_op", "(", "self", ")", ":", "\n", "    ", "with", "tf", ".", "name_scope", "(", "\"similarity\"", ")", ":", "\n", "# 1D: batch_size, 2D: max_num_spans, 3D: num_instances", "\n", "      ", "self", ".", "similarity", "=", "tf", ".", "tensordot", "(", "self", ".", "span_rep", ",", "self", ".", "neighbor_reps", ",", "\n", "axes", "=", "[", "-", "1", ",", "-", "1", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.models.knn_models.KnnModel._build_neighbor_proba_op": [[81, 85], ["tensorflow.name_scope", "tensorflow.nn.softmax"], "methods", ["None"], ["", "", "def", "_build_neighbor_proba_op", "(", "self", ")", ":", "\n", "    ", "with", "tf", ".", "name_scope", "(", "\"neighbor_prob\"", ")", ":", "\n", "# 1D: batch_size, 2D: max_num_spans, 3D: num_instances", "\n", "      ", "self", ".", "neighbor_proba", "=", "tf", ".", "nn", ".", "softmax", "(", "self", ".", "similarity", ",", "axis", "=", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.models.knn_models.KnnModel._build_marginal_proba_op": [[86, 98], ["tensorflow.name_scope", "tensorflow.expand_dims", "tensorflow.cast", "tensorflow.reduce_sum", "tensorflow.cast", "tensorflow.equal", "tensorflow.clip_by_value"], "methods", ["None"], ["", "", "def", "_build_marginal_proba_op", "(", "self", ")", ":", "\n", "    ", "with", "tf", ".", "name_scope", "(", "\"gold_label_prob\"", ")", ":", "\n", "# 1D: batch_size, 2D: max_num_spans, 3D: 1", "\n", "      ", "tags", "=", "tf", ".", "expand_dims", "(", "tf", ".", "cast", "(", "self", ".", "tags", ",", "dtype", "=", "tf", ".", "float32", ")", ",", "axis", "=", "2", ")", "\n", "# 1D: batch_size, 2D: max_num_spans, 3D: num_instances", "\n", "gold_label_mask", "=", "tf", ".", "cast", "(", "\n", "tf", ".", "equal", "(", "self", ".", "neighbor_tags", ",", "tags", ")", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "# 1D: batch_size, 2D: max_num_spans, 3D: num_instances", "\n", "proba", "=", "self", ".", "neighbor_proba", "*", "gold_label_mask", "\n", "# 1D: batch_size, 2D: max_num_spans", "\n", "self", ".", "gold_label_proba", "=", "tf", ".", "reduce_sum", "(", "\n", "tf", ".", "clip_by_value", "(", "proba", ",", "1e-10", ",", "1.0", ")", ",", "axis", "=", "2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.models.knn_models.KnnModel._build_knn_loss_op": [[99, 105], ["tensorflow.name_scope", "tensorflow.math.log", "tensorflow.summary.scalar", "tensorflow.reduce_mean", "tensorflow.reduce_sum"], "methods", ["None"], ["", "", "def", "_build_knn_loss_op", "(", "self", ")", ":", "\n", "    ", "with", "tf", ".", "name_scope", "(", "\"loss\"", ")", ":", "\n", "# 1D: batch_size, 2D: max_num_spans", "\n", "      ", "self", ".", "losses", "=", "tf", ".", "math", ".", "log", "(", "self", ".", "gold_label_proba", ")", "\n", "self", ".", "loss", "=", "-", "tf", ".", "reduce_mean", "(", "tf", ".", "reduce_sum", "(", "self", ".", "losses", ",", "axis", "=", "-", "1", ")", ")", "\n", "tf", ".", "summary", ".", "scalar", "(", "\"loss\"", ",", "self", ".", "loss", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.models.knn_models.KnnModel._build_one_nn_predict_op": [[106, 112], ["tensorflow.name_scope", "tensorflow.argmax", "tensorflow.gather", "tensorflow.reshape", "tensorflow.shape"], "methods", ["None"], ["", "", "def", "_build_one_nn_predict_op", "(", "self", ")", ":", "\n", "    ", "with", "tf", ".", "name_scope", "(", "\"prediction\"", ")", ":", "\n", "      ", "neighbor_indices", "=", "tf", ".", "argmax", "(", "self", ".", "similarity", ",", "axis", "=", "2", ")", "\n", "knn_predicts", "=", "tf", ".", "gather", "(", "self", ".", "neighbor_tags", ",", "neighbor_indices", ")", "\n", "self", ".", "predicts", "=", "tf", ".", "reshape", "(", "knn_predicts", ",", "\n", "shape", "=", "(", "tf", ".", "shape", "(", "self", ".", "words", ")", "[", "0", "]", ",", "-", "1", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.models.knn_models.KnnModel._build_max_marginal_predict_op": [[113, 125], ["tensorflow.name_scope", "tensorflow.reshape", "tensorflow.expand_dims", "tensorflow.reduce_sum", "tensorflow.argmax"], "methods", ["None"], ["", "", "def", "_build_max_marginal_predict_op", "(", "self", ")", ":", "\n", "    ", "with", "tf", ".", "name_scope", "(", "\"prediction\"", ")", ":", "\n", "# 1D: 1, 2D: 1, 3D: num_instances, 4D: num_tags", "\n", "      ", "one_hot_tags", "=", "tf", ".", "reshape", "(", "self", ".", "neighbor_tag_one_hots", ",", "\n", "shape", "=", "[", "1", ",", "1", ",", "-", "1", ",", "self", ".", "tag_vocab_size", "]", ")", "\n", "# 1D: batch_size, 2D: max_num_spans, 3D: num_instances, 4D: 1", "\n", "proba", "=", "tf", ".", "expand_dims", "(", "self", ".", "neighbor_proba", ",", "axis", "=", "3", ")", "\n", "# 1D: batch_size, 2D: max_num_spans, 3D: num_instances, 4D: num_tags", "\n", "proba", "=", "proba", "*", "one_hot_tags", "\n", "# 1D: batch_size, 2D: max_num_spans, 3D: num_tags", "\n", "self", ".", "marginal_proba", "=", "tf", ".", "reduce_sum", "(", "proba", ",", "axis", "=", "2", ")", "\n", "self", ".", "predicts", "=", "tf", ".", "argmax", "(", "self", ".", "marginal_proba", ",", "axis", "=", "2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.models.knn_models.KnnModel._build_model_op": [[126, 136], ["knn_models.KnnModel._build_rnn_op", "knn_models.KnnModel._make_span_indices", "knn_models.KnnModel._build_span_projection_op", "knn_models.KnnModel._build_neighbor_similarity_op", "knn_models.KnnModel._build_neighbor_proba_op", "knn_models.KnnModel._build_span_minus_op", "knn_models.KnnModel._build_span_add_and_minus_op"], "methods", ["home.repos.pwc.inspect_result.hiroki13_instance-based-ner.models.span_models.MaskSpanModel._build_rnn_op", "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.models.span_models.SpanModel._make_span_indices", "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.models.span_models.SpanModel._build_span_projection_op", "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.models.knn_models.KnnModel._build_neighbor_similarity_op", "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.models.knn_models.KnnModel._build_neighbor_proba_op", "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.models.span_models.SpanModel._build_span_minus_op", "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.models.span_models.SpanModel._build_span_add_and_minus_op"], ["", "", "def", "_build_model_op", "(", "self", ")", ":", "\n", "    ", "self", ".", "_build_rnn_op", "(", ")", "\n", "self", ".", "_make_span_indices", "(", ")", "\n", "if", "self", ".", "cfg", "[", "\"bilstm_type\"", "]", "==", "\"minus\"", ":", "\n", "      ", "self", ".", "_build_span_minus_op", "(", ")", "\n", "", "else", ":", "\n", "      ", "self", ".", "_build_span_add_and_minus_op", "(", ")", "\n", "", "self", ".", "_build_span_projection_op", "(", ")", "\n", "self", ".", "_build_neighbor_similarity_op", "(", ")", "\n", "self", ".", "_build_neighbor_proba_op", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.models.knn_models.KnnModel._build_loss_op": [[137, 140], ["knn_models.KnnModel._build_marginal_proba_op", "knn_models.KnnModel._build_knn_loss_op"], "methods", ["home.repos.pwc.inspect_result.hiroki13_instance-based-ner.models.knn_models.KnnModel._build_marginal_proba_op", "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.models.knn_models.KnnModel._build_knn_loss_op"], ["", "def", "_build_loss_op", "(", "self", ")", ":", "\n", "    ", "self", ".", "_build_marginal_proba_op", "(", ")", "\n", "self", ".", "_build_knn_loss_op", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.models.knn_models.KnnModel._build_predict_op": [[141, 146], ["knn_models.KnnModel._build_one_nn_predict_op", "knn_models.KnnModel._build_max_marginal_predict_op"], "methods", ["home.repos.pwc.inspect_result.hiroki13_instance-based-ner.models.knn_models.KnnModel._build_one_nn_predict_op", "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.models.knn_models.KnnModel._build_max_marginal_predict_op"], ["", "def", "_build_predict_op", "(", "self", ")", ":", "\n", "    ", "if", "self", ".", "cfg", "[", "\"predict\"", "]", "==", "\"one_nn\"", ":", "\n", "      ", "self", ".", "_build_one_nn_predict_op", "(", ")", "\n", "", "else", ":", "\n", "      ", "self", ".", "_build_max_marginal_predict_op", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.models.knn_models.KnnModel.get_neighbor_batch": [[147, 150], ["knn_models.KnnModel.batcher.batchnize_neighbor_train_sents"], "methods", ["home.repos.pwc.inspect_result.hiroki13_instance-based-ner.batchers.knn_batchers.BaseKnnBatcher.batchnize_neighbor_train_sents"], ["", "", "def", "get_neighbor_batch", "(", "self", ",", "train_sents", ",", "train_sent_ids", ")", ":", "\n", "    ", "return", "self", ".", "batcher", ".", "batchnize_neighbor_train_sents", "(", "\n", "train_sents", ",", "train_sent_ids", ",", "self", ".", "max_span_len", ",", "self", ".", "max_n_spans", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.models.knn_models.KnnModel.get_neighbor_reps_and_tags": [[151, 154], ["knn_models.KnnModel.batcher.batchnize_span_reps_and_tags"], "methods", ["home.repos.pwc.inspect_result.hiroki13_instance-based-ner.batchers.knn_batchers.KnnBatcher.batchnize_span_reps_and_tags"], ["", "def", "get_neighbor_reps_and_tags", "(", "self", ",", "span_reps", ",", "batch", ")", ":", "\n", "    ", "return", "self", ".", "batcher", ".", "batchnize_span_reps_and_tags", "(", "\n", "span_reps", ",", "batch", "[", "\"tags\"", "]", ",", "batch", "[", "\"masks\"", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.models.knn_models.KnnModel.get_neighbor_reps_and_tag_one_hots": [[155, 158], ["knn_models.KnnModel.batcher.batchnize_span_reps_and_tag_one_hots"], "methods", ["home.repos.pwc.inspect_result.hiroki13_instance-based-ner.batchers.knn_batchers.KnnBatcher.batchnize_span_reps_and_tag_one_hots"], ["", "def", "get_neighbor_reps_and_tag_one_hots", "(", "self", ",", "span_reps", ",", "batch", ")", ":", "\n", "    ", "return", "self", ".", "batcher", ".", "batchnize_span_reps_and_tag_one_hots", "(", "\n", "span_reps", ",", "batch", "[", "\"tags\"", "]", ",", "batch", "[", "\"masks\"", "]", ",", "self", ".", "tag_vocab_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.models.knn_models.KnnModel.make_one_batch_for_target": [[159, 167], ["knn_models.KnnModel.batcher.make_each_batch_for_targets"], "methods", ["home.repos.pwc.inspect_result.hiroki13_instance-based-ner.batchers.knn_batchers.BaseKnnBatcher.make_each_batch_for_targets"], ["", "def", "make_one_batch_for_target", "(", "self", ",", "data", ",", "sent_id", ",", "add_tags", "=", "True", ")", ":", "\n", "    ", "return", "self", ".", "batcher", ".", "make_each_batch_for_targets", "(", "\n", "batch_words", "=", "[", "data", "[", "\"words\"", "]", "]", ",", "\n", "batch_chars", "=", "[", "data", "[", "\"chars\"", "]", "]", ",", "\n", "batch_ids", "=", "[", "sent_id", "]", ",", "\n", "max_span_len", "=", "self", ".", "max_span_len", ",", "\n", "max_n_spans", "=", "0", ",", "\n", "batch_tags", "=", "[", "data", "[", "\"tags\"", "]", "]", "if", "add_tags", "else", "None", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.models.knn_models.KnnModel._add_neighbor_instances_to_batch": [[168, 194], ["knn_models.KnnModel.get_neighbor_batch", "knn_models.KnnModel._get_feed_dict", "random.shuffle", "knn_models.KnnModel.sess.run", "knn_models.KnnModel.get_neighbor_reps_and_tags", "knn_models.KnnModel.get_neighbor_reps_and_tag_one_hots", "list", "set", "set"], "methods", ["home.repos.pwc.inspect_result.hiroki13_instance-based-ner.models.knn_models.KnnModel.get_neighbor_batch", "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.models.base_model.BaseModel._get_feed_dict", "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.models.knn_models.KnnModel.get_neighbor_reps_and_tags", "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.models.knn_models.KnnModel.get_neighbor_reps_and_tag_one_hots"], ["", "def", "_add_neighbor_instances_to_batch", "(", "self", ",", "batch", ",", "train_sents", ",", "\n", "train_sent_ids", ",", "is_train", ")", ":", "\n", "    ", "if", "train_sent_ids", ":", "\n", "      ", "if", "is_train", ":", "\n", "        ", "train_sent_ids", "=", "list", "(", "set", "(", "train_sent_ids", ")", "-", "set", "(", "batch", "[", "\"instance_ids\"", "]", ")", ")", "\n", "", "random", ".", "shuffle", "(", "train_sent_ids", ")", "\n", "", "else", ":", "\n", "      ", "train_sent_ids", "=", "batch", "[", "\"train_sent_ids\"", "]", "\n", "\n", "", "neighbor_batch", "=", "self", ".", "get_neighbor_batch", "(", "train_sents", ",", "\n", "train_sent_ids", "[", ":", "self", ".", "cfg", "[", "\"k\"", "]", "]", ")", "\n", "feed_dict", "=", "self", ".", "_get_feed_dict", "(", "neighbor_batch", ")", "\n", "span_reps", "=", "self", ".", "sess", ".", "run", "(", "[", "self", ".", "span_rep", "]", ",", "feed_dict", ")", "[", "0", "]", "\n", "\n", "if", "is_train", "or", "self", ".", "cfg", "[", "\"predict\"", "]", "==", "\"one_nn\"", ":", "\n", "      ", "rep_list", ",", "tag_list", "=", "self", ".", "get_neighbor_reps_and_tags", "(", "\n", "span_reps", ",", "neighbor_batch", ")", "\n", "batch", "[", "\"neighbor_reps\"", "]", "=", "rep_list", "\n", "batch", "[", "\"neighbor_tags\"", "]", "=", "tag_list", "\n", "", "else", ":", "\n", "      ", "rep_list", ",", "tag_list", "=", "self", ".", "get_neighbor_reps_and_tag_one_hots", "(", "\n", "span_reps", ",", "neighbor_batch", ")", "\n", "batch", "[", "\"neighbor_reps\"", "]", "=", "rep_list", "\n", "batch", "[", "\"neighbor_tag_one_hots\"", "]", "=", "tag_list", "\n", "\n", "", "return", "batch", "\n", "\n"]], "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.models.knn_models.KnnModel._make_batch_and_sample_sent_ids": [[195, 213], ["knn_models.KnnModel.batcher.make_batch_from_sent_ids", "knn_models.KnnModel._get_feed_dict", "knn_models.KnnModel.get_neighbor_reps_and_tag_one_hots", "random.shuffle", "knn_models.KnnModel.sess.run"], "methods", ["home.repos.pwc.inspect_result.hiroki13_instance-based-ner.batchers.knn_batchers.BaseKnnBatcher.make_batch_from_sent_ids", "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.models.base_model.BaseModel._get_feed_dict", "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.models.knn_models.KnnModel.get_neighbor_reps_and_tag_one_hots"], ["", "def", "_make_batch_and_sample_sent_ids", "(", "self", ",", "batch", ",", "valid_record", ",", "train_sents", ",", "\n", "train_sent_ids", ")", ":", "\n", "    ", "if", "train_sent_ids", ":", "\n", "      ", "random", ".", "shuffle", "(", "train_sent_ids", ")", "\n", "sampled_train_sent_ids", "=", "train_sent_ids", "[", ":", "self", ".", "cfg", "[", "\"k\"", "]", "]", "\n", "", "else", ":", "\n", "      ", "sampled_train_sent_ids", "=", "valid_record", "[", "\"train_sent_ids\"", "]", "[", ":", "self", ".", "cfg", "[", "\"k\"", "]", "]", "\n", "\n", "", "train_batch", "=", "self", ".", "batcher", ".", "make_batch_from_sent_ids", "(", "train_sents", ",", "\n", "sampled_train_sent_ids", ")", "\n", "feed_dict", "=", "self", ".", "_get_feed_dict", "(", "train_batch", ")", "\n", "span_reps", "=", "self", ".", "sess", ".", "run", "(", "[", "self", ".", "span_rep", "]", ",", "feed_dict", ")", "[", "0", "]", "\n", "rep_list", ",", "tag_list", "=", "self", ".", "get_neighbor_reps_and_tag_one_hots", "(", "span_reps", ",", "\n", "train_batch", ")", "\n", "batch", "[", "\"neighbor_reps\"", "]", "=", "rep_list", "\n", "batch", "[", "\"neighbor_tag_one_hots\"", "]", "=", "tag_list", "\n", "\n", "return", "batch", ",", "sampled_train_sent_ids", "\n", "\n"]], "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.models.knn_models.KnnModel.train_knn_epoch": [[214, 254], ["time.time", "utils.common.load_json", "knn_models.KnnModel.logger.info", "knn_models.KnnModel.logger.info", "knn_models.KnnModel._add_neighbor_instances_to_batch", "knn_models.KnnModel._get_feed_dict", "knn_models.KnnModel.sess.run", "math.isnan", "print", "knn_models.KnnModel.logger.info", "exit", "range", "time.time", "len"], "methods", ["home.repos.pwc.inspect_result.hiroki13_instance-based-ner.scripts.retrieve_knn_sents_with_glove.load_json", "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.models.knn_models.KnnModel._add_neighbor_instances_to_batch", "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.models.base_model.BaseModel._get_feed_dict"], ["", "def", "train_knn_epoch", "(", "self", ",", "batches", ",", "name", ")", ":", "\n", "    ", "loss_total", "=", "0.", "\n", "num_batches", "=", "0", "\n", "start_time", "=", "time", ".", "time", "(", ")", "\n", "train_sents", "=", "load_json", "(", "self", ".", "cfg", "[", "\"train_set\"", "]", ")", "\n", "if", "self", ".", "cfg", "[", "\"knn_sampling\"", "]", "==", "\"random\"", ":", "\n", "      ", "train_sent_ids", "=", "[", "sent_id", "for", "sent_id", "in", "range", "(", "len", "(", "train_sents", ")", ")", "]", "\n", "", "else", ":", "\n", "      ", "train_sent_ids", "=", "None", "\n", "\n", "", "for", "batch", "in", "batches", ":", "\n", "      ", "num_batches", "+=", "1", "\n", "if", "num_batches", "%", "100", "==", "0", ":", "\n", "        ", "print", "(", "\"%d\"", "%", "num_batches", ",", "flush", "=", "True", ",", "end", "=", "\" \"", ")", "\n", "\n", "# Setup a batch", "\n", "", "batch", "=", "self", ".", "_add_neighbor_instances_to_batch", "(", "batch", ",", "\n", "train_sents", ",", "\n", "train_sent_ids", ",", "\n", "is_train", "=", "True", ")", "\n", "# Convert a batch to the input format", "\n", "feed_dict", "=", "self", ".", "_get_feed_dict", "(", "batch", ",", "\n", "is_train", "=", "True", ",", "\n", "keep_prob", "=", "self", ".", "cfg", "[", "\"keep_prob\"", "]", ",", "\n", "lr", "=", "self", ".", "cfg", "[", "\"lr\"", "]", ")", "\n", "# Train a model", "\n", "_", ",", "train_loss", "=", "self", ".", "sess", ".", "run", "(", "[", "self", ".", "train_op", ",", "self", ".", "loss", "]", ",", "\n", "feed_dict", ")", "\n", "\n", "if", "math", ".", "isnan", "(", "train_loss", ")", ":", "\n", "        ", "self", ".", "logger", ".", "info", "(", "\"\\n\\n\\nNAN: Index: %d\\n\"", "%", "num_batches", ")", "\n", "exit", "(", ")", "\n", "\n", "", "loss_total", "+=", "train_loss", "\n", "\n", "", "avg_loss", "=", "loss_total", "/", "num_batches", "\n", "self", ".", "logger", ".", "info", "(", "\"-- Time: %f seconds\"", "%", "(", "time", ".", "time", "(", ")", "-", "start_time", ")", ")", "\n", "self", ".", "logger", ".", "info", "(", "\n", "\"-- Averaged loss: %f(%f/%d)\"", "%", "(", "avg_loss", ",", "loss_total", ",", "num_batches", ")", ")", "\n", "return", "avg_loss", ",", "loss_total", "\n", "\n"]], "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.models.knn_models.KnnModel.evaluate_knn_epoch": [[255, 293], ["time.time", "utils.common.load_json", "utils.data_utils.f_score", "knn_models.KnnModel.logger.info", "knn_models.KnnModel.logger.info", "knn_models.KnnModel._add_neighbor_instances_to_batch", "knn_models.KnnModel._get_feed_dict", "utils.data_utils.count_gold_and_system_outputs", "print", "knn_models.KnnModel.sess.run", "range", "time.time", "len"], "methods", ["home.repos.pwc.inspect_result.hiroki13_instance-based-ner.scripts.retrieve_knn_sents_with_glove.load_json", "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.utils.data_utils.f_score", "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.models.knn_models.KnnModel._add_neighbor_instances_to_batch", "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.models.base_model.BaseModel._get_feed_dict", "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.utils.data_utils.count_gold_and_system_outputs"], ["", "def", "evaluate_knn_epoch", "(", "self", ",", "batches", ",", "name", ")", ":", "\n", "    ", "correct", "=", "0", "\n", "p_total", "=", "0", "\n", "num_batches", "=", "0", "\n", "start_time", "=", "time", ".", "time", "(", ")", "\n", "train_sents", "=", "load_json", "(", "self", ".", "cfg", "[", "\"train_set\"", "]", ")", "\n", "if", "self", ".", "cfg", "[", "\"knn_sampling\"", "]", "==", "\"random\"", ":", "\n", "      ", "train_sent_ids", "=", "[", "sent_id", "for", "sent_id", "in", "range", "(", "len", "(", "train_sents", ")", ")", "]", "\n", "", "else", ":", "\n", "      ", "train_sent_ids", "=", "None", "\n", "\n", "", "for", "batch", "in", "batches", ":", "\n", "      ", "num_batches", "+=", "1", "\n", "if", "num_batches", "%", "100", "==", "0", ":", "\n", "        ", "print", "(", "\"%d\"", "%", "num_batches", ",", "flush", "=", "True", ",", "end", "=", "\" \"", ")", "\n", "\n", "# Setup a batch", "\n", "", "batch", "=", "self", ".", "_add_neighbor_instances_to_batch", "(", "batch", ",", "\n", "train_sents", ",", "\n", "train_sent_ids", ",", "\n", "is_train", "=", "False", ")", "\n", "# Convert a batch to the input format", "\n", "feed_dict", "=", "self", ".", "_get_feed_dict", "(", "batch", ")", "\n", "# Classify spans", "\n", "predicted_tags", "=", "self", ".", "sess", ".", "run", "(", "[", "self", ".", "predicts", "]", ",", "feed_dict", ")", "[", "0", "]", "\n", "\n", "crr_i", ",", "p_total_i", "=", "count_gold_and_system_outputs", "(", "batch", "[", "\"tags\"", "]", ",", "\n", "predicted_tags", ",", "\n", "NULL_LABEL_ID", ")", "\n", "correct", "+=", "crr_i", "\n", "p_total", "+=", "p_total_i", "\n", "\n", "", "p", ",", "r", ",", "f", "=", "f_score", "(", "correct", ",", "p_total", ",", "self", ".", "n_gold_spans", ")", "\n", "self", ".", "logger", ".", "info", "(", "\"-- Time: %f seconds\"", "%", "(", "time", ".", "time", "(", ")", "-", "start_time", ")", ")", "\n", "self", ".", "logger", ".", "info", "(", "\n", "\"-- {} set\\tF:{:>7.2%} P:{:>7.2%} ({:>5}/{:>5}) R:{:>7.2%} ({:>5}/{:>5})\"", "\n", ".", "format", "(", "name", ",", "f", ",", "p", ",", "correct", ",", "p_total", ",", "r", ",", "correct", ",", "self", ".", "n_gold_spans", ")", ")", "\n", "return", "f", ",", "p", ",", "r", ",", "correct", ",", "p_total", ",", "self", ".", "n_gold_spans", "\n", "\n"]], "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.models.knn_models.KnnModel.train": [[294, 351], ["knn_models.KnnModel.logger.info", "os.path.join", "utils.common.write_json", "utils.data_utils.count_gold_spans", "list", "knn_models.KnnModel.log_trainable_variables", "knn_models.KnnModel.logger.info", "knn_models.KnnModel._add_summary", "range", "knn_models.KnnModel.train_writer.close", "knn_models.KnnModel.test_writer.close", "str", "h5py.File", "knn_models.KnnModel.batcher.batchnize_dataset", "knn_models.KnnModel.logger.info", "knn_models.KnnModel.batcher.batchnize_dataset", "knn_models.KnnModel.train_knn_epoch", "knn_models.KnnModel.evaluate_knn_epoch", "os.path.join", "max", "knn_models.KnnModel.save_session", "knn_models.KnnModel.logger.info"], "methods", ["home.repos.pwc.inspect_result.hiroki13_instance-based-ner.scripts.retrieve_knn_sents_with_glove.write_json", "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.utils.data_utils.count_gold_spans", "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.models.base_model.BaseModel.log_trainable_variables", "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.models.base_model.BaseModel._add_summary", "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.batchers.span_batchers.MaskSpanBatcher.batchnize_dataset", "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.batchers.span_batchers.MaskSpanBatcher.batchnize_dataset", "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.models.knn_models.KnnModel.train_knn_epoch", "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.models.knn_models.KnnModel.evaluate_knn_epoch", "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.models.base_model.BaseModel.save_session"], ["", "def", "train", "(", "self", ")", ":", "\n", "    ", "self", ".", "logger", ".", "info", "(", "str", "(", "self", ".", "cfg", ")", ")", "\n", "\n", "config_path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "cfg", "[", "\"checkpoint_path\"", "]", ",", "\"config.json\"", ")", "\n", "write_json", "(", "config_path", ",", "self", ".", "cfg", ")", "\n", "\n", "batch_size", "=", "self", ".", "cfg", "[", "\"batch_size\"", "]", "\n", "epochs", "=", "self", ".", "cfg", "[", "\"epochs\"", "]", "\n", "train_path", "=", "self", ".", "cfg", "[", "\"train_set\"", "]", "\n", "valid_path", "=", "self", ".", "cfg", "[", "\"valid_set\"", "]", "\n", "self", ".", "n_gold_spans", "=", "count_gold_spans", "(", "valid_path", ")", "\n", "\n", "if", "self", ".", "cfg", "[", "\"knn_sampling\"", "]", "==", "\"knn\"", ":", "\n", "      ", "self", ".", "knn_ids", "=", "h5py", ".", "File", "(", "\n", "os", ".", "path", ".", "join", "(", "self", ".", "cfg", "[", "\"raw_path\"", "]", ",", "\"knn_ids.hdf5\"", ")", ",", "\"r\"", ")", "\n", "valid_batch_size", "=", "1", "\n", "shuffle", "=", "False", "\n", "", "else", ":", "\n", "      ", "valid_batch_size", "=", "batch_size", "\n", "shuffle", "=", "True", "\n", "\n", "", "valid_set", "=", "list", "(", "\n", "self", ".", "batcher", ".", "batchnize_dataset", "(", "data", "=", "valid_path", ",", "\n", "data_name", "=", "\"valid\"", ",", "\n", "batch_size", "=", "valid_batch_size", ",", "\n", "shuffle", "=", "shuffle", ")", ")", "\n", "best_f1", "=", "-", "np", ".", "inf", "\n", "init_lr", "=", "self", ".", "cfg", "[", "\"lr\"", "]", "\n", "\n", "self", ".", "log_trainable_variables", "(", ")", "\n", "self", ".", "logger", ".", "info", "(", "\"Start training...\"", ")", "\n", "self", ".", "_add_summary", "(", ")", "\n", "\n", "for", "epoch", "in", "range", "(", "1", ",", "epochs", "+", "1", ")", ":", "\n", "      ", "self", ".", "logger", ".", "info", "(", "'Epoch {}/{}:'", ".", "format", "(", "epoch", ",", "epochs", ")", ")", "\n", "\n", "train_set", "=", "self", ".", "batcher", ".", "batchnize_dataset", "(", "data", "=", "train_path", ",", "\n", "data_name", "=", "\"train\"", ",", "\n", "batch_size", "=", "batch_size", ",", "\n", "shuffle", "=", "True", ")", "\n", "_", "=", "self", ".", "train_knn_epoch", "(", "train_set", ",", "\"train\"", ")", "\n", "\n", "if", "self", ".", "cfg", "[", "\"use_lr_decay\"", "]", ":", "# learning rate decay", "\n", "        ", "self", ".", "cfg", "[", "\"lr\"", "]", "=", "max", "(", "init_lr", "/", "(", "1.0", "+", "self", ".", "cfg", "[", "\"lr_decay\"", "]", "*", "epoch", ")", ",", "\n", "self", ".", "cfg", "[", "\"minimal_lr\"", "]", ")", "\n", "\n", "", "eval_metrics", "=", "self", ".", "evaluate_knn_epoch", "(", "valid_set", ",", "\"valid\"", ")", "\n", "cur_valid_f1", "=", "eval_metrics", "[", "0", "]", "\n", "\n", "if", "cur_valid_f1", ">", "best_f1", ":", "\n", "        ", "best_f1", "=", "cur_valid_f1", "\n", "self", ".", "save_session", "(", "epoch", ")", "\n", "self", ".", "logger", ".", "info", "(", "\n", "'-- new BEST F1 on valid set: {:>7.2%}'", ".", "format", "(", "best_f1", ")", ")", "\n", "\n", "", "", "self", ".", "train_writer", ".", "close", "(", ")", "\n", "self", ".", "test_writer", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.models.knn_models.KnnModel.eval": [[352, 423], ["knn_models.KnnModel.logger.info", "preprocessor.load_dataset", "preprocessor.build_dataset", "os.path.join", "utils.common.write_json", "knn_models.KnnModel.logger.info", "utils.data_utils.count_gold_spans", "utils.common.load_json", "knn_models.KnnModel.logger.info", "time.time", "print", "zip", "utils.data_utils.f_score", "knn_models.KnnModel.logger.info", "knn_models.KnnModel.logger.info", "str", "knn_models.KnnModel.make_one_batch_for_target", "knn_models.KnnModel._make_batch_and_sample_sent_ids", "knn_models.KnnModel._get_feed_dict", "knn_models.KnnModel.sess.run", "utils.data_utils.count_gold_and_system_outputs", "len", "len", "print", "range", "time.time", "len"], "methods", ["home.repos.pwc.inspect_result.hiroki13_instance-based-ner.preprocessors.span_preprocessors.SpanPreprocessor.load_dataset", "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.preprocessors.span_preprocessors.SpanPreprocessor.build_dataset", "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.scripts.retrieve_knn_sents_with_glove.write_json", "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.utils.data_utils.count_gold_spans", "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.scripts.retrieve_knn_sents_with_glove.load_json", "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.utils.data_utils.f_score", "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.models.knn_models.KnnModel.make_one_batch_for_target", "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.models.knn_models.KnnModel._make_batch_and_sample_sent_ids", "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.models.base_model.BaseModel._get_feed_dict", "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.utils.data_utils.count_gold_and_system_outputs"], ["", "def", "eval", "(", "self", ",", "preprocessor", ")", ":", "\n", "    ", "self", ".", "logger", ".", "info", "(", "str", "(", "self", ".", "cfg", ")", ")", "\n", "\n", "########################", "\n", "# Load validation data #", "\n", "########################", "\n", "valid_data", "=", "preprocessor", ".", "load_dataset", "(", "\n", "self", ".", "cfg", "[", "\"data_path\"", "]", ",", "keep_number", "=", "True", ",", "\n", "lowercase", "=", "self", ".", "cfg", "[", "\"char_lowercase\"", "]", ")", "\n", "valid_data", "=", "valid_data", "[", ":", "self", ".", "cfg", "[", "\"data_size\"", "]", "]", "\n", "dataset", "=", "preprocessor", ".", "build_dataset", "(", "valid_data", ",", "\n", "self", ".", "word_dict", ",", "\n", "self", ".", "char_dict", ",", "\n", "self", ".", "tag_dict", ")", "\n", "dataset_path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "cfg", "[", "\"save_path\"", "]", ",", "\"tmp.json\"", ")", "\n", "write_json", "(", "dataset_path", ",", "dataset", ")", "\n", "self", ".", "logger", ".", "info", "(", "\"Valid sentences: {:>7}\"", ".", "format", "(", "len", "(", "dataset", ")", ")", ")", "\n", "self", ".", "n_gold_spans", "=", "count_gold_spans", "(", "dataset_path", ")", "\n", "\n", "######################", "\n", "# Load training data #", "\n", "######################", "\n", "train_sents", "=", "load_json", "(", "self", ".", "cfg", "[", "\"train_set\"", "]", ")", "\n", "if", "self", ".", "cfg", "[", "\"knn_sampling\"", "]", "==", "\"random\"", ":", "\n", "      ", "train_sent_ids", "=", "[", "sent_id", "for", "sent_id", "in", "range", "(", "len", "(", "train_sents", ")", ")", "]", "\n", "", "else", ":", "\n", "      ", "train_sent_ids", "=", "None", "\n", "", "self", ".", "logger", ".", "info", "(", "\"Train sentences: {:>7}\"", ".", "format", "(", "len", "(", "train_sents", ")", ")", ")", "\n", "\n", "#############", "\n", "# Main loop #", "\n", "#############", "\n", "correct", "=", "0", "\n", "p_total", "=", "0", "\n", "start_time", "=", "time", ".", "time", "(", ")", "\n", "\n", "print", "(", "\"PREDICTION START\"", ")", "\n", "for", "record", ",", "data", "in", "zip", "(", "valid_data", ",", "dataset", ")", ":", "\n", "      ", "valid_sent_id", "=", "record", "[", "\"sent_id\"", "]", "\n", "\n", "if", "(", "valid_sent_id", "+", "1", ")", "%", "100", "==", "0", ":", "\n", "        ", "print", "(", "\"%d\"", "%", "(", "valid_sent_id", "+", "1", ")", ",", "flush", "=", "True", ",", "end", "=", "\" \"", ")", "\n", "\n", "", "batch", "=", "self", ".", "make_one_batch_for_target", "(", "data", ",", "valid_sent_id", ")", "\n", "\n", "#####################", "\n", "# Sentence sampling #", "\n", "#####################", "\n", "batch", ",", "sampled_sent_ids", "=", "self", ".", "_make_batch_and_sample_sent_ids", "(", "\n", "batch", ",", "record", ",", "train_sents", ",", "train_sent_ids", ")", "\n", "\n", "##############", "\n", "# Prediction #", "\n", "##############", "\n", "feed_dict", "=", "self", ".", "_get_feed_dict", "(", "batch", ")", "\n", "batch_sims", ",", "batch_preds", "=", "self", ".", "sess", ".", "run", "(", "\n", "[", "self", ".", "similarity", ",", "self", ".", "predicts", "]", ",", "feed_dict", ")", "\n", "\n", "crr_i", ",", "p_total_i", "=", "count_gold_and_system_outputs", "(", "\n", "batch", "[", "\"tags\"", "]", ",", "batch_preds", ",", "NULL_LABEL_ID", ")", "\n", "correct", "+=", "crr_i", "\n", "p_total", "+=", "p_total_i", "\n", "\n", "##############", "\n", "# Evaluation #", "\n", "##############", "\n", "", "p", ",", "r", ",", "f", "=", "f_score", "(", "correct", ",", "p_total", ",", "self", ".", "n_gold_spans", ")", "\n", "self", ".", "logger", ".", "info", "(", "\"-- Time: %f seconds\"", "%", "(", "time", ".", "time", "(", ")", "-", "start_time", ")", ")", "\n", "self", ".", "logger", ".", "info", "(", "\n", "\"-- F:{:>7.2%} P:{:>7.2%} ({:>5}/{:>5}) R:{:>7.2%} ({:>5}/{:>5})\"", "\n", ".", "format", "(", "f", ",", "p", ",", "correct", ",", "p_total", ",", "r", ",", "correct", ",", "self", ".", "n_gold_spans", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.models.knn_models.KnnModel.save_predicted_spans": [[424, 501], ["knn_models.KnnModel.logger.info", "preprocessor.load_dataset", "preprocessor.build_dataset", "os.path.join", "utils.common.write_json", "knn_models.KnnModel.logger.info", "utils.common.load_json", "knn_models.KnnModel.logger.info", "time.time", "print", "zip", "os.path.join", "utils.common.write_json", "knn_models.KnnModel.logger.info", "str", "knn_models.KnnModel.make_one_batch_for_target", "knn_models.KnnModel._make_batch_and_sample_sent_ids", "knn_models.KnnModel._get_feed_dict", "models.decoders.get_span_indices", "results.append", "len", "len", "print", "knn_models.KnnModel.sess.run", "len", "len", "len", "range", "len", "int", "int", "zip", "time.time", "len"], "methods", ["home.repos.pwc.inspect_result.hiroki13_instance-based-ner.preprocessors.span_preprocessors.SpanPreprocessor.load_dataset", "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.preprocessors.span_preprocessors.SpanPreprocessor.build_dataset", "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.scripts.retrieve_knn_sents_with_glove.write_json", "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.scripts.retrieve_knn_sents_with_glove.load_json", "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.scripts.retrieve_knn_sents_with_glove.write_json", "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.models.knn_models.KnnModel.make_one_batch_for_target", "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.models.knn_models.KnnModel._make_batch_and_sample_sent_ids", "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.models.base_model.BaseModel._get_feed_dict", "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.models.decoders.get_span_indices"], ["", "def", "save_predicted_spans", "(", "self", ",", "data_name", ",", "preprocessor", ")", ":", "\n", "    ", "self", ".", "logger", ".", "info", "(", "str", "(", "self", ".", "cfg", ")", ")", "\n", "\n", "########################", "\n", "# Load validation data #", "\n", "########################", "\n", "valid_data", "=", "preprocessor", ".", "load_dataset", "(", "\n", "self", ".", "cfg", "[", "\"data_path\"", "]", ",", "keep_number", "=", "True", ",", "\n", "lowercase", "=", "self", ".", "cfg", "[", "\"char_lowercase\"", "]", ")", "\n", "valid_data", "=", "valid_data", "[", ":", "self", ".", "cfg", "[", "\"data_size\"", "]", "]", "\n", "dataset", "=", "preprocessor", ".", "build_dataset", "(", "valid_data", ",", "\n", "self", ".", "word_dict", ",", "\n", "self", ".", "char_dict", ",", "\n", "self", ".", "tag_dict", ")", "\n", "dataset_path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "cfg", "[", "\"save_path\"", "]", ",", "\"tmp.json\"", ")", "\n", "write_json", "(", "dataset_path", ",", "dataset", ")", "\n", "self", ".", "logger", ".", "info", "(", "\"Valid sentences: {:>7}\"", ".", "format", "(", "len", "(", "dataset", ")", ")", ")", "\n", "\n", "######################", "\n", "# Load training data #", "\n", "######################", "\n", "train_sents", "=", "load_json", "(", "self", ".", "cfg", "[", "\"train_set\"", "]", ")", "\n", "if", "self", ".", "cfg", "[", "\"knn_sampling\"", "]", "==", "\"random\"", ":", "\n", "      ", "train_sent_ids", "=", "[", "sent_id", "for", "sent_id", "in", "range", "(", "len", "(", "train_sents", ")", ")", "]", "\n", "", "else", ":", "\n", "      ", "train_sent_ids", "=", "None", "\n", "", "self", ".", "logger", ".", "info", "(", "\"Train sentences: {:>7}\"", ".", "format", "(", "len", "(", "train_sents", ")", ")", ")", "\n", "\n", "#############", "\n", "# Main loop #", "\n", "#############", "\n", "start_time", "=", "time", ".", "time", "(", ")", "\n", "results", "=", "[", "]", "\n", "print", "(", "\"PREDICTION START\"", ")", "\n", "for", "record", ",", "data", "in", "zip", "(", "valid_data", ",", "dataset", ")", ":", "\n", "      ", "valid_sent_id", "=", "record", "[", "\"sent_id\"", "]", "\n", "batch", "=", "self", ".", "make_one_batch_for_target", "(", "data", ",", "valid_sent_id", ",", "\n", "add_tags", "=", "False", ")", "\n", "if", "(", "valid_sent_id", "+", "1", ")", "%", "100", "==", "0", ":", "\n", "        ", "print", "(", "\"%d\"", "%", "(", "valid_sent_id", "+", "1", ")", ",", "flush", "=", "True", ",", "end", "=", "\" \"", ")", "\n", "\n", "#####################", "\n", "# Sentence sampling #", "\n", "#####################", "\n", "", "batch", ",", "sampled_sent_ids", "=", "self", ".", "_make_batch_and_sample_sent_ids", "(", "\n", "batch", ",", "record", ",", "train_sents", ",", "train_sent_ids", ")", "\n", "\n", "###############", "\n", "# KNN predict #", "\n", "###############", "\n", "feed_dict", "=", "self", ".", "_get_feed_dict", "(", "batch", ")", "\n", "batch_preds", "=", "self", ".", "sess", ".", "run", "(", "[", "self", ".", "predicts", "]", ",", "feed_dict", ")", "[", "0", "]", "\n", "preds", "=", "batch_preds", "[", "0", "]", "\n", "\n", "########################", "\n", "# Make predicted spans #", "\n", "########################", "\n", "indx_i", ",", "indx_j", "=", "get_span_indices", "(", "n_words", "=", "len", "(", "record", "[", "\"words\"", "]", ")", ",", "\n", "max_span_len", "=", "self", ".", "max_span_len", ")", "\n", "assert", "len", "(", "preds", ")", "==", "len", "(", "indx_i", ")", "==", "len", "(", "indx_j", ")", "\n", "pred_spans", "=", "[", "[", "self", ".", "rev_tag_dict", "[", "pred_label_id", "]", ",", "int", "(", "i", ")", ",", "int", "(", "j", ")", "]", "\n", "for", "pred_label_id", ",", "i", ",", "j", "in", "zip", "(", "preds", ",", "indx_i", ",", "indx_j", ")", "\n", "if", "pred_label_id", "!=", "NULL_LABEL_ID", "]", "\n", "\n", "##################", "\n", "# Add the result #", "\n", "##################", "\n", "results", ".", "append", "(", "{", "\"sent_id\"", ":", "valid_sent_id", ",", "\n", "\"words\"", ":", "record", "[", "\"words\"", "]", ",", "\n", "\"spans\"", ":", "pred_spans", ",", "\n", "\"train_sent_ids\"", ":", "sampled_sent_ids", "}", ")", "\n", "\n", "", "path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "cfg", "[", "\"checkpoint_path\"", "]", ",", "\n", "\"%s.predicted_spans.json\"", "%", "data_name", ")", "\n", "write_json", "(", "path", ",", "results", ")", "\n", "self", ".", "logger", ".", "info", "(", "\n", "\"-- Time: %f seconds\\nFINISHED.\"", "%", "(", "time", ".", "time", "(", ")", "-", "start_time", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.models.knn_models.KnnModel.save_predicted_bio_tags": [[502, 580], ["knn_models.KnnModel.logger.info", "preprocessor.load_dataset", "preprocessor.build_dataset", "os.path.join", "utils.common.write_json", "knn_models.KnnModel.logger.info", "utils.common.load_json", "knn_models.KnnModel.logger.info", "time.time", "os.path.join", "open", "print", "zip", "knn_models.KnnModel.logger.info", "str", "knn_models.KnnModel.make_one_batch_for_target", "knn_models.KnnModel._make_batch_and_sample_sent_ids", "knn_models.KnnModel._get_feed_dict", "models.decoders.greedy_search", "utils.data_utils.span2bio", "utils.data_utils.span2bio", "zip", "open.write", "len", "len", "print", "len", "len", "len", "open.write", "range", "knn_models.KnnModel.sess.run", "len", "len", "len", "time.time", "len"], "methods", ["home.repos.pwc.inspect_result.hiroki13_instance-based-ner.preprocessors.span_preprocessors.SpanPreprocessor.load_dataset", "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.preprocessors.span_preprocessors.SpanPreprocessor.build_dataset", "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.scripts.retrieve_knn_sents_with_glove.write_json", "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.scripts.retrieve_knn_sents_with_glove.load_json", "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.models.knn_models.KnnModel.make_one_batch_for_target", "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.models.knn_models.KnnModel._make_batch_and_sample_sent_ids", "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.models.base_model.BaseModel._get_feed_dict", "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.models.decoders.greedy_search", "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.utils.data_utils.span2bio", "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.utils.data_utils.span2bio"], ["", "def", "save_predicted_bio_tags", "(", "self", ",", "data_name", ",", "preprocessor", ")", ":", "\n", "    ", "self", ".", "logger", ".", "info", "(", "str", "(", "self", ".", "cfg", ")", ")", "\n", "\n", "########################", "\n", "# Load validation data #", "\n", "########################", "\n", "valid_data", "=", "preprocessor", ".", "load_dataset", "(", "\n", "self", ".", "cfg", "[", "\"data_path\"", "]", ",", "keep_number", "=", "True", ",", "\n", "lowercase", "=", "self", ".", "cfg", "[", "\"char_lowercase\"", "]", ")", "\n", "valid_data", "=", "valid_data", "[", ":", "self", ".", "cfg", "[", "\"data_size\"", "]", "]", "\n", "dataset", "=", "preprocessor", ".", "build_dataset", "(", "valid_data", ",", "\n", "self", ".", "word_dict", ",", "\n", "self", ".", "char_dict", ",", "\n", "self", ".", "tag_dict", ")", "\n", "dataset_path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "cfg", "[", "\"save_path\"", "]", ",", "\"tmp.json\"", ")", "\n", "write_json", "(", "dataset_path", ",", "dataset", ")", "\n", "self", ".", "logger", ".", "info", "(", "\"Valid sentences: {:>7}\"", ".", "format", "(", "len", "(", "dataset", ")", ")", ")", "\n", "\n", "######################", "\n", "# Load training data #", "\n", "######################", "\n", "train_sents", "=", "load_json", "(", "self", ".", "cfg", "[", "\"train_set\"", "]", ")", "\n", "if", "self", ".", "cfg", "[", "\"knn_sampling\"", "]", "==", "\"random\"", ":", "\n", "      ", "train_sent_ids", "=", "[", "sent_id", "for", "sent_id", "in", "range", "(", "len", "(", "train_sents", ")", ")", "]", "\n", "", "else", ":", "\n", "      ", "train_sent_ids", "=", "None", "\n", "", "self", ".", "logger", ".", "info", "(", "\"Train sentences: {:>7}\"", ".", "format", "(", "len", "(", "train_sents", ")", ")", ")", "\n", "\n", "#############", "\n", "# Main loop #", "\n", "#############", "\n", "start_time", "=", "time", ".", "time", "(", ")", "\n", "path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "cfg", "[", "\"checkpoint_path\"", "]", ",", "\"%s.bio.txt\"", "%", "data_name", ")", "\n", "fout_txt", "=", "open", "(", "path", ",", "\"w\"", ")", "\n", "print", "(", "\"PREDICTION START\"", ")", "\n", "for", "record", ",", "data", "in", "zip", "(", "valid_data", ",", "dataset", ")", ":", "\n", "      ", "valid_sent_id", "=", "record", "[", "\"sent_id\"", "]", "\n", "batch", "=", "self", ".", "make_one_batch_for_target", "(", "data", ",", "valid_sent_id", ",", "\n", "add_tags", "=", "False", ")", "\n", "if", "(", "valid_sent_id", "+", "1", ")", "%", "100", "==", "0", ":", "\n", "        ", "print", "(", "\"%d\"", "%", "(", "valid_sent_id", "+", "1", ")", ",", "flush", "=", "True", ",", "end", "=", "\" \"", ")", "\n", "\n", "#####################", "\n", "# Sentence sampling #", "\n", "#####################", "\n", "", "batch", ",", "sampled_sent_ids", "=", "self", ".", "_make_batch_and_sample_sent_ids", "(", "\n", "batch", ",", "record", ",", "train_sents", ",", "train_sent_ids", ")", "\n", "\n", "###############", "\n", "# KNN predict #", "\n", "###############", "\n", "feed_dict", "=", "self", ".", "_get_feed_dict", "(", "batch", ")", "\n", "proba", "=", "self", ".", "sess", ".", "run", "(", "[", "self", ".", "marginal_proba", "]", ",", "feed_dict", ")", "[", "0", "]", "[", "0", "]", "\n", "\n", "########################", "\n", "# Make predicted spans #", "\n", "########################", "\n", "words", "=", "record", "[", "\"words\"", "]", "\n", "triples", "=", "greedy_search", "(", "proba", ",", "\n", "n_words", "=", "len", "(", "words", ")", ",", "\n", "max_span_len", "=", "self", ".", "max_span_len", ",", "\n", "null_label_id", "=", "NULL_LABEL_ID", ")", "\n", "pred_bio_tags", "=", "span2bio", "(", "spans", "=", "triples", ",", "\n", "n_words", "=", "len", "(", "words", ")", ",", "\n", "tag_dict", "=", "self", ".", "rev_tag_dict", ")", "\n", "gold_bio_tags", "=", "span2bio", "(", "spans", "=", "record", "[", "\"tags\"", "]", ",", "\n", "n_words", "=", "len", "(", "words", ")", ")", "\n", "assert", "len", "(", "words", ")", "==", "len", "(", "pred_bio_tags", ")", "==", "len", "(", "gold_bio_tags", ")", "\n", "\n", "####################", "\n", "# Write the result #", "\n", "####################", "\n", "for", "word", ",", "gold_tag", ",", "pred_tag", "in", "zip", "(", "words", ",", "gold_bio_tags", ",", "pred_bio_tags", ")", ":", "\n", "        ", "fout_txt", ".", "write", "(", "\"%s _ %s %s\\n\"", "%", "(", "word", ",", "gold_tag", ",", "pred_tag", ")", ")", "\n", "", "fout_txt", ".", "write", "(", "\"\\n\"", ")", "\n", "\n", "", "self", ".", "logger", ".", "info", "(", "\n", "\"-- Time: %f seconds\\nFINISHED.\"", "%", "(", "time", ".", "time", "(", ")", "-", "start_time", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.models.knn_models.KnnModel.save_nearest_spans": [[581, 664], ["knn_models.KnnModel.logger.info", "preprocessor.load_dataset", "preprocessor.build_dataset", "os.path.join", "utils.common.write_json", "knn_models.KnnModel.logger.info", "utils.data_utils.count_gold_spans", "utils.common.load_json", "preprocessor.load_dataset", "knn_models.KnnModel.logger.info", "time.time", "os.path.join", "open", "print", "zip", "open.close", "utils.data_utils.f_score", "knn_models.KnnModel.logger.info", "knn_models.KnnModel.logger.info", "str", "os.path.join", "knn_models.KnnModel.make_one_batch_for_target", "knn_models.KnnModel._make_batch_and_sample_sent_ids", "knn_models.KnnModel._get_feed_dict", "knn_models.KnnModel.sess.run", "utils.data_utils.count_gold_and_system_outputs", "knn_models.KnnModel._write_predictions", "knn_models.KnnModel._write_nearest_spans", "len", "len", "print", "range", "time.time", "len"], "methods", ["home.repos.pwc.inspect_result.hiroki13_instance-based-ner.preprocessors.span_preprocessors.SpanPreprocessor.load_dataset", "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.preprocessors.span_preprocessors.SpanPreprocessor.build_dataset", "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.scripts.retrieve_knn_sents_with_glove.write_json", "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.utils.data_utils.count_gold_spans", "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.scripts.retrieve_knn_sents_with_glove.load_json", "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.preprocessors.span_preprocessors.SpanPreprocessor.load_dataset", "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.utils.data_utils.f_score", "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.models.knn_models.KnnModel.make_one_batch_for_target", "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.models.knn_models.KnnModel._make_batch_and_sample_sent_ids", "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.models.base_model.BaseModel._get_feed_dict", "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.utils.data_utils.count_gold_and_system_outputs", "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.models.knn_models.KnnModel._write_predictions", "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.models.knn_models.KnnModel._write_nearest_spans"], ["", "def", "save_nearest_spans", "(", "self", ",", "data_name", ",", "preprocessor", ",", "print_knn", ")", ":", "\n", "    ", "self", ".", "logger", ".", "info", "(", "str", "(", "self", ".", "cfg", ")", ")", "\n", "\n", "########################", "\n", "# Load validation data #", "\n", "########################", "\n", "valid_data", "=", "preprocessor", ".", "load_dataset", "(", "\n", "self", ".", "cfg", "[", "\"data_path\"", "]", ",", "keep_number", "=", "True", ",", "\n", "lowercase", "=", "self", ".", "cfg", "[", "\"char_lowercase\"", "]", ")", "\n", "valid_data", "=", "valid_data", "[", ":", "self", ".", "cfg", "[", "\"data_size\"", "]", "]", "\n", "dataset", "=", "preprocessor", ".", "build_dataset", "(", "valid_data", ",", "\n", "self", ".", "word_dict", ",", "\n", "self", ".", "char_dict", ",", "\n", "self", ".", "tag_dict", ")", "\n", "dataset_path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "cfg", "[", "\"save_path\"", "]", ",", "\"tmp.json\"", ")", "\n", "write_json", "(", "dataset_path", ",", "dataset", ")", "\n", "self", ".", "logger", ".", "info", "(", "\"Valid sentences: {:>7}\"", ".", "format", "(", "len", "(", "dataset", ")", ")", ")", "\n", "self", ".", "n_gold_spans", "=", "count_gold_spans", "(", "dataset_path", ")", "\n", "\n", "######################", "\n", "# Load training data #", "\n", "######################", "\n", "train_sents", "=", "load_json", "(", "self", ".", "cfg", "[", "\"train_set\"", "]", ")", "\n", "if", "self", ".", "cfg", "[", "\"knn_sampling\"", "]", "==", "\"random\"", ":", "\n", "      ", "train_sent_ids", "=", "[", "sent_id", "for", "sent_id", "in", "range", "(", "len", "(", "train_sents", ")", ")", "]", "\n", "", "else", ":", "\n", "      ", "train_sent_ids", "=", "None", "\n", "", "train_data", "=", "preprocessor", ".", "load_dataset", "(", "\n", "os", ".", "path", ".", "join", "(", "self", ".", "cfg", "[", "\"raw_path\"", "]", ",", "\"train.json\"", ")", ",", "\n", "keep_number", "=", "True", ",", "lowercase", "=", "False", ")", "\n", "self", ".", "logger", ".", "info", "(", "\"Train sentences: {:>7}\"", ".", "format", "(", "len", "(", "train_sents", ")", ")", ")", "\n", "\n", "#############", "\n", "# Main loop #", "\n", "#############", "\n", "correct", "=", "0", "\n", "p_total", "=", "0", "\n", "start_time", "=", "time", ".", "time", "(", ")", "\n", "file_path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "cfg", "[", "\"checkpoint_path\"", "]", ",", "\n", "\"%s.nearest_spans.txt\"", "%", "data_name", ")", "\n", "fout_txt", "=", "open", "(", "file_path", ",", "\"w\"", ")", "\n", "print", "(", "\"PREDICTION START\"", ")", "\n", "for", "record", ",", "data", "in", "zip", "(", "valid_data", ",", "dataset", ")", ":", "\n", "      ", "valid_sent_id", "=", "record", "[", "\"sent_id\"", "]", "\n", "batch", "=", "self", ".", "make_one_batch_for_target", "(", "data", ",", "valid_sent_id", ")", "\n", "\n", "if", "(", "valid_sent_id", "+", "1", ")", "%", "100", "==", "0", ":", "\n", "        ", "print", "(", "\"%d\"", "%", "(", "valid_sent_id", "+", "1", ")", ",", "flush", "=", "True", ",", "end", "=", "\" \"", ")", "\n", "\n", "#####################", "\n", "# Sentence sampling #", "\n", "#####################", "\n", "", "batch", ",", "sampled_sent_ids", "=", "self", ".", "_make_batch_and_sample_sent_ids", "(", "\n", "batch", ",", "record", ",", "train_sents", ",", "train_sent_ids", ")", "\n", "\n", "##############", "\n", "# Prediction #", "\n", "##############", "\n", "feed_dict", "=", "self", ".", "_get_feed_dict", "(", "batch", ")", "\n", "batch_sims", ",", "batch_preds", "=", "self", ".", "sess", ".", "run", "(", "\n", "[", "self", ".", "similarity", ",", "self", ".", "predicts", "]", ",", "feed_dict", ")", "\n", "\n", "crr_i", ",", "p_total_i", "=", "count_gold_and_system_outputs", "(", "\n", "batch", "[", "\"tags\"", "]", ",", "batch_preds", ",", "NULL_LABEL_ID", ")", "\n", "correct", "+=", "crr_i", "\n", "p_total", "+=", "p_total_i", "\n", "\n", "####################", "\n", "# Write the result #", "\n", "####################", "\n", "self", ".", "_write_predictions", "(", "fout_txt", ",", "record", ")", "\n", "self", ".", "_write_nearest_spans", "(", "\n", "fout_txt", ",", "record", ",", "train_data", ",", "sampled_sent_ids", ",", "batch_sims", ",", "\n", "batch_preds", ",", "print_knn", ")", "\n", "\n", "", "fout_txt", ".", "close", "(", ")", "\n", "\n", "p", ",", "r", ",", "f", "=", "f_score", "(", "correct", ",", "p_total", ",", "self", ".", "n_gold_spans", ")", "\n", "self", ".", "logger", ".", "info", "(", "\"-- Time: %f seconds\"", "%", "(", "time", ".", "time", "(", ")", "-", "start_time", ")", ")", "\n", "self", ".", "logger", ".", "info", "(", "\n", "\"-- {} set\\tF:{:>7.2%} P:{:>7.2%} ({:>5}/{:>5}) R:{:>7.2%} ({:>5}/{:>5})\"", "\n", ".", "format", "(", "data_name", ",", "f", ",", "p", ",", "correct", ",", "p_total", ",", "r", ",", "correct", ",", "\n", "self", ".", "n_gold_spans", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.models.knn_models.KnnModel._write_predictions": [[665, 671], ["fout_txt.write"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_write_predictions", "(", "fout_txt", ",", "record", ")", ":", "\n", "    ", "fout_txt", ".", "write", "(", "\"-SENT:%d || %s || %s\\n\"", "%", "(", "\n", "record", "[", "\"sent_id\"", "]", ",", "\n", "\" \"", ".", "join", "(", "record", "[", "\"words\"", "]", ")", ",", "\n", "\" \"", ".", "join", "(", "[", "\"(%s,%d,%d)\"", "%", "(", "r", ",", "i", ",", "j", ")", "for", "(", "r", ",", "i", ",", "j", ")", "in", "record", "[", "\"tags\"", "]", "]", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.models.knn_models.KnnModel._write_nearest_spans": [[672, 742], ["models.decoders.get_span_indices", "zip", "fout_txt.write", "fout_txt.write", "knn_models.KnnModel._write_nearest_spans._get_nearest_spans"], "methods", ["home.repos.pwc.inspect_result.hiroki13_instance-based-ner.models.decoders.get_span_indices"], ["", "def", "_write_nearest_spans", "(", "self", ",", "fout_txt", ",", "record", ",", "train_data", ",", "\n", "sampled_sent_ids", ",", "batch_sims", ",", "batch_preds", ",", "\n", "print_knn", ")", ":", "\n", "\n", "    ", "def", "_write_train_sents", "(", "_sampled_train_sents", ")", ":", "\n", "      ", "for", "_train_record", "in", "_sampled_train_sents", ":", "\n", "        ", "fout_txt", ".", "write", "(", "\"--kNN:%d || %s || %s\\n\"", "%", "(", "\n", "_train_record", "[", "\"sent_id\"", "]", ",", "\n", "\" \"", ".", "join", "(", "_train_record", "[", "\"words\"", "]", ")", ",", "\n", "\" \"", ".", "join", "(", "[", "\"(%s,%d,%d)\"", "%", "(", "r", ",", "i", ",", "j", ")", "\n", "for", "(", "r", ",", "i", ",", "j", ")", "in", "_train_record", "[", "\"tags\"", "]", "]", ")", ")", ")", "\n", "\n", "", "", "def", "_write_gold_and_pred_spans", "(", "_record", ",", "_pred_label_id", ",", "_span_boundaries", ")", ":", "\n", "      ", "if", "(", "i", ",", "j", ")", "in", "_span_boundaries", ":", "\n", "        ", "_index", "=", "_span_boundaries", ".", "index", "(", "(", "i", ",", "j", ")", ")", "\n", "gold_label", "=", "_record", "[", "\"tags\"", "]", "[", "_index", "]", "[", "0", "]", "\n", "", "else", ":", "\n", "        ", "gold_label", "=", "\"O\"", "\n", "\n", "", "pred_label", "=", "self", ".", "rev_tag_dict", "[", "_pred_label_id", "]", "\n", "fout_txt", ".", "write", "(", "\"##(%d,%d) || %s || %s || %s\\n\"", "%", "(", "\n", "i", ",", "j", ",", "\" \"", ".", "join", "(", "record", "[", "\"words\"", "]", "[", "i", ":", "j", "+", "1", "]", ")", ",", "pred_label", ",", "gold_label", ")", ")", "\n", "\n", "", "def", "_get_nearest_spans", "(", "_sampled_train_sents", ")", ":", "\n", "      ", "_nearest_spans", "=", "[", "]", "\n", "_prev_indx", "=", "0", "\n", "_temp_indx", "=", "0", "\n", "for", "_record", "in", "_sampled_train_sents", ":", "\n", "        ", "_indx_i", ",", "_indx_j", "=", "get_span_indices", "(", "n_words", "=", "len", "(", "_record", "[", "\"words\"", "]", ")", ",", "\n", "max_span_len", "=", "self", ".", "max_span_len", ")", "\n", "_temp_indx", "+=", "len", "(", "_indx_i", ")", "\n", "_temp_scores", "=", "scores", "[", "_prev_indx", ":", "_temp_indx", "]", "\n", "assert", "len", "(", "_temp_scores", ")", "==", "len", "(", "_indx_i", ")", "==", "len", "(", "_indx_j", ")", "\n", "_nearest_spans", ".", "extend", "(", "\n", "get_scores_and_spans", "(", "spans", "=", "_record", "[", "\"tags\"", "]", ",", "\n", "scores", "=", "_temp_scores", ",", "\n", "sent_id", "=", "_record", "[", "\"sent_id\"", "]", ",", "\n", "indx_i", "=", "_indx_i", ",", "\n", "indx_j", "=", "_indx_j", ")", ")", "\n", "_prev_indx", "=", "_temp_indx", "\n", "", "return", "_nearest_spans", "\n", "\n", "", "def", "_write_nearest_spans_for_each_span", "(", "_sampled_train_sents", ")", ":", "\n", "      ", "nearest_spans", "=", "_get_nearest_spans", "(", "_sampled_train_sents", ")", "\n", "nearest_spans", ".", "sort", "(", "key", "=", "lambda", "span", ":", "span", "[", "-", "1", "]", ",", "reverse", "=", "True", ")", "\n", "for", "rank", ",", "(", "r", ",", "sent_id", ",", "i", ",", "j", ",", "score", ")", "in", "enumerate", "(", "nearest_spans", "[", ":", "10", "]", ")", ":", "\n", "        ", "mention", "=", "\" \"", ".", "join", "(", "train_data", "[", "sent_id", "]", "[", "\"words\"", "]", "[", "i", ":", "j", "+", "1", "]", ")", "\n", "text", "=", "\"{} || {} || sent:{} || ({},{}) || {:.3g}\"", ".", "format", "(", "\n", "r", ",", "mention", ",", "sent_id", ",", "i", ",", "j", ",", "score", ")", "\n", "fout_txt", ".", "write", "(", "\"####RANK:%d %s\\n\"", "%", "(", "rank", ",", "text", ")", ")", "\n", "\n", "", "", "sampled_train_sents", "=", "[", "train_data", "[", "sent_id", "]", "\n", "for", "sent_id", "in", "sampled_sent_ids", "]", "\n", "if", "print_knn", ":", "\n", "      ", "_write_train_sents", "(", "sampled_train_sents", ")", "\n", "\n", "", "sims", "=", "batch_sims", "[", "0", "]", "# 1D: n_spans, 2D: n_instances", "\n", "preds", "=", "batch_preds", "[", "0", "]", "# 1D: n_spans", "\n", "indx_i", ",", "indx_j", "=", "get_span_indices", "(", "n_words", "=", "len", "(", "record", "[", "\"words\"", "]", ")", ",", "\n", "max_span_len", "=", "self", ".", "max_span_len", ")", "\n", "span_boundaries", "=", "[", "(", "i", ",", "j", ")", "for", "_", ",", "i", ",", "j", "in", "record", "[", "\"tags\"", "]", "]", "\n", "\n", "assert", "len", "(", "sims", ")", "==", "len", "(", "preds", ")", "==", "len", "(", "indx_i", ")", "==", "len", "(", "indx_j", ")", "\n", "for", "scores", ",", "pred_label_id", ",", "i", ",", "j", "in", "zip", "(", "sims", ",", "preds", ",", "indx_i", ",", "indx_j", ")", ":", "\n", "      ", "if", "pred_label_id", "==", "NULL_LABEL_ID", "and", "(", "i", ",", "j", ")", "not", "in", "span_boundaries", ":", "\n", "        ", "continue", "\n", "", "_write_gold_and_pred_spans", "(", "record", ",", "pred_label_id", ",", "span_boundaries", ")", "\n", "_write_nearest_spans_for_each_span", "(", "sampled_train_sents", ")", "\n", "\n", "", "fout_txt", ".", "write", "(", "\"\\n\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.models.knn_models.KnnModel.save_span_representation": [[743, 799], ["knn_models.KnnModel.logger.info", "preprocessor.load_dataset", "preprocessor.build_dataset", "knn_models.KnnModel.logger.info", "time.time", "os.path.join", "h5py.File", "print", "zip", "h5py.File.close", "os.path.join", "utils.common.write_json", "knn_models.KnnModel.logger.info", "str", "knn_models.KnnModel.make_one_batch_for_target", "knn_models.KnnModel._get_feed_dict", "h5py.File.create_dataset", "len", "print", "len", "len", "knn_models.KnnModel.sess.run", "time.time", "int"], "methods", ["home.repos.pwc.inspect_result.hiroki13_instance-based-ner.preprocessors.span_preprocessors.SpanPreprocessor.load_dataset", "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.preprocessors.span_preprocessors.SpanPreprocessor.build_dataset", "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.scripts.retrieve_knn_sents_with_glove.write_json", "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.models.knn_models.KnnModel.make_one_batch_for_target", "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.models.base_model.BaseModel._get_feed_dict"], ["", "def", "save_span_representation", "(", "self", ",", "data_name", ",", "preprocessor", ")", ":", "\n", "    ", "self", ".", "logger", ".", "info", "(", "str", "(", "self", ".", "cfg", ")", ")", "\n", "\n", "########################", "\n", "# Load validation data #", "\n", "########################", "\n", "valid_data", "=", "preprocessor", ".", "load_dataset", "(", "\n", "self", ".", "cfg", "[", "\"data_path\"", "]", ",", "keep_number", "=", "True", ",", "\n", "lowercase", "=", "self", ".", "cfg", "[", "\"char_lowercase\"", "]", ")", "\n", "valid_data", "=", "valid_data", "[", ":", "self", ".", "cfg", "[", "\"data_size\"", "]", "]", "\n", "dataset", "=", "preprocessor", ".", "build_dataset", "(", "valid_data", ",", "\n", "self", ".", "word_dict", ",", "\n", "self", ".", "char_dict", ",", "\n", "self", ".", "tag_dict", ")", "\n", "self", ".", "logger", ".", "info", "(", "\"Valid sentences: {:>7}\"", ".", "format", "(", "len", "(", "dataset", ")", ")", ")", "\n", "\n", "#############", "\n", "# Main loop #", "\n", "#############", "\n", "start_time", "=", "time", ".", "time", "(", ")", "\n", "gold_labels", "=", "{", "}", "\n", "fout_path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "cfg", "[", "\"checkpoint_path\"", "]", ",", "\n", "\"%s.span_reps.hdf5\"", "%", "data_name", ")", "\n", "fout", "=", "h5py", ".", "File", "(", "fout_path", ",", "'w'", ")", "\n", "\n", "print", "(", "\"PREDICTION START\"", ")", "\n", "for", "record", ",", "data", "in", "zip", "(", "valid_data", ",", "dataset", ")", ":", "\n", "      ", "valid_sent_id", "=", "record", "[", "\"sent_id\"", "]", "\n", "batch", "=", "self", ".", "make_one_batch_for_target", "(", "data", ",", "valid_sent_id", ")", "\n", "\n", "if", "(", "valid_sent_id", "+", "1", ")", "%", "100", "==", "0", ":", "\n", "        ", "print", "(", "\"%d\"", "%", "(", "valid_sent_id", "+", "1", ")", ",", "flush", "=", "True", ",", "end", "=", "\" \"", ")", "\n", "\n", "##############", "\n", "# Prediction #", "\n", "##############", "\n", "", "feed_dict", "=", "self", ".", "_get_feed_dict", "(", "batch", ")", "\n", "span_reps", "=", "self", ".", "sess", ".", "run", "(", "[", "self", ".", "span_rep", "]", ",", "feed_dict", ")", "[", "0", "]", "[", "0", "]", "\n", "span_tags", "=", "batch", "[", "\"tags\"", "]", "[", "0", "]", "\n", "assert", "len", "(", "span_reps", ")", "==", "len", "(", "span_tags", ")", "\n", "\n", "##################", "\n", "# Add the result #", "\n", "##################", "\n", "fout", ".", "create_dataset", "(", "\n", "name", "=", "'{}'", ".", "format", "(", "valid_sent_id", ")", ",", "\n", "dtype", "=", "'float32'", ",", "\n", "data", "=", "span_reps", ")", "\n", "gold_labels", "[", "valid_sent_id", "]", "=", "[", "self", ".", "rev_tag_dict", "[", "int", "(", "tag", ")", "]", "\n", "for", "tag", "in", "span_tags", "]", "\n", "", "fout", ".", "close", "(", ")", "\n", "path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "cfg", "[", "\"checkpoint_path\"", "]", ",", "\n", "\"%s.gold_labels.json\"", "%", "data_name", ")", "\n", "write_json", "(", "path", ",", "gold_labels", ")", "\n", "self", ".", "logger", ".", "info", "(", "\n", "\"-- Time: %f seconds\\nFINISHED.\"", "%", "(", "time", ".", "time", "(", ")", "-", "start_time", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.models.knn_models.KnnModel.predict_on_command_line": [[800, 958], ["utils.common.load_json", "preprocessor.load_dataset", "knn_models.KnnModel.predict_on_command_line._setup_repository"], "methods", ["home.repos.pwc.inspect_result.hiroki13_instance-based-ner.scripts.retrieve_knn_sents_with_glove.load_json", "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.preprocessors.span_preprocessors.SpanPreprocessor.load_dataset"], ["", "def", "predict_on_command_line", "(", "self", ",", "preprocessor", ")", ":", "\n", "\n", "    ", "def", "_load_glove", "(", "glove_path", ")", ":", "\n", "      ", "vocab", "=", "{", "}", "\n", "vectors", "=", "[", "]", "\n", "total", "=", "int", "(", "4e5", ")", "\n", "with", "codecs", ".", "open", "(", "glove_path", ",", "mode", "=", "'r'", ",", "encoding", "=", "'utf-8'", ")", "as", "f", ":", "\n", "        ", "for", "line", "in", "tqdm", "(", "f", ",", "total", "=", "total", ",", "desc", "=", "\"Load glove\"", ")", ":", "\n", "          ", "line", "=", "line", ".", "lstrip", "(", ")", ".", "rstrip", "(", ")", ".", "split", "(", "\" \"", ")", "\n", "vocab", "[", "line", "[", "0", "]", "]", "=", "len", "(", "vocab", ")", "\n", "vectors", ".", "append", "(", "[", "float", "(", "x", ")", "for", "x", "in", "line", "[", "1", ":", "]", "]", ")", "\n", "", "", "assert", "len", "(", "vocab", ")", "==", "len", "(", "vectors", ")", "\n", "return", "vocab", ",", "np", ".", "asarray", "(", "vectors", ")", "\n", "\n", "", "def", "_mean_vectors", "(", "sents", ",", "emb", ",", "vocab", ")", ":", "\n", "      ", "unk_vec", "=", "np", ".", "zeros", "(", "emb", ".", "shape", "[", "1", "]", ")", "\n", "mean_vecs", "=", "[", "]", "\n", "for", "words", "in", "sents", ":", "\n", "        ", "vecs", "=", "[", "]", "\n", "for", "word", "in", "words", ":", "\n", "          ", "word", "=", "word", ".", "lower", "(", ")", "\n", "if", "word", "in", "vocab", ":", "\n", "            ", "vec", "=", "emb", "[", "vocab", "[", "word", "]", "]", "\n", "", "else", ":", "\n", "            ", "vec", "=", "unk_vec", "\n", "", "vecs", ".", "append", "(", "vec", ")", "\n", "", "mean_vecs", ".", "append", "(", "np", ".", "mean", "(", "vecs", ",", "axis", "=", "0", ")", ")", "\n", "", "return", "mean_vecs", "\n", "\n", "", "def", "_cosine_sim", "(", "p0", ",", "p1", ")", ":", "\n", "      ", "d", "=", "(", "norm", "(", "p0", ")", "*", "norm", "(", "p1", ")", ")", "\n", "if", "d", ">", "0", ":", "\n", "        ", "return", "np", ".", "dot", "(", "p0", ",", "p1", ")", "/", "d", "\n", "", "return", "0.0", "\n", "\n", "", "def", "_setup_repository", "(", "_train_sents", ",", "_train_data", "=", "None", ")", ":", "\n", "      ", "if", "self", ".", "cfg", "[", "\"knn_sampling\"", "]", "==", "\"random\"", ":", "\n", "        ", "_train_sent_ids", "=", "[", "_sent_id", "for", "_sent_id", "in", "range", "(", "len", "(", "_train_sents", ")", ")", "]", "\n", "_vocab", "=", "_glove", "=", "_train_embs", "=", "None", "\n", "", "else", ":", "\n", "        ", "_train_sent_ids", "=", "None", "\n", "_vocab", ",", "_glove", "=", "_load_glove", "(", "\"data/emb/glove.6B.100d.txt\"", ")", "\n", "_train_words", "=", "[", "[", "w", ".", "lower", "(", ")", "for", "w", "in", "_train_record", "[", "\"words\"", "]", "]", "\n", "for", "_train_record", "in", "_train_data", "]", "\n", "_train_embs", "=", "_mean_vectors", "(", "_train_words", ",", "_glove", ",", "_vocab", ")", "\n", "", "return", "_train_sent_ids", ",", "_train_embs", ",", "_vocab", ",", "_glove", "\n", "\n", "", "def", "_make_ids", "(", "_words", ")", ":", "\n", "      ", "_char_ids", "=", "[", "]", "\n", "_word_ids", "=", "[", "]", "\n", "for", "word", "in", "_words", ":", "\n", "        ", "_char_ids", ".", "append", "(", "[", "self", ".", "char_dict", "[", "char", "]", "\n", "if", "char", "in", "self", ".", "char_dict", "else", "self", ".", "char_dict", "[", "UNK", "]", "\n", "for", "char", "in", "word", "]", ")", "\n", "word", "=", "word_convert", "(", "word", ",", "keep_number", "=", "False", ",", "lowercase", "=", "True", ")", "\n", "_word_ids", ".", "append", "(", "self", ".", "word_dict", "[", "word", "]", "\n", "if", "word", "in", "self", ".", "word_dict", "else", "self", ".", "word_dict", "[", "UNK", "]", ")", "\n", "", "return", "_char_ids", ",", "_word_ids", "\n", "\n", "", "def", "_retrieve_knn_train_sents", "(", "_record", ",", "_train_embs", ",", "_vocab", ",", "_glove", ")", ":", "\n", "      ", "test_words", "=", "[", "w", ".", "lower", "(", ")", "for", "w", "in", "_record", "[", "\"words\"", "]", "]", "\n", "test_emb", "=", "_mean_vectors", "(", "[", "test_words", "]", ",", "_glove", ",", "_vocab", ")", "[", "0", "]", "\n", "sim", "=", "[", "_cosine_sim", "(", "train_emb", ",", "test_emb", ")", "for", "train_emb", "in", "_train_embs", "]", "\n", "arg_sort", "=", "np", ".", "argsort", "(", "sim", ")", "[", ":", ":", "-", "1", "]", "[", ":", "self", ".", "cfg", "[", "\"k\"", "]", "]", "\n", "_record", "[", "\"train_sent_ids\"", "]", "=", "[", "int", "(", "arg", ")", "for", "arg", "in", "arg_sort", "]", "\n", "return", "_record", "\n", "\n", "", "def", "_get_nearest_spans", "(", "_sampled_train_sents", ",", "_scores", ")", ":", "\n", "      ", "_nearest_spans", "=", "[", "]", "\n", "_prev_indx", "=", "0", "\n", "_temp_indx", "=", "0", "\n", "for", "_record", "in", "_sampled_train_sents", ":", "\n", "        ", "_indx_i", ",", "_indx_j", "=", "get_span_indices", "(", "n_words", "=", "len", "(", "_record", "[", "\"words\"", "]", ")", ",", "\n", "max_span_len", "=", "self", ".", "max_span_len", ")", "\n", "_temp_indx", "+=", "len", "(", "_indx_i", ")", "\n", "_temp_scores", "=", "_scores", "[", "_prev_indx", ":", "_temp_indx", "]", "\n", "assert", "len", "(", "_temp_scores", ")", "==", "len", "(", "_indx_i", ")", "==", "len", "(", "_indx_j", ")", "\n", "_nearest_spans", ".", "extend", "(", "\n", "get_scores_and_spans", "(", "spans", "=", "_record", "[", "\"tags\"", "]", ",", "\n", "scores", "=", "_temp_scores", ",", "\n", "sent_id", "=", "_record", "[", "\"sent_id\"", "]", ",", "\n", "indx_i", "=", "_indx_i", ",", "\n", "indx_j", "=", "_indx_j", ")", ")", "\n", "_prev_indx", "=", "_temp_indx", "\n", "", "_nearest_spans", ".", "sort", "(", "key", "=", "lambda", "span", ":", "span", "[", "-", "1", "]", ",", "reverse", "=", "True", ")", "\n", "return", "_nearest_spans", "\n", "\n", "######################", "\n", "# Load training data #", "\n", "######################", "\n", "", "train_sents", "=", "load_json", "(", "self", ".", "cfg", "[", "\"train_set\"", "]", ")", "\n", "train_data", "=", "preprocessor", ".", "load_dataset", "(", "\n", "os", ".", "path", ".", "join", "(", "self", ".", "cfg", "[", "\"raw_path\"", "]", ",", "\"train.json\"", ")", ",", "\n", "keep_number", "=", "True", ",", "lowercase", "=", "False", ")", "\n", "train_sent_ids", ",", "train_embs", ",", "vocab", ",", "glove", "=", "_setup_repository", "(", "\n", "train_sents", ",", "train_data", ")", "\n", "\n", "########################################", "\n", "# Load each sentence from command line #", "\n", "########################################", "\n", "print", "(", "\"\\nPREDICTION START\\n\"", ")", "\n", "while", "True", ":", "\n", "      ", "sentence", "=", "input", "(", "'\\nEnter a tokenized sentence: '", ")", "\n", "words", "=", "sentence", ".", "split", "(", ")", "\n", "char_ids", ",", "word_ids", "=", "_make_ids", "(", "words", ")", "\n", "data", "=", "{", "\"words\"", ":", "word_ids", ",", "\"chars\"", ":", "char_ids", "}", "\n", "record", "=", "{", "\"sent_id\"", ":", "0", ",", "\"words\"", ":", "words", ",", "\"train_sent_ids\"", ":", "None", "}", "\n", "batch", "=", "self", ".", "make_one_batch_for_target", "(", "data", ",", "sent_id", "=", "0", ",", "add_tags", "=", "False", ")", "\n", "\n", "#####################", "\n", "# Sentence sampling #", "\n", "#####################", "\n", "if", "self", ".", "cfg", "[", "\"knn_sampling\"", "]", "==", "\"knn\"", ":", "\n", "        ", "record", "=", "_retrieve_knn_train_sents", "(", "record", ",", "train_embs", ",", "vocab", ",", "glove", ")", "\n", "", "batch", ",", "sampled_sent_ids", "=", "self", ".", "_make_batch_and_sample_sent_ids", "(", "\n", "batch", ",", "record", ",", "train_sents", ",", "train_sent_ids", ")", "\n", "\n", "##############", "\n", "# Prediction #", "\n", "##############", "\n", "feed_dict", "=", "self", ".", "_get_feed_dict", "(", "batch", ")", "\n", "batch_sims", ",", "batch_preds", "=", "self", ".", "sess", ".", "run", "(", "\n", "[", "self", ".", "similarity", ",", "self", ".", "predicts", "]", ",", "feed_dict", ")", "\n", "\n", "####################", "\n", "# Write the result #", "\n", "####################", "\n", "sims", "=", "batch_sims", "[", "0", "]", "# 1D: n_spans, 2D: n_instances", "\n", "preds", "=", "batch_preds", "[", "0", "]", "# 1D: n_spans", "\n", "indx_i", ",", "indx_j", "=", "get_span_indices", "(", "n_words", "=", "len", "(", "record", "[", "\"words\"", "]", ")", ",", "\n", "max_span_len", "=", "self", ".", "max_span_len", ")", "\n", "\n", "assert", "len", "(", "sims", ")", "==", "len", "(", "preds", ")", "==", "len", "(", "indx_i", ")", "==", "len", "(", "indx_j", ")", "\n", "sampled_train_sents", "=", "[", "train_data", "[", "sent_id", "]", "\n", "for", "sent_id", "in", "sampled_sent_ids", "]", "\n", "\n", "for", "scores", ",", "pred_label_id", ",", "i", ",", "j", "in", "zip", "(", "sims", ",", "preds", ",", "indx_i", ",", "indx_j", ")", ":", "\n", "        ", "if", "pred_label_id", "==", "NULL_LABEL_ID", ":", "\n", "          ", "continue", "\n", "", "pred_label", "=", "self", ".", "rev_tag_dict", "[", "pred_label_id", "]", "\n", "print", "(", "\"#(%d,%d) || %s || %s\"", "%", "(", "\n", "i", ",", "j", ",", "\" \"", ".", "join", "(", "record", "[", "\"words\"", "]", "[", "i", ":", "j", "+", "1", "]", ")", ",", "pred_label", ")", ")", "\n", "\n", "nearest_spans", "=", "_get_nearest_spans", "(", "sampled_train_sents", ",", "scores", ")", "\n", "for", "k", ",", "(", "r", ",", "_sent_id", ",", "a", ",", "b", ",", "_score", ")", "in", "enumerate", "(", "nearest_spans", "[", ":", "5", "]", ")", ":", "\n", "          ", "train_words", "=", "train_data", "[", "_sent_id", "]", "[", "\"words\"", "]", "\n", "if", "a", "-", "5", "<", "0", ":", "\n", "            ", "left_context", "=", "\"\"", "\n", "", "else", ":", "\n", "            ", "left_context", "=", "\" \"", ".", "join", "(", "train_words", "[", "a", "-", "5", ":", "a", "]", ")", "\n", "left_context", "=", "\"... \"", "+", "left_context", "\n", "", "right_context", "=", "\" \"", ".", "join", "(", "train_words", "[", "b", "+", "1", ":", "b", "+", "6", "]", ")", "\n", "if", "b", "+", "6", "<", "len", "(", "train_words", ")", ":", "\n", "            ", "right_context", "=", "right_context", "+", "\" ...\"", "\n", "", "mention", "=", "\" \"", ".", "join", "(", "train_words", "[", "a", ":", "b", "+", "1", "]", ")", "\n", "text", "=", "\"{}: {} [{}] {}\"", ".", "format", "(", "\n", "r", ",", "left_context", ",", "mention", ",", "right_context", ")", "\n", "print", "(", "\"## %d %s\"", "%", "(", "k", ",", "text", ")", ")", "\n", "", "", "", "", "", ""]], "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.models.network_components.highway_layer": [[10, 29], ["tensorflow.variable_scope", "inputs.get_shape().as_list", "tensorflow.variable_scope", "tensorflow.layers.dropout", "tensorflow.layers.dense", "tensorflow.nn.relu", "tensorflow.variable_scope", "tensorflow.layers.dropout", "tensorflow.layers.dense", "tensorflow.nn.sigmoid", "inputs.get_shape", "tensorflow.constant_initializer", "tensorflow.constant_initializer"], "function", ["None"], ["def", "highway_layer", "(", "inputs", ",", "use_bias", "=", "True", ",", "bias_init", "=", "0.0", ",", "keep_prob", "=", "1.0", ",", "\n", "is_train", "=", "False", ",", "scope", "=", "None", ")", ":", "\n", "  ", "with", "tf", ".", "variable_scope", "(", "scope", "or", "\"highway_layer\"", ")", ":", "\n", "    ", "hidden", "=", "inputs", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", "[", "-", "1", "]", "\n", "with", "tf", ".", "variable_scope", "(", "\"trans\"", ")", ":", "\n", "      ", "trans", "=", "tf", ".", "layers", ".", "dropout", "(", "inputs", ",", "rate", "=", "1.0", "-", "keep_prob", ",", "\n", "training", "=", "is_train", ")", "\n", "trans", "=", "tf", ".", "layers", ".", "dense", "(", "trans", ",", "units", "=", "hidden", ",", "use_bias", "=", "use_bias", ",", "\n", "bias_initializer", "=", "tf", ".", "constant_initializer", "(", "\n", "bias_init", ")", ",", "activation", "=", "None", ")", "\n", "trans", "=", "tf", ".", "nn", ".", "relu", "(", "trans", ")", "\n", "", "with", "tf", ".", "variable_scope", "(", "\"gate\"", ")", ":", "\n", "      ", "gate", "=", "tf", ".", "layers", ".", "dropout", "(", "inputs", ",", "rate", "=", "1.0", "-", "keep_prob", ",", "training", "=", "is_train", ")", "\n", "gate", "=", "tf", ".", "layers", ".", "dense", "(", "gate", ",", "units", "=", "hidden", ",", "use_bias", "=", "use_bias", ",", "\n", "bias_initializer", "=", "tf", ".", "constant_initializer", "(", "\n", "bias_init", ")", ",", "activation", "=", "None", ")", "\n", "gate", "=", "tf", ".", "nn", ".", "sigmoid", "(", "gate", ")", "\n", "", "", "outputs", "=", "gate", "*", "trans", "+", "(", "1", "-", "gate", ")", "*", "inputs", "\n", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.models.network_components.highway_network": [[31, 41], ["tensorflow.variable_scope", "range", "network_components.highway_layer"], "function", ["home.repos.pwc.inspect_result.hiroki13_instance-based-ner.models.network_components.highway_layer"], ["", "def", "highway_network", "(", "inputs", ",", "highway_layers", "=", "2", ",", "use_bias", "=", "True", ",", "bias_init", "=", "0.0", ",", "\n", "keep_prob", "=", "1.0", ",", "is_train", "=", "False", ",", "scope", "=", "None", ")", ":", "\n", "  ", "with", "tf", ".", "variable_scope", "(", "scope", "or", "\"highway_network\"", ")", ":", "\n", "    ", "prev", "=", "inputs", "\n", "cur", "=", "None", "\n", "for", "idx", "in", "range", "(", "highway_layers", ")", ":", "\n", "      ", "cur", "=", "highway_layer", "(", "prev", ",", "use_bias", ",", "bias_init", ",", "keep_prob", ",", "is_train", ",", "\n", "scope", "=", "\"highway_layer_{}\"", ".", "format", "(", "idx", ")", ")", "\n", "prev", "=", "cur", "\n", "", "return", "cur", "\n", "\n"]], "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.models.network_components.conv1d": [[43, 57], ["tensorflow.variable_scope", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.layers.dropout", "tensorflow.reduce_max", "tf.layers.dropout.get_shape", "tensorflow.nn.conv2d", "tensorflow.nn.relu"], "function", ["None"], ["", "", "def", "conv1d", "(", "in_", ",", "filter_size", ",", "height", ",", "padding", ",", "is_train", "=", "True", ",", "drop_rate", "=", "0.0", ",", "\n", "scope", "=", "None", ")", ":", "\n", "  ", "with", "tf", ".", "variable_scope", "(", "scope", "or", "\"conv1d\"", ")", ":", "\n", "    ", "num_channels", "=", "in_", ".", "get_shape", "(", ")", "[", "-", "1", "]", "\n", "filter_", "=", "tf", ".", "get_variable", "(", "\"filter\"", ",", "\n", "shape", "=", "[", "1", ",", "height", ",", "num_channels", ",", "filter_size", "]", ",", "\n", "dtype", "=", "tf", ".", "float32", ")", "\n", "bias", "=", "tf", ".", "get_variable", "(", "\"bias\"", ",", "shape", "=", "[", "filter_size", "]", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "strides", "=", "[", "1", ",", "1", ",", "1", ",", "1", "]", "\n", "in_", "=", "tf", ".", "layers", ".", "dropout", "(", "in_", ",", "rate", "=", "drop_rate", ",", "training", "=", "is_train", ")", "\n", "# [batch, max_len_sent, max_len_word / filter_stride, char output size]", "\n", "xxc", "=", "tf", ".", "nn", ".", "conv2d", "(", "in_", ",", "filter_", ",", "strides", ",", "padding", ")", "+", "bias", "\n", "out", "=", "tf", ".", "reduce_max", "(", "tf", ".", "nn", ".", "relu", "(", "xxc", ")", ",", "axis", "=", "2", ")", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.models.network_components.multi_conv1d": [[59, 77], ["tensorflow.variable_scope", "enumerate", "tensorflow.concat", "len", "len", "zip", "network_components.conv1d", "outs.append"], "function", ["home.repos.pwc.inspect_result.hiroki13_instance-based-ner.models.network_components.conv1d"], ["", "", "def", "multi_conv1d", "(", "in_", ",", "filter_sizes", ",", "heights", ",", "padding", "=", "\"VALID\"", ",", "is_train", "=", "True", ",", "\n", "drop_rate", "=", "0.0", ",", "scope", "=", "None", ")", ":", "\n", "  ", "with", "tf", ".", "variable_scope", "(", "scope", "or", "\"multi_conv1d\"", ")", ":", "\n", "    ", "assert", "len", "(", "filter_sizes", ")", "==", "len", "(", "heights", ")", "\n", "outs", "=", "[", "]", "\n", "for", "i", ",", "(", "filter_size", ",", "height", ")", "in", "enumerate", "(", "zip", "(", "filter_sizes", ",", "heights", ")", ")", ":", "\n", "      ", "if", "filter_size", "==", "0", ":", "\n", "        ", "continue", "\n", "", "out", "=", "conv1d", "(", "in_", ",", "\n", "filter_size", ",", "\n", "height", ",", "\n", "padding", ",", "\n", "is_train", "=", "is_train", ",", "\n", "drop_rate", "=", "drop_rate", ",", "\n", "scope", "=", "\"conv1d_{}\"", ".", "format", "(", "i", ")", ")", "\n", "outs", ".", "append", "(", "out", ")", "\n", "", "concat_out", "=", "tf", ".", "concat", "(", "axis", "=", "2", ",", "values", "=", "outs", ")", "\n", "return", "concat_out", "\n", "", "", ""]], "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.models.span_models.SpanModel.__init__": [[31, 36], ["models.BaseModel.__init__"], "methods", ["home.repos.pwc.inspect_result.hiroki13_instance-based-ner.models.base_model.BaseModel.__init__"], ["  ", "def", "__init__", "(", "self", ",", "config", ",", "batcher", ",", "is_train", "=", "True", ")", ":", "\n", "    ", "self", ".", "max_span_len", "=", "config", "[", "\"max_span_len\"", "]", "\n", "self", ".", "n_gold_spans", "=", "None", "\n", "self", ".", "proba", "=", "None", "\n", "super", "(", "SpanModel", ",", "self", ")", ".", "__init__", "(", "config", ",", "batcher", ",", "is_train", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.models.span_models.SpanModel._add_placeholders": [[37, 49], ["tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder"], "methods", ["None"], ["", "def", "_add_placeholders", "(", "self", ")", ":", "\n", "    ", "self", ".", "words", "=", "tf", ".", "placeholder", "(", "tf", ".", "int32", ",", "shape", "=", "[", "None", ",", "None", "]", ",", "name", "=", "\"words\"", ")", "\n", "self", ".", "tags", "=", "tf", ".", "placeholder", "(", "tf", ".", "int32", ",", "shape", "=", "[", "None", ",", "None", "]", ",", "name", "=", "\"tags\"", ")", "\n", "self", ".", "seq_len", "=", "tf", ".", "placeholder", "(", "tf", ".", "int32", ",", "shape", "=", "[", "None", "]", ",", "name", "=", "\"seq_len\"", ")", "\n", "if", "self", ".", "cfg", "[", "\"use_chars\"", "]", ":", "\n", "      ", "self", ".", "chars", "=", "tf", ".", "placeholder", "(", "tf", ".", "int32", ",", "shape", "=", "[", "None", ",", "None", ",", "None", "]", ",", "\n", "name", "=", "\"chars\"", ")", "\n", "# hyperparameters", "\n", "", "self", ".", "is_train", "=", "tf", ".", "placeholder", "(", "tf", ".", "bool", ",", "name", "=", "\"is_train\"", ")", "\n", "self", ".", "keep_prob", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "name", "=", "\"rnn_keep_probability\"", ")", "\n", "self", ".", "drop_rate", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "name", "=", "\"dropout_rate\"", ")", "\n", "self", ".", "lr", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "name", "=", "\"learning_rate\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.models.span_models.SpanModel._get_feed_dict": [[50, 62], ["None"], "methods", ["None"], ["", "def", "_get_feed_dict", "(", "self", ",", "batch", ",", "keep_prob", "=", "1.0", ",", "is_train", "=", "False", ",", "lr", "=", "None", ")", ":", "\n", "    ", "feed_dict", "=", "{", "self", ".", "words", ":", "batch", "[", "\"words\"", "]", ",", "self", ".", "seq_len", ":", "batch", "[", "\"seq_len\"", "]", "}", "\n", "if", "\"tags\"", "in", "batch", ":", "\n", "      ", "feed_dict", "[", "self", ".", "tags", "]", "=", "batch", "[", "\"tags\"", "]", "\n", "", "if", "self", ".", "cfg", "[", "\"use_chars\"", "]", ":", "\n", "      ", "feed_dict", "[", "self", ".", "chars", "]", "=", "batch", "[", "\"chars\"", "]", "\n", "", "feed_dict", "[", "self", ".", "keep_prob", "]", "=", "keep_prob", "\n", "feed_dict", "[", "self", ".", "drop_rate", "]", "=", "1.0", "-", "keep_prob", "\n", "feed_dict", "[", "self", ".", "is_train", "]", "=", "is_train", "\n", "if", "lr", "is", "not", "None", ":", "\n", "      ", "feed_dict", "[", "self", ".", "lr", "]", "=", "lr", "\n", "", "return", "feed_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.models.span_models.SpanModel._create_rnn_cell": [[63, 83], ["span_models.SpanModel._create_single_rnn_cell", "range", "tensorflow.python.ops.rnn_cell.MultiRNNCell", "tensorflow.nn.rnn_cell.LSTMCell", "tensorflow.contrib.rnn.DropoutWrapper", "lstm_cells.append", "span_models.SpanModel._create_single_rnn_cell", "range"], "methods", ["home.repos.pwc.inspect_result.hiroki13_instance-based-ner.models.base_model.BaseModel._create_single_rnn_cell", "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.models.base_model.BaseModel._create_single_rnn_cell"], ["", "def", "_create_rnn_cell", "(", "self", ")", ":", "\n", "    ", "if", "self", ".", "cfg", "[", "\"num_layers\"", "]", "is", "None", "or", "self", ".", "cfg", "[", "\"num_layers\"", "]", "<=", "1", ":", "\n", "      ", "return", "self", ".", "_create_single_rnn_cell", "(", "self", ".", "cfg", "[", "\"num_units\"", "]", ")", "\n", "", "else", ":", "\n", "      ", "if", "self", ".", "cfg", "[", "\"use_stack_rnn\"", "]", ":", "\n", "        ", "lstm_cells", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "self", ".", "cfg", "[", "\"num_layers\"", "]", ")", ":", "\n", "          ", "cell", "=", "tf", ".", "nn", ".", "rnn_cell", ".", "LSTMCell", "(", "self", ".", "cfg", "[", "\"num_units\"", "]", ",", "\n", "initializer", "=", "tf", ".", "initializers", ".", "orthogonal", "\n", ")", "\n", "cell", "=", "tf", ".", "contrib", ".", "rnn", ".", "DropoutWrapper", "(", "cell", ",", "\n", "state_keep_prob", "=", "self", ".", "keep_prob", ",", "\n", "input_keep_prob", "=", "self", ".", "keep_prob", ",", "\n", "dtype", "=", "tf", ".", "float32", ")", "\n", "lstm_cells", ".", "append", "(", "cell", ")", "\n", "", "return", "lstm_cells", "\n", "", "else", ":", "\n", "        ", "return", "MultiRNNCell", "(", "\n", "[", "self", ".", "_create_single_rnn_cell", "(", "self", ".", "cfg", "[", "\"num_units\"", "]", ")", "\n", "for", "_", "in", "range", "(", "self", ".", "cfg", "[", "\"num_layers\"", "]", ")", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.models.span_models.SpanModel._build_embedding_op": [[84, 138], ["tensorflow.variable_scope", "tensorflow.nn.embedding_lookup", "print", "print", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.Variable", "tensorflow.concat", "tensorflow.get_variable", "tensorflow.nn.embedding_lookup", "models.network_components.multi_conv1d", "print", "tensorflow.concat", "models.network_components.highway_network", "tensorflow.layers.dropout", "tensorflow.concat.get_shape().as_list", "span_models.SpanModel.word_emb.get_shape().as_list", "numpy.load", "models.network_components.multi_conv1d.get_shape().as_list", "tensorflow.concat.get_shape", "span_models.SpanModel.word_emb.get_shape", "models.network_components.multi_conv1d.get_shape"], "methods", ["home.repos.pwc.inspect_result.hiroki13_instance-based-ner.models.network_components.multi_conv1d", "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.models.network_components.highway_network", "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.scripts.convert_genia_to_json.load"], ["", "", "", "def", "_build_embedding_op", "(", "self", ")", ":", "\n", "    ", "with", "tf", ".", "variable_scope", "(", "\"embeddings\"", ")", ":", "\n", "      ", "if", "not", "self", ".", "cfg", "[", "\"use_pretrained\"", "]", ":", "\n", "        ", "self", ".", "word_embeddings", "=", "tf", ".", "get_variable", "(", "name", "=", "\"emb\"", ",", "\n", "dtype", "=", "tf", ".", "float32", ",", "\n", "trainable", "=", "True", ",", "\n", "shape", "=", "[", "self", ".", "word_vocab_size", ",", "\n", "self", ".", "cfg", "[", "\"emb_dim\"", "]", "]", ")", "\n", "", "else", ":", "\n", "        ", "padding_token_emb", "=", "tf", ".", "get_variable", "(", "name", "=", "\"padding_emb\"", ",", "\n", "dtype", "=", "tf", ".", "float32", ",", "\n", "trainable", "=", "False", ",", "\n", "shape", "=", "[", "1", ",", "self", ".", "cfg", "[", "\"emb_dim\"", "]", "]", ")", "\n", "special_token_emb", "=", "tf", ".", "get_variable", "(", "name", "=", "\"spacial_emb\"", ",", "\n", "dtype", "=", "tf", ".", "float32", ",", "\n", "trainable", "=", "True", ",", "\n", "shape", "=", "[", "2", ",", "self", ".", "cfg", "[", "\"emb_dim\"", "]", "]", ")", "\n", "token_emb", "=", "tf", ".", "Variable", "(", "\n", "np", ".", "load", "(", "self", ".", "cfg", "[", "\"pretrained_emb\"", "]", ")", "[", "\"embeddings\"", "]", ",", "\n", "name", "=", "\"emb\"", ",", "dtype", "=", "tf", ".", "float32", ",", "trainable", "=", "self", ".", "cfg", "[", "\"tuning_emb\"", "]", ")", "\n", "self", ".", "word_embeddings", "=", "tf", ".", "concat", "(", "\n", "[", "padding_token_emb", ",", "special_token_emb", ",", "token_emb", "]", ",", "axis", "=", "0", ")", "\n", "\n", "", "word_emb", "=", "tf", ".", "nn", ".", "embedding_lookup", "(", "self", ".", "word_embeddings", ",", "self", ".", "words", ",", "\n", "name", "=", "\"words_emb\"", ")", "\n", "print", "(", "\"word embedding shape: {}\"", ".", "format", "(", "word_emb", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", ")", ")", "\n", "\n", "if", "self", ".", "cfg", "[", "\"use_chars\"", "]", ":", "\n", "        ", "self", ".", "char_embeddings", "=", "tf", ".", "get_variable", "(", "name", "=", "\"char_emb\"", ",", "\n", "dtype", "=", "tf", ".", "float32", ",", "\n", "trainable", "=", "True", ",", "\n", "shape", "=", "[", "self", ".", "char_vocab_size", ",", "\n", "self", ".", "cfg", "[", "\"char_emb_dim\"", "]", "]", "\n", ")", "\n", "char_emb", "=", "tf", ".", "nn", ".", "embedding_lookup", "(", "self", ".", "char_embeddings", ",", "self", ".", "chars", ",", "\n", "name", "=", "\"chars_emb\"", ")", "\n", "char_represent", "=", "multi_conv1d", "(", "char_emb", ",", "self", ".", "cfg", "[", "\"filter_sizes\"", "]", ",", "\n", "self", ".", "cfg", "[", "\"channel_sizes\"", "]", ",", "\n", "drop_rate", "=", "self", ".", "drop_rate", ",", "\n", "is_train", "=", "self", ".", "is_train", ")", "\n", "print", "(", "\"chars representation shape: {}\"", ".", "format", "(", "\n", "char_represent", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", ")", ")", "\n", "word_emb", "=", "tf", ".", "concat", "(", "[", "word_emb", ",", "char_represent", "]", ",", "axis", "=", "-", "1", ")", "\n", "\n", "", "if", "self", ".", "cfg", "[", "\"use_highway\"", "]", ":", "\n", "        ", "self", ".", "word_emb", "=", "highway_network", "(", "word_emb", ",", "self", ".", "cfg", "[", "\"highway_layers\"", "]", ",", "\n", "use_bias", "=", "True", ",", "bias_init", "=", "0.0", ",", "\n", "keep_prob", "=", "self", ".", "keep_prob", ",", "\n", "is_train", "=", "self", ".", "is_train", ")", "\n", "", "else", ":", "\n", "        ", "self", ".", "word_emb", "=", "tf", ".", "layers", ".", "dropout", "(", "word_emb", ",", "rate", "=", "self", ".", "drop_rate", ",", "\n", "training", "=", "self", ".", "is_train", ")", "\n", "", "print", "(", "\"word and chars concatenation shape: {}\"", ".", "format", "(", "\n", "self", ".", "word_emb", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.models.span_models.SpanModel._build_rnn_op": [[139, 155], ["tensorflow.variable_scope", "span_models.SpanModel._create_rnn_cell", "span_models.SpanModel._create_rnn_cell", "tensorflow.concat", "tensorflow.layers.dropout", "print", "tensorflow.contrib.rnn.python.ops.rnn.stack_bidirectional_dynamic_rnn", "tensorflow.python.ops.rnn.bidirectional_dynamic_rnn", "tensorflow.layers.dropout.get_shape().as_list", "tensorflow.layers.dropout.get_shape"], "methods", ["home.repos.pwc.inspect_result.hiroki13_instance-based-ner.models.base_model.BaseModel._create_rnn_cell", "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.models.base_model.BaseModel._create_rnn_cell"], ["", "", "def", "_build_rnn_op", "(", "self", ")", ":", "\n", "    ", "with", "tf", ".", "variable_scope", "(", "\"bi_directional_rnn\"", ")", ":", "\n", "      ", "cell_fw", "=", "self", ".", "_create_rnn_cell", "(", ")", "\n", "cell_bw", "=", "self", ".", "_create_rnn_cell", "(", ")", "\n", "\n", "if", "self", ".", "cfg", "[", "\"use_stack_rnn\"", "]", ":", "\n", "        ", "rnn_outs", ",", "*", "_", "=", "stack_bidirectional_dynamic_rnn", "(", "\n", "cell_fw", ",", "cell_bw", ",", "self", ".", "word_emb", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "", "else", ":", "\n", "        ", "rnn_outs", ",", "*", "_", "=", "bidirectional_dynamic_rnn", "(", "\n", "cell_fw", ",", "cell_bw", ",", "self", ".", "word_emb", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "", "rnn_outs", "=", "tf", ".", "concat", "(", "rnn_outs", ",", "axis", "=", "-", "1", ")", "\n", "rnn_outs", "=", "tf", ".", "layers", ".", "dropout", "(", "rnn_outs", ",", "rate", "=", "self", ".", "drop_rate", ",", "\n", "training", "=", "self", ".", "is_train", ")", "\n", "self", ".", "rnn_outs", "=", "rnn_outs", "\n", "print", "(", "\"rnn output shape: {}\"", ".", "format", "(", "rnn_outs", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.models.span_models.SpanModel._make_span_indices": [[156, 167], ["tensorflow.name_scope", "tensorflow.cast", "tensorflow.contrib.distributions.fill_triangular", "tensorflow.minimum", "tensorflow.linalg.band_part", "tensorflow.transpose", "tensorflow.shape", "tensorflow.ones", "tensorflow.where", "tensorflow.cast", "tensorflow.not_equal", "tensorflow.constant"], "methods", ["None"], ["", "", "def", "_make_span_indices", "(", "self", ")", ":", "\n", "    ", "with", "tf", ".", "name_scope", "(", "\"span_indices\"", ")", ":", "\n", "      ", "n_words", "=", "tf", ".", "shape", "(", "self", ".", "rnn_outs", ")", "[", "1", "]", "\n", "n_spans", "=", "tf", ".", "cast", "(", "n_words", "*", "(", "n_words", "+", "1", ")", "/", "2", ",", "dtype", "=", "tf", ".", "int32", ")", "\n", "ones", "=", "tf", ".", "contrib", ".", "distributions", ".", "fill_triangular", "(", "tf", ".", "ones", "(", "shape", "=", "[", "n_spans", "]", ")", ",", "\n", "upper", "=", "True", ")", "\n", "num_upper", "=", "tf", ".", "minimum", "(", "n_words", ",", "self", ".", "cfg", "[", "\"max_span_len\"", "]", "-", "1", ")", "\n", "ones", "=", "tf", ".", "linalg", ".", "band_part", "(", "ones", ",", "num_lower", "=", "tf", ".", "cast", "(", "0", ",", "dtype", "=", "tf", ".", "int32", ")", ",", "\n", "num_upper", "=", "num_upper", ")", "\n", "self", ".", "span_indices", "=", "tf", ".", "transpose", "(", "\n", "tf", ".", "where", "(", "tf", ".", "not_equal", "(", "ones", ",", "tf", ".", "constant", "(", "0", ",", "dtype", "=", "tf", ".", "float32", ")", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.models.span_models.SpanModel._build_span_minus_op": [[168, 192], ["tensorflow.variable_scope", "tensorflow.zeros", "tensorflow.concat", "tensorflow.concat", "tensorflow.gather", "tensorflow.gather", "tensorflow.gather", "tensorflow.gather", "tensorflow.concat", "print", "tensorflow.shape", "span_models.SpanModel.rnn_span_rep.get_shape().as_list", "span_models.SpanModel.rnn_span_rep.get_shape"], "methods", ["None"], ["", "", "def", "_build_span_minus_op", "(", "self", ")", ":", "\n", "    ", "with", "tf", ".", "variable_scope", "(", "\"rnn_span_rep\"", ")", ":", "\n", "      ", "i", "=", "self", ".", "span_indices", "[", "0", "]", "\n", "j", "=", "self", ".", "span_indices", "[", "1", "]", "\n", "batch_size", "=", "tf", ".", "shape", "(", "self", ".", "rnn_outs", ")", "[", "0", "]", "\n", "dim", "=", "self", ".", "cfg", "[", "\"num_units\"", "]", "\n", "x_fw", "=", "self", ".", "rnn_outs", "[", ":", ",", ":", ",", ":", "dim", "]", "\n", "x_bw", "=", "self", ".", "rnn_outs", "[", ":", ",", ":", ",", "dim", ":", "]", "\n", "\n", "pad", "=", "tf", ".", "zeros", "(", "shape", "=", "(", "batch_size", ",", "1", ",", "dim", ")", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "x_fw_pad", "=", "tf", ".", "concat", "(", "[", "pad", ",", "x_fw", "]", ",", "axis", "=", "1", ")", "\n", "x_bw_pad", "=", "tf", ".", "concat", "(", "[", "x_bw", ",", "pad", "]", ",", "axis", "=", "1", ")", "\n", "\n", "h_fw_i", "=", "tf", ".", "gather", "(", "x_fw_pad", ",", "i", ",", "axis", "=", "1", ")", "\n", "h_fw_j", "=", "tf", ".", "gather", "(", "x_fw", ",", "j", ",", "axis", "=", "1", ")", "\n", "h_bw_i", "=", "tf", ".", "gather", "(", "x_bw", ",", "i", ",", "axis", "=", "1", ")", "\n", "h_bw_j", "=", "tf", ".", "gather", "(", "x_bw_pad", ",", "j", "+", "1", ",", "axis", "=", "1", ")", "\n", "\n", "span_fw", "=", "h_fw_j", "-", "h_fw_i", "\n", "span_bw", "=", "h_bw_i", "-", "h_bw_j", "\n", "self", ".", "rnn_span_rep", "=", "tf", ".", "concat", "(", "[", "span_fw", ",", "span_bw", "]", ",", "axis", "=", "-", "1", ")", "\n", "\n", "print", "(", "\"rnn span rep shape: {}\"", ".", "format", "(", "\n", "self", ".", "rnn_span_rep", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.models.span_models.SpanModel._build_span_add_and_minus_op": [[193, 222], ["tensorflow.variable_scope", "tensorflow.zeros", "tensorflow.concat", "tensorflow.concat", "tensorflow.gather", "tensorflow.gather", "tensorflow.gather", "tensorflow.gather", "tensorflow.gather", "tensorflow.gather", "tensorflow.concat", "print", "tensorflow.shape", "span_models.SpanModel.rnn_span_rep.get_shape().as_list", "span_models.SpanModel.rnn_span_rep.get_shape"], "methods", ["None"], ["", "", "def", "_build_span_add_and_minus_op", "(", "self", ")", ":", "\n", "    ", "with", "tf", ".", "variable_scope", "(", "\"rnn_span_rep\"", ")", ":", "\n", "      ", "i", "=", "self", ".", "span_indices", "[", "0", "]", "\n", "j", "=", "self", ".", "span_indices", "[", "1", "]", "\n", "batch_size", "=", "tf", ".", "shape", "(", "self", ".", "rnn_outs", ")", "[", "0", "]", "\n", "dim", "=", "self", ".", "cfg", "[", "\"num_units\"", "]", "\n", "x_fw", "=", "self", ".", "rnn_outs", "[", ":", ",", ":", ",", ":", "dim", "]", "\n", "x_bw", "=", "self", ".", "rnn_outs", "[", ":", ",", ":", ",", "dim", ":", "]", "\n", "\n", "pad", "=", "tf", ".", "zeros", "(", "shape", "=", "(", "batch_size", ",", "1", ",", "dim", ")", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "x_fw_pad", "=", "tf", ".", "concat", "(", "[", "pad", ",", "x_fw", "]", ",", "axis", "=", "1", ")", "\n", "x_bw_pad", "=", "tf", ".", "concat", "(", "[", "x_bw", ",", "pad", "]", ",", "axis", "=", "1", ")", "\n", "\n", "h_fw_i", "=", "tf", ".", "gather", "(", "x_fw", ",", "i", ",", "axis", "=", "1", ")", "\n", "h_fw_i_pad", "=", "tf", ".", "gather", "(", "x_fw_pad", ",", "i", ",", "axis", "=", "1", ")", "\n", "h_fw_j", "=", "tf", ".", "gather", "(", "x_fw", ",", "j", ",", "axis", "=", "1", ")", "\n", "h_bw_i", "=", "tf", ".", "gather", "(", "x_bw", ",", "i", ",", "axis", "=", "1", ")", "\n", "h_bw_j", "=", "tf", ".", "gather", "(", "x_bw", ",", "j", ",", "axis", "=", "1", ")", "\n", "h_bw_j_pad", "=", "tf", ".", "gather", "(", "x_bw_pad", ",", "j", "+", "1", ",", "axis", "=", "1", ")", "\n", "\n", "span_add_fw", "=", "h_fw_i", "+", "h_fw_j", "\n", "span_add_bw", "=", "h_bw_i", "+", "h_bw_j", "\n", "span_minus_fw", "=", "h_fw_j", "-", "h_fw_i_pad", "\n", "span_minus_bw", "=", "h_bw_i", "-", "h_bw_j_pad", "\n", "self", ".", "rnn_span_rep", "=", "tf", ".", "concat", "(", "\n", "[", "span_add_fw", ",", "span_add_bw", ",", "span_minus_fw", ",", "span_minus_bw", "]", ",", "axis", "=", "-", "1", ")", "\n", "\n", "print", "(", "\"rnn span rep shape: {}\"", ".", "format", "(", "\n", "self", ".", "rnn_span_rep", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.models.span_models.SpanModel._build_span_projection_op": [[223, 232], ["print", "tensorflow.variable_scope", "tensorflow.layers.dense", "tensorflow.layers.dropout", "span_models.SpanModel.span_rep.get_shape().as_list", "span_models.SpanModel.span_rep.get_shape"], "methods", ["None"], ["", "", "def", "_build_span_projection_op", "(", "self", ")", ":", "\n", "    ", "with", "tf", ".", "variable_scope", "(", "\"span_projection\"", ")", ":", "\n", "      ", "span_rep", "=", "tf", ".", "layers", ".", "dense", "(", "self", ".", "rnn_span_rep", ",", "\n", "units", "=", "self", ".", "cfg", "[", "\"num_units\"", "]", ",", "\n", "use_bias", "=", "True", ")", "\n", "self", ".", "span_rep", "=", "tf", ".", "layers", ".", "dropout", "(", "span_rep", ",", "\n", "rate", "=", "self", ".", "drop_rate", ",", "\n", "training", "=", "self", ".", "is_train", ")", "\n", "", "print", "(", "\"span rep shape: {}\"", ".", "format", "(", "self", ".", "span_rep", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.models.span_models.SpanModel._build_label_projection_with_null_zero_op": [[233, 247], ["tensorflow.variable_scope", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.concat", "tensorflow.tensordot", "print", "span_models.SpanModel.logits.get_shape().as_list", "span_models.SpanModel.logits.get_shape"], "methods", ["None"], ["", "def", "_build_label_projection_with_null_zero_op", "(", "self", ")", ":", "\n", "    ", "with", "tf", ".", "variable_scope", "(", "\"label_projection\"", ")", ":", "\n", "      ", "null_label_emb", "=", "tf", ".", "get_variable", "(", "name", "=", "\"null_label_emb\"", ",", "\n", "trainable", "=", "False", ",", "\n", "shape", "=", "[", "1", ",", "self", ".", "cfg", "[", "\"num_units\"", "]", "]", ")", "\n", "label_emb", "=", "tf", ".", "get_variable", "(", "name", "=", "\"label_emb\"", ",", "\n", "dtype", "=", "tf", ".", "float32", ",", "\n", "trainable", "=", "True", ",", "\n", "shape", "=", "[", "self", ".", "tag_vocab_size", "-", "1", ",", "\n", "self", ".", "cfg", "[", "\"num_units\"", "]", "]", ")", "\n", "self", ".", "label_embeddings", "=", "tf", ".", "concat", "(", "[", "null_label_emb", ",", "label_emb", "]", ",", "axis", "=", "0", ")", "\n", "self", ".", "logits", "=", "tf", ".", "tensordot", "(", "self", ".", "span_rep", ",", "self", ".", "label_embeddings", ",", "\n", "axes", "=", "[", "-", "1", ",", "-", "1", "]", ")", "\n", "print", "(", "\"logits shape: {}\"", ".", "format", "(", "self", ".", "logits", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.models.span_models.SpanModel._build_model_op": [[248, 259], ["span_models.SpanModel._build_rnn_op", "span_models.SpanModel._make_span_indices", "span_models.SpanModel._build_span_projection_op", "span_models.SpanModel._build_label_projection_with_null_zero_op", "span_models.SpanModel._build_span_minus_op", "span_models.SpanModel._build_span_add_and_minus_op"], "methods", ["home.repos.pwc.inspect_result.hiroki13_instance-based-ner.models.span_models.MaskSpanModel._build_rnn_op", "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.models.span_models.SpanModel._make_span_indices", "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.models.span_models.SpanModel._build_span_projection_op", "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.models.span_models.SpanModel._build_label_projection_with_null_zero_op", "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.models.span_models.SpanModel._build_span_minus_op", "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.models.span_models.SpanModel._build_span_add_and_minus_op"], ["", "", "def", "_build_model_op", "(", "self", ")", ":", "\n", "    ", "self", ".", "_build_rnn_op", "(", ")", "\n", "self", ".", "_make_span_indices", "(", ")", "\n", "\n", "if", "self", ".", "cfg", "[", "\"bilstm_type\"", "]", "==", "\"minus\"", ":", "\n", "      ", "self", ".", "_build_span_minus_op", "(", ")", "\n", "", "else", ":", "\n", "      ", "self", ".", "_build_span_add_and_minus_op", "(", ")", "\n", "\n", "", "self", ".", "_build_span_projection_op", "(", ")", "\n", "self", ".", "_build_label_projection_with_null_zero_op", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.models.span_models.SpanModel._build_loss_op": [[260, 265], ["tensorflow.nn.sparse_softmax_cross_entropy_with_logits", "tensorflow.reduce_mean", "tensorflow.summary.scalar", "tensorflow.reduce_sum"], "methods", ["None"], ["", "def", "_build_loss_op", "(", "self", ")", ":", "\n", "    ", "self", ".", "losses", "=", "tf", ".", "nn", ".", "sparse_softmax_cross_entropy_with_logits", "(", "\n", "logits", "=", "self", ".", "logits", ",", "labels", "=", "self", ".", "tags", ")", "\n", "self", ".", "loss", "=", "tf", ".", "reduce_mean", "(", "tf", ".", "reduce_sum", "(", "self", ".", "losses", ",", "axis", "=", "-", "1", ")", ")", "\n", "tf", ".", "summary", ".", "scalar", "(", "\"loss\"", ",", "self", ".", "loss", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.models.span_models.SpanModel._build_train_op": [[266, 275], ["tensorflow.variable_scope", "tensorflow.train.AdamOptimizer", "zip", "tensorflow.clip_by_global_norm", "tensorflow.train.AdamOptimizer.apply_gradients", "tensorflow.train.AdamOptimizer.minimize", "zip", "tensorflow.train.AdamOptimizer.compute_gradients"], "methods", ["None"], ["", "def", "_build_train_op", "(", "self", ")", ":", "\n", "    ", "with", "tf", ".", "variable_scope", "(", "\"train_step\"", ")", ":", "\n", "      ", "optimizer", "=", "tf", ".", "train", ".", "AdamOptimizer", "(", "learning_rate", "=", "self", ".", "lr", ")", "\n", "if", "self", ".", "cfg", "[", "\"grad_clip\"", "]", "is", "not", "None", "and", "self", ".", "cfg", "[", "\"grad_clip\"", "]", ">", "0", ":", "\n", "        ", "grads", ",", "vs", "=", "zip", "(", "*", "optimizer", ".", "compute_gradients", "(", "self", ".", "loss", ")", ")", "\n", "grads", ",", "_", "=", "tf", ".", "clip_by_global_norm", "(", "grads", ",", "self", ".", "cfg", "[", "\"grad_clip\"", "]", ")", "\n", "self", ".", "train_op", "=", "optimizer", ".", "apply_gradients", "(", "zip", "(", "grads", ",", "vs", ")", ")", "\n", "", "else", ":", "\n", "        ", "self", ".", "train_op", "=", "optimizer", ".", "minimize", "(", "self", ".", "loss", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.models.span_models.SpanModel._build_predict_op": [[276, 278], ["tensorflow.cast", "tensorflow.argmax"], "methods", ["None"], ["", "", "", "def", "_build_predict_op", "(", "self", ")", ":", "\n", "    ", "self", ".", "predicts", "=", "tf", ".", "cast", "(", "tf", ".", "argmax", "(", "self", ".", "logits", ",", "axis", "=", "-", "1", ")", ",", "tf", ".", "int32", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.models.span_models.SpanModel.build_proba_op": [[279, 281], ["tensorflow.nn.softmax"], "methods", ["None"], ["", "def", "build_proba_op", "(", "self", ")", ":", "\n", "    ", "self", ".", "proba", "=", "tf", ".", "nn", ".", "softmax", "(", "self", ".", "logits", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.models.span_models.SpanModel.train_epoch": [[282, 319], ["time.time", "utils.data_utils.f_score", "span_models.SpanModel.logger.info", "span_models.SpanModel.logger.info", "span_models.SpanModel.logger.info", "span_models.SpanModel._get_feed_dict", "span_models.SpanModel.sess.run", "utils.data_utils.metrics_for_multi_class_spans", "print", "time.time"], "methods", ["home.repos.pwc.inspect_result.hiroki13_instance-based-ner.utils.data_utils.f_score", "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.models.base_model.BaseModel._get_feed_dict", "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.utils.data_utils.metrics_for_multi_class_spans"], ["", "def", "train_epoch", "(", "self", ",", "batches", ")", ":", "\n", "    ", "loss_total", "=", "0.", "\n", "correct", "=", "0", "\n", "p_total", "=", "0", "\n", "r_total", "=", "0", "\n", "num_batches", "=", "0", "\n", "start_time", "=", "time", ".", "time", "(", ")", "\n", "\n", "for", "batch", "in", "batches", ":", "\n", "      ", "num_batches", "+=", "1", "\n", "if", "num_batches", "%", "100", "==", "0", ":", "\n", "        ", "print", "(", "\"%d\"", "%", "num_batches", ",", "flush", "=", "True", ",", "end", "=", "\" \"", ")", "\n", "\n", "", "feed_dict", "=", "self", ".", "_get_feed_dict", "(", "batch", ",", "is_train", "=", "True", ",", "\n", "keep_prob", "=", "self", ".", "cfg", "[", "\"keep_prob\"", "]", ",", "\n", "lr", "=", "self", ".", "cfg", "[", "\"lr\"", "]", ")", "\n", "outputs", "=", "self", ".", "sess", ".", "run", "(", "[", "self", ".", "train_op", ",", "self", ".", "loss", ",", "self", ".", "predicts", "]", ",", "\n", "feed_dict", ")", "\n", "_", ",", "train_loss", ",", "predicts", "=", "outputs", "\n", "\n", "loss_total", "+=", "train_loss", "\n", "crr_i", ",", "p_total_i", ",", "r_total_i", "=", "metrics_for_multi_class_spans", "(", "\n", "batch", "[", "\"tags\"", "]", ",", "predicts", ",", "NULL_LABEL_ID", ")", "\n", "correct", "+=", "crr_i", "\n", "p_total", "+=", "p_total_i", "\n", "r_total", "+=", "r_total_i", "\n", "\n", "", "avg_loss", "=", "loss_total", "/", "num_batches", "\n", "p", ",", "r", ",", "f", "=", "f_score", "(", "correct", ",", "p_total", ",", "r_total", ")", "\n", "\n", "self", ".", "logger", ".", "info", "(", "\"-- Time: %f seconds\"", "%", "(", "time", ".", "time", "(", ")", "-", "start_time", ")", ")", "\n", "self", ".", "logger", ".", "info", "(", "\n", "\"-- Averaged loss: %f(%f/%d)\"", "%", "(", "avg_loss", ",", "loss_total", ",", "num_batches", ")", ")", "\n", "self", ".", "logger", ".", "info", "(", "\n", "\"-- {} set\\tF:{:>7.2%} P:{:>7.2%} ({:>5}/{:>5}) R:{:>7.2%} ({:>5}/{:>5})\"", "\n", ".", "format", "(", "\"train\"", ",", "f", ",", "p", ",", "correct", ",", "p_total", ",", "r", ",", "correct", ",", "r_total", ")", ")", "\n", "return", "avg_loss", ",", "loss_total", "\n", "\n"]], "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.models.span_models.SpanModel.evaluate_epoch": [[320, 344], ["time.time", "utils.data_utils.f_score", "span_models.SpanModel.logger.info", "span_models.SpanModel.logger.info", "span_models.SpanModel._get_feed_dict", "span_models.SpanModel.sess.run", "utils.data_utils.count_gold_and_system_outputs", "print", "time.time"], "methods", ["home.repos.pwc.inspect_result.hiroki13_instance-based-ner.utils.data_utils.f_score", "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.models.base_model.BaseModel._get_feed_dict", "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.utils.data_utils.count_gold_and_system_outputs"], ["", "def", "evaluate_epoch", "(", "self", ",", "batches", ",", "name", ")", ":", "\n", "    ", "correct", "=", "0", "\n", "p_total", "=", "0", "\n", "num_batches", "=", "0", "\n", "start_time", "=", "time", ".", "time", "(", ")", "\n", "\n", "for", "batch", "in", "batches", ":", "\n", "      ", "num_batches", "+=", "1", "\n", "if", "num_batches", "%", "100", "==", "0", ":", "\n", "        ", "print", "(", "\"%d\"", "%", "num_batches", ",", "flush", "=", "True", ",", "end", "=", "\" \"", ")", "\n", "\n", "", "feed_dict", "=", "self", ".", "_get_feed_dict", "(", "batch", ")", "\n", "predicts", "=", "self", ".", "sess", ".", "run", "(", "self", ".", "predicts", ",", "feed_dict", ")", "\n", "crr_i", ",", "p_total_i", "=", "count_gold_and_system_outputs", "(", "\n", "batch", "[", "\"tags\"", "]", ",", "predicts", ",", "NULL_LABEL_ID", ")", "\n", "correct", "+=", "crr_i", "\n", "p_total", "+=", "p_total_i", "\n", "\n", "", "p", ",", "r", ",", "f", "=", "f_score", "(", "correct", ",", "p_total", ",", "self", ".", "n_gold_spans", ")", "\n", "self", ".", "logger", ".", "info", "(", "'-- Time: %f seconds'", "%", "(", "time", ".", "time", "(", ")", "-", "start_time", ")", ")", "\n", "self", ".", "logger", ".", "info", "(", "\n", "\"-- {} set\\tF:{:>7.2%} P:{:>7.2%} ({:>5}/{:>5}) R:{:>7.2%} ({:>5}/{:>5})\"", "\n", ".", "format", "(", "name", ",", "f", ",", "p", ",", "correct", ",", "p_total", ",", "r", ",", "correct", ",", "self", ".", "n_gold_spans", ")", ")", "\n", "return", "f", ",", "p", ",", "r", ",", "correct", ",", "p_total", ",", "self", ".", "n_gold_spans", "\n", "\n"]], "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.models.span_models.SpanModel.train": [[345, 386], ["span_models.SpanModel.logger.info", "utils.common.write_json", "utils.data_utils.count_gold_spans", "list", "span_models.SpanModel.log_trainable_variables", "span_models.SpanModel.logger.info", "span_models.SpanModel._add_summary", "range", "span_models.SpanModel.train_writer.close", "span_models.SpanModel.test_writer.close", "str", "os.path.join", "span_models.SpanModel.batcher.batchnize_dataset", "span_models.SpanModel.logger.info", "span_models.SpanModel.batcher.batchnize_dataset", "span_models.SpanModel.train_epoch", "span_models.SpanModel.evaluate_epoch", "max", "span_models.SpanModel.save_session", "span_models.SpanModel.logger.info"], "methods", ["home.repos.pwc.inspect_result.hiroki13_instance-based-ner.scripts.retrieve_knn_sents_with_glove.write_json", "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.utils.data_utils.count_gold_spans", "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.models.base_model.BaseModel.log_trainable_variables", "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.models.base_model.BaseModel._add_summary", "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.batchers.span_batchers.MaskSpanBatcher.batchnize_dataset", "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.batchers.span_batchers.MaskSpanBatcher.batchnize_dataset", "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.models.base_model.BaseModel.train_epoch", "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.models.span_models.SpanModel.evaluate_epoch", "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.models.base_model.BaseModel.save_session"], ["", "def", "train", "(", "self", ")", ":", "\n", "    ", "self", ".", "logger", ".", "info", "(", "str", "(", "self", ".", "cfg", ")", ")", "\n", "write_json", "(", "os", ".", "path", ".", "join", "(", "self", ".", "cfg", "[", "\"checkpoint_path\"", "]", ",", "\"config.json\"", ")", ",", "\n", "self", ".", "cfg", ")", "\n", "\n", "batch_size", "=", "self", ".", "cfg", "[", "\"batch_size\"", "]", "\n", "epochs", "=", "self", ".", "cfg", "[", "\"epochs\"", "]", "\n", "train_path", "=", "self", ".", "cfg", "[", "\"train_set\"", "]", "\n", "valid_path", "=", "self", ".", "cfg", "[", "\"valid_set\"", "]", "\n", "self", ".", "n_gold_spans", "=", "count_gold_spans", "(", "valid_path", ")", "\n", "valid_set", "=", "list", "(", "\n", "self", ".", "batcher", ".", "batchnize_dataset", "(", "valid_path", ",", "batch_size", ",", "shuffle", "=", "True", ")", ")", "\n", "\n", "best_f1", "=", "-", "np", ".", "inf", "\n", "init_lr", "=", "self", ".", "cfg", "[", "\"lr\"", "]", "\n", "\n", "self", ".", "log_trainable_variables", "(", ")", "\n", "self", ".", "logger", ".", "info", "(", "\"Start training...\"", ")", "\n", "self", ".", "_add_summary", "(", ")", "\n", "for", "epoch", "in", "range", "(", "1", ",", "epochs", "+", "1", ")", ":", "\n", "      ", "self", ".", "logger", ".", "info", "(", "'Epoch {}/{}:'", ".", "format", "(", "epoch", ",", "epochs", ")", ")", "\n", "\n", "train_set", "=", "self", ".", "batcher", ".", "batchnize_dataset", "(", "train_path", ",", "batch_size", ",", "\n", "shuffle", "=", "True", ")", "\n", "_", "=", "self", ".", "train_epoch", "(", "train_set", ")", "\n", "\n", "if", "self", ".", "cfg", "[", "\"use_lr_decay\"", "]", ":", "# learning rate decay", "\n", "        ", "self", ".", "cfg", "[", "\"lr\"", "]", "=", "max", "(", "init_lr", "/", "(", "1.0", "+", "self", ".", "cfg", "[", "\"lr_decay\"", "]", "*", "epoch", ")", ",", "\n", "self", ".", "cfg", "[", "\"minimal_lr\"", "]", ")", "\n", "\n", "", "eval_metrics", "=", "self", ".", "evaluate_epoch", "(", "valid_set", ",", "\"valid\"", ")", "\n", "cur_valid_f1", "=", "eval_metrics", "[", "0", "]", "\n", "\n", "if", "cur_valid_f1", ">", "best_f1", ":", "\n", "        ", "best_f1", "=", "cur_valid_f1", "\n", "self", ".", "save_session", "(", "epoch", ")", "\n", "self", ".", "logger", ".", "info", "(", "\n", "\"-- new BEST F1 on valid set: {:>7.2%}\"", ".", "format", "(", "best_f1", ")", ")", "\n", "\n", "", "", "self", ".", "train_writer", ".", "close", "(", ")", "\n", "self", ".", "test_writer", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.models.span_models.SpanModel.eval": [[387, 406], ["span_models.SpanModel.logger.info", "preprocessor.load_dataset", "preprocessor.build_dataset", "utils.common.write_json", "utils.data_utils.count_gold_spans", "span_models.SpanModel.logger.info", "list", "span_models.SpanModel.logger.info", "span_models.SpanModel.evaluate_epoch", "str", "os.path.join", "os.path.join", "span_models.SpanModel.batcher.batchnize_dataset", "len", "os.path.join", "len"], "methods", ["home.repos.pwc.inspect_result.hiroki13_instance-based-ner.preprocessors.span_preprocessors.SpanPreprocessor.load_dataset", "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.preprocessors.span_preprocessors.SpanPreprocessor.build_dataset", "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.scripts.retrieve_knn_sents_with_glove.write_json", "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.utils.data_utils.count_gold_spans", "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.models.span_models.SpanModel.evaluate_epoch", "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.batchers.span_batchers.MaskSpanBatcher.batchnize_dataset"], ["", "def", "eval", "(", "self", ",", "preprocessor", ")", ":", "\n", "    ", "self", ".", "logger", ".", "info", "(", "str", "(", "self", ".", "cfg", ")", ")", "\n", "data", "=", "preprocessor", ".", "load_dataset", "(", "self", ".", "cfg", "[", "\"data_path\"", "]", ",", "\n", "keep_number", "=", "True", ",", "\n", "lowercase", "=", "self", ".", "cfg", "[", "\"char_lowercase\"", "]", ")", "\n", "data", "=", "data", "[", ":", "self", ".", "cfg", "[", "\"data_size\"", "]", "]", "\n", "dataset", "=", "preprocessor", ".", "build_dataset", "(", "data", ",", "self", ".", "word_dict", ",", "\n", "self", ".", "char_dict", ",", "self", ".", "tag_dict", ")", "\n", "write_json", "(", "os", ".", "path", ".", "join", "(", "self", ".", "cfg", "[", "\"save_path\"", "]", ",", "\"tmp.json\"", ")", ",", "dataset", ")", "\n", "self", ".", "n_gold_spans", "=", "count_gold_spans", "(", "\n", "os", ".", "path", ".", "join", "(", "self", ".", "cfg", "[", "\"save_path\"", "]", ",", "\"tmp.json\"", ")", ")", "\n", "self", ".", "logger", ".", "info", "(", "\"Target data: %s sentences\"", "%", "len", "(", "dataset", ")", ")", "\n", "del", "dataset", "\n", "\n", "batches", "=", "list", "(", "self", ".", "batcher", ".", "batchnize_dataset", "(", "\n", "os", ".", "path", ".", "join", "(", "self", ".", "cfg", "[", "\"save_path\"", "]", ",", "\"tmp.json\"", ")", ",", "\n", "batch_size", "=", "self", ".", "cfg", "[", "\"batch_size\"", "]", ",", "shuffle", "=", "True", ")", ")", "\n", "self", ".", "logger", ".", "info", "(", "\"Target data: %s batches\"", "%", "len", "(", "batches", ")", ")", "\n", "_", "=", "self", ".", "evaluate_epoch", "(", "batches", ",", "\"valid\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.models.span_models.SpanModel.make_one_batch": [[407, 413], ["span_models.SpanModel.batcher.make_each_batch"], "methods", ["home.repos.pwc.inspect_result.hiroki13_instance-based-ner.batchers.span_batchers.MaskSpanBatcher.make_each_batch"], ["", "def", "make_one_batch", "(", "self", ",", "data", ",", "add_tags", "=", "True", ")", ":", "\n", "    ", "return", "self", ".", "batcher", ".", "make_each_batch", "(", "\n", "batch_words", "=", "[", "data", "[", "\"words\"", "]", "]", ",", "\n", "batch_chars", "=", "[", "data", "[", "\"chars\"", "]", "]", ",", "\n", "max_span_len", "=", "self", ".", "max_span_len", ",", "\n", "batch_tags", "=", "[", "data", "[", "\"tags\"", "]", "]", "if", "add_tags", "else", "None", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.models.span_models.SpanModel.save_predicted_spans": [[414, 476], ["span_models.SpanModel.logger.info", "preprocessor.load_dataset", "preprocessor.build_dataset", "os.path.join", "utils.common.write_json", "span_models.SpanModel.logger.info", "time.time", "print", "zip", "os.path.join", "utils.common.write_json", "span_models.SpanModel.logger.info", "str", "span_models.SpanModel.batcher.make_each_batch", "span_models.SpanModel._get_feed_dict", "models.decoders.get_span_indices", "results.append", "len", "print", "span_models.SpanModel.sess.run", "len", "len", "len", "len", "int", "int", "zip", "time.time"], "methods", ["home.repos.pwc.inspect_result.hiroki13_instance-based-ner.preprocessors.span_preprocessors.SpanPreprocessor.load_dataset", "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.preprocessors.span_preprocessors.SpanPreprocessor.build_dataset", "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.scripts.retrieve_knn_sents_with_glove.write_json", "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.scripts.retrieve_knn_sents_with_glove.write_json", "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.batchers.span_batchers.MaskSpanBatcher.make_each_batch", "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.models.base_model.BaseModel._get_feed_dict", "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.models.decoders.get_span_indices"], ["", "def", "save_predicted_spans", "(", "self", ",", "data_name", ",", "preprocessor", ")", ":", "\n", "    ", "self", ".", "logger", ".", "info", "(", "str", "(", "self", ".", "cfg", ")", ")", "\n", "\n", "########################", "\n", "# Load validation data #", "\n", "########################", "\n", "valid_data", "=", "preprocessor", ".", "load_dataset", "(", "\n", "self", ".", "cfg", "[", "\"data_path\"", "]", ",", "keep_number", "=", "True", ",", "\n", "lowercase", "=", "self", ".", "cfg", "[", "\"char_lowercase\"", "]", ")", "\n", "valid_data", "=", "valid_data", "[", ":", "self", ".", "cfg", "[", "\"data_size\"", "]", "]", "\n", "dataset", "=", "preprocessor", ".", "build_dataset", "(", "valid_data", ",", "\n", "self", ".", "word_dict", ",", "\n", "self", ".", "char_dict", ",", "\n", "self", ".", "tag_dict", ")", "\n", "dataset_path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "cfg", "[", "\"save_path\"", "]", ",", "\"tmp.json\"", ")", "\n", "write_json", "(", "dataset_path", ",", "dataset", ")", "\n", "self", ".", "logger", ".", "info", "(", "\"Valid sentences: {:>7}\"", ".", "format", "(", "len", "(", "dataset", ")", ")", ")", "\n", "\n", "#############", "\n", "# Main loop #", "\n", "#############", "\n", "start_time", "=", "time", ".", "time", "(", ")", "\n", "results", "=", "[", "]", "\n", "print", "(", "\"PREDICTION START\"", ")", "\n", "for", "record", ",", "data", "in", "zip", "(", "valid_data", ",", "dataset", ")", ":", "\n", "      ", "valid_sent_id", "=", "record", "[", "\"sent_id\"", "]", "\n", "batch", "=", "self", ".", "batcher", ".", "make_each_batch", "(", "\n", "batch_words", "=", "[", "data", "[", "\"words\"", "]", "]", ",", "batch_chars", "=", "[", "data", "[", "\"chars\"", "]", "]", ",", "\n", "max_span_len", "=", "self", ".", "max_span_len", ")", "\n", "\n", "if", "(", "valid_sent_id", "+", "1", ")", "%", "100", "==", "0", ":", "\n", "        ", "print", "(", "\"%d\"", "%", "(", "valid_sent_id", "+", "1", ")", ",", "flush", "=", "True", ",", "end", "=", "\" \"", ")", "\n", "\n", "#################", "\n", "# Predict spans #", "\n", "#################", "\n", "", "feed_dict", "=", "self", ".", "_get_feed_dict", "(", "batch", ")", "\n", "batch_preds", "=", "self", ".", "sess", ".", "run", "(", "[", "self", ".", "predicts", "]", ",", "feed_dict", ")", "[", "0", "]", "\n", "preds", "=", "batch_preds", "[", "0", "]", "\n", "\n", "########################", "\n", "# Make predicted spans #", "\n", "########################", "\n", "indx_i", ",", "indx_j", "=", "get_span_indices", "(", "n_words", "=", "len", "(", "record", "[", "\"words\"", "]", ")", ",", "\n", "max_span_len", "=", "self", ".", "max_span_len", ")", "\n", "assert", "len", "(", "preds", ")", "==", "len", "(", "indx_i", ")", "==", "len", "(", "indx_j", ")", "\n", "pred_spans", "=", "[", "[", "self", ".", "rev_tag_dict", "[", "pred_label_id", "]", ",", "int", "(", "i", ")", ",", "int", "(", "j", ")", "]", "\n", "for", "pred_label_id", ",", "i", ",", "j", "in", "zip", "(", "preds", ",", "indx_i", ",", "indx_j", ")", "\n", "if", "pred_label_id", "!=", "NULL_LABEL_ID", "]", "\n", "\n", "##################", "\n", "# Add the result #", "\n", "##################", "\n", "results", ".", "append", "(", "{", "\"sent_id\"", ":", "valid_sent_id", ",", "\n", "\"words\"", ":", "record", "[", "\"words\"", "]", ",", "\n", "\"spans\"", ":", "pred_spans", "}", ")", "\n", "\n", "", "path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "cfg", "[", "\"checkpoint_path\"", "]", ",", "\n", "\"%s.predicted_spans.json\"", "%", "data_name", ")", "\n", "write_json", "(", "path", ",", "results", ")", "\n", "self", ".", "logger", ".", "info", "(", "\n", "\"-- Time: %f seconds\\nFINISHED.\"", "%", "(", "time", ".", "time", "(", ")", "-", "start_time", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.models.span_models.SpanModel.save_predicted_bio_tags": [[477, 539], ["span_models.SpanModel.logger.info", "preprocessor.load_dataset", "preprocessor.build_dataset", "os.path.join", "utils.common.write_json", "span_models.SpanModel.logger.info", "time.time", "os.path.join", "open", "print", "zip", "span_models.SpanModel.logger.info", "str", "span_models.SpanModel.make_one_batch", "span_models.SpanModel._get_feed_dict", "models.decoders.greedy_search", "utils.data_utils.span2bio", "utils.data_utils.span2bio", "zip", "open.write", "len", "print", "len", "len", "len", "open.write", "span_models.SpanModel.sess.run", "len", "len", "len", "time.time"], "methods", ["home.repos.pwc.inspect_result.hiroki13_instance-based-ner.preprocessors.span_preprocessors.SpanPreprocessor.load_dataset", "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.preprocessors.span_preprocessors.SpanPreprocessor.build_dataset", "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.scripts.retrieve_knn_sents_with_glove.write_json", "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.models.span_models.SpanModel.make_one_batch", "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.models.base_model.BaseModel._get_feed_dict", "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.models.decoders.greedy_search", "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.utils.data_utils.span2bio", "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.utils.data_utils.span2bio"], ["", "def", "save_predicted_bio_tags", "(", "self", ",", "data_name", ",", "preprocessor", ")", ":", "\n", "    ", "self", ".", "logger", ".", "info", "(", "str", "(", "self", ".", "cfg", ")", ")", "\n", "\n", "########################", "\n", "# Load validation data #", "\n", "########################", "\n", "valid_data", "=", "preprocessor", ".", "load_dataset", "(", "\n", "self", ".", "cfg", "[", "\"data_path\"", "]", ",", "keep_number", "=", "True", ",", "\n", "lowercase", "=", "self", ".", "cfg", "[", "\"char_lowercase\"", "]", ")", "\n", "valid_data", "=", "valid_data", "[", ":", "self", ".", "cfg", "[", "\"data_size\"", "]", "]", "\n", "dataset", "=", "preprocessor", ".", "build_dataset", "(", "valid_data", ",", "\n", "self", ".", "word_dict", ",", "\n", "self", ".", "char_dict", ",", "\n", "self", ".", "tag_dict", ")", "\n", "dataset_path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "cfg", "[", "\"save_path\"", "]", ",", "\"tmp.json\"", ")", "\n", "write_json", "(", "dataset_path", ",", "dataset", ")", "\n", "self", ".", "logger", ".", "info", "(", "\"Valid sentences: {:>7}\"", ".", "format", "(", "len", "(", "dataset", ")", ")", ")", "\n", "\n", "#############", "\n", "# Main loop #", "\n", "#############", "\n", "start_time", "=", "time", ".", "time", "(", ")", "\n", "path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "cfg", "[", "\"checkpoint_path\"", "]", ",", "\"%s.bio.txt\"", "%", "data_name", ")", "\n", "fout_txt", "=", "open", "(", "path", ",", "\"w\"", ")", "\n", "print", "(", "\"PREDICTION START\"", ")", "\n", "for", "record", ",", "data", "in", "zip", "(", "valid_data", ",", "dataset", ")", ":", "\n", "      ", "valid_sent_id", "=", "record", "[", "\"sent_id\"", "]", "\n", "batch", "=", "self", ".", "make_one_batch", "(", "data", ",", "add_tags", "=", "False", ")", "\n", "\n", "if", "(", "valid_sent_id", "+", "1", ")", "%", "100", "==", "0", ":", "\n", "        ", "print", "(", "\"%d\"", "%", "(", "valid_sent_id", "+", "1", ")", ",", "flush", "=", "True", ",", "end", "=", "\" \"", ")", "\n", "\n", "#################", "\n", "# Predict spans #", "\n", "#################", "\n", "", "feed_dict", "=", "self", ".", "_get_feed_dict", "(", "batch", ")", "\n", "proba", "=", "self", ".", "sess", ".", "run", "(", "[", "self", ".", "proba", "]", ",", "feed_dict", ")", "[", "0", "]", "[", "0", "]", "\n", "\n", "########################", "\n", "# Make predicted spans #", "\n", "########################", "\n", "words", "=", "record", "[", "\"words\"", "]", "\n", "triples", "=", "greedy_search", "(", "proba", ",", "\n", "n_words", "=", "len", "(", "words", ")", ",", "\n", "max_span_len", "=", "self", ".", "max_span_len", ",", "\n", "null_label_id", "=", "NULL_LABEL_ID", ")", "\n", "pred_bio_tags", "=", "span2bio", "(", "spans", "=", "triples", ",", "\n", "n_words", "=", "len", "(", "words", ")", ",", "\n", "tag_dict", "=", "self", ".", "rev_tag_dict", ")", "\n", "gold_bio_tags", "=", "span2bio", "(", "spans", "=", "record", "[", "\"tags\"", "]", ",", "\n", "n_words", "=", "len", "(", "words", ")", ")", "\n", "assert", "len", "(", "words", ")", "==", "len", "(", "pred_bio_tags", ")", "==", "len", "(", "gold_bio_tags", ")", "\n", "\n", "####################", "\n", "# Write the result #", "\n", "####################", "\n", "for", "word", ",", "gold_tag", ",", "pred_tag", "in", "zip", "(", "words", ",", "gold_bio_tags", ",", "pred_bio_tags", ")", ":", "\n", "        ", "fout_txt", ".", "write", "(", "\"%s _ %s %s\\n\"", "%", "(", "word", ",", "gold_tag", ",", "pred_tag", ")", ")", "\n", "", "fout_txt", ".", "write", "(", "\"\\n\"", ")", "\n", "\n", "", "self", ".", "logger", ".", "info", "(", "\n", "\"-- Time: %f seconds\\nFINISHED.\"", "%", "(", "time", ".", "time", "(", ")", "-", "start_time", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.models.span_models.SpanModel.save_span_representation": [[540, 611], ["span_models.SpanModel.logger.info", "preprocessor.load_dataset", "preprocessor.build_dataset", "os.path.join", "utils.common.write_json", "span_models.SpanModel.logger.info", "time.time", "h5py.File", "print", "zip", "h5py.File.close", "utils.common.write_json", "span_models.SpanModel.logger.info", "str", "os.path.join", "span_models.SpanModel.batcher.make_each_batch", "span_models.SpanModel._get_feed_dict", "span_models.SpanModel.sess.run", "models.decoders.get_span_indices", "h5py.File.create_dataset", "results.append", "os.path.join", "len", "print", "len", "len", "len", "len", "len", "len", "len", "int", "int", "zip", "int", "int", "zip", "time.time"], "methods", ["home.repos.pwc.inspect_result.hiroki13_instance-based-ner.preprocessors.span_preprocessors.SpanPreprocessor.load_dataset", "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.preprocessors.span_preprocessors.SpanPreprocessor.build_dataset", "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.scripts.retrieve_knn_sents_with_glove.write_json", "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.scripts.retrieve_knn_sents_with_glove.write_json", "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.batchers.span_batchers.MaskSpanBatcher.make_each_batch", "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.models.base_model.BaseModel._get_feed_dict", "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.models.decoders.get_span_indices"], ["", "def", "save_span_representation", "(", "self", ",", "data_name", ",", "preprocessor", ")", ":", "\n", "    ", "self", ".", "logger", ".", "info", "(", "str", "(", "self", ".", "cfg", ")", ")", "\n", "\n", "########################", "\n", "# Load validation data #", "\n", "########################", "\n", "valid_data", "=", "preprocessor", ".", "load_dataset", "(", "\n", "self", ".", "cfg", "[", "\"data_path\"", "]", ",", "keep_number", "=", "True", ",", "\n", "lowercase", "=", "self", ".", "cfg", "[", "\"char_lowercase\"", "]", ")", "\n", "valid_data", "=", "valid_data", "[", ":", "self", ".", "cfg", "[", "\"data_size\"", "]", "]", "\n", "dataset", "=", "preprocessor", ".", "build_dataset", "(", "valid_data", ",", "self", ".", "word_dict", ",", "\n", "self", ".", "char_dict", ",", "self", ".", "tag_dict", ")", "\n", "dataset_path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "cfg", "[", "\"save_path\"", "]", ",", "\"tmp.json\"", ")", "\n", "write_json", "(", "dataset_path", ",", "dataset", ")", "\n", "self", ".", "logger", ".", "info", "(", "\"Valid sentences: {:>7}\"", ".", "format", "(", "len", "(", "dataset", ")", ")", ")", "\n", "\n", "#############", "\n", "# Main loop #", "\n", "#############", "\n", "start_time", "=", "time", ".", "time", "(", ")", "\n", "results", "=", "[", "]", "\n", "fout_hdf5", "=", "h5py", ".", "File", "(", "os", ".", "path", ".", "join", "(", "self", ".", "cfg", "[", "\"checkpoint_path\"", "]", ",", "\n", "\"%s.span_reps.hdf5\"", "%", "data_name", ")", ",", "'w'", ")", "\n", "print", "(", "\"PREDICTION START\"", ")", "\n", "for", "record", ",", "data", "in", "zip", "(", "valid_data", ",", "dataset", ")", ":", "\n", "      ", "valid_sent_id", "=", "record", "[", "\"sent_id\"", "]", "\n", "batch", "=", "self", ".", "batcher", ".", "make_each_batch", "(", "\n", "batch_words", "=", "[", "data", "[", "\"words\"", "]", "]", ",", "batch_chars", "=", "[", "data", "[", "\"chars\"", "]", "]", ",", "\n", "max_span_len", "=", "self", ".", "max_span_len", ",", "batch_tags", "=", "[", "data", "[", "\"tags\"", "]", "]", ")", "\n", "\n", "if", "(", "valid_sent_id", "+", "1", ")", "%", "100", "==", "0", ":", "\n", "        ", "print", "(", "\"%d\"", "%", "(", "valid_sent_id", "+", "1", ")", ",", "flush", "=", "True", ",", "end", "=", "\" \"", ")", "\n", "\n", "#################", "\n", "# Predict spans #", "\n", "#################", "\n", "", "feed_dict", "=", "self", ".", "_get_feed_dict", "(", "batch", ")", "\n", "preds", ",", "span_reps", "=", "self", ".", "sess", ".", "run", "(", "[", "self", ".", "predicts", ",", "self", ".", "span_rep", "]", ",", "\n", "feed_dict", "=", "feed_dict", ")", "\n", "golds", "=", "batch", "[", "\"tags\"", "]", "[", "0", "]", "\n", "preds", "=", "preds", "[", "0", "]", "\n", "span_reps", "=", "span_reps", "[", "0", "]", "\n", "assert", "len", "(", "span_reps", ")", "==", "len", "(", "golds", ")", "==", "len", "(", "preds", ")", "\n", "\n", "########################", "\n", "# Make predicted spans #", "\n", "########################", "\n", "indx_i", ",", "indx_j", "=", "get_span_indices", "(", "n_words", "=", "len", "(", "record", "[", "\"words\"", "]", ")", ",", "\n", "max_span_len", "=", "self", ".", "max_span_len", ")", "\n", "assert", "len", "(", "preds", ")", "==", "len", "(", "indx_i", ")", "==", "len", "(", "indx_j", ")", "\n", "pred_spans", "=", "[", "[", "self", ".", "rev_tag_dict", "[", "label_id", "]", ",", "int", "(", "i", ")", ",", "int", "(", "j", ")", "]", "\n", "for", "label_id", ",", "i", ",", "j", "in", "zip", "(", "preds", ",", "indx_i", ",", "indx_j", ")", "]", "\n", "gold_spans", "=", "[", "[", "self", ".", "rev_tag_dict", "[", "label_id", "]", ",", "int", "(", "i", ")", ",", "int", "(", "j", ")", "]", "\n", "for", "label_id", ",", "i", ",", "j", "in", "zip", "(", "golds", ",", "indx_i", ",", "indx_j", ")", "]", "\n", "\n", "####################", "\n", "# Write the result #", "\n", "####################", "\n", "fout_hdf5", ".", "create_dataset", "(", "\n", "name", "=", "'{}'", ".", "format", "(", "valid_sent_id", ")", ",", "\n", "dtype", "=", "'float32'", ",", "\n", "data", "=", "span_reps", ")", "\n", "results", ".", "append", "(", "{", "\"sent_id\"", ":", "valid_sent_id", ",", "\n", "\"words\"", ":", "record", "[", "\"words\"", "]", ",", "\n", "\"gold_spans\"", ":", "gold_spans", ",", "\n", "\"pred_spans\"", ":", "pred_spans", "}", ")", "\n", "", "fout_hdf5", ".", "close", "(", ")", "\n", "write_json", "(", "os", ".", "path", ".", "join", "(", "self", ".", "cfg", "[", "\"checkpoint_path\"", "]", ",", "\n", "\"%s.spans.json\"", "%", "data_name", ")", ",", "results", ")", "\n", "self", ".", "logger", ".", "info", "(", "\n", "\"-- Time: %f seconds\\nFINISHED.\"", "%", "(", "time", ".", "time", "(", ")", "-", "start_time", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.models.span_models.MaskSpanModel._add_placeholders": [[615, 628], ["tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder"], "methods", ["None"], ["  ", "def", "_add_placeholders", "(", "self", ")", ":", "\n", "    ", "self", ".", "words", "=", "tf", ".", "placeholder", "(", "tf", ".", "int32", ",", "shape", "=", "[", "None", ",", "None", "]", ",", "name", "=", "\"words\"", ")", "\n", "self", ".", "tags", "=", "tf", ".", "placeholder", "(", "tf", ".", "int32", ",", "shape", "=", "[", "None", ",", "None", "]", ",", "name", "=", "\"tags\"", ")", "\n", "self", ".", "seq_len", "=", "tf", ".", "placeholder", "(", "tf", ".", "int32", ",", "shape", "=", "[", "None", "]", ",", "name", "=", "\"seq_len\"", ")", "\n", "self", ".", "masks", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "shape", "=", "[", "None", ",", "None", "]", ",", "name", "=", "\"mask\"", ")", "\n", "if", "self", ".", "cfg", "[", "\"use_chars\"", "]", ":", "\n", "      ", "self", ".", "chars", "=", "tf", ".", "placeholder", "(", "tf", ".", "int32", ",", "shape", "=", "[", "None", ",", "None", ",", "None", "]", ",", "\n", "name", "=", "\"chars\"", ")", "\n", "# hyperparameters", "\n", "", "self", ".", "is_train", "=", "tf", ".", "placeholder", "(", "tf", ".", "bool", ",", "name", "=", "\"is_train\"", ")", "\n", "self", ".", "keep_prob", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "name", "=", "\"rnn_keep_probability\"", ")", "\n", "self", ".", "drop_rate", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "name", "=", "\"dropout_rate\"", ")", "\n", "self", ".", "lr", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "name", "=", "\"learning_rate\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.models.span_models.MaskSpanModel._get_feed_dict": [[629, 643], ["None"], "methods", ["None"], ["", "def", "_get_feed_dict", "(", "self", ",", "batch", ",", "keep_prob", "=", "1.0", ",", "is_train", "=", "False", ",", "lr", "=", "None", ")", ":", "\n", "    ", "feed_dict", "=", "{", "self", ".", "words", ":", "batch", "[", "\"words\"", "]", ",", "\n", "self", ".", "seq_len", ":", "batch", "[", "\"seq_len\"", "]", ",", "\n", "self", ".", "masks", ":", "batch", "[", "\"masks\"", "]", "}", "\n", "if", "\"tags\"", "in", "batch", ":", "\n", "      ", "feed_dict", "[", "self", ".", "tags", "]", "=", "batch", "[", "\"tags\"", "]", "\n", "", "if", "self", ".", "cfg", "[", "\"use_chars\"", "]", ":", "\n", "      ", "feed_dict", "[", "self", ".", "chars", "]", "=", "batch", "[", "\"chars\"", "]", "\n", "", "feed_dict", "[", "self", ".", "keep_prob", "]", "=", "keep_prob", "\n", "feed_dict", "[", "self", ".", "drop_rate", "]", "=", "1.0", "-", "keep_prob", "\n", "feed_dict", "[", "self", ".", "is_train", "]", "=", "is_train", "\n", "if", "lr", "is", "not", "None", ":", "\n", "      ", "feed_dict", "[", "self", ".", "lr", "]", "=", "lr", "\n", "", "return", "feed_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.models.span_models.MaskSpanModel._build_rnn_op": [[644, 663], ["tensorflow.variable_scope", "span_models.MaskSpanModel._create_rnn_cell", "span_models.MaskSpanModel._create_rnn_cell", "tensorflow.concat", "tensorflow.layers.dropout", "print", "tensorflow.contrib.rnn.python.ops.rnn.stack_bidirectional_dynamic_rnn", "tensorflow.python.ops.rnn.bidirectional_dynamic_rnn", "tensorflow.layers.dropout.get_shape().as_list", "tensorflow.layers.dropout.get_shape"], "methods", ["home.repos.pwc.inspect_result.hiroki13_instance-based-ner.models.base_model.BaseModel._create_rnn_cell", "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.models.base_model.BaseModel._create_rnn_cell"], ["", "def", "_build_rnn_op", "(", "self", ")", ":", "\n", "    ", "with", "tf", ".", "variable_scope", "(", "\"bi_directional_rnn\"", ")", ":", "\n", "      ", "cell_fw", "=", "self", ".", "_create_rnn_cell", "(", ")", "\n", "cell_bw", "=", "self", ".", "_create_rnn_cell", "(", ")", "\n", "\n", "if", "self", ".", "cfg", "[", "\"use_stack_rnn\"", "]", ":", "\n", "        ", "rnn_outs", ",", "*", "_", "=", "stack_bidirectional_dynamic_rnn", "(", "\n", "cell_fw", ",", "cell_bw", ",", "self", ".", "word_emb", ",", "\n", "dtype", "=", "tf", ".", "float32", ",", "sequence_length", "=", "self", ".", "seq_len", ")", "\n", "", "else", ":", "\n", "        ", "rnn_outs", ",", "*", "_", "=", "bidirectional_dynamic_rnn", "(", "\n", "cell_fw", ",", "cell_bw", ",", "self", ".", "word_emb", ",", "\n", "dtype", "=", "tf", ".", "float32", ",", "sequence_length", "=", "self", ".", "seq_len", ")", "\n", "", "rnn_outs", "=", "tf", ".", "concat", "(", "rnn_outs", ",", "axis", "=", "-", "1", ")", "\n", "rnn_outs", "=", "tf", ".", "layers", ".", "dropout", "(", "rnn_outs", ",", "\n", "rate", "=", "self", ".", "drop_rate", ",", "\n", "training", "=", "self", ".", "is_train", ")", "\n", "self", ".", "rnn_outs", "=", "rnn_outs", "\n", "print", "(", "\"rnn output shape: {}\"", ".", "format", "(", "rnn_outs", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.models.span_models.MaskSpanModel._build_loss_op": [[664, 670], ["tensorflow.nn.sparse_softmax_cross_entropy_with_logits", "tensorflow.reduce_mean", "tensorflow.summary.scalar", "tensorflow.reduce_sum"], "methods", ["None"], ["", "", "def", "_build_loss_op", "(", "self", ")", ":", "\n", "    ", "self", ".", "losses", "=", "tf", ".", "nn", ".", "sparse_softmax_cross_entropy_with_logits", "(", "\n", "logits", "=", "self", ".", "logits", ",", "labels", "=", "self", ".", "tags", ")", "\n", "self", ".", "losses", "=", "self", ".", "losses", "*", "self", ".", "masks", "\n", "self", ".", "loss", "=", "tf", ".", "reduce_mean", "(", "tf", ".", "reduce_sum", "(", "self", ".", "losses", ",", "axis", "=", "-", "1", ")", ")", "\n", "tf", ".", "summary", ".", "scalar", "(", "\"loss\"", ",", "self", ".", "loss", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.models.span_models.MaskSpanModel._build_predict_op": [[671, 674], ["tensorflow.cast", "tensorflow.cast", "tensorflow.argmax"], "methods", ["None"], ["", "def", "_build_predict_op", "(", "self", ")", ":", "\n", "    ", "self", ".", "predicts", "=", "tf", ".", "cast", "(", "tf", ".", "argmax", "(", "self", ".", "logits", ",", "axis", "=", "-", "1", ")", ",", "\n", "tf", ".", "int32", ")", "*", "tf", ".", "cast", "(", "self", ".", "masks", ",", "tf", ".", "int32", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.models.base_model.BaseModel.__init__": [[20, 38], ["base_model.BaseModel._initialize_config", "base_model.BaseModel._add_placeholders", "base_model.BaseModel._build_embedding_op", "base_model.BaseModel._build_model_op", "base_model.BaseModel._build_predict_op", "print", "base_model.BaseModel.initialize_session", "base_model.BaseModel._build_loss_op", "base_model.BaseModel._build_train_op", "numpy.sum", "numpy.prod", "v.get_shape().as_list", "tensorflow.trainable_variables", "v.get_shape"], "methods", ["home.repos.pwc.inspect_result.hiroki13_instance-based-ner.models.base_model.BaseModel._initialize_config", "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.models.base_model.BaseModel._add_placeholders", "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.models.base_model.BaseModel._build_embedding_op", "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.models.base_model.BaseModel._build_model_op", "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.models.base_model.BaseModel._build_predict_op", "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.models.base_model.BaseModel.initialize_session", "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.models.base_model.BaseModel._build_loss_op", "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.models.base_model.BaseModel._build_train_op"], ["  ", "def", "__init__", "(", "self", ",", "config", ",", "batcher", ",", "is_train", "=", "True", ")", ":", "\n", "    ", "self", ".", "cfg", "=", "config", "\n", "self", ".", "batcher", "=", "batcher", "\n", "self", ".", "sess", "=", "None", "\n", "self", ".", "saver", "=", "None", "\n", "\n", "self", ".", "_initialize_config", "(", ")", "\n", "self", ".", "_add_placeholders", "(", ")", "\n", "self", ".", "_build_embedding_op", "(", ")", "\n", "self", ".", "_build_model_op", "(", ")", "\n", "if", "is_train", ":", "\n", "      ", "self", ".", "_build_loss_op", "(", ")", "\n", "self", ".", "_build_train_op", "(", ")", "\n", "", "self", ".", "_build_predict_op", "(", ")", "\n", "print", "(", "'Num. params: {}'", ".", "format", "(", "\n", "np", ".", "sum", "(", "[", "np", ".", "prod", "(", "v", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", ")", "\n", "for", "v", "in", "tf", ".", "trainable_variables", "(", ")", "]", ")", ")", ")", "\n", "self", ".", "initialize_session", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.models.base_model.BaseModel._initialize_config": [[39, 61], ["os.makedirs", "os.makedirs", "utils.get_logger", "utils.common.load_json", "len", "len", "len", "dict", "dict", "dict", "os.path.join", "os.path.join", "base_model.BaseModel.word_dict.items", "base_model.BaseModel.char_dict.items", "base_model.BaseModel.tag_dict.items"], "methods", ["home.repos.pwc.inspect_result.hiroki13_instance-based-ner.utils.logger.get_logger", "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.scripts.retrieve_knn_sents_with_glove.load_json"], ["", "def", "_initialize_config", "(", "self", ")", ":", "\n", "# create folders and logger", "\n", "    ", "os", ".", "makedirs", "(", "self", ".", "cfg", "[", "\"checkpoint_path\"", "]", ",", "exist_ok", "=", "True", ")", "\n", "os", ".", "makedirs", "(", "os", ".", "path", ".", "join", "(", "self", ".", "cfg", "[", "\"summary_path\"", "]", ")", ",", "exist_ok", "=", "True", ")", "\n", "self", ".", "logger", "=", "get_logger", "(", "\n", "os", ".", "path", ".", "join", "(", "self", ".", "cfg", "[", "\"checkpoint_path\"", "]", ",", "\"log.txt\"", ")", ")", "\n", "\n", "# load dictionary", "\n", "dict_data", "=", "load_json", "(", "self", ".", "cfg", "[", "\"vocab\"", "]", ")", "\n", "self", ".", "word_dict", "=", "dict_data", "[", "\"word_dict\"", "]", "\n", "self", ".", "char_dict", "=", "dict_data", "[", "\"char_dict\"", "]", "\n", "self", ".", "tag_dict", "=", "dict_data", "[", "\"tag_dict\"", "]", "\n", "del", "dict_data", "\n", "self", ".", "word_vocab_size", "=", "len", "(", "self", ".", "word_dict", ")", "\n", "self", ".", "char_vocab_size", "=", "len", "(", "self", ".", "char_dict", ")", "\n", "self", ".", "tag_vocab_size", "=", "len", "(", "self", ".", "tag_dict", ")", "\n", "self", ".", "rev_word_dict", "=", "dict", "(", "[", "(", "idx", ",", "word", ")", "\n", "for", "word", ",", "idx", "in", "self", ".", "word_dict", ".", "items", "(", ")", "]", ")", "\n", "self", ".", "rev_char_dict", "=", "dict", "(", "[", "(", "idx", ",", "char", ")", "\n", "for", "char", ",", "idx", "in", "self", ".", "char_dict", ".", "items", "(", ")", "]", ")", "\n", "self", ".", "rev_tag_dict", "=", "dict", "(", "[", "(", "idx", ",", "tag", ")", "\n", "for", "tag", ",", "idx", "in", "self", ".", "tag_dict", ".", "items", "(", ")", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.models.base_model.BaseModel.initialize_session": [[62, 68], ["tensorflow.ConfigProto", "tensorflow.Session", "tensorflow.train.Saver", "base_model.BaseModel.sess.run", "tensorflow.global_variables_initializer"], "methods", ["None"], ["", "def", "initialize_session", "(", "self", ")", ":", "\n", "    ", "sess_config", "=", "tf", ".", "ConfigProto", "(", ")", "\n", "sess_config", ".", "gpu_options", ".", "allow_growth", "=", "True", "\n", "self", ".", "sess", "=", "tf", ".", "Session", "(", "config", "=", "sess_config", ")", "\n", "self", ".", "saver", "=", "tf", ".", "train", ".", "Saver", "(", "max_to_keep", "=", "self", ".", "cfg", "[", "\"max_to_keep\"", "]", ")", "\n", "self", ".", "sess", ".", "run", "(", "tf", ".", "global_variables_initializer", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.models.base_model.BaseModel.restore_last_session": [[69, 76], ["tensorflow.train.get_checkpoint_state", "tensorflow.train.get_checkpoint_state", "base_model.BaseModel.saver.restore"], "methods", ["None"], ["", "def", "restore_last_session", "(", "self", ",", "ckpt_path", "=", "None", ")", ":", "\n", "    ", "if", "ckpt_path", "is", "not", "None", ":", "\n", "      ", "ckpt", "=", "tf", ".", "train", ".", "get_checkpoint_state", "(", "ckpt_path", ")", "\n", "", "else", ":", "\n", "      ", "ckpt", "=", "tf", ".", "train", ".", "get_checkpoint_state", "(", "self", ".", "cfg", "[", "\"checkpoint_path\"", "]", ")", "\n", "", "if", "ckpt", "and", "ckpt", ".", "model_checkpoint_path", ":", "# restore session", "\n", "      ", "self", ".", "saver", ".", "restore", "(", "self", ".", "sess", ",", "ckpt", ".", "model_checkpoint_path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.models.base_model.BaseModel.log_trainable_variables": [[77, 82], ["base_model.BaseModel.logger.info", "tensorflow.trainable_variables", "base_model.BaseModel.logger.info", "v.get_shape().as_list", "v.get_shape"], "methods", ["None"], ["", "", "def", "log_trainable_variables", "(", "self", ")", ":", "\n", "    ", "self", ".", "logger", ".", "info", "(", "\"\\nTrainable variable\"", ")", "\n", "for", "v", "in", "tf", ".", "trainable_variables", "(", ")", ":", "\n", "      ", "self", ".", "logger", ".", "info", "(", "\"-- {}: shape:{}\"", ".", "format", "(", "\n", "v", ".", "name", ",", "v", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.models.base_model.BaseModel.save_session": [[83, 88], ["base_model.BaseModel.saver.save", "os.path.join"], "methods", ["None"], ["", "", "def", "save_session", "(", "self", ",", "epoch", ")", ":", "\n", "    ", "self", ".", "saver", ".", "save", "(", "self", ".", "sess", ",", "\n", "os", ".", "path", ".", "join", "(", "self", ".", "cfg", "[", "\"checkpoint_path\"", "]", ",", "\n", "self", ".", "cfg", "[", "\"model_name\"", "]", ")", ",", "\n", "global_step", "=", "epoch", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.models.base_model.BaseModel.close_session": [[89, 91], ["base_model.BaseModel.sess.close"], "methods", ["None"], ["", "def", "close_session", "(", "self", ")", ":", "\n", "    ", "self", ".", "sess", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.models.base_model.BaseModel._add_summary": [[92, 99], ["tensorflow.summary.merge_all", "tensorflow.summary.FileWriter", "tensorflow.summary.FileWriter", "os.path.join", "os.path.join"], "methods", ["None"], ["", "def", "_add_summary", "(", "self", ")", ":", "\n", "    ", "self", ".", "summary", "=", "tf", ".", "summary", ".", "merge_all", "(", ")", "\n", "self", ".", "train_writer", "=", "tf", ".", "summary", ".", "FileWriter", "(", "\n", "os", ".", "path", ".", "join", "(", "self", ".", "cfg", "[", "\"summary_path\"", "]", ",", "\"train\"", ")", ",", "\n", "self", ".", "sess", ".", "graph", ")", "\n", "self", ".", "test_writer", "=", "tf", ".", "summary", ".", "FileWriter", "(", "\n", "os", ".", "path", ".", "join", "(", "self", ".", "cfg", "[", "\"summary_path\"", "]", ",", "\"test\"", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.models.base_model.BaseModel.reinitialize_weights": [[100, 107], ["base_model.BaseModel.sess.run", "tensorflow.contrib.framework.get_variables", "base_model.BaseModel.sess.run", "tensorflow.global_variables_initializer", "tensorflow.variables_initializer"], "methods", ["None"], ["", "def", "reinitialize_weights", "(", "self", ",", "scope_name", "=", "None", ")", ":", "\n", "    ", "\"\"\"Reinitialize parameters in a scope\"\"\"", "\n", "if", "scope_name", "is", "None", ":", "\n", "      ", "self", ".", "sess", ".", "run", "(", "tf", ".", "global_variables_initializer", "(", ")", ")", "\n", "", "else", ":", "\n", "      ", "variables", "=", "tf", ".", "contrib", ".", "framework", ".", "get_variables", "(", "scope_name", ")", "\n", "self", ".", "sess", ".", "run", "(", "tf", ".", "variables_initializer", "(", "variables", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.models.base_model.BaseModel.variable_summaries": [[108, 118], ["tensorflow.name_scope", "tensorflow.reduce_mean", "tensorflow.summary.scalar", "tensorflow.sqrt", "tensorflow.summary.scalar", "tensorflow.summary.scalar", "tensorflow.summary.scalar", "tensorflow.summary.histogram", "tensorflow.reduce_mean", "tensorflow.reduce_max", "tensorflow.reduce_min", "tensorflow.square"], "methods", ["None"], ["", "", "@", "staticmethod", "\n", "def", "variable_summaries", "(", "variable", ",", "name", "=", "None", ")", ":", "\n", "    ", "with", "tf", ".", "name_scope", "(", "name", "or", "\"summary\"", ")", ":", "\n", "      ", "mean", "=", "tf", ".", "reduce_mean", "(", "variable", ")", "\n", "tf", ".", "summary", ".", "scalar", "(", "\"mean\"", ",", "mean", ")", "# add mean value", "\n", "stddev", "=", "tf", ".", "sqrt", "(", "tf", ".", "reduce_mean", "(", "tf", ".", "square", "(", "variable", "-", "mean", ")", ")", ")", "\n", "tf", ".", "summary", ".", "scalar", "(", "\"stddev\"", ",", "stddev", ")", "# add standard deviation value", "\n", "tf", ".", "summary", ".", "scalar", "(", "\"max\"", ",", "tf", ".", "reduce_max", "(", "variable", ")", ")", "# add maximal value", "\n", "tf", ".", "summary", ".", "scalar", "(", "\"min\"", ",", "tf", ".", "reduce_min", "(", "variable", ")", ")", "# add minimal value", "\n", "tf", ".", "summary", ".", "histogram", "(", "\"histogram\"", ",", "variable", ")", "# add histogram", "\n", "\n"]], "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.models.base_model.BaseModel._create_single_rnn_cell": [[119, 122], ["tensorflow.python.ops.rnn_cell.GRUCell", "tensorflow.python.ops.rnn_cell.LSTMCell"], "methods", ["None"], ["", "", "def", "_create_single_rnn_cell", "(", "self", ",", "num_units", ")", ":", "\n", "    ", "return", "GRUCell", "(", "num_units", ")", "if", "self", ".", "cfg", "[", "\"cell_type\"", "]", "==", "\"gru\"", "else", "LSTMCell", "(", "num_units", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.models.base_model.BaseModel._create_rnn_cell": [[123, 129], ["base_model.BaseModel._create_single_rnn_cell", "tensorflow.python.ops.rnn_cell.MultiRNNCell", "base_model.BaseModel._create_single_rnn_cell", "range"], "methods", ["home.repos.pwc.inspect_result.hiroki13_instance-based-ner.models.base_model.BaseModel._create_single_rnn_cell", "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.models.base_model.BaseModel._create_single_rnn_cell"], ["", "def", "_create_rnn_cell", "(", "self", ")", ":", "\n", "    ", "if", "self", ".", "cfg", "[", "\"num_layers\"", "]", "is", "None", "or", "self", ".", "cfg", "[", "\"num_layers\"", "]", "<=", "1", ":", "\n", "      ", "return", "self", ".", "_create_single_rnn_cell", "(", "self", ".", "cfg", "[", "\"num_units\"", "]", ")", "\n", "", "else", ":", "\n", "      ", "MultiRNNCell", "(", "[", "self", ".", "_create_single_rnn_cell", "(", "self", ".", "cfg", "[", "\"num_units\"", "]", ")", "\n", "for", "_", "in", "range", "(", "self", ".", "cfg", "[", "\"num_layers\"", "]", ")", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.models.base_model.BaseModel._add_placeholders": [[130, 132], ["NotImplementedError"], "methods", ["None"], ["", "", "def", "_add_placeholders", "(", "self", ")", ":", "\n", "    ", "raise", "NotImplementedError", "(", "\"To be implemented...\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.models.base_model.BaseModel._get_feed_dict": [[133, 135], ["NotImplementedError"], "methods", ["None"], ["", "def", "_get_feed_dict", "(", "self", ",", "data", ")", ":", "\n", "    ", "raise", "NotImplementedError", "(", "\"To be implemented...\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.models.base_model.BaseModel._build_embedding_op": [[136, 138], ["NotImplementedError"], "methods", ["None"], ["", "def", "_build_embedding_op", "(", "self", ")", ":", "\n", "    ", "raise", "NotImplementedError", "(", "\"To be implemented...\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.models.base_model.BaseModel._build_model_op": [[139, 141], ["NotImplementedError"], "methods", ["None"], ["", "def", "_build_model_op", "(", "self", ")", ":", "\n", "    ", "raise", "NotImplementedError", "(", "\"To be implemented...\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.models.base_model.BaseModel._build_loss_op": [[142, 144], ["NotImplementedError"], "methods", ["None"], ["", "def", "_build_loss_op", "(", "self", ")", ":", "\n", "    ", "raise", "NotImplementedError", "(", "\"To be implemented...\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.models.base_model.BaseModel._build_train_op": [[145, 147], ["NotImplementedError"], "methods", ["None"], ["", "def", "_build_train_op", "(", "self", ")", ":", "\n", "    ", "raise", "NotImplementedError", "(", "\"To be implemented...\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.models.base_model.BaseModel._build_predict_op": [[148, 150], ["NotImplementedError"], "methods", ["None"], ["", "def", "_build_predict_op", "(", "self", ")", ":", "\n", "    ", "raise", "NotImplementedError", "(", "\"To be implemented...\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.models.base_model.BaseModel.train_epoch": [[151, 153], ["NotImplementedError"], "methods", ["None"], ["", "def", "train_epoch", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "    ", "raise", "NotImplementedError", "(", "\"To be implemented...\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.models.base_model.BaseModel.train": [[154, 156], ["NotImplementedError"], "methods", ["None"], ["", "def", "train", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "    ", "raise", "NotImplementedError", "(", "\"To be implemented...\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.models.base_model.BaseModel.words_to_indices": [[157, 169], ["chars_idx.append", "base_model.BaseModel.batcher.make_each_batch", "utils.common.word_convert"], "methods", ["home.repos.pwc.inspect_result.hiroki13_instance-based-ner.batchers.span_batchers.MaskSpanBatcher.make_each_batch", "home.repos.pwc.inspect_result.hiroki13_instance-based-ner.utils.common.word_convert"], ["", "def", "words_to_indices", "(", "self", ",", "words", ")", ":", "\n", "    ", "chars_idx", "=", "[", "]", "\n", "for", "word", "in", "words", ":", "\n", "      ", "chars", "=", "[", "self", ".", "char_dict", "[", "char", "]", "\n", "if", "char", "in", "self", ".", "char_dict", "else", "self", ".", "char_dict", "[", "UNK", "]", "\n", "for", "char", "in", "word", "]", "\n", "chars_idx", ".", "append", "(", "chars", ")", "\n", "words", "=", "[", "word_convert", "(", "word", ")", "for", "word", "in", "words", "]", "\n", "words_idx", "=", "[", "self", ".", "word_dict", "[", "word", "]", "\n", "if", "word", "in", "self", ".", "word_dict", "else", "self", ".", "word_dict", "[", "UNK", "]", "\n", "for", "word", "in", "words", "]", "\n", "return", "self", ".", "batcher", ".", "make_each_batch", "(", "[", "words_idx", "]", ",", "[", "chars_idx", "]", ")", "\n", "", "", "", ""]]}