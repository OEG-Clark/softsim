{"home.repos.pwc.inspect_result.VegB_Text_Infilling.bin.train._process_config": [[95, 133], ["texar.utils.load_config", "yaml.load", "yaml.load", "yaml.load", "dir", "tensorflow.logging.info", "getattr", "utils.load_config.get", "tempfile.mkdtemp", "yaml.dump", "isinstance", "isinstance", "texar.utils.dict_patch"], "function", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.utils_io.load_config", "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.vocabulary.Vocab.load", "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.vocabulary.Vocab.load", "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.vocabulary.Vocab.load", "home.repos.pwc.inspect_result.VegB_Text_Infilling.core.replay_memories.DequeReplayMemory.get", "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.utils.dict_patch"], ["def", "_process_config", "(", ")", ":", "\n", "# Loads configs", "\n", "    ", "config", "=", "utils", ".", "load_config", "(", "FLAGS", ".", "config_paths", ")", "\n", "\n", "# Parses YAML FLAGS", "\n", "FLAGS", ".", "model_hparams", "=", "yaml", ".", "load", "(", "FLAGS", ".", "model_hparams", ")", "\n", "FLAGS", ".", "data_hparams_train", "=", "yaml", ".", "load", "(", "FLAGS", ".", "data_hparams_train", ")", "\n", "FLAGS", ".", "data_hparams_eval", "=", "yaml", ".", "load", "(", "FLAGS", ".", "data_hparams_eval", ")", "\n", "\n", "# Merges", "\n", "final_config", "=", "{", "}", "\n", "for", "flag_key", "in", "dir", "(", "FLAGS", ")", ":", "\n", "        ", "if", "flag_key", "in", "{", "'h'", ",", "'help'", ",", "'helpshort'", "}", ":", "# Filters out help flags", "\n", "            ", "continue", "\n", "", "flag_value", "=", "getattr", "(", "FLAGS", ",", "flag_key", ")", "\n", "config_value", "=", "config", ".", "get", "(", "flag_key", ",", "None", ")", "\n", "if", "isinstance", "(", "flag_value", ",", "dict", ")", "and", "isinstance", "(", "config_value", ",", "dict", ")", ":", "\n", "            ", "final_config", "[", "flag_key", "]", "=", "utils", ".", "dict_patch", "(", "config_value", ",", "flag_value", ")", "\n", "", "elif", "flag_key", "in", "config", ":", "\n", "            ", "final_config", "[", "flag_key", "]", "=", "config_value", "\n", "", "else", ":", "\n", "            ", "final_config", "[", "flag_key", "]", "=", "flag_value", "\n", "\n", "# Processes", "\n", "", "", "if", "final_config", "[", "'model_dir'", "]", "is", "None", ":", "\n", "        ", "final_config", "[", "'model_dir'", "]", "=", "tempfile", ".", "mkdtemp", "(", ")", "\n", "\n", "", "if", "final_config", "[", "'save_checkpoints_steps'", "]", "is", "None", "and", "final_config", "[", "'save_checkpoints_secs'", "]", "is", "None", ":", "\n", "        ", "final_config", "[", "'save_checkpoints_secs'", "]", "=", "600", "\n", "", "if", "final_config", "[", "'save_checkpoints_steps'", "]", "==", "-", "1", "and", "final_config", "[", "'save_checkpoints_secs'", "]", "==", "-", "1", ":", "\n", "        ", "final_config", "[", "'save_checkpoints_steps'", "]", "=", "None", "\n", "final_config", "[", "'save_checkpoints_secs'", "]", "=", "None", "\n", "\n", "", "tf", ".", "logging", ".", "info", "(", "\"Final Config:\\n%s\"", ",", "yaml", ".", "dump", "(", "final_config", ")", ")", "\n", "\n", "return", "final_config", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.bin.train._get_run_config": [[134, 155], ["tensorflow.GPUOptions", "tensorflow.ConfigProto", "tensorflow.estimator.RunConfig"], "function", ["None"], ["", "def", "_get_run_config", "(", "config", ")", ":", "\n", "    ", "gpu_options", "=", "tf", ".", "GPUOptions", "(", "\n", "per_process_gpu_memory_fraction", "=", "config", "[", "'per_process_gpu_memory_fraction'", "]", ",", "\n", "allow_growth", "=", "config", "[", "'gpu_allow_growth'", "]", ")", "\n", "sess_config", "=", "tf", ".", "ConfigProto", "(", "\n", "gpu_options", "=", "gpu_options", ",", "\n", "log_device_placement", "=", "config", "[", "'log_device_placement'", "]", ")", "\n", "\n", "run_config", "=", "tf", ".", "estimator", ".", "RunConfig", "(", "\n", "model_dir", "=", "config", "[", "'model_dir'", "]", ",", "\n", "tf_random_seed", "=", "config", "[", "'tf_random_seed'", "]", ",", "\n", "save_summary_steps", "=", "config", "[", "'save_summary_steps'", "]", ",", "\n", "save_checkpoints_steps", "=", "config", "[", "'save_checkpoints_steps'", "]", ",", "\n", "save_checkpoints_secs", "=", "config", "[", "'save_checkpoints_secs'", "]", ",", "\n", "keep_checkpoint_max", "=", "config", "[", "'keep_checkpoint_max'", "]", ",", "\n", "keep_checkpoint_every_n_hours", "=", "config", "[", "'keep_checkpoint_every_n_hours'", "]", ",", "\n", "log_step_count_steps", "=", "config", "[", "'log_step_count_steps'", "]", ",", "\n", "session_config", "=", "sess_config", ")", "\n", "\n", "return", "run_config", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.bin.train.main": [[156, 184], ["train._process_config", "train._get_run_config", "texar.utils.check_or_get_instance_with_redundant_kwargs", "texar.run.Executor", "texar.run.Executor.train_and_evaluate"], "function", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.bin.train._process_config", "home.repos.pwc.inspect_result.VegB_Text_Infilling.bin.train._get_run_config", "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.utils.check_or_get_instance_with_redundant_kwargs", "home.repos.pwc.inspect_result.VegB_Text_Infilling.run.executor.Executor.train_and_evaluate"], ["", "def", "main", "(", "_", ")", ":", "\n", "    ", "\"\"\"The entrypoint.\"\"\"", "\n", "\n", "config", "=", "_process_config", "(", ")", "\n", "\n", "run_config", "=", "_get_run_config", "(", "config", ")", "\n", "\n", "kwargs", "=", "{", "\n", "'data_hparams'", ":", "config", "[", "'data_hparams_train'", "]", ",", "\n", "'hparams'", ":", "config", "[", "'model_hparams'", "]", "\n", "}", "\n", "model", "=", "utils", ".", "check_or_get_instance_with_redundant_kwargs", "(", "\n", "config", "[", "'model'", "]", ",", "kwargs", "=", "kwargs", ",", "\n", "module_paths", "=", "[", "'texar.models'", ",", "'texar.custom'", "]", ")", "\n", "\n", "data_hparams", "=", "{", "\n", "'train'", ":", "config", "[", "'data_hparams_train'", "]", ",", "\n", "'eval'", ":", "config", "[", "'data_hparams_eval'", "]", "\n", "}", "\n", "\n", "exor", "=", "Executor", "(", "\n", "model", "=", "model", ",", "\n", "data_hparams", "=", "data_hparams", ",", "\n", "config", "=", "run_config", ")", "\n", "\n", "exor", ".", "train_and_evaluate", "(", "\n", "max_train_steps", "=", "config", "[", "'max_train_steps'", "]", ",", "\n", "eval_steps", "=", "config", "[", "'eval_steps'", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.bin.make_vocab.main": [[38, 48], ["texar.data.get_files", "texar.data.make_vocab", "open", "fout.write"], "function", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.data.data_utils.get_files", "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.multi_aligned_data.MultiAlignedData.make_vocab"], ["def", "main", "(", "_", ")", ":", "\n", "    ", "\"\"\"Makes vocab.\n    \"\"\"", "\n", "filenames", "=", "tx", ".", "data", ".", "get_files", "(", "FLAGS", ".", "files", ")", "\n", "vocab", "=", "tx", ".", "data", ".", "make_vocab", "(", "filenames", ",", "\n", "max_vocab_size", "=", "FLAGS", ".", "max_vocab_size", ",", "\n", "newline_token", "=", "FLAGS", ".", "newline_token", ")", "\n", "\n", "with", "open", "(", "FLAGS", ".", "output_path", ",", "\"w\"", ")", "as", "fout", ":", "\n", "        ", "fout", ".", "write", "(", "'\\n'", ".", "join", "(", "vocab", ")", ".", "encode", "(", "\"utf-8\"", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.bin.average_checkpoints.main": [[29, 84], ["tensorflow.logging.set_verbosity", "argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "len", "tensorflow.logging.info", "tensorflow.logging.info", "tensorflow.train.list_variables", "six.iteritems", "int", "os.path.join", "tensorflow.get_variable", "tensorflow.train.Saver", "ValueError", "tensorflow.train.get_checkpoint_state", "len", "tensorflow.logging.info", "tensorflow.train.load_checkpoint", "tf_vars.append", "tensorflow.placeholder", "tensorflow.assign", "tensorflow.global_variables", "tensorflow.Session", "sess.run", "zip", "tensorflow.logging.info", "tf.train.Saver.save", "name.startswith", "numpy.zeros", "tensorflow.get_variable", "zip", "checkpoints_path[].split", "tensorflow.constant", "tensorflow.global_variables_initializer", "six.iteritems", "sess.run", "tf.train.load_checkpoint.get_tensor"], "function", ["None"], ["def", "main", "(", ")", ":", "\n", "  ", "tf", ".", "logging", ".", "set_verbosity", "(", "tf", ".", "logging", ".", "INFO", ")", "\n", "\n", "parser", "=", "argparse", ".", "ArgumentParser", "(", "formatter_class", "=", "argparse", ".", "ArgumentDefaultsHelpFormatter", ")", "\n", "parser", ".", "add_argument", "(", "\"--model_dir\"", ",", "required", "=", "True", ",", "\n", "help", "=", "\"The model directory containing the checkpoints.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--output_dir\"", ",", "required", "=", "True", ",", "\n", "help", "=", "\"The output directory where the averaged checkpoint will be saved.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--max_count\"", ",", "type", "=", "int", ",", "default", "=", "8", ",", "\n", "help", "=", "\"The maximal number of checkpoints to average.\"", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "if", "args", ".", "model_dir", "==", "args", ".", "output_dir", ":", "\n", "    ", "raise", "ValueError", "(", "\"Model and output directory must be different\"", ")", "\n", "\n", "", "checkpoints_path", "=", "tf", ".", "train", ".", "get_checkpoint_state", "(", "args", ".", "model_dir", ")", ".", "all_model_checkpoint_paths", "\n", "if", "len", "(", "checkpoints_path", ")", ">", "args", ".", "max_count", ":", "\n", "    ", "checkpoints_path", "=", "checkpoints_path", "[", "-", "args", ".", "max_count", ":", "]", "\n", "", "num_checkpoints", "=", "len", "(", "checkpoints_path", ")", "\n", "\n", "tf", ".", "logging", ".", "info", "(", "\"Averaging %d checkpoints...\"", "%", "num_checkpoints", ")", "\n", "tf", ".", "logging", ".", "info", "(", "\"Listing variables...\"", ")", "\n", "\n", "var_list", "=", "tf", ".", "train", ".", "list_variables", "(", "checkpoints_path", "[", "0", "]", ")", "\n", "avg_values", "=", "{", "}", "\n", "for", "name", ",", "shape", "in", "var_list", ":", "\n", "    ", "if", "not", "name", ".", "startswith", "(", "\"global_step\"", ")", ":", "\n", "      ", "avg_values", "[", "name", "]", "=", "np", ".", "zeros", "(", "shape", ")", "\n", "\n", "", "", "for", "checkpoint_path", "in", "checkpoints_path", ":", "\n", "    ", "tf", ".", "logging", ".", "info", "(", "\"Loading checkpoint %s\"", "%", "checkpoint_path", ")", "\n", "reader", "=", "tf", ".", "train", ".", "load_checkpoint", "(", "checkpoint_path", ")", "\n", "for", "name", "in", "avg_values", ":", "\n", "      ", "avg_values", "[", "name", "]", "+=", "reader", ".", "get_tensor", "(", "name", ")", "/", "num_checkpoints", "\n", "\n", "", "", "tf_vars", "=", "[", "]", "\n", "for", "name", ",", "value", "in", "six", ".", "iteritems", "(", "avg_values", ")", ":", "\n", "    ", "tf_vars", ".", "append", "(", "tf", ".", "get_variable", "(", "name", ",", "shape", "=", "value", ".", "shape", ")", ")", "\n", "", "placeholders", "=", "[", "tf", ".", "placeholder", "(", "v", ".", "dtype", ",", "shape", "=", "v", ".", "shape", ")", "for", "v", "in", "tf_vars", "]", "\n", "assign_ops", "=", "[", "tf", ".", "assign", "(", "v", ",", "p", ")", "for", "(", "v", ",", "p", ")", "in", "zip", "(", "tf_vars", ",", "placeholders", ")", "]", "\n", "\n", "latest_step", "=", "int", "(", "checkpoints_path", "[", "-", "1", "]", ".", "split", "(", "\"-\"", ")", "[", "-", "1", "]", ")", "\n", "out_base_file", "=", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "\"model.ckpt\"", ")", "\n", "global_step", "=", "tf", ".", "get_variable", "(", "\n", "\"global_step\"", ",", "\n", "initializer", "=", "tf", ".", "constant", "(", "latest_step", ",", "dtype", "=", "tf", ".", "int64", ")", ",", "\n", "trainable", "=", "False", ")", "\n", "saver", "=", "tf", ".", "train", ".", "Saver", "(", "tf", ".", "global_variables", "(", ")", ")", "\n", "\n", "with", "tf", ".", "Session", "(", ")", "as", "sess", ":", "\n", "    ", "sess", ".", "run", "(", "tf", ".", "global_variables_initializer", "(", ")", ")", "\n", "for", "p", ",", "assign_op", ",", "(", "name", ",", "value", ")", "in", "zip", "(", "placeholders", ",", "assign_ops", ",", "six", ".", "iteritems", "(", "avg_values", ")", ")", ":", "\n", "      ", "sess", ".", "run", "(", "assign_op", ",", "{", "p", ":", "value", "}", ")", "\n", "", "tf", ".", "logging", ".", "info", "(", "\"Saving averaged checkpoint to %s-%d\"", "%", "(", "out_base_file", ",", "latest_step", ")", ")", "\n", "saver", ".", "save", "(", "sess", ",", "out_base_file", ",", "global_step", "=", "global_step", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.make_vocab.main": [[38, 48], ["texar.data.get_files", "texar.data.make_vocab", "open", "fout.write"], "function", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.data.data_utils.get_files", "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.multi_aligned_data.MultiAlignedData.make_vocab"], ["def", "main", "(", "_", ")", ":", "\n", "    ", "\"\"\"Makes vocab.\n    \"\"\"", "\n", "filenames", "=", "tx", ".", "data", ".", "get_files", "(", "FLAGS", ".", "files", ")", "\n", "vocab", "=", "tx", ".", "data", ".", "make_vocab", "(", "filenames", ",", "\n", "max_vocab_size", "=", "FLAGS", ".", "max_vocab_size", ",", "\n", "newline_token", "=", "FLAGS", ".", "newline_token", ")", "\n", "\n", "with", "open", "(", "FLAGS", ".", "output_path", ",", "\"w\"", ")", "as", "fout", ":", "\n", "        ", "fout", ".", "write", "(", "'\\n'", ".", "join", "(", "vocab", ")", ".", "encode", "(", "\"utf-8\"", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.average_checkpoints.main": [[29, 84], ["tensorflow.logging.set_verbosity", "argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "len", "tensorflow.logging.info", "tensorflow.logging.info", "tensorflow.train.list_variables", "six.iteritems", "int", "os.path.join", "tensorflow.get_variable", "tensorflow.train.Saver", "ValueError", "tensorflow.train.get_checkpoint_state", "len", "tensorflow.logging.info", "tensorflow.train.load_checkpoint", "tf_vars.append", "tensorflow.placeholder", "tensorflow.assign", "tensorflow.global_variables", "tensorflow.Session", "sess.run", "zip", "tensorflow.logging.info", "tf.train.Saver.save", "name.startswith", "numpy.zeros", "tensorflow.get_variable", "zip", "checkpoints_path[].split", "tensorflow.constant", "tensorflow.global_variables_initializer", "six.iteritems", "sess.run", "tf.train.load_checkpoint.get_tensor"], "function", ["None"], ["def", "main", "(", ")", ":", "\n", "  ", "tf", ".", "logging", ".", "set_verbosity", "(", "tf", ".", "logging", ".", "INFO", ")", "\n", "\n", "parser", "=", "argparse", ".", "ArgumentParser", "(", "formatter_class", "=", "argparse", ".", "ArgumentDefaultsHelpFormatter", ")", "\n", "parser", ".", "add_argument", "(", "\"--model_dir\"", ",", "required", "=", "True", ",", "\n", "help", "=", "\"The model directory containing the checkpoints.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--output_dir\"", ",", "required", "=", "True", ",", "\n", "help", "=", "\"The output directory where the averaged checkpoint will be saved.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--max_count\"", ",", "type", "=", "int", ",", "default", "=", "8", ",", "\n", "help", "=", "\"The maximal number of checkpoints to average.\"", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "if", "args", ".", "model_dir", "==", "args", ".", "output_dir", ":", "\n", "    ", "raise", "ValueError", "(", "\"Model and output directory must be different\"", ")", "\n", "\n", "", "checkpoints_path", "=", "tf", ".", "train", ".", "get_checkpoint_state", "(", "args", ".", "model_dir", ")", ".", "all_model_checkpoint_paths", "\n", "if", "len", "(", "checkpoints_path", ")", ">", "args", ".", "max_count", ":", "\n", "    ", "checkpoints_path", "=", "checkpoints_path", "[", "-", "args", ".", "max_count", ":", "]", "\n", "", "num_checkpoints", "=", "len", "(", "checkpoints_path", ")", "\n", "\n", "tf", ".", "logging", ".", "info", "(", "\"Averaging %d checkpoints...\"", "%", "num_checkpoints", ")", "\n", "tf", ".", "logging", ".", "info", "(", "\"Listing variables...\"", ")", "\n", "\n", "var_list", "=", "tf", ".", "train", ".", "list_variables", "(", "checkpoints_path", "[", "0", "]", ")", "\n", "avg_values", "=", "{", "}", "\n", "for", "name", ",", "shape", "in", "var_list", ":", "\n", "    ", "if", "not", "name", ".", "startswith", "(", "\"global_step\"", ")", ":", "\n", "      ", "avg_values", "[", "name", "]", "=", "np", ".", "zeros", "(", "shape", ")", "\n", "\n", "", "", "for", "checkpoint_path", "in", "checkpoints_path", ":", "\n", "    ", "tf", ".", "logging", ".", "info", "(", "\"Loading checkpoint %s\"", "%", "checkpoint_path", ")", "\n", "reader", "=", "tf", ".", "train", ".", "load_checkpoint", "(", "checkpoint_path", ")", "\n", "for", "name", "in", "avg_values", ":", "\n", "      ", "avg_values", "[", "name", "]", "+=", "reader", ".", "get_tensor", "(", "name", ")", "/", "num_checkpoints", "\n", "\n", "", "", "tf_vars", "=", "[", "]", "\n", "for", "name", ",", "value", "in", "six", ".", "iteritems", "(", "avg_values", ")", ":", "\n", "    ", "tf_vars", ".", "append", "(", "tf", ".", "get_variable", "(", "name", ",", "shape", "=", "value", ".", "shape", ")", ")", "\n", "", "placeholders", "=", "[", "tf", ".", "placeholder", "(", "v", ".", "dtype", ",", "shape", "=", "v", ".", "shape", ")", "for", "v", "in", "tf_vars", "]", "\n", "assign_ops", "=", "[", "tf", ".", "assign", "(", "v", ",", "p", ")", "for", "(", "v", ",", "p", ")", "in", "zip", "(", "tf_vars", ",", "placeholders", ")", "]", "\n", "\n", "latest_step", "=", "int", "(", "checkpoints_path", "[", "-", "1", "]", ".", "split", "(", "\"-\"", ")", "[", "-", "1", "]", ")", "\n", "out_base_file", "=", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "\"model.ckpt\"", ")", "\n", "global_step", "=", "tf", ".", "get_variable", "(", "\n", "\"global_step\"", ",", "\n", "initializer", "=", "tf", ".", "constant", "(", "latest_step", ",", "dtype", "=", "tf", ".", "int64", ")", ",", "\n", "trainable", "=", "False", ")", "\n", "saver", "=", "tf", ".", "train", ".", "Saver", "(", "tf", ".", "global_variables", "(", ")", ")", "\n", "\n", "with", "tf", ".", "Session", "(", ")", "as", "sess", ":", "\n", "    ", "sess", ".", "run", "(", "tf", ".", "global_variables_initializer", "(", ")", ")", "\n", "for", "p", ",", "assign_op", ",", "(", "name", ",", "value", ")", "in", "zip", "(", "placeholders", ",", "assign_ops", ",", "six", ".", "iteritems", "(", "avg_values", ")", ")", ":", "\n", "      ", "sess", ".", "run", "(", "assign_op", ",", "{", "p", ":", "value", "}", ")", "\n", "", "tf", ".", "logging", ".", "info", "(", "\"Saving averaged checkpoint to %s-%d\"", "%", "(", "out_base_file", ",", "latest_step", ")", ")", "\n", "saver", ".", "save", "(", "sess", ",", "out_base_file", ",", "global_step", "=", "global_step", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.transformer_utils_test.Hyperparams.__init__": [[14, 16], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "self", ".", "help", "=", "\"the hyperparams dictionary to use\"", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.transformer_utils_test.load_hyperparams": [[18, 31], ["transformer_utils_test.Hyperparams", "argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "int", "int", "math.log"], "function", ["None"], ["", "", "def", "load_hyperparams", "(", ")", ":", "\n", "    ", "args", "=", "Hyperparams", "(", ")", "\n", "argparser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "argparser", ".", "add_argument", "(", "'--max_seq_length'", ",", "type", "=", "int", ",", "default", "=", "11", ")", "\n", "argparser", ".", "add_argument", "(", "'--max_decode_len'", ",", "type", "=", "int", ",", "default", "=", "5", ")", "\n", "argparser", ".", "add_argument", "(", "'--mask_strategy'", ",", "type", "=", "str", ",", "default", "=", "'random'", ")", "# equal_length", "\n", "argparser", ".", "add_argument", "(", "'--present_rate'", ",", "type", "=", "float", ",", "default", "=", "0.5", ")", "\n", "argparser", ".", "add_argument", "(", "'--mask_num'", ",", "type", "=", "int", ",", "default", "=", "3", ")", "\n", "argparser", ".", "add_argument", "(", "'--mask_length'", ",", "type", "=", "int", ",", "default", "=", "5", ")", "\n", "argparser", ".", "parse_args", "(", "namespace", "=", "args", ")", "\n", "args", ".", "max_partition_num", "=", "int", "(", "(", "args", ".", "max_seq_length", "+", "1", ")", "/", "2", ")", "\n", "args", ".", "partition_num", "=", "int", "(", "math", ".", "log", "(", "args", ".", "max_seq_length", ")", ")", "\n", "return", "args", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.transformer_utils_test.test_generate_equal_length_mask": [[33, 51], ["tensorflow.Variable", "tensorflow.Variable", "texar.utils.transformer_utils.generate_equal_length_mask", "tensorflow.Session", "sess.run", "sess.run", "print", "print", "print", "print", "tensorflow.global_variables_initializer"], "function", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.transformer_utils.generate_equal_length_mask"], ["", "def", "test_generate_equal_length_mask", "(", ")", ":", "\n", "    ", "mask_length", "=", "2", "\n", "mask_num", "=", "2", "\n", "mask_id", "=", "7", "\n", "eos_id", "=", "8", "\n", "inputs", "=", "tf", ".", "Variable", "(", "[", "[", "3", ",", "5", ",", "4", ",", "4", ",", "2", ",", "1", ",", "3", ",", "3", ",", "2", ",", "5", ",", "1", "]", ",", "\n", "[", "2", ",", "1", ",", "4", ",", "3", ",", "5", ",", "1", ",", "5", ",", "4", ",", "3", ",", "1", ",", "5", "]", "]", ",", "dtype", "=", "tf", ".", "int64", ")", "\n", "lengths", "=", "tf", ".", "Variable", "(", "[", "11", ",", "11", "]", ",", "dtype", "=", "tf", ".", "int64", ")", "\n", "\n", "masks", ",", "answers", ",", "templates", ",", "_", "=", "generate_equal_length_mask", "(", "inputs", ",", "lengths", ",", "mask_num", ",", "mask_length", ",", "mask_id", ",", "eos_id", ")", "\n", "with", "tf", ".", "Session", "(", ")", "as", "sess", ":", "\n", "        ", "sess", ".", "run", "(", "tf", ".", "global_variables_initializer", "(", ")", ")", "\n", "inputs_", ",", "masks_", ",", "answers_", ",", "templates_", "=", "sess", ".", "run", "(", "[", "inputs", ",", "masks", ",", "answers", ",", "templates", "]", ")", "\n", "print", "(", "inputs_", ")", "\n", "print", "(", "masks_", ")", "\n", "print", "(", "answers_", ")", "\n", "print", "(", "templates_", ")", "\n", "# test_generate_equal_length_mask()", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.transformer_utils_test.test_prepare_template": [[54, 81], ["tensorflow.Variable", "tensorflow.Variable", "transformer_utils_test.load_hyperparams", "texar.utils.transformer_utils.prepare_template", "tensorflow.Session", "sess.run", "sess.run", "print", "print", "print", "tensorflow.global_variables_initializer"], "function", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.text_infilling.self_attn_hyperparams.load_hyperparams", "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.transformer_utils.prepare_template"], ["", "", "def", "test_prepare_template", "(", ")", ":", "\n", "    ", "inputs", "=", "tf", ".", "Variable", "(", "[", "[", "0", ",", "1", ",", "2", ",", "3", ",", "4", ",", "5", ",", "6", ",", "7", ",", "8", ",", "9", ",", "10", "]", ",", "\n", "[", "0", ",", "1", ",", "2", ",", "3", ",", "4", ",", "5", ",", "6", ",", "7", ",", "8", ",", "9", ",", "10", "]", "]", ",", "dtype", "=", "tf", ".", "int64", ")", "\n", "length", "=", "tf", ".", "Variable", "(", "[", "11", ",", "11", "]", ",", "dtype", "=", "tf", ".", "int32", ")", "\n", "data_batch", "=", "{", "\n", "'text_ids'", ":", "inputs", ",", "\n", "'length'", ":", "length", "\n", "}", "\n", "mask_id", "=", "22", "\n", "boa_id", "=", "100", "\n", "eoa_id", "=", "99", "\n", "pad_id", "=", "33", "\n", "args", "=", "load_hyperparams", "(", ")", "\n", "template_pack", ",", "answer_packs", "=", "prepare_template", "(", "data_batch", ",", "args", ",", "mask_id", ",", "boa_id", ",", "eoa_id", ",", "pad_id", ")", "\n", "\n", "with", "tf", ".", "Session", "(", ")", "as", "sess", ":", "\n", "        ", "sess", ".", "run", "(", "tf", ".", "global_variables_initializer", "(", ")", ")", "\n", "fetches", "=", "{", "\n", "'ori'", ":", "data_batch", ",", "\n", "'template'", ":", "template_pack", ",", "\n", "'fills'", ":", "answer_packs", "\n", "}", "\n", "rtns", "=", "sess", ".", "run", "(", "fetches", ")", "\n", "print", "(", "rtns", "[", "'ori'", "]", ")", "\n", "print", "(", "rtns", "[", "'template'", "]", ")", "\n", "print", "(", "rtns", "[", "'fills'", "]", ")", "\n", "# test_prepare_template()", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.transformer_utils_test.test_split_template": [[84, 89], ["texar.utils.transformer_utils._split_template"], "function", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.transformer_utils._split_template"], ["", "", "def", "test_split_template", "(", ")", ":", "\n", "    ", "a", "=", "[", "3", ",", "5", ",", "4", ",", "7", ",", "7", ",", "1", ",", "3", ",", "3", ",", "7", ",", "7", ",", "1", "]", "\n", "s_pos", "=", "[", "3", ",", "8", "]", "\n", "e_pos", "=", "[", "5", ",", "10", "]", "\n", "assert", "_split_template", "(", "a", ",", "s_pos", ",", "e_pos", ")", "==", "[", "[", "3", ",", "5", ",", "4", "]", ",", "[", "1", ",", "3", ",", "3", "]", ",", "[", "1", "]", "]", "\n", "# test_split_template()", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.transformer_utils_test.test_merge_segments": [[92, 99], ["texar.utils.transformer_utils._merge_segments", "texar.utils.transformer_utils._merge_segments"], "function", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.transformer_utils._merge_segments", "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.transformer_utils._merge_segments"], ["", "def", "test_merge_segments", "(", ")", ":", "\n", "    ", "t_seg_1", "=", "[", "[", "3", ",", "5", ",", "4", "]", ",", "[", "1", ",", "3", ",", "3", "]", ",", "[", "1", "]", "]", "\n", "fillings_1", "=", "[", "[", "4", ",", "2", "]", ",", "[", "2", ",", "5", "]", "]", "\n", "assert", "_merge_segments", "(", "t_seg_1", ",", "fillings_1", ")", "==", "[", "3", ",", "5", ",", "4", ",", "4", ",", "2", ",", "1", ",", "3", ",", "3", ",", "2", ",", "5", ",", "1", "]", "\n", "assert", "_merge_segments", "(", "t_seg_1", "[", ":", "-", "1", "]", ",", "fillings_1", ")", "==", "[", "3", ",", "5", ",", "4", ",", "4", ",", "2", ",", "1", ",", "3", ",", "3", ",", "2", ",", "5", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.transformer_utils_test.test_fill_template": [[101, 109], ["numpy.array", "numpy.array", "texar.utils.transformer_utils.fill_template"], "function", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.transformer_utils.fill_template"], ["", "def", "test_fill_template", "(", ")", ":", "\n", "    ", "templates", "=", "np", ".", "array", "(", "[", "[", "3", ",", "5", ",", "4", ",", "7", ",", "7", ",", "1", ",", "3", ",", "3", ",", "7", ",", "7", ",", "1", "]", ",", "\n", "[", "2", ",", "1", ",", "7", ",", "7", ",", "6", ",", "2", ",", "5", ",", "7", ",", "7", ",", "4", ",", "5", "]", "]", ")", "\n", "predictions", "=", "np", ".", "array", "(", "[", "[", "[", "4", ",", "2", "]", ",", "[", "2", ",", "5", "]", "]", ",", "[", "[", "4", ",", "3", "]", ",", "[", "3", ",", "1", "]", "]", "]", ")", "\n", "mask_id", "=", "7", "\n", "rst", "=", "fill_template", "(", "templates", ",", "predictions", ",", "mask_id", ")", "\n", "assert", "rst", "==", "[", "[", "3", ",", "5", ",", "4", ",", "4", ",", "2", ",", "1", ",", "3", ",", "3", ",", "2", ",", "5", ",", "1", "]", ",", "\n", "[", "2", ",", "1", ",", "4", ",", "3", ",", "6", ",", "2", ",", "5", ",", "3", ",", "1", ",", "4", ",", "5", "]", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.transformer_utils_test.test_fill_template_with_tensor": [[111, 149], ["tensorflow.Variable", "tensorflow.Variable", "transformer_utils_test.load_hyperparams", "texar.utils.transformer_utils.prepare_template", "tensorflow.Session", "sess.run", "sess.run", "print", "print", "print", "texar.utils.transformer_utils.fill_template", "print", "tensorflow.global_variables_initializer", "predictions.append", "[].tolist"], "function", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.text_infilling.self_attn_hyperparams.load_hyperparams", "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.transformer_utils.prepare_template", "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.transformer_utils.fill_template"], ["", "def", "test_fill_template_with_tensor", "(", ")", ":", "\n", "    ", "text_ids", "=", "tf", ".", "Variable", "(", "[", "[", "3", ",", "5", ",", "4", ",", "4", ",", "2", ",", "1", ",", "3", ",", "3", ",", "2", ",", "5", ",", "1", "]", ",", "\n", "[", "2", ",", "1", ",", "4", ",", "3", ",", "5", ",", "1", ",", "5", ",", "4", ",", "3", ",", "1", ",", "5", "]", "]", ",", "dtype", "=", "tf", ".", "int64", ")", "\n", "length", "=", "tf", ".", "Variable", "(", "[", "11", ",", "11", "]", ",", "dtype", "=", "tf", ".", "int32", ")", "\n", "data_batch", "=", "{", "\n", "'text_ids'", ":", "text_ids", ",", "\n", "'length'", ":", "length", "\n", "}", "\n", "args", "=", "load_hyperparams", "(", ")", "\n", "mask_id", "=", "7", "\n", "boa_id", "=", "8", "\n", "eoa_id", "=", "9", "\n", "eos_id", "=", "10", "\n", "pad_id", "=", "11", "\n", "template_pack", ",", "answer_packs", "=", "prepare_template", "(", "data_batch", ",", "args", ",", "mask_id", ",", "boa_id", ",", "eoa_id", ",", "pad_id", ")", "\n", "\n", "with", "tf", ".", "Session", "(", ")", "as", "sess", ":", "\n", "        ", "sess", ".", "run", "(", "tf", ".", "global_variables_initializer", "(", ")", ")", "\n", "fetches", "=", "{", "\n", "'ori'", ":", "data_batch", ",", "\n", "'template'", ":", "template_pack", ",", "\n", "'fills'", ":", "answer_packs", "\n", "}", "\n", "rtns", "=", "sess", ".", "run", "(", "fetches", ")", "\n", "print", "(", "rtns", "[", "'ori'", "]", ")", "\n", "print", "(", "rtns", "[", "'template'", "]", ")", "\n", "print", "(", "rtns", "[", "'fills'", "]", ")", "\n", "predictions", "=", "[", "]", "\n", "for", "hole", "in", "rtns", "[", "'fills'", "]", ":", "\n", "            ", "predictions", ".", "append", "(", "hole", "[", "'text_ids'", "]", ")", "\n", "\n", "", "filled", "=", "fill_template", "(", "template_pack", "=", "rtns", "[", "'template'", "]", ",", "\n", "predictions", "=", "predictions", ",", "\n", "eoa_id", "=", "eoa_id", ",", "pad_id", "=", "pad_id", ",", "eos_id", "=", "eos_id", ")", "\n", "\n", "print", "(", "filled", ")", "\n", "assert", "filled", "==", "rtns", "[", "'ori'", "]", "[", "'text_ids'", "]", ".", "tolist", "(", ")", "\n", "# test_fill_template_with_tensor()", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.transformer_utils_test.test_generate_random_mask": [[152, 173], ["tensorflow.Variable", "tensorflow.Variable", "texar.utils.transformer_utils.generate_random_mask", "tensorflow.Session", "sess.run", "sess.run", "print", "print", "print", "print", "tensorflow.global_variables_initializer"], "function", ["None"], ["", "", "def", "test_generate_random_mask", "(", ")", ":", "\n", "    ", "inputs", "=", "tf", ".", "Variable", "(", "[", "[", "0", ",", "1", ",", "2", ",", "3", ",", "4", ",", "5", ",", "6", ",", "7", ",", "8", ",", "9", ",", "10", "]", ",", "\n", "[", "0", ",", "1", ",", "2", ",", "3", ",", "4", ",", "5", ",", "6", ",", "7", ",", "8", ",", "9", ",", "10", "]", "]", ",", "dtype", "=", "tf", ".", "int64", ")", "\n", "lengths", "=", "tf", ".", "Variable", "(", "[", "11", ",", "11", "]", ",", "dtype", "=", "tf", ".", "int32", ")", "\n", "present_rate", "=", "0.2", "\n", "mask_id", "=", "99", "\n", "eoa_id", "=", "22", "\n", "pad_id", "=", "33", "\n", "partition_num", "=", "3", "\n", "masks", ",", "answers", ",", "ans_len", ",", "templates", ",", "template_masks", "=", "generate_random_mask", "(", "inputs", ",", "lengths", ",", "present_rate", ",", "\n", "mask_id", ",", "eoa_id", ",", "pad_id", ",", "partition_num", ")", "\n", "\n", "with", "tf", ".", "Session", "(", ")", "as", "sess", ":", "\n", "        ", "sess", ".", "run", "(", "tf", ".", "global_variables_initializer", "(", ")", ")", "\n", "masks", ",", "answers", ",", "templates", ",", "template_masks", "=", "sess", ".", "run", "(", "[", "masks", ",", "answers", ",", "templates", ",", "template_masks", "]", ")", "\n", "print", "(", "\"masks:\\n\"", ",", "masks", ")", "\n", "print", "(", "\"answers:\\n\"", ",", "answers", ")", "\n", "print", "(", "\"templates:\\n\"", ",", "templates", ")", "\n", "print", "(", "\"template_masks:\\n\"", ",", "template_masks", ")", "\n", "# test_generate_random_mask()", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.shapes.transpose_batch_time": [[30, 46], ["tensorflow.python.util.nest.flatten", "tensorflow.python.util.nest.pack_sequence_as", "tensorflow.python.framework.ops.convert_to_tensor", "tensorflow.python.ops.rnn._transpose_batch_time"], "function", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.encoders.hierarchical_encoders.HierarchicalRNNEncoder.flatten"], ["def", "transpose_batch_time", "(", "inputs", ")", ":", "\n", "    ", "\"\"\"Transposes inputs between time-major and batch-major.\n\n    Args:\n        inputs: A Tensor of shape `[batch_size, max_time, ...]` (batch-major)\n            or `[max_time, batch_size, ...]` (time-major), or a (possibly\n            nested) tuple of such elements.\n\n    Returns:\n        A Tensor with transposed batch and time dimensions of inputs.\n    \"\"\"", "\n", "flat_input", "=", "nest", ".", "flatten", "(", "inputs", ")", "\n", "flat_input", "=", "[", "ops", ".", "convert_to_tensor", "(", "input_", ")", "for", "input_", "in", "flat_input", "]", "\n", "# pylint: disable=protected-access", "\n", "flat_input", "=", "[", "rnn", ".", "_transpose_batch_time", "(", "input_", ")", "for", "input_", "in", "flat_input", "]", "\n", "return", "nest", ".", "pack_sequence_as", "(", "structure", "=", "inputs", ",", "flat_sequence", "=", "flat_input", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.shapes.get_batch_size": [[47, 52], ["tensorflow.shape"], "function", ["None"], ["", "def", "get_batch_size", "(", "tensor", ")", ":", "\n", "    ", "\"\"\"Returns a unit `Tensor` representing the batch size, i.e.,\n    the size of the 1st dimension of :attr:`tensor`.\n    \"\"\"", "\n", "return", "tf", ".", "shape", "(", "tensor", ")", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.shapes.get_rank": [[54, 75], ["tensorflow.contrib.framework.is_tensor", "numpy.asarray", "len", "shape.as_list"], "function", ["None"], ["", "def", "get_rank", "(", "tensor", ")", ":", "\n", "    ", "\"\"\"Returns the tensor rank as a python `int`. The input tensor can also be\n    a python array.\n\n    Args:\n        tensor: A Tensor or python array.\n\n    Returns:\n        A python `int` representing the rank of :attr:`tensor`. Returns\n        `None` if the rank cannot be determined.\n    \"\"\"", "\n", "if", "tf", ".", "contrib", ".", "framework", ".", "is_tensor", "(", "tensor", ")", ":", "\n", "        ", "shape", "=", "tensor", ".", "shape", "\n", "try", ":", "\n", "            ", "rank", "=", "len", "(", "shape", ".", "as_list", "(", ")", ")", "\n", "", "except", "ValueError", ":", "# when `shape==TensorShape(None)`", "\n", "            ", "rank", "=", "None", "\n", "", "", "else", ":", "\n", "        ", "array", "=", "np", ".", "asarray", "(", "tensor", ")", "\n", "rank", "=", "array", ".", "ndim", "\n", "", "return", "rank", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.shapes.mask_sequences": [[76, 128], ["is_tensor", "is_tensor", "shapes._mask_sequences_tensor", "shapes._mask_sequences_py"], "function", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.shapes._mask_sequences_tensor", "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.shapes._mask_sequences_py"], ["", "def", "mask_sequences", "(", "sequence", ",", "\n", "sequence_length", ",", "\n", "dtype", "=", "None", ",", "\n", "time_major", "=", "False", ",", "\n", "tensor_rank", "=", "2", ")", ":", "\n", "    ", "\"\"\"Masks out sequence entries that are beyond the respective sequence\n    lengths. Masks along the time dimension.\n\n    :attr:`sequence` and :attr:`sequence_length` can either be python\n    arrays or Tensors, respectively. If both are python arrays (or None), the\n    return will be a python array as well.\n\n    :attr:`tensor_rank` is ignored when :attr:`sequence` and\n    :attr:`sequence_length` are both python arrays (rather than Tensors).\n\n    Args:\n        sequence: A Tensor or python array of sequence values.\n\n            If `time_major=False` (default), this must be a Tensor of shape:\n                `[batch_size, max_time, ...]`.\n\n            If `time_major=True`, this must be a Tensor of shape:\n                `[max_time, batch_size, ...].`\n        sequence_length: A Tensor or python array of shape `[batch_size]`.\n            Time steps beyond the respective sequence lengths will be\n            made zero.\n        dtype (dtype): Type of :attr:`sequence`. If `None`, infer from\n            :attr:`sequence` automatically.\n        time_major (bool): The shape format of the inputs. If `True`,\n            :attr:`sequence` must have shape\n            `[max_time, batch_size, ...]`.\n            If `False` (default), :attr:`sequence` must have\n            shape `[batch_size, max_time, ...]`.\n        tensor_rank (int): The number of dimensions of :attr:`sequence`.\n            Default is 2, i.e., :attr:`sequence` is a 2D Tensor consisting\n            of batch and time dimensions. Ignored if both :attr:`sequence`\n            and :attr:`sequence_length` are python arrays.\n\n    Returns:\n        The masked sequence, i.e., a Tensor or python array of the same shape\n        as :attr:`sequence` but with masked-out entries (set to zero).\n\n        If both :attr:`sequence` and :attr:`sequence_length` are python\n        arrays, the returned value is a python array as well.\n    \"\"\"", "\n", "is_tensor", "=", "tf", ".", "contrib", ".", "framework", ".", "is_tensor", "\n", "if", "is_tensor", "(", "sequence", ")", "or", "is_tensor", "(", "sequence_length", ")", ":", "\n", "        ", "return", "_mask_sequences_tensor", "(", "\n", "sequence", ",", "sequence_length", ",", "dtype", ",", "time_major", ",", "tensor_rank", ")", "\n", "", "else", ":", "\n", "        ", "return", "_mask_sequences_py", "(", "\n", "sequence", ",", "sequence_length", ",", "dtype", ",", "time_major", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.shapes._mask_sequences_tensor": [[129, 181], ["tensorflow.to_int32", "tensorflow.sequence_mask", "range", "ValueError", "tensorflow.python.ops.rnn._transpose_batch_time", "tensorflow.to_int32", "tensorflow.expand_dims", "tensorflow.python.ops.rnn._transpose_batch_time", "tensorflow.shape"], "function", ["None"], ["", "", "def", "_mask_sequences_tensor", "(", "sequence", ",", "\n", "sequence_length", ",", "\n", "dtype", "=", "None", ",", "\n", "time_major", "=", "False", ",", "\n", "tensor_rank", "=", "2", ")", ":", "\n", "    ", "\"\"\"Masks out sequence entries that are beyond the respective sequence\n    lengths. Masks along the time dimension.\n\n    Args:\n        sequence: A Tensor of sequence values.\n\n            If `time_major=False` (default), this must be a Tensor of shape:\n                `[batch_size, max_time, d_2, ..., d_rank]`, where the rank of\n                the Tensor is specified with :attr:`tensor_rank`.\n\n            If `time_major=True`, this must be a Tensor of shape:\n                `[max_time, batch_size, d_2, ..., d_rank].`\n        sequence_length: A Tensor of shape `[batch_size]`. Time steps beyond\n            the respective sequence lengths will be made zero.\n        dtype (dtype): Type of :attr:`sequence`. If `None`, infer from\n            :attr:`sequence` automatically.\n        time_major (bool): The shape format of the inputs. If `True`,\n            :attr:`sequence` must have shape\n            `[max_time, batch_size, d_2, ..., d_rank]`.\n            If `False` (default), :attr:`sequence` must have\n            shape `[batch_size, max_time, d_2, ..., d_rank]`.\n        tensor_rank (int): The number of dimensions of :attr:`sequence`.\n            Default is 2, i.e., :attr:`sequence` is a 2D Tensor consisting\n            of batch and time dimensions.\n\n    Returns:\n        The masked sequence, i.e., a Tensor of the same shape as\n        :attr:`sequence` but with masked-out entries (set to zero).\n    \"\"\"", "\n", "if", "tensor_rank", "is", "None", ":", "\n", "        ", "tensor_rank", "=", "2", "\n", "", "if", "tensor_rank", "<", "2", ":", "\n", "        ", "raise", "ValueError", "(", "\n", "\"tensor_rank must be > 2. Got tensor_rank = {}\"", ".", "format", "(", "tensor_rank", ")", ")", "\n", "", "if", "time_major", ":", "\n", "        ", "sequence", "=", "rnn", ".", "_transpose_batch_time", "(", "sequence", ")", "\n", "", "max_time", "=", "tf", ".", "to_int32", "(", "tf", ".", "shape", "(", "sequence", ")", "[", "1", "]", ")", "\n", "if", "dtype", "is", "None", ":", "\n", "        ", "dtype", "=", "sequence", ".", "dtype", "\n", "", "mask", "=", "tf", ".", "sequence_mask", "(", "\n", "tf", ".", "to_int32", "(", "sequence_length", ")", ",", "max_time", ",", "dtype", "=", "dtype", ")", "\n", "for", "_", "in", "range", "(", "2", ",", "tensor_rank", ")", ":", "\n", "        ", "mask", "=", "tf", ".", "expand_dims", "(", "mask", ",", "axis", "=", "-", "1", ")", "\n", "", "sequence", "=", "sequence", "*", "mask", "\n", "if", "time_major", ":", "\n", "        ", "sequence", "=", "rnn", ".", "_transpose_batch_time", "(", "sequence", ")", "\n", "", "return", "sequence", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.shapes._mask_sequences_py": [[182, 237], ["numpy.array", "numpy.array", "numpy.tile", "numpy.asarray", "range", "ValueError", "numpy.transpose", "numpy.arange", "numpy.expand_dims", "numpy.transpose"], "function", ["None"], ["", "def", "_mask_sequences_py", "(", "sequence", ",", "\n", "sequence_length", ",", "\n", "dtype", "=", "None", ",", "\n", "time_major", "=", "False", ")", ":", "\n", "    ", "\"\"\"Masks out sequence entries that are beyond the respective sequence\n    lengths. Masks along the time dimension.\n\n    This is the numpy version of :func:`texar.utils.mask_sequences`.\n\n    Args:\n        sequence: An python array of sequence values.\n\n            If `time_major=False` (default), this must be an array of shape:\n                `[batch_size, max_time, ...]`\n\n            If `time_major=True`, this must be a Tensor of shape:\n                `[max_time, batch_size, ...].`\n        sequence_length: An array of shape `[batch_size]`. Time steps beyond\n            the respective sequence lengths will be made zero.\n        dtype (dtype): Type of :attr:`sequence`. If `None`, infer from\n            :attr:`sequence` automatically.\n        time_major (bool): The shape format of the inputs. If `True`,\n            :attr:`sequence` must have shape\n            `[max_time, batch_size, ...]`.\n            If `False` (default), :attr:`sequence` must have\n            shape `[batch_size, max_time, ...]`.\n\n    Returns:\n        The masked sequence, i.e., an array of the same shape as\n        :attr:`sequence` but with masked-out entries (set to zero).\n    \"\"\"", "\n", "sequence", "=", "np", ".", "array", "(", "sequence", ")", "\n", "sequence_length", "=", "np", ".", "array", "(", "sequence_length", ")", "\n", "\n", "rank", "=", "sequence", ".", "ndim", "\n", "if", "rank", "<", "2", ":", "\n", "        ", "raise", "ValueError", "(", "\"`sequence` must be 2D or higher order.\"", ")", "\n", "", "batch_size", "=", "sequence", ".", "shape", "[", "0", "]", "\n", "max_time", "=", "sequence", ".", "shape", "[", "1", "]", "\n", "dtype", "=", "dtype", "or", "sequence", ".", "dtype", "\n", "\n", "if", "time_major", ":", "\n", "        ", "sequence", "=", "np", ".", "transpose", "(", "sequence", ",", "axes", "=", "[", "1", ",", "0", ",", "2", "]", ")", "\n", "\n", "", "steps", "=", "np", ".", "tile", "(", "np", ".", "arange", "(", "max_time", ")", ",", "[", "batch_size", ",", "1", "]", ")", "\n", "mask", "=", "np", ".", "asarray", "(", "steps", "<", "sequence_length", "[", ":", ",", "None", "]", ",", "dtype", "=", "dtype", ")", "\n", "for", "_", "in", "range", "(", "2", ",", "rank", ")", ":", "\n", "        ", "mask", "=", "np", ".", "expand_dims", "(", "mask", ",", "-", "1", ")", "\n", "\n", "", "sequence", "=", "sequence", "*", "mask", "\n", "\n", "if", "time_major", ":", "\n", "        ", "sequence", "=", "np", ".", "transpose", "(", "sequence", ",", "axes", "=", "[", "1", ",", "0", ",", "2", "]", ")", "\n", "\n", "", "return", "sequence", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.shapes.flatten": [[239, 266], ["tensorflow.concat", "tensorflow.reshape", "tensorflow.shape"], "function", ["None"], ["", "def", "flatten", "(", "tensor", ",", "preserve_dims", ",", "flattened_dim", "=", "None", ")", ":", "\n", "    ", "\"\"\"Flattens a tensor whiling keeping several leading dimensions.\n\n    :attr:`preserve_dims` must < tensor's rank\n\n    Args:\n        tensor: A Tensor to flatten.\n        preserve_dims (int): The number of leading dimensions to preserve.\n        flatterned_dim (int, optional): The size of the resulting flattened\n            dimension. If not given, infer automatically, which can cause\n            a statically unknown dimension size.\n\n    Returns:\n        A Tensor with rank :attr:`perserve_dims`+1.\n\n    Example:\n        .. code-block:: python\n\n            x = tf.ones(shape=[d_1, d_2, d_3, d_4])\n            y = flatten(x, 2) # y.shape == [d_1, d_2, d_3 * d_4]\n    \"\"\"", "\n", "if", "flattened_dim", "is", "None", ":", "\n", "        ", "flattened_dim", "=", "-", "1", "\n", "", "shape", "=", "tf", ".", "concat", "(", "[", "tf", ".", "shape", "(", "tensor", ")", "[", ":", "preserve_dims", "]", ",", "[", "flattened_dim", "]", "]", ",", "\n", "axis", "=", "0", ")", "\n", "tensor_", "=", "tf", ".", "reshape", "(", "tensor", ",", "shape", ")", "\n", "return", "tensor_", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.shapes.shape_list": [[267, 291], ["tensorflow.convert_to_tensor", "tf.convert_to_tensor.get_shape().as_list", "tensorflow.shape", "enumerate", "tensorflow.shape", "ret.append", "tf.convert_to_tensor.get_shape", "tf.convert_to_tensor.get_shape"], "function", ["None"], ["", "def", "shape_list", "(", "x", ")", ":", "\n", "    ", "\"\"\"Returns the tensor shape.\n\n    Returns static shape when possible.\n\n    Returns:\n\n        - If the rank of :attr:`x` is unknown, returns the dynamic shape: \\\n        `tf.shape(x)`\n        - Otherwise, returns a list of dims, each of which is either an `int` \\\n        whenever it can be statically determined, or a scalar Tensor.\n    \"\"\"", "\n", "x", "=", "tf", ".", "convert_to_tensor", "(", "x", ")", "\n", "# If unknown rank, return dynamic shape", "\n", "if", "x", ".", "get_shape", "(", ")", ".", "dims", "is", "None", ":", "\n", "        ", "return", "tf", ".", "shape", "(", "x", ")", "\n", "", "static", "=", "x", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", "\n", "shape", "=", "tf", ".", "shape", "(", "x", ")", "\n", "ret", "=", "[", "]", "\n", "for", "i", ",", "dim", "in", "enumerate", "(", "static", ")", ":", "\n", "        ", "if", "dim", "is", "None", ":", "\n", "            ", "dim", "=", "shape", "[", "i", "]", "\n", "", "ret", ".", "append", "(", "dim", ")", "\n", "", "return", "ret", "\n", "", ""]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.beam_search._merge_beam_dim": [[30, 43], ["texar.utils.shapes.shape_list", "texar.utils.shapes.shape_list.pop", "tensorflow.reshape"], "function", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.shapes.shape_list"], ["def", "_merge_beam_dim", "(", "tensor", ")", ":", "\n", "    ", "\"\"\"Reshapes first two dimensions in to single dimension.\n\n    Args:\n        tensor: Tensor to reshape of shape [A, B, ...]\n\n    Returns:\n        Reshaped tensor of shape [A*B, ...]\n    \"\"\"", "\n", "shape", "=", "shape_list", "(", "tensor", ")", "\n", "shape", "[", "0", "]", "*=", "shape", "[", "1", "]", "# batch -> batch * beam_size", "\n", "shape", ".", "pop", "(", "1", ")", "# Remove beam dim", "\n", "return", "tf", ".", "reshape", "(", "tensor", ",", "shape", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.beam_search._unmerge_beam_dim": [[45, 59], ["texar.utils.shapes.shape_list", "tensorflow.reshape"], "function", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.shapes.shape_list"], ["", "def", "_unmerge_beam_dim", "(", "tensor", ",", "batch_size", ",", "beam_size", ")", ":", "\n", "    ", "\"\"\"Reshapes first dimension back to [batch_size, beam_size].\n\n    Args:\n        tensor: Tensor to reshape of shape [batch_size*beam_size, ...]\n        batch_size: Tensor, original batch size.\n        beam_size: int, original beam size.\n\n    Returns:\n        Reshaped tensor of shape [batch_size, beam_size, ...]\n    \"\"\"", "\n", "shape", "=", "shape_list", "(", "tensor", ")", "\n", "new_shape", "=", "[", "batch_size", "]", "+", "[", "beam_size", "]", "+", "shape", "[", "1", ":", "]", "\n", "return", "tf", ".", "reshape", "(", "tensor", ",", "new_shape", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.beam_search._expand_to_beam_size": [[61, 76], ["tensorflow.expand_dims", "tensorflow.tile"], "function", ["None"], ["", "def", "_expand_to_beam_size", "(", "tensor", ",", "beam_size", ")", ":", "\n", "    ", "\"\"\"Tiles a given tensor by beam_size.\n\n    Args:\n        tensor: tensor to tile [batch_size, ...]\n        beam_size: How much to tile the tensor by.\n\n    Returns:\n        Tiled tensor [batch_size, beam_size, ...]\n    \"\"\"", "\n", "tensor", "=", "tf", ".", "expand_dims", "(", "tensor", ",", "axis", "=", "1", ")", "\n", "tile_dims", "=", "[", "1", "]", "*", "tensor", ".", "shape", ".", "ndims", "\n", "tile_dims", "[", "1", "]", "=", "beam_size", "\n", "\n", "return", "tf", ".", "tile", "(", "tensor", ",", "tile_dims", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.beam_search.get_state_shape_invariants": [[78, 84], ["tensor.shape.as_list", "range", "tensorflow.TensorShape", "len"], "function", ["None"], ["", "def", "get_state_shape_invariants", "(", "tensor", ")", ":", "\n", "    ", "\"\"\"Returns the shape of the tensor but sets middle dims to None.\"\"\"", "\n", "shape", "=", "tensor", ".", "shape", ".", "as_list", "(", ")", "\n", "for", "i", "in", "range", "(", "1", ",", "len", "(", "shape", ")", "-", "1", ")", ":", "\n", "        ", "shape", "[", "i", "]", "=", "None", "\n", "", "return", "tf", ".", "TensorShape", "(", "shape", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.beam_search.log_prob_from_logits": [[86, 88], ["tensorflow.reduce_logsumexp"], "function", ["None"], ["", "def", "log_prob_from_logits", "(", "logits", ")", ":", "\n", "    ", "return", "logits", "-", "tf", ".", "reduce_logsumexp", "(", "logits", ",", "axis", "=", "-", "1", ",", "keep_dims", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.beam_search.compute_batch_indices": [[90, 106], ["tensorflow.reshape", "tensorflow.range"], "function", ["None"], ["", "def", "compute_batch_indices", "(", "batch_size", ",", "beam_size", ")", ":", "\n", "    ", "\"\"\"Computes the i'th coodinate that contains the batch index for gathers.\n\n    Batch pos is a tensor like [[0,0,0,0,],[1,1,1,1],..]. It says which\n    batch the beam item is in. This will create the i of the i,j coordinate\n    needed for the gather.\n\n    Args:\n        batch_size: Batch size\n        beam_size: Size of the beam.\n    Returns:\n        batch_pos: [batch_size, beam_size] tensor of ids\n    \"\"\"", "\n", "batch_pos", "=", "tf", ".", "range", "(", "batch_size", "*", "beam_size", ")", "//", "beam_size", "\n", "batch_pos", "=", "tf", ".", "reshape", "(", "batch_pos", ",", "[", "batch_size", ",", "beam_size", "]", ")", "\n", "return", "batch_pos", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.beam_search.compute_topk_scores_and_seq": [[108, 172], ["tensorflow.nn.top_k", "beam_search.compute_batch_indices", "tensorflow.stack", "beam_search.compute_topk_scores_and_seq.gather"], "function", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.beam_search.compute_batch_indices"], ["", "def", "compute_topk_scores_and_seq", "(", "sequences", ",", "scores", ",", "scores_to_gather", ",", "flags", ",", "\n", "beam_size", ",", "batch_size", ",", "prefix", "=", "\"default\"", ",", "\n", "states_to_gather", "=", "None", ")", ":", "\n", "    ", "\"\"\"Given sequences and scores, will gather the top k=beam size sequences.\n\n    This function is used to grow alive, and finished. It takes sequences,\n    scores, and flags, and returns the top k from sequences, scores_to_gather,\n    and flags based on the values in scores.\n\n    This method permits easy introspection using tfdbg.    It adds three named ops\n    that are prefixed by `prefix`:\n        - _topk_seq: the tensor for topk_seq returned by this method.\n        - _topk_flags: the tensor for topk_finished_flags returned by this method.\n        - _topk_scores: the tensor for tokp_gathered_scores returned by this method.\n\n    Args:\n        sequences: Tensor of sequences that we need to gather from.\n            [batch_size, beam_size, seq_length]\n        scores: Tensor of scores for each sequence in sequences.\n            [batch_size, beam_size]. We will use these to compute the topk.\n        scores_to_gather: Tensor of scores for each sequence in sequences.\n            [batch_size, beam_size]. We will return the gathered scores from here.\n            Scores to gather is different from scores because for grow_alive, we will\n            need to return log_probs, while for grow_finished, we will need to return\n            the length penalized scors.\n        flags: Tensor of bools for sequences that say whether a sequence has reached\n            EOS or not\n        beam_size: int\n        batch_size: int\n        prefix: string that will prefix unique names for the ops run.\n        states_to_gather: dict (possibly nested) of decoding states.\n    Returns:\n        Tuple of\n        (topk_seq [batch_size, beam_size, decode_length],\n         topk_gathered_scores [batch_size, beam_size],\n         topk_finished_flags[batch_size, beam_size])\n    \"\"\"", "\n", "_", ",", "topk_indexes", "=", "tf", ".", "nn", ".", "top_k", "(", "scores", ",", "k", "=", "beam_size", ")", "\n", "# The next three steps are to create coordinates for tf.gather_nd to pull", "\n", "# out the topk sequences from sequences based on scores.", "\n", "# batch pos is a tensor like [[0,0,0,0,],[1,1,1,1],..]. It says which", "\n", "# batch the beam item is in. This will create the i of the i,j coordinate", "\n", "# needed for the gather", "\n", "batch_pos", "=", "compute_batch_indices", "(", "batch_size", ",", "beam_size", ")", "\n", "\n", "# top coordinates will give us the actual coordinates to do the gather.", "\n", "# stacking will create a tensor of dimension batch * beam * 2, where the", "\n", "# last dimension contains the i,j gathering coordinates.", "\n", "top_coordinates", "=", "tf", ".", "stack", "(", "[", "batch_pos", ",", "topk_indexes", "]", ",", "axis", "=", "2", ")", "\n", "\n", "# Gather up the highest scoring sequences.    For each operation added, give it", "\n", "# a concrete name to simplify observing these operations with tfdbg.    Clients", "\n", "# can capture these tensors by watching these node names.", "\n", "def", "gather", "(", "tensor", ",", "name", ")", ":", "\n", "        ", "return", "tf", ".", "gather_nd", "(", "tensor", ",", "top_coordinates", ",", "name", "=", "(", "prefix", "+", "name", ")", ")", "\n", "", "topk_seq", "=", "gather", "(", "sequences", ",", "\"_topk_seq\"", ")", "\n", "topk_flags", "=", "gather", "(", "flags", ",", "\"_topk_flags\"", ")", "\n", "topk_gathered_scores", "=", "gather", "(", "scores_to_gather", ",", "\"_topk_scores\"", ")", "\n", "if", "states_to_gather", ":", "\n", "        ", "topk_gathered_states", "=", "nest", ".", "map_structure", "(", "\n", "lambda", "state", ":", "gather", "(", "state", ",", "\"_topk_states\"", ")", ",", "states_to_gather", ")", "\n", "", "else", ":", "\n", "        ", "topk_gathered_states", "=", "states_to_gather", "\n", "", "return", "topk_seq", ",", "topk_gathered_scores", ",", "topk_flags", ",", "topk_gathered_states", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.beam_search.beam_search": [[174, 550], ["tensorflow.constant", "tensorflow.tile", "beam_search._expand_to_beam_size", "tensorflow.expand_dims", "tensorflow.zeros", "tensorflow.zeros", "tensorflow.while_loop", "tf.expand_dims.set_shape", "tf.concat.set_shape", "tensorflow.where", "tensorflow.where", "texar.utils.shapes.shape_list", "tensorflow.python.util.nest.map_structure", "texar.utils.shapes.shape_list", "tensorflow.ones", "tensorflow.concat", "tensorflow.concat", "tensorflow.concat", "tensorflow.concat", "beam_search.compute_topk_scores_and_seq", "beam_search.compute_topk_scores_and_seq", "tensorflow.reshape", "tensorflow.reshape", "beam_search.log_prob_from_logits", "tensorflow.pow", "tensorflow.reshape", "tensorflow.nn.top_k", "beam_search.compute_batch_indices", "tensorflow.stack", "tensorflow.gather_nd", "tensorflow.concat", "tensorflow.equal", "beam_search.beam_search.grow_topk"], "function", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.beam_search._expand_to_beam_size", "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.shapes.shape_list", "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.shapes.shape_list", "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.beam_search.compute_topk_scores_and_seq", "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.beam_search.compute_topk_scores_and_seq", "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.beam_search.log_prob_from_logits", "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.beam_search.compute_batch_indices"], ["", "def", "beam_search", "(", "symbols_to_logits_fn", ",", "\n", "initial_ids", ",", "\n", "beam_size", ",", "\n", "decode_length", ",", "\n", "vocab_size", ",", "\n", "alpha", ",", "\n", "eos_id", ",", "\n", "states", "=", "None", ",", "\n", "stop_early", "=", "True", ")", ":", "\n", "    ", "\"\"\"Beam search with length penalties.\n\n    Requires a function that can take the currently decoded sybmols and return\n    the logits for the next symbol. The implementation is inspired by\n    https://arxiv.org/abs/1609.08144.\n\n    When running, the beam search steps can be visualized by using tfdbg to watch\n    the operations generating the output ids for each beam step.    These operations\n    have the pattern:\n        (alive|finished)_topk_(seq,scores)\n\n    Operations marked `alive` represent the new beam sequences that will be\n    processed in the next step.    Operations marked `finished` represent the\n    completed beam sequences, which may be padded with 0s if no beams finished.\n\n    Operations marked `seq` store the full beam sequence for the time step.\n    Operations marked `scores` store the sequence's final log scores.\n\n    The beam search steps will be processed sequentially in order, so when\n    capturing observed from these operations, tensors, clients can make\n    assumptions about which step is being recorded.\n\n    WARNING: Assumes 2nd dimension of tensors in `states` and not invariant, this\n    means that the shape of the 2nd dimension of these tensors will not be\n    available (i.e. set to None) inside symbols_to_logits_fn.\n\n    Args:\n        symbols_to_logits_fn: Interface to the model, to provide logits.\n                Shoud take [batch_size, decoded_ids] and return [batch_size, vocab_size]\n        initial_ids: Ids to start off the decoding, this will be the first thing\n                handed to symbols_to_logits_fn (after expanding to beam size)\n                [batch_size]\n        beam_size: Size of the beam.\n        decode_length: Number of steps to decode for.\n        vocab_size: Size of the vocab, must equal the size of the logits returned by\n                symbols_to_logits_fn\n        alpha: alpha for length penalty.\n        states: dict (possibly nested) of decoding states.\n        eos_id: ID for end of sentence.\n        stop_early: a boolean - stop once best sequence is provably determined.\n    Returns:\n        Tuple of\n        (decoded beams [batch_size, beam_size, decode_length]\n         decoding probablities [batch_size, beam_size])\n    \"\"\"", "\n", "batch_size", "=", "shape_list", "(", "initial_ids", ")", "[", "0", "]", "\n", "\n", "# Assume initial_ids are prob 1.0", "\n", "initial_log_probs", "=", "tf", ".", "constant", "(", "[", "[", "0.", "]", "+", "[", "-", "float", "(", "\"inf\"", ")", "]", "*", "(", "beam_size", "-", "1", ")", "]", ")", "\n", "# Expand to beam_size (batch_size, beam_size)", "\n", "alive_log_probs", "=", "tf", ".", "tile", "(", "initial_log_probs", ",", "[", "batch_size", ",", "1", "]", ")", "\n", "\n", "# Expand each batch and state to beam_size", "\n", "alive_seq", "=", "_expand_to_beam_size", "(", "initial_ids", ",", "beam_size", ")", "\n", "alive_seq", "=", "tf", ".", "expand_dims", "(", "alive_seq", ",", "axis", "=", "2", ")", "# (batch_size, beam_size, 1)", "\n", "if", "states", ":", "\n", "        ", "states", "=", "nest", ".", "map_structure", "(", "\n", "lambda", "state", ":", "_expand_to_beam_size", "(", "state", ",", "beam_size", ")", ",", "states", ")", "\n", "", "else", ":", "\n", "        ", "states", "=", "{", "}", "\n", "\n", "# Finished will keep track of all the sequences that have finished so far", "\n", "# Finished log probs will be negative infinity in the beginning", "\n", "# finished_flags will keep track of booleans", "\n", "", "finished_seq", "=", "tf", ".", "zeros", "(", "shape_list", "(", "alive_seq", ")", ",", "tf", ".", "int32", ")", "\n", "# Setting the scores of the initial to negative infinity.", "\n", "finished_scores", "=", "tf", ".", "ones", "(", "[", "batch_size", ",", "beam_size", "]", ")", "*", "-", "INF", "\n", "finished_flags", "=", "tf", ".", "zeros", "(", "[", "batch_size", ",", "beam_size", "]", ",", "tf", ".", "bool", ")", "\n", "\n", "def", "grow_finished", "(", "finished_seq", ",", "finished_scores", ",", "finished_flags", ",", "curr_seq", ",", "\n", "curr_scores", ",", "curr_finished", ")", ":", "\n", "        ", "\"\"\"Given sequences and scores, will gather the top k=beam size sequences.\n\n        Args:\n            finished_seq: Current finished sequences.\n                [batch_size, beam_size, current_decoded_length]\n            finished_scores: scores for each of these sequences.\n                [batch_size, beam_size]\n            finished_flags: finished bools for each of these sequences.\n                [batch_size, beam_size]\n            curr_seq: current topk sequence that has been grown by one position.\n                [batch_size, beam_size, current_decoded_length]\n            curr_scores: scores for each of these sequences. [batch_size, beam_size]\n            curr_finished: Finished flags for each of these sequences.\n                [batch_size, beam_size]\n        Returns:\n            Tuple of\n                (Topk sequences based on scores,\n                 log probs of these sequences,\n                 Finished flags of these sequences)\n        \"\"\"", "\n", "# First append a column of 0'ids to finished to make the same length with", "\n", "# finished scores", "\n", "finished_seq", "=", "tf", ".", "concat", "(", "\n", "[", "finished_seq", ",", "\n", "tf", ".", "zeros", "(", "[", "batch_size", ",", "beam_size", ",", "1", "]", ",", "tf", ".", "int32", ")", "]", ",", "axis", "=", "2", ")", "\n", "\n", "# Set the scores of the unfinished seq in curr_seq to large negative", "\n", "# values", "\n", "curr_scores", "+=", "(", "1.", "-", "tf", ".", "to_float", "(", "curr_finished", ")", ")", "*", "-", "INF", "\n", "# concatenating the sequences and scores along beam axis", "\n", "curr_finished_seq", "=", "tf", ".", "concat", "(", "[", "finished_seq", ",", "curr_seq", "]", ",", "axis", "=", "1", ")", "\n", "curr_finished_scores", "=", "tf", ".", "concat", "(", "[", "finished_scores", ",", "curr_scores", "]", ",", "axis", "=", "1", ")", "\n", "curr_finished_flags", "=", "tf", ".", "concat", "(", "[", "finished_flags", ",", "curr_finished", "]", ",", "axis", "=", "1", ")", "\n", "return", "compute_topk_scores_and_seq", "(", "\n", "curr_finished_seq", ",", "curr_finished_scores", ",", "curr_finished_scores", ",", "\n", "curr_finished_flags", ",", "beam_size", ",", "batch_size", ",", "\"grow_finished\"", ")", "\n", "\n", "", "def", "grow_alive", "(", "curr_seq", ",", "curr_scores", ",", "curr_log_probs", ",", "curr_finished", ",", "states", ")", ":", "\n", "        ", "\"\"\"Given sequences and scores, will gather the top k=beam size sequences.\n\n        Args:\n            curr_seq: current topk sequence that has been grown by one position.\n                [batch_size, beam_size, i+1]\n            curr_scores: scores for each of these sequences. [batch_size, beam_size]\n            curr_log_probs: log probs for each of these sequences.\n                [batch_size, beam_size]\n            curr_finished: Finished flags for each of these sequences.\n                [batch_size, beam_size]\n            states: dict (possibly nested) of decoding states.\n        Returns:\n            Tuple of\n                (Topk sequences based on scores,\n                 log probs of these sequences,\n                 Finished flags of these sequences)\n        \"\"\"", "\n", "# Set the scores of the finished seq in curr_seq to large negative", "\n", "# values", "\n", "curr_scores", "+=", "tf", ".", "to_float", "(", "curr_finished", ")", "*", "-", "INF", "\n", "return", "compute_topk_scores_and_seq", "(", "curr_seq", ",", "curr_scores", ",", "curr_log_probs", ",", "\n", "curr_finished", ",", "beam_size", ",", "batch_size", ",", "\n", "\"grow_alive\"", ",", "states", ")", "\n", "\n", "", "def", "grow_topk", "(", "i", ",", "alive_seq", ",", "alive_log_probs", ",", "states", ")", ":", "\n", "        ", "r\"\"\"Inner beam seach loop.\n\n        This function takes the current alive sequences, and grows them to topk\n        sequences where k = 2*beam. We use 2*beam because, we could have beam_size\n        number of sequences that might hit <EOS> and there will be no alive\n        sequences to continue. With 2*beam_size, this will not happen. This relies\n        on the assumption the vocab size is > beam size. If this is true, we'll\n        have at least beam_size non <EOS> extensions if we extract the next top\n        2*beam words.\n        Length penalty is given by = (5+len(decode)/6) ^ -\\alpha. Pls refer to\n        https://arxiv.org/abs/1609.08144.\n\n        Args:\n            i: loop index\n            alive_seq: Topk sequences decoded so far [batch_size, beam_size, i+1]\n            alive_log_probs: probabilities of these sequences. [batch_size, beam_size]\n            states: dict (possibly nested) of decoding states.\n        Returns:\n            Tuple of\n                (Topk sequences extended by the next word,\n                 The log probs of these sequences,\n                 The scores with length penalty of these sequences,\n                 Flags indicating which of these sequences have finished decoding,\n                 dict of transformed decoding states)\n        \"\"\"", "\n", "# Get the logits for all the possible next symbols", "\n", "flat_ids", "=", "tf", ".", "reshape", "(", "alive_seq", ",", "[", "batch_size", "*", "beam_size", ",", "-", "1", "]", ")", "\n", "\n", "# (batch_size * beam_size, decoded_length)", "\n", "if", "states", ":", "\n", "            ", "flat_states", "=", "nest", ".", "map_structure", "(", "_merge_beam_dim", ",", "states", ")", "\n", "flat_logits", ",", "flat_states", "=", "symbols_to_logits_fn", "(", "flat_ids", ",", "i", ",", "flat_states", ")", "\n", "states", "=", "nest", ".", "map_structure", "(", "\n", "lambda", "t", ":", "_unmerge_beam_dim", "(", "t", ",", "batch_size", ",", "beam_size", ")", ",", "flat_states", ")", "\n", "", "else", ":", "\n", "            ", "flat_logits", "=", "symbols_to_logits_fn", "(", "flat_ids", ")", "\n", "", "logits", "=", "tf", ".", "reshape", "(", "flat_logits", ",", "[", "batch_size", ",", "beam_size", ",", "-", "1", "]", ")", "\n", "\n", "# Convert logits to normalized log probs", "\n", "candidate_log_probs", "=", "log_prob_from_logits", "(", "logits", ")", "\n", "\n", "# Multiply the probabilites by the current probabilites of the beam.", "\n", "# (batch_size, beam_size, vocab_size) + (batch_size, beam_size, 1)", "\n", "log_probs", "=", "candidate_log_probs", "+", "tf", ".", "expand_dims", "(", "alive_log_probs", ",", "axis", "=", "2", ")", "\n", "\n", "length_penalty", "=", "tf", ".", "pow", "(", "(", "(", "5.", "+", "tf", ".", "to_float", "(", "i", "+", "1", ")", ")", "/", "6.", ")", ",", "alpha", ")", "\n", "\n", "curr_scores", "=", "log_probs", "/", "length_penalty", "\n", "# Flatten out (beam_size, vocab_size) probs in to a list of possibilites", "\n", "flat_curr_scores", "=", "tf", ".", "reshape", "(", "curr_scores", ",", "[", "-", "1", ",", "beam_size", "*", "vocab_size", "]", ")", "\n", "\n", "topk_scores", ",", "topk_ids", "=", "tf", ".", "nn", ".", "top_k", "(", "flat_curr_scores", ",", "k", "=", "beam_size", "*", "2", ")", "\n", "\n", "# Recovering the log probs because we will need to send them back", "\n", "topk_log_probs", "=", "topk_scores", "*", "length_penalty", "\n", "\n", "# Work out what beam the top probs are in.", "\n", "topk_beam_index", "=", "topk_ids", "//", "vocab_size", "\n", "topk_ids", "%=", "vocab_size", "# Unflatten the ids", "\n", "\n", "# The next three steps are to create coordinates for tf.gather_nd to pull", "\n", "# out the correct seqences from id's that we need to grow.", "\n", "# We will also use the coordinates to gather the booleans of the beam items", "\n", "# that survived.", "\n", "batch_pos", "=", "compute_batch_indices", "(", "batch_size", ",", "beam_size", "*", "2", ")", "\n", "\n", "# top beams will give us the actual coordinates to do the gather.", "\n", "# stacking will create a tensor of dimension batch * beam * 2, where the", "\n", "# last dimension contains the i,j gathering coordinates.", "\n", "topk_coordinates", "=", "tf", ".", "stack", "(", "[", "batch_pos", ",", "topk_beam_index", "]", ",", "axis", "=", "2", ")", "\n", "\n", "# Gather up the most probable 2*beams both for the ids and finished_in_alive", "\n", "# bools", "\n", "topk_seq", "=", "tf", ".", "gather_nd", "(", "alive_seq", ",", "topk_coordinates", ")", "\n", "if", "states", ":", "\n", "            ", "states", "=", "nest", ".", "map_structure", "(", "\n", "lambda", "state", ":", "tf", ".", "gather_nd", "(", "state", ",", "topk_coordinates", ")", ",", "states", ")", "\n", "\n", "# Append the most probable alive", "\n", "", "topk_seq", "=", "tf", ".", "concat", "(", "[", "topk_seq", ",", "tf", ".", "expand_dims", "(", "topk_ids", ",", "axis", "=", "2", ")", "]", ",", "axis", "=", "2", ")", "\n", "\n", "topk_finished", "=", "tf", ".", "equal", "(", "topk_ids", ",", "eos_id", ")", "\n", "\n", "return", "topk_seq", ",", "topk_log_probs", ",", "topk_scores", ",", "topk_finished", ",", "states", "\n", "\n", "", "def", "inner_loop", "(", "i", ",", "alive_seq", ",", "alive_log_probs", ",", "finished_seq", ",", "finished_scores", ",", "\n", "finished_flags", ",", "states", ")", ":", "\n", "        ", "\"\"\"Inner beam seach loop.\n\n        There are three groups of tensors, alive, finished, and topk.\n        The alive group contains information about the current alive sequences\n        The topk group contains information about alive + topk current decoded words\n        the finished group contains information about finished sentences, that is,\n        the ones that have decoded to <EOS>. These are what we return.\n        The general beam search algorithm is as follows:\n        While we haven't terminated (pls look at termination condition)\n            1. Grow the current alive to get beam*2 topk sequences\n            2. Among the topk, keep the top beam_size ones that haven't reached EOS\n            into alive\n            3. Among the topk, keep the top beam_size ones have reached EOS into\n            finished\n        Repeat\n        To make things simple with using fixed size tensors, we will end\n        up inserting unfinished sequences into finished in the beginning. To stop\n        that we add -ve INF to the score of the unfinished sequence so that when a\n        true finished sequence does appear, it will have a higher score than all the\n        unfinished ones.\n\n        Args:\n            i: loop index\n            alive_seq: Topk sequences decoded so far [batch_size, beam_size, i+1]\n            alive_log_probs: probabilities of the beams. [batch_size, beam_size]\n            finished_seq: Current finished sequences.\n                [batch_size, beam_size, i+1]\n            finished_scores: scores for each of these sequences.\n                [batch_size, beam_size]\n            finished_flags: finished bools for each of these sequences.\n                [batch_size, beam_size]\n            states: dict (possibly nested) of decoding states.\n\n        Returns:\n            Tuple of\n                (Incremented loop index\n                 New alive sequences,\n                 Log probs of the alive sequences,\n                 New finished sequences,\n                 Scores of the new finished sequences,\n                 Flags inidicating which sequence in finished as reached EOS,\n                 dict of final decoding states)\n        \"\"\"", "\n", "\n", "# Each inner loop, we carry out three steps:", "\n", "# 1. Get the current topk items.", "\n", "# 2. Extract the ones that have finished and haven't finished", "\n", "# 3. Recompute the contents of finished based on scores.", "\n", "topk_seq", ",", "topk_log_probs", ",", "topk_scores", ",", "topk_finished", ",", "states", "=", "grow_topk", "(", "\n", "i", ",", "alive_seq", ",", "alive_log_probs", ",", "states", ")", "\n", "alive_seq", ",", "alive_log_probs", ",", "_", ",", "states", "=", "grow_alive", "(", "\n", "topk_seq", ",", "topk_scores", ",", "topk_log_probs", ",", "topk_finished", ",", "states", ")", "\n", "finished_seq", ",", "finished_scores", ",", "finished_flags", ",", "_", "=", "grow_finished", "(", "\n", "finished_seq", ",", "finished_scores", ",", "finished_flags", ",", "topk_seq", ",", "topk_scores", ",", "\n", "topk_finished", ")", "\n", "\n", "return", "(", "i", "+", "1", ",", "alive_seq", ",", "alive_log_probs", ",", "finished_seq", ",", "finished_scores", ",", "\n", "finished_flags", ",", "states", ")", "\n", "\n", "", "def", "_is_finished", "(", "i", ",", "unused_alive_seq", ",", "alive_log_probs", ",", "unused_finished_seq", ",", "\n", "finished_scores", ",", "finished_in_finished", ",", "unused_states", ")", ":", "\n", "        ", "\"\"\"Checking termination condition.\n\n        We terminate when we decoded up to decode_length or the lowest scoring item\n        in finished has a greater score that the higest prob item in alive divided\n        by the max length penalty\n\n        Args:\n            i: loop index\n            alive_log_probs: probabilities of the beams. [batch_size, beam_size]\n            finished_scores: scores for each of these sequences.\n                [batch_size, beam_size]\n            finished_in_finished: finished bools for each of these sequences.\n                [batch_size, beam_size]\n\n        Returns:\n            Bool.\n        \"\"\"", "\n", "if", "not", "stop_early", ":", "\n", "            ", "return", "tf", ".", "less", "(", "i", ",", "decode_length", ")", "\n", "", "max_length_penalty", "=", "tf", ".", "pow", "(", "(", "(", "5.", "+", "tf", ".", "to_float", "(", "decode_length", ")", ")", "/", "6.", ")", ",", "alpha", ")", "\n", "# The best possible score of the most likley alive sequence", "\n", "lower_bound_alive_scores", "=", "alive_log_probs", "[", ":", ",", "0", "]", "/", "max_length_penalty", "\n", "\n", "# Now to compute the lowest score of a finished sequence in finished", "\n", "# If the sequence isn't finished, we multiply it's score by 0. since", "\n", "# scores are all -ve, taking the min will give us the score of the lowest", "\n", "# finished item.", "\n", "lowest_score_of_fininshed_in_finished", "=", "tf", ".", "reduce_min", "(", "\n", "finished_scores", "*", "tf", ".", "to_float", "(", "finished_in_finished", ")", ",", "axis", "=", "1", ")", "\n", "# If none of the sequences have finished, then the min will be 0 and", "\n", "# we have to replace it by -ve INF if it is. The score of any seq in alive", "\n", "# will be much higher than -ve INF and the termination condition will not", "\n", "# be met.", "\n", "lowest_score_of_fininshed_in_finished", "+=", "(", "\n", "(", "1.", "-", "tf", ".", "to_float", "(", "tf", ".", "reduce_any", "(", "finished_in_finished", ",", "1", ")", ")", ")", "*", "-", "INF", ")", "\n", "\n", "bound_is_met", "=", "tf", ".", "reduce_all", "(", "\n", "tf", ".", "greater", "(", "lowest_score_of_fininshed_in_finished", ",", "\n", "lower_bound_alive_scores", ")", ")", "\n", "\n", "return", "tf", ".", "logical_and", "(", "\n", "tf", ".", "less", "(", "i", ",", "decode_length", ")", ",", "tf", ".", "logical_not", "(", "bound_is_met", ")", ")", "\n", "\n", "#shapes = [tf.TensorShape([]),", "\n", "#                tf.TensorShape([None, None, None]),", "\n", "#                alive_log_probs.get_shape(),", "\n", "#                tf.TensorShape([None, None, None]),", "\n", "#                finished_scores.get_shape(),", "\n", "#                finished_flags.get_shape(),", "\n", "#                nest.map_structure(get_state_shape_invariants, states),", "\n", "#                ]", "\n", "#print('shapes:{}'.format(shapes))", "\n", "\n", "", "(", "_", ",", "alive_seq", ",", "alive_log_probs", ",", "finished_seq", ",", "finished_scores", ",", "\n", "finished_flags", ",", "_", ")", "=", "tf", ".", "while_loop", "(", "\n", "_is_finished", ",", "\n", "inner_loop", ",", "[", "\n", "tf", ".", "constant", "(", "0", ")", ",", "alive_seq", ",", "alive_log_probs", ",", "finished_seq", ",", "\n", "finished_scores", ",", "finished_flags", ",", "states", "\n", "]", ",", "\n", "shape_invariants", "=", "[", "\n", "tf", ".", "TensorShape", "(", "[", "]", ")", ",", "\n", "tf", ".", "TensorShape", "(", "[", "None", ",", "None", ",", "None", "]", ")", ",", "\n", "alive_log_probs", ".", "get_shape", "(", ")", ",", "\n", "tf", ".", "TensorShape", "(", "[", "None", ",", "None", ",", "None", "]", ")", ",", "\n", "finished_scores", ".", "get_shape", "(", ")", ",", "\n", "finished_flags", ".", "get_shape", "(", ")", ",", "\n", "nest", ".", "map_structure", "(", "get_state_shape_invariants", ",", "states", ")", ",", "\n", "]", ",", "\n", "parallel_iterations", "=", "1", ",", "\n", "back_prop", "=", "False", ")", "\n", "\n", "alive_seq", ".", "set_shape", "(", "(", "None", ",", "beam_size", ",", "None", ")", ")", "\n", "finished_seq", ".", "set_shape", "(", "(", "None", ",", "beam_size", ",", "None", ")", ")", "\n", "\n", "# Accounting for corner case: It's possible that no sequence in alive for a", "\n", "# particular batch item ever reached EOS. In that case, we should just copy", "\n", "# the contents of alive for that batch item. tf.reduce_any(finished_flags, 1)", "\n", "# if 0, means that no sequence for that batch index had reached EOS. We need", "\n", "# to do the same for the scores as well.", "\n", "finished_seq", "=", "tf", ".", "where", "(", "\n", "tf", ".", "reduce_any", "(", "finished_flags", ",", "1", ")", ",", "finished_seq", ",", "alive_seq", ")", "\n", "finished_scores", "=", "tf", ".", "where", "(", "\n", "tf", ".", "reduce_any", "(", "finished_flags", ",", "1", ")", ",", "finished_scores", ",", "alive_log_probs", ")", "\n", "return", "finished_seq", ",", "finished_scores", "\n", "", ""]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.variables.get_unique_named_variable_scope": [[21, 32], ["tensorflow.variable_scope"], "function", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.agents.agent_base.AgentBase.variable_scope"], ["def", "get_unique_named_variable_scope", "(", "base_name", ")", ":", "\n", "    ", "\"\"\"Returns a variable scope with a unique name.\n\n    Args:\n        base_name (str): The base name to uniquified.\n\n    Returns:\n        An instance of :tf_main:`variable_scope <variable_scope>`.\n    \"\"\"", "\n", "with", "tf", ".", "variable_scope", "(", "None", ",", "default_name", "=", "base_name", ")", "as", "vs", ":", "\n", "        ", "return", "vs", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.variables.add_variable": [[33, 46], ["isinstance", "variables.add_variable", "var_list.append"], "function", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.variables.add_variable"], ["", "", "def", "add_variable", "(", "variable", ",", "var_list", ")", ":", "\n", "    ", "\"\"\"Adds variable to a given list.\n\n    Args:\n        variable: A (list of) variable(s).\n        var_list (list): The list where the :attr:`variable` are added.\n    \"\"\"", "\n", "if", "isinstance", "(", "variable", ",", "(", "list", ",", "tuple", ")", ")", ":", "\n", "        ", "for", "var", "in", "variable", ":", "\n", "            ", "add_variable", "(", "var", ",", "var_list", ")", "\n", "", "", "else", ":", "\n", "        ", "if", "variable", "not", "in", "var_list", ":", "\n", "            ", "var_list", ".", "append", "(", "variable", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.variables.collect_trainable_variables": [[47, 68], ["isinstance", "variables.add_variable"], "function", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.variables.add_variable"], ["", "", "", "def", "collect_trainable_variables", "(", "modules", ")", ":", "\n", "    ", "\"\"\"Collects all trainable variables of modules.\n\n    Trainable variables included in multiple modules occur only once in the\n    returned list.\n\n    Args:\n        modules: A (list of) instance of the subclasses of\n            :class:`~texar.modules.ModuleBase`.\n\n    Returns:\n        A list of trainable variables in the modules.\n    \"\"\"", "\n", "if", "not", "isinstance", "(", "modules", ",", "(", "list", ",", "tuple", ")", ")", ":", "\n", "        ", "modules", "=", "[", "modules", "]", "\n", "\n", "", "var_list", "=", "[", "]", "\n", "for", "mod", "in", "modules", ":", "\n", "        ", "add_variable", "(", "mod", ".", "trainable_variables", ",", "var_list", ")", "\n", "\n", "", "return", "var_list", "\n", "", ""]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.mode_test.UtilsTest.test_mode": [[20, 44], ["texar.utils.mode.is_train_mode", "texar.utils.mode.is_train_mode", "mode_test.UtilsTest.test_session", "sess.run", "sess.run", "mode_test.UtilsTest.assertTrue", "sess.run", "mode_test.UtilsTest.assertTrue", "sess.run", "mode_test.UtilsTest.assertFalse", "mode_test.UtilsTest.test_session", "sess.run", "sess.run", "mode_test.UtilsTest.assertTrue", "tensorflow.global_variables_initializer", "tensorflow.global_variables_initializer", "texar.context.global_mode", "texar.context.global_mode"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.mode.is_train_mode", "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.mode.is_train_mode", "home.repos.pwc.inspect_result.VegB_Text_Infilling.texar.context.global_mode", "home.repos.pwc.inspect_result.VegB_Text_Infilling.texar.context.global_mode"], ["def", "test_mode", "(", "self", ")", ":", "\n", "        ", "\"\"\" Tests mode related utilities.\n        \"\"\"", "\n", "training", "=", "mode", ".", "is_train_mode", "(", "None", ")", "\n", "with", "self", ".", "test_session", "(", ")", "as", "sess", ":", "\n", "            ", "sess", ".", "run", "(", "tf", ".", "global_variables_initializer", "(", ")", ")", "\n", "training_", "=", "sess", ".", "run", "(", "training", ")", "\n", "self", ".", "assertTrue", "(", "training_", ")", "\n", "\n", "training_", "=", "sess", ".", "run", "(", "\n", "training", ",", "\n", "feed_dict", "=", "{", "context", ".", "global_mode", "(", ")", ":", "tf", ".", "estimator", ".", "ModeKeys", ".", "TRAIN", "}", ")", "\n", "self", ".", "assertTrue", "(", "training_", ")", "\n", "\n", "training_", "=", "sess", ".", "run", "(", "\n", "training", ",", "\n", "feed_dict", "=", "{", "context", ".", "global_mode", "(", ")", ":", "tf", ".", "estimator", ".", "ModeKeys", ".", "EVAL", "}", ")", "\n", "self", ".", "assertFalse", "(", "training_", ")", "\n", "\n", "", "training", "=", "mode", ".", "is_train_mode", "(", "tf", ".", "estimator", ".", "ModeKeys", ".", "TRAIN", ")", "\n", "with", "self", ".", "test_session", "(", ")", "as", "sess", ":", "\n", "            ", "sess", ".", "run", "(", "tf", ".", "global_variables_initializer", "(", ")", ")", "\n", "training_", "=", "sess", ".", "run", "(", "training", ")", "\n", "self", ".", "assertTrue", "(", "training_", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.shapes_test.ShapesTest.test_mask_sequences": [[21, 31], ["numpy.ones", "numpy.array", "texar.utils.shapes.mask_sequences", "shapes_test.ShapesTest.assertEqual", "numpy.sum", "numpy.testing.assert_array_equal"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.shapes.mask_sequences"], ["def", "test_mask_sequences", "(", "self", ")", ":", "\n", "        ", "\"\"\"Tests :func:`texar.utils.shapes.mask_sequences`.\n        \"\"\"", "\n", "seq", "=", "np", ".", "ones", "(", "[", "3", ",", "4", ",", "3", "]", ",", "dtype", "=", "np", ".", "int32", ")", "\n", "seq_length", "=", "np", ".", "array", "(", "[", "3", ",", "2", ",", "1", "]", ",", "dtype", "=", "np", ".", "int32", ")", "\n", "\n", "masked_seq", "=", "shapes", ".", "mask_sequences", "(", "seq", ",", "seq_length", ")", "\n", "self", ".", "assertEqual", "(", "masked_seq", ".", "shape", ",", "seq", ".", "shape", ")", "\n", "seq_sum", "=", "np", ".", "sum", "(", "masked_seq", ",", "axis", "=", "(", "1", ",", "2", ")", ")", "\n", "np", ".", "testing", ".", "assert_array_equal", "(", "seq_sum", ",", "seq_length", "*", "3", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.transformer_utils.PadRemover.__init__": [[46, 64], ["tensorflow.name_scope", "tensorflow.reshape", "tensorflow.to_int32", "tensorflow.where", "tensorflow.shape"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "pad_mask", ")", ":", "\n", "        ", "\"\"\"Compute and store the location of the padding.\n        Args:\n            pad_mask (tf.Tensor): Reference padding tensor of shape\n                [batch_size,length] or [dim_origin] (dim_origin=batch_size*length)\n                containing non-zeros positive values to indicate padding location.\n        \"\"\"", "\n", "self", ".", "nonpad_ids", "=", "None", "\n", "self", ".", "dim_origin", "=", "None", "\n", "\n", "with", "tf", ".", "name_scope", "(", "\"pad_reduce/get_ids\"", ")", ":", "\n", "            ", "pad_mask", "=", "tf", ".", "reshape", "(", "pad_mask", ",", "[", "-", "1", "]", ")", "# Flatten the batch", "\n", "# nonpad_ids contains coordinates of zeros rows (as pad_mask is", "\n", "# float32, checking zero equality is done with |x| < epsilon, with", "\n", "# epsilon=1e-9 as standard, here pad_mask only contains positive values", "\n", "# so tf.abs would be redundant)", "\n", "self", ".", "nonpad_ids", "=", "tf", ".", "to_int32", "(", "tf", ".", "where", "(", "pad_mask", "<", "1e-9", ")", ")", "\n", "self", ".", "dim_origin", "=", "tf", ".", "shape", "(", "pad_mask", ")", "[", ":", "1", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.transformer_utils.PadRemover.remove": [[65, 83], ["tensorflow.name_scope", "tensorflow.gather_nd.get_shape().as_list", "tensorflow.gather_nd", "tensorflow.gather_nd.set_shape", "tensorflow.gather_nd.get_shape"], "methods", ["None"], ["", "", "def", "remove", "(", "self", ",", "x", ")", ":", "\n", "        ", "\"\"\"Remove padding from the given tensor.\n        Args:\n            x (tf.Tensor): of shape [dim_origin,...]\n        Returns:\n            a tensor of shape [dim_compressed,...] with dim_compressed <= dim_origin\n        \"\"\"", "\n", "with", "tf", ".", "name_scope", "(", "\"pad_reduce/remove\"", ")", ":", "\n", "            ", "x_shape", "=", "x", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", "\n", "x", "=", "tf", ".", "gather_nd", "(", "\n", "x", ",", "\n", "indices", "=", "self", ".", "nonpad_ids", ",", "\n", ")", "\n", "#if not context.in_eager_mode():", "\n", "# This is a hack but for some reason, gather_nd return a tensor of", "\n", "# undefined shape, so the shape is set up manually", "\n", "x", ".", "set_shape", "(", "[", "None", "]", "+", "x_shape", "[", "1", ":", "]", ")", "\n", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.transformer_utils.PadRemover.restore": [[84, 99], ["tensorflow.name_scope", "tensorflow.scatter_nd", "tensorflow.concat", "tensorflow.shape"], "methods", ["None"], ["", "def", "restore", "(", "self", ",", "x", ")", ":", "\n", "        ", "\"\"\"Add padding back to the given tensor.\n        Args:\n            x (tf.Tensor): of shape [dim_compressed,...]\n        Returns:\n            a tensor of shape [dim_origin,...] with dim_compressed >= dim_origin. The\n            dim is restored from the original reference tensor\n        \"\"\"", "\n", "with", "tf", ".", "name_scope", "(", "\"pad_reduce/restore\"", ")", ":", "\n", "            ", "x", "=", "tf", ".", "scatter_nd", "(", "\n", "indices", "=", "self", ".", "nonpad_ids", ",", "\n", "updates", "=", "x", ",", "\n", "shape", "=", "tf", ".", "concat", "(", "[", "self", ".", "dim_origin", ",", "tf", ".", "shape", "(", "x", ")", "[", "1", ":", "]", "]", ",", "axis", "=", "0", ")", ",", "\n", ")", "\n", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.transformer_utils.embedding_to_padding": [[100, 110], ["tensorflow.reduce_sum", "tensorflow.to_float", "tensorflow.abs", "tensorflow.equal"], "function", ["None"], ["", "", "def", "embedding_to_padding", "(", "emb", ")", ":", "\n", "    ", "\"\"\"Calculates the padding mask based on which embeddings are all zero.\n    We have hacked symbol_modality to return all-zero embeddings for padding.\n    Args:\n        emb: a Tensor with shape [..., depth].\n    Returns:\n        a float Tensor with shape [...].\n    \"\"\"", "\n", "emb_sum", "=", "tf", ".", "reduce_sum", "(", "tf", ".", "abs", "(", "emb", ")", ",", "axis", "=", "-", "1", ")", "\n", "return", "tf", ".", "to_float", "(", "tf", ".", "equal", "(", "emb_sum", ",", "0.0", ")", ")", "\n", "", "def", "_bucket_boundaries", "(", "max_length", ",", "min_length", "=", "8", ",", "length_bucket_step", "=", "1.1", ")", ":", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.transformer_utils._bucket_boundaries": [[110, 119], ["boundaries.append", "max", "int"], "function", ["None"], ["", "def", "_bucket_boundaries", "(", "max_length", ",", "min_length", "=", "8", ",", "length_bucket_step", "=", "1.1", ")", ":", "\n", "  ", "\"\"\"A default set of length-bucket boundaries.\"\"\"", "\n", "assert", "length_bucket_step", ">", "1.0", "\n", "x", "=", "min_length", "\n", "boundaries", "=", "[", "]", "\n", "while", "x", "<", "max_length", ":", "\n", "    ", "boundaries", ".", "append", "(", "x", ")", "\n", "x", "=", "max", "(", "x", "+", "1", ",", "int", "(", "x", "*", "length_bucket_step", ")", ")", "\n", "", "return", "boundaries", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.transformer_utils._batching_scheme": [[121, 203], ["transformer_utils._bucket_boundaries", "max", "max", "ValueError", "max", "max", "min", "range"], "function", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.transformer_utils._bucket_boundaries"], ["", "def", "_batching_scheme", "(", "batch_size", ",", "\n", "max_length", ",", "\n", "min_length_bucket", ",", "\n", "length_bucket_step", ",", "\n", "drop_long_sequences", "=", "False", ",", "\n", "shard_multiplier", "=", "1", ",", "\n", "length_multiplier", "=", "1", ",", "\n", "min_length", "=", "0", ",", "\n", "batch_relax", "=", "False", ")", ":", "\n", "  ", "\"\"\"A batching scheme based on model hyperparameters.\n  Every batch containins a number of sequences divisible by `shard_multiplier`.\n  Args:\n    batch_size: int, total number of tokens in a batch.\n    max_length: int, sequences longer than this will be skipped. Defaults to\n      batch_size.\n    min_length_bucket: int\n    length_bucket_step: float greater than 1.0\n    drop_long_sequences: bool, if True, then sequences longer than\n      `max_length` are dropped.  This prevents generating batches with\n      more than the usual number of tokens, which can cause out-of-memory\n      errors.\n    shard_multiplier: an integer increasing the batch_size to suit splitting\n      across datashards.\n    length_multiplier: an integer multiplier that is used to increase the\n      batch sizes and sequence length tolerance.\n    min_length: int, sequences shorter than this will be skipped.\n  Returns:\n     A dictionary with parameters that can be passed to input_pipeline:\n       * boundaries: list of bucket boundaries\n       * batch_sizes: list of batch sizes for each length bucket\n       * max_length: int, maximum length of an example\n  Raises:\n    ValueError: If min_length > max_length\n  \"\"\"", "\n", "max_length", "=", "max_length", "or", "batch_size", "\n", "if", "max_length", "<", "min_length", ":", "\n", "    ", "raise", "ValueError", "(", "\"max_length must be greater or equal to min_length\"", ")", "\n", "\n", "", "boundaries", "=", "_bucket_boundaries", "(", "max_length", ",", "min_length_bucket", ",", "\n", "length_bucket_step", ")", "\n", "boundaries", "=", "[", "boundary", "*", "length_multiplier", "for", "boundary", "in", "boundaries", "]", "\n", "max_length", "*=", "length_multiplier", "\n", "\n", "batch_sizes", "=", "[", "\n", "max", "(", "1", ",", "batch_size", "//", "length", ")", "for", "length", "in", "boundaries", "+", "[", "max_length", "]", "\n", "]", "\n", "max_batch_size", "=", "max", "(", "batch_sizes", ")", "\n", "# Since the Datasets API only allows a single constant for window_size,", "\n", "# and it needs divide all bucket_batch_sizes, we pick a highly-compoisite", "\n", "# window size and then round down all batch sizes to divisors of that window", "\n", "# size, so that a window can always be divided evenly into batches.", "\n", "# TODO(noam): remove this when Dataset API improves.", "\n", "highly_composite_numbers", "=", "[", "\n", "1", ",", "2", ",", "4", ",", "6", ",", "12", ",", "24", ",", "36", ",", "48", ",", "60", ",", "120", ",", "180", ",", "240", ",", "360", ",", "720", ",", "840", ",", "1260", ",", "1680", ",", "\n", "2520", ",", "5040", ",", "7560", ",", "10080", ",", "15120", ",", "20160", ",", "25200", ",", "27720", ",", "45360", ",", "50400", ",", "55440", ",", "\n", "83160", ",", "110880", ",", "166320", ",", "221760", ",", "277200", ",", "332640", ",", "498960", ",", "554400", ",", "665280", ",", "\n", "720720", ",", "1081080", ",", "1441440", ",", "2162160", ",", "2882880", ",", "3603600", ",", "4324320", ",", "6486480", ",", "\n", "7207200", ",", "8648640", ",", "10810800", ",", "14414400", ",", "17297280", ",", "21621600", ",", "32432400", ",", "\n", "36756720", ",", "43243200", ",", "61261200", ",", "73513440", ",", "110270160", "\n", "]", "\n", "window_size", "=", "max", "(", "\n", "[", "i", "for", "i", "in", "highly_composite_numbers", "if", "i", "<=", "3", "*", "max_batch_size", "]", ")", "\n", "divisors", "=", "[", "i", "for", "i", "in", "range", "(", "1", ",", "window_size", "+", "1", ")", "if", "window_size", "%", "i", "==", "0", "]", "\n", "batch_sizes", "=", "[", "max", "(", "[", "d", "for", "d", "in", "divisors", "if", "d", "<=", "bs", "]", ")", "for", "bs", "in", "batch_sizes", "]", "\n", "window_size", "*=", "shard_multiplier", "\n", "batch_sizes", "=", "[", "bs", "*", "shard_multiplier", "for", "bs", "in", "batch_sizes", "]", "\n", "# The Datasets API splits one window into multiple batches, which", "\n", "# produces runs of many consecutive batches of the same size.  This", "\n", "# is bad for training.  To solve this, we will shuffle the batches", "\n", "# using a queue which must be several times as large as the maximum", "\n", "# number of batches per window.", "\n", "max_batches_per_window", "=", "window_size", "//", "min", "(", "batch_sizes", ")", "\n", "shuffle_queue_size", "=", "max_batches_per_window", "*", "3", "\n", "\n", "ret", "=", "{", "\n", "\"boundaries\"", ":", "boundaries", ",", "\n", "\"batch_sizes\"", ":", "batch_sizes", ",", "\n", "\"min_length\"", ":", "min_length", ",", "\n", "\"max_length\"", ":", "(", "max_length", "if", "drop_long_sequences", "else", "10", "**", "9", ")", ",", "\n", "\"shuffle_queue_size\"", ":", "shuffle_queue_size", ",", "\n", "}", "\n", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.transformer_utils.smoothing_cross_entropy": [[204, 260], ["cross_entropy_fn", "tensorflow.name_scope", "hasattr", "tensorflow.cast", "tensorflow.distributions.Normal", "tf.distributions.Normal.prob", "tensorflow.transpose", "tensorflow.one_hot", "tensorflow.concat", "tensorflow.to_float", "tensorflow.to_float", "tensorflow.cast", "tensorflow.cast", "tensorflow.expand_dims", "tensorflow.range", "tensorflow.zeros_like"], "function", ["None"], ["", "def", "smoothing_cross_entropy", "(", "logits", ",", "\n", "labels", ",", "\n", "vocab_size", ",", "\n", "confidence", ",", "\n", "gaussian", "=", "False", ",", "\n", "zero_pad", "=", "True", ")", ":", "\n", "    ", "\"\"\"Cross entropy with label smoothing to limit over-confidence.\n    Args:\n        logits: Tensor of size [batch_size, ?, vocab_size]\n        labels: Tensor of size [batch_size, ?]\n        vocab_size: Tensor representing the size of the vocabulary.\n        confidence: Used to determine on and off values for label smoothing.\n            If `gaussian` is true, `confidence` is the variance to the gaussian\n            distribution.\n        gaussian: Uses a gaussian distribution for label smoothing\n        zero_pad: use 0 as the probabitlity of the padding\n            in the smoothed labels. By setting this, we replicate the\n            numeric calculation of tensor2tensor, which doesn't set the\n            <BOS> token in the vocabulary.\n    Returns:\n        the cross entropy loss.\n    \"\"\"", "\n", "with", "tf", ".", "name_scope", "(", "\"smoothing_cross_entropy\"", ",", "values", "=", "[", "logits", ",", "labels", "]", ")", ":", "\n", "# Low confidence is given to all non-true labels, uniformly.", "\n", "        ", "if", "zero_pad", ":", "\n", "            ", "low_confidence", "=", "(", "1.0", "-", "confidence", ")", "/", "tf", ".", "to_float", "(", "vocab_size", "-", "2", ")", "\n", "", "else", ":", "\n", "            ", "low_confidence", "=", "(", "1.0", "-", "confidence", ")", "/", "tf", ".", "to_float", "(", "vocab_size", "-", "1", ")", "\n", "\n", "", "if", "gaussian", "and", "confidence", ">", "0.0", ":", "\n", "            ", "labels", "=", "tf", ".", "cast", "(", "labels", ",", "tf", ".", "float32", ")", "\n", "normal_dist", "=", "tf", ".", "distributions", ".", "Normal", "(", "loc", "=", "labels", ",", "scale", "=", "confidence", ")", "\n", "soft_targets", "=", "normal_dist", ".", "prob", "(", "\n", "tf", ".", "cast", "(", "tf", ".", "range", "(", "vocab_size", ")", ",", "tf", ".", "float32", ")", "[", ":", ",", "None", ",", "None", "]", ")", "\n", "# Reordering soft_targets from [vocab_size, batch_size, ?]", "\n", "# to match logits: [batch_size, ?, vocab_size]", "\n", "soft_targets", "=", "tf", ".", "transpose", "(", "soft_targets", ",", "perm", "=", "[", "1", ",", "2", ",", "0", "]", ")", "\n", "", "else", ":", "\n", "            ", "soft_targets", "=", "tf", ".", "one_hot", "(", "\n", "tf", ".", "cast", "(", "labels", ",", "tf", ".", "int32", ")", ",", "\n", "depth", "=", "vocab_size", ",", "\n", "on_value", "=", "confidence", ",", "\n", "off_value", "=", "low_confidence", ",", "\n", "dtype", "=", "logits", ".", "dtype", ")", "\n", "", "if", "zero_pad", ":", "\n", "            ", "soft_targets", "=", "tf", ".", "concat", "(", "[", "tf", ".", "expand_dims", "(", "tf", ".", "zeros_like", "(", "labels", ",", "dtype", "=", "tf", ".", "float32", ")", ",", "2", ")", ",", "soft_targets", "[", ":", ",", ":", ",", "1", ":", "]", "]", ",", "-", "1", ")", "\n", "\n", "", "if", "hasattr", "(", "tf", ".", "nn", ",", "'softmax_cross_entropy_with_logits_v2'", ")", ":", "\n", "            ", "cross_entropy_fn", "=", "tf", ".", "nn", ".", "softmax_cross_entropy_with_logits_v2", "\n", "", "else", ":", "\n", "            ", "cross_entropy_fn", "=", "tf", ".", "nn", ".", "softmax_cross_entropy_with_logits", "\n", "", "", "return", "cross_entropy_fn", "(", "\n", "logits", "=", "logits", ",", "labels", "=", "soft_targets", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.transformer_utils.parse_segment": [[262, 290], ["tensorflow.py_func", "numpy.full_like", "numpy.full_like", "range", "range"], "function", ["None"], ["", "def", "parse_segment", "(", "lengths", ",", "masks", ")", ":", "\n", "    ", "def", "_parse_segment", "(", "lengths", ",", "masks", ")", ":", "\n", "        ", "\"\"\"\n        mask:        [[0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0],\n                      [0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0]] <- 1 is masked out\n        segment_ids: [[0, 0, 0, 1, 1, 2, 2, 2, 3, 3, 4],\n                      [0, 0, 1, 1, 1, 1, 2, 2, 3, 3, 4]] <- start from 0\n        offsets:     [[0, 1, 2, 0, 1, 0, 1, 2, 0, 1, 0],\n                      [0, 1, 0, 1, 2, 3, 0, 1, 0, 1, 0]]\n        :param masks:\n        :return: segment_ids, offsets\n        \"\"\"", "\n", "segment_ids", "=", "np", ".", "full_like", "(", "masks", ",", "0", ")", "\n", "offsets", "=", "np", ".", "full_like", "(", "masks", ",", "0", ")", "\n", "batch_size", "=", "masks", ".", "shape", "[", "0", "]", "\n", "for", "i", "in", "range", "(", "batch_size", ")", ":", "\n", "            ", "mask", "=", "masks", "[", "i", "]", "\n", "segment_ids", "[", "i", "]", "[", "0", "]", "=", "0", "\n", "for", "j", "in", "range", "(", "1", ",", "lengths", "[", "i", "]", ")", ":", "\n", "                ", "if", "mask", "[", "j", "]", "==", "mask", "[", "j", "-", "1", "]", ":", "\n", "                    ", "segment_ids", "[", "i", "]", "[", "j", "]", "=", "segment_ids", "[", "i", "]", "[", "j", "-", "1", "]", "\n", "offsets", "[", "i", "]", "[", "j", "]", "=", "offsets", "[", "i", "]", "[", "j", "-", "1", "]", "+", "1", "\n", "", "else", ":", "\n", "                    ", "segment_ids", "[", "i", "]", "[", "j", "]", "=", "segment_ids", "[", "i", "]", "[", "j", "-", "1", "]", "+", "1", "\n", "offsets", "[", "i", "]", "[", "j", "]", "=", "0", "\n", "", "", "", "return", "segment_ids", ",", "offsets", "\n", "\n", "", "return", "tf", ".", "py_func", "(", "_parse_segment", ",", "[", "lengths", ",", "masks", "]", ",", "[", "masks", ".", "dtype", ",", "masks", ".", "dtype", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.transformer_utils._pad_array_list": [[292, 303], ["numpy.amax", "enumerate", "rst.append", "numpy.array", "numpy.pad"], "function", ["None"], ["", "def", "_pad_array_list", "(", "arrays", ",", "lens", ",", "pad_id", ")", ":", "\n", "    ", "\"\"\"\n    :param ar: a list of 1-D array of different lengths, [batch_size, unfixed length]\n    :return: a 2-D array, [batch_size, max_seq_len_in_original_list]\n    \"\"\"", "\n", "rst", "=", "[", "]", "\n", "max_len", "=", "np", ".", "amax", "(", "lens", ")", "\n", "for", "idx", ",", "ar", "in", "enumerate", "(", "arrays", ")", ":", "\n", "        ", "rst", ".", "append", "(", "np", ".", "pad", "(", "ar", ",", "(", "0", ",", "max_len", "-", "lens", "[", "idx", "]", ")", ",", "\n", "'constant'", ",", "constant_values", "=", "pad_id", ")", ")", "\n", "", "return", "np", ".", "array", "(", "rst", ")", ",", "max_len", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.transformer_utils._parse_template": [[305, 337], ["inputs.tolist.tolist", "masks.tolist.tolist", "len", "zip", "transformer_utils._pad_array_list", "transformer_utils._pad_array_list", "start_pos.extend", "start_pos_.tolist", "start_pos_.tolist.append", "zip", "tmp_rst.pop", "tmp_mask.pop", "rst.append", "mask_rst.append", "template_len.append", "end_pos_.tolist", "tmp_rst.extend", "tmp_rst.append", "tmp_mask.extend", "tmp_mask.append", "len"], "function", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.transformer_utils._pad_array_list", "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.transformer_utils._pad_array_list"], ["", "def", "_parse_template", "(", "inputs", ",", "masks", ",", "start_positions", ",", "end_positions", ",", "mask_id", ",", "pad_id", ")", ":", "\n", "    ", "\"\"\"\n    :param inputs:\n    :param masks:\n    :param start_positions: [batch_size, mask_num]\n    :param end_positions:\n    :param mask_id:\n    :return:\n    \"\"\"", "\n", "inputs", "=", "inputs", ".", "tolist", "(", ")", "\n", "masks", "=", "masks", ".", "tolist", "(", ")", "\n", "l", "=", "len", "(", "inputs", "[", "0", "]", ")", "\n", "rst", ",", "mask_rst", ",", "template_len", "=", "[", "]", ",", "[", "]", ",", "[", "]", "\n", "for", "input", ",", "mask", ",", "start_pos_", ",", "end_pos_", "in", "zip", "(", "inputs", ",", "masks", ",", "start_positions", ",", "end_positions", ")", ":", "\n", "        ", "start_pos", "=", "[", "0", "]", "\n", "start_pos", ".", "extend", "(", "end_pos_", ".", "tolist", "(", ")", ")", "\n", "end_pos", "=", "start_pos_", ".", "tolist", "(", ")", "\n", "end_pos", ".", "append", "(", "l", ")", "\n", "tmp_rst", ",", "tmp_mask", "=", "[", "]", ",", "[", "]", "\n", "for", "s", ",", "e", "in", "zip", "(", "start_pos", ",", "end_pos", ")", ":", "\n", "            ", "tmp_rst", ".", "extend", "(", "input", "[", "s", ":", "e", "]", ")", "\n", "tmp_rst", ".", "append", "(", "mask_id", ")", "\n", "tmp_mask", ".", "extend", "(", "mask", "[", "s", ":", "e", "]", ")", "\n", "tmp_mask", ".", "append", "(", "1", ")", "\n", "", "tmp_rst", ".", "pop", "(", ")", "# delete the last mask_id", "\n", "tmp_mask", ".", "pop", "(", ")", "\n", "rst", ".", "append", "(", "tmp_rst", ")", "\n", "mask_rst", ".", "append", "(", "tmp_mask", ")", "\n", "template_len", ".", "append", "(", "len", "(", "tmp_rst", ")", ")", "\n", "", "rst", ",", "_", "=", "_pad_array_list", "(", "rst", ",", "template_len", ",", "pad_id", ")", "\n", "mask_rst", ",", "_", "=", "_pad_array_list", "(", "mask_rst", ",", "template_len", ",", "pad_id", ")", "\n", "return", "rst", ",", "mask_rst", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.transformer_utils._prepare_squeezed_template": [[339, 348], ["tensorflow.py_func", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.shape", "tensorflow.stack", "tensorflow.stack"], "function", ["None"], ["", "def", "_prepare_squeezed_template", "(", "inputs", ",", "masks", ",", "start_positions", ",", "end_positions", ",", "mask_id", ",", "pad_id", ")", ":", "\n", "    ", "templates", ",", "template_masks", "=", "tf", ".", "py_func", "(", "_parse_template", ",", "\n", "[", "inputs", ",", "masks", ",", "start_positions", ",", "end_positions", ",", "mask_id", ",", "pad_id", "]", ",", "\n", "[", "tf", ".", "int64", ",", "tf", ".", "int64", "]", ")", "\n", "batch_size", "=", "tf", ".", "shape", "(", "inputs", ")", "[", "0", "]", "\n", "templates", "=", "tf", ".", "reshape", "(", "templates", ",", "shape", "=", "tf", ".", "stack", "(", "[", "batch_size", ",", "-", "1", "]", ")", ")", "\n", "template_masks", "=", "tf", ".", "reshape", "(", "template_masks", ",", "shape", "=", "tf", ".", "stack", "(", "[", "batch_size", ",", "-", "1", "]", ")", ")", "\n", "return", "templates", ",", "template_masks", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.transformer_utils.generate_equal_length_mask": [[350, 424], ["tensorflow.Variable", "tensorflow.Variable", "tensorflow.Variable", "tensorflow.Variable", "tensorflow.Variable", "tensorflow.Variable", "tensorflow.Variable", "tensorflow.zeros_like", "range", "transformer_utils._prepare_squeezed_template", "range", "numpy.full_like", "range", "range", "tensorflow.ones_like", "tensorflow.py_func", "tensorflow.py_func", "answers.append", "tensorflow.transpose", "tensorflow.transpose", "numpy.random.randint", "numpy.concatenate", "numpy.concatenate", "numpy.append", "numpy.concatenate"], "function", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.transformer_utils._prepare_squeezed_template"], ["", "def", "generate_equal_length_mask", "(", "inputs", ",", "lengths", ",", "mask_num", ",", "mask_len", ",", "mask_id", ",", "eoa_id", ",", "pad_id", ")", ":", "\n", "    ", "\"\"\"\n    inputs and lengths are numpy arrays!\n    mask_num = 2, having two masked out segment\n    mask_length = 2, min length of each masked out segment\n    inputs:[[3, 5, 4, 4, 2, 1, 3, 3, 2, 5, 1],\n            [2, 1, 4, 3, 5, 1, 5, 4, 3, 1, 5]]\n    mask:  [[0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0],\n            [0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0]] <- 1 is masked out\n    \"\"\"", "\n", "def", "_parse_answer", "(", "inputs", ",", "start_pos", ",", "end_pos", ",", "eoa_id", ")", ":", "\n", "        ", "rst", "=", "None", "\n", "batch_size", "=", "inputs", ".", "shape", "[", "0", "]", "\n", "for", "i", "in", "range", "(", "batch_size", ")", ":", "\n", "            ", "tmp_answer", "=", "np", ".", "append", "(", "inputs", "[", "i", ",", "start_pos", "[", "i", "]", ":", "end_pos", "[", "i", "]", "]", ",", "eoa_id", ")", "[", "np", ".", "newaxis", ",", ":", "]", "\n", "rst", "=", "tmp_answer", "if", "rst", "is", "None", "else", "np", ".", "concatenate", "(", "(", "rst", ",", "tmp_answer", ")", ",", "axis", "=", "0", ")", "\n", "", "return", "rst", "\n", "\n", "# TODO(wanrong): OUT-OF-RANGE bound check, tf.argmin(length) >= masknum * (1 + mask_length)", "\n", "", "def", "_fill_mask", "(", "mask_not_generated", ",", "mask_length", ",", "prev_end_pos", ",", "\n", "lengths", ",", "masks", ",", "start_positions", ",", "end_positions", ")", ":", "\n", "        ", "\"\"\"\n        :param mask_not_generated: number of mask not generated(excluding this one)\n        :param prev_end_pos: open range\n        :param masks:\n        :return: after loop start_positions will be of shape [max_num, batch_size]\n        \"\"\"", "\n", "cur_start_pos", "=", "np", ".", "full_like", "(", "prev_end_pos", ",", "1", ")", "\n", "batch_size", "=", "cur_start_pos", ".", "shape", "[", "0", "]", "\n", "for", "i", "in", "range", "(", "batch_size", ")", ":", "\n", "            ", "cur_start_pos", "[", "i", "]", "=", "np", ".", "random", ".", "randint", "(", "prev_end_pos", "[", "i", "]", "+", "1", ",", "\n", "lengths", "[", "i", "]", "-", "mask_not_generated", "*", "(", "1", "+", "mask_length", ")", "+", "1", ",", "\n", "size", "=", "1", ")", "\n", "", "cur_end_pos", "=", "cur_start_pos", "+", "mask_length", "\n", "if", "start_positions", ".", "size", "==", "0", ":", "\n", "            ", "start_positions", "=", "cur_start_pos", "[", "np", ".", "newaxis", ",", ":", "]", "\n", "end_positions", "=", "cur_end_pos", "[", "np", ".", "newaxis", ",", ":", "]", "\n", "", "else", ":", "\n", "            ", "start_positions", "=", "np", ".", "concatenate", "(", "(", "start_positions", ",", "cur_start_pos", "[", "np", ".", "newaxis", ",", ":", "]", ")", ",", "axis", "=", "0", ")", "\n", "end_positions", "=", "np", ".", "concatenate", "(", "(", "end_positions", ",", "cur_end_pos", "[", "np", ".", "newaxis", ",", ":", "]", ")", ",", "axis", "=", "0", ")", "\n", "\n", "", "for", "i", "in", "range", "(", "batch_size", ")", ":", "\n", "            ", "masks", "[", "i", ",", "cur_start_pos", "[", "i", "]", ":", "cur_end_pos", "[", "i", "]", "]", "=", "1", "\n", "", "return", "mask_not_generated", "-", "1", ",", "cur_end_pos", ",", "masks", ",", "start_positions", ",", "end_positions", "\n", "\n", "", "mask_id", "=", "tf", ".", "Variable", "(", "mask_id", ",", "dtype", "=", "tf", ".", "int64", ")", "\n", "pad_id", "=", "tf", ".", "Variable", "(", "pad_id", ",", "dtype", "=", "tf", ".", "int64", ")", "\n", "eoa_id", "=", "tf", ".", "Variable", "(", "eoa_id", ",", "dtype", "=", "tf", ".", "int64", ")", "\n", "mask_not_generated", "=", "tf", ".", "Variable", "(", "mask_num", ",", "dtype", "=", "tf", ".", "int64", ")", "\n", "mask_length", "=", "tf", ".", "Variable", "(", "mask_len", ",", "dtype", "=", "tf", ".", "int64", ")", "\n", "prev_end_pos", "=", "tf", ".", "ones_like", "(", "inputs", ")", "[", ":", ",", "0", "]", "\n", "start_positions", "=", "tf", ".", "Variable", "(", "[", "]", ",", "dtype", "=", "tf", ".", "int64", ")", "\n", "end_positions", "=", "tf", ".", "Variable", "(", "[", "]", ",", "dtype", "=", "tf", ".", "int64", ")", "\n", "masks", "=", "tf", ".", "zeros_like", "(", "inputs", ")", "\n", "answers", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "mask_num", ")", ":", "\n", "        ", "mask_not_generated", ",", "prev_end_pos", ",", "masks", ",", "start_positions", ",", "end_positions", "=", "tf", ".", "py_func", "(", "_fill_mask", ",", "\n", "[", "mask_not_generated", ",", "mask_length", ",", "prev_end_pos", ",", "\n", "lengths", ",", "masks", ",", "start_positions", ",", "end_positions", "]", ",", "\n", "[", "tf", ".", "int64", ",", "tf", ".", "int64", ",", "prev_end_pos", ".", "dtype", ",", "tf", ".", "int64", ",", "\n", "tf", ".", "int64", "]", ")", "\n", "cur_answer", "=", "tf", ".", "py_func", "(", "_parse_answer", ",", "\n", "[", "inputs", ",", "prev_end_pos", "-", "mask_length", ",", "prev_end_pos", ",", "eoa_id", "]", ",", "\n", "inputs", ".", "dtype", ")", "\n", "answers", ".", "append", "(", "cur_answer", ")", "\n", "\n", "", "templates", ",", "template_masks", "=", "_prepare_squeezed_template", "(", "inputs", ",", "masks", ",", "tf", ".", "transpose", "(", "start_positions", ",", "perm", "=", "[", "1", ",", "0", "]", ")", ",", "\n", "tf", ".", "transpose", "(", "end_positions", ",", "perm", "=", "[", "1", ",", "0", "]", ")", ",", "mask_id", ",", "pad_id", ")", "\n", "return", "masks", ",", "answers", ",", "templates", ",", "template_masks", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.transformer_utils.generate_dynamic_mask": [[426, 528], ["transformer_utils.generate_equal_length_mask._fill_mask"], "function", ["None"], ["", "def", "generate_dynamic_mask", "(", "inputs", ",", "lengths", ",", "present_rate", ",", "mask_id", ",", "boa_id", ",", "\n", "eoa_id", ",", "pad_id", ",", "partition_num", ")", ":", "\n", "    ", "def", "_fill_mask", "(", "inputs", ",", "lengths", ",", "present_rate", ",", "eoa_id", ",", "pad_id", ",", "partition_num", ")", ":", "\n", "        ", "\"\"\"\n        The input batch has the same mask pattern, randoms through max_seq_length in lengths.\n        :param inputs:\n        :param lengths:\n        :param present_rate:\n        :return: answers: a tensor of shape [batch_size, sum(unfixed_answer_len for each ans)]\n        start_pos and end_pos marks out ranges for answers\n        \"\"\"", "\n", "def", "_fill_mask_py_func", "(", "inputs", ",", "lengths", ",", "present_rate", ",", "eoa_id", ",", "pad_id", ",", "partition_num", ")", ":", "\n", "# TODO(wanrong): bound check", "\n", "            ", "def", "_get_split_pos", "(", "masked_num", ")", ":", "\n", "# split masked_num into partition_num segments", "\n", "                ", "if", "masked_num", "<=", "1", ":", "\n", "                    ", "return", "[", "1", "]", "*", "(", "partition_num", "-", "1", ")", "\n", "\n", "", "splitted", "=", "np", ".", "array_split", "(", "range", "(", "masked_num", ")", ",", "partition_num", ")", "\n", "split_positions", "=", "[", "a", ".", "size", "for", "a", "in", "splitted", "]", "\n", "for", "i", "in", "range", "(", "1", ",", "partition_num", ")", ":", "\n", "                    ", "split_positions", "[", "i", "]", "+=", "split_positions", "[", "i", "-", "1", "]", "\n", "", "return", "np", ".", "insert", "(", "split_positions", ",", "0", ",", "0", ",", "axis", "=", "0", ")", "\n", "\n", "", "batch_size", "=", "inputs", ".", "shape", "[", "0", "]", "\n", "masked_nums", "=", "(", "(", "lengths", "-", "2", ")", "*", "(", "1", "-", "present_rate", ")", ")", ".", "astype", "(", "np", ".", "int64", ")", "# [batch_size]", "\n", "split_positions", "=", "[", "_get_split_pos", "(", "masked_num", ")", "for", "masked_num", "in", "masked_nums", "]", "# [batch_size, partition_num+1]", "\n", "\n", "# calculate the length of each mask segment", "\n", "mask_lengths", "=", "np", ".", "zeros", "(", "shape", "=", "(", "batch_size", ",", "partition_num", ")", ",", "dtype", "=", "np", ".", "int64", ")", "\n", "left_len", "=", "np", ".", "zeros", "(", "shape", "=", "(", "batch_size", ",", "partition_num", "+", "1", ")", ",", "dtype", "=", "np", ".", "int64", ")", "# add a -1 at the end", "\n", "for", "bid", ",", "split_position", "in", "enumerate", "(", "split_positions", ")", ":", "\n", "                ", "for", "idx", ",", "(", "prev", ",", "cur", ")", "in", "enumerate", "(", "zip", "(", "split_position", "[", ":", "-", "1", "]", ",", "split_position", "[", "1", ":", "]", ")", ")", ":", "\n", "                    ", "mask_lengths", "[", "bid", "]", "[", "idx", "]", "=", "cur", "-", "prev", "\n", "", "left_len", "[", "bid", "]", "[", "-", "1", "]", "=", "0", "# leave <EOS> unmasked", "\n", "for", "idx", ",", "cur_len", "in", "reversed", "(", "list", "(", "enumerate", "(", "mask_lengths", "[", "bid", "]", ")", ")", ")", ":", "\n", "                    ", "left_len", "[", "bid", "]", "[", "idx", "]", "=", "left_len", "[", "bid", "]", "[", "idx", "+", "1", "]", "+", "cur_len", "+", "1", "\n", "", "", "left_len", "=", "left_len", "[", ":", ",", ":", "-", "1", "]", "# remove last column", "\n", "\n", "# splitting", "\n", "start_positions", "=", "np", ".", "zeros", "(", "shape", "=", "(", "batch_size", ",", "1", ")", ")", "\n", "end_positions", "=", "np", ".", "zeros", "(", "shape", "=", "(", "batch_size", ",", "1", ")", ")", "\n", "answers", "=", "np", ".", "zeros", "(", "(", "batch_size", ",", "0", ")", ")", "\n", "partitions", "=", "np", ".", "array", "(", "[", "]", ")", "\n", "masks", "=", "np", ".", "full_like", "(", "inputs", ",", "0", ")", "\n", "after_pad_ans_lens", "=", "np", ".", "zeros", "(", "shape", "=", "partition_num", ")", "\n", "boa", "=", "np", ".", "full", "(", "shape", "=", "(", "batch_size", ",", "1", ")", ",", "fill_value", "=", "boa_id", ")", "\n", "for", "i", "in", "range", "(", "1", ",", "partition_num", "+", "1", ")", ":", "\n", "                ", "idx", "=", "i", "-", "1", "# ignore padding 0 in start/end_positions", "\n", "# get start and end position for current mask", "\n", "cur_start_pos", "=", "np", ".", "zeros", "(", "shape", "=", "(", "batch_size", ",", "1", ")", ",", "dtype", "=", "np", ".", "int64", ")", "\n", "cur_end_pos", "=", "np", ".", "zeros", "(", "shape", "=", "(", "batch_size", ",", "1", ")", ",", "dtype", "=", "np", ".", "int64", ")", "\n", "cur_answers", "=", "[", "]", "\n", "for", "bid", "in", "range", "(", "batch_size", ")", ":", "\n", "                    ", "s", "=", "end_positions", "[", "bid", "]", "[", "idx", "]", "+", "1", "\n", "e", "=", "lengths", "[", "bid", "]", "-", "left_len", "[", "bid", "]", "[", "idx", "]", "+", "1", "\n", "cur_start_pos", "[", "bid", "]", "[", "0", "]", "=", "s", "+", "(", "e", "-", "s", ")", "/", "(", "partition_num", "+", "1", ")", "\n", "cur_end_pos", "[", "bid", "]", "[", "0", "]", "=", "cur_start_pos", "[", "bid", "]", "[", "0", "]", "+", "mask_lengths", "[", "bid", "]", "[", "idx", "]", "\n", "cur_answers", ".", "append", "(", "\n", "np", ".", "append", "(", "inputs", "[", "bid", "]", "[", "cur_start_pos", "[", "bid", "]", "[", "0", "]", ":", "cur_end_pos", "[", "bid", "]", "[", "0", "]", "]", ",", "eoa_id", ")", ")", "\n", "# update mask", "\n", "for", "j", "in", "range", "(", "cur_start_pos", "[", "bid", "]", "[", "0", "]", ",", "cur_end_pos", "[", "bid", "]", "[", "0", "]", ")", ":", "\n", "                        ", "masks", "[", "bid", "]", "[", "j", "]", "=", "1", "# set masked element to 1", "\n", "", "", "start_positions", "=", "np", ".", "concatenate", "(", "(", "start_positions", ",", "cur_start_pos", ")", ",", "axis", "=", "1", ")", "\n", "end_positions", "=", "np", ".", "concatenate", "(", "(", "end_positions", ",", "cur_end_pos", ")", ",", "axis", "=", "1", ")", "\n", "\n", "# pad cur_answers to same length", "\n", "cur_padded_ans", ",", "cur_max_len", "=", "_pad_array_list", "(", "cur_answers", ",", "mask_lengths", "[", ":", ",", "idx", "]", ",", "pad_id", ")", "\n", "cur_padded_ans", "=", "np", ".", "concatenate", "(", "(", "boa", ",", "cur_padded_ans", ")", ",", "axis", "=", "1", ")", "\n", "after_pad_ans_lens", "[", "idx", "]", "=", "cur_max_len", "\n", "answers", "=", "np", ".", "concatenate", "(", "(", "answers", ",", "cur_padded_ans", ")", ",", "axis", "=", "1", ")", "\n", "\n", "# generate current partition index", "\n", "cur_idx", "=", "np", ".", "full_like", "(", "cur_padded_ans", "[", "0", "]", ",", "idx", ")", "\n", "partitions", "=", "np", ".", "concatenate", "(", "(", "partitions", ",", "cur_idx", ")", ",", "axis", "=", "0", ")", "\n", "\n", "", "return", "masks", ",", "start_positions", "[", ":", ",", "1", ":", "]", ".", "astype", "(", "np", ".", "int64", ")", ",", "end_positions", "[", ":", ",", "1", ":", "]", ".", "astype", "(", "np", ".", "int64", ")", ",", "answers", ".", "astype", "(", "np", ".", "int64", ")", ",", "after_pad_ans_lens", ".", "astype", "(", "np", ".", "int64", ")", ",", "mask_lengths", ".", "astype", "(", "np", ".", "int32", ")", ",", "partitions", ".", "astype", "(", "np", ".", "int32", ")", "\n", "\n", "", "eoa_id", "=", "tf", ".", "Variable", "(", "eoa_id", ",", "dtype", "=", "tf", ".", "int64", ")", "\n", "present_rate", "=", "tf", ".", "Variable", "(", "present_rate", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "partition_num", "=", "tf", ".", "Variable", "(", "partition_num", ",", "dtype", "=", "tf", ".", "int64", ")", "\n", "return", "tf", ".", "py_func", "(", "_fill_mask_py_func", ",", "\n", "[", "inputs", ",", "lengths", ",", "present_rate", ",", "eoa_id", ",", "pad_id", ",", "partition_num", "]", ",", "\n", "[", "tf", ".", "int64", ",", "tf", ".", "int64", ",", "tf", ".", "int64", ",", "tf", ".", "int64", ",", "tf", ".", "int64", ",", "tf", ".", "int32", ",", "tf", ".", "int32", "]", ")", "\n", "\n", "", "masks", ",", "start_positions", ",", "end_positions", ",", "answers", ",", "after_pad_ans_lens", ",", "true_ans_lens", ",", "partitions", "=", "_fill_mask", "(", "inputs", ",", "lengths", ",", "present_rate", ",", "eoa_id", ",", "pad_id", ",", "partition_num", ")", "\n", "answers", "=", "tf", ".", "dynamic_partition", "(", "data", "=", "tf", ".", "transpose", "(", "answers", ",", "perm", "=", "[", "1", ",", "0", "]", ")", ",", "# [sum(lens), batch_size]", "\n", "partitions", "=", "partitions", ",", "\n", "num_partitions", "=", "partition_num", ")", "\n", "answers", "=", "[", "tf", ".", "transpose", "(", "ans", ",", "perm", "=", "[", "1", ",", "0", "]", ")", "for", "ans", "in", "answers", "]", "\n", "mask_id", "=", "tf", ".", "Variable", "(", "mask_id", ",", "dtype", "=", "tf", ".", "int64", ")", "\n", "pad_id", "=", "tf", ".", "Variable", "(", "pad_id", ",", "dtype", "=", "tf", ".", "int64", ")", "\n", "templates", ",", "template_masks", "=", "_prepare_squeezed_template", "(", "inputs", ",", "masks", ",", "start_positions", ",", "end_positions", ",", "mask_id", ",", "pad_id", ")", "\n", "\n", "return", "masks", ",", "answers", ",", "after_pad_ans_lens", ",", "true_ans_lens", ",", "templates", ",", "template_masks", ",", "start_positions", ",", "end_positions", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.transformer_utils.generate_prediction_offsets": [[530, 536], ["tensorflow.cast", "transformer_utils.parse_segment", "tensorflow.cast", "tensorflow.shape", "tensorflow.fill", "tensorflow.fill"], "function", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.transformer_utils.parse_segment"], ["", "def", "generate_prediction_offsets", "(", "inputs", ",", "max_length", ")", ":", "\n", "    ", "batch_size", "=", "tf", ".", "shape", "(", "inputs", ")", "[", "0", "]", "\n", "max_length", "=", "tf", ".", "cast", "(", "max_length", ",", "dtype", "=", "tf", ".", "int32", ")", "\n", "_", ",", "offsets", "=", "parse_segment", "(", "tf", ".", "fill", "(", "[", "batch_size", "]", ",", "max_length", ")", ",", "\n", "tf", ".", "fill", "(", "[", "batch_size", ",", "max_length", "]", ",", "0", ")", ")", "\n", "return", "tf", ".", "cast", "(", "offsets", ",", "dtype", "=", "tf", ".", "int64", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.transformer_utils.generate_prediction_segment_ids": [[538, 541], ["tensorflow.cast", "tensorflow.shape", "tensorflow.fill", "tensorflow.cast"], "function", ["None"], ["", "def", "generate_prediction_segment_ids", "(", "inputs", ",", "segment_id", ",", "max_length", ")", ":", "\n", "    ", "batch_size", "=", "tf", ".", "shape", "(", "inputs", ")", "[", "0", "]", "\n", "return", "tf", ".", "cast", "(", "tf", ".", "fill", "(", "[", "batch_size", ",", "tf", ".", "cast", "(", "max_length", ",", "dtype", "=", "tf", ".", "int32", ")", "]", ",", "segment_id", ")", ",", "dtype", "=", "tf", ".", "int64", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.transformer_utils._get_start_end_pos": [[543, 560], ["tensorflow.Variable", "tensorflow.py_func", "enumerate", "enumerate", "[].astype", "[].astype", "range", "range", "end_pos[].append", "len", "len", "end_pos[].pop", "start_pos[].append", "numpy.array", "numpy.array"], "function", ["None"], ["", "def", "_get_start_end_pos", "(", "mask_by_word", ",", "mask_id", ")", ":", "\n", "    ", "def", "_get_start_end_pos_py_func", "(", "mask_by_word", ",", "mask_id", ")", ":", "\n", "        ", "start_pos", ",", "end_pos", "=", "[", "[", "-", "2", "]", "for", "i", "in", "range", "(", "len", "(", "mask_by_word", ")", ")", "]", ",", "[", "[", "-", "2", "]", "for", "i", "in", "range", "(", "len", "(", "mask_by_word", ")", ")", "]", "\n", "for", "idx", ",", "template", "in", "enumerate", "(", "mask_by_word", ")", ":", "\n", "            ", "for", "i", ",", "word", "in", "enumerate", "(", "template", ")", ":", "\n", "                ", "if", "word", "==", "mask_id", ":", "\n", "                    ", "if", "end_pos", "[", "idx", "]", "[", "-", "1", "]", "==", "i", ":", "\n", "                        ", "end_pos", "[", "idx", "]", ".", "pop", "(", ")", "\n", "", "else", ":", "\n", "                        ", "start_pos", "[", "idx", "]", ".", "append", "(", "i", ")", "\n", "", "end_pos", "[", "idx", "]", ".", "append", "(", "i", "+", "1", ")", "\n", "", "", "", "return", "np", ".", "array", "(", "start_pos", ")", "[", ":", ",", "1", ":", "]", ".", "astype", "(", "np", ".", "int64", ")", ",", "np", ".", "array", "(", "end_pos", ")", "[", ":", ",", "1", ":", "]", ".", "astype", "(", "np", ".", "int64", ")", "\n", "\n", "", "mask_id", "=", "tf", ".", "Variable", "(", "mask_id", ",", "dtype", "=", "tf", ".", "int64", ")", "\n", "return", "tf", ".", "py_func", "(", "_get_start_end_pos_py_func", ",", "\n", "[", "mask_by_word", ",", "mask_id", "]", ",", "\n", "[", "tf", ".", "int64", ",", "tf", ".", "int64", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.transformer_utils.prepare_template": [[562, 616], ["transformer_utils.generate_dynamic_mask", "tensorflow.fill", "transformer_utils.parse_segment", "tensorflow.cast", "tensorflow.where", "enumerate", "tensorflow.shape", "tensorflow.fill", "tensorflow.equal", "transformer_utils.generate_prediction_segment_ids", "transformer_utils.generate_prediction_offsets", "tensorflow.reshape", "tensorflow.reshape", "answer_packs.append", "tensorflow.shape", "tensorflow.shape", "tensorflow.ones_like", "tensorflow.stack", "tensorflow.stack"], "function", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.transformer_utils.generate_dynamic_mask", "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.transformer_utils.parse_segment", "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.transformer_utils.generate_prediction_segment_ids", "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.transformer_utils.generate_prediction_offsets"], ["", "def", "prepare_template", "(", "data_batch", ",", "args", ",", "mask_id", ",", "boa_id", ",", "eoa_id", ",", "pad_id", ")", ":", "\n", "    ", "\"\"\"\n    mask_id = 7\n    pad_id = 6\n    inputs:        [[3, 5, 4, 4, 2, 1, 3, 3, 2, 5, 1], [2, 1, 4, 3, 5, 1, 5, 4, 3, 1, 5]] <- a tensor\n    mask:          [[0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0], [0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0]] <- 1 is masked out\n    masked_inputs: [[3, 5, 4, 7, 7, 1, 3, 3, 7, 7, 1], [2, 1, 4, 3, 7, 7, 5, 4, 7, 7, 5]]\n    templates:     [[3, 5, 4, 7, 1, 3, 3, 7, 1], [2, 1, 4, 3, 7, 5, 4, 7, 5]]\n    segment_ids:   [[1, 1, 1, 2, 3, 3, 3, 4, 5], [1, 1, 1, 1, 2, 3, 3, 4, 5]]\n    answers:       [[[4, 2], [5, 1]],\n                    [[2, 5], [3, 1]]] <- used as decode outputs(targets) in training\n    :param masked_inputs:\n    :param mask_id:\n    :return: masked_inputs, segment_ids, answers\n    \"\"\"", "\n", "inputs", "=", "data_batch", "[", "'text_ids'", "]", "\n", "lengths", "=", "data_batch", "[", "'length'", "]", "\n", "masks", ",", "answers", ",", "after_pad_ans_lens", ",", "true_ans_lens", ",", "templates", ",", "template_masks", ",", "start_positions", ",", "end_positions", "=", "generate_dynamic_mask", "(", "inputs", ",", "lengths", ",", "args", ".", "present_rate", ",", "mask_id", ",", "boa_id", ",", "\n", "eoa_id", ",", "pad_id", ",", "args", ".", "blank_num", ")", "\n", "\n", "template_lengths", "=", "tf", ".", "fill", "(", "tf", ".", "shape", "(", "lengths", ")", ",", "tf", ".", "shape", "(", "templates", ")", "[", "1", "]", ")", "\n", "template_segment_ids", ",", "template_offsets", "=", "parse_segment", "(", "template_lengths", ",", "template_masks", ")", "\n", "all_masked_out", "=", "tf", ".", "cast", "(", "tf", ".", "fill", "(", "tf", ".", "shape", "(", "inputs", ")", ",", "mask_id", ")", ",", "dtype", "=", "tf", ".", "int64", ")", "\n", "masked_inputs", "=", "tf", ".", "where", "(", "tf", ".", "equal", "(", "masks", ",", "tf", ".", "ones_like", "(", "inputs", ")", ")", ",", "\n", "all_masked_out", ",", "inputs", ")", "\n", "template_pack", "=", "{", "\n", "'masks'", ":", "masks", ",", "\n", "'text_ids'", ":", "masked_inputs", ",", "\n", "'segment_ids'", ":", "template_segment_ids", ",", "\n", "'offsets'", ":", "template_offsets", ",", "\n", "'templates'", ":", "templates", ",", "\n", "'start_positions'", ":", "start_positions", ",", "\n", "'end_positions'", ":", "end_positions", ",", "\n", "'template_lengths'", ":", "template_lengths", "\n", "}", "\n", "\n", "answer_packs", "=", "[", "]", "\n", "for", "idx", ",", "answer", "in", "enumerate", "(", "answers", ")", ":", "\n", "        ", "mask_len", "=", "after_pad_ans_lens", "[", "idx", "]", "+", "2", "# has <eoa> and <boa>", "\n", "answer_segment_ids", "=", "generate_prediction_segment_ids", "(", "answer", ",", "idx", "*", "2", "+", "1", ",", "mask_len", ")", "\n", "answer_offsets", "=", "generate_prediction_offsets", "(", "answer", ",", "mask_len", ")", "\n", "answer", "=", "tf", ".", "reshape", "(", "answer", ",", "shape", "=", "tf", ".", "stack", "(", "[", "-", "1", ",", "mask_len", "]", ")", ")", "\n", "lengths", "=", "tf", ".", "reshape", "(", "true_ans_lens", "[", ":", ",", "idx", "]", ",", "shape", "=", "tf", ".", "stack", "(", "[", "-", "1", "]", ")", ")", "\n", "answer_packs", ".", "append", "(", "{", "\n", "'text_ids'", ":", "answer", ",", "\n", "'segment_ids'", ":", "answer_segment_ids", ",", "\n", "'offsets'", ":", "answer_offsets", ",", "\n", "'lengths'", ":", "lengths", "\n", "}", ")", "\n", "\n", "", "return", "template_pack", ",", "answer_packs", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.transformer_utils._split_template": [[618, 633], ["zip", "mask_end_positions.tolist", "mask_start_positions.tolist", "rst.append", "len"], "function", ["None"], ["", "def", "_split_template", "(", "template", ",", "mask_start_positions", ",", "mask_end_positions", ")", ":", "\n", "    ", "\"\"\"\n    template: [3, 5, 4, 7, 7, 1, 3, 3, 7, 7, 1]\n    start_positions: [3, 8], starting positions of the masks\n    end_positions: [5, 10], ending positions of the masks\n    will be split into: [[3, 5, 4], [1, 3, 3], [1]]\n    :param template: a list of numbers\n    :return:\n    \"\"\"", "\n", "rst", "=", "[", "]", "\n", "start_positions", "=", "[", "0", "]", "+", "mask_end_positions", ".", "tolist", "(", ")", "\n", "end_positions", "=", "mask_start_positions", ".", "tolist", "(", ")", "+", "[", "len", "(", "template", ")", "]", "\n", "for", "s", ",", "e", "in", "zip", "(", "start_positions", ",", "end_positions", ")", ":", "\n", "        ", "rst", ".", "append", "(", "template", "[", "s", ":", "e", "]", ")", "\n", "", "return", "rst", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.transformer_utils._merge_segments": [[635, 665], ["len", "len", "range", "rst.extend", "rst.extend", "rst.extend", "transformer_utils._merge_segments._parse"], "function", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.texar.hyperparams.HParams._parse"], ["", "def", "_merge_segments", "(", "template_segments", ",", "fillings", ",", "eoa_id", ",", "pad_id", ",", "eos_id", ")", ":", "\n", "    ", "\"\"\"\n    template_segments: [[3, 5, 4], [1, 3, 3], [1]]\n    fillings: [[4, 2], [2, 5]]\n    rst: [3, 5, 4, 4, 2, 1, 3, 3, 2, 5, 1]\n    :param template_segments:\n    :param fillings:\n    :return:\n    \"\"\"", "\n", "def", "_parse", "(", "id_list", ",", "eoa_id", ",", "pad_id", ",", "eos_id", ")", ":", "\n", "        ", "rst", "=", "[", "]", "\n", "for", "id", "in", "id_list", ":", "\n", "            ", "if", "id", "in", "[", "eoa_id", ",", "eos_id", "]", ":", "\n", "                ", "break", "\n", "", "elif", "id", "is", "not", "pad_id", ":", "\n", "                ", "rst", ".", "append", "(", "id", ")", "\n", "", "", "return", "rst", "\n", "\n", "", "template_segment_num", "=", "len", "(", "template_segments", ")", "\n", "filling_segment_num", "=", "len", "(", "fillings", ")", "\n", "assert", "template_segment_num", "==", "filling_segment_num", "or", "template_segment_num", "==", "filling_segment_num", "+", "1", "\n", "\n", "rst", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "filling_segment_num", ")", ":", "\n", "        ", "rst", ".", "extend", "(", "template_segments", "[", "i", "]", ")", "\n", "rst", ".", "extend", "(", "_parse", "(", "fillings", "[", "i", "]", ",", "eoa_id", ",", "pad_id", ",", "eos_id", ")", ")", "\n", "", "if", "template_segment_num", ">", "filling_segment_num", ":", "\n", "        ", "rst", ".", "extend", "(", "template_segments", "[", "-", "1", "]", ")", "\n", "", "return", "rst", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.transformer_utils.fill_template": [[667, 698], ["templates.tolist.tolist", "transformer_utils.fill_template._transpose"], "function", ["None"], ["", "def", "fill_template", "(", "template_pack", ",", "predictions", ",", "eoa_id", ",", "pad_id", ",", "eos_id", ")", ":", "\n", "    ", "\"\"\"\n    :param template: [batch_size, max_seq_len]\n    :param mask: [batch_size, max_seq_len]\n    :param predictions: a list of tensors\n    :return:\n    \"\"\"", "\n", "def", "_transpose", "(", "a", ")", ":", "\n", "        ", "\"\"\"\n        :param a: mask_num * batch_size * undefined_len\n        :return: batch_size * mask_num * undefined_len\n        \"\"\"", "\n", "rst", "=", "[", "]", "\n", "for", "_", "in", "a", "[", "0", "]", ":", "\n", "            ", "rst", ".", "append", "(", "[", "]", ")", "\n", "", "for", "ar", "in", "a", ":", "\n", "            ", "for", "idx", ",", "sent", "in", "enumerate", "(", "ar", ")", ":", "\n", "                ", "rst", "[", "idx", "]", ".", "append", "(", "sent", ")", "\n", "", "", "return", "rst", "\n", "\n", "", "start_positions", "=", "template_pack", "[", "'start_positions'", "]", "\n", "end_positions", "=", "template_pack", "[", "'end_positions'", "]", "\n", "templates", "=", "template_pack", "[", "'text_ids'", "]", "\n", "templates", "=", "templates", ".", "tolist", "(", ")", "\n", "predictions", "=", "[", "prediction", ".", "tolist", "(", ")", "for", "prediction", "in", "predictions", "]", "# mask_num * batch_size * undefined_len", "\n", "predictions", "=", "_transpose", "(", "predictions", ")", "\n", "rst", "=", "[", "]", "\n", "for", "template", ",", "start_pos", ",", "end_pos", ",", "fillings", "in", "zip", "(", "templates", ",", "start_positions", ",", "end_positions", ",", "predictions", ")", ":", "\n", "        ", "template_segments", "=", "_split_template", "(", "template", ",", "start_pos", ",", "end_pos", ")", "\n", "rst", ".", "append", "(", "_merge_segments", "(", "template_segments", ",", "fillings", ",", "eoa_id", ",", "pad_id", ",", "eos_id", ")", ")", "\n", "", "return", "rst", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.transformer_utils.update_template_pack": [[700, 747], ["tensorflow.Variable", "tensorflow.Variable", "transformer_utils.update_template_pack._fill_segment"], "function", ["None"], ["", "def", "update_template_pack", "(", "template_pack", ",", "filling", ",", "mask_id", ",", "eoa_id", ",", "pad_id", ")", ":", "\n", "    ", "def", "_fill_segment", "(", "masked_by_word_template", ",", "filling", ",", "start_pos", ",", "end_pos", ",", "eoa_id", ",", "pad_id", ")", ":", "\n", "        ", "def", "_fill_segment_py_func", "(", "masked_by_word_templates", ",", "fillings", ",", "start_pos", ",", "end_pos", ",", "eoa_id", ",", "pad_id", ")", ":", "\n", "            ", "masked_by_word_templates", "=", "masked_by_word_templates", ".", "tolist", "(", ")", "\n", "fillings", "=", "fillings", ".", "tolist", "(", ")", "\n", "start_pos", "=", "start_pos", ".", "tolist", "(", ")", "\n", "end_pos", "=", "end_pos", ".", "tolist", "(", ")", "\n", "rst", ",", "length", "=", "[", "]", ",", "[", "]", "\n", "for", "template", ",", "filling", ",", "s", ",", "e", "in", "zip", "(", "masked_by_word_templates", ",", "fillings", ",", "start_pos", ",", "end_pos", ")", ":", "\n", "                ", "try", ":", "\n", "                    ", "end_pos", "=", "filling", ".", "index", "(", "eoa_id", ")", "\n", "filling", "=", "filling", "[", ":", "end_pos", "]", "\n", "", "except", "ValueError", ":", "\n", "                    ", "pass", "\n", "", "cur_rst", "=", "template", "[", ":", "s", "]", "+", "filling", "+", "template", "[", "e", ":", "]", "\n", "length", ".", "append", "(", "len", "(", "cur_rst", ")", ")", "\n", "rst", ".", "append", "(", "cur_rst", ")", "\n", "", "rst", ",", "_", "=", "_pad_array_list", "(", "rst", ",", "length", ",", "pad_id", ")", "\n", "return", "rst", "\n", "", "return", "tf", ".", "py_func", "(", "_fill_segment_py_func", ",", "\n", "[", "masked_by_word_template", ",", "filling", ",", "start_pos", ",", "end_pos", ",", "eoa_id", ",", "pad_id", "]", ",", "\n", "tf", ".", "int64", ")", "\n", "\n", "", "eoa_id", "=", "tf", ".", "Variable", "(", "eoa_id", ",", "dtype", "=", "tf", ".", "int64", ")", "\n", "pad_id", "=", "tf", ".", "Variable", "(", "pad_id", ",", "dtype", "=", "tf", ".", "int64", ")", "\n", "masked_inputs", "=", "_fill_segment", "(", "template_pack", "[", "'text_ids'", "]", ",", "filling", ",", "\n", "template_pack", "[", "'start_positions'", "]", "[", ":", ",", "0", "]", ",", "\n", "template_pack", "[", "'end_positions'", "]", "[", ":", ",", "0", "]", ",", "eoa_id", ",", "pad_id", ")", "\n", "masks", "=", "tf", ".", "where", "(", "tf", ".", "equal", "(", "masked_inputs", ",", "mask_id", "*", "tf", ".", "ones_like", "(", "masked_inputs", ")", ")", ",", "\n", "tf", ".", "ones_like", "(", "masked_inputs", ")", ",", "tf", ".", "zeros_like", "(", "masked_inputs", ")", ")", "\n", "start_positions", ",", "end_positions", "=", "_get_start_end_pos", "(", "masked_inputs", ",", "mask_id", ")", "\n", "templates", ",", "template_masks", "=", "_prepare_squeezed_template", "(", "masked_inputs", ",", "masks", ",", "start_positions", ",", "end_positions", ",", "mask_id", ",", "pad_id", ")", "\n", "template_lengths", "=", "tf", ".", "fill", "(", "tf", ".", "shape", "(", "template_pack", "[", "'template_lengths'", "]", ")", ",", "tf", ".", "shape", "(", "templates", ")", "[", "1", "]", ")", "\n", "template_segment_ids", ",", "template_offsets", "=", "parse_segment", "(", "template_lengths", ",", "template_masks", ")", "\n", "return_pack", "=", "{", "\n", "'text_ids'", ":", "masked_inputs", ",", "\n", "'segment_ids'", ":", "template_segment_ids", ",", "\n", "'offsets'", ":", "template_offsets", ",", "\n", "'templates'", ":", "templates", ",", "\n", "'start_positions'", ":", "start_positions", ",", "\n", "'end_positions'", ":", "end_positions", ",", "\n", "'masks'", ":", "masks", ",", "\n", "'template_lengths'", ":", "template_lengths", "\n", "}", "\n", "return", "return_pack", "", "", ""]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.mode.maybe_global_mode": [[25, 33], ["texar.context.global_mode"], "function", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.texar.context.global_mode"], ["def", "maybe_global_mode", "(", "mode", ")", ":", "\n", "    ", "\"\"\"Returns :func:`texar.contex.global_mode` if :attr:`mode` is `None`,\n    otherwise returns :attr:`mode` as-is.\n    \"\"\"", "\n", "if", "mode", "is", "None", ":", "\n", "        ", "return", "context", ".", "global_mode", "(", ")", "\n", "", "else", ":", "\n", "        ", "return", "mode", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.mode.is_train_mode": [[34, 43], ["texar.context.global_mode_train", "tensorflow.equal"], "function", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.texar.context.global_mode_train"], ["", "", "def", "is_train_mode", "(", "mode", ")", ":", "\n", "    ", "\"\"\"Returns a bool Tensor indicating whether the global mode is TRAIN.\n    If :attr:`mode` is `None`, the mode is determined by\n    :func:`texar.contex.global_mode`.\n    \"\"\"", "\n", "if", "mode", "is", "None", ":", "\n", "        ", "return", "context", ".", "global_mode_train", "(", ")", "\n", "", "else", ":", "\n", "        ", "return", "tf", ".", "equal", "(", "mode", ",", "tf", ".", "estimator", ".", "ModeKeys", ".", "TRAIN", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.mode.is_eval_mode": [[44, 53], ["texar.context.global_mode_eval", "tensorflow.equal"], "function", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.texar.context.global_mode_eval"], ["", "", "def", "is_eval_mode", "(", "mode", ")", ":", "\n", "    ", "\"\"\"Returns a bool Tensor indicating whether the global mode is EVAL.\n    If :attr:`mode` is `None`, the mode is determined by\n    :func:`texar.contex.global_mode`.\n    \"\"\"", "\n", "if", "mode", "is", "None", ":", "\n", "        ", "return", "context", ".", "global_mode_eval", "(", ")", "\n", "", "else", ":", "\n", "        ", "return", "tf", ".", "equal", "(", "mode", ",", "tf", ".", "estimator", ".", "ModeKeys", ".", "EVAL", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.mode.is_predict_mode": [[54, 63], ["texar.context.global_mode_predict", "tensorflow.equal"], "function", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.texar.context.global_mode_predict"], ["", "", "def", "is_predict_mode", "(", "mode", ")", ":", "\n", "    ", "\"\"\"Returns a bool Tensor indicating whether the global mode is PREDICT.\n    If :attr:`mode` is `None`, the mode is determined by\n    :func:`texar.contex.global_mode`.\n    \"\"\"", "\n", "if", "mode", "is", "None", ":", "\n", "        ", "return", "context", ".", "global_mode_predict", "(", ")", "\n", "", "else", ":", "\n", "        ", "return", "tf", ".", "equal", "(", "mode", ",", "tf", ".", "estimator", ".", "ModeKeys", ".", "PREDICT", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.mode.is_train_mode_py": [[64, 82], ["texar.context.valid_modes", "ValueError"], "function", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.texar.context.valid_modes"], ["", "", "def", "is_train_mode_py", "(", "mode", ",", "default", "=", "True", ")", ":", "\n", "    ", "\"\"\"Returns a python boolean indicating whether the mode is TRAIN.\n\n    Args:\n        mode: A string taking value in\n            :tf_main:`tf.estimator.ModeKeys <estimator/ModeKeys>`.\n            Can be `None`.\n        default (bool): The return value when :attr:`mode` is `None`. Default\n            is `True`.\n\n    Returns:\n        A python boolean.\n    \"\"\"", "\n", "if", "mode", "is", "None", ":", "\n", "        ", "return", "default", "\n", "", "if", "mode", "not", "in", "context", ".", "valid_modes", "(", ")", ":", "\n", "        ", "raise", "ValueError", "(", "'Unknown mode: {}'", ".", "format", "(", "mode", ")", ")", "\n", "", "return", "mode", "==", "tf", ".", "estimator", ".", "ModeKeys", ".", "TRAIN", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.mode.is_eval_mode_py": [[83, 101], ["texar.context.valid_modes", "ValueError"], "function", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.texar.context.valid_modes"], ["", "def", "is_eval_mode_py", "(", "mode", ",", "default", "=", "False", ")", ":", "\n", "    ", "\"\"\"Returns a python boolean indicating whether the mode is EVAL.\n\n    Args:\n        mode: A string taking value in\n            :tf_main:`tf.estimator.ModeKeys <estimator/ModeKeys>`.\n            Can be `None`.\n        default (bool): The return value when :attr:`mode` is `None`. Default\n            is `False`.\n\n    Returns:\n        A python boolean.\n    \"\"\"", "\n", "if", "mode", "is", "None", ":", "\n", "        ", "return", "default", "\n", "", "if", "mode", "not", "in", "context", ".", "valid_modes", "(", ")", ":", "\n", "        ", "raise", "ValueError", "(", "'Unknown mode: {}'", ".", "format", "(", "mode", ")", ")", "\n", "", "return", "mode", "==", "tf", ".", "estimator", ".", "ModeKeys", ".", "EVAL", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.mode.is_predict_mode_py": [[102, 120], ["texar.context.valid_modes", "ValueError"], "function", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.texar.context.valid_modes"], ["", "def", "is_predict_mode_py", "(", "mode", ",", "default", "=", "False", ")", ":", "\n", "    ", "\"\"\"Returns a python boolean indicating whether the mode is PREDICT.\n\n    Args:\n        mode: A string taking value in\n            :tf_main:`tf.estimator.ModeKeys <estimator/ModeKeys>`.\n            Can be `None`.\n        default (bool): The return value when :attr:`mode` is `None`. Default\n            is `False`.\n\n    Returns:\n        A python boolean.\n    \"\"\"", "\n", "if", "mode", "is", "None", ":", "\n", "        ", "return", "default", "\n", "", "if", "mode", "not", "in", "context", ".", "valid_modes", "(", ")", ":", "\n", "        ", "raise", "ValueError", "(", "'Unknown mode: {}'", ".", "format", "(", "mode", ")", ")", "\n", "", "return", "mode", "==", "tf", ".", "estimator", ".", "ModeKeys", ".", "PREDICT", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.mode.switch_dropout": [[121, 137], ["tensorflow.to_float", "mode.is_train_mode"], "function", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.mode.is_train_mode"], ["", "def", "switch_dropout", "(", "dropout_keep_prob", ",", "mode", "=", "None", ")", ":", "\n", "    ", "\"\"\"Turns off dropout when not in training mode.\n\n    Args:\n        dropout_keep_prob: Dropout keep probability in training mode\n        mode (optional): A Tensor taking values of\n            :tf_main:`tf.estimator.ModeKeys <estimator/ModeKeys>`.\n            Dropout is activated if :attr:`mode` is `TRAIN`.\n            If `None`, the mode is inferred from\n            :func:`texar.context.global_mode`.\n\n    Returns:\n        A unit Tensor that equals the dropout keep probability in `TRAIN` mode,\n        and `1.` in other modes.\n    \"\"\"", "\n", "return", "1.", "-", "(", "1.", "-", "dropout_keep_prob", ")", "*", "tf", ".", "to_float", "(", "is_train_mode", "(", "mode", ")", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.average_recorder._SingleAverageRecorder.__init__": [[27, 36], ["collections.deque", "collections.deque", "ValueError"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "size", "=", "None", ",", "name", "=", "None", ")", ":", "\n", "        ", "if", "size", "is", "not", "None", "and", "size", "<=", "0", ":", "\n", "            ", "raise", "ValueError", "(", "\"`size` must be > 0 or `None`.\"", ")", "\n", "", "self", ".", "_size", "=", "size", "\n", "self", ".", "_q", "=", "deque", "(", "[", "]", ")", "\n", "self", ".", "_w", "=", "deque", "(", "[", "]", ")", "\n", "self", ".", "_sum", "=", "0.", "\n", "self", ".", "_w_sum", "=", "0", "\n", "self", ".", "_name", "=", "name", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.average_recorder._SingleAverageRecorder.add": [[37, 65], ["average_recorder._SingleAverageRecorder.avg", "average_recorder._SingleAverageRecorder._q.append", "average_recorder._SingleAverageRecorder._w.append", "len", "average_recorder._SingleAverageRecorder._w.popleft", "average_recorder._SingleAverageRecorder._q.popleft"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.average_recorder.AverageRecorder.avg"], ["", "def", "add", "(", "self", ",", "record", ",", "weight", "=", "None", ")", ":", "\n", "        ", "\"\"\"Appends a new record.\n\n        Args:\n            record: A scalar; the new record to append.\n            weight (optional): A scalar, weight of the new record for\n                calculating a weighted average. If `None`, weight is set to `1`.\n                For example, :attr:`weight` can be set to batch size and\n                :attr:`record` the average value of certain metric on the batch\n                in order to calculate the average metric value on a whole\n                dataset.\n\n        Returns:\n            The (moving) average after appending the record.\n        \"\"\"", "\n", "w", "=", "weight", "if", "weight", "is", "not", "None", "else", "1", "\n", "self", ".", "_w_sum", "+=", "w", "\n", "self", ".", "_sum", "+=", "record", "*", "w", "\n", "\n", "if", "self", ".", "_size", "is", "not", "None", ":", "\n", "            ", "if", "len", "(", "self", ".", "_q", ")", "==", "self", ".", "_size", ":", "\n", "                ", "w_pop", "=", "self", ".", "_w", ".", "popleft", "(", ")", "\n", "self", ".", "_sum", "-=", "self", ".", "_q", ".", "popleft", "(", ")", "*", "w_pop", "\n", "self", ".", "_w_sum", "-=", "w_pop", "\n", "", "self", ".", "_q", ".", "append", "(", "record", ")", "\n", "self", ".", "_w", ".", "append", "(", "w", ")", "\n", "\n", "", "return", "self", ".", "avg", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.average_recorder._SingleAverageRecorder.avg": [[66, 72], ["None"], "methods", ["None"], ["", "def", "avg", "(", "self", ")", ":", "\n", "        ", "\"\"\"Returns the (moving) average.\n        \"\"\"", "\n", "if", "self", ".", "_w_sum", "==", "0", ":", "\n", "            ", "return", "0.", "\n", "", "return", "self", ".", "_sum", "/", "self", ".", "_w_sum", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.average_recorder._SingleAverageRecorder.reset": [[73, 80], ["average_recorder._SingleAverageRecorder._q.clear", "average_recorder._SingleAverageRecorder._w.clear"], "methods", ["None"], ["", "def", "reset", "(", "self", ")", ":", "\n", "        ", "\"\"\"Cleans all records.\n        \"\"\"", "\n", "self", ".", "_q", ".", "clear", "(", ")", "\n", "self", ".", "_w", ".", "clear", "(", ")", "\n", "self", ".", "_sum", "=", "0.", "\n", "self", ".", "_w_sum", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.average_recorder._SingleAverageRecorder.to_str": [[81, 103], ["prec_str.format", "average_recorder._SingleAverageRecorder.avg"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.average_recorder.AverageRecorder.avg"], ["", "def", "to_str", "(", "self", ",", "precision", "=", "None", ")", ":", "\n", "        ", "\"\"\"Returns a string of the average value.\n\n        Args:\n            precision (int, optional): The number of decimal places to keep in\n                the returned string. E.g., for an average value of `0.1234`,\n                :attr:`precision = 2` leads to `'0.12'`.\n\n        Returns:\n            A string of the average value. If :meth:`name` is given, the\n            string is of the format like `'name: 0.1234'`, otherwise\n            the string is of the format like `'0.1234'`.\n        \"\"\"", "\n", "prec_str", "=", "\"{}\"", "\n", "if", "precision", "is", "not", "None", ":", "\n", "            ", "prec_str", "=", "\"{:.%df}\"", "%", "precision", "\n", "\n", "", "avg_str", "=", "prec_str", ".", "format", "(", "self", ".", "avg", "(", ")", ")", "\n", "if", "self", ".", "_name", "is", "not", "None", ":", "\n", "            ", "avg_str", "=", "\"{}: {}\"", ".", "format", "(", "self", ".", "_name", ",", "avg_str", ")", "\n", "\n", "", "return", "avg_str", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.average_recorder._SingleAverageRecorder.name": [[104, 109], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "name", "(", "self", ")", ":", "\n", "        ", "\"\"\"The name of the recorder.\n        \"\"\"", "\n", "return", "self", ".", "name", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.average_recorder.AverageRecorder.__init__": [[121, 128], ["ValueError"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "size", "=", "None", ")", ":", "\n", "        ", "if", "size", "is", "not", "None", "and", "size", "<=", "0", ":", "\n", "            ", "raise", "ValueError", "(", "\"`size` must be > 0 or `None`.\"", ")", "\n", "", "self", ".", "_size", "=", "size", "\n", "self", ".", "_recorders", "=", "None", "\n", "self", ".", "_default_metric_name", "=", "\"metric\"", "\n", "self", ".", "_record_type", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.average_recorder.AverageRecorder._to_dict": [[129, 137], ["isinstance", "isinstance", "enumerate"], "methods", ["None"], ["", "def", "_to_dict", "(", "self", ",", "record", ")", ":", "\n", "        ", "if", "isinstance", "(", "record", ",", "dict", ")", ":", "\n", "            ", "record_dict", "=", "record", "\n", "", "elif", "isinstance", "(", "record", ",", "(", "list", ",", "tuple", ")", ")", ":", "\n", "            ", "record_dict", "=", "{", "i", ":", "vi", "for", "i", ",", "vi", "in", "enumerate", "(", "record", ")", "}", "\n", "", "else", ":", "\n", "            ", "record_dict", "=", "{", "self", ".", "_default_metric_name", ":", "record", "}", "\n", "", "return", "record_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.average_recorder.AverageRecorder.add": [[138, 187], ["average_recorder.AverageRecorder._to_dict", "average_recorder.AverageRecorder.items", "average_recorder.AverageRecorder.avg", "type", "average_recorder.AverageRecorder._recorders[].add", "type", "ValueError", "average_recorder._SingleAverageRecorder", "average_recorder.AverageRecorder.keys"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.average_recorder.AverageRecorder._to_dict", "home.repos.pwc.inspect_result.VegB_Text_Infilling.texar.hyperparams.HParams.items", "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.average_recorder.AverageRecorder.avg", "home.repos.pwc.inspect_result.VegB_Text_Infilling.core.replay_memories.DequeReplayMemory.add", "home.repos.pwc.inspect_result.VegB_Text_Infilling.texar.hyperparams.HParams.keys"], ["", "def", "add", "(", "self", ",", "record", ",", "weight", "=", "None", ")", ":", "\n", "        ", "\"\"\"Appends a new record.\n\n        :attr:`record` can be a `list`, `dict`, or a single scalar. The\n        record type is determined at the first time :meth:`add` is called.\n        All subsequent calls to :meth:`add` must have the same type of\n        :attr:`record`.\n\n        :attr:`record` in subsequent calls to :meth:`add` can contain only\n        a subset of fields than the first call to :meth:`add`.\n\n        Example:\n            .. code-block:: python\n\n                recorder.add({1: v1, 2: v2}) # 1st call to `add`\n                x = recorder.add({1: v3}) # 2nd call to `add`\n                # x == {1: (v1 + v3) / 2, 2: v2}\n\n        Args:\n            record: A single scalar, a list of scalars, or a dict of scalars.\n            weight (optional): A scalar, weight of the new record for\n                calculating a weighted average. If `None`, weight is set to `1`.\n                For example, :attr:`weight` can be set to batch size and\n                :attr:`record` the average value of certain metrics on the batch\n                in order to calculate the average metric values on a whole\n                dataset.\n\n        Returns:\n            The (moving) average after appending the record, with the same\n            type as :attr:`record`.\n        \"\"\"", "\n", "if", "self", ".", "_record_type", "is", "None", ":", "\n", "            ", "self", ".", "_record_type", "=", "type", "(", "record", ")", "\n", "", "elif", "self", ".", "_record_type", "!=", "type", "(", "record", ")", ":", "\n", "            ", "raise", "ValueError", "(", "'The type of `record` is not consistent. '", "\n", "'Expect type `{}`'", ".", "format", "(", "self", ".", "_record_type", ")", ")", "\n", "\n", "", "record_dict", "=", "self", ".", "_to_dict", "(", "record", ")", "\n", "if", "self", ".", "_recorders", "is", "None", ":", "\n", "            ", "self", ".", "_recorders", "=", "{", "\n", "name", ":", "_SingleAverageRecorder", "(", "\n", "self", ".", "_size", ",", "name", "if", "self", ".", "_record_type", "==", "dict", "else", "None", ")", "\n", "for", "name", "in", "record_dict", ".", "keys", "(", ")", "\n", "}", "\n", "\n", "", "for", "name", ",", "val", "in", "record_dict", ".", "items", "(", ")", ":", "\n", "            ", "self", ".", "_recorders", "[", "name", "]", ".", "add", "(", "val", ",", "weight", "=", "weight", ")", "\n", "\n", "", "return", "self", ".", "avg", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.average_recorder.AverageRecorder.avg": [[188, 226], ["list", "isinstance", "average_recorder.AverageRecorder._recorders[].avg", "average_recorder.AverageRecorder._recorders[].avg", "avg.items", "average_recorder.AverageRecorder._record_type", "average_recorder.AverageRecorder._recorders.keys", "ret_avg.append"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.average_recorder.AverageRecorder.avg", "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.average_recorder.AverageRecorder.avg", "home.repos.pwc.inspect_result.VegB_Text_Infilling.texar.hyperparams.HParams.items", "home.repos.pwc.inspect_result.VegB_Text_Infilling.texar.hyperparams.HParams.keys"], ["", "def", "avg", "(", "self", ",", "id_or_name", "=", "None", ")", ":", "\n", "        ", "\"\"\"Returns the (moving) average.\n\n        Args:\n            id_or_name (optional): A list of or a single element.\n                Each element is the index (if the record type is `list`) or\n                name (if the record type is `dict`) of the field for which\n                the average is calculated. If not given, the average of all\n                fields are returned.\n\n        Returns:\n            The average value(s). If :attr:`id_or_name` is a single element\n            (not a list), then returns the average value of the corresponding\n            field. Otherwise, if :attr:`id_or_name` is a list of element(s),\n            then returns average value(s) in the same type as :attr:`record`\n            of :meth:`add`.\n        \"\"\"", "\n", "if", "self", ".", "_recorders", "is", "None", ":", "\n", "            ", "return", "0.", "\n", "\n", "", "keys", "=", "id_or_name", "\n", "if", "keys", "is", "None", ":", "\n", "            ", "keys", "=", "list", "(", "self", ".", "_recorders", ".", "keys", "(", ")", ")", "\n", "\n", "", "if", "not", "isinstance", "(", "keys", ",", "(", "list", ",", "tuple", ")", ")", ":", "\n", "            ", "return", "self", ".", "_recorders", "[", "keys", "]", ".", "avg", "(", ")", "\n", "\n", "", "avg", "=", "{", "key", ":", "self", ".", "_recorders", "[", "key", "]", ".", "avg", "(", ")", "for", "key", "in", "keys", "}", "\n", "if", "self", ".", "_record_type", "in", "{", "list", ",", "tuple", "}", ":", "\n", "            ", "ret_avg", "=", "[", "]", "\n", "for", "k", ",", "v", "in", "avg", ".", "items", "(", ")", ":", "\n", "                ", "if", "k", "in", "keys", ":", "\n", "                    ", "ret_avg", ".", "append", "(", "v", ")", "\n", "", "", "return", "self", ".", "_record_type", "(", "ret_avg", ")", "\n", "", "elif", "self", ".", "_record_type", "==", "dict", ":", "\n", "            ", "return", "avg", "\n", "", "else", ":", "\n", "            ", "return", "avg", "[", "self", ".", "_default_metric_name", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.average_recorder.AverageRecorder.reset": [[227, 243], ["list", "average_recorder.AverageRecorder._recorders[].reset", "average_recorder.AverageRecorder._recorders.keys", "isinstance"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.agents.episodic_agent_base.EpisodicAgentBase.reset", "home.repos.pwc.inspect_result.VegB_Text_Infilling.texar.hyperparams.HParams.keys"], ["", "", "def", "reset", "(", "self", ",", "id_or_name", "=", "None", ")", ":", "\n", "        ", "\"\"\"Resets the record.\n\n        id_or_name (optional): A list or a single element. Each element is\n            the index (if the record type is `list`) or name (if the\n            record type is `dict`) of the field to reset.\n            If `None`, all fields are reset.\n        \"\"\"", "\n", "keys", "=", "id_or_name", "\n", "if", "keys", "is", "None", ":", "\n", "            ", "keys", "=", "list", "(", "self", ".", "_recorders", ".", "keys", "(", ")", ")", "\n", "", "elif", "not", "isinstance", "(", "keys", ",", "(", "list", ",", "tuple", ")", ")", ":", "\n", "            ", "keys", "=", "[", "keys", "]", "\n", "\n", "", "for", "key", "in", "keys", ":", "\n", "            ", "self", ".", "_recorders", "[", "key", "]", ".", "reset", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.average_recorder.AverageRecorder.to_str": [[244, 278], ["delimiter.join", "rec.to_str", "range", "average_recorder.AverageRecorder._recorders.items", "len", "list.append", "list", "strs.values"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.average_recorder.AverageRecorder.to_str", "home.repos.pwc.inspect_result.VegB_Text_Infilling.texar.hyperparams.HParams.items"], ["", "", "def", "to_str", "(", "self", ",", "precision", "=", "None", ",", "delimiter", "=", "' '", ")", ":", "\n", "        ", "\"\"\"Returns a string of the average values of the records.\n\n        Args:\n            precision (int, optional): The number of decimal places to keep in\n                the returned string. E.g., for an average value of `0.1234`,\n                :attr:`precision = 2` leads to `'0.12'`.\n            delimiter (str): The delimiter string that separates between\n                fields.\n\n        Returns:\n            A string of the average values.\n\n            If record is of type `dict`, the string is a concatenation of\n            'field_name: average_value', delimited with :attr:`delimiter`.\n            E.g., `'field_name_1: 0.1234 field_name_2: 0.5678 ...'`.\n\n            Otherwise, the string is of a concatenation of 'average_value'.\n            E.g., `'0.1234 0.5678 ...'`\n        \"\"\"", "\n", "strs", "=", "{", "name", ":", "rec", ".", "to_str", "(", "precision", "=", "precision", ")", "\n", "for", "name", ",", "rec", "in", "self", ".", "_recorders", ".", "items", "(", ")", "}", "\n", "str_list", "=", "[", "]", "\n", "if", "self", ".", "_record_type", "in", "{", "list", ",", "tuple", "}", ":", "\n", "            ", "for", "i", "in", "range", "(", "len", "(", "strs", ")", ")", ":", "\n", "                ", "str_list", ".", "append", "(", "strs", "[", "i", "]", ")", "\n", "", "", "elif", "self", ".", "_record_type", "==", "dict", ":", "\n", "            ", "str_list", "=", "list", "(", "strs", ".", "values", "(", ")", ")", "\n", "", "else", ":", "\n", "            ", "str_list", "=", "[", "strs", "[", "self", ".", "_default_metric_name", "]", "]", "\n", "\n", "", "avg_str", "=", "delimiter", ".", "join", "(", "str_list", ")", "\n", "\n", "return", "avg_str", "\n", "", "", ""]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.average_recorder_test.AverageRecorderTest.test_single_average_recoder": [[18, 48], ["texar.utils.average_recorder._SingleAverageRecorder", "range", "texar.utils.average_recorder._SingleAverageRecorder", "range", "texar.utils.average_recorder._SingleAverageRecorder", "range", "average_recorder_test.AverageRecorderTest.assertEqual", "average_recorder_test.AverageRecorderTest.assertEqual", "average_recorder_test.AverageRecorderTest.assertEqual", "average_recorder_test.AverageRecorderTest.assertEqual", "max", "range", "average_recorder_test.AverageRecorderTest.assertEqual", "average_recorder_test.AverageRecorderTest.assertEqual", "texar.utils.average_recorder._SingleAverageRecorder.add", "texar.utils.average_recorder._SingleAverageRecorder.avg", "texar.utils.average_recorder._SingleAverageRecorder.add", "texar.utils.average_recorder._SingleAverageRecorder.avg", "texar.utils.average_recorder._SingleAverageRecorder.add", "average_recorder_test.AverageRecorderTest.test_single_average_recoder._cal_ground_truth"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.core.replay_memories.DequeReplayMemory.add", "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.average_recorder.AverageRecorder.avg", "home.repos.pwc.inspect_result.VegB_Text_Infilling.core.replay_memories.DequeReplayMemory.add", "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.average_recorder.AverageRecorder.avg", "home.repos.pwc.inspect_result.VegB_Text_Infilling.core.replay_memories.DequeReplayMemory.add"], ["def", "test_single_average_recoder", "(", "self", ")", ":", "\n", "        ", "\"\"\"Tests :class:`~texar.utils._SingleAverageRecorder`\n        \"\"\"", "\n", "recoder", "=", "_SingleAverageRecorder", "(", "5", ")", "\n", "for", "i", "in", "range", "(", "100", ")", ":", "\n", "            ", "self", ".", "assertEqual", "(", "recoder", ".", "add", "(", "1", ")", ",", "1.", ")", "\n", "self", ".", "assertEqual", "(", "recoder", ".", "avg", "(", ")", ",", "1.", ")", "\n", "\n", "", "recoder", "=", "_SingleAverageRecorder", "(", ")", "\n", "for", "i", "in", "range", "(", "100", ")", ":", "\n", "            ", "self", ".", "assertEqual", "(", "recoder", ".", "add", "(", "1", ")", ",", "1.", ")", "\n", "self", ".", "assertEqual", "(", "recoder", ".", "avg", "(", ")", ",", "1.", ")", "\n", "\n", "", "def", "_cal_ground_truth", "(", "n", ")", ":", "\n", "            ", "\"\"\"Calculates ((n-4)^2 + ... + n^5) / (n-4 + ... + n)\n            \"\"\"", "\n", "lb", "=", "max", "(", "n", "-", "4", ",", "0", ")", "\n", "_sum", "=", "0", "\n", "_w", "=", "0", "\n", "for", "i", "in", "range", "(", "lb", ",", "n", "+", "1", ")", ":", "\n", "                ", "_sum", "+=", "i", "*", "i", "\n", "_w", "+=", "i", "\n", "", "if", "_w", "==", "0", ":", "\n", "                ", "return", "0", "\n", "", "return", "_sum", "/", "_w", "\n", "\n", "", "recoder", "=", "_SingleAverageRecorder", "(", "5", ")", "\n", "for", "i", "in", "range", "(", "100", ")", ":", "\n", "            ", "self", ".", "assertEqual", "(", "recoder", ".", "add", "(", "i", ",", "i", ")", ",", "_cal_ground_truth", "(", "i", ")", ")", "\n", "self", ".", "assertEqual", "(", "recoder", ".", "avg", "(", ")", ",", "_cal_ground_truth", "(", "i", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.average_recorder_test.AverageRecorderTest.test_average_recorder": [[49, 69], ["texar.utils.average_recorder.AverageRecorder", "range", "texar.utils.average_recorder.AverageRecorder", "range", "average_recorder_test.AverageRecorderTest.assertEqual", "average_recorder_test.AverageRecorderTest.assertEqual", "average_recorder_test.AverageRecorderTest.assertEqual", "average_recorder_test.AverageRecorderTest.assertEqual", "average_recorder_test.AverageRecorderTest.assertEqual", "average_recorder_test.AverageRecorderTest.assertEqual", "average_recorder_test.AverageRecorderTest.assertEqual", "average_recorder_test.AverageRecorderTest.assertEqual", "average_recorder_test.AverageRecorderTest.assertEqual", "average_recorder_test.AverageRecorderTest.assertEqual", "average_recorder_test.AverageRecorderTest.assertEqual", "average_recorder_test.AverageRecorderTest.assertEqual", "texar.utils.average_recorder.AverageRecorder.add", "texar.utils.average_recorder.AverageRecorder.add", "texar.utils.average_recorder.AverageRecorder.avg", "texar.utils.average_recorder.AverageRecorder.avg", "texar.utils.average_recorder.AverageRecorder.avg", "texar.utils.average_recorder.AverageRecorder.avg", "texar.utils.average_recorder.AverageRecorder.add", "texar.utils.average_recorder.AverageRecorder.add", "texar.utils.average_recorder.AverageRecorder.avg", "texar.utils.average_recorder.AverageRecorder.avg", "texar.utils.average_recorder.AverageRecorder.avg", "texar.utils.average_recorder.AverageRecorder.avg"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.core.replay_memories.DequeReplayMemory.add", "home.repos.pwc.inspect_result.VegB_Text_Infilling.core.replay_memories.DequeReplayMemory.add", "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.average_recorder.AverageRecorder.avg", "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.average_recorder.AverageRecorder.avg", "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.average_recorder.AverageRecorder.avg", "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.average_recorder.AverageRecorder.avg", "home.repos.pwc.inspect_result.VegB_Text_Infilling.core.replay_memories.DequeReplayMemory.add", "home.repos.pwc.inspect_result.VegB_Text_Infilling.core.replay_memories.DequeReplayMemory.add", "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.average_recorder.AverageRecorder.avg", "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.average_recorder.AverageRecorder.avg", "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.average_recorder.AverageRecorder.avg", "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.average_recorder.AverageRecorder.avg"], ["", "", "def", "test_average_recorder", "(", "self", ")", ":", "\n", "        ", "\"\"\"Tests :class:`~texar.utils.AverageRecorder`\n        \"\"\"", "\n", "recorder", "=", "AverageRecorder", "(", "5", ")", "\n", "for", "i", "in", "range", "(", "100", ")", ":", "\n", "            ", "self", ".", "assertEqual", "(", "recorder", ".", "add", "(", "[", "1.", ",", "2.", "]", ")", ",", "[", "1.", ",", "2.", "]", ")", "\n", "self", ".", "assertEqual", "(", "recorder", ".", "add", "(", "[", "1.", "]", ")", ",", "[", "1.", ",", "2.", "]", ")", "\n", "self", ".", "assertEqual", "(", "recorder", ".", "avg", "(", ")", ",", "[", "1.", ",", "2.", "]", ")", "\n", "self", ".", "assertEqual", "(", "recorder", ".", "avg", "(", "0", ")", ",", "[", "1.", "]", ")", "\n", "self", ".", "assertEqual", "(", "recorder", ".", "avg", "(", "1", ")", ",", "[", "2.", "]", ")", "\n", "self", ".", "assertEqual", "(", "recorder", ".", "avg", "(", "[", "0", ",", "1", "]", ")", ",", "[", "1.", ",", "2.", "]", ")", "\n", "\n", "", "recorder", "=", "AverageRecorder", "(", ")", "\n", "for", "i", "in", "range", "(", "100", ")", ":", "\n", "            ", "self", ".", "assertEqual", "(", "recorder", ".", "add", "(", "{", "'1'", ":", "1", ",", "'2'", ":", "2", "}", ")", ",", "{", "'1'", ":", "1.", ",", "'2'", ":", "2.", "}", ")", "\n", "self", ".", "assertEqual", "(", "recorder", ".", "add", "(", "{", "'1'", ":", "1", "}", ")", ",", "{", "'1'", ":", "1.", ",", "'2'", ":", "2.", "}", ")", "\n", "self", ".", "assertEqual", "(", "recorder", ".", "avg", "(", ")", ",", "{", "'1'", ":", "1.", ",", "'2'", ":", "2.", "}", ")", "\n", "self", ".", "assertEqual", "(", "recorder", ".", "avg", "(", "'1'", ")", ",", "{", "'1'", ":", "1.", "}", ")", "\n", "self", ".", "assertEqual", "(", "recorder", ".", "avg", "(", "'2'", ")", ",", "{", "'2'", ":", "2.", "}", ")", "\n", "self", ".", "assertEqual", "(", "recorder", ".", "avg", "(", "[", "'1'", ",", "'2'", "]", ")", ",", "{", "'1'", ":", "1.", ",", "'2'", ":", "2.", "}", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.utils_io._load_config_python": [[50, 59], ["importlib.import_module", "dir", "fname.rstrip", "getattr", "key.startswith", "key.endswith"], "function", ["None"], ["def", "_load_config_python", "(", "fname", ")", ":", "\n", "    ", "config", "=", "{", "}", "\n", "\n", "config_module", "=", "importlib", ".", "import_module", "(", "fname", ".", "rstrip", "(", "'.py'", ")", ")", "\n", "for", "key", "in", "dir", "(", "config_module", ")", ":", "\n", "        ", "if", "not", "(", "key", ".", "startswith", "(", "'__'", ")", "and", "key", ".", "endswith", "(", "'__'", ")", ")", ":", "\n", "            ", "config", "[", "key", "]", "=", "getattr", "(", "config_module", ",", "key", ")", "\n", "\n", "", "", "return", "config", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.utils_io._load_config_yaml": [[60, 64], ["tensorflow.gfile.GFile", "yaml.load"], "function", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.data.vocabulary.Vocab.load"], ["", "def", "_load_config_yaml", "(", "fname", ")", ":", "\n", "    ", "with", "gfile", ".", "GFile", "(", "fname", ")", "as", "config_file", ":", "\n", "        ", "config", "=", "yaml", ".", "load", "(", "config_file", ")", "\n", "", "return", "config", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.utils_io.load_config_single": [[65, 98], ["fname.endswith", "utils_io._load_config_python", "utils_io._load_config_yaml", "_load_config_yaml.items", "isinstance", "config[].update"], "function", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.utils_io._load_config_python", "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.utils_io._load_config_yaml", "home.repos.pwc.inspect_result.VegB_Text_Infilling.texar.hyperparams.HParams.items"], ["", "def", "load_config_single", "(", "fname", ",", "config", "=", "None", ")", ":", "\n", "    ", "\"\"\"Loads config from a single file.\n\n    The config file can be either a Python file (with suffix '.py')\n    or a YAML file. If the filename is not suffixed with '.py', the file is\n    parsed as YAML.\n\n    Args:\n        fname (str): The config file name.\n        config (dict, optional): A config dict to which new configurations are\n            added. If `None`, a new config dict is created.\n\n    Returns:\n        A `dict` of configurations.\n    \"\"\"", "\n", "if", "fname", ".", "endswith", "(", "'.py'", ")", ":", "\n", "        ", "new_config", "=", "_load_config_python", "(", "fname", ")", "\n", "", "else", ":", "\n", "        ", "new_config", "=", "_load_config_yaml", "(", "fname", ")", "\n", "\n", "", "if", "config", "is", "None", ":", "\n", "        ", "config", "=", "new_config", "\n", "", "else", ":", "\n", "        ", "for", "key", ",", "value", "in", "new_config", ".", "items", "(", ")", ":", "\n", "            ", "if", "key", "in", "config", ":", "\n", "                ", "if", "isinstance", "(", "config", "[", "key", "]", ",", "dict", ")", ":", "\n", "                    ", "config", "[", "key", "]", ".", "update", "(", "value", ")", "\n", "", "else", ":", "\n", "                    ", "config", "[", "key", "]", "=", "value", "\n", "", "", "else", ":", "\n", "                ", "config", "[", "key", "]", "=", "value", "\n", "\n", "", "", "", "return", "config", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.utils_io.load_config": [[99, 134], ["isinstance", "list", "tensorflow.gfile.IsDirectory", "utils_io.load_config_single", "tensorflow.gfile.ListDirectory", "config_path.split", "os.path.join", "fname.strip.strip", "list.append", "tensorflow.gfile.IsDirectory", "list.append"], "function", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.utils_io.load_config_single"], ["", "def", "load_config", "(", "config_path", ",", "config", "=", "None", ")", ":", "\n", "    ", "\"\"\"Loads configs from (possibly multiple) file(s).\n\n    Args:\n        config_path: Paths to configuration files. This can be a `list` of\n            config file names, or a path to a directory in which all files\n            are loaded, or a string of multiple file names separated by commas.\n        config (dict, optional): A config dict to which new configurations are\n            added. If `None`, a new config dict is created.\n\n    Returns:\n        A `dict` of configurations.\n    \"\"\"", "\n", "fnames", "=", "[", "]", "\n", "if", "isinstance", "(", "config_path", ",", "(", "list", ",", "tuple", ")", ")", ":", "\n", "        ", "fnames", "=", "list", "(", "config_path", ")", "\n", "", "elif", "gfile", ".", "IsDirectory", "(", "config_path", ")", ":", "\n", "        ", "for", "fname", "in", "gfile", ".", "ListDirectory", "(", "config_path", ")", ":", "\n", "            ", "fname", "=", "os", ".", "path", ".", "join", "(", "config_path", ",", "fname", ")", "\n", "if", "not", "gfile", ".", "IsDirectory", "(", "fname", ")", ":", "\n", "                ", "fnames", ".", "append", "(", "fname", ")", "\n", "", "", "", "else", ":", "\n", "        ", "for", "fname", "in", "config_path", ".", "split", "(", "\",\"", ")", ":", "\n", "            ", "fname", "=", "fname", ".", "strip", "(", ")", "\n", "if", "not", "fname", ":", "\n", "                ", "continue", "\n", "", "fnames", ".", "append", "(", "fname", ")", "\n", "\n", "", "", "if", "config", "is", "None", ":", "\n", "        ", "config", "=", "{", "}", "\n", "\n", "", "for", "fname", "in", "fnames", ":", "\n", "        ", "config", "=", "load_config_single", "(", "fname", ",", "config", ")", "\n", "\n", "", "return", "config", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.utils_io.write_paired_text": [[135, 193], ["io.open", "fs.write", "fs.write", "io.open", "ft.write", "ft.write", "io.open", "zip", "as_text", "as_text", "f.write", "as_text", "as_text", "as_text", "f.write", "ValueError", "as_text", "as_text", "as_text"], "function", ["None"], ["", "def", "write_paired_text", "(", "src", ",", "tgt", ",", "fname", ",", "append", "=", "False", ",", "mode", "=", "'h'", ",", "sep", "=", "'\\t'", ")", ":", "\n", "    ", "\"\"\"Writes paired text to a file.\n\n    Args:\n        src: A list (or array) of `str` source text.\n        ttg: A list (or array) of `str` target text.\n        fname (str): The output filename.\n        append (bool): Whether appending to the end of the file if exists.\n        mode (str): The mode of writing, with the following options:\n\n            - :attr:`'h'`: The \"horizontal\" mode. Each source target pair is \\\n                written in one line, intervened with :attr:`sep`, e.g.,\n\n                    source_1 target_1\n                    source_2 target_2\n\n            - :attr:`'v'`: The \"vertical\" mode. Each source target pair is \\\n                written in two consecutive lines, e.g,\n\n                    source_1\n                    target_1\n                    source_2\n                    target_2\n\n            - :attr:`'s'`: The \"separate\" mode. Each source target pair is \\\n                    written in corresponding lines of two files named \\\n                    as :attr:`fname`.src and :attr:`fname`.tgt, respectively.\n        sep (str): The string intervening between source and target. Used\n            when :attr:`mode`='h'.\n\n    Returns:\n        The fileanme(s). If :attr:`mode`=='h' or :attr:`mode`=='v', returns\n        :attr:`fname`. If :attr:`mode`=='s', returns a list of filenames\n        `[':attr:`fname`.src', ':attr:`fname`.tgt']`.\n    \"\"\"", "\n", "fmode", "=", "'a'", "if", "append", "else", "'w'", "\n", "if", "mode", "==", "'s'", ":", "\n", "        ", "fn_src", "=", "'{}.src'", ".", "format", "(", "fname", ")", "\n", "fn_tgt", "=", "'{}.tgt'", ".", "format", "(", "fname", ")", "\n", "with", "open", "(", "fn_src", ",", "fmode", ",", "encoding", "=", "'utf-8'", ")", "as", "fs", ":", "\n", "            ", "fs", ".", "write", "(", "as_text", "(", "'\\n'", ".", "join", "(", "src", ")", ")", ")", "\n", "fs", ".", "write", "(", "'\\n'", ")", "\n", "", "with", "open", "(", "fn_tgt", ",", "fmode", ",", "encoding", "=", "'utf-8'", ")", "as", "ft", ":", "\n", "            ", "ft", ".", "write", "(", "as_text", "(", "'\\n'", ".", "join", "(", "tgt", ")", ")", ")", "\n", "ft", ".", "write", "(", "'\\n'", ")", "\n", "", "return", "fn_src", ",", "fn_tgt", "\n", "", "else", ":", "\n", "        ", "with", "open", "(", "fname", ",", "fmode", ",", "encoding", "=", "'utf-8'", ")", "as", "f", ":", "\n", "            ", "for", "s", ",", "t", "in", "zip", "(", "src", ",", "tgt", ")", ":", "\n", "                ", "if", "mode", "==", "'h'", ":", "\n", "                    ", "text", "=", "'{}{}{}\\n'", ".", "format", "(", "as_text", "(", "s", ")", ",", "sep", ",", "as_text", "(", "t", ")", ")", "\n", "f", ".", "write", "(", "as_text", "(", "text", ")", ")", "\n", "", "elif", "mode", "==", "'v'", ":", "\n", "                    ", "text", "=", "'{}\\n{}\\n'", ".", "format", "(", "as_text", "(", "s", ")", ",", "as_text", "(", "t", ")", ")", "\n", "f", ".", "write", "(", "as_text", "(", "text", ")", ")", "\n", "", "else", ":", "\n", "                    ", "raise", "ValueError", "(", "'Unknown mode: {}'", ".", "format", "(", "mode", ")", ")", "\n", "", "", "", "return", "fname", "\n", "", "", ""]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.utils_test.UtilsTest.test_dict_patch": [[20, 45], ["texar.utils.utils.dict_patch", "utils_test.UtilsTest.assertEqual", "utils_test.UtilsTest.assertEqual", "utils_test.UtilsTest.assertEqual"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.utils.dict_patch"], ["def", "test_dict_patch", "(", "self", ")", ":", "\n", "        ", "\"\"\"Tests :meth:`texar.utils.dict_patch`.\n        \"\"\"", "\n", "src_dict", "=", "{", "\n", "\"k1\"", ":", "\"k1\"", ",", "\n", "\"k_dict_1\"", ":", "{", "\n", "\"kd1_k1\"", ":", "\"kd1_k1\"", ",", "\n", "\"kd1_k2\"", ":", "\"kd1_k2\"", "\n", "}", ",", "\n", "\"k_dict_2\"", ":", "{", "\n", "\"kd2_k1\"", ":", "\"kd2_k1\"", "\n", "}", "\n", "}", "\n", "tgt_dict", "=", "{", "\n", "\"k1\"", ":", "\"k1_tgt\"", ",", "\n", "\"k_dict_1\"", ":", "{", "\n", "\"kd1_k1\"", ":", "\"kd1_k1\"", "\n", "}", ",", "\n", "\"k_dict_2\"", ":", "\"kd2_not_dict\"", "\n", "}", "\n", "\n", "patched_dict", "=", "utils", ".", "dict_patch", "(", "tgt_dict", ",", "src_dict", ")", "\n", "self", ".", "assertEqual", "(", "patched_dict", "[", "\"k1\"", "]", ",", "tgt_dict", "[", "\"k1\"", "]", ")", "\n", "self", ".", "assertEqual", "(", "patched_dict", "[", "\"k_dict_1\"", "]", ",", "src_dict", "[", "\"k_dict_1\"", "]", ")", "\n", "self", ".", "assertEqual", "(", "patched_dict", "[", "\"k_dict_2\"", "]", ",", "tgt_dict", "[", "\"k_dict_2\"", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.utils_test.UtilsTest.test_strip_token": [[46, 58], ["utils_test.UtilsTest.assertEqual", "utils_test.UtilsTest.assertEqual", "utils_test.UtilsTest.assertEqual", "utils_test.UtilsTest.assertEqual", "texar.utils.utils.strip_token", "texar.utils.utils.strip_token", "texar.utils.utils.strip_token", "texar.utils.utils.strip_token", "numpy.asarray"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.utils.strip_token", "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.utils.strip_token", "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.utils.strip_token", "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.utils.strip_token"], ["", "def", "test_strip_token", "(", "self", ")", ":", "\n", "        ", "\"\"\"Tests :func:`texar.utils.strip_token`\n        \"\"\"", "\n", "str_", "=", "\" <PAD>  <PAD>\\t  i am <PAD> \\t <PAD>  \\t\"", "\n", "self", ".", "assertEqual", "(", "utils", ".", "strip_token", "(", "str_", ",", "\"<PAD>\"", ")", ",", "\"i am\"", ")", "\n", "self", ".", "assertEqual", "(", "utils", ".", "strip_token", "(", "[", "str_", "]", ",", "\"<PAD>\"", ")", ",", "[", "\"i am\"", "]", ")", "\n", "self", ".", "assertEqual", "(", "\n", "utils", ".", "strip_token", "(", "np", ".", "asarray", "(", "[", "str_", "]", ")", ",", "\"<PAD>\"", ")", ",", "\n", "[", "\"i am\"", "]", ")", "\n", "self", ".", "assertEqual", "(", "\n", "utils", ".", "strip_token", "(", "[", "[", "[", "str_", "]", "]", ",", "[", "''", "]", "]", ",", "\"<PAD>\"", ")", ",", "\n", "[", "[", "[", "\"i am\"", "]", "]", ",", "[", "''", "]", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.utils_test.UtilsTest.test_str_join": [[59, 77], ["numpy.ones", "texar.utils.utils.str_join", "numpy.testing.assert_array_equal", "utils_test.UtilsTest.assertIsInstance", "texar.utils.utils.str_join", "numpy.testing.assert_array_equal", "utils_test.UtilsTest.assertIsInstance", "texar.utils.utils.str_join", "numpy.testing.assert_array_equal", "numpy.asarray", "numpy.ones.tolist"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.utils.str_join", "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.utils.str_join", "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.utils.str_join"], ["", "def", "test_str_join", "(", "self", ")", ":", "\n", "        ", "\"\"\"Tests :func:`texar.utils.str_join`\n        \"\"\"", "\n", "tokens", "=", "np", ".", "ones", "(", "[", "2", ",", "2", ",", "3", "]", ",", "dtype", "=", "'str'", ")", "\n", "\n", "str_", "=", "utils", ".", "str_join", "(", "tokens", ")", "\n", "np", ".", "testing", ".", "assert_array_equal", "(", "\n", "str_", ",", "np", ".", "asarray", "(", "[", "[", "'1 1 1'", ",", "'1 1 1'", "]", ",", "[", "'1 1 1'", ",", "'1 1 1'", "]", "]", ")", ")", "\n", "self", ".", "assertIsInstance", "(", "str_", ",", "np", ".", "ndarray", ")", "\n", "\n", "str_", "=", "utils", ".", "str_join", "(", "tokens", ".", "tolist", "(", ")", ")", "\n", "np", ".", "testing", ".", "assert_array_equal", "(", "\n", "str_", ",", "[", "[", "'1 1 1'", ",", "'1 1 1'", "]", ",", "[", "'1 1 1'", ",", "'1 1 1'", "]", "]", ")", "\n", "self", ".", "assertIsInstance", "(", "str_", ",", "list", ")", "\n", "\n", "tokens", "=", "[", "[", "]", ",", "[", "'1'", ",", "'1'", "]", "]", "\n", "str_", "=", "utils", ".", "str_join", "(", "tokens", ")", "\n", "np", ".", "testing", ".", "assert_array_equal", "(", "str_", ",", "[", "''", ",", "'1 1'", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.utils_test.UtilsTest.test_uniquify_str": [[78, 89], ["texar.utils.utils.uniquify_str", "utils_test.UtilsTest.assertEqual", "str_set.append", "str_set.append", "texar.utils.utils.uniquify_str", "utils_test.UtilsTest.assertEqual"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.utils.uniquify_str", "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.utils.uniquify_str"], ["", "def", "test_uniquify_str", "(", "self", ")", ":", "\n", "        ", "\"\"\"Tests :func:`texar.utils.uniquify_str`.\n        \"\"\"", "\n", "str_set", "=", "[", "'str'", "]", "\n", "unique_str", "=", "utils", ".", "uniquify_str", "(", "'str'", ",", "str_set", ")", "\n", "self", ".", "assertEqual", "(", "unique_str", ",", "'str_1'", ")", "\n", "\n", "str_set", ".", "append", "(", "'str_1'", ")", "\n", "str_set", ".", "append", "(", "'str_2'", ")", "\n", "unique_str", "=", "utils", ".", "uniquify_str", "(", "'str'", ",", "str_set", ")", "\n", "self", ".", "assertEqual", "(", "unique_str", ",", "'str_3'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.utils._expand_name": [[64, 71], ["None"], "function", ["None"], ["def", "_expand_name", "(", "name", ")", ":", "\n", "    ", "\"\"\"Replaces common shorthands with respective full names.\n\n        \"tf.xxx\" --> \"tensorflow.xxx\"\n        \"tx.xxx\" --> \"texar.xxx\"\n    \"\"\"", "\n", "return", "name", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.utils.check_or_get_class": [[72, 102], ["texar.utils.dtypes.is_str", "utils.get_class", "issubclass", "TypeError"], "function", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.dtypes.is_str", "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.utils.get_class"], ["", "def", "check_or_get_class", "(", "class_or_name", ",", "module_path", "=", "None", ",", "superclass", "=", "None", ")", ":", "\n", "    ", "\"\"\"Returns the class and checks if the class inherits :attr:`superclass`.\n\n    Args:\n        class_or_name: Name or full path to the class, or the class itself.\n        module_paths (list, optional): Paths to candidate modules to search\n            for the class. This is used if :attr:`class_or_name` is a string and\n            the class cannot be located solely based on :attr:`class_or_name`.\n            The first module in the list that contains the class\n            is used.\n        superclass (optional): A (list of) classes that the target class\n            must inherit.\n\n    Returns:\n        The target class.\n\n    Raises:\n        ValueError: If class is not found based on :attr:`class_or_name` and\n            :attr:`module_paths`.\n        TypeError: If class does not inherits :attr:`superclass`.\n    \"\"\"", "\n", "class_", "=", "class_or_name", "\n", "if", "is_str", "(", "class_", ")", ":", "\n", "        ", "class_", "=", "get_class", "(", "class_", ",", "module_path", ")", "\n", "", "if", "superclass", "is", "not", "None", ":", "\n", "        ", "if", "not", "issubclass", "(", "class_", ",", "superclass", ")", ":", "\n", "            ", "raise", "TypeError", "(", "\n", "\"A subclass of {} is expected. Got: {}\"", ".", "format", "(", "\n", "superclass", ",", "class_", ")", ")", "\n", "", "", "return", "class_", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.utils.get_class": [[103, 140], ["pydoc.locate", "ValueError", "pydoc.locate"], "function", ["None"], ["", "def", "get_class", "(", "class_name", ",", "module_paths", "=", "None", ")", ":", "\n", "    ", "\"\"\"Returns the class based on class name.\n\n    Args:\n        class_name (str): Name or full path to the class.\n        module_paths (list): Paths to candidate modules to search for the\n            class. This is used if the class cannot be located solely based on\n            `class_name`. The first module in the list that contains the class\n            is used.\n\n    Returns:\n        The target class.\n\n    Raises:\n        ValueError: If class is not found based on :attr:`class_name` and\n            :attr:`module_paths`.\n    \"\"\"", "\n", "class_", "=", "locate", "(", "class_name", ")", "\n", "if", "(", "class_", "is", "None", ")", "and", "(", "module_paths", "is", "not", "None", ")", ":", "\n", "        ", "for", "module_path", "in", "module_paths", ":", "\n", "#if module_path in _unimportable_modules:", "\n", "# Special treatment for unimportable modules by directly", "\n", "# accessing the class", "\n", "            ", "class_", "=", "locate", "(", "'.'", ".", "join", "(", "[", "module_path", ",", "class_name", "]", ")", ")", "\n", "if", "class_", "is", "not", "None", ":", "\n", "                ", "break", "\n", "#else:", "\n", "#    module = importlib.import_module(module_path)", "\n", "#    if class_name in dir(module):", "\n", "#        class_ = getattr(module, class_name)", "\n", "#        break", "\n", "\n", "", "", "", "if", "class_", "is", "None", ":", "\n", "        ", "raise", "ValueError", "(", "\n", "\"Class not found in {}: {}\"", ".", "format", "(", "module_paths", ",", "class_name", ")", ")", "\n", "\n", "", "return", "class_", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.utils.check_or_get_instance": [[141, 177], ["texar.utils.dtypes.is_str", "isinstance", "utils.get_instance", "isinstance", "TypeError"], "function", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.dtypes.is_str", "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.utils.get_instance"], ["", "def", "check_or_get_instance", "(", "ins_or_class_or_name", ",", "kwargs", ",", "module_paths", "=", "None", ",", "\n", "classtype", "=", "None", ")", ":", "\n", "    ", "\"\"\"Returns a class instance and checks types.\n\n    Args:\n        ins_or_class_or_name: Can be of 3 types:\n\n            - A string representing the name or full path to a class to \\\n              instantiate.\n            - The class itself to instantiate.\n            - The class instance itself to check types.\n\n        kwargs (dict): Keyword arguments for the class constructor.\n        module_paths (list, optional): Paths to candidate modules to\n            search for the class. This is used if the class cannot be\n            located solely based on :attr:`class_name`. The first module\n            in the list that contains the class is used.\n        classtype (optional): A (list of) classes of which the instance must\n            be an instantiation.\n\n    Raises:\n        ValueError: If class is not found based on :attr:`class_name` and\n            :attr:`module_paths`.\n        ValueError: If :attr:`kwargs` contains arguments that are invalid\n            for the class construction.\n        TypeError: If the instance is not an instantiation of\n            :attr:`classtype`.\n    \"\"\"", "\n", "ret", "=", "ins_or_class_or_name", "\n", "if", "is_str", "(", "ret", ")", "or", "isinstance", "(", "ret", ",", "type", ")", ":", "\n", "        ", "ret", "=", "get_instance", "(", "ret", ",", "kwargs", ",", "module_paths", ")", "\n", "", "if", "classtype", "is", "not", "None", ":", "\n", "        ", "if", "not", "isinstance", "(", "ret", ",", "classtype", ")", ":", "\n", "            ", "raise", "TypeError", "(", "\n", "\"An instance of {} is expected. Got: {}\"", ".", "format", "(", "classtype", ",", "ret", ")", ")", "\n", "", "", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.utils.get_instance": [[178, 212], ["texar.utils.dtypes.is_str", "set", "kwargs.keys", "get_class.", "utils.get_class", "inspect.getargspec", "ValueError"], "function", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.dtypes.is_str", "home.repos.pwc.inspect_result.VegB_Text_Infilling.texar.hyperparams.HParams.keys", "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.utils.get_class"], ["", "def", "get_instance", "(", "class_or_name", ",", "kwargs", ",", "module_paths", "=", "None", ")", ":", "\n", "    ", "\"\"\"Creates a class instance.\n\n    Args:\n        class_or_name: Name or full path to a class to instantiate, or the\n            class itself.\n        kwargs (dict): Keyword arguments for the class constructor.\n        module_paths (list, optional): Paths to candidate modules to\n            search for the class. This is used if the class cannot be\n            located solely based on :attr:`class_name`. The first module\n            in the list that contains the class is used.\n\n    Returns:\n        A class instance.\n\n    Raises:\n        ValueError: If class is not found based on :attr:`class_or_name` and\n            :attr:`module_paths`.\n        ValueError: If :attr:`kwargs` contains arguments that are invalid\n            for the class construction.\n    \"\"\"", "\n", "# Locate the class", "\n", "class_", "=", "class_or_name", "\n", "if", "is_str", "(", "class_", ")", ":", "\n", "        ", "class_", "=", "get_class", "(", "class_", ",", "module_paths", ")", "\n", "# Check validity of arguments", "\n", "", "class_args", "=", "set", "(", "inspect", ".", "getargspec", "(", "class_", ".", "__init__", ")", ".", "args", ")", "\n", "for", "key", "in", "kwargs", ".", "keys", "(", ")", ":", "\n", "        ", "if", "key", "not", "in", "class_args", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "\"Invalid argument for class %s.%s: %s, valid args:%s\"", "%", "\n", "(", "class_", ".", "__module__", ",", "class_", ".", "__name__", ",", "key", ",", "class_args", ")", ")", "\n", "\n", "", "", "return", "class_", "(", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.utils.check_or_get_instance_with_redundant_kwargs": [[213, 252], ["texar.utils.dtypes.is_str", "isinstance", "utils.get_instance_with_redundant_kwargs", "isinstance", "TypeError"], "function", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.dtypes.is_str", "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.utils.get_instance_with_redundant_kwargs"], ["", "def", "check_or_get_instance_with_redundant_kwargs", "(", "\n", "ins_or_class_or_name", ",", "kwargs", ",", "module_paths", "=", "None", ",", "classtype", "=", "None", ")", ":", "\n", "    ", "\"\"\"Returns a class instance and checks types.\n\n    Only those keyword arguments in :attr:`kwargs` that are included in the\n    class construction method are used.\n\n    Args:\n        ins_or_class_or_name: Can be of 3 types:\n\n            - A string representing the name or full path to a class to \\\n              instantiate.\n            - The class itself to instantiate.\n            - The class instance itself to check types.\n\n        kwargs (dict): Keyword arguments for the class constructor.\n        module_paths (list, optional): Paths to candidate modules to\n            search for the class. This is used if the class cannot be\n            located solely based on :attr:`class_name`. The first module\n            in the list that contains the class is used.\n        classtype (optional): A (list of) classes of which the instance must\n            be an instantiation.\n\n    Raises:\n        ValueError: If class is not found based on :attr:`class_name` and\n            :attr:`module_paths`.\n        ValueError: If :attr:`kwargs` contains arguments that are invalid\n            for the class construction.\n        TypeError: If the instance is not an instantiation of\n            :attr:`classtype`.\n    \"\"\"", "\n", "ret", "=", "ins_or_class_or_name", "\n", "if", "is_str", "(", "ret", ")", "or", "isinstance", "(", "ret", ",", "type", ")", ":", "\n", "        ", "ret", "=", "get_instance_with_redundant_kwargs", "(", "ret", ",", "kwargs", ",", "module_paths", ")", "\n", "", "if", "classtype", "is", "not", "None", ":", "\n", "        ", "if", "not", "isinstance", "(", "ret", ",", "classtype", ")", ":", "\n", "            ", "raise", "TypeError", "(", "\n", "\"An instance of {} is expected. Got: {}\"", ".", "format", "(", "classtype", ",", "ret", ")", ")", "\n", "", "", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.utils.get_instance_with_redundant_kwargs": [[253, 287], ["utils.get_class", "set", "kwargs.items", "get_class.", "inspect.getargspec"], "function", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.utils.get_class", "home.repos.pwc.inspect_result.VegB_Text_Infilling.texar.hyperparams.HParams.items"], ["", "def", "get_instance_with_redundant_kwargs", "(", "\n", "class_name", ",", "kwargs", ",", "module_paths", "=", "None", ")", ":", "\n", "    ", "\"\"\"Creates a class instance.\n\n    Only those keyword arguments in :attr:`kwargs` that are included in the\n    class construction method are used.\n\n    Args:\n        class_name (str): Name or full path of the class to instantiate.\n        kwargs (dict): A dictionary of arguments for the class constructor. It\n            may include invalid arguments which will be ignored.\n        module_paths (list of str): A list of paths to candidate modules to\n            search for the class. This is used if the class cannot be located\n            solely based on :attr:`class_name`. The first module in the list\n            that contains the class is used.\n\n    Returns:\n        A class instance.\n\n    Raises:\n        ValueError: If class is not found based on :attr:`class_name` and\n            :attr:`module_paths`.\n    \"\"\"", "\n", "# Locate the class", "\n", "class_", "=", "get_class", "(", "class_name", ",", "module_paths", ")", "\n", "\n", "# Select valid arguments", "\n", "selected_kwargs", "=", "{", "}", "\n", "class_args", "=", "set", "(", "inspect", ".", "getargspec", "(", "class_", ".", "__init__", ")", ".", "args", ")", "\n", "for", "key", ",", "value", "in", "kwargs", ".", "items", "(", ")", ":", "\n", "        ", "if", "key", "in", "class_args", ":", "\n", "            ", "selected_kwargs", "[", "key", "]", "=", "value", "\n", "\n", "", "", "return", "class_", "(", "**", "selected_kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.utils.get_function": [[288, 322], ["texar.utils.dtypes.is_callable", "pydoc.locate", "ValueError", "pydoc.locate"], "function", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.dtypes.is_callable"], ["", "def", "get_function", "(", "fn_or_name", ",", "module_paths", "=", "None", ")", ":", "\n", "    ", "\"\"\"Returns the function of specified name and module.\n\n    Args:\n        fn_or_name (str or callable): Name or full path to a function, or the\n            function itself.\n        module_paths (list, optional): A list of paths to candidate modules to\n            search for the function. This is used only when the function\n            cannot be located solely based on :attr:`fn_or_name`. The first\n            module in the list that contains the function is used.\n\n    Returns:\n        A function.\n    \"\"\"", "\n", "if", "is_callable", "(", "fn_or_name", ")", ":", "\n", "        ", "return", "fn_or_name", "\n", "\n", "", "fn", "=", "locate", "(", "fn_or_name", ")", "\n", "if", "(", "fn", "is", "None", ")", "and", "(", "module_paths", "is", "not", "None", ")", ":", "\n", "        ", "for", "module_path", "in", "module_paths", ":", "\n", "#if module_path in _unimportable_modules:", "\n", "            ", "fn", "=", "locate", "(", "'.'", ".", "join", "(", "[", "module_path", ",", "fn_or_name", "]", ")", ")", "\n", "if", "fn", "is", "not", "None", ":", "\n", "                ", "break", "\n", "#module = importlib.import_module(module_path)", "\n", "#if fn_name in dir(module):", "\n", "#    fn = getattr(module, fn_name)", "\n", "#    break", "\n", "\n", "", "", "", "if", "fn", "is", "None", ":", "\n", "        ", "raise", "ValueError", "(", "\n", "\"Method not found in {}: {}\"", ".", "format", "(", "module_paths", ",", "fn_or_name", ")", ")", "\n", "\n", "", "return", "fn", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.utils.call_function_with_redundant_kwargs": [[324, 351], ["kwargs.items", "fn", "set", "set", "inspect.getargspec", "inspect.getargspec"], "function", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.texar.hyperparams.HParams.items"], ["", "def", "call_function_with_redundant_kwargs", "(", "fn", ",", "kwargs", ")", ":", "\n", "    ", "\"\"\"Calls a function and returns the results.\n\n    Only those keyword arguments in :attr:`kwargs` that are included in the\n    function's argument list are used to call the function.\n\n    Args:\n        fn (function): A callable. If :attr:`fn` is not a python function,\n            :attr:`fn.__call__` is called.\n        kwargs (dict): A `dict` of arguments for the callable. It\n            may include invalid arguments which will be ignored.\n\n    Returns:\n        The returned results by calling :attr:`fn`.\n    \"\"\"", "\n", "try", ":", "\n", "        ", "fn_args", "=", "set", "(", "inspect", ".", "getargspec", "(", "fn", ")", ".", "args", ")", "\n", "", "except", "TypeError", ":", "\n", "        ", "fn_args", "=", "set", "(", "inspect", ".", "getargspec", "(", "fn", ".", "__call__", ")", ".", "args", ")", "\n", "\n", "# Select valid arguments", "\n", "", "selected_kwargs", "=", "{", "}", "\n", "for", "key", ",", "value", "in", "kwargs", ".", "items", "(", ")", ":", "\n", "        ", "if", "key", "in", "fn_args", ":", "\n", "            ", "selected_kwargs", "[", "key", "]", "=", "value", "\n", "\n", "", "", "return", "fn", "(", "**", "selected_kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.utils.get_args": [[352, 363], ["inspect.getargspec"], "function", ["None"], ["", "def", "get_args", "(", "fn", ")", ":", "\n", "    ", "\"\"\"Gets the arguments of a function.\n\n    Args:\n        fn (callable): The function to inspect.\n\n    Returns:\n        list: A list of argument names (str) of the function.\n    \"\"\"", "\n", "argspec", "=", "inspect", ".", "getargspec", "(", "fn", ")", "\n", "return", "argspec", ".", "args", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.utils.get_default_arg_values": [[364, 381], ["inspect.getargspec", "len", "dict", "zip"], "function", ["None"], ["", "def", "get_default_arg_values", "(", "fn", ")", ":", "\n", "    ", "\"\"\"Gets the arguments and respective default values of a function.\n\n    Only arguments with default values are included in the output dictionary.\n\n    Args:\n        fn (callable): The function to inspect.\n\n    Returns:\n        dict: A dictionary that maps argument names (str) to their default\n        values. The dictionary is empty if no arguments have default values.\n    \"\"\"", "\n", "argspec", "=", "inspect", ".", "getargspec", "(", "fn", ")", "\n", "if", "argspec", ".", "defaults", "is", "None", ":", "\n", "        ", "return", "{", "}", "\n", "", "num_defaults", "=", "len", "(", "argspec", ".", "defaults", ")", "\n", "return", "dict", "(", "zip", "(", "argspec", ".", "args", "[", "-", "num_defaults", ":", "]", ",", "argspec", ".", "defaults", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.utils.get_instance_kwargs": [[382, 407], ["kwargs_.update", "isinstance", "isinstance", "ValueError", "hparams.todict"], "function", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.texar.hyperparams.HParams.todict"], ["", "def", "get_instance_kwargs", "(", "kwargs", ",", "hparams", ")", ":", "\n", "    ", "\"\"\"Makes a dict of keyword arguments with the following structure:\n\n    `kwargs_ = {'hparams': dict(hparams), **kwargs}`.\n\n    This is typically used for constructing a module which takes a set of\n    arguments as well as a argument named `hparams`.\n\n    Args:\n        kwargs (dict): A dict of keyword arguments. Can be `None`.\n        hparams: A dict or an instance of :class:`~texar.HParams` Can be `None`.\n\n    Returns:\n        A `dict` that contains the keyword arguments in :attr:`kwargs`, and\n        an additional keyword argument named `hparams`.\n    \"\"\"", "\n", "if", "hparams", "is", "None", "or", "isinstance", "(", "hparams", ",", "dict", ")", ":", "\n", "        ", "kwargs_", "=", "{", "'hparams'", ":", "hparams", "}", "\n", "", "elif", "isinstance", "(", "hparams", ",", "HParams", ")", ":", "\n", "        ", "kwargs_", "=", "{", "'hparams'", ":", "hparams", ".", "todict", "(", ")", "}", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "\n", "'`hparams` must be a dict, an instance of HParams, or a `None`.'", ")", "\n", "", "kwargs_", ".", "update", "(", "kwargs", "or", "{", "}", ")", "\n", "return", "kwargs_", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.utils.dict_patch": [[408, 431], ["src_dict.items", "copy.deepcopy", "isinstance", "isinstance", "utils.dict_patch"], "function", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.texar.hyperparams.HParams.items", "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.utils.dict_patch"], ["", "def", "dict_patch", "(", "tgt_dict", ",", "src_dict", ")", ":", "\n", "    ", "\"\"\"Recursively patch :attr:`tgt_dict` by adding items from :attr:`src_dict`\n    that do not exist in :attr:`tgt_dict`.\n\n    If respective items in :attr:`src_dict` and :attr:`tgt_dict` are both\n    `dict`, the :attr:`tgt_dict` item is patched recursively.\n\n    Args:\n        tgt_dict (dict): Target dictionary to patch.\n        src_dict (dict): Source dictionary.\n\n    Return:\n        dict: The new :attr:`tgt_dict` that is patched.\n    \"\"\"", "\n", "if", "src_dict", "is", "None", ":", "\n", "        ", "return", "tgt_dict", "\n", "\n", "", "for", "key", ",", "value", "in", "src_dict", ".", "items", "(", ")", ":", "\n", "        ", "if", "key", "not", "in", "tgt_dict", ":", "\n", "            ", "tgt_dict", "[", "key", "]", "=", "copy", ".", "deepcopy", "(", "value", ")", "\n", "", "elif", "isinstance", "(", "value", ",", "dict", ")", "and", "isinstance", "(", "tgt_dict", "[", "key", "]", ",", "dict", ")", ":", "\n", "            ", "tgt_dict", "[", "key", "]", "=", "dict_patch", "(", "tgt_dict", "[", "key", "]", ",", "value", ")", "\n", "", "", "return", "tgt_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.utils.dict_lookup": [[432, 451], ["numpy.vectorize", "dict_.get"], "function", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.core.replay_memories.DequeReplayMemory.get"], ["", "def", "dict_lookup", "(", "dict_", ",", "keys", ",", "default", "=", "None", ")", ":", "\n", "    ", "\"\"\"Looks up :attr:`keys` in the dict, outputs the corresponding values.\n\n    The :attr:`default` is used for keys not present in the dict.\n\n    Args:\n        dict_ (dict): A dictionary for lookup.\n        keys: A numpy array or a (possibly nested) list of keys.\n        default (optional): Value to be returned when a key is not in\n            :attr:`dict_`. Error is raised if :attr:`default` is not given and\n            key is not in the dict.\n\n    Returns:\n        A numpy array of values with the same structure as :attr:`keys`.\n\n    Raises:\n        TypeError: If key is not in :attr:`dict_` and :attr:`default` is `None`.\n    \"\"\"", "\n", "return", "np", ".", "vectorize", "(", "lambda", "x", ":", "dict_", ".", "get", "(", "x", ",", "default", ")", ")", "(", "keys", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.utils.dict_fetch": [[452, 479], ["isinstance", "isinstance", "list", "isinstance", "tgt_dict_or_keys.keys.todict", "tgt_dict_or_keys.keys.keys", "src_dict.todict.todict"], "function", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.texar.hyperparams.HParams.todict", "home.repos.pwc.inspect_result.VegB_Text_Infilling.texar.hyperparams.HParams.keys", "home.repos.pwc.inspect_result.VegB_Text_Infilling.texar.hyperparams.HParams.todict"], ["", "def", "dict_fetch", "(", "src_dict", ",", "tgt_dict_or_keys", ")", ":", "\n", "    ", "\"\"\"Fetches a sub dict of :attr:`src_dict` with the keys in\n    :attr:`tgt_dict_or_keys`.\n\n    Args:\n        src_dict: A dict or instance of :class:`texar.HParams`.\n            The source dict to fetch values from.\n        tgt_dict_or_keys: A dict, instance of :class:`texar.HParams`,\n            or a list (or a dict_keys) of keys to be included in the output\n            dict.\n\n    Returns:\n        A new dict that is a subdict of :attr:`src_dict`.\n    \"\"\"", "\n", "if", "src_dict", "is", "None", ":", "\n", "        ", "return", "src_dict", "\n", "\n", "", "if", "isinstance", "(", "tgt_dict_or_keys", ",", "HParams", ")", ":", "\n", "        ", "tgt_dict_or_keys", "=", "tgt_dict_or_keys", ".", "todict", "(", ")", "\n", "", "if", "isinstance", "(", "tgt_dict_or_keys", ",", "dict", ")", ":", "\n", "        ", "tgt_dict_or_keys", "=", "tgt_dict_or_keys", ".", "keys", "(", ")", "\n", "", "keys", "=", "list", "(", "tgt_dict_or_keys", ")", "\n", "\n", "if", "isinstance", "(", "src_dict", ",", "HParams", ")", ":", "\n", "        ", "src_dict", "=", "src_dict", ".", "todict", "(", ")", "\n", "\n", "", "return", "{", "k", ":", "src_dict", "[", "k", "]", "for", "k", "in", "keys", "if", "k", "in", "src_dict", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.utils.dict_pop": [[480, 497], ["isinstance", "dict_.pop"], "function", ["None"], ["", "def", "dict_pop", "(", "dict_", ",", "pop_keys", ",", "default", "=", "None", ")", ":", "\n", "    ", "\"\"\"Removes keys from a dict and returns their values.\n\n    Args:\n        dict_ (dict): A dictionary from which items are removed.\n        pop_keys: A key or a list of keys to remove and return respective\n            values or :attr:`default`.\n        default (optional): Value to be returned when a key is not in\n            :attr:`dict_`. The default value is `None`.\n\n    Returns:\n        A `dict` of the items removed from :attr:`dict_`.\n    \"\"\"", "\n", "if", "not", "isinstance", "(", "pop_keys", ",", "(", "list", ",", "tuple", ")", ")", ":", "\n", "        ", "pop_keys", "=", "[", "pop_keys", "]", "\n", "", "ret_dict", "=", "{", "key", ":", "dict_", ".", "pop", "(", "key", ",", "default", ")", "for", "key", "in", "pop_keys", "}", "\n", "return", "ret_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.utils.flatten_dict": [[498, 526], ["dict_.items", "dict", "isinstance", "items.extend", "flatten_dict().items", "isinstance", "hasattr", "collections.OrderedDict", "items.extend", "items.append", "zip", "flatten_dict().items", "utils.flatten_dict", "utils.flatten_dict"], "function", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.texar.hyperparams.HParams.items", "home.repos.pwc.inspect_result.VegB_Text_Infilling.texar.hyperparams.HParams.items", "home.repos.pwc.inspect_result.VegB_Text_Infilling.texar.hyperparams.HParams.items", "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.utils.flatten_dict", "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.utils.flatten_dict"], ["", "def", "flatten_dict", "(", "dict_", ",", "parent_key", "=", "\"\"", ",", "sep", "=", "\".\"", ")", ":", "\n", "    ", "\"\"\"Flattens a nested dictionary. Namedtuples within the dictionary are\n    converted to dicts.\n\n    Adapted from:\n    https://github.com/google/seq2seq/blob/master/seq2seq/models/model_base.py\n\n    Args:\n        dict_ (dict): The dictionary to flatten.\n        parent_key (str): A prefix to prepend to each key.\n        sep (str): Separator that intervenes between parent and child keys.\n            E.g., if :attr:`sep``='.'`, then { \"a\": { \"b\": 3 } } is converted\n            into { \"a.b\": 3 }.\n\n    Returns:\n        A new flattened `dict`.\n    \"\"\"", "\n", "items", "=", "[", "]", "\n", "for", "key", ",", "value", "in", "dict_", ".", "items", "(", ")", ":", "\n", "        ", "key_", "=", "parent_key", "+", "sep", "+", "key", "if", "parent_key", "else", "key", "\n", "if", "isinstance", "(", "value", ",", "collections", ".", "MutableMapping", ")", ":", "\n", "            ", "items", ".", "extend", "(", "flatten_dict", "(", "value", ",", "key_", ",", "sep", "=", "sep", ")", ".", "items", "(", ")", ")", "\n", "", "elif", "isinstance", "(", "value", ",", "tuple", ")", "and", "hasattr", "(", "value", ",", "\"_asdict\"", ")", ":", "\n", "            ", "dict_items", "=", "collections", ".", "OrderedDict", "(", "zip", "(", "value", ".", "_fields", ",", "value", ")", ")", "\n", "items", ".", "extend", "(", "flatten_dict", "(", "dict_items", ",", "key_", ",", "sep", "=", "sep", ")", ".", "items", "(", ")", ")", "\n", "", "else", ":", "\n", "            ", "items", ".", "append", "(", "(", "key_", ",", "value", ")", ")", "\n", "", "", "return", "dict", "(", "items", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.utils.default_str": [[527, 542], ["None"], "function", ["None"], ["", "def", "default_str", "(", "str_", ",", "default_str", ")", ":", "\n", "    ", "\"\"\"Returns :attr:`str_` if it is not `None` or empty, otherwise returns\n    :attr:`default_str`.\n\n    Args:\n        str_: A string.\n        default_str: A string.\n\n    Returns:\n        Either :attr:`str_` or :attr:`default_str`.\n    \"\"\"", "\n", "if", "str_", "is", "not", "None", "and", "str_", "!=", "\"\"", ":", "\n", "        ", "return", "str_", "\n", "", "else", ":", "\n", "        ", "return", "default_str", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.utils.uniquify_str": [[543, 567], ["ValueError", "range", "len"], "function", ["None"], ["", "", "def", "uniquify_str", "(", "str_", ",", "str_set", ")", ":", "\n", "    ", "\"\"\"Uniquifies :attr:`str_` if :attr:`str_` is included in :attr:`str_set`.\n\n    This is done by appending '_[digits]' to :attr:`str_`. Returns\n    :attr:`str_` directly if :attr:`str_` is not included in :attr:`str_set`.\n\n    Args:\n        str_ (string): A string to uniquify.\n        str_set (set, dict, or list): A collection of strings. The returned\n            string is guaranteed to be different from the elements in the\n            collection.\n\n    Returns:\n        string: The uniquified string. Returns :attr:`str_` directly if it is\n            already unique.\n    \"\"\"", "\n", "if", "str_", "not", "in", "str_set", ":", "\n", "        ", "return", "str_", "\n", "", "else", ":", "\n", "        ", "for", "i", "in", "range", "(", "1", ",", "len", "(", "str_set", ")", "+", "1", ")", ":", "\n", "            ", "unique_str", "=", "str_", "+", "\"_%d\"", "%", "i", "\n", "if", "unique_str", "not", "in", "str_set", ":", "\n", "                ", "return", "unique_str", "\n", "", "", "", "raise", "ValueError", "(", "\"Fails to uniquify string: \"", "+", "str_", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.utils.strip_token": [[568, 603], ["utils.strip_token._recur_strip"], "function", ["None"], ["", "def", "strip_token", "(", "str_", ",", "token", ",", "compat", "=", "True", ")", ":", "\n", "    ", "\"\"\"Returns a copy of the strings with leading and trailing tokens\n    removed.\n\n    Assumes tokens in the strings are separated with the space character.\n\n    Args:\n        str_: A `str`, or an `n`-D numpy array or (possibly nested)\n            list of `str`.\n        token (str): The token to strip, e.g., the '<PAD>' token defined in\n            :class:`~texar.data.vocabulary.SpecialTokens`.PAD\n        compat (bool): Whether to convert tokens into `unicode` (Python 2)\n            or `str` (Python 3).\n\n    Returns:\n        The stripped strings of the same structure/shape as :attr:`str_`.\n    \"\"\"", "\n", "def", "_recur_strip", "(", "s", ")", ":", "\n", "        ", "if", "is_str", "(", "s", ")", ":", "\n", "            ", "return", "' '", ".", "join", "(", "s", ".", "strip", "(", ")", ".", "split", "(", ")", ")", ".", "replace", "(", "' '", "+", "token", ",", "''", ")", ".", "replace", "(", "token", "+", "' '", ",", "''", ")", "\n", "", "else", ":", "\n", "            ", "s_", "=", "[", "_recur_strip", "(", "si", ")", "for", "si", "in", "s", "]", "\n", "return", "_maybe_list_to_array", "(", "s_", ",", "s", ")", "\n", "\n", "", "", "if", "compat", ":", "\n", "        ", "str_", "=", "compat_as_text", "(", "str_", ")", "\n", "\n", "", "strp_str", "=", "_recur_strip", "(", "str_", ")", "\n", "\n", "#if isinstance(str_, (list, tuple)):", "\n", "#    return type(str_)(strp_str)", "\n", "#else:", "\n", "#    return np.asarray(strp_str)", "\n", "return", "strp_str", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.utils.strip_eos": [[604, 641], ["utils.strip_token._recur_strip"], "function", ["None"], ["", "def", "strip_eos", "(", "str_", ",", "eos_token", "=", "'<EOS>'", ",", "compat", "=", "True", ")", ":", "\n", "    ", "\"\"\"Remove the EOS token and all subsequent tokens.\n\n    Assumes tokens in the strings are separated with the space character.\n\n    Args:\n        str_: A `str`, or an `n`-D numpy array or (possibly nested)\n            list of `str`.\n        eos_token (str): The EOS token. Default is '<EOS>' as defined in\n            :class:`~texar.data.vocabulary.SpecialTokens`.`EOS`\n        compat (bool): Whether to convert tokens into `unicode` (Python 2)\n            or `str` (Python 3).\n\n    Returns:\n        Strings of the same structure/shape as :attr:`str_`.\n    \"\"\"", "\n", "def", "_recur_strip", "(", "s", ")", ":", "\n", "        ", "if", "is_str", "(", "s", ")", ":", "\n", "            ", "s_tokens", "=", "s", ".", "split", "(", ")", "\n", "if", "eos_token", "in", "s_tokens", ":", "\n", "                ", "return", "' '", ".", "join", "(", "s_tokens", "[", ":", "s_tokens", ".", "index", "(", "eos_token", ")", "]", ")", "\n", "", "else", ":", "\n", "                ", "return", "s", "\n", "", "", "else", ":", "\n", "            ", "s_", "=", "[", "_recur_strip", "(", "si", ")", "for", "si", "in", "s", "]", "\n", "return", "_maybe_list_to_array", "(", "s_", ",", "s", ")", "\n", "\n", "", "", "if", "compat", ":", "\n", "        ", "str_", "=", "compat_as_text", "(", "str_", ")", "\n", "\n", "", "strp_str", "=", "_recur_strip", "(", "str_", ")", "\n", "\n", "#if isinstance(str_, (list, tuple)):", "\n", "#    return type(str_)(strp_str)", "\n", "#else:", "\n", "#    return np.asarray(strp_str)", "\n", "return", "strp_str", "\n", "", "_strip_eos_", "=", "strip_eos", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.utils.strip_bos": [[643, 676], ["utils.strip_token._recur_strip"], "function", ["None"], ["def", "strip_bos", "(", "str_", ",", "bos_token", "=", "'<BOS>'", ",", "compat", "=", "True", ")", ":", "\n", "    ", "\"\"\"Remove the leading BOS token.\n\n    Assumes tokens in the strings are separated with the space character.\n\n    Args:\n        str_: A `str`, or an `n`-D numpy array or (possibly nested)\n            list of `str`.\n        bos_token (str): The BOS token. Default is '<BOS>' as defined in\n            :class:`~texar.data.vocabulary.SpecialTokens`.`BOS`\n        compat (bool): Whether to convert tokens into `unicode` (Python 2)\n            or `str` (Python 3).\n\n    Returns:\n        Strings of the same structure/shape as :attr:`str_`.\n    \"\"\"", "\n", "def", "_recur_strip", "(", "s", ")", ":", "\n", "        ", "if", "is_str", "(", "s", ")", ":", "\n", "            ", "return", "' '", ".", "join", "(", "s", ".", "strip", "(", ")", ".", "split", "(", ")", ")", ".", "replace", "(", "bos_token", "+", "' '", ",", "''", ")", "\n", "", "else", ":", "\n", "            ", "s_", "=", "[", "_recur_strip", "(", "si", ")", "for", "si", "in", "s", "]", "\n", "return", "_maybe_list_to_array", "(", "s_", ",", "s", ")", "\n", "\n", "", "", "if", "compat", ":", "\n", "        ", "str_", "=", "compat_as_text", "(", "str_", ")", "\n", "\n", "", "strp_str", "=", "_recur_strip", "(", "str_", ")", "\n", "\n", "#if isinstance(str_, (list, tuple)):", "\n", "#    return type(str_)(strp_str)", "\n", "#else:", "\n", "#    return np.asarray(strp_str)", "\n", "return", "strp_str", "\n", "", "_strip_bos_", "=", "strip_bos", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.utils.strip_special_tokens": [[678, 723], ["texar.utils.dtypes.compat_as_text", "_strip_eos_", "utils.strip_token", "_strip_bos_"], "function", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.dtypes.compat_as_text", "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.utils.strip_token"], ["def", "strip_special_tokens", "(", "str_", ",", "strip_pad", "=", "'<PAD>'", ",", "strip_bos", "=", "'<BOS>'", ",", "\n", "strip_eos", "=", "'<EOS>'", ",", "compat", "=", "True", ")", ":", "\n", "    ", "\"\"\"Removes special tokens of strings, including:\n\n        - Removes EOS and all subsequent tokens\n        - Removes leading and and trailing PAD tokens\n        - Removes leading BOS tokens\n\n    Args:\n        str_: A `str`, or an `n`-D numpy array or (possibly nested)\n            list of `str`.\n        strip_pad (str): The PAD token to strip from the strings (i.e., remove\n            the leading and trailing PAD tokens of the strings). Default\n            is '<PAD>' as defined in\n            :class:`~texar.data.vocabulary.SpecialTokens`.`PAD`.\n            Set to `None` or `False` to disable the stripping.\n        strip_bos (str): The BOS token to strip from the strings (i.e., remove\n            the leading BOS tokens of the strings).\n            Default is '<BOS>' as defined in\n            :class:`~texar.data.vocabulary.SpecialTokens`.`BOS`.\n            Set to `None` or `False` to disable the stripping.\n        strip_eos (str): The EOS token to strip from the strings (i.e., remove\n            the EOS tokens and all subsequent tokens of the strings).\n            Default is '<EOS>' as defined in\n            :class:`~texar.data.vocabulary.SpecialTokens`.`EOS`.\n            Set to `None` or `False` to disable the stripping.\n        compat (bool): Whether to convert tokens into `unicode` (Python 2)\n            or `str` (Python 3).\n\n    Returns:\n        Strings of the same shape of :attr:`str_` with special tokens stripped.\n    \"\"\"", "\n", "if", "compat", ":", "\n", "        ", "str_", "=", "compat_as_text", "(", "str_", ")", "\n", "\n", "", "if", "strip_eos", "is", "not", "None", "and", "strip_eos", "is", "not", "False", ":", "\n", "        ", "str_", "=", "_strip_eos_", "(", "str_", ",", "strip_eos", ",", "compat", "=", "False", ")", "\n", "\n", "", "if", "strip_pad", "is", "not", "None", "and", "strip_pad", "is", "not", "False", ":", "\n", "        ", "str_", "=", "strip_token", "(", "str_", ",", "strip_pad", ",", "compat", "=", "False", ")", "\n", "\n", "", "if", "strip_bos", "is", "not", "None", "and", "strip_bos", "is", "not", "False", ":", "\n", "        ", "str_", "=", "_strip_bos_", "(", "str_", ",", "strip_bos", ",", "compat", "=", "False", ")", "\n", "\n", "", "return", "str_", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.utils.str_join": [[724, 756], ["utils.str_join._recur_join"], "function", ["None"], ["", "def", "str_join", "(", "tokens", ",", "sep", "=", "' '", ",", "compat", "=", "True", ")", ":", "\n", "    ", "\"\"\"Concats :attr:`tokens` along the last dimension with intervening\n    occurrences of :attr:`sep`.\n\n    Args:\n        tokens: An `n`-D numpy array or (possibly nested) list of `str`.\n        sep (str): The string intervening between the tokens.\n        compat (bool): Whether to convert tokens into `unicode` (Python 2)\n            or `str` (Python 3).\n\n    Returns:\n        An `(n-1)`-D numpy array (or list) of `str`.\n    \"\"\"", "\n", "def", "_recur_join", "(", "s", ")", ":", "\n", "        ", "if", "len", "(", "s", ")", "==", "0", ":", "\n", "            ", "return", "''", "\n", "", "elif", "is_str", "(", "s", "[", "0", "]", ")", ":", "\n", "            ", "return", "sep", ".", "join", "(", "s", ")", "\n", "", "else", ":", "\n", "            ", "s_", "=", "[", "_recur_join", "(", "si", ")", "for", "si", "in", "s", "]", "\n", "return", "_maybe_list_to_array", "(", "s_", ",", "s", ")", "\n", "\n", "", "", "if", "compat", ":", "\n", "        ", "tokens", "=", "compat_as_text", "(", "tokens", ")", "\n", "\n", "", "str_", "=", "_recur_join", "(", "tokens", ")", "\n", "\n", "#if isinstance(tokens, (list, tuple)):", "\n", "#    return type(tokens)(str_)", "\n", "#else:", "\n", "#    return np.asarray(str_)", "\n", "return", "str_", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.utils.map_ids_to_strs": [[757, 809], ["vocab.map_ids_to_tokens_py", "utils.str_join", "utils.strip_special_tokens", "texar.utils.dtypes.compat_as_text", "texar.utils.dtypes.is_str", "utils.map_ids_to_strs._recur_split"], "function", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.data.vocabulary.Vocab.map_ids_to_tokens_py", "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.utils.str_join", "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.utils.strip_special_tokens", "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.dtypes.compat_as_text", "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.dtypes.is_str"], ["", "def", "map_ids_to_strs", "(", "ids", ",", "vocab", ",", "join", "=", "True", ",", "strip_pad", "=", "'<PAD>'", ",", "\n", "strip_bos", "=", "'<BOS>'", ",", "strip_eos", "=", "'<EOS>'", ",", "compat", "=", "True", ")", ":", "\n", "    ", "\"\"\"Transforms indexes to strings by id-token mapping, token concat, token\n    stripping, etc.\n\n    Args:\n        ids: An n-D numpy array or (possibly nested) list of `int` indexes.\n        vocab: An instance of :class:`~texar.data.Vocab`.\n        join (bool): Whether concat along the last dimension of :attr:`ids`\n            the tokens into a string with a space character.\n        strip_pad (str): The PAD token to strip from the strings (i.e., remove\n            the leading and trailing PAD tokens of the strings). Default\n            is '<PAD>' as defined in\n            :class:`~texar.data.vocabulary.SpecialTokens`.`PAD`.\n            Set to `None` or `False` to disable the stripping.\n        strip_bos (str): The BOS token to strip from the strings (i.e., remove\n            the leading BOS tokens of the strings).\n            Default is '<BOS>' as defined in\n            :class:`~texar.data.vocabulary.SpecialTokens`.`BOS`.\n            Set to `None` or `False` to disable the stripping.\n        strip_eos (str): The EOS token to strip from the strings (i.e., remove\n            the EOS tokens and all subsequent tokens of the strings).\n            Default is '<EOS>' as defined in\n            :class:`~texar.data.vocabulary.SpecialTokens`.`EOS`.\n            Set to `None` or `False` to disable the stripping.\n    Returns:\n        If :attr:`join`=True, returns a (n-1)-D numpy array (or list) of\n        concatenated strings. If :attr:`join`=False, returns an n-D numpy\n        array (or list) of str tokens.\n    \"\"\"", "\n", "tokens", "=", "vocab", ".", "map_ids_to_tokens_py", "(", "ids", ")", "\n", "\n", "if", "compat", ":", "\n", "        ", "tokens", "=", "compat_as_text", "(", "tokens", ")", "\n", "\n", "", "str_", "=", "str_join", "(", "tokens", ",", "compat", "=", "False", ")", "\n", "\n", "str_", "=", "strip_special_tokens", "(", "\n", "str_", ",", "strip_pad", "=", "strip_pad", ",", "strip_bos", "=", "strip_bos", ",", "strip_eos", "=", "strip_eos", ",", "\n", "compat", "=", "False", ")", "\n", "\n", "def", "_recur_split", "(", "s", ")", ":", "\n", "        ", "if", "is_str", "(", "s", ")", ":", "\n", "            ", "return", "_maybe_list_to_array", "(", "s", ".", "split", "(", ")", ",", "str_", ")", "\n", "", "else", ":", "\n", "            ", "s_", "=", "[", "_recur_split", "(", "si", ")", "for", "si", "in", "s", "]", "\n", "return", "_maybe_list_to_array", "(", "s_", ",", "s", ")", "\n", "\n", "", "", "if", "join", ":", "\n", "        ", "return", "str_", "\n", "", "else", ":", "\n", "        ", "return", "_recur_split", "(", "str_", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.utils.ceildiv": [[810, 823], ["None"], "function", ["None"], ["", "", "def", "ceildiv", "(", "a", ",", "b", ")", ":", "\n", "    ", "\"\"\"Divides with ceil.\n\n    E.g., `5 / 2 = 2.5`, `ceildiv(5, 2) = 3`.\n\n    Args:\n        a (int): Dividend integer.\n        b (int): Divisor integer.\n\n    Returns:\n        int: Ceil quotient.\n    \"\"\"", "\n", "return", "-", "(", "-", "a", "//", "b", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.utils.straight_through": [[824, 837], ["tensorflow.stop_gradient", "tensorflow.stop_gradient"], "function", ["None"], ["", "def", "straight_through", "(", "fw_tensor", ",", "bw_tensor", ")", ":", "\n", "    ", "\"\"\"Use a tensor in forward pass while backpropagating gradient to another.\n\n    Args:\n        fw_tensor: A tensor to be used in the forward pass.\n        bw_tensor: A tensor to which gradient is backpropagated. Must have the\n            same shape and type with :attr:`fw_tensor`.\n\n    Returns:\n        A tensor of the same shape and value with :attr:`fw_tensor` but will\n            direct gradient to bw_tensor.\n    \"\"\"", "\n", "return", "tf", ".", "stop_gradient", "(", "fw_tensor", ")", "+", "bw_tensor", "-", "tf", ".", "stop_gradient", "(", "bw_tensor", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.dtypes.get_tf_dtype": [[27, 62], ["ValueError", "str"], "function", ["None"], ["def", "get_tf_dtype", "(", "dtype", ")", ":", "# pylint: disable=too-many-return-statements", "\n", "    ", "\"\"\"Returns respective tf dtype.\n\n    Args:\n        dtype: A str, python numeric or string type, numpy data type, or\n            tf dtype.\n\n    Returns:\n        The respective tf dtype.\n    \"\"\"", "\n", "if", "dtype", "in", "{", "'float'", ",", "'float32'", ",", "'tf.float32'", ",", "float", ",", "\n", "np", ".", "float32", ",", "tf", ".", "float32", "}", ":", "\n", "        ", "return", "tf", ".", "float32", "\n", "", "elif", "dtype", "in", "{", "'float64'", ",", "'tf.float64'", ",", "np", ".", "float64", ",", "np", ".", "float_", ",", "tf", ".", "float64", "}", ":", "\n", "        ", "return", "tf", ".", "float64", "\n", "", "elif", "dtype", "in", "{", "'float16'", ",", "'tf.float16'", ",", "np", ".", "float16", ",", "tf", ".", "float16", "}", ":", "\n", "        ", "return", "tf", ".", "float16", "\n", "", "elif", "dtype", "in", "{", "'int'", ",", "'int32'", ",", "'tf.int32'", ",", "int", ",", "np", ".", "int32", ",", "tf", ".", "int32", "}", ":", "\n", "        ", "return", "tf", ".", "int32", "\n", "", "elif", "dtype", "in", "{", "'int64'", ",", "'tf.int64'", ",", "np", ".", "int64", ",", "tf", ".", "int64", "}", ":", "\n", "        ", "return", "tf", ".", "int64", "\n", "", "elif", "dtype", "in", "{", "'int16'", ",", "'tf.int16'", ",", "np", ".", "int16", ",", "tf", ".", "int16", "}", ":", "\n", "        ", "return", "tf", ".", "int16", "\n", "", "elif", "dtype", "in", "{", "'bool'", ",", "'tf.bool'", ",", "bool", ",", "np", ".", "bool_", ",", "tf", ".", "bool", "}", ":", "\n", "        ", "return", "tf", ".", "bool", "\n", "", "elif", "dtype", "in", "{", "'string'", ",", "'str'", ",", "'tf.string'", ",", "str", ",", "np", ".", "str", ",", "tf", ".", "string", "}", ":", "\n", "        ", "return", "tf", ".", "string", "\n", "", "try", ":", "\n", "        ", "if", "dtype", "==", "{", "'unicode'", ",", "unicode", "}", ":", "\n", "            ", "return", "tf", ".", "string", "\n", "", "", "except", "NameError", ":", "\n", "        ", "pass", "\n", "\n", "", "raise", "ValueError", "(", "\n", "\"Unsupported conversion from type {} to tf dtype\"", ".", "format", "(", "str", "(", "dtype", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.dtypes.is_callable": [[63, 71], ["callable", "hasattr"], "function", ["None"], ["", "def", "is_callable", "(", "x", ")", ":", "\n", "    ", "\"\"\"Return `True` if :attr:`x` is callable.\n    \"\"\"", "\n", "try", ":", "\n", "        ", "_is_callable", "=", "callable", "(", "x", ")", "\n", "", "except", ":", "# pylint: disable=bare-except", "\n", "        ", "_is_callable", "=", "hasattr", "(", "x", ",", "'__call__'", ")", "\n", "", "return", "_is_callable", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.dtypes.is_str": [[72, 77], ["isinstance"], "function", ["None"], ["", "def", "is_str", "(", "x", ")", ":", "\n", "    ", "\"\"\"Returns `True` if :attr:`x` is either a str or unicode. Returns `False`\n    otherwise.\n    \"\"\"", "\n", "return", "isinstance", "(", "x", ",", "six", ".", "string_types", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.dtypes.is_placeholder": [[78, 86], ["None"], "function", ["None"], ["", "def", "is_placeholder", "(", "x", ")", ":", "\n", "    ", "\"\"\"Returns `True` if :attr:`x` is a :tf_main:`tf.placeholder <placeholder>`\n    or :tf_main:`tf.placeholder_with_default <placeholder_with_default>`.\n    \"\"\"", "\n", "try", ":", "\n", "        ", "return", "x", ".", "_ops", ".", "type", "in", "[", "'Placeholder'", ",", "'PlaceholderWithDefault'", "]", "\n", "", "except", ":", "# pylint: disable=bare-except", "\n", "        ", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.dtypes.maybe_hparams_to_dict": [[87, 97], ["isinstance", "hparams.todict"], "function", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.texar.hyperparams.HParams.todict"], ["", "", "def", "maybe_hparams_to_dict", "(", "hparams", ")", ":", "\n", "    ", "\"\"\"If :attr:`hparams` is an instance of :class:`~texar.hyperparams.HParams`,\n    converts it to a `dict` and returns. If :attr:`hparams` is a `dict`,\n    returns as is.\n    \"\"\"", "\n", "if", "hparams", "is", "None", ":", "\n", "        ", "return", "None", "\n", "", "if", "isinstance", "(", "hparams", ",", "dict", ")", ":", "\n", "        ", "return", "hparams", "\n", "", "return", "hparams", ".", "todict", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.dtypes._maybe_list_to_array": [[98, 103], ["isinstance", "numpy.array", "type"], "function", ["None"], ["", "def", "_maybe_list_to_array", "(", "str_list", ",", "dtype_as", ")", ":", "\n", "    ", "if", "isinstance", "(", "dtype_as", ",", "(", "list", ",", "tuple", ")", ")", ":", "\n", "        ", "return", "type", "(", "dtype_as", ")", "(", "str_list", ")", "\n", "", "else", ":", "\n", "        ", "return", "np", ".", "array", "(", "str_list", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.dtypes.compat_as_text": [[104, 128], ["dtypes.compat_as_text._recur_convert"], "function", ["None"], ["", "", "def", "compat_as_text", "(", "str_", ")", ":", "\n", "    ", "\"\"\"Converts strings into `unicode` (Python 2) or `str` (Python 3).\n\n    Args:\n        str_: A string or element of other types convertible to string. Or an\n            `n`-D numpy array or (possibly nested) list of elements of such\n            types.\n\n    Returns:\n        The converted strings of the same structure/shape as :attr:`str_`.\n    \"\"\"", "\n", "def", "_recur_convert", "(", "s", ")", ":", "\n", "        ", "if", "isinstance", "(", "s", ",", "(", "list", ",", "tuple", ",", "np", ".", "ndarray", ")", ")", ":", "\n", "            ", "s_", "=", "[", "_recur_convert", "(", "si", ")", "for", "si", "in", "s", "]", "\n", "return", "_maybe_list_to_array", "(", "s_", ",", "s", ")", "\n", "", "else", ":", "\n", "            ", "try", ":", "\n", "                ", "return", "tf", ".", "compat", ".", "as_text", "(", "s", ")", "\n", "", "except", "TypeError", ":", "\n", "                ", "return", "tf", ".", "compat", ".", "as_text", "(", "str", "(", "s", ")", ")", "\n", "\n", "", "", "", "text", "=", "_recur_convert", "(", "str_", ")", "\n", "\n", "return", "text", "\n", "", ""]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.texar.context.global_mode": [[22, 41], ["tensorflow.get_collection_ref", "len", "tensorflow.placeholder_with_default", "tf.get_collection_ref.append"], "function", ["None"], ["def", "global_mode", "(", ")", ":", "\n", "    ", "\"\"\"Returns the tensor of global mode.\n\n    The default mode is\n    :tf_main:`tf.estimator.ModeKeys.TRAIN <estimator/ModeKeys>`.\n    \"\"\"", "\n", "mode", "=", "tf", ".", "get_collection_ref", "(", "_GLOBAL_MODE_KEY", ")", "\n", "if", "len", "(", "mode", ")", "<", "1", ":", "\n", "#mode_tensor = tf.placeholder(tf.string, name=\"global_mode\")", "\n", "        ", "mode_tensor", "=", "tf", ".", "placeholder_with_default", "(", "\n", "input", "=", "tf", ".", "estimator", ".", "ModeKeys", ".", "TRAIN", ",", "\n", "shape", "=", "(", ")", ",", "\n", "name", "=", "\"global_mode\"", ")", "\n", "#mode_tensor = tf.constant(", "\n", "#    value=tf.estimator.ModeKeys.TRAIN,", "\n", "#    dtype=tf.string,", "\n", "#    name=\"global_mode\")", "\n", "mode", ".", "append", "(", "mode_tensor", ")", "\n", "", "return", "mode", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.texar.context.global_mode_train": [[42, 47], ["context.global_mode", "tensorflow.equal"], "function", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.texar.context.global_mode"], ["", "def", "global_mode_train", "(", ")", ":", "\n", "    ", "\"\"\"Returns a bool Tensor indicating whether the global mode is TRAIN.\n    \"\"\"", "\n", "mode", "=", "global_mode", "(", ")", "\n", "return", "tf", ".", "equal", "(", "mode", ",", "tf", ".", "estimator", ".", "ModeKeys", ".", "TRAIN", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.texar.context.global_mode_eval": [[48, 53], ["context.global_mode", "tensorflow.equal"], "function", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.texar.context.global_mode"], ["", "def", "global_mode_eval", "(", ")", ":", "\n", "    ", "\"\"\"Returns a bool Tensor indicating whether the global mode is EVAL.\n    \"\"\"", "\n", "mode", "=", "global_mode", "(", ")", "\n", "return", "tf", ".", "equal", "(", "mode", ",", "tf", ".", "estimator", ".", "ModeKeys", ".", "EVAL", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.texar.context.global_mode_predict": [[54, 59], ["context.global_mode", "tensorflow.equal"], "function", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.texar.context.global_mode"], ["", "def", "global_mode_predict", "(", ")", ":", "\n", "    ", "\"\"\"Returns a bool Tensor indicating whether the global mode is PREDICT.\n    \"\"\"", "\n", "mode", "=", "global_mode", "(", ")", "\n", "return", "tf", ".", "equal", "(", "mode", ",", "tf", ".", "estimator", ".", "ModeKeys", ".", "PREDICT", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.texar.context.valid_modes": [[60, 66], ["None"], "function", ["None"], ["", "def", "valid_modes", "(", ")", ":", "\n", "    ", "\"\"\"Returns a set of possible values of mode.\n    \"\"\"", "\n", "return", "{", "tf", ".", "estimator", ".", "ModeKeys", ".", "TRAIN", ",", "\n", "tf", ".", "estimator", ".", "ModeKeys", ".", "EVAL", ",", "\n", "tf", ".", "estimator", ".", "ModeKeys", ".", "PREDICT", "}", "\n", "", ""]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.texar.context_test.ContextTest.test_global_mode": [[22, 66], ["texar.context.global_mode", "context_test.ContextTest.assertIsInstance", "texar.context.global_mode_train", "texar.context.global_mode_eval", "texar.context.global_mode_predict", "tensorflow.get_collection_ref", "context_test.ContextTest.assertEqual", "context_test.ContextTest.test_session", "sess.run", "sess.run", "context_test.ContextTest.assertEqual", "sess.run", "context_test.ContextTest.assertEqual", "context_test.ContextTest.assertTrue", "context_test.ContextTest.assertFalse", "context_test.ContextTest.assertFalse", "sess.run", "context_test.ContextTest.assertEqual", "context_test.ContextTest.assertFalse", "context_test.ContextTest.assertTrue", "context_test.ContextTest.assertFalse", "sess.run", "context_test.ContextTest.assertEqual", "context_test.ContextTest.assertFalse", "context_test.ContextTest.assertFalse", "context_test.ContextTest.assertTrue", "len", "tensorflow.global_variables_initializer", "tensorflow.compat.as_str", "texar.context.global_mode", "texar.context.global_mode", "texar.context.global_mode"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.texar.context.global_mode", "home.repos.pwc.inspect_result.VegB_Text_Infilling.texar.context.global_mode_train", "home.repos.pwc.inspect_result.VegB_Text_Infilling.texar.context.global_mode_eval", "home.repos.pwc.inspect_result.VegB_Text_Infilling.texar.context.global_mode_predict", "home.repos.pwc.inspect_result.VegB_Text_Infilling.texar.context.global_mode", "home.repos.pwc.inspect_result.VegB_Text_Infilling.texar.context.global_mode", "home.repos.pwc.inspect_result.VegB_Text_Infilling.texar.context.global_mode"], ["def", "test_global_mode", "(", "self", ")", ":", "\n", "        ", "\"\"\"Tests the mode context manager.\n        \"\"\"", "\n", "global_mode", "=", "context", ".", "global_mode", "(", ")", "\n", "self", ".", "assertIsInstance", "(", "global_mode", ",", "tf", ".", "Tensor", ")", "\n", "\n", "mode_train", "=", "context", ".", "global_mode_train", "(", ")", "\n", "mode_eval", "=", "context", ".", "global_mode_eval", "(", ")", "\n", "mode_predict", "=", "context", ".", "global_mode_predict", "(", ")", "\n", "\n", "with", "self", ".", "test_session", "(", ")", "as", "sess", ":", "\n", "            ", "sess", ".", "run", "(", "tf", ".", "global_variables_initializer", "(", ")", ")", "\n", "\n", "global_mode_", "=", "sess", ".", "run", "(", "global_mode", ")", "\n", "self", ".", "assertEqual", "(", "tf", ".", "compat", ".", "as_str", "(", "global_mode_", ")", ",", "\n", "tf", ".", "estimator", ".", "ModeKeys", ".", "TRAIN", ")", "\n", "\n", "global_mode_", ",", "mode_train_", ",", "mode_eval_", ",", "mode_predict_", "=", "sess", ".", "run", "(", "\n", "[", "global_mode", ",", "mode_train", ",", "mode_eval", ",", "mode_predict", "]", ",", "\n", "feed_dict", "=", "{", "context", ".", "global_mode", "(", ")", ":", "tf", ".", "estimator", ".", "ModeKeys", ".", "TRAIN", "}", ")", "\n", "self", ".", "assertEqual", "(", "global_mode_", ",", "tf", ".", "estimator", ".", "ModeKeys", ".", "TRAIN", ")", "\n", "self", ".", "assertTrue", "(", "mode_train_", ")", "\n", "self", ".", "assertFalse", "(", "mode_eval_", ")", "\n", "self", ".", "assertFalse", "(", "mode_predict_", ")", "\n", "\n", "global_mode_", ",", "mode_train_", ",", "mode_eval_", ",", "mode_predict_", "=", "sess", ".", "run", "(", "\n", "[", "global_mode", ",", "mode_train", ",", "mode_eval", ",", "mode_predict", "]", ",", "\n", "feed_dict", "=", "{", "context", ".", "global_mode", "(", ")", ":", "tf", ".", "estimator", ".", "ModeKeys", ".", "EVAL", "}", ")", "\n", "self", ".", "assertEqual", "(", "global_mode_", ",", "tf", ".", "estimator", ".", "ModeKeys", ".", "EVAL", ")", "\n", "self", ".", "assertFalse", "(", "mode_train_", ")", "\n", "self", ".", "assertTrue", "(", "mode_eval_", ")", "\n", "self", ".", "assertFalse", "(", "mode_predict_", ")", "\n", "\n", "global_mode_", ",", "mode_train_", ",", "mode_eval_", ",", "mode_predict_", "=", "sess", ".", "run", "(", "\n", "[", "global_mode", ",", "mode_train", ",", "mode_eval", ",", "mode_predict", "]", ",", "\n", "feed_dict", "=", "{", "context", ".", "global_mode", "(", ")", ":", "\n", "tf", ".", "estimator", ".", "ModeKeys", ".", "PREDICT", "}", ")", "\n", "self", ".", "assertEqual", "(", "global_mode_", ",", "tf", ".", "estimator", ".", "ModeKeys", ".", "PREDICT", ")", "\n", "self", ".", "assertFalse", "(", "mode_train_", ")", "\n", "self", ".", "assertFalse", "(", "mode_eval_", ")", "\n", "self", ".", "assertTrue", "(", "mode_predict_", ")", "\n", "\n", "", "global_mode_values", "=", "tf", ".", "get_collection_ref", "(", "context", ".", "_GLOBAL_MODE_KEY", ")", "\n", "self", ".", "assertEqual", "(", "len", "(", "global_mode_values", ")", ",", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.texar.hyperparams_test.HParamsTest.test_hparams": [[23, 97], ["texar.hyperparams.HParams", "texar.hyperparams.HParams.items", "hyperparams_test.HParamsTest.assertEqual", "texar.hyperparams.HParams", "hyperparams_test.HParamsTest.assertEqual", "hyperparams_test.HParamsTest.assertEqual", "hyperparams_test.HParamsTest.assertEqual", "hyperparams_test.HParamsTest.assertEqual", "hyperparams_test.HParamsTest.assertEqual", "hyperparams_test.HParamsTest.assertEqual", "copy.deepcopy", "new_hparams[].update", "hyperparams_test.HParamsTest.assertEqual", "hyperparams_test.HParamsTest.assertTrue", "hyperparams_test.HParamsTest.assertIsNone", "hyperparams_test.HParamsTest.assertEqual", "hyperparams_test.HParamsTest.assertEqual", "hyperparams_test.HParamsTest.assertEqual", "texar.hyperparams.HParams.add_hparam", "texar.hyperparams.HParams.add_hparam", "texar.hyperparams.HParams.kwargs.add_hparam", "hyperparams_test.HParamsTest.assertEqual", "hyperparams_test.HParamsTest.assertEqual", "hyperparams_test.HParamsTest.assertEqual", "tempfile.NamedTemporaryFile", "pickle.dump", "hyperparams_test.HParamsTest.assertEqual", "names.append", "default_hparams.keys", "len", "len", "texar.hyperparams.HParams.todict", "texar.hyperparams.HParams.get", "texar.hyperparams.HParams.get", "texar.hyperparams.HParams.added_dict.todict", "open", "pickle.load", "pickle.load.todict", "texar.hyperparams.HParams.todict"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.texar.hyperparams.HParams.items", "home.repos.pwc.inspect_result.VegB_Text_Infilling.texar.hyperparams.HParams.add_hparam", "home.repos.pwc.inspect_result.VegB_Text_Infilling.texar.hyperparams.HParams.add_hparam", "home.repos.pwc.inspect_result.VegB_Text_Infilling.texar.hyperparams.HParams.add_hparam", "home.repos.pwc.inspect_result.VegB_Text_Infilling.texar.hyperparams.HParams.keys", "home.repos.pwc.inspect_result.VegB_Text_Infilling.texar.hyperparams.HParams.todict", "home.repos.pwc.inspect_result.VegB_Text_Infilling.core.replay_memories.DequeReplayMemory.get", "home.repos.pwc.inspect_result.VegB_Text_Infilling.core.replay_memories.DequeReplayMemory.get", "home.repos.pwc.inspect_result.VegB_Text_Infilling.texar.hyperparams.HParams.todict", "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.vocabulary.Vocab.load", "home.repos.pwc.inspect_result.VegB_Text_Infilling.texar.hyperparams.HParams.todict", "home.repos.pwc.inspect_result.VegB_Text_Infilling.texar.hyperparams.HParams.todict"], ["def", "test_hparams", "(", "self", ")", ":", "\n", "        ", "\"\"\"Tests the HParams class.\n        \"\"\"", "\n", "default_hparams", "=", "{", "\n", "\"str\"", ":", "\"str\"", ",", "\n", "\"list\"", ":", "[", "'item1'", ",", "'item2'", "]", ",", "\n", "\"dict\"", ":", "{", "\n", "\"key1\"", ":", "\"value1\"", ",", "\n", "\"key2\"", ":", "\"value2\"", "\n", "}", ",", "\n", "\"nested_dict\"", ":", "{", "\n", "\"dict_l2\"", ":", "{", "\n", "\"key1_l2\"", ":", "\"value1_l2\"", "\n", "}", "\n", "}", ",", "\n", "\"type\"", ":", "\"type\"", ",", "\n", "\"kwargs\"", ":", "{", "\n", "\"arg1\"", ":", "\"argv1\"", "\n", "}", ",", "\n", "}", "\n", "\n", "# Test HParams.items() function", "\n", "hparams_", "=", "HParams", "(", "None", ",", "default_hparams", ")", "\n", "names", "=", "[", "]", "\n", "for", "name", ",", "_", "in", "hparams_", ".", "items", "(", ")", ":", "\n", "            ", "names", ".", "append", "(", "name", ")", "\n", "", "self", ".", "assertEqual", "(", "names", ",", "default_hparams", ".", "keys", "(", ")", ")", "\n", "\n", "hparams", "=", "{", "\n", "\"dict\"", ":", "{", "\"key1\"", ":", "\"new_value\"", "}", ",", "\n", "\"kwargs\"", ":", "{", "\"arg2\"", ":", "\"argv2\"", "}", "\n", "}", "\n", "\n", "hparams_", "=", "HParams", "(", "hparams", ",", "default_hparams", ")", "\n", "\n", "# Test HParams construction", "\n", "self", ".", "assertEqual", "(", "hparams_", ".", "str", ",", "default_hparams", "[", "\"str\"", "]", ")", "\n", "self", ".", "assertEqual", "(", "hparams_", ".", "list", ",", "default_hparams", "[", "\"list\"", "]", ")", "\n", "self", ".", "assertEqual", "(", "hparams_", ".", "dict", ".", "key1", ",", "hparams", "[", "\"dict\"", "]", "[", "\"key1\"", "]", ")", "\n", "self", ".", "assertEqual", "(", "hparams_", ".", "kwargs", ".", "arg2", ",", "hparams", "[", "\"kwargs\"", "]", "[", "\"arg2\"", "]", ")", "\n", "self", ".", "assertEqual", "(", "hparams_", ".", "nested_dict", ".", "dict_l2", ".", "key1_l2", ",", "\n", "default_hparams", "[", "\"nested_dict\"", "]", "[", "\"dict_l2\"", "]", "[", "\"key1_l2\"", "]", ")", "\n", "\n", "self", ".", "assertEqual", "(", "len", "(", "hparams_", ")", ",", "len", "(", "default_hparams", ")", ")", "\n", "\n", "new_hparams", "=", "copy", ".", "deepcopy", "(", "default_hparams", ")", "\n", "new_hparams", "[", "\"dict\"", "]", "[", "\"key1\"", "]", "=", "hparams", "[", "\"dict\"", "]", "[", "\"key1\"", "]", "\n", "new_hparams", "[", "\"kwargs\"", "]", ".", "update", "(", "hparams", "[", "\"kwargs\"", "]", ")", "\n", "self", ".", "assertEqual", "(", "hparams_", ".", "todict", "(", ")", ",", "new_hparams", ")", "\n", "\n", "self", ".", "assertTrue", "(", "\"dict\"", "in", "hparams_", ")", "\n", "\n", "self", ".", "assertIsNone", "(", "hparams_", ".", "get", "(", "'not_existed_name'", ",", "None", ")", ")", "\n", "self", ".", "assertEqual", "(", "hparams_", ".", "get", "(", "'str'", ")", ",", "default_hparams", "[", "'str'", "]", ")", "\n", "\n", "# Test HParams update related operations", "\n", "hparams_", ".", "str", "=", "\"new_str\"", "\n", "hparams_", ".", "dict", "=", "{", "\"key3\"", ":", "\"value3\"", "}", "\n", "self", ".", "assertEqual", "(", "hparams_", ".", "str", ",", "\"new_str\"", ")", "\n", "self", ".", "assertEqual", "(", "hparams_", ".", "dict", ".", "key3", ",", "\"value3\"", ")", "\n", "\n", "hparams_", ".", "add_hparam", "(", "\"added_str\"", ",", "\"added_str\"", ")", "\n", "hparams_", ".", "add_hparam", "(", "\"added_dict\"", ",", "{", "\"key4\"", ":", "\"value4\"", "}", ")", "\n", "hparams_", ".", "kwargs", ".", "add_hparam", "(", "\"added_arg\"", ",", "\"added_argv\"", ")", "\n", "self", ".", "assertEqual", "(", "hparams_", ".", "added_str", ",", "\"added_str\"", ")", "\n", "self", ".", "assertEqual", "(", "hparams_", ".", "added_dict", ".", "todict", "(", ")", ",", "{", "\"key4\"", ":", "\"value4\"", "}", ")", "\n", "self", ".", "assertEqual", "(", "hparams_", ".", "kwargs", ".", "added_arg", ",", "\"added_argv\"", ")", "\n", "\n", "# Test HParams I/O", "\n", "hparams_file", "=", "tempfile", ".", "NamedTemporaryFile", "(", ")", "\n", "pickle", ".", "dump", "(", "hparams_", ",", "hparams_file", ")", "\n", "with", "open", "(", "hparams_file", ".", "name", ",", "'rb'", ")", "as", "hparams_file", ":", "\n", "            ", "hparams_loaded", "=", "pickle", ".", "load", "(", "hparams_file", ")", "\n", "", "self", ".", "assertEqual", "(", "hparams_loaded", ".", "todict", "(", ")", ",", "hparams_", ".", "todict", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.texar.hyperparams_test.HParamsTest.test_typecheck": [[99, 117], ["texar.hyperparams.HParams", "hyperparams_test.HParamsTest.assertEqual"], "methods", ["None"], ["", "def", "test_typecheck", "(", "self", ")", ":", "\n", "        ", "\"\"\"Tests type-check functionality.\n        \"\"\"", "\n", "def", "_foo", "(", ")", ":", "\n", "            ", "pass", "\n", "", "def", "_bar", "(", ")", ":", "\n", "            ", "pass", "\n", "\n", "", "default_hparams", "=", "{", "\n", "\"fn\"", ":", "_foo", ",", "\n", "\"fn_2\"", ":", "_foo", "\n", "}", "\n", "hparams", "=", "{", "\n", "\"fn\"", ":", "_foo", ",", "\n", "\"fn_2\"", ":", "_bar", "\n", "}", "\n", "hparams_", "=", "HParams", "(", "hparams", ",", "default_hparams", ")", "\n", "self", ".", "assertEqual", "(", "hparams_", ".", "fn", ",", "default_hparams", "[", "\"fn\"", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.texar.hyperparams_test.HParamsTest.test_type_kwargs": [[119, 170], ["texar.hyperparams.HParams", "hyperparams_test.HParamsTest.assertEqual", "texar.hyperparams.HParams", "full_kwargs.update", "full_kwargs.update", "hyperparams_test.HParamsTest.assertEqual", "texar.hyperparams.HParams", "hyperparams_test.HParamsTest.assertEqual", "texar.hyperparams.HParams", "hyperparams_test.HParamsTest.assertEqual", "texar.hyperparams.HParams", "hyperparams_test.HParamsTest.assertEqual", "texar.hyperparams.HParams.kwargs.todict", "texar.hyperparams.HParams.kwargs.todict", "texar.hyperparams.HParams.kwargs.todict", "texar.hyperparams.HParams.kwargs.todict", "texar.hyperparams.HParams.kwargs.todict"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.texar.hyperparams.HParams.todict", "home.repos.pwc.inspect_result.VegB_Text_Infilling.texar.hyperparams.HParams.todict", "home.repos.pwc.inspect_result.VegB_Text_Infilling.texar.hyperparams.HParams.todict", "home.repos.pwc.inspect_result.VegB_Text_Infilling.texar.hyperparams.HParams.todict", "home.repos.pwc.inspect_result.VegB_Text_Infilling.texar.hyperparams.HParams.todict"], ["", "def", "test_type_kwargs", "(", "self", ")", ":", "\n", "        ", "\"\"\"The the special cases involving \"type\" and \"kwargs\"\n        hyperparameters.\n        \"\"\"", "\n", "default_hparams", "=", "{", "\n", "\"type\"", ":", "\"type_name\"", ",", "\n", "\"kwargs\"", ":", "{", "\n", "\"arg1\"", ":", "\"argv1\"", "\n", "}", "\n", "}", "\n", "\n", "hparams", "=", "{", "\n", "\"type\"", ":", "\"type_name\"", "\n", "}", "\n", "hparams_", "=", "HParams", "(", "hparams", ",", "default_hparams", ")", "\n", "self", ".", "assertEqual", "(", "hparams_", ".", "kwargs", ".", "todict", "(", ")", ",", "default_hparams", "[", "\"kwargs\"", "]", ")", "\n", "\n", "hparams", "=", "{", "\n", "\"type\"", ":", "\"type_name\"", ",", "\n", "\"kwargs\"", ":", "{", "\n", "\"arg2\"", ":", "\"argv2\"", "\n", "}", "\n", "}", "\n", "hparams_", "=", "HParams", "(", "hparams", ",", "default_hparams", ")", "\n", "full_kwargs", "=", "{", "}", "\n", "full_kwargs", ".", "update", "(", "default_hparams", "[", "\"kwargs\"", "]", ")", "\n", "full_kwargs", ".", "update", "(", "hparams", "[", "\"kwargs\"", "]", ")", "\n", "self", ".", "assertEqual", "(", "hparams_", ".", "kwargs", ".", "todict", "(", ")", ",", "full_kwargs", ")", "\n", "\n", "hparams", "=", "{", "\n", "\"kwargs\"", ":", "{", "\n", "\"arg2\"", ":", "\"argv2\"", "\n", "}", "\n", "}", "\n", "hparams_", "=", "HParams", "(", "hparams", ",", "default_hparams", ")", "\n", "self", ".", "assertEqual", "(", "hparams_", ".", "kwargs", ".", "todict", "(", ")", ",", "full_kwargs", ")", "\n", "\n", "hparams", "=", "{", "\n", "\"type\"", ":", "\"type_name2\"", "\n", "}", "\n", "hparams_", "=", "HParams", "(", "hparams", ",", "default_hparams", ")", "\n", "self", ".", "assertEqual", "(", "hparams_", ".", "kwargs", ".", "todict", "(", ")", ",", "{", "}", ")", "\n", "\n", "hparams", "=", "{", "\n", "\"type\"", ":", "\"type_name2\"", ",", "\n", "\"kwargs\"", ":", "{", "\n", "\"arg3\"", ":", "\"argv3\"", "\n", "}", "\n", "}", "\n", "hparams_", "=", "HParams", "(", "hparams", ",", "default_hparams", ")", "\n", "self", ".", "assertEqual", "(", "hparams_", ".", "kwargs", ".", "todict", "(", ")", ",", "hparams", "[", "\"kwargs\"", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.texar.module_base.ModuleBase.__init__": [[30, 37], ["texar.hyperparams.HParams", "tensorflow.make_template", "module_base.ModuleBase.default_hparams", "module_base.ModuleBase.variable_scope.name.split"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.core.replay_memories.DequeReplayMemory.default_hparams"], ["def", "__init__", "(", "self", ",", "hparams", "=", "None", ")", ":", "\n", "        ", "self", ".", "_hparams", "=", "HParams", "(", "hparams", ",", "self", ".", "default_hparams", "(", ")", ")", "\n", "self", ".", "_template", "=", "tf", ".", "make_template", "(", "self", ".", "_hparams", ".", "name", ",", "self", ".", "_build", ",", "\n", "create_scope_now_", "=", "True", ")", "\n", "self", ".", "_unique_name", "=", "self", ".", "variable_scope", ".", "name", ".", "split", "(", "\"/\"", ")", "[", "-", "1", "]", "\n", "self", ".", "_trainable_variables", "=", "[", "]", "\n", "self", ".", "_built", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.texar.module_base.ModuleBase.default_hparams": [[38, 46], ["None"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "default_hparams", "(", ")", ":", "\n", "        ", "\"\"\"Returns a dictionary of hyperparameters of the module with default\n        values. Used to replace the missing values of input :attr:`hparams`\n        during module construction.\n        \"\"\"", "\n", "return", "{", "\n", "\"name\"", ":", "\"module\"", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.texar.module_base.ModuleBase._build": [[48, 59], ["None"], "methods", ["None"], ["", "def", "_build", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"Subclass must implement this method to build the logic.\n\n        Args:\n            *args: Arguments.\n            **kwargs: Keyword arguments.\n\n        Returns:\n            Output Tensor(s).\n        \"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.texar.module_base.ModuleBase.__call__": [[60, 71], ["module_base.ModuleBase._template"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"Executes the module logic defined in _build method\n\n        Args:\n            *args: Arguments of _build method.\n            **kwargs: Keyword arguments of _build method.\n\n        Returns:\n            The output of _build method.\n        \"\"\"", "\n", "return", "self", ".", "_template", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.texar.module_base.ModuleBase._add_internal_trainable_variables": [[72, 86], ["tensorflow.get_collection", "module_base.ModuleBase._add_trainable_variable", "re.escape"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.texar.module_base.ModuleBase._add_trainable_variable"], ["", "def", "_add_internal_trainable_variables", "(", "self", ")", ":", "# pylint: disable=invalid-name", "\n", "        ", "\"\"\"Collects trainable variables constructured internally in this module.\n\n        This is typically called at the end of `_build()` where all necessary\n        trainable variables have been constructed.\n        \"\"\"", "\n", "scope_name", "=", "self", ".", "variable_scope", ".", "name", "\n", "# Escape to handle possible \".\" characters in the name.", "\n", "# Append a slash to the end to avoid searching scopes that have this", "\n", "# scope name as a prefix.", "\n", "scope_name", "=", "re", ".", "escape", "(", "scope_name", ")", "+", "\"/\"", "\n", "internal_trainable_variables", "=", "tf", ".", "get_collection", "(", "\n", "tf", ".", "GraphKeys", ".", "TRAINABLE_VARIABLES", ",", "scope", "=", "scope_name", ")", "\n", "self", ".", "_add_trainable_variable", "(", "internal_trainable_variables", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.texar.module_base.ModuleBase._add_trainable_variable": [[87, 102], ["isinstance", "module_base.ModuleBase._add_trainable_variable", "module_base.ModuleBase._trainable_variables.append"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.texar.module_base.ModuleBase._add_trainable_variable"], ["", "def", "_add_trainable_variable", "(", "self", ",", "variable", ")", ":", "\n", "        ", "\"\"\"Adds a trainable variable to the trainable variable list of the\n        module.\n\n        Args:\n            variable: a (list of) trainable variable(s) constructed either\n                internally in the module or constructured outside but used\n                inside the module.\n        \"\"\"", "\n", "if", "isinstance", "(", "variable", ",", "(", "list", ",", "tuple", ")", ")", ":", "\n", "            ", "for", "var", "in", "variable", ":", "\n", "                ", "self", ".", "_add_trainable_variable", "(", "var", ")", "\n", "", "", "else", ":", "\n", "            ", "if", "variable", "not", "in", "self", ".", "_trainable_variables", ":", "\n", "                ", "self", ".", "_trainable_variables", ".", "append", "(", "variable", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.texar.module_base.ModuleBase.variable_scope": [[103, 108], ["None"], "methods", ["None"], ["", "", "", "@", "property", "\n", "def", "variable_scope", "(", "self", ")", ":", "\n", "        ", "\"\"\"The variable scope of the module.\n        \"\"\"", "\n", "return", "self", ".", "_template", ".", "variable_scope", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.texar.module_base.ModuleBase.name": [[109, 114], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "name", "(", "self", ")", ":", "\n", "        ", "\"\"\"The uniquified name of the module.\n        \"\"\"", "\n", "return", "self", ".", "_unique_name", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.texar.module_base.ModuleBase.trainable_variables": [[115, 125], ["texar.utils.exceptions.TexarError"], "methods", ["None"], ["", "@", "property", "\n", "def", "trainable_variables", "(", "self", ")", ":", "\n", "        ", "\"\"\"The list of trainable variables of the module.\n        \"\"\"", "\n", "if", "not", "self", ".", "_built", ":", "\n", "            ", "raise", "TexarError", "(", "\n", "\"Attempting to access trainable_variables before module %s \"", "\n", "\"was fully built. The module is built once it is called, \"", "\n", "\"e.g., with `%s(...)`\"", "%", "(", "self", ".", "name", ",", "self", ".", "name", ")", ")", "\n", "", "return", "self", ".", "_trainable_variables", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.texar.module_base.ModuleBase.hparams": [[126, 132], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "hparams", "(", "self", ")", ":", "\n", "        ", "\"\"\"A :class:`~texar.hyperparams.HParams` instance. The hyperparameters\n        of the module.\n        \"\"\"", "\n", "return", "self", ".", "_hparams", "\n", "", "", ""]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.texar.hyperparams.HParams.__init__": [[67, 76], ["isinstance", "object.__setattr__", "hparams.todict.todict.todict", "hyperparams.HParams._parse", "hyperparams.HParams._parse"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.texar.hyperparams.HParams.__setattr__", "home.repos.pwc.inspect_result.VegB_Text_Infilling.texar.hyperparams.HParams.todict", "home.repos.pwc.inspect_result.VegB_Text_Infilling.texar.hyperparams.HParams._parse", "home.repos.pwc.inspect_result.VegB_Text_Infilling.texar.hyperparams.HParams._parse"], ["def", "__init__", "(", "self", ",", "hparams", ",", "default_hparams", ",", "allow_new_hparam", "=", "False", ")", ":", "\n", "        ", "if", "isinstance", "(", "hparams", ",", "HParams", ")", ":", "\n", "            ", "hparams", "=", "hparams", ".", "todict", "(", ")", "\n", "", "if", "default_hparams", "is", "not", "None", ":", "\n", "            ", "parsed_hparams", "=", "self", ".", "_parse", "(", "\n", "hparams", ",", "default_hparams", ",", "allow_new_hparam", ")", "\n", "", "else", ":", "\n", "            ", "parsed_hparams", "=", "self", ".", "_parse", "(", "hparams", ",", "hparams", ")", "\n", "", "super", "(", "HParams", ",", "self", ")", ".", "__setattr__", "(", "'_hparams'", ",", "parsed_hparams", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.texar.hyperparams.HParams._parse": [[77, 198], ["default_hparams.get", "copy.deepcopy", "default_hparams.items", "hparams.items", "hyperparams.HParams._parse", "ValueError", "ValueError", "isinstance", "isinstance", "hyperparams.HParams._parse_value", "hyperparams.HParams._parse_value", "isinstance", "hyperparams.HParams", "hyperparams.HParams", "hyperparams.HParams._parse_value", "ValueError", "ValueError", "type", "isinstance", "hyperparams.HParams", "hyperparams.HParams", "hyperparams.HParams", "hyperparams.HParams", "texar.utils.dtypes.is_callable", "texar.utils.dtypes.is_callable", "hyperparams._type_name", "hyperparams._type_name", "type", "ValueError", "hyperparams._type_name", "hyperparams._type_name"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.core.replay_memories.DequeReplayMemory.get", "home.repos.pwc.inspect_result.VegB_Text_Infilling.texar.hyperparams.HParams.items", "home.repos.pwc.inspect_result.VegB_Text_Infilling.texar.hyperparams.HParams.items", "home.repos.pwc.inspect_result.VegB_Text_Infilling.texar.hyperparams.HParams._parse", "home.repos.pwc.inspect_result.VegB_Text_Infilling.texar.hyperparams.HParams._parse_value", "home.repos.pwc.inspect_result.VegB_Text_Infilling.texar.hyperparams.HParams._parse_value", "home.repos.pwc.inspect_result.VegB_Text_Infilling.texar.hyperparams.HParams._parse_value", "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.dtypes.is_callable", "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.dtypes.is_callable", "home.repos.pwc.inspect_result.VegB_Text_Infilling.texar.hyperparams._type_name", "home.repos.pwc.inspect_result.VegB_Text_Infilling.texar.hyperparams._type_name", "home.repos.pwc.inspect_result.VegB_Text_Infilling.texar.hyperparams._type_name", "home.repos.pwc.inspect_result.VegB_Text_Infilling.texar.hyperparams._type_name"], ["", "@", "staticmethod", "\n", "def", "_parse", "(", "hparams", ",", "# pylint: disable=too-many-branches, too-many-statements", "\n", "default_hparams", ",", "\n", "allow_new_hparam", "=", "False", ")", ":", "\n", "        ", "\"\"\"Parses hyperparameters.\n\n        Args:\n            hparams (dict): Hyperparameters. If `None`, all hyperparameters are\n                set to default values.\n            default_hparams (dict): Hyperparameters with default values.\n                If `None`,Hyperparameters are fully defined by :attr:`hparams`.\n            allow_new_hparam (bool): If `False` (default), :attr:`hparams`\n                cannot contain hyperparameters that are not included in\n                :attr:`default_hparams`, except the case of :attr:`\"kwargs\"`.\n\n        Return:\n            A dictionary of parsed hyperparameters. Returns `None` if both\n            :attr:`hparams` and :attr:`default_hparams` are `None`.\n\n        Raises:\n            ValueError: If :attr:`hparams` is not `None` and\n                :attr:`default_hparams` is `None`.\n            ValueError: If :attr:`default_hparams` contains \"kwargs\" not does\n                not contains \"type\".\n        \"\"\"", "\n", "if", "hparams", "is", "None", "and", "default_hparams", "is", "None", ":", "\n", "            ", "return", "None", "\n", "\n", "", "if", "hparams", "is", "None", ":", "\n", "            ", "return", "HParams", ".", "_parse", "(", "default_hparams", ",", "default_hparams", ")", "\n", "\n", "", "if", "default_hparams", "is", "None", ":", "\n", "            ", "raise", "ValueError", "(", "\"`default_hparams` cannot be `None` if `hparams` \"", "\n", "\"is not `None`.\"", ")", "\n", "", "no_typecheck_names", "=", "default_hparams", ".", "get", "(", "\"@no_typecheck\"", ",", "[", "]", ")", "\n", "\n", "if", "\"kwargs\"", "in", "default_hparams", "and", "\"type\"", "not", "in", "default_hparams", ":", "\n", "            ", "raise", "ValueError", "(", "\"Ill-defined hyperparameter structure: 'kwargs' \"", "\n", "\"must accompany with 'type'.\"", ")", "\n", "\n", "", "parsed_hparams", "=", "copy", ".", "deepcopy", "(", "default_hparams", ")", "\n", "\n", "# Parse recursively for params of type dictionary that are missing", "\n", "# in `hparams`.", "\n", "for", "name", ",", "value", "in", "default_hparams", ".", "items", "(", ")", ":", "\n", "            ", "if", "name", "not", "in", "hparams", "and", "isinstance", "(", "value", ",", "dict", ")", ":", "\n", "                ", "if", "name", "==", "\"kwargs\"", "and", "\"type\"", "in", "hparams", "and", "hparams", "[", "\"type\"", "]", "!=", "default_hparams", "[", "\"type\"", "]", ":", "\n", "# Set params named \"kwargs\" to empty dictionary if \"type\"", "\n", "# takes value other than default.", "\n", "                    ", "parsed_hparams", "[", "name", "]", "=", "HParams", "(", "{", "}", ",", "{", "}", ")", "\n", "", "else", ":", "\n", "                    ", "parsed_hparams", "[", "name", "]", "=", "HParams", "(", "value", ",", "value", ")", "\n", "\n", "# Parse hparams", "\n", "", "", "", "for", "name", ",", "value", "in", "hparams", ".", "items", "(", ")", ":", "\n", "            ", "if", "name", "not", "in", "default_hparams", ":", "\n", "                ", "if", "allow_new_hparam", ":", "\n", "                    ", "parsed_hparams", "[", "name", "]", "=", "HParams", ".", "_parse_value", "(", "value", ",", "name", ")", "\n", "continue", "\n", "", "else", ":", "\n", "                    ", "raise", "ValueError", "(", "\n", "\"Unknown hyperparameter: %s. Only hyperparameters \"", "\n", "\"named 'kwargs' hyperparameters can contain new \"", "\n", "\"entries undefined in default hyperparameters.\"", "%", "name", ")", "\n", "\n", "", "", "if", "value", "is", "None", ":", "\n", "                ", "parsed_hparams", "[", "name", "]", "=", "HParams", ".", "_parse_value", "(", "parsed_hparams", "[", "name", "]", ")", "\n", "\n", "", "default_value", "=", "default_hparams", "[", "name", "]", "\n", "if", "default_value", "is", "None", ":", "\n", "                ", "parsed_hparams", "[", "name", "]", "=", "HParams", ".", "_parse_value", "(", "value", ")", "\n", "continue", "\n", "\n", "# Parse recursively for params of type dictionary.", "\n", "", "if", "isinstance", "(", "value", ",", "dict", ")", ":", "\n", "                ", "if", "name", "not", "in", "no_typecheck_names", "and", "not", "isinstance", "(", "default_value", ",", "dict", ")", ":", "\n", "                    ", "raise", "ValueError", "(", "\n", "\"Hyperparameter '%s' must have type %s, got %s\"", "%", "\n", "(", "name", ",", "_type_name", "(", "default_value", ")", ",", "_type_name", "(", "value", ")", ")", ")", "\n", "", "if", "name", "==", "\"kwargs\"", ":", "\n", "                    ", "if", "\"type\"", "in", "hparams", "and", "hparams", "[", "\"type\"", "]", "!=", "default_hparams", "[", "\"type\"", "]", ":", "\n", "# Leave \"kwargs\" as-is if \"type\" takes value", "\n", "# other than default.", "\n", "                        ", "parsed_hparams", "[", "name", "]", "=", "HParams", "(", "value", ",", "value", ")", "\n", "", "else", ":", "\n", "# Allow new hyperparameters if \"type\" takes default", "\n", "# value", "\n", "                        ", "parsed_hparams", "[", "name", "]", "=", "HParams", "(", "\n", "value", ",", "default_value", ",", "allow_new_hparam", "=", "True", ")", "\n", "", "", "elif", "name", "in", "no_typecheck_names", ":", "\n", "                    ", "parsed_hparams", "[", "name", "]", "=", "HParams", "(", "value", ",", "value", ")", "\n", "", "else", ":", "\n", "                    ", "parsed_hparams", "[", "name", "]", "=", "HParams", "(", "\n", "value", ",", "default_value", ",", "allow_new_hparam", ")", "\n", "", "continue", "\n", "\n", "# Do not type-check hyperparameter named \"type\" and accompanied", "\n", "# with \"kwargs\"", "\n", "", "if", "name", "==", "\"type\"", "and", "\"kwargs\"", "in", "default_hparams", ":", "\n", "                ", "parsed_hparams", "[", "name", "]", "=", "value", "\n", "continue", "\n", "\n", "", "if", "name", "in", "no_typecheck_names", ":", "\n", "                ", "parsed_hparams", "[", "name", "]", "=", "value", "\n", "", "elif", "isinstance", "(", "value", ",", "type", "(", "default_value", ")", ")", ":", "\n", "                ", "parsed_hparams", "[", "name", "]", "=", "value", "\n", "", "elif", "is_callable", "(", "value", ")", "and", "is_callable", "(", "default_value", ")", ":", "\n", "                ", "parsed_hparams", "[", "name", "]", "=", "value", "\n", "", "else", ":", "\n", "                ", "try", ":", "\n", "                    ", "parsed_hparams", "[", "name", "]", "=", "type", "(", "default_value", ")", "(", "value", ")", "\n", "", "except", "TypeError", ":", "\n", "                    ", "raise", "ValueError", "(", "\n", "\"Hyperparameter '%s' must have type %s, got %s\"", "%", "\n", "(", "name", ",", "_type_name", "(", "default_value", ")", ",", "_type_name", "(", "value", ")", ")", ")", "\n", "\n", "", "", "", "return", "parsed_hparams", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.texar.hyperparams.HParams._parse_value": [[199, 205], ["isinstance", "hyperparams.HParams"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_parse_value", "(", "value", ",", "name", "=", "None", ")", ":", "\n", "        ", "if", "isinstance", "(", "value", ",", "dict", ")", "and", "(", "name", "is", "None", "or", "name", "!=", "\"kwargs\"", ")", ":", "\n", "            ", "return", "HParams", "(", "value", ",", "None", ")", "\n", "", "else", ":", "\n", "            ", "return", "value", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.texar.hyperparams.HParams.__getattr__": [[206, 215], ["object.__getattribute__", "AttributeError"], "methods", ["None"], ["", "", "def", "__getattr__", "(", "self", ",", "name", ")", ":", "\n", "        ", "\"\"\"Retrieves the value of the hyperparameter.\n        \"\"\"", "\n", "if", "name", "==", "'_hparams'", ":", "\n", "            ", "return", "super", "(", "HParams", ",", "self", ")", ".", "__getattribute__", "(", "'_hparams'", ")", "\n", "", "if", "name", "not", "in", "self", ".", "_hparams", ":", "\n", "# Raise AttributeError to allow copy.deepcopy, etc", "\n", "            ", "raise", "AttributeError", "(", "\"Unknown hyperparameter: %s\"", "%", "name", ")", "\n", "", "return", "self", ".", "_hparams", "[", "name", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.texar.hyperparams.HParams.__getitem__": [[216, 220], ["hyperparams.HParams.__getattr__"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.texar.hyperparams.HParams.__getattr__"], ["", "def", "__getitem__", "(", "self", ",", "name", ")", ":", "\n", "        ", "\"\"\"Retrieves the value of the hyperparameter.\n        \"\"\"", "\n", "return", "self", ".", "__getattr__", "(", "name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.texar.hyperparams.HParams.__setattr__": [[221, 230], ["hyperparams.HParams._parse_value", "ValueError"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.texar.hyperparams.HParams._parse_value"], ["", "def", "__setattr__", "(", "self", ",", "name", ",", "value", ")", ":", "\n", "        ", "\"\"\"Sets the value of the hyperparameter.\n        \"\"\"", "\n", "if", "name", "not", "in", "self", ".", "_hparams", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "\"Unknown hyperparameter: %s. Only the `kwargs` \"", "\n", "\"hyperparameters can contain new entries undefined \"", "\n", "\"in default hyperparameters.\"", "%", "name", ")", "\n", "", "self", ".", "_hparams", "[", "name", "]", "=", "self", ".", "_parse_value", "(", "value", ",", "name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.texar.hyperparams.HParams.items": [[231, 235], ["iter"], "methods", ["None"], ["", "def", "items", "(", "self", ")", ":", "\n", "        ", "\"\"\"Returns the list of hyperparam `(name, value)` pairs\n        \"\"\"", "\n", "return", "iter", "(", "self", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.texar.hyperparams.HParams.keys": [[236, 240], ["hyperparams.HParams._hparams.keys"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.texar.hyperparams.HParams.keys"], ["", "def", "keys", "(", "self", ")", ":", "\n", "        ", "\"\"\"Returns the list of hyperparam names\n        \"\"\"", "\n", "return", "self", ".", "_hparams", ".", "keys", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.texar.hyperparams.HParams.__iter__": [[241, 244], ["hyperparams.HParams._hparams.items"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.texar.hyperparams.HParams.items"], ["", "def", "__iter__", "(", "self", ")", ":", "\n", "        ", "for", "name", ",", "value", "in", "self", ".", "_hparams", ".", "items", "(", ")", ":", "\n", "            ", "yield", "name", ",", "value", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.texar.hyperparams.HParams.__len__": [[245, 247], ["len"], "methods", ["None"], ["", "", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "_hparams", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.texar.hyperparams.HParams.__contains__": [[248, 250], ["None"], "methods", ["None"], ["", "def", "__contains__", "(", "self", ",", "name", ")", ":", "\n", "        ", "return", "name", "in", "self", ".", "_hparams", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.texar.hyperparams.HParams.__str__": [[251, 256], ["hyperparams.HParams.todict", "json.dumps"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.texar.hyperparams.HParams.todict"], ["", "def", "__str__", "(", "self", ")", ":", "\n", "        ", "\"\"\"Return a string of the hparams.\n        \"\"\"", "\n", "hparams_dict", "=", "self", ".", "todict", "(", ")", "\n", "return", "json", ".", "dumps", "(", "hparams_dict", ",", "sort_keys", "=", "True", ",", "indent", "=", "2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.texar.hyperparams.HParams.get": [[257, 269], ["hyperparams.HParams.__getattr__"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.texar.hyperparams.HParams.__getattr__"], ["", "def", "get", "(", "self", ",", "name", ",", "default", "=", "None", ")", ":", "\n", "        ", "\"\"\"Returns the hyperparameter value for the given name. If name is not\n        available then returns :attr:`default`.\n\n        Args:\n            name (str): the name of hyperparameter.\n            default: the value to be returned in case name does not exist.\n        \"\"\"", "\n", "try", ":", "\n", "            ", "return", "self", ".", "__getattr__", "(", "name", ")", "\n", "", "except", "AttributeError", ":", "\n", "            ", "return", "default", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.texar.hyperparams.HParams.add_hparam": [[270, 276], ["hyperparams.HParams._parse_value", "hasattr", "ValueError"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.texar.hyperparams.HParams._parse_value"], ["", "", "def", "add_hparam", "(", "self", ",", "name", ",", "value", ")", ":", "\n", "        ", "\"\"\"Adds a new hyperparameter.\n        \"\"\"", "\n", "if", "(", "name", "in", "self", ".", "_hparams", ")", "or", "hasattr", "(", "self", ",", "name", ")", ":", "\n", "            ", "raise", "ValueError", "(", "\"Hyperparameter name already exists: %s\"", "%", "name", ")", "\n", "", "self", ".", "_hparams", "[", "name", "]", "=", "self", ".", "_parse_value", "(", "value", ",", "name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.texar.hyperparams.HParams.todict": [[277, 285], ["copy.deepcopy", "hyperparams.HParams._hparams.items", "isinstance", "value.todict"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.texar.hyperparams.HParams.items", "home.repos.pwc.inspect_result.VegB_Text_Infilling.texar.hyperparams.HParams.todict"], ["", "def", "todict", "(", "self", ")", ":", "\n", "        ", "\"\"\"Returns a copy of hyperparameters as a dictionary.\n        \"\"\"", "\n", "dict_", "=", "copy", ".", "deepcopy", "(", "self", ".", "_hparams", ")", "\n", "for", "name", ",", "value", "in", "self", ".", "_hparams", ".", "items", "(", ")", ":", "\n", "            ", "if", "isinstance", "(", "value", ",", "HParams", ")", ":", "\n", "                ", "dict_", "[", "name", "]", "=", "value", ".", "todict", "(", ")", "\n", "", "", "return", "dict_", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.texar.hyperparams._type_name": [[19, 21], ["type"], "function", ["None"], ["def", "_type_name", "(", "value", ")", ":", "\n", "    ", "return", "type", "(", "value", ")", ".", "__name__", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.evals.metrics.accuracy": [[17, 30], ["tensorflow.cast", "tensorflow.reduce_mean", "tensorflow.to_float", "tensorflow.equal"], "function", ["None"], ["def", "accuracy", "(", "labels", ",", "preds", ")", ":", "\n", "    ", "\"\"\"Calculates the accuracy of predictions.\n\n    Args:\n        labels: The ground truth values. A Tensor of the same shape of\n            :attr:`preds`.\n        preds: A Tensor of any shape containing the predicted values.\n\n    Returns:\n        A float scalar Tensor containing the accuracy.\n    \"\"\"", "\n", "labels", "=", "tf", ".", "cast", "(", "labels", ",", "preds", ".", "dtype", ")", "\n", "return", "tf", ".", "reduce_mean", "(", "tf", ".", "to_float", "(", "tf", ".", "equal", "(", "preds", ",", "labels", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.evals.metrics.binary_clas_accuracy": [[31, 51], ["metrics.accuracy", "metrics.accuracy", "tensorflow.to_float", "tensorflow.to_float", "tensorflow.ones_like", "tensorflow.zeros_like", "tensorflow.size", "tensorflow.size"], "function", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.evals.metrics.accuracy", "home.repos.pwc.inspect_result.VegB_Text_Infilling.evals.metrics.accuracy", "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.vocabulary.Vocab.size", "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.vocabulary.Vocab.size"], ["", "def", "binary_clas_accuracy", "(", "pos_preds", "=", "None", ",", "neg_preds", "=", "None", ")", ":", "\n", "    ", "\"\"\"Calculates the accuracy of binary predictions.\n\n    Args:\n        pos_preds (optional): A Tensor of any shape containing the\n            predicted values on positive data (i.e., ground truth labels are\n            `1`).\n        neg_preds (optional): A Tensor of any shape containing the\n            predicted values on negative data (i.e., ground truth labels are\n            `0`).\n\n    Returns:\n        A float scalar Tensor containing the accuracy.\n    \"\"\"", "\n", "pos_accu", "=", "accuracy", "(", "tf", ".", "ones_like", "(", "pos_preds", ")", ",", "pos_preds", ")", "\n", "neg_accu", "=", "accuracy", "(", "tf", ".", "zeros_like", "(", "neg_preds", ")", ",", "neg_preds", ")", "\n", "psize", "=", "tf", ".", "to_float", "(", "tf", ".", "size", "(", "pos_preds", ")", ")", "\n", "nsize", "=", "tf", ".", "to_float", "(", "tf", ".", "size", "(", "neg_preds", ")", ")", "\n", "accu", "=", "(", "pos_accu", "*", "psize", "+", "neg_accu", "*", "nsize", ")", "/", "(", "psize", "+", "nsize", ")", "\n", "return", "accu", "\n", "", ""]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.evals.bleu._get_ngrams": [[47, 65], ["collections.Counter", "range", "range", "tuple", "len"], "function", ["None"], ["def", "_get_ngrams", "(", "segment", ",", "max_order", ")", ":", "\n", "    ", "\"\"\"Extracts all n-grams up to a given maximum order from an input segment.\n\n    Args:\n        segment: text segment from which n-grams will be extracted.\n        max_order: maximum length in tokens of the n-grams returned by this\n            methods.\n\n    Returns:\n        The Counter containing all n-grams upto max_order in segment\n        with a count of how many times each n-gram occurred.\n    \"\"\"", "\n", "ngram_counts", "=", "collections", ".", "Counter", "(", ")", "\n", "for", "order", "in", "range", "(", "1", ",", "max_order", "+", "1", ")", ":", "\n", "        ", "for", "i", "in", "range", "(", "0", ",", "len", "(", "segment", ")", "-", "order", "+", "1", ")", ":", "\n", "            ", "ngram", "=", "tuple", "(", "segment", "[", "i", ":", "i", "+", "order", "]", ")", "\n", "ngram_counts", "[", "ngram", "]", "+=", "1", "\n", "", "", "return", "ngram_counts", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.evals.bleu._maybe_str_to_list": [[66, 70], ["texar.utils.dtypes.is_str", "list_or_str.split"], "function", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.dtypes.is_str"], ["", "def", "_maybe_str_to_list", "(", "list_or_str", ")", ":", "\n", "    ", "if", "is_str", "(", "list_or_str", ")", ":", "\n", "        ", "return", "list_or_str", ".", "split", "(", ")", "\n", "", "return", "list_or_str", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.evals.bleu._lowercase": [[71, 73], ["str_.lower"], "function", ["None"], ["", "def", "_lowercase", "(", "str_list", ")", ":", "\n", "    ", "return", "[", "str_", ".", "lower", "(", ")", "for", "str_", "in", "str_list", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.evals.bleu.sentence_bleu": [[74, 103], ["bleu.corpus_bleu"], "function", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.evals.bleu.corpus_bleu"], ["", "def", "sentence_bleu", "(", "references", ",", "hypothesis", ",", "max_order", "=", "4", ",", "lowercase", "=", "False", ",", "\n", "smooth", "=", "False", ",", "return_all", "=", "False", ")", ":", "\n", "    ", "\"\"\"Calculates BLEU score of a hypothesis sentence.\n\n    Args:\n        references: A list of reference for the hypothesis.\n            Each reference can be either a list of string tokens, or a string\n            containing tokenized tokens separated with whitespaces.\n            List can also be numpy array.\n        hypotheses: A hypothesis sentence.\n            Each hypothesis can be either a list of string tokens, or a\n            string containing tokenized tokens separated with whitespaces.\n            List can also be numpy array.\n        lowercase (bool): If `True`, pass the \"-lc\" flag to the multi-bleu\n            script.\n        max_order (int): Maximum n-gram order to use when computing BLEU score.\n        smooth (bool): Whether or not to apply (Lin et al. 2004) smoothing.\n        return_all (bool): If `True`, returns BLEU and all n-gram precisions.\n\n    Returns:\n        If :attr:`return_all` is `False` (default), returns a float32\n        BLEU score.\n\n        If :attr:`return_all` is `True`, returns a list of float32 scores:\n        `[BLEU] + n-gram precisions`, which is of length :attr:`max_order`+1.\n    \"\"\"", "\n", "return", "corpus_bleu", "(", "\n", "[", "references", "]", ",", "[", "hypothesis", "]", ",", "max_order", "=", "max_order", ",", "lowercase", "=", "lowercase", ",", "\n", "smooth", "=", "smooth", ",", "return_all", "=", "return_all", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.evals.bleu.corpus_bleu": [[104, 194], ["texar.utils.dtypes.compat_as_text", "texar.utils.dtypes.compat_as_text", "zip", "range", "min", "len", "collections.Counter", "bleu._maybe_str_to_list", "bleu._get_ngrams", "range", "min", "sum", "math.exp", "float", "bleu._maybe_str_to_list", "bleu._get_ngrams", "bleu._lowercase", "math.exp", "len", "bleu._lowercase", "math.exp", "len", "float", "math.log", "len"], "function", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.dtypes.compat_as_text", "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.dtypes.compat_as_text", "home.repos.pwc.inspect_result.VegB_Text_Infilling.evals.bleu._maybe_str_to_list", "home.repos.pwc.inspect_result.VegB_Text_Infilling.text_infilling.bleu_tool._get_ngrams", "home.repos.pwc.inspect_result.VegB_Text_Infilling.evals.bleu._maybe_str_to_list", "home.repos.pwc.inspect_result.VegB_Text_Infilling.text_infilling.bleu_tool._get_ngrams", "home.repos.pwc.inspect_result.VegB_Text_Infilling.evals.bleu._lowercase", "home.repos.pwc.inspect_result.VegB_Text_Infilling.evals.bleu._lowercase"], ["", "def", "corpus_bleu", "(", "list_of_references", ",", "hypotheses", ",", "max_order", "=", "4", ",", "lowercase", "=", "False", ",", "\n", "smooth", "=", "False", ",", "return_all", "=", "True", ")", ":", "\n", "    ", "\"\"\"Computes corpus-level BLEU score.\n\n    Args:\n        list_of_references: A list of lists of references for each hypothesis.\n            Each reference can be either a list of string tokens, or a string\n            containing tokenized tokens separated with whitespaces.\n            List can also be numpy array.\n        hypotheses: A list of hypothesis sentences.\n            Each hypothesis can be either a list of string tokens, or a\n            string containing tokenized tokens separated with whitespaces.\n            List can also be numpy array.\n        lowercase (bool): If `True`, lowercase reference and hypothesis tokens.\n        max_order (int): Maximum n-gram order to use when computing BLEU score.\n        smooth (bool): Whether or not to apply (Lin et al. 2004) smoothing.\n        return_all (bool): If `True`, returns BLEU and all n-gram precisions.\n\n    Returns:\n        If :attr:`return_all` is `False` (default), returns a float32\n        BLEU score.\n\n        If :attr:`return_all` is `True`, returns a list of float32 scores:\n        `[BLEU] + n-gram precisions`, which is of length :attr:`max_order`+1.\n    \"\"\"", "\n", "list_of_references", "=", "compat_as_text", "(", "list_of_references", ")", "\n", "hypotheses", "=", "compat_as_text", "(", "hypotheses", ")", "\n", "\n", "matches_by_order", "=", "[", "0", "]", "*", "max_order", "\n", "possible_matches_by_order", "=", "[", "0", "]", "*", "max_order", "\n", "reference_length", "=", "0", "\n", "hyperthsis_length", "=", "0", "\n", "for", "(", "references", ",", "hyperthsis", ")", "in", "zip", "(", "list_of_references", ",", "hypotheses", ")", ":", "\n", "        ", "reference_length", "+=", "min", "(", "len", "(", "r", ")", "for", "r", "in", "references", ")", "\n", "hyperthsis_length", "+=", "len", "(", "hyperthsis", ")", "\n", "\n", "merged_ref_ngram_counts", "=", "collections", ".", "Counter", "(", ")", "\n", "for", "reference", "in", "references", ":", "\n", "            ", "reference", "=", "_maybe_str_to_list", "(", "reference", ")", "\n", "if", "lowercase", ":", "\n", "                ", "reference", "=", "_lowercase", "(", "reference", ")", "\n", "", "merged_ref_ngram_counts", "|=", "_get_ngrams", "(", "reference", ",", "max_order", ")", "\n", "\n", "", "hyperthsis", "=", "_maybe_str_to_list", "(", "hyperthsis", ")", "\n", "if", "lowercase", ":", "\n", "            ", "hyperthsis", "=", "_lowercase", "(", "hyperthsis", ")", "\n", "", "hyperthsis_ngram_counts", "=", "_get_ngrams", "(", "hyperthsis", ",", "max_order", ")", "\n", "\n", "overlap", "=", "hyperthsis_ngram_counts", "&", "merged_ref_ngram_counts", "\n", "for", "ngram", "in", "overlap", ":", "\n", "            ", "matches_by_order", "[", "len", "(", "ngram", ")", "-", "1", "]", "+=", "overlap", "[", "ngram", "]", "\n", "", "for", "order", "in", "range", "(", "1", ",", "max_order", "+", "1", ")", ":", "\n", "            ", "possible_matches", "=", "len", "(", "hyperthsis", ")", "-", "order", "+", "1", "\n", "if", "possible_matches", ">", "0", ":", "\n", "                ", "possible_matches_by_order", "[", "order", "-", "1", "]", "+=", "possible_matches", "\n", "\n", "", "", "", "precisions", "=", "[", "0", "]", "*", "max_order", "\n", "for", "i", "in", "range", "(", "0", ",", "max_order", ")", ":", "\n", "        ", "if", "smooth", ":", "\n", "            ", "precisions", "[", "i", "]", "=", "(", "(", "matches_by_order", "[", "i", "]", "+", "1.", ")", "/", "\n", "(", "possible_matches_by_order", "[", "i", "]", "+", "1.", ")", ")", "\n", "", "else", ":", "\n", "            ", "if", "possible_matches_by_order", "[", "i", "]", ">", "0", ":", "\n", "                ", "precisions", "[", "i", "]", "=", "(", "float", "(", "matches_by_order", "[", "i", "]", ")", "/", "\n", "possible_matches_by_order", "[", "i", "]", ")", "\n", "", "else", ":", "\n", "                ", "precisions", "[", "i", "]", "=", "0.0", "\n", "\n", "", "", "", "if", "min", "(", "precisions", ")", ">", "0", ":", "\n", "        ", "p_log_sum", "=", "sum", "(", "(", "1.", "/", "max_order", ")", "*", "math", ".", "log", "(", "p", ")", "for", "p", "in", "precisions", ")", "\n", "geo_mean", "=", "math", ".", "exp", "(", "p_log_sum", ")", "\n", "", "else", ":", "\n", "        ", "geo_mean", "=", "0", "\n", "\n", "", "ratio", "=", "float", "(", "hyperthsis_length", ")", "/", "reference_length", "\n", "\n", "if", "ratio", ">", "1.0", ":", "\n", "        ", "bp", "=", "1.", "\n", "", "else", ":", "\n", "        ", "try", ":", "\n", "            ", "bp", "=", "math", ".", "exp", "(", "1", "-", "1.", "/", "ratio", ")", "\n", "", "except", "ZeroDivisionError", ":", "\n", "            ", "bp", "=", "math", ".", "exp", "(", "1", "-", "1.", "/", "(", "ratio", "+", "1e-8", ")", ")", "\n", "\n", "", "", "bleu", "=", "geo_mean", "*", "bp", "\n", "\n", "if", "return_all", ":", "\n", "        ", "return", "[", "bleu", "*", "100", "]", "+", "[", "p", "*", "100", "for", "p", "in", "precisions", "]", "\n", "", "else", ":", "\n", "        ", "return", "bleu", "*", "100", "\n", "", "", ""]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.evals.bleu_moses._maybe_list_to_str": [[30, 34], ["isinstance"], "function", ["None"], ["def", "_maybe_list_to_str", "(", "list_or_str", ")", ":", "\n", "    ", "if", "isinstance", "(", "list_or_str", ",", "(", "tuple", ",", "list", ",", "np", ".", "ndarray", ")", ")", ":", "\n", "        ", "return", "' '", ".", "join", "(", "list_or_str", ")", "\n", "", "return", "list_or_str", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.evals.bleu_moses._parse_multi_bleu_ret": [[35, 46], ["re.search().group", "numpy.float32", "re.search", "re.search", "re.search.group", "numpy.float32", "range"], "function", ["None"], ["", "def", "_parse_multi_bleu_ret", "(", "bleu_str", ",", "return_all", "=", "False", ")", ":", "\n", "    ", "bleu_score", "=", "re", ".", "search", "(", "r\"BLEU = (.+?),\"", ",", "bleu_str", ")", ".", "group", "(", "1", ")", "\n", "bleu_score", "=", "np", ".", "float32", "(", "bleu_score", ")", "\n", "\n", "if", "return_all", ":", "\n", "        ", "bleus", "=", "re", ".", "search", "(", "r\", (.+?)/(.+?)/(.+?)/(.+?) \"", ",", "bleu_str", ")", "\n", "bleus", "=", "[", "bleus", ".", "group", "(", "group_idx", ")", "for", "group_idx", "in", "range", "(", "1", ",", "5", ")", "]", "\n", "bleus", "=", "[", "np", ".", "float32", "(", "b", ")", "for", "b", "in", "bleus", "]", "\n", "bleu_score", "=", "[", "bleu_score", "]", "+", "bleus", "\n", "\n", "", "return", "bleu_score", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.evals.bleu_moses.sentence_bleu_moses": [[47, 72], ["bleu_moses.corpus_bleu_moses"], "function", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.evals.bleu_moses.corpus_bleu_moses"], ["", "def", "sentence_bleu_moses", "(", "references", ",", "hypothesis", ",", "lowercase", "=", "False", ",", "\n", "return_all", "=", "False", ")", ":", "\n", "    ", "\"\"\"Calculates BLEU score of a hypothesis sentence using the MOSES\n    multi-bleu.perl script.\n\n    Args:\n        references: A list of reference for the hypothesis.\n            Each reference can be either a string, or a list of string tokens.\n            List can also be numpy array.\n        hypotheses: A hypothesis sentence.\n            The hypothesis can be either a string, or a list of string tokens.\n            List can also be numpy array.\n        lowercase (bool): If `True`, pass the \"-lc\" flag to the multi-bleu\n            script.\n        return_all (bool): If `True`, returns BLEU and all n-gram precisions.\n\n    Returns:\n        If :attr:`return_all` is `False` (default), returns a float32\n        BLEU score.\n\n        If :attr:`return_all` is `True`, returns a list of 5 float32 scores:\n        `[BLEU, 1-gram precision, ..., 4-gram precision]`.\n    \"\"\"", "\n", "return", "corpus_bleu_moses", "(", "\n", "[", "references", "]", ",", "[", "hypothesis", "]", ",", "lowercase", "=", "lowercase", ",", "return_all", "=", "return_all", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.evals.bleu_moses.corpus_bleu_moses": [[73, 152], ["texar.utils.dtypes.compat_as_text", "texar.utils.dtypes.compat_as_text", "os.path.dirname", "os.path.abspath", "tempfile.mkdtemp", "os.path.join", "max", "os.path.join", "range", "shutil.rmtree", "numpy.float32", "numpy.size", "numpy.float32", "os.path.realpath", "os.path.join", "bleu_moses._maybe_list_to_str", "io.open", "hfile.write", "hfile.write", "io.open", "len", "io.open", "subprocess.check_output", "multi_bleu_ret.decode.decode", "bleu_moses._parse_multi_bleu_ret", "len", "bleu_moses._maybe_list_to_str", "rfile.write", "rfile.write", "tensorflow.logging.warning", "tensorflow.logging.warning", "numpy.float32", "numpy.float32"], "function", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.dtypes.compat_as_text", "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.dtypes.compat_as_text", "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.vocabulary.Vocab.size", "home.repos.pwc.inspect_result.VegB_Text_Infilling.evals.bleu_moses._maybe_list_to_str", "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.data_decoders.VarUttTextDataDecoder.decode", "home.repos.pwc.inspect_result.VegB_Text_Infilling.evals.bleu_moses._parse_multi_bleu_ret", "home.repos.pwc.inspect_result.VegB_Text_Infilling.evals.bleu_moses._maybe_list_to_str"], ["", "def", "corpus_bleu_moses", "(", "list_of_references", ",", "hypotheses", ",", "lowercase", "=", "False", ",", "\n", "return_all", "=", "False", ")", ":", "\n", "    ", "\"\"\"Calculates corpus-level BLEU score using the MOSES\n    multi-bleu.perl script.\n\n    Args:\n        list_of_references: A list of lists of references for each hypothesis.\n            Each reference can be either a string, or a list of string tokens.\n            List can also be numpy array.\n        hypotheses: A list of hypothesis sentences.\n            Each hyperthsis can be either a string, or a list of string tokens.\n            List can also be numpy array.\n        lowercase (bool): If `True`, pass the \"-lc\" flag to the multi-bleu\n            script.\n        return_all (bool): If `True`, returns BLEU and all n-gram precisions.\n\n    Returns:\n        If :attr:`return_all` is `False` (default), returns a float32\n        BLEU score.\n\n        If :attr:`return_all` is `True`, returns a list of 5 float32 scores:\n        `[BLEU, 1-gram precision, ..., 4-gram precision]`.\n    \"\"\"", "\n", "list_of_references", "=", "compat_as_text", "(", "list_of_references", ")", "\n", "hypotheses", "=", "compat_as_text", "(", "hypotheses", ")", "\n", "\n", "if", "np", ".", "size", "(", "hypotheses", ")", "==", "0", ":", "\n", "        ", "return", "np", ".", "float32", "(", "0.", ")", "# pylint: disable=no-member", "\n", "\n", "# Get multi-bleu.perl", "\n", "", "cur_dir", "=", "os", ".", "path", ".", "dirname", "(", "os", ".", "path", ".", "realpath", "(", "__file__", ")", ")", "\n", "multi_bleu_path", "=", "os", ".", "path", ".", "abspath", "(", "\n", "os", ".", "path", ".", "join", "(", "cur_dir", ",", "\"..\"", ",", "\"..\"", ",", "\"bin\"", ",", "\"utils\"", ",", "\"multi-bleu.perl\"", ")", ")", "\n", "\n", "# Create a temporary folder containing hyperthesis and reference files", "\n", "result_path", "=", "tempfile", ".", "mkdtemp", "(", ")", "\n", "# Create hyperthesis file", "\n", "hfile_path", "=", "os", ".", "path", ".", "join", "(", "result_path", ",", "'hyp'", ")", "\n", "hyps", "=", "[", "_maybe_list_to_str", "(", "h", ")", "for", "h", "in", "hypotheses", "]", "\n", "with", "open", "(", "hfile_path", ",", "'w'", ",", "encoding", "=", "'utf-8'", ")", "as", "hfile", ":", "\n", "        ", "text", "=", "\"\\n\"", ".", "join", "(", "hyps", ")", "\n", "hfile", ".", "write", "(", "text", ")", "\n", "hfile", ".", "write", "(", "\"\\n\"", ")", "\n", "# Create reference files", "\n", "", "max_nrefs", "=", "max", "(", "[", "len", "(", "refs", ")", "for", "refs", "in", "list_of_references", "]", ")", "\n", "rfile_path", "=", "os", ".", "path", ".", "join", "(", "result_path", ",", "'ref'", ")", "\n", "for", "rid", "in", "range", "(", "max_nrefs", ")", ":", "\n", "        ", "with", "open", "(", "rfile_path", "+", "'%d'", "%", "rid", ",", "'w'", ",", "encoding", "=", "'utf-8'", ")", "as", "rfile", ":", "\n", "            ", "for", "refs", "in", "list_of_references", ":", "\n", "                ", "if", "rid", "<", "len", "(", "refs", ")", ":", "\n", "                    ", "ref", "=", "_maybe_list_to_str", "(", "refs", "[", "rid", "]", ")", "\n", "rfile", ".", "write", "(", "ref", "+", "\"\\n\"", ")", "\n", "", "else", ":", "\n", "                    ", "rfile", ".", "write", "(", "\"\\n\"", ")", "\n", "\n", "# Calculate BLEU", "\n", "", "", "", "", "multi_bleu_cmd", "=", "[", "multi_bleu_path", "]", "\n", "if", "lowercase", ":", "\n", "        ", "multi_bleu_cmd", "+=", "[", "\"-lc\"", "]", "\n", "", "multi_bleu_cmd", "+=", "[", "rfile_path", "]", "\n", "with", "open", "(", "hfile_path", ",", "\"r\"", ")", "as", "hyp_input", ":", "\n", "        ", "try", ":", "\n", "            ", "multi_bleu_ret", "=", "subprocess", ".", "check_output", "(", "\n", "multi_bleu_cmd", ",", "stdin", "=", "hyp_input", ",", "stderr", "=", "subprocess", ".", "STDOUT", ")", "\n", "multi_bleu_ret", "=", "multi_bleu_ret", ".", "decode", "(", "\"utf-8\"", ")", "\n", "bleu_score", "=", "_parse_multi_bleu_ret", "(", "multi_bleu_ret", ",", "return_all", ")", "\n", "", "except", "subprocess", ".", "CalledProcessError", "as", "error", ":", "\n", "            ", "if", "error", ".", "output", "is", "not", "None", ":", "\n", "                ", "tf", ".", "logging", ".", "warning", "(", "\n", "\"multi-bleu.perl returned non-zero exit code\"", ")", "\n", "tf", ".", "logging", ".", "warning", "(", "error", ".", "output", ")", "\n", "", "if", "return_all", ":", "\n", "                ", "bleu_score", "=", "[", "np", ".", "float32", "(", "0.0", ")", "]", "*", "5", "\n", "", "else", ":", "\n", "                ", "bleu_score", "=", "np", ".", "float32", "(", "0.0", ")", "\n", "\n", "", "", "", "shutil", ".", "rmtree", "(", "result_path", ")", "\n", "\n", "return", "np", ".", "float32", "(", "bleu_score", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.evals.bleu_test.BLEUTest._test_sentence_bleu": [[25, 36], ["texar.evals.bleu_moses.sentence_bleu_moses", "bleu_test.BLEUTest.assertAlmostEqual", "texar.evals.bleu.sentence_bleu", "bleu_test.BLEUTest.assertAlmostEqual"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.evals.bleu_moses.sentence_bleu_moses", "home.repos.pwc.inspect_result.VegB_Text_Infilling.evals.bleu.sentence_bleu"], ["def", "_test_sentence_bleu", "(", "self", ",", "references", ",", "hypothesis", ",", "lowercase", ",", "\n", "true_bleu", ")", ":", "\n", "        ", "bleu", "=", "sentence_bleu_moses", "(", "references", "=", "references", ",", "\n", "hypothesis", "=", "hypothesis", ",", "\n", "lowercase", "=", "lowercase", ")", "\n", "self", ".", "assertAlmostEqual", "(", "bleu", ",", "true_bleu", ",", "places", "=", "2", ")", "\n", "\n", "bleu", "=", "sentence_bleu", "(", "references", "=", "references", ",", "\n", "hypothesis", "=", "hypothesis", ",", "\n", "lowercase", "=", "lowercase", ")", "\n", "self", ".", "assertAlmostEqual", "(", "bleu", ",", "true_bleu", ",", "places", "=", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.evals.bleu_test.BLEUTest.test_sentence_strings": [[37, 45], ["bleu_test.BLEUTest._test_sentence_bleu"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.evals.bleu_test.BLEUTest._test_sentence_bleu"], ["", "def", "test_sentence_strings", "(", "self", ")", ":", "\n", "        ", "\"\"\"Tests hypothesis as strings.\n        \"\"\"", "\n", "hypothesis", "=", "\"this is a test sentence to evaluate the good bleu score . \u8bcd\"", "\n", "references", "=", "[", "\"this is a test sentence to evaluate the bleu score .\"", "]", "\n", "self", ".", "_test_sentence_bleu", "(", "\n", "references", ",", "hypothesis", ",", "lowercase", "=", "False", ",", "true_bleu", "=", "67.03", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.evals.bleu_test.BLEUTest.test_sentence_list": [[46, 56], ["hypothesis.split.split.split", "bleu_test.BLEUTest._test_sentence_bleu", "references[].split"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.evals.bleu_test.BLEUTest._test_sentence_bleu"], ["", "def", "test_sentence_list", "(", "self", ")", ":", "\n", "        ", "\"\"\"Tests hypothesis as a list of tokens.\n        \"\"\"", "\n", "hypothesis", "=", "\"this is a test sentence to evaluate the good bleu score . \u8bcd\"", "\n", "hypothesis", "=", "hypothesis", ".", "split", "(", ")", "\n", "references", "=", "[", "\"this is a test sentence to evaluate the bleu score .\"", "]", "\n", "references", "=", "[", "references", "[", "0", "]", ".", "split", "(", ")", "]", "\n", "self", ".", "_test_sentence_bleu", "(", "\n", "references", ",", "hypothesis", ",", "lowercase", "=", "False", ",", "true_bleu", "=", "67.03", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.evals.bleu_test.BLEUTest.test_sentence_multi_references": [[57, 66], ["bleu_test.BLEUTest._test_sentence_bleu"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.evals.bleu_test.BLEUTest._test_sentence_bleu"], ["", "def", "test_sentence_multi_references", "(", "self", ")", ":", "\n", "        ", "\"\"\"Tests multiple references.\n        \"\"\"", "\n", "hypothesis", "=", "\"this is a test sentence to evaluate the good bleu score . \u8bcd\"", "\n", "references", "=", "[", "\"this is a test sentence to evaluate the bleu score .\"", ",", "\n", "\"this is a test sentence to evaluate the good score .\"", "]", "\n", "self", ".", "_test_sentence_bleu", "(", "\n", "references", ",", "hypothesis", ",", "lowercase", "=", "False", ",", "true_bleu", "=", "76.12", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.evals.bleu_test.BLEUTest.test_sentence_numpy": [[67, 78], ["numpy.array", "numpy.array", "bleu_test.BLEUTest._test_sentence_bleu", "numpy.array.split", "numpy.array", "r.split"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.evals.bleu_test.BLEUTest._test_sentence_bleu"], ["", "def", "test_sentence_numpy", "(", "self", ")", ":", "\n", "        ", "\"\"\"Tests with numpy format.\n        \"\"\"", "\n", "hypothesis", "=", "\"this is a test sentence to evaluate the good bleu score . \u8bcd\"", "\n", "hypothesis", "=", "np", ".", "array", "(", "hypothesis", ".", "split", "(", ")", ")", "\n", "references", "=", "[", "\"this is a test sentence to evaluate the bleu score .\"", ",", "\n", "\"this is a test sentence to evaluate the good score .\"", "]", "\n", "references", "=", "np", ".", "array", "(", "[", "np", ".", "array", "(", "r", ".", "split", "(", ")", ")", "for", "r", "in", "references", "]", ")", "\n", "self", ".", "_test_sentence_bleu", "(", "\n", "references", ",", "hypothesis", ",", "lowercase", "=", "False", ",", "true_bleu", "=", "76.12", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.evals.bleu_test.BLEUTest._test_corpus_bleu": [[80, 102], ["texar.evals.bleu_moses.corpus_bleu_moses", "texar.evals.bleu.corpus_bleu", "bleu_test.BLEUTest.assertAlmostEqual", "zip", "bleu_test.BLEUTest.assertAlmostEqual", "zip", "bleu_test.BLEUTest.assertAlmostEqual", "bleu_test.BLEUTest.assertAlmostEqual"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.evals.bleu_moses.corpus_bleu_moses", "home.repos.pwc.inspect_result.VegB_Text_Infilling.evals.bleu.corpus_bleu"], ["", "def", "_test_corpus_bleu", "(", "self", ",", "list_of_references", ",", "hypotheses", ",", "lowercase", ",", "\n", "return_all", ",", "true_bleu", ")", ":", "\n", "        ", "bleu", "=", "corpus_bleu_moses", "(", "list_of_references", "=", "list_of_references", ",", "\n", "hypotheses", "=", "hypotheses", ",", "\n", "lowercase", "=", "lowercase", ",", "\n", "return_all", "=", "return_all", ")", "\n", "if", "not", "return_all", ":", "\n", "            ", "self", ".", "assertAlmostEqual", "(", "bleu", ",", "true_bleu", ",", "places", "=", "2", ")", "\n", "", "else", ":", "\n", "            ", "for", "ret", ",", "true", "in", "zip", "(", "bleu", ",", "true_bleu", ")", ":", "\n", "                ", "self", ".", "assertAlmostEqual", "(", "ret", ",", "true", ",", "places", "=", "2", ")", "\n", "\n", "\n", "", "", "bleu", "=", "corpus_bleu", "(", "list_of_references", "=", "list_of_references", ",", "\n", "hypotheses", "=", "hypotheses", ",", "\n", "lowercase", "=", "lowercase", ",", "\n", "return_all", "=", "return_all", ")", "\n", "if", "not", "return_all", ":", "\n", "            ", "self", ".", "assertAlmostEqual", "(", "bleu", ",", "true_bleu", ",", "places", "=", "0", ")", "\n", "", "else", ":", "\n", "            ", "for", "ret", ",", "true", "in", "zip", "(", "bleu", ",", "true_bleu", ")", ":", "\n", "                ", "self", ".", "assertAlmostEqual", "(", "ret", ",", "true", ",", "places", "=", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.evals.bleu_test.BLEUTest.test_corpus_strings": [[104, 121], ["bleu_test.BLEUTest._test_corpus_bleu", "bleu_test.BLEUTest._test_corpus_bleu"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.evals.bleu_test.BLEUTest._test_corpus_bleu", "home.repos.pwc.inspect_result.VegB_Text_Infilling.evals.bleu_test.BLEUTest._test_corpus_bleu"], ["", "", "", "def", "test_corpus_strings", "(", "self", ")", ":", "\n", "        ", "\"\"\"Tests corpus level BLEU.\n        \"\"\"", "\n", "hypotheses", "=", "[", "\n", "\"this is a test sentence to evaluate the good bleu score . \u8bcd\"", ",", "\n", "\"i believe that that the script is \u8bcd perfectly correct .\"", "\n", "]", "\n", "list_of_references", "=", "[", "\n", "[", "\"this is a test sentence to evaluate the bleu score .\"", ",", "\n", "\"this is a test sentence to evaluate the good score .\"", "]", ",", "\n", "[", "\"i believe that the script is perfectly correct .\"", ".", "split", "(", ")", "]", "\n", "]", "\n", "self", ".", "_test_corpus_bleu", "(", "list_of_references", ",", "hypotheses", ",", "\n", "False", ",", "False", ",", "63.02", ")", "\n", "\n", "self", ".", "_test_corpus_bleu", "(", "list_of_references", ",", "hypotheses", ",", "\n", "False", ",", "True", ",", "[", "63.02", ",", "87.5", ",", "77.3", ",", "60.0", ",", "38.9", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.agents.agent_gym_utils.convert_gym_space": [[16, 32], ["isinstance", "isinstance", "Space", "isinstance", "Space"], "function", ["None"], ["def", "convert_gym_space", "(", "spc", ")", ":", "\n", "    ", "\"\"\"Converts a gym Space instance to a\n    :class:`~texar.agents.agent_utils.Space` instance.\n\n    Args:\n        spc: An instance of `gym.Space` or\n            :class:`~texar.agents.agent_utils.Space`.\n    \"\"\"", "\n", "from", "texar", ".", "agents", ".", "agent_utils", "import", "Space", "\n", "if", "isinstance", "(", "spc", ",", "Space", ")", ":", "\n", "        ", "return", "spc", "\n", "", "if", "isinstance", "(", "spc", ",", "gym", ".", "spaces", ".", "Discrete", ")", ":", "\n", "        ", "return", "Space", "(", "shape", "=", "(", ")", ",", "low", "=", "0", ",", "high", "=", "spc", ".", "n", ",", "dtype", "=", "spc", ".", "dtype", ")", "\n", "", "elif", "isinstance", "(", "spc", ",", "gym", ".", "spaces", ".", "Box", ")", ":", "\n", "        ", "return", "Space", "(", "\n", "shape", "=", "spc", ".", "shape", ",", "low", "=", "spc", ".", "low", ",", "high", "=", "spc", ".", "high", ",", "dtype", "=", "spc", ".", "dtype", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.agents.agent_gym_utils.get_gym_env_config": [[33, 48], ["EnvConfig"], "function", ["None"], ["", "", "def", "get_gym_env_config", "(", "env", ")", ":", "\n", "    ", "\"\"\"Creates an instance of :class:`texar.agents.agent_utils.EnvConfig`\n    from a gym env.\n\n    Args:\n        env: An instance of OpenAI gym Environment.\n\n    Returns:\n        An instance of :class:`texar.agents.agent_utils.EnvConfig`.\n    \"\"\"", "\n", "from", "texar", ".", "agents", ".", "agent_utils", "import", "EnvConfig", "\n", "return", "EnvConfig", "(", "\n", "action_space", "=", "env", ".", "action_space", ",", "\n", "observ_space", "=", "env", ".", "observation_space", ",", "\n", "reward_range", "=", "env", ".", "reward_range", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.agents.agent_utils_test.SpaceTest._test_space": [[23, 28], ["agent_utils_test.SpaceTest.assertEqual", "agent_utils_test.SpaceTest.assertEqual", "agent_utils_test.SpaceTest.assertEqual", "agent_utils_test.SpaceTest.assertEqual"], "methods", ["None"], ["def", "_test_space", "(", "self", ",", "s", ",", "shape", ",", "low", ",", "high", ",", "dtype", ")", ":", "\n", "        ", "self", ".", "assertEqual", "(", "s", ".", "shape", ",", "shape", ")", "\n", "self", ".", "assertEqual", "(", "s", ".", "low", ",", "low", ")", "\n", "self", ".", "assertEqual", "(", "s", ".", "high", ",", "high", ")", "\n", "self", ".", "assertEqual", "(", "s", ".", "dtype", ",", "dtype", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.agents.agent_utils_test.SpaceTest.test_space": [[29, 40], ["texar.agents.agent_utils.Space", "agent_utils_test.SpaceTest._test_space", "agent_utils_test.SpaceTest.assertTrue", "agent_utils_test.SpaceTest.assertFalse", "agent_utils_test.SpaceTest.assertFalse", "texar.agents.agent_utils.Space", "agent_utils_test.SpaceTest._test_space", "numpy.dtype", "texar.agents.agent_utils.Space.contains", "texar.agents.agent_utils.Space.contains", "texar.agents.agent_utils.Space.contains", "numpy.dtype"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.agents.agent_utils_test.SpaceTest._test_space", "home.repos.pwc.inspect_result.VegB_Text_Infilling.agents.agent_utils_test.SpaceTest._test_space", "home.repos.pwc.inspect_result.VegB_Text_Infilling.agents.agent_utils.Space.contains", "home.repos.pwc.inspect_result.VegB_Text_Infilling.agents.agent_utils.Space.contains", "home.repos.pwc.inspect_result.VegB_Text_Infilling.agents.agent_utils.Space.contains"], ["", "def", "test_space", "(", "self", ")", ":", "\n", "        ", "\"\"\"Tests descrete space.\n        \"\"\"", "\n", "s", "=", "Space", "(", "shape", "=", "(", ")", ",", "low", "=", "0", ",", "high", "=", "10", ",", "dtype", "=", "np", ".", "int32", ")", "\n", "self", ".", "_test_space", "(", "s", ",", "(", ")", ",", "0", ",", "10", ",", "np", ".", "dtype", "(", "np", ".", "int32", ")", ")", "\n", "self", ".", "assertTrue", "(", "s", ".", "contains", "(", "5", ")", ")", "\n", "self", ".", "assertFalse", "(", "s", ".", "contains", "(", "5.", ")", ")", "\n", "self", ".", "assertFalse", "(", "s", ".", "contains", "(", "15", ")", ")", "\n", "\n", "s", "=", "Space", "(", "low", "=", "0", ",", "high", "=", "10", ",", "dtype", "=", "np", ".", "int32", ")", "\n", "self", ".", "_test_space", "(", "s", ",", "(", ")", ",", "0", ",", "10", ",", "np", ".", "dtype", "(", "np", ".", "int32", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.agents.seq_agent_base.SeqAgentBase.__init__": [[20, 22], ["texar.agents.agent_base.AgentBase.__init__"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.text_infilling.self_attn_hyperparams.Hyperparams.__init__"], ["def", "__init__", "(", "self", ",", "hparams", "=", "None", ")", ":", "\n", "        ", "AgentBase", ".", "__init__", "(", "self", ",", "hparams", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.agents.seq_agent_base.SeqAgentBase.default_hparams": [[24, 32], ["None"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "default_hparams", "(", ")", ":", "\n", "        ", "\"\"\"Returns a dictionary of hyperparameters with default values.\n\n        TODO\n        \"\"\"", "\n", "return", "{", "\n", "'name'", ":", "'agent'", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.agents.pg_agent.PGAgent.__init__": [[23, 60], ["texar.agents.agent_base.AgentBase.__init__", "texar.utils.utils.get_instance", "list", "tensorflow.Session", "pg_agent.PGAgent.sess.run", "tensorflow.variable_scope", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "pg_agent.PGAgent.network", "tensorflow.nn.softmax", "pg_agent.PGAgent._hparams.trainer.loss_fn", "texar.core.optimization.get_train_op", "tensorflow.global_variables_initializer", "list"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.text_infilling.self_attn_hyperparams.Hyperparams.__init__", "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.utils.get_instance", "home.repos.pwc.inspect_result.VegB_Text_Infilling.agents.agent_base.AgentBase.variable_scope", "home.repos.pwc.inspect_result.VegB_Text_Infilling.qnets.qnets.QNetBase.network", "home.repos.pwc.inspect_result.VegB_Text_Infilling.core.optimization.get_train_op"], ["\n", "def", "__init__", "(", "self", ",", "\n", "env_config", ",", "\n", "sess", "=", "None", ",", "\n", "policy", "=", "None", ",", "\n", "policy_kwargs", "=", "None", ",", "\n", "policy_caller_kwargs", "=", "None", ",", "\n", "learning_rate", "=", "None", ",", "\n", "hparams", "=", "None", ")", ":", "\n", "        ", "EpisodicAgentBase", ".", "__init__", "(", "self", ",", "env_config", ",", "hparams", ")", "\n", "\n", "self", ".", "_sess", "=", "sess", "\n", "self", ".", "_lr", "=", "learning_rate", "\n", "self", ".", "_discount_factor", "=", "self", ".", "_hparams", ".", "discount_factor", "\n", "\n", "with", "tf", ".", "variable_scope", "(", "self", ".", "variable_scope", ")", ":", "\n", "            ", "if", "policy", "is", "None", ":", "\n", "                ", "kwargs", "=", "utils", ".", "get_instance_kwargs", "(", "\n", "policy_kwargs", ",", "self", ".", "_hparams", ".", "policy_hparams", ")", "\n", "policy", "=", "utils", ".", "check_or_get_instance", "(", "\n", "self", ".", "_hparams", ".", "policy_type", ",", "\n", "kwargs", ",", "\n", "module_paths", "=", "[", "'texar.modules'", ",", "'texar.custom'", "]", ")", "\n", "", "self", ".", "_policy", "=", "policy", "\n", "self", ".", "_policy_caller_kwargs", "=", "policy_caller_kwargs", "or", "{", "}", "\n", "\n", "", "self", ".", "_observs", "=", "[", "]", "\n", "self", ".", "_actions", "=", "[", "]", "\n", "self", ".", "_rewards", "=", "[", "]", "\n", "\n", "self", ".", "_train_outputs", "=", "None", "\n", "\n", "self", ".", "_build_graph", "(", ")", "\n", "\n", "", "def", "_build_graph", "(", "self", ")", ":", "\n", "        ", "with", "tf", ".", "variable_scope", "(", "self", ".", "variable_scope", ")", ":", "\n", "            ", "self", ".", "_observ_inputs", "=", "tf", ".", "placeholder", "(", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.agents.pg_agent.PGAgent._build_graph": [[58, 78], ["tensorflow.variable_scope", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "pg_agent.PGAgent._get_policy_outputs", "pg_agent.PGAgent._get_pg_loss", "pg_agent.PGAgent._get_train_op", "list", "list"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.agents.agent_base.AgentBase.variable_scope", "home.repos.pwc.inspect_result.VegB_Text_Infilling.agents.pg_agent.PGAgent._get_policy_outputs", "home.repos.pwc.inspect_result.VegB_Text_Infilling.agents.seq_pg_agent.SeqPGAgent._get_pg_loss", "home.repos.pwc.inspect_result.VegB_Text_Infilling.seq2seq.seq2seq_base.Seq2seqBase._get_train_op"], ["", "def", "_build_graph", "(", "self", ")", ":", "\n", "        ", "with", "tf", ".", "variable_scope", "(", "self", ".", "variable_scope", ")", ":", "\n", "            ", "self", ".", "_observ_inputs", "=", "tf", ".", "placeholder", "(", "\n", "dtype", "=", "self", ".", "_env_config", ".", "observ_dtype", ",", "\n", "shape", "=", "[", "None", ",", "]", "+", "list", "(", "self", ".", "_env_config", ".", "observ_shape", ")", ",", "\n", "name", "=", "'observ_inputs'", ")", "\n", "self", ".", "_action_inputs", "=", "tf", ".", "placeholder", "(", "\n", "dtype", "=", "self", ".", "_env_config", ".", "action_dtype", ",", "\n", "shape", "=", "[", "None", ",", "]", "+", "list", "(", "self", ".", "_env_config", ".", "action_shape", ")", ",", "\n", "name", "=", "'action_inputs'", ")", "\n", "self", ".", "_advantage_inputs", "=", "tf", ".", "placeholder", "(", "\n", "dtype", "=", "tf", ".", "float32", ",", "\n", "shape", "=", "[", "None", ",", "]", ",", "\n", "name", "=", "'advantages_inputs'", ")", "\n", "\n", "self", ".", "_outputs", "=", "self", ".", "_get_policy_outputs", "(", ")", "\n", "\n", "self", ".", "_pg_loss", "=", "self", ".", "_get_pg_loss", "(", ")", "\n", "\n", "self", ".", "_train_op", "=", "self", ".", "_get_train_op", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.agents.pg_agent.PGAgent._get_policy_outputs": [[79, 83], ["pg_agent.PGAgent._policy"], "methods", ["None"], ["", "", "def", "_get_policy_outputs", "(", "self", ")", ":", "\n", "        ", "outputs", "=", "self", ".", "_policy", "(", "\n", "inputs", "=", "self", ".", "_observ_inputs", ",", "**", "self", ".", "_policy_caller_kwargs", ")", "\n", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.agents.pg_agent.PGAgent._get_pg_loss": [[84, 92], ["pg_agent.PGAgent._outputs[].log_prob", "texar.losses.pg_losses.pg_loss_with_log_probs"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.losses.pg_losses.pg_loss_with_log_probs"], ["", "def", "_get_pg_loss", "(", "self", ")", ":", "\n", "        ", "log_probs", "=", "self", ".", "_outputs", "[", "'dist'", "]", ".", "log_prob", "(", "self", ".", "_action_inputs", ")", "\n", "pg_loss", "=", "losses", ".", "pg_loss_with_log_probs", "(", "\n", "log_probs", "=", "log_probs", ",", "\n", "advantages", "=", "self", ".", "_advantage_inputs", ",", "\n", "average_across_timesteps", "=", "True", ",", "\n", "sum_over_timesteps", "=", "False", ")", "\n", "return", "pg_loss", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.agents.pg_agent.PGAgent._get_train_op": [[93, 100], ["texar.core.optimization.get_train_op", "pg_agent.PGAgent._hparams.optimization.todict"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.core.optimization.get_train_op", "home.repos.pwc.inspect_result.VegB_Text_Infilling.texar.hyperparams.HParams.todict"], ["", "def", "_get_train_op", "(", "self", ")", ":", "\n", "        ", "train_op", "=", "opt", ".", "get_train_op", "(", "\n", "loss", "=", "self", ".", "_pg_loss", ",", "\n", "variables", "=", "self", ".", "_policy", ".", "trainable_variables", ",", "\n", "learning_rate", "=", "self", ".", "_lr", ",", "\n", "hparams", "=", "self", ".", "_hparams", ".", "optimization", ".", "todict", "(", ")", ")", "\n", "return", "train_op", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.agents.pg_agent.PGAgent.default_hparams": [[61, 73], ["texar.core.optimization.default_optimization_hparams"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.core.optimization.default_optimization_hparams"], ["dtype", "=", "self", ".", "_env_config", ".", "observ_dtype", ",", "\n", "shape", "=", "[", "None", ",", "]", "+", "list", "(", "self", ".", "_env_config", ".", "observ_shape", ")", ",", "\n", "name", "=", "'observ_inputs'", ")", "\n", "self", ".", "_action_inputs", "=", "tf", ".", "placeholder", "(", "\n", "dtype", "=", "self", ".", "_env_config", ".", "action_dtype", ",", "\n", "shape", "=", "[", "None", ",", "]", "+", "list", "(", "self", ".", "_env_config", ".", "action_shape", ")", ",", "\n", "name", "=", "'action_inputs'", ")", "\n", "self", ".", "_advantage_inputs", "=", "tf", ".", "placeholder", "(", "\n", "dtype", "=", "tf", ".", "float32", ",", "\n", "shape", "=", "[", "None", ",", "]", ",", "\n", "name", "=", "'advantages_inputs'", ")", "\n", "\n", "self", ".", "_outputs", "=", "self", ".", "_get_policy_outputs", "(", ")", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.agents.pg_agent.PGAgent._reset": [[112, 116], ["None"], "methods", ["None"], ["", "def", "_reset", "(", "self", ")", ":", "\n", "        ", "self", ".", "_observs", "=", "[", "]", "\n", "self", ".", "_actions", "=", "[", "]", "\n", "self", ".", "_rewards", "=", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.agents.pg_agent.PGAgent._get_action": [[117, 130], ["dict", "feed_dict_.update", "pg_agent.PGAgent._sess.run", "pg_agent.PGAgent._observs.append", "pg_agent.PGAgent._actions.append"], "methods", ["None"], ["", "def", "_get_action", "(", "self", ",", "observ", ",", "feed_dict", ")", ":", "\n", "        ", "fetches", "=", "dict", "(", "action", "=", "self", ".", "_outputs", "[", "'action'", "]", ")", "\n", "\n", "feed_dict_", "=", "{", "self", ".", "_observ_inputs", ":", "[", "observ", ",", "]", "}", "\n", "feed_dict_", ".", "update", "(", "feed_dict", "or", "{", "}", ")", "\n", "\n", "vals", "=", "self", ".", "_sess", ".", "run", "(", "fetches", ",", "feed_dict", "=", "feed_dict_", ")", "\n", "action", "=", "vals", "[", "'action'", "]", "\n", "\n", "self", ".", "_observs", ".", "append", "(", "observ", ")", "\n", "self", ".", "_actions", ".", "append", "(", "action", ")", "\n", "\n", "return", "action", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.agents.pg_agent.PGAgent._observe": [[131, 136], ["pg_agent.PGAgent._rewards.append", "pg_agent.PGAgent._train_policy"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.agents.seq_pg_agent.SeqPGAgent._train_policy"], ["", "def", "_observe", "(", "self", ",", "observ", ",", "action", ",", "reward", ",", "terminal", ",", "next_observ", ",", "train_policy", ",", "feed_dict", ")", ":", "\n", "        ", "self", ".", "_rewards", ".", "append", "(", "reward", ")", "\n", "\n", "if", "terminal", "and", "train_policy", ":", "\n", "            ", "self", ".", "_train_policy", "(", "feed_dict", "=", "feed_dict", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.agents.pg_agent.PGAgent._train_policy": [[137, 156], ["texar.losses.rewards.discount_reward", "dict", "feed_dict_.update", "pg_agent.PGAgent._sess.run"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.losses.rewards.discount_reward"], ["", "", "def", "_train_policy", "(", "self", ",", "feed_dict", "=", "None", ")", ":", "\n", "        ", "\"\"\"Updates the policy.\n\n        Args:\n            TODO\n        \"\"\"", "\n", "qvalues", "=", "discount_reward", "(", "\n", "[", "self", ".", "_rewards", "]", ",", "discount", "=", "self", ".", "_hparams", ".", "discount_factor", ",", "\n", "normalize", "=", "self", ".", "_hparams", ".", "normalize_reward", ")", "\n", "qvalues", "=", "qvalues", "[", "0", ",", ":", "]", "\n", "\n", "fetches", "=", "dict", "(", "loss", "=", "self", ".", "_train_op", ")", "\n", "feed_dict_", "=", "{", "\n", "self", ".", "_observ_inputs", ":", "self", ".", "_observs", ",", "\n", "self", ".", "_action_inputs", ":", "self", ".", "_actions", ",", "\n", "self", ".", "_advantage_inputs", ":", "qvalues", "}", "\n", "feed_dict_", ".", "update", "(", "feed_dict", "or", "{", "}", ")", "\n", "\n", "self", ".", "_train_outputs", "=", "self", ".", "_sess", ".", "run", "(", "fetches", ",", "feed_dict", "=", "feed_dict_", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.agents.pg_agent.PGAgent.sess": [[163, 166], ["None"], "methods", ["None"], ["", "@", "sess", ".", "setter", "\n", "def", "sess", "(", "self", ",", "session", ")", ":", "\n", "        ", "self", ".", "_sess", "=", "session", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.agents.pg_agent.PGAgent.policy": [[167, 172], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "policy", "(", "self", ")", ":", "\n", "        ", "\"\"\"The policy model.\n        \"\"\"", "\n", "return", "self", ".", "_policy", "\n", "", "", ""]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.agents.agent_base.AgentBase.__init__": [[19, 28], ["texar.hyperparams.HParams", "agent_base.AgentBase.default_hparams"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.core.replay_memories.DequeReplayMemory.default_hparams"], ["    ", "\"\"\"\n    Base class inherited by RL agents.\n\n    Args:\n        TODO\n    \"\"\"", "\n", "def", "__init__", "(", "self", ",", "hparams", "=", "None", ")", ":", "\n", "        ", "self", ".", "_hparams", "=", "HParams", "(", "hparams", ",", "self", ".", "default_hparams", "(", ")", ")", "\n", "\n", "name", "=", "self", ".", "_hparams", ".", "name", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.agents.agent_base.AgentBase.default_hparams": [[29, 35], ["None"], "methods", ["None"], ["self", ".", "_variable_scope", "=", "get_unique_named_variable_scope", "(", "name", ")", "\n", "self", ".", "_unique_name", "=", "self", ".", "_variable_scope", ".", "name", ".", "split", "(", "\"/\"", ")", "[", "-", "1", "]", "\n", "\n", "", "@", "staticmethod", "\n", "def", "default_hparams", "(", ")", ":", "\n", "        "]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.agents.agent_base.AgentBase.variable_scope": [[71, 76], ["None"], "methods", ["None"], []], "home.repos.pwc.inspect_result.VegB_Text_Infilling.agents.agent_base.AgentBase.name": [[77, 83], ["None"], "methods", ["None"], []], "home.repos.pwc.inspect_result.VegB_Text_Infilling.agents.agent_base.AgentBase.hparams": [[54, 60], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "hparams", "(", "self", ")", ":", "\n", "        ", "\"\"\"A :class:`~texar.hyperparams.HParams` instance. The hyperparameters\n        of the module.\n        \"\"\"", "\n", "return", "self", ".", "_hparams", "\n", "", "", ""]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.agents.agent_base.AgentBase.set_initial_state": [[37, 44], ["None"], "methods", ["None"], ["\n", "return", "{", "\n", "'name'", ":", "'agent'", "\n", "}", "\n", "\n", "", "@", "property", "\n", "def", "variable_scope", "(", "self", ")", ":", "\n", "        "]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.agents.agent_base.AgentBase.perceive": [[45, 55], ["None"], "methods", ["None"], ["\n", "return", "self", ".", "_variable_scope", "\n", "\n", "", "@", "property", "\n", "def", "name", "(", "self", ")", ":", "\n", "        ", "\"\"\"The name of the module (not uniquified).\n        \"\"\"", "\n", "return", "self", ".", "_unique_name", "\n", "\n", "", "@", "property", "\n", "def", "hparams", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.agents.agent_base.AgentBase.get_action": [[56, 70], ["None"], "methods", ["None"], ["        ", "\"\"\"A :class:`~texar.hyperparams.HParams` instance. The hyperparameters\n        of the module.\n        \"\"\"", "\n", "return", "self", ".", "_hparams", "\n", "", "", ""]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.agents.ac_agent.ActorCriticAgent.__init__": [[17, 54], ["texar.agents.episodic_agent_base.EpisodicAgentBase.__init__", "tensorflow.variable_scope", "texar.utils.utils.get_instance_kwargs", "texar.utils.utils.get_instance_kwargs.update", "texar.utils.utils.get_instance", "texar.utils.utils.get_instance_kwargs", "texar.utils.utils.get_instance_kwargs.update", "texar.utils.utils.get_instance", "dict", "dict"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.text_infilling.self_attn_hyperparams.Hyperparams.__init__", "home.repos.pwc.inspect_result.VegB_Text_Infilling.agents.agent_base.AgentBase.variable_scope", "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.utils.get_instance_kwargs", "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.utils.get_instance", "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.utils.get_instance_kwargs", "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.utils.get_instance"], ["    ", "def", "__init__", "(", "self", ",", "\n", "env_config", ",", "\n", "sess", "=", "None", ",", "\n", "actor", "=", "None", ",", "\n", "actor_kwargs", "=", "None", ",", "\n", "critic", "=", "None", ",", "\n", "critic_kwargs", "=", "None", ",", "\n", "hparams", "=", "None", ")", ":", "\n", "        ", "EpisodicAgentBase", ".", "__init__", "(", "self", ",", "env_config", "=", "env_config", ",", "hparams", "=", "hparams", ")", "\n", "\n", "self", ".", "_sess", "=", "sess", "\n", "self", ".", "_num_actions", "=", "self", ".", "_env_config", ".", "action_space", ".", "high", "-", "self", ".", "_env_config", ".", "action_space", ".", "low", "\n", "\n", "with", "tf", ".", "variable_scope", "(", "self", ".", "variable_scope", ")", ":", "\n", "            ", "if", "actor", "is", "None", ":", "\n", "                ", "kwargs", "=", "utils", ".", "get_instance_kwargs", "(", "\n", "actor_kwargs", ",", "self", ".", "_hparams", ".", "actor_kwargs", ")", "\n", "kwargs", ".", "update", "(", "dict", "(", "env_config", "=", "env_config", ",", "sess", "=", "sess", ")", ")", "\n", "actor", "=", "utils", ".", "get_instance", "(", "\n", "class_or_name", "=", "self", ".", "_hparams", ".", "actor_type", ",", "\n", "kwargs", "=", "kwargs", ",", "\n", "module_paths", "=", "[", "'texar.agents'", ",", "'texar.custom'", "]", ")", "\n", "", "self", ".", "actor", "=", "actor", "\n", "\n", "if", "critic", "is", "None", ":", "\n", "                ", "kwargs", "=", "utils", ".", "get_instance_kwargs", "(", "\n", "critic_kwargs", ",", "self", ".", "_hparams", ".", "critic_kwargs", ")", "\n", "kwargs", ".", "update", "(", "dict", "(", "env_config", "=", "env_config", ",", "sess", "=", "sess", ")", ")", "\n", "critic", "=", "utils", ".", "get_instance", "(", "\n", "class_or_name", "=", "self", ".", "_hparams", ".", "critic_type", ",", "\n", "kwargs", "=", "kwargs", ",", "\n", "module_paths", "=", "[", "'texar.agents'", ",", "'texar.custom'", "]", ")", "\n", "", "self", ".", "critic", "=", "critic", "\n", "\n", "assert", "self", ".", "actor", ".", "_discount_factor", "==", "self", ".", "critic", ".", "_discount_factor", "\n", "self", ".", "_discount_factor", "=", "self", ".", "actor", ".", "_discount_factor", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.agents.ac_agent.ActorCriticAgent.default_hparams": [[55, 65], ["texar.agents.PGAgent.default_hparams", "texar.agents.DQNAgent.default_hparams"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.core.replay_memories.DequeReplayMemory.default_hparams", "home.repos.pwc.inspect_result.VegB_Text_Infilling.core.replay_memories.DequeReplayMemory.default_hparams"], ["", "", "@", "staticmethod", "\n", "def", "default_hparams", "(", ")", ":", "\n", "        ", "return", "{", "\n", "'actor_type'", ":", "'PGAgent'", ",", "\n", "'actor_kwargs'", ":", "None", ",", "\n", "'actor_hparams'", ":", "PGAgent", ".", "default_hparams", "(", ")", ",", "\n", "'critic_type'", ":", "'DQNAgent'", ",", "\n", "'critic_kwargs'", ":", "None", ",", "\n", "'critic_hparams'", ":", "DQNAgent", ".", "default_hparams", "(", ")", ",", "\n", "'name'", ":", "'actor_critic_agents'", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.agents.ac_agent.ActorCriticAgent._reset": [[67, 70], ["ac_agent.ActorCriticAgent.actor._reset", "ac_agent.ActorCriticAgent.critic._reset"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.agents.episodic_agent_base.EpisodicAgentBase._reset", "home.repos.pwc.inspect_result.VegB_Text_Infilling.agents.episodic_agent_base.EpisodicAgentBase._reset"], ["", "def", "_reset", "(", "self", ")", ":", "\n", "        ", "self", ".", "actor", ".", "_reset", "(", ")", "\n", "self", ".", "critic", ".", "_reset", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.agents.ac_agent.ActorCriticAgent._observe": [[71, 101], ["ac_agent.ActorCriticAgent.critic._observe", "feed_dict_.update", "ac_agent.ActorCriticAgent.critic._sess.run", "feed_dict_.update", "ac_agent.ActorCriticAgent.critic._sess.run", "feed_dict_.update", "ac_agent.ActorCriticAgent.actor._train_policy"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.agents.episodic_agent_base.EpisodicAgentBase._observe", "home.repos.pwc.inspect_result.VegB_Text_Infilling.agents.seq_pg_agent.SeqPGAgent._train_policy"], ["", "def", "_observe", "(", "self", ",", "observ", ",", "action", ",", "reward", ",", "terminal", ",", "next_observ", ",", "\n", "train_policy", ",", "feed_dict", ")", ":", "\n", "        ", "self", ".", "critic", ".", "_observe", "(", "observ", ",", "action", ",", "reward", ",", "terminal", ",", "next_observ", ",", "\n", "train_policy", ",", "feed_dict", ")", "\n", "\n", "feed_dict_", "=", "{", "self", ".", "critic", ".", "_observ_inputs", ":", "[", "next_observ", "]", "}", "\n", "feed_dict_", ".", "update", "(", "feed_dict", ")", "\n", "next_step_qvalues", "=", "self", ".", "critic", ".", "_sess", ".", "run", "(", "\n", "self", ".", "critic", ".", "_qnet_outputs", "[", "'qvalues'", "]", ",", "feed_dict", "=", "feed_dict_", ")", "\n", "\n", "action_one_hot", "=", "[", "0.", "]", "*", "self", ".", "_num_actions", "\n", "action_one_hot", "[", "action", "]", "=", "1.", "\n", "feed_dict_", "=", "{", "\n", "self", ".", "critic", ".", "_observ_inputs", ":", "[", "observ", "]", ",", "\n", "self", ".", "critic", ".", "_y_inputs", ":", "\n", "[", "reward", "+", "self", ".", "_discount_factor", "*", "next_step_qvalues", "[", "0", "]", "[", "action", "]", "]", ",", "\n", "self", ".", "critic", ".", "_action_inputs", ":", "[", "action_one_hot", "]", "\n", "}", "\n", "feed_dict_", ".", "update", "(", "feed_dict", ")", "\n", "td_errors", "=", "self", ".", "critic", ".", "_sess", ".", "run", "(", "\n", "self", ".", "critic", ".", "_td_error", ",", "feed_dict", "=", "feed_dict_", ")", "\n", "\n", "feed_dict_", "=", "{", "\n", "self", ".", "actor", ".", "_observ_inputs", ":", "[", "observ", "]", ",", "\n", "self", ".", "actor", ".", "_action_inputs", ":", "[", "action", "]", ",", "\n", "self", ".", "actor", ".", "_advantage_inputs", ":", "td_errors", "\n", "}", "\n", "feed_dict_", ".", "update", "(", "feed_dict", ")", "\n", "\n", "self", ".", "actor", ".", "_train_policy", "(", "feed_dict", "=", "feed_dict_", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.agents.ac_agent.ActorCriticAgent.get_action": [[102, 104], ["ac_agent.ActorCriticAgent.actor.get_action"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.agents.pg_agent.PGAgent.get_action"], ["", "def", "get_action", "(", "self", ",", "observ", ",", "feed_dict", "=", "None", ")", ":", "\n", "        ", "return", "self", ".", "actor", ".", "get_action", "(", "observ", ",", "feed_dict", "=", "feed_dict", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.agents.ac_agent.ActorCriticAgent.sess": [[111, 116], ["None"], "methods", ["None"], ["", "@", "sess", ".", "setter", "\n", "def", "sess", "(", "self", ",", "session", ")", ":", "\n", "        ", "self", ".", "_sess", "=", "session", "\n", "self", ".", "actor", ".", "_sess", "=", "session", "\n", "self", ".", "critic", ".", "_sess", "=", "session", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.agents.dqn_agent.DQNAgent.__init__": [[20, 79], ["texar.agents.episodic_agent_base.EpisodicAgentBase.__init__", "dqn_agent.DQNAgent._build_graph", "tensorflow.variable_scope", "texar.utils.utils.get_instance_kwargs", "texar.utils.utils.check_or_get_instance", "texar.utils.utils.check_or_get_instance", "texar.utils.utils.get_instance_kwargs", "texar.utils.utils.check_or_get_instance", "texar.utils.utils.get_instance_kwargs", "texar.utils.utils.check_or_get_instance"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.text_infilling.self_attn_hyperparams.Hyperparams.__init__", "home.repos.pwc.inspect_result.VegB_Text_Infilling.agents.seq_pg_agent.SeqPGAgent._build_graph", "home.repos.pwc.inspect_result.VegB_Text_Infilling.agents.agent_base.AgentBase.variable_scope", "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.utils.get_instance_kwargs", "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.utils.check_or_get_instance", "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.utils.check_or_get_instance", "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.utils.get_instance_kwargs", "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.utils.check_or_get_instance", "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.utils.get_instance_kwargs", "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.utils.check_or_get_instance"], ["    ", "def", "__init__", "(", "self", ",", "\n", "env_config", ",", "\n", "sess", "=", "None", ",", "\n", "qnet", "=", "None", ",", "\n", "target", "=", "None", ",", "\n", "qnet_kwargs", "=", "None", ",", "\n", "qnet_caller_kwargs", "=", "None", ",", "\n", "replay_memory", "=", "None", ",", "\n", "replay_memory_kwargs", "=", "None", ",", "\n", "exploration", "=", "None", ",", "\n", "exploration_kwargs", "=", "None", ",", "\n", "hparams", "=", "None", ")", ":", "\n", "        ", "EpisodicAgentBase", ".", "__init__", "(", "self", ",", "env_config", ",", "hparams", ")", "\n", "\n", "self", ".", "_sess", "=", "sess", "\n", "self", ".", "_cold_start_steps", "=", "self", ".", "_hparams", ".", "cold_start_steps", "\n", "self", ".", "_sample_batch_size", "=", "self", ".", "_hparams", ".", "sample_batch_size", "\n", "self", ".", "_update_period", "=", "self", ".", "_hparams", ".", "update_period", "\n", "self", ".", "_discount_factor", "=", "self", ".", "_hparams", ".", "discount_factor", "\n", "self", ".", "_update_type", "=", "self", ".", "_hparams", ".", "update_type", "\n", "self", ".", "_num_actions", "=", "self", ".", "_env_config", ".", "action_space", ".", "high", "-", "self", ".", "_env_config", ".", "action_space", ".", "low", "\n", "\n", "with", "tf", ".", "variable_scope", "(", "self", ".", "variable_scope", ")", ":", "\n", "            ", "if", "qnet", "is", "None", ":", "\n", "                ", "kwargs", "=", "utils", ".", "get_instance_kwargs", "(", "\n", "qnet_kwargs", ",", "self", ".", "_hparams", ".", "qnet_hparams", ")", "\n", "qnet", "=", "utils", ".", "check_or_get_instance", "(", "\n", "ins_or_class_or_name", "=", "self", ".", "_hparams", ".", "qnet_type", ",", "\n", "kwargs", "=", "kwargs", ",", "\n", "module_paths", "=", "[", "'texar.modules'", ",", "'texar.custom'", "]", ")", "\n", "target", "=", "utils", ".", "check_or_get_instance", "(", "\n", "ins_or_class_or_name", "=", "self", ".", "_hparams", ".", "qnet_type", ",", "\n", "kwargs", "=", "kwargs", ",", "\n", "module_paths", "=", "[", "'texar.modules'", ",", "'texar.custom'", "]", ")", "\n", "", "self", ".", "_qnet", "=", "qnet", "\n", "self", ".", "_target", "=", "target", "\n", "self", ".", "_qnet_caller_kwargs", "=", "qnet_caller_kwargs", "or", "{", "}", "\n", "\n", "if", "replay_memory", "is", "None", ":", "\n", "                ", "kwargs", "=", "utils", ".", "get_instance_kwargs", "(", "\n", "replay_memory_kwargs", ",", "self", ".", "_hparams", ".", "replay_memory_hparams", ")", "\n", "replay_memory", "=", "utils", ".", "check_or_get_instance", "(", "\n", "ins_or_class_or_name", "=", "self", ".", "_hparams", ".", "replay_memory_type", ",", "\n", "kwargs", "=", "kwargs", ",", "\n", "module_paths", "=", "[", "'texar.core'", ",", "'texar.custom'", "]", ")", "\n", "", "self", ".", "_replay_memory", "=", "replay_memory", "\n", "\n", "if", "exploration", "is", "None", ":", "\n", "                ", "kwargs", "=", "utils", ".", "get_instance_kwargs", "(", "\n", "exploration_kwargs", ",", "self", ".", "_hparams", ".", "exploration_hparams", ")", "\n", "exploration", "=", "utils", ".", "check_or_get_instance", "(", "\n", "ins_or_class_or_name", "=", "self", ".", "_hparams", ".", "exploration_type", ",", "\n", "kwargs", "=", "kwargs", ",", "\n", "module_paths", "=", "[", "'texar.core'", ",", "'texar.custom'", "]", ")", "\n", "", "self", ".", "_exploration", "=", "exploration", "\n", "\n", "", "self", ".", "_build_graph", "(", ")", "\n", "self", ".", "timestep", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.agents.dqn_agent.DQNAgent.default_hparams": [[80, 96], ["texar.core.optimization.default_optimization_hparams"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.core.optimization.default_optimization_hparams"], ["", "@", "staticmethod", "\n", "def", "default_hparams", "(", ")", ":", "\n", "        ", "return", "{", "\n", "'qnet_type'", ":", "'CategoricalQNet'", ",", "\n", "'qnet_hparams'", ":", "None", ",", "\n", "'replay_memory_type'", ":", "'DequeReplayMemory'", ",", "\n", "'replay_memory_hparams'", ":", "None", ",", "\n", "'exploration_type'", ":", "'EpsilonLinearDecayExploration'", ",", "\n", "'exploration_hparams'", ":", "None", ",", "\n", "'optimization'", ":", "opt", ".", "default_optimization_hparams", "(", ")", ",", "\n", "'update_type'", ":", "'copy'", ",", "\n", "'cold_start_steps'", ":", "100", ",", "\n", "'sample_batch_size'", ":", "32", ",", "\n", "'update_period'", ":", "100", ",", "\n", "'discount_factor'", ":", "0.95", ",", "\n", "'name'", ":", "'dqn_agent'", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.agents.dqn_agent.DQNAgent._build_graph": [[98, 125], ["tensorflow.variable_scope", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "dqn_agent.DQNAgent._get_qnet_outputs", "dqn_agent.DQNAgent._get_target_outputs", "dqn_agent.DQNAgent._get_td_error", "dqn_agent.DQNAgent._get_train_op", "dqn_agent.DQNAgent._get_copy_update_op", "dqn_agent.DQNAgent._get_tau_update_op", "list"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.agents.agent_base.AgentBase.variable_scope", "home.repos.pwc.inspect_result.VegB_Text_Infilling.agents.dqn_agent.DQNAgent._get_qnet_outputs", "home.repos.pwc.inspect_result.VegB_Text_Infilling.agents.dqn_agent.DQNAgent._get_target_outputs", "home.repos.pwc.inspect_result.VegB_Text_Infilling.agents.dqn_agent.DQNAgent._get_td_error", "home.repos.pwc.inspect_result.VegB_Text_Infilling.seq2seq.seq2seq_base.Seq2seqBase._get_train_op", "home.repos.pwc.inspect_result.VegB_Text_Infilling.agents.dqn_agent.DQNAgent._get_copy_update_op", "home.repos.pwc.inspect_result.VegB_Text_Infilling.agents.dqn_agent.DQNAgent._get_tau_update_op"], ["", "def", "_build_graph", "(", "self", ")", ":", "\n", "        ", "with", "tf", ".", "variable_scope", "(", "self", ".", "variable_scope", ")", ":", "\n", "            ", "self", ".", "_observ_inputs", "=", "tf", ".", "placeholder", "(", "\n", "dtype", "=", "self", ".", "_env_config", ".", "observ_dtype", ",", "\n", "shape", "=", "[", "None", ",", "]", "+", "list", "(", "self", ".", "_env_config", ".", "observ_shape", ")", ",", "\n", "name", "=", "'observ_inputs'", ")", "\n", "self", ".", "_action_inputs", "=", "tf", ".", "placeholder", "(", "\n", "dtype", "=", "self", ".", "_env_config", ".", "action_dtype", ",", "\n", "shape", "=", "[", "None", ",", "self", ".", "_num_actions", "]", ",", "\n", "name", "=", "'action_inputs'", ")", "\n", "self", ".", "_y_inputs", "=", "tf", ".", "placeholder", "(", "\n", "dtype", "=", "tf", ".", "float32", ",", "\n", "shape", "=", "[", "None", ",", "]", ",", "\n", "name", "=", "'y_inputs'", ")", "\n", "\n", "self", ".", "_qnet_outputs", "=", "self", ".", "_get_qnet_outputs", "(", "self", ".", "_observ_inputs", ")", "\n", "self", ".", "_target_outputs", "=", "self", ".", "_get_target_outputs", "(", "self", ".", "_observ_inputs", ")", "\n", "self", ".", "_td_error", "=", "self", ".", "_get_td_error", "(", "\n", "qnet_qvalues", "=", "self", ".", "_qnet_outputs", "[", "'qvalues'", "]", ",", "\n", "actions", "=", "self", ".", "_action_inputs", ",", "\n", "y", "=", "self", ".", "_y_inputs", ")", "\n", "self", ".", "_train_op", "=", "self", ".", "_get_train_op", "(", ")", "\n", "\n", "if", "self", ".", "_update_type", "==", "'copy'", ":", "\n", "                ", "self", ".", "_update_op", "=", "self", ".", "_get_copy_update_op", "(", ")", "\n", "", "elif", "self", ".", "_update_type", "==", "'tau'", ":", "\n", "                ", "self", ".", "_update_op", "=", "self", ".", "_get_tau_update_op", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.agents.dqn_agent.DQNAgent._get_qnet_outputs": [[126, 128], ["dqn_agent.DQNAgent._qnet"], "methods", ["None"], ["", "", "", "def", "_get_qnet_outputs", "(", "self", ",", "state_inputs", ")", ":", "\n", "        ", "return", "self", ".", "_qnet", "(", "inputs", "=", "state_inputs", ",", "**", "self", ".", "_qnet_caller_kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.agents.dqn_agent.DQNAgent._get_target_outputs": [[129, 131], ["dqn_agent.DQNAgent._target"], "methods", ["None"], ["", "def", "_get_target_outputs", "(", "self", ",", "state_inputs", ")", ":", "\n", "        ", "return", "self", ".", "_target", "(", "inputs", "=", "state_inputs", ",", "**", "self", ".", "_qnet_caller_kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.agents.dqn_agent.DQNAgent._get_td_error": [[132, 134], ["tensorflow.reduce_sum", "tensorflow.to_float"], "methods", ["None"], ["", "def", "_get_td_error", "(", "self", ",", "qnet_qvalues", ",", "actions", ",", "y", ")", ":", "\n", "        ", "return", "y", "-", "tf", ".", "reduce_sum", "(", "qnet_qvalues", "*", "tf", ".", "to_float", "(", "actions", ")", ",", "axis", "=", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.agents.dqn_agent.DQNAgent._get_train_op": [[135, 141], ["texar.core.optimization.get_train_op", "tensorflow.reduce_sum", "dqn_agent.DQNAgent._hparams.optimization.todict"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.core.optimization.get_train_op", "home.repos.pwc.inspect_result.VegB_Text_Infilling.texar.hyperparams.HParams.todict"], ["", "def", "_get_train_op", "(", "self", ")", ":", "\n", "        ", "train_op", "=", "opt", ".", "get_train_op", "(", "\n", "loss", "=", "tf", ".", "reduce_sum", "(", "self", ".", "_td_error", "**", "2", ")", ",", "\n", "variables", "=", "self", ".", "_qnet", ".", "trainable_variables", ",", "\n", "hparams", "=", "self", ".", "_hparams", ".", "optimization", ".", "todict", "(", ")", ")", "\n", "return", "train_op", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.agents.dqn_agent.DQNAgent._get_copy_update_op": [[142, 148], ["range", "len", "op.append", "tensorflow.assign"], "methods", ["None"], ["", "def", "_get_copy_update_op", "(", "self", ")", ":", "\n", "        ", "op", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "self", ".", "_qnet", ".", "trainable_variables", ")", ")", ":", "\n", "            ", "op", ".", "append", "(", "tf", ".", "assign", "(", "ref", "=", "self", ".", "_target", ".", "trainable_variables", "[", "i", "]", ",", "\n", "value", "=", "self", ".", "_qnet", ".", "trainable_variables", "[", "i", "]", ")", ")", "\n", "", "return", "op", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.agents.dqn_agent.DQNAgent._get_tau_update_op": [[149, 158], ["range", "len", "op.append", "tensorflow.assign"], "methods", ["None"], ["", "def", "_get_tau_update_op", "(", "self", ")", ":", "\n", "        ", "tau", "=", "1.", "/", "self", ".", "_update_period", "\n", "op", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "self", ".", "_qnet", ".", "trainable_variables", ")", ")", ":", "\n", "            ", "op", ".", "append", "(", "tf", ".", "assign", "(", "\n", "ref", "=", "self", ".", "_target", ".", "trainable_variables", "[", "i", "]", ",", "\n", "value", "=", "(", "1.", "-", "tau", ")", "*", "self", ".", "_target", ".", "trainable_variables", "[", "i", "]", "+", "\n", "tau", "*", "self", ".", "_qnet", ".", "trainable_variables", "[", "i", "]", ")", ")", "\n", "", "return", "op", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.agents.dqn_agent.DQNAgent._observe": [[159, 174], ["dqn_agent.DQNAgent._replay_memory.add", "dict", "dqn_agent.DQNAgent._train_qnet"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.core.replay_memories.DequeReplayMemory.add", "home.repos.pwc.inspect_result.VegB_Text_Infilling.agents.dqn_agent.DQNAgent._train_qnet"], ["", "def", "_observe", "(", "self", ",", "observ", ",", "action", ",", "reward", ",", "terminal", ",", "next_observ", ",", "\n", "train_policy", ",", "feed_dict", ")", ":", "\n", "        ", "action_one_hot", "=", "[", "0.", "]", "*", "self", ".", "_num_actions", "\n", "action_one_hot", "[", "action", "]", "=", "1.", "\n", "\n", "self", ".", "_replay_memory", ".", "add", "(", "dict", "(", "\n", "observ", "=", "observ", ",", "\n", "action", "=", "action_one_hot", ",", "\n", "reward", "=", "reward", ",", "\n", "terminal", "=", "terminal", ",", "\n", "next_observ", "=", "next_observ", ")", ")", "\n", "self", ".", "timestep", "+=", "1", "\n", "\n", "if", "self", ".", "timestep", ">", "self", ".", "_cold_start_steps", "and", "train_policy", ":", "\n", "            ", "self", ".", "_train_qnet", "(", "feed_dict", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.agents.dqn_agent.DQNAgent._train_qnet": [[175, 204], ["dqn_agent.DQNAgent._replay_memory.get", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "dqn_agent.DQNAgent._sess.run", "range", "feed_dict_.update", "dqn_agent.DQNAgent._sess.run", "dqn_agent.DQNAgent.update_target", "texar.global_mode", "numpy.max"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.core.replay_memories.DequeReplayMemory.get", "home.repos.pwc.inspect_result.VegB_Text_Infilling.agents.dqn_agent.DQNAgent.update_target", "home.repos.pwc.inspect_result.VegB_Text_Infilling.texar.context.global_mode"], ["", "", "def", "_train_qnet", "(", "self", ",", "feed_dict", ")", ":", "\n", "        ", "minibatch", "=", "self", ".", "_replay_memory", ".", "get", "(", "self", ".", "_sample_batch_size", ")", "\n", "observ_batch", "=", "np", ".", "array", "(", "[", "data", "[", "'observ'", "]", "for", "data", "in", "minibatch", "]", ")", "\n", "action_batch", "=", "np", ".", "array", "(", "[", "data", "[", "'action'", "]", "for", "data", "in", "minibatch", "]", ")", "\n", "reward_batch", "=", "np", ".", "array", "(", "[", "data", "[", "'reward'", "]", "for", "data", "in", "minibatch", "]", ")", "\n", "terminal_batch", "=", "np", ".", "array", "(", "[", "data", "[", "'terminal'", "]", "for", "data", "in", "minibatch", "]", ")", "\n", "next_observ_batch", "=", "np", ".", "array", "(", "[", "data", "[", "'next_observ'", "]", "for", "data", "in", "minibatch", "]", ")", "\n", "\n", "target_qvalue", "=", "self", ".", "_sess", ".", "run", "(", "\n", "self", ".", "_target_outputs", "[", "'qvalues'", "]", ",", "feed_dict", "=", "{", "\n", "self", ".", "_observ_inputs", ":", "next_observ_batch", ",", "\n", "tx", ".", "global_mode", "(", ")", ":", "tf", ".", "estimator", ".", "ModeKeys", ".", "PREDICT", "}", ")", "\n", "\n", "y_batch", "=", "reward_batch", "\n", "for", "i", "in", "range", "(", "self", ".", "_sample_batch_size", ")", ":", "\n", "            ", "if", "not", "terminal_batch", "[", "i", "]", ":", "\n", "                ", "y_batch", "[", "i", "]", "+=", "self", ".", "_discount_factor", "*", "np", ".", "max", "(", "target_qvalue", "[", "i", "]", ")", "\n", "\n", "", "", "feed_dict_", "=", "{", "\n", "self", ".", "_observ_inputs", ":", "observ_batch", ",", "\n", "self", ".", "_y_inputs", ":", "y_batch", ",", "\n", "self", ".", "_action_inputs", ":", "action_batch", "\n", "}", "\n", "feed_dict_", ".", "update", "(", "feed_dict", "or", "{", "}", ")", "\n", "\n", "self", ".", "_sess", ".", "run", "(", "self", ".", "_train_op", ",", "feed_dict", "=", "feed_dict_", ")", "\n", "\n", "self", ".", "update_target", "(", "feed_dict", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.agents.dqn_agent.DQNAgent.update_target": [[205, 210], ["dqn_agent.DQNAgent._sess.run"], "methods", ["None"], ["", "def", "update_target", "(", "self", ",", "feed_dict", ")", ":", "\n", "        ", "if", "self", ".", "_update_type", "==", "'tau'", "or", "(", "\n", "self", ".", "_update_type", "==", "'copy'", "and", "\n", "self", ".", "timestep", "%", "self", ".", "_update_period", "==", "0", ")", ":", "\n", "            ", "self", ".", "_sess", ".", "run", "(", "self", ".", "_update_op", ",", "feed_dict", "=", "feed_dict", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.agents.dqn_agent.DQNAgent.get_action": [[211, 225], ["dqn_agent.DQNAgent._sess.run", "numpy.zeros", "random.random", "dqn_agent.DQNAgent._exploration.get_epsilon", "random.randrange", "numpy.argmax", "texar.global_mode", "numpy.array"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.core.explorations.EpsilonLinearDecayExploration.get_epsilon", "home.repos.pwc.inspect_result.VegB_Text_Infilling.texar.context.global_mode"], ["", "", "def", "get_action", "(", "self", ",", "observ", ",", "feed_dict", "=", "None", ")", ":", "\n", "        ", "qvalue", "=", "self", ".", "_sess", ".", "run", "(", "\n", "self", ".", "_qnet_outputs", "[", "'qvalues'", "]", ",", "\n", "feed_dict", "=", "{", "self", ".", "_observ_inputs", ":", "np", ".", "array", "(", "[", "observ", "]", ")", ",", "\n", "tx", ".", "global_mode", "(", ")", ":", "tf", ".", "estimator", ".", "ModeKeys", ".", "PREDICT", "}", ")", "\n", "\n", "action", "=", "np", ".", "zeros", "(", "shape", "=", "self", ".", "_num_actions", ")", "\n", "if", "random", ".", "random", "(", ")", "<", "self", ".", "_exploration", ".", "get_epsilon", "(", "self", ".", "timestep", ")", ":", "\n", "            ", "action_id", "=", "random", ".", "randrange", "(", "self", ".", "_num_actions", ")", "\n", "", "else", ":", "\n", "            ", "action_id", "=", "np", ".", "argmax", "(", "qvalue", ")", "\n", "", "action", "[", "action_id", "]", "=", "1.0", "\n", "\n", "return", "action_id", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.agents.dqn_agent.DQNAgent._reset": [[226, 228], ["None"], "methods", ["None"], ["", "def", "_reset", "(", "self", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.agents.dqn_agent.DQNAgent.sess": [[235, 238], ["None"], "methods", ["None"], ["", "@", "sess", ".", "setter", "\n", "def", "sess", "(", "self", ",", "session", ")", ":", "\n", "        ", "self", ".", "_sess", "=", "session", "\n", "", "", ""]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.agents.agent_utils.Space.__init__": [[28, 56], ["numpy.isscalar", "numpy.isscalar", "numpy.dtype", "numpy.asarray.astype", "numpy.asarray.astype", "float", "numpy.asarray", "numpy.asarray", "ValueError", "float", "ValueError", "numpy.zeros", "numpy.zeros"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "shape", "=", "None", ",", "low", "=", "None", ",", "high", "=", "None", ",", "dtype", "=", "None", ")", ":", "\n", "        ", "if", "low", "is", "None", ":", "\n", "            ", "low", "=", "-", "float", "(", "'inf'", ")", "\n", "", "if", "high", "is", "None", ":", "\n", "            ", "high", "=", "float", "(", "'inf'", ")", "\n", "", "if", "shape", "is", "None", ":", "\n", "            ", "low", "=", "np", ".", "asarray", "(", "low", ")", "\n", "high", "=", "np", ".", "asarray", "(", "high", ")", "\n", "if", "low", ".", "shape", "!=", "high", ".", "shape", ":", "\n", "                ", "raise", "ValueError", "(", "'`low` and `high` must have the same shape.'", ")", "\n", "", "shape", "=", "low", ".", "shape", "\n", "", "if", "np", ".", "isscalar", "(", "low", ")", ":", "\n", "            ", "low", "=", "low", "+", "np", ".", "zeros", "(", "shape", ",", "dtype", "=", "dtype", ")", "\n", "", "if", "np", ".", "isscalar", "(", "high", ")", ":", "\n", "            ", "high", "=", "high", "+", "np", ".", "zeros", "(", "shape", ",", "dtype", "=", "dtype", ")", "\n", "", "if", "shape", "!=", "low", ".", "shape", "or", "shape", "!=", "high", ".", "shape", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "'Shape inconsistent: shape={}, low.shape={}, high.shape={}'", "\n", ".", "format", "(", "shape", ",", "low", ".", "shape", ",", "high", ".", "shape", ")", ")", "\n", "", "if", "dtype", "is", "None", ":", "\n", "            ", "dtype", "=", "low", ".", "dtype", "\n", "", "dtype", "=", "np", ".", "dtype", "(", "dtype", ")", "\n", "low", "=", "low", ".", "astype", "(", "dtype", ")", "\n", "high", "=", "high", ".", "astype", "(", "dtype", ")", "\n", "self", ".", "shape", "=", "shape", "\n", "self", ".", "low", "=", "low", "\n", "self", ".", "high", "=", "high", "\n", "self", ".", "dtype", "=", "dtype", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.agents.agent_utils.Space.contains": [[57, 69], ["numpy.asarray"], "methods", ["None"], ["", "def", "contains", "(", "self", ",", "x", ")", ":", "\n", "        ", "\"\"\"Checks if :attr:`x` is contained in the space.\n        \"\"\"", "\n", "x", "=", "np", ".", "asarray", "(", "x", ")", "\n", "dtype_match", "=", "True", "\n", "if", "self", ".", "dtype", ".", "kind", "in", "np", ".", "typecodes", "[", "'AllInteger'", "]", ":", "\n", "            ", "if", "x", ".", "dtype", ".", "kind", "not", "in", "np", ".", "typecodes", "[", "'AllInteger'", "]", ":", "\n", "                ", "dtype_match", "=", "False", "\n", "", "", "shape_match", "=", "x", ".", "shape", "==", "self", ".", "shape", "\n", "low_match", "=", "(", "x", ">=", "self", ".", "low", ")", ".", "all", "(", ")", "\n", "high_match", "=", "(", "x", "<=", "self", ".", "high", ")", ".", "all", "(", ")", "\n", "return", "dtype_match", "and", "shape_match", "and", "low_match", "and", "high_match", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.agents.agent_utils.EnvConfig.__init__": [[82, 99], ["gym_utils.convert_gym_space", "gym_utils.convert_gym_space"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.agents.agent_gym_utils.convert_gym_space", "home.repos.pwc.inspect_result.VegB_Text_Infilling.agents.agent_gym_utils.convert_gym_space"], ["def", "__init__", "(", "self", ",", "\n", "action_space", ",", "\n", "observ_space", ",", "\n", "reward_range", ")", ":", "\n", "        ", "if", "gym_utils", ":", "\n", "            ", "action_space", "=", "gym_utils", ".", "convert_gym_space", "(", "action_space", ")", "\n", "observ_space", "=", "gym_utils", ".", "convert_gym_space", "(", "observ_space", ")", "\n", "\n", "", "self", ".", "action_space", "=", "action_space", "\n", "self", ".", "action_dtype", "=", "action_space", ".", "dtype", "\n", "self", ".", "action_shape", "=", "action_space", ".", "shape", "\n", "\n", "self", ".", "observ_space", "=", "observ_space", "\n", "self", ".", "observ_dtype", "=", "observ_space", ".", "dtype", "\n", "self", ".", "observ_shape", "=", "observ_space", ".", "shape", "\n", "\n", "self", ".", "reward_range", "=", "reward_range", "\n", "", "", ""]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.agents.episodic_agent_base.EpisodicAgentBase.__init__": [[22, 33], ["texar.agents.agent_base.AgentBase.__init__", "tensorflow.make_template", "tensorflow.make_template", "tensorflow.make_template"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.text_infilling.self_attn_hyperparams.Hyperparams.__init__"], ["def", "__init__", "(", "self", ",", "env_config", ",", "hparams", "=", "None", ")", ":", "\n", "        ", "AgentBase", ".", "__init__", "(", "self", ",", "hparams", ")", "\n", "\n", "self", ".", "_env_config", "=", "env_config", "\n", "\n", "self", ".", "_reset_tmplt_fn", "=", "tf", ".", "make_template", "(", "\n", "\"{}_reset\"", ".", "format", "(", "self", ".", "name", ")", ",", "self", ".", "_reset", ")", "\n", "self", ".", "_observe_tmplt_fn", "=", "tf", ".", "make_template", "(", "\n", "\"{}_observe\"", ".", "format", "(", "self", ".", "name", ")", ",", "self", ".", "_observe", ")", "\n", "self", ".", "_get_action_tmplt_fn", "=", "tf", ".", "make_template", "(", "\n", "\"{}_get_action\"", ".", "format", "(", "self", ".", "name", ")", ",", "self", ".", "_get_action", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.agents.episodic_agent_base.EpisodicAgentBase.default_hparams": [[34, 42], ["None"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "default_hparams", "(", ")", ":", "\n", "        ", "\"\"\"Returns a dictionary of hyperparameters with default values.\n\n        TODO\n        \"\"\"", "\n", "return", "{", "\n", "'name'", ":", "'agent'", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.agents.episodic_agent_base.EpisodicAgentBase.reset": [[44, 48], ["episodic_agent_base.EpisodicAgentBase._reset_tmplt_fn"], "methods", ["None"], ["", "def", "reset", "(", "self", ")", ":", "\n", "        ", "\"\"\"Resets the states to begin new episodes.\n        \"\"\"", "\n", "self", ".", "_reset_tmplt_fn", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.agents.episodic_agent_base.EpisodicAgentBase._reset": [[49, 51], ["None"], "methods", ["None"], ["", "def", "_reset", "(", "self", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.agents.episodic_agent_base.EpisodicAgentBase.observe": [[52, 59], ["episodic_agent_base.EpisodicAgentBase._observe_tmplt_fn"], "methods", ["None"], ["", "def", "observe", "(", "self", ",", "observ", ",", "action", ",", "reward", ",", "terminal", ",", "next_observ", ",", "train_policy", "=", "True", ",", "feed_dict", "=", "None", ")", ":", "\n", "        ", "\"\"\"Observes experience from environment.\n\n        Args:\n        \"\"\"", "\n", "return", "self", ".", "_observe_tmplt_fn", "(", "\n", "observ", ",", "action", ",", "reward", ",", "terminal", ",", "next_observ", ",", "train_policy", ",", "feed_dict", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.agents.episodic_agent_base.EpisodicAgentBase._observe": [[60, 62], ["None"], "methods", ["None"], ["", "def", "_observe", "(", "self", ",", "observ", ",", "action", ",", "reward", ",", "terminal", ",", "next_observ", ",", "train_policy", ",", "feed_dict", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.agents.episodic_agent_base.EpisodicAgentBase.get_action": [[63, 71], ["episodic_agent_base.EpisodicAgentBase._get_action_tmplt_fn"], "methods", ["None"], ["", "def", "get_action", "(", "self", ",", "observ", ",", "feed_dict", "=", "None", ")", ":", "\n", "        ", "\"\"\"Gets action according to observation.\n\n        Args:\n\n        Returns:\n        \"\"\"", "\n", "return", "self", ".", "_get_action_tmplt_fn", "(", "observ", ",", "feed_dict", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.agents.episodic_agent_base.EpisodicAgentBase._get_action": [[72, 74], ["None"], "methods", ["None"], ["", "def", "_get_action", "(", "self", ",", "observ", ",", "feed_dict", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.agents.seq_pg_agent_test.SeqPGAgentTest.setUp": [[20, 31], ["tensorflow.test.TestCase.setUp", "tensorflow.random_uniform", "tensorflow.random_uniform"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.losses.mle_losses_test.MLELossesTest.setUp"], ["def", "setUp", "(", "self", ")", ":", "\n", "        ", "tf", ".", "test", ".", "TestCase", ".", "setUp", "(", "self", ")", "\n", "self", ".", "_vocab_size", "=", "4", "\n", "self", ".", "_max_time", "=", "8", "\n", "self", ".", "_batch_size", "=", "16", "\n", "self", ".", "_emb_dim", "=", "20", "\n", "self", ".", "_inputs", "=", "tf", ".", "random_uniform", "(", "\n", "[", "self", ".", "_batch_size", ",", "self", ".", "_max_time", ",", "self", ".", "_emb_dim", "]", ",", "\n", "maxval", "=", "1.", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "self", ".", "_embedding", "=", "tf", ".", "random_uniform", "(", "\n", "[", "self", ".", "_vocab_size", ",", "self", ".", "_emb_dim", "]", ",", "maxval", "=", "1.", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.agents.seq_pg_agent_test.SeqPGAgentTest.test_seq_pg_agent": [[32, 64], ["texar.modules.decoders.rnn_decoders.BasicRNNDecoder", "texar.modules.decoders.rnn_decoders.BasicRNNDecoder.", "texar.agents.SeqPGAgent", "seq_pg_agent_test.SeqPGAgentTest.test_session", "sess.run", "range", "tensorflow.global_variables_initializer", "texar.context.global_mode", "texar.agents.SeqPGAgent.get_samples", "seq_pg_agent_test.SeqPGAgentTest.assertEqual", "texar.agents.SeqPGAgent.observe", "texar.agents.SeqPGAgent.observe", "seq_pg_agent_test.SeqPGAgentTest.assertEqual", "seq_pg_agent_test.SeqPGAgentTest.assertEqual"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.texar.context.global_mode", "home.repos.pwc.inspect_result.VegB_Text_Infilling.agents.seq_pg_agent.SeqPGAgent.get_samples", "home.repos.pwc.inspect_result.VegB_Text_Infilling.agents.seq_pg_agent.SeqPGAgent.observe", "home.repos.pwc.inspect_result.VegB_Text_Infilling.agents.seq_pg_agent.SeqPGAgent.observe"], ["", "def", "test_seq_pg_agent", "(", "self", ")", ":", "\n", "        ", "\"\"\"Tests logits.\n        \"\"\"", "\n", "decoder", "=", "BasicRNNDecoder", "(", "vocab_size", "=", "self", ".", "_vocab_size", ")", "\n", "outputs", ",", "_", ",", "sequence_length", "=", "decoder", "(", "\n", "decoding_strategy", "=", "\"infer_greedy\"", ",", "\n", "max_decoding_length", "=", "10", ",", "\n", "embedding", "=", "self", ".", "_embedding", ",", "\n", "start_tokens", "=", "[", "1", "]", "*", "self", ".", "_batch_size", ",", "\n", "end_token", "=", "2", ")", "\n", "\n", "agent", "=", "SeqPGAgent", "(", "\n", "outputs", ".", "sample_id", ",", "outputs", ".", "logits", ",", "sequence_length", ",", "\n", "decoder", ".", "trainable_variables", ")", "\n", "\n", "with", "self", ".", "test_session", "(", ")", "as", "sess", ":", "\n", "            ", "sess", ".", "run", "(", "tf", ".", "global_variables_initializer", "(", ")", ")", "\n", "\n", "agent", ".", "sess", "=", "sess", "\n", "\n", "feed_dict", "=", "{", "context", ".", "global_mode", "(", ")", ":", "tf", ".", "estimator", ".", "ModeKeys", ".", "TRAIN", "}", "\n", "for", "_", "in", "range", "(", "2", ")", ":", "\n", "                ", "samples", ",", "_", "=", "agent", ".", "get_samples", "(", "feed_dict", ")", "\n", "self", ".", "assertEqual", "(", "samples", ".", "shape", "[", "0", "]", ",", "self", ".", "_batch_size", ")", "\n", "\n", "loss_1", "=", "agent", ".", "observe", "(", "\n", "[", "1.", "]", "*", "self", ".", "_batch_size", ",", "feed_dict", "=", "feed_dict", ")", "\n", "loss_2", "=", "agent", ".", "observe", "(", "\n", "[", "1.", "]", "*", "self", ".", "_batch_size", ",", "train_policy", "=", "False", ",", "\n", "feed_dict", "=", "feed_dict", ")", "\n", "self", ".", "assertEqual", "(", "loss_1", ".", "shape", ",", "(", ")", ")", "\n", "self", ".", "assertEqual", "(", "loss_2", ".", "shape", ",", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.agents.seq_pg_agent.SeqPGAgent.__init__": [[28, 58], ["texar.agents.seq_agent_base.SeqAgentBase.__init__", "seq_pg_agent.SeqPGAgent._build_graph"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.text_infilling.self_attn_hyperparams.Hyperparams.__init__", "home.repos.pwc.inspect_result.VegB_Text_Infilling.agents.seq_pg_agent.SeqPGAgent._build_graph"], ["def", "__init__", "(", "self", ",", "\n", "samples", ",", "\n", "logits", ",", "\n", "sequence_length", ",", "\n", "trainable_variables", "=", "None", ",", "\n", "learning_rate", "=", "None", ",", "\n", "sess", "=", "None", ",", "\n", "hparams", "=", "None", ")", ":", "\n", "        ", "SeqAgentBase", ".", "__init__", "(", "self", ",", "hparams", ")", "\n", "\n", "self", ".", "_lr", "=", "learning_rate", "\n", "\n", "# Tensors", "\n", "self", ".", "_samples", "=", "samples", "\n", "self", ".", "_logits", "=", "logits", "\n", "self", ".", "_sequence_length", "=", "sequence_length", "\n", "self", ".", "_trainable_variables", "=", "trainable_variables", "\n", "\n", "# Python values", "\n", "self", ".", "_samples_py", "=", "None", "\n", "self", ".", "_sequence_length_py", "=", "None", "\n", "self", ".", "_rewards", "=", "None", "\n", "\n", "self", ".", "_sess", "=", "sess", "\n", "\n", "# For session partial run", "\n", "self", ".", "_partial_run_handle", "=", "None", "\n", "self", ".", "_qvalue_inputs_fed", "=", "False", "\n", "\n", "self", ".", "_build_graph", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.agents.seq_pg_agent.SeqPGAgent._build_graph": [[59, 67], ["tensorflow.variable_scope", "tensorflow.placeholder", "seq_pg_agent.SeqPGAgent._get_pg_loss", "seq_pg_agent.SeqPGAgent._get_train_op"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.agents.agent_base.AgentBase.variable_scope", "home.repos.pwc.inspect_result.VegB_Text_Infilling.agents.seq_pg_agent.SeqPGAgent._get_pg_loss", "home.repos.pwc.inspect_result.VegB_Text_Infilling.seq2seq.seq2seq_base.Seq2seqBase._get_train_op"], ["", "def", "_build_graph", "(", "self", ")", ":", "\n", "        ", "with", "tf", ".", "variable_scope", "(", "self", ".", "variable_scope", ")", ":", "\n", "            ", "self", ".", "_qvalue_inputs", "=", "tf", ".", "placeholder", "(", "\n", "dtype", "=", "tf", ".", "float32", ",", "\n", "shape", "=", "[", "None", ",", "None", "]", ",", "\n", "name", "=", "'qvalue_inputs'", ")", "\n", "self", ".", "_pg_loss", "=", "self", ".", "_get_pg_loss", "(", ")", "\n", "self", ".", "_train_op", "=", "self", ".", "_get_train_op", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.agents.seq_pg_agent.SeqPGAgent._get_pg_loss": [[68, 87], ["texar.losses.pg_losses.pg_loss_with_logits", "seq_pg_agent.SeqPGAgent._get_entropy"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.losses.pg_losses.pg_loss_with_logits", "home.repos.pwc.inspect_result.VegB_Text_Infilling.losses.entropy._get_entropy"], ["", "", "def", "_get_pg_loss", "(", "self", ")", ":", "\n", "        ", "loss_hparams", "=", "self", ".", "_hparams", ".", "loss", "\n", "pg_loss", "=", "pg_loss_with_logits", "(", "\n", "actions", "=", "self", ".", "_samples", ",", "\n", "logits", "=", "self", ".", "_logits", ",", "\n", "sequence_length", "=", "self", ".", "_sequence_length", ",", "\n", "advantages", "=", "self", ".", "_qvalue_inputs", ",", "\n", "batched", "=", "True", ",", "\n", "average_across_batch", "=", "loss_hparams", ".", "average_across_batch", ",", "\n", "average_across_timesteps", "=", "loss_hparams", ".", "average_across_timesteps", ",", "\n", "sum_over_batch", "=", "loss_hparams", ".", "sum_over_batch", ",", "\n", "sum_over_timesteps", "=", "loss_hparams", ".", "sum_over_timesteps", ",", "\n", "time_major", "=", "loss_hparams", ".", "time_major", ")", "\n", "\n", "if", "self", ".", "_hparams", ".", "entropy_weight", ">", "0", ":", "\n", "            ", "entropy", "=", "self", ".", "_get_entropy", "(", ")", "\n", "pg_loss", "-=", "self", ".", "_hparams", ".", "entropy_weight", "*", "entropy", "\n", "\n", "", "return", "pg_loss", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.agents.seq_pg_agent.SeqPGAgent._get_entropy": [[88, 98], ["texar.losses.entropy.sequence_entropy_with_logits"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.losses.entropy.sequence_entropy_with_logits"], ["", "def", "_get_entropy", "(", "self", ")", ":", "\n", "        ", "loss_hparams", "=", "self", ".", "_hparams", ".", "loss", "\n", "return", "sequence_entropy_with_logits", "(", "\n", "self", ".", "_logits", ",", "\n", "sequence_length", "=", "self", ".", "_sequence_length", ",", "\n", "average_across_batch", "=", "loss_hparams", ".", "average_across_batch", ",", "\n", "average_across_timesteps", "=", "loss_hparams", ".", "average_across_timesteps", ",", "\n", "sum_over_batch", "=", "loss_hparams", ".", "sum_over_batch", ",", "\n", "sum_over_timesteps", "=", "loss_hparams", ".", "sum_over_timesteps", ",", "\n", "time_major", "=", "loss_hparams", ".", "time_major", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.agents.seq_pg_agent.SeqPGAgent._get_train_op": [[99, 106], ["texar.core.optimization.get_train_op", "seq_pg_agent.SeqPGAgent._hparams.optimization.todict"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.core.optimization.get_train_op", "home.repos.pwc.inspect_result.VegB_Text_Infilling.texar.hyperparams.HParams.todict"], ["", "def", "_get_train_op", "(", "self", ")", ":", "\n", "        ", "train_op", "=", "opt", ".", "get_train_op", "(", "\n", "loss", "=", "self", ".", "_pg_loss", ",", "\n", "variables", "=", "self", ".", "_trainable_variables", ",", "\n", "learning_rate", "=", "self", ".", "_lr", ",", "\n", "hparams", "=", "self", ".", "_hparams", ".", "optimization", ".", "todict", "(", ")", ")", "\n", "return", "train_op", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.agents.seq_pg_agent.SeqPGAgent.default_hparams": [[107, 122], ["texar.core.optimization.default_optimization_hparams"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.core.optimization.default_optimization_hparams"], ["", "@", "staticmethod", "\n", "def", "default_hparams", "(", ")", ":", "\n", "        ", "return", "{", "\n", "'discount_factor'", ":", "0.95", ",", "\n", "'normalize_reward'", ":", "False", ",", "\n", "'entropy_weight'", ":", "0.", ",", "\n", "'loss'", ":", "{", "\n", "'average_across_batch'", ":", "True", ",", "\n", "'average_across_timesteps'", ":", "False", ",", "\n", "'sum_over_batch'", ":", "False", ",", "\n", "'sum_over_timesteps'", ":", "True", ",", "\n", "'time_major'", ":", "False", "\n", "}", ",", "\n", "'optimization'", ":", "opt", ".", "default_optimization_hparams", "(", ")", ",", "\n", "'name'", ":", "'pg_agent'", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.agents.seq_pg_agent.SeqPGAgent._get_partial_run_feeds": [[124, 129], ["None"], "methods", ["None"], ["", "def", "_get_partial_run_feeds", "(", "self", ",", "feeds", "=", "None", ")", ":", "\n", "        ", "if", "feeds", "is", "None", ":", "\n", "            ", "feeds", "=", "[", "]", "\n", "", "feeds", "+=", "[", "self", ".", "_qvalue_inputs", "]", "\n", "return", "feeds", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.agents.seq_pg_agent.SeqPGAgent._setup_partial_run": [[130, 144], ["seq_pg_agent.SeqPGAgent._get_partial_run_feeds", "seq_pg_agent.SeqPGAgent._sess.partial_run_setup", "fetches_.append"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.agents.seq_pg_agent.SeqPGAgent._get_partial_run_feeds"], ["", "def", "_setup_partial_run", "(", "self", ",", "fetches", "=", "None", ",", "feeds", "=", "None", ")", ":", "\n", "        ", "fetches_", "=", "[", "self", ".", "_samples", ",", "self", ".", "_sequence_length", ",", "self", ".", "_pg_loss", ",", "\n", "self", ".", "_train_op", "]", "\n", "if", "fetches", "is", "not", "None", ":", "\n", "            ", "for", "fet", "in", "fetches", ":", "\n", "                ", "if", "fet", "not", "in", "fetches_", ":", "\n", "                    ", "fetches_", ".", "append", "(", "fet", ")", "\n", "\n", "", "", "", "feeds", "=", "self", ".", "_get_partial_run_feeds", "(", "feeds", ")", "\n", "\n", "self", ".", "_partial_run_handle", "=", "self", ".", "_sess", ".", "partial_run_setup", "(", "\n", "fetches_", ",", "feeds", "=", "feeds", ")", "\n", "\n", "self", ".", "_qvalue_inputs_fed", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.agents.seq_pg_agent.SeqPGAgent._check_extra_fetches": [[145, 165], ["list", "extra_fetches.values", "ValueError", "ValueError", "ValueError", "ValueError"], "methods", ["None"], ["", "def", "_check_extra_fetches", "(", "self", ",", "extra_fetches", ")", ":", "\n", "        ", "fetch_values", "=", "None", "\n", "if", "extra_fetches", "is", "not", "None", ":", "\n", "            ", "fetch_values", "=", "list", "(", "extra_fetches", ".", "values", "(", ")", ")", "\n", "", "if", "fetch_values", "is", "not", "None", ":", "\n", "            ", "if", "self", ".", "_samples", "in", "fetch_values", ":", "\n", "                ", "raise", "ValueError", "(", "\n", "\"`samples` must not be included in `extra_fetches`. \"", "\n", "\"It is added automatically.\"", ")", "\n", "", "if", "self", ".", "_sequence_length", "in", "fetch_values", ":", "\n", "                ", "raise", "ValueError", "(", "\n", "\"`sequence_length` must not be included in `extra_fetches`.\"", "\n", "\" It is added automatically.\"", ")", "\n", "", "if", "\"samples\"", "in", "extra_fetches", ":", "\n", "                ", "raise", "ValueError", "(", "\n", "\"Key 'samples' is preserved and must not be used \"", "\n", "\"in `extra_fetches`.\"", ")", "\n", "", "if", "\"sequence_length\"", "in", "extra_fetches", ":", "\n", "                ", "raise", "ValueError", "(", "\n", "\"Key 'sequence_length' is preserved and must not be used \"", "\n", "\"in `extra_fetches`.\"", ")", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.agents.seq_pg_agent.SeqPGAgent.get_samples": [[167, 201], ["seq_pg_agent.SeqPGAgent._check_extra_fetches", "seq_pg_agent.SeqPGAgent._setup_partial_run", "seq_pg_agent.SeqPGAgent._sess.partial_run", "ValueError", "list", "list", "fetches.update", "extra_fetches.values", "feed_dict.keys"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.agents.seq_pg_agent.SeqPGAgent._check_extra_fetches", "home.repos.pwc.inspect_result.VegB_Text_Infilling.agents.seq_pg_agent.SeqPGAgent._setup_partial_run", "home.repos.pwc.inspect_result.VegB_Text_Infilling.texar.hyperparams.HParams.keys"], ["", "", "", "def", "get_samples", "(", "self", ",", "extra_fetches", "=", "None", ",", "feed_dict", "=", "None", ")", ":", "\n", "        ", "\"\"\"TODO\n        \"\"\"", "\n", "if", "self", ".", "_sess", "is", "None", ":", "\n", "            ", "raise", "ValueError", "(", "\"`sess` must be specified before sampling.\"", ")", "\n", "\n", "", "self", ".", "_check_extra_fetches", "(", "extra_fetches", ")", "\n", "\n", "# Sets up partial_run", "\n", "fetch_values", "=", "None", "\n", "if", "extra_fetches", "is", "not", "None", ":", "\n", "            ", "fetch_values", "=", "list", "(", "extra_fetches", ".", "values", "(", ")", ")", "\n", "", "feeds", "=", "None", "\n", "if", "feed_dict", "is", "not", "None", ":", "\n", "            ", "feeds", "=", "list", "(", "feed_dict", ".", "keys", "(", ")", ")", "\n", "", "self", ".", "_setup_partial_run", "(", "fetches", "=", "fetch_values", ",", "feeds", "=", "feeds", ")", "\n", "\n", "# Runs the sampling", "\n", "fetches", "=", "{", "\n", "\"samples\"", ":", "self", ".", "_samples", ",", "\n", "\"sequence_length\"", ":", "self", ".", "_sequence_length", "\n", "}", "\n", "if", "extra_fetches", "is", "not", "None", ":", "\n", "            ", "fetches", ".", "update", "(", "extra_fetches", ")", "\n", "\n", "", "feed_dict_", "=", "feed_dict", "\n", "\n", "vals", "=", "self", ".", "_sess", ".", "partial_run", "(", "\n", "self", ".", "_partial_run_handle", ",", "fetches", ",", "feed_dict", "=", "feed_dict_", ")", "\n", "\n", "self", ".", "_samples_py", "=", "vals", "[", "'samples'", "]", "\n", "self", ".", "_sequence_length_py", "=", "vals", "[", "'sequence_length'", "]", "\n", "\n", "return", "vals", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.agents.seq_pg_agent.SeqPGAgent.observe": [[202, 217], ["seq_pg_agent.SeqPGAgent._train_policy", "seq_pg_agent.SeqPGAgent._evaluate_pg_loss"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.agents.seq_pg_agent.SeqPGAgent._train_policy", "home.repos.pwc.inspect_result.VegB_Text_Infilling.agents.seq_pg_agent.SeqPGAgent._evaluate_pg_loss"], ["", "def", "observe", "(", "self", ",", "reward", ",", "train_policy", "=", "True", ",", "return_loss", "=", "True", ")", ":", "\n", "        ", "\"\"\"\n\n        Args:\n            reward: A Python array of shape `[batch_size]`.\n            TODO\n        \"\"\"", "\n", "self", ".", "_rewards", "=", "reward", "\n", "\n", "if", "train_policy", ":", "\n", "            ", "return", "self", ".", "_train_policy", "(", ")", "\n", "", "elif", "return_loss", ":", "\n", "            ", "return", "self", ".", "_evaluate_pg_loss", "(", ")", "\n", "", "else", ":", "\n", "            ", "return", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.agents.seq_pg_agent.SeqPGAgent._get_qvalues": [[218, 225], ["texar.losses.rewards.discount_reward"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.losses.rewards.discount_reward"], ["", "", "def", "_get_qvalues", "(", "self", ")", ":", "\n", "        ", "qvalues", "=", "discount_reward", "(", "\n", "self", ".", "_rewards", ",", "\n", "self", ".", "_sequence_length_py", ",", "\n", "discount", "=", "self", ".", "_hparams", ".", "discount_factor", ",", "\n", "normalize", "=", "self", ".", "_hparams", ".", "normalize_reward", ")", "\n", "return", "qvalues", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.agents.seq_pg_agent.SeqPGAgent._evaluate_pg_loss": [[226, 242], ["seq_pg_agent.SeqPGAgent._sess.partial_run", "seq_pg_agent.SeqPGAgent._get_qvalues"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.agents.seq_pg_agent.SeqPGAgent._get_qvalues"], ["", "def", "_evaluate_pg_loss", "(", "self", ")", ":", "\n", "        ", "fetches", "=", "{", "\n", "\"loss\"", ":", "self", ".", "_pg_loss", "\n", "}", "\n", "\n", "feed_dict_", "=", "None", "\n", "if", "not", "self", ".", "_qvalue_inputs_fed", ":", "\n", "            ", "qvalues", "=", "self", ".", "_get_qvalues", "(", ")", "\n", "feed_dict_", "=", "{", "self", ".", "_qvalue_inputs", ":", "qvalues", "}", "\n", "\n", "", "vals", "=", "self", ".", "_sess", ".", "partial_run", "(", "\n", "self", ".", "_partial_run_handle", ",", "fetches", ",", "feed_dict", "=", "feed_dict_", ")", "\n", "\n", "self", ".", "_qvalue_inputs_fed", "=", "True", "\n", "\n", "return", "vals", "[", "'loss'", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.agents.seq_pg_agent.SeqPGAgent._train_policy": [[243, 264], ["seq_pg_agent.SeqPGAgent._sess.partial_run", "seq_pg_agent.SeqPGAgent._get_qvalues"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.agents.seq_pg_agent.SeqPGAgent._get_qvalues"], ["", "def", "_train_policy", "(", "self", ")", ":", "\n", "        ", "\"\"\"Updates the policy.\n\n        Args:\n            TODO\n        \"\"\"", "\n", "fetches", "=", "{", "\n", "\"loss\"", ":", "self", ".", "_train_op", ",", "\n", "}", "\n", "\n", "feed_dict_", "=", "None", "\n", "if", "not", "self", ".", "_qvalue_inputs_fed", ":", "\n", "            ", "qvalues", "=", "self", ".", "_get_qvalues", "(", ")", "\n", "feed_dict_", "=", "{", "self", ".", "_qvalue_inputs", ":", "qvalues", "}", "\n", "\n", "", "vals", "=", "self", ".", "_sess", ".", "partial_run", "(", "\n", "self", ".", "_partial_run_handle", ",", "fetches", ",", "feed_dict", "=", "feed_dict_", ")", "\n", "\n", "self", ".", "_qvalue_inputs_fed", "=", "True", "\n", "\n", "return", "vals", "[", "'loss'", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.agents.seq_pg_agent.SeqPGAgent.sess": [[271, 274], ["None"], "methods", ["None"], ["", "@", "sess", ".", "setter", "\n", "def", "sess", "(", "self", ",", "sess", ")", ":", "\n", "        ", "self", ".", "_sess", "=", "sess", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.agents.seq_pg_agent.SeqPGAgent.pg_loss": [[275, 280], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "pg_loss", "(", "self", ")", ":", "\n", "        ", "\"\"\"The scalar tensor of policy gradient loss.\n        \"\"\"", "\n", "return", "self", ".", "_pg_loss", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.agents.seq_pg_agent.SeqPGAgent.sequence_length": [[281, 286], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "sequence_length", "(", "self", ")", ":", "\n", "        ", "\"\"\"The tensor of sample sequence length, of shape `[batch_size]`.\n        \"\"\"", "\n", "return", "self", ".", "_sequence_length", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.agents.seq_pg_agent.SeqPGAgent.samples": [[287, 292], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "samples", "(", "self", ")", ":", "\n", "        ", "\"\"\"The tensor of sequence samples.\n        \"\"\"", "\n", "return", "self", ".", "_samples", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.agents.seq_pg_agent.SeqPGAgent.logits": [[293, 298], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "logits", "(", "self", ")", ":", "\n", "        ", "\"\"\"The tensor of sequence logits.\n        \"\"\"", "\n", "return", "self", ".", "_logits", "\n", "", "", ""]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.agents.pg_agent.PGAgent.set_initial_state": [[76, 78], ["numpy.array"], "methods", ["None"], ["\n", "self", ".", "_train_op", "=", "self", ".", "_get_train_op", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.agents.pg_agent.PGAgent.perceive": [[79, 92], ["pg_agent.PGAgent.record.append", "numpy.array", "pg_agent.PGAgent.train_network", "list"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.agents.pg_agent.PGAgent.train_network"], ["", "", "def", "_get_policy_outputs", "(", "self", ")", ":", "\n", "        ", "outputs", "=", "self", ".", "_policy", "(", "\n", "inputs", "=", "self", ".", "_observ_inputs", ",", "**", "self", ".", "_policy_caller_kwargs", ")", "\n", "return", "outputs", "\n", "\n", "", "def", "_get_pg_loss", "(", "self", ")", ":", "\n", "        ", "log_probs", "=", "self", ".", "_outputs", "[", "'dist'", "]", ".", "log_prob", "(", "self", ".", "_action_inputs", ")", "\n", "pg_loss", "=", "losses", ".", "pg_loss_with_log_probs", "(", "\n", "log_probs", "=", "log_probs", ",", "\n", "advantages", "=", "self", ".", "_advantage_inputs", ",", "\n", "average_across_timesteps", "=", "True", ",", "\n", "sum_over_timesteps", "=", "False", ")", "\n", "return", "pg_loss", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.agents.pg_agent.PGAgent.train_network": [[93, 117], ["list", "list", "list", "range", "numpy.mean", "numpy.std", "enumerate", "pg_agent.PGAgent.sess.run", "list.append", "list.append", "list.append", "len"], "methods", ["None"], ["", "def", "_get_train_op", "(", "self", ")", ":", "\n", "        ", "train_op", "=", "opt", ".", "get_train_op", "(", "\n", "loss", "=", "self", ".", "_pg_loss", ",", "\n", "variables", "=", "self", ".", "_policy", ".", "trainable_variables", ",", "\n", "learning_rate", "=", "self", ".", "_lr", ",", "\n", "hparams", "=", "self", ".", "_hparams", ".", "optimization", ".", "todict", "(", ")", ")", "\n", "return", "train_op", "\n", "\n", "", "@", "staticmethod", "\n", "def", "default_hparams", "(", ")", ":", "\n", "        ", "return", "{", "\n", "'policy_type'", ":", "'CategoricalPolicyNet'", ",", "\n", "'policy_hparams'", ":", "None", ",", "\n", "'discount_factor'", ":", "0.95", ",", "\n", "'normalize_reward'", ":", "False", ",", "\n", "'optimization'", ":", "opt", ".", "default_optimization_hparams", "(", ")", ",", "\n", "'name'", ":", "'pg_agent'", ",", "\n", "}", "\n", "\n", "", "def", "_reset", "(", "self", ")", ":", "\n", "        ", "self", ".", "_observs", "=", "[", "]", "\n", "self", ".", "_actions", "=", "[", "]", "\n", "self", ".", "_rewards", "=", "[", "]", "\n", "\n", "", "def", "_get_action", "(", "self", ",", "observ", ",", "feed_dict", ")", ":", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.agents.pg_agent.PGAgent.get_action": [[119, 139], ["range", "range", "numpy.random.choice", "pg_agent.PGAgent.sess.run"], "methods", ["None"], ["\n", "feed_dict_", "=", "{", "self", ".", "_observ_inputs", ":", "[", "observ", ",", "]", "}", "\n", "feed_dict_", ".", "update", "(", "feed_dict", "or", "{", "}", ")", "\n", "\n", "vals", "=", "self", ".", "_sess", ".", "run", "(", "fetches", ",", "feed_dict", "=", "feed_dict_", ")", "\n", "action", "=", "vals", "[", "'action'", "]", "\n", "\n", "self", ".", "_observs", ".", "append", "(", "observ", ")", "\n", "self", ".", "_actions", ".", "append", "(", "action", ")", "\n", "\n", "return", "action", "\n", "\n", "", "def", "_observe", "(", "self", ",", "observ", ",", "action", ",", "reward", ",", "terminal", ",", "next_observ", ",", "train_policy", ",", "feed_dict", ")", ":", "\n", "        ", "self", ".", "_rewards", ".", "append", "(", "reward", ")", "\n", "\n", "if", "terminal", "and", "train_policy", ":", "\n", "            ", "self", ".", "_train_policy", "(", "feed_dict", "=", "feed_dict", ")", "\n", "\n", "", "", "def", "_train_policy", "(", "self", ",", "feed_dict", "=", "None", ")", ":", "\n", "        "]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.run.executor_test.ExecutorTest.setUp": [[24, 57], ["tensorflow.test.TestCase.setUp", "tempfile.NamedTemporaryFile", "tempfile.NamedTemporaryFile.write", "tempfile.NamedTemporaryFile.flush", "len", "tempfile.NamedTemporaryFile", "tempfile.NamedTemporaryFile.write", "tempfile.NamedTemporaryFile.flush", "tempfile.NamedTemporaryFile", "tempfile.NamedTemporaryFile.write", "tempfile.NamedTemporaryFile.flush"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.losses.mle_losses_test.MLELossesTest.setUp"], ["def", "setUp", "(", "self", ")", ":", "\n", "        ", "tf", ".", "test", ".", "TestCase", ".", "setUp", "(", "self", ")", "\n", "\n", "# Create data", "\n", "vocab_list", "=", "[", "'This'", ",", "'is'", ",", "'a'", ",", "'word'", ",", "'\u8bcd'", "]", "\n", "vocab_file", "=", "tempfile", ".", "NamedTemporaryFile", "(", ")", "\n", "vocab_file", ".", "write", "(", "'\\n'", ".", "join", "(", "vocab_list", ")", ".", "encode", "(", "\"utf-8\"", ")", ")", "\n", "vocab_file", ".", "flush", "(", ")", "\n", "self", ".", "_vocab_file", "=", "vocab_file", "\n", "self", ".", "_vocab_size", "=", "len", "(", "vocab_list", ")", "\n", "\n", "src_text", "=", "[", "'This is a sentence from source .'", ",", "'\u8bcd \u8bcd \u3002 source'", "]", "\n", "src_text_file", "=", "tempfile", ".", "NamedTemporaryFile", "(", ")", "\n", "src_text_file", ".", "write", "(", "'\\n'", ".", "join", "(", "src_text", ")", ".", "encode", "(", "\"utf-8\"", ")", ")", "\n", "src_text_file", ".", "flush", "(", ")", "\n", "self", ".", "_src_text_file", "=", "src_text_file", "\n", "\n", "tgt_text", "=", "[", "'This is a sentence from target .'", ",", "'\u8bcd \u8bcd \u3002 target'", "]", "\n", "tgt_text_file", "=", "tempfile", ".", "NamedTemporaryFile", "(", ")", "\n", "tgt_text_file", ".", "write", "(", "'\\n'", ".", "join", "(", "tgt_text", ")", ".", "encode", "(", "\"utf-8\"", ")", ")", "\n", "tgt_text_file", ".", "flush", "(", ")", "\n", "self", ".", "_tgt_text_file", "=", "tgt_text_file", "\n", "\n", "self", ".", "_data_hparams", "=", "{", "\n", "\"num_epochs\"", ":", "20", ",", "\n", "\"batch_size\"", ":", "2", ",", "\n", "\"source_dataset\"", ":", "{", "\n", "\"files\"", ":", "[", "self", ".", "_src_text_file", ".", "name", "]", ",", "\n", "\"vocab_file\"", ":", "self", ".", "_vocab_file", ".", "name", ",", "\n", "}", ",", "\n", "\"target_dataset\"", ":", "{", "\n", "\"files\"", ":", "self", ".", "_tgt_text_file", ".", "name", ",", "\n", "\"vocab_share\"", ":", "True", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.run.executor_test.ExecutorTest.test_execute_seq2seq": [[60, 81], ["texar.models.seq2seq.basic_seq2seq.BasicSeq2seq", "tempfile.mkdtemp", "tensorflow.estimator.RunConfig", "texar.run.executor.Executor", "texar.run.executor.Executor.train_and_evaluate", "texar.run.executor.Executor.train", "texar.run.executor.Executor.evaluate", "shutil.rmtree"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.run.executor.Executor.train_and_evaluate", "home.repos.pwc.inspect_result.VegB_Text_Infilling.run.executor.Executor.train", "home.repos.pwc.inspect_result.VegB_Text_Infilling.run.executor.Executor.evaluate"], ["", "def", "test_execute_seq2seq", "(", "self", ")", ":", "\n", "        ", "\"\"\"Tests running seq2seq with Executor.\n        \"\"\"", "\n", "seq2seq", "=", "BasicSeq2seq", "(", "self", ".", "_data_hparams", ")", "\n", "data_hparams", "=", "{", "'train'", ":", "self", ".", "_data_hparams", ",", "'eval'", ":", "self", ".", "_data_hparams", "}", "\n", "\n", "model_dir", "=", "tempfile", ".", "mkdtemp", "(", ")", "\n", "config", "=", "tf", ".", "estimator", ".", "RunConfig", "(", "\n", "model_dir", "=", "model_dir", ",", "\n", "save_summary_steps", "=", "10", ",", "\n", "save_checkpoints_steps", "=", "10", ",", "\n", "save_checkpoints_secs", "=", "None", ")", "\n", "\n", "exor", "=", "Executor", "(", "model", "=", "seq2seq", ",", "data_hparams", "=", "data_hparams", ",", "config", "=", "config", ")", "\n", "\n", "exor", ".", "train_and_evaluate", "(", "max_train_steps", "=", "20", ",", "eval_steps", "=", "5", ")", "\n", "\n", "exor", ".", "train", "(", "max_steps", "=", "20", ")", "\n", "exor", ".", "evaluate", "(", "steps", "=", "5", ")", "\n", "\n", "shutil", ".", "rmtree", "(", "model_dir", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.run.executor.Executor.__init__": [[46, 67], ["texar.utils.dtypes.maybe_hparams_to_dict", "texar.utils.dtypes.maybe_hparams_to_dict", "tensorflow.estimator.Estimator"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.dtypes.maybe_hparams_to_dict", "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.dtypes.maybe_hparams_to_dict"], ["def", "__init__", "(", "self", ",", "\n", "model", ",", "\n", "data_hparams", ",", "\n", "config", ",", "\n", "model_hparams", "=", "None", ",", "\n", "train_hooks", "=", "None", ",", "\n", "eval_hooks", "=", "None", ",", "\n", "session_config", "=", "None", ")", ":", "\n", "        ", "self", ".", "_model", "=", "model", "\n", "self", ".", "_data_hparams", "=", "maybe_hparams_to_dict", "(", "data_hparams", ")", "\n", "self", ".", "_config", "=", "config", "\n", "self", ".", "_train_hooks", "=", "train_hooks", "\n", "self", ".", "_eval_hooks", "=", "eval_hooks", "\n", "self", ".", "_session_config", "=", "session_config", "\n", "\n", "if", "model_hparams", "is", "None", ":", "\n", "            ", "model_hparams", "=", "model", ".", "hparams", "\n", "", "self", ".", "_model_hparams", "=", "maybe_hparams_to_dict", "(", "model_hparams", ")", "\n", "\n", "self", ".", "_estimator", "=", "tf", ".", "estimator", ".", "Estimator", "(", "\n", "model_fn", "=", "self", ".", "_model", ",", "config", "=", "config", ",", "params", "=", "self", ".", "_model_hparams", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.run.executor.Executor._get_train_spec": [[68, 79], ["executor.Executor._model.get_input_fn", "tensorflow.estimator.TrainSpec", "ValueError"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.seq2seq.seq2seq_base.Seq2seqBase.get_input_fn"], ["", "def", "_get_train_spec", "(", "self", ",", "max_steps", "=", "None", ")", ":", "\n", "        ", "if", "'train'", "not", "in", "self", ".", "_data_hparams", ":", "\n", "            ", "raise", "ValueError", "(", "'`data_hparams` must contain field `train` for '", "\n", "'training data config.'", ")", "\n", "", "input_fn", "=", "self", ".", "_model", ".", "get_input_fn", "(", "\n", "mode", "=", "tf", ".", "estimator", ".", "ModeKeys", ".", "TRAIN", ",", "\n", "hparams", "=", "self", ".", "_data_hparams", "[", "'train'", "]", ")", "\n", "return", "tf", ".", "estimator", ".", "TrainSpec", "(", "\n", "input_fn", "=", "input_fn", ",", "\n", "max_steps", "=", "max_steps", ",", "\n", "hooks", "=", "self", ".", "_train_hooks", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.run.executor.Executor._get_eval_spec": [[80, 91], ["executor.Executor._model.get_input_fn", "tensorflow.estimator.EvalSpec", "ValueError"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.seq2seq.seq2seq_base.Seq2seqBase.get_input_fn"], ["", "def", "_get_eval_spec", "(", "self", ",", "steps", ")", ":", "\n", "        ", "if", "'eval'", "not", "in", "self", ".", "_data_hparams", ":", "\n", "            ", "raise", "ValueError", "(", "'`data_hparams` must contain field `eval` for '", "\n", "'evaluation data config.'", ")", "\n", "", "input_fn", "=", "self", ".", "_model", ".", "get_input_fn", "(", "\n", "mode", "=", "tf", ".", "estimator", ".", "ModeKeys", ".", "EVAL", ",", "\n", "hparams", "=", "self", ".", "_data_hparams", "[", "'eval'", "]", ")", "\n", "return", "tf", ".", "estimator", ".", "EvalSpec", "(", "\n", "input_fn", "=", "input_fn", ",", "\n", "steps", "=", "steps", ",", "\n", "hooks", "=", "self", ".", "_eval_hooks", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.run.executor.Executor.train": [[92, 107], ["executor.Executor._get_train_spec", "executor.Executor._estimator.train"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.run.executor.Executor._get_train_spec", "home.repos.pwc.inspect_result.VegB_Text_Infilling.run.executor.Executor.train"], ["", "def", "train", "(", "self", ",", "max_steps", "=", "None", ")", ":", "\n", "        ", "\"\"\"Trains the model. See :tf_main:`tf.estimator.Estimator.train\n        <estimator/Estimator#train>` for more details.\n\n        Args:\n            max_steps (int, optional): Total number of steps for which\n                to train model. If `None`, train forever or until the train\n                data generates the OutOfRange exception. If OutOfRange occurs\n                in the middle, training stops before :attr:`max_steps` steps.\n        \"\"\"", "\n", "train_spec", "=", "self", ".", "_get_train_spec", "(", "max_steps", "=", "max_steps", ")", "\n", "self", ".", "_estimator", ".", "train", "(", "\n", "input_fn", "=", "train_spec", ".", "input_fn", ",", "\n", "hooks", "=", "train_spec", ".", "hooks", ",", "\n", "max_steps", "=", "train_spec", ".", "max_steps", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.run.executor.Executor.evaluate": [[108, 128], ["executor.Executor._get_eval_spec", "executor.Executor._estimator.evaluate"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.run.executor.Executor._get_eval_spec", "home.repos.pwc.inspect_result.VegB_Text_Infilling.run.executor.Executor.evaluate"], ["", "def", "evaluate", "(", "self", ",", "steps", "=", "None", ",", "checkpoint_path", "=", "None", ")", ":", "\n", "        ", "\"\"\"Evaluates the model. See :tf_main:`tf.estimator.Estimator.evaluate\n        <estimator/Estimator#evaluate>` for more details.\n\n        Args:\n            steps (int, optional): Number of steps for which to evaluate\n                model. If `None`, evaluates until the eval data raises an\n                OutOfRange exception.\n            checkpoint_path (str, optional): Path of a specific checkpoint to\n                evaluate. If `None`, the the latest checkpoint in\n                :attr:`config.model_dir` is used. If there are no checkpoints\n                in :attr:`model_dir`, evaluation is run with newly initialized\n                variables instead of restored from checkpoint.\n        \"\"\"", "\n", "eval_spec", "=", "self", ".", "_get_eval_spec", "(", "steps", "=", "steps", ")", "\n", "self", ".", "_estimator", ".", "evaluate", "(", "\n", "input_fn", "=", "eval_spec", ".", "input_fn", ",", "\n", "steps", "=", "eval_spec", ".", "steps", ",", "\n", "hooks", "=", "eval_spec", ".", "hooks", ",", "\n", "checkpoint_path", "=", "checkpoint_path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.run.executor.Executor.train_and_evaluate": [[129, 146], ["executor.Executor._get_train_spec", "executor.Executor._get_eval_spec", "tensorflow.estimator.train_and_evaluate"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.run.executor.Executor._get_train_spec", "home.repos.pwc.inspect_result.VegB_Text_Infilling.run.executor.Executor._get_eval_spec", "home.repos.pwc.inspect_result.VegB_Text_Infilling.run.executor.Executor.train_and_evaluate"], ["", "def", "train_and_evaluate", "(", "self", ",", "max_train_steps", "=", "None", ",", "eval_steps", "=", "None", ")", ":", "\n", "        ", "\"\"\"Trains and evaluates the model. See\n        :tf_main:`tf.estimator.train_and_evaluate\n        <estimator/train_and_evaluate>` for more details.\n\n        Args:\n            max_train_steps (int, optional): Total number of steps for which\n                to train model. If `None`, train forever or until the train\n                data generates the OutOfRange exception. If OutOfRange occurs\n                in the middle, training stops before :attr:`max_steps` steps.\n            eval_steps (int, optional): Number of steps for which to evaluate\n                model. If `None`, evaluates until the eval data raises an\n                OutOfRange exception.\n        \"\"\"", "\n", "train_spec", "=", "self", ".", "_get_train_spec", "(", "max_steps", "=", "max_train_steps", ")", "\n", "eval_spec", "=", "self", ".", "_get_eval_spec", "(", "steps", "=", "eval_steps", ")", "\n", "tf", ".", "estimator", ".", "train_and_evaluate", "(", "self", ".", "_estimator", ",", "train_spec", ",", "eval_spec", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.memory.memory_network.MemNetSingleLayer.__init__": [[76, 80], ["texar.module_base.ModuleBase.__init__"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.text_infilling.self_attn_hyperparams.Hyperparams.__init__"], ["def", "__init__", "(", "self", ",", "H", "=", "None", ",", "hparams", "=", "None", ")", ":", "\n", "        ", "ModuleBase", ".", "__init__", "(", "self", ",", "hparams", ")", "\n", "\n", "self", ".", "_H", "=", "H", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.memory.memory_network.MemNetSingleLayer.default_hparams": [[81, 99], ["None"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "default_hparams", "(", ")", ":", "\n", "        ", "\"\"\"Returns a dictionary of hyperparameters with default values.\n\n        Returns:\n            .. code-block:: python\n\n                {\n                    \"name\": \"memnet_single_layer\"\n                }\n\n            Here:\n\n            \"name\": str\n                Name of the memory network single layer.\n        \"\"\"", "\n", "return", "{", "\n", "\"name\"", ":", "\"memnet_single_layer\"", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.memory.memory_network.MemNetSingleLayer._build": [[101, 133], ["tensorflow.variable_scope", "tensorflow.expand_dims", "tensorflow.matmul", "tensorflow.transpose", "tensorflow.nn.softmax", "tensorflow.matmul", "tensorflow.squeeze", "tensorflow.add", "memory_network.MemNetSingleLayer._add_internal_trainable_variables", "tensorflow.matmul", "memory_network.MemNetSingleLayer._add_trainable_variable"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.agents.agent_base.AgentBase.variable_scope", "home.repos.pwc.inspect_result.VegB_Text_Infilling.core.replay_memories.DequeReplayMemory.add", "home.repos.pwc.inspect_result.VegB_Text_Infilling.texar.module_base.ModuleBase._add_internal_trainable_variables", "home.repos.pwc.inspect_result.VegB_Text_Infilling.texar.module_base.ModuleBase._add_trainable_variable"], ["", "def", "_build", "(", "self", ",", "query", ",", "Aout", ",", "Cout", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"An A-C operation with memory and query vector.\n\n        Args:\n            query (Tensor): A `Tensor`.\n            Aout (Tensor): Output of A operation. Should be in shape `[None, memory_size, dim]`.\n            Cout (Tensor): Output of C operation. Should be in shape `[None, memory_size, dim]`.\n\n        Returns:\n            A `Tensor` of shape same as :attr:`query`.\n        \"\"\"", "\n", "u", "=", "query", "\n", "with", "tf", ".", "variable_scope", "(", "self", ".", "variable_scope", ")", ":", "\n", "            ", "a", "=", "Aout", "\n", "c", "=", "Cout", "\n", "u", "=", "tf", ".", "expand_dims", "(", "u", ",", "axis", "=", "2", ")", "\n", "p", "=", "tf", ".", "matmul", "(", "a", ",", "u", ")", "\n", "p", "=", "tf", ".", "transpose", "(", "p", ",", "perm", "=", "[", "0", ",", "2", ",", "1", "]", ")", "\n", "p", "=", "tf", ".", "nn", ".", "softmax", "(", "p", ")", "\n", "o", "=", "tf", ".", "matmul", "(", "p", ",", "c", ")", "\n", "o", "=", "tf", ".", "squeeze", "(", "o", ",", "axis", "=", "[", "1", "]", ")", "\n", "if", "self", ".", "_H", ":", "\n", "                ", "query", "=", "tf", ".", "matmul", "(", "query", ",", "self", ".", "_H", ")", "\n", "", "u_", "=", "tf", ".", "add", "(", "o", ",", "query", ")", "\n", "\n", "", "if", "not", "self", ".", "_built", ":", "\n", "            ", "self", ".", "_add_internal_trainable_variables", "(", ")", "\n", "if", "self", ".", "_H", ":", "\n", "                ", "self", ".", "_add_trainable_variable", "(", "self", ".", "_H", ")", "\n", "", "self", ".", "_built", "=", "True", "\n", "\n", "", "return", "u_", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.memory.memory_network.MemNetBase.__init__": [[151, 174], ["texar.module_base.ModuleBase.__init__", "tensorflow.variable_scope", "tensorflow.transpose", "tensorflow.get_variable", "texar.modules.embedders.WordEmbedder"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.text_infilling.self_attn_hyperparams.Hyperparams.__init__", "home.repos.pwc.inspect_result.VegB_Text_Infilling.agents.agent_base.AgentBase.variable_scope"], ["def", "__init__", "(", "self", ",", "vocab_size", ",", "input_embedder_fn", ",", "output_embedder_fn", ",", "\n", "query_embedder_fn", ",", "hparams", "=", "None", ")", ":", "\n", "        ", "ModuleBase", ".", "__init__", "(", "self", ",", "hparams", ")", "\n", "self", ".", "_n_hops", "=", "self", ".", "hparams", ".", "n_hops", "\n", "self", ".", "_dim", "=", "self", ".", "hparams", ".", "dim", "\n", "self", ".", "_reludim", "=", "self", ".", "hparams", ".", "reludim", "\n", "self", ".", "_memory_size", "=", "self", ".", "hparams", ".", "memory_size", "\n", "self", ".", "_vocab_size", "=", "vocab_size", "\n", "self", ".", "_input_embedder_fn", "=", "input_embedder_fn", "\n", "self", ".", "_output_embedder_fn", "=", "output_embedder_fn", "\n", "self", ".", "_query_embedder_fn", "=", "query_embedder_fn", "\n", "with", "tf", ".", "variable_scope", "(", "self", ".", "variable_scope", ")", ":", "\n", "            ", "if", "self", ".", "hparams", ".", "need_H", ":", "\n", "                ", "self", ".", "H", "=", "tf", ".", "get_variable", "(", "\n", "name", "=", "\"H\"", ",", "shape", "=", "[", "self", ".", "_dim", ",", "self", ".", "_dim", "]", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "H", "=", "None", "\n", "", "self", ".", "_final_matrix", "=", "tf", ".", "transpose", "(", "\n", "WordEmbedder", "(", "\n", "vocab_size", "=", "vocab_size", ",", "\n", "hparams", "=", "self", ".", "hparams", ".", "final_matrix", "\n", ")", ".", "embedding", ",", "\n", "name", "=", "\"final_matrix\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.memory.memory_network.MemNetBase.default_hparams": [[175, 240], ["None"], "methods", ["None"], ["", "", "@", "staticmethod", "\n", "def", "default_hparams", "(", ")", ":", "\n", "        ", "\"\"\"\n        Returns:\n            .. code-block:: python\n\n                {\n                    \"name\": \"memnet_base\",\n                    \"n_hops\": 1,\n                    \"dim\": 100,\n                    \"reludim\": 50,\n                    \"memory_size\": 100,\n                    \"need_H\": False,\n                    \"final_matrix\": {\n                        \"name\": \"final_matrix\",\n                        \"dim\": 100,\n                        \"dropout_rate\": 0,\n                    },\n                    \"dropout_rate\": 0,\n                    \"variational\": False,\n                }\n\n            Here:\n\n            \"n_hops\": int\n                Number of hops.\n\n            \"dim\": int\n                Dimension of all the vectors.\n\n            \"reludim\": int\n                Number of elements in dim that have relu at the end of each hop.\n                Should be not less than 0 and not more than :attr`\"dim\"`.\n\n            \"memory_size\": int\n                Size of elements used in the memory.\n\n            \"need_H\": bool\n                Whether needs to perform transform with :attr:`H` matrix at the end of A-C layer.\n\n            \"final_matrix\": dict\n                Hyperparameters of the final matrix.\n                Should be same as :class:`~texar.modules.embedders.WordEmbedder`.\n\n            \"dropout_rate\": float\n                The dropout rate to apply to the output of each hop. Should be between 0 and 1.\n                E.g., `dropout_rate=0.1` would drop out 10% of the units.\n\n            \"variational\": bool\n                Whether to share dropout masks after each hop like variational RNNs.\n        \"\"\"", "\n", "return", "{", "\n", "\"name\"", ":", "\"memnet_base\"", ",", "\n", "\"n_hops\"", ":", "1", ",", "\n", "\"dim\"", ":", "100", ",", "\n", "\"reludim\"", ":", "50", ",", "\n", "\"memory_size\"", ":", "100", ",", "\n", "\"need_H\"", ":", "False", ",", "\n", "\"final_matrix\"", ":", "{", "\n", "\"name\"", ":", "\"final_matrix\"", ",", "\n", "\"dim\"", ":", "100", ",", "\n", "\"dropout_rate\"", ":", "0", ",", "\n", "}", ",", "\n", "\"dropout_rate\"", ":", "0", ",", "\n", "\"variational\"", ":", "False", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.memory.memory_network.MemNetBase._build": [[242, 244], ["None"], "methods", ["None"], ["", "def", "_build", "(", "self", ",", "memory", ",", "query", ",", "**", "kwargs", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.memory.memory_network.MemNetRNNLike.__init__": [[267, 297], ["memory_network.MemNetBase.__init__", "tensorflow.variable_scope", "tensorflow.make_template", "tensorflow.make_template", "memory_network.MemNetSingleLayer", "tensorflow.make_template"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.text_infilling.self_attn_hyperparams.Hyperparams.__init__", "home.repos.pwc.inspect_result.VegB_Text_Infilling.agents.agent_base.AgentBase.variable_scope"], ["def", "__init__", "(", "self", ",", "vocab_size", ",", "\n", "input_embedder_fn", "=", "default_embedder_fn", ",", "\n", "output_embedder_fn", "=", "default_embedder_fn", ",", "\n", "query_embedder_fn", "=", "None", ",", "hparams", "=", "None", ")", ":", "\n", "        ", "MemNetBase", ".", "__init__", "(", "self", ",", "vocab_size", ",", "input_embedder_fn", ",", "\n", "output_embedder_fn", ",", "query_embedder_fn", ",", "hparams", ")", "\n", "with", "tf", ".", "variable_scope", "(", "self", ".", "variable_scope", ")", ":", "\n", "            ", "if", "self", ".", "_query_embedder_fn", ":", "\n", "                ", "self", ".", "B", "=", "tf", ".", "make_template", "(", "\n", "\"B\"", ",", "\n", "self", ".", "_query_embedder_fn", ",", "\n", "vocab_size", "=", "self", ".", "_vocab_size", ",", "\n", "hparams", "=", "self", ".", "hparams", ".", "B", ",", "\n", "create_scope_now_", "=", "True", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "B", "=", "None", "\n", "", "self", ".", "A", "=", "tf", ".", "make_template", "(", "\n", "\"A\"", ",", "\n", "self", ".", "_input_embedder_fn", ",", "\n", "vocab_size", "=", "self", ".", "_vocab_size", ",", "\n", "hparams", "=", "self", ".", "hparams", ".", "A", ",", "\n", "create_scope_now_", "=", "True", ")", "\n", "self", ".", "C", "=", "tf", ".", "make_template", "(", "\n", "\"C\"", ",", "\n", "self", ".", "_output_embedder_fn", ",", "\n", "vocab_size", "=", "self", ".", "_vocab_size", ",", "\n", "hparams", "=", "self", ".", "hparams", ".", "C", ",", "\n", "create_scope_now_", "=", "True", ")", "\n", "self", ".", "AC", "=", "MemNetSingleLayer", "(", "self", ".", "H", ",", "\n", "hparams", "=", "{", "\"name\"", ":", "\"AC\"", "}", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.memory.memory_network.MemNetRNNLike.default_hparams": [[299, 383], ["memory_network.MemNetBase.default_hparams"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.core.replay_memories.DequeReplayMemory.default_hparams"], ["", "", "@", "staticmethod", "\n", "def", "default_hparams", "(", ")", ":", "\n", "        ", "\"\"\"Returns a dictionary of hyperparameters with default values.\n\n        Returns:\n            .. code-block:: python\n\n                {\n                    \"name\": \"memnet_rnnlike\",\n                    \"n_hops\": 1,\n                    \"dim\": 100,\n                    \"reludim\": 50,\n                    \"memory_size\": 100,\n                    \"need_H\": True,\n                    \"final_matrix\": {\n                        \"name\": \"final_matrix\",\n                        \"dim\": 100,\n                        \"dropout_rate\": 0\n                    }\n                    \"A\": {\n                        \"memory_size\": 100,\n                        \"word_embedder\": {\n                            \"name\": \"word_embedder\",\n                            \"dim\": 100,\n                            \"initializer\": None, # use default initializer\n                            \"dropout_rate\": 0\n                        }\n                        \"temporal_embedding\": {\n                            \"name\": \"temporal_embedding\",\n                            \"dim\": 100,\n                            \"dropout_rate\": 0\n                        }\n                    }\n                    \"C\": {\n                        \"memory_size\": 100,\n                        \"word_embedder\": {\n                            \"name\": \"word_embedder\",\n                            \"dim\": 100,\n                            \"initializer\": None, # use default initializer\n                            \"dropout_rate\": 0\n                        }\n                        \"temporal_embedding\": {\n                            \"name\": \"temporal_embedding\",\n                            \"dim\": 100,\n                            \"dropout_rate\": 0\n                        }\n                    }\n                    \"B\": {\n                        \"memory_size\": 100,\n                        \"word_embedder\": {\n                            \"name\": \"word_embedder\",\n                            \"dim\": 100,\n                            \"initializer\": None, # use default initializer\n                            \"dropout_rate\": 0\n                        }\n                        \"temporal_embedding\": {\n                            \"name\": \"temporal_embedding\",\n                            \"dim\": 100,\n                            \"dropout_rate\": 0\n                        }\n                    }\n                    \"dropout_rate\": 0 # dropout after each hop\n                }\n        \"\"\"", "\n", "hparams", "=", "MemNetBase", ".", "default_hparams", "(", ")", "\n", "hparams", "[", "\"name\"", "]", "=", "\"memnet_rnnlike\"", "\n", "hparams", "[", "\"need_H\"", "]", "=", "True", "\n", "default_embedder_hparams", "=", "{", "\n", "\"memory_size\"", ":", "100", ",", "\n", "\"word_embedder\"", ":", "{", "\n", "\"name\"", ":", "\"word_embedder\"", ",", "\n", "\"dim\"", ":", "100", ",", "\n", "\"initializer\"", ":", "None", ",", "\n", "\"dropout_rate\"", ":", "0", "\n", "}", ",", "\n", "\"temporal_embedding\"", ":", "{", "\n", "\"name\"", ":", "\"temporal_embedding\"", ",", "\n", "\"dim\"", ":", "100", ",", "\n", "\"dropout_rate\"", ":", "0", "\n", "}", "\n", "}", "\n", "for", "_", "in", "(", "\"A\"", ",", "\"C\"", ",", "\"B\"", ")", ":", "\n", "            ", "hparams", "[", "_", "]", "=", "default_embedder_hparams", "\n", "", "return", "hparams", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.memory.memory_network.MemNetRNNLike._build": [[384, 430], ["tensorflow.variable_scope", "memory_network.MemNetRNNLike.A", "memory_network.MemNetRNNLike.C", "texar.utils.mode.switch_dropout", "range", "tensorflow.matmul", "memory_network.MemNetRNNLike._add_internal_trainable_variables", "memory_network.MemNetRNNLike.B", "memory_network.MemNetRNNLike.AC", "memory_network.MemNetRNNLike.u.append", "tensorflow.variable_scope", "tensorflow.random_uniform", "tensorflow.floor", "memory_network.MemNetRNNLike._build.variational_dropout"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.agents.agent_base.AgentBase.variable_scope", "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.mode.switch_dropout", "home.repos.pwc.inspect_result.VegB_Text_Infilling.texar.module_base.ModuleBase._add_internal_trainable_variables", "home.repos.pwc.inspect_result.VegB_Text_Infilling.agents.agent_base.AgentBase.variable_scope"], ["", "def", "_build", "(", "self", ",", "memory", ",", "query", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"Pass the :attr:`memory` and :attr:`query` through the memory network\n        and return the :attr:`logits` after the final matrix.\n        \"\"\"", "\n", "with", "tf", ".", "variable_scope", "(", "self", ".", "variable_scope", ")", ":", "\n", "            ", "if", "self", ".", "_query_embedder_fn", ":", "\n", "                ", "query", "=", "self", ".", "B", "(", "query", ")", "\n", "", "self", ".", "u", "=", "[", "query", "]", "\n", "self", ".", "Aout", "=", "self", ".", "A", "(", "memory", ")", "\n", "self", ".", "Cout", "=", "self", ".", "C", "(", "memory", ")", "\n", "\n", "keep_prob", "=", "switch_dropout", "(", "1", "-", "self", ".", "hparams", ".", "dropout_rate", ")", "\n", "if", "self", ".", "hparams", ".", "variational", ":", "\n", "                ", "with", "tf", ".", "variable_scope", "(", "\"variational_dropout\"", ")", ":", "\n", "                    ", "noise", "=", "tf", ".", "random_uniform", "(", "tf", ".", "shape", "(", "self", ".", "u", "[", "-", "1", "]", ")", ")", "\n", "random_tensor", "=", "keep_prob", "+", "noise", "\n", "binary_tensor", "=", "tf", ".", "floor", "(", "random_tensor", ")", "\n", "", "def", "variational_dropout", "(", "val", ")", ":", "\n", "                    ", "return", "tf", ".", "div", "(", "val", ",", "keep_prob", ")", "*", "binary_tensor", "\n", "\n", "", "", "for", "k", "in", "range", "(", "self", ".", "_n_hops", ")", ":", "\n", "                ", "u_", "=", "self", ".", "AC", "(", "self", ".", "u", "[", "-", "1", "]", ",", "self", ".", "Aout", ",", "self", ".", "Cout", ")", "\n", "if", "self", ".", "_reludim", "==", "0", ":", "\n", "                    ", "pass", "\n", "", "elif", "self", ".", "_reludim", "==", "self", ".", "_dim", ":", "\n", "                    ", "u_", "=", "tf", ".", "nn", ".", "relu", "(", "u_", ")", "\n", "", "elif", "0", "<", "self", ".", "_reludim", "<", "self", ".", "_dim", ":", "\n", "                    ", "linear_part", "=", "u_", "[", ":", ",", ":", "self", ".", "_dim", "-", "self", ".", "_reludim", "]", "\n", "relu_part", "=", "u_", "[", ":", ",", "self", ".", "_dim", "-", "self", ".", "_reludim", ":", "]", "\n", "relued_part", "=", "tf", ".", "nn", ".", "relu", "(", "relu_part", ")", "\n", "u_", "=", "tf", ".", "concat", "(", "axis", "=", "1", ",", "values", "=", "[", "linear_part", ",", "relued_part", "]", ")", "\n", "", "else", ":", "\n", "                    ", "raise", "Exception", "(", "\"reludim = {} is illegal\"", ".", "format", "(", "\n", "self", ".", "_reludim", ")", ")", "\n", "", "if", "self", ".", "hparams", ".", "variational", ":", "\n", "                    ", "u_", "=", "variational_dropout", "(", "u_", ")", "\n", "", "else", ":", "\n", "                    ", "u_", "=", "tf", ".", "nn", ".", "dropout", "(", "u_", ",", "keep_prob", ")", "\n", "", "self", ".", "u", ".", "append", "(", "u_", ")", "\n", "", "logits", "=", "tf", ".", "matmul", "(", "self", ".", "u", "[", "-", "1", "]", ",", "self", ".", "_final_matrix", ")", "\n", "\n", "", "if", "not", "self", ".", "_built", ":", "\n", "            ", "self", ".", "_add_internal_trainable_variables", "(", ")", "\n", "self", ".", "_built", "=", "True", "\n", "\n", "", "return", "logits", "\n", "", "", ""]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.memory.memory_network.default_embedder_fn": [[22, 64], ["texar.modules.embedders.WordEmbedder", "texar.modules.embedders.WordEmbedder.", "tensorflow.add", "texar.modules.embedders.WordEmbedder"], "function", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.core.replay_memories.DequeReplayMemory.add"], ["def", "default_embedder_fn", "(", "memory", ",", "vocab_size", ",", "hparams", ")", ":", "\n", "    ", "\"\"\"Default embedder function for A, C or B operation.\n\n    Args:\n        memory: Memory elements used for embedding lookup.\n        vocab_size(int): Size of vocabulary used for embedding.\n        hparams(HParams or dict): Hyperparameters of this function.\n            Example:\n\n            .. code-block:: python\n\n                {\n                    \"memory_size\": 100,\n                    \"word_embedder\": {\n                        \"name\": \"word_embedder\",\n                        \"dim\": 100,\n                        \"initializer\": None, # use default initializer\n                        \"dropout_rate\": 0\n                    }\n                    \"temporal_embedding\": {\n                        \"name\": \"temporal_embedding\",\n                        \"dim\": 100,\n                        \"dropout_rate\": 0\n                    }\n                }\n\n    Returns:\n        Result of the memory operation.\n        In this case, :attr:`embedded_memory + temporal_embedding`.\n    \"\"\"", "\n", "memory_size", "=", "hparams", "[", "\"memory_size\"", "]", "\n", "word_embedder", "=", "WordEmbedder", "(", "\n", "vocab_size", "=", "vocab_size", ",", "\n", "hparams", "=", "hparams", "[", "\"word_embedder\"", "]", "\n", ")", "\n", "embedded_memory", "=", "word_embedder", "(", "memory", ")", "\n", "# temporal embedding", "\n", "temporal_embedding", "=", "WordEmbedder", "(", "\n", "vocab_size", "=", "memory_size", ",", "\n", "hparams", "=", "hparams", "[", "\"temporal_embedding\"", "]", "\n", ")", ".", "embedding", "\n", "return", "tf", ".", "add", "(", "embedded_memory", ",", "temporal_embedding", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.policies.policy_nets_test.CategoricalPolicyNetTest.test_categorical_policy": [[19, 29], ["texar.modules.policies.policy_nets.CategoricalPolicyNet", "tensorflow.random_uniform", "texar.modules.policies.policy_nets.CategoricalPolicyNet.", "policy_nets_test.CategoricalPolicyNetTest.assertEqual", "policy_nets_test.CategoricalPolicyNetTest.assertIsInstance"], "methods", ["None"], ["def", "test_categorical_policy", "(", "self", ")", ":", "\n", "        ", "\"\"\"Tests logics.\n        \"\"\"", "\n", "policy", "=", "CategoricalPolicyNet", "(", ")", "\n", "\n", "inputs", "=", "tf", ".", "random_uniform", "(", "shape", "=", "[", "64", ",", "4", "]", ")", "\n", "outputs", "=", "policy", "(", "inputs", "=", "inputs", ")", "\n", "self", ".", "assertEqual", "(", "outputs", "[", "'action'", "]", ".", "shape", ",", "outputs", "[", "'log_prob'", "]", ".", "shape", ")", "\n", "self", ".", "assertIsInstance", "(", "\n", "outputs", "[", "'distribution'", "]", ",", "tf", ".", "distributions", ".", "Categorical", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.policies.policy_nets.PolicyNetBase.__init__": [[28, 36], ["texar.module_base.ModuleBase.__init__", "tensorflow.variable_scope", "policy_nets.PolicyNetBase._build_network"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.text_infilling.self_attn_hyperparams.Hyperparams.__init__", "home.repos.pwc.inspect_result.VegB_Text_Infilling.agents.agent_base.AgentBase.variable_scope", "home.repos.pwc.inspect_result.VegB_Text_Infilling.qnets.qnets.QNetBase._build_network"], ["def", "__init__", "(", "self", ",", "\n", "network", "=", "None", ",", "\n", "network_kwargs", "=", "None", ",", "\n", "hparams", "=", "None", ")", ":", "\n", "        ", "ModuleBase", ".", "__init__", "(", "self", ",", "hparams", "=", "hparams", ")", "\n", "\n", "with", "tf", ".", "variable_scope", "(", "self", ".", "variable_scope", ")", ":", "\n", "            ", "self", ".", "_build_network", "(", "network", ",", "network_kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.policies.policy_nets.PolicyNetBase.default_hparams": [[37, 56], ["None"], "methods", ["None"], ["", "", "@", "staticmethod", "\n", "def", "default_hparams", "(", ")", ":", "\n", "        ", "\"\"\"Returns a dictionary of hyperparameters with default values.\n\n        TODO\n        \"\"\"", "\n", "return", "{", "\n", "'network_type'", ":", "'FeedForwardNetwork'", ",", "\n", "'network_hparams'", ":", "{", "\n", "'layers'", ":", "[", "\n", "{", "'type'", ":", "'Dense'", ",", "\n", "'kwargs'", ":", "{", "'units'", ":", "256", ",", "'activation'", ":", "'relu'", "}", "}", ",", "\n", "{", "'type'", ":", "'Dense'", ",", "\n", "'kwargs'", ":", "{", "'units'", ":", "256", ",", "'activation'", ":", "'relu'", "}", "}", ",", "\n", "]", "\n", "}", ",", "\n", "'distribution_kwargs'", ":", "None", ",", "\n", "'name'", ":", "'policy_net'", ",", "\n", "'@no_typecheck'", ":", "[", "'network_type'", ",", "'network_hparams'", "]", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.policies.policy_nets.PolicyNetBase._build_network": [[58, 69], ["texar.utils.utils.get_instance_kwargs", "texar.utils.utils.check_or_get_instance"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.utils.get_instance_kwargs", "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.utils.check_or_get_instance"], ["", "def", "_build_network", "(", "self", ",", "network", ",", "kwargs", ")", ":", "\n", "        ", "if", "network", "is", "not", "None", ":", "\n", "            ", "self", ".", "_network", "=", "network", "\n", "", "else", ":", "\n", "            ", "kwargs", "=", "utils", ".", "get_instance_kwargs", "(", "\n", "kwargs", ",", "self", ".", "_hparams", ".", "network_hparams", ")", "\n", "self", ".", "_network", "=", "utils", ".", "check_or_get_instance", "(", "\n", "self", ".", "_hparams", ".", "network_type", ",", "\n", "kwargs", ",", "\n", "module_paths", "=", "[", "'texar.modules'", ",", "'texar.custom'", "]", ",", "\n", "classtype", "=", "FeedForwardNetworkBase", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.policies.policy_nets.PolicyNetBase._build": [[70, 72], ["None"], "methods", ["None"], ["", "", "def", "_build", "(", "self", ",", "inputs", ",", "mode", "=", "None", ")", ":", "# pylint: disable=arguments-differ", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.policies.policy_nets.PolicyNetBase.network": [[73, 78], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "network", "(", "self", ")", ":", "\n", "        ", "\"\"\"The network.\n        \"\"\"", "\n", "return", "self", ".", "_network", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.policies.policy_nets.CategoricalPolicyNet.__init__": [[85, 98], ["policy_nets.PolicyNetBase.__init__", "tensorflow.variable_scope", "policy_nets.CategoricalPolicyNet._append_output_layer", "texar.agents.agent_utils.Space"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.text_infilling.self_attn_hyperparams.Hyperparams.__init__", "home.repos.pwc.inspect_result.VegB_Text_Infilling.agents.agent_base.AgentBase.variable_scope", "home.repos.pwc.inspect_result.VegB_Text_Infilling.qnets.qnets.CategoricalQNet._append_output_layer"], ["def", "__init__", "(", "self", ",", "\n", "action_space", "=", "None", ",", "\n", "network", "=", "None", ",", "\n", "network_kwargs", "=", "None", ",", "\n", "hparams", "=", "None", ")", ":", "\n", "        ", "PolicyNetBase", ".", "__init__", "(", "self", ",", "hparams", "=", "hparams", ")", "\n", "\n", "with", "tf", ".", "variable_scope", "(", "self", ".", "variable_scope", ")", ":", "\n", "            ", "if", "action_space", "is", "None", ":", "\n", "                ", "action_space", "=", "Space", "(", "\n", "low", "=", "0", ",", "high", "=", "self", ".", "_hparams", ".", "action_space", ",", "dtype", "=", "np", ".", "int32", ")", "\n", "", "self", ".", "_action_space", "=", "action_space", "\n", "self", ".", "_append_output_layer", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.policies.policy_nets.CategoricalPolicyNet.default_hparams": [[99, 116], ["policy_nets.PolicyNetBase.default_hparams", "policy_nets.PolicyNetBase.default_hparams"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.core.replay_memories.DequeReplayMemory.default_hparams", "home.repos.pwc.inspect_result.VegB_Text_Infilling.core.replay_memories.DequeReplayMemory.default_hparams"], ["", "", "@", "staticmethod", "\n", "def", "default_hparams", "(", ")", ":", "\n", "        ", "\"\"\"Returns a dictionary of hyperparameters with default values.\n\n        TODO\n        \"\"\"", "\n", "hparams", "=", "PolicyNetBase", ".", "default_hparams", "(", ")", "\n", "hparams", ".", "update", "(", "{", "\n", "'distribution_kwargs'", ":", "{", "\n", "'dtype'", ":", "'int32'", ",", "\n", "'validate_args'", ":", "False", ",", "\n", "'allow_nan_stats'", ":", "True", "\n", "}", ",", "\n", "'action_space'", ":", "2", ",", "\n", "'make_output_layer'", ":", "True", "\n", "}", ")", "\n", "return", "hparams", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.policies.policy_nets.CategoricalPolicyNet._append_output_layer": [[117, 131], ["policy_nets.CategoricalPolicyNet._network.append_layer", "ValueError"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.networks.network_base.FeedForwardNetworkBase.append_layer"], ["", "def", "_append_output_layer", "(", "self", ")", ":", "\n", "        ", "if", "not", "self", ".", "_hparams", ".", "make_output_layer", ":", "\n", "            ", "return", "\n", "\n", "", "if", "self", ".", "_action_space", ".", "shape", "!=", "(", ")", ":", "\n", "            ", "raise", "ValueError", "(", "'Only scalar discrete action is supported.'", ")", "\n", "", "else", ":", "\n", "            ", "output_size", "=", "self", ".", "_action_space", ".", "high", "-", "self", ".", "_action_space", ".", "low", "\n", "\n", "", "layer_hparams", "=", "{", "\n", "'type'", ":", "'Dense'", ",", "\n", "'kwargs'", ":", "{", "'units'", ":", "output_size", "}", "\n", "}", "\n", "self", ".", "_network", ".", "append_layer", "(", "layer_hparams", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.policies.policy_nets.CategoricalPolicyNet._build": [[132, 154], ["policy_nets.CategoricalPolicyNet._network", "policy_nets.CategoricalPolicyNet._hparams.distribution_kwargs.todict", "texar.utils.dtypes.get_tf_dtype", "tensorflow.distributions.Categorical", "tensorflow.distributions.Categorical.sample", "tensorflow.reshape", "dict", "policy_nets.CategoricalPolicyNet._add_internal_trainable_variables", "policy_nets.CategoricalPolicyNet._add_trainable_variable"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.texar.hyperparams.HParams.todict", "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.dtypes.get_tf_dtype", "home.repos.pwc.inspect_result.VegB_Text_Infilling.decoders.rnn_decoder_helpers.GumbelSoftmaxEmbeddingHelper.sample", "home.repos.pwc.inspect_result.VegB_Text_Infilling.texar.module_base.ModuleBase._add_internal_trainable_variables", "home.repos.pwc.inspect_result.VegB_Text_Infilling.texar.module_base.ModuleBase._add_trainable_variable"], ["", "def", "_build", "(", "self", ",", "inputs", ",", "mode", "=", "None", ")", ":", "\n", "        ", "logits", "=", "self", ".", "_network", "(", "inputs", ",", "mode", "=", "mode", ")", "\n", "\n", "dkwargs", "=", "self", ".", "_hparams", ".", "distribution_kwargs", ".", "todict", "(", ")", "\n", "dkwargs", "[", "'dtype'", "]", "=", "get_tf_dtype", "(", "dkwargs", "[", "'dtype'", "]", ")", "\n", "dist", "=", "tf", ".", "distributions", ".", "Categorical", "(", "logits", "=", "logits", ",", "**", "dkwargs", ")", "\n", "\n", "action", "=", "dist", ".", "sample", "(", ")", "\n", "action", "=", "tf", ".", "reshape", "(", "action", ",", "self", ".", "_action_space", ".", "shape", ")", "\n", "\n", "outputs", "=", "dict", "(", "\n", "logits", "=", "logits", ",", "\n", "action", "=", "action", ",", "\n", "dist", "=", "dist", "\n", ")", "\n", "\n", "if", "not", "self", ".", "_built", ":", "\n", "            ", "self", ".", "_add_internal_trainable_variables", "(", ")", "\n", "self", ".", "_add_trainable_variable", "(", "self", ".", "_network", ".", "trainable_variables", ")", "\n", "self", ".", "_built", "=", "True", "\n", "\n", "", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.policies.policy_nets.CategoricalPolicyNet.action_space": [[155, 161], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "action_space", "(", "self", ")", ":", "\n", "        ", "\"\"\"An instance of :class:`~texar.agents.Space` specifiying the\n        action space.\n        \"\"\"", "\n", "return", "self", ".", "_action_space", "\n", "", "", ""]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.connectors.connectors.ConstantConnector.__init__": [[128, 130], ["texar.modules.connectors.connector_base.ConnectorBase.__init__"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.text_infilling.self_attn_hyperparams.Hyperparams.__init__"], ["def", "__init__", "(", "self", ",", "output_size", ",", "hparams", "=", "None", ")", ":", "\n", "        ", "ConnectorBase", ".", "__init__", "(", "self", ",", "output_size", ",", "hparams", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.connectors.connectors.ConstantConnector.default_hparams": [[131, 158], ["None"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "default_hparams", "(", ")", ":", "\n", "        ", "\"\"\"Returns a dictionary of default hyperparameters.\n\n        Returns:\n            .. code-block:: python\n\n                {\n                    \"value\": 0.,\n                    \"name\": \"constant_connector\"\n                }\n\n            Here:\n\n            \"value\" : float\n                The constant value that the output tensor(s) has.\n\n                The default value is `0.`.\n\n            \"name\" : str\n                Name of the connector.\n\n                The default value is \"constant_connector\".\n        \"\"\"", "\n", "return", "{", "\n", "\"value\"", ":", "0.", ",", "\n", "\"name\"", ":", "\"constant_connector\"", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.connectors.connectors.ConstantConnector._build": [[160, 184], ["tensorflow.python.util.nest.map_structure", "tensorflow.python.util.nest.map_structure", "tensorflow.constant", "tensorflow.constant"], "methods", ["None"], ["", "def", "_build", "(", "self", ",", "batch_size", ",", "value", "=", "None", ")", ":", "\n", "        ", "\"\"\"Creates output tensor(s) that has the given value.\n\n        Args:\n            batch_size (int or scalar int Tensor): The batch size.\n            value (python number or scalar Tensor, optional): The value that\n                the output tensor(s) has. If `None` (default), the decoder\n                initial state is set to :attr:`hparams[\"value\"]`.\n\n        Returns:\n            A (structure of) tensor with the structure specified by\n            :attr:`output_size`, and with the value speicified by\n            :attr:`value` and :attr:`hparams[\"value\"]`.\n        \"\"\"", "\n", "value_", "=", "value", "\n", "if", "value_", "is", "None", ":", "\n", "            ", "value_", "=", "self", ".", "hparams", ".", "value", "\n", "", "output", "=", "nest", ".", "map_structure", "(", "\n", "lambda", "x", ":", "tf", ".", "constant", "(", "value_", ",", "shape", "=", "[", "batch_size", ",", "x", "]", ")", ",", "\n", "self", ".", "_output_size", ")", "\n", "\n", "self", ".", "_built", "=", "True", "\n", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.connectors.connectors.ForwardConnector.__init__": [[204, 206], ["texar.modules.connectors.connector_base.ConnectorBase.__init__"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.text_infilling.self_attn_hyperparams.Hyperparams.__init__"], ["def", "__init__", "(", "self", ",", "output_size", ",", "hparams", "=", "None", ")", ":", "\n", "        ", "ConnectorBase", ".", "__init__", "(", "self", ",", "output_size", ",", "hparams", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.connectors.connectors.ForwardConnector.default_hparams": [[207, 227], ["None"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "default_hparams", "(", ")", ":", "\n", "        ", "\"\"\"Returns a dictionary of default hyperparameters.\n\n        Returns:\n            .. code-block:: python\n\n                {\n                    \"name\": \"forward_connector\"\n                }\n\n            Here:\n\n            \"name\" : str\n                Name of the connector.\n\n                The default value is \"forward_connector\".\n        \"\"\"", "\n", "return", "{", "\n", "\"name\"", ":", "\"forward_connector\"", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.connectors.connectors.ForwardConnector._build": [[229, 253], ["tensorflow.python.util.nest.assert_same_structure", "tensorflow.python.util.nest.assert_same_structure", "tensorflow.python.util.nest.flatten", "tensorflow.python.util.nest.flatten", "tensorflow.python.util.nest.pack_sequence_as", "tensorflow.python.util.nest.pack_sequence_as"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.encoders.hierarchical_encoders.HierarchicalRNNEncoder.flatten", "home.repos.pwc.inspect_result.VegB_Text_Infilling.encoders.hierarchical_encoders.HierarchicalRNNEncoder.flatten"], ["", "def", "_build", "(", "self", ",", "inputs", ")", ":", "\n", "        ", "\"\"\"Passes inputs to the initial states of decoder.\n\n        :attr:`inputs` must either have the same structure, or the same number\n        of elements with the decoder state.\n\n        Args:\n            inputs: The input (structure of) tensors to pass forward.\n\n        Returns:\n            The input (structure of) tensors that might be re-packed to have\n            the same structure with decoder state.\n        \"\"\"", "\n", "output", "=", "inputs", "\n", "try", ":", "\n", "            ", "nest", ".", "assert_same_structure", "(", "inputs", ",", "self", ".", "_output_size", ")", "\n", "", "except", "(", "ValueError", ",", "TypeError", ")", ":", "\n", "            ", "flat_input", "=", "nest", ".", "flatten", "(", "inputs", ")", "\n", "output", "=", "nest", ".", "pack_sequence_as", "(", "\n", "self", ".", "_output_size", ",", "flat_input", ")", "\n", "\n", "", "self", ".", "_built", "=", "True", "\n", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.connectors.connectors.MLPTransformConnector.__init__": [[268, 270], ["texar.modules.connectors.connector_base.ConnectorBase.__init__"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.text_infilling.self_attn_hyperparams.Hyperparams.__init__"], ["def", "__init__", "(", "self", ",", "output_size", ",", "hparams", "=", "None", ")", ":", "\n", "        ", "ConnectorBase", ".", "__init__", "(", "self", ",", "output_size", ",", "hparams", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.connectors.connectors.MLPTransformConnector.default_hparams": [[271, 306], ["None"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "default_hparams", "(", ")", ":", "\n", "        ", "\"\"\"Returns a dictionary of hyperparameters with default values.\n\n        Returns:\n            .. code-block:: python\n\n                {\n                    \"activation_fn\": \"identity\",\n                    \"name\": \"mlp_connector\"\n                }\n\n            Here:\n\n            \"activation_fn\" : str\n                The name or full path to the activation function applied to\n                the outputs of the MLP layer. The activation functions can be:\n\n                - Built-in activation functions defined in :mod:`tf` or \\\n                  :mod:`tf.nn`, e.g., :tf_main:`identity <identity>`.\n                - User-defined activation functions in `texar.custom`.\n                - External activation functions. Must provide the full path, \\\n                  e.g., \"my_module.my_activation_fn\".\n\n                The default value is :attr:`\"identity\"`, i.e., the MLP\n                transformation is linear.\n\n            \"name\" : str\n                Name of the connector.\n\n                The default value is \"mlp_connector\".\n        \"\"\"", "\n", "return", "{", "\n", "\"activation_fn\"", ":", "\"identity\"", ",", "\n", "\"name\"", ":", "\"mlp_connector\"", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.connectors.connectors.MLPTransformConnector._build": [[308, 330], ["texar.core.layers.get_activation_fn", "connectors._mlp_transform", "connectors.MLPTransformConnector._add_internal_trainable_variables"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.core.layers.get_activation_fn", "home.repos.pwc.inspect_result.VegB_Text_Infilling.connectors.connectors._mlp_transform", "home.repos.pwc.inspect_result.VegB_Text_Infilling.texar.module_base.ModuleBase._add_internal_trainable_variables"], ["", "def", "_build", "(", "self", ",", "inputs", ")", ":", "\n", "        ", "\"\"\"Transforms the inputs with an MLP layer and packs the results to have\n        the same structure with the decoder state.\n\n        Args:\n            inputs: Input (structure of) tensors to be transformed and passed\n                to the decoder. Must be a Tensor of shape `[batch_size, ...]`\n                or a (nested) tuple of such Tensors.\n\n        Returns:\n            A Tensor or a (nested) tuple of Tensors of the same structure of\n            the decoder state.\n        \"\"\"", "\n", "activation_fn", "=", "layers", ".", "get_activation_fn", "(", "self", ".", "hparams", ".", "activation_fn", ")", "\n", "\n", "output", "=", "_mlp_transform", "(", "inputs", ",", "self", ".", "_output_size", ",", "activation_fn", ")", "\n", "\n", "if", "not", "self", ".", "_built", ":", "\n", "            ", "self", ".", "_add_internal_trainable_variables", "(", ")", "\n", "self", ".", "_built", "=", "True", "\n", "\n", "", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.connectors.connectors.ReparameterizedStochasticConnector.__init__": [[349, 351], ["texar.modules.connectors.connector_base.ConnectorBase.__init__"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.text_infilling.self_attn_hyperparams.Hyperparams.__init__"], ["def", "__init__", "(", "self", ",", "output_size", ",", "hparams", "=", "None", ")", ":", "\n", "        ", "ConnectorBase", ".", "__init__", "(", "self", ",", "output_size", ",", "hparams", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.connectors.connectors.ReparameterizedStochasticConnector.default_hparams": [[352, 389], ["None"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "default_hparams", "(", ")", ":", "\n", "        ", "\"\"\"Returns a dictionary of hyperparameters with default values.\n\n        Returns:\n            .. code-block:: python\n\n                {\n                    \"activation_fn\": \"identity\",\n                    \"name\": \"reparameterized_stochastic_connector\"\n                }\n\n            Here:\n\n            \"activation_fn\" : str\n                The name or full path to the activation function applied to\n                the outputs of the MLP layer. The activation functions can be:\n\n                - Built-in activation functions defined in :mod:`tf` or \\\n                  :mod:`tf.nn`, e.g., :tf_main:`identity <identity>`.\n                - User-defined activation functions in `texar.custom`.\n                - External activation functions. Must provide the full path, \\\n                  e.g., \"my_module.my_activation_fn\".\n\n                The default value is :attr:`\"identity\"`, i.e., the MLP\n                transformation is linear.\n\n            \"name\" : str\n                Name of the connector.\n\n                The default value is \"reparameterized_stochastic_connector\".\n\n\n        \"\"\"", "\n", "return", "{", "\n", "\"activation_fn\"", ":", "\"tensorflow.identity\"", ",", "\n", "\"name\"", ":", "\"reparameterized_stochastic_connector\"", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.connectors.connectors.ReparameterizedStochasticConnector._build": [[391, 464], ["connectors._assert_same_size", "ValueError", "texar.utils.utils.get_instance.sample", "texar.utils.utils.get_instance.sample", "texar.utils.utils.get_function", "connectors._mlp_transform", "connectors.ReparameterizedStochasticConnector._add_internal_trainable_variables", "texar.utils.utils.get_instance"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.connectors.connectors._assert_same_size", "home.repos.pwc.inspect_result.VegB_Text_Infilling.decoders.rnn_decoder_helpers.GumbelSoftmaxEmbeddingHelper.sample", "home.repos.pwc.inspect_result.VegB_Text_Infilling.decoders.rnn_decoder_helpers.GumbelSoftmaxEmbeddingHelper.sample", "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.utils.get_function", "home.repos.pwc.inspect_result.VegB_Text_Infilling.connectors.connectors._mlp_transform", "home.repos.pwc.inspect_result.VegB_Text_Infilling.texar.module_base.ModuleBase._add_internal_trainable_variables", "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.utils.get_instance"], ["", "def", "_build", "(", "self", ",", "\n", "distribution", "=", "None", ",", "\n", "distribution_type", "=", "'MultivariateNormalDiag'", ",", "\n", "distribution_kwargs", "=", "None", ",", "\n", "transform", "=", "True", ",", "\n", "num_samples", "=", "None", ")", ":", "\n", "        ", "\"\"\"Samples from a distribution and optionally performs transformation.\n\n        The distribution must be reparameterizable, i.e.,\n        `distribution.reparameterization_type = FULLY_REPARAMETERIZED`.\n\n        Args:\n            distribution (optional): An instance of\n                :class:`~tensorflow.contrib.distributions.Distribution`. If\n                `None` (default), distribution is constructed based on\n                :attr:`distribution_type` or\n                :attr:`hparams['distribution']['type']`.\n            distribution_type (str, optional): Name or path to the distribution\n                class which inherits\n                :class:`~tensorflow.contrib.distributions.Distribution`. Ignored\n                if :attr:`distribution` is specified.\n            distribution_kwargs (dict, optional): Keyword arguments of the\n                distribution class specified in :attr:`distribution_type`.\n            transform (bool): Whether to perform MLP transformation of the\n                samples. If `False`, the shape of a sample must match the\n                :attr:`output_size`.\n            num_samples (int or scalar int Tensor, optional): Number of samples\n                to generate. `None` is required in training stage.\n\n        Returns:\n            output: If `num_samples`==None, returns a Tensor of shape\n                `[batch_size x output_size]`, else returns a Tensor of shape\n                `[num_samples x output_size]`. `num_samples` should be specified\n                if not in training stage.\n            latent_z: The latent sampled z\n\n        Raises:\n            ValueError: If distribution cannot be reparametrized.\n            ValueError: The output does not match the :attr:`output_size`.\n        \"\"\"", "\n", "if", "distribution", ":", "\n", "            ", "dstr", "=", "distribution", "\n", "", "elif", "distribution_type", "and", "distribution_kwargs", ":", "\n", "            ", "dstr", "=", "get_instance", "(", "\n", "distribution_type", ",", "distribution_kwargs", ",", "\n", "[", "\"texar.custom\"", ",", "\"tensorflow.contrib.distributions\"", "]", ")", "\n", "\n", "", "if", "dstr", ".", "reparameterization_type", "==", "tf_dstr", ".", "NOT_REPARAMETERIZED", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "\"Distribution is not reparameterized: %s\"", "%", "dstr", ".", "name", ")", "\n", "\n", "", "if", "num_samples", ":", "\n", "            ", "latent_z", "=", "dstr", ".", "sample", "(", "num_samples", ")", "\n", "", "else", ":", "\n", "            ", "latent_z", "=", "dstr", ".", "sample", "(", ")", "\n", "\n", "#if dstr.event_shape == []:", "\n", "#    latent_z = tf.reshape(", "\n", "#        latent_z,", "\n", "#        latent_z.shape.concatenate(tf.TensorShape(1)))", "\n", "\n", "# latent_z = tf.cast(latent_z, tf.float32)", "\n", "", "if", "transform", ":", "\n", "            ", "fn_modules", "=", "[", "'texar.custom'", ",", "'tensorflow'", ",", "'tensorflow.nn'", "]", "\n", "activation_fn", "=", "get_function", "(", "self", ".", "hparams", ".", "activation_fn", ",", "fn_modules", ")", "\n", "output", "=", "_mlp_transform", "(", "latent_z", ",", "self", ".", "_output_size", ",", "activation_fn", ")", "\n", "", "_assert_same_size", "(", "output", ",", "self", ".", "_output_size", ")", "\n", "\n", "if", "not", "self", ".", "_built", ":", "\n", "            ", "self", ".", "_add_internal_trainable_variables", "(", ")", "\n", "self", ".", "_built", "=", "True", "\n", "\n", "", "return", "output", ",", "latent_z", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.connectors.connectors.StochasticConnector.__init__": [[482, 484], ["texar.modules.connectors.connector_base.ConnectorBase.__init__"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.text_infilling.self_attn_hyperparams.Hyperparams.__init__"], ["def", "__init__", "(", "self", ",", "output_size", ",", "hparams", "=", "None", ")", ":", "\n", "        ", "ConnectorBase", ".", "__init__", "(", "self", ",", "output_size", ",", "hparams", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.connectors.connectors.StochasticConnector.default_hparams": [[485, 521], ["None"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "default_hparams", "(", ")", ":", "\n", "        ", "\"\"\"Returns a dictionary of hyperparameters with default values.\n\n        Returns:\n            .. code-block:: python\n\n                {\n                    \"activation_fn\": \"tensorflow.identity\",\n                    \"name\": \"stochastic_connector\"\n                }\n\n            Here:\n\n            \"activation_fn\" : str\n                The name or full path to the activation function applied to\n                the outputs of the MLP layer. The activation functions can be:\n\n                - Built-in activation functions defined in :mod:`tf` or \\\n                  :mod:`tf.nn`, e.g., :tf_main:`identity <identity>`.\n                - User-defined activation functions in `texar.custom`.\n                - External activation functions. Must provide the full path, \\\n                  e.g., \"my_module.my_activation_fn\".\n\n                The default value is :attr:`\"identity\"`, i.e., the MLP\n                transformation is linear.\n\n            \"name\" : str\n                Name of the connector.\n\n                The default value is \"stochastic_connector\".\n\n        \"\"\"", "\n", "return", "{", "\n", "\"activation_fn\"", ":", "\"tensorflow.identity\"", ",", "\n", "\"name\"", ":", "\"stochastic_connector\"", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.connectors.connectors.StochasticConnector._build": [[523, 592], ["tensorflow.stop_gradient", "tensorflow.stop_gradient", "tensorflow.cast", "tensorflow.cast", "connectors._assert_same_size", "texar.utils.utils.get_instance.sample", "texar.utils.utils.get_instance.sample", "tensorflow.reshape", "tensorflow.reshape", "texar.utils.utils.get_function", "connectors._mlp_transform", "connectors.StochasticConnector._add_internal_trainable_variables", "texar.utils.utils.get_instance", "_mlp_transform.shape.concatenate", "tensorflow.TensorShape", "tensorflow.TensorShape"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.connectors.connectors._assert_same_size", "home.repos.pwc.inspect_result.VegB_Text_Infilling.decoders.rnn_decoder_helpers.GumbelSoftmaxEmbeddingHelper.sample", "home.repos.pwc.inspect_result.VegB_Text_Infilling.decoders.rnn_decoder_helpers.GumbelSoftmaxEmbeddingHelper.sample", "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.utils.get_function", "home.repos.pwc.inspect_result.VegB_Text_Infilling.connectors.connectors._mlp_transform", "home.repos.pwc.inspect_result.VegB_Text_Infilling.texar.module_base.ModuleBase._add_internal_trainable_variables", "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.utils.get_instance"], ["", "def", "_build", "(", "self", ",", "\n", "distribution", "=", "None", ",", "\n", "distribution_type", "=", "'MultivariateNormalDiag'", ",", "\n", "distribution_kwargs", "=", "None", ",", "\n", "transform", "=", "False", ",", "\n", "num_samples", "=", "None", ")", ":", "\n", "        ", "\"\"\"Samples from a distribution and optionally performs transformation.\n\n        Gradients would not propagate through the random samples.\n\n        Args:\n            distribution (optional): An instance of\n                :class:`~tensorflow.contrib.distributions.Distribution`. If\n                `None` (default), distribution is constructed based on\n                :attr:`distribution_type`\n            distribution_type (str, optional): Name or path to the distribution\n                class which inherits\n                :class:`~tensorflow.contrib.distributions.Distribution`. Ignored\n                if :attr:`distribution` is specified.\n            distribution_kwargs (dict, optional): Keyword arguments of the\n                distribution class specified in :attr:`distribution_type`.\n            transform (bool): Whether to perform MLP transformation of the\n                samples. If `False`, the shape of a sample must match the\n                :attr:`output_size`.\n            num_samples (int or scalar int Tensor, optional): Number of samples\n                to generate. `None` is required in training stage.\n\n        Returns:\n            If `num_samples`==None, returns a Tensor of shape `[batch_size x\n            output_size]`, else returns a Tensor of shape `[num_samples x\n            output_size]`. `num_samples` should be specified if not in\n            training stage.\n\n        Raises:\n            ValueError: The output does not match the :attr:`output_size`.\n        \"\"\"", "\n", "if", "distribution", ":", "\n", "            ", "dstr", "=", "distribution", "\n", "", "elif", "distribution_type", "and", "distribution_kwargs", ":", "\n", "            ", "dstr", "=", "get_instance", "(", "\n", "distribution_type", ",", "distribution_kwargs", ",", "\n", "[", "\"texar.custom\"", ",", "\"tensorflow.contrib.distributions\"", "]", ")", "\n", "\n", "\n", "", "if", "num_samples", ":", "\n", "            ", "output", "=", "dstr", ".", "sample", "(", "num_samples", ")", "\n", "", "else", ":", "\n", "            ", "output", "=", "dstr", ".", "sample", "(", ")", "\n", "\n", "", "if", "dstr", ".", "event_shape", "==", "[", "]", ":", "\n", "            ", "output", "=", "tf", ".", "reshape", "(", "output", ",", "\n", "output", ".", "shape", ".", "concatenate", "(", "tf", ".", "TensorShape", "(", "1", ")", ")", ")", "\n", "\n", "# Disable gradients through samples", "\n", "", "output", "=", "tf", ".", "stop_gradient", "(", "output", ")", "\n", "\n", "output", "=", "tf", ".", "cast", "(", "output", ",", "tf", ".", "float32", ")", "\n", "\n", "if", "transform", ":", "\n", "            ", "fn_modules", "=", "[", "'texar.custom'", ",", "'tensorflow'", ",", "'tensorflow.nn'", "]", "\n", "activation_fn", "=", "get_function", "(", "self", ".", "hparams", ".", "activation_fn", ",", "fn_modules", ")", "\n", "output", "=", "_mlp_transform", "(", "output", ",", "self", ".", "_output_size", ",", "activation_fn", ")", "\n", "", "_assert_same_size", "(", "output", ",", "self", ".", "_output_size", ")", "\n", "\n", "if", "not", "self", ".", "_built", ":", "\n", "            ", "self", ".", "_add_internal_trainable_variables", "(", ")", "\n", "self", ".", "_built", "=", "True", "\n", "\n", "", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.connectors.connectors._assert_same_size": [[32, 48], ["tensorflow.python.util.nest.assert_same_structure", "tensorflow.python.util.nest.flatten", "tensorflow.python.util.nest.flatten", "zip", "tensorflow.TensorShape", "ValueError"], "function", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.encoders.hierarchical_encoders.HierarchicalRNNEncoder.flatten", "home.repos.pwc.inspect_result.VegB_Text_Infilling.encoders.hierarchical_encoders.HierarchicalRNNEncoder.flatten"], ["def", "_assert_same_size", "(", "outputs", ",", "output_size", ")", ":", "\n", "    ", "\"\"\"Check if outputs match output_size\n\n    Args:\n        outputs: A Tensor or a (nested) tuple of tensors\n        output_size: Can be an Integer, a TensorShape, or a (nested) tuple of\n            Integers or TensorShape.\n    \"\"\"", "\n", "nest", ".", "assert_same_structure", "(", "outputs", ",", "output_size", ")", "\n", "flat_output_size", "=", "nest", ".", "flatten", "(", "output_size", ")", "\n", "flat_output", "=", "nest", ".", "flatten", "(", "outputs", ")", "\n", "\n", "for", "(", "output", ",", "size", ")", "in", "zip", "(", "flat_output", ",", "flat_output_size", ")", ":", "\n", "        ", "if", "output", "[", "0", "]", ".", "shape", "!=", "tf", ".", "TensorShape", "(", "size", ")", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "\"The output size does not match the the required output_size\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.connectors.connectors._get_tensor_depth": [[49, 57], ["numpy.prod", "x.get_shape().as_list", "x.get_shape"], "function", ["None"], ["", "", "", "def", "_get_tensor_depth", "(", "x", ")", ":", "\n", "    ", "\"\"\"Returns the size of a tensor excluding the first dimension\n    (typically the batch dimension).\n\n    Args:\n        x: A tensor.\n    \"\"\"", "\n", "return", "np", ".", "prod", "(", "x", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", "[", "1", ":", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.connectors.connectors._mlp_transform": [[58, 113], ["tensorflow.python.util.nest.flatten", "tensorflow.concat", "tensorflow.python.util.nest.flatten", "isinstance", "sum", "tensorflow.contrib.layers.fully_connected", "tensorflow.split", "isinstance", "tensorflow.python.util.nest.pack_sequence_as", "connectors._get_tensor_depth", "tensorflow.reshape", "enumerate", "enumerate", "zip", "len", "numpy.prod", "tensorflow.reshape", "shape.as_list"], "function", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.encoders.hierarchical_encoders.HierarchicalRNNEncoder.flatten", "home.repos.pwc.inspect_result.VegB_Text_Infilling.encoders.hierarchical_encoders.HierarchicalRNNEncoder.flatten", "home.repos.pwc.inspect_result.VegB_Text_Infilling.connectors.connectors._get_tensor_depth"], ["", "def", "_mlp_transform", "(", "inputs", ",", "output_size", ",", "activation_fn", "=", "tf", ".", "identity", ")", ":", "\n", "    ", "\"\"\"Transforms inputs through a fully-connected layer that creates the output\n    with specified size.\n\n    Args:\n        inputs: A Tensor of shape `[batch_size, ...]` (i.e., batch-major), or a\n            (nested) tuple of such elements. A Tensor or a (nested) tuple of\n            Tensors with shape `[max_time, batch_size, ...]` (i.e., time-major)\n            can be transposed to batch-major using\n            :func:`~texar.utils.transpose_batch_time` prior to this\n            function.\n        output_size: Can be an Integer, a TensorShape, or a (nested) tuple of\n            Integers or TensorShape.\n        activation_fn: Activation function applied to the output.\n\n    Returns:\n        If :attr:`output_size` is an Integer or a TensorShape, returns a Tensor\n        of shape `[batch_size x output_size]`. If :attr:`output_size` is a tuple\n        of Integers or TensorShape, returns a tuple having the same structure as\n        :attr:`output_size`, where each element Tensor has the same size as\n        defined in :attr:`output_size`.\n    \"\"\"", "\n", "# flatten inputs", "\n", "flat_input", "=", "nest", ".", "flatten", "(", "inputs", ")", "\n", "# batch_size = flat_input[0].shape[0].value", "\n", "# TODO(zhiting): correct ?", "\n", "dims", "=", "[", "_get_tensor_depth", "(", "x", ")", "for", "x", "in", "flat_input", "]", "\n", "flat_input", "=", "[", "tf", ".", "reshape", "(", "x", ",", "(", "[", "-", "1", ",", "d", "]", ")", ")", "for", "x", ",", "d", "in", "zip", "(", "flat_input", ",", "dims", ")", "]", "\n", "#shape = inputs.get_shape().as_list()", "\n", "#dim = reduce(lambda x, y: x*y, shape[1:])", "\n", "#flat_input = [tf.reshape(input_, ([-1, dim])) for input_ in flat_input]", "\n", "concat_input", "=", "tf", ".", "concat", "(", "flat_input", ",", "1", ")", "\n", "\n", "# get output dimension", "\n", "flat_output_size", "=", "nest", ".", "flatten", "(", "output_size", ")", "\n", "if", "isinstance", "(", "flat_output_size", "[", "0", "]", ",", "tf", ".", "TensorShape", ")", ":", "\n", "        ", "size_list", "=", "[", "0", "]", "*", "len", "(", "flat_output_size", ")", "\n", "for", "(", "i", ",", "shape", ")", "in", "enumerate", "(", "flat_output_size", ")", ":", "\n", "            ", "size_list", "[", "i", "]", "=", "np", ".", "prod", "(", "[", "dim", ".", "value", "for", "dim", "in", "shape", "]", ")", "\n", "", "", "else", ":", "\n", "        ", "size_list", "=", "flat_output_size", "\n", "", "sum_output_size", "=", "sum", "(", "size_list", ")", "\n", "\n", "fc_output", "=", "tf", ".", "contrib", ".", "layers", ".", "fully_connected", "(", "\n", "concat_input", ",", "sum_output_size", ",", "activation_fn", "=", "activation_fn", ")", "\n", "\n", "flat_output", "=", "tf", ".", "split", "(", "fc_output", ",", "size_list", ",", "axis", "=", "1", ")", "\n", "\n", "if", "isinstance", "(", "flat_output_size", "[", "0", "]", ",", "tf", ".", "TensorShape", ")", ":", "\n", "        ", "for", "(", "i", ",", "shape", ")", "in", "enumerate", "(", "flat_output_size", ")", ":", "\n", "            ", "flat_output", "[", "i", "]", "=", "tf", ".", "reshape", "(", "flat_output", "[", "i", "]", ",", "[", "-", "1", "]", "+", "shape", ".", "as_list", "(", ")", ")", "\n", "", "", "output", "=", "nest", ".", "pack_sequence_as", "(", "structure", "=", "output_size", ",", "\n", "flat_sequence", "=", "flat_output", ")", "\n", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.connectors.connectors_test.TestConnectors.setUp": [[29, 35], ["tensorflow.test.TestCase.setUp", "tensorflow.test.TestCase.setUp", "texar.core.layers.get_rnn_cell", "texar.core.layers.default_rnn_cell_hparams"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.losses.mle_losses_test.MLELossesTest.setUp", "home.repos.pwc.inspect_result.VegB_Text_Infilling.losses.mle_losses_test.MLELossesTest.setUp", "home.repos.pwc.inspect_result.VegB_Text_Infilling.core.layers.get_rnn_cell", "home.repos.pwc.inspect_result.VegB_Text_Infilling.core.layers.default_rnn_cell_hparams"], ["def", "setUp", "(", "self", ")", ":", "\n", "        ", "tf", ".", "test", ".", "TestCase", ".", "setUp", "(", "self", ")", "\n", "self", ".", "_batch_size", "=", "100", "\n", "\n", "self", ".", "_decoder_cell", "=", "layers", ".", "get_rnn_cell", "(", "\n", "layers", ".", "default_rnn_cell_hparams", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.connectors.connectors_test.TestConnectors.assert_same_size": [[36, 40], ["texar.modules.connectors.connectors._assert_same_size"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.connectors.connectors._assert_same_size"], ["", "def", "assert_same_size", "(", "self", ",", "outputs", ",", "output_size", ")", ":", "\n", "        ", "\"\"\"see :ref:`texar.modules.connectors.connectors._assert_same_size\n        \"\"\"", "\n", "_assert_same_size", "(", "outputs", ",", "output_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.connectors.connectors_test.TestConnectors.test_constant_connector": [[42, 61], ["texar.modules.ConstantConnector", "texar.modules.ConstantConnector.", "texar.modules.ConstantConnector.", "tensorflow.python.util.nest.assert_same_structure", "tensorflow.python.util.nest.assert_same_structure", "tensorflow.python.util.nest.assert_same_structure", "tensorflow.python.util.nest.assert_same_structure", "connectors_test.TestConnectors.test_session", "sess.run", "sess.run", "connectors_test.TestConnectors.assertEqual", "connectors_test.TestConnectors.assertEqual", "tensorflow.global_variables_initializer", "tensorflow.global_variables_initializer", "tensorflow.python.util.nest.flatten", "tensorflow.python.util.nest.flatten", "tensorflow.python.util.nest.flatten", "tensorflow.python.util.nest.flatten"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.encoders.hierarchical_encoders.HierarchicalRNNEncoder.flatten", "home.repos.pwc.inspect_result.VegB_Text_Infilling.encoders.hierarchical_encoders.HierarchicalRNNEncoder.flatten", "home.repos.pwc.inspect_result.VegB_Text_Infilling.encoders.hierarchical_encoders.HierarchicalRNNEncoder.flatten", "home.repos.pwc.inspect_result.VegB_Text_Infilling.encoders.hierarchical_encoders.HierarchicalRNNEncoder.flatten"], ["", "def", "test_constant_connector", "(", "self", ")", ":", "\n", "        ", "\"\"\"Tests the logic of\n        :class:`~texar.modules.connectors.ConstantConnector`.\n        \"\"\"", "\n", "connector", "=", "ConstantConnector", "(", "self", ".", "_decoder_cell", ".", "state_size", ")", "\n", "\n", "decoder_initial_state_0", "=", "connector", "(", "self", ".", "_batch_size", ")", "\n", "decoder_initial_state_1", "=", "connector", "(", "self", ".", "_batch_size", ",", "value", "=", "1.", ")", "\n", "nest", ".", "assert_same_structure", "(", "decoder_initial_state_0", ",", "\n", "self", ".", "_decoder_cell", ".", "state_size", ")", "\n", "nest", ".", "assert_same_structure", "(", "decoder_initial_state_1", ",", "\n", "self", ".", "_decoder_cell", ".", "state_size", ")", "\n", "\n", "with", "self", ".", "test_session", "(", ")", "as", "sess", ":", "\n", "            ", "sess", ".", "run", "(", "tf", ".", "global_variables_initializer", "(", ")", ")", "\n", "s_0", ",", "s_1", "=", "sess", ".", "run", "(", "\n", "[", "decoder_initial_state_0", ",", "decoder_initial_state_1", "]", ")", "\n", "self", ".", "assertEqual", "(", "nest", ".", "flatten", "(", "s_0", ")", "[", "0", "]", "[", "0", ",", "0", "]", ",", "0.", ")", "\n", "self", ".", "assertEqual", "(", "nest", ".", "flatten", "(", "s_1", ")", "[", "0", "]", "[", "0", ",", "0", "]", ",", "1.", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.connectors.connectors_test.TestConnectors.test_forward_connector": [[62, 68], ["None"], "methods", ["None"], ["", "", "def", "test_forward_connector", "(", "self", ")", ":", "\n", "        ", "\"\"\"Tests the logic of\n        :class:`~texar.modules.connectors.ForwardConnector`.\n        \"\"\"", "\n", "# TODO(zhiting)", "\n", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.connectors.connectors_test.TestConnectors.test_mlp_transform_connector": [[69, 82], ["texar.modules.MLPTransformConnector", "texar.modules.MLPTransformConnector.", "tensorflow.python.util.nest.assert_same_structure", "tensorflow.python.util.nest.assert_same_structure", "tensorflow.zeros", "tensorflow.zeros", "connectors_test.TestConnectors.test_session", "sess.run", "sess.run", "tensorflow.python.util.nest.assert_same_structure", "tensorflow.python.util.nest.assert_same_structure", "tensorflow.global_variables_initializer", "tensorflow.global_variables_initializer"], "methods", ["None"], ["", "def", "test_mlp_transform_connector", "(", "self", ")", ":", "\n", "        ", "\"\"\"Tests the logic of\n        :class:`~texar.modules.connectors.MLPTransformConnector`.\n        \"\"\"", "\n", "connector", "=", "MLPTransformConnector", "(", "self", ".", "_decoder_cell", ".", "state_size", ")", "\n", "output", "=", "connector", "(", "tf", ".", "zeros", "(", "[", "5", ",", "10", "]", ")", ")", "\n", "nest", ".", "assert_same_structure", "(", "output", ",", "self", ".", "_decoder_cell", ".", "state_size", ")", "\n", "\n", "with", "self", ".", "test_session", "(", ")", "as", "sess", ":", "\n", "            ", "sess", ".", "run", "(", "tf", ".", "global_variables_initializer", "(", ")", ")", "\n", "\n", "output_", "=", "sess", ".", "run", "(", "output", ")", "\n", "nest", ".", "assert_same_structure", "(", "output_", ",", "self", ".", "_decoder_cell", ".", "state_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.connectors.connectors_test.TestConnectors.test_reparameterized_stochastic_connector": [[83, 131], ["tensorflow.zeros", "tensorflow.zeros", "tensorflow.ones", "tensorflow.ones", "tensorflow.zeros", "tensorflow.zeros", "tensorflow.ones", "tensorflow.ones", "tensorflow.MultivariateNormalDiag", "tensorflow.MultivariateNormalDiag", "tensorflow.MultivariateNormalDiag", "tensorflow.MultivariateNormalDiag", "texar.modules.ReparameterizedStochasticConnector", "texar.modules.ReparameterizedStochasticConnector", "texar.modules.ReparameterizedStochasticConnector.", "texar.modules.ReparameterizedStochasticConnector.", "texar.modules.ReparameterizedStochasticConnector.", "texar.modules.ReparameterizedStochasticConnector.", "tensorflow.TensorShape", "tensorflow.TensorShape", "tensorflow.TensorShape", "tensorflow.TensorShape", "connectors_test.TestConnectors.test_session", "sess.run", "sess.run", "connectors_test.TestConnectors.assertEqual", "connectors_test.TestConnectors.assertEqual", "connectors_test.TestConnectors.assertEqual", "connectors_test.TestConnectors.assert_same_size", "tensorflow.global_variables_initializer", "tensorflow.global_variables_initializer", "tensorflow.TensorShape", "tensorflow.TensorShape", "tensorflow.TensorShape", "tensorflow.TensorShape", "tensorflow.TensorShape", "tensorflow.TensorShape"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.connectors.connectors_test.TestConnectors.assert_same_size"], ["", "", "def", "test_reparameterized_stochastic_connector", "(", "self", ")", ":", "\n", "        ", "\"\"\"Tests the logic of\n        :class:`~texar.modules.connectors.ReparameterizedStochasticConnector`.\n        \"\"\"", "\n", "state_size", "=", "(", "10", ",", "10", ")", "\n", "variable_size", "=", "100", "\n", "state_size_ts", "=", "(", "tf", ".", "TensorShape", "(", "[", "10", ",", "10", "]", ")", ",", "tf", ".", "TensorShape", "(", "[", "2", ",", "3", ",", "4", "]", ")", ")", "\n", "sample_num", "=", "10", "\n", "\n", "# pylint: disable=invalid-name", "\n", "mu", "=", "tf", ".", "zeros", "(", "[", "self", ".", "_batch_size", ",", "variable_size", "]", ")", "\n", "var", "=", "tf", ".", "ones", "(", "[", "self", ".", "_batch_size", ",", "variable_size", "]", ")", "\n", "mu_vec", "=", "tf", ".", "zeros", "(", "[", "variable_size", "]", ")", "\n", "var_vec", "=", "tf", ".", "ones", "(", "[", "variable_size", "]", ")", "\n", "gauss_ds", "=", "tfds", ".", "MultivariateNormalDiag", "(", "loc", "=", "mu", ",", "scale_diag", "=", "var", ")", "\n", "gauss_ds_vec", "=", "tfds", ".", "MultivariateNormalDiag", "(", "loc", "=", "mu_vec", ",", "scale_diag", "=", "var_vec", ")", "\n", "gauss_connector", "=", "ReparameterizedStochasticConnector", "(", "state_size", ")", "\n", "gauss_connector_ts", "=", "ReparameterizedStochasticConnector", "(", "state_size_ts", ")", "\n", "\n", "sample1", ",", "latent1", "=", "gauss_connector", "(", "gauss_ds", ")", "\n", "sample2", ",", "latent2", "=", "gauss_connector", "(", "distribution_type", "=", "\"MultivariateNormalDiag\"", ",", "distribution_kwargs", "=", "{", "\"loc\"", ":", "mu", ",", "\"scale_diag\"", ":", "var", "}", ")", "\n", "# sample3, latent3 = gauss_connector(gauss_ds, num_samples=sample_num)", "\n", "sample_ts", ",", "latent_ts", "=", "gauss_connector_ts", "(", "gauss_ds", ")", "\n", "\n", "# specify sample num", "\n", "sample_test_num", ",", "latent_test_num", "=", "gauss_connector", "(", "gauss_ds_vec", ",", "num_samples", "=", "sample_num", ")", "\n", "\n", "# test when :attr:`transform` is False", "\n", "# sample_test_no_transform = gauss_connector(gauss_ds, transform=False)", "\n", "\n", "# test_list = [sample1, sample2, sample_ts, sample_test_num, sample_test_no_transform]", "\n", "test_list", "=", "[", "sample1", ",", "sample2", ",", "sample_ts", ",", "sample_test_num", "]", "\n", "\n", "with", "self", ".", "test_session", "(", ")", "as", "sess", ":", "\n", "            ", "sess", ".", "run", "(", "tf", ".", "global_variables_initializer", "(", ")", ")", "\n", "out_list", "=", "sess", ".", "run", "(", "test_list", ")", "\n", "out1", "=", "out_list", "[", "0", "]", "\n", "out2", "=", "out_list", "[", "1", "]", "\n", "# out3 = out_list[2]", "\n", "out_ts", "=", "out_list", "[", "2", "]", "\n", "out_test_num", "=", "out_list", "[", "3", "]", "\n", "\n", "# check the same size", "\n", "# print(out3.shape)", "\n", "self", ".", "assertEqual", "(", "out_test_num", "[", "0", "]", ".", "shape", ",", "tf", ".", "TensorShape", "(", "[", "sample_num", ",", "state_size", "[", "0", "]", "]", ")", ")", "\n", "self", ".", "assertEqual", "(", "out1", "[", "0", "]", ".", "shape", ",", "tf", ".", "TensorShape", "(", "[", "self", ".", "_batch_size", ",", "state_size", "[", "0", "]", "]", ")", ")", "\n", "self", ".", "assertEqual", "(", "out2", "[", "0", "]", ".", "shape", ",", "tf", ".", "TensorShape", "(", "[", "self", ".", "_batch_size", ",", "state_size", "[", "0", "]", "]", ")", ")", "\n", "self", ".", "assert_same_size", "(", "out_ts", ",", "state_size_ts", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.connectors.connector_base.ConnectorBase.__init__": [[28, 31], ["texar.module_base.ModuleBase.__init__"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.text_infilling.self_attn_hyperparams.Hyperparams.__init__"], ["def", "__init__", "(", "self", ",", "output_size", ",", "hparams", "=", "None", ")", ":", "\n", "        ", "ModuleBase", ".", "__init__", "(", "self", ",", "hparams", ")", "\n", "self", ".", "_output_size", "=", "output_size", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.connectors.connector_base.ConnectorBase.default_hparams": [[32, 38], ["None"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "default_hparams", "(", ")", ":", "\n", "        ", "\"\"\"Returns a dictionary of hyperparameters with default values.\n        \"\"\"", "\n", "return", "{", "\n", "\"name\"", ":", "\"connector\"", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.connectors.connector_base.ConnectorBase._build": [[40, 44], ["None"], "methods", ["None"], ["", "def", "_build", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"Transforms inputs to outputs with specified shape.\n        \"\"\"", "\n", "raise", "NotImplementedError", "\n", "", "", ""]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.qnets.qnets.QNetBase.__init__": [[20, 28], ["texar.module_base.ModuleBase.__init__", "tensorflow.variable_scope", "qnets.QNetBase._build_network"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.text_infilling.self_attn_hyperparams.Hyperparams.__init__", "home.repos.pwc.inspect_result.VegB_Text_Infilling.agents.agent_base.AgentBase.variable_scope", "home.repos.pwc.inspect_result.VegB_Text_Infilling.qnets.qnets.QNetBase._build_network"], ["    ", "def", "__init__", "(", "self", ",", "\n", "network", "=", "None", ",", "\n", "network_kwargs", "=", "None", ",", "\n", "hparams", "=", "None", ")", ":", "\n", "        ", "ModuleBase", ".", "__init__", "(", "self", ",", "hparams", "=", "hparams", ")", "\n", "\n", "with", "tf", ".", "variable_scope", "(", "self", ".", "variable_scope", ")", ":", "\n", "            ", "self", ".", "_build_network", "(", "network", ",", "network_kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.qnets.qnets.QNetBase.default_hparams": [[29, 47], ["None"], "methods", ["None"], ["", "", "@", "staticmethod", "\n", "def", "default_hparams", "(", ")", ":", "\n", "        ", "\"\"\"Returns a dictionary of hyperparameters with default values.\n        TODO\n        \"\"\"", "\n", "return", "{", "\n", "'network_type'", ":", "'FeedForwardNetwork'", ",", "\n", "'network_hparams'", ":", "{", "\n", "'layers'", ":", "[", "\n", "{", "'type'", ":", "'Dense'", ",", "\n", "'kwargs'", ":", "{", "'units'", ":", "256", ",", "'activation'", ":", "'relu'", "}", "}", ",", "\n", "{", "'type'", ":", "'Dense'", ",", "\n", "'kwargs'", ":", "{", "'units'", ":", "256", ",", "'activation'", ":", "'relu'", "}", "}", ",", "\n", "]", "\n", "}", ",", "\n", "'distribution_kwargs'", ":", "None", ",", "\n", "'name'", ":", "'policy_net'", ",", "\n", "'@no_typecheck'", ":", "[", "'network_type'", ",", "'network_hparams'", "]", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.qnets.qnets.QNetBase._build_network": [[49, 60], ["texar.utils.utils.get_instance_kwargs", "texar.utils.utils.check_or_get_instance"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.utils.get_instance_kwargs", "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.utils.check_or_get_instance"], ["", "def", "_build_network", "(", "self", ",", "network", ",", "kwargs", ")", ":", "\n", "        ", "if", "network", "is", "not", "None", ":", "\n", "            ", "self", ".", "_network", "=", "network", "\n", "", "else", ":", "\n", "            ", "kwargs", "=", "utils", ".", "get_instance_kwargs", "(", "\n", "kwargs", ",", "self", ".", "_hparams", ".", "network_hparams", ")", "\n", "self", ".", "_network", "=", "utils", ".", "check_or_get_instance", "(", "\n", "self", ".", "_hparams", ".", "network_type", ",", "\n", "kwargs", ",", "\n", "module_paths", "=", "[", "'texar.modules'", ",", "'texar.custom'", "]", ",", "\n", "classtype", "=", "FeedForwardNetworkBase", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.qnets.qnets.QNetBase._build": [[61, 63], ["None"], "methods", ["None"], ["", "", "def", "_build", "(", "self", ",", "inputs", ",", "mode", "=", "None", ")", ":", "# pylint: disable=arguments-differ", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.qnets.qnets.QNetBase.network": [[64, 69], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "network", "(", "self", ")", ":", "\n", "        ", "\"\"\"The network.\n        \"\"\"", "\n", "return", "self", ".", "_network", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.qnets.qnets.CategoricalQNet.__init__": [[72, 85], ["qnets.QNetBase.__init__", "tensorflow.variable_scope", "qnets.CategoricalQNet._append_output_layer", "texar.agents.agent_utils.Space"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.text_infilling.self_attn_hyperparams.Hyperparams.__init__", "home.repos.pwc.inspect_result.VegB_Text_Infilling.agents.agent_base.AgentBase.variable_scope", "home.repos.pwc.inspect_result.VegB_Text_Infilling.qnets.qnets.CategoricalQNet._append_output_layer"], ["    ", "def", "__init__", "(", "self", ",", "\n", "action_space", "=", "None", ",", "\n", "network", "=", "None", ",", "\n", "network_kwargs", "=", "None", ",", "\n", "hparams", "=", "None", ")", ":", "\n", "        ", "QNetBase", ".", "__init__", "(", "self", ",", "hparams", "=", "hparams", ")", "\n", "\n", "with", "tf", ".", "variable_scope", "(", "self", ".", "variable_scope", ")", ":", "\n", "            ", "if", "action_space", "is", "None", ":", "\n", "                ", "action_space", "=", "Space", "(", "\n", "low", "=", "0", ",", "high", "=", "self", ".", "_hparams", ".", "action_space", ",", "dtype", "=", "np", ".", "int32", ")", "\n", "", "self", ".", "_action_space", "=", "action_space", "\n", "self", ".", "_append_output_layer", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.qnets.qnets.CategoricalQNet.default_hparams": [[86, 93], ["qnets.QNetBase.default_hparams", "qnets.QNetBase.default_hparams"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.core.replay_memories.DequeReplayMemory.default_hparams", "home.repos.pwc.inspect_result.VegB_Text_Infilling.core.replay_memories.DequeReplayMemory.default_hparams"], ["", "", "@", "staticmethod", "\n", "def", "default_hparams", "(", ")", ":", "\n", "        ", "hparams", "=", "QNetBase", ".", "default_hparams", "(", ")", "\n", "hparams", ".", "update", "(", "{", "\n", "'action_space'", ":", "2", ",", "\n", "'make_output_layer'", ":", "True", "}", ")", "\n", "return", "hparams", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.qnets.qnets.CategoricalQNet._append_output_layer": [[94, 107], ["qnets.CategoricalQNet._network.append_layer", "ValueError"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.networks.network_base.FeedForwardNetworkBase.append_layer"], ["", "def", "_append_output_layer", "(", "self", ")", ":", "\n", "        ", "if", "not", "self", ".", "_hparams", ".", "make_output_layer", ":", "\n", "            ", "return", "\n", "\n", "", "if", "self", ".", "_action_space", ".", "shape", "!=", "(", ")", ":", "\n", "            ", "raise", "ValueError", "(", "'Only scalar discrete action is supported.'", ")", "\n", "", "else", ":", "\n", "            ", "output_size", "=", "self", ".", "_action_space", ".", "high", "-", "self", ".", "_action_space", ".", "low", "\n", "\n", "", "layer_hparams", "=", "{", "\n", "'type'", ":", "'Dense'", ",", "\n", "'kwargs'", ":", "{", "'units'", ":", "output_size", "}", "}", "\n", "self", ".", "_network", ".", "append_layer", "(", "layer_hparams", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.qnets.qnets.CategoricalQNet._build": [[108, 117], ["dict", "qnets.CategoricalQNet._add_internal_trainable_variables", "qnets.CategoricalQNet._add_trainable_variable", "qnets.CategoricalQNet._network"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.texar.module_base.ModuleBase._add_internal_trainable_variables", "home.repos.pwc.inspect_result.VegB_Text_Infilling.texar.module_base.ModuleBase._add_trainable_variable"], ["", "def", "_build", "(", "self", ",", "inputs", ",", "mode", "=", "None", ")", ":", "\n", "        ", "outputs", "=", "dict", "(", "qvalues", "=", "self", ".", "_network", "(", "inputs", ",", "mode", "=", "mode", ")", ")", "\n", "\n", "if", "not", "self", ".", "_built", ":", "\n", "            ", "self", ".", "_add_internal_trainable_variables", "(", ")", "\n", "self", ".", "_add_trainable_variable", "(", "self", ".", "_network", ".", "trainable_variables", ")", "\n", "self", ".", "_built", "=", "True", "\n", "\n", "", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.qnets.qnets.CategoricalQNet.action_space": [[118, 124], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "action_space", "(", "self", ")", ":", "\n", "        ", "\"\"\"An instance of :class:`~texar.agents.Space` specifiying the\n        action space.\n        \"\"\"", "\n", "return", "self", ".", "_action_space", "", "", "", ""]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.decoders.rnn_decoder_helpers.SoftmaxEmbeddingHelper.__init__": [[181, 213], ["callable", "tensorflow.convert_to_tensor", "tensorflow.convert_to_tensor", "rnn_decoder_helpers.SoftmaxEmbeddingHelper._embedding_fn", "tensorflow.size", "ValueError", "tensorflow.nn.embedding_lookup"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.data.vocabulary.Vocab.size"], ["def", "__init__", "(", "self", ",", "embedding", ",", "start_tokens", ",", "end_token", ",", "tau", ",", "\n", "stop_gradient", "=", "False", ",", "use_finish", "=", "True", ")", ":", "\n", "        ", "\"\"\"Initializer.\n\n        Args:\n            embedding: An embedding argument (:attr:`params`) for\n                :tf_main:`tf.nn.embedding_lookup <nn/embedding_lookup>`. Note\n                that a callable is not acceptable here.\n            start_tokens: An `int32` vector tensor  shaped `[batch_size]`. The\n                start tokens.\n            end_token: An `int32` scalar tensor. The token that marks end of\n                decoding.\n            tau: softmax anneal temperature.\n            stop_gradient: stop the gradient when feeding to the next step.\n        \"\"\"", "\n", "\n", "if", "callable", "(", "embedding", ")", ":", "\n", "            ", "raise", "ValueError", "(", "\"embedding must be an embedding matrix.\"", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "_embedding", "=", "embedding", "\n", "self", ".", "_embedding_fn", "=", "(", "\n", "lambda", "ids", ":", "tf", ".", "nn", ".", "embedding_lookup", "(", "embedding", ",", "ids", ")", ")", "\n", "\n", "", "self", ".", "_start_tokens", "=", "tf", ".", "convert_to_tensor", "(", "\n", "start_tokens", ",", "dtype", "=", "tf", ".", "int32", ",", "name", "=", "\"start_tokens\"", ")", "\n", "self", ".", "_end_token", "=", "tf", ".", "convert_to_tensor", "(", "\n", "end_token", ",", "dtype", "=", "tf", ".", "int32", ",", "name", "=", "\"end_token\"", ")", "\n", "self", ".", "_start_inputs", "=", "self", ".", "_embedding_fn", "(", "self", ".", "_start_tokens", ")", "\n", "self", ".", "_batch_size", "=", "tf", ".", "size", "(", "self", ".", "_start_tokens", ")", "\n", "self", ".", "_tau", "=", "tau", "\n", "self", ".", "_stop_gradient", "=", "stop_gradient", "\n", "self", ".", "_use_finish", "=", "use_finish", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.decoders.rnn_decoder_helpers.SoftmaxEmbeddingHelper.batch_size": [[214, 217], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "batch_size", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_batch_size", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.decoders.rnn_decoder_helpers.SoftmaxEmbeddingHelper.sample_ids_dtype": [[218, 221], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "sample_ids_dtype", "(", "self", ")", ":", "\n", "        ", "return", "tf", ".", "float32", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.decoders.rnn_decoder_helpers.SoftmaxEmbeddingHelper.sample_ids_shape": [[222, 225], ["rnn_decoder_helpers.SoftmaxEmbeddingHelper._embedding.get_shape"], "methods", ["None"], ["", "@", "property", "\n", "def", "sample_ids_shape", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_embedding", ".", "get_shape", "(", ")", "[", ":", "1", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.decoders.rnn_decoder_helpers.SoftmaxEmbeddingHelper.initialize": [[226, 229], ["tensorflow.tile"], "methods", ["None"], ["", "def", "initialize", "(", "self", ",", "name", "=", "None", ")", ":", "\n", "        ", "finished", "=", "tf", ".", "tile", "(", "[", "False", "]", ",", "[", "self", ".", "_batch_size", "]", ")", "\n", "return", "(", "finished", ",", "self", ".", "_start_inputs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.decoders.rnn_decoder_helpers.SoftmaxEmbeddingHelper.sample": [[230, 233], ["tensorflow.nn.softmax"], "methods", ["None"], ["", "def", "sample", "(", "self", ",", "time", ",", "outputs", ",", "state", ",", "name", "=", "None", ")", ":", "\n", "        ", "sample_ids", "=", "tf", ".", "nn", ".", "softmax", "(", "outputs", "/", "self", ".", "_tau", ")", "\n", "return", "sample_ids", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.decoders.rnn_decoder_helpers.SoftmaxEmbeddingHelper.next_inputs": [[234, 244], ["tensorflow.matmul", "tensorflow.argmax", "tensorflow.equal", "tensorflow.tile", "tensorflow.stop_gradient"], "methods", ["None"], ["", "def", "next_inputs", "(", "self", ",", "time", ",", "outputs", ",", "state", ",", "sample_ids", ",", "name", "=", "None", ")", ":", "\n", "        ", "if", "self", ".", "_use_finish", ":", "\n", "            ", "hard_ids", "=", "tf", ".", "argmax", "(", "sample_ids", ",", "axis", "=", "-", "1", ",", "output_type", "=", "tf", ".", "int32", ")", "\n", "finished", "=", "tf", ".", "equal", "(", "hard_ids", ",", "self", ".", "_end_token", ")", "\n", "", "else", ":", "\n", "            ", "finished", "=", "tf", ".", "tile", "(", "[", "False", "]", ",", "[", "self", ".", "_batch_size", "]", ")", "\n", "", "if", "self", ".", "_stop_gradient", ":", "\n", "            ", "sample_ids", "=", "tf", ".", "stop_gradient", "(", "sample_ids", ")", "\n", "", "next_inputs", "=", "tf", ".", "matmul", "(", "sample_ids", ",", "self", ".", "_embedding", ")", "\n", "return", "(", "finished", ",", "next_inputs", ",", "state", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.decoders.rnn_decoder_helpers.GumbelSoftmaxEmbeddingHelper.__init__": [[253, 272], ["rnn_decoder_helpers.SoftmaxEmbeddingHelper.__init__"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.text_infilling.self_attn_hyperparams.Hyperparams.__init__"], ["def", "__init__", "(", "self", ",", "embedding", ",", "start_tokens", ",", "end_token", ",", "tau", ",", "\n", "straight_through", "=", "False", ",", "stop_gradient", "=", "False", ",", "use_finish", "=", "True", ")", ":", "\n", "        ", "\"\"\"Initializer.\n\n        Args:\n            embedding: An embedding argument (:attr:`params`) for\n                :tf_main:`tf.nn.embedding_lookup <nn/embedding_lookup>`. Note\n                that a callable is not acceptable here.\n            start_tokens: An `int32` vector tensor shaped `[batch_size]`. The\n                start tokens.\n            end_token: An `int32` scalar tensor. The token that marks end of\n                decoding.\n            tau: anneal temperature for sampling.\n            straight_through: whether to use the straight through estimator.\n            stop_gradient: stop gradients when feeding to the next step.\n        \"\"\"", "\n", "super", "(", "GumbelSoftmaxEmbeddingHelper", ",", "self", ")", ".", "__init__", "(", "\n", "embedding", ",", "start_tokens", ",", "end_token", ",", "tau", ",", "stop_gradient", ",", "use_finish", ")", "\n", "self", ".", "_straight_through", "=", "straight_through", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.decoders.rnn_decoder_helpers.GumbelSoftmaxEmbeddingHelper.sample": [[273, 282], ["tensorflow.contrib.distributions.RelaxedOneHotCategorical.sample", "tensorflow.cast", "tensorflow.contrib.distributions.RelaxedOneHotCategorical", "tensorflow.shape", "tensorflow.one_hot", "tensorflow.stop_gradient", "tensorflow.argmax"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.decoders.rnn_decoder_helpers.GumbelSoftmaxEmbeddingHelper.sample"], ["", "def", "sample", "(", "self", ",", "time", ",", "outputs", ",", "state", ",", "name", "=", "None", ")", ":", "\n", "        ", "sample_ids", "=", "GumbelSoftmax", "(", "self", ".", "_tau", ",", "logits", "=", "outputs", ")", ".", "sample", "(", ")", "\n", "if", "self", ".", "_straight_through", ":", "\n", "            ", "size", "=", "tf", ".", "shape", "(", "sample_ids", ")", "[", "-", "1", "]", "\n", "sample_ids_hard", "=", "tf", ".", "cast", "(", "\n", "tf", ".", "one_hot", "(", "tf", ".", "argmax", "(", "sample_ids", ",", "-", "1", ")", ",", "size", ")", ",", "sample_ids", ".", "dtype", ")", "\n", "sample_ids", "=", "tf", ".", "stop_gradient", "(", "sample_ids_hard", "-", "sample_ids", ")", "+", "sample_ids", "\n", "", "return", "sample_ids", "\n", "", "", ""]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.decoders.rnn_decoder_helpers.default_helper_train_hparams": [[30, 55], ["None"], "function", ["None"], ["def", "default_helper_train_hparams", "(", ")", ":", "\n", "    ", "\"\"\"Returns default hyperparameters of an RNN decoder helper in the training\n    phase.\n\n    See also :meth:`~texar.modules.decoders.rnn_decoder_helpers.get_helper`\n    for information of the hyperparameters.\n\n    Returns:\n        dict: A dictionary with following structure and values:\n\n        .. code-block:: python\n\n            {\n                # The `helper_type` argument for `get_helper`, i.e., the name\n                # or full path to the helper class.\n                \"type\": \"TrainingHelper\",\n\n                # The `**kwargs` argument for `get_helper`, i.e., additional\n                # keyword arguments for constructing the helper.\n                \"kwargs\": {}\n            }\n    \"\"\"", "\n", "return", "{", "\n", "\"type\"", ":", "\"TrainingHelper\"", ",", "\n", "\"kwargs\"", ":", "{", "}", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.decoders.rnn_decoder_helpers.default_helper_infer_hparams": [[57, 82], ["None"], "function", ["None"], ["", "def", "default_helper_infer_hparams", "(", ")", ":", "\n", "    ", "\"\"\"Returns default hyperparameters of an RNN decoder helper in the inference\n    phase.\n\n    See also :meth:`~texar.modules.decoders.rnn_decoder_helpers.get_helper`\n    for information of the hyperparameters.\n\n    Returns:\n        dict: A dictionary with following structure and values:\n\n        .. code-block:: python\n\n            {\n                # The `helper_type` argument for `get_helper`, i.e., the name\n                # or full path to the helper class.\n                \"type\": \"SampleEmbeddingHelper\",\n\n                # The `**kwargs` argument for `get_helper`, i.e., additional\n                # keyword arguments for constructing the helper.\n                \"kwargs\": {}\n            }\n    \"\"\"", "\n", "return", "{", "\n", "\"type\"", ":", "\"SampleEmbeddingHelper\"", ",", "\n", "\"kwargs\"", ":", "{", "}", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.decoders.rnn_decoder_helpers.get_helper": [[85, 128], ["class_kwargs.update", "texar.utils.utils.get_instance_with_redundant_kwargs"], "function", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.utils.get_instance_with_redundant_kwargs"], ["", "def", "get_helper", "(", "helper_type", ",", "\n", "inputs", "=", "None", ",", "\n", "sequence_length", "=", "None", ",", "\n", "embedding", "=", "None", ",", "\n", "start_tokens", "=", "None", ",", "\n", "end_token", "=", "None", ",", "\n", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Creates a Helper instance.\n\n    Args:\n        helper_type (str): The name or full path to the helper class.\n            E.g., the classname of the built-in helpers in\n            :mod:`texar.modules.decoders.rnn_decoder_helpers` or\n            :mod:`tensorflow.contrib.seq2seq`, or the classname of user-defined\n            helpers in :mod:`texar.custom`, or a full path like\n            \"my_module.MyHelper\".\n        inputs ((structure of) Tensors, optional): Inputs to the decoder.\n        sequence_length (1D integer array or Tensor, optional): Lengths of input\n            token sequences.\n        embedding (optional): A callable that takes a vector tensor of integer\n            indexes, or the `params` argument for `embedding_lookup` (e.g.,\n            the embedding Tensor).\n        start_tokens (int array or 1D int Tensor, optional): Of shape\n            `[batch_size]`. The start tokens.\n        end_token (int or int scalar Tensor, optional): The token that marks\n            end of decoding.\n        **kwargs: additional keyword arguments for constructing the helper.\n\n    Returns:\n        An instance of specified helper.\n    \"\"\"", "\n", "module_paths", "=", "[", "\n", "'texar.modules.decoders.rnn_decoder_helpers'", ",", "\n", "'tensorflow.contrib.seq2seq'", ",", "\n", "'texar.custom'", "]", "\n", "class_kwargs", "=", "{", "\"inputs\"", ":", "inputs", ",", "\n", "\"sequence_length\"", ":", "sequence_length", ",", "\n", "\"embedding\"", ":", "embedding", ",", "\n", "\"start_tokens\"", ":", "start_tokens", ",", "\n", "\"end_token\"", ":", "end_token", "}", "\n", "class_kwargs", ".", "update", "(", "kwargs", ")", "\n", "return", "utils", ".", "get_instance_with_redundant_kwargs", "(", "\n", "helper_type", ",", "class_kwargs", ",", "module_paths", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.decoders.rnn_decoder_helpers._get_training_helper": [[130, 172], ["tensorflow.contrib.seq2seq.TrainingHelper", "tensorflow.contrib.seq2seq.TrainingHelper", "tensorflow.name_scope", "callable", "embedding_fn", "tensorflow.nn.embedding_lookup"], "function", ["None"], ["", "def", "_get_training_helper", "(", "#pylint: disable=invalid-name", "\n", "inputs", ",", "sequence_length", ",", "embedding", "=", "None", ",", "time_major", "=", "False", ",", "name", "=", "None", ")", ":", "\n", "    ", "\"\"\"Returns an instance of :tf_main:`TrainingHelper\n    <contrib/seq2seq/TrainingHelper>` given embeddings.\n\n    Args:\n        inputs: If :attr:`embedding` is given, this is sequences of input\n            token indexes. If :attr:`embedding` is `None`, this is passed to\n            TrainingHelper directly.\n        sequence_length (1D Tensor): Lengths of input token sequences.\n        embedding (optional): The `params` argument of\n        :tf_main:`tf.nn.embedding_lookup\n        <nn/embedding_lookup>` (e.g., the embedding Tensor); or a callable that\n        takes a vector of integer indexes and returns respective embedding.\n        time_major (bool): Whether the tensors in `inputs` are time major.\n            If `False` (default), they are assumed to be batch major.\n        name (str, optional): Name scope for any created operations.\n\n    Returns:\n        An instance of TrainingHelper.\n\n    Raises:\n        ValueError: if `sequence_length` is not a 1D tensor.\n    \"\"\"", "\n", "if", "embedding", "is", "None", ":", "\n", "        ", "return", "TFTrainingHelper", "(", "inputs", "=", "inputs", ",", "\n", "sequence_length", "=", "sequence_length", ",", "\n", "time_major", "=", "time_major", ",", "\n", "name", "=", "name", ")", "\n", "\n", "", "with", "tf", ".", "name_scope", "(", "name", ",", "\"TrainingHelper\"", ",", "[", "embedding", ",", "inputs", "]", ")", ":", "\n", "        ", "if", "callable", "(", "embedding", ")", ":", "\n", "            ", "embedding_fn", "=", "embedding", "\n", "", "else", ":", "\n", "            ", "embedding_fn", "=", "(", "\n", "lambda", "ids", ":", "tf", ".", "nn", ".", "embedding_lookup", "(", "embedding", ",", "ids", ")", ")", "\n", "", "emb_inputs", "=", "embedding_fn", "(", "inputs", ")", "\n", "", "helper", "=", "TFTrainingHelper", "(", "inputs", "=", "emb_inputs", ",", "\n", "sequence_length", "=", "sequence_length", ",", "\n", "time_major", "=", "time_major", ",", "\n", "name", "=", "name", ")", "\n", "return", "helper", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.decoders.beam_search_decode._get_initial_state": [[24, 49], ["isinstance", "isinstance", "cell.zero_state", "cell.zero_state.clone", "ValueError", "cell.zero_state", "tensorflow.contrib.seq2seq.tile_batch", "isinstance", "tensorflow.tf.float32"], "function", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.decoders.rnn_decoder_base.RNNDecoderBase.zero_state", "home.repos.pwc.inspect_result.VegB_Text_Infilling.decoders.rnn_decoder_base.RNNDecoderBase.zero_state"], ["def", "_get_initial_state", "(", "initial_state", ",", "\n", "tiled_initial_state", ",", "\n", "cell", ",", "\n", "batch_size", ",", "\n", "beam_width", ",", "\n", "dtype", ")", ":", "\n", "    ", "if", "tiled_initial_state", "is", "None", ":", "\n", "        ", "if", "isinstance", "(", "initial_state", ",", "AttentionWrapperState", ")", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "'`initial_state` must not be an AttentionWrapperState. Use '", "\n", "'a plain cell state instead, which will be wrapped into an '", "\n", "'AttentionWrapperState automatically.'", ")", "\n", "", "if", "initial_state", "is", "None", ":", "\n", "            ", "tiled_initial_state", "=", "cell", ".", "zero_state", "(", "batch_size", "*", "beam_width", ",", "\n", "dtype", ")", "\n", "", "else", ":", "\n", "            ", "tiled_initial_state", "=", "tile_batch", "(", "initial_state", ",", "\n", "multiplier", "=", "beam_width", ")", "\n", "\n", "", "", "if", "isinstance", "(", "cell", ",", "AttentionWrapper", ")", "and", "not", "isinstance", "(", "tiled_initial_state", ",", "AttentionWrapperState", ")", ":", "\n", "        ", "zero_state", "=", "cell", ".", "zero_state", "(", "batch_size", "*", "beam_width", ",", "dtype", ")", "\n", "tiled_initial_state", "=", "zero_state", ".", "clone", "(", "cell_state", "=", "tiled_initial_state", ")", "\n", "\n", "", "return", "tiled_initial_state", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.decoders.beam_search_decode.beam_search_decode": [[50, 169], ["isinstance", "tensorflow.convert_to_tensor", "tensorflow.size", "beam_search_decode._get_initial_state", "isinstance", "decoder_or_cell._get_beam_search_cell", "isinstance", "ValueError", "isinstance", "tensorflow.contrib.seq2seq.BeamSearchDecoder", "tensorflow.contrib.seq2seq.dynamic_decode", "beam_search_decode.beam_search_decode._decode"], "function", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.data.vocabulary.Vocab.size", "home.repos.pwc.inspect_result.VegB_Text_Infilling.decoders.beam_search_decode._get_initial_state", "home.repos.pwc.inspect_result.VegB_Text_Infilling.decoders.rnn_decoder_base.RNNDecoderBase._get_beam_search_cell", "home.repos.pwc.inspect_result.VegB_Text_Infilling.decoders.template_transformer_decoder.TemplateTransformerDecoder.dynamic_decode"], ["", "def", "beam_search_decode", "(", "decoder_or_cell", ",", "\n", "embedding", ",", "\n", "start_tokens", ",", "\n", "end_token", ",", "\n", "beam_width", ",", "\n", "initial_state", "=", "None", ",", "\n", "tiled_initial_state", "=", "None", ",", "\n", "output_layer", "=", "None", ",", "\n", "length_penalty_weight", "=", "0.0", ",", "\n", "max_decoding_length", "=", "None", ",", "\n", "output_time_major", "=", "False", ",", "\n", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Performs BeamSearch sampling decoding.\n\n    Args:\n        decoder_or_cell: An instance of\n            :class:`~texar.modules.decoders.rnn_decoder_base.RNNDecoderBase`,\n            or an instance of :tf_main:`RNNCell <contrib/rnn/RNNCell>`.\n        embedding: A callable that takes a vector tensor of `ids` (argmax ids),\n            or the :attr:`params` argument for\n            :tf_main:`tf.nn.embedding_lookup <nn/embedding_lookup>`.\n        start_tokens: `int32` vector shaped `[batch_size]`, the start tokens.\n        end_token: `int32` scalar, the token that marks end of decoding.\n        beam_width: Python integer, the number of beams.\n        initial_state (optional): Initial state of decoding. The state must NOT\n            be tiled with :tf_main:`tile_batch <contrib/seq2seq/tile_batch>`.\n            If you have an already-tiled initial state, use\n            :attr:`tiled_initial_state` instead.\n\n            In the case of attention RNN decoder,:attr:`initial_state` must\n            NOT be an :tf_main:`AttentionWrapperState\n            <contrib/seq2seq/AttentionWrapperState>`. Instead, it must be a\n            state of the wrapped `RNNCell`, and the state will be wrapped into\n            `AttentionWrapperState` automatically.\n\n            If `None` (default), zero state is used. Ignored if\n            :attr:`tiled_initial_state` is given.\n        tiled_initial_state (optional): Initial state that has been tiled\n            (typicaly with :tf_main:`tile_batch <contrib/seq2seq/tile_batch>`)\n            so that the batch dimension has size `batch_size * beam_width`.\n\n            In the case of attention RNN decoder, this can be either a state\n            of the wrapped `RNNCell`, or an `AttentionWrapperState`.\n\n            If not given, :attr:`initial_state` is used.\n        output_layer: (optional) An instance of `tf.layers.Layer` to apply\n            to the RNN output prior to storing the result or sampling. If\n            `None` and :attr:`decoder_or_cell` is a decoder, the decoder's\n            output layer will be used.\n        length_penalty_weight: Float weight to penalize length.\n            Disabled with `0.0` (default).\n        max_decoding_length (optional): A int scalar Tensor indicating the\n            maximum allowed number of decoding steps. If `None` (default),\n            decoding will continue until the end token is encountered.\n        output_time_major (bool): If `True`, outputs are returned as\n            time major tensors. If `False` (default), outputs are returned\n            as batch major tensors.\n        **kwargs: Other keyword arguments for :tf_main:`dynamic_decode\n            <contrib/seq2seq/dynamic_decode>`. Argument `maximum_iterations`\n            is set to :attr:`max_decoding_length`.\n\n    Returns:\n        (outputs, final_state, sequence_length):\n\n        - outputs: An instance of :tf_main:`FinalBeamSearchDecoderOutput\n            <contrib/seq2seq/FinalBeamSearchDecoderOutput>`.\n        - final_state: An instance of :tf_main:`BeamSearchDecoderState\n            <contrib/seq2seq/BeamSearchDecoderState>`.\n        - sequence_length: A Tensor of shape `[batch_size]`.\n    \"\"\"", "\n", "if", "isinstance", "(", "decoder_or_cell", ",", "RNNDecoderBase", ")", ":", "\n", "        ", "cell", "=", "decoder_or_cell", ".", "_get_beam_search_cell", "(", "beam_width", "=", "beam_width", ")", "\n", "", "elif", "isinstance", "(", "decoder_or_cell", ",", "tf", ".", "contrib", ".", "rnn", ".", "RNNCell", ")", ":", "\n", "        ", "cell", "=", "decoder_or_cell", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "\"`decoder` must be an instance of a subclass of \"", "\n", "\"either `RNNDecoderBase` or `RNNCell`.\"", ")", "\n", "\n", "", "start_tokens", "=", "tf", ".", "convert_to_tensor", "(", "\n", "start_tokens", ",", "dtype", "=", "tf", ".", "int32", ",", "name", "=", "\"start_tokens\"", ")", "\n", "if", "start_tokens", ".", "get_shape", "(", ")", ".", "ndims", "!=", "1", ":", "\n", "        ", "raise", "ValueError", "(", "\"`start_tokens` must be a vector\"", ")", "\n", "", "batch_size", "=", "tf", ".", "size", "(", "start_tokens", ")", "\n", "\n", "initial_state", "=", "_get_initial_state", "(", "\n", "initial_state", ",", "tiled_initial_state", ",", "cell", ",", "\n", "batch_size", ",", "beam_width", ",", "tf", ".", "float32", ")", "\n", "\n", "if", "output_layer", "is", "None", "and", "isinstance", "(", "decoder_or_cell", ",", "RNNDecoderBase", ")", ":", "\n", "        ", "output_layer", "=", "decoder_or_cell", ".", "output_layer", "\n", "\n", "", "def", "_decode", "(", ")", ":", "\n", "        ", "beam_docoder", "=", "BeamSearchDecoder", "(", "\n", "cell", "=", "cell", ",", "\n", "embedding", "=", "embedding", ",", "\n", "start_tokens", "=", "start_tokens", ",", "\n", "end_token", "=", "end_token", ",", "\n", "initial_state", "=", "initial_state", ",", "\n", "beam_width", "=", "beam_width", ",", "\n", "output_layer", "=", "output_layer", ",", "\n", "length_penalty_weight", "=", "length_penalty_weight", ")", "\n", "\n", "if", "'maximum_iterations'", "in", "kwargs", ":", "\n", "            ", "raise", "ValueError", "(", "'Use `max_decoding_length` to set the maximum '", "\n", "'allowed number of decoding steps.'", ")", "\n", "", "outputs", ",", "final_state", ",", "_", "=", "dynamic_decode", "(", "\n", "decoder", "=", "beam_docoder", ",", "\n", "output_time_major", "=", "output_time_major", ",", "\n", "maximum_iterations", "=", "max_decoding_length", ",", "\n", "**", "kwargs", ")", "\n", "\n", "return", "outputs", ",", "final_state", ",", "final_state", ".", "lengths", "\n", "\n", "", "if", "isinstance", "(", "decoder_or_cell", ",", "RNNDecoderBase", ")", ":", "\n", "        ", "vs", "=", "decoder_or_cell", ".", "variable_scope", "\n", "with", "tf", ".", "variable_scope", "(", "vs", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", ":", "\n", "            ", "return", "_decode", "(", ")", "\n", "", "", "else", ":", "\n", "        ", "return", "_decode", "(", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.decoders.beam_search_decode_test.BeamSearchDecodeTest.setUp": [[28, 44], ["tensorflow.test.TestCase.setUp", "tensorflow.random_uniform", "tensorflow.random_uniform", "tensorflow.random_uniform"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.losses.mle_losses_test.MLELossesTest.setUp"], ["def", "setUp", "(", "self", ")", ":", "\n", "        ", "tf", ".", "test", ".", "TestCase", ".", "setUp", "(", "self", ")", "\n", "self", ".", "_vocab_size", "=", "10", "\n", "self", ".", "_max_time", "=", "16", "\n", "self", ".", "_batch_size", "=", "8", "\n", "self", ".", "_emb_dim", "=", "20", "\n", "self", ".", "_cell_dim", "=", "256", "\n", "self", ".", "_attention_dim", "=", "self", ".", "_cell_dim", "\n", "self", ".", "_beam_width", "=", "11", "\n", "self", ".", "_inputs", "=", "tf", ".", "random_uniform", "(", "\n", "[", "self", ".", "_batch_size", ",", "self", ".", "_max_time", ",", "self", ".", "_emb_dim", "]", ",", "\n", "maxval", "=", "1.", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "self", ".", "_embedding", "=", "tf", ".", "random_uniform", "(", "\n", "[", "self", ".", "_vocab_size", ",", "self", ".", "_emb_dim", "]", ",", "maxval", "=", "1.", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "self", ".", "_encoder_output", "=", "tf", ".", "random_uniform", "(", "\n", "[", "self", ".", "_batch_size", ",", "self", ".", "_max_time", ",", "64", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.decoders.beam_search_decode_test.BeamSearchDecodeTest._test_beam_search": [[45, 141], ["texar.modules.decoders.beam_search_decode.beam_search_decode", "beam_search_decode_test.BeamSearchDecodeTest.assertIsInstance", "beam_search_decode_test.BeamSearchDecodeTest.assertIsInstance", "len", "decoder", "beam_search_decode_test.BeamSearchDecodeTest.assertEqual", "tensorflow.contrib.seq2seq.BeamSearchDecoder", "tensorflow.contrib.seq2seq.dynamic_decode", "texar.modules.decoders.beam_search_decode.beam_search_decode", "texar.modules.decoders.beam_search_decode.beam_search_decode", "tensorflow.trainable_variables", "len", "decoder.cell.zero_state", "beam_search_decode_test.BeamSearchDecodeTest.test_session", "sess.run", "numpy.testing.assert_array_equal", "numpy.testing.assert_array_equal", "numpy.testing.assert_array_equal", "numpy.testing.assert_array_equal", "numpy.testing.assert_array_equal", "numpy.testing.assert_array_equal", "sess.run", "beam_search_decode_test.BeamSearchDecodeTest.assertEqual", "beam_search_decode_test.BeamSearchDecodeTest.assertEqual", "tensorflow.trainable_variables", "sess.run", "tuple", "tuple", "tensorflow.global_variables_initializer", "texar.context.global_mode", "texar.context.global_mode"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.decoders.beam_search_decode.beam_search_decode", "home.repos.pwc.inspect_result.VegB_Text_Infilling.decoders.template_transformer_decoder.TemplateTransformerDecoder.dynamic_decode", "home.repos.pwc.inspect_result.VegB_Text_Infilling.decoders.beam_search_decode.beam_search_decode", "home.repos.pwc.inspect_result.VegB_Text_Infilling.decoders.beam_search_decode.beam_search_decode", "home.repos.pwc.inspect_result.VegB_Text_Infilling.classifiers.conv_classifiers.Conv1DClassifier.trainable_variables", "home.repos.pwc.inspect_result.VegB_Text_Infilling.decoders.rnn_decoder_base.RNNDecoderBase.zero_state", "home.repos.pwc.inspect_result.VegB_Text_Infilling.classifiers.conv_classifiers.Conv1DClassifier.trainable_variables", "home.repos.pwc.inspect_result.VegB_Text_Infilling.texar.context.global_mode", "home.repos.pwc.inspect_result.VegB_Text_Infilling.texar.context.global_mode"], ["", "def", "_test_beam_search", "(", "\n", "self", ",", "decoder", ",", "initial_state", "=", "None", ",", "tiled_initial_state", "=", "None", ",", "\n", "tf_initial_state", "=", "None", ",", "beam_width_1", "=", "1", ",", "initiated", "=", "False", ")", ":", "\n", "## Compare with tf built-in BeamSearchDecoder", "\n", "        ", "outputs", ",", "final_state", ",", "_", "=", "beam_search_decode", "(", "\n", "decoder_or_cell", "=", "decoder", ",", "\n", "embedding", "=", "self", ".", "_embedding", ",", "\n", "start_tokens", "=", "[", "1", "]", "*", "self", ".", "_batch_size", ",", "\n", "end_token", "=", "2", ",", "\n", "beam_width", "=", "beam_width_1", ",", "\n", "max_decoding_length", "=", "20", ")", "\n", "\n", "self", ".", "assertIsInstance", "(", "\n", "outputs", ",", "tf", ".", "contrib", ".", "seq2seq", ".", "FinalBeamSearchDecoderOutput", ")", "\n", "self", ".", "assertIsInstance", "(", "\n", "final_state", ",", "tf", ".", "contrib", ".", "seq2seq", ".", "BeamSearchDecoderState", ")", "\n", "\n", "num_trainable_variables", "=", "len", "(", "tf", ".", "trainable_variables", "(", ")", ")", "\n", "_", "=", "decoder", "(", "\n", "decoding_strategy", "=", "'infer_greedy'", ",", "\n", "embedding", "=", "self", ".", "_embedding", ",", "\n", "start_tokens", "=", "[", "1", "]", "*", "self", ".", "_batch_size", ",", "\n", "end_token", "=", "2", ",", "\n", "max_decoding_length", "=", "20", ")", "\n", "self", ".", "assertEqual", "(", "num_trainable_variables", ",", "len", "(", "tf", ".", "trainable_variables", "(", ")", ")", ")", "\n", "\n", "if", "tf_initial_state", "is", "None", ":", "\n", "            ", "tf_initial_state", "=", "decoder", ".", "cell", ".", "zero_state", "(", "\n", "self", ".", "_batch_size", "*", "beam_width_1", ",", "tf", ".", "float32", ")", "\n", "", "beam_decoder", "=", "BeamSearchDecoder", "(", "\n", "cell", "=", "decoder", ".", "cell", ",", "\n", "embedding", "=", "self", ".", "_embedding", ",", "\n", "start_tokens", "=", "[", "1", "]", "*", "self", ".", "_batch_size", ",", "\n", "end_token", "=", "2", ",", "\n", "initial_state", "=", "tf_initial_state", ",", "\n", "beam_width", "=", "beam_width_1", ",", "\n", "output_layer", "=", "decoder", ".", "output_layer", ")", "\n", "\n", "outputs_1", ",", "final_state_1", ",", "_", "=", "dynamic_decode", "(", "\n", "decoder", "=", "beam_decoder", ",", "maximum_iterations", "=", "20", ")", "\n", "\n", "## Tests time major", "\n", "outputs_2", ",", "_", ",", "_", "=", "beam_search_decode", "(", "\n", "decoder_or_cell", "=", "decoder", ",", "\n", "embedding", "=", "self", ".", "_embedding", ",", "\n", "start_tokens", "=", "[", "1", "]", "*", "self", ".", "_batch_size", ",", "\n", "end_token", "=", "2", ",", "\n", "beam_width", "=", "self", ".", "_beam_width", ",", "\n", "initial_state", "=", "initial_state", ",", "\n", "tiled_initial_state", "=", "tiled_initial_state", ",", "\n", "max_decoding_length", "=", "21", ")", "\n", "outputs_3", ",", "_", ",", "_", "=", "beam_search_decode", "(", "\n", "decoder_or_cell", "=", "decoder", ",", "\n", "embedding", "=", "self", ".", "_embedding", ",", "\n", "start_tokens", "=", "[", "1", "]", "*", "self", ".", "_batch_size", ",", "\n", "end_token", "=", "2", ",", "\n", "beam_width", "=", "self", ".", "_beam_width", ",", "\n", "initial_state", "=", "initial_state", ",", "\n", "tiled_initial_state", "=", "tiled_initial_state", ",", "\n", "max_decoding_length", "=", "21", ",", "\n", "output_time_major", "=", "True", ")", "\n", "\n", "\n", "with", "self", ".", "test_session", "(", ")", "as", "sess", ":", "\n", "            ", "if", "not", "initiated", ":", "\n", "                ", "sess", ".", "run", "(", "tf", ".", "global_variables_initializer", "(", ")", ")", "\n", "\n", "", "outputs_", ",", "final_state_", ",", "outputs_1_", ",", "final_state_1_", "=", "sess", ".", "run", "(", "\n", "[", "outputs", ",", "final_state", ",", "outputs_1", ",", "final_state_1", "]", ",", "\n", "feed_dict", "=", "{", "context", ".", "global_mode", "(", ")", ":", "\n", "tf", ".", "estimator", ".", "ModeKeys", ".", "PREDICT", "}", ")", "\n", "\n", "np", ".", "testing", ".", "assert_array_equal", "(", "\n", "outputs_", ".", "predicted_ids", ",", "outputs_1_", ".", "predicted_ids", ")", "\n", "np", ".", "testing", ".", "assert_array_equal", "(", "\n", "outputs_", ".", "beam_search_decoder_output", ".", "scores", ",", "\n", "outputs_1_", ".", "beam_search_decoder_output", ".", "scores", ")", "\n", "np", ".", "testing", ".", "assert_array_equal", "(", "\n", "outputs_", ".", "beam_search_decoder_output", ".", "predicted_ids", ",", "\n", "outputs_1_", ".", "beam_search_decoder_output", ".", "predicted_ids", ")", "\n", "np", ".", "testing", ".", "assert_array_equal", "(", "\n", "outputs_", ".", "beam_search_decoder_output", ".", "parent_ids", ",", "\n", "outputs_1_", ".", "beam_search_decoder_output", ".", "parent_ids", ")", "\n", "np", ".", "testing", ".", "assert_array_equal", "(", "\n", "final_state_", ".", "log_probs", ",", "final_state_1_", ".", "log_probs", ")", "\n", "np", ".", "testing", ".", "assert_array_equal", "(", "\n", "final_state_", ".", "lengths", ",", "final_state_1_", ".", "lengths", ")", "\n", "\n", "outputs_2_", ",", "outputs_3_", "=", "sess", ".", "run", "(", "\n", "[", "outputs_2", ",", "outputs_3", "]", ",", "\n", "feed_dict", "=", "{", "context", ".", "global_mode", "(", ")", ":", "\n", "tf", ".", "estimator", ".", "ModeKeys", ".", "PREDICT", "}", ")", "\n", "self", ".", "assertEqual", "(", "outputs_2_", ".", "predicted_ids", ".", "shape", ",", "\n", "tuple", "(", "[", "self", ".", "_batch_size", ",", "21", ",", "11", "]", ")", ")", "\n", "self", ".", "assertEqual", "(", "outputs_3_", ".", "predicted_ids", ".", "shape", ",", "\n", "tuple", "(", "[", "21", ",", "self", ".", "_batch_size", ",", "11", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.decoders.beam_search_decode_test.BeamSearchDecodeTest.test_basic_rnn_decoder_beam_search": [[142, 158], ["texar.modules.BasicRNNDecoder", "beam_search_decode_test.BeamSearchDecodeTest._test_beam_search", "beam_search_decode_test.BeamSearchDecodeTest._test_beam_search"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.decoders.beam_search_decode_test.BeamSearchDecodeTest._test_beam_search", "home.repos.pwc.inspect_result.VegB_Text_Infilling.decoders.beam_search_decode_test.BeamSearchDecodeTest._test_beam_search"], ["", "", "def", "test_basic_rnn_decoder_beam_search", "(", "self", ")", ":", "\n", "        ", "\"\"\"Tests beam search with BasicRNNDecoder.\n        \"\"\"", "\n", "hparams", "=", "{", "\n", "\"rnn_cell\"", ":", "{", "\n", "\"kwargs\"", ":", "{", "\"num_units\"", ":", "self", ".", "_cell_dim", "}", "\n", "}", "\n", "}", "\n", "decoder", "=", "tx", ".", "modules", ".", "BasicRNNDecoder", "(", "\n", "vocab_size", "=", "self", ".", "_vocab_size", ",", "\n", "hparams", "=", "hparams", ")", "\n", "\n", "self", ".", "_test_beam_search", "(", "decoder", ")", "\n", "\n", "self", ".", "_test_beam_search", "(", "\n", "decoder", ",", "beam_width_1", "=", "self", ".", "_beam_width", ",", "initiated", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.decoders.beam_search_decode_test.BeamSearchDecodeTest.test_basic_rnn_decoder_given_initial_state": [[159, 182], ["texar.modules.BasicRNNDecoder", "texar.modules.BasicRNNDecoder.cell.zero_state", "texar.modules.BasicRNNDecoder.cell.zero_state", "beam_search_decode_test.BeamSearchDecodeTest._test_beam_search", "tensorflow.contrib.seq2seq.tile_batch", "beam_search_decode_test.BeamSearchDecodeTest._test_beam_search"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.decoders.rnn_decoder_base.RNNDecoderBase.zero_state", "home.repos.pwc.inspect_result.VegB_Text_Infilling.decoders.rnn_decoder_base.RNNDecoderBase.zero_state", "home.repos.pwc.inspect_result.VegB_Text_Infilling.decoders.beam_search_decode_test.BeamSearchDecodeTest._test_beam_search", "home.repos.pwc.inspect_result.VegB_Text_Infilling.decoders.beam_search_decode_test.BeamSearchDecodeTest._test_beam_search"], ["", "def", "test_basic_rnn_decoder_given_initial_state", "(", "self", ")", ":", "\n", "        ", "\"\"\"Tests beam search with BasicRNNDecoder given initial state.\n        \"\"\"", "\n", "hparams", "=", "{", "\n", "\"rnn_cell\"", ":", "{", "\n", "\"kwargs\"", ":", "{", "\"num_units\"", ":", "self", ".", "_cell_dim", "}", "\n", "}", "\n", "}", "\n", "decoder", "=", "tx", ".", "modules", ".", "BasicRNNDecoder", "(", "\n", "vocab_size", "=", "self", ".", "_vocab_size", ",", "\n", "hparams", "=", "hparams", ")", "\n", "\n", "# (zhiting): The beam search decoder does not generate max-length", "\n", "# samples if only one cell_state is created. Perhaps due to", "\n", "# random seed or bugs?", "\n", "cell_state", "=", "decoder", ".", "cell", ".", "zero_state", "(", "self", ".", "_batch_size", ",", "tf", ".", "float32", ")", "\n", "cell_state", "=", "decoder", ".", "cell", ".", "zero_state", "(", "self", ".", "_batch_size", ",", "tf", ".", "float32", ")", "\n", "\n", "self", ".", "_test_beam_search", "(", "decoder", ",", "initial_state", "=", "cell_state", ")", "\n", "\n", "tiled_cell_state", "=", "tile_batch", "(", "cell_state", ",", "multiplier", "=", "self", ".", "_beam_width", ")", "\n", "self", ".", "_test_beam_search", "(", "\n", "decoder", ",", "tiled_initial_state", "=", "tiled_cell_state", ",", "initiated", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.decoders.beam_search_decode_test.BeamSearchDecodeTest.test_attention_decoder_beam_search": [[183, 204], ["tensorflow.constant", "texar.modules.AttentionRNNDecoder", "beam_search_decode_test.BeamSearchDecodeTest._test_beam_search", "numpy.random.randint"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.decoders.beam_search_decode_test.BeamSearchDecodeTest._test_beam_search"], ["", "def", "test_attention_decoder_beam_search", "(", "self", ")", ":", "\n", "        ", "\"\"\"Tests beam search with RNNAttentionDecoder.\n        \"\"\"", "\n", "seq_length", "=", "np", ".", "random", ".", "randint", "(", "\n", "self", ".", "_max_time", ",", "size", "=", "[", "self", ".", "_batch_size", "]", ")", "+", "1", "\n", "encoder_values_length", "=", "tf", ".", "constant", "(", "seq_length", ")", "\n", "hparams", "=", "{", "\n", "\"attention\"", ":", "{", "\n", "\"kwargs\"", ":", "{", "\"num_units\"", ":", "self", ".", "_attention_dim", "}", "\n", "}", ",", "\n", "\"rnn_cell\"", ":", "{", "\n", "\"kwargs\"", ":", "{", "\"num_units\"", ":", "self", ".", "_cell_dim", "}", "\n", "}", "\n", "}", "\n", "decoder", "=", "tx", ".", "modules", ".", "AttentionRNNDecoder", "(", "\n", "vocab_size", "=", "self", ".", "_vocab_size", ",", "\n", "memory", "=", "self", ".", "_encoder_output", ",", "\n", "memory_sequence_length", "=", "encoder_values_length", ",", "\n", "hparams", "=", "hparams", ")", "\n", "\n", "self", ".", "_test_beam_search", "(", "decoder", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.decoders.beam_search_decode_test.BeamSearchDecodeTest.test_attention_decoder_given_initial_state": [[205, 233], ["tensorflow.constant", "texar.modules.AttentionRNNDecoder", "texar.modules.AttentionRNNDecoder.cell.zero_state", "beam_search_decode_test.BeamSearchDecodeTest._test_beam_search", "tensorflow.contrib.seq2seq.tile_batch", "beam_search_decode_test.BeamSearchDecodeTest._test_beam_search", "numpy.random.randint"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.decoders.rnn_decoder_base.RNNDecoderBase.zero_state", "home.repos.pwc.inspect_result.VegB_Text_Infilling.decoders.beam_search_decode_test.BeamSearchDecodeTest._test_beam_search", "home.repos.pwc.inspect_result.VegB_Text_Infilling.decoders.beam_search_decode_test.BeamSearchDecodeTest._test_beam_search"], ["", "def", "test_attention_decoder_given_initial_state", "(", "self", ")", ":", "\n", "        ", "\"\"\"Tests beam search with RNNAttentionDecoder given initial state.\n        \"\"\"", "\n", "seq_length", "=", "np", ".", "random", ".", "randint", "(", "\n", "self", ".", "_max_time", ",", "size", "=", "[", "self", ".", "_batch_size", "]", ")", "+", "1", "\n", "encoder_values_length", "=", "tf", ".", "constant", "(", "seq_length", ")", "\n", "hparams", "=", "{", "\n", "\"attention\"", ":", "{", "\n", "\"kwargs\"", ":", "{", "\"num_units\"", ":", "self", ".", "_attention_dim", "}", "\n", "}", ",", "\n", "\"rnn_cell\"", ":", "{", "\n", "\"kwargs\"", ":", "{", "\"num_units\"", ":", "self", ".", "_cell_dim", "}", "\n", "}", "\n", "}", "\n", "decoder", "=", "tx", ".", "modules", ".", "AttentionRNNDecoder", "(", "\n", "vocab_size", "=", "self", ".", "_vocab_size", ",", "\n", "memory", "=", "self", ".", "_encoder_output", ",", "\n", "memory_sequence_length", "=", "encoder_values_length", ",", "\n", "hparams", "=", "hparams", ")", "\n", "\n", "state", "=", "decoder", ".", "cell", ".", "zero_state", "(", "self", ".", "_batch_size", ",", "tf", ".", "float32", ")", "\n", "\n", "cell_state", "=", "state", ".", "cell_state", "\n", "self", ".", "_test_beam_search", "(", "decoder", ",", "initial_state", "=", "cell_state", ")", "\n", "\n", "tiled_cell_state", "=", "tile_batch", "(", "cell_state", ",", "multiplier", "=", "self", ".", "_beam_width", ")", "\n", "self", ".", "_test_beam_search", "(", "\n", "decoder", ",", "tiled_initial_state", "=", "tiled_cell_state", ",", "initiated", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.decoders.rnn_decoders.BasicRNNDecoder.__init__": [[116, 124], ["texar.modules.decoders.rnn_decoder_base.RNNDecoderBase.__init__"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.text_infilling.self_attn_hyperparams.Hyperparams.__init__"], ["def", "__init__", "(", "self", ",", "\n", "cell", "=", "None", ",", "\n", "cell_dropout_mode", "=", "None", ",", "\n", "vocab_size", "=", "None", ",", "\n", "output_layer", "=", "None", ",", "\n", "hparams", "=", "None", ")", ":", "\n", "        ", "RNNDecoderBase", ".", "__init__", "(", "\n", "self", ",", "cell", ",", "vocab_size", ",", "output_layer", ",", "cell_dropout_mode", ",", "hparams", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.decoders.rnn_decoders.BasicRNNDecoder.default_hparams": [[125, 184], ["texar.modules.decoders.rnn_decoder_base.RNNDecoderBase.default_hparams"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.core.replay_memories.DequeReplayMemory.default_hparams"], ["", "@", "staticmethod", "\n", "def", "default_hparams", "(", ")", ":", "\n", "        ", "\"\"\"Returns a dictionary of hyperparameters with default values.\n\n        Returns:\n            .. code-block:: python\n\n                {\n                    \"rnn_cell\": default_rnn_cell_hparams(),\n                    \"helper_train\": default_helper_train_hparams(),\n                    \"helper_infer\": default_helper_infer_hparams(),\n                    \"max_decoding_length_train\": None,\n                    \"max_decoding_length_infer\": None,\n                    \"name\": \"basic_rnn_decoder\"\n                }\n\n            Here:\n\n            \"rnn_cell\" : dict\n                A dictionary of RNN cell hyperparameters. Ignored if\n                :attr:`cell` is given when constructing the decoder.\n\n                The default value is defined in\n                :meth:`~texar.core.layers.default_rnn_cell_hparams`.\n\n            \"helper_train\" : dict\n                A dictionary of :class:`Helper` hyperparameters. The\n                helper is used in training phase.\n\n                The default value is defined in\n                :meth:`~texar.modules.default_helper_train_hparams`\n\n            \"helper_infer\": dict\n                A dictionary of :class:`Helper` hyperparameters. The\n                helper is used in inference phase.\n\n                The default value is defined in\n                :meth:`~texar.modules.default_helper_infer_hparams`\n\n            \"max_decoding_length_train\": int or None\n                Maximum allowed number of decoding steps in training mode..\n\n                The default is `None`, which means decoding is\n                performed until fully done, e.g., encountering the <EOS> token.\n\n            \"max_decoding_length_infer\" : int or None\n                Maximum allowed number of decoding steps in inference mode.\n\n                The default is `None`, which means decoding is\n                performed until fully done, e.g., encountering the <EOS> token.\n\n            \"name\" : str\n                Name of the decoder.\n\n                The default value is \"basic_rnn_decoder\".\n        \"\"\"", "\n", "hparams", "=", "RNNDecoderBase", ".", "default_hparams", "(", ")", "\n", "hparams", "[", "\"name\"", "]", "=", "\"basic_rnn_decoder\"", "\n", "return", "hparams", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.decoders.rnn_decoders.BasicRNNDecoder.initialize": [[185, 187], ["rnn_decoders.BasicRNNDecoder._helper.initialize"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.decoders.rnn_decoder_base.RNNDecoderBase.initialize"], ["", "def", "initialize", "(", "self", ",", "name", "=", "None", ")", ":", "\n", "        ", "return", "self", ".", "_helper", ".", "initialize", "(", ")", "+", "(", "self", ".", "_initial_state", ",", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.decoders.rnn_decoders.BasicRNNDecoder.step": [[188, 200], ["rnn_decoders.BasicRNNDecoder._cell", "rnn_decoders.BasicRNNDecoder._output_layer", "rnn_decoders.BasicRNNDecoder._helper.sample", "rnn_decoders.BasicRNNDecoder._helper.next_inputs", "rnn_decoders.BasicRNNDecoderOutput"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.decoders.rnn_decoder_helpers.GumbelSoftmaxEmbeddingHelper.sample", "home.repos.pwc.inspect_result.VegB_Text_Infilling.decoders.rnn_decoder_helpers.SoftmaxEmbeddingHelper.next_inputs"], ["", "def", "step", "(", "self", ",", "time", ",", "inputs", ",", "state", ",", "name", "=", "None", ")", ":", "\n", "        ", "cell_outputs", ",", "cell_state", "=", "self", ".", "_cell", "(", "inputs", ",", "state", ")", "\n", "logits", "=", "self", ".", "_output_layer", "(", "cell_outputs", ")", "\n", "sample_ids", "=", "self", ".", "_helper", ".", "sample", "(", "\n", "time", "=", "time", ",", "outputs", "=", "logits", ",", "state", "=", "cell_state", ")", "\n", "(", "finished", ",", "next_inputs", ",", "next_state", ")", "=", "self", ".", "_helper", ".", "next_inputs", "(", "\n", "time", "=", "time", ",", "\n", "outputs", "=", "logits", ",", "\n", "state", "=", "cell_state", ",", "\n", "sample_ids", "=", "sample_ids", ")", "\n", "outputs", "=", "BasicRNNDecoderOutput", "(", "logits", ",", "sample_ids", ",", "cell_outputs", ")", "\n", "return", "(", "outputs", ",", "next_state", ",", "next_inputs", ",", "finished", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.decoders.rnn_decoders.BasicRNNDecoder.finalize": [[201, 203], ["None"], "methods", ["None"], ["", "def", "finalize", "(", "self", ",", "outputs", ",", "final_state", ",", "sequence_lengths", ")", ":", "\n", "        ", "return", "outputs", ",", "final_state", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.decoders.rnn_decoders.BasicRNNDecoder.output_size": [[204, 212], ["rnn_decoders.BasicRNNDecoderOutput", "rnn_decoders.BasicRNNDecoder._rnn_output_size"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.decoders.rnn_decoder_base.RNNDecoderBase._rnn_output_size"], ["", "@", "property", "\n", "def", "output_size", "(", "self", ")", ":", "\n", "        ", "\"\"\"Output size of one step.\n        \"\"\"", "\n", "return", "BasicRNNDecoderOutput", "(", "\n", "logits", "=", "self", ".", "_rnn_output_size", "(", ")", ",", "\n", "sample_id", "=", "self", ".", "_helper", ".", "sample_ids_shape", ",", "\n", "cell_output", "=", "self", ".", "_cell", ".", "output_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.decoders.rnn_decoders.BasicRNNDecoder.output_dtype": [[213, 226], ["rnn_decoders.BasicRNNDecoderOutput", "tensorflow.python.util.nest.flatten", "tensorflow.python.util.nest.map_structure", "tensorflow.python.util.nest.map_structure", "rnn_decoders.BasicRNNDecoder._rnn_output_size"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.encoders.hierarchical_encoders.HierarchicalRNNEncoder.flatten", "home.repos.pwc.inspect_result.VegB_Text_Infilling.decoders.rnn_decoder_base.RNNDecoderBase._rnn_output_size"], ["", "@", "property", "\n", "def", "output_dtype", "(", "self", ")", ":", "\n", "        ", "\"\"\"Types of output of one step.\n        \"\"\"", "\n", "# Assume the dtype of the cell is the output_size structure", "\n", "# containing the input_state's first component's dtype.", "\n", "# Return that structure and the sample_ids_dtype from the helper.", "\n", "dtype", "=", "nest", ".", "flatten", "(", "self", ".", "_initial_state", ")", "[", "0", "]", ".", "dtype", "\n", "return", "BasicRNNDecoderOutput", "(", "\n", "logits", "=", "nest", ".", "map_structure", "(", "lambda", "_", ":", "dtype", ",", "self", ".", "_rnn_output_size", "(", ")", ")", ",", "\n", "sample_id", "=", "self", ".", "_helper", ".", "sample_ids_dtype", ",", "\n", "cell_output", "=", "nest", ".", "map_structure", "(", "\n", "lambda", "_", ":", "dtype", ",", "self", ".", "_cell", ".", "output_size", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.decoders.rnn_decoders.BasicPositionalRNNDecoder.__init__": [[256, 267], ["texar.modules.decoders.rnn_decoder_base.RNNDecoderBase.__init__"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.text_infilling.self_attn_hyperparams.Hyperparams.__init__"], ["def", "__init__", "(", "self", ",", "\n", "cell", "=", "None", ",", "\n", "cell_dropout_mode", "=", "None", ",", "\n", "vocab_size", "=", "None", ",", "\n", "output_layer", "=", "None", ",", "\n", "position_embedder", "=", "None", ",", "\n", "hparams", "=", "None", ")", ":", "\n", "        ", "RNNDecoderBase", ".", "__init__", "(", "\n", "self", ",", "cell", ",", "vocab_size", ",", "output_layer", ",", "cell_dropout_mode", ",", "hparams", ")", "\n", "self", ".", "position_embedder", "=", "position_embedder", "\n", "self", ".", "current_segment_id", "=", "-", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.decoders.rnn_decoders.BasicPositionalRNNDecoder.default_hparams": [[268, 327], ["texar.modules.decoders.rnn_decoder_base.RNNDecoderBase.default_hparams"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.core.replay_memories.DequeReplayMemory.default_hparams"], ["", "@", "staticmethod", "\n", "def", "default_hparams", "(", ")", ":", "\n", "        ", "\"\"\"Returns a dictionary of hyperparameters with default values.\n\n        Returns:\n            .. code-block:: python\n\n                {\n                    \"rnn_cell\": default_rnn_cell_hparams(),\n                    \"helper_train\": default_helper_train_hparams(),\n                    \"helper_infer\": default_helper_infer_hparams(),\n                    \"max_decoding_length_train\": None,\n                    \"max_decoding_length_infer\": None,\n                    \"name\": \"basic_rnn_decoder\"\n                }\n\n            Here:\n\n            \"rnn_cell\" : dict\n                A dictionary of RNN cell hyperparameters. Ignored if\n                :attr:`cell` is given when constructing the decoder.\n\n                The default value is defined in\n                :meth:`~texar.core.layers.default_rnn_cell_hparams`.\n\n            \"helper_train\" : dict\n                A dictionary of :class:`Helper` hyperparameters. The\n                helper is used in training phase.\n\n                The default value is defined in\n                :meth:`~texar.modules.default_helper_train_hparams`\n\n            \"helper_infer\": dict\n                A dictionary of :class:`Helper` hyperparameters. The\n                helper is used in inference phase.\n\n                The default value is defined in\n                :meth:`~texar.modules.default_helper_infer_hparams`\n\n            \"max_decoding_length_train\": int or None\n                Maximum allowed number of decoding steps in training mode..\n\n                The default is `None`, which means decoding is\n                performed until fully done, e.g., encountering the <EOS> token.\n\n            \"max_decoding_length_infer\" : int or None\n                Maximum allowed number of decoding steps in inference mode.\n\n                The default is `None`, which means decoding is\n                performed until fully done, e.g., encountering the <EOS> token.\n\n            \"name\" : str\n                Name of the decoder.\n\n                The default value is \"basic_rnn_decoder\".\n        \"\"\"", "\n", "hparams", "=", "RNNDecoderBase", ".", "default_hparams", "(", ")", "\n", "hparams", "[", "\"name\"", "]", "=", "\"basic_rnn_decoder\"", "\n", "return", "hparams", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.decoders.rnn_decoders.BasicPositionalRNNDecoder.initialize": [[328, 330], ["rnn_decoders.BasicPositionalRNNDecoder._helper.initialize"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.decoders.rnn_decoder_base.RNNDecoderBase.initialize"], ["", "def", "initialize", "(", "self", ",", "name", "=", "None", ")", ":", "\n", "        ", "return", "self", ".", "_helper", ".", "initialize", "(", ")", "+", "(", "self", ".", "_initial_state", ",", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.decoders.rnn_decoders.BasicPositionalRNNDecoder.step": [[331, 351], ["rnn_decoders.BasicPositionalRNNDecoder._cell", "rnn_decoders.BasicPositionalRNNDecoder._output_layer", "rnn_decoders.BasicPositionalRNNDecoder._helper.sample", "rnn_decoders.BasicPositionalRNNDecoder._helper.next_inputs", "texar.utils.shapes.shape_list", "rnn_decoders.BasicPositionalRNNDecoder.position_embedder", "tensorflow.reshape", "rnn_decoders.BasicRNNDecoderOutput", "tensorflow.cast", "tensorflow.cast", "tensorflow.fill", "tensorflow.fill"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.decoders.rnn_decoder_helpers.GumbelSoftmaxEmbeddingHelper.sample", "home.repos.pwc.inspect_result.VegB_Text_Infilling.decoders.rnn_decoder_helpers.SoftmaxEmbeddingHelper.next_inputs", "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.shapes.shape_list"], ["", "def", "step", "(", "self", ",", "time", ",", "inputs", ",", "state", ",", "name", "=", "None", ")", ":", "\n", "        ", "cell_outputs", ",", "cell_state", "=", "self", ".", "_cell", "(", "inputs", ",", "state", ")", "\n", "logits", "=", "self", ".", "_output_layer", "(", "cell_outputs", ")", "# turn cell outputs into logits for for each vocab", "\n", "sample_ids", "=", "self", ".", "_helper", ".", "sample", "(", "# turn logits into ids", "\n", "time", "=", "time", ",", "outputs", "=", "logits", ",", "state", "=", "cell_state", ")", "\n", "(", "finished", ",", "next_inputs_word_embeds", ",", "next_state", ")", "=", "self", ".", "_helper", ".", "next_inputs", "(", "\n", "time", "=", "time", ",", "\n", "outputs", "=", "logits", ",", "\n", "state", "=", "cell_state", ",", "\n", "sample_ids", "=", "sample_ids", ")", "# look up in embedding -> next_inputs", "\n", "batch_size", ",", "channels", "=", "shape_list", "(", "next_inputs_word_embeds", ")", "\n", "next_input_pos_embeds", "=", "self", ".", "position_embedder", "(", "\n", "length", "=", "1", ",", "\n", "channels", "=", "channels", ",", "\n", "segment_ids", "=", "tf", ".", "cast", "(", "tf", ".", "fill", "(", "[", "batch_size", ",", "1", "]", ",", "self", ".", "current_segment_id", ")", ",", "dtype", "=", "tf", ".", "int64", ")", ",", "\n", "offsets", "=", "tf", ".", "cast", "(", "tf", ".", "fill", "(", "[", "batch_size", ",", "1", "]", ",", "time", ")", ",", "dtype", "=", "tf", ".", "int64", ")", ")", "\n", "next_input_pos_embeds", "=", "tf", ".", "reshape", "(", "next_input_pos_embeds", ",", "[", "batch_size", ",", "channels", "]", ")", "\n", "next_inputs", "=", "next_inputs_word_embeds", "+", "next_input_pos_embeds", "\n", "outputs", "=", "BasicRNNDecoderOutput", "(", "logits", ",", "sample_ids", ",", "cell_outputs", ")", "\n", "return", "(", "outputs", ",", "next_state", ",", "next_inputs", ",", "finished", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.decoders.rnn_decoders.BasicPositionalRNNDecoder.finalize": [[352, 354], ["None"], "methods", ["None"], ["", "def", "finalize", "(", "self", ",", "outputs", ",", "final_state", ",", "sequence_lengths", ")", ":", "\n", "        ", "return", "outputs", ",", "final_state", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.decoders.rnn_decoders.BasicPositionalRNNDecoder.output_size": [[355, 363], ["rnn_decoders.BasicRNNDecoderOutput", "rnn_decoders.BasicPositionalRNNDecoder._rnn_output_size"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.decoders.rnn_decoder_base.RNNDecoderBase._rnn_output_size"], ["", "@", "property", "\n", "def", "output_size", "(", "self", ")", ":", "\n", "        ", "\"\"\"Output size of one step.\n        \"\"\"", "\n", "return", "BasicRNNDecoderOutput", "(", "\n", "logits", "=", "self", ".", "_rnn_output_size", "(", ")", ",", "\n", "sample_id", "=", "self", ".", "_helper", ".", "sample_ids_shape", ",", "\n", "cell_output", "=", "self", ".", "_cell", ".", "output_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.decoders.rnn_decoders.BasicPositionalRNNDecoder.output_dtype": [[364, 377], ["rnn_decoders.BasicRNNDecoderOutput", "tensorflow.python.util.nest.flatten", "tensorflow.python.util.nest.map_structure", "tensorflow.python.util.nest.map_structure", "rnn_decoders.BasicPositionalRNNDecoder._rnn_output_size"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.encoders.hierarchical_encoders.HierarchicalRNNEncoder.flatten", "home.repos.pwc.inspect_result.VegB_Text_Infilling.decoders.rnn_decoder_base.RNNDecoderBase._rnn_output_size"], ["", "@", "property", "\n", "def", "output_dtype", "(", "self", ")", ":", "\n", "        ", "\"\"\"Types of output of one step.\n        \"\"\"", "\n", "# Assume the dtype of the cell is the output_size structure", "\n", "# containing the input_state's first component's dtype.", "\n", "# Return that structure and the sample_ids_dtype from the helper.", "\n", "dtype", "=", "nest", ".", "flatten", "(", "self", ".", "_initial_state", ")", "[", "0", "]", ".", "dtype", "\n", "return", "BasicRNNDecoderOutput", "(", "\n", "logits", "=", "nest", ".", "map_structure", "(", "lambda", "_", ":", "dtype", ",", "self", ".", "_rnn_output_size", "(", ")", ")", ",", "\n", "sample_id", "=", "self", ".", "_helper", ".", "sample_ids_dtype", ",", "\n", "cell_output", "=", "nest", ".", "map_structure", "(", "\n", "lambda", "_", ":", "dtype", ",", "self", ".", "_cell", ".", "output_size", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.decoders.rnn_decoders.BasicPositionalRNNDecoder.set_segment_id": [[378, 380], ["None"], "methods", ["None"], ["", "def", "set_segment_id", "(", "self", ",", "segment_id", ")", ":", "\n", "        ", "self", ".", "current_segment_id", "=", "segment_id", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.decoders.rnn_decoders.AttentionRNNDecoder.__init__": [[424, 476], ["texar.modules.decoders.rnn_decoder_base.RNNDecoderBase.__init__", "attn_hparams[].todict", "attn_hparams[].todict.update", "tensorflow.variable_scope", "texar.utils.utils.check_or_get_instance", "tensorflow.variable_scope", "tensorflow.contrib.seq2seq.AttentionWrapper", "texar.utils.utils.get_function", "callable"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.text_infilling.self_attn_hyperparams.Hyperparams.__init__", "home.repos.pwc.inspect_result.VegB_Text_Infilling.texar.hyperparams.HParams.todict", "home.repos.pwc.inspect_result.VegB_Text_Infilling.agents.agent_base.AgentBase.variable_scope", "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.utils.check_or_get_instance", "home.repos.pwc.inspect_result.VegB_Text_Infilling.agents.agent_base.AgentBase.variable_scope", "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.utils.get_function"], ["def", "__init__", "(", "self", ",", "\n", "memory", ",", "\n", "memory_sequence_length", "=", "None", ",", "\n", "cell_input_fn", "=", "None", ",", "\n", "cell", "=", "None", ",", "\n", "cell_dropout_mode", "=", "None", ",", "\n", "vocab_size", "=", "None", ",", "\n", "output_layer", "=", "None", ",", "\n", "hparams", "=", "None", ")", ":", "\n", "        ", "RNNDecoderBase", ".", "__init__", "(", "\n", "self", ",", "cell", ",", "vocab_size", ",", "output_layer", ",", "cell_dropout_mode", ",", "hparams", ")", "\n", "\n", "attn_hparams", "=", "self", ".", "_hparams", "[", "'attention'", "]", "\n", "attn_kwargs", "=", "attn_hparams", "[", "'kwargs'", "]", ".", "todict", "(", ")", "\n", "\n", "# Parse the 'probability_fn' argument", "\n", "if", "'probability_fn'", "in", "attn_kwargs", ":", "\n", "            ", "prob_fn", "=", "attn_kwargs", "[", "'probability_fn'", "]", "\n", "if", "prob_fn", "is", "not", "None", "and", "not", "callable", "(", "prob_fn", ")", ":", "\n", "                ", "prob_fn", "=", "utils", ".", "get_function", "(", "\n", "prob_fn", ",", "\n", "[", "'tensorflow.nn'", ",", "'tensorflow.contrib.sparsemax'", ",", "\n", "'tensorflow.contrib.seq2seq'", "]", ")", "\n", "", "attn_kwargs", "[", "'probability_fn'", "]", "=", "prob_fn", "\n", "\n", "", "attn_kwargs", ".", "update", "(", "{", "\n", "\"memory_sequence_length\"", ":", "memory_sequence_length", ",", "\n", "\"memory\"", ":", "memory", "}", ")", "\n", "self", ".", "_attn_kwargs", "=", "attn_kwargs", "\n", "attn_modules", "=", "[", "'tensorflow.contrib.seq2seq'", ",", "'texar.custom'", "]", "\n", "# Use variable_scope to ensure all trainable variables created in", "\n", "# the attention mechanism are collected", "\n", "with", "tf", ".", "variable_scope", "(", "self", ".", "variable_scope", ")", ":", "\n", "            ", "attention_mechanism", "=", "utils", ".", "check_or_get_instance", "(", "\n", "attn_hparams", "[", "\"type\"", "]", ",", "attn_kwargs", ",", "attn_modules", ",", "\n", "classtype", "=", "tf", ".", "contrib", ".", "seq2seq", ".", "AttentionMechanism", ")", "\n", "\n", "", "self", ".", "_attn_cell_kwargs", "=", "{", "\n", "\"attention_layer_size\"", ":", "attn_hparams", "[", "\"attention_layer_size\"", "]", ",", "\n", "\"alignment_history\"", ":", "attn_hparams", "[", "\"alignment_history\"", "]", ",", "\n", "\"output_attention\"", ":", "attn_hparams", "[", "\"output_attention\"", "]", ",", "\n", "}", "\n", "self", ".", "_cell_input_fn", "=", "cell_input_fn", "\n", "# Use variable_scope to ensure all trainable variables created in", "\n", "# AttentionWrapper are collected", "\n", "with", "tf", ".", "variable_scope", "(", "self", ".", "variable_scope", ")", ":", "\n", "            ", "attn_cell", "=", "AttentionWrapper", "(", "\n", "self", ".", "_cell", ",", "\n", "attention_mechanism", ",", "\n", "cell_input_fn", "=", "self", ".", "_cell_input_fn", ",", "\n", "**", "self", ".", "_attn_cell_kwargs", ")", "\n", "self", ".", "_cell", "=", "attn_cell", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.decoders.rnn_decoders.AttentionRNNDecoder.default_hparams": [[478, 623], ["texar.modules.decoders.rnn_decoder_base.RNNDecoderBase.default_hparams"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.core.replay_memories.DequeReplayMemory.default_hparams"], ["", "", "@", "staticmethod", "\n", "def", "default_hparams", "(", ")", ":", "\n", "        ", "\"\"\"Returns a dictionary of hyperparameters with default values:\n\n        Common hyperparameters are the same as in\n        :class:`~texar.modules.BasicRNNDecoder`\n        (see :meth:`texar.modules.BasicRNNDecoder.default_hparams`).\n        Additional hyperparameters are included for attention mechanism\n        configuration.\n\n        Returns:\n            .. code-block:: python\n\n                {\n                    \"attention\": {\n                        \"type\": \"LuongAttention\",\n                        \"kwargs\": {\n                            \"num_units\": 256,\n                        },\n                        \"attention_layer_size\": None,\n                        \"alignment_history\": False,\n                        \"output_attention\": True,\n                    },\n                    # The following hyperparameters are the same with\n                    # `BasicRNNDecoder`\n                    \"rnn_cell\": default_rnn_cell_hparams(),\n                    \"helper_train\": default_helper_train_hparams(),\n                    \"helper_infer\": default_helper_infer_hparams(),\n                    \"max_decoding_length_train\": None,\n                    \"max_decoding_length_infer\": None,\n                    \"name\": \"attention_rnn_decoder\"\n                }\n\n            Here:\n\n            \"attention\" : dict\n                Attention hyperparameters, which includes:\n\n                \"type\" : str\n                    Name or full path to the attention class which can be\n\n                    - Built-in attentions defined in \\\n                `tensorflow.contrib.seq2seq`, including \\\n                :class:`~tensorflow.contrib.seq2seq.LuongAttention`,\\\n                :class:`~tensorflow.contrib.seq2seq.BahdanauAttention`,\\\n                :class:`~tensorflow.contrib.seq2seq.BahdanauMonotonicAttention`\\\n                and \\\n                :class:`~tensorflow.contrib.seq2seq.LuongMonotonicAttention`.\n                    - User-defined attention classes in :mod:`texar.custom`.\n                    - External attention classes. Must provide the full path, \\\n                      e.g., \"my_module.MyAttentionClass\".\n\n                    The default value is \"LuongAttention\".\n\n                \"kwargs\" : dict\n                    A dictionary of arguments for constructor of the attention\n                    class. Any arguments besides the ones in the default\n                    value are allowed, except :attr:`memory` and\n                    :attr:`memory_sequence_length` (if exist) which are provided\n                    by :attr:`attention_keys` and\n                    :attr:`attention_values_length` in the decoder's\n                    constructor, respectively.\n\n                    The default value is:\n\n                        .. code-block:: python\n\n                            {\n                                \"num_units\": 256,\n                            }\n\n                        - :attr:`\"num_units\"` is the depth of the attention \\\n                        mechanism.\n\n                        E.g., We can specify :attr:`probability_fn` for\n                        :tf_main:`LuongAttention\n                        <contrib/seq2seq/LuongAttention>` or\n                        :tf_main:`BahdanauAttention\n                        <contrib/seq2seq/BahdanauAttention>` like:\n\n                        .. code-block:: python\n\n                            {\n                                \"probability_fn\": pf_value,\n                                ...\n                            }\n\n                        where :attr:`pf_value` is a callable or its name\n                        or full path to that converts the attention score to\n                        probabilities.\n                        The callable can be :tf_main:`tf.nn.softmax\n                        <nn/softmax>` (default),\n                        :tf_main:`tf.contrib.seq2seq.hardmax\n                        <contrib/seq2seq/hardmax>`, or\n                        :tf_main:`tf.contrib.sparsemax.sparsemax\n                        <contrib/sparsemax/sparsemax>`.\n                        Its signature should be:\n                        `probabilities = probability_fn(score)`\n\n                    \"attention_layer_size\" : int or None\n                        The depth of the attention (output) layer. If `None`\n                        (default), use the context as attention at each time\n                        step. Otherwise, feed the context and cell output into\n                        the attention layer to generate attention at each time\n                        step.\n\n                        The default value is `None`.\n\n                        TODO(zhiting): what does this mean?\n\n                    \"alignment_history\": bool\n                        whether to store alignment history from all time steps\n                        in the final output state.\n\n                        The default value is `False`.\n\n                        TODO(zhiting): what does this mean?\n\n                    \"output_attention\": bool\n                        If `True` (default), the output at each time step is\n                        the attention value. This is the behavior of Luong-style\n                        attention mechanisms. If `False`, the output at each\n                        time step is the output of `cell`.  This is the\n                        beahvior of Bhadanau-style attention mechanisms.\n                        In both cases, the `attention` tensor is propagated to\n                        the next time step via the state and is used there.\n                        This flag only controls whether the attention mechanism\n                        is propagated up to the next cell in an RNN stack or to\n                        the top RNN output.\n\n                        The default value is `True`.\n\n        \"\"\"", "\n", "hparams", "=", "RNNDecoderBase", ".", "default_hparams", "(", ")", "\n", "hparams", "[", "\"name\"", "]", "=", "\"attention_rnn_decoder\"", "\n", "hparams", "[", "\"attention\"", "]", "=", "{", "\n", "\"type\"", ":", "\"LuongAttention\"", ",", "\n", "\"kwargs\"", ":", "{", "\n", "\"num_units\"", ":", "256", ",", "\n", "}", ",", "\n", "\"attention_layer_size\"", ":", "None", ",", "\n", "\"alignment_history\"", ":", "False", ",", "\n", "\"output_attention\"", ":", "True", ",", "\n", "}", "\n", "return", "hparams", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.decoders.rnn_decoders.AttentionRNNDecoder._get_beam_search_cell": [[624, 652], ["tensorflow.variable_scope", "copy.copy", "tensorflow.contrib.seq2seq.tile_batch", "texar.utils.utils.check_or_get_instance", "tensorflow.contrib.seq2seq.AttentionWrapper", "tensorflow.contrib.seq2seq.tile_batch"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.agents.agent_base.AgentBase.variable_scope", "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.utils.check_or_get_instance"], ["", "def", "_get_beam_search_cell", "(", "self", ",", "beam_width", ")", ":", "\n", "        ", "\"\"\"Returns the RNN cell for beam search decoding.\n        \"\"\"", "\n", "with", "tf", ".", "variable_scope", "(", "self", ".", "variable_scope", ",", "reuse", "=", "True", ")", ":", "\n", "            ", "attn_kwargs", "=", "copy", ".", "copy", "(", "self", ".", "_attn_kwargs", ")", "\n", "\n", "memory", "=", "attn_kwargs", "[", "'memory'", "]", "\n", "attn_kwargs", "[", "'memory'", "]", "=", "tile_batch", "(", "memory", ",", "multiplier", "=", "beam_width", ")", "\n", "\n", "memory_seq_length", "=", "attn_kwargs", "[", "'memory_sequence_length'", "]", "\n", "if", "memory_seq_length", "is", "not", "None", ":", "\n", "                ", "attn_kwargs", "[", "'memory_sequence_length'", "]", "=", "tile_batch", "(", "\n", "memory_seq_length", ",", "beam_width", ")", "\n", "\n", "", "attn_modules", "=", "[", "'tensorflow.contrib.seq2seq'", ",", "'texar.custom'", "]", "\n", "bs_attention_mechanism", "=", "utils", ".", "check_or_get_instance", "(", "\n", "self", ".", "_hparams", ".", "attention", ".", "type", ",", "attn_kwargs", ",", "attn_modules", ",", "\n", "classtype", "=", "tf", ".", "contrib", ".", "seq2seq", ".", "AttentionMechanism", ")", "\n", "\n", "bs_attn_cell", "=", "AttentionWrapper", "(", "\n", "self", ".", "_cell", ".", "_cell", ",", "\n", "bs_attention_mechanism", ",", "\n", "cell_input_fn", "=", "self", ".", "_cell_input_fn", ",", "\n", "**", "self", ".", "_attn_cell_kwargs", ")", "\n", "\n", "self", ".", "_beam_search_cell", "=", "bs_attn_cell", "\n", "\n", "return", "bs_attn_cell", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.decoders.rnn_decoders.AttentionRNNDecoder.initialize": [[653, 663], ["rnn_decoders.AttentionRNNDecoder._helper.initialize", "tensorflow.python.util.nest.flatten", "rnn_decoders.AttentionRNNDecoder._cell.zero_state", "initial_state.clone.clone.clone", "tensorflow.shape"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.decoders.rnn_decoder_base.RNNDecoderBase.initialize", "home.repos.pwc.inspect_result.VegB_Text_Infilling.encoders.hierarchical_encoders.HierarchicalRNNEncoder.flatten", "home.repos.pwc.inspect_result.VegB_Text_Infilling.decoders.rnn_decoder_base.RNNDecoderBase.zero_state"], ["", "", "def", "initialize", "(", "self", ",", "name", "=", "None", ")", ":", "\n", "        ", "helper_init", "=", "self", ".", "_helper", ".", "initialize", "(", ")", "\n", "\n", "flat_initial_state", "=", "nest", ".", "flatten", "(", "self", ".", "_initial_state", ")", "\n", "dtype", "=", "flat_initial_state", "[", "0", "]", ".", "dtype", "\n", "initial_state", "=", "self", ".", "_cell", ".", "zero_state", "(", "\n", "batch_size", "=", "tf", ".", "shape", "(", "flat_initial_state", "[", "0", "]", ")", "[", "0", "]", ",", "dtype", "=", "dtype", ")", "\n", "initial_state", "=", "initial_state", ".", "clone", "(", "cell_state", "=", "self", ".", "_initial_state", ")", "\n", "\n", "return", "[", "helper_init", "[", "0", "]", ",", "helper_init", "[", "1", "]", ",", "initial_state", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.decoders.rnn_decoders.AttentionRNNDecoder.step": [[664, 683], ["rnn_decoders.AttentionRNNDecoder._cell", "rnn_decoders.AttentionRNNDecoder._output_layer", "rnn_decoders.AttentionRNNDecoder._helper.sample", "rnn_decoders.AttentionRNNDecoder._helper.next_inputs", "rnn_decoders.AttentionRNNDecoderOutput"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.decoders.rnn_decoder_helpers.GumbelSoftmaxEmbeddingHelper.sample", "home.repos.pwc.inspect_result.VegB_Text_Infilling.decoders.rnn_decoder_helpers.SoftmaxEmbeddingHelper.next_inputs"], ["", "def", "step", "(", "self", ",", "time", ",", "inputs", ",", "state", ",", "name", "=", "None", ")", ":", "\n", "        ", "wrapper_outputs", ",", "wrapper_state", "=", "self", ".", "_cell", "(", "inputs", ",", "state", ")", "\n", "# Essentisally the same as in BasicRNNDecoder.step()", "\n", "logits", "=", "self", ".", "_output_layer", "(", "wrapper_outputs", ")", "\n", "sample_ids", "=", "self", ".", "_helper", ".", "sample", "(", "\n", "time", "=", "time", ",", "outputs", "=", "logits", ",", "state", "=", "wrapper_state", ")", "\n", "(", "finished", ",", "next_inputs", ",", "next_state", ")", "=", "self", ".", "_helper", ".", "next_inputs", "(", "\n", "time", "=", "time", ",", "\n", "outputs", "=", "logits", ",", "\n", "state", "=", "wrapper_state", ",", "\n", "sample_ids", "=", "sample_ids", ")", "\n", "\n", "attention_scores", "=", "wrapper_state", ".", "alignments", "\n", "attention_context", "=", "wrapper_state", ".", "attention", "\n", "outputs", "=", "AttentionRNNDecoderOutput", "(", "\n", "logits", ",", "sample_ids", ",", "wrapper_outputs", ",", "\n", "attention_scores", ",", "attention_context", ")", "\n", "\n", "return", "(", "outputs", ",", "next_state", ",", "next_inputs", ",", "finished", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.decoders.rnn_decoders.AttentionRNNDecoder.finalize": [[684, 686], ["None"], "methods", ["None"], ["", "def", "finalize", "(", "self", ",", "outputs", ",", "final_state", ",", "sequence_lengths", ")", ":", "\n", "        ", "return", "outputs", ",", "final_state", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.decoders.rnn_decoders.AttentionRNNDecoder._alignments_size": [[687, 702], ["rnn_decoders.AttentionRNNDecoder._cell._item_or_tuple", "alignments_size.append", "tensorflow.shape"], "methods", ["None"], ["", "def", "_alignments_size", "(", "self", ")", ":", "\n", "# Reimplementation of the alignments_size of each of", "\n", "# AttentionWrapper.attention_mechanisms. The original implementation", "\n", "# of `_BaseAttentionMechanism._alignments_size`:", "\n", "#", "\n", "#    self._alignments_size = (self._keys.shape[1].value or", "\n", "#                       array_ops.shape(self._keys)[1])", "\n", "#", "\n", "# can be `None` when the seq length of encoder outputs are priori", "\n", "# unknown.", "\n", "        ", "alignments_size", "=", "[", "]", "\n", "for", "am", "in", "self", ".", "_cell", ".", "_attention_mechanisms", ":", "\n", "            ", "az", "=", "(", "am", ".", "_keys", ".", "shape", "[", "1", "]", ".", "value", "or", "tf", ".", "shape", "(", "am", ".", "_keys", ")", "[", "1", ":", "-", "1", "]", ")", "\n", "alignments_size", ".", "append", "(", "az", ")", "\n", "", "return", "self", ".", "_cell", ".", "_item_or_tuple", "(", "alignments_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.decoders.rnn_decoders.AttentionRNNDecoder.output_size": [[703, 711], ["rnn_decoders.AttentionRNNDecoderOutput", "rnn_decoders.AttentionRNNDecoder._rnn_output_size", "rnn_decoders.AttentionRNNDecoder._alignments_size"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.decoders.rnn_decoder_base.RNNDecoderBase._rnn_output_size", "home.repos.pwc.inspect_result.VegB_Text_Infilling.decoders.rnn_decoders.AttentionRNNDecoder._alignments_size"], ["", "@", "property", "\n", "def", "output_size", "(", "self", ")", ":", "\n", "        ", "return", "AttentionRNNDecoderOutput", "(", "\n", "logits", "=", "self", ".", "_rnn_output_size", "(", ")", ",", "\n", "sample_id", "=", "self", ".", "_helper", ".", "sample_ids_shape", ",", "\n", "cell_output", "=", "self", ".", "_cell", ".", "output_size", ",", "\n", "attention_scores", "=", "self", ".", "_alignments_size", "(", ")", ",", "\n", "attention_context", "=", "self", ".", "_cell", ".", "state_size", ".", "attention", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.decoders.rnn_decoders.AttentionRNNDecoder.output_dtype": [[712, 729], ["rnn_decoders.AttentionRNNDecoderOutput", "tensorflow.python.util.nest.flatten", "tensorflow.python.util.nest.map_structure", "tensorflow.python.util.nest.map_structure", "tensorflow.python.util.nest.map_structure", "tensorflow.python.util.nest.map_structure", "rnn_decoders.AttentionRNNDecoder._rnn_output_size", "rnn_decoders.AttentionRNNDecoder._alignments_size"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.encoders.hierarchical_encoders.HierarchicalRNNEncoder.flatten", "home.repos.pwc.inspect_result.VegB_Text_Infilling.decoders.rnn_decoder_base.RNNDecoderBase._rnn_output_size", "home.repos.pwc.inspect_result.VegB_Text_Infilling.decoders.rnn_decoders.AttentionRNNDecoder._alignments_size"], ["", "@", "property", "\n", "def", "output_dtype", "(", "self", ")", ":", "\n", "        ", "\"\"\"Types of output of one step.\n        \"\"\"", "\n", "# Assume the dtype of the cell is the output_size structure", "\n", "# containing the input_state's first component's dtype.", "\n", "# Return that structure and the sample_ids_dtype from the helper.", "\n", "dtype", "=", "nest", ".", "flatten", "(", "self", ".", "_initial_state", ")", "[", "0", "]", ".", "dtype", "\n", "return", "AttentionRNNDecoderOutput", "(", "\n", "logits", "=", "nest", ".", "map_structure", "(", "lambda", "_", ":", "dtype", ",", "self", ".", "_rnn_output_size", "(", ")", ")", ",", "\n", "sample_id", "=", "self", ".", "_helper", ".", "sample_ids_dtype", ",", "\n", "cell_output", "=", "nest", ".", "map_structure", "(", "\n", "lambda", "_", ":", "dtype", ",", "self", ".", "_cell", ".", "output_size", ")", ",", "\n", "attention_scores", "=", "nest", ".", "map_structure", "(", "\n", "lambda", "_", ":", "dtype", ",", "self", ".", "_alignments_size", "(", ")", ")", ",", "\n", "attention_context", "=", "nest", ".", "map_structure", "(", "\n", "lambda", "_", ":", "dtype", ",", "self", ".", "_cell", ".", "state_size", ".", "attention", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.decoders.rnn_decoders.AttentionRNNDecoder.zero_state": [[730, 736], ["rnn_decoders.AttentionRNNDecoder._cell._cell.zero_state"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.decoders.rnn_decoder_base.RNNDecoderBase.zero_state"], ["", "def", "zero_state", "(", "self", ",", "batch_size", ",", "dtype", ")", ":", "\n", "        ", "\"\"\"Returns zero state of the basic cell.\n\n        Same as :attr:`decoder.cell._cell.zero_state`.\n        \"\"\"", "\n", "return", "self", ".", "_cell", ".", "_cell", ".", "zero_state", "(", "batch_size", "=", "batch_size", ",", "dtype", "=", "dtype", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.decoders.rnn_decoders.AttentionRNNDecoder.wrapper_zero_state": [[737, 743], ["rnn_decoders.AttentionRNNDecoder._cell.zero_state"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.decoders.rnn_decoder_base.RNNDecoderBase.zero_state"], ["", "def", "wrapper_zero_state", "(", "self", ",", "batch_size", ",", "dtype", ")", ":", "\n", "        ", "\"\"\"Returns zero state of the attention-wrapped cell.\n\n        Same as :attr:`decoder.cell.zero_state`.\n        \"\"\"", "\n", "return", "self", ".", "_cell", ".", "zero_state", "(", "batch_size", "=", "batch_size", ",", "dtype", "=", "dtype", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.decoders.rnn_decoders.AttentionRNNDecoder.state_size": [[744, 751], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "state_size", "(", "self", ")", ":", "\n", "        ", "\"\"\"The state size of the basic cell.\n\n        Same as :attr:`decoder.cell._cell.state_size`.\n        \"\"\"", "\n", "return", "self", ".", "_cell", ".", "_cell", ".", "state_size", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.decoders.rnn_decoders.AttentionRNNDecoder.wrapper_state_size": [[753, 760], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "wrapper_state_size", "(", "self", ")", ":", "\n", "        ", "\"\"\"The state size of the attention-wrapped cell.\n\n        Same as :attr:`decoder.cell.state_size`.\n        \"\"\"", "\n", "return", "self", ".", "_cell", ".", "state_size", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.decoders.rnn_decoder_base.RNNDecoderBase.__init__": [[52, 87], ["texar.module_base.ModuleBase.__init__", "tensorflow.variable_scope", "texar.core.layers.get_rnn_cell", "ValueError", "tensorflow.variable_scope", "tensorflow.layers.Dense", "isinstance", "ValueError"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.text_infilling.self_attn_hyperparams.Hyperparams.__init__", "home.repos.pwc.inspect_result.VegB_Text_Infilling.agents.agent_base.AgentBase.variable_scope", "home.repos.pwc.inspect_result.VegB_Text_Infilling.core.layers.get_rnn_cell", "home.repos.pwc.inspect_result.VegB_Text_Infilling.agents.agent_base.AgentBase.variable_scope"], ["def", "__init__", "(", "self", ",", "\n", "cell", "=", "None", ",", "\n", "vocab_size", "=", "None", ",", "\n", "output_layer", "=", "None", ",", "\n", "cell_dropout_mode", "=", "None", ",", "\n", "hparams", "=", "None", ")", ":", "\n", "        ", "ModuleBase", ".", "__init__", "(", "self", ",", "hparams", ")", "\n", "\n", "self", ".", "_helper", "=", "None", "\n", "self", ".", "_initial_state", "=", "None", "\n", "\n", "# Make rnn cell", "\n", "with", "tf", ".", "variable_scope", "(", "self", ".", "variable_scope", ")", ":", "\n", "            ", "if", "cell", "is", "not", "None", ":", "\n", "                ", "self", ".", "_cell", "=", "cell", "\n", "", "else", ":", "\n", "                ", "self", ".", "_cell", "=", "layers", ".", "get_rnn_cell", "(", "\n", "self", ".", "_hparams", ".", "rnn_cell", ",", "cell_dropout_mode", ")", "\n", "", "", "self", ".", "_beam_search_cell", "=", "None", "\n", "\n", "# Make the output layer", "\n", "self", ".", "_vocab_size", "=", "vocab_size", "\n", "self", ".", "_output_layer", "=", "output_layer", "\n", "if", "output_layer", "is", "None", ":", "\n", "            ", "if", "self", ".", "_vocab_size", "is", "None", ":", "\n", "                ", "raise", "ValueError", "(", "\n", "\"Either `output_layer` or `vocab_size` must be provided. \"", "\n", "\"Set `output_layer=tf.identity` if no output layer is \"", "\n", "\"wanted.\"", ")", "\n", "", "with", "tf", ".", "variable_scope", "(", "self", ".", "variable_scope", ")", ":", "\n", "                ", "self", ".", "_output_layer", "=", "tf", ".", "layers", ".", "Dense", "(", "units", "=", "self", ".", "_vocab_size", ")", "\n", "", "", "elif", "output_layer", "is", "not", "tf", ".", "identity", ":", "\n", "            ", "if", "not", "isinstance", "(", "output_layer", ",", "tf", ".", "layers", ".", "Layer", ")", ":", "\n", "                ", "raise", "ValueError", "(", "\n", "\"`output_layer` must be either `tf.identity` or \"", "\n", "\"an instance of `tf.layers.Layer`.\"", ")", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.decoders.rnn_decoder_base.RNNDecoderBase.default_hparams": [[89, 105], ["texar.core.layers.default_rnn_cell_hparams", "texar.modules.decoders.rnn_decoder_helpers.default_helper_train_hparams", "texar.modules.decoders.rnn_decoder_helpers.default_helper_infer_hparams"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.core.layers.default_rnn_cell_hparams", "home.repos.pwc.inspect_result.VegB_Text_Infilling.decoders.rnn_decoder_helpers.default_helper_train_hparams", "home.repos.pwc.inspect_result.VegB_Text_Infilling.decoders.rnn_decoder_helpers.default_helper_infer_hparams"], ["", "", "", "@", "staticmethod", "\n", "def", "default_hparams", "(", ")", ":", "\n", "        ", "\"\"\"Returns a dictionary of hyperparameters with default values.\n\n        The hyperparameters have the same structure as in\n        :meth:`~texar.modules.BasicRNNDecoder.default_hparams` of\n        :class:`~texar.modules.BasicRNNDecoder`, except that the default\n        \"name\" here is \"rnn_decoder\".\n        \"\"\"", "\n", "return", "{", "\n", "\"rnn_cell\"", ":", "layers", ".", "default_rnn_cell_hparams", "(", ")", ",", "\n", "\"helper_train\"", ":", "rnn_decoder_helpers", ".", "default_helper_train_hparams", "(", ")", ",", "\n", "\"helper_infer\"", ":", "rnn_decoder_helpers", ".", "default_helper_infer_hparams", "(", ")", ",", "\n", "\"max_decoding_length_train\"", ":", "None", ",", "\n", "\"max_decoding_length_infer\"", ":", "None", ",", "\n", "\"name\"", ":", "\"rnn_decoder\"", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.decoders.rnn_decoder_base.RNNDecoderBase._build": [[107, 350], ["tensorflow.contrib.seq2seq.dynamic_decode", "rnn_decoder_base.RNNDecoderBase.zero_state", "tensorflow.cond", "rnn_decoder_base.RNNDecoderBase._add_internal_trainable_variables", "rnn_decoder_base.RNNDecoderBase._add_trainable_variable", "isinstance", "texar.utils.mode.is_train_mode_py", "copy.copy.update", "copy.copy.update", "texar.modules.decoders.rnn_decoder_helpers.get_helper", "texar.utils.mode.is_train_mode", "texar.core.layers.get_rnn_cell_trainable_variables", "rnn_decoder_base.RNNDecoderBase._add_trainable_variable", "rnn_decoder_base.RNNDecoderBase._add_trainable_variable", "texar.modules.decoders.rnn_decoder_helpers._get_training_helper", "copy.copy", "copy.copy", "tensorflow.contrib.seq2seq.GreedyEmbeddingHelper", "rnn_decoder_base.RNNDecoderBase._hparams.helper_train.kwargs.todict", "rnn_decoder_base.RNNDecoderBase._hparams.helper_infer.kwargs.todict", "tensorflow.contrib.seq2seq.SampleEmbeddingHelper", "tensorflow.contrib.seq2seq.GreedyEmbeddingHelper", "ValueError"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.decoders.template_transformer_decoder.TemplateTransformerDecoder.dynamic_decode", "home.repos.pwc.inspect_result.VegB_Text_Infilling.decoders.rnn_decoder_base.RNNDecoderBase.zero_state", "home.repos.pwc.inspect_result.VegB_Text_Infilling.texar.module_base.ModuleBase._add_internal_trainable_variables", "home.repos.pwc.inspect_result.VegB_Text_Infilling.texar.module_base.ModuleBase._add_trainable_variable", "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.mode.is_train_mode_py", "home.repos.pwc.inspect_result.VegB_Text_Infilling.decoders.rnn_decoder_helpers.get_helper", "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.mode.is_train_mode", "home.repos.pwc.inspect_result.VegB_Text_Infilling.core.layers.get_rnn_cell_trainable_variables", "home.repos.pwc.inspect_result.VegB_Text_Infilling.texar.module_base.ModuleBase._add_trainable_variable", "home.repos.pwc.inspect_result.VegB_Text_Infilling.texar.module_base.ModuleBase._add_trainable_variable", "home.repos.pwc.inspect_result.VegB_Text_Infilling.decoders.rnn_decoder_helpers._get_training_helper", "home.repos.pwc.inspect_result.VegB_Text_Infilling.texar.hyperparams.HParams.todict", "home.repos.pwc.inspect_result.VegB_Text_Infilling.texar.hyperparams.HParams.todict"], ["", "def", "_build", "(", "self", ",", "\n", "initial_state", "=", "None", ",", "\n", "max_decoding_length", "=", "None", ",", "\n", "impute_finished", "=", "False", ",", "\n", "output_time_major", "=", "False", ",", "\n", "decoding_strategy", "=", "\"train_greedy\"", ",", "\n", "inputs", "=", "None", ",", "\n", "sequence_length", "=", "None", ",", "\n", "input_time_major", "=", "False", ",", "\n", "embedding", "=", "None", ",", "\n", "start_tokens", "=", "None", ",", "\n", "end_token", "=", "None", ",", "\n", "softmax_temperature", "=", "None", ",", "\n", "helper", "=", "None", ",", "\n", "mode", "=", "None", ",", "\n", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"Performs decoding. The decoder provides 3 ways to specify the\n        decoding strategy, with varying flexibility:\n\n        - :attr:`decoding_strategy` argument: A string taking value:\n\n            - \"train_greedy\": decoding in training fashion (i.e., feeding \\\n              ground truth to decode the next step), and each sample is \\\n              obtained by taking the argmax of the RNN output logits. \\\n              Arguments :attr:`(inputs, sequence_length, input_time_major)` \\\n              are required for this strategy, and argument :attr:`embedding` \\\n              is optional.\n            - \"infer_greedy\": decoding in inference fashion (i.e., feeding \\\n              the generated sample to decode the next step), and each sample\\\n              is obtained by taking the argmax of the RNN output logits.\\\n              Arguments :attr:`(embedding, start_tokens, end_token)` are \\\n              required for this strategy.\n            - \"infer_sample\": decoding in inference fashion, and each sample \\\n              is obtained by random sampling from the RNN output distribution. \\\n              Arguments :attr:`(embedding, start_tokens, end_token)` are \\\n              required for this strategy.\n            - \"infer_positional\": adding positional embedding during inference.\n\n          This argument is used only when :attr:`helper` is `None`.\n\n        - :attr:`helper` argument: An instance of \\\n          :tf_main:`tf.contrib.seq2seq.Helper <contrib/seq2seq/Helper>`. This \\\n          provides a superset of decoding strategies than above, for example:\n\n            - :tf_main:`TrainingHelper\n              <contrib/seq2seq/TrainingHelper>` corresponding to the \\\n              :attr:`\"train_argmax\"` strategy.\n            - :tf_main:`ScheduledEmbeddingTrainingHelper\n              <contrib/seq2seq/ScheduledEmbeddingTrainingHelper>` and \\\n              :tf_main:`ScheduledOutputTrainingHelper\n              <contrib/seq2seq/ScheduledOutputTrainingHelper>` for scheduled \\\n              sampling.\n            - :class:`~texar.modules.SoftmaxEmbeddingHelper` and \\\n              :class:`~texar.modules.GumbelSoftmaxEmbeddingHelper` for \\\n              soft decoding and gradient backpropagation.\n\n          This means gives the maximal flexibility of configuring the decoding\\\n          strategy.\n\n        - :attr:`hparams[\"helper_train\"]` and :attr:`hparams[\"helper_infer\"]`:\\\n          Specifying the helper through hyperparameters. Train and infer \\\n          strategy is toggled based on :attr:`mode`. Appriopriate arguments \\\n          (e.g., :attr:`inputs`, :attr:`start_tokens`, etc) are selected to \\\n          construct the helper. Additional construction arguments can be \\\n          provided either through :attr:`**kwargs`, or through \\\n          :attr:`hparams[\"helper_train/infer\"][\"kwargs\"]`.\n\n          This means is used only when :attr:`decoding_strategy` and \\\n          :attr:`helper` are both `None`.\n\n        Args:\n            initial_state (optional): Initial state of decoding.\n                If `None` (default), zero state is used.\n            max_decoding_length: A int scalar Tensor indicating the maximum\n                allowed number of decoding steps. If `None` (default), either\n                :attr:`hparams[\"max_decoding_length_train\"]` or\n                :attr:`hparams[\"max_decoding_length_infer\"]` is used\n                according to :attr:`mode`.\n            impute_finished (bool): If `True`, then states for batch\n                entries which are marked as finished get copied through and\n                the corresponding outputs get zeroed out.  This causes some\n                slowdown at each time step, but ensures that the final state\n                and outputs have the correct values and that backprop ignores\n                time steps that were marked as finished.\n            output_time_major (bool): If `True`, outputs are returned as\n                time major tensors. If `False` (default), outputs are returned\n                as batch major tensors.\n            decoding_strategy (str, optional): A string specifying the decoding\n                strategy. Different arguments are required based on the\n                strategy.\n                Ignored if :attr:`helper` is given.\n            inputs (optional): Input tensors. Used when\n                :attr:`decoding_strategy=\"train_greedy\"` or\n                :attr:`hparams`-configured helper is used.\n\n                If :attr:`embedding` is `None`, :attr:`inputs` is directly\n                fed to the decoder. E.g., in `\"train_greedy\"` strategy,\n                :attr:`inputs` must be a 3D Tensor of shape\n                `[batch_size, max_time, emb_dim]` (or\n                `[max_time, batch_size, emb_dim]` if :attr:`input_time_major`\n                is `True`).\n\n                If :attr:`embedding` is given, :attr:`inputs` is used as index\n                to look up embeddings to be fed in the decoder. Requirements on\n                :attr:`inputs` depend on :attr:`embedding`.\n                E.g., if :attr:`embedding` is an instance of\n                :class:`~texar.modules.WordEmbedder`,\n                then :attr:`inputs` is usually a 2D int Tensor\n                `[batch_size, max_time]` (or\n                `[max_time, batch_size]` if :attr:`input_time_major`\n                is `True`) containing the token indexes.\n            sequence_length (optional): A 1D int Tensor containing the\n                sequence length of :attr:`inputs`.\n                Used when :attr:`decoding_strategy=\"train_greedy\"` or\n                :attr:`hparams`-configured helper is used.\n            input_time_major (optional): Whether the :attr:`inputs` tensor is\n                time major.\n                Used when :attr:`decoding_strategy=\"train_greedy\"` or\n                :attr:`hparams`-configured helper is used.\n            embedding (optional): A callable that returns embedding vectors\n                of inputs, or the :attr:`params` argument of\n                :tf_main:`tf.nn.embedding_lookup <nn/embedding_lookup>`. In the\n                later case, :attr:`inputs` (if used) must be an `int` Tensor\n                containing the ids to be looked up in :attr:`embedding`.\n                Required when :attr:`decoding_strategy=\"infer_greedy\"`\n                or `\"infer_sample\"`; optional when\n                :attr:`decoding_strategy=\"train_greedy\"`.\n            start_tokens (optional): A int Tensor of shape `[batch_size]`,\n                the start tokens.\n                Used when :attr:`decoding_strategy=\"infer_greedy\"` or\n                `\"infer_sample\"`, or when :attr:`hparams`-configured\n                helper is used.\n            end_token (optional): A int 0D Tensor, the token that marks end\n                of decoding.\n                Used when :attr:`decoding_strategy=\"infer_greedy\"` or\n                `\"infer_sample\"`, or when :attr:`hparams`-configured\n                helper is used.\n            softmax_temperature (optional): A float 0D Tensor, value to divide\n                the logits by before computing the softmax. Larger values\n                (above 1.0) result in more random samples. Must > 0. If `None`,\n                1.0 is used. Used when :attr:`decoding_strategy=\"infer_sample\"`.\n            helper (optional): An instance of\n                :tf_main:`Helper <contrib/seq2seq/Helper>`\n                that defines the decoding strategy. If given,\n                :attr:`decoding_strategy`\n                and helper configs in :attr:`hparams` are ignored.\n            mode (str, optional): A string taking value in\n                :tf_main:`tf.estimator.ModeKeys <estimator/ModeKeys>`. If\n                `TRAIN`, training related hyperparameters are used (e.g.,\n                :attr:`hparams['max_decoding_length_train']`), otherwise,\n                inference related hyperparameters are used (e.g.,\n                :attr:`hparams['max_decoding_length_infer']`). If\n                `None` (default), `TRAIN` mode is used.\n            **kwargs: Other keyword arguments for constructing helper\n                defined by :attr:`hparams[\"helper_trainn\"]` or\n                :attr:`hparams[\"helper_infer\"]`.\n\n        Returns:\n            `(outputs, final_state, sequence_lengths)`: `outputs` is an object\n            containing the decoder output on all time steps, `final_state` is\n            the cell state of the final time step, `sequence_lengths` is a\n            Tensor of shape `[batch_size]`.\n        \"\"\"", "\n", "# Helper", "\n", "if", "helper", "is", "not", "None", ":", "\n", "            ", "pass", "\n", "", "elif", "decoding_strategy", "is", "not", "None", ":", "\n", "            ", "if", "decoding_strategy", "==", "\"train_greedy\"", ":", "\n", "                ", "helper", "=", "rnn_decoder_helpers", ".", "_get_training_helper", "(", "\n", "inputs", ",", "sequence_length", ",", "embedding", ",", "input_time_major", ")", "\n", "", "elif", "decoding_strategy", "==", "\"infer_greedy\"", ":", "\n", "                ", "helper", "=", "tf", ".", "contrib", ".", "seq2seq", ".", "GreedyEmbeddingHelper", "(", "\n", "embedding", ",", "start_tokens", ",", "end_token", ")", "\n", "", "elif", "decoding_strategy", "==", "\"infer_sample\"", ":", "\n", "                ", "helper", "=", "tf", ".", "contrib", ".", "seq2seq", ".", "SampleEmbeddingHelper", "(", "\n", "embedding", ",", "start_tokens", ",", "end_token", ",", "softmax_temperature", ")", "\n", "", "elif", "decoding_strategy", "==", "\"infer_positional\"", ":", "\n", "                ", "helper", "=", "tf", ".", "contrib", ".", "seq2seq", ".", "GreedyEmbeddingHelper", "(", "\n", "embedding", ",", "start_tokens", ",", "end_token", ")", "\n", "", "else", ":", "\n", "                ", "raise", "ValueError", "(", "\n", "\"Unknown decoding strategy: {}\"", ".", "format", "(", "decoding_strategy", ")", ")", "\n", "", "", "else", ":", "\n", "            ", "if", "is_train_mode_py", "(", "mode", ")", ":", "\n", "                ", "kwargs_", "=", "copy", ".", "copy", "(", "self", ".", "_hparams", ".", "helper_train", ".", "kwargs", ".", "todict", "(", ")", ")", "\n", "helper_type", "=", "self", ".", "_hparams", ".", "helper_train", ".", "type", "\n", "", "else", ":", "\n", "                ", "kwargs_", "=", "copy", ".", "copy", "(", "self", ".", "_hparams", ".", "helper_infer", ".", "kwargs", ".", "todict", "(", ")", ")", "\n", "helper_type", "=", "self", ".", "_hparams", ".", "helper_infer", ".", "type", "\n", "", "kwargs_", ".", "update", "(", "{", "\n", "\"inputs\"", ":", "inputs", ",", "\n", "\"sequence_length\"", ":", "sequence_length", ",", "\n", "\"time_major\"", ":", "input_time_major", ",", "\n", "\"embedding\"", ":", "embedding", ",", "\n", "\"start_tokens\"", ":", "start_tokens", ",", "\n", "\"end_token\"", ":", "end_token", ",", "\n", "\"softmax_temperature\"", ":", "softmax_temperature", "}", ")", "\n", "kwargs_", ".", "update", "(", "kwargs", ")", "\n", "helper", "=", "rnn_decoder_helpers", ".", "get_helper", "(", "helper_type", ",", "**", "kwargs_", ")", "\n", "", "self", ".", "_helper", "=", "helper", "\n", "\n", "# Initial state", "\n", "if", "initial_state", "is", "not", "None", ":", "\n", "            ", "self", ".", "_initial_state", "=", "initial_state", "\n", "", "else", ":", "\n", "            ", "self", ".", "_initial_state", "=", "self", ".", "zero_state", "(", "\n", "batch_size", "=", "self", ".", "batch_size", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "\n", "# Maximum decoding length", "\n", "", "max_l", "=", "max_decoding_length", "\n", "if", "max_l", "is", "None", ":", "\n", "            ", "max_l_train", "=", "self", ".", "_hparams", ".", "max_decoding_length_train", "\n", "if", "max_l_train", "is", "None", ":", "\n", "                ", "max_l_train", "=", "utils", ".", "MAX_SEQ_LENGTH", "\n", "", "max_l_infer", "=", "self", ".", "_hparams", ".", "max_decoding_length_infer", "\n", "if", "max_l_infer", "is", "None", ":", "\n", "                ", "max_l_infer", "=", "utils", ".", "MAX_SEQ_LENGTH", "\n", "", "max_l", "=", "tf", ".", "cond", "(", "is_train_mode", "(", "mode", ")", ",", "\n", "lambda", ":", "max_l_train", ",", "lambda", ":", "max_l_infer", ")", "\n", "\n", "# Decode", "\n", "", "outputs", ",", "final_state", ",", "sequence_lengths", "=", "dynamic_decode", "(", "\n", "decoder", "=", "self", ",", "impute_finished", "=", "impute_finished", ",", "\n", "maximum_iterations", "=", "max_l", ",", "output_time_major", "=", "output_time_major", ")", "\n", "\n", "if", "not", "self", ".", "_built", ":", "\n", "            ", "self", ".", "_add_internal_trainable_variables", "(", ")", "\n", "# Add trainable variables of `self._cell` which may be", "\n", "# constructed externally.", "\n", "self", ".", "_add_trainable_variable", "(", "\n", "layers", ".", "get_rnn_cell_trainable_variables", "(", "self", ".", "_cell", ")", ")", "\n", "if", "isinstance", "(", "self", ".", "_output_layer", ",", "tf", ".", "layers", ".", "Layer", ")", ":", "\n", "                ", "self", ".", "_add_trainable_variable", "(", "\n", "self", ".", "_output_layer", ".", "trainable_variables", ")", "\n", "# Add trainable variables of `self._beam_search_rnn_cell` which", "\n", "# may already be constructed and used.", "\n", "", "if", "self", ".", "_beam_search_cell", "is", "not", "None", ":", "\n", "                ", "self", ".", "_add_trainable_variable", "(", "\n", "self", ".", "_beam_search_cell", ".", "trainable_variables", ")", "\n", "\n", "", "self", ".", "_built", "=", "True", "\n", "\n", "", "return", "outputs", ",", "final_state", ",", "sequence_lengths", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.decoders.rnn_decoder_base.RNNDecoderBase._get_beam_search_cell": [[351, 354], ["None"], "methods", ["None"], ["", "def", "_get_beam_search_cell", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "        ", "self", ".", "_beam_search_cell", "=", "self", ".", "_cell", "\n", "return", "self", ".", "_cell", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.decoders.rnn_decoder_base.RNNDecoderBase._rnn_output_size": [[355, 373], ["tensorflow.python.util.nest.map_structure", "rnn_decoder_base.compute_output_shape", "tensorflow.python.util.nest.map_structure", "tensorflow.python.framework.tensor_shape.TensorShape().concatenate", "tensorflow.python.framework.tensor_shape.TensorShape"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.core.layers.SequentialLayer.compute_output_shape"], ["", "def", "_rnn_output_size", "(", "self", ")", ":", "\n", "        ", "size", "=", "self", ".", "_cell", ".", "output_size", "\n", "if", "self", ".", "_output_layer", "is", "tf", ".", "identity", ":", "\n", "            ", "return", "size", "\n", "", "else", ":", "\n", "# To use layer's compute_output_shape, we need to convert the", "\n", "# RNNCell's output_size entries into shapes with an unknown", "\n", "# batch size.  We then pass this through the layer's", "\n", "# compute_output_shape and read off all but the first (batch)", "\n", "# dimensions to get the output size of the rnn with the layer", "\n", "# applied to the top.", "\n", "            ", "output_shape_with_unknown_batch", "=", "nest", ".", "map_structure", "(", "\n", "lambda", "s", ":", "tensor_shape", ".", "TensorShape", "(", "[", "None", "]", ")", ".", "concatenate", "(", "s", ")", ",", "\n", "size", ")", "\n", "# layer_output_shape = self._output_layer.compute_output_shape(", "\n", "#     output_shape_with_unknown_batch)", "\n", "layer_output_shape", "=", "compute_output_shape", "(", "self", ".", "_output_layer", ".", "units", ",", "output_shape_with_unknown_batch", ")", "\n", "return", "nest", ".", "map_structure", "(", "lambda", "s", ":", "s", "[", "1", ":", "]", ",", "layer_output_shape", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.decoders.rnn_decoder_base.RNNDecoderBase.batch_size": [[374, 377], ["None"], "methods", ["None"], ["", "", "@", "property", "\n", "def", "batch_size", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_helper", ".", "batch_size", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.decoders.rnn_decoder_base.RNNDecoderBase.output_size": [[378, 383], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "output_size", "(", "self", ")", ":", "\n", "        ", "\"\"\"Output size of one step.\n        \"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.decoders.rnn_decoder_base.RNNDecoderBase.output_dtype": [[384, 389], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "output_dtype", "(", "self", ")", ":", "\n", "        ", "\"\"\"Types of output of one step.\n        \"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.decoders.rnn_decoder_base.RNNDecoderBase.initialize": [[390, 394], ["None"], "methods", ["None"], ["", "def", "initialize", "(", "self", ",", "name", "=", "None", ")", ":", "\n", "# Inherits from TFDecoder", "\n", "# All RNN decoder classes must implement this", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.decoders.rnn_decoder_base.RNNDecoderBase.step": [[395, 399], ["None"], "methods", ["None"], ["", "def", "step", "(", "self", ",", "time", ",", "inputs", ",", "state", ",", "name", "=", "None", ")", ":", "\n", "# Inherits from TFDecoder", "\n", "# All RNN decoder classes must implement this", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.decoders.rnn_decoder_base.RNNDecoderBase.finalize": [[400, 404], ["None"], "methods", ["None"], ["", "def", "finalize", "(", "self", ",", "outputs", ",", "final_state", ",", "sequence_lengths", ")", ":", "\n", "# Inherits from TFDecoder", "\n", "# All RNN decoder classes must implement this", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.decoders.rnn_decoder_base.RNNDecoderBase.cell": [[405, 410], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "cell", "(", "self", ")", ":", "\n", "        ", "\"\"\"The RNN cell.\n        \"\"\"", "\n", "return", "self", ".", "_cell", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.decoders.rnn_decoder_base.RNNDecoderBase.zero_state": [[411, 418], ["rnn_decoder_base.RNNDecoderBase._cell.zero_state"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.decoders.rnn_decoder_base.RNNDecoderBase.zero_state"], ["", "def", "zero_state", "(", "self", ",", "batch_size", ",", "dtype", ")", ":", "\n", "        ", "\"\"\"Zero state of the rnn cell.\n\n        Same as :attr:`decoder.cell.zero_state`.\n        \"\"\"", "\n", "return", "self", ".", "_cell", ".", "zero_state", "(", "\n", "batch_size", "=", "batch_size", ",", "dtype", "=", "dtype", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.decoders.rnn_decoder_base.RNNDecoderBase.state_size": [[419, 426], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "state_size", "(", "self", ")", ":", "\n", "        ", "\"\"\"The state size of decoder cell.\n\n        Same as :attr:`decoder.cell.state_size`.\n        \"\"\"", "\n", "return", "self", ".", "cell", ".", "state_size", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.decoders.rnn_decoder_base.RNNDecoderBase.vocab_size": [[427, 432], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "vocab_size", "(", "self", ")", ":", "\n", "        ", "\"\"\"The vocab size.\n        \"\"\"", "\n", "return", "self", ".", "_vocab_size", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.decoders.rnn_decoder_base.RNNDecoderBase.output_layer": [[433, 438], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "output_layer", "(", "self", ")", ":", "\n", "        ", "\"\"\"The output layer.\n        \"\"\"", "\n", "return", "self", ".", "_output_layer", "\n", "", "", ""]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.decoders.rnn_decoder_base.compute_output_shape": [[33, 44], ["tensorflow.python.framework.tensor_shape.TensorShape", "input_shape.with_rank_at_least.with_rank_at_least", "input_shape[].concatenate", "ValueError"], "function", ["None"], ["def", "compute_output_shape", "(", "units", ",", "input_shape", ")", ":", "\n", "    ", "\"\"\"\n    added to fit into tf1.4\n    \"\"\"", "\n", "input_shape", "=", "tensor_shape", ".", "TensorShape", "(", "input_shape", ")", "\n", "input_shape", "=", "input_shape", ".", "with_rank_at_least", "(", "2", ")", "\n", "if", "input_shape", "[", "-", "1", "]", ".", "value", "is", "None", ":", "\n", "        ", "raise", "ValueError", "(", "\n", "'The innermost dimension of input_shape must be defined, but saw: %s'", "\n", "%", "input_shape", ")", "\n", "", "return", "input_shape", "[", ":", "-", "1", "]", ".", "concatenate", "(", "units", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.decoders.rnn_decoders_test.BasicRNNDecoderTest.setUp": [[28, 39], ["tensorflow.test.TestCase.setUp", "tensorflow.random_uniform", "tensorflow.random_uniform"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.losses.mle_losses_test.MLELossesTest.setUp"], ["def", "setUp", "(", "self", ")", ":", "\n", "        ", "tf", ".", "test", ".", "TestCase", ".", "setUp", "(", "self", ")", "\n", "self", ".", "_vocab_size", "=", "4", "\n", "self", ".", "_max_time", "=", "8", "\n", "self", ".", "_batch_size", "=", "16", "\n", "self", ".", "_emb_dim", "=", "20", "\n", "self", ".", "_inputs", "=", "tf", ".", "random_uniform", "(", "\n", "[", "self", ".", "_batch_size", ",", "self", ".", "_max_time", ",", "self", ".", "_emb_dim", "]", ",", "\n", "maxval", "=", "1.", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "self", ".", "_embedding", "=", "tf", ".", "random_uniform", "(", "\n", "[", "self", ".", "_vocab_size", ",", "self", ".", "_emb_dim", "]", ",", "maxval", "=", "1.", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.decoders.rnn_decoders_test.BasicRNNDecoderTest._test_outputs": [[40, 65], ["rnn_decoders_test.BasicRNNDecoderTest.assertEqual", "len", "rnn_decoders_test.BasicRNNDecoderTest.test_session", "sess.run", "sess.run", "rnn_decoders_test.BasicRNNDecoderTest.assertIsInstance", "rnn_decoders_test.BasicRNNDecoderTest.assertEqual", "tensorflow.global_variables_initializer", "rnn_decoders_test.BasicRNNDecoderTest.assertEqual", "rnn_decoders_test.BasicRNNDecoderTest.assertEqual", "numpy.testing.assert_array_equal", "texar.context.global_mode"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.texar.context.global_mode"], ["", "def", "_test_outputs", "(", "self", ",", "decoder", ",", "outputs", ",", "final_state", ",", "sequence_lengths", ",", "\n", "test_mode", "=", "False", ")", ":", "\n", "# 4 trainable variables: cell-kernel, cell-bias,", "\n", "# fc-layer-weights, fc-layer-bias", "\n", "        ", "self", ".", "assertEqual", "(", "len", "(", "decoder", ".", "trainable_variables", ")", ",", "4", ")", "\n", "\n", "cell_dim", "=", "decoder", ".", "hparams", ".", "rnn_cell", ".", "kwargs", ".", "num_units", "\n", "with", "self", ".", "test_session", "(", ")", "as", "sess", ":", "\n", "            ", "sess", ".", "run", "(", "tf", ".", "global_variables_initializer", "(", ")", ")", "\n", "\n", "outputs_", ",", "final_state_", ",", "sequence_lengths_", "=", "sess", ".", "run", "(", "\n", "[", "outputs", ",", "final_state", ",", "sequence_lengths", "]", ",", "\n", "feed_dict", "=", "{", "context", ".", "global_mode", "(", ")", ":", "tf", ".", "estimator", ".", "ModeKeys", ".", "TRAIN", "}", ")", "\n", "self", ".", "assertIsInstance", "(", "outputs_", ",", "BasicRNNDecoderOutput", ")", "\n", "if", "not", "test_mode", ":", "\n", "                ", "self", ".", "assertEqual", "(", "\n", "outputs_", ".", "logits", ".", "shape", ",", "\n", "(", "self", ".", "_batch_size", ",", "self", ".", "_max_time", ",", "self", ".", "_vocab_size", ")", ")", "\n", "self", ".", "assertEqual", "(", "\n", "outputs_", ".", "sample_id", ".", "shape", ",", "\n", "(", "self", ".", "_batch_size", ",", "self", ".", "_max_time", ")", ")", "\n", "np", ".", "testing", ".", "assert_array_equal", "(", "\n", "sequence_lengths_", ",", "[", "self", ".", "_max_time", "]", "*", "self", ".", "_batch_size", ")", "\n", "", "self", ".", "assertEqual", "(", "final_state_", "[", "0", "]", ".", "shape", ",", "\n", "(", "self", ".", "_batch_size", ",", "cell_dim", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.decoders.rnn_decoders_test.BasicRNNDecoderTest.test_decode_train": [[66, 100], ["tensorflow.layers.Dense", "texar.modules.decoders.rnn_decoders.BasicRNNDecoder", "texar.modules.decoders.rnn_decoder_helpers.get_helper", "texar.modules.decoders.rnn_decoders.BasicRNNDecoder.", "rnn_decoders_test.BasicRNNDecoderTest._test_outputs", "texar.modules.decoders.rnn_decoders.BasicRNNDecoder.", "rnn_decoders_test.BasicRNNDecoderTest._test_outputs", "texar.modules.decoders.rnn_decoders.BasicRNNDecoder.", "rnn_decoders_test.BasicRNNDecoderTest._test_outputs", "texar.modules.decoders.rnn_decoders.BasicRNNDecoder.", "rnn_decoders_test.BasicRNNDecoderTest._test_outputs", "texar.modules.decoders.rnn_decoders.BasicRNNDecoder.hparams.helper_train.kwargs.todict"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.decoders.rnn_decoder_helpers.get_helper", "home.repos.pwc.inspect_result.VegB_Text_Infilling.decoders.rnn_decoders_test.BasicRNNDecoderTest._test_outputs", "home.repos.pwc.inspect_result.VegB_Text_Infilling.decoders.rnn_decoders_test.BasicRNNDecoderTest._test_outputs", "home.repos.pwc.inspect_result.VegB_Text_Infilling.decoders.rnn_decoders_test.BasicRNNDecoderTest._test_outputs", "home.repos.pwc.inspect_result.VegB_Text_Infilling.decoders.rnn_decoders_test.BasicRNNDecoderTest._test_outputs", "home.repos.pwc.inspect_result.VegB_Text_Infilling.texar.hyperparams.HParams.todict"], ["", "", "def", "test_decode_train", "(", "self", ")", ":", "\n", "        ", "\"\"\"Tests decoding in training mode.\n        \"\"\"", "\n", "output_layer", "=", "tf", ".", "layers", ".", "Dense", "(", "self", ".", "_vocab_size", ")", "\n", "decoder", "=", "BasicRNNDecoder", "(", "vocab_size", "=", "self", ".", "_vocab_size", ",", "\n", "output_layer", "=", "output_layer", ")", "\n", "\n", "helper_train", "=", "get_helper", "(", "\n", "decoder", ".", "hparams", ".", "helper_train", ".", "type", ",", "\n", "inputs", "=", "self", ".", "_inputs", ",", "\n", "sequence_length", "=", "[", "self", ".", "_max_time", "]", "*", "self", ".", "_batch_size", ",", "\n", "**", "decoder", ".", "hparams", ".", "helper_train", ".", "kwargs", ".", "todict", "(", ")", ")", "\n", "outputs", ",", "final_state", ",", "sequence_lengths", "=", "decoder", "(", "helper", "=", "helper_train", ")", "\n", "self", ".", "_test_outputs", "(", "decoder", ",", "outputs", ",", "final_state", ",", "sequence_lengths", ")", "\n", "\n", "outputs", ",", "final_state", ",", "sequence_lengths", "=", "decoder", "(", "\n", "inputs", "=", "self", ".", "_inputs", ",", "\n", "sequence_length", "=", "[", "self", ".", "_max_time", "]", "*", "self", ".", "_batch_size", ")", "\n", "self", ".", "_test_outputs", "(", "decoder", ",", "outputs", ",", "final_state", ",", "sequence_lengths", ")", "\n", "\n", "outputs", ",", "final_state", ",", "sequence_lengths", "=", "decoder", "(", "\n", "decoding_strategy", "=", "None", ",", "\n", "inputs", "=", "self", ".", "_inputs", ",", "\n", "sequence_length", "=", "[", "self", ".", "_max_time", "]", "*", "self", ".", "_batch_size", ")", "\n", "self", ".", "_test_outputs", "(", "decoder", ",", "outputs", ",", "final_state", ",", "sequence_lengths", ")", "\n", "\n", "outputs", ",", "final_state", ",", "sequence_lengths", "=", "decoder", "(", "\n", "decoding_strategy", "=", "None", ",", "\n", "embedding", "=", "self", ".", "_embedding", ",", "\n", "start_tokens", "=", "[", "1", "]", "*", "self", ".", "_batch_size", ",", "\n", "end_token", "=", "2", ",", "\n", "mode", "=", "tf", ".", "estimator", ".", "ModeKeys", ".", "EVAL", ")", "\n", "self", ".", "_test_outputs", "(", "decoder", ",", "outputs", ",", "final_state", ",", "sequence_lengths", ",", "\n", "test_mode", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.decoders.rnn_decoders_test.BasicRNNDecoderTest.test_decode_train_with_tf": [[101, 165], ["tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.nn.embedding_lookup", "tensorflow.layers.Dense", "texar.modules.decoders.rnn_decoders.BasicRNNDecoder", "texar.modules.decoders.rnn_decoder_helpers.get_helper", "texar.modules.decoders.rnn_decoders.BasicRNNDecoder.", "tensorflow.contrib.seq2seq.TrainingHelper", "tensorflow.contrib.seq2seq.BasicDecoder", "tensorflow.contrib.seq2seq.dynamic_decode", "texar.modules.decoders.rnn_decoders.BasicRNNDecoder.cell.zero_state", "rnn_decoders_test.BasicRNNDecoderTest.test_session", "sess.run", "numpy.random.randint", "numpy.random.randn", "sess.run", "rnn_decoders_test.BasicRNNDecoderTest.assertEqual", "sess.run", "numpy.testing.assert_array_equal", "numpy.testing.assert_array_equal", "numpy.testing.assert_array_equal", "numpy.testing.assert_array_equal", "numpy.testing.assert_array_equal", "texar.modules.decoders.rnn_decoders.BasicRNNDecoder.hparams.helper_train.kwargs.todict", "tensorflow.global_variables_initializer", "texar.context.global_mode", "texar.context.global_mode"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.decoders.rnn_decoder_helpers.get_helper", "home.repos.pwc.inspect_result.VegB_Text_Infilling.decoders.template_transformer_decoder.TemplateTransformerDecoder.dynamic_decode", "home.repos.pwc.inspect_result.VegB_Text_Infilling.decoders.rnn_decoder_base.RNNDecoderBase.zero_state", "home.repos.pwc.inspect_result.VegB_Text_Infilling.texar.hyperparams.HParams.todict", "home.repos.pwc.inspect_result.VegB_Text_Infilling.texar.context.global_mode", "home.repos.pwc.inspect_result.VegB_Text_Infilling.texar.context.global_mode"], ["", "def", "test_decode_train_with_tf", "(", "self", ")", ":", "\n", "        ", "\"\"\"Compares decoding results with TF built-in decoder.\n        \"\"\"", "\n", "_inputs_placeholder", "=", "tf", ".", "placeholder", "(", "\n", "tf", ".", "int32", ",", "[", "self", ".", "_batch_size", ",", "self", ".", "_max_time", "]", ",", "name", "=", "\"inputs\"", ")", "\n", "_embedding_placeholder", "=", "tf", ".", "placeholder", "(", "\n", "tf", ".", "float32", ",", "[", "self", ".", "_vocab_size", ",", "self", ".", "_emb_dim", "]", ",", "name", "=", "\"emb\"", ")", "\n", "inputs", "=", "tf", ".", "nn", ".", "embedding_lookup", "(", "_embedding_placeholder", ",", "\n", "_inputs_placeholder", ")", "\n", "\n", "output_layer", "=", "tf", ".", "layers", ".", "Dense", "(", "self", ".", "_vocab_size", ")", "\n", "decoder", "=", "BasicRNNDecoder", "(", "vocab_size", "=", "self", ".", "_vocab_size", ",", "\n", "output_layer", "=", "output_layer", ")", "\n", "\n", "helper_train", "=", "get_helper", "(", "\n", "decoder", ".", "hparams", ".", "helper_train", ".", "type", ",", "\n", "inputs", "=", "inputs", ",", "\n", "sequence_length", "=", "[", "self", ".", "_max_time", "]", "*", "self", ".", "_batch_size", ",", "\n", "**", "decoder", ".", "hparams", ".", "helper_train", ".", "kwargs", ".", "todict", "(", ")", ")", "\n", "\n", "outputs", ",", "final_state", ",", "sequence_lengths", "=", "decoder", "(", "helper", "=", "helper_train", ")", "\n", "\n", "tf_helper", "=", "tf", ".", "contrib", ".", "seq2seq", ".", "TrainingHelper", "(", "\n", "inputs", ",", "[", "self", ".", "_max_time", "]", "*", "self", ".", "_batch_size", ")", "\n", "\n", "tf_decoder", "=", "tf", ".", "contrib", ".", "seq2seq", ".", "BasicDecoder", "(", "\n", "decoder", ".", "cell", ",", "\n", "tf_helper", ",", "\n", "decoder", ".", "cell", ".", "zero_state", "(", "self", ".", "_batch_size", ",", "tf", ".", "float32", ")", ",", "\n", "output_layer", "=", "output_layer", ")", "\n", "\n", "tf_outputs", ",", "tf_final_state", ",", "tf_sequence_lengths", "=", "tf", ".", "contrib", ".", "seq2seq", ".", "dynamic_decode", "(", "tf_decoder", ")", "\n", "\n", "cell_dim", "=", "decoder", ".", "hparams", ".", "rnn_cell", ".", "kwargs", ".", "num_units", "\n", "with", "self", ".", "test_session", "(", ")", "as", "sess", ":", "\n", "            ", "sess", ".", "run", "(", "tf", ".", "global_variables_initializer", "(", ")", ")", "\n", "inputs_", "=", "np", ".", "random", ".", "randint", "(", "\n", "self", ".", "_vocab_size", ",", "size", "=", "(", "self", ".", "_batch_size", ",", "self", ".", "_max_time", ")", ",", "\n", "dtype", "=", "np", ".", "int32", ")", "\n", "embedding_", "=", "np", ".", "random", ".", "randn", "(", "self", ".", "_vocab_size", ",", "self", ".", "_emb_dim", ")", "\n", "\n", "outputs_", ",", "final_state_", ",", "sequence_lengths_", "=", "sess", ".", "run", "(", "\n", "[", "outputs", ",", "final_state", ",", "sequence_lengths", "]", ",", "\n", "feed_dict", "=", "{", "context", ".", "global_mode", "(", ")", ":", "tf", ".", "estimator", ".", "ModeKeys", ".", "TRAIN", ",", "\n", "_inputs_placeholder", ":", "inputs_", ",", "\n", "_embedding_placeholder", ":", "embedding_", "}", ")", "\n", "self", ".", "assertEqual", "(", "final_state_", "[", "0", "]", ".", "shape", ",", "\n", "(", "self", ".", "_batch_size", ",", "cell_dim", ")", ")", "\n", "\n", "tf_outputs_", ",", "tf_final_state_", ",", "tf_sequence_lengths_", "=", "sess", ".", "run", "(", "\n", "[", "tf_outputs", ",", "tf_final_state", ",", "tf_sequence_lengths", "]", ",", "\n", "feed_dict", "=", "{", "context", ".", "global_mode", "(", ")", ":", "tf", ".", "estimator", ".", "ModeKeys", ".", "TRAIN", ",", "\n", "_inputs_placeholder", ":", "inputs_", ",", "\n", "_embedding_placeholder", ":", "embedding_", "}", ")", "\n", "\n", "np", ".", "testing", ".", "assert_array_equal", "(", "outputs_", ".", "logits", ",", "\n", "tf_outputs_", ".", "rnn_output", ")", "\n", "np", ".", "testing", ".", "assert_array_equal", "(", "outputs_", ".", "sample_id", ",", "\n", "tf_outputs_", ".", "sample_id", ")", "\n", "np", ".", "testing", ".", "assert_array_equal", "(", "final_state_", ".", "c", ",", "tf_final_state_", ".", "c", ")", "\n", "np", ".", "testing", ".", "assert_array_equal", "(", "final_state_", ".", "h", ",", "tf_final_state_", ".", "h", ")", "\n", "np", ".", "testing", ".", "assert_array_equal", "(", "sequence_lengths_", ",", "\n", "tf_sequence_lengths_", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.decoders.rnn_decoders_test.BasicRNNDecoderTest.test_decode_infer": [[166, 202], ["tensorflow.layers.Dense", "texar.modules.decoders.rnn_decoders.BasicRNNDecoder", "texar.modules.decoders.rnn_decoder_helpers.get_helper", "texar.modules.decoders.rnn_decoders.BasicRNNDecoder.", "rnn_decoders_test.BasicRNNDecoderTest.assertEqual", "len", "rnn_decoders_test.BasicRNNDecoderTest.test_session", "sess.run", "sess.run", "rnn_decoders_test.BasicRNNDecoderTest.assertIsInstance", "max", "rnn_decoders_test.BasicRNNDecoderTest.assertEqual", "rnn_decoders_test.BasicRNNDecoderTest.assertEqual", "rnn_decoders_test.BasicRNNDecoderTest.assertEqual", "texar.modules.decoders.rnn_decoders.BasicRNNDecoder.hparams.helper_train.kwargs.todict", "tensorflow.global_variables_initializer", "texar.context.global_mode"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.decoders.rnn_decoder_helpers.get_helper", "home.repos.pwc.inspect_result.VegB_Text_Infilling.texar.hyperparams.HParams.todict", "home.repos.pwc.inspect_result.VegB_Text_Infilling.texar.context.global_mode"], ["", "", "def", "test_decode_infer", "(", "self", ")", ":", "\n", "        ", "\"\"\"Tests decoding in inferencee mode.\n        \"\"\"", "\n", "output_layer", "=", "tf", ".", "layers", ".", "Dense", "(", "self", ".", "_vocab_size", ")", "\n", "decoder", "=", "BasicRNNDecoder", "(", "vocab_size", "=", "self", ".", "_vocab_size", ",", "\n", "output_layer", "=", "output_layer", ")", "\n", "\n", "helper_infer", "=", "get_helper", "(", "\n", "decoder", ".", "hparams", ".", "helper_infer", ".", "type", ",", "\n", "embedding", "=", "self", ".", "_embedding", ",", "\n", "start_tokens", "=", "[", "self", ".", "_vocab_size", "-", "2", "]", "*", "self", ".", "_batch_size", ",", "\n", "end_token", "=", "self", ".", "_vocab_size", "-", "1", ",", "\n", "**", "decoder", ".", "hparams", ".", "helper_train", ".", "kwargs", ".", "todict", "(", ")", ")", "\n", "\n", "outputs", ",", "final_state", ",", "sequence_lengths", "=", "decoder", "(", "helper", "=", "helper_infer", ")", "\n", "\n", "# 4 trainable variables: embedding, cell-kernel, cell-bias,", "\n", "# fc-layer-weights, fc-layer-bias", "\n", "self", ".", "assertEqual", "(", "len", "(", "decoder", ".", "trainable_variables", ")", ",", "4", ")", "\n", "\n", "cell_dim", "=", "decoder", ".", "hparams", ".", "rnn_cell", ".", "kwargs", ".", "num_units", "\n", "with", "self", ".", "test_session", "(", ")", "as", "sess", ":", "\n", "            ", "sess", ".", "run", "(", "tf", ".", "global_variables_initializer", "(", ")", ")", "\n", "outputs_", ",", "final_state_", ",", "sequence_lengths_", "=", "sess", ".", "run", "(", "\n", "[", "outputs", ",", "final_state", ",", "sequence_lengths", "]", ",", "\n", "feed_dict", "=", "{", "context", ".", "global_mode", "(", ")", ":", "\n", "tf", ".", "estimator", ".", "ModeKeys", ".", "PREDICT", "}", ")", "\n", "self", ".", "assertIsInstance", "(", "outputs_", ",", "BasicRNNDecoderOutput", ")", "\n", "max_length", "=", "max", "(", "sequence_lengths_", ")", "\n", "self", ".", "assertEqual", "(", "\n", "outputs_", ".", "logits", ".", "shape", ",", "\n", "(", "self", ".", "_batch_size", ",", "max_length", ",", "self", ".", "_vocab_size", ")", ")", "\n", "self", ".", "assertEqual", "(", "\n", "outputs_", ".", "sample_id", ".", "shape", ",", "(", "self", ".", "_batch_size", ",", "max_length", ")", ")", "\n", "self", ".", "assertEqual", "(", "final_state_", "[", "0", "]", ".", "shape", ",", "\n", "(", "self", ".", "_batch_size", ",", "cell_dim", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.decoders.rnn_decoders_test.AttentionRNNDecoderTest.setUp": [[208, 222], ["tensorflow.test.TestCase.setUp", "tensorflow.random_uniform", "tensorflow.random_uniform", "tensorflow.random_uniform"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.losses.mle_losses_test.MLELossesTest.setUp"], ["def", "setUp", "(", "self", ")", ":", "\n", "        ", "tf", ".", "test", ".", "TestCase", ".", "setUp", "(", "self", ")", "\n", "self", ".", "_vocab_size", "=", "10", "\n", "self", ".", "_max_time", "=", "16", "\n", "self", ".", "_batch_size", "=", "8", "\n", "self", ".", "_emb_dim", "=", "20", "\n", "self", ".", "_attention_dim", "=", "256", "\n", "self", ".", "_inputs", "=", "tf", ".", "random_uniform", "(", "\n", "[", "self", ".", "_batch_size", ",", "self", ".", "_max_time", ",", "self", ".", "_emb_dim", "]", ",", "\n", "maxval", "=", "1.", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "self", ".", "_embedding", "=", "tf", ".", "random_uniform", "(", "\n", "[", "self", ".", "_vocab_size", ",", "self", ".", "_emb_dim", "]", ",", "maxval", "=", "1.", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "self", ".", "_encoder_output", "=", "tf", ".", "random_uniform", "(", "\n", "[", "self", ".", "_batch_size", ",", "self", ".", "_max_time", ",", "64", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.decoders.rnn_decoders_test.AttentionRNNDecoderTest.test_decode_train": [[223, 272], ["tensorflow.constant", "texar.modules.decoders.rnn_decoders.AttentionRNNDecoder", "texar.modules.decoders.rnn_decoder_helpers.get_helper", "texar.modules.decoders.rnn_decoders.AttentionRNNDecoder.", "rnn_decoders_test.AttentionRNNDecoderTest.assertEqual", "numpy.random.randint", "len", "rnn_decoders_test.AttentionRNNDecoderTest.test_session", "sess.run", "sess.run", "rnn_decoders_test.AttentionRNNDecoderTest.assertIsInstance", "rnn_decoders_test.AttentionRNNDecoderTest.assertEqual", "rnn_decoders_test.AttentionRNNDecoderTest.assertEqual", "rnn_decoders_test.AttentionRNNDecoderTest.assertEqual", "numpy.testing.assert_array_equal", "texar.modules.decoders.rnn_decoders.AttentionRNNDecoder.hparams.helper_train.kwargs.todict", "tensorflow.global_variables_initializer", "texar.context.global_mode"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.decoders.rnn_decoder_helpers.get_helper", "home.repos.pwc.inspect_result.VegB_Text_Infilling.texar.hyperparams.HParams.todict", "home.repos.pwc.inspect_result.VegB_Text_Infilling.texar.context.global_mode"], ["", "def", "test_decode_train", "(", "self", ")", ":", "\n", "        ", "\"\"\"Tests decoding in training mode.\n        \"\"\"", "\n", "seq_length", "=", "np", ".", "random", ".", "randint", "(", "\n", "self", ".", "_max_time", ",", "size", "=", "[", "self", ".", "_batch_size", "]", ")", "+", "1", "\n", "encoder_values_length", "=", "tf", ".", "constant", "(", "seq_length", ")", "\n", "hparams", "=", "{", "\n", "\"attention\"", ":", "{", "\n", "\"kwargs\"", ":", "{", "\n", "\"num_units\"", ":", "self", ".", "_attention_dim", ",", "\n", "\"probability_fn\"", ":", "\"sparsemax\"", "\n", "}", "\n", "}", "\n", "}", "\n", "decoder", "=", "AttentionRNNDecoder", "(", "\n", "memory", "=", "self", ".", "_encoder_output", ",", "\n", "memory_sequence_length", "=", "encoder_values_length", ",", "\n", "vocab_size", "=", "self", ".", "_vocab_size", ",", "\n", "hparams", "=", "hparams", ")", "\n", "\n", "helper_train", "=", "get_helper", "(", "\n", "decoder", ".", "hparams", ".", "helper_train", ".", "type", ",", "\n", "inputs", "=", "self", ".", "_inputs", ",", "\n", "sequence_length", "=", "[", "self", ".", "_max_time", "]", "*", "self", ".", "_batch_size", ",", "\n", "**", "decoder", ".", "hparams", ".", "helper_train", ".", "kwargs", ".", "todict", "(", ")", ")", "\n", "\n", "outputs", ",", "final_state", ",", "sequence_lengths", "=", "decoder", "(", "helper", "=", "helper_train", ")", "\n", "# 4+1 trainable variables: cell-kernel, cell-bias,", "\n", "# fc-weight, fc-bias, and", "\n", "# memory_layer: For LuongAttention, we only transform the memory layer;", "\n", "# thus num_units *must* match the expected query depth.", "\n", "self", ".", "assertEqual", "(", "len", "(", "decoder", ".", "trainable_variables", ")", ",", "5", ")", "\n", "\n", "cell_dim", "=", "decoder", ".", "hparams", ".", "rnn_cell", ".", "kwargs", ".", "num_units", "\n", "with", "self", ".", "test_session", "(", ")", "as", "sess", ":", "\n", "            ", "sess", ".", "run", "(", "tf", ".", "global_variables_initializer", "(", ")", ")", "\n", "outputs_", ",", "final_state_", ",", "sequence_lengths_", "=", "sess", ".", "run", "(", "\n", "[", "outputs", ",", "final_state", ",", "sequence_lengths", "]", ",", "\n", "feed_dict", "=", "{", "context", ".", "global_mode", "(", ")", ":", "tf", ".", "estimator", ".", "ModeKeys", ".", "TRAIN", "}", ")", "\n", "self", ".", "assertIsInstance", "(", "outputs_", ",", "AttentionRNNDecoderOutput", ")", "\n", "self", ".", "assertEqual", "(", "\n", "outputs_", ".", "logits", ".", "shape", ",", "\n", "(", "self", ".", "_batch_size", ",", "self", ".", "_max_time", ",", "self", ".", "_vocab_size", ")", ")", "\n", "self", ".", "assertEqual", "(", "\n", "outputs_", ".", "sample_id", ".", "shape", ",", "(", "self", ".", "_batch_size", ",", "self", ".", "_max_time", ")", ")", "\n", "self", ".", "assertEqual", "(", "final_state_", ".", "cell_state", "[", "0", "]", ".", "shape", ",", "\n", "(", "self", ".", "_batch_size", ",", "cell_dim", ")", ")", "\n", "np", ".", "testing", ".", "assert_array_equal", "(", "\n", "sequence_lengths_", ",", "[", "self", ".", "_max_time", "]", "*", "self", ".", "_batch_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.decoders.rnn_decoders_test.AttentionRNNDecoderTest.test_decode_infer": [[274, 323], ["tensorflow.constant", "texar.modules.decoders.rnn_decoders.AttentionRNNDecoder", "texar.modules.decoders.rnn_decoder_helpers.get_helper", "texar.modules.decoders.rnn_decoders.AttentionRNNDecoder.", "rnn_decoders_test.AttentionRNNDecoderTest.assertEqual", "numpy.random.randint", "len", "rnn_decoders_test.AttentionRNNDecoderTest.test_session", "sess.run", "sess.run", "rnn_decoders_test.AttentionRNNDecoderTest.assertIsInstance", "max", "rnn_decoders_test.AttentionRNNDecoderTest.assertEqual", "rnn_decoders_test.AttentionRNNDecoderTest.assertEqual", "rnn_decoders_test.AttentionRNNDecoderTest.assertEqual", "texar.modules.decoders.rnn_decoders.AttentionRNNDecoder.hparams.helper_train.kwargs.todict", "tensorflow.global_variables_initializer", "texar.context.global_mode"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.decoders.rnn_decoder_helpers.get_helper", "home.repos.pwc.inspect_result.VegB_Text_Infilling.texar.hyperparams.HParams.todict", "home.repos.pwc.inspect_result.VegB_Text_Infilling.texar.context.global_mode"], ["", "", "def", "test_decode_infer", "(", "self", ")", ":", "\n", "        ", "\"\"\"Tests decoding in inference mode.\n        \"\"\"", "\n", "seq_length", "=", "np", ".", "random", ".", "randint", "(", "\n", "self", ".", "_max_time", ",", "size", "=", "[", "self", ".", "_batch_size", "]", ")", "+", "1", "\n", "encoder_values_length", "=", "tf", ".", "constant", "(", "seq_length", ")", "\n", "hparams", "=", "{", "\n", "\"attention\"", ":", "{", "\n", "\"kwargs\"", ":", "{", "\n", "\"num_units\"", ":", "256", ",", "\n", "}", "\n", "}", "\n", "}", "\n", "decoder", "=", "AttentionRNNDecoder", "(", "\n", "vocab_size", "=", "self", ".", "_vocab_size", ",", "\n", "memory", "=", "self", ".", "_encoder_output", ",", "\n", "memory_sequence_length", "=", "encoder_values_length", ",", "\n", "hparams", "=", "hparams", ")", "\n", "\n", "helper_infer", "=", "get_helper", "(", "\n", "decoder", ".", "hparams", ".", "helper_infer", ".", "type", ",", "\n", "embedding", "=", "self", ".", "_embedding", ",", "\n", "start_tokens", "=", "[", "1", "]", "*", "self", ".", "_batch_size", ",", "\n", "end_token", "=", "2", ",", "\n", "**", "decoder", ".", "hparams", ".", "helper_train", ".", "kwargs", ".", "todict", "(", ")", ")", "\n", "\n", "outputs", ",", "final_state", ",", "sequence_lengths", "=", "decoder", "(", "helper", "=", "helper_infer", ")", "\n", "\n", "# 4+1 trainable variables: cell-kernel, cell-bias,", "\n", "# fc-weight, fc-bias, and", "\n", "# memory_layer: For LuongAttention, we only transform the memory layer;", "\n", "# thus num_units *must* match the expected query depth.", "\n", "self", ".", "assertEqual", "(", "len", "(", "decoder", ".", "trainable_variables", ")", ",", "5", ")", "\n", "cell_dim", "=", "decoder", ".", "hparams", ".", "rnn_cell", ".", "kwargs", ".", "num_units", "\n", "with", "self", ".", "test_session", "(", ")", "as", "sess", ":", "\n", "            ", "sess", ".", "run", "(", "tf", ".", "global_variables_initializer", "(", ")", ")", "\n", "outputs_", ",", "final_state_", ",", "sequence_lengths_", "=", "sess", ".", "run", "(", "\n", "[", "outputs", ",", "final_state", ",", "sequence_lengths", "]", ",", "\n", "feed_dict", "=", "{", "context", ".", "global_mode", "(", ")", ":", "\n", "tf", ".", "estimator", ".", "ModeKeys", ".", "PREDICT", "}", ")", "\n", "self", ".", "assertIsInstance", "(", "outputs_", ",", "AttentionRNNDecoderOutput", ")", "\n", "max_length", "=", "max", "(", "sequence_lengths_", ")", "\n", "self", ".", "assertEqual", "(", "\n", "outputs_", ".", "logits", ".", "shape", ",", "\n", "(", "self", ".", "_batch_size", ",", "max_length", ",", "self", ".", "_vocab_size", ")", ")", "\n", "self", ".", "assertEqual", "(", "\n", "outputs_", ".", "sample_id", ".", "shape", ",", "(", "self", ".", "_batch_size", ",", "max_length", ")", ")", "\n", "self", ".", "assertEqual", "(", "final_state_", ".", "cell_state", "[", "0", "]", ".", "shape", ",", "\n", "(", "self", ".", "_batch_size", ",", "cell_dim", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.decoders.rnn_decoders_test.AttentionRNNDecoderTest.test_beam_search_cell": [[324, 367], ["tensorflow.constant", "texar.modules.decoders.rnn_decoders.AttentionRNNDecoder", "texar.modules.decoders.rnn_decoder_helpers.get_helper", "texar.modules.decoders.rnn_decoders.AttentionRNNDecoder.", "rnn_decoders_test.AttentionRNNDecoderTest.assertEqual", "texar.modules.decoders.rnn_decoders.AttentionRNNDecoder._get_beam_search_cell", "tensorflow.random_uniform", "texar.modules.decoders.rnn_decoders.AttentionRNNDecoder._get_beam_search_cell.zero_state", "texar.modules.decoders.rnn_decoders.AttentionRNNDecoder._get_beam_search_cell.", "rnn_decoders_test.AttentionRNNDecoderTest.assertEqual", "numpy.random.randint", "len", "len", "texar.modules.decoders.rnn_decoders.AttentionRNNDecoder.hparams.helper_train.kwargs.todict"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.decoders.rnn_decoder_helpers.get_helper", "home.repos.pwc.inspect_result.VegB_Text_Infilling.decoders.rnn_decoder_base.RNNDecoderBase._get_beam_search_cell", "home.repos.pwc.inspect_result.VegB_Text_Infilling.decoders.rnn_decoder_base.RNNDecoderBase.zero_state", "home.repos.pwc.inspect_result.VegB_Text_Infilling.texar.hyperparams.HParams.todict"], ["", "", "def", "test_beam_search_cell", "(", "self", ")", ":", "\n", "        ", "\"\"\"Tests :meth:`texar.modules.AttentionRNNDecoder._get_beam_search_cell`\n        \"\"\"", "\n", "seq_length", "=", "np", ".", "random", ".", "randint", "(", "\n", "self", ".", "_max_time", ",", "size", "=", "[", "self", ".", "_batch_size", "]", ")", "+", "1", "\n", "encoder_values_length", "=", "tf", ".", "constant", "(", "seq_length", ")", "\n", "hparams", "=", "{", "\n", "\"attention\"", ":", "{", "\n", "\"kwargs\"", ":", "{", "\n", "\"num_units\"", ":", "self", ".", "_attention_dim", ",", "\n", "\"probability_fn\"", ":", "\"sparsemax\"", "\n", "}", "\n", "}", "\n", "}", "\n", "decoder", "=", "AttentionRNNDecoder", "(", "\n", "memory", "=", "self", ".", "_encoder_output", ",", "\n", "memory_sequence_length", "=", "encoder_values_length", ",", "\n", "vocab_size", "=", "self", ".", "_vocab_size", ",", "\n", "hparams", "=", "hparams", ")", "\n", "\n", "helper_train", "=", "get_helper", "(", "\n", "decoder", ".", "hparams", ".", "helper_train", ".", "type", ",", "\n", "inputs", "=", "self", ".", "_inputs", ",", "\n", "sequence_length", "=", "[", "self", ".", "_max_time", "]", "*", "self", ".", "_batch_size", ",", "\n", "**", "decoder", ".", "hparams", ".", "helper_train", ".", "kwargs", ".", "todict", "(", ")", ")", "\n", "\n", "_", ",", "_", ",", "_", "=", "decoder", "(", "helper", "=", "helper_train", ")", "\n", "\n", "## 4+1 trainable variables: cell-kernel, cell-bias,", "\n", "## fc-weight, fc-bias, and", "\n", "## memory_layer: For LuongAttention, we only transform the memory layer;", "\n", "## thus num_units *must* match the expected query depth.", "\n", "self", ".", "assertEqual", "(", "len", "(", "decoder", ".", "trainable_variables", ")", ",", "5", ")", "\n", "\n", "beam_width", "=", "3", "\n", "beam_cell", "=", "decoder", ".", "_get_beam_search_cell", "(", "beam_width", ")", "\n", "cell_input", "=", "tf", ".", "random_uniform", "(", "[", "self", ".", "_batch_size", "*", "beam_width", ",", "\n", "self", ".", "_emb_dim", "]", ")", "\n", "cell_state", "=", "beam_cell", ".", "zero_state", "(", "self", ".", "_batch_size", "*", "beam_width", ",", "\n", "tf", ".", "float32", ")", "\n", "_", "=", "beam_cell", "(", "cell_input", ",", "cell_state", ")", "\n", "# Test if beam_cell is sharing variables with decoder cell.", "\n", "self", ".", "assertEqual", "(", "len", "(", "beam_cell", ".", "trainable_variables", ")", ",", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.decoders.transformer_decoders.TransformerDecoder.__init__": [[35, 68], ["texar.module_base.ModuleBase.__init__", "transformer_decoders.TransformerDecoder.build_output_layer", "tensorflow.variable_scope", "isinstance", "tensorflow.get_variable_scope().set_initializer", "texar.modules.embedders.position_embedders.SinusoidsPositionEmbedder", "ValueError", "texar.modules.embedders.embedder_utils.get_embedding", "texar.utils.shapes.shape_list", "texar.core.layers.get_initializer", "texar.utils.shapes.shape_list", "tensorflow.concat", "transformer_decoders.TransformerDecoder._embedding.get_shape().as_list", "tensorflow.get_variable_scope", "tensorflow.zeros", "transformer_decoders.TransformerDecoder._embedding.get_shape"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.text_infilling.self_attn_hyperparams.Hyperparams.__init__", "home.repos.pwc.inspect_result.VegB_Text_Infilling.decoders.template_transformer_decoder.TemplateTransformerDecoder.build_output_layer", "home.repos.pwc.inspect_result.VegB_Text_Infilling.agents.agent_base.AgentBase.variable_scope", "home.repos.pwc.inspect_result.VegB_Text_Infilling.embedders.embedder_utils.get_embedding", "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.shapes.shape_list", "home.repos.pwc.inspect_result.VegB_Text_Infilling.core.layers.get_initializer", "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.shapes.shape_list"], ["def", "__init__", "(", "self", ",", "embedding", "=", "None", ",", "vocab_size", "=", "None", ",", "hparams", "=", "None", ")", ":", "\n", "        ", "ModuleBase", ".", "__init__", "(", "self", ",", "hparams", ")", "\n", "self", ".", "_vocab_size", "=", "vocab_size", "\n", "self", ".", "_embedding", "=", "None", "\n", "self", ".", "sampling_method", "=", "self", ".", "_hparams", ".", "sampling_method", "\n", "with", "tf", ".", "variable_scope", "(", "self", ".", "variable_scope", ")", ":", "\n", "            ", "if", "self", ".", "_hparams", ".", "initializer", ":", "\n", "                ", "tf", ".", "get_variable_scope", "(", ")", ".", "set_initializer", "(", "layers", ".", "get_initializer", "(", "self", ".", "_hparams", ".", "initializer", ")", ")", "\n", "", "if", "self", ".", "_hparams", ".", "position_embedder", ".", "name", "==", "'sinusoids'", ":", "\n", "                ", "self", ".", "position_embedder", "=", "position_embedders", ".", "SinusoidsPositionEmbedder", "(", "self", ".", "_hparams", ".", "position_embedder", ".", "hparams", ")", "\n", "\n", "", "", "if", "self", ".", "_hparams", ".", "use_embedding", ":", "\n", "            ", "if", "embedding", "is", "None", "and", "vocab_size", "is", "None", ":", "\n", "                ", "raise", "ValueError", "(", "\"\"\"If 'embedding' is not provided,\n                    'vocab_size' must be specified.\"\"\"", ")", "\n", "", "if", "isinstance", "(", "embedding", ",", "(", "tf", ".", "Tensor", ",", "tf", ".", "Variable", ")", ")", ":", "\n", "                ", "self", ".", "_embedding", "=", "embedding", "\n", "", "else", ":", "\n", "                ", "self", ".", "_embedding", "=", "embedder_utils", ".", "get_embedding", "(", "\n", "self", ".", "_hparams", ".", "embedding", ",", "embedding", ",", "vocab_size", ",", "\n", "variable_scope", "=", "self", ".", "variable_scope", ")", "\n", "self", ".", "_embed_dim", "=", "shape_list", "(", "self", ".", "_embedding", ")", "[", "-", "1", "]", "\n", "if", "self", ".", "_hparams", ".", "zero_pad", ":", "\n", "                    ", "self", ".", "_embedding", "=", "tf", ".", "concat", "(", "(", "tf", ".", "zeros", "(", "shape", "=", "[", "1", ",", "self", ".", "_embed_dim", "]", ")", ",", "self", ".", "_embedding", "[", "1", ":", ",", ":", "]", ")", ",", "0", ")", "\n", "", "", "if", "self", ".", "_vocab_size", "is", "None", ":", "\n", "                ", "self", ".", "_vocab_size", "=", "self", ".", "_embedding", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", "[", "0", "]", "\n", "", "", "self", ".", "output_layer", "=", "self", ".", "build_output_layer", "(", "shape_list", "(", "self", ".", "_embedding", ")", "[", "-", "1", "]", ")", "\n", "", "@", "staticmethod", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.decoders.transformer_decoders.TransformerDecoder.default_hparams": [[68, 98], ["None"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "default_hparams", "(", ")", ":", "\n", "        ", "\"\"\"default hyperrams for transformer deocder.\n            sampling_method: argmax or sample. To choose the function transforming the logits to the sampled id in the next position when inferencing.\n        \"\"\"", "\n", "return", "{", "\n", "'sampling_method'", ":", "'argmax'", ",", "\n", "'initializer'", ":", "None", ",", "\n", "'multiply_embedding_mode'", ":", "'sqrt_depth'", ",", "\n", "'position_embedder'", ":", "None", ",", "\n", "'share_embed_and_transform'", ":", "True", ",", "\n", "'transform_with_bias'", ":", "True", ",", "\n", "\"use_embedding\"", ":", "True", ",", "\n", "\"name\"", ":", "\"decoder\"", ",", "\n", "\"num_heads\"", ":", "8", ",", "\n", "\"num_blocks\"", ":", "6", ",", "\n", "\"zero_pad\"", ":", "False", ",", "\n", "\"bos_pad\"", ":", "False", ",", "\n", "\"max_seq_length\"", ":", "10", ",", "\n", "\"maximum_decode_length\"", ":", "10", ",", "\n", "\"beam_width\"", ":", "1", ",", "\n", "'alpha'", ":", "0", ",", "\n", "\"embedding_dropout\"", ":", "0.1", ",", "\n", "'attention_dropout'", ":", "0.1", ",", "\n", "'residual_dropout'", ":", "0.1", ",", "\n", "\"sinusoid\"", ":", "True", ",", "\n", "'poswise_feedforward'", ":", "None", ",", "\n", "'num_units'", ":", "512", ",", "\n", "'eos_idx'", ":", "2", ",", "\n", "'bos_idx'", ":", "1", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.decoders.transformer_decoders.TransformerDecoder.prepare_tokens_to_embeds": [[100, 104], ["tensorflow.nn.embedding_lookup"], "methods", ["None"], ["", "def", "prepare_tokens_to_embeds", "(", "self", ",", "tokens", ")", ":", "\n", "        ", "\"\"\" a callable function to transform tokens into embeddings.\"\"\"", "\n", "token_emb", "=", "tf", ".", "nn", ".", "embedding_lookup", "(", "self", ".", "_embedding", ",", "tokens", ")", "\n", "return", "token_emb", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.decoders.transformer_decoders.TransformerDecoder._symbols_to_logits_fn": [[105, 134], ["transformer_decoders.TransformerDecoder.position_embedder", "texar.utils.shapes.shape_list", "embedding_fn", "transformer_decoders.TransformerDecoder._self_attention_stack", "transformer_decoders.TransformerDecoder.output_layer", "tensorflow.squeeze", "transformer_decoders.TransformerDecoder._embedding.shape.as_list"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.shapes.shape_list", "home.repos.pwc.inspect_result.VegB_Text_Infilling.decoders.template_transformer_decoder.TemplateTransformerDecoder._self_attention_stack", "home.repos.pwc.inspect_result.VegB_Text_Infilling.encoders.rnn_encoders.UnidirectionalRNNEncoder.output_layer"], ["", "def", "_symbols_to_logits_fn", "(", "self", ",", "embedding_fn", ",", "max_length", ")", ":", "\n", "        ", "channels", "=", "shape_list", "(", "self", ".", "_embedding", ")", "[", "-", "1", "]", "\n", "timing_signal", "=", "self", ".", "position_embedder", "(", "max_length", ",", "channels", ")", "\n", "\n", "\"\"\" the function is normally called in dynamic decoding mode.\n                the ids should be `next_id` with the shape [batch_size, 1]\n            the returned logits is [batch_size, 1]\n        \"\"\"", "\n", "def", "_impl", "(", "ids", ",", "step", ",", "cache", ")", ":", "\n", "            ", "ids", "=", "ids", "[", ":", ",", "-", "1", ":", "]", "\n", "inputs", "=", "embedding_fn", "(", "ids", ")", "\n", "if", "self", ".", "_hparams", ".", "multiply_embedding_mode", "==", "'sqrt_depth'", ":", "\n", "                ", "inputs", "*=", "self", ".", "_embedding", ".", "shape", ".", "as_list", "(", ")", "[", "-", "1", "]", "**", "0.5", "\n", "", "else", ":", "\n", "                ", "assert", "NotImplementedError", "\n", "", "inputs", "+=", "timing_signal", "[", ":", ",", "step", ":", "step", "+", "1", "]", "\n", "\n", "outputs", "=", "self", ".", "_self_attention_stack", "(", "\n", "inputs", ",", "\n", "encoder_output", "=", "cache", "[", "'memory'", "]", ",", "\n", "cache", "=", "cache", ",", "\n", ")", "\n", "#outputs = outputs[:, -1:, :]", "\n", "logits", "=", "self", ".", "output_layer", "(", "outputs", ")", "\n", "logits", "=", "tf", ".", "squeeze", "(", "logits", ",", "axis", "=", "[", "1", "]", ")", "\n", "\n", "return", "logits", ",", "cache", "\n", "\n", "", "return", "_impl", "\n", "#pylint:disable=arguments-differ", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.decoders.transformer_decoders.TransformerDecoder._build": [[135, 175], ["texar.core.attentions.attention_bias_lower_triangle", "tensorflow.nn.embedding_lookup", "transformer_decoders.TransformerDecoder.position_embedder", "transformer_decoders.TransformerDecoder._self_attention_stack", "transformer_decoders.TransformerDecoder.output_layer", "tensorflow.to_int32", "texar.utils.shapes.shape_list", "texar.utils.shapes.shape_list", "tensorflow.argmax", "transformer_decoders.TransformerDecoder._add_internal_trainable_variables", "texar.utils.shapes.shape_list", "transformer_decoders.TransformerDecoder._embedding.shape.as_list"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.core.attentions.attention_bias_lower_triangle", "home.repos.pwc.inspect_result.VegB_Text_Infilling.decoders.template_transformer_decoder.TemplateTransformerDecoder._self_attention_stack", "home.repos.pwc.inspect_result.VegB_Text_Infilling.encoders.rnn_encoders.UnidirectionalRNNEncoder.output_layer", "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.shapes.shape_list", "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.shapes.shape_list", "home.repos.pwc.inspect_result.VegB_Text_Infilling.texar.module_base.ModuleBase._add_internal_trainable_variables", "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.shapes.shape_list"], ["", "def", "_build", "(", "self", ",", "decoder_input", ",", "encoder_output", ",", "encoder_decoder_attention_bias", ",", "mode", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n            this function is called on training generally.\n            Args:\n                targets: [bath_size, target_length], generally begins with [bos] token\n                encoder_output: [batch_size, source_length, channels]\n            outputs:\n                logits: [batch_size, target_length, vocab_size]\n                preds: [batch_size, target_length]\n        \"\"\"", "\n", "logits", "=", "None", "\n", "decoder_self_attention_bias", "=", "(", "\n", "attentions", ".", "attention_bias_lower_triangle", "(", "\n", "shape_list", "(", "decoder_input", ")", "[", "1", "]", ")", ")", "\n", "target_inputs", "=", "tf", ".", "nn", ".", "embedding_lookup", "(", "self", ".", "_embedding", ",", "decoder_input", ")", "\n", "if", "self", ".", "_hparams", ".", "multiply_embedding_mode", "==", "'sqrt_depth'", ":", "\n", "            ", "target_inputs", "=", "target_inputs", "*", "(", "self", ".", "_embedding", ".", "shape", ".", "as_list", "(", ")", "[", "-", "1", "]", "**", "0.5", ")", "\n", "", "lengths", "=", "shape_list", "(", "target_inputs", ")", "[", "1", "]", "\n", "channels", "=", "shape_list", "(", "target_inputs", ")", "[", "2", "]", "\n", "pos_embeds", "=", "self", ".", "position_embedder", "(", "lengths", ",", "channels", ")", "\n", "inputs", "=", "target_inputs", "+", "pos_embeds", "\n", "self", ".", "decoder_output", "=", "self", ".", "_self_attention_stack", "(", "\n", "inputs", ",", "\n", "encoder_output", ",", "\n", "decoder_self_attention_bias", "=", "decoder_self_attention_bias", ",", "\n", "encoder_decoder_attention_bias", "=", "encoder_decoder_attention_bias", ",", "\n", "cache", "=", "None", ",", "\n", "mode", "=", "None", ",", "\n", ")", "\n", "\n", "logits", "=", "self", ".", "output_layer", "(", "self", ".", "decoder_output", ")", "\n", "preds", "=", "tf", ".", "to_int32", "(", "tf", ".", "argmax", "(", "logits", ",", "axis", "=", "-", "1", ")", ")", "\n", "\n", "if", "not", "self", ".", "_built", ":", "\n", "            ", "self", ".", "_add_internal_trainable_variables", "(", ")", "\n", "self", ".", "_built", "=", "True", "\n", "\n", "", "return", "logits", ",", "preds", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.decoders.transformer_decoders.TransformerDecoder.dynamic_decode": [[176, 214], ["print", "print", "print", "tensorflow.variable_scope", "tensorflow.fill", "tensorflow.shape", "transformer_decoders.TransformerDecoder.greedy_decode", "transformer_decoders.TransformerDecoder.beam_decode"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.agents.agent_base.AgentBase.variable_scope", "home.repos.pwc.inspect_result.VegB_Text_Infilling.decoders.template_transformer_decoder.TemplateTransformerDecoder.greedy_decode", "home.repos.pwc.inspect_result.VegB_Text_Infilling.decoders.template_transformer_decoder.TemplateTransformerDecoder.beam_decode"], ["", "def", "dynamic_decode", "(", "self", ",", "encoder_output", ",", "encoder_decoder_attention_bias", ")", ":", "\n", "        ", "\"\"\"\n            this function is called on in test mode, without the target input.\n        \"\"\"", "\n", "print", "(", "'dynamic_decode()'", ")", "\n", "print", "(", "encoder_output", ".", "shape", ")", "\n", "print", "(", "encoder_decoder_attention_bias", ".", "shape", ")", "\n", "with", "tf", ".", "variable_scope", "(", "self", ".", "variable_scope", ",", "reuse", "=", "True", ")", ":", "\n", "            ", "batch_size", "=", "tf", ".", "shape", "(", "encoder_decoder_attention_bias", ")", "[", "0", "]", "\n", "beam_width", "=", "self", ".", "_hparams", ".", "beam_width", "\n", "maximum_decode_length", "=", "self", ".", "hparams", ".", "maximum_decode_length", "\n", "start_tokens", "=", "tf", ".", "fill", "(", "[", "batch_size", "]", ",", "1", ")", "\n", "if", "beam_width", "<=", "1", ":", "\n", "                ", "sampled_ids", ",", "log_probs", "=", "self", ".", "greedy_decode", "(", "\n", "self", ".", "prepare_tokens_to_embeds", ",", "\n", "start_tokens", ",", "\n", "self", ".", "_hparams", ".", "eos_idx", ",", "\n", "decode_length", "=", "maximum_decode_length", ",", "\n", "memory", "=", "encoder_output", ",", "\n", "encoder_decoder_attention_bias", "=", "encoder_decoder_attention_bias", "\n", ")", "\n", "", "else", ":", "\n", "                ", "sampled_ids", ",", "log_probs", "=", "self", ".", "beam_decode", "(", "\n", "self", ".", "prepare_tokens_to_embeds", ",", "\n", "start_tokens", ",", "\n", "self", ".", "_hparams", ".", "eos_idx", ",", "\n", "beam_width", "=", "beam_width", ",", "\n", "decode_length", "=", "maximum_decode_length", ",", "\n", "memory", "=", "encoder_output", ",", "\n", "encoder_decoder_attention_bias", "=", "encoder_decoder_attention_bias", ",", "\n", ")", "\n", "", "predictions", "=", "{", "\n", "'sampled_ids'", ":", "sampled_ids", ",", "\n", "'log_probs'", ":", "log_probs", "\n", "}", "\n", "", "return", "predictions", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.decoders.transformer_decoders.TransformerDecoder._self_attention_stack": [[215, 281], ["tensorflow.layers.dropout", "range", "texar.core.layers.layer_normalize", "utils.is_train_mode", "tensorflow.variable_scope", "texar.modules.networks.networks.FeedForwardNetwork", "tensorflow.variable_scope", "texar.core.attentions.multihead_attention", "tensorflow.variable_scope", "tensorflow.layers.dropout", "tensorflow.layers.dropout", "tensorflow.variable_scope", "texar.core.attentions.multihead_attention", "texar.modules.networks.networks.FeedForwardNetwork.", "texar.core.layers.layer_normalize", "tensorflow.layers.dropout", "texar.core.layers.layer_normalize", "utils.is_train_mode", "utils.is_train_mode", "texar.core.layers.layer_normalize", "utils.is_train_mode"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.core.layers.layer_normalize", "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.mode.is_train_mode", "home.repos.pwc.inspect_result.VegB_Text_Infilling.agents.agent_base.AgentBase.variable_scope", "home.repos.pwc.inspect_result.VegB_Text_Infilling.agents.agent_base.AgentBase.variable_scope", "home.repos.pwc.inspect_result.VegB_Text_Infilling.core.layers.multihead_attention", "home.repos.pwc.inspect_result.VegB_Text_Infilling.agents.agent_base.AgentBase.variable_scope", "home.repos.pwc.inspect_result.VegB_Text_Infilling.agents.agent_base.AgentBase.variable_scope", "home.repos.pwc.inspect_result.VegB_Text_Infilling.core.layers.multihead_attention", "home.repos.pwc.inspect_result.VegB_Text_Infilling.core.layers.layer_normalize", "home.repos.pwc.inspect_result.VegB_Text_Infilling.core.layers.layer_normalize", "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.mode.is_train_mode", "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.mode.is_train_mode", "home.repos.pwc.inspect_result.VegB_Text_Infilling.core.layers.layer_normalize", "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.mode.is_train_mode"], ["", "def", "_self_attention_stack", "(", "self", ",", "\n", "inputs", ",", "\n", "encoder_output", ",", "\n", "decoder_self_attention_bias", "=", "None", ",", "\n", "encoder_decoder_attention_bias", "=", "None", ",", "\n", "cache", "=", "None", ",", "\n", "mode", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n            stacked multihead attention module.\n        \"\"\"", "\n", "inputs", "=", "tf", ".", "layers", ".", "dropout", "(", "inputs", ",", "\n", "rate", "=", "self", ".", "_hparams", ".", "embedding_dropout", ",", "\n", "training", "=", "utils", ".", "is_train_mode", "(", "mode", ")", ")", "\n", "if", "cache", "is", "not", "None", ":", "\n", "            ", "encoder_decoder_attention_bias", "=", "cache", "[", "'encoder_decoder_attention_bias'", "]", "\n", "", "else", ":", "\n", "            ", "assert", "decoder_self_attention_bias", "is", "not", "None", "\n", "\n", "", "x", "=", "inputs", "\n", "for", "i", "in", "range", "(", "self", ".", "_hparams", ".", "num_blocks", ")", ":", "\n", "            ", "layer_name", "=", "'layer_{}'", ".", "format", "(", "i", ")", "\n", "layer_cache", "=", "cache", "[", "layer_name", "]", "if", "cache", "is", "not", "None", "else", "None", "\n", "with", "tf", ".", "variable_scope", "(", "layer_name", ")", ":", "\n", "                ", "with", "tf", ".", "variable_scope", "(", "\"self_attention\"", ")", ":", "\n", "                    ", "selfatt_output", "=", "attentions", ".", "multihead_attention", "(", "\n", "queries", "=", "layers", ".", "layer_normalize", "(", "x", ")", ",", "\n", "memory", "=", "None", ",", "\n", "memory_attention_bias", "=", "decoder_self_attention_bias", ",", "\n", "num_units", "=", "self", ".", "_hparams", ".", "num_units", ",", "\n", "num_heads", "=", "self", ".", "_hparams", ".", "num_heads", ",", "\n", "dropout_rate", "=", "self", ".", "_hparams", ".", "attention_dropout", ",", "\n", "cache", "=", "layer_cache", ",", "\n", "scope", "=", "\"multihead_attention\"", ",", "\n", ")", "\n", "x", "=", "x", "+", "tf", ".", "layers", ".", "dropout", "(", "\n", "selfatt_output", ",", "\n", "rate", "=", "self", ".", "_hparams", ".", "residual_dropout", ",", "\n", "training", "=", "utils", ".", "is_train_mode", "(", "mode", ")", ",", "\n", ")", "\n", "", "if", "encoder_output", "is", "not", "None", ":", "\n", "                    ", "with", "tf", ".", "variable_scope", "(", "'encdec_attention'", ")", ":", "\n", "                        ", "encdec_output", "=", "attentions", ".", "multihead_attention", "(", "\n", "queries", "=", "layers", ".", "layer_normalize", "(", "x", ")", ",", "\n", "memory", "=", "encoder_output", ",", "\n", "memory_attention_bias", "=", "encoder_decoder_attention_bias", ",", "\n", "num_units", "=", "self", ".", "_hparams", ".", "num_units", ",", "\n", "num_heads", "=", "self", ".", "_hparams", ".", "num_heads", ",", "\n", "dropout_rate", "=", "self", ".", "_hparams", ".", "attention_dropout", ",", "\n", "scope", "=", "\"multihead_attention\"", "\n", ")", "\n", "x", "=", "x", "+", "tf", ".", "layers", ".", "dropout", "(", "encdec_output", ",", "rate", "=", "self", ".", "_hparams", ".", "residual_dropout", ",", "training", "=", "utils", ".", "is_train_mode", "(", "mode", ")", ",", "\n", ")", "\n", "", "", "poswise_network", "=", "FeedForwardNetwork", "(", "hparams", "=", "self", ".", "_hparams", "[", "'poswise_feedforward'", "]", ")", "\n", "with", "tf", ".", "variable_scope", "(", "poswise_network", ".", "variable_scope", ")", ":", "\n", "                    ", "sub_output", "=", "tf", ".", "layers", ".", "dropout", "(", "\n", "poswise_network", "(", "layers", ".", "layer_normalize", "(", "x", ")", ")", ",", "\n", "rate", "=", "self", ".", "_hparams", ".", "residual_dropout", ",", "\n", "training", "=", "utils", ".", "is_train_mode", "(", "mode", ")", ",", "\n", ")", "\n", "x", "=", "x", "+", "sub_output", "\n", "\n", "", "", "", "return", "layers", ".", "layer_normalize", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.decoders.transformer_decoders.TransformerDecoder.build_output_layer": [[282, 304], ["tensorflow.layers.Dense", "tensorflow.layers.Dense.build", "texar.utils.shapes.shape_list", "tensorflow.reshape", "tensorflow.matmul", "tensorflow.reshape", "tensorflow.variable_scope", "tensorflow.get_variable"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.core.layers.SequentialLayer.build", "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.shapes.shape_list", "home.repos.pwc.inspect_result.VegB_Text_Infilling.agents.agent_base.AgentBase.variable_scope"], ["", "def", "build_output_layer", "(", "self", ",", "num_units", ")", ":", "\n", "        ", "if", "self", ".", "_hparams", ".", "share_embed_and_transform", ":", "\n", "            ", "if", "self", ".", "_hparams", ".", "transform_with_bias", ":", "\n", "                ", "with", "tf", ".", "variable_scope", "(", "self", ".", "variable_scope", ")", ":", "\n", "                    ", "affine_bias", "=", "tf", ".", "get_variable", "(", "'affine_bias'", ",", "\n", "[", "self", ".", "_vocab_size", "]", ")", "\n", "", "", "else", ":", "\n", "                ", "affine_bias", "=", "None", "\n", "", "def", "outputs_to_logits", "(", "outputs", ")", ":", "\n", "                ", "shape", "=", "shape_list", "(", "outputs", ")", "\n", "outputs", "=", "tf", ".", "reshape", "(", "outputs", ",", "[", "-", "1", ",", "num_units", "]", ")", "\n", "logits", "=", "tf", ".", "matmul", "(", "outputs", ",", "self", ".", "_embedding", ",", "transpose_b", "=", "True", ")", "\n", "if", "affine_bias", "is", "not", "None", ":", "\n", "                    ", "logits", "+=", "affine_bias", "\n", "", "logits", "=", "tf", ".", "reshape", "(", "logits", ",", "shape", "[", ":", "-", "1", "]", "+", "[", "self", ".", "_vocab_size", "]", ")", "\n", "return", "logits", "\n", "", "return", "outputs_to_logits", "\n", "", "else", ":", "\n", "            ", "layer", "=", "tf", ".", "layers", ".", "Dense", "(", "self", ".", "_vocab_size", ",", "use_bias", "=", "self", ".", "_hparams", ".", "transform_with_bias", ")", "\n", "layer", ".", "build", "(", "[", "None", ",", "num_units", "]", ")", "\n", "return", "layer", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.decoders.transformer_decoders.TransformerDecoder.output_size": [[305, 315], ["transformer_decoders.TransformerDecoderOutput", "tensorflow.python.framework.tensor_shape.TensorShape", "tensorflow.python.framework.tensor_shape.TensorShape"], "methods", ["None"], ["", "", "@", "property", "\n", "def", "output_size", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        The output of the _build function, (logits, preds)\n        logits: [batch_size, length, vocab_size]\n        preds: [batch_size, length]\n        \"\"\"", "\n", "return", "TransformerDecoderOutput", "(", "\n", "output_logits", "=", "tensor_shape", ".", "TensorShape", "(", "[", "None", ",", "None", ",", "self", ".", "_vocab_size", "]", ")", ",", "\n", "sample_id", "=", "tensor_shape", ".", "TensorShape", "(", "[", "None", ",", "None", "]", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.decoders.transformer_decoders.TransformerDecoder.output_dtype": [[317, 323], ["transformer_decoders.TransformerDecoderOutput"], "methods", ["None"], ["", "def", "output_dtype", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        The output dtype of the _build function, (float32, int32)\n        \"\"\"", "\n", "return", "TransformerDecoderOutput", "(", "\n", "output_logits", "=", "dtypes", ".", "float32", ",", "sample_id", "=", "dtypes", ".", "int32", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.decoders.transformer_decoders.TransformerDecoder._init_cache": [[324, 339], ["range", "tensorflow.shape", "memory.get_shape().as_list", "tensorflow.zeros", "tensorflow.zeros", "tensorflow.zeros", "tensorflow.zeros", "memory.get_shape"], "methods", ["None"], ["", "def", "_init_cache", "(", "self", ",", "memory", ",", "encoder_decoder_attention_bias", ")", ":", "\n", "        ", "cache", "=", "{", "\n", "'memory'", ":", "memory", ",", "\n", "'encoder_decoder_attention_bias'", ":", "encoder_decoder_attention_bias", ",", "\n", "}", "\n", "batch_size", "=", "tf", ".", "shape", "(", "memory", ")", "[", "0", "]", "\n", "depth", "=", "memory", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", "[", "-", "1", "]", "\n", "for", "l", "in", "range", "(", "self", ".", "_hparams", ".", "num_blocks", ")", ":", "\n", "            ", "cache", "[", "'layer_{}'", ".", "format", "(", "l", ")", "]", "=", "{", "\n", "'self_keys'", ":", "tf", ".", "zeros", "(", "[", "batch_size", ",", "0", ",", "depth", "]", ")", ",", "\n", "'self_values'", ":", "tf", ".", "zeros", "(", "[", "batch_size", ",", "0", ",", "depth", "]", ")", ",", "\n", "'memory_keys'", ":", "tf", ".", "zeros", "(", "[", "batch_size", ",", "0", ",", "depth", "]", ")", ",", "\n", "'memory_values'", ":", "tf", ".", "zeros", "(", "[", "batch_size", ",", "0", ",", "depth", "]", ")", ",", "\n", "}", "\n", "", "return", "cache", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.decoders.transformer_decoders.TransformerDecoder.greedy_decode": [[340, 401], ["tensorflow.fill", "tensorflow.constant", "tensorflow.zeros", "tensorflow.expand_dims", "print", "tensorflow.zeros", "transformer_decoders.TransformerDecoder._init_cache", "transformer_decoders.TransformerDecoder._symbols_to_logits_fn", "tensorflow.while_loop", "tensorflow.expand_dims", "tensorflow.expand_dims", "tensorflow.shape", "transformer_decoders.TransformerDecoder.", "tensorflow.equal", "tensorflow.stack", "tensorflow.gather_nd", "tensorflow.expand_dims", "tensorflow.concat", "tensorflow.reduce_logsumexp", "tensorflow.argmax", "tensorflow.logical_not", "tensorflow.multinomial().squeeze", "tensorflow.range", "tensorflow.reduce_all", "tensorflow.TensorShape", "tensorflow.TensorShape", "tensorflow.TensorShape", "tensorflow.TensorShape", "tensorflow.python.util.nest.map_structure", "tensorflow.TensorShape", "tensorflow.to_int32", "tensorflow.multinomial"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.decoders.template_transformer_decoder.TemplateTransformerDecoder._init_cache", "home.repos.pwc.inspect_result.VegB_Text_Infilling.decoders.template_transformer_decoder.TemplateTransformerDecoder._symbols_to_logits_fn"], ["", "def", "greedy_decode", "(", "self", ",", "\n", "embedding_fn", ",", "\n", "start_tokens", ",", "\n", "EOS", ",", "\n", "decode_length", ",", "\n", "memory", ",", "\n", "encoder_decoder_attention_bias", ")", ":", "\n", "        ", "batch_size", "=", "tf", ".", "shape", "(", "start_tokens", ")", "[", "0", "]", "\n", "finished", "=", "tf", ".", "fill", "(", "[", "batch_size", "]", ",", "False", ")", "\n", "step", "=", "tf", ".", "constant", "(", "0", ")", "\n", "decoded_ids", "=", "tf", ".", "zeros", "(", "[", "batch_size", ",", "0", "]", ",", "dtype", "=", "tf", ".", "int32", ")", "\n", "next_id", "=", "tf", ".", "expand_dims", "(", "start_tokens", ",", "1", ")", "\n", "print", "(", "'next id:{}'", ".", "format", "(", "next_id", ".", "shape", ")", ")", "\n", "log_prob", "=", "tf", ".", "zeros", "(", "[", "batch_size", "]", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "\n", "cache", "=", "self", ".", "_init_cache", "(", "memory", ",", "encoder_decoder_attention_bias", ")", "\n", "symbols_to_logits_fn", "=", "self", ".", "_symbols_to_logits_fn", "(", "embedding_fn", ",", "\n", "max_length", "=", "decode_length", "+", "1", ")", "\n", "\n", "def", "_body", "(", "step", ",", "finished", ",", "next_id", ",", "decoded_ids", ",", "cache", ",", "log_prob", ")", ":", "\n", "\n", "            ", "logits", ",", "cache", "=", "symbols_to_logits_fn", "(", "next_id", ",", "step", ",", "cache", ")", "\n", "log_probs", "=", "logits", "-", "tf", ".", "reduce_logsumexp", "(", "logits", ",", "axis", "=", "-", "1", ",", "keep_dims", "=", "True", ")", "\n", "\n", "#TODO: by default, the output_type is tf.int64.", "\n", "# Can we adjust the default int type of texar to tf.int64?", "\n", "if", "self", ".", "sampling_method", "==", "'argmax'", ":", "\n", "                ", "next_id", "=", "tf", ".", "argmax", "(", "logits", ",", "-", "1", ",", "output_type", "=", "tf", ".", "int32", ")", "\n", "", "elif", "self", ".", "sampling_method", "==", "'sample'", ":", "\n", "                ", "next_id", "=", "tf", ".", "multinomial", "(", "logits", ",", "1", ")", ".", "squeeze", "(", "axis", "=", "1", ")", "\n", "", "finished", "|=", "tf", ".", "equal", "(", "next_id", ",", "EOS", ")", "\n", "log_prob_indices", "=", "tf", ".", "stack", "(", "\n", "[", "tf", ".", "range", "(", "tf", ".", "to_int32", "(", "batch_size", ")", ")", ",", "next_id", "]", ",", "axis", "=", "1", ")", "\n", "log_prob", "+=", "tf", ".", "gather_nd", "(", "log_probs", ",", "log_prob_indices", ")", "\n", "\n", "next_id", "=", "tf", ".", "expand_dims", "(", "next_id", ",", "axis", "=", "1", ")", "\n", "#keep the shape as [batch_size, seq_len]", "\n", "\n", "decoded_ids", "=", "tf", ".", "concat", "(", "[", "decoded_ids", ",", "next_id", "]", ",", "axis", "=", "1", ")", "\n", "return", "step", "+", "1", ",", "finished", ",", "next_id", ",", "decoded_ids", ",", "cache", ",", "log_prob", "\n", "\n", "", "def", "is_not_finished", "(", "i", ",", "finished", ",", "*", "_", ")", ":", "\n", "            ", "return", "(", "i", "<", "decode_length", ")", "&", "tf", ".", "logical_not", "(", "tf", ".", "reduce_all", "(", "finished", ")", ")", "\n", "\n", "", "_", ",", "_", ",", "_", ",", "decoded_ids", ",", "_", ",", "log_prob", "=", "tf", ".", "while_loop", "(", "\n", "is_not_finished", ",", "\n", "_body", ",", "\n", "loop_vars", "=", "(", "step", ",", "finished", ",", "next_id", ",", "decoded_ids", ",", "cache", ",", "log_prob", ")", ",", "\n", "shape_invariants", "=", "(", "\n", "tf", ".", "TensorShape", "(", "[", "]", ")", ",", "\n", "tf", ".", "TensorShape", "(", "[", "None", "]", ")", ",", "\n", "tf", ".", "TensorShape", "(", "[", "None", ",", "None", "]", ")", ",", "\n", "tf", ".", "TensorShape", "(", "[", "None", ",", "None", "]", ")", ",", "\n", "nest", ".", "map_structure", "(", "beam_search", ".", "get_state_shape_invariants", ",", "cache", ")", ",", "\n", "tf", ".", "TensorShape", "(", "[", "None", "]", ")", ",", "\n", ")", ")", "\n", "\n", "outputs", "=", "tf", ".", "expand_dims", "(", "decoded_ids", ",", "1", ")", "\n", "log_prob", "=", "tf", ".", "expand_dims", "(", "log_prob", ",", "1", ")", "\n", "return", "(", "outputs", ",", "log_prob", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.decoders.transformer_decoders.TransformerDecoder.beam_decode": [[402, 425], ["transformer_decoders.TransformerDecoder._init_cache", "transformer_decoders.TransformerDecoder._symbols_to_logits_fn", "texar.utils.beam_search.beam_search"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.decoders.template_transformer_decoder.TemplateTransformerDecoder._init_cache", "home.repos.pwc.inspect_result.VegB_Text_Infilling.decoders.template_transformer_decoder.TemplateTransformerDecoder._symbols_to_logits_fn", "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.beam_search.beam_search"], ["", "def", "beam_decode", "(", "self", ",", "\n", "embedding_fn", ",", "\n", "start_tokens", ",", "\n", "EOS", ",", "\n", "memory", ",", "\n", "encoder_decoder_attention_bias", ",", "\n", "decode_length", "=", "256", ",", "\n", "beam_width", "=", "5", ")", ":", "\n", "        ", "cache", "=", "self", ".", "_init_cache", "(", "memory", ",", "encoder_decoder_attention_bias", ")", "\n", "symbols_to_logits_fn", "=", "self", ".", "_symbols_to_logits_fn", "(", "embedding_fn", ",", "max_length", "=", "decode_length", "+", "1", ")", "\n", "outputs", ",", "log_probs", "=", "beam_search", ".", "beam_search", "(", "\n", "symbols_to_logits_fn", ",", "\n", "start_tokens", ",", "\n", "beam_width", ",", "\n", "decode_length", ",", "\n", "self", ".", "_vocab_size", ",", "\n", "self", ".", "_hparams", ".", "alpha", ",", "\n", "states", "=", "cache", ",", "\n", "eos_id", "=", "EOS", ")", "\n", "\n", "outputs", "=", "outputs", "[", ":", ",", ":", ",", "1", ":", "]", "# ignore <BOS>", "\n", "return", "(", "outputs", ",", "log_probs", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.decoders.template_transformer_decoder.TemplateTransformerDecoder.__init__": [[28, 61], ["texar.module_base.ModuleBase.__init__", "template_transformer_decoder.TemplateTransformerDecoder.build_output_layer", "tensorflow.variable_scope", "isinstance", "tensorflow.get_variable_scope().set_initializer", "texar.modules.embedders.position_embedders.SinusoidsSegmentalPositionEmbedder", "ValueError", "texar.modules.embedders.embedder_utils.get_embedding", "texar.utils.shapes.shape_list", "texar.core.layers.get_initializer", "texar.utils.shapes.shape_list", "tensorflow.concat", "template_transformer_decoder.TemplateTransformerDecoder._embedding.get_shape().as_list", "tensorflow.get_variable_scope", "tensorflow.zeros", "template_transformer_decoder.TemplateTransformerDecoder._embedding.get_shape"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.text_infilling.self_attn_hyperparams.Hyperparams.__init__", "home.repos.pwc.inspect_result.VegB_Text_Infilling.decoders.template_transformer_decoder.TemplateTransformerDecoder.build_output_layer", "home.repos.pwc.inspect_result.VegB_Text_Infilling.agents.agent_base.AgentBase.variable_scope", "home.repos.pwc.inspect_result.VegB_Text_Infilling.embedders.embedder_utils.get_embedding", "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.shapes.shape_list", "home.repos.pwc.inspect_result.VegB_Text_Infilling.core.layers.get_initializer", "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.shapes.shape_list"], ["def", "__init__", "(", "self", ",", "embedding", "=", "None", ",", "vocab_size", "=", "None", ",", "hparams", "=", "None", ")", ":", "\n", "        ", "ModuleBase", ".", "__init__", "(", "self", ",", "hparams", ")", "\n", "self", ".", "_vocab_size", "=", "vocab_size", "\n", "self", ".", "_embedding", "=", "None", "\n", "self", ".", "sampling_method", "=", "self", ".", "_hparams", ".", "sampling_method", "\n", "with", "tf", ".", "variable_scope", "(", "self", ".", "variable_scope", ")", ":", "\n", "            ", "if", "self", ".", "_hparams", ".", "initializer", ":", "\n", "                ", "tf", ".", "get_variable_scope", "(", ")", ".", "set_initializer", "(", "layers", ".", "get_initializer", "(", "self", ".", "_hparams", ".", "initializer", ")", ")", "\n", "", "if", "self", ".", "_hparams", ".", "position_embedder", ".", "name", "==", "'sinusoids'", ":", "\n", "                ", "self", ".", "position_embedder", "=", "position_embedders", ".", "SinusoidsSegmentalPositionEmbedder", "(", "self", ".", "_hparams", ".", "position_embedder", ".", "hparams", ")", "\n", "\n", "", "", "if", "self", ".", "_hparams", ".", "use_embedding", ":", "\n", "            ", "if", "embedding", "is", "None", "and", "vocab_size", "is", "None", ":", "\n", "                ", "raise", "ValueError", "(", "\"\"\"If 'embedding' is not provided,\n                    'vocab_size' must be specified.\"\"\"", ")", "\n", "", "if", "isinstance", "(", "embedding", ",", "(", "tf", ".", "Tensor", ",", "tf", ".", "Variable", ")", ")", ":", "\n", "                ", "self", ".", "_embedding", "=", "embedding", "\n", "", "else", ":", "\n", "                ", "self", ".", "_embedding", "=", "embedder_utils", ".", "get_embedding", "(", "\n", "self", ".", "_hparams", ".", "embedding", ",", "embedding", ",", "vocab_size", ",", "\n", "variable_scope", "=", "self", ".", "variable_scope", ")", "\n", "self", ".", "_embed_dim", "=", "shape_list", "(", "self", ".", "_embedding", ")", "[", "-", "1", "]", "\n", "if", "self", ".", "_hparams", ".", "zero_pad", ":", "\n", "                    ", "self", ".", "_embedding", "=", "tf", ".", "concat", "(", "(", "tf", ".", "zeros", "(", "shape", "=", "[", "1", ",", "self", ".", "_embed_dim", "]", ")", ",", "self", ".", "_embedding", "[", "1", ":", ",", ":", "]", ")", ",", "0", ")", "\n", "", "", "if", "self", ".", "_vocab_size", "is", "None", ":", "\n", "                ", "self", ".", "_vocab_size", "=", "self", ".", "_embedding", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", "[", "0", "]", "\n", "", "", "self", ".", "output_layer", "=", "self", ".", "build_output_layer", "(", "shape_list", "(", "self", ".", "_embedding", ")", "[", "-", "1", "]", ")", "\n", "", "@", "staticmethod", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.decoders.template_transformer_decoder.TemplateTransformerDecoder.default_hparams": [[61, 91], ["None"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "default_hparams", "(", ")", ":", "\n", "        ", "\"\"\"default hyperrams for transformer deocder.\n            sampling_method: argmax or sample. To choose the function transforming the logits to the sampled id in the next position when inferencing.\n        \"\"\"", "\n", "return", "{", "\n", "'sampling_method'", ":", "'argmax'", ",", "\n", "'initializer'", ":", "None", ",", "\n", "'multiply_embedding_mode'", ":", "'sqrt_depth'", ",", "\n", "'position_embedder'", ":", "None", ",", "\n", "'share_embed_and_transform'", ":", "True", ",", "\n", "'transform_with_bias'", ":", "True", ",", "\n", "\"use_embedding\"", ":", "True", ",", "\n", "\"name\"", ":", "\"decoder\"", ",", "\n", "\"num_heads\"", ":", "8", ",", "\n", "\"num_blocks\"", ":", "6", ",", "\n", "\"zero_pad\"", ":", "False", ",", "\n", "\"bos_pad\"", ":", "False", ",", "\n", "\"max_seq_length\"", ":", "10", ",", "\n", "\"maximum_decode_length\"", ":", "10", ",", "\n", "\"beam_width\"", ":", "1", ",", "\n", "'alpha'", ":", "0", ",", "\n", "\"embedding_dropout\"", ":", "0.1", ",", "\n", "'attention_dropout'", ":", "0.1", ",", "\n", "'residual_dropout'", ":", "0.1", ",", "\n", "\"sinusoid\"", ":", "True", ",", "\n", "'poswise_feedforward'", ":", "None", ",", "\n", "'num_units'", ":", "512", ",", "\n", "'eos_idx'", ":", "2", ",", "\n", "'bos_idx'", ":", "1", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.decoders.template_transformer_decoder.TemplateTransformerDecoder.prepare_tokens_to_embeds": [[93, 97], ["tensorflow.nn.embedding_lookup"], "methods", ["None"], ["", "def", "prepare_tokens_to_embeds", "(", "self", ",", "tokens", ")", ":", "\n", "        ", "\"\"\" a callable function to transform tokens into embeddings.\"\"\"", "\n", "token_emb", "=", "tf", ".", "nn", ".", "embedding_lookup", "(", "self", ".", "_embedding", ",", "tokens", ")", "\n", "return", "token_emb", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.decoders.template_transformer_decoder.TemplateTransformerDecoder._symbols_to_logits_fn": [[98, 130], ["template_transformer_decoder.TemplateTransformerDecoder.position_embedder", "texar.utils.shapes.shape_list", "texar.core.attentions.attention_bias_lower_triangle", "embedding_fn", "template_transformer_decoder.TemplateTransformerDecoder._self_attention_stack", "template_transformer_decoder.TemplateTransformerDecoder.output_layer", "tensorflow.squeeze", "texar.utils.shapes.shape_list", "template_transformer_decoder.TemplateTransformerDecoder._embedding.shape.as_list"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.shapes.shape_list", "home.repos.pwc.inspect_result.VegB_Text_Infilling.core.attentions.attention_bias_lower_triangle", "home.repos.pwc.inspect_result.VegB_Text_Infilling.decoders.template_transformer_decoder.TemplateTransformerDecoder._self_attention_stack", "home.repos.pwc.inspect_result.VegB_Text_Infilling.encoders.rnn_encoders.UnidirectionalRNNEncoder.output_layer", "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.shapes.shape_list"], ["", "def", "_symbols_to_logits_fn", "(", "self", ",", "embedding_fn", ",", "max_length", ",", "segment_ids", ",", "offsets", ")", ":", "\n", "        ", "channels", "=", "shape_list", "(", "self", ".", "_embedding", ")", "[", "-", "1", "]", "\n", "timing_signal", "=", "self", ".", "position_embedder", "(", "max_length", ",", "channels", ",", "segment_ids", ",", "offsets", ")", "\n", "\n", "\"\"\" the function is normally called in dynamic decoding mode.\n                the ids should be `next_id` with the shape [batch_size, 1]\n            the returned logits is [batch_size, 1]\n        \"\"\"", "\n", "def", "_impl", "(", "ids", ",", "step", ",", "cache", ")", ":", "\n", "            ", "ids", "=", "ids", "[", ":", ",", "-", "1", ":", "]", "\n", "decoder_self_attention_bias", "=", "(", "\n", "attentions", ".", "attention_bias_lower_triangle", "(", "\n", "shape_list", "(", "ids", ")", "[", "1", "]", ")", ")", "\n", "inputs", "=", "embedding_fn", "(", "ids", ")", "\n", "if", "self", ".", "_hparams", ".", "multiply_embedding_mode", "==", "'sqrt_depth'", ":", "\n", "                ", "inputs", "*=", "self", ".", "_embedding", ".", "shape", ".", "as_list", "(", ")", "[", "-", "1", "]", "**", "0.5", "\n", "", "else", ":", "\n", "                ", "assert", "NotImplementedError", "\n", "", "inputs", "+=", "timing_signal", "[", ":", ",", "step", ":", "step", "+", "1", "]", "\n", "\n", "outputs", "=", "self", ".", "_self_attention_stack", "(", "\n", "inputs", ",", "\n", "template_input", "=", "cache", "[", "'memory'", "]", ",", "\n", "cache", "=", "cache", ",", "\n", "decoder_self_attention_bias", "=", "decoder_self_attention_bias", ",", "\n", ")", "\n", "logits", "=", "self", ".", "output_layer", "(", "outputs", ")", "\n", "logits", "=", "tf", ".", "squeeze", "(", "logits", ",", "axis", "=", "[", "1", "]", ")", "\n", "\n", "return", "logits", ",", "cache", "\n", "\n", "", "return", "_impl", "\n", "#pylint:disable=arguments-differ", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.decoders.template_transformer_decoder.TemplateTransformerDecoder._build": [[131, 179], ["texar.core.attentions.attention_bias_lower_triangle", "tensorflow.nn.embedding_lookup", "template_transformer_decoder.TemplateTransformerDecoder.position_embedder", "tensorflow.nn.embedding_lookup", "template_transformer_decoder.TemplateTransformerDecoder.position_embedder", "template_transformer_decoder.TemplateTransformerDecoder._self_attention_stack", "template_transformer_decoder.TemplateTransformerDecoder.output_layer", "tensorflow.to_int32", "texar.utils.shapes.shape_list", "texar.utils.shapes.shape_list", "texar.utils.shapes.shape_list", "tensorflow.argmax", "template_transformer_decoder.TemplateTransformerDecoder._add_internal_trainable_variables", "texar.utils.shapes.shape_list", "template_transformer_decoder.TemplateTransformerDecoder._embedding.shape.as_list"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.core.attentions.attention_bias_lower_triangle", "home.repos.pwc.inspect_result.VegB_Text_Infilling.decoders.template_transformer_decoder.TemplateTransformerDecoder._self_attention_stack", "home.repos.pwc.inspect_result.VegB_Text_Infilling.encoders.rnn_encoders.UnidirectionalRNNEncoder.output_layer", "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.shapes.shape_list", "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.shapes.shape_list", "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.shapes.shape_list", "home.repos.pwc.inspect_result.VegB_Text_Infilling.texar.module_base.ModuleBase._add_internal_trainable_variables", "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.shapes.shape_list"], ["", "def", "_build", "(", "self", ",", "decoder_input_pack", ",", "template_input_pack", ",", "\n", "encoder_decoder_attention_bias", ",", "args", ")", ":", "\n", "        ", "\"\"\"\n            this function is called on training generally.\n            Args:\n                targets: [bath_size, target_length], generally begins with [bos] token\n                template_input: [batch_size, source_length, channels]\n                segment_ids: [batch_size, source_length], which segment this word belongs to\n            outputs:\n                logits: [batch_size, target_length, vocab_size]\n                preds: [batch_size, target_length]\n        \"\"\"", "\n", "input", "=", "decoder_input_pack", "[", "'text_ids'", "]", "[", ":", ",", ":", "-", "1", "]", "\n", "decoder_self_attention_bias", "=", "(", "\n", "attentions", ".", "attention_bias_lower_triangle", "(", "\n", "shape_list", "(", "input", ")", "[", "1", "]", ")", ")", "\n", "input_word_embeds", "=", "tf", ".", "nn", ".", "embedding_lookup", "(", "self", ".", "_embedding", ",", "input", ")", "\n", "if", "self", ".", "_hparams", ".", "multiply_embedding_mode", "==", "'sqrt_depth'", ":", "\n", "            ", "input_word_embeds", "=", "input_word_embeds", "*", "(", "self", ".", "_embedding", ".", "shape", ".", "as_list", "(", ")", "[", "-", "1", "]", "**", "0.5", ")", "\n", "", "length", "=", "shape_list", "(", "input_word_embeds", ")", "[", "1", "]", "\n", "channels", "=", "shape_list", "(", "input_word_embeds", ")", "[", "2", "]", "\n", "input_pos_embeds", "=", "self", ".", "position_embedder", "(", "length", ",", "channels", ",", "\n", "decoder_input_pack", "[", "'segment_ids'", "]", "[", ":", ",", ":", "-", "1", "]", ",", "\n", "decoder_input_pack", "[", "'offsets'", "]", "[", ":", ",", ":", "-", "1", "]", ")", "\n", "inputs", "=", "input_word_embeds", "+", "input_pos_embeds", "\n", "\n", "template", "=", "template_input_pack", "[", "'templates'", "]", "\n", "template_word_embeds", "=", "tf", ".", "nn", ".", "embedding_lookup", "(", "self", ".", "_embedding", ",", "template", ")", "\n", "template_length", "=", "shape_list", "(", "template", ")", "[", "1", "]", "\n", "template_pos_embeds", "=", "self", ".", "position_embedder", "(", "template_length", ",", "channels", ",", "\n", "template_input_pack", "[", "'segment_ids'", "]", ",", "\n", "template_input_pack", "[", "'offsets'", "]", ")", "\n", "template_inputs", "=", "template_word_embeds", "+", "template_pos_embeds", "\n", "self", ".", "decoder_output", "=", "self", ".", "_self_attention_stack", "(", "\n", "inputs", ",", "\n", "template_inputs", ",", "\n", "decoder_self_attention_bias", "=", "decoder_self_attention_bias", ",", "\n", ")", "\n", "\n", "logits", "=", "self", ".", "output_layer", "(", "self", ".", "decoder_output", ")", "\n", "preds", "=", "tf", ".", "to_int32", "(", "tf", ".", "argmax", "(", "logits", ",", "axis", "=", "-", "1", ")", ")", "\n", "\n", "if", "not", "self", ".", "_built", ":", "\n", "            ", "self", ".", "_add_internal_trainable_variables", "(", ")", "\n", "self", ".", "_built", "=", "True", "\n", "\n", "", "return", "logits", ",", "preds", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.decoders.template_transformer_decoder.TemplateTransformerDecoder.dynamic_decode": [[180, 230], ["tensorflow.variable_scope", "tensorflow.nn.embedding_lookup", "template_transformer_decoder.TemplateTransformerDecoder.position_embedder", "tensorflow.cast", "tensorflow.shape", "texar.utils.shapes.shape_list", "texar.utils.shapes.shape_list", "tensorflow.fill", "template_transformer_decoder.TemplateTransformerDecoder.greedy_decode", "template_transformer_decoder.TemplateTransformerDecoder.beam_decode"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.agents.agent_base.AgentBase.variable_scope", "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.shapes.shape_list", "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.shapes.shape_list", "home.repos.pwc.inspect_result.VegB_Text_Infilling.decoders.template_transformer_decoder.TemplateTransformerDecoder.greedy_decode", "home.repos.pwc.inspect_result.VegB_Text_Infilling.decoders.template_transformer_decoder.TemplateTransformerDecoder.beam_decode"], ["", "def", "dynamic_decode", "(", "self", ",", "template_input_pack", ",", "encoder_decoder_attention_bias", ",", "\n", "segment_ids", ",", "offsets", ",", "bos_id", ",", "eos_id", ")", ":", "\n", "        ", "\"\"\"\n            this function is called on in test mode, without the target input.\n        \"\"\"", "\n", "with", "tf", ".", "variable_scope", "(", "self", ".", "variable_scope", ",", "reuse", "=", "True", ")", ":", "\n", "            ", "template", "=", "template_input_pack", "[", "'templates'", "]", "\n", "template_word_embeds", "=", "tf", ".", "nn", ".", "embedding_lookup", "(", "self", ".", "_embedding", ",", "template", ")", "\n", "batch_size", "=", "tf", ".", "shape", "(", "template", ")", "[", "0", "]", "\n", "template_length", "=", "shape_list", "(", "template", ")", "[", "1", "]", "\n", "channels", "=", "shape_list", "(", "template_word_embeds", ")", "[", "2", "]", "\n", "template_pos_embeds", "=", "self", ".", "position_embedder", "(", "template_length", ",", "channels", ",", "\n", "template_input_pack", "[", "'segment_ids'", "]", ",", "\n", "template_input_pack", "[", "'offsets'", "]", ")", "\n", "template_inputs", "=", "template_word_embeds", "+", "template_pos_embeds", "\n", "\n", "# batch_size = tf.shape(template_inputs)[0]", "\n", "beam_width", "=", "self", ".", "_hparams", ".", "beam_width", "\n", "maximum_decode_length", "=", "self", ".", "hparams", ".", "maximum_decode_length", "\n", "start_tokens", "=", "tf", ".", "cast", "(", "tf", ".", "fill", "(", "[", "batch_size", "]", ",", "bos_id", ")", ",", "dtype", "=", "tf", ".", "int32", ")", "\n", "if", "beam_width", "<=", "1", ":", "\n", "                ", "sampled_ids", ",", "log_probs", "=", "self", ".", "greedy_decode", "(", "\n", "self", ".", "prepare_tokens_to_embeds", ",", "\n", "start_tokens", ",", "\n", "eos_id", ",", "#self._hparams.eos_idx,", "\n", "decode_length", "=", "maximum_decode_length", ",", "\n", "memory", "=", "template_inputs", ",", "\n", "encoder_decoder_attention_bias", "=", "encoder_decoder_attention_bias", ",", "\n", "segment_ids", "=", "segment_ids", ",", "\n", "offsets", "=", "offsets", ",", "\n", ")", "\n", "", "else", ":", "\n", "                ", "sampled_ids", ",", "log_probs", "=", "self", ".", "beam_decode", "(", "\n", "self", ".", "prepare_tokens_to_embeds", ",", "\n", "start_tokens", ",", "\n", "eos_id", ",", "#self._hparams.eos_idx,", "\n", "beam_width", "=", "beam_width", ",", "\n", "decode_length", "=", "maximum_decode_length", ",", "\n", "memory", "=", "template_inputs", ",", "\n", "encoder_decoder_attention_bias", "=", "encoder_decoder_attention_bias", ",", "\n", "segment_ids", "=", "segment_ids", ",", "\n", "offsets", "=", "offsets", "\n", ")", "\n", "", "predictions", "=", "{", "\n", "'sampled_ids'", ":", "sampled_ids", ",", "\n", "'log_probs'", ":", "log_probs", "\n", "}", "\n", "", "return", "predictions", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.decoders.template_transformer_decoder.TemplateTransformerDecoder._self_attention_stack": [[231, 296], ["tensorflow.layers.dropout", "range", "texar.core.layers.layer_normalize", "texar.context.global_mode_train", "cache.keys", "tensorflow.variable_scope", "texar.modules.networks.networks.FeedForwardNetwork", "tensorflow.variable_scope", "texar.core.attentions.multihead_attention", "tensorflow.variable_scope", "tensorflow.layers.dropout", "tensorflow.layers.dropout", "tensorflow.variable_scope", "texar.core.attentions.multihead_attention", "texar.modules.networks.networks.FeedForwardNetwork.", "texar.core.layers.layer_normalize", "tensorflow.layers.dropout", "texar.core.layers.layer_normalize", "texar.context.global_mode_train", "texar.context.global_mode_train", "texar.core.layers.layer_normalize", "texar.context.global_mode_train"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.core.layers.layer_normalize", "home.repos.pwc.inspect_result.VegB_Text_Infilling.texar.context.global_mode_train", "home.repos.pwc.inspect_result.VegB_Text_Infilling.texar.hyperparams.HParams.keys", "home.repos.pwc.inspect_result.VegB_Text_Infilling.agents.agent_base.AgentBase.variable_scope", "home.repos.pwc.inspect_result.VegB_Text_Infilling.agents.agent_base.AgentBase.variable_scope", "home.repos.pwc.inspect_result.VegB_Text_Infilling.core.layers.multihead_attention", "home.repos.pwc.inspect_result.VegB_Text_Infilling.agents.agent_base.AgentBase.variable_scope", "home.repos.pwc.inspect_result.VegB_Text_Infilling.agents.agent_base.AgentBase.variable_scope", "home.repos.pwc.inspect_result.VegB_Text_Infilling.core.layers.multihead_attention", "home.repos.pwc.inspect_result.VegB_Text_Infilling.core.layers.layer_normalize", "home.repos.pwc.inspect_result.VegB_Text_Infilling.core.layers.layer_normalize", "home.repos.pwc.inspect_result.VegB_Text_Infilling.texar.context.global_mode_train", "home.repos.pwc.inspect_result.VegB_Text_Infilling.texar.context.global_mode_train", "home.repos.pwc.inspect_result.VegB_Text_Infilling.core.layers.layer_normalize", "home.repos.pwc.inspect_result.VegB_Text_Infilling.texar.context.global_mode_train"], ["", "def", "_self_attention_stack", "(", "self", ",", "\n", "inputs", ",", "\n", "template_input", ",", "\n", "decoder_self_attention_bias", "=", "None", ",", "\n", "encoder_decoder_attention_bias", "=", "None", ",", "\n", "cache", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n            stacked multihead attention module.\n        \"\"\"", "\n", "inputs", "=", "tf", ".", "layers", ".", "dropout", "(", "inputs", ",", "\n", "rate", "=", "self", ".", "_hparams", ".", "embedding_dropout", ",", "\n", "training", "=", "context", ".", "global_mode_train", "(", ")", ")", "\n", "if", "cache", "is", "not", "None", "and", "'encoder_decoder_attention_bias'", "in", "cache", ".", "keys", "(", ")", ":", "\n", "            ", "encoder_decoder_attention_bias", "=", "cache", "[", "'encoder_decoder_attention_bias'", "]", "\n", "", "else", ":", "\n", "            ", "assert", "decoder_self_attention_bias", "is", "not", "None", "\n", "\n", "", "x", "=", "inputs", "\n", "for", "i", "in", "range", "(", "self", ".", "_hparams", ".", "num_blocks", ")", ":", "\n", "            ", "layer_name", "=", "'layer_{}'", ".", "format", "(", "i", ")", "\n", "layer_cache", "=", "cache", "[", "layer_name", "]", "if", "cache", "is", "not", "None", "else", "None", "\n", "with", "tf", ".", "variable_scope", "(", "layer_name", ")", ":", "\n", "                ", "with", "tf", ".", "variable_scope", "(", "\"self_attention\"", ")", ":", "\n", "                    ", "selfatt_output", "=", "attentions", ".", "multihead_attention", "(", "\n", "queries", "=", "layers", ".", "layer_normalize", "(", "x", ")", ",", "\n", "memory", "=", "None", ",", "\n", "memory_attention_bias", "=", "decoder_self_attention_bias", ",", "\n", "num_units", "=", "self", ".", "_hparams", ".", "num_units", ",", "\n", "num_heads", "=", "self", ".", "_hparams", ".", "num_heads", ",", "\n", "dropout_rate", "=", "self", ".", "_hparams", ".", "attention_dropout", ",", "\n", "cache", "=", "layer_cache", ",", "\n", "scope", "=", "\"multihead_attention\"", ",", "\n", ")", "\n", "x", "=", "x", "+", "tf", ".", "layers", ".", "dropout", "(", "\n", "selfatt_output", ",", "\n", "rate", "=", "self", ".", "_hparams", ".", "residual_dropout", ",", "\n", "training", "=", "context", ".", "global_mode_train", "(", ")", "\n", ")", "\n", "", "if", "template_input", "is", "not", "None", ":", "\n", "                    ", "with", "tf", ".", "variable_scope", "(", "'encdec_attention'", ")", ":", "\n", "                        ", "encdec_output", "=", "attentions", ".", "multihead_attention", "(", "\n", "queries", "=", "layers", ".", "layer_normalize", "(", "x", ")", ",", "\n", "memory", "=", "template_input", ",", "\n", "memory_attention_bias", "=", "encoder_decoder_attention_bias", ",", "\n", "num_units", "=", "self", ".", "_hparams", ".", "num_units", ",", "\n", "num_heads", "=", "self", ".", "_hparams", ".", "num_heads", ",", "\n", "dropout_rate", "=", "self", ".", "_hparams", ".", "attention_dropout", ",", "\n", "scope", "=", "\"multihead_attention\"", "\n", ")", "\n", "x", "=", "x", "+", "tf", ".", "layers", ".", "dropout", "(", "encdec_output", ",", "rate", "=", "self", ".", "_hparams", ".", "residual_dropout", ",", "training", "=", "context", ".", "global_mode_train", "(", ")", "\n", ")", "\n", "", "", "poswise_network", "=", "FeedForwardNetwork", "(", "hparams", "=", "self", ".", "_hparams", "[", "'poswise_feedforward'", "]", ")", "\n", "with", "tf", ".", "variable_scope", "(", "poswise_network", ".", "variable_scope", ")", ":", "\n", "                    ", "sub_output", "=", "tf", ".", "layers", ".", "dropout", "(", "\n", "poswise_network", "(", "layers", ".", "layer_normalize", "(", "x", ")", ")", ",", "\n", "rate", "=", "self", ".", "_hparams", ".", "residual_dropout", ",", "\n", "training", "=", "context", ".", "global_mode_train", "(", ")", "\n", ")", "\n", "x", "=", "x", "+", "sub_output", "\n", "\n", "", "", "", "return", "layers", ".", "layer_normalize", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.decoders.template_transformer_decoder.TemplateTransformerDecoder.build_output_layer": [[297, 319], ["tensorflow.layers.Dense", "tensorflow.layers.Dense.build", "texar.utils.shapes.shape_list", "tensorflow.reshape", "tensorflow.matmul", "tensorflow.reshape", "tensorflow.variable_scope", "tensorflow.get_variable"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.core.layers.SequentialLayer.build", "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.shapes.shape_list", "home.repos.pwc.inspect_result.VegB_Text_Infilling.agents.agent_base.AgentBase.variable_scope"], ["", "def", "build_output_layer", "(", "self", ",", "num_units", ")", ":", "\n", "        ", "if", "self", ".", "_hparams", ".", "share_embed_and_transform", ":", "\n", "            ", "if", "self", ".", "_hparams", ".", "transform_with_bias", ":", "\n", "                ", "with", "tf", ".", "variable_scope", "(", "self", ".", "variable_scope", ")", ":", "\n", "                    ", "affine_bias", "=", "tf", ".", "get_variable", "(", "'affine_bias'", ",", "\n", "[", "self", ".", "_vocab_size", "]", ")", "\n", "", "", "else", ":", "\n", "                ", "affine_bias", "=", "None", "\n", "", "def", "outputs_to_logits", "(", "outputs", ")", ":", "\n", "                ", "shape", "=", "shape_list", "(", "outputs", ")", "\n", "outputs", "=", "tf", ".", "reshape", "(", "outputs", ",", "[", "-", "1", ",", "num_units", "]", ")", "\n", "logits", "=", "tf", ".", "matmul", "(", "outputs", ",", "self", ".", "_embedding", ",", "transpose_b", "=", "True", ")", "\n", "if", "affine_bias", "is", "not", "None", ":", "\n", "                    ", "logits", "+=", "affine_bias", "\n", "", "logits", "=", "tf", ".", "reshape", "(", "logits", ",", "shape", "[", ":", "-", "1", "]", "+", "[", "self", ".", "_vocab_size", "]", ")", "\n", "return", "logits", "\n", "", "return", "outputs_to_logits", "\n", "", "else", ":", "\n", "            ", "layer", "=", "tf", ".", "layers", ".", "Dense", "(", "self", ".", "_vocab_size", ",", "use_bias", "=", "self", ".", "_hparams", ".", "transform_with_bias", ")", "\n", "layer", ".", "build", "(", "[", "None", ",", "num_units", "]", ")", "\n", "return", "layer", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.decoders.template_transformer_decoder.TemplateTransformerDecoder.output_size": [[320, 330], ["texar.modules.decoders.transformer_decoders.TransformerDecoderOutput", "tensorflow.python.framework.tensor_shape.TensorShape", "tensorflow.python.framework.tensor_shape.TensorShape"], "methods", ["None"], ["", "", "@", "property", "\n", "def", "output_size", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        The output of the _build function, (logits, preds)\n        logits: [batch_size, length, vocab_size]\n        preds: [batch_size, length]\n        \"\"\"", "\n", "return", "TransformerDecoderOutput", "(", "\n", "output_logits", "=", "tensor_shape", ".", "TensorShape", "(", "[", "None", ",", "None", ",", "self", ".", "_vocab_size", "]", ")", ",", "\n", "sample_id", "=", "tensor_shape", ".", "TensorShape", "(", "[", "None", ",", "None", "]", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.decoders.template_transformer_decoder.TemplateTransformerDecoder.output_dtype": [[332, 338], ["texar.modules.decoders.transformer_decoders.TransformerDecoderOutput"], "methods", ["None"], ["", "def", "output_dtype", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        The output dtype of the _build function, (float32, int32)\n        \"\"\"", "\n", "return", "TransformerDecoderOutput", "(", "\n", "output_logits", "=", "dtypes", ".", "float32", ",", "sample_id", "=", "dtypes", ".", "int32", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.decoders.template_transformer_decoder.TemplateTransformerDecoder._init_cache": [[339, 354], ["range", "tensorflow.shape", "memory.get_shape().as_list", "tensorflow.zeros", "tensorflow.zeros", "tensorflow.zeros", "tensorflow.zeros", "memory.get_shape"], "methods", ["None"], ["", "def", "_init_cache", "(", "self", ",", "memory", ",", "encoder_decoder_attention_bias", ")", ":", "\n", "        ", "cache", "=", "{", "'memory'", ":", "memory", "}", "\n", "if", "encoder_decoder_attention_bias", "is", "not", "None", ":", "\n", "            ", "cache", "[", "'encoder_decoder_attention_bias'", "]", "=", "encoder_decoder_attention_bias", "\n", "", "batch_size", "=", "tf", ".", "shape", "(", "memory", ")", "[", "0", "]", "\n", "depth", "=", "memory", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", "[", "-", "1", "]", "\n", "for", "l", "in", "range", "(", "self", ".", "_hparams", ".", "num_blocks", ")", ":", "\n", "            ", "cache", "[", "'layer_{}'", ".", "format", "(", "l", ")", "]", "=", "{", "\n", "'self_keys'", ":", "tf", ".", "zeros", "(", "[", "batch_size", ",", "0", ",", "depth", "]", ")", ",", "\n", "'self_values'", ":", "tf", ".", "zeros", "(", "[", "batch_size", ",", "0", ",", "depth", "]", ")", ",", "\n", "'memory_keys'", ":", "tf", ".", "zeros", "(", "[", "batch_size", ",", "0", ",", "depth", "]", ")", ",", "\n", "'memory_values'", ":", "tf", ".", "zeros", "(", "[", "batch_size", ",", "0", ",", "depth", "]", ")", ",", "\n", "}", "\n", "", "return", "cache", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.decoders.template_transformer_decoder.TemplateTransformerDecoder.greedy_decode": [[355, 419], ["tensorflow.fill", "tensorflow.constant", "tensorflow.zeros", "tensorflow.expand_dims", "print", "tensorflow.zeros", "template_transformer_decoder.TemplateTransformerDecoder._init_cache", "template_transformer_decoder.TemplateTransformerDecoder._symbols_to_logits_fn", "tensorflow.while_loop", "tensorflow.expand_dims", "tensorflow.expand_dims", "tensorflow.shape", "template_transformer_decoder.TemplateTransformerDecoder.", "tensorflow.equal", "tensorflow.stack", "tensorflow.gather_nd", "tensorflow.expand_dims", "tensorflow.concat", "tensorflow.reduce_logsumexp", "tensorflow.argmax", "tensorflow.logical_not", "tensorflow.multinomial().squeeze", "tensorflow.range", "tensorflow.reduce_all", "tensorflow.TensorShape", "tensorflow.TensorShape", "tensorflow.TensorShape", "tensorflow.TensorShape", "tensorflow.python.util.nest.map_structure", "tensorflow.TensorShape", "tensorflow.to_int32", "tensorflow.multinomial"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.decoders.template_transformer_decoder.TemplateTransformerDecoder._init_cache", "home.repos.pwc.inspect_result.VegB_Text_Infilling.decoders.template_transformer_decoder.TemplateTransformerDecoder._symbols_to_logits_fn"], ["", "def", "greedy_decode", "(", "self", ",", "\n", "embedding_fn", ",", "\n", "start_tokens", ",", "\n", "EOS", ",", "\n", "decode_length", ",", "\n", "memory", ",", "\n", "encoder_decoder_attention_bias", ",", "\n", "segment_ids", ",", "\n", "offsets", ")", ":", "\n", "        ", "batch_size", "=", "tf", ".", "shape", "(", "start_tokens", ")", "[", "0", "]", "\n", "finished", "=", "tf", ".", "fill", "(", "[", "batch_size", "]", ",", "False", ")", "\n", "step", "=", "tf", ".", "constant", "(", "0", ")", "\n", "decoded_ids", "=", "tf", ".", "zeros", "(", "[", "batch_size", ",", "0", "]", ",", "dtype", "=", "tf", ".", "int32", ")", "\n", "next_id", "=", "tf", ".", "expand_dims", "(", "start_tokens", ",", "1", ")", "\n", "print", "(", "'next id:{}'", ".", "format", "(", "next_id", ".", "shape", ")", ")", "\n", "log_prob", "=", "tf", ".", "zeros", "(", "[", "batch_size", "]", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "\n", "cache", "=", "self", ".", "_init_cache", "(", "memory", ",", "encoder_decoder_attention_bias", ")", "\n", "symbols_to_logits_fn", "=", "self", ".", "_symbols_to_logits_fn", "(", "embedding_fn", ",", "\n", "max_length", "=", "decode_length", "+", "1", ",", "segment_ids", "=", "segment_ids", ",", "\n", "offsets", "=", "offsets", ")", "\n", "\n", "def", "_body", "(", "step", ",", "finished", ",", "next_id", ",", "decoded_ids", ",", "cache", ",", "log_prob", ")", ":", "\n", "\n", "            ", "logits", ",", "cache", "=", "symbols_to_logits_fn", "(", "next_id", ",", "step", ",", "cache", ")", "\n", "log_probs", "=", "logits", "-", "tf", ".", "reduce_logsumexp", "(", "logits", ",", "axis", "=", "-", "1", ",", "keep_dims", "=", "True", ")", "\n", "\n", "#TODO: by default, the output_type is tf.int64.", "\n", "# Can we adjust the default int type of texar to tf.int64?", "\n", "if", "self", ".", "sampling_method", "==", "'argmax'", ":", "\n", "                ", "next_id", "=", "tf", ".", "argmax", "(", "logits", ",", "-", "1", ",", "output_type", "=", "tf", ".", "int32", ")", "\n", "", "elif", "self", ".", "sampling_method", "==", "'sample'", ":", "\n", "                ", "next_id", "=", "tf", ".", "multinomial", "(", "logits", ",", "1", ")", ".", "squeeze", "(", "axis", "=", "1", ")", "\n", "", "finished", "|=", "tf", ".", "equal", "(", "next_id", ",", "EOS", ")", "\n", "log_prob_indices", "=", "tf", ".", "stack", "(", "\n", "[", "tf", ".", "range", "(", "tf", ".", "to_int32", "(", "batch_size", ")", ")", ",", "next_id", "]", ",", "axis", "=", "1", ")", "\n", "log_prob", "+=", "tf", ".", "gather_nd", "(", "log_probs", ",", "log_prob_indices", ")", "\n", "\n", "next_id", "=", "tf", ".", "expand_dims", "(", "next_id", ",", "axis", "=", "1", ")", "\n", "#keep the shape as [batch_size, seq_len]", "\n", "\n", "decoded_ids", "=", "tf", ".", "concat", "(", "[", "decoded_ids", ",", "next_id", "]", ",", "axis", "=", "1", ")", "\n", "return", "step", "+", "1", ",", "finished", ",", "next_id", ",", "decoded_ids", ",", "cache", ",", "log_prob", "\n", "\n", "", "def", "is_not_finished", "(", "i", ",", "finished", ",", "*", "_", ")", ":", "\n", "            ", "return", "(", "i", "<", "decode_length", ")", "&", "tf", ".", "logical_not", "(", "tf", ".", "reduce_all", "(", "finished", ")", ")", "\n", "\n", "", "_", ",", "_", ",", "_", ",", "decoded_ids", ",", "_", ",", "log_prob", "=", "tf", ".", "while_loop", "(", "\n", "is_not_finished", ",", "\n", "_body", ",", "\n", "loop_vars", "=", "(", "step", ",", "finished", ",", "next_id", ",", "decoded_ids", ",", "cache", ",", "log_prob", ")", ",", "\n", "shape_invariants", "=", "(", "\n", "tf", ".", "TensorShape", "(", "[", "]", ")", ",", "\n", "tf", ".", "TensorShape", "(", "[", "None", "]", ")", ",", "\n", "tf", ".", "TensorShape", "(", "[", "None", ",", "None", "]", ")", ",", "\n", "tf", ".", "TensorShape", "(", "[", "None", ",", "None", "]", ")", ",", "\n", "nest", ".", "map_structure", "(", "beam_search", ".", "get_state_shape_invariants", ",", "cache", ")", ",", "\n", "tf", ".", "TensorShape", "(", "[", "None", "]", ")", ",", "\n", ")", ")", "\n", "\n", "outputs", "=", "tf", ".", "expand_dims", "(", "decoded_ids", ",", "1", ")", "\n", "log_prob", "=", "tf", ".", "expand_dims", "(", "log_prob", ",", "1", ")", "\n", "return", "(", "outputs", ",", "log_prob", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.decoders.template_transformer_decoder.TemplateTransformerDecoder._expand_to_beam_width": [[420, 429], ["tensorflow.tile", "tensorflow.reshape", "texar.utils.shapes.shape_list", "tensorflow.expand_dims"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.shapes.shape_list"], ["", "def", "_expand_to_beam_width", "(", "self", ",", "tensor", ",", "beam_width", ")", ":", "\n", "        ", "\"\"\"\n        :param tensor: [batch_size, max_len]\n        :param beam_width:\n        :return: [batch_size*beam_width, max_len]\n        \"\"\"", "\n", "batch_size", "=", "shape_list", "(", "tensor", ")", "[", "0", "]", "\n", "expanded", "=", "tf", ".", "tile", "(", "tf", ".", "expand_dims", "(", "tensor", ",", "axis", "=", "1", ")", ",", "[", "1", ",", "beam_width", ",", "1", "]", ")", "\n", "return", "tf", ".", "reshape", "(", "expanded", ",", "[", "batch_size", "*", "beam_width", ",", "-", "1", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.decoders.template_transformer_decoder.TemplateTransformerDecoder.beam_decode": [[430, 457], ["template_transformer_decoder.TemplateTransformerDecoder._init_cache", "template_transformer_decoder.TemplateTransformerDecoder._symbols_to_logits_fn", "texar.utils.beam_search.beam_search", "template_transformer_decoder.TemplateTransformerDecoder._expand_to_beam_width", "template_transformer_decoder.TemplateTransformerDecoder._expand_to_beam_width"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.decoders.template_transformer_decoder.TemplateTransformerDecoder._init_cache", "home.repos.pwc.inspect_result.VegB_Text_Infilling.decoders.template_transformer_decoder.TemplateTransformerDecoder._symbols_to_logits_fn", "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.beam_search.beam_search", "home.repos.pwc.inspect_result.VegB_Text_Infilling.decoders.template_transformer_decoder.TemplateTransformerDecoder._expand_to_beam_width", "home.repos.pwc.inspect_result.VegB_Text_Infilling.decoders.template_transformer_decoder.TemplateTransformerDecoder._expand_to_beam_width"], ["", "def", "beam_decode", "(", "self", ",", "\n", "embedding_fn", ",", "\n", "start_tokens", ",", "\n", "EOS", ",", "\n", "memory", ",", "\n", "encoder_decoder_attention_bias", ",", "\n", "segment_ids", ",", "\n", "offsets", ",", "\n", "decode_length", "=", "256", ",", "\n", "beam_width", "=", "5", ",", ")", ":", "\n", "        ", "cache", "=", "self", ".", "_init_cache", "(", "memory", ",", "encoder_decoder_attention_bias", ")", "\n", "symbols_to_logits_fn", "=", "self", ".", "_symbols_to_logits_fn", "(", "embedding_fn", ",", "\n", "max_length", "=", "decode_length", "+", "1", ",", "\n", "segment_ids", "=", "self", ".", "_expand_to_beam_width", "(", "segment_ids", ",", "beam_width", ")", ",", "\n", "offsets", "=", "self", ".", "_expand_to_beam_width", "(", "offsets", ",", "beam_width", ")", ")", "\n", "outputs", ",", "log_probs", "=", "beam_search", ".", "beam_search", "(", "\n", "symbols_to_logits_fn", ",", "\n", "start_tokens", ",", "\n", "beam_width", ",", "\n", "decode_length", ",", "\n", "self", ".", "_vocab_size", ",", "\n", "self", ".", "_hparams", ".", "alpha", ",", "\n", "states", "=", "cache", ",", "\n", "eos_id", "=", "EOS", ")", "\n", "\n", "outputs", "=", "outputs", "[", ":", ",", ":", ",", "1", ":", "]", "# ignore <BOS>", "\n", "return", "(", "outputs", ",", "log_probs", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.classifiers.rnn_classifiers.UnidirectionalRNNClassifier.__init__": [[61, 99], ["texar.modules.classifiers.classifier_base.ClassifierBase.__init__", "tensorflow.variable_scope", "texar.utils.utils.dict_fetch", "texar.modules.encoders.rnn_encoders.UnidirectionalRNNEncoder", "texar.modules.encoders.rnn_encoders.UnidirectionalRNNEncoder.default_hparams", "logit_kwargs.todict.todict.update", "texar.core.layers.get_layer", "isinstance", "ValueError", "logit_kwargs.todict.todict.todict"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.text_infilling.self_attn_hyperparams.Hyperparams.__init__", "home.repos.pwc.inspect_result.VegB_Text_Infilling.agents.agent_base.AgentBase.variable_scope", "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.utils.dict_fetch", "home.repos.pwc.inspect_result.VegB_Text_Infilling.core.replay_memories.DequeReplayMemory.default_hparams", "home.repos.pwc.inspect_result.VegB_Text_Infilling.core.layers.get_layer", "home.repos.pwc.inspect_result.VegB_Text_Infilling.texar.hyperparams.HParams.todict"], ["def", "__init__", "(", "self", ",", "\n", "cell", "=", "None", ",", "\n", "cell_dropout_mode", "=", "None", ",", "\n", "output_layer", "=", "None", ",", "\n", "hparams", "=", "None", ")", ":", "\n", "        ", "ClassifierBase", ".", "__init__", "(", "self", ",", "hparams", ")", "\n", "\n", "with", "tf", ".", "variable_scope", "(", "self", ".", "variable_scope", ")", ":", "\n", "# Creates the underlying encoder", "\n", "            ", "encoder_hparams", "=", "utils", ".", "dict_fetch", "(", "\n", "hparams", ",", "UnidirectionalRNNEncoder", ".", "default_hparams", "(", ")", ")", "\n", "if", "encoder_hparams", "is", "not", "None", ":", "\n", "                ", "encoder_hparams", "[", "'name'", "]", "=", "None", "\n", "", "self", ".", "_encoder", "=", "UnidirectionalRNNEncoder", "(", "\n", "cell", "=", "cell", ",", "\n", "cell_dropout_mode", "=", "cell_dropout_mode", ",", "\n", "output_layer", "=", "output_layer", ",", "\n", "hparams", "=", "encoder_hparams", ")", "\n", "\n", "# Creates an additional classification layer if needed", "\n", "self", ".", "_num_classes", "=", "self", ".", "_hparams", ".", "num_classes", "\n", "if", "self", ".", "_num_classes", "<=", "0", ":", "\n", "                ", "self", ".", "_logit_layer", "=", "None", "\n", "", "else", ":", "\n", "                ", "logit_kwargs", "=", "self", ".", "_hparams", ".", "logit_layer_kwargs", "\n", "if", "logit_kwargs", "is", "None", ":", "\n", "                    ", "logit_kwargs", "=", "{", "}", "\n", "", "elif", "not", "isinstance", "(", "logit_kwargs", ",", "HParams", ")", ":", "\n", "                    ", "raise", "ValueError", "(", "\n", "\"hparams['logit_layer_kwargs'] must be a dict.\"", ")", "\n", "", "else", ":", "\n", "                    ", "logit_kwargs", "=", "logit_kwargs", ".", "todict", "(", ")", "\n", "", "logit_kwargs", ".", "update", "(", "{", "\"units\"", ":", "self", ".", "_num_classes", "}", ")", "\n", "if", "'name'", "not", "in", "logit_kwargs", ":", "\n", "                    ", "logit_kwargs", "[", "'name'", "]", "=", "\"logit_layer\"", "\n", "\n", "", "layer_hparams", "=", "{", "\"type\"", ":", "\"Dense\"", ",", "\"kwargs\"", ":", "logit_kwargs", "}", "\n", "self", ".", "_logit_layer", "=", "layers", ".", "get_layer", "(", "hparams", "=", "layer_hparams", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.classifiers.rnn_classifiers.UnidirectionalRNNClassifier.default_hparams": [[101, 117], ["texar.modules.encoders.rnn_encoders.UnidirectionalRNNEncoder.default_hparams", "texar.modules.encoders.rnn_encoders.UnidirectionalRNNEncoder.default_hparams.update"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.core.replay_memories.DequeReplayMemory.default_hparams"], ["", "", "", "@", "staticmethod", "\n", "def", "default_hparams", "(", ")", ":", "\n", "        ", "\"\"\"Returns a dictionary of hyperparameters with default values.\n\n        TODO\n        final_time, all_time, time_wise,\n        \"\"\"", "\n", "hparams", "=", "UnidirectionalRNNEncoder", ".", "default_hparams", "(", ")", "\n", "hparams", ".", "update", "(", "{", "\n", "\"num_classes\"", ":", "2", ",", "\n", "\"logit_layer_kwargs\"", ":", "None", ",", "\n", "\"clas_strategy\"", ":", "\"final_time\"", ",", "\n", "\"max_seq_length\"", ":", "None", ",", "\n", "\"name\"", ":", "\"unidirectional_rnn_classifier\"", "\n", "}", ")", "\n", "return", "hparams", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.classifiers.rnn_classifiers.UnidirectionalRNNClassifier._build": [[118, 206], ["rnn_classifiers.UnidirectionalRNNClassifier._encoder", "tensorflow.contrib.framework.nest.flatten", "tensorflow.contrib.framework.nest.flatten", "numpy.prod", "texar.utils.shapes.flatten", "len", "tensorflow.concat", "numpy.sum", "tensorflow.argmax", "tensorflow.argmax", "rnn_classifiers.UnidirectionalRNNClassifier._add_internal_trainable_variables", "zip", "texar.modules.encoders.rnn_encoders._forward_single_output_layer", "rnn_classifiers.UnidirectionalRNNClassifier._add_trainable_variable", "ValueError", "rnn_classifiers.UnidirectionalRNNClassifier._logit_layer", "ValueError", "ValueError", "tensorflow.reshape", "tensorflow.pad", "tensorflow.pad", "tensorflow.reshape", "rnn_classifiers.UnidirectionalRNNClassifier._logit_layer", "tensorflow.shape"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.encoders.hierarchical_encoders.HierarchicalRNNEncoder.flatten", "home.repos.pwc.inspect_result.VegB_Text_Infilling.encoders.hierarchical_encoders.HierarchicalRNNEncoder.flatten", "home.repos.pwc.inspect_result.VegB_Text_Infilling.encoders.hierarchical_encoders.HierarchicalRNNEncoder.flatten", "home.repos.pwc.inspect_result.VegB_Text_Infilling.texar.module_base.ModuleBase._add_internal_trainable_variables", "home.repos.pwc.inspect_result.VegB_Text_Infilling.encoders.rnn_encoders._forward_single_output_layer", "home.repos.pwc.inspect_result.VegB_Text_Infilling.texar.module_base.ModuleBase._add_trainable_variable"], ["", "def", "_build", "(", "self", ",", "\n", "inputs", ",", "\n", "sequence_length", "=", "None", ",", "\n", "initial_state", "=", "None", ",", "\n", "time_major", "=", "False", ",", "\n", "mode", "=", "None", ",", "\n", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"\n        \"\"\"", "\n", "enc_outputs", ",", "_", ",", "enc_output_size", "=", "self", ".", "_encoder", "(", "\n", "inputs", "=", "inputs", ",", "\n", "sequence_length", "=", "sequence_length", ",", "\n", "initial_state", "=", "initial_state", ",", "\n", "time_major", "=", "time_major", ",", "\n", "mode", "=", "mode", ",", "\n", "return_output_size", "=", "True", ",", "\n", "**", "kwargs", ")", "\n", "\n", "# Flatten enc_outputs", "\n", "enc_outputs_flat", "=", "nest", ".", "flatten", "(", "enc_outputs", ")", "\n", "enc_output_size_flat", "=", "nest", ".", "flatten", "(", "enc_output_size", ")", "\n", "enc_output_dims_flat", "=", "[", "np", ".", "prod", "(", "xs", ")", "for", "xs", "in", "enc_output_size_flat", "]", "\n", "enc_outputs_flat", "=", "[", "shapes", ".", "flatten", "(", "x", ",", "2", ",", "xs", ")", "for", "x", ",", "xs", "\n", "in", "zip", "(", "enc_outputs_flat", ",", "enc_output_dims_flat", ")", "]", "\n", "if", "len", "(", "enc_outputs_flat", ")", "==", "1", ":", "\n", "            ", "enc_outputs_flat", "=", "enc_outputs_flat", "[", "0", "]", "\n", "", "else", ":", "\n", "            ", "enc_outputs_flat", "=", "tf", ".", "concat", "(", "enc_outputs_flat", ",", "axis", "=", "2", ")", "\n", "\n", "# Compute logits", "\n", "", "stra", "=", "self", ".", "_hparams", ".", "clas_strategy", "\n", "if", "stra", "==", "'time_wise'", ":", "\n", "            ", "logits", "=", "enc_outputs_flat", "\n", "", "elif", "stra", "==", "'final_time'", ":", "\n", "            ", "if", "time_major", ":", "\n", "                ", "logits", "=", "enc_outputs_flat", "[", "-", "1", ",", ":", ",", ":", "]", "\n", "", "else", ":", "\n", "                ", "logits", "=", "enc_outputs_flat", "[", ":", ",", "-", "1", ",", ":", "]", "\n", "", "", "elif", "stra", "==", "'all_time'", ":", "\n", "            ", "if", "self", ".", "_logit_layer", "is", "None", ":", "\n", "                ", "raise", "ValueError", "(", "\n", "'logit layer must not be `None` if '", "\n", "'clas_strategy=\"all_time\". Specify the logit layer by '", "\n", "'either passing the layer in the constructor or '", "\n", "'specifying the hparams.'", ")", "\n", "", "if", "self", ".", "_hparams", ".", "max_seq_length", "is", "None", ":", "\n", "                ", "raise", "ValueError", "(", "\n", "'hparams.max_seq_length must not be `None` if '", "\n", "'clas_strategy=\"all_time\"'", ")", "\n", "", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "'Unknown classification strategy: {}'", ".", "format", "(", "stra", ")", ")", "\n", "\n", "", "if", "self", ".", "_logit_layer", "is", "not", "None", ":", "\n", "            ", "logit_input_dim", "=", "np", ".", "sum", "(", "enc_output_dims_flat", ")", "\n", "if", "stra", "==", "'time_wise'", ":", "\n", "                ", "logits", ",", "_", "=", "_forward_single_output_layer", "(", "\n", "logits", ",", "logit_input_dim", ",", "self", ".", "_logit_layer", ")", "\n", "", "elif", "stra", "==", "'final_time'", ":", "\n", "                ", "logits", "=", "self", ".", "_logit_layer", "(", "logits", ")", "\n", "", "elif", "stra", "==", "'all_time'", ":", "\n", "# Pad `enc_outputs_flat` to have max_seq_length before flatten", "\n", "                ", "length_diff", "=", "self", ".", "_hparams", ".", "max_seq_length", "-", "tf", ".", "shape", "(", "inputs", ")", "[", "1", "]", "\n", "length_diff", "=", "tf", ".", "reshape", "(", "length_diff", ",", "[", "1", ",", "1", "]", ")", "\n", "# Set `paddings = [[0, 0], [0, length_dif], [0, 0]]`", "\n", "paddings", "=", "tf", ".", "pad", "(", "length_diff", ",", "paddings", "=", "[", "[", "1", ",", "1", "]", ",", "[", "1", ",", "0", "]", "]", ")", "\n", "logit_input", "=", "tf", ".", "pad", "(", "enc_outputs_flat", ",", "paddings", "=", "paddings", ")", "\n", "\n", "logit_input_dim", "*=", "self", ".", "_hparams", ".", "max_seq_length", "\n", "logit_input", "=", "tf", ".", "reshape", "(", "logit_input", ",", "[", "-", "1", ",", "logit_input_dim", "]", ")", "\n", "\n", "logits", "=", "self", ".", "_logit_layer", "(", "logit_input", ")", "\n", "\n", "# Compute predications", "\n", "", "", "if", "stra", "==", "'time_wise'", ":", "\n", "            ", "pred", "=", "tf", ".", "argmax", "(", "logits", ",", "axis", "=", "-", "1", ")", "\n", "", "else", ":", "\n", "            ", "pred", "=", "tf", ".", "argmax", "(", "logits", ",", "axis", "=", "1", ")", "\n", "\n", "", "if", "not", "self", ".", "_built", ":", "\n", "            ", "self", ".", "_add_internal_trainable_variables", "(", ")", "\n", "# Add trainable variables of `self._logit_layer`", "\n", "# which may be constructed externally.", "\n", "if", "self", ".", "_logit_layer", ":", "\n", "                ", "self", ".", "_add_trainable_variable", "(", "\n", "self", ".", "_logit_layer", ".", "trainable_variables", ")", "\n", "", "self", ".", "_built", "=", "True", "\n", "\n", "", "return", "logits", ",", "pred", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.classifiers.rnn_classifiers.UnidirectionalRNNClassifier.num_classes": [[207, 212], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "num_classes", "(", "self", ")", ":", "\n", "        ", "\"\"\"The number of classes, specified in :attr:`hparams`.\n        \"\"\"", "\n", "return", "self", ".", "_hparams", ".", "num_classes", "\n", "", "", ""]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.classifiers.conv_classifiers_test.Conv1DClassifierTest.test_classifier": [[21, 49], ["texar.modules.classifiers.conv_classifiers.Conv1DClassifier", "conv_classifiers_test.Conv1DClassifierTest.assertEqual", "conv_classifiers_test.Conv1DClassifierTest.assertTrue", "tensorflow.ones", "texar.modules.classifiers.conv_classifiers.Conv1DClassifier.", "conv_classifiers_test.Conv1DClassifierTest.assertEqual", "conv_classifiers_test.Conv1DClassifierTest.assertEqual", "tensorflow.placeholder", "texar.modules.classifiers.conv_classifiers.Conv1DClassifier.", "conv_classifiers_test.Conv1DClassifierTest.assertEqual", "conv_classifiers_test.Conv1DClassifierTest.assertEqual", "texar.modules.classifiers.conv_classifiers.Conv1DClassifier", "tensorflow.ones", "texar.modules.classifiers.conv_classifiers.Conv1DClassifier.", "conv_classifiers_test.Conv1DClassifierTest.assertEqual", "conv_classifiers_test.Conv1DClassifierTest.assertEqual", "len", "isinstance"], "methods", ["None"], ["def", "test_classifier", "(", "self", ")", ":", "\n", "        ", "\"\"\"Tests classification.\n        \"\"\"", "\n", "# case 1: default hparams", "\n", "classifier", "=", "Conv1DClassifier", "(", ")", "\n", "self", ".", "assertEqual", "(", "len", "(", "classifier", ".", "layers", ")", ",", "5", ")", "\n", "self", ".", "assertTrue", "(", "isinstance", "(", "classifier", ".", "layers", "[", "-", "1", "]", ",", "\n", "tf", ".", "layers", ".", "Dense", ")", ")", "\n", "inputs", "=", "tf", ".", "ones", "(", "[", "64", ",", "16", ",", "300", "]", ",", "tf", ".", "float32", ")", "\n", "logits", ",", "pred", "=", "classifier", "(", "inputs", ")", "\n", "self", ".", "assertEqual", "(", "logits", ".", "shape", ",", "[", "64", ",", "2", "]", ")", "\n", "self", ".", "assertEqual", "(", "pred", ".", "shape", ",", "[", "64", "]", ")", "\n", "\n", "inputs", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "[", "64", ",", "None", ",", "300", "]", ")", "\n", "logits", ",", "pred", "=", "classifier", "(", "inputs", ")", "\n", "self", ".", "assertEqual", "(", "logits", ".", "shape", ",", "[", "64", ",", "2", "]", ")", "\n", "self", ".", "assertEqual", "(", "pred", ".", "shape", ",", "[", "64", "]", ")", "\n", "\n", "# case 1", "\n", "hparams", "=", "{", "\n", "\"num_classes\"", ":", "10", ",", "\n", "\"logit_layer_kwargs\"", ":", "{", "\"use_bias\"", ":", "False", "}", "\n", "}", "\n", "classifier", "=", "Conv1DClassifier", "(", "hparams", "=", "hparams", ")", "\n", "inputs", "=", "tf", ".", "ones", "(", "[", "64", ",", "16", ",", "300", "]", ",", "tf", ".", "float32", ")", "\n", "logits", ",", "pred", "=", "classifier", "(", "inputs", ")", "\n", "self", ".", "assertEqual", "(", "logits", ".", "shape", ",", "[", "64", ",", "10", "]", ")", "\n", "self", ".", "assertEqual", "(", "pred", ".", "shape", ",", "[", "64", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.classifiers.conv_classifiers.Conv1DClassifier.__init__": [[28, 56], ["texar.modules.classifiers.classifier_base.ClassifierBase.__init__", "tensorflow.variable_scope", "texar.utils.utils.dict_fetch", "texar.modules.encoders.conv_encoders.Conv1DEncoder", "texar.modules.encoders.conv_encoders.Conv1DEncoder.default_hparams", "logit_kwargs.todict.todict.update", "conv_classifiers.Conv1DClassifier._encoder.append_layer", "conv_classifiers.Conv1DClassifier._encoder.append_layer", "isinstance", "ValueError", "logit_kwargs.todict.todict.todict"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.text_infilling.self_attn_hyperparams.Hyperparams.__init__", "home.repos.pwc.inspect_result.VegB_Text_Infilling.agents.agent_base.AgentBase.variable_scope", "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.utils.dict_fetch", "home.repos.pwc.inspect_result.VegB_Text_Infilling.core.replay_memories.DequeReplayMemory.default_hparams", "home.repos.pwc.inspect_result.VegB_Text_Infilling.networks.network_base.FeedForwardNetworkBase.append_layer", "home.repos.pwc.inspect_result.VegB_Text_Infilling.networks.network_base.FeedForwardNetworkBase.append_layer", "home.repos.pwc.inspect_result.VegB_Text_Infilling.texar.hyperparams.HParams.todict"], ["def", "__init__", "(", "self", ",", "hparams", "=", "None", ")", ":", "\n", "        ", "ClassifierBase", ".", "__init__", "(", "self", ",", "hparams", ")", "\n", "\n", "with", "tf", ".", "variable_scope", "(", "self", ".", "variable_scope", ")", ":", "\n", "            ", "encoder_hparams", "=", "utils", ".", "dict_fetch", "(", "\n", "hparams", ",", "Conv1DEncoder", ".", "default_hparams", "(", ")", ")", "\n", "self", ".", "_encoder", "=", "Conv1DEncoder", "(", "hparams", "=", "encoder_hparams", ")", "\n", "\n", "# Add an additional dense layer if needed", "\n", "self", ".", "_num_classes", "=", "self", ".", "_hparams", ".", "num_classes", "\n", "if", "self", ".", "_num_classes", ">", "0", ":", "\n", "                ", "if", "self", ".", "_hparams", ".", "num_dense_layers", "<=", "0", ":", "\n", "                    ", "self", ".", "_encoder", ".", "append_layer", "(", "{", "\"type\"", ":", "\"Flatten\"", "}", ")", "\n", "\n", "", "logit_kwargs", "=", "self", ".", "_hparams", ".", "logit_layer_kwargs", "\n", "if", "logit_kwargs", "is", "None", ":", "\n", "                    ", "logit_kwargs", "=", "{", "}", "\n", "", "elif", "not", "isinstance", "(", "logit_kwargs", ",", "HParams", ")", ":", "\n", "                    ", "raise", "ValueError", "(", "\n", "\"hparams['logit_layer_kwargs'] must be a dict.\"", ")", "\n", "", "else", ":", "\n", "                    ", "logit_kwargs", "=", "logit_kwargs", ".", "todict", "(", ")", "\n", "", "logit_kwargs", ".", "update", "(", "{", "\"units\"", ":", "self", ".", "_num_classes", "}", ")", "\n", "if", "'name'", "not", "in", "logit_kwargs", ":", "\n", "                    ", "logit_kwargs", "[", "'name'", "]", "=", "\"logit_layer\"", "\n", "\n", "", "self", ".", "_encoder", ".", "append_layer", "(", "\n", "{", "\"type\"", ":", "\"Dense\"", ",", "\"kwargs\"", ":", "logit_kwargs", "}", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.classifiers.conv_classifiers.Conv1DClassifier.default_hparams": [[57, 68], ["texar.modules.encoders.conv_encoders.Conv1DEncoder.default_hparams", "texar.modules.encoders.conv_encoders.Conv1DEncoder.default_hparams.update"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.core.replay_memories.DequeReplayMemory.default_hparams"], ["", "", "", "@", "staticmethod", "\n", "def", "default_hparams", "(", ")", ":", "\n", "        ", "\"\"\"Returns a dictionary of hyperparameters with default values.\n        \"\"\"", "\n", "hparams", "=", "Conv1DEncoder", ".", "default_hparams", "(", ")", "\n", "hparams", ".", "update", "(", "{", "\n", "\"name\"", ":", "\"conv1d_classifier\"", ",", "\n", "\"num_classes\"", ":", "2", ",", "#set to <=0 to avoid appending output layer", "\n", "\"logit_layer_kwargs\"", ":", "{", "\"use_bias\"", ":", "False", "}", "\n", "}", ")", "\n", "return", "hparams", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.classifiers.conv_classifiers.Conv1DClassifier._build": [[69, 90], ["conv_classifiers.Conv1DClassifier._encoder", "tensorflow.to_int64", "tensorflow.reshape", "tensorflow.argmax", "tensorflow.reshape", "tensorflow.greater"], "methods", ["None"], ["", "def", "_build", "(", "self", ",", "# pylint: disable=arguments-differ", "\n", "inputs", ",", "\n", "sequence_length", "=", "None", ",", "\n", "dtype", "=", "None", ",", "\n", "time_major", "=", "False", ",", "\n", "mode", "=", "None", ")", ":", "\n", "        ", "logits", "=", "self", ".", "_encoder", "(", "inputs", ",", "sequence_length", ",", "dtype", ",", "time_major", ",", "mode", ")", "\n", "\n", "num_classes", "=", "self", ".", "_hparams", ".", "num_classes", "\n", "is_binary", "=", "num_classes", "==", "1", "\n", "is_binary", "=", "is_binary", "or", "(", "num_classes", "<=", "0", "and", "logits", ".", "shape", "[", "1", "]", "==", "1", ")", "\n", "\n", "if", "is_binary", ":", "\n", "            ", "pred", "=", "tf", ".", "to_int64", "(", "tf", ".", "reshape", "(", "tf", ".", "greater", "(", "logits", ",", "0", ")", ",", "[", "-", "1", "]", ")", ")", "\n", "logits", "=", "tf", ".", "reshape", "(", "logits", ",", "[", "-", "1", "]", ")", "\n", "", "else", ":", "\n", "            ", "pred", "=", "tf", ".", "argmax", "(", "logits", ",", "1", ")", "\n", "\n", "", "self", ".", "_built", "=", "True", "\n", "\n", "return", "logits", ",", "pred", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.classifiers.conv_classifiers.Conv1DClassifier.trainable_variables": [[91, 101], ["texar.utils.exceptions.TexarError"], "methods", ["None"], ["", "@", "property", "\n", "def", "trainable_variables", "(", "self", ")", ":", "\n", "        ", "\"\"\"The list of trainable variables of the module.\n        \"\"\"", "\n", "if", "not", "self", ".", "_built", ":", "\n", "            ", "raise", "TexarError", "(", "\n", "\"Attempting to access trainable_variables before module %s \"", "\n", "\"was fully built. The module is built once it is called, \"", "\n", "\"e.g., with `%s(...)`\"", "%", "(", "self", ".", "name", ",", "self", ".", "name", ")", ")", "\n", "", "return", "self", ".", "_encoder", ".", "trainable_variables", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.classifiers.conv_classifiers.Conv1DClassifier.num_classes": [[102, 107], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "num_classes", "(", "self", ")", ":", "\n", "        ", "\"\"\"The number of classes.\n        \"\"\"", "\n", "return", "self", ".", "_num_classes", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.classifiers.conv_classifiers.Conv1DClassifier.nn": [[108, 113], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "nn", "(", "self", ")", ":", "# pylint: disable=invalid-name", "\n", "        ", "\"\"\"The neural network feature extractor.\n        \"\"\"", "\n", "return", "self", ".", "_encoder", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.classifiers.conv_classifiers.Conv1DClassifier.has_layer": [[114, 122], ["conv_classifiers.Conv1DClassifier._encoder.has_layer"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.networks.network_base.FeedForwardNetworkBase.has_layer"], ["", "def", "has_layer", "(", "self", ",", "layer_name", ")", ":", "\n", "        ", "\"\"\"Returns `True` if the network with the name exists. Returns `False`\n        otherwise.\n\n        Args:\n            layer_name (str): Name of the layer.\n        \"\"\"", "\n", "return", "self", ".", "_encoder", ".", "has_layer", "(", "layer_name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.classifiers.conv_classifiers.Conv1DClassifier.layer_by_name": [[123, 131], ["conv_classifiers.Conv1DClassifier._encoder.layer_by_name"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.networks.network_base.FeedForwardNetworkBase.layer_by_name"], ["", "def", "layer_by_name", "(", "self", ",", "layer_name", ")", ":", "\n", "        ", "\"\"\"Returns the layer with the name. Returns 'None' if the layer name\n        does not exist.\n\n        Args:\n            layer_name (str): Name of the layer.\n        \"\"\"", "\n", "return", "self", ".", "_encoder", ".", "layer_by_name", "(", "layer_name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.classifiers.conv_classifiers.Conv1DClassifier.layers_by_name": [[132, 137], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "layers_by_name", "(", "self", ")", ":", "\n", "        ", "\"\"\"A dictionary mapping layer names to the layers.\n        \"\"\"", "\n", "return", "self", ".", "_encoder", ".", "layers_by_name", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.classifiers.conv_classifiers.Conv1DClassifier.layers": [[138, 143], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "layers", "(", "self", ")", ":", "\n", "        ", "\"\"\"A list of the layers.\n        \"\"\"", "\n", "return", "self", ".", "_encoder", ".", "layers", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.classifiers.conv_classifiers.Conv1DClassifier.layer_names": [[144, 149], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "layer_names", "(", "self", ")", ":", "\n", "        ", "\"\"\"A list of uniquified layer names.\n        \"\"\"", "\n", "return", "self", ".", "_encoder", ".", "layer_names", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.classifiers.conv_classifiers.Conv1DClassifier.layer_outputs_by_name": [[150, 158], ["conv_classifiers.Conv1DClassifier._encoder.layer_outputs_by_name"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.networks.network_base.FeedForwardNetworkBase.layer_outputs_by_name"], ["", "def", "layer_outputs_by_name", "(", "self", ",", "layer_name", ")", ":", "\n", "        ", "\"\"\"Returns the output tensors of the layer with the specified name.\n        Returns `None` if the layer name does not exist.\n\n        Args:\n            layer_name (str): Name of the layer.\n        \"\"\"", "\n", "return", "self", ".", "_encoder", ".", "layer_outputs_by_name", "(", "layer_name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.classifiers.conv_classifiers.Conv1DClassifier.layer_outputs": [[159, 164], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "layer_outputs", "(", "self", ")", ":", "\n", "        ", "\"\"\"A list containing output tensors of each layer.\n        \"\"\"", "\n", "return", "self", ".", "_encoder", ".", "layer_outputs", "\n", "", "", ""]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.classifiers.rnn_classifiers_test.UnidirectionalRNNClassifierTest.test_trainable_variables": [[24, 45], ["tensorflow.placeholder", "texar.modules.classifiers.rnn_classifiers.UnidirectionalRNNClassifier", "texar.modules.classifiers.rnn_classifiers.UnidirectionalRNNClassifier.", "rnn_classifiers_test.UnidirectionalRNNClassifierTest.assertEqual", "texar.modules.classifiers.rnn_classifiers.UnidirectionalRNNClassifier", "texar.modules.classifiers.rnn_classifiers.UnidirectionalRNNClassifier.", "rnn_classifiers_test.UnidirectionalRNNClassifierTest.assertEqual", "texar.modules.classifiers.rnn_classifiers.UnidirectionalRNNClassifier.", "rnn_classifiers_test.UnidirectionalRNNClassifierTest.assertEqual", "len", "len", "len"], "methods", ["None"], ["def", "test_trainable_variables", "(", "self", ")", ":", "\n", "        ", "\"\"\"Tests the functionality of automatically collecting trainable\n        variables.\n        \"\"\"", "\n", "inputs", "=", "tf", ".", "placeholder", "(", "dtype", "=", "tf", ".", "float32", ",", "shape", "=", "[", "None", ",", "None", ",", "100", "]", ")", "\n", "\n", "# case 1", "\n", "clas", "=", "UnidirectionalRNNClassifier", "(", ")", "\n", "_", ",", "_", "=", "clas", "(", "inputs", ")", "\n", "self", ".", "assertEqual", "(", "len", "(", "clas", ".", "trainable_variables", ")", ",", "2", "+", "2", ")", "\n", "\n", "# case 2", "\n", "hparams", "=", "{", "\n", "\"output_layer\"", ":", "{", "\"num_layers\"", ":", "2", "}", ",", "\n", "\"logit_layer_kwargs\"", ":", "{", "\"use_bias\"", ":", "False", "}", "\n", "}", "\n", "clas", "=", "UnidirectionalRNNClassifier", "(", "hparams", "=", "hparams", ")", "\n", "_", ",", "_", "=", "clas", "(", "inputs", ")", "\n", "self", ".", "assertEqual", "(", "len", "(", "clas", ".", "trainable_variables", ")", ",", "2", "+", "2", "+", "2", "+", "1", ")", "\n", "_", ",", "_", "=", "clas", "(", "inputs", ")", "\n", "self", ".", "assertEqual", "(", "len", "(", "clas", ".", "trainable_variables", ")", ",", "2", "+", "2", "+", "2", "+", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.classifiers.rnn_classifiers_test.UnidirectionalRNNClassifierTest.test_encode": [[46, 117], ["tensorflow.random_uniform", "texar.modules.classifiers.rnn_classifiers.UnidirectionalRNNClassifier", "texar.modules.classifiers.rnn_classifiers.UnidirectionalRNNClassifier.", "texar.modules.classifiers.rnn_classifiers.UnidirectionalRNNClassifier", "texar.modules.classifiers.rnn_classifiers.UnidirectionalRNNClassifier.", "texar.modules.classifiers.rnn_classifiers.UnidirectionalRNNClassifier", "texar.modules.classifiers.rnn_classifiers.UnidirectionalRNNClassifier.", "tensorflow.placeholder", "texar.modules.classifiers.rnn_classifiers.UnidirectionalRNNClassifier", "texar.modules.classifiers.rnn_classifiers.UnidirectionalRNNClassifier.", "rnn_classifiers_test.UnidirectionalRNNClassifierTest.test_session", "sess.run", "sess.run", "rnn_classifiers_test.UnidirectionalRNNClassifierTest.assertEqual", "rnn_classifiers_test.UnidirectionalRNNClassifierTest.assertEqual", "rnn_classifiers_test.UnidirectionalRNNClassifierTest.test_session", "sess.run", "sess.run", "rnn_classifiers_test.UnidirectionalRNNClassifierTest.assertEqual", "rnn_classifiers_test.UnidirectionalRNNClassifierTest.assertEqual", "rnn_classifiers_test.UnidirectionalRNNClassifierTest.test_session", "sess.run", "sess.run", "rnn_classifiers_test.UnidirectionalRNNClassifierTest.assertEqual", "rnn_classifiers_test.UnidirectionalRNNClassifierTest.assertEqual", "rnn_classifiers_test.UnidirectionalRNNClassifierTest.test_session", "sess.run", "sess.run", "rnn_classifiers_test.UnidirectionalRNNClassifierTest.assertEqual", "rnn_classifiers_test.UnidirectionalRNNClassifierTest.assertEqual", "tensorflow.global_variables_initializer", "tensorflow.global_variables_initializer", "tensorflow.global_variables_initializer", "tensorflow.global_variables_initializer", "numpy.random.randn"], "methods", ["None"], ["", "def", "test_encode", "(", "self", ")", ":", "\n", "        ", "\"\"\"Tests encoding.\n        \"\"\"", "\n", "max_time", "=", "8", "\n", "batch_size", "=", "16", "\n", "emb_dim", "=", "100", "\n", "inputs", "=", "tf", ".", "random_uniform", "(", "[", "batch_size", ",", "max_time", ",", "emb_dim", "]", ",", "\n", "maxval", "=", "1.", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "\n", "# case 1", "\n", "clas", "=", "UnidirectionalRNNClassifier", "(", ")", "\n", "logits", ",", "pred", "=", "clas", "(", "inputs", ")", "\n", "\n", "with", "self", ".", "test_session", "(", ")", "as", "sess", ":", "\n", "            ", "sess", ".", "run", "(", "tf", ".", "global_variables_initializer", "(", ")", ")", "\n", "logits_", ",", "pred_", "=", "sess", ".", "run", "(", "[", "logits", ",", "pred", "]", ")", "\n", "self", ".", "assertEqual", "(", "logits_", ".", "shape", ",", "(", "batch_size", ",", "clas", ".", "num_classes", ")", ")", "\n", "self", ".", "assertEqual", "(", "pred_", ".", "shape", ",", "(", "batch_size", ",", ")", ")", "\n", "\n", "# case 2", "\n", "", "hparams", "=", "{", "\n", "\"num_classes\"", ":", "10", ",", "\n", "\"clas_strategy\"", ":", "\"time_wise\"", "\n", "}", "\n", "clas", "=", "UnidirectionalRNNClassifier", "(", "hparams", "=", "hparams", ")", "\n", "logits", ",", "pred", "=", "clas", "(", "inputs", ")", "\n", "\n", "with", "self", ".", "test_session", "(", ")", "as", "sess", ":", "\n", "            ", "sess", ".", "run", "(", "tf", ".", "global_variables_initializer", "(", ")", ")", "\n", "logits_", ",", "pred_", "=", "sess", ".", "run", "(", "[", "logits", ",", "pred", "]", ")", "\n", "self", ".", "assertEqual", "(", "logits_", ".", "shape", ",", "\n", "(", "batch_size", ",", "max_time", ",", "clas", ".", "num_classes", ")", ")", "\n", "self", ".", "assertEqual", "(", "pred_", ".", "shape", ",", "(", "batch_size", ",", "max_time", ")", ")", "\n", "\n", "# case 3", "\n", "", "hparams", "=", "{", "\n", "\"output_layer\"", ":", "{", "\n", "\"num_layers\"", ":", "1", ",", "\n", "\"layer_size\"", ":", "10", "\n", "}", ",", "\n", "\"num_classes\"", ":", "0", ",", "\n", "\"clas_strategy\"", ":", "\"time_wise\"", "\n", "}", "\n", "clas", "=", "UnidirectionalRNNClassifier", "(", "hparams", "=", "hparams", ")", "\n", "logits", ",", "pred", "=", "clas", "(", "inputs", ")", "\n", "\n", "with", "self", ".", "test_session", "(", ")", "as", "sess", ":", "\n", "            ", "sess", ".", "run", "(", "tf", ".", "global_variables_initializer", "(", ")", ")", "\n", "logits_", ",", "pred_", "=", "sess", ".", "run", "(", "[", "logits", ",", "pred", "]", ")", "\n", "self", ".", "assertEqual", "(", "logits_", ".", "shape", ",", "\n", "(", "batch_size", ",", "max_time", ",", "10", ")", ")", "\n", "self", ".", "assertEqual", "(", "pred_", ".", "shape", ",", "(", "batch_size", ",", "max_time", ")", ")", "\n", "\n", "\n", "# case 4", "\n", "", "hparams", "=", "{", "\n", "\"num_classes\"", ":", "10", ",", "\n", "\"clas_strategy\"", ":", "\"all_time\"", ",", "\n", "\"max_seq_length\"", ":", "max_time", "\n", "}", "\n", "inputs", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "shape", "=", "[", "batch_size", ",", "6", ",", "emb_dim", "]", ")", "\n", "clas", "=", "UnidirectionalRNNClassifier", "(", "hparams", "=", "hparams", ")", "\n", "logits", ",", "pred", "=", "clas", "(", "inputs", ")", "\n", "\n", "with", "self", ".", "test_session", "(", ")", "as", "sess", ":", "\n", "            ", "sess", ".", "run", "(", "tf", ".", "global_variables_initializer", "(", ")", ")", "\n", "logits_", ",", "pred_", "=", "sess", ".", "run", "(", "\n", "[", "logits", ",", "pred", "]", ",", "\n", "feed_dict", "=", "{", "inputs", ":", "np", ".", "random", ".", "randn", "(", "batch_size", ",", "6", ",", "emb_dim", ")", "}", ")", "\n", "self", ".", "assertEqual", "(", "logits_", ".", "shape", ",", "(", "batch_size", ",", "clas", ".", "num_classes", ")", ")", "\n", "self", ".", "assertEqual", "(", "pred_", ".", "shape", ",", "(", "batch_size", ",", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.classifiers.classifier_base.ClassifierBase.__init__": [[20, 22], ["texar.module_base.ModuleBase.__init__"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.text_infilling.self_attn_hyperparams.Hyperparams.__init__"], ["def", "__init__", "(", "self", ",", "hparams", "=", "None", ")", ":", "\n", "        ", "ModuleBase", ".", "__init__", "(", "self", ",", "hparams", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.classifiers.classifier_base.ClassifierBase.default_hparams": [[23, 29], ["None"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "default_hparams", "(", ")", ":", "\n", "        ", "\"\"\"Returns a dictionary of hyperparameters with default values.\n        \"\"\"", "\n", "return", "{", "\n", "\"name\"", ":", "\"classifier\"", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.classifiers.classifier_base.ClassifierBase._build": [[31, 43], ["None"], "methods", ["None"], ["", "def", "_build", "(", "self", ",", "inputs", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"Classifies the inputs.\n\n        Args:\n          inputs: Inputs to the classifier.\n          *args: Other arguments.\n          **kwargs: Keyword arguments.\n\n        Returns:\n          Classification results.\n        \"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.classifiers.conv1d_discriminator.CNN.__init__": [[16, 37], ["texar.ModuleBase.__init__", "zip", "tensorflow.layers.Dense", "tensorflow.layers.Dense", "tensorflow.layers.Conv1D", "conv1d_discriminator.CNN._conv_layers.append", "tensorflow.variable_scope", "tensorflow.get_variable", "tensorflow.variable_scope", "tensorflow.get_variable"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.text_infilling.self_attn_hyperparams.Hyperparams.__init__", "home.repos.pwc.inspect_result.VegB_Text_Infilling.agents.agent_base.AgentBase.variable_scope", "home.repos.pwc.inspect_result.VegB_Text_Infilling.agents.agent_base.AgentBase.variable_scope"], ["def", "__init__", "(", "self", ",", "hparams", "=", "None", ")", ":", "\n", "    ", "ModuleBase", ".", "__init__", "(", "self", ",", "hparams", ")", "\n", "\n", "if", "self", ".", "_hparams", ".", "use_embedding", ":", "\n", "      ", "with", "tf", ".", "variable_scope", "(", "self", ".", "variable_scope", ")", ":", "\n", "        ", "self", ".", "_embedding", "=", "tf", ".", "get_variable", "(", "\"embedding\"", ",", "\n", "[", "self", ".", "_hparams", ".", "vocab_size", ",", "self", ".", "_hparams", ".", "embedding_size", "]", ")", "\n", "", "", "if", "self", ".", "_hparams", ".", "use_gate", ":", "\n", "      ", "self", ".", "_gate_proj", "=", "tf", ".", "layers", ".", "Dense", "(", "self", ".", "_hparams", ".", "attn_size", ")", "\n", "with", "tf", ".", "variable_scope", "(", "self", ".", "variable_scope", ")", ":", "\n", "        ", "self", ".", "_gate_u", "=", "tf", ".", "get_variable", "(", "\"u\"", ",", "[", "self", ".", "_hparams", ".", "attn_size", "]", ")", "\n", "", "", "self", ".", "_conv_layers", "=", "[", "]", "\n", "# for k in self._hparams.kernel_sizes:", "\n", "#   conv_layer = tf.layers.Conv1D(self._hparams.num_filter, k,", "\n", "#                                 padding='same')", "\n", "#   self._conv_layers.append(conv_layer)", "\n", "for", "filter_size", ",", "num_filter", "in", "zip", "(", "self", ".", "_hparams", ".", "kernel_sizes", ",", "[", "100", ",", "200", "]", ")", ":", "\n", "      ", "conv_layer", "=", "tf", ".", "layers", ".", "Conv1D", "(", "num_filter", ",", "filter_size", ",", "\n", "padding", "=", "'same'", ")", "\n", "self", ".", "_conv_layers", ".", "append", "(", "conv_layer", ")", "\n", "", "self", ".", "_proj_layer", "=", "tf", ".", "layers", ".", "Dense", "(", "2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.classifiers.conv1d_discriminator.CNN.default_hparams": [[38, 53], ["None"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "default_hparams", "(", ")", ":", "\n", "    ", "return", "{", "\n", "\"name\"", ":", "\"cnn\"", ",", "\n", "\"use_embedding\"", ":", "False", ",", "\n", "\"use_gate\"", ":", "False", ",", "\n", "\"scale_attn\"", ":", "False", ",", "\n", "\"attn_size\"", ":", "100", ",", "\n", "\"kernel_sizes\"", ":", "[", "3", ",", "4", ",", "5", "]", ",", "\n", "\"num_filter\"", ":", "128", ",", "\n", "\"output_keep_prob\"", ":", "0.5", ",", "\n", "\"input_keep_prob\"", ":", "1.", ",", "\n", "\"leaky_relu_alpha\"", ":", "0.01", ",", "\n", "\"vocab_size\"", ":", "10000", ",", "\n", "\"embedding_size\"", ":", "100", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.classifiers.conv1d_discriminator.CNN._build": [[56, 113], ["tensorflow.nn.dropout", "tensorflow.concat", "tensorflow.nn.dropout", "conv1d_discriminator.CNN._proj_layer", "conv1d_discriminator.CNN._add_internal_trainable_variables", "tensorflow.ones", "tensorflow.cast", "tensorflow.sequence_mask", "tensorflow.ones", "tensorflow.tanh", "tensorflow.nn.softmax", "texar.utils.mode.switch_dropout", "conv_layer", "tensorflow.nn.leaky_relu", "tensorflow.reduce_max", "pooled_outputs.append", "texar.utils.mode.switch_dropout", "tensorflow.nn.embedding_lookup", "conv1d_discriminator.CNN._gate_proj", "tensorflow.reduce_sum", "tensorflow.expand_dims", "tensorflow.expand_dims", "tensorflow.reshape.get_shape", "tensorflow.reshape.get_shape", "tensorflow.matmul", "tensorflow.reshape", "tensorflow.shape", "tensorflow.shape", "tensorflow.to_int32", "tensorflow.to_int32", "tensorflow.shape", "tensorflow.reduce_sum", "tensorflow.reshape.get_shape", "tensorflow.reshape", "tensorflow.shape", "tensorflow.reshape.get_shape"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.texar.module_base.ModuleBase._add_internal_trainable_variables", "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.mode.switch_dropout", "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.mode.switch_dropout"], ["", "def", "_build", "(", "self", ",", "inputs", ",", "seq_len", "=", "None", ",", "gamma", "=", "None", ")", ":", "\n", "    ", "if", "self", ".", "_hparams", ".", "use_embedding", ":", "\n", "      ", "if", "inputs", ".", "get_shape", "(", ")", ".", "ndims", "==", "2", ":", "\n", "        ", "inputs", "=", "tf", ".", "nn", ".", "embedding_lookup", "(", "self", ".", "_embedding", ",", "inputs", ")", "\n", "", "elif", "inputs", ".", "get_shape", "(", ")", ".", "ndims", "==", "3", ":", "\n", "        ", "inputs_shape", "=", "inputs", ".", "get_shape", "(", ")", "\n", "inputs", "=", "tf", ".", "matmul", "(", "tf", ".", "reshape", "(", "inputs", ",", "[", "-", "1", ",", "inputs_shape", "[", "-", "1", "]", "]", ")", ",", "\n", "self", ".", "_embedding", ")", "\n", "inputs", "=", "tf", ".", "reshape", "(", "inputs", ",", "[", "inputs_shape", "[", "0", "]", ",", "-", "1", ",", "inputs", ".", "get_shape", "(", ")", "[", "-", "1", "]", "]", ")", "\n", "\n", "", "", "scores", "=", "tf", ".", "ones", "(", "tf", ".", "shape", "(", "inputs", ")", "[", ":", "2", "]", ",", "tf", ".", "float32", ")", "/", "tf", ".", "cast", "(", "tf", ".", "shape", "(", "inputs", ")", "[", "1", "]", ",", "tf", ".", "float32", ")", "\n", "\n", "if", "seq_len", "is", "not", "None", ":", "\n", "      ", "mask", "=", "tf", ".", "sequence_mask", "(", "lengths", "=", "tf", ".", "to_int32", "(", "seq_len", ")", ",", "\n", "maxlen", "=", "tf", ".", "to_int32", "(", "tf", ".", "shape", "(", "inputs", ")", "[", "1", "]", ")", ",", "\n", "dtype", "=", "tf", ".", "float32", ")", "\n", "", "else", ":", "\n", "      ", "mask", "=", "tf", ".", "ones", "(", "tf", ".", "shape", "(", "inputs", ")", "[", ":", "2", "]", ",", "tf", ".", "float32", ")", "\n", "\n", "\n", "", "if", "self", ".", "_hparams", ".", "use_gate", ":", "\n", "      ", "proj", "=", "tf", ".", "tanh", "(", "self", ".", "_gate_proj", "(", "inputs", ")", ")", "\n", "if", "gamma", "is", "None", ":", "\n", "        ", "gamma", "=", "1.", "\n", "", "scores", "=", "tf", ".", "reduce_sum", "(", "self", ".", "_gate_u", "*", "proj", ",", "[", "2", "]", ")", "/", "gamma", "\n", "scores", "=", "scores", "*", "mask", "+", "(", "(", "1.0", "-", "mask", ")", "*", "tf", ".", "float32", ".", "min", ")", "\n", "scores", "=", "tf", ".", "nn", ".", "softmax", "(", "scores", ")", "\n", "if", "self", ".", "_hparams", ".", "scale_attn", ":", "\n", "        ", "scores", "=", "scores", "*", "tf", ".", "reduce_sum", "(", "mask", ",", "axis", "=", "1", ",", "keep_dims", "=", "True", ")", "\n", "", "inputs", "=", "tf", ".", "expand_dims", "(", "scores", ",", "2", ")", "*", "inputs", "\n", "", "else", ":", "\n", "      ", "inputs", "=", "tf", ".", "expand_dims", "(", "mask", ",", "2", ")", "*", "inputs", "\n", "\n", "\n", "# input keep prob??", "\n", "", "inputs", "=", "tf", ".", "nn", ".", "dropout", "(", "\n", "inputs", ",", "switch_dropout", "(", "self", ".", "_hparams", ".", "input_keep_prob", ")", ")", "\n", "\n", "pooled_outputs", "=", "[", "]", "\n", "for", "conv_layer", "in", "self", ".", "_conv_layers", ":", "\n", "      ", "h", "=", "conv_layer", "(", "inputs", ")", "\n", "h", "=", "tf", ".", "nn", ".", "leaky_relu", "(", "h", ",", "alpha", "=", "self", ".", "_hparams", ".", "leaky_relu_alpha", ")", "\n", "# pooling after conv", "\n", "h", "=", "tf", ".", "reduce_max", "(", "h", ",", "axis", "=", "1", ")", "\n", "pooled_outputs", ".", "append", "(", "h", ")", "\n", "\n", "", "outputs", "=", "tf", ".", "concat", "(", "pooled_outputs", ",", "1", ")", "\n", "outputs", "=", "tf", ".", "nn", ".", "dropout", "(", "\n", "outputs", ",", "switch_dropout", "(", "self", ".", "_hparams", ".", "output_keep_prob", ")", ")", "\n", "\n", "logits", "=", "self", ".", "_proj_layer", "(", "outputs", ")", "\n", "\n", "self", ".", "_add_internal_trainable_variables", "(", ")", "\n", "self", ".", "_built", "=", "True", "\n", "\n", "return", "logits", "\n", "", "", ""]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.networks.networks.FeedForwardNetwork.__init__": [[31, 37], ["texar.modules.networks.network_base.FeedForwardNetworkBase.__init__", "tensorflow.variable_scope", "texar.modules.networks.network_base._build_layers"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.text_infilling.self_attn_hyperparams.Hyperparams.__init__", "home.repos.pwc.inspect_result.VegB_Text_Infilling.agents.agent_base.AgentBase.variable_scope", "home.repos.pwc.inspect_result.VegB_Text_Infilling.networks.network_base._build_layers"], ["def", "__init__", "(", "self", ",", "layers", "=", "None", ",", "hparams", "=", "None", ")", ":", "\n", "        ", "FeedForwardNetworkBase", ".", "__init__", "(", "self", ",", "hparams", ")", "\n", "\n", "with", "tf", ".", "variable_scope", "(", "self", ".", "variable_scope", ")", ":", "\n", "            ", "_build_layers", "(", "\n", "self", ",", "layers", "=", "layers", ",", "layer_hparams", "=", "self", ".", "_hparams", ".", "layers", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.networks.networks.FeedForwardNetwork.default_hparams": [[39, 48], ["None"], "methods", ["None"], ["", "", "@", "staticmethod", "\n", "def", "default_hparams", "(", ")", ":", "\n", "        ", "\"\"\"Returns a dictionary of hyperparameters with default values.\n\n        TODO\n        \"\"\"", "\n", "return", "{", "\n", "\"layers\"", ":", "[", "]", ",", "\n", "\"name\"", ":", "\"NN\"", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.networks.network_base.FeedForwardNetworkBase.__init__": [[60, 68], ["texar.module_base.ModuleBase.__init__"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.text_infilling.self_attn_hyperparams.Hyperparams.__init__"], ["def", "__init__", "(", "self", ",", "hparams", "=", "None", ")", ":", "\n", "        ", "ModuleBase", ".", "__init__", "(", "self", ",", "hparams", ")", "\n", "\n", "self", ".", "_layers", "=", "[", "]", "\n", "self", ".", "_layer_names", "=", "[", "]", "\n", "self", ".", "_layers_by_name", "=", "{", "}", "\n", "self", ".", "_layer_outputs", "=", "[", "]", "\n", "self", ".", "_layer_outputs_by_name", "=", "{", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.networks.network_base.FeedForwardNetworkBase.default_hparams": [[69, 77], ["None"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "default_hparams", "(", ")", ":", "\n", "        ", "\"\"\"Returns a dictionary of hyperparameters with default values.\n\n        TODO\n        \"\"\"", "\n", "return", "{", "\n", "\"name\"", ":", "\"NN\"", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.networks.network_base.FeedForwardNetworkBase._build": [[79, 109], ["texar.utils.mode.is_train_mode", "enumerate", "network_base.FeedForwardNetworkBase._layer_outputs.append", "network_base.FeedForwardNetworkBase._add_internal_trainable_variables", "isinstance", "isinstance", "layer", "layer", "network_base.FeedForwardNetworkBase._add_trainable_variable"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.mode.is_train_mode", "home.repos.pwc.inspect_result.VegB_Text_Infilling.texar.module_base.ModuleBase._add_internal_trainable_variables", "home.repos.pwc.inspect_result.VegB_Text_Infilling.texar.module_base.ModuleBase._add_trainable_variable"], ["", "def", "_build", "(", "self", ",", "inputs", ",", "mode", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n\n        Args:\n            inputs:\n\n        Returns:\n        \"\"\"", "\n", "training", "=", "is_train_mode", "(", "mode", ")", "\n", "\n", "prev_outputs", "=", "inputs", "\n", "for", "layer_id", ",", "layer", "in", "enumerate", "(", "self", ".", "_layers", ")", ":", "\n", "            ", "if", "isinstance", "(", "layer", ",", "tf", ".", "layers", ".", "Dropout", ")", "or", "isinstance", "(", "layer", ",", "tf", ".", "layers", ".", "BatchNormalization", ")", ":", "\n", "                ", "outputs", "=", "layer", "(", "prev_outputs", ",", "training", "=", "training", ")", "\n", "", "else", ":", "\n", "                ", "outputs", "=", "layer", "(", "prev_outputs", ")", "\n", "", "self", ".", "_layer_outputs", ".", "append", "(", "outputs", ")", "\n", "self", ".", "_layer_outputs_by_name", "[", "self", ".", "_layer_names", "[", "layer_id", "]", "]", "=", "outputs", "\n", "prev_outputs", "=", "outputs", "\n", "\n", "", "if", "not", "self", ".", "_built", ":", "\n", "            ", "self", ".", "_add_internal_trainable_variables", "(", ")", "\n", "# Add trainable variables of `self._layers` which may be", "\n", "# constructed externally.", "\n", "for", "layer", "in", "self", ".", "_layers", ":", "\n", "                ", "self", ".", "_add_trainable_variable", "(", "layer", ".", "trainable_variables", ")", "\n", "", "self", ".", "_built", "=", "True", "\n", "\n", "", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.networks.network_base.FeedForwardNetworkBase.append_layer": [[110, 130], ["texar.utils.TexarError", "tensorflow.variable_scope", "network_base.FeedForwardNetworkBase._layers.append", "texar.utils.utils.uniquify_str", "network_base.FeedForwardNetworkBase._layer_names.append", "isinstance", "texar.core.layers.get_layer"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.agents.agent_base.AgentBase.variable_scope", "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.utils.uniquify_str", "home.repos.pwc.inspect_result.VegB_Text_Infilling.core.layers.get_layer"], ["", "def", "append_layer", "(", "self", ",", "layer", ")", ":", "\n", "        ", "\"\"\"Appends a layer to the end of the network. The method is only\n        feasible before :attr:`_build` is called.\n\n        Args:\n            layer: A :tf_main:`tf.layers.Layer <layers/Layer>` instance, or\n                a dict of layer hyperparameters.\n        \"\"\"", "\n", "if", "self", ".", "_built", ":", "\n", "            ", "raise", "TexarError", "(", "\"`FeedForwardNetwork.append_layer` can be \"", "\n", "\"called only before `_build` is called.\"", ")", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "self", ".", "variable_scope", ")", ":", "\n", "            ", "layer_", "=", "layer", "\n", "if", "not", "isinstance", "(", "layer_", ",", "tf", ".", "layers", ".", "Layer", ")", ":", "\n", "                ", "layer_", "=", "get_layer", "(", "hparams", "=", "layer_", ")", "\n", "", "self", ".", "_layers", ".", "append", "(", "layer_", ")", "\n", "layer_name", "=", "uniquify_str", "(", "layer_", ".", "name", ",", "self", ".", "_layer_names", ")", "\n", "self", ".", "_layer_names", ".", "append", "(", "layer_name", ")", "\n", "self", ".", "_layers_by_name", "[", "layer_name", "]", "=", "layer_", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.networks.network_base.FeedForwardNetworkBase.has_layer": [[131, 139], ["None"], "methods", ["None"], ["", "", "def", "has_layer", "(", "self", ",", "layer_name", ")", ":", "\n", "        ", "\"\"\"Returns `True` if the network with the name exists. Returns `False`\n        otherwise.\n\n        Args:\n            layer_name (str): Name of the layer.\n        \"\"\"", "\n", "return", "layer_name", "in", "self", ".", "_layers_by_name", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.networks.network_base.FeedForwardNetworkBase.layer_by_name": [[140, 148], ["network_base.FeedForwardNetworkBase._layers_by_name.get"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.core.replay_memories.DequeReplayMemory.get"], ["", "def", "layer_by_name", "(", "self", ",", "layer_name", ")", ":", "\n", "        ", "\"\"\"Returns the layer with the name. Returns 'None' if the layer name\n        does not exist.\n\n        Args:\n            layer_name (str): Name of the layer.\n        \"\"\"", "\n", "return", "self", ".", "_layers_by_name", ".", "get", "(", "layer_name", ",", "None", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.networks.network_base.FeedForwardNetworkBase.layers_by_name": [[149, 154], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "layers_by_name", "(", "self", ")", ":", "\n", "        ", "\"\"\"A dictionary mapping layer names to the layers.\n        \"\"\"", "\n", "return", "self", ".", "_layers_by_name", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.networks.network_base.FeedForwardNetworkBase.layers": [[155, 160], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "layers", "(", "self", ")", ":", "\n", "        ", "\"\"\"A list of the layers.\n        \"\"\"", "\n", "return", "self", ".", "_layers", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.networks.network_base.FeedForwardNetworkBase.layer_names": [[161, 166], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "layer_names", "(", "self", ")", ":", "\n", "        ", "\"\"\"A list of uniquified layer names.\n        \"\"\"", "\n", "return", "self", ".", "_layer_names", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.networks.network_base.FeedForwardNetworkBase.layer_outputs_by_name": [[167, 175], ["network_base.FeedForwardNetworkBase._layer_outputs_by_name.get"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.core.replay_memories.DequeReplayMemory.get"], ["", "def", "layer_outputs_by_name", "(", "self", ",", "layer_name", ")", ":", "\n", "        ", "\"\"\"Returns the output tensors of the layer with the specified name.\n        Returns `None` if the layer name does not exist.\n\n        Args:\n            layer_name (str): Name of the layer.\n        \"\"\"", "\n", "return", "self", ".", "_layer_outputs_by_name", ".", "get", "(", "layer_name", ",", "None", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.networks.network_base.FeedForwardNetworkBase.layer_outputs": [[176, 181], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "layer_outputs", "(", "self", ")", ":", "\n", "        ", "\"\"\"A list containing output tensors of each layer.\n        \"\"\"", "\n", "return", "self", ".", "_layer_outputs", "\n", "", "", ""]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.networks.network_base._build_layers": [[26, 55], ["tensorflow.variable_scope", "texar.utils.utils.uniquify_str", "network._layer_names.append", "enumerate", "ValueError", "network._layers.append", "texar.core.layers.get_layer"], "function", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.agents.agent_base.AgentBase.variable_scope", "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.utils.uniquify_str", "home.repos.pwc.inspect_result.VegB_Text_Infilling.core.layers.get_layer"], ["def", "_build_layers", "(", "network", ",", "layers", "=", "None", ",", "layer_hparams", "=", "None", ")", ":", "\n", "    ", "\"\"\"Builds layers.\n\n    Either :attr:`layer_hparams` or :attr:`layers` must be\n    provided. If both are given, :attr:`layers` will be used.\n\n    Args:\n        network: An instance of a subclass of\n            :class:`~texar.modules.networks.network_base.FeedForwardNetworkBase`\n        layers (optional): A list of layer instances.\n        layer_hparams (optional): A list of layer hparams, each to which\n            is fed to :func:`~texar.core.layers.get_layer` to create the\n            layer instance.\n    \"\"\"", "\n", "with", "tf", ".", "variable_scope", "(", "network", ".", "variable_scope", ")", ":", "\n", "        ", "if", "layers", "is", "not", "None", ":", "\n", "            ", "network", ".", "_layers", "=", "layers", "\n", "", "else", ":", "\n", "            ", "if", "layer_hparams", "is", "None", ":", "\n", "                ", "raise", "ValueError", "(", "\n", "'Either `layer` or `layer_hparams` is required.'", ")", "\n", "", "network", ".", "_layers", "=", "[", "]", "\n", "for", "_", ",", "hparams", "in", "enumerate", "(", "layer_hparams", ")", ":", "\n", "                ", "network", ".", "_layers", ".", "append", "(", "get_layer", "(", "hparams", "=", "hparams", ")", ")", "\n", "\n", "", "", "", "for", "layer", "in", "network", ".", "_layers", ":", "\n", "        ", "layer_name", "=", "uniquify_str", "(", "layer", ".", "name", ",", "network", ".", "_layer_names", ")", "\n", "network", ".", "_layer_names", ".", "append", "(", "layer_name", ")", "\n", "network", ".", "_layers_by_name", "[", "layer_name", "]", "=", "layer", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.networks.networks_test.FeedForwardNetworkTest.test_feedforward": [[20, 41], ["texar.modules.networks.networks.FeedForwardNetwork", "networks_test.FeedForwardNetworkTest.assertEqual", "texar.modules.networks.networks.FeedForwardNetwork.", "networks_test.FeedForwardNetworkTest.assertEqual", "networks_test.FeedForwardNetworkTest.assertEqual", "len", "len", "tensorflow.ones", "len", "len", "len", "len"], "methods", ["None"], ["def", "test_feedforward", "(", "self", ")", ":", "\n", "        ", "\"\"\"Tests feed-forward.\n        \"\"\"", "\n", "hparams", "=", "{", "\n", "\"layers\"", ":", "[", "\n", "{", "\n", "\"type\"", ":", "\"Dense\"", ",", "\n", "}", ",", "\n", "{", "\n", "\"type\"", ":", "\"Dense\"", ",", "\n", "}", "\n", "]", "\n", "}", "\n", "\n", "nn", "=", "FeedForwardNetwork", "(", "hparams", "=", "hparams", ")", "\n", "\n", "self", ".", "assertEqual", "(", "len", "(", "nn", ".", "layers", ")", ",", "len", "(", "hparams", "[", "\"layers\"", "]", ")", ")", "\n", "_", "=", "nn", "(", "tf", ".", "ones", "(", "[", "64", ",", "16", ",", "16", "]", ")", ")", "\n", "self", ".", "assertEqual", "(", "len", "(", "nn", ".", "trainable_variables", ")", ",", "\n", "len", "(", "hparams", "[", "\"layers\"", "]", ")", "*", "2", ")", "\n", "self", ".", "assertEqual", "(", "len", "(", "nn", ".", "layer_outputs", ")", ",", "len", "(", "hparams", "[", "\"layers\"", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.networks.conv_networks.Conv1DNetwork.__init__": [[49, 55], ["texar.modules.networks.network_base.FeedForwardNetworkBase.__init__", "tensorflow.variable_scope", "conv_networks.Conv1DNetwork._build_layer_hparams", "texar.modules.networks.network_base._build_layers"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.text_infilling.self_attn_hyperparams.Hyperparams.__init__", "home.repos.pwc.inspect_result.VegB_Text_Infilling.agents.agent_base.AgentBase.variable_scope", "home.repos.pwc.inspect_result.VegB_Text_Infilling.networks.conv_networks.Conv1DNetwork._build_layer_hparams", "home.repos.pwc.inspect_result.VegB_Text_Infilling.networks.network_base._build_layers"], ["def", "__init__", "(", "self", ",", "hparams", "=", "None", ")", ":", "\n", "        ", "FeedForwardNetworkBase", ".", "__init__", "(", "self", ",", "hparams", ")", "\n", "\n", "with", "tf", ".", "variable_scope", "(", "self", ".", "variable_scope", ")", ":", "\n", "            ", "layer_hparams", "=", "self", ".", "_build_layer_hparams", "(", ")", "\n", "_build_layers", "(", "self", ",", "layers", "=", "None", ",", "layer_hparams", "=", "layer_hparams", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.networks.conv_networks.Conv1DNetwork.default_hparams": [[56, 93], ["None"], "methods", ["None"], ["", "", "@", "staticmethod", "\n", "def", "default_hparams", "(", ")", ":", "\n", "        ", "\"\"\"Returns a dictionary of hyperparameters with default values.\n\n        TODO\n        \"\"\"", "\n", "return", "{", "\n", "# Conv layers", "\n", "\"num_conv_layers\"", ":", "1", ",", "\n", "\"filters\"", ":", "128", ",", "\n", "\"kernel_size\"", ":", "[", "3", ",", "4", ",", "5", "]", ",", "\n", "\"conv_activation\"", ":", "\"relu\"", ",", "\n", "\"conv_activation_kwargs\"", ":", "None", ",", "\n", "\"other_conv_kwargs\"", ":", "None", ",", "\n", "# Pooling layers", "\n", "\"pooling\"", ":", "\"MaxPooling1D\"", ",", "\n", "\"pool_size\"", ":", "None", ",", "\n", "\"pool_strides\"", ":", "1", ",", "\n", "\"other_pool_kwargs\"", ":", "None", ",", "\n", "# Dense layers", "\n", "\"num_dense_layers\"", ":", "1", ",", "\n", "\"dense_size\"", ":", "128", ",", "\n", "\"dense_activation\"", ":", "\"identity\"", ",", "\n", "\"dense_activation_kwargs\"", ":", "None", ",", "\n", "\"final_dense_activation\"", ":", "None", ",", "\n", "\"final_dense_activation_kwargs\"", ":", "None", ",", "\n", "\"other_dense_kwargs\"", ":", "None", ",", "\n", "# Dropout", "\n", "\"dropout_conv\"", ":", "[", "1", "]", ",", "\n", "\"dropout_dense\"", ":", "[", "]", ",", "\n", "\"dropout_rate\"", ":", "0.75", ",", "\n", "# Others", "\n", "\"name\"", ":", "\"conv1d_network\"", ",", "\n", "\"@no_typecheck\"", ":", "[", "\"filters\"", ",", "\"kernel_size\"", ",", "\"conv_activation\"", ",", "\n", "\"pool_size\"", ",", "\"pool_strides\"", ",", "\n", "\"dense_size\"", ",", "\"dense_activation\"", ",", "\n", "\"dropout_conv\"", ",", "\"dropout_dense\"", "]", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.networks.conv_networks.Conv1DNetwork._build_pool_hparams": [[95, 122], ["conv_networks._to_list", "conv_networks._to_list", "isinstance", "range", "other_kwargs.todict.todict.todict", "isinstance", "ValueError", "kwargs_i.update", "texar.core.layers.get_pooling_layer_hparams", "pool_hparams.append"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.networks.conv_networks._to_list", "home.repos.pwc.inspect_result.VegB_Text_Infilling.networks.conv_networks._to_list", "home.repos.pwc.inspect_result.VegB_Text_Infilling.texar.hyperparams.HParams.todict", "home.repos.pwc.inspect_result.VegB_Text_Infilling.core.layers.get_pooling_layer_hparams"], ["", "def", "_build_pool_hparams", "(", "self", ")", ":", "\n", "        ", "pool_type", "=", "self", ".", "_hparams", ".", "pooling", "\n", "if", "pool_type", "==", "\"MaxPooling\"", ":", "\n", "            ", "pool_type", "=", "\"MaxPooling1D\"", "\n", "", "elif", "pool_type", "==", "\"AveragePooling\"", ":", "\n", "            ", "pool_type", "=", "\"AveragePooling1D\"", "\n", "\n", "", "npool", "=", "self", ".", "_hparams", ".", "num_conv_layers", "\n", "pool_size", "=", "_to_list", "(", "self", ".", "_hparams", ".", "pool_size", ",", "\"pool_size\"", ",", "npool", ")", "\n", "strides", "=", "_to_list", "(", "self", ".", "_hparams", ".", "pool_strides", ",", "\"pool_strides\"", ",", "npool", ")", "\n", "\n", "other_kwargs", "=", "self", ".", "_hparams", ".", "other_pool_kwargs", "or", "{", "}", "\n", "if", "isinstance", "(", "other_kwargs", ",", "HParams", ")", ":", "\n", "            ", "other_kwargs", "=", "other_kwargs", ".", "todict", "(", ")", "\n", "", "if", "not", "isinstance", "(", "other_kwargs", ",", "dict", ")", ":", "\n", "            ", "raise", "ValueError", "(", "\"hparams['other_pool_kwargs'] must be a dict.\"", ")", "\n", "\n", "", "pool_hparams", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "npool", ")", ":", "\n", "            ", "kwargs_i", "=", "{", "\"pool_size\"", ":", "pool_size", "[", "i", "]", ",", "\"strides\"", ":", "strides", "[", "i", "]", ",", "\n", "\"name\"", ":", "\"pool_%d\"", "%", "(", "i", "+", "1", ")", "}", "\n", "kwargs_i", ".", "update", "(", "other_kwargs", ")", "\n", "pool_hparams_", "=", "get_pooling_layer_hparams", "(", "{", "\"type\"", ":", "pool_type", ",", "\n", "\"kwargs\"", ":", "kwargs_i", "}", ")", "\n", "pool_hparams", ".", "append", "(", "pool_hparams_", ")", "\n", "\n", "", "return", "pool_hparams", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.networks.conv_networks.Conv1DNetwork._build_conv1d_hparams": [[123, 180], ["conv_networks._to_list", "isinstance", "texar.core.layers.get_activation_fn", "range", "len", "ValueError", "conv_networks._to_list", "other_kwargs.todict.todict.todict", "isinstance", "ValueError", "isinstance", "conv_networks._to_list", "texar.utils.utils.uniquify_str", "names.append", "conv_kwargs_ij.update", "hparams_i.append", "len", "conv_pool_hparams.append", "conv_pool_hparams.append", "conv_networks._to_list", "mrg_kwargs_layers.append"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.networks.conv_networks._to_list", "home.repos.pwc.inspect_result.VegB_Text_Infilling.core.layers.get_activation_fn", "home.repos.pwc.inspect_result.VegB_Text_Infilling.networks.conv_networks._to_list", "home.repos.pwc.inspect_result.VegB_Text_Infilling.texar.hyperparams.HParams.todict", "home.repos.pwc.inspect_result.VegB_Text_Infilling.networks.conv_networks._to_list", "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.utils.uniquify_str", "home.repos.pwc.inspect_result.VegB_Text_Infilling.networks.conv_networks._to_list"], ["", "def", "_build_conv1d_hparams", "(", "self", ",", "pool_hparams", ")", ":", "\n", "        ", "\"\"\"Creates the hparams for each of the conv layers usable for\n        :func:`texar.core.layers.get_layer`.\n        \"\"\"", "\n", "nconv", "=", "self", ".", "_hparams", ".", "num_conv_layers", "\n", "if", "len", "(", "pool_hparams", ")", "!=", "nconv", ":", "\n", "            ", "raise", "ValueError", "(", "\"`pool_hparams` must be of length %d\"", "%", "nconv", ")", "\n", "\n", "", "filters", "=", "_to_list", "(", "self", ".", "_hparams", ".", "filters", ",", "'filters'", ",", "nconv", ")", "\n", "if", "nconv", "==", "1", ":", "\n", "            ", "kernel_size", "=", "_to_list", "(", "self", ".", "_hparams", ".", "kernel_size", ")", "\n", "if", "not", "isinstance", "(", "kernel_size", "[", "0", "]", ",", "(", "list", ",", "tuple", ")", ")", ":", "\n", "                ", "kernel_size", "=", "[", "kernel_size", "]", "\n", "", "", "elif", "nconv", ">", "1", ":", "\n", "            ", "kernel_size", "=", "_to_list", "(", "self", ".", "_hparams", ".", "kernel_size", ",", "\n", "'kernel_size'", ",", "nconv", ")", "\n", "kernel_size", "=", "[", "_to_list", "(", "ks", ")", "for", "ks", "in", "kernel_size", "]", "\n", "\n", "", "other_kwargs", "=", "self", ".", "_hparams", ".", "other_conv_kwargs", "or", "{", "}", "\n", "if", "isinstance", "(", "other_kwargs", ",", "HParams", ")", ":", "\n", "            ", "other_kwargs", "=", "other_kwargs", ".", "todict", "(", ")", "\n", "", "if", "not", "isinstance", "(", "other_kwargs", ",", "dict", ")", ":", "\n", "            ", "raise", "ValueError", "(", "\"hparams['other_conv_kwargs'] must be a dict.\"", ")", "\n", "\n", "", "conv_pool_hparams", "=", "[", "]", "\n", "activation_fn", "=", "get_activation_fn", "(", "\n", "self", ".", "_hparams", ".", "conv_activation", ",", "\n", "self", ".", "_hparams", ".", "conv_activation_kwargs", ")", "\n", "for", "i", "in", "range", "(", "nconv", ")", ":", "\n", "            ", "hparams_i", "=", "[", "]", "\n", "names", "=", "[", "]", "\n", "for", "ks_ij", "in", "kernel_size", "[", "i", "]", ":", "\n", "                ", "name", "=", "uniquify_str", "(", "\"conv_%d\"", "%", "(", "i", "+", "1", ")", ",", "names", ")", "\n", "names", ".", "append", "(", "name", ")", "\n", "conv_kwargs_ij", "=", "{", "\n", "\"filters\"", ":", "filters", "[", "i", "]", ",", "\n", "\"kernel_size\"", ":", "ks_ij", ",", "\n", "\"activation\"", ":", "activation_fn", ",", "\n", "\"name\"", ":", "name", "\n", "}", "\n", "conv_kwargs_ij", ".", "update", "(", "other_kwargs", ")", "\n", "hparams_i", ".", "append", "(", "\n", "{", "\"type\"", ":", "\"Conv1D\"", ",", "\"kwargs\"", ":", "conv_kwargs_ij", "}", ")", "\n", "", "if", "len", "(", "hparams_i", ")", "==", "1", ":", "\n", "                ", "conv_pool_hparams", ".", "append", "(", "[", "hparams_i", "[", "0", "]", ",", "pool_hparams", "[", "i", "]", "]", ")", "\n", "", "else", ":", "# creates MergeLayer", "\n", "                ", "mrg_kwargs_layers", "=", "[", "]", "\n", "for", "hparams_ij", "in", "hparams_i", ":", "\n", "                    ", "seq_kwargs_j", "=", "{", "\"layers\"", ":", "[", "hparams_ij", ",", "pool_hparams", "[", "i", "]", "]", "}", "\n", "mrg_kwargs_layers", ".", "append", "(", "\n", "{", "\"type\"", ":", "\"SequentialLayer\"", ",", "\"kwargs\"", ":", "seq_kwargs_j", "}", ")", "\n", "", "mrg_hparams", "=", "{", "\"type\"", ":", "\"MergeLayer\"", ",", "\n", "\"kwargs\"", ":", "{", "\"layers\"", ":", "mrg_kwargs_layers", ",", "\n", "\"name\"", ":", "\"conv_pool_%d\"", "%", "(", "i", "+", "1", ")", "}", "}", "\n", "conv_pool_hparams", ".", "append", "(", "mrg_hparams", ")", "\n", "\n", "", "", "return", "conv_pool_hparams", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.networks.conv_networks.Conv1DNetwork._build_dense_hparams": [[181, 209], ["conv_networks._to_list", "isinstance", "texar.core.layers.get_activation_fn", "range", "other_kwargs.todict.todict.todict", "isinstance", "ValueError", "kwargs_i.update", "dense_hparams.append", "texar.core.layers.get_activation_fn"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.networks.conv_networks._to_list", "home.repos.pwc.inspect_result.VegB_Text_Infilling.core.layers.get_activation_fn", "home.repos.pwc.inspect_result.VegB_Text_Infilling.texar.hyperparams.HParams.todict", "home.repos.pwc.inspect_result.VegB_Text_Infilling.core.layers.get_activation_fn"], ["", "def", "_build_dense_hparams", "(", "self", ")", ":", "\n", "        ", "ndense", "=", "self", ".", "_hparams", ".", "num_dense_layers", "\n", "dense_size", "=", "_to_list", "(", "self", ".", "_hparams", ".", "dense_size", ",", "'dense_size'", ",", "ndense", ")", "\n", "\n", "other_kwargs", "=", "self", ".", "_hparams", ".", "other_dense_kwargs", "or", "{", "}", "\n", "if", "isinstance", "(", "other_kwargs", ",", "HParams", ")", ":", "\n", "            ", "other_kwargs", "=", "other_kwargs", ".", "todict", "(", ")", "\n", "", "if", "not", "isinstance", "(", "other_kwargs", ",", "dict", ")", ":", "\n", "            ", "raise", "ValueError", "(", "\"hparams['other_dense_kwargs'] must be a dict.\"", ")", "\n", "\n", "", "dense_hparams", "=", "[", "]", "\n", "activation_fn", "=", "get_activation_fn", "(", "\n", "self", ".", "_hparams", ".", "dense_activation", ",", "\n", "self", ".", "_hparams", ".", "dense_activation_kwargs", ")", "\n", "for", "i", "in", "range", "(", "ndense", ")", ":", "\n", "            ", "if", "i", "==", "ndense", "-", "1", ":", "\n", "                ", "activation_fn", "=", "get_activation_fn", "(", "\n", "self", ".", "_hparams", ".", "final_dense_activation", ",", "\n", "self", ".", "_hparams", ".", "final_dense_activation_kwargs", ")", "\n", "\n", "", "kwargs_i", "=", "{", "\"units\"", ":", "dense_size", "[", "i", "]", ",", "\n", "\"activation\"", ":", "activation_fn", ",", "\n", "\"name\"", ":", "\"dense_%d\"", "%", "(", "i", "+", "1", ")", "}", "\n", "kwargs_i", ".", "update", "(", "other_kwargs", ")", "\n", "\n", "dense_hparams", ".", "append", "(", "{", "\"type\"", ":", "\"Dense\"", ",", "\"kwargs\"", ":", "kwargs_i", "}", ")", "\n", "\n", "", "return", "dense_hparams", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.networks.conv_networks.Conv1DNetwork._build_layer_hparams": [[210, 245], ["conv_networks.Conv1DNetwork._build_pool_hparams", "conv_networks.Conv1DNetwork._build_conv1d_hparams", "conv_networks.Conv1DNetwork._build_dense_hparams", "conv_networks._to_list", "conv_networks._to_list", "range", "range", "isinstance", "layers_hparams.append", "layers_hparams.append", "layers_hparams.append", "layers_hparams.append", "layers_hparams.append", "layers_hparams.append", "conv_networks.Conv1DNetwork._build_layer_hparams._dropout_hparams"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.networks.conv_networks.Conv1DNetwork._build_pool_hparams", "home.repos.pwc.inspect_result.VegB_Text_Infilling.networks.conv_networks.Conv1DNetwork._build_conv1d_hparams", "home.repos.pwc.inspect_result.VegB_Text_Infilling.networks.conv_networks.Conv1DNetwork._build_dense_hparams", "home.repos.pwc.inspect_result.VegB_Text_Infilling.networks.conv_networks._to_list", "home.repos.pwc.inspect_result.VegB_Text_Infilling.networks.conv_networks._to_list"], ["", "def", "_build_layer_hparams", "(", "self", ")", ":", "\n", "        ", "pool_hparams", "=", "self", ".", "_build_pool_hparams", "(", ")", "\n", "conv_pool_hparams", "=", "self", ".", "_build_conv1d_hparams", "(", "pool_hparams", ")", "\n", "dense_hparams", "=", "self", ".", "_build_dense_hparams", "(", ")", "\n", "\n", "def", "_dropout_hparams", "(", "layer_id", ")", ":", "\n", "            ", "return", "{", "\"type\"", ":", "\"Dropout\"", ",", "\n", "\"kwargs\"", ":", "{", "\"rate\"", ":", "self", ".", "_hparams", ".", "dropout_rate", ",", "\n", "\"name\"", ":", "\"dropout_%d\"", "%", "layer_id", "}", "}", "\n", "", "dropout_conv", "=", "_to_list", "(", "self", ".", "_hparams", ".", "dropout_conv", ")", "\n", "dropout_dense", "=", "_to_list", "(", "self", ".", "_hparams", ".", "dropout_dense", ")", "\n", "\n", "layers_hparams", "=", "[", "]", "\n", "nconv", "=", "self", ".", "_hparams", ".", "num_conv_layers", "\n", "for", "conv_i", "in", "range", "(", "nconv", ")", ":", "\n", "            ", "if", "conv_i", "in", "dropout_conv", ":", "\n", "                ", "layers_hparams", ".", "append", "(", "_dropout_hparams", "(", "conv_i", ")", ")", "\n", "", "if", "isinstance", "(", "conv_pool_hparams", "[", "conv_i", "]", ",", "(", "list", ",", "tuple", ")", ")", ":", "\n", "                ", "layers_hparams", "+=", "conv_pool_hparams", "[", "conv_i", "]", "\n", "", "else", ":", "\n", "                ", "layers_hparams", ".", "append", "(", "conv_pool_hparams", "[", "conv_i", "]", ")", "\n", "", "", "if", "nconv", "in", "dropout_conv", ":", "\n", "            ", "layers_hparams", ".", "append", "(", "_dropout_hparams", "(", "nconv", ")", ")", "\n", "\n", "", "ndense", "=", "self", ".", "_hparams", ".", "num_dense_layers", "\n", "if", "ndense", ">", "0", ":", "# Add flatten layers before dense layers", "\n", "            ", "layers_hparams", ".", "append", "(", "{", "\"type\"", ":", "\"Flatten\"", "}", ")", "\n", "", "for", "dense_i", "in", "range", "(", "ndense", ")", ":", "\n", "            ", "if", "dense_i", "in", "dropout_dense", ":", "\n", "                ", "layers_hparams", ".", "append", "(", "_dropout_hparams", "(", "dense_i", "+", "nconv", ")", ")", "\n", "", "layers_hparams", ".", "append", "(", "dense_hparams", "[", "dense_i", "]", ")", "\n", "", "if", "ndense", "in", "dropout_dense", ":", "\n", "            ", "layers_hparams", ".", "append", "(", "_dropout_hparams", "(", "ndense", "+", "nconv", ")", ")", "\n", "\n", "", "return", "layers_hparams", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.networks.conv_networks.Conv1DNetwork._build": [[246, 257], ["super()._build", "texar.utils.shapes.mask_sequences"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.seq2seq.seq2seq_base.Seq2seqBase._build", "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.shapes.mask_sequences"], ["", "def", "_build", "(", "self", ",", "# pylint: disable=arguments-differ", "\n", "inputs", ",", "\n", "sequence_length", "=", "None", ",", "\n", "dtype", "=", "None", ",", "\n", "time_major", "=", "False", ",", "\n", "mode", "=", "None", ")", ":", "\n", "        ", "if", "sequence_length", "is", "not", "None", ":", "\n", "            ", "inputs", "=", "mask_sequences", "(", "\n", "inputs", ",", "sequence_length", ",", "dtype", "=", "dtype", ",", "time_major", "=", "time_major", ",", "\n", "tensor_rank", "=", "3", ")", "\n", "", "return", "super", "(", "Conv1DNetwork", ",", "self", ")", ".", "_build", "(", "inputs", ",", "mode", "=", "mode", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.networks.conv_networks._to_list": [[26, 43], ["isinstance", "ValueError", "len"], "function", ["None"], ["def", "_to_list", "(", "value", ",", "name", "=", "None", ",", "list_length", "=", "None", ")", ":", "\n", "    ", "\"\"\"Converts hparam value into a list.\n\n    If :attr:`list_length` is given,\n    then the canonicalized :attr:`value` must be of\n    length :attr:`list_length`.\n    \"\"\"", "\n", "if", "not", "isinstance", "(", "value", ",", "(", "list", ",", "tuple", ")", ")", ":", "\n", "        ", "if", "list_length", "is", "not", "None", ":", "\n", "            ", "value", "=", "[", "value", "]", "*", "list_length", "\n", "", "else", ":", "\n", "            ", "value", "=", "[", "value", "]", "\n", "", "", "if", "list_length", "is", "not", "None", "and", "len", "(", "value", ")", "!=", "list_length", ":", "\n", "        ", "name", "=", "''", "if", "name", "is", "None", "else", "name", "\n", "raise", "ValueError", "(", "\"hparams '%s' must be a list of length %d\"", "\n", "%", "(", "name", ",", "list_length", ")", ")", "\n", "", "return", "value", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.networks.conv_networks_test.Conv1DNetworkTest.test_feedforward": [[21, 65], ["texar.modules.networks.conv_networks.Conv1DNetwork", "conv_networks_test.Conv1DNetworkTest.assertEqual", "conv_networks_test.Conv1DNetworkTest.assertTrue", "tensorflow.ones", "texar.modules.networks.conv_networks.Conv1DNetwork.", "conv_networks_test.Conv1DNetworkTest.assertEqual", "texar.modules.networks.conv_networks.Conv1DNetwork", "conv_networks_test.Conv1DNetworkTest.assertEqual", "conv_networks_test.Conv1DNetworkTest.assertTrue", "tensorflow.ones", "texar.modules.networks.conv_networks.Conv1DNetwork.", "conv_networks_test.Conv1DNetworkTest.assertEqual", "len", "isinstance", "conv_networks_test.Conv1DNetworkTest.assertTrue", "len", "isinstance", "conv_networks_test.Conv1DNetworkTest.assertTrue", "texar.modules.networks.conv_networks.Conv1DNetwork.layer_by_name", "isinstance", "texar.modules.networks.conv_networks.Conv1DNetwork.layer_by_name", "isinstance"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.networks.network_base.FeedForwardNetworkBase.layer_by_name", "home.repos.pwc.inspect_result.VegB_Text_Infilling.networks.network_base.FeedForwardNetworkBase.layer_by_name"], ["def", "test_feedforward", "(", "self", ")", ":", "\n", "        ", "\"\"\"Tests feed forward.\n        \"\"\"", "\n", "network_1", "=", "Conv1DNetwork", "(", ")", "\n", "self", ".", "assertEqual", "(", "len", "(", "network_1", ".", "layers", ")", ",", "4", ")", "\n", "self", ".", "assertTrue", "(", "isinstance", "(", "network_1", ".", "layer_by_name", "(", "\"conv_pool_1\"", ")", ",", "\n", "tx", ".", "core", ".", "MergeLayer", ")", ")", "\n", "for", "layer", "in", "network_1", ".", "layers", "[", "0", "]", ".", "layers", ":", "\n", "            ", "self", ".", "assertTrue", "(", "isinstance", "(", "layer", ",", "tx", ".", "core", ".", "SequentialLayer", ")", ")", "\n", "\n", "", "inputs_1", "=", "tf", ".", "ones", "(", "[", "64", ",", "16", ",", "300", "]", ",", "tf", ".", "float32", ")", "\n", "outputs_1", "=", "network_1", "(", "inputs_1", ")", "\n", "self", ".", "assertEqual", "(", "outputs_1", ".", "shape", ",", "[", "64", ",", "128", "]", ")", "\n", "\n", "hparams", "=", "{", "\n", "# Conv layers", "\n", "\"num_conv_layers\"", ":", "2", ",", "\n", "\"filters\"", ":", "128", ",", "\n", "\"kernel_size\"", ":", "[", "[", "3", ",", "4", ",", "5", "]", ",", "4", "]", ",", "\n", "\"other_conv_kwargs\"", ":", "{", "\"padding\"", ":", "\"same\"", "}", ",", "\n", "# Pooling layers", "\n", "\"pooling\"", ":", "\"AveragePooling\"", ",", "\n", "\"pool_size\"", ":", "2", ",", "\n", "\"pool_strides\"", ":", "1", ",", "\n", "# Dense layers", "\n", "\"num_dense_layers\"", ":", "3", ",", "\n", "\"dense_size\"", ":", "[", "128", ",", "128", ",", "10", "]", ",", "\n", "\"dense_activation\"", ":", "\"relu\"", ",", "\n", "\"other_dense_kwargs\"", ":", "{", "\"use_bias\"", ":", "False", "}", ",", "\n", "# Dropout", "\n", "\"dropout_conv\"", ":", "[", "0", ",", "1", ",", "2", "]", ",", "\n", "\"dropout_dense\"", ":", "2", "\n", "}", "\n", "network_2", "=", "Conv1DNetwork", "(", "hparams", ")", "\n", "# nlayers = nconv-pool + nconv + npool + ndense + ndropout + flatten", "\n", "self", ".", "assertEqual", "(", "len", "(", "network_2", ".", "layers", ")", ",", "1", "+", "1", "+", "1", "+", "3", "+", "4", "+", "1", ")", "\n", "self", ".", "assertTrue", "(", "isinstance", "(", "network_2", ".", "layer_by_name", "(", "\"conv_pool_1\"", ")", ",", "\n", "tx", ".", "core", ".", "MergeLayer", ")", ")", "\n", "for", "layer", "in", "network_2", ".", "layers", "[", "1", "]", ".", "layers", ":", "\n", "            ", "self", ".", "assertTrue", "(", "isinstance", "(", "layer", ",", "tx", ".", "core", ".", "SequentialLayer", ")", ")", "\n", "\n", "", "inputs_2", "=", "tf", ".", "ones", "(", "[", "64", ",", "16", ",", "300", "]", ",", "tf", ".", "float32", ")", "\n", "outputs_2", "=", "network_2", "(", "inputs_2", ")", "\n", "self", ".", "assertEqual", "(", "outputs_2", ".", "shape", ",", "[", "64", ",", "10", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.networks.conv_networks_test.Conv1DNetworkTest.test_unknown_seq_length": [[66, 114], ["texar.modules.networks.conv_networks.Conv1DNetwork", "tensorflow.placeholder", "texar.modules.networks.conv_networks.Conv1DNetwork.", "conv_networks_test.Conv1DNetworkTest.assertEqual", "texar.modules.networks.conv_networks.Conv1DNetwork", "conv_networks_test.Conv1DNetworkTest.assertEqual", "conv_networks_test.Conv1DNetworkTest.assertTrue", "tensorflow.placeholder", "texar.modules.networks.conv_networks.Conv1DNetwork.", "conv_networks_test.Conv1DNetworkTest.assertEqual", "texar.modules.networks.conv_networks.Conv1DNetwork", "tensorflow.placeholder", "texar.modules.networks.conv_networks.Conv1DNetwork.", "conv_networks_test.Conv1DNetworkTest.assertEqual", "len", "isinstance", "texar.modules.networks.conv_networks.Conv1DNetwork.layer_by_name"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.networks.network_base.FeedForwardNetworkBase.layer_by_name"], ["", "def", "test_unknown_seq_length", "(", "self", ")", ":", "\n", "        ", "\"\"\"Tests use of pooling layer when the seq_length dimension of inputs\n        is `None`.\n        \"\"\"", "\n", "network_1", "=", "Conv1DNetwork", "(", ")", "\n", "inputs_1", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "[", "64", ",", "None", ",", "300", "]", ")", "\n", "outputs_1", "=", "network_1", "(", "inputs_1", ")", "\n", "self", ".", "assertEqual", "(", "outputs_1", ".", "shape", ",", "[", "64", ",", "128", "]", ")", "\n", "\n", "hparams", "=", "{", "\n", "# Conv layers", "\n", "\"num_conv_layers\"", ":", "2", ",", "\n", "\"filters\"", ":", "128", ",", "\n", "\"kernel_size\"", ":", "[", "[", "3", ",", "4", ",", "5", "]", ",", "4", "]", ",", "\n", "# Pooling layers", "\n", "\"pooling\"", ":", "\"AveragePooling\"", ",", "\n", "\"pool_size\"", ":", "[", "2", ",", "None", "]", ",", "\n", "# Dense layers", "\n", "\"num_dense_layers\"", ":", "1", ",", "\n", "\"dense_size\"", ":", "10", ",", "\n", "}", "\n", "network", "=", "Conv1DNetwork", "(", "hparams", ")", "\n", "# nlayers = nconv-pool + nconv + npool + ndense + ndropout + flatten", "\n", "self", ".", "assertEqual", "(", "len", "(", "network", ".", "layers", ")", ",", "1", "+", "1", "+", "1", "+", "1", "+", "1", "+", "1", ")", "\n", "self", ".", "assertTrue", "(", "isinstance", "(", "network", ".", "layer_by_name", "(", "'pool_2'", ")", ",", "\n", "tx", ".", "core", ".", "AverageReducePooling1D", ")", ")", "\n", "\n", "inputs", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "[", "64", ",", "None", ",", "300", "]", ")", "\n", "outputs", "=", "network", "(", "inputs", ")", "\n", "self", ".", "assertEqual", "(", "outputs", ".", "shape", ",", "[", "64", ",", "10", "]", ")", "\n", "\n", "hparams_2", "=", "{", "\n", "# Conv layers", "\n", "\"num_conv_layers\"", ":", "1", ",", "\n", "\"filters\"", ":", "128", ",", "\n", "\"kernel_size\"", ":", "4", ",", "\n", "\"other_conv_kwargs\"", ":", "{", "'data_format'", ":", "'channels_first'", "}", ",", "\n", "# Pooling layers", "\n", "\"pooling\"", ":", "\"MaxPooling\"", ",", "\n", "\"other_pool_kwargs\"", ":", "{", "'data_format'", ":", "'channels_first'", "}", ",", "\n", "# Dense layers", "\n", "\"num_dense_layers\"", ":", "1", ",", "\n", "\"dense_size\"", ":", "10", ",", "\n", "}", "\n", "network_2", "=", "Conv1DNetwork", "(", "hparams_2", ")", "\n", "inputs_2", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "[", "64", ",", "300", ",", "None", "]", ")", "\n", "outputs_2", "=", "network_2", "(", "inputs_2", ")", "\n", "self", ".", "assertEqual", "(", "outputs_2", ".", "shape", ",", "[", "64", ",", "10", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.networks.conv_networks_test.Conv1DNetworkTest.test_mask_input": [[115, 123], ["texar.modules.networks.conv_networks.Conv1DNetwork", "tensorflow.ones", "texar.modules.networks.conv_networks.Conv1DNetwork.", "conv_networks_test.Conv1DNetworkTest.assertEqual"], "methods", ["None"], ["", "def", "test_mask_input", "(", "self", ")", ":", "\n", "        ", "\"\"\"Tests masked inputs.\n        \"\"\"", "\n", "network_1", "=", "Conv1DNetwork", "(", ")", "\n", "inputs_1", "=", "tf", ".", "ones", "(", "[", "3", ",", "16", ",", "300", "]", ",", "tf", ".", "float32", ")", "\n", "seq_length", "=", "[", "10", ",", "15", ",", "1", "]", "\n", "outputs_1", "=", "network_1", "(", "inputs_1", ",", "sequence_length", "=", "seq_length", ")", "\n", "self", ".", "assertEqual", "(", "outputs_1", ".", "shape", ",", "[", "3", ",", "128", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.encoders.rnn_encoders.RNNEncoderBase.__init__": [[200, 202], ["texar.modules.encoders.encoder_base.EncoderBase.__init__"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.text_infilling.self_attn_hyperparams.Hyperparams.__init__"], ["def", "__init__", "(", "self", ",", "hparams", "=", "None", ")", ":", "\n", "        ", "EncoderBase", ".", "__init__", "(", "self", ",", "hparams", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.encoders.rnn_encoders.RNNEncoderBase.default_hparams": [[203, 221], ["None"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "default_hparams", "(", ")", ":", "\n", "        ", "\"\"\"Returns a dictionary of hyperparameters with default values.\n\n        Returns:\n            .. code-block:: python\n\n                {\n                    \"name\": \"rnn_encoder\"\n                }\n\n            Here:\n\n            \"name\" : str\n                Name of the encoder.\n        \"\"\"", "\n", "return", "{", "\n", "\"name\"", ":", "\"rnn_encoder\"", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.encoders.rnn_encoders.RNNEncoderBase._build": [[223, 235], ["None"], "methods", ["None"], ["", "def", "_build", "(", "self", ",", "inputs", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"Encodes the inputs.\n\n        Args:\n          inputs: Inputs to the encoder.\n          *args: Other arguments.\n          **kwargs: Keyword arguments.\n\n        Returns:\n          Encoding results.\n        \"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.encoders.rnn_encoders.UnidirectionalRNNEncoder.__init__": [[258, 282], ["rnn_encoders.RNNEncoderBase.__init__", "tensorflow.variable_scope", "tensorflow.variable_scope", "texar.core.layers.get_rnn_cell", "rnn_encoders._build_dense_output_layer"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.text_infilling.self_attn_hyperparams.Hyperparams.__init__", "home.repos.pwc.inspect_result.VegB_Text_Infilling.agents.agent_base.AgentBase.variable_scope", "home.repos.pwc.inspect_result.VegB_Text_Infilling.agents.agent_base.AgentBase.variable_scope", "home.repos.pwc.inspect_result.VegB_Text_Infilling.core.layers.get_rnn_cell", "home.repos.pwc.inspect_result.VegB_Text_Infilling.encoders.rnn_encoders._build_dense_output_layer"], ["def", "__init__", "(", "self", ",", "\n", "cell", "=", "None", ",", "\n", "cell_dropout_mode", "=", "None", ",", "\n", "output_layer", "=", "None", ",", "\n", "hparams", "=", "None", ")", ":", "\n", "        ", "RNNEncoderBase", ".", "__init__", "(", "self", ",", "hparams", ")", "\n", "\n", "# Make RNN cell", "\n", "with", "tf", ".", "variable_scope", "(", "self", ".", "variable_scope", ")", ":", "\n", "            ", "if", "cell", "is", "not", "None", ":", "\n", "                ", "self", ".", "_cell", "=", "cell", "\n", "", "else", ":", "\n", "                ", "self", ".", "_cell", "=", "layers", ".", "get_rnn_cell", "(", "\n", "self", ".", "_hparams", ".", "rnn_cell", ",", "cell_dropout_mode", ")", "\n", "\n", "# Make output layer", "\n", "", "", "with", "tf", ".", "variable_scope", "(", "self", ".", "variable_scope", ")", ":", "\n", "            ", "if", "output_layer", "is", "not", "None", ":", "\n", "                ", "self", ".", "_output_layer", "=", "output_layer", "\n", "self", ".", "_output_layer_hparams", "=", "None", "\n", "", "else", ":", "\n", "                ", "self", ".", "_output_layer", "=", "_build_dense_output_layer", "(", "\n", "self", ".", "_hparams", ".", "output_layer", ")", "\n", "self", ".", "_output_layer_hparams", "=", "self", ".", "_hparams", ".", "output_layer", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.encoders.rnn_encoders.UnidirectionalRNNEncoder.default_hparams": [[283, 384], ["rnn_encoders.RNNEncoderBase.default_hparams", "rnn_encoders.RNNEncoderBase.default_hparams", "texar.core.layers.default_rnn_cell_hparams", "rnn_encoders._default_output_layer_hparams"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.core.replay_memories.DequeReplayMemory.default_hparams", "home.repos.pwc.inspect_result.VegB_Text_Infilling.core.replay_memories.DequeReplayMemory.default_hparams", "home.repos.pwc.inspect_result.VegB_Text_Infilling.core.layers.default_rnn_cell_hparams", "home.repos.pwc.inspect_result.VegB_Text_Infilling.encoders.rnn_encoders._default_output_layer_hparams"], ["", "", "", "@", "staticmethod", "\n", "def", "default_hparams", "(", ")", ":", "\n", "        ", "\"\"\"Returns a dictionary of hyperparameters with default values.\n\n        Returns:\n            .. code-block:: python\n\n                {\n                    \"rnn_cell\": default_rnn_cell_hparams(),\n                    \"output_layer\": {\n                        \"num_layers\": 0,\n                        \"layer_size\": 128,\n                        \"activation\": \"identity\",\n                        \"final_layer_activation\": None,\n                        \"other_dense_kwargs\": None,\n                        \"dropout_layer_ids\": [],\n                        \"dropout_rate\": 0.5,\n                        \"variational_dropout\": False\n                    },\n                    \"name\": \"unidirectional_rnn_encoder\"\n                }\n\n            Here:\n\n            \"rnn_cell\" : dict\n                A dictionary of RNN cell hyperparameters. Ignored if\n                :attr:`cell` is given when constructing the encoder.\n\n                The default value is defined in\n                :func:`~texar.core.layers.default_rnn_cell_hparams`.\n\n            \"output_layer\" : dict\n                Output layer hyperparameters. Ignored if :attr:`output_layer`\n                is given in the constructor. Includes:\n\n                \"num_layers\" : int\n                    The number of output (dense) layers. Set to 0 to avoid any\n                    output layers applied to the cell outputs..\n\n                \"layer_size\" : int or list\n                    The size of each of the output (dense) layers.\n\n                    If an `int`, each output layer will have the same size. If\n                    a list, the length must equal to :attr:`num_layers`.\n\n                \"activation\" : str or callable or None\n                    The activation function for each of the output (dense)\n                    layer except for the final layer. This can be\n                    the function itself, or its string name or full path.\n\n                    E.g., `\"activation\": tensorflow.nn.relu`\n                    or `\"activation\": \"relu\"`\n                    or `\"activation\": \"tensorflow.nn.relu\"`\n\n                    Default is `None` which maintains a linear activation.\n\n                \"final_layer_activation\" : str or callable or None\n                    The activation function for the final output layer.\n\n                \"other_dense_kwargs\" : dict or None\n                    Other keyword arguments to construct each of the output\n                    dense layers, e.g., :attr:`use_bias`. See\n                    :tf_main:`Dense <layers/Dense>` for the arguments.\n\n                    E.g., `\"other_dense_kwargs\": { \"use_bias\": False }`.\n\n                \"dropout_layer_ids\" : int or list\n                    The indexes of layers (starting from `0`) whose inputs\n                    are applied with dropout. The index = :attr:`num_layers`\n                    means dropout applies to the final layer output. E.g.,\n\n                    .. code-block:: python\n\n                        {\n                            \"num_layers\": 2,\n                            \"dropout_layer_ids\": [0, 2]\n                        }\n\n                    will leads to a series of layers as\n                    `-dropout-layer0-layer1-dropout-`.\n\n                    The dropout mode (training or not) is controlled\n                    by the :attr:`mode` argument when calling the encoder.\n\n                \"dropout_rate\" : float\n                    The dropout rate, between 0 and 1. E.g.,\n                    `\"dropout_rate\": 0.1` would drop out 10% of elements.\n\n                \"variational_dropout\": bool\n                    Whether the dropout mask is the same across all time steps.\n\n            \"name\" : str\n                Name of the encoder\n        \"\"\"", "\n", "hparams", "=", "RNNEncoderBase", ".", "default_hparams", "(", ")", "\n", "hparams", ".", "update", "(", "{", "\n", "\"rnn_cell\"", ":", "layers", ".", "default_rnn_cell_hparams", "(", ")", ",", "\n", "\"output_layer\"", ":", "_default_output_layer_hparams", "(", ")", ",", "\n", "\"name\"", ":", "\"unidirectional_rnn_encoder\"", "\n", "}", ")", "\n", "return", "hparams", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.encoders.rnn_encoders.UnidirectionalRNNEncoder._build": [[385, 501], ["rnn_encoders._apply_rnn_encoder_output_layer", "tensorflow.nn.dynamic_rnn", "tensorflow.nn.dynamic_rnn", "rnn_encoders.UnidirectionalRNNEncoder._add_internal_trainable_variables", "rnn_encoders.UnidirectionalRNNEncoder._add_trainable_variable", "texar.core.layers.get_rnn_cell_trainable_variables", "rnn_encoders.UnidirectionalRNNEncoder._add_trainable_variable", "isinstance"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.encoders.rnn_encoders._apply_rnn_encoder_output_layer", "home.repos.pwc.inspect_result.VegB_Text_Infilling.texar.module_base.ModuleBase._add_internal_trainable_variables", "home.repos.pwc.inspect_result.VegB_Text_Infilling.texar.module_base.ModuleBase._add_trainable_variable", "home.repos.pwc.inspect_result.VegB_Text_Infilling.core.layers.get_rnn_cell_trainable_variables", "home.repos.pwc.inspect_result.VegB_Text_Infilling.texar.module_base.ModuleBase._add_trainable_variable"], ["", "def", "_build", "(", "self", ",", "\n", "inputs", ",", "\n", "sequence_length", "=", "None", ",", "\n", "initial_state", "=", "None", ",", "\n", "time_major", "=", "False", ",", "\n", "mode", "=", "None", ",", "\n", "return_cell_output", "=", "False", ",", "\n", "return_output_size", "=", "False", ",", "\n", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"Encodes the inputs.\n\n        Args:\n            inputs: A 3D Tensor of shape `[batch_size, max_time, dim]`.\n                The first two dimensions\n                :attr:`batch_size` and :attr:`max_time` are exchanged if\n                :attr:`time_major=True` is specified.\n            sequence_length (int list or 1D Tensor, optional): Sequence lengths\n                of the batch inputs. Used to copy-through state and zero-out\n                outputs when past a batch element's sequence length.\n            initial_state (optional): Initial state of the RNN.\n            time_major (bool): The shape format of the :attr:`inputs` and\n                :attr:`outputs` Tensors. If `True`, these tensors are of shape\n                `[max_time, batch_size, depth]`. If `False` (default),\n                these tensors are of shape `[batch_size, max_time, depth]`.\n            mode (optional): A tensor taking value in\n                :tf_main:`tf.estimator.ModeKeys <estimator/ModeKeys>`, including\n                `TRAIN`, `EVAL`, and `PREDICT`. Controls output layer dropout\n                if the output layer is specified with :attr:`hparams`.\n                If `None` (default), :func:`texar.context.global_mode()`\n                is used.\n            return_cell_output (bool): Whether to return the output of the RNN\n                cell. This is the results prior to the output layer.\n            return_output_size (bool): Whether to return the size of the\n                output (i.e., the results after output layers).\n            **kwargs: Optional keyword arguments of\n                :tf_main:`tf.nn.dynamic_rnn <nn/dynamic_rnn>`,\n                such as `swap_memory`, `dtype`, `parallel_iterations`, etc.\n\n        Returns:\n            By default (both :attr:`return_cell_output` and\n            :attr:`return_output_size` are `False`), returns a pair\n            :attr:`(outputs, final_state)` where\n\n            - :attr:`outputs`: The RNN output tensor by the output layer \\\n              (if exists) or the RNN cell (otherwise). The tensor is of shape \\\n              `[batch_size, max_time, output_size]` (if \\\n              :attr:`time_major` == `False`) or \\\n              `[max_time, batch_size, output_size]` (if \\\n              :attr:`time_major` == `True`). \\\n\n              If RNN cell output is a (nested) tuple of Tensors, then the \\\n              :attr:`outputs` will be a (nested) tuple having the same \\\n              nest structure as the cell output.\n\n            - :attr:`final_state`: The final state of the RNN, which is a \\\n              Tensor of shape `[batch_size] + cell.state_size` or \\\n              a (nested) tuple of Tensors (if `cell.state_size` is a (nested) \\\n              tuple).\n\n            If :attr:`return_cell_output` is `True`, returns a triple\n            :attr:`(outputs, final_state, cell_outputs)` where\n\n            - :attr:`cell_outputs`: The outputs by the RNN cell prior to the \\\n              output layer, having the same structure with :attr:`outputs` \\\n              except for the `output_dim`.\n\n            If :attr:`return_output_size` is also `True`, returns a tuple\n            :attr:`(outputs, final_state, cell_outputs, output_size)` where\n\n            - :attr:`output_size`: A (possibly nested tuple of) `int` \\\n              representing the size of :attr:`outputs`. If a single `int` or \\\n              an `int` array, then :attr:`outputs` has shape \\\n              `[batch/time, time/batch] + output_size`. If :attr:`output_size` \\\n              is a (nested) tuple, then :attr:`output_size` has the same \\\n              structure as with :attr:`outputs`.\n        \"\"\"", "\n", "if", "(", "'dtype'", "not", "in", "kwargs", ")", "and", "(", "initial_state", "is", "None", ")", ":", "\n", "            ", "cell_outputs", ",", "state", "=", "tf", ".", "nn", ".", "dynamic_rnn", "(", "\n", "cell", "=", "self", ".", "_cell", ",", "\n", "inputs", "=", "inputs", ",", "\n", "sequence_length", "=", "sequence_length", ",", "\n", "initial_state", "=", "initial_state", ",", "\n", "time_major", "=", "time_major", ",", "\n", "dtype", "=", "tf", ".", "float32", ",", "\n", "**", "kwargs", ")", "\n", "", "else", ":", "\n", "            ", "cell_outputs", ",", "state", "=", "tf", ".", "nn", ".", "dynamic_rnn", "(", "\n", "cell", "=", "self", ".", "_cell", ",", "\n", "inputs", "=", "inputs", ",", "\n", "sequence_length", "=", "sequence_length", ",", "\n", "initial_state", "=", "initial_state", ",", "\n", "time_major", "=", "time_major", ",", "\n", "**", "kwargs", ")", "\n", "\n", "", "outputs", ",", "output_size", "=", "_apply_rnn_encoder_output_layer", "(", "\n", "self", ".", "_output_layer", ",", "time_major", ",", "self", ".", "_output_layer_hparams", ",", "\n", "mode", ",", "cell_outputs", ",", "self", ".", "_cell", ".", "output_size", ")", "\n", "\n", "if", "not", "self", ".", "_built", ":", "\n", "            ", "self", ".", "_add_internal_trainable_variables", "(", ")", "\n", "# Add trainable variables of `self._cell` and `self._output_layer`", "\n", "# which may be constructed externally.", "\n", "self", ".", "_add_trainable_variable", "(", "\n", "layers", ".", "get_rnn_cell_trainable_variables", "(", "self", ".", "_cell", ")", ")", "\n", "if", "self", ".", "_output_layer", "and", "not", "isinstance", "(", "self", ".", "_output_layer", ",", "(", "list", ",", "tuple", ")", ")", ":", "\n", "                ", "self", ".", "_add_trainable_variable", "(", "\n", "self", ".", "_output_layer", ".", "trainable_variables", ")", "\n", "", "self", ".", "_built", "=", "True", "\n", "\n", "", "rets", "=", "(", "outputs", ",", "state", ")", "\n", "if", "return_cell_output", ":", "\n", "            ", "rets", "+=", "(", "cell_outputs", ",", ")", "\n", "", "if", "return_output_size", ":", "\n", "            ", "rets", "+=", "(", "output_size", ",", ")", "\n", "", "return", "rets", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.encoders.rnn_encoders.UnidirectionalRNNEncoder.cell": [[527, 532], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "cell", "(", "self", ")", ":", "\n", "        ", "\"\"\"The RNN cell.\n        \"\"\"", "\n", "return", "self", ".", "_cell", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.encoders.rnn_encoders.UnidirectionalRNNEncoder.state_size": [[533, 540], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "state_size", "(", "self", ")", ":", "\n", "        ", "\"\"\"The state size of encoder cell.\n\n        Same as :attr:`encoder.cell.state_size`.\n        \"\"\"", "\n", "return", "self", ".", "cell", ".", "state_size", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.encoders.rnn_encoders.UnidirectionalRNNEncoder.output_layer": [[541, 546], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "output_layer", "(", "self", ")", ":", "\n", "        ", "\"\"\"The output layer.\n        \"\"\"", "\n", "return", "self", ".", "_output_layer", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.encoders.rnn_encoders.BidirectionalRNNEncoder.__init__": [[574, 621], ["rnn_encoders.RNNEncoderBase.__init__", "tensorflow.variable_scope", "tensorflow.variable_scope", "texar.core.layers.get_rnn_cell", "rnn_encoders._build_dense_output_layer", "texar.core.layers.get_rnn_cell", "texar.core.layers.get_rnn_cell", "rnn_encoders._build_dense_output_layer", "rnn_encoders._build_dense_output_layer"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.text_infilling.self_attn_hyperparams.Hyperparams.__init__", "home.repos.pwc.inspect_result.VegB_Text_Infilling.agents.agent_base.AgentBase.variable_scope", "home.repos.pwc.inspect_result.VegB_Text_Infilling.agents.agent_base.AgentBase.variable_scope", "home.repos.pwc.inspect_result.VegB_Text_Infilling.core.layers.get_rnn_cell", "home.repos.pwc.inspect_result.VegB_Text_Infilling.encoders.rnn_encoders._build_dense_output_layer", "home.repos.pwc.inspect_result.VegB_Text_Infilling.core.layers.get_rnn_cell", "home.repos.pwc.inspect_result.VegB_Text_Infilling.core.layers.get_rnn_cell", "home.repos.pwc.inspect_result.VegB_Text_Infilling.encoders.rnn_encoders._build_dense_output_layer", "home.repos.pwc.inspect_result.VegB_Text_Infilling.encoders.rnn_encoders._build_dense_output_layer"], ["def", "__init__", "(", "self", ",", "\n", "cell_fw", "=", "None", ",", "\n", "cell_bw", "=", "None", ",", "\n", "cell_dropout_mode", "=", "None", ",", "\n", "output_layer_fw", "=", "None", ",", "\n", "output_layer_bw", "=", "None", ",", "\n", "hparams", "=", "None", ")", ":", "\n", "        ", "RNNEncoderBase", ".", "__init__", "(", "self", ",", "hparams", ")", "\n", "\n", "# Make RNN cells", "\n", "with", "tf", ".", "variable_scope", "(", "self", ".", "variable_scope", ")", ":", "\n", "            ", "if", "cell_fw", "is", "not", "None", ":", "\n", "                ", "self", ".", "_cell_fw", "=", "cell_fw", "\n", "", "else", ":", "\n", "                ", "self", ".", "_cell_fw", "=", "layers", ".", "get_rnn_cell", "(", "\n", "self", ".", "_hparams", ".", "rnn_cell_fw", ",", "cell_dropout_mode", ")", "\n", "\n", "", "if", "cell_bw", "is", "not", "None", ":", "\n", "                ", "self", ".", "_cell_bw", "=", "cell_bw", "\n", "", "elif", "self", ".", "_hparams", ".", "rnn_cell_share_config", ":", "\n", "                ", "self", ".", "_cell_bw", "=", "layers", ".", "get_rnn_cell", "(", "\n", "self", ".", "_hparams", ".", "rnn_cell_fw", ",", "cell_dropout_mode", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "_cell_bw", "=", "layers", ".", "get_rnn_cell", "(", "\n", "self", ".", "_hparams", ".", "rnn_cell_bw", ",", "cell_dropout_mode", ")", "\n", "\n", "# Make output layers", "\n", "", "", "with", "tf", ".", "variable_scope", "(", "self", ".", "variable_scope", ")", ":", "\n", "            ", "if", "output_layer_fw", "is", "not", "None", ":", "\n", "                ", "self", ".", "_output_layer_fw", "=", "output_layer_fw", "\n", "self", ".", "_output_layer_hparams_fw", "=", "None", "\n", "", "else", ":", "\n", "                ", "self", ".", "_output_layer_fw", "=", "_build_dense_output_layer", "(", "\n", "self", ".", "_hparams", ".", "output_layer_fw", ")", "\n", "self", ".", "_output_layer_hparams_fw", "=", "self", ".", "_hparams", ".", "output_layer_fw", "\n", "\n", "", "if", "output_layer_bw", "is", "not", "None", ":", "\n", "                ", "self", ".", "_output_layer_bw", "=", "output_layer_bw", "\n", "self", ".", "_output_layer_hparams_bw", "=", "None", "\n", "", "elif", "self", ".", "_hparams", ".", "output_layer_share_config", ":", "\n", "                ", "self", ".", "_output_layer_bw", "=", "_build_dense_output_layer", "(", "\n", "self", ".", "_hparams", ".", "output_layer_fw", ")", "\n", "self", ".", "_output_layer_hparams_bw", "=", "self", ".", "_hparams", ".", "output_layer_fw", "\n", "", "else", ":", "\n", "                ", "self", ".", "_output_layer_bw", "=", "_build_dense_output_layer", "(", "\n", "self", ".", "_hparams", ".", "output_layer_bw", ")", "\n", "self", ".", "_output_layer_hparams_bw", "=", "self", ".", "_hparams", ".", "output_layer_bw", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.encoders.rnn_encoders.BidirectionalRNNEncoder.default_hparams": [[623, 762], ["rnn_encoders.RNNEncoderBase.default_hparams", "rnn_encoders.RNNEncoderBase.default_hparams", "texar.core.layers.default_rnn_cell_hparams", "texar.core.layers.default_rnn_cell_hparams", "rnn_encoders._default_output_layer_hparams", "rnn_encoders._default_output_layer_hparams"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.core.replay_memories.DequeReplayMemory.default_hparams", "home.repos.pwc.inspect_result.VegB_Text_Infilling.core.replay_memories.DequeReplayMemory.default_hparams", "home.repos.pwc.inspect_result.VegB_Text_Infilling.core.layers.default_rnn_cell_hparams", "home.repos.pwc.inspect_result.VegB_Text_Infilling.core.layers.default_rnn_cell_hparams", "home.repos.pwc.inspect_result.VegB_Text_Infilling.encoders.rnn_encoders._default_output_layer_hparams", "home.repos.pwc.inspect_result.VegB_Text_Infilling.encoders.rnn_encoders._default_output_layer_hparams"], ["", "", "", "@", "staticmethod", "\n", "def", "default_hparams", "(", ")", ":", "\n", "        ", "\"\"\"Returns a dictionary of hyperparameters with default values.\n\n        Returns:\n            .. code-block:: python\n\n                {\n                    \"rnn_cell_fw\": default_rnn_cell_hparams(),\n                    \"rnn_cell_bw\": default_rnn_cell_hparams(),\n                    \"rnn_cell_share_config\": True,\n                    \"output_layer_fw\": {\n                        \"num_layers\": 0,\n                        \"layer_size\": 128,\n                        \"activation\": \"identity\",\n                        \"final_layer_activation\": None,\n                        \"other_dense_kwargs\": None,\n                        \"dropout_layer_ids\": [],\n                        \"dropout_rate\": 0.5,\n                        \"variational_dropout\": False\n                    },\n                    \"output_layer_bw\": {\n                        # Same as \"output_layer_fw\"\n                        # ...\n                    },\n                    \"output_layer_share_config\": True,\n                    \"name\": \"bidirectional_rnn_encoder\"\n                }\n\n            Here:\n\n            \"rnn_cell_fw\" : dict\n                Hyperparameters of the forward RNN cell.\n                Ignored if :attr:`cell_fw` is given when constructing\n                the encoder.\n\n                The default value is defined in\n                :meth:`~texar.core.layers.default_rnn_cell_hparams`.\n\n            \"rnn_cell_bw\" : dict\n                Hyperparameters of the backward RNN cell.\n                Ignored if :attr:`cell_bw` is given when constructing\n                the encoder, or if :attr:`\"rnn_cell_share_config\"` is `True`.\n\n                The default value is defined in\n                :meth:`~texar.core.layers.default_rnn_cell_hparams`.\n\n            \"rnn_cell_share_config\" : bool\n                Whether share hyperparameters of the backward cell with the\n                forward cell. Note that the cell parameters are not shared.\n\n                If `True` (default), :attr:`\"rnn_cell_bw\"` is ignored.\n\n            \"output_layer_fw\" : dict\n                Hyperparameters of the forward output layer. Ignored if\n                :attr:`output_layer_fw` is given in the constructor. Includes:\n\n                \"num_layers\" : int\n                    The number of output (dense) layers. Set to 0 to avoid any\n                    output layers applied to the cell outputs..\n\n                \"layer_size\" : int or list\n                    The size of each of the output (dense) layers.\n\n                    If an `int`, each output layer will have the same size. If\n                    a list, the length must equal to :attr:`num_layers`.\n\n                \"activation\" : str or callable or None\n                    The activation function for each of the output (dense)\n                    layer except for the final layer. This can be\n                    the function itself, or its string name or full path.\n\n                    E.g., `\"activation\": tensorflow.nn.relu`\n                    or `\"activation\": \"relu\"`\n                    or `\"activation\": \"tensorflow.nn.relu\"`\n\n                    Default is `None` which maintains a linear activation.\n\n                \"final_layer_activation\" : str or callable or None\n                    The activation function for the final output layer.\n\n                \"other_dense_kwargs\" : dict or None\n                    Other keyword arguments to construct each of the output\n                    dense layers, e.g., :attr:`use_bias`. See\n                    :tf_main:`Dense <layers/Dense>` for the arguments.\n\n                    E.g., `\"other_dense_kwargs\": { \"use_bias\": False }`.\n\n                \"dropout_layer_ids\" : int or list\n                    The indexes of layers (starting from `0`) whose inputs\n                    are applied with dropout. The index = :attr:`num_layers`\n                    means dropout applies to the final layer output. E.g.,\n\n                    .. code-block:: python\n\n                        {\n                            \"num_layers\": 2,\n                            \"dropout_layer_ids\": [0, 2]\n                        }\n\n                    will leads to a series of layers as\n                    `-dropout-layer0-layer1-dropout-`.\n\n                    The dropout mode (training or not) is controlled\n                    by the :attr:`mode` argument when calling the encoder.\n\n                \"dropout_rate\" : float\n                    The dropout rate, between 0 and 1. E.g.,\n                    `\"dropout_rate\": 0.1` would drop out 10% of elements.\n\n                \"variational_dropout\": bool\n                    Whether the dropout mask is the same across all time steps.\n\n            \"output_layer_bw\" : dict\n                Hyperparameters of the backward output layer. Ignored if\n                :attr:`output_layer_bw` is given in the constructor. Have the\n                same structure and defaults with :attr:`\"output_layer_fw\"`.\n\n            \"output_layer_share_config\" : bool\n                Whether share hyperparameters of the backward output layer\n                with the forward output layer. Note that the layer parameters\n                are not shared.\n\n                If `True` (default), :attr:`\"output_layer_bw\"` is ignored.\n\n            \"name\" : str\n                Name of the encoder\n        \"\"\"", "\n", "hparams", "=", "RNNEncoderBase", ".", "default_hparams", "(", ")", "\n", "hparams", ".", "update", "(", "{", "\n", "\"rnn_cell_fw\"", ":", "layers", ".", "default_rnn_cell_hparams", "(", ")", ",", "\n", "\"rnn_cell_bw\"", ":", "layers", ".", "default_rnn_cell_hparams", "(", ")", ",", "\n", "\"rnn_cell_share_config\"", ":", "True", ",", "\n", "\"output_layer_fw\"", ":", "_default_output_layer_hparams", "(", ")", ",", "\n", "\"output_layer_bw\"", ":", "_default_output_layer_hparams", "(", ")", ",", "\n", "\"output_layer_share_config\"", ":", "True", ",", "\n", "\"name\"", ":", "\"bidirectional_rnn_encoder\"", "\n", "}", ")", "\n", "return", "hparams", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.encoders.rnn_encoders.BidirectionalRNNEncoder._build": [[763, 889], ["rnn_encoders._apply_rnn_encoder_output_layer", "rnn_encoders._apply_rnn_encoder_output_layer", "tensorflow.nn.bidirectional_dynamic_rnn", "tensorflow.nn.bidirectional_dynamic_rnn", "rnn_encoders.BidirectionalRNNEncoder._add_internal_trainable_variables", "rnn_encoders.BidirectionalRNNEncoder._add_trainable_variable", "rnn_encoders.BidirectionalRNNEncoder._add_trainable_variable", "texar.core.layers.get_rnn_cell_trainable_variables", "texar.core.layers.get_rnn_cell_trainable_variables", "rnn_encoders.BidirectionalRNNEncoder._add_trainable_variable", "rnn_encoders.BidirectionalRNNEncoder._add_trainable_variable", "isinstance", "isinstance"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.encoders.rnn_encoders._apply_rnn_encoder_output_layer", "home.repos.pwc.inspect_result.VegB_Text_Infilling.encoders.rnn_encoders._apply_rnn_encoder_output_layer", "home.repos.pwc.inspect_result.VegB_Text_Infilling.texar.module_base.ModuleBase._add_internal_trainable_variables", "home.repos.pwc.inspect_result.VegB_Text_Infilling.texar.module_base.ModuleBase._add_trainable_variable", "home.repos.pwc.inspect_result.VegB_Text_Infilling.texar.module_base.ModuleBase._add_trainable_variable", "home.repos.pwc.inspect_result.VegB_Text_Infilling.core.layers.get_rnn_cell_trainable_variables", "home.repos.pwc.inspect_result.VegB_Text_Infilling.core.layers.get_rnn_cell_trainable_variables", "home.repos.pwc.inspect_result.VegB_Text_Infilling.texar.module_base.ModuleBase._add_trainable_variable", "home.repos.pwc.inspect_result.VegB_Text_Infilling.texar.module_base.ModuleBase._add_trainable_variable"], ["", "def", "_build", "(", "self", ",", "\n", "inputs", ",", "\n", "sequence_length", "=", "None", ",", "\n", "initial_state_fw", "=", "None", ",", "\n", "initial_state_bw", "=", "None", ",", "\n", "time_major", "=", "False", ",", "\n", "mode", "=", "None", ",", "\n", "return_cell_output", "=", "False", ",", "\n", "return_output_size", "=", "False", ",", "\n", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"Encodes the inputs.\n\n        Args:\n            inputs: A 3D Tensor of shape `[batch_size, max_time, dim]`.\n                The first two dimensions\n                `batch_size` and `max_time` may be exchanged if\n                `time_major=True` is specified.\n            sequence_length (int list or 1D Tensor, optional): Sequence lengths\n                of the batch inputs. Used to copy-through state and zero-out\n                outputs when past a batch element's sequence length.\n            initial_state (optional): Initial state of the RNN.\n            time_major (bool): The shape format of the :attr:`inputs` and\n                :attr:`outputs` Tensors. If `True`, these tensors are of shape\n                `[max_time, batch_size, depth]`. If `False` (default),\n                these tensors are of shape `[batch_size, max_time, depth]`.\n            mode (optional): A tensor taking value in\n                :tf_main:`tf.estimator.ModeKeys <estimator/ModeKeys>`, including\n                `TRAIN`, `EVAL`, and `PREDICT`. Controls output layer dropout\n                if the output layer is specified with :attr:`hparams`.\n                If `None` (default), :func:`texar.context.global_mode()`\n                is used.\n            return_cell_output (bool): Whether to return the output of the RNN\n                cell. This is the results prior to the output layer.\n            **kwargs: Optional keyword arguments of\n                :tf_main:`tf.nn.dynamic_rnn <nn/dynamic_rnn>`,\n                such as `swap_memory`, `dtype`, `parallel_iterations`, etc.\n\n        Returns:\n            If :attr:`return_cell_output` is `False` (default), returns a\n            pair :attr:`(outputs, final_state)` where\n\n            - :attr:`outputs`: A tuple `(outputs_fw, outputs_bw)` containing \\\n              the forward and the backward RNN outputs, each of which is of \\\n              shape `[batch_size, max_time, output_dim]` (if \\\n              :attr:`time_major` == `False`) or \\\n              `[max_time, batch_size, output_dim]` (if \\\n              :attr:`time_major` == `True`). \\\n\n              If RNN cell output is a (nested) tuple of Tensors, then the \\\n              `outputs_fw` and `outputs_bw` will be a (nested) tuple having \\\n              the same structure as the cell output.\n\n            - :attr:`final_state`: A tuple `(final_state_fw, final_state_bw)` \\\n              containing the final states of the forward and the backward \\\n              RNNs, each of which is a \\\n              Tensor of shape `[batch_size] + cell.state_size` or \\\n              a (nested) tuple of Tensors (if `cell.state_size` is a (nested) \\\n              tuple).\n\n            If :attr:`return_cell_output` is `True`, returns a triple\n            :attr:`(outputs, final_state, cell_outputs)` where\n\n            - :attr:`cell_outputs`: A tuple \\\n              `(cell_outputs_fw, cell_outputs_bw)` containting the outputs \\\n              by the forward and backward RNN cells prior to the \\\n              output layers, having the same structure with :attr:`outputs` \\\n              except for the `output_dim`.\n        \"\"\"", "\n", "no_initial_state", "=", "initial_state_fw", "is", "None", "and", "initial_state_bw", "is", "None", "\n", "if", "(", "'dtype'", "not", "in", "kwargs", ")", "and", "no_initial_state", ":", "\n", "            ", "cell_outputs", ",", "states", "=", "tf", ".", "nn", ".", "bidirectional_dynamic_rnn", "(", "\n", "cell_fw", "=", "self", ".", "_cell_fw", ",", "\n", "cell_bw", "=", "self", ".", "_cell_bw", ",", "\n", "inputs", "=", "inputs", ",", "\n", "sequence_length", "=", "sequence_length", ",", "\n", "initial_state_fw", "=", "initial_state_fw", ",", "\n", "initial_state_bw", "=", "initial_state_bw", ",", "\n", "time_major", "=", "time_major", ",", "\n", "dtype", "=", "tf", ".", "float32", ",", "\n", "**", "kwargs", ")", "\n", "", "else", ":", "\n", "            ", "cell_outputs", ",", "states", "=", "tf", ".", "nn", ".", "bidirectional_dynamic_rnn", "(", "\n", "cell_fw", "=", "self", ".", "_cell_fw", ",", "\n", "cell_bw", "=", "self", ".", "_cell_bw", ",", "\n", "inputs", "=", "inputs", ",", "\n", "sequence_length", "=", "sequence_length", ",", "\n", "initial_state_fw", "=", "initial_state_fw", ",", "\n", "initial_state_bw", "=", "initial_state_bw", ",", "\n", "time_major", "=", "time_major", ",", "\n", "**", "kwargs", ")", "\n", "\n", "", "outputs_fw", ",", "output_size_fw", "=", "_apply_rnn_encoder_output_layer", "(", "\n", "self", ".", "_output_layer_fw", ",", "time_major", ",", "self", ".", "_output_layer_hparams_fw", ",", "\n", "mode", ",", "cell_outputs", "[", "0", "]", ",", "self", ".", "_cell_fw", ".", "output_size", ")", "\n", "\n", "outputs_bw", ",", "output_size_bw", "=", "_apply_rnn_encoder_output_layer", "(", "\n", "self", ".", "_output_layer_bw", ",", "time_major", ",", "self", ".", "_output_layer_hparams_bw", ",", "\n", "mode", ",", "cell_outputs", "[", "1", "]", ",", "self", ".", "_cell_bw", ".", "output_size", ")", "\n", "\n", "outputs", "=", "(", "outputs_fw", ",", "outputs_bw", ")", "\n", "output_size", "=", "(", "output_size_fw", ",", "output_size_bw", ")", "\n", "\n", "if", "not", "self", ".", "_built", ":", "\n", "            ", "self", ".", "_add_internal_trainable_variables", "(", ")", "\n", "# Add trainable variables of cells and output layers", "\n", "# which may be constructed externally.", "\n", "self", ".", "_add_trainable_variable", "(", "\n", "layers", ".", "get_rnn_cell_trainable_variables", "(", "self", ".", "_cell_fw", ")", ")", "\n", "self", ".", "_add_trainable_variable", "(", "\n", "layers", ".", "get_rnn_cell_trainable_variables", "(", "self", ".", "_cell_bw", ")", ")", "\n", "if", "self", ".", "_output_layer_fw", "and", "not", "isinstance", "(", "self", ".", "_output_layer_fw", ",", "(", "list", ",", "tuple", ")", ")", ":", "\n", "                ", "self", ".", "_add_trainable_variable", "(", "\n", "self", ".", "_output_layer_fw", ".", "trainable_variables", ")", "\n", "", "if", "self", ".", "_output_layer_bw", "and", "not", "isinstance", "(", "self", ".", "_output_layer_bw", ",", "(", "list", ",", "tuple", ")", ")", ":", "\n", "                ", "self", ".", "_add_trainable_variable", "(", "\n", "self", ".", "_output_layer_bw", ".", "trainable_variables", ")", "\n", "", "self", ".", "_built", "=", "True", "\n", "\n", "", "returns", "=", "(", "outputs", ",", "states", ")", "\n", "if", "return_cell_output", ":", "\n", "            ", "returns", "+=", "(", "cell_outputs", ",", ")", "\n", "", "if", "return_output_size", ":", "\n", "            ", "returns", "+=", "(", "output_size", ",", ")", "\n", "", "return", "returns", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.encoders.rnn_encoders.BidirectionalRNNEncoder.concat_outputs": [[890, 896], ["tensorflow.concat"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "concat_outputs", "(", "outputs", ")", ":", "\n", "        ", "\"\"\"Concats the outputs of the bidirectional encoder into a single\n        tensor.\n        \"\"\"", "\n", "return", "tf", ".", "concat", "(", "outputs", ",", "2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.encoders.rnn_encoders.BidirectionalRNNEncoder.cell_fw": [[897, 902], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "cell_fw", "(", "self", ")", ":", "\n", "        ", "\"\"\"The forward RNN cell.\n        \"\"\"", "\n", "return", "self", ".", "_cell_fw", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.encoders.rnn_encoders.BidirectionalRNNEncoder.cell_bw": [[903, 908], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "cell_bw", "(", "self", ")", ":", "\n", "        ", "\"\"\"The backward RNN cell.\n        \"\"\"", "\n", "return", "self", ".", "_cell_bw", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.encoders.rnn_encoders.BidirectionalRNNEncoder.state_size_fw": [[909, 916], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "state_size_fw", "(", "self", ")", ":", "\n", "        ", "\"\"\"The state size of the forward encoder cell.\n\n        Same as :attr:`encoder.cell_fw.state_size`.\n        \"\"\"", "\n", "return", "self", ".", "cell_fw", ".", "state_size", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.encoders.rnn_encoders.BidirectionalRNNEncoder.state_size_bw": [[917, 924], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "state_size_bw", "(", "self", ")", ":", "\n", "        ", "\"\"\"The state size of the backward encoder cell.\n\n        Same as :attr:`encoder.cell_bw.state_size`.\n        \"\"\"", "\n", "return", "self", ".", "cell_bw", ".", "state_size", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.encoders.rnn_encoders.BidirectionalRNNEncoder.output_layer_fw": [[925, 930], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "output_layer_fw", "(", "self", ")", ":", "\n", "        ", "\"\"\"The output layer of the forward RNN.\n        \"\"\"", "\n", "return", "self", ".", "_output_layer_fw", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.encoders.rnn_encoders.BidirectionalRNNEncoder.output_layer_bw": [[931, 936], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "output_layer_bw", "(", "self", ")", ":", "\n", "        ", "\"\"\"The output layer of the backward RNN.\n        \"\"\"", "\n", "return", "self", ".", "_output_layer_bw", "\n", "", "", ""]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.encoders.rnn_encoders._default_output_layer_hparams": [[33, 45], ["None"], "function", ["None"], ["def", "_default_output_layer_hparams", "(", ")", ":", "\n", "    ", "return", "{", "\n", "\"num_layers\"", ":", "0", ",", "\n", "\"layer_size\"", ":", "128", ",", "\n", "\"activation\"", ":", "\"identity\"", ",", "\n", "\"final_layer_activation\"", ":", "None", ",", "\n", "\"other_dense_kwargs\"", ":", "None", ",", "\n", "\"dropout_layer_ids\"", ":", "[", "]", ",", "\n", "\"dropout_rate\"", ":", "0.5", ",", "\n", "\"variational_dropout\"", ":", "False", ",", "\n", "\"@no_typecheck\"", ":", "[", "\"activation\"", ",", "\"final_layer_activation\"", ",", "\n", "\"layer_size\"", ",", "\"dropout_layer_ids\"", "]", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.encoders.rnn_encoders._build_dense_output_layer": [[47, 82], ["texar.modules.networks.conv_networks._to_list", "isinstance", "range", "other_kwargs.todict.todict", "isinstance", "ValueError", "kwargs_i.update", "dense_layers.append", "len", "texar.core.layers.get_layer"], "function", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.networks.conv_networks._to_list", "home.repos.pwc.inspect_result.VegB_Text_Infilling.texar.hyperparams.HParams.todict", "home.repos.pwc.inspect_result.VegB_Text_Infilling.core.layers.get_layer"], ["", "def", "_build_dense_output_layer", "(", "hparams", ")", ":", "\n", "    ", "nlayers", "=", "hparams", ".", "num_layers", "\n", "\n", "if", "nlayers", "<=", "0", ":", "\n", "        ", "return", "None", "\n", "\n", "", "layer_size", "=", "_to_list", "(", "\n", "hparams", ".", "layer_size", ",", "'output_layer.layer_size'", ",", "nlayers", ")", "\n", "\n", "other_kwargs", "=", "hparams", ".", "other_dense_kwargs", "or", "{", "}", "\n", "if", "isinstance", "(", "other_kwargs", ",", "HParams", ")", ":", "\n", "        ", "other_kwargs", "=", "other_kwargs", ".", "todict", "(", ")", "\n", "", "if", "not", "isinstance", "(", "other_kwargs", ",", "dict", ")", ":", "\n", "        ", "raise", "ValueError", "(", "\n", "\"hparams 'output_layer.other_dense_kwargs' must be a dict.\"", ")", "\n", "\n", "", "dense_layers", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "nlayers", ")", ":", "\n", "        ", "if", "i", "==", "nlayers", "-", "1", ":", "\n", "            ", "activation", "=", "hparams", ".", "final_layer_activation", "\n", "", "else", ":", "\n", "            ", "activation", "=", "hparams", ".", "activation", "\n", "\n", "", "kwargs_i", "=", "{", "\"units\"", ":", "layer_size", "[", "i", "]", ",", "\n", "\"activation\"", ":", "activation", ",", "\n", "\"name\"", ":", "\"dense_%d\"", "%", "(", "i", "+", "1", ")", "}", "\n", "kwargs_i", ".", "update", "(", "other_kwargs", ")", "\n", "\n", "layer_hparams", "=", "{", "\"type\"", ":", "\"Dense\"", ",", "\"kwargs\"", ":", "kwargs_i", "}", "\n", "dense_layers", ".", "append", "(", "layers", ".", "get_layer", "(", "hparams", "=", "layer_hparams", ")", ")", "\n", "\n", "", "if", "len", "(", "dense_layers", ")", "==", "1", ":", "\n", "        ", "dense_layers", "=", "dense_layers", "[", "0", "]", "\n", "\n", "", "return", "dense_layers", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.encoders.rnn_encoders._forward_single_output_layer": [[83, 104], ["numpy.prod", "tensorflow.reshape", "output_layer", "numpy.array", "tensorflow.concat", "tensorflow.reshape", "texar.modules.decoders.rnn_decoder_base.compute_output_shape().as_list", "texar.modules.decoders.rnn_decoder_base.compute_output_shape", "tensorflow.shape"], "function", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.encoders.rnn_encoders.UnidirectionalRNNEncoder.output_layer", "home.repos.pwc.inspect_result.VegB_Text_Infilling.core.layers.SequentialLayer.compute_output_shape"], ["", "def", "_forward_single_output_layer", "(", "inputs", ",", "input_size", ",", "output_layer", ")", ":", "\n", "    ", "\"\"\"Forwards the input through a single output layer.\n\n    Args:\n        inputs: A Tensor of shape `[batch_size, max_time] + input_size` if\n            :attr:`time_major=False`, or shape\n            `[max_time, batch_size] + input_size` if :attr:`time_major=True`.\n        input_size: An `int` or 1D `int` array.\n    \"\"\"", "\n", "dim", "=", "np", ".", "prod", "(", "input_size", ")", "\n", "inputs_flat", "=", "inputs", "\n", "inputs_flat", "=", "tf", ".", "reshape", "(", "inputs_flat", ",", "[", "-", "1", ",", "dim", "]", ")", "\n", "# Feed to the layer", "\n", "output_flat", "=", "output_layer", "(", "inputs_flat", ")", "\n", "# output_size = output_layer.compute_output_shape([1, dim]).as_list()[1:]", "\n", "output_size", "=", "compute_output_shape", "(", "output_layer", ".", "units", ",", "[", "1", ",", "dim", "]", ")", ".", "as_list", "(", ")", "[", "1", ":", "]", "\n", "output_size", "=", "np", ".", "array", "(", "output_size", ")", "\n", "# Reshape output to [batch_size/max_time, max_time/batch_size] + output_size", "\n", "output_shape", "=", "tf", ".", "concat", "(", "[", "tf", ".", "shape", "(", "inputs", ")", "[", ":", "2", "]", ",", "output_size", "]", ",", "axis", "=", "0", ")", "\n", "output", "=", "tf", ".", "reshape", "(", "output_flat", ",", "output_shape", ")", "\n", "return", "output", ",", "output_size", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.encoders.rnn_encoders._apply_dropout": [[105, 120], ["tensorflow.layers.dropout"], "function", ["None"], ["", "def", "_apply_dropout", "(", "inputs", ",", "time_major", ",", "hparams", ",", "training", ")", ":", "\n", "    ", "\"\"\"Applies dropout to the inputs.\n\n    :attr:`inputs` is a Tensor of shape `[batch_size, max_time, dim]`\n    if :attr:`time_major=False`, or shape `[max_time, batch_size, dim]`\n    if :attr:`time_major=True`.\n    \"\"\"", "\n", "noise_shape", "=", "None", "\n", "if", "hparams", ".", "variational_dropout", ":", "\n", "        ", "if", "time_major", ":", "\n", "            ", "noise_shape", "=", "[", "1", ",", "None", ",", "None", "]", "\n", "", "else", ":", "\n", "            ", "noise_shape", "=", "[", "None", ",", "1", ",", "None", "]", "\n", "", "", "return", "tf", ".", "layers", ".", "dropout", "(", "inputs", ",", "rate", "=", "hparams", ".", "dropout_rate", ",", "\n", "noise_shape", "=", "noise_shape", ",", "training", "=", "training", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.encoders.rnn_encoders._forward_output_layers": [[121, 172], ["isinstance", "rnn_encoders._forward_single_output_layer", "texar.modules.networks.conv_networks._to_list", "texar.modules.networks.conv_networks._to_list", "enumerate", "texar.utils.shapes.mask_sequences", "ValueError", "len", "texar.utils.mode.is_train_mode", "rnn_encoders._forward_single_output_layer", "len", "rnn_encoders._apply_dropout", "rnn_encoders._apply_dropout"], "function", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.encoders.rnn_encoders._forward_single_output_layer", "home.repos.pwc.inspect_result.VegB_Text_Infilling.networks.conv_networks._to_list", "home.repos.pwc.inspect_result.VegB_Text_Infilling.networks.conv_networks._to_list", "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.shapes.mask_sequences", "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.mode.is_train_mode", "home.repos.pwc.inspect_result.VegB_Text_Infilling.encoders.rnn_encoders._forward_single_output_layer", "home.repos.pwc.inspect_result.VegB_Text_Infilling.encoders.rnn_encoders._apply_dropout", "home.repos.pwc.inspect_result.VegB_Text_Infilling.encoders.rnn_encoders._apply_dropout"], ["", "def", "_forward_output_layers", "(", "inputs", ",", "input_size", ",", "output_layer", ",", "time_major", ",", "\n", "hparams", ",", "mode", ",", "sequence_length", "=", "None", ")", ":", "\n", "    ", "\"\"\"Forwards inputs through the output layers.\n\n    Args:\n        inputs: A Tensor of shape `[batch_size, max_time] + input_size` if\n            :attr:`time_major=False`, or shape\n            `[max_time, batch_size] + input_size` if :attr:`time_major=True`.\n\n    Returns:\n        A pair :attr:`(outputs, outputs_size), where\n\n        - :attr:`outputs`: A Tensor of shape \\\n          `[batch_size, max_time] + outputs_size`.\n\n        - :attr:`outputs_size`: An `int` or 1D `int` array representing the \\\n          output size.\n    \"\"\"", "\n", "if", "output_layer", "is", "None", ":", "\n", "        ", "return", "inputs", ",", "input_size", "\n", "\n", "", "if", "hparams", "is", "None", ":", "\n", "# output_layer was passed in from the constructor", "\n", "        ", "if", "isinstance", "(", "output_layer", ",", "(", "list", ",", "tuple", ")", ")", ":", "\n", "            ", "raise", "ValueError", "(", "'output_layer must not be a list or tuple.'", ")", "\n", "", "output", ",", "output_size", "=", "_forward_single_output_layer", "(", "\n", "inputs", ",", "input_size", ",", "output_layer", ")", "\n", "", "else", ":", "\n", "# output_layer was built based on hparams", "\n", "        ", "output_layer", "=", "_to_list", "(", "output_layer", ")", "\n", "\n", "dropout_layer_ids", "=", "_to_list", "(", "hparams", ".", "dropout_layer_ids", ")", "\n", "if", "len", "(", "dropout_layer_ids", ")", ">", "0", ":", "\n", "            ", "training", "=", "is_train_mode", "(", "mode", ")", "\n", "\n", "", "output", "=", "inputs", "\n", "output_size", "=", "input_size", "\n", "for", "i", ",", "layer", "in", "enumerate", "(", "output_layer", ")", ":", "\n", "            ", "if", "i", "in", "dropout_layer_ids", ":", "\n", "                ", "output", "=", "_apply_dropout", "(", "output", ",", "time_major", ",", "hparams", ",", "training", ")", "\n", "", "output", ",", "output_size", "=", "_forward_single_output_layer", "(", "\n", "output", ",", "output_size", ",", "layer", ")", "\n", "\n", "", "if", "len", "(", "output_layer", ")", "in", "dropout_layer_ids", ":", "\n", "            ", "output", "=", "_apply_dropout", "(", "output", ",", "time_major", ",", "hparams", ",", "training", ")", "\n", "\n", "", "", "if", "sequence_length", "is", "not", "None", ":", "\n", "        ", "output", "=", "mask_sequences", "(", "\n", "output", ",", "sequence_length", ",", "time_major", "=", "time_major", ",", "tensor_rank", "=", "3", ")", "\n", "\n", "", "return", "output", ",", "output_size", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.encoders.rnn_encoders._apply_rnn_encoder_output_layer": [[173, 189], ["functools.partial", "tensorflow.contrib.framework.nest.flatten", "tensorflow.contrib.framework.nest.flatten", "zip", "tensorflow.contrib.framework.nest.pack_sequence_as", "tensorflow.contrib.framework.nest.pack_sequence_as", "functools.partial.", "zip"], "function", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.encoders.hierarchical_encoders.HierarchicalRNNEncoder.flatten", "home.repos.pwc.inspect_result.VegB_Text_Infilling.encoders.hierarchical_encoders.HierarchicalRNNEncoder.flatten"], ["", "def", "_apply_rnn_encoder_output_layer", "(", "output_layer", ",", "time_major", ",", "hparams", ",", "mode", ",", "\n", "cell_outputs", ",", "cell_output_size", ")", ":", "\n", "    ", "map_func", "=", "functools", ".", "partial", "(", "\n", "_forward_output_layers", ",", "\n", "output_layer", "=", "output_layer", ",", "\n", "time_major", "=", "time_major", ",", "\n", "hparams", "=", "hparams", ",", "\n", "mode", "=", "mode", ")", "\n", "cell_outputs_flat", "=", "nest", ".", "flatten", "(", "cell_outputs", ")", "\n", "cell_output_size_flat", "=", "nest", ".", "flatten", "(", "cell_output_size", ")", "\n", "o", "=", "[", "map_func", "(", "inputs", "=", "x", ",", "input_size", "=", "xs", ")", "\n", "for", "x", ",", "xs", "in", "zip", "(", "cell_outputs_flat", ",", "cell_output_size_flat", ")", "]", "\n", "outputs_flat", ",", "output_size_flat", "=", "zip", "(", "*", "o", ")", "\n", "outputs", "=", "nest", ".", "pack_sequence_as", "(", "cell_outputs", ",", "outputs_flat", ")", "\n", "output_size", "=", "nest", ".", "pack_sequence_as", "(", "cell_outputs", ",", "output_size_flat", ")", "\n", "return", "outputs", ",", "output_size", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.encoders.conv_encoders.Conv1DEncoder.__init__": [[26, 28], ["texar.modules.networks.conv_networks.Conv1DNetwork.__init__"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.text_infilling.self_attn_hyperparams.Hyperparams.__init__"], ["def", "__init__", "(", "self", ",", "hparams", "=", "None", ")", ":", "# pylint: disable=super-init-not-called", "\n", "        ", "Conv1DNetwork", ".", "__init__", "(", "self", ",", "hparams", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.encoders.conv_encoders.Conv1DEncoder.default_hparams": [[29, 39], ["texar.modules.networks.conv_networks.Conv1DNetwork.default_hparams"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.core.replay_memories.DequeReplayMemory.default_hparams"], ["", "@", "staticmethod", "\n", "def", "default_hparams", "(", ")", ":", "\n", "        ", "\"\"\"Returns a dictionary of hyperparameters with default values.\n\n        The same as :meth:`texar.modules.Conv1DNetwork.default_hparams`,\n        except that the default name is 'conv_encoder'.\n        \"\"\"", "\n", "hparams", "=", "Conv1DNetwork", ".", "default_hparams", "(", ")", "\n", "hparams", "[", "'name'", "]", "=", "'conv_encoder'", "\n", "return", "hparams", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.encoders.conv_encoders_test.Conv1DEncoderTest.test_encode": [[21, 65], ["texar.modules.encoders.conv_encoders.Conv1DEncoder", "conv_encoders_test.Conv1DEncoderTest.assertEqual", "conv_encoders_test.Conv1DEncoderTest.assertTrue", "tensorflow.ones", "texar.modules.encoders.conv_encoders.Conv1DEncoder.", "conv_encoders_test.Conv1DEncoderTest.assertEqual", "texar.modules.encoders.conv_encoders.Conv1DEncoder", "conv_encoders_test.Conv1DEncoderTest.assertEqual", "conv_encoders_test.Conv1DEncoderTest.assertTrue", "tensorflow.ones", "texar.modules.encoders.conv_encoders.Conv1DEncoder.", "conv_encoders_test.Conv1DEncoderTest.assertEqual", "len", "isinstance", "conv_encoders_test.Conv1DEncoderTest.assertTrue", "len", "isinstance", "conv_encoders_test.Conv1DEncoderTest.assertTrue", "texar.modules.encoders.conv_encoders.Conv1DEncoder.layer_by_name", "isinstance", "texar.modules.encoders.conv_encoders.Conv1DEncoder.layer_by_name", "isinstance"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.networks.network_base.FeedForwardNetworkBase.layer_by_name", "home.repos.pwc.inspect_result.VegB_Text_Infilling.networks.network_base.FeedForwardNetworkBase.layer_by_name"], ["def", "test_encode", "(", "self", ")", ":", "\n", "        ", "\"\"\"Tests encode.\n        \"\"\"", "\n", "encoder_1", "=", "Conv1DEncoder", "(", ")", "\n", "self", ".", "assertEqual", "(", "len", "(", "encoder_1", ".", "layers", ")", ",", "4", ")", "\n", "self", ".", "assertTrue", "(", "isinstance", "(", "encoder_1", ".", "layer_by_name", "(", "\"conv_pool_1\"", ")", ",", "\n", "tx", ".", "core", ".", "MergeLayer", ")", ")", "\n", "for", "layer", "in", "encoder_1", ".", "layers", "[", "0", "]", ".", "layers", ":", "\n", "            ", "self", ".", "assertTrue", "(", "isinstance", "(", "layer", ",", "tx", ".", "core", ".", "SequentialLayer", ")", ")", "\n", "\n", "", "inputs_1", "=", "tf", ".", "ones", "(", "[", "64", ",", "16", ",", "300", "]", ",", "tf", ".", "float32", ")", "\n", "outputs_1", "=", "encoder_1", "(", "inputs_1", ")", "\n", "self", ".", "assertEqual", "(", "outputs_1", ".", "shape", ",", "[", "64", ",", "128", "]", ")", "\n", "\n", "hparams", "=", "{", "\n", "# Conv layers", "\n", "\"num_conv_layers\"", ":", "2", ",", "\n", "\"filters\"", ":", "128", ",", "\n", "\"kernel_size\"", ":", "[", "[", "3", ",", "4", ",", "5", "]", ",", "4", "]", ",", "\n", "\"other_conv_kwargs\"", ":", "{", "\"padding\"", ":", "\"same\"", "}", ",", "\n", "# Pooling layers", "\n", "\"pooling\"", ":", "\"AveragePooling\"", ",", "\n", "\"pool_size\"", ":", "2", ",", "\n", "\"pool_strides\"", ":", "1", ",", "\n", "# Dense layers", "\n", "\"num_dense_layers\"", ":", "3", ",", "\n", "\"dense_size\"", ":", "[", "128", ",", "128", ",", "10", "]", ",", "\n", "\"dense_activation\"", ":", "\"relu\"", ",", "\n", "\"other_dense_kwargs\"", ":", "{", "\"use_bias\"", ":", "False", "}", ",", "\n", "# Dropout", "\n", "\"dropout_conv\"", ":", "[", "0", ",", "1", ",", "2", "]", ",", "\n", "\"dropout_dense\"", ":", "2", "\n", "}", "\n", "encoder_2", "=", "Conv1DEncoder", "(", "hparams", ")", "\n", "# nlayers = nconv-pool + nconv + npool + ndense + ndropout + flatten", "\n", "self", ".", "assertEqual", "(", "len", "(", "encoder_2", ".", "layers", ")", ",", "1", "+", "1", "+", "1", "+", "3", "+", "4", "+", "1", ")", "\n", "self", ".", "assertTrue", "(", "isinstance", "(", "encoder_2", ".", "layer_by_name", "(", "\"conv_pool_1\"", ")", ",", "\n", "tx", ".", "core", ".", "MergeLayer", ")", ")", "\n", "for", "layer", "in", "encoder_2", ".", "layers", "[", "1", "]", ".", "layers", ":", "\n", "            ", "self", ".", "assertTrue", "(", "isinstance", "(", "layer", ",", "tx", ".", "core", ".", "SequentialLayer", ")", ")", "\n", "\n", "", "inputs_2", "=", "tf", ".", "ones", "(", "[", "64", ",", "16", ",", "300", "]", ",", "tf", ".", "float32", ")", "\n", "outputs_2", "=", "encoder_2", "(", "inputs_2", ")", "\n", "self", ".", "assertEqual", "(", "outputs_2", ".", "shape", ",", "[", "64", ",", "10", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.encoders.conv_encoders_test.Conv1DEncoderTest.test_unknown_seq_length": [[66, 114], ["texar.modules.encoders.conv_encoders.Conv1DEncoder", "tensorflow.placeholder", "texar.modules.encoders.conv_encoders.Conv1DEncoder.", "conv_encoders_test.Conv1DEncoderTest.assertEqual", "texar.modules.encoders.conv_encoders.Conv1DEncoder", "conv_encoders_test.Conv1DEncoderTest.assertEqual", "conv_encoders_test.Conv1DEncoderTest.assertTrue", "tensorflow.placeholder", "texar.modules.encoders.conv_encoders.Conv1DEncoder.", "conv_encoders_test.Conv1DEncoderTest.assertEqual", "texar.modules.encoders.conv_encoders.Conv1DEncoder", "tensorflow.placeholder", "texar.modules.encoders.conv_encoders.Conv1DEncoder.", "conv_encoders_test.Conv1DEncoderTest.assertEqual", "len", "isinstance", "texar.modules.encoders.conv_encoders.Conv1DEncoder.layer_by_name"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.networks.network_base.FeedForwardNetworkBase.layer_by_name"], ["", "def", "test_unknown_seq_length", "(", "self", ")", ":", "\n", "        ", "\"\"\"Tests use of pooling layer when the seq_length dimension of inputs\n        is `None`.\n        \"\"\"", "\n", "encoder_1", "=", "Conv1DEncoder", "(", ")", "\n", "inputs_1", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "[", "64", ",", "None", ",", "300", "]", ")", "\n", "outputs_1", "=", "encoder_1", "(", "inputs_1", ")", "\n", "self", ".", "assertEqual", "(", "outputs_1", ".", "shape", ",", "[", "64", ",", "128", "]", ")", "\n", "\n", "hparams", "=", "{", "\n", "# Conv layers", "\n", "\"num_conv_layers\"", ":", "2", ",", "\n", "\"filters\"", ":", "128", ",", "\n", "\"kernel_size\"", ":", "[", "[", "3", ",", "4", ",", "5", "]", ",", "4", "]", ",", "\n", "# Pooling layers", "\n", "\"pooling\"", ":", "\"AveragePooling\"", ",", "\n", "\"pool_size\"", ":", "[", "2", ",", "None", "]", ",", "\n", "# Dense layers", "\n", "\"num_dense_layers\"", ":", "1", ",", "\n", "\"dense_size\"", ":", "10", ",", "\n", "}", "\n", "encoder", "=", "Conv1DEncoder", "(", "hparams", ")", "\n", "# nlayers = nconv-pool + nconv + npool + ndense + ndropout + flatten", "\n", "self", ".", "assertEqual", "(", "len", "(", "encoder", ".", "layers", ")", ",", "1", "+", "1", "+", "1", "+", "1", "+", "1", "+", "1", ")", "\n", "self", ".", "assertTrue", "(", "isinstance", "(", "encoder", ".", "layer_by_name", "(", "'pool_2'", ")", ",", "\n", "tx", ".", "core", ".", "AverageReducePooling1D", ")", ")", "\n", "\n", "inputs", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "[", "64", ",", "None", ",", "300", "]", ")", "\n", "outputs", "=", "encoder", "(", "inputs", ")", "\n", "self", ".", "assertEqual", "(", "outputs", ".", "shape", ",", "[", "64", ",", "10", "]", ")", "\n", "\n", "hparams_2", "=", "{", "\n", "# Conv layers", "\n", "\"num_conv_layers\"", ":", "1", ",", "\n", "\"filters\"", ":", "128", ",", "\n", "\"kernel_size\"", ":", "4", ",", "\n", "\"other_conv_kwargs\"", ":", "{", "'data_format'", ":", "'channels_first'", "}", ",", "\n", "# Pooling layers", "\n", "\"pooling\"", ":", "\"MaxPooling\"", ",", "\n", "\"other_pool_kwargs\"", ":", "{", "'data_format'", ":", "'channels_first'", "}", ",", "\n", "# Dense layers", "\n", "\"num_dense_layers\"", ":", "1", ",", "\n", "\"dense_size\"", ":", "10", ",", "\n", "}", "\n", "encoder_2", "=", "Conv1DEncoder", "(", "hparams_2", ")", "\n", "inputs_2", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "[", "64", ",", "300", ",", "None", "]", ")", "\n", "outputs_2", "=", "encoder_2", "(", "inputs_2", ")", "\n", "self", ".", "assertEqual", "(", "outputs_2", ".", "shape", ",", "[", "64", ",", "10", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.encoders.hierarchical_encoders.HierarchicalRNNEncoder.__init__": [[45, 79], ["texar.modules.encoders.encoder_base.EncoderBase.__init__", "texar.utils.utils.get_instance_kwargs", "texar.utils.utils.get_instance_kwargs", "isinstance", "isinstance", "tensorflow.variable_scope", "tensorflow.variable_scope", "texar.utils.utils.check_or_get_instance", "tensorflow.variable_scope", "tensorflow.variable_scope", "tensorflow.variable_scope", "texar.utils.utils.check_or_get_instance", "tensorflow.variable_scope", "texar.utils.utils.check_or_get_instance"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.text_infilling.self_attn_hyperparams.Hyperparams.__init__", "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.utils.get_instance_kwargs", "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.utils.get_instance_kwargs", "home.repos.pwc.inspect_result.VegB_Text_Infilling.agents.agent_base.AgentBase.variable_scope", "home.repos.pwc.inspect_result.VegB_Text_Infilling.agents.agent_base.AgentBase.variable_scope", "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.utils.check_or_get_instance", "home.repos.pwc.inspect_result.VegB_Text_Infilling.agents.agent_base.AgentBase.variable_scope", "home.repos.pwc.inspect_result.VegB_Text_Infilling.agents.agent_base.AgentBase.variable_scope", "home.repos.pwc.inspect_result.VegB_Text_Infilling.agents.agent_base.AgentBase.variable_scope", "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.utils.check_or_get_instance", "home.repos.pwc.inspect_result.VegB_Text_Infilling.agents.agent_base.AgentBase.variable_scope", "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.utils.check_or_get_instance"], ["def", "__init__", "(", "self", ",", "encoder_major", "=", "None", ",", "encoder_minor", "=", "None", ",", "\n", "hparams", "=", "None", ")", ":", "\n", "        ", "EncoderBase", ".", "__init__", "(", "self", ",", "hparams", ")", "\n", "\n", "encoder_major_hparams", "=", "utils", ".", "get_instance_kwargs", "(", "\n", "None", ",", "self", ".", "_hparams", ".", "encoder_major_hparams", ")", "\n", "encoder_minor_hparams", "=", "utils", ".", "get_instance_kwargs", "(", "\n", "None", ",", "self", ".", "_hparams", ".", "encoder_minor_hparams", ")", "\n", "\n", "if", "isinstance", "(", "encoder_major", ",", "EncoderBase", ")", ":", "\n", "            ", "self", ".", "_encoder_major", "=", "encoder_major", "\n", "", "else", ":", "\n", "            ", "with", "tf", ".", "variable_scope", "(", "self", ".", "variable_scope", ".", "name", ")", ":", "\n", "                ", "with", "tf", ".", "variable_scope", "(", "'encoder_major'", ")", ":", "\n", "                    ", "self", ".", "_encoder_major", "=", "utils", ".", "check_or_get_instance", "(", "\n", "self", ".", "_hparams", ".", "encoder_major_type", ",", "\n", "encoder_major_hparams", ",", "\n", "[", "'texar.modules.encoders'", ",", "'texar.custom'", "]", ")", "\n", "", "", "", "if", "isinstance", "(", "encoder_minor", ",", "EncoderBase", ")", ":", "\n", "            ", "self", ".", "_encoder_minor", "=", "encoder_minor", "\n", "", "elif", "self", ".", "_hparams", ".", "config_share", ":", "\n", "            ", "with", "tf", ".", "variable_scope", "(", "self", ".", "variable_scope", ".", "name", ")", ":", "\n", "                ", "with", "tf", ".", "variable_scope", "(", "'encoder_minor'", ")", ":", "\n", "                    ", "self", ".", "_encoder_minor", "=", "utils", ".", "check_or_get_instance", "(", "\n", "self", ".", "_hparams", ".", "encoder_major_type", ",", "\n", "encoder_major_hparams", ",", "\n", "[", "'texar.modules.encoders'", ",", "'texar.custom'", "]", ")", "\n", "", "", "", "else", ":", "\n", "            ", "with", "tf", ".", "variable_scope", "(", "self", ".", "variable_scope", ".", "name", ")", ":", "\n", "                ", "with", "tf", ".", "variable_scope", "(", "'encoder_minor'", ")", ":", "\n", "                    ", "self", ".", "_encoder_minor", "=", "utils", ".", "check_or_get_instance", "(", "\n", "self", ".", "_hparams", ".", "encoder_minor_type", ",", "\n", "encoder_minor_hparams", ",", "\n", "[", "'texar.modules.encoders'", ",", "'texar.custom'", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.encoders.hierarchical_encoders.HierarchicalRNNEncoder.default_hparams": [[80, 126], ["hparams.update", "texar.modules.encoders.encoder_base.EncoderBase.default_hparams"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.core.replay_memories.DequeReplayMemory.default_hparams"], ["", "", "", "", "@", "staticmethod", "\n", "def", "default_hparams", "(", ")", ":", "\n", "        ", "\"\"\"Returns a dictionary of hyperparameters with default values.\n        The dictionary has the following structure and default values.\n\n        Returns:\n            dict: Adictionary with following structure and values:\n            .. code-block:: python\n                {\n                    \"encoder_major_type\": \"UnidirectionalRNNEncoder\",\n                    \"encoder_major_hparams\": {},\n                    \"encoder_minor_type\": \"UnidirectionalRNNEncoder\",\n                    \"encoder_minor_hparams\": {},\n                    \"config_share\": False,\n                    \"name\": \"hierarchical_encoder_wrapper\"\n                }\n\n            Here:\n\n            \"encoder_major_type\":\n                The class name of major encoder which can be found in\n                ~texar.modules.encoders or ~texar.custom.\n\n            \"encoder_major_hparams\":\n                The hparams for major encoder's construction.\n\n            \"config_share\":\n                :attr:`encoder_minor_type` and :attr:`encoder_minor_hparams`\n                will be replaced by major's corresponding hparams if set to true.\n\n            \"name\":\n                Name of the encoder.\n        \"\"\"", "\n", "hparams", "=", "{", "\n", "\"name\"", ":", "\"hierarchical_encoder\"", ",", "\n", "\"encoder_major_type\"", ":", "\"UnidirectionalRNNEncoder\"", ",", "\n", "\"encoder_major_hparams\"", ":", "{", "}", ",", "\n", "\"encoder_minor_type\"", ":", "\"UnidirectionalRNNEncoder\"", ",", "\n", "\"encoder_minor_hparams\"", ":", "{", "}", ",", "\n", "\"config_share\"", ":", "False", ",", "\n", "\"@no_typecheck\"", ":", "[", "\n", "'encoder_major_hparams'", ",", "\n", "'encoder_minor_hparams'", "]", "\n", "}", "\n", "hparams", ".", "update", "(", "EncoderBase", ".", "default_hparams", "(", ")", ")", "\n", "return", "hparams", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.encoders.hierarchical_encoders.HierarchicalRNNEncoder._build": [[127, 242], ["hierarchical_encoders.HierarchicalRNNEncoder._build.kwargs_split"], "methods", ["None"], ["", "def", "_build", "(", "self", ",", "inputs", ",", "order", "=", "'btu'", ",", "\n", "medium", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"Encodes the inputs.\n\n        Args:\n            inputs: A 4D tensor of shape [B, T, U, dim], where\n                        B: batch_size\n                        T: the major seq len (context-level length)\n                        U: the minor seq len (utterance-level length)\n\n                    The order of first three dimensions can be changed\n                    regarding to :attr:`time_major` of the two encoders.\n\n            order (optional): a 3-char string with some order of 'b', 't', 'u',\n                              specifying the order of inputs dimension.\n                              Following four can be accepted:\n\n                              'btu': time_major=False for both. (default)\n                              'utb': time_major=True for both.\n                              'tbu': time_major=True for major encoder only.\n                              'ubt': time_major=True for minor encoder only.\n\n            medium (optional): A list of callable successively rocess the\n                               final states of minor encoder to be the input\n                               for major encoder. Extra meta like speaker token\n                               can be added using this function.\n                               If not specified, a final state will be flatten\n                               into a vector while hidden part of LSTMTuple is\n                               skipped, see :meth:`flatten` for details.\n\n                               Use :attr:`states_minor_before_medium` and\n                               :attr:`states_minor_after_medium` to see its input\n                               and output respectively.\n\n            **kwargs: Optional keyword arguments of `tensorflow.nn.dynamic_rnn`,\n                      such as `sequence_length`, `initial_state`, etc.\n\n                      By default, arguments except `initial_state` and\n                      `sequence_length` will be sent to both major and minor\n                      encoders. To specify the encoder that arguments sent to, add\n                      '_minor'/'_major' as its suffix.\n\n                      `initial_state` and `sequence_length` will be sent to minor\n                      encoder only if not specifing its encoder.\n\n                      `initial_state` and `sequence_length` sent to minor encoder\n                      can be either 1-D tensor or 2-D tensor, with BxT units following\n                      correct order.\n\n        Returns:\n            Outputs and final state of the major encoder.\n\n        \"\"\"", "\n", "\n", "def", "kwargs_split", "(", "kwargs", ")", ":", "\n", "            ", "kwargs_minor", ",", "kwargs_major", "=", "{", "}", ",", "{", "}", "\n", "for", "k", ",", "v", "in", "kwargs", ".", "items", "(", ")", ":", "\n", "                ", "if", "len", "(", "k", ")", "<", "5", "or", "(", "k", "[", "-", "5", ":", "]", "not", "in", "[", "'major'", ",", "'minor'", "]", ")", ":", "\n", "                    ", "kwargs_minor", "[", "k", "]", "=", "v", "\n", "if", "k", "not", "in", "[", "'sequence_length'", ",", "'initial_state'", "]", ":", "\n", "                        ", "kwargs_major", "[", "k", "]", "=", "v", "\n", "", "else", ":", "\n", "                        ", "kwargs_minor", "[", "k", "]", "=", "tf", ".", "reshape", "(", "v", ",", "[", "-", "1", "]", ")", "\n", "", "", "", "for", "k", ",", "v", "in", "kwargs", ".", "items", "(", ")", ":", "\n", "                ", "if", "len", "(", "k", ")", ">=", "6", "and", "k", "[", "-", "6", ":", "]", "==", "[", "'_minor'", "]", ":", "\n", "                    ", "kwargs_minor", "[", "k", "[", ":", "-", "6", "]", "]", "=", "v", "\n", "", "if", "len", "(", "k", ")", ">=", "6", "and", "k", "[", "-", "6", ":", "]", "==", "[", "'_major'", "]", ":", "\n", "                    ", "kwargs_major", "[", "k", "[", ":", "-", "6", "]", "]", "=", "v", "\n", "\n", "", "", "return", "kwargs_minor", ",", "kwargs_major", "\n", "\n", "", "kwargs_minor", ",", "kwargs_major", "=", "kwargs_split", "(", "kwargs", ")", "\n", "\n", "shape", "=", "tf", ".", "shape", "(", "inputs", ")", "[", ":", "3", "]", "\n", "\n", "expand", ",", "shape", "=", "self", ".", "_get_flatten_order", "(", "\n", "order", ",", "kwargs_major", ",", "kwargs_minor", ",", "tf", ".", "shape", "(", "inputs", ")", ")", "\n", "\n", "inputs", "=", "tf", ".", "reshape", "(", "inputs", ",", "shape", "+", "[", "inputs", ".", "shape", "[", "3", "]", "]", ")", "\n", "\n", "outputs_minor", ",", "states_minor", "=", "self", ".", "_encoder_minor", "(", "inputs", ",", "\n", "**", "kwargs_minor", ")", "\n", "\n", "self", ".", "states_minor_before_medium", "=", "states_minor", "\n", "\n", "if", "medium", "is", "None", ":", "\n", "            ", "states_minor", "=", "self", ".", "flatten", "(", "states_minor", ")", "\n", "", "else", ":", "\n", "            ", "if", "not", "isinstance", "(", "medium", ",", "collections", ".", "Sequence", ")", ":", "\n", "                ", "raise", "ValueError", "(", "'medium is not iterable.'", ")", "\n", "", "for", "fn", "in", "medium", ":", "\n", "                ", "if", "isinstance", "(", "fn", ",", "str", ")", "and", "fn", "==", "'flatten'", ":", "\n", "                    ", "states_minor", "=", "self", ".", "flatten", "(", "states_minor", ")", "\n", "", "else", ":", "\n", "                    ", "states_minor", "=", "fn", "(", "states_minor", ")", "\n", "\n", "", "", "", "self", ".", "states_minor_after_medium", "=", "states_minor", "\n", "\n", "states_minor", "=", "tf", ".", "reshape", "(", "\n", "states_minor", ",", "tf", ".", "concat", "(", "[", "expand", ",", "tf", ".", "shape", "(", "states_minor", ")", "[", "1", ":", "]", "]", ",", "0", ")", ")", "\n", "\n", "outputs_major", ",", "states_major", "=", "self", ".", "_encoder_major", "(", "states_minor", ",", "\n", "**", "kwargs_major", ")", "\n", "\n", "# Add trainable variables of `self._cell` which may be constructed", "\n", "# externally", "\n", "\n", "if", "self", ".", "_built", "==", "False", ":", "\n", "            ", "self", ".", "_add_trainable_variable", "(", "\n", "self", ".", "_encoder_minor", ".", "trainable_variables", ")", "\n", "self", ".", "_add_trainable_variable", "(", "\n", "self", ".", "_encoder_major", ".", "trainable_variables", ")", "\n", "self", ".", "_built", "=", "True", "\n", "\n", "", "return", "outputs_major", ",", "states_major", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.encoders.hierarchical_encoders.HierarchicalRNNEncoder._get_flatten_order": [[243, 285], ["kwargs_minor.get", "kwargs_major.get", "kwargs_minor.setdefault", "kwargs_major.setdefault", "ValueError", "kwargs_minor.setdefault", "kwargs_major.setdefault", "hierarchical_encoders.HierarchicalRNNEncoder._get_flatten_order.error_message"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.core.replay_memories.DequeReplayMemory.get", "home.repos.pwc.inspect_result.VegB_Text_Infilling.core.replay_memories.DequeReplayMemory.get"], ["", "@", "staticmethod", "\n", "def", "_get_flatten_order", "(", "order", ",", "kwargs_minor", ",", "kwargs_major", ",", "shape", ")", ":", "\n", "        ", "def", "error_message", "(", "order", ")", ":", "\n", "            ", "return", "(", "'Fail to match input order \\'{}\\''", "'with given `time_major` params.'", ")", ".", "format", "(", "order", ")", "\n", "\n", "", "time_major_minor", "=", "kwargs_minor", ".", "get", "(", "'time_major'", ",", "None", ")", "\n", "time_major_major", "=", "kwargs_major", ".", "get", "(", "'time_major'", ",", "None", ")", "\n", "if", "order", "==", "'btu'", ":", "\n", "            ", "if", "not", "(", "(", "time_major_minor", "is", "None", "or", "not", "time_major_minor", ")", "and", "(", "time_major_major", "is", "None", "or", "not", "time_major_major", ")", ")", ":", "\n", "                ", "raise", "ValueError", "(", "error_message", "(", "order", ")", ")", "\n", "", "kwargs_minor", ".", "setdefault", "(", "'time_major'", ",", "False", ")", "\n", "kwargs_major", ".", "setdefault", "(", "'time_major'", ",", "False", ")", "\n", "expand", "=", "shape", "[", "0", ":", "2", "]", "\n", "shape", "=", "[", "shape", "[", "0", "]", "*", "shape", "[", "1", "]", ",", "shape", "[", "2", "]", "]", "\n", "", "elif", "order", "==", "'utb'", ":", "\n", "            ", "if", "not", "(", "(", "time_major_minor", "is", "None", "or", "time_major_minor", ")", "and", "(", "time_major_major", "is", "None", "or", "time_major_major", ")", ")", ":", "\n", "                ", "raise", "ValueError", "(", "error_message", "(", "order", ")", ")", "\n", "", "kwargs_minor", ".", "setdefault", "(", "'time_major'", ",", "True", ")", "\n", "kwargs_major", ".", "setdefault", "(", "'time_major'", ",", "True", ")", "\n", "expand", "=", "shape", "[", "1", ":", "3", "]", "\n", "shape", "=", "[", "shape", "[", "0", "]", ",", "shape", "[", "1", "]", "*", "shape", "[", "2", "]", "]", "\n", "", "elif", "order", "==", "'tbu'", ":", "\n", "            ", "if", "not", "(", "(", "time_major_minor", "is", "None", "or", "not", "time_major_minor", ")", "and", "(", "time_major_major", "is", "None", "or", "time_major_major", ")", ")", ":", "\n", "                ", "raise", "ValueError", "(", "error_message", "(", "order", ")", ")", "\n", "", "kwargs_minor", ".", "setdefault", "(", "'time_major'", ",", "False", ")", "\n", "kwargs_major", ".", "setdefault", "(", "'time_major'", ",", "True", ")", "\n", "expand", "=", "shape", "[", "0", ":", "2", "]", "\n", "shape", "=", "[", "shape", "[", "0", "]", "*", "shape", "[", "1", "]", ",", "shape", "[", "2", "]", "]", "\n", "", "elif", "order", "==", "'ubt'", ":", "\n", "            ", "if", "not", "(", "(", "time_major_minor", "is", "None", "or", "time_major_minor", ")", "and", "(", "time_major_major", "is", "None", "or", "not", "time_major_major", ")", ")", ":", "\n", "                ", "raise", "ValueError", "(", "error_message", "(", "order", ")", ")", "\n", "", "kwargs_minor", ".", "setdefault", "(", "'time_major'", ",", "True", ")", "\n", "kwargs_major", ".", "setdefault", "(", "'time_major'", ",", "False", ")", "\n", "expand", "=", "shape", "[", "1", ":", "3", "]", "\n", "shape", "=", "[", "shape", "[", "0", "]", ",", "shape", "[", "1", "]", "*", "shape", "[", "2", "]", "]", "\n", "\n", "", "return", "expand", ",", "shape", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.encoders.hierarchical_encoders.HierarchicalRNNEncoder.flatten": [[286, 299], ["isinstance", "isinstance", "tensorflow.concat", "hierarchical_encoders.HierarchicalRNNEncoder.flatten"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.encoders.hierarchical_encoders.HierarchicalRNNEncoder.flatten"], ["", "@", "staticmethod", "\n", "def", "flatten", "(", "x", ")", ":", "\n", "        ", "\"\"\"Flatten a state into tf vector while hidden part of LSTMTuple are\n        skipped.\n        :arg:`medium` supports 'flatten' str item to recoginize this function.\n        \"\"\"", "\n", "if", "isinstance", "(", "x", ",", "LSTMStateTuple", ")", ":", "\n", "            ", "return", "x", ".", "h", "\n", "", "if", "isinstance", "(", "x", ",", "collections", ".", "Sequence", ")", ":", "\n", "            ", "return", "tf", ".", "concat", "(", "\n", "[", "HierarchicalRNNEncoder", ".", "flatten", "(", "v", ")", "for", "v", "in", "x", "]", ",", "-", "1", ")", "\n", "", "else", ":", "\n", "            ", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.encoders.hierarchical_encoders.HierarchicalRNNEncoder.encoder_major": [[300, 303], ["None"], "methods", ["None"], ["", "", "@", "property", "\n", "def", "encoder_major", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_encoder_major", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.encoders.hierarchical_encoders.HierarchicalRNNEncoder.encoder_minor": [[304, 307], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "encoder_minor", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_encoder_minor", "\n", "", "", ""]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.encoders.rnn_encoders_test.UnidirectionalRNNEncoderTest.test_trainable_variables": [[24, 63], ["tensorflow.placeholder", "texar.modules.encoders.rnn_encoders.UnidirectionalRNNEncoder", "texar.modules.encoders.rnn_encoders.UnidirectionalRNNEncoder.", "rnn_encoders_test.UnidirectionalRNNEncoderTest.assertEqual", "texar.modules.encoders.rnn_encoders.UnidirectionalRNNEncoder", "texar.modules.encoders.rnn_encoders.UnidirectionalRNNEncoder.", "rnn_encoders_test.UnidirectionalRNNEncoderTest.assertEqual", "texar.modules.encoders.rnn_encoders.UnidirectionalRNNEncoder", "texar.modules.encoders.rnn_encoders.UnidirectionalRNNEncoder.", "rnn_encoders_test.UnidirectionalRNNEncoderTest.assertEqual", "texar.modules.encoders.rnn_encoders.UnidirectionalRNNEncoder.", "rnn_encoders_test.UnidirectionalRNNEncoderTest.assertEqual", "len", "len", "len", "len"], "methods", ["None"], ["def", "test_trainable_variables", "(", "self", ")", ":", "\n", "        ", "\"\"\"Tests the functionality of automatically collecting trainable\n        variables.\n        \"\"\"", "\n", "inputs", "=", "tf", ".", "placeholder", "(", "dtype", "=", "tf", ".", "float32", ",", "shape", "=", "[", "None", ",", "None", ",", "100", "]", ")", "\n", "\n", "# case 1", "\n", "encoder", "=", "UnidirectionalRNNEncoder", "(", ")", "\n", "_", ",", "_", "=", "encoder", "(", "inputs", ")", "\n", "self", ".", "assertEqual", "(", "len", "(", "encoder", ".", "trainable_variables", ")", ",", "2", ")", "\n", "\n", "# case 2", "\n", "hparams", "=", "{", "\n", "\"rnn_cell\"", ":", "{", "\n", "\"dropout\"", ":", "{", "\n", "\"input_keep_prob\"", ":", "0.5", "\n", "}", "\n", "}", "\n", "}", "\n", "encoder", "=", "UnidirectionalRNNEncoder", "(", "hparams", "=", "hparams", ")", "\n", "_", ",", "_", "=", "encoder", "(", "inputs", ")", "\n", "self", ".", "assertEqual", "(", "len", "(", "encoder", ".", "trainable_variables", ")", ",", "2", ")", "\n", "\n", "# case 3", "\n", "hparams", "=", "{", "\n", "\"output_layer\"", ":", "{", "\n", "\"num_layers\"", ":", "2", ",", "\n", "\"layer_size\"", ":", "[", "100", ",", "6", "]", ",", "\n", "\"activation\"", ":", "\"relu\"", ",", "\n", "\"final_layer_activation\"", ":", "\"identity\"", ",", "\n", "\"dropout_layer_ids\"", ":", "[", "0", ",", "1", ",", "2", "]", ",", "\n", "\"variational_dropout\"", ":", "False", "\n", "}", "\n", "}", "\n", "encoder", "=", "UnidirectionalRNNEncoder", "(", "hparams", "=", "hparams", ")", "\n", "_", ",", "_", "=", "encoder", "(", "inputs", ")", "\n", "self", ".", "assertEqual", "(", "len", "(", "encoder", ".", "trainable_variables", ")", ",", "2", "+", "2", "+", "2", ")", "\n", "_", ",", "_", "=", "encoder", "(", "inputs", ")", "\n", "self", ".", "assertEqual", "(", "len", "(", "encoder", ".", "trainable_variables", ")", ",", "2", "+", "2", "+", "2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.encoders.rnn_encoders_test.UnidirectionalRNNEncoderTest.test_encode": [[64, 111], ["texar.modules.encoders.rnn_encoders.UnidirectionalRNNEncoder", "tensorflow.random_uniform", "texar.modules.encoders.rnn_encoders.UnidirectionalRNNEncoder.", "texar.modules.encoders.rnn_encoders.UnidirectionalRNNEncoder", "tensorflow.random_uniform", "texar.modules.encoders.rnn_encoders.UnidirectionalRNNEncoder.", "rnn_encoders_test.UnidirectionalRNNEncoderTest.assertEqual", "rnn_encoders_test.UnidirectionalRNNEncoderTest.assertEqual", "rnn_encoders_test.UnidirectionalRNNEncoderTest.test_session", "sess.run", "sess.run", "rnn_encoders_test.UnidirectionalRNNEncoderTest.assertEqual", "rnn_encoders_test.UnidirectionalRNNEncoderTest.assertEqual", "rnn_encoders_test.UnidirectionalRNNEncoderTest.test_session", "sess.run", "sess.run", "rnn_encoders_test.UnidirectionalRNNEncoderTest.assertEqual", "tensorflow.global_variables_initializer", "tensorflow.global_variables_initializer"], "methods", ["None"], ["", "def", "test_encode", "(", "self", ")", ":", "\n", "        ", "\"\"\"Tests encoding.\n        \"\"\"", "\n", "# case 1", "\n", "encoder", "=", "UnidirectionalRNNEncoder", "(", ")", "\n", "\n", "max_time", "=", "8", "\n", "batch_size", "=", "16", "\n", "emb_dim", "=", "100", "\n", "inputs", "=", "tf", ".", "random_uniform", "(", "[", "batch_size", ",", "max_time", ",", "emb_dim", "]", ",", "\n", "maxval", "=", "1.", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "outputs", ",", "state", "=", "encoder", "(", "inputs", ")", "\n", "\n", "cell_dim", "=", "encoder", ".", "hparams", ".", "rnn_cell", ".", "kwargs", ".", "num_units", "\n", "with", "self", ".", "test_session", "(", ")", "as", "sess", ":", "\n", "            ", "sess", ".", "run", "(", "tf", ".", "global_variables_initializer", "(", ")", ")", "\n", "outputs_", ",", "state_", "=", "sess", ".", "run", "(", "[", "outputs", ",", "state", "]", ")", "\n", "self", ".", "assertEqual", "(", "outputs_", ".", "shape", ",", "(", "batch_size", ",", "max_time", ",", "cell_dim", ")", ")", "\n", "self", ".", "assertEqual", "(", "state_", "[", "0", "]", ".", "shape", ",", "(", "batch_size", ",", "cell_dim", ")", ")", "\n", "\n", "# case 2: with output layers", "\n", "", "hparams", "=", "{", "\n", "\"output_layer\"", ":", "{", "\n", "\"num_layers\"", ":", "2", ",", "\n", "\"layer_size\"", ":", "[", "100", ",", "6", "]", ",", "\n", "\"dropout_layer_ids\"", ":", "[", "0", ",", "1", ",", "2", "]", ",", "\n", "\"variational_dropout\"", ":", "True", "\n", "}", "\n", "}", "\n", "encoder", "=", "UnidirectionalRNNEncoder", "(", "hparams", "=", "hparams", ")", "\n", "\n", "max_time", "=", "8", "\n", "batch_size", "=", "16", "\n", "emb_dim", "=", "100", "\n", "inputs", "=", "tf", ".", "random_uniform", "(", "[", "batch_size", ",", "max_time", ",", "emb_dim", "]", ",", "\n", "maxval", "=", "1.", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "outputs", ",", "state", ",", "cell_outputs", ",", "output_size", "=", "encoder", "(", "\n", "inputs", ",", "return_cell_output", "=", "True", ",", "return_output_size", "=", "True", ")", "\n", "\n", "self", ".", "assertEqual", "(", "output_size", "[", "0", "]", ",", "6", ")", "\n", "self", ".", "assertEqual", "(", "cell_outputs", ".", "shape", "[", "-", "1", "]", ",", "encoder", ".", "cell", ".", "output_size", ")", "\n", "\n", "out_dim", "=", "encoder", ".", "hparams", ".", "output_layer", ".", "layer_size", "[", "-", "1", "]", "\n", "with", "self", ".", "test_session", "(", ")", "as", "sess", ":", "\n", "            ", "sess", ".", "run", "(", "tf", ".", "global_variables_initializer", "(", ")", ")", "\n", "outputs_", "=", "sess", ".", "run", "(", "outputs", ")", "\n", "self", ".", "assertEqual", "(", "outputs_", ".", "shape", ",", "(", "batch_size", ",", "max_time", ",", "out_dim", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.encoders.rnn_encoders_test.UnidirectionalRNNEncoderTest.test_encode_with_embedder": [[113, 128], ["texar.modules.embedders.embedders.WordEmbedder", "tensorflow.ones", "texar.modules.encoders.rnn_encoders.UnidirectionalRNNEncoder", "texar.modules.encoders.rnn_encoders.UnidirectionalRNNEncoder.", "texar.modules.embedders.embedders.WordEmbedder.", "rnn_encoders_test.UnidirectionalRNNEncoderTest.test_session", "sess.run", "sess.run", "rnn_encoders_test.UnidirectionalRNNEncoderTest.assertEqual", "rnn_encoders_test.UnidirectionalRNNEncoderTest.assertEqual", "tensorflow.global_variables_initializer"], "methods", ["None"], ["", "", "def", "test_encode_with_embedder", "(", "self", ")", ":", "\n", "        ", "\"\"\"Tests encoding companioned with :mod:`texar.modules.embedders`.\n        \"\"\"", "\n", "embedder", "=", "WordEmbedder", "(", "vocab_size", "=", "20", ",", "hparams", "=", "{", "\"dim\"", ":", "100", "}", ")", "\n", "inputs", "=", "tf", ".", "ones", "(", "[", "64", ",", "16", "]", ",", "dtype", "=", "tf", ".", "int32", ")", "\n", "\n", "encoder", "=", "UnidirectionalRNNEncoder", "(", ")", "\n", "outputs", ",", "state", "=", "encoder", "(", "embedder", "(", "inputs", ")", ")", "\n", "\n", "cell_dim", "=", "encoder", ".", "hparams", ".", "rnn_cell", ".", "kwargs", ".", "num_units", "\n", "with", "self", ".", "test_session", "(", ")", "as", "sess", ":", "\n", "            ", "sess", ".", "run", "(", "tf", ".", "global_variables_initializer", "(", ")", ")", "\n", "outputs_", ",", "state_", "=", "sess", ".", "run", "(", "[", "outputs", ",", "state", "]", ")", "\n", "self", ".", "assertEqual", "(", "outputs_", ".", "shape", ",", "(", "64", ",", "16", ",", "cell_dim", ")", ")", "\n", "self", ".", "assertEqual", "(", "state_", "[", "0", "]", ".", "shape", ",", "(", "64", ",", "cell_dim", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.encoders.rnn_encoders_test.BidirectionalRNNEncoderTest.test_trainable_variables": [[133, 177], ["tensorflow.placeholder", "texar.modules.encoders.rnn_encoders.BidirectionalRNNEncoder", "texar.modules.encoders.rnn_encoders.BidirectionalRNNEncoder.", "rnn_encoders_test.BidirectionalRNNEncoderTest.assertEqual", "texar.modules.encoders.rnn_encoders.BidirectionalRNNEncoder", "texar.modules.encoders.rnn_encoders.BidirectionalRNNEncoder.", "rnn_encoders_test.BidirectionalRNNEncoderTest.assertEqual", "texar.modules.encoders.rnn_encoders.BidirectionalRNNEncoder", "texar.modules.encoders.rnn_encoders.BidirectionalRNNEncoder.", "rnn_encoders_test.BidirectionalRNNEncoderTest.assertEqual", "texar.modules.encoders.rnn_encoders.BidirectionalRNNEncoder.", "rnn_encoders_test.BidirectionalRNNEncoderTest.assertEqual", "len", "len", "len", "len"], "methods", ["None"], ["def", "test_trainable_variables", "(", "self", ")", ":", "\n", "        ", "\"\"\"Tests the functionality of automatically collecting trainable\n        variables.\n        \"\"\"", "\n", "inputs", "=", "tf", ".", "placeholder", "(", "dtype", "=", "tf", ".", "float32", ",", "shape", "=", "[", "None", ",", "None", ",", "100", "]", ")", "\n", "\n", "# case 1", "\n", "encoder", "=", "BidirectionalRNNEncoder", "(", ")", "\n", "_", ",", "_", "=", "encoder", "(", "inputs", ")", "\n", "self", ".", "assertEqual", "(", "len", "(", "encoder", ".", "trainable_variables", ")", ",", "4", ")", "\n", "\n", "# case 2", "\n", "hparams", "=", "{", "\n", "\"rnn_cell_fw\"", ":", "{", "\n", "\"dropout\"", ":", "{", "\n", "\"input_keep_prob\"", ":", "0.5", "\n", "}", "\n", "}", "\n", "}", "\n", "encoder", "=", "BidirectionalRNNEncoder", "(", "hparams", "=", "hparams", ")", "\n", "_", ",", "_", "=", "encoder", "(", "inputs", ")", "\n", "self", ".", "assertEqual", "(", "len", "(", "encoder", ".", "trainable_variables", ")", ",", "4", ")", "\n", "\n", "# case 3", "\n", "hparams", "=", "{", "\n", "\"output_layer_fw\"", ":", "{", "\n", "\"num_layers\"", ":", "2", ",", "\n", "\"layer_size\"", ":", "[", "100", ",", "6", "]", ",", "\n", "\"activation\"", ":", "\"relu\"", ",", "\n", "\"final_layer_activation\"", ":", "\"identity\"", ",", "\n", "\"dropout_layer_ids\"", ":", "[", "0", ",", "1", ",", "2", "]", ",", "\n", "\"variational_dropout\"", ":", "False", "\n", "}", ",", "\n", "\"output_layer_bw\"", ":", "{", "\n", "\"num_layers\"", ":", "3", ",", "\n", "\"other_dense_kwargs\"", ":", "{", "\"use_bias\"", ":", "False", "}", "\n", "}", ",", "\n", "\"output_layer_share_config\"", ":", "False", "\n", "}", "\n", "encoder", "=", "BidirectionalRNNEncoder", "(", "hparams", "=", "hparams", ")", "\n", "_", ",", "_", "=", "encoder", "(", "inputs", ")", "\n", "self", ".", "assertEqual", "(", "len", "(", "encoder", ".", "trainable_variables", ")", ",", "4", "+", "4", "+", "3", ")", "\n", "_", ",", "_", "=", "encoder", "(", "inputs", ")", "\n", "self", ".", "assertEqual", "(", "len", "(", "encoder", ".", "trainable_variables", ")", ",", "4", "+", "4", "+", "3", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.encoders.rnn_encoders_test.BidirectionalRNNEncoderTest.test_encode": [[178, 229], ["texar.modules.encoders.rnn_encoders.BidirectionalRNNEncoder", "tensorflow.random_uniform", "texar.modules.encoders.rnn_encoders.BidirectionalRNNEncoder.", "texar.modules.encoders.rnn_encoders.BidirectionalRNNEncoder", "tensorflow.random_uniform", "texar.modules.encoders.rnn_encoders.BidirectionalRNNEncoder.", "rnn_encoders_test.BidirectionalRNNEncoderTest.assertEqual", "rnn_encoders_test.BidirectionalRNNEncoderTest.assertEqual", "rnn_encoders_test.BidirectionalRNNEncoderTest.assertEqual", "rnn_encoders_test.BidirectionalRNNEncoderTest.assertEqual", "rnn_encoders_test.BidirectionalRNNEncoderTest.test_session", "sess.run", "sess.run", "rnn_encoders_test.BidirectionalRNNEncoderTest.assertEqual", "rnn_encoders_test.BidirectionalRNNEncoderTest.assertEqual", "rnn_encoders_test.BidirectionalRNNEncoderTest.test_session", "sess.run", "sess.run", "rnn_encoders_test.BidirectionalRNNEncoderTest.assertEqual", "rnn_encoders_test.BidirectionalRNNEncoderTest.assertEqual", "tensorflow.global_variables_initializer", "tensorflow.global_variables_initializer"], "methods", ["None"], ["", "def", "test_encode", "(", "self", ")", ":", "\n", "        ", "\"\"\"Tests encoding.\n        \"\"\"", "\n", "# case 1", "\n", "encoder", "=", "BidirectionalRNNEncoder", "(", ")", "\n", "\n", "max_time", "=", "8", "\n", "batch_size", "=", "16", "\n", "emb_dim", "=", "100", "\n", "inputs", "=", "tf", ".", "random_uniform", "(", "[", "batch_size", ",", "max_time", ",", "emb_dim", "]", ",", "\n", "maxval", "=", "1.", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "outputs", ",", "state", "=", "encoder", "(", "inputs", ")", "\n", "\n", "cell_dim", "=", "encoder", ".", "hparams", ".", "rnn_cell_fw", ".", "kwargs", ".", "num_units", "\n", "with", "self", ".", "test_session", "(", ")", "as", "sess", ":", "\n", "            ", "sess", ".", "run", "(", "tf", ".", "global_variables_initializer", "(", ")", ")", "\n", "outputs_", ",", "state_", "=", "sess", ".", "run", "(", "[", "outputs", ",", "state", "]", ")", "\n", "self", ".", "assertEqual", "(", "outputs_", "[", "0", "]", ".", "shape", ",", "\n", "(", "batch_size", ",", "max_time", ",", "cell_dim", ")", ")", "\n", "self", ".", "assertEqual", "(", "state_", "[", "0", "]", "[", "0", "]", ".", "shape", ",", "(", "batch_size", ",", "cell_dim", ")", ")", "\n", "\n", "# case 2: with output layers", "\n", "", "hparams", "=", "{", "\n", "\"output_layer_fw\"", ":", "{", "\n", "\"num_layers\"", ":", "2", ",", "\n", "\"layer_size\"", ":", "[", "100", ",", "6", "]", ",", "\n", "\"dropout_layer_ids\"", ":", "[", "0", ",", "1", ",", "2", "]", ",", "\n", "\"variational_dropout\"", ":", "True", "\n", "}", "\n", "}", "\n", "encoder", "=", "BidirectionalRNNEncoder", "(", "hparams", "=", "hparams", ")", "\n", "\n", "max_time", "=", "8", "\n", "batch_size", "=", "16", "\n", "emb_dim", "=", "100", "\n", "inputs", "=", "tf", ".", "random_uniform", "(", "[", "batch_size", ",", "max_time", ",", "emb_dim", "]", ",", "\n", "maxval", "=", "1.", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "outputs", ",", "state", ",", "cell_outputs", ",", "output_size", "=", "encoder", "(", "\n", "inputs", ",", "return_cell_output", "=", "True", ",", "return_output_size", "=", "True", ")", "\n", "\n", "self", ".", "assertEqual", "(", "output_size", "[", "0", "]", "[", "0", "]", ",", "6", ")", "\n", "self", ".", "assertEqual", "(", "output_size", "[", "1", "]", "[", "0", "]", ",", "6", ")", "\n", "self", ".", "assertEqual", "(", "cell_outputs", "[", "0", "]", ".", "shape", "[", "-", "1", "]", ",", "encoder", ".", "cell_fw", ".", "output_size", ")", "\n", "self", ".", "assertEqual", "(", "cell_outputs", "[", "1", "]", ".", "shape", "[", "-", "1", "]", ",", "encoder", ".", "cell_bw", ".", "output_size", ")", "\n", "\n", "out_dim", "=", "encoder", ".", "hparams", ".", "output_layer_fw", ".", "layer_size", "[", "-", "1", "]", "\n", "with", "self", ".", "test_session", "(", ")", "as", "sess", ":", "\n", "            ", "sess", ".", "run", "(", "tf", ".", "global_variables_initializer", "(", ")", ")", "\n", "outputs_", "=", "sess", ".", "run", "(", "outputs", ")", "\n", "self", ".", "assertEqual", "(", "outputs_", "[", "0", "]", ".", "shape", ",", "(", "batch_size", ",", "max_time", ",", "out_dim", ")", ")", "\n", "self", ".", "assertEqual", "(", "outputs_", "[", "1", "]", ".", "shape", ",", "(", "batch_size", ",", "max_time", ",", "out_dim", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.encoders.transformer_encoders.TransformerEncoder.__init__": [[39, 80], ["texar.modules.encoders.encoder_base.EncoderBase.__init__", "tensorflow.variable_scope", "isinstance", "tensorflow.variable_scope", "tensorflow.get_variable_scope().set_initializer", "texar.modules.embedders.position_embedders.SinusoidsPositionEmbedder", "transformer_encoders.TransformerEncoder._embedding.get_shape().as_list", "tensorflow.get_variable", "tensorflow.gather", "texar.core.layers.get_initializer", "tensorflow.concat", "tensorflow.concat", "transformer_encoders.TransformerEncoder._embedding.get_shape().as_list", "tensorflow.get_variable_scope", "transformer_encoders.TransformerEncoder._embedding.get_shape", "tensorflow.zeros", "tensorflow.zeros", "transformer_encoders.TransformerEncoder._embedding.get_shape"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.text_infilling.self_attn_hyperparams.Hyperparams.__init__", "home.repos.pwc.inspect_result.VegB_Text_Infilling.agents.agent_base.AgentBase.variable_scope", "home.repos.pwc.inspect_result.VegB_Text_Infilling.agents.agent_base.AgentBase.variable_scope", "home.repos.pwc.inspect_result.VegB_Text_Infilling.core.layers.get_initializer"], ["def", "__init__", "(", "self", ",", "\n", "embedding", ",", "\n", "vocab_size", "=", "None", ",", "\n", "hparams", "=", "None", ")", ":", "\n", "        ", "EncoderBase", ".", "__init__", "(", "self", ",", "hparams", ")", "\n", "self", ".", "_vocab_size", "=", "vocab_size", "\n", "self", ".", "_embedding", "=", "None", "\n", "self", ".", "enc", "=", "None", "\n", "with", "tf", ".", "variable_scope", "(", "self", ".", "variable_scope", ")", ":", "\n", "            ", "if", "self", ".", "_hparams", ".", "initializer", ":", "\n", "                ", "tf", ".", "get_variable_scope", "(", ")", ".", "set_initializer", "(", "\n", "layers", ".", "get_initializer", "(", "self", ".", "_hparams", ".", "initializer", ")", ")", "\n", "", "if", "self", ".", "_hparams", ".", "position_embedder", ".", "name", "==", "'sinusoids'", ":", "\n", "                ", "self", ".", "position_embedder", "=", "position_embedders", ".", "SinusoidsPositionEmbedder", "(", "self", ".", "_hparams", ".", "position_embedder", ".", "hparams", ")", "\n", "\n", "", "", "if", "self", ".", "_hparams", ".", "use_embedding", ":", "\n", "            ", "if", "isinstance", "(", "embedding", ",", "tf", ".", "Variable", ")", ":", "\n", "                ", "self", ".", "_embedding", "=", "embedding", "\n", "", "embed_dim", "=", "self", ".", "_embedding", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", "[", "-", "1", "]", "\n", "if", "self", ".", "_hparams", ".", "zero_pad", ":", "# TODO(zhiting): vocab has zero pad", "\n", "                ", "if", "not", "self", ".", "_hparams", ".", "bos_pad", ":", "\n", "                    ", "self", ".", "_embedding", "=", "tf", ".", "concat", "(", "(", "tf", ".", "zeros", "(", "shape", "=", "[", "1", ",", "embed_dim", "]", ")", ",", "\n", "self", ".", "_embedding", "[", "1", ":", ",", ":", "]", ")", ",", "0", ")", "\n", "", "else", ":", "\n", "                    ", "self", ".", "_embedding", "=", "tf", ".", "concat", "(", "(", "tf", ".", "zeros", "(", "shape", "=", "[", "2", ",", "embed_dim", "]", ")", ",", "\n", "self", ".", "_embedding", "[", "2", ":", ",", ":", "]", ")", ",", "0", ")", "\n", "", "", "if", "self", ".", "_vocab_size", "is", "None", ":", "\n", "                ", "self", ".", "_vocab_size", "=", "self", ".", "_embedding", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", "[", "0", "]", "\n", "", "", "with", "tf", ".", "variable_scope", "(", "self", ".", "variable_scope", ")", ":", "\n", "            ", "if", "self", ".", "_hparams", ".", "target_space_id", "is", "not", "None", ":", "\n", "                ", "space_embedding", "=", "tf", ".", "get_variable", "(", "'target_space_embedding'", ",", "[", "32", ",", "embed_dim", "]", ")", "\n", "self", ".", "target_symbol_embedding", "=", "tf", ".", "gather", "(", "space_embedding", ",", "self", ".", "_hparams", ".", "target_space_id", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "target_symbol_embedding", "=", "None", "\n", "", "", "self", ".", "stack_output", "=", "None", "\n", "", "@", "staticmethod", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.encoders.transformer_encoders.TransformerEncoder.default_hparams": [[80, 130], ["None"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "default_hparams", "(", ")", ":", "\n", "        ", "\"\"\"Returns a dictionary of hyperparameters with default values.\n        The dictionary has the following structure and default values.\n        See :meth:`~texar.core.layers.default_rnn_cell_hparams` for the\n        default rnn cell hyperparameters, and\n        :meth:`~texar.core.layers.default_embedding_hparams` for the default\n        embedding hyperparameters.\n        .. code-block:: python\n            {\n                # (bool) Wether embedding is used in the encoder. If `True`\n                # (default), input to the encoder should contain integer\n                # indexes and will be used to look up the embedding vectors.\n                # If `False`, the input is directly fed into the RNN to encode.\n                \"use_embedding\": True,\n\n                # A dictionary of token embedding hyperparameters for embedding\n                # initialization.\n                #\n                # Ignored if \"use_embedding\" is `False`, or a tf.Variable\n                # is given to `embedding` in the encoder constructor. Note that\n                # in the second case, the embedding variable might be updated\n                # outside the encoder even if \"embedding.trainable\" is set to\n                # `False` and not updated by the encoder.\n                #\n                # If a Tensor or array is given to `embedding` in the\n                # constructor, \"dim\" and \"initializer\" in the configuration\n                # are ignored.\n                \"embedding\": texar.core.layers.default_embedding_hparams(),\n                # Name of the encoder.\n                \"name\": \"transformer_encoder\"\n            }\n        \"\"\"", "\n", "return", "{", "\n", "'initializer'", ":", "None", ",", "\n", "'multiply_embedding_mode'", ":", "'sqrt_depth'", ",", "\n", "\"use_embedding\"", ":", "True", ",", "\n", "\"position_embedder\"", ":", "None", ",", "\n", "\"name\"", ":", "\"encoder\"", ",", "\n", "\"zero_pad\"", ":", "False", ",", "\n", "\"bos_pad\"", ":", "False", ",", "\n", "'sinusoid'", ":", "True", ",", "\n", "'embedding_dropout'", ":", "0.1", ",", "\n", "'attention_dropout'", ":", "0.1", ",", "\n", "'residual_dropout'", ":", "0.1", ",", "\n", "'num_blocks'", ":", "6", ",", "\n", "'num_heads'", ":", "8", ",", "\n", "'poswise_feedforward'", ":", "None", ",", "\n", "'target_space_id'", ":", "None", ",", "\n", "'num_units'", ":", "512", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.encoders.transformer_encoders.TransformerEncoder._build": [[133, 209], ["tensorflow.to_float", "tensorflow.nn.embedding_lookup", "texar.utils.shapes.shape_list", "texar.core.attentions.attention_bias_ignore_padding", "transformer_encoders.TransformerEncoder.position_embedder", "tensorflow.layers.dropout", "texar.utils.transformer_utils.PadRemover", "range", "texar.core.layers.layer_normalize", "tensorflow.equal", "tensorflow.reshape", "texar.utils.shapes.shape_list", "texar.utils.shapes.shape_list", "transformer_encoders.TransformerEncoder._add_internal_trainable_variables", "texar.context.global_mode_train", "tensorflow.variable_scope", "texar.modules.networks.networks.FeedForwardNetwork", "tensorflow.variable_scope", "texar.core.attentions.multihead_attention", "tensorflow.variable_scope", "texar.core.layers.layer_normalize", "texar.utils.shapes.shape_list", "tensorflow.reshape", "tensorflow.expand_dims", "tensorflow.layers.dropout", "tensorflow.reshape", "tensorflow.layers.dropout", "texar.utils.transformer_utils.PadRemover.remove", "texar.modules.networks.networks.FeedForwardNetwork.", "texar.utils.transformer_utils.PadRemover.restore", "texar.core.layers.layer_normalize", "texar.context.global_mode_train", "tensorflow.squeeze", "texar.context.global_mode_train"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.shapes.shape_list", "home.repos.pwc.inspect_result.VegB_Text_Infilling.core.attentions.attention_bias_ignore_padding", "home.repos.pwc.inspect_result.VegB_Text_Infilling.core.layers.layer_normalize", "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.shapes.shape_list", "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.shapes.shape_list", "home.repos.pwc.inspect_result.VegB_Text_Infilling.texar.module_base.ModuleBase._add_internal_trainable_variables", "home.repos.pwc.inspect_result.VegB_Text_Infilling.texar.context.global_mode_train", "home.repos.pwc.inspect_result.VegB_Text_Infilling.agents.agent_base.AgentBase.variable_scope", "home.repos.pwc.inspect_result.VegB_Text_Infilling.agents.agent_base.AgentBase.variable_scope", "home.repos.pwc.inspect_result.VegB_Text_Infilling.core.layers.multihead_attention", "home.repos.pwc.inspect_result.VegB_Text_Infilling.agents.agent_base.AgentBase.variable_scope", "home.repos.pwc.inspect_result.VegB_Text_Infilling.core.layers.layer_normalize", "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.shapes.shape_list", "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.transformer_utils.PadRemover.remove", "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.transformer_utils.PadRemover.restore", "home.repos.pwc.inspect_result.VegB_Text_Infilling.core.layers.layer_normalize", "home.repos.pwc.inspect_result.VegB_Text_Infilling.texar.context.global_mode_train", "home.repos.pwc.inspect_result.VegB_Text_Infilling.texar.context.global_mode_train"], ["", "def", "_build", "(", "self", ",", "inputs", ",", "mode", "=", "None", ")", ":", "\n", "        ", "\"\"\"Encodes the inputs with transformer encoder.\n\n        Args:\n            inputs: A 2D Tensor of shape `[batch_size, max_time]`\n            mode(optional): A tensor taking value in\n                :tf_main:`tf.estimator.ModeKeys <estimator/ModeKeys>`\n        \"\"\"", "\n", "encoder_padding", "=", "tf", ".", "to_float", "(", "tf", ".", "equal", "(", "inputs", ",", "0", ")", ")", "\n", "#pylint:disable=too-many-locals", "\n", "self", ".", "enc", "=", "tf", ".", "nn", ".", "embedding_lookup", "(", "self", ".", "_embedding", ",", "inputs", ")", "\n", "_", ",", "_", ",", "channels", "=", "shape_list", "(", "self", ".", "enc", ")", "\n", "if", "self", ".", "_hparams", ".", "multiply_embedding_mode", "==", "'sqrt_depth'", ":", "\n", "            ", "self", ".", "enc", "=", "self", ".", "enc", "*", "channels", "**", "0.5", "\n", "\n", "", "ignore_padding", "=", "attentions", ".", "attention_bias_ignore_padding", "(", "\n", "encoder_padding", ")", "\n", "encoder_self_attention_bias", "=", "ignore_padding", "\n", "encoder_decoder_attention_bias", "=", "ignore_padding", "\n", "\n", "if", "self", ".", "target_symbol_embedding", ":", "\n", "            ", "emb_target_space", "=", "tf", ".", "reshape", "(", "\n", "self", ".", "target_symbol_embedding", ",", "[", "1", ",", "1", ",", "-", "1", "]", ")", "\n", "self", ".", "enc", "=", "self", ".", "enc", "+", "emb_target_space", "\n", "", "lengths", "=", "shape_list", "(", "self", ".", "enc", ")", "[", "1", "]", "\n", "channels", "=", "shape_list", "(", "self", ".", "enc", ")", "[", "2", "]", "\n", "pos_embeds", "=", "self", ".", "position_embedder", "(", "lengths", ",", "channels", ")", "\n", "input_embedding", "=", "self", ".", "enc", "+", "pos_embeds", "\n", "\n", "x", "=", "tf", ".", "layers", ".", "dropout", "(", "input_embedding", ",", "\n", "rate", "=", "self", ".", "_hparams", ".", "embedding_dropout", ",", "\n", "training", "=", "context", ".", "global_mode_train", "(", ")", ")", "\n", "pad_remover", "=", "utils", ".", "transformer_utils", ".", "PadRemover", "(", "encoder_padding", ")", "\n", "for", "i", "in", "range", "(", "self", ".", "_hparams", ".", "num_blocks", ")", ":", "\n", "            ", "with", "tf", ".", "variable_scope", "(", "\"layer_{}\"", ".", "format", "(", "i", ")", ")", ":", "\n", "                ", "with", "tf", ".", "variable_scope", "(", "'self_attention'", ")", ":", "\n", "                    ", "selfatt_output", "=", "attentions", ".", "multihead_attention", "(", "\n", "queries", "=", "layers", ".", "layer_normalize", "(", "x", ")", ",", "\n", "memory", "=", "None", ",", "\n", "memory_attention_bias", "=", "encoder_self_attention_bias", ",", "\n", "num_heads", "=", "self", ".", "_hparams", ".", "num_heads", ",", "\n", "dropout_rate", "=", "self", ".", "_hparams", ".", "attention_dropout", ",", "\n", "num_units", "=", "self", ".", "_hparams", ".", "num_units", ",", "\n", "scope", "=", "'multihead_attention'", "\n", ")", "\n", "x", "=", "x", "+", "tf", ".", "layers", ".", "dropout", "(", "\n", "selfatt_output", ",", "\n", "rate", "=", "self", ".", "_hparams", ".", "residual_dropout", ",", "\n", "training", "=", "context", ".", "global_mode_train", "(", ")", "\n", ")", "\n", "", "poswise_network", "=", "FeedForwardNetwork", "(", "\n", "hparams", "=", "self", ".", "_hparams", "[", "'poswise_feedforward'", "]", ")", "\n", "with", "tf", ".", "variable_scope", "(", "poswise_network", ".", "variable_scope", ")", ":", "\n", "                    ", "y", "=", "layers", ".", "layer_normalize", "(", "x", ")", "\n", "original_shape", "=", "shape_list", "(", "y", ")", "\n", "y", "=", "tf", ".", "reshape", "(", "y", ",", "[", "-", "1", ",", "self", ".", "_hparams", ".", "num_units", "]", ")", "\n", "y", "=", "tf", ".", "expand_dims", "(", "pad_remover", ".", "remove", "(", "y", ")", ",", "axis", "=", "0", ")", "\n", "#[1, batch_size*seq_length, hidden_dim]", "\n", "sub_output", "=", "tf", ".", "layers", ".", "dropout", "(", "\n", "poswise_network", "(", "y", ")", ",", "\n", "rate", "=", "self", ".", "_hparams", ".", "residual_dropout", ",", "\n", "training", "=", "context", ".", "global_mode_train", "(", ")", "\n", ")", "\n", "sub_output", "=", "tf", ".", "reshape", "(", "pad_remover", ".", "restore", "(", "tf", ".", "squeeze", "(", "sub_output", ",", "axis", "=", "0", ")", ")", ",", "original_shape", ")", "\n", "x", "=", "x", "+", "sub_output", "\n", "\n", "", "", "", "self", ".", "stack_output", "=", "x", "\n", "encoder_output", "=", "layers", ".", "layer_normalize", "(", "x", ")", "\n", "\n", "if", "not", "self", ".", "_built", ":", "\n", "            ", "self", ".", "_add_internal_trainable_variables", "(", ")", "\n", "self", ".", "_built", "=", "True", "\n", "\n", "", "return", "encoder_output", ",", "encoder_decoder_attention_bias", "\n", "", "", ""]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.encoders.encoder_base.EncoderBase.__init__": [[20, 22], ["texar.module_base.ModuleBase.__init__"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.text_infilling.self_attn_hyperparams.Hyperparams.__init__"], ["def", "__init__", "(", "self", ",", "hparams", "=", "None", ")", ":", "\n", "        ", "ModuleBase", ".", "__init__", "(", "self", ",", "hparams", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.encoders.encoder_base.EncoderBase.default_hparams": [[23, 29], ["None"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "default_hparams", "(", ")", ":", "\n", "        ", "\"\"\"Returns a dictionary of hyperparameters with default values.\n        \"\"\"", "\n", "return", "{", "\n", "\"name\"", ":", "\"encoder\"", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.encoders.encoder_base.EncoderBase._build": [[31, 43], ["None"], "methods", ["None"], ["", "def", "_build", "(", "self", ",", "inputs", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"Encodes the inputs.\n\n        Args:\n          inputs: Inputs to the encoder.\n          *args: Other arguments.\n          **kwargs: Keyword arguments.\n\n        Returns:\n          Encoding results.\n        \"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.encoders.hierarchical_encoders_test.HierarchicalRNNEncoderTest.test_trainable_variables": [[18, 32], ["texar.modules.encoders.hierarchical_encoders.HierarchicalRNNEncoder", "tensorflow.random_uniform", "texar.modules.encoders.hierarchical_encoders.HierarchicalRNNEncoder.", "hierarchical_encoders_test.HierarchicalRNNEncoderTest.assertEqual", "len", "len", "len"], "methods", ["None"], ["    ", "def", "test_trainable_variables", "(", "self", ")", ":", "\n", "        ", "encoder", "=", "HierarchicalRNNEncoder", "(", ")", "\n", "\n", "inputs", "=", "tf", ".", "random_uniform", "(", "\n", "[", "3", ",", "2", ",", "3", ",", "4", "]", ",", "\n", "maxval", "=", "1", ",", "\n", "minval", "=", "-", "1", ",", "\n", "dtype", "=", "tf", ".", "float32", ")", "\n", "_", ",", "_", "=", "encoder", "(", "inputs", ")", "\n", "\n", "self", ".", "assertEqual", "(", "\n", "len", "(", "encoder", ".", "trainable_variables", ")", ",", "\n", "len", "(", "encoder", ".", "encoder_major", ".", "trainable_variables", ")", "+", "len", "(", "encoder", ".", "encoder_minor", ".", "trainable_variables", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.encoders.hierarchical_encoders_test.HierarchicalRNNEncoderTest.test_encode": [[33, 53], ["texar.modules.encoders.hierarchical_encoders.HierarchicalRNNEncoder", "tensorflow.random_uniform", "texar.modules.encoders.hierarchical_encoders.HierarchicalRNNEncoder.", "hierarchical_encoders_test.HierarchicalRNNEncoderTest.test_session", "sess.run", "sess.run", "hierarchical_encoders_test.HierarchicalRNNEncoderTest.assertEqual", "tensorflow.global_variables_initializer"], "methods", ["None"], ["", "def", "test_encode", "(", "self", ")", ":", "\n", "        ", "encoder", "=", "HierarchicalRNNEncoder", "(", ")", "\n", "\n", "batch_size", "=", "16", "\n", "max_major_time", "=", "8", "\n", "max_minor_time", "=", "6", "\n", "dim", "=", "10", "\n", "inputs", "=", "tf", ".", "random_uniform", "(", "\n", "[", "batch_size", ",", "max_major_time", ",", "max_minor_time", ",", "dim", "]", ",", "\n", "maxval", "=", "1", ",", "\n", "minval", "=", "-", "1", ",", "\n", "dtype", "=", "tf", ".", "float32", ")", "\n", "outputs", ",", "state", "=", "encoder", "(", "inputs", ")", "\n", "\n", "cell_dim", "=", "encoder", ".", "encoder_major", ".", "hparams", ".", "rnn_cell", ".", "kwargs", ".", "num_units", "\n", "\n", "with", "self", ".", "test_session", "(", ")", "as", "sess", ":", "\n", "            ", "sess", ".", "run", "(", "tf", ".", "global_variables_initializer", "(", ")", ")", "\n", "outputs_", ",", "state_", "=", "sess", ".", "run", "(", "[", "outputs", ",", "state", "]", ")", "\n", "self", ".", "assertEqual", "(", "state_", "[", "0", "]", ".", "shape", ",", "(", "batch_size", ",", "cell_dim", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.encoders.hierarchical_encoders_test.HierarchicalRNNEncoderTest.test_order": [[54, 71], ["texar.modules.encoders.hierarchical_encoders.HierarchicalRNNEncoder", "tensorflow.random_uniform", "texar.modules.encoders.hierarchical_encoders.HierarchicalRNNEncoder.", "texar.modules.encoders.hierarchical_encoders.HierarchicalRNNEncoder.", "texar.modules.encoders.hierarchical_encoders.HierarchicalRNNEncoder.", "texar.modules.encoders.hierarchical_encoders.HierarchicalRNNEncoder."], "methods", ["None"], ["", "", "def", "test_order", "(", "self", ")", ":", "\n", "        ", "encoder", "=", "HierarchicalRNNEncoder", "(", ")", "\n", "\n", "batch_size", "=", "16", "\n", "max_major_time", "=", "8", "\n", "max_minor_time", "=", "6", "\n", "dim", "=", "10", "\n", "inputs", "=", "tf", ".", "random_uniform", "(", "\n", "[", "batch_size", ",", "max_major_time", ",", "max_minor_time", ",", "dim", "]", ",", "\n", "maxval", "=", "1", ",", "\n", "minval", "=", "-", "1", ",", "\n", "dtype", "=", "tf", ".", "float32", ")", "\n", "\n", "outputs", ",", "state", "=", "encoder", "(", "inputs", ",", "order", "=", "'btu'", ",", "time_major", "=", "False", ")", "\n", "outputs", ",", "state", "=", "encoder", "(", "inputs", ",", "order", "=", "'utb'", ",", "time_major", "=", "True", ")", "\n", "outputs", ",", "state", "=", "encoder", "(", "inputs", ",", "order", "=", "'tbu'", ",", "time_major_major", "=", "True", ")", "\n", "outputs", ",", "state", "=", "encoder", "(", "inputs", ",", "order", "=", "'ubt'", ",", "time_major_minor", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.encoders.hierarchical_encoders_test.HierarchicalRNNEncoderTest.test_depack": [[72, 101], ["texar.modules.encoders.hierarchical_encoders.HierarchicalRNNEncoder", "tensorflow.random_uniform", "texar.modules.encoders.hierarchical_encoders.HierarchicalRNNEncoder.", "hierarchical_encoders_test.HierarchicalRNNEncoderTest.assertEqual"], "methods", ["None"], ["", "def", "test_depack", "(", "self", ")", ":", "\n", "        ", "hparams", "=", "{", "\n", "\"encoder_major_type\"", ":", "\"BidirectionalRNNEncoder\"", ",", "\n", "\"encoder_major_hparams\"", ":", "{", "\n", "\"rnn_cell_fw\"", ":", "{", "\n", "\"type\"", ":", "\"LSTMCell\"", ",", "\n", "\"kwargs\"", ":", "{", "\n", "\"num_units\"", ":", "100", "\n", "}", "\n", "}", "\n", "}", "\n", "}", "\n", "encoder", "=", "HierarchicalRNNEncoder", "(", "hparams", "=", "hparams", ")", "\n", "\n", "batch_size", "=", "16", "\n", "max_major_time", "=", "8", "\n", "max_minor_time", "=", "6", "\n", "dim", "=", "10", "\n", "inputs", "=", "tf", ".", "random_uniform", "(", "\n", "[", "batch_size", ",", "max_major_time", ",", "max_minor_time", ",", "dim", "]", ",", "\n", "maxval", "=", "1", ",", "\n", "minval", "=", "-", "1", ",", "\n", "dtype", "=", "tf", ".", "float32", ")", "\n", "\n", "outputs", ",", "state", "=", "encoder", "(", "inputs", ")", "\n", "\n", "self", ".", "assertEqual", "(", "\n", "encoder", ".", "states_minor_before_medium", ".", "h", ".", "shape", "[", "1", "]", ",", "\n", "encoder", ".", "states_minor_after_medium", ".", "shape", "[", "1", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.embedders.position_embedders.PositionEmbedder.__init__": [[50, 69], ["texar.modules.embedders.embedder_base.EmbedderBase.__init__", "position_embedders.PositionEmbedder._init_parameterized_embedding", "ValueError", "ValueError"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.text_infilling.self_attn_hyperparams.Hyperparams.__init__", "home.repos.pwc.inspect_result.VegB_Text_Infilling.embedders.embedder_base.EmbedderBase._init_parameterized_embedding"], ["def", "__init__", "(", "self", ",", "init_value", "=", "None", ",", "position_size", "=", "None", ",", "hparams", "=", "None", ")", ":", "\n", "        ", "EmbedderBase", ".", "__init__", "(", "self", ",", "hparams", "=", "hparams", ")", "\n", "\n", "if", "init_value", "is", "None", "and", "position_size", "is", "None", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "\"Either `init_value` or `position_size` is required.\"", ")", "\n", "\n", "", "self", ".", "_init_parameterized_embedding", "(", "init_value", ",", "position_size", ",", "\n", "self", ".", "_hparams", ")", "\n", "\n", "self", ".", "_position_size", "=", "position_size", "\n", "if", "position_size", "is", "None", ":", "\n", "            ", "self", ".", "_position_size", "=", "self", ".", "_num_embeds", "\n", "", "if", "self", ".", "_position_size", "!=", "self", ".", "_num_embeds", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "'position_size must equal to init_value.shape[0].'", "\n", "'Got %d and %d'", "%", "(", "self", ".", "_position_size", ",", "self", ".", "_num_embeds", ")", ")", "\n", "\n", "", "self", ".", "_built", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.embedders.position_embedders.PositionEmbedder.default_hparams": [[70, 107], ["texar.modules.embedders.embedder_utils.default_embedding_hparams"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.embedders.embedder_utils.default_embedding_hparams"], ["", "@", "staticmethod", "\n", "def", "default_hparams", "(", ")", ":", "\n", "        ", "\"\"\"Returns a dictionary of hyperparameters with default values.\n\n        Returns:\n            A dictionary with the following structure and values.\n\n            .. code-block:: python\n\n                {\n                    \"name\": \"position_embedder\",\n                    \"dim\": 100,\n                    \"initializer\": {\n                        \"type\": \"random_uniform_initializer\",\n                        \"kwargs\": {\n                            \"minval\": -0.1,\n                            \"maxval\": 0.1,\n                            \"seed\": None\n                        }\n                    },\n                    \"regularizer\": {\n                        \"type\": \"L1L2\",\n                        \"kwargs\": {\n                            \"l1\": 0.,\n                            \"l2\": 0.\n                        }\n                    },\n                    \"dropout_rate\": 0,\n                    \"trainable\": True,\n                }\n\n            See :func:`~texar.modules.default_embedding_hparams` for more\n            details.\n        \"\"\"", "\n", "hparams", "=", "embedder_utils", ".", "default_embedding_hparams", "(", ")", "\n", "hparams", "[", "\"name\"", "]", "=", "\"position_embedder\"", "\n", "return", "hparams", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.embedders.position_embedders.PositionEmbedder._build": [[108, 190], ["len", "texar.utils.mode.is_train_mode", "tensorflow.nn.embedding_lookup", "tensorflow.reduce_max", "tensorflow.range", "tensorflow.expand_dims", "position_embedders.PositionEmbedder._get_dropout_layer", "position_embedders.PositionEmbedder._get_dropout_layer", "texar.utils.shapes.mask_sequences", "ValueError", "tensorflow.ones_like", "tensorflow.expand_dims", "position_embedders.PositionEmbedder.apply", "position_embedders.PositionEmbedder.apply", "len"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.mode.is_train_mode", "home.repos.pwc.inspect_result.VegB_Text_Infilling.embedders.embedder_base.EmbedderBase._get_dropout_layer", "home.repos.pwc.inspect_result.VegB_Text_Infilling.embedders.embedder_base.EmbedderBase._get_dropout_layer", "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.shapes.mask_sequences"], ["", "def", "_build", "(", "self", ",", "positions", "=", "None", ",", "sequence_length", "=", "None", ",", "mode", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"Embeds with look-up.\n\n        Either :attr:`position` or :attr:`sequence_length` is required:\n\n            - If both are given, :attr:`sequence_length` is used to mask out \\\n            embeddings of those time steps beyond the respective sequence \\\n            lengths.\n            - If only :attr:`sequence_length` is given, then positions \\\n            from 0 to sequence length - 1 are embedded.\n\n        Args:\n            positions (optional): An integer tensor containing the position\n                ids to embed.\n            sequence_length (optional): An integer tensor of shape\n                `[batch_size]`. Time steps beyond\n                the respective sequence lengths will have zero-valued\n                embeddings.\n            mode (optional): A tensor taking value in\n                :tf_main:`tf.estimator.ModeKeys <estimator/ModeKeys>`, including\n                `TRAIN`, `EVAL`, and `PREDICT`. If `None`, dropout will be\n                controlled by :func:`texar.context.global_mode`.\n            kwargs: Additional keyword arguments for\n                :tf_main:`tf.nn.embedding_lookup <nn/embedding_lookup>` besides\n                :attr:`params` and :attr:`ids`.\n\n        Returns:\n            A `Tensor` of shape `shape(inputs) + embedding dimension`.\n        \"\"\"", "\n", "# Gets embedder inputs", "\n", "inputs", "=", "positions", "\n", "if", "positions", "is", "None", ":", "\n", "            ", "if", "sequence_length", "is", "None", ":", "\n", "                ", "raise", "ValueError", "(", "\n", "'Either `positions` or `sequence_length` is required.'", ")", "\n", "", "max_length", "=", "tf", ".", "reduce_max", "(", "sequence_length", ")", "\n", "single_inputs", "=", "tf", ".", "range", "(", "start", "=", "0", ",", "limit", "=", "max_length", ",", "dtype", "=", "tf", ".", "int32", ")", "\n", "# Expands `single_inputs` to have shape [batch_size, max_length]", "\n", "expander", "=", "tf", ".", "expand_dims", "(", "tf", ".", "ones_like", "(", "sequence_length", ")", ",", "-", "1", ")", "\n", "inputs", "=", "expander", "*", "tf", ".", "expand_dims", "(", "single_inputs", ",", "0", ")", "\n", "", "ids_rank", "=", "len", "(", "inputs", ".", "shape", ".", "dims", ")", "\n", "\n", "embedding", "=", "self", ".", "_embedding", "\n", "\n", "is_training", "=", "is_train_mode", "(", "mode", ")", "\n", "\n", "# Gets dropout strategy", "\n", "st", "=", "self", ".", "_hparams", ".", "dropout_strategy", "\n", "if", "positions", "is", "None", "and", "st", "==", "'item'", ":", "\n", "# If `inputs` is based on `sequence_length`, then dropout", "\n", "# strategies 'item' and 'item_type' have the same effect, we", "\n", "# use 'item_type' to avoid unknown noise_shape in the 'item'", "\n", "# strategy", "\n", "            ", "st", "=", "'item_type'", "\n", "\n", "# Dropouts as 'item_type' before embedding", "\n", "", "if", "st", "==", "'item_type'", ":", "\n", "            ", "dropout_layer", "=", "self", ".", "_get_dropout_layer", "(", "\n", "self", ".", "_hparams", ",", "dropout_strategy", "=", "st", ")", "\n", "if", "dropout_layer", ":", "\n", "                ", "embedding", "=", "dropout_layer", ".", "apply", "(", "inputs", "=", "embedding", ",", "\n", "training", "=", "is_training", ")", "\n", "\n", "# Embeds", "\n", "", "", "outputs", "=", "tf", ".", "nn", ".", "embedding_lookup", "(", "embedding", ",", "inputs", ",", "**", "kwargs", ")", "\n", "\n", "# Dropouts as 'item' or 'elements' after embedding", "\n", "if", "st", "!=", "'item_type'", ":", "\n", "            ", "dropout_layer", "=", "self", ".", "_get_dropout_layer", "(", "\n", "self", ".", "_hparams", ",", "ids_rank", "=", "ids_rank", ",", "dropout_input", "=", "outputs", ",", "\n", "dropout_strategy", "=", "st", ")", "\n", "if", "dropout_layer", ":", "\n", "                ", "outputs", "=", "dropout_layer", ".", "apply", "(", "inputs", "=", "outputs", ",", "\n", "training", "=", "is_training", ")", "\n", "\n", "# Optionally masks", "\n", "", "", "if", "sequence_length", "is", "not", "None", ":", "\n", "            ", "outputs", "=", "mask_sequences", "(", "\n", "outputs", ",", "sequence_length", ",", "\n", "tensor_rank", "=", "len", "(", "inputs", ".", "shape", ".", "dims", ")", "+", "self", ".", "_dim_rank", ")", "\n", "\n", "", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.embedders.position_embedders.PositionEmbedder.embedding": [[191, 196], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "embedding", "(", "self", ")", ":", "\n", "        ", "\"\"\"The embedding tensor.\n        \"\"\"", "\n", "return", "self", ".", "_embedding", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.embedders.position_embedders.PositionEmbedder.dim": [[197, 202], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "dim", "(", "self", ")", ":", "\n", "        ", "\"\"\"The embedding dimension.\n        \"\"\"", "\n", "return", "self", ".", "_dim", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.embedders.position_embedders.PositionEmbedder.position_size": [[203, 208], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "position_size", "(", "self", ")", ":", "\n", "        ", "\"\"\"The position size, i.e., maximum number of positions.\n        \"\"\"", "\n", "return", "self", ".", "_position_size", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.embedders.position_embedders.SinusoidsPositionEmbedder.__init__": [[227, 229], ["texar.modules.embedders.embedder_base.EmbedderBase.__init__"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.text_infilling.self_attn_hyperparams.Hyperparams.__init__"], ["def", "__init__", "(", "self", ",", "hparams", "=", "None", ")", ":", "\n", "        ", "EmbedderBase", ".", "__init__", "(", "self", ",", "hparams", "=", "hparams", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.embedders.position_embedders.SinusoidsPositionEmbedder.default_hparams": [[230, 243], ["None"], "methods", ["None"], ["", "def", "default_hparams", "(", "self", ")", ":", "\n", "        ", "\"\"\"returns a dictionary of hyperparameters with default values\n        We use a geometric sequence of timescales starting with\n        min_timescale and ending with max_timescale. The number of different\n        timescales is equal to channels/2.\n        \"\"\"", "\n", "hparams", "=", "{", "\n", "'name'", ":", "'sinusoid_posisiton_embedder'", ",", "\n", "'min_timescale'", ":", "1.0", ",", "\n", "'max_timescale'", ":", "1.0e4", ",", "\n", "'trainable'", ":", "False", ",", "\n", "}", "\n", "return", "hparams", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.embedders.position_embedders.SinusoidsPositionEmbedder._build": [[244, 260], ["tensorflow.to_float", "tensorflow.concat", "tensorflow.pad", "tensorflow.reshape", "tensorflow.range", "math.log", "tensorflow.exp", "tensorflow.expand_dims", "tensorflow.expand_dims", "tensorflow.to_float", "tensorflow.sin", "tensorflow.cos", "float", "float", "tensorflow.to_float", "tensorflow.mod", "tensorflow.range"], "methods", ["None"], ["", "def", "_build", "(", "self", ",", "length", ",", "channels", ")", ":", "\n", "        ", "position", "=", "tf", ".", "to_float", "(", "tf", ".", "range", "(", "length", ")", ")", "\n", "num_timescales", "=", "channels", "//", "2", "\n", "min_timescale", "=", "self", ".", "_hparams", ".", "min_timescale", "\n", "max_timescale", "=", "self", ".", "_hparams", ".", "max_timescale", "\n", "log_timescale_increment", "=", "(", "\n", "math", ".", "log", "(", "float", "(", "max_timescale", ")", "/", "float", "(", "min_timescale", ")", ")", "/", "\n", "(", "tf", ".", "to_float", "(", "num_timescales", ")", "-", "1", ")", ")", "\n", "inv_timescales", "=", "min_timescale", "*", "tf", ".", "exp", "(", "\n", "tf", ".", "to_float", "(", "tf", ".", "range", "(", "num_timescales", ")", ")", "*", "-", "log_timescale_increment", ")", "\n", "scaled_time", "=", "tf", ".", "expand_dims", "(", "position", ",", "1", ")", "*", "tf", ".", "expand_dims", "(", "inv_timescales", ",", "0", ")", "\n", "signal", "=", "tf", ".", "concat", "(", "[", "tf", ".", "sin", "(", "scaled_time", ")", ",", "tf", ".", "cos", "(", "scaled_time", ")", "]", ",", "axis", "=", "1", ")", "\n", "signal", "=", "tf", ".", "pad", "(", "signal", ",", "[", "[", "0", ",", "0", "]", ",", "[", "0", ",", "tf", ".", "mod", "(", "channels", ",", "2", ")", "]", "]", ")", "\n", "signal", "=", "tf", ".", "reshape", "(", "signal", ",", "[", "1", ",", "length", ",", "channels", "]", ")", "\n", "return", "signal", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.embedders.position_embedders.SinusoidsSegmentalPositionEmbedder.__init__": [[263, 265], ["texar.modules.embedders.embedder_base.EmbedderBase.__init__"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.text_infilling.self_attn_hyperparams.Hyperparams.__init__"], ["    ", "def", "__init__", "(", "self", ",", "hparams", "=", "None", ")", ":", "\n", "        ", "EmbedderBase", ".", "__init__", "(", "self", ",", "hparams", "=", "hparams", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.embedders.position_embedders.SinusoidsSegmentalPositionEmbedder.default_hparams": [[266, 280], ["None"], "methods", ["None"], ["", "def", "default_hparams", "(", "self", ")", ":", "\n", "        ", "\"\"\"returns a dictionary of hyperparameters with default values\n        We use a geometric sequence of timescales starting with\n        min_timescale and ending with max_timescale. The number of different\n        timescales is equal to channels/2.\n        \"\"\"", "\n", "hparams", "=", "{", "\n", "'name'", ":", "'sinusoid_segmental_posisiton_embedder'", ",", "\n", "'min_timescale'", ":", "1.0", ",", "\n", "'max_timescale'", ":", "1.0e4", ",", "\n", "'trainable'", ":", "False", ",", "\n", "'base'", ":", "256", ",", "\n", "}", "\n", "return", "hparams", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.embedders.position_embedders.SinusoidsSegmentalPositionEmbedder._build": [[281, 304], ["tensorflow.to_float", "tensorflow.concat", "tensorflow.reshape", "tensorflow.add", "math.log", "tensorflow.exp", "tensorflow.expand_dims", "tensorflow.multiply", "tensorflow.to_float", "tensorflow.sin", "tensorflow.cos", "tensorflow.cast", "float", "float", "tensorflow.to_float", "tensorflow.range"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.core.replay_memories.DequeReplayMemory.add"], ["", "def", "_build", "(", "self", ",", "length", ",", "channels", ",", "segment_ids", ",", "offsets", ")", ":", "\n", "        ", "\"\"\"\n        :param length: an int\n        :param channels: an int\n        :param segment_id: [batch_size, length]\n        :param segment_offset: [batch_size, length]\n        :return: [batch_size, length, channels]\n        \"\"\"", "\n", "# TODO(wanrong): check if segment_ids is of shape [batch_size, length]", "\n", "position", "=", "tf", ".", "to_float", "(", "tf", ".", "add", "(", "tf", ".", "multiply", "(", "tf", ".", "cast", "(", "256", ",", "tf", ".", "int64", ")", ",", "segment_ids", ")", ",", "\n", "offsets", ")", ")", "\n", "num_timescales", "=", "channels", "//", "2", "\n", "min_timescale", "=", "1.0", "\n", "max_timescale", "=", "1.0e4", "\n", "log_timescale_increment", "=", "(", "\n", "math", ".", "log", "(", "float", "(", "max_timescale", ")", "/", "float", "(", "min_timescale", ")", ")", "/", "\n", "(", "tf", ".", "to_float", "(", "num_timescales", ")", "-", "1", ")", ")", "\n", "inv_timescales", "=", "min_timescale", "*", "tf", ".", "exp", "(", "\n", "tf", ".", "to_float", "(", "tf", ".", "range", "(", "num_timescales", ")", ")", "*", "-", "log_timescale_increment", ")", "\n", "scaled_time", "=", "tf", ".", "expand_dims", "(", "position", ",", "2", ")", "*", "inv_timescales", "\n", "signal", "=", "tf", ".", "concat", "(", "[", "tf", ".", "sin", "(", "scaled_time", ")", ",", "tf", ".", "cos", "(", "scaled_time", ")", "]", ",", "axis", "=", "2", ")", "\n", "signal", "=", "tf", ".", "reshape", "(", "signal", ",", "shape", "=", "[", "-", "1", ",", "length", ",", "channels", "]", ")", "\n", "return", "signal", "", "", "", ""]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.embedders.embedders_test.EmbedderTest._test_word_embedder": [[25, 67], ["texar.modules.embedders.embedders.WordEmbedder", "tensorflow.ones", "texar.modules.embedders.embedders.WordEmbedder.", "tensorflow.ones", "texar.modules.embedders.embedders.WordEmbedder.", "embedders_test.EmbedderTest.assertEqual", "embedders_test.EmbedderTest.assertEqual", "embedders_test.EmbedderTest.assertEqual", "embedders_test.EmbedderTest.assertEqual", "embedders_test.EmbedderTest.assertEqual", "tensorflow.placeholder", "texar.modules.embedders.embedders.WordEmbedder.", "embedders_test.EmbedderTest.assertEqual", "tensorflow.placeholder", "texar.modules.embedders.embedders.WordEmbedder.", "embedders_test.EmbedderTest.assertEqual", "isinstance", "isinstance", "len", "embedders_test.EmbedderTest.test_session", "sess.run", "sess.run", "embedders_test.EmbedderTest.assertEqual", "embedders_test.EmbedderTest.assertEqual", "len", "len", "tensorflow.global_variables_initializer", "texar.modules.embedders.embedders.WordEmbedder.get_shape", "len", "texar.modules.embedders.embedders.WordEmbedder.get_shape", "len", "tuple", "tuple", "texar.context.global_mode"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.texar.context.global_mode"], ["def", "_test_word_embedder", "(", "self", ",", "hparams", ")", ":", "\n", "        ", "\"\"\"Tests :class:`texar.modules.WordEmbedder`.\n        \"\"\"", "\n", "embedder", "=", "WordEmbedder", "(", "\n", "vocab_size", "=", "100", ",", "hparams", "=", "hparams", ")", "\n", "\n", "inputs", "=", "tf", ".", "ones", "(", "[", "64", ",", "16", "]", ",", "dtype", "=", "tf", ".", "int32", ")", "\n", "outputs", "=", "embedder", "(", "inputs", ")", "\n", "\n", "inputs_soft", "=", "tf", ".", "ones", "(", "[", "64", ",", "16", ",", "embedder", ".", "vocab_size", "]", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "outputs_soft", "=", "embedder", "(", "soft_ids", "=", "inputs_soft", ")", "\n", "\n", "emb_dim", "=", "embedder", ".", "dim", "\n", "if", "not", "isinstance", "(", "emb_dim", ",", "(", "list", ",", "tuple", ")", ")", ":", "\n", "            ", "emb_dim", "=", "[", "emb_dim", "]", "\n", "\n", "", "hparams_dim", "=", "hparams", "[", "\"dim\"", "]", "\n", "if", "not", "isinstance", "(", "hparams", "[", "\"dim\"", "]", ",", "(", "list", ",", "tuple", ")", ")", ":", "\n", "            ", "hparams_dim", "=", "[", "hparams", "[", "\"dim\"", "]", "]", "\n", "\n", "", "self", ".", "assertEqual", "(", "outputs", ".", "shape", ",", "[", "64", ",", "16", "]", "+", "emb_dim", ")", "\n", "self", ".", "assertEqual", "(", "outputs_soft", ".", "shape", ",", "[", "64", ",", "16", "]", "+", "emb_dim", ")", "\n", "self", ".", "assertEqual", "(", "emb_dim", ",", "hparams_dim", ")", "\n", "self", ".", "assertEqual", "(", "embedder", ".", "vocab_size", ",", "100", ")", "\n", "self", ".", "assertEqual", "(", "len", "(", "embedder", ".", "trainable_variables", ")", ",", "1", ")", "\n", "\n", "with", "self", ".", "test_session", "(", ")", "as", "sess", ":", "\n", "            ", "sess", ".", "run", "(", "tf", ".", "global_variables_initializer", "(", ")", ")", "\n", "outputs_", ",", "outputs_soft_", "=", "sess", ".", "run", "(", "\n", "[", "outputs", ",", "outputs_soft", "]", ",", "\n", "feed_dict", "=", "{", "global_mode", "(", ")", ":", "tf", ".", "estimator", ".", "ModeKeys", ".", "TRAIN", "}", ")", "\n", "self", ".", "assertEqual", "(", "outputs_", ".", "shape", ",", "(", "64", ",", "16", ")", "+", "tuple", "(", "emb_dim", ")", ")", "\n", "self", ".", "assertEqual", "(", "outputs_soft_", ".", "shape", ",", "(", "64", ",", "16", ")", "+", "tuple", "(", "emb_dim", ")", ")", "\n", "\n", "# Tests unknown input shapes", "\n", "", "inputs", "=", "tf", ".", "placeholder", "(", "dtype", "=", "tf", ".", "int64", ",", "shape", "=", "[", "None", ",", "None", "]", ")", "\n", "outputs", "=", "embedder", "(", "inputs", ")", "\n", "self", ".", "assertEqual", "(", "len", "(", "outputs", ".", "get_shape", "(", ")", ")", ",", "2", "+", "len", "(", "hparams_dim", ")", ")", "\n", "\n", "inputs_soft", "=", "tf", ".", "placeholder", "(", "dtype", "=", "tf", ".", "int64", ",", "shape", "=", "[", "None", ",", "None", ",", "None", "]", ")", "\n", "outputs_soft", "=", "embedder", "(", "soft_ids", "=", "inputs_soft", ")", "\n", "self", ".", "assertEqual", "(", "len", "(", "outputs_soft", ".", "get_shape", "(", ")", ")", ",", "2", "+", "len", "(", "hparams_dim", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.embedders.embedders_test.EmbedderTest._test_position_embedder": [[69, 100], ["texar.modules.embedders.position_embedders.PositionEmbedder", "tensorflow.ones", "texar.modules.embedders.position_embedders.PositionEmbedder.", "embedders_test.EmbedderTest.assertEqual", "embedders_test.EmbedderTest.assertEqual", "embedders_test.EmbedderTest.assertEqual", "embedders_test.EmbedderTest.assertEqual", "tensorflow.random_uniform", "texar.modules.embedders.position_embedders.PositionEmbedder.", "isinstance", "isinstance", "len", "embedders_test.EmbedderTest.test_session", "sess.run", "sess.run", "embedders_test.EmbedderTest.assertEqual", "tensorflow.global_variables_initializer", "tensorflow.reduce_max", "tuple", "texar.context.global_mode"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.texar.context.global_mode"], ["", "def", "_test_position_embedder", "(", "self", ",", "hparams", ")", ":", "\n", "        ", "\"\"\"Tests :class:`texar.modules.PositionEmbedder`.\n        \"\"\"", "\n", "pos_size", "=", "100", "\n", "embedder", "=", "PositionEmbedder", "(", "\n", "position_size", "=", "pos_size", ",", "hparams", "=", "hparams", ")", "\n", "inputs", "=", "tf", ".", "ones", "(", "[", "64", ",", "16", "]", ",", "dtype", "=", "tf", ".", "int32", ")", "\n", "outputs", "=", "embedder", "(", "inputs", ")", "\n", "\n", "emb_dim", "=", "embedder", ".", "dim", "\n", "if", "not", "isinstance", "(", "emb_dim", ",", "(", "list", ",", "tuple", ")", ")", ":", "\n", "            ", "emb_dim", "=", "[", "emb_dim", "]", "\n", "\n", "", "hparams_dim", "=", "hparams", "[", "\"dim\"", "]", "\n", "if", "not", "isinstance", "(", "hparams", "[", "\"dim\"", "]", ",", "(", "list", ",", "tuple", ")", ")", ":", "\n", "            ", "hparams_dim", "=", "[", "hparams", "[", "\"dim\"", "]", "]", "\n", "\n", "", "self", ".", "assertEqual", "(", "outputs", ".", "shape", ",", "[", "64", ",", "16", "]", "+", "emb_dim", ")", "\n", "self", ".", "assertEqual", "(", "emb_dim", ",", "hparams_dim", ")", "\n", "self", ".", "assertEqual", "(", "embedder", ".", "position_size", ",", "100", ")", "\n", "self", ".", "assertEqual", "(", "len", "(", "embedder", ".", "trainable_variables", ")", ",", "1", ")", "\n", "\n", "seq_length", "=", "tf", ".", "random_uniform", "(", "[", "64", "]", ",", "maxval", "=", "pos_size", ",", "dtype", "=", "tf", ".", "int32", ")", "\n", "outputs", "=", "embedder", "(", "sequence_length", "=", "seq_length", ")", "\n", "with", "self", ".", "test_session", "(", ")", "as", "sess", ":", "\n", "            ", "sess", ".", "run", "(", "tf", ".", "global_variables_initializer", "(", ")", ")", "\n", "outputs_", ",", "max_seq_length", "=", "sess", ".", "run", "(", "\n", "[", "outputs", ",", "tf", ".", "reduce_max", "(", "seq_length", ")", "]", ",", "\n", "feed_dict", "=", "{", "global_mode", "(", ")", ":", "tf", ".", "estimator", ".", "ModeKeys", ".", "TRAIN", "}", ")", "\n", "self", ".", "assertEqual", "(", "outputs_", ".", "shape", ",", "\n", "(", "64", ",", "max_seq_length", ")", "+", "tuple", "(", "emb_dim", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.embedders.embedders_test.EmbedderTest.test_embedder": [[101, 160], ["embedders_test.EmbedderTest._test_word_embedder", "embedders_test.EmbedderTest._test_position_embedder", "embedders_test.EmbedderTest._test_word_embedder", "embedders_test.EmbedderTest._test_position_embedder", "embedders_test.EmbedderTest._test_word_embedder", "embedders_test.EmbedderTest._test_position_embedder", "embedders_test.EmbedderTest._test_word_embedder", "embedders_test.EmbedderTest._test_position_embedder", "embedders_test.EmbedderTest._test_word_embedder", "embedders_test.EmbedderTest._test_position_embedder", "embedders_test.EmbedderTest._test_word_embedder", "embedders_test.EmbedderTest._test_position_embedder", "embedders_test.EmbedderTest._test_word_embedder", "embedders_test.EmbedderTest._test_position_embedder", "embedders_test.EmbedderTest._test_word_embedder", "embedders_test.EmbedderTest._test_position_embedder", "embedders_test.EmbedderTest._test_word_embedder", "embedders_test.EmbedderTest._test_position_embedder", "embedders_test.EmbedderTest._test_word_embedder", "embedders_test.EmbedderTest._test_position_embedder", "embedders_test.EmbedderTest._test_word_embedder", "embedders_test.EmbedderTest._test_position_embedder", "embedders_test.EmbedderTest._test_word_embedder", "embedders_test.EmbedderTest._test_position_embedder"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.embedders.embedders_test.EmbedderTest._test_word_embedder", "home.repos.pwc.inspect_result.VegB_Text_Infilling.embedders.embedders_test.EmbedderTest._test_position_embedder", "home.repos.pwc.inspect_result.VegB_Text_Infilling.embedders.embedders_test.EmbedderTest._test_word_embedder", "home.repos.pwc.inspect_result.VegB_Text_Infilling.embedders.embedders_test.EmbedderTest._test_position_embedder", "home.repos.pwc.inspect_result.VegB_Text_Infilling.embedders.embedders_test.EmbedderTest._test_word_embedder", "home.repos.pwc.inspect_result.VegB_Text_Infilling.embedders.embedders_test.EmbedderTest._test_position_embedder", "home.repos.pwc.inspect_result.VegB_Text_Infilling.embedders.embedders_test.EmbedderTest._test_word_embedder", "home.repos.pwc.inspect_result.VegB_Text_Infilling.embedders.embedders_test.EmbedderTest._test_position_embedder", "home.repos.pwc.inspect_result.VegB_Text_Infilling.embedders.embedders_test.EmbedderTest._test_word_embedder", "home.repos.pwc.inspect_result.VegB_Text_Infilling.embedders.embedders_test.EmbedderTest._test_position_embedder", "home.repos.pwc.inspect_result.VegB_Text_Infilling.embedders.embedders_test.EmbedderTest._test_word_embedder", "home.repos.pwc.inspect_result.VegB_Text_Infilling.embedders.embedders_test.EmbedderTest._test_position_embedder", "home.repos.pwc.inspect_result.VegB_Text_Infilling.embedders.embedders_test.EmbedderTest._test_word_embedder", "home.repos.pwc.inspect_result.VegB_Text_Infilling.embedders.embedders_test.EmbedderTest._test_position_embedder", "home.repos.pwc.inspect_result.VegB_Text_Infilling.embedders.embedders_test.EmbedderTest._test_word_embedder", "home.repos.pwc.inspect_result.VegB_Text_Infilling.embedders.embedders_test.EmbedderTest._test_position_embedder", "home.repos.pwc.inspect_result.VegB_Text_Infilling.embedders.embedders_test.EmbedderTest._test_word_embedder", "home.repos.pwc.inspect_result.VegB_Text_Infilling.embedders.embedders_test.EmbedderTest._test_position_embedder", "home.repos.pwc.inspect_result.VegB_Text_Infilling.embedders.embedders_test.EmbedderTest._test_word_embedder", "home.repos.pwc.inspect_result.VegB_Text_Infilling.embedders.embedders_test.EmbedderTest._test_position_embedder", "home.repos.pwc.inspect_result.VegB_Text_Infilling.embedders.embedders_test.EmbedderTest._test_word_embedder", "home.repos.pwc.inspect_result.VegB_Text_Infilling.embedders.embedders_test.EmbedderTest._test_position_embedder", "home.repos.pwc.inspect_result.VegB_Text_Infilling.embedders.embedders_test.EmbedderTest._test_word_embedder", "home.repos.pwc.inspect_result.VegB_Text_Infilling.embedders.embedders_test.EmbedderTest._test_position_embedder"], ["", "", "def", "test_embedder", "(", "self", ")", ":", "\n", "        ", "\"\"\"Tests various embedders.\n        \"\"\"", "\n", "# no dropout", "\n", "hparams", "=", "{", "\"dim\"", ":", "1024", ",", "\"dropout_rate\"", ":", "0", "}", "\n", "self", ".", "_test_word_embedder", "(", "hparams", ")", "\n", "self", ".", "_test_position_embedder", "(", "hparams", ")", "\n", "\n", "hparams", "=", "{", "\"dim\"", ":", "[", "1024", "]", ",", "\"dropout_rate\"", ":", "0", "}", "\n", "self", ".", "_test_word_embedder", "(", "hparams", ")", "\n", "self", ".", "_test_position_embedder", "(", "hparams", ")", "\n", "\n", "hparams", "=", "{", "\"dim\"", ":", "[", "1024", ",", "10", "]", ",", "\"dropout_rate\"", ":", "0", "}", "\n", "self", ".", "_test_word_embedder", "(", "hparams", ")", "\n", "self", ".", "_test_position_embedder", "(", "hparams", ")", "\n", "\n", "# dropout with default strategy", "\n", "hparams", "=", "{", "\"dim\"", ":", "1024", ",", "\"dropout_rate\"", ":", "0.3", "}", "\n", "self", ".", "_test_word_embedder", "(", "hparams", ")", "\n", "self", ".", "_test_position_embedder", "(", "hparams", ")", "\n", "\n", "hparams", "=", "{", "\"dim\"", ":", "[", "1024", "]", ",", "\"dropout_rate\"", ":", "0.3", "}", "\n", "self", ".", "_test_word_embedder", "(", "hparams", ")", "\n", "self", ".", "_test_position_embedder", "(", "hparams", ")", "\n", "\n", "hparams", "=", "{", "\"dim\"", ":", "[", "1024", ",", "10", "]", ",", "\"dropout_rate\"", ":", "0.3", "}", "\n", "self", ".", "_test_word_embedder", "(", "hparams", ")", "\n", "self", ".", "_test_position_embedder", "(", "hparams", ")", "\n", "\n", "# dropout with different strategies", "\n", "hparams", "=", "{", "\"dim\"", ":", "1024", ",", "\"dropout_rate\"", ":", "0.3", ",", "\n", "\"dropout_strategy\"", ":", "\"item\"", "}", "\n", "self", ".", "_test_word_embedder", "(", "hparams", ")", "\n", "self", ".", "_test_position_embedder", "(", "hparams", ")", "\n", "\n", "hparams", "=", "{", "\"dim\"", ":", "[", "1024", "]", ",", "\"dropout_rate\"", ":", "0.3", ",", "\n", "\"dropout_strategy\"", ":", "\"item\"", "}", "\n", "self", ".", "_test_word_embedder", "(", "hparams", ")", "\n", "self", ".", "_test_position_embedder", "(", "hparams", ")", "\n", "\n", "hparams", "=", "{", "\"dim\"", ":", "[", "1024", ",", "10", "]", ",", "\"dropout_rate\"", ":", "0.3", ",", "\n", "\"dropout_strategy\"", ":", "\"item\"", "}", "\n", "self", ".", "_test_word_embedder", "(", "hparams", ")", "\n", "self", ".", "_test_position_embedder", "(", "hparams", ")", "\n", "\n", "hparams", "=", "{", "\"dim\"", ":", "1024", ",", "\"dropout_rate\"", ":", "0.3", ",", "\n", "\"dropout_strategy\"", ":", "\"item_type\"", "}", "\n", "self", ".", "_test_word_embedder", "(", "hparams", ")", "\n", "self", ".", "_test_position_embedder", "(", "hparams", ")", "\n", "\n", "hparams", "=", "{", "\"dim\"", ":", "[", "1024", "]", ",", "\"dropout_rate\"", ":", "0.3", ",", "\n", "\"dropout_strategy\"", ":", "\"item_type\"", "}", "\n", "self", ".", "_test_word_embedder", "(", "hparams", ")", "\n", "self", ".", "_test_position_embedder", "(", "hparams", ")", "\n", "\n", "hparams", "=", "{", "\"dim\"", ":", "[", "1024", ",", "10", "]", ",", "\"dropout_rate\"", ":", "0.3", ",", "\n", "\"dropout_strategy\"", ":", "\"item_type\"", "}", "\n", "self", ".", "_test_word_embedder", "(", "hparams", ")", "\n", "self", ".", "_test_position_embedder", "(", "hparams", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.embedders.embedders_test.EmbedderTest.test_embedder_multi_calls": [[161, 184], ["texar.modules.embedders.embedders.WordEmbedder", "tensorflow.ones", "texar.modules.embedders.embedders.WordEmbedder.", "embedders_test.EmbedderTest.assertEqual", "tensorflow.ones", "texar.modules.embedders.embedders.WordEmbedder.", "embedders_test.EmbedderTest.assertEqual", "isinstance", "isinstance"], "methods", ["None"], ["", "def", "test_embedder_multi_calls", "(", "self", ")", ":", "\n", "        ", "\"\"\"Tests embedders called by multiple times.\n        \"\"\"", "\n", "hparams", "=", "{", "\"dim\"", ":", "1024", ",", "\"dropout_rate\"", ":", "0.3", ",", "\n", "\"dropout_strategy\"", ":", "\"item\"", "}", "\n", "embedder", "=", "WordEmbedder", "(", "\n", "vocab_size", "=", "100", ",", "hparams", "=", "hparams", ")", "\n", "inputs", "=", "tf", ".", "ones", "(", "[", "64", ",", "16", "]", ",", "dtype", "=", "tf", ".", "int32", ")", "\n", "outputs", "=", "embedder", "(", "inputs", ")", "\n", "\n", "emb_dim", "=", "embedder", ".", "dim", "\n", "if", "not", "isinstance", "(", "emb_dim", ",", "(", "list", ",", "tuple", ")", ")", ":", "\n", "            ", "emb_dim", "=", "[", "emb_dim", "]", "\n", "", "self", ".", "assertEqual", "(", "outputs", ".", "shape", ",", "[", "64", ",", "16", "]", "+", "emb_dim", ")", "\n", "\n", "# Call with inputs in a different shape", "\n", "inputs", "=", "tf", ".", "ones", "(", "[", "64", ",", "10", ",", "20", "]", ",", "dtype", "=", "tf", ".", "int32", ")", "\n", "outputs", "=", "embedder", "(", "inputs", ")", "\n", "\n", "emb_dim", "=", "embedder", ".", "dim", "\n", "if", "not", "isinstance", "(", "emb_dim", ",", "(", "list", ",", "tuple", ")", ")", ":", "\n", "            ", "emb_dim", "=", "[", "emb_dim", "]", "\n", "", "self", ".", "assertEqual", "(", "outputs", ".", "shape", ",", "[", "64", ",", "10", ",", "20", "]", "+", "emb_dim", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.embedders.embedders_test.EmbedderTest.test_word_embedder_soft_ids": [[185, 201], ["numpy.expand_dims", "texar.modules.embedders.embedders.WordEmbedder", "numpy.array", "numpy.array", "texar.modules.embedders.embedders.WordEmbedder.", "texar.modules.embedders.embedders.WordEmbedder.", "numpy.arange", "embedders_test.EmbedderTest.test_session", "sess.run", "sess.run", "embedders_test.EmbedderTest.assertEqual", "tensorflow.global_variables_initializer"], "methods", ["None"], ["", "def", "test_word_embedder_soft_ids", "(", "self", ")", ":", "\n", "        ", "\"\"\"Tests the correctness of using soft ids.\n        \"\"\"", "\n", "init_value", "=", "np", ".", "expand_dims", "(", "np", ".", "arange", "(", "5", ")", ",", "1", ")", "\n", "embedder", "=", "WordEmbedder", "(", "init_value", "=", "init_value", ")", "\n", "\n", "ids", "=", "np", ".", "array", "(", "[", "3", "]", ")", "\n", "soft_ids", "=", "np", ".", "array", "(", "[", "[", "0", ",", "0", ",", "0", ",", "1", ",", "0", "]", "]", ")", "\n", "\n", "outputs", "=", "embedder", "(", "ids", "=", "ids", ")", "\n", "soft_outputs", "=", "embedder", "(", "soft_ids", "=", "soft_ids", ")", "\n", "\n", "with", "self", ".", "test_session", "(", ")", "as", "sess", ":", "\n", "            ", "sess", ".", "run", "(", "tf", ".", "global_variables_initializer", "(", ")", ")", "\n", "outputs_", ",", "soft_outputs_", "=", "sess", ".", "run", "(", "[", "outputs", ",", "soft_outputs", "]", ")", "\n", "self", ".", "assertEqual", "(", "outputs_", ",", "soft_outputs_", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.embedders.embedder_utils.default_embedding_hparams": [[20, 155], ["texar.core.layers.default_regularizer_hparams"], "function", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.core.layers.default_regularizer_hparams"], ["def", "default_embedding_hparams", "(", ")", ":", "\n", "    ", "\"\"\"Returns default hyperparameters of token embedding used in encoders,\n    decoders, and other modules.\n\n    Returns:\n        A dictionary with the following structure and values.\n\n        .. code-block:: python\n\n            {\n                \"name\": \"embedding\",\n                \"dim\": 100,\n                \"initializer\": None,\n                \"regularizer\": {\n                    \"type\": \"L1L2\",\n                    \"kwargs\": {\n                        \"l1\": 0.,\n                        \"l2\": 0.\n                    }\n                },\n                \"dropout_rate\": 0.,\n                \"dropout_strategy\": 'element',\n                \"trainable\": True,\n            }\n\n        Here:\n\n        \"name\" : str\n            Name of the embedding variable.\n\n        \"dim\" : int or list\n            Embedding dimension. Can be a list of integers to yield embeddings\n            with dimensionality > 1.\n\n        \"initializer\" : dict or None\n            Hyperparameters of the initializer for the embedding values. An\n            example is as\n\n            .. code-block:: python\n\n                {\n                    \"type\": \"random_uniform_initializer\",\n                    \"kwargs\": {\n                        \"minval\": -0.1,\n                        \"maxval\": 0.1,\n                        \"seed\": None\n                    }\n                }\n\n            which corresponds to :tf_main:`tf.random_uniform_initializer\n            <random_uniform_initializer>`, and includes:\n\n            \"type\" : str or initializer instance\n                Name, full path, or instance of the initializer class; Or name\n                or full path to a function that returns the initializer class.\n                The class or function can be\n\n                - Built-in initializer defined in \\\n                  :tf_main:`tf.initializers <initializers>`, e.g., \\\n                  :tf_main:`random_uniform <random_uniform_initializer>` \\\n                  (a.k.a :class:`tf.random_uniform_initializer`), or \\\n                  in :mod:`tf`, e.g., :tf_main:`glorot_uniform_initializer \\\n                  <glorot_uniform_initializer>`, or in \\\n                  :tf_main:`tf.keras.initializers <keras/initializers>`.\n                - User-defined initializer in :mod:`texar.custom`.\n                - External initializer. Must provide the full path, \\\n                  e.g., :attr:`\"my_module.MyInitializer\"`, or the instance.\n\n            \"kwargs\" : dict\n                A dictionary of arguments for constructor of the\n                initializer class or for the function. An initializer is\n                created by `initialzier = initializer_class_or_fn(**kwargs)`\n                where :attr:`initializer_class_or_fn` is specified in\n                :attr:`\"type\"`.\n                Ignored if :attr:`\"type\"` is an initializer instance.\n\n        \"regularizer\" : dict\n            Hyperparameters of the regularizer for the embedding values. The\n            regularizer must be an instance of\n            the base :tf_main:`Regularizer <keras/regularizers/Regularizer>`\n            class. The hyperparameters include:\n\n            \"type\" : str or Regularizer instance\n                Name, full path, or instance of the regularizer class. The\n                class can be\n\n                - Built-in regularizer defined in\n                  :tf_main:`tf.keras.regularizers <keras/regularizers>`, e.g.,\n                  :tf_main:`L1L2 <keras/regularizers/L1L2>`.\n                - User-defined regularizer in :mod:`texar.custom`. The\n                  regularizer class should inherit the base class\n                  :tf_main:`Regularizer <keras/regularizers/Regularizer>`.\n                - External regularizer. Must provide the full path, \\\n                  e.g., :attr:`\"my_module.MyRegularizer\"`, or the instance.\n\n            \"kwargs\" : dict\n                A dictionary of arguments for constructor of the\n                regularizer class. A regularizer is created by\n                calling `regularizer_class(**kwargs)` where\n                :attr:`regularizer_class` is specified in :attr:`\"type\"`.\n                Ignored if :attr:`\"type\"` is a Regularizer instance.\n\n            The default value corresponds to\n            :tf_main:`L1L2 <keras/regularizers/L1L2>` with `(l1=0, l2=0)`,\n            which disables regularization.\n\n        \"dropout_rate\" : float\n            The dropout rate between 0 and 1. E.g., `dropout_rate=0.1` would\n            drop out 10% of the embedding.\n\n        \"dropout_strategy\" : str\n            The dropout strategy. Can be one of the following\n\n            - 'element': The regular strategy that drops individual elements \\\n              in the embedding vectors.\n            - 'item': Drops individual items (e.g., words) entirely. E.g., for \\\n              the word sequence 'the simpler the better', the strategy can \\\n              yield '_ simpler the better', where the first `the` is dropped.\n            - 'item_type': Drops item types (e.g., word types). E.g., for the \\\n              above sequence, the strategy can yield '_ simpler _ better', \\\n              where the word type 'the' is dropped. The dropout will never \\\n              yield '_ simpler the better' as in the 'item' strategy.\n\n        \"trainable\" : bool\n            Whether the embedding is trainable.\n    \"\"\"", "\n", "return", "{", "\n", "\"name\"", ":", "\"embedding\"", ",", "\n", "\"dim\"", ":", "100", ",", "\n", "\"initializer\"", ":", "None", ",", "\n", "\"regularizer\"", ":", "layers", ".", "default_regularizer_hparams", "(", ")", ",", "\n", "\"dropout_rate\"", ":", "0.", ",", "\n", "\"dropout_strategy\"", ":", "'element'", ",", "\n", "\"trainable\"", ":", "True", ",", "\n", "\"@no_typecheck\"", ":", "[", "\"dim\"", "]", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.embedders.embedder_utils.get_embedding": [[158, 207], ["tensorflow.variable_scope", "texar.core.layers.get_regularizer", "isinstance", "texar.hyperparams.HParams", "texar.core.layers.get_initializer", "tensorflow.get_variable", "tensorflow.get_variable", "embedder_utils.default_embedding_hparams", "isinstance", "tensorflow.to_float"], "function", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.agents.agent_base.AgentBase.variable_scope", "home.repos.pwc.inspect_result.VegB_Text_Infilling.core.layers.get_regularizer", "home.repos.pwc.inspect_result.VegB_Text_Infilling.core.layers.get_initializer", "home.repos.pwc.inspect_result.VegB_Text_Infilling.embedders.embedder_utils.default_embedding_hparams"], ["", "def", "get_embedding", "(", "hparams", "=", "None", ",", "\n", "init_value", "=", "None", ",", "\n", "num_embeds", "=", "None", ",", "\n", "variable_scope", "=", "'Embedding'", ")", ":", "\n", "    ", "\"\"\"Creates embedding variable if not exists.\n\n    Args:\n        hparams (dict or HParams, optional): Embedding hyperparameters. Missing\n            hyperparameters are set to default values. See\n            :func:`~texar.modules.default_embedding_hparams`\n            for all hyperparameters and default values.\n\n            If :attr:`init_value` is given, :attr:`hparams[\"initializer\"]`,\n            and :attr:`hparams[\"dim\"]` are ignored.\n        init_value (Tensor or numpy array, optional): Initial values of the\n            embedding variable. If not given, embedding is initialized as\n            specified in :attr:`hparams[\"initializer\"]`.\n        num_embeds (int, optional): The number of embedding items\n            (e.g., vocabulary size). Required if :attr:`init_value` is\n            not provided.\n        variable_scope (str or VariableScope, optional): Variable scope of\n            the embedding variable.\n\n    Returns:\n        Variable or Tensor: A 2D `Variable` or `Tensor` of the same shape with\n        :attr:`init_value` or of the shape\n        :attr:`[num_embeds, hparams[\"dim\"]]`.\n    \"\"\"", "\n", "with", "tf", ".", "variable_scope", "(", "variable_scope", ")", ":", "\n", "        ", "if", "hparams", "is", "None", "or", "isinstance", "(", "hparams", ",", "dict", ")", ":", "\n", "            ", "hparams", "=", "HParams", "(", "hparams", ",", "default_embedding_hparams", "(", ")", ")", "\n", "", "regularizer", "=", "layers", ".", "get_regularizer", "(", "hparams", "[", "\"regularizer\"", "]", ")", "\n", "if", "init_value", "is", "None", ":", "\n", "            ", "initializer", "=", "layers", ".", "get_initializer", "(", "hparams", "[", "\"initializer\"", "]", ")", "\n", "dim", "=", "hparams", "[", "\"dim\"", "]", "\n", "if", "not", "isinstance", "(", "hparams", "[", "\"dim\"", "]", ",", "(", "list", ",", "tuple", ")", ")", ":", "\n", "                ", "dim", "=", "[", "dim", "]", "\n", "", "embedding", "=", "tf", ".", "get_variable", "(", "name", "=", "hparams", "[", "\"name\"", "]", ",", "\n", "shape", "=", "[", "num_embeds", "]", "+", "dim", ",", "\n", "initializer", "=", "initializer", ",", "\n", "regularizer", "=", "regularizer", ",", "\n", "trainable", "=", "hparams", "[", "\"trainable\"", "]", ")", "\n", "", "else", ":", "\n", "            ", "embedding", "=", "tf", ".", "get_variable", "(", "name", "=", "hparams", "[", "\"name\"", "]", ",", "\n", "initializer", "=", "tf", ".", "to_float", "(", "init_value", ")", ",", "\n", "regularizer", "=", "regularizer", ",", "\n", "trainable", "=", "hparams", "[", "\"trainable\"", "]", ")", "\n", "\n", "", "return", "embedding", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.embedders.embedder_utils.soft_embedding_lookup": [[208, 233], ["tensorflow.tensordot", "tensorflow.to_float"], "function", ["None"], ["", "", "def", "soft_embedding_lookup", "(", "embedding", ",", "soft_ids", ")", ":", "\n", "    ", "\"\"\"Transforms soft ids (e.g., probability distribution over ids) into\n    embeddings, by mixing the embedding vectors with the soft weights.\n\n    Args:\n        embedding: A Tensor of shape `[num_classes] + embedding-dim` containing\n            the embedding vectors. Embedding can have dimensionality > 1, i.e.,\n            :attr:`embedding` can be of shape\n            `[num_classes, emb_dim_1, emb_dim_2, ...]`\n        soft_ids: A Tensor of weights (probabilities) used to mix the\n            embedding vectors.\n\n    Returns:\n        A Tensor of shape `shape(soft_ids)[:-1] + shape(embedding)[1:]`. For\n        example, if `shape(soft_ids) = [batch_size, max_time, vocab_size]`\n        and `shape(embedding) = [vocab_size, emb_dim]`, then the return tensor\n        has shape `[batch_size, max_time, emb_dim]`.\n\n    Example::\n\n        decoder_outputs, ... = decoder(...)\n        soft_seq_emb = soft_embedding_lookup(\n            embedding, tf.nn.softmax(decoder_outputs.logits))\n    \"\"\"", "\n", "return", "tf", ".", "tensordot", "(", "tf", ".", "to_float", "(", "soft_ids", ")", ",", "embedding", ",", "[", "-", "1", ",", "0", "]", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.embedders.embedder_base.EmbedderBase.__init__": [[25, 29], ["texar.module_base.ModuleBase.__init__"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.text_infilling.self_attn_hyperparams.Hyperparams.__init__"], ["def", "__init__", "(", "self", ",", "num_embeds", "=", "None", ",", "hparams", "=", "None", ")", ":", "\n", "        ", "ModuleBase", ".", "__init__", "(", "self", ",", "hparams", ")", "\n", "\n", "self", ".", "_num_embeds", "=", "num_embeds", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.embedders.embedder_base.EmbedderBase._init_parameterized_embedding": [[31, 43], ["texar.modules.embedders.embedder_utils.get_embedding", "len", "embedder_base.EmbedderBase._add_trainable_variable", "embedder_base.EmbedderBase._embedding.get_shape().as_list", "embedder_base.EmbedderBase._embedding.get_shape().as_list", "embedder_base.EmbedderBase._embedding.get_shape", "embedder_base.EmbedderBase._embedding.get_shape"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.embedders.embedder_utils.get_embedding", "home.repos.pwc.inspect_result.VegB_Text_Infilling.texar.module_base.ModuleBase._add_trainable_variable"], ["", "def", "_init_parameterized_embedding", "(", "self", ",", "init_value", ",", "num_embeds", ",", "hparams", ")", ":", "\n", "        ", "self", ".", "_embedding", "=", "embedder_utils", ".", "get_embedding", "(", "\n", "hparams", ",", "init_value", ",", "num_embeds", ",", "self", ".", "variable_scope", ")", "\n", "if", "hparams", ".", "trainable", ":", "\n", "            ", "self", ".", "_add_trainable_variable", "(", "self", ".", "_embedding", ")", "\n", "\n", "", "self", ".", "_num_embeds", "=", "self", ".", "_embedding", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", "[", "0", "]", "\n", "\n", "self", ".", "_dim", "=", "self", ".", "_embedding", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", "[", "1", ":", "]", "\n", "self", ".", "_dim_rank", "=", "len", "(", "self", ".", "_dim", ")", "\n", "if", "self", ".", "_dim_rank", "==", "1", ":", "\n", "            ", "self", ".", "_dim", "=", "self", ".", "_dim", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.embedders.embedder_base.EmbedderBase._get_dropout_layer": [[44, 71], ["tensorflow.layers.Dropout", "tensorflow.concat", "ValueError", "tensorflow.ones", "tensorflow.shape"], "methods", ["None"], ["", "", "def", "_get_dropout_layer", "(", "self", ",", "hparams", ",", "ids_rank", "=", "None", ",", "dropout_input", "=", "None", ",", "\n", "dropout_strategy", "=", "None", ")", ":", "\n", "        ", "\"\"\"Creates dropout layer according to dropout strategy.\n\n        Called in :meth:`_build()`.\n        \"\"\"", "\n", "dropout_layer", "=", "None", "\n", "\n", "st", "=", "dropout_strategy", "\n", "st", "=", "hparams", ".", "dropout_strategy", "if", "st", "is", "None", "else", "st", "\n", "\n", "if", "hparams", ".", "dropout_rate", ">", "0.", ":", "\n", "            ", "if", "st", "==", "'element'", ":", "\n", "                ", "noise_shape", "=", "None", "\n", "", "elif", "st", "==", "'item'", ":", "\n", "                ", "noise_shape", "=", "tf", ".", "concat", "(", "[", "tf", ".", "shape", "(", "dropout_input", ")", "[", ":", "ids_rank", "]", ",", "\n", "tf", ".", "ones", "(", "[", "self", ".", "_dim_rank", "]", ",", "tf", ".", "int32", ")", "]", ",", "\n", "axis", "=", "0", ")", "\n", "", "elif", "st", "==", "'item_type'", ":", "\n", "                ", "noise_shape", "=", "[", "None", "]", "+", "[", "1", "]", "*", "self", ".", "_dim_rank", "\n", "", "else", ":", "\n", "                ", "raise", "ValueError", "(", "'Unknown dropout strategy: {}'", ".", "format", "(", "st", ")", ")", "\n", "\n", "", "dropout_layer", "=", "tf", ".", "layers", ".", "Dropout", "(", "\n", "rate", "=", "hparams", ".", "dropout_rate", ",", "noise_shape", "=", "noise_shape", ")", "\n", "\n", "", "return", "dropout_layer", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.embedders.embedder_base.EmbedderBase.default_hparams": [[72, 78], ["None"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "default_hparams", "(", ")", ":", "\n", "        ", "\"\"\"Returns a dictionary of hyperparameters with default values.\n        \"\"\"", "\n", "return", "{", "\n", "\"name\"", ":", "\"embedder\"", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.embedders.embedder_base.EmbedderBase._build": [[80, 82], ["None"], "methods", ["None"], ["", "def", "_build", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.embedders.embedder_base.EmbedderBase.num_embeds": [[83, 88], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "num_embeds", "(", "self", ")", ":", "\n", "        ", "\"\"\"The number of embedding vectors.\n        \"\"\"", "\n", "return", "self", ".", "_num_embeds", "\n", "", "", ""]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.embedders.embedders.WordEmbedder.__init__": [[45, 64], ["texar.modules.embedders.embedder_base.EmbedderBase.__init__", "embedders.WordEmbedder._init_parameterized_embedding", "ValueError", "ValueError"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.text_infilling.self_attn_hyperparams.Hyperparams.__init__", "home.repos.pwc.inspect_result.VegB_Text_Infilling.embedders.embedder_base.EmbedderBase._init_parameterized_embedding"], ["def", "__init__", "(", "self", ",", "init_value", "=", "None", ",", "vocab_size", "=", "None", ",", "hparams", "=", "None", ")", ":", "\n", "        ", "EmbedderBase", ".", "__init__", "(", "self", ",", "hparams", "=", "hparams", ")", "\n", "\n", "if", "init_value", "is", "None", "and", "vocab_size", "is", "None", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "\"Either `init_value` or `vocab_size` is required.\"", ")", "\n", "\n", "", "self", ".", "_init_parameterized_embedding", "(", "init_value", ",", "vocab_size", ",", "\n", "self", ".", "_hparams", ")", "\n", "\n", "self", ".", "_vocab_size", "=", "vocab_size", "\n", "if", "vocab_size", "is", "None", ":", "\n", "            ", "self", ".", "_vocab_size", "=", "self", ".", "_num_embeds", "\n", "", "if", "self", ".", "_vocab_size", "!=", "self", ".", "_num_embeds", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "'vocab_size must equal to init_value.shape[0].'", "\n", "'Got %d and %d'", "%", "(", "self", ".", "_vocab_size", ",", "self", ".", "_num_embeds", ")", ")", "\n", "\n", "", "self", ".", "_built", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.embedders.embedders.WordEmbedder.default_hparams": [[65, 103], ["texar.modules.embedders.embedder_utils.default_embedding_hparams"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.embedders.embedder_utils.default_embedding_hparams"], ["", "@", "staticmethod", "\n", "def", "default_hparams", "(", ")", ":", "\n", "        ", "\"\"\"Returns a dictionary of hyperparameters with default values.\n\n        Returns:\n            A dictionary with the following structure and values.\n\n            .. code-block:: python\n\n                {\n                    \"name\": \"word_embedder\",\n                    \"dim\": 100,\n                    \"initializer\": {\n                        \"type\": \"random_uniform_initializer\",\n                        \"kwargs\": {\n                            \"minval\": -0.1,\n                            \"maxval\": 0.1,\n                            \"seed\": None\n                        }\n                    },\n                    \"regularizer\": {\n                        \"type\": \"L1L2\",\n                        \"kwargs\": {\n                            \"l1\": 0.,\n                            \"l2\": 0.\n                        }\n                    },\n                    \"dropout_rate\": 0,\n                    \"dropout_strategy\": 'element',\n                    \"trainable\": True,\n                }\n\n            See :func:`~texar.modules.default_embedding_hparams` for more\n            details.\n        \"\"\"", "\n", "hparams", "=", "embedder_utils", ".", "default_embedding_hparams", "(", ")", "\n", "hparams", "[", "\"name\"", "]", "=", "\"word_embedder\"", "\n", "return", "hparams", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.embedders.embedders.WordEmbedder._build": [[104, 167], ["texar.utils.mode.is_train_mode", "texar.utils.shapes.get_rank", "embedders.WordEmbedder._get_dropout_layer", "tensorflow.nn.embedding_lookup", "texar.modules.embedders.embedder_utils.soft_embedding_lookup", "embedders.WordEmbedder._get_dropout_layer", "ValueError", "ValueError", "embedders.WordEmbedder.apply", "embedders.WordEmbedder.apply", "texar.utils.shapes.get_rank"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.mode.is_train_mode", "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.shapes.get_rank", "home.repos.pwc.inspect_result.VegB_Text_Infilling.embedders.embedder_base.EmbedderBase._get_dropout_layer", "home.repos.pwc.inspect_result.VegB_Text_Infilling.embedders.embedder_utils.soft_embedding_lookup", "home.repos.pwc.inspect_result.VegB_Text_Infilling.embedders.embedder_base.EmbedderBase._get_dropout_layer", "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.shapes.get_rank"], ["", "def", "_build", "(", "self", ",", "ids", "=", "None", ",", "soft_ids", "=", "None", ",", "mode", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"Embeds (soft) ids.\n\n        Either :attr:`ids` or :attr:`soft_ids` must be given, and they\n        must not be given at the same time.\n\n        Args:\n            ids (optional): An integer tensor containing the ids to embed.\n            soft_ids (optional): A Tensor of weights (probabilities) used to\n                mix the embedding vectors.\n            mode (optional): A tensor taking value in\n                :tf_main:`tf.estimator.ModeKeys <estimator/ModeKeys>`, including\n                `TRAIN`, `EVAL`, and `PREDICT`. If `None`, dropout will be\n                controlled by :func:`texar.context.global_mode`.\n            kwargs: Additional keyword arguments for\n                :tf_main:`tf.nn.embedding_lookup <nn/embedding_lookup>` besides\n                :attr:`params` and :attr:`ids`.\n\n        Returns:\n            If :attr:`ids` is given, returns a Tensor of shape\n            `shape(ids) + embedding-dim`. For example,\n            if `shape(ids) = [batch_size, max_time]`\n            and `shape(embedding) = [vocab_size, emb_dim]`, then the return\n            tensor has shape `[batch_size, max_time, emb_dim]`.\n\n            If :attr:`soft_ids` is given, returns a Tensor of shape\n            `shape(soft_ids)[:-1] + embdding-dim`. For example,\n            if `shape(soft_ids) = [batch_size, max_time, vocab_size]`\n            and `shape(embedding) = [vocab_size, emb_dim]`, then the return\n            tensor has shape `[batch_size, max_time, emb_dim]`.\n        \"\"\"", "\n", "if", "ids", "is", "not", "None", ":", "\n", "            ", "if", "soft_ids", "is", "not", "None", ":", "\n", "                ", "raise", "ValueError", "(", "\n", "'Must not specify `ids` and `soft_ids` at the same time.'", ")", "\n", "", "ids_rank", "=", "get_rank", "(", "ids", ")", "\n", "", "elif", "soft_ids", "is", "not", "None", ":", "\n", "            ", "ids_rank", "=", "get_rank", "(", "soft_ids", ")", "-", "1", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "'Either `ids` or `soft_ids` must be given.'", ")", "\n", "\n", "", "embedding", "=", "self", ".", "_embedding", "\n", "\n", "is_training", "=", "is_train_mode", "(", "mode", ")", "\n", "if", "self", ".", "_hparams", ".", "dropout_strategy", "==", "'item_type'", ":", "\n", "            ", "dropout_layer", "=", "self", ".", "_get_dropout_layer", "(", "self", ".", "_hparams", ")", "\n", "if", "dropout_layer", ":", "\n", "                ", "embedding", "=", "dropout_layer", ".", "apply", "(", "inputs", "=", "embedding", ",", "\n", "training", "=", "is_training", ")", "\n", "\n", "", "", "if", "ids", "is", "not", "None", ":", "\n", "            ", "outputs", "=", "tf", ".", "nn", ".", "embedding_lookup", "(", "embedding", ",", "ids", ",", "**", "kwargs", ")", "\n", "", "else", ":", "\n", "            ", "outputs", "=", "embedder_utils", ".", "soft_embedding_lookup", "(", "embedding", ",", "soft_ids", ")", "\n", "\n", "", "if", "self", ".", "_hparams", ".", "dropout_strategy", "!=", "'item_type'", ":", "\n", "            ", "dropout_layer", "=", "self", ".", "_get_dropout_layer", "(", "\n", "self", ".", "_hparams", ",", "ids_rank", "=", "ids_rank", ",", "dropout_input", "=", "outputs", ")", "\n", "if", "dropout_layer", ":", "\n", "                ", "outputs", "=", "dropout_layer", ".", "apply", "(", "\n", "inputs", "=", "outputs", ",", "training", "=", "is_training", ")", "\n", "\n", "", "", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.embedders.embedders.WordEmbedder.embedding": [[168, 173], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "embedding", "(", "self", ")", ":", "\n", "        ", "\"\"\"The embedding tensor.\n        \"\"\"", "\n", "return", "self", ".", "_embedding", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.embedders.embedders.WordEmbedder.dim": [[174, 179], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "dim", "(", "self", ")", ":", "\n", "        ", "\"\"\"The embedding dimension.\n        \"\"\"", "\n", "return", "self", ".", "_dim", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.embedders.embedders.WordEmbedder.vocab_size": [[180, 185], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "vocab_size", "(", "self", ")", ":", "\n", "        ", "\"\"\"The vocabulary size.\n        \"\"\"", "\n", "return", "self", ".", "_vocab_size", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.embedders.embedder_utils_test.GetEmbeddingTest.test_get_embedding": [[20, 43], ["texar.modules.embedders.embedder_utils.get_embedding", "embedder_utils_test.GetEmbeddingTest.assertEqual", "embedder_utils_test.GetEmbeddingTest.assertEqual", "texar.modules.embedders.embedder_utils.get_embedding", "embedder_utils_test.GetEmbeddingTest.assertEqual", "embedder_utils_test.GetEmbeddingTest.assertEqual", "texar.modules.embedders.embedder_utils.default_embedding_hparams", "tensorflow.random_uniform_initializer", "tensorflow.keras.regularizers.L1L2", "texar.modules.embedders.embedder_utils.default_embedding_hparams"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.embedders.embedder_utils.get_embedding", "home.repos.pwc.inspect_result.VegB_Text_Infilling.embedders.embedder_utils.get_embedding", "home.repos.pwc.inspect_result.VegB_Text_Infilling.embedders.embedder_utils.default_embedding_hparams", "home.repos.pwc.inspect_result.VegB_Text_Infilling.embedders.embedder_utils.default_embedding_hparams"], ["def", "test_get_embedding", "(", "self", ")", ":", "\n", "        ", "\"\"\"Tests :func:`~texar.modules.embedder.embedder_utils.get_embedding`.\n        \"\"\"", "\n", "vocab_size", "=", "100", "\n", "emb", "=", "embedder_utils", ".", "get_embedding", "(", "vocab_size", "=", "vocab_size", ")", "\n", "self", ".", "assertEqual", "(", "emb", ".", "shape", "[", "0", "]", ".", "value", ",", "vocab_size", ")", "\n", "self", ".", "assertEqual", "(", "emb", ".", "shape", "[", "1", "]", ".", "value", ",", "\n", "embedder_utils", ".", "default_embedding_hparams", "(", ")", "[", "\"dim\"", "]", ")", "\n", "\n", "hparams", "=", "{", "\n", "\"name\"", ":", "\"embedding_2\"", ",", "\n", "\"initializer\"", ":", "{", "\n", "\"type\"", ":", "tf", ".", "random_uniform_initializer", "(", "minval", "=", "-", "0.1", ",", "maxval", "=", "0.1", ")", "\n", "}", ",", "\n", "\"regularizer\"", ":", "{", "\n", "\"type\"", ":", "tf", ".", "keras", ".", "regularizers", ".", "L1L2", "(", "0.1", ",", "0.1", ")", "\n", "}", "\n", "}", "\n", "emb", "=", "embedder_utils", ".", "get_embedding", "(", "\n", "hparams", "=", "hparams", ",", "vocab_size", "=", "vocab_size", ")", "\n", "self", ".", "assertEqual", "(", "emb", ".", "shape", "[", "0", "]", ".", "value", ",", "vocab_size", ")", "\n", "self", ".", "assertEqual", "(", "emb", ".", "shape", "[", "1", "]", ".", "value", ",", "\n", "embedder_utils", ".", "default_embedding_hparams", "(", ")", "[", "\"dim\"", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.models.model_base.ModelBase.__init__": [[20, 23], ["texar.HParams", "model_base.ModelBase.default_hparams"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.core.replay_memories.DequeReplayMemory.default_hparams"], ["def", "__init__", "(", "self", ",", "hparams", "=", "None", ")", ":", "\n", "        ", "self", ".", "_hparams", "=", "HParams", "(", "hparams", ",", "self", ".", "default_hparams", "(", ")", ",", "\n", "allow_new_hparam", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.models.model_base.ModelBase.default_hparams": [[24, 32], ["None"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "default_hparams", "(", ")", ":", "\n", "        ", "\"\"\"Returns a dictionary of hyperparameters with default values.\n        \"\"\"", "\n", "hparams", "=", "{", "\n", "\"name\"", ":", "\"model\"", "\n", "}", "\n", "return", "hparams", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.models.model_base.ModelBase.__call__": [[33, 39], ["model_base.ModelBase._build"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.seq2seq.seq2seq_base.Seq2seqBase._build"], ["", "def", "__call__", "(", "self", ",", "features", ",", "labels", ",", "params", ",", "mode", ",", "config", "=", "None", ")", ":", "\n", "        ", "\"\"\"Used for the :tf_main:`model_fn <estimator/Estimator#__init__>`\n        argument when constructing\n        :tf_main:`tf.estimator.Estimator <estimator/Estimator>`.\n        \"\"\"", "\n", "return", "self", ".", "_build", "(", "features", ",", "labels", ",", "params", ",", "mode", ",", "config", "=", "config", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.models.model_base.ModelBase._build": [[40, 42], ["None"], "methods", ["None"], ["", "def", "_build", "(", "self", ",", "features", ",", "labels", ",", "params", ",", "mode", ",", "config", "=", "None", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.models.model_base.ModelBase.get_input_fn": [[43, 48], ["None"], "methods", ["None"], ["", "def", "get_input_fn", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"Returns the :attr:`input_fn` function that constructs the input\n        data, used in :tf_main:`tf.estimator.Estimator <estimator/Estimator>`.\n        \"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.models.model_base.ModelBase.hparams": [[49, 55], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "hparams", "(", "self", ")", ":", "\n", "        ", "\"\"\"A :class:`~texar.hyperparams.HParams` instance. The hyperparameters\n        of the module.\n        \"\"\"", "\n", "return", "self", ".", "_hparams", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.seq2seq.seq2seq_base.Seq2seqBase.__init__": [[28, 41], ["texar.models.model_base.ModelBase.__init__", "texar.HParams", "texar.data.data.paired_text_data.PairedTextData.default_hparams"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.text_infilling.self_attn_hyperparams.Hyperparams.__init__", "home.repos.pwc.inspect_result.VegB_Text_Infilling.core.replay_memories.DequeReplayMemory.default_hparams"], ["def", "__init__", "(", "self", ",", "data_hparams", ",", "hparams", "=", "None", ")", ":", "\n", "        ", "ModelBase", ".", "__init__", "(", "self", ",", "hparams", ")", "\n", "\n", "self", ".", "_data_hparams", "=", "HParams", "(", "data_hparams", ",", "\n", "PairedTextData", ".", "default_hparams", "(", ")", ")", "\n", "\n", "self", ".", "_src_vocab", "=", "None", "\n", "self", ".", "_tgt_vocab", "=", "None", "\n", "self", ".", "_src_embedder", "=", "None", "\n", "self", ".", "_tgt_embedder", "=", "None", "\n", "self", ".", "_connector", "=", "None", "\n", "self", ".", "_encoder", "=", "None", "\n", "self", ".", "_decoder", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.seq2seq.seq2seq_base.Seq2seqBase.default_hparams": [[42, 67], ["texar.models.model_base.ModelBase.default_hparams", "texar.models.model_base.ModelBase.default_hparams.update"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.core.replay_memories.DequeReplayMemory.default_hparams"], ["", "@", "staticmethod", "\n", "def", "default_hparams", "(", ")", ":", "\n", "        ", "\"\"\"Returns a dictionary of hyperparameters with default values.\n        \"\"\"", "\n", "hparams", "=", "ModelBase", ".", "default_hparams", "(", ")", "\n", "hparams", ".", "update", "(", "{", "\n", "\"name\"", ":", "\"seq2seq\"", ",", "\n", "\"source_embedder\"", ":", "\"WordEmbedder\"", ",", "\n", "\"source_embedder_hparams\"", ":", "{", "}", ",", "\n", "\"target_embedder\"", ":", "\"WordEmbedder\"", ",", "\n", "\"target_embedder_hparams\"", ":", "{", "}", ",", "\n", "\"embedder_share\"", ":", "True", ",", "\n", "\"embedder_hparams_share\"", ":", "True", ",", "\n", "\"encoder\"", ":", "\"UnidirectionalRNNEncoder\"", ",", "\n", "\"encoder_hparams\"", ":", "{", "}", ",", "\n", "\"decoder\"", ":", "\"BasicRNNDecoder\"", ",", "\n", "\"decoder_hparams\"", ":", "{", "}", ",", "\n", "\"decoding_strategy_train\"", ":", "\"train_greedy\"", ",", "\n", "\"decoding_strategy_infer\"", ":", "\"infer_greedy\"", ",", "\n", "\"beam_search_width\"", ":", "0", ",", "\n", "\"connector\"", ":", "\"MLPTransformConnector\"", ",", "\n", "\"connector_hparams\"", ":", "{", "}", ",", "\n", "\"optimization\"", ":", "{", "}", "\n", "}", ")", "\n", "return", "hparams", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.seq2seq.seq2seq_base.Seq2seqBase._build_vocab": [[68, 72], ["texar.data.data.paired_text_data.PairedTextData.make_vocab"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.data.multi_aligned_data.MultiAlignedData.make_vocab"], ["", "def", "_build_vocab", "(", "self", ")", ":", "\n", "        ", "self", ".", "_src_vocab", ",", "self", ".", "_tgt_vocab", "=", "PairedTextData", ".", "make_vocab", "(", "\n", "self", ".", "_data_hparams", ".", "source_dataset", ",", "\n", "self", ".", "_data_hparams", ".", "target_dataset", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.seq2seq.seq2seq_base.Seq2seqBase._build_embedders": [[73, 97], ["texar.utils.utils.check_or_get_instance", "seq2seq_base.Seq2seqBase._hparams.source_embedder_hparams.todict", "texar.utils.utils.check_or_get_instance", "seq2seq_base.Seq2seqBase._hparams.source_embedder_hparams.todict", "seq2seq_base.Seq2seqBase._hparams.target_embedder_hparams.todict"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.utils.check_or_get_instance", "home.repos.pwc.inspect_result.VegB_Text_Infilling.texar.hyperparams.HParams.todict", "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.utils.check_or_get_instance", "home.repos.pwc.inspect_result.VegB_Text_Infilling.texar.hyperparams.HParams.todict", "home.repos.pwc.inspect_result.VegB_Text_Infilling.texar.hyperparams.HParams.todict"], ["", "def", "_build_embedders", "(", "self", ")", ":", "\n", "        ", "kwargs", "=", "{", "\n", "\"vocab_size\"", ":", "self", ".", "_src_vocab", ".", "size", ",", "\n", "\"hparams\"", ":", "self", ".", "_hparams", ".", "source_embedder_hparams", ".", "todict", "(", ")", "\n", "}", "\n", "self", ".", "_src_embedder", "=", "utils", ".", "check_or_get_instance", "(", "\n", "self", ".", "_hparams", ".", "source_embedder", ",", "kwargs", ",", "\n", "[", "\"texar.modules\"", ",", "\"texar.custom\"", "]", ")", "\n", "\n", "if", "self", ".", "_hparams", ".", "embedder_share", ":", "\n", "            ", "self", ".", "_tgt_embedder", "=", "self", ".", "_src_embedder", "\n", "", "else", ":", "\n", "            ", "kwargs", "=", "{", "\n", "\"vocab_size\"", ":", "self", ".", "_tgt_vocab", ".", "size", ",", "\n", "}", "\n", "if", "self", ".", "_hparams", ".", "embedder_hparams_share", ":", "\n", "                ", "kwargs", "[", "\"hparams\"", "]", "=", "self", ".", "_hparams", ".", "source_embedder_hparams", ".", "todict", "(", ")", "\n", "", "else", ":", "\n", "                ", "kwargs", "[", "\"hparams\"", "]", "=", "self", ".", "_hparams", ".", "target_embedder_hparams", ".", "todict", "(", ")", "\n", "", "self", ".", "_tgt_embedder", "=", "utils", ".", "check_or_get_instance", "(", "\n", "self", ".", "_hparams", ".", "target_embedder", ",", "kwargs", ",", "\n", "[", "\"texar.modules\"", ",", "\"texar.custom\"", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.seq2seq.seq2seq_base.Seq2seqBase._build_encoder": [[98, 105], ["texar.utils.utils.check_or_get_instance", "seq2seq_base.Seq2seqBase._hparams.encoder_hparams.todict"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.utils.check_or_get_instance", "home.repos.pwc.inspect_result.VegB_Text_Infilling.texar.hyperparams.HParams.todict"], ["", "", "def", "_build_encoder", "(", "self", ")", ":", "\n", "        ", "kwargs", "=", "{", "\n", "\"hparams\"", ":", "self", ".", "_hparams", ".", "encoder_hparams", ".", "todict", "(", ")", "\n", "}", "\n", "self", ".", "_encoder", "=", "utils", ".", "check_or_get_instance", "(", "\n", "self", ".", "_hparams", ".", "encoder", ",", "kwargs", ",", "\n", "[", "\"texar.modules\"", ",", "\"texar.custom\"", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.seq2seq.seq2seq_base.Seq2seqBase._build_decoder": [[106, 108], ["None"], "methods", ["None"], ["", "def", "_build_decoder", "(", "self", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.seq2seq.seq2seq_base.Seq2seqBase._build_connector": [[109, 117], ["texar.utils.utils.check_or_get_instance", "seq2seq_base.Seq2seqBase._hparams.connector_hparams.todict"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.utils.check_or_get_instance", "home.repos.pwc.inspect_result.VegB_Text_Infilling.texar.hyperparams.HParams.todict"], ["", "def", "_build_connector", "(", "self", ")", ":", "\n", "        ", "kwargs", "=", "{", "\n", "\"output_size\"", ":", "self", ".", "_decoder", ".", "state_size", ",", "\n", "\"hparams\"", ":", "self", ".", "_hparams", ".", "connector_hparams", ".", "todict", "(", ")", "\n", "}", "\n", "self", ".", "_connector", "=", "utils", ".", "check_or_get_instance", "(", "\n", "self", ".", "_hparams", ".", "connector", ",", "kwargs", ",", "\n", "[", "\"texar.modules\"", ",", "\"texar.custom\"", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.seq2seq.seq2seq_base.Seq2seqBase.get_loss": [[118, 125], ["texar.losses.mle_losses.sequence_sparse_softmax_cross_entropy"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.losses.mle_losses.sequence_sparse_softmax_cross_entropy"], ["", "def", "get_loss", "(", "self", ",", "decoder_results", ",", "features", ",", "labels", ")", ":", "\n", "        ", "\"\"\"Computes the training loss.\n        \"\"\"", "\n", "return", "sequence_sparse_softmax_cross_entropy", "(", "\n", "labels", "=", "labels", "[", "'target_text_ids'", "]", "[", ":", ",", "1", ":", "]", ",", "\n", "logits", "=", "decoder_results", "[", "'outputs'", "]", ".", "logits", ",", "\n", "sequence_length", "=", "decoder_results", "[", "'sequence_length'", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.seq2seq.seq2seq_base.Seq2seqBase._get_predictions": [[126, 128], ["None"], "methods", ["None"], ["", "def", "_get_predictions", "(", "self", ",", "decoder_results", ",", "features", ",", "labels", ",", "loss", "=", "None", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.seq2seq.seq2seq_base.Seq2seqBase._get_train_op": [[129, 135], ["texar.utils.variables.collect_trainable_variables", "texar.core.optimization.get_train_op"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.variables.collect_trainable_variables", "home.repos.pwc.inspect_result.VegB_Text_Infilling.core.optimization.get_train_op"], ["", "def", "_get_train_op", "(", "self", ",", "loss", ")", ":", "\n", "        ", "varlist", "=", "collect_trainable_variables", "(", "\n", "[", "self", ".", "_src_embedder", ",", "self", ".", "_tgt_embedder", ",", "self", ".", "_encoder", ",", "\n", "self", ".", "_connector", ",", "self", ".", "_decoder", "]", ")", "\n", "return", "get_train_op", "(", "\n", "loss", ",", "variables", "=", "varlist", ",", "hparams", "=", "self", ".", "_hparams", ".", "optimization", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.seq2seq.seq2seq_base.Seq2seqBase._get_eval_metric_ops": [[136, 138], ["None"], "methods", ["None"], ["", "def", "_get_eval_metric_ops", "(", "self", ",", "decoder_results", ",", "features", ",", "labels", ")", ":", "\n", "        ", "return", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.seq2seq.seq2seq_base.Seq2seqBase.embed_source": [[139, 143], ["None"], "methods", ["None"], ["", "def", "embed_source", "(", "self", ",", "features", ",", "labels", ",", "mode", ")", ":", "\n", "        ", "\"\"\"Embeds the inputs.\n        \"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.seq2seq.seq2seq_base.Seq2seqBase.embed_target": [[144, 148], ["None"], "methods", ["None"], ["", "def", "embed_target", "(", "self", ",", "features", ",", "labels", ",", "mode", ")", ":", "\n", "        ", "\"\"\"Embeds the target inputs. Used in training.\n        \"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.seq2seq.seq2seq_base.Seq2seqBase.encode": [[149, 153], ["None"], "methods", ["None"], ["", "def", "encode", "(", "self", ",", "features", ",", "labels", ",", "mode", ")", ":", "\n", "        ", "\"\"\"Encodes the inputs.\n        \"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.seq2seq.seq2seq_base.Seq2seqBase._connect": [[154, 158], ["None"], "methods", ["None"], ["", "def", "_connect", "(", "self", ",", "encoder_results", ",", "features", ",", "labels", ",", "mode", ")", ":", "\n", "        ", "\"\"\"Transforms encoder final state into decoder initial state.\n        \"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.seq2seq.seq2seq_base.Seq2seqBase.decode": [[159, 163], ["None"], "methods", ["None"], ["", "def", "decode", "(", "self", ",", "encoder_results", ",", "features", ",", "labels", ",", "mode", ")", ":", "\n", "        ", "\"\"\"Decodes.\n        \"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.seq2seq.seq2seq_base.Seq2seqBase._build": [[164, 195], ["seq2seq_base.Seq2seqBase._build_vocab", "seq2seq_base.Seq2seqBase._build_embedders", "seq2seq_base.Seq2seqBase._build_encoder", "seq2seq_base.Seq2seqBase._build_decoder", "seq2seq_base.Seq2seqBase._build_connector", "seq2seq_base.Seq2seqBase.encode", "seq2seq_base.Seq2seqBase.decode", "tensorflow.estimator.EstimatorSpec", "seq2seq_base.Seq2seqBase._get_predictions", "seq2seq_base.Seq2seqBase.get_loss", "seq2seq_base.Seq2seqBase._get_predictions", "seq2seq_base.Seq2seqBase._get_train_op", "seq2seq_base.Seq2seqBase._get_eval_metric_ops"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.seq2seq.seq2seq_base.Seq2seqBase._build_vocab", "home.repos.pwc.inspect_result.VegB_Text_Infilling.seq2seq.seq2seq_base.Seq2seqBase._build_embedders", "home.repos.pwc.inspect_result.VegB_Text_Infilling.seq2seq.seq2seq_base.Seq2seqBase._build_encoder", "home.repos.pwc.inspect_result.VegB_Text_Infilling.seq2seq.basic_seq2seq.BasicSeq2seq._build_decoder", "home.repos.pwc.inspect_result.VegB_Text_Infilling.seq2seq.seq2seq_base.Seq2seqBase._build_connector", "home.repos.pwc.inspect_result.VegB_Text_Infilling.seq2seq.basic_seq2seq.BasicSeq2seq.encode", "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.data_decoders.VarUttTextDataDecoder.decode", "home.repos.pwc.inspect_result.VegB_Text_Infilling.seq2seq.basic_seq2seq.BasicSeq2seq._get_predictions", "home.repos.pwc.inspect_result.VegB_Text_Infilling.seq2seq.seq2seq_base.Seq2seqBase.get_loss", "home.repos.pwc.inspect_result.VegB_Text_Infilling.seq2seq.basic_seq2seq.BasicSeq2seq._get_predictions", "home.repos.pwc.inspect_result.VegB_Text_Infilling.seq2seq.seq2seq_base.Seq2seqBase._get_train_op", "home.repos.pwc.inspect_result.VegB_Text_Infilling.seq2seq.seq2seq_base.Seq2seqBase._get_eval_metric_ops"], ["", "def", "_build", "(", "self", ",", "features", ",", "labels", ",", "params", ",", "mode", ",", "config", "=", "None", ")", ":", "\n", "        ", "self", ".", "_build_vocab", "(", ")", "\n", "self", ".", "_build_embedders", "(", ")", "\n", "self", ".", "_build_encoder", "(", ")", "\n", "self", ".", "_build_decoder", "(", ")", "\n", "self", ".", "_build_connector", "(", ")", "\n", "\n", "encoder_results", "=", "self", ".", "encode", "(", "features", ",", "labels", ",", "mode", ")", "\n", "decoder_results", "=", "self", ".", "decode", "(", "encoder_results", ",", "features", ",", "labels", ",", "mode", ")", "\n", "\n", "loss", ",", "train_op", ",", "preds", ",", "eval_metric_ops", "=", "None", ",", "None", ",", "None", ",", "None", "\n", "if", "mode", "==", "tf", ".", "estimator", ".", "ModeKeys", ".", "PREDICT", ":", "\n", "            ", "preds", "=", "self", ".", "_get_predictions", "(", "decoder_results", ",", "features", ",", "labels", ")", "\n", "", "else", ":", "\n", "            ", "loss", "=", "self", ".", "get_loss", "(", "decoder_results", ",", "features", ",", "labels", ")", "\n", "\n", "if", "mode", "==", "tf", ".", "estimator", ".", "ModeKeys", ".", "TRAIN", ":", "\n", "                ", "train_op", "=", "self", ".", "_get_train_op", "(", "loss", ")", "\n", "", "if", "mode", "==", "tf", ".", "estimator", ".", "ModeKeys", ".", "EVAL", ":", "\n", "                ", "eval_metric_ops", "=", "self", ".", "_get_eval_metric_ops", "(", "\n", "decoder_results", ",", "features", ",", "labels", ")", "\n", "\n", "", "preds", "=", "self", ".", "_get_predictions", "(", "decoder_results", ",", "features", ",", "labels", ",", "\n", "loss", ")", "\n", "\n", "", "return", "tf", ".", "estimator", ".", "EstimatorSpec", "(", "\n", "mode", "=", "mode", ",", "\n", "predictions", "=", "preds", ",", "\n", "loss", "=", "loss", ",", "\n", "train_op", "=", "train_op", ",", "\n", "eval_metric_ops", "=", "eval_metric_ops", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.seq2seq.seq2seq_base.Seq2seqBase.get_input_fn": [[196, 233], ["texar.data.data.paired_text_data.PairedTextData", "texar.data.data.paired_text_data.PairedTextData.dataset.make_initializable_iterator", "tensorflow.add_to_collection", "texar.data.data.paired_text_data.PairedTextData.dataset.make_initializable_iterator.get_next", "data.dataset.make_initializable_iterator.get_next.items", "key.startswith"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.data.data_iterators.FeedableDataIterator.get_next", "home.repos.pwc.inspect_result.VegB_Text_Infilling.texar.hyperparams.HParams.items"], ["", "def", "get_input_fn", "(", "self", ",", "mode", ",", "hparams", "=", "None", ")", ":", "\n", "        ", "\"\"\"Creates an input function `input_fn` that provides input data\n        for the model in an :tf_main:`Estimator <estimator/Estimator>`.\n        See, e.g., :tf_main:`tf.estimator.train_and_evaluate\n        <estimator/train_and_evaluate>`.\n\n        Args:\n            mode: One of members in\n                :tf_main:`tf.estimator.ModeKeys <estimator/ModeKeys>`.\n            hparams: A `dict` or an :class:`~texar.hparams.HParams` instance\n                containing the hyperparameters of\n                :class:`~texar.data.PairedTextData`. See\n                :meth:`~texar.data.PairedTextData.default_hparams` for the\n                the structure and default values of the hyperparameters.\n\n        Returns:\n            An input function that returns a tuple `(features, labels)`\n            when called.\n        \"\"\"", "\n", "def", "_input_fn", "(", ")", ":", "\n", "            ", "data", "=", "PairedTextData", "(", "hparams", ")", "\n", "\n", "iterator", "=", "data", ".", "dataset", ".", "make_initializable_iterator", "(", ")", "\n", "tf", ".", "add_to_collection", "(", "tf", ".", "GraphKeys", ".", "TABLE_INITIALIZERS", ",", "\n", "iterator", ".", "initializer", ")", "\n", "\n", "batch", "=", "iterator", ".", "get_next", "(", ")", "\n", "\n", "features", ",", "labels", "=", "{", "}", ",", "{", "}", "\n", "for", "key", ",", "value", "in", "batch", ".", "items", "(", ")", ":", "\n", "                ", "if", "key", ".", "startswith", "(", "'source_'", ")", ":", "\n", "                    ", "features", "[", "key", "]", "=", "value", "\n", "", "else", ":", "\n", "                    ", "labels", "[", "key", "]", "=", "value", "\n", "", "", "return", "features", ",", "labels", "\n", "\n", "", "return", "_input_fn", "\n", "", "", ""]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.seq2seq.basic_seq2seq.BasicSeq2seq.__init__": [[25, 27], ["texar.models.seq2seq.seq2seq_base.Seq2seqBase.__init__"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.text_infilling.self_attn_hyperparams.Hyperparams.__init__"], ["def", "__init__", "(", "self", ",", "data_hparams", ",", "hparams", "=", "None", ")", ":", "\n", "        ", "Seq2seqBase", ".", "__init__", "(", "self", ",", "data_hparams", ",", "hparams", "=", "hparams", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.seq2seq.basic_seq2seq.BasicSeq2seq.default_hparams": [[28, 37], ["texar.models.seq2seq.seq2seq_base.Seq2seqBase.default_hparams", "texar.models.seq2seq.seq2seq_base.Seq2seqBase.default_hparams.update"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.core.replay_memories.DequeReplayMemory.default_hparams"], ["", "@", "staticmethod", "\n", "def", "default_hparams", "(", ")", ":", "\n", "        ", "\"\"\"Returns a dictionary of hyperparameters with default values.\n        \"\"\"", "\n", "hparams", "=", "Seq2seqBase", ".", "default_hparams", "(", ")", "\n", "hparams", ".", "update", "(", "{", "\n", "\"name\"", ":", "\"basic_seq2seq\"", "\n", "}", ")", "\n", "return", "hparams", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.seq2seq.basic_seq2seq.BasicSeq2seq._build_decoder": [[38, 46], ["texar.utils.utils.check_or_get_instance", "basic_seq2seq.BasicSeq2seq._hparams.decoder_hparams.todict"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.utils.check_or_get_instance", "home.repos.pwc.inspect_result.VegB_Text_Infilling.texar.hyperparams.HParams.todict"], ["", "def", "_build_decoder", "(", "self", ")", ":", "\n", "        ", "kwargs", "=", "{", "\n", "\"vocab_size\"", ":", "self", ".", "_tgt_vocab", ".", "size", ",", "\n", "\"hparams\"", ":", "self", ".", "_hparams", ".", "decoder_hparams", ".", "todict", "(", ")", "\n", "}", "\n", "self", ".", "_decoder", "=", "utils", ".", "check_or_get_instance", "(", "\n", "self", ".", "_hparams", ".", "decoder", ",", "kwargs", ",", "\n", "[", "\"texar.modules\"", ",", "\"texar.custom\"", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.seq2seq.basic_seq2seq.BasicSeq2seq._get_predictions": [[47, 63], ["preds.update", "preds.update", "basic_seq2seq.BasicSeq2seq._tgt_vocab.map_ids_to_tokens", "preds.update", "texar.utils.utils.flatten_dict"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.data.vocabulary.Vocab.map_ids_to_tokens", "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.utils.flatten_dict"], ["", "def", "_get_predictions", "(", "self", ",", "decoder_results", ",", "features", ",", "labels", ",", "loss", "=", "None", ")", ":", "\n", "        ", "preds", "=", "{", "}", "\n", "\n", "preds", ".", "update", "(", "features", ")", "\n", "\n", "if", "labels", "is", "not", "None", ":", "\n", "            ", "preds", ".", "update", "(", "labels", ")", "\n", "\n", "", "preds", ".", "update", "(", "utils", ".", "flatten_dict", "(", "{", "'decode'", ":", "decoder_results", "}", ")", ")", "\n", "preds", "[", "'decode.outputs.sample'", "]", "=", "self", ".", "_tgt_vocab", ".", "map_ids_to_tokens", "(", "\n", "preds", "[", "'decode.outputs.sample_id'", "]", ")", "\n", "\n", "if", "loss", "is", "not", "None", ":", "\n", "            ", "preds", "[", "'loss'", "]", "=", "loss", "\n", "\n", "", "return", "preds", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.seq2seq.basic_seq2seq.BasicSeq2seq.embed_source": [[64, 68], ["basic_seq2seq.BasicSeq2seq._src_embedder"], "methods", ["None"], ["", "def", "embed_source", "(", "self", ",", "features", ",", "labels", ",", "mode", ")", ":", "\n", "        ", "\"\"\"Embeds the inputs.\n        \"\"\"", "\n", "return", "self", ".", "_src_embedder", "(", "ids", "=", "features", "[", "\"source_text_ids\"", "]", ",", "mode", "=", "mode", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.seq2seq.basic_seq2seq.BasicSeq2seq.embed_target": [[69, 73], ["basic_seq2seq.BasicSeq2seq._tgt_embedder"], "methods", ["None"], ["", "def", "embed_target", "(", "self", ",", "features", ",", "labels", ",", "mode", ")", ":", "\n", "        ", "\"\"\"Embeds the target inputs. Used in training.\n        \"\"\"", "\n", "return", "self", ".", "_tgt_embedder", "(", "ids", "=", "labels", "[", "\"target_text_ids\"", "]", ",", "mode", "=", "mode", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.seq2seq.basic_seq2seq.BasicSeq2seq.encode": [[74, 85], ["basic_seq2seq.BasicSeq2seq.embed_source", "basic_seq2seq.BasicSeq2seq._encoder"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.seq2seq.basic_seq2seq.BasicSeq2seq.embed_source"], ["", "def", "encode", "(", "self", ",", "features", ",", "labels", ",", "mode", ")", ":", "\n", "        ", "\"\"\"Encodes the inputs.\n        \"\"\"", "\n", "embedded_source", "=", "self", ".", "embed_source", "(", "features", ",", "labels", ",", "mode", ")", "\n", "\n", "outputs", ",", "final_state", "=", "self", ".", "_encoder", "(", "\n", "embedded_source", ",", "\n", "sequence_length", "=", "features", "[", "\"source_length\"", "]", ",", "\n", "mode", "=", "mode", ")", "\n", "\n", "return", "{", "'outputs'", ":", "outputs", ",", "'final_state'", ":", "final_state", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.seq2seq.basic_seq2seq.BasicSeq2seq._connect": [[86, 97], ["texar.utils.utils.call_function_with_redundant_kwargs", "texar.utils.shapes.get_batch_size"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.utils.call_function_with_redundant_kwargs", "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.shapes.get_batch_size"], ["", "def", "_connect", "(", "self", ",", "encoder_results", ",", "features", ",", "labels", ",", "mode", ")", ":", "\n", "        ", "\"\"\"Transforms encoder final state into decoder initial state.\n        \"\"\"", "\n", "enc_state", "=", "encoder_results", "[", "\"final_state\"", "]", "\n", "possible_kwargs", "=", "{", "\n", "\"inputs\"", ":", "enc_state", ",", "\n", "\"batch_size\"", ":", "get_batch_size", "(", "enc_state", ")", "\n", "}", "\n", "outputs", "=", "utils", ".", "call_function_with_redundant_kwargs", "(", "\n", "self", ".", "_connector", ".", "_build", ",", "possible_kwargs", ")", "\n", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.seq2seq.basic_seq2seq.BasicSeq2seq._decode_train": [[98, 106], ["basic_seq2seq.BasicSeq2seq._decoder", "basic_seq2seq.BasicSeq2seq.embed_target"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.seq2seq.basic_seq2seq.BasicSeq2seq.embed_target"], ["", "def", "_decode_train", "(", "self", ",", "initial_state", ",", "encoder_results", ",", "features", ",", "\n", "labels", ",", "mode", ")", ":", "\n", "        ", "return", "self", ".", "_decoder", "(", "\n", "initial_state", "=", "initial_state", ",", "\n", "decoding_strategy", "=", "self", ".", "_hparams", ".", "decoding_strategy_train", ",", "\n", "inputs", "=", "self", ".", "embed_target", "(", "features", ",", "labels", ",", "mode", ")", ",", "\n", "sequence_length", "=", "labels", "[", "'target_length'", "]", "-", "1", ",", "\n", "mode", "=", "mode", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.seq2seq.basic_seq2seq.BasicSeq2seq._decode_infer": [[107, 131], ["tensorflow.ones_like", "texar.modules.decoders.beam_search_decode.beam_search_decode", "basic_seq2seq.BasicSeq2seq._decoder"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.decoders.beam_search_decode.beam_search_decode"], ["", "def", "_decode_infer", "(", "self", ",", "initial_state", ",", "encoder_results", ",", "features", ",", "\n", "labels", ",", "mode", ")", ":", "\n", "        ", "start_token", "=", "self", ".", "_tgt_vocab", ".", "bos_token_id", "\n", "start_tokens", "=", "tf", ".", "ones_like", "(", "features", "[", "'source_length'", "]", ")", "*", "start_token", "\n", "\n", "max_l", "=", "self", ".", "_decoder", ".", "hparams", ".", "max_decoding_length_infer", "\n", "\n", "if", "self", ".", "_hparams", ".", "beam_search_width", ">", "1", ":", "\n", "            ", "return", "beam_search_decode", "(", "\n", "decoder_or_cell", "=", "self", ".", "_decoder", ",", "\n", "embedding", "=", "self", ".", "_tgt_embedder", ".", "embedding", ",", "\n", "start_tokens", "=", "start_tokens", ",", "\n", "end_token", "=", "self", ".", "_tgt_vocab", ".", "eos_token_id", ",", "\n", "beam_width", "=", "self", ".", "_hparams", ".", "beam_search_width", ",", "\n", "initial_state", "=", "initial_state", ",", "\n", "max_decoding_length", "=", "max_l", ")", "\n", "", "else", ":", "\n", "            ", "return", "self", ".", "_decoder", "(", "\n", "initial_state", "=", "initial_state", ",", "\n", "decoding_strategy", "=", "self", ".", "_hparams", ".", "decoding_strategy_infer", ",", "\n", "embedding", "=", "self", ".", "_tgt_embedder", ".", "embedding", ",", "\n", "start_tokens", "=", "start_tokens", ",", "\n", "end_token", "=", "self", ".", "_tgt_vocab", ".", "eos_token_id", ",", "\n", "mode", "=", "mode", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.seq2seq.basic_seq2seq.BasicSeq2seq.decode": [[132, 147], ["basic_seq2seq.BasicSeq2seq._connect", "basic_seq2seq.BasicSeq2seq._decode_infer", "basic_seq2seq.BasicSeq2seq._decode_train"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.seq2seq.basic_seq2seq.BasicSeq2seq._connect", "home.repos.pwc.inspect_result.VegB_Text_Infilling.seq2seq.basic_seq2seq.BasicSeq2seq._decode_infer", "home.repos.pwc.inspect_result.VegB_Text_Infilling.seq2seq.basic_seq2seq.BasicSeq2seq._decode_train"], ["", "", "def", "decode", "(", "self", ",", "encoder_results", ",", "features", ",", "labels", ",", "mode", ")", ":", "\n", "        ", "\"\"\"Decodes.\n        \"\"\"", "\n", "initial_state", "=", "self", ".", "_connect", "(", "encoder_results", ",", "features", ",", "labels", ",", "mode", ")", "\n", "\n", "if", "mode", "==", "tf", ".", "estimator", ".", "ModeKeys", ".", "PREDICT", ":", "\n", "            ", "outputs", ",", "final_state", ",", "sequence_length", "=", "self", ".", "_decode_infer", "(", "\n", "initial_state", ",", "encoder_results", ",", "features", ",", "labels", ",", "mode", ")", "\n", "", "else", ":", "\n", "            ", "outputs", ",", "final_state", ",", "sequence_length", "=", "self", ".", "_decode_train", "(", "\n", "initial_state", ",", "encoder_results", ",", "features", ",", "labels", ",", "mode", ")", "\n", "\n", "", "return", "{", "'outputs'", ":", "outputs", ",", "\n", "'final_state'", ":", "final_state", ",", "\n", "'sequence_length'", ":", "sequence_length", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.vocabulary.Vocab.__init__": [[94, 109], ["vocabulary.Vocab.load"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.data.vocabulary.Vocab.load"], ["def", "__init__", "(", "self", ",", "\n", "filename", ",", "\n", "pad_token", "=", "SpecialTokens", ".", "PAD", ",", "\n", "bos_token", "=", "SpecialTokens", ".", "BOS", ",", "\n", "eos_token", "=", "SpecialTokens", ".", "EOS", ",", "\n", "unk_token", "=", "SpecialTokens", ".", "UNK", ")", ":", "\n", "        ", "self", ".", "_filename", "=", "filename", "\n", "self", ".", "_pad_token", "=", "pad_token", "\n", "self", ".", "_bos_token", "=", "bos_token", "\n", "self", ".", "_eos_token", "=", "eos_token", "\n", "self", ".", "_unk_token", "=", "unk_token", "\n", "\n", "self", ".", "_id_to_token_map", ",", "self", ".", "_token_to_id_map", ",", "self", ".", "_id_to_token_map_py", ",", "self", ".", "_token_to_id_map_py", "=", "self", ".", "load", "(", "self", ".", "_filename", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.vocabulary.Vocab.load": [[110, 173], ["warnings.simplefilter", "warnings.simplefilter", "len", "numpy.arange", "tensorflow.contrib.lookup.HashTable", "tensorflow.contrib.lookup.HashTable", "vocabulary._make_defaultdict", "vocabulary._make_defaultdict", "tensorflow.gfile.GFile", "list", "ValueError", "ValueError", "ValueError", "ValueError", "tensorflow.contrib.lookup.KeyValueTensorInitializer", "tensorflow.contrib.lookup.KeyValueTensorInitializer", "tensorflow.compat.as_text", "line.strip"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.data.vocabulary._make_defaultdict", "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.vocabulary._make_defaultdict"], ["", "def", "load", "(", "self", ",", "filename", ")", ":", "\n", "        ", "\"\"\"Loads the vocabulary from the file.\n\n        Args:\n            filename (str): Path to the vocabulary file.\n\n        Returns:\n            A tuple of TF and python mapping tables between word string and\n            index, (:attr:`id_to_token_map`, :attr:`token_to_id_map`,\n            :attr:`id_to_token_map_py`, :attr:`token_to_id_map_py`), where\n            :attr:`id_to_token_map` and :attr:`token_to_id_map` are\n            TF :tf_main:`HashTable <contrib/lookup/HashTable>` instances,\n            and :attr:`id_to_token_map_py` and\n            :attr:`token_to_id_map_py` are python `defaultdict` instances.\n        \"\"\"", "\n", "with", "gfile", ".", "GFile", "(", "filename", ")", "as", "vocab_file", ":", "\n", "# Converts to 'unicode' (Python 2) or 'str' (Python 3)", "\n", "            ", "vocab", "=", "list", "(", "tf", ".", "compat", ".", "as_text", "(", "line", ".", "strip", "(", ")", ")", "for", "line", "in", "vocab_file", ")", "\n", "\n", "", "warnings", ".", "simplefilter", "(", "\"ignore\"", ",", "UnicodeWarning", ")", "\n", "\n", "if", "self", ".", "_bos_token", "in", "vocab", ":", "\n", "            ", "raise", "ValueError", "(", "\"Special begin-of-seq token already exists in the \"", "\n", "\"vocabulary: '%s'\"", "%", "self", ".", "_bos_token", ")", "\n", "", "if", "self", ".", "_eos_token", "in", "vocab", ":", "\n", "            ", "raise", "ValueError", "(", "\"Special end-of-seq token already exists in the \"", "\n", "\"vocabulary: '%s'\"", "%", "self", ".", "_eos_token", ")", "\n", "", "if", "self", ".", "_unk_token", "in", "vocab", ":", "\n", "            ", "raise", "ValueError", "(", "\"Special UNK token already exists in the \"", "\n", "\"vocabulary: '%s'\"", "%", "self", ".", "_unk_token", ")", "\n", "", "if", "self", ".", "_pad_token", "in", "vocab", ":", "\n", "            ", "raise", "ValueError", "(", "\"Special padding token already exists in the \"", "\n", "\"vocabulary: '%s'\"", "%", "self", ".", "_pad_token", ")", "\n", "\n", "", "warnings", ".", "simplefilter", "(", "\"default\"", ",", "UnicodeWarning", ")", "\n", "\n", "# Places _pad_token at the beginning to make sure it take index 0.", "\n", "vocab", "=", "[", "self", ".", "_pad_token", ",", "self", ".", "_bos_token", ",", "self", ".", "_eos_token", ",", "\n", "self", ".", "_unk_token", "]", "+", "vocab", "\n", "# Must make sure this is consistent with the above line", "\n", "unk_token_idx", "=", "3", "\n", "vocab_size", "=", "len", "(", "vocab", ")", "\n", "vocab_idx", "=", "np", ".", "arange", "(", "vocab_size", ")", "\n", "\n", "# Creates TF maps", "\n", "id_to_token_map", "=", "tf", ".", "contrib", ".", "lookup", ".", "HashTable", "(", "\n", "tf", ".", "contrib", ".", "lookup", ".", "KeyValueTensorInitializer", "(", "\n", "vocab_idx", ",", "vocab", ",", "key_dtype", "=", "tf", ".", "int64", ",", "value_dtype", "=", "tf", ".", "string", ")", ",", "\n", "self", ".", "_unk_token", ")", "\n", "\n", "token_to_id_map", "=", "tf", ".", "contrib", ".", "lookup", ".", "HashTable", "(", "\n", "tf", ".", "contrib", ".", "lookup", ".", "KeyValueTensorInitializer", "(", "\n", "vocab", ",", "vocab_idx", ",", "key_dtype", "=", "tf", ".", "string", ",", "value_dtype", "=", "tf", ".", "int64", ")", ",", "\n", "unk_token_idx", ")", "\n", "\n", "# Creates python maps to interface with python code", "\n", "id_to_token_map_py", "=", "_make_defaultdict", "(", "\n", "vocab_idx", ",", "vocab", ",", "self", ".", "_unk_token", ")", "\n", "token_to_id_map_py", "=", "_make_defaultdict", "(", "\n", "vocab", ",", "vocab_idx", ",", "unk_token_idx", ")", "\n", "\n", "return", "id_to_token_map", ",", "token_to_id_map", ",", "id_to_token_map_py", ",", "token_to_id_map_py", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.vocabulary.Vocab.map_ids_to_tokens": [[174, 186], ["vocabulary.Vocab.id_to_token_map.lookup", "tensorflow.to_int64"], "methods", ["None"], ["", "def", "map_ids_to_tokens", "(", "self", ",", "ids", ")", ":", "\n", "        ", "\"\"\"Maps ids into text tokens.\n\n        The returned tokens are a Tensor.\n\n        Args:\n            ids: An `int` tensor of token ids.\n\n        Returns:\n            A tensor of text tokens of the same shape.\n        \"\"\"", "\n", "return", "self", ".", "id_to_token_map", ".", "lookup", "(", "tf", ".", "to_int64", "(", "ids", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.vocabulary.Vocab.map_tokens_to_ids": [[187, 199], ["vocabulary.Vocab.token_to_id_map.lookup"], "methods", ["None"], ["", "def", "map_tokens_to_ids", "(", "self", ",", "tokens", ")", ":", "\n", "        ", "\"\"\"Maps text tokens into ids.\n\n        The returned ids are a Tensor.\n\n        Args:\n            tokens: An tensor of text tokens.\n\n        Returns:\n            A tensor of token ids of the same shape.\n        \"\"\"", "\n", "return", "self", ".", "token_to_id_map", ".", "lookup", "(", "tokens", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.vocabulary.Vocab.map_ids_to_tokens_py": [[200, 213], ["texar.utils.utils.dict_lookup"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.utils.dict_lookup"], ["", "def", "map_ids_to_tokens_py", "(", "self", ",", "ids", ")", ":", "\n", "        ", "\"\"\"Maps ids into text tokens.\n\n        The input :attr:`ids` and returned tokens are both python\n        arrays or list.\n\n        Args:\n            ids: An `int` numpy arry or (possibly nested) list of token ids.\n\n        Returns:\n            A numpy array of text tokens of the same shape as :attr:`ids`.\n        \"\"\"", "\n", "return", "dict_lookup", "(", "self", ".", "id_to_token_map_py", ",", "ids", ",", "self", ".", "unk_token", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.vocabulary.Vocab.map_tokens_to_ids_py": [[214, 227], ["texar.utils.utils.dict_lookup"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.utils.dict_lookup"], ["", "def", "map_tokens_to_ids_py", "(", "self", ",", "tokens", ")", ":", "\n", "        ", "\"\"\"Maps text tokens into ids.\n\n        The input :attr:`tokens` and returned ids are both python\n        arrays or list.\n\n        Args:\n            tokens: A numpy array or (possibly nested) list of text tokens.\n\n        Returns:\n            A numpy array of token ids of the same shape as :attr:`tokens`.\n        \"\"\"", "\n", "return", "dict_lookup", "(", "self", ".", "token_to_id_map_py", ",", "tokens", ",", "self", ".", "unk_token_id", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.vocabulary.Vocab.id_to_token_map": [[228, 234], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "id_to_token_map", "(", "self", ")", ":", "\n", "        ", "\"\"\"The :tf_main:`HashTable <contrib/lookup/HashTable>`instance that\n        maps from token index to the string form.\n        \"\"\"", "\n", "return", "self", ".", "_id_to_token_map", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.vocabulary.Vocab.token_to_id_map": [[235, 241], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "token_to_id_map", "(", "self", ")", ":", "\n", "        ", "\"\"\"The :tf_main:`HashTable <contrib/lookup/HashTable>` instance\n        that maps from token string to the index.\n        \"\"\"", "\n", "return", "self", ".", "_token_to_id_map", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.vocabulary.Vocab.id_to_token_map_py": [[242, 248], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "id_to_token_map_py", "(", "self", ")", ":", "\n", "        ", "\"\"\"The python `defaultdict` instance that maps from token index to the\n        string form.\n        \"\"\"", "\n", "return", "self", ".", "_id_to_token_map_py", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.vocabulary.Vocab.token_to_id_map_py": [[249, 255], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "token_to_id_map_py", "(", "self", ")", ":", "\n", "        ", "\"\"\"The python `defaultdict` instance that maps from token string to the\n        index.\n        \"\"\"", "\n", "return", "self", ".", "_token_to_id_map_py", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.vocabulary.Vocab.size": [[256, 261], ["len"], "methods", ["None"], ["", "@", "property", "\n", "def", "size", "(", "self", ")", ":", "\n", "        ", "\"\"\"The vocabulary size.\n        \"\"\"", "\n", "return", "len", "(", "self", ".", "token_to_id_map_py", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.vocabulary.Vocab.bos_token": [[262, 267], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "bos_token", "(", "self", ")", ":", "\n", "        ", "\"\"\"A string of the special token indicating the beginning of sequence.\n        \"\"\"", "\n", "return", "self", ".", "_bos_token", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.vocabulary.Vocab.bos_token_id": [[268, 274], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "bos_token_id", "(", "self", ")", ":", "\n", "        ", "\"\"\"The `int` index of the special token indicating the beginning\n        of sequence.\n        \"\"\"", "\n", "return", "self", ".", "token_to_id_map_py", "[", "self", ".", "_bos_token", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.vocabulary.Vocab.eos_token": [[275, 280], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "eos_token", "(", "self", ")", ":", "\n", "        ", "\"\"\"A string of the special token indicating the end of sequence.\n        \"\"\"", "\n", "return", "self", ".", "_eos_token", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.vocabulary.Vocab.eos_token_id": [[281, 287], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "eos_token_id", "(", "self", ")", ":", "\n", "        ", "\"\"\"The `int` index of the special token indicating the end\n        of sequence.\n        \"\"\"", "\n", "return", "self", ".", "token_to_id_map_py", "[", "self", ".", "_eos_token", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.vocabulary.Vocab.unk_token": [[288, 293], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "unk_token", "(", "self", ")", ":", "\n", "        ", "\"\"\"A string of the special token indicating unknown token.\n        \"\"\"", "\n", "return", "self", ".", "_unk_token", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.vocabulary.Vocab.unk_token_id": [[294, 299], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "unk_token_id", "(", "self", ")", ":", "\n", "        ", "\"\"\"The `int` index of the special token indicating unknown token.\n        \"\"\"", "\n", "return", "self", ".", "token_to_id_map_py", "[", "self", ".", "_unk_token", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.vocabulary.Vocab.pad_token": [[300, 306], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "pad_token", "(", "self", ")", ":", "\n", "        ", "\"\"\"A string of the special token indicating padding token. The\n        default padding token is an empty string.\n        \"\"\"", "\n", "return", "self", ".", "_pad_token", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.vocabulary.Vocab.pad_token_id": [[307, 312], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "pad_token_id", "(", "self", ")", ":", "\n", "        ", "\"\"\"The `int` index of the special token indicating padding token.\n        \"\"\"", "\n", "return", "self", ".", "token_to_id_map_py", "[", "self", ".", "_pad_token", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.vocabulary.Vocab.special_tokens": [[313, 321], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "special_tokens", "(", "self", ")", ":", "\n", "        ", "\"\"\"The list of special tokens\n        [:attr:`pad_token`, :attr:`bos_token`, :attr:`eos_token`,\n        :attr:`unk_token`].\n        \"\"\"", "\n", "return", "[", "self", ".", "_pad_token", ",", "self", ".", "_bos_token", ",", "self", ".", "_eos_token", ",", "\n", "self", ".", "_unk_token", "]", "\n", "", "", ""]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.vocabulary._make_defaultdict": [[52, 69], ["collections.defaultdict", "zip"], "function", ["None"], ["", "def", "_make_defaultdict", "(", "keys", ",", "values", ",", "default_value", ")", ":", "\n", "    ", "\"\"\"Creates a python defaultdict.\n\n    Args:\n        keys (list): Keys of the dictionary.\n        values (list): Values correspond to keys. The two lists :attr:`keys` and\n            :attr:`values` must be of the same length.\n        default_value: default value returned when key is missing.\n\n    Returns:\n        defaultdict: A python `defaultdict` instance that maps keys to values.\n    \"\"\"", "\n", "dict_", "=", "defaultdict", "(", "lambda", ":", "default_value", ")", "\n", "for", "k", ",", "v", "in", "zip", "(", "keys", ",", "values", ")", ":", "\n", "        ", "dict_", "[", "k", "]", "=", "v", "\n", "\n", "", "return", "dict_", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.data_utils.create_dir_if_needed": [[35, 42], ["tensorflow.gfile.IsDirectory", "tensorflow.gfile.MakeDirs"], "function", ["None"], ["def", "create_dir_if_needed", "(", "dirname", ")", ":", "\n", "    ", "\"\"\"Creates directory if doesn't exist\n    \"\"\"", "\n", "if", "not", "tf", ".", "gfile", ".", "IsDirectory", "(", "dirname", ")", ":", "\n", "        ", "tf", ".", "gfile", ".", "MakeDirs", "(", "dirname", ")", "\n", "return", "True", "\n", "", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.data_utils.maybe_download": [[43, 102], ["data_utils.create_dir_if_needed", "enumerate", "isinstance", "os.path.join", "result.append", "isinstance", "len", "len", "ValueError", "tensorflow.gfile.Exists", "data_utils._extract_google_drive_file_id", "_extract_google_drive_file_id.endswith", "data_utils._download_from_google_drive", "data_utils._download", "tensorflow.logging.info", "tarfile.is_tarfile", "url.split", "tarfile.open().extractall", "zipfile.is_zipfile", "tensorflow.logging.info", "tarfile.open", "zipfile.ZipFile", "zfile.extractall"], "function", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.data.data_utils.create_dir_if_needed", "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.data_utils._extract_google_drive_file_id", "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.data_utils._download_from_google_drive", "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.data_utils._download"], ["", "def", "maybe_download", "(", "urls", ",", "path", ",", "filenames", "=", "None", ",", "extract", "=", "False", ")", ":", "\n", "    ", "\"\"\"Downloads a set of files.\n\n    Args:\n        urls: A (list of) urls to download files.\n        path (str): The destination path to save the files.\n        filenames: A (list of) strings of the file names. If given,\n            must have the same length with :attr:`urls`. If `None`,\n            filenames are extracted from :attr:`urls`.\n        extract (bool): Whether to extract compressed files.\n\n    Returns:\n        A list of paths to the downloaded files.\n    \"\"\"", "\n", "create_dir_if_needed", "(", "path", ")", "\n", "\n", "if", "not", "isinstance", "(", "urls", ",", "(", "list", ",", "tuple", ")", ")", ":", "\n", "        ", "urls", "=", "[", "urls", "]", "\n", "", "if", "filenames", "is", "not", "None", ":", "\n", "        ", "if", "not", "isinstance", "(", "filenames", ",", "(", "list", ",", "tuple", ")", ")", ":", "\n", "            ", "filenames", "=", "[", "filenames", "]", "\n", "", "if", "len", "(", "urls", ")", "!=", "len", "(", "filenames", ")", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "'`filenames` must have the same number of elements as `urls`.'", ")", "\n", "\n", "", "", "result", "=", "[", "]", "\n", "for", "i", ",", "url", "in", "enumerate", "(", "urls", ")", ":", "\n", "        ", "if", "filenames", "is", "not", "None", ":", "\n", "            ", "filename", "=", "filenames", "[", "i", "]", "\n", "", "elif", "'drive.google.com'", "in", "url", ":", "\n", "            ", "filename", "=", "_extract_google_drive_file_id", "(", "url", ")", "\n", "", "else", ":", "\n", "            ", "filename", "=", "url", ".", "split", "(", "'/'", ")", "[", "-", "1", "]", "\n", "# If downloading from GitHub, remove suffix ?raw=True", "\n", "# from local filename", "\n", "if", "filename", ".", "endswith", "(", "\"?raw=true\"", ")", ":", "\n", "                ", "filename", "=", "filename", "[", ":", "-", "9", "]", "\n", "\n", "", "", "filepath", "=", "os", ".", "path", ".", "join", "(", "path", ",", "filename", ")", "\n", "result", ".", "append", "(", "filepath", ")", "\n", "\n", "if", "not", "tf", ".", "gfile", ".", "Exists", "(", "filepath", ")", ":", "\n", "            ", "if", "'drive.google.com'", "in", "url", ":", "\n", "                ", "filepath", "=", "_download_from_google_drive", "(", "url", ",", "filename", ",", "path", ")", "\n", "", "else", ":", "\n", "                ", "filepath", "=", "_download", "(", "url", ",", "filename", ",", "path", ")", "\n", "\n", "", "if", "extract", ":", "\n", "                ", "tf", ".", "logging", ".", "info", "(", "'Extract %s'", ",", "filepath", ")", "\n", "if", "tarfile", ".", "is_tarfile", "(", "filepath", ")", ":", "\n", "                    ", "tarfile", ".", "open", "(", "filepath", ",", "'r'", ")", ".", "extractall", "(", "path", ")", "\n", "", "elif", "zipfile", ".", "is_zipfile", "(", "filepath", ")", ":", "\n", "                    ", "with", "zipfile", ".", "ZipFile", "(", "filepath", ")", "as", "zfile", ":", "\n", "                        ", "zfile", ".", "extractall", "(", "path", ")", "\n", "", "", "else", ":", "\n", "                    ", "tf", ".", "logging", ".", "info", "(", "\"Unknown compression type. Only .tar.gz, \"", "\n", "\".tar.bz2, .tar, and .zip are supported\"", ")", "\n", "\n", "", "", "", "", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.data_utils._download": [[103, 119], ["os.path.join", "six.moves.urllib.request.urlretrieve", "print", "os.stat", "print", "sys.stdout.write", "sys.stdout.flush", "float", "float"], "function", ["None"], ["", "def", "_download", "(", "url", ",", "filename", ",", "path", ")", ":", "\n", "    ", "def", "_progress", "(", "count", ",", "block_size", ",", "total_size", ")", ":", "\n", "        ", "percent", "=", "float", "(", "count", "*", "block_size", ")", "/", "float", "(", "total_size", ")", "*", "100.", "\n", "# pylint: disable=cell-var-from-loop", "\n", "sys", ".", "stdout", ".", "write", "(", "'\\r>> Downloading %s %.1f%%'", "%", "\n", "(", "filename", ",", "percent", ")", ")", "\n", "sys", ".", "stdout", ".", "flush", "(", ")", "\n", "\n", "", "filepath", "=", "os", ".", "path", ".", "join", "(", "path", ",", "filename", ")", "\n", "filepath", ",", "_", "=", "urllib", ".", "request", ".", "urlretrieve", "(", "url", ",", "filepath", ",", "_progress", ")", "\n", "print", "(", ")", "\n", "statinfo", "=", "os", ".", "stat", "(", "filepath", ")", "\n", "print", "(", "'Successfully downloaded {} {} bytes.'", ".", "format", "(", "\n", "filename", ",", "statinfo", ".", "st_size", ")", ")", "\n", "\n", "return", "filepath", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.data_utils._extract_google_drive_file_id": [[120, 125], ["url_suffix.find", "url.find"], "function", ["None"], ["", "def", "_extract_google_drive_file_id", "(", "url", ")", ":", "\n", "# id is between `/d/` and '/'", "\n", "    ", "url_suffix", "=", "url", "[", "url", ".", "find", "(", "'/d/'", ")", "+", "3", ":", "]", "\n", "file_id", "=", "url_suffix", "[", ":", "url_suffix", ".", "find", "(", "'/'", ")", "]", "\n", "return", "file_id", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.data_utils._download_from_google_drive": [[126, 156], ["data_utils._extract_google_drive_file_id", "requests.Session", "requests.Session.get", "data_utils._download_from_google_drive._get_confirm_token"], "function", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.data.data_utils._extract_google_drive_file_id", "home.repos.pwc.inspect_result.VegB_Text_Infilling.core.replay_memories.DequeReplayMemory.get"], ["", "def", "_download_from_google_drive", "(", "url", ",", "filename", ",", "path", ")", ":", "\n", "    ", "\"\"\"Adapted from `https://github.com/saurabhshri/gdrive-downloader`\n    \"\"\"", "\n", "def", "_get_confirm_token", "(", "response", ")", ":", "\n", "        ", "for", "key", ",", "value", "in", "response", ".", "cookies", ".", "items", "(", ")", ":", "\n", "            ", "if", "key", ".", "startswith", "(", "'download_warning'", ")", ":", "\n", "                ", "return", "value", "\n", "", "", "return", "None", "\n", "\n", "", "file_id", "=", "_extract_google_drive_file_id", "(", "url", ")", "\n", "\n", "gurl", "=", "\"https://docs.google.com/uc?export=download\"", "\n", "sess", "=", "requests", ".", "Session", "(", ")", "\n", "response", "=", "sess", ".", "get", "(", "gurl", ",", "params", "=", "{", "'id'", ":", "file_id", "}", ",", "stream", "=", "True", ")", "\n", "token", "=", "_get_confirm_token", "(", "response", ")", "\n", "\n", "if", "token", ":", "\n", "        ", "params", "=", "{", "'id'", ":", "file_id", ",", "'confirm'", ":", "token", "}", "\n", "response", "=", "sess", ".", "get", "(", "gurl", ",", "params", "=", "params", ",", "stream", "=", "True", ")", "\n", "\n", "", "filepath", "=", "os", ".", "path", ".", "join", "(", "path", ",", "filename", ")", "\n", "CHUNK_SIZE", "=", "32768", "\n", "with", "tf", ".", "gfile", ".", "GFile", "(", "filepath", ",", "\"wb\"", ")", "as", "f", ":", "\n", "        ", "for", "chunk", "in", "response", ".", "iter_content", "(", "CHUNK_SIZE", ")", ":", "\n", "            ", "if", "chunk", ":", "\n", "                ", "f", ".", "write", "(", "chunk", ")", "\n", "\n", "", "", "", "print", "(", "'Successfully downloaded {}.'", ".", "format", "(", "filename", ")", ")", "\n", "\n", "return", "filepath", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.data_utils.get_files": [[157, 184], ["isinstance", "ValueError", "data_utils.get_files", "tensorflow.gfile.Glob"], "function", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.data.data_utils.get_files"], ["", "def", "get_files", "(", "file_paths", ")", ":", "\n", "    ", "\"\"\"Gets a list of file paths given possibly a pattern :attr:`file_paths`.\n\n    Adapted from `tf.contrib.slim.data.parallel_reader.get_data_files`.\n\n    Args:\n        file_paths: A (list of) path to the files. The path can be a pattern,\n            e.g., /path/to/train*, /path/to/train[12]\n\n    Returns:\n        A list of file paths.\n\n    Raises:\n        ValueError: If no files are not found\n    \"\"\"", "\n", "if", "isinstance", "(", "file_paths", ",", "(", "list", ",", "tuple", ")", ")", ":", "\n", "        ", "files", "=", "[", "]", "\n", "for", "f", "in", "file_paths", ":", "\n", "            ", "files", "+=", "get_files", "(", "f", ")", "\n", "", "", "else", ":", "\n", "        ", "if", "'*'", "in", "file_paths", "or", "'?'", "in", "file_paths", "or", "'['", "in", "file_paths", ":", "\n", "            ", "files", "=", "tf", ".", "gfile", ".", "Glob", "(", "file_paths", ")", "\n", "", "else", ":", "\n", "            ", "files", "=", "[", "file_paths", "]", "\n", "", "", "if", "not", "files", ":", "\n", "        ", "raise", "ValueError", "(", "'No data files found in %s'", "%", "(", "file_paths", ",", ")", ")", "\n", "", "return", "files", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.data_utils.read_words": [[185, 209], ["tensorflow.gfile.GFile", "f.read().split", "f.read().replace().split", "f.read().decode().split", "f.read().decode().replace().split", "f.read", "f.read().replace", "f.read().decode", "f.read().decode().replace", "f.read", "f.read", "f.read().decode", "f.read"], "function", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.data.data_decoders.VarUttTextDataDecoder.decode", "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.data_decoders.VarUttTextDataDecoder.decode"], ["", "def", "read_words", "(", "filename", ",", "newline_token", "=", "None", ")", ":", "\n", "    ", "\"\"\"Reads word from a file.\n\n    Args:\n        filename (str): Path to the file.\n        newline_token (str): The token to replace the original newline\n            token `\\n`. For example, `newline_token=tx.data.SpecialTokens.EOS`.\n            If `None`, no replacement is performed.\n\n    Returns:\n        A list of words.\n    \"\"\"", "\n", "with", "tf", ".", "gfile", ".", "GFile", "(", "filename", ",", "\"r\"", ")", "as", "f", ":", "\n", "        ", "if", "Py3", ":", "\n", "            ", "if", "newline_token", "is", "None", ":", "\n", "                ", "return", "f", ".", "read", "(", ")", ".", "split", "(", ")", "\n", "", "else", ":", "\n", "                ", "return", "f", ".", "read", "(", ")", ".", "replace", "(", "\"\\n\"", ",", "newline_token", ")", ".", "split", "(", ")", "\n", "", "", "else", ":", "\n", "            ", "if", "newline_token", "is", "None", ":", "\n", "                ", "return", "f", ".", "read", "(", ")", ".", "decode", "(", "\"utf-8\"", ")", ".", "split", "(", ")", "\n", "", "else", ":", "\n", "                ", "return", "(", "f", ".", "read", "(", ")", ".", "decode", "(", "\"utf-8\"", ")", "\n", ".", "replace", "(", "\"\\n\"", ",", "newline_token", ")", ".", "split", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.data_utils.make_vocab": [[211, 252], ["collections.Counter", "sorted", "list", "isinstance", "data_utils.read_words", "collections.Counter.items", "zip", "dict", "ValueError", "zip", "range", "len"], "function", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.data.data_utils.read_words", "home.repos.pwc.inspect_result.VegB_Text_Infilling.texar.hyperparams.HParams.items"], ["", "", "", "", "def", "make_vocab", "(", "filenames", ",", "max_vocab_size", "=", "-", "1", ",", "\n", "newline_token", "=", "None", ",", "return_type", "=", "\"list\"", ")", ":", "\n", "    ", "\"\"\"Builds vocab of the files.\n\n    Args:\n        filenames (str): A (list of) files.\n        max_vocab_size (int): Maximum size of the vocabulary. Low frequency\n            words that exceeding the limit will be discarded.\n            Set to `-1` (default) if no truncation is wanted.\n        newline_token (str): The token to replace the original newline\n            token `\\n`. For example, `newline_token=tx.data.SpecialTokens.EOS`.\n            If `None`, no replacement is performed.\n        return_type (str): Either \"list\" or \"dict\". If \"list\" (default), this\n            function returns a list of words sorted by frequency. If \"dict\",\n            this function returns a dict mapping words to their index sorted\n            by frequency.\n\n    Returns:\n        A list or dict.\n    \"\"\"", "\n", "if", "not", "isinstance", "(", "filenames", ",", "(", "list", ",", "tuple", ")", ")", ":", "\n", "        ", "filenames", "=", "[", "filenames", "]", "\n", "\n", "", "words", "=", "[", "]", "\n", "for", "fn", "in", "filenames", ":", "\n", "        ", "words", "+=", "read_words", "(", "fn", ",", "newline_token", "=", "newline_token", ")", "\n", "\n", "", "counter", "=", "collections", ".", "Counter", "(", "words", ")", "\n", "count_pairs", "=", "sorted", "(", "counter", ".", "items", "(", ")", ",", "key", "=", "lambda", "x", ":", "(", "-", "x", "[", "1", "]", ",", "x", "[", "0", "]", ")", ")", "\n", "\n", "words", ",", "_", "=", "list", "(", "zip", "(", "*", "count_pairs", ")", ")", "\n", "if", "max_vocab_size", ">=", "0", ":", "\n", "        ", "words", "=", "words", "[", ":", "max_vocab_size", "]", "\n", "\n", "", "if", "return_type", "==", "\"list\"", ":", "\n", "        ", "return", "words", "\n", "", "elif", "return_type", "==", "\"dict\"", ":", "\n", "        ", "word_to_id", "=", "dict", "(", "zip", "(", "words", ",", "range", "(", "len", "(", "words", ")", ")", ")", ")", "\n", "return", "word_to_id", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "\"Unknown return_type: {}\"", ".", "format", "(", "return_type", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.data_utils.count_file_lines": [[254, 268], ["numpy.sum", "isinstance", "open", "enumerate", "data_utils.count_file_lines._count_lines"], "function", ["None"], ["", "", "def", "count_file_lines", "(", "filenames", ")", ":", "\n", "    ", "\"\"\"Counts the number of lines in the file(s).\n    \"\"\"", "\n", "def", "_count_lines", "(", "fn", ")", ":", "\n", "        ", "with", "open", "(", "fn", ",", "\"rb\"", ")", "as", "f", ":", "\n", "            ", "i", "=", "-", "1", "\n", "for", "i", ",", "_", "in", "enumerate", "(", "f", ")", ":", "\n", "                ", "pass", "\n", "", "return", "i", "+", "1", "\n", "\n", "", "", "if", "not", "isinstance", "(", "filenames", ",", "(", "list", ",", "tuple", ")", ")", ":", "\n", "        ", "filenames", "=", "[", "filenames", "]", "\n", "", "num_lines", "=", "np", ".", "sum", "(", "[", "_count_lines", "(", "fn", ")", "for", "fn", "in", "filenames", "]", ")", "\n", "return", "num_lines", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.vocabulary_test.VocabularyTest.test_make_defaultdict": [[23, 36], ["texar.data.vocabulary._make_defaultdict", "vocabulary_test.VocabularyTest.assertEqual", "vocabulary_test.VocabularyTest.assertEqual", "vocabulary_test.VocabularyTest.assertEqual", "vocabulary_test.VocabularyTest.assertEqual", "len"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.data.vocabulary._make_defaultdict"], ["def", "test_make_defaultdict", "(", "self", ")", ":", "\n", "        ", "\"\"\"Tests the _make_defaultdict function.\n        \"\"\"", "\n", "keys", "=", "[", "'word'", ",", "'\u8bcd'", "]", "\n", "values", "=", "[", "0", ",", "1", "]", "\n", "default_value", "=", "-", "1", "\n", "\n", "dict_", "=", "vocabulary", ".", "_make_defaultdict", "(", "keys", ",", "values", ",", "default_value", ")", "\n", "\n", "self", ".", "assertEqual", "(", "len", "(", "dict_", ")", ",", "2", ")", "\n", "self", ".", "assertEqual", "(", "dict_", "[", "'word'", "]", ",", "0", ")", "\n", "self", ".", "assertEqual", "(", "dict_", "[", "'\u8bcd'", "]", ",", "1", ")", "\n", "self", ".", "assertEqual", "(", "dict_", "[", "'sth_else'", "]", ",", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.vocabulary_test.VocabularyTest.test_vocab_construction": [[37, 56], ["tempfile.NamedTemporaryFile", "tempfile.NamedTemporaryFile.write", "tempfile.NamedTemporaryFile.flush", "texar.data.vocabulary.Vocab", "vocabulary_test.VocabularyTest.assertEqual", "vocabulary_test.VocabularyTest.assertEqual", "vocabulary_test.VocabularyTest.assertEqual", "set", "set", "len", "texar.data.vocabulary.Vocab.token_to_id_map_py.keys"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.texar.hyperparams.HParams.keys"], ["", "def", "test_vocab_construction", "(", "self", ")", ":", "\n", "        ", "\"\"\"Test vocabulary construction.\n        \"\"\"", "\n", "vocab_list", "=", "[", "'word'", ",", "'\u8bcd'", "]", "\n", "vocab_file", "=", "tempfile", ".", "NamedTemporaryFile", "(", ")", "\n", "vocab_file", ".", "write", "(", "'\\n'", ".", "join", "(", "vocab_list", ")", ".", "encode", "(", "\"utf-8\"", ")", ")", "\n", "vocab_file", ".", "flush", "(", ")", "\n", "\n", "vocab", "=", "vocabulary", ".", "Vocab", "(", "vocab_file", ".", "name", ")", "\n", "\n", "self", ".", "assertEqual", "(", "vocab", ".", "size", ",", "len", "(", "vocab_list", ")", "+", "4", ")", "\n", "self", ".", "assertEqual", "(", "\n", "set", "(", "vocab", ".", "token_to_id_map_py", ".", "keys", "(", ")", ")", ",", "\n", "set", "(", "[", "'word'", ",", "'\u8bcd'", "]", "+", "vocab", ".", "special_tokens", ")", ")", "\n", "\n", "# Tests UNK token", "\n", "unk_token_id", "=", "vocab", ".", "token_to_id_map_py", "[", "'new'", "]", "\n", "unk_token_text", "=", "vocab", ".", "id_to_token_map_py", "[", "unk_token_id", "]", "\n", "self", ".", "assertEqual", "(", "unk_token_text", ",", "vocab", ".", "unk_token", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.embedding.Embedding.__init__": [[119, 146], ["texar.hyperparams.HParams", "embedding.Embedding._hparams.init_fn.kwargs.todict", "texar.utils.utils.get_function", "embedding.Embedding.default_hparams", "ValueError", "texar.utils.utils.get_function.", "texar.utils.utils.get_function", "texar.utils.utils.get_function.", "texar.utils.utils.get_function.", "len", "len"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.texar.hyperparams.HParams.todict", "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.utils.get_function", "home.repos.pwc.inspect_result.VegB_Text_Infilling.core.replay_memories.DequeReplayMemory.default_hparams", "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.utils.get_function"], ["def", "__init__", "(", "self", ",", "vocab", ",", "hparams", "=", "None", ")", ":", "\n", "        ", "self", ".", "_hparams", "=", "HParams", "(", "hparams", ",", "self", ".", "default_hparams", "(", ")", ")", "\n", "\n", "# Initialize embeddings", "\n", "init_fn_kwargs", "=", "self", ".", "_hparams", ".", "init_fn", ".", "kwargs", ".", "todict", "(", ")", "\n", "if", "\"shape\"", "in", "init_fn_kwargs", "or", "\"size\"", "in", "init_fn_kwargs", ":", "\n", "            ", "raise", "ValueError", "(", "\"Argument 'shape' or 'size' must not be \"", "\n", "\"specified. They are inferred automatically.\"", ")", "\n", "", "init_fn", "=", "utils", ".", "get_function", "(", "\n", "self", ".", "_hparams", ".", "init_fn", ".", "type", ",", "\n", "[", "\"numpy.random\"", ",", "\"numpy\"", ",", "\"texar.custom\"", "]", ")", "\n", "\n", "try", ":", "\n", "            ", "self", ".", "_word_vecs", "=", "init_fn", "(", "size", "=", "[", "len", "(", "vocab", ")", ",", "self", ".", "_hparams", ".", "dim", "]", ",", "\n", "**", "init_fn_kwargs", ")", "\n", "", "except", "TypeError", ":", "\n", "            ", "self", ".", "_word_vecs", "=", "init_fn", "(", "shape", "=", "[", "len", "(", "vocab", ")", ",", "self", ".", "_hparams", ".", "dim", "]", ",", "\n", "**", "init_fn_kwargs", ")", "\n", "\n", "# Optionally read embeddings from file", "\n", "", "if", "self", ".", "_hparams", ".", "file", "is", "not", "None", "and", "self", ".", "_hparams", ".", "file", "!=", "\"\"", ":", "\n", "            ", "read_fn", "=", "utils", ".", "get_function", "(", "\n", "self", ".", "_hparams", ".", "read_fn", ",", "\n", "[", "\"texar.data.embedding\"", ",", "\"texar.data\"", ",", "\"texar.custom\"", "]", ")", "\n", "\n", "self", ".", "_word_vecs", "=", "read_fn", "(", "self", ".", "_hparams", ".", "file", ",", "vocab", ",", "self", ".", "_word_vecs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.embedding.Embedding.default_hparams": [[147, 225], ["None"], "methods", ["None"], ["", "", "@", "staticmethod", "\n", "def", "default_hparams", "(", ")", ":", "\n", "        ", "\"\"\"Returns a dictionary of hyperparameters with default values:\n\n        .. role:: python(code)\n           :language: python\n\n        .. code-block:: python\n\n            {\n                \"file\": \"\",\n                \"dim\": 50,\n                \"read_fn\": \"load_word2vec\",\n                \"init_fn\": {\n                    \"type\": \"numpy.random.uniform\",\n                    \"kwargs\": {\n                        \"low\": -0.1,\n                        \"high\": 0.1,\n                    }\n                },\n            }\n\n        Here:\n\n        \"file\" : str\n            Path to the embedding file. If not provided, all embeddings are\n            initialized with the initialization function.\n\n        \"dim\": int\n            Dimension size of each embedding vector\n\n        \"read_fn\" : str or callable\n            Function to read the embedding file. This can be the function,\n            or its string name or full module path. E.g.,\n\n            .. code-block:: python\n\n                \"read_fn\": texar.data.load_word2vec\n                \"read_fn\": \"load_word2vec\"\n                \"read_fn\": \"texar.data.load_word2vec\"\n                \"read_fn\": \"my_module.my_read_fn\"\n\n            If function string name is used, the function must be in\n            one of the modules: :mod:`texar.data` or :mod:`texar.custom`.\n\n            The function must have the same signature as with\n            :func:`load_word2vec`.\n\n        \"init_fn\" : dict\n            Hyperparameters of the initialization function used to initialize\n            embedding of tokens missing in the embedding\n            file.\n\n            The function must accept argument named `size` or `shape` to\n            specify the output shape, and return a numpy array of the shape.\n\n            The `dict` has the following fields:\n\n                \"type\" : str or callable\n                    The initialization function. Can be either the function,\n                    or its string name or full module path.\n\n                \"kwargs\" : dict\n                    Keyword arguments for calling the function. The function\n                    is called with :python:`init_fn(size=[.., ..], **kwargs)`.\n        \"\"\"", "\n", "return", "{", "\n", "\"file\"", ":", "\"\"", ",", "\n", "\"dim\"", ":", "50", ",", "\n", "\"read_fn\"", ":", "\"load_word2vec\"", ",", "\n", "\"init_fn\"", ":", "{", "\n", "\"type\"", ":", "\"numpy.random.uniform\"", ",", "\n", "\"kwargs\"", ":", "{", "\n", "\"low\"", ":", "-", "0.1", ",", "\n", "\"high\"", ":", "0.1", ",", "\n", "}", ",", "\n", "}", ",", "\n", "\"@no_typecheck\"", ":", "[", "\"read_fn\"", ",", "\"init_fn\"", "]", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.embedding.Embedding.word_vecs": [[227, 232], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "word_vecs", "(", "self", ")", ":", "\n", "        ", "\"\"\"2D numpy array of shape `[vocab_size, embedding_dim]`.\n        \"\"\"", "\n", "return", "self", ".", "_word_vecs", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.embedding.Embedding.vector_size": [[233, 238], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "vector_size", "(", "self", ")", ":", "\n", "        ", "\"\"\"The embedding dimention size.\n        \"\"\"", "\n", "return", "self", ".", "_hparams", ".", "dim", "\n", "", "", ""]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.embedding.load_word2vec": [[36, 75], ["tensorflow.gfile.GFile", "fin.readline", "numpy.arange", "int", "ValueError", "tensorflow.compat.as_text", "fin.readline.split", "numpy.dtype", "fin.read", "numpy.fromstring", "fin.read", "chars.append", "fin.read"], "function", ["None"], ["def", "load_word2vec", "(", "filename", ",", "vocab", ",", "word_vecs", ")", ":", "\n", "    ", "\"\"\"Loads embeddings in the word2vec binary format which has a header line\n    containing the number of vectors and their dimensionality (two integers),\n    followed with number-of-vectors lines each of which is formatted as\n    '<word-string> <embedding-vector>'.\n\n    Args:\n        filename (str): Path to the embedding file.\n        vocab (dict): A dictionary that maps token strings to integer index.\n            Tokens not in :attr:`vocab` are not read.\n        word_vecs: A 2D numpy array of shape `[vocab_size, embed_dim]`\n            which is updated as reading from the file.\n\n    Returns:\n        The updated :attr:`word_vecs`.\n    \"\"\"", "\n", "with", "gfile", ".", "GFile", "(", "filename", ",", "\"rb\"", ")", "as", "fin", ":", "\n", "        ", "header", "=", "fin", ".", "readline", "(", ")", "\n", "vocab_size", ",", "vector_size", "=", "[", "int", "(", "s", ")", "for", "s", "in", "header", ".", "split", "(", ")", "]", "\n", "if", "vector_size", "!=", "word_vecs", ".", "shape", "[", "1", "]", ":", "\n", "            ", "raise", "ValueError", "(", "\"Inconsistent word vector sizes: %d vs %d\"", "%", "\n", "(", "vector_size", ",", "word_vecs", ".", "shape", "[", "1", "]", ")", ")", "\n", "", "binary_len", "=", "np", ".", "dtype", "(", "'float32'", ")", ".", "itemsize", "*", "vector_size", "\n", "for", "_", "in", "np", ".", "arange", "(", "vocab_size", ")", ":", "\n", "            ", "chars", "=", "[", "]", "\n", "while", "True", ":", "\n", "                ", "char", "=", "fin", ".", "read", "(", "1", ")", "\n", "if", "char", "==", "b' '", ":", "\n", "                    ", "break", "\n", "", "if", "char", "!=", "b'\\n'", ":", "\n", "                    ", "chars", ".", "append", "(", "char", ")", "\n", "", "", "word", "=", "b''", ".", "join", "(", "chars", ")", "\n", "word", "=", "tf", ".", "compat", ".", "as_text", "(", "word", ")", "\n", "if", "word", "in", "vocab", ":", "\n", "                ", "word_vecs", "[", "vocab", "[", "word", "]", "]", "=", "np", ".", "fromstring", "(", "\n", "fin", ".", "read", "(", "binary_len", ")", ",", "dtype", "=", "'float32'", ")", "\n", "", "else", ":", "\n", "                ", "fin", ".", "read", "(", "binary_len", ")", "\n", "", "", "", "return", "word_vecs", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.embedding.load_glove": [[76, 105], ["tensorflow.gfile.GFile", "line.strip().split", "tensorflow.compat.as_text", "numpy.array", "len", "len", "ValueError", "line.strip", "float", "len"], "function", ["None"], ["", "def", "load_glove", "(", "filename", ",", "vocab", ",", "word_vecs", ")", ":", "\n", "    ", "\"\"\"Loads embeddings in the glove text format in which each line is\n    '<word-string> <embedding-vector>'. Dimensions of the embedding vector\n    are separated with whitespace characters.\n\n    Args:\n        filename (str): Path to the embedding file.\n        vocab (dict): A dictionary that maps token strings to integer index.\n            Tokens not in :attr:`vocab` are not read.\n        word_vecs: A 2D numpy array of shape `[vocab_size, embed_dim]`\n            which is updated as reading from the file.\n\n    Returns:\n        The updated :attr:`word_vecs`.\n    \"\"\"", "\n", "with", "gfile", ".", "GFile", "(", "filename", ")", "as", "fin", ":", "\n", "        ", "for", "line", "in", "fin", ":", "\n", "            ", "vec", "=", "line", ".", "strip", "(", ")", ".", "split", "(", ")", "\n", "if", "len", "(", "vec", ")", "==", "0", ":", "\n", "                ", "continue", "\n", "", "word", ",", "vec", "=", "vec", "[", "0", "]", ",", "vec", "[", "1", ":", "]", "\n", "word", "=", "tf", ".", "compat", ".", "as_text", "(", "word", ")", "\n", "if", "word", "not", "in", "vocab", ":", "\n", "                ", "continue", "\n", "", "if", "len", "(", "vec", ")", "!=", "word_vecs", ".", "shape", "[", "1", "]", ":", "\n", "                ", "raise", "ValueError", "(", "\"Inconsistent word vector sizes: %d vs %d\"", "%", "\n", "(", "len", "(", "vec", ")", ",", "word_vecs", ".", "shape", "[", "1", "]", ")", ")", "\n", "", "word_vecs", "[", "vocab", "[", "word", "]", "]", "=", "np", ".", "array", "(", "[", "float", "(", "v", ")", "for", "v", "in", "vec", "]", ")", "\n", "", "", "return", "word_vecs", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.embedding_test.EmbeddingTest.test_load_glove": [[38, 57], ["tempfile.NamedTemporaryFile", "tempfile.NamedTemporaryFile.flush", "numpy.zeros", "texar.data.embedding.load_glove", "embedding_test.EmbeddingTest.assertEqual", "embedding_test.EmbeddingTest.assertEqual", "numpy.testing.assert_array_equal", "numpy.testing.assert_array_equal", "tempfile.NamedTemporaryFile.write", "tempfile.NamedTemporaryFile.write"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.data.embedding.load_glove"], ["def", "test_load_glove", "(", "self", ")", ":", "\n", "        ", "\"\"\"Tests the load_glove function.\n        \"\"\"", "\n", "word_vec_lines", "=", "[", "\"word 1.2 3.4 5.6\"", ",", "\"\u8bcd 1. 3. 5.\"", "]", "\n", "glove_file", "=", "tempfile", ".", "NamedTemporaryFile", "(", "mode", "=", "\"w+\"", ")", "\n", "if", "Py3", ":", "\n", "            ", "glove_file", ".", "write", "(", "'\\n'", ".", "join", "(", "word_vec_lines", ")", ")", "\n", "", "else", ":", "\n", "            ", "glove_file", ".", "write", "(", "'\\n'", ".", "join", "(", "word_vec_lines", ")", ".", "encode", "(", "\"utf-8\"", ")", ")", "\n", "", "glove_file", ".", "flush", "(", ")", "\n", "vocab", "=", "{", "\"word\"", ":", "0", ",", "\"\u8bcd\"", ":", "1", "}", "\n", "word_vecs", "=", "np", ".", "zeros", "(", "[", "2", ",", "3", "]", ")", "\n", "\n", "word_vecs", "=", "embedding", ".", "load_glove", "(", "glove_file", ".", "name", ",", "vocab", ",", "word_vecs", ")", "\n", "\n", "self", ".", "assertEqual", "(", "word_vecs", ".", "shape", "[", "0", "]", ",", "2", ")", "\n", "self", ".", "assertEqual", "(", "word_vecs", ".", "shape", "[", "1", "]", ",", "3", ")", "\n", "np", ".", "testing", ".", "assert_array_equal", "(", "word_vecs", "[", "0", "]", ",", "[", "1.2", ",", "3.4", ",", "5.6", "]", ")", "\n", "np", ".", "testing", ".", "assert_array_equal", "(", "word_vecs", "[", "1", "]", ",", "[", "1.", ",", "3.", ",", "5.", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.embedding_test.EmbeddingTest.test_load_word2vec": [[58, 79], ["numpy.array", "tempfile.NamedTemporaryFile", "tempfile.NamedTemporaryFile.write", "tempfile.NamedTemporaryFile.flush", "numpy.zeros", "texar.data.embedding.load_word2vec", "embedding_test.EmbeddingTest.assertEqual", "embedding_test.EmbeddingTest.assertEqual", "numpy.testing.assert_array_equal", "numpy.testing.assert_array_equal", "tensorflow.compat.as_bytes", "tempfile.NamedTemporaryFile.write", "tempfile.NamedTemporaryFile.write", "tensorflow.compat.as_bytes", "numpy.array.tostring"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.data.embedding.load_word2vec"], ["", "def", "test_load_word2vec", "(", "self", ")", ":", "\n", "        ", "\"\"\"Tests the load_word2vec function.\n        \"\"\"", "\n", "header", "=", "\"2 3\"", "\n", "words", "=", "[", "\"word\"", ",", "\"\u8bcd\"", "]", "\n", "vec", "=", "np", ".", "array", "(", "[", "1.2", ",", "3.4", ",", "5.6", "]", ",", "dtype", "=", "'float32'", ")", "\n", "w2v_file", "=", "tempfile", ".", "NamedTemporaryFile", "(", ")", "\n", "w2v_file", ".", "write", "(", "tf", ".", "compat", ".", "as_bytes", "(", "header", "+", "\"\\n\"", ")", ")", "\n", "for", "word", "in", "words", ":", "\n", "            ", "w2v_file", ".", "write", "(", "tf", ".", "compat", ".", "as_bytes", "(", "word", "+", "\" \"", ")", ")", "\n", "w2v_file", ".", "write", "(", "vec", ".", "tostring", "(", ")", "+", "b'\\n'", ")", "\n", "", "w2v_file", ".", "flush", "(", ")", "\n", "vocab", "=", "{", "\"word\"", ":", "0", ",", "\"\u8bcd\"", ":", "1", "}", "\n", "word_vecs", "=", "np", ".", "zeros", "(", "[", "2", ",", "3", "]", ")", "\n", "\n", "word_vecs", "=", "embedding", ".", "load_word2vec", "(", "w2v_file", ".", "name", ",", "vocab", ",", "word_vecs", ")", "\n", "\n", "self", ".", "assertEqual", "(", "word_vecs", ".", "shape", "[", "0", "]", ",", "2", ")", "\n", "self", ".", "assertEqual", "(", "word_vecs", ".", "shape", "[", "1", "]", ",", "3", ")", "\n", "np", ".", "testing", ".", "assert_array_equal", "(", "word_vecs", "[", "0", "]", ",", "vec", ")", "\n", "np", ".", "testing", ".", "assert_array_equal", "(", "word_vecs", "[", "1", "]", ",", "vec", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.embedding_test.EmbeddingTest.test_embedding": [[80, 86], ["texar.data.embedding.Embedding", "embedding_test.EmbeddingTest.assertEqual", "len", "len"], "methods", ["None"], ["", "def", "test_embedding", "(", "self", ")", ":", "\n", "        ", "\"\"\"Tests :class:`texar.data.embedding.Embedding`.\n        \"\"\"", "\n", "vocab", "=", "{", "\"word\"", ":", "0", ",", "\"\u8bcd\"", ":", "1", "}", "\n", "emb", "=", "embedding", ".", "Embedding", "(", "vocab", ")", "\n", "self", ".", "assertEqual", "(", "len", "(", "emb", ".", "word_vecs", ")", ",", "len", "(", "vocab", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.data_decoders.ScalarDataDecoder.__init__": [[43, 48], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "dtype", "=", "tf", ".", "int32", ",", "data_name", "=", "\"data\"", ")", ":", "\n", "        ", "self", ".", "_dtype", "=", "dtype", "\n", "self", ".", "_data_name", "=", "data_name", "\n", "if", "self", ".", "_data_name", "is", "None", ":", "\n", "            ", "self", ".", "_data_name", "=", "\"data\"", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.data_decoders.ScalarDataDecoder.__call__": [[49, 52], ["data_decoders.ScalarDataDecoder.decode", "dict", "data_decoders.ScalarDataDecoder.list_items", "zip", "data_decoders.ScalarDataDecoder.list_items"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.data.data_decoders.VarUttTextDataDecoder.decode", "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.multi_aligned_data.MultiAlignedData.list_items", "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.multi_aligned_data.MultiAlignedData.list_items"], ["", "", "def", "__call__", "(", "self", ",", "data", ")", ":", "\n", "        ", "outputs", "=", "self", ".", "decode", "(", "data", ",", "self", ".", "list_items", "(", ")", ")", "\n", "return", "dict", "(", "zip", "(", "self", ".", "list_items", "(", ")", ",", "outputs", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.data_decoders.ScalarDataDecoder.decode": [[53, 74], ["tensorflow.reshape", "tensorflow.string_to_number", "tensorflow.cast"], "methods", ["None"], ["", "def", "decode", "(", "self", ",", "data", ",", "items", ")", ":", "\n", "        ", "\"\"\"Decodes the data to return the tensors specified by the list of\n        items.\n\n        Args:\n            data: The scalar data to decode.\n            items: A list of strings, each of which is the name of the resulting\n                tensors to retrieve.\n\n        Returns:\n            A list of tensors, each of which corresponds to each item.\n        \"\"\"", "\n", "data", "=", "tf", ".", "reshape", "(", "data", ",", "shape", "=", "[", "]", ")", "\n", "if", "data", ".", "dtype", "is", "tf", ".", "string", ":", "\n", "            ", "decoded_data", "=", "tf", ".", "string_to_number", "(", "data", ",", "out_type", "=", "self", ".", "_dtype", ")", "\n", "", "else", ":", "\n", "            ", "decoded_data", "=", "tf", ".", "cast", "(", "data", ",", "self", ".", "_dtype", ")", ",", "\n", "", "outputs", "=", "{", "\n", "self", ".", "_data_name", ":", "decoded_data", "\n", "}", "\n", "return", "[", "outputs", "[", "item", "]", "for", "item", "in", "items", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.data_decoders.ScalarDataDecoder.list_items": [[75, 82], ["None"], "methods", ["None"], ["", "def", "list_items", "(", "self", ")", ":", "\n", "        ", "\"\"\"Returns the list of item names that the decoder can produce.\n\n        Returns:\n            A list of strings can be passed to :meth:`decode()`.\n        \"\"\"", "\n", "return", "[", "self", ".", "_data_name", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.data_decoders.ScalarDataDecoder.data_tensor_name": [[83, 88], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "data_tensor_name", "(", "self", ")", ":", "\n", "        ", "\"\"\"The name of the data tensor.\n        \"\"\"", "\n", "return", "self", ".", "_data_name", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.data_decoders.TextDataDecoder.__init__": [[122, 142], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "\n", "split_level", "=", "\"word\"", ",", "\n", "delimiter", "=", "\" \"", ",", "\n", "bos_token", "=", "None", ",", "\n", "eos_token", "=", "None", ",", "\n", "max_seq_length", "=", "None", ",", "\n", "token_to_id_map", "=", "None", ",", "\n", "text_tensor_name", "=", "\"text\"", ",", "\n", "length_tensor_name", "=", "\"length\"", ",", "\n", "text_id_tensor_name", "=", "\"text_ids\"", ")", ":", "\n", "        ", "self", ".", "_split_level", "=", "split_level", "\n", "self", ".", "_delimiter", "=", "delimiter", "\n", "self", ".", "_bos_token", "=", "bos_token", "\n", "self", ".", "_eos_token", "=", "eos_token", "\n", "self", ".", "_max_seq_length", "=", "max_seq_length", "\n", "self", ".", "_token_to_id_map", "=", "token_to_id_map", "\n", "self", ".", "_text_tensor_name", "=", "text_tensor_name", "\n", "self", ".", "_text_id_tensor_name", "=", "text_id_tensor_name", "\n", "self", ".", "_length_tensor_name", "=", "length_tensor_name", "\n", "self", ".", "_added_length", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.data_decoders.TextDataDecoder.__call__": [[143, 146], ["data_decoders.TextDataDecoder.decode", "dict", "data_decoders.TextDataDecoder.list_items", "zip", "data_decoders.TextDataDecoder.list_items"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.data.data_decoders.VarUttTextDataDecoder.decode", "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.multi_aligned_data.MultiAlignedData.list_items", "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.multi_aligned_data.MultiAlignedData.list_items"], ["", "def", "__call__", "(", "self", ",", "data", ")", ":", "\n", "        ", "outputs", "=", "self", ".", "decode", "(", "data", ",", "self", ".", "list_items", "(", ")", ")", "\n", "return", "dict", "(", "zip", "(", "self", ".", "list_items", "(", ")", ",", "outputs", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.data_decoders.TextDataDecoder.decode": [[147, 192], ["data_decoders._append_token", "data_decoders._append_token", "tensorflow.concat", "tensorflow.concat", "data_decoders.TextDataDecoder._token_to_id_map.lookup", "tensorflow.size", "tensorflow.string_split", "ValueError"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.data.data_decoders._append_token", "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.data_decoders._append_token", "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.vocabulary.Vocab.size"], ["", "def", "decode", "(", "self", ",", "data", ",", "items", ")", ":", "\n", "        ", "\"\"\"Decodes the data to return the tensors specified by the list of\n        items.\n\n        Args:\n            data: The text data to decode.\n            items: A list of strings, each of which is the name of the resulting\n                tensors to retrieve.\n\n        Returns:\n            A list of tensors, each of which corresponds to each item. If\n            `token_to_id_map` is not given when constructing the decoder,\n            returns `None` for the token index item.\n        \"\"\"", "\n", "# Split", "\n", "if", "self", ".", "_split_level", "==", "\"word\"", ":", "\n", "            ", "tokens", "=", "tf", ".", "string_split", "(", "[", "data", "]", ",", "delimiter", "=", "self", ".", "_delimiter", ")", ".", "values", "\n", "", "elif", "self", ".", "_split_level", "==", "\"char\"", ":", "\n", "            ", "raise", "NotImplementedError", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\"Unknown split level: %s\"", "%", "self", ".", "_split_level", ")", "\n", "\n", "# Truncate", "\n", "", "if", "self", ".", "_max_seq_length", "is", "not", "None", ":", "\n", "            ", "tokens", "=", "tokens", "[", ":", "self", ".", "_max_seq_length", "]", "\n", "\n", "# Add BOS/EOS tokens", "\n", "", "if", "_append_token", "(", "self", ".", "_bos_token", ")", ":", "\n", "            ", "tokens", "=", "tf", ".", "concat", "(", "[", "[", "self", ".", "_bos_token", "]", ",", "tokens", "]", ",", "axis", "=", "0", ")", "\n", "self", ".", "_added_length", "+=", "1", "\n", "", "if", "_append_token", "(", "self", ".", "_eos_token", ")", ":", "\n", "            ", "tokens", "=", "tf", ".", "concat", "(", "[", "tokens", ",", "[", "self", ".", "_eos_token", "]", "]", ",", "axis", "=", "0", ")", "\n", "self", ".", "_added_length", "+=", "1", "\n", "\n", "# Map to index", "\n", "", "token_ids", "=", "None", "\n", "if", "self", ".", "_token_to_id_map", "is", "not", "None", ":", "\n", "            ", "token_ids", "=", "self", ".", "_token_to_id_map", ".", "lookup", "(", "tokens", ")", "\n", "\n", "", "outputs", "=", "{", "\n", "self", ".", "_text_tensor_name", ":", "tokens", ",", "\n", "self", ".", "_length_tensor_name", ":", "tf", ".", "size", "(", "tokens", ")", ",", "\n", "self", ".", "_text_id_tensor_name", ":", "token_ids", "\n", "}", "\n", "return", "[", "outputs", "[", "item", "]", "for", "item", "in", "items", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.data_decoders.TextDataDecoder.list_items": [[193, 202], ["None"], "methods", ["None"], ["", "def", "list_items", "(", "self", ")", ":", "\n", "        ", "\"\"\"Returns the list of item names that the decoder can produce.\n\n        Returns:\n            A list of strings can be passed to :meth:`decode()`.\n        \"\"\"", "\n", "return", "[", "self", ".", "_text_tensor_name", ",", "\n", "self", ".", "_length_tensor_name", ",", "\n", "self", ".", "_text_id_tensor_name", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.data_decoders.TextDataDecoder.text_tensor_name": [[209, 212], ["None"], "methods", ["None"], ["", "@", "text_tensor_name", ".", "setter", "\n", "def", "text_tensor_name", "(", "self", ",", "name", ")", ":", "\n", "        ", "self", ".", "_text_tensor_name", "=", "name", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.data_decoders.TextDataDecoder.length_tensor_name": [[219, 222], ["None"], "methods", ["None"], ["", "@", "length_tensor_name", ".", "setter", "\n", "def", "length_tensor_name", "(", "self", ",", "name", ")", ":", "\n", "        ", "self", ".", "_length_tensor_name", "=", "name", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.data_decoders.TextDataDecoder.text_id_tensor_name": [[229, 232], ["None"], "methods", ["None"], ["", "@", "text_id_tensor_name", ".", "setter", "\n", "def", "text_id_tensor_name", "(", "self", ",", "name", ")", ":", "\n", "        ", "self", ".", "_text_id_tensor_name", "=", "name", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.data_decoders.TextDataDecoder.added_length": [[233, 238], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "added_length", "(", "self", ")", ":", "\n", "        ", "\"\"\"The added text length due to appended bos and eos tokens.\n        \"\"\"", "\n", "return", "self", ".", "_added_length", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.data_decoders.VarUttTextDataDecoder.__init__": [[280, 306], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "\n", "split_level", "=", "\"word\"", ",", "\n", "delimiter", "=", "\" \"", ",", "\n", "sentence_delimiter", "=", "\"|||\"", ",", "\n", "bos_token", "=", "None", ",", "\n", "eos_token", "=", "None", ",", "\n", "max_seq_length", "=", "None", ",", "\n", "max_utterance_cnt", "=", "None", ",", "\n", "token_to_id_map", "=", "None", ",", "\n", "text_tensor_name", "=", "\"text\"", ",", "\n", "length_tensor_name", "=", "\"length\"", ",", "\n", "text_id_tensor_name", "=", "\"text_ids\"", ",", "\n", "utterance_cnt_tensor_name", "=", "\"utterance_cnt\"", ")", ":", "\n", "        ", "self", ".", "_split_level", "=", "split_level", "\n", "self", ".", "_delimiter", "=", "delimiter", "\n", "self", ".", "_bos_token", "=", "bos_token", "\n", "self", ".", "_eos_token", "=", "eos_token", "\n", "self", ".", "_max_seq_length", "=", "max_seq_length", "\n", "self", ".", "_token_to_id_map", "=", "token_to_id_map", "\n", "self", ".", "_text_tensor_name", "=", "text_tensor_name", "\n", "self", ".", "_text_id_tensor_name", "=", "text_id_tensor_name", "\n", "self", ".", "_length_tensor_name", "=", "length_tensor_name", "\n", "self", ".", "_utterance_cnt_tensor_name", "=", "utterance_cnt_tensor_name", "\n", "self", ".", "_sentence_delimiter", "=", "sentence_delimiter", "\n", "self", ".", "_max_utterance_cnt", "=", "max_utterance_cnt", "\n", "self", ".", "_added_length", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.data_decoders.VarUttTextDataDecoder.__call__": [[307, 310], ["data_decoders.VarUttTextDataDecoder.decode", "dict", "data_decoders.VarUttTextDataDecoder.list_items", "zip", "data_decoders.VarUttTextDataDecoder.list_items"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.data.data_decoders.VarUttTextDataDecoder.decode", "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.multi_aligned_data.MultiAlignedData.list_items", "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.multi_aligned_data.MultiAlignedData.list_items"], ["", "def", "__call__", "(", "self", ",", "data", ")", ":", "\n", "        ", "outputs", "=", "self", ".", "decode", "(", "data", ",", "self", ".", "list_items", "(", ")", ")", "\n", "return", "dict", "(", "zip", "(", "self", ".", "list_items", "(", ")", ",", "outputs", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.data_decoders.VarUttTextDataDecoder.decode": [[311, 396], ["tensorflow.map_fn", "data_decoders._append_token", "data_decoders._append_token", "tensorflow.map_fn", "tensorflow.reshape", "tensorflow.string_split", "tensorflow.shape", "tensorflow.size", "tensorflow.reduce_max", "data_decoders._append_token", "data_decoders._append_token", "numpy.append", "data_decoders.VarUttTextDataDecoder._token_to_id_map.lookup", "tensorflow.minimum", "numpy.append", "numpy.append", "tensorflow.py_func", "tensorflow.shape", "tensorflow.string_split", "tensorflow.string_split"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.data.data_decoders._append_token", "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.data_decoders._append_token", "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.vocabulary.Vocab.size", "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.data_decoders._append_token", "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.data_decoders._append_token"], ["", "def", "decode", "(", "self", ",", "data", ",", "items", ")", ":", "# pylint: disable=too-many-locals", "\n", "        ", "\"\"\"Decodes the data to return the tensors specified by the list of\n        items.\n\n        Args:\n            data: The text data to decode.\n            items: A list of strings, each of which is the name of the resulting\n                tensors to retrieve.\n\n        Returns:\n            A list of tensors, each of which corresponds to each item. If\n            `token_to_id_map` is not given when constructing the decoder,\n            returns `None` for the token index item.\n        \"\"\"", "\n", "\n", "sentences", "=", "tf", ".", "string_split", "(", "[", "data", "]", ",", "\n", "delimiter", "=", "self", ".", "_sentence_delimiter", ")", ".", "values", "\n", "\n", "# Truncate utterances", "\n", "if", "self", ".", "_max_utterance_cnt", ":", "\n", "            ", "sentences", "=", "sentences", "[", ":", "self", ".", "_max_utterance_cnt", "]", "\n", "", "utterance_cnt", "=", "tf", ".", "shape", "(", "sentences", ")", "[", "0", "]", "\n", "\n", "# Get (max) sentence length", "\n", "def", "_get_sent_length", "(", "s", ")", ":", "\n", "            ", "raw_length", "=", "tf", ".", "size", "(", "\n", "tf", ".", "string_split", "(", "[", "s", "]", ",", "delimiter", "=", "self", ".", "_delimiter", ")", ".", "values", ")", "\n", "if", "self", ".", "_max_seq_length", ":", "\n", "                ", "return", "tf", ".", "minimum", "(", "raw_length", ",", "self", ".", "_max_seq_length", ")", "\n", "", "else", ":", "\n", "                ", "return", "raw_length", "\n", "\n", "", "", "raw_sent_length", "=", "tf", ".", "map_fn", "(", "\n", "_get_sent_length", ",", "sentences", ",", "dtype", "=", "tf", ".", "int32", ")", "\n", "sent_length", "=", "self", ".", "_max_seq_length", "\n", "if", "not", "sent_length", ":", "\n", "            ", "sent_length", "=", "tf", ".", "reduce_max", "(", "raw_sent_length", ")", "\n", "", "if", "_append_token", "(", "self", ".", "_eos_token", ")", ":", "\n", "            ", "raw_sent_length", "+=", "1", "\n", "sent_length", "+=", "1", "\n", "self", ".", "_added_length", "+=", "1", "\n", "", "if", "_append_token", "(", "self", ".", "_bos_token", ")", ":", "\n", "            ", "raw_sent_length", "+=", "1", "\n", "sent_length", "+=", "1", "\n", "self", ".", "_added_length", "+=", "1", "\n", "\n", "", "def", "_trunc_and_pad", "(", "s", ",", "pad_token", ",", "max_length", ")", ":", "\n", "            ", "if", "self", ".", "_max_seq_length", ":", "\n", "                ", "s", "=", "s", "[", ":", "self", ".", "_max_seq_length", "]", "\n", "", "if", "_append_token", "(", "self", ".", "_bos_token", ")", ":", "\n", "                ", "s", "=", "np", ".", "append", "(", "[", "self", ".", "_bos_token", "]", ",", "s", ")", "\n", "", "if", "_append_token", "(", "self", ".", "_eos_token", ")", ":", "\n", "                ", "s", "=", "np", ".", "append", "(", "s", ",", "[", "self", ".", "_eos_token", "]", ")", "\n", "", "s", "=", "np", ".", "append", "(", "s", ",", "[", "pad_token", "]", "*", "(", "max_length", "-", "s", ".", "size", ")", ")", "\n", "return", "s", "\n", "\n", "# Split each sentence to tokens, and pad them to a same length.", "\n", "# This is necessary to treat all sentences as a single tensor.", "\n", "", "split_sentences", "=", "tf", ".", "map_fn", "(", "\n", "lambda", "s", ":", "tf", ".", "py_func", "(", "\n", "_trunc_and_pad", ",", "\n", "[", "\n", "tf", ".", "string_split", "(", "[", "s", "]", ",", "delimiter", "=", "self", ".", "_delimiter", ")", ".", "values", ",", "\n", "SpecialTokens", ".", "PAD", ",", "\n", "sent_length", "\n", "]", ",", "\n", "tf", ".", "string", ")", ",", "\n", "sentences", ",", "dtype", "=", "tf", ".", "string", "\n", ")", "\n", "\n", "split_sentences", "=", "tf", ".", "reshape", "(", "split_sentences", ",", "\n", "[", "utterance_cnt", ",", "sent_length", "]", ")", "\n", "\n", "# Map to index", "\n", "token_ids", "=", "None", "\n", "if", "self", ".", "_token_to_id_map", "is", "not", "None", ":", "\n", "            ", "token_ids", "=", "self", ".", "_token_to_id_map", ".", "lookup", "(", "split_sentences", ")", "\n", "\n", "", "outputs", "=", "{", "\n", "self", ".", "_text_tensor_name", ":", "split_sentences", ",", "\n", "self", ".", "_length_tensor_name", ":", "raw_sent_length", ",", "\n", "self", ".", "_utterance_cnt_tensor_name", ":", "tf", ".", "shape", "(", "sentences", ")", "[", "0", "]", ",", "\n", "self", ".", "_text_id_tensor_name", ":", "token_ids", "\n", "}", "\n", "return", "[", "outputs", "[", "item", "]", "for", "item", "in", "items", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.data_decoders.VarUttTextDataDecoder.list_items": [[397, 408], ["None"], "methods", ["None"], ["", "def", "list_items", "(", "self", ")", ":", "\n", "        ", "\"\"\"Returns the list of item names that the decoder can produce.\n\n        Returns:\n            A list of strings can be passed to :meth:`decode()`.\n        \"\"\"", "\n", "return", "[", "\n", "self", ".", "_text_tensor_name", ",", "\n", "self", ".", "_length_tensor_name", ",", "\n", "self", ".", "_text_id_tensor_name", ",", "\n", "self", ".", "_utterance_cnt_tensor_name", "\n", "]", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.data_decoders.VarUttTextDataDecoder.text_tensor_name": [[416, 419], ["None"], "methods", ["None"], ["", "@", "text_tensor_name", ".", "setter", "\n", "def", "text_tensor_name", "(", "self", ",", "name", ")", ":", "\n", "        ", "self", ".", "_text_tensor_name", "=", "name", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.data_decoders.VarUttTextDataDecoder.utterance_cnt_tensor_name": [[420, 425], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "utterance_cnt_tensor_name", "(", "self", ")", ":", "\n", "        ", "\"\"\"The name of the utterance count tensor.\n        \"\"\"", "\n", "return", "self", ".", "_utterance_cnt_tensor_name", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.data_decoders.VarUttTextDataDecoder.length_tensor_name": [[432, 435], ["None"], "methods", ["None"], ["", "@", "length_tensor_name", ".", "setter", "\n", "def", "length_tensor_name", "(", "self", ",", "name", ")", ":", "\n", "        ", "self", ".", "_length_tensor_name", "=", "name", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.data_decoders.VarUttTextDataDecoder.text_id_tensor_name": [[442, 445], ["None"], "methods", ["None"], ["", "@", "text_id_tensor_name", ".", "setter", "\n", "def", "text_id_tensor_name", "(", "self", ",", "name", ")", ":", "\n", "        ", "self", ".", "_text_id_tensor_name", "=", "name", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.data_decoders.VarUttTextDataDecoder.added_length": [[446, 451], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "added_length", "(", "self", ")", ":", "\n", "        ", "\"\"\"The added text length due to appended bos and eos tokens.\n        \"\"\"", "\n", "return", "self", ".", "_added_length", "\n", "", "", ""]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.data_decoders._append_token": [[29, 31], ["None"], "function", ["None"], ["def", "_append_token", "(", "token", ")", ":", "\n", "    ", "return", "token", "is", "not", "None", "and", "token", "!=", "\"\"", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.data_utils_test.CountFileLinesTest.test_load_glove": [[23, 36], ["tempfile.NamedTemporaryFile", "texar.data.data_utils.count_file_lines", "data_utils_test.CountFileLinesTest.assertEqual", "tempfile.NamedTemporaryFile", "tempfile.NamedTemporaryFile.write", "tempfile.NamedTemporaryFile.flush", "texar.data.data_utils.count_file_lines", "data_utils_test.CountFileLinesTest.assertEqual"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.data.data_utils.count_file_lines", "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.data_utils.count_file_lines"], ["def", "test_load_glove", "(", "self", ")", ":", "\n", "        ", "\"\"\"Tests the load_glove function.\n        \"\"\"", "\n", "file_1", "=", "tempfile", ".", "NamedTemporaryFile", "(", "mode", "=", "\"w+\"", ")", "\n", "num_lines", "=", "data_utils", ".", "count_file_lines", "(", "file_1", ".", "name", ")", "\n", "self", ".", "assertEqual", "(", "num_lines", ",", "0", ")", "\n", "\n", "file_2", "=", "tempfile", ".", "NamedTemporaryFile", "(", "mode", "=", "\"w+\"", ")", "\n", "file_2", ".", "write", "(", "'\\n'", ".", "join", "(", "[", "'x'", "]", "*", "5", ")", ")", "\n", "file_2", ".", "flush", "(", ")", "\n", "num_lines", "=", "data_utils", ".", "count_file_lines", "(", "\n", "[", "file_1", ".", "name", ",", "file_2", ".", "name", ",", "file_2", ".", "name", "]", ")", "\n", "self", ".", "assertEqual", "(", "num_lines", ",", "0", "+", "5", "+", "5", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.scalar_data.ScalarData.__init__": [[49, 53], ["texar.data.data.data_base.DataBase.__init__", "tensorflow.name_scope", "scalar_data.ScalarData._make_data", "scalar_data.ScalarData.default_hparams"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.text_infilling.self_attn_hyperparams.Hyperparams.__init__", "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.multi_aligned_data.MultiAlignedData._make_data", "home.repos.pwc.inspect_result.VegB_Text_Infilling.core.replay_memories.DequeReplayMemory.default_hparams"], ["def", "__init__", "(", "self", ",", "hparams", ")", ":", "\n", "        ", "DataBase", ".", "__init__", "(", "self", ",", "hparams", ")", "\n", "with", "tf", ".", "name_scope", "(", "self", ".", "name", ",", "self", ".", "default_hparams", "(", ")", "[", "\"name\"", "]", ")", ":", "\n", "            ", "self", ".", "_make_data", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.scalar_data.ScalarData.default_hparams": [[54, 64], ["texar.data.data.data_base.DataBase.default_hparams", "texar.data.data.data_base.DataBase.default_hparams.update", "scalar_data._default_scalar_dataset_hparams"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.core.replay_memories.DequeReplayMemory.default_hparams", "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.scalar_data._default_scalar_dataset_hparams"], ["", "", "@", "staticmethod", "\n", "def", "default_hparams", "(", ")", ":", "\n", "        ", "\"\"\"Returns a dicitionary of default hyperparameters.\n        \"\"\"", "\n", "hparams", "=", "DataBase", ".", "default_hparams", "(", ")", "\n", "hparams", "[", "\"name\"", "]", "=", "\"scalar_data\"", "\n", "hparams", ".", "update", "(", "{", "\n", "\"dataset\"", ":", "_default_scalar_dataset_hparams", "(", ")", "\n", "}", ")", "\n", "return", "hparams", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.scalar_data.ScalarData._get_dtype": [[65, 74], ["ValueError"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_get_dtype", "(", "dtype_hparam", ")", ":", "\n", "        ", "if", "dtype_hparam", "==", "\"int\"", ":", "\n", "            ", "dtype", "=", "tf", ".", "int32", "\n", "", "elif", "dtype_hparam", "==", "\"float\"", ":", "\n", "            ", "dtype", "=", "tf", ".", "float32", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\"Unknown data type: \"", "+", "dtype_hparam", ")", "\n", "", "return", "dtype", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.scalar_data.ScalarData._make_processor": [[75, 96], ["texar.data.data_decoders.ScalarDataDecoder", "data_spec.add_spec", "texar.data.data.mono_text_data.MonoTextData._make_other_transformations", "data_spec.add_spec", "scalar_data.ScalarData._get_dtype", "texar.data.data.dataset_utils.make_chained_transformation"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.data.dataset_utils._DataSpec.add_spec", "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.mono_text_data.MonoTextData._make_other_transformations", "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.dataset_utils._DataSpec.add_spec", "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.scalar_data.ScalarData._get_dtype", "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.dataset_utils.make_chained_transformation"], ["", "@", "staticmethod", "\n", "def", "_make_processor", "(", "dataset_hparams", ",", "data_spec", ",", "chained", "=", "True", ",", "\n", "name_prefix", "=", "None", ")", ":", "\n", "# Create data decoder", "\n", "        ", "decoder", "=", "ScalarDataDecoder", "(", "\n", "ScalarData", ".", "_get_dtype", "(", "dataset_hparams", "[", "\"data_type\"", "]", ")", ",", "\n", "data_name", "=", "name_prefix", ")", "\n", "# Create other transformations", "\n", "data_spec", ".", "add_spec", "(", "decoder", "=", "decoder", ")", "\n", "# pylint: disable=protected-access", "\n", "other_trans", "=", "MonoTextData", ".", "_make_other_transformations", "(", "\n", "dataset_hparams", "[", "\"other_transformations\"", "]", ",", "data_spec", ")", "\n", "\n", "data_spec", ".", "add_spec", "(", "name_prefix", "=", "name_prefix", ")", "\n", "\n", "if", "chained", ":", "\n", "            ", "chained_tran", "=", "dsutils", ".", "make_chained_transformation", "(", "\n", "[", "decoder", "]", "+", "other_trans", ")", "\n", "return", "chained_tran", ",", "data_spec", "\n", "", "else", ":", "\n", "            ", "return", "decoder", ",", "other_trans", ",", "data_spec", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.scalar_data.ScalarData._process_dataset": [[97, 110], ["scalar_data.ScalarData._make_processor", "dataset.take.take.map", "dataset.take.take.take", "chained_tran", "texar.data.data.dataset_utils.maybe_tuple"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.data.multi_aligned_data.MultiAlignedData._make_processor", "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.dataset_utils.maybe_tuple"], ["", "", "def", "_process_dataset", "(", "self", ",", "dataset", ",", "hparams", ",", "data_spec", ")", ":", "\n", "        ", "chained_tran", ",", "data_spec", "=", "self", ".", "_make_processor", "(", "\n", "hparams", "[", "\"dataset\"", "]", ",", "data_spec", ",", "\n", "name_prefix", "=", "hparams", "[", "\"dataset\"", "]", "[", "\"data_name\"", "]", ")", "\n", "num_parallel_calls", "=", "hparams", "[", "\"num_parallel_calls\"", "]", "\n", "dataset", "=", "dataset", ".", "map", "(", "\n", "lambda", "*", "args", ":", "chained_tran", "(", "dsutils", ".", "maybe_tuple", "(", "args", ")", ")", ",", "\n", "num_parallel_calls", "=", "num_parallel_calls", ")", "\n", "\n", "# Truncates data count", "\n", "dataset", "=", "dataset", ".", "take", "(", "hparams", "[", "\"max_dataset_size\"", "]", ")", "\n", "\n", "return", "dataset", ",", "data_spec", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.scalar_data.ScalarData._make_data": [[111, 137], ["texar.data.data.mono_text_data.MonoTextData._make_mono_text_dataset", "scalar_data.ScalarData._shuffle_dataset", "texar.data.data.dataset_utils._DataSpec", "scalar_data.ScalarData._process_dataset", "scalar_data.ScalarData._make_batch", "dataset.prefetch.prefetch.prefetch"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.data.mono_text_data.MonoTextData._make_mono_text_dataset", "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.data_base.DataBase._shuffle_dataset", "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.multi_aligned_data.MultiAlignedData._process_dataset", "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.text_data_base.TextDataBase._make_batch"], ["", "def", "_make_data", "(", "self", ")", ":", "\n", "        ", "dataset_hparams", "=", "self", ".", "_hparams", ".", "dataset", "\n", "\n", "# Create and shuffle dataset", "\n", "dataset", "=", "MonoTextData", ".", "_make_mono_text_dataset", "(", "dataset_hparams", ")", "\n", "dataset", ",", "dataset_size", "=", "self", ".", "_shuffle_dataset", "(", "\n", "dataset", ",", "self", ".", "_hparams", ",", "self", ".", "_hparams", ".", "dataset", ".", "files", ")", "\n", "self", ".", "_dataset_size", "=", "dataset_size", "\n", "\n", "# Processing", "\n", "# pylint: disable=protected-access", "\n", "data_spec", "=", "dsutils", ".", "_DataSpec", "(", "dataset", "=", "dataset", ",", "\n", "dataset_size", "=", "self", ".", "_dataset_size", ")", "\n", "dataset", ",", "data_spec", "=", "self", ".", "_process_dataset", "(", "dataset", ",", "self", ".", "_hparams", ",", "\n", "data_spec", ")", "\n", "self", ".", "_data_spec", "=", "data_spec", "\n", "self", ".", "_decoder", "=", "data_spec", ".", "decoder", "# pylint: disable=no-member", "\n", "\n", "# Batching", "\n", "dataset", "=", "self", ".", "_make_batch", "(", "dataset", ",", "self", ".", "_hparams", ")", "\n", "\n", "# Prefetching", "\n", "if", "self", ".", "_hparams", ".", "prefetch_buffer_size", ">", "0", ":", "\n", "            ", "dataset", "=", "dataset", ".", "prefetch", "(", "self", ".", "_hparams", ".", "prefetch_buffer_size", ")", "\n", "\n", "", "self", ".", "_dataset", "=", "dataset", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.scalar_data.ScalarData.list_items": [[138, 145], ["list", "scalar_data.ScalarData._dataset.output_types.keys"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.texar.hyperparams.HParams.keys"], ["", "def", "list_items", "(", "self", ")", ":", "\n", "        ", "\"\"\"Returns the list of item names that the data can produce.\n\n        Returns:\n            A list of strings.\n        \"\"\"", "\n", "return", "list", "(", "self", ".", "_dataset", ".", "output_types", ".", "keys", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.scalar_data.ScalarData.dataset": [[146, 151], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "dataset", "(", "self", ")", ":", "\n", "        ", "\"\"\"The dataset.\n        \"\"\"", "\n", "return", "self", ".", "_dataset", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.scalar_data.ScalarData.dataset_size": [[152, 163], ["texar.data.data_utils.count_file_lines"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.data.data_utils.count_file_lines"], ["", "def", "dataset_size", "(", "self", ")", ":", "\n", "        ", "\"\"\"Returns the number of data instances in the dataset.\n\n        Note that this is the total data count in the raw files, before any\n        filtering and truncation.\n        \"\"\"", "\n", "if", "not", "self", ".", "_dataset_size", ":", "\n", "# pylint: disable=attribute-defined-outside-init", "\n", "            ", "self", ".", "_dataset_size", "=", "count_file_lines", "(", "\n", "self", ".", "_hparams", ".", "dataset", ".", "files", ")", "\n", "", "return", "self", ".", "_dataset_size", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.scalar_data.ScalarData.data_name": [[164, 169], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "data_name", "(", "self", ")", ":", "\n", "        ", "\"\"\"The name of the data tensor.\n        \"\"\"", "\n", "return", "self", ".", "_decoder", ".", "data_tensor_name", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.scalar_data._default_scalar_dataset_hparams": [[27, 38], ["None"], "function", ["None"], ["def", "_default_scalar_dataset_hparams", "(", ")", ":", "\n", "    ", "\"\"\"Returns hyperparameters of a scalar dataset with default values.\n    \"\"\"", "\n", "# TODO(zhiting): add more docs", "\n", "return", "{", "\n", "\"files\"", ":", "[", "]", ",", "\n", "\"compression_type\"", ":", "None", ",", "\n", "\"data_type\"", ":", "\"int\"", ",", "\n", "\"data_name\"", ":", "None", ",", "\n", "\"other_transformations\"", ":", "[", "]", ",", "\n", "\"@no_typecheck\"", ":", "[", "\"files\"", "]", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.dataset_utils._DataSpec.__init__": [[43, 51], ["dataset_utils._DataSpec.__dict__.update"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "dataset", "=", "None", ",", "dataset_size", "=", "None", ",", "decoder", "=", "None", ",", "\n", "vocab", "=", "None", ",", "embedding", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "        ", "kwargs", "[", "'dataset'", "]", "=", "dataset", "\n", "kwargs", "[", "'dataset_size'", "]", "=", "dataset_size", "\n", "kwargs", "[", "'decoder'", "]", "=", "decoder", "\n", "kwargs", "[", "'vocab'", "]", "=", "vocab", "\n", "kwargs", "[", "'embedding'", "]", "=", "embedding", "\n", "self", ".", "__dict__", ".", "update", "(", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.dataset_utils._DataSpec.add_spec": [[52, 56], ["dataset_utils._DataSpec.__dict__.update"], "methods", ["None"], ["", "def", "add_spec", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"Adds new field(s).\n        \"\"\"", "\n", "self", ".", "__dict__", ".", "update", "(", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.dataset_utils._DataSpec.get_ith_data_spec": [[57, 65], ["six.iteritems", "dataset_utils._DataSpec", "isinstance"], "methods", ["None"], ["", "def", "get_ith_data_spec", "(", "self", ",", "i", ")", ":", "\n", "        ", "\"\"\"Returns an instance of :class:`_DataSpec` that contains the\n        `i`-th specifications.\n        \"\"\"", "\n", "kwargs", "=", "{", "}", "\n", "for", "k", ",", "v", "in", "six", ".", "iteritems", "(", "self", ".", "__dict__", ")", ":", "\n", "            ", "kwargs", "[", "k", "]", "=", "v", "[", "i", "]", "if", "isinstance", "(", "v", ",", "(", "tuple", ",", "list", ")", ")", "else", "v", "\n", "", "return", "_DataSpec", "(", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.dataset_utils._DataSpec.set_ith_data_spec": [[66, 83], ["six.iteritems", "isinstance"], "methods", ["None"], ["", "def", "set_ith_data_spec", "(", "self", ",", "i", ",", "data_spec", ",", "total_count", ")", ":", "\n", "        ", "\"\"\"Sets the `i`-th specification to respective values in\n        :attr:`data_spec`.\n        \"\"\"", "\n", "for", "k", ",", "v", "in", "six", ".", "iteritems", "(", "data_spec", ".", "__dict__", ")", ":", "\n", "            ", "if", "k", "in", "self", ".", "__dict__", ":", "\n", "                ", "v_", "=", "self", ".", "__dict__", "[", "k", "]", "\n", "if", "isinstance", "(", "v_", ",", "(", "tuple", ",", "list", ")", ")", ":", "\n", "                    ", "v_", "[", "i", "]", "=", "v", "\n", "", "else", ":", "\n", "                    ", "new_v_", "=", "[", "v_", "]", "*", "total_count", "\n", "new_v_", "[", "i", "]", "=", "v", "\n", "self", ".", "__dict__", "[", "k", "]", "=", "new_v_", "\n", "", "", "else", ":", "\n", "                ", "v_", "=", "[", "None", "]", "*", "total_count", "\n", "v_", "[", "i", "]", "=", "v", "\n", "self", ".", "__dict__", "[", "k", "]", "=", "v_", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.dataset_utils._make_length_filter_fn": [[84, 91], ["None"], "function", ["None"], ["", "", "", "", "def", "_make_length_filter_fn", "(", "length_name", ",", "max_length", ")", ":", "\n", "    ", "\"\"\"Returns a predicate function which takes in data sample\n    and returns a bool indicating whether to filter by length.\n    \"\"\"", "\n", "def", "_filter_fn", "(", "data", ")", ":", "\n", "        ", "return", "data", "[", "length_name", "]", "<=", "max_length", "\n", "", "return", "_filter_fn", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.dataset_utils._make_smaller_batch_filter_fn": [[92, 105], ["isinstance", "dataset_utils._make_length_filter_fn._filter_fn"], "function", ["None"], ["", "def", "_make_smaller_batch_filter_fn", "(", "batch_size", ")", ":", "\n", "    ", "\"\"\"Returns a predicate function which takes in a batched data\n    and returns a bool indicating whether the batch is of :attr:`batch_size`.\n    \"\"\"", "\n", "def", "_filter_fn", "(", "data", ")", ":", "\n", "        ", "if", "isinstance", "(", "data", ",", "(", "list", ",", "tuple", ")", ")", ":", "\n", "            ", "return", "_filter_fn", "(", "data", "[", "0", "]", ")", "\n", "", "elif", "isinstance", "(", "data", ",", "dict", ")", ":", "\n", "            ", "return", "_filter_fn", "(", "data", "[", "next", "(", "iter", "(", "data", ")", ")", "]", ")", "\n", "", "else", ":", "\n", "            ", "return", "tf", ".", "equal", "(", "tf", ".", "shape", "(", "data", ")", "[", "0", "]", ",", "batch_size", ")", "\n", "\n", "", "", "return", "_filter_fn", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.dataset_utils._make_combined_filter_fn": [[106, 132], ["any", "tensorflow.reduce_all", "outputs.append", "tensorflow.reduce_any", "ValueError", "fn"], "function", ["None"], ["", "def", "_make_combined_filter_fn", "(", "filter_fns", ",", "mode", "=", "\"and\"", ")", ":", "\n", "    ", "\"\"\"Returns a new predicate function that combines multiple\n    predicate functions with certain mode.\n\n    Returns `None` if all elements in :attr:`filter_fns` are `None`.\n\n    Args:\n        filter_fns (list): Filter functions to combine. `None` functions are\n            ignored.\n        mode (str): A mode from `{\"and\", \"or\"}`.\n    \"\"\"", "\n", "if", "not", "any", "(", "filter_fns", ")", ":", "\n", "        ", "return", "None", "\n", "\n", "", "def", "_combined_fn", "(", "data", ")", ":", "\n", "        ", "outputs", "=", "[", "]", "\n", "for", "fn", "in", "filter_fns", ":", "\n", "            ", "if", "fn", ":", "\n", "                ", "outputs", ".", "append", "(", "fn", "(", "data", ")", ")", "\n", "", "", "if", "mode", "==", "\"and\"", ":", "\n", "            ", "return", "tf", ".", "reduce_all", "(", "outputs", ")", "\n", "", "elif", "mode", "==", "\"or\"", ":", "\n", "            ", "return", "tf", ".", "reduce_any", "(", "outputs", ")", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\"Unknown mode: {}\"", ".", "format", "(", "mode", ")", ")", "\n", "", "", "return", "_combined_fn", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.dataset_utils._connect_name": [[133, 139], ["None"], "function", ["None"], ["", "def", "_connect_name", "(", "lhs_name", ",", "rhs_name", ")", ":", "\n", "    ", "if", "not", "lhs_name", ":", "\n", "        ", "return", "rhs_name", "\n", "", "if", "not", "rhs_name", ":", "\n", "        ", "return", "lhs_name", "\n", "", "return", "\"{}_{}\"", ".", "format", "(", "lhs_name", ",", "rhs_name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.dataset_utils.maybe_tuple": [[140, 148], ["tuple", "len"], "function", ["None"], ["", "def", "maybe_tuple", "(", "data", ")", ":", "\n", "    ", "\"\"\"Returns `tuple(data)` if :attr:`data` contains more than 1 elements.\n\n    Used to wrap `map_func` inputs.\n    \"\"\"", "\n", "data", "=", "tuple", "(", "data", ")", "\n", "data", "=", "data", "if", "len", "(", "data", ")", ">", "1", "else", "data", "[", "0", "]", "\n", "return", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.dataset_utils.make_partial": [[149, 156], ["fn"], "function", ["None"], ["", "def", "make_partial", "(", "fn", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Returns a new function with single argument by freezing other arguments\n    of :attr:`fn`.\n    \"\"\"", "\n", "def", "_new_fn", "(", "data", ")", ":", "\n", "        ", "return", "fn", "(", "data", ",", "*", "args", ",", "**", "kwargs", ")", "\n", "", "return", "_new_fn", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.dataset_utils.name_prefix_fn": [[157, 168], ["six.iteritems", "dataset_utils._connect_name"], "function", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.data.dataset_utils._connect_name"], ["", "def", "name_prefix_fn", "(", "name_prefix", ")", ":", "\n", "    ", "\"\"\"Returns a function that append a prefix to field names.\n    \"\"\"", "\n", "def", "_prefix_fn", "(", "data", ")", ":", "\n", "        ", "transformed_data", "=", "{", "}", "\n", "for", "name", ",", "value", "in", "six", ".", "iteritems", "(", "data", ")", ":", "\n", "            ", "new_name", "=", "_connect_name", "(", "name_prefix", ",", "name", ")", "\n", "transformed_data", "[", "new_name", "]", "=", "value", "\n", "", "return", "transformed_data", "\n", "\n", "", "return", "_prefix_fn", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.dataset_utils.make_chained_transformation": [[169, 189], ["tran_fns_i"], "function", ["None"], ["", "def", "make_chained_transformation", "(", "tran_fns", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Returns a dataset transformation function that applies a list of\n    transformations sequentially.\n\n    Args:\n        tran_fns (list): A list of dataset transformation.\n        *args: Extra arguments for each of the transformation function.\n        **kwargs: Extra keyword arguments for each of the transformation\n            function.\n\n    Returns:\n        A transformation function to be used in\n        :tf_main:`tf.data.Dataset.map <data/Dataset#map>`.\n    \"\"\"", "\n", "def", "_chained_fn", "(", "data", ")", ":", "\n", "        ", "for", "tran_fns_i", "in", "tran_fns", ":", "\n", "            ", "data", "=", "tran_fns_i", "(", "data", ",", "*", "args", ",", "**", "kwargs", ")", "\n", "", "return", "data", "\n", "\n", "", "return", "_chained_fn", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.dataset_utils.make_combined_transformation": [[190, 237], ["ValueError", "enumerate", "len", "len", "six.iteritems", "isinstance", "tran_fns_ij", "dataset_utils._connect_name", "ValueError"], "function", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.data.dataset_utils._connect_name"], ["", "def", "make_combined_transformation", "(", "tran_fns", ",", "name_prefix", "=", "None", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Returns a dataset transformation function that applies\n    transformations to each component of the data.\n\n    The data to be transformed must be a tuple of the same length\n    of :attr:`tran_fns`.\n\n    Args:\n        tran_fns (list): A list of elements where each element is a\n            transformation function or a list of transformation functions.\n        name_prefix (list, optional): Prefix to the field names of each\n            component of the data, to prevent fields with the same name\n            in different components from overriding each other. If not `None`,\n            must be of the same length of :attr:`tran_fns`.\n        *args: Extra arguments for each of the transformation function.\n        **kwargs: Extra keyword arguments for each of the transformation\n            function.\n\n    Returns:\n        A transformation function to be used in\n        :tf_main:`tf.data.Dataset.map <data/Dataset#map>`.\n    \"\"\"", "\n", "if", "name_prefix", "and", "len", "(", "name_prefix", ")", "!=", "len", "(", "tran_fns", ")", ":", "\n", "        ", "raise", "ValueError", "(", "\"`name_prefix`, if provided, must be of the same \"", "\n", "\"length of `tran_fns`.\"", ")", "\n", "\n", "", "def", "_combined_fn", "(", "data", ")", ":", "\n", "        ", "transformed_data", "=", "{", "}", "\n", "for", "i", ",", "tran_fns_i", "in", "enumerate", "(", "tran_fns", ")", ":", "\n", "            ", "data_i", "=", "data", "[", "i", "]", "\n", "# Process data_i", "\n", "if", "not", "isinstance", "(", "tran_fns_i", ",", "(", "list", ",", "tuple", ")", ")", ":", "\n", "                ", "tran_fns_i", "=", "[", "tran_fns_i", "]", "\n", "", "for", "tran_fns_ij", "in", "tran_fns_i", ":", "\n", "                ", "data_i", "=", "tran_fns_ij", "(", "data_i", ",", "*", "args", ",", "**", "kwargs", ")", "\n", "# Add to dict by appending name prefix", "\n", "", "for", "name", ",", "value", "in", "six", ".", "iteritems", "(", "data_i", ")", ":", "\n", "                ", "new_name", "=", "name", "\n", "if", "name_prefix", ":", "\n", "                    ", "new_name", "=", "_connect_name", "(", "name_prefix", "[", "i", "]", ",", "name", ")", "\n", "", "if", "new_name", "in", "transformed_data", ":", "\n", "                    ", "raise", "ValueError", "(", "\n", "\"Field name already exists: {}\"", ".", "format", "(", "new_name", ")", ")", "\n", "", "transformed_data", "[", "new_name", "]", "=", "value", "\n", "", "", "return", "transformed_data", "\n", "\n", "", "return", "_combined_fn", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.dataset_utils.random_shard_dataset": [[238, 254], ["texar.utils.utils.ceildiv", "numpy.linspace", "tensorflow.data.Dataset.from_tensor_slices().shuffle().flat_map", "tensorflow.data.Dataset.from_tensor_slices().shuffle", "dataset.skip().take", "tensorflow.data.Dataset.from_tensor_slices", "dataset.skip"], "function", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.utils.ceildiv"], ["", "def", "random_shard_dataset", "(", "dataset_size", ",", "shard_size", ",", "seed", "=", "None", ")", ":", "\n", "    ", "\"\"\"Returns a dataset transformation function that randomly shards a\n    dataset.\n    \"\"\"", "\n", "num_shards", "=", "utils", ".", "ceildiv", "(", "dataset_size", ",", "shard_size", ")", "\n", "boundaries", "=", "np", ".", "linspace", "(", "0", ",", "dataset_size", ",", "num", "=", "num_shards", ",", "endpoint", "=", "False", ",", "\n", "dtype", "=", "np", ".", "int64", ")", "#pylint: disable=no-member", "\n", "\n", "def", "_shard_fn", "(", "dataset", ")", ":", "\n", "        ", "sharded_dataset", "=", "(", "\n", "tf", ".", "data", ".", "Dataset", ".", "from_tensor_slices", "(", "boundaries", ")", "\n", ".", "shuffle", "(", "num_shards", ",", "seed", "=", "seed", ")", "\n", ".", "flat_map", "(", "lambda", "lb", ":", "dataset", ".", "skip", "(", "lb", ")", ".", "take", "(", "shard_size", ")", ")", ")", "\n", "return", "sharded_dataset", "\n", "\n", "", "return", "_shard_fn", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.multi_aligned_data_test.MultiAlignedDataTest.setUp": [[26, 91], ["tensorflow.test.TestCase.setUp", "tempfile.NamedTemporaryFile", "tempfile.NamedTemporaryFile.write", "tempfile.NamedTemporaryFile.flush", "len", "tempfile.NamedTemporaryFile", "tempfile.NamedTemporaryFile.write", "tempfile.NamedTemporaryFile.flush", "tempfile.NamedTemporaryFile", "tempfile.NamedTemporaryFile.write", "tempfile.NamedTemporaryFile.flush", "tempfile.NamedTemporaryFile", "tempfile.NamedTemporaryFile.write", "tempfile.NamedTemporaryFile.flush", "tempfile.NamedTemporaryFile", "tempfile.NamedTemporaryFile.write", "tempfile.NamedTemporaryFile.flush", "str"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.losses.mle_losses_test.MLELossesTest.setUp"], ["def", "setUp", "(", "self", ")", ":", "\n", "        ", "tf", ".", "test", ".", "TestCase", ".", "setUp", "(", "self", ")", "\n", "\n", "# Create test data", "\n", "vocab_list", "=", "[", "'This'", ",", "'is'", ",", "'a'", ",", "'word'", ",", "'\u8bcd'", "]", "\n", "vocab_file", "=", "tempfile", ".", "NamedTemporaryFile", "(", ")", "\n", "vocab_file", ".", "write", "(", "'\\n'", ".", "join", "(", "vocab_list", ")", ".", "encode", "(", "\"utf-8\"", ")", ")", "\n", "vocab_file", ".", "flush", "(", ")", "\n", "self", ".", "_vocab_file", "=", "vocab_file", "\n", "self", ".", "_vocab_size", "=", "len", "(", "vocab_list", ")", "\n", "\n", "text_0", "=", "[", "'This is a sentence from source .'", ",", "'\u8bcd \u8bcd \u3002 source'", "]", "\n", "text_0_file", "=", "tempfile", ".", "NamedTemporaryFile", "(", ")", "\n", "text_0_file", ".", "write", "(", "'\\n'", ".", "join", "(", "text_0", ")", ".", "encode", "(", "\"utf-8\"", ")", ")", "\n", "text_0_file", ".", "flush", "(", ")", "\n", "self", ".", "_text_0_file", "=", "text_0_file", "\n", "\n", "text_1", "=", "[", "'This is a sentence from target .'", ",", "'\u8bcd \u8bcd \u3002 target'", "]", "\n", "text_1_file", "=", "tempfile", ".", "NamedTemporaryFile", "(", ")", "\n", "text_1_file", ".", "write", "(", "'\\n'", ".", "join", "(", "text_1", ")", ".", "encode", "(", "\"utf-8\"", ")", ")", "\n", "text_1_file", ".", "flush", "(", ")", "\n", "self", ".", "_text_1_file", "=", "text_1_file", "\n", "\n", "text_2", "=", "[", "\n", "'This is a sentence from dialog . ||| dialog '", ",", "\n", "'\u8bcd \u8bcd \u3002 ||| \u8bcd dialog'", "]", "\n", "text_2_file", "=", "tempfile", ".", "NamedTemporaryFile", "(", ")", "\n", "text_2_file", ".", "write", "(", "'\\n'", ".", "join", "(", "text_2", ")", ".", "encode", "(", "\"utf-8\"", ")", ")", "\n", "text_2_file", ".", "flush", "(", ")", "\n", "self", ".", "_text_2_file", "=", "text_2_file", "\n", "\n", "int_3", "=", "[", "0", ",", "1", "]", "\n", "int_3_file", "=", "tempfile", ".", "NamedTemporaryFile", "(", ")", "\n", "int_3_file", ".", "write", "(", "'\\n'", ".", "join", "(", "[", "str", "(", "_", ")", "for", "_", "in", "int_3", "]", ")", ")", "\n", "int_3_file", ".", "flush", "(", ")", "\n", "self", ".", "_int_3_file", "=", "int_3_file", "\n", "\n", "# Construct database", "\n", "self", ".", "_hparams", "=", "{", "\n", "\"num_epochs\"", ":", "123", ",", "\n", "\"batch_size\"", ":", "23", ",", "\n", "\"datasets\"", ":", "[", "\n", "{", "# dataset 0", "\n", "\"files\"", ":", "[", "self", ".", "_text_0_file", ".", "name", "]", ",", "\n", "\"vocab_file\"", ":", "self", ".", "_vocab_file", ".", "name", ",", "\n", "\"bos_token\"", ":", "\"\"", ",", "\n", "\"data_name\"", ":", "\"0\"", "\n", "}", ",", "\n", "{", "# dataset 1", "\n", "\"files\"", ":", "[", "self", ".", "_text_1_file", ".", "name", "]", ",", "\n", "\"vocab_share_with\"", ":", "0", ",", "\n", "\"eos_token\"", ":", "\"<TARGET_EOS>\"", ",", "\n", "\"data_name\"", ":", "\"1\"", "\n", "}", ",", "\n", "{", "# dataset 2", "\n", "\"files\"", ":", "[", "self", ".", "_text_2_file", ".", "name", "]", ",", "\n", "\"vocab_file\"", ":", "self", ".", "_vocab_file", ".", "name", ",", "\n", "\"processing_share_with\"", ":", "0", ",", "\n", "\"variable_utterance\"", ":", "True", ",", "\n", "\"data_name\"", ":", "\"2\"", "\n", "}", ",", "\n", "{", "# dataset 3", "\n", "\"files\"", ":", "self", ".", "_int_3_file", ".", "name", ",", "\n", "\"data_type\"", ":", "\"int\"", ",", "\n", "\"data_name\"", ":", "\"label\"", "\n", "}", ",", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.multi_aligned_data_test.MultiAlignedDataTest._run_and_test": [[95, 158], ["texar.data.MultiAlignedData", "multi_aligned_data_test.MultiAlignedDataTest.assertEqual", "texar.data.MultiAlignedData.dataset.make_initializable_iterator", "tx.data.MultiAlignedData.dataset.make_initializable_iterator.get_next", "multi_aligned_data_test.MultiAlignedDataTest.test_session", "sess.run", "sess.run", "sess.run", "sess.run", "texar.data.MultiAlignedData.vocab", "len", "tensorflow.global_variables_initializer", "tensorflow.local_variables_initializer", "tensorflow.tables_initializer", "sess.run", "multi_aligned_data_test.MultiAlignedDataTest.assertEqual", "multi_aligned_data_test.MultiAlignedDataTest.assertEqual", "zip", "enumerate", "texar.data.MultiAlignedData.vocab", "set", "set", "texar.data.MultiAlignedData.utterance_cnt_name", "numpy.testing.assert_array_equal", "numpy.testing.assert_array_equal", "t0[].startswith", "range", "print", "sess.run.keys", "texar.data.MultiAlignedData.list_items", "multi_aligned_data_test.MultiAlignedDataTest.assertEqual", "multi_aligned_data_test.MultiAlignedDataTest.assertEqual", "multi_aligned_data_test.MultiAlignedDataTest.assertLessEqual", "texar.data.MultiAlignedData.length_name", "multi_aligned_data_test.MultiAlignedDataTest.assertLessEqual", "multi_aligned_data_test.MultiAlignedDataTest.assertLessEqual", "texar.data.MultiAlignedData.length_name", "texar.data.MultiAlignedData.length_name"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.data.data_iterators.FeedableDataIterator.get_next", "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.multi_aligned_data.MultiAlignedData.vocab", "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.multi_aligned_data.MultiAlignedData.vocab", "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.multi_aligned_data.MultiAlignedData.utterance_cnt_name", "home.repos.pwc.inspect_result.VegB_Text_Infilling.texar.hyperparams.HParams.keys", "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.multi_aligned_data.MultiAlignedData.list_items", "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.multi_aligned_data.MultiAlignedData.length_name", "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.multi_aligned_data.MultiAlignedData.length_name", "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.multi_aligned_data.MultiAlignedData.length_name"], ["", "def", "_run_and_test", "(", "self", ",", "hparams", ",", "discard_did", "=", "None", ")", ":", "\n", "# Construct database", "\n", "        ", "text_data", "=", "tx", ".", "data", ".", "MultiAlignedData", "(", "hparams", ")", "\n", "self", ".", "assertEqual", "(", "\n", "text_data", ".", "vocab", "(", "0", ")", ".", "size", ",", "\n", "self", ".", "_vocab_size", "+", "len", "(", "text_data", ".", "vocab", "(", "0", ")", ".", "special_tokens", ")", ")", "\n", "\n", "iterator", "=", "text_data", ".", "dataset", ".", "make_initializable_iterator", "(", ")", "\n", "text_data_batch", "=", "iterator", ".", "get_next", "(", ")", "\n", "\n", "with", "self", ".", "test_session", "(", ")", "as", "sess", ":", "\n", "            ", "sess", ".", "run", "(", "tf", ".", "global_variables_initializer", "(", ")", ")", "\n", "sess", ".", "run", "(", "tf", ".", "local_variables_initializer", "(", ")", ")", "\n", "sess", ".", "run", "(", "tf", ".", "tables_initializer", "(", ")", ")", "\n", "sess", ".", "run", "(", "iterator", ".", "initializer", ")", "\n", "\n", "while", "True", ":", "\n", "                ", "try", ":", "\n", "# Run the logics", "\n", "                    ", "data_batch_", "=", "sess", ".", "run", "(", "text_data_batch", ")", "\n", "\n", "self", ".", "assertEqual", "(", "set", "(", "data_batch_", ".", "keys", "(", ")", ")", ",", "\n", "set", "(", "text_data", ".", "list_items", "(", ")", ")", ")", "\n", "self", ".", "assertEqual", "(", "text_data", ".", "utterance_cnt_name", "(", "'2'", ")", ",", "\n", "'2_utterance_cnt'", ")", "\n", "text_0", "=", "data_batch_", "[", "'0_text'", "]", "\n", "text_1", "=", "data_batch_", "[", "'1_text'", "]", "\n", "text_2", "=", "data_batch_", "[", "'2_text'", "]", "\n", "int_3", "=", "data_batch_", "[", "'label'", "]", "\n", "# pylint: disable=invalid-name", "\n", "for", "t0", ",", "t1", ",", "t2", ",", "i3", "in", "zip", "(", "text_0", ",", "text_1", ",", "text_2", ",", "int_3", ")", ":", "\n", "                        ", "np", ".", "testing", ".", "assert_array_equal", "(", "\n", "t0", "[", ":", "2", "]", ",", "t1", "[", "1", ":", "3", "]", ")", "\n", "np", ".", "testing", ".", "assert_array_equal", "(", "\n", "t0", "[", ":", "3", "]", ",", "t2", "[", "0", "]", "[", ":", "3", "]", ")", "\n", "if", "t0", "[", "0", "]", ".", "startswith", "(", "b'This'", ")", ":", "\n", "                            ", "self", ".", "assertEqual", "(", "i3", ",", "0", ")", "\n", "", "else", ":", "\n", "                            ", "self", ".", "assertEqual", "(", "i3", ",", "1", ")", "\n", "\n", "", "", "if", "discard_did", "is", "not", "None", ":", "\n", "                        ", "hpms", "=", "text_data", ".", "_hparams", ".", "datasets", "[", "discard_did", "]", "\n", "max_l", "=", "hpms", ".", "max_seq_length", "\n", "max_l", "+=", "text_data", ".", "_decoder", "[", "discard_did", "]", ".", "added_length", "\n", "for", "i", "in", "range", "(", "2", ")", ":", "\n", "                            ", "for", "length", "in", "data_batch_", "[", "text_data", ".", "length_name", "(", "i", ")", "]", ":", "\n", "                                ", "self", ".", "assertLessEqual", "(", "length", ",", "max_l", ")", "\n", "", "", "for", "lengths", "in", "data_batch_", "[", "text_data", ".", "length_name", "(", "2", ")", "]", ":", "\n", "                            ", "for", "length", "in", "lengths", ":", "\n", "                                ", "self", ".", "assertLessEqual", "(", "length", ",", "max_l", ")", "\n", "", "", "", "for", "i", ",", "hpms", "in", "enumerate", "(", "text_data", ".", "_hparams", ".", "datasets", ")", ":", "\n", "                        ", "if", "hpms", ".", "data_type", "!=", "\"text\"", ":", "\n", "                            ", "continue", "\n", "", "max_l", "=", "hpms", ".", "max_seq_length", "\n", "mode", "=", "hpms", ".", "length_filter_mode", "\n", "if", "max_l", "is", "not", "None", "and", "mode", "==", "\"truncate\"", ":", "\n", "                            ", "max_l", "+=", "text_data", ".", "_decoder", "[", "i", "]", ".", "added_length", "\n", "for", "length", "in", "data_batch_", "[", "text_data", ".", "length_name", "(", "i", ")", "]", ":", "\n", "                                ", "self", ".", "assertLessEqual", "(", "length", ",", "max_l", ")", "\n", "\n", "", "", "", "", "except", "tf", ".", "errors", ".", "OutOfRangeError", ":", "\n", "                    ", "print", "(", "'Done -- epoch limit reached'", ")", "\n", "break", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.multi_aligned_data_test.MultiAlignedDataTest.test_default_setting": [[159, 163], ["multi_aligned_data_test.MultiAlignedDataTest._run_and_test"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.data.mono_text_data_test.VarUttMonoTextDataTest._run_and_test"], ["", "", "", "", "def", "test_default_setting", "(", "self", ")", ":", "\n", "        ", "\"\"\"Tests the logics of the text data.\n        \"\"\"", "\n", "self", ".", "_run_and_test", "(", "self", ".", "_hparams", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.multi_aligned_data_test.MultiAlignedDataTest.test_length_filter": [[164, 175], ["copy.copy", "[].update", "[].update", "multi_aligned_data_test.MultiAlignedDataTest._run_and_test"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.data.mono_text_data_test.VarUttMonoTextDataTest._run_and_test"], ["", "def", "test_length_filter", "(", "self", ")", ":", "\n", "        ", "\"\"\"Tests filtering by length.\n        \"\"\"", "\n", "hparams", "=", "copy", ".", "copy", "(", "self", ".", "_hparams", ")", "\n", "hparams", "[", "\"datasets\"", "]", "[", "0", "]", ".", "update", "(", "\n", "{", "\"max_seq_length\"", ":", "4", ",", "\n", "\"length_filter_mode\"", ":", "\"discard\"", "}", ")", "\n", "hparams", "[", "\"datasets\"", "]", "[", "1", "]", ".", "update", "(", "\n", "{", "\"max_seq_length\"", ":", "2", ",", "\n", "\"length_filter_mode\"", ":", "\"truncate\"", "}", ")", "\n", "self", ".", "_run_and_test", "(", "hparams", ",", "discard_did", "=", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.dataset_utils_test.TransformationTest.test_make_chained_transformation": [[25, 54], ["numpy.arange", "tensorflow.data.Dataset.from_tensor_slices", "texar.data.data.dataset_utils.make_chained_transformation", "dataset.map.map.map", "dataset.map.map.make_one_shot_iterator", "dataset.map.make_one_shot_iterator.get_next", "dataset_utils_test.TransformationTest.test_session", "dataset_utils_test.TransformationTest.assertEqual", "dataset_utils_test.TransformationTest.assertEqual", "len", "len", "numpy.arange.tolist", "data_.append", "sess.run"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.data.dataset_utils.make_chained_transformation", "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.data_iterators.FeedableDataIterator.get_next"], ["def", "test_make_chained_transformation", "(", "self", ")", ":", "\n", "        ", "\"\"\"Tests :func:`texar.data.make_chained_transformation`\n        \"\"\"", "\n", "original_data", "=", "np", ".", "arange", "(", "0", ",", "10", ")", "\n", "dataset", "=", "tf", ".", "data", ".", "Dataset", ".", "from_tensor_slices", "(", "original_data", ")", "\n", "\n", "def", "_tran_a", "(", "data", ")", ":", "\n", "            ", "return", "data", "+", "100", "\n", "", "def", "_tran_b", "(", "data", ")", ":", "\n", "            ", "return", "data", "+", "1000", "\n", "", "def", "_tran_c", "(", "data", ")", ":", "\n", "            ", "return", "data", "+", "10000", "\n", "\n", "", "chained_tran", "=", "dsutils", ".", "make_chained_transformation", "(", "\n", "[", "_tran_a", ",", "_tran_b", ",", "_tran_c", "]", ")", "\n", "dataset", "=", "dataset", ".", "map", "(", "chained_tran", ")", "\n", "\n", "iterator", "=", "dataset", ".", "make_one_shot_iterator", "(", ")", "\n", "elem", "=", "iterator", ".", "get_next", "(", ")", "\n", "with", "self", ".", "test_session", "(", ")", "as", "sess", ":", "\n", "            ", "data_", "=", "[", "]", "\n", "while", "True", ":", "\n", "                ", "try", ":", "\n", "                    ", "data_", ".", "append", "(", "sess", ".", "run", "(", "elem", ")", ")", "\n", "", "except", "tf", ".", "errors", ".", "OutOfRangeError", ":", "\n", "                    ", "break", "\n", "", "", "self", ".", "assertEqual", "(", "len", "(", "data_", ")", ",", "len", "(", "original_data", ")", ")", "\n", "data_", "=", "[", "elem_", "-", "11100", "for", "elem_", "in", "data_", "]", "\n", "self", ".", "assertEqual", "(", "data_", ",", "original_data", ".", "tolist", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.paired_text_data_test.PairedTextDataTest.setUp": [[28, 62], ["tensorflow.test.TestCase.setUp", "tempfile.NamedTemporaryFile", "tempfile.NamedTemporaryFile.write", "tempfile.NamedTemporaryFile.flush", "len", "tempfile.NamedTemporaryFile", "tempfile.NamedTemporaryFile.write", "tempfile.NamedTemporaryFile.flush", "tempfile.NamedTemporaryFile", "tempfile.NamedTemporaryFile.write", "tempfile.NamedTemporaryFile.flush"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.losses.mle_losses_test.MLELossesTest.setUp"], ["def", "setUp", "(", "self", ")", ":", "\n", "        ", "tf", ".", "test", ".", "TestCase", ".", "setUp", "(", "self", ")", "\n", "\n", "# Create test data", "\n", "vocab_list", "=", "[", "'This'", ",", "'is'", ",", "'a'", ",", "'word'", ",", "'\u8bcd'", "]", "\n", "vocab_file", "=", "tempfile", ".", "NamedTemporaryFile", "(", ")", "\n", "vocab_file", ".", "write", "(", "'\\n'", ".", "join", "(", "vocab_list", ")", ".", "encode", "(", "\"utf-8\"", ")", ")", "\n", "vocab_file", ".", "flush", "(", ")", "\n", "self", ".", "_vocab_file", "=", "vocab_file", "\n", "self", ".", "_vocab_size", "=", "len", "(", "vocab_list", ")", "\n", "\n", "src_text", "=", "[", "'This is a sentence from source .'", ",", "'\u8bcd \u8bcd \u3002 source'", "]", "\n", "src_text_file", "=", "tempfile", ".", "NamedTemporaryFile", "(", ")", "\n", "src_text_file", ".", "write", "(", "'\\n'", ".", "join", "(", "src_text", ")", ".", "encode", "(", "\"utf-8\"", ")", ")", "\n", "src_text_file", ".", "flush", "(", ")", "\n", "self", ".", "_src_text_file", "=", "src_text_file", "\n", "\n", "tgt_text", "=", "[", "'This is a sentence from target .'", ",", "'\u8bcd \u8bcd \u3002 target'", "]", "\n", "tgt_text_file", "=", "tempfile", ".", "NamedTemporaryFile", "(", ")", "\n", "tgt_text_file", ".", "write", "(", "'\\n'", ".", "join", "(", "tgt_text", ")", ".", "encode", "(", "\"utf-8\"", ")", ")", "\n", "tgt_text_file", ".", "flush", "(", ")", "\n", "self", ".", "_tgt_text_file", "=", "tgt_text_file", "\n", "\n", "self", ".", "_hparams", "=", "{", "\n", "\"num_epochs\"", ":", "50", ",", "\n", "\"batch_size\"", ":", "3", ",", "\n", "\"source_dataset\"", ":", "{", "\n", "\"files\"", ":", "[", "self", ".", "_src_text_file", ".", "name", "]", ",", "\n", "\"vocab_file\"", ":", "self", ".", "_vocab_file", ".", "name", ",", "\n", "}", ",", "\n", "\"target_dataset\"", ":", "{", "\n", "\"files\"", ":", "self", ".", "_tgt_text_file", ".", "name", ",", "\n", "\"vocab_share\"", ":", "True", ",", "\n", "\"eos_token\"", ":", "\"<TARGET_EOS>\"", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.paired_text_data_test.PairedTextDataTest._run_and_test": [[65, 127], ["texar.data.PairedTextData", "paired_text_data_test.PairedTextDataTest.assertEqual", "texar.data.PairedTextData.dataset.make_initializable_iterator", "tx.data.PairedTextData.dataset.make_initializable_iterator.get_next", "paired_text_data_test.PairedTextDataTest.test_session", "sess.run", "sess.run", "sess.run", "sess.run", "len", "tensorflow.global_variables_initializer", "tensorflow.local_variables_initializer", "tensorflow.tables_initializer", "sess.run", "paired_text_data_test.PairedTextDataTest.assertEqual", "paired_text_data_test.PairedTextDataTest.assertTrue", "set", "set", "zip", "zip", "range", "range", "print", "sess.run.keys", "texar.data.PairedTextData.list_items", "numpy.testing.assert_array_equal", "numpy.testing.assert_array_equal", "len", "[].tolist", "paired_text_data_test.PairedTextDataTest.assertEqual", "len", "[].tolist", "paired_text_data_test.PairedTextDataTest.assertEqual", "paired_text_data_test.PairedTextDataTest.assertLessEqual", "[].tolist.index", "[].tolist.index"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.data.data_iterators.FeedableDataIterator.get_next", "home.repos.pwc.inspect_result.VegB_Text_Infilling.texar.hyperparams.HParams.keys", "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.multi_aligned_data.MultiAlignedData.list_items"], ["", "def", "_run_and_test", "(", "self", ",", "hparams", ",", "proc_shr", "=", "False", ",", "length_inc", "=", "None", ",", "\n", "discard_src", "=", "False", ")", ":", "\n", "# Construct database", "\n", "        ", "text_data", "=", "tx", ".", "data", ".", "PairedTextData", "(", "hparams", ")", "\n", "self", ".", "assertEqual", "(", "\n", "text_data", ".", "source_vocab", ".", "size", ",", "\n", "self", ".", "_vocab_size", "+", "len", "(", "text_data", ".", "source_vocab", ".", "special_tokens", ")", ")", "\n", "\n", "iterator", "=", "text_data", ".", "dataset", ".", "make_initializable_iterator", "(", ")", "\n", "text_data_batch", "=", "iterator", ".", "get_next", "(", ")", "\n", "\n", "with", "self", ".", "test_session", "(", ")", "as", "sess", ":", "\n", "            ", "sess", ".", "run", "(", "tf", ".", "global_variables_initializer", "(", ")", ")", "\n", "sess", ".", "run", "(", "tf", ".", "local_variables_initializer", "(", ")", ")", "\n", "sess", ".", "run", "(", "tf", ".", "tables_initializer", "(", ")", ")", "\n", "sess", ".", "run", "(", "iterator", ".", "initializer", ")", "\n", "\n", "if", "proc_shr", ":", "\n", "                ", "tgt_eos", "=", "b'<EOS>'", "\n", "", "else", ":", "\n", "                ", "tgt_eos", "=", "b'<TARGET_EOS>'", "\n", "\n", "", "while", "True", ":", "\n", "                ", "try", ":", "\n", "# Run the logics", "\n", "                    ", "data_batch_", "=", "sess", ".", "run", "(", "text_data_batch", ")", "\n", "self", ".", "assertEqual", "(", "set", "(", "data_batch_", ".", "keys", "(", ")", ")", ",", "\n", "set", "(", "text_data", ".", "list_items", "(", ")", ")", ")", "\n", "# Test matching", "\n", "src_text", "=", "data_batch_", "[", "'source_text'", "]", "\n", "tgt_text", "=", "data_batch_", "[", "'target_text'", "]", "\n", "if", "proc_shr", ":", "\n", "                        ", "for", "src", ",", "tgt", "in", "zip", "(", "src_text", ",", "tgt_text", ")", ":", "\n", "                            ", "np", ".", "testing", ".", "assert_array_equal", "(", "src", "[", ":", "3", "]", ",", "tgt", "[", ":", "3", "]", ")", "\n", "", "", "else", ":", "\n", "                        ", "for", "src", ",", "tgt", "in", "zip", "(", "src_text", ",", "tgt_text", ")", ":", "\n", "                            ", "np", ".", "testing", ".", "assert_array_equal", "(", "src", "[", ":", "3", "]", ",", "tgt", "[", "1", ":", "4", "]", ")", "\n", "", "", "self", ".", "assertTrue", "(", "\n", "tgt_eos", "in", "data_batch_", "[", "'target_text'", "]", "[", "0", "]", ")", "\n", "\n", "if", "length_inc", ":", "\n", "                        ", "for", "i", "in", "range", "(", "len", "(", "data_batch_", "[", "'source_text'", "]", ")", ")", ":", "\n", "                            ", "text_", "=", "data_batch_", "[", "'source_text'", "]", "[", "i", "]", ".", "tolist", "(", ")", "\n", "self", ".", "assertEqual", "(", "\n", "text_", ".", "index", "(", "b'<EOS>'", ")", "+", "1", ",", "\n", "data_batch_", "[", "'source_length'", "]", "[", "i", "]", "-", "length_inc", "[", "0", "]", ")", "\n", "", "for", "i", "in", "range", "(", "len", "(", "data_batch_", "[", "'target_text'", "]", ")", ")", ":", "\n", "                            ", "text_", "=", "data_batch_", "[", "'target_text'", "]", "[", "i", "]", ".", "tolist", "(", ")", "\n", "self", ".", "assertEqual", "(", "\n", "text_", ".", "index", "(", "tgt_eos", ")", "+", "1", ",", "\n", "data_batch_", "[", "'target_length'", "]", "[", "i", "]", "-", "length_inc", "[", "1", "]", ")", "\n", "\n", "", "", "if", "discard_src", ":", "\n", "                        ", "src_hparams", "=", "text_data", ".", "hparams", ".", "source_dataset", "\n", "max_l", "=", "src_hparams", ".", "max_seq_length", "\n", "max_l", "+=", "text_data", ".", "_decoder", "[", "0", "]", ".", "added_length", "\n", "for", "l", "in", "data_batch_", "[", "text_data", ".", "source_length_name", "]", ":", "\n", "                            ", "self", ".", "assertLessEqual", "(", "l", ",", "max_l", ")", "\n", "\n", "", "", "", "except", "tf", ".", "errors", ".", "OutOfRangeError", ":", "\n", "                    ", "print", "(", "'Done -- epoch limit reached'", ")", "\n", "break", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.paired_text_data_test.PairedTextDataTest.test_default_setting": [[128, 132], ["paired_text_data_test.PairedTextDataTest._run_and_test"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.data.mono_text_data_test.VarUttMonoTextDataTest._run_and_test"], ["", "", "", "", "def", "test_default_setting", "(", "self", ")", ":", "\n", "        ", "\"\"\"Tests the logics of the text data.\n        \"\"\"", "\n", "self", ".", "_run_and_test", "(", "self", ".", "_hparams", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.paired_text_data_test.PairedTextDataTest.test_shuffle": [[133, 139], ["copy.copy", "paired_text_data_test.PairedTextDataTest._run_and_test"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.data.mono_text_data_test.VarUttMonoTextDataTest._run_and_test"], ["", "def", "test_shuffle", "(", "self", ")", ":", "\n", "        ", "\"\"\"Tests toggling shuffle.\n        \"\"\"", "\n", "hparams", "=", "copy", ".", "copy", "(", "self", ".", "_hparams", ")", "\n", "hparams", "[", "\"shuffle\"", "]", "=", "False", "\n", "self", ".", "_run_and_test", "(", "hparams", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.paired_text_data_test.PairedTextDataTest.test_processing_share": [[140, 146], ["copy.copy", "paired_text_data_test.PairedTextDataTest._run_and_test"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.data.mono_text_data_test.VarUttMonoTextDataTest._run_and_test"], ["", "def", "test_processing_share", "(", "self", ")", ":", "\n", "        ", "\"\"\"Tests sharing processing.\n        \"\"\"", "\n", "hparams", "=", "copy", ".", "copy", "(", "self", ".", "_hparams", ")", "\n", "hparams", "[", "\"target_dataset\"", "]", "[", "\"processing_share\"", "]", "=", "True", "\n", "self", ".", "_run_and_test", "(", "hparams", ",", "proc_shr", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.paired_text_data_test.PairedTextDataTest.test_other_transformations": [[147, 160], ["copy.copy", "hparams[].update", "hparams[].update", "paired_text_data_test.PairedTextDataTest._run_and_test"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.data.mono_text_data_test.VarUttMonoTextDataTest._run_and_test"], ["", "def", "test_other_transformations", "(", "self", ")", ":", "\n", "        ", "\"\"\"Tests use of other transformations\n        \"\"\"", "\n", "def", "_transform", "(", "x", ",", "data_specs", ")", ":", "# pylint: disable=invalid-name", "\n", "            ", "x", "[", "data_specs", ".", "decoder", ".", "length_tensor_name", "]", "+=", "1", "\n", "return", "x", "\n", "\n", "", "hparams", "=", "copy", ".", "copy", "(", "self", ".", "_hparams", ")", "\n", "hparams", "[", "\"source_dataset\"", "]", ".", "update", "(", "\n", "{", "\"other_transformations\"", ":", "[", "_transform", ",", "_transform", "]", "}", ")", "\n", "hparams", "[", "\"target_dataset\"", "]", ".", "update", "(", "\n", "{", "\"other_transformations\"", ":", "[", "_transform", "]", "}", ")", "\n", "self", ".", "_run_and_test", "(", "hparams", ",", "length_inc", "=", "(", "2", ",", "1", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.paired_text_data_test.PairedTextDataTest.test_length_filter": [[161, 169], ["copy.copy", "hparams[].update", "paired_text_data_test.PairedTextDataTest._run_and_test"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.data.mono_text_data_test.VarUttMonoTextDataTest._run_and_test"], ["", "def", "test_length_filter", "(", "self", ")", ":", "\n", "        ", "\"\"\"Tests filtering by length.\n        \"\"\"", "\n", "hparams", "=", "copy", ".", "copy", "(", "self", ".", "_hparams", ")", "\n", "hparams", "[", "\"source_dataset\"", "]", ".", "update", "(", "\n", "{", "\"max_seq_length\"", ":", "4", ",", "\n", "\"length_filter_mode\"", ":", "\"discard\"", "}", ")", "\n", "self", ".", "_run_and_test", "(", "hparams", ",", "discard_src", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.mono_text_data.MonoTextData.__init__": [[139, 143], ["texar.data.data.text_data_base.TextDataBase.__init__", "tensorflow.name_scope", "mono_text_data.MonoTextData._make_data", "mono_text_data.MonoTextData.default_hparams"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.text_infilling.self_attn_hyperparams.Hyperparams.__init__", "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.multi_aligned_data.MultiAlignedData._make_data", "home.repos.pwc.inspect_result.VegB_Text_Infilling.core.replay_memories.DequeReplayMemory.default_hparams"], ["def", "__init__", "(", "self", ",", "hparams", ")", ":", "\n", "        ", "TextDataBase", ".", "__init__", "(", "self", ",", "hparams", ")", "\n", "with", "tf", ".", "name_scope", "(", "self", ".", "name", ",", "self", ".", "default_hparams", "(", ")", "[", "\"name\"", "]", ")", ":", "\n", "            ", "self", ".", "_make_data", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.mono_text_data.MonoTextData.default_hparams": [[144, 255], ["texar.data.data.text_data_base.TextDataBase.default_hparams", "texar.data.data.text_data_base.TextDataBase.default_hparams.update", "mono_text_data._default_mono_text_dataset_hparams"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.core.replay_memories.DequeReplayMemory.default_hparams", "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.mono_text_data._default_mono_text_dataset_hparams"], ["", "", "@", "staticmethod", "\n", "def", "default_hparams", "(", ")", ":", "\n", "        ", "\"\"\"Returns a dicitionary of default hyperparameters:\n\n        .. code-block:: python\n\n            {\n                \"files\": [],\n                \"compression_type\": None,\n                \"vocab_file\": \"\",\n                \"embedding_init\": {},\n                \"delimiter\": \" \",\n                \"max_seq_length\": None,\n                \"length_filter_mode\": \"truncate\",\n                \"pad_to_max_seq_length\": False,\n                \"bos_token\": SpecialTokens.BOS,\n                \"eos_token\": SpecialTokens.EOS,\n                \"other_transformations\": [],\n                \"variable_utterance\": False,\n                \"utterance_delimiter\": \"|||\",\n                \"max_utterance_cnt\": 5,\n                \"data_name\": None,\n            }\n\n        Here:\n\n        \"files\" : str or list\n            A (list of) text file path(s).\n\n            Each line contains a single text sequence.\n\n        \"compression_type\" : str, optional\n            One of \"\" (no compression), \"ZLIB\", or \"GZIP\".\n\n        \"vocab_file\": str\n            Path to vocabulary file. Each line of the file should contain\n            one vocabulary token.\n\n            Used to create an instance of :class:`~texar.data.Vocab`.\n\n        \"embedding_init\" : dict\n            The hyperparameters for pre-trained embedding loading and\n            initialization.\n\n            The structure and default values are defined in\n            :meth:`texar.data.Embedding.default_hparams`.\n\n        \"delimiter\" : str\n            The delimiter to split each line of the text files into tokens.\n\n        \"max_seq_length\" : int, optional\n            Maximum length of output sequences. Data samples exceeding the\n            length will be truncated or discarded according to\n            :attr:`\"length_filter_mode\"`. The length does not include any added\n            :attr:`\"bos_token\"` or :attr:`\"eos_token\"`. If `None` (default),\n            no filtering is performed.\n\n        \"length_filter_mode\" : str\n            Either \"truncate\" or \"discard\". If \"truncate\" (default),\n            tokens exceeding the :attr:`\"max_seq_length\"` will be truncated.\n            If \"discard\", data samples longer than the :attr:`\"max_seq_length\"`\n            will be discarded.\n\n        \"pad_to_max_seq_length\" : bool\n            If `True`, pad all data instances to length\n            :attr:`\"max_seq_length\"`.\n            Raises error if :attr:`\"max_seq_length\"` is not provided.\n\n        \"bos_token\" : str\n            The Begin-Of-Sequence token prepended to each sequence.\n\n            Set to an empty string to avoid prepending.\n\n        \"eos_token\" : str\n            The End-Of-Sequence token appended to each sequence.\n\n            Set to an empty string to avoid appending.\n\n        \"other_transformations\" : list\n            A list of transformation functions or function names/paths to\n            further transform the data instances.\n\n            (More documentations to be added.)\n\n        \"variable_utterance\" : bool\n            If `True`, each line of the text file is considered to contain\n            multiple sequences (utterances) separated by\n            :attr:`\"utterance_delimiter\"`.\n\n            For example, in dialog data, each line can contain a series of\n            dialog history utterances. See the example in\n            `examples/hierarchical_dialog` for a use case.\n\n        \"utterance_delimiter\" : str\n            The delimiter to split over utterance level. Should not be the\n            same with :attr:`\"delimiter\"`. Used only when\n            :attr:`\"variable_utterance\"``==True`.\n\n        \"max_utterance_cnt\" : int\n            Maximally allowed number of utterances in a data instance.\n            Extra utterances are truncated out.\n\n        \"data_name\" : str\n            Name of the data.\n        \"\"\"", "\n", "hparams", "=", "TextDataBase", ".", "default_hparams", "(", ")", "\n", "hparams", "[", "\"name\"", "]", "=", "\"mono_text_data\"", "\n", "hparams", ".", "update", "(", "{", "\n", "\"dataset\"", ":", "_default_mono_text_dataset_hparams", "(", ")", "\n", "}", ")", "\n", "return", "hparams", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.mono_text_data.MonoTextData.make_vocab": [[256, 268], ["texar.utils.utils.default_str", "texar.utils.utils.default_str", "texar.data.vocabulary.Vocab"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.utils.default_str", "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.utils.default_str"], ["", "@", "staticmethod", "\n", "def", "make_vocab", "(", "hparams", ")", ":", "\n", "        ", "\"\"\"Reads vocab file and returns an instance of\n        :class:`texar.data.Vocab`.\n        \"\"\"", "\n", "bos_token", "=", "utils", ".", "default_str", "(", "\n", "hparams", "[", "\"bos_token\"", "]", ",", "SpecialTokens", ".", "BOS", ")", "\n", "eos_token", "=", "utils", ".", "default_str", "(", "\n", "hparams", "[", "\"eos_token\"", "]", ",", "SpecialTokens", ".", "EOS", ")", "\n", "vocab", "=", "Vocab", "(", "hparams", "[", "\"vocab_file\"", "]", ",", "\n", "bos_token", "=", "bos_token", ",", "eos_token", "=", "eos_token", ")", "\n", "return", "vocab", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.mono_text_data.MonoTextData.make_embedding": [[269, 278], ["texar.data.embedding.Embedding", "len"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "make_embedding", "(", "emb_hparams", ",", "token_to_id_map", ")", ":", "\n", "        ", "\"\"\"Optionally loads embedding from file (if provided), and returns\n        an instance of :class:`texar.data.Embedding`.\n        \"\"\"", "\n", "embedding", "=", "None", "\n", "if", "emb_hparams", "[", "\"file\"", "]", "is", "not", "None", "and", "len", "(", "emb_hparams", "[", "\"file\"", "]", ")", ">", "0", ":", "\n", "            ", "embedding", "=", "Embedding", "(", "token_to_id_map", ",", "emb_hparams", ")", "\n", "", "return", "embedding", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.mono_text_data.MonoTextData._make_mono_text_dataset": [[279, 285], ["tensorflow.data.TextLineDataset"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_make_mono_text_dataset", "(", "dataset_hparams", ")", ":", "\n", "        ", "dataset", "=", "tf", ".", "data", ".", "TextLineDataset", "(", "\n", "dataset_hparams", "[", "\"files\"", "]", ",", "\n", "compression_type", "=", "dataset_hparams", "[", "\"compression_type\"", "]", ")", "\n", "return", "dataset", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.mono_text_data.MonoTextData._make_other_transformations": [[286, 306], ["other_trans.append", "texar.utils.dtypes.is_callable", "texar.utils.utils.get_function", "texar.data.data.dataset_utils.make_partial"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.dtypes.is_callable", "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.utils.get_function", "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.dataset_utils.make_partial"], ["", "@", "staticmethod", "\n", "def", "_make_other_transformations", "(", "other_trans_hparams", ",", "data_spec", ")", ":", "\n", "        ", "\"\"\"Creates a list of tranformation functions based on the\n        hyperparameters.\n\n        Args:\n            other_trans_hparams (list): A list of transformation functions,\n                names, or full paths.\n            data_spec: An instance of :class:`texar.data._DataSpec` to\n                be passed to transformation functions.\n\n        Returns:\n            A list of transformation functions.\n        \"\"\"", "\n", "other_trans", "=", "[", "]", "\n", "for", "tran", "in", "other_trans_hparams", ":", "\n", "            ", "if", "not", "is_callable", "(", "tran", ")", ":", "\n", "                ", "tran", "=", "utils", ".", "get_function", "(", "tran", ",", "[", "\"texar.custom\"", "]", ")", "\n", "", "other_trans", ".", "append", "(", "dsutils", ".", "make_partial", "(", "tran", ",", "data_spec", ")", ")", "\n", "", "return", "other_trans", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.mono_text_data.MonoTextData._make_processor": [[307, 347], ["data_spec.add_spec", "mono_text_data.MonoTextData._make_other_transformations", "data_spec.add_spec", "texar.data.data_decoders.TextDataDecoder", "texar.data.data_decoders.VarUttTextDataDecoder", "mono_text_data.MonoTextData._make_other_transformations", "texar.data.data.dataset_utils.make_chained_transformation", "texar.data.data.dataset_utils.name_prefix_fn"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.data.dataset_utils._DataSpec.add_spec", "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.mono_text_data.MonoTextData._make_other_transformations", "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.dataset_utils._DataSpec.add_spec", "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.mono_text_data.MonoTextData._make_other_transformations", "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.dataset_utils.make_chained_transformation", "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.dataset_utils.name_prefix_fn"], ["", "@", "staticmethod", "\n", "def", "_make_processor", "(", "dataset_hparams", ",", "data_spec", ",", "chained", "=", "True", ",", "\n", "name_prefix", "=", "None", ")", ":", "\n", "# Create data decoder", "\n", "        ", "max_seq_length", "=", "None", "\n", "if", "dataset_hparams", "[", "\"length_filter_mode\"", "]", "==", "\"truncate\"", ":", "\n", "            ", "max_seq_length", "=", "dataset_hparams", "[", "\"max_seq_length\"", "]", "\n", "\n", "", "if", "not", "dataset_hparams", "[", "\"variable_utterance\"", "]", ":", "\n", "            ", "decoder", "=", "TextDataDecoder", "(", "\n", "delimiter", "=", "dataset_hparams", "[", "\"delimiter\"", "]", ",", "\n", "bos_token", "=", "dataset_hparams", "[", "\"bos_token\"", "]", ",", "\n", "eos_token", "=", "dataset_hparams", "[", "\"eos_token\"", "]", ",", "\n", "max_seq_length", "=", "max_seq_length", ",", "\n", "token_to_id_map", "=", "data_spec", ".", "vocab", ".", "token_to_id_map", ")", "\n", "", "else", ":", "\n", "            ", "decoder", "=", "VarUttTextDataDecoder", "(", "# pylint: disable=redefined-variable-type", "\n", "sentence_delimiter", "=", "dataset_hparams", "[", "\"utterance_delimiter\"", "]", ",", "\n", "delimiter", "=", "dataset_hparams", "[", "\"delimiter\"", "]", ",", "\n", "bos_token", "=", "dataset_hparams", "[", "\"bos_token\"", "]", ",", "\n", "eos_token", "=", "dataset_hparams", "[", "\"eos_token\"", "]", ",", "\n", "max_seq_length", "=", "max_seq_length", ",", "\n", "max_utterance_cnt", "=", "dataset_hparams", "[", "\"max_utterance_cnt\"", "]", ",", "\n", "token_to_id_map", "=", "data_spec", ".", "vocab", ".", "token_to_id_map", ")", "\n", "\n", "# Create other transformations", "\n", "", "data_spec", ".", "add_spec", "(", "decoder", "=", "decoder", ")", "\n", "other_trans", "=", "MonoTextData", ".", "_make_other_transformations", "(", "\n", "dataset_hparams", "[", "\"other_transformations\"", "]", ",", "data_spec", ")", "\n", "if", "name_prefix", ":", "\n", "            ", "other_trans", ".", "append", "(", "dsutils", ".", "name_prefix_fn", "(", "name_prefix", ")", ")", "\n", "\n", "", "data_spec", ".", "add_spec", "(", "name_prefix", "=", "name_prefix", ")", "\n", "\n", "if", "chained", ":", "\n", "            ", "chained_tran", "=", "dsutils", ".", "make_chained_transformation", "(", "\n", "[", "decoder", "]", "+", "other_trans", ")", "\n", "return", "chained_tran", ",", "data_spec", "\n", "", "else", ":", "\n", "            ", "return", "decoder", ",", "other_trans", ",", "data_spec", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.mono_text_data.MonoTextData._make_length_filter": [[348, 358], ["texar.data.data.dataset_utils._make_length_filter_fn"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.data.dataset_utils._make_length_filter_fn"], ["", "", "@", "staticmethod", "\n", "def", "_make_length_filter", "(", "dataset_hparams", ",", "length_name", ",", "decoder", ")", ":", "\n", "        ", "filter_mode", "=", "dataset_hparams", "[", "\"length_filter_mode\"", "]", "\n", "max_length", "=", "dataset_hparams", "[", "\"max_seq_length\"", "]", "\n", "filter_fn", "=", "None", "\n", "if", "filter_mode", "==", "_LengthFilterMode", ".", "DISCARD", "and", "max_length", "is", "not", "None", ":", "\n", "            ", "max_length", "+=", "decoder", ".", "added_length", "\n", "filter_fn", "=", "dsutils", ".", "_make_length_filter_fn", "(", "length_name", ",", "\n", "max_length", ")", "\n", "", "return", "filter_fn", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.mono_text_data.MonoTextData._process_dataset": [[359, 381], ["mono_text_data.MonoTextData._make_processor", "dataset.filter.filter.map", "texar.data.data.dataset_utils._connect_name", "mono_text_data.MonoTextData._make_length_filter", "dataset.filter.filter.take", "dataset.filter.filter.filter", "chained_tran", "texar.data.data.dataset_utils.maybe_tuple"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.data.multi_aligned_data.MultiAlignedData._make_processor", "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.dataset_utils._connect_name", "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.multi_aligned_data.MultiAlignedData._make_length_filter", "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.dataset_utils.maybe_tuple"], ["", "def", "_process_dataset", "(", "self", ",", "dataset", ",", "hparams", ",", "data_spec", ")", ":", "\n", "        ", "chained_tran", ",", "data_spec", "=", "self", ".", "_make_processor", "(", "\n", "hparams", "[", "\"dataset\"", "]", ",", "data_spec", ",", "\n", "name_prefix", "=", "hparams", "[", "\"dataset\"", "]", "[", "\"data_name\"", "]", ")", "\n", "num_parallel_calls", "=", "hparams", "[", "\"num_parallel_calls\"", "]", "\n", "dataset", "=", "dataset", ".", "map", "(", "\n", "lambda", "*", "args", ":", "chained_tran", "(", "dsutils", ".", "maybe_tuple", "(", "args", ")", ")", ",", "\n", "num_parallel_calls", "=", "num_parallel_calls", ")", "\n", "\n", "# Filters by length", "\n", "length_name", "=", "dsutils", ".", "_connect_name", "(", "\n", "data_spec", ".", "name_prefix", ",", "\n", "data_spec", ".", "decoder", ".", "length_tensor_name", ")", "\n", "filter_fn", "=", "self", ".", "_make_length_filter", "(", "\n", "hparams", "[", "\"dataset\"", "]", ",", "length_name", ",", "data_spec", ".", "decoder", ")", "\n", "if", "filter_fn", ":", "\n", "            ", "dataset", "=", "dataset", ".", "filter", "(", "filter_fn", ")", "\n", "\n", "# Truncates data count", "\n", "", "dataset", "=", "dataset", ".", "take", "(", "hparams", "[", "\"max_dataset_size\"", "]", ")", "\n", "\n", "return", "dataset", ",", "data_spec", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.mono_text_data.MonoTextData._make_bucket_length_fn": [[382, 390], ["texar.utils.dtypes.is_callable", "texar.utils.utils.get_function"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.dtypes.is_callable", "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.utils.get_function"], ["", "def", "_make_bucket_length_fn", "(", "self", ")", ":", "\n", "        ", "length_fn", "=", "self", ".", "_hparams", ".", "bucket_length_fn", "\n", "if", "not", "length_fn", ":", "\n", "            ", "length_fn", "=", "lambda", "x", ":", "x", "[", "self", ".", "length_name", "]", "\n", "", "elif", "not", "is_callable", "(", "length_fn", ")", ":", "\n", "# pylint: disable=redefined-variable-type", "\n", "            ", "length_fn", "=", "utils", ".", "get_function", "(", "length_fn", ",", "[", "\"texar.custom\"", "]", ")", "\n", "", "return", "length_fn", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.mono_text_data.MonoTextData._make_padded_text_and_id_shapes": [[391, 424], ["ValueError", "len", "mono_text_data.MonoTextData._make_padded_text_and_id_shapes._get_new_shape"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_make_padded_text_and_id_shapes", "(", "dataset", ",", "dataset_hparams", ",", "decoder", ",", "\n", "text_name", ",", "text_id_name", ")", ":", "\n", "        ", "max_length", "=", "dataset_hparams", "[", "'max_seq_length'", "]", "\n", "if", "max_length", "is", "None", ":", "\n", "            ", "raise", "ValueError", "(", "\"hparams 'max_seq_length' must be specified \"", "\n", "\"when 'pad_to_max_seq_length' is True.\"", ")", "\n", "", "max_length", "+=", "decoder", ".", "added_length", "\n", "\n", "padded_shapes", "=", "dataset", ".", "output_shapes", "\n", "\n", "def", "_get_new_shape", "(", "name", ")", ":", "\n", "            ", "dim", "=", "len", "(", "padded_shapes", "[", "name", "]", ")", "\n", "if", "not", "dataset_hparams", "[", "'variable_utterance'", "]", ":", "\n", "                ", "if", "dim", "!=", "1", ":", "\n", "                    ", "raise", "ValueError", "(", "\n", "\"Unable to pad data '%s' to max seq length. Expected \"", "\n", "\"1D Tensor, but got %dD Tensor.\"", "%", "(", "name", ",", "dim", ")", ")", "\n", "", "return", "tf", ".", "TensorShape", "(", "max_length", ")", "\n", "", "else", ":", "\n", "                ", "if", "dim", "!=", "2", ":", "\n", "                    ", "raise", "ValueError", "(", "\n", "\"Unable to pad data '%s' to max seq length. Expected \"", "\n", "\"2D Tensor, but got %dD Tensor.\"", "%", "(", "name", ",", "dim", ")", ")", "\n", "", "return", "tf", ".", "TensorShape", "(", "[", "padded_shapes", "[", "name", "]", "[", "0", "]", ",", "max_length", "]", ")", "\n", "\n", "", "", "text_and_id_shapes", "=", "{", "}", "\n", "if", "text_name", "in", "padded_shapes", ":", "\n", "            ", "text_and_id_shapes", "[", "text_name", "]", "=", "_get_new_shape", "(", "text_name", ")", "\n", "", "if", "text_id_name", "in", "padded_shapes", ":", "\n", "            ", "text_and_id_shapes", "[", "text_id_name", "]", "=", "_get_new_shape", "(", "text_id_name", ")", "\n", "\n", "", "return", "text_and_id_shapes", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.mono_text_data.MonoTextData._make_padded_shapes": [[425, 437], ["mono_text_data.MonoTextData._make_padded_text_and_id_shapes", "padded_shapes.update"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.data.mono_text_data.MonoTextData._make_padded_text_and_id_shapes"], ["", "def", "_make_padded_shapes", "(", "self", ",", "dataset", ",", "decoder", ")", ":", "\n", "        ", "if", "not", "self", ".", "_hparams", ".", "dataset", ".", "pad_to_max_seq_length", ":", "\n", "            ", "return", "None", "\n", "\n", "", "text_and_id_shapes", "=", "MonoTextData", ".", "_make_padded_text_and_id_shapes", "(", "\n", "dataset", ",", "self", ".", "_hparams", ".", "dataset", ",", "decoder", ",", "\n", "self", ".", "text_name", ",", "self", ".", "text_id_name", ")", "\n", "\n", "padded_shapes", "=", "dataset", ".", "output_shapes", "\n", "padded_shapes", ".", "update", "(", "text_and_id_shapes", ")", "\n", "\n", "return", "padded_shapes", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.mono_text_data.MonoTextData._make_data": [[438, 473], ["mono_text_data.MonoTextData.make_vocab", "mono_text_data.MonoTextData.make_embedding", "mono_text_data.MonoTextData._make_mono_text_dataset", "mono_text_data.MonoTextData._shuffle_dataset", "texar.data.data.dataset_utils._DataSpec", "mono_text_data.MonoTextData._process_dataset", "mono_text_data.MonoTextData._make_bucket_length_fn", "mono_text_data.MonoTextData._make_padded_shapes", "mono_text_data.MonoTextData._make_batch", "dataset.prefetch.prefetch.prefetch"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.data.multi_aligned_data.MultiAlignedData.make_vocab", "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.multi_aligned_data.MultiAlignedData.make_embedding", "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.mono_text_data.MonoTextData._make_mono_text_dataset", "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.data_base.DataBase._shuffle_dataset", "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.multi_aligned_data.MultiAlignedData._process_dataset", "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.multi_aligned_data.MultiAlignedData._make_bucket_length_fn", "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.multi_aligned_data.MultiAlignedData._make_padded_shapes", "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.text_data_base.TextDataBase._make_batch"], ["", "def", "_make_data", "(", "self", ")", ":", "\n", "        ", "dataset_hparams", "=", "self", ".", "_hparams", ".", "dataset", "\n", "\n", "# Create vocab and embedding", "\n", "self", ".", "_vocab", "=", "self", ".", "make_vocab", "(", "dataset_hparams", ")", "\n", "self", ".", "_embedding", "=", "self", ".", "make_embedding", "(", "\n", "dataset_hparams", "[", "\"embedding_init\"", "]", ",", "self", ".", "_vocab", ".", "token_to_id_map_py", ")", "\n", "\n", "# Create and shuffle dataset", "\n", "dataset", "=", "self", ".", "_make_mono_text_dataset", "(", "dataset_hparams", ")", "\n", "dataset", ",", "dataset_size", "=", "self", ".", "_shuffle_dataset", "(", "\n", "dataset", ",", "self", ".", "_hparams", ",", "self", ".", "_hparams", ".", "dataset", ".", "files", ")", "\n", "self", ".", "_dataset_size", "=", "dataset_size", "\n", "\n", "# Processing", "\n", "data_spec", "=", "dsutils", ".", "_DataSpec", "(", "dataset", "=", "dataset", ",", "\n", "dataset_size", "=", "self", ".", "_dataset_size", ",", "\n", "vocab", "=", "self", ".", "_vocab", ",", "\n", "embedding", "=", "self", ".", "_embedding", ")", "\n", "dataset", ",", "data_spec", "=", "self", ".", "_process_dataset", "(", "dataset", ",", "self", ".", "_hparams", ",", "\n", "data_spec", ")", "\n", "self", ".", "_data_spec", "=", "data_spec", "\n", "self", ".", "_decoder", "=", "data_spec", ".", "decoder", "\n", "\n", "# Batching", "\n", "length_fn", "=", "self", ".", "_make_bucket_length_fn", "(", ")", "\n", "padded_shapes", "=", "self", ".", "_make_padded_shapes", "(", "dataset", ",", "self", ".", "_decoder", ")", "\n", "dataset", "=", "self", ".", "_make_batch", "(", "\n", "dataset", ",", "self", ".", "_hparams", ",", "length_fn", ",", "padded_shapes", ")", "\n", "\n", "# Prefetching", "\n", "if", "self", ".", "_hparams", ".", "prefetch_buffer_size", ">", "0", ":", "\n", "            ", "dataset", "=", "dataset", ".", "prefetch", "(", "self", ".", "_hparams", ".", "prefetch_buffer_size", ")", "\n", "\n", "", "self", ".", "_dataset", "=", "dataset", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.mono_text_data.MonoTextData.list_items": [[474, 481], ["list", "mono_text_data.MonoTextData._dataset.output_types.keys"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.texar.hyperparams.HParams.keys"], ["", "def", "list_items", "(", "self", ")", ":", "\n", "        ", "\"\"\"Returns the list of item names that the data can produce.\n\n        Returns:\n            A list of strings.\n        \"\"\"", "\n", "return", "list", "(", "self", ".", "_dataset", ".", "output_types", ".", "keys", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.mono_text_data.MonoTextData.dataset": [[482, 488], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "dataset", "(", "self", ")", ":", "\n", "        ", "\"\"\"The dataset, an instance of\n        :tf_main:`TF dataset <data/TextLineDataset>`.\n        \"\"\"", "\n", "return", "self", ".", "_dataset", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.mono_text_data.MonoTextData.dataset_size": [[489, 500], ["texar.data.data_utils.count_file_lines"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.data.data_utils.count_file_lines"], ["", "def", "dataset_size", "(", "self", ")", ":", "\n", "        ", "\"\"\"Returns the number of data instances in the data files.\n\n        Note that this is the total data count in the raw files, before any\n        filtering and truncation.\n        \"\"\"", "\n", "if", "not", "self", ".", "_dataset_size", ":", "\n", "# pylint: disable=attribute-defined-outside-init", "\n", "            ", "self", ".", "_dataset_size", "=", "count_file_lines", "(", "\n", "self", ".", "_hparams", ".", "dataset", ".", "files", ")", "\n", "", "return", "self", ".", "_dataset_size", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.mono_text_data.MonoTextData.vocab": [[501, 506], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "vocab", "(", "self", ")", ":", "\n", "        ", "\"\"\"The vocabulary, an instance of :class:`~texar.data.Vocab`.\n        \"\"\"", "\n", "return", "self", ".", "_vocab", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.mono_text_data.MonoTextData.embedding_init_value": [[507, 515], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "embedding_init_value", "(", "self", ")", ":", "\n", "        ", "\"\"\"The `Tensor` containing the embedding value loaded from file.\n        `None` if embedding is not specified.\n        \"\"\"", "\n", "if", "self", ".", "_embedding", "is", "None", ":", "\n", "            ", "return", "None", "\n", "", "return", "self", ".", "_embedding", ".", "word_vecs", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.mono_text_data.MonoTextData.text_name": [[516, 524], ["texar.data.data.dataset_utils._connect_name"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.data.dataset_utils._connect_name"], ["", "@", "property", "\n", "def", "text_name", "(", "self", ")", ":", "\n", "        ", "\"\"\"The name of text tensor, \"text\" by default.\n        \"\"\"", "\n", "name", "=", "dsutils", ".", "_connect_name", "(", "\n", "self", ".", "_data_spec", ".", "name_prefix", ",", "\n", "self", ".", "_data_spec", ".", "decoder", ".", "text_tensor_name", ")", "\n", "return", "name", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.mono_text_data.MonoTextData.length_name": [[525, 533], ["texar.data.data.dataset_utils._connect_name"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.data.dataset_utils._connect_name"], ["", "@", "property", "\n", "def", "length_name", "(", "self", ")", ":", "\n", "        ", "\"\"\"The name of length tensor, \"length\" by default.\n        \"\"\"", "\n", "name", "=", "dsutils", ".", "_connect_name", "(", "\n", "self", ".", "_data_spec", ".", "name_prefix", ",", "\n", "self", ".", "_data_spec", ".", "decoder", ".", "length_tensor_name", ")", "\n", "return", "name", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.mono_text_data.MonoTextData.text_id_name": [[534, 542], ["texar.data.data.dataset_utils._connect_name"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.data.dataset_utils._connect_name"], ["", "@", "property", "\n", "def", "text_id_name", "(", "self", ")", ":", "\n", "        ", "\"\"\"The name of text index tensor, \"text_ids\" by default.\n        \"\"\"", "\n", "name", "=", "dsutils", ".", "_connect_name", "(", "\n", "self", ".", "_data_spec", ".", "name_prefix", ",", "\n", "self", ".", "_data_spec", ".", "decoder", ".", "text_id_tensor_name", ")", "\n", "return", "name", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.mono_text_data.MonoTextData.utterance_cnt_name": [[543, 553], ["texar.data.data.dataset_utils._connect_name", "ValueError"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.data.dataset_utils._connect_name"], ["", "@", "property", "\n", "def", "utterance_cnt_name", "(", "self", ")", ":", "\n", "        ", "\"\"\"The name of utterance count tensor, \"utterance_cnt\" by default.\n        \"\"\"", "\n", "if", "not", "self", ".", "_hparams", ".", "dataset", ".", "variable_utterance", ":", "\n", "            ", "raise", "ValueError", "(", "\"`utterance_cnt_name` is not defined.\"", ")", "\n", "", "name", "=", "dsutils", ".", "_connect_name", "(", "\n", "self", ".", "_data_spec", ".", "name_prefix", ",", "\n", "self", ".", "_data_spec", ".", "decoder", ".", "utterance_cnt_tensor_name", ")", "\n", "return", "name", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.mono_text_data._default_mono_text_dataset_hparams": [[48, 68], ["texar.data.embedding.Embedding.default_hparams"], "function", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.core.replay_memories.DequeReplayMemory.default_hparams"], ["", "def", "_default_mono_text_dataset_hparams", "(", ")", ":", "\n", "    ", "\"\"\"Returns hyperparameters of a mono text dataset with default values.\n    \"\"\"", "\n", "return", "{", "\n", "\"files\"", ":", "[", "]", ",", "\n", "\"compression_type\"", ":", "None", ",", "\n", "\"vocab_file\"", ":", "\"\"", ",", "\n", "\"embedding_init\"", ":", "Embedding", ".", "default_hparams", "(", ")", ",", "\n", "\"delimiter\"", ":", "\" \"", ",", "\n", "\"max_seq_length\"", ":", "None", ",", "\n", "\"length_filter_mode\"", ":", "\"truncate\"", ",", "\n", "\"pad_to_max_seq_length\"", ":", "False", ",", "\n", "\"bos_token\"", ":", "SpecialTokens", ".", "BOS", ",", "\n", "\"eos_token\"", ":", "SpecialTokens", ".", "EOS", ",", "\n", "\"other_transformations\"", ":", "[", "]", ",", "\n", "\"variable_utterance\"", ":", "False", ",", "\n", "\"utterance_delimiter\"", ":", "\"|||\"", ",", "\n", "\"max_utterance_cnt\"", ":", "5", ",", "\n", "\"data_name\"", ":", "None", ",", "\n", "\"@no_typecheck\"", ":", "[", "\"files\"", "]", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.scalar_data_test.ScalarDataTest.setUp": [[24, 55], ["tensorflow.test.TestCase.setUp", "numpy.linspace().tolist", "tempfile.NamedTemporaryFile", "tempfile.NamedTemporaryFile.write", "tempfile.NamedTemporaryFile.flush", "str", "numpy.linspace"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.losses.mle_losses_test.MLELossesTest.setUp"], ["def", "setUp", "(", "self", ")", ":", "\n", "        ", "tf", ".", "test", ".", "TestCase", ".", "setUp", "(", "self", ")", "\n", "\n", "# Create test data", "\n", "# pylint: disable=no-member", "\n", "int_data", "=", "np", ".", "linspace", "(", "0", ",", "100", ",", "num", "=", "101", ",", "dtype", "=", "np", ".", "int32", ")", ".", "tolist", "(", ")", "\n", "int_data", "=", "[", "str", "(", "i", ")", "for", "i", "in", "int_data", "]", "\n", "int_file", "=", "tempfile", ".", "NamedTemporaryFile", "(", ")", "\n", "int_file", ".", "write", "(", "'\\n'", ".", "join", "(", "int_data", ")", ".", "encode", "(", "\"utf-8\"", ")", ")", "\n", "int_file", ".", "flush", "(", ")", "\n", "self", ".", "_int_file", "=", "int_file", "\n", "\n", "self", ".", "_int_hparams", "=", "{", "\n", "\"num_epochs\"", ":", "1", ",", "\n", "\"batch_size\"", ":", "1", ",", "\n", "\"shuffle\"", ":", "False", ",", "\n", "\"dataset\"", ":", "{", "\n", "\"files\"", ":", "self", ".", "_int_file", ".", "name", ",", "\n", "\"data_type\"", ":", "\"int\"", ",", "\n", "\"data_name\"", ":", "\"label\"", "\n", "}", "\n", "}", "\n", "\n", "self", ".", "_float_hparams", "=", "{", "\n", "\"num_epochs\"", ":", "1", ",", "\n", "\"batch_size\"", ":", "1", ",", "\n", "\"shuffle\"", ":", "False", ",", "\n", "\"dataset\"", ":", "{", "\n", "\"files\"", ":", "self", ".", "_int_file", ".", "name", ",", "\n", "\"data_type\"", ":", "\"float\"", ",", "\n", "\"data_name\"", ":", "\"feat\"", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.scalar_data_test.ScalarDataTest._run_and_test": [[59, 93], ["texar.data.ScalarData", "scalar_data_test.ScalarDataTest.assertEqual", "texar.data.ScalarData.dataset.make_initializable_iterator", "tx.data.ScalarData.dataset.make_initializable_iterator.get_next", "scalar_data_test.ScalarDataTest.test_session", "sess.run", "sess.run", "sess.run", "sess.run", "texar.data.ScalarData.list_items", "tensorflow.global_variables_initializer", "tensorflow.local_variables_initializer", "tensorflow.tables_initializer", "sess.run", "scalar_data_test.ScalarDataTest.assertEqual", "scalar_data_test.ScalarDataTest.assertEqual", "set", "set", "scalar_data_test.ScalarDataTest.assertTrue", "scalar_data_test.ScalarDataTest.assertTrue", "print", "sess.run.keys", "texar.data.ScalarData.list_items", "isinstance", "isinstance"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.data.data_iterators.FeedableDataIterator.get_next", "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.multi_aligned_data.MultiAlignedData.list_items", "home.repos.pwc.inspect_result.VegB_Text_Infilling.texar.hyperparams.HParams.keys", "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.multi_aligned_data.MultiAlignedData.list_items"], ["", "def", "_run_and_test", "(", "self", ",", "hparams", ")", ":", "\n", "# Construct database", "\n", "        ", "scalar_data", "=", "tx", ".", "data", ".", "ScalarData", "(", "hparams", ")", "\n", "\n", "self", ".", "assertEqual", "(", "scalar_data", ".", "list_items", "(", ")", "[", "0", "]", ",", "\n", "hparams", "[", "\"dataset\"", "]", "[", "\"data_name\"", "]", ")", "\n", "\n", "iterator", "=", "scalar_data", ".", "dataset", ".", "make_initializable_iterator", "(", ")", "\n", "data_batch", "=", "iterator", ".", "get_next", "(", ")", "\n", "\n", "with", "self", ".", "test_session", "(", ")", "as", "sess", ":", "\n", "            ", "sess", ".", "run", "(", "tf", ".", "global_variables_initializer", "(", ")", ")", "\n", "sess", ".", "run", "(", "tf", ".", "local_variables_initializer", "(", ")", ")", "\n", "sess", ".", "run", "(", "tf", ".", "tables_initializer", "(", ")", ")", "\n", "sess", ".", "run", "(", "iterator", ".", "initializer", ")", "\n", "\n", "i", "=", "0", "\n", "while", "True", ":", "\n", "                ", "try", ":", "\n", "# Run the logics", "\n", "                    ", "data_batch_", "=", "sess", ".", "run", "(", "data_batch", ")", "\n", "self", ".", "assertEqual", "(", "set", "(", "data_batch_", ".", "keys", "(", ")", ")", ",", "\n", "set", "(", "scalar_data", ".", "list_items", "(", ")", ")", ")", "\n", "value", "=", "data_batch_", "[", "scalar_data", ".", "data_name", "]", "[", "0", "]", "\n", "self", ".", "assertEqual", "(", "i", ",", "value", ")", "\n", "i", "+=", "1", "\n", "# pylint: disable=no-member", "\n", "if", "hparams", "[", "\"dataset\"", "]", "[", "\"data_type\"", "]", "==", "\"int\"", ":", "\n", "                        ", "self", ".", "assertTrue", "(", "isinstance", "(", "value", ",", "np", ".", "int32", ")", ")", "\n", "", "else", ":", "\n", "                        ", "self", ".", "assertTrue", "(", "isinstance", "(", "value", ",", "np", ".", "float32", ")", ")", "\n", "", "", "except", "tf", ".", "errors", ".", "OutOfRangeError", ":", "\n", "                    ", "print", "(", "'Done -- epoch limit reached'", ")", "\n", "break", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.scalar_data_test.ScalarDataTest.test_default_setting": [[94, 99], ["scalar_data_test.ScalarDataTest._run_and_test", "scalar_data_test.ScalarDataTest._run_and_test"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.data.mono_text_data_test.VarUttMonoTextDataTest._run_and_test", "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.mono_text_data_test.VarUttMonoTextDataTest._run_and_test"], ["", "", "", "", "def", "test_default_setting", "(", "self", ")", ":", "\n", "        ", "\"\"\"Tests the logics of ScalarData.\n        \"\"\"", "\n", "self", ".", "_run_and_test", "(", "self", ".", "_int_hparams", ")", "\n", "self", ".", "_run_and_test", "(", "self", ".", "_float_hparams", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.scalar_data_test.ScalarDataTest.test_shuffle": [[100, 136], ["copy.copy", "texar.data.ScalarData", "texar.data.ScalarData.dataset.make_initializable_iterator", "tx.data.ScalarData.dataset.make_initializable_iterator.get_next", "copy.copy", "texar.data.ScalarData", "texar.data.ScalarData.dataset.make_initializable_iterator", "tx.data.ScalarData.dataset.make_initializable_iterator.get_next", "scalar_data_test.ScalarDataTest.test_session", "sess.run", "sess.run", "sess.run", "sess.run", "sess.run", "scalar_data_test.ScalarDataTest.assertEqual", "scalar_data_test.ScalarDataTest.assertSetEqual", "tensorflow.global_variables_initializer", "tensorflow.local_variables_initializer", "tensorflow.tables_initializer", "len", "len", "set", "set", "sess.run", "data_batch_[].tolist", "data_batch_sfl_[].tolist", "print"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.data.data_iterators.FeedableDataIterator.get_next", "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.data_iterators.FeedableDataIterator.get_next"], ["", "def", "test_shuffle", "(", "self", ")", ":", "\n", "        ", "\"\"\"Tests results of toggling shuffle.\n        \"\"\"", "\n", "hparams", "=", "copy", ".", "copy", "(", "self", ".", "_int_hparams", ")", "\n", "hparams", "[", "\"batch_size\"", "]", "=", "10", "\n", "scalar_data", "=", "tx", ".", "data", ".", "ScalarData", "(", "hparams", ")", "\n", "iterator", "=", "scalar_data", ".", "dataset", ".", "make_initializable_iterator", "(", ")", "\n", "data_batch", "=", "iterator", ".", "get_next", "(", ")", "\n", "\n", "hparams_sfl", "=", "copy", ".", "copy", "(", "hparams", ")", "\n", "hparams_sfl", "[", "\"shuffle\"", "]", "=", "True", "\n", "scalar_data_sfl", "=", "tx", ".", "data", ".", "ScalarData", "(", "hparams_sfl", ")", "\n", "iterator_sfl", "=", "scalar_data_sfl", ".", "dataset", ".", "make_initializable_iterator", "(", ")", "\n", "data_batch_sfl", "=", "iterator_sfl", ".", "get_next", "(", ")", "\n", "\n", "with", "self", ".", "test_session", "(", ")", "as", "sess", ":", "\n", "            ", "sess", ".", "run", "(", "tf", ".", "global_variables_initializer", "(", ")", ")", "\n", "sess", ".", "run", "(", "tf", ".", "local_variables_initializer", "(", ")", ")", "\n", "sess", ".", "run", "(", "tf", ".", "tables_initializer", "(", ")", ")", "\n", "sess", ".", "run", "(", "iterator", ".", "initializer", ")", "\n", "sess", ".", "run", "(", "iterator_sfl", ".", "initializer", ")", "\n", "\n", "vals", "=", "[", "]", "\n", "vals_sfl", "=", "[", "]", "\n", "while", "True", ":", "\n", "                ", "try", ":", "\n", "# Run the logics", "\n", "                    ", "data_batch_", ",", "data_batch_sfl_", "=", "sess", ".", "run", "(", "[", "data_batch", ",", "\n", "data_batch_sfl", "]", ")", "\n", "vals", "+=", "data_batch_", "[", "scalar_data", ".", "data_name", "]", ".", "tolist", "(", ")", "\n", "vals_sfl", "+=", "data_batch_sfl_", "[", "scalar_data", ".", "data_name", "]", ".", "tolist", "(", ")", "\n", "", "except", "tf", ".", "errors", ".", "OutOfRangeError", ":", "\n", "                    ", "print", "(", "'Done -- epoch limit reached'", ")", "\n", "break", "\n", "", "", "self", ".", "assertEqual", "(", "len", "(", "vals", ")", ",", "len", "(", "vals_sfl", ")", ")", "\n", "self", ".", "assertSetEqual", "(", "set", "(", "vals", ")", ",", "set", "(", "vals_sfl", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.paired_text_data.PairedTextData.__init__": [[76, 80], ["texar.data.data.text_data_base.TextDataBase.__init__", "tensorflow.name_scope", "paired_text_data.PairedTextData._make_data", "paired_text_data.PairedTextData.default_hparams"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.text_infilling.self_attn_hyperparams.Hyperparams.__init__", "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.multi_aligned_data.MultiAlignedData._make_data", "home.repos.pwc.inspect_result.VegB_Text_Infilling.core.replay_memories.DequeReplayMemory.default_hparams"], ["def", "__init__", "(", "self", ",", "hparams", ")", ":", "\n", "        ", "TextDataBase", ".", "__init__", "(", "self", ",", "hparams", ")", "\n", "with", "tf", ".", "name_scope", "(", "self", ".", "name", ",", "self", ".", "default_hparams", "(", ")", "[", "\"name\"", "]", ")", ":", "\n", "            ", "self", ".", "_make_data", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.paired_text_data.PairedTextData.default_hparams": [[81, 89], ["texar.data.data.text_data_base.TextDataBase.default_hparams", "texar.data.data.text_data_base.TextDataBase.default_hparams.update", "paired_text_data._default_paired_text_dataset_hparams"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.core.replay_memories.DequeReplayMemory.default_hparams", "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.paired_text_data._default_paired_text_dataset_hparams"], ["", "", "@", "staticmethod", "\n", "def", "default_hparams", "(", ")", ":", "\n", "        ", "\"\"\"Returns a dicitionary of default hyperparameters.\n        \"\"\"", "\n", "hparams", "=", "TextDataBase", ".", "default_hparams", "(", ")", "\n", "hparams", "[", "\"name\"", "]", "=", "\"paired_text_data\"", "\n", "hparams", ".", "update", "(", "_default_paired_text_dataset_hparams", "(", ")", ")", "\n", "return", "hparams", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.paired_text_data.PairedTextData.make_vocab": [[90, 129], ["texar.data.data.mono_text_data.MonoTextData.make_vocab", "texar.utils.utils.default_str", "texar.utils.utils.default_str", "texar.data.vocabulary.Vocab", "texar.data.vocabulary.Vocab"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.data.multi_aligned_data.MultiAlignedData.make_vocab", "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.utils.default_str", "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.utils.default_str"], ["", "@", "staticmethod", "\n", "def", "make_vocab", "(", "src_hparams", ",", "tgt_hparams", ")", ":", "\n", "        ", "\"\"\"Reads vocab files and returns source vocab and target vocab.\n\n        Args:\n            src_hparams (dict or HParams): Hyperparameters of source dataset.\n            tgt_hparams (dict or HParams): Hyperparameters of target dataset.\n\n        Returns:\n            A pair of :class:`texar.data.Vocab` instances. The two instances\n            may be the same objects if source and target vocabs are shared\n            and have the same other configs.\n        \"\"\"", "\n", "src_vocab", "=", "MonoTextData", ".", "make_vocab", "(", "src_hparams", ")", "\n", "\n", "if", "tgt_hparams", "[", "\"processing_share\"", "]", ":", "\n", "            ", "tgt_bos_token", "=", "src_hparams", "[", "\"bos_token\"", "]", "\n", "tgt_eos_token", "=", "src_hparams", "[", "\"eos_token\"", "]", "\n", "", "else", ":", "\n", "            ", "tgt_bos_token", "=", "tgt_hparams", "[", "\"bos_token\"", "]", "\n", "tgt_eos_token", "=", "tgt_hparams", "[", "\"eos_token\"", "]", "\n", "", "tgt_bos_token", "=", "utils", ".", "default_str", "(", "tgt_bos_token", ",", "\n", "SpecialTokens", ".", "BOS", ")", "\n", "tgt_eos_token", "=", "utils", ".", "default_str", "(", "tgt_eos_token", ",", "\n", "SpecialTokens", ".", "EOS", ")", "\n", "if", "tgt_hparams", "[", "\"vocab_share\"", "]", ":", "\n", "            ", "if", "tgt_bos_token", "==", "src_vocab", ".", "bos_token", "and", "tgt_eos_token", "==", "src_vocab", ".", "eos_token", ":", "\n", "                ", "tgt_vocab", "=", "src_vocab", "\n", "", "else", ":", "\n", "                ", "tgt_vocab", "=", "Vocab", "(", "src_hparams", "[", "\"vocab_file\"", "]", ",", "\n", "bos_token", "=", "tgt_bos_token", ",", "\n", "eos_token", "=", "tgt_eos_token", ")", "\n", "", "", "else", ":", "\n", "            ", "tgt_vocab", "=", "Vocab", "(", "tgt_hparams", "[", "\"vocab_file\"", "]", ",", "\n", "bos_token", "=", "tgt_bos_token", ",", "\n", "eos_token", "=", "tgt_eos_token", ")", "\n", "\n", "", "return", "src_vocab", ",", "tgt_vocab", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.paired_text_data.PairedTextData.make_embedding": [[131, 151], ["texar.data.data.mono_text_data.MonoTextData.make_embedding", "texar.data.embedding.Embedding"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.data.multi_aligned_data.MultiAlignedData.make_embedding"], ["", "@", "staticmethod", "\n", "def", "make_embedding", "(", "src_emb_hparams", ",", "src_token_to_id_map", ",", "\n", "tgt_emb_hparams", "=", "None", ",", "tgt_token_to_id_map", "=", "None", ",", "\n", "emb_init_share", "=", "False", ")", ":", "\n", "        ", "\"\"\"Optionally loads source and target embeddings from files\n        (if provided), and returns respective :class:`texar.data.Embedding`\n        instances.\n        \"\"\"", "\n", "src_embedding", "=", "MonoTextData", ".", "make_embedding", "(", "src_emb_hparams", ",", "\n", "src_token_to_id_map", ")", "\n", "\n", "if", "emb_init_share", ":", "\n", "            ", "tgt_embedding", "=", "src_embedding", "\n", "", "else", ":", "\n", "            ", "tgt_emb_file", "=", "tgt_emb_hparams", "[", "\"file\"", "]", "\n", "tgt_embedding", "=", "None", "\n", "if", "tgt_emb_file", "is", "not", "None", "and", "tgt_emb_file", "!=", "\"\"", ":", "\n", "                ", "tgt_embedding", "=", "Embedding", "(", "tgt_token_to_id_map", ",", "tgt_emb_hparams", ")", "\n", "\n", "", "", "return", "src_embedding", ",", "tgt_embedding", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.paired_text_data.PairedTextData._make_dataset": [[152, 160], ["tensorflow.data.TextLineDataset", "tensorflow.data.TextLineDataset", "tensorflow.data.Dataset.zip"], "methods", ["None"], ["", "def", "_make_dataset", "(", "self", ")", ":", "\n", "        ", "src_dataset", "=", "tf", ".", "data", ".", "TextLineDataset", "(", "\n", "self", ".", "_hparams", ".", "source_dataset", ".", "files", ",", "\n", "compression_type", "=", "self", ".", "_hparams", ".", "source_dataset", ".", "compression_type", ")", "\n", "tgt_dataset", "=", "tf", ".", "data", ".", "TextLineDataset", "(", "\n", "self", ".", "_hparams", ".", "target_dataset", ".", "files", ",", "\n", "compression_type", "=", "self", ".", "_hparams", ".", "target_dataset", ".", "compression_type", ")", "\n", "return", "tf", ".", "data", ".", "Dataset", ".", "zip", "(", "(", "src_dataset", ",", "tgt_dataset", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.paired_text_data.PairedTextData._get_name_prefix": [[161, 169], ["ValueError"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_get_name_prefix", "(", "src_hparams", ",", "tgt_hparams", ")", ":", "\n", "        ", "name_prefix", "=", "[", "\n", "src_hparams", "[", "\"data_name\"", "]", ",", "tgt_hparams", "[", "\"data_name\"", "]", "]", "\n", "if", "name_prefix", "[", "0", "]", "==", "name_prefix", "[", "1", "]", ":", "\n", "            ", "raise", "ValueError", "(", "\"'data_name' of source and target \"", "\n", "\"datasets cannot be the same.\"", ")", "\n", "", "return", "name_prefix", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.paired_text_data.PairedTextData._make_processor": [[170, 200], ["data_spec.get_ith_data_spec", "texar.data.data.mono_text_data.MonoTextData._make_processor", "data_spec.set_ith_data_spec", "data_spec.get_ith_data_spec", "texar.data.data.mono_text_data.MonoTextData._make_processor", "data_spec.set_ith_data_spec", "texar.data.data.dataset_utils.make_combined_transformation", "data_spec.add_spec", "copy.copy"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.data.dataset_utils._DataSpec.get_ith_data_spec", "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.multi_aligned_data.MultiAlignedData._make_processor", "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.dataset_utils._DataSpec.set_ith_data_spec", "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.dataset_utils._DataSpec.get_ith_data_spec", "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.multi_aligned_data.MultiAlignedData._make_processor", "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.dataset_utils._DataSpec.set_ith_data_spec", "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.dataset_utils.make_combined_transformation", "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.dataset_utils._DataSpec.add_spec"], ["", "@", "staticmethod", "\n", "def", "_make_processor", "(", "src_hparams", ",", "tgt_hparams", ",", "data_spec", ",", "name_prefix", ")", ":", "\n", "# Create source data decoder", "\n", "        ", "data_spec_i", "=", "data_spec", ".", "get_ith_data_spec", "(", "0", ")", "\n", "src_decoder", ",", "src_trans", ",", "data_spec_i", "=", "MonoTextData", ".", "_make_processor", "(", "\n", "src_hparams", ",", "data_spec_i", ",", "chained", "=", "False", ")", "\n", "data_spec", ".", "set_ith_data_spec", "(", "0", ",", "data_spec_i", ",", "2", ")", "\n", "\n", "# Create target data decoder", "\n", "tgt_proc_hparams", "=", "tgt_hparams", "\n", "if", "tgt_hparams", "[", "\"processing_share\"", "]", ":", "\n", "            ", "tgt_proc_hparams", "=", "copy", ".", "copy", "(", "src_hparams", ")", "\n", "try", ":", "\n", "                ", "tgt_proc_hparams", "[", "\"variable_utterance\"", "]", "=", "tgt_hparams", "[", "\"variable_utterance\"", "]", "\n", "", "except", "TypeError", ":", "\n", "                ", "tgt_proc_hparams", ".", "variable_utterance", "=", "tgt_hparams", "[", "\"variable_utterance\"", "]", "\n", "", "", "data_spec_i", "=", "data_spec", ".", "get_ith_data_spec", "(", "1", ")", "\n", "tgt_decoder", ",", "tgt_trans", ",", "data_spec_i", "=", "MonoTextData", ".", "_make_processor", "(", "\n", "tgt_proc_hparams", ",", "data_spec_i", ",", "chained", "=", "False", ")", "\n", "data_spec", ".", "set_ith_data_spec", "(", "1", ",", "data_spec_i", ",", "2", ")", "\n", "\n", "tran_fn", "=", "dsutils", ".", "make_combined_transformation", "(", "\n", "[", "[", "src_decoder", "]", "+", "src_trans", ",", "[", "tgt_decoder", "]", "+", "tgt_trans", "]", ",", "\n", "name_prefix", "=", "name_prefix", ")", "\n", "\n", "data_spec", ".", "add_spec", "(", "name_prefix", "=", "name_prefix", ")", "\n", "\n", "return", "tran_fn", ",", "data_spec", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.paired_text_data.PairedTextData._make_length_filter": [[201, 212], ["texar.data.data.mono_text_data.MonoTextData._make_length_filter", "texar.data.data.mono_text_data.MonoTextData._make_length_filter", "texar.data.data.dataset_utils._make_combined_filter_fn"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.data.multi_aligned_data.MultiAlignedData._make_length_filter", "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.multi_aligned_data.MultiAlignedData._make_length_filter", "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.dataset_utils._make_combined_filter_fn"], ["", "@", "staticmethod", "\n", "def", "_make_length_filter", "(", "src_hparams", ",", "tgt_hparams", ",", "\n", "src_length_name", ",", "tgt_length_name", ",", "\n", "src_decoder", ",", "tgt_decoder", ")", ":", "\n", "        ", "src_filter_fn", "=", "MonoTextData", ".", "_make_length_filter", "(", "\n", "src_hparams", ",", "src_length_name", ",", "src_decoder", ")", "\n", "tgt_filter_fn", "=", "MonoTextData", ".", "_make_length_filter", "(", "\n", "tgt_hparams", ",", "tgt_length_name", ",", "tgt_decoder", ")", "\n", "combined_filter_fn", "=", "dsutils", ".", "_make_combined_filter_fn", "(", "\n", "[", "src_filter_fn", ",", "tgt_filter_fn", "]", ")", "\n", "return", "combined_filter_fn", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.paired_text_data.PairedTextData._process_dataset": [[213, 243], ["paired_text_data.PairedTextData._get_name_prefix", "paired_text_data.PairedTextData._make_processor", "dataset.filter.filter.map", "texar.data.data.dataset_utils._connect_name", "texar.data.data.dataset_utils._connect_name", "paired_text_data.PairedTextData._make_length_filter", "dataset.filter.filter.take", "dataset.filter.filter.filter", "tran_fn", "texar.data.data.dataset_utils.maybe_tuple"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.data.multi_aligned_data.MultiAlignedData._get_name_prefix", "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.multi_aligned_data.MultiAlignedData._make_processor", "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.dataset_utils._connect_name", "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.dataset_utils._connect_name", "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.multi_aligned_data.MultiAlignedData._make_length_filter", "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.dataset_utils.maybe_tuple"], ["", "def", "_process_dataset", "(", "self", ",", "dataset", ",", "hparams", ",", "data_spec", ")", ":", "\n", "        ", "name_prefix", "=", "PairedTextData", ".", "_get_name_prefix", "(", "\n", "hparams", "[", "\"source_dataset\"", "]", ",", "hparams", "[", "\"target_dataset\"", "]", ")", "\n", "tran_fn", ",", "data_spec", "=", "self", ".", "_make_processor", "(", "\n", "hparams", "[", "\"source_dataset\"", "]", ",", "hparams", "[", "\"target_dataset\"", "]", ",", "\n", "data_spec", ",", "name_prefix", "=", "name_prefix", ")", "\n", "\n", "num_parallel_calls", "=", "hparams", "[", "\"num_parallel_calls\"", "]", "\n", "dataset", "=", "dataset", ".", "map", "(", "\n", "lambda", "*", "args", ":", "tran_fn", "(", "dsutils", ".", "maybe_tuple", "(", "args", ")", ")", ",", "\n", "num_parallel_calls", "=", "num_parallel_calls", ")", "\n", "\n", "# Filters by length", "\n", "src_length_name", "=", "dsutils", ".", "_connect_name", "(", "\n", "data_spec", ".", "name_prefix", "[", "0", "]", ",", "\n", "data_spec", ".", "decoder", "[", "0", "]", ".", "length_tensor_name", ")", "\n", "tgt_length_name", "=", "dsutils", ".", "_connect_name", "(", "\n", "data_spec", ".", "name_prefix", "[", "1", "]", ",", "\n", "data_spec", ".", "decoder", "[", "1", "]", ".", "length_tensor_name", ")", "\n", "filter_fn", "=", "self", ".", "_make_length_filter", "(", "\n", "hparams", "[", "\"source_dataset\"", "]", ",", "hparams", "[", "\"target_dataset\"", "]", ",", "\n", "src_length_name", ",", "tgt_length_name", ",", "\n", "data_spec", ".", "decoder", "[", "0", "]", ",", "data_spec", ".", "decoder", "[", "1", "]", ")", "\n", "if", "filter_fn", ":", "\n", "            ", "dataset", "=", "dataset", ".", "filter", "(", "filter_fn", ")", "\n", "\n", "# Truncates data count", "\n", "", "dataset", "=", "dataset", ".", "take", "(", "hparams", "[", "\"max_dataset_size\"", "]", ")", "\n", "\n", "return", "dataset", ",", "data_spec", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.paired_text_data.PairedTextData._make_bucket_length_fn": [[244, 253], ["tensorflow.maximum", "texar.utils.dtypes.is_callable", "texar.utils.utils.get_function"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.dtypes.is_callable", "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.utils.get_function"], ["", "def", "_make_bucket_length_fn", "(", "self", ")", ":", "\n", "        ", "length_fn", "=", "self", ".", "_hparams", ".", "bucket_length_fn", "\n", "if", "not", "length_fn", ":", "\n", "            ", "length_fn", "=", "lambda", "x", ":", "tf", ".", "maximum", "(", "\n", "x", "[", "self", ".", "source_length_name", "]", ",", "x", "[", "self", ".", "target_length_name", "]", ")", "\n", "", "elif", "not", "is_callable", "(", "length_fn", ")", ":", "\n", "# pylint: disable=redefined-variable-type", "\n", "            ", "length_fn", "=", "utils", ".", "get_function", "(", "length_fn", ",", "[", "\"texar.custom\"", "]", ")", "\n", "", "return", "length_fn", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.paired_text_data.PairedTextData._make_padded_shapes": [[254, 274], ["padded_shapes.update", "padded_shapes.update", "texar.data.data.mono_text_data.MonoTextData._make_padded_text_and_id_shapes", "texar.data.data.mono_text_data.MonoTextData._make_padded_text_and_id_shapes"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.data.mono_text_data.MonoTextData._make_padded_text_and_id_shapes", "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.mono_text_data.MonoTextData._make_padded_text_and_id_shapes"], ["", "def", "_make_padded_shapes", "(", "self", ",", "dataset", ",", "src_decoder", ",", "tgt_decoder", ")", ":", "\n", "        ", "src_text_and_id_shapes", "=", "{", "}", "\n", "if", "self", ".", "_hparams", ".", "source_dataset", ".", "pad_to_max_seq_length", ":", "\n", "            ", "src_text_and_id_shapes", "=", "MonoTextData", ".", "_make_padded_text_and_id_shapes", "(", "\n", "dataset", ",", "self", ".", "_hparams", ".", "source_dataset", ",", "src_decoder", ",", "\n", "self", ".", "source_text_name", ",", "self", ".", "source_text_id_name", ")", "\n", "\n", "", "tgt_text_and_id_shapes", "=", "{", "}", "\n", "if", "self", ".", "_hparams", ".", "target_dataset", ".", "pad_to_max_seq_length", ":", "\n", "            ", "tgt_text_and_id_shapes", "=", "MonoTextData", ".", "_make_padded_text_and_id_shapes", "(", "\n", "dataset", ",", "self", ".", "_hparams", ".", "target_dataset", ",", "tgt_decoder", ",", "\n", "self", ".", "target_text_name", ",", "self", ".", "target_text_id_name", ")", "\n", "\n", "", "padded_shapes", "=", "dataset", ".", "output_shapes", "\n", "padded_shapes", ".", "update", "(", "src_text_and_id_shapes", ")", "\n", "padded_shapes", ".", "update", "(", "tgt_text_and_id_shapes", ")", "\n", "\n", "return", "padded_shapes", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.paired_text_data.PairedTextData._make_data": [[275, 321], ["paired_text_data.PairedTextData.make_vocab", "paired_text_data.PairedTextData.make_embedding", "paired_text_data.PairedTextData._make_dataset", "paired_text_data.PairedTextData._shuffle_dataset", "texar.data.data.dataset_utils._DataSpec", "paired_text_data.PairedTextData._process_dataset", "paired_text_data.PairedTextData._make_bucket_length_fn", "paired_text_data.PairedTextData._make_padded_shapes", "paired_text_data.PairedTextData._make_batch", "ValueError", "dataset.prefetch.prefetch.prefetch"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.data.multi_aligned_data.MultiAlignedData.make_vocab", "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.multi_aligned_data.MultiAlignedData.make_embedding", "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.multi_aligned_data.MultiAlignedData._make_dataset", "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.data_base.DataBase._shuffle_dataset", "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.multi_aligned_data.MultiAlignedData._process_dataset", "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.multi_aligned_data.MultiAlignedData._make_bucket_length_fn", "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.multi_aligned_data.MultiAlignedData._make_padded_shapes", "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.text_data_base.TextDataBase._make_batch"], ["", "def", "_make_data", "(", "self", ")", ":", "\n", "        ", "self", ".", "_src_vocab", ",", "self", ".", "_tgt_vocab", "=", "self", ".", "make_vocab", "(", "\n", "self", ".", "_hparams", ".", "source_dataset", ",", "self", ".", "_hparams", ".", "target_dataset", ")", "\n", "\n", "tgt_hparams", "=", "self", ".", "_hparams", ".", "target_dataset", "\n", "if", "not", "tgt_hparams", ".", "vocab_share", "and", "tgt_hparams", ".", "embedding_init_share", ":", "\n", "            ", "raise", "ValueError", "(", "\"embedding_init can be shared only when vocab \"", "\n", "\"is shared. Got `vocab_share=False, \"", "\n", "\"emb_init_share=True`.\"", ")", "\n", "", "self", ".", "_src_embedding", ",", "self", ".", "_tgt_embedding", "=", "self", ".", "make_embedding", "(", "\n", "self", ".", "_hparams", ".", "source_dataset", ".", "embedding_init", ",", "\n", "self", ".", "_src_vocab", ".", "token_to_id_map_py", ",", "\n", "self", ".", "_hparams", ".", "target_dataset", ".", "embedding_init", ",", "\n", "self", ".", "_tgt_vocab", ".", "token_to_id_map_py", ",", "\n", "self", ".", "_hparams", ".", "target_dataset", ".", "embedding_init_share", ")", "\n", "\n", "# Create dataset", "\n", "dataset", "=", "self", ".", "_make_dataset", "(", ")", "\n", "dataset", ",", "dataset_size", "=", "self", ".", "_shuffle_dataset", "(", "\n", "dataset", ",", "self", ".", "_hparams", ",", "self", ".", "_hparams", ".", "source_dataset", ".", "files", ")", "\n", "self", ".", "_dataset_size", "=", "dataset_size", "\n", "\n", "# Processing.", "\n", "data_spec", "=", "dsutils", ".", "_DataSpec", "(", "\n", "dataset", "=", "dataset", ",", "dataset_size", "=", "self", ".", "_dataset_size", ",", "\n", "vocab", "=", "[", "self", ".", "_src_vocab", ",", "self", ".", "_tgt_vocab", "]", ",", "\n", "embedding", "=", "[", "self", ".", "_src_embedding", ",", "self", ".", "_tgt_embedding", "]", ")", "\n", "dataset", ",", "data_spec", "=", "self", ".", "_process_dataset", "(", "\n", "dataset", ",", "self", ".", "_hparams", ",", "data_spec", ")", "\n", "self", ".", "_data_spec", "=", "data_spec", "\n", "self", ".", "_decoder", "=", "data_spec", ".", "decoder", "\n", "self", ".", "_src_decoder", "=", "data_spec", ".", "decoder", "[", "0", "]", "\n", "self", ".", "_tgt_decoder", "=", "data_spec", ".", "decoder", "[", "1", "]", "\n", "\n", "# Batching", "\n", "length_fn", "=", "self", ".", "_make_bucket_length_fn", "(", ")", "\n", "padded_shapes", "=", "self", ".", "_make_padded_shapes", "(", "\n", "dataset", ",", "self", ".", "_src_decoder", ",", "self", ".", "_tgt_decoder", ")", "\n", "dataset", "=", "self", ".", "_make_batch", "(", "\n", "dataset", ",", "self", ".", "_hparams", ",", "length_fn", ",", "padded_shapes", ")", "\n", "\n", "# Prefetching", "\n", "if", "self", ".", "_hparams", ".", "prefetch_buffer_size", ">", "0", ":", "\n", "            ", "dataset", "=", "dataset", ".", "prefetch", "(", "self", ".", "_hparams", ".", "prefetch_buffer_size", ")", "\n", "\n", "", "self", ".", "_dataset", "=", "dataset", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.paired_text_data.PairedTextData.list_items": [[322, 329], ["list", "paired_text_data.PairedTextData._dataset.output_types.keys"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.texar.hyperparams.HParams.keys"], ["", "def", "list_items", "(", "self", ")", ":", "\n", "        ", "\"\"\"Returns the list of item names that the data can produce.\n\n        Returns:\n            A list of strings.\n        \"\"\"", "\n", "return", "list", "(", "self", ".", "_dataset", ".", "output_types", ".", "keys", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.paired_text_data.PairedTextData.dataset": [[330, 335], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "dataset", "(", "self", ")", ":", "\n", "        ", "\"\"\"The dataset.\n        \"\"\"", "\n", "return", "self", ".", "_dataset", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.paired_text_data.PairedTextData.dataset_size": [[336, 347], ["texar.data.data_utils.count_file_lines"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.data.data_utils.count_file_lines"], ["", "def", "dataset_size", "(", "self", ")", ":", "\n", "        ", "\"\"\"Returns the number of data instances in the dataset.\n\n        Note that this is the total data count in the raw files, before any\n        filtering and truncation.\n        \"\"\"", "\n", "if", "not", "self", ".", "_dataset_size", ":", "\n", "# pylint: disable=attribute-defined-outside-init", "\n", "            ", "self", ".", "_dataset_size", "=", "count_file_lines", "(", "\n", "self", ".", "_hparams", ".", "source_dataset", ".", "files", ")", "\n", "", "return", "self", ".", "_dataset_size", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.paired_text_data.PairedTextData.vocab": [[348, 354], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "vocab", "(", "self", ")", ":", "\n", "        ", "\"\"\"A pair instances of :class:`~texar.data.Vocab` that are source\n        and target vocabs, respectively.\n        \"\"\"", "\n", "return", "self", ".", "_src_vocab", ",", "self", ".", "_tgt_vocab", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.paired_text_data.PairedTextData.source_vocab": [[355, 360], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "source_vocab", "(", "self", ")", ":", "\n", "        ", "\"\"\"The source vocab, an instance of :class:`~texar.data.Vocab`.\n        \"\"\"", "\n", "return", "self", ".", "_src_vocab", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.paired_text_data.PairedTextData.target_vocab": [[361, 366], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "target_vocab", "(", "self", ")", ":", "\n", "        ", "\"\"\"The target vocab, an instance of :class:`~texar.data.Vocab`.\n        \"\"\"", "\n", "return", "self", ".", "_tgt_vocab", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.paired_text_data.PairedTextData.source_embedding_init_value": [[367, 375], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "source_embedding_init_value", "(", "self", ")", ":", "\n", "        ", "\"\"\"The `Tensor` containing the embedding value of source data\n        loaded from file. `None` if embedding is not specified.\n        \"\"\"", "\n", "if", "self", ".", "_src_embedding", "is", "None", ":", "\n", "            ", "return", "None", "\n", "", "return", "self", ".", "_src_embedding", ".", "word_vecs", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.paired_text_data.PairedTextData.target_embedding_init_value": [[376, 384], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "target_embedding_init_value", "(", "self", ")", ":", "\n", "        ", "\"\"\"The `Tensor` containing the embedding value of target data\n        loaded from file. `None` if embedding is not specified.\n        \"\"\"", "\n", "if", "self", ".", "_tgt_embedding", "is", "None", ":", "\n", "            ", "return", "None", "\n", "", "return", "self", ".", "_tgt_embedding", ".", "word_vecs", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.paired_text_data.PairedTextData.embedding_init_value": [[385, 392], ["None"], "methods", ["None"], ["", "def", "embedding_init_value", "(", "self", ")", ":", "\n", "        ", "\"\"\"A pair of `Tensor` containing the embedding values of source and\n        target data loaded from file.\n        \"\"\"", "\n", "src_emb", "=", "self", ".", "source_embedding_init_value", "\n", "tgt_emb", "=", "self", ".", "target_embedding_init_value", "\n", "return", "src_emb", ",", "tgt_emb", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.paired_text_data.PairedTextData.source_text_name": [[393, 401], ["texar.data.data.dataset_utils._connect_name"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.data.dataset_utils._connect_name"], ["", "@", "property", "\n", "def", "source_text_name", "(", "self", ")", ":", "\n", "        ", "\"\"\"The name of the source text tensor.\n        \"\"\"", "\n", "name", "=", "dsutils", ".", "_connect_name", "(", "\n", "self", ".", "_data_spec", ".", "name_prefix", "[", "0", "]", ",", "\n", "self", ".", "_src_decoder", ".", "text_tensor_name", ")", "\n", "return", "name", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.paired_text_data.PairedTextData.source_length_name": [[402, 410], ["texar.data.data.dataset_utils._connect_name"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.data.dataset_utils._connect_name"], ["", "@", "property", "\n", "def", "source_length_name", "(", "self", ")", ":", "\n", "        ", "\"\"\"The name of the source length tensor.\n        \"\"\"", "\n", "name", "=", "dsutils", ".", "_connect_name", "(", "\n", "self", ".", "_data_spec", ".", "name_prefix", "[", "0", "]", ",", "\n", "self", ".", "_src_decoder", ".", "length_tensor_name", ")", "\n", "return", "name", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.paired_text_data.PairedTextData.source_text_id_name": [[411, 419], ["texar.data.data.dataset_utils._connect_name"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.data.dataset_utils._connect_name"], ["", "@", "property", "\n", "def", "source_text_id_name", "(", "self", ")", ":", "\n", "        ", "\"\"\"The name of the source text index tensor.\n        \"\"\"", "\n", "name", "=", "dsutils", ".", "_connect_name", "(", "\n", "self", ".", "_data_spec", ".", "name_prefix", "[", "0", "]", ",", "\n", "self", ".", "_src_decoder", ".", "text_id_tensor_name", ")", "\n", "return", "name", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.paired_text_data.PairedTextData.source_utterance_cnt_name": [[420, 431], ["texar.data.data.dataset_utils._connect_name", "ValueError"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.data.dataset_utils._connect_name"], ["", "@", "property", "\n", "def", "source_utterance_cnt_name", "(", "self", ")", ":", "\n", "        ", "\"\"\"The name of the source text utterance count tensor.\n        \"\"\"", "\n", "if", "not", "self", ".", "_hparams", ".", "source_dataset", ".", "variable_utterance", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "\"`utterance_cnt_name` of source data is undefined.\"", ")", "\n", "", "name", "=", "dsutils", ".", "_connect_name", "(", "\n", "self", ".", "_data_spec", ".", "name_prefix", "[", "0", "]", ",", "\n", "self", ".", "_src_decoder", ".", "utterance_cnt_tensor_name", ")", "\n", "return", "name", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.paired_text_data.PairedTextData.target_text_name": [[432, 440], ["texar.data.data.dataset_utils._connect_name"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.data.dataset_utils._connect_name"], ["", "@", "property", "\n", "def", "target_text_name", "(", "self", ")", ":", "\n", "        ", "\"\"\"The name of the target text tensor.\n        \"\"\"", "\n", "name", "=", "dsutils", ".", "_connect_name", "(", "\n", "self", ".", "_data_spec", ".", "name_prefix", "[", "1", "]", ",", "\n", "self", ".", "_tgt_decoder", ".", "text_tensor_name", ")", "\n", "return", "name", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.paired_text_data.PairedTextData.target_length_name": [[441, 449], ["texar.data.data.dataset_utils._connect_name"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.data.dataset_utils._connect_name"], ["", "@", "property", "\n", "def", "target_length_name", "(", "self", ")", ":", "\n", "        ", "\"\"\"The name of the target length tensor.\n        \"\"\"", "\n", "name", "=", "dsutils", ".", "_connect_name", "(", "\n", "self", ".", "_data_spec", ".", "name_prefix", "[", "1", "]", ",", "\n", "self", ".", "_tgt_decoder", ".", "length_tensor_name", ")", "\n", "return", "name", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.paired_text_data.PairedTextData.target_text_id_name": [[450, 458], ["texar.data.data.dataset_utils._connect_name"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.data.dataset_utils._connect_name"], ["", "@", "property", "\n", "def", "target_text_id_name", "(", "self", ")", ":", "\n", "        ", "\"\"\"The name of the target text index tensor.\n        \"\"\"", "\n", "name", "=", "dsutils", ".", "_connect_name", "(", "\n", "self", ".", "_data_spec", ".", "name_prefix", "[", "1", "]", ",", "\n", "self", ".", "_tgt_decoder", ".", "text_id_tensor_name", ")", "\n", "return", "name", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.paired_text_data.PairedTextData.target_utterance_cnt_name": [[459, 470], ["texar.data.data.dataset_utils._connect_name", "ValueError"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.data.dataset_utils._connect_name"], ["", "@", "property", "\n", "def", "target_utterance_cnt_name", "(", "self", ")", ":", "\n", "        ", "\"\"\"The name of the target text utterance count tensor.\n        \"\"\"", "\n", "if", "not", "self", ".", "_hparams", ".", "target_dataset", ".", "variable_utterance", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "\"`utterance_cnt_name` of target data is undefined.\"", ")", "\n", "", "name", "=", "dsutils", ".", "_connect_name", "(", "\n", "self", ".", "_data_spec", ".", "name_prefix", "[", "1", "]", ",", "\n", "self", ".", "_tgt_decoder", ".", "utterance_cnt_tensor_name", ")", "\n", "return", "name", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.paired_text_data.PairedTextData.text_name": [[471, 476], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "text_name", "(", "self", ")", ":", "\n", "        ", "\"\"\"The name of text tensor.\n        \"\"\"", "\n", "return", "self", ".", "_src_decoder", ".", "text_tensor_name", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.paired_text_data.PairedTextData.length_name": [[477, 482], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "length_name", "(", "self", ")", ":", "\n", "        ", "\"\"\"The name of length tensor.\n        \"\"\"", "\n", "return", "self", ".", "_src_decoder", ".", "length_tensor_name", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.paired_text_data.PairedTextData.text_id_name": [[483, 488], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "text_id_name", "(", "self", ")", ":", "\n", "        ", "\"\"\"The name of text index tensor.\n        \"\"\"", "\n", "return", "self", ".", "_src_decoder", ".", "text_id_tensor_name", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.paired_text_data.PairedTextData.utterance_cnt_name": [[489, 498], ["ValueError"], "methods", ["None"], ["", "@", "property", "\n", "def", "utterance_cnt_name", "(", "self", ")", ":", "\n", "        ", "\"\"\"The name of the target text utterance count tensor.\n        \"\"\"", "\n", "if", "self", ".", "_hparams", ".", "source_dataset", ".", "variable_utterance", ":", "\n", "            ", "return", "self", ".", "_src_decoder", ".", "utterance_cnt_tensor_name", "\n", "", "if", "self", ".", "_hparams", ".", "target_dataset", ".", "variable_utterance", ":", "\n", "            ", "return", "self", ".", "_tgt_decoder", ".", "utterance_cnt_tensor_name", "\n", "", "raise", "ValueError", "(", "\"`utterance_cnt_name` is not defined.\"", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.paired_text_data._default_paired_text_dataset_hparams": [[45, 64], ["texar.data.data.mono_text_data._default_mono_text_dataset_hparams", "texar.data.data.mono_text_data._default_mono_text_dataset_hparams", "texar.data.data.mono_text_data._default_mono_text_dataset_hparams.update"], "function", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.data.mono_text_data._default_mono_text_dataset_hparams", "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.mono_text_data._default_mono_text_dataset_hparams"], ["def", "_default_paired_text_dataset_hparams", "(", ")", ":", "\n", "    ", "\"\"\"Returns hyperparameters of a mono text dataset with default values.\n    \"\"\"", "\n", "# TODO(zhiting): add more docs", "\n", "source_hparams", "=", "_default_mono_text_dataset_hparams", "(", ")", "\n", "source_hparams", "[", "\"bos_token\"", "]", "=", "None", "\n", "source_hparams", "[", "\"data_name\"", "]", "=", "\"source\"", "\n", "target_hparams", "=", "_default_mono_text_dataset_hparams", "(", ")", "\n", "target_hparams", ".", "update", "(", "\n", "{", "\n", "\"vocab_share\"", ":", "False", ",", "\n", "\"embedding_init_share\"", ":", "False", ",", "\n", "\"processing_share\"", ":", "False", ",", "\n", "\"data_name\"", ":", "\"target\"", "\n", "}", "\n", ")", "\n", "return", "{", "\n", "\"source_dataset\"", ":", "source_hparams", ",", "\n", "\"target_dataset\"", ":", "target_hparams", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.data_iterators_test.DataIteratorTest.setUp": [[26, 75], ["tensorflow.test.TestCase.setUp", "list", "tempfile.NamedTemporaryFile", "tempfile.NamedTemporaryFile.write", "tempfile.NamedTemporaryFile.flush", "list", "tempfile.NamedTemporaryFile", "tempfile.NamedTemporaryFile.write", "tempfile.NamedTemporaryFile.flush", "tempfile.NamedTemporaryFile", "tempfile.NamedTemporaryFile.write", "tempfile.NamedTemporaryFile.flush", "len", "numpy.linspace", "str", "numpy.linspace", "str"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.losses.mle_losses_test.MLELossesTest.setUp"], ["def", "setUp", "(", "self", ")", ":", "\n", "        ", "tf", ".", "test", ".", "TestCase", ".", "setUp", "(", "self", ")", "\n", "\n", "# Create data", "\n", "train_text", "=", "list", "(", "np", ".", "linspace", "(", "1", ",", "1000", ",", "num", "=", "1000", ",", "dtype", "=", "np", ".", "int64", ")", ")", "\n", "train_text", "=", "[", "str", "(", "x", ")", "for", "x", "in", "train_text", "]", "\n", "train_text_file", "=", "tempfile", ".", "NamedTemporaryFile", "(", ")", "\n", "train_text_file", ".", "write", "(", "'\\n'", ".", "join", "(", "train_text", ")", ".", "encode", "(", "\"utf-8\"", ")", ")", "\n", "train_text_file", ".", "flush", "(", ")", "\n", "self", ".", "_train_text_file", "=", "train_text_file", "\n", "\n", "test_text", "=", "list", "(", "np", ".", "linspace", "(", "1001", ",", "2000", ",", "num", "=", "1000", ",", "dtype", "=", "np", ".", "int64", ")", ")", "\n", "test_text", "=", "[", "str", "(", "x", ")", "for", "x", "in", "test_text", "]", "\n", "test_text_file", "=", "tempfile", ".", "NamedTemporaryFile", "(", ")", "\n", "test_text_file", ".", "write", "(", "'\\n'", ".", "join", "(", "test_text", ")", ".", "encode", "(", "\"utf-8\"", ")", ")", "\n", "test_text_file", ".", "flush", "(", ")", "\n", "self", ".", "_test_text_file", "=", "test_text_file", "\n", "\n", "vocab_list", "=", "train_text", "+", "test_text", "\n", "vocab_file", "=", "tempfile", ".", "NamedTemporaryFile", "(", ")", "\n", "vocab_file", ".", "write", "(", "'\\n'", ".", "join", "(", "vocab_list", ")", ".", "encode", "(", "\"utf-8\"", ")", ")", "\n", "vocab_file", ".", "flush", "(", ")", "\n", "self", ".", "_vocab_file", "=", "vocab_file", "\n", "self", ".", "_vocab_size", "=", "len", "(", "vocab_list", ")", "\n", "\n", "self", ".", "_train_hparams", "=", "{", "\n", "\"num_epochs\"", ":", "2", ",", "\n", "\"batch_size\"", ":", "1", ",", "\n", "\"shuffle\"", ":", "False", ",", "\n", "\"dataset\"", ":", "{", "\n", "\"files\"", ":", "self", ".", "_train_text_file", ".", "name", ",", "\n", "\"vocab_file\"", ":", "self", ".", "_vocab_file", ".", "name", ",", "\n", "\"bos_token\"", ":", "''", ",", "\n", "\"eos_token\"", ":", "''", "\n", "}", ",", "\n", "\"name\"", ":", "\"train\"", "\n", "}", "\n", "\n", "self", ".", "_test_hparams", "=", "{", "\n", "\"num_epochs\"", ":", "1", ",", "\n", "\"batch_size\"", ":", "1", ",", "\n", "\"shuffle\"", ":", "False", ",", "\n", "\"dataset\"", ":", "{", "\n", "\"files\"", ":", "self", ".", "_test_text_file", ".", "name", ",", "\n", "\"vocab_file\"", ":", "self", ".", "_vocab_file", ".", "name", ",", "\n", "\"bos_token\"", ":", "''", ",", "\n", "\"eos_token\"", ":", "''", "\n", "}", ",", "\n", "\"name\"", ":", "\"test\"", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.data_iterators_test.DataIteratorTest.test_iterator_single_dataset": [[77, 102], ["texar.data.MonoTextData", "texar.data.DataIterator", "texar.data.DataIterator.get_next", "data_iterators_test.DataIteratorTest.test_session", "sess.run", "sess.run", "sess.run", "range", "tensorflow.global_variables_initializer", "tensorflow.local_variables_initializer", "tensorflow.tables_initializer", "texar.data.DataIterator.switch_to_dataset", "sess.run", "data_iterators_test.DataIteratorTest.assertEqual", "str", "print", "data_iterators_test.DataIteratorTest.assertEqual"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.data.data_iterators.FeedableDataIterator.get_next", "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.data_iterators.DataIterator.switch_to_dataset"], ["", "def", "test_iterator_single_dataset", "(", "self", ")", ":", "\n", "        ", "\"\"\"Tests iterating over a single dataset.\n        \"\"\"", "\n", "data", "=", "tx", ".", "data", ".", "MonoTextData", "(", "self", ".", "_test_hparams", ")", "\n", "\n", "iterator", "=", "tx", ".", "data", ".", "DataIterator", "(", "data", ")", "\n", "data_batch", "=", "iterator", ".", "get_next", "(", ")", "\n", "\n", "with", "self", ".", "test_session", "(", ")", "as", "sess", ":", "\n", "            ", "sess", ".", "run", "(", "tf", ".", "global_variables_initializer", "(", ")", ")", "\n", "sess", ".", "run", "(", "tf", ".", "local_variables_initializer", "(", ")", ")", "\n", "sess", ".", "run", "(", "tf", ".", "tables_initializer", "(", ")", ")", "\n", "\n", "for", "_", "in", "range", "(", "2", ")", ":", "\n", "                ", "iterator", ".", "switch_to_dataset", "(", "sess", ")", "\n", "i", "=", "1001", "\n", "while", "True", ":", "\n", "                    ", "try", ":", "\n", "                        ", "data_batch_", "=", "sess", ".", "run", "(", "data_batch", ")", "\n", "self", ".", "assertEqual", "(", "data_batch_", "[", "'text'", "]", "[", "0", "]", "[", "0", "]", ",", "str", "(", "i", ")", ")", "\n", "i", "+=", "1", "\n", "", "except", "tf", ".", "errors", ".", "OutOfRangeError", ":", "\n", "                        ", "print", "(", "'Done -- epoch limit reached'", ")", "\n", "self", ".", "assertEqual", "(", "i", ",", "2001", ")", "\n", "break", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.data_iterators_test.DataIteratorTest.test_iterator_multi_datasets": [[104, 144], ["texar.data.MonoTextData", "texar.data.MonoTextData", "texar.data.DataIterator", "texar.data.DataIterator.get_next", "data_iterators_test.DataIteratorTest.test_session", "sess.run", "sess.run", "sess.run", "range", "tensorflow.global_variables_initializer", "tensorflow.local_variables_initializer", "tensorflow.tables_initializer", "texar.data.DataIterator.switch_to_dataset", "texar.data.DataIterator.switch_to_dataset", "sess.run", "data_iterators_test.DataIteratorTest.assertEqual", "sess.run", "data_iterators_test.DataIteratorTest.assertEqual", "str", "print", "data_iterators_test.DataIteratorTest.assertEqual", "str", "print", "data_iterators_test.DataIteratorTest.assertEqual"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.data.data_iterators.FeedableDataIterator.get_next", "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.data_iterators.DataIterator.switch_to_dataset", "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.data_iterators.DataIterator.switch_to_dataset"], ["", "", "", "", "", "def", "test_iterator_multi_datasets", "(", "self", ")", ":", "\n", "        ", "\"\"\"Tests iterating over multiple datasets.\n        \"\"\"", "\n", "train_data", "=", "tx", ".", "data", ".", "MonoTextData", "(", "self", ".", "_train_hparams", ")", "\n", "test_data", "=", "tx", ".", "data", ".", "MonoTextData", "(", "self", ".", "_test_hparams", ")", "\n", "\n", "iterator", "=", "tx", ".", "data", ".", "DataIterator", "(", "[", "train_data", ",", "test_data", "]", ")", "\n", "data_batch", "=", "iterator", ".", "get_next", "(", ")", "\n", "\n", "with", "self", ".", "test_session", "(", ")", "as", "sess", ":", "\n", "            ", "sess", ".", "run", "(", "tf", ".", "global_variables_initializer", "(", ")", ")", "\n", "sess", ".", "run", "(", "tf", ".", "local_variables_initializer", "(", ")", ")", "\n", "sess", ".", "run", "(", "tf", ".", "tables_initializer", "(", ")", ")", "\n", "\n", "for", "_", "in", "range", "(", "2", ")", ":", "\n", "# Iterates over train data", "\n", "                ", "iterator", ".", "switch_to_dataset", "(", "sess", ",", "train_data", ".", "name", ")", "\n", "i", "=", "0", "\n", "while", "True", ":", "\n", "                    ", "try", ":", "\n", "                        ", "data_batch_", "=", "sess", ".", "run", "(", "data_batch", ")", "\n", "self", ".", "assertEqual", "(", "data_batch_", "[", "'text'", "]", "[", "0", "]", "[", "0", "]", ",", "str", "(", "i", "+", "1", ")", ")", "\n", "i", "=", "(", "i", "+", "1", ")", "%", "1000", "\n", "", "except", "tf", ".", "errors", ".", "OutOfRangeError", ":", "\n", "                        ", "print", "(", "'Train data limit reached'", ")", "\n", "self", ".", "assertEqual", "(", "i", ",", "0", ")", "\n", "break", "\n", "\n", "# Iterates over test data", "\n", "", "", "iterator", ".", "switch_to_dataset", "(", "sess", ",", "test_data", ".", "name", ")", "\n", "i", "=", "1001", "\n", "while", "True", ":", "\n", "                    ", "try", ":", "\n", "                        ", "data_batch_", "=", "sess", ".", "run", "(", "data_batch", ")", "\n", "self", ".", "assertEqual", "(", "data_batch_", "[", "'text'", "]", "[", "0", "]", "[", "0", "]", ",", "str", "(", "i", ")", ")", "\n", "i", "+=", "1", "\n", "", "except", "tf", ".", "errors", ".", "OutOfRangeError", ":", "\n", "                        ", "print", "(", "'Test data limit reached'", ")", "\n", "self", ".", "assertEqual", "(", "i", ",", "2001", ")", "\n", "break", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.data_iterators_test.DataIteratorTest.test_train_test_data_iterator": [[145, 184], ["texar.data.MonoTextData", "texar.data.MonoTextData", "texar.data.TrainTestDataIterator", "texar.data.TrainTestDataIterator.get_next", "data_iterators_test.DataIteratorTest.test_session", "sess.run", "sess.run", "sess.run", "range", "tensorflow.global_variables_initializer", "tensorflow.local_variables_initializer", "tensorflow.tables_initializer", "texar.data.TrainTestDataIterator.switch_to_train_data", "texar.data.TrainTestDataIterator.switch_to_test_data", "sess.run", "data_iterators_test.DataIteratorTest.assertEqual", "sess.run", "data_iterators_test.DataIteratorTest.assertEqual", "str", "print", "data_iterators_test.DataIteratorTest.assertEqual", "str", "print", "data_iterators_test.DataIteratorTest.assertEqual"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.data.data_iterators.FeedableDataIterator.get_next", "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.data_iterators.TrainTestDataIterator.switch_to_train_data", "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.data_iterators.TrainTestDataIterator.switch_to_test_data"], ["", "", "", "", "", "def", "test_train_test_data_iterator", "(", "self", ")", ":", "\n", "        ", "\"\"\"Tests :class:`texar.data.TrainTestDataIterator`\n        \"\"\"", "\n", "train_data", "=", "tx", ".", "data", ".", "MonoTextData", "(", "self", ".", "_train_hparams", ")", "\n", "test_data", "=", "tx", ".", "data", ".", "MonoTextData", "(", "self", ".", "_test_hparams", ")", "\n", "\n", "iterator", "=", "tx", ".", "data", ".", "TrainTestDataIterator", "(", "train", "=", "train_data", ",", "\n", "test", "=", "test_data", ")", "\n", "data_batch", "=", "iterator", ".", "get_next", "(", ")", "\n", "\n", "with", "self", ".", "test_session", "(", ")", "as", "sess", ":", "\n", "            ", "sess", ".", "run", "(", "tf", ".", "global_variables_initializer", "(", ")", ")", "\n", "sess", ".", "run", "(", "tf", ".", "local_variables_initializer", "(", ")", ")", "\n", "sess", ".", "run", "(", "tf", ".", "tables_initializer", "(", ")", ")", "\n", "\n", "for", "_", "in", "range", "(", "2", ")", ":", "\n", "                ", "iterator", ".", "switch_to_train_data", "(", "sess", ")", "\n", "i", "=", "0", "\n", "while", "True", ":", "\n", "                    ", "try", ":", "\n", "                        ", "data_batch_", "=", "sess", ".", "run", "(", "data_batch", ")", "\n", "self", ".", "assertEqual", "(", "data_batch_", "[", "'text'", "]", "[", "0", "]", "[", "0", "]", ",", "str", "(", "i", "+", "1", ")", ")", "\n", "i", "=", "(", "i", "+", "1", ")", "%", "1000", "\n", "", "except", "tf", ".", "errors", ".", "OutOfRangeError", ":", "\n", "                        ", "print", "(", "'Train data limit reached'", ")", "\n", "self", ".", "assertEqual", "(", "i", ",", "0", ")", "\n", "break", "\n", "\n", "", "", "iterator", ".", "switch_to_test_data", "(", "sess", ")", "\n", "i", "=", "1001", "\n", "while", "True", ":", "\n", "                    ", "try", ":", "\n", "                        ", "data_batch_", "=", "sess", ".", "run", "(", "data_batch", ")", "\n", "self", ".", "assertEqual", "(", "data_batch_", "[", "'text'", "]", "[", "0", "]", "[", "0", "]", ",", "str", "(", "i", ")", ")", "\n", "i", "+=", "1", "\n", "", "except", "tf", ".", "errors", ".", "OutOfRangeError", ":", "\n", "                        ", "print", "(", "'Test data limit reached'", ")", "\n", "self", ".", "assertEqual", "(", "i", ",", "2001", ")", "\n", "break", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.data_iterators_test.DataIteratorTest.test_feedable_iterator_multi_datasets": [[185, 232], ["texar.data.MonoTextData", "texar.data.MonoTextData", "texar.data.FeedableDataIterator", "texar.data.FeedableDataIterator.get_next", "data_iterators_test.DataIteratorTest.test_session", "sess.run", "sess.run", "sess.run", "texar.data.FeedableDataIterator.initialize_dataset", "range", "tensorflow.global_variables_initializer", "tensorflow.local_variables_initializer", "tensorflow.tables_initializer", "texar.data.FeedableDataIterator.restart_dataset", "texar.data.FeedableDataIterator.get_handle", "texar.data.FeedableDataIterator.restart_dataset", "texar.data.FeedableDataIterator.get_handle", "sess.run", "data_iterators_test.DataIteratorTest.assertEqual", "sess.run", "data_iterators_test.DataIteratorTest.assertEqual", "str", "print", "data_iterators_test.DataIteratorTest.assertEqual", "str", "print", "data_iterators_test.DataIteratorTest.assertEqual"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.data.data_iterators.FeedableDataIterator.get_next", "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.data_iterators.FeedableDataIterator.initialize_dataset", "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.data_iterators.FeedableDataIterator.restart_dataset", "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.data_iterators.FeedableDataIterator.get_handle", "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.data_iterators.FeedableDataIterator.restart_dataset", "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.data_iterators.FeedableDataIterator.get_handle"], ["", "", "", "", "", "def", "test_feedable_iterator_multi_datasets", "(", "self", ")", ":", "\n", "        ", "\"\"\"Tests iterating over multiple datasets with the\n        :class:`FeedableDataIterator`.\n        \"\"\"", "\n", "train_data", "=", "tx", ".", "data", ".", "MonoTextData", "(", "self", ".", "_train_hparams", ")", "\n", "test_data", "=", "tx", ".", "data", ".", "MonoTextData", "(", "self", ".", "_test_hparams", ")", "\n", "\n", "iterator", "=", "tx", ".", "data", ".", "FeedableDataIterator", "(", "[", "train_data", ",", "test_data", "]", ")", "\n", "data_batch", "=", "iterator", ".", "get_next", "(", ")", "\n", "\n", "with", "self", ".", "test_session", "(", ")", "as", "sess", ":", "\n", "            ", "sess", ".", "run", "(", "tf", ".", "global_variables_initializer", "(", ")", ")", "\n", "sess", ".", "run", "(", "tf", ".", "local_variables_initializer", "(", ")", ")", "\n", "sess", ".", "run", "(", "tf", ".", "tables_initializer", "(", ")", ")", "\n", "\n", "iterator", ".", "initialize_dataset", "(", "sess", ")", "\n", "\n", "for", "_", "in", "range", "(", "2", ")", ":", "\n", "# Iterates over train data", "\n", "                ", "iterator", ".", "restart_dataset", "(", "sess", ",", "train_data", ".", "name", ")", "\n", "data_handle", "=", "iterator", ".", "get_handle", "(", "sess", ",", "train_data", ".", "name", ")", "\n", "i", "=", "0", "\n", "while", "True", ":", "\n", "                    ", "try", ":", "\n", "                        ", "feed_dict", "=", "{", "iterator", ".", "handle", ":", "data_handle", "}", "\n", "data_batch_", "=", "sess", ".", "run", "(", "data_batch", ",", "feed_dict", "=", "feed_dict", ")", "\n", "self", ".", "assertEqual", "(", "data_batch_", "[", "'text'", "]", "[", "0", "]", "[", "0", "]", ",", "str", "(", "i", "+", "1", ")", ")", "\n", "i", "=", "(", "i", "+", "1", ")", "%", "1000", "\n", "", "except", "tf", ".", "errors", ".", "OutOfRangeError", ":", "\n", "                        ", "print", "(", "'Train data limit reached'", ")", "\n", "self", ".", "assertEqual", "(", "i", ",", "0", ")", "\n", "break", "\n", "\n", "# Iterates over test data", "\n", "", "", "iterator", ".", "restart_dataset", "(", "sess", ",", "test_data", ".", "name", ")", "\n", "data_handle", "=", "iterator", ".", "get_handle", "(", "sess", ",", "test_data", ".", "name", ")", "\n", "i", "=", "1001", "\n", "while", "True", ":", "\n", "                    ", "try", ":", "\n", "                        ", "feed_dict", "=", "{", "iterator", ".", "handle", ":", "data_handle", "}", "\n", "data_batch_", "=", "sess", ".", "run", "(", "data_batch", ",", "feed_dict", "=", "feed_dict", ")", "\n", "self", ".", "assertEqual", "(", "data_batch_", "[", "'text'", "]", "[", "0", "]", "[", "0", "]", ",", "str", "(", "i", ")", ")", "\n", "i", "+=", "1", "\n", "", "except", "tf", ".", "errors", ".", "OutOfRangeError", ":", "\n", "                        ", "print", "(", "'Test data limit reached'", ")", "\n", "self", ".", "assertEqual", "(", "i", ",", "2001", ")", "\n", "break", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.data_iterators_test.DataIteratorTest.test_train_test_feedable_data_iterator": [[233, 278], ["texar.data.MonoTextData", "texar.data.MonoTextData", "texar.data.TrainTestFeedableDataIterator", "texar.data.TrainTestFeedableDataIterator.get_next", "data_iterators_test.DataIteratorTest.test_session", "sess.run", "sess.run", "sess.run", "range", "tensorflow.global_variables_initializer", "tensorflow.local_variables_initializer", "tensorflow.tables_initializer", "texar.data.TrainTestFeedableDataIterator.restart_train_dataset", "texar.data.TrainTestFeedableDataIterator.restart_test_dataset", "sess.run", "data_iterators_test.DataIteratorTest.assertEqual", "sess.run", "data_iterators_test.DataIteratorTest.assertEqual", "texar.data.TrainTestFeedableDataIterator.get_train_handle", "str", "print", "data_iterators_test.DataIteratorTest.assertEqual", "texar.data.TrainTestFeedableDataIterator.get_test_handle", "str", "print", "data_iterators_test.DataIteratorTest.assertEqual"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.data.data_iterators.FeedableDataIterator.get_next", "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.data_iterators.TrainTestFeedableDataIterator.restart_train_dataset", "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.data_iterators.TrainTestFeedableDataIterator.restart_test_dataset", "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.data_iterators.TrainTestFeedableDataIterator.get_train_handle", "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.data_iterators.TrainTestFeedableDataIterator.get_test_handle"], ["", "", "", "", "", "def", "test_train_test_feedable_data_iterator", "(", "self", ")", ":", "\n", "        ", "\"\"\"Tests :class:`texar.data.TrainTestFeedableDataIterator`\n        \"\"\"", "\n", "train_data", "=", "tx", ".", "data", ".", "MonoTextData", "(", "self", ".", "_train_hparams", ")", "\n", "test_data", "=", "tx", ".", "data", ".", "MonoTextData", "(", "self", ".", "_test_hparams", ")", "\n", "\n", "iterator", "=", "tx", ".", "data", ".", "TrainTestFeedableDataIterator", "(", "train", "=", "train_data", ",", "\n", "test", "=", "test_data", ")", "\n", "data_batch", "=", "iterator", ".", "get_next", "(", ")", "\n", "\n", "with", "self", ".", "test_session", "(", ")", "as", "sess", ":", "\n", "            ", "sess", ".", "run", "(", "tf", ".", "global_variables_initializer", "(", ")", ")", "\n", "sess", ".", "run", "(", "tf", ".", "local_variables_initializer", "(", ")", ")", "\n", "sess", ".", "run", "(", "tf", ".", "tables_initializer", "(", ")", ")", "\n", "\n", "for", "_", "in", "range", "(", "2", ")", ":", "\n", "                ", "iterator", ".", "restart_train_dataset", "(", "sess", ")", "\n", "i", "=", "0", "\n", "while", "True", ":", "\n", "                    ", "try", ":", "\n", "                        ", "feed_dict", "=", "{", "\n", "iterator", ".", "handle", ":", "iterator", ".", "get_train_handle", "(", "sess", ")", "\n", "}", "\n", "data_batch_", "=", "sess", ".", "run", "(", "data_batch", ",", "feed_dict", "=", "feed_dict", ")", "\n", "self", ".", "assertEqual", "(", "data_batch_", "[", "'text'", "]", "[", "0", "]", "[", "0", "]", ",", "str", "(", "i", "+", "1", ")", ")", "\n", "i", "=", "(", "i", "+", "1", ")", "%", "1000", "\n", "", "except", "tf", ".", "errors", ".", "OutOfRangeError", ":", "\n", "                        ", "print", "(", "'Train data limit reached'", ")", "\n", "self", ".", "assertEqual", "(", "i", ",", "0", ")", "\n", "break", "\n", "\n", "", "", "iterator", ".", "restart_test_dataset", "(", "sess", ")", "\n", "i", "=", "1001", "\n", "while", "True", ":", "\n", "                    ", "try", ":", "\n", "                        ", "feed_dict", "=", "{", "\n", "iterator", ".", "handle", ":", "iterator", ".", "get_test_handle", "(", "sess", ")", "\n", "}", "\n", "data_batch_", "=", "sess", ".", "run", "(", "data_batch", ",", "feed_dict", "=", "feed_dict", ")", "\n", "self", ".", "assertEqual", "(", "data_batch_", "[", "'text'", "]", "[", "0", "]", "[", "0", "]", ",", "str", "(", "i", ")", ")", "\n", "i", "+=", "1", "\n", "", "except", "tf", ".", "errors", ".", "OutOfRangeError", ":", "\n", "                        ", "print", "(", "'Test data limit reached'", ")", "\n", "self", ".", "assertEqual", "(", "i", ",", "2001", ")", "\n", "break", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.mono_text_data_test.MonoTextDataTest.setUp": [[27, 50], ["tensorflow.test.TestCase.setUp", "tempfile.NamedTemporaryFile", "tempfile.NamedTemporaryFile.write", "tempfile.NamedTemporaryFile.flush", "len", "tempfile.NamedTemporaryFile", "tempfile.NamedTemporaryFile.write", "tempfile.NamedTemporaryFile.flush"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.losses.mle_losses_test.MLELossesTest.setUp"], ["def", "setUp", "(", "self", ")", ":", "\n", "        ", "tf", ".", "test", ".", "TestCase", ".", "setUp", "(", "self", ")", "\n", "\n", "# Create test data", "\n", "vocab_list", "=", "[", "'word'", ",", "'\u8bcd'", "]", "\n", "vocab_file", "=", "tempfile", ".", "NamedTemporaryFile", "(", ")", "\n", "vocab_file", ".", "write", "(", "'\\n'", ".", "join", "(", "vocab_list", ")", ".", "encode", "(", "\"utf-8\"", ")", ")", "\n", "vocab_file", ".", "flush", "(", ")", "\n", "self", ".", "_vocab_file", "=", "vocab_file", "\n", "self", ".", "_vocab_size", "=", "len", "(", "vocab_list", ")", "\n", "\n", "text", "=", "[", "'This is a test sentence .'", ",", "'\u8bcd \u8bcd \u3002'", "]", "\n", "text_file", "=", "tempfile", ".", "NamedTemporaryFile", "(", ")", "\n", "text_file", ".", "write", "(", "'\\n'", ".", "join", "(", "text", ")", ".", "encode", "(", "\"utf-8\"", ")", ")", "\n", "text_file", ".", "flush", "(", ")", "\n", "self", ".", "_text_file", "=", "text_file", "\n", "\n", "self", ".", "_hparams", "=", "{", "\n", "\"num_epochs\"", ":", "50", ",", "\n", "\"batch_size\"", ":", "3", ",", "\n", "\"dataset\"", ":", "{", "\n", "\"files\"", ":", "self", ".", "_text_file", ".", "name", ",", "\n", "\"vocab_file\"", ":", "self", ".", "_vocab_file", ".", "name", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.mono_text_data_test.MonoTextDataTest._run_and_test": [[53, 117], ["texar.data.MonoTextData", "mono_text_data_test.MonoTextDataTest.assertEqual", "texar.data.MonoTextData.dataset.make_initializable_iterator", "tx.data.MonoTextData.dataset.make_initializable_iterator.get_next", "mono_text_data_test.MonoTextDataTest.test_session", "sess.run", "sess.run", "sess.run", "sess.run", "len", "tensorflow.global_variables_initializer", "tensorflow.local_variables_initializer", "tensorflow.tables_initializer", "sess.run", "mono_text_data_test.MonoTextDataTest.assertEqual", "set", "set", "mono_text_data_test.MonoTextDataTest.assertEqual", "range", "print", "sess.run.keys", "texar.data.MonoTextData.list_items", "len", "len", "[].tolist", "mono_text_data_test.MonoTextDataTest.assertEqual", "mono_text_data_test.MonoTextDataTest.assertLessEqual", "mono_text_data_test.MonoTextDataTest.assertEqual", "mono_text_data_test.MonoTextDataTest.assertEqual", "mono_text_data_test.MonoTextDataTest.assertEqual", "mono_text_data_test.MonoTextDataTest.assertGreater", "ValueError", "len", "len", "[].tolist.index", "int"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.data.data_iterators.FeedableDataIterator.get_next", "home.repos.pwc.inspect_result.VegB_Text_Infilling.texar.hyperparams.HParams.keys", "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.multi_aligned_data.MultiAlignedData.list_items"], ["", "def", "_run_and_test", "(", "self", ",", "\n", "hparams", ",", "\n", "test_batch_size", "=", "False", ",", "\n", "length_inc", "=", "None", ")", ":", "\n", "# Construct database", "\n", "        ", "text_data", "=", "tx", ".", "data", ".", "MonoTextData", "(", "hparams", ")", "\n", "self", ".", "assertEqual", "(", "text_data", ".", "vocab", ".", "size", ",", "\n", "self", ".", "_vocab_size", "+", "len", "(", "text_data", ".", "vocab", ".", "special_tokens", ")", ")", "\n", "\n", "iterator", "=", "text_data", ".", "dataset", ".", "make_initializable_iterator", "(", ")", "\n", "text_data_batch", "=", "iterator", ".", "get_next", "(", ")", "\n", "\n", "with", "self", ".", "test_session", "(", ")", "as", "sess", ":", "\n", "            ", "sess", ".", "run", "(", "tf", ".", "global_variables_initializer", "(", ")", ")", "\n", "sess", ".", "run", "(", "tf", ".", "local_variables_initializer", "(", ")", ")", "\n", "sess", ".", "run", "(", "tf", ".", "tables_initializer", "(", ")", ")", "\n", "sess", ".", "run", "(", "iterator", ".", "initializer", ")", "\n", "\n", "while", "True", ":", "\n", "                ", "try", ":", "\n", "                    ", "data_batch_", "=", "sess", ".", "run", "(", "text_data_batch", ")", "\n", "\n", "self", ".", "assertEqual", "(", "set", "(", "data_batch_", ".", "keys", "(", ")", ")", ",", "\n", "set", "(", "text_data", ".", "list_items", "(", ")", ")", ")", "\n", "\n", "if", "test_batch_size", ":", "\n", "                        ", "self", ".", "assertEqual", "(", "len", "(", "data_batch_", "[", "'text'", "]", ")", ",", "\n", "hparams", "[", "'batch_size'", "]", ")", "\n", "\n", "", "if", "length_inc", ":", "\n", "                        ", "for", "i", "in", "range", "(", "len", "(", "data_batch_", "[", "'text'", "]", ")", ")", ":", "\n", "                            ", "text_", "=", "data_batch_", "[", "'text'", "]", "[", "i", "]", ".", "tolist", "(", ")", "\n", "self", ".", "assertEqual", "(", "\n", "text_", ".", "index", "(", "b'<EOS>'", ")", "+", "1", ",", "\n", "data_batch_", "[", "'length'", "]", "[", "i", "]", "-", "length_inc", ")", "\n", "\n", "", "", "max_seq_length", "=", "text_data", ".", "hparams", ".", "dataset", ".", "max_seq_length", "\n", "mode", "=", "text_data", ".", "hparams", ".", "dataset", ".", "length_filter_mode", "\n", "if", "max_seq_length", "==", "6", ":", "\n", "                        ", "max_l", "=", "max_seq_length", "\n", "max_l", "+=", "text_data", ".", "_decoder", ".", "added_length", "\n", "for", "length", "in", "data_batch_", "[", "'length'", "]", ":", "\n", "                            ", "self", ".", "assertLessEqual", "(", "length", ",", "max_l", ")", "\n", "", "if", "mode", "==", "\"discard\"", ":", "\n", "                            ", "for", "length", "in", "data_batch_", "[", "'length'", "]", ":", "\n", "                                ", "self", ".", "assertEqual", "(", "length", ",", "5", ")", "\n", "", "", "elif", "mode", "==", "\"truncate\"", ":", "\n", "                            ", "num_length_6", "=", "0", "\n", "for", "length", "in", "data_batch_", "[", "'length'", "]", ":", "\n", "                                ", "num_length_6", "+=", "int", "(", "length", "==", "6", ")", "\n", "", "self", ".", "assertGreater", "(", "num_length_6", ",", "0", ")", "\n", "", "else", ":", "\n", "                            ", "raise", "ValueError", "(", "\"Unknown mode: %s\"", "%", "mode", ")", "\n", "\n", "", "", "if", "text_data", ".", "hparams", ".", "dataset", ".", "pad_to_max_seq_length", ":", "\n", "                        ", "max_l", "=", "max_seq_length", "+", "text_data", ".", "_decoder", ".", "added_length", "\n", "for", "x", "in", "data_batch_", "[", "'text'", "]", ":", "\n", "                            ", "self", ".", "assertEqual", "(", "len", "(", "x", ")", ",", "max_l", ")", "\n", "", "for", "x", "in", "data_batch_", "[", "'text_ids'", "]", ":", "\n", "                            ", "self", ".", "assertEqual", "(", "len", "(", "x", ")", ",", "max_l", ")", "\n", "\n", "", "", "", "except", "tf", ".", "errors", ".", "OutOfRangeError", ":", "\n", "                    ", "print", "(", "'Done -- epoch limit reached'", ")", "\n", "break", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.mono_text_data_test.MonoTextDataTest.test_default_setting": [[118, 122], ["mono_text_data_test.MonoTextDataTest._run_and_test"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.data.mono_text_data_test.VarUttMonoTextDataTest._run_and_test"], ["", "", "", "", "def", "test_default_setting", "(", "self", ")", ":", "\n", "        ", "\"\"\"Tests the logics of MonoTextData.\n        \"\"\"", "\n", "self", ".", "_run_and_test", "(", "self", ".", "_hparams", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.mono_text_data_test.MonoTextDataTest.test_batching": [[123, 130], ["copy.copy", "copy.copy.update", "mono_text_data_test.MonoTextDataTest._run_and_test"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.data.mono_text_data_test.VarUttMonoTextDataTest._run_and_test"], ["", "def", "test_batching", "(", "self", ")", ":", "\n", "        ", "\"\"\"Tests different batching.\n        \"\"\"", "\n", "# dis-allow smaller final batch", "\n", "hparams", "=", "copy", ".", "copy", "(", "self", ".", "_hparams", ")", "\n", "hparams", ".", "update", "(", "{", "\"allow_smaller_final_batch\"", ":", "False", "}", ")", "\n", "self", ".", "_run_and_test", "(", "hparams", ",", "test_batch_size", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.mono_text_data_test.MonoTextDataTest.test_bucketing": [[131, 182], ["copy.copy", "copy.copy.update", "texar.data.MonoTextData", "texar.data.MonoTextData.dataset.make_initializable_iterator", "tx.data.MonoTextData.dataset.make_initializable_iterator.get_next", "copy.copy.update", "texar.data.MonoTextData", "texar.data.MonoTextData.dataset.make_initializable_iterator", "tx.data.MonoTextData.dataset.make_initializable_iterator.get_next", "mono_text_data_test.MonoTextDataTest.test_session", "sess.run", "sess.run", "sess.run", "sess.run", "sess.run", "tensorflow.global_variables_initializer", "tensorflow.local_variables_initializer", "tensorflow.tables_initializer", "sess.run", "mono_text_data_test.MonoTextDataTest.assertEqual", "mono_text_data_test.MonoTextDataTest.assertTrue", "mono_text_data_test.MonoTextDataTest.assertTrue", "len", "print", "len", "len", "len", "len"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.data.data_iterators.FeedableDataIterator.get_next", "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.data_iterators.FeedableDataIterator.get_next"], ["", "def", "test_bucketing", "(", "self", ")", ":", "\n", "        ", "\"\"\"Tests bucketing.\n        \"\"\"", "\n", "hparams", "=", "copy", ".", "copy", "(", "self", ".", "_hparams", ")", "\n", "hparams", ".", "update", "(", "{", "\n", "\"bucket_boundaries\"", ":", "[", "7", "]", ",", "\n", "\"bucket_batch_sizes\"", ":", "[", "6", ",", "4", "]", "}", ")", "\n", "\n", "text_data", "=", "tx", ".", "data", ".", "MonoTextData", "(", "hparams", ")", "\n", "iterator", "=", "text_data", ".", "dataset", ".", "make_initializable_iterator", "(", ")", "\n", "text_data_batch", "=", "iterator", ".", "get_next", "(", ")", "\n", "\n", "hparams", ".", "update", "(", "{", "\n", "\"bucket_boundaries\"", ":", "[", "7", "]", ",", "\n", "\"bucket_batch_sizes\"", ":", "[", "7", ",", "7", "]", ",", "\n", "\"allow_smaller_final_batch\"", ":", "False", "}", ")", "\n", "\n", "text_data_1", "=", "tx", ".", "data", ".", "MonoTextData", "(", "hparams", ")", "\n", "iterator_1", "=", "text_data_1", ".", "dataset", ".", "make_initializable_iterator", "(", ")", "\n", "text_data_batch_1", "=", "iterator_1", ".", "get_next", "(", ")", "\n", "\n", "with", "self", ".", "test_session", "(", ")", "as", "sess", ":", "\n", "            ", "sess", ".", "run", "(", "tf", ".", "global_variables_initializer", "(", ")", ")", "\n", "sess", ".", "run", "(", "tf", ".", "local_variables_initializer", "(", ")", ")", "\n", "sess", ".", "run", "(", "tf", ".", "tables_initializer", "(", ")", ")", "\n", "sess", ".", "run", "(", "iterator", ".", "initializer", ")", "\n", "sess", ".", "run", "(", "iterator_1", ".", "initializer", ")", "\n", "\n", "while", "True", ":", "\n", "                ", "try", ":", "\n", "# Run the logics", "\n", "                    ", "data_batch_", ",", "data_batch_1_", "=", "sess", ".", "run", "(", "\n", "[", "text_data_batch", ",", "text_data_batch_1", "]", ")", "\n", "\n", "length_", "=", "data_batch_", "[", "'length'", "]", "[", "0", "]", "\n", "if", "length_", "<", "7", ":", "\n", "                        ", "last_batch_size", "=", "hparams", "[", "'num_epochs'", "]", "%", "6", "\n", "self", ".", "assertTrue", "(", "\n", "len", "(", "data_batch_", "[", "'text'", "]", ")", "==", "6", "or", "\n", "len", "(", "data_batch_", "[", "'text'", "]", ")", "==", "last_batch_size", ")", "\n", "", "else", ":", "\n", "                        ", "last_batch_size", "=", "hparams", "[", "'num_epochs'", "]", "%", "4", "\n", "self", ".", "assertTrue", "(", "\n", "len", "(", "data_batch_", "[", "'text'", "]", ")", "==", "4", "or", "\n", "len", "(", "data_batch_", "[", "'text'", "]", ")", "==", "last_batch_size", ")", "\n", "\n", "", "self", ".", "assertEqual", "(", "len", "(", "data_batch_1_", "[", "'text'", "]", ")", ",", "7", ")", "\n", "\n", "", "except", "tf", ".", "errors", ".", "OutOfRangeError", ":", "\n", "                    ", "print", "(", "'Done -- epoch limit reached'", ")", "\n", "break", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.mono_text_data_test.MonoTextDataTest.test_shuffle": [[183, 191], ["copy.copy", "copy.copy.update", "mono_text_data_test.MonoTextDataTest._run_and_test"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.data.mono_text_data_test.VarUttMonoTextDataTest._run_and_test"], ["", "", "", "", "def", "test_shuffle", "(", "self", ")", ":", "\n", "        ", "\"\"\"Tests different shuffle strategies.\n        \"\"\"", "\n", "hparams", "=", "copy", ".", "copy", "(", "self", ".", "_hparams", ")", "\n", "hparams", ".", "update", "(", "{", "\n", "\"shard_and_shuffle\"", ":", "True", ",", "\n", "\"shuffle_buffer_size\"", ":", "1", "}", ")", "\n", "self", ".", "_run_and_test", "(", "hparams", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.mono_text_data_test.MonoTextDataTest.test_prefetch": [[192, 198], ["copy.copy", "copy.copy.update", "mono_text_data_test.MonoTextDataTest._run_and_test"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.data.mono_text_data_test.VarUttMonoTextDataTest._run_and_test"], ["", "def", "test_prefetch", "(", "self", ")", ":", "\n", "        ", "\"\"\"Tests prefetching.\n        \"\"\"", "\n", "hparams", "=", "copy", ".", "copy", "(", "self", ".", "_hparams", ")", "\n", "hparams", ".", "update", "(", "{", "\"prefetch_buffer_size\"", ":", "2", "}", ")", "\n", "self", ".", "_run_and_test", "(", "hparams", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.mono_text_data_test.MonoTextDataTest.test_other_transformations": [[199, 210], ["copy.copy", "hparams[].update", "mono_text_data_test.MonoTextDataTest._run_and_test"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.data.mono_text_data_test.VarUttMonoTextDataTest._run_and_test"], ["", "def", "test_other_transformations", "(", "self", ")", ":", "\n", "        ", "\"\"\"Tests use of other transformations\n        \"\"\"", "\n", "def", "_transform", "(", "x", ",", "data_specs", ")", ":", "# pylint: disable=invalid-name", "\n", "            ", "x", "[", "data_specs", ".", "decoder", ".", "length_tensor_name", "]", "+=", "1", "\n", "return", "x", "\n", "\n", "", "hparams", "=", "copy", ".", "copy", "(", "self", ".", "_hparams", ")", "\n", "hparams", "[", "\"dataset\"", "]", ".", "update", "(", "\n", "{", "\"other_transformations\"", ":", "[", "_transform", ",", "_transform", "]", "}", ")", "\n", "self", ".", "_run_and_test", "(", "hparams", ",", "length_inc", "=", "2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.mono_text_data_test.MonoTextDataTest.test_list_items": [[211, 223], ["texar.data.MonoTextData", "mono_text_data_test.MonoTextDataTest.assertSetEqual", "copy.copy", "texar.data.MonoTextData", "mono_text_data_test.MonoTextDataTest.assertSetEqual", "set", "set", "texar.data.MonoTextData.list_items", "texar.data.MonoTextData.list_items"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.data.multi_aligned_data.MultiAlignedData.list_items", "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.multi_aligned_data.MultiAlignedData.list_items"], ["", "def", "test_list_items", "(", "self", ")", ":", "\n", "        ", "\"\"\"Tests the item names of the output data.\n        \"\"\"", "\n", "text_data", "=", "tx", ".", "data", ".", "MonoTextData", "(", "self", ".", "_hparams", ")", "\n", "self", ".", "assertSetEqual", "(", "set", "(", "text_data", ".", "list_items", "(", ")", ")", ",", "\n", "{", "\"text\"", ",", "\"text_ids\"", ",", "\"length\"", "}", ")", "\n", "\n", "hparams", "=", "copy", ".", "copy", "(", "self", ".", "_hparams", ")", "\n", "hparams", "[", "\"dataset\"", "]", "[", "\"data_name\"", "]", "=", "\"data\"", "\n", "text_data", "=", "tx", ".", "data", ".", "MonoTextData", "(", "hparams", ")", "\n", "self", ".", "assertSetEqual", "(", "set", "(", "text_data", ".", "list_items", "(", ")", ")", ",", "\n", "{", "\"data_text\"", ",", "\"data_text_ids\"", ",", "\"data_length\"", "}", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.mono_text_data_test.MonoTextDataTest.test_length_discard": [[224, 231], ["copy.copy", "hparams[].update", "mono_text_data_test.MonoTextDataTest._run_and_test"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.data.mono_text_data_test.VarUttMonoTextDataTest._run_and_test"], ["", "def", "test_length_discard", "(", "self", ")", ":", "\n", "        ", "\"\"\"Tests discard lenghy seq.\n        \"\"\"", "\n", "hparams", "=", "copy", ".", "copy", "(", "self", ".", "_hparams", ")", "\n", "hparams", "[", "\"dataset\"", "]", ".", "update", "(", "{", "\"max_seq_length\"", ":", "4", ",", "\n", "\"length_filter_mode\"", ":", "\"discard\"", "}", ")", "\n", "self", ".", "_run_and_test", "(", "hparams", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.mono_text_data_test.MonoTextDataTest.test_length_truncate": [[232, 241], ["copy.copy", "hparams[].update", "mono_text_data_test.MonoTextDataTest._run_and_test"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.data.mono_text_data_test.VarUttMonoTextDataTest._run_and_test"], ["", "def", "test_length_truncate", "(", "self", ")", ":", "\n", "        ", "\"\"\"Tests truncation.\n        \"\"\"", "\n", "hparams", "=", "copy", ".", "copy", "(", "self", ".", "_hparams", ")", "\n", "hparams", "[", "\"dataset\"", "]", ".", "update", "(", "{", "\"max_seq_length\"", ":", "4", ",", "\n", "\"length_filter_mode\"", ":", "\"truncate\"", "}", ")", "\n", "hparams", "[", "\"shuffle\"", "]", "=", "False", "\n", "hparams", "[", "\"allow_smaller_final_batch\"", "]", "=", "False", "\n", "self", ".", "_run_and_test", "(", "hparams", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.mono_text_data_test.MonoTextDataTest.test_pad_to_max_length": [[242, 250], ["copy.copy", "hparams[].update", "mono_text_data_test.MonoTextDataTest._run_and_test"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.data.mono_text_data_test.VarUttMonoTextDataTest._run_and_test"], ["", "def", "test_pad_to_max_length", "(", "self", ")", ":", "\n", "        ", "\"\"\"Tests padding.\n        \"\"\"", "\n", "hparams", "=", "copy", ".", "copy", "(", "self", ".", "_hparams", ")", "\n", "hparams", "[", "\"dataset\"", "]", ".", "update", "(", "{", "\"max_seq_length\"", ":", "10", ",", "\n", "\"length_filter_mode\"", ":", "\"truncate\"", ",", "\n", "\"pad_to_max_seq_length\"", ":", "True", "}", ")", "\n", "self", ".", "_run_and_test", "(", "hparams", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.mono_text_data_test.VarUttMonoTextDataTest.setUp": [[256, 291], ["tensorflow.test.TestCase.setUp", "tempfile.NamedTemporaryFile", "tempfile.NamedTemporaryFile.write", "tempfile.NamedTemporaryFile.flush", "len", "tempfile.NamedTemporaryFile", "tempfile.NamedTemporaryFile.write", "tempfile.NamedTemporaryFile.flush"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.losses.mle_losses_test.MLELossesTest.setUp"], ["def", "setUp", "(", "self", ")", ":", "\n", "        ", "tf", ".", "test", ".", "TestCase", ".", "setUp", "(", "self", ")", "\n", "\n", "# Create test data", "\n", "vocab_list", "=", "[", "'word'", ",", "'sentence'", ",", "'\u8bcd'", ",", "'response'", ",", "'dialog'", ",", "'1'", ",", "'2'", "]", "\n", "vocab_file", "=", "tempfile", ".", "NamedTemporaryFile", "(", ")", "\n", "vocab_file", ".", "write", "(", "'\\n'", ".", "join", "(", "vocab_list", ")", ".", "encode", "(", "\"utf-8\"", ")", ")", "\n", "vocab_file", ".", "flush", "(", ")", "\n", "self", ".", "_vocab_file", "=", "vocab_file", "\n", "self", ".", "_vocab_size", "=", "len", "(", "vocab_list", ")", "\n", "\n", "text", "=", "[", "\n", "'This is a dialog 1 sentence . ||| This is a dialog 1 sentence . '", "\n", "'||| This is yet another dialog 1 sentence .'", ",", "#//", "\n", "'This is a dialog 2 sentence . ||| '", "\n", "'This is also a dialog 2 sentence . '", ",", "#//", "\n", "'\u8bcd \u8bcd \u8bcd ||| word'", ",", "#//", "\n", "'This This'", ",", "#//", "\n", "'1 1 1 ||| 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 ||| 1 1 1 ||| 2'", "\n", "]", "\n", "text_file", "=", "tempfile", ".", "NamedTemporaryFile", "(", ")", "\n", "text_file", ".", "write", "(", "'\\n'", ".", "join", "(", "text", ")", ".", "encode", "(", "\"utf-8\"", ")", ")", "\n", "text_file", ".", "flush", "(", ")", "\n", "self", ".", "_text_file", "=", "text_file", "\n", "\n", "self", ".", "_hparams", "=", "{", "\n", "\"num_epochs\"", ":", "50", ",", "\n", "\"batch_size\"", ":", "3", ",", "\n", "\"shuffle\"", ":", "False", ",", "\n", "\"dataset\"", ":", "{", "\n", "\"files\"", ":", "self", ".", "_text_file", ".", "name", ",", "\n", "\"vocab_file\"", ":", "self", ".", "_vocab_file", ".", "name", ",", "\n", "\"variable_utterance\"", ":", "True", ",", "\n", "\"max_utterance_cnt\"", ":", "3", ",", "\n", "\"max_seq_length\"", ":", "10", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.mono_text_data_test.VarUttMonoTextDataTest._run_and_test": [[294, 337], ["texar.data.MonoTextData", "mono_text_data_test.VarUttMonoTextDataTest.assertEqual", "texar.data.MonoTextData.dataset.make_initializable_iterator", "tx.data.MonoTextData.dataset.make_initializable_iterator.get_next", "mono_text_data_test.VarUttMonoTextDataTest.test_session", "sess.run", "sess.run", "sess.run", "sess.run", "len", "tensorflow.global_variables_initializer", "tensorflow.local_variables_initializer", "tensorflow.tables_initializer", "sess.run", "mono_text_data_test.VarUttMonoTextDataTest.assertEqual", "numpy.sum", "mono_text_data_test.VarUttMonoTextDataTest.assertListEqual", "set", "set", "numpy.sum", "data_batch_[].tolist", "numpy.sum.tolist", "print", "sess.run.keys", "texar.data.MonoTextData.list_items", "mono_text_data_test.VarUttMonoTextDataTest.assertEqual", "mono_text_data_test.VarUttMonoTextDataTest.assertEqual", "len", "len"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.data.data_iterators.FeedableDataIterator.get_next", "home.repos.pwc.inspect_result.VegB_Text_Infilling.texar.hyperparams.HParams.keys", "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.multi_aligned_data.MultiAlignedData.list_items"], ["", "def", "_run_and_test", "(", "self", ",", "hparams", ")", ":", "\n", "# Construct database", "\n", "        ", "text_data", "=", "tx", ".", "data", ".", "MonoTextData", "(", "hparams", ")", "\n", "self", ".", "assertEqual", "(", "text_data", ".", "vocab", ".", "size", ",", "\n", "self", ".", "_vocab_size", "+", "len", "(", "text_data", ".", "vocab", ".", "special_tokens", ")", ")", "\n", "\n", "iterator", "=", "text_data", ".", "dataset", ".", "make_initializable_iterator", "(", ")", "\n", "text_data_batch", "=", "iterator", ".", "get_next", "(", ")", "\n", "\n", "with", "self", ".", "test_session", "(", ")", "as", "sess", ":", "\n", "            ", "sess", ".", "run", "(", "tf", ".", "global_variables_initializer", "(", ")", ")", "\n", "sess", ".", "run", "(", "tf", ".", "local_variables_initializer", "(", ")", ")", "\n", "sess", ".", "run", "(", "tf", ".", "tables_initializer", "(", ")", ")", "\n", "sess", ".", "run", "(", "iterator", ".", "initializer", ")", "\n", "\n", "while", "True", ":", "\n", "                ", "try", ":", "\n", "# Run the logics", "\n", "                    ", "data_batch_", "=", "sess", ".", "run", "(", "text_data_batch", ")", "\n", "\n", "self", ".", "assertEqual", "(", "set", "(", "data_batch_", ".", "keys", "(", ")", ")", ",", "\n", "set", "(", "text_data", ".", "list_items", "(", ")", ")", ")", "\n", "\n", "# Test utterance count", "\n", "utt_ind", "=", "np", ".", "sum", "(", "data_batch_", "[", "\"text_ids\"", "]", ",", "2", ")", "!=", "0", "\n", "utt_cnt", "=", "np", ".", "sum", "(", "utt_ind", ",", "1", ")", "\n", "self", ".", "assertListEqual", "(", "\n", "data_batch_", "[", "text_data", ".", "utterance_cnt_name", "]", ".", "tolist", "(", ")", ",", "\n", "utt_cnt", ".", "tolist", "(", ")", ")", "\n", "\n", "if", "text_data", ".", "hparams", ".", "dataset", ".", "pad_to_max_seq_length", ":", "\n", "                        ", "max_l", "=", "text_data", ".", "hparams", ".", "dataset", ".", "max_seq_length", "\n", "max_l", "+=", "text_data", ".", "_decoder", ".", "added_length", "\n", "for", "x", "in", "data_batch_", "[", "'text'", "]", ":", "\n", "                            ", "for", "xx", "in", "x", ":", "\n", "                                ", "self", ".", "assertEqual", "(", "len", "(", "xx", ")", ",", "max_l", ")", "\n", "", "", "for", "x", "in", "data_batch_", "[", "'text_ids'", "]", ":", "\n", "                            ", "for", "xx", "in", "x", ":", "\n", "                                ", "self", ".", "assertEqual", "(", "len", "(", "xx", ")", ",", "max_l", ")", "\n", "\n", "", "", "", "", "except", "tf", ".", "errors", ".", "OutOfRangeError", ":", "\n", "                    ", "print", "(", "'Done -- epoch limit reached'", ")", "\n", "break", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.mono_text_data_test.VarUttMonoTextDataTest.test_default_setting": [[338, 342], ["mono_text_data_test.VarUttMonoTextDataTest._run_and_test"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.data.mono_text_data_test.VarUttMonoTextDataTest._run_and_test"], ["", "", "", "", "def", "test_default_setting", "(", "self", ")", ":", "\n", "        ", "\"\"\"Tests the logics of the text data.\n        \"\"\"", "\n", "self", ".", "_run_and_test", "(", "self", ".", "_hparams", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.mono_text_data_test.VarUttMonoTextDataTest.test_pad_to_max_length": [[343, 351], ["copy.copy", "hparams[].update", "mono_text_data_test.VarUttMonoTextDataTest._run_and_test"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.data.mono_text_data_test.VarUttMonoTextDataTest._run_and_test"], ["", "def", "test_pad_to_max_length", "(", "self", ")", ":", "\n", "        ", "\"\"\"Tests padding.\n        \"\"\"", "\n", "hparams", "=", "copy", ".", "copy", "(", "self", ".", "_hparams", ")", "\n", "hparams", "[", "\"dataset\"", "]", ".", "update", "(", "{", "\"max_seq_length\"", ":", "20", ",", "\n", "\"length_filter_mode\"", ":", "\"truncate\"", ",", "\n", "\"pad_to_max_seq_length\"", ":", "True", "}", ")", "\n", "self", ".", "_run_and_test", "(", "hparams", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.data_base.DataBase.__init__": [[27, 29], ["texar.hyperparams.HParams", "data_base.DataBase.default_hparams"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.core.replay_memories.DequeReplayMemory.default_hparams"], ["def", "__init__", "(", "self", ",", "hparams", ")", ":", "\n", "        ", "self", ".", "_hparams", "=", "HParams", "(", "hparams", ",", "self", ".", "default_hparams", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.data_base.DataBase.default_hparams": [[31, 53], ["None"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "default_hparams", "(", ")", ":", "\n", "        ", "\"\"\"Returns a dictionary of default hyperparameters.\n\n            max_dataset_size: int, maximum number of instances to include in\n                the dataset. If set to `-1` or greater than the size of\n                dataset, all instances will be included. This constraint is\n                imposed after data shuffling and filtering.\n\n        \"\"\"", "\n", "return", "{", "\n", "\"name\"", ":", "\"data\"", ",", "\n", "\"num_epochs\"", ":", "1", ",", "\n", "\"batch_size\"", ":", "64", ",", "\n", "\"allow_smaller_final_batch\"", ":", "True", ",", "\n", "\"shuffle\"", ":", "True", ",", "\n", "\"shuffle_buffer_size\"", ":", "None", ",", "\n", "\"shard_and_shuffle\"", ":", "False", ",", "\n", "\"num_parallel_calls\"", ":", "1", ",", "\n", "\"prefetch_buffer_size\"", ":", "0", ",", "\n", "\"max_dataset_size\"", ":", "-", "1", ",", "\n", "\"seed\"", ":", "None", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.data_base.DataBase._make_batch": [[55, 70], ["dataset.batch.batch.repeat", "dataset.batch.batch.apply", "dataset.batch.batch.padded_batch", "dataset.batch.batch.batch", "tensorflow.contrib.data.padded_batch_and_drop_remainder"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_make_batch", "(", "dataset", ",", "hparams", ",", "padded_batch", "=", "False", ")", ":", "\n", "        ", "dataset", "=", "dataset", ".", "repeat", "(", "hparams", ".", "num_epochs", ")", "\n", "batch_size", "=", "hparams", "[", "\"batch_size\"", "]", "\n", "if", "hparams", "[", "\"allow_smaller_final_batch\"", "]", ":", "\n", "            ", "if", "padded_batch", ":", "\n", "                ", "dataset", "=", "dataset", ".", "padded_batch", "(", "\n", "batch_size", ",", "dataset", ".", "output_shapes", ")", "\n", "", "else", ":", "\n", "                ", "dataset", "=", "dataset", ".", "batch", "(", "batch_size", ")", "\n", "", "", "else", ":", "\n", "            ", "dataset", "=", "dataset", ".", "apply", "(", "\n", "tf", ".", "contrib", ".", "data", ".", "padded_batch_and_drop_remainder", "(", "\n", "batch_size", ",", "dataset", ".", "output_shapes", ")", ")", "\n", "", "return", "dataset", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.data_base.DataBase._shuffle_dataset": [[71, 98], ["texar.data.data_utils.count_file_lines", "dataset.shuffle.shuffle.apply", "dataset.shuffle.shuffle.shuffle", "ValueError", "ValueError", "texar.data.data.dataset_utils.random_shard_dataset", "dataset.shuffle.shuffle.shuffle", "texar.data.data_utils.count_file_lines"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.data.data_utils.count_file_lines", "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.dataset_utils.random_shard_dataset", "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.data_utils.count_file_lines"], ["", "@", "staticmethod", "\n", "def", "_shuffle_dataset", "(", "dataset", ",", "hparams", ",", "dataset_files", ")", ":", "\n", "        ", "dataset_size", "=", "None", "\n", "shuffle_buffer_size", "=", "hparams", "[", "\"shuffle_buffer_size\"", "]", "\n", "if", "hparams", "[", "\"shard_and_shuffle\"", "]", ":", "\n", "            ", "if", "shuffle_buffer_size", "is", "None", ":", "\n", "                ", "raise", "ValueError", "(", "\n", "\"Dataset hyperparameter 'shuffle_buffer_size' \"", "\n", "\"must not be `None` if 'shard_and_shuffle'=`True`.\"", ")", "\n", "", "dataset_size", "=", "count_file_lines", "(", "dataset_files", ")", "\n", "if", "shuffle_buffer_size", ">=", "dataset_size", ":", "\n", "                ", "raise", "ValueError", "(", "\n", "\"Dataset size (%d) <= shuffle_buffer_size (%d). Set \"", "\n", "\"shuffle_and_shard to `False`.\"", "%", "\n", "(", "dataset_size", ",", "shuffle_buffer_size", ")", ")", "\n", "#TODO(zhiting): Use a different seed?", "\n", "", "dataset", "=", "dataset", ".", "apply", "(", "dsutils", ".", "random_shard_dataset", "(", "\n", "dataset_size", ",", "shuffle_buffer_size", ",", "hparams", "[", "\"seed\"", "]", ")", ")", "\n", "dataset", "=", "dataset", ".", "shuffle", "(", "shuffle_buffer_size", "+", "16", ",", "# add a margin", "\n", "seed", "=", "hparams", "[", "\"seed\"", "]", ")", "\n", "", "elif", "hparams", "[", "\"shuffle\"", "]", ":", "\n", "            ", "if", "shuffle_buffer_size", "is", "None", ":", "\n", "                ", "dataset_size", "=", "count_file_lines", "(", "dataset_files", ")", "\n", "shuffle_buffer_size", "=", "dataset_size", "\n", "", "dataset", "=", "dataset", ".", "shuffle", "(", "shuffle_buffer_size", ",", "seed", "=", "hparams", "[", "\"seed\"", "]", ")", "\n", "\n", "", "return", "dataset", ",", "dataset_size", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.data_base.DataBase.num_epochs": [[99, 104], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "num_epochs", "(", "self", ")", ":", "\n", "        ", "\"\"\"Number of epochs.\n        \"\"\"", "\n", "return", "self", ".", "_hparams", ".", "num_epochs", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.data_base.DataBase.batch_size": [[105, 110], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "batch_size", "(", "self", ")", ":", "\n", "        ", "\"\"\"The batch size.\n        \"\"\"", "\n", "return", "self", ".", "_hparams", ".", "batch_size", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.data_base.DataBase.hparams": [[111, 117], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "hparams", "(", "self", ")", ":", "\n", "        ", "\"\"\"A :class:`~texar.hyperparams.HParams` instance of the\n        data hyperparameters.\n        \"\"\"", "\n", "return", "self", ".", "_hparams", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.data_base.DataBase.name": [[118, 123], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "name", "(", "self", ")", ":", "\n", "        ", "\"\"\"The data name.\n        \"\"\"", "\n", "return", "self", ".", "_hparams", ".", "name", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.text_data_base.TextDataBase.__init__": [[26, 28], ["texar.data.data.data_base.DataBase.__init__"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.text_infilling.self_attn_hyperparams.Hyperparams.__init__"], ["def", "__init__", "(", "self", ",", "hparams", ")", ":", "\n", "        ", "DataBase", ".", "__init__", "(", "self", ",", "hparams", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.text_data_base.TextDataBase.default_hparams": [[30, 40], ["texar.data.data.data_base.DataBase.default_hparams", "texar.data.data.data_base.DataBase.default_hparams.update"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.core.replay_memories.DequeReplayMemory.default_hparams"], ["", "@", "staticmethod", "\n", "def", "default_hparams", "(", ")", ":", "\n", "        ", "\"\"\"Returns a dictionary of default hyperparameters.\n        \"\"\"", "\n", "hparams", "=", "DataBase", ".", "default_hparams", "(", ")", "\n", "hparams", ".", "update", "(", "{", "\n", "\"bucket_boundaries\"", ":", "[", "]", ",", "\n", "\"bucket_batch_sizes\"", ":", "None", ",", "\n", "\"bucket_length_fn\"", ":", "None", "}", ")", "\n", "return", "hparams", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.text_data_base.TextDataBase._make_batch": [[41, 77], ["dataset.filter.filter.repeat", "len", "dataset.filter.filter.apply", "dataset.filter.filter.padded_batch", "dataset.filter.filter.apply", "tensorflow.contrib.data.bucket_by_sequence_length", "texar.data.data.dataset_utils._make_smaller_batch_filter_fn", "dataset.filter.filter.filter", "tensorflow.contrib.data.padded_batch_and_drop_remainder", "len", "ValueError", "len", "set", "texar.data.data.dataset_utils._make_smaller_batch_filter_fn.", "texar.data.data.dataset_utils.maybe_tuple"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.data.dataset_utils._make_smaller_batch_filter_fn", "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.dataset_utils.maybe_tuple"], ["", "@", "staticmethod", "\n", "def", "_make_batch", "(", "dataset", ",", "hparams", ",", "element_length_func", ",", "\n", "padded_shapes", "=", "None", ",", "padding_values", "=", "None", ")", ":", "\n", "        ", "dataset", "=", "dataset", ".", "repeat", "(", "hparams", ".", "num_epochs", ")", "\n", "\n", "batch_size", "=", "hparams", "[", "\"batch_size\"", "]", "\n", "bucket_boundaries", "=", "hparams", "[", "\"bucket_boundaries\"", "]", "\n", "if", "padded_shapes", "is", "None", ":", "\n", "            ", "padded_shapes", "=", "dataset", ".", "output_shapes", "\n", "\n", "", "if", "len", "(", "bucket_boundaries", ")", "==", "0", ":", "\n", "            ", "if", "hparams", "[", "\"allow_smaller_final_batch\"", "]", ":", "\n", "                ", "dataset", "=", "dataset", ".", "padded_batch", "(", "\n", "batch_size", ",", "padded_shapes", ",", "padding_values", "=", "padding_values", ")", "\n", "", "else", ":", "\n", "                ", "dataset", "=", "dataset", ".", "apply", "(", "\n", "tf", ".", "contrib", ".", "data", ".", "padded_batch_and_drop_remainder", "(", "\n", "batch_size", ",", "padded_shapes", ",", "\n", "padding_values", "=", "padding_values", ")", ")", "\n", "", "", "else", ":", "\n", "            ", "bucket_batch_size", "=", "hparams", "[", "\"bucket_batch_sizes\"", "]", "\n", "if", "bucket_batch_size", "is", "None", ":", "\n", "                ", "bucket_batch_size", "=", "[", "batch_size", "]", "*", "(", "len", "(", "bucket_boundaries", ")", "+", "1", ")", "\n", "", "dataset", "=", "dataset", ".", "apply", "(", "tf", ".", "contrib", ".", "data", ".", "bucket_by_sequence_length", "(", "\n", "element_length_func", ",", "bucket_boundaries", ",", "bucket_batch_size", ")", ")", "\n", "if", "not", "hparams", "[", "\"allow_smaller_final_batch\"", "]", ":", "\n", "                ", "if", "len", "(", "set", "(", "bucket_batch_size", ")", ")", ">", "1", ":", "\n", "                    ", "raise", "ValueError", "(", "\n", "\"Batch size of every bucket must be the same if \"", "\n", "\"smaller final batch is not allowed.\"", ")", "\n", "", "batch_size", "=", "bucket_batch_size", "[", "0", "]", "\n", "filter_fn", "=", "dsutils", ".", "_make_smaller_batch_filter_fn", "(", "batch_size", ")", "\n", "dataset", "=", "dataset", ".", "filter", "(", "\n", "lambda", "*", "args", ":", "filter_fn", "(", "dsutils", ".", "maybe_tuple", "(", "args", ")", ")", ")", "\n", "\n", "", "", "return", "dataset", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.multi_aligned_data.MultiAlignedData.__init__": [[72, 86], ["texar.data.data.text_data_base.TextDataBase.__init__", "ds_hpms.get", "texar.hyperparams.HParams", "defaultized_datasets_hparams.append", "tensorflow.name_scope", "multi_aligned_data.MultiAlignedData._make_data", "multi_aligned_data._default_dataset_hparams", "multi_aligned_data.MultiAlignedData.default_hparams"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.text_infilling.self_attn_hyperparams.Hyperparams.__init__", "home.repos.pwc.inspect_result.VegB_Text_Infilling.core.replay_memories.DequeReplayMemory.get", "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.multi_aligned_data.MultiAlignedData._make_data", "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.multi_aligned_data._default_dataset_hparams", "home.repos.pwc.inspect_result.VegB_Text_Infilling.core.replay_memories.DequeReplayMemory.default_hparams"], ["def", "__init__", "(", "self", ",", "hparams", ")", ":", "\n", "        ", "TextDataBase", ".", "__init__", "(", "self", ",", "hparams", ")", "\n", "# Defaultizes hparams of each dataset", "\n", "datasets_hparams", "=", "self", ".", "_hparams", ".", "datasets", "\n", "defaultized_datasets_hparams", "=", "[", "]", "\n", "for", "ds_hpms", "in", "datasets_hparams", ":", "\n", "            ", "data_type", "=", "ds_hpms", ".", "get", "(", "\"data_type\"", ",", "None", ")", "\n", "defaultized_ds_hpms", "=", "HParams", "(", "ds_hpms", ",", "\n", "_default_dataset_hparams", "(", "data_type", ")", ")", "\n", "defaultized_datasets_hparams", ".", "append", "(", "defaultized_ds_hpms", ")", "\n", "", "self", ".", "_hparams", ".", "datasets", "=", "defaultized_datasets_hparams", "\n", "\n", "with", "tf", ".", "name_scope", "(", "self", ".", "name", ",", "self", ".", "default_hparams", "(", ")", "[", "\"name\"", "]", ")", ":", "\n", "            ", "self", ".", "_make_data", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.multi_aligned_data.MultiAlignedData.default_hparams": [[87, 95], ["texar.data.data.text_data_base.TextDataBase.default_hparams", "multi_aligned_data._default_dataset_hparams"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.core.replay_memories.DequeReplayMemory.default_hparams", "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.multi_aligned_data._default_dataset_hparams"], ["", "", "@", "staticmethod", "\n", "def", "default_hparams", "(", ")", ":", "\n", "        ", "\"\"\"Returns a dicitionary of default hyperparameters.\n        \"\"\"", "\n", "hparams", "=", "TextDataBase", ".", "default_hparams", "(", ")", "\n", "hparams", "[", "\"name\"", "]", "=", "\"multi_aligned_data\"", "\n", "hparams", "[", "\"datasets\"", "]", "=", "[", "_default_dataset_hparams", "(", ")", "]", "\n", "return", "hparams", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.multi_aligned_data.MultiAlignedData._raise_sharing_error": [[96, 101], ["ValueError"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_raise_sharing_error", "(", "err_data", ",", "shr_data", ",", "hparam_name", ")", ":", "\n", "        ", "raise", "ValueError", "(", "\n", "\"Must only share specifications with a preceding dataset. \"", "\n", "\"Dataset %d has '%s=%d'\"", "%", "(", "err_data", ",", "hparam_name", ",", "shr_data", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.multi_aligned_data.MultiAlignedData.make_vocab": [[102, 157], ["enumerate", "isinstance", "texar.utils.utils.default_str", "texar.utils.utils.default_str", "vocabs.append", "multi_aligned_data._is_text_data", "vocabs.append", "texar.data.vocabulary.Vocab", "multi_aligned_data.MultiAlignedData._raise_sharing_error", "ValueError", "texar.data.vocabulary.Vocab"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.utils.default_str", "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.utils.default_str", "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.multi_aligned_data._is_text_data", "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.multi_aligned_data.MultiAlignedData._raise_sharing_error"], ["", "@", "staticmethod", "\n", "def", "make_vocab", "(", "hparams", ")", ":", "\n", "        ", "\"\"\"Makes a list of vocabs based on the hparams.\n\n        Args:\n            hparams (list): A list of dataset hyperparameters.\n\n        Returns:\n            A list of :class:`texar.data.Vocab` instances. Some instances\n            may be the same objects if they are set to be shared and have\n            the same other configs.\n        \"\"\"", "\n", "if", "not", "isinstance", "(", "hparams", ",", "(", "list", ",", "tuple", ")", ")", ":", "\n", "            ", "hparams", "=", "[", "hparams", "]", "\n", "\n", "", "vocabs", "=", "[", "]", "\n", "for", "i", ",", "hparams_i", "in", "enumerate", "(", "hparams", ")", ":", "\n", "            ", "if", "not", "_is_text_data", "(", "hparams_i", "[", "\"data_type\"", "]", ")", ":", "\n", "                ", "vocabs", ".", "append", "(", "None", ")", "\n", "continue", "\n", "\n", "", "proc_shr", "=", "hparams_i", "[", "\"processing_share_with\"", "]", "\n", "if", "proc_shr", "is", "not", "None", ":", "\n", "                ", "bos_token", "=", "hparams", "[", "proc_shr", "]", "[", "\"bos_token\"", "]", "\n", "eos_token", "=", "hparams", "[", "proc_shr", "]", "[", "\"eos_token\"", "]", "\n", "", "else", ":", "\n", "                ", "bos_token", "=", "hparams_i", "[", "\"bos_token\"", "]", "\n", "eos_token", "=", "hparams_i", "[", "\"eos_token\"", "]", "\n", "", "bos_token", "=", "utils", ".", "default_str", "(", "\n", "bos_token", ",", "SpecialTokens", ".", "BOS", ")", "\n", "eos_token", "=", "utils", ".", "default_str", "(", "\n", "eos_token", ",", "SpecialTokens", ".", "EOS", ")", "\n", "\n", "vocab_shr", "=", "hparams_i", "[", "\"vocab_share_with\"", "]", "\n", "if", "vocab_shr", "is", "not", "None", ":", "\n", "                ", "if", "vocab_shr", ">=", "i", ":", "\n", "                    ", "MultiAlignedData", ".", "_raise_sharing_error", "(", "\n", "i", ",", "vocab_shr", ",", "\"vocab_share_with\"", ")", "\n", "", "if", "not", "vocabs", "[", "vocab_shr", "]", ":", "\n", "                    ", "raise", "ValueError", "(", "\"Cannot share vocab with dataset %d which \"", "\n", "\"does not have a vocab.\"", "%", "vocab_shr", ")", "\n", "", "if", "bos_token", "==", "vocabs", "[", "vocab_shr", "]", ".", "bos_token", "and", "eos_token", "==", "vocabs", "[", "vocab_shr", "]", ".", "eos_token", ":", "\n", "                    ", "vocab", "=", "vocabs", "[", "vocab_shr", "]", "\n", "", "else", ":", "\n", "                    ", "vocab", "=", "Vocab", "(", "hparams", "[", "vocab_shr", "]", "[", "\"vocab_file\"", "]", ",", "\n", "bos_token", "=", "bos_token", ",", "\n", "eos_token", "=", "eos_token", ")", "\n", "", "", "else", ":", "\n", "                ", "vocab", "=", "Vocab", "(", "hparams_i", "[", "\"vocab_file\"", "]", ",", "\n", "bos_token", "=", "bos_token", ",", "\n", "eos_token", "=", "eos_token", ")", "\n", "", "vocabs", ".", "append", "(", "vocab", ")", "\n", "\n", "", "return", "vocabs", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.multi_aligned_data.MultiAlignedData.make_embedding": [[158, 195], ["enumerate", "isinstance", "embs.append", "multi_aligned_data._is_text_data", "embs.append", "multi_aligned_data.MultiAlignedData._raise_sharing_error", "ValueError", "ValueError", "texar.data.embedding.Embedding"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.data.multi_aligned_data._is_text_data", "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.multi_aligned_data.MultiAlignedData._raise_sharing_error"], ["", "@", "staticmethod", "\n", "def", "make_embedding", "(", "hparams", ",", "vocabs", ")", ":", "\n", "        ", "\"\"\"Optionally loads embeddings from files (if provided), and\n        returns respective :class:`texar.data.Embedding` instances.\n        \"\"\"", "\n", "if", "not", "isinstance", "(", "hparams", ",", "(", "list", ",", "tuple", ")", ")", ":", "\n", "            ", "hparams", "=", "[", "hparams", "]", "\n", "\n", "", "embs", "=", "[", "]", "\n", "for", "i", ",", "hparams_i", "in", "enumerate", "(", "hparams", ")", ":", "\n", "            ", "if", "not", "_is_text_data", "(", "hparams_i", "[", "\"data_type\"", "]", ")", ":", "\n", "                ", "embs", ".", "append", "(", "None", ")", "\n", "continue", "\n", "\n", "", "emb_shr", "=", "hparams_i", "[", "\"embedding_init_share_with\"", "]", "\n", "if", "emb_shr", "is", "not", "None", ":", "\n", "                ", "if", "emb_shr", ">=", "i", ":", "\n", "                    ", "MultiAlignedData", ".", "_raise_sharing_error", "(", "\n", "i", ",", "emb_shr", ",", "\"embedding_init_share_with\"", ")", "\n", "", "if", "not", "embs", "[", "emb_shr", "]", ":", "\n", "                    ", "raise", "ValueError", "(", "\"Cannot share embedding with dataset %d \"", "\n", "\"which does not have an embedding.\"", "%", "\n", "emb_shr", ")", "\n", "", "if", "emb_shr", "!=", "hparams_i", "[", "\"vocab_share_with\"", "]", ":", "\n", "                    ", "raise", "ValueError", "(", "\"'embedding_init_share_with' != \"", "\n", "\"vocab_share_with. embedding_init can \"", "\n", "\"be shared only when vocab is shared.\"", ")", "\n", "", "emb", "=", "embs", "[", "emb_shr", "]", "\n", "", "else", ":", "\n", "                ", "emb", "=", "None", "\n", "emb_file", "=", "hparams_i", "[", "\"embedding_init\"", "]", "[", "\"file\"", "]", "\n", "if", "emb_file", "and", "emb_file", "!=", "\"\"", ":", "\n", "                    ", "emb", "=", "Embedding", "(", "vocabs", "[", "i", "]", ".", "token_to_id_map_py", ",", "\n", "hparams_i", "[", "\"embedding_init\"", "]", ")", "\n", "", "", "embs", ".", "append", "(", "emb", ")", "\n", "\n", "", "return", "embs", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.multi_aligned_data.MultiAlignedData._make_dataset": [[196, 208], ["enumerate", "tensorflow.data.Dataset.zip", "tuple", "multi_aligned_data._is_text_data", "multi_aligned_data._is_scalar_data", "tensorflow.data.TextLineDataset", "datasets.append", "ValueError"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.data.multi_aligned_data._is_text_data", "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.multi_aligned_data._is_scalar_data"], ["", "def", "_make_dataset", "(", "self", ")", ":", "\n", "        ", "datasets", "=", "[", "]", "\n", "for", "_", ",", "hparams_i", "in", "enumerate", "(", "self", ".", "_hparams", ".", "datasets", ")", ":", "\n", "            ", "dtype", "=", "hparams_i", ".", "data_type", "\n", "if", "_is_text_data", "(", "dtype", ")", "or", "_is_scalar_data", "(", "dtype", ")", ":", "\n", "                ", "dataset", "=", "tf", ".", "data", ".", "TextLineDataset", "(", "\n", "hparams_i", ".", "files", ",", "\n", "compression_type", "=", "hparams_i", ".", "compression_type", ")", "\n", "datasets", ".", "append", "(", "dataset", ")", "\n", "", "else", ":", "\n", "                ", "raise", "ValueError", "(", "\"Unknown data type: %s\"", "%", "hparams_i", ".", "data_type", ")", "\n", "", "", "return", "tf", ".", "data", ".", "Dataset", ".", "zip", "(", "tuple", "(", "datasets", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.multi_aligned_data.MultiAlignedData._get_name_prefix": [[233, 240], ["range", "len", "ValueError"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_get_name_prefix", "(", "dataset_hparams", ")", ":", "\n", "        ", "name_prefix", "=", "[", "hpms", "[", "\"data_name\"", "]", "for", "hpms", "in", "dataset_hparams", "]", "\n", "for", "i", "in", "range", "(", "1", ",", "len", "(", "name_prefix", ")", ")", ":", "\n", "            ", "if", "name_prefix", "[", "i", "]", "in", "name_prefix", "[", ":", "i", "-", "1", "]", ":", "\n", "                ", "raise", "ValueError", "(", "\"Data name duplicated: %s\"", "%", "name_prefix", "[", "i", "]", ")", "\n", "", "", "return", "name_prefix", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.multi_aligned_data.MultiAlignedData._make_processor": [[241, 277], ["enumerate", "texar.data.data.dataset_utils.make_combined_transformation", "data_spec.add_spec", "data_spec.get_ith_data_spec", "multi_aligned_data._is_text_data", "processors.append", "data_spec.set_ith_data_spec", "texar.data.data.mono_text_data.MonoTextData._make_processor", "multi_aligned_data._is_scalar_data", "len", "copy.copy", "texar.data.data.scalar_data.ScalarData._make_processor", "ValueError"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.data.dataset_utils.make_combined_transformation", "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.dataset_utils._DataSpec.add_spec", "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.dataset_utils._DataSpec.get_ith_data_spec", "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.multi_aligned_data._is_text_data", "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.dataset_utils._DataSpec.set_ith_data_spec", "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.multi_aligned_data.MultiAlignedData._make_processor", "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.multi_aligned_data._is_scalar_data", "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.multi_aligned_data.MultiAlignedData._make_processor"], ["", "@", "staticmethod", "\n", "def", "_make_processor", "(", "dataset_hparams", ",", "data_spec", ",", "name_prefix", ")", ":", "\n", "        ", "processors", "=", "[", "]", "\n", "for", "i", ",", "hparams_i", "in", "enumerate", "(", "dataset_hparams", ")", ":", "\n", "            ", "data_spec_i", "=", "data_spec", ".", "get_ith_data_spec", "(", "i", ")", "\n", "\n", "data_type", "=", "hparams_i", "[", "\"data_type\"", "]", "\n", "if", "_is_text_data", "(", "data_type", ")", ":", "\n", "                ", "tgt_proc_hparams", "=", "hparams_i", "\n", "proc_shr", "=", "hparams_i", "[", "\"processing_share_with\"", "]", "\n", "if", "proc_shr", "is", "not", "None", ":", "\n", "                    ", "tgt_proc_hparams", "=", "copy", ".", "copy", "(", "dataset_hparams", "[", "proc_shr", "]", ")", "\n", "try", ":", "\n", "                        ", "tgt_proc_hparams", "[", "\"variable_utterance\"", "]", "=", "hparams_i", "[", "\"variable_utterance\"", "]", "\n", "", "except", "TypeError", ":", "\n", "                        ", "tgt_proc_hparams", ".", "variable_utterance", "=", "hparams_i", "[", "\"variable_utterance\"", "]", "\n", "\n", "", "", "processor", ",", "data_spec_i", "=", "MonoTextData", ".", "_make_processor", "(", "\n", "tgt_proc_hparams", ",", "data_spec_i", ")", "\n", "", "elif", "_is_scalar_data", "(", "data_type", ")", ":", "\n", "                ", "processor", ",", "data_spec_i", "=", "ScalarData", ".", "_make_processor", "(", "\n", "hparams_i", ",", "data_spec_i", ",", "name_prefix", "=", "''", ")", "\n", "", "else", ":", "\n", "                ", "raise", "ValueError", "(", "\"Unsupported data type: %s\"", "%", "data_type", ")", "\n", "\n", "", "processors", ".", "append", "(", "processor", ")", "\n", "data_spec", ".", "set_ith_data_spec", "(", "i", ",", "data_spec_i", ",", "len", "(", "dataset_hparams", ")", ")", "\n", "\n", "", "tran_fn", "=", "dsutils", ".", "make_combined_transformation", "(", "\n", "processors", ",", "name_prefix", "=", "name_prefix", ")", "\n", "\n", "data_spec", ".", "add_spec", "(", "name_prefix", "=", "name_prefix", ")", "\n", "\n", "return", "tran_fn", ",", "data_spec", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.multi_aligned_data.MultiAlignedData._make_length_filter": [[278, 290], ["enumerate", "texar.data.data.dataset_utils._make_combined_filter_fn", "filter_fns.append", "multi_aligned_data._is_text_data", "texar.data.data.mono_text_data.MonoTextData._make_length_filter"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.data.dataset_utils._make_combined_filter_fn", "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.multi_aligned_data._is_text_data", "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.multi_aligned_data.MultiAlignedData._make_length_filter"], ["", "@", "staticmethod", "\n", "def", "_make_length_filter", "(", "dataset_hparams", ",", "length_name", ",", "decoder", ")", ":", "\n", "        ", "filter_fns", "=", "[", "]", "\n", "for", "i", ",", "hpms", "in", "enumerate", "(", "dataset_hparams", ")", ":", "\n", "            ", "if", "not", "_is_text_data", "(", "hpms", "[", "\"data_type\"", "]", ")", ":", "\n", "                ", "filter_fn", "=", "None", "\n", "", "else", ":", "\n", "                ", "filter_fn", "=", "MonoTextData", ".", "_make_length_filter", "(", "\n", "hpms", ",", "length_name", "[", "i", "]", ",", "decoder", "[", "i", "]", ")", "\n", "", "filter_fns", ".", "append", "(", "filter_fn", ")", "\n", "", "combined_filter_fn", "=", "dsutils", ".", "_make_combined_filter_fn", "(", "filter_fns", ")", "\n", "return", "combined_filter_fn", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.multi_aligned_data.MultiAlignedData._process_dataset": [[291, 323], ["multi_aligned_data.MultiAlignedData._get_name_prefix", "multi_aligned_data.MultiAlignedData._make_processor", "dataset.filter.filter.map", "multi_aligned_data.MultiAlignedData._make_length_filter", "dataset.filter.filter.take", "texar.data.data.dataset_utils._connect_name", "dataset.filter.filter.filter", "enumerate", "tran_fn", "multi_aligned_data._is_text_data", "multi_aligned_data.MultiAlignedData._process_dataset._get_length_name"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.data.multi_aligned_data.MultiAlignedData._get_name_prefix", "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.multi_aligned_data.MultiAlignedData._make_processor", "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.multi_aligned_data.MultiAlignedData._make_length_filter", "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.dataset_utils._connect_name", "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.multi_aligned_data._is_text_data"], ["", "def", "_process_dataset", "(", "self", ",", "dataset", ",", "hparams", ",", "data_spec", ")", ":", "\n", "        ", "name_prefix", "=", "self", ".", "_get_name_prefix", "(", "hparams", "[", "\"datasets\"", "]", ")", "\n", "# pylint: disable=attribute-defined-outside-init", "\n", "self", ".", "_name_to_id", "=", "{", "v", ":", "k", "for", "k", ",", "v", "in", "enumerate", "(", "name_prefix", ")", "}", "\n", "\n", "tran_fn", ",", "data_spec", "=", "self", ".", "_make_processor", "(", "\n", "hparams", "[", "\"datasets\"", "]", ",", "data_spec", ",", "name_prefix", ")", "\n", "\n", "num_parallel_calls", "=", "hparams", "[", "\"num_parallel_calls\"", "]", "\n", "dataset", "=", "dataset", ".", "map", "(", "\n", "lambda", "*", "args", ":", "tran_fn", "(", "dsutils", ".", "maybe_tuple", "(", "args", ")", ")", ",", "\n", "num_parallel_calls", "=", "num_parallel_calls", ")", "\n", "\n", "# Filters by length", "\n", "def", "_get_length_name", "(", "i", ")", ":", "\n", "            ", "if", "not", "_is_text_data", "(", "hparams", "[", "\"datasets\"", "]", "[", "i", "]", "[", "\"data_type\"", "]", ")", ":", "\n", "                ", "return", "None", "\n", "", "name", "=", "dsutils", ".", "_connect_name", "(", "\n", "data_spec", ".", "name_prefix", "[", "i", "]", ",", "\n", "data_spec", ".", "decoder", "[", "i", "]", ".", "length_tensor_name", ")", "\n", "return", "name", "\n", "", "filter_fn", "=", "self", ".", "_make_length_filter", "(", "\n", "hparams", "[", "\"datasets\"", "]", ",", "\n", "[", "_get_length_name", "(", "i", ")", "for", "i", "in", "range", "(", "len", "(", "hparams", "[", "\"datasets\"", "]", ")", ")", "]", ",", "\n", "data_spec", ".", "decoder", ")", "\n", "if", "filter_fn", ":", "\n", "            ", "dataset", "=", "dataset", ".", "filter", "(", "filter_fn", ")", "\n", "\n", "# Truncates data count", "\n", "", "dataset", "=", "dataset", ".", "take", "(", "hparams", "[", "\"max_dataset_size\"", "]", ")", "\n", "\n", "return", "dataset", ",", "data_spec", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.multi_aligned_data.MultiAlignedData._make_bucket_length_fn": [[324, 339], ["enumerate", "multi_aligned_data._is_text_data", "ValueError", "texar.utils.dtypes.is_callable", "texar.utils.utils.get_function", "multi_aligned_data.MultiAlignedData.length_name"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.data.multi_aligned_data._is_text_data", "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.dtypes.is_callable", "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.utils.get_function", "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.multi_aligned_data.MultiAlignedData.length_name"], ["", "def", "_make_bucket_length_fn", "(", "self", ")", ":", "\n", "        ", "length_fn", "=", "self", ".", "_hparams", ".", "bucket_length_fn", "\n", "if", "not", "length_fn", ":", "\n", "# Uses the length of the first text data", "\n", "            ", "i", "=", "-", "1", "\n", "for", "i", ",", "hparams_i", "in", "enumerate", "(", "self", ".", "_hparams", ".", "datasets", ")", ":", "\n", "                ", "if", "_is_text_data", "(", "hparams_i", "[", "\"data_type\"", "]", ")", ":", "\n", "                    ", "break", "\n", "", "", "if", "i", "<", "0", ":", "\n", "                ", "raise", "ValueError", "(", "\"Undefined `length_fn`.\"", ")", "\n", "", "length_fn", "=", "lambda", "x", ":", "x", "[", "self", ".", "length_name", "(", "i", ")", "]", "\n", "", "elif", "not", "is_callable", "(", "length_fn", ")", ":", "\n", "# pylint: disable=redefined-variable-type", "\n", "            ", "length_fn", "=", "utils", ".", "get_function", "(", "length_fn", ",", "[", "\"texar.custom\"", "]", ")", "\n", "", "return", "length_fn", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.multi_aligned_data.MultiAlignedData._make_padded_shapes": [[340, 354], ["enumerate", "texar.data.data.mono_text_data.MonoTextData._make_padded_text_and_id_shapes", "padded_shapes.update", "multi_aligned_data._is_text_data", "multi_aligned_data.MultiAlignedData.text_name", "multi_aligned_data.MultiAlignedData.text_id_name"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.data.mono_text_data.MonoTextData._make_padded_text_and_id_shapes", "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.multi_aligned_data._is_text_data", "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.multi_aligned_data.MultiAlignedData.text_name", "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.multi_aligned_data.MultiAlignedData.text_id_name"], ["", "def", "_make_padded_shapes", "(", "self", ",", "dataset", ",", "decoders", ")", ":", "\n", "        ", "padded_shapes", "=", "dataset", ".", "output_shapes", "\n", "for", "i", ",", "hparams_i", "in", "enumerate", "(", "self", ".", "_hparams", ".", "datasets", ")", ":", "\n", "            ", "if", "not", "_is_text_data", "(", "hparams_i", "[", "\"data_type\"", "]", ")", ":", "\n", "                ", "continue", "\n", "", "if", "not", "hparams_i", "[", "\"pad_to_max_seq_length\"", "]", ":", "\n", "                ", "continue", "\n", "", "text_and_id_shapes", "=", "MonoTextData", ".", "_make_padded_text_and_id_shapes", "(", "\n", "dataset", ",", "hparams_i", ",", "decoders", "[", "i", "]", ",", "\n", "self", ".", "text_name", "(", "i", ")", ",", "self", ".", "text_id_name", "(", "i", ")", ")", "\n", "\n", "padded_shapes", ".", "update", "(", "text_and_id_shapes", ")", "\n", "\n", "", "return", "padded_shapes", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.multi_aligned_data.MultiAlignedData._make_data": [[355, 387], ["multi_aligned_data.MultiAlignedData.make_vocab", "multi_aligned_data.MultiAlignedData.make_embedding", "multi_aligned_data.MultiAlignedData._make_dataset", "multi_aligned_data.MultiAlignedData._shuffle_dataset", "texar.data.data.dataset_utils._DataSpec", "multi_aligned_data.MultiAlignedData._process_dataset", "multi_aligned_data.MultiAlignedData._make_bucket_length_fn", "multi_aligned_data.MultiAlignedData._make_padded_shapes", "multi_aligned_data.MultiAlignedData._make_batch", "dataset.prefetch.prefetch.prefetch"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.data.multi_aligned_data.MultiAlignedData.make_vocab", "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.multi_aligned_data.MultiAlignedData.make_embedding", "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.multi_aligned_data.MultiAlignedData._make_dataset", "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.data_base.DataBase._shuffle_dataset", "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.multi_aligned_data.MultiAlignedData._process_dataset", "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.multi_aligned_data.MultiAlignedData._make_bucket_length_fn", "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.multi_aligned_data.MultiAlignedData._make_padded_shapes", "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.text_data_base.TextDataBase._make_batch"], ["", "def", "_make_data", "(", "self", ")", ":", "\n", "        ", "self", ".", "_vocab", "=", "self", ".", "make_vocab", "(", "self", ".", "_hparams", ".", "datasets", ")", "\n", "self", ".", "_embedding", "=", "self", ".", "make_embedding", "(", "self", ".", "_hparams", ".", "datasets", ",", "\n", "self", ".", "_vocab", ")", "\n", "\n", "# Create dataset", "\n", "dataset", "=", "self", ".", "_make_dataset", "(", ")", "\n", "dataset", ",", "dataset_size", "=", "self", ".", "_shuffle_dataset", "(", "\n", "dataset", ",", "self", ".", "_hparams", ",", "self", ".", "_hparams", ".", "datasets", "[", "0", "]", ".", "files", ")", "\n", "self", ".", "_dataset_size", "=", "dataset_size", "\n", "\n", "# Processing", "\n", "data_spec", "=", "dsutils", ".", "_DataSpec", "(", "dataset", "=", "dataset", ",", "\n", "dataset_size", "=", "self", ".", "_dataset_size", ",", "\n", "vocab", "=", "self", ".", "_vocab", ",", "\n", "embedding", "=", "self", ".", "_embedding", ")", "\n", "dataset", ",", "data_spec", "=", "self", ".", "_process_dataset", "(", "\n", "dataset", ",", "self", ".", "_hparams", ",", "data_spec", ")", "\n", "self", ".", "_data_spec", "=", "data_spec", "\n", "self", ".", "_decoder", "=", "data_spec", ".", "decoder", "\n", "\n", "# Batching", "\n", "length_fn", "=", "self", ".", "_make_bucket_length_fn", "(", ")", "\n", "padded_shapes", "=", "self", ".", "_make_padded_shapes", "(", "dataset", ",", "self", ".", "_decoder", ")", "\n", "dataset", "=", "self", ".", "_make_batch", "(", "\n", "dataset", ",", "self", ".", "_hparams", ",", "length_fn", ",", "padded_shapes", ")", "\n", "\n", "# Prefetching", "\n", "if", "self", ".", "_hparams", ".", "prefetch_buffer_size", ">", "0", ":", "\n", "            ", "dataset", "=", "dataset", ".", "prefetch", "(", "self", ".", "_hparams", ".", "prefetch_buffer_size", ")", "\n", "\n", "", "self", ".", "_dataset", "=", "dataset", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.multi_aligned_data.MultiAlignedData.list_items": [[389, 396], ["list", "multi_aligned_data.MultiAlignedData._dataset.output_types.keys"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.texar.hyperparams.HParams.keys"], ["", "def", "list_items", "(", "self", ")", ":", "\n", "        ", "\"\"\"Returns the list of item names that the data can produce.\n\n        Returns:\n            A list of strings.\n        \"\"\"", "\n", "return", "list", "(", "self", ".", "_dataset", ".", "output_types", ".", "keys", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.multi_aligned_data.MultiAlignedData.dataset": [[397, 402], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "dataset", "(", "self", ")", ":", "\n", "        ", "\"\"\"The dataset.\n        \"\"\"", "\n", "return", "self", ".", "_dataset", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.multi_aligned_data.MultiAlignedData.dataset_size": [[403, 414], ["texar.data.data_utils.count_file_lines"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.data.data_utils.count_file_lines"], ["", "def", "dataset_size", "(", "self", ")", ":", "\n", "        ", "\"\"\"Returns the number of data instances in the dataset.\n\n        Note that this is the total data count in the raw files, before any\n        filtering and truncation.\n        \"\"\"", "\n", "if", "not", "self", ".", "_dataset_size", ":", "\n", "# pylint: disable=attribute-defined-outside-init", "\n", "            ", "self", ".", "_dataset_size", "=", "count_file_lines", "(", "\n", "self", ".", "_hparams", ".", "datasets", "[", "0", "]", ".", "files", ")", "\n", "", "return", "self", ".", "_dataset_size", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.multi_aligned_data.MultiAlignedData._maybe_name_to_id": [[415, 421], ["texar.utils.dtypes.is_str", "ValueError"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.dtypes.is_str"], ["", "def", "_maybe_name_to_id", "(", "self", ",", "name_or_id", ")", ":", "\n", "        ", "if", "is_str", "(", "name_or_id", ")", ":", "\n", "            ", "if", "name_or_id", "not", "in", "self", ".", "_name_to_id", ":", "\n", "                ", "raise", "ValueError", "(", "\"Unknown data name: {}\"", ".", "format", "(", "name_or_id", ")", ")", "\n", "", "return", "self", ".", "_name_to_id", "[", "name_or_id", "]", "\n", "", "return", "name_or_id", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.multi_aligned_data.MultiAlignedData.vocab": [[422, 431], ["multi_aligned_data.MultiAlignedData._maybe_name_to_id"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.data.multi_aligned_data.MultiAlignedData._maybe_name_to_id"], ["", "def", "vocab", "(", "self", ",", "name_or_id", ")", ":", "\n", "        ", "\"\"\"Returns the :class:`~texar.data.Vocab` of text dataset by its name\n        or id. `None` if the dataset is not of text type.\n\n        Args:\n            name_or_id (str or int): Data name or the index of text dataset.\n        \"\"\"", "\n", "i", "=", "self", ".", "_maybe_name_to_id", "(", "name_or_id", ")", "\n", "return", "self", ".", "_vocab", "[", "i", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.multi_aligned_data.MultiAlignedData.embedding_init_value": [[432, 438], ["multi_aligned_data.MultiAlignedData._maybe_name_to_id"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.data.multi_aligned_data.MultiAlignedData._maybe_name_to_id"], ["", "def", "embedding_init_value", "(", "self", ",", "name_or_id", ")", ":", "\n", "        ", "\"\"\"Returns the `Tensor` of embedding init value of the\n        dataset by its name or id. `None` if the dataset is not of text type.\n        \"\"\"", "\n", "i", "=", "self", ".", "_maybe_name_to_id", "(", "name_or_id", ")", "\n", "return", "self", ".", "_embedding", "[", "i", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.multi_aligned_data.MultiAlignedData.text_name": [[439, 450], ["multi_aligned_data.MultiAlignedData._maybe_name_to_id", "texar.data.data.dataset_utils._connect_name", "multi_aligned_data._is_text_data"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.data.multi_aligned_data.MultiAlignedData._maybe_name_to_id", "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.dataset_utils._connect_name", "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.multi_aligned_data._is_text_data"], ["", "def", "text_name", "(", "self", ",", "name_or_id", ")", ":", "\n", "        ", "\"\"\"The name of text tensor of text dataset by its name or id. If the\n        dataaet is not of text type, returns `None`.\n        \"\"\"", "\n", "i", "=", "self", ".", "_maybe_name_to_id", "(", "name_or_id", ")", "\n", "if", "not", "_is_text_data", "(", "self", ".", "_hparams", ".", "datasets", "[", "i", "]", "[", "\"data_type\"", "]", ")", ":", "\n", "            ", "return", "None", "\n", "", "name", "=", "dsutils", ".", "_connect_name", "(", "\n", "self", ".", "_data_spec", ".", "name_prefix", "[", "i", "]", ",", "\n", "self", ".", "_data_spec", ".", "decoder", "[", "i", "]", ".", "text_tensor_name", ")", "\n", "return", "name", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.multi_aligned_data.MultiAlignedData.length_name": [[451, 462], ["multi_aligned_data.MultiAlignedData._maybe_name_to_id", "texar.data.data.dataset_utils._connect_name", "multi_aligned_data._is_text_data"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.data.multi_aligned_data.MultiAlignedData._maybe_name_to_id", "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.dataset_utils._connect_name", "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.multi_aligned_data._is_text_data"], ["", "def", "length_name", "(", "self", ",", "name_or_id", ")", ":", "\n", "        ", "\"\"\"The name of length tensor of text dataset by its name or id. If the\n        dataset is not of text type, returns `None`.\n        \"\"\"", "\n", "i", "=", "self", ".", "_maybe_name_to_id", "(", "name_or_id", ")", "\n", "if", "not", "_is_text_data", "(", "self", ".", "_hparams", ".", "datasets", "[", "i", "]", "[", "\"data_type\"", "]", ")", ":", "\n", "            ", "return", "None", "\n", "", "name", "=", "dsutils", ".", "_connect_name", "(", "\n", "self", ".", "_data_spec", ".", "name_prefix", "[", "i", "]", ",", "\n", "self", ".", "_data_spec", ".", "decoder", "[", "i", "]", ".", "length_tensor_name", ")", "\n", "return", "name", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.multi_aligned_data.MultiAlignedData.text_id_name": [[463, 474], ["multi_aligned_data.MultiAlignedData._maybe_name_to_id", "texar.data.data.dataset_utils._connect_name", "multi_aligned_data._is_text_data"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.data.multi_aligned_data.MultiAlignedData._maybe_name_to_id", "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.dataset_utils._connect_name", "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.multi_aligned_data._is_text_data"], ["", "def", "text_id_name", "(", "self", ",", "name_or_id", ")", ":", "\n", "        ", "\"\"\"The name of length tensor of text dataset by its name or id. If the\n        dataset is not of text type, returns `None`.\n        \"\"\"", "\n", "i", "=", "self", ".", "_maybe_name_to_id", "(", "name_or_id", ")", "\n", "if", "not", "_is_text_data", "(", "self", ".", "_hparams", ".", "datasets", "[", "i", "]", "[", "\"data_type\"", "]", ")", ":", "\n", "            ", "return", "None", "\n", "", "name", "=", "dsutils", ".", "_connect_name", "(", "\n", "self", ".", "_data_spec", ".", "name_prefix", "[", "i", "]", ",", "\n", "self", ".", "_data_spec", ".", "decoder", "[", "i", "]", ".", "text_id_tensor_name", ")", "\n", "return", "name", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.multi_aligned_data.MultiAlignedData.utterance_cnt_name": [[475, 487], ["multi_aligned_data.MultiAlignedData._maybe_name_to_id", "texar.data.data.dataset_utils._connect_name", "multi_aligned_data._is_text_data"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.data.multi_aligned_data.MultiAlignedData._maybe_name_to_id", "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.dataset_utils._connect_name", "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.multi_aligned_data._is_text_data"], ["", "def", "utterance_cnt_name", "(", "self", ",", "name_or_id", ")", ":", "\n", "        ", "\"\"\"The name of utterance count tensor of text dataset by its name or id.\n        If the dataset is not variable utterance text data, returns `None`.\n        \"\"\"", "\n", "i", "=", "self", ".", "_maybe_name_to_id", "(", "name_or_id", ")", "\n", "if", "not", "_is_text_data", "(", "self", ".", "_hparams", ".", "datasets", "[", "i", "]", "[", "\"data_type\"", "]", ")", "or", "not", "self", ".", "_hparams", ".", "datasets", "[", "i", "]", "[", "\"variable_utterance\"", "]", ":", "\n", "            ", "return", "None", "\n", "", "name", "=", "dsutils", ".", "_connect_name", "(", "\n", "self", ".", "_data_spec", ".", "name_prefix", "[", "i", "]", ",", "\n", "self", ".", "_data_spec", ".", "decoder", "[", "i", "]", ".", "utterance_cnt_tensor_name", ")", "\n", "return", "name", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.multi_aligned_data.MultiAlignedData.data_name": [[488, 500], ["multi_aligned_data.MultiAlignedData._maybe_name_to_id", "texar.data.data.dataset_utils._connect_name", "multi_aligned_data._is_scalar_data"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.data.multi_aligned_data.MultiAlignedData._maybe_name_to_id", "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.dataset_utils._connect_name", "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.multi_aligned_data._is_scalar_data"], ["", "@", "property", "\n", "def", "data_name", "(", "self", ",", "name_or_id", ")", ":", "\n", "        ", "\"\"\"The name of the data tensor of scalar dataset by its name or id..\n        If the dataset is not a scalar data, returns `None`.\n        \"\"\"", "\n", "i", "=", "self", ".", "_maybe_name_to_id", "(", "name_or_id", ")", "\n", "if", "not", "_is_scalar_data", "(", "self", ".", "_hparams", ".", "datasets", "[", "i", "]", "[", "\"data_type\"", "]", ")", ":", "\n", "            ", "return", "None", "\n", "", "name", "=", "dsutils", ".", "_connect_name", "(", "\n", "self", ".", "_data_spec", ".", "name_prefix", "[", "i", "]", ",", "\n", "self", ".", "_data_spec", ".", "decoder", "[", "i", "]", ".", "data_tensor_name", ")", "\n", "return", "name", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.multi_aligned_data._is_text_data": [[43, 45], ["None"], "function", ["None"], ["", "def", "_is_text_data", "(", "data_type", ")", ":", "\n", "    ", "return", "data_type", "==", "_DataTypes", ".", "TEXT", "\n", "", "def", "_is_scalar_data", "(", "data_type", ")", ":", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.multi_aligned_data._is_scalar_data": [[45, 47], ["None"], "function", ["None"], ["", "def", "_is_scalar_data", "(", "data_type", ")", ":", "\n", "    ", "return", "data_type", "==", "_DataTypes", ".", "INT", "or", "data_type", "==", "_DataTypes", ".", "FLOAT", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.multi_aligned_data._default_dataset_hparams": [[48, 63], ["multi_aligned_data._is_text_data", "texar.data.data.mono_text_data._default_mono_text_dataset_hparams", "texar.data.data.scalar_data._default_scalar_dataset_hparams.update", "multi_aligned_data._is_scalar_data", "texar.data.data.scalar_data._default_scalar_dataset_hparams"], "function", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.data.multi_aligned_data._is_text_data", "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.mono_text_data._default_mono_text_dataset_hparams", "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.multi_aligned_data._is_scalar_data", "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.scalar_data._default_scalar_dataset_hparams"], ["", "def", "_default_dataset_hparams", "(", "data_type", "=", "None", ")", ":", "\n", "    ", "\"\"\"Returns hyperparameters of a dataset with default values.\n    \"\"\"", "\n", "# TODO(zhiting): add more docs", "\n", "if", "not", "data_type", "or", "_is_text_data", "(", "data_type", ")", ":", "\n", "        ", "hparams", "=", "_default_mono_text_dataset_hparams", "(", ")", "\n", "hparams", ".", "update", "(", "{", "\n", "\"data_type\"", ":", "_DataTypes", ".", "TEXT", ",", "\n", "\"vocab_share_with\"", ":", "None", ",", "\n", "\"embedding_init_share_with\"", ":", "None", ",", "\n", "\"processing_share_with\"", ":", "None", ",", "\n", "}", ")", "\n", "", "elif", "_is_scalar_data", "(", "data_type", ")", ":", "\n", "        ", "hparams", "=", "_default_scalar_dataset_hparams", "(", ")", "\n", "", "return", "hparams", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.data_iterators.DataIteratorBase.__init__": [[41, 61], ["isinstance", "datasets.items", "isinstance", "len", "ValueError", "any", "len", "isinstance", "ValueError", "len", "ValueError", "isinstance"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.texar.hyperparams.HParams.items"], ["def", "__init__", "(", "self", ",", "datasets", ")", ":", "\n", "        ", "self", ".", "_default_dataset_name", "=", "'data'", "\n", "if", "isinstance", "(", "datasets", ",", "(", "tf", ".", "data", ".", "Dataset", ",", "tx", ".", "data", ".", "DataBase", ")", ")", ":", "\n", "            ", "datasets", "=", "{", "self", ".", "_default_dataset_name", ":", "datasets", "}", "\n", "", "elif", "isinstance", "(", "datasets", ",", "(", "list", ",", "tuple", ")", ")", ":", "\n", "            ", "if", "any", "(", "not", "isinstance", "(", "d", ",", "tx", ".", "data", ".", "DataBase", ")", "for", "d", "in", "datasets", ")", ":", "\n", "                ", "raise", "ValueError", "(", "\"`datasets` must be an non-empty list of \"", "\n", "\"`texar.data.DataBase` instances.\"", ")", "\n", "", "num_datasets", "=", "len", "(", "datasets", ")", "\n", "datasets", "=", "{", "d", ".", "name", ":", "d", "for", "d", "in", "datasets", "}", "\n", "if", "len", "(", "datasets", ")", "<", "num_datasets", ":", "\n", "                ", "raise", "ValueError", "(", "\"Names of datasets must be unique.\"", ")", "\n", "\n", "", "", "_datasets", "=", "{", "}", "\n", "for", "k", ",", "v", "in", "datasets", ".", "items", "(", ")", ":", "# pylint: disable=invalid-name", "\n", "            ", "_datasets", "[", "k", "]", "=", "v", "if", "isinstance", "(", "v", ",", "tf", ".", "data", ".", "Dataset", ")", "else", "v", ".", "dataset", "\n", "", "self", ".", "_datasets", "=", "_datasets", "\n", "\n", "if", "len", "(", "self", ".", "_datasets", ")", "<=", "0", ":", "\n", "            ", "raise", "ValueError", "(", "\"`datasets` must not be empty.\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.data_iterators.DataIteratorBase.num_datasets": [[62, 67], ["len"], "methods", ["None"], ["", "", "@", "property", "\n", "def", "num_datasets", "(", "self", ")", ":", "\n", "        ", "\"\"\"Number of datasets.\n        \"\"\"", "\n", "return", "len", "(", "self", ".", "_datasets", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.data_iterators.DataIteratorBase.dataset_names": [[68, 73], ["list", "data_iterators.DataIteratorBase._datasets.keys"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.texar.hyperparams.HParams.keys"], ["", "@", "property", "\n", "def", "dataset_names", "(", "self", ")", ":", "\n", "        ", "\"\"\"A list of dataset names.\n        \"\"\"", "\n", "return", "list", "(", "self", ".", "_datasets", ".", "keys", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.data_iterators.DataIterator.__init__": [[91, 102], ["data_iterators.DataIteratorBase.__init__", "texar.utils.variables.get_unique_named_variable_scope", "tensorflow.variable_scope", "tensorflow.data.Iterator.from_structure", "data_iterators.DataIterator._iterator.make_initializer", "next", "data_iterators.DataIterator._datasets.items", "iter"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.text_infilling.self_attn_hyperparams.Hyperparams.__init__", "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.variables.get_unique_named_variable_scope", "home.repos.pwc.inspect_result.VegB_Text_Infilling.agents.agent_base.AgentBase.variable_scope", "home.repos.pwc.inspect_result.VegB_Text_Infilling.texar.hyperparams.HParams.items"], ["def", "__init__", "(", "self", ",", "datasets", ")", ":", "\n", "        ", "DataIteratorBase", ".", "__init__", "(", "self", ",", "datasets", ")", "\n", "\n", "self", ".", "_variable_scope", "=", "get_unique_named_variable_scope", "(", "'data_iterator'", ")", "\n", "with", "tf", ".", "variable_scope", "(", "self", ".", "_variable_scope", ")", ":", "\n", "            ", "arb_dataset", "=", "self", ".", "_datasets", "[", "next", "(", "iter", "(", "self", ".", "_datasets", ")", ")", "]", "\n", "self", ".", "_iterator", "=", "tf", ".", "data", ".", "Iterator", ".", "from_structure", "(", "\n", "arb_dataset", ".", "output_types", ",", "arb_dataset", ".", "output_shapes", ")", "\n", "self", ".", "_iterator_init_ops", "=", "{", "\n", "name", ":", "self", ".", "_iterator", ".", "make_initializer", "(", "d", ")", "\n", "for", "name", ",", "d", "in", "self", ".", "_datasets", ".", "items", "(", ")", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.data_iterators.DataIterator.switch_to_dataset": [[104, 121], ["sess.run", "next", "ValueError", "ValueError", "iter"], "methods", ["None"], ["", "", "def", "switch_to_dataset", "(", "self", ",", "sess", ",", "dataset_name", "=", "None", ")", ":", "\n", "        ", "\"\"\"Re-initializes the iterator of a given dataset and starts iterating\n        over the dataset (from the beginning).\n\n        Args:\n            sess: The current tf session.\n            dataset_name (optional): Name of the dataset. If not provided,\n                there must be only one Dataset.\n        \"\"\"", "\n", "if", "dataset_name", "is", "None", ":", "\n", "            ", "if", "self", ".", "num_datasets", ">", "1", ":", "\n", "                ", "raise", "ValueError", "(", "\"`dataset_name` is required if there are \"", "\n", "\"more than one datasets.\"", ")", "\n", "", "dataset_name", "=", "next", "(", "iter", "(", "self", ".", "_datasets", ")", ")", "\n", "", "if", "dataset_name", "not", "in", "self", ".", "_datasets", ":", "\n", "            ", "raise", "ValueError", "(", "\"Dataset not found: \"", ",", "dataset_name", ")", "\n", "", "sess", ".", "run", "(", "self", ".", "_iterator_init_ops", "[", "dataset_name", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.data_iterators.DataIterator.get_next": [[122, 126], ["data_iterators.DataIterator._iterator.get_next"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.data.data_iterators.FeedableDataIterator.get_next"], ["", "def", "get_next", "(", "self", ")", ":", "\n", "        ", "\"\"\"Returns the next element of the activated dataset.\n        \"\"\"", "\n", "return", "self", ".", "_iterator", ".", "get_next", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.data_iterators.TrainTestDataIterator.__init__": [[140, 156], ["data_iterators.DataIterator.__init__", "len", "ValueError"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.text_infilling.self_attn_hyperparams.Hyperparams.__init__"], ["def", "__init__", "(", "self", ",", "train", "=", "None", ",", "val", "=", "None", ",", "test", "=", "None", ")", ":", "\n", "        ", "dataset_dict", "=", "{", "}", "\n", "self", ".", "_train_name", "=", "'train'", "\n", "self", ".", "_val_name", "=", "'val'", "\n", "self", ".", "_test_name", "=", "'test'", "\n", "if", "train", "is", "not", "None", ":", "\n", "            ", "dataset_dict", "[", "self", ".", "_train_name", "]", "=", "train", "\n", "", "if", "val", "is", "not", "None", ":", "\n", "            ", "dataset_dict", "[", "self", ".", "_val_name", "]", "=", "val", "\n", "", "if", "test", "is", "not", "None", ":", "\n", "            ", "dataset_dict", "[", "self", ".", "_test_name", "]", "=", "test", "\n", "", "if", "len", "(", "dataset_dict", ")", "==", "0", ":", "\n", "            ", "raise", "ValueError", "(", "\"At least one of `train`, `val`, and `test` \"", "\n", "\"must be provided.\"", ")", "\n", "\n", "", "DataIterator", ".", "__init__", "(", "self", ",", "dataset_dict", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.data_iterators.TrainTestDataIterator.switch_to_train_data": [[158, 167], ["data_iterators.TrainTestDataIterator.switch_to_dataset", "ValueError"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.data.data_iterators.DataIterator.switch_to_dataset"], ["", "def", "switch_to_train_data", "(", "self", ",", "sess", ")", ":", "\n", "        ", "\"\"\"Starts to iterate through training data\n\n        Args:\n            sess: The current tf session.\n        \"\"\"", "\n", "if", "self", ".", "_train_name", "not", "in", "self", ".", "_datasets", ":", "\n", "            ", "raise", "ValueError", "(", "\"Training data not provided.\"", ")", "\n", "", "self", ".", "switch_to_dataset", "(", "sess", ",", "self", ".", "_train_name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.data_iterators.TrainTestDataIterator.switch_to_val_data": [[168, 177], ["data_iterators.TrainTestDataIterator.switch_to_dataset", "ValueError"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.data.data_iterators.DataIterator.switch_to_dataset"], ["", "def", "switch_to_val_data", "(", "self", ",", "sess", ")", ":", "\n", "        ", "\"\"\"Starts to iterate through val data\n\n        Args:\n            sess: The current tf session.\n        \"\"\"", "\n", "if", "self", ".", "_val_name", "not", "in", "self", ".", "_datasets", ":", "\n", "            ", "raise", "ValueError", "(", "\"Val data not provided.\"", ")", "\n", "", "self", ".", "switch_to_dataset", "(", "sess", ",", "self", ".", "_val_name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.data_iterators.TrainTestDataIterator.switch_to_test_data": [[178, 187], ["data_iterators.TrainTestDataIterator.switch_to_dataset", "ValueError"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.data.data_iterators.DataIterator.switch_to_dataset"], ["", "def", "switch_to_test_data", "(", "self", ",", "sess", ")", ":", "\n", "        ", "\"\"\"Starts to iterate through test data\n\n        Args:\n            sess: The current tf session.\n        \"\"\"", "\n", "if", "self", ".", "_test_name", "not", "in", "self", ".", "_datasets", ":", "\n", "            ", "raise", "ValueError", "(", "\"Test data not provided.\"", ")", "\n", "", "self", ".", "switch_to_dataset", "(", "sess", ",", "self", ".", "_test_name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.data_iterators.FeedableDataIterator.__init__": [[209, 224], ["data_iterators.DataIteratorBase.__init__", "texar.utils.variables.get_unique_named_variable_scope", "tensorflow.variable_scope", "tensorflow.placeholder", "tensorflow.data.Iterator.from_string_handle", "dataset.make_initializable_iterator", "next", "data_iterators.FeedableDataIterator._datasets.items", "iter"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.text_infilling.self_attn_hyperparams.Hyperparams.__init__", "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.variables.get_unique_named_variable_scope", "home.repos.pwc.inspect_result.VegB_Text_Infilling.agents.agent_base.AgentBase.variable_scope", "home.repos.pwc.inspect_result.VegB_Text_Infilling.texar.hyperparams.HParams.items"], ["def", "__init__", "(", "self", ",", "datasets", ")", ":", "\n", "        ", "DataIteratorBase", ".", "__init__", "(", "self", ",", "datasets", ")", "\n", "\n", "self", ".", "_variable_scope", "=", "get_unique_named_variable_scope", "(", "\n", "'feedable_data_iterator'", ")", "\n", "with", "tf", ".", "variable_scope", "(", "self", ".", "_variable_scope", ")", ":", "\n", "            ", "self", ".", "_handle", "=", "tf", ".", "placeholder", "(", "tf", ".", "string", ",", "shape", "=", "[", "]", ",", "name", "=", "'handle'", ")", "\n", "arb_dataset", "=", "self", ".", "_datasets", "[", "next", "(", "iter", "(", "self", ".", "_datasets", ")", ")", "]", "\n", "self", ".", "_iterator", "=", "tf", ".", "data", ".", "Iterator", ".", "from_string_handle", "(", "\n", "self", ".", "_handle", ",", "arb_dataset", ".", "output_types", ",", "\n", "arb_dataset", ".", "output_shapes", ")", "\n", "\n", "self", ".", "_dataset_iterators", "=", "{", "\n", "name", ":", "dataset", ".", "make_initializable_iterator", "(", ")", "\n", "for", "name", ",", "dataset", "in", "self", ".", "_datasets", ".", "items", "(", ")", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.data_iterators.FeedableDataIterator.get_handle": [[226, 255], ["sess.run", "next", "ValueError", "data_iterators.FeedableDataIterator._dataset_iterators[].string_handle", "ValueError", "iter"], "methods", ["None"], ["", "", "def", "get_handle", "(", "self", ",", "sess", ",", "dataset_name", "=", "None", ")", ":", "\n", "        ", "\"\"\"Returns a dataset handle that can be used to feed the\n        :meth:`handle` placeholder to fetch data from the dataset.\n\n        Args:\n            sess: The current tf session.\n            dataset_name (optional): Name of the dataset. If not provided,\n                there must be only one Dataset.\n\n        Returns:\n            A string handle to be fed to the :meth:`handle` placeholder.\n\n        Example:\n            .. code-block:: python\n\n                next_element = iterator.get_next()\n                train_handle = iterator.get_handle(sess, 'train')\n                # Gets the next training element\n                ne_ = sess.run(next_element,\n                               feed_dict={iterator.handle: train_handle})\n        \"\"\"", "\n", "if", "dataset_name", "is", "None", ":", "\n", "            ", "if", "self", ".", "num_datasets", ">", "1", ":", "\n", "                ", "raise", "ValueError", "(", "\"`dataset_name` is required if there are \"", "\n", "\"more than one datasets.\"", ")", "\n", "", "dataset_name", "=", "next", "(", "iter", "(", "self", ".", "_datasets", ")", ")", "\n", "", "if", "dataset_name", "not", "in", "self", ".", "_datasets", ":", "\n", "            ", "raise", "ValueError", "(", "\"Dataset not found: \"", ",", "dataset_name", ")", "\n", "", "return", "sess", ".", "run", "(", "self", ".", "_dataset_iterators", "[", "dataset_name", "]", ".", "string_handle", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.data_iterators.FeedableDataIterator.restart_dataset": [[256, 267], ["data_iterators.FeedableDataIterator.initialize_dataset"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.data.data_iterators.FeedableDataIterator.initialize_dataset"], ["", "def", "restart_dataset", "(", "self", ",", "sess", ",", "dataset_name", "=", "None", ")", ":", "\n", "        ", "\"\"\"Restarts datasets so that next iteration will fetch data from\n        the beginning of the datasets.\n\n        Args:\n            sess: The current tf session.\n            dataset_name (optional): A dataset name or a list of dataset names\n                that specifies which dataset(s) to restart. If `None`, all\n                datasets are restart.\n        \"\"\"", "\n", "self", ".", "initialize_dataset", "(", "sess", ",", "dataset_name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.data_iterators.FeedableDataIterator.initialize_dataset": [[268, 285], ["isinstance", "sess.run"], "methods", ["None"], ["", "def", "initialize_dataset", "(", "self", ",", "sess", ",", "dataset_name", "=", "None", ")", ":", "\n", "        ", "\"\"\"Initializes datasets. A dataset must be initialized before being\n        used.\n\n        Args:\n            sess: The current tf session.\n            dataset_name (optional): A dataset name or a list of dataset names\n                that specifies which dataset(s) to initialize. If `None`, all\n                datasets are initialized.\n        \"\"\"", "\n", "if", "dataset_name", "is", "None", ":", "\n", "            ", "dataset_name", "=", "self", ".", "dataset_names", "\n", "", "if", "not", "isinstance", "(", "dataset_name", ",", "(", "tuple", ",", "list", ")", ")", ":", "\n", "            ", "dataset_name", "=", "[", "dataset_name", "]", "\n", "\n", "", "for", "name", "in", "dataset_name", ":", "\n", "            ", "sess", ".", "run", "(", "self", ".", "_dataset_iterators", "[", "name", "]", ".", "initializer", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.data_iterators.FeedableDataIterator.get_next": [[286, 290], ["data_iterators.FeedableDataIterator._iterator.get_next"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.data.data_iterators.FeedableDataIterator.get_next"], ["", "", "def", "get_next", "(", "self", ")", ":", "\n", "        ", "\"\"\"Returns the next element of the activated dataset.\n        \"\"\"", "\n", "return", "self", ".", "_iterator", ".", "get_next", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.data_iterators.FeedableDataIterator.handle": [[291, 297], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "handle", "(", "self", ")", ":", "\n", "        ", "\"\"\"The handle placeholder that can be fed with a dataset handle to\n        fetch data from the dataset.\n        \"\"\"", "\n", "return", "self", ".", "_handle", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.data_iterators.TrainTestFeedableDataIterator.__init__": [[315, 331], ["data_iterators.FeedableDataIterator.__init__", "len", "ValueError"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.text_infilling.self_attn_hyperparams.Hyperparams.__init__"], ["def", "__init__", "(", "self", ",", "train", "=", "None", ",", "val", "=", "None", ",", "test", "=", "None", ")", ":", "\n", "        ", "dataset_dict", "=", "{", "}", "\n", "self", ".", "_train_name", "=", "'train'", "\n", "self", ".", "_val_name", "=", "'val'", "\n", "self", ".", "_test_name", "=", "'test'", "\n", "if", "train", "is", "not", "None", ":", "\n", "            ", "dataset_dict", "[", "self", ".", "_train_name", "]", "=", "train", "\n", "", "if", "val", "is", "not", "None", ":", "\n", "            ", "dataset_dict", "[", "self", ".", "_val_name", "]", "=", "val", "\n", "", "if", "test", "is", "not", "None", ":", "\n", "            ", "dataset_dict", "[", "self", ".", "_test_name", "]", "=", "test", "\n", "", "if", "len", "(", "dataset_dict", ")", "==", "0", ":", "\n", "            ", "raise", "ValueError", "(", "\"At least one of `train`, `val`, and `test` \"", "\n", "\"must be provided.\"", ")", "\n", "\n", "", "FeedableDataIterator", ".", "__init__", "(", "self", ",", "dataset_dict", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.data_iterators.TrainTestFeedableDataIterator.get_train_handle": [[332, 354], ["data_iterators.TrainTestFeedableDataIterator.get_handle", "ValueError"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.data.data_iterators.FeedableDataIterator.get_handle"], ["", "def", "get_train_handle", "(", "self", ",", "sess", ")", ":", "\n", "        ", "\"\"\"Returns the handle of the training dataset. The handle can be used\n        to feed the :meth:`handle` placeholder to fetch training data.\n\n        Args:\n            sess: The current tf session.\n\n        Returns:\n            A string handle to be fed to the :meth:`handle` placeholder.\n\n        Example:\n            .. code-block:: python\n\n                next_element = iterator.get_next()\n                train_handle = iterator.get_train_handle(sess)\n                # Gets the next training element\n                ne_ = sess.run(next_element,\n                               feed_dict={iterator.handle: train_handle})\n        \"\"\"", "\n", "if", "self", ".", "_train_name", "not", "in", "self", ".", "_datasets", ":", "\n", "            ", "raise", "ValueError", "(", "\"Training data not provided.\"", ")", "\n", "", "return", "self", ".", "get_handle", "(", "sess", ",", "self", ".", "_train_name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.data_iterators.TrainTestFeedableDataIterator.get_val_handle": [[355, 368], ["data_iterators.TrainTestFeedableDataIterator.get_handle", "ValueError"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.data.data_iterators.FeedableDataIterator.get_handle"], ["", "def", "get_val_handle", "(", "self", ",", "sess", ")", ":", "\n", "        ", "\"\"\"Returns the handle of the validation dataset. The handle can be used\n        to feed the :meth:`handle` placeholder to fetch validation data.\n\n        Args:\n            sess: The current tf session.\n\n        Returns:\n            A string handle to be fed to the :meth:`handle` placeholder.\n        \"\"\"", "\n", "if", "self", ".", "_val_name", "not", "in", "self", ".", "_datasets", ":", "\n", "            ", "raise", "ValueError", "(", "\"Val data not provided.\"", ")", "\n", "", "return", "self", ".", "get_handle", "(", "sess", ",", "self", ".", "_val_name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.data_iterators.TrainTestFeedableDataIterator.get_test_handle": [[369, 382], ["data_iterators.TrainTestFeedableDataIterator.get_handle", "ValueError"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.data.data_iterators.FeedableDataIterator.get_handle"], ["", "def", "get_test_handle", "(", "self", ",", "sess", ")", ":", "\n", "        ", "\"\"\"Returns the handle of the test dataset. The handle can be used\n        to feed the :meth:`handle` placeholder to fetch test data.\n\n        Args:\n            sess: The current tf session.\n\n        Returns:\n            A string handle to be fed to the :meth:`handle` placeholder.\n        \"\"\"", "\n", "if", "self", ".", "_test_name", "not", "in", "self", ".", "_datasets", ":", "\n", "            ", "raise", "ValueError", "(", "\"Test data not provided.\"", ")", "\n", "", "return", "self", ".", "get_handle", "(", "sess", ",", "self", ".", "_test_name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.data_iterators.TrainTestFeedableDataIterator.restart_train_dataset": [[383, 393], ["data_iterators.TrainTestFeedableDataIterator.restart_dataset", "ValueError"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.data.data_iterators.FeedableDataIterator.restart_dataset"], ["", "def", "restart_train_dataset", "(", "self", ",", "sess", ")", ":", "\n", "        ", "\"\"\"Restarts the training dataset so that next iteration will fetch\n        data from the beginning of the training dataset.\n\n        Args:\n            sess: The current tf session.\n        \"\"\"", "\n", "if", "self", ".", "_train_name", "not", "in", "self", ".", "_datasets", ":", "\n", "            ", "raise", "ValueError", "(", "\"Training data not provided.\"", ")", "\n", "", "self", ".", "restart_dataset", "(", "sess", ",", "self", ".", "_train_name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.data_iterators.TrainTestFeedableDataIterator.restart_val_dataset": [[394, 404], ["data_iterators.TrainTestFeedableDataIterator.restart_dataset", "ValueError"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.data.data_iterators.FeedableDataIterator.restart_dataset"], ["", "def", "restart_val_dataset", "(", "self", ",", "sess", ")", ":", "\n", "        ", "\"\"\"Restarts the validation dataset so that next iteration will fetch\n        data from the beginning of the validation dataset.\n\n        Args:\n            sess: The current tf session.\n        \"\"\"", "\n", "if", "self", ".", "_val_name", "not", "in", "self", ".", "_datasets", ":", "\n", "            ", "raise", "ValueError", "(", "\"Val data not provided.\"", ")", "\n", "", "self", ".", "restart_dataset", "(", "sess", ",", "self", ".", "_val_name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.data_iterators.TrainTestFeedableDataIterator.restart_test_dataset": [[405, 415], ["data_iterators.TrainTestFeedableDataIterator.restart_dataset", "ValueError"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.data.data_iterators.FeedableDataIterator.restart_dataset"], ["", "def", "restart_test_dataset", "(", "self", ",", "sess", ")", ":", "\n", "        ", "\"\"\"Restarts the test dataset so that next iteration will fetch\n        data from the beginning of the test dataset.\n\n        Args:\n            sess: The current tf session.\n        \"\"\"", "\n", "if", "self", ".", "_test_name", "not", "in", "self", ".", "_datasets", ":", "\n", "            ", "raise", "ValueError", "(", "\"Test data not provided.\"", ")", "\n", "", "self", ".", "restart_dataset", "(", "sess", ",", "self", ".", "_test_name", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.core.attentions.attention_bias_lower_triangle": [[13, 22], ["attentions.attention_bias_local"], "function", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.core.attentions.attention_bias_local"], ["def", "attention_bias_lower_triangle", "(", "length", ")", ":", "\n", "    ", "\"\"\"Create an bias tensor to be added to attention logits.\n    Allows a query to attend to all positions up to and including its own.\n    Args:\n     length: a Scalar.\n    Returns:\n        a `Tensor` with shape [1, 1, length, length].\n    \"\"\"", "\n", "return", "attention_bias_local", "(", "length", ",", "-", "1", ",", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.core.attentions.attention_bias_local": [[23, 45], ["attentions._ones_matrix_band_part"], "function", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.core.attentions._ones_matrix_band_part"], ["", "def", "attention_bias_local", "(", "length", ",", "max_backward", ",", "max_forward", ")", ":", "\n", "    ", "\"\"\"Create an bias tensor to be added to attention logits.\n    A position may attend to positions at most max_distance from it,\n    forward and backwards.\n    This does not actually save any computation.\n    Args:\n        length: int\n        max_backward: int, maximum distance backward to attend. Negative values\n            indicate unlimited.\n        max_forward: int, maximum distance forward to attend. Negative values\n            indicate unlimited.\n    Returns:\n        a `Tensor` with shape [1, 1, length, length].\n        [batch_size, num_heads, queri_len, queri_len]\n    \"\"\"", "\n", "band", "=", "_ones_matrix_band_part", "(", "\n", "length", ",", "\n", "length", ",", "\n", "max_backward", ",", "\n", "max_forward", ",", "\n", "out_shape", "=", "[", "1", ",", "1", ",", "length", ",", "length", "]", ")", "\n", "return", "-", "1e18", "*", "(", "1.0", "-", "band", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.core.attentions.attention_bias_ignore_padding": [[46, 56], ["tensorflow.expand_dims", "tensorflow.expand_dims"], "function", ["None"], ["", "def", "attention_bias_ignore_padding", "(", "memory_padding", ")", ":", "\n", "    ", "\"\"\"Create an bias tensor to be added to attention logits.\n    Args:\n        memory_padding: a float `Tensor` with shape [batch, memory_length].\n    Returns:\n        a `Tensor` with shape [batch, 1, 1, memory_length].\n        each dim corresponding to batch_size, num_heads, queries_len, memory_length\n    \"\"\"", "\n", "ret", "=", "memory_padding", "*", "-", "1e18", "\n", "return", "tf", ".", "expand_dims", "(", "tf", ".", "expand_dims", "(", "ret", ",", "axis", "=", "1", ")", ",", "axis", "=", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.core.attentions.multihead_attention": [[57, 137], ["tensorflow.variable_scope", "attentions._split_heads", "attentions._split_heads", "attentions._split_heads", "tensorflow.matmul", "tensorflow.nn.softmax", "tensorflow.layers.dropout", "tensorflow.matmul", "attentions._combine_heads", "tensorflow.layers.dense", "ValueError", "tensorflow.layers.dense", "tensorflow.layers.dense", "tensorflow.layers.dense", "tensorflow.layers.dense", "queries.get_shape().as_list", "tensorflow.concat", "tensorflow.concat", "tensorflow.cond", "texar.context.global_mode_train", "tensorflow.equal", "tensorflow.layers.dense", "tensorflow.layers.dense", "queries.get_shape", "tensorflow.shape", "tensorflow.layers.dense", "tensorflow.layers.dense"], "function", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.agents.agent_base.AgentBase.variable_scope", "home.repos.pwc.inspect_result.VegB_Text_Infilling.core.attentions._split_heads", "home.repos.pwc.inspect_result.VegB_Text_Infilling.core.attentions._split_heads", "home.repos.pwc.inspect_result.VegB_Text_Infilling.core.attentions._split_heads", "home.repos.pwc.inspect_result.VegB_Text_Infilling.core.attentions._combine_heads", "home.repos.pwc.inspect_result.VegB_Text_Infilling.texar.context.global_mode_train"], ["", "def", "multihead_attention", "(", "queries", ",", "\n", "memory_attention_bias", "=", "None", ",", "\n", "memory", "=", "None", ",", "\n", "num_heads", "=", "8", ",", "\n", "num_units", "=", "None", ",", "\n", "dropout_rate", "=", "0", ",", "\n", "cache", "=", "None", ",", "\n", "scope", "=", "'multihead_attention'", ")", ":", "\n", "    ", "'''Applies multihead attention.\n    Args:\n      queries: A 3d tensor with shape of [batch, length_query, depth_query].\n      keys: A 3d tensor with shape of [batch, length_key, depth_key].\n      num_units: A scalar indicating the attention size,\n        equals to depth_query if not given.\n      dropout_rate: A floating point number.\n      num_heads: An int. Number of heads with calculating attention.\n      scope: Optional scope for `variable_scope`.\n      reuse: Boolean, whether to reuse the weights of a previous layer\n        by the same name.\n    Returns\n      A 3d tensor with shape of (batch, length_query, num_units)\n    '''", "\n", "#pylint: disable=too-many-locals", "\n", "with", "tf", ".", "variable_scope", "(", "scope", ")", ":", "\n", "        ", "if", "num_units", "is", "None", ":", "\n", "            ", "num_units", "=", "queries", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", "[", "-", "1", "]", "\n", "", "if", "num_units", "%", "num_heads", "!=", "0", ":", "\n", "            ", "raise", "ValueError", "(", "\"Value depth (%d) must be divisible by the number\"", "\n", "\"of attention heads (%d).\"", "%", "(", "num_units", ",", "num_heads", ")", ")", "\n", "", "if", "memory", "is", "None", ":", "\n", "#'self attention'", "\n", "            ", "Q", "=", "tf", ".", "layers", ".", "dense", "(", "queries", ",", "num_units", ",", "use_bias", "=", "False", ",", "name", "=", "'q'", ")", "\n", "K", "=", "tf", ".", "layers", ".", "dense", "(", "queries", ",", "num_units", ",", "use_bias", "=", "False", ",", "name", "=", "'k'", ")", "\n", "V", "=", "tf", ".", "layers", ".", "dense", "(", "queries", ",", "num_units", ",", "use_bias", "=", "False", ",", "name", "=", "'v'", ")", "\n", "if", "cache", "is", "not", "None", ":", "\n", "# 'decoder self attention when dynamic decoding'", "\n", "                ", "K", "=", "tf", ".", "concat", "(", "[", "cache", "[", "'self_keys'", "]", ",", "K", "]", ",", "axis", "=", "1", ")", "\n", "V", "=", "tf", ".", "concat", "(", "[", "cache", "[", "'self_values'", "]", ",", "V", "]", ",", "axis", "=", "1", ")", "\n", "cache", "[", "'self_keys'", "]", "=", "K", "\n", "cache", "[", "'self_values'", "]", "=", "V", "\n", "", "", "else", ":", "\n", "# 'encoder decoder attention'", "\n", "            ", "Q", "=", "tf", ".", "layers", ".", "dense", "(", "queries", ",", "num_units", ",", "use_bias", "=", "False", ",", "name", "=", "'q'", ")", "\n", "if", "cache", "is", "not", "None", ":", "\n", "                ", "K", ",", "V", "=", "tf", ".", "cond", "(", "\n", "tf", ".", "equal", "(", "tf", ".", "shape", "(", "cache", "[", "\"memory_keys\"", "]", ")", "[", "1", "]", ",", "0", ")", ",", "\n", "true_fn", "=", "lambda", ":", "[", "tf", ".", "layers", ".", "dense", "(", "memory", ",", "num_units", ",", "use_bias", "=", "False", ",", "name", "=", "'k'", ")", ",", "tf", ".", "layers", ".", "dense", "(", "memory", ",", "num_units", ",", "use_bias", "=", "False", ",", "name", "=", "'v'", ")", "]", ",", "\n", "false_fn", "=", "lambda", ":", "[", "cache", "[", "\"memory_keys\"", "]", ",", "cache", "[", "\"memory_values\"", "]", "]", ")", "\n", "", "else", ":", "\n", "                ", "K", ",", "V", "=", "[", "tf", ".", "layers", ".", "dense", "(", "memory", ",", "num_units", ",", "use_bias", "=", "False", ",", "name", "=", "'k'", ")", ",", "\n", "tf", ".", "layers", ".", "dense", "(", "memory", ",", "num_units", ",", "use_bias", "=", "False", ",", "name", "=", "'v'", ")", "]", "\n", "\n", "", "", "Q_", "=", "_split_heads", "(", "Q", ",", "num_heads", ")", "\n", "K_", "=", "_split_heads", "(", "K", ",", "num_heads", ")", "\n", "V_", "=", "_split_heads", "(", "V", ",", "num_heads", ")", "\n", "#[batch_size, num_heads, seq_length, memory_depth]", "\n", "key_depth_per_head", "=", "num_units", "//", "num_heads", "\n", "Q_", "*=", "key_depth_per_head", "**", "-", "0.5", "\n", "\n", "logits", "=", "tf", ".", "matmul", "(", "Q_", ",", "K_", ",", "transpose_b", "=", "True", ")", "\n", "if", "memory_attention_bias", "is", "not", "None", ":", "\n", "            ", "logits", "+=", "memory_attention_bias", "\n", "", "weights", "=", "tf", ".", "nn", ".", "softmax", "(", "logits", ",", "name", "=", "\"attention_weights\"", ")", "\n", "weights", "=", "tf", ".", "layers", ".", "dropout", "(", "weights", ",", "rate", "=", "dropout_rate", ",", "training", "=", "context", ".", "global_mode_train", "(", ")", ")", "\n", "outputs", "=", "tf", ".", "matmul", "(", "weights", ",", "V_", ")", "\n", "\n", "outputs", "=", "_combine_heads", "(", "outputs", ")", "\n", "outputs", "=", "tf", ".", "layers", ".", "dense", "(", "outputs", ",", "num_units", ",", "use_bias", "=", "False", ",", "name", "=", "'output_transform'", ")", "\n", "#(batch_size, length_query, attention_depth)", "\n", "", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.core.attentions.layer_normalize": [[138, 164], ["tensorflow.variable_scope", "tensorflow.nn.moments", "tensorflow.get_variable", "tensorflow.get_variable", "inputs.get_shape", "tensorflow.rsqrt", "tensorflow.ones_initializer", "tensorflow.zeros_initializer"], "function", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.agents.agent_base.AgentBase.variable_scope"], ["", "def", "layer_normalize", "(", "inputs", ",", "\n", "epsilon", "=", "1e-8", ",", "\n", "scope", "=", "'ln'", ",", "\n", "reuse", "=", "None", ")", ":", "\n", "    ", "'''Applies layer normalization. averaging over the last dimension\n    Args:\n        inputs: A tensor with 2 or more dimensions, where the first\n            dimension has `batch_size`.\n        epsilon: A floating number. A very small number for preventing\n            ZeroDivision Error.\n        scope: Optional scope for `variable_scope`.\n        reuse: Boolean, whether to reuse the weights of a previous layer\n            by the same name.\n    Returns:\n        A tensor with the same shape and data dtype as `inputs`.\n    '''", "\n", "with", "tf", ".", "variable_scope", "(", "scope", ",", "reuse", "=", "reuse", ")", ":", "\n", "        ", "filters", "=", "inputs", ".", "get_shape", "(", ")", "[", "-", "1", "]", "\n", "mean", ",", "variance", "=", "tf", ".", "nn", ".", "moments", "(", "inputs", ",", "[", "-", "1", "]", ",", "keep_dims", "=", "True", ")", "\n", "scale", "=", "tf", ".", "get_variable", "(", "'layer_norm_scale'", ",", "[", "filters", "]", ",", "initializer", "=", "tf", ".", "ones_initializer", "(", ")", ")", "\n", "bias", "=", "tf", ".", "get_variable", "(", "'layer_norm_bias'", ",", "[", "filters", "]", ",", "initializer", "=", "tf", ".", "zeros_initializer", "(", ")", ")", "\n", "norm_x", "=", "(", "inputs", "-", "mean", ")", "*", "tf", ".", "rsqrt", "(", "variance", "+", "epsilon", ")", "\n", "outputs", "=", "norm_x", "*", "scale", "+", "bias", "\n", "", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.core.attentions._split_heads": [[166, 174], ["tensorflow.reshape", "tensorflow.transpose", "x.get_shape", "tensorflow.shape", "tensorflow.shape"], "function", ["None"], ["", "def", "_split_heads", "(", "x", ",", "num_heads", ")", ":", "\n", "    ", "\"\"\"Split channels (dimension 2) into multiple heads, becomes dimension 1).\n        must ensure x.shape[-1] can be deviced by num_heads.any\n    \"\"\"", "\n", "depth", "=", "x", ".", "get_shape", "(", ")", "[", "-", "1", "]", "\n", "splitted_x", "=", "tf", ".", "reshape", "(", "x", ",", "[", "tf", ".", "shape", "(", "x", ")", "[", "0", "]", ",", "tf", ".", "shape", "(", "x", ")", "[", "1", "]", ",", "num_heads", ",", "depth", "//", "num_heads", "]", ")", "\n", "return", "tf", ".", "transpose", "(", "splitted_x", ",", "[", "0", ",", "2", ",", "1", ",", "3", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.core.attentions._combine_heads": [[175, 183], ["tensorflow.transpose", "tensorflow.reshape", "tf.transpose.get_shape", "tensorflow.shape", "tensorflow.shape"], "function", ["None"], ["", "def", "_combine_heads", "(", "x", ")", ":", "\n", "    ", "\"\"\"\n    input: [batch, num_heads, seq_len, dim]\n    output:[batch, seq_len, num_heads*dim]\n    \"\"\"", "\n", "t", "=", "tf", ".", "transpose", "(", "x", ",", "[", "0", ",", "2", ",", "1", ",", "3", "]", ")", "#[batch, seq_len, num_heads, dim]", "\n", "num_heads", ",", "dim", "=", "t", ".", "get_shape", "(", ")", "[", "-", "2", ":", "]", "\n", "return", "tf", ".", "reshape", "(", "t", ",", "[", "tf", ".", "shape", "(", "t", ")", "[", "0", "]", ",", "tf", ".", "shape", "(", "t", ")", "[", "1", "]", ",", "num_heads", "*", "dim", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.core.attentions._ones_matrix_band_part": [[186, 207], ["all", "numpy.tri", "tensorflow.constant", "tensorflow.matrix_band_part", "isinstance", "numpy.tri", "tf.reshape.reshape", "tensorflow.ones", "tensorflow.cast", "tensorflow.cast", "tensorflow.reshape", "numpy.ones"], "function", ["None"], ["", "def", "_ones_matrix_band_part", "(", "rows", ",", "cols", ",", "num_lower", ",", "num_upper", ",", "out_shape", "=", "None", ")", ":", "\n", "    ", "\"\"\"Matrix band part of ones.\"\"\"", "\n", "if", "all", "(", "[", "isinstance", "(", "el", ",", "int", ")", "for", "el", "in", "[", "rows", ",", "cols", ",", "num_lower", ",", "num_upper", "]", "]", ")", ":", "\n", "# Needed info is constant, so we construct in numpy", "\n", "        ", "if", "num_lower", "<", "0", ":", "\n", "            ", "num_lower", "=", "rows", "-", "1", "\n", "", "if", "num_upper", "<", "0", ":", "\n", "            ", "num_upper", "=", "cols", "-", "1", "\n", "", "lower_mask", "=", "np", ".", "tri", "(", "cols", ",", "rows", ",", "num_lower", ")", ".", "T", "\n", "upper_mask", "=", "np", ".", "tri", "(", "rows", ",", "cols", ",", "num_upper", ")", "\n", "band", "=", "np", ".", "ones", "(", "(", "rows", ",", "cols", ")", ")", "*", "lower_mask", "*", "upper_mask", "\n", "if", "out_shape", ":", "\n", "            ", "band", "=", "band", ".", "reshape", "(", "out_shape", ")", "\n", "", "band", "=", "tf", ".", "constant", "(", "band", ",", "tf", ".", "float32", ")", "\n", "", "else", ":", "\n", "        ", "band", "=", "tf", ".", "matrix_band_part", "(", "tf", ".", "ones", "(", "[", "rows", ",", "cols", "]", ")", ",", "\n", "tf", ".", "cast", "(", "num_lower", ",", "tf", ".", "int64", ")", ",", "\n", "tf", ".", "cast", "(", "num_upper", ",", "tf", ".", "int64", ")", ")", "\n", "if", "out_shape", ":", "\n", "            ", "band", "=", "tf", ".", "reshape", "(", "band", ",", "out_shape", ")", "\n", "", "", "return", "band", "\n", "", ""]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.core.optimization.default_optimization_hparams": [[27, 60], ["None"], "function", ["None"], ["def", "default_optimization_hparams", "(", ")", ":", "\n", "    ", "\"\"\"Returns default hyperparameters of optimization.\n\n    Returns:\n        dict: A dictionary with the following structure and values:\n\n    .. code-block:: python\n\n        {\n        }\n\n    \"\"\"", "\n", "return", "{", "\n", "\"optimizer\"", ":", "{", "\n", "\"type\"", ":", "\"AdamOptimizer\"", ",", "\n", "\"kwargs\"", ":", "{", "\n", "\"learning_rate\"", ":", "0.001", "\n", "}", "\n", "}", ",", "\n", "\"learning_rate_decay\"", ":", "{", "\n", "\"type\"", ":", "\"\"", ",", "\n", "\"kwargs\"", ":", "{", "}", ",", "\n", "\"min_learning_rate\"", ":", "0.", ",", "\n", "\"start_decay_step\"", ":", "0", ",", "\n", "\"end_decay_step\"", ":", "utils", ".", "MAX_SEQ_LENGTH", ",", "\n", "}", ",", "\n", "\"gradient_clip\"", ":", "{", "\n", "\"type\"", ":", "\"\"", ",", "\n", "\"kwargs\"", ":", "{", "}", "\n", "}", ",", "\n", "\"gradient_noise_scale\"", ":", "None", ",", "\n", "# TODO(zhiting): allow module-level control of gradient_multipliers", "\n", "\"name\"", ":", "None", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.core.optimization.get_optimizer_fn": [[62, 115], ["isinstance", "isinstance", "texar.hyperparams.HParams", "hparams[].todict", "set", "utils.check_or_get_class.", "type", "texar.utils.utils.check_or_get_class", "optimization.default_optimization_hparams", "ValueError", "inspect.getargspec"], "function", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.texar.hyperparams.HParams.todict", "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.utils.check_or_get_class", "home.repos.pwc.inspect_result.VegB_Text_Infilling.core.optimization.default_optimization_hparams"], ["", "def", "get_optimizer_fn", "(", "hparams", "=", "None", ")", ":", "\n", "    ", "\"\"\"Returns a function of making optimizer instance, along with the\n    optimizer class.\n\n    The function has the signiture:\n        (learning_rate=None) -> instance of the optimizer class,\n\n    The optimizer class must be a subclass of :tf_main:`~tf.train.Optimizer`.\n\n    See the :attr:`\"optimizer\"` field in\n    :meth:`~texar.core.optimization.default_optimization_hparams` for all\n    hyperparameters and default values.\n\n    If :attr:`hparams[\"type\"]` is an optimier instance, returns the instance\n    directly.\n\n    Args:\n        hparams (dict or HParams, optional): hyperparameters. Missing\n            hyperparameters are set to default values automatically.\n\n    Returns:\n        (function that creates optimizer instance, optimizer class),\n        or the optimizer instance.\n    \"\"\"", "\n", "if", "hparams", "is", "None", "or", "isinstance", "(", "hparams", ",", "dict", ")", ":", "\n", "        ", "hparams", "=", "HParams", "(", "\n", "hparams", ",", "default_optimization_hparams", "(", ")", "[", "\"optimizer\"", "]", ")", "\n", "\n", "", "opt", "=", "hparams", "[", "\"type\"", "]", "\n", "if", "isinstance", "(", "opt", ",", "tf", ".", "train", ".", "Optimizer", ")", ":", "\n", "        ", "return", "opt", ",", "type", "(", "opt", ")", "\n", "", "else", ":", "\n", "        ", "opt_modules", "=", "[", "'tensorflow.train'", ",", "\n", "'tensorflow.contrib.opt'", ",", "\n", "'texar.custom'", "]", "\n", "try", ":", "\n", "            ", "opt_class", "=", "utils", ".", "check_or_get_class", "(", "opt", ",", "opt_modules", ",", "\n", "tf", ".", "train", ".", "Optimizer", ")", "\n", "", "except", "TypeError", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "\"Unrecognized optimizer. Must be string name of the \"", "\n", "\"optimizer class, or the class which is a subclass of \"", "\n", "\"tf.train.Optimizer, or an instance of the subclass of \"", "\n", "\"Optimizer.\"", ")", "\n", "\n", "", "", "def", "_get_opt", "(", "learning_rate", "=", "None", ")", ":", "\n", "        ", "opt_kwargs", "=", "hparams", "[", "\"kwargs\"", "]", ".", "todict", "(", ")", "\n", "fn_args", "=", "set", "(", "inspect", ".", "getargspec", "(", "opt_class", ".", "__init__", ")", ".", "args", ")", "\n", "if", "'learning_rate'", "in", "fn_args", "and", "learning_rate", "is", "not", "None", ":", "\n", "            ", "opt_kwargs", "[", "\"learning_rate\"", "]", "=", "learning_rate", "\n", "", "return", "opt_class", "(", "**", "opt_kwargs", ")", "\n", "\n", "", "return", "_get_opt", ",", "opt_class", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.core.optimization.get_learning_rate_decay_fn": [[116, 177], ["texar.utils.utils.get_function", "tensorflow.to_int32", "tensorflow.to_int32", "isinstance", "texar.hyperparams.HParams", "fn_kwargs.todict.todict", "tensorflow.maximum", "utils.get_function.", "fn_kwargs_.update", "texar.utils.utils.call_function_with_redundant_kwargs", "tensorflow.maximum", "optimization.default_optimization_hparams", "tensorflow.minimum", "tensorflow.to_int32"], "function", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.utils.get_function", "home.repos.pwc.inspect_result.VegB_Text_Infilling.texar.hyperparams.HParams.todict", "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.utils.call_function_with_redundant_kwargs", "home.repos.pwc.inspect_result.VegB_Text_Infilling.core.optimization.default_optimization_hparams"], ["", "def", "get_learning_rate_decay_fn", "(", "hparams", "=", "None", ")", ":", "\n", "    ", "\"\"\"Creates learning rate decay function based on the hyperparameters.\n\n    See the :attr:`learning_rate_decay` field in\n    :meth:`~texar.core.optimization.default_optimization_hparams` for all\n    hyperparameters and default values.\n\n    Args:\n        hparams (dict or HParams, optional): hyperparameters. Missing\n            hyperparameters are set to default values automatically.\n\n    Returns:\n        function or None: If :attr:`hparams[\"type\"]` is specified, returns a\n        function that takes :attr:`learning_rate` and :attr:`global_step` and\n        returns a scalar Tensor representing the decayed learning rate. If\n        :attr:`hparams[\"type\"]` is empty, returns `None`.\n    \"\"\"", "\n", "if", "hparams", "is", "None", "or", "isinstance", "(", "hparams", ",", "dict", ")", ":", "\n", "        ", "hparams", "=", "HParams", "(", "\n", "hparams", ",", "default_optimization_hparams", "(", ")", "[", "\"learning_rate_decay\"", "]", ")", "\n", "\n", "", "fn_type", "=", "hparams", "[", "\"type\"", "]", "\n", "if", "fn_type", "is", "None", "or", "fn_type", "==", "\"\"", ":", "\n", "        ", "return", "None", "\n", "\n", "", "fn_modules", "=", "[", "\"tensorflow.train\"", ",", "\"texar.custom\"", "]", "\n", "decay_fn", "=", "utils", ".", "get_function", "(", "fn_type", ",", "fn_modules", ")", "\n", "fn_kwargs", "=", "hparams", "[", "\"kwargs\"", "]", "\n", "if", "fn_kwargs", "is", "HParams", ":", "\n", "        ", "fn_kwargs", "=", "fn_kwargs", ".", "todict", "(", ")", "\n", "\n", "", "start_step", "=", "tf", ".", "to_int32", "(", "hparams", "[", "\"start_decay_step\"", "]", ")", "\n", "end_step", "=", "tf", ".", "to_int32", "(", "hparams", "[", "\"end_decay_step\"", "]", ")", "\n", "\n", "def", "lr_decay_fn", "(", "learning_rate", ",", "global_step", ")", ":", "\n", "        ", "\"\"\"Learning rate decay function.\n\n        Args:\n            learning_rate (float or Tensor): The original learning rate.\n            global_step (int or scalar int Tensor): optimization step counter.\n\n        Returns:\n            scalar float Tensor: decayed learning rate.\n        \"\"\"", "\n", "offset_global_step", "=", "tf", ".", "maximum", "(", "\n", "tf", ".", "minimum", "(", "tf", ".", "to_int32", "(", "global_step", ")", ",", "end_step", ")", "-", "start_step", ",", "0", ")", "\n", "if", "decay_fn", "==", "tf", ".", "train", ".", "piecewise_constant", ":", "\n", "            ", "decayed_lr", "=", "decay_fn", "(", "x", "=", "offset_global_step", ",", "**", "fn_kwargs", ")", "\n", "", "else", ":", "\n", "            ", "fn_kwargs_", "=", "{", "\n", "\"learning_rate\"", ":", "learning_rate", ",", "\n", "\"global_step\"", ":", "offset_global_step", "}", "\n", "fn_kwargs_", ".", "update", "(", "fn_kwargs", ")", "\n", "decayed_lr", "=", "utils", ".", "call_function_with_redundant_kwargs", "(", "\n", "decay_fn", ",", "fn_kwargs_", ")", "\n", "\n", "decayed_lr", "=", "tf", ".", "maximum", "(", "decayed_lr", ",", "hparams", "[", "\"min_learning_rate\"", "]", ")", "\n", "\n", "", "return", "decayed_lr", "\n", "\n", "", "return", "lr_decay_fn", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.core.optimization.get_gradient_clip_fn": [[179, 237], ["texar.utils.utils.get_function", "isinstance", "isinstance", "texar.hyperparams.HParams", "inspect.getargspec", "fn_kwargs.todict.todict", "zip", "list", "utils.get_function.", "zip", "optimization.default_optimization_hparams", "utils.get_function.", "utils.get_function."], "function", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.utils.get_function", "home.repos.pwc.inspect_result.VegB_Text_Infilling.texar.hyperparams.HParams.todict", "home.repos.pwc.inspect_result.VegB_Text_Infilling.core.optimization.default_optimization_hparams"], ["", "def", "get_gradient_clip_fn", "(", "hparams", "=", "None", ")", ":", "\n", "    ", "\"\"\"Creates a gradient clipping function based on the hyperparameters.\n\n    See the :attr:`gradient_clip` field in\n    :meth:`~texar.core.optimization.default_optimization_hparams` for all\n    hyperparameters and default values.\n\n    The gradient clipping function takes a list of `(gradients, variables)`\n    tuples and returns a list of `(clipped_gradients, variables)` tuples.\n    Typical examples include\n    :tf_main:`tf.clip_by_global_norm <clip_by_global_norm>`,\n    :tf_main:`tf.clip_by_value <clip_by_value>`,\n    :tf_main:`tf.clip_by_norm <clip_by_norm>`,\n    :tf_main:`tf.clip_by_average_norm <clip_by_average_norm>`, etc.\n\n    Args:\n        hparams (dict or HParams, optional): hyperparameters. Missing\n            hyperparameters are set to default values automatically.\n\n    Returns:\n        function or `None`: If :attr:`hparams[\"type\"]` is specified, returns\n        the respective function. If :attr:`hparams[\"type\"]` is empty,\n        returns `None`.\n    \"\"\"", "\n", "if", "hparams", "is", "None", "or", "isinstance", "(", "hparams", ",", "dict", ")", ":", "\n", "        ", "hparams", "=", "HParams", "(", "\n", "hparams", ",", "default_optimization_hparams", "(", ")", "[", "\"gradient_clip\"", "]", ")", "\n", "", "fn_type", "=", "hparams", "[", "\"type\"", "]", "\n", "if", "fn_type", "is", "None", "or", "fn_type", "==", "\"\"", ":", "\n", "        ", "return", "None", "\n", "\n", "", "fn_modules", "=", "[", "\"tensorflow\"", ",", "\"texar.custom\"", "]", "\n", "clip_fn", "=", "utils", ".", "get_function", "(", "fn_type", ",", "fn_modules", ")", "\n", "clip_fn_args", "=", "inspect", ".", "getargspec", "(", "clip_fn", ")", ".", "args", "\n", "fn_kwargs", "=", "hparams", "[", "\"kwargs\"", "]", "\n", "if", "isinstance", "(", "fn_kwargs", ",", "HParams", ")", ":", "\n", "        ", "fn_kwargs", "=", "fn_kwargs", ".", "todict", "(", ")", "\n", "\n", "", "def", "grad_clip_fn", "(", "grads_and_vars", ")", ":", "\n", "        ", "\"\"\"Gradient clipping function.\n\n        Args:\n            grads_and_vars (list): A list of `(gradients, variables)` tuples.\n\n        Returns:\n            list: A list of `(clipped_gradients, variables)` tuples.\n        \"\"\"", "\n", "grads", ",", "vars_", "=", "zip", "(", "*", "grads_and_vars", ")", "\n", "if", "clip_fn", "==", "tf", ".", "clip_by_global_norm", ":", "\n", "            ", "clipped_grads", ",", "_", "=", "clip_fn", "(", "t_list", "=", "grads", ",", "**", "fn_kwargs", ")", "\n", "", "elif", "'t_list'", "in", "clip_fn_args", ":", "\n", "            ", "clipped_grads", "=", "clip_fn", "(", "t_list", "=", "grads", ",", "**", "fn_kwargs", ")", "\n", "", "elif", "'t'", "in", "clip_fn_args", ":", "# e.g., tf.clip_by_value", "\n", "            ", "clipped_grads", "=", "[", "clip_fn", "(", "t", "=", "grad", ",", "**", "fn_kwargs", ")", "for", "grad", "in", "grads", "]", "\n", "\n", "", "return", "list", "(", "zip", "(", "clipped_grads", ",", "vars_", ")", ")", "\n", "\n", "", "return", "grad_clip_fn", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.core.optimization.get_train_op": [[239, 298], ["texar.hyperparams.HParams", "optimization.get_optimizer_fn", "optimization.get_gradient_clip_fn", "optimization.get_learning_rate_decay_fn", "tensorflow.contrib.layers.optimize_loss", "optimization.default_optimization_hparams", "opt_hparams[].get", "texar.utils.utils.get_default_arg_values", "utils.get_default_arg_values.get"], "function", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.core.optimization.get_optimizer_fn", "home.repos.pwc.inspect_result.VegB_Text_Infilling.core.optimization.get_gradient_clip_fn", "home.repos.pwc.inspect_result.VegB_Text_Infilling.core.optimization.get_learning_rate_decay_fn", "home.repos.pwc.inspect_result.VegB_Text_Infilling.core.optimization.default_optimization_hparams", "home.repos.pwc.inspect_result.VegB_Text_Infilling.core.replay_memories.DequeReplayMemory.get", "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.utils.get_default_arg_values", "home.repos.pwc.inspect_result.VegB_Text_Infilling.core.replay_memories.DequeReplayMemory.get"], ["", "def", "get_train_op", "(", "loss", ",", "variables", "=", "None", ",", "learning_rate", "=", "None", ",", "\n", "global_step", "=", "None", ",", "increment_global_step", "=", "True", ",", "hparams", "=", "None", ")", ":", "\n", "    ", "\"\"\"Creates a training op.\n\n    Args:\n        loss: A scalar Tensor representing the loss to optimize.\n        variables (optional): A list of Variables to optimize. If\n            `None`, all trainable variables are used.\n        learning_rate (float or Tensor, optional): If `None`, learning rate\n            specified in :attr:`hparams`, or the default learning rate\n            of the optimizer will be used (if exists).\n        global_step (optional): A scalar int Tensor. Step counter to update on\n            each step unless :attr:`increment_global_step` is `False`.\n            Learning rate decay requires requires :attr:`global_step`.\n        increment_global_step (bool): Whether to increment\n            :attr:`global_step`. This is useful if the :attr:`global_step` is\n            used in multiple training ops per training step (e.g. to optimize\n            different parts of the model) to avoid incrementing\n            :attr:`global_step` more times than necessary.\n        hparams (dict or HParams, optional): hyperparameters. Missing\n            hyperparameters are set to default values automatically. See\n            :meth:`~texar.core.optimization.default_optimization_hparams` for\n            all hyperparameters and default values.\n\n    Returns:\n        tuple: (train_op, global_step). If :attr:`global_step` is provided, the\n        same :attr:`global_step` variable is returned, otherwise a new global\n        step is created and returned.\n    \"\"\"", "\n", "hparams", "=", "HParams", "(", "hparams", ",", "default_optimization_hparams", "(", ")", ")", "\n", "\n", "opt_hparams", "=", "hparams", "[", "\"optimizer\"", "]", "\n", "optimizer_fn", ",", "optimizer_class", "=", "get_optimizer_fn", "(", "opt_hparams", ")", "\n", "\n", "if", "learning_rate", "is", "None", ":", "\n", "        ", "learning_rate", "=", "opt_hparams", "[", "\"kwargs\"", "]", ".", "get", "(", "\"learning_rate\"", ",", "None", ")", "\n", "", "if", "learning_rate", "is", "None", ":", "\n", "# Try to get learning_rate from the default value of the", "\n", "# optimizer's argument", "\n", "        ", "opt_argspec", "=", "utils", ".", "get_default_arg_values", "(", "optimizer_class", ".", "__init__", ")", "\n", "learning_rate", "=", "opt_argspec", ".", "get", "(", "\"learning_rate\"", ",", "None", ")", "\n", "\n", "", "grad_clip_fn", "=", "get_gradient_clip_fn", "(", "hparams", "[", "\"gradient_clip\"", "]", ")", "\n", "\n", "lr_decay_fn", "=", "get_learning_rate_decay_fn", "(", "hparams", "[", "\"learning_rate_decay\"", "]", ")", "\n", "\n", "train_op", "=", "tf", ".", "contrib", ".", "layers", ".", "optimize_loss", "(", "\n", "loss", "=", "loss", ",", "\n", "global_step", "=", "global_step", ",", "\n", "learning_rate", "=", "learning_rate", ",", "\n", "optimizer", "=", "optimizer_fn", ",", "\n", "gradient_noise_scale", "=", "hparams", "[", "\"gradient_noise_scale\"", "]", ",", "\n", "clip_gradients", "=", "grad_clip_fn", ",", "\n", "learning_rate_decay_fn", "=", "lr_decay_fn", ",", "\n", "variables", "=", "variables", ",", "\n", "name", "=", "hparams", "[", "\"name\"", "]", ",", "\n", "increment_global_step", "=", "increment_global_step", ")", "\n", "\n", "return", "train_op", "\n", "", ""]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.core.layers.get_timing_signal_1d": [[6, 45], ["tensorflow.to_float", "tensorflow.concat", "tensorflow.pad", "tensorflow.reshape", "tensorflow.range", "math.log", "tensorflow.exp", "tensorflow.expand_dims", "tensorflow.expand_dims", "tensorflow.to_float", "tensorflow.sin", "tensorflow.cos", "float", "float", "tensorflow.to_float", "tensorflow.mod", "tensorflow.range"], "function", ["None"], ["from", "__future__", "import", "print_function", "\n", "from", "__future__", "import", "division", "\n", "\n", "import", "copy", "\n", "import", "numpy", "as", "np", "\n", "\n", "import", "tensorflow", "as", "tf", "\n", "import", "tensorflow", ".", "contrib", ".", "rnn", "as", "rnn", "\n", "from", "texar", "import", "context", "\n", "from", "texar", ".", "hyperparams", "import", "HParams", "\n", "from", "texar", ".", "utils", "import", "utils", "\n", "from", "texar", ".", "utils", ".", "dtypes", "import", "is_str", "\n", "from", "texar", ".", "utils", ".", "variables", "import", "add_variable", "\n", "from", "texar", ".", "utils", ".", "mode", "import", "is_train_mode", ",", "switch_dropout", "\n", "\n", "# pylint: disable=not-context-manager, redefined-variable-type, invalid-name", "\n", "# pylint: disable=too-many-branches, too-many-arguments, too-many-lines", "\n", "# pylint: disable=protected-access", "\n", "\n", "__all__", "=", "[", "\n", "\"default_rnn_cell_hparams\"", ",", "\n", "\"get_rnn_cell\"", ",", "\n", "\"get_rnn_cell_trainable_variables\"", ",", "\n", "\"default_regularizer_hparams\"", ",", "\n", "\"get_regularizer\"", ",", "\n", "\"get_initializer\"", ",", "\n", "\"get_activation_fn\"", ",", "\n", "\"get_constraint_fn\"", ",", "\n", "\"get_layer\"", ",", "\n", "\"_ReducePooling1D\"", ",", "\n", "\"MaxReducePooling1D\"", ",", "\n", "\"AverageReducePooling1D\"", ",", "\n", "\"get_pooling_layer_hparams\"", ",", "\n", "\"MergeLayer\"", ",", "\n", "\"SequentialLayer\"", ",", "\n", "\"default_conv1d_kwargs\"", ",", "\n", "\"default_conv2d_kwargs\"", ",", "\n", "\"default_conv3d_kwargs\"", ",", "\n", "\"default_conv2d_transpose_kwargs\"", ",", "\n", "\"default_conv3d_transpose_kwargs\"", ",", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.core.layers.add_timing_signal_1d": [[46, 72], ["layers.get_timing_signal_1d", "texar.core.layers.shape_list", "texar.core.layers.shape_list"], "function", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.core.layers.get_timing_signal_1d", "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.shapes.shape_list", "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.shapes.shape_list"], ["\"default_dense_kwargs\"", ",", "\n", "\"default_dropout_kwargs\"", ",", "\n", "\"default_flatten_kwargs\"", ",", "\n", "\"default_max_pooling1d_kwargs\"", ",", "\n", "\"default_max_pooling2d_kwargs\"", ",", "\n", "\"default_max_pooling3d_kwargs\"", ",", "\n", "\"default_separable_conv2d_kwargs\"", ",", "\n", "\"default_batch_normalization_kwargs\"", ",", "\n", "\"default_average_pooling1d_kwargs\"", ",", "\n", "\"default_average_pooling2d_kwargs\"", ",", "\n", "\"default_average_pooling3d_kwargs\"", ",", "\n", "#TODO(haoran): the reorganizing of following functions", "\n", "\"multihead_attention\"", ",", "\n", "\"layer_normalize\"", ",", "\n", "]", "\n", "\n", "def", "default_rnn_cell_hparams", "(", ")", ":", "\n", "    "]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.core.layers.add_timing_signal_1d_given_position": [[74, 101], ["tensorflow.concat", "tensorflow.pad", "tensorflow.cast", "texar.core.layers.shape_list", "math.log", "tensorflow.exp", "tensorflow.expand_dims", "tensorflow.expand_dims", "tensorflow.to_float", "tensorflow.to_float", "tensorflow.expand_dims", "tensorflow.sin", "tensorflow.cos", "float", "float", "tensorflow.to_float", "tensorflow.mod", "tensorflow.range"], "function", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.shapes.shape_list"], []], "home.repos.pwc.inspect_result.VegB_Text_Infilling.core.explorations.ExplorationBase.__init__": [[20, 22], ["texar.hyperparams.HParams", "explorations.ExplorationBase.default_hparams"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.core.replay_memories.DequeReplayMemory.default_hparams"], ["def", "__init__", "(", "self", ",", "hparams", "=", "None", ")", ":", "\n", "        ", "self", ".", "_hparams", "=", "HParams", "(", "hparams", ",", "self", ".", "default_hparams", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.core.explorations.ExplorationBase.default_hparams": [[23, 31], ["None"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "default_hparams", "(", ")", ":", "\n", "        ", "\"\"\"Returns a dictionary of default hyperparameters.\n\n        TODO: docs\n        \"\"\"", "\n", "return", "{", "\n", "'name'", ":", "'exploration_base'", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.core.explorations.ExplorationBase.get_epsilon": [[33, 43], ["None"], "methods", ["None"], ["", "def", "get_epsilon", "(", "self", ",", "timestep", ")", ":", "\n", "        ", "\"\"\"Returns the epsilon value.\n\n        Args:\n            timestep (int): The time step.\n\n        Returns:\n            float: the epsilon value.\n        \"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.core.explorations.ExplorationBase.hparams": [[44, 49], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "hparams", "(", "self", ")", ":", "\n", "        ", "\"\"\"The hyperparameter.\n        \"\"\"", "\n", "return", "self", ".", "_hparams", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.core.explorations.EpsilonLinearDecayExploration.__init__": [[56, 58], ["explorations.ExplorationBase.__init__"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.text_infilling.self_attn_hyperparams.Hyperparams.__init__"], ["def", "__init__", "(", "self", ",", "hparams", "=", "None", ")", ":", "\n", "        ", "ExplorationBase", ".", "__init__", "(", "self", ",", "hparams", "=", "hparams", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.core.explorations.EpsilonLinearDecayExploration.default_hparams": [[59, 69], ["None"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "default_hparams", "(", ")", ":", "\n", "        ", "\"\"\"TODO\n        \"\"\"", "\n", "return", "{", "\n", "'name'", ":", "'epsilon_linear_decay_exploration'", ",", "\n", "'initial_epsilon'", ":", "0.1", ",", "\n", "'final_epsilon'", ":", "0.0", ",", "\n", "'decay_timesteps'", ":", "20000", ",", "\n", "'start_timestep'", ":", "0", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.core.explorations.EpsilonLinearDecayExploration.get_epsilon": [[71, 85], ["None"], "methods", ["None"], ["", "def", "get_epsilon", "(", "self", ",", "timestep", ")", ":", "\n", "        ", "nsteps", "=", "self", ".", "_hparams", ".", "decay_timesteps", "\n", "st", "=", "self", ".", "_hparams", ".", "start_timestep", "\n", "et", "=", "st", "+", "nsteps", "\n", "\n", "if", "timestep", "<=", "st", ":", "\n", "            ", "return", "self", ".", "_hparams", ".", "initial_epsilon", "\n", "", "if", "timestep", ">", "et", ":", "\n", "            ", "return", "self", ".", "_hparams", ".", "final_epsilon", "\n", "", "r", "=", "(", "timestep", "-", "st", ")", "*", "1.0", "/", "nsteps", "\n", "epsilon", "=", "(", "1", "-", "r", ")", "*", "self", ".", "_hparams", ".", "initial_epsilon", "+", "r", "*", "self", ".", "_hparams", ".", "final_epsilon", "\n", "\n", "return", "epsilon", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.core.layers._ReducePooling1D.__init__": [[549, 557], ["super().__init__", "ValueError"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.text_infilling.self_attn_hyperparams.Hyperparams.__init__"], ["def", "__init__", "(", "self", ",", "reduce_function", ",", "data_format", "=", "'channels_last'", ",", "\n", "name", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "_ReducePooling1D", ",", "self", ")", ".", "__init__", "(", "name", "=", "name", ",", "**", "kwargs", ")", "\n", "self", ".", "_reduce_function", "=", "reduce_function", "\n", "if", "data_format", "not", "in", "{", "'channels_last'", ",", "'channels_first'", "}", ":", "\n", "            ", "raise", "ValueError", "(", "\"`data_format must be either 'channels_last' or` \"", "\n", "\"'channels_first'. Got: {}\"", ".", "format", "(", "data_format", ")", ")", "\n", "", "self", ".", "_data_format", "=", "data_format", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.core.layers._ReducePooling1D.compute_output_shape": [[558, 564], ["tensorflow.TensorShape().as_list", "tensorflow.TensorShape().as_list", "tensorflow.TensorShape", "tensorflow.TensorShape", "tensorflow.TensorShape", "tensorflow.TensorShape", "tensorflow.TensorShape", "tensorflow.TensorShape"], "methods", ["None"], ["", "def", "compute_output_shape", "(", "self", ",", "input_shape", ")", ":", "\n", "        ", "input_shape", "=", "tf", ".", "TensorShape", "(", "input_shape", ")", ".", "as_list", "(", ")", "\n", "if", "self", ".", "_data_format", "==", "'channels_last'", ":", "\n", "            ", "return", "tf", ".", "TensorShape", "(", "[", "input_shape", "[", "0", "]", ",", "input_shape", "[", "2", "]", "]", ")", "\n", "", "else", ":", "\n", "            ", "return", "tf", ".", "TensorShape", "(", "[", "input_shape", "[", "0", "]", ",", "input_shape", "[", "1", "]", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.core.layers._ReducePooling1D.call": [[565, 570], ["layers._ReducePooling1D._reduce_function", "layers._ReducePooling1D._reduce_function"], "methods", ["None"], ["", "", "def", "call", "(", "self", ",", "inputs", ")", ":", "\n", "        ", "if", "self", ".", "_data_format", "==", "'channels_last'", ":", "\n", "            ", "return", "self", ".", "_reduce_function", "(", "inputs", ",", "axis", "=", "1", ")", "\n", "", "else", ":", "\n", "            ", "return", "self", ".", "_reduce_function", "(", "inputs", ",", "axis", "=", "2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.core.layers.MaxReducePooling1D.__init__": [[578, 581], ["layers._ReducePooling1D.__init__"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.text_infilling.self_attn_hyperparams.Hyperparams.__init__"], ["def", "__init__", "(", "self", ",", "data_format", "=", "'channels_last'", ",", "name", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "MaxReducePooling1D", ",", "self", ")", ".", "__init__", "(", "\n", "tf", ".", "reduce_max", ",", "data_format", "=", "data_format", ",", "name", "=", "name", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.core.layers.AverageReducePooling1D.__init__": [[589, 592], ["layers._ReducePooling1D.__init__"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.text_infilling.self_attn_hyperparams.Hyperparams.__init__"], ["def", "__init__", "(", "self", ",", "data_format", "=", "'channels_last'", ",", "name", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "AverageReducePooling1D", ",", "self", ")", ".", "__init__", "(", "\n", "tf", ".", "reduce_mean", ",", "data_format", "=", "data_format", ",", "name", "=", "name", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.core.layers.MergeLayer.__init__": [[663, 686], ["super().__init__", "len", "ValueError", "isinstance", "layers.MergeLayer._layers.append", "layers.MergeLayer._layers.append", "layers.get_layer"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.text_infilling.self_attn_hyperparams.Hyperparams.__init__", "home.repos.pwc.inspect_result.VegB_Text_Infilling.core.layers.get_layer"], ["def", "__init__", "(", "self", ",", "\n", "layers", "=", "None", ",", "\n", "mode", "=", "'concat'", ",", "\n", "axis", "=", "1", ",", "\n", "trainable", "=", "True", ",", "\n", "name", "=", "None", ",", "\n", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "MergeLayer", ",", "self", ")", ".", "__init__", "(", "\n", "trainable", "=", "trainable", ",", "name", "=", "name", ",", "**", "kwargs", ")", "\n", "self", ".", "_mode", "=", "mode", "\n", "self", ".", "_axis", "=", "axis", "\n", "\n", "self", ".", "_layers", "=", "None", "\n", "if", "layers", "is", "not", "None", ":", "\n", "            ", "if", "len", "(", "layers", ")", "==", "0", ":", "\n", "                ", "raise", "ValueError", "(", "\n", "\"'layers' must be either None or a non-empty list.\"", ")", "\n", "", "self", ".", "_layers", "=", "[", "]", "\n", "for", "layer", "in", "layers", ":", "\n", "                ", "if", "isinstance", "(", "layer", ",", "tf", ".", "layers", ".", "Layer", ")", ":", "\n", "                    ", "self", ".", "_layers", ".", "append", "(", "layer", ")", "\n", "", "else", ":", "\n", "                    ", "self", ".", "_layers", ".", "append", "(", "get_layer", "(", "hparams", "=", "layer", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.core.layers.MergeLayer.compute_output_shape": [[687, 720], ["tensorflow.TensorShape", "tensorflow.TensorShape", "tensorflow.TensorShape", "tensorflow.TensorShape", "layers._compute_concat_output_shape", "isinstance", "layer.compute_output_shape", "_shapes.append", "layers._compute_concat_output_shape", "_compute_concat_output_shape.pop", "max", "enumerate", "ValueError", "next", "max_ranked_shapes.append", "zip", "s.as_list"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.core.layers._compute_concat_output_shape", "home.repos.pwc.inspect_result.VegB_Text_Infilling.core.layers.SequentialLayer.compute_output_shape", "home.repos.pwc.inspect_result.VegB_Text_Infilling.core.layers._compute_concat_output_shape"], ["", "", "", "", "def", "compute_output_shape", "(", "self", ",", "input_shape", ")", ":", "\n", "        ", "if", "self", ".", "_layers", "is", "None", ":", "\n", "            ", "_shapes", "=", "input_shape", "\n", "if", "not", "isinstance", "(", "_shapes", ",", "(", "list", ",", "tuple", ")", ")", ":", "\n", "                ", "_shapes", "=", "[", "_shapes", "]", "\n", "", "", "else", ":", "\n", "            ", "_shapes", "=", "[", "]", "\n", "for", "layer", "in", "self", ".", "_layers", ":", "\n", "                ", "layer_output_shape", "=", "layer", ".", "compute_output_shape", "(", "input_shape", ")", "\n", "_shapes", ".", "append", "(", "layer_output_shape", ")", "\n", "", "", "_shapes", "=", "[", "tf", ".", "TensorShape", "(", "s", ")", "for", "s", "in", "_shapes", "]", "\n", "\n", "if", "self", ".", "_mode", "==", "'concat'", ":", "\n", "            ", "output_shape", "=", "_compute_concat_output_shape", "(", "_shapes", ",", "self", ".", "_axis", ")", "\n", "", "elif", "self", ".", "_mode", "in", "[", "'sum'", ",", "'mean'", ",", "'prod'", ",", "'max'", ",", "'min'", ",", "\n", "'and'", ",", "'or'", ",", "'logsumexp'", "]", ":", "\n", "            ", "output_shape", "=", "_compute_concat_output_shape", "(", "_shapes", ",", "self", ".", "_axis", ")", "\n", "output_shape", ".", "pop", "(", "self", ".", "_axis", ")", "\n", "", "elif", "self", ".", "_mode", "in", "[", "'elemwise_sum'", ",", "'elemwise_mul'", "]", ":", "\n", "# Simply infer the output shape as the input shape of highest rank", "\n", "            ", "_ranks", "=", "[", "s", ".", "ndims", "for", "s", "in", "_shapes", "]", "\n", "max_rank", "=", "max", "(", "_ranks", ")", "\n", "max_ranked_shapes", "=", "[", "]", "\n", "for", "i", ",", "s", "in", "enumerate", "(", "_shapes", ")", ":", "\n", "                ", "if", "_ranks", "[", "i", "]", "==", "max_rank", ":", "\n", "                    ", "max_ranked_shapes", ".", "append", "(", "s", ".", "as_list", "(", ")", ")", "\n", "# Grab the first size of each axis that is not `None`", "\n", "", "", "output_shape", "=", "[", "next", "(", "(", "s", "for", "s", "in", "sizes", "if", "s", "is", "not", "None", ")", ",", "None", ")", "\n", "for", "sizes", "in", "zip", "(", "*", "max_ranked_shapes", ")", "]", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\"Unknown merge mode: '%s'\"", "%", "self", ".", "_mode", ")", "\n", "\n", "", "return", "tf", ".", "TensorShape", "(", "output_shape", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.core.layers.MergeLayer.build": [[721, 726], ["None"], "methods", ["None"], ["", "def", "build", "(", "self", ",", "_", ")", ":", "\n", "        ", "\"\"\"Dumb method.\n        \"\"\"", "\n", "# Does not set :attr:`self.built` as this point.", "\n", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.core.layers.MergeLayer._collect_weights": [[727, 741], ["texar.utils.variables.add_variable", "texar.utils.variables.add_variable", "texar.utils.variables.add_variable"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.variables.add_variable", "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.variables.add_variable", "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.variables.add_variable"], ["", "def", "_collect_weights", "(", "self", ")", ":", "\n", "        ", "\"\"\"Collects (non-)trainable weights of each of the parallel layers.\n        \"\"\"", "\n", "if", "self", ".", "_layers", "is", "None", ":", "\n", "            ", "pass", "\n", "", "for", "layer", "in", "self", ".", "_layers", ":", "\n", "            ", "if", "self", ".", "trainable", ":", "\n", "                ", "add_variable", "(", "\n", "layer", ".", "_trainable_weights", ",", "self", ".", "_trainable_weights", ")", "\n", "", "else", ":", "\n", "                ", "add_variable", "(", "\n", "layer", ".", "_trainable_weights", ",", "self", ".", "_non_trainable_weights", ")", "\n", "", "add_variable", "(", "\n", "layer", ".", "_non_trainable_weights", ",", "self", ".", "_non_trainable_weights", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.core.layers.MergeLayer.call": [[742, 794], ["tensorflow.concat", "tensorflow.concat", "layers.MergeLayer._collect_weights", "isinstance", "layer", "layer_outputs.append", "range", "len", "tensorflow.add", "tensorflow.add", "range", "len", "tensorflow.multiply", "tensorflow.multiply", "tensorflow.concat", "tensorflow.concat", "tensorflow.reduce_sum", "tensorflow.reduce_sum", "tensorflow.concat", "tensorflow.concat", "tensorflow.reduce_mean", "tensorflow.reduce_mean", "tensorflow.concat", "tensorflow.concat", "tensorflow.reduce_prod", "tensorflow.reduce_prod", "tensorflow.concat", "tensorflow.concat", "tensorflow.reduce_max", "tensorflow.reduce_max", "tensorflow.concat", "tensorflow.concat", "tensorflow.reduce_min", "tensorflow.reduce_min", "tensorflow.concat", "tensorflow.concat", "tensorflow.reduce_all", "tensorflow.reduce_all", "tensorflow.concat", "tensorflow.concat", "tensorflow.reduce_any", "tensorflow.reduce_any", "tensorflow.concat", "tensorflow.concat", "tensorflow.reduce_logsumexp", "tensorflow.reduce_logsumexp", "ValueError"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.core.layers.SequentialLayer._collect_weights", "home.repos.pwc.inspect_result.VegB_Text_Infilling.core.replay_memories.DequeReplayMemory.add", "home.repos.pwc.inspect_result.VegB_Text_Infilling.core.replay_memories.DequeReplayMemory.add"], ["", "", "def", "call", "(", "self", ",", "inputs", ")", ":", "\n", "        ", "if", "self", ".", "_layers", "is", "None", ":", "\n", "            ", "layer_outputs", "=", "inputs", "\n", "if", "not", "isinstance", "(", "layer_outputs", ",", "(", "list", ",", "tuple", ")", ")", ":", "\n", "                ", "layer_outputs", "=", "[", "layer_outputs", "]", "\n", "", "", "else", ":", "\n", "            ", "layer_outputs", "=", "[", "]", "\n", "for", "layer", "in", "self", ".", "_layers", ":", "\n", "                ", "layer_output", "=", "layer", "(", "inputs", ")", "\n", "layer_outputs", ".", "append", "(", "layer_output", ")", "\n", "\n", "", "", "if", "self", ".", "_mode", "==", "'concat'", ":", "\n", "            ", "outputs", "=", "tf", ".", "concat", "(", "values", "=", "layer_outputs", ",", "axis", "=", "self", ".", "_axis", ")", "\n", "", "elif", "self", ".", "_mode", "==", "'elemwise_sum'", ":", "\n", "            ", "outputs", "=", "layer_outputs", "[", "0", "]", "\n", "for", "i", "in", "range", "(", "1", ",", "len", "(", "layer_outputs", ")", ")", ":", "\n", "                ", "outputs", "=", "tf", ".", "add", "(", "outputs", ",", "layer_outputs", "[", "i", "]", ")", "\n", "", "", "elif", "self", ".", "_mode", "==", "'elemwise_mul'", ":", "\n", "            ", "outputs", "=", "layer_outputs", "[", "0", "]", "\n", "for", "i", "in", "range", "(", "1", ",", "len", "(", "layer_outputs", ")", ")", ":", "\n", "                ", "outputs", "=", "tf", ".", "multiply", "(", "outputs", ",", "layer_outputs", "[", "i", "]", ")", "\n", "", "", "elif", "self", ".", "_mode", "==", "'sum'", ":", "\n", "            ", "_concat", "=", "tf", ".", "concat", "(", "values", "=", "layer_outputs", ",", "axis", "=", "self", ".", "_axis", ")", "\n", "outputs", "=", "tf", ".", "reduce_sum", "(", "_concat", ",", "axis", "=", "self", ".", "_axis", ")", "\n", "", "elif", "self", ".", "_mode", "==", "'mean'", ":", "\n", "            ", "_concat", "=", "tf", ".", "concat", "(", "values", "=", "layer_outputs", ",", "axis", "=", "self", ".", "_axis", ")", "\n", "outputs", "=", "tf", ".", "reduce_mean", "(", "_concat", ",", "axis", "=", "self", ".", "_axis", ")", "\n", "", "elif", "self", ".", "_mode", "==", "'prod'", ":", "\n", "            ", "_concat", "=", "tf", ".", "concat", "(", "values", "=", "layer_outputs", ",", "axis", "=", "self", ".", "_axis", ")", "\n", "outputs", "=", "tf", ".", "reduce_prod", "(", "_concat", ",", "axis", "=", "self", ".", "_axis", ")", "\n", "", "elif", "self", ".", "_mode", "==", "'max'", ":", "\n", "            ", "_concat", "=", "tf", ".", "concat", "(", "values", "=", "layer_outputs", ",", "axis", "=", "self", ".", "_axis", ")", "\n", "outputs", "=", "tf", ".", "reduce_max", "(", "_concat", ",", "axis", "=", "self", ".", "_axis", ")", "\n", "", "elif", "self", ".", "_mode", "==", "'min'", ":", "\n", "            ", "_concat", "=", "tf", ".", "concat", "(", "values", "=", "layer_outputs", ",", "axis", "=", "self", ".", "_axis", ")", "\n", "outputs", "=", "tf", ".", "reduce_min", "(", "_concat", ",", "axis", "=", "self", ".", "_axis", ")", "\n", "", "elif", "self", ".", "_mode", "==", "'and'", ":", "\n", "            ", "_concat", "=", "tf", ".", "concat", "(", "values", "=", "layer_outputs", ",", "axis", "=", "self", ".", "_axis", ")", "\n", "outputs", "=", "tf", ".", "reduce_all", "(", "_concat", ",", "axis", "=", "self", ".", "_axis", ")", "\n", "", "elif", "self", ".", "_mode", "==", "'or'", ":", "\n", "            ", "_concat", "=", "tf", ".", "concat", "(", "values", "=", "layer_outputs", ",", "axis", "=", "self", ".", "_axis", ")", "\n", "outputs", "=", "tf", ".", "reduce_any", "(", "_concat", ",", "axis", "=", "self", ".", "_axis", ")", "\n", "", "elif", "self", ".", "_mode", "==", "'logsumexp'", ":", "\n", "            ", "_concat", "=", "tf", ".", "concat", "(", "values", "=", "layer_outputs", ",", "axis", "=", "self", ".", "_axis", ")", "\n", "outputs", "=", "tf", ".", "reduce_logsumexp", "(", "_concat", ",", "axis", "=", "self", ".", "_axis", ")", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\"Unknown merge mode: '%s'\"", "%", "self", ".", "_mode", ")", "\n", "\n", "", "if", "not", "self", ".", "built", ":", "\n", "            ", "self", ".", "_collect_weights", "(", ")", "\n", "\n", "", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.core.layers.MergeLayer.layers": [[795, 800], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "layers", "(", "self", ")", ":", "\n", "        ", "\"\"\"The list of parallel layers.\n        \"\"\"", "\n", "return", "self", ".", "_layers", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.core.layers.SequentialLayer.__init__": [[812, 828], ["super().__init__", "len", "ValueError", "isinstance", "layers.SequentialLayer._layers.append", "layers.SequentialLayer._layers.append", "layers.get_layer"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.text_infilling.self_attn_hyperparams.Hyperparams.__init__", "home.repos.pwc.inspect_result.VegB_Text_Infilling.core.layers.get_layer"], ["def", "__init__", "(", "self", ",", "\n", "layers", ",", "\n", "trainable", "=", "True", ",", "\n", "name", "=", "None", ",", "\n", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "SequentialLayer", ",", "self", ")", ".", "__init__", "(", "\n", "trainable", "=", "trainable", ",", "name", "=", "name", ",", "**", "kwargs", ")", "\n", "\n", "if", "len", "(", "layers", ")", "==", "0", ":", "\n", "            ", "raise", "ValueError", "(", "\"'layers' must be a non-empty list.\"", ")", "\n", "", "self", ".", "_layers", "=", "[", "]", "\n", "for", "layer", "in", "layers", ":", "\n", "            ", "if", "isinstance", "(", "layer", ",", "tf", ".", "layers", ".", "Layer", ")", ":", "\n", "                ", "self", ".", "_layers", ".", "append", "(", "layer", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "_layers", ".", "append", "(", "get_layer", "(", "hparams", "=", "layer", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.core.layers.SequentialLayer.compute_output_shape": [[829, 835], ["tensorflow.TensorShape", "tensorflow.TensorShape", "layer.compute_output_shape"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.core.layers.SequentialLayer.compute_output_shape"], ["", "", "", "def", "compute_output_shape", "(", "self", ",", "input_shape", ")", ":", "\n", "        ", "input_shape", "=", "tf", ".", "TensorShape", "(", "input_shape", ")", "\n", "for", "layer", "in", "self", ".", "_layers", ":", "\n", "            ", "output_shape", "=", "layer", ".", "compute_output_shape", "(", "input_shape", ")", "\n", "input_shape", "=", "output_shape", "\n", "", "return", "output_shape", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.core.layers.SequentialLayer.build": [[836, 841], ["None"], "methods", ["None"], ["", "def", "build", "(", "self", ",", "_", ")", ":", "\n", "        ", "\"\"\"Dumb method.\n        \"\"\"", "\n", "# Does not set :attr:`self.built` as this point.", "\n", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.core.layers.SequentialLayer._collect_weights": [[842, 854], ["texar.utils.variables.add_variable", "texar.utils.variables.add_variable", "texar.utils.variables.add_variable"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.variables.add_variable", "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.variables.add_variable", "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.variables.add_variable"], ["", "def", "_collect_weights", "(", "self", ")", ":", "\n", "        ", "\"\"\"Collects (non-)trainable weights of each of the layers.\n        \"\"\"", "\n", "for", "layer", "in", "self", ".", "_layers", ":", "\n", "            ", "if", "self", ".", "trainable", ":", "\n", "                ", "add_variable", "(", "\n", "layer", ".", "_trainable_weights", ",", "self", ".", "_trainable_weights", ")", "\n", "", "else", ":", "\n", "                ", "add_variable", "(", "\n", "layer", ".", "_trainable_weights", ",", "self", ".", "_non_trainable_weights", ")", "\n", "", "add_variable", "(", "\n", "layer", ".", "_non_trainable_weights", ",", "self", ".", "_non_trainable_weights", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.core.layers.SequentialLayer.call": [[855, 873], ["texar.utils.mode.is_train_mode", "layers.SequentialLayer._collect_weights", "isinstance", "isinstance", "layer", "layer"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.mode.is_train_mode", "home.repos.pwc.inspect_result.VegB_Text_Infilling.core.layers.SequentialLayer._collect_weights"], ["", "", "def", "call", "(", "self", ",", "inputs", ",", "mode", "=", "None", ")", ":", "# pylint: disable=arguments-differ", "\n", "        ", "\"\"\"TODO\n        \"\"\"", "\n", "training", "=", "is_train_mode", "(", "mode", ")", "\n", "\n", "outputs", "=", "inputs", "\n", "for", "layer", "in", "self", ".", "_layers", ":", "\n", "            ", "if", "isinstance", "(", "layer", ",", "tf", ".", "layers", ".", "Dropout", ")", "or", "isinstance", "(", "layer", ",", "tf", ".", "layers", ".", "BatchNormalization", ")", ":", "\n", "                ", "outputs", "=", "layer", "(", "outputs", ",", "training", "=", "training", ")", "\n", "", "else", ":", "\n", "                ", "outputs", "=", "layer", "(", "inputs", ")", "\n", "", "inputs", "=", "outputs", "\n", "\n", "", "if", "not", "self", ".", "built", ":", "\n", "            ", "self", ".", "_collect_weights", "(", ")", "\n", "\n", "", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.core.layers.SequentialLayer.layers": [[874, 879], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "layers", "(", "self", ")", ":", "\n", "        ", "\"\"\"The list of layers connected sequentially.\n        \"\"\"", "\n", "return", "self", ".", "_layers", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.core.layers.default_rnn_cell_hparams": [[62, 135], ["None"], "function", ["None"], ["def", "default_rnn_cell_hparams", "(", ")", ":", "\n", "    ", "\"\"\"Returns default hyperparameters of an RNN cell.\n\n    Returns:\n        A dictionary with the following structure and values:\n\n        .. code-block:: python\n\n            {\n                # Name or full path of the cell class. E.g., the classname\n                # of built-in cells in `tensorflow.contrib.rnn`, or the\n                # classname of user-defined cells in `texar.custom`, or a\n                # full path like \"my_module.MyCell\".\n                \"type\": \"BasicLSTMCell\",\n\n                # A dictionary of arguments for constructor of the cell\n                # class. An RNN cell is created by calling the cell class\n                # named in `type` passing the arguments specified in\n                # `kwargs` as `cell_class(**kwargs)`\n                \"kwargs\": {\n                    \"num_units\": 256\n                }\n\n                # Number of cell layers\n                \"num_layers\": 1\n\n                # Dropout applied to the cell in each layer. See\n                # `tensorflow.contrib.rnn.DropoutWrapper` for each of the\n                # hyperparameters. If all keep probablities are 1.0, no dropout\n                # is applied.\n                \"dropout\": {\n                    \"input_keep_prob\": 1.0,\n                    \"output_keep_prob\": 1.0,\n                    \"state_keep_prob\": 1.0,\n\n                    # If True, the same dropout mask is applied at every step,\n                    # and the list of input size of each layer is required\n                    # (in \"input_size\"). The input size of a layer is the size\n                    # of the last dimension of its input tensor. E.g., the\n                    # input size of the first layer is usually the dimension of\n                    # word embeddings, while the input size of followup layers\n                    # are usually the num_units of the cells.\n                    \"variational_recurrent\": False,\n                    \"input_size\": []\n                },\n\n                # If True, apply residual connection on the inputs and\n                # outputs of cell in each layer except the first layer.\n                \"residual\": False,\n\n                # If True, apply highway connection on the inputs and\n                # outputs of cell in each layer except the first layer.\n                \"highway\": False,\n            }\n    \"\"\"", "\n", "return", "{", "\n", "\"type\"", ":", "\"BasicLSTMCell\"", ",", "\n", "\"kwargs\"", ":", "{", "\n", "\"num_units\"", ":", "256", ",", "\n", "}", ",", "\n", "\"num_layers\"", ":", "1", ",", "\n", "\"dropout\"", ":", "{", "\n", "\"input_keep_prob\"", ":", "1.0", ",", "\n", "\"output_keep_prob\"", ":", "1.0", ",", "\n", "\"state_keep_prob\"", ":", "1.0", ",", "\n", "\"variational_recurrent\"", ":", "False", ",", "\n", "\"input_size\"", ":", "[", "]", ",", "\n", "\"@no_typecheck\"", ":", "[", "\n", "\"input_keep_prob\"", ",", "\"output_keep_prob\"", ",", "\"state_keep_prob\"", "\n", "]", "\n", "}", ",", "\n", "\"residual\"", ":", "False", ",", "\n", "\"highway\"", ":", "False", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.core.layers.get_rnn_cell": [[138, 231], ["hparams[].todict", "range", "isinstance", "texar.hyperparams.HParams", "ValueError", "texar.utils.dtypes.is_str", "cells.append", "tensorflow.MultiRNNCell", "layers.default_rnn_cell_hparams", "len", "texar.utils.utils.get_instance", "isinstance", "ValueError", "texar.utils.mode.switch_dropout", "texar.utils.mode.switch_dropout", "texar.utils.mode.switch_dropout", "tensorflow.DropoutWrapper", "ValueError", "tensorflow.ResidualWrapper", "tensorflow.HighwayWrapper", "len"], "function", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.texar.hyperparams.HParams.todict", "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.dtypes.is_str", "home.repos.pwc.inspect_result.VegB_Text_Infilling.core.layers.default_rnn_cell_hparams", "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.utils.get_instance", "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.mode.switch_dropout", "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.mode.switch_dropout", "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.mode.switch_dropout"], ["", "def", "get_rnn_cell", "(", "hparams", "=", "None", ",", "mode", "=", "None", ")", ":", "\n", "    ", "\"\"\"Creates an RNN cell.\n\n    See :meth:`~texar.core.layers.default_rnn_cell_hparams` for all\n    hyperparameters and default values.\n\n    Args:\n        hparams (dict or HParams, optional): Cell hyperparameters. Missing\n            hyperparameters are set to default values. If\n            :attr:`hparams[\"type\"]` is a cell instance (rather\n            than the name or path to the cell class), then\n            :attr:`hparams[\"num_layers\"]` must be 1.\n        mode (optional): A Tensor taking value in\n            :tf_main:`tf.estimator.ModeKeys <estimator/ModeKeys>`, including\n            `TRAIN`, `EVAL`, and `PREDICT`. If `None`, dropout will be\n            controlled by :func:`texar.context.global_mode`.\n\n    Returns:\n        An instance of :tf_main:`RNNCell <contrib/rnn/RNNCell>`.\n\n    Raises:\n        ValueError: If :attr:`hparams[\"num_layers\"]` > 1 and\n            :attr:`hparams[\"type\"]` is not of type string.\n        ValueError: The cell is not an\n            :tf_main:`RNNCell <contrib/rnn/RNNCell>` instance.\n    \"\"\"", "\n", "if", "hparams", "is", "None", "or", "isinstance", "(", "hparams", ",", "dict", ")", ":", "\n", "        ", "hparams", "=", "HParams", "(", "hparams", ",", "default_rnn_cell_hparams", "(", ")", ")", "\n", "\n", "", "d_hp", "=", "hparams", "[", "\"dropout\"", "]", "\n", "if", "d_hp", "[", "\"variational_recurrent\"", "]", "and", "len", "(", "d_hp", "[", "\"input_size\"", "]", ")", "!=", "hparams", "[", "\"num_layers\"", "]", ":", "\n", "        ", "raise", "ValueError", "(", "\n", "\"If variational_recurrent=True, input_size must be a list of \"", "\n", "\"num_layers(%d) integers. Got len(input_size)=%d.\"", "%", "\n", "(", "hparams", "[", "\"num_layers\"", "]", ",", "len", "(", "d_hp", "[", "\"input_size\"", "]", ")", ")", ")", "\n", "\n", "", "cells", "=", "[", "]", "\n", "cell_kwargs", "=", "hparams", "[", "\"kwargs\"", "]", ".", "todict", "(", ")", "\n", "num_layers", "=", "hparams", "[", "\"num_layers\"", "]", "\n", "for", "layer_i", "in", "range", "(", "num_layers", ")", ":", "\n", "# Create the basic cell", "\n", "        ", "cell_type", "=", "hparams", "[", "\"type\"", "]", "\n", "if", "is_str", "(", "cell_type", ")", ":", "\n", "            ", "cell_modules", "=", "[", "'tensorflow.contrib.rnn'", ",", "'texar.custom'", "]", "\n", "cell", "=", "utils", ".", "get_instance", "(", "cell_type", ",", "cell_kwargs", ",", "cell_modules", ")", "\n", "", "else", ":", "\n", "            ", "if", "num_layers", ">", "1", ":", "\n", "                ", "raise", "ValueError", "(", "\n", "\"If `hparams['num_layers']`>1, then \"", "\n", "\"`hparams['type']` must be a string name or path \"", "\n", "\"to the class.\"", ")", "\n", "", "cell", "=", "cell_type", "\n", "", "if", "not", "isinstance", "(", "cell", ",", "rnn", ".", "RNNCell", ")", ":", "\n", "            ", "raise", "ValueError", "(", "\"cell must be an instance of RNNCell.\"", ")", "\n", "\n", "# Optionally add dropout", "\n", "", "if", "d_hp", "[", "\"input_keep_prob\"", "]", "<", "1.0", "or", "d_hp", "[", "\"output_keep_prob\"", "]", "<", "1.0", "or", "d_hp", "[", "\"state_keep_prob\"", "]", "<", "1.0", ":", "\n", "            ", "vr_kwargs", "=", "{", "}", "\n", "if", "d_hp", "[", "\"variational_recurrent\"", "]", ":", "\n", "                ", "vr_kwargs", "=", "{", "\"variational_recurrent\"", ":", "True", ",", "\n", "\"input_size\"", ":", "d_hp", "[", "\"input_size\"", "]", "[", "layer_i", "]", ",", "\n", "\"dtype\"", ":", "tf", ".", "float32", "}", "\n", "", "input_keep_prob", "=", "switch_dropout", "(", "d_hp", "[", "\"input_keep_prob\"", "]", ",", "\n", "mode", ")", "\n", "output_keep_prob", "=", "switch_dropout", "(", "d_hp", "[", "\"output_keep_prob\"", "]", ",", "\n", "mode", ")", "\n", "state_keep_prob", "=", "switch_dropout", "(", "d_hp", "[", "\"state_keep_prob\"", "]", ",", "\n", "mode", ")", "\n", "cell", "=", "rnn", ".", "DropoutWrapper", "(", "\n", "cell", "=", "cell", ",", "\n", "input_keep_prob", "=", "input_keep_prob", ",", "\n", "output_keep_prob", "=", "output_keep_prob", ",", "\n", "state_keep_prob", "=", "state_keep_prob", ",", "\n", "**", "vr_kwargs", ")", "\n", "\n", "# Optionally add residual and highway connections", "\n", "", "if", "layer_i", ">", "0", ":", "\n", "            ", "if", "hparams", "[", "\"residual\"", "]", ":", "\n", "                ", "cell", "=", "rnn", ".", "ResidualWrapper", "(", "cell", ")", "\n", "", "if", "hparams", "[", "\"highway\"", "]", ":", "\n", "                ", "cell", "=", "rnn", ".", "HighwayWrapper", "(", "cell", ")", "\n", "\n", "", "", "cells", ".", "append", "(", "cell", ")", "\n", "\n", "", "if", "hparams", "[", "\"num_layers\"", "]", ">", "1", ":", "\n", "        ", "cell", "=", "rnn", ".", "MultiRNNCell", "(", "cells", ")", "\n", "", "else", ":", "\n", "        ", "cell", "=", "cells", "[", "0", "]", "\n", "\n", "", "return", "cell", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.core.layers.get_rnn_cell_trainable_variables": [[232, 250], ["None"], "function", ["None"], ["", "def", "get_rnn_cell_trainable_variables", "(", "cell", ")", ":", "\n", "    ", "\"\"\"Returns the list of trainable variables of an RNN cell.\n\n    Args:\n        cell: an instance of :class:`tensorflow.contrib.rnn.RNNCell`.\n\n    Returns:\n        list: trainable variables of the cell.\n    \"\"\"", "\n", "cell_", "=", "cell", "\n", "while", "True", ":", "\n", "        ", "try", ":", "\n", "            ", "return", "cell_", ".", "trainable_variables", "\n", "", "except", "AttributeError", ":", "\n", "# Cell wrappers (e.g., `DropoutWrapper`) cannot directly access to", "\n", "# `trainable_variables` as they don't initialize superclass", "\n", "# (tf==v1.3). So try to access through the cell in the wrapper.", "\n", "            ", "cell_", "=", "cell", ".", "_cell", "# pylint: disable=protected-access", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.core.layers.default_regularizer_hparams": [[251, 273], ["None"], "function", ["None"], ["", "", "", "def", "default_regularizer_hparams", "(", ")", ":", "\n", "    ", "\"\"\"Returns the hyperparameters and their default values of a variable\n    regularizer:\n\n    .. code-block:: python\n\n        {\n            \"type\": \"L1L2\",\n            \"kwargs\": {\n                \"l1\": 0.,\n                \"l2\": 0.\n            }\n        }\n\n    The default value corresponds to :tf_main:`L1L2 <keras/regularizers/L1L2>`\n    and, with `(l1=0, l2=0)`, disables regularization.\n    \"\"\"", "\n", "return", "{", "\n", "\"type\"", ":", "\"L1L2\"", ",", "\n", "\"kwargs\"", ":", "{", "\n", "\"l1\"", ":", "0.", ",", "\n", "\"l2\"", ":", "0.", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.core.layers.get_regularizer": [[276, 313], ["isinstance", "texar.utils.dtypes.is_str", "texar.hyperparams.HParams", "texar.utils.utils.get_instance", "isinstance", "ValueError", "isinstance", "layers.default_regularizer_hparams", "texar.hyperparams.HParams.kwargs.todict"], "function", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.dtypes.is_str", "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.utils.get_instance", "home.repos.pwc.inspect_result.VegB_Text_Infilling.core.layers.default_regularizer_hparams", "home.repos.pwc.inspect_result.VegB_Text_Infilling.texar.hyperparams.HParams.todict"], ["", "def", "get_regularizer", "(", "hparams", "=", "None", ")", ":", "\n", "    ", "\"\"\"Returns a variable regularizer instance.\n\n    See :func:`~texar.core.layers.default_regularizer_hparams` for all\n    hyperparameters and default values.\n\n    Args:\n        hparams (dict or HParams, optional): Hyperparameters. Missing\n            hyperparameters are set to default values.\n\n    Returns:\n        A :tf_main:`Regularizer <keras/regularizers/Regularizer>` instance.\n        `None` if :attr:`hparams` is `None` or takes the default\n        hyperparameter value.\n\n    Raises:\n        ValueError: The resulting regularizer is not an instance of\n            :tf_main:`Regularizer <keras/regularizers/Regularizer>`.\n    \"\"\"", "\n", "if", "hparams", "is", "None", ":", "\n", "        ", "return", "None", "\n", "\n", "", "if", "isinstance", "(", "hparams", ",", "dict", ")", ":", "\n", "        ", "hparams", "=", "HParams", "(", "hparams", ",", "default_regularizer_hparams", "(", ")", ")", "\n", "", "if", "is_str", "(", "hparams", ".", "type", ")", ":", "\n", "        ", "rgl", "=", "utils", ".", "get_instance", "(", "\n", "hparams", ".", "type", ",", "hparams", ".", "kwargs", ".", "todict", "(", ")", ",", "\n", "[", "\"tensorflow.keras.regularizers\"", ",", "\"texar.custom\"", "]", ")", "\n", "", "else", ":", "\n", "        ", "rgl", "=", "hparams", ".", "type", "\n", "", "if", "not", "isinstance", "(", "rgl", ",", "tf", ".", "keras", ".", "regularizers", ".", "Regularizer", ")", ":", "\n", "        ", "raise", "ValueError", "(", "\"The regularizer must be an instance of \"", "\n", "\"tf.keras.regularizers.Regularizer.\"", ")", "\n", "", "if", "isinstance", "(", "rgl", ",", "tf", ".", "keras", ".", "regularizers", ".", "L1L2", ")", "and", "rgl", ".", "l1", "==", "0.", "and", "rgl", ".", "l2", "==", "0.", ":", "\n", "        ", "return", "None", "\n", "", "return", "rgl", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.core.layers.get_initializer": [[314, 341], ["texar.utils.dtypes.is_str", "isinstance", "kwargs.todict.todict", "texar.utils.utils.get_instance", "texar.utils.utils.get_function", "utils.get_function."], "function", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.dtypes.is_str", "home.repos.pwc.inspect_result.VegB_Text_Infilling.texar.hyperparams.HParams.todict", "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.utils.get_instance", "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.utils.get_function"], ["", "def", "get_initializer", "(", "hparams", "=", "None", ")", ":", "\n", "    ", "\"\"\"Returns an initializer instance.\n\n    Args:\n        hparams (dict or HParams, optional): Hyperparameters.\n\n    Returns:\n        An initializer instance. `None` if :attr:`hparams` is `None`.\n    \"\"\"", "\n", "if", "hparams", "is", "None", ":", "\n", "        ", "return", "None", "\n", "\n", "", "if", "is_str", "(", "hparams", "[", "\"type\"", "]", ")", ":", "\n", "        ", "kwargs", "=", "hparams", "[", "\"kwargs\"", "]", "\n", "if", "isinstance", "(", "kwargs", ",", "HParams", ")", ":", "\n", "            ", "kwargs", "=", "kwargs", ".", "todict", "(", ")", "\n", "", "modules", "=", "[", "\"tensorflow.initializers\"", ",", "\"tensorflow.keras.initializers\"", ",", "\n", "\"tensorflow\"", ",", "\"texar.custom\"", "]", "\n", "try", ":", "\n", "            ", "initializer", "=", "utils", ".", "get_instance", "(", "hparams", "[", "\"type\"", "]", ",", "kwargs", ",", "modules", ")", "\n", "", "except", "TypeError", ":", "\n", "            ", "modules", "+=", "[", "'tensorflow.contrib.layers'", "]", "\n", "initializer_fn", "=", "utils", ".", "get_function", "(", "hparams", "[", "\"type\"", "]", ",", "modules", ")", "\n", "initializer", "=", "initializer_fn", "(", "**", "kwargs", ")", "\n", "", "", "else", ":", "\n", "        ", "initializer", "=", "hparams", "[", "\"type\"", "]", "\n", "", "return", "initializer", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.core.layers.get_activation_fn": [[342, 388], ["texar.utils.utils.get_function", "isinstance", "kwargs.todict.todict", "utils.get_function."], "function", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.utils.get_function", "home.repos.pwc.inspect_result.VegB_Text_Infilling.texar.hyperparams.HParams.todict"], ["", "def", "get_activation_fn", "(", "fn_name", "=", "\"identity\"", ",", "kwargs", "=", "None", ")", ":", "\n", "    ", "\"\"\"Returns an activation function `fn` with the signature\n    `output = fn(input)`.\n\n    If the function specified by :attr:`fn_name` has more than one arguments\n    without default values, then all these arguments except the input feature\n    argument must be specified in :attr:`kwargs`. Arguments with default values\n    can also be specified in :attr:`kwargs` to take values other than the\n    defaults.\n\n    Args:\n        fn_name (str or callable): The name or full path to an activation\n            function, or the function itself.\n\n            The function can be:\n\n            - Built-in function defined in :mod:`tf` or \\\n              :mod:`tf.nn`, e.g., :tf_main:`identity <identity>`.\n            - User-defined activation functions in `texar.custom`.\n            - External activation functions. Must provide the full path, \\\n              e.g., \"my_module.my_activation_fn\".\n\n            If a callable is provided, then it is returned directly.\n\n        kwargs (optional): A `dict` or instance of :class:`~texar.HParams`\n            containing the keyword arguments of the activation function.\n\n    Returns:\n        The activation function. `None` if :attr:`fn_name` is `None`.\n    \"\"\"", "\n", "if", "fn_name", "is", "None", ":", "\n", "        ", "return", "None", "\n", "\n", "", "fn_modules", "=", "[", "'tensorflow'", ",", "'tensorflow.nn'", ",", "'texar.custom'", "]", "\n", "activation_fn_", "=", "utils", ".", "get_function", "(", "fn_name", ",", "fn_modules", ")", "\n", "activation_fn", "=", "activation_fn_", "\n", "\n", "# Make a partial function if necessary", "\n", "if", "kwargs", "is", "not", "None", ":", "\n", "        ", "if", "isinstance", "(", "kwargs", ",", "HParams", ")", ":", "\n", "            ", "kwargs", "=", "kwargs", ".", "todict", "(", ")", "\n", "", "def", "_partial_fn", "(", "features", ")", ":", "\n", "            ", "return", "activation_fn_", "(", "features", ",", "**", "kwargs", ")", "\n", "", "activation_fn", "=", "_partial_fn", "\n", "\n", "", "return", "activation_fn", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.core.layers.get_constraint_fn": [[390, 420], ["texar.utils.utils.get_function"], "function", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.utils.get_function"], ["", "def", "get_constraint_fn", "(", "fn_name", "=", "\"NonNeg\"", ")", ":", "\n", "    ", "\"\"\"Returns a constraint function based on its name or full path.\n\n    Args:\n        fn_name (str or callable): The name or full path to a\n            constraint function, or the function itself.\n\n            The function can be:\n\n            - Built-in constraint functions defined in \\\n            :tf_main:`tf.keras.constraints <keras/constraints>` \\\n            (e.g., :tf_main:`NonNeg <keras/constraints/NonNeg>`) \\\n            or :mod:`tf` or :mod:`tf.nn` (e.g., activation functions).\n            - User-defined function in :mod:`texar.custom`. The function \\\n            must follow the signature `w' = constraint_fn(w)`.\n            - Externally defined function. Must provide the full path, \\\n            e.g., :attr:`\"my_module.my_constraint_fn\"`.\n\n            If a callable is provided, then it is returned directly.\n\n    Returns:\n        The constraint function. `None` if :attr:`fn_name` is `None`.\n    \"\"\"", "\n", "if", "fn_name", "is", "None", ":", "\n", "        ", "return", "None", "\n", "\n", "", "fn_modules", "=", "[", "'tensorflow.keras.constraints'", ",", "'tensorflow'", ",", "\n", "'tensorflow.nn'", ",", "'texar.custom'", "]", "\n", "constraint_fn", "=", "utils", ".", "get_function", "(", "fn_name", ",", "fn_modules", ")", "\n", "return", "constraint_fn", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.core.layers.get_layer": [[423, 514], ["ValueError", "texar.utils.dtypes.is_str", "texar.utils.utils.get_class", "isinstance", "texar.hyperparams.HParams.kwargs.items", "texar.utils.utils.get_instance", "isinstance", "ValueError", "_layer_class_to_default_kwargs_map.get", "texar.hyperparams.HParams", "k.endswith", "layers.get_regularizer", "k.endswith", "layers.get_initializer", "k.endswith", "layers.get_activation_fn", "k.endswith", "layers.get_constraint_fn"], "function", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.dtypes.is_str", "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.utils.get_class", "home.repos.pwc.inspect_result.VegB_Text_Infilling.texar.hyperparams.HParams.items", "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.utils.get_instance", "home.repos.pwc.inspect_result.VegB_Text_Infilling.core.replay_memories.DequeReplayMemory.get", "home.repos.pwc.inspect_result.VegB_Text_Infilling.core.layers.get_regularizer", "home.repos.pwc.inspect_result.VegB_Text_Infilling.core.layers.get_initializer", "home.repos.pwc.inspect_result.VegB_Text_Infilling.core.layers.get_activation_fn", "home.repos.pwc.inspect_result.VegB_Text_Infilling.core.layers.get_constraint_fn"], ["", "def", "get_layer", "(", "hparams", ")", ":", "\n", "    ", "\"\"\"Makes a layer instance.\n\n    The layer must be an instance of :tf_main:`Layer <layers/Layer>`.\n\n    Args:\n        hparams (dict or HParams): Hyperparameters of the layer, with\n            structure:\n\n            .. code-block:: python\n\n                {\n                    \"type\": \"LayerClass\",\n                    \"kwargs\": {\n                        # Keyword arguments of the layer class\n                        # ...\n                    }\n                }\n\n            Here:\n\n            \"type\" : str or layer instance\n                Name, full path, or instance of the layer class. The\n                class can be\n\n                - Built-in layer defined in \\\n                  :tf_main:`tf.layers <layers>` (e.g., \\\n                  :tf_main:`tf.layers.Conv2D <layers/Conv2D>`), or \\\n                  :mod:`tx.core <texar.core>` (e.g., \\\n                  :class:`tx.core.MergeLayer <texar.core.MergeLayer>`)\n                - User-defined layer class in :mod:`tx.custom <texar.custom>`.\\\n                  The class must inherit :tf_main:`Layer <layers/Layer>`.\n                - External layer. If str, must provide the full path, \\\n                  e.g., :attr:`\"my_module.MyInitializer\"`.\n\n            \"kwargs\" : dict\n                A dictionary of arguments for constructor of the\n                layer class. Ignored if :attr:`\"type\"` is a layer instance.\n\n                - Arguments named \"activation\" can be a callable, \\\n                or a `str` of \\\n                the name or full path to the activation function. \\\n                - Arguments named \"*_regularizer\" and \"*_initializer\" \\\n                can be a class instance, or a `dict` of \\\n                hyperparameters of \\\n                respective regularizers and initializers.\n                - Arguments named \"*_constraint\" can be a callable, or a `str` \\\n                of the name or full path to the constraint function. \\\n\n    Returns:\n        A layer instance. If :attr:`hparams[\"type\"]` is already a layer\n        instance, returns it directly.\n\n    Raises:\n        ValueError: If :attr:`hparams` is `None`.\n        ValueError: If the resulting layer is not an instance of\n            :tf_main:`Layer <layers/Layer>`.\n    \"\"\"", "\n", "if", "hparams", "is", "None", ":", "\n", "        ", "raise", "ValueError", "(", "\"`hparams` must not be `None`.\"", ")", "\n", "\n", "", "layer_type", "=", "hparams", "[", "\"type\"", "]", "\n", "if", "not", "is_str", "(", "layer_type", ")", ":", "\n", "        ", "layer", "=", "layer_type", "\n", "", "else", ":", "\n", "        ", "layer_modules", "=", "[", "\"tensorflow.layers\"", ",", "\"texar.core\"", ",", "\"texar.costum\"", "]", "\n", "layer_class", "=", "utils", ".", "get_class", "(", "layer_type", ",", "layer_modules", ")", "\n", "if", "isinstance", "(", "hparams", ",", "dict", ")", ":", "\n", "            ", "default_kwargs", "=", "_layer_class_to_default_kwargs_map", ".", "get", "(", "layer_class", ",", "\n", "{", "}", ")", "\n", "default_hparams", "=", "{", "\"type\"", ":", "layer_type", ",", "\"kwargs\"", ":", "default_kwargs", "}", "\n", "hparams", "=", "HParams", "(", "hparams", ",", "default_hparams", ")", "\n", "\n", "", "kwargs", "=", "{", "}", "\n", "for", "k", ",", "v", "in", "hparams", ".", "kwargs", ".", "items", "(", ")", ":", "\n", "            ", "if", "k", ".", "endswith", "(", "'_regularizer'", ")", ":", "\n", "                ", "kwargs", "[", "k", "]", "=", "get_regularizer", "(", "v", ")", "\n", "", "elif", "k", ".", "endswith", "(", "'_initializer'", ")", ":", "\n", "                ", "kwargs", "[", "k", "]", "=", "get_initializer", "(", "v", ")", "\n", "", "elif", "k", ".", "endswith", "(", "'activation'", ")", ":", "\n", "                ", "kwargs", "[", "k", "]", "=", "get_activation_fn", "(", "v", ")", "\n", "", "elif", "k", ".", "endswith", "(", "'_constraint'", ")", ":", "\n", "                ", "kwargs", "[", "k", "]", "=", "get_constraint_fn", "(", "v", ")", "\n", "", "else", ":", "\n", "                ", "kwargs", "[", "k", "]", "=", "v", "\n", "", "", "layer", "=", "utils", ".", "get_instance", "(", "layer_type", ",", "kwargs", ",", "layer_modules", ")", "\n", "\n", "", "if", "not", "isinstance", "(", "layer", ",", "tf", ".", "layers", ".", "Layer", ")", ":", "\n", "        ", "raise", "ValueError", "(", "\"layer must be an instance of `tf.layers.Layer`.\"", ")", "\n", "\n", "", "return", "layer", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.core.layers._compute_concat_output_shape": [[516, 540], ["tensorflow.TensorShape().as_list", "next", "any", "sum", "zip", "tensorflow.TensorShape"], "function", ["None"], ["", "def", "_compute_concat_output_shape", "(", "input_shape", ",", "axis", ")", ":", "\n", "    ", "\"\"\"Infers the output shape of concat given the input shape.\n\n    The code is adapted from the ConcatLayer of lasagne\n    (https://github.com/Lasagne/Lasagne/blob/master/lasagne/layers/merge.py)\n\n    Args:\n        input_shape (list): A list of shapes, each of which is in turn a\n            list or TensorShape.\n        axis (int): Axis of the concat operation.\n\n    Returns:\n        list: Output shape of concat.\n    \"\"\"", "\n", "# The size of each axis of the output shape equals the first", "\n", "# input size of respective axis that is not `None`", "\n", "input_shape", "=", "[", "tf", ".", "TensorShape", "(", "s", ")", ".", "as_list", "(", ")", "for", "s", "in", "input_shape", "]", "\n", "output_shape", "=", "[", "next", "(", "(", "s", "for", "s", "in", "sizes", "if", "s", "is", "not", "None", ")", ",", "None", ")", "\n", "for", "sizes", "in", "zip", "(", "*", "input_shape", ")", "]", "\n", "axis_sizes", "=", "[", "s", "[", "axis", "]", "for", "s", "in", "input_shape", "]", "\n", "concat_axis_size", "=", "None", "if", "any", "(", "s", "is", "None", "for", "s", "in", "axis_sizes", ")", "else", "sum", "(", "axis_sizes", ")", "\n", "output_shape", "[", "axis", "]", "=", "concat_axis_size", "\n", "return", "output_shape", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.core.layers.get_pooling_layer_hparams": [[600, 620], ["isinstance", "copy.copy", "copy.copy.get", "hparams.todict.todict", "_POOLING_TO_REDUCE.get", "new_hparams.get.pop", "new_hparams.get.pop", "new_hparams.get.pop", "new_hparams.get.get"], "function", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.core.replay_memories.DequeReplayMemory.get", "home.repos.pwc.inspect_result.VegB_Text_Infilling.texar.hyperparams.HParams.todict", "home.repos.pwc.inspect_result.VegB_Text_Infilling.core.replay_memories.DequeReplayMemory.get", "home.repos.pwc.inspect_result.VegB_Text_Infilling.core.replay_memories.DequeReplayMemory.get"], ["def", "get_pooling_layer_hparams", "(", "hparams", ")", ":", "\n", "    ", "\"\"\"Creates pooling layer hparams dict usable for :func:`get_layer`.\n\n    If the :attr:`hparams` sets `'pool_size'` to `None`, the layer will be\n    changed to the respective reduce-pooling layer.\n    \"\"\"", "\n", "if", "isinstance", "(", "hparams", ",", "HParams", ")", ":", "\n", "        ", "hparams", "=", "hparams", ".", "todict", "(", ")", "\n", "\n", "", "new_hparams", "=", "copy", ".", "copy", "(", "hparams", ")", "\n", "kwargs", "=", "new_hparams", ".", "get", "(", "'kwargs'", ",", "None", ")", "\n", "\n", "if", "kwargs", "and", "kwargs", ".", "get", "(", "'pool_size'", ",", "None", ")", "is", "None", ":", "\n", "        ", "pool_type", "=", "hparams", "[", "'type'", "]", "\n", "new_hparams", "[", "'type'", "]", "=", "_POOLING_TO_REDUCE", ".", "get", "(", "pool_type", ",", "pool_type", ")", "\n", "kwargs", ".", "pop", "(", "'pool_size'", ",", "None", ")", "\n", "kwargs", ".", "pop", "(", "'strides'", ",", "None", ")", "\n", "kwargs", ".", "pop", "(", "'padding'", ",", "None", ")", "\n", "\n", "", "return", "new_hparams", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.core.layers._common_default_conv_dense_kwargs": [[881, 903], ["layers.default_regularizer_hparams", "layers.default_regularizer_hparams", "layers.default_regularizer_hparams"], "function", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.core.layers.default_regularizer_hparams", "home.repos.pwc.inspect_result.VegB_Text_Infilling.core.layers.default_regularizer_hparams", "home.repos.pwc.inspect_result.VegB_Text_Infilling.core.layers.default_regularizer_hparams"], ["", "", "def", "_common_default_conv_dense_kwargs", "(", ")", ":", "\n", "    ", "\"\"\"Returns the default keyword argument values that are common to\n    convolution layers.\n    \"\"\"", "\n", "return", "{", "\n", "\"activation\"", ":", "None", ",", "\n", "\"use_bias\"", ":", "True", ",", "\n", "\"kernel_initializer\"", ":", "{", "\n", "\"type\"", ":", "\"glorot_uniform_initializer\"", ",", "\n", "\"kwargs\"", ":", "{", "}", "\n", "}", ",", "\n", "\"bias_initializer\"", ":", "{", "\n", "\"type\"", ":", "\"zeros_initializer\"", ",", "\n", "\"kwargs\"", ":", "{", "}", "\n", "}", ",", "\n", "\"kernel_regularizer\"", ":", "default_regularizer_hparams", "(", ")", ",", "\n", "\"bias_regularizer\"", ":", "default_regularizer_hparams", "(", ")", ",", "\n", "\"activity_regularizer\"", ":", "default_regularizer_hparams", "(", ")", ",", "\n", "\"kernel_constraint\"", ":", "None", ",", "\n", "\"bias_constraint\"", ":", "None", ",", "\n", "\"trainable\"", ":", "True", ",", "\n", "\"name\"", ":", "None", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.core.layers.default_conv1d_kwargs": [[906, 1066], ["layers._common_default_conv_dense_kwargs", "_common_default_conv_dense_kwargs.update"], "function", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.core.layers._common_default_conv_dense_kwargs"], ["", "def", "default_conv1d_kwargs", "(", ")", ":", "\n", "    ", "\"\"\"Returns the default keyword argument values of 1D convolution layer\n    defined in :tf_main:`tf.layers.Conv1D <layers/Conv1D>`.\n\n    Returns:\n        .. code-block:: python\n\n            {\n                \"filters\": 100,\n                \"kernel_size\": 3,\n                \"strides\": 1,\n                \"padding\": 'valid',\n                \"data_format\": 'channels_last',\n                \"dilation_rate\": 1\n                \"activation\": \"identity\",\n                \"use_bias\": True,\n                \"kernel_initializer\": {\n                    \"type\": \"glorot_uniform_initializer\",\n                    \"kwargs\": {}\n                },\n                \"bias_initializer\": {\n                    \"type\": \"zeros_initializer\",\n                    \"kwargs\": {}\n                },\n                \"kernel_regularizer\": {\n                    \"type\": \"L1L2\",\n                    \"kwargs\": {\n                        \"l1\": 0.,\n                        \"l2\": 0.\n                    }\n                },\n                \"bias_regularizer\": {\n                    # same as in \"kernel_regularizer\"\n                    # ...\n                },\n                \"activity_regularizer\": {\n                    # same as in \"kernel_regularizer\"\n                    # ...\n                },\n                \"kernel_constraint\": None,\n                \"bias_constraint\": None,\n                \"trainable\": True,\n                \"name\": None\n            }\n\n        Here:\n\n        \"filters\" : int\n            The number of filters in the convolution.\n\n            The default value is `100`.\n\n        \"kernel_size\" : int\n            The length of 1D convolution window.\n\n            The default value is `3`.\n\n        \"strides\" : int\n            The stride length of the convolution.\n\n            The default value is `1`.\n\n        \"padding\" : str\n            One of `\"valid\"` or `\"same\"` (case-insensitive).\n\n            The default value is `\"valid\"`.\n\n        \"data_format\" : str\n            The ordering of the dimensions in the inputs. One of\n            `\"channels_last\"` or `\"channels_first\"`.\n            `\"channels_last\"` corresponds to inputs with shape\n            `(batch, length, channels)`; `\"channels_first\"` corresponds to\n            inputs with shape `(batch, channels, length)`.\n\n            The default value is `\"channels_last\"`.\n\n        \"dilation_rate\" : int\n            The dilation rate to use for dilated convolution.\n\n            The default value is `1`.\n\n        \"activation\" : str\n            The name or full path to the activation function applied to the\n            outputs of the layer.\n\n            The default value is \"identity\", which corr. to\n            :tf_main:`tf.identity <identity>`.\n\n        \"kernel_initializer\" : dict\n            Hyperparameters of the initializer for the filters, including\n            :attr:`\"type\"` (str or object) and :attr:`\"kwargs\"` (dict).\n\n            The default corr. to :tf_main:`tf.glorot_uniform_initializer\n            <glorot_uniform_initializer>`.\n\n        \"bias_initializer\" : dict\n            Hyperparameters of the initializer for the bias, including\n            :attr:`\"type\"` (str or object) and :attr:`\"kwargs\"` (dict).\n\n            The default corr. to\n            :tf_main:`tf.zeros_initializer <zeros_initializer>`.\n\n        \"kernel_regularizer\" : dict\n            Optional hyperparameters of the regularizer for the convolution\n            filters, including :attr:`\"type\"` (str or object) and\n            :attr:`\"kwargs\"` (dict).\n\n            The default value disables regularization.\n\n        \"bias_regularizer\" : dict\n            Optional hyperparameters of the regularizer for the bias,\n            including :attr:`\"type\"` (str or object) and\n            :attr:`\"kwargs\"` (dict).\n\n            The default value disables regularization.\n\n        \"activity_regularizer\" : dict\n            Optional hyperparameters of the regularizer for the layer output,\n            including :attr:`\"type\"` (str or object) and\n            :attr:`\"kwargs\"` (dict).\n\n            The default value disables regularization.\n\n        \"kernel_constraint\" : str\n            Optional name or full path to projection function to be applied to\n            the kernel after being updated by an `Optimizer`. Used to\n            implement norm constraints\n            or value constraints for layer weights. The function must take\n            as input the unprojected variable and return the projected variable\n            with the same shape. Constraints are not safe to use when doing\n            asynchronous distributed training.\n\n            The function can be:\n\n            - Built-in constraint functions defined in \\\n            :tf_main:`tf.keras.constraints <keras/constraints>` \\\n            (e.g., :tf_main:`NonNeg <keras/constraints/NonNeg>`) \\\n            or :mod:`tf` or :mod:`tf.nn` (e.g., activation functions).\n            - User-defined function in :mod:`texar.custom`. The function \\\n            must follow the signature `w' = constraint_fn(w)`.\n            - Externally defined function. Must provide the full path, \\\n            e.g., :attr:`\"my_module.my_function\"`.\n\n            The default value is `None`.\n\n        \"bias_constraint\" : str\n            Optional name or full path to projection function to be applied to\n            the bias after being updated by an `Optimizer`.\n\n            The default value is `None`.\n    \"\"\"", "\n", "kwargs", "=", "_common_default_conv_dense_kwargs", "(", ")", "\n", "kwargs", ".", "update", "(", "{", "\n", "\"kernel_size\"", ":", "3", ",", "\n", "\"filters\"", ":", "100", ",", "\n", "\"strides\"", ":", "1", ",", "\n", "\"dilation_rate\"", ":", "1", ",", "\n", "\"data_format\"", ":", "\"channels_last\"", "\n", "}", ")", "\n", "return", "kwargs", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.core.layers.default_conv2d_kwargs": [[1067, 1071], ["None"], "function", ["None"], ["", "def", "default_conv2d_kwargs", "(", ")", ":", "\n", "    ", "\"\"\"TODO\n    \"\"\"", "\n", "return", "{", "}", "\n", "", "def", "default_conv3d_kwargs", "(", ")", ":", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.core.layers.default_conv3d_kwargs": [[1071, 1075], ["None"], "function", ["None"], ["", "def", "default_conv3d_kwargs", "(", ")", ":", "\n", "    ", "\"\"\"TODO\n    \"\"\"", "\n", "return", "{", "}", "\n", "", "def", "default_conv2d_transpose_kwargs", "(", ")", ":", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.core.layers.default_conv2d_transpose_kwargs": [[1075, 1079], ["None"], "function", ["None"], ["", "def", "default_conv2d_transpose_kwargs", "(", ")", ":", "\n", "    ", "\"\"\"TODO\n    \"\"\"", "\n", "return", "{", "}", "\n", "", "def", "default_conv3d_transpose_kwargs", "(", ")", ":", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.core.layers.default_conv3d_transpose_kwargs": [[1079, 1083], ["None"], "function", ["None"], ["", "def", "default_conv3d_transpose_kwargs", "(", ")", ":", "\n", "    ", "\"\"\"TODO\n    \"\"\"", "\n", "return", "{", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.core.layers.default_dense_kwargs": [[1084, 1093], ["layers._common_default_conv_dense_kwargs", "_common_default_conv_dense_kwargs.update"], "function", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.core.layers._common_default_conv_dense_kwargs"], ["", "def", "default_dense_kwargs", "(", ")", ":", "\n", "    ", "\"\"\"Returns the default keyword argument values of dense layer\n    defined in :tf_main:`tf.layers.Dense <layers/Dense>`.\n    \"\"\"", "\n", "kwargs", "=", "_common_default_conv_dense_kwargs", "(", ")", "\n", "kwargs", ".", "update", "(", "{", "\n", "\"units\"", ":", "256", "\n", "}", ")", "\n", "return", "kwargs", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.core.layers.default_dropout_kwargs": [[1094, 1098], ["None"], "function", ["None"], ["", "def", "default_dropout_kwargs", "(", ")", ":", "\n", "    ", "\"\"\"TODO\n    \"\"\"", "\n", "return", "{", "}", "\n", "#raise NotImplementedError", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.core.layers.default_flatten_kwargs": [[1099, 1103], ["None"], "function", ["None"], ["", "def", "default_flatten_kwargs", "(", ")", ":", "\n", "    ", "\"\"\"TODO\n    \"\"\"", "\n", "return", "{", "}", "\n", "", "def", "default_max_pooling1d_kwargs", "(", ")", ":", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.core.layers.default_max_pooling1d_kwargs": [[1103, 1107], ["None"], "function", ["None"], ["", "def", "default_max_pooling1d_kwargs", "(", ")", ":", "\n", "    ", "\"\"\"TODO\n    \"\"\"", "\n", "return", "{", "}", "\n", "#raise NotImplementedError", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.core.layers.default_max_pooling2d_kwargs": [[1108, 1112], ["None"], "function", ["None"], ["", "def", "default_max_pooling2d_kwargs", "(", ")", ":", "\n", "    ", "\"\"\"TODO\n    \"\"\"", "\n", "return", "{", "}", "\n", "#raise NotImplementedError", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.core.layers.default_max_pooling3d_kwargs": [[1113, 1117], ["None"], "function", ["None"], ["", "def", "default_max_pooling3d_kwargs", "(", ")", ":", "\n", "    ", "\"\"\"TODO\n    \"\"\"", "\n", "return", "{", "}", "\n", "#raise NotImplementedError", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.core.layers.default_separable_conv2d_kwargs": [[1118, 1122], ["None"], "function", ["None"], ["", "def", "default_separable_conv2d_kwargs", "(", ")", ":", "\n", "    ", "\"\"\"TODO\n    \"\"\"", "\n", "return", "{", "}", "\n", "#raise NotImplementedError", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.core.layers.default_batch_normalization_kwargs": [[1123, 1127], ["None"], "function", ["None"], ["", "def", "default_batch_normalization_kwargs", "(", ")", ":", "\n", "    ", "\"\"\"TODO\n    \"\"\"", "\n", "return", "{", "}", "\n", "#raise NotImplementedError", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.core.layers.default_average_pooling1d_kwargs": [[1128, 1132], ["None"], "function", ["None"], ["", "def", "default_average_pooling1d_kwargs", "(", ")", ":", "\n", "    ", "\"\"\"TODO\n    \"\"\"", "\n", "return", "{", "}", "\n", "#raise NotImplementedError", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.core.layers.default_average_pooling2d_kwargs": [[1133, 1137], ["None"], "function", ["None"], ["", "def", "default_average_pooling2d_kwargs", "(", ")", ":", "\n", "    ", "\"\"\"TODO\n    \"\"\"", "\n", "return", "{", "}", "\n", "#raise NotImplementedError", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.core.layers.default_average_pooling3d_kwargs": [[1138, 1142], ["None"], "function", ["None"], ["", "def", "default_average_pooling3d_kwargs", "(", ")", ":", "\n", "    ", "\"\"\"TODO\n    \"\"\"", "\n", "return", "{", "}", "\n", "#raise NotImplementedError", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.core.layers.multihead_attention": [[1162, 1243], ["tensorflow.variable_scope", "layers.split_heads", "layers.split_heads", "layers.split_heads", "tensorflow.matmul", "tensorflow.nn.softmax", "tensorflow.layers.dropout", "tensorflow.matmul", "layers.combine_heads", "tensorflow.layers.dense", "ValueError", "tensorflow.layers.dense", "tensorflow.layers.dense", "tensorflow.layers.dense", "tensorflow.layers.dense", "queries.get_shape().as_list", "tensorflow.concat", "tensorflow.concat", "tensorflow.cond", "texar.context.global_mode_train", "tensorflow.equal", "tensorflow.layers.dense", "tensorflow.layers.dense", "queries.get_shape", "tensorflow.shape", "tensorflow.layers.dense", "tensorflow.layers.dense"], "function", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.agents.agent_base.AgentBase.variable_scope", "home.repos.pwc.inspect_result.VegB_Text_Infilling.core.layers.split_heads", "home.repos.pwc.inspect_result.VegB_Text_Infilling.core.layers.split_heads", "home.repos.pwc.inspect_result.VegB_Text_Infilling.core.layers.split_heads", "home.repos.pwc.inspect_result.VegB_Text_Infilling.core.layers.combine_heads", "home.repos.pwc.inspect_result.VegB_Text_Infilling.texar.context.global_mode_train"], ["def", "multihead_attention", "(", "queries", ",", "\n", "memory_attention_bias", "=", "None", ",", "\n", "memory", "=", "None", ",", "\n", "num_heads", "=", "8", ",", "\n", "num_units", "=", "None", ",", "\n", "dropout_rate", "=", "0", ",", "\n", "cache", "=", "None", ",", "\n", "scope", "=", "'multihead_attention'", ")", ":", "\n", "    ", "'''Applies multihead attention.\n\n    Args:\n      queries: A 3d tensor with shape of [batch, length_query, depth_query].\n      keys: A 3d tensor with shape of [batch, length_key, depth_key].\n      num_units: A scalar indicating the attention size,\n        equals to depth_query if not given.\n      dropout_rate: A floating point number.\n      num_heads: An int. Number of heads with calculating attention.\n      scope: Optional scope for `variable_scope`.\n      reuse: Boolean, whether to reuse the weights of a previous layer\n        by the same name.\n    Returns\n      A 3d tensor with shape of (batch, length_query, num_units)\n    '''", "\n", "#pylint: disable=too-many-locals", "\n", "with", "tf", ".", "variable_scope", "(", "scope", ")", ":", "\n", "        ", "if", "num_units", "is", "None", ":", "\n", "            ", "num_units", "=", "queries", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", "[", "-", "1", "]", "\n", "", "if", "num_units", "%", "num_heads", "!=", "0", ":", "\n", "            ", "raise", "ValueError", "(", "\"Value depth (%d) must be divisible by the number\"", "\n", "\"of attention heads (%d).\"", "%", "(", "num_units", ",", "num_heads", ")", ")", "\n", "", "if", "memory", "is", "None", ":", "\n", "#'self attention'", "\n", "            ", "Q", "=", "tf", ".", "layers", ".", "dense", "(", "queries", ",", "num_units", ",", "use_bias", "=", "False", ",", "name", "=", "'q'", ")", "\n", "K", "=", "tf", ".", "layers", ".", "dense", "(", "queries", ",", "num_units", ",", "use_bias", "=", "False", ",", "name", "=", "'k'", ")", "\n", "V", "=", "tf", ".", "layers", ".", "dense", "(", "queries", ",", "num_units", ",", "use_bias", "=", "False", ",", "name", "=", "'v'", ")", "\n", "if", "cache", "is", "not", "None", ":", "\n", "# 'decoder self attention when dynamic decoding'", "\n", "                ", "K", "=", "tf", ".", "concat", "(", "[", "cache", "[", "'self_keys'", "]", ",", "K", "]", ",", "axis", "=", "1", ")", "\n", "V", "=", "tf", ".", "concat", "(", "[", "cache", "[", "'self_values'", "]", ",", "V", "]", ",", "axis", "=", "1", ")", "\n", "cache", "[", "'self_keys'", "]", "=", "K", "\n", "cache", "[", "'self_values'", "]", "=", "V", "\n", "", "", "else", ":", "\n", "# 'encoder decoder attention'", "\n", "            ", "Q", "=", "tf", ".", "layers", ".", "dense", "(", "queries", ",", "num_units", ",", "use_bias", "=", "False", ",", "name", "=", "'q'", ")", "\n", "if", "cache", "is", "not", "None", ":", "\n", "                ", "K", ",", "V", "=", "tf", ".", "cond", "(", "\n", "tf", ".", "equal", "(", "tf", ".", "shape", "(", "cache", "[", "\"memory_keys\"", "]", ")", "[", "1", "]", ",", "0", ")", ",", "\n", "true_fn", "=", "lambda", ":", "[", "tf", ".", "layers", ".", "dense", "(", "memory", ",", "num_units", ",", "use_bias", "=", "False", ",", "name", "=", "'k'", ")", ",", "tf", ".", "layers", ".", "dense", "(", "memory", ",", "num_units", ",", "use_bias", "=", "False", ",", "name", "=", "'v'", ")", "]", ",", "\n", "false_fn", "=", "lambda", ":", "[", "cache", "[", "\"memory_keys\"", "]", ",", "cache", "[", "\"memory_values\"", "]", "]", ")", "\n", "", "else", ":", "\n", "                ", "K", ",", "V", "=", "[", "tf", ".", "layers", ".", "dense", "(", "memory", ",", "num_units", ",", "use_bias", "=", "False", ",", "name", "=", "'k'", ")", ",", "\n", "tf", ".", "layers", ".", "dense", "(", "memory", ",", "num_units", ",", "use_bias", "=", "False", ",", "name", "=", "'v'", ")", "]", "\n", "\n", "", "", "Q_", "=", "split_heads", "(", "Q", ",", "num_heads", ")", "\n", "K_", "=", "split_heads", "(", "K", ",", "num_heads", ")", "\n", "V_", "=", "split_heads", "(", "V", ",", "num_heads", ")", "\n", "#[batch_size, num_heads, seq_length, memory_depth]", "\n", "key_depth_per_head", "=", "num_units", "//", "num_heads", "\n", "Q_", "*=", "key_depth_per_head", "**", "-", "0.5", "\n", "\n", "logits", "=", "tf", ".", "matmul", "(", "Q_", ",", "K_", ",", "transpose_b", "=", "True", ")", "\n", "if", "memory_attention_bias", "is", "not", "None", ":", "\n", "            ", "logits", "+=", "memory_attention_bias", "\n", "", "weights", "=", "tf", ".", "nn", ".", "softmax", "(", "logits", ",", "name", "=", "\"attention_weights\"", ")", "\n", "weights", "=", "tf", ".", "layers", ".", "dropout", "(", "weights", ",", "rate", "=", "dropout_rate", ",", "training", "=", "context", ".", "global_mode_train", "(", ")", ")", "\n", "outputs", "=", "tf", ".", "matmul", "(", "weights", ",", "V_", ")", "\n", "\n", "outputs", "=", "combine_heads", "(", "outputs", ")", "\n", "outputs", "=", "tf", ".", "layers", ".", "dense", "(", "outputs", ",", "num_units", ",", "use_bias", "=", "False", ",", "name", "=", "'output_transform'", ")", "\n", "#(batch_size, length_query, attention_depth)", "\n", "", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.core.layers.layer_normalize": [[1244, 1270], ["tensorflow.variable_scope", "tensorflow.nn.moments", "tensorflow.get_variable", "tensorflow.get_variable", "inputs.get_shape", "tensorflow.rsqrt", "tensorflow.ones_initializer", "tensorflow.zeros_initializer"], "function", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.agents.agent_base.AgentBase.variable_scope"], ["", "def", "layer_normalize", "(", "inputs", ",", "\n", "epsilon", "=", "1e-8", ",", "\n", "scope", "=", "'ln'", ",", "\n", "reuse", "=", "None", ")", ":", "\n", "    ", "'''Applies layer normalization. averaging over the last dimension\n    Args:\n        inputs: A tensor with 2 or more dimensions, where the first\n            dimension has `batch_size`.\n        epsilon: A floating number. A very small number for preventing\n            ZeroDivision Error.\n        scope: Optional scope for `variable_scope`.\n        reuse: Boolean, whether to reuse the weights of a previous layer\n            by the same name.\n    Returns:\n        A tensor with the same shape and data dtype as `inputs`.\n    '''", "\n", "with", "tf", ".", "variable_scope", "(", "scope", ",", "reuse", "=", "reuse", ")", ":", "\n", "        ", "filters", "=", "inputs", ".", "get_shape", "(", ")", "[", "-", "1", "]", "\n", "mean", ",", "variance", "=", "tf", ".", "nn", ".", "moments", "(", "inputs", ",", "[", "-", "1", "]", ",", "keep_dims", "=", "True", ")", "\n", "scale", "=", "tf", ".", "get_variable", "(", "'layer_norm_scale'", ",", "[", "filters", "]", ",", "initializer", "=", "tf", ".", "ones_initializer", "(", ")", ")", "\n", "bias", "=", "tf", ".", "get_variable", "(", "'layer_norm_bias'", ",", "[", "filters", "]", ",", "initializer", "=", "tf", ".", "zeros_initializer", "(", ")", ")", "\n", "norm_x", "=", "(", "inputs", "-", "mean", ")", "*", "tf", ".", "rsqrt", "(", "variance", "+", "epsilon", ")", "\n", "outputs", "=", "norm_x", "*", "scale", "+", "bias", "\n", "", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.core.layers.split_heads": [[1272, 1280], ["tensorflow.reshape", "tensorflow.transpose", "x.get_shape", "tensorflow.shape", "tensorflow.shape"], "function", ["None"], ["", "def", "split_heads", "(", "x", ",", "num_heads", ")", ":", "\n", "    ", "\"\"\"Split channels (dimension 2) into multiple heads, becomes dimension 1).\n        must ensure x.shape[-1] can be deviced by num_heads.any\n    \"\"\"", "\n", "depth", "=", "x", ".", "get_shape", "(", ")", "[", "-", "1", "]", "\n", "splitted_x", "=", "tf", ".", "reshape", "(", "x", ",", "[", "tf", ".", "shape", "(", "x", ")", "[", "0", "]", ",", "tf", ".", "shape", "(", "x", ")", "[", "1", "]", ",", "num_heads", ",", "depth", "//", "num_heads", "]", ")", "\n", "return", "tf", ".", "transpose", "(", "splitted_x", ",", "[", "0", ",", "2", ",", "1", ",", "3", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.core.layers.combine_heads": [[1281, 1289], ["tensorflow.transpose", "tensorflow.reshape", "tf.transpose.get_shape", "tensorflow.shape", "tensorflow.shape"], "function", ["None"], ["", "def", "combine_heads", "(", "x", ")", ":", "\n", "    ", "\"\"\"\n    input: [batch, num_heads, seq_len, dim]\n    output:[batch, seq_len, num_heads*dim]\n    \"\"\"", "\n", "t", "=", "tf", ".", "transpose", "(", "x", ",", "[", "0", ",", "2", ",", "1", ",", "3", "]", ")", "#[batch, seq_len, num_heads, dim]", "\n", "num_heads", ",", "dim", "=", "t", ".", "get_shape", "(", ")", "[", "-", "2", ":", "]", "\n", "return", "tf", ".", "reshape", "(", "t", ",", "[", "tf", ".", "shape", "(", "t", ")", "[", "0", "]", ",", "tf", ".", "shape", "(", "t", ")", "[", "1", "]", ",", "num_heads", "*", "dim", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.core.layers.ones_matrix_band_part": [[1291, 1312], ["all", "numpy.tri", "tensorflow.constant", "tensorflow.matrix_band_part", "isinstance", "numpy.tri", "tf.reshape.reshape", "tensorflow.ones", "tensorflow.cast", "tensorflow.cast", "tensorflow.reshape", "numpy.ones"], "function", ["None"], ["", "def", "ones_matrix_band_part", "(", "rows", ",", "cols", ",", "num_lower", ",", "num_upper", ",", "out_shape", "=", "None", ")", ":", "\n", "    ", "\"\"\"Matrix band part of ones.\"\"\"", "\n", "if", "all", "(", "[", "isinstance", "(", "el", ",", "int", ")", "for", "el", "in", "[", "rows", ",", "cols", ",", "num_lower", ",", "num_upper", "]", "]", ")", ":", "\n", "# Needed info is constant, so we construct in numpy", "\n", "        ", "if", "num_lower", "<", "0", ":", "\n", "            ", "num_lower", "=", "rows", "-", "1", "\n", "", "if", "num_upper", "<", "0", ":", "\n", "            ", "num_upper", "=", "cols", "-", "1", "\n", "", "lower_mask", "=", "np", ".", "tri", "(", "cols", ",", "rows", ",", "num_lower", ")", ".", "T", "\n", "upper_mask", "=", "np", ".", "tri", "(", "rows", ",", "cols", ",", "num_upper", ")", "\n", "band", "=", "np", ".", "ones", "(", "(", "rows", ",", "cols", ")", ")", "*", "lower_mask", "*", "upper_mask", "\n", "if", "out_shape", ":", "\n", "            ", "band", "=", "band", ".", "reshape", "(", "out_shape", ")", "\n", "", "band", "=", "tf", ".", "constant", "(", "band", ",", "tf", ".", "float32", ")", "\n", "", "else", ":", "\n", "        ", "band", "=", "tf", ".", "matrix_band_part", "(", "tf", ".", "ones", "(", "[", "rows", ",", "cols", "]", ")", ",", "\n", "tf", ".", "cast", "(", "num_lower", ",", "tf", ".", "int64", ")", ",", "\n", "tf", ".", "cast", "(", "num_upper", ",", "tf", ".", "int64", ")", ")", "\n", "if", "out_shape", ":", "\n", "            ", "band", "=", "tf", ".", "reshape", "(", "band", ",", "out_shape", ")", "\n", "", "", "return", "band", "\n", "", ""]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.core.replay_memories.ReplayMemoryBase.__init__": [[19, 21], ["texar.hyperparams.HParams", "replay_memories.ReplayMemoryBase.default_hparams"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.core.replay_memories.DequeReplayMemory.default_hparams"], ["def", "__init__", "(", "self", ",", "hparams", "=", "None", ")", ":", "\n", "        ", "self", ".", "_hparams", "=", "HParams", "(", "hparams", ",", "self", ".", "default_hparams", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.core.replay_memories.ReplayMemoryBase.add": [[22, 26], ["None"], "methods", ["None"], ["", "def", "add", "(", "self", ",", "element", ")", ":", "\n", "        ", "\"\"\"TODO: docs\n        \"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.core.replay_memories.ReplayMemoryBase.get": [[27, 31], ["None"], "methods", ["None"], ["", "def", "get", "(", "self", ",", "size", ")", ":", "\n", "        ", "\"\"\"TODO: docs\n        \"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.core.replay_memories.ReplayMemoryBase.default_hparams": [[32, 38], ["None"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "default_hparams", "(", ")", ":", "\n", "        ", "\"\"\"Returns a dictionary of default hyperparameters.\n        \"\"\"", "\n", "return", "{", "\n", "'name'", ":", "'replay_memory'", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.core.replay_memories.DequeReplayMemory.__init__": [[44, 48], ["replay_memories.ReplayMemoryBase.__init__", "collections.deque"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.text_infilling.self_attn_hyperparams.Hyperparams.__init__"], ["def", "__init__", "(", "self", ",", "hparams", "=", "None", ")", ":", "\n", "        ", "ReplayMemoryBase", ".", "__init__", "(", "self", ",", "hparams", ")", "\n", "self", ".", "deque", "=", "deque", "(", ")", "\n", "self", ".", "capacity", "=", "self", ".", "_hparams", ".", "capacity", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.core.replay_memories.DequeReplayMemory.default_hparams": [[49, 54], ["None"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "default_hparams", "(", ")", ":", "\n", "        ", "return", "{", "\n", "'name'", ":", "'deque_replay_memory'", ",", "\n", "'capacity'", ":", "80000", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.core.replay_memories.DequeReplayMemory.add": [[56, 60], ["replay_memories.DequeReplayMemory.deque.append", "len", "replay_memories.DequeReplayMemory.deque.popleft"], "methods", ["None"], ["", "def", "add", "(", "self", ",", "element", ")", ":", "\n", "        ", "self", ".", "deque", ".", "append", "(", "element", ")", "\n", "if", "len", "(", "self", ".", "deque", ")", ">", "self", ".", "capacity", ":", "\n", "            ", "self", ".", "deque", ".", "popleft", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.core.replay_memories.DequeReplayMemory.get": [[62, 64], ["random.sample"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.decoders.rnn_decoder_helpers.GumbelSoftmaxEmbeddingHelper.sample"], ["", "", "def", "get", "(", "self", ",", "size", ")", ":", "\n", "        ", "return", "random", ".", "sample", "(", "self", ".", "deque", ",", "size", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.core.distributions.sample_gaussian": [[6, 21], ["tensorflow.random_normal", "tensorflow.exp", "tensorflow.shape", "tensorflow.multiply"], "function", ["None"], ["def", "sample_gaussian", "(", "mu", ",", "logvar", ")", ":", "\n", "    ", "\"\"\"\n    Sample a sample from a multivariate Gaussian distribution with a diagonal covariance matrix using the\n    reparametrization trick.\n\n    TODO: this should be better be a instance method in a Gaussian class.\n\n    :param mu: a tensor of size [batch_size, variable_dim]. Batch_size can be None to support dynamic batching\n    :param logvar: a tensor of size [batch_size, variable_dim]. Batch_size can be None.\n    :return:\n    \"\"\"", "\n", "epsilon", "=", "tf", ".", "random_normal", "(", "tf", ".", "shape", "(", "logvar", ")", ",", "name", "=", "\"epsilon\"", ")", "\n", "std", "=", "tf", ".", "exp", "(", "0.5", "*", "logvar", ")", "\n", "z", "=", "mu", "+", "tf", ".", "multiply", "(", "std", ",", "epsilon", ")", "\n", "return", "z", "\n", "", ""]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.core.optimization_test.OptimizationTest.test_get_optimizer": [[23, 60], ["texar.get_optimizer_fn", "default_optimizer_fn", "optimization_test.OptimizationTest.assertTrue", "optimization_test.OptimizationTest.assertIsInstance", "texar.get_optimizer_fn", "momentum_optimizer_fn", "optimization_test.OptimizationTest.assertIsInstance", "texar.get_optimizer_fn", "momentum_optimizer_fn", "optimization_test.OptimizationTest.assertIsInstance", "texar.get_optimizer_fn", "optimization_test.OptimizationTest.assertIsInstance", "tensorflow.train.MomentumOptimizer", "texar.default_optimization_hparams"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.core.optimization.get_optimizer_fn", "home.repos.pwc.inspect_result.VegB_Text_Infilling.core.optimization.get_optimizer_fn", "home.repos.pwc.inspect_result.VegB_Text_Infilling.core.optimization.get_optimizer_fn", "home.repos.pwc.inspect_result.VegB_Text_Infilling.core.optimization.get_optimizer_fn", "home.repos.pwc.inspect_result.VegB_Text_Infilling.core.optimization.default_optimization_hparams"], ["def", "test_get_optimizer", "(", "self", ")", ":", "\n", "        ", "\"\"\"Tests get_optimizer.\n        \"\"\"", "\n", "default_optimizer_fn", ",", "optimizer_class", "=", "opt", ".", "get_optimizer_fn", "(", "\n", "opt", ".", "default_optimization_hparams", "(", ")", "[", "\"optimizer\"", "]", ")", "\n", "default_optimizer", "=", "default_optimizer_fn", "(", "1.0", ")", "\n", "self", ".", "assertTrue", "(", "optimizer_class", ",", "tf", ".", "train", ".", "Optimizer", ")", "\n", "self", ".", "assertIsInstance", "(", "default_optimizer", ",", "tf", ".", "train", ".", "AdamOptimizer", ")", "\n", "\n", "hparams", "=", "{", "\n", "\"type\"", ":", "\"MomentumOptimizer\"", ",", "\n", "\"kwargs\"", ":", "{", "\n", "\"learning_rate\"", ":", "0.001", ",", "\n", "\"momentum\"", ":", "0.9", ",", "\n", "\"use_nesterov\"", ":", "True", "\n", "}", "\n", "}", "\n", "momentum_optimizer_fn", ",", "_", "=", "opt", ".", "get_optimizer_fn", "(", "hparams", ")", "\n", "momentum_optimizer", "=", "momentum_optimizer_fn", "(", ")", "\n", "self", ".", "assertIsInstance", "(", "momentum_optimizer", ",", "tf", ".", "train", ".", "MomentumOptimizer", ")", "\n", "\n", "hparams", "=", "{", "\n", "\"type\"", ":", "tf", ".", "train", ".", "MomentumOptimizer", ",", "\n", "\"kwargs\"", ":", "{", "\n", "\"momentum\"", ":", "0.9", ",", "\n", "\"use_nesterov\"", ":", "True", "\n", "}", "\n", "}", "\n", "momentum_optimizer_fn", ",", "_", "=", "opt", ".", "get_optimizer_fn", "(", "hparams", ")", "\n", "momentum_optimizer", "=", "momentum_optimizer_fn", "(", "0.001", ")", "\n", "self", ".", "assertIsInstance", "(", "momentum_optimizer", ",", "tf", ".", "train", ".", "MomentumOptimizer", ")", "\n", "\n", "hparams", "=", "{", "\n", "\"type\"", ":", "tf", ".", "train", ".", "MomentumOptimizer", "(", "0.001", ",", "0.9", ")", "\n", "}", "\n", "momentum_optimizer", "=", "opt", ".", "get_optimizer_fn", "(", "hparams", ")", "\n", "self", ".", "assertIsInstance", "(", "momentum_optimizer", ",", "tf", ".", "train", ".", "MomentumOptimizer", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.core.optimization_test.OptimizationTest.test_get_learning_rate_decay_fn": [[62, 105], ["texar.get_learning_rate_decay_fn", "optimization_test.OptimizationTest.assertIsNone", "texar.get_learning_rate_decay_fn", "texar.get_learning_rate_decay_fn.", "tensorflow.train.piecewise_constant", "texar.get_learning_rate_decay_fn", "texar.get_learning_rate_decay_fn.", "tensorflow.train.natural_exp_decay", "optimization_test.OptimizationTest.test_session", "sess.run", "sess.run", "optimization_test.OptimizationTest.assertEqual", "optimization_test.OptimizationTest.assertEqual", "texar.default_optimization_hparams", "tensorflow.global_variables_initializer"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.core.optimization.get_learning_rate_decay_fn", "home.repos.pwc.inspect_result.VegB_Text_Infilling.core.optimization.get_learning_rate_decay_fn", "home.repos.pwc.inspect_result.VegB_Text_Infilling.core.optimization.get_learning_rate_decay_fn", "home.repos.pwc.inspect_result.VegB_Text_Infilling.core.optimization.default_optimization_hparams"], ["", "def", "test_get_learning_rate_decay_fn", "(", "self", ")", ":", "# pylint: disable=too-many-locals", "\n", "        ", "\"\"\"Tests get_learning_rate_decay_fn.\n        \"\"\"", "\n", "default_lr_decay_fn", "=", "opt", ".", "get_learning_rate_decay_fn", "(", "\n", "opt", ".", "default_optimization_hparams", "(", ")", "[", "\"learning_rate_decay\"", "]", ")", "\n", "self", ".", "assertIsNone", "(", "default_lr_decay_fn", ")", "\n", "\n", "boundaries", "=", "[", "2", ",", "4", "]", "\n", "values", "=", "[", "0.1", ",", "0.01", ",", "0.001", "]", "\n", "hparams", "=", "{", "\n", "\"type\"", ":", "\"piecewise_constant\"", ",", "\n", "\"kwargs\"", ":", "{", "\n", "\"boundaries\"", ":", "boundaries", ",", "\n", "\"values\"", ":", "values", "\n", "}", ",", "\n", "\"min_learning_rate\"", ":", "0.05", ",", "\n", "\"start_decay_step\"", ":", "1", ",", "\n", "\"end_decay_step\"", ":", "utils", ".", "MAX_SEQ_LENGTH", ",", "\n", "}", "\n", "pc_lr_decay_fn", "=", "opt", ".", "get_learning_rate_decay_fn", "(", "hparams", ")", "\n", "\n", "global_step", "=", "1", "\n", "pc_lr", "=", "pc_lr_decay_fn", "(", "learning_rate", "=", "1.", ",", "global_step", "=", "global_step", ")", "\n", "pc_lr_true", "=", "tf", ".", "train", ".", "piecewise_constant", "(", "\n", "global_step", "-", "hparams", "[", "\"start_decay_step\"", "]", ",", "boundaries", ",", "values", ")", "\n", "\n", "hparams", "[", "\"type\"", "]", "=", "\"natural_exp_decay\"", "\n", "hparams", "[", "\"kwargs\"", "]", "=", "{", "\n", "\"decay_steps\"", ":", "1", ",", "\n", "\"decay_rate\"", ":", "0.5", "\n", "}", "\n", "ned_lr_decay_fn", "=", "opt", ".", "get_learning_rate_decay_fn", "(", "hparams", ")", "\n", "ned_lr", "=", "ned_lr_decay_fn", "(", "learning_rate", "=", "1.", ",", "global_step", "=", "global_step", ")", "\n", "ned_lr_true", "=", "tf", ".", "train", ".", "natural_exp_decay", "(", "\n", "1.", ",", "global_step", "-", "hparams", "[", "\"start_decay_step\"", "]", ",", "\n", "hparams", "[", "\"kwargs\"", "]", "[", "\"decay_steps\"", "]", ",", "hparams", "[", "\"kwargs\"", "]", "[", "\"decay_rate\"", "]", ")", "\n", "\n", "with", "self", ".", "test_session", "(", ")", "as", "sess", ":", "\n", "            ", "sess", ".", "run", "(", "tf", ".", "global_variables_initializer", "(", ")", ")", "\n", "pc_lr_", ",", "pc_lr_true_", ",", "ned_lr_", ",", "ned_lr_true_", "=", "sess", ".", "run", "(", "\n", "[", "pc_lr", ",", "pc_lr_true", ",", "ned_lr", ",", "ned_lr_true", "]", ")", "\n", "self", ".", "assertEqual", "(", "pc_lr_", ",", "pc_lr_true_", ")", "\n", "self", ".", "assertEqual", "(", "ned_lr_", ",", "ned_lr_true_", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.core.optimization_test.OptimizationTest.test_get_gradient_clip_fn": [[106, 148], ["texar.get_gradient_clip_fn", "optimization_test.OptimizationTest.assertIsNone", "list", "texar.get_gradient_clip_fn", "texar.get_gradient_clip_fn.", "zip", "tensorflow.clip_by_global_norm", "texar.get_gradient_clip_fn", "texar.get_gradient_clip_fn.", "zip", "tensorflow.clip_by_value", "tensorflow.random_uniform", "zip", "optimization_test.OptimizationTest.test_session", "sess.run", "sess.run", "numpy.testing.assert_array_equal", "numpy.testing.assert_array_equal", "texar.default_optimization_hparams", "range", "range", "tensorflow.global_variables_initializer"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.core.optimization.get_gradient_clip_fn", "home.repos.pwc.inspect_result.VegB_Text_Infilling.core.optimization.get_gradient_clip_fn", "home.repos.pwc.inspect_result.VegB_Text_Infilling.core.optimization.get_gradient_clip_fn", "home.repos.pwc.inspect_result.VegB_Text_Infilling.core.optimization.default_optimization_hparams"], ["", "", "def", "test_get_gradient_clip_fn", "(", "self", ")", ":", "# pylint: disable=too-many-locals", "\n", "        ", "\"\"\"Tests get_gradient_clip_fn.\n        \"\"\"", "\n", "default_grad_clip_fn", "=", "opt", ".", "get_gradient_clip_fn", "(", "\n", "opt", ".", "default_optimization_hparams", "(", ")", "[", "\"gradient_clip\"", "]", ")", "\n", "self", ".", "assertIsNone", "(", "default_grad_clip_fn", ")", "\n", "\n", "grads", "=", "[", "tf", ".", "random_uniform", "(", "[", "10", ",", "10", "]", ",", "-", "1.", ",", "1.", ")", "for", "_", "in", "range", "(", "5", ")", "]", "\n", "grads_and_vars", "=", "list", "(", "zip", "(", "grads", ",", "range", "(", "5", ")", ")", ")", "\n", "\n", "hparams", "=", "{", "\n", "\"type\"", ":", "\"clip_by_global_norm\"", ",", "\n", "\"kwargs\"", ":", "{", "\n", "\"clip_norm\"", ":", "0.1", "\n", "}", "\n", "}", "\n", "gn_grad_clip_fn", "=", "opt", ".", "get_gradient_clip_fn", "(", "hparams", ")", "\n", "gn_grads_and_vars", "=", "gn_grad_clip_fn", "(", "grads_and_vars", ")", "\n", "gn_grads", ",", "_", "=", "zip", "(", "*", "gn_grads_and_vars", ")", "\n", "gn_grads_true", ",", "_", "=", "tf", ".", "clip_by_global_norm", "(", "\n", "grads", ",", "hparams", "[", "\"kwargs\"", "]", "[", "\"clip_norm\"", "]", ")", "\n", "\n", "hparams", "=", "{", "\n", "\"type\"", ":", "\"clip_by_value\"", ",", "\n", "\"kwargs\"", ":", "{", "\n", "\"clip_value_min\"", ":", "-", "0.01", ",", "\n", "\"clip_value_max\"", ":", "0.01", "\n", "}", "\n", "}", "\n", "v_grad_clip_fn", "=", "opt", ".", "get_gradient_clip_fn", "(", "hparams", ")", "\n", "v_grads_and_vars", "=", "v_grad_clip_fn", "(", "grads_and_vars", ")", "\n", "v_grads", ",", "_", "=", "zip", "(", "*", "v_grads_and_vars", ")", "\n", "v_grads_true", "=", "tf", ".", "clip_by_value", "(", "grads", ",", "\n", "hparams", "[", "\"kwargs\"", "]", "[", "\"clip_value_min\"", "]", ",", "\n", "hparams", "[", "\"kwargs\"", "]", "[", "\"clip_value_max\"", "]", ")", "\n", "\n", "with", "self", ".", "test_session", "(", ")", "as", "sess", ":", "\n", "            ", "sess", ".", "run", "(", "tf", ".", "global_variables_initializer", "(", ")", ")", "\n", "gn_grads_", ",", "gn_grads_true_", ",", "v_grads_", ",", "v_grads_true_", "=", "sess", ".", "run", "(", "\n", "[", "gn_grads", ",", "gn_grads_true", ",", "v_grads", ",", "v_grads_true", "]", ")", "\n", "np", ".", "testing", ".", "assert_array_equal", "(", "gn_grads_", ",", "gn_grads_true_", ")", "\n", "np", ".", "testing", ".", "assert_array_equal", "(", "v_grads_", ",", "v_grads_true_", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.core.optimization_test.OptimizationTest.test_get_train_op": [[149, 156], ["tensorflow.Variable", "tensorflow.nn.l2_loss", "texar.get_train_op", "optimization_test.OptimizationTest.assertTrue", "tensorflow.contrib.framework.is_tensor"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.losses.dqn_losses.l2_loss", "home.repos.pwc.inspect_result.VegB_Text_Infilling.core.optimization.get_train_op"], ["", "", "def", "test_get_train_op", "(", "self", ")", ":", "\n", "        ", "\"\"\"Tests get_train_op.\n        \"\"\"", "\n", "var", "=", "tf", ".", "Variable", "(", "0.", ")", "\n", "loss", "=", "tf", ".", "nn", ".", "l2_loss", "(", "var", ")", "\n", "train_op", "=", "opt", ".", "get_train_op", "(", "loss", ")", "\n", "self", ".", "assertTrue", "(", "tf", ".", "contrib", ".", "framework", ".", "is_tensor", "(", "train_op", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.core.layers_test.GetRNNCellTest.test_get_rnn_cell": [[27, 82], ["texar.core.layers.get_rnn_cell", "layers_test.GetRNNCellTest.assertTrue", "tensorflow.placeholder", "tensorflow.placeholder", "texar.hyperparams.HParams", "texar.core.layers.get_rnn_cell", "tensorflow.zeros", "tensorflow.zeros", "texar.core.layers.get_rnn_cell.", "tensorflow.BasicLSTMCell", "tensorflow.BasicLSTMCell", "isinstance", "texar.core.layers.default_rnn_cell_hparams", "texar.core.layers.get_rnn_cell.zero_state", "layers_test.GetRNNCellTest.test_session", "sess.run", "sess.run", "layers_test.GetRNNCellTest.assertEqual", "isinstance", "tensorflow.global_variables_initializer", "tensorflow.global_variables_initializer", "texar.context.global_mode", "layers_test.GetRNNCellTest.assertEqual", "layers_test.GetRNNCellTest.assertEqual", "layers_test.GetRNNCellTest.assertEqual", "layers_test.GetRNNCellTest.assertEqual"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.core.layers.get_rnn_cell", "home.repos.pwc.inspect_result.VegB_Text_Infilling.core.layers.get_rnn_cell", "home.repos.pwc.inspect_result.VegB_Text_Infilling.core.layers.default_rnn_cell_hparams", "home.repos.pwc.inspect_result.VegB_Text_Infilling.decoders.rnn_decoder_base.RNNDecoderBase.zero_state", "home.repos.pwc.inspect_result.VegB_Text_Infilling.texar.context.global_mode"], ["def", "test_get_rnn_cell", "(", "self", ")", ":", "\n", "        ", "\"\"\"Tests :func:`texar.core.layers.get_rnn_cell`.\n        \"\"\"", "\n", "emb_dim", "=", "4", "\n", "num_units", "=", "64", "\n", "\n", "hparams", "=", "{", "\n", "\"type\"", ":", "rnn", ".", "BasicLSTMCell", "(", "num_units", ")", "\n", "}", "\n", "cell", "=", "layers", ".", "get_rnn_cell", "(", "hparams", ")", "\n", "self", ".", "assertTrue", "(", "isinstance", "(", "cell", ",", "rnn", ".", "BasicLSTMCell", ")", ")", "\n", "\n", "keep_prob_x", "=", "tf", ".", "placeholder", "(", "\n", "name", "=", "'keep_prob'", ",", "shape", "=", "[", "]", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "hparams", "=", "{", "\n", "\"type\"", ":", "\"tensorflow.contrib.rnn.GRUCell\"", ",", "\n", "\"kwargs\"", ":", "{", "\n", "\"num_units\"", ":", "num_units", "\n", "}", ",", "\n", "\"num_layers\"", ":", "2", ",", "\n", "\"dropout\"", ":", "{", "\n", "\"input_keep_prob\"", ":", "0.8", ",", "\n", "\"state_keep_prob\"", ":", "keep_prob_x", ",", "\n", "\"variational_recurrent\"", ":", "True", ",", "\n", "\"input_size\"", ":", "[", "emb_dim", ",", "num_units", "]", "\n", "}", ",", "\n", "\"residual\"", ":", "True", ",", "\n", "\"highway\"", ":", "True", "\n", "}", "\n", "\n", "hparams_", "=", "HParams", "(", "hparams", ",", "layers", ".", "default_rnn_cell_hparams", "(", ")", ")", "\n", "cell", "=", "layers", ".", "get_rnn_cell", "(", "hparams_", ")", "\n", "\n", "batch_size", "=", "16", "\n", "inputs", "=", "tf", ".", "zeros", "(", "[", "batch_size", ",", "emb_dim", "]", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "output", ",", "state", "=", "cell", "(", "inputs", ",", "\n", "cell", ".", "zero_state", "(", "batch_size", ",", "dtype", "=", "tf", ".", "float32", ")", ")", "\n", "with", "self", ".", "test_session", "(", ")", "as", "sess", ":", "\n", "            ", "sess", ".", "run", "(", "tf", ".", "global_variables_initializer", "(", ")", ")", "\n", "\n", "feed_dict", "=", "{", "\n", "keep_prob_x", ":", "1.0", ",", "\n", "context", ".", "global_mode", "(", ")", ":", "tf", ".", "estimator", ".", "ModeKeys", ".", "TRAIN", "\n", "}", "\n", "output_", ",", "state_", "=", "sess", ".", "run", "(", "[", "output", ",", "state", "]", ",", "feed_dict", "=", "feed_dict", ")", "\n", "\n", "self", ".", "assertEqual", "(", "output_", ".", "shape", "[", "0", "]", ",", "batch_size", ")", "\n", "if", "isinstance", "(", "state_", ",", "(", "list", ",", "tuple", ")", ")", ":", "\n", "                ", "self", ".", "assertEqual", "(", "state_", "[", "0", "]", ".", "shape", "[", "0", "]", ",", "batch_size", ")", "\n", "self", ".", "assertEqual", "(", "state_", "[", "0", "]", ".", "shape", "[", "1", "]", ",", "\n", "hparams_", ".", "kwargs", ".", "num_units", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "assertEqual", "(", "state_", ".", "shape", "[", "0", "]", ",", "batch_size", ")", "\n", "self", ".", "assertEqual", "(", "state_", ".", "shape", "[", "1", "]", ",", "\n", "hparams_", ".", "kwargs", ".", "num_units", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.core.layers_test.GetRNNCellTest.test_switch_dropout": [[84, 116], ["tensorflow.placeholder", "tensorflow.placeholder", "texar.hyperparams.HParams", "texar.core.layers.get_rnn_cell", "tensorflow.zeros", "tensorflow.zeros", "texar.core.layers.get_rnn_cell.", "texar.core.layers.default_rnn_cell_hparams", "texar.core.layers.get_rnn_cell.zero_state", "layers_test.GetRNNCellTest.test_session", "sess.run", "sess.run", "layers_test.GetRNNCellTest.assertEqual", "sess.run", "layers_test.GetRNNCellTest.assertEqual", "tensorflow.global_variables_initializer", "tensorflow.global_variables_initializer"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.core.layers.get_rnn_cell", "home.repos.pwc.inspect_result.VegB_Text_Infilling.core.layers.default_rnn_cell_hparams", "home.repos.pwc.inspect_result.VegB_Text_Infilling.decoders.rnn_decoder_base.RNNDecoderBase.zero_state"], ["", "", "", "def", "test_switch_dropout", "(", "self", ")", ":", "\n", "        ", "\"\"\"Tests dropout mode.\n        \"\"\"", "\n", "emb_dim", "=", "4", "\n", "num_units", "=", "64", "\n", "hparams", "=", "{", "\n", "\"kwargs\"", ":", "{", "\n", "\"num_units\"", ":", "num_units", "\n", "}", ",", "\n", "\"num_layers\"", ":", "2", ",", "\n", "\"dropout\"", ":", "{", "\n", "\"input_keep_prob\"", ":", "0.8", ",", "\n", "}", ",", "\n", "}", "\n", "mode", "=", "tf", ".", "placeholder", "(", "tf", ".", "string", ")", "\n", "hparams_", "=", "HParams", "(", "hparams", ",", "layers", ".", "default_rnn_cell_hparams", "(", ")", ")", "\n", "cell", "=", "layers", ".", "get_rnn_cell", "(", "hparams_", ",", "mode", ")", "\n", "\n", "batch_size", "=", "16", "\n", "inputs", "=", "tf", ".", "zeros", "(", "[", "batch_size", ",", "emb_dim", "]", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "output", ",", "state", "=", "cell", "(", "inputs", ",", "\n", "cell", ".", "zero_state", "(", "batch_size", ",", "dtype", "=", "tf", ".", "float32", ")", ")", "\n", "with", "self", ".", "test_session", "(", ")", "as", "sess", ":", "\n", "            ", "sess", ".", "run", "(", "tf", ".", "global_variables_initializer", "(", ")", ")", "\n", "output_train", ",", "_", "=", "sess", ".", "run", "(", "\n", "[", "output", ",", "state", "]", ",", "\n", "feed_dict", "=", "{", "mode", ":", "tf", ".", "estimator", ".", "ModeKeys", ".", "TRAIN", "}", ")", "\n", "self", ".", "assertEqual", "(", "output_train", ".", "shape", "[", "0", "]", ",", "batch_size", ")", "\n", "output_test", ",", "_", "=", "sess", ".", "run", "(", "\n", "[", "output", ",", "state", "]", ",", "\n", "feed_dict", "=", "{", "mode", ":", "tf", ".", "estimator", ".", "ModeKeys", ".", "EVAL", "}", ")", "\n", "self", ".", "assertEqual", "(", "output_test", ".", "shape", "[", "0", "]", ",", "batch_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.core.layers_test.GetActivationFnTest.test_get_activation_fn": [[121, 147], ["texar.core.layers.get_activation_fn", "layers_test.GetActivationFnTest.assertEqual", "texar.core.layers.get_activation_fn", "layers_test.GetActivationFnTest.assertEqual", "tensorflow.random_uniform", "tensorflow.random_uniform", "texar.core.layers.get_activation_fn", "texar.core.layers.get_activation_fn.", "tensorflow.nn.leaky_relu", "tensorflow.nn.leaky_relu", "texar.core.layers.get_activation_fn", "texar.core.layers.get_activation_fn.", "tensorflow.nn.leaky_relu", "tensorflow.nn.leaky_relu", "layers_test.GetActivationFnTest.test_session", "sess.run", "sess.run", "numpy.testing.assert_array_equal", "layers_test.GetActivationFnTest.test_session", "sess.run", "sess.run", "numpy.testing.assert_array_equal", "tensorflow.global_variables_initializer", "tensorflow.global_variables_initializer", "tensorflow.global_variables_initializer", "tensorflow.global_variables_initializer"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.core.layers.get_activation_fn", "home.repos.pwc.inspect_result.VegB_Text_Infilling.core.layers.get_activation_fn", "home.repos.pwc.inspect_result.VegB_Text_Infilling.core.layers.get_activation_fn", "home.repos.pwc.inspect_result.VegB_Text_Infilling.core.layers.get_activation_fn"], ["def", "test_get_activation_fn", "(", "self", ")", ":", "\n", "        ", "\"\"\"Tests.\n        \"\"\"", "\n", "fn", "=", "layers", ".", "get_activation_fn", "(", ")", "\n", "self", ".", "assertEqual", "(", "fn", ",", "tf", ".", "identity", ")", "\n", "\n", "fn", "=", "layers", ".", "get_activation_fn", "(", "'relu'", ")", "\n", "self", ".", "assertEqual", "(", "fn", ",", "tf", ".", "nn", ".", "relu", ")", "\n", "\n", "inputs", "=", "tf", ".", "random_uniform", "(", "[", "64", ",", "100", "]", ",", "-", "5", ",", "20", ",", "dtype", "=", "tf", ".", "int32", ")", "\n", "\n", "fn", "=", "layers", ".", "get_activation_fn", "(", "'leaky_relu'", ")", "\n", "fn_output", "=", "fn", "(", "inputs", ")", "\n", "ref_output", "=", "tf", ".", "nn", ".", "leaky_relu", "(", "inputs", ")", "\n", "with", "self", ".", "test_session", "(", ")", "as", "sess", ":", "\n", "            ", "sess", ".", "run", "(", "tf", ".", "global_variables_initializer", "(", ")", ")", "\n", "fn_output_", ",", "ref_output_", "=", "sess", ".", "run", "(", "[", "fn_output", ",", "ref_output", "]", ")", "\n", "np", ".", "testing", ".", "assert_array_equal", "(", "fn_output_", ",", "ref_output_", ")", "\n", "\n", "", "fn", "=", "layers", ".", "get_activation_fn", "(", "'leaky_relu'", ",", "kwargs", "=", "{", "'alpha'", ":", "0.1", "}", ")", "\n", "fn_output", "=", "fn", "(", "inputs", ")", "\n", "ref_output", "=", "tf", ".", "nn", ".", "leaky_relu", "(", "inputs", ",", "alpha", "=", "0.1", ")", "\n", "with", "self", ".", "test_session", "(", ")", "as", "sess", ":", "\n", "            ", "sess", ".", "run", "(", "tf", ".", "global_variables_initializer", "(", ")", ")", "\n", "fn_output_", ",", "ref_output_", "=", "sess", ".", "run", "(", "[", "fn_output", ",", "ref_output", "]", ")", "\n", "np", ".", "testing", ".", "assert_array_equal", "(", "fn_output_", ",", "ref_output_", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.core.layers_test.GetLayerTest.test_get_layer": [[152, 172], ["texar.core.layers.get_layer", "layers_test.GetLayerTest.assertTrue", "texar.core.layers.get_layer", "layers_test.GetLayerTest.assertTrue", "isinstance", "isinstance"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.core.layers.get_layer", "home.repos.pwc.inspect_result.VegB_Text_Infilling.core.layers.get_layer"], ["def", "test_get_layer", "(", "self", ")", ":", "\n", "        ", "\"\"\"Tests :func:`texar.core.layers.get_layer`.\n        \"\"\"", "\n", "hparams", "=", "{", "\n", "\"type\"", ":", "\"Conv1D\"", "\n", "}", "\n", "layer", "=", "layers", ".", "get_layer", "(", "hparams", ")", "\n", "self", ".", "assertTrue", "(", "isinstance", "(", "layer", ",", "tf", ".", "layers", ".", "Conv1D", ")", ")", "\n", "\n", "hparams", "=", "{", "\n", "\"type\"", ":", "\"MergeLayer\"", ",", "\n", "\"kwargs\"", ":", "{", "\n", "\"layers\"", ":", "[", "\n", "{", "\"type\"", ":", "\"Conv1D\"", "}", ",", "\n", "{", "\"type\"", ":", "\"Conv1D\"", "}", "\n", "]", "\n", "}", "\n", "}", "\n", "layer", "=", "layers", ".", "get_layer", "(", "hparams", ")", "\n", "self", ".", "assertTrue", "(", "isinstance", "(", "layer", ",", "tx", ".", "core", ".", "MergeLayer", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.core.layers_test.ReducePoolingLayerTest.setUp": [[176, 182], ["tensorflow.test.TestCase.setUp", "tensorflow.test.TestCase.setUp"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.losses.mle_losses_test.MLELossesTest.setUp", "home.repos.pwc.inspect_result.VegB_Text_Infilling.losses.mle_losses_test.MLELossesTest.setUp"], ["def", "setUp", "(", "self", ")", ":", "\n", "        ", "tf", ".", "test", ".", "TestCase", ".", "setUp", "(", "self", ")", "\n", "\n", "self", ".", "_batch_size", "=", "64", "\n", "self", ".", "_seq_length", "=", "16", "\n", "self", ".", "_emb_dim", "=", "100", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.core.layers_test.ReducePoolingLayerTest.test_max_reduce_pooling_layer": [[183, 200], ["texar.core.layers.MaxReducePooling1D", "tensorflow.random_uniform", "tensorflow.random_uniform", "texar.core.layers.MaxReducePooling1D.compute_output_shape", "texar.core.layers.MaxReducePooling1D.", "tensorflow.reduce_max", "tensorflow.reduce_max", "layers_test.ReducePoolingLayerTest.assertEqual", "layers_test.ReducePoolingLayerTest.assertEqual", "tensorflow.random_uniform.get_shape", "layers.MaxReducePooling1D.get_shape", "layers.MaxReducePooling1D.get_shape", "layers_test.ReducePoolingLayerTest.test_session", "sess.run", "sess.run", "numpy.testing.assert_array_equal", "tensorflow.global_variables_initializer", "tensorflow.global_variables_initializer"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.core.layers.SequentialLayer.compute_output_shape"], ["", "def", "test_max_reduce_pooling_layer", "(", "self", ")", ":", "\n", "        ", "\"\"\"Tests :class:`texar.core.MaxReducePooling1D`.\n        \"\"\"", "\n", "pool_layer", "=", "layers", ".", "MaxReducePooling1D", "(", ")", "\n", "\n", "inputs", "=", "tf", ".", "random_uniform", "(", "\n", "[", "self", ".", "_batch_size", ",", "self", ".", "_seq_length", ",", "self", ".", "_emb_dim", "]", ")", "\n", "output_shape", "=", "pool_layer", ".", "compute_output_shape", "(", "inputs", ".", "get_shape", "(", ")", ")", "\n", "output", "=", "pool_layer", "(", "inputs", ")", "\n", "output_reduce", "=", "tf", ".", "reduce_max", "(", "inputs", ",", "axis", "=", "1", ")", "\n", "self", ".", "assertEqual", "(", "output", ".", "get_shape", "(", ")", ",", "output_shape", ")", "\n", "self", ".", "assertEqual", "(", "output", ".", "get_shape", "(", ")", ",", "[", "self", ".", "_batch_size", ",", "self", ".", "_emb_dim", "]", ")", "\n", "\n", "with", "self", ".", "test_session", "(", ")", "as", "sess", ":", "\n", "            ", "sess", ".", "run", "(", "tf", ".", "global_variables_initializer", "(", ")", ")", "\n", "output_", ",", "output_reduce_", "=", "sess", ".", "run", "(", "[", "output", ",", "output_reduce", "]", ")", "\n", "np", ".", "testing", ".", "assert_array_equal", "(", "output_", ",", "output_reduce_", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.core.layers_test.ReducePoolingLayerTest.test_average_reduce_pooling_layer": [[201, 218], ["texar.core.layers.AverageReducePooling1D", "tensorflow.random_uniform", "tensorflow.random_uniform", "texar.core.layers.AverageReducePooling1D.compute_output_shape", "texar.core.layers.AverageReducePooling1D.", "tensorflow.reduce_mean", "tensorflow.reduce_mean", "layers_test.ReducePoolingLayerTest.assertEqual", "layers_test.ReducePoolingLayerTest.assertEqual", "tensorflow.random_uniform.get_shape", "layers.AverageReducePooling1D.get_shape", "layers.AverageReducePooling1D.get_shape", "layers_test.ReducePoolingLayerTest.test_session", "sess.run", "sess.run", "numpy.testing.assert_array_equal", "tensorflow.global_variables_initializer", "tensorflow.global_variables_initializer"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.core.layers.SequentialLayer.compute_output_shape"], ["", "", "def", "test_average_reduce_pooling_layer", "(", "self", ")", ":", "\n", "        ", "\"\"\"Tests :class:`texar.core.AverageReducePooling1D`.\n        \"\"\"", "\n", "pool_layer", "=", "layers", ".", "AverageReducePooling1D", "(", ")", "\n", "\n", "inputs", "=", "tf", ".", "random_uniform", "(", "\n", "[", "self", ".", "_batch_size", ",", "self", ".", "_seq_length", ",", "self", ".", "_emb_dim", "]", ")", "\n", "output_shape", "=", "pool_layer", ".", "compute_output_shape", "(", "inputs", ".", "get_shape", "(", ")", ")", "\n", "output", "=", "pool_layer", "(", "inputs", ")", "\n", "output_reduce", "=", "tf", ".", "reduce_mean", "(", "inputs", ",", "axis", "=", "1", ")", "\n", "self", ".", "assertEqual", "(", "output", ".", "get_shape", "(", ")", ",", "output_shape", ")", "\n", "self", ".", "assertEqual", "(", "output", ".", "get_shape", "(", ")", ",", "[", "self", ".", "_batch_size", ",", "self", ".", "_emb_dim", "]", ")", "\n", "\n", "with", "self", ".", "test_session", "(", ")", "as", "sess", ":", "\n", "            ", "sess", ".", "run", "(", "tf", ".", "global_variables_initializer", "(", ")", ")", "\n", "output_", ",", "output_reduce_", "=", "sess", ".", "run", "(", "[", "output", ",", "output_reduce", "]", ")", "\n", "np", ".", "testing", ".", "assert_array_equal", "(", "output_", ",", "output_reduce_", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.core.layers_test.MergeLayerTest.test_output_shape": [[223, 240], ["texar.core.layers.MergeLayer", "texar.core.layers.MergeLayer.compute_output_shape", "layers_test.MergeLayerTest.assertEqual", "texar.core.layers.MergeLayer", "texar.core.layers.MergeLayer.compute_output_shape", "layers_test.MergeLayerTest.assertEqual", "texar.core.layers.MergeLayer", "texar.core.layers.MergeLayer.compute_output_shape", "layers_test.MergeLayerTest.assertEqual"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.core.layers.SequentialLayer.compute_output_shape", "home.repos.pwc.inspect_result.VegB_Text_Infilling.core.layers.SequentialLayer.compute_output_shape", "home.repos.pwc.inspect_result.VegB_Text_Infilling.core.layers.SequentialLayer.compute_output_shape"], ["def", "test_output_shape", "(", "self", ")", ":", "\n", "        ", "\"\"\"Tests MergeLayer.compute_output_shape function.\n        \"\"\"", "\n", "input_shapes", "=", "[", "[", "None", ",", "1", ",", "2", "]", ",", "[", "64", ",", "2", ",", "2", "]", ",", "[", "None", ",", "3", ",", "2", "]", "]", "\n", "\n", "concat_layer", "=", "layers", ".", "MergeLayer", "(", "mode", "=", "'concat'", ",", "axis", "=", "1", ")", "\n", "concat_output_shape", "=", "concat_layer", ".", "compute_output_shape", "(", "input_shapes", ")", "\n", "self", ".", "assertEqual", "(", "concat_output_shape", ",", "[", "64", ",", "6", ",", "2", "]", ")", "\n", "\n", "sum_layer", "=", "layers", ".", "MergeLayer", "(", "mode", "=", "'sum'", ",", "axis", "=", "1", ")", "\n", "sum_output_shape", "=", "sum_layer", ".", "compute_output_shape", "(", "input_shapes", ")", "\n", "self", ".", "assertEqual", "(", "sum_output_shape", ",", "[", "64", ",", "2", "]", ")", "\n", "\n", "input_shapes", "=", "[", "[", "None", ",", "5", ",", "2", "]", ",", "[", "64", ",", "None", ",", "2", "]", ",", "[", "2", "]", "]", "\n", "esum_layer", "=", "layers", ".", "MergeLayer", "(", "mode", "=", "'elemwise_sum'", ")", "\n", "esum_output_shape", "=", "esum_layer", ".", "compute_output_shape", "(", "input_shapes", ")", "\n", "self", ".", "assertEqual", "(", "esum_output_shape", ",", "[", "64", ",", "5", ",", "2", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.core.layers_test.MergeLayerTest.test_layer_logics": [[241, 262], ["layers_.append", "layers_.append", "layers_.append", "layers_.append", "layers_.append", "texar.core.layers.MergeLayer", "tensorflow.zeros", "tensorflow.zeros", "texar.core.layers.MergeLayer.", "tensorflow.layers.Conv1D", "tensorflow.layers.Conv1D", "tensorflow.layers.Conv1D", "tensorflow.layers.Conv1D", "tensorflow.layers.Conv1D", "tensorflow.layers.Conv1D", "tensorflow.layers.Dense", "tensorflow.layers.Dense", "tensorflow.layers.Dense", "tensorflow.layers.Dense", "layers_test.MergeLayerTest.test_session", "sess.run", "sess.run", "layers_test.MergeLayerTest.assertEqual", "layers_test.MergeLayerTest.assertEqual", "layers_test.MergeLayerTest.assertEqual", "tensorflow.global_variables_initializer", "tensorflow.global_variables_initializer", "texar.core.layers.MergeLayer.compute_output_shape", "tensorflow.zeros.shape.as_list"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.core.layers.SequentialLayer.compute_output_shape"], ["", "def", "test_layer_logics", "(", "self", ")", ":", "\n", "        ", "\"\"\"Test the logic of MergeLayer.\n        \"\"\"", "\n", "layers_", "=", "[", "]", "\n", "layers_", ".", "append", "(", "tf", ".", "layers", ".", "Conv1D", "(", "filters", "=", "200", ",", "kernel_size", "=", "3", ")", ")", "\n", "layers_", ".", "append", "(", "tf", ".", "layers", ".", "Conv1D", "(", "filters", "=", "200", ",", "kernel_size", "=", "4", ")", ")", "\n", "layers_", ".", "append", "(", "tf", ".", "layers", ".", "Conv1D", "(", "filters", "=", "200", ",", "kernel_size", "=", "5", ")", ")", "\n", "layers_", ".", "append", "(", "tf", ".", "layers", ".", "Dense", "(", "200", ")", ")", "\n", "layers_", ".", "append", "(", "tf", ".", "layers", ".", "Dense", "(", "200", ")", ")", "\n", "m_layer", "=", "layers", ".", "MergeLayer", "(", "layers_", ")", "\n", "\n", "inputs", "=", "tf", ".", "zeros", "(", "[", "64", ",", "16", ",", "1024", "]", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "outputs", "=", "m_layer", "(", "inputs", ")", "\n", "with", "self", ".", "test_session", "(", ")", "as", "sess", ":", "\n", "            ", "sess", ".", "run", "(", "tf", ".", "global_variables_initializer", "(", ")", ")", "\n", "outputs_", "=", "sess", ".", "run", "(", "outputs", ")", "\n", "self", ".", "assertEqual", "(", "outputs_", ".", "shape", "[", "0", "]", ",", "64", ")", "\n", "self", ".", "assertEqual", "(", "outputs_", ".", "shape", "[", "2", "]", ",", "200", ")", "\n", "self", ".", "assertEqual", "(", "\n", "outputs_", ".", "shape", ",", "\n", "m_layer", ".", "compute_output_shape", "(", "inputs", ".", "shape", ".", "as_list", "(", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.core.layers_test.MergeLayerTest.test_trainable_variables": [[263, 279], ["layers_.append", "layers_.append", "layers_.append", "layers_.append", "layers_.append", "texar.core.layers.MergeLayer", "tensorflow.zeros", "tensorflow.zeros", "texar.core.layers.MergeLayer.", "sum", "layers_test.MergeLayerTest.assertEqual", "tensorflow.layers.Conv1D", "tensorflow.layers.Conv1D", "tensorflow.layers.Conv1D", "tensorflow.layers.Conv1D", "tensorflow.layers.Conv1D", "tensorflow.layers.Conv1D", "tensorflow.layers.Dense", "tensorflow.layers.Dense", "tensorflow.layers.Dense", "tensorflow.layers.Dense", "len", "len"], "methods", ["None"], ["", "", "def", "test_trainable_variables", "(", "self", ")", ":", "\n", "        ", "\"\"\"Test the trainable_variables of the layer.\n        \"\"\"", "\n", "layers_", "=", "[", "]", "\n", "layers_", ".", "append", "(", "tf", ".", "layers", ".", "Conv1D", "(", "filters", "=", "200", ",", "kernel_size", "=", "3", ")", ")", "\n", "layers_", ".", "append", "(", "tf", ".", "layers", ".", "Conv1D", "(", "filters", "=", "200", ",", "kernel_size", "=", "4", ")", ")", "\n", "layers_", ".", "append", "(", "tf", ".", "layers", ".", "Conv1D", "(", "filters", "=", "200", ",", "kernel_size", "=", "5", ")", ")", "\n", "layers_", ".", "append", "(", "tf", ".", "layers", ".", "Dense", "(", "200", ")", ")", "\n", "layers_", ".", "append", "(", "tf", ".", "layers", ".", "Dense", "(", "200", ")", ")", "\n", "m_layer", "=", "layers", ".", "MergeLayer", "(", "layers_", ")", "\n", "\n", "inputs", "=", "tf", ".", "zeros", "(", "[", "64", ",", "16", ",", "1024", "]", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "_", "=", "m_layer", "(", "inputs", ")", "\n", "\n", "num_vars", "=", "sum", "(", "[", "len", "(", "layer", ".", "trainable_variables", ")", "for", "layer", "in", "layers_", "]", ")", "\n", "self", ".", "assertEqual", "(", "num_vars", ",", "len", "(", "m_layer", ".", "trainable_variables", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.core.layers_test.SequentialLayerTest.test_seq_layer": [[284, 306], ["layers_.append", "layers_.append", "texar.core.layers.SequentialLayer", "texar.core.layers.SequentialLayer.compute_output_shape", "layers_test.SequentialLayerTest.assertEqual", "tensorflow.zeros", "tensorflow.zeros", "texar.core.layers.SequentialLayer.", "sum", "layers_test.SequentialLayerTest.assertEqual", "tensorflow.layers.Dense", "tensorflow.layers.Dense", "tensorflow.layers.Dense", "tensorflow.layers.Dense", "len", "layers_test.SequentialLayerTest.test_session", "sess.run", "sess.run", "layers_test.SequentialLayerTest.assertEqual", "layers_test.SequentialLayerTest.assertEqual", "len", "tensorflow.global_variables_initializer", "tensorflow.global_variables_initializer"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.core.layers.SequentialLayer.compute_output_shape"], ["def", "test_seq_layer", "(", "self", ")", ":", "\n", "        ", "\"\"\"Test sequential layer.\n        \"\"\"", "\n", "layers_", "=", "[", "]", "\n", "layers_", ".", "append", "(", "tf", ".", "layers", ".", "Dense", "(", "100", ")", ")", "\n", "layers_", ".", "append", "(", "tf", ".", "layers", ".", "Dense", "(", "200", ")", ")", "\n", "seq_layer", "=", "layers", ".", "SequentialLayer", "(", "layers_", ")", "\n", "\n", "output_shape", "=", "seq_layer", ".", "compute_output_shape", "(", "[", "None", ",", "10", "]", ")", "\n", "self", ".", "assertEqual", "(", "output_shape", "[", "1", "]", ".", "value", ",", "200", ")", "\n", "\n", "inputs", "=", "tf", ".", "zeros", "(", "[", "10", ",", "20", "]", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "outputs", "=", "seq_layer", "(", "inputs", ")", "\n", "\n", "num_vars", "=", "sum", "(", "[", "len", "(", "layer", ".", "trainable_variables", ")", "for", "layer", "in", "layers_", "]", ")", "\n", "self", ".", "assertEqual", "(", "num_vars", ",", "len", "(", "seq_layer", ".", "trainable_variables", ")", ")", "\n", "\n", "with", "self", ".", "test_session", "(", ")", "as", "sess", ":", "\n", "            ", "sess", ".", "run", "(", "tf", ".", "global_variables_initializer", "(", ")", ")", "\n", "outputs_", "=", "sess", ".", "run", "(", "outputs", ")", "\n", "self", ".", "assertEqual", "(", "outputs_", ".", "shape", "[", "0", "]", ",", "10", ")", "\n", "self", ".", "assertEqual", "(", "outputs_", ".", "shape", "[", "1", "]", ",", "200", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.losses.adv_losses_test.AdvLossesTest.test_binary_adversarial_losses": [[17, 36], ["tensorflow.zeros", "tensorflow.ones", "tensorflow.zeros", "texar.losses.adv_losses.binary_adversarial_losses", "texar.losses.adv_losses.binary_adversarial_losses", "adv_losses_test.AdvLossesTest.test_session", "sess.run", "sess.run", "adv_losses_test.AdvLossesTest.assertAlmostEqual", "adv_losses_test.AdvLossesTest.assertAlmostEqual"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.losses.adv_losses.binary_adversarial_losses", "home.repos.pwc.inspect_result.VegB_Text_Infilling.losses.adv_losses.binary_adversarial_losses"], ["def", "test_binary_adversarial_losses", "(", "self", ")", ":", "\n", "        ", "\"\"\"Tests :meth:`~texar.losses.adv_losses.binary_adversarial_losse`.\n        \"\"\"", "\n", "batch_size", "=", "16", "\n", "data_dim", "=", "64", "\n", "real_data", "=", "tf", ".", "zeros", "(", "[", "batch_size", ",", "data_dim", "]", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "fake_data", "=", "tf", ".", "ones", "(", "[", "batch_size", ",", "data_dim", "]", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "const_logits", "=", "tf", ".", "zeros", "(", "[", "batch_size", "]", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "# Use a dumb discriminator that always outputs logits=0.", "\n", "gen_loss", ",", "disc_loss", "=", "binary_adversarial_losses", "(", "\n", "real_data", ",", "fake_data", ",", "lambda", "x", ":", "const_logits", ")", "\n", "gen_loss_2", ",", "disc_loss_2", "=", "binary_adversarial_losses", "(", "\n", "real_data", ",", "fake_data", ",", "lambda", "x", ":", "const_logits", ",", "mode", "=", "\"min_fake\"", ")", "\n", "\n", "with", "self", ".", "test_session", "(", ")", "as", "sess", ":", "\n", "            ", "gen_loss_", ",", "disc_loss_", "=", "sess", ".", "run", "(", "[", "gen_loss", ",", "disc_loss", "]", ")", "\n", "gen_loss_2_", ",", "disc_loss_2_", "=", "sess", ".", "run", "(", "[", "gen_loss_2", ",", "disc_loss_2", "]", ")", "\n", "self", ".", "assertAlmostEqual", "(", "gen_loss_", ",", "-", "gen_loss_2_", ")", "\n", "self", ".", "assertAlmostEqual", "(", "disc_loss_", ",", "disc_loss_2_", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.losses.losses_utils.mask_and_reduce": [[24, 113], ["losses_utils.reduce_batch_time", "ValueError", "tensorflow.python.ops.rnn._transpose_batch_time", "texar.utils.shapes.mask_sequences", "tensorflow.python.ops.rnn._transpose_batch_time", "ValueError", "tensorflow.reduce_mean", "tensorflow.reduce_sum", "range", "range"], "function", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.losses.losses_utils.reduce_batch_time", "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.shapes.mask_sequences"], ["def", "mask_and_reduce", "(", "sequence", ",", "\n", "sequence_length", ",", "\n", "rank", "=", "2", ",", "\n", "average_across_batch", "=", "True", ",", "\n", "average_across_timesteps", "=", "False", ",", "\n", "average_across_remaining", "=", "False", ",", "\n", "sum_over_batch", "=", "False", ",", "\n", "sum_over_timesteps", "=", "True", ",", "\n", "sum_over_remaining", "=", "True", ",", "\n", "dtype", "=", "None", ",", "\n", "time_major", "=", "False", ")", ":", "\n", "    ", "\"\"\"Masks out sequence entries that are beyond the respective sequence\n    lengths, and reduces (average or sum) away dimensions.\n\n    This is a combined function of :func:`~texar.utils.shapes.mask_sequences`\n    and :func:`~texar.losses.losses_utils.reduce_batch_time`.\n\n    Args:\n        sequence: A Tensor of sequence values.\n\n            If `time_major=False` (default), this must be a Tensor of shape:\n                `[batch_size, max_time, d_2, ..., d_rank]`, where the rank of\n                the Tensor is specified with :attr:`rank`.\n\n            If `time_major=True`, this must be a Tensor of shape:\n                `[max_time, batch_size, d_2, ..., d_rank].`\n        sequence_length: A Tensor of shape `[batch_size]`. Time steps beyond\n            the respective sequence lengths will be made zero. If `None`,\n            not masking is performed.\n        rank (int): The rank of :attr:`sequence`. Must be >= 2. Default is 2,\n            i.e., :attr:`sequence` is a 2D Tensor consisting of batch and time\n            dimensions.\n        average_across_timesteps (bool): If set, average the sequence across\n            the time dimension. Must not set :attr:`average_across_timesteps`\n            and :attr:`sum_over_timesteps` at the same time.\n        average_across_batch (bool): If set, average the sequence across the\n            batch dimension. Must not set :attr:`average_across_batch`'\n            and :attr:`sum_over_batch` at the same time.\n        average_across_remaining (bool): If set, average the sequence across the\n            remaining dimensions. Must not set :attr:`average_across_remaining`'\n            and :attr:`sum_over_remaining` at the same time.\n        sum_over_timesteps (bool): If set, sum the loss across the\n            time dimension. Must not set :attr:`average_across_timesteps`\n            and :attr:`sum_over_timesteps` at the same time.\n        sum_over_batch (bool): If set, sum the loss across the\n            batch dimension. Must not set :attr:`average_across_batch`\n            and :attr:`sum_over_batch` at the same time.\n        sum_over_remaining (bool): If set, sum the loss across the\n            remaining dimension. Must not set :attr:`average_across_remaining`\n            and :attr:`sum_over_remaining` at the same time.\n        time_major (bool): The shape format of the inputs. If `True`,\n            :attr:`sequence` must have shape `[max_time, batch_size, ...]`.\n            If `False` (default), :attr:`sequence` must have\n            shape `[batch_size, max_time, ...]`.\n        dtype (dtype): Type of :attr:`sequence`. If `None`, infer from\n            :attr:`sequence` automatically.\n    \"\"\"", "\n", "if", "rank", "<", "2", ":", "\n", "        ", "raise", "ValueError", "(", "'`rank` must be >= 2.'", ")", "\n", "\n", "", "if", "time_major", ":", "\n", "        ", "sequence", "=", "rnn", ".", "_transpose_batch_time", "(", "sequence", ")", "\n", "\n", "", "if", "sequence_length", "is", "None", ":", "\n", "        ", "sequence", "=", "mask_sequences", "(", "sequence", ",", "sequence_length", ",", "dtype", "=", "dtype", ",", "\n", "time_major", "=", "False", ",", "tensor_rank", "=", "rank", ")", "\n", "\n", "", "if", "rank", ">", "2", ":", "\n", "        ", "if", "average_across_remaining", "and", "sum_over_remaining", ":", "\n", "            ", "raise", "ValueError", "(", "\"Only one of `average_across_remaining` and \"", "\n", "\"`sum_over_remaining` can be set.\"", ")", "\n", "", "if", "average_across_remaining", ":", "\n", "            ", "sequence", "=", "tf", ".", "reduce_mean", "(", "sequence", ",", "axis", "=", "range", "(", "2", ",", "rank", ")", ")", "\n", "", "elif", "sum_over_remaining", ":", "\n", "            ", "sequence", "=", "tf", ".", "reduce_sum", "(", "sequence", ",", "axis", "=", "range", "(", "2", ",", "rank", ")", ")", "\n", "\n", "", "", "sequence", "=", "reduce_batch_time", "(", "sequence", ",", "\n", "sequence_length", ",", "\n", "average_across_batch", ",", "\n", "average_across_timesteps", ",", "\n", "sum_over_batch", ",", "\n", "sum_over_timesteps", ")", "\n", "\n", "reduce_time", "=", "average_across_timesteps", "or", "sum_over_timesteps", "\n", "reduce_batch", "=", "average_across_batch", "or", "sum_over_batch", "\n", "if", "not", "reduce_time", "and", "not", "reduce_batch", "and", "time_major", ":", "\n", "        ", "sequence", "=", "rnn", ".", "_transpose_batch_time", "(", "sequence", ")", "\n", "\n", "", "return", "sequence", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.losses.losses_utils.reduce_batch_time": [[115, 150], ["ValueError", "ValueError", "tensorflow.reduce_sum", "tensorflow.reduce_sum", "tensorflow.reduce_mean", "tensorflow.reduce_mean", "tensorflow.reduce_sum", "tensorflow.to_float"], "function", ["None"], ["", "def", "reduce_batch_time", "(", "sequence", ",", "\n", "sequence_length", ",", "\n", "average_across_batch", "=", "True", ",", "\n", "average_across_timesteps", "=", "False", ",", "\n", "sum_over_batch", "=", "False", ",", "\n", "sum_over_timesteps", "=", "True", ")", ":", "\n", "    ", "\"\"\"Average or sum over the respective dimensions of :attr:`sequence`, which\n    is of shape `[batch_size, max_time, ...]`.\n\n    Assumes :attr:`sequence` has been properly masked according to\n    :attr:`sequence_length`.\n    \"\"\"", "\n", "if", "average_across_timesteps", "and", "sum_over_timesteps", ":", "\n", "        ", "raise", "ValueError", "(", "\"Only one of `average_across_timesteps` and \"", "\n", "\"`sum_over_timesteps` can be set.\"", ")", "\n", "", "if", "average_across_batch", "and", "sum_over_batch", ":", "\n", "        ", "raise", "ValueError", "(", "\"Only one of `average_across_batch` and \"", "\n", "\"`sum_over_batch` can be set.\"", ")", "\n", "\n", "", "if", "sum_over_timesteps", ":", "\n", "        ", "sequence", "=", "tf", ".", "reduce_sum", "(", "sequence", ",", "axis", "=", "[", "1", "]", ")", "\n", "", "elif", "average_across_timesteps", ":", "\n", "        ", "if", "sequence_length", "is", "None", ":", "\n", "            ", "sequence", "=", "tf", ".", "reduce_mean", "(", "sequence", ",", "axis", "=", "[", "1", "]", ")", "\n", "", "else", ":", "\n", "            ", "sequence", "=", "tf", ".", "reduce_sum", "(", "sequence", ",", "axis", "=", "[", "1", "]", ")", "\n", "if", "average_across_timesteps", ":", "\n", "                ", "sequence", "=", "sequence", "/", "tf", ".", "to_float", "(", "sequence_length", ")", "\n", "\n", "", "", "", "if", "sum_over_batch", ":", "\n", "        ", "sequence", "=", "tf", ".", "reduce_sum", "(", "sequence", ",", "axis", "=", "[", "0", "]", ")", "\n", "", "elif", "average_across_batch", ":", "\n", "        ", "sequence", "=", "tf", ".", "reduce_mean", "(", "sequence", ",", "axis", "=", "[", "0", "]", ")", "\n", "\n", "", "return", "sequence", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.losses.losses_utils.reduce_dimensions": [[152, 192], ["tensorflow.reduce_mean", "tensorflow.reduce_sum", "tensorflow.squeeze", "len", "isinstance", "len", "isinstance", "len", "ValueError", "len", "len"], "function", ["None"], ["", "def", "reduce_dimensions", "(", "tensor", ",", "average_axes", "=", "None", ",", "sum_axes", "=", "None", ",", "keepdims", "=", "None", ")", ":", "\n", "    ", "\"\"\"Average or sum over the respective dimensions of :attr:`tensor`.\n\n    :attr:`average_axes` and :attr:`sum_axes` must be mutually exclusive. That\n    is, elements in :attr:`average_axes` must not be contained in\n    :attr:`sum_axes`, and vice versa.\n\n    Args:\n        tensor: A tensor to reduce.\n        average_axes (optional): A (list of) `int` that indicates the\n            dimensions to reduce by taking average.\n        sum_axes (optional): A (list of) `int` that indicates the\n            dimensions to reduce by taking sum.\n        keepdims (optional): If `True`, retains reduced dimensions with\n            length 1.\n    \"\"\"", "\n", "reduced_axes", "=", "[", "]", "\n", "if", "average_axes", "is", "not", "None", "and", "len", "(", "average_axes", ")", ">", "0", ":", "\n", "        ", "tensor", "=", "tf", ".", "reduce_mean", "(", "tensor", ",", "axis", "=", "average_axes", ",", "keepdims", "=", "True", ")", "\n", "\n", "if", "not", "isinstance", "(", "average_axes", ",", "(", "list", ",", "tuple", ")", ")", ":", "\n", "            ", "average_axes", "=", "[", "average_axes", "]", "\n", "", "reduced_axes", "+=", "average_axes", "\n", "\n", "", "if", "sum_axes", "is", "not", "None", "and", "len", "(", "sum_axes", ")", ">", "0", ":", "\n", "        ", "tensor", "=", "tf", ".", "reduce_sum", "(", "tensor", ",", "axis", "=", "sum_axes", ",", "keepdims", "=", "True", ")", "\n", "\n", "if", "not", "isinstance", "(", "sum_axes", ",", "(", "list", ",", "tuple", ")", ")", ":", "\n", "            ", "sum_axes", "=", "[", "sum_axes", "]", "\n", "", "reduced_axes", "+=", "sum_axes", "\n", "\n", "if", "average_axes", "is", "not", "None", ":", "\n", "            ", "if", "len", "(", "reduced_axes", ")", "!=", "len", "(", "average_axes", ")", "+", "len", "(", "sum_axes", ")", ":", "\n", "                ", "raise", "ValueError", "(", "'`average_axes` and `sum_axes` must not have '", "\n", "'overlapped elements.'", ")", "\n", "\n", "", "", "", "if", "not", "keepdims", ":", "\n", "        ", "tensor", "=", "tf", ".", "squeeze", "(", "tensor", ",", "axis", "=", "reduced_axes", ")", "\n", "\n", "", "return", "tensor", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.losses.dqn_losses.l2_loss": [[8, 22], ["tensorflow.reduce_sum", "tensorflow.reduce_sum"], "function", ["None"], ["def", "l2_loss", "(", "qvalue", ",", "action_input", ",", "y_input", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"\n    L2 loss function.\n\n    Args:\n         qvalue(Tensor):\n         action_input(Tensor):\n         y_input(Tensor):\n\n    \"\"\"", "\n", "temp", "=", "qvalue", "*", "action_input", "\n", "temp", "=", "tf", ".", "reduce_sum", "(", "input_tensor", "=", "temp", ",", "axis", "=", "1", ")", "\n", "loss", "=", "tf", ".", "reduce_sum", "(", "(", "temp", "-", "y_input", ")", "**", "2.0", ")", "\n", "return", "loss", "\n", "", ""]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.losses.mle_losses_test.MLELossesTest.setUp": [[24, 39], ["tensorflow.test.TestCase.setUp", "tensorflow.ones", "tensorflow.one_hot", "tensorflow.reshape", "tensorflow.random_uniform", "tensorflow.random_uniform"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.losses.mle_losses_test.MLELossesTest.setUp"], ["def", "setUp", "(", "self", ")", ":", "\n", "        ", "tf", ".", "test", ".", "TestCase", ".", "setUp", "(", "self", ")", "\n", "self", ".", "_batch_size", "=", "64", "\n", "self", ".", "_max_time", "=", "16", "\n", "self", ".", "_num_classes", "=", "100", "\n", "self", ".", "_labels", "=", "tf", ".", "ones", "(", "[", "self", ".", "_batch_size", ",", "self", ".", "_max_time", "]", ",", "\n", "dtype", "=", "tf", ".", "int32", ")", "\n", "one_hot_labels", "=", "tf", ".", "one_hot", "(", "\n", "self", ".", "_labels", ",", "self", ".", "_num_classes", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "self", ".", "_one_hot_labels", "=", "tf", ".", "reshape", "(", "\n", "one_hot_labels", ",", "[", "self", ".", "_batch_size", ",", "self", ".", "_max_time", ",", "-", "1", "]", ")", "\n", "self", ".", "_logits", "=", "tf", ".", "random_uniform", "(", "\n", "[", "self", ".", "_batch_size", ",", "self", ".", "_max_time", ",", "self", ".", "_num_classes", "]", ")", "\n", "self", ".", "_sequence_length", "=", "tf", ".", "random_uniform", "(", "\n", "[", "self", ".", "_batch_size", "]", ",", "maxval", "=", "self", ".", "_max_time", ",", "dtype", "=", "tf", ".", "int32", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.losses.mle_losses_test.MLELossesTest._test_sequence_loss": [[40, 74], ["mle_losses_test.MLELossesTest.test_session", "loss_fn", "sess.run", "mle_losses_test.MLELossesTest.assertEqual", "loss_fn", "sess.run", "mle_losses_test.MLELossesTest.assertEqual", "mle_losses_test.MLELossesTest.assertEqual", "loss_fn", "sess.run", "mle_losses_test.MLELossesTest.assertEqual", "mle_losses_test.MLELossesTest.assertEqual", "loss_fn", "sess.run", "mle_losses_test.MLELossesTest.assertEqual", "mle_losses_test.MLELossesTest.assertEqual", "tensorflow.random_uniform", "loss_fn", "mle_losses_test.MLELossesTest.assertEqual", "tensorflow.rank", "tensorflow.rank", "tensorflow.TensorShape", "tensorflow.rank", "tensorflow.TensorShape", "tensorflow.rank", "tensorflow.TensorShape", "tensorflow.TensorShape"], "methods", ["None"], ["", "def", "_test_sequence_loss", "(", "self", ",", "loss_fn", ",", "labels", ",", "logits", ",", "sequence_length", ")", ":", "\n", "        ", "with", "self", ".", "test_session", "(", ")", "as", "sess", ":", "\n", "            ", "loss", "=", "loss_fn", "(", "labels", ",", "logits", ",", "sequence_length", ")", "\n", "rank", "=", "sess", ".", "run", "(", "tf", ".", "rank", "(", "loss", ")", ")", "\n", "self", ".", "assertEqual", "(", "rank", ",", "0", ")", "\n", "\n", "loss", "=", "loss_fn", "(", "\n", "labels", ",", "logits", ",", "sequence_length", ",", "sum_over_timesteps", "=", "False", ")", "\n", "rank", "=", "sess", ".", "run", "(", "tf", ".", "rank", "(", "loss", ")", ")", "\n", "self", ".", "assertEqual", "(", "rank", ",", "1", ")", "\n", "self", ".", "assertEqual", "(", "loss", ".", "shape", ",", "tf", ".", "TensorShape", "(", "[", "self", ".", "_max_time", "]", ")", ")", "\n", "\n", "loss", "=", "loss_fn", "(", "\n", "labels", ",", "logits", ",", "sequence_length", ",", "sum_over_timesteps", "=", "False", ",", "\n", "average_across_timesteps", "=", "True", ",", "average_across_batch", "=", "False", ")", "\n", "rank", "=", "sess", ".", "run", "(", "tf", ".", "rank", "(", "loss", ")", ")", "\n", "self", ".", "assertEqual", "(", "rank", ",", "1", ")", "\n", "self", ".", "assertEqual", "(", "loss", ".", "shape", ",", "tf", ".", "TensorShape", "(", "[", "self", ".", "_batch_size", "]", ")", ")", "\n", "\n", "loss", "=", "loss_fn", "(", "\n", "labels", ",", "logits", ",", "sequence_length", ",", "sum_over_timesteps", "=", "False", ",", "\n", "average_across_batch", "=", "False", ")", "\n", "rank", "=", "sess", ".", "run", "(", "tf", ".", "rank", "(", "loss", ")", ")", "\n", "self", ".", "assertEqual", "(", "rank", ",", "2", ")", "\n", "self", ".", "assertEqual", "(", "loss", ".", "shape", ",", "\n", "tf", ".", "TensorShape", "(", "[", "self", ".", "_batch_size", ",", "self", ".", "_max_time", "]", ")", ")", "\n", "\n", "sequence_length_time", "=", "tf", ".", "random_uniform", "(", "\n", "[", "self", ".", "_max_time", "]", ",", "maxval", "=", "self", ".", "_max_time", ",", "dtype", "=", "tf", ".", "int32", ")", "\n", "loss", "=", "loss_fn", "(", "\n", "labels", ",", "logits", ",", "sequence_length_time", ",", "sum_over_timesteps", "=", "False", ",", "\n", "average_across_batch", "=", "False", ",", "time_major", "=", "True", ")", "\n", "self", ".", "assertEqual", "(", "loss", ".", "shape", ",", "\n", "tf", ".", "TensorShape", "(", "[", "self", ".", "_batch_size", ",", "self", ".", "_max_time", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.losses.mle_losses_test.MLELossesTest.test_sequence_softmax_cross_entropy": [[75, 81], ["mle_losses_test.MLELossesTest._test_sequence_loss"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.losses.mle_losses_test.MLELossesTest._test_sequence_loss"], ["", "", "def", "test_sequence_softmax_cross_entropy", "(", "self", ")", ":", "\n", "        ", "\"\"\"Tests `sequence_softmax_cross_entropy`\n        \"\"\"", "\n", "self", ".", "_test_sequence_loss", "(", "\n", "tx", ".", "losses", ".", "sequence_softmax_cross_entropy", ",", "\n", "self", ".", "_one_hot_labels", ",", "self", ".", "_logits", ",", "self", ".", "_sequence_length", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.losses.mle_losses_test.MLELossesTest.test_sequence_sparse_softmax_cross_entropy": [[82, 88], ["mle_losses_test.MLELossesTest._test_sequence_loss"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.losses.mle_losses_test.MLELossesTest._test_sequence_loss"], ["", "def", "test_sequence_sparse_softmax_cross_entropy", "(", "self", ")", ":", "\n", "        ", "\"\"\"Tests `sequence_sparse_softmax_cross_entropy`\n        \"\"\"", "\n", "self", ".", "_test_sequence_loss", "(", "\n", "tx", ".", "losses", ".", "sequence_sparse_softmax_cross_entropy", ",", "\n", "self", ".", "_labels", ",", "self", ".", "_logits", ",", "self", ".", "_sequence_length", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.losses.mle_losses_test.MLELossesTest.test_sequence_sigmoid_cross_entropy": [[89, 112], ["mle_losses_test.MLELossesTest._test_sequence_loss", "mle_losses_test.MLELossesTest._test_sequence_loss", "tensorflow.placeholder", "texar.losses.sequence_sigmoid_cross_entropy", "mle_losses_test.MLELossesTest.test_session", "sess.run", "mle_losses_test.MLELossesTest.assertEqual", "tensorflow.to_float", "tensorflow.rank", "numpy.ones"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.losses.mle_losses_test.MLELossesTest._test_sequence_loss", "home.repos.pwc.inspect_result.VegB_Text_Infilling.losses.mle_losses_test.MLELossesTest._test_sequence_loss", "home.repos.pwc.inspect_result.VegB_Text_Infilling.losses.mle_losses.sequence_sigmoid_cross_entropy"], ["", "def", "test_sequence_sigmoid_cross_entropy", "(", "self", ")", ":", "\n", "        ", "\"\"\"Tests `texar.losses.test_sequence_sigmoid_cross_entropy`.\n        \"\"\"", "\n", "self", ".", "_test_sequence_loss", "(", "\n", "tx", ".", "losses", ".", "sequence_sigmoid_cross_entropy", ",", "\n", "self", ".", "_one_hot_labels", ",", "self", ".", "_logits", ",", "self", ".", "_sequence_length", ")", "\n", "\n", "self", ".", "_test_sequence_loss", "(", "\n", "tx", ".", "losses", ".", "sequence_sigmoid_cross_entropy", ",", "\n", "self", ".", "_one_hot_labels", "[", ":", ",", ":", ",", "0", "]", ",", "\n", "self", ".", "_logits", "[", ":", ",", ":", ",", "0", "]", ",", "\n", "self", ".", "_sequence_length", ")", "\n", "\n", "labels", "=", "tf", ".", "placeholder", "(", "dtype", "=", "tf", ".", "int32", ",", "shape", "=", "None", ")", "\n", "loss", "=", "tx", ".", "losses", ".", "sequence_sigmoid_cross_entropy", "(", "\n", "logits", "=", "self", ".", "_logits", "[", ":", ",", ":", ",", "0", "]", ",", "\n", "labels", "=", "tf", ".", "to_float", "(", "labels", ")", ",", "\n", "sequence_length", "=", "self", ".", "_sequence_length", ")", "\n", "with", "self", ".", "test_session", "(", ")", "as", "sess", ":", "\n", "            ", "rank", "=", "sess", ".", "run", "(", "\n", "tf", ".", "rank", "(", "loss", ")", ",", "\n", "feed_dict", "=", "{", "labels", ":", "np", ".", "ones", "(", "[", "self", ".", "_batch_size", ",", "self", ".", "_max_time", "]", ")", "}", ")", "\n", "self", ".", "assertEqual", "(", "rank", ",", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.losses.adv_losses.binary_adversarial_losses": [[11, 64], ["discriminator_fn", "isinstance", "tensorflow.reduce_mean", "discriminator_fn", "isinstance", "tensorflow.reduce_mean", "tensorflow.nn.sigmoid_cross_entropy_with_logits", "tensorflow.nn.sigmoid_cross_entropy_with_logits", "tensorflow.reduce_mean", "ValueError", "tensorflow.ones_like", "tensorflow.zeros_like", "tensorflow.nn.sigmoid_cross_entropy_with_logits", "tensorflow.ones_like"], "function", ["None"], ["def", "binary_adversarial_losses", "(", "real_data", ",", "\n", "fake_data", ",", "\n", "discriminator_fn", ",", "\n", "mode", "=", "\"max_real\"", ")", ":", "\n", "    ", "\"\"\"Computes adversarial loss of the real/fake binary classification game.\n\n    Args:\n        real_data (Tensor or array): Real data of shape\n            `[num_real_examples, ...]`.\n        fake_data (Tensor or array): Fake data of shape\n            `[num_fake_examples, ...]`. `num_real_examples` does not necessarily\n            equal `num_fake_examples`.\n        discriminator_fn: A callable takes data (e.g., :attr:`real_data` and\n            :attr:`fake_data`) and returns the logits of being real. The\n            signature of :attr:`discriminator_fn` must be:\n\n                `logits, ... = discriminator_fn(data)`\n\n        mode (str): Mode of the generator loss. Either `max_real` or `min_fake`.\n\n            If `max_real` (default), minimizing the generator loss is to\n            maximize the probability of fake data being classified as real.\n\n            If `min_fake`, minimizing the generator loss is to minimize the\n            probability of fake data being classified as fake.\n\n    Returns:\n        (scalar Tensor, scalar Tensor): (generator_loss, discriminator_loss).\n    \"\"\"", "\n", "real_logits", "=", "discriminator_fn", "(", "real_data", ")", "\n", "if", "isinstance", "(", "real_logits", ",", "(", "list", ",", "tuple", ")", ")", ":", "\n", "        ", "real_logits", "=", "real_logits", "[", "0", "]", "\n", "", "real_loss", "=", "tf", ".", "reduce_mean", "(", "tf", ".", "nn", ".", "sigmoid_cross_entropy_with_logits", "(", "\n", "logits", "=", "real_logits", ",", "labels", "=", "tf", ".", "ones_like", "(", "real_logits", ")", ")", ")", "\n", "\n", "fake_logits", "=", "discriminator_fn", "(", "fake_data", ")", "\n", "if", "isinstance", "(", "fake_logits", ",", "(", "list", ",", "tuple", ")", ")", ":", "\n", "        ", "fake_logits", "=", "fake_logits", "[", "0", "]", "\n", "", "fake_loss", "=", "tf", ".", "reduce_mean", "(", "tf", ".", "nn", ".", "sigmoid_cross_entropy_with_logits", "(", "\n", "logits", "=", "fake_logits", ",", "labels", "=", "tf", ".", "zeros_like", "(", "fake_logits", ")", ")", ")", "\n", "\n", "d_loss", "=", "real_loss", "+", "fake_loss", "\n", "\n", "if", "mode", "==", "\"min_fake\"", ":", "\n", "        ", "g_loss", "=", "-", "fake_loss", "\n", "", "elif", "mode", "==", "\"max_real\"", ":", "\n", "        ", "g_loss", "=", "tf", ".", "reduce_mean", "(", "tf", ".", "nn", ".", "sigmoid_cross_entropy_with_logits", "(", "\n", "logits", "=", "fake_logits", ",", "labels", "=", "tf", ".", "ones_like", "(", "fake_logits", ")", ")", ")", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "\"Unknown mode: %s. Only 'min_fake' and 'max_real' \"", "\n", "\"are allowed.\"", ")", "\n", "\n", "", "return", "g_loss", ",", "d_loss", "\n", "", ""]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.losses.rl_losses.reinforce_loss": [[15, 65], ["sample_fn", "tensorflow.shape", "tensorflow.constant", "global_reward_fn", "texar.losses.mle_losses._mask_sequences", "local_reward_fn", "tensorflow.reshape", "tensorflow.log", "tensorflow.reduce_mean", "tensorflow.reduce_sum"], "function", ["None"], ["def", "reinforce_loss", "(", "sample_fn", ",", "\n", "global_reward_fn", ",", "\n", "local_reward_fn", "=", "None", ",", "\n", "num_samples", "=", "1", ")", ":", "\n", "    ", "\"\"\"Computes REINFORCE loss with global and local rewards.\n\n    Args:\n        sample_fn: A callable that takes :attr:`num_samples` and returns\n            `(samples, probabilities, sequence_lengths)`, where:\n\n            `samples` is a Tensor of shape `[num_samples, max_sequence_length]`\n            containing the generated samples;\n\n            `probabilities` is a Tensor of shape\n            `[num_samples, max_sequence_length]` containing the probabilities of\n            generating each position of the samples. Probabilities beyond the\n            respective sequence lengths are ignored.\n\n            `sequence_lengths` is a Tensor of shape `[num_samples]` containing\n            the length of each samples.\n        global_reward_fn: A callable that takes `(samples, sequence_lengths)`\n            and returns a Tensor of shape `[num_samples]` containing the reward\n            of each of the samples.\n        local_reward_fn (optional): A callable that takes\n            `(samples, sequence_lengths)` and returns a Tensor of shape\n            `[num_samples, max_sequence_length]` containing the local reward\n            at each time step of samples.\n        num_samples (int scalar Tensor): the number of sequences to sample.\n\n    Returns:\n        A scalar Tensor of the REINFORCE loss.\n    \"\"\"", "\n", "\n", "# shape = [batch, length]", "\n", "sequences", ",", "probs", ",", "seq_lens", "=", "sample_fn", "(", "num_samples", ")", "\n", "batch", ",", "_", "=", "tf", ".", "shape", "(", "sequences", ")", "\n", "rewards_local", "=", "tf", ".", "constant", "(", "0.", ",", "dtype", "=", "probs", ".", "dtype", ",", "shape", "=", "probs", ".", "shape", ")", "\n", "if", "local_reward_fn", "is", "not", "None", ":", "\n", "        ", "rewards_local", "=", "local_reward_fn", "(", "sequences", ",", "seq_lens", ")", "\n", "\n", "# shape = [batch, ]", "\n", "", "rewards_global", "=", "global_reward_fn", "(", "sequences", ",", "seq_lens", ")", "\n", "# add broadcast to rewards_global to match the shape of rewards_local", "\n", "rewards", "=", "rewards_local", "+", "tf", ".", "reshape", "(", "rewards_global", ",", "[", "batch", ",", "1", "]", ")", "\n", "\n", "eps", "=", "1e-12", "\n", "log_probs", "=", "_mask_sequences", "(", "tf", ".", "log", "(", "probs", "+", "eps", ")", ",", "seq_lens", ")", "\n", "loss", "=", "-", "tf", ".", "reduce_mean", "(", "\n", "tf", ".", "reduce_sum", "(", "log_probs", "*", "rewards", ",", "axis", "=", "1", ")", "/", "seq_lens", ")", "\n", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.losses.rl_losses.reinforce_loss_with_MCtree": [[67, 100], ["None"], "function", ["None"], ["", "def", "reinforce_loss_with_MCtree", "(", "sample_fn", ",", "# pylint: disable=invalid-name", "\n", "global_reward_fn", ",", "\n", "local_reward_fn", "=", "None", ",", "\n", "num_samples", "=", "1", ")", ":", "\n", "    ", "\"\"\"Computes REINFORCE loss with Monte Carlo tree search.\n\n    Args:\n        sample_fn: A callable that takes :attr:`num_samples`, 'given_actions'\n            and returns `(samples, probabilities, sequence_lengths)`, where:\n\n            `samples` is a Tensor of shape `[num_samples, max_sequence_length]`\n            containing the generated samples;\n\n            `probabilities` is a Tensor of shape\n            `[num_samples, max_sequence_length]` containing the probabilities of\n            generating each position of the samples. Probabilities beyond the\n            respective sequence lengths are ignored.\n\n            `sequence_lengths` is a Tensor of shape `[num_samples]` containing\n            the length of each samples.\n        global_reward_fn: A callable that takes `(samples, sequence_lengths)`\n            and returns a Tensor of shape `[num_samples]` containing the reward\n            of each of the samples.\n        local_reward_fn (optional): A callable that takes\n            `(samples, sequence_lengths)` and returns a Tensor of shape\n            `[num_samples, max_sequence_length]` containing the local reward\n            at each time step of samples.\n        num_samples (int scalar Tensor): the number of sequences to sample.\n\n    Returns:\n        A scalar Tensor of the REINFORCE loss.\n    \"\"\"", "\n", "raise", "NotImplementedError", "\n", "", ""]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.losses.entropy._get_entropy": [[22, 27], ["tensorflow.reduce_sum", "tensorflow.nn.softmax", "tensorflow.log"], "function", ["None"], ["def", "_get_entropy", "(", "logits", ")", ":", "\n", "    ", "probs", "=", "tf", ".", "nn", ".", "softmax", "(", "logits", ")", "+", "1e-8", "\n", "entropy", "=", "-", "probs", "*", "tf", ".", "log", "(", "probs", ")", "\n", "entropy", "=", "tf", ".", "reduce_sum", "(", "entropy", ",", "-", "1", ")", "\n", "return", "entropy", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.losses.entropy.entropy_with_logits": [[28, 97], ["entropy._get_entropy", "texar.losses.losses_utils.reduce_dimensions", "texar.utils.shapes.get_rank", "ValueError", "ValueError", "sum_axes.append", "average_axes.append", "list", "list", "range", "range"], "function", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.losses.entropy._get_entropy", "home.repos.pwc.inspect_result.VegB_Text_Infilling.losses.losses_utils.reduce_dimensions", "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.shapes.get_rank"], ["", "def", "entropy_with_logits", "(", "logits", ",", "\n", "rank", "=", "None", ",", "\n", "average_across_batch", "=", "True", ",", "\n", "average_across_remaining", "=", "False", ",", "\n", "sum_over_batch", "=", "False", ",", "\n", "sum_over_remaining", "=", "True", ")", ":", "\n", "    ", "\"\"\"Shannon entropy given logits.\n\n    Args:\n        logits: Unscaled log probabilities of shape\n            `[batch_size, d_2, ..., d_{rank-1}, distribution_dim]`\n            and of dtype `float32` or `float64`.\n\n            The rank of the tensor is optionally specified by the argument\n            :attr:`rank`.\n\n            The tensor is considered as having `[batch_size, .., d_{rank-1}]`\n            elements, each of which has a distribution of length `d_rank`\n            (i.e., `distribution_dim`). So the last dimension is always\n            summed out to compute the entropy.\n        rank (int, optional): The rank of :attr:`logits`.\n            If `None` (default), :attr:`rank` is inferred automatically from\n            :attr:`logits`. If the inferred rank is `None`, :attr:`rank` is\n            set to 2, i.e., assuming :attr:`logits` is of shape\n            `[batch_size, distribution_dim]`\n        average_across_batch (bool): If set, average the entropy across the\n            batch dimension. Must not set :attr:`average_across_batch`'\n            and :attr:`sum_over_batch` at the same time.\n        average_across_remaining (bool): If set, average the entropy across the\n            remaining dimensions. Must not set :attr:`average_across_remaining`'\n            and :attr:`sum_over_remaining` at the same time.\n            Used only when :attr:`logits` has rank >= 3.\n        sum_over_batch (bool): If set, sum the entropy across the\n            batch dimension. Must not set :attr:`average_across_batch`\n            and :attr:`sum_over_batch` at the same time.\n        sum_over_remaining (bool): If set, sum the entropy across the\n            remaining dimension. Must not set :attr:`average_across_remaining`\n            and :attr:`sum_over_remaining` at the same time.\n            Used only when :attr:`logits` has rank >= 3.\n    \"\"\"", "\n", "entropy", "=", "_get_entropy", "(", "logits", ")", "\n", "\n", "if", "rank", "is", "None", ":", "\n", "        ", "rank", "=", "get_rank", "(", "logits", ")", "\n", "", "if", "rank", "is", "None", ":", "\n", "        ", "rank", "=", "2", "\n", "", "rank", "-=", "1", "# reduced last dimension", "\n", "\n", "# Reduces", "\n", "if", "average_across_batch", "and", "sum_over_batch", ":", "\n", "        ", "raise", "ValueError", "(", "\"Only one of `average_across_batch` and \"", "\n", "\"`sum_over_batch` can be set.\"", ")", "\n", "", "if", "average_across_remaining", "and", "sum_over_remaining", ":", "\n", "        ", "raise", "ValueError", "(", "\"Only one of `average_across_remaining` and \"", "\n", "\"`sum_over_remaining` can be set.\"", ")", "\n", "", "sum_axes", ",", "average_axes", "=", "[", "]", ",", "[", "]", "\n", "if", "sum_over_batch", ":", "\n", "        ", "sum_axes", ".", "append", "(", "0", ")", "\n", "", "if", "average_across_batch", ":", "\n", "        ", "average_axes", ".", "append", "(", "0", ")", "\n", "", "if", "sum_over_remaining", "and", "rank", ">=", "2", ":", "\n", "        ", "sum_axes", "+=", "list", "(", "range", "(", "1", ",", "rank", ")", ")", "\n", "", "if", "average_across_remaining", "and", "rank", ">=", "2", ":", "\n", "        ", "average_axes", "+=", "list", "(", "range", "(", "1", ",", "rank", ")", ")", "\n", "\n", "", "entropy", "=", "reduce_dimensions", "(", "\n", "entropy", ",", "average_axes", "=", "average_axes", ",", "sum_axes", "=", "sum_axes", ")", "\n", "\n", "return", "entropy", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.losses.entropy.sequence_entropy_with_logits": [[98, 179], ["entropy._get_entropy", "texar.losses.losses_utils.mask_and_reduce", "texar.utils.shapes.get_rank"], "function", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.losses.entropy._get_entropy", "home.repos.pwc.inspect_result.VegB_Text_Infilling.losses.losses_utils.mask_and_reduce", "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.shapes.get_rank"], ["", "def", "sequence_entropy_with_logits", "(", "logits", ",", "\n", "rank", "=", "None", ",", "\n", "sequence_length", "=", "None", ",", "\n", "average_across_batch", "=", "True", ",", "\n", "average_across_timesteps", "=", "False", ",", "\n", "average_across_remaining", "=", "False", ",", "\n", "sum_over_batch", "=", "False", ",", "\n", "sum_over_timesteps", "=", "True", ",", "\n", "sum_over_remaining", "=", "True", ",", "\n", "time_major", "=", "False", ")", ":", "\n", "    ", "\"\"\"Shannon entropy given logits.\n\n    Args:\n        logits: Unscaled log probabilities of shape\n            `[batch_size, max_time, d_3, ..., d_{rank-1}, distribution_dim]`\n            and of dtype `float32` or `float64`.\n\n            The rank of the tensor is optionally specified by the argument\n            :attr:`rank`.\n\n            The tensor is considered as having `[batch_size, .., d_{rank-1}]`\n            elements, each of which has a distribution of length `d_rank`\n            (i.e., `distribution_dim`). So the last dimension is always\n            summed out to compute the entropy.\n\n            The batch and time dimensions are exchanged if :attr:`time_major`\n            is `True`.\n        rank (int, optional): The rank of :attr:`logits`.\n            If `None` (default), :attr:`rank` is inferred automatically from\n            :attr:`logits`. If the inferred rank is `None`, :attr:`rank` is\n            set to 3, i.e., assuming :attr:`logits` is of shape\n            `[batch_size, max_time, distribution_dim]`\n        sequence_length (optional): A Tensor of shape `[batch_size]`.\n            Time steps beyond the respective sequence lengths are\n            counted into the entropy.\n        average_across_timesteps (bool): If set, average the entropy across\n            the time dimension. Must not set :attr:`average_across_timesteps`\n            and :attr:`sum_over_timesteps` at the same time.\n        average_across_batch (bool): If set, average the entropy across the\n            batch dimension. Must not set :attr:`average_across_batch`'\n            and :attr:`sum_over_batch` at the same time.\n        average_across_remaining (bool): If set, average the entropy across the\n            remaining dimensions. Must not set :attr:`average_across_remaining`'\n            and :attr:`sum_over_remaining` at the same time.\n            Used only when :attr:`logits` has rank >= 4.\n        sum_over_timesteps (bool): If set, sum the entropy across the\n            time dimension. Must not set :attr:`average_across_timesteps`\n            and :attr:`sum_over_timesteps` at the same time.\n        sum_over_batch (bool): If set, sum the entropy across the\n            batch dimension. Must not set :attr:`average_across_batch`\n            and :attr:`sum_over_batch` at the same time.\n        sum_over_remaining (bool): If set, sum the entropy across the\n            remaining dimension. Must not set :attr:`average_across_remaining`\n            and :attr:`sum_over_remaining` at the same time.\n            Used only when :attr:`logits` has rank >= 4.\n        time_major (bool): The shape format of the inputs. If `True`,\n            :attr:`logits` must have shape `[max_time, batch_size, ...]`.\n            If `False` (default), it must have shape\n            `[batch_size, max_time, ...]`.\n    \"\"\"", "\n", "entropy", "=", "_get_entropy", "(", "logits", ")", "\n", "\n", "if", "rank", "is", "None", ":", "\n", "        ", "rank", "=", "get_rank", "(", "logits", ")", "\n", "", "if", "rank", "is", "None", ":", "\n", "        ", "rank", "=", "3", "\n", "", "rank", "-=", "1", "# reduced last dimension", "\n", "\n", "entropy", "=", "mask_and_reduce", "(", "\n", "entropy", ",", "\n", "sequence_length", ",", "\n", "rank", "=", "rank", ",", "\n", "average_across_batch", "=", "average_across_batch", ",", "\n", "average_across_timesteps", "=", "average_across_timesteps", ",", "\n", "average_across_remaining", "=", "average_across_remaining", ",", "\n", "sum_over_batch", "=", "sum_over_batch", ",", "\n", "sum_over_timesteps", "=", "sum_over_timesteps", ",", "\n", "sum_over_remaining", "=", "sum_over_remaining", ",", "\n", "time_major", "=", "time_major", ")", "\n", "\n", "return", "entropy", "\n", "", ""]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.losses.rewards.discount_reward": [[25, 111], ["is_tensor", "is_tensor", "numpy.array", "rewards._discount_reward_tensor_1d", "tensorflow.nn.moments", "rewards._discount_reward_py_1d", "numpy.mean", "numpy.std", "rewards._discount_reward_tensor_2d", "ValueError", "rewards._discount_reward_py_2d", "ValueError", "tensorflow.sqrt"], "function", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.losses.rewards._discount_reward_tensor_1d", "home.repos.pwc.inspect_result.VegB_Text_Infilling.losses.rewards._discount_reward_py_1d", "home.repos.pwc.inspect_result.VegB_Text_Infilling.losses.rewards._discount_reward_tensor_2d", "home.repos.pwc.inspect_result.VegB_Text_Infilling.losses.rewards._discount_reward_py_2d"], ["def", "discount_reward", "(", "reward", ",", "\n", "sequence_length", "=", "None", ",", "\n", "discount", "=", "1.", ",", "\n", "normalize", "=", "False", ",", "\n", "dtype", "=", "None", ",", "\n", "tensor_rank", "=", "1", ")", ":", "\n", "    ", "\"\"\"Computes discounted reward.\n\n    :attr:`reward` and :attr:`sequence_length` can be either Tensors or python\n    arrays. If both are python array (or None), the return will be a python\n    array as well.\n\n    :attr:`tensor_rank` is ignored when :attr:`sequence` and\n    :attr:`sequence_length` are both python arrays (or None) rather than\n    Tensors.\n\n    Args:\n        reward: A Tensor or python array. Can be 1D with shape `[batch_size]`,\n            or 2D with shape `[batch_size, max_time]`.\n        sequence_length (optional): A Tensor or python array of shape\n            `[batch_size]`. Time steps beyond the respective sequence lengths\n            will be masked. Required if :attr:`reward` is 1D.\n        discount (float): A scalar. The discount factor.\n        normalize (bool): Whether to normalize the discounted reward, by\n            `(discounted_reward - mean) / std`.\n        dtype (dtype): Type of :attr:`sequence`. If `None`, infer from\n            :attr:`reward` automatically.\n        tensor_rank (int): The number of dimensions of :attr:`reward`.\n            Default is 1, i.e., :attr:`reward` is a 1D Tensor consisting\n            of a batch dimension. Ignored if :attr:`reward`\n            and :attr:`sequence_length` are python arrays (or None).\n\n    Returns:\n        A 2D Tensor or python array of the discounted reward.\n\n        If :attr:`reward` and :attr:`sequence_length` are python\n        arrays (or None), the returned value is a python array as well.\n\n\n    Example:\n        .. code-block:: python\n\n            r = [2., 1.]\n            seq_length = [3, 2]\n            discounted_r = discount_reward(r, seq_length, discount=0.1)\n            # discounted_r == [[2. * 0.1^2, 2. * 0.1, 2.],\n            #                  [1. * 0.1,   1.,       0.]]\n\n            r = [[3., 4., 5.], [6., 7., 0.]]\n            seq_length = [3, 2]\n            discounted_r = discount_reward(r, seq_length, discount=0.1)\n            # discounted_r == [[3. + 4.*0.1 + 5.*0.1^2, 4. + 5.*0.1, 5.],\n            #                  [6. + 7.*0.1,            7.,          0.]]\n    \"\"\"", "\n", "is_tensor", "=", "tf", ".", "contrib", ".", "framework", ".", "is_tensor", "\n", "if", "is_tensor", "(", "reward", ")", "or", "is_tensor", "(", "sequence_length", ")", ":", "\n", "        ", "if", "tensor_rank", "==", "1", ":", "\n", "            ", "disc_reward", "=", "_discount_reward_tensor_1d", "(", "\n", "reward", ",", "sequence_length", ",", "discount", ",", "dtype", ")", "\n", "", "elif", "tensor_rank", "==", "2", ":", "\n", "            ", "disc_reward", "=", "_discount_reward_tensor_2d", "(", "\n", "reward", ",", "sequence_length", ",", "discount", ",", "dtype", ")", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\"`tensor_rank` can only be 1 or 2.\"", ")", "\n", "\n", "", "if", "normalize", ":", "\n", "            ", "mu", ",", "var", "=", "tf", ".", "nn", ".", "moments", "(", "disc_reward", ",", "axes", "=", "[", "0", ",", "1", "]", ",", "keep_dims", "=", "True", ")", "\n", "disc_reward", "=", "(", "disc_reward", "-", "mu", ")", "/", "(", "tf", ".", "sqrt", "(", "var", ")", "+", "1e-8", ")", "\n", "", "", "else", ":", "\n", "        ", "reward", "=", "np", ".", "array", "(", "reward", ")", "\n", "tensor_rank", "=", "reward", ".", "ndim", "\n", "if", "tensor_rank", "==", "1", ":", "\n", "            ", "disc_reward", "=", "_discount_reward_py_1d", "(", "\n", "reward", ",", "sequence_length", ",", "discount", ",", "dtype", ")", "\n", "", "elif", "tensor_rank", "==", "2", ":", "\n", "            ", "disc_reward", "=", "_discount_reward_py_2d", "(", "\n", "reward", ",", "sequence_length", ",", "discount", ",", "dtype", ")", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\"`reward` can only be 1D or 2D.\"", ")", "\n", "\n", "", "if", "normalize", ":", "\n", "            ", "mu", "=", "np", ".", "mean", "(", "disc_reward", ")", "\n", "std", "=", "np", ".", "std", "(", "disc_reward", ")", "\n", "disc_reward", "=", "(", "disc_reward", "-", "mu", ")", "/", "(", "std", "+", "1e-8", ")", "\n", "\n", "", "", "return", "disc_reward", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.losses.rewards._discount_reward_py_1d": [[112, 138], ["numpy.array", "numpy.array", "numpy.max", "texar.utils.shapes.mask_sequences", "ValueError", "numpy.ones", "numpy.tile", "numpy.asarray", "numpy.arange", "numpy.cumprod"], "function", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.shapes.mask_sequences"], ["", "def", "_discount_reward_py_1d", "(", "reward", ",", "sequence_length", ",", "discount", "=", "1.", ",", "dtype", "=", "None", ")", ":", "\n", "    ", "if", "sequence_length", "is", "None", ":", "\n", "        ", "raise", "ValueError", "(", "'sequence_length must not be `None` for 1D reward.'", ")", "\n", "\n", "", "reward", "=", "np", ".", "array", "(", "reward", ")", "\n", "sequence_length", "=", "np", ".", "array", "(", "sequence_length", ")", "\n", "\n", "batch_size", "=", "reward", ".", "shape", "[", "0", "]", "\n", "max_seq_length", "=", "np", ".", "max", "(", "sequence_length", ")", "\n", "dtype", "=", "dtype", "or", "reward", ".", "dtype", "\n", "\n", "if", "discount", "==", "1.", ":", "\n", "        ", "dmat", "=", "np", ".", "ones", "(", "[", "batch_size", ",", "max_seq_length", "]", ",", "dtype", "=", "dtype", ")", "\n", "", "else", ":", "\n", "        ", "steps", "=", "np", ".", "tile", "(", "np", ".", "arange", "(", "max_seq_length", ")", ",", "[", "batch_size", ",", "1", "]", ")", "\n", "mask", "=", "np", ".", "asarray", "(", "steps", "<", "(", "sequence_length", "-", "1", ")", "[", ":", ",", "None", "]", ",", "dtype", "=", "dtype", ")", "\n", "# Make each row = [discount, ..., discount, 1, ..., 1]", "\n", "dmat", "=", "mask", "*", "discount", "+", "(", "1", "-", "mask", ")", "\n", "dmat", "=", "np", ".", "cumprod", "(", "dmat", "[", ":", ",", ":", ":", "-", "1", "]", ",", "axis", "=", "1", ")", "[", ":", ",", ":", ":", "-", "1", "]", "\n", "\n", "", "disc_reward", "=", "dmat", "*", "reward", "[", ":", ",", "None", "]", "\n", "disc_reward", "=", "mask_sequences", "(", "disc_reward", ",", "sequence_length", ",", "dtype", "=", "dtype", ")", "\n", "#mask = np.asarray(steps < sequence_length[:, None], dtype=dtype)", "\n", "#disc_reward = mask * disc_reward", "\n", "\n", "return", "disc_reward", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.losses.rewards._discount_reward_tensor_1d": [[139, 163], ["tensorflow.reduce_max", "texar.utils.shapes.mask_sequences", "ValueError", "tensorflow.shape", "tensorflow.ones", "tensorflow.sequence_mask", "tensorflow.concat", "tensorflow.cumprod", "tensorflow.expand_dims", "tensorflow.concat", "tensorflow.zeros_like"], "function", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.shapes.mask_sequences"], ["", "def", "_discount_reward_tensor_1d", "(", "reward", ",", "sequence_length", ",", "\n", "discount", "=", "1.", ",", "dtype", "=", "None", ")", ":", "\n", "    ", "if", "sequence_length", "is", "None", ":", "\n", "        ", "raise", "ValueError", "(", "'sequence_length must not be `None` for 1D reward.'", ")", "\n", "\n", "", "batch_size", "=", "tf", ".", "shape", "(", "reward", ")", "[", "0", "]", "\n", "max_seq_length", "=", "tf", ".", "reduce_max", "(", "sequence_length", ")", "\n", "dtype", "=", "dtype", "or", "reward", ".", "dtype", "\n", "\n", "if", "discount", "==", "1.", ":", "\n", "        ", "dmat", "=", "tf", ".", "ones", "(", "\n", "tf", ".", "concat", "(", "[", "[", "batch_size", "]", ",", "[", "max_seq_length", "]", "]", ",", "0", ")", ",", "dtype", "=", "dtype", ")", "\n", "", "else", ":", "\n", "        ", "mask", "=", "tf", ".", "sequence_mask", "(", "sequence_length", ",", "dtype", "=", "dtype", ")", "\n", "mask", "=", "tf", ".", "concat", "(", "[", "mask", "[", ":", ",", "1", ":", "]", ",", "tf", ".", "zeros_like", "(", "mask", "[", ":", ",", "-", "1", ":", "]", ")", "]", ",", "axis", "=", "1", ")", "\n", "# Make each row = [discount, ..., discount, 1, ..., 1]", "\n", "dmat", "=", "mask", "*", "discount", "+", "(", "1", "-", "mask", ")", "\n", "dmat", "=", "tf", ".", "cumprod", "(", "dmat", ",", "axis", "=", "1", ",", "reverse", "=", "True", ")", "\n", "\n", "", "disc_reward", "=", "dmat", "*", "tf", ".", "expand_dims", "(", "reward", ",", "-", "1", ")", "\n", "disc_reward", "=", "mask_sequences", "(", "\n", "disc_reward", ",", "sequence_length", ",", "dtype", "=", "dtype", ",", "tensor_rank", "=", "2", ")", "\n", "\n", "return", "disc_reward", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.losses.rewards._discount_reward_py_2d": [[164, 180], ["texar.utils.shapes.mask_sequences", "numpy.copy", "range", "numpy.cumsum"], "function", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.shapes.mask_sequences"], ["", "def", "_discount_reward_py_2d", "(", "reward", ",", "sequence_length", "=", "None", ",", "\n", "discount", "=", "1.", ",", "dtype", "=", "None", ")", ":", "\n", "    ", "if", "sequence_length", "is", "not", "None", ":", "\n", "        ", "reward", "=", "mask_sequences", "(", "reward", ",", "sequence_length", ",", "dtype", "=", "dtype", ")", "\n", "\n", "", "dtype", "=", "dtype", "or", "reward", ".", "dtype", "\n", "\n", "if", "discount", "==", "1.", ":", "\n", "        ", "disc_reward", "=", "np", ".", "cumsum", "(", "\n", "reward", "[", ":", ",", ":", ":", "-", "1", "]", ",", "axis", "=", "1", ",", "dtype", "=", "dtype", ")", "[", ":", ",", ":", ":", "-", "1", "]", "\n", "", "else", ":", "\n", "        ", "disc_reward", "=", "np", ".", "copy", "(", "reward", ")", "\n", "for", "i", "in", "range", "(", "reward", ".", "shape", "[", "1", "]", "-", "2", ",", "-", "1", ",", "-", "1", ")", ":", "\n", "            ", "disc_reward", "[", ":", ",", "i", "]", "+=", "disc_reward", "[", ":", ",", "i", "+", "1", "]", "*", "discount", "\n", "\n", "", "", "return", "disc_reward", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.losses.rewards._discount_reward_tensor_2d": [[181, 201], ["texar.utils.shapes.mask_sequences", "tensorflow.cumsum", "tensorflow.transpose", "tensorflow.scan", "tensorflow.reverse", "tensorflow.reverse", "tensorflow.transpose", "tensorflow.zeros_like"], "function", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.shapes.mask_sequences"], ["", "def", "_discount_reward_tensor_2d", "(", "reward", ",", "sequence_length", "=", "None", ",", "\n", "discount", "=", "1.", ",", "dtype", "=", "None", ")", ":", "\n", "    ", "if", "sequence_length", "is", "not", "None", ":", "\n", "        ", "reward", "=", "mask_sequences", "(", "\n", "reward", ",", "sequence_length", ",", "dtype", "=", "dtype", ",", "tensor_rank", "=", "2", ")", "\n", "\n", "", "if", "discount", "==", "1.", ":", "\n", "        ", "disc_reward", "=", "tf", ".", "cumsum", "(", "reward", ",", "axis", "=", "1", ",", "reverse", "=", "True", ")", "\n", "", "else", ":", "\n", "# [max_time, batch_size]", "\n", "        ", "rev_reward_T", "=", "tf", ".", "transpose", "(", "tf", ".", "reverse", "(", "reward", ",", "[", "1", "]", ")", ",", "[", "1", ",", "0", "]", ")", "\n", "rev_reward_T_cum", "=", "tf", ".", "scan", "(", "\n", "fn", "=", "lambda", "acc", ",", "cur", ":", "cur", "+", "discount", "*", "acc", ",", "\n", "elems", "=", "rev_reward_T", ",", "\n", "initializer", "=", "tf", ".", "zeros_like", "(", "reward", "[", ":", ",", "1", "]", ")", ",", "\n", "back_prop", "=", "False", ")", "\n", "disc_reward", "=", "tf", ".", "reverse", "(", "\n", "tf", ".", "transpose", "(", "rev_reward_T_cum", ",", "[", "1", ",", "0", "]", ")", ",", "[", "1", "]", ")", "\n", "\n", "", "return", "disc_reward", "\n", "", ""]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.losses.rewards_test.RewardTest.test_discount_reward": [[25, 75], ["numpy.ones", "texar.losses.rewards.discount_reward", "texar.losses.rewards.discount_reward", "texar.losses.rewards.discount_reward", "texar.losses.rewards.discount_reward", "numpy.ones", "texar.losses.rewards.discount_reward", "texar.losses.rewards.discount_reward", "texar.losses.rewards.discount_reward", "texar.losses.rewards.discount_reward", "tensorflow.constant", "tensorflow.constant", "rewards_test.RewardTest.test_session", "sess.run", "sess.run", "numpy.testing.assert_array_equal", "numpy.testing.assert_array_equal", "tensorflow.constant", "tensorflow.constant", "rewards_test.RewardTest.test_session", "sess.run", "sess.run", "numpy.testing.assert_array_equal", "numpy.testing.assert_array_equal", "tensorflow.global_variables_initializer", "tensorflow.global_variables_initializer"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.losses.rewards.discount_reward", "home.repos.pwc.inspect_result.VegB_Text_Infilling.losses.rewards.discount_reward", "home.repos.pwc.inspect_result.VegB_Text_Infilling.losses.rewards.discount_reward", "home.repos.pwc.inspect_result.VegB_Text_Infilling.losses.rewards.discount_reward", "home.repos.pwc.inspect_result.VegB_Text_Infilling.losses.rewards.discount_reward", "home.repos.pwc.inspect_result.VegB_Text_Infilling.losses.rewards.discount_reward", "home.repos.pwc.inspect_result.VegB_Text_Infilling.losses.rewards.discount_reward", "home.repos.pwc.inspect_result.VegB_Text_Infilling.losses.rewards.discount_reward"], ["def", "test_discount_reward", "(", "self", ")", ":", "\n", "        ", "\"\"\"Tests :func:`texar.losses.rewards.discount_reward`\n        \"\"\"", "\n", "# 1D", "\n", "reward", "=", "np", ".", "ones", "(", "[", "2", "]", ",", "dtype", "=", "np", ".", "float64", ")", "\n", "sequence_length", "=", "[", "3", ",", "5", "]", "\n", "\n", "discounted_reward", "=", "discount_reward", "(", "\n", "reward", ",", "sequence_length", ",", "discount", "=", "1.", ")", "\n", "discounted_reward_n", "=", "discount_reward", "(", "\n", "reward", ",", "sequence_length", ",", "discount", "=", ".1", ",", "normalize", "=", "True", ")", "\n", "\n", "discounted_reward_", "=", "discount_reward", "(", "\n", "tf", ".", "constant", "(", "reward", ",", "dtype", "=", "tf", ".", "float64", ")", ",", "\n", "sequence_length", ",", "discount", "=", "1.", ")", "\n", "discounted_reward_n_", "=", "discount_reward", "(", "\n", "tf", ".", "constant", "(", "reward", ",", "dtype", "=", "tf", ".", "float64", ")", ",", "\n", "sequence_length", ",", "discount", "=", ".1", ",", "normalize", "=", "True", ")", "\n", "\n", "with", "self", ".", "test_session", "(", ")", "as", "sess", ":", "\n", "            ", "sess", ".", "run", "(", "tf", ".", "global_variables_initializer", "(", ")", ")", "\n", "\n", "r", ",", "r_n", "=", "sess", ".", "run", "(", "[", "discounted_reward_", ",", "discounted_reward_n_", "]", ")", "\n", "\n", "np", ".", "testing", ".", "assert_array_equal", "(", "discounted_reward", ",", "r", ")", "\n", "np", ".", "testing", ".", "assert_array_equal", "(", "discounted_reward_n", ",", "r_n", ")", "\n", "\n", "# 2D", "\n", "", "reward", "=", "np", ".", "ones", "(", "[", "2", ",", "10", "]", ",", "dtype", "=", "np", ".", "float64", ")", "\n", "sequence_length", "=", "[", "5", ",", "10", "]", "\n", "\n", "discounted_reward", "=", "discount_reward", "(", "\n", "reward", ",", "sequence_length", ",", "discount", "=", "1.", ")", "\n", "discounted_reward_n", "=", "discount_reward", "(", "\n", "reward", ",", "sequence_length", ",", "discount", "=", ".1", ",", "normalize", "=", "True", ")", "\n", "\n", "discounted_reward_", "=", "discount_reward", "(", "\n", "tf", ".", "constant", "(", "reward", ",", "dtype", "=", "tf", ".", "float64", ")", ",", "sequence_length", ",", "\n", "discount", "=", "1.", ",", "tensor_rank", "=", "2", ")", "\n", "discounted_reward_n_", "=", "discount_reward", "(", "\n", "tf", ".", "constant", "(", "reward", ",", "dtype", "=", "tf", ".", "float64", ")", ",", "sequence_length", ",", "\n", "discount", "=", ".1", ",", "tensor_rank", "=", "2", ",", "normalize", "=", "True", ")", "\n", "\n", "with", "self", ".", "test_session", "(", ")", "as", "sess", ":", "\n", "            ", "sess", ".", "run", "(", "tf", ".", "global_variables_initializer", "(", ")", ")", "\n", "\n", "r", ",", "r_n", "=", "sess", ".", "run", "(", "[", "discounted_reward_", ",", "discounted_reward_n_", "]", ")", "\n", "\n", "np", ".", "testing", ".", "assert_array_equal", "(", "discounted_reward", ",", "r", ")", "\n", "np", ".", "testing", ".", "assert_array_equal", "(", "discounted_reward_n", ",", "r_n", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.losses.rewards_test.RewardTest.test_discount_reward_py_1d": [[76, 103], ["numpy.ones", "texar.losses.rewards._discount_reward_py_1d", "texar.losses.rewards._discount_reward_py_1d", "range", "range", "rewards_test.RewardTest.assertEqual", "rewards_test.RewardTest.assertAlmostEqual", "rewards_test.RewardTest.assertEqual", "rewards_test.RewardTest.assertEqual", "rewards_test.RewardTest.assertAlmostEqual", "rewards_test.RewardTest.assertAlmostEqual"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.losses.rewards._discount_reward_py_1d", "home.repos.pwc.inspect_result.VegB_Text_Infilling.losses.rewards._discount_reward_py_1d"], ["", "", "def", "test_discount_reward_py_1d", "(", "self", ")", ":", "\n", "        ", "\"\"\"Tests :func:`texar.losses.rewards._discount_reward_py_1d`\n        \"\"\"", "\n", "reward", "=", "np", ".", "ones", "(", "[", "2", "]", ",", "dtype", "=", "np", ".", "float64", ")", "\n", "sequence_length", "=", "[", "3", ",", "5", "]", "\n", "\n", "discounted_reward_1", "=", "_discount_reward_py_1d", "(", "\n", "reward", ",", "sequence_length", ",", "discount", "=", "1.", ")", "\n", "\n", "discounted_reward_2", "=", "_discount_reward_py_1d", "(", "\n", "reward", ",", "sequence_length", ",", "discount", "=", ".1", ")", "\n", "\n", "r", "=", "discounted_reward_1", "\n", "for", "i", "in", "range", "(", "5", ")", ":", "\n", "            ", "if", "i", "<", "3", ":", "\n", "                ", "self", ".", "assertEqual", "(", "r", "[", "0", ",", "i", "]", ",", "1", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "assertEqual", "(", "r", "[", "0", ",", "i", "]", ",", "0", ")", "\n", "", "self", ".", "assertEqual", "(", "r", "[", "1", ",", "i", "]", ",", "1", ")", "\n", "\n", "", "r", "=", "discounted_reward_2", "\n", "for", "i", "in", "range", "(", "5", ")", ":", "\n", "            ", "if", "i", "<", "3", ":", "\n", "                ", "self", ".", "assertAlmostEqual", "(", "r", "[", "0", ",", "i", "]", ",", "0.1", "**", "(", "2", "-", "i", ")", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "assertAlmostEqual", "(", "r", "[", "0", ",", "i", "]", ",", "0", ")", "\n", "", "self", ".", "assertAlmostEqual", "(", "r", "[", "1", ",", "i", "]", ",", "0.1", "**", "(", "4", "-", "i", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.losses.rewards_test.RewardTest.test_discount_reward_tensor_1d": [[104, 134], ["tensorflow.ones", "texar.losses.rewards._discount_reward_tensor_1d", "texar.losses.rewards._discount_reward_tensor_1d", "rewards_test.RewardTest.test_session", "sess.run", "sess.run", "range", "sess.run", "range", "tensorflow.global_variables_initializer", "rewards_test.RewardTest.assertEqual", "rewards_test.RewardTest.assertAlmostEqual", "rewards_test.RewardTest.assertEqual", "rewards_test.RewardTest.assertEqual", "rewards_test.RewardTest.assertAlmostEqual", "rewards_test.RewardTest.assertAlmostEqual"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.losses.rewards._discount_reward_tensor_1d", "home.repos.pwc.inspect_result.VegB_Text_Infilling.losses.rewards._discount_reward_tensor_1d"], ["", "", "def", "test_discount_reward_tensor_1d", "(", "self", ")", ":", "\n", "        ", "\"\"\"Tests :func:`texar.losses.rewards._discount_reward_tensor_1d`\n        \"\"\"", "\n", "reward", "=", "tf", ".", "ones", "(", "[", "2", "]", ",", "dtype", "=", "tf", ".", "float64", ")", "\n", "sequence_length", "=", "[", "3", ",", "5", "]", "\n", "\n", "discounted_reward_1", "=", "_discount_reward_tensor_1d", "(", "\n", "reward", ",", "sequence_length", ",", "discount", "=", "1.", ")", "\n", "\n", "discounted_reward_2", "=", "_discount_reward_tensor_1d", "(", "\n", "reward", ",", "sequence_length", ",", "discount", "=", ".1", ")", "\n", "\n", "with", "self", ".", "test_session", "(", ")", "as", "sess", ":", "\n", "            ", "sess", ".", "run", "(", "tf", ".", "global_variables_initializer", "(", ")", ")", "\n", "\n", "r", "=", "sess", ".", "run", "(", "discounted_reward_1", ")", "\n", "for", "i", "in", "range", "(", "5", ")", ":", "\n", "                ", "if", "i", "<", "3", ":", "\n", "                    ", "self", ".", "assertEqual", "(", "r", "[", "0", ",", "i", "]", ",", "1", ")", "\n", "", "else", ":", "\n", "                    ", "self", ".", "assertEqual", "(", "r", "[", "0", ",", "i", "]", ",", "0", ")", "\n", "", "self", ".", "assertEqual", "(", "r", "[", "1", ",", "i", "]", ",", "1", ")", "\n", "\n", "", "r", "=", "sess", ".", "run", "(", "discounted_reward_2", ")", "\n", "for", "i", "in", "range", "(", "5", ")", ":", "\n", "                ", "if", "i", "<", "3", ":", "\n", "                    ", "self", ".", "assertAlmostEqual", "(", "r", "[", "0", ",", "i", "]", ",", "0.1", "**", "(", "2", "-", "i", ")", ")", "\n", "", "else", ":", "\n", "                    ", "self", ".", "assertAlmostEqual", "(", "r", "[", "0", ",", "i", "]", ",", "0", ")", "\n", "", "self", ".", "assertAlmostEqual", "(", "r", "[", "1", ",", "i", "]", ",", "0.1", "**", "(", "4", "-", "i", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.losses.rewards_test.RewardTest.test_discount_reward_py_2d": [[135, 162], ["numpy.ones", "texar.losses.rewards._discount_reward_py_2d", "texar.losses.rewards._discount_reward_py_2d", "range", "range", "rewards_test.RewardTest.assertEqual", "rewards_test.RewardTest.assertEqual", "rewards_test.RewardTest.assertEqual", "rewards_test.RewardTest.assertEqual", "rewards_test.RewardTest.assertEqual", "rewards_test.RewardTest.assertEqual", "int", "int"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.losses.rewards._discount_reward_py_2d", "home.repos.pwc.inspect_result.VegB_Text_Infilling.losses.rewards._discount_reward_py_2d"], ["", "", "", "def", "test_discount_reward_py_2d", "(", "self", ")", ":", "\n", "        ", "\"\"\"Tests :func:`texar.losses.rewards._discount_reward_py_2d`\n        \"\"\"", "\n", "reward", "=", "np", ".", "ones", "(", "[", "2", ",", "10", "]", ",", "dtype", "=", "np", ".", "float64", ")", "\n", "sequence_length", "=", "[", "5", ",", "10", "]", "\n", "\n", "discounted_reward_1", "=", "_discount_reward_py_2d", "(", "\n", "reward", ",", "sequence_length", ",", "discount", "=", "1.", ")", "\n", "\n", "discounted_reward_2", "=", "_discount_reward_py_2d", "(", "\n", "reward", ",", "sequence_length", ",", "discount", "=", ".1", ")", "\n", "\n", "r", "=", "discounted_reward_1", "\n", "for", "i", "in", "range", "(", "10", ")", ":", "\n", "            ", "if", "i", "<", "5", ":", "\n", "                ", "self", ".", "assertEqual", "(", "r", "[", "0", ",", "i", "]", ",", "5", "-", "i", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "assertEqual", "(", "r", "[", "0", ",", "i", "]", ",", "0", ")", "\n", "", "self", ".", "assertEqual", "(", "r", "[", "1", ",", "i", "]", ",", "10", "-", "i", ")", "\n", "\n", "", "r", "=", "discounted_reward_2", "\n", "for", "i", "in", "range", "(", "10", ")", ":", "\n", "            ", "if", "i", "<", "5", ":", "\n", "                ", "self", ".", "assertEqual", "(", "r", "[", "0", ",", "i", "]", ",", "int", "(", "11111.", "/", "10", "**", "i", ")", "/", "10", "**", "(", "4", "-", "i", ")", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "assertEqual", "(", "r", "[", "0", ",", "i", "]", ",", "0", ")", "\n", "", "self", ".", "assertEqual", "(", "r", "[", "1", ",", "i", "]", ",", "int", "(", "1111111111.", "/", "10", "**", "i", ")", "/", "10", "**", "(", "9", "-", "i", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.losses.rewards_test.RewardTest.test_discount_reward_tensor_2d": [[163, 193], ["tensorflow.ones", "texar.losses.rewards._discount_reward_tensor_2d", "texar.losses.rewards._discount_reward_tensor_2d", "rewards_test.RewardTest.test_session", "sess.run", "sess.run", "range", "sess.run", "range", "tensorflow.global_variables_initializer", "rewards_test.RewardTest.assertEqual", "rewards_test.RewardTest.assertEqual", "rewards_test.RewardTest.assertEqual", "rewards_test.RewardTest.assertEqual", "rewards_test.RewardTest.assertEqual", "rewards_test.RewardTest.assertEqual", "int", "int"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.losses.rewards._discount_reward_tensor_2d", "home.repos.pwc.inspect_result.VegB_Text_Infilling.losses.rewards._discount_reward_tensor_2d"], ["", "", "def", "test_discount_reward_tensor_2d", "(", "self", ")", ":", "\n", "        ", "\"\"\"Tests :func:`texar.losses.rewards._discount_reward_tensor_2d`\n        \"\"\"", "\n", "reward", "=", "tf", ".", "ones", "(", "[", "2", ",", "10", "]", ",", "dtype", "=", "tf", ".", "float64", ")", "\n", "sequence_length", "=", "[", "5", ",", "10", "]", "\n", "\n", "discounted_reward_1", "=", "_discount_reward_tensor_2d", "(", "\n", "reward", ",", "sequence_length", ",", "discount", "=", "1.", ")", "\n", "\n", "discounted_reward_2", "=", "_discount_reward_tensor_2d", "(", "\n", "reward", ",", "sequence_length", ",", "discount", "=", ".1", ")", "\n", "\n", "with", "self", ".", "test_session", "(", ")", "as", "sess", ":", "\n", "            ", "sess", ".", "run", "(", "tf", ".", "global_variables_initializer", "(", ")", ")", "\n", "\n", "r", "=", "sess", ".", "run", "(", "discounted_reward_1", ")", "\n", "for", "i", "in", "range", "(", "10", ")", ":", "\n", "                ", "if", "i", "<", "5", ":", "\n", "                    ", "self", ".", "assertEqual", "(", "r", "[", "0", ",", "i", "]", ",", "5", "-", "i", ")", "\n", "", "else", ":", "\n", "                    ", "self", ".", "assertEqual", "(", "r", "[", "0", ",", "i", "]", ",", "0", ")", "\n", "", "self", ".", "assertEqual", "(", "r", "[", "1", ",", "i", "]", ",", "10", "-", "i", ")", "\n", "\n", "", "r", "=", "sess", ".", "run", "(", "discounted_reward_2", ")", "\n", "for", "i", "in", "range", "(", "10", ")", ":", "\n", "                ", "if", "i", "<", "5", ":", "\n", "                    ", "self", ".", "assertEqual", "(", "r", "[", "0", ",", "i", "]", ",", "int", "(", "11111.", "/", "10", "**", "i", ")", "/", "10", "**", "(", "4", "-", "i", ")", ")", "\n", "", "else", ":", "\n", "                    ", "self", ".", "assertEqual", "(", "r", "[", "0", ",", "i", "]", ",", "0", ")", "\n", "", "self", ".", "assertEqual", "(", "r", "[", "1", ",", "i", "]", ",", "int", "(", "1111111111.", "/", "10", "**", "i", ")", "/", "10", "**", "(", "9", "-", "i", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.losses.pg_losses.pg_loss_with_logits": [[22, 125], ["tensorflow.stop_gradient", "tensorflow.nn.sparse_softmax_cross_entropy_with_logits", "pg_losses.pg_loss_with_log_probs"], "function", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.losses.pg_losses.pg_loss_with_log_probs"], ["def", "pg_loss_with_logits", "(", "actions", ",", "\n", "logits", ",", "\n", "advantages", ",", "\n", "rank", "=", "None", ",", "\n", "batched", "=", "False", ",", "\n", "sequence_length", "=", "None", ",", "\n", "average_across_batch", "=", "True", ",", "\n", "average_across_timesteps", "=", "False", ",", "\n", "average_across_remaining", "=", "False", ",", "\n", "sum_over_batch", "=", "False", ",", "\n", "sum_over_timesteps", "=", "True", ",", "\n", "sum_over_remaining", "=", "True", ",", "\n", "time_major", "=", "False", ")", ":", "\n", "    ", "\"\"\"Policy gradient loss with logits. Used for discrete actions.\n\n    pg_loss = reduce( advantages * -log_prob( actions )  ),\n    where `advantages` and `actions` will not bprop gradients.\n\n    All arguments except :attr:`logits` and :attr:`actions` are the same as\n    :func:`pg_loss_with_log_probs`.\n\n    Args:\n        actions: Tensor of shape\n            `[(batch_size,) max_time, d_3, ..., d_rank]` and of dtype\n            `int32` or `int64`.\n            The rank of the Tensor is specified with :attr:`rank`.\n\n            The batch dimension exists only if :attr:`batched` is `True`.\n\n            The batch and time dimensions\n            are exchanged, i.e., `[max_time, batch_size, ...]` if\n            :attr:`time_major` is `True`.\n        logits: Unscaled log probabilities of shape\n            `[(batch_size,) max_time, d_3, ..., d_{rank+1}]`\n            and dtype `float32` or `float64`.\n\n            The batch and time dimensions are exchanged if :attr:`time_major`\n            is `True`.\n        advantages: Tensor of shape\n            `[(batch_size,) max_time, d_3, ..., d_rank]` and\n            dtype `float32` or `float64`.\n\n            The batch and time dimensions are exchanged if :attr:`time_major`\n            is `True`.\n        rank (int, optional): The rank of :attr:`actions`.\n            If `None` (default), rank is automatically inferred from\n            :attr:`actions` or :attr:`advantages`. If the inferred rank is\n            `None`, :attr:`rank` is set to 1 if :attr:`batched` is `False`,\n            and :attr:`rank`=2 if :attr:`batched` is `True`.\n        batched (bool): `True` if the inputs are batched.\n        sequence_length (optional): A Tensor of shape `[batch_size]`.\n            Time steps beyond the respective sequence lengths will have zero\n            losses. Used if :attr:`batched` is `True`.\n        average_across_timesteps (bool): If set, average the loss across\n            the time dimension. Must not set :attr:`average_across_timesteps`\n            and :attr:`sum_over_timesteps` at the same time.\n        average_across_batch (bool): If set, average the loss across the\n            batch dimension. Must not set :attr:`average_across_batch`'\n            and :attr:`sum_over_batch` at the same time.\n            Ignored if :attr:`batched` is `False`.\n        average_across_remaining (bool): If set, average the sequence across the\n            remaining dimensions. Must not set :attr:`average_across_remaining`'\n            and :attr:`sum_over_remaining` at the same time. Ignored if\n            no more dimensions other than the batch and time dimensions.\n        sum_over_timesteps (bool): If set, sum the loss across the\n            time dimension. Must not set :attr:`average_across_timesteps`\n            and :attr:`sum_over_timesteps` at the same time.\n        sum_over_batch (bool): If set, sum the loss across the\n            batch dimension. Must not set :attr:`average_across_batch`\n            and :attr:`sum_over_batch` at the same time.\n            Ignored if :attr:`batched` is `False`.\n        sum_over_remaining (bool): If set, sum the loss across the\n            remaining dimension. Must not set :attr:`average_across_remaining`\n            and :attr:`sum_over_remaining` at the same time. Ignored if\n            no more dimensions other than the batch and time dimensions.\n        time_major (bool): The shape format of the inputs. If `True`,\n            :attr:`logits`, :attr:`actions` and :attr:`advantages` must\n            have shape `[max_time, batch_size, ...]`. If `False` (default),\n            they must have shape `[batch_size, max_time, ...]`.\n            Ignored if :attr:`batched` is `False`.\n\n    Returns:\n        A Tensor containing the loss to minimize, whose rank depends on the\n        reduce arguments. For example, the batch dimension is reduced if\n        either :attr:`average_across_batch` or :attr:`sum_over_batch` is\n        `True`, which makes the rank of output tensor decrease by 1.\n    \"\"\"", "\n", "actions", "=", "tf", ".", "stop_gradient", "(", "actions", ")", "\n", "neg_log_probs", "=", "tf", ".", "nn", ".", "sparse_softmax_cross_entropy_with_logits", "(", "\n", "logits", "=", "logits", ",", "labels", "=", "actions", ")", "\n", "return", "pg_loss_with_log_probs", "(", "\n", "log_probs", "=", "-", "neg_log_probs", ",", "\n", "advantages", "=", "advantages", ",", "\n", "rank", "=", "rank", ",", "\n", "batched", "=", "batched", ",", "\n", "sequence_length", "=", "sequence_length", ",", "\n", "average_across_batch", "=", "average_across_batch", ",", "\n", "average_across_timesteps", "=", "average_across_timesteps", ",", "\n", "average_across_remaining", "=", "average_across_remaining", ",", "\n", "sum_over_batch", "=", "sum_over_batch", ",", "\n", "sum_over_timesteps", "=", "sum_over_timesteps", ",", "\n", "sum_over_remaining", "=", "sum_over_remaining", ",", "\n", "time_major", "=", "time_major", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.losses.pg_losses.pg_loss_with_log_probs": [[126, 249], ["tensorflow.stop_gradient", "texar.losses.losses_utils.mask_and_reduce", "texar.utils.shapes.get_rank", "texar.utils.shapes.get_rank", "ValueError", "tensorflow.reduce_mean", "ValueError", "tensorflow.reduce_mean", "tensorflow.reduce_mean", "tensorflow.reduce_sum", "range", "range"], "function", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.losses.losses_utils.mask_and_reduce", "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.shapes.get_rank", "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.shapes.get_rank"], ["", "def", "pg_loss_with_log_probs", "(", "log_probs", ",", "\n", "advantages", ",", "\n", "rank", "=", "None", ",", "\n", "batched", "=", "False", ",", "\n", "sequence_length", "=", "None", ",", "\n", "average_across_batch", "=", "True", ",", "\n", "average_across_timesteps", "=", "False", ",", "\n", "average_across_remaining", "=", "False", ",", "\n", "sum_over_batch", "=", "False", ",", "\n", "sum_over_timesteps", "=", "True", ",", "\n", "sum_over_remaining", "=", "True", ",", "\n", "time_major", "=", "False", ")", ":", "\n", "    ", "\"\"\"Policy gradient loss with log probs of actions.\n\n    pg_loss = reduce( advantages * -log_probs ),\n    where `advantages` will not bprop gradients.\n\n    All arguments except :attr:`log_probs` are the same as\n    :func:`pg_loss_with_logits`.\n\n    Args:\n        log_probs: Log probabilities of shape\n            `[(batch_size,) max_time, ..., d_rank]` and dtype `float32`\n            or `float64`. The rank of the Tensor is specified\n            with :attr:`rank`.\n\n            The batch dimension exists only if :attr:`batched` is `True`.\n\n            The batch and time dimensions are exchanged, i.e.,\n            `[max_time, batch_size, ...]` if :attr:`time_major` is `True`.\n        advantages: Tensor of shape\n            `[(batch_size,) max_time, d_3, ..., d_rank]` and\n            dtype `float32` or `float64`.\n\n            The batch dimension exists only if\n            :attr:`batched` is `True`.\n\n            The batch and time dimensions\n            are exchanged, i.e., `[max_time, batch_size, ...]` if\n            :attr:`time_major` is `True`.\n        rank (int, optional): The rank of :attr:`log_probs`.\n            If `None` (default), rank is automatically inferred from\n            :attr:`log_probs` or :attr:`advantages`. If the inferred rank is\n            `None`, :attr:`rank` is set to 1 if :attr:`batched``==False`,\n            and :attr:`rank`=2 if :attr:`batched``==True`.\n        batched (bool): `True` if the inputs are batched.\n        sequence_length (optional): A Tensor of shape `[batch_size]`.\n            Time steps beyond the respective sequence lengths will have zero\n            losses. Used if :attr:`batched` is `True`.\n        average_across_timesteps (bool): If set, average the loss across\n            the time dimension. Must not set :attr:`average_across_timesteps`\n            and :attr:`sum_over_timesteps` at the same time.\n        average_across_batch (bool): If set, average the loss across the\n            batch dimension. Must not set :attr:`average_across_batch`'\n            and :attr:`sum_over_batch` at the same time.\n            Ignored if :attr:`batched` is `False`.\n        average_across_remaining (bool): If set, average the sequence across the\n            remaining dimensions. Must not set :attr:`average_across_remaining`'\n            and :attr:`sum_over_remaining` at the same time. Ignored if\n            no more dimensions other than the batch and time dimensions.\n        sum_over_timesteps (bool): If set, sum the loss across the\n            time dimension. Must not set :attr:`average_across_timesteps`\n            and :attr:`sum_over_timesteps` at the same time.\n        sum_over_batch (bool): If set, sum the loss across the\n            batch dimension. Must not set :attr:`average_across_batch`\n            and :attr:`sum_over_batch` at the same time.\n            Ignored if :attr:`batched` is `False`.\n        sum_over_remaining (bool): If set, sum the loss across the\n            remaining dimension. Must not set :attr:`average_across_remaining`\n            and :attr:`sum_over_remaining` at the same time. Ignored if\n            no more dimensions other than the batch and time dimensions.\n        time_major (bool): The shape format of the inputs. If `True`,\n            :attr:`log_probs` and :attr:`advantages` must have shape\n            `[max_time, batch_size, ...]`. If `False` (default),\n            they must have shape `[batch_size, max_time, ...]`.\n            Ignored if :attr:`batched` is `False`.\n\n    Returns:\n        A Tensor containing the loss to minimize, whose rank depends on the\n        reduce arguments. For example, the batch dimension is reduced if\n        either :attr:`average_across_batch` or :attr:`sum_over_batch` is\n        `True`, which makes the rank of output tensor decrease by 1.\n    \"\"\"", "\n", "advantages", "=", "tf", ".", "stop_gradient", "(", "advantages", ")", "\n", "\n", "losses", "=", "-", "log_probs", "*", "advantages", "\n", "\n", "if", "rank", "is", "None", ":", "\n", "        ", "rank", "=", "get_rank", "(", "log_probs", ")", "or", "get_rank", "(", "advantages", ")", "\n", "", "if", "rank", "is", "None", ":", "\n", "        ", "rank", "=", "2", "if", "batched", "else", "1", "\n", "\n", "", "if", "batched", ":", "\n", "        ", "losses", "=", "mask_and_reduce", "(", "\n", "losses", ",", "\n", "sequence_length", ",", "\n", "rank", "=", "rank", ",", "\n", "average_across_batch", "=", "average_across_batch", ",", "\n", "average_across_timesteps", "=", "average_across_timesteps", ",", "\n", "average_across_remaining", "=", "average_across_remaining", ",", "\n", "sum_over_batch", "=", "sum_over_batch", ",", "\n", "sum_over_timesteps", "=", "sum_over_timesteps", ",", "\n", "sum_over_remaining", "=", "sum_over_remaining", ",", "\n", "time_major", "=", "time_major", ")", "\n", "", "elif", "rank", ">", "1", ":", "\n", "        ", "if", "average_across_remaining", "and", "sum_over_remaining", ":", "\n", "            ", "raise", "ValueError", "(", "\"Only one of `average_across_remaining` and \"", "\n", "\"`sum_over_remaining` can be set.\"", ")", "\n", "", "if", "average_across_remaining", ":", "\n", "            ", "losses", "=", "tf", ".", "reduce_mean", "(", "losses", ",", "axis", "=", "range", "(", "1", ",", "rank", ")", ")", "\n", "", "elif", "sum_over_remaining", ":", "\n", "            ", "losses", "=", "tf", ".", "reduce_sum", "(", "losses", ",", "axis", "=", "range", "(", "1", ",", "rank", ")", ")", "\n", "\n", "", "", "if", "not", "batched", ":", "\n", "        ", "if", "average_across_timesteps", "and", "sum_over_timesteps", ":", "\n", "            ", "raise", "ValueError", "(", "\"Only one of `average_across_timesteps` and \"", "\n", "\"`sum_over_timesteps` can be set.\"", ")", "\n", "", "if", "average_across_timesteps", ":", "\n", "            ", "losses", "=", "tf", ".", "reduce_mean", "(", "losses", ")", "\n", "", "elif", "sum_over_timesteps", ":", "\n", "            ", "losses", "=", "tf", ".", "reduce_mean", "(", "losses", ")", "\n", "\n", "", "", "return", "losses", "\n", "", ""]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.losses.mle_losses.sequence_softmax_cross_entropy": [[26, 106], ["tensorflow.name_scope", "tensorflow.nn.softmax_cross_entropy_with_logits_v2", "texar.losses.losses_utils.mask_and_reduce", "tensorflow.stop_gradient"], "function", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.losses.losses_utils.mask_and_reduce"], ["def", "sequence_softmax_cross_entropy", "(", "labels", ",", "\n", "logits", ",", "\n", "sequence_length", ",", "\n", "average_across_batch", "=", "True", ",", "\n", "average_across_timesteps", "=", "False", ",", "\n", "sum_over_batch", "=", "False", ",", "\n", "sum_over_timesteps", "=", "True", ",", "\n", "time_major", "=", "False", ",", "\n", "stop_gradient_to_label", "=", "False", ",", "\n", "name", "=", "None", ")", ":", "\n", "    ", "\"\"\"Computes softmax cross entropy for each time step of sequence\n    predictions.\n\n    Args:\n        labels: Target class distributions.\n\n            If :attr:`time_major` is `False` (default), this must be a\n                Tensor of shape `[batch_size, max_time, num_classes]`.\n\n            If :attr:`time_major` is `True`, this must be a Tensor of shape\n                `[max_time, batch_size, num_classes]`.\n\n            Each row of :attr:`labels` should be a valid probability\n            distribution, otherwise, the computation of the gradient will be\n            incorrect.\n        logits: Unscaled log probabilities. This must have the shape of\n            `[max_time, batch_size, num_classes]` or\n            `[batch_size, max_time, num_classes]` according to\n            the value of :attr:`time_major`.\n        sequence_length: A Tensor of shape `[batch_size]`. Time steps beyond\n            the respective sequence lengths will have zero losses.\n        average_across_timesteps (bool): If set, average the loss across\n            the time dimension. Must not set :attr:`average_across_timesteps`\n            and :attr:`sum_over_timesteps` at the same time.\n        average_across_batch (bool): If set, average the loss across the\n            batch dimension. Must not set :attr:`average_across_batch`'\n            and :attr:`sum_over_batch` at the same time.\n        sum_over_timesteps (bool): If set, sum the loss across the\n            time dimension. Must not set :attr:`average_across_timesteps`\n            and :attr:`sum_over_timesteps` at the same time.\n        sum_over_batch (bool): If set, sum the loss across the\n            batch dimension. Must not set :attr:`average_across_batch`\n            and :attr:`sum_over_batch` at the same time.\n        time_major (bool): The shape format of the inputs. If `True`,\n            :attr:`labels` and :attr:`logits` must have shape\n            `[max_time, batch_size, ...]`. If `False`\n            (default), they must have shape `[batch_size, max_time, ...]`.\n        stop_gradient_to_label (bool): If set, gradient propagation to\n            :attr:`labels` will be disabled.\n        name (str, optional): A name for the operation.\n\n    Returns:\n        A Tensor containing the loss, of rank 0, 1, or 2 depending on the\n        arguments :attr:`{average_across}/{sum_over}_{timesteps}/{batch}`.\n        For example:\n\n        - If :attr:`sum_over_timesteps` and :attr:`average_across_batch`  \\\n        are `True` (default), the return Tensor is of rank 0.\n\n        - If :attr:`average_across_batch` is `True` and other arguments are \\\n        `False`, the return Tensor is of shape `[max_time]`.\n    \"\"\"", "\n", "with", "tf", ".", "name_scope", "(", "name", ",", "\"sequence_softmax_cross_entropy\"", ")", ":", "\n", "        ", "if", "stop_gradient_to_label", ":", "\n", "            ", "labels", "=", "tf", ".", "stop_gradient", "(", "labels", ")", "\n", "\n", "", "losses", "=", "tf", ".", "nn", ".", "softmax_cross_entropy_with_logits_v2", "(", "\n", "labels", "=", "labels", ",", "logits", "=", "logits", ")", "\n", "\n", "losses", "=", "mask_and_reduce", "(", "\n", "losses", ",", "\n", "sequence_length", ",", "\n", "rank", "=", "2", ",", "\n", "average_across_batch", "=", "average_across_batch", ",", "\n", "average_across_timesteps", "=", "average_across_timesteps", ",", "\n", "sum_over_batch", "=", "sum_over_batch", ",", "\n", "sum_over_timesteps", "=", "sum_over_timesteps", ",", "\n", "time_major", "=", "time_major", ")", "\n", "\n", "return", "losses", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.losses.mle_losses.sequence_sparse_softmax_cross_entropy": [[107, 178], ["tensorflow.name_scope", "tensorflow.nn.sparse_softmax_cross_entropy_with_logits", "texar.losses.losses_utils.mask_and_reduce"], "function", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.losses.losses_utils.mask_and_reduce"], ["", "", "def", "sequence_sparse_softmax_cross_entropy", "(", "labels", ",", "\n", "logits", ",", "\n", "sequence_length", ",", "\n", "average_across_batch", "=", "True", ",", "\n", "average_across_timesteps", "=", "False", ",", "\n", "sum_over_batch", "=", "False", ",", "\n", "sum_over_timesteps", "=", "True", ",", "\n", "time_major", "=", "False", ",", "\n", "name", "=", "None", ")", ":", "\n", "    ", "\"\"\"Computes sparse softmax cross entropy for each time step of sequence\n    predictions.\n\n    Args:\n        labels: Target class indexes. I.e., classes are mutually exclusive\n            (each entry is in exactly one class).\n\n            If :attr:`time_major` is `False` (default), this must be\n                a Tensor of shape `[batch_size, max_time]`.\n\n            If :attr:`time_major` is `True`, this must be a Tensor of shape\n                `[max_time, batch_size].`\n        logits: Unscaled log probabilities. This must have the shape of\n            `[max_time, batch_size, num_classes]` or\n            `[batch_size, max_time, num_classes]` according to\n            the value of :attr:`time_major`.\n        sequence_length: A Tensor of shape `[batch_size]`. Time steps beyond\n            the respective sequence lengths will have zero losses.\n        average_across_timesteps (bool): If set, average the loss across\n            the time dimension. Must not set :attr:`average_across_timesteps`\n            and :attr:`sum_over_timesteps` at the same time.\n        average_across_batch (bool): If set, average the loss across the\n            batch dimension. Must not set :attr:`average_across_batch`'\n            and :attr:`sum_over_batch` at the same time.\n        sum_over_timesteps (bool): If set, sum the loss across the\n            time dimension. Must not set :attr:`average_across_timesteps`\n            and :attr:`sum_over_timesteps` at the same time.\n        sum_over_batch (bool): If set, sum the loss across the\n            batch dimension. Must not set :attr:`average_across_batch`\n            and :attr:`sum_over_batch` at the same time.\n        time_major (bool): The shape format of the inputs. If `True`,\n            :attr:`labels` and :attr:`logits` must have shape\n            `[max_time, batch_size, ...]`. If `False`\n            (default), they must have shape `[batch_size, max_time, ...]`.\n        name (str, optional): A name for the operation.\n\n    Returns:\n        A Tensor containing the loss, of rank 0, 1, or 2 depending on the\n        arguments :attr:`{average_across}/{sum_over}_{timesteps}/{batch}`.\n        For example:\n\n        - If :attr:`sum_over_timesteps` and :attr:`average_across_batch`  \\\n        are `True` (default), the return Tensor is of rank 0.\n\n        - If :attr:`average_across_batch` is `True` and other arguments are \\\n        `False`, the return Tensor is of shape `[max_time]`.\n    \"\"\"", "\n", "with", "tf", ".", "name_scope", "(", "name", ",", "\"sequence_sparse_softmax_cross_entropy\"", ")", ":", "\n", "        ", "losses", "=", "tf", ".", "nn", ".", "sparse_softmax_cross_entropy_with_logits", "(", "\n", "labels", "=", "labels", ",", "logits", "=", "logits", ")", "\n", "\n", "losses", "=", "mask_and_reduce", "(", "\n", "losses", ",", "\n", "sequence_length", ",", "\n", "rank", "=", "2", ",", "\n", "average_across_batch", "=", "average_across_batch", ",", "\n", "average_across_timesteps", "=", "average_across_timesteps", ",", "\n", "sum_over_batch", "=", "sum_over_batch", ",", "\n", "sum_over_timesteps", "=", "sum_over_timesteps", ",", "\n", "time_major", "=", "time_major", ")", "\n", "\n", "return", "losses", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.losses.mle_losses.sequence_sigmoid_cross_entropy": [[179, 276], ["tensorflow.name_scope", "tensorflow.nn.sigmoid_cross_entropy_with_logits", "texar.losses.losses_utils.mask_and_reduce", "tensorflow.stop_gradient", "texar.utils.shapes.get_rank", "texar.utils.shapes.get_rank", "ValueError"], "function", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.losses.losses_utils.mask_and_reduce", "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.shapes.get_rank", "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.shapes.get_rank"], ["", "", "def", "sequence_sigmoid_cross_entropy", "(", "labels", ",", "\n", "logits", ",", "\n", "sequence_length", ",", "\n", "average_across_batch", "=", "True", ",", "\n", "average_across_timesteps", "=", "False", ",", "\n", "average_across_classes", "=", "True", ",", "\n", "sum_over_batch", "=", "False", ",", "\n", "sum_over_timesteps", "=", "True", ",", "\n", "sum_over_classes", "=", "False", ",", "\n", "time_major", "=", "False", ",", "\n", "stop_gradient_to_label", "=", "False", ",", "\n", "name", "=", "None", ")", ":", "\n", "    ", "\"\"\"Computes sigmoid cross entropy for each time step of sequence\n    predictions.\n\n    Args:\n        labels: Target class distributions.\n\n            If :attr:`time_major` is `False` (default), this must be a\n                Tensor of shape `[batch_size, max_time(, num_classes)]`.\n\n            If :attr:`time_major` is `True`, this must be a Tensor of shape\n                `[max_time, batch_size(, num_classes)]`.\n\n            Each row of :attr:`labels` should be a valid probability\n            distribution, otherwise, the computation of the gradient will be\n            incorrect.\n        logits: Unscaled log probabilities having the same shape as with\n            :attr:`labels`.\n        sequence_length: A Tensor of shape `[batch_size]`. Time steps beyond\n            the respective sequence lengths will have zero losses.\n        average_across_timesteps (bool): If set, average the loss across\n            the time dimension. Must not set :attr:`average_across_timesteps`\n            and :attr:`sum_over_timesteps` at the same time.\n        average_across_batch (bool): If set, average the loss across the\n            batch dimension. Must not set :attr:`average_across_batch`'\n            and :attr:`sum_over_batch` at the same time.\n        average_across_classes (bool): If set, average the loss across the\n            class dimension (if exists). Must not set\n            :attr:`average_across_classes`' and :attr:`sum_over_classes` at\n            the same time. Ignored if :attr:`logits` is a 2D Tensor.\n        sum_over_timesteps (bool): If set, sum the loss across the\n            time dimension. Must not set :attr:`average_across_timesteps`\n            and :attr:`sum_over_timesteps` at the same time.\n        sum_over_batch (bool): If set, sum the loss across the\n            batch dimension. Must not set :attr:`average_across_batch`\n            and :attr:`sum_over_batch` at the same time.\n        sum_over_classes (bool): If set, sum the loss across the\n            class dimension. Must not set :attr:`average_across_classes`\n            and :attr:`sum_over_classes` at the same time. Ignored if\n            :attr:`logits` is a 2D Tensor.\n        time_major (bool): The shape format of the inputs. If `True`,\n            :attr:`labels` and :attr:`logits` must have shape\n            `[max_time, batch_size, ...]`. If `False`\n            (default), they must have shape `[batch_size, max_time, ...]`.\n        stop_gradient_to_label (bool): If set, gradient propagation to\n            :attr:`labels` will be disabled.\n        name (str, optional): A name for the operation.\n\n    Returns:\n        A Tensor containing the loss, of rank 0, 1, or 2 depending on the\n        arguments\n        :attr:`{average_across}/{sum_over}_{timesteps}/{batch}/{classes}`.\n        For example, if the class dimension does not exist, and\n\n        - If :attr:`sum_over_timesteps` and :attr:`average_across_batch`  \\\n        are `True` (default), the return Tensor is of rank 0.\n\n        - If :attr:`average_across_batch` is `True` and other arguments are \\\n        `False`, the return Tensor is of shape `[max_time]`.\n    \"\"\"", "\n", "\n", "with", "tf", ".", "name_scope", "(", "name", ",", "\"sequence_sigmoid_cross_entropy\"", ")", ":", "\n", "        ", "if", "stop_gradient_to_label", ":", "\n", "            ", "labels", "=", "tf", ".", "stop_gradient", "(", "labels", ")", "\n", "\n", "", "losses", "=", "tf", ".", "nn", ".", "sigmoid_cross_entropy_with_logits", "(", "\n", "labels", "=", "labels", ",", "logits", "=", "logits", ")", "\n", "\n", "rank", "=", "shapes", ".", "get_rank", "(", "logits", ")", "or", "shapes", ".", "get_rank", "(", "labels", ")", "\n", "if", "rank", "is", "None", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "'Cannot determine the rank of `logits` or `labels`.'", ")", "\n", "\n", "", "losses", "=", "mask_and_reduce", "(", "\n", "losses", ",", "\n", "sequence_length", ",", "\n", "rank", "=", "rank", ",", "\n", "average_across_batch", "=", "average_across_batch", ",", "\n", "average_across_timesteps", "=", "average_across_timesteps", ",", "\n", "average_across_remaining", "=", "average_across_classes", ",", "\n", "sum_over_batch", "=", "sum_over_batch", ",", "\n", "sum_over_timesteps", "=", "sum_over_timesteps", ",", "\n", "sum_over_remaining", "=", "sum_over_classes", ",", "\n", "time_major", "=", "time_major", ")", "\n", "\n", "return", "losses", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.losses.mle_losses.binary_sigmoid_cross_entropy": [[277, 354], ["tensorflow.name_scope", "tensorflow.nn.sigmoid_cross_entropy_with_logits", "texar.losses.losses_utils.reduce_dimensions", "tensorflow.nn.sigmoid_cross_entropy_with_logits", "texar.losses.losses_utils.reduce_dimensions", "tensorflow.ones_like", "tensorflow.zeros_like"], "function", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.losses.losses_utils.reduce_dimensions", "home.repos.pwc.inspect_result.VegB_Text_Infilling.losses.losses_utils.reduce_dimensions"], ["", "", "def", "binary_sigmoid_cross_entropy", "(", "pos_logits", "=", "None", ",", "\n", "neg_logits", "=", "None", ",", "\n", "average_across_batch", "=", "True", ",", "\n", "average_across_classes", "=", "True", ",", "\n", "sum_over_batch", "=", "False", ",", "\n", "sum_over_classes", "=", "False", ",", "\n", "return_pos_neg_losses", "=", "False", ",", "\n", "name", "=", "None", ")", ":", "\n", "    ", "\"\"\"Computes sigmoid cross entropy of binary predictions.\n\n    Args:\n        pos_logits: The logits of predicting positive on positive data. A\n            tensor of shape `[batch_size(, num_classes)]`.\n        neg_logits: The logits of predicting positive on negative data. A\n            tensor of shape `[batch_size(, num_classes)]`.\n        average_across_batch (bool): If set, average the loss across the\n            batch dimension. Must not set :attr:`average_across_batch`'\n            and :attr:`sum_over_batch` at the same time.\n        average_across_classes (bool): If set, average the loss across the\n            class dimension (if exists). Must not set\n            :attr:`average_across_classes`' and :attr:`sum_over_classes` at\n            the same time. Ignored if :attr:`logits` is a 1D Tensor.\n        sum_over_batch (bool): If set, sum the loss across the\n            batch dimension. Must not set :attr:`average_across_batch`\n            and :attr:`sum_over_batch` at the same time.\n        sum_over_classes (bool): If set, sum the loss across the\n            class dimension. Must not set :attr:`average_across_classes`\n            and :attr:`sum_over_classes` at the same time. Ignored if\n            :attr:`logits` is a 2D Tensor.\n        return_pos_neg_losses (bool): If set, additionally returns the losses\n            on :attr:`pos_logits` and :attr:`neg_logits`, respectively.\n        name (str, optional): A name for the operation.\n\n    Returns:\n        By default, a Tensor containing the loss, of rank 0, 1, or 2 depending\n        on the arguments :attr:`{average_across}/{sum_over}_{batch}/{classes}`.\n        For example:\n\n        - If :attr:`sum_over_batch` and :attr:`average_across_classes`  \\\n        are `True` (default), the return Tensor is of rank 0.\n\n        - If  arguments are `False`, the return Tensor is of shape \\\n        `[batch_size(, num_classes)]`.\n\n        If :attr:`return_pos_neg_losses`=`True`, returns a tuple\n        `(loss, pos_loss, neg_loss)`, where :attr:`loss` is the loss above;\n        :attr:`pos_loss` is the loss on :attr:`pos_logits` only; and\n        :attr:`neg_loss` is the loss on :attr:`neg_logits` only. They have\n        `loss = pos_loss + neg_loss`.\n    \"\"\"", "\n", "with", "tf", ".", "name_scope", "(", "name", ",", "\"binary_sigmoid_cross_entropy\"", ")", ":", "\n", "        ", "average_axes", ",", "sum_axes", "=", "[", "]", ",", "[", "]", "\n", "average_axes", "+=", "[", "0", "]", "if", "average_across_batch", "else", "[", "]", "\n", "average_axes", "+=", "[", "1", "]", "if", "average_across_classes", "else", "[", "]", "\n", "sum_axes", "+=", "[", "0", "]", "if", "sum_over_batch", "else", "[", "]", "\n", "sum_axes", "+=", "[", "1", "]", "if", "sum_over_classes", "else", "[", "]", "\n", "\n", "pos_loss", "=", "0", "\n", "if", "pos_logits", "is", "not", "None", ":", "\n", "            ", "pos_loss", "=", "tf", ".", "nn", ".", "sigmoid_cross_entropy_with_logits", "(", "\n", "logits", "=", "pos_logits", ",", "labels", "=", "tf", ".", "ones_like", "(", "pos_logits", ")", ")", "\n", "\n", "pos_loss", "=", "reduce_dimensions", "(", "pos_loss", ",", "average_axes", ",", "sum_axes", ")", "\n", "\n", "", "neg_loss", "=", "0", "\n", "if", "neg_logits", "is", "not", "None", ":", "\n", "            ", "neg_loss", "=", "tf", ".", "nn", ".", "sigmoid_cross_entropy_with_logits", "(", "\n", "logits", "=", "neg_logits", ",", "labels", "=", "tf", ".", "zeros_like", "(", "neg_logits", ")", ")", "\n", "\n", "neg_loss", "=", "reduce_dimensions", "(", "neg_loss", ",", "average_axes", ",", "sum_axes", ")", "\n", "\n", "", "", "loss", "=", "pos_loss", "+", "neg_loss", "\n", "\n", "if", "return_pos_neg_losses", ":", "\n", "        ", "return", "loss", ",", "pos_loss", ",", "neg_loss", "\n", "", "else", ":", "\n", "        ", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.losses.mle_losses.binary_sigmoid_cross_entropy_with_clas": [[355, 433], ["mle_losses.binary_sigmoid_cross_entropy", "clas_fn", "isinstance", "clas_fn", "isinstance"], "function", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.losses.mle_losses.binary_sigmoid_cross_entropy"], ["", "", "def", "binary_sigmoid_cross_entropy_with_clas", "(", "clas_fn", ",", "\n", "pos_inputs", "=", "None", ",", "\n", "neg_inputs", "=", "None", ",", "\n", "average_across_batch", "=", "True", ",", "\n", "average_across_classes", "=", "True", ",", "\n", "sum_over_batch", "=", "False", ",", "\n", "sum_over_classes", "=", "False", ",", "\n", "return_pos_neg_losses", "=", "False", ",", "\n", "name", "=", "None", ")", ":", "\n", "    ", "\"\"\"Computes sigmoid cross entropy of binary classifier.\n\n    Args:\n        clas_fn: A callable takes data (e.g., :attr:`pos_inputs` and\n            :attr:`fake_inputs`) and returns the logits of being positive. The\n            signature of :attr:`clas_fn` must be:\n\n                `logits (, ...) = clas_fn(inputs)`\n\n            That is, the return value of :attr:`clas_fn` can be the logits, or\n            a tuple where the logits are the first element.\n        pos_inputs: The positive data fed into :attr:`clas_fn`.\n        neg_inputs: The negative data fed into :attr:`clas_fn`.\n        average_across_batch (bool): If set, average the loss across the\n            batch dimension. Must not set :attr:`average_across_batch`'\n            and :attr:`sum_over_batch` at the same time.\n        average_across_classes (bool): If set, average the loss across the\n            class dimension (if exists). Must not set\n            :attr:`average_across_classes`' and :attr:`sum_over_classes` at\n            the same time. Ignored if :attr:`logits` is a 1D Tensor.\n        sum_over_batch (bool): If set, sum the loss across the\n            batch dimension. Must not set :attr:`average_across_batch`\n            and :attr:`sum_over_batch` at the same time.\n        sum_over_classes (bool): If set, sum the loss across the\n            class dimension. Must not set :attr:`average_across_classes`\n            and :attr:`sum_over_classes` at the same time. Ignored if\n            :attr:`logits` is a 2D Tensor.\n        return_pos_neg_losses (bool): If set, additionally returns the losses\n            on :attr:`pos_logits` and :attr:`neg_logits`, respectively.\n        name (str, optional): A name for the operation.\n\n    Returns:\n        By default, a Tensor containing the loss, of rank 0, 1, or 2 depending\n        on the arguments :attr:`{average_across}/{sum_over}_{batch}/{classes}`.\n        For example:\n\n        - If :attr:`sum_over_batch` and :attr:`average_across_classes`  \\\n        are `True` (default), the return Tensor is of rank 0.\n\n        - If  arguments are `False`, the return Tensor is of shape \\\n        `[batch_size(, num_classes)]`.\n\n        If :attr:`return_pos_neg_losses`=`True`, returns a tuple\n        `(loss, pos_loss, neg_loss)`, where :attr:`loss` is the loss above;\n        :attr:`pos_loss` is the loss on :attr:`pos_logits` only; and\n        :attr:`neg_loss` is the loss on :attr:`neg_logits` only. They have\n        `loss = pos_loss + neg_loss`.\n    \"\"\"", "\n", "pos_logits", "=", "None", "\n", "if", "pos_inputs", "is", "not", "None", ":", "\n", "        ", "pos_logits", "=", "clas_fn", "(", "pos_inputs", ")", "\n", "if", "isinstance", "(", "pos_logits", ",", "(", "list", ",", "tuple", ")", ")", ":", "\n", "            ", "pos_logits", "=", "pos_logits", "[", "0", "]", "\n", "\n", "", "", "neg_logits", "=", "None", "\n", "if", "neg_inputs", "is", "not", "None", ":", "\n", "        ", "neg_logits", "=", "clas_fn", "(", "neg_inputs", ")", "\n", "if", "isinstance", "(", "neg_logits", ",", "(", "list", ",", "tuple", ")", ")", ":", "\n", "            ", "neg_logits", "=", "neg_logits", "[", "0", "]", "\n", "\n", "", "", "return", "binary_sigmoid_cross_entropy", "(", "\n", "pos_logits", "=", "pos_logits", ",", "\n", "neg_logits", "=", "neg_logits", ",", "\n", "average_across_batch", "=", "average_across_batch", ",", "\n", "average_across_classes", "=", "average_across_classes", ",", "\n", "sum_over_batch", "=", "sum_over_batch", ",", "\n", "sum_over_classes", "=", "sum_over_classes", ",", "\n", "return_pos_neg_losses", "=", "return_pos_neg_losses", ",", "\n", "name", "=", "name", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.text_infilling.self_attn._main": [[37, 332], ["self_attn..load_hyperparams", "texar.data.MonoTextData", "texar.data.MonoTextData", "texar.data.MonoTextData", "texar.data.TrainTestDataIterator", "tx.data.TrainTestDataIterator.get_next", "texar.utils.prepare_template", "texar.modules.WordEmbedder", "texar.modules.TemplateTransformerDecoder", "tensorflow.reduce_mean", "tensorflow.Variable", "tensorflow.train.AdamOptimizer", "tf.train.AdamOptimizer.minimize", "texar.utils.generate_prediction_offsets", "enumerate", "tensorflow.train.Saver", "tensorflow.ConfigProto", "tx.modules.TemplateTransformerDecoder.", "texar.utils.smoothing_cross_entropy", "texar.utils.update_template_pack", "tensorflow.placeholder", "texar.utils.generate_prediction_segment_ids", "tx.modules.TemplateTransformerDecoder.dynamic_decode", "predictions.append", "texar.utils.update_template_pack", "tx.data.TrainTestDataIterator.switch_to_train_data", "os.path.join", "float", "float", "print", "os.remove", "os.remove", "os.remove", "matplotlib.pyplot.figure", "matplotlib.pyplot.plot", "matplotlib.pyplot.ylabel", "matplotlib.pyplot.xlabel", "matplotlib.pyplot.savefig", "matplotlib.pyplot.close", "matplotlib.pyplot.figure", "matplotlib.pyplot.plot", "matplotlib.pyplot.plot", "legends.extend", "matplotlib.pyplot.ylabel", "matplotlib.pyplot.xlabel", "matplotlib.pyplot.legend", "matplotlib.pyplot.savefig", "matplotlib.pyplot.figure", "matplotlib.pyplot.plot", "matplotlib.pyplot.plot", "legends.extend", "matplotlib.pyplot.ylabel", "matplotlib.pyplot.xlabel", "matplotlib.pyplot.legend", "matplotlib.pyplot.savefig", "matplotlib.pyplot.close", "tensorflow.Session", "sess.run", "sess.run", "sess.run", "tensorflow.concat", "tensorflow.to_float", "ValueError", "tx.data.TrainTestDataIterator.switch_to_test_data", "numpy.mean", "numpy.mean", "codecs.open", "codecs.open", "codecs.open", "zip", "tensorflow.global_variables_initializer", "tensorflow.local_variables_initializer", "tensorflow.tables_initializer", "range", "tensorflow.minimum", "session.run", "numpy.exp", "loss_lists.append", "ppl_lists.append", "tx.data.TrainTestDataIterator.switch_to_train_data", "tx.data.TrainTestDataIterator.switch_to_val_data", "cur_sess.run", "numpy.exp", "loss_lists.append", "ppl_lists.append", "texar.utils.fill_template", "zip", "tmpfile.write", "tmptpltfile.write", "tmpreffile.write", "bleu_tool.bleu_wrapper", "bleu_tool.bleu_wrapper", "codecs.open", "zip", "self_attn._main._train_epochs"], "function", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.text_infilling.self_attn_hyperparams.load_hyperparams", "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.data_iterators.FeedableDataIterator.get_next", "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.transformer_utils.prepare_template", "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.transformer_utils.generate_prediction_offsets", "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.transformer_utils.smoothing_cross_entropy", "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.transformer_utils.update_template_pack", "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.transformer_utils.generate_prediction_segment_ids", "home.repos.pwc.inspect_result.VegB_Text_Infilling.decoders.template_transformer_decoder.TemplateTransformerDecoder.dynamic_decode", "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.transformer_utils.update_template_pack", "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.data_iterators.TrainTestDataIterator.switch_to_train_data", "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.transformer_utils.PadRemover.remove", "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.transformer_utils.PadRemover.remove", "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.transformer_utils.PadRemover.remove", "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.data_iterators.TrainTestDataIterator.switch_to_test_data", "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.data_iterators.TrainTestDataIterator.switch_to_train_data", "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.data_iterators.TrainTestDataIterator.switch_to_val_data", "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.transformer_utils.fill_template", "home.repos.pwc.inspect_result.VegB_Text_Infilling.text_infilling.bleu_tool.bleu_wrapper", "home.repos.pwc.inspect_result.VegB_Text_Infilling.text_infilling.bleu_tool.bleu_wrapper"], ["def", "_main", "(", "_", ")", ":", "\n", "    ", "hparams", "=", "self_attn_hyperparams", ".", "load_hyperparams", "(", ")", "\n", "train_dataset_hparams", ",", "valid_dataset_hparams", ",", "test_dataset_hparams", ",", "decoder_hparams", ",", "opt_hparams", ",", "opt_vars", ",", "loss_hparams", ",", "args", "=", "hparams", "[", "'train_dataset_hparams'", "]", ",", "hparams", "[", "'eval_dataset_hparams'", "]", ",", "hparams", "[", "'test_dataset_hparams'", "]", ",", "hparams", "[", "'decoder_hparams'", "]", ",", "hparams", "[", "'opt_hparams'", "]", ",", "hparams", "[", "'opt_vars'", "]", ",", "hparams", "[", "'loss_hparams'", "]", ",", "hparams", "[", "'args'", "]", "\n", "\n", "# Data", "\n", "train_data", "=", "tx", ".", "data", ".", "MonoTextData", "(", "train_dataset_hparams", ")", "\n", "valid_data", "=", "tx", ".", "data", ".", "MonoTextData", "(", "valid_dataset_hparams", ")", "\n", "test_data", "=", "tx", ".", "data", ".", "MonoTextData", "(", "test_dataset_hparams", ")", "\n", "iterator", "=", "tx", ".", "data", ".", "TrainTestDataIterator", "(", "train", "=", "train_data", ",", "\n", "val", "=", "valid_data", ",", "\n", "test", "=", "test_data", ")", "\n", "data_batch", "=", "iterator", ".", "get_next", "(", ")", "\n", "mask_id", "=", "train_data", ".", "vocab", ".", "token_to_id_map_py", "[", "'<m>'", "]", "\n", "boa_id", "=", "train_data", ".", "vocab", ".", "token_to_id_map_py", "[", "'<BOA>'", "]", "\n", "eoa_id", "=", "train_data", ".", "vocab", ".", "token_to_id_map_py", "[", "'<EOA>'", "]", "\n", "eos_id", "=", "train_data", ".", "vocab", ".", "token_to_id_map_py", "[", "'<EOS>'", "]", "\n", "pad_id", "=", "train_data", ".", "vocab", ".", "token_to_id_map_py", "[", "'<PAD>'", "]", "\n", "template_pack", ",", "answer_packs", "=", "tx", ".", "utils", ".", "prepare_template", "(", "data_batch", ",", "args", ",", "mask_id", ",", "boa_id", ",", "eoa_id", ",", "pad_id", ")", "\n", "\n", "# Model architecture", "\n", "embedder", "=", "tx", ".", "modules", ".", "WordEmbedder", "(", "vocab_size", "=", "train_data", ".", "vocab", ".", "size", ",", "\n", "hparams", "=", "args", ".", "word_embedding_hparams", ")", "\n", "decoder", "=", "tx", ".", "modules", ".", "TemplateTransformerDecoder", "(", "embedding", "=", "embedder", ".", "_embedding", ",", "\n", "hparams", "=", "decoder_hparams", ")", "\n", "\n", "cetp_loss", "=", "None", "\n", "cur_template_pack", "=", "template_pack", "\n", "for", "hole", "in", "answer_packs", ":", "\n", "        ", "logits", ",", "preds", "=", "decoder", "(", "decoder_input_pack", "=", "hole", ",", "\n", "template_input_pack", "=", "cur_template_pack", ",", "\n", "encoder_decoder_attention_bias", "=", "None", ",", "\n", "args", "=", "args", ")", "\n", "cur_loss", "=", "tx", ".", "utils", ".", "smoothing_cross_entropy", "(", "\n", "logits", ",", "\n", "hole", "[", "'text_ids'", "]", "[", ":", ",", "1", ":", "]", ",", "\n", "train_data", ".", "vocab", ".", "size", ",", "\n", "loss_hparams", "[", "'label_confidence'", "]", ")", "\n", "cetp_loss", "=", "cur_loss", "if", "cetp_loss", "is", "None", "else", "tf", ".", "concat", "(", "[", "cetp_loss", ",", "cur_loss", "]", ",", "-", "1", ")", "\n", "cur_template_pack", "=", "tx", ".", "utils", ".", "update_template_pack", "(", "cur_template_pack", ",", "\n", "hole", "[", "'text_ids'", "]", "[", ":", ",", "1", ":", "]", ",", "\n", "mask_id", ",", "eoa_id", ",", "pad_id", ")", "\n", "", "cetp_loss", "=", "tf", ".", "reduce_mean", "(", "cetp_loss", ")", "\n", "\n", "global_step", "=", "tf", ".", "Variable", "(", "0", ",", "trainable", "=", "False", ")", "\n", "if", "args", ".", "learning_rate_strategy", "==", "'static'", ":", "\n", "        ", "learning_rate", "=", "tf", ".", "placeholder", "(", "dtype", "=", "tf", ".", "float32", ",", "shape", "=", "(", ")", ",", "name", "=", "'learning_rate'", ")", "\n", "", "elif", "args", ".", "learning_rate_strategy", "==", "'dynamic'", ":", "\n", "        ", "fstep", "=", "tf", ".", "to_float", "(", "global_step", ")", "\n", "learning_rate", "=", "opt_hparams", "[", "'lr_constant'", "]", "*", "args", ".", "hidden_dim", "**", "-", "0.5", "*", "tf", ".", "minimum", "(", "fstep", "**", "-", "0.5", ",", "fstep", "*", "opt_hparams", "[", "'warmup_steps'", "]", "**", "-", "1.5", ")", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "'Unknown learning_rate_strategy: %s, expecting one of '", "\n", "'[\\'static\\', \\'dynamic\\']'", "%", "args", ".", "learning_rate_strategy", ")", "\n", "\n", "", "optimizer", "=", "tf", ".", "train", ".", "AdamOptimizer", "(", "learning_rate", "=", "learning_rate", ",", "\n", "beta1", "=", "opt_hparams", "[", "'Adam_beta1'", "]", ",", "\n", "beta2", "=", "opt_hparams", "[", "'Adam_beta2'", "]", ",", "\n", "epsilon", "=", "opt_hparams", "[", "'Adam_epsilon'", "]", ")", "\n", "train_op", "=", "optimizer", ".", "minimize", "(", "cetp_loss", ",", "global_step", ")", "\n", "\n", "offsets", "=", "tx", ".", "utils", ".", "generate_prediction_offsets", "(", "data_batch", "[", "'text_ids'", "]", ",", "\n", "args", ".", "max_decode_len", "+", "1", ")", "\n", "predictions", "=", "[", "]", "\n", "cur_test_pack", "=", "template_pack", "\n", "for", "idx", ",", "hole", "in", "enumerate", "(", "answer_packs", ")", ":", "\n", "        ", "segment_ids", "=", "tx", ".", "utils", ".", "generate_prediction_segment_ids", "(", "data_batch", "[", "'text_ids'", "]", ",", "\n", "1", ",", "# segment_id will always be 1", "\n", "args", ".", "max_decode_len", "+", "1", ")", "\n", "preds", "=", "decoder", ".", "dynamic_decode", "(", "\n", "template_input_pack", "=", "cur_test_pack", ",", "\n", "encoder_decoder_attention_bias", "=", "None", ",", "\n", "segment_ids", "=", "segment_ids", ",", "\n", "offsets", "=", "offsets", ",", "\n", "bos_id", "=", "boa_id", ",", "\n", "eos_id", "=", "eoa_id", ")", "\n", "predictions", ".", "append", "(", "preds", "[", "'sampled_ids'", "]", "[", ":", ",", "0", "]", ")", "\n", "cur_test_pack", "=", "tx", ".", "utils", ".", "update_template_pack", "(", "cur_test_pack", ",", "\n", "preds", "[", "'sampled_ids'", "]", "[", ":", ",", "0", "]", ",", "\n", "mask_id", ",", "eoa_id", ",", "pad_id", ")", "\n", "\n", "", "def", "_train_epochs", "(", "session", ",", "cur_epoch", ",", "mode", "=", "'train'", ")", ":", "\n", "        ", "iterator", ".", "switch_to_train_data", "(", "session", ")", "\n", "loss_lists", ",", "ppl_lists", "=", "[", "]", ",", "[", "]", "\n", "cnt", "=", "0", "\n", "while", "True", ":", "\n", "            ", "try", ":", "\n", "                ", "fetches", "=", "{", "\n", "'template'", ":", "template_pack", ",", "\n", "'holes'", ":", "answer_packs", ",", "\n", "'step'", ":", "global_step", ",", "\n", "'lr'", ":", "learning_rate", ",", "\n", "'loss'", ":", "cetp_loss", "\n", "}", "\n", "if", "mode", "==", "'train'", ":", "\n", "                    ", "fetches", "[", "'train_op'", "]", "=", "train_op", "\n", "", "feed", "=", "{", "\n", "tx", ".", "context", ".", "global_mode", "(", ")", ":", "tf", ".", "estimator", ".", "ModeKeys", ".", "TRAIN", "if", "mode", "==", "'train'", "\n", "else", "tf", ".", "estimator", ".", "ModeKeys", ".", "EVAL", "\n", "}", "\n", "if", "args", ".", "learning_rate_strategy", "==", "'static'", ":", "\n", "                    ", "feed", "[", "learning_rate", "]", "=", "opt_vars", "[", "'learning_rate'", "]", "\n", "", "rtns", "=", "session", ".", "run", "(", "fetches", ",", "feed_dict", "=", "feed", ")", "\n", "step", ",", "template_", ",", "holes_", ",", "loss", "=", "rtns", "[", "'step'", "]", ",", "rtns", "[", "'template'", "]", ",", "rtns", "[", "'holes'", "]", ",", "rtns", "[", "'loss'", "]", "\n", "ppl", "=", "np", ".", "exp", "(", "loss", ")", "\n", "if", "step", "%", "200", "==", "1", "and", "mode", "==", "'train'", ":", "\n", "                    ", "rst", "=", "'step:%s source:%s loss:%f ppl:%f lr:%f'", "%", "(", "step", ",", "template_", "[", "'text_ids'", "]", ".", "shape", ",", "loss", ",", "ppl", ",", "rtns", "[", "'lr'", "]", ")", "\n", "print", "(", "rst", ")", "\n", "", "loss_lists", ".", "append", "(", "loss", ")", "\n", "ppl_lists", ".", "append", "(", "ppl", ")", "\n", "cnt", "+=", "1", "\n", "if", "mode", "is", "not", "'train'", "and", "cnt", ">=", "50", ":", "\n", "                    ", "break", "\n", "", "", "except", "tf", ".", "errors", ".", "OutOfRangeError", ":", "\n", "                ", "if", "args", ".", "learning_rate_strategy", "==", "'static'", ":", "\n", "                    ", "avg_loss", "=", "np", ".", "average", "(", "loss_list", ")", "\n", "if", "avg_loss", "<", "opt_vars", "[", "'best_train_loss'", "]", ":", "\n", "                        ", "opt_vars", "[", "'best_train_loss'", "]", "=", "avg_loss", "\n", "opt_vars", "[", "'epochs_not_improved'", "]", "=", "0", "\n", "", "else", ":", "\n", "                        ", "opt_vars", "[", "'epochs_not_improved'", "]", "+=", "1", "\n", "", "if", "opt_vars", "[", "'epochs_not_improved'", "]", ">=", "8", "and", "opt_vars", "[", "'decay_time'", "]", "<=", "3", ":", "\n", "                        ", "opt_vars", "[", "'learning_rate'", "]", "*=", "opt_vars", "[", "'lr_decay_rate'", "]", "\n", "print", "(", "\"[LR DECAY]: lr decay to %f at epoch %d\"", "%", "\n", "(", "opt_vars", "[", "'learning_rate'", "]", ",", "cur_epoch", ")", ")", "\n", "opt_vars", "[", "'decay_time'", "]", "+=", "1", "\n", "", "", "break", "\n", "", "", "return", "loss_lists", ",", "ppl_lists", "\n", "\n", "", "def", "_test_epoch", "(", "cur_sess", ",", "cur_epoch", ",", "mode", "=", "'test'", ")", ":", "\n", "        ", "def", "_id2word_map", "(", "id_arrays", ")", ":", "\n", "            ", "return", "[", "' '", ".", "join", "(", "[", "train_data", ".", "vocab", ".", "_id_to_token_map_py", "[", "i", "]", "\n", "for", "i", "in", "sent", "]", ")", "for", "sent", "in", "id_arrays", "]", "\n", "\n", "", "if", "mode", "==", "'test'", ":", "\n", "            ", "iterator", ".", "switch_to_test_data", "(", "cur_sess", ")", "\n", "", "elif", "mode", "==", "'train'", ":", "\n", "            ", "iterator", ".", "switch_to_train_data", "(", "cur_sess", ")", "\n", "", "else", ":", "\n", "            ", "iterator", ".", "switch_to_val_data", "(", "cur_sess", ")", "\n", "", "templates_list", ",", "targets_list", ",", "hypothesis_list", "=", "[", "]", ",", "[", "]", ",", "[", "]", "\n", "cnt", "=", "0", "\n", "loss_lists", ",", "ppl_lists", "=", "[", "]", ",", "[", "]", "\n", "while", "True", ":", "\n", "            ", "try", ":", "\n", "                ", "fetches", "=", "{", "\n", "'data_batch'", ":", "data_batch", ",", "\n", "'predictions'", ":", "predictions", ",", "\n", "'template'", ":", "template_pack", ",", "\n", "'step'", ":", "global_step", ",", "\n", "'loss'", ":", "cetp_loss", "\n", "}", "\n", "feed", "=", "{", "tx", ".", "context", ".", "global_mode", "(", ")", ":", "tf", ".", "estimator", ".", "ModeKeys", ".", "EVAL", "}", "\n", "rtns", "=", "cur_sess", ".", "run", "(", "fetches", ",", "feed_dict", "=", "feed", ")", "\n", "real_templates_", ",", "templates_", ",", "targets_", ",", "predictions_", "=", "rtns", "[", "'template'", "]", "[", "'templates'", "]", ",", "rtns", "[", "'template'", "]", "[", "'text_ids'", "]", ",", "rtns", "[", "'data_batch'", "]", "[", "'text_ids'", "]", ",", "rtns", "[", "'predictions'", "]", "\n", "loss", "=", "rtns", "[", "'loss'", "]", "\n", "ppl", "=", "np", ".", "exp", "(", "loss", ")", "\n", "loss_lists", ".", "append", "(", "loss", ")", "\n", "ppl_lists", ".", "append", "(", "ppl", ")", "\n", "\n", "filled_templates", "=", "tx", ".", "utils", ".", "fill_template", "(", "template_pack", "=", "rtns", "[", "'template'", "]", ",", "\n", "predictions", "=", "rtns", "[", "'predictions'", "]", ",", "\n", "eoa_id", "=", "eoa_id", ",", "pad_id", "=", "pad_id", ",", "eos_id", "=", "eos_id", ")", "\n", "\n", "templates", ",", "targets", ",", "generateds", "=", "_id2word_map", "(", "real_templates_", ".", "tolist", "(", ")", ")", ",", "_id2word_map", "(", "targets_", ")", ",", "_id2word_map", "(", "filled_templates", ")", "\n", "\n", "for", "template", ",", "target", ",", "generated", "in", "zip", "(", "templates", ",", "targets", ",", "generateds", ")", ":", "\n", "                    ", "template", "=", "template", ".", "split", "(", "'<EOS>'", ")", "[", "0", "]", ".", "split", "(", "'<PAD>'", ")", "[", "0", "]", ".", "strip", "(", ")", ".", "split", "(", ")", "\n", "target", "=", "target", ".", "split", "(", "'<EOS>'", ")", "[", "0", "]", ".", "split", "(", "'<PAD>'", ")", "[", "0", "]", ".", "strip", "(", ")", ".", "split", "(", ")", "\n", "got", "=", "generated", ".", "split", "(", "'<EOS>'", ")", "[", "0", "]", ".", "split", "(", "'<PAD>'", ")", "[", "0", "]", ".", "strip", "(", ")", ".", "split", "(", ")", "\n", "templates_list", ".", "append", "(", "template", ")", "\n", "targets_list", ".", "append", "(", "target", ")", "\n", "hypothesis_list", ".", "append", "(", "got", ")", "\n", "\n", "", "cnt", "+=", "1", "\n", "if", "mode", "is", "not", "'test'", "and", "cnt", ">=", "60", ":", "\n", "                    ", "break", "\n", "", "", "except", "tf", ".", "errors", ".", "OutOfRangeError", ":", "\n", "                ", "break", "\n", "\n", "", "", "avg_loss", ",", "avg_ppl", "=", "np", ".", "mean", "(", "loss_lists", ")", ",", "np", ".", "mean", "(", "ppl_lists", ")", "\n", "outputs_tmp_filename", "=", "args", ".", "log_dir", "+", "'epoch{}.beam{}.outputs.tmp'", ".", "format", "(", "cur_epoch", ",", "args", ".", "beam_width", ")", "\n", "template_tmp_filename", "=", "args", ".", "log_dir", "+", "'epoch{}.beam{}.templates.tmp'", ".", "format", "(", "cur_epoch", ",", "args", ".", "beam_width", ")", "\n", "refer_tmp_filename", "=", "os", ".", "path", ".", "join", "(", "args", ".", "log_dir", ",", "'eval_reference.tmp'", ")", "\n", "with", "codecs", ".", "open", "(", "outputs_tmp_filename", ",", "'w+'", ",", "'utf-8'", ")", "as", "tmpfile", ",", "codecs", ".", "open", "(", "template_tmp_filename", ",", "'w+'", ",", "'utf-8'", ")", "as", "tmptpltfile", ",", "codecs", ".", "open", "(", "refer_tmp_filename", ",", "'w+'", ",", "'utf-8'", ")", "as", "tmpreffile", ":", "\n", "            ", "for", "hyp", ",", "tplt", ",", "tgt", "in", "zip", "(", "hypothesis_list", ",", "templates_list", ",", "targets_list", ")", ":", "\n", "                ", "tmpfile", ".", "write", "(", "' '", ".", "join", "(", "hyp", ")", "+", "'\\n'", ")", "\n", "tmptpltfile", ".", "write", "(", "' '", ".", "join", "(", "tplt", ")", "+", "'\\n'", ")", "\n", "tmpreffile", ".", "write", "(", "' '", ".", "join", "(", "tgt", ")", "+", "'\\n'", ")", "\n", "", "", "eval_bleu", "=", "float", "(", "100", "*", "bleu_tool", ".", "bleu_wrapper", "(", "\n", "refer_tmp_filename", ",", "outputs_tmp_filename", ",", "case_sensitive", "=", "True", ")", ")", "\n", "template_bleu", "=", "float", "(", "100", "*", "bleu_tool", ".", "bleu_wrapper", "(", "\n", "refer_tmp_filename", ",", "template_tmp_filename", ",", "case_sensitive", "=", "True", ")", ")", "\n", "print", "(", "'epoch:{} {}_bleu:{} template_bleu:{} {}_loss:{} {}_ppl:{} '", ".", "\n", "format", "(", "cur_epoch", ",", "mode", ",", "eval_bleu", ",", "template_bleu", ",", "mode", ",", "avg_loss", ",", "mode", ",", "avg_ppl", ")", ")", "\n", "os", ".", "remove", "(", "outputs_tmp_filename", ")", "\n", "os", ".", "remove", "(", "template_tmp_filename", ")", "\n", "os", ".", "remove", "(", "refer_tmp_filename", ")", "\n", "if", "args", ".", "save_eval_output", ":", "\n", "            ", "result_filename", "=", "args", ".", "log_dir", "+", "'epoch{}.beam{}.{}.results.bleu{:.3f}'", ".", "format", "(", "cur_epoch", ",", "args", ".", "beam_width", ",", "mode", ",", "eval_bleu", ")", "\n", "with", "codecs", ".", "open", "(", "result_filename", ",", "'w+'", ",", "'utf-8'", ")", "as", "resultfile", ":", "\n", "                ", "for", "tmplt", ",", "tgt", ",", "hyp", "in", "zip", "(", "templates_list", ",", "targets_list", ",", "hypothesis_list", ")", ":", "\n", "                    ", "resultfile", ".", "write", "(", "\"- template: \"", "+", "' '", ".", "join", "(", "tmplt", ")", "+", "'\\n'", ")", "\n", "resultfile", ".", "write", "(", "\"- expected: \"", "+", "' '", ".", "join", "(", "tgt", ")", "+", "'\\n'", ")", "\n", "resultfile", ".", "write", "(", "'- got:      '", "+", "' '", ".", "join", "(", "hyp", ")", "+", "'\\n\\n'", ")", "\n", "", "", "", "return", "{", "\n", "'eval'", ":", "eval_bleu", ",", "\n", "'template'", ":", "template_bleu", "\n", "}", ",", "avg_ppl", "\n", "\n", "", "def", "_draw_train_loss", "(", "epoch", ",", "loss_list", ",", "mode", ")", ":", "\n", "        ", "plt", ".", "figure", "(", "figsize", "=", "(", "14", ",", "10", ")", ")", "\n", "plt", ".", "plot", "(", "loss_list", ",", "'--'", ",", "linewidth", "=", "1", ",", "label", "=", "'loss trend'", ")", "\n", "plt", ".", "ylabel", "(", "'%s till epoch %s'", "%", "(", "mode", ",", "epoch", ")", ")", "\n", "plt", ".", "xlabel", "(", "'every 50 steps, present_rate=%f'", "%", "args", ".", "present_rate", ")", "\n", "plt", ".", "savefig", "(", "args", ".", "log_dir", "+", "'/img/%s_curve.png'", "%", "mode", ")", "\n", "plt", ".", "close", "(", "'all'", ")", "\n", "\n", "", "def", "_draw_bleu", "(", "epoch", ",", "test_bleu", ",", "tplt_bleu", ",", "train_bleu", ",", "train_tplt_bleu", ")", ":", "\n", "        ", "plt", ".", "figure", "(", "figsize", "=", "(", "14", ",", "10", ")", ")", "\n", "legends", "=", "[", "]", "\n", "plt", ".", "plot", "(", "test_bleu", ",", "'--'", ",", "linewidth", "=", "1", ",", "label", "=", "'test bleu'", ")", "\n", "plt", ".", "plot", "(", "tplt_bleu", ",", "'--'", ",", "linewidth", "=", "1", ",", "label", "=", "'template bleu'", ")", "\n", "legends", ".", "extend", "(", "[", "'test bleu'", ",", "'template bleu'", "]", ")", "\n", "plt", ".", "ylabel", "(", "'bleu till epoch {}'", ".", "format", "(", "epoch", ")", ")", "\n", "plt", ".", "xlabel", "(", "'every epoch'", ")", "\n", "plt", ".", "legend", "(", "legends", ",", "loc", "=", "'upper left'", ")", "\n", "plt", ".", "savefig", "(", "args", ".", "log_dir", "+", "'/img/bleu.png'", ")", "\n", "\n", "plt", ".", "figure", "(", "figsize", "=", "(", "14", ",", "10", ")", ")", "\n", "legends", "=", "[", "]", "\n", "plt", ".", "plot", "(", "train_bleu", ",", "'--'", ",", "linewidth", "=", "1", ",", "label", "=", "'train bleu'", ")", "\n", "plt", ".", "plot", "(", "train_tplt_bleu", ",", "'--'", ",", "linewidth", "=", "1", ",", "label", "=", "'train template bleu'", ")", "\n", "legends", ".", "extend", "(", "[", "'train bleu'", ",", "'train template bleu'", "]", ")", "\n", "plt", ".", "ylabel", "(", "'bleu till epoch {}'", ".", "format", "(", "epoch", ")", ")", "\n", "plt", ".", "xlabel", "(", "'every epoch'", ")", "\n", "plt", ".", "legend", "(", "legends", ",", "loc", "=", "'upper left'", ")", "\n", "plt", ".", "savefig", "(", "args", ".", "log_dir", "+", "'/img/train_bleu.png'", ")", "\n", "plt", ".", "close", "(", "'all'", ")", "\n", "\n", "", "eval_saver", "=", "tf", ".", "train", ".", "Saver", "(", "max_to_keep", "=", "5", ")", "\n", "config", "=", "tf", ".", "ConfigProto", "(", ")", "\n", "config", ".", "gpu_options", ".", "allow_growth", "=", "True", "\n", "with", "tf", ".", "Session", "(", "config", "=", "config", ")", "as", "sess", ":", "\n", "        ", "sess", ".", "run", "(", "tf", ".", "global_variables_initializer", "(", ")", ")", "\n", "sess", ".", "run", "(", "tf", ".", "local_variables_initializer", "(", ")", ")", "\n", "sess", ".", "run", "(", "tf", ".", "tables_initializer", "(", ")", ")", "\n", "\n", "loss_list", ",", "ppl_list", ",", "test_ppl_list", "=", "[", "]", ",", "[", "]", ",", "[", "]", "\n", "test_bleu", ",", "tplt_bleu", ",", "train_bleu", ",", "train_tplt_bleu", "=", "[", "]", ",", "[", "]", ",", "[", "]", ",", "[", "]", "\n", "if", "args", ".", "running_mode", "==", "'train_and_evaluate'", ":", "\n", "            ", "for", "epoch", "in", "range", "(", "args", ".", "max_train_epoch", ")", ":", "\n", "# bleu on test set and train set", "\n", "                ", "if", "epoch", "%", "args", ".", "bleu_interval", "==", "0", "or", "epoch", "==", "args", ".", "max_train_epoch", "-", "1", ":", "\n", "                    ", "bleu_scores", ",", "test_ppl", "=", "_test_epoch", "(", "sess", ",", "epoch", ")", "\n", "test_bleu", ".", "append", "(", "bleu_scores", "[", "'eval'", "]", ")", "\n", "tplt_bleu", ".", "append", "(", "bleu_scores", "[", "'template'", "]", ")", "\n", "test_ppl_list", ".", "append", "(", "test_ppl", ")", "\n", "_draw_train_loss", "(", "epoch", ",", "test_ppl_list", ",", "mode", "=", "'test_perplexity'", ")", "\n", "\n", "train_bleu_scores", ",", "_", "=", "_test_epoch", "(", "sess", ",", "epoch", ",", "mode", "=", "'train'", ")", "\n", "train_bleu", ".", "append", "(", "train_bleu_scores", "[", "'eval'", "]", ")", "\n", "train_tplt_bleu", ".", "append", "(", "train_bleu_scores", "[", "'template'", "]", ")", "\n", "_draw_bleu", "(", "epoch", ",", "test_bleu", ",", "tplt_bleu", ",", "train_bleu", ",", "train_tplt_bleu", ")", "\n", "eval_saver", ".", "save", "(", "sess", ",", "args", ".", "log_dir", "+", "'my-model-latest.ckpt'", ")", "\n", "\n", "# train", "\n", "", "losses", ",", "ppls", "=", "_train_epochs", "(", "sess", ",", "epoch", ")", "\n", "loss_list", ".", "extend", "(", "losses", ")", "\n", "ppl_list", ".", "extend", "(", "ppls", ")", "\n", "_draw_train_loss", "(", "epoch", ",", "loss_list", ",", "mode", "=", "'train_loss'", ")", "\n", "_draw_train_loss", "(", "epoch", ",", "ppl_list", ",", "mode", "=", "'perplexity'", ")", "\n", "sys", ".", "stdout", ".", "flush", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.text_infilling.gan._main": [[38, 424], ["gan_hyperparams.load_hyperparams", "texar.data.MonoTextData", "texar.data.MonoTextData", "texar.data.MonoTextData", "texar.data.FeedableDataIterator", "tx.data.FeedableDataIterator.get_next", "texar.utils.prepare_template", "tensorflow.placeholder", "tensorflow.placeholder", "texar.modules.WordEmbedder", "texar.modules.embedders.position_embedders.SinusoidsSegmentalPositionEmbedder", "texar.modules.UnidirectionalRNNEncoder", "texar.modules.BasicPositionalRNNDecoder", "texar.modules.connectors.ForwardConnector", "texar.modules.GumbelSoftmaxEmbeddingHelper", "texar.modules.Conv1DClassifier", "texar.modules.WordEmbedder", "enumerate", "tensorflow.reduce_mean", "tensorflow.reduce_mean", "tensorflow.reduce_mean", "tensorflow.Variable", "texar.utils.collect_trainable_variables", "tensorflow.train.AdamOptimizer", "tf.train.AdamOptimizer.minimize", "texar.utils.collect_trainable_variables", "texar.core.get_train_op", "enumerate", "tensorflow.train.Saver", "tensorflow.ConfigProto", "tensorflow.ones_like", "tx.modules.WordEmbedder.", "position_embedders.SinusoidsSegmentalPositionEmbedder.", "tx.modules.UnidirectionalRNNEncoder.", "tx.modules.connectors.ForwardConnector.", "tx.modules.WordEmbedder.", "tx.modules.BasicPositionalRNNDecoder.set_segment_id", "tx.modules.BasicPositionalRNNDecoder.", "texar.utils.smoothing_cross_entropy", "tx.modules.BasicPositionalRNNDecoder.", "tx.modules.Conv1DClassifier.", "tensorflow.nn.sigmoid_cross_entropy_with_logits", "tx.modules.Conv1DClassifier.", "tensorflow.nn.sigmoid_cross_entropy_with_logits", "texar.utils.update_template_pack", "tensorflow.Variable", "tx.modules.WordEmbedder.", "position_embedders.SinusoidsSegmentalPositionEmbedder.", "tx.modules.UnidirectionalRNNEncoder.", "tx.modules.connectors.ForwardConnector.", "tx.modules.BasicPositionalRNNDecoder.set_segment_id", "tx.modules.BasicPositionalRNNDecoder.", "predictions.append", "texar.utils.update_template_pack", "os.path.join", "float", "float", "print", "os.remove", "os.remove", "os.remove", "matplotlib.pyplot.figure", "matplotlib.pyplot.plot", "matplotlib.pyplot.ylabel", "matplotlib.pyplot.xlabel", "matplotlib.pyplot.savefig", "matplotlib.pyplot.close", "matplotlib.pyplot.figure", "matplotlib.pyplot.plot", "matplotlib.pyplot.plot", "legends.extend", "matplotlib.pyplot.ylabel", "matplotlib.pyplot.xlabel", "matplotlib.pyplot.legend", "matplotlib.pyplot.savefig", "matplotlib.pyplot.figure", "matplotlib.pyplot.plot", "matplotlib.pyplot.plot", "legends.extend", "matplotlib.pyplot.ylabel", "matplotlib.pyplot.xlabel", "matplotlib.pyplot.legend", "matplotlib.pyplot.savefig", "matplotlib.pyplot.close", "tensorflow.Session", "sess.run", "sess.run", "sess.run", "tx.data.FeedableDataIterator.initialize_dataset", "texar.utils.shapes.shape_list", "texar.utils.shapes.shape_list", "tensorflow.concat", "tensorflow.concat", "tensorflow.concat", "tensorflow.to_float", "ValueError", "texar.utils.shapes.shape_list", "texar.utils.shapes.shape_list", "numpy.mean", "numpy.mean", "codecs.open", "codecs.open", "codecs.open", "zip", "tensorflow.global_variables_initializer", "tensorflow.local_variables_initializer", "tensorflow.tables_initializer", "range", "tx.modules.WordEmbedder.", "tensorflow.to_float", "tx.modules.WordEmbedder.", "tensorflow.to_float", "tensorflow.minimum", "session.run", "session.run", "numpy.exp", "loss_lists.append", "ppl_lists.append", "cur_sess.run", "numpy.exp", "loss_lists.append", "ppl_lists.append", "texar.utils.fill_template", "zip", "tmpfile.write", "tmptpltfile.write", "tmpreffile.write", "bleu_tool.bleu_wrapper", "bleu_tool.bleu_wrapper", "codecs.open", "zip", "tx.data.FeedableDataIterator.restart_dataset", "gan._main._train_epochs"], "function", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.text_infilling.self_attn_hyperparams.load_hyperparams", "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.data_iterators.FeedableDataIterator.get_next", "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.transformer_utils.prepare_template", "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.variables.collect_trainable_variables", "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.variables.collect_trainable_variables", "home.repos.pwc.inspect_result.VegB_Text_Infilling.core.optimization.get_train_op", "home.repos.pwc.inspect_result.VegB_Text_Infilling.decoders.rnn_decoders.BasicPositionalRNNDecoder.set_segment_id", "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.transformer_utils.smoothing_cross_entropy", "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.transformer_utils.update_template_pack", "home.repos.pwc.inspect_result.VegB_Text_Infilling.decoders.rnn_decoders.BasicPositionalRNNDecoder.set_segment_id", "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.transformer_utils.update_template_pack", "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.transformer_utils.PadRemover.remove", "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.transformer_utils.PadRemover.remove", "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.transformer_utils.PadRemover.remove", "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.data_iterators.FeedableDataIterator.initialize_dataset", "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.shapes.shape_list", "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.shapes.shape_list", "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.shapes.shape_list", "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.shapes.shape_list", "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.transformer_utils.fill_template", "home.repos.pwc.inspect_result.VegB_Text_Infilling.text_infilling.bleu_tool.bleu_wrapper", "home.repos.pwc.inspect_result.VegB_Text_Infilling.text_infilling.bleu_tool.bleu_wrapper", "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.data_iterators.FeedableDataIterator.restart_dataset"], ["def", "_main", "(", "_", ")", ":", "\n", "    ", "hparams", "=", "gan_hyperparams", ".", "load_hyperparams", "(", ")", "\n", "train_dataset_hparams", ",", "valid_dataset_hparams", ",", "test_dataset_hparams", ",", "encoder_hparams", ",", "decoder_hparams", ",", "classifier_hparams", ",", "opt_hparams", ",", "loss_hparams", ",", "d_opt_hparams", ",", "args", "=", "hparams", "[", "'train_dataset_hparams'", "]", ",", "hparams", "[", "'eval_dataset_hparams'", "]", ",", "hparams", "[", "'test_dataset_hparams'", "]", ",", "hparams", "[", "'encoder_hparams'", "]", ",", "hparams", "[", "'decoder_hparams'", "]", ",", "hparams", "[", "'classifier_hparams'", "]", ",", "hparams", "[", "'opt_hparams'", "]", ",", "hparams", "[", "'loss_hparams'", "]", ",", "hparams", "[", "'d_opt'", "]", ",", "hparams", "[", "'args'", "]", "\n", "\n", "# Data", "\n", "train_data", "=", "tx", ".", "data", ".", "MonoTextData", "(", "train_dataset_hparams", ")", "\n", "valid_data", "=", "tx", ".", "data", ".", "MonoTextData", "(", "valid_dataset_hparams", ")", "\n", "test_data", "=", "tx", ".", "data", ".", "MonoTextData", "(", "test_dataset_hparams", ")", "\n", "iterator", "=", "tx", ".", "data", ".", "FeedableDataIterator", "(", "\n", "{", "'train_g'", ":", "train_data", ",", "'train_d'", ":", "train_data", ",", "\n", "'val'", ":", "valid_data", ",", "'test'", ":", "test_data", "}", ")", "\n", "\n", "data_batch", "=", "iterator", ".", "get_next", "(", ")", "\n", "mask_id", "=", "train_data", ".", "vocab", ".", "token_to_id_map_py", "[", "'<m>'", "]", "\n", "boa_id", "=", "train_data", ".", "vocab", ".", "token_to_id_map_py", "[", "'<BOA>'", "]", "\n", "eoa_id", "=", "train_data", ".", "vocab", ".", "token_to_id_map_py", "[", "'<EOA>'", "]", "\n", "eos_id", "=", "train_data", ".", "vocab", ".", "token_to_id_map_py", "[", "SpecialTokens", ".", "EOS", "]", "\n", "pad_id", "=", "train_data", ".", "vocab", ".", "token_to_id_map_py", "[", "'<PAD>'", "]", "\n", "template_pack", ",", "answer_packs", "=", "tx", ".", "utils", ".", "prepare_template", "(", "data_batch", ",", "args", ",", "mask_id", ",", "boa_id", ",", "eoa_id", ",", "pad_id", ")", "\n", "\n", "gamma", "=", "tf", ".", "placeholder", "(", "dtype", "=", "tf", ".", "float32", ",", "shape", "=", "[", "]", ",", "name", "=", "'gamma'", ")", "\n", "lambda_g", "=", "tf", ".", "placeholder", "(", "dtype", "=", "tf", ".", "float32", ",", "shape", "=", "[", "]", ",", "name", "=", "'lambda_g'", ")", "\n", "\n", "# Model architecture", "\n", "embedder", "=", "tx", ".", "modules", ".", "WordEmbedder", "(", "vocab_size", "=", "train_data", ".", "vocab", ".", "size", ",", "\n", "hparams", "=", "args", ".", "word_embedding_hparams", ")", "\n", "position_embedder", "=", "position_embedders", ".", "SinusoidsSegmentalPositionEmbedder", "(", ")", "\n", "encoder", "=", "tx", ".", "modules", ".", "UnidirectionalRNNEncoder", "(", "hparams", "=", "encoder_hparams", ")", "\n", "decoder", "=", "tx", ".", "modules", ".", "BasicPositionalRNNDecoder", "(", "vocab_size", "=", "train_data", ".", "vocab", ".", "size", ",", "\n", "hparams", "=", "decoder_hparams", ",", "\n", "position_embedder", "=", "position_embedder", ")", "\n", "decoder_initial_state_size", "=", "decoder", ".", "cell", ".", "state_size", "\n", "connector", "=", "tx", ".", "modules", ".", "connectors", ".", "ForwardConnector", "(", "decoder_initial_state_size", ")", "\n", "\n", "start_tokens", "=", "tf", ".", "ones_like", "(", "data_batch", "[", "'length'", "]", ")", "*", "boa_id", "\n", "gumbel_helper", "=", "tx", ".", "modules", ".", "GumbelSoftmaxEmbeddingHelper", "(", "\n", "embedder", ".", "embedding", ",", "start_tokens", ",", "eoa_id", ",", "gamma", ")", "\n", "\n", "# Creates classifier", "\n", "classifier", "=", "tx", ".", "modules", ".", "Conv1DClassifier", "(", "hparams", "=", "classifier_hparams", ")", "\n", "clas_embedder", "=", "tx", ".", "modules", ".", "WordEmbedder", "(", "vocab_size", "=", "train_data", ".", "vocab", ".", "size", ",", "\n", "hparams", "=", "args", ".", "word_embedding_hparams", ")", "\n", "\n", "cetp_loss", ",", "d_class_loss", ",", "g_class_loss", "=", "None", ",", "None", ",", "None", "\n", "cur_template_pack", "=", "template_pack", "\n", "for", "idx", ",", "hole", "in", "enumerate", "(", "answer_packs", ")", ":", "\n", "        ", "template", "=", "cur_template_pack", "[", "'templates'", "]", "\n", "template_word_embeds", "=", "embedder", "(", "template", ")", "\n", "template_length", "=", "shape_list", "(", "template", ")", "[", "1", "]", "\n", "channels", "=", "shape_list", "(", "template_word_embeds", ")", "[", "2", "]", "\n", "template_pos_embeds", "=", "position_embedder", "(", "template_length", ",", "channels", ",", "\n", "cur_template_pack", "[", "'segment_ids'", "]", ",", "\n", "cur_template_pack", "[", "'offsets'", "]", ")", "\n", "enc_input_embedded", "=", "template_word_embeds", "+", "template_pos_embeds", "\n", "\n", "_", ",", "ecdr_states", "=", "encoder", "(", "\n", "enc_input_embedded", ",", "\n", "sequence_length", "=", "data_batch", "[", "\"length\"", "]", ")", "\n", "\n", "dcdr_init_states", "=", "connector", "(", "ecdr_states", ")", "\n", "\n", "dec_input", "=", "hole", "[", "'text_ids'", "]", "[", ":", ",", ":", "-", "1", "]", "\n", "dec_input_word_embeds", "=", "embedder", "(", "dec_input", ")", "\n", "decoder", ".", "set_segment_id", "(", "1", ")", "\n", "dec_input_embedded", "=", "dec_input_word_embeds", "\n", "outputs", ",", "_", ",", "_", "=", "decoder", "(", "\n", "initial_state", "=", "dcdr_init_states", ",", "\n", "decoding_strategy", "=", "\"train_greedy\"", ",", "\n", "inputs", "=", "dec_input_embedded", ",", "\n", "sequence_length", "=", "hole", "[", "\"lengths\"", "]", "+", "1", ")", "\n", "cur_loss", "=", "tx", ".", "utils", ".", "smoothing_cross_entropy", "(", "\n", "outputs", ".", "logits", ",", "\n", "hole", "[", "'text_ids'", "]", "[", ":", ",", "1", ":", "]", ",", "\n", "train_data", ".", "vocab", ".", "size", ",", "\n", "loss_hparams", "[", "'label_confidence'", "]", ",", "\n", ")", "\n", "cetp_loss", "=", "cur_loss", "if", "cetp_loss", "is", "None", "else", "tf", ".", "concat", "(", "[", "cetp_loss", ",", "cur_loss", "]", ",", "-", "1", ")", "\n", "\n", "soft_outputs_", ",", "_", ",", "soft_length_", ",", "=", "decoder", "(", "\n", "helper", "=", "gumbel_helper", ",", "initial_state", "=", "dcdr_init_states", ")", "\n", "\n", "# Classification loss for the classifier", "\n", "clas_logits", ",", "clas_preds", "=", "classifier", "(", "\n", "inputs", "=", "clas_embedder", "(", "ids", "=", "hole", "[", "'text_ids'", "]", "[", ":", ",", "1", ":", "]", ")", ",", "\n", "sequence_length", "=", "hole", "[", "\"lengths\"", "]", "+", "1", ")", "\n", "loss_d_clas", "=", "tf", ".", "nn", ".", "sigmoid_cross_entropy_with_logits", "(", "\n", "labels", "=", "tf", ".", "to_float", "(", "tf", ".", "ones_like", "(", "data_batch", "[", "'length'", "]", ")", ")", ",", "logits", "=", "clas_logits", ")", "\n", "d_class_loss", "=", "loss_d_clas", "if", "d_class_loss", "is", "None", "else", "tf", ".", "concat", "(", "[", "d_class_loss", ",", "loss_d_clas", "]", ",", "-", "1", ")", "\n", "\n", "# Classification loss for the generator, based on soft samples", "\n", "soft_logits", ",", "soft_preds", "=", "classifier", "(", "\n", "inputs", "=", "clas_embedder", "(", "soft_ids", "=", "soft_outputs_", ".", "sample_id", ")", ",", "\n", "sequence_length", "=", "soft_length_", ")", "\n", "loss_g_clas", "=", "tf", ".", "nn", ".", "sigmoid_cross_entropy_with_logits", "(", "\n", "labels", "=", "tf", ".", "to_float", "(", "tf", ".", "zeros_like", "(", "data_batch", "[", "'length'", "]", ")", ")", ",", "logits", "=", "soft_logits", ")", "\n", "g_class_loss", "=", "loss_g_clas", "if", "g_class_loss", "is", "None", "else", "tf", ".", "concat", "(", "[", "g_class_loss", ",", "loss_g_clas", "]", ",", "-", "1", ")", "\n", "\n", "cur_template_pack", "=", "tx", ".", "utils", ".", "update_template_pack", "(", "cur_template_pack", ",", "\n", "hole", "[", "'text_ids'", "]", "[", ":", ",", "1", ":", "]", ",", "\n", "mask_id", ",", "eoa_id", ",", "pad_id", ")", "\n", "", "cetp_loss", "=", "tf", ".", "reduce_mean", "(", "cetp_loss", ")", "\n", "d_class_loss", "=", "tf", ".", "reduce_mean", "(", "d_class_loss", ")", "\n", "g_class_loss", "=", "tf", ".", "reduce_mean", "(", "g_class_loss", ")", "\n", "\n", "global_step", "=", "tf", ".", "Variable", "(", "0", ",", "trainable", "=", "False", ")", "\n", "if", "args", ".", "learning_rate_strategy", "==", "'static'", ":", "\n", "        ", "learning_rate", "=", "tf", ".", "Variable", "(", "1e-3", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "", "elif", "args", ".", "learning_rate_strategy", "==", "'dynamic'", ":", "\n", "        ", "fstep", "=", "tf", ".", "to_float", "(", "global_step", ")", "\n", "learning_rate", "=", "opt_hparams", "[", "'lr_constant'", "]", "*", "args", ".", "hidden_dim", "**", "-", "0.5", "*", "tf", ".", "minimum", "(", "fstep", "**", "-", "0.5", ",", "fstep", "*", "opt_hparams", "[", "'warmup_steps'", "]", "**", "-", "1.5", ")", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "'Unknown learning_rate_strategy: %s, expecting one of '", "\n", "'[\\'static\\', \\'dynamic\\']'", "%", "args", ".", "learning_rate_strategy", ")", "\n", "\n", "", "g_loss", "=", "cetp_loss", "+", "lambda_g", "*", "g_class_loss", "\n", "g_vars", "=", "tx", ".", "utils", ".", "collect_trainable_variables", "(", "\n", "[", "embedder", ",", "encoder", ",", "connector", ",", "decoder", "]", ")", "\n", "optimizer", "=", "tf", ".", "train", ".", "AdamOptimizer", "(", "\n", "learning_rate", "=", "learning_rate", ",", "\n", "beta1", "=", "opt_hparams", "[", "'Adam_beta1'", "]", ",", "\n", "beta2", "=", "opt_hparams", "[", "'Adam_beta2'", "]", ",", "\n", "epsilon", "=", "opt_hparams", "[", "'Adam_epsilon'", "]", ",", "\n", ")", "\n", "train_op", "=", "optimizer", ".", "minimize", "(", "g_loss", ",", "global_step", ",", "var_list", "=", "g_vars", ")", "\n", "\n", "d_loss", "=", "d_class_loss", "\n", "d_vars", "=", "tx", ".", "utils", ".", "collect_trainable_variables", "(", "[", "clas_embedder", ",", "classifier", "]", ")", "\n", "train_op_d", "=", "tx", ".", "core", ".", "get_train_op", "(", "d_loss", ",", "d_vars", ",", "hparams", "=", "d_opt_hparams", ")", "\n", "\n", "# Inference", "\n", "predictions", "=", "[", "]", "\n", "cur_test_pack", "=", "template_pack", "\n", "for", "idx", ",", "hole", "in", "enumerate", "(", "answer_packs", ")", ":", "\n", "        ", "template", "=", "cur_test_pack", "[", "'templates'", "]", "\n", "template_word_embeds", "=", "embedder", "(", "template", ")", "\n", "template_length", "=", "shape_list", "(", "template", ")", "[", "1", "]", "\n", "channels", "=", "shape_list", "(", "template_word_embeds", ")", "[", "2", "]", "\n", "template_pos_embeds", "=", "position_embedder", "(", "template_length", ",", "channels", ",", "\n", "cur_test_pack", "[", "'segment_ids'", "]", ",", "\n", "cur_test_pack", "[", "'offsets'", "]", ")", "\n", "enc_input_embedded", "=", "template_word_embeds", "+", "template_pos_embeds", "\n", "\n", "_", ",", "ecdr_states", "=", "encoder", "(", "\n", "enc_input_embedded", ",", "\n", "sequence_length", "=", "data_batch", "[", "\"length\"", "]", ")", "\n", "\n", "dcdr_init_states", "=", "connector", "(", "ecdr_states", ")", "\n", "\n", "decoder", ".", "set_segment_id", "(", "1", ")", "\n", "outputs_infer", ",", "_", ",", "_", "=", "decoder", "(", "\n", "decoding_strategy", "=", "\"infer_positional\"", ",", "\n", "start_tokens", "=", "start_tokens", ",", "\n", "end_token", "=", "eoa_id", ",", "\n", "embedding", "=", "embedder", ",", "\n", "initial_state", "=", "dcdr_init_states", ")", "\n", "predictions", ".", "append", "(", "outputs_infer", ".", "sample_id", ")", "\n", "cur_test_pack", "=", "tx", ".", "utils", ".", "update_template_pack", "(", "cur_test_pack", ",", "\n", "outputs_infer", ".", "sample_id", ",", "\n", "mask_id", ",", "eoa_id", ",", "pad_id", ")", "\n", "\n", "", "eval_saver", "=", "tf", ".", "train", ".", "Saver", "(", "max_to_keep", "=", "5", ")", "\n", "\n", "def", "_train_epochs", "(", "session", ",", "cur_epoch", ",", "gamma_", ",", "lambda_g_", ")", ":", "\n", "        ", "loss_lists", ",", "ppl_lists", "=", "[", "]", ",", "[", "]", "\n", "while", "True", ":", "\n", "            ", "try", ":", "\n", "                ", "fetches_d", "=", "{", "\n", "'train_op_d'", ":", "train_op_d", ",", "\n", "'d_loss'", ":", "d_loss", "\n", "}", "\n", "feed_d", "=", "{", "\n", "iterator", ".", "handle", ":", "iterator", ".", "get_handle", "(", "sess", ",", "'train_d'", ")", ",", "\n", "gamma", ":", "gamma_", ",", "\n", "lambda_g", ":", "lambda_g_", ",", "\n", "tx", ".", "context", ".", "global_mode", "(", ")", ":", "tf", ".", "estimator", ".", "ModeKeys", ".", "TRAIN", "\n", "}", "\n", "rtns_d", "=", "session", ".", "run", "(", "fetches_d", ",", "feed_dict", "=", "feed_d", ")", "\n", "d_loss_", "=", "rtns_d", "[", "'d_loss'", "]", "\n", "fetches_g", "=", "{", "\n", "'template'", ":", "template_pack", ",", "\n", "'holes'", ":", "answer_packs", ",", "\n", "'train_op'", ":", "train_op", ",", "\n", "'step'", ":", "global_step", ",", "\n", "'lr'", ":", "learning_rate", ",", "\n", "'loss'", ":", "cetp_loss", ",", "\n", "'g_loss'", ":", "g_loss", "\n", "}", "\n", "feed_g", "=", "{", "\n", "iterator", ".", "handle", ":", "iterator", ".", "get_handle", "(", "sess", ",", "'train_g'", ")", ",", "\n", "gamma", ":", "gamma_", ",", "\n", "lambda_g", ":", "lambda_g_", ",", "\n", "tx", ".", "context", ".", "global_mode", "(", ")", ":", "tf", ".", "estimator", ".", "ModeKeys", ".", "TRAIN", "\n", "}", "\n", "rtns", "=", "session", ".", "run", "(", "fetches_g", ",", "feed_dict", "=", "feed_g", ")", "\n", "step", ",", "template_", ",", "holes_", ",", "cetp_loss_", ",", "g_loss_", "=", "rtns", "[", "'step'", "]", ",", "rtns", "[", "'template'", "]", ",", "rtns", "[", "'holes'", "]", ",", "rtns", "[", "'loss'", "]", ",", "rtns", "[", "'g_loss'", "]", "\n", "ppl", "=", "np", ".", "exp", "(", "cetp_loss_", ")", "\n", "if", "step", "%", "200", "==", "1", ":", "\n", "                    ", "rst", "=", "'step:%s source:%s g_loss:%f d_loss:%f ppl:%f lr:%f'", "%", "(", "step", ",", "template_", "[", "'text_ids'", "]", ".", "shape", ",", "g_loss_", ",", "d_loss_", ",", "ppl", ",", "rtns", "[", "'lr'", "]", ")", "\n", "print", "(", "rst", ")", "\n", "", "loss_lists", ".", "append", "(", "g_loss_", ")", "\n", "ppl_lists", ".", "append", "(", "ppl", ")", "\n", "", "except", "tf", ".", "errors", ".", "OutOfRangeError", ":", "\n", "                ", "break", "\n", "", "", "return", "loss_lists", "[", ":", ":", "50", "]", ",", "ppl_lists", "[", ":", ":", "50", "]", "\n", "\n", "", "def", "_test_epoch", "(", "cur_sess", ",", "cur_epoch", ",", "gamma_", ",", "lambda_g_", ",", "mode", "=", "'test'", ")", ":", "\n", "        ", "def", "_id2word_map", "(", "id_arrays", ")", ":", "\n", "            ", "return", "[", "' '", ".", "join", "(", "[", "train_data", ".", "vocab", ".", "_id_to_token_map_py", "[", "i", "]", "\n", "for", "i", "in", "sent", "]", ")", "for", "sent", "in", "id_arrays", "]", "\n", "\n", "", "templates_list", ",", "targets_list", ",", "hypothesis_list", "=", "[", "]", ",", "[", "]", ",", "[", "]", "\n", "cnt", "=", "0", "\n", "loss_lists", ",", "ppl_lists", "=", "[", "]", ",", "[", "]", "\n", "while", "True", ":", "\n", "            ", "try", ":", "\n", "                ", "fetches", "=", "{", "\n", "'data_batch'", ":", "data_batch", ",", "\n", "'predictions'", ":", "predictions", ",", "\n", "'template'", ":", "template_pack", ",", "\n", "'step'", ":", "global_step", ",", "\n", "'loss'", ":", "cetp_loss", "\n", "}", "\n", "feed", "=", "{", "\n", "iterator", ".", "handle", ":", "iterator", ".", "get_handle", "(", "sess", ",", "mode", ")", ",", "\n", "gamma", ":", "gamma_", ",", "\n", "lambda_g", ":", "lambda_g_", ",", "\n", "tx", ".", "context", ".", "global_mode", "(", ")", ":", "tf", ".", "estimator", ".", "ModeKeys", ".", "EVAL", "\n", "}", "\n", "rtns", "=", "cur_sess", ".", "run", "(", "fetches", ",", "feed_dict", "=", "feed", ")", "\n", "real_templates_", ",", "templates_", ",", "targets_", ",", "predictions_", "=", "rtns", "[", "'template'", "]", "[", "'templates'", "]", ",", "rtns", "[", "'template'", "]", "[", "'text_ids'", "]", ",", "rtns", "[", "'data_batch'", "]", "[", "'text_ids'", "]", ",", "rtns", "[", "'predictions'", "]", "\n", "loss", "=", "rtns", "[", "'loss'", "]", "\n", "ppl", "=", "np", ".", "exp", "(", "loss", ")", "\n", "loss_lists", ".", "append", "(", "loss", ")", "\n", "ppl_lists", ".", "append", "(", "ppl", ")", "\n", "\n", "filled_templates", "=", "tx", ".", "utils", ".", "fill_template", "(", "template_pack", "=", "rtns", "[", "'template'", "]", ",", "\n", "predictions", "=", "rtns", "[", "'predictions'", "]", ",", "\n", "eoa_id", "=", "eoa_id", ",", "pad_id", "=", "pad_id", ",", "eos_id", "=", "eos_id", ")", "\n", "\n", "templates", ",", "targets", ",", "generateds", "=", "_id2word_map", "(", "real_templates_", ".", "tolist", "(", ")", ")", ",", "_id2word_map", "(", "targets_", ")", ",", "_id2word_map", "(", "filled_templates", ")", "\n", "\n", "for", "template", ",", "target", ",", "generated", "in", "zip", "(", "templates", ",", "targets", ",", "generateds", ")", ":", "\n", "                    ", "template", "=", "template", ".", "split", "(", "'<EOS>'", ")", "[", "0", "]", ".", "split", "(", "'<PAD>'", ")", "[", "0", "]", ".", "strip", "(", ")", ".", "split", "(", ")", "\n", "target", "=", "target", ".", "split", "(", "'<EOS>'", ")", "[", "0", "]", ".", "split", "(", "'<PAD>'", ")", "[", "0", "]", ".", "strip", "(", ")", ".", "split", "(", ")", "\n", "got", "=", "generated", ".", "split", "(", "'<EOS>'", ")", "[", "0", "]", ".", "split", "(", "'<PAD>'", ")", "[", "0", "]", ".", "strip", "(", ")", ".", "split", "(", ")", "\n", "templates_list", ".", "append", "(", "template", ")", "\n", "targets_list", ".", "append", "(", "target", ")", "\n", "hypothesis_list", ".", "append", "(", "got", ")", "\n", "\n", "", "cnt", "+=", "1", "\n", "if", "mode", "is", "not", "'test'", "and", "cnt", ">=", "60", ":", "\n", "                    ", "break", "\n", "", "", "except", "tf", ".", "errors", ".", "OutOfRangeError", ":", "\n", "                ", "break", "\n", "\n", "", "", "avg_loss", ",", "avg_ppl", "=", "np", ".", "mean", "(", "loss_lists", ")", ",", "np", ".", "mean", "(", "ppl_lists", ")", "\n", "outputs_tmp_filename", "=", "args", ".", "log_dir", "+", "'epoch{}.beam{}.outputs.tmp'", ".", "format", "(", "cur_epoch", ",", "args", ".", "beam_width", ")", "\n", "template_tmp_filename", "=", "args", ".", "log_dir", "+", "'epoch{}.beam{}.templates.tmp'", ".", "format", "(", "cur_epoch", ",", "args", ".", "beam_width", ")", "\n", "refer_tmp_filename", "=", "os", ".", "path", ".", "join", "(", "args", ".", "log_dir", ",", "'eval_reference.tmp'", ")", "\n", "with", "codecs", ".", "open", "(", "outputs_tmp_filename", ",", "'w+'", ",", "'utf-8'", ")", "as", "tmpfile", ",", "codecs", ".", "open", "(", "template_tmp_filename", ",", "'w+'", ",", "'utf-8'", ")", "as", "tmptpltfile", ",", "codecs", ".", "open", "(", "refer_tmp_filename", ",", "'w+'", ",", "'utf-8'", ")", "as", "tmpreffile", ":", "\n", "            ", "for", "hyp", ",", "tplt", ",", "tgt", "in", "zip", "(", "hypothesis_list", ",", "templates_list", ",", "targets_list", ")", ":", "\n", "                ", "tmpfile", ".", "write", "(", "' '", ".", "join", "(", "hyp", ")", "+", "'\\n'", ")", "\n", "tmptpltfile", ".", "write", "(", "' '", ".", "join", "(", "tplt", ")", "+", "'\\n'", ")", "\n", "tmpreffile", ".", "write", "(", "' '", ".", "join", "(", "tgt", ")", "+", "'\\n'", ")", "\n", "", "", "eval_bleu", "=", "float", "(", "100", "*", "bleu_tool", ".", "bleu_wrapper", "(", "\n", "refer_tmp_filename", ",", "outputs_tmp_filename", ",", "case_sensitive", "=", "True", ")", ")", "\n", "template_bleu", "=", "float", "(", "100", "*", "bleu_tool", ".", "bleu_wrapper", "(", "\n", "refer_tmp_filename", ",", "template_tmp_filename", ",", "case_sensitive", "=", "True", ")", ")", "\n", "print", "(", "'epoch:{} {}_bleu:{} template_bleu:{} {}_loss:{} {}_ppl:{} '", ".", "\n", "format", "(", "cur_epoch", ",", "mode", ",", "eval_bleu", ",", "template_bleu", ",", "mode", ",", "avg_loss", ",", "mode", ",", "avg_ppl", ")", ")", "\n", "os", ".", "remove", "(", "outputs_tmp_filename", ")", "\n", "os", ".", "remove", "(", "template_tmp_filename", ")", "\n", "os", ".", "remove", "(", "refer_tmp_filename", ")", "\n", "if", "args", ".", "save_eval_output", ":", "\n", "            ", "result_filename", "=", "args", ".", "log_dir", "+", "'epoch{}.beam{}.{}.results.bleu{:.3f}'", ".", "format", "(", "cur_epoch", ",", "args", ".", "beam_width", ",", "mode", ",", "eval_bleu", ")", "\n", "with", "codecs", ".", "open", "(", "result_filename", ",", "'w+'", ",", "'utf-8'", ")", "as", "resultfile", ":", "\n", "                ", "for", "tmplt", ",", "tgt", ",", "hyp", "in", "zip", "(", "templates_list", ",", "targets_list", ",", "hypothesis_list", ")", ":", "\n", "                    ", "resultfile", ".", "write", "(", "\"- template: \"", "+", "' '", ".", "join", "(", "tmplt", ")", "+", "'\\n'", ")", "\n", "resultfile", ".", "write", "(", "\"- expected: \"", "+", "' '", ".", "join", "(", "tgt", ")", "+", "'\\n'", ")", "\n", "resultfile", ".", "write", "(", "'- got:      '", "+", "' '", ".", "join", "(", "hyp", ")", "+", "'\\n\\n'", ")", "\n", "", "", "", "return", "{", "\n", "'eval'", ":", "eval_bleu", ",", "\n", "'template'", ":", "template_bleu", "\n", "}", ",", "avg_ppl", "\n", "\n", "", "def", "_draw_train_loss", "(", "epoch", ",", "loss_list", ",", "mode", ")", ":", "\n", "        ", "plt", ".", "figure", "(", "figsize", "=", "(", "14", ",", "10", ")", ")", "\n", "plt", ".", "plot", "(", "loss_list", ",", "'--'", ",", "linewidth", "=", "1", ",", "label", "=", "'loss trend'", ")", "\n", "plt", ".", "ylabel", "(", "'%s till epoch %s'", "%", "(", "mode", ",", "epoch", ")", ")", "\n", "plt", ".", "xlabel", "(", "'every 50 steps, present_rate=%f'", "%", "args", ".", "present_rate", ")", "\n", "plt", ".", "savefig", "(", "args", ".", "log_dir", "+", "'/img/%s_curve.png'", "%", "mode", ")", "\n", "plt", ".", "close", "(", "'all'", ")", "\n", "\n", "", "def", "_draw_bleu", "(", "epoch", ",", "test_bleu", ",", "tplt_bleu", ",", "train_bleu", ",", "train_tplt_bleu", ")", ":", "\n", "        ", "plt", ".", "figure", "(", "figsize", "=", "(", "14", ",", "10", ")", ")", "\n", "legends", "=", "[", "]", "\n", "plt", ".", "plot", "(", "test_bleu", ",", "'--'", ",", "linewidth", "=", "1", ",", "label", "=", "'test bleu'", ")", "\n", "plt", ".", "plot", "(", "tplt_bleu", ",", "'--'", ",", "linewidth", "=", "1", ",", "label", "=", "'template bleu'", ")", "\n", "legends", ".", "extend", "(", "[", "'test bleu'", ",", "'template bleu'", "]", ")", "\n", "plt", ".", "ylabel", "(", "'bleu till epoch {}'", ".", "format", "(", "epoch", ")", ")", "\n", "plt", ".", "xlabel", "(", "'every epoch'", ")", "\n", "plt", ".", "legend", "(", "legends", ",", "loc", "=", "'upper left'", ")", "\n", "plt", ".", "savefig", "(", "args", ".", "log_dir", "+", "'/img/bleu.png'", ")", "\n", "\n", "plt", ".", "figure", "(", "figsize", "=", "(", "14", ",", "10", ")", ")", "\n", "legends", "=", "[", "]", "\n", "plt", ".", "plot", "(", "train_bleu", ",", "'--'", ",", "linewidth", "=", "1", ",", "label", "=", "'train bleu'", ")", "\n", "plt", ".", "plot", "(", "train_tplt_bleu", ",", "'--'", ",", "linewidth", "=", "1", ",", "label", "=", "'train template bleu'", ")", "\n", "legends", ".", "extend", "(", "[", "'train bleu'", ",", "'train template bleu'", "]", ")", "\n", "plt", ".", "ylabel", "(", "'bleu till epoch {}'", ".", "format", "(", "epoch", ")", ")", "\n", "plt", ".", "xlabel", "(", "'every epoch'", ")", "\n", "plt", ".", "legend", "(", "legends", ",", "loc", "=", "'upper left'", ")", "\n", "plt", ".", "savefig", "(", "args", ".", "log_dir", "+", "'/img/train_bleu.png'", ")", "\n", "plt", ".", "close", "(", "'all'", ")", "\n", "\n", "", "config_", "=", "tf", ".", "ConfigProto", "(", "allow_soft_placement", "=", "True", ")", "\n", "config_", ".", "gpu_options", ".", "allow_growth", "=", "True", "\n", "\n", "with", "tf", ".", "Session", "(", "config", "=", "config_", ")", "as", "sess", ":", "\n", "        ", "sess", ".", "run", "(", "tf", ".", "global_variables_initializer", "(", ")", ")", "\n", "sess", ".", "run", "(", "tf", ".", "local_variables_initializer", "(", ")", ")", "\n", "sess", ".", "run", "(", "tf", ".", "tables_initializer", "(", ")", ")", "\n", "\n", "iterator", ".", "initialize_dataset", "(", "sess", ")", "\n", "\n", "loss_list", ",", "ppl_list", ",", "test_ppl_list", "=", "[", "]", ",", "[", "]", ",", "[", "]", "\n", "test_bleu", ",", "tplt_bleu", ",", "train_bleu", ",", "train_tplt_bleu", "=", "[", "]", ",", "[", "]", ",", "[", "]", ",", "[", "]", "\n", "gamma_", ",", "lambda_g_", "=", "1.", ",", "0.", "\n", "if", "args", ".", "running_mode", "==", "'train_and_evaluate'", ":", "\n", "            ", "for", "epoch", "in", "range", "(", "70", ",", "args", ".", "max_train_epoch", ")", ":", "\n", "# Anneals the gumbel-softmax temperature", "\n", "                ", "if", "epoch", ">", "args", ".", "pretrain_epoch", ":", "\n", "                    ", "gamma_", "=", "max", "(", "0.001", ",", "gamma_", "*", "args", ".", "gamma_decay", ")", "\n", "lambda_g_", "=", "args", ".", "lambda_g", "\n", "\n", "# bleu on test set and train set", "\n", "", "if", "epoch", "%", "args", ".", "bleu_interval", "==", "0", "or", "epoch", "==", "args", ".", "max_train_epoch", "-", "1", ":", "\n", "                    ", "iterator", ".", "restart_dataset", "(", "sess", ",", "'test'", ")", "\n", "bleu_scores", ",", "test_ppl", "=", "_test_epoch", "(", "sess", ",", "epoch", ",", "gamma_", ",", "lambda_g_", ")", "\n", "test_bleu", ".", "append", "(", "bleu_scores", "[", "'eval'", "]", ")", "\n", "tplt_bleu", ".", "append", "(", "bleu_scores", "[", "'template'", "]", ")", "\n", "test_ppl_list", ".", "append", "(", "test_ppl", ")", "\n", "_draw_train_loss", "(", "epoch", ",", "test_ppl_list", ",", "mode", "=", "'test_perplexity'", ")", "\n", "\n", "iterator", ".", "restart_dataset", "(", "sess", ",", "'train_g'", ")", "\n", "train_bleu_scores", ",", "_", "=", "_test_epoch", "(", "sess", ",", "epoch", ",", "gamma_", ",", "lambda_g_", ",", "mode", "=", "'train_g'", ")", "\n", "train_bleu", ".", "append", "(", "train_bleu_scores", "[", "'eval'", "]", ")", "\n", "train_tplt_bleu", ".", "append", "(", "train_bleu_scores", "[", "'template'", "]", ")", "\n", "_draw_bleu", "(", "epoch", ",", "test_bleu", ",", "tplt_bleu", ",", "train_bleu", ",", "train_tplt_bleu", ")", "\n", "eval_saver", ".", "save", "(", "sess", ",", "args", ".", "log_dir", "+", "'my-model-latest.ckpt'", ")", "\n", "\n", "# train", "\n", "", "iterator", ".", "restart_dataset", "(", "sess", ",", "[", "'train_g'", ",", "'train_d'", "]", ")", "\n", "losses", ",", "ppls", "=", "_train_epochs", "(", "sess", ",", "epoch", ",", "gamma_", ",", "lambda_g_", ")", "\n", "loss_list", ".", "extend", "(", "losses", ")", "\n", "ppl_list", ".", "extend", "(", "ppls", ")", "\n", "_draw_train_loss", "(", "epoch", ",", "loss_list", ",", "mode", "=", "'train_loss'", ")", "\n", "_draw_train_loss", "(", "epoch", ",", "ppl_list", ",", "mode", "=", "'perplexity'", ")", "\n", "sys", ".", "stdout", ".", "flush", "(", ")", "\n", "\n", "if", "epoch", "==", "args", ".", "pretrain_epoch", ":", "\n", "                    ", "eval_saver", ".", "save", "(", "sess", ",", "args", ".", "log_dir", "+", "'pretrained-model.ckpt'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.text_infilling.data_utils.transform_input_with_is_missing_token": [[9, 45], ["tensorflow.fill", "print", "print", "tensorflow.concat", "tensorflow.where", "tensorflow.shape", "tensorflow.equal", "tensorflow.zeros_like", "tensorflow.ones_like"], "function", ["None"], ["from", "__future__", "import", "unicode_literals", "\n", "\n", "import", "os", "\n", "import", "sys", "\n", "import", "tarfile", "\n", "import", "zipfile", "\n", "import", "collections", "\n", "import", "numpy", "as", "np", "\n", "from", "six", ".", "moves", "import", "urllib", "\n", "import", "requests", "\n", "\n", "import", "tensorflow", "as", "tf", "\n", "\n", "# pylint: disable=invalid-name, too-many-branches", "\n", "\n", "__all__", "=", "[", "\n", "\"create_dir_if_needed\"", ",", "\n", "\"maybe_download\"", ",", "\n", "\"get_files\"", ",", "\n", "\"read_words\"", ",", "\n", "\"make_vocab\"", ",", "\n", "\"count_file_lines\"", "\n", "]", "\n", "\n", "Py3", "=", "sys", ".", "version_info", "[", "0", "]", "==", "3", "\n", "\n", "def", "create_dir_if_needed", "(", "dirname", ")", ":", "\n", "    ", "\"\"\"Creates directory if doesn't exist\n    \"\"\"", "\n", "if", "not", "tf", ".", "gfile", ".", "IsDirectory", "(", "dirname", ")", ":", "\n", "        ", "tf", ".", "gfile", ".", "MakeDirs", "(", "dirname", ")", "\n", "return", "True", "\n", "", "return", "False", "\n", "\n", "", "def", "maybe_download", "(", "urls", ",", "path", ",", "filenames", "=", "None", ",", "extract", "=", "False", ")", ":", "\n", "    "]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.text_infilling.data_utils.prepare_data": [[47, 56], ["tensorflow.gfile.Exists", "texar.data.maybe_download", "os.remove"], "function", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.data.data_utils.maybe_download", "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.transformer_utils.PadRemover.remove"], ["\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.text_infilling.bleu_tool.UnicodeRegex.__init__": [[141, 146], ["bleu_tool.UnicodeRegex.property_chars", "re.compile", "re.compile", "re.compile", "bleu_tool.UnicodeRegex.property_chars"], "methods", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.text_infilling.bleu_tool.UnicodeRegex.property_chars", "home.repos.pwc.inspect_result.VegB_Text_Infilling.text_infilling.bleu_tool.UnicodeRegex.property_chars"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "punctuation", "=", "self", ".", "property_chars", "(", "\"P\"", ")", "\n", "self", ".", "nondigit_punct_re", "=", "re", ".", "compile", "(", "r\"([^\\d])([\"", "+", "punctuation", "+", "r\"])\"", ")", "\n", "self", ".", "punct_nondigit_re", "=", "re", ".", "compile", "(", "r\"([\"", "+", "punctuation", "+", "r\"])([^\\d])\"", ")", "\n", "self", ".", "symbol_re", "=", "re", ".", "compile", "(", "\"([\"", "+", "self", ".", "property_chars", "(", "\"S\"", ")", "+", "\"])\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.text_infilling.bleu_tool.UnicodeRegex.property_chars": [[147, 151], ["six.unichr", "range", "unicodedata.category().startswith", "unicodedata.category", "six.unichr"], "methods", ["None"], ["", "def", "property_chars", "(", "self", ",", "prefix", ")", ":", "\n", "#pylint:disable=no-self-use", "\n", "        ", "return", "\"\"", ".", "join", "(", "six", ".", "unichr", "(", "x", ")", "for", "x", "in", "range", "(", "sys", ".", "maxunicode", ")", "if", "unicodedata", ".", "category", "(", "six", ".", "unichr", "(", "x", ")", ")", ".", "startswith", "(", "prefix", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.text_infilling.bleu_tool._get_ngrams": [[52, 70], ["collections.Counter", "six.moves.xrange", "six.moves.xrange", "tuple", "len"], "function", ["None"], ["def", "_get_ngrams", "(", "segment", ",", "max_order", ")", ":", "\n", "    ", "\"\"\"Extracts all n-grams upto a given maximum order from an input segment.\n\n  Args:\n    segment: text segment from which n-grams will be extracted.\n    max_order: maximum length in tokens of the n-grams returned by this\n        methods.\n\n  Returns:\n    The Counter containing all n-grams upto max_order in segment\n    with a count of how many times each n-gram occurred.\n  \"\"\"", "\n", "ngram_counts", "=", "collections", ".", "Counter", "(", ")", "\n", "for", "order", "in", "xrange", "(", "1", ",", "max_order", "+", "1", ")", ":", "\n", "        ", "for", "i", "in", "xrange", "(", "0", ",", "len", "(", "segment", ")", "-", "order", "+", "1", ")", ":", "\n", "            ", "ngram", "=", "tuple", "(", "segment", "[", "i", ":", "i", "+", "order", "]", ")", "\n", "ngram_counts", "[", "ngram", "]", "+=", "1", "\n", "", "", "return", "ngram_counts", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.text_infilling.bleu_tool.compute_bleu": [[72, 136], ["six.moves.zip", "six.moves.xrange", "numpy.float32", "len", "len", "bleu_tool._get_ngrams", "bleu_tool._get_ngrams", "dict", "max", "sum", "math.exp", "math.exp", "math.log", "min", "_get_ngrams.items", "len", "len"], "function", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.text_infilling.bleu_tool._get_ngrams", "home.repos.pwc.inspect_result.VegB_Text_Infilling.text_infilling.bleu_tool._get_ngrams", "home.repos.pwc.inspect_result.VegB_Text_Infilling.texar.hyperparams.HParams.items"], ["", "def", "compute_bleu", "(", "reference_corpus", ",", "\n", "translation_corpus", ",", "\n", "max_order", "=", "4", ",", "\n", "use_bp", "=", "True", ")", ":", "\n", "    ", "\"\"\"Computes BLEU score of translated segments against references.\n\n    Args:\n        reference_corpus: list of references for each translation. Each\n            reference should be tokenized into a list of tokens.\n        translation_corpus: list of translations to score. Each translation\n            should be tokenized into a list of tokens.\n        max_order: Maximum n-gram order to use when computing BLEU score.\n        use_bp: boolean, whether to apply brevity penalty.\n    Returns:\n        BLEU score.\n    \"\"\"", "\n", "\n", "reference_length", "=", "0", "\n", "translation_length", "=", "0", "\n", "bp", "=", "1.0", "\n", "geo_mean", "=", "0", "\n", "\n", "matches_by_order", "=", "[", "0", "]", "*", "max_order", "\n", "possible_matches_by_order", "=", "[", "0", "]", "*", "max_order", "\n", "precisions", "=", "[", "]", "\n", "\n", "for", "(", "references", ",", "translations", ")", "in", "zip", "(", "reference_corpus", ",", "translation_corpus", ")", ":", "\n", "        ", "reference_length", "+=", "len", "(", "references", ")", "\n", "translation_length", "+=", "len", "(", "translations", ")", "\n", "ref_ngram_counts", "=", "_get_ngrams", "(", "references", ",", "max_order", ")", "\n", "translation_ngram_counts", "=", "_get_ngrams", "(", "translations", ",", "max_order", ")", "\n", "\n", "overlap", "=", "dict", "(", "(", "ngram", ",", "\n", "min", "(", "count", ",", "translation_ngram_counts", "[", "ngram", "]", ")", ")", "\n", "for", "ngram", ",", "count", "in", "ref_ngram_counts", ".", "items", "(", ")", ")", "\n", "\n", "for", "ngram", "in", "overlap", ":", "\n", "            ", "matches_by_order", "[", "len", "(", "ngram", ")", "-", "1", "]", "+=", "overlap", "[", "ngram", "]", "\n", "", "for", "ngram", "in", "translation_ngram_counts", ":", "\n", "            ", "possible_matches_by_order", "[", "len", "(", "ngram", ")", "-", "1", "]", "+=", "translation_ngram_counts", "[", "ngram", "]", "\n", "", "", "precisions", "=", "[", "0", "]", "*", "max_order", "\n", "smooth", "=", "1.0", "\n", "for", "i", "in", "xrange", "(", "0", ",", "max_order", ")", ":", "\n", "        ", "if", "possible_matches_by_order", "[", "i", "]", ">", "0", ":", "\n", "            ", "precisions", "[", "i", "]", "=", "matches_by_order", "[", "i", "]", "/", "possible_matches_by_order", "[", "i", "]", "\n", "if", "matches_by_order", "[", "i", "]", ">", "0", ":", "\n", "                ", "precisions", "[", "i", "]", "=", "matches_by_order", "[", "i", "]", "/", "possible_matches_by_order", "[", "i", "]", "\n", "", "else", ":", "\n", "                ", "smooth", "*=", "2", "\n", "precisions", "[", "i", "]", "=", "1.0", "/", "(", "smooth", "*", "possible_matches_by_order", "[", "i", "]", ")", "\n", "", "", "else", ":", "\n", "            ", "precisions", "[", "i", "]", "=", "0.0", "\n", "\n", "", "", "if", "max", "(", "precisions", ")", ">", "0", ":", "\n", "        ", "p_log_sum", "=", "sum", "(", "math", ".", "log", "(", "p", ")", "for", "p", "in", "precisions", "if", "p", ")", "\n", "geo_mean", "=", "math", ".", "exp", "(", "p_log_sum", "/", "max_order", ")", "\n", "\n", "", "if", "use_bp", ":", "\n", "        ", "ratio", "=", "translation_length", "/", "reference_length", "\n", "bp", "=", "math", ".", "exp", "(", "1", "-", "1.", "/", "ratio", ")", "if", "ratio", "<", "1.0", "else", "1.0", "\n", "", "bleu", "=", "geo_mean", "*", "bp", "\n", "return", "np", ".", "float32", "(", "bleu", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.text_infilling.bleu_tool.bleu_tokenize": [[156, 184], ["uregex.nondigit_punct_re.sub", "uregex.punct_nondigit_re.sub", "uregex.symbol_re.sub", "uregex.symbol_re.sub.split"], "function", ["None"], ["def", "bleu_tokenize", "(", "string", ")", ":", "\n", "    ", "r\"\"\"Tokenize a string following the official BLEU implementation.\n\n  See https://github.com/moses-smt/mosesdecoder/\"\n           \"blob/master/scripts/generic/mteval-v14.pl#L954-L983\n  In our case, the input string is expected to be just one line\n  and no HTML entities de-escaping is needed.\n  So we just tokenize on punctuation and symbols,\n  except when a punctuation is preceded and followed by a digit\n  (e.g. a comma/dot as a thousand/decimal separator).\n\n  Note that a numer (e.g. a year) followed by a dot at the end of sentence\n  is NOT tokenized,\n  i.e. the dot stays with the number because `s/(\\p{P})(\\P{N})/ $1 $2/g`\n  does not match this case (unless we add a space after each sentence).\n  However, this error is already in the original mteval-v14.pl\n  and we want to be consistent with it.\n\n  Args:\n    string: the input string\n\n  Returns:\n    a list of tokens\n  \"\"\"", "\n", "string", "=", "uregex", ".", "nondigit_punct_re", ".", "sub", "(", "r\"\\1 \\2 \"", ",", "string", ")", "\n", "string", "=", "uregex", ".", "punct_nondigit_re", ".", "sub", "(", "r\" \\1 \\2\"", ",", "string", ")", "\n", "string", "=", "uregex", ".", "symbol_re", ".", "sub", "(", "r\" \\1 \"", ",", "string", ")", "\n", "return", "string", ".", "split", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.text_infilling.bleu_tool.bleu_wrapper": [[186, 197], ["open().read().decode().splitlines", "open().read().decode().splitlines", "bleu_tool.compute_bleu", "len", "len", "bleu_tool.bleu_tokenize", "bleu_tool.bleu_tokenize", "open().read().decode", "open().read().decode", "x.lower", "x.lower", "open().read", "open().read", "open", "open"], "function", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.text_infilling.bleu_tool.compute_bleu", "home.repos.pwc.inspect_result.VegB_Text_Infilling.text_infilling.bleu_tool.bleu_tokenize", "home.repos.pwc.inspect_result.VegB_Text_Infilling.text_infilling.bleu_tool.bleu_tokenize", "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.data_decoders.VarUttTextDataDecoder.decode", "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.data_decoders.VarUttTextDataDecoder.decode"], ["", "def", "bleu_wrapper", "(", "ref_filename", ",", "hyp_filename", ",", "case_sensitive", "=", "False", ")", ":", "\n", "    ", "\"\"\"Compute BLEU for two files (reference and hypothesis translation).\"\"\"", "\n", "ref_lines", "=", "open", "(", "ref_filename", ",", "'rb'", ")", ".", "read", "(", ")", ".", "decode", "(", "'utf-8'", ")", ".", "splitlines", "(", ")", "\n", "hyp_lines", "=", "open", "(", "hyp_filename", ",", "'rb'", ")", ".", "read", "(", ")", ".", "decode", "(", "'utf-8'", ")", ".", "splitlines", "(", ")", "\n", "assert", "len", "(", "ref_lines", ")", "==", "len", "(", "hyp_lines", ")", "\n", "if", "not", "case_sensitive", ":", "\n", "        ", "ref_lines", "=", "[", "x", ".", "lower", "(", ")", "for", "x", "in", "ref_lines", "]", "\n", "hyp_lines", "=", "[", "x", ".", "lower", "(", ")", "for", "x", "in", "hyp_lines", "]", "\n", "", "ref_tokens", "=", "[", "bleu_tokenize", "(", "x", ")", "for", "x", "in", "ref_lines", "]", "\n", "hyp_tokens", "=", "[", "bleu_tokenize", "(", "x", ")", "for", "x", "in", "hyp_lines", "]", "\n", "return", "compute_bleu", "(", "ref_tokens", ",", "hyp_tokens", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.text_infilling.seq2seq._main": [[38, 350], ["seq2seq_hyperparams.load_hyperparams", "texar.data.MonoTextData", "texar.data.MonoTextData", "texar.data.MonoTextData", "texar.data.TrainTestDataIterator", "tx.data.TrainTestDataIterator.get_next", "texar.utils.prepare_template", "texar.modules.WordEmbedder", "texar.modules.embedders.position_embedders.SinusoidsSegmentalPositionEmbedder", "texar.modules.UnidirectionalRNNEncoder", "texar.modules.BasicPositionalRNNDecoder", "texar.modules.connectors.ForwardConnector", "enumerate", "tensorflow.reduce_mean", "tensorflow.Variable", "tensorflow.train.AdamOptimizer", "tf.train.AdamOptimizer.minimize", "enumerate", "tensorflow.train.Saver", "tensorflow.ConfigProto", "tensorflow.ConfigProto", "tx.modules.WordEmbedder.", "position_embedders.SinusoidsSegmentalPositionEmbedder.", "tx.modules.UnidirectionalRNNEncoder.", "tx.modules.connectors.ForwardConnector.", "tx.modules.WordEmbedder.", "tx.modules.BasicPositionalRNNDecoder.set_segment_id", "tx.modules.BasicPositionalRNNDecoder.", "texar.utils.smoothing_cross_entropy", "texar.utils.update_template_pack", "tensorflow.Variable", "tx.modules.WordEmbedder.", "position_embedders.SinusoidsSegmentalPositionEmbedder.", "tx.modules.UnidirectionalRNNEncoder.", "tx.modules.connectors.ForwardConnector.", "tx.modules.BasicPositionalRNNDecoder.set_segment_id", "tx.modules.BasicPositionalRNNDecoder.", "predictions.append", "texar.utils.update_template_pack", "tx.data.TrainTestDataIterator.switch_to_train_data", "os.path.join", "float", "float", "print", "os.remove", "os.remove", "os.remove", "matplotlib.pyplot.figure", "matplotlib.pyplot.plot", "matplotlib.pyplot.ylabel", "matplotlib.pyplot.xlabel", "matplotlib.pyplot.savefig", "matplotlib.pyplot.close", "matplotlib.pyplot.figure", "matplotlib.pyplot.plot", "matplotlib.pyplot.plot", "legends.extend", "matplotlib.pyplot.ylabel", "matplotlib.pyplot.xlabel", "matplotlib.pyplot.legend", "matplotlib.pyplot.savefig", "matplotlib.pyplot.figure", "matplotlib.pyplot.plot", "matplotlib.pyplot.plot", "legends.extend", "matplotlib.pyplot.ylabel", "matplotlib.pyplot.xlabel", "matplotlib.pyplot.legend", "matplotlib.pyplot.savefig", "matplotlib.pyplot.close", "tensorflow.Session", "sess.run", "sess.run", "sess.run", "texar.utils.shapes.shape_list", "texar.utils.shapes.shape_list", "tensorflow.concat", "tensorflow.to_float", "ValueError", "texar.utils.shapes.shape_list", "texar.utils.shapes.shape_list", "tx.data.TrainTestDataIterator.switch_to_test_data", "numpy.mean", "numpy.mean", "codecs.open", "codecs.open", "codecs.open", "zip", "tensorflow.global_variables_initializer", "tensorflow.local_variables_initializer", "tensorflow.tables_initializer", "range", "tensorflow.minimum", "tensorflow.cast", "session.run", "numpy.exp", "loss_lists.append", "ppl_lists.append", "tx.data.TrainTestDataIterator.switch_to_train_data", "tx.data.TrainTestDataIterator.switch_to_val_data", "cur_sess.run", "numpy.exp", "loss_lists.append", "ppl_lists.append", "texar.utils.fill_template", "zip", "tmpfile.write", "tmptpltfile.write", "tmpreffile.write", "bleu_tool.bleu_wrapper", "bleu_tool.bleu_wrapper", "codecs.open", "zip", "seq2seq._main._train_epochs"], "function", ["home.repos.pwc.inspect_result.VegB_Text_Infilling.text_infilling.self_attn_hyperparams.load_hyperparams", "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.data_iterators.FeedableDataIterator.get_next", "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.transformer_utils.prepare_template", "home.repos.pwc.inspect_result.VegB_Text_Infilling.decoders.rnn_decoders.BasicPositionalRNNDecoder.set_segment_id", "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.transformer_utils.smoothing_cross_entropy", "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.transformer_utils.update_template_pack", "home.repos.pwc.inspect_result.VegB_Text_Infilling.decoders.rnn_decoders.BasicPositionalRNNDecoder.set_segment_id", "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.transformer_utils.update_template_pack", "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.data_iterators.TrainTestDataIterator.switch_to_train_data", "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.transformer_utils.PadRemover.remove", "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.transformer_utils.PadRemover.remove", "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.transformer_utils.PadRemover.remove", "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.shapes.shape_list", "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.shapes.shape_list", "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.shapes.shape_list", "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.shapes.shape_list", "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.data_iterators.TrainTestDataIterator.switch_to_test_data", "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.data_iterators.TrainTestDataIterator.switch_to_train_data", "home.repos.pwc.inspect_result.VegB_Text_Infilling.data.data_iterators.TrainTestDataIterator.switch_to_val_data", "home.repos.pwc.inspect_result.VegB_Text_Infilling.utils.transformer_utils.fill_template", "home.repos.pwc.inspect_result.VegB_Text_Infilling.text_infilling.bleu_tool.bleu_wrapper", "home.repos.pwc.inspect_result.VegB_Text_Infilling.text_infilling.bleu_tool.bleu_wrapper"], ["def", "_main", "(", "_", ")", ":", "\n", "    ", "hparams", "=", "seq2seq_hyperparams", ".", "load_hyperparams", "(", ")", "\n", "train_dataset_hparams", ",", "valid_dataset_hparams", ",", "test_dataset_hparams", ",", "encoder_hparams", ",", "decoder_hparams", ",", "opt_hparams", ",", "loss_hparams", ",", "args", "=", "hparams", "[", "'train_dataset_hparams'", "]", ",", "hparams", "[", "'eval_dataset_hparams'", "]", ",", "hparams", "[", "'test_dataset_hparams'", "]", ",", "hparams", "[", "'encoder_hparams'", "]", ",", "hparams", "[", "'decoder_hparams'", "]", ",", "hparams", "[", "'opt_hparams'", "]", ",", "hparams", "[", "'loss_hparams'", "]", ",", "hparams", "[", "'args'", "]", "\n", "\n", "# Data", "\n", "train_data", "=", "tx", ".", "data", ".", "MonoTextData", "(", "train_dataset_hparams", ")", "\n", "valid_data", "=", "tx", ".", "data", ".", "MonoTextData", "(", "valid_dataset_hparams", ")", "\n", "test_data", "=", "tx", ".", "data", ".", "MonoTextData", "(", "test_dataset_hparams", ")", "\n", "iterator", "=", "tx", ".", "data", ".", "TrainTestDataIterator", "(", "train", "=", "train_data", ",", "\n", "val", "=", "valid_data", ",", "\n", "test", "=", "test_data", ")", "\n", "data_batch", "=", "iterator", ".", "get_next", "(", ")", "\n", "mask_id", "=", "train_data", ".", "vocab", ".", "token_to_id_map_py", "[", "'<m>'", "]", "\n", "boa_id", "=", "train_data", ".", "vocab", ".", "token_to_id_map_py", "[", "'<BOA>'", "]", "\n", "eoa_id", "=", "train_data", ".", "vocab", ".", "token_to_id_map_py", "[", "'<EOA>'", "]", "\n", "eos_id", "=", "train_data", ".", "vocab", ".", "token_to_id_map_py", "[", "SpecialTokens", ".", "EOS", "]", "\n", "pad_id", "=", "train_data", ".", "vocab", ".", "token_to_id_map_py", "[", "'<PAD>'", "]", "\n", "template_pack", ",", "answer_packs", "=", "tx", ".", "utils", ".", "prepare_template", "(", "data_batch", ",", "args", ",", "mask_id", ",", "boa_id", ",", "eoa_id", ",", "pad_id", ")", "\n", "\n", "# Model architecture", "\n", "embedder", "=", "tx", ".", "modules", ".", "WordEmbedder", "(", "vocab_size", "=", "train_data", ".", "vocab", ".", "size", ",", "\n", "hparams", "=", "args", ".", "word_embedding_hparams", ")", "\n", "position_embedder", "=", "position_embedders", ".", "SinusoidsSegmentalPositionEmbedder", "(", ")", "\n", "encoder", "=", "tx", ".", "modules", ".", "UnidirectionalRNNEncoder", "(", "hparams", "=", "encoder_hparams", ")", "\n", "decoder", "=", "tx", ".", "modules", ".", "BasicPositionalRNNDecoder", "(", "vocab_size", "=", "train_data", ".", "vocab", ".", "size", ",", "\n", "hparams", "=", "decoder_hparams", ",", "\n", "position_embedder", "=", "position_embedder", ")", "\n", "decoder_initial_state_size", "=", "decoder", ".", "cell", ".", "state_size", "\n", "connector", "=", "tx", ".", "modules", ".", "connectors", ".", "ForwardConnector", "(", "decoder_initial_state_size", ")", "\n", "\n", "cetp_loss", "=", "None", "\n", "cur_template_pack", "=", "template_pack", "\n", "for", "idx", ",", "hole", "in", "enumerate", "(", "answer_packs", ")", ":", "\n", "        ", "template", "=", "cur_template_pack", "[", "'templates'", "]", "\n", "template_word_embeds", "=", "embedder", "(", "template", ")", "\n", "template_length", "=", "shape_list", "(", "template", ")", "[", "1", "]", "\n", "channels", "=", "shape_list", "(", "template_word_embeds", ")", "[", "2", "]", "\n", "template_pos_embeds", "=", "position_embedder", "(", "template_length", ",", "channels", ",", "\n", "cur_template_pack", "[", "'segment_ids'", "]", ",", "\n", "cur_template_pack", "[", "'offsets'", "]", ")", "\n", "enc_input_embedded", "=", "template_word_embeds", "+", "template_pos_embeds", "\n", "\n", "_", ",", "ecdr_states", "=", "encoder", "(", "\n", "enc_input_embedded", ",", "\n", "sequence_length", "=", "data_batch", "[", "\"length\"", "]", ")", "\n", "\n", "dcdr_init_states", "=", "connector", "(", "ecdr_states", ")", "\n", "\n", "dec_input", "=", "hole", "[", "'text_ids'", "]", "[", ":", ",", ":", "-", "1", "]", "\n", "dec_input_word_embeds", "=", "embedder", "(", "dec_input", ")", "\n", "decoder", ".", "set_segment_id", "(", "1", ")", "\n", "dec_input_embedded", "=", "dec_input_word_embeds", "\n", "outputs", ",", "_", ",", "_", "=", "decoder", "(", "\n", "initial_state", "=", "dcdr_init_states", ",", "\n", "decoding_strategy", "=", "\"train_greedy\"", ",", "\n", "inputs", "=", "dec_input_embedded", ",", "\n", "sequence_length", "=", "hole", "[", "\"lengths\"", "]", "+", "1", ")", "\n", "cur_loss", "=", "tx", ".", "utils", ".", "smoothing_cross_entropy", "(", "\n", "outputs", ".", "logits", ",", "\n", "hole", "[", "'text_ids'", "]", "[", ":", ",", "1", ":", "]", ",", "\n", "train_data", ".", "vocab", ".", "size", ",", "\n", "loss_hparams", "[", "'label_confidence'", "]", ",", "\n", ")", "\n", "cetp_loss", "=", "cur_loss", "if", "cetp_loss", "is", "None", "else", "tf", ".", "concat", "(", "[", "cetp_loss", ",", "cur_loss", "]", ",", "-", "1", ")", "\n", "cur_template_pack", "=", "tx", ".", "utils", ".", "update_template_pack", "(", "cur_template_pack", ",", "\n", "hole", "[", "'text_ids'", "]", "[", ":", ",", "1", ":", "]", ",", "\n", "mask_id", ",", "eoa_id", ",", "pad_id", ")", "\n", "", "cetp_loss", "=", "tf", ".", "reduce_mean", "(", "cetp_loss", ")", "\n", "\n", "global_step", "=", "tf", ".", "Variable", "(", "0", ",", "trainable", "=", "False", ")", "\n", "if", "args", ".", "learning_rate_strategy", "==", "'static'", ":", "\n", "        ", "learning_rate", "=", "tf", ".", "Variable", "(", "1e-3", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "", "elif", "args", ".", "learning_rate_strategy", "==", "'dynamic'", ":", "\n", "        ", "fstep", "=", "tf", ".", "to_float", "(", "global_step", ")", "\n", "learning_rate", "=", "opt_hparams", "[", "'lr_constant'", "]", "*", "args", ".", "hidden_dim", "**", "-", "0.5", "*", "tf", ".", "minimum", "(", "fstep", "**", "-", "0.5", ",", "fstep", "*", "opt_hparams", "[", "'warmup_steps'", "]", "**", "-", "1.5", ")", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "'Unknown learning_rate_strategy: %s, expecting one of '", "\n", "'[\\'static\\', \\'dynamic\\']'", "%", "args", ".", "learning_rate_strategy", ")", "\n", "\n", "", "optimizer", "=", "tf", ".", "train", ".", "AdamOptimizer", "(", "\n", "learning_rate", "=", "learning_rate", ",", "\n", "beta1", "=", "opt_hparams", "[", "'Adam_beta1'", "]", ",", "\n", "beta2", "=", "opt_hparams", "[", "'Adam_beta2'", "]", ",", "\n", "epsilon", "=", "opt_hparams", "[", "'Adam_epsilon'", "]", ",", "\n", ")", "\n", "train_op", "=", "optimizer", ".", "minimize", "(", "cetp_loss", ",", "global_step", ")", "\n", "\n", "predictions", "=", "[", "]", "\n", "cur_test_pack", "=", "template_pack", "\n", "for", "idx", ",", "hole", "in", "enumerate", "(", "answer_packs", ")", ":", "\n", "        ", "template", "=", "cur_test_pack", "[", "'templates'", "]", "\n", "template_word_embeds", "=", "embedder", "(", "template", ")", "\n", "template_length", "=", "shape_list", "(", "template", ")", "[", "1", "]", "\n", "channels", "=", "shape_list", "(", "template_word_embeds", ")", "[", "2", "]", "\n", "template_pos_embeds", "=", "position_embedder", "(", "template_length", ",", "channels", ",", "\n", "cur_test_pack", "[", "'segment_ids'", "]", ",", "\n", "cur_test_pack", "[", "'offsets'", "]", ")", "\n", "enc_input_embedded", "=", "template_word_embeds", "+", "template_pos_embeds", "\n", "\n", "_", ",", "ecdr_states", "=", "encoder", "(", "\n", "enc_input_embedded", ",", "\n", "sequence_length", "=", "data_batch", "[", "\"length\"", "]", ")", "\n", "\n", "dcdr_init_states", "=", "connector", "(", "ecdr_states", ")", "\n", "\n", "decoder", ".", "set_segment_id", "(", "1", ")", "\n", "outputs_infer", ",", "_", ",", "_", "=", "decoder", "(", "\n", "decoding_strategy", "=", "\"infer_positional\"", ",", "\n", "start_tokens", "=", "tf", ".", "cast", "(", "tf", ".", "fill", "(", "[", "tf", ".", "shape", "(", "data_batch", "[", "'text_ids'", "]", ")", "[", "0", "]", "]", ",", "boa_id", ")", ",", "tf", ".", "int32", ")", ",", "\n", "end_token", "=", "eoa_id", ",", "\n", "embedding", "=", "embedder", ",", "\n", "initial_state", "=", "dcdr_init_states", ")", "\n", "predictions", ".", "append", "(", "outputs_infer", ".", "sample_id", ")", "\n", "cur_test_pack", "=", "tx", ".", "utils", ".", "update_template_pack", "(", "cur_test_pack", ",", "\n", "outputs_infer", ".", "sample_id", ",", "\n", "mask_id", ",", "eoa_id", ",", "pad_id", ")", "\n", "\n", "", "eval_saver", "=", "tf", ".", "train", ".", "Saver", "(", "max_to_keep", "=", "5", ")", "\n", "\n", "config", "=", "tf", ".", "ConfigProto", "(", "allow_soft_placement", "=", "True", ")", "\n", "config", ".", "gpu_options", ".", "allow_growth", "=", "True", "\n", "\n", "def", "_train_epochs", "(", "session", ",", "cur_epoch", ")", ":", "\n", "        ", "iterator", ".", "switch_to_train_data", "(", "session", ")", "\n", "loss_lists", ",", "ppl_lists", "=", "[", "]", ",", "[", "]", "\n", "while", "True", ":", "\n", "            ", "try", ":", "\n", "                ", "fetches", "=", "{", "'template'", ":", "template_pack", ",", "\n", "'holes'", ":", "answer_packs", ",", "\n", "'train_op'", ":", "train_op", ",", "\n", "'step'", ":", "global_step", ",", "\n", "'lr'", ":", "learning_rate", ",", "\n", "'loss'", ":", "cetp_loss", "}", "\n", "feed", "=", "{", "tx", ".", "context", ".", "global_mode", "(", ")", ":", "tf", ".", "estimator", ".", "ModeKeys", ".", "TRAIN", "}", "\n", "rtns", "=", "session", ".", "run", "(", "fetches", ",", "feed_dict", "=", "feed", ")", "\n", "step", ",", "template_", ",", "holes_", ",", "loss", "=", "rtns", "[", "'step'", "]", ",", "rtns", "[", "'template'", "]", ",", "rtns", "[", "'holes'", "]", ",", "rtns", "[", "'loss'", "]", "\n", "ppl", "=", "np", ".", "exp", "(", "loss", ")", "\n", "if", "step", "%", "200", "==", "1", ":", "\n", "                    ", "rst", "=", "'step:%s source:%s loss:%f ppl:%f lr:%f'", "%", "(", "step", ",", "template_", "[", "'text_ids'", "]", ".", "shape", ",", "loss", ",", "ppl", ",", "rtns", "[", "'lr'", "]", ")", "\n", "print", "(", "rst", ")", "\n", "", "loss_lists", ".", "append", "(", "loss", ")", "\n", "ppl_lists", ".", "append", "(", "ppl", ")", "\n", "", "except", "tf", ".", "errors", ".", "OutOfRangeError", ":", "\n", "                ", "break", "\n", "", "", "return", "loss_lists", "[", ":", ":", "50", "]", ",", "ppl_lists", "[", ":", ":", "50", "]", "\n", "\n", "", "def", "_test_epoch", "(", "cur_sess", ",", "cur_epoch", ",", "mode", "=", "'test'", ")", ":", "\n", "        ", "def", "_id2word_map", "(", "id_arrays", ")", ":", "\n", "            ", "return", "[", "' '", ".", "join", "(", "[", "train_data", ".", "vocab", ".", "_id_to_token_map_py", "[", "i", "]", "\n", "for", "i", "in", "sent", "]", ")", "for", "sent", "in", "id_arrays", "]", "\n", "\n", "", "if", "mode", "==", "'test'", ":", "\n", "            ", "iterator", ".", "switch_to_test_data", "(", "cur_sess", ")", "\n", "", "elif", "mode", "==", "'train'", ":", "\n", "            ", "iterator", ".", "switch_to_train_data", "(", "cur_sess", ")", "\n", "", "else", ":", "\n", "            ", "iterator", ".", "switch_to_val_data", "(", "cur_sess", ")", "\n", "", "templates_list", ",", "targets_list", ",", "hypothesis_list", "=", "[", "]", ",", "[", "]", ",", "[", "]", "\n", "cnt", "=", "0", "\n", "loss_lists", ",", "ppl_lists", "=", "[", "]", ",", "[", "]", "\n", "while", "True", ":", "\n", "            ", "try", ":", "\n", "                ", "fetches", "=", "{", "\n", "'data_batch'", ":", "data_batch", ",", "\n", "'predictions'", ":", "predictions", ",", "\n", "'template'", ":", "template_pack", ",", "\n", "'step'", ":", "global_step", ",", "\n", "'loss'", ":", "cetp_loss", "\n", "}", "\n", "feed", "=", "{", "tx", ".", "context", ".", "global_mode", "(", ")", ":", "tf", ".", "estimator", ".", "ModeKeys", ".", "EVAL", "}", "\n", "rtns", "=", "cur_sess", ".", "run", "(", "fetches", ",", "feed_dict", "=", "feed", ")", "\n", "real_templates_", ",", "templates_", ",", "targets_", ",", "predictions_", "=", "rtns", "[", "'template'", "]", "[", "'templates'", "]", ",", "rtns", "[", "'template'", "]", "[", "'text_ids'", "]", ",", "rtns", "[", "'data_batch'", "]", "[", "'text_ids'", "]", ",", "rtns", "[", "'predictions'", "]", "\n", "loss", "=", "rtns", "[", "'loss'", "]", "\n", "ppl", "=", "np", ".", "exp", "(", "loss", ")", "\n", "loss_lists", ".", "append", "(", "loss", ")", "\n", "ppl_lists", ".", "append", "(", "ppl", ")", "\n", "\n", "filled_templates", "=", "tx", ".", "utils", ".", "fill_template", "(", "template_pack", "=", "rtns", "[", "'template'", "]", ",", "\n", "predictions", "=", "rtns", "[", "'predictions'", "]", ",", "\n", "eoa_id", "=", "eoa_id", ",", "pad_id", "=", "pad_id", ",", "eos_id", "=", "eos_id", ")", "\n", "\n", "templates", ",", "targets", ",", "generateds", "=", "_id2word_map", "(", "real_templates_", ".", "tolist", "(", ")", ")", ",", "_id2word_map", "(", "targets_", ")", ",", "_id2word_map", "(", "filled_templates", ")", "\n", "\n", "for", "template", ",", "target", ",", "generated", "in", "zip", "(", "templates", ",", "targets", ",", "generateds", ")", ":", "\n", "                    ", "template", "=", "template", ".", "split", "(", "'<EOS>'", ")", "[", "0", "]", ".", "split", "(", "'<PAD>'", ")", "[", "0", "]", ".", "strip", "(", ")", ".", "split", "(", ")", "\n", "target", "=", "target", ".", "split", "(", "'<EOS>'", ")", "[", "0", "]", ".", "split", "(", "'<PAD>'", ")", "[", "0", "]", ".", "strip", "(", ")", ".", "split", "(", ")", "\n", "got", "=", "generated", ".", "split", "(", "'<EOS>'", ")", "[", "0", "]", ".", "split", "(", "'<PAD>'", ")", "[", "0", "]", ".", "strip", "(", ")", ".", "split", "(", ")", "\n", "templates_list", ".", "append", "(", "template", ")", "\n", "targets_list", ".", "append", "(", "target", ")", "\n", "hypothesis_list", ".", "append", "(", "got", ")", "\n", "\n", "", "cnt", "+=", "1", "\n", "if", "mode", "is", "not", "'test'", "and", "cnt", ">=", "60", ":", "\n", "                    ", "break", "\n", "", "", "except", "tf", ".", "errors", ".", "OutOfRangeError", ":", "\n", "                ", "break", "\n", "\n", "", "", "avg_loss", ",", "avg_ppl", "=", "np", ".", "mean", "(", "loss_lists", ")", ",", "np", ".", "mean", "(", "ppl_lists", ")", "\n", "outputs_tmp_filename", "=", "args", ".", "log_dir", "+", "'epoch{}.beam{}.outputs.tmp'", ".", "format", "(", "cur_epoch", ",", "args", ".", "beam_width", ")", "\n", "template_tmp_filename", "=", "args", ".", "log_dir", "+", "'epoch{}.beam{}.templates.tmp'", ".", "format", "(", "cur_epoch", ",", "args", ".", "beam_width", ")", "\n", "refer_tmp_filename", "=", "os", ".", "path", ".", "join", "(", "args", ".", "log_dir", ",", "'eval_reference.tmp'", ")", "\n", "with", "codecs", ".", "open", "(", "outputs_tmp_filename", ",", "'w+'", ",", "'utf-8'", ")", "as", "tmpfile", ",", "codecs", ".", "open", "(", "template_tmp_filename", ",", "'w+'", ",", "'utf-8'", ")", "as", "tmptpltfile", ",", "codecs", ".", "open", "(", "refer_tmp_filename", ",", "'w+'", ",", "'utf-8'", ")", "as", "tmpreffile", ":", "\n", "            ", "for", "hyp", ",", "tplt", ",", "tgt", "in", "zip", "(", "hypothesis_list", ",", "templates_list", ",", "targets_list", ")", ":", "\n", "                ", "tmpfile", ".", "write", "(", "' '", ".", "join", "(", "hyp", ")", "+", "'\\n'", ")", "\n", "tmptpltfile", ".", "write", "(", "' '", ".", "join", "(", "tplt", ")", "+", "'\\n'", ")", "\n", "tmpreffile", ".", "write", "(", "' '", ".", "join", "(", "tgt", ")", "+", "'\\n'", ")", "\n", "", "", "eval_bleu", "=", "float", "(", "100", "*", "bleu_tool", ".", "bleu_wrapper", "(", "refer_tmp_filename", ",", "outputs_tmp_filename", ",", "case_sensitive", "=", "True", ")", ")", "\n", "template_bleu", "=", "float", "(", "100", "*", "bleu_tool", ".", "bleu_wrapper", "(", "refer_tmp_filename", ",", "template_tmp_filename", ",", "case_sensitive", "=", "True", ")", ")", "\n", "print", "(", "'epoch:{} {}_bleu:{} template_bleu:{} {}_loss:{} {}_ppl:{} '", ".", "\n", "format", "(", "cur_epoch", ",", "mode", ",", "eval_bleu", ",", "template_bleu", ",", "mode", ",", "avg_loss", ",", "mode", ",", "avg_ppl", ")", ")", "\n", "os", ".", "remove", "(", "outputs_tmp_filename", ")", "\n", "os", ".", "remove", "(", "template_tmp_filename", ")", "\n", "os", ".", "remove", "(", "refer_tmp_filename", ")", "\n", "if", "args", ".", "save_eval_output", ":", "\n", "            ", "result_filename", "=", "args", ".", "log_dir", "+", "'epoch{}.beam{}.{}.results.bleu{:.3f}'", ".", "format", "(", "cur_epoch", ",", "args", ".", "beam_width", ",", "mode", ",", "eval_bleu", ")", "\n", "with", "codecs", ".", "open", "(", "result_filename", ",", "'w+'", ",", "'utf-8'", ")", "as", "resultfile", ":", "\n", "                ", "for", "tmplt", ",", "tgt", ",", "hyp", "in", "zip", "(", "templates_list", ",", "targets_list", ",", "hypothesis_list", ")", ":", "\n", "                    ", "resultfile", ".", "write", "(", "\"- template: \"", "+", "' '", ".", "join", "(", "tmplt", ")", "+", "'\\n'", ")", "\n", "resultfile", ".", "write", "(", "\"- expected: \"", "+", "' '", ".", "join", "(", "tgt", ")", "+", "'\\n'", ")", "\n", "resultfile", ".", "write", "(", "'- got:      '", "+", "' '", ".", "join", "(", "hyp", ")", "+", "'\\n\\n'", ")", "\n", "", "", "", "return", "{", "\n", "'eval'", ":", "eval_bleu", ",", "\n", "'template'", ":", "template_bleu", "\n", "}", ",", "avg_ppl", "\n", "\n", "", "def", "_draw_train_loss", "(", "epoch", ",", "loss_list", ",", "mode", ")", ":", "\n", "        ", "plt", ".", "figure", "(", "figsize", "=", "(", "14", ",", "10", ")", ")", "\n", "plt", ".", "plot", "(", "loss_list", ",", "'--'", ",", "linewidth", "=", "1", ",", "label", "=", "'loss trend'", ")", "\n", "plt", ".", "ylabel", "(", "'%s till epoch %s'", "%", "(", "mode", ",", "epoch", ")", ")", "\n", "plt", ".", "xlabel", "(", "'every 50 steps, present_rate=%f'", "%", "args", ".", "present_rate", ")", "\n", "plt", ".", "savefig", "(", "args", ".", "log_dir", "+", "'/img/%s_curve.png'", "%", "mode", ")", "\n", "plt", ".", "close", "(", "'all'", ")", "\n", "\n", "", "def", "_draw_bleu", "(", "epoch", ",", "test_bleu", ",", "tplt_bleu", ",", "train_bleu", ",", "train_tplt_bleu", ")", ":", "\n", "        ", "plt", ".", "figure", "(", "figsize", "=", "(", "14", ",", "10", ")", ")", "\n", "legends", "=", "[", "]", "\n", "plt", ".", "plot", "(", "test_bleu", ",", "'--'", ",", "linewidth", "=", "1", ",", "label", "=", "'test bleu'", ")", "\n", "plt", ".", "plot", "(", "tplt_bleu", ",", "'--'", ",", "linewidth", "=", "1", ",", "label", "=", "'template bleu'", ")", "\n", "legends", ".", "extend", "(", "[", "'test bleu'", ",", "'template bleu'", "]", ")", "\n", "plt", ".", "ylabel", "(", "'bleu till epoch {}'", ".", "format", "(", "epoch", ")", ")", "\n", "plt", ".", "xlabel", "(", "'every epoch'", ")", "\n", "plt", ".", "legend", "(", "legends", ",", "loc", "=", "'upper left'", ")", "\n", "plt", ".", "savefig", "(", "args", ".", "log_dir", "+", "'/img/bleu.png'", ")", "\n", "\n", "plt", ".", "figure", "(", "figsize", "=", "(", "14", ",", "10", ")", ")", "\n", "legends", "=", "[", "]", "\n", "plt", ".", "plot", "(", "train_bleu", ",", "'--'", ",", "linewidth", "=", "1", ",", "label", "=", "'train bleu'", ")", "\n", "plt", ".", "plot", "(", "train_tplt_bleu", ",", "'--'", ",", "linewidth", "=", "1", ",", "label", "=", "'train template bleu'", ")", "\n", "legends", ".", "extend", "(", "[", "'train bleu'", ",", "'train template bleu'", "]", ")", "\n", "plt", ".", "ylabel", "(", "'bleu till epoch {}'", ".", "format", "(", "epoch", ")", ")", "\n", "plt", ".", "xlabel", "(", "'every epoch'", ")", "\n", "plt", ".", "legend", "(", "legends", ",", "loc", "=", "'upper left'", ")", "\n", "plt", ".", "savefig", "(", "args", ".", "log_dir", "+", "'/img/train_bleu.png'", ")", "\n", "plt", ".", "close", "(", "'all'", ")", "\n", "\n", "", "config", "=", "tf", ".", "ConfigProto", "(", ")", "\n", "config", ".", "gpu_options", ".", "allow_growth", "=", "True", "\n", "\n", "with", "tf", ".", "Session", "(", "config", "=", "config", ")", "as", "sess", ":", "\n", "        ", "sess", ".", "run", "(", "tf", ".", "global_variables_initializer", "(", ")", ")", "\n", "sess", ".", "run", "(", "tf", ".", "local_variables_initializer", "(", ")", ")", "\n", "sess", ".", "run", "(", "tf", ".", "tables_initializer", "(", ")", ")", "\n", "\n", "loss_list", ",", "ppl_list", ",", "test_ppl_list", "=", "[", "]", ",", "[", "]", ",", "[", "]", "\n", "test_bleu", ",", "tplt_bleu", ",", "train_bleu", ",", "train_tplt_bleu", "=", "[", "]", ",", "[", "]", ",", "[", "]", ",", "[", "]", "\n", "if", "args", ".", "running_mode", "==", "'train_and_evaluate'", ":", "\n", "            ", "for", "epoch", "in", "range", "(", "args", ".", "max_train_epoch", ")", ":", "\n", "# bleu on test set and train set", "\n", "                ", "if", "epoch", "%", "args", ".", "bleu_interval", "==", "0", "or", "epoch", "==", "args", ".", "max_train_epoch", "-", "1", ":", "\n", "                    ", "bleu_scores", ",", "test_ppl", "=", "_test_epoch", "(", "sess", ",", "epoch", ")", "\n", "test_bleu", ".", "append", "(", "bleu_scores", "[", "'eval'", "]", ")", "\n", "tplt_bleu", ".", "append", "(", "bleu_scores", "[", "'template'", "]", ")", "\n", "test_ppl_list", ".", "append", "(", "test_ppl", ")", "\n", "_draw_train_loss", "(", "epoch", ",", "test_ppl_list", ",", "mode", "=", "'test_perplexity'", ")", "\n", "\n", "train_bleu_scores", ",", "_", "=", "_test_epoch", "(", "sess", ",", "epoch", ",", "mode", "=", "'train'", ")", "\n", "train_bleu", ".", "append", "(", "train_bleu_scores", "[", "'eval'", "]", ")", "\n", "train_tplt_bleu", ".", "append", "(", "train_bleu_scores", "[", "'template'", "]", ")", "\n", "_draw_bleu", "(", "epoch", ",", "test_bleu", ",", "tplt_bleu", ",", "train_bleu", ",", "train_tplt_bleu", ")", "\n", "eval_saver", ".", "save", "(", "sess", ",", "args", ".", "log_dir", "+", "'my-model-latest.ckpt'", ")", "\n", "\n", "# train", "\n", "", "losses", ",", "ppls", "=", "_train_epochs", "(", "sess", ",", "epoch", ")", "\n", "loss_list", ".", "extend", "(", "losses", ")", "\n", "ppl_list", ".", "extend", "(", "ppls", ")", "\n", "_draw_train_loss", "(", "epoch", ",", "loss_list", ",", "mode", "=", "'train_loss'", ")", "\n", "_draw_train_loss", "(", "epoch", ",", "ppl_list", ",", "mode", "=", "'perplexity'", ")", "\n", "sys", ".", "stdout", ".", "flush", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.text_infilling.gan_hyperparams.Hyperparams.__init__": [[16, 18], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "self", ".", "help", "=", "\"the hyperparams dictionary to use\"", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.text_infilling.gan_hyperparams.load_hyperparams": [[20, 210], ["gan_hyperparams.Hyperparams", "argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "os.path.abspath", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "print", "print", "print", "os.path.exists", "os.makedirs", "os.path.exists", "os.makedirs"], "function", ["None"], ["", "", "def", "load_hyperparams", "(", ")", ":", "\n", "    ", "\"\"\"\n        main function to define hyperparams\n    \"\"\"", "\n", "# pylint: disable=too-many-statements", "\n", "args", "=", "Hyperparams", "(", ")", "\n", "argparser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "argparser", ".", "add_argument", "(", "'--mask_rate'", ",", "type", "=", "float", ",", "default", "=", "0.5", ")", "\n", "argparser", ".", "add_argument", "(", "'--blank_num'", ",", "type", "=", "int", ",", "default", "=", "1", ")", "\n", "argparser", ".", "add_argument", "(", "'--batch_size'", ",", "type", "=", "int", ",", "default", "=", "400", ")", "# 4096", "\n", "argparser", ".", "add_argument", "(", "'--test_batch_size'", ",", "type", "=", "int", ",", "default", "=", "10", ")", "\n", "argparser", ".", "add_argument", "(", "'--max_seq_length'", ",", "type", "=", "int", ",", "default", "=", "16", ")", "# 256", "\n", "argparser", ".", "add_argument", "(", "'--hidden_dim'", ",", "type", "=", "int", ",", "default", "=", "512", ")", "\n", "argparser", ".", "add_argument", "(", "'--running_mode'", ",", "type", "=", "str", ",", "\n", "default", "=", "'train_and_evaluate'", ",", "\n", "help", "=", "'can also be test mode'", ")", "\n", "argparser", ".", "add_argument", "(", "'--max_training_steps'", ",", "type", "=", "int", ",", "default", "=", "2500000", ")", "\n", "argparser", ".", "add_argument", "(", "'--warmup_steps'", ",", "type", "=", "int", ",", "default", "=", "10000", ")", "\n", "argparser", ".", "add_argument", "(", "'--max_train_epoch'", ",", "type", "=", "int", ",", "default", "=", "150", ")", "\n", "argparser", ".", "add_argument", "(", "'--bleu_interval'", ",", "type", "=", "int", ",", "default", "=", "5", ")", "\n", "argparser", ".", "add_argument", "(", "'--log_disk_dir'", ",", "type", "=", "str", ",", "default", "=", "'./'", ")", "\n", "argparser", ".", "add_argument", "(", "'--filename_prefix'", ",", "type", "=", "str", ",", "default", "=", "'yahoo.'", ")", "\n", "argparser", ".", "add_argument", "(", "'--data_dir'", ",", "type", "=", "str", ",", "\n", "default", "=", "'./yahoo_data/'", ")", "\n", "argparser", ".", "add_argument", "(", "'--save_eval_output'", ",", "default", "=", "1", ",", "\n", "help", "=", "'save the eval output to file'", ")", "\n", "argparser", ".", "add_argument", "(", "'--lr_constant'", ",", "type", "=", "float", ",", "default", "=", "1", ")", "\n", "argparser", ".", "add_argument", "(", "'--learning_rate_strategy'", ",", "type", "=", "str", ",", "default", "=", "'dynamic'", ")", "# 'static'", "\n", "argparser", ".", "add_argument", "(", "'--zero_pad'", ",", "type", "=", "int", ",", "default", "=", "0", ")", "\n", "argparser", ".", "add_argument", "(", "'--bos_pad'", ",", "type", "=", "int", ",", "default", "=", "0", ",", "\n", "help", "=", "'use all-zero embedding for bos'", ")", "\n", "argparser", ".", "add_argument", "(", "'--random_seed'", ",", "type", "=", "int", ",", "default", "=", "1234", ")", "\n", "argparser", ".", "add_argument", "(", "'--beam_width'", ",", "type", "=", "int", ",", "default", "=", "2", ")", "\n", "argparser", ".", "add_argument", "(", "'--gamma_decay'", ",", "type", "=", "float", ",", "default", "=", "0.5", ")", "\n", "argparser", ".", "add_argument", "(", "'--lambda_g'", ",", "type", "=", "float", ",", "default", "=", "0.0001", ")", "\n", "argparser", ".", "parse_args", "(", "namespace", "=", "args", ")", "\n", "\n", "args", ".", "present_rate", "=", "1", "-", "args", ".", "mask_rate", "\n", "args", ".", "pretrain_epoch", "=", "args", ".", "max_train_epoch", "*", "0.8", "\n", "args", ".", "max_decode_len", "=", "args", ".", "max_seq_length", "\n", "args", ".", "data_dir", "=", "os", ".", "path", ".", "abspath", "(", "args", ".", "data_dir", ")", "\n", "args", ".", "filename_suffix", "=", "'.txt'", "\n", "args", ".", "train_file", "=", "os", ".", "path", ".", "join", "(", "args", ".", "data_dir", ",", "\n", "'{}train{}'", ".", "format", "(", "args", ".", "filename_prefix", ",", "args", ".", "filename_suffix", ")", ")", "\n", "args", ".", "valid_file", "=", "os", ".", "path", ".", "join", "(", "args", ".", "data_dir", ",", "\n", "'{}valid{}'", ".", "format", "(", "args", ".", "filename_prefix", ",", "args", ".", "filename_suffix", ")", ")", "\n", "args", ".", "test_file", "=", "os", ".", "path", ".", "join", "(", "args", ".", "data_dir", ",", "\n", "'{}test{}'", ".", "format", "(", "args", ".", "filename_prefix", ",", "args", ".", "filename_suffix", ")", ")", "\n", "args", ".", "vocab_file", "=", "os", ".", "path", ".", "join", "(", "args", ".", "data_dir", ",", "'vocab.txt'", ")", "\n", "log_params_dir", "=", "'log_dir/{}bsize{}.epoch{}.seqlen{}.{}_lr.present{}.partition{}.hidden{}.gan/'", ".", "format", "(", "\n", "args", ".", "filename_prefix", ",", "args", ".", "batch_size", ",", "args", ".", "max_train_epoch", ",", "args", ".", "max_seq_length", ",", "\n", "args", ".", "learning_rate_strategy", ",", "args", ".", "present_rate", ",", "args", ".", "blank_num", ",", "args", ".", "hidden_dim", ")", "\n", "args", ".", "log_dir", "=", "os", ".", "path", ".", "join", "(", "args", ".", "log_disk_dir", ",", "log_params_dir", ")", "\n", "print", "(", "'train_file:{}'", ".", "format", "(", "args", ".", "train_file", ")", ")", "\n", "print", "(", "'valid_file:{}'", ".", "format", "(", "args", ".", "valid_file", ")", ")", "\n", "train_dataset_hparams", "=", "{", "\n", "\"num_epochs\"", ":", "1", ",", "\n", "\"seed\"", ":", "args", ".", "random_seed", ",", "\n", "\"shuffle\"", ":", "True", ",", "\n", "\"dataset\"", ":", "{", "\n", "\"files\"", ":", "args", ".", "train_file", ",", "\n", "\"vocab_file\"", ":", "args", ".", "vocab_file", ",", "\n", "\"max_seq_length\"", ":", "args", ".", "max_seq_length", ",", "\n", "\"bos_token\"", ":", "SpecialTokens", ".", "BOS", ",", "\n", "\"eos_token\"", ":", "SpecialTokens", ".", "EOS", ",", "\n", "\"length_filter_mode\"", ":", "\"truncate\"", ",", "\n", "}", ",", "\n", "'batch_size'", ":", "args", ".", "batch_size", ",", "\n", "'allow_smaller_final_batch'", ":", "True", ",", "\n", "}", "\n", "eval_dataset_hparams", "=", "{", "\n", "\"num_epochs\"", ":", "1", ",", "\n", "'seed'", ":", "args", ".", "random_seed", ",", "\n", "'shuffle'", ":", "False", ",", "\n", "'dataset'", ":", "{", "\n", "'files'", ":", "args", ".", "valid_file", ",", "\n", "'vocab_file'", ":", "args", ".", "vocab_file", ",", "\n", "\"max_seq_length\"", ":", "args", ".", "max_seq_length", ",", "\n", "\"bos_token\"", ":", "SpecialTokens", ".", "BOS", ",", "\n", "\"eos_token\"", ":", "SpecialTokens", ".", "EOS", ",", "\n", "\"length_filter_mode\"", ":", "\"truncate\"", ",", "\n", "}", ",", "\n", "'batch_size'", ":", "args", ".", "test_batch_size", ",", "\n", "'allow_smaller_final_batch'", ":", "True", ",", "\n", "}", "\n", "test_dataset_hparams", "=", "{", "\n", "\"num_epochs\"", ":", "1", ",", "\n", "\"seed\"", ":", "args", ".", "random_seed", ",", "\n", "\"shuffle\"", ":", "False", ",", "\n", "\"dataset\"", ":", "{", "\n", "\"files\"", ":", "args", ".", "test_file", ",", "\n", "\"vocab_file\"", ":", "args", ".", "vocab_file", ",", "\n", "\"max_seq_length\"", ":", "args", ".", "max_seq_length", ",", "\n", "\"bos_token\"", ":", "SpecialTokens", ".", "BOS", ",", "\n", "\"eos_token\"", ":", "SpecialTokens", ".", "EOS", ",", "\n", "\"length_filter_mode\"", ":", "\"truncate\"", ",", "\n", "}", ",", "\n", "'batch_size'", ":", "args", ".", "test_batch_size", ",", "\n", "'allow_smaller_final_batch'", ":", "True", ",", "\n", "}", "\n", "args", ".", "word_embedding_hparams", "=", "{", "\n", "'name'", ":", "'lookup_table'", ",", "\n", "'dim'", ":", "args", ".", "hidden_dim", ",", "\n", "'initializer'", ":", "{", "\n", "'type'", ":", "'random_normal_initializer'", ",", "\n", "'kwargs'", ":", "{", "\n", "'mean'", ":", "0.0", ",", "\n", "'stddev'", ":", "args", ".", "hidden_dim", "**", "-", "0.5", ",", "\n", "}", ",", "\n", "}", "\n", "}", "\n", "cell", "=", "{", "\n", "\"type\"", ":", "\"LSTMBlockCell\"", ",", "\n", "\"kwargs\"", ":", "{", "\n", "\"num_units\"", ":", "args", ".", "hidden_dim", "*", "4", ",", "\n", "\"forget_bias\"", ":", "0.", "\n", "}", ",", "\n", "\"dropout\"", ":", "{", "\"output_keep_prob\"", ":", "1", "-", "0.1", "}", ",", "\n", "\"num_layers\"", ":", "1", "\n", "}", "\n", "output_layer", "=", "{", "\n", "\"num_layers\"", ":", "0", ",", "\n", "\"layer_size\"", ":", "args", ".", "hidden_dim", "*", "4", ",", "\n", "\"activation\"", ":", "\"identity\"", ",", "\n", "\"final_layer_activation\"", ":", "None", ",", "\n", "\"other_dense_kwargs\"", ":", "None", ",", "\n", "\"dropout_layer_ids\"", ":", "[", "]", ",", "\n", "\"dropout_rate\"", ":", "0.1", ",", "\n", "\"variational_dropout\"", ":", "False", ",", "\n", "\"@no_typecheck\"", ":", "[", "\"activation\"", ",", "\"final_layer_activation\"", ",", "\n", "\"layer_size\"", ",", "\"dropout_layer_ids\"", "]", "\n", "}", "\n", "encoder_hparams", "=", "{", "\n", "\"rnn_cell\"", ":", "cell", ",", "\n", "\"output_layer\"", ":", "output_layer", ",", "\n", "\"name\"", ":", "\"unidirectional_rnn_encoder\"", "\n", "}", "\n", "decoder_hparams", "=", "{", "\n", "\"rnn_cell\"", ":", "cell", ",", "\n", "\"max_decoding_length_train\"", ":", "args", ".", "max_seq_length", "+", "2", ",", "\n", "\"max_decoding_length_infer\"", ":", "args", ".", "max_seq_length", "+", "2", ",", "\n", "\"name\"", ":", "\"basic_rnn_decoder\"", "\n", "}", "\n", "classifier_hparams", "=", "{", "\n", "'kernel_size'", ":", "[", "3", ",", "4", ",", "5", "]", ",", "\n", "'filters'", ":", "128", ",", "\n", "'other_conv_kwargs'", ":", "{", "'padding'", ":", "'same'", "}", ",", "\n", "'dropout_conv'", ":", "[", "1", "]", ",", "\n", "'dropout_rate'", ":", "0.5", ",", "\n", "'num_dense_layers'", ":", "0", ",", "\n", "'num_classes'", ":", "1", "\n", "}", "\n", "\n", "loss_hparams", "=", "{", "\n", "'label_confidence'", ":", "0.9", ",", "\n", "}", "\n", "\n", "opt_hparams", "=", "{", "\n", "'learning_rate_schedule'", ":", "args", ".", "learning_rate_strategy", ",", "\n", "'lr_constant'", ":", "args", ".", "lr_constant", ",", "\n", "'warmup_steps'", ":", "args", ".", "warmup_steps", ",", "\n", "'max_training_steps'", ":", "args", ".", "max_training_steps", ",", "\n", "'Adam_beta1'", ":", "0.9", ",", "\n", "'Adam_beta2'", ":", "0.997", ",", "\n", "'Adam_epsilon'", ":", "1e-9", ",", "\n", "}", "\n", "d_opt", "=", "{", "\n", "'optimizer'", ":", "{", "\n", "'type'", ":", "'AdamOptimizer'", ",", "\n", "'kwargs'", ":", "{", "\n", "'learning_rate'", ":", "5e-4", ",", "\n", "}", ",", "\n", "}", ",", "\n", "}", "\n", "print", "(", "'logdir:{}'", ".", "format", "(", "args", ".", "log_dir", ")", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "args", ".", "log_dir", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "args", ".", "log_dir", ")", "\n", "", "if", "not", "os", ".", "path", ".", "exists", "(", "args", ".", "log_dir", "+", "'img/'", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "args", ".", "log_dir", "+", "'img/'", ")", "\n", "", "return", "{", "\n", "'train_dataset_hparams'", ":", "train_dataset_hparams", ",", "\n", "'eval_dataset_hparams'", ":", "eval_dataset_hparams", ",", "\n", "'test_dataset_hparams'", ":", "test_dataset_hparams", ",", "\n", "'encoder_hparams'", ":", "encoder_hparams", ",", "\n", "'decoder_hparams'", ":", "decoder_hparams", ",", "\n", "'classifier_hparams'", ":", "classifier_hparams", ",", "\n", "'loss_hparams'", ":", "loss_hparams", ",", "\n", "'opt_hparams'", ":", "opt_hparams", ",", "\n", "'d_opt'", ":", "d_opt", ",", "\n", "'args'", ":", "args", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.text_infilling.seq2seq_hyperparams.Hyperparams.__init__": [[16, 18], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "self", ".", "help", "=", "\"the hyperparams dictionary to use\"", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.text_infilling.seq2seq_hyperparams.load_hyperparams": [[20, 208], ["seq2seq_hyperparams.Hyperparams", "argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "os.path.abspath", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "print", "print", "print", "os.path.exists", "os.makedirs", "os.path.exists", "os.makedirs"], "function", ["None"], ["", "", "def", "load_hyperparams", "(", ")", ":", "\n", "    ", "\"\"\"\n        main function to define hyperparams\n    \"\"\"", "\n", "# pylint: disable=too-many-statements", "\n", "args", "=", "Hyperparams", "(", ")", "\n", "argparser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "argparser", ".", "add_argument", "(", "'--mask_rate'", ",", "type", "=", "float", ",", "default", "=", "0.5", ")", "\n", "argparser", ".", "add_argument", "(", "'--blank_num'", ",", "type", "=", "int", ",", "default", "=", "1", ")", "\n", "argparser", ".", "add_argument", "(", "'--batch_size'", ",", "type", "=", "int", ",", "default", "=", "400", ")", "# 4096", "\n", "argparser", ".", "add_argument", "(", "'--test_batch_size'", ",", "type", "=", "int", ",", "default", "=", "10", ")", "\n", "argparser", ".", "add_argument", "(", "'--max_seq_length'", ",", "type", "=", "int", ",", "default", "=", "16", ")", "# 256", "\n", "argparser", ".", "add_argument", "(", "'--hidden_dim'", ",", "type", "=", "int", ",", "default", "=", "512", ")", "\n", "argparser", ".", "add_argument", "(", "'--running_mode'", ",", "type", "=", "str", ",", "\n", "default", "=", "'train_and_evaluate'", ",", "\n", "help", "=", "'can also be test mode'", ")", "\n", "argparser", ".", "add_argument", "(", "'--max_training_steps'", ",", "type", "=", "int", ",", "default", "=", "2500000", ")", "\n", "argparser", ".", "add_argument", "(", "'--warmup_steps'", ",", "type", "=", "int", ",", "default", "=", "10000", ")", "\n", "argparser", ".", "add_argument", "(", "'--max_train_epoch'", ",", "type", "=", "int", ",", "default", "=", "150", ")", "\n", "argparser", ".", "add_argument", "(", "'--bleu_interval'", ",", "type", "=", "int", ",", "default", "=", "5", ")", "\n", "argparser", ".", "add_argument", "(", "'--log_disk_dir'", ",", "type", "=", "str", ",", "default", "=", "'./'", ")", "\n", "argparser", ".", "add_argument", "(", "'--filename_prefix'", ",", "type", "=", "str", ",", "default", "=", "'yahoo.'", ")", "\n", "argparser", ".", "add_argument", "(", "'--data_dir'", ",", "type", "=", "str", ",", "\n", "default", "=", "'./yahoo_data/'", ")", "\n", "argparser", ".", "add_argument", "(", "'--save_eval_output'", ",", "default", "=", "1", ",", "\n", "help", "=", "'save the eval output to file'", ")", "\n", "argparser", ".", "add_argument", "(", "'--lr_constant'", ",", "type", "=", "float", ",", "default", "=", "1", ")", "\n", "argparser", ".", "add_argument", "(", "'--learning_rate_strategy'", ",", "type", "=", "str", ",", "default", "=", "'dynamic'", ")", "# 'static'", "\n", "argparser", ".", "add_argument", "(", "'--zero_pad'", ",", "type", "=", "int", ",", "default", "=", "0", ")", "\n", "argparser", ".", "add_argument", "(", "'--bos_pad'", ",", "type", "=", "int", ",", "default", "=", "0", ",", "\n", "help", "=", "'use all-zero embedding for bos'", ")", "\n", "argparser", ".", "add_argument", "(", "'--random_seed'", ",", "type", "=", "int", ",", "default", "=", "1234", ")", "\n", "argparser", ".", "add_argument", "(", "'--beam_width'", ",", "type", "=", "int", ",", "default", "=", "2", ")", "\n", "argparser", ".", "parse_args", "(", "namespace", "=", "args", ")", "\n", "\n", "args", ".", "present_rate", "=", "1", "-", "args", ".", "mask_rate", "\n", "args", ".", "pretrain_epoch", "=", "args", ".", "max_train_epoch", "*", "0.8", "\n", "args", ".", "max_decode_len", "=", "args", ".", "max_seq_length", "\n", "args", ".", "data_dir", "=", "os", ".", "path", ".", "abspath", "(", "args", ".", "data_dir", ")", "\n", "args", ".", "filename_suffix", "=", "'.txt'", "\n", "args", ".", "train_file", "=", "os", ".", "path", ".", "join", "(", "args", ".", "data_dir", ",", "\n", "'{}train{}'", ".", "format", "(", "args", ".", "filename_prefix", ",", "args", ".", "filename_suffix", ")", ")", "\n", "args", ".", "valid_file", "=", "os", ".", "path", ".", "join", "(", "args", ".", "data_dir", ",", "\n", "'{}valid{}'", ".", "format", "(", "args", ".", "filename_prefix", ",", "args", ".", "filename_suffix", ")", ")", "\n", "args", ".", "test_file", "=", "os", ".", "path", ".", "join", "(", "args", ".", "data_dir", ",", "\n", "'{}test{}'", ".", "format", "(", "args", ".", "filename_prefix", ",", "args", ".", "filename_suffix", ")", ")", "\n", "args", ".", "vocab_file", "=", "os", ".", "path", ".", "join", "(", "args", ".", "data_dir", ",", "'vocab.txt'", ")", "\n", "log_params_dir", "=", "'log_dir/{}bsize{}.epoch{}.seqlen{}.{}_lr.present{}.partition{}.hidden{}.seq2seq/'", ".", "format", "(", "\n", "args", ".", "filename_prefix", ",", "args", ".", "batch_size", ",", "args", ".", "max_train_epoch", ",", "args", ".", "max_seq_length", ",", "\n", "args", ".", "learning_rate_strategy", ",", "args", ".", "present_rate", ",", "args", ".", "blank_num", ",", "args", ".", "hidden_dim", ")", "\n", "args", ".", "log_dir", "=", "os", ".", "path", ".", "join", "(", "args", ".", "log_disk_dir", ",", "log_params_dir", ")", "\n", "print", "(", "'train_file:{}'", ".", "format", "(", "args", ".", "train_file", ")", ")", "\n", "print", "(", "'valid_file:{}'", ".", "format", "(", "args", ".", "valid_file", ")", ")", "\n", "train_dataset_hparams", "=", "{", "\n", "\"num_epochs\"", ":", "1", ",", "\n", "\"seed\"", ":", "args", ".", "random_seed", ",", "\n", "\"shuffle\"", ":", "True", ",", "\n", "\"dataset\"", ":", "{", "\n", "\"files\"", ":", "args", ".", "train_file", ",", "\n", "\"vocab_file\"", ":", "args", ".", "vocab_file", ",", "\n", "\"max_seq_length\"", ":", "args", ".", "max_seq_length", ",", "\n", "\"bos_token\"", ":", "SpecialTokens", ".", "BOS", ",", "\n", "\"eos_token\"", ":", "SpecialTokens", ".", "EOS", ",", "\n", "\"length_filter_mode\"", ":", "\"truncate\"", ",", "\n", "}", ",", "\n", "'batch_size'", ":", "args", ".", "batch_size", ",", "\n", "'allow_smaller_final_batch'", ":", "True", ",", "\n", "}", "\n", "eval_dataset_hparams", "=", "{", "\n", "\"num_epochs\"", ":", "1", ",", "\n", "'seed'", ":", "args", ".", "random_seed", ",", "\n", "'shuffle'", ":", "False", ",", "\n", "'dataset'", ":", "{", "\n", "'files'", ":", "args", ".", "valid_file", ",", "\n", "'vocab_file'", ":", "args", ".", "vocab_file", ",", "\n", "\"max_seq_length\"", ":", "args", ".", "max_seq_length", ",", "\n", "\"bos_token\"", ":", "SpecialTokens", ".", "BOS", ",", "\n", "\"eos_token\"", ":", "SpecialTokens", ".", "EOS", ",", "\n", "\"length_filter_mode\"", ":", "\"truncate\"", ",", "\n", "}", ",", "\n", "'batch_size'", ":", "args", ".", "test_batch_size", ",", "\n", "'allow_smaller_final_batch'", ":", "True", ",", "\n", "}", "\n", "test_dataset_hparams", "=", "{", "\n", "\"num_epochs\"", ":", "1", ",", "\n", "\"seed\"", ":", "args", ".", "random_seed", ",", "\n", "\"shuffle\"", ":", "False", ",", "\n", "\"dataset\"", ":", "{", "\n", "\"files\"", ":", "args", ".", "test_file", ",", "\n", "\"vocab_file\"", ":", "args", ".", "vocab_file", ",", "\n", "\"max_seq_length\"", ":", "args", ".", "max_seq_length", ",", "\n", "\"bos_token\"", ":", "SpecialTokens", ".", "BOS", ",", "\n", "\"eos_token\"", ":", "SpecialTokens", ".", "EOS", ",", "\n", "\"length_filter_mode\"", ":", "\"truncate\"", ",", "\n", "}", ",", "\n", "'batch_size'", ":", "args", ".", "test_batch_size", ",", "\n", "'allow_smaller_final_batch'", ":", "True", ",", "\n", "}", "\n", "args", ".", "word_embedding_hparams", "=", "{", "\n", "'name'", ":", "'lookup_table'", ",", "\n", "'dim'", ":", "args", ".", "hidden_dim", ",", "\n", "'initializer'", ":", "{", "\n", "'type'", ":", "'random_normal_initializer'", ",", "\n", "'kwargs'", ":", "{", "\n", "'mean'", ":", "0.0", ",", "\n", "'stddev'", ":", "args", ".", "hidden_dim", "**", "-", "0.5", ",", "\n", "}", ",", "\n", "}", "\n", "}", "\n", "cell", "=", "{", "\n", "\"type\"", ":", "\"LSTMBlockCell\"", ",", "\n", "\"kwargs\"", ":", "{", "\n", "\"num_units\"", ":", "args", ".", "hidden_dim", "*", "4", ",", "\n", "\"forget_bias\"", ":", "0.", "\n", "}", ",", "\n", "\"dropout\"", ":", "{", "\"output_keep_prob\"", ":", "1", "-", "0.1", "}", ",", "\n", "\"num_layers\"", ":", "1", "\n", "}", "\n", "output_layer", "=", "{", "\n", "\"num_layers\"", ":", "0", ",", "\n", "\"layer_size\"", ":", "args", ".", "hidden_dim", "*", "4", ",", "\n", "\"activation\"", ":", "\"identity\"", ",", "\n", "\"final_layer_activation\"", ":", "None", ",", "\n", "\"other_dense_kwargs\"", ":", "None", ",", "\n", "\"dropout_layer_ids\"", ":", "[", "]", ",", "\n", "\"dropout_rate\"", ":", "0.1", ",", "\n", "\"variational_dropout\"", ":", "False", ",", "\n", "\"@no_typecheck\"", ":", "[", "\"activation\"", ",", "\"final_layer_activation\"", ",", "\n", "\"layer_size\"", ",", "\"dropout_layer_ids\"", "]", "\n", "}", "\n", "encoder_hparams", "=", "{", "\n", "\"rnn_cell\"", ":", "cell", ",", "\n", "\"output_layer\"", ":", "output_layer", ",", "\n", "\"name\"", ":", "\"unidirectional_rnn_encoder\"", "\n", "}", "\n", "decoder_hparams", "=", "{", "\n", "\"rnn_cell\"", ":", "cell", ",", "\n", "\"max_decoding_length_train\"", ":", "args", ".", "max_seq_length", "+", "2", ",", "\n", "\"max_decoding_length_infer\"", ":", "args", ".", "max_seq_length", "+", "2", ",", "\n", "\"name\"", ":", "\"basic_rnn_decoder\"", "\n", "}", "\n", "classifier_hparams", "=", "{", "\n", "'kernel_size'", ":", "[", "3", ",", "4", ",", "5", "]", ",", "\n", "'filters'", ":", "128", ",", "\n", "'other_conv_kwargs'", ":", "{", "'padding'", ":", "'same'", "}", ",", "\n", "'dropout_conv'", ":", "[", "1", "]", ",", "\n", "'dropout_rate'", ":", "0.5", ",", "\n", "'num_dense_layers'", ":", "0", ",", "\n", "'num_classes'", ":", "1", "\n", "}", "\n", "\n", "loss_hparams", "=", "{", "\n", "'label_confidence'", ":", "0.9", ",", "\n", "}", "\n", "\n", "opt_hparams", "=", "{", "\n", "'learning_rate_schedule'", ":", "args", ".", "learning_rate_strategy", ",", "\n", "'lr_constant'", ":", "args", ".", "lr_constant", ",", "\n", "'warmup_steps'", ":", "args", ".", "warmup_steps", ",", "\n", "'max_training_steps'", ":", "args", ".", "max_training_steps", ",", "\n", "'Adam_beta1'", ":", "0.9", ",", "\n", "'Adam_beta2'", ":", "0.997", ",", "\n", "'Adam_epsilon'", ":", "1e-9", ",", "\n", "}", "\n", "d_opt", "=", "{", "\n", "'optimizer'", ":", "{", "\n", "'type'", ":", "'AdamOptimizer'", ",", "\n", "'kwargs'", ":", "{", "\n", "'learning_rate'", ":", "5e-4", ",", "\n", "}", ",", "\n", "}", ",", "\n", "}", "\n", "print", "(", "'logdir:{}'", ".", "format", "(", "args", ".", "log_dir", ")", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "args", ".", "log_dir", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "args", ".", "log_dir", ")", "\n", "", "if", "not", "os", ".", "path", ".", "exists", "(", "args", ".", "log_dir", "+", "'img/'", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "args", ".", "log_dir", "+", "'img/'", ")", "\n", "", "return", "{", "\n", "'train_dataset_hparams'", ":", "train_dataset_hparams", ",", "\n", "'eval_dataset_hparams'", ":", "eval_dataset_hparams", ",", "\n", "'test_dataset_hparams'", ":", "test_dataset_hparams", ",", "\n", "'encoder_hparams'", ":", "encoder_hparams", ",", "\n", "'decoder_hparams'", ":", "decoder_hparams", ",", "\n", "'classifier_hparams'", ":", "classifier_hparams", ",", "\n", "'loss_hparams'", ":", "loss_hparams", ",", "\n", "'opt_hparams'", ":", "opt_hparams", ",", "\n", "'d_opt'", ":", "d_opt", ",", "\n", "'args'", ":", "args", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.text_infilling.self_attn_hyperparams.Hyperparams.__init__": [[17, 19], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "self", ".", "help", "=", "\"the hyperparams dictionary to use\"", "\n", "\n"]], "home.repos.pwc.inspect_result.VegB_Text_Infilling.text_infilling.self_attn_hyperparams.load_hyperparams": [[21, 230], ["self_attn_hyperparams.Hyperparams", "argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "os.path.abspath", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "print", "print", "copy.deepcopy", "print", "os.path.exists", "os.makedirs", "os.path.exists", "os.makedirs"], "function", ["None"], ["", "", "def", "load_hyperparams", "(", ")", ":", "\n", "    ", "\"\"\"\n        main function to define hyperparams\n    \"\"\"", "\n", "# pylint: disable=too-many-statements", "\n", "args", "=", "Hyperparams", "(", ")", "\n", "argparser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "argparser", ".", "add_argument", "(", "'--mask_rate'", ",", "type", "=", "float", ",", "default", "=", "0.5", ")", "\n", "argparser", ".", "add_argument", "(", "'--blank_num'", ",", "type", "=", "int", ",", "default", "=", "1", ")", "\n", "argparser", ".", "add_argument", "(", "'--batch_size'", ",", "type", "=", "int", ",", "default", "=", "400", ")", "\n", "argparser", ".", "add_argument", "(", "'--test_batch_size'", ",", "type", "=", "int", ",", "default", "=", "10", ")", "\n", "argparser", ".", "add_argument", "(", "'--max_seq_length'", ",", "type", "=", "int", ",", "default", "=", "16", ")", "\n", "argparser", ".", "add_argument", "(", "'--hidden_dim'", ",", "type", "=", "int", ",", "default", "=", "512", ")", "\n", "argparser", ".", "add_argument", "(", "'--running_mode'", ",", "type", "=", "str", ",", "\n", "default", "=", "'train_and_evaluate'", ",", "\n", "help", "=", "'can also be test mode'", ")", "\n", "argparser", ".", "add_argument", "(", "'--max_training_steps'", ",", "type", "=", "int", ",", "default", "=", "2500000", ")", "\n", "argparser", ".", "add_argument", "(", "'--warmup_steps'", ",", "type", "=", "int", ",", "default", "=", "10000", ")", "\n", "argparser", ".", "add_argument", "(", "'--max_train_epoch'", ",", "type", "=", "int", ",", "default", "=", "150", ")", "\n", "argparser", ".", "add_argument", "(", "'--bleu_interval'", ",", "type", "=", "int", ",", "default", "=", "5", ")", "\n", "argparser", ".", "add_argument", "(", "'--decay_interval'", ",", "type", "=", "float", ",", "default", "=", "20", ")", "\n", "argparser", ".", "add_argument", "(", "'--log_disk_dir'", ",", "type", "=", "str", ",", "default", "=", "'./'", ")", "\n", "argparser", ".", "add_argument", "(", "'--filename_prefix'", ",", "type", "=", "str", ",", "default", "=", "'yahoo.'", ")", "\n", "argparser", ".", "add_argument", "(", "'--data_dir'", ",", "type", "=", "str", ",", "\n", "default", "=", "'./yahoo_data/'", ")", "\n", "argparser", ".", "add_argument", "(", "'--save_eval_output'", ",", "default", "=", "1", ",", "\n", "help", "=", "'save the eval output to file'", ")", "\n", "argparser", ".", "add_argument", "(", "'--lr_constant'", ",", "type", "=", "float", ",", "default", "=", "0.3", ")", "\n", "argparser", ".", "add_argument", "(", "'--lr_decay_rate'", ",", "type", "=", "float", ",", "default", "=", "0.1", ")", "\n", "argparser", ".", "add_argument", "(", "'--lr_factor'", ",", "type", "=", "float", ",", "default", "=", "0.1", ")", "\n", "argparser", ".", "add_argument", "(", "'--learning_rate_strategy'", ",", "type", "=", "str", ",", "default", "=", "'dynamic'", ")", "# 'static'", "\n", "argparser", ".", "add_argument", "(", "'--zero_pad'", ",", "type", "=", "int", ",", "default", "=", "0", ")", "\n", "argparser", ".", "add_argument", "(", "'--bos_pad'", ",", "type", "=", "int", ",", "default", "=", "0", ",", "\n", "help", "=", "'use all-zero embedding for bos'", ")", "\n", "argparser", ".", "add_argument", "(", "'--random_seed'", ",", "type", "=", "int", ",", "default", "=", "1234", ")", "\n", "argparser", ".", "add_argument", "(", "'--beam_width'", ",", "type", "=", "int", ",", "default", "=", "2", ")", "\n", "argparser", ".", "add_argument", "(", "'--affine_bias'", ",", "type", "=", "int", ",", "default", "=", "0", ")", "\n", "argparser", ".", "parse_args", "(", "namespace", "=", "args", ")", "\n", "\n", "args", ".", "present_rate", "=", "1", "-", "args", ".", "mask_rate", "\n", "args", ".", "max_decode_len", "=", "args", ".", "max_seq_length", "\n", "args", ".", "data_dir", "=", "os", ".", "path", ".", "abspath", "(", "args", ".", "data_dir", ")", "\n", "args", ".", "filename_suffix", "=", "'.txt'", "\n", "args", ".", "train_file", "=", "os", ".", "path", ".", "join", "(", "args", ".", "data_dir", ",", "\n", "'{}train{}'", ".", "format", "(", "args", ".", "filename_prefix", ",", "args", ".", "filename_suffix", ")", ")", "\n", "args", ".", "valid_file", "=", "os", ".", "path", ".", "join", "(", "args", ".", "data_dir", ",", "\n", "'{}valid{}'", ".", "format", "(", "args", ".", "filename_prefix", ",", "args", ".", "filename_suffix", ")", ")", "\n", "args", ".", "test_file", "=", "os", ".", "path", ".", "join", "(", "args", ".", "data_dir", ",", "\n", "'{}test{}'", ".", "format", "(", "args", ".", "filename_prefix", ",", "args", ".", "filename_suffix", ")", ")", "\n", "args", ".", "vocab_file", "=", "os", ".", "path", ".", "join", "(", "args", ".", "data_dir", ",", "'vocab.txt'", ")", "\n", "log_params_dir", "=", "'log_dir/{}bsize{}.epoch{}.seqlen{}.{}_lr.present{}.partition{}.hidden{}.self_attn/'", ".", "format", "(", "\n", "args", ".", "filename_prefix", ",", "args", ".", "batch_size", ",", "args", ".", "max_train_epoch", ",", "args", ".", "max_seq_length", ",", "\n", "args", ".", "learning_rate_strategy", ",", "args", ".", "present_rate", ",", "args", ".", "blank_num", ",", "args", ".", "hidden_dim", ")", "\n", "args", ".", "log_dir", "=", "os", ".", "path", ".", "join", "(", "args", ".", "log_disk_dir", ",", "log_params_dir", ")", "\n", "print", "(", "'train_file:{}'", ".", "format", "(", "args", ".", "train_file", ")", ")", "\n", "print", "(", "'valid_file:{}'", ".", "format", "(", "args", ".", "valid_file", ")", ")", "\n", "train_dataset_hparams", "=", "{", "\n", "\"num_epochs\"", ":", "1", ",", "\n", "\"seed\"", ":", "args", ".", "random_seed", ",", "\n", "\"shuffle\"", ":", "True", ",", "\n", "\"dataset\"", ":", "{", "\n", "\"files\"", ":", "args", ".", "train_file", ",", "\n", "\"vocab_file\"", ":", "args", ".", "vocab_file", ",", "\n", "\"max_seq_length\"", ":", "args", ".", "max_seq_length", ",", "\n", "\"bos_token\"", ":", "SpecialTokens", ".", "BOS", ",", "\n", "\"eos_token\"", ":", "SpecialTokens", ".", "EOS", ",", "\n", "\"length_filter_mode\"", ":", "\"truncate\"", ",", "\n", "}", ",", "\n", "'batch_size'", ":", "args", ".", "batch_size", ",", "\n", "'allow_smaller_final_batch'", ":", "True", ",", "\n", "}", "\n", "eval_dataset_hparams", "=", "{", "\n", "\"num_epochs\"", ":", "1", ",", "\n", "'seed'", ":", "args", ".", "random_seed", ",", "\n", "'shuffle'", ":", "False", ",", "\n", "'dataset'", ":", "{", "\n", "'files'", ":", "args", ".", "valid_file", ",", "\n", "'vocab_file'", ":", "args", ".", "vocab_file", ",", "\n", "\"max_seq_length\"", ":", "args", ".", "max_seq_length", ",", "\n", "\"bos_token\"", ":", "SpecialTokens", ".", "BOS", ",", "\n", "\"eos_token\"", ":", "SpecialTokens", ".", "EOS", ",", "\n", "\"length_filter_mode\"", ":", "\"truncate\"", ",", "\n", "}", ",", "\n", "'batch_size'", ":", "args", ".", "batch_size", ",", "\n", "'allow_smaller_final_batch'", ":", "True", ",", "\n", "}", "\n", "test_dataset_hparams", "=", "{", "\n", "\"num_epochs\"", ":", "1", ",", "\n", "\"seed\"", ":", "args", ".", "random_seed", ",", "\n", "\"shuffle\"", ":", "False", ",", "\n", "\"dataset\"", ":", "{", "\n", "\"files\"", ":", "args", ".", "test_file", ",", "\n", "\"vocab_file\"", ":", "args", ".", "vocab_file", ",", "\n", "\"max_seq_length\"", ":", "args", ".", "max_seq_length", ",", "\n", "\"bos_token\"", ":", "SpecialTokens", ".", "BOS", ",", "\n", "\"eos_token\"", ":", "SpecialTokens", ".", "EOS", ",", "\n", "\"length_filter_mode\"", ":", "\"truncate\"", ",", "\n", "}", ",", "\n", "'batch_size'", ":", "args", ".", "test_batch_size", ",", "\n", "'allow_smaller_final_batch'", ":", "True", ",", "\n", "}", "\n", "args", ".", "word_embedding_hparams", "=", "{", "\n", "'name'", ":", "'lookup_table'", ",", "\n", "'dim'", ":", "args", ".", "hidden_dim", ",", "\n", "'initializer'", ":", "{", "\n", "'type'", ":", "'random_normal_initializer'", ",", "\n", "'kwargs'", ":", "{", "\n", "'mean'", ":", "0.0", ",", "\n", "'stddev'", ":", "args", ".", "hidden_dim", "**", "-", "0.5", ",", "\n", "}", ",", "\n", "}", "\n", "}", "\n", "encoder_hparams", "=", "{", "\n", "'multiply_embedding_mode'", ":", "\"sqrt_depth\"", ",", "\n", "'embedding_dropout'", ":", "0.1", ",", "\n", "'position_embedder'", ":", "{", "\n", "'name'", ":", "'sinusoids'", ",", "\n", "'hparams'", ":", "None", ",", "\n", "}", ",", "\n", "'attention_dropout'", ":", "0.1", ",", "\n", "'residual_dropout'", ":", "0.1", ",", "\n", "'sinusoid'", ":", "True", ",", "\n", "'num_blocks'", ":", "6", ",", "\n", "'num_heads'", ":", "8", ",", "\n", "'num_units'", ":", "args", ".", "hidden_dim", ",", "\n", "'zero_pad'", ":", "args", ".", "zero_pad", ",", "\n", "'bos_pad'", ":", "args", ".", "bos_pad", ",", "\n", "'initializer'", ":", "{", "\n", "'type'", ":", "'variance_scaling_initializer'", ",", "\n", "'kwargs'", ":", "{", "\n", "'scale'", ":", "1.0", ",", "\n", "'mode'", ":", "'fan_avg'", ",", "\n", "'distribution'", ":", "'uniform'", ",", "\n", "}", ",", "\n", "}", ",", "\n", "'poswise_feedforward'", ":", "{", "\n", "'name'", ":", "'ffn'", ",", "\n", "'layers'", ":", "[", "\n", "{", "\n", "'type'", ":", "'Dense'", ",", "\n", "'kwargs'", ":", "{", "\n", "'name'", ":", "'conv1'", ",", "\n", "'units'", ":", "args", ".", "hidden_dim", "*", "4", ",", "\n", "'activation'", ":", "'relu'", ",", "\n", "'use_bias'", ":", "True", ",", "\n", "}", "\n", "}", ",", "\n", "{", "\n", "'type'", ":", "'Dropout'", ",", "\n", "'kwargs'", ":", "{", "\n", "'rate'", ":", "0.1", ",", "\n", "}", "\n", "}", ",", "\n", "{", "\n", "'type'", ":", "'Dense'", ",", "\n", "'kwargs'", ":", "{", "\n", "'name'", ":", "'conv2'", ",", "\n", "'units'", ":", "args", ".", "hidden_dim", ",", "\n", "'use_bias'", ":", "True", ",", "\n", "}", "\n", "}", "\n", "]", ",", "\n", "}", ",", "\n", "}", "\n", "decoder_hparams", "=", "copy", ".", "deepcopy", "(", "encoder_hparams", ")", "\n", "decoder_hparams", "[", "'share_embed_and_transform'", "]", "=", "True", "\n", "decoder_hparams", "[", "'transform_with_bias'", "]", "=", "args", ".", "affine_bias", "\n", "decoder_hparams", "[", "'maximum_decode_length'", "]", "=", "args", ".", "max_decode_len", "\n", "decoder_hparams", "[", "'beam_width'", "]", "=", "args", ".", "beam_width", "\n", "decoder_hparams", "[", "'sampling_method'", "]", "=", "'argmax'", "\n", "loss_hparams", "=", "{", "\n", "'label_confidence'", ":", "0.9", ",", "\n", "}", "\n", "\n", "opt_hparams", "=", "{", "\n", "'learning_rate_schedule'", ":", "args", ".", "learning_rate_strategy", ",", "\n", "'lr_constant'", ":", "args", ".", "lr_constant", ",", "\n", "'warmup_steps'", ":", "args", ".", "warmup_steps", ",", "\n", "'max_training_steps'", ":", "args", ".", "max_training_steps", ",", "\n", "'Adam_beta1'", ":", "0.9", ",", "\n", "'Adam_beta2'", ":", "0.997", ",", "\n", "'Adam_epsilon'", ":", "1e-9", ",", "\n", "}", "\n", "opt_vars", "=", "{", "\n", "'learning_rate'", ":", "args", ".", "hidden_dim", "**", "-", "0.5", "*", "args", ".", "present_rate", "*", "args", ".", "lr_factor", ",", "# 0.016", "\n", "'best_train_loss'", ":", "1e100", ",", "\n", "'best_eval_loss'", ":", "1e100", ",", "\n", "'best_eval_bleu'", ":", "0", ",", "\n", "'steps_not_improved'", ":", "0", ",", "\n", "'epochs_not_improved'", ":", "0", ",", "\n", "'decay_interval'", ":", "args", ".", "decay_interval", ",", "\n", "'lr_decay_rate'", ":", "args", ".", "lr_decay_rate", ",", "\n", "'decay_time'", ":", "0", "\n", "}", "\n", "print", "(", "'logdir:{}'", ".", "format", "(", "args", ".", "log_dir", ")", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "args", ".", "log_dir", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "args", ".", "log_dir", ")", "\n", "", "if", "not", "os", ".", "path", ".", "exists", "(", "args", ".", "log_dir", "+", "'img/'", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "args", ".", "log_dir", "+", "'img/'", ")", "\n", "", "return", "{", "\n", "'train_dataset_hparams'", ":", "train_dataset_hparams", ",", "\n", "'eval_dataset_hparams'", ":", "eval_dataset_hparams", ",", "\n", "'test_dataset_hparams'", ":", "test_dataset_hparams", ",", "\n", "'encoder_hparams'", ":", "encoder_hparams", ",", "\n", "'decoder_hparams'", ":", "decoder_hparams", ",", "\n", "'loss_hparams'", ":", "loss_hparams", ",", "\n", "'opt_hparams'", ":", "opt_hparams", ",", "\n", "'opt_vars'", ":", "opt_vars", ",", "\n", "'args'", ":", "args", ",", "\n", "}", "\n"]]}