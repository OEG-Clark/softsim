{"home.repos.pwc.inspect_result.ahmedest61_multires-netvlad.None.main.Flatten.forward": [[393, 395], ["input.view", "input.size"], "methods", ["None"], ["    ", "def", "forward", "(", "self", ",", "input", ")", ":", "\n", "        ", "return", "input", ".", "view", "(", "input", ".", "size", "(", "0", ")", ",", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ahmedest61_multires-netvlad.None.main.L2Norm.__init__": [[397, 400], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.ahmedest61_multires-netvlad.training_tools.msls.MSLS.__init__"], ["    ", "def", "__init__", "(", "self", ",", "dim", "=", "1", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dim", "=", "dim", "\n", "\n"]], "home.repos.pwc.inspect_result.ahmedest61_multires-netvlad.None.main.L2Norm.forward": [[401, 403], ["torch.normalize", "torch.normalize", "torch.normalize", "torch.normalize"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input", ")", ":", "\n", "        ", "return", "F", ".", "normalize", "(", "input", ",", "p", "=", "2", ",", "dim", "=", "self", ".", "dim", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ahmedest61_multires-netvlad.None.main.train": [[85, 231], ["range", "print", "wandb.log", "writer.add_scalar", "math.ceil", "numpy.array_split", "print", "model.eval", "torch.utils.data.dataset.Subset", "torch.utils.data.DataLoader", "print", "print", "model.train", "tqdm.tqdm", "len", "optimizer.zero_grad", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "os.remove", "numpy.arange", "numpy.arange", "h5py.File", "h5.create_dataset", "torch.cuda.memory_allocated", "torch.cuda.memory_allocated", "torch.cuda.memory_allocated", "torch.cuda.memory_allocated", "torch.cuda.memory_reserved", "torch.cuda.memory_reserved", "torch.cuda.memory_reserved", "torch.cuda.memory_reserved", "enumerate", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "input.to.to", "model.encoder", "torch.cat.view", "torch.cat.unsqueeze", "model.pool", "torch.split", "torch.split", "torch.split", "torch.split", "optimizer.zero_grad", "enumerate", "torch.sum.float().to", "loss.backward", "optimizer.step", "loss.item", "len", "len", "len", "len", "opt.pooling.lower", "len", "print", "print", "print", "torch.cat.size", "torch.cat.size", "model.encoder", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "range", "print", "exit", "print", "writer.add_scalar", "writer.add_scalar", "wandb.log", "print", "print", "len", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "tqdm.tqdm", "print", "criterion", "torch.sum.float", "torch.cuda.memory_allocated", "torch.cuda.memory_allocated", "torch.cuda.memory_allocated", "torch.cuda.memory_allocated", "torch.cuda.memory_reserved", "torch.cuda.memory_reserved", "torch.cuda.memory_reserved", "torch.cuda.memory_reserved", "enumerate", "input.to.to", "model.encoder", "torch.cat.view", "torch.cat.unsqueeze", "model.pool", "model.pool.detach().cpu().numpy", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "str", "model.encoder.view", "print", "print", "print", "print", "print", "torch.cat.size", "torch.cat.size", "model.encoder", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "print", "print", "print", "model.encoder.size", "model.encoder.size", "len", "print", "print", "print", "model.pool.detach().cpu", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "str", "model.encoder.view", "indices.detach().numpy", "model.encoder.size", "model.encoder.size", "model.pool.detach", "indices.detach"], "function", ["home.repos.pwc.inspect_result.ahmedest61_multires-netvlad.None.main.train"], ["def", "train", "(", "epoch", ")", ":", "\n", "    ", "epoch_loss", "=", "0", "\n", "startIter", "=", "1", "# keep track of batch iter across subsets for logging", "\n", "\n", "if", "opt", ".", "cacheRefreshRate", ">", "0", ":", "\n", "        ", "subsetN", "=", "ceil", "(", "len", "(", "train_set", ")", "/", "opt", ".", "cacheRefreshRate", ")", "\n", "#TODO randomise the arange before splitting?", "\n", "subsetIdx", "=", "np", ".", "array_split", "(", "np", ".", "arange", "(", "len", "(", "train_set", ")", ")", ",", "subsetN", ")", "\n", "", "else", ":", "\n", "        ", "subsetN", "=", "1", "\n", "subsetIdx", "=", "[", "np", ".", "arange", "(", "len", "(", "train_set", ")", ")", "]", "\n", "\n", "", "nBatches", "=", "(", "len", "(", "train_set", ")", "+", "opt", ".", "batchSize", "-", "1", ")", "//", "opt", ".", "batchSize", "\n", "\n", "for", "subIter", "in", "range", "(", "subsetN", ")", ":", "\n", "        ", "print", "(", "'====> Building Cache %d/%d'", "%", "(", "subIter", ",", "subsetN", ")", ")", "\n", "model", ".", "eval", "(", ")", "\n", "with", "h5py", ".", "File", "(", "train_set", ".", "cache", ",", "mode", "=", "'w'", ")", "as", "h5", ":", "\n", "            ", "pool_size", "=", "encoder_dim", "\n", "if", "opt", ".", "pooling", ".", "lower", "(", ")", "==", "'netvlad'", ":", "\n", "                ", "pool_size", "*=", "opt", ".", "num_clusters", "\n", "", "h5feat", "=", "h5", ".", "create_dataset", "(", "\"features\"", ",", "\n", "[", "len", "(", "whole_train_set", ")", ",", "pool_size", "]", ",", "\n", "dtype", "=", "np", ".", "float32", ")", "\n", "if", "not", "opt", ".", "testTrainMem", ":", "\n", "                ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                    ", "for", "iteration", ",", "(", "input", ",", "indices", ")", "in", "tqdm", "(", "enumerate", "(", "whole_training_data_loader", ",", "1", ")", ",", "total", "=", "len", "(", "whole_training_data_loader", ")", "-", "1", ",", "leave", "=", "False", ")", ":", "\n", "                        ", "input", "=", "input", ".", "to", "(", "device", ")", "\n", "image_encoding", "=", "model", ".", "encoder", "(", "input", ")", "\n", "if", "iteration", "<", "2", ":", "\n", "                            ", "print", "(", "'\\n'", ")", "\n", "print", "(", "'******MultiRes-NetVLAD Caching==> l:%s*****'", "%", "str", "(", "opt", ".", "scaleSpace", ")", ")", "\n", "print", "(", "'Scale at:1'", ")", "\n", "print", "(", "'Input Scaled Shape:'", ",", "input", ".", "shape", ")", "\n", "print", "(", "'Output Encoded Shape:'", ",", "image_encoding", ".", "shape", ")", "\n", "", "image_encoding", "=", "image_encoding", ".", "view", "(", "image_encoding", ".", "size", "(", "0", ")", ",", "image_encoding", ".", "size", "(", "1", ")", ",", "-", "1", ")", "\n", "for", "l", "in", "opt", ".", "scaleSpace", ":", "\n", "                            ", "input_scaled", "=", "input", "[", ":", ",", ":", ",", ":", ":", "l", ",", ":", ":", "l", "]", "\n", "image_scaled_encoding", "=", "model", ".", "encoder", "(", "input_scaled", ")", "\n", "if", "iteration", "<", "2", ":", "\n", "                                ", "print", "(", "'Scale at:'", ",", "l", ")", "\n", "print", "(", "'Input Scaled Shape:'", ",", "input_scaled", ".", "shape", ")", "\n", "print", "(", "'Output Encoded Shape:'", ",", "image_scaled_encoding", ".", "shape", ")", "\n", "", "image_encoding", "=", "torch", ".", "cat", "(", "[", "image_encoding", ",", "image_scaled_encoding", ".", "view", "(", "image_scaled_encoding", ".", "size", "(", "0", ")", ",", "image_scaled_encoding", ".", "size", "(", "1", ")", ",", "-", "1", ")", "]", ",", "dim", "=", "2", ")", "\n", "", "image_encoding", "=", "image_encoding", ".", "unsqueeze", "(", "3", ")", "\n", "vlad_encoding", "=", "model", ".", "pool", "(", "image_encoding", ")", "\n", "if", "iteration", "<", "2", ":", "\n", "                            ", "print", "(", "'input'", ",", "input", ".", "shape", ")", "\n", "print", "(", "'image_encoding'", ",", "image_encoding", ".", "shape", ")", "\n", "print", "(", "'vlad_encoding'", ",", "vlad_encoding", ".", "shape", ")", "\n", "\n", "", "h5feat", "[", "indices", ".", "detach", "(", ")", ".", "numpy", "(", ")", ",", ":", "]", "=", "vlad_encoding", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "del", "input", ",", "image_encoding", ",", "vlad_encoding", "\n", "torch", ".", "cuda", ".", "empty_cache", "(", ")", "\n", "\n", "", "", "", "", "sub_train_set", "=", "Subset", "(", "dataset", "=", "train_set", ",", "indices", "=", "subsetIdx", "[", "subIter", "]", ")", "\n", "\n", "training_data_loader", "=", "DataLoader", "(", "dataset", "=", "sub_train_set", ",", "num_workers", "=", "opt", ".", "threads", ",", "\n", "batch_size", "=", "opt", ".", "batchSize", ",", "shuffle", "=", "True", ",", "\n", "collate_fn", "=", "dataset", ".", "collate_fn", ",", "pin_memory", "=", "False", ")", "\n", "\n", "print", "(", "'Allocated:'", ",", "torch", ".", "cuda", ".", "memory_allocated", "(", ")", ")", "\n", "print", "(", "'Cached:'", ",", "torch", ".", "cuda", ".", "memory_reserved", "(", ")", ")", "\n", "\n", "model", ".", "train", "(", ")", "\n", "loss", "=", "None", "\n", "for", "iteration", ",", "(", "query", ",", "positives", ",", "negatives", ",", "\n", "negCounts", ",", "indices", ")", "in", "tqdm", "(", "enumerate", "(", "training_data_loader", ",", "startIter", ")", ",", "total", "=", "len", "(", "training_data_loader", ")", ",", "leave", "=", "False", ")", ":", "\n", "# with torch.cuda.amp.autocast():", "\n", "# some reshaping to put query, pos, negs in a single (N, 3, H, W) tensor", "\n", "# where N = batchSize * (nQuery + nPos + nNeg)", "\n", "            ", "if", "query", "is", "None", ":", "continue", "# in case we get an empty batch", "\n", "\n", "B", ",", "C", ",", "H", ",", "W", "=", "query", ".", "shape", "\n", "nNeg", "=", "torch", ".", "sum", "(", "negCounts", ")", "\n", "input", "=", "torch", ".", "cat", "(", "[", "query", ",", "positives", ",", "negatives", "]", ")", "\n", "del", "query", ",", "positives", ",", "negatives", "\n", "\n", "input", "=", "input", ".", "to", "(", "device", ")", "\n", "image_encoding", "=", "model", ".", "encoder", "(", "input", ")", "\n", "if", "iteration", "<", "2", ":", "\n", "                ", "print", "(", "'\\n'", ")", "\n", "print", "(", "'******MultiRes-NetVLAD Training==> l:%s*****'", "%", "str", "(", "opt", ".", "scaleSpace", ")", ")", "\n", "print", "(", "'Scale at:1'", ")", "\n", "", "image_encoding", "=", "image_encoding", ".", "view", "(", "image_encoding", ".", "size", "(", "0", ")", ",", "image_encoding", ".", "size", "(", "1", ")", ",", "-", "1", ")", "\n", "for", "l", "in", "opt", ".", "scaleSpace", ":", "\n", "                ", "input_scaled", "=", "input", "[", ":", ",", ":", ",", ":", ":", "l", ",", ":", ":", "l", "]", "\n", "image_scaled_encoding", "=", "model", ".", "encoder", "(", "input_scaled", ")", "\n", "if", "iteration", "<", "2", ":", "\n", "                    ", "print", "(", "'Scale at:'", ",", "l", ")", "\n", "", "image_encoding", "=", "torch", ".", "cat", "(", "[", "image_encoding", ",", "image_scaled_encoding", ".", "view", "(", "image_scaled_encoding", ".", "size", "(", "0", ")", ",", "image_scaled_encoding", ".", "size", "(", "1", ")", ",", "-", "1", ")", "]", ",", "dim", "=", "2", ")", "\n", "", "image_encoding", "=", "image_encoding", ".", "unsqueeze", "(", "3", ")", "\n", "\n", "vlad_encoding", "=", "model", ".", "pool", "(", "image_encoding", ")", "\n", "\n", "vladQ", ",", "vladP", ",", "vladN", "=", "torch", ".", "split", "(", "vlad_encoding", ",", "[", "B", ",", "B", ",", "nNeg", "]", ")", "\n", "\n", "del", "input", ",", "image_encoding", ",", "vlad_encoding", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "\n", "# calculate loss for each Query, Positive, Negative triplet", "\n", "# due to potential difference in number of negatives have to ", "\n", "# do it per query, per negative", "\n", "loss", "=", "0", "\n", "for", "i", ",", "negCount", "in", "enumerate", "(", "negCounts", ")", ":", "\n", "                ", "for", "n", "in", "range", "(", "negCount", ")", ":", "\n", "                    ", "negIx", "=", "(", "torch", ".", "sum", "(", "negCounts", "[", ":", "i", "]", ")", "+", "n", ")", ".", "item", "(", ")", "\n", "loss", "+=", "criterion", "(", "vladQ", "[", "i", ":", "i", "+", "1", "]", ",", "vladP", "[", "i", ":", "i", "+", "1", "]", ",", "vladN", "[", "negIx", ":", "negIx", "+", "1", "]", ")", "\n", "\n", "", "", "del", "vladQ", ",", "vladP", ",", "vladN", "\n", "loss", "/=", "nNeg", ".", "float", "(", ")", ".", "to", "(", "device", ")", "# normalise by actual number of negatives", "\n", "loss", ".", "backward", "(", ")", "\n", "optimizer", ".", "step", "(", ")", "\n", "\n", "batch_loss", "=", "loss", ".", "item", "(", ")", "\n", "epoch_loss", "+=", "batch_loss", "\n", "if", "opt", ".", "testTrainMem", ":", "\n", "                ", "print", "(", "\"Mem test passed!\"", ")", "\n", "exit", "(", "-", "1", ")", "\n", "\n", "", "if", "iteration", "%", "50", "==", "0", "or", "nBatches", "<=", "10", ":", "\n", "                ", "print", "(", "\"==> Epoch[{}]({}/{}): Loss: {:.4f}\"", ".", "format", "(", "epoch", ",", "iteration", ",", "\n", "nBatches", ",", "batch_loss", ")", ",", "flush", "=", "True", ")", "\n", "writer", ".", "add_scalar", "(", "'Train/Loss'", ",", "batch_loss", ",", "\n", "(", "(", "epoch", "-", "1", ")", "*", "nBatches", ")", "+", "iteration", ")", "\n", "writer", ".", "add_scalar", "(", "'Train/nNeg'", ",", "nNeg", ",", "\n", "(", "(", "epoch", "-", "1", ")", "*", "nBatches", ")", "+", "iteration", ")", "\n", "wandb", ".", "log", "(", "{", "\"loss\"", ":", "batch_loss", ",", "\"nNeg\"", ":", "nNeg", ",", "\"epoch\"", ":", "epoch", "}", ")", "\n", "print", "(", "'Allocated:'", ",", "torch", ".", "cuda", ".", "memory_allocated", "(", ")", ")", "\n", "print", "(", "'Cached:'", ",", "torch", ".", "cuda", ".", "memory_reserved", "(", ")", ")", "\n", "\n", "", "", "startIter", "+=", "len", "(", "training_data_loader", ")", "\n", "del", "training_data_loader", ",", "loss", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "torch", ".", "cuda", ".", "empty_cache", "(", ")", "\n", "remove", "(", "train_set", ".", "cache", ")", "# delete HDF5 cache", "\n", "\n", "", "avg_loss", "=", "epoch_loss", "/", "nBatches", "\n", "\n", "print", "(", "\"===> Epoch {} Complete: Avg. Loss: {:.4f}\"", ".", "format", "(", "epoch", ",", "avg_loss", ")", ",", "\n", "flush", "=", "True", ")", "\n", "wandb", ".", "log", "(", "{", "\"loss_e\"", ":", "avg_loss", "}", ")", "\n", "writer", ".", "add_scalar", "(", "'Train/AvgLoss'", ",", "avg_loss", ",", "epoch", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ahmedest61_multires-netvlad.None.main.test": [[232, 320], ["print", "print", "torch.utils.data.DataLoader", "model.eval", "time.time", "dbFeat[].astype", "dbFeat[].astype", "print", "faiss.IndexFlatL2", "faiss.IndexFlatL2.add", "print", "time.time", "faiss.IndexFlatL2.search", "eval_set.getPositives", "numpy.zeros", "enumerate", "enumerate", "sum", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "print", "numpy.empty", "tqdm.tqdm", "time.time", "max", "time.time", "len", "enumerate", "print", "wandb.log", "opt.pooling.lower", "enumerate", "input.to.to", "model.encoder", "torch.cat.view", "torch.cat.unsqueeze", "model.pool", "model.WPCA.detach().cpu().numpy", "numpy.any", "writer.add_scalar", "p.numel", "opt.mode.lower", "len", "print", "print", "print", "torch.cat.size", "torch.cat.size", "model.encoder", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "model.WPCA", "print", "numpy.in1d", "model.parameters", "len", "print", "opt.mode.lower", "model.WPCA.unsqueeze().unsqueeze", "model.WPCA.detach().cpu", "len", "str", "str", "model.encoder.view", "indices.detach().numpy", "len", "model.encoder.size", "model.encoder.size", "model.WPCA.unsqueeze", "model.WPCA.detach", "indices.detach"], "function", ["home.repos.pwc.inspect_result.ahmedest61_multires-netvlad.None.pittsburgh.WholeDatasetFromStruct.getPositives"], ["", "def", "test", "(", "eval_set", ",", "epoch", "=", "0", ",", "write_tboard", "=", "False", ")", ":", "\n", "    ", "print", "(", "\"Testing====>\"", ")", "\n", "print", "(", "'===>Parameters: '", ",", "sum", "(", "p", ".", "numel", "(", ")", "for", "p", "in", "model", ".", "parameters", "(", ")", ")", ")", "\n", "\n", "# TODO what if features dont fit in memory? ", "\n", "test_data_loader", "=", "DataLoader", "(", "dataset", "=", "eval_set", ",", "\n", "num_workers", "=", "opt", ".", "threads", ",", "batch_size", "=", "opt", ".", "cacheBatchSize", ",", "shuffle", "=", "False", ",", "\n", "pin_memory", "=", "False", ")", "\n", "\n", "model", ".", "eval", "(", ")", "\n", "t_extract_start", "=", "time", ".", "time", "(", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "print", "(", "'====> Extracting Features'", ")", "\n", "pool_size", "=", "encoder_dim", "\n", "if", "opt", ".", "pooling", ".", "lower", "(", ")", "==", "'netvlad'", ":", "\n", "            ", "pool_size", "*=", "opt", ".", "num_clusters", "\n", "\n", "", "if", "opt", ".", "appendPcaLayer", "==", "True", "and", "opt", ".", "mode", ".", "lower", "(", ")", "==", "'test'", ":", "\n", "            ", "pool_size", "=", "4096", "\n", "", "dbFeat", "=", "np", ".", "empty", "(", "(", "len", "(", "eval_set", ")", ",", "pool_size", ")", ")", "\n", "\n", "for", "iteration", ",", "(", "input", ",", "indices", ")", "in", "tqdm", "(", "enumerate", "(", "test_data_loader", ",", "1", ")", ",", "total", "=", "len", "(", "test_data_loader", ")", "-", "1", ")", ":", "\n", "            ", "input", "=", "input", ".", "to", "(", "device", ")", "\n", "image_encoding", "=", "model", ".", "encoder", "(", "input", ")", "\n", "if", "iteration", "<", "2", ":", "\n", "                ", "print", "(", "'\\n'", ")", "\n", "print", "(", "'******MultiRes-NetVLAD Testing==> l:%s*****'", "%", "str", "(", "opt", ".", "scaleSpace", ")", ")", "\n", "print", "(", "'Scale at:1'", ")", "\n", "", "image_encoding", "=", "image_encoding", ".", "view", "(", "image_encoding", ".", "size", "(", "0", ")", ",", "image_encoding", ".", "size", "(", "1", ")", ",", "-", "1", ")", "\n", "for", "l", "in", "opt", ".", "scaleSpace", ":", "\n", "                ", "input_scaled", "=", "input", "[", ":", ",", ":", ",", ":", ":", "l", ",", ":", ":", "l", "]", "\n", "image_scaled_encoding", "=", "model", ".", "encoder", "(", "input_scaled", ")", "\n", "if", "iteration", "<", "2", ":", "\n", "                    ", "print", "(", "'Scale at:'", ",", "l", ")", "\n", "", "image_encoding", "=", "torch", ".", "cat", "(", "[", "image_encoding", ",", "image_scaled_encoding", ".", "view", "(", "image_scaled_encoding", ".", "size", "(", "0", ")", ",", "image_scaled_encoding", ".", "size", "(", "1", ")", ",", "-", "1", ")", "]", ",", "dim", "=", "2", ")", "\n", "", "image_encoding", "=", "image_encoding", ".", "unsqueeze", "(", "3", ")", "\n", "\n", "vlad_encoding", "=", "model", ".", "pool", "(", "image_encoding", ")", "\n", "if", "opt", ".", "appendPcaLayer", "==", "True", "and", "opt", ".", "mode", ".", "lower", "(", ")", "==", "'test'", ":", "\n", "                ", "vlad_encoding", "=", "model", ".", "WPCA", "(", "vlad_encoding", ".", "unsqueeze", "(", "-", "1", ")", ".", "unsqueeze", "(", "-", "1", ")", ")", "\n", "\n", "", "dbFeat", "[", "indices", ".", "detach", "(", ")", ".", "numpy", "(", ")", ",", ":", "]", "=", "vlad_encoding", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "if", "iteration", "%", "50", "==", "0", "or", "len", "(", "test_data_loader", ")", "<=", "10", ":", "\n", "                ", "print", "(", "\"==> Batch ({}/{})\"", ".", "format", "(", "iteration", ",", "\n", "len", "(", "test_data_loader", ")", ")", ",", "flush", "=", "True", ")", "\n", "\n", "", "del", "input", ",", "image_encoding", ",", "vlad_encoding", "\n", "", "", "del", "test_data_loader", "\n", "t_extract_dur", "=", "time", ".", "time", "(", ")", "-", "t_extract_start", "\n", "\n", "# extracted for both db and query, now split in own sets", "\n", "qFeat", "=", "dbFeat", "[", "eval_set", ".", "dbStruct", ".", "numDb", ":", "]", ".", "astype", "(", "'float32'", ")", "\n", "dbFeat", "=", "dbFeat", "[", ":", "eval_set", ".", "dbStruct", ".", "numDb", "]", ".", "astype", "(", "'float32'", ")", "\n", "\n", "print", "(", "'====> Building faiss index'", ")", "\n", "faiss_index", "=", "faiss", ".", "IndexFlatL2", "(", "pool_size", ")", "\n", "faiss_index", ".", "add", "(", "dbFeat", ")", "\n", "\n", "print", "(", "'====> Calculating recall @ N'", ")", "\n", "n_values", "=", "[", "1", ",", "5", ",", "10", ",", "20", ",", "50", ",", "100", "]", "\n", "\n", "t_retrieve_start", "=", "time", ".", "time", "(", ")", "\n", "\n", "_", ",", "predictions", "=", "faiss_index", ".", "search", "(", "qFeat", ",", "max", "(", "n_values", ")", ")", "\n", "t_retrieve_dur", "=", "time", ".", "time", "(", ")", "-", "t_retrieve_start", "\n", "\n", "# for each query get those within threshold distance", "\n", "gt", "=", "eval_set", ".", "getPositives", "(", ")", "\n", "\n", "correct_at_n", "=", "np", ".", "zeros", "(", "len", "(", "n_values", ")", ")", "\n", "#TODO can we do this on the matrix in one go?", "\n", "for", "qIx", ",", "pred", "in", "enumerate", "(", "predictions", ")", ":", "\n", "        ", "for", "i", ",", "n", "in", "enumerate", "(", "n_values", ")", ":", "\n", "# if in top N then also in top NN, where NN > N", "\n", "            ", "if", "np", ".", "any", "(", "np", ".", "in1d", "(", "pred", "[", ":", "n", "]", ",", "gt", "[", "qIx", "]", ")", ")", ":", "\n", "                ", "correct_at_n", "[", "i", ":", "]", "+=", "1", "\n", "break", "\n", "", "", "", "recall_at_n", "=", "correct_at_n", "/", "eval_set", ".", "dbStruct", ".", "numQ", "\n", "\n", "recalls", "=", "{", "}", "#make dict for output", "\n", "for", "i", ",", "n", "in", "enumerate", "(", "n_values", ")", ":", "\n", "        ", "recalls", "[", "n", "]", "=", "recall_at_n", "[", "i", "]", "\n", "print", "(", "\"====> Recall@{}: {:.4f}\"", ".", "format", "(", "n", ",", "recall_at_n", "[", "i", "]", ")", ")", "\n", "if", "write_tboard", ":", "writer", ".", "add_scalar", "(", "'Val/Recall@'", "+", "str", "(", "n", ")", ",", "recall_at_n", "[", "i", "]", ",", "epoch", ")", "\n", "wandb", ".", "log", "(", "{", "'Val/Recall@'", "+", "\"{0:03d}\"", ".", "format", "(", "n", ")", ":", "recall_at_n", "[", "i", "]", "}", ",", "commit", "=", "False", ")", "\n", "\n", "", "return", "recalls", "\n", "\n"]], "home.repos.pwc.inspect_result.ahmedest61_multires-netvlad.None.main.get_clusters": [[321, 385], ["math.ceil", "torch.utils.data.SubsetRandomSampler", "torch.utils.data.DataLoader", "os.path.join", "numpy.random.choice", "os.path.exists", "os.makedirs", "h5py.File", "print", "faiss.Kmeans", "faiss.Kmeans.train", "print", "h5.create_dataset", "print", "len", "os.path.join", "os.path.join", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "model.eval", "print", "h5.create_dataset", "tqdm.tqdm", "str", "enumerate", "input.to.to", "model.encoder", "torch.cat.view", "torch.cat.permute", "range", "print", "print", "print", "torch.cat.size", "torch.cat.size", "model.encoder", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "image_encoding.permute.size", "numpy.random.choice", "image_descriptors[].detach().cpu().numpy", "print", "str", "len", "print", "image_encoding.permute.size", "min", "len", "str", "model.encoder.view", "image_encoding.permute.size", "image_descriptors[].detach().cpu", "math.ceil", "model.encoder.size", "model.encoder.size", "image_descriptors[].detach", "str"], "function", ["home.repos.pwc.inspect_result.ahmedest61_multires-netvlad.None.main.train"], ["", "def", "get_clusters", "(", "cluster_set", ")", ":", "\n", "    ", "nDescriptors", "=", "50000", "\n", "nPerImage", "=", "16", "\n", "nIm", "=", "ceil", "(", "nDescriptors", "/", "nPerImage", ")", "\n", "\n", "sampler", "=", "SubsetRandomSampler", "(", "np", ".", "random", ".", "choice", "(", "len", "(", "cluster_set", ")", ",", "nIm", ",", "replace", "=", "False", ")", ")", "\n", "data_loader", "=", "DataLoader", "(", "dataset", "=", "cluster_set", ",", "\n", "num_workers", "=", "opt", ".", "threads", ",", "batch_size", "=", "opt", ".", "cacheBatchSize", ",", "shuffle", "=", "False", ",", "\n", "pin_memory", "=", "False", ",", "\n", "sampler", "=", "sampler", ")", "\n", "\n", "if", "not", "exists", "(", "join", "(", "opt", ".", "dataPath", ",", "'centroids'", ")", ")", ":", "\n", "        ", "makedirs", "(", "join", "(", "opt", ".", "dataPath", ",", "'centroids'", ")", ")", "\n", "\n", "", "initcache", "=", "join", "(", "opt", ".", "dataPath", ",", "'centroids'", ",", "opt", ".", "arch", "+", "'_L_'", "+", "str", "(", "opt", ".", "density_L", ")", "+", "\"_\"", "+", "opt", ".", "pooling", "+", "'_'", "+", "cluster_set", ".", "dataset", "+", "'_cluster'", "+", "str", "(", "opt", ".", "num_clusters", ")", "+", "'_trim'", "+", "str", "(", "opt", ".", "trim", ")", "+", "'_desc_cen.hdf5'", ")", "\n", "with", "h5py", ".", "File", "(", "initcache", ",", "mode", "=", "'w'", ")", "as", "h5", ":", "\n", "        ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "model", ".", "eval", "(", ")", "\n", "print", "(", "'====> Extracting Descriptors'", ")", "\n", "dbFeat", "=", "h5", ".", "create_dataset", "(", "\"descriptors\"", ",", "\n", "[", "nDescriptors", ",", "encoder_dim", "]", ",", "\n", "dtype", "=", "np", ".", "float32", ")", "\n", "\n", "for", "iteration", ",", "(", "input", ",", "indices", ")", "in", "tqdm", "(", "enumerate", "(", "data_loader", ",", "1", ")", ",", "total", "=", "len", "(", "data_loader", ")", "-", "1", ")", ":", "\n", "                ", "input", "=", "input", ".", "to", "(", "device", ")", "\n", "image_encoding", "=", "model", ".", "encoder", "(", "input", ")", "\n", "if", "iteration", "<", "2", ":", "\n", "                    ", "print", "(", "'\\n'", ")", "\n", "print", "(", "'******MultiRes-NetVLAD Clustering: %s*****'", "%", "str", "(", "opt", ".", "scaleSpace", ")", ")", "\n", "print", "(", "'Scale at:1'", ")", "\n", "\n", "", "image_encoding", "=", "image_encoding", ".", "view", "(", "image_encoding", ".", "size", "(", "0", ")", ",", "image_encoding", ".", "size", "(", "1", ")", ",", "-", "1", ")", "\n", "\n", "for", "l", "in", "opt", ".", "scaleSpace", ":", "\n", "                    ", "input_scaled", "=", "input", "[", ":", ",", ":", ",", ":", ":", "l", ",", ":", ":", "l", "]", "\n", "image_scaled_encoding", "=", "model", ".", "encoder", "(", "input_scaled", ")", "\n", "if", "iteration", "<", "2", ":", "\n", "                        ", "print", "(", "'Scale at:'", ",", "l", ")", "\n", "", "image_encoding", "=", "torch", ".", "cat", "(", "[", "image_encoding", ",", "image_scaled_encoding", ".", "view", "(", "image_scaled_encoding", ".", "size", "(", "0", ")", ",", "image_scaled_encoding", ".", "size", "(", "1", ")", ",", "-", "1", ")", "]", ",", "dim", "=", "2", ")", "\n", "\n", "", "image_descriptors", "=", "image_encoding", ".", "permute", "(", "0", ",", "2", ",", "1", ")", "\n", "#                image_descriptors = model.encoder(input).view(input.size(0), encoder_dim, -1).permute(0, 2, 1)", "\n", "\n", "batchix", "=", "(", "iteration", "-", "1", ")", "*", "opt", ".", "cacheBatchSize", "*", "nPerImage", "\n", "for", "ix", "in", "range", "(", "image_descriptors", ".", "size", "(", "0", ")", ")", ":", "\n", "# sample different location for each image in batch", "\n", "                    ", "sample", "=", "np", ".", "random", ".", "choice", "(", "image_descriptors", ".", "size", "(", "1", ")", ",", "min", "(", "nPerImage", ",", "image_descriptors", ".", "size", "(", "1", ")", ")", ",", "replace", "=", "False", ")", "\n", "startix", "=", "batchix", "+", "ix", "*", "nPerImage", "\n", "dbFeat", "[", "startix", ":", "startix", "+", "nPerImage", ",", ":", "]", "=", "image_descriptors", "[", "ix", ",", "sample", ",", ":", "]", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "\n", "", "if", "iteration", "%", "50", "==", "0", "or", "len", "(", "data_loader", ")", "<=", "10", ":", "\n", "                    ", "print", "(", "\"==> Batch ({}/{})\"", ".", "format", "(", "iteration", ",", "\n", "ceil", "(", "nIm", "/", "opt", ".", "cacheBatchSize", ")", ")", ",", "flush", "=", "True", ")", "\n", "", "del", "input", ",", "image_descriptors", "\n", "\n", "", "", "print", "(", "'====> Clustering..'", ")", "\n", "niter", "=", "100", "\n", "kmeans", "=", "faiss", ".", "Kmeans", "(", "encoder_dim", ",", "opt", ".", "num_clusters", ",", "niter", "=", "niter", ",", "verbose", "=", "False", ")", "\n", "kmeans", ".", "train", "(", "dbFeat", "[", "...", "]", ")", "\n", "\n", "print", "(", "'====> Storing centroids'", ",", "kmeans", ".", "centroids", ".", "shape", ")", "\n", "h5", ".", "create_dataset", "(", "'centroids'", ",", "data", "=", "kmeans", ".", "centroids", ")", "\n", "print", "(", "'====> Done!'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ahmedest61_multires-netvlad.None.main.save_checkpoint": [[386, 391], ["os.path.join", "torch.save", "torch.save", "torch.save", "torch.save", "shutil.copyfile", "os.path.join"], "function", ["None"], ["", "", "def", "save_checkpoint", "(", "savePath", ",", "state", ",", "is_best", ",", "filename", "=", "'checkpoint.pth.tar'", ")", ":", "\n", "    ", "model_out_path", "=", "join", "(", "savePath", ",", "filename", ")", "\n", "torch", ".", "save", "(", "state", ",", "model_out_path", ")", "\n", "if", "is_best", ":", "\n", "        ", "shutil", ".", "copyfile", "(", "model_out_path", ",", "join", "(", "savePath", ",", "'model_best.pth.tar'", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ahmedest61_multires-netvlad.None.pittsburgh.WholeDatasetFromStruct.__init__": [[114, 129], ["torch.Dataset.__init__", "pittsburgh.parse_dbStruct", "os.path.join", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.ahmedest61_multires-netvlad.training_tools.msls.MSLS.__init__", "home.repos.pwc.inspect_result.ahmedest61_multires-netvlad.None.pittsburgh.parse_dbStruct"], ["    ", "def", "__init__", "(", "self", ",", "structFile", ",", "input_transform", "=", "None", ",", "onlyDB", "=", "False", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "input_transform", "=", "input_transform", "\n", "\n", "self", ".", "dbStruct", "=", "parse_dbStruct", "(", "structFile", ")", "\n", "self", ".", "images", "=", "[", "join", "(", "root_dir", ",", "dbIm", ")", "for", "dbIm", "in", "self", ".", "dbStruct", ".", "dbImage", "]", "\n", "if", "not", "onlyDB", ":", "\n", "            ", "self", ".", "images", "+=", "[", "join", "(", "queries_dir", ",", "qIm", ")", "for", "qIm", "in", "self", ".", "dbStruct", ".", "qImage", "]", "\n", "\n", "", "self", ".", "whichSet", "=", "self", ".", "dbStruct", ".", "whichSet", "\n", "self", ".", "dataset", "=", "self", ".", "dbStruct", ".", "dataset", "\n", "\n", "self", ".", "positives", "=", "None", "\n", "self", ".", "distances", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.ahmedest61_multires-netvlad.None.pittsburgh.WholeDatasetFromStruct.__getitem__": [[130, 137], ["PIL.Image.open", "pittsburgh.WholeDatasetFromStruct.input_transform"], "methods", ["home.repos.pwc.inspect_result.ahmedest61_multires-netvlad.tools.datasets.input_transform"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "img", "=", "Image", ".", "open", "(", "self", ".", "images", "[", "index", "]", ")", "\n", "\n", "if", "self", ".", "input_transform", ":", "\n", "            ", "img", "=", "self", ".", "input_transform", "(", "img", ")", "\n", "\n", "", "return", "img", ",", "index", "\n", "\n"]], "home.repos.pwc.inspect_result.ahmedest61_multires-netvlad.None.pittsburgh.WholeDatasetFromStruct.__len__": [[138, 140], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "images", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ahmedest61_multires-netvlad.None.pittsburgh.WholeDatasetFromStruct.getPositives": [[141, 152], ["sklearn.neighbors.NearestNeighbors", "sklearn.neighbors.NearestNeighbors.fit", "sklearn.neighbors.NearestNeighbors.radius_neighbors"], "methods", ["None"], ["", "def", "getPositives", "(", "self", ")", ":", "\n", "# positives for evaluation are those within trivial threshold range", "\n", "#fit NN to find them, search by radius", "\n", "        ", "if", "self", ".", "positives", "is", "None", ":", "\n", "            ", "knn", "=", "NearestNeighbors", "(", "n_jobs", "=", "-", "1", ")", "\n", "knn", ".", "fit", "(", "self", ".", "dbStruct", ".", "utmDb", ")", "\n", "\n", "self", ".", "distances", ",", "self", ".", "positives", "=", "knn", ".", "radius_neighbors", "(", "self", ".", "dbStruct", ".", "utmQ", ",", "\n", "radius", "=", "self", ".", "dbStruct", ".", "posDistThr", ")", "\n", "\n", "", "return", "self", ".", "positives", "\n", "\n"]], "home.repos.pwc.inspect_result.ahmedest61_multires-netvlad.None.pittsburgh.QueryDatasetFromStruct.__init__": [[182, 223], ["torch.Dataset.__init__", "pittsburgh.parse_dbStruct", "sklearn.neighbors.NearestNeighbors", "sklearn.neighbors.NearestNeighbors.fit", "list", "enumerate", "sklearn.neighbors.NearestNeighbors.radius_neighbors", "sklearn.neighbors.NearestNeighbors.radius_neighbors", "numpy.sort", "numpy.where", "pittsburgh.QueryDatasetFromStruct.potential_negatives.append", "numpy.empty", "numpy.setdiff1d", "range", "numpy.array", "numpy.arange", "len"], "methods", ["home.repos.pwc.inspect_result.ahmedest61_multires-netvlad.training_tools.msls.MSLS.__init__", "home.repos.pwc.inspect_result.ahmedest61_multires-netvlad.None.pittsburgh.parse_dbStruct"], ["    ", "def", "__init__", "(", "self", ",", "structFile", ",", "nNegSample", "=", "1000", ",", "nNeg", "=", "10", ",", "margin", "=", "0.1", ",", "input_transform", "=", "None", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "input_transform", "=", "input_transform", "\n", "self", ".", "margin", "=", "margin", "\n", "\n", "self", ".", "dbStruct", "=", "parse_dbStruct", "(", "structFile", ")", "\n", "self", ".", "whichSet", "=", "self", ".", "dbStruct", ".", "whichSet", "\n", "self", ".", "dataset", "=", "self", ".", "dbStruct", ".", "dataset", "\n", "self", ".", "nNegSample", "=", "nNegSample", "# number of negatives to randomly sample", "\n", "self", ".", "nNeg", "=", "nNeg", "# number of negatives used for training", "\n", "\n", "# potential positives are those within nontrivial threshold range", "\n", "#fit NN to find them, search by radius", "\n", "knn", "=", "NearestNeighbors", "(", "n_jobs", "=", "-", "1", ")", "\n", "knn", ".", "fit", "(", "self", ".", "dbStruct", ".", "utmDb", ")", "\n", "\n", "# TODO use sqeuclidean as metric?", "\n", "self", ".", "nontrivial_positives", "=", "list", "(", "knn", ".", "radius_neighbors", "(", "self", ".", "dbStruct", ".", "utmQ", ",", "\n", "radius", "=", "self", ".", "dbStruct", ".", "nonTrivPosDistSqThr", "**", "0.5", ",", "\n", "return_distance", "=", "False", ")", ")", "\n", "# radius returns unsorted, sort once now so we dont have to later", "\n", "for", "i", ",", "posi", "in", "enumerate", "(", "self", ".", "nontrivial_positives", ")", ":", "\n", "            ", "self", ".", "nontrivial_positives", "[", "i", "]", "=", "np", ".", "sort", "(", "posi", ")", "\n", "# its possible some queries don't have any non trivial potential positives", "\n", "# lets filter those out", "\n", "", "self", ".", "queries", "=", "np", ".", "where", "(", "np", ".", "array", "(", "[", "len", "(", "x", ")", "for", "x", "in", "self", ".", "nontrivial_positives", "]", ")", ">", "0", ")", "[", "0", "]", "\n", "\n", "# potential negatives are those outside of posDistThr range", "\n", "potential_positives", "=", "knn", ".", "radius_neighbors", "(", "self", ".", "dbStruct", ".", "utmQ", ",", "\n", "radius", "=", "self", ".", "dbStruct", ".", "posDistThr", ",", "\n", "return_distance", "=", "False", ")", "\n", "\n", "self", ".", "potential_negatives", "=", "[", "]", "\n", "for", "pos", "in", "potential_positives", ":", "\n", "            ", "self", ".", "potential_negatives", ".", "append", "(", "np", ".", "setdiff1d", "(", "np", ".", "arange", "(", "self", ".", "dbStruct", ".", "numDb", ")", ",", "\n", "pos", ",", "assume_unique", "=", "True", ")", ")", "\n", "\n", "", "self", ".", "cache", "=", "None", "# filepath of HDF5 containing feature vectors for images", "\n", "\n", "self", ".", "negCache", "=", "[", "np", ".", "empty", "(", "(", "0", ",", ")", ")", "for", "_", "in", "range", "(", "self", ".", "dbStruct", ".", "numQ", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.ahmedest61_multires-netvlad.None.pittsburgh.QueryDatasetFromStruct.__getitem__": [[224, 282], ["PIL.Image.open", "PIL.Image.open", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "h5py.File", "h5.get", "faiss.IndexFlatL2", "faiss.IndexFlatL2.add", "faiss.IndexFlatL2.search", "dPos.item.item.item", "[].item", "numpy.random.choice", "numpy.unique().astype", "faiss.IndexFlatL2", "faiss.IndexFlatL2.add", "faiss.IndexFlatL2.search", "dNeg.reshape.reshape.reshape", "negNN.reshape.reshape.reshape", "negSample[].astype", "os.path.join", "os.path.join", "pittsburgh.QueryDatasetFromStruct.input_transform", "pittsburgh.QueryDatasetFromStruct.input_transform", "PIL.Image.open", "torch.stack.append", "torch.stack.append", "len", "qFeat.reshape", "qFeat.reshape", "numpy.sum", "os.path.join", "pittsburgh.QueryDatasetFromStruct.input_transform", "negSample[].astype.tolist", "pittsburgh.QueryDatasetFromStruct.nontrivial_positives[].tolist", "numpy.unique", "numpy.unique().astype.tolist", "numpy.concatenate"], "methods", ["home.repos.pwc.inspect_result.ahmedest61_multires-netvlad.tools.datasets.input_transform", "home.repos.pwc.inspect_result.ahmedest61_multires-netvlad.tools.datasets.input_transform", "home.repos.pwc.inspect_result.ahmedest61_multires-netvlad.tools.datasets.input_transform"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "#         index = self.queries[index] # re-map index to match dataset", "\n", "        ", "with", "h5py", ".", "File", "(", "self", ".", "cache", ",", "mode", "=", "'r'", ")", "as", "h5", ":", "\n", "            ", "h5feat", "=", "h5", ".", "get", "(", "\"features\"", ")", "\n", "\n", "qOffset", "=", "self", ".", "dbStruct", ".", "numDb", "\n", "qFeat", "=", "h5feat", "[", "index", "+", "qOffset", "]", "\n", "\n", "if", "len", "(", "self", ".", "nontrivial_positives", "[", "index", "]", ")", "<", "1", ":", "\n", "                ", "return", "None", "\n", "\n", "", "posFeat", "=", "h5feat", "[", "self", ".", "nontrivial_positives", "[", "index", "]", ".", "tolist", "(", ")", "]", "\n", "knn", "=", "faiss", ".", "IndexFlatL2", "(", "posFeat", ".", "shape", "[", "1", "]", ")", "\n", "knn", ".", "add", "(", "posFeat", ")", "\n", "dPos", ",", "posNN", "=", "knn", ".", "search", "(", "qFeat", ".", "reshape", "(", "1", ",", "-", "1", ")", ",", "1", ")", "\n", "dPos", "=", "dPos", ".", "item", "(", ")", "\n", "posIndex", "=", "self", ".", "nontrivial_positives", "[", "index", "]", "[", "posNN", "[", "0", "]", "]", ".", "item", "(", ")", "\n", "\n", "negSample", "=", "np", ".", "random", ".", "choice", "(", "self", ".", "potential_negatives", "[", "index", "]", ",", "self", ".", "nNegSample", ")", "\n", "negSample", "=", "np", ".", "unique", "(", "np", ".", "concatenate", "(", "[", "self", ".", "negCache", "[", "index", "]", ",", "negSample", "]", ")", ")", ".", "astype", "(", "int", ")", "\n", "\n", "negFeat", "=", "h5feat", "[", "negSample", ".", "tolist", "(", ")", "]", "\n", "knn", "=", "faiss", ".", "IndexFlatL2", "(", "negFeat", ".", "shape", "[", "1", "]", ")", "\n", "knn", ".", "add", "(", "negFeat", ")", "\n", "\n", "dNeg", ",", "negNN", "=", "knn", ".", "search", "(", "qFeat", ".", "reshape", "(", "1", ",", "-", "1", ")", ",", "\n", "self", ".", "nNeg", "*", "10", ")", "# to quote netvlad paper code: 10x is hacky but fine", "\n", "dNeg", "=", "dNeg", ".", "reshape", "(", "-", "1", ")", "\n", "negNN", "=", "negNN", ".", "reshape", "(", "-", "1", ")", "\n", "\n", "# try to find negatives that are within margin, if there aren't any return none", "\n", "violatingNeg", "=", "dNeg", "<", "dPos", "+", "self", ".", "margin", "**", "0.5", "\n", "\n", "if", "np", ".", "sum", "(", "violatingNeg", ")", "<", "1", ":", "\n", "#if none are violating then skip this query", "\n", "                ", "return", "None", "\n", "\n", "", "negNN", "=", "negNN", "[", "violatingNeg", "]", "[", ":", "self", ".", "nNeg", "]", "\n", "negIndices", "=", "negSample", "[", "negNN", "]", ".", "astype", "(", "np", ".", "int32", ")", "\n", "self", ".", "negCache", "[", "index", "]", "=", "negIndices", "\n", "\n", "", "query", "=", "Image", ".", "open", "(", "join", "(", "queries_dir", ",", "self", ".", "dbStruct", ".", "qImage", "[", "index", "]", ")", ")", "\n", "positive", "=", "Image", ".", "open", "(", "join", "(", "root_dir", ",", "self", ".", "dbStruct", ".", "dbImage", "[", "posIndex", "]", ")", ")", "\n", "\n", "if", "self", ".", "input_transform", ":", "\n", "            ", "query", "=", "self", ".", "input_transform", "(", "query", ")", "\n", "positive", "=", "self", ".", "input_transform", "(", "positive", ")", "\n", "\n", "", "negatives", "=", "[", "]", "\n", "for", "negIndex", "in", "negIndices", ":", "\n", "            ", "negative", "=", "Image", ".", "open", "(", "join", "(", "root_dir", ",", "self", ".", "dbStruct", ".", "dbImage", "[", "negIndex", "]", ")", ")", "\n", "if", "self", ".", "input_transform", ":", "\n", "                ", "negative", "=", "self", ".", "input_transform", "(", "negative", ")", "\n", "", "negatives", ".", "append", "(", "negative", ")", "\n", "\n", "", "negatives", "=", "torch", ".", "stack", "(", "negatives", ",", "0", ")", "\n", "\n", "return", "query", ",", "positive", ",", "negatives", ",", "[", "index", ",", "posIndex", "]", "+", "negIndices", ".", "tolist", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ahmedest61_multires-netvlad.None.pittsburgh.QueryDatasetFromStruct.__len__": [[283, 285], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "queries", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.ahmedest61_multires-netvlad.None.pittsburgh.input_transform": [[33, 39], ["torchvision.Compose", "torchvision.Resize", "torchvision.ToTensor", "torchvision.Normalize"], "function", ["None"], ["def", "input_transform", "(", ")", ":", "\n", "    ", "return", "transforms", ".", "Compose", "(", "[", "\n", "transforms", ".", "Resize", "(", "(", "wandb", ".", "config", ".", "imgHeight", ",", "wandb", ".", "config", ".", "imgWidth", ")", ")", ",", "\n", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "transforms", ".", "Normalize", "(", "mean", "=", "[", "0.485", ",", "0.456", ",", "0.406", "]", ",", "\n", "std", "=", "[", "0.229", ",", "0.224", ",", "0.225", "]", ")", ",", "\n", "]", ")", "\n"]], "home.repos.pwc.inspect_result.ahmedest61_multires-netvlad.None.pittsburgh.get_whole_training_set": [[41, 46], ["os.path.join", "pittsburgh.WholeDatasetFromStruct", "pittsburgh.input_transform"], "function", ["home.repos.pwc.inspect_result.ahmedest61_multires-netvlad.tools.datasets.input_transform"], ["", "def", "get_whole_training_set", "(", "onlyDB", "=", "False", ")", ":", "\n", "    ", "structFile", "=", "join", "(", "struct_dir", ",", "'pitts30k_train.mat'", ")", "\n", "return", "WholeDatasetFromStruct", "(", "structFile", ",", "\n", "input_transform", "=", "input_transform", "(", ")", ",", "\n", "onlyDB", "=", "onlyDB", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ahmedest61_multires-netvlad.None.pittsburgh.get_whole_val_set": [[47, 51], ["os.path.join", "pittsburgh.WholeDatasetFromStruct", "pittsburgh.input_transform"], "function", ["home.repos.pwc.inspect_result.ahmedest61_multires-netvlad.tools.datasets.input_transform"], ["", "def", "get_whole_val_set", "(", ")", ":", "\n", "    ", "structFile", "=", "join", "(", "struct_dir", ",", "'pitts30k_val.mat'", ")", "\n", "return", "WholeDatasetFromStruct", "(", "structFile", ",", "\n", "input_transform", "=", "input_transform", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ahmedest61_multires-netvlad.None.pittsburgh.get_250k_val_set": [[52, 56], ["os.path.join", "pittsburgh.WholeDatasetFromStruct", "pittsburgh.input_transform"], "function", ["home.repos.pwc.inspect_result.ahmedest61_multires-netvlad.tools.datasets.input_transform"], ["", "def", "get_250k_val_set", "(", ")", ":", "\n", "    ", "structFile", "=", "join", "(", "struct_dir", ",", "'pitts250k_val.mat'", ")", "\n", "return", "WholeDatasetFromStruct", "(", "structFile", ",", "\n", "input_transform", "=", "input_transform", "(", ")", ")", "\n", "", "def", "get_whole_test_set", "(", ")", ":", "\n"]], "home.repos.pwc.inspect_result.ahmedest61_multires-netvlad.None.pittsburgh.get_whole_test_set": [[56, 60], ["os.path.join", "pittsburgh.WholeDatasetFromStruct", "pittsburgh.input_transform"], "function", ["home.repos.pwc.inspect_result.ahmedest61_multires-netvlad.tools.datasets.input_transform"], ["", "def", "get_whole_test_set", "(", ")", ":", "\n", "    ", "structFile", "=", "join", "(", "struct_dir", ",", "'pitts30k_test.mat'", ")", "\n", "return", "WholeDatasetFromStruct", "(", "structFile", ",", "\n", "input_transform", "=", "input_transform", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ahmedest61_multires-netvlad.None.pittsburgh.get_250k_test_set": [[61, 65], ["os.path.join", "pittsburgh.WholeDatasetFromStruct", "pittsburgh.input_transform"], "function", ["home.repos.pwc.inspect_result.ahmedest61_multires-netvlad.tools.datasets.input_transform"], ["", "def", "get_250k_test_set", "(", ")", ":", "\n", "    ", "structFile", "=", "join", "(", "struct_dir", ",", "'pitts250k_test.mat'", ")", "\n", "return", "WholeDatasetFromStruct", "(", "structFile", ",", "\n", "input_transform", "=", "input_transform", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ahmedest61_multires-netvlad.None.pittsburgh.get_training_query_set": [[66, 70], ["os.path.join", "pittsburgh.QueryDatasetFromStruct", "pittsburgh.input_transform"], "function", ["home.repos.pwc.inspect_result.ahmedest61_multires-netvlad.tools.datasets.input_transform"], ["", "def", "get_training_query_set", "(", "margin", "=", "0.1", ",", "nNeg", "=", "10", ")", ":", "\n", "    ", "structFile", "=", "join", "(", "struct_dir", ",", "'pitts30k_train.mat'", ")", "\n", "return", "QueryDatasetFromStruct", "(", "structFile", ",", "\n", "input_transform", "=", "input_transform", "(", ")", ",", "margin", "=", "margin", ",", "nNeg", "=", "nNeg", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ahmedest61_multires-netvlad.None.pittsburgh.get_val_query_set": [[71, 75], ["os.path.join", "pittsburgh.QueryDatasetFromStruct", "pittsburgh.input_transform"], "function", ["home.repos.pwc.inspect_result.ahmedest61_multires-netvlad.tools.datasets.input_transform"], ["", "def", "get_val_query_set", "(", ")", ":", "\n", "    ", "structFile", "=", "join", "(", "struct_dir", ",", "'pitts30k_val.mat'", ")", "\n", "return", "QueryDatasetFromStruct", "(", "structFile", ",", "\n", "input_transform", "=", "input_transform", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ahmedest61_multires-netvlad.None.pittsburgh.get_250k_val_query_set": [[76, 80], ["os.path.join", "pittsburgh.QueryDatasetFromStruct", "pittsburgh.input_transform"], "function", ["home.repos.pwc.inspect_result.ahmedest61_multires-netvlad.tools.datasets.input_transform"], ["", "def", "get_250k_val_query_set", "(", ")", ":", "\n", "    ", "structFile", "=", "join", "(", "struct_dir", ",", "'pitts250k_val.mat'", ")", "\n", "return", "QueryDatasetFromStruct", "(", "structFile", ",", "\n", "input_transform", "=", "input_transform", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ahmedest61_multires-netvlad.None.pittsburgh.parse_dbStruct": [[85, 112], ["scipy.io.loadmat", "mat[].item", "matStruct[].item", "matStruct[].item", "matStruct[].item", "matStruct[].item", "matStruct[].item", "matStruct[].item", "dbStruct", "f[].item", "f[].item", "path.split"], "function", ["None"], ["def", "parse_dbStruct", "(", "path", ")", ":", "\n", "    ", "mat", "=", "loadmat", "(", "path", ")", "\n", "matStruct", "=", "mat", "[", "'dbStruct'", "]", ".", "item", "(", ")", "\n", "\n", "if", "'250k'", "in", "path", ".", "split", "(", "'/'", ")", "[", "-", "1", "]", ":", "\n", "        ", "dataset", "=", "'pitts250k'", "\n", "", "else", ":", "\n", "        ", "dataset", "=", "'pitts30k'", "\n", "\n", "", "whichSet", "=", "matStruct", "[", "0", "]", ".", "item", "(", ")", "\n", "\n", "dbImage", "=", "[", "f", "[", "0", "]", ".", "item", "(", ")", "for", "f", "in", "matStruct", "[", "1", "]", "]", "\n", "utmDb", "=", "matStruct", "[", "2", "]", ".", "T", "\n", "\n", "qImage", "=", "[", "f", "[", "0", "]", ".", "item", "(", ")", "for", "f", "in", "matStruct", "[", "3", "]", "]", "\n", "utmQ", "=", "matStruct", "[", "4", "]", ".", "T", "\n", "\n", "numDb", "=", "matStruct", "[", "5", "]", ".", "item", "(", ")", "\n", "numQ", "=", "matStruct", "[", "6", "]", ".", "item", "(", ")", "\n", "\n", "posDistThr", "=", "matStruct", "[", "7", "]", ".", "item", "(", ")", "\n", "posDistSqThr", "=", "matStruct", "[", "8", "]", ".", "item", "(", ")", "\n", "nonTrivPosDistSqThr", "=", "matStruct", "[", "9", "]", ".", "item", "(", ")", "\n", "\n", "return", "dbStruct", "(", "whichSet", ",", "dataset", ",", "dbImage", ",", "utmDb", ",", "qImage", ",", "\n", "utmQ", ",", "numDb", ",", "numQ", ",", "posDistThr", ",", "\n", "posDistSqThr", ",", "nonTrivPosDistSqThr", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ahmedest61_multires-netvlad.None.pittsburgh.collate_fn": [[153, 180], ["list", "zip", "torch.dataloader.default_collate", "torch.dataloader.default_collate", "torch.dataloader.default_collate", "torch.cat", "torch.cat", "list", "filter", "len", "itertools.chain"], "function", ["home.repos.pwc.inspect_result.ahmedest61_multires-netvlad.training_tools.msls.MSLS.filter"], ["", "", "def", "collate_fn", "(", "batch", ")", ":", "\n", "    ", "\"\"\"Creates mini-batch tensors from the list of tuples (query, positive, negatives).\n    \n    Args:\n        data: list of tuple (query, positive, negatives). \n            - query: torch tensor of shape (3, h, w).\n            - positive: torch tensor of shape (3, h, w).\n            - negative: torch tensor of shape (n, 3, h, w).\n    Returns:\n        query: torch tensor of shape (batch_size, 3, h, w).\n        positive: torch tensor of shape (batch_size, 3, h, w).\n        negatives: torch tensor of shape (batch_size, n, 3, h, w).\n    \"\"\"", "\n", "\n", "batch", "=", "list", "(", "filter", "(", "lambda", "x", ":", "x", "is", "not", "None", ",", "batch", ")", ")", "\n", "if", "len", "(", "batch", ")", "==", "0", ":", "return", "None", ",", "None", ",", "None", ",", "None", ",", "None", "\n", "\n", "query", ",", "positive", ",", "negatives", ",", "indices", "=", "zip", "(", "*", "batch", ")", "\n", "\n", "query", "=", "data", ".", "dataloader", ".", "default_collate", "(", "query", ")", "\n", "positive", "=", "data", ".", "dataloader", ".", "default_collate", "(", "positive", ")", "\n", "negCounts", "=", "data", ".", "dataloader", ".", "default_collate", "(", "[", "x", ".", "shape", "[", "0", "]", "for", "x", "in", "negatives", "]", ")", "\n", "negatives", "=", "torch", ".", "cat", "(", "negatives", ",", "0", ")", "\n", "import", "itertools", "\n", "indices", "=", "list", "(", "itertools", ".", "chain", "(", "*", "indices", ")", ")", "\n", "\n", "return", "query", ",", "positive", ",", "negatives", ",", "negCounts", ",", "indices", "\n", "\n"]], "home.repos.pwc.inspect_result.ahmedest61_multires-netvlad.None.netvlad.NetVLAD.__init__": [[11, 34], ["torch.Module.__init__", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand"], "methods", ["home.repos.pwc.inspect_result.ahmedest61_multires-netvlad.training_tools.msls.MSLS.__init__"], ["def", "__init__", "(", "self", ",", "num_clusters", "=", "64", ",", "dim", "=", "128", ",", "\n", "normalize_input", "=", "True", ",", "vladv2", "=", "False", ",", "reg_attention", "=", "False", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            num_clusters : int\n                The number of clusters\n            dim : int\n                Dimension of descriptors\n            alpha : float\n                Parameter of initialization. Larger value is harder assignment.\n            normalize_input : bool\n                If true, descriptor-wise L2 normalization is applied to input.\n            vladv2 : bool\n                If true, use vladv2 otherwise use vladv1\n        \"\"\"", "\n", "super", "(", "NetVLAD", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "num_clusters", "=", "num_clusters", "\n", "self", ".", "dim", "=", "dim", "\n", "self", ".", "alpha", "=", "0", "\n", "self", ".", "vladv2", "=", "vladv2", "\n", "self", ".", "normalize_input", "=", "normalize_input", "\n", "self", ".", "conv", "=", "nn", ".", "Conv2d", "(", "dim", ",", "num_clusters", ",", "kernel_size", "=", "(", "1", ",", "1", ")", ",", "bias", "=", "vladv2", ")", "\n", "self", ".", "centroids", "=", "nn", ".", "Parameter", "(", "torch", ".", "rand", "(", "num_clusters", ",", "dim", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ahmedest61_multires-netvlad.None.netvlad.NetVLAD.init_params": [[35, 62], ["numpy.dot", "numpy.dot.sort", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "faiss.IndexFlatL2", "faiss.IndexFlatL2.add", "numpy.square", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "numpy.linalg.norm", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy().unsqueeze().unsqueeze", "torch.from_numpy().unsqueeze().unsqueeze", "torch.from_numpy().unsqueeze().unsqueeze", "torch.from_numpy().unsqueeze().unsqueeze", "torch.from_numpy().unsqueeze().unsqueeze", "torch.from_numpy().unsqueeze().unsqueeze", "torch.from_numpy().unsqueeze().unsqueeze", "torch.from_numpy().unsqueeze().unsqueeze", "torch.from_numpy().unsqueeze().unsqueeze", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "faiss.IndexFlatL2.search", "netvlad.NetVLAD.centroids.norm", "numpy.mean", "torch.from_numpy().unsqueeze", "torch.from_numpy().unsqueeze", "torch.from_numpy().unsqueeze", "torch.from_numpy().unsqueeze", "torch.from_numpy().unsqueeze", "torch.from_numpy().unsqueeze", "torch.from_numpy().unsqueeze", "torch.from_numpy().unsqueeze", "torch.from_numpy().unsqueeze", "numpy.mean", "numpy.log", "numpy.log", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy"], "methods", ["None"], ["", "def", "init_params", "(", "self", ",", "clsts", ",", "traindescs", ")", ":", "\n", "#TODO replace numpy ops with pytorch ops", "\n", "        ", "if", "self", ".", "vladv2", "==", "False", ":", "\n", "            ", "clstsAssign", "=", "clsts", "/", "np", ".", "linalg", ".", "norm", "(", "clsts", ",", "axis", "=", "1", ",", "keepdims", "=", "True", ")", "\n", "dots", "=", "np", ".", "dot", "(", "clstsAssign", ",", "traindescs", ".", "T", ")", "\n", "dots", ".", "sort", "(", "0", ")", "\n", "dots", "=", "dots", "[", ":", ":", "-", "1", ",", ":", "]", "# sort, descending", "\n", "\n", "self", ".", "alpha", "=", "(", "-", "np", ".", "log", "(", "0.01", ")", "/", "np", ".", "mean", "(", "dots", "[", "0", ",", ":", "]", "-", "dots", "[", "1", ",", ":", "]", ")", ")", ".", "item", "(", ")", "\n", "self", ".", "centroids", "=", "nn", ".", "Parameter", "(", "torch", ".", "from_numpy", "(", "clsts", ")", ")", "\n", "self", ".", "conv", ".", "weight", "=", "nn", ".", "Parameter", "(", "torch", ".", "from_numpy", "(", "self", ".", "alpha", "*", "clstsAssign", ")", ".", "unsqueeze", "(", "2", ")", ".", "unsqueeze", "(", "3", ")", ")", "\n", "self", ".", "conv", ".", "bias", "=", "None", "\n", "", "else", ":", "\n", "            ", "knn", "=", "faiss", ".", "IndexFlatL2", "(", "traindescs", ".", "shape", "[", "1", "]", ")", "\n", "knn", ".", "add", "(", "traindescs", ")", "\n", "del", "traindescs", "\n", "dsSq", "=", "np", ".", "square", "(", "knn", ".", "search", "(", "clsts", ",", "2", ")", "[", "1", "]", ")", "\n", "del", "knn", "\n", "self", ".", "alpha", "=", "(", "-", "np", ".", "log", "(", "0.01", ")", "/", "np", ".", "mean", "(", "dsSq", "[", ":", ",", "1", "]", "-", "dsSq", "[", ":", ",", "0", "]", ")", ")", ".", "item", "(", ")", "\n", "self", ".", "centroids", "=", "nn", ".", "Parameter", "(", "torch", ".", "from_numpy", "(", "clsts", ")", ")", "\n", "del", "clsts", ",", "dsSq", "\n", "\n", "self", ".", "conv", ".", "weight", "=", "nn", ".", "Parameter", "(", "\n", "(", "2.0", "*", "self", ".", "alpha", "*", "self", ".", "centroids", ")", ".", "unsqueeze", "(", "-", "1", ")", ".", "unsqueeze", "(", "-", "1", ")", "\n", ")", "\n", "self", ".", "conv", ".", "bias", "=", "nn", ".", "Parameter", "(", "\n", "-", "self", ".", "alpha", "*", "self", ".", "centroids", ".", "norm", "(", "dim", "=", "1", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.ahmedest61_multires-netvlad.None.netvlad.NetVLAD.forward": [[64, 92], ["netvlad.NetVLAD.conv().view", "torch.softmax", "torch.softmax", "torch.softmax", "torch.normalize.view", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "range", "torch.normalize", "torch.normalize", "torch.normalize", "torch.normalize.view", "torch.normalize", "torch.normalize", "torch.normalize", "torch.normalize", "torch.normalize", "torch.normalize", "soft_assign[].unsqueeze", "residual.sum", "torch.normalize.size", "netvlad.NetVLAD.conv", "F.normalize.view.unsqueeze().permute", "netvlad.NetVLAD.centroids[].expand().permute().unsqueeze", "F.normalize.view.unsqueeze", "netvlad.NetVLAD.centroids[].expand().permute", "netvlad.NetVLAD.centroids[].expand", "F.normalize.view.size"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "N", ",", "C", "=", "x", ".", "shape", "[", ":", "2", "]", "\n", "\n", "if", "self", ".", "normalize_input", ":", "\n", "            ", "x", "=", "F", ".", "normalize", "(", "x", ",", "p", "=", "2", ",", "dim", "=", "1", ")", "# across descriptor dim", "\n", "\n", "# soft-assignment", "\n", "", "soft_assign", "=", "self", ".", "conv", "(", "x", ")", ".", "view", "(", "N", ",", "self", ".", "num_clusters", ",", "-", "1", ")", "\n", "soft_assign", "=", "F", ".", "softmax", "(", "soft_assign", ",", "dim", "=", "1", ")", "\n", "\n", "x_flatten", "=", "x", ".", "view", "(", "N", ",", "C", ",", "-", "1", ")", "\n", "\n", "# calculate residuals to each clusters", "\n", "vlad", "=", "torch", ".", "zeros", "(", "[", "N", ",", "self", ".", "num_clusters", ",", "C", "]", ",", "dtype", "=", "x", ".", "dtype", ",", "layout", "=", "x", ".", "layout", ",", "device", "=", "x", ".", "device", ")", "\n", "for", "C", "in", "range", "(", "self", ".", "num_clusters", ")", ":", "# slower than non-looped, but lower memory usage ", "\n", "            ", "residual", "=", "x_flatten", ".", "unsqueeze", "(", "0", ")", ".", "permute", "(", "1", ",", "0", ",", "2", ",", "3", ")", "-", "self", ".", "centroids", "[", "C", ":", "C", "+", "1", ",", ":", "]", ".", "expand", "(", "x_flatten", ".", "size", "(", "-", "1", ")", ",", "-", "1", ",", "-", "1", ")", ".", "permute", "(", "1", ",", "2", ",", "0", ")", ".", "unsqueeze", "(", "0", ")", "\n", "residual", "*=", "soft_assign", "[", ":", ",", "C", ":", "C", "+", "1", ",", ":", "]", ".", "unsqueeze", "(", "2", ")", "\n", "vlad", "[", ":", ",", "C", ":", "C", "+", "1", ",", ":", "]", "=", "residual", ".", "sum", "(", "dim", "=", "-", "1", ")", "\n", "\n", "", "vlad", "=", "F", ".", "normalize", "(", "vlad", ",", "p", "=", "2", ",", "dim", "=", "2", ")", "# intra-normalization", "\n", "vlad", "=", "vlad", ".", "view", "(", "x", ".", "size", "(", "0", ")", ",", "-", "1", ")", "# flatten", "\n", "vlad", "=", "F", ".", "normalize", "(", "vlad", ",", "p", "=", "2", ",", "dim", "=", "1", ")", "# L2 normalize", "\n", "\n", "# remove it ", "\n", "#vlad = vlad.view(N,self.num_clusters,-1)", "\n", "#vlad = vlad.unsqueeze(1)", "\n", "return", "vlad", "\n", "", "", ""]], "home.repos.pwc.inspect_result.ahmedest61_multires-netvlad.tools.patch_matcher.PatchMatcher.__init__": [[47, 53], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "matcher", ",", "patch_sizes", ",", "strides", ",", "all_keypoints", ",", "all_indices", ")", ":", "\n", "        ", "self", ".", "matcher", "=", "matcher", "\n", "self", ".", "patch_sizes", "=", "patch_sizes", "\n", "self", ".", "strides", "=", "strides", "\n", "self", ".", "all_keypoints", "=", "all_keypoints", "\n", "self", ".", "all_indices", "=", "all_indices", "\n", "\n"]], "home.repos.pwc.inspect_result.ahmedest61_multires-netvlad.tools.patch_matcher.PatchMatcher.match": [[54, 61], ["patch_matcher.PatchMatcher.compare_two_ransac", "patch_matcher.PatchMatcher.compare_two_spatial", "ValueError"], "methods", ["home.repos.pwc.inspect_result.ahmedest61_multires-netvlad.tools.patch_matcher.PatchMatcher.compare_two_ransac", "home.repos.pwc.inspect_result.ahmedest61_multires-netvlad.tools.patch_matcher.PatchMatcher.compare_two_spatial"], ["", "def", "match", "(", "self", ",", "qfeats", ",", "dbfeats", ")", ":", "\n", "        ", "if", "self", ".", "matcher", "==", "'RANSAC'", ":", "\n", "            ", "return", "self", ".", "compare_two_ransac", "(", "qfeats", ",", "dbfeats", ")", "\n", "", "elif", "self", ".", "matcher", "==", "'spatialApproximator'", ":", "\n", "            ", "return", "self", ".", "compare_two_spatial", "(", "qfeats", ",", "dbfeats", ")", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "'unknown matcher descriptor'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ahmedest61_multires-netvlad.tools.patch_matcher.PatchMatcher.compare_two_ransac": [[62, 99], ["zip", "patch_matcher.torch_nn", "fw_inds.cpu().numpy.cpu().numpy.cpu().numpy", "bw_inds.cpu().numpy.cpu().numpy.cpu().numpy", "numpy.atleast_1d", "numpy.argwhere().squeeze", "len", "numpy.transpose", "numpy.transpose", "cv2.findHomography", "all_inlier_query_keypoints.append", "scores.append", "all_inlier_index_keypoints.append", "scores.append", "fw_inds.cpu().numpy.cpu().numpy.cpu", "bw_inds.cpu().numpy.cpu().numpy.cpu", "numpy.argwhere", "mask.ravel", "numpy.arange", "mask.ravel", "len"], "methods", ["home.repos.pwc.inspect_result.ahmedest61_multires-netvlad.tools.patch_matcher.torch_nn"], ["", "", "def", "compare_two_ransac", "(", "self", ",", "qfeats", ",", "dbfeats", ")", ":", "\n", "        ", "scores", "=", "[", "]", "\n", "all_inlier_index_keypoints", "=", "[", "]", "\n", "all_inlier_query_keypoints", "=", "[", "]", "\n", "for", "qfeat", ",", "dbfeat", ",", "keypoints", ",", "stride", "in", "zip", "(", "qfeats", ",", "dbfeats", ",", "self", ".", "all_keypoints", ",", "self", ".", "strides", ")", ":", "\n", "            ", "fw_inds", ",", "bw_inds", "=", "torch_nn", "(", "qfeat", ",", "dbfeat", ")", "\n", "\n", "fw_inds", "=", "fw_inds", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "bw_inds", "=", "bw_inds", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "\n", "mutuals", "=", "np", ".", "atleast_1d", "(", "np", ".", "argwhere", "(", "bw_inds", "[", "fw_inds", "]", "==", "np", ".", "arange", "(", "len", "(", "fw_inds", ")", ")", ")", ".", "squeeze", "(", ")", ")", "\n", "\n", "if", "len", "(", "mutuals", ")", ">", "3", ":", "# need at least four points to estimate a Homography", "\n", "                ", "index_keypoints", "=", "keypoints", "[", ":", ",", "mutuals", "]", "\n", "query_keypoints", "=", "keypoints", "[", ":", ",", "fw_inds", "[", "mutuals", "]", "]", "\n", "\n", "index_keypoints", "=", "np", ".", "transpose", "(", "index_keypoints", ")", "\n", "query_keypoints", "=", "np", ".", "transpose", "(", "query_keypoints", ")", "\n", "\n", "_", ",", "mask", "=", "cv2", ".", "findHomography", "(", "index_keypoints", ",", "query_keypoints", ",", "cv2", ".", "FM_RANSAC", ",", "\n", "ransacReprojThreshold", "=", "16", "*", "stride", "*", "1.5", ")", "\n", "# RANSAC reproj threshold is set to the (stride*1.5) in image space for vgg-16, given a particular patch stride", "\n", "# in this work, we ignore the H matrix output - but users of this code are welcome to utilise this for", "\n", "# pose estimation (something we may also investigate in future work)", "\n", "\n", "inlier_index_keypoints", "=", "index_keypoints", "[", "mask", ".", "ravel", "(", ")", "==", "1", "]", "\n", "all_inlier_query_keypoints", ".", "append", "(", "query_keypoints", "[", "mask", ".", "ravel", "(", ")", "==", "1", "]", ")", "\n", "inlier_count", "=", "inlier_index_keypoints", ".", "shape", "[", "0", "]", "\n", "scores", ".", "append", "(", "-", "inlier_count", "/", "qfeat", ".", "shape", "[", "0", "]", ")", "\n", "all_inlier_index_keypoints", ".", "append", "(", "inlier_index_keypoints", ")", "\n", "# we flip to negative such that best match is the smallest number, to be consistent with vanilla NetVlad", "\n", "# we normalise by patch count to remove biases in the scoring between different patch sizes (so that all", "\n", "# patch sizes are weighted equally and that the only weighting is from the user-defined patch weights)", "\n", "", "else", ":", "\n", "                ", "scores", ".", "append", "(", "0.", ")", "\n", "\n", "", "", "return", "scores", ",", "all_inlier_query_keypoints", ",", "all_inlier_index_keypoints", "\n", "\n"]], "home.repos.pwc.inspect_result.ahmedest61_multires-netvlad.tools.patch_matcher.PatchMatcher.compare_two_spatial": [[100, 140], ["zip", "patch_matcher.torch_nn", "fw_inds.cpu().numpy.cpu().numpy.cpu().numpy", "bw_inds.cpu().numpy.cpu().numpy.cpu().numpy", "numpy.atleast_1d", "numpy.argwhere().squeeze", "len", "numpy.mean", "numpy.absolute", "numpy.absolute", "numpy.max", "numpy.max", "scores.append", "scores.append", "fw_inds.cpu().numpy.cpu().numpy.cpu", "bw_inds.cpu().numpy.cpu().numpy.cpu", "numpy.argwhere", "s_score.sum", "numpy.arange", "len"], "methods", ["home.repos.pwc.inspect_result.ahmedest61_multires-netvlad.tools.patch_matcher.torch_nn"], ["", "def", "compare_two_spatial", "(", "self", ",", "qfeats", ",", "dbfeats", ")", ":", "\n", "        ", "scores", "=", "[", "]", "\n", "for", "qfeat", ",", "dbfeat", ",", "indices", "in", "zip", "(", "qfeats", ",", "dbfeats", ",", "self", ".", "all_indices", ")", ":", "\n", "            ", "fw_inds", ",", "bw_inds", "=", "torch_nn", "(", "qfeat", ",", "dbfeat", ")", "\n", "\n", "fw_inds", "=", "fw_inds", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "bw_inds", "=", "bw_inds", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "\n", "mutuals", "=", "np", ".", "atleast_1d", "(", "np", ".", "argwhere", "(", "bw_inds", "[", "fw_inds", "]", "==", "np", ".", "arange", "(", "len", "(", "fw_inds", ")", ")", ")", ".", "squeeze", "(", ")", ")", "\n", "\n", "if", "len", "(", "mutuals", ")", ">", "0", ":", "\n", "                ", "index_keypoints", "=", "indices", "[", ":", ",", "mutuals", "]", "\n", "query_keypoints", "=", "indices", "[", ":", ",", "fw_inds", "[", "mutuals", "]", "]", "\n", "\n", "spatial_dist", "=", "index_keypoints", "-", "query_keypoints", "# manhattan distance works reasonably well and is fast", "\n", "mean_spatial_dist", "=", "np", ".", "mean", "(", "spatial_dist", ",", "axis", "=", "1", ")", "\n", "\n", "# residual between a spatial distance and the mean spatial distance. Smaller is better", "\n", "s_dists_x", "=", "spatial_dist", "[", "0", ",", ":", "]", "-", "mean_spatial_dist", "[", "0", "]", "\n", "s_dists_y", "=", "spatial_dist", "[", "1", ",", ":", "]", "-", "mean_spatial_dist", "[", "1", "]", "\n", "s_dists_x", "=", "np", ".", "absolute", "(", "s_dists_x", ")", "\n", "s_dists_y", "=", "np", ".", "absolute", "(", "s_dists_y", ")", "\n", "\n", "# anchor to the maximum x and y axis index for the patch \"feature space\"", "\n", "xmax", "=", "np", ".", "max", "(", "indices", "[", "0", ",", ":", "]", ")", "\n", "ymax", "=", "np", ".", "max", "(", "indices", "[", "1", ",", ":", "]", ")", "\n", "\n", "# find second-order residual, by comparing the first residual to the respective anchors", "\n", "# after this step, larger is now better", "\n", "# add non-linearity to the system to excessively penalise deviations from the mean", "\n", "s_score", "=", "(", "xmax", "-", "s_dists_x", ")", "**", "2", "+", "(", "ymax", "-", "s_dists_y", ")", "**", "2", "\n", "\n", "scores", ".", "append", "(", "-", "s_score", ".", "sum", "(", ")", "/", "qfeat", ".", "shape", "[", "0", "]", ")", "\n", "# we flip to negative such that best match is the smallest number, to be consistent with vanilla NetVlad", "\n", "# we normalise by patch count to remove biases in the scoring between different patch sizes (so that all", "\n", "# patch sizes are weighted equally and that the only weighting is from the user-defined patch weights)", "\n", "", "else", ":", "\n", "                ", "scores", ".", "append", "(", "0.", ")", "\n", "\n", "", "", "return", "scores", ",", "None", ",", "None", "\n", "", "", ""]], "home.repos.pwc.inspect_result.ahmedest61_multires-netvlad.tools.patch_matcher.torch_nn": [[34, 44], ["torch.matmul", "torch.sqrt", "torch.min", "torch.argmin"], "function", ["None"], ["def", "torch_nn", "(", "x", ",", "y", ")", ":", "\n", "    ", "mul", "=", "torch", ".", "matmul", "(", "x", ",", "y", ")", "\n", "\n", "dist", "=", "2", "-", "2", "*", "mul", "+", "1e-9", "\n", "dist", "=", "torch", ".", "sqrt", "(", "dist", ")", "\n", "\n", "_", ",", "fw_inds", "=", "torch", ".", "min", "(", "dist", ",", "0", ")", "\n", "bw_inds", "=", "torch", ".", "argmin", "(", "dist", ",", "1", ")", "\n", "\n", "return", "fw_inds", ",", "bw_inds", "\n", "\n"]], "home.repos.pwc.inspect_result.ahmedest61_multires-netvlad.tools.gen_image_file_list.has_file_allowed_extension": [[33, 36], ["filename.lower", "any", "filename.lower.endswith"], "function", ["None"], ["def", "has_file_allowed_extension", "(", "filename", ",", "extensions", ")", ":", "\n", "    ", "filename_lower", "=", "filename", ".", "lower", "(", ")", "\n", "return", "any", "(", "filename_lower", ".", "endswith", "(", "ext", ")", "for", "ext", "in", "extensions", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ahmedest61_multires-netvlad.tools.datasets.PlaceDataset.__init__": [[56, 83], ["torch.Dataset.__init__", "datasets.input_transform", "datasets.PlaceDataset.parse_text_file", "datasets.PlaceDataset.parse_text_file", "datasets.PlaceDataset.parse_gt_file", "os.path.join", "os.path.isfile", "os.path.isfile", "int", "int", "os.path.join", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.ahmedest61_multires-netvlad.training_tools.msls.MSLS.__init__", "home.repos.pwc.inspect_result.ahmedest61_multires-netvlad.tools.datasets.input_transform", "home.repos.pwc.inspect_result.ahmedest61_multires-netvlad.tools.datasets.PlaceDataset.parse_text_file", "home.repos.pwc.inspect_result.ahmedest61_multires-netvlad.tools.datasets.PlaceDataset.parse_text_file", "home.repos.pwc.inspect_result.ahmedest61_multires-netvlad.tools.datasets.PlaceDataset.parse_gt_file"], ["    ", "def", "__init__", "(", "self", ",", "query_file_path", ",", "index_file_path", ",", "dataset_root_dir", ",", "ground_truth_path", ",", "config", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "queries", ",", "self", ".", "database", ",", "self", ".", "numQ", ",", "self", ".", "numDb", ",", "self", ".", "utmQ", ",", "self", ".", "utmDb", ",", "self", ".", "posDistThr", "=", "None", ",", "None", ",", "None", ",", "None", ",", "None", ",", "None", ",", "None", "\n", "if", "query_file_path", "is", "not", "None", ":", "\n", "            ", "self", ".", "queries", ",", "self", ".", "numQ", "=", "self", ".", "parse_text_file", "(", "query_file_path", ")", "\n", "", "if", "index_file_path", "is", "not", "None", ":", "\n", "            ", "self", ".", "database", ",", "self", ".", "numDb", "=", "self", ".", "parse_text_file", "(", "index_file_path", ")", "\n", "", "if", "ground_truth_path", "is", "not", "None", ":", "\n", "            ", "self", ".", "utmQ", ",", "self", ".", "utmDb", ",", "self", ".", "posDistThr", "=", "self", ".", "parse_gt_file", "(", "ground_truth_path", ")", "\n", "\n", "", "if", "self", ".", "queries", "is", "not", "None", ":", "\n", "            ", "self", ".", "images", "=", "self", ".", "database", "+", "self", ".", "queries", "\n", "", "else", ":", "\n", "            ", "self", ".", "images", "=", "self", ".", "database", "\n", "\n", "", "self", ".", "images", "=", "[", "os", ".", "path", ".", "join", "(", "dataset_root_dir", ",", "image", ")", "for", "image", "in", "self", ".", "images", "]", "\n", "# check if images are relative to root dir", "\n", "if", "not", "os", ".", "path", ".", "isfile", "(", "self", ".", "images", "[", "0", "]", ")", ":", "\n", "            ", "if", "os", ".", "path", ".", "isfile", "(", "os", ".", "path", ".", "join", "(", "PATCHNETVLAD_ROOT_DIR", ",", "self", ".", "images", "[", "0", "]", ")", ")", ":", "\n", "                ", "self", ".", "images", "=", "[", "os", ".", "path", ".", "join", "(", "PATCHNETVLAD_ROOT_DIR", ",", "image", ")", "for", "image", "in", "self", ".", "images", "]", "\n", "\n", "", "", "self", ".", "positives", "=", "None", "\n", "self", ".", "distances", "=", "None", "\n", "self", ".", "resize", "=", "(", "int", "(", "config", "[", "'imageresizeH'", "]", ")", ",", "int", "(", "config", "[", "'imageresizeW'", "]", ")", ")", "\n", "\n", "self", ".", "mytransform", "=", "input_transform", "(", "resize", "=", "self", ".", "resize", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ahmedest61_multires-netvlad.tools.datasets.PlaceDataset.__getitem__": [[84, 89], ["PIL.Image.open", "datasets.PlaceDataset.mytransform"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "img", "=", "Image", ".", "open", "(", "self", ".", "images", "[", "index", "]", ")", "\n", "img", "=", "self", ".", "mytransform", "(", "img", ")", "\n", "\n", "return", "img", ",", "index", "\n", "\n"]], "home.repos.pwc.inspect_result.ahmedest61_multires-netvlad.tools.datasets.PlaceDataset.__len__": [[90, 92], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "images", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ahmedest61_multires-netvlad.tools.datasets.PlaceDataset.get_positives": [[93, 103], ["sklearn.neighbors.NearestNeighbors", "sklearn.neighbors.NearestNeighbors.fit", "sklearn.neighbors.NearestNeighbors.radius_neighbors"], "methods", ["None"], ["", "def", "get_positives", "(", "self", ")", ":", "\n", "# positives for evaluation are those within trivial threshold range", "\n", "# fit NN to find them, search by radius", "\n", "        ", "if", "self", ".", "positives", "is", "None", ":", "\n", "            ", "knn", "=", "NearestNeighbors", "(", "n_jobs", "=", "-", "1", ")", "\n", "knn", ".", "fit", "(", "self", ".", "utmDb", ")", "\n", "\n", "self", ".", "distances", ",", "self", ".", "positives", "=", "knn", ".", "radius_neighbors", "(", "self", ".", "utmQ", ",", "radius", "=", "self", ".", "posDistThr", ")", "\n", "\n", "", "return", "self", ".", "positives", "\n", "\n"]], "home.repos.pwc.inspect_result.ahmedest61_multires-netvlad.tools.datasets.PlaceDataset.parse_text_file": [[104, 119], ["print", "len", "print", "open", "f.read().splitlines", "image_list[].lower", "f.read", "os.path.splitext", "q_im.split"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "parse_text_file", "(", "textfile", ")", ":", "\n", "        ", "print", "(", "'Parsing dataset...'", ")", "\n", "\n", "with", "open", "(", "textfile", ",", "'r'", ")", "as", "f", ":", "\n", "            ", "image_list", "=", "f", ".", "read", "(", ")", ".", "splitlines", "(", ")", "\n", "\n", "", "if", "'robotcar'", "in", "image_list", "[", "0", "]", ".", "lower", "(", ")", ":", "\n", "            ", "image_list", "=", "[", "os", ".", "path", ".", "splitext", "(", "'/'", ".", "join", "(", "q_im", ".", "split", "(", "'/'", ")", "[", "-", "3", ":", "]", ")", ")", "[", "0", "]", "for", "q_im", "in", "image_list", "]", "\n", "\n", "", "num_images", "=", "len", "(", "image_list", ")", "\n", "\n", "print", "(", "'Done! Found %d images'", "%", "num_images", ")", "\n", "\n", "return", "image_list", ",", "num_images", "\n", "\n"]], "home.repos.pwc.inspect_result.ahmedest61_multires-netvlad.tools.datasets.PlaceDataset.parse_gt_file": [[120, 125], ["print", "numpy.load"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "parse_gt_file", "(", "gtfile", ")", ":", "\n", "        ", "print", "(", "'Parsing ground truth data file...'", ")", "\n", "gtdata", "=", "np", ".", "load", "(", "gtfile", ")", "\n", "return", "gtdata", "[", "'utmQ'", "]", ",", "gtdata", "[", "'utmDb'", "]", ",", "gtdata", "[", "'posDistThr'", "]", "\n", "", "", ""]], "home.repos.pwc.inspect_result.ahmedest61_multires-netvlad.tools.datasets.input_transform": [[39, 52], ["torchvision.Compose", "torchvision.Compose", "torchvision.Resize", "torchvision.ToTensor", "torchvision.Normalize", "torchvision.ToTensor", "torchvision.Normalize"], "function", ["None"], ["def", "input_transform", "(", "resize", "=", "(", "640", ",", "480", ")", ")", ":", "\n", "    ", "if", "resize", "[", "0", "]", ">", "0", "and", "resize", "[", "1", "]", ">", "0", ":", "\n", "        ", "return", "transforms", ".", "Compose", "(", "[", "\n", "transforms", ".", "Resize", "(", "resize", ")", ",", "\n", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "transforms", ".", "Normalize", "(", "mean", "=", "[", "0.485", ",", "0.456", ",", "0.406", "]", ",", "\n", "std", "=", "[", "0.229", ",", "0.224", ",", "0.225", "]", ")", ",", "\n", "]", ")", "\n", "", "else", ":", "\n", "        ", "return", "transforms", ".", "Compose", "(", "[", "\n", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "transforms", ".", "Normalize", "(", "mean", "=", "[", "0.485", ",", "0.456", ",", "0.406", "]", ",", "\n", "std", "=", "[", "0.229", ",", "0.224", ",", "0.225", "]", ")", ",", "\n", "]", ")", "\n"]], "home.repos.pwc.inspect_result.ahmedest61_multires-netvlad.models.local_matcher.calc_receptive_boxes": [[48, 74], ["torch.meshgrid", "torch.reshape", "torch.cat", "torch.arange", "torch.arange", "torch.stack", "torch.FloatTensor"], "function", ["None"], ["def", "calc_receptive_boxes", "(", "height", ",", "width", ")", ":", "\n", "    ", "\"\"\"Calculate receptive boxes for each feature point.\n    Modified from\n    https://github.com/tensorflow/models/blob/238922e98dd0e8254b5c0921b241a1f5a151782f/research/delf/delf/python/feature_extractor.py\n\n    Args:\n      height: The height of feature map.\n      width: The width of feature map.\n      rf: The receptive field size.\n      stride: The effective stride between two adjacent feature points.\n      padding: The effective padding size.\n\n    Returns:\n      rf_boxes: [N, 4] receptive boxes tensor. Here N equals to height x width.\n      Each box is represented by [xmin, ymin, xmax, ymax].\n    \"\"\"", "\n", "\n", "rf", ",", "stride", ",", "padding", "=", "[", "196.0", ",", "16.0", ",", "90.0", "]", "# hardcoded for vgg-16 conv5_3", "\n", "\n", "x", ",", "y", "=", "torch", ".", "meshgrid", "(", "torch", ".", "arange", "(", "0", ",", "height", ")", ",", "torch", ".", "arange", "(", "0", ",", "width", ")", ")", "\n", "coordinates", "=", "torch", ".", "reshape", "(", "torch", ".", "stack", "(", "[", "y", ",", "x", "]", ",", "dim", "=", "2", ")", ",", "[", "-", "1", ",", "2", "]", ")", "\n", "# [y,x,y,x]", "\n", "point_boxes", "=", "torch", ".", "cat", "(", "[", "coordinates", ",", "coordinates", "]", ",", "1", ")", "\n", "bias", "=", "[", "-", "padding", ",", "-", "padding", ",", "-", "padding", "+", "rf", "-", "1", ",", "-", "padding", "+", "rf", "-", "1", "]", "\n", "rf_boxes", "=", "stride", "*", "point_boxes", "+", "torch", ".", "FloatTensor", "(", "bias", ")", "\n", "return", "rf_boxes", "\n", "\n"]], "home.repos.pwc.inspect_result.ahmedest61_multires-netvlad.models.local_matcher.calc_keypoint_centers_from_patches": [[76, 117], ["int", "int", "int", "int", "local_matcher.calc_receptive_boxes", "numpy.zeros", "numpy.zeros", "range", "int", "int", "int", "int", "range", "int", "int"], "function", ["home.repos.pwc.inspect_result.ahmedest61_multires-netvlad.models.local_matcher.calc_receptive_boxes"], ["", "def", "calc_keypoint_centers_from_patches", "(", "config", ",", "patch_size_h", ",", "patch_size_w", ",", "stride_h", ",", "stride_w", ")", ":", "\n", "    ", "'''Calculate patch positions in image space\n\n    Args:\n        config: feature_match config data\n        patch_size_h: height of patches\n        patch_size_w: width of patches\n        stride_h: stride in vertical direction between patches\n        stride_w: stride in horizontal direction between patches\n\n    :returns\n        keypoints: patch positions back in image space for RANSAC\n        indices: 2-D patch positions for rapid spatial scoring\n    '''", "\n", "\n", "H", "=", "int", "(", "int", "(", "config", "[", "'imageresizeH'", "]", ")", "/", "16", ")", "# 16 is the vgg scaling from image space to feature space (conv5)", "\n", "W", "=", "int", "(", "int", "(", "config", "[", "'imageresizeW'", "]", ")", "/", "16", ")", "\n", "padding_size", "=", "[", "0", ",", "0", "]", "\n", "patch_size", "=", "(", "int", "(", "patch_size_h", ")", ",", "int", "(", "patch_size_w", ")", ")", "\n", "stride", "=", "(", "int", "(", "stride_h", ")", ",", "int", "(", "stride_w", ")", ")", "\n", "\n", "Hout", "=", "int", "(", "(", "H", "+", "(", "2", "*", "padding_size", "[", "0", "]", ")", "-", "patch_size", "[", "0", "]", ")", "/", "stride", "[", "0", "]", "+", "1", ")", "\n", "Wout", "=", "int", "(", "(", "W", "+", "(", "2", "*", "padding_size", "[", "1", "]", ")", "-", "patch_size", "[", "1", "]", ")", "/", "stride", "[", "1", "]", "+", "1", ")", "\n", "\n", "boxes", "=", "calc_receptive_boxes", "(", "H", ",", "W", ")", "\n", "\n", "num_regions", "=", "Hout", "*", "Wout", "\n", "\n", "k", "=", "0", "\n", "indices", "=", "np", ".", "zeros", "(", "(", "2", ",", "num_regions", ")", ",", "dtype", "=", "int", ")", "\n", "keypoints", "=", "np", ".", "zeros", "(", "(", "2", ",", "num_regions", ")", ",", "dtype", "=", "int", ")", "\n", "# Assuming sensible values for stride here, may get errors with large stride values", "\n", "for", "i", "in", "range", "(", "0", ",", "Hout", ",", "stride_h", ")", ":", "\n", "        ", "for", "j", "in", "range", "(", "0", ",", "Wout", ",", "stride_w", ")", ":", "\n", "            ", "keypoints", "[", "0", ",", "k", "]", "=", "(", "(", "boxes", "[", "j", "+", "(", "i", "*", "W", ")", ",", "0", "]", "+", "boxes", "[", "(", "j", "+", "(", "patch_size", "[", "1", "]", "-", "1", ")", ")", "+", "(", "i", "*", "W", ")", ",", "2", "]", ")", "/", "2", ")", "\n", "keypoints", "[", "1", ",", "k", "]", "=", "(", "(", "boxes", "[", "j", "+", "(", "i", "*", "W", ")", ",", "1", "]", "+", "boxes", "[", "j", "+", "(", "(", "i", "+", "(", "patch_size", "[", "0", "]", "-", "1", ")", ")", "*", "W", ")", ",", "3", "]", ")", "/", "2", ")", "\n", "indices", "[", "0", ",", "k", "]", "=", "j", "\n", "indices", "[", "1", ",", "k", "]", "=", "i", "\n", "k", "+=", "1", "\n", "\n", "", "", "return", "keypoints", ",", "indices", "\n", "\n"]], "home.repos.pwc.inspect_result.ahmedest61_multires-netvlad.models.local_matcher.normalise_func": [[119, 127], ["range", "len", "ValueError", "numpy.std", "numpy.mean"], "function", ["None"], ["", "def", "normalise_func", "(", "input_diff", ",", "num_patches", ",", "patch_weights", ")", ":", "\n", "    ", "normed_diff", "=", "0", "\n", "if", "len", "(", "patch_weights", ")", "!=", "num_patches", ":", "\n", "        ", "raise", "ValueError", "(", "'The number of patch weights must equal the number of patches used'", ")", "\n", "", "for", "i", "in", "range", "(", "num_patches", ")", ":", "\n", "        ", "normed_diff", "=", "normed_diff", "+", "patch_weights", "[", "i", "]", "*", "(", "\n", "(", "input_diff", "[", ":", ",", "i", "]", "-", "np", ".", "mean", "(", "input_diff", "[", ":", ",", "i", "]", ")", ")", "/", "np", ".", "std", "(", "input_diff", "[", ":", ",", "i", "]", ")", ")", "\n", "", "return", "normed_diff", "\n", "\n"]], "home.repos.pwc.inspect_result.ahmedest61_multires-netvlad.models.local_matcher.local_matcher": [[129, 172], ["numpy.array().astype", "zip", "patchnetvlad.tools.patch_matcher.PatchMatcher", "enumerate", "int", "int", "local_matcher.calc_keypoint_centers_from_patches", "all_keypoints.append", "all_indices.append", "tqdm.auto.tqdm", "numpy.zeros", "enumerate", "local_matcher.normalise_func", "numpy.argsort", "reordered_preds.append", "[].split", "[].split", "numpy.array", "os.path.splitext", "qfeat.append", "patchnetvlad.tools.patch_matcher.PatchMatcher.match", "len", "[].split", "len", "os.path.basename", "torch.transpose", "os.path.splitext", "dbfeat.append", "torch.tensor", "os.path.basename", "torch.tensor", "numpy.load", "numpy.load"], "function", ["home.repos.pwc.inspect_result.ahmedest61_multires-netvlad.models.local_matcher.calc_keypoint_centers_from_patches", "home.repos.pwc.inspect_result.ahmedest61_multires-netvlad.models.local_matcher.normalise_func", "home.repos.pwc.inspect_result.ahmedest61_multires-netvlad.tools.patch_matcher.PatchMatcher.match"], ["", "def", "local_matcher", "(", "predictions", ",", "eval_set", ",", "input_query_local_features_prefix", ",", "\n", "input_index_local_features_prefix", ",", "config", ",", "device", ")", ":", "\n", "\n", "    ", "patch_sizes", "=", "[", "int", "(", "s", ")", "for", "s", "in", "config", "[", "'global_params'", "]", "[", "'patch_sizes'", "]", ".", "split", "(", "\",\"", ")", "]", "\n", "strides", "=", "[", "int", "(", "s", ")", "for", "s", "in", "config", "[", "'global_params'", "]", "[", "'strides'", "]", ".", "split", "(", "\",\"", ")", "]", "\n", "patch_weights", "=", "np", ".", "array", "(", "config", "[", "'feature_match'", "]", "[", "'patchWeights2Use'", "]", ".", "split", "(", "\",\"", ")", ")", ".", "astype", "(", "float", ")", "\n", "\n", "all_keypoints", "=", "[", "]", "\n", "all_indices", "=", "[", "]", "\n", "\n", "for", "patch_size", ",", "stride", "in", "zip", "(", "patch_sizes", ",", "strides", ")", ":", "\n", "# we currently only provide support for square patches, but this can be easily modified for future works", "\n", "        ", "keypoints", ",", "indices", "=", "calc_keypoint_centers_from_patches", "(", "config", "[", "'feature_match'", "]", ",", "patch_size", ",", "patch_size", ",", "stride", ",", "stride", ")", "\n", "all_keypoints", ".", "append", "(", "keypoints", ")", "\n", "all_indices", ".", "append", "(", "indices", ")", "\n", "\n", "", "reordered_preds", "=", "[", "]", "\n", "\n", "matcher", "=", "PatchMatcher", "(", "config", "[", "'feature_match'", "]", "[", "'matcher'", "]", ",", "patch_sizes", ",", "strides", ",", "all_keypoints", ",", "\n", "all_indices", ")", "\n", "\n", "for", "q_idx", ",", "pred", "in", "enumerate", "(", "tqdm", "(", "predictions", ",", "leave", "=", "False", ",", "desc", "=", "'Patch compare pred'", ")", ")", ":", "\n", "        ", "diffs", "=", "np", ".", "zeros", "(", "(", "predictions", ".", "shape", "[", "1", "]", ",", "len", "(", "patch_sizes", ")", ")", ")", "\n", "image_name_query", "=", "os", ".", "path", ".", "splitext", "(", "os", ".", "path", ".", "basename", "(", "eval_set", ".", "images", "[", "eval_set", ".", "numDb", "+", "q_idx", "]", ")", ")", "[", "0", "]", "\n", "qfeat", "=", "[", "]", "\n", "for", "patch_size", "in", "patch_sizes", ":", "\n", "            ", "qfilename", "=", "input_query_local_features_prefix", "+", "'_'", "+", "'psize{}_'", ".", "format", "(", "patch_size", ")", "+", "image_name_query", "+", "'.npy'", "\n", "qfeat", ".", "append", "(", "torch", ".", "transpose", "(", "torch", ".", "tensor", "(", "np", ".", "load", "(", "qfilename", ")", ",", "device", "=", "device", ")", ",", "0", ",", "1", ")", ")", "\n", "# we pre-transpose here to save compute speed", "\n", "", "for", "k", ",", "candidate", "in", "enumerate", "(", "pred", ")", ":", "\n", "            ", "image_name_index", "=", "os", ".", "path", ".", "splitext", "(", "os", ".", "path", ".", "basename", "(", "eval_set", ".", "images", "[", "candidate", "]", ")", ")", "[", "0", "]", "\n", "dbfeat", "=", "[", "]", "\n", "for", "patch_size", "in", "patch_sizes", ":", "\n", "                ", "dbfilename", "=", "input_index_local_features_prefix", "+", "'_'", "+", "'psize{}_'", ".", "format", "(", "patch_size", ")", "+", "image_name_index", "+", "'.npy'", "\n", "dbfeat", ".", "append", "(", "torch", ".", "tensor", "(", "np", ".", "load", "(", "dbfilename", ")", ",", "device", "=", "device", ")", ")", "\n", "\n", "", "diffs", "[", "k", ",", ":", "]", ",", "_", ",", "_", "=", "matcher", ".", "match", "(", "qfeat", ",", "dbfeat", ")", "\n", "\n", "", "diffs", "=", "normalise_func", "(", "diffs", ",", "len", "(", "patch_sizes", ")", ",", "patch_weights", ")", "\n", "cand_sorted", "=", "np", ".", "argsort", "(", "diffs", ")", "\n", "reordered_preds", ".", "append", "(", "pred", "[", "cand_sorted", "]", ")", "\n", "\n", "", "return", "reordered_preds", "\n", "", ""]], "home.repos.pwc.inspect_result.ahmedest61_multires-netvlad.models.patchnetvlad.PatchNetVLAD.__init__": [[75, 112], ["torch.Module.__init__", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Parameter", "torch.Parameter", "torch.Parameter", "patch_sizes.split.split.split", "strides.split.split.split", "zip", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "patchnetvlad.PatchNetVLAD.patch_sizes.append", "patchnetvlad.PatchNetVLAD.strides.append", "int", "int"], "methods", ["home.repos.pwc.inspect_result.ahmedest61_multires-netvlad.training_tools.msls.MSLS.__init__"], ["def", "__init__", "(", "self", ",", "num_clusters", "=", "64", ",", "dim", "=", "128", ",", "normalize_input", "=", "True", ",", "vladv2", "=", "False", ",", "use_faiss", "=", "True", ",", "\n", "patch_sizes", "=", "'4'", ",", "strides", "=", "'1'", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            num_clusters : int\n                The number of clusters\n            dim : int\n                Dimension of descriptors\n            normalize_input : bool\n                If true, descriptor-wise L2 normalization is applied to input.\n            vladv2 : bool\n                If true, use vladv2 otherwise use vladv1\n            use_faiss: bool\n                Default true, if false don't use faiss for similarity search\n            patch_sizes: string\n                comma separated string of patch sizes\n            strides: string\n                comma separated string of strides (for patch aggregation)\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "num_clusters", "=", "num_clusters", "\n", "self", ".", "dim", "=", "dim", "\n", "self", ".", "alpha", "=", "0", "\n", "self", ".", "vladv2", "=", "vladv2", "\n", "self", ".", "normalize_input", "=", "normalize_input", "\n", "self", ".", "conv", "=", "nn", ".", "Conv2d", "(", "dim", ",", "num_clusters", ",", "kernel_size", "=", "(", "1", ",", "1", ")", ",", "bias", "=", "vladv2", ")", "\n", "# noinspection PyArgumentList", "\n", "self", ".", "centroids", "=", "nn", ".", "Parameter", "(", "torch", ".", "rand", "(", "num_clusters", ",", "dim", ")", ")", "\n", "self", ".", "use_faiss", "=", "use_faiss", "\n", "self", ".", "padding_size", "=", "0", "\n", "patch_sizes", "=", "patch_sizes", ".", "split", "(", "\",\"", ")", "\n", "strides", "=", "strides", ".", "split", "(", "\",\"", ")", "\n", "self", ".", "patch_sizes", "=", "[", "]", "\n", "self", ".", "strides", "=", "[", "]", "\n", "for", "patch_size", ",", "stride", "in", "zip", "(", "patch_sizes", ",", "strides", ")", ":", "\n", "            ", "self", ".", "patch_sizes", ".", "append", "(", "int", "(", "patch_size", ")", ")", "\n", "self", ".", "strides", ".", "append", "(", "int", "(", "stride", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ahmedest61_multires-netvlad.models.patchnetvlad.PatchNetVLAD.init_params": [[113, 154], ["numpy.dot", "numpy.dot.sort", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "numpy.linalg.norm", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy().unsqueeze().unsqueeze", "torch.from_numpy().unsqueeze().unsqueeze", "torch.from_numpy().unsqueeze().unsqueeze", "torch.from_numpy().unsqueeze().unsqueeze", "torch.from_numpy().unsqueeze().unsqueeze", "torch.from_numpy().unsqueeze().unsqueeze", "torch.from_numpy().unsqueeze().unsqueeze", "torch.from_numpy().unsqueeze().unsqueeze", "torch.from_numpy().unsqueeze().unsqueeze", "sklearn.neighbors.NearestNeighbors", "sklearn.neighbors.NearestNeighbors.fit", "numpy.square", "faiss.IndexFlatL2", "faiss.IndexFlatL2.add", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "faiss.IndexFlatL2.search", "patchnetvlad.PatchNetVLAD.centroids.norm", "numpy.mean", "torch.from_numpy().unsqueeze", "torch.from_numpy().unsqueeze", "torch.from_numpy().unsqueeze", "torch.from_numpy().unsqueeze", "torch.from_numpy().unsqueeze", "torch.from_numpy().unsqueeze", "torch.from_numpy().unsqueeze", "torch.from_numpy().unsqueeze", "torch.from_numpy().unsqueeze", "sklearn.neighbors.NearestNeighbors.kneighbors", "numpy.mean", "numpy.log", "numpy.log", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy"], "methods", ["None"], ["", "", "def", "init_params", "(", "self", ",", "clsts", ",", "traindescs", ")", ":", "\n", "        ", "if", "not", "self", ".", "vladv2", ":", "\n", "            ", "clsts_assign", "=", "clsts", "/", "np", ".", "linalg", ".", "norm", "(", "clsts", ",", "axis", "=", "1", ",", "keepdims", "=", "True", ")", "\n", "dots", "=", "np", ".", "dot", "(", "clsts_assign", ",", "traindescs", ".", "T", ")", "\n", "dots", ".", "sort", "(", "0", ")", "\n", "dots", "=", "dots", "[", ":", ":", "-", "1", ",", ":", "]", "# sort, descending", "\n", "\n", "self", ".", "alpha", "=", "(", "-", "np", ".", "log", "(", "0.01", ")", "/", "np", ".", "mean", "(", "dots", "[", "0", ",", ":", "]", "-", "dots", "[", "1", ",", ":", "]", ")", ")", ".", "item", "(", ")", "\n", "# noinspection PyArgumentList", "\n", "self", ".", "centroids", "=", "nn", ".", "Parameter", "(", "torch", ".", "from_numpy", "(", "clsts", ")", ")", "\n", "# noinspection PyArgumentList", "\n", "self", ".", "conv", ".", "weight", "=", "nn", ".", "Parameter", "(", "torch", ".", "from_numpy", "(", "self", ".", "alpha", "*", "clsts_assign", ")", ".", "unsqueeze", "(", "2", ")", ".", "unsqueeze", "(", "3", ")", ")", "\n", "self", ".", "conv", ".", "bias", "=", "None", "\n", "", "else", ":", "\n", "            ", "if", "not", "self", ".", "use_faiss", ":", "\n", "                ", "knn", "=", "NearestNeighbors", "(", "n_jobs", "=", "-", "1", ")", "\n", "knn", ".", "fit", "(", "traindescs", ")", "\n", "del", "traindescs", "\n", "ds_sq", "=", "np", ".", "square", "(", "knn", ".", "kneighbors", "(", "clsts", ",", "2", ")", "[", "1", "]", ")", "\n", "del", "knn", "\n", "", "else", ":", "\n", "                ", "index", "=", "faiss", ".", "IndexFlatL2", "(", "traindescs", ".", "shape", "[", "1", "]", ")", "\n", "# noinspection PyArgumentList", "\n", "index", ".", "add", "(", "traindescs", ")", "\n", "del", "traindescs", "\n", "# noinspection PyArgumentList", "\n", "ds_sq", "=", "index", ".", "search", "(", "clsts", ",", "2", ")", "[", "1", "]", "\n", "del", "index", "\n", "\n", "", "self", ".", "alpha", "=", "(", "-", "np", ".", "log", "(", "0.01", ")", "/", "np", ".", "mean", "(", "ds_sq", "[", ":", ",", "1", "]", "-", "ds_sq", "[", ":", ",", "0", "]", ")", ")", ".", "item", "(", ")", "\n", "# noinspection PyArgumentList", "\n", "self", ".", "centroids", "=", "nn", ".", "Parameter", "(", "torch", ".", "from_numpy", "(", "clsts", ")", ")", "\n", "del", "clsts", ",", "ds_sq", "\n", "\n", "# noinspection PyArgumentList", "\n", "self", ".", "conv", ".", "weight", "=", "nn", ".", "Parameter", "(", "\n", "(", "2.0", "*", "self", ".", "alpha", "*", "self", ".", "centroids", ")", ".", "unsqueeze", "(", "-", "1", ")", ".", "unsqueeze", "(", "-", "1", ")", "\n", ")", "\n", "# noinspection PyArgumentList", "\n", "self", ".", "conv", ".", "bias", "=", "nn", ".", "Parameter", "(", "\n", "-", "self", ".", "alpha", "*", "self", ".", "centroids", ".", "norm", "(", "dim", "=", "1", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.ahmedest61_multires-netvlad.models.patchnetvlad.PatchNetVLAD.forward": [[156, 197], ["patchnetvlad.PatchNetVLAD.conv().view", "torch.softmax", "torch.softmax", "torch.softmax", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "range", "store_residual.view.view.view", "torch.normalize.sum", "store_residual.view.view.view", "patchnetvlad.get_integral_feature", "zip", "torch.normalize", "torch.normalize", "torch.normalize", "torch.normalize.view", "torch.normalize", "torch.normalize", "torch.normalize", "torch.normalize", "torch.normalize", "torch.normalize", "soft_assign[].unsqueeze", "vladflattened.append", "torch.normalize.view", "torch.normalize", "torch.normalize", "torch.normalize", "torch.normalize.view", "torch.normalize", "torch.normalize", "torch.normalize", "vlad_local.append", "torch.normalize.size", "patchnetvlad.PatchNetVLAD.conv", "torch.normalize.unsqueeze().permute", "patchnetvlad.PatchNetVLAD.centroids[].expand().permute().unsqueeze", "patchnetvlad.get_square_regions_from_integral", "torch.normalize.size", "torch.normalize.size", "int", "int", "torch.normalize.unsqueeze", "patchnetvlad.PatchNetVLAD.centroids[].expand().permute", "patchnetvlad.PatchNetVLAD.centroids[].expand", "torch.normalize.size", "torch.normalize.size"], "methods", ["home.repos.pwc.inspect_result.ahmedest61_multires-netvlad.models.patchnetvlad.get_integral_feature", "home.repos.pwc.inspect_result.ahmedest61_multires-netvlad.models.patchnetvlad.get_square_regions_from_integral"], ["", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "N", ",", "C", ",", "H", ",", "W", "=", "x", ".", "shape", "\n", "\n", "if", "self", ".", "normalize_input", ":", "\n", "            ", "x", "=", "F", ".", "normalize", "(", "x", ",", "p", "=", "2", ",", "dim", "=", "1", ")", "# across descriptor dim", "\n", "\n", "# soft-assignment", "\n", "", "soft_assign", "=", "self", ".", "conv", "(", "x", ")", ".", "view", "(", "N", ",", "self", ".", "num_clusters", ",", "H", ",", "W", ")", "\n", "soft_assign", "=", "F", ".", "softmax", "(", "soft_assign", ",", "dim", "=", "1", ")", "\n", "\n", "# calculate residuals to each cluster", "\n", "store_residual", "=", "torch", ".", "zeros", "(", "[", "N", ",", "self", ".", "num_clusters", ",", "C", ",", "H", ",", "W", "]", ",", "dtype", "=", "x", ".", "dtype", ",", "layout", "=", "x", ".", "layout", ",", "device", "=", "x", ".", "device", ")", "\n", "for", "j", "in", "range", "(", "self", ".", "num_clusters", ")", ":", "# slower than non-looped, but lower memory usage", "\n", "            ", "residual", "=", "x", ".", "unsqueeze", "(", "0", ")", ".", "permute", "(", "1", ",", "0", ",", "2", ",", "3", ",", "4", ")", "-", "self", ".", "centroids", "[", "j", ":", "j", "+", "1", ",", ":", "]", ".", "expand", "(", "x", ".", "size", "(", "2", ")", ",", "x", ".", "size", "(", "3", ")", ",", "-", "1", ",", "-", "1", ")", ".", "permute", "(", "2", ",", "3", ",", "0", ",", "1", ")", ".", "unsqueeze", "(", "0", ")", "\n", "\n", "residual", "*=", "soft_assign", "[", ":", ",", "j", ":", "j", "+", "1", ",", ":", "]", ".", "unsqueeze", "(", "2", ")", "# residual should be size [N K C H W]", "\n", "store_residual", "[", ":", ",", "j", ":", "j", "+", "1", ",", ":", ",", ":", ",", ":", "]", "=", "residual", "\n", "\n", "", "vlad_global", "=", "store_residual", ".", "view", "(", "N", ",", "self", ".", "num_clusters", ",", "C", ",", "-", "1", ")", "\n", "vlad_global", "=", "vlad_global", ".", "sum", "(", "dim", "=", "-", "1", ")", "\n", "store_residual", "=", "store_residual", ".", "view", "(", "N", ",", "-", "1", ",", "H", ",", "W", ")", "\n", "\n", "ivlad", "=", "get_integral_feature", "(", "store_residual", ")", "\n", "vladflattened", "=", "[", "]", "\n", "for", "patch_size", ",", "stride", "in", "zip", "(", "self", ".", "patch_sizes", ",", "self", ".", "strides", ")", ":", "\n", "            ", "vladflattened", ".", "append", "(", "get_square_regions_from_integral", "(", "ivlad", ",", "int", "(", "patch_size", ")", ",", "int", "(", "stride", ")", ")", ")", "\n", "\n", "", "vlad_local", "=", "[", "]", "\n", "for", "thisvlad", "in", "vladflattened", ":", "# looped to avoid GPU memory issues with certain config combinations", "\n", "            ", "thisvlad", "=", "thisvlad", ".", "view", "(", "N", ",", "self", ".", "num_clusters", ",", "C", ",", "-", "1", ")", "\n", "thisvlad", "=", "F", ".", "normalize", "(", "thisvlad", ",", "p", "=", "2", ",", "dim", "=", "2", ")", "\n", "thisvlad", "=", "thisvlad", ".", "view", "(", "x", ".", "size", "(", "0", ")", ",", "-", "1", ",", "thisvlad", ".", "size", "(", "3", ")", ")", "\n", "thisvlad", "=", "F", ".", "normalize", "(", "thisvlad", ",", "p", "=", "2", ",", "dim", "=", "1", ")", "\n", "vlad_local", ".", "append", "(", "thisvlad", ")", "\n", "\n", "", "vlad_global", "=", "F", ".", "normalize", "(", "vlad_global", ",", "p", "=", "2", ",", "dim", "=", "2", ")", "\n", "vlad_global", "=", "vlad_global", ".", "view", "(", "x", ".", "size", "(", "0", ")", ",", "-", "1", ")", "\n", "vlad_global", "=", "F", ".", "normalize", "(", "vlad_global", ",", "p", "=", "2", ",", "dim", "=", "1", ")", "\n", "\n", "return", "vlad_local", ",", "vlad_global", "# vlad_local is a list of tensors", "\n", "", "", ""]], "home.repos.pwc.inspect_result.ahmedest61_multires-netvlad.models.patchnetvlad.get_integral_feature": [[44, 53], ["torch.cumsum", "torch.cumsum", "torch.cumsum", "torch.cumsum", "torch.cumsum", "torch.cumsum", "torch.nn.functional.pad", "torch.nn.functional.pad", "torch.nn.functional.pad"], "function", ["None"], ["def", "get_integral_feature", "(", "feat_in", ")", ":", "\n", "    ", "\"\"\"\n    Input/Output as [N,D,H,W] where N is batch size and D is descriptor dimensions\n    For VLAD, D = K x d where K is the number of clusters and d is the original descriptor dimensions\n    \"\"\"", "\n", "feat_out", "=", "torch", ".", "cumsum", "(", "feat_in", ",", "dim", "=", "-", "1", ")", "\n", "feat_out", "=", "torch", ".", "cumsum", "(", "feat_out", ",", "dim", "=", "-", "2", ")", "\n", "feat_out", "=", "torch", ".", "nn", ".", "functional", ".", "pad", "(", "feat_out", ",", "(", "1", ",", "0", ",", "1", ",", "0", ")", ",", "\"constant\"", ",", "0", ")", "\n", "return", "feat_out", "\n", "\n"]], "home.repos.pwc.inspect_result.ahmedest61_multires-netvlad.models.patchnetvlad.get_square_regions_from_integral": [[55, 70], ["torch.nn.functional.conv2d", "torch.nn.functional.conv2d", "torch.nn.functional.conv2d", "feat_integral.get_device", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "feat_integral.get_device"], "function", ["None"], ["", "def", "get_square_regions_from_integral", "(", "feat_integral", ",", "patch_size", ",", "patch_stride", ")", ":", "\n", "    ", "\"\"\"\n    Input as [N,D,H+1,W+1] where additional 1s for last two axes are zero paddings\n    regSize and regStride are single values as only square regions are implemented currently\n    \"\"\"", "\n", "N", ",", "D", ",", "H", ",", "W", "=", "feat_integral", ".", "shape", "\n", "\n", "if", "feat_integral", ".", "get_device", "(", ")", "==", "-", "1", ":", "\n", "        ", "conv_weight", "=", "torch", ".", "ones", "(", "D", ",", "1", ",", "2", ",", "2", ")", "\n", "", "else", ":", "\n", "        ", "conv_weight", "=", "torch", ".", "ones", "(", "D", ",", "1", ",", "2", ",", "2", ",", "device", "=", "feat_integral", ".", "get_device", "(", ")", ")", "\n", "", "conv_weight", "[", ":", ",", ":", ",", "0", ",", "-", "1", "]", "=", "-", "1", "\n", "conv_weight", "[", ":", ",", ":", ",", "-", "1", ",", "0", "]", "=", "-", "1", "\n", "feat_regions", "=", "torch", ".", "nn", ".", "functional", ".", "conv2d", "(", "feat_integral", ",", "conv_weight", ",", "stride", "=", "patch_stride", ",", "groups", "=", "D", ",", "dilation", "=", "patch_size", ")", "\n", "return", "feat_regions", "/", "(", "patch_size", "**", "2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ahmedest61_multires-netvlad.models.models_generic.Flatten.forward": [[33, 35], ["input_data.view", "input_data.size"], "methods", ["None"], ["    ", "def", "forward", "(", "self", ",", "input_data", ")", ":", "\n", "        ", "return", "input_data", ".", "view", "(", "input_data", ".", "size", "(", "0", ")", ",", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ahmedest61_multires-netvlad.models.models_generic.L2Norm.__init__": [[38, 41], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.ahmedest61_multires-netvlad.training_tools.msls.MSLS.__init__"], ["    ", "def", "__init__", "(", "self", ",", "dim", "=", "1", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dim", "=", "dim", "\n", "\n"]], "home.repos.pwc.inspect_result.ahmedest61_multires-netvlad.models.models_generic.L2Norm.forward": [[42, 44], ["torch.normalize", "torch.normalize"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input_data", ")", ":", "\n", "        ", "return", "F", ".", "normalize", "(", "input_data", ",", "p", "=", "2", ",", "dim", "=", "self", ".", "dim", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ahmedest61_multires-netvlad.models.models_generic.get_pca_encoding": [[46, 49], ["model.WPCA", "vlad_encoding.unsqueeze().unsqueeze", "vlad_encoding.unsqueeze"], "function", ["None"], ["", "", "def", "get_pca_encoding", "(", "model", ",", "vlad_encoding", ")", ":", "\n", "    ", "pca_encoding", "=", "model", ".", "WPCA", "(", "vlad_encoding", ".", "unsqueeze", "(", "-", "1", ")", ".", "unsqueeze", "(", "-", "1", ")", ")", "\n", "return", "pca_encoding", "\n", "\n"]], "home.repos.pwc.inspect_result.ahmedest61_multires-netvlad.models.models_generic.get_backend": [[51, 65], ["torchvision.vgg16", "torch.Sequential", "int", "list", "l.parameters", "models.vgg16.features.children", "arch.split"], "function", ["None"], ["", "def", "get_backend", "(", "arch", ",", "trim", ")", ":", "\n", "    ", "if", "'vgg16'", "in", "arch", ":", "\n", "        ", "reqGradLayer", "=", "int", "(", "arch", ".", "split", "(", "'-'", ")", "[", "1", "]", ")", "*", "-", "1", "\n", "encoder", "=", "models", ".", "vgg16", "(", "pretrained", "=", "True", ")", "\n", "# capture only feature part and remove last relu and maxpool", "\n", "layers", "=", "list", "(", "encoder", ".", "features", ".", "children", "(", ")", ")", "[", ":", "trim", "]", "\n", "enc_dim", "=", "layers", "[", "-", "1", "]", ".", "out_channels", "\n", "# if using pretrained then only train conv5_1, conv5_2, and conv5_3", "\n", "for", "l", "in", "layers", "[", ":", "reqGradLayer", "]", ":", "\n", "            ", "for", "p", "in", "l", ".", "parameters", "(", ")", ":", "\n", "                ", "p", ".", "requires_grad", "=", "False", "\n", "", "", "enc", "=", "nn", ".", "Sequential", "(", "*", "layers", ")", "\n", "\n", "", "return", "enc_dim", ",", "enc", "\n", "\n"]], "home.repos.pwc.inspect_result.ahmedest61_multires-netvlad.models.models_generic.get_model": [[66, 99], ["torch.Module", "nn.Module.add_module", "config[].lower", "patchnetvlad.models.netvlad.NetVLAD", "nn.Module.add_module", "int", "torch.Conv2d", "nn.Module.add_module", "config[].lower", "patchnetvlad.models.patchnetvlad.PatchNetVLAD", "nn.Module.add_module", "int", "torch.Sequential", "int", "config.getboolean", "config[].lower", "torch.AdaptiveMaxPool2d", "nn.Module.add_module", "config[].lower", "config[].lower", "int", "config.getboolean", "torch.Sequential", "config[].pooling.lower", "torch.AdaptiveAvgPool2d", "nn.Module.add_module", "ValueError", "torch.Sequential", "models_generic.Flatten", "models_generic.L2Norm", "config[].lower", "models_generic.Flatten", "models_generic.L2Norm", "models_generic.Flatten", "models_generic.L2Norm"], "function", ["None"], ["", "def", "get_model", "(", "encoder", ",", "encoder_dim", ",", "config", ",", "append_pca_layer", "=", "False", ")", ":", "\n", "# config['global_params'] is passed as config", "\n", "    ", "nn_model", "=", "nn", ".", "Module", "(", ")", "\n", "nn_model", ".", "add_module", "(", "'encoder'", ",", "encoder", ")", "\n", "\n", "if", "config", "[", "'pooling'", "]", ".", "lower", "(", ")", "==", "'netvlad'", ":", "\n", "        ", "net_vlad", "=", "NetVLAD", "(", "num_clusters", "=", "int", "(", "config", "[", "'num_clusters'", "]", ")", ",", "dim", "=", "encoder_dim", ",", "\n", "vladv2", "=", "config", ".", "getboolean", "(", "'vladv2'", ")", ")", "\n", "nn_model", ".", "add_module", "(", "'pool'", ",", "net_vlad", ")", "\n", "", "elif", "config", "[", "'pooling'", "]", ".", "lower", "(", ")", "==", "'patchnetvlad'", ":", "\n", "        ", "net_vlad", "=", "PatchNetVLAD", "(", "num_clusters", "=", "int", "(", "config", "[", "'num_clusters'", "]", ")", ",", "dim", "=", "encoder_dim", ",", "\n", "vladv2", "=", "config", ".", "getboolean", "(", "'vladv2'", ")", ",", "\n", "patch_sizes", "=", "config", "[", "'patch_sizes'", "]", ",", "strides", "=", "config", "[", "'strides'", "]", ")", "\n", "nn_model", ".", "add_module", "(", "'pool'", ",", "net_vlad", ")", "\n", "", "elif", "config", "[", "'pooling'", "]", ".", "lower", "(", ")", "==", "'max'", ":", "\n", "        ", "global_pool", "=", "nn", ".", "AdaptiveMaxPool2d", "(", "(", "1", ",", "1", ")", ")", "\n", "nn_model", ".", "add_module", "(", "'pool'", ",", "nn", ".", "Sequential", "(", "*", "[", "global_pool", ",", "Flatten", "(", ")", ",", "L2Norm", "(", ")", "]", ")", ")", "\n", "", "elif", "config", "[", "'pooling'", "]", ".", "pooling", ".", "lower", "(", ")", "==", "'avg'", ":", "\n", "        ", "global_pool", "=", "nn", ".", "AdaptiveAvgPool2d", "(", "(", "1", ",", "1", ")", ")", "\n", "nn_model", ".", "add_module", "(", "'pool'", ",", "nn", ".", "Sequential", "(", "*", "[", "global_pool", ",", "Flatten", "(", ")", ",", "L2Norm", "(", ")", "]", ")", ")", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "'Unknown pooling type: '", "+", "config", "[", "'pooling'", "]", ".", "lower", "(", ")", ")", "\n", "\n", "", "if", "append_pca_layer", ":", "\n", "        ", "num_pcs", "=", "int", "(", "config", "[", "'num_pcs'", "]", ")", "\n", "netvlad_output_dim", "=", "encoder_dim", "\n", "if", "config", "[", "'pooling'", "]", ".", "lower", "(", ")", "==", "'netvlad'", "or", "config", "[", "'pooling'", "]", ".", "lower", "(", ")", "==", "'patchnetvlad'", ":", "\n", "            ", "netvlad_output_dim", "*=", "int", "(", "config", "[", "'num_clusters'", "]", ")", "\n", "\n", "", "pca_conv", "=", "nn", ".", "Conv2d", "(", "netvlad_output_dim", ",", "num_pcs", ",", "kernel_size", "=", "(", "1", ",", "1", ")", ",", "stride", "=", "1", ",", "padding", "=", "0", ")", "\n", "nn_model", ".", "add_module", "(", "'WPCA'", ",", "nn", ".", "Sequential", "(", "*", "[", "pca_conv", ",", "Flatten", "(", ")", ",", "L2Norm", "(", "dim", "=", "-", "1", ")", "]", ")", ")", "\n", "\n", "", "return", "nn_model", "\n", "", ""]], "home.repos.pwc.inspect_result.ahmedest61_multires-netvlad.models.netvlad.NetVLAD.__init__": [[40, 63], ["torch.Module.__init__", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand"], "methods", ["home.repos.pwc.inspect_result.ahmedest61_multires-netvlad.training_tools.msls.MSLS.__init__"], ["dots", ".", "sort", "(", "0", ")", "\n", "dots", "=", "dots", "[", ":", ":", "-", "1", ",", ":", "]", "# sort, descending", "\n", "\n", "self", ".", "alpha", "=", "(", "-", "np", ".", "log", "(", "0.01", ")", "/", "np", ".", "mean", "(", "dots", "[", "0", ",", ":", "]", "-", "dots", "[", "1", ",", ":", "]", ")", ")", ".", "item", "(", ")", "\n", "self", ".", "centroids", "=", "nn", ".", "Parameter", "(", "torch", ".", "from_numpy", "(", "clsts", ")", ")", "\n", "self", ".", "conv", ".", "weight", "=", "nn", ".", "Parameter", "(", "torch", ".", "from_numpy", "(", "self", ".", "alpha", "*", "clstsAssign", ")", ".", "unsqueeze", "(", "2", ")", ".", "unsqueeze", "(", "3", ")", ")", "\n", "self", ".", "conv", ".", "bias", "=", "None", "\n", "", "else", ":", "\n", "            ", "knn", "=", "faiss", ".", "IndexFlatL2", "(", "traindescs", ".", "shape", "[", "1", "]", ")", "\n", "knn", ".", "add", "(", "traindescs", ")", "\n", "del", "traindescs", "\n", "dsSq", "=", "np", ".", "square", "(", "knn", ".", "search", "(", "clsts", ",", "2", ")", "[", "1", "]", ")", "\n", "del", "knn", "\n", "self", ".", "alpha", "=", "(", "-", "np", ".", "log", "(", "0.01", ")", "/", "np", ".", "mean", "(", "dsSq", "[", ":", ",", "1", "]", "-", "dsSq", "[", ":", ",", "0", "]", ")", ")", ".", "item", "(", ")", "\n", "self", ".", "centroids", "=", "nn", ".", "Parameter", "(", "torch", ".", "from_numpy", "(", "clsts", ")", ")", "\n", "del", "clsts", ",", "dsSq", "\n", "\n", "self", ".", "conv", ".", "weight", "=", "nn", ".", "Parameter", "(", "\n", "(", "2.0", "*", "self", ".", "alpha", "*", "self", ".", "centroids", ")", ".", "unsqueeze", "(", "-", "1", ")", ".", "unsqueeze", "(", "-", "1", ")", "\n", ")", "\n", "self", ".", "conv", ".", "bias", "=", "nn", ".", "Parameter", "(", "\n", "-", "self", ".", "alpha", "*", "self", ".", "centroids", ".", "norm", "(", "dim", "=", "1", ")", "\n", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ahmedest61_multires-netvlad.models.netvlad.NetVLAD.init_params": [[64, 105], ["numpy.dot", "numpy.dot.sort", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "numpy.linalg.norm", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy().unsqueeze().unsqueeze", "torch.from_numpy().unsqueeze().unsqueeze", "torch.from_numpy().unsqueeze().unsqueeze", "torch.from_numpy().unsqueeze().unsqueeze", "torch.from_numpy().unsqueeze().unsqueeze", "torch.from_numpy().unsqueeze().unsqueeze", "torch.from_numpy().unsqueeze().unsqueeze", "torch.from_numpy().unsqueeze().unsqueeze", "torch.from_numpy().unsqueeze().unsqueeze", "sklearn.neighbors.NearestNeighbors", "sklearn.neighbors.NearestNeighbors.fit", "numpy.square", "faiss.IndexFlatL2", "faiss.IndexFlatL2.add", "numpy.square", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "netvlad.NetVLAD.centroids.norm", "numpy.mean", "torch.from_numpy().unsqueeze", "torch.from_numpy().unsqueeze", "torch.from_numpy().unsqueeze", "torch.from_numpy().unsqueeze", "torch.from_numpy().unsqueeze", "torch.from_numpy().unsqueeze", "torch.from_numpy().unsqueeze", "torch.from_numpy().unsqueeze", "torch.from_numpy().unsqueeze", "sklearn.neighbors.NearestNeighbors.kneighbors", "faiss.IndexFlatL2.search", "numpy.mean", "numpy.log", "numpy.log", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "N", ",", "C", "=", "x", ".", "shape", "[", ":", "2", "]", "\n", "\n", "if", "self", ".", "normalize_input", ":", "\n", "            ", "x", "=", "F", ".", "normalize", "(", "x", ",", "p", "=", "2", ",", "dim", "=", "1", ")", "# across descriptor dim", "\n", "\n", "# soft-assignment", "\n", "", "soft_assign", "=", "self", ".", "conv", "(", "x", ")", ".", "view", "(", "N", ",", "self", ".", "num_clusters", ",", "-", "1", ")", "\n", "soft_assign", "=", "F", ".", "softmax", "(", "soft_assign", ",", "dim", "=", "1", ")", "\n", "\n", "x_flatten", "=", "x", ".", "view", "(", "N", ",", "C", ",", "-", "1", ")", "\n", "\n", "# calculate residuals to each clusters", "\n", "vlad", "=", "torch", ".", "zeros", "(", "[", "N", ",", "self", ".", "num_clusters", ",", "C", "]", ",", "dtype", "=", "x", ".", "dtype", ",", "layout", "=", "x", ".", "layout", ",", "device", "=", "x", ".", "device", ")", "\n", "for", "C", "in", "range", "(", "self", ".", "num_clusters", ")", ":", "# slower than non-looped, but lower memory usage ", "\n", "            ", "residual", "=", "x_flatten", ".", "unsqueeze", "(", "0", ")", ".", "permute", "(", "1", ",", "0", ",", "2", ",", "3", ")", "-", "self", ".", "centroids", "[", "C", ":", "C", "+", "1", ",", ":", "]", ".", "expand", "(", "x_flatten", ".", "size", "(", "-", "1", ")", ",", "-", "1", ",", "-", "1", ")", ".", "permute", "(", "1", ",", "2", ",", "0", ")", ".", "unsqueeze", "(", "0", ")", "\n", "residual", "*=", "soft_assign", "[", ":", ",", "C", ":", "C", "+", "1", ",", ":", "]", ".", "unsqueeze", "(", "2", ")", "\n", "vlad", "[", ":", ",", "C", ":", "C", "+", "1", ",", ":", "]", "=", "residual", ".", "sum", "(", "dim", "=", "-", "1", ")", "\n", "\n", "", "vlad", "=", "F", ".", "normalize", "(", "vlad", ",", "p", "=", "2", ",", "dim", "=", "2", ")", "# intra-normalization", "\n", "vlad", "=", "vlad", ".", "view", "(", "x", ".", "size", "(", "0", ")", ",", "-", "1", ")", "# flatten", "\n", "vlad", "=", "F", ".", "normalize", "(", "vlad", ",", "p", "=", "2", ",", "dim", "=", "1", ")", "# L2 normalize", "\n", "\n", "# remove it ", "\n", "#vlad = vlad.view(N,self.num_clusters,-1)", "\n", "#vlad = vlad.unsqueeze(1)", "\n", "return", "vlad", "\n", "", "", ""]], "home.repos.pwc.inspect_result.ahmedest61_multires-netvlad.models.netvlad.NetVLAD.forward": [[107, 132], ["netvlad.NetVLAD.conv().view", "torch.softmax", "torch.softmax", "torch.softmax", "torch.normalize.view", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "range", "torch.normalize", "torch.normalize", "torch.normalize", "torch.normalize.view", "torch.normalize", "torch.normalize", "torch.normalize", "torch.normalize", "torch.normalize", "torch.normalize", "soft_assign[].unsqueeze", "residual.sum", "torch.normalize.size", "netvlad.NetVLAD.conv", "F.normalize.view.unsqueeze().permute", "netvlad.NetVLAD.centroids[].expand().permute().unsqueeze", "F.normalize.view.unsqueeze", "netvlad.NetVLAD.centroids[].expand().permute", "netvlad.NetVLAD.centroids[].expand", "F.normalize.view.size"], "methods", ["None"], []], "home.repos.pwc.inspect_result.ahmedest61_multires-netvlad.training_tools.train_epoch.train_epoch": [[39, 123], ["train_dataset.new_epoch", "tqdm.auto.trange", "tqdm.auto.tqdm.write", "writer.add_scalar", "int", "tqdm.auto.tqdm.write", "train_dataset.update_subcache", "torch.utils.data.DataLoader", "tqdm.auto.tqdm.write", "tqdm.auto.tqdm.write", "model.train", "enumerate", "len", "optimizer.zero_grad", "torch.cuda.empty_cache", "[].lower", "int", "tqdm.auto.tqdm", "torch.sum", "torch.cat", "data_input.to.to", "model.encoder", "model.pool", "torch.split", "optimizer.zero_grad", "enumerate", "torch.sum.float().to", "loss.backward", "optimizer.step", "loss.item", "len", "int", "int", "patchnetvlad.training_tools.tools.humanbytes", "patchnetvlad.training_tools.tools.humanbytes", "range", "tqdm.auto.tqdm.write", "writer.add_scalar", "writer.add_scalar", "tqdm.auto.tqdm.write", "tqdm.auto.tqdm.write", "torch.cuda.memory_allocated", "torch.cuda.memory_cached", "criterion", "torch.sum.float", "patchnetvlad.training_tools.tools.humanbytes", "patchnetvlad.training_tools.tools.humanbytes", "torch.cuda.memory_allocated", "torch.cuda.memory_cached", "torch.sum"], "function", ["home.repos.pwc.inspect_result.ahmedest61_multires-netvlad.training_tools.msls.MSLS.new_epoch", "home.repos.pwc.inspect_result.ahmedest61_multires-netvlad.training_tools.msls.MSLS.update_subcache", "home.repos.pwc.inspect_result.ahmedest61_multires-netvlad.None.main.train", "home.repos.pwc.inspect_result.ahmedest61_multires-netvlad.training_tools.tools.humanbytes", "home.repos.pwc.inspect_result.ahmedest61_multires-netvlad.training_tools.tools.humanbytes", "home.repos.pwc.inspect_result.ahmedest61_multires-netvlad.training_tools.tools.humanbytes", "home.repos.pwc.inspect_result.ahmedest61_multires-netvlad.training_tools.tools.humanbytes"], ["def", "train_epoch", "(", "train_dataset", ",", "model", ",", "optimizer", ",", "criterion", ",", "encoder_dim", ",", "device", ",", "epoch_num", ",", "opt", ",", "config", ",", "writer", ")", ":", "\n", "    ", "if", "device", ".", "type", "==", "'cuda'", ":", "\n", "        ", "cuda", "=", "True", "\n", "", "else", ":", "\n", "        ", "cuda", "=", "False", "\n", "", "train_dataset", ".", "new_epoch", "(", ")", "\n", "\n", "epoch_loss", "=", "0", "\n", "startIter", "=", "1", "# keep track of batch iter across subsets for logging", "\n", "\n", "nBatches", "=", "(", "len", "(", "train_dataset", ".", "qIdx", ")", "+", "int", "(", "config", "[", "'train'", "]", "[", "'batchsize'", "]", ")", "-", "1", ")", "//", "int", "(", "config", "[", "'train'", "]", "[", "'batchsize'", "]", ")", "\n", "\n", "for", "subIter", "in", "trange", "(", "train_dataset", ".", "nCacheSubset", ",", "desc", "=", "'Cache refresh'", ".", "rjust", "(", "15", ")", ",", "position", "=", "1", ")", ":", "\n", "        ", "pool_size", "=", "encoder_dim", "\n", "if", "config", "[", "'global_params'", "]", "[", "'pooling'", "]", ".", "lower", "(", ")", "==", "'netvlad'", ":", "\n", "            ", "pool_size", "*=", "int", "(", "config", "[", "'global_params'", "]", "[", "'num_clusters'", "]", ")", "\n", "\n", "", "tqdm", ".", "write", "(", "'====> Building Cache'", ")", "\n", "train_dataset", ".", "update_subcache", "(", "model", ",", "pool_size", ")", "\n", "\n", "training_data_loader", "=", "DataLoader", "(", "dataset", "=", "train_dataset", ",", "num_workers", "=", "opt", ".", "threads", ",", "\n", "batch_size", "=", "int", "(", "config", "[", "'train'", "]", "[", "'batchsize'", "]", ")", ",", "shuffle", "=", "True", ",", "\n", "collate_fn", "=", "MSLS", ".", "collate_fn", ",", "pin_memory", "=", "cuda", ")", "\n", "\n", "tqdm", ".", "write", "(", "'Allocated: '", "+", "humanbytes", "(", "torch", ".", "cuda", ".", "memory_allocated", "(", ")", ")", ")", "\n", "tqdm", ".", "write", "(", "'Cached:    '", "+", "humanbytes", "(", "torch", ".", "cuda", ".", "memory_cached", "(", ")", ")", ")", "\n", "\n", "model", ".", "train", "(", ")", "\n", "for", "iteration", ",", "(", "query", ",", "positives", ",", "negatives", ",", "negCounts", ",", "indices", ")", "in", "enumerate", "(", "tqdm", "(", "training_data_loader", ",", "position", "=", "2", ",", "leave", "=", "False", ",", "desc", "=", "'Train Iter'", ".", "rjust", "(", "15", ")", ")", ",", "startIter", ")", ":", "\n", "# some reshaping to put query, pos, negs in a single (N, 3, H, W) tensor", "\n", "# where N = batchSize * (nQuery + nPos + nNeg)", "\n", "            ", "if", "query", "is", "None", ":", "\n", "                ", "continue", "# in case we get an empty batch", "\n", "\n", "", "B", ",", "C", ",", "H", ",", "W", "=", "query", ".", "shape", "\n", "nNeg", "=", "torch", ".", "sum", "(", "negCounts", ")", "\n", "data_input", "=", "torch", ".", "cat", "(", "[", "query", ",", "positives", ",", "negatives", "]", ")", "\n", "\n", "data_input", "=", "data_input", ".", "to", "(", "device", ")", "\n", "image_encoding", "=", "model", ".", "encoder", "(", "data_input", ")", "\n", "vlad_encoding", "=", "model", ".", "pool", "(", "image_encoding", ")", "\n", "\n", "vladQ", ",", "vladP", ",", "vladN", "=", "torch", ".", "split", "(", "vlad_encoding", ",", "[", "B", ",", "B", ",", "nNeg", "]", ")", "\n", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "\n", "# calculate loss for each Query, Positive, Negative triplet", "\n", "# due to potential difference in number of negatives have to", "\n", "# do it per query, per negative", "\n", "loss", "=", "0", "\n", "for", "i", ",", "negCount", "in", "enumerate", "(", "negCounts", ")", ":", "\n", "                ", "for", "n", "in", "range", "(", "negCount", ")", ":", "\n", "                    ", "negIx", "=", "(", "torch", ".", "sum", "(", "negCounts", "[", ":", "i", "]", ")", "+", "n", ")", ".", "item", "(", ")", "\n", "loss", "+=", "criterion", "(", "vladQ", "[", "i", ":", "i", "+", "1", "]", ",", "vladP", "[", "i", ":", "i", "+", "1", "]", ",", "vladN", "[", "negIx", ":", "negIx", "+", "1", "]", ")", "\n", "\n", "", "", "loss", "/=", "nNeg", ".", "float", "(", ")", ".", "to", "(", "device", ")", "# normalise by actual number of negatives", "\n", "loss", ".", "backward", "(", ")", "\n", "optimizer", ".", "step", "(", ")", "\n", "del", "data_input", ",", "image_encoding", ",", "vlad_encoding", ",", "vladQ", ",", "vladP", ",", "vladN", "\n", "del", "query", ",", "positives", ",", "negatives", "\n", "\n", "batch_loss", "=", "loss", ".", "item", "(", ")", "\n", "epoch_loss", "+=", "batch_loss", "\n", "\n", "if", "iteration", "%", "50", "==", "0", "or", "nBatches", "<=", "10", ":", "\n", "                ", "tqdm", ".", "write", "(", "\"==> Epoch[{}]({}/{}): Loss: {:.4f}\"", ".", "format", "(", "epoch_num", ",", "iteration", ",", "\n", "nBatches", ",", "batch_loss", ")", ")", "\n", "writer", ".", "add_scalar", "(", "'Train/Loss'", ",", "batch_loss", ",", "\n", "(", "(", "epoch_num", "-", "1", ")", "*", "nBatches", ")", "+", "iteration", ")", "\n", "writer", ".", "add_scalar", "(", "'Train/nNeg'", ",", "nNeg", ",", "\n", "(", "(", "epoch_num", "-", "1", ")", "*", "nBatches", ")", "+", "iteration", ")", "\n", "tqdm", ".", "write", "(", "'Allocated: '", "+", "humanbytes", "(", "torch", ".", "cuda", ".", "memory_allocated", "(", ")", ")", ")", "\n", "tqdm", ".", "write", "(", "'Cached:    '", "+", "humanbytes", "(", "torch", ".", "cuda", ".", "memory_cached", "(", ")", ")", ")", "\n", "\n", "", "", "startIter", "+=", "len", "(", "training_data_loader", ")", "\n", "del", "training_data_loader", ",", "loss", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "torch", ".", "cuda", ".", "empty_cache", "(", ")", "\n", "\n", "", "avg_loss", "=", "epoch_loss", "/", "nBatches", "\n", "\n", "tqdm", ".", "write", "(", "\"===> Epoch {} Complete: Avg. Loss: {:.4f}\"", ".", "format", "(", "epoch_num", ",", "avg_loss", ")", ")", "\n", "writer", ".", "add_scalar", "(", "'Train/AvgLoss'", ",", "avg_loss", ",", "epoch_num", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.ahmedest61_multires-netvlad.training_tools.tools.pca": [[35, 91], ["print", "numpy.real", "numpy.real", "numpy.mean", "numpy.zeros", "print", "scipy.sparse.linalg.eigs", "print", "numpy.linalg.eig", "numpy.all", "numpy.all", "numpy.argsort", "numpy.diag", "numpy.matmul", "numpy.matmul", "numpy.matmul", "numpy.matmul", "numpy.isreal", "numpy.isreal", "numpy.sqrt", "numpy.sqrt", "numpy.maximum"], "function", ["None"], ["def", "pca", "(", "x", ":", "np", ".", "ndarray", ",", "num_pcs", "=", "None", ",", "subtract_mean", "=", "True", ")", ":", "\n", "# translated from MATLAB:", "\n", "# - https://github.com/Relja/relja_matlab/blob/master/relja_PCA.m", "\n", "# - https://github.com/Relja/netvlad/blob/master/addPCA.m", "\n", "\n", "# assumes x = nvectors x ndims", "\n", "    ", "x", "=", "x", ".", "T", "# matlab code is ndims x nvectors, so transpose", "\n", "\n", "n_points", "=", "x", ".", "shape", "[", "1", "]", "\n", "n_dims", "=", "x", ".", "shape", "[", "0", "]", "\n", "\n", "if", "num_pcs", "is", "None", ":", "\n", "        ", "num_pcs", "=", "n_dims", "\n", "\n", "", "print", "(", "'PCA for {} points of dimension {} to PCA dimension {}'", ".", "format", "(", "n_points", ",", "n_dims", ",", "num_pcs", ")", ")", "\n", "\n", "if", "subtract_mean", ":", "\n", "# Subtract mean", "\n", "        ", "mu", "=", "np", ".", "mean", "(", "x", ",", "axis", "=", "1", ")", "\n", "x", "=", "(", "x", ".", "T", "-", "mu", ")", ".", "T", "\n", "", "else", ":", "\n", "        ", "mu", "=", "np", ".", "zeros", "(", "n_dims", ")", "\n", "\n", "", "assert", "num_pcs", "<", "n_dims", "\n", "\n", "if", "n_dims", "<=", "n_points", ":", "\n", "        ", "do_dual", "=", "False", "\n", "# x2 = dims * dims", "\n", "x2", "=", "np", ".", "matmul", "(", "x", ",", "x", ".", "T", ")", "/", "(", "n_points", "-", "1", ")", "\n", "", "else", ":", "\n", "        ", "do_dual", "=", "True", "\n", "# x2 = vectors * vectors", "\n", "x2", "=", "np", ".", "matmul", "(", "x", ".", "T", ",", "x", ")", "/", "(", "n_points", "-", "1", ")", "\n", "\n", "", "if", "num_pcs", "<", "x2", ".", "shape", "[", "0", "]", ":", "\n", "        ", "print", "(", "'Compute {} eigenvectors'", ".", "format", "(", "num_pcs", ")", ")", "\n", "lams", ",", "u", "=", "eigs", "(", "x2", ",", "num_pcs", ")", "\n", "", "else", ":", "\n", "        ", "print", "(", "'Compute eigenvectors'", ")", "\n", "lams", ",", "u", "=", "np", ".", "linalg", ".", "eig", "(", "x2", ")", "\n", "\n", "", "assert", "np", ".", "all", "(", "np", ".", "isreal", "(", "lams", ")", ")", "and", "np", ".", "all", "(", "np", ".", "isreal", "(", "u", ")", ")", "\n", "lams", "=", "np", ".", "real", "(", "lams", ")", "\n", "u", "=", "np", ".", "real", "(", "u", ")", "\n", "\n", "sort_indices", "=", "np", ".", "argsort", "(", "lams", ")", "[", ":", ":", "-", "1", "]", "\n", "lams", "=", "lams", "[", "sort_indices", "]", "\n", "u", "=", "u", "[", ":", ",", "sort_indices", "]", "\n", "\n", "if", "do_dual", ":", "\n", "# U = x * ( U * diag(1./sqrt(max(lams,1e-9))) / sqrt(nPoints-1) );", "\n", "        ", "diag", "=", "np", ".", "diag", "(", "1.", "/", "np", ".", "sqrt", "(", "np", ".", "maximum", "(", "lams", ",", "1e-9", ")", ")", ")", "\n", "utimesdiag", "=", "np", ".", "matmul", "(", "u", ",", "diag", ")", "\n", "u", "=", "np", ".", "matmul", "(", "x", ",", "utimesdiag", "/", "np", ".", "sqrt", "(", "n_points", "-", "1", ")", ")", "\n", "\n", "", "return", "u", ",", "lams", ",", "mu", "\n", "\n"]], "home.repos.pwc.inspect_result.ahmedest61_multires-netvlad.training_tools.tools.humanbytes": [[93, 111], ["float", "float", "float", "float", "float"], "function", ["None"], ["", "def", "humanbytes", "(", "B", ")", ":", "\n", "    ", "\"\"\"Return the given bytes as a human friendly KB, MB, GB, or TB string\"\"\"", "\n", "B", "=", "float", "(", "B", ")", "\n", "KB", "=", "float", "(", "1024", ")", "\n", "MB", "=", "float", "(", "KB", "**", "2", ")", "# 1,048,576", "\n", "GB", "=", "float", "(", "KB", "**", "3", ")", "# 1,073,741,824", "\n", "TB", "=", "float", "(", "KB", "**", "4", ")", "# 1,099,511,627,776", "\n", "\n", "if", "B", "<", "KB", ":", "\n", "        ", "return", "'{0} {1}'", ".", "format", "(", "B", ",", "'Bytes'", "if", "0", "==", "B", ">", "1", "else", "'Byte'", ")", "\n", "", "elif", "KB", "<=", "B", "<", "MB", ":", "\n", "        ", "return", "'{0:.2f} KB'", ".", "format", "(", "B", "/", "KB", ")", "\n", "", "elif", "MB", "<=", "B", "<", "GB", ":", "\n", "        ", "return", "'{0:.2f} MB'", ".", "format", "(", "B", "/", "MB", ")", "\n", "", "elif", "GB", "<=", "B", "<", "TB", ":", "\n", "        ", "return", "'{0:.2f} GB'", ".", "format", "(", "B", "/", "GB", ")", "\n", "", "elif", "TB", "<=", "B", ":", "\n", "        ", "return", "'{0:.2f} TB'", ".", "format", "(", "B", "/", "TB", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ahmedest61_multires-netvlad.training_tools.tools.save_checkpoint": [[113, 121], ["torch.save", "os.path.join", "os.path.join", "shutil.copyfile", "os.path.join", "str"], "function", ["None"], ["", "", "def", "save_checkpoint", "(", "state", ",", "opt", ",", "is_best_sofar", ",", "filename", "=", "'checkpoint.pth.tar'", ")", ":", "\n", "    ", "if", "opt", ".", "save_every_epoch", ":", "\n", "        ", "model_out_path", "=", "join", "(", "opt", ".", "save_file_path", ",", "'checkpoint_epoch'", "+", "str", "(", "state", "[", "'epoch'", "]", ")", "+", "'.pth.tar'", ")", "\n", "", "else", ":", "\n", "        ", "model_out_path", "=", "join", "(", "opt", ".", "save_file_path", ",", "filename", ")", "\n", "", "torch", ".", "save", "(", "state", ",", "model_out_path", ")", "\n", "if", "is_best_sofar", ":", "\n", "        ", "shutil", ".", "copyfile", "(", "model_out_path", ",", "join", "(", "opt", ".", "save_file_path", ",", "'model_best.pth.tar'", ")", ")", "", "", "", ""]], "home.repos.pwc.inspect_result.ahmedest61_multires-netvlad.training_tools.get_clusters.get_clusters": [[46, 96], ["math.ceil", "torch.utils.data.SubsetRandomSampler", "torch.utils.data.DataLoader", "os.path.join", "numpy.random.choice", "os.path.exists", "os.makedirs", "h5py.File", "tqdm.auto.tqdm.write", "faiss.Kmeans", "faiss.Kmeans.train", "tqdm.auto.tqdm.write", "h5_file.create_dataset", "tqdm.auto.tqdm.write", "len", "patchnetvlad.training_tools.msls.ImagesFromList", "int", "os.path.join", "os.path.join", "torch.no_grad", "torch.no_grad", "model.eval", "tqdm.auto.tqdm.write", "h5_file.create_dataset", "enumerate", "int", "tqdm.auto.tqdm", "input_data.to.to", "model.encoder().view().permute", "torch.normalize", "range", "str", "patchnetvlad.tools.datasets.input_transform", "F.normalize.size", "numpy.random.choice", "image_descriptors[].detach().cpu().numpy", "model.encoder().view", "int", "F.normalize.size", "input_data.to.size", "image_descriptors[].detach().cpu", "model.encoder", "image_descriptors[].detach"], "function", ["home.repos.pwc.inspect_result.ahmedest61_multires-netvlad.None.main.train", "home.repos.pwc.inspect_result.ahmedest61_multires-netvlad.tools.datasets.input_transform"], ["def", "get_clusters", "(", "cluster_set", ",", "model", ",", "encoder_dim", ",", "device", ",", "opt", ",", "config", ")", ":", "\n", "    ", "if", "device", ".", "type", "==", "'cuda'", ":", "\n", "        ", "cuda", "=", "True", "\n", "", "else", ":", "\n", "        ", "cuda", "=", "False", "\n", "", "nDescriptors", "=", "50000", "\n", "nPerImage", "=", "100", "\n", "nIm", "=", "ceil", "(", "nDescriptors", "/", "nPerImage", ")", "\n", "\n", "cluster_sampler", "=", "SubsetRandomSampler", "(", "np", ".", "random", ".", "choice", "(", "len", "(", "cluster_set", ".", "dbImages", ")", ",", "nIm", ",", "replace", "=", "False", ")", ")", "\n", "\n", "cluster_data_loader", "=", "DataLoader", "(", "dataset", "=", "ImagesFromList", "(", "cluster_set", ".", "dbImages", ",", "transform", "=", "input_transform", "(", ")", ")", ",", "\n", "num_workers", "=", "opt", ".", "threads", ",", "batch_size", "=", "int", "(", "config", "[", "'train'", "]", "[", "'cachebatchsize'", "]", ")", ",", "shuffle", "=", "False", ",", "\n", "pin_memory", "=", "cuda", ",", "\n", "sampler", "=", "cluster_sampler", ")", "\n", "\n", "if", "not", "exists", "(", "join", "(", "opt", ".", "cache_path", ",", "'centroids'", ")", ")", ":", "\n", "        ", "makedirs", "(", "join", "(", "opt", ".", "cache_path", ",", "'centroids'", ")", ")", "\n", "\n", "", "initcache_clusters", "=", "join", "(", "opt", ".", "cache_path", ",", "'centroids'", ",", "\n", "'vgg16_'", "+", "'mapillary_'", "+", "config", "[", "'train'", "]", "[", "'num_clusters'", "]", "+", "'_desc_cen.hdf5'", ")", "\n", "with", "h5py", ".", "File", "(", "initcache_clusters", ",", "mode", "=", "'w'", ")", "as", "h5_file", ":", "\n", "        ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "model", ".", "eval", "(", ")", "\n", "tqdm", ".", "write", "(", "'====> Extracting Descriptors'", ")", "\n", "dbFeat", "=", "h5_file", ".", "create_dataset", "(", "\"descriptors\"", ",", "[", "nDescriptors", ",", "encoder_dim", "]", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "\n", "for", "iteration", ",", "(", "input_data", ",", "indices", ")", "in", "enumerate", "(", "tqdm", "(", "cluster_data_loader", ",", "desc", "=", "'Iter'", ".", "rjust", "(", "15", ")", ")", ",", "1", ")", ":", "\n", "                ", "input_data", "=", "input_data", ".", "to", "(", "device", ")", "\n", "image_descriptors", "=", "model", ".", "encoder", "(", "input_data", ")", ".", "view", "(", "input_data", ".", "size", "(", "0", ")", ",", "encoder_dim", ",", "-", "1", ")", ".", "permute", "(", "0", ",", "2", ",", "1", ")", "\n", "image_descriptors", "=", "F", ".", "normalize", "(", "image_descriptors", ",", "p", "=", "2", ",", "dim", "=", "2", ")", "# we L2-norm descriptors before vlad so", "\n", "# need to L2-norm here as well", "\n", "\n", "batchix", "=", "(", "iteration", "-", "1", ")", "*", "int", "(", "config", "[", "'train'", "]", "[", "'cachebatchsize'", "]", ")", "*", "nPerImage", "\n", "for", "ix", "in", "range", "(", "image_descriptors", ".", "size", "(", "0", ")", ")", ":", "\n", "# sample different location for each image in batch", "\n", "                    ", "sample", "=", "np", ".", "random", ".", "choice", "(", "image_descriptors", ".", "size", "(", "1", ")", ",", "nPerImage", ",", "replace", "=", "False", ")", "\n", "startix", "=", "batchix", "+", "ix", "*", "nPerImage", "\n", "dbFeat", "[", "startix", ":", "startix", "+", "nPerImage", ",", ":", "]", "=", "image_descriptors", "[", "ix", ",", "sample", ",", ":", "]", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "\n", "", "del", "input_data", ",", "image_descriptors", "\n", "\n", "", "", "tqdm", ".", "write", "(", "'====> Clustering..'", ")", "\n", "niter", "=", "100", "\n", "kmeans", "=", "faiss", ".", "Kmeans", "(", "encoder_dim", ",", "int", "(", "config", "[", "'train'", "]", "[", "'num_clusters'", "]", ")", ",", "niter", "=", "niter", ",", "verbose", "=", "False", ")", "\n", "kmeans", ".", "train", "(", "dbFeat", "[", "...", "]", ")", "\n", "\n", "tqdm", ".", "write", "(", "'====> Storing centroids '", "+", "str", "(", "kmeans", ".", "centroids", ".", "shape", ")", ")", "\n", "h5_file", ".", "create_dataset", "(", "'centroids'", ",", "data", "=", "kmeans", ".", "centroids", ")", "\n", "tqdm", ".", "write", "(", "'====> Done!'", ")", "", "", "", ""]], "home.repos.pwc.inspect_result.ahmedest61_multires-netvlad.training_tools.msls.ImagesFromList.__init__": [[56, 59], ["numpy.asarray"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "images", ",", "transform", ")", ":", "\n", "        ", "self", ".", "images", "=", "np", ".", "asarray", "(", "images", ")", "\n", "self", ".", "transform", "=", "transform", "\n", "\n"]], "home.repos.pwc.inspect_result.ahmedest61_multires-netvlad.training_tools.msls.ImagesFromList.__len__": [[60, 62], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "images", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ahmedest61_multires-netvlad.training_tools.msls.ImagesFromList.__getitem__": [[63, 74], ["msls.ImagesFromList.transform", "len", "PIL.Image.open", "msls.ImagesFromList.images[].split", "PIL.Image.open"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "idx", ")", ":", "\n", "        ", "try", ":", "\n", "            ", "img", "=", "[", "Image", ".", "open", "(", "im", ")", "for", "im", "in", "self", ".", "images", "[", "idx", "]", ".", "split", "(", "\",\"", ")", "]", "\n", "", "except", ":", "\n", "            ", "img", "=", "[", "Image", ".", "open", "(", "self", ".", "images", "[", "0", "]", ")", "]", "\n", "", "img", "=", "[", "self", ".", "transform", "(", "im", ")", "for", "im", "in", "img", "]", "\n", "\n", "if", "len", "(", "img", ")", "==", "1", ":", "\n", "            ", "img", "=", "img", "[", "0", "]", "\n", "\n", "", "return", "img", ",", "idx", "\n", "\n"]], "home.repos.pwc.inspect_result.ahmedest61_multires-netvlad.training_tools.msls.MSLS.__init__": [[77, 308], ["print", "numpy.asarray", "numpy.asarray", "numpy.asarray", "numpy.asarray", "numpy.asarray", "numpy.asarray", "numpy.asarray", "torch.device", "torch.device", "torch.device", "torch.device", "print", "len", "len", "print", "print", "print", "sys.exit", "numpy.asarray", "cities.split", "pandas.read_csv", "pandas.read_csv", "pandas.read_csv", "pandas.read_csv", "msls.MSLS.arange_as_seq", "msls.MSLS.arange_as_seq", "numpy.unique", "numpy.unique", "msls.MSLS.qImages.extend", "msls.MSLS.dbImages.extend", "msls.MSLS.qEndPosList.append", "msls.MSLS.dbEndPosList.append", "qData[].values.reshape", "dbData[].values.reshape", "sklearn.neighbors.NearestNeighbors", "sklearn.neighbors.NearestNeighbors.fit", "sklearn.neighbors.NearestNeighbors.radius_neighbors", "msls.MSLS.all_pos_indices.extend", "range", "len", "len", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "msls.MSLS.__calcSamplingWeights__", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "pandas.read_csv", "pandas.read_csv", "msls.MSLS.filter", "msls.MSLS.filter", "msls.MSLS.filter", "msls.MSLS.filter", "len", "len", "sklearn.neighbors.NearestNeighbors.radius_neighbors", "len", "seqIdx2frameIdx", "frameIdx2uniqFrameIdx", "numpy.unique", "pandas.read_csv", "pandas.read_csv", "msls.MSLS.arange_as_seq", "msls.MSLS.arange_as_seq", "msls.MSLS.filter", "msls.MSLS.filter", "msls.MSLS.qImages.extend", "msls.MSLS.dbImages.extend", "msls.MSLS.qIdx.extend", "len", "numpy.ones", "float", "os.path.join", "os.path.join", "numpy.where", "numpy.where", "numpy.where", "numpy.where", "len", "len", "numpy.where", "numpy.where", "len", "numpy.unique", "msls.MSLS.pIdx.append", "msls.MSLS.qIdx.append", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "numpy.where", "numpy.where", "list", "numpy.empty", "len", "len", "numpy.in1d", "numpy.in1d().reshape", "uniqFrameIdx2seqIdx", "numpy.unique", "numpy.unique", "msls.MSLS.nonNegIdx.append", "range", "uniqFrameIdx2seqIdx", "sum", "msls.MSLS.night.append", "sum", "msls.MSLS.sideways.append", "numpy.in1d", "len", "len", "len", "numpy.in1d", "numpy.in1d"], "methods", ["home.repos.pwc.inspect_result.ahmedest61_multires-netvlad.training_tools.msls.MSLS.arange_as_seq", "home.repos.pwc.inspect_result.ahmedest61_multires-netvlad.training_tools.msls.MSLS.arange_as_seq", "home.repos.pwc.inspect_result.ahmedest61_multires-netvlad.training_tools.msls.MSLS.__calcSamplingWeights__", "home.repos.pwc.inspect_result.ahmedest61_multires-netvlad.training_tools.msls.MSLS.filter", "home.repos.pwc.inspect_result.ahmedest61_multires-netvlad.training_tools.msls.MSLS.filter", "home.repos.pwc.inspect_result.ahmedest61_multires-netvlad.training_tools.msls.MSLS.filter", "home.repos.pwc.inspect_result.ahmedest61_multires-netvlad.training_tools.msls.MSLS.filter", "home.repos.pwc.inspect_result.ahmedest61_multires-netvlad.training_tools.msls.MSLS.arange_as_seq", "home.repos.pwc.inspect_result.ahmedest61_multires-netvlad.training_tools.msls.MSLS.arange_as_seq", "home.repos.pwc.inspect_result.ahmedest61_multires-netvlad.training_tools.msls.MSLS.filter", "home.repos.pwc.inspect_result.ahmedest61_multires-netvlad.training_tools.msls.MSLS.filter"], ["    ", "def", "__init__", "(", "self", ",", "root_dir", ",", "cities", "=", "''", ",", "nNeg", "=", "5", ",", "transform", "=", "None", ",", "mode", "=", "'train'", ",", "task", "=", "'im2im'", ",", "subtask", "=", "'all'", ",", "\n", "seq_length", "=", "1", ",", "posDistThr", "=", "10", ",", "negDistThr", "=", "25", ",", "cached_queries", "=", "1000", ",", "cached_negatives", "=", "1000", ",", "\n", "positive_sampling", "=", "True", ",", "bs", "=", "24", ",", "threads", "=", "8", ",", "margin", "=", "0.1", ",", "exclude_panos", "=", "True", ")", ":", "\n", "\n", "# initializing", "\n", "        ", "assert", "mode", "in", "(", "'train'", ",", "'val'", ",", "'test'", ")", "\n", "assert", "task", "in", "(", "'im2im'", ",", "'im2seq'", ",", "'seq2im'", ",", "'seq2seq'", ")", "\n", "assert", "subtask", "in", "(", "'all'", ",", "'s2w'", ",", "'w2s'", ",", "'o2n'", ",", "'n2o'", ",", "'d2n'", ",", "'n2d'", ")", "\n", "assert", "seq_length", "%", "2", "==", "1", "\n", "assert", "(", "task", "==", "'im2im'", "and", "seq_length", "==", "1", ")", "or", "(", "task", "!=", "'im2im'", "and", "seq_length", ">", "1", ")", "\n", "\n", "if", "cities", "in", "default_cities", ":", "\n", "            ", "self", ".", "cities", "=", "default_cities", "[", "cities", "]", "\n", "", "elif", "cities", "==", "''", ":", "\n", "            ", "self", ".", "cities", "=", "default_cities", "[", "mode", "]", "\n", "", "else", ":", "\n", "            ", "self", ".", "cities", "=", "cities", ".", "split", "(", "','", ")", "\n", "\n", "", "self", ".", "qIdx", "=", "[", "]", "\n", "self", ".", "qImages", "=", "[", "]", "\n", "self", ".", "pIdx", "=", "[", "]", "\n", "self", ".", "nonNegIdx", "=", "[", "]", "\n", "self", ".", "dbImages", "=", "[", "]", "\n", "self", ".", "sideways", "=", "[", "]", "\n", "self", ".", "night", "=", "[", "]", "\n", "self", ".", "qEndPosList", "=", "[", "]", "\n", "self", ".", "dbEndPosList", "=", "[", "]", "\n", "\n", "self", ".", "all_pos_indices", "=", "[", "]", "\n", "\n", "# hyper-parameters", "\n", "self", ".", "nNeg", "=", "nNeg", "\n", "self", ".", "margin", "=", "margin", "\n", "self", ".", "posDistThr", "=", "posDistThr", "\n", "self", ".", "negDistThr", "=", "negDistThr", "\n", "self", ".", "cached_queries", "=", "cached_queries", "\n", "self", ".", "cached_negatives", "=", "cached_negatives", "\n", "\n", "# flags", "\n", "self", ".", "cache", "=", "None", "\n", "self", ".", "exclude_panos", "=", "exclude_panos", "\n", "self", ".", "mode", "=", "mode", "\n", "self", ".", "subtask", "=", "subtask", "\n", "print", "(", "'Exclude panoramas:'", ",", "self", ".", "exclude_panos", ")", "\n", "\n", "# other", "\n", "self", ".", "transform", "=", "transform", "\n", "\n", "# define sequence length based on task", "\n", "if", "task", "==", "'im2im'", ":", "\n", "            ", "seq_length_q", ",", "seq_length_db", "=", "1", ",", "1", "\n", "", "elif", "task", "==", "'seq2seq'", ":", "\n", "            ", "seq_length_q", ",", "seq_length_db", "=", "seq_length", ",", "seq_length", "\n", "", "elif", "task", "==", "'seq2im'", ":", "\n", "            ", "seq_length_q", ",", "seq_length_db", "=", "seq_length", ",", "1", "\n", "", "else", ":", "# im2seq", "\n", "            ", "seq_length_q", ",", "seq_length_db", "=", "1", ",", "seq_length", "\n", "\n", "# load data", "\n", "", "for", "city", "in", "self", ".", "cities", ":", "\n", "            ", "print", "(", "\"=====> {}\"", ".", "format", "(", "city", ")", ")", "\n", "\n", "subdir", "=", "'test'", "if", "city", "in", "default_cities", "[", "'test'", "]", "else", "'train_val'", "\n", "\n", "# get len of images from cities so far for indexing", "\n", "_lenQ", "=", "len", "(", "self", ".", "qImages", ")", "\n", "_lenDb", "=", "len", "(", "self", ".", "dbImages", ")", "\n", "\n", "# when GPS / UTM is available", "\n", "if", "self", ".", "mode", "in", "[", "'train'", ",", "'val'", "]", ":", "\n", "# load query data", "\n", "                ", "qData", "=", "pd", ".", "read_csv", "(", "join", "(", "root_dir", ",", "subdir", ",", "city", ",", "'query'", ",", "'postprocessed.csv'", ")", ",", "index_col", "=", "0", ")", "\n", "qDataRaw", "=", "pd", ".", "read_csv", "(", "join", "(", "root_dir", ",", "subdir", ",", "city", ",", "'query'", ",", "'raw.csv'", ")", ",", "index_col", "=", "0", ")", "\n", "\n", "# load database data", "\n", "dbData", "=", "pd", ".", "read_csv", "(", "join", "(", "root_dir", ",", "subdir", ",", "city", ",", "'database'", ",", "'postprocessed.csv'", ")", ",", "index_col", "=", "0", ")", "\n", "dbDataRaw", "=", "pd", ".", "read_csv", "(", "join", "(", "root_dir", ",", "subdir", ",", "city", ",", "'database'", ",", "'raw.csv'", ")", ",", "index_col", "=", "0", ")", "\n", "\n", "# arange based on task", "\n", "qSeqKeys", ",", "qSeqIdxs", "=", "self", ".", "arange_as_seq", "(", "qData", ",", "join", "(", "root_dir", ",", "subdir", ",", "city", ",", "'query'", ")", ",", "seq_length_q", ")", "\n", "dbSeqKeys", ",", "dbSeqIdxs", "=", "self", ".", "arange_as_seq", "(", "dbData", ",", "join", "(", "root_dir", ",", "subdir", ",", "city", ",", "'database'", ")", ",", "\n", "seq_length_db", ")", "\n", "\n", "# filter based on subtasks", "\n", "if", "self", ".", "mode", "in", "[", "'val'", "]", ":", "\n", "                    ", "qIdx", "=", "pd", ".", "read_csv", "(", "join", "(", "root_dir", ",", "subdir", ",", "city", ",", "'query'", ",", "'subtask_index.csv'", ")", ",", "index_col", "=", "0", ")", "\n", "dbIdx", "=", "pd", ".", "read_csv", "(", "join", "(", "root_dir", ",", "subdir", ",", "city", ",", "'database'", ",", "'subtask_index.csv'", ")", ",", "index_col", "=", "0", ")", "\n", "\n", "# find all the sequence where the center frame belongs to a subtask", "\n", "val_frames", "=", "np", ".", "where", "(", "qIdx", "[", "self", ".", "subtask", "]", ")", "[", "0", "]", "\n", "qSeqKeys", ",", "qSeqIdxs", "=", "self", ".", "filter", "(", "qSeqKeys", ",", "qSeqIdxs", ",", "val_frames", ")", "\n", "\n", "val_frames", "=", "np", ".", "where", "(", "dbIdx", "[", "self", ".", "subtask", "]", ")", "[", "0", "]", "\n", "dbSeqKeys", ",", "dbSeqIdxs", "=", "self", ".", "filter", "(", "dbSeqKeys", ",", "dbSeqIdxs", ",", "val_frames", ")", "\n", "\n", "# filter based on panorama data", "\n", "", "if", "self", ".", "exclude_panos", ":", "\n", "                    ", "panos_frames", "=", "np", ".", "where", "(", "(", "qDataRaw", "[", "'pano'", "]", "==", "False", ")", ".", "values", ")", "[", "0", "]", "\n", "qSeqKeys", ",", "qSeqIdxs", "=", "self", ".", "filter", "(", "qSeqKeys", ",", "qSeqIdxs", ",", "panos_frames", ")", "\n", "\n", "panos_frames", "=", "np", ".", "where", "(", "(", "dbDataRaw", "[", "'pano'", "]", "==", "False", ")", ".", "values", ")", "[", "0", "]", "\n", "dbSeqKeys", ",", "dbSeqIdxs", "=", "self", ".", "filter", "(", "dbSeqKeys", ",", "dbSeqIdxs", ",", "panos_frames", ")", "\n", "\n", "", "unique_qSeqIdx", "=", "np", ".", "unique", "(", "qSeqIdxs", ")", "\n", "unique_dbSeqIdx", "=", "np", ".", "unique", "(", "dbSeqIdxs", ")", "\n", "\n", "# if a combination of city, task and subtask is chosen, where there are no query/dabase images,", "\n", "# then continue to next city", "\n", "if", "len", "(", "unique_qSeqIdx", ")", "==", "0", "or", "len", "(", "unique_dbSeqIdx", ")", "==", "0", ":", "\n", "                    ", "continue", "\n", "\n", "", "self", ".", "qImages", ".", "extend", "(", "qSeqKeys", ")", "\n", "self", ".", "dbImages", ".", "extend", "(", "dbSeqKeys", ")", "\n", "\n", "self", ".", "qEndPosList", ".", "append", "(", "len", "(", "qSeqKeys", ")", ")", "\n", "self", ".", "dbEndPosList", ".", "append", "(", "len", "(", "dbSeqKeys", ")", ")", "\n", "\n", "qData", "=", "qData", ".", "loc", "[", "unique_qSeqIdx", "]", "\n", "dbData", "=", "dbData", ".", "loc", "[", "unique_dbSeqIdx", "]", "\n", "\n", "# useful indexing functions", "\n", "seqIdx2frameIdx", "=", "lambda", "seqIdx", ",", "seqIdxs", ":", "seqIdxs", "[", "seqIdx", "]", "\n", "# frameIdx2seqIdx = lambda frameIdx, seqIdxs: np.where(seqIdxs == frameIdx)[0][1]", "\n", "frameIdx2uniqFrameIdx", "=", "lambda", "frameIdx", ",", "uniqFrameIdx", ":", "np", ".", "where", "(", "np", ".", "in1d", "(", "uniqFrameIdx", ",", "frameIdx", ")", ")", "[", "0", "]", "\n", "uniqFrameIdx2seqIdx", "=", "lambda", "frameIdxs", ",", "seqIdxs", ":", "np", ".", "where", "(", "np", ".", "in1d", "(", "seqIdxs", ",", "frameIdxs", ")", ".", "reshape", "(", "seqIdxs", ".", "shape", ")", ")", "[", "0", "]", "\n", "\n", "# utm coordinates", "\n", "utmQ", "=", "qData", "[", "[", "'easting'", ",", "'northing'", "]", "]", ".", "values", ".", "reshape", "(", "-", "1", ",", "2", ")", "\n", "utmDb", "=", "dbData", "[", "[", "'easting'", ",", "'northing'", "]", "]", ".", "values", ".", "reshape", "(", "-", "1", ",", "2", ")", "\n", "\n", "night", ",", "sideways", ",", "index", "=", "qData", "[", "'night'", "]", ".", "values", ",", "(", "\n", "qData", "[", "'view_direction'", "]", "==", "'Sideways'", ")", ".", "values", ",", "qData", ".", "index", "\n", "\n", "# find positive images for training", "\n", "neigh", "=", "NearestNeighbors", "(", "algorithm", "=", "'brute'", ")", "\n", "neigh", ".", "fit", "(", "utmDb", ")", "\n", "pos_distances", ",", "pos_indices", "=", "neigh", ".", "radius_neighbors", "(", "utmQ", ",", "self", ".", "posDistThr", ")", "\n", "self", ".", "all_pos_indices", ".", "extend", "(", "pos_indices", ")", "\n", "\n", "if", "self", ".", "mode", "==", "'train'", ":", "\n", "                    ", "nD", ",", "nI", "=", "neigh", ".", "radius_neighbors", "(", "utmQ", ",", "self", ".", "negDistThr", ")", "\n", "\n", "", "for", "q_seq_idx", "in", "range", "(", "len", "(", "qSeqKeys", ")", ")", ":", "\n", "\n", "                    ", "q_frame_idxs", "=", "seqIdx2frameIdx", "(", "q_seq_idx", ",", "qSeqIdxs", ")", "\n", "q_uniq_frame_idx", "=", "frameIdx2uniqFrameIdx", "(", "q_frame_idxs", ",", "unique_qSeqIdx", ")", "\n", "\n", "p_uniq_frame_idxs", "=", "np", ".", "unique", "(", "[", "p", "for", "pos", "in", "pos_indices", "[", "q_uniq_frame_idx", "]", "for", "p", "in", "pos", "]", ")", "\n", "\n", "# the query image has at least one positive", "\n", "if", "len", "(", "p_uniq_frame_idxs", ")", ">", "0", ":", "\n", "                        ", "p_seq_idx", "=", "np", ".", "unique", "(", "uniqFrameIdx2seqIdx", "(", "unique_dbSeqIdx", "[", "p_uniq_frame_idxs", "]", ",", "dbSeqIdxs", ")", ")", "\n", "\n", "self", ".", "pIdx", ".", "append", "(", "p_seq_idx", "+", "_lenDb", ")", "\n", "self", ".", "qIdx", ".", "append", "(", "q_seq_idx", "+", "_lenQ", ")", "\n", "\n", "# in training we have two thresholds, one for finding positives and one for finding images", "\n", "# that we are certain are negatives.", "\n", "if", "self", ".", "mode", "==", "'train'", ":", "\n", "\n", "                            ", "n_uniq_frame_idxs", "=", "np", ".", "unique", "(", "[", "n", "for", "nonNeg", "in", "nI", "[", "q_uniq_frame_idx", "]", "for", "n", "in", "nonNeg", "]", ")", "\n", "n_seq_idx", "=", "np", ".", "unique", "(", "uniqFrameIdx2seqIdx", "(", "unique_dbSeqIdx", "[", "n_uniq_frame_idxs", "]", ",", "dbSeqIdxs", ")", ")", "\n", "\n", "self", ".", "nonNegIdx", ".", "append", "(", "n_seq_idx", "+", "_lenDb", ")", "\n", "\n", "# gather meta which is useful for positive sampling", "\n", "if", "sum", "(", "night", "[", "np", ".", "in1d", "(", "index", ",", "q_frame_idxs", ")", "]", ")", ">", "0", ":", "\n", "                                ", "self", ".", "night", ".", "append", "(", "len", "(", "self", ".", "qIdx", ")", "-", "1", ")", "\n", "", "if", "sum", "(", "sideways", "[", "np", ".", "in1d", "(", "index", ",", "q_frame_idxs", ")", "]", ")", ">", "0", ":", "\n", "                                ", "self", ".", "sideways", ".", "append", "(", "len", "(", "self", ".", "qIdx", ")", "-", "1", ")", "\n", "\n", "# when GPS / UTM / pano info is not available", "\n", "", "", "", "", "", "elif", "self", ".", "mode", "in", "[", "'test'", "]", ":", "\n", "\n", "# load images for subtask", "\n", "                ", "qIdx", "=", "pd", ".", "read_csv", "(", "join", "(", "root_dir", ",", "subdir", ",", "city", ",", "'query'", ",", "'subtask_index.csv'", ")", ",", "index_col", "=", "0", ")", "\n", "dbIdx", "=", "pd", ".", "read_csv", "(", "join", "(", "root_dir", ",", "subdir", ",", "city", ",", "'database'", ",", "'subtask_index.csv'", ")", ",", "index_col", "=", "0", ")", "\n", "\n", "# arange in sequences", "\n", "qSeqKeys", ",", "qSeqIdxs", "=", "self", ".", "arange_as_seq", "(", "qIdx", ",", "join", "(", "root_dir", ",", "subdir", ",", "city", ",", "'query'", ")", ",", "seq_length_q", ")", "\n", "dbSeqKeys", ",", "dbSeqIdxs", "=", "self", ".", "arange_as_seq", "(", "dbIdx", ",", "join", "(", "root_dir", ",", "subdir", ",", "city", ",", "'database'", ")", ",", "\n", "seq_length_db", ")", "\n", "\n", "# filter query based on subtask", "\n", "val_frames", "=", "np", ".", "where", "(", "qIdx", "[", "self", ".", "subtask", "]", ")", "[", "0", "]", "\n", "qSeqKeys", ",", "qSeqIdxs", "=", "self", ".", "filter", "(", "qSeqKeys", ",", "qSeqIdxs", ",", "val_frames", ")", "\n", "\n", "# filter database based on subtask", "\n", "val_frames", "=", "np", ".", "where", "(", "dbIdx", "[", "self", ".", "subtask", "]", ")", "[", "0", "]", "\n", "dbSeqKeys", ",", "dbSeqIdxs", "=", "self", ".", "filter", "(", "dbSeqKeys", ",", "dbSeqIdxs", ",", "val_frames", ")", "\n", "\n", "self", ".", "qImages", ".", "extend", "(", "qSeqKeys", ")", "\n", "self", ".", "dbImages", ".", "extend", "(", "dbSeqKeys", ")", "\n", "\n", "# add query index", "\n", "self", ".", "qIdx", ".", "extend", "(", "list", "(", "range", "(", "_lenQ", ",", "len", "(", "qSeqKeys", ")", "+", "_lenQ", ")", ")", ")", "\n", "\n", "# if a combination of cities, task and subtask is chosen, where there are no query/database images,", "\n", "# then exit", "\n", "", "", "if", "len", "(", "self", ".", "qImages", ")", "==", "0", "or", "len", "(", "self", ".", "dbImages", ")", "==", "0", ":", "\n", "            ", "print", "(", "\"Exiting...\"", ")", "\n", "print", "(", "\n", "\"A combination of cities, task and subtask have been chosen, where there are no query/database images.\"", ")", "\n", "print", "(", "\"Try choosing a different subtask or more cities\"", ")", "\n", "sys", ".", "exit", "(", ")", "\n", "\n", "# cast to np.arrays for indexing during training", "\n", "", "self", ".", "qIdx", "=", "np", ".", "asarray", "(", "self", ".", "qIdx", ")", "\n", "self", ".", "qImages", "=", "np", ".", "asarray", "(", "self", ".", "qImages", ")", "\n", "self", ".", "pIdx", "=", "np", ".", "asarray", "(", "self", ".", "pIdx", ")", "\n", "self", ".", "nonNegIdx", "=", "np", ".", "asarray", "(", "self", ".", "nonNegIdx", ")", "\n", "self", ".", "dbImages", "=", "np", ".", "asarray", "(", "self", ".", "dbImages", ")", "\n", "self", ".", "sideways", "=", "np", ".", "asarray", "(", "self", ".", "sideways", ")", "\n", "self", ".", "night", "=", "np", ".", "asarray", "(", "self", ".", "night", ")", "\n", "\n", "# decide device type ( important for triplet mining )", "\n", "self", ".", "device", "=", "torch", ".", "device", "(", "\"cuda:0\"", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "else", "\"cpu\"", ")", "\n", "self", ".", "threads", "=", "threads", "\n", "self", ".", "bs", "=", "bs", "\n", "\n", "if", "mode", "==", "'train'", ":", "\n", "\n", "# for now always 1-1 lookup.", "\n", "            ", "self", ".", "negCache", "=", "np", ".", "asarray", "(", "[", "np", ".", "empty", "(", "(", "0", ",", ")", ",", "dtype", "=", "int", ")", "]", "*", "len", "(", "self", ".", "qIdx", ")", ")", "\n", "\n", "# calculate weights for positive sampling", "\n", "if", "positive_sampling", ":", "\n", "                ", "self", ".", "__calcSamplingWeights__", "(", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "weights", "=", "np", ".", "ones", "(", "len", "(", "self", ".", "qIdx", ")", ")", "/", "float", "(", "len", "(", "self", ".", "qIdx", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ahmedest61_multires-netvlad.training_tools.msls.MSLS.__calcSamplingWeights__": [[309, 332], ["len", "numpy.ones", "print", "print", "len", "len", "len", "print", "len", "print", "print", "len", "len", "len", "len", "len", "len", "len", "len", "len", "len"], "methods", ["None"], ["", "", "", "def", "__calcSamplingWeights__", "(", "self", ")", ":", "\n", "\n", "# length of query", "\n", "        ", "N", "=", "len", "(", "self", ".", "qIdx", ")", "\n", "\n", "# initialize weights", "\n", "self", ".", "weights", "=", "np", ".", "ones", "(", "N", ")", "\n", "\n", "# weight higher if from night or sideways facing", "\n", "if", "len", "(", "self", ".", "night", ")", "!=", "0", ":", "\n", "            ", "self", ".", "weights", "[", "self", ".", "night", "]", "+=", "N", "/", "len", "(", "self", ".", "night", ")", "\n", "", "if", "len", "(", "self", ".", "sideways", ")", "!=", "0", ":", "\n", "            ", "self", ".", "weights", "[", "self", ".", "sideways", "]", "+=", "N", "/", "len", "(", "self", ".", "sideways", ")", "\n", "\n", "# print weight information", "\n", "", "print", "(", "\"#Sideways [{}/{}]; #Night; [{}/{}]\"", ".", "format", "(", "len", "(", "self", ".", "sideways", ")", ",", "N", ",", "len", "(", "self", ".", "night", ")", ",", "N", ")", ")", "\n", "print", "(", "\"Forward and Day weighted with {:.4f}\"", ".", "format", "(", "1", ")", ")", "\n", "if", "len", "(", "self", ".", "night", ")", "!=", "0", ":", "\n", "            ", "print", "(", "\"Forward and Night weighted with {:.4f}\"", ".", "format", "(", "1", "+", "N", "/", "len", "(", "self", ".", "night", ")", ")", ")", "\n", "", "if", "len", "(", "self", ".", "sideways", ")", "!=", "0", ":", "\n", "            ", "print", "(", "\"Sideways and Day weighted with {:.4f}\"", ".", "format", "(", "1", "+", "N", "/", "len", "(", "self", ".", "sideways", ")", ")", ")", "\n", "", "if", "len", "(", "self", ".", "sideways", ")", "!=", "0", "and", "len", "(", "self", ".", "night", ")", "!=", "0", ":", "\n", "            ", "print", "(", "\"Sideways and Night weighted with {:.4f}\"", ".", "format", "(", "1", "+", "N", "/", "len", "(", "self", ".", "night", ")", "+", "N", "/", "len", "(", "self", ".", "sideways", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ahmedest61_multires-netvlad.training_tools.msls.MSLS.arange_as_seq": [[333, 357], ["pandas.read_csv", "os.path.join", "numpy.asarray", "seq_keys.append", "seq_idxs.append", "numpy.arange", "len", "len", "numpy.unique", "os.path.join", "seq[].diff"], "methods", ["None"], ["", "", "@", "staticmethod", "\n", "def", "arange_as_seq", "(", "data", ",", "path", ",", "seq_length", ")", ":", "\n", "\n", "        ", "seqInfo", "=", "pd", ".", "read_csv", "(", "join", "(", "path", ",", "'seq_info.csv'", ")", ",", "index_col", "=", "0", ")", "\n", "\n", "seq_keys", ",", "seq_idxs", "=", "[", "]", ",", "[", "]", "\n", "for", "idx", "in", "data", ".", "index", ":", "\n", "\n", "# edge cases.", "\n", "            ", "if", "idx", "<", "(", "seq_length", "//", "2", ")", "or", "idx", ">=", "(", "len", "(", "seqInfo", ")", "-", "seq_length", "//", "2", ")", ":", "\n", "                ", "continue", "\n", "\n", "# find surrounding frames in sequence", "\n", "", "seq_idx", "=", "np", ".", "arange", "(", "-", "seq_length", "//", "2", ",", "seq_length", "//", "2", ")", "+", "1", "+", "idx", "\n", "seq", "=", "seqInfo", ".", "iloc", "[", "seq_idx", "]", "\n", "\n", "# the sequence must have the same sequence key and must have consecutive frames", "\n", "if", "len", "(", "np", ".", "unique", "(", "seq", "[", "'sequence_key'", "]", ")", ")", "==", "1", "and", "(", "seq", "[", "'frame_number'", "]", ".", "diff", "(", ")", "[", "1", ":", "]", "==", "1", ")", ".", "all", "(", ")", ":", "\n", "                ", "seq_key", "=", "','", ".", "join", "(", "[", "join", "(", "path", ",", "'images'", ",", "key", "+", "'.jpg'", ")", "for", "key", "in", "seq", "[", "'key'", "]", "]", ")", "\n", "\n", "seq_keys", ".", "append", "(", "seq_key", ")", "\n", "seq_idxs", ".", "append", "(", "seq_idx", ")", "\n", "\n", "", "", "return", "seq_keys", ",", "np", ".", "asarray", "(", "seq_idxs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ahmedest61_multires-netvlad.training_tools.msls.MSLS.filter": [[358, 366], ["zip", "numpy.asarray", "keys.append", "idxs.append", "len"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "filter", "(", "seqKeys", ",", "seqIdxs", ",", "center_frame_condition", ")", ":", "\n", "        ", "keys", ",", "idxs", "=", "[", "]", ",", "[", "]", "\n", "for", "key", ",", "idx", "in", "zip", "(", "seqKeys", ",", "seqIdxs", ")", ":", "\n", "            ", "if", "idx", "[", "len", "(", "idx", ")", "//", "2", "]", "in", "center_frame_condition", ":", "\n", "                ", "keys", ".", "append", "(", "key", ")", "\n", "idxs", ".", "append", "(", "idx", ")", "\n", "", "", "return", "keys", ",", "np", ".", "asarray", "(", "idxs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ahmedest61_multires-netvlad.training_tools.msls.MSLS.collate_fn": [[367, 395], ["list", "zip", "torch.dataloader.default_collate", "torch.dataloader.default_collate", "torch.dataloader.default_collate", "torch.dataloader.default_collate", "torch.dataloader.default_collate", "torch.dataloader.default_collate", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "list", "msls.MSLS.filter"], "methods", ["home.repos.pwc.inspect_result.ahmedest61_multires-netvlad.training_tools.msls.MSLS.filter"], ["", "@", "staticmethod", "\n", "def", "collate_fn", "(", "batch", ")", ":", "\n", "        ", "\"\"\"Creates mini-batch tensors from the list of tuples (query, positive, negatives).\n\n        Args:\n            batch: list of tuple (query, positive, negatives).\n                - query: torch tensor of shape (3, h, w).\n                - positive: torch tensor of shape (3, h, w).\n                - negative: torch tensor of shape (n, 3, h, w).\n        Returns:\n            query: torch tensor of shape (batch_size, 3, h, w).\n            positive: torch tensor of shape (batch_size, 3, h, w).\n            negatives: torch tensor of shape (batch_size, n, 3, h, w).\n        \"\"\"", "\n", "\n", "batch", "=", "list", "(", "filter", "(", "lambda", "x", ":", "x", "is", "not", "None", ",", "batch", ")", ")", "\n", "if", "len", "(", "batch", ")", "==", "0", ":", "\n", "            ", "return", "None", ",", "None", ",", "None", ",", "None", ",", "None", "\n", "\n", "", "query", ",", "positive", ",", "negatives", ",", "indices", "=", "zip", "(", "*", "batch", ")", "\n", "\n", "query", "=", "data", ".", "dataloader", ".", "default_collate", "(", "query", ")", "\n", "positive", "=", "data", ".", "dataloader", ".", "default_collate", "(", "positive", ")", "\n", "negCounts", "=", "data", ".", "dataloader", ".", "default_collate", "(", "[", "x", ".", "shape", "[", "0", "]", "for", "x", "in", "negatives", "]", ")", "\n", "negatives", "=", "torch", ".", "cat", "(", "negatives", ",", "0", ")", "\n", "indices", "=", "list", "(", "itertools", ".", "chain", "(", "*", "indices", ")", ")", "\n", "\n", "return", "query", ",", "positive", ",", "negatives", ",", "negCounts", ",", "indices", "\n", "\n"]], "home.repos.pwc.inspect_result.ahmedest61_multires-netvlad.training_tools.msls.MSLS.__len__": [[396, 398], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "triplets", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ahmedest61_multires-netvlad.training_tools.msls.MSLS.new_epoch": [[399, 415], ["math.ceil", "numpy.arange", "random.choices", "numpy.array_split", "len", "len", "len"], "methods", ["None"], ["", "def", "new_epoch", "(", "self", ")", ":", "\n", "\n", "# find how many subset we need to do 1 epoch", "\n", "        ", "self", ".", "nCacheSubset", "=", "math", ".", "ceil", "(", "len", "(", "self", ".", "qIdx", ")", "/", "self", ".", "cached_queries", ")", "\n", "\n", "# get all indices", "\n", "arr", "=", "np", ".", "arange", "(", "len", "(", "self", ".", "qIdx", ")", ")", "\n", "\n", "# apply positive sampling of indices", "\n", "arr", "=", "random", ".", "choices", "(", "arr", ",", "self", ".", "weights", ",", "k", "=", "len", "(", "arr", ")", ")", "\n", "\n", "# calculate the subcache indices", "\n", "self", ".", "subcache_indices", "=", "np", ".", "array_split", "(", "arr", ",", "self", ".", "nCacheSubset", ")", "\n", "\n", "# reset subset counter", "\n", "self", ".", "current_subset", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.ahmedest61_multires-netvlad.training_tools.msls.MSLS.update_subcache": [[416, 568], ["numpy.asarray", "numpy.unique", "numpy.random.choice", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "net.eval", "tqdm.tqdm.tqdm.write", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.sort", "torch.sort", "torch.sort", "torch.sort", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.sort", "torch.sort", "torch.sort", "torch.sort", "range", "numpy.random.choice", "len", "tqdm.tqdm.tqdm.write", "len", "msls.ImagesFromList", "msls.ImagesFromList", "msls.ImagesFromList", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "tqdm.tqdm.tqdm", "tqdm.tqdm.tqdm", "tqdm.tqdm.tqdm", "torch.zeros().to.t", "torch.zeros().to.t", "torch.zeros().to.t", "torch.zeros().to.t", "torch.mm.cpu().numpy", "torch.mm.cpu().numpy", "pRanks.cpu().numpy", "torch.mm.cpu().numpy", "torch.mm.cpu().numpy", "nRanks.cpu().numpy", "len", "numpy.where", "numpy.where", "msls.MSLS.triplets.append", "len", "msls.MSLS.triplets.append", "numpy.in1d", "enumerate", "net.encoder", "net.pool", "enumerate", "net.encoder", "net.pool", "enumerate", "net.encoder", "net.pool", "numpy.in1d", "numpy.in1d", "numpy.sum", "numpy.argsort", "numpy.random.choice", "numpy.random.choice", "numpy.unique", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "X.to", "X.to", "X.to", "torch.mm.cpu", "torch.mm.cpu", "pRanks.cpu", "torch.mm.cpu", "torch.mm.cpu", "nRanks.cpu", "len", "len", "sum", "len", "len", "len", "len", "len", "len", "len", "numpy.in1d"], "methods", ["None"], ["", "def", "update_subcache", "(", "self", ",", "net", "=", "None", ",", "outputdim", "=", "None", ")", ":", "\n", "\n", "# reset triplets", "\n", "        ", "self", ".", "triplets", "=", "[", "]", "\n", "\n", "# if there is no network associate to the cache, then we don't do any hard negative mining.", "\n", "# Instead we just create some naive triplets based on distance.", "\n", "if", "net", "is", "None", ":", "\n", "            ", "qidxs", "=", "np", ".", "random", ".", "choice", "(", "len", "(", "self", ".", "qIdx", ")", ",", "self", ".", "cached_queries", ",", "replace", "=", "False", ")", "\n", "\n", "for", "q", "in", "qidxs", ":", "\n", "\n", "# get query idx", "\n", "                ", "qidx", "=", "self", ".", "qIdx", "[", "q", "]", "\n", "\n", "# get positives", "\n", "pidxs", "=", "self", ".", "pIdx", "[", "q", "]", "\n", "\n", "# choose a random positive (within positive range (default 10 m))", "\n", "pidx", "=", "np", ".", "random", ".", "choice", "(", "pidxs", ",", "size", "=", "1", ")", "[", "0", "]", "\n", "\n", "# get negatives", "\n", "while", "True", ":", "\n", "                    ", "nidxs", "=", "np", ".", "random", ".", "choice", "(", "len", "(", "self", ".", "dbImages", ")", ",", "size", "=", "self", ".", "nNeg", ")", "\n", "\n", "# ensure that non of the choice negative images are within the negative range (default 25 m)", "\n", "if", "sum", "(", "np", ".", "in1d", "(", "nidxs", ",", "self", ".", "nonNegIdx", "[", "q", "]", ")", ")", "==", "0", ":", "\n", "                        ", "break", "\n", "\n", "# package the triplet and target", "\n", "", "", "triplet", "=", "[", "qidx", ",", "pidx", ",", "*", "nidxs", "]", "\n", "target", "=", "[", "-", "1", ",", "1", "]", "+", "[", "0", "]", "*", "len", "(", "nidxs", ")", "\n", "\n", "self", ".", "triplets", ".", "append", "(", "(", "triplet", ",", "target", ")", ")", "\n", "\n", "# increment subset counter", "\n", "", "self", ".", "current_subset", "+=", "1", "\n", "\n", "return", "\n", "\n", "# take n query images", "\n", "", "if", "self", ".", "current_subset", ">=", "len", "(", "self", ".", "subcache_indices", ")", ":", "\n", "            ", "tqdm", ".", "write", "(", "'Reset epoch - FIX THIS LATER!'", ")", "\n", "self", ".", "current_subset", "=", "0", "\n", "", "qidxs", "=", "np", ".", "asarray", "(", "self", ".", "subcache_indices", "[", "self", ".", "current_subset", "]", ")", "\n", "\n", "# take their positive in the database", "\n", "pidxs", "=", "np", ".", "unique", "(", "[", "i", "for", "idx", "in", "self", ".", "pIdx", "[", "qidxs", "]", "for", "i", "in", "idx", "]", ")", "\n", "\n", "# take m = 5*cached_queries is number of negative images", "\n", "nidxs", "=", "np", ".", "random", ".", "choice", "(", "len", "(", "self", ".", "dbImages", ")", ",", "self", ".", "cached_negatives", ",", "replace", "=", "False", ")", "\n", "\n", "# and make sure that there is no positives among them", "\n", "nidxs", "=", "nidxs", "[", "np", ".", "in1d", "(", "nidxs", ",", "np", ".", "unique", "(", "[", "i", "for", "idx", "in", "self", ".", "nonNegIdx", "[", "qidxs", "]", "for", "i", "in", "idx", "]", ")", ",", "invert", "=", "True", ")", "]", "\n", "\n", "# make dataloaders for query, positive and negative images", "\n", "opt", "=", "{", "'batch_size'", ":", "self", ".", "bs", ",", "'shuffle'", ":", "False", ",", "'num_workers'", ":", "self", ".", "threads", ",", "'pin_memory'", ":", "True", "}", "\n", "qloader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "ImagesFromList", "(", "self", ".", "qImages", "[", "qidxs", "]", ",", "transform", "=", "self", ".", "transform", ")", ",", "**", "opt", ")", "\n", "ploader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "ImagesFromList", "(", "self", ".", "dbImages", "[", "pidxs", "]", ",", "transform", "=", "self", ".", "transform", ")", ",", "**", "opt", ")", "\n", "nloader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "ImagesFromList", "(", "self", ".", "dbImages", "[", "nidxs", "]", ",", "transform", "=", "self", ".", "transform", ")", ",", "**", "opt", ")", "\n", "\n", "# calculate their descriptors", "\n", "net", ".", "eval", "(", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "\n", "# initialize descriptors", "\n", "            ", "qvecs", "=", "torch", ".", "zeros", "(", "len", "(", "qidxs", ")", ",", "outputdim", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "pvecs", "=", "torch", ".", "zeros", "(", "len", "(", "pidxs", ")", ",", "outputdim", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "nvecs", "=", "torch", ".", "zeros", "(", "len", "(", "nidxs", ")", ",", "outputdim", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "\n", "bs", "=", "opt", "[", "'batch_size'", "]", "\n", "\n", "# compute descriptors", "\n", "for", "i", ",", "batch", "in", "tqdm", "(", "enumerate", "(", "qloader", ")", ",", "desc", "=", "'compute query descriptors'", ",", "total", "=", "len", "(", "qidxs", ")", "//", "bs", ",", "\n", "position", "=", "2", ",", "leave", "=", "False", ")", ":", "\n", "                ", "X", ",", "y", "=", "batch", "\n", "image_encoding", "=", "net", ".", "encoder", "(", "X", ".", "to", "(", "self", ".", "device", ")", ")", "\n", "vlad_encoding", "=", "net", ".", "pool", "(", "image_encoding", ")", "\n", "qvecs", "[", "i", "*", "bs", ":", "(", "i", "+", "1", ")", "*", "bs", ",", ":", "]", "=", "vlad_encoding", "\n", "", "for", "i", ",", "batch", "in", "tqdm", "(", "enumerate", "(", "ploader", ")", ",", "desc", "=", "'compute positive descriptors'", ",", "total", "=", "len", "(", "pidxs", ")", "//", "bs", ",", "\n", "position", "=", "2", ",", "leave", "=", "False", ")", ":", "\n", "                ", "X", ",", "y", "=", "batch", "\n", "image_encoding", "=", "net", ".", "encoder", "(", "X", ".", "to", "(", "self", ".", "device", ")", ")", "\n", "vlad_encoding", "=", "net", ".", "pool", "(", "image_encoding", ")", "\n", "pvecs", "[", "i", "*", "bs", ":", "(", "i", "+", "1", ")", "*", "bs", ",", ":", "]", "=", "vlad_encoding", "\n", "", "for", "i", ",", "batch", "in", "tqdm", "(", "enumerate", "(", "nloader", ")", ",", "desc", "=", "'compute negative descriptors'", ",", "total", "=", "len", "(", "nidxs", ")", "//", "bs", ",", "\n", "position", "=", "2", ",", "leave", "=", "False", ")", ":", "\n", "                ", "X", ",", "y", "=", "batch", "\n", "image_encoding", "=", "net", ".", "encoder", "(", "X", ".", "to", "(", "self", ".", "device", ")", ")", "\n", "vlad_encoding", "=", "net", ".", "pool", "(", "image_encoding", ")", "\n", "nvecs", "[", "i", "*", "bs", ":", "(", "i", "+", "1", ")", "*", "bs", ",", ":", "]", "=", "vlad_encoding", "\n", "\n", "", "", "tqdm", ".", "write", "(", "'>> Searching for hard negatives...'", ")", "\n", "# compute dot product scores and ranks on GPU", "\n", "pScores", "=", "torch", ".", "mm", "(", "qvecs", ",", "pvecs", ".", "t", "(", ")", ")", "\n", "pScores", ",", "pRanks", "=", "torch", ".", "sort", "(", "pScores", ",", "dim", "=", "1", ",", "descending", "=", "True", ")", "\n", "\n", "# calculate distance between query and negatives", "\n", "nScores", "=", "torch", ".", "mm", "(", "qvecs", ",", "nvecs", ".", "t", "(", ")", ")", "\n", "nScores", ",", "nRanks", "=", "torch", ".", "sort", "(", "nScores", ",", "dim", "=", "1", ",", "descending", "=", "True", ")", "\n", "\n", "# convert to cpu and numpy", "\n", "pScores", ",", "pRanks", "=", "pScores", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ",", "pRanks", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "nScores", ",", "nRanks", "=", "nScores", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ",", "nRanks", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "\n", "# selection of hard triplets", "\n", "for", "q", "in", "range", "(", "len", "(", "qidxs", ")", ")", ":", "\n", "\n", "            ", "qidx", "=", "qidxs", "[", "q", "]", "\n", "\n", "# find positive idx for this query (cache idx domain)", "\n", "cached_pidx", "=", "np", ".", "where", "(", "np", ".", "in1d", "(", "pidxs", ",", "self", ".", "pIdx", "[", "qidx", "]", ")", ")", "\n", "\n", "# find idx of positive idx in rank matrix (descending cache idx domain)", "\n", "pidx", "=", "np", ".", "where", "(", "np", ".", "in1d", "(", "pRanks", "[", "q", ",", ":", "]", ",", "cached_pidx", ")", ")", "\n", "\n", "# take the closest positve", "\n", "dPos", "=", "pScores", "[", "q", ",", "pidx", "]", "[", "0", "]", "[", "0", "]", "\n", "\n", "# get distances to all negatives", "\n", "dNeg", "=", "nScores", "[", "q", ",", ":", "]", "\n", "\n", "# how much are they violating", "\n", "loss", "=", "dPos", "-", "dNeg", "+", "self", ".", "margin", "**", "0.5", "\n", "violatingNeg", "=", "0", "<", "loss", "\n", "\n", "# if less than nNeg are violating then skip this query", "\n", "if", "np", ".", "sum", "(", "violatingNeg", ")", "<=", "self", ".", "nNeg", ":", "\n", "                ", "continue", "\n", "\n", "# select hardest negatives", "\n", "", "hardest_negIdx", "=", "np", ".", "argsort", "(", "loss", ")", "[", ":", "self", ".", "nNeg", "]", "\n", "\n", "# select the hardest negatives", "\n", "cached_hardestNeg", "=", "nRanks", "[", "q", ",", "hardest_negIdx", "]", "\n", "\n", "# select the closest positive (back to cache idx domain)", "\n", "cached_pidx", "=", "pRanks", "[", "q", ",", "pidx", "]", "[", "0", "]", "[", "0", "]", "\n", "\n", "# transform back to original index (back to original idx domain)", "\n", "qidx", "=", "self", ".", "qIdx", "[", "qidx", "]", "\n", "pidx", "=", "pidxs", "[", "cached_pidx", "]", "\n", "hardestNeg", "=", "nidxs", "[", "cached_hardestNeg", "]", "\n", "\n", "# package the triplet and target", "\n", "triplet", "=", "[", "qidx", ",", "pidx", ",", "*", "hardestNeg", "]", "\n", "target", "=", "[", "-", "1", ",", "1", "]", "+", "[", "0", "]", "*", "len", "(", "hardestNeg", ")", "\n", "\n", "self", ".", "triplets", ".", "append", "(", "(", "triplet", ",", "target", ")", ")", "\n", "\n", "# increment subset counter", "\n", "", "self", ".", "current_subset", "+=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.ahmedest61_multires-netvlad.training_tools.msls.MSLS.__getitem__": [[569, 585], ["msls.MSLS.transform", "msls.MSLS.transform", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "PIL.Image.open", "PIL.Image.open", "msls.MSLS.transform", "PIL.Image.open"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "idx", ")", ":", "\n", "# get triplet", "\n", "        ", "triplet", ",", "target", "=", "self", ".", "triplets", "[", "idx", "]", "\n", "\n", "# get query, positive and negative idx", "\n", "qidx", "=", "triplet", "[", "0", "]", "\n", "pidx", "=", "triplet", "[", "1", "]", "\n", "nidx", "=", "triplet", "[", "2", ":", "]", "\n", "\n", "# load images into triplet list", "\n", "query", "=", "self", ".", "transform", "(", "Image", ".", "open", "(", "self", ".", "qImages", "[", "qidx", "]", ")", ")", "\n", "positive", "=", "self", ".", "transform", "(", "Image", ".", "open", "(", "self", ".", "dbImages", "[", "pidx", "]", ")", ")", "\n", "negatives", "=", "[", "self", ".", "transform", "(", "Image", ".", "open", "(", "self", ".", "dbImages", "[", "idx", "]", ")", ")", "for", "idx", "in", "nidx", "]", "\n", "negatives", "=", "torch", ".", "stack", "(", "negatives", ",", "0", ")", "\n", "\n", "return", "query", ",", "positive", ",", "negatives", ",", "[", "qidx", ",", "pidx", "]", "+", "nidx", "", "", "", ""]], "home.repos.pwc.inspect_result.ahmedest61_multires-netvlad.training_tools.val.val": [[41, 120], ["patchnetvlad.training_tools.msls.ImagesFromList", "patchnetvlad.training_tools.msls.ImagesFromList", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "model.eval", "tqdm.auto.tqdm.write", "faiss.IndexFlatL2", "faiss.IndexFlatL2.add", "tqdm.auto.tqdm.write", "enumerate", "numpy.zeros", "enumerate", "enumerate", "torch.no_grad", "tqdm.auto.tqdm.write", "numpy.empty", "numpy.empty", "zip", "zip", "faiss.IndexFlatL2", "faiss.IndexFlatL2.add", "faiss.IndexFlatL2.search", "len", "enumerate", "len", "tqdm.auto.tqdm.write", "patchnetvlad.tools.datasets.input_transform", "patchnetvlad.tools.datasets.input_transform", "int", "int", "[].lower", "int", "enumerate", "max", "numpy.vstack", "numpy.any", "writer.add_scalar", "len", "len", "tqdm.auto.tqdm", "input_data.to.to", "model.encoder", "model.pool", "model.pool.detach().cpu().numpy", "numpy.in1d", "str", "model.pool.detach().cpu", "indices.detach().numpy", "model.pool.detach", "indices.detach"], "function", ["home.repos.pwc.inspect_result.ahmedest61_multires-netvlad.tools.datasets.input_transform", "home.repos.pwc.inspect_result.ahmedest61_multires-netvlad.tools.datasets.input_transform"], ["def", "val", "(", "eval_set", ",", "model", ",", "encoder_dim", ",", "device", ",", "opt", ",", "config", ",", "writer", ",", "epoch_num", "=", "0", ",", "write_tboard", "=", "False", ",", "pbar_position", "=", "0", ")", ":", "\n", "    ", "if", "device", ".", "type", "==", "'cuda'", ":", "\n", "        ", "cuda", "=", "True", "\n", "", "else", ":", "\n", "        ", "cuda", "=", "False", "\n", "", "eval_set_queries", "=", "ImagesFromList", "(", "eval_set", ".", "qImages", ",", "transform", "=", "input_transform", "(", ")", ")", "\n", "eval_set_dbs", "=", "ImagesFromList", "(", "eval_set", ".", "dbImages", ",", "transform", "=", "input_transform", "(", ")", ")", "\n", "test_data_loader_queries", "=", "DataLoader", "(", "dataset", "=", "eval_set_queries", ",", "\n", "num_workers", "=", "opt", ".", "threads", ",", "batch_size", "=", "int", "(", "config", "[", "'train'", "]", "[", "'cachebatchsize'", "]", ")", ",", "\n", "shuffle", "=", "False", ",", "pin_memory", "=", "cuda", ")", "\n", "test_data_loader_dbs", "=", "DataLoader", "(", "dataset", "=", "eval_set_dbs", ",", "\n", "num_workers", "=", "opt", ".", "threads", ",", "batch_size", "=", "int", "(", "config", "[", "'train'", "]", "[", "'cachebatchsize'", "]", ")", ",", "\n", "shuffle", "=", "False", ",", "pin_memory", "=", "cuda", ")", "\n", "\n", "model", ".", "eval", "(", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "tqdm", ".", "write", "(", "'====> Extracting Features'", ")", "\n", "pool_size", "=", "encoder_dim", "\n", "if", "config", "[", "'global_params'", "]", "[", "'pooling'", "]", ".", "lower", "(", ")", "==", "'netvlad'", ":", "\n", "            ", "pool_size", "*=", "int", "(", "config", "[", "'global_params'", "]", "[", "'num_clusters'", "]", ")", "\n", "", "qFeat", "=", "np", ".", "empty", "(", "(", "len", "(", "eval_set_queries", ")", ",", "pool_size", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "dbFeat", "=", "np", ".", "empty", "(", "(", "len", "(", "eval_set_dbs", ")", ",", "pool_size", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "\n", "for", "feat", ",", "test_data_loader", "in", "zip", "(", "[", "qFeat", ",", "dbFeat", "]", ",", "[", "test_data_loader_queries", ",", "test_data_loader_dbs", "]", ")", ":", "\n", "            ", "for", "iteration", ",", "(", "input_data", ",", "indices", ")", "in", "enumerate", "(", "tqdm", "(", "test_data_loader", ",", "position", "=", "pbar_position", ",", "leave", "=", "False", ",", "desc", "=", "'Test Iter'", ".", "rjust", "(", "15", ")", ")", ",", "1", ")", ":", "\n", "                ", "input_data", "=", "input_data", ".", "to", "(", "device", ")", "\n", "image_encoding", "=", "model", ".", "encoder", "(", "input_data", ")", "\n", "\n", "vlad_encoding", "=", "model", ".", "pool", "(", "image_encoding", ")", "\n", "feat", "[", "indices", ".", "detach", "(", ")", ".", "numpy", "(", ")", ",", ":", "]", "=", "vlad_encoding", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "\n", "del", "input_data", ",", "image_encoding", ",", "vlad_encoding", "\n", "\n", "", "", "", "del", "test_data_loader_queries", ",", "test_data_loader_dbs", "\n", "\n", "tqdm", ".", "write", "(", "'====> Building faiss index'", ")", "\n", "faiss_index", "=", "faiss", ".", "IndexFlatL2", "(", "pool_size", ")", "\n", "# noinspection PyArgumentList", "\n", "faiss_index", ".", "add", "(", "dbFeat", ")", "\n", "\n", "tqdm", ".", "write", "(", "'====> Calculating recall @ N'", ")", "\n", "n_values", "=", "[", "1", ",", "5", ",", "10", ",", "20", ",", "50", ",", "100", "]", "\n", "\n", "# for each query get those within threshold distance", "\n", "gt", "=", "eval_set", ".", "all_pos_indices", "\n", "\n", "# any combination of mapillary cities will work as a val set", "\n", "qEndPosTot", "=", "0", "\n", "dbEndPosTot", "=", "0", "\n", "for", "cityNum", ",", "(", "qEndPos", ",", "dbEndPos", ")", "in", "enumerate", "(", "zip", "(", "eval_set", ".", "qEndPosList", ",", "eval_set", ".", "dbEndPosList", ")", ")", ":", "\n", "        ", "faiss_index", "=", "faiss", ".", "IndexFlatL2", "(", "pool_size", ")", "\n", "faiss_index", ".", "add", "(", "dbFeat", "[", "dbEndPosTot", ":", "dbEndPosTot", "+", "dbEndPos", ",", ":", "]", ")", "\n", "_", ",", "preds", "=", "faiss_index", ".", "search", "(", "qFeat", "[", "qEndPosTot", ":", "qEndPosTot", "+", "qEndPos", ",", ":", "]", ",", "max", "(", "n_values", ")", ")", "\n", "if", "cityNum", "==", "0", ":", "\n", "            ", "predictions", "=", "preds", "\n", "", "else", ":", "\n", "            ", "predictions", "=", "np", ".", "vstack", "(", "(", "predictions", ",", "preds", ")", ")", "\n", "", "qEndPosTot", "+=", "qEndPos", "\n", "dbEndPosTot", "+=", "dbEndPos", "\n", "\n", "", "correct_at_n", "=", "np", ".", "zeros", "(", "len", "(", "n_values", ")", ")", "\n", "# TODO can we do this on the matrix in one go?", "\n", "for", "qIx", ",", "pred", "in", "enumerate", "(", "predictions", ")", ":", "\n", "        ", "for", "i", ",", "n", "in", "enumerate", "(", "n_values", ")", ":", "\n", "# if in top N then also in top NN, where NN > N", "\n", "            ", "if", "np", ".", "any", "(", "np", ".", "in1d", "(", "pred", "[", ":", "n", "]", ",", "gt", "[", "qIx", "]", ")", ")", ":", "\n", "                ", "correct_at_n", "[", "i", ":", "]", "+=", "1", "\n", "break", "\n", "", "", "", "recall_at_n", "=", "correct_at_n", "/", "len", "(", "eval_set", ".", "qIdx", ")", "\n", "\n", "all_recalls", "=", "{", "}", "# make dict for output", "\n", "for", "i", ",", "n", "in", "enumerate", "(", "n_values", ")", ":", "\n", "        ", "all_recalls", "[", "n", "]", "=", "recall_at_n", "[", "i", "]", "\n", "tqdm", ".", "write", "(", "\"====> Recall@{}: {:.4f}\"", ".", "format", "(", "n", ",", "recall_at_n", "[", "i", "]", ")", ")", "\n", "if", "write_tboard", ":", "\n", "            ", "writer", ".", "add_scalar", "(", "'Val/Recall@'", "+", "str", "(", "n", ")", ",", "recall_at_n", "[", "i", "]", ",", "epoch_num", ")", "\n", "\n", "", "", "return", "all_recalls", "\n", "", ""]]}