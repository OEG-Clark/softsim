{"home.repos.pwc.inspect_result.astooke_rlpyt.examples.example_1.build_and_train": [[24, 52], ["rlpyt.samplers.serial.sampler.SerialSampler", "rlpyt.algos.dqn.dqn.DQN", "rlpyt.agents.dqn.atari.atari_dqn_agent.AtariDqnAgent", "rlpyt.runners.minibatch_rl.MinibatchRlEval", "dict", "rlpyt.utils.logging.context.logger_context", "rlpyt.runners.minibatch_rl.MinibatchRlEval.train", "dict", "dict", "int", "dict"], "function", ["home.repos.pwc.inspect_result.astooke_rlpyt.logging.context.logger_context", "home.repos.pwc.inspect_result.astooke_rlpyt.runners.minibatch_rl.MinibatchRlEval.train"], ["def", "build_and_train", "(", "game", "=", "\"pong\"", ",", "run_ID", "=", "0", ",", "cuda_idx", "=", "None", ")", ":", "\n", "    ", "sampler", "=", "SerialSampler", "(", "\n", "EnvCls", "=", "AtariEnv", ",", "\n", "TrajInfoCls", "=", "AtariTrajInfo", ",", "# default traj info + GameScore", "\n", "env_kwargs", "=", "dict", "(", "game", "=", "game", ")", ",", "\n", "eval_env_kwargs", "=", "dict", "(", "game", "=", "game", ")", ",", "\n", "batch_T", "=", "4", ",", "# Four time-steps per sampler iteration.", "\n", "batch_B", "=", "1", ",", "\n", "max_decorrelation_steps", "=", "0", ",", "\n", "eval_n_envs", "=", "10", ",", "\n", "eval_max_steps", "=", "int", "(", "10e3", ")", ",", "\n", "eval_max_trajectories", "=", "5", ",", "\n", ")", "\n", "algo", "=", "DQN", "(", "min_steps_learn", "=", "1e3", ")", "# Run with defaults.", "\n", "agent", "=", "AtariDqnAgent", "(", ")", "\n", "runner", "=", "MinibatchRlEval", "(", "\n", "algo", "=", "algo", ",", "\n", "agent", "=", "agent", ",", "\n", "sampler", "=", "sampler", ",", "\n", "n_steps", "=", "50e6", ",", "\n", "log_interval_steps", "=", "1e3", ",", "\n", "affinity", "=", "dict", "(", "cuda_idx", "=", "cuda_idx", ")", ",", "\n", ")", "\n", "config", "=", "dict", "(", "game", "=", "game", ")", "\n", "name", "=", "\"dqn_\"", "+", "game", "\n", "log_dir", "=", "\"example_1\"", "\n", "with", "logger_context", "(", "log_dir", ",", "run_ID", ",", "name", ",", "config", ",", "snapshot_mode", "=", "\"last\"", ")", ":", "\n", "        ", "runner", ".", "train", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.examples.atari_dqn_async_gpu.build_and_train": [[16, 63], ["rlpyt.utils.launching.affinity.make_affinity", "rlpyt.samplers.async_.gpu_sampler.AsyncGpuSampler", "rlpyt.algos.dqn.dqn.DQN", "rlpyt.agents.dqn.atari.atari_dqn_agent.AtariDqnAgent", "rlpyt.runners.async_rl.AsyncRlEval", "dict", "rlpyt.utils.logging.context.logger_context", "rlpyt.runners.async_rl.AsyncRlEval.train", "dict", "dict", "int", "int"], "function", ["home.repos.pwc.inspect_result.astooke_rlpyt.launching.affinity.make_affinity", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.context.logger_context", "home.repos.pwc.inspect_result.astooke_rlpyt.runners.minibatch_rl.MinibatchRlEval.train"], ["def", "build_and_train", "(", "game", "=", "\"pong\"", ",", "run_ID", "=", "0", ")", ":", "\n", "# Change these inputs to match local machine and desired parallelism.", "\n", "    ", "affinity", "=", "make_affinity", "(", "\n", "run_slot", "=", "0", ",", "\n", "n_cpu_core", "=", "8", ",", "# Use 16 cores across all experiments.", "\n", "n_gpu", "=", "2", ",", "# Use 8 gpus across all experiments.", "\n", "gpu_per_run", "=", "1", ",", "\n", "sample_gpu_per_run", "=", "1", ",", "\n", "async_sample", "=", "True", ",", "\n", "optim_sample_share_gpu", "=", "False", ",", "\n", "# hyperthread_offset=24,  # If machine has 24 cores.", "\n", "# n_socket=2,  # Presume CPU socket affinity to lower/upper half GPUs.", "\n", "# gpu_per_run=2,  # How many GPUs to parallelize one run across.", "\n", "# cpu_per_run=1,", "\n", ")", "\n", "\n", "sampler", "=", "AsyncGpuSampler", "(", "\n", "EnvCls", "=", "AtariEnv", ",", "\n", "TrajInfoCls", "=", "AtariTrajInfo", ",", "\n", "env_kwargs", "=", "dict", "(", "game", "=", "game", ")", ",", "\n", "batch_T", "=", "5", ",", "\n", "batch_B", "=", "36", ",", "\n", "max_decorrelation_steps", "=", "100", ",", "\n", "eval_env_kwargs", "=", "dict", "(", "game", "=", "game", ")", ",", "\n", "eval_n_envs", "=", "2", ",", "\n", "eval_max_steps", "=", "int", "(", "10e3", ")", ",", "\n", "eval_max_trajectories", "=", "4", ",", "\n", ")", "\n", "algo", "=", "DQN", "(", "\n", "replay_ratio", "=", "8", ",", "\n", "min_steps_learn", "=", "1e4", ",", "\n", "replay_size", "=", "int", "(", "1e5", ")", "\n", ")", "\n", "agent", "=", "AtariDqnAgent", "(", ")", "\n", "runner", "=", "AsyncRlEval", "(", "\n", "algo", "=", "algo", ",", "\n", "agent", "=", "agent", ",", "\n", "sampler", "=", "sampler", ",", "\n", "n_steps", "=", "2e6", ",", "\n", "log_interval_steps", "=", "1e4", ",", "\n", "affinity", "=", "affinity", ",", "\n", ")", "\n", "config", "=", "dict", "(", "game", "=", "game", ")", "\n", "name", "=", "\"async_dqn_\"", "+", "game", "\n", "log_dir", "=", "\"async_dqn\"", "\n", "with", "logger_context", "(", "log_dir", ",", "run_ID", ",", "name", ",", "config", ")", ":", "\n", "        ", "runner", ".", "train", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.examples.example_5.build_and_train": [[19, 52], ["dict", "rlpyt.samplers.parallel.gpu.sampler.GpuSampler", "rlpyt.algos.dqn.dqn.DQN", "rlpyt.agents.dqn.atari.atari_dqn_agent.AtariDqnAgent", "rlpyt.runners.minibatch_rl.MinibatchRlEval", "rlpyt.utils.logging.context.logger_context", "rlpyt.runners.minibatch_rl.MinibatchRlEval.train", "dict", "dict", "dict", "dict", "dict", "int", "dict", "list", "range"], "function", ["home.repos.pwc.inspect_result.astooke_rlpyt.logging.context.logger_context", "home.repos.pwc.inspect_result.astooke_rlpyt.runners.minibatch_rl.MinibatchRlEval.train"], ["def", "build_and_train", "(", "game", "=", "\"pong\"", ",", "run_ID", "=", "0", ",", "cuda_idx", "=", "None", ",", "n_parallel", "=", "2", ")", ":", "\n", "    ", "config", "=", "dict", "(", "\n", "env", "=", "dict", "(", "game", "=", "game", ")", ",", "\n", "algo", "=", "dict", "(", "batch_size", "=", "128", ")", ",", "\n", "sampler", "=", "dict", "(", "batch_T", "=", "2", ",", "batch_B", "=", "32", ")", ",", "\n", ")", "\n", "sampler", "=", "GpuSampler", "(", "\n", "EnvCls", "=", "AtariEnv", ",", "\n", "TrajInfoCls", "=", "AtariTrajInfo", ",", "\n", "env_kwargs", "=", "dict", "(", "game", "=", "game", ")", ",", "\n", "eval_env_kwargs", "=", "dict", "(", "game", "=", "game", ")", ",", "\n", "max_decorrelation_steps", "=", "0", ",", "\n", "eval_n_envs", "=", "10", ",", "\n", "eval_max_steps", "=", "int", "(", "10e3", ")", ",", "\n", "eval_max_trajectories", "=", "5", ",", "\n", "# batch_T=4,  # Get from config.", "\n", "# batch_B=1,", "\n", "**", "config", "[", "\"sampler\"", "]", "# More parallel environments for batched forward-pass.", "\n", ")", "\n", "algo", "=", "DQN", "(", "**", "config", "[", "\"algo\"", "]", ")", "# Run with defaults.", "\n", "agent", "=", "AtariDqnAgent", "(", ")", "\n", "runner", "=", "MinibatchRlEval", "(", "\n", "algo", "=", "algo", ",", "\n", "agent", "=", "agent", ",", "\n", "sampler", "=", "sampler", ",", "\n", "n_steps", "=", "50e6", ",", "\n", "log_interval_steps", "=", "1e3", ",", "\n", "affinity", "=", "dict", "(", "cuda_idx", "=", "cuda_idx", ",", "workers_cpus", "=", "list", "(", "range", "(", "n_parallel", ")", ")", ")", ",", "\n", ")", "\n", "name", "=", "\"dqn_\"", "+", "game", "\n", "log_dir", "=", "\"example_5\"", "\n", "with", "logger_context", "(", "log_dir", ",", "run_ID", ",", "name", ",", "config", ")", ":", "\n", "        ", "runner", ".", "train", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.examples.example_4.build_and_train": [[28, 57], ["dict", "print", "rlpyt.samplers.parallel.gpu.sampler.GpuSampler", "rlpyt.algos.pg.a2c.A2C", "rlpyt.agents.pg.atari.AtariLstmAgent", "rlpyt.runners.minibatch_rl.MinibatchRl", "dict", "rlpyt.utils.logging.context.logger_context", "rlpyt.runners.minibatch_rl.MinibatchRl.train", "list", "dict", "range"], "function", ["home.repos.pwc.inspect_result.astooke_rlpyt.logging.context.logger_context", "home.repos.pwc.inspect_result.astooke_rlpyt.runners.minibatch_rl.MinibatchRlEval.train"], ["def", "build_and_train", "(", "game", "=", "\"pong\"", ",", "run_ID", "=", "0", ",", "cuda_idx", "=", "None", ",", "mid_batch_reset", "=", "False", ",", "n_parallel", "=", "2", ")", ":", "\n", "    ", "affinity", "=", "dict", "(", "cuda_idx", "=", "cuda_idx", ",", "workers_cpus", "=", "list", "(", "range", "(", "n_parallel", ")", ")", ")", "\n", "Collector", "=", "GpuResetCollector", "if", "mid_batch_reset", "else", "GpuWaitResetCollector", "\n", "print", "(", "f\"To satisfy mid_batch_reset=={mid_batch_reset}, using {Collector}.\"", ")", "\n", "\n", "sampler", "=", "GpuSampler", "(", "\n", "EnvCls", "=", "AtariEnv", ",", "\n", "TrajInfoCls", "=", "AtariTrajInfo", ",", "\n", "env_kwargs", "=", "dict", "(", "game", "=", "game", ",", "num_img_obs", "=", "1", ")", ",", "# Learn on individual frames.", "\n", "CollectorCls", "=", "Collector", ",", "\n", "batch_T", "=", "20", ",", "# Longer sampling/optimization horizon for recurrence.", "\n", "batch_B", "=", "16", ",", "# 16 parallel environments.", "\n", "max_decorrelation_steps", "=", "400", ",", "\n", ")", "\n", "algo", "=", "A2C", "(", ")", "# Run with defaults.", "\n", "agent", "=", "AtariLstmAgent", "(", ")", "\n", "runner", "=", "MinibatchRl", "(", "\n", "algo", "=", "algo", ",", "\n", "agent", "=", "agent", ",", "\n", "sampler", "=", "sampler", ",", "\n", "n_steps", "=", "50e6", ",", "\n", "log_interval_steps", "=", "1e5", ",", "\n", "affinity", "=", "affinity", ",", "\n", ")", "\n", "config", "=", "dict", "(", "game", "=", "game", ")", "\n", "name", "=", "\"a2c_\"", "+", "game", "\n", "log_dir", "=", "\"example_4\"", "\n", "with", "logger_context", "(", "log_dir", ",", "run_ID", ",", "name", ",", "config", ")", ":", "\n", "        ", "runner", ".", "train", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.examples.example_2.build_and_train": [[21, 48], ["rlpyt.samplers.serial.sampler.SerialSampler", "rlpyt.algos.qpg.sac.SAC", "rlpyt.agents.qpg.sac_agent.SacAgent", "rlpyt.runners.minibatch_rl.MinibatchRlEval", "dict", "rlpyt.utils.logging.context.logger_context", "rlpyt.runners.minibatch_rl.MinibatchRlEval.train", "dict", "dict", "int", "dict"], "function", ["home.repos.pwc.inspect_result.astooke_rlpyt.logging.context.logger_context", "home.repos.pwc.inspect_result.astooke_rlpyt.runners.minibatch_rl.MinibatchRlEval.train"], ["def", "build_and_train", "(", "env_id", "=", "\"Hopper-v3\"", ",", "run_ID", "=", "0", ",", "cuda_idx", "=", "None", ")", ":", "\n", "    ", "sampler", "=", "SerialSampler", "(", "\n", "EnvCls", "=", "gym_make", ",", "\n", "env_kwargs", "=", "dict", "(", "id", "=", "env_id", ")", ",", "\n", "eval_env_kwargs", "=", "dict", "(", "id", "=", "env_id", ")", ",", "\n", "batch_T", "=", "1", ",", "# One time-step per sampler iteration.", "\n", "batch_B", "=", "1", ",", "# One environment (i.e. sampler Batch dimension).", "\n", "max_decorrelation_steps", "=", "0", ",", "\n", "eval_n_envs", "=", "10", ",", "\n", "eval_max_steps", "=", "int", "(", "51e3", ")", ",", "\n", "eval_max_trajectories", "=", "50", ",", "\n", ")", "\n", "algo", "=", "SAC", "(", ")", "# Run with defaults.", "\n", "agent", "=", "SacAgent", "(", ")", "\n", "runner", "=", "MinibatchRlEval", "(", "\n", "algo", "=", "algo", ",", "\n", "agent", "=", "agent", ",", "\n", "sampler", "=", "sampler", ",", "\n", "n_steps", "=", "1e6", ",", "\n", "log_interval_steps", "=", "1e4", ",", "\n", "affinity", "=", "dict", "(", "cuda_idx", "=", "cuda_idx", ")", ",", "\n", ")", "\n", "config", "=", "dict", "(", "env_id", "=", "env_id", ")", "\n", "name", "=", "\"sac_\"", "+", "env_id", "\n", "log_dir", "=", "\"example_2\"", "\n", "with", "logger_context", "(", "log_dir", ",", "run_ID", ",", "name", ",", "config", ")", ":", "\n", "        ", "runner", ".", "train", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.examples.example_7.build_and_train": [[28, 66], ["rlpyt.utils.launching.affinity.make_affinity", "rlpyt.samplers.parallel.gpu.sampler.GpuSampler", "rlpyt.algos.pg.a2c.A2C", "rlpyt.agents.pg.atari.AtariFfAgent", "rlpyt.runners.sync_rl.SyncRl", "dict", "rlpyt.utils.logging.context.logger_context", "rlpyt.runners.sync_rl.SyncRl.train", "dict"], "function", ["home.repos.pwc.inspect_result.astooke_rlpyt.launching.affinity.make_affinity", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.context.logger_context", "home.repos.pwc.inspect_result.astooke_rlpyt.runners.minibatch_rl.MinibatchRlEval.train"], ["def", "build_and_train", "(", "game", "=", "\"pong\"", ",", "run_ID", "=", "0", ")", ":", "\n", "# Seems like we should be able to skip the intermediate step of the code,", "\n", "# but so far have just always run that way.", "\n", "# Change these inputs to match local machine and desired parallelism.", "\n", "    ", "affinity", "=", "make_affinity", "(", "\n", "run_slot", "=", "0", ",", "\n", "n_cpu_core", "=", "16", ",", "# Use 16 cores across all experiments.", "\n", "n_gpu", "=", "8", ",", "# Use 8 gpus across all experiments.", "\n", "hyperthread_offset", "=", "24", ",", "# If machine has 24 cores.", "\n", "n_socket", "=", "2", ",", "# Presume CPU socket affinity to lower/upper half GPUs.", "\n", "gpu_per_run", "=", "2", ",", "# How many GPUs to parallelize one run across.", "\n", "# cpu_per_run=1,", "\n", ")", "\n", "\n", "sampler", "=", "GpuSampler", "(", "\n", "EnvCls", "=", "AtariEnv", ",", "\n", "TrajInfoCls", "=", "AtariTrajInfo", ",", "\n", "env_kwargs", "=", "dict", "(", "game", "=", "game", ")", ",", "\n", "CollectorCls", "=", "GpuWaitResetCollector", ",", "\n", "batch_T", "=", "5", ",", "\n", "batch_B", "=", "16", ",", "\n", "max_decorrelation_steps", "=", "400", ",", "\n", ")", "\n", "algo", "=", "A2C", "(", ")", "# Run with defaults.", "\n", "agent", "=", "AtariFfAgent", "(", ")", "\n", "runner", "=", "SyncRl", "(", "\n", "algo", "=", "algo", ",", "\n", "agent", "=", "agent", ",", "\n", "sampler", "=", "sampler", ",", "\n", "n_steps", "=", "50e6", ",", "\n", "log_interval_steps", "=", "1e5", ",", "\n", "affinity", "=", "affinity", ",", "\n", ")", "\n", "config", "=", "dict", "(", "game", "=", "game", ")", "\n", "name", "=", "\"a2c_\"", "+", "game", "\n", "log_dir", "=", "\"example_7\"", "\n", "with", "logger_context", "(", "log_dir", ",", "run_ID", ",", "name", ",", "config", ")", ":", "\n", "        ", "runner", ".", "train", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.examples.atari_dqn_async_serial.build_and_train": [[19, 65], ["rlpyt.utils.launching.affinity.make_affinity", "rlpyt.samplers.async_.serial_sampler.AsyncSerialSampler", "rlpyt.algos.dqn.dqn.DQN", "rlpyt.agents.dqn.atari.atari_dqn_agent.AtariDqnAgent", "rlpyt.runners.async_rl.AsyncRlEval", "dict", "rlpyt.utils.logging.context.logger_context", "rlpyt.runners.async_rl.AsyncRlEval.train", "dict", "dict", "int", "int"], "function", ["home.repos.pwc.inspect_result.astooke_rlpyt.launching.affinity.make_affinity", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.context.logger_context", "home.repos.pwc.inspect_result.astooke_rlpyt.runners.minibatch_rl.MinibatchRlEval.train"], ["def", "build_and_train", "(", "game", "=", "\"pong\"", ",", "run_ID", "=", "0", ")", ":", "\n", "# Change these inputs to match local machine and desired parallelism.", "\n", "    ", "affinity", "=", "make_affinity", "(", "\n", "run_slot", "=", "0", ",", "\n", "n_cpu_core", "=", "2", ",", "# Use 16 cores across all experiments.", "\n", "n_gpu", "=", "1", ",", "# Use 8 gpus across all experiments.", "\n", "sample_gpu_per_run", "=", "0", ",", "\n", "async_sample", "=", "True", ",", "# Different affinity structure fo async.", "\n", "# hyperthread_offset=24,  # If machine has 24 cores.", "\n", "# n_socket=2,  # Presume CPU socket affinity to lower/upper half GPUs.", "\n", "# gpu_per_run=2,  # How many optimizer GPUs to parallelize one run.", "\n", "# cpu_per_run=1,", "\n", ")", "\n", "\n", "sampler", "=", "AsyncSerialSampler", "(", "\n", "EnvCls", "=", "AtariEnv", ",", "\n", "TrajInfoCls", "=", "AtariTrajInfo", ",", "\n", "env_kwargs", "=", "dict", "(", "game", "=", "game", ")", ",", "\n", "CollectorCls", "=", "DbCpuResetCollector", ",", "\n", "batch_T", "=", "5", ",", "\n", "batch_B", "=", "4", ",", "\n", "max_decorrelation_steps", "=", "100", ",", "\n", "eval_env_kwargs", "=", "dict", "(", "game", "=", "game", ")", ",", "\n", "eval_n_envs", "=", "1", ",", "\n", "eval_max_steps", "=", "int", "(", "10e3", ")", ",", "\n", "eval_max_trajectories", "=", "2", ",", "\n", ")", "\n", "algo", "=", "DQN", "(", "\n", "replay_ratio", "=", "18", ",", "\n", "min_steps_learn", "=", "5e3", ",", "\n", "replay_size", "=", "int", "(", "1e5", ")", "\n", ")", "\n", "agent", "=", "AtariDqnAgent", "(", ")", "\n", "runner", "=", "AsyncRlEval", "(", "\n", "algo", "=", "algo", ",", "\n", "agent", "=", "agent", ",", "\n", "sampler", "=", "sampler", ",", "\n", "n_steps", "=", "2e6", ",", "\n", "log_interval_steps", "=", "5e3", ",", "\n", "affinity", "=", "affinity", ",", "\n", ")", "\n", "config", "=", "dict", "(", "game", "=", "game", ")", "\n", "name", "=", "\"async_dqn_\"", "+", "game", "\n", "log_dir", "=", "\"async_dqn\"", "\n", "with", "logger_context", "(", "log_dir", ",", "run_ID", ",", "name", ",", "config", ")", ":", "\n", "        ", "runner", ".", "train", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.examples.atari_dqn_async_cpu.build_and_train": [[16, 61], ["rlpyt.utils.launching.affinity.make_affinity", "rlpyt.samplers.async_.cpu_sampler.AsyncCpuSampler", "rlpyt.algos.dqn.dqn.DQN", "rlpyt.agents.dqn.atari.atari_dqn_agent.AtariDqnAgent", "rlpyt.runners.async_rl.AsyncRlEval", "dict", "rlpyt.utils.logging.context.logger_context", "rlpyt.runners.async_rl.AsyncRlEval.train", "dict", "dict", "int", "int"], "function", ["home.repos.pwc.inspect_result.astooke_rlpyt.launching.affinity.make_affinity", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.context.logger_context", "home.repos.pwc.inspect_result.astooke_rlpyt.runners.minibatch_rl.MinibatchRlEval.train"], ["def", "build_and_train", "(", "game", "=", "\"pong\"", ",", "run_ID", "=", "0", ")", ":", "\n", "# Change these inputs to match local machine and desired parallelism.", "\n", "    ", "affinity", "=", "make_affinity", "(", "\n", "run_slot", "=", "0", ",", "\n", "n_cpu_core", "=", "3", ",", "# Use 16 cores across all experiments.", "\n", "n_gpu", "=", "1", ",", "# Use 8 gpus across all experiments.", "\n", "sample_gpu_per_run", "=", "0", ",", "\n", "async_sample", "=", "True", ",", "\n", "# hyperthread_offset=24,  # If machine has 24 cores.", "\n", "# n_socket=2,  # Presume CPU socket affinity to lower/upper half GPUs.", "\n", "# gpu_per_run=2,  # How many GPUs to parallelize one run across.", "\n", "# cpu_per_run=1,", "\n", ")", "\n", "\n", "sampler", "=", "AsyncCpuSampler", "(", "\n", "EnvCls", "=", "AtariEnv", ",", "\n", "TrajInfoCls", "=", "AtariTrajInfo", ",", "\n", "env_kwargs", "=", "dict", "(", "game", "=", "game", ")", ",", "\n", "batch_T", "=", "5", ",", "\n", "batch_B", "=", "8", ",", "\n", "max_decorrelation_steps", "=", "100", ",", "\n", "eval_env_kwargs", "=", "dict", "(", "game", "=", "game", ")", ",", "\n", "eval_n_envs", "=", "2", ",", "\n", "eval_max_steps", "=", "int", "(", "10e3", ")", ",", "\n", "eval_max_trajectories", "=", "4", ",", "\n", ")", "\n", "algo", "=", "DQN", "(", "\n", "replay_ratio", "=", "8", ",", "\n", "min_steps_learn", "=", "1e4", ",", "\n", "replay_size", "=", "int", "(", "1e5", ")", "\n", ")", "\n", "agent", "=", "AtariDqnAgent", "(", ")", "\n", "runner", "=", "AsyncRlEval", "(", "\n", "algo", "=", "algo", ",", "\n", "agent", "=", "agent", ",", "\n", "sampler", "=", "sampler", ",", "\n", "n_steps", "=", "2e6", ",", "\n", "log_interval_steps", "=", "1e4", ",", "\n", "affinity", "=", "affinity", ",", "\n", ")", "\n", "config", "=", "dict", "(", "game", "=", "game", ")", "\n", "name", "=", "\"async_dqn_\"", "+", "game", "\n", "log_dir", "=", "\"async_dqn\"", "\n", "with", "logger_context", "(", "log_dir", ",", "run_ID", ",", "name", ",", "config", ")", ":", "\n", "        ", "runner", ".", "train", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.examples.example_6a.build_and_train": [[22, 59], ["dict", "rlpyt.utils.launching.affinity.affinity_from_code", "rlpyt.utils.launching.variant.load_variant", "rlpyt.utils.launching.variant.update_config", "rlpyt.samplers.parallel.gpu.sampler.GpuSampler", "rlpyt.algos.pg.a2c.A2C", "rlpyt.agents.pg.atari.AtariFfAgent", "rlpyt.runners.minibatch_rl.MinibatchRl", "rlpyt.utils.logging.context.logger_context", "rlpyt.runners.minibatch_rl.MinibatchRl.train", "dict", "dict", "dict"], "function", ["home.repos.pwc.inspect_result.astooke_rlpyt.launching.affinity.affinity_from_code", "home.repos.pwc.inspect_result.astooke_rlpyt.launching.variant.load_variant", "home.repos.pwc.inspect_result.astooke_rlpyt.launching.variant.update_config", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.context.logger_context", "home.repos.pwc.inspect_result.astooke_rlpyt.runners.minibatch_rl.MinibatchRlEval.train"], ["def", "build_and_train", "(", "slot_affinity_code", ",", "log_dir", ",", "run_ID", ")", ":", "\n", "# (Or load from a central store of configs.)", "\n", "    ", "config", "=", "dict", "(", "\n", "env", "=", "dict", "(", "game", "=", "\"pong\"", ")", ",", "\n", "algo", "=", "dict", "(", "learning_rate", "=", "7e-4", ")", ",", "\n", "sampler", "=", "dict", "(", "batch_B", "=", "16", ")", ",", "\n", ")", "\n", "\n", "affinity", "=", "affinity_from_code", "(", "slot_affinity_code", ")", "\n", "variant", "=", "load_variant", "(", "log_dir", ")", "\n", "global", "config", "\n", "config", "=", "update_config", "(", "config", ",", "variant", ")", "\n", "\n", "sampler", "=", "GpuSampler", "(", "\n", "EnvCls", "=", "AtariEnv", ",", "\n", "TrajInfoCls", "=", "AtariTrajInfo", ",", "\n", "env_kwargs", "=", "config", "[", "\"env\"", "]", ",", "\n", "CollectorCls", "=", "GpuWaitResetCollector", ",", "\n", "batch_T", "=", "5", ",", "\n", "# batch_B=16,  # Get from config.", "\n", "max_decorrelation_steps", "=", "400", ",", "\n", "**", "config", "[", "\"sampler\"", "]", "\n", ")", "\n", "algo", "=", "A2C", "(", "**", "config", "[", "\"algo\"", "]", ")", "# Run with defaults.", "\n", "agent", "=", "AtariFfAgent", "(", ")", "\n", "runner", "=", "MinibatchRl", "(", "\n", "algo", "=", "algo", ",", "\n", "agent", "=", "agent", ",", "\n", "sampler", "=", "sampler", ",", "\n", "n_steps", "=", "50e6", ",", "\n", "log_interval_steps", "=", "1e5", ",", "\n", "affinity", "=", "affinity", ",", "\n", ")", "\n", "name", "=", "\"a2c_\"", "+", "config", "[", "\"env\"", "]", "[", "\"game\"", "]", "\n", "log_dir", "=", "\"example_6\"", "\n", "with", "logger_context", "(", "log_dir", ",", "run_ID", ",", "name", ",", "config", ")", ":", "\n", "        ", "runner", ".", "train", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.examples.example_3.build_and_train": [[23, 64], ["dict", "Sampler", "rlpyt.algos.pg.a2c.A2C", "rlpyt.agents.pg.atari.AtariFfAgent", "rlpyt.runners.minibatch_rl.MinibatchRl", "dict", "print", "rlpyt.utils.logging.context.logger_context", "rlpyt.runners.minibatch_rl.MinibatchRl.train", "list", "print", "dict", "range", "print", "print"], "function", ["home.repos.pwc.inspect_result.astooke_rlpyt.logging.context.logger_context", "home.repos.pwc.inspect_result.astooke_rlpyt.runners.minibatch_rl.MinibatchRlEval.train"], ["def", "build_and_train", "(", "game", "=", "\"pong\"", ",", "run_ID", "=", "0", ",", "cuda_idx", "=", "None", ",", "sample_mode", "=", "\"serial\"", ",", "n_parallel", "=", "2", ")", ":", "\n", "    ", "affinity", "=", "dict", "(", "cuda_idx", "=", "cuda_idx", ",", "workers_cpus", "=", "list", "(", "range", "(", "n_parallel", ")", ")", ")", "\n", "gpu_cpu", "=", "\"CPU\"", "if", "cuda_idx", "is", "None", "else", "f\"GPU {cuda_idx}\"", "\n", "if", "sample_mode", "==", "\"serial\"", ":", "\n", "        ", "Sampler", "=", "SerialSampler", "# (Ignores workers_cpus.)", "\n", "print", "(", "f\"Using serial sampler, {gpu_cpu} for sampling and optimizing.\"", ")", "\n", "", "elif", "sample_mode", "==", "\"cpu\"", ":", "\n", "        ", "Sampler", "=", "CpuSampler", "\n", "print", "(", "f\"Using CPU parallel sampler (agent in workers), {gpu_cpu} for optimizing.\"", ")", "\n", "", "elif", "sample_mode", "==", "\"gpu\"", ":", "\n", "        ", "Sampler", "=", "GpuSampler", "\n", "print", "(", "f\"Using GPU parallel sampler (agent in master), {gpu_cpu} for sampling and optimizing.\"", ")", "\n", "", "elif", "sample_mode", "==", "\"alternating\"", ":", "\n", "        ", "Sampler", "=", "AlternatingSampler", "\n", "affinity", "[", "\"workers_cpus\"", "]", "+=", "affinity", "[", "\"workers_cpus\"", "]", "# (Double list)", "\n", "affinity", "[", "\"alternating\"", "]", "=", "True", "# Sampler will check for this.", "\n", "print", "(", "f\"Using Alternating GPU parallel sampler, {gpu_cpu} for sampling and optimizing.\"", ")", "\n", "\n", "", "sampler", "=", "Sampler", "(", "\n", "EnvCls", "=", "AtariEnv", ",", "\n", "TrajInfoCls", "=", "AtariTrajInfo", ",", "\n", "env_kwargs", "=", "dict", "(", "game", "=", "game", ")", ",", "\n", "batch_T", "=", "5", ",", "# 5 time-steps per sampler iteration.", "\n", "batch_B", "=", "16", ",", "# 16 parallel environments.", "\n", "max_decorrelation_steps", "=", "400", ",", "\n", ")", "\n", "algo", "=", "A2C", "(", ")", "# Run with defaults.", "\n", "agent", "=", "AtariFfAgent", "(", ")", "\n", "runner", "=", "MinibatchRl", "(", "\n", "algo", "=", "algo", ",", "\n", "agent", "=", "agent", ",", "\n", "sampler", "=", "sampler", ",", "\n", "n_steps", "=", "50e6", ",", "\n", "log_interval_steps", "=", "1e5", ",", "\n", "affinity", "=", "affinity", ",", "\n", ")", "\n", "config", "=", "dict", "(", "game", "=", "game", ")", "\n", "name", "=", "\"a2c_\"", "+", "game", "\n", "log_dir", "=", "\"example_3\"", "\n", "with", "logger_context", "(", "log_dir", ",", "run_ID", ",", "name", ",", "config", ")", ":", "\n", "        ", "runner", ".", "train", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.algos.base.RlAlgorithm.initialize": [[14, 29], ["None"], "methods", ["None"], ["def", "initialize", "(", "self", ",", "agent", ",", "n_itr", ",", "batch_spec", ",", "mid_batch_reset", ",", "examples", ",", "\n", "world_size", "=", "1", ",", "rank", "=", "0", ")", ":", "\n", "        ", "\"\"\"\n        Typically called in the runner during startup.\n        \n        Args:\n            agent: The learning agent instance.\n            n_itr (int): Number of training loop iterations which will be run (e.g. corresponds to each call of ``optimize_agent()``)\n            batch_spec: Holds sampler batch dimensions.\n            mid_batch_reset (bool): Whether the sampler resets environments during a sampling batch (``True``) or only between batches (``False``).  Affects whether some samples are invalid for training.\n            examples:  Structure of example RL quantities, e.g. observation, action, agent_info, env_info, e.g. in case needed to allocate replay buffer.\n            world_size (int): Number of separate optimizing processes (e.g. multi-GPU).\n            rank (int): Unique index for each optimizing process.\n        \"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.algos.base.RlAlgorithm.async_initialize": [[30, 36], ["None"], "methods", ["None"], ["", "def", "async_initialize", "(", "self", ",", "agent", ",", "sampler_n_itr", ",", "batch_spec", ",", "mid_batch_reset", ",", "\n", "examples", ",", "world_size", "=", "1", ")", ":", "\n", "        ", "\"\"\"Called instead of ``initialize()`` in async runner (not needed unless\n        using async runner). Should return async replay_buffer using shared\n        memory.\"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.algos.base.RlAlgorithm.optim_initialize": [[37, 41], ["None"], "methods", ["None"], ["", "def", "optim_initialize", "(", "self", ",", "rank", "=", "0", ")", ":", "\n", "        ", "\"\"\"Called in async runner which requires two stages of initialization;\n        might also be used in ``initialize()`` to avoid redundant code.\"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.algos.base.RlAlgorithm.optimize_agent": [[42, 55], ["None"], "methods", ["None"], ["", "def", "optimize_agent", "(", "self", ",", "itr", ",", "samples", "=", "None", ",", "sampler_itr", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Train the agent for some number of parameter updates, e.g. either\n        using new samples or a replay buffer.\n\n        Typically called in the runner's training loop.\n\n        Args:\n            itr (int): Iteration of the training loop.\n            samples: New samples from the sampler (for ``None`` case, see async runner).\n            sampler_itr:  For case other than ``None``, see async runner.\n        \"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.algos.base.RlAlgorithm.optim_state_dict": [[56, 60], ["base.RlAlgorithm.optimizer.state_dict"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.replay_saver.DummyOptimizer.state_dict"], ["", "def", "optim_state_dict", "(", "self", ")", ":", "\n", "        ", "\"\"\"Return the optimizer state dict (e.g. Adam); overwrite if using\n        multiple optimizers.\"\"\"", "\n", "return", "self", ".", "optimizer", ".", "state_dict", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.algos.base.RlAlgorithm.load_optim_state_dict": [[61, 65], ["base.RlAlgorithm.optimizer.load_state_dict"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.augmented_temporal_similarity.AugmentedTemporalSimilarity.load_state_dict"], ["", "def", "load_optim_state_dict", "(", "self", ",", "state_dict", ")", ":", "\n", "        ", "\"\"\"Load an optimizer state dict; should expect the format returned\n        from ``optim_state_dict().``\"\"\"", "\n", "self", ".", "optimizer", ".", "load_state_dict", "(", "state_dict", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.algos.base.RlAlgorithm.batch_size": [[66, 69], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "batch_size", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_batch_size", "# For logging at least.", "\n", "", "", ""]], "home.repos.pwc.inspect_result.astooke_rlpyt.algos.utils.discount_return": [[8, 22], ["reversed", "rlpyt.utils.misc.zeros", "isinstance", "nd.type", "range", "len"], "function", ["home.repos.pwc.inspect_result.astooke_rlpyt.utils.misc.zeros"], ["def", "discount_return", "(", "reward", ",", "done", ",", "bootstrap_value", ",", "discount", ",", "return_dest", "=", "None", ")", ":", "\n", "    ", "\"\"\"Time-major inputs, optional other dimensions: [T], [T,B], etc. Computes\n    discounted sum of future rewards from each time-step to the end of the\n    batch, including bootstrapping value.  Sum resets where `done` is 1.\n    Optionally, writes to buffer `return_dest`, if provided.  Operations\n    vectorized across all trailing dimensions after the first [T,].\"\"\"", "\n", "return_", "=", "return_dest", "if", "return_dest", "is", "not", "None", "else", "zeros", "(", "\n", "reward", ".", "shape", ",", "dtype", "=", "reward", ".", "dtype", ")", "\n", "nd", "=", "1", "-", "done", "\n", "nd", "=", "nd", ".", "type", "(", "reward", ".", "dtype", ")", "if", "isinstance", "(", "nd", ",", "torch", ".", "Tensor", ")", "else", "nd", "\n", "return_", "[", "-", "1", "]", "=", "reward", "[", "-", "1", "]", "+", "discount", "*", "bootstrap_value", "*", "nd", "[", "-", "1", "]", "\n", "for", "t", "in", "reversed", "(", "range", "(", "len", "(", "reward", ")", "-", "1", ")", ")", ":", "\n", "        ", "return_", "[", "t", "]", "=", "reward", "[", "t", "]", "+", "return_", "[", "t", "+", "1", "]", "*", "discount", "*", "nd", "[", "t", "]", "\n", "", "return", "return_", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.algos.utils.generalized_advantage_estimation": [[24, 41], ["reversed", "rlpyt.utils.misc.zeros", "rlpyt.utils.misc.zeros", "isinstance", "nd.type", "range", "len"], "function", ["home.repos.pwc.inspect_result.astooke_rlpyt.utils.misc.zeros", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.misc.zeros"], ["", "def", "generalized_advantage_estimation", "(", "reward", ",", "value", ",", "done", ",", "bootstrap_value", ",", "\n", "discount", ",", "gae_lambda", ",", "advantage_dest", "=", "None", ",", "return_dest", "=", "None", ")", ":", "\n", "    ", "\"\"\"Time-major inputs, optional other dimensions: [T], [T,B], etc.  Similar\n    to `discount_return()` but using Generalized Advantage Estimation to\n    compute advantages and returns.\"\"\"", "\n", "advantage", "=", "advantage_dest", "if", "advantage_dest", "is", "not", "None", "else", "zeros", "(", "\n", "reward", ".", "shape", ",", "dtype", "=", "reward", ".", "dtype", ")", "\n", "return_", "=", "return_dest", "if", "return_dest", "is", "not", "None", "else", "zeros", "(", "\n", "reward", ".", "shape", ",", "dtype", "=", "reward", ".", "dtype", ")", "\n", "nd", "=", "1", "-", "done", "\n", "nd", "=", "nd", ".", "type", "(", "reward", ".", "dtype", ")", "if", "isinstance", "(", "nd", ",", "torch", ".", "Tensor", ")", "else", "nd", "\n", "advantage", "[", "-", "1", "]", "=", "reward", "[", "-", "1", "]", "+", "discount", "*", "bootstrap_value", "*", "nd", "[", "-", "1", "]", "-", "value", "[", "-", "1", "]", "\n", "for", "t", "in", "reversed", "(", "range", "(", "len", "(", "reward", ")", "-", "1", ")", ")", ":", "\n", "        ", "delta", "=", "reward", "[", "t", "]", "+", "discount", "*", "value", "[", "t", "+", "1", "]", "*", "nd", "[", "t", "]", "-", "value", "[", "t", "]", "\n", "advantage", "[", "t", "]", "=", "delta", "+", "discount", "*", "gae_lambda", "*", "nd", "[", "t", "]", "*", "advantage", "[", "t", "+", "1", "]", "\n", "", "return_", "[", ":", "]", "=", "advantage", "+", "value", "\n", "return", "advantage", ",", "return_", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.algos.utils.discount_return_n_step": [[67, 102], ["isinstance", "rlpyt.utils.misc.zeros", "rlpyt.utils.misc.zeros", "done_n.type.type", "done.type.type", "done_n.type.type", "range", "range", "numpy.maximum", "numpy.maximum"], "function", ["home.repos.pwc.inspect_result.astooke_rlpyt.utils.misc.zeros", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.misc.zeros"], ["", "def", "discount_return_n_step", "(", "reward", ",", "done", ",", "n_step", ",", "discount", ",", "return_dest", "=", "None", ",", "\n", "done_n_dest", "=", "None", ",", "do_truncated", "=", "False", ")", ":", "\n", "    ", "\"\"\"Time-major inputs, optional other dimension: [T], [T,B], etc.  Computes\n    n-step discounted returns within the timeframe of the of given rewards. If\n    `do_truncated==False`, then only compute at time-steps with full n-step\n    future rewards are provided (i.e. not at last n-steps--output shape will\n    change!).  Returns n-step returns as well as n-step done signals, which is\n    True if `done=True` at any future time before the n-step target bootstrap\n    would apply (bootstrap in the algo, not here).\"\"\"", "\n", "rlen", "=", "reward", ".", "shape", "[", "0", "]", "\n", "if", "not", "do_truncated", ":", "\n", "        ", "rlen", "-=", "(", "n_step", "-", "1", ")", "\n", "", "return_", "=", "return_dest", "if", "return_dest", "is", "not", "None", "else", "zeros", "(", "\n", "(", "rlen", ",", ")", "+", "reward", ".", "shape", "[", "1", ":", "]", ",", "dtype", "=", "reward", ".", "dtype", ")", "\n", "done_n", "=", "done_n_dest", "if", "done_n_dest", "is", "not", "None", "else", "zeros", "(", "\n", "(", "rlen", ",", ")", "+", "reward", ".", "shape", "[", "1", ":", "]", ",", "dtype", "=", "done", ".", "dtype", ")", "\n", "return_", "[", ":", "]", "=", "reward", "[", ":", "rlen", "]", "# 1-step return is current reward.", "\n", "done_n", "[", ":", "]", "=", "done", "[", ":", "rlen", "]", "# True at time t if done any time by t + n - 1", "\n", "is_torch", "=", "isinstance", "(", "done", ",", "torch", ".", "Tensor", ")", "\n", "if", "is_torch", ":", "\n", "        ", "done_dtype", "=", "done", ".", "dtype", "\n", "done_n", "=", "done_n", ".", "type", "(", "reward", ".", "dtype", ")", "\n", "done", "=", "done", ".", "type", "(", "reward", ".", "dtype", ")", "\n", "", "if", "n_step", ">", "1", ":", "\n", "        ", "if", "do_truncated", ":", "\n", "            ", "for", "n", "in", "range", "(", "1", ",", "n_step", ")", ":", "\n", "                ", "return_", "[", ":", "-", "n", "]", "+=", "(", "discount", "**", "n", ")", "*", "reward", "[", "n", ":", "n", "+", "rlen", "]", "*", "(", "1", "-", "done_n", "[", ":", "-", "n", "]", ")", "\n", "done_n", "[", ":", "-", "n", "]", "=", "np", ".", "maximum", "(", "done_n", "[", ":", "-", "n", "]", ",", "done", "[", "n", ":", "n", "+", "rlen", "]", ")", "\n", "", "", "else", ":", "\n", "            ", "for", "n", "in", "range", "(", "1", ",", "n_step", ")", ":", "\n", "                ", "return_", "+=", "(", "discount", "**", "n", ")", "*", "reward", "[", "n", ":", "n", "+", "rlen", "]", "*", "(", "1", "-", "done_n", ")", "\n", "done_n", "[", ":", "]", "=", "np", ".", "maximum", "(", "done_n", ",", "done", "[", "n", ":", "n", "+", "rlen", "]", ")", "# Supports tensors.", "\n", "", "", "", "if", "is_torch", ":", "\n", "        ", "done_n", "=", "done_n", ".", "type", "(", "done_dtype", ")", "\n", "", "return", "return_", ",", "done_n", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.algos.utils.valid_from_done": [[104, 113], ["done.type.type", "torch.ones_like", "torch.clamp", "torch.cumsum"], "function", ["None"], ["", "def", "valid_from_done", "(", "done", ")", ":", "\n", "    ", "\"\"\"Returns a float mask which is zero for all time-steps after a\n    `done=True` is signaled.  This function operates on the leading dimension\n    of `done`, assumed to correspond to time [T,...], other dimensions are\n    preserved.\"\"\"", "\n", "done", "=", "done", ".", "type", "(", "torch", ".", "float", ")", "\n", "valid", "=", "torch", ".", "ones_like", "(", "done", ")", "\n", "valid", "[", "1", ":", "]", "=", "1", "-", "torch", ".", "clamp", "(", "torch", ".", "cumsum", "(", "done", "[", ":", "-", "1", "]", ",", "dim", "=", "0", ")", ",", "max", "=", "1", ")", "\n", "return", "valid", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.algos.utils.discount_return_tl": [[118, 136], ["all", "reversed", "rlpyt.utils.misc.zeros", "isinstance", "nd.type", "range", "len"], "function", ["home.repos.pwc.inspect_result.astooke_rlpyt.utils.misc.zeros"], ["", "def", "discount_return_tl", "(", "reward", ",", "done", ",", "bootstrap_value", ",", "discount", ",", "timeout", ",", "value", ",", "\n", "return_dest", "=", "None", ")", ":", "\n", "    ", "\"\"\"Like discount_return(), above, except uses bootstrapping where 'done'\n    is due to env horizon time-limit (tl=Time-Limit).  (In the algo, should\n    not train on samples where `timeout=True`.)\"\"\"", "\n", "return_", "=", "return_dest", "if", "return_dest", "is", "not", "None", "else", "zeros", "(", "\n", "reward", ".", "shape", ",", "dtype", "=", "reward", ".", "dtype", ")", "\n", "assert", "all", "(", "done", "[", "timeout", "]", ")", "# Anywhere timeout, was done (timeout is bool dtype).", "\n", "nd", "=", "1", "-", "done", "\n", "nd", "=", "nd", ".", "type", "(", "reward", ".", "dtype", ")", "if", "isinstance", "(", "nd", ",", "torch", ".", "Tensor", ")", "else", "nd", "\n", "return_", "[", "-", "1", "]", "=", "reward", "[", "-", "1", "]", "+", "discount", "*", "bootstrap_value", "*", "nd", "[", "-", "1", "]", "\n", "for", "t", "in", "reversed", "(", "range", "(", "len", "(", "reward", ")", "-", "1", ")", ")", ":", "\n", "        ", "return_", "[", "t", "]", "=", "reward", "[", "t", "]", "+", "return_", "[", "t", "+", "1", "]", "*", "discount", "*", "nd", "[", "t", "]", "\n", "# Replace with bootstrap value where 'done' due to timeout.", "\n", "# Should mask out those samples for training: valid *= (1 - timeout),", "\n", "# because don't have valid next_state for bootstrap_value(next_state).", "\n", "return_", "[", "t", "]", "[", "timeout", "[", "t", "]", "]", "=", "value", "[", "t", "]", "[", "timeout", "[", "t", "]", "]", "\n", "", "return", "return_", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.algos.utils.generalized_advantage_estimation_tl": [[138, 163], ["all", "reversed", "rlpyt.utils.misc.zeros", "rlpyt.utils.misc.zeros", "isinstance", "nd.type", "range", "len"], "function", ["home.repos.pwc.inspect_result.astooke_rlpyt.utils.misc.zeros", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.misc.zeros"], ["", "def", "generalized_advantage_estimation_tl", "(", "reward", ",", "value", ",", "done", ",", "bootstrap_value", ",", "\n", "discount", ",", "gae_lambda", ",", "timeout", ",", "advantage_dest", "=", "None", ",", "return_dest", "=", "None", ")", ":", "\n", "    ", "\"\"\"Like generalized_advantage_estimation(), above, except uses\n    bootstrapping where 'done' is due to env horizon time-limit\n    (tl=Time-Limit).  (In the algo, should not train on samples where\n    `timeout=True`.)\"\"\"", "\n", "advantage", "=", "advantage_dest", "if", "advantage_dest", "is", "not", "None", "else", "zeros", "(", "\n", "reward", ".", "shape", ",", "dtype", "=", "reward", ".", "dtype", ")", "\n", "return_", "=", "return_dest", "if", "return_dest", "is", "not", "None", "else", "zeros", "(", "\n", "reward", ".", "shape", ",", "dtype", "=", "reward", ".", "dtype", ")", "\n", "assert", "all", "(", "done", "[", "timeout", "]", ")", "# timeout is bool dtype.", "\n", "nd", "=", "1", "-", "done", "\n", "nd", "=", "nd", ".", "type", "(", "reward", ".", "dtype", ")", "if", "isinstance", "(", "nd", ",", "torch", ".", "Tensor", ")", "else", "nd", "\n", "advantage", "[", "-", "1", "]", "=", "reward", "[", "-", "1", "]", "+", "discount", "*", "bootstrap_value", "*", "nd", "[", "-", "1", "]", "-", "value", "[", "-", "1", "]", "\n", "for", "t", "in", "reversed", "(", "range", "(", "len", "(", "reward", ")", "-", "1", ")", ")", ":", "\n", "        ", "delta", "=", "reward", "[", "t", "]", "+", "discount", "*", "value", "[", "t", "+", "1", "]", "*", "nd", "[", "t", "]", "-", "value", "[", "t", "]", "\n", "advantage", "[", "t", "]", "=", "delta", "+", "discount", "*", "gae_lambda", "*", "nd", "[", "t", "]", "*", "advantage", "[", "t", "+", "1", "]", "\n", "# Replace with bootstrap value where 'done' due to timeout.", "\n", "# Should mask out those samples for training: valid *= (1 - timeout),", "\n", "# because don't have valid next_state for bootstrap_value(next_state).", "\n", "tt", "=", "timeout", "[", "t", "+", "1", "]", "\n", "advantage", "[", "t", "]", "[", "tt", "]", "=", "(", "reward", "[", "t", "]", "[", "tt", "]", "+", "# Same formula before loop.", "\n", "discount", "*", "value", "[", "t", "+", "1", "]", "[", "tt", "]", "-", "value", "[", "t", "]", "[", "tt", "]", ")", "\n", "", "return_", "[", ":", "]", "=", "advantage", "+", "value", "\n", "return", "advantage", ",", "return_", "\n", "", ""]], "home.repos.pwc.inspect_result.astooke_rlpyt.qpg.sac_v.SAC_V.__init__": [[34, 63], ["int", "int", "rlpyt.utils.quick_args.save__init__args", "dict", "locals"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.utils.quick_args.save__init__args"], ["def", "__init__", "(", "\n", "self", ",", "\n", "discount", "=", "0.99", ",", "\n", "batch_size", "=", "256", ",", "\n", "min_steps_learn", "=", "int", "(", "1e4", ")", ",", "\n", "replay_size", "=", "int", "(", "1e6", ")", ",", "\n", "replay_ratio", "=", "256", ",", "# data_consumption / data_generation", "\n", "target_update_tau", "=", "0.005", ",", "# tau=1 for hard update.", "\n", "target_update_interval", "=", "1", ",", "# 1000 for hard update, 1 for soft.", "\n", "learning_rate", "=", "3e-4", ",", "\n", "OptimCls", "=", "torch", ".", "optim", ".", "Adam", ",", "\n", "optim_kwargs", "=", "None", ",", "\n", "initial_optim_state_dict", "=", "None", ",", "# for all of them.", "\n", "action_prior", "=", "\"uniform\"", ",", "# or \"gaussian\"", "\n", "reward_scale", "=", "1", ",", "\n", "reparameterize", "=", "True", ",", "\n", "clip_grad_norm", "=", "1e9", ",", "\n", "policy_output_regularization", "=", "0.001", ",", "\n", "n_step_return", "=", "1", ",", "\n", "updates_per_sync", "=", "1", ",", "# For async mode only.", "\n", "bootstrap_timelimit", "=", "True", ",", "\n", "ReplayBufferCls", "=", "None", ",", "#  Leave None to select by above options.", "\n", ")", ":", "\n", "        ", "if", "optim_kwargs", "is", "None", ":", "\n", "            ", "optim_kwargs", "=", "dict", "(", ")", "\n", "", "assert", "action_prior", "in", "[", "\"uniform\"", ",", "\"gaussian\"", "]", "\n", "self", ".", "_batch_size", "=", "batch_size", "\n", "del", "batch_size", "# Property.", "\n", "save__init__args", "(", "locals", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.qpg.sac_v.SAC_V.initialize": [[64, 81], ["int", "rlpyt.utils.logging.logger.log", "agent.give_min_itr_learn", "sac_v.SAC_V.initialize_replay_buffer", "sac_v.SAC_V.optim_initialize"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.logging.console.log", "home.repos.pwc.inspect_result.astooke_rlpyt.agents.dmc_sac_agent.SacAgent.give_min_itr_learn", "home.repos.pwc.inspect_result.astooke_rlpyt.rl_with_ul.ppo_with_ul.PpoUl.initialize_replay_buffer", "home.repos.pwc.inspect_result.astooke_rlpyt.rl_with_ul.sac_with_ul.SacWithUl.optim_initialize"], ["", "def", "initialize", "(", "self", ",", "agent", ",", "n_itr", ",", "batch_spec", ",", "mid_batch_reset", ",", "examples", ",", "\n", "world_size", "=", "1", ",", "rank", "=", "0", ")", ":", "\n", "        ", "\"\"\"Used in basic or synchronous multi-GPU runners, not async.\"\"\"", "\n", "self", ".", "agent", "=", "agent", "\n", "self", ".", "n_itr", "=", "n_itr", "\n", "self", ".", "mid_batch_reset", "=", "mid_batch_reset", "\n", "self", ".", "sampler_bs", "=", "sampler_bs", "=", "batch_spec", ".", "size", "\n", "self", ".", "updates_per_optimize", "=", "int", "(", "self", ".", "replay_ratio", "*", "sampler_bs", "/", "\n", "self", ".", "batch_size", ")", "\n", "logger", ".", "log", "(", "f\"From sampler batch size {sampler_bs}, training \"", "\n", "f\"batch size {self.batch_size}, and replay ratio \"", "\n", "f\"{self.replay_ratio}, computed {self.updates_per_optimize} \"", "\n", "f\"updates per iteration.\"", ")", "\n", "self", ".", "min_itr_learn", "=", "self", ".", "min_steps_learn", "//", "sampler_bs", "\n", "agent", ".", "give_min_itr_learn", "(", "self", ".", "min_itr_learn", ")", "\n", "self", ".", "initialize_replay_buffer", "(", "examples", ",", "batch_spec", ")", "\n", "self", ".", "optim_initialize", "(", "rank", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.qpg.sac_v.SAC_V.async_initialize": [[82, 94], ["sac_v.SAC_V.initialize_replay_buffer", "int", "agent.give_min_itr_learn"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.rl_with_ul.ppo_with_ul.PpoUl.initialize_replay_buffer", "home.repos.pwc.inspect_result.astooke_rlpyt.agents.dmc_sac_agent.SacAgent.give_min_itr_learn"], ["", "def", "async_initialize", "(", "self", ",", "agent", ",", "sampler_n_itr", ",", "batch_spec", ",", "mid_batch_reset", ",", "\n", "examples", ",", "world_size", "=", "1", ")", ":", "\n", "        ", "\"\"\"Used in async runner only.\"\"\"", "\n", "self", ".", "agent", "=", "agent", "\n", "self", ".", "n_itr", "=", "sampler_n_itr", "\n", "self", ".", "initialize_replay_buffer", "(", "examples", ",", "batch_spec", ",", "async_", "=", "True", ")", "\n", "self", ".", "mid_batch_reset", "=", "mid_batch_reset", "\n", "self", ".", "sampler_bs", "=", "sampler_bs", "=", "batch_spec", ".", "size", "\n", "self", ".", "updates_per_optimize", "=", "self", ".", "updates_per_sync", "\n", "self", ".", "min_itr_learn", "=", "int", "(", "self", ".", "min_steps_learn", "//", "sampler_bs", ")", "\n", "agent", ".", "give_min_itr_learn", "(", "self", ".", "min_itr_learn", ")", "\n", "return", "self", ".", "replay_buffer", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.qpg.sac_v.SAC_V.optim_initialize": [[95, 111], ["sac_v.SAC_V.OptimCls", "sac_v.SAC_V.OptimCls", "sac_v.SAC_V.OptimCls", "sac_v.SAC_V.OptimCls", "sac_v.SAC_V.agent.pi_parameters", "sac_v.SAC_V.agent.q1_parameters", "sac_v.SAC_V.agent.q2_parameters", "sac_v.SAC_V.agent.v_parameters", "sac_v.SAC_V.load_optim_state_dict", "rlpyt.distributions.gaussian.Gaussian"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.qpg.sac_agent.SacAgent.pi_parameters", "home.repos.pwc.inspect_result.astooke_rlpyt.qpg.sac_agent.SacAgent.q1_parameters", "home.repos.pwc.inspect_result.astooke_rlpyt.qpg.sac_agent.SacAgent.q2_parameters", "home.repos.pwc.inspect_result.astooke_rlpyt.qpg.sac_v_agent.SacAgent.v_parameters", "home.repos.pwc.inspect_result.astooke_rlpyt.rl_with_ul.sac_with_ul.SacWithUl.load_optim_state_dict"], ["", "def", "optim_initialize", "(", "self", ",", "rank", "=", "0", ")", ":", "\n", "        ", "\"\"\"Called by async runner.\"\"\"", "\n", "self", ".", "rank", "=", "rank", "\n", "self", ".", "pi_optimizer", "=", "self", ".", "OptimCls", "(", "self", ".", "agent", ".", "pi_parameters", "(", ")", ",", "\n", "lr", "=", "self", ".", "learning_rate", ",", "**", "self", ".", "optim_kwargs", ")", "\n", "self", ".", "q1_optimizer", "=", "self", ".", "OptimCls", "(", "self", ".", "agent", ".", "q1_parameters", "(", ")", ",", "\n", "lr", "=", "self", ".", "learning_rate", ",", "**", "self", ".", "optim_kwargs", ")", "\n", "self", ".", "q2_optimizer", "=", "self", ".", "OptimCls", "(", "self", ".", "agent", ".", "q2_parameters", "(", ")", ",", "\n", "lr", "=", "self", ".", "learning_rate", ",", "**", "self", ".", "optim_kwargs", ")", "\n", "self", ".", "v_optimizer", "=", "self", ".", "OptimCls", "(", "self", ".", "agent", ".", "v_parameters", "(", ")", ",", "\n", "lr", "=", "self", ".", "learning_rate", ",", "**", "self", ".", "optim_kwargs", ")", "\n", "if", "self", ".", "initial_optim_state_dict", "is", "not", "None", ":", "\n", "            ", "self", ".", "load_optim_state_dict", "(", "self", ".", "initial_optim_state_dict", ")", "\n", "", "if", "self", ".", "action_prior", "==", "\"gaussian\"", ":", "\n", "            ", "self", ".", "action_prior_distribution", "=", "Gaussian", "(", "\n", "dim", "=", "self", ".", "agent", ".", "env_spaces", ".", "action", ".", "size", ",", "std", "=", "1.", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.qpg.sac_v.SAC_V.initialize_replay_buffer": [[112, 136], ["SamplesToBuffer", "dict", "ReplayCls", "rlpyt.utils.logging.logger.log", "getattr"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.logging.console.log"], ["", "", "def", "initialize_replay_buffer", "(", "self", ",", "examples", ",", "batch_spec", ",", "async_", "=", "False", ")", ":", "\n", "        ", "example_to_buffer", "=", "SamplesToBuffer", "(", "\n", "observation", "=", "examples", "[", "\"observation\"", "]", ",", "\n", "action", "=", "examples", "[", "\"action\"", "]", ",", "\n", "reward", "=", "examples", "[", "\"reward\"", "]", ",", "\n", "done", "=", "examples", "[", "\"done\"", "]", ",", "\n", "timeout", "=", "getattr", "(", "examples", "[", "\"env_info\"", "]", ",", "\"timeout\"", ",", "None", ")", ",", "\n", ")", "\n", "replay_kwargs", "=", "dict", "(", "\n", "example", "=", "example_to_buffer", ",", "\n", "size", "=", "self", ".", "replay_size", ",", "\n", "B", "=", "batch_spec", ".", "B", ",", "\n", "n_step_return", "=", "self", ".", "n_step_return", ",", "\n", ")", "\n", "if", "not", "self", ".", "bootstrap_timelimit", ":", "\n", "            ", "ReplayCls", "=", "AsyncUniformReplayBuffer", "if", "async_", "else", "UniformReplayBuffer", "\n", "", "else", ":", "\n", "            ", "ReplayCls", "=", "AsyncTlUniformReplayBuffer", "if", "async_", "else", "TlUniformReplayBuffer", "\n", "", "if", "self", ".", "ReplayBufferCls", "is", "not", "None", ":", "\n", "            ", "ReplayCls", "=", "self", ".", "ReplayBufferCls", "\n", "logger", ".", "log", "(", "f\"WARNING: ignoring internal selection logic and using\"", "\n", "f\" input replay buffer class: {ReplayCls} -- compatibility not\"", "\n", "\" guaranteed.\"", ")", "\n", "", "self", ".", "replay_buffer", "=", "ReplayCls", "(", "**", "replay_kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.qpg.sac_v.SAC_V.optimize_agent": [[138, 183], ["OptInfo", "range", "sac_v.SAC_V.samples_to_buffer", "sac_v.SAC_V.replay_buffer.append_samples", "sac_v.SAC_V.replay_buffer.sample_batch", "sac_v.SAC_V.loss", "sac_v.SAC_V.v_optimizer.zero_grad", "v_loss.backward", "torch.nn.utils.clip_grad_norm_", "sac_v.SAC_V.v_optimizer.step", "sac_v.SAC_V.pi_optimizer.zero_grad", "pi_loss.backward", "torch.nn.utils.clip_grad_norm_", "sac_v.SAC_V.pi_optimizer.step", "sac_v.SAC_V.q1_optimizer.zero_grad", "q1_loss.backward", "torch.nn.utils.clip_grad_norm_", "sac_v.SAC_V.q1_optimizer.step", "sac_v.SAC_V.q2_optimizer.zero_grad", "q2_loss.backward", "torch.nn.utils.clip_grad_norm_", "sac_v.SAC_V.q2_optimizer.step", "sac_v.SAC_V.append_opt_info_", "sac_v.SAC_V.agent.v_parameters", "sac_v.SAC_V.agent.pi_parameters", "sac_v.SAC_V.agent.q1_parameters", "sac_v.SAC_V.agent.q2_parameters", "sac_v.SAC_V.agent.update_target", "range", "len"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.rl_with_ul.ppo_with_ul.PpoUl.samples_to_buffer", "home.repos.pwc.inspect_result.astooke_rlpyt.sequence.prioritized.PrioritizedSequenceReplay.append_samples", "home.repos.pwc.inspect_result.astooke_rlpyt.sequence.uniform.UniformSequenceReplay.sample_batch", "home.repos.pwc.inspect_result.astooke_rlpyt.safe.cppo_pid.CppoPID.loss", "home.repos.pwc.inspect_result.astooke_rlpyt.models.utils.ScaleGrad.backward", "home.repos.pwc.inspect_result.astooke_rlpyt.safe.safety_gym_env.SafetyGymTrajInfo.step", "home.repos.pwc.inspect_result.astooke_rlpyt.models.utils.ScaleGrad.backward", "home.repos.pwc.inspect_result.astooke_rlpyt.safe.safety_gym_env.SafetyGymTrajInfo.step", "home.repos.pwc.inspect_result.astooke_rlpyt.models.utils.ScaleGrad.backward", "home.repos.pwc.inspect_result.astooke_rlpyt.safe.safety_gym_env.SafetyGymTrajInfo.step", "home.repos.pwc.inspect_result.astooke_rlpyt.models.utils.ScaleGrad.backward", "home.repos.pwc.inspect_result.astooke_rlpyt.safe.safety_gym_env.SafetyGymTrajInfo.step", "home.repos.pwc.inspect_result.astooke_rlpyt.qpg.sac.SAC.append_opt_info_", "home.repos.pwc.inspect_result.astooke_rlpyt.qpg.sac_v_agent.SacAgent.v_parameters", "home.repos.pwc.inspect_result.astooke_rlpyt.qpg.sac_agent.SacAgent.pi_parameters", "home.repos.pwc.inspect_result.astooke_rlpyt.qpg.sac_agent.SacAgent.q1_parameters", "home.repos.pwc.inspect_result.astooke_rlpyt.qpg.sac_agent.SacAgent.q2_parameters", "home.repos.pwc.inspect_result.astooke_rlpyt.agents.atari_dqn_agent.AtariDqnAgent.update_target"], ["", "def", "optimize_agent", "(", "self", ",", "itr", ",", "samples", "=", "None", ",", "sampler_itr", "=", "None", ")", ":", "\n", "        ", "itr", "=", "itr", "if", "sampler_itr", "is", "None", "else", "sampler_itr", "# Async uses sampler_itr.", "\n", "if", "samples", "is", "not", "None", ":", "\n", "            ", "samples_to_buffer", "=", "self", ".", "samples_to_buffer", "(", "samples", ")", "\n", "self", ".", "replay_buffer", ".", "append_samples", "(", "samples_to_buffer", ")", "\n", "", "opt_info", "=", "OptInfo", "(", "*", "(", "[", "]", "for", "_", "in", "range", "(", "len", "(", "OptInfo", ".", "_fields", ")", ")", ")", ")", "\n", "if", "itr", "<", "self", ".", "min_itr_learn", ":", "\n", "            ", "return", "opt_info", "\n", "", "for", "_", "in", "range", "(", "self", ".", "updates_per_optimize", ")", ":", "\n", "            ", "samples_from_replay", "=", "self", ".", "replay_buffer", ".", "sample_batch", "(", "self", ".", "batch_size", ")", "\n", "losses", ",", "values", "=", "self", ".", "loss", "(", "samples_from_replay", ")", "\n", "q1_loss", ",", "q2_loss", ",", "v_loss", ",", "pi_loss", "=", "losses", "\n", "\n", "self", ".", "v_optimizer", ".", "zero_grad", "(", ")", "\n", "v_loss", ".", "backward", "(", ")", "\n", "v_grad_norm", "=", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "self", ".", "agent", ".", "v_parameters", "(", ")", ",", "\n", "self", ".", "clip_grad_norm", ")", "\n", "self", ".", "v_optimizer", ".", "step", "(", ")", "\n", "\n", "self", ".", "pi_optimizer", ".", "zero_grad", "(", ")", "\n", "pi_loss", ".", "backward", "(", ")", "\n", "pi_grad_norm", "=", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "self", ".", "agent", ".", "pi_parameters", "(", ")", ",", "\n", "self", ".", "clip_grad_norm", ")", "\n", "self", ".", "pi_optimizer", ".", "step", "(", ")", "\n", "\n", "# Step Q's last because pi_loss.backward() uses them?", "\n", "self", ".", "q1_optimizer", ".", "zero_grad", "(", ")", "\n", "q1_loss", ".", "backward", "(", ")", "\n", "q1_grad_norm", "=", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "self", ".", "agent", ".", "q1_parameters", "(", ")", ",", "\n", "self", ".", "clip_grad_norm", ")", "\n", "self", ".", "q1_optimizer", ".", "step", "(", ")", "\n", "\n", "self", ".", "q2_optimizer", ".", "zero_grad", "(", ")", "\n", "q2_loss", ".", "backward", "(", ")", "\n", "q2_grad_norm", "=", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "self", ".", "agent", ".", "q2_parameters", "(", ")", ",", "\n", "self", ".", "clip_grad_norm", ")", "\n", "self", ".", "q2_optimizer", ".", "step", "(", ")", "\n", "\n", "grad_norms", "=", "(", "q1_grad_norm", ",", "q2_grad_norm", ",", "v_grad_norm", ",", "pi_grad_norm", ")", "\n", "\n", "self", ".", "append_opt_info_", "(", "opt_info", ",", "losses", ",", "grad_norms", ",", "values", ")", "\n", "self", ".", "update_counter", "+=", "1", "\n", "if", "self", ".", "update_counter", "%", "self", ".", "target_update_interval", "==", "0", ":", "\n", "                ", "self", ".", "agent", ".", "update_target", "(", "self", ".", "target_update_tau", ")", "\n", "", "", "return", "opt_info", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.qpg.sac_v.SAC_V.samples_to_buffer": [[184, 191], ["SamplesToBuffer", "getattr"], "methods", ["None"], ["", "def", "samples_to_buffer", "(", "self", ",", "samples", ")", ":", "\n", "        ", "return", "SamplesToBuffer", "(", "\n", "observation", "=", "samples", ".", "env", ".", "observation", ",", "\n", "action", "=", "samples", ".", "agent", ".", "action", ",", "\n", "reward", "=", "samples", ".", "env", ".", "reward", ",", "\n", "done", "=", "samples", ".", "env", ".", "done", ",", "\n", "timeout", "=", "getattr", "(", "samples", ".", "env", ".", "env_info", ",", "\"timeout\"", ",", "None", ")", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.qpg.sac_v.SAC_V.loss": [[193, 240], ["rlpyt.utils.buffer.buffer_to", "sac_v.SAC_V.agent.q", "sac_v.SAC_V.agent.v", "sac_v.SAC_V.agent.pi", "sac_v.SAC_V.agent.q", "torch.min", "sac_v.SAC_V.get_action_prior", "rlpyt.utils.tensor.valid_mean", "tuple", "torch.no_grad", "sac_v.SAC_V.agent.target_v", "torch.ones_like", "rlpyt.algos.utils.valid_from_done", "rlpyt.utils.tensor.valid_mean", "rlpyt.utils.tensor.valid_mean", "new_action.detach.detach.detach", "new_action.detach.detach.cpu", "rlpyt.utils.tensor.valid_mean", "samples.timeout_n.float", "torch.mean", "val.detach", "samples.done_n.float"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.utils.buffer.buffer_to", "home.repos.pwc.inspect_result.astooke_rlpyt.agents.dmc_sac_agent.SacAgent.q", "home.repos.pwc.inspect_result.astooke_rlpyt.qpg.sac_v_agent.SacAgent.v", "home.repos.pwc.inspect_result.astooke_rlpyt.agents.dmc_sac_agent.SacAgent.pi", "home.repos.pwc.inspect_result.astooke_rlpyt.agents.dmc_sac_agent.SacAgent.q", "home.repos.pwc.inspect_result.astooke_rlpyt.rl_with_ul.sac_with_ul.SacWithUl.get_action_prior", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.tensor.valid_mean", "home.repos.pwc.inspect_result.astooke_rlpyt.qpg.sac_v_agent.SacAgent.target_v", "home.repos.pwc.inspect_result.astooke_rlpyt.algos.utils.valid_from_done", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.tensor.valid_mean", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.tensor.valid_mean", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.tensor.valid_mean"], ["", "def", "loss", "(", "self", ",", "samples", ")", ":", "\n", "        ", "\"\"\"Samples have leading batch dimension [B,..] (but not time).\"\"\"", "\n", "agent_inputs", ",", "target_inputs", ",", "action", "=", "buffer_to", "(", "\n", "(", "samples", ".", "agent_inputs", ",", "samples", ".", "target_inputs", ",", "samples", ".", "action", ")", ")", "\n", "q1", ",", "q2", "=", "self", ".", "agent", ".", "q", "(", "*", "agent_inputs", ",", "action", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "target_v", "=", "self", ".", "agent", ".", "target_v", "(", "*", "target_inputs", ")", "\n", "", "disc", "=", "self", ".", "discount", "**", "self", ".", "n_step_return", "\n", "y", "=", "(", "self", ".", "reward_scale", "*", "samples", ".", "return_", "+", "\n", "(", "1", "-", "samples", ".", "done_n", ".", "float", "(", ")", ")", "*", "disc", "*", "target_v", ")", "\n", "if", "self", ".", "mid_batch_reset", "and", "not", "self", ".", "agent", ".", "recurrent", ":", "\n", "            ", "valid", "=", "torch", ".", "ones_like", "(", "samples", ".", "done", ",", "dtype", "=", "torch", ".", "float", ")", "\n", "", "else", ":", "\n", "            ", "valid", "=", "valid_from_done", "(", "samples", ".", "done", ")", "\n", "\n", "", "if", "self", ".", "bootstrap_timelimit", ":", "\n", "# To avoid non-use of bootstrap when environment is 'done' due to", "\n", "# time-limit, turn off training on these samples.", "\n", "            ", "valid", "*=", "(", "1", "-", "samples", ".", "timeout_n", ".", "float", "(", ")", ")", "\n", "\n", "", "q1_loss", "=", "0.5", "*", "valid_mean", "(", "(", "y", "-", "q1", ")", "**", "2", ",", "valid", ")", "\n", "q2_loss", "=", "0.5", "*", "valid_mean", "(", "(", "y", "-", "q2", ")", "**", "2", ",", "valid", ")", "\n", "\n", "v", "=", "self", ".", "agent", ".", "v", "(", "*", "agent_inputs", ")", "\n", "new_action", ",", "log_pi", ",", "(", "pi_mean", ",", "pi_log_std", ")", "=", "self", ".", "agent", ".", "pi", "(", "*", "agent_inputs", ")", "\n", "if", "not", "self", ".", "reparameterize", ":", "\n", "            ", "new_action", "=", "new_action", ".", "detach", "(", ")", "# No grad.", "\n", "", "log_target1", ",", "log_target2", "=", "self", ".", "agent", ".", "q", "(", "*", "agent_inputs", ",", "new_action", ")", "\n", "min_log_target", "=", "torch", ".", "min", "(", "log_target1", ",", "log_target2", ")", "\n", "prior_log_pi", "=", "self", ".", "get_action_prior", "(", "new_action", ".", "cpu", "(", ")", ")", "\n", "v_target", "=", "(", "min_log_target", "-", "log_pi", "+", "prior_log_pi", ")", ".", "detach", "(", ")", "# No grad.", "\n", "\n", "v_loss", "=", "0.5", "*", "valid_mean", "(", "(", "v", "-", "v_target", ")", "**", "2", ",", "valid", ")", "\n", "\n", "if", "self", ".", "reparameterize", ":", "\n", "            ", "pi_losses", "=", "log_pi", "-", "min_log_target", "\n", "", "else", ":", "\n", "            ", "pi_factor", "=", "(", "v", "-", "v_target", ")", ".", "detach", "(", ")", "\n", "pi_losses", "=", "log_pi", "*", "pi_factor", "\n", "", "if", "self", ".", "policy_output_regularization", ">", "0", ":", "\n", "            ", "pi_losses", "+=", "self", ".", "policy_output_regularization", "*", "torch", ".", "mean", "(", "\n", "0.5", "*", "pi_mean", "**", "2", "+", "0.5", "*", "pi_log_std", "**", "2", ",", "dim", "=", "-", "1", ")", "\n", "", "pi_loss", "=", "valid_mean", "(", "pi_losses", ",", "valid", ")", "\n", "\n", "losses", "=", "(", "q1_loss", ",", "q2_loss", ",", "v_loss", ",", "pi_loss", ")", "\n", "values", "=", "tuple", "(", "val", ".", "detach", "(", ")", "for", "val", "in", "(", "q1", ",", "q2", ",", "v", ",", "pi_mean", ",", "pi_log_std", ")", ")", "\n", "return", "losses", ",", "values", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.qpg.sac_v.SAC_V.get_action_prior": [[332, 339], ["sac_v.SAC_V.action_prior_distribution.log_likelihood", "rlpyt.distributions.gaussian.DistInfo", "torch.zeros_like"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.distributions.gaussian.Gaussian.log_likelihood"], ["", "def", "get_action_prior", "(", "self", ",", "action", ")", ":", "\n", "        ", "if", "self", ".", "action_prior", "==", "\"uniform\"", ":", "\n", "            ", "prior_log_pi", "=", "0.0", "\n", "", "elif", "self", ".", "action_prior", "==", "\"gaussian\"", ":", "\n", "            ", "prior_log_pi", "=", "self", ".", "action_prior_distribution", ".", "log_likelihood", "(", "\n", "action", ",", "GaussianDistInfo", "(", "mean", "=", "torch", ".", "zeros_like", "(", "action", ")", ")", ")", "\n", "", "return", "prior_log_pi", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.qpg.sac_v.SAC_V.append_opt_info_": [[340, 359], ["opt_info.q1Loss.append", "opt_info.q2Loss.append", "opt_info.vLoss.append", "opt_info.piLoss.append", "opt_info.q1GradNorm.append", "opt_info.q2GradNorm.append", "opt_info.vGradNorm.append", "opt_info.piGradNorm.append", "opt_info.q1.extend", "opt_info.q2.extend", "opt_info.v.extend", "opt_info.piMu.extend", "opt_info.piLogStd.extend", "opt_info.qMeanDiff.append", "q1_loss.item", "q2_loss.item", "v_loss.item", "pi_loss.item", "torch.tensor().item", "torch.tensor().item", "torch.tensor().item", "torch.tensor().item", "q1[].numpy", "q2[].numpy", "v[].numpy", "pi_mean[].numpy", "pi_log_std[].numpy", "torch.mean().item", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.mean", "abs"], "methods", ["None"], ["", "def", "append_opt_info_", "(", "self", ",", "opt_info", ",", "losses", ",", "grad_norms", ",", "values", ")", ":", "\n", "        ", "\"\"\"In-place.\"\"\"", "\n", "q1_loss", ",", "q2_loss", ",", "v_loss", ",", "pi_loss", "=", "losses", "\n", "q1_grad_norm", ",", "q2_grad_norm", ",", "v_grad_norm", ",", "pi_grad_norm", "=", "grad_norms", "\n", "q1", ",", "q2", ",", "v", ",", "pi_mean", ",", "pi_log_std", "=", "values", "\n", "opt_info", ".", "q1Loss", ".", "append", "(", "q1_loss", ".", "item", "(", ")", ")", "\n", "opt_info", ".", "q2Loss", ".", "append", "(", "q2_loss", ".", "item", "(", ")", ")", "\n", "opt_info", ".", "vLoss", ".", "append", "(", "v_loss", ".", "item", "(", ")", ")", "\n", "opt_info", ".", "piLoss", ".", "append", "(", "pi_loss", ".", "item", "(", ")", ")", "\n", "opt_info", ".", "q1GradNorm", ".", "append", "(", "torch", ".", "tensor", "(", "q1_grad_norm", ")", ".", "item", "(", ")", ")", "# backwards compatible", "\n", "opt_info", ".", "q2GradNorm", ".", "append", "(", "torch", ".", "tensor", "(", "q2_grad_norm", ")", ".", "item", "(", ")", ")", "# backwards compatible", "\n", "opt_info", ".", "vGradNorm", ".", "append", "(", "torch", ".", "tensor", "(", "v_grad_norm", ")", ".", "item", "(", ")", ")", "# backwards compatible", "\n", "opt_info", ".", "piGradNorm", ".", "append", "(", "torch", ".", "tensor", "(", "pi_grad_norm", ")", ".", "item", "(", ")", ")", "# backwards compatible", "\n", "opt_info", ".", "q1", ".", "extend", "(", "q1", "[", ":", ":", "10", "]", ".", "numpy", "(", ")", ")", "# Downsample for stats.", "\n", "opt_info", ".", "q2", ".", "extend", "(", "q2", "[", ":", ":", "10", "]", ".", "numpy", "(", ")", ")", "\n", "opt_info", ".", "v", ".", "extend", "(", "v", "[", ":", ":", "10", "]", ".", "numpy", "(", ")", ")", "\n", "opt_info", ".", "piMu", ".", "extend", "(", "pi_mean", "[", ":", ":", "10", "]", ".", "numpy", "(", ")", ")", "\n", "opt_info", ".", "piLogStd", ".", "extend", "(", "pi_log_std", "[", ":", ":", "10", "]", ".", "numpy", "(", ")", ")", "\n", "opt_info", ".", "qMeanDiff", ".", "append", "(", "torch", ".", "mean", "(", "abs", "(", "q1", "-", "q2", ")", ")", ".", "item", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.qpg.sac_v.SAC_V.optim_state_dict": [[360, 366], ["dict", "sac_v.SAC_V.pi_optimizer.state_dict", "sac_v.SAC_V.q1_optimizer.state_dict", "sac_v.SAC_V.q2_optimizer.state_dict", "sac_v.SAC_V.v_optimizer.state_dict"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.replay_saver.DummyOptimizer.state_dict", "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.replay_saver.DummyOptimizer.state_dict", "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.replay_saver.DummyOptimizer.state_dict", "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.replay_saver.DummyOptimizer.state_dict"], ["", "def", "optim_state_dict", "(", "self", ")", ":", "\n", "        ", "return", "dict", "(", "\n", "pi_optimizer", "=", "self", ".", "pi_optimizer", ".", "state_dict", "(", ")", ",", "\n", "q1_optimizer", "=", "self", ".", "q1_optimizer", ".", "state_dict", "(", ")", ",", "\n", "q2_optimizer", "=", "self", ".", "q2_optimizer", ".", "state_dict", "(", ")", ",", "\n", "v_optimizer", "=", "self", ".", "v_optimizer", ".", "state_dict", "(", ")", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.qpg.sac_v.SAC_V.load_optim_state_dict": [[368, 373], ["sac_v.SAC_V.pi_optimizer.load_state_dict", "sac_v.SAC_V.q1_optimizer.load_state_dict", "sac_v.SAC_V.q2_optimizer.load_state_dict", "sac_v.SAC_V.v_optimizer.load_state_dict"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.augmented_temporal_similarity.AugmentedTemporalSimilarity.load_state_dict", "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.augmented_temporal_similarity.AugmentedTemporalSimilarity.load_state_dict", "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.augmented_temporal_similarity.AugmentedTemporalSimilarity.load_state_dict", "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.augmented_temporal_similarity.AugmentedTemporalSimilarity.load_state_dict"], ["", "def", "load_optim_state_dict", "(", "self", ",", "state_dict", ")", ":", "\n", "        ", "self", ".", "pi_optimizer", ".", "load_state_dict", "(", "state_dict", "[", "\"pi_optimizer\"", "]", ")", "\n", "self", ".", "q1_optimizer", ".", "load_state_dict", "(", "state_dict", "[", "\"q1_optimizer\"", "]", ")", "\n", "self", ".", "q2_optimizer", ".", "load_state_dict", "(", "state_dict", "[", "\"q2_optimizer\"", "]", ")", "\n", "self", ".", "v_optimizer", ".", "load_state_dict", "(", "state_dict", "[", "\"v_optimizer\"", "]", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.astooke_rlpyt.qpg.sac.SAC.__init__": [[36, 68], ["int", "int", "rlpyt.utils.quick_args.save__init__args", "dict", "locals"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.utils.quick_args.save__init__args"], ["def", "__init__", "(", "\n", "self", ",", "\n", "discount", "=", "0.99", ",", "\n", "batch_size", "=", "256", ",", "\n", "min_steps_learn", "=", "int", "(", "1e4", ")", ",", "\n", "replay_size", "=", "int", "(", "1e6", ")", ",", "\n", "replay_ratio", "=", "256", ",", "# data_consumption / data_generation", "\n", "target_update_tau", "=", "0.005", ",", "# tau=1 for hard update.", "\n", "target_update_interval", "=", "1", ",", "# 1000 for hard update, 1 for soft.", "\n", "learning_rate", "=", "3e-4", ",", "\n", "fixed_alpha", "=", "None", ",", "# None for adaptive alpha, float for any fixed value", "\n", "OptimCls", "=", "torch", ".", "optim", ".", "Adam", ",", "\n", "optim_kwargs", "=", "None", ",", "\n", "initial_optim_state_dict", "=", "None", ",", "# for all of them.", "\n", "action_prior", "=", "\"uniform\"", ",", "# or \"gaussian\"", "\n", "reward_scale", "=", "1", ",", "\n", "target_entropy", "=", "\"auto\"", ",", "# \"auto\", float, or None", "\n", "reparameterize", "=", "True", ",", "\n", "clip_grad_norm", "=", "1e9", ",", "\n", "# policy_output_regularization=0.001,", "\n", "n_step_return", "=", "1", ",", "\n", "updates_per_sync", "=", "1", ",", "# For async mode only.", "\n", "bootstrap_timelimit", "=", "True", ",", "\n", "ReplayBufferCls", "=", "None", ",", "# Leave None to select by above options.", "\n", ")", ":", "\n", "        ", "\"\"\"Save input arguments.\"\"\"", "\n", "if", "optim_kwargs", "is", "None", ":", "\n", "            ", "optim_kwargs", "=", "dict", "(", ")", "\n", "", "assert", "action_prior", "in", "[", "\"uniform\"", ",", "\"gaussian\"", "]", "\n", "self", ".", "_batch_size", "=", "batch_size", "\n", "del", "batch_size", "# Property.", "\n", "save__init__args", "(", "locals", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.qpg.sac.SAC.initialize": [[69, 89], ["int", "rlpyt.utils.logging.logger.log", "agent.give_min_itr_learn", "sac.SAC.initialize_replay_buffer", "sac.SAC.optim_initialize"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.logging.console.log", "home.repos.pwc.inspect_result.astooke_rlpyt.agents.dmc_sac_agent.SacAgent.give_min_itr_learn", "home.repos.pwc.inspect_result.astooke_rlpyt.rl_with_ul.ppo_with_ul.PpoUl.initialize_replay_buffer", "home.repos.pwc.inspect_result.astooke_rlpyt.rl_with_ul.sac_with_ul.SacWithUl.optim_initialize"], ["", "def", "initialize", "(", "self", ",", "agent", ",", "n_itr", ",", "batch_spec", ",", "mid_batch_reset", ",", "examples", ",", "\n", "world_size", "=", "1", ",", "rank", "=", "0", ")", ":", "\n", "        ", "\"\"\"Stores input arguments and initializes replay buffer and optimizer.\n        Use in non-async runners.  Computes number of gradient updates per\n        optimization iteration as `(replay_ratio * sampler-batch-size /\n        training-batch_size)`.\"\"\"", "\n", "self", ".", "agent", "=", "agent", "\n", "self", ".", "n_itr", "=", "n_itr", "\n", "self", ".", "mid_batch_reset", "=", "mid_batch_reset", "\n", "self", ".", "sampler_bs", "=", "sampler_bs", "=", "batch_spec", ".", "size", "\n", "self", ".", "updates_per_optimize", "=", "int", "(", "self", ".", "replay_ratio", "*", "sampler_bs", "/", "\n", "self", ".", "batch_size", ")", "\n", "logger", ".", "log", "(", "f\"From sampler batch size {sampler_bs}, training \"", "\n", "f\"batch size {self.batch_size}, and replay ratio \"", "\n", "f\"{self.replay_ratio}, computed {self.updates_per_optimize} \"", "\n", "f\"updates per iteration.\"", ")", "\n", "self", ".", "min_itr_learn", "=", "self", ".", "min_steps_learn", "//", "sampler_bs", "\n", "agent", ".", "give_min_itr_learn", "(", "self", ".", "min_itr_learn", ")", "\n", "self", ".", "initialize_replay_buffer", "(", "examples", ",", "batch_spec", ")", "\n", "self", ".", "optim_initialize", "(", "rank", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.qpg.sac.SAC.async_initialize": [[90, 103], ["sac.SAC.initialize_replay_buffer", "int", "agent.give_min_itr_learn"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.rl_with_ul.ppo_with_ul.PpoUl.initialize_replay_buffer", "home.repos.pwc.inspect_result.astooke_rlpyt.agents.dmc_sac_agent.SacAgent.give_min_itr_learn"], ["", "def", "async_initialize", "(", "self", ",", "agent", ",", "sampler_n_itr", ",", "batch_spec", ",", "mid_batch_reset", ",", "\n", "examples", ",", "world_size", "=", "1", ")", ":", "\n", "        ", "\"\"\"Used in async runner only; returns replay buffer allocated in shared\n        memory, does not instantiate optimizer. \"\"\"", "\n", "self", ".", "agent", "=", "agent", "\n", "self", ".", "n_itr", "=", "sampler_n_itr", "\n", "self", ".", "initialize_replay_buffer", "(", "examples", ",", "batch_spec", ",", "async_", "=", "True", ")", "\n", "self", ".", "mid_batch_reset", "=", "mid_batch_reset", "\n", "self", ".", "sampler_bs", "=", "sampler_bs", "=", "batch_spec", ".", "size", "\n", "self", ".", "updates_per_optimize", "=", "self", ".", "updates_per_sync", "\n", "self", ".", "min_itr_learn", "=", "int", "(", "self", ".", "min_steps_learn", "//", "sampler_bs", ")", "\n", "agent", ".", "give_min_itr_learn", "(", "self", ".", "min_itr_learn", ")", "\n", "return", "self", ".", "replay_buffer", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.qpg.sac.SAC.optim_initialize": [[104, 129], ["sac.SAC.OptimCls", "sac.SAC.OptimCls", "sac.SAC.OptimCls", "sac.SAC.agent.pi_parameters", "sac.SAC.agent.q1_parameters", "sac.SAC.agent.q2_parameters", "torch.zeros", "torch.exp", "sac.SAC.OptimCls", "torch.tensor", "torch.tensor", "sac.SAC.load_optim_state_dict", "rlpyt.distributions.gaussian.Gaussian", "sac.SAC._log_alpha.detach", "numpy.prod", "numpy.log", "numpy.prod"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.qpg.sac_agent.SacAgent.pi_parameters", "home.repos.pwc.inspect_result.astooke_rlpyt.qpg.sac_agent.SacAgent.q1_parameters", "home.repos.pwc.inspect_result.astooke_rlpyt.qpg.sac_agent.SacAgent.q2_parameters", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.misc.zeros", "home.repos.pwc.inspect_result.astooke_rlpyt.rl_with_ul.sac_with_ul.SacWithUl.load_optim_state_dict", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.console.log"], ["", "def", "optim_initialize", "(", "self", ",", "rank", "=", "0", ")", ":", "\n", "        ", "\"\"\"Called in initilize or by async runner after forking sampler.\"\"\"", "\n", "self", ".", "rank", "=", "rank", "\n", "self", ".", "pi_optimizer", "=", "self", ".", "OptimCls", "(", "self", ".", "agent", ".", "pi_parameters", "(", ")", ",", "\n", "lr", "=", "self", ".", "learning_rate", ",", "**", "self", ".", "optim_kwargs", ")", "\n", "self", ".", "q1_optimizer", "=", "self", ".", "OptimCls", "(", "self", ".", "agent", ".", "q1_parameters", "(", ")", ",", "\n", "lr", "=", "self", ".", "learning_rate", ",", "**", "self", ".", "optim_kwargs", ")", "\n", "self", ".", "q2_optimizer", "=", "self", ".", "OptimCls", "(", "self", ".", "agent", ".", "q2_parameters", "(", ")", ",", "\n", "lr", "=", "self", ".", "learning_rate", ",", "**", "self", ".", "optim_kwargs", ")", "\n", "if", "self", ".", "fixed_alpha", "is", "None", ":", "\n", "            ", "self", ".", "_log_alpha", "=", "torch", ".", "zeros", "(", "1", ",", "requires_grad", "=", "True", ")", "\n", "self", ".", "_alpha", "=", "torch", ".", "exp", "(", "self", ".", "_log_alpha", ".", "detach", "(", ")", ")", "\n", "self", ".", "alpha_optimizer", "=", "self", ".", "OptimCls", "(", "(", "self", ".", "_log_alpha", ",", ")", ",", "\n", "lr", "=", "self", ".", "learning_rate", ",", "**", "self", ".", "optim_kwargs", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "_log_alpha", "=", "torch", ".", "tensor", "(", "[", "np", ".", "log", "(", "self", ".", "fixed_alpha", ")", "]", ")", "\n", "self", ".", "_alpha", "=", "torch", ".", "tensor", "(", "[", "self", ".", "fixed_alpha", "]", ")", "\n", "self", ".", "alpha_optimizer", "=", "None", "\n", "", "if", "self", ".", "target_entropy", "==", "\"auto\"", ":", "\n", "            ", "self", ".", "target_entropy", "=", "-", "np", ".", "prod", "(", "self", ".", "agent", ".", "env_spaces", ".", "action", ".", "shape", ")", "\n", "", "if", "self", ".", "initial_optim_state_dict", "is", "not", "None", ":", "\n", "            ", "self", ".", "load_optim_state_dict", "(", "self", ".", "initial_optim_state_dict", ")", "\n", "", "if", "self", ".", "action_prior", "==", "\"gaussian\"", ":", "\n", "            ", "self", ".", "action_prior_distribution", "=", "Gaussian", "(", "\n", "dim", "=", "np", ".", "prod", "(", "self", ".", "agent", ".", "env_spaces", ".", "action", ".", "shape", ")", ",", "std", "=", "1.", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.qpg.sac.SAC.initialize_replay_buffer": [[130, 159], ["SamplesToBuffer", "dict", "ReplayCls", "SamplesToBufferTl", "rlpyt.utils.logging.logger.log"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.logging.console.log"], ["", "", "def", "initialize_replay_buffer", "(", "self", ",", "examples", ",", "batch_spec", ",", "async_", "=", "False", ")", ":", "\n", "        ", "\"\"\"\n        Allocates replay buffer using examples and with the fields in `SamplesToBuffer`\n        namedarraytuple.\n        \"\"\"", "\n", "example_to_buffer", "=", "SamplesToBuffer", "(", "\n", "observation", "=", "examples", "[", "\"observation\"", "]", ",", "\n", "action", "=", "examples", "[", "\"action\"", "]", ",", "\n", "reward", "=", "examples", "[", "\"reward\"", "]", ",", "\n", "done", "=", "examples", "[", "\"done\"", "]", ",", "\n", ")", "\n", "if", "not", "self", ".", "bootstrap_timelimit", ":", "\n", "            ", "ReplayCls", "=", "AsyncUniformReplayBuffer", "if", "async_", "else", "UniformReplayBuffer", "\n", "", "else", ":", "\n", "            ", "example_to_buffer", "=", "SamplesToBufferTl", "(", "*", "example_to_buffer", ",", "\n", "timeout", "=", "examples", "[", "\"env_info\"", "]", ".", "timeout", ")", "\n", "ReplayCls", "=", "AsyncTlUniformReplayBuffer", "if", "async_", "else", "TlUniformReplayBuffer", "\n", "", "replay_kwargs", "=", "dict", "(", "\n", "example", "=", "example_to_buffer", ",", "\n", "size", "=", "self", ".", "replay_size", ",", "\n", "B", "=", "batch_spec", ".", "B", ",", "\n", "n_step_return", "=", "self", ".", "n_step_return", ",", "\n", ")", "\n", "if", "self", ".", "ReplayBufferCls", "is", "not", "None", ":", "\n", "            ", "ReplayCls", "=", "self", ".", "ReplayBufferCls", "\n", "logger", ".", "log", "(", "f\"WARNING: ignoring internal selection logic and using\"", "\n", "f\" input replay buffer class: {ReplayCls} -- compatibility not\"", "\n", "\" guaranteed.\"", ")", "\n", "", "self", ".", "replay_buffer", "=", "ReplayCls", "(", "**", "replay_kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.qpg.sac.SAC.optimize_agent": [[160, 212], ["OptInfo", "range", "sac.SAC.samples_to_buffer", "sac.SAC.replay_buffer.append_samples", "sac.SAC.replay_buffer.sample_batch", "sac.SAC.loss", "sac.SAC.pi_optimizer.zero_grad", "pi_loss.backward", "torch.nn.utils.clip_grad_norm_", "sac.SAC.pi_optimizer.step", "sac.SAC.q1_optimizer.zero_grad", "q1_loss.backward", "torch.nn.utils.clip_grad_norm_", "sac.SAC.q1_optimizer.step", "sac.SAC.q2_optimizer.zero_grad", "q2_loss.backward", "torch.nn.utils.clip_grad_norm_", "sac.SAC.q2_optimizer.step", "sac.SAC.append_opt_info_", "sac.SAC.alpha_optimizer.zero_grad", "alpha_loss.backward", "sac.SAC.alpha_optimizer.step", "torch.exp", "sac.SAC.agent.pi_parameters", "sac.SAC.agent.q1_parameters", "sac.SAC.agent.q2_parameters", "sac.SAC.agent.update_target", "sac.SAC._log_alpha.detach", "range", "len"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.rl_with_ul.ppo_with_ul.PpoUl.samples_to_buffer", "home.repos.pwc.inspect_result.astooke_rlpyt.sequence.prioritized.PrioritizedSequenceReplay.append_samples", "home.repos.pwc.inspect_result.astooke_rlpyt.sequence.uniform.UniformSequenceReplay.sample_batch", "home.repos.pwc.inspect_result.astooke_rlpyt.safe.cppo_pid.CppoPID.loss", "home.repos.pwc.inspect_result.astooke_rlpyt.models.utils.ScaleGrad.backward", "home.repos.pwc.inspect_result.astooke_rlpyt.safe.safety_gym_env.SafetyGymTrajInfo.step", "home.repos.pwc.inspect_result.astooke_rlpyt.models.utils.ScaleGrad.backward", "home.repos.pwc.inspect_result.astooke_rlpyt.safe.safety_gym_env.SafetyGymTrajInfo.step", "home.repos.pwc.inspect_result.astooke_rlpyt.models.utils.ScaleGrad.backward", "home.repos.pwc.inspect_result.astooke_rlpyt.safe.safety_gym_env.SafetyGymTrajInfo.step", "home.repos.pwc.inspect_result.astooke_rlpyt.qpg.sac.SAC.append_opt_info_", "home.repos.pwc.inspect_result.astooke_rlpyt.models.utils.ScaleGrad.backward", "home.repos.pwc.inspect_result.astooke_rlpyt.safe.safety_gym_env.SafetyGymTrajInfo.step", "home.repos.pwc.inspect_result.astooke_rlpyt.qpg.sac_agent.SacAgent.pi_parameters", "home.repos.pwc.inspect_result.astooke_rlpyt.qpg.sac_agent.SacAgent.q1_parameters", "home.repos.pwc.inspect_result.astooke_rlpyt.qpg.sac_agent.SacAgent.q2_parameters", "home.repos.pwc.inspect_result.astooke_rlpyt.agents.atari_dqn_agent.AtariDqnAgent.update_target"], ["", "def", "optimize_agent", "(", "self", ",", "itr", ",", "samples", "=", "None", ",", "sampler_itr", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Extracts the needed fields from input samples and stores them in the \n        replay buffer.  Then samples from the replay buffer to train the agent\n        by gradient updates (with the number of updates determined by replay\n        ratio, sampler batch size, and training batch size).\n        \"\"\"", "\n", "itr", "=", "itr", "if", "sampler_itr", "is", "None", "else", "sampler_itr", "# Async uses sampler_itr.", "\n", "if", "samples", "is", "not", "None", ":", "\n", "            ", "samples_to_buffer", "=", "self", ".", "samples_to_buffer", "(", "samples", ")", "\n", "self", ".", "replay_buffer", ".", "append_samples", "(", "samples_to_buffer", ")", "\n", "", "opt_info", "=", "OptInfo", "(", "*", "(", "[", "]", "for", "_", "in", "range", "(", "len", "(", "OptInfo", ".", "_fields", ")", ")", ")", ")", "\n", "if", "itr", "<", "self", ".", "min_itr_learn", ":", "\n", "            ", "return", "opt_info", "\n", "", "for", "_", "in", "range", "(", "self", ".", "updates_per_optimize", ")", ":", "\n", "            ", "samples_from_replay", "=", "self", ".", "replay_buffer", ".", "sample_batch", "(", "self", ".", "batch_size", ")", "\n", "losses", ",", "values", "=", "self", ".", "loss", "(", "samples_from_replay", ")", "\n", "q1_loss", ",", "q2_loss", ",", "pi_loss", ",", "alpha_loss", "=", "losses", "\n", "\n", "if", "alpha_loss", "is", "not", "None", ":", "\n", "                ", "self", ".", "alpha_optimizer", ".", "zero_grad", "(", ")", "\n", "alpha_loss", ".", "backward", "(", ")", "\n", "self", ".", "alpha_optimizer", ".", "step", "(", ")", "\n", "self", ".", "_alpha", "=", "torch", ".", "exp", "(", "self", ".", "_log_alpha", ".", "detach", "(", ")", ")", "\n", "\n", "", "self", ".", "pi_optimizer", ".", "zero_grad", "(", ")", "\n", "pi_loss", ".", "backward", "(", ")", "\n", "pi_grad_norm", "=", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "self", ".", "agent", ".", "pi_parameters", "(", ")", ",", "\n", "self", ".", "clip_grad_norm", ")", "\n", "self", ".", "pi_optimizer", ".", "step", "(", ")", "\n", "\n", "# Step Q's last because pi_loss.backward() uses them?", "\n", "self", ".", "q1_optimizer", ".", "zero_grad", "(", ")", "\n", "q1_loss", ".", "backward", "(", ")", "\n", "q1_grad_norm", "=", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "self", ".", "agent", ".", "q1_parameters", "(", ")", ",", "\n", "self", ".", "clip_grad_norm", ")", "\n", "self", ".", "q1_optimizer", ".", "step", "(", ")", "\n", "\n", "self", ".", "q2_optimizer", ".", "zero_grad", "(", ")", "\n", "q2_loss", ".", "backward", "(", ")", "\n", "q2_grad_norm", "=", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "self", ".", "agent", ".", "q2_parameters", "(", ")", ",", "\n", "self", ".", "clip_grad_norm", ")", "\n", "self", ".", "q2_optimizer", ".", "step", "(", ")", "\n", "\n", "grad_norms", "=", "(", "q1_grad_norm", ",", "q2_grad_norm", ",", "pi_grad_norm", ")", "\n", "\n", "self", ".", "append_opt_info_", "(", "opt_info", ",", "losses", ",", "grad_norms", ",", "values", ")", "\n", "self", ".", "update_counter", "+=", "1", "\n", "if", "self", ".", "update_counter", "%", "self", ".", "target_update_interval", "==", "0", ":", "\n", "                ", "self", ".", "agent", ".", "update_target", "(", "self", ".", "target_update_tau", ")", "\n", "\n", "", "", "return", "opt_info", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.qpg.sac.SAC.samples_to_buffer": [[213, 226], ["SamplesToBuffer", "SamplesToBufferTl"], "methods", ["None"], ["", "def", "samples_to_buffer", "(", "self", ",", "samples", ")", ":", "\n", "        ", "\"\"\"Defines how to add data from sampler into the replay buffer. Called\n        in optimize_agent() if samples are provided to that method.\"\"\"", "\n", "samples_to_buffer", "=", "SamplesToBuffer", "(", "\n", "observation", "=", "samples", ".", "env", ".", "observation", ",", "\n", "action", "=", "samples", ".", "agent", ".", "action", ",", "\n", "reward", "=", "samples", ".", "env", ".", "reward", ",", "\n", "done", "=", "samples", ".", "env", ".", "done", ",", "\n", ")", "\n", "if", "self", ".", "bootstrap_timelimit", ":", "\n", "            ", "samples_to_buffer", "=", "SamplesToBufferTl", "(", "*", "samples_to_buffer", ",", "\n", "timeout", "=", "samples", ".", "env", ".", "env_info", ".", "timeout", ")", "\n", "", "return", "samples_to_buffer", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.qpg.sac.SAC.loss": [[227, 286], ["rlpyt.utils.buffer.buffer_to", "sac.SAC.agent.q", "torch.min", "sac.SAC.agent.pi", "sac.SAC.agent.q", "torch.min", "sac.SAC.get_action_prior", "rlpyt.utils.tensor.valid_mean", "tuple", "torch.ones_like", "rlpyt.algos.utils.valid_from_done", "torch.no_grad", "sac.SAC.agent.pi", "sac.SAC.agent.target_q", "rlpyt.utils.tensor.valid_mean", "rlpyt.utils.tensor.valid_mean", "new_action.detach.detach.detach", "new_action.detach.detach.cpu", "rlpyt.utils.tensor.valid_mean", "samples.timeout_n.float", "val.detach", "log_pi.detach", "samples.done_n.float"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.utils.buffer.buffer_to", "home.repos.pwc.inspect_result.astooke_rlpyt.agents.dmc_sac_agent.SacAgent.q", "home.repos.pwc.inspect_result.astooke_rlpyt.agents.dmc_sac_agent.SacAgent.pi", "home.repos.pwc.inspect_result.astooke_rlpyt.agents.dmc_sac_agent.SacAgent.q", "home.repos.pwc.inspect_result.astooke_rlpyt.rl_with_ul.sac_with_ul.SacWithUl.get_action_prior", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.tensor.valid_mean", "home.repos.pwc.inspect_result.astooke_rlpyt.algos.utils.valid_from_done", "home.repos.pwc.inspect_result.astooke_rlpyt.agents.dmc_sac_agent.SacAgent.pi", "home.repos.pwc.inspect_result.astooke_rlpyt.agents.dmc_sac_agent.SacAgent.target_q", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.tensor.valid_mean", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.tensor.valid_mean", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.tensor.valid_mean"], ["", "def", "loss", "(", "self", ",", "samples", ")", ":", "\n", "        ", "\"\"\"\n        Computes losses for twin Q-values against the min of twin target Q-values\n        and an entropy term.  Computes reparameterized policy loss, and loss for\n        tuning entropy weighting, alpha.  \n        \n        Input samples have leading batch dimension [B,..] (but not time).\n        \"\"\"", "\n", "agent_inputs", ",", "target_inputs", ",", "action", "=", "buffer_to", "(", "\n", "(", "samples", ".", "agent_inputs", ",", "samples", ".", "target_inputs", ",", "samples", ".", "action", ")", ")", "\n", "\n", "if", "self", ".", "mid_batch_reset", "and", "not", "self", ".", "agent", ".", "recurrent", ":", "\n", "            ", "valid", "=", "torch", ".", "ones_like", "(", "samples", ".", "done", ",", "dtype", "=", "torch", ".", "float", ")", "# or None", "\n", "", "else", ":", "\n", "            ", "valid", "=", "valid_from_done", "(", "samples", ".", "done", ")", "\n", "", "if", "self", ".", "bootstrap_timelimit", ":", "\n", "# To avoid non-use of bootstrap when environment is 'done' due to", "\n", "# time-limit, turn off training on these samples.", "\n", "            ", "valid", "*=", "(", "1", "-", "samples", ".", "timeout_n", ".", "float", "(", ")", ")", "\n", "\n", "", "q1", ",", "q2", "=", "self", ".", "agent", ".", "q", "(", "*", "agent_inputs", ",", "action", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "target_action", ",", "target_log_pi", ",", "_", "=", "self", ".", "agent", ".", "pi", "(", "*", "target_inputs", ")", "\n", "target_q1", ",", "target_q2", "=", "self", ".", "agent", ".", "target_q", "(", "*", "target_inputs", ",", "target_action", ")", "\n", "", "min_target_q", "=", "torch", ".", "min", "(", "target_q1", ",", "target_q2", ")", "\n", "target_value", "=", "min_target_q", "-", "self", ".", "_alpha", "*", "target_log_pi", "\n", "disc", "=", "self", ".", "discount", "**", "self", ".", "n_step_return", "\n", "y", "=", "(", "self", ".", "reward_scale", "*", "samples", ".", "return_", "+", "\n", "(", "1", "-", "samples", ".", "done_n", ".", "float", "(", ")", ")", "*", "disc", "*", "target_value", ")", "\n", "\n", "q1_loss", "=", "0.5", "*", "valid_mean", "(", "(", "y", "-", "q1", ")", "**", "2", ",", "valid", ")", "\n", "q2_loss", "=", "0.5", "*", "valid_mean", "(", "(", "y", "-", "q2", ")", "**", "2", ",", "valid", ")", "\n", "\n", "new_action", ",", "log_pi", ",", "(", "pi_mean", ",", "pi_log_std", ")", "=", "self", ".", "agent", ".", "pi", "(", "*", "agent_inputs", ")", "\n", "if", "not", "self", ".", "reparameterize", ":", "\n", "            ", "new_action", "=", "new_action", ".", "detach", "(", ")", "# No grad.", "\n", "", "log_target1", ",", "log_target2", "=", "self", ".", "agent", ".", "q", "(", "*", "agent_inputs", ",", "new_action", ")", "\n", "min_log_target", "=", "torch", ".", "min", "(", "log_target1", ",", "log_target2", ")", "\n", "prior_log_pi", "=", "self", ".", "get_action_prior", "(", "new_action", ".", "cpu", "(", ")", ")", "\n", "\n", "if", "self", ".", "reparameterize", ":", "\n", "            ", "pi_losses", "=", "self", ".", "_alpha", "*", "log_pi", "-", "min_log_target", "-", "prior_log_pi", "\n", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "\n", "\n", "# if self.policy_output_regularization > 0:", "\n", "#     pi_losses += self.policy_output_regularization * torch.mean(", "\n", "#         0.5 * pi_mean ** 2 + 0.5 * pi_log_std ** 2, dim=-1)", "\n", "", "pi_loss", "=", "valid_mean", "(", "pi_losses", ",", "valid", ")", "\n", "\n", "if", "self", ".", "target_entropy", "is", "not", "None", "and", "self", ".", "fixed_alpha", "is", "None", ":", "\n", "            ", "alpha_losses", "=", "-", "self", ".", "_log_alpha", "*", "(", "log_pi", ".", "detach", "(", ")", "+", "self", ".", "target_entropy", ")", "\n", "alpha_loss", "=", "valid_mean", "(", "alpha_losses", ",", "valid", ")", "\n", "", "else", ":", "\n", "            ", "alpha_loss", "=", "None", "\n", "\n", "", "losses", "=", "(", "q1_loss", ",", "q2_loss", ",", "pi_loss", ",", "alpha_loss", ")", "\n", "values", "=", "tuple", "(", "val", ".", "detach", "(", ")", "for", "val", "in", "(", "q1", ",", "q2", ",", "pi_mean", ",", "pi_log_std", ")", ")", "\n", "return", "losses", ",", "values", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.qpg.sac.SAC.get_action_prior": [[287, 294], ["sac.SAC.action_prior_distribution.log_likelihood", "rlpyt.distributions.gaussian.DistInfo", "torch.zeros_like"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.distributions.gaussian.Gaussian.log_likelihood"], ["", "def", "get_action_prior", "(", "self", ",", "action", ")", ":", "\n", "        ", "if", "self", ".", "action_prior", "==", "\"uniform\"", ":", "\n", "            ", "prior_log_pi", "=", "0.0", "\n", "", "elif", "self", ".", "action_prior", "==", "\"gaussian\"", ":", "\n", "            ", "prior_log_pi", "=", "self", ".", "action_prior_distribution", ".", "log_likelihood", "(", "\n", "action", ",", "GaussianDistInfo", "(", "mean", "=", "torch", ".", "zeros_like", "(", "action", ")", ")", ")", "\n", "", "return", "prior_log_pi", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.qpg.sac.SAC.append_opt_info_": [[295, 312], ["opt_info.q1Loss.append", "opt_info.q2Loss.append", "opt_info.piLoss.append", "opt_info.q1GradNorm.append", "opt_info.q2GradNorm.append", "opt_info.piGradNorm.append", "opt_info.q1.extend", "opt_info.q2.extend", "opt_info.piMu.extend", "opt_info.piLogStd.extend", "opt_info.qMeanDiff.append", "opt_info.alpha.append", "q1_loss.item", "q2_loss.item", "pi_loss.item", "torch.tensor().item", "torch.tensor().item", "torch.tensor().item", "q1[].numpy", "q2[].numpy", "pi_mean[].numpy", "pi_log_std[].numpy", "torch.mean().item", "sac.SAC._alpha.item", "torch.tensor", "torch.tensor", "torch.tensor", "torch.mean", "abs"], "methods", ["None"], ["", "def", "append_opt_info_", "(", "self", ",", "opt_info", ",", "losses", ",", "grad_norms", ",", "values", ")", ":", "\n", "        ", "\"\"\"In-place.\"\"\"", "\n", "q1_loss", ",", "q2_loss", ",", "pi_loss", ",", "alpha_loss", "=", "losses", "\n", "q1_grad_norm", ",", "q2_grad_norm", ",", "pi_grad_norm", "=", "grad_norms", "\n", "q1", ",", "q2", ",", "pi_mean", ",", "pi_log_std", "=", "values", "\n", "opt_info", ".", "q1Loss", ".", "append", "(", "q1_loss", ".", "item", "(", ")", ")", "\n", "opt_info", ".", "q2Loss", ".", "append", "(", "q2_loss", ".", "item", "(", ")", ")", "\n", "opt_info", ".", "piLoss", ".", "append", "(", "pi_loss", ".", "item", "(", ")", ")", "\n", "opt_info", ".", "q1GradNorm", ".", "append", "(", "torch", ".", "tensor", "(", "q1_grad_norm", ")", ".", "item", "(", ")", ")", "# backwards compatible", "\n", "opt_info", ".", "q2GradNorm", ".", "append", "(", "torch", ".", "tensor", "(", "q2_grad_norm", ")", ".", "item", "(", ")", ")", "# backwards compatible", "\n", "opt_info", ".", "piGradNorm", ".", "append", "(", "torch", ".", "tensor", "(", "pi_grad_norm", ")", ".", "item", "(", ")", ")", "# backwards compatible", "\n", "opt_info", ".", "q1", ".", "extend", "(", "q1", "[", ":", ":", "10", "]", ".", "numpy", "(", ")", ")", "# Downsample for stats.", "\n", "opt_info", ".", "q2", ".", "extend", "(", "q2", "[", ":", ":", "10", "]", ".", "numpy", "(", ")", ")", "\n", "opt_info", ".", "piMu", ".", "extend", "(", "pi_mean", "[", ":", ":", "10", "]", ".", "numpy", "(", ")", ")", "\n", "opt_info", ".", "piLogStd", ".", "extend", "(", "pi_log_std", "[", ":", ":", "10", "]", ".", "numpy", "(", ")", ")", "\n", "opt_info", ".", "qMeanDiff", ".", "append", "(", "torch", ".", "mean", "(", "abs", "(", "q1", "-", "q2", ")", ")", ".", "item", "(", ")", ")", "\n", "opt_info", ".", "alpha", ".", "append", "(", "self", ".", "_alpha", ".", "item", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.qpg.sac.SAC.optim_state_dict": [[313, 320], ["dict", "sac.SAC.pi_optimizer.state_dict", "sac.SAC.q1_optimizer.state_dict", "sac.SAC.q2_optimizer.state_dict", "sac.SAC._log_alpha.detach().item", "sac.SAC.alpha_optimizer.state_dict", "sac.SAC._log_alpha.detach"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.replay_saver.DummyOptimizer.state_dict", "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.replay_saver.DummyOptimizer.state_dict", "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.replay_saver.DummyOptimizer.state_dict", "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.replay_saver.DummyOptimizer.state_dict"], ["", "def", "optim_state_dict", "(", "self", ")", ":", "\n", "        ", "return", "dict", "(", "\n", "pi_optimizer", "=", "self", ".", "pi_optimizer", ".", "state_dict", "(", ")", ",", "\n", "q1_optimizer", "=", "self", ".", "q1_optimizer", ".", "state_dict", "(", ")", ",", "\n", "q2_optimizer", "=", "self", ".", "q2_optimizer", ".", "state_dict", "(", ")", ",", "\n", "alpha_optimizer", "=", "self", ".", "alpha_optimizer", ".", "state_dict", "(", ")", "if", "self", ".", "alpha_optimizer", "else", "None", ",", "\n", "log_alpha", "=", "self", ".", "_log_alpha", ".", "detach", "(", ")", ".", "item", "(", ")", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.qpg.sac.SAC.load_optim_state_dict": [[322, 331], ["sac.SAC.pi_optimizer.load_state_dict", "sac.SAC.q1_optimizer.load_state_dict", "sac.SAC.q2_optimizer.load_state_dict", "sac.SAC.alpha_optimizer.load_state_dict", "torch.no_grad", "torch.exp", "sac.SAC._log_alpha.detach"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.augmented_temporal_similarity.AugmentedTemporalSimilarity.load_state_dict", "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.augmented_temporal_similarity.AugmentedTemporalSimilarity.load_state_dict", "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.augmented_temporal_similarity.AugmentedTemporalSimilarity.load_state_dict", "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.augmented_temporal_similarity.AugmentedTemporalSimilarity.load_state_dict"], ["", "def", "load_optim_state_dict", "(", "self", ",", "state_dict", ")", ":", "\n", "        ", "self", ".", "pi_optimizer", ".", "load_state_dict", "(", "state_dict", "[", "\"pi_optimizer\"", "]", ")", "\n", "self", ".", "q1_optimizer", ".", "load_state_dict", "(", "state_dict", "[", "\"q1_optimizer\"", "]", ")", "\n", "self", ".", "q2_optimizer", ".", "load_state_dict", "(", "state_dict", "[", "\"q2_optimizer\"", "]", ")", "\n", "if", "self", ".", "alpha_optimizer", "is", "not", "None", "and", "state_dict", "[", "\"alpha_optimizer\"", "]", "is", "not", "None", ":", "\n", "            ", "self", ".", "alpha_optimizer", ".", "load_state_dict", "(", "state_dict", "[", "\"alpha_optimizer\"", "]", ")", "\n", "", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "self", ".", "_log_alpha", "[", ":", "]", "=", "state_dict", "[", "\"log_alpha\"", "]", "\n", "self", ".", "_alpha", "=", "torch", ".", "exp", "(", "self", ".", "_log_alpha", ".", "detach", "(", ")", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.astooke_rlpyt.qpg.ddpg.DDPG.__init__": [[28, 56], ["int", "int", "rlpyt.utils.quick_args.save__init__args", "dict", "locals"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.utils.quick_args.save__init__args"], ["def", "__init__", "(", "\n", "self", ",", "\n", "discount", "=", "0.99", ",", "\n", "batch_size", "=", "64", ",", "\n", "min_steps_learn", "=", "int", "(", "1e4", ")", ",", "\n", "replay_size", "=", "int", "(", "1e6", ")", ",", "\n", "replay_ratio", "=", "64", ",", "# data_consumption / data_generation", "\n", "target_update_tau", "=", "0.01", ",", "\n", "target_update_interval", "=", "1", ",", "\n", "policy_update_interval", "=", "1", ",", "\n", "learning_rate", "=", "1e-4", ",", "\n", "q_learning_rate", "=", "1e-3", ",", "\n", "OptimCls", "=", "torch", ".", "optim", ".", "Adam", ",", "\n", "optim_kwargs", "=", "None", ",", "\n", "initial_optim_state_dict", "=", "None", ",", "\n", "clip_grad_norm", "=", "1e8", ",", "\n", "q_target_clip", "=", "1e6", ",", "\n", "n_step_return", "=", "1", ",", "\n", "updates_per_sync", "=", "1", ",", "# For async mode only.", "\n", "bootstrap_timelimit", "=", "True", ",", "\n", "ReplayBufferCls", "=", "None", ",", "\n", ")", ":", "\n", "        ", "\"\"\"Saves input arguments.\"\"\"", "\n", "if", "optim_kwargs", "is", "None", ":", "\n", "            ", "optim_kwargs", "=", "dict", "(", ")", "\n", "", "self", ".", "_batch_size", "=", "batch_size", "\n", "del", "batch_size", "# Property.", "\n", "save__init__args", "(", "locals", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.qpg.ddpg.DDPG.initialize": [[57, 77], ["max", "rlpyt.utils.logging.logger.log", "int", "ddpg.DDPG.initialize_replay_buffer", "ddpg.DDPG.optim_initialize", "round"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.logging.console.log", "home.repos.pwc.inspect_result.astooke_rlpyt.rl_with_ul.ppo_with_ul.PpoUl.initialize_replay_buffer", "home.repos.pwc.inspect_result.astooke_rlpyt.rl_with_ul.sac_with_ul.SacWithUl.optim_initialize"], ["", "def", "initialize", "(", "self", ",", "agent", ",", "n_itr", ",", "batch_spec", ",", "mid_batch_reset", ",", "examples", ",", "\n", "world_size", "=", "1", ",", "rank", "=", "0", ")", ":", "\n", "        ", "\"\"\"Stores input arguments and initializes replay buffer and optimizer.\n        Use in non-async runners.  Computes number of gradient updates per\n        optimization iteration as `(replay_ratio * sampler-batch-size /\n        training-batch_size)`.\"\"\"", "\n", "self", ".", "agent", "=", "agent", "\n", "self", ".", "n_itr", "=", "n_itr", "\n", "self", ".", "mid_batch_reset", "=", "mid_batch_reset", "\n", "self", ".", "sampler_bs", "=", "sampler_bs", "=", "batch_spec", ".", "size", "\n", "self", ".", "updates_per_optimize", "=", "max", "(", "1", ",", "round", "(", "self", ".", "replay_ratio", "*", "sampler_bs", "/", "\n", "self", ".", "batch_size", ")", ")", "\n", "logger", ".", "log", "(", "f\"From sampler batch size {sampler_bs}, training \"", "\n", "f\"batch size {self.batch_size}, and replay ratio \"", "\n", "f\"{self.replay_ratio}, computed {self.updates_per_optimize} \"", "\n", "f\"updates per iteration.\"", ")", "\n", "self", ".", "min_itr_learn", "=", "int", "(", "self", ".", "min_steps_learn", "//", "sampler_bs", ")", "\n", "# Agent give min itr learn.?", "\n", "self", ".", "initialize_replay_buffer", "(", "examples", ",", "batch_spec", ")", "\n", "self", ".", "optim_initialize", "(", "rank", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.qpg.ddpg.DDPG.async_initialize": [[78, 90], ["ddpg.DDPG.initialize_replay_buffer", "int"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.rl_with_ul.ppo_with_ul.PpoUl.initialize_replay_buffer"], ["", "def", "async_initialize", "(", "self", ",", "agent", ",", "sampler_n_itr", ",", "batch_spec", ",", "mid_batch_reset", ",", "\n", "examples", ",", "world_size", "=", "1", ")", ":", "\n", "        ", "\"\"\"Used in async runner only; returns replay buffer allocated in shared\n        memory, does not instantiate optimizer. \"\"\"", "\n", "self", ".", "agent", "=", "agent", "\n", "self", ".", "n_itr", "=", "sampler_n_itr", "\n", "self", ".", "initialize_replay_buffer", "(", "examples", ",", "batch_spec", ",", "async_", "=", "True", ")", "\n", "self", ".", "mid_batch_reset", "=", "mid_batch_reset", "\n", "self", ".", "sampler_bs", "=", "sampler_bs", "=", "batch_spec", ".", "size", "\n", "self", ".", "updates_per_optimize", "=", "self", ".", "updates_per_sync", "\n", "self", ".", "min_itr_learn", "=", "int", "(", "self", ".", "min_steps_learn", "//", "sampler_bs", ")", "\n", "return", "self", ".", "replay_buffer", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.qpg.ddpg.DDPG.optim_initialize": [[91, 101], ["ddpg.DDPG.OptimCls", "ddpg.DDPG.OptimCls", "ddpg.DDPG.agent.mu_parameters", "ddpg.DDPG.agent.q_parameters", "ddpg.DDPG.q_optimizer.load_state_dict", "ddpg.DDPG.mu_optimizer.load_state_dict"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.qpg.ddpg_agent.DdpgAgent.mu_parameters", "home.repos.pwc.inspect_result.astooke_rlpyt.qpg.td3_agent.Td3Agent.q_parameters", "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.augmented_temporal_similarity.AugmentedTemporalSimilarity.load_state_dict", "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.augmented_temporal_similarity.AugmentedTemporalSimilarity.load_state_dict"], ["", "def", "optim_initialize", "(", "self", ",", "rank", "=", "0", ")", ":", "\n", "        ", "\"\"\"Called in initilize or by async runner after forking sampler.\"\"\"", "\n", "self", ".", "rank", "=", "rank", "\n", "self", ".", "mu_optimizer", "=", "self", ".", "OptimCls", "(", "self", ".", "agent", ".", "mu_parameters", "(", ")", ",", "\n", "lr", "=", "self", ".", "learning_rate", ",", "**", "self", ".", "optim_kwargs", ")", "\n", "self", ".", "q_optimizer", "=", "self", ".", "OptimCls", "(", "self", ".", "agent", ".", "q_parameters", "(", ")", ",", "\n", "lr", "=", "self", ".", "q_learning_rate", ",", "**", "self", ".", "optim_kwargs", ")", "\n", "if", "self", ".", "initial_optim_state_dict", "is", "not", "None", ":", "\n", "            ", "self", ".", "q_optimizer", ".", "load_state_dict", "(", "self", ".", "initial_optim_state_dict", "[", "\"q\"", "]", ")", "\n", "self", ".", "mu_optimizer", ".", "load_state_dict", "(", "self", ".", "initial_optim_state_dict", "[", "\"mu\"", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.qpg.ddpg.DDPG.initialize_replay_buffer": [[102, 130], ["SamplesToBuffer", "dict", "ReplayCls", "rlpyt.utils.logging.logger.log", "getattr"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.logging.console.log"], ["", "", "def", "initialize_replay_buffer", "(", "self", ",", "examples", ",", "batch_spec", ",", "async_", "=", "False", ")", ":", "\n", "        ", "\"\"\"\n        Allocates replay buffer using examples and with the fields in `SamplesToBuffer`\n        namedarraytuple.\n        \"\"\"", "\n", "example_to_buffer", "=", "SamplesToBuffer", "(", "\n", "observation", "=", "examples", "[", "\"observation\"", "]", ",", "\n", "action", "=", "examples", "[", "\"action\"", "]", ",", "\n", "reward", "=", "examples", "[", "\"reward\"", "]", ",", "\n", "done", "=", "examples", "[", "\"done\"", "]", ",", "\n", "timeout", "=", "getattr", "(", "examples", "[", "\"env_info\"", "]", ",", "\"timeout\"", ",", "None", ")", "\n", ")", "\n", "replay_kwargs", "=", "dict", "(", "\n", "example", "=", "example_to_buffer", ",", "\n", "size", "=", "self", ".", "replay_size", ",", "\n", "B", "=", "batch_spec", ".", "B", ",", "\n", "n_step_return", "=", "self", ".", "n_step_return", ",", "\n", ")", "\n", "if", "not", "self", ".", "bootstrap_timelimit", ":", "\n", "            ", "ReplayCls", "=", "AsyncUniformReplayBuffer", "if", "async_", "else", "UniformReplayBuffer", "\n", "", "else", ":", "\n", "            ", "ReplayCls", "=", "AsyncTlUniformReplayBuffer", "if", "async_", "else", "TlUniformReplayBuffer", "\n", "", "if", "self", ".", "ReplayBufferCls", "is", "not", "None", ":", "\n", "            ", "ReplayCls", "=", "self", ".", "ReplayBufferCls", "\n", "logger", ".", "log", "(", "f\"WARNING: ignoring internal selection logic and using\"", "\n", "f\" input replay buffer class: {ReplayCls} -- compatibility not\"", "\n", "\" guaranteed.\"", ")", "\n", "", "self", ".", "replay_buffer", "=", "ReplayCls", "(", "**", "replay_kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.qpg.ddpg.DDPG.optimize_agent": [[131, 176], ["OptInfo", "range", "ddpg.DDPG.samples_to_buffer", "ddpg.DDPG.replay_buffer.append_samples", "ddpg.DDPG.replay_buffer.sample_batch", "ddpg.DDPG.q_optimizer.zero_grad", "ddpg.DDPG.q_loss", "ddpg.DDPG.backward", "torch.nn.utils.clip_grad_norm_", "ddpg.DDPG.q_optimizer.step", "OptInfo.qLoss.append", "OptInfo.qGradNorm.append", "torch.ones_like", "rlpyt.algos.utils.valid_from_done", "ddpg.DDPG.agent.q_parameters", "ddpg.DDPG.item", "torch.tensor().item", "ddpg.DDPG.mu_optimizer.zero_grad", "ddpg.DDPG.mu_loss", "ddpg.DDPG.backward", "torch.nn.utils.clip_grad_norm_", "ddpg.DDPG.mu_optimizer.step", "OptInfo.muLoss.append", "OptInfo.muGradNorm.append", "ddpg.DDPG.agent.update_target", "ddpg.DDPG.timeout_n.float", "ddpg.DDPG.agent.mu_parameters", "ddpg.DDPG.item", "torch.tensor().item", "range", "torch.tensor", "len", "torch.tensor"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.rl_with_ul.ppo_with_ul.PpoUl.samples_to_buffer", "home.repos.pwc.inspect_result.astooke_rlpyt.sequence.prioritized.PrioritizedSequenceReplay.append_samples", "home.repos.pwc.inspect_result.astooke_rlpyt.sequence.uniform.UniformSequenceReplay.sample_batch", "home.repos.pwc.inspect_result.astooke_rlpyt.rl_with_ul.sac_with_ul.SacWithUl.q_loss", "home.repos.pwc.inspect_result.astooke_rlpyt.models.utils.ScaleGrad.backward", "home.repos.pwc.inspect_result.astooke_rlpyt.safe.safety_gym_env.SafetyGymTrajInfo.step", "home.repos.pwc.inspect_result.astooke_rlpyt.algos.utils.valid_from_done", "home.repos.pwc.inspect_result.astooke_rlpyt.qpg.td3_agent.Td3Agent.q_parameters", "home.repos.pwc.inspect_result.astooke_rlpyt.qpg.ddpg.DDPG.mu_loss", "home.repos.pwc.inspect_result.astooke_rlpyt.models.utils.ScaleGrad.backward", "home.repos.pwc.inspect_result.astooke_rlpyt.safe.safety_gym_env.SafetyGymTrajInfo.step", "home.repos.pwc.inspect_result.astooke_rlpyt.agents.atari_dqn_agent.AtariDqnAgent.update_target", "home.repos.pwc.inspect_result.astooke_rlpyt.qpg.ddpg_agent.DdpgAgent.mu_parameters"], ["", "def", "optimize_agent", "(", "self", ",", "itr", ",", "samples", "=", "None", ",", "sampler_itr", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Extracts the needed fields from input samples and stores them in the \n        replay buffer.  Then samples from the replay buffer to train the agent\n        by gradient updates (with the number of updates determined by replay\n        ratio, sampler batch size, and training batch size).\n        \"\"\"", "\n", "itr", "=", "itr", "if", "sampler_itr", "is", "None", "else", "sampler_itr", "# Async uses sampler_itr.", "\n", "if", "samples", "is", "not", "None", ":", "\n", "            ", "samples_to_buffer", "=", "self", ".", "samples_to_buffer", "(", "samples", ")", "\n", "self", ".", "replay_buffer", ".", "append_samples", "(", "samples_to_buffer", ")", "\n", "", "opt_info", "=", "OptInfo", "(", "*", "(", "[", "]", "for", "_", "in", "range", "(", "len", "(", "OptInfo", ".", "_fields", ")", ")", ")", ")", "\n", "if", "itr", "<", "self", ".", "min_itr_learn", ":", "\n", "            ", "return", "opt_info", "\n", "", "for", "_", "in", "range", "(", "self", ".", "updates_per_optimize", ")", ":", "\n", "            ", "samples_from_replay", "=", "self", ".", "replay_buffer", ".", "sample_batch", "(", "self", ".", "batch_size", ")", "\n", "if", "self", ".", "mid_batch_reset", "and", "not", "self", ".", "agent", ".", "recurrent", ":", "\n", "                ", "valid", "=", "torch", ".", "ones_like", "(", "samples_from_replay", ".", "done", ",", "dtype", "=", "torch", ".", "float", ")", "\n", "", "else", ":", "\n", "                ", "valid", "=", "valid_from_done", "(", "samples_from_replay", ".", "done", ")", "\n", "", "if", "self", ".", "bootstrap_timelimit", ":", "\n", "# To avoid non-use of bootstrap when environment is 'done' due to", "\n", "# time-limit, turn off training on these samples.", "\n", "                ", "valid", "*=", "(", "1", "-", "samples_from_replay", ".", "timeout_n", ".", "float", "(", ")", ")", "\n", "", "self", ".", "q_optimizer", ".", "zero_grad", "(", ")", "\n", "q_loss", "=", "self", ".", "q_loss", "(", "samples_from_replay", ",", "valid", ")", "\n", "q_loss", ".", "backward", "(", ")", "\n", "q_grad_norm", "=", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "\n", "self", ".", "agent", ".", "q_parameters", "(", ")", ",", "self", ".", "clip_grad_norm", ")", "\n", "self", ".", "q_optimizer", ".", "step", "(", ")", "\n", "opt_info", ".", "qLoss", ".", "append", "(", "q_loss", ".", "item", "(", ")", ")", "\n", "opt_info", ".", "qGradNorm", ".", "append", "(", "torch", ".", "tensor", "(", "q_grad_norm", ")", ".", "item", "(", ")", ")", "# backwards compatible", "\n", "self", ".", "update_counter", "+=", "1", "\n", "if", "self", ".", "update_counter", "%", "self", ".", "policy_update_interval", "==", "0", ":", "\n", "                ", "self", ".", "mu_optimizer", ".", "zero_grad", "(", ")", "\n", "mu_loss", "=", "self", ".", "mu_loss", "(", "samples_from_replay", ",", "valid", ")", "\n", "mu_loss", ".", "backward", "(", ")", "\n", "mu_grad_norm", "=", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "\n", "self", ".", "agent", ".", "mu_parameters", "(", ")", ",", "self", ".", "clip_grad_norm", ")", "\n", "self", ".", "mu_optimizer", ".", "step", "(", ")", "\n", "opt_info", ".", "muLoss", ".", "append", "(", "mu_loss", ".", "item", "(", ")", ")", "\n", "opt_info", ".", "muGradNorm", ".", "append", "(", "torch", ".", "tensor", "(", "mu_grad_norm", ")", ".", "item", "(", ")", ")", "# backwards compatible", "\n", "", "if", "self", ".", "update_counter", "%", "self", ".", "target_update_interval", "==", "0", ":", "\n", "                ", "self", ".", "agent", ".", "update_target", "(", "self", ".", "target_update_tau", ")", "\n", "", "", "return", "opt_info", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.qpg.ddpg.DDPG.samples_to_buffer": [[177, 186], ["SamplesToBuffer", "getattr"], "methods", ["None"], ["", "def", "samples_to_buffer", "(", "self", ",", "samples", ")", ":", "\n", "        ", "\"\"\"Defines how to add data from sampler into the replay buffer. Called\n        in optimize_agent() if samples are provided to that method.\"\"\"", "\n", "return", "SamplesToBuffer", "(", "\n", "observation", "=", "samples", ".", "env", ".", "observation", ",", "\n", "action", "=", "samples", ".", "agent", ".", "action", ",", "\n", "reward", "=", "samples", ".", "env", ".", "reward", ",", "\n", "done", "=", "samples", ".", "env", ".", "done", ",", "\n", "timeout", "=", "getattr", "(", "samples", ".", "env", ".", "env_info", ",", "\"timeout\"", ",", "None", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.qpg.ddpg.DDPG.mu_loss": [[188, 193], ["ddpg.DDPG.agent.q_at_mu", "rlpyt.utils.tensor.valid_mean"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.qpg.ddpg_agent.DdpgAgent.q_at_mu", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.tensor.valid_mean"], ["", "def", "mu_loss", "(", "self", ",", "samples", ",", "valid", ")", ":", "\n", "        ", "\"\"\"Computes the mu_loss as the Q-value at that action.\"\"\"", "\n", "mu_losses", "=", "self", ".", "agent", ".", "q_at_mu", "(", "*", "samples", ".", "agent_inputs", ")", "\n", "mu_loss", "=", "valid_mean", "(", "mu_losses", ",", "valid", ")", "# valid can be None.", "\n", "return", "-", "mu_loss", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.qpg.ddpg.DDPG.q_loss": [[194, 206], ["ddpg.DDPG.agent.q", "torch.clamp", "rlpyt.utils.tensor.valid_mean", "torch.no_grad", "ddpg.DDPG.agent.target_q_at_mu", "samples.done_n.float"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.agents.dmc_sac_agent.SacAgent.q", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.tensor.valid_mean", "home.repos.pwc.inspect_result.astooke_rlpyt.qpg.td3_agent.Td3Agent.target_q_at_mu"], ["", "def", "q_loss", "(", "self", ",", "samples", ",", "valid", ")", ":", "\n", "        ", "\"\"\"Constructs the n-step Q-learning loss using target Q.  Input\n        samples have leading batch dimension [B,..] (but not time).\"\"\"", "\n", "q", "=", "self", ".", "agent", ".", "q", "(", "*", "samples", ".", "agent_inputs", ",", "samples", ".", "action", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "target_q", "=", "self", ".", "agent", ".", "target_q_at_mu", "(", "*", "samples", ".", "target_inputs", ")", "\n", "", "disc", "=", "self", ".", "discount", "**", "self", ".", "n_step_return", "\n", "y", "=", "samples", ".", "return_", "+", "(", "1", "-", "samples", ".", "done_n", ".", "float", "(", ")", ")", "*", "disc", "*", "target_q", "\n", "y", "=", "torch", ".", "clamp", "(", "y", ",", "-", "self", ".", "q_target_clip", ",", "self", ".", "q_target_clip", ")", "\n", "q_losses", "=", "0.5", "*", "(", "y", "-", "q", ")", "**", "2", "\n", "q_loss", "=", "valid_mean", "(", "q_losses", ",", "valid", ")", "# valid can be None.", "\n", "return", "q_loss", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.qpg.ddpg.DDPG.optim_state_dict": [[207, 210], ["dict", "ddpg.DDPG.q_optimizer.state_dict", "ddpg.DDPG.mu_optimizer.state_dict"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.replay_saver.DummyOptimizer.state_dict", "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.replay_saver.DummyOptimizer.state_dict"], ["", "def", "optim_state_dict", "(", "self", ")", ":", "\n", "        ", "return", "dict", "(", "q", "=", "self", ".", "q_optimizer", ".", "state_dict", "(", ")", ",", "\n", "mu", "=", "self", ".", "mu_optimizer", ".", "state_dict", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.qpg.ddpg.DDPG.load_optim_state_dict": [[211, 214], ["ddpg.DDPG.q_optimizer.load_state_dict", "ddpg.DDPG.mu_optimizer.load_state_dict"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.augmented_temporal_similarity.AugmentedTemporalSimilarity.load_state_dict", "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.augmented_temporal_similarity.AugmentedTemporalSimilarity.load_state_dict"], ["", "def", "load_optim_state_dict", "(", "self", ",", "state_dict", ")", ":", "\n", "        ", "self", ".", "q_optimizer", ".", "load_state_dict", "(", "state_dict", "[", "\"q\"", "]", ")", "\n", "self", ".", "mu_optimizer", ".", "load_state_dict", "(", "state_dict", "[", "\"mu\"", "]", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.astooke_rlpyt.qpg.td3.TD3.__init__": [[12, 28], ["rlpyt.algos.qpg.ddpg.DDPG.__init__", "rlpyt.utils.quick_args.save__init__args", "locals"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.spaces.gym_wrapper.GymSpaceWrapper.__init__", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.quick_args.save__init__args"], ["def", "__init__", "(", "\n", "self", ",", "\n", "batch_size", "=", "100", ",", "\n", "replay_ratio", "=", "100", ",", "# data_consumption / data_generation", "\n", "target_update_tau", "=", "0.005", ",", "\n", "target_update_interval", "=", "2", ",", "\n", "policy_update_interval", "=", "2", ",", "\n", "mu_learning_rate", "=", "1e-3", ",", "\n", "q_learning_rate", "=", "1e-3", ",", "\n", "**", "kwargs", "\n", ")", ":", "\n", "        ", "\"\"\"Saved input arguments.\"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "self", ".", "_batch_size", "=", "batch_size", "\n", "del", "batch_size", "# Property.", "\n", "save__init__args", "(", "locals", "(", ")", ",", "overwrite", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.qpg.td3.TD3.initialize": [[29, 32], ["super().initialize", "td3.TD3.agent.give_min_itr_learn"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.safe.cppo_agent.CppoLstmAgent.initialize", "home.repos.pwc.inspect_result.astooke_rlpyt.agents.dmc_sac_agent.SacAgent.give_min_itr_learn"], ["", "def", "initialize", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "initialize", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "self", ".", "agent", ".", "give_min_itr_learn", "(", "self", ".", "min_itr_learn", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.qpg.td3.TD3.async_initialize": [[33, 37], ["super().async_initialize", "td3.TD3.agent.give_min_itr_learn"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.rl_with_ul.sac_with_ul.SacWithUl.async_initialize", "home.repos.pwc.inspect_result.astooke_rlpyt.agents.dmc_sac_agent.SacAgent.give_min_itr_learn"], ["", "def", "async_initialize", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "ret", "=", "super", "(", ")", ".", "async_initialize", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "self", ".", "agent", ".", "give_min_itr_learn", "(", "self", ".", "min_itr_learn", ")", "\n", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.qpg.td3.TD3.q_loss": [[38, 51], ["td3.TD3.agent.q", "rlpyt.utils.tensor.valid_mean", "torch.no_grad", "td3.TD3.agent.target_q_at_mu", "torch.min", "samples.done_n.float"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.agents.dmc_sac_agent.SacAgent.q", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.tensor.valid_mean", "home.repos.pwc.inspect_result.astooke_rlpyt.qpg.td3_agent.Td3Agent.target_q_at_mu"], ["", "def", "q_loss", "(", "self", ",", "samples", ",", "valid", ")", ":", "\n", "        ", "\"\"\"Computes MSE Q-loss for twin Q-values and min of target-Q values.\"\"\"", "\n", "q1", ",", "q2", "=", "self", ".", "agent", ".", "q", "(", "*", "samples", ".", "agent_inputs", ",", "samples", ".", "action", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "target_q1", ",", "target_q2", "=", "self", ".", "agent", ".", "target_q_at_mu", "(", "\n", "*", "samples", ".", "target_inputs", ")", "# Includes target action noise.", "\n", "target_q", "=", "torch", ".", "min", "(", "target_q1", ",", "target_q2", ")", "\n", "", "disc", "=", "self", ".", "discount", "**", "self", ".", "n_step_return", "\n", "y", "=", "samples", ".", "return_", "+", "(", "1", "-", "samples", ".", "done_n", ".", "float", "(", ")", ")", "*", "disc", "*", "target_q", "\n", "q1_losses", "=", "0.5", "*", "(", "y", "-", "q1", ")", "**", "2", "\n", "q2_losses", "=", "0.5", "*", "(", "y", "-", "q2", ")", "**", "2", "\n", "q_loss", "=", "valid_mean", "(", "q1_losses", "+", "q2_losses", ",", "valid", ")", "# valid can be None.", "\n", "return", "q_loss", "\n", "", "", ""]], "home.repos.pwc.inspect_result.astooke_rlpyt.qpg.ddpg_agent.DdpgAgent.__init__": [[24, 42], ["rlpyt.utils.quick_args.save__init__args", "rlpyt.agents.base.BaseAgent.__init__", "dict", "dict", "locals"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.utils.quick_args.save__init__args", "home.repos.pwc.inspect_result.astooke_rlpyt.spaces.gym_wrapper.GymSpaceWrapper.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "ModelCls", "=", "MuMlpModel", ",", "# Mu model.", "\n", "QModelCls", "=", "QofMuMlpModel", ",", "\n", "model_kwargs", "=", "None", ",", "# Mu model.", "\n", "q_model_kwargs", "=", "None", ",", "\n", "initial_model_state_dict", "=", "None", ",", "# Mu model.", "\n", "initial_q_model_state_dict", "=", "None", ",", "\n", "action_std", "=", "0.1", ",", "\n", "action_noise_clip", "=", "None", ",", "\n", ")", ":", "\n", "        ", "\"\"\"Saves input arguments; default network sizes saved here.\"\"\"", "\n", "if", "model_kwargs", "is", "None", ":", "\n", "            ", "model_kwargs", "=", "dict", "(", "hidden_sizes", "=", "[", "400", ",", "300", "]", ")", "\n", "", "if", "q_model_kwargs", "is", "None", ":", "\n", "            ", "q_model_kwargs", "=", "dict", "(", "hidden_sizes", "=", "[", "400", ",", "300", "]", ")", "\n", "", "save__init__args", "(", "locals", "(", ")", ")", "\n", "super", "(", ")", ".", "__init__", "(", ")", "# For async setup.", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.qpg.ddpg_agent.DdpgAgent.initialize": [[43, 63], ["super().initialize", "ddpg_agent.DdpgAgent.QModelCls", "ddpg_agent.DdpgAgent.ModelCls", "ddpg_agent.DdpgAgent.QModelCls", "ddpg_agent.DdpgAgent.target_q_model.load_state_dict", "rlpyt.distributions.gaussian.Gaussian", "ddpg_agent.DdpgAgent.q_model.load_state_dict", "ddpg_agent.DdpgAgent.q_model.state_dict", "len"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.safe.cppo_agent.CppoLstmAgent.initialize", "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.augmented_temporal_similarity.AugmentedTemporalSimilarity.load_state_dict", "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.augmented_temporal_similarity.AugmentedTemporalSimilarity.load_state_dict", "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.replay_saver.DummyOptimizer.state_dict"], ["", "def", "initialize", "(", "self", ",", "env_spaces", ",", "share_memory", "=", "False", ",", "\n", "global_B", "=", "1", ",", "env_ranks", "=", "None", ")", ":", "\n", "        ", "\"\"\"Instantiates mu and q, and target_mu and target_q models.\"\"\"", "\n", "super", "(", ")", ".", "initialize", "(", "env_spaces", ",", "share_memory", ",", "\n", "global_B", "=", "global_B", ",", "env_ranks", "=", "env_ranks", ")", "\n", "self", ".", "q_model", "=", "self", ".", "QModelCls", "(", "**", "self", ".", "env_model_kwargs", ",", "\n", "**", "self", ".", "q_model_kwargs", ")", "\n", "if", "self", ".", "initial_q_model_state_dict", "is", "not", "None", ":", "\n", "            ", "self", ".", "q_model", ".", "load_state_dict", "(", "self", ".", "initial_q_model_state_dict", ")", "\n", "", "self", ".", "target_model", "=", "self", ".", "ModelCls", "(", "**", "self", ".", "env_model_kwargs", ",", "\n", "**", "self", ".", "model_kwargs", ")", "\n", "self", ".", "target_q_model", "=", "self", ".", "QModelCls", "(", "**", "self", ".", "env_model_kwargs", ",", "\n", "**", "self", ".", "q_model_kwargs", ")", "\n", "self", ".", "target_q_model", ".", "load_state_dict", "(", "self", ".", "q_model", ".", "state_dict", "(", ")", ")", "\n", "assert", "len", "(", "env_spaces", ".", "action", ".", "shape", ")", "==", "1", "\n", "self", ".", "distribution", "=", "Gaussian", "(", "\n", "dim", "=", "env_spaces", ".", "action", ".", "shape", "[", "0", "]", ",", "\n", "std", "=", "self", ".", "action_std", ",", "\n", "noise_clip", "=", "self", ".", "action_noise_clip", ",", "\n", "clip", "=", "env_spaces", ".", "action", ".", "high", "[", "0", "]", ",", "# Assume symmetric low=-high.", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.qpg.ddpg_agent.DdpgAgent.to_device": [[65, 70], ["super().to_device", "ddpg_agent.DdpgAgent.target_model.to", "ddpg_agent.DdpgAgent.q_model.to", "ddpg_agent.DdpgAgent.target_q_model.to"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.safe.cppo_agent.CppoLstmAgent.to_device"], ["", "def", "to_device", "(", "self", ",", "cuda_idx", "=", "None", ")", ":", "\n", "        ", "super", "(", ")", ".", "to_device", "(", "cuda_idx", ")", "# Takes care of self.model.", "\n", "self", ".", "target_model", ".", "to", "(", "self", ".", "device", ")", "\n", "self", ".", "q_model", ".", "to", "(", "self", ".", "device", ")", "\n", "self", ".", "target_q_model", ".", "to", "(", "self", ".", "device", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.qpg.ddpg_agent.DdpgAgent.data_parallel": [[71, 79], ["super().data_parallel", "torch.nn.parallel.DistributedDataParallel"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.safe.cppo_agent.CppoLstmAgent.data_parallel"], ["", "def", "data_parallel", "(", "self", ")", ":", "\n", "        ", "device_id", "=", "super", "(", ")", ".", "data_parallel", "(", ")", "# Takes care of self.model.", "\n", "self", ".", "q_model", "=", "DDP", "(", "\n", "self", ".", "q_model", ",", "\n", "device_ids", "=", "None", "if", "device_id", "is", "None", "else", "[", "device_id", "]", ",", "# 1 GPU.", "\n", "output_device", "=", "device_id", ",", "\n", ")", "\n", "return", "device_id", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.qpg.ddpg_agent.DdpgAgent.make_env_to_model_kwargs": [[80, 85], ["dict", "len"], "methods", ["None"], ["", "def", "make_env_to_model_kwargs", "(", "self", ",", "env_spaces", ")", ":", "\n", "        ", "assert", "len", "(", "env_spaces", ".", "action", ".", "shape", ")", "==", "1", "\n", "return", "dict", "(", "\n", "observation_shape", "=", "env_spaces", ".", "observation", ".", "shape", ",", "\n", "action_size", "=", "env_spaces", ".", "action", ".", "shape", "[", "0", "]", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.qpg.ddpg_agent.DdpgAgent.q": [[87, 93], ["rlpyt.utils.buffer.buffer_to", "ddpg_agent.DdpgAgent.q_model", "ddpg_agent.DdpgAgent.cpu"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.utils.buffer.buffer_to"], ["", "def", "q", "(", "self", ",", "observation", ",", "prev_action", ",", "prev_reward", ",", "action", ")", ":", "\n", "        ", "\"\"\"Compute Q-value for input state/observation and action (with grad).\"\"\"", "\n", "model_inputs", "=", "buffer_to", "(", "(", "observation", ",", "prev_action", ",", "prev_reward", ",", "\n", "action", ")", ",", "device", "=", "self", ".", "device", ")", "\n", "q", "=", "self", ".", "q_model", "(", "*", "model_inputs", ")", "\n", "return", "q", ".", "cpu", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.qpg.ddpg_agent.DdpgAgent.q_at_mu": [[94, 102], ["rlpyt.utils.buffer.buffer_to", "ddpg_agent.DdpgAgent.model", "ddpg_agent.DdpgAgent.q_model", "ddpg_agent.DdpgAgent.cpu"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.utils.buffer.buffer_to"], ["", "def", "q_at_mu", "(", "self", ",", "observation", ",", "prev_action", ",", "prev_reward", ")", ":", "\n", "        ", "\"\"\"Compute Q-value for input state/observation, through the mu_model\n        (with grad).\"\"\"", "\n", "model_inputs", "=", "buffer_to", "(", "(", "observation", ",", "prev_action", ",", "prev_reward", ")", ",", "\n", "device", "=", "self", ".", "device", ")", "\n", "mu", "=", "self", ".", "model", "(", "*", "model_inputs", ")", "\n", "q", "=", "self", ".", "q_model", "(", "*", "model_inputs", ",", "mu", ")", "\n", "return", "q", ".", "cpu", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.qpg.ddpg_agent.DdpgAgent.target_q_at_mu": [[103, 111], ["rlpyt.utils.buffer.buffer_to", "ddpg_agent.DdpgAgent.target_model", "ddpg_agent.DdpgAgent.target_q_model", "ddpg_agent.DdpgAgent.cpu"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.utils.buffer.buffer_to"], ["", "def", "target_q_at_mu", "(", "self", ",", "observation", ",", "prev_action", ",", "prev_reward", ")", ":", "\n", "        ", "\"\"\"Compute target Q-value for input state/observation, through the\n        target mu_model.\"\"\"", "\n", "model_inputs", "=", "buffer_to", "(", "(", "observation", ",", "prev_action", ",", "prev_reward", ")", ",", "\n", "device", "=", "self", ".", "device", ")", "\n", "target_mu", "=", "self", ".", "target_model", "(", "*", "model_inputs", ")", "\n", "target_q_at_mu", "=", "self", ".", "target_q_model", "(", "*", "model_inputs", ",", "target_mu", ")", "\n", "return", "target_q_at_mu", ".", "cpu", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.qpg.ddpg_agent.DdpgAgent.step": [[112, 123], ["torch.no_grad", "rlpyt.utils.buffer.buffer_to", "ddpg_agent.DdpgAgent.model", "ddpg_agent.DdpgAgent.distribution.sample", "AgentInfo", "rlpyt.utils.buffer.buffer_to", "rlpyt.agents.base.AgentStep", "rlpyt.distributions.gaussian.DistInfo"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.utils.buffer.buffer_to", "home.repos.pwc.inspect_result.astooke_rlpyt.spaces.gym_wrapper.GymSpaceWrapper.sample", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.buffer.buffer_to"], ["", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "step", "(", "self", ",", "observation", ",", "prev_action", ",", "prev_reward", ")", ":", "\n", "        ", "\"\"\"Computes distribution parameters (mu) for state/observation,\n        returns (gaussian) sampled action.\"\"\"", "\n", "model_inputs", "=", "buffer_to", "(", "(", "observation", ",", "prev_action", ",", "prev_reward", ")", ",", "\n", "device", "=", "self", ".", "device", ")", "\n", "mu", "=", "self", ".", "model", "(", "*", "model_inputs", ")", "\n", "action", "=", "self", ".", "distribution", ".", "sample", "(", "DistInfo", "(", "mean", "=", "mu", ")", ")", "\n", "agent_info", "=", "AgentInfo", "(", "mu", "=", "mu", ")", "\n", "action", ",", "agent_info", "=", "buffer_to", "(", "(", "action", ",", "agent_info", ")", ",", "device", "=", "\"cpu\"", ")", "\n", "return", "AgentStep", "(", "action", "=", "action", ",", "agent_info", "=", "agent_info", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.qpg.ddpg_agent.DdpgAgent.update_target": [[124, 127], ["rlpyt.models.utils.update_state_dict", "rlpyt.models.utils.update_state_dict", "ddpg_agent.DdpgAgent.model.state_dict", "ddpg_agent.DdpgAgent.q_model.state_dict"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.models.utils.update_state_dict", "home.repos.pwc.inspect_result.astooke_rlpyt.models.utils.update_state_dict", "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.replay_saver.DummyOptimizer.state_dict", "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.replay_saver.DummyOptimizer.state_dict"], ["", "def", "update_target", "(", "self", ",", "tau", "=", "1", ")", ":", "\n", "        ", "update_state_dict", "(", "self", ".", "target_model", ",", "self", ".", "model", ".", "state_dict", "(", ")", ",", "tau", ")", "\n", "update_state_dict", "(", "self", ".", "target_q_model", ",", "self", ".", "q_model", ".", "state_dict", "(", ")", ",", "tau", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.qpg.ddpg_agent.DdpgAgent.q_parameters": [[128, 130], ["ddpg_agent.DdpgAgent.q_model.parameters"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.rl.atari_rl_models.AtariDqnModel.parameters"], ["", "def", "q_parameters", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "q_model", ".", "parameters", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.qpg.ddpg_agent.DdpgAgent.mu_parameters": [[131, 133], ["ddpg_agent.DdpgAgent.model.parameters"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.rl.atari_rl_models.AtariDqnModel.parameters"], ["", "def", "mu_parameters", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "model", ".", "parameters", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.qpg.ddpg_agent.DdpgAgent.train_mode": [[134, 137], ["super().train_mode", "ddpg_agent.DdpgAgent.q_model.train"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.agents.dmc_sac_agent.SacAgent.train_mode", "home.repos.pwc.inspect_result.astooke_rlpyt.runners.minibatch_rl.MinibatchRlEval.train"], ["", "def", "train_mode", "(", "self", ",", "itr", ")", ":", "\n", "        ", "super", "(", ")", ".", "train_mode", "(", "itr", ")", "\n", "self", ".", "q_model", ".", "train", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.qpg.ddpg_agent.DdpgAgent.sample_mode": [[138, 142], ["super().sample_mode", "ddpg_agent.DdpgAgent.q_model.eval", "ddpg_agent.DdpgAgent.distribution.set_std"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.agents.dmc_sac_agent.SacAgent.sample_mode", "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.augmented_temporal_similarity.AugmentedTemporalSimilarity.eval", "home.repos.pwc.inspect_result.astooke_rlpyt.distributions.gaussian.Gaussian.set_std"], ["", "def", "sample_mode", "(", "self", ",", "itr", ")", ":", "\n", "        ", "super", "(", ")", ".", "sample_mode", "(", "itr", ")", "\n", "self", ".", "q_model", ".", "eval", "(", ")", "\n", "self", ".", "distribution", ".", "set_std", "(", "self", ".", "action_std", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.qpg.ddpg_agent.DdpgAgent.eval_mode": [[143, 147], ["super().eval_mode", "ddpg_agent.DdpgAgent.q_model.eval", "ddpg_agent.DdpgAgent.distribution.set_std"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.agents.dmc_sac_agent.SacAgent.eval_mode", "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.augmented_temporal_similarity.AugmentedTemporalSimilarity.eval", "home.repos.pwc.inspect_result.astooke_rlpyt.distributions.gaussian.Gaussian.set_std"], ["", "def", "eval_mode", "(", "self", ",", "itr", ")", ":", "\n", "        ", "super", "(", ")", ".", "eval_mode", "(", "itr", ")", "\n", "self", ".", "q_model", ".", "eval", "(", ")", "\n", "self", ".", "distribution", ".", "set_std", "(", "0.", ")", "# Deterministic.", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.qpg.ddpg_agent.DdpgAgent.state_dict": [[148, 154], ["dict", "ddpg_agent.DdpgAgent.model.state_dict", "ddpg_agent.DdpgAgent.q_model.state_dict", "ddpg_agent.DdpgAgent.target_model.state_dict", "ddpg_agent.DdpgAgent.target_q_model.state_dict"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.replay_saver.DummyOptimizer.state_dict", "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.replay_saver.DummyOptimizer.state_dict", "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.replay_saver.DummyOptimizer.state_dict", "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.replay_saver.DummyOptimizer.state_dict"], ["", "def", "state_dict", "(", "self", ")", ":", "\n", "        ", "return", "dict", "(", "\n", "model", "=", "self", ".", "model", ".", "state_dict", "(", ")", ",", "\n", "q_model", "=", "self", ".", "q_model", ".", "state_dict", "(", ")", ",", "\n", "target_model", "=", "self", ".", "target_model", ".", "state_dict", "(", ")", ",", "\n", "target_q_model", "=", "self", ".", "target_q_model", ".", "state_dict", "(", ")", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.qpg.ddpg_agent.DdpgAgent.load_state_dict": [[156, 161], ["ddpg_agent.DdpgAgent.model.load_state_dict", "ddpg_agent.DdpgAgent.q_model.load_state_dict", "ddpg_agent.DdpgAgent.target_model.load_state_dict", "ddpg_agent.DdpgAgent.target_q_model.load_state_dict"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.augmented_temporal_similarity.AugmentedTemporalSimilarity.load_state_dict", "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.augmented_temporal_similarity.AugmentedTemporalSimilarity.load_state_dict", "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.augmented_temporal_similarity.AugmentedTemporalSimilarity.load_state_dict", "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.augmented_temporal_similarity.AugmentedTemporalSimilarity.load_state_dict"], ["", "def", "load_state_dict", "(", "self", ",", "state_dict", ")", ":", "\n", "        ", "self", ".", "model", ".", "load_state_dict", "(", "state_dict", "[", "\"model\"", "]", ")", "\n", "self", ".", "q_model", ".", "load_state_dict", "(", "state_dict", "[", "\"q_model\"", "]", ")", "\n", "self", ".", "target_model", ".", "load_state_dict", "(", "state_dict", "[", "\"target_model\"", "]", ")", "\n", "self", ".", "target_q_model", ".", "load_state_dict", "(", "state_dict", "[", "\"target_q_model\"", "]", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.astooke_rlpyt.qpg.sac_v_agent.SacAgent.__init__": [[28, 50], ["rlpyt.agents.base.BaseAgent.__init__", "rlpyt.utils.quick_args.save__init__args", "dict", "dict", "dict", "locals"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.spaces.gym_wrapper.GymSpaceWrapper.__init__", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.quick_args.save__init__args"], ["def", "__init__", "(", "\n", "self", ",", "\n", "ModelCls", "=", "PiMlpModel", ",", "# Pi model.", "\n", "QModelCls", "=", "QofMuMlpModel", ",", "\n", "VModelCls", "=", "VMlpModel", ",", "\n", "model_kwargs", "=", "None", ",", "# Pi model.", "\n", "q_model_kwargs", "=", "None", ",", "\n", "v_model_kwargs", "=", "None", ",", "\n", "initial_model_state_dict", "=", "None", ",", "# All models.", "\n", "action_squash", "=", "1.", ",", "# Max magnitude (or None).", "\n", "pretrain_std", "=", "0.75", ",", "# With squash 0.75 is near uniform.", "\n", ")", ":", "\n", "        ", "if", "model_kwargs", "is", "None", ":", "\n", "            ", "model_kwargs", "=", "dict", "(", "hidden_sizes", "=", "[", "256", ",", "256", "]", ")", "\n", "", "if", "q_model_kwargs", "is", "None", ":", "\n", "            ", "q_model_kwargs", "=", "dict", "(", "hidden_sizes", "=", "[", "256", ",", "256", "]", ")", "\n", "", "if", "v_model_kwargs", "is", "None", ":", "\n", "            ", "v_model_kwargs", "=", "dict", "(", "hidden_sizes", "=", "[", "256", ",", "256", "]", ")", "\n", "", "super", "(", ")", ".", "__init__", "(", "ModelCls", "=", "ModelCls", ",", "model_kwargs", "=", "model_kwargs", ",", "\n", "initial_model_state_dict", "=", "initial_model_state_dict", ")", "\n", "save__init__args", "(", "locals", "(", ")", ")", "\n", "self", ".", "min_itr_learn", "=", "0", "# Get from algo.", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.qpg.sac_v_agent.SacAgent.initialize": [[51, 72], ["super().initialize", "sac_v_agent.SacAgent.QModelCls", "sac_v_agent.SacAgent.QModelCls", "sac_v_agent.SacAgent.VModelCls", "sac_v_agent.SacAgent.VModelCls", "sac_v_agent.SacAgent.target_v_model.load_state_dict", "rlpyt.distributions.gaussian.Gaussian", "sac_v_agent.SacAgent.v_model.state_dict", "sac_v_agent.SacAgent.load_state_dict", "len", "numpy.exp", "numpy.exp"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.safe.cppo_agent.CppoLstmAgent.initialize", "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.augmented_temporal_similarity.AugmentedTemporalSimilarity.load_state_dict", "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.replay_saver.DummyOptimizer.state_dict", "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.augmented_temporal_similarity.AugmentedTemporalSimilarity.load_state_dict"], ["", "def", "initialize", "(", "self", ",", "env_spaces", ",", "share_memory", "=", "False", ",", "\n", "global_B", "=", "1", ",", "env_ranks", "=", "None", ")", ":", "\n", "        ", "_initial_model_state_dict", "=", "self", ".", "initial_model_state_dict", "\n", "self", ".", "initial_model_state_dict", "=", "None", "# Don't let base agent try to load.", "\n", "super", "(", ")", ".", "initialize", "(", "env_spaces", ",", "share_memory", ",", "\n", "global_B", "=", "global_B", ",", "env_ranks", "=", "env_ranks", ")", "\n", "self", ".", "initial_model_state_dict", "=", "_initial_model_state_dict", "\n", "self", ".", "q1_model", "=", "self", ".", "QModelCls", "(", "**", "self", ".", "env_model_kwargs", ",", "**", "self", ".", "q_model_kwargs", ")", "\n", "self", ".", "q2_model", "=", "self", ".", "QModelCls", "(", "**", "self", ".", "env_model_kwargs", ",", "**", "self", ".", "q_model_kwargs", ")", "\n", "self", ".", "v_model", "=", "self", ".", "VModelCls", "(", "**", "self", ".", "env_model_kwargs", ",", "**", "self", ".", "v_model_kwargs", ")", "\n", "self", ".", "target_v_model", "=", "self", ".", "VModelCls", "(", "**", "self", ".", "env_model_kwargs", ",", "\n", "**", "self", ".", "v_model_kwargs", ")", "\n", "self", ".", "target_v_model", ".", "load_state_dict", "(", "self", ".", "v_model", ".", "state_dict", "(", ")", ")", "\n", "if", "self", ".", "initial_model_state_dict", "is", "not", "None", ":", "\n", "            ", "self", ".", "load_state_dict", "(", "self", ".", "initial_model_state_dict", ")", "\n", "", "assert", "len", "(", "env_spaces", ".", "action", ".", "shape", ")", "==", "1", "\n", "self", ".", "distribution", "=", "Gaussian", "(", "\n", "dim", "=", "env_spaces", ".", "action", ".", "shape", "[", "0", "]", ",", "\n", "squash", "=", "self", ".", "action_squash", ",", "\n", "min_std", "=", "np", ".", "exp", "(", "MIN_LOG_STD", ")", ",", "\n", "max_std", "=", "np", ".", "exp", "(", "MAX_LOG_STD", ")", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.qpg.sac_v_agent.SacAgent.to_device": [[74, 80], ["super().to_device", "sac_v_agent.SacAgent.q1_model.to", "sac_v_agent.SacAgent.q2_model.to", "sac_v_agent.SacAgent.v_model.to", "sac_v_agent.SacAgent.target_v_model.to"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.safe.cppo_agent.CppoLstmAgent.to_device"], ["", "def", "to_device", "(", "self", ",", "cuda_idx", "=", "None", ")", ":", "\n", "        ", "super", "(", ")", ".", "to_device", "(", "cuda_idx", ")", "\n", "self", ".", "q1_model", ".", "to", "(", "self", ".", "device", ")", "\n", "self", ".", "q2_model", ".", "to", "(", "self", ".", "device", ")", "\n", "self", ".", "v_model", ".", "to", "(", "self", ".", "device", ")", "\n", "self", ".", "target_v_model", ".", "to", "(", "self", ".", "device", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.qpg.sac_v_agent.SacAgent.data_parallel": [[81, 99], ["torch.nn.parallel.DistributedDataParallel", "torch.nn.parallel.DistributedDataParallel", "torch.nn.parallel.DistributedDataParallel"], "methods", ["None"], ["", "def", "data_parallel", "(", "self", ")", ":", "\n", "        ", "device_id", "=", "super", "(", ")", ".", "data_parallel", "\n", "self", ".", "q1_model", "=", "DDP", "(", "\n", "self", ".", "q1_model", ",", "\n", "device_ids", "=", "None", "if", "device_id", "is", "None", "else", "[", "device_id", "]", ",", "# 1 GPU.", "\n", "output_device", "=", "device_id", ",", "\n", ")", "\n", "self", ".", "q2_model", "=", "DDP", "(", "\n", "self", ".", "q2_model", ",", "\n", "device_ids", "=", "None", "if", "device_id", "is", "None", "else", "[", "device_id", "]", ",", "# 1 GPU.", "\n", "output_device", "=", "device_id", ",", "\n", ")", "\n", "self", ".", "v_model", "=", "DDP", "(", "\n", "self", ".", "v_model", ",", "\n", "device_ids", "=", "None", "if", "device_id", "is", "None", "else", "[", "device_id", "]", ",", "# 1 GPU.", "\n", "output_device", "=", "device_id", ",", "\n", ")", "\n", "return", "device_id", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.qpg.sac_v_agent.SacAgent.give_min_itr_learn": [[100, 102], ["None"], "methods", ["None"], ["", "def", "give_min_itr_learn", "(", "self", ",", "min_itr_learn", ")", ":", "\n", "        ", "self", ".", "min_itr_learn", "=", "min_itr_learn", "# From algo.", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.qpg.sac_v_agent.SacAgent.make_env_to_model_kwargs": [[103, 108], ["dict", "len"], "methods", ["None"], ["", "def", "make_env_to_model_kwargs", "(", "self", ",", "env_spaces", ")", ":", "\n", "        ", "assert", "len", "(", "env_spaces", ".", "action", ".", "shape", ")", "==", "1", "\n", "return", "dict", "(", "\n", "observation_shape", "=", "env_spaces", ".", "observation", ".", "shape", ",", "\n", "action_size", "=", "env_spaces", ".", "action", ".", "shape", "[", "0", "]", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.qpg.sac_v_agent.SacAgent.q": [[110, 116], ["rlpyt.utils.buffer.buffer_to", "sac_v_agent.SacAgent.q1_model", "sac_v_agent.SacAgent.q2_model", "sac_v_agent.SacAgent.cpu", "sac_v_agent.SacAgent.cpu"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.utils.buffer.buffer_to"], ["", "def", "q", "(", "self", ",", "observation", ",", "prev_action", ",", "prev_reward", ",", "action", ")", ":", "\n", "        ", "model_inputs", "=", "buffer_to", "(", "(", "observation", ",", "prev_action", ",", "prev_reward", ",", "\n", "action", ")", ",", "device", "=", "self", ".", "device", ")", "\n", "q1", "=", "self", ".", "q1_model", "(", "*", "model_inputs", ")", "\n", "q2", "=", "self", ".", "q2_model", "(", "*", "model_inputs", ")", "\n", "return", "q1", ".", "cpu", "(", ")", ",", "q2", ".", "cpu", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.qpg.sac_v_agent.SacAgent.v": [[117, 122], ["rlpyt.utils.buffer.buffer_to", "sac_v_agent.SacAgent.v_model", "sac_v_agent.SacAgent.cpu"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.utils.buffer.buffer_to"], ["", "def", "v", "(", "self", ",", "observation", ",", "prev_action", ",", "prev_reward", ")", ":", "\n", "        ", "model_inputs", "=", "buffer_to", "(", "(", "observation", ",", "prev_action", ",", "prev_reward", ")", ",", "\n", "device", "=", "self", ".", "device", ")", "\n", "v", "=", "self", ".", "v_model", "(", "*", "model_inputs", ")", "\n", "return", "v", ".", "cpu", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.qpg.sac_v_agent.SacAgent.pi": [[123, 133], ["rlpyt.utils.buffer.buffer_to", "sac_v_agent.SacAgent.model", "rlpyt.distributions.gaussian.DistInfoStd", "sac_v_agent.SacAgent.distribution.sample_loglikelihood", "rlpyt.utils.buffer.buffer_to"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.utils.buffer.buffer_to", "home.repos.pwc.inspect_result.astooke_rlpyt.distributions.gaussian.Gaussian.sample_loglikelihood", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.buffer.buffer_to"], ["", "def", "pi", "(", "self", ",", "observation", ",", "prev_action", ",", "prev_reward", ")", ":", "\n", "        ", "model_inputs", "=", "buffer_to", "(", "(", "observation", ",", "prev_action", ",", "prev_reward", ")", ",", "\n", "device", "=", "self", ".", "device", ")", "\n", "mean", ",", "log_std", "=", "self", ".", "model", "(", "*", "model_inputs", ")", "\n", "dist_info", "=", "DistInfoStd", "(", "mean", "=", "mean", ",", "log_std", "=", "log_std", ")", "\n", "action", ",", "log_pi", "=", "self", ".", "distribution", ".", "sample_loglikelihood", "(", "dist_info", ")", "\n", "# action = self.distribution.sample(dist_info)", "\n", "# log_pi = self.distribution.log_likelihood(action, dist_info)", "\n", "log_pi", ",", "dist_info", "=", "buffer_to", "(", "(", "log_pi", ",", "dist_info", ")", ",", "device", "=", "\"cpu\"", ")", "\n", "return", "action", ",", "log_pi", ",", "dist_info", "# Action stays on device for q models.", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.qpg.sac_v_agent.SacAgent.target_v": [[134, 139], ["rlpyt.utils.buffer.buffer_to", "sac_v_agent.SacAgent.target_v_model", "sac_v_agent.SacAgent.cpu"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.utils.buffer.buffer_to"], ["", "def", "target_v", "(", "self", ",", "observation", ",", "prev_action", ",", "prev_reward", ")", ":", "\n", "        ", "model_inputs", "=", "buffer_to", "(", "(", "observation", ",", "prev_action", ",", "prev_reward", ")", ",", "\n", "device", "=", "self", ".", "device", ")", "\n", "target_v", "=", "self", ".", "target_v_model", "(", "*", "model_inputs", ")", "\n", "return", "target_v", ".", "cpu", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.qpg.sac_v_agent.SacAgent.step": [[140, 150], ["torch.no_grad", "rlpyt.utils.buffer.buffer_to", "sac_v_agent.SacAgent.model", "rlpyt.distributions.gaussian.DistInfoStd", "sac_v_agent.SacAgent.distribution.sample", "AgentInfo", "rlpyt.utils.buffer.buffer_to", "rlpyt.agents.base.AgentStep"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.utils.buffer.buffer_to", "home.repos.pwc.inspect_result.astooke_rlpyt.spaces.gym_wrapper.GymSpaceWrapper.sample", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.buffer.buffer_to"], ["", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "step", "(", "self", ",", "observation", ",", "prev_action", ",", "prev_reward", ")", ":", "\n", "        ", "model_inputs", "=", "buffer_to", "(", "(", "observation", ",", "prev_action", ",", "prev_reward", ")", ",", "\n", "device", "=", "self", ".", "device", ")", "\n", "mean", ",", "log_std", "=", "self", ".", "model", "(", "*", "model_inputs", ")", "\n", "dist_info", "=", "DistInfoStd", "(", "mean", "=", "mean", ",", "log_std", "=", "log_std", ")", "\n", "action", "=", "self", ".", "distribution", ".", "sample", "(", "dist_info", ")", "\n", "agent_info", "=", "AgentInfo", "(", "dist_info", "=", "dist_info", ")", "\n", "action", ",", "agent_info", "=", "buffer_to", "(", "(", "action", ",", "agent_info", ")", ",", "device", "=", "\"cpu\"", ")", "\n", "return", "AgentStep", "(", "action", "=", "action", ",", "agent_info", "=", "agent_info", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.qpg.sac_v_agent.SacAgent.update_target": [[151, 153], ["rlpyt.models.utils.update_state_dict", "sac_v_agent.SacAgent.v_model.state_dict"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.models.utils.update_state_dict", "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.replay_saver.DummyOptimizer.state_dict"], ["", "def", "update_target", "(", "self", ",", "tau", "=", "1", ")", ":", "\n", "        ", "update_state_dict", "(", "self", ".", "target_v_model", ",", "self", ".", "v_model", ".", "state_dict", "(", ")", ",", "tau", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.qpg.sac_v_agent.SacAgent.models": [[154, 158], ["Models"], "methods", ["None"], ["", "@", "property", "\n", "def", "models", "(", "self", ")", ":", "\n", "        ", "return", "Models", "(", "pi", "=", "self", ".", "model", ",", "q1", "=", "self", ".", "q1_model", ",", "q2", "=", "self", ".", "q2_model", ",", "\n", "v", "=", "self", ".", "v_model", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.qpg.sac_v_agent.SacAgent.pi_parameters": [[159, 161], ["sac_v_agent.SacAgent.model.parameters"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.rl.atari_rl_models.AtariDqnModel.parameters"], ["", "def", "pi_parameters", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "model", ".", "parameters", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.qpg.sac_v_agent.SacAgent.q1_parameters": [[162, 164], ["sac_v_agent.SacAgent.q1_model.parameters"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.rl.atari_rl_models.AtariDqnModel.parameters"], ["", "def", "q1_parameters", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "q1_model", ".", "parameters", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.qpg.sac_v_agent.SacAgent.q2_parameters": [[165, 167], ["sac_v_agent.SacAgent.q2_model.parameters"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.rl.atari_rl_models.AtariDqnModel.parameters"], ["", "def", "q2_parameters", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "q2_model", ".", "parameters", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.qpg.sac_v_agent.SacAgent.v_parameters": [[168, 170], ["sac_v_agent.SacAgent.v_model.parameters"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.rl.atari_rl_models.AtariDqnModel.parameters"], ["", "def", "v_parameters", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "v_model", ".", "parameters", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.qpg.sac_v_agent.SacAgent.train_mode": [[171, 176], ["super().train_mode", "sac_v_agent.SacAgent.q1_model.train", "sac_v_agent.SacAgent.q2_model.train", "sac_v_agent.SacAgent.v_model.train"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.agents.dmc_sac_agent.SacAgent.train_mode", "home.repos.pwc.inspect_result.astooke_rlpyt.runners.minibatch_rl.MinibatchRlEval.train", "home.repos.pwc.inspect_result.astooke_rlpyt.runners.minibatch_rl.MinibatchRlEval.train", "home.repos.pwc.inspect_result.astooke_rlpyt.runners.minibatch_rl.MinibatchRlEval.train"], ["", "def", "train_mode", "(", "self", ",", "itr", ")", ":", "\n", "        ", "super", "(", ")", ".", "train_mode", "(", "itr", ")", "\n", "self", ".", "q1_model", ".", "train", "(", ")", "\n", "self", ".", "q2_model", ".", "train", "(", ")", "\n", "self", ".", "v_model", ".", "train", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.qpg.sac_v_agent.SacAgent.sample_mode": [[177, 188], ["super().sample_mode", "sac_v_agent.SacAgent.q1_model.eval", "sac_v_agent.SacAgent.q2_model.eval", "sac_v_agent.SacAgent.v_model.eval", "sac_v_agent.SacAgent.distribution.set_std", "rlpyt.utils.logging.logger.log", "rlpyt.utils.logging.logger.log"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.agents.dmc_sac_agent.SacAgent.sample_mode", "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.augmented_temporal_similarity.AugmentedTemporalSimilarity.eval", "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.augmented_temporal_similarity.AugmentedTemporalSimilarity.eval", "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.augmented_temporal_similarity.AugmentedTemporalSimilarity.eval", "home.repos.pwc.inspect_result.astooke_rlpyt.distributions.gaussian.Gaussian.set_std", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.console.log", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.console.log"], ["", "def", "sample_mode", "(", "self", ",", "itr", ")", ":", "\n", "        ", "super", "(", ")", ".", "sample_mode", "(", "itr", ")", "\n", "self", ".", "q1_model", ".", "eval", "(", ")", "\n", "self", ".", "q2_model", ".", "eval", "(", ")", "\n", "self", ".", "v_model", ".", "eval", "(", ")", "\n", "if", "itr", "==", "0", ":", "\n", "            ", "logger", ".", "log", "(", "f\"Agent at itr {itr}, sample std: {self.pretrain_std}\"", ")", "\n", "", "if", "itr", "==", "self", ".", "min_itr_learn", ":", "\n", "            ", "logger", ".", "log", "(", "f\"Agent at itr {itr}, sample std: learned.\"", ")", "\n", "", "std", "=", "None", "if", "itr", ">=", "self", ".", "min_itr_learn", "else", "self", ".", "pretrain_std", "\n", "self", ".", "distribution", ".", "set_std", "(", "std", ")", "# If None: std from policy dist_info.", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.qpg.sac_v_agent.SacAgent.eval_mode": [[189, 195], ["super().eval_mode", "sac_v_agent.SacAgent.q1_model.eval", "sac_v_agent.SacAgent.q2_model.eval", "sac_v_agent.SacAgent.v_model.eval", "sac_v_agent.SacAgent.distribution.set_std"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.agents.dmc_sac_agent.SacAgent.eval_mode", "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.augmented_temporal_similarity.AugmentedTemporalSimilarity.eval", "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.augmented_temporal_similarity.AugmentedTemporalSimilarity.eval", "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.augmented_temporal_similarity.AugmentedTemporalSimilarity.eval", "home.repos.pwc.inspect_result.astooke_rlpyt.distributions.gaussian.Gaussian.set_std"], ["", "def", "eval_mode", "(", "self", ",", "itr", ")", ":", "\n", "        ", "super", "(", ")", ".", "eval_mode", "(", "itr", ")", "\n", "self", ".", "q1_model", ".", "eval", "(", ")", "\n", "self", ".", "q2_model", ".", "eval", "(", ")", "\n", "self", ".", "v_model", ".", "eval", "(", ")", "\n", "self", ".", "distribution", ".", "set_std", "(", "0.", ")", "# Deterministic (dist_info std ignored).", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.qpg.sac_v_agent.SacAgent.state_dict": [[196, 203], ["dict", "sac_v_agent.SacAgent.model.state_dict", "sac_v_agent.SacAgent.q1_model.state_dict", "sac_v_agent.SacAgent.q2_model.state_dict", "sac_v_agent.SacAgent.v_model.state_dict", "sac_v_agent.SacAgent.target_v_model.state_dict"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.replay_saver.DummyOptimizer.state_dict", "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.replay_saver.DummyOptimizer.state_dict", "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.replay_saver.DummyOptimizer.state_dict", "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.replay_saver.DummyOptimizer.state_dict", "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.replay_saver.DummyOptimizer.state_dict"], ["", "def", "state_dict", "(", "self", ")", ":", "\n", "        ", "return", "dict", "(", "\n", "model", "=", "self", ".", "model", ".", "state_dict", "(", ")", ",", "# Pi model.", "\n", "q1_model", "=", "self", ".", "q1_model", ".", "state_dict", "(", ")", ",", "\n", "q2_model", "=", "self", ".", "q2_model", ".", "state_dict", "(", ")", ",", "\n", "v_model", "=", "self", ".", "v_model", ".", "state_dict", "(", ")", ",", "\n", "target_v_model", "=", "self", ".", "target_v_model", ".", "state_dict", "(", ")", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.qpg.sac_v_agent.SacAgent.load_state_dict": [[205, 211], ["sac_v_agent.SacAgent.model.load_state_dict", "sac_v_agent.SacAgent.q1_model.load_state_dict", "sac_v_agent.SacAgent.q2_model.load_state_dict", "sac_v_agent.SacAgent.v_model.load_state_dict", "sac_v_agent.SacAgent.target_v_model.load_state_dict"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.augmented_temporal_similarity.AugmentedTemporalSimilarity.load_state_dict", "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.augmented_temporal_similarity.AugmentedTemporalSimilarity.load_state_dict", "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.augmented_temporal_similarity.AugmentedTemporalSimilarity.load_state_dict", "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.augmented_temporal_similarity.AugmentedTemporalSimilarity.load_state_dict", "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.augmented_temporal_similarity.AugmentedTemporalSimilarity.load_state_dict"], ["", "def", "load_state_dict", "(", "self", ",", "state_dict", ")", ":", "\n", "        ", "self", ".", "model", ".", "load_state_dict", "(", "state_dict", "[", "\"model\"", "]", ")", "\n", "self", ".", "q1_model", ".", "load_state_dict", "(", "state_dict", "[", "\"q1_model\"", "]", ")", "\n", "self", ".", "q2_model", ".", "load_state_dict", "(", "state_dict", "[", "\"q2_model\"", "]", ")", "\n", "self", ".", "v_model", ".", "load_state_dict", "(", "state_dict", "[", "\"v_model\"", "]", ")", "\n", "self", ".", "target_v_model", ".", "load_state_dict", "(", "state_dict", "[", "\"target_v_model\"", "]", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.astooke_rlpyt.qpg.sac_agent.SacAgent.__init__": [[28, 50], ["rlpyt.agents.base.BaseAgent.__init__", "rlpyt.utils.quick_args.save__init__args", "dict", "dict", "dict", "locals"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.spaces.gym_wrapper.GymSpaceWrapper.__init__", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.quick_args.save__init__args"], ["def", "__init__", "(", "\n", "self", ",", "\n", "ModelCls", "=", "PiMlpModel", ",", "# Pi model.", "\n", "QModelCls", "=", "QofMuMlpModel", ",", "\n", "model_kwargs", "=", "None", ",", "# Pi model.", "\n", "q_model_kwargs", "=", "None", ",", "\n", "v_model_kwargs", "=", "None", ",", "\n", "initial_model_state_dict", "=", "None", ",", "# All models.", "\n", "action_squash", "=", "1.", ",", "# Max magnitude (or None).", "\n", "pretrain_std", "=", "0.75", ",", "# With squash 0.75 is near uniform.", "\n", ")", ":", "\n", "        ", "\"\"\"Saves input arguments; network defaults stored within.\"\"\"", "\n", "if", "model_kwargs", "is", "None", ":", "\n", "            ", "model_kwargs", "=", "dict", "(", "hidden_sizes", "=", "[", "256", ",", "256", "]", ")", "\n", "", "if", "q_model_kwargs", "is", "None", ":", "\n", "            ", "q_model_kwargs", "=", "dict", "(", "hidden_sizes", "=", "[", "256", ",", "256", "]", ")", "\n", "", "if", "v_model_kwargs", "is", "None", ":", "\n", "            ", "v_model_kwargs", "=", "dict", "(", "hidden_sizes", "=", "[", "256", ",", "256", "]", ")", "\n", "", "super", "(", ")", ".", "__init__", "(", "ModelCls", "=", "ModelCls", ",", "model_kwargs", "=", "model_kwargs", ",", "\n", "initial_model_state_dict", "=", "initial_model_state_dict", ")", "\n", "save__init__args", "(", "locals", "(", ")", ")", "\n", "self", ".", "min_itr_learn", "=", "0", "# Get from algo.", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.qpg.sac_agent.SacAgent.initialize": [[51, 74], ["super().initialize", "sac_agent.SacAgent.QModelCls", "sac_agent.SacAgent.QModelCls", "sac_agent.SacAgent.QModelCls", "sac_agent.SacAgent.QModelCls", "sac_agent.SacAgent.target_q1_model.load_state_dict", "sac_agent.SacAgent.target_q2_model.load_state_dict", "rlpyt.distributions.gaussian.Gaussian", "sac_agent.SacAgent.q1_model.state_dict", "sac_agent.SacAgent.q2_model.state_dict", "sac_agent.SacAgent.load_state_dict", "len", "numpy.exp", "numpy.exp"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.safe.cppo_agent.CppoLstmAgent.initialize", "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.augmented_temporal_similarity.AugmentedTemporalSimilarity.load_state_dict", "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.augmented_temporal_similarity.AugmentedTemporalSimilarity.load_state_dict", "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.replay_saver.DummyOptimizer.state_dict", "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.replay_saver.DummyOptimizer.state_dict", "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.augmented_temporal_similarity.AugmentedTemporalSimilarity.load_state_dict"], ["", "def", "initialize", "(", "self", ",", "env_spaces", ",", "share_memory", "=", "False", ",", "\n", "global_B", "=", "1", ",", "env_ranks", "=", "None", ")", ":", "\n", "        ", "_initial_model_state_dict", "=", "self", ".", "initial_model_state_dict", "\n", "self", ".", "initial_model_state_dict", "=", "None", "# Don't let base agent try to load.", "\n", "super", "(", ")", ".", "initialize", "(", "env_spaces", ",", "share_memory", ",", "\n", "global_B", "=", "global_B", ",", "env_ranks", "=", "env_ranks", ")", "\n", "self", ".", "initial_model_state_dict", "=", "_initial_model_state_dict", "\n", "self", ".", "q1_model", "=", "self", ".", "QModelCls", "(", "**", "self", ".", "env_model_kwargs", ",", "**", "self", ".", "q_model_kwargs", ")", "\n", "self", ".", "q2_model", "=", "self", ".", "QModelCls", "(", "**", "self", ".", "env_model_kwargs", ",", "**", "self", ".", "q_model_kwargs", ")", "\n", "self", ".", "target_q1_model", "=", "self", ".", "QModelCls", "(", "**", "self", ".", "env_model_kwargs", ",", "\n", "**", "self", ".", "q_model_kwargs", ")", "\n", "self", ".", "target_q2_model", "=", "self", ".", "QModelCls", "(", "**", "self", ".", "env_model_kwargs", ",", "\n", "**", "self", ".", "q_model_kwargs", ")", "\n", "self", ".", "target_q1_model", ".", "load_state_dict", "(", "self", ".", "q1_model", ".", "state_dict", "(", ")", ")", "\n", "self", ".", "target_q2_model", ".", "load_state_dict", "(", "self", ".", "q2_model", ".", "state_dict", "(", ")", ")", "\n", "if", "self", ".", "initial_model_state_dict", "is", "not", "None", ":", "\n", "            ", "self", ".", "load_state_dict", "(", "self", ".", "initial_model_state_dict", ")", "\n", "", "assert", "len", "(", "env_spaces", ".", "action", ".", "shape", ")", "==", "1", "\n", "self", ".", "distribution", "=", "Gaussian", "(", "\n", "dim", "=", "env_spaces", ".", "action", ".", "shape", "[", "0", "]", ",", "\n", "squash", "=", "self", ".", "action_squash", ",", "\n", "min_std", "=", "np", ".", "exp", "(", "MIN_LOG_STD", ")", ",", "\n", "max_std", "=", "np", ".", "exp", "(", "MAX_LOG_STD", ")", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.qpg.sac_agent.SacAgent.to_device": [[76, 82], ["super().to_device", "sac_agent.SacAgent.q1_model.to", "sac_agent.SacAgent.q2_model.to", "sac_agent.SacAgent.target_q1_model.to", "sac_agent.SacAgent.target_q2_model.to"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.safe.cppo_agent.CppoLstmAgent.to_device"], ["", "def", "to_device", "(", "self", ",", "cuda_idx", "=", "None", ")", ":", "\n", "        ", "super", "(", ")", ".", "to_device", "(", "cuda_idx", ")", "\n", "self", ".", "q1_model", ".", "to", "(", "self", ".", "device", ")", "\n", "self", ".", "q2_model", ".", "to", "(", "self", ".", "device", ")", "\n", "self", ".", "target_q1_model", ".", "to", "(", "self", ".", "device", ")", "\n", "self", ".", "target_q2_model", ".", "to", "(", "self", ".", "device", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.qpg.sac_agent.SacAgent.data_parallel": [[83, 96], ["torch.nn.parallel.DistributedDataParallel", "torch.nn.parallel.DistributedDataParallel"], "methods", ["None"], ["", "def", "data_parallel", "(", "self", ")", ":", "\n", "        ", "device_id", "=", "super", "(", ")", ".", "data_parallel", "\n", "self", ".", "q1_model", "=", "DDP", "(", "\n", "self", ".", "q1_model", ",", "\n", "device_ids", "=", "None", "if", "device_id", "is", "None", "else", "[", "device_id", "]", ",", "# 1 GPU.", "\n", "output_device", "=", "device_id", ",", "\n", ")", "\n", "self", ".", "q2_model", "=", "DDP", "(", "\n", "self", ".", "q2_model", ",", "\n", "device_ids", "=", "None", "if", "device_id", "is", "None", "else", "[", "device_id", "]", ",", "# 1 GPU.", "\n", "output_device", "=", "device_id", ",", "\n", ")", "\n", "return", "device_id", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.qpg.sac_agent.SacAgent.give_min_itr_learn": [[97, 99], ["None"], "methods", ["None"], ["", "def", "give_min_itr_learn", "(", "self", ",", "min_itr_learn", ")", ":", "\n", "        ", "self", ".", "min_itr_learn", "=", "min_itr_learn", "# From algo.", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.qpg.sac_agent.SacAgent.make_env_to_model_kwargs": [[100, 105], ["dict", "len"], "methods", ["None"], ["", "def", "make_env_to_model_kwargs", "(", "self", ",", "env_spaces", ")", ":", "\n", "        ", "assert", "len", "(", "env_spaces", ".", "action", ".", "shape", ")", "==", "1", "\n", "return", "dict", "(", "\n", "observation_shape", "=", "env_spaces", ".", "observation", ".", "shape", ",", "\n", "action_size", "=", "env_spaces", ".", "action", ".", "shape", "[", "0", "]", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.qpg.sac_agent.SacAgent.q": [[107, 115], ["rlpyt.utils.buffer.buffer_to", "sac_agent.SacAgent.q1_model", "sac_agent.SacAgent.q2_model", "sac_agent.SacAgent.cpu", "sac_agent.SacAgent.cpu"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.utils.buffer.buffer_to"], ["", "def", "q", "(", "self", ",", "observation", ",", "prev_action", ",", "prev_reward", ",", "action", ")", ":", "\n", "        ", "\"\"\"Compute twin Q-values for state/observation and input action \n        (with grad).\"\"\"", "\n", "model_inputs", "=", "buffer_to", "(", "(", "observation", ",", "prev_action", ",", "prev_reward", ",", "\n", "action", ")", ",", "device", "=", "self", ".", "device", ")", "\n", "q1", "=", "self", ".", "q1_model", "(", "*", "model_inputs", ")", "\n", "q2", "=", "self", ".", "q2_model", "(", "*", "model_inputs", ")", "\n", "return", "q1", ".", "cpu", "(", ")", ",", "q2", ".", "cpu", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.qpg.sac_agent.SacAgent.target_q": [[116, 124], ["rlpyt.utils.buffer.buffer_to", "sac_agent.SacAgent.target_q1_model", "sac_agent.SacAgent.target_q2_model", "sac_agent.SacAgent.cpu", "sac_agent.SacAgent.cpu"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.utils.buffer.buffer_to"], ["", "def", "target_q", "(", "self", ",", "observation", ",", "prev_action", ",", "prev_reward", ",", "action", ")", ":", "\n", "        ", "\"\"\"Compute twin target Q-values for state/observation and input\n        action.\"\"\"", "\n", "model_inputs", "=", "buffer_to", "(", "(", "observation", ",", "prev_action", ",", "\n", "prev_reward", ",", "action", ")", ",", "device", "=", "self", ".", "device", ")", "\n", "target_q1", "=", "self", ".", "target_q1_model", "(", "*", "model_inputs", ")", "\n", "target_q2", "=", "self", ".", "target_q2_model", "(", "*", "model_inputs", ")", "\n", "return", "target_q1", ".", "cpu", "(", ")", ",", "target_q2", ".", "cpu", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.qpg.sac_agent.SacAgent.pi": [[125, 139], ["rlpyt.utils.buffer.buffer_to", "sac_agent.SacAgent.model", "rlpyt.distributions.gaussian.DistInfoStd", "sac_agent.SacAgent.distribution.sample_loglikelihood", "rlpyt.utils.buffer.buffer_to"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.utils.buffer.buffer_to", "home.repos.pwc.inspect_result.astooke_rlpyt.distributions.gaussian.Gaussian.sample_loglikelihood", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.buffer.buffer_to"], ["", "def", "pi", "(", "self", ",", "observation", ",", "prev_action", ",", "prev_reward", ")", ":", "\n", "        ", "\"\"\"Compute action log-probabilities for state/observation, and\n        sample new action (with grad).  Uses special ``sample_loglikelihood()``\n        method of Gaussian distriution, which handles action squashing\n        through this process.\"\"\"", "\n", "model_inputs", "=", "buffer_to", "(", "(", "observation", ",", "prev_action", ",", "prev_reward", ")", ",", "\n", "device", "=", "self", ".", "device", ")", "\n", "mean", ",", "log_std", "=", "self", ".", "model", "(", "*", "model_inputs", ")", "\n", "dist_info", "=", "DistInfoStd", "(", "mean", "=", "mean", ",", "log_std", "=", "log_std", ")", "\n", "action", ",", "log_pi", "=", "self", ".", "distribution", ".", "sample_loglikelihood", "(", "dist_info", ")", "\n", "# action = self.distribution.sample(dist_info)", "\n", "# log_pi = self.distribution.log_likelihood(action, dist_info)", "\n", "log_pi", ",", "dist_info", "=", "buffer_to", "(", "(", "log_pi", ",", "dist_info", ")", ",", "device", "=", "\"cpu\"", ")", "\n", "return", "action", ",", "log_pi", ",", "dist_info", "# Action stays on device for q models.", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.qpg.sac_agent.SacAgent.step": [[140, 150], ["torch.no_grad", "rlpyt.utils.buffer.buffer_to", "sac_agent.SacAgent.model", "rlpyt.distributions.gaussian.DistInfoStd", "sac_agent.SacAgent.distribution.sample", "AgentInfo", "rlpyt.utils.buffer.buffer_to", "rlpyt.agents.base.AgentStep"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.utils.buffer.buffer_to", "home.repos.pwc.inspect_result.astooke_rlpyt.spaces.gym_wrapper.GymSpaceWrapper.sample", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.buffer.buffer_to"], ["", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "step", "(", "self", ",", "observation", ",", "prev_action", ",", "prev_reward", ")", ":", "\n", "        ", "model_inputs", "=", "buffer_to", "(", "(", "observation", ",", "prev_action", ",", "prev_reward", ")", ",", "\n", "device", "=", "self", ".", "device", ")", "\n", "mean", ",", "log_std", "=", "self", ".", "model", "(", "*", "model_inputs", ")", "\n", "dist_info", "=", "DistInfoStd", "(", "mean", "=", "mean", ",", "log_std", "=", "log_std", ")", "\n", "action", "=", "self", ".", "distribution", ".", "sample", "(", "dist_info", ")", "\n", "agent_info", "=", "AgentInfo", "(", "dist_info", "=", "dist_info", ")", "\n", "action", ",", "agent_info", "=", "buffer_to", "(", "(", "action", ",", "agent_info", ")", ",", "device", "=", "\"cpu\"", ")", "\n", "return", "AgentStep", "(", "action", "=", "action", ",", "agent_info", "=", "agent_info", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.qpg.sac_agent.SacAgent.update_target": [[151, 154], ["rlpyt.models.utils.update_state_dict", "rlpyt.models.utils.update_state_dict", "sac_agent.SacAgent.q1_model.state_dict", "sac_agent.SacAgent.q2_model.state_dict"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.models.utils.update_state_dict", "home.repos.pwc.inspect_result.astooke_rlpyt.models.utils.update_state_dict", "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.replay_saver.DummyOptimizer.state_dict", "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.replay_saver.DummyOptimizer.state_dict"], ["", "def", "update_target", "(", "self", ",", "tau", "=", "1", ")", ":", "\n", "        ", "update_state_dict", "(", "self", ".", "target_q1_model", ",", "self", ".", "q1_model", ".", "state_dict", "(", ")", ",", "tau", ")", "\n", "update_state_dict", "(", "self", ".", "target_q2_model", ",", "self", ".", "q2_model", ".", "state_dict", "(", ")", ",", "tau", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.qpg.sac_agent.SacAgent.models": [[155, 158], ["Models"], "methods", ["None"], ["", "@", "property", "\n", "def", "models", "(", "self", ")", ":", "\n", "        ", "return", "Models", "(", "pi", "=", "self", ".", "model", ",", "q1", "=", "self", ".", "q1_model", ",", "q2", "=", "self", ".", "q2_model", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.qpg.sac_agent.SacAgent.pi_parameters": [[159, 161], ["sac_agent.SacAgent.model.parameters"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.rl.atari_rl_models.AtariDqnModel.parameters"], ["", "def", "pi_parameters", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "model", ".", "parameters", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.qpg.sac_agent.SacAgent.q1_parameters": [[162, 164], ["sac_agent.SacAgent.q1_model.parameters"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.rl.atari_rl_models.AtariDqnModel.parameters"], ["", "def", "q1_parameters", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "q1_model", ".", "parameters", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.qpg.sac_agent.SacAgent.q2_parameters": [[165, 167], ["sac_agent.SacAgent.q2_model.parameters"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.rl.atari_rl_models.AtariDqnModel.parameters"], ["", "def", "q2_parameters", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "q2_model", ".", "parameters", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.qpg.sac_agent.SacAgent.train_mode": [[168, 172], ["super().train_mode", "sac_agent.SacAgent.q1_model.train", "sac_agent.SacAgent.q2_model.train"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.agents.dmc_sac_agent.SacAgent.train_mode", "home.repos.pwc.inspect_result.astooke_rlpyt.runners.minibatch_rl.MinibatchRlEval.train", "home.repos.pwc.inspect_result.astooke_rlpyt.runners.minibatch_rl.MinibatchRlEval.train"], ["", "def", "train_mode", "(", "self", ",", "itr", ")", ":", "\n", "        ", "super", "(", ")", ".", "train_mode", "(", "itr", ")", "\n", "self", ".", "q1_model", ".", "train", "(", ")", "\n", "self", ".", "q2_model", ".", "train", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.qpg.sac_agent.SacAgent.sample_mode": [[173, 183], ["super().sample_mode", "sac_agent.SacAgent.q1_model.eval", "sac_agent.SacAgent.q2_model.eval", "sac_agent.SacAgent.distribution.set_std", "rlpyt.utils.logging.logger.log", "rlpyt.utils.logging.logger.log"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.agents.dmc_sac_agent.SacAgent.sample_mode", "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.augmented_temporal_similarity.AugmentedTemporalSimilarity.eval", "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.augmented_temporal_similarity.AugmentedTemporalSimilarity.eval", "home.repos.pwc.inspect_result.astooke_rlpyt.distributions.gaussian.Gaussian.set_std", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.console.log", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.console.log"], ["", "def", "sample_mode", "(", "self", ",", "itr", ")", ":", "\n", "        ", "super", "(", ")", ".", "sample_mode", "(", "itr", ")", "\n", "self", ".", "q1_model", ".", "eval", "(", ")", "\n", "self", ".", "q2_model", ".", "eval", "(", ")", "\n", "if", "itr", "==", "0", ":", "\n", "            ", "logger", ".", "log", "(", "f\"Agent at itr {itr}, sample std: {self.pretrain_std}\"", ")", "\n", "", "if", "itr", "==", "self", ".", "min_itr_learn", ":", "\n", "            ", "logger", ".", "log", "(", "f\"Agent at itr {itr}, sample std: learned.\"", ")", "\n", "", "std", "=", "None", "if", "itr", ">=", "self", ".", "min_itr_learn", "else", "self", ".", "pretrain_std", "\n", "self", ".", "distribution", ".", "set_std", "(", "std", ")", "# If None: std from policy dist_info.", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.qpg.sac_agent.SacAgent.eval_mode": [[184, 189], ["super().eval_mode", "sac_agent.SacAgent.q1_model.eval", "sac_agent.SacAgent.q2_model.eval", "sac_agent.SacAgent.distribution.set_std"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.agents.dmc_sac_agent.SacAgent.eval_mode", "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.augmented_temporal_similarity.AugmentedTemporalSimilarity.eval", "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.augmented_temporal_similarity.AugmentedTemporalSimilarity.eval", "home.repos.pwc.inspect_result.astooke_rlpyt.distributions.gaussian.Gaussian.set_std"], ["", "def", "eval_mode", "(", "self", ",", "itr", ")", ":", "\n", "        ", "super", "(", ")", ".", "eval_mode", "(", "itr", ")", "\n", "self", ".", "q1_model", ".", "eval", "(", ")", "\n", "self", ".", "q2_model", ".", "eval", "(", ")", "\n", "self", ".", "distribution", ".", "set_std", "(", "0.", ")", "# Deterministic (dist_info std ignored).", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.qpg.sac_agent.SacAgent.state_dict": [[190, 197], ["dict", "sac_agent.SacAgent.model.state_dict", "sac_agent.SacAgent.q1_model.state_dict", "sac_agent.SacAgent.q2_model.state_dict", "sac_agent.SacAgent.target_q1_model.state_dict", "sac_agent.SacAgent.target_q2_model.state_dict"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.replay_saver.DummyOptimizer.state_dict", "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.replay_saver.DummyOptimizer.state_dict", "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.replay_saver.DummyOptimizer.state_dict", "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.replay_saver.DummyOptimizer.state_dict", "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.replay_saver.DummyOptimizer.state_dict"], ["", "def", "state_dict", "(", "self", ")", ":", "\n", "        ", "return", "dict", "(", "\n", "model", "=", "self", ".", "model", ".", "state_dict", "(", ")", ",", "# Pi model.", "\n", "q1_model", "=", "self", ".", "q1_model", ".", "state_dict", "(", ")", ",", "\n", "q2_model", "=", "self", ".", "q2_model", ".", "state_dict", "(", ")", ",", "\n", "target_q1_model", "=", "self", ".", "target_q1_model", ".", "state_dict", "(", ")", ",", "\n", "target_q2_model", "=", "self", ".", "target_q2_model", ".", "state_dict", "(", ")", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.qpg.sac_agent.SacAgent.load_state_dict": [[199, 205], ["sac_agent.SacAgent.model.load_state_dict", "sac_agent.SacAgent.q1_model.load_state_dict", "sac_agent.SacAgent.q2_model.load_state_dict", "sac_agent.SacAgent.target_q1_model.load_state_dict", "sac_agent.SacAgent.target_q2_model.load_state_dict"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.augmented_temporal_similarity.AugmentedTemporalSimilarity.load_state_dict", "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.augmented_temporal_similarity.AugmentedTemporalSimilarity.load_state_dict", "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.augmented_temporal_similarity.AugmentedTemporalSimilarity.load_state_dict", "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.augmented_temporal_similarity.AugmentedTemporalSimilarity.load_state_dict", "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.augmented_temporal_similarity.AugmentedTemporalSimilarity.load_state_dict"], ["", "def", "load_state_dict", "(", "self", ",", "state_dict", ")", ":", "\n", "        ", "self", ".", "model", ".", "load_state_dict", "(", "state_dict", "[", "\"model\"", "]", ")", "\n", "self", ".", "q1_model", ".", "load_state_dict", "(", "state_dict", "[", "\"q1_model\"", "]", ")", "\n", "self", ".", "q2_model", ".", "load_state_dict", "(", "state_dict", "[", "\"q2_model\"", "]", ")", "\n", "self", ".", "target_q1_model", ".", "load_state_dict", "(", "state_dict", "[", "\"target_q1_model\"", "]", ")", "\n", "self", ".", "target_q2_model", ".", "load_state_dict", "(", "state_dict", "[", "\"target_q2_model\"", "]", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.astooke_rlpyt.qpg.td3_agent.Td3Agent.__init__": [[16, 28], ["rlpyt.agents.qpg.ddpg_agent.DdpgAgent.__init__", "rlpyt.utils.quick_args.save__init__args", "locals"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.spaces.gym_wrapper.GymSpaceWrapper.__init__", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.quick_args.save__init__args"], ["def", "__init__", "(", "\n", "self", ",", "\n", "pretrain_std", "=", "0.5", ",", "# To make actions roughly uniform.", "\n", "target_noise_std", "=", "0.2", ",", "\n", "target_noise_clip", "=", "0.5", ",", "\n", "initial_q2_model_state_dict", "=", "None", ",", "\n", "**", "kwargs", "\n", ")", ":", "\n", "        ", "\"\"\"Saves input arguments.\"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "save__init__args", "(", "locals", "(", ")", ")", "\n", "self", ".", "min_itr_learn", "=", "0", "# Get from algo.", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.qpg.td3_agent.Td3Agent.initialize": [[29, 44], ["super().initialize", "td3_agent.Td3Agent.QModelCls", "td3_agent.Td3Agent.QModelCls", "td3_agent.Td3Agent.target_q2_model.load_state_dict", "rlpyt.distributions.gaussian.Gaussian", "td3_agent.Td3Agent.q2_model.load_state_dict", "td3_agent.Td3Agent.q2_model.state_dict"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.safe.cppo_agent.CppoLstmAgent.initialize", "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.augmented_temporal_similarity.AugmentedTemporalSimilarity.load_state_dict", "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.augmented_temporal_similarity.AugmentedTemporalSimilarity.load_state_dict", "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.replay_saver.DummyOptimizer.state_dict"], ["", "def", "initialize", "(", "self", ",", "env_spaces", ",", "share_memory", "=", "False", ",", "\n", "global_B", "=", "1", ",", "env_ranks", "=", "None", ")", ":", "\n", "        ", "super", "(", ")", ".", "initialize", "(", "env_spaces", ",", "share_memory", ",", "global_B", ",", "env_ranks", ")", "\n", "self", ".", "q2_model", "=", "self", ".", "QModelCls", "(", "**", "self", ".", "env_model_kwargs", ",", "\n", "**", "self", ".", "q_model_kwargs", ")", "\n", "if", "self", ".", "initial_q2_model_state_dict", "is", "not", "None", ":", "\n", "            ", "self", ".", "q2_model", ".", "load_state_dict", "(", "self", ".", "initial_q2_model_state_dict", ")", "\n", "", "self", ".", "target_q2_model", "=", "self", ".", "QModelCls", "(", "**", "self", ".", "env_model_kwargs", ",", "\n", "**", "self", ".", "q_model_kwargs", ")", "\n", "self", ".", "target_q2_model", ".", "load_state_dict", "(", "self", ".", "q2_model", ".", "state_dict", "(", ")", ")", "\n", "self", ".", "target_distribution", "=", "Gaussian", "(", "\n", "dim", "=", "env_spaces", ".", "action", ".", "shape", "[", "0", "]", ",", "\n", "std", "=", "self", ".", "target_noise_std", ",", "\n", "noise_clip", "=", "self", ".", "target_noise_clip", ",", "\n", "clip", "=", "env_spaces", ".", "action", ".", "high", "[", "0", "]", ",", "# Assume symmetric low=-high.", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.qpg.td3_agent.Td3Agent.to_device": [[46, 50], ["super().to_device", "td3_agent.Td3Agent.q2_model.to", "td3_agent.Td3Agent.target_q2_model.to"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.safe.cppo_agent.CppoLstmAgent.to_device"], ["", "def", "to_device", "(", "self", ",", "cuda_idx", "=", "None", ")", ":", "\n", "        ", "super", "(", ")", ".", "to_device", "(", "cuda_idx", ")", "\n", "self", ".", "q2_model", ".", "to", "(", "self", ".", "device", ")", "\n", "self", ".", "target_q2_model", ".", "to", "(", "self", ".", "device", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.qpg.td3_agent.Td3Agent.data_parallel": [[51, 59], ["super().data_parallel", "torch.nn.parallel.DistributedDataParallel"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.safe.cppo_agent.CppoLstmAgent.data_parallel"], ["", "def", "data_parallel", "(", "self", ")", ":", "\n", "        ", "device_id", "=", "super", "(", ")", ".", "data_parallel", "(", ")", "\n", "self", ".", "q2_model", "=", "DDP", "(", "\n", "self", ".", "q2_model", ",", "\n", "device_ids", "=", "None", "if", "device_id", "is", "None", "else", "[", "device_id", "]", ",", "# 1 GPU.", "\n", "output_device", "=", "device_id", ",", "\n", ")", "\n", "return", "device_id", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.qpg.td3_agent.Td3Agent.give_min_itr_learn": [[60, 62], ["None"], "methods", ["None"], ["", "def", "give_min_itr_learn", "(", "self", ",", "min_itr_learn", ")", ":", "\n", "        ", "self", ".", "min_itr_learn", "=", "min_itr_learn", "# From algo.", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.qpg.td3_agent.Td3Agent.q": [[63, 71], ["rlpyt.utils.buffer.buffer_to", "td3_agent.Td3Agent.q_model", "td3_agent.Td3Agent.q2_model", "td3_agent.Td3Agent.cpu", "td3_agent.Td3Agent.cpu"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.utils.buffer.buffer_to"], ["", "def", "q", "(", "self", ",", "observation", ",", "prev_action", ",", "prev_reward", ",", "action", ")", ":", "\n", "        ", "\"\"\"Compute twin Q-values for state/observation and input action \n        (with grad).\"\"\"", "\n", "model_inputs", "=", "buffer_to", "(", "(", "observation", ",", "prev_action", ",", "prev_reward", ",", "\n", "action", ")", ",", "device", "=", "self", ".", "device", ")", "\n", "q1", "=", "self", ".", "q_model", "(", "*", "model_inputs", ")", "\n", "q2", "=", "self", ".", "q2_model", "(", "*", "model_inputs", ")", "\n", "return", "q1", ".", "cpu", "(", ")", ",", "q2", ".", "cpu", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.qpg.td3_agent.Td3Agent.target_q_at_mu": [[72, 82], ["rlpyt.utils.buffer.buffer_to", "td3_agent.Td3Agent.target_model", "td3_agent.Td3Agent.target_distribution.sample", "td3_agent.Td3Agent.target_q_model", "td3_agent.Td3Agent.target_q2_model", "rlpyt.distributions.gaussian.DistInfo", "td3_agent.Td3Agent.cpu", "td3_agent.Td3Agent.cpu"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.utils.buffer.buffer_to", "home.repos.pwc.inspect_result.astooke_rlpyt.spaces.gym_wrapper.GymSpaceWrapper.sample"], ["", "def", "target_q_at_mu", "(", "self", ",", "observation", ",", "prev_action", ",", "prev_reward", ")", ":", "\n", "        ", "\"\"\"Compute twin target Q-values for state/observation, through\n        target mu model.\"\"\"", "\n", "model_inputs", "=", "buffer_to", "(", "(", "observation", ",", "prev_action", ",", "prev_reward", ")", ",", "\n", "device", "=", "self", ".", "device", ")", "\n", "target_mu", "=", "self", ".", "target_model", "(", "*", "model_inputs", ")", "\n", "target_action", "=", "self", ".", "target_distribution", ".", "sample", "(", "DistInfo", "(", "mean", "=", "target_mu", ")", ")", "\n", "target_q1_at_mu", "=", "self", ".", "target_q_model", "(", "*", "model_inputs", ",", "target_action", ")", "\n", "target_q2_at_mu", "=", "self", ".", "target_q2_model", "(", "*", "model_inputs", ",", "target_action", ")", "\n", "return", "target_q1_at_mu", ".", "cpu", "(", ")", ",", "target_q2_at_mu", ".", "cpu", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.qpg.td3_agent.Td3Agent.update_target": [[83, 86], ["super().update_target", "rlpyt.models.utils.update_state_dict", "td3_agent.Td3Agent.q2_model.state_dict"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.agents.atari_dqn_agent.AtariDqnAgent.update_target", "home.repos.pwc.inspect_result.astooke_rlpyt.models.utils.update_state_dict", "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.replay_saver.DummyOptimizer.state_dict"], ["", "def", "update_target", "(", "self", ",", "tau", "=", "1", ")", ":", "\n", "        ", "super", "(", ")", ".", "update_target", "(", "tau", ")", "\n", "update_state_dict", "(", "self", ".", "target_q2_model", ",", "self", ".", "q2_model", ".", "state_dict", "(", ")", ",", "tau", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.qpg.td3_agent.Td3Agent.q_parameters": [[87, 90], ["td3_agent.Td3Agent.q_model.parameters", "td3_agent.Td3Agent.q2_model.parameters"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.rl.atari_rl_models.AtariDqnModel.parameters", "home.repos.pwc.inspect_result.astooke_rlpyt.rl.atari_rl_models.AtariDqnModel.parameters"], ["", "def", "q_parameters", "(", "self", ")", ":", "\n", "        ", "yield", "from", "self", ".", "q_model", ".", "parameters", "(", ")", "\n", "yield", "from", "self", ".", "q2_model", ".", "parameters", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.qpg.td3_agent.Td3Agent.set_target_noise": [[91, 94], ["td3_agent.Td3Agent.target_distribution.set_std", "td3_agent.Td3Agent.target_distribution.set_noise_clip"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.distributions.gaussian.Gaussian.set_std", "home.repos.pwc.inspect_result.astooke_rlpyt.distributions.gaussian.Gaussian.set_noise_clip"], ["", "def", "set_target_noise", "(", "self", ",", "std", ",", "noise_clip", "=", "None", ")", ":", "\n", "        ", "self", ".", "target_distribution", ".", "set_std", "(", "std", ")", "\n", "self", ".", "target_distribution", ".", "set_noise_clip", "(", "noise_clip", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.qpg.td3_agent.Td3Agent.train_mode": [[95, 98], ["super().train_mode", "td3_agent.Td3Agent.q2_model.train"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.agents.dmc_sac_agent.SacAgent.train_mode", "home.repos.pwc.inspect_result.astooke_rlpyt.runners.minibatch_rl.MinibatchRlEval.train"], ["", "def", "train_mode", "(", "self", ",", "itr", ")", ":", "\n", "        ", "super", "(", ")", ".", "train_mode", "(", "itr", ")", "\n", "self", ".", "q2_model", ".", "train", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.qpg.td3_agent.Td3Agent.sample_mode": [[99, 106], ["super().sample_mode", "td3_agent.Td3Agent.q2_model.eval", "td3_agent.Td3Agent.distribution.set_std", "rlpyt.utils.logging.logger.log"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.agents.dmc_sac_agent.SacAgent.sample_mode", "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.augmented_temporal_similarity.AugmentedTemporalSimilarity.eval", "home.repos.pwc.inspect_result.astooke_rlpyt.distributions.gaussian.Gaussian.set_std", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.console.log"], ["", "def", "sample_mode", "(", "self", ",", "itr", ")", ":", "\n", "        ", "super", "(", ")", ".", "sample_mode", "(", "itr", ")", "\n", "self", ".", "q2_model", ".", "eval", "(", ")", "\n", "std", "=", "self", ".", "action_std", "if", "itr", ">=", "self", ".", "min_itr_learn", "else", "self", ".", "pretrain_std", "\n", "if", "itr", "==", "0", "or", "itr", "==", "self", ".", "min_itr_learn", ":", "\n", "            ", "logger", ".", "log", "(", "f\"Agent at itr {itr}, sample std: {std}.\"", ")", "\n", "", "self", ".", "distribution", ".", "set_std", "(", "std", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.qpg.td3_agent.Td3Agent.eval_mode": [[107, 110], ["super().eval_mode", "td3_agent.Td3Agent.q2_model.eval"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.agents.dmc_sac_agent.SacAgent.eval_mode", "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.augmented_temporal_similarity.AugmentedTemporalSimilarity.eval"], ["", "def", "eval_mode", "(", "self", ",", "itr", ")", ":", "\n", "        ", "super", "(", ")", ".", "eval_mode", "(", "itr", ")", "\n", "self", ".", "q2_model", ".", "eval", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.qpg.td3_agent.Td3Agent.state_dict": [[111, 116], ["super().state_dict", "td3_agent.Td3Agent.q2_model.state_dict", "td3_agent.Td3Agent.target_q2_model.state_dict"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.replay_saver.DummyOptimizer.state_dict", "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.replay_saver.DummyOptimizer.state_dict", "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.replay_saver.DummyOptimizer.state_dict"], ["", "def", "state_dict", "(", "self", ")", ":", "\n", "        ", "state_dict", "=", "super", "(", ")", ".", "state_dict", "(", ")", "\n", "state_dict", "[", "\"q2_model\"", "]", "=", "self", ".", "q2_model", ".", "state_dict", "(", ")", "\n", "state_dict", "[", "\"target_q2_model\"", "]", "=", "self", ".", "target_q2_model", ".", "state_dict", "(", ")", "\n", "return", "state_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.qpg.td3_agent.Td3Agent.load_state_dict": [[117, 121], ["super().load_state_dict", "td3_agent.Td3Agent.q2_model.load_state_dict", "td3_agent.Td3Agent.target_q2_model.load_state_dict"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.augmented_temporal_similarity.AugmentedTemporalSimilarity.load_state_dict", "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.augmented_temporal_similarity.AugmentedTemporalSimilarity.load_state_dict", "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.augmented_temporal_similarity.AugmentedTemporalSimilarity.load_state_dict"], ["", "def", "load_state_dict", "(", "self", ",", "state_dict", ")", ":", "\n", "        ", "super", "(", ")", ".", "load_state_dict", "(", "state_dict", ")", "\n", "self", ".", "q2_model", ".", "load_state_dict", "(", "state_dict", "[", "\"q2_model\"", "]", ")", "\n", "self", ".", "target_q2_model", ".", "load_state_dict", "(", "state_dict", "[", "\"target_q2_model\"", "]", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.astooke_rlpyt.qpg.mlp.MuMlpModel.__init__": [[11, 26], ["super().__init__", "len", "rlpyt.models.mlp.MlpModel", "int", "numpy.prod"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.spaces.gym_wrapper.GymSpaceWrapper.__init__"], ["\n", "\n", "def", "__init__", "(", "\n", "self", ",", "\n", "input_size", ",", "\n", "hidden_sizes", ",", "# Can be empty list or None for none.", "\n", "output_size", "=", "None", ",", "# if None, last layer has nonlinearity applied.", "\n", "nonlinearity", "=", "torch", ".", "nn", ".", "ReLU", ",", "# Module, not Functional.", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "if", "isinstance", "(", "hidden_sizes", ",", "int", ")", ":", "\n", "            ", "hidden_sizes", "=", "[", "hidden_sizes", "]", "\n", "", "elif", "hidden_sizes", "is", "None", ":", "\n", "            ", "hidden_sizes", "=", "[", "]", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.qpg.mlp.MuMlpModel.forward": [[28, 33], ["rlpyt.utils.tensor.infer_leading_dims", "rlpyt.utils.tensor.restore_leading_dims", "torch.tanh", "mlp.MuMlpModel.mlp", "observation.view"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.utils.tensor.infer_leading_dims", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.tensor.restore_leading_dims"], ["zip", "(", "[", "input_size", "]", "+", "hidden_sizes", "[", ":", "-", "1", "]", ",", "hidden_sizes", ")", "]", "\n", "sequence", "=", "list", "(", ")", "\n", "for", "layer", "in", "hidden_layers", ":", "\n", "            ", "sequence", ".", "extend", "(", "[", "layer", ",", "nonlinearity", "(", ")", "]", ")", "\n", "", "if", "output_size", "is", "not", "None", ":", "\n", "            ", "last_size", "=", "hidden_sizes", "[", "-", "1", "]", "if", "hidden_sizes", "else", "input_size", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.qpg.mlp.PiMlpModel.__init__": [[38, 51], ["super().__init__", "len", "rlpyt.models.mlp.MlpModel", "int", "numpy.prod"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.spaces.gym_wrapper.GymSpaceWrapper.__init__"], ["\n", "", "def", "forward", "(", "self", ",", "input", ")", ":", "\n", "        ", "\"\"\"Compute the model on the input, assuming input shape [B,input_size].\"\"\"", "\n", "return", "self", ".", "model", "(", "input", ")", "\n", "\n", "", "@", "property", "\n", "def", "output_size", "(", "self", ")", ":", "\n", "        ", "\"\"\"Retuns the output size of the model.\"\"\"", "\n", "return", "self", ".", "_output_size", "\n", "", "", ""]], "home.repos.pwc.inspect_result.astooke_rlpyt.qpg.mlp.PiMlpModel.forward": [[53, 60], ["rlpyt.utils.tensor.infer_leading_dims", "mlp.PiMlpModel.mlp", "rlpyt.utils.tensor.restore_leading_dims", "observation.view"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.utils.tensor.infer_leading_dims", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.tensor.restore_leading_dims"], []], "home.repos.pwc.inspect_result.astooke_rlpyt.qpg.mlp.QofMuMlpModel.__init__": [[65, 78], ["super().__init__", "len", "rlpyt.models.mlp.MlpModel", "int", "numpy.prod"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.spaces.gym_wrapper.GymSpaceWrapper.__init__"], []], "home.repos.pwc.inspect_result.astooke_rlpyt.qpg.mlp.QofMuMlpModel.forward": [[80, 88], ["rlpyt.utils.tensor.infer_leading_dims", "torch.cat", "mlp.QofMuMlpModel.mlp().squeeze", "rlpyt.utils.tensor.restore_leading_dims", "observation.view", "action.view", "mlp.QofMuMlpModel.mlp"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.utils.tensor.infer_leading_dims", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.tensor.restore_leading_dims"], []], "home.repos.pwc.inspect_result.astooke_rlpyt.qpg.mlp.VMlpModel.__init__": [[92, 104], ["super().__init__", "len", "rlpyt.models.mlp.MlpModel", "int", "numpy.prod"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.spaces.gym_wrapper.GymSpaceWrapper.__init__"], []], "home.repos.pwc.inspect_result.astooke_rlpyt.qpg.mlp.VMlpModel.forward": [[106, 112], ["rlpyt.utils.tensor.infer_leading_dims", "mlp.VMlpModel.mlp().squeeze", "rlpyt.utils.tensor.restore_leading_dims", "mlp.VMlpModel.mlp", "observation.view"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.utils.tensor.infer_leading_dims", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.tensor.restore_leading_dims"], []], "home.repos.pwc.inspect_result.astooke_rlpyt.pg.a2c.A2C.__init__": [[19, 36], ["rlpyt.utils.quick_args.save__init__args", "dict", "locals"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.utils.quick_args.save__init__args"], ["def", "__init__", "(", "\n", "self", ",", "\n", "discount", "=", "0.99", ",", "\n", "learning_rate", "=", "0.001", ",", "\n", "value_loss_coeff", "=", "0.5", ",", "\n", "entropy_loss_coeff", "=", "0.01", ",", "\n", "OptimCls", "=", "torch", ".", "optim", ".", "Adam", ",", "\n", "optim_kwargs", "=", "None", ",", "\n", "clip_grad_norm", "=", "1.", ",", "\n", "initial_optim_state_dict", "=", "None", ",", "\n", "gae_lambda", "=", "1", ",", "\n", "normalize_advantage", "=", "False", ",", "\n", ")", ":", "\n", "        ", "\"\"\"Saves the input settings.\"\"\"", "\n", "if", "optim_kwargs", "is", "None", ":", "\n", "            ", "optim_kwargs", "=", "dict", "(", ")", "\n", "", "save__init__args", "(", "locals", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.pg.a2c.A2C.initialize": [[37, 40], ["super().initialize"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.safe.cppo_agent.CppoLstmAgent.initialize"], ["", "def", "initialize", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "initialize", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "self", ".", "_batch_size", "=", "self", ".", "batch_spec", ".", "size", "# For logging.", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.pg.a2c.A2C.optimize_agent": [[41, 62], ["hasattr", "a2c.A2C.optimizer.zero_grad", "a2c.A2C.loss", "loss.backward", "torch.nn.utils.clip_grad_norm_", "a2c.A2C.optimizer.step", "rlpyt.algos.pg.base.OptInfo", "a2c.A2C.agent.update_obs_rms", "a2c.A2C.agent.parameters", "loss.item", "torch.tensor().item", "entropy.item", "perplexity.item", "torch.tensor"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.safe.cppo_pid.CppoPID.loss", "home.repos.pwc.inspect_result.astooke_rlpyt.models.utils.ScaleGrad.backward", "home.repos.pwc.inspect_result.astooke_rlpyt.safe.safety_gym_env.SafetyGymTrajInfo.step", "home.repos.pwc.inspect_result.astooke_rlpyt.safe.cppo_agent.CppoLstmAgent.update_obs_rms", "home.repos.pwc.inspect_result.astooke_rlpyt.rl.atari_rl_models.AtariDqnModel.parameters"], ["", "def", "optimize_agent", "(", "self", ",", "itr", ",", "samples", ")", ":", "\n", "        ", "\"\"\"\n        Train the agent on input samples, by one gradient step.\n        \"\"\"", "\n", "if", "hasattr", "(", "self", ".", "agent", ",", "\"update_obs_rms\"", ")", ":", "\n", "# NOTE: suboptimal--obs sent to device here and in agent(*inputs).", "\n", "            ", "self", ".", "agent", ".", "update_obs_rms", "(", "samples", ".", "env", ".", "observation", ")", "\n", "", "self", ".", "optimizer", ".", "zero_grad", "(", ")", "\n", "loss", ",", "entropy", ",", "perplexity", "=", "self", ".", "loss", "(", "samples", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "grad_norm", "=", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "\n", "self", ".", "agent", ".", "parameters", "(", ")", ",", "self", ".", "clip_grad_norm", ")", "\n", "self", ".", "optimizer", ".", "step", "(", ")", "\n", "opt_info", "=", "OptInfo", "(", "\n", "loss", "=", "loss", ".", "item", "(", ")", ",", "\n", "gradNorm", "=", "torch", ".", "tensor", "(", "grad_norm", ")", ".", "item", "(", ")", ",", "# backwards compatible,", "\n", "entropy", "=", "entropy", ".", "item", "(", ")", ",", "\n", "perplexity", "=", "perplexity", ".", "item", "(", ")", ",", "\n", ")", "\n", "self", ".", "update_counter", "+=", "1", "\n", "return", "opt_info", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.pg.a2c.A2C.loss": [[63, 104], ["rlpyt.agents.base.AgentInputs", "a2c.A2C.process_returns", "dist.log_likelihood", "dist.mean_entropy", "dist.mean_perplexity", "rlpyt.utils.buffer.buffer_method", "rlpyt.utils.buffer.buffer_method", "a2c.A2C.agent", "a2c.A2C.agent", "rlpyt.utils.tensor.valid_mean", "rlpyt.utils.tensor.valid_mean"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.safe.cppo_pid.CppoPID.process_returns", "home.repos.pwc.inspect_result.astooke_rlpyt.distributions.gaussian.Gaussian.log_likelihood", "home.repos.pwc.inspect_result.astooke_rlpyt.distributions.gaussian.Gaussian.mean_entropy", "home.repos.pwc.inspect_result.astooke_rlpyt.distributions.gaussian.Gaussian.mean_perplexity", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.buffer.buffer_method", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.buffer.buffer_method", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.tensor.valid_mean", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.tensor.valid_mean"], ["", "def", "loss", "(", "self", ",", "samples", ")", ":", "\n", "        ", "\"\"\"\n        Computes the training loss: policy_loss + value_loss + entropy_loss.\n        Policy loss: log-likelihood of actions * advantages\n        Value loss: 0.5 * (estimated_value - return) ^ 2\n        Organizes agent inputs from training samples, calls the agent instance\n        to run forward pass on training data, and uses the\n        ``agent.distribution`` to compute likelihoods and entropies.  Valid\n        for feedforward or recurrent agents.\n        \"\"\"", "\n", "agent_inputs", "=", "AgentInputs", "(", "\n", "observation", "=", "samples", ".", "env", ".", "observation", ",", "\n", "prev_action", "=", "samples", ".", "agent", ".", "prev_action", ",", "\n", "prev_reward", "=", "samples", ".", "env", ".", "prev_reward", ",", "\n", ")", "\n", "if", "self", ".", "agent", ".", "recurrent", ":", "\n", "            ", "init_rnn_state", "=", "samples", ".", "agent", ".", "agent_info", ".", "prev_rnn_state", "[", "0", "]", "# T = 0.", "\n", "# [B,N,H] --> [N,B,H] (for cudnn).", "\n", "init_rnn_state", "=", "buffer_method", "(", "init_rnn_state", ",", "\"transpose\"", ",", "0", ",", "1", ")", "\n", "init_rnn_state", "=", "buffer_method", "(", "init_rnn_state", ",", "\"contiguous\"", ")", "\n", "dist_info", ",", "value", ",", "_rnn_state", "=", "self", ".", "agent", "(", "*", "agent_inputs", ",", "init_rnn_state", ")", "\n", "", "else", ":", "\n", "            ", "dist_info", ",", "value", "=", "self", ".", "agent", "(", "*", "agent_inputs", ")", "\n", "# TODO: try to compute everyone on device.", "\n", "", "return_", ",", "advantage", ",", "valid", "=", "self", ".", "process_returns", "(", "samples", ")", "\n", "\n", "dist", "=", "self", ".", "agent", ".", "distribution", "\n", "logli", "=", "dist", ".", "log_likelihood", "(", "samples", ".", "agent", ".", "action", ",", "dist_info", ")", "\n", "pi_loss", "=", "-", "valid_mean", "(", "logli", "*", "advantage", ",", "valid", ")", "\n", "\n", "value_error", "=", "0.5", "*", "(", "value", "-", "return_", ")", "**", "2", "\n", "value_loss", "=", "self", ".", "value_loss_coeff", "*", "valid_mean", "(", "value_error", ",", "valid", ")", "\n", "\n", "entropy", "=", "dist", ".", "mean_entropy", "(", "dist_info", ",", "valid", ")", "\n", "entropy_loss", "=", "-", "self", ".", "entropy_loss_coeff", "*", "entropy", "\n", "\n", "loss", "=", "pi_loss", "+", "value_loss", "+", "entropy_loss", "\n", "\n", "perplexity", "=", "dist", ".", "mean_perplexity", "(", "dist_info", ",", "valid", ")", "\n", "\n", "return", "loss", ",", "entropy", ",", "perplexity", "\n", "", "", ""]], "home.repos.pwc.inspect_result.astooke_rlpyt.pg.base.PolicyGradientAlgo.initialize": [[24, 40], ["base.PolicyGradientAlgo.OptimCls", "agent.parameters", "base.PolicyGradientAlgo.optimizer.load_state_dict"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.rl.atari_rl_models.AtariDqnModel.parameters", "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.augmented_temporal_similarity.AugmentedTemporalSimilarity.load_state_dict"], ["\n", "raise", "NotImplementedError", "\n", "\n", "", "def", "async_initialize", "(", "self", ",", "agent", ",", "sampler_n_itr", ",", "batch_spec", ",", "mid_batch_reset", ",", "\n", "examples", ",", "world_size", "=", "1", ")", ":", "\n", "        ", "\"\"\"Called instead of ``initialize()`` in async runner (not needed unless\n        using async runner). Should return async replay_buffer using shared\n        memory.\"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n", "", "def", "optim_initialize", "(", "self", ",", "rank", "=", "0", ")", ":", "\n", "        ", "\"\"\"Called in async runner which requires two stages of initialization;\n        might also be used in ``initialize()`` to avoid redundant code.\"\"\"", "\n", "raise", "NotImplementedError", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.pg.base.PolicyGradientAlgo.process_returns": [[41, 76], ["done.type.type.type", "rlpyt.algos.utils.discount_return", "rlpyt.algos.utils.generalized_advantage_estimation", "rlpyt.algos.utils.valid_from_done", "advantage[].mean", "advantage[].std", "advantage.mean", "advantage.std", "max"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.algos.utils.discount_return", "home.repos.pwc.inspect_result.astooke_rlpyt.algos.utils.generalized_advantage_estimation", "home.repos.pwc.inspect_result.astooke_rlpyt.algos.utils.valid_from_done"], ["\n", "", "def", "optimize_agent", "(", "self", ",", "itr", ",", "samples", "=", "None", ",", "sampler_itr", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Train the agent for some number of parameter updates, e.g. either\n        using new samples or a replay buffer.\n\n        Typically called in the runner's training loop.\n\n        Args:\n            itr (int): Iteration of the training loop.\n            samples: New samples from the sampler (for ``None`` case, see async runner).\n            sampler_itr:  For case other than ``None``, see async runner.\n        \"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n", "", "def", "optim_state_dict", "(", "self", ")", ":", "\n", "        ", "\"\"\"Return the optimizer state dict (e.g. Adam); overwrite if using\n        multiple optimizers.\"\"\"", "\n", "return", "self", ".", "optimizer", ".", "state_dict", "(", ")", "\n", "\n", "", "def", "load_optim_state_dict", "(", "self", ",", "state_dict", ")", ":", "\n", "        ", "\"\"\"Load an optimizer state dict; should expect the format returned\n        from ``optim_state_dict().``\"\"\"", "\n", "self", ".", "optimizer", ".", "load_state_dict", "(", "state_dict", ")", "\n", "\n", "", "@", "property", "\n", "def", "batch_size", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_batch_size", "# For logging at least.", "\n", "", "", ""]], "home.repos.pwc.inspect_result.astooke_rlpyt.pg.ppo.PPO.__init__": [[24, 45], ["rlpyt.utils.quick_args.save__init__args", "dict", "locals"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.utils.quick_args.save__init__args"], ["def", "__init__", "(", "\n", "self", ",", "\n", "discount", "=", "0.99", ",", "\n", "learning_rate", "=", "0.001", ",", "\n", "value_loss_coeff", "=", "1.", ",", "\n", "entropy_loss_coeff", "=", "0.01", ",", "\n", "OptimCls", "=", "torch", ".", "optim", ".", "Adam", ",", "\n", "optim_kwargs", "=", "None", ",", "\n", "clip_grad_norm", "=", "1.", ",", "\n", "initial_optim_state_dict", "=", "None", ",", "\n", "gae_lambda", "=", "1", ",", "\n", "minibatches", "=", "4", ",", "\n", "epochs", "=", "4", ",", "\n", "ratio_clip", "=", "0.1", ",", "\n", "linear_lr_schedule", "=", "True", ",", "\n", "normalize_advantage", "=", "False", ",", "\n", ")", ":", "\n", "        ", "\"\"\"Saves input settings.\"\"\"", "\n", "if", "optim_kwargs", "is", "None", ":", "\n", "            ", "optim_kwargs", "=", "dict", "(", ")", "\n", "", "save__init__args", "(", "locals", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.pg.ppo.PPO.initialize": [[46, 58], ["super().initialize", "torch.optim.lr_scheduler.LambdaLR"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.safe.cppo_agent.CppoLstmAgent.initialize"], ["", "def", "initialize", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"\n        Extends base ``initialize()`` to initialize learning rate schedule, if\n        applicable.\n        \"\"\"", "\n", "super", "(", ")", ".", "initialize", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "self", ".", "_batch_size", "=", "self", ".", "batch_spec", ".", "size", "//", "self", ".", "minibatches", "# For logging.", "\n", "if", "self", ".", "linear_lr_schedule", ":", "\n", "            ", "self", ".", "lr_scheduler", "=", "torch", ".", "optim", ".", "lr_scheduler", ".", "LambdaLR", "(", "\n", "optimizer", "=", "self", ".", "optimizer", ",", "\n", "lr_lambda", "=", "lambda", "itr", ":", "(", "self", ".", "n_itr", "-", "itr", ")", "/", "self", ".", "n_itr", ")", "# Step once per itr.", "\n", "self", ".", "_ratio_clip", "=", "self", ".", "ratio_clip", "# Save base value.", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.pg.ppo.PPO.optimize_agent": [[59, 116], ["rlpyt.agents.base.AgentInputs", "rlpyt.utils.buffer.buffer_to", "hasattr", "ppo.PPO.process_returns", "LossInputs", "rlpyt.algos.pg.base.OptInfo", "range", "ppo.PPO.agent.update_obs_rms", "rlpyt.utils.misc.iterate_mb_idxs", "ppo.PPO.lr_scheduler.step", "ppo.PPO.optimizer.zero_grad", "ppo.PPO.loss", "loss.backward", "torch.nn.utils.clip_grad_norm_", "ppo.PPO.optimizer.step", "rlpyt.algos.pg.base.OptInfo.loss.append", "rlpyt.algos.pg.base.OptInfo.gradNorm.append", "rlpyt.algos.pg.base.OptInfo.entropy.append", "rlpyt.algos.pg.base.OptInfo.perplexity.append", "slice", "ppo.PPO.agent.parameters", "loss.item", "torch.tensor().item", "entropy.item", "perplexity.item", "range", "len", "torch.tensor"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.utils.buffer.buffer_to", "home.repos.pwc.inspect_result.astooke_rlpyt.safe.cppo_pid.CppoPID.process_returns", "home.repos.pwc.inspect_result.astooke_rlpyt.safe.cppo_agent.CppoLstmAgent.update_obs_rms", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.misc.iterate_mb_idxs", "home.repos.pwc.inspect_result.astooke_rlpyt.safe.safety_gym_env.SafetyGymTrajInfo.step", "home.repos.pwc.inspect_result.astooke_rlpyt.safe.cppo_pid.CppoPID.loss", "home.repos.pwc.inspect_result.astooke_rlpyt.models.utils.ScaleGrad.backward", "home.repos.pwc.inspect_result.astooke_rlpyt.safe.safety_gym_env.SafetyGymTrajInfo.step", "home.repos.pwc.inspect_result.astooke_rlpyt.rl.atari_rl_models.AtariDqnModel.parameters"], ["", "", "def", "optimize_agent", "(", "self", ",", "itr", ",", "samples", ")", ":", "\n", "        ", "\"\"\"\n        Train the agent, for multiple epochs over minibatches taken from the\n        input samples.  Organizes agent inputs from the training data, and\n        moves them to device (e.g. GPU) up front, so that minibatches are\n        formed within device, without further data transfer.\n        \"\"\"", "\n", "recurrent", "=", "self", ".", "agent", ".", "recurrent", "\n", "agent_inputs", "=", "AgentInputs", "(", "# Move inputs to device once, index there.", "\n", "observation", "=", "samples", ".", "env", ".", "observation", ",", "\n", "prev_action", "=", "samples", ".", "agent", ".", "prev_action", ",", "\n", "prev_reward", "=", "samples", ".", "env", ".", "prev_reward", ",", "\n", ")", "\n", "agent_inputs", "=", "buffer_to", "(", "agent_inputs", ",", "device", "=", "self", ".", "agent", ".", "device", ")", "\n", "if", "hasattr", "(", "self", ".", "agent", ",", "\"update_obs_rms\"", ")", ":", "\n", "            ", "self", ".", "agent", ".", "update_obs_rms", "(", "agent_inputs", ".", "observation", ")", "\n", "", "return_", ",", "advantage", ",", "valid", "=", "self", ".", "process_returns", "(", "samples", ")", "\n", "loss_inputs", "=", "LossInputs", "(", "# So can slice all.", "\n", "agent_inputs", "=", "agent_inputs", ",", "\n", "action", "=", "samples", ".", "agent", ".", "action", ",", "\n", "return_", "=", "return_", ",", "\n", "advantage", "=", "advantage", ",", "\n", "valid", "=", "valid", ",", "\n", "old_dist_info", "=", "samples", ".", "agent", ".", "agent_info", ".", "dist_info", ",", "\n", ")", "\n", "if", "recurrent", ":", "\n", "# Leave in [B,N,H] for slicing to minibatches.", "\n", "            ", "init_rnn_state", "=", "samples", ".", "agent", ".", "agent_info", ".", "prev_rnn_state", "[", "0", "]", "# T=0.", "\n", "", "T", ",", "B", "=", "samples", ".", "env", ".", "reward", ".", "shape", "[", ":", "2", "]", "\n", "opt_info", "=", "OptInfo", "(", "*", "(", "[", "]", "for", "_", "in", "range", "(", "len", "(", "OptInfo", ".", "_fields", ")", ")", ")", ")", "\n", "# If recurrent, use whole trajectories, only shuffle B; else shuffle all.", "\n", "batch_size", "=", "B", "if", "self", ".", "agent", ".", "recurrent", "else", "T", "*", "B", "\n", "mb_size", "=", "batch_size", "//", "self", ".", "minibatches", "\n", "for", "_", "in", "range", "(", "self", ".", "epochs", ")", ":", "\n", "            ", "for", "idxs", "in", "iterate_mb_idxs", "(", "batch_size", ",", "mb_size", ",", "shuffle", "=", "True", ")", ":", "\n", "                ", "T_idxs", "=", "slice", "(", "None", ")", "if", "recurrent", "else", "idxs", "%", "T", "\n", "B_idxs", "=", "idxs", "if", "recurrent", "else", "idxs", "//", "T", "\n", "self", ".", "optimizer", ".", "zero_grad", "(", ")", "\n", "rnn_state", "=", "init_rnn_state", "[", "B_idxs", "]", "if", "recurrent", "else", "None", "\n", "# NOTE: if not recurrent, will lose leading T dim, should be OK.", "\n", "loss", ",", "entropy", ",", "perplexity", "=", "self", ".", "loss", "(", "\n", "*", "loss_inputs", "[", "T_idxs", ",", "B_idxs", "]", ",", "rnn_state", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "grad_norm", "=", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "\n", "self", ".", "agent", ".", "parameters", "(", ")", ",", "self", ".", "clip_grad_norm", ")", "\n", "self", ".", "optimizer", ".", "step", "(", ")", "\n", "\n", "opt_info", ".", "loss", ".", "append", "(", "loss", ".", "item", "(", ")", ")", "\n", "opt_info", ".", "gradNorm", ".", "append", "(", "torch", ".", "tensor", "(", "grad_norm", ")", ".", "item", "(", ")", ")", "# backwards compatible", "\n", "opt_info", ".", "entropy", ".", "append", "(", "entropy", ".", "item", "(", ")", ")", "\n", "opt_info", ".", "perplexity", ".", "append", "(", "perplexity", ".", "item", "(", ")", ")", "\n", "self", ".", "update_counter", "+=", "1", "\n", "", "", "if", "self", ".", "linear_lr_schedule", ":", "\n", "            ", "self", ".", "lr_scheduler", ".", "step", "(", ")", "\n", "self", ".", "ratio_clip", "=", "self", ".", "_ratio_clip", "*", "(", "self", ".", "n_itr", "-", "itr", ")", "/", "self", ".", "n_itr", "\n", "\n", "", "return", "opt_info", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.pg.ppo.PPO.loss": [[117, 155], ["dist.likelihood_ratio", "torch.clamp", "torch.min", "dist.mean_entropy", "dist.mean_perplexity", "rlpyt.utils.buffer.buffer_method", "rlpyt.utils.buffer.buffer_method", "ppo.PPO.agent", "ppo.PPO.agent", "rlpyt.utils.tensor.valid_mean", "rlpyt.utils.tensor.valid_mean"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.distributions.gaussian.Gaussian.likelihood_ratio", "home.repos.pwc.inspect_result.astooke_rlpyt.distributions.gaussian.Gaussian.mean_entropy", "home.repos.pwc.inspect_result.astooke_rlpyt.distributions.gaussian.Gaussian.mean_perplexity", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.buffer.buffer_method", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.buffer.buffer_method", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.tensor.valid_mean", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.tensor.valid_mean"], ["", "def", "loss", "(", "self", ",", "agent_inputs", ",", "action", ",", "return_", ",", "advantage", ",", "valid", ",", "old_dist_info", ",", "\n", "init_rnn_state", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Compute the training loss: policy_loss + value_loss + entropy_loss\n        Policy loss: min(likelhood-ratio * advantage, clip(likelihood_ratio, 1-eps, 1+eps) * advantage)\n        Value loss:  0.5 * (estimated_value - return) ^ 2\n        Calls the agent to compute forward pass on training data, and uses\n        the ``agent.distribution`` to compute likelihoods and entropies.  Valid\n        for feedforward or recurrent agents.\n        \"\"\"", "\n", "if", "init_rnn_state", "is", "not", "None", ":", "\n", "# [B,N,H] --> [N,B,H] (for cudnn).", "\n", "            ", "init_rnn_state", "=", "buffer_method", "(", "init_rnn_state", ",", "\"transpose\"", ",", "0", ",", "1", ")", "\n", "init_rnn_state", "=", "buffer_method", "(", "init_rnn_state", ",", "\"contiguous\"", ")", "\n", "dist_info", ",", "value", ",", "_rnn_state", "=", "self", ".", "agent", "(", "*", "agent_inputs", ",", "init_rnn_state", ")", "\n", "", "else", ":", "\n", "            ", "dist_info", ",", "value", "=", "self", ".", "agent", "(", "*", "agent_inputs", ")", "\n", "", "dist", "=", "self", ".", "agent", ".", "distribution", "\n", "\n", "ratio", "=", "dist", ".", "likelihood_ratio", "(", "action", ",", "old_dist_info", "=", "old_dist_info", ",", "\n", "new_dist_info", "=", "dist_info", ")", "\n", "surr_1", "=", "ratio", "*", "advantage", "\n", "clipped_ratio", "=", "torch", ".", "clamp", "(", "ratio", ",", "1.", "-", "self", ".", "ratio_clip", ",", "\n", "1.", "+", "self", ".", "ratio_clip", ")", "\n", "surr_2", "=", "clipped_ratio", "*", "advantage", "\n", "surrogate", "=", "torch", ".", "min", "(", "surr_1", ",", "surr_2", ")", "\n", "pi_loss", "=", "-", "valid_mean", "(", "surrogate", ",", "valid", ")", "\n", "\n", "value_error", "=", "0.5", "*", "(", "value", "-", "return_", ")", "**", "2", "\n", "value_loss", "=", "self", ".", "value_loss_coeff", "*", "valid_mean", "(", "value_error", ",", "valid", ")", "\n", "\n", "entropy", "=", "dist", ".", "mean_entropy", "(", "dist_info", ",", "valid", ")", "\n", "entropy_loss", "=", "-", "self", ".", "entropy_loss_coeff", "*", "entropy", "\n", "\n", "loss", "=", "pi_loss", "+", "value_loss", "+", "entropy_loss", "\n", "\n", "perplexity", "=", "dist", ".", "mean_perplexity", "(", "dist_info", ",", "valid", ")", "\n", "return", "loss", ",", "entropy", ",", "perplexity", "\n", "", "", ""]], "home.repos.pwc.inspect_result.astooke_rlpyt.pg.categorical.CategoricalPgAgent.__call__": [[20, 26], ["categorical.CategoricalPgAgent.distribution.to_onehot", "rlpyt.utils.buffer.buffer_to", "categorical.CategoricalPgAgent.model", "rlpyt.utils.buffer.buffer_to", "rlpyt.distributions.categorical.DistInfo"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.distributions.discrete.DiscreteMixin.to_onehot", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.buffer.buffer_to", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.buffer.buffer_to"], ["def", "__call__", "(", "self", ",", "observation", ",", "prev_action", ",", "prev_reward", ")", ":", "\n", "        ", "prev_action", "=", "self", ".", "distribution", ".", "to_onehot", "(", "prev_action", ")", "\n", "model_inputs", "=", "buffer_to", "(", "(", "observation", ",", "prev_action", ",", "prev_reward", ")", ",", "\n", "device", "=", "self", ".", "device", ")", "\n", "pi", ",", "value", "=", "self", ".", "model", "(", "*", "model_inputs", ")", "\n", "return", "buffer_to", "(", "(", "DistInfo", "(", "prob", "=", "pi", ")", ",", "value", ")", ",", "device", "=", "\"cpu\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.pg.categorical.CategoricalPgAgent.initialize": [[27, 32], ["super().initialize", "rlpyt.distributions.categorical.Categorical"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.safe.cppo_agent.CppoLstmAgent.initialize"], ["", "def", "initialize", "(", "self", ",", "env_spaces", ",", "share_memory", "=", "False", ",", "\n", "global_B", "=", "1", ",", "env_ranks", "=", "None", ")", ":", "\n", "        ", "super", "(", ")", ".", "initialize", "(", "env_spaces", ",", "share_memory", ",", "\n", "global_B", "=", "global_B", ",", "env_ranks", "=", "env_ranks", ")", "\n", "self", ".", "distribution", "=", "Categorical", "(", "dim", "=", "env_spaces", ".", "action", ".", "n", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.pg.categorical.CategoricalPgAgent.step": [[33, 44], ["torch.no_grad", "categorical.CategoricalPgAgent.distribution.to_onehot", "rlpyt.utils.buffer.buffer_to", "categorical.CategoricalPgAgent.model", "rlpyt.distributions.categorical.DistInfo", "categorical.CategoricalPgAgent.distribution.sample", "rlpyt.agents.pg.base.AgentInfo", "rlpyt.utils.buffer.buffer_to", "rlpyt.agents.base.AgentStep"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.distributions.discrete.DiscreteMixin.to_onehot", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.buffer.buffer_to", "home.repos.pwc.inspect_result.astooke_rlpyt.spaces.gym_wrapper.GymSpaceWrapper.sample", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.buffer.buffer_to"], ["", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "step", "(", "self", ",", "observation", ",", "prev_action", ",", "prev_reward", ")", ":", "\n", "        ", "prev_action", "=", "self", ".", "distribution", ".", "to_onehot", "(", "prev_action", ")", "\n", "model_inputs", "=", "buffer_to", "(", "(", "observation", ",", "prev_action", ",", "prev_reward", ")", ",", "\n", "device", "=", "self", ".", "device", ")", "\n", "pi", ",", "value", "=", "self", ".", "model", "(", "*", "model_inputs", ")", "\n", "dist_info", "=", "DistInfo", "(", "prob", "=", "pi", ")", "\n", "action", "=", "self", ".", "distribution", ".", "sample", "(", "dist_info", ")", "\n", "agent_info", "=", "AgentInfo", "(", "dist_info", "=", "dist_info", ",", "value", "=", "value", ")", "\n", "action", ",", "agent_info", "=", "buffer_to", "(", "(", "action", ",", "agent_info", ")", ",", "device", "=", "\"cpu\"", ")", "\n", "return", "AgentStep", "(", "action", "=", "action", ",", "agent_info", "=", "agent_info", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.pg.categorical.CategoricalPgAgent.value": [[45, 52], ["torch.no_grad", "categorical.CategoricalPgAgent.distribution.to_onehot", "rlpyt.utils.buffer.buffer_to", "categorical.CategoricalPgAgent.model", "value.to"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.distributions.discrete.DiscreteMixin.to_onehot", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.buffer.buffer_to"], ["", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "value", "(", "self", ",", "observation", ",", "prev_action", ",", "prev_reward", ")", ":", "\n", "        ", "prev_action", "=", "self", ".", "distribution", ".", "to_onehot", "(", "prev_action", ")", "\n", "model_inputs", "=", "buffer_to", "(", "(", "observation", ",", "prev_action", ",", "prev_reward", ")", ",", "\n", "device", "=", "self", ".", "device", ")", "\n", "_pi", ",", "value", "=", "self", ".", "model", "(", "*", "model_inputs", ")", "\n", "return", "value", ".", "to", "(", "\"cpu\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.pg.categorical.RecurrentCategoricalPgAgentBase.__call__": [[56, 64], ["categorical.RecurrentCategoricalPgAgentBase.distribution.to_onehot", "rlpyt.utils.buffer.buffer_to", "categorical.RecurrentCategoricalPgAgentBase.model", "rlpyt.utils.buffer.buffer_to", "rlpyt.distributions.categorical.DistInfo"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.distributions.discrete.DiscreteMixin.to_onehot", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.buffer.buffer_to", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.buffer.buffer_to"], ["    ", "def", "__call__", "(", "self", ",", "observation", ",", "prev_action", ",", "prev_reward", ",", "init_rnn_state", ")", ":", "\n", "# Assume init_rnn_state already shaped: [N,B,H]", "\n", "        ", "prev_action", "=", "self", ".", "distribution", ".", "to_onehot", "(", "prev_action", ")", "\n", "model_inputs", "=", "buffer_to", "(", "(", "observation", ",", "prev_action", ",", "prev_reward", ",", "\n", "init_rnn_state", ")", ",", "device", "=", "self", ".", "device", ")", "\n", "pi", ",", "value", ",", "next_rnn_state", "=", "self", ".", "model", "(", "*", "model_inputs", ")", "\n", "dist_info", ",", "value", "=", "buffer_to", "(", "(", "DistInfo", "(", "prob", "=", "pi", ")", ",", "value", ")", ",", "device", "=", "\"cpu\"", ")", "\n", "return", "dist_info", ",", "value", ",", "next_rnn_state", "# Leave rnn_state on device.", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.pg.categorical.RecurrentCategoricalPgAgentBase.initialize": [[65, 70], ["super().initialize", "rlpyt.distributions.categorical.Categorical"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.safe.cppo_agent.CppoLstmAgent.initialize"], ["", "def", "initialize", "(", "self", ",", "env_spaces", ",", "share_memory", "=", "False", ",", "\n", "global_B", "=", "1", ",", "env_ranks", "=", "None", ")", ":", "\n", "        ", "super", "(", ")", ".", "initialize", "(", "env_spaces", ",", "share_memory", ",", "\n", "global_B", "=", "global_B", ",", "env_ranks", "=", "env_ranks", ")", "\n", "self", ".", "distribution", "=", "Categorical", "(", "dim", "=", "env_spaces", ".", "action", ".", "n", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.pg.categorical.RecurrentCategoricalPgAgentBase.step": [[71, 89], ["torch.no_grad", "categorical.RecurrentCategoricalPgAgentBase.distribution.to_onehot", "rlpyt.utils.buffer.buffer_to", "categorical.RecurrentCategoricalPgAgentBase.model", "rlpyt.distributions.categorical.DistInfo", "categorical.RecurrentCategoricalPgAgentBase.distribution.sample", "rlpyt.utils.buffer.buffer_method", "rlpyt.agents.pg.base.AgentInfoRnn", "rlpyt.utils.buffer.buffer_to", "categorical.RecurrentCategoricalPgAgentBase.advance_rnn_state", "rlpyt.agents.base.AgentStep", "rlpyt.utils.buffer.buffer_func"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.distributions.discrete.DiscreteMixin.to_onehot", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.buffer.buffer_to", "home.repos.pwc.inspect_result.astooke_rlpyt.spaces.gym_wrapper.GymSpaceWrapper.sample", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.buffer.buffer_method", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.buffer.buffer_to", "home.repos.pwc.inspect_result.astooke_rlpyt.agents.base.AlternatingRecurrentAgentMixin.advance_rnn_state", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.buffer.buffer_func"], ["", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "step", "(", "self", ",", "observation", ",", "prev_action", ",", "prev_reward", ")", ":", "\n", "        ", "prev_action", "=", "self", ".", "distribution", ".", "to_onehot", "(", "prev_action", ")", "\n", "agent_inputs", "=", "buffer_to", "(", "(", "observation", ",", "prev_action", ",", "prev_reward", ")", ",", "\n", "device", "=", "self", ".", "device", ")", "\n", "pi", ",", "value", ",", "rnn_state", "=", "self", ".", "model", "(", "*", "agent_inputs", ",", "self", ".", "prev_rnn_state", ")", "\n", "dist_info", "=", "DistInfo", "(", "prob", "=", "pi", ")", "\n", "action", "=", "self", ".", "distribution", ".", "sample", "(", "dist_info", ")", "\n", "# Model handles None, but Buffer does not, make zeros if needed:", "\n", "prev_rnn_state", "=", "self", ".", "prev_rnn_state", "or", "buffer_func", "(", "rnn_state", ",", "torch", ".", "zeros_like", ")", "\n", "# Transpose the rnn_state from [N,B,H] --> [B,N,H] for storage.", "\n", "# (Special case: model should always leave B dimension in.)", "\n", "prev_rnn_state", "=", "buffer_method", "(", "prev_rnn_state", ",", "\"transpose\"", ",", "0", ",", "1", ")", "\n", "agent_info", "=", "AgentInfoRnn", "(", "dist_info", "=", "dist_info", ",", "value", "=", "value", ",", "\n", "prev_rnn_state", "=", "prev_rnn_state", ")", "\n", "action", ",", "agent_info", "=", "buffer_to", "(", "(", "action", ",", "agent_info", ")", ",", "device", "=", "\"cpu\"", ")", "\n", "self", ".", "advance_rnn_state", "(", "rnn_state", ")", "# Keep on device.", "\n", "return", "AgentStep", "(", "action", "=", "action", ",", "agent_info", "=", "agent_info", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.pg.categorical.RecurrentCategoricalPgAgentBase.value": [[90, 97], ["torch.no_grad", "categorical.RecurrentCategoricalPgAgentBase.distribution.to_onehot", "rlpyt.utils.buffer.buffer_to", "categorical.RecurrentCategoricalPgAgentBase.model", "value.to"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.distributions.discrete.DiscreteMixin.to_onehot", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.buffer.buffer_to"], ["", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "value", "(", "self", ",", "observation", ",", "prev_action", ",", "prev_reward", ")", ":", "\n", "        ", "prev_action", "=", "self", ".", "distribution", ".", "to_onehot", "(", "prev_action", ")", "\n", "agent_inputs", "=", "buffer_to", "(", "(", "observation", ",", "prev_action", ",", "prev_reward", ")", ",", "\n", "device", "=", "self", ".", "device", ")", "\n", "_pi", ",", "value", ",", "_rnn_state", "=", "self", ".", "model", "(", "*", "agent_inputs", ",", "self", ".", "prev_rnn_state", ")", "\n", "return", "value", ".", "to", "(", "\"cpu\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.pg.atari.AtariMixin.make_env_to_model_kwargs": [[15, 19], ["dict"], "methods", ["None"], ["def", "make_env_to_model_kwargs", "(", "self", ",", "env_spaces", ")", ":", "\n", "        ", "\"\"\"Extract image shape and action size.\"\"\"", "\n", "return", "dict", "(", "image_shape", "=", "env_spaces", ".", "observation", ".", "shape", ",", "\n", "output_size", "=", "env_spaces", ".", "action", ".", "n", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.pg.atari.AtariFfAgent.__init__": [[23, 25], ["rlpyt.agents.pg.categorical.CategoricalPgAgent.__init__"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.spaces.gym_wrapper.GymSpaceWrapper.__init__"], ["    ", "def", "__init__", "(", "self", ",", "ModelCls", "=", "AtariFfModel", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "ModelCls", "=", "ModelCls", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.pg.atari.AtariLstmAgent.__init__": [[29, 31], ["rlpyt.agents.pg.categorical.RecurrentCategoricalPgAgent.__init__"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.spaces.gym_wrapper.GymSpaceWrapper.__init__"], ["    ", "def", "__init__", "(", "self", ",", "ModelCls", "=", "AtariLstmModel", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "ModelCls", "=", "ModelCls", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.pg.atari.AlternatingAtariLstmAgent.__init__": [[36, 38], ["rlpyt.agents.pg.categorical.AlternatingRecurrentCategoricalPgAgent.__init__"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.spaces.gym_wrapper.GymSpaceWrapper.__init__"], ["    ", "def", "__init__", "(", "self", ",", "ModelCls", "=", "AtariLstmModel", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "ModelCls", "=", "ModelCls", ",", "**", "kwargs", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.astooke_rlpyt.pg.gaussian.GaussianPgAgent.__call__": [[19, 25], ["rlpyt.utils.buffer.buffer_to", "gaussian.GaussianPgAgent.model", "rlpyt.utils.buffer.buffer_to", "rlpyt.distributions.gaussian.DistInfoStd"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.utils.buffer.buffer_to", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.buffer.buffer_to"], ["def", "__call__", "(", "self", ",", "observation", ",", "prev_action", ",", "prev_reward", ")", ":", "\n", "        ", "\"\"\"Performs forward pass on training data, for algorithm.\"\"\"", "\n", "model_inputs", "=", "buffer_to", "(", "(", "observation", ",", "prev_action", ",", "prev_reward", ")", ",", "\n", "device", "=", "self", ".", "device", ")", "\n", "mu", ",", "log_std", ",", "value", "=", "self", ".", "model", "(", "*", "model_inputs", ")", "\n", "return", "buffer_to", "(", "(", "DistInfoStd", "(", "mean", "=", "mu", ",", "log_std", "=", "log_std", ")", ",", "value", ")", ",", "device", "=", "\"cpu\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.pg.gaussian.GaussianPgAgent.initialize": [[26, 36], ["super().initialize", "numpy.all", "rlpyt.distributions.gaussian.Gaussian", "len", "len", "numpy.unique"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.safe.cppo_agent.CppoLstmAgent.initialize"], ["", "def", "initialize", "(", "self", ",", "env_spaces", ",", "share_memory", "=", "False", ",", "\n", "global_B", "=", "1", ",", "env_ranks", "=", "None", ")", ":", "\n", "        ", "\"\"\"Extends base method to build Gaussian distribution.\"\"\"", "\n", "super", "(", ")", ".", "initialize", "(", "env_spaces", ",", "share_memory", ",", "\n", "global_B", "=", "global_B", ",", "env_ranks", "=", "env_ranks", ")", "\n", "assert", "len", "(", "env_spaces", ".", "action", ".", "shape", ")", "==", "1", "\n", "assert", "len", "(", "np", ".", "unique", "(", "env_spaces", ".", "action", ".", "high", ")", ")", "==", "1", "\n", "assert", "np", ".", "all", "(", "env_spaces", ".", "action", ".", "low", "==", "-", "env_spaces", ".", "action", ".", "high", ")", "\n", "self", ".", "distribution", "=", "Gaussian", "(", "\n", "dim", "=", "env_spaces", ".", "action", ".", "shape", "[", "0", "]", ",", "\n", "# min_std=MIN_STD,", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.pg.gaussian.GaussianPgAgent.step": [[40, 56], ["torch.no_grad", "rlpyt.utils.buffer.buffer_to", "gaussian.GaussianPgAgent.model", "rlpyt.distributions.gaussian.DistInfoStd", "gaussian.GaussianPgAgent.distribution.sample", "rlpyt.agents.pg.base.AgentInfo", "rlpyt.utils.buffer.buffer_to", "rlpyt.agents.base.AgentStep"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.utils.buffer.buffer_to", "home.repos.pwc.inspect_result.astooke_rlpyt.spaces.gym_wrapper.GymSpaceWrapper.sample", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.buffer.buffer_to"], ["", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "step", "(", "self", ",", "observation", ",", "prev_action", ",", "prev_reward", ")", ":", "\n", "        ", "\"\"\"\n        Compute policy's action distribution from inputs, and sample an\n        action. Calls the model to produce mean, log_std, and value estimate.\n        Moves inputs to device and returns outputs back to CPU, for the\n        sampler.  (no grad)\n        \"\"\"", "\n", "model_inputs", "=", "buffer_to", "(", "(", "observation", ",", "prev_action", ",", "prev_reward", ")", ",", "\n", "device", "=", "self", ".", "device", ")", "\n", "mu", ",", "log_std", ",", "value", "=", "self", ".", "model", "(", "*", "model_inputs", ")", "\n", "dist_info", "=", "DistInfoStd", "(", "mean", "=", "mu", ",", "log_std", "=", "log_std", ")", "\n", "action", "=", "self", ".", "distribution", ".", "sample", "(", "dist_info", ")", "\n", "agent_info", "=", "AgentInfo", "(", "dist_info", "=", "dist_info", ",", "value", "=", "value", ")", "\n", "action", ",", "agent_info", "=", "buffer_to", "(", "(", "action", ",", "agent_info", ")", ",", "device", "=", "\"cpu\"", ")", "\n", "return", "AgentStep", "(", "action", "=", "action", ",", "agent_info", "=", "agent_info", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.pg.gaussian.GaussianPgAgent.value": [[57, 67], ["torch.no_grad", "rlpyt.utils.buffer.buffer_to", "gaussian.GaussianPgAgent.model", "value.to"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.utils.buffer.buffer_to"], ["", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "value", "(", "self", ",", "observation", ",", "prev_action", ",", "prev_reward", ")", ":", "\n", "        ", "\"\"\"\n        Compute the value estimate for the environment state, e.g. for the\n        bootstrap value, V(s_{T+1}), in the sampler.  (no grad)\n        \"\"\"", "\n", "model_inputs", "=", "buffer_to", "(", "(", "observation", ",", "prev_action", ",", "prev_reward", ")", ",", "\n", "device", "=", "self", ".", "device", ")", "\n", "_mu", ",", "_log_std", ",", "value", "=", "self", ".", "model", "(", "*", "model_inputs", ")", "\n", "return", "value", ".", "to", "(", "\"cpu\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.pg.gaussian.RecurrentGaussianPgAgentBase.__call__": [[71, 80], ["rlpyt.utils.buffer.buffer_to", "gaussian.RecurrentGaussianPgAgentBase.model", "rlpyt.utils.buffer.buffer_to", "rlpyt.distributions.gaussian.DistInfoStd"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.utils.buffer.buffer_to", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.buffer.buffer_to"], ["    ", "def", "__call__", "(", "self", ",", "observation", ",", "prev_action", ",", "prev_reward", ",", "init_rnn_state", ")", ":", "\n", "        ", "\"\"\"Performs forward pass on training data, for algorithm (requires\n        recurrent state input).\"\"\"", "\n", "# Assume init_rnn_state already shaped: [N,B,H]", "\n", "model_inputs", "=", "buffer_to", "(", "(", "observation", ",", "prev_action", ",", "prev_reward", ",", "\n", "init_rnn_state", ")", ",", "device", "=", "self", ".", "device", ")", "\n", "mu", ",", "log_std", ",", "value", ",", "next_rnn_state", "=", "self", ".", "model", "(", "*", "model_inputs", ")", "\n", "dist_info", ",", "value", "=", "buffer_to", "(", "(", "DistInfoStd", "(", "mean", "=", "mu", ",", "log_std", "=", "log_std", ")", ",", "value", ")", ",", "device", "=", "\"cpu\"", ")", "\n", "return", "dist_info", ",", "value", ",", "next_rnn_state", "# Leave rnn_state on device.", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.pg.gaussian.RecurrentGaussianPgAgentBase.initialize": [[81, 87], ["super().initialize", "rlpyt.distributions.gaussian.Gaussian", "len"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.safe.cppo_agent.CppoLstmAgent.initialize"], ["", "def", "initialize", "(", "self", ",", "env_spaces", ",", "share_memory", "=", "False", ",", "\n", "global_B", "=", "1", ",", "env_ranks", "=", "None", ")", ":", "\n", "        ", "super", "(", ")", ".", "initialize", "(", "env_spaces", ",", "share_memory", ")", "\n", "assert", "len", "(", "env_spaces", ".", "action", ".", "shape", ")", "==", "1", "\n", "self", ".", "distribution", "=", "Gaussian", "(", "\n", "dim", "=", "env_spaces", ".", "action", ".", "shape", "[", "0", "]", ",", "\n", "# min_std=MIN_STD,", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.pg.gaussian.RecurrentGaussianPgAgentBase.step": [[91, 115], ["torch.no_grad", "rlpyt.utils.buffer.buffer_to", "gaussian.RecurrentGaussianPgAgentBase.model", "rlpyt.distributions.gaussian.DistInfoStd", "gaussian.RecurrentGaussianPgAgentBase.distribution.sample", "rlpyt.utils.buffer.buffer_method", "rlpyt.agents.pg.base.AgentInfoRnn", "rlpyt.utils.buffer.buffer_to", "gaussian.RecurrentGaussianPgAgentBase.advance_rnn_state", "rlpyt.agents.base.AgentStep", "rlpyt.utils.buffer.buffer_func"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.utils.buffer.buffer_to", "home.repos.pwc.inspect_result.astooke_rlpyt.spaces.gym_wrapper.GymSpaceWrapper.sample", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.buffer.buffer_method", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.buffer.buffer_to", "home.repos.pwc.inspect_result.astooke_rlpyt.agents.base.AlternatingRecurrentAgentMixin.advance_rnn_state", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.buffer.buffer_func"], ["", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "step", "(", "self", ",", "observation", ",", "prev_action", ",", "prev_reward", ")", ":", "\n", "        ", "\"\"\"\n        Compute policy's action distribution from inputs, and sample an\n        action. Calls the model to produce mean, log_std, value estimate, and\n        next recurrent state.  Moves inputs to device and returns outputs back\n        to CPU, for the sampler.  Advances the recurrent state of the agent.\n        (no grad)\n        \"\"\"", "\n", "agent_inputs", "=", "buffer_to", "(", "(", "observation", ",", "prev_action", ",", "prev_reward", ")", ",", "\n", "device", "=", "self", ".", "device", ")", "\n", "mu", ",", "log_std", ",", "value", ",", "rnn_state", "=", "self", ".", "model", "(", "*", "agent_inputs", ",", "self", ".", "prev_rnn_state", ")", "\n", "dist_info", "=", "DistInfoStd", "(", "mean", "=", "mu", ",", "log_std", "=", "log_std", ")", "\n", "action", "=", "self", ".", "distribution", ".", "sample", "(", "dist_info", ")", "\n", "# Model handles None, but Buffer does not, make zeros if needed:", "\n", "prev_rnn_state", "=", "self", ".", "prev_rnn_state", "or", "buffer_func", "(", "rnn_state", ",", "torch", ".", "zeros_like", ")", "\n", "# Transpose the rnn_state from [N,B,H] --> [B,N,H] for storage.", "\n", "# (Special case: model should always leave B dimension in.)", "\n", "prev_rnn_state", "=", "buffer_method", "(", "prev_rnn_state", ",", "\"transpose\"", ",", "0", ",", "1", ")", "\n", "agent_info", "=", "AgentInfoRnn", "(", "dist_info", "=", "dist_info", ",", "value", "=", "value", ",", "\n", "prev_rnn_state", "=", "prev_rnn_state", ")", "\n", "action", ",", "agent_info", "=", "buffer_to", "(", "(", "action", ",", "agent_info", ")", ",", "device", "=", "\"cpu\"", ")", "\n", "self", ".", "advance_rnn_state", "(", "rnn_state", ")", "# Keep on device.", "\n", "return", "AgentStep", "(", "action", "=", "action", ",", "agent_info", "=", "agent_info", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.pg.gaussian.RecurrentGaussianPgAgentBase.value": [[116, 127], ["torch.no_grad", "rlpyt.utils.buffer.buffer_to", "gaussian.RecurrentGaussianPgAgentBase.model", "value.to"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.utils.buffer.buffer_to"], ["", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "value", "(", "self", ",", "observation", ",", "prev_action", ",", "prev_reward", ")", ":", "\n", "        ", "\"\"\"\n        Compute the value estimate for the environment state using the\n        currently held recurrent state, without advancing the recurrent state,\n        e.g. for the bootstrap value V(s_{T+1}), in the sampler.  (no grad)\n        \"\"\"", "\n", "agent_inputs", "=", "buffer_to", "(", "(", "observation", ",", "prev_action", ",", "prev_reward", ")", ",", "\n", "device", "=", "self", ".", "device", ")", "\n", "_mu", ",", "_log_std", ",", "value", ",", "_rnn_state", "=", "self", ".", "model", "(", "*", "agent_inputs", ",", "self", ".", "prev_rnn_state", ")", "\n", "return", "value", ".", "to", "(", "\"cpu\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.pg.mujoco.MujocoMixin.make_env_to_model_kwargs": [[18, 23], ["dict", "len"], "methods", ["None"], ["def", "make_env_to_model_kwargs", "(", "self", ",", "env_spaces", ")", ":", "\n", "        ", "\"\"\"Extract observation_shape and action_size.\"\"\"", "\n", "assert", "len", "(", "env_spaces", ".", "action", ".", "shape", ")", "==", "1", "\n", "return", "dict", "(", "observation_shape", "=", "env_spaces", ".", "observation", ".", "shape", ",", "\n", "action_size", "=", "env_spaces", ".", "action", ".", "shape", "[", "0", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.pg.mujoco.MujocoMixin.update_obs_rms": [[24, 30], ["rlpyt.utils.buffer.buffer_to", "mujoco.MujocoMixin.model.module.update_obs_rms", "mujoco.MujocoMixin.model.update_obs_rms"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.utils.buffer.buffer_to", "home.repos.pwc.inspect_result.astooke_rlpyt.safe.cppo_agent.CppoLstmAgent.update_obs_rms", "home.repos.pwc.inspect_result.astooke_rlpyt.safe.cppo_agent.CppoLstmAgent.update_obs_rms"], ["", "def", "update_obs_rms", "(", "self", ",", "observation", ")", ":", "\n", "        ", "observation", "=", "buffer_to", "(", "observation", ",", "device", "=", "self", ".", "device", ")", "\n", "if", "self", ".", "_ddp", ":", "\n", "            ", "self", ".", "model", ".", "module", ".", "update_obs_rms", "(", "observation", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "model", ".", "update_obs_rms", "(", "observation", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.pg.mujoco.MujocoMixin.data_parallel": [[31, 34], ["super().data_parallel"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.safe.cppo_agent.CppoLstmAgent.data_parallel"], ["", "", "def", "data_parallel", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "data_parallel", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "self", ".", "_ddp", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.pg.mujoco.MujocoFfAgent.__init__": [[38, 40], ["rlpyt.agents.pg.gaussian.GaussianPgAgent.__init__"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.spaces.gym_wrapper.GymSpaceWrapper.__init__"], ["    ", "def", "__init__", "(", "self", ",", "ModelCls", "=", "MujocoFfModel", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "ModelCls", "=", "ModelCls", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.pg.mujoco.MujocoLstmAgent.__init__": [[44, 46], ["rlpyt.agents.pg.gaussian.RecurrentGaussianPgAgent.__init__"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.spaces.gym_wrapper.GymSpaceWrapper.__init__"], ["    ", "def", "__init__", "(", "self", ",", "ModelCls", "=", "MujocoLstmModel", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "ModelCls", "=", "ModelCls", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.pg.mujoco.AlternatingMujocoLstmAgent.__init__": [[51, 53], ["rlpyt.agents.pg.gaussian.AlternatingRecurrentGaussianPgAgent.__init__"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.spaces.gym_wrapper.GymSpaceWrapper.__init__"], ["    ", "def", "__init__", "(", "self", ",", "ModelCls", "=", "MujocoLstmModel", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "ModelCls", "=", "ModelCls", ",", "**", "kwargs", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.astooke_rlpyt.pg.atari_ff_model.AtariFfModel.__init__": [[15, 39], ["super().__init__", "rlpyt.models.conv2d.Conv2dHeadModel", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.spaces.gym_wrapper.GymSpaceWrapper.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "image_shape", ",", "\n", "output_size", ",", "\n", "fc_sizes", "=", "512", ",", "\n", "use_maxpool", "=", "False", ",", "\n", "channels", "=", "None", ",", "# None uses default.", "\n", "kernel_sizes", "=", "None", ",", "\n", "strides", "=", "None", ",", "\n", "paddings", "=", "None", ",", "\n", ")", ":", "\n", "        ", "\"\"\"Instantiate neural net module according to inputs.\"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "conv", "=", "Conv2dHeadModel", "(", "\n", "image_shape", "=", "image_shape", ",", "\n", "channels", "=", "channels", "or", "[", "16", ",", "32", "]", ",", "\n", "kernel_sizes", "=", "kernel_sizes", "or", "[", "8", ",", "4", "]", ",", "\n", "strides", "=", "strides", "or", "[", "4", ",", "2", "]", ",", "\n", "paddings", "=", "paddings", "or", "[", "0", ",", "1", "]", ",", "\n", "use_maxpool", "=", "use_maxpool", ",", "\n", "hidden_sizes", "=", "fc_sizes", ",", "# Applies nonlinearity at end.", "\n", ")", "\n", "self", ".", "pi", "=", "torch", ".", "nn", ".", "Linear", "(", "self", ".", "conv", ".", "output_size", ",", "output_size", ")", "\n", "self", ".", "value", "=", "torch", ".", "nn", ".", "Linear", "(", "self", ".", "conv", ".", "output_size", ",", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.pg.atari_ff_model.AtariFfModel.forward": [[40, 64], ["image.type", "img.mul_.mul_.mul_", "rlpyt.utils.tensor.infer_leading_dims", "atari_ff_model.AtariFfModel.conv", "torch.softmax", "torch.softmax", "atari_ff_model.AtariFfModel.value().squeeze", "rlpyt.utils.tensor.restore_leading_dims", "img.mul_.mul_.view", "atari_ff_model.AtariFfModel.pi", "atari_ff_model.AtariFfModel.value"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.utils.tensor.infer_leading_dims", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.tensor.restore_leading_dims", "home.repos.pwc.inspect_result.astooke_rlpyt.agents.dmc_sac_agent.SacAgent.pi", "home.repos.pwc.inspect_result.astooke_rlpyt.safe.cppo_agent.CppoLstmAgent.value"], ["", "def", "forward", "(", "self", ",", "image", ",", "prev_action", ",", "prev_reward", ")", ":", "\n", "        ", "\"\"\"\n        Compute action probabilities and value estimate from input state.\n        Infers leading dimensions of input: can be [T,B], [B], or []; provides\n        returns with same leading dims.  Convolution layers process as [T*B,\n        *image_shape], with T=1,B=1 when not given.  Expects uint8 images in\n        [0,255] and converts them to float32 in [0,1] (to minimize image data\n        storage and transfer).  Used in both sampler and in algorithm (both\n        via the agent).\n        \"\"\"", "\n", "img", "=", "image", ".", "type", "(", "torch", ".", "float", ")", "# Expect torch.uint8 inputs", "\n", "img", "=", "img", ".", "mul_", "(", "1.", "/", "255", ")", "# From [0-255] to [0-1], in place.", "\n", "\n", "# Infer (presence of) leading dimensions: [T,B], [B], or [].", "\n", "lead_dim", ",", "T", ",", "B", ",", "img_shape", "=", "infer_leading_dims", "(", "img", ",", "3", ")", "\n", "\n", "fc_out", "=", "self", ".", "conv", "(", "img", ".", "view", "(", "T", "*", "B", ",", "*", "img_shape", ")", ")", "\n", "pi", "=", "F", ".", "softmax", "(", "self", ".", "pi", "(", "fc_out", ")", ",", "dim", "=", "-", "1", ")", "\n", "v", "=", "self", ".", "value", "(", "fc_out", ")", ".", "squeeze", "(", "-", "1", ")", "\n", "\n", "# Restore leading dimensions: [T,B], [B], or [], as input.", "\n", "pi", ",", "v", "=", "restore_leading_dims", "(", "(", "pi", ",", "v", ")", ",", "lead_dim", ",", "T", ",", "B", ")", "\n", "\n", "return", "pi", ",", "v", "\n", "", "", ""]], "home.repos.pwc.inspect_result.astooke_rlpyt.pg.atari_lstm_model.AtariLstmModel.__init__": [[18, 44], ["super().__init__", "rlpyt.models.conv2d.Conv2dHeadModel", "torch.nn.LSTM", "torch.nn.LSTM", "torch.nn.LSTM", "torch.nn.LSTM", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.spaces.gym_wrapper.GymSpaceWrapper.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "image_shape", ",", "\n", "output_size", ",", "\n", "fc_sizes", "=", "512", ",", "# Between conv and lstm.", "\n", "lstm_size", "=", "512", ",", "\n", "use_maxpool", "=", "False", ",", "\n", "channels", "=", "None", ",", "# None uses default.", "\n", "kernel_sizes", "=", "None", ",", "\n", "strides", "=", "None", ",", "\n", "paddings", "=", "None", ",", "\n", ")", ":", "\n", "        ", "\"\"\"Instantiate neural net module according to inputs.\"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "conv", "=", "Conv2dHeadModel", "(", "\n", "image_shape", "=", "image_shape", ",", "\n", "channels", "=", "channels", "or", "[", "16", ",", "32", "]", ",", "\n", "kernel_sizes", "=", "kernel_sizes", "or", "[", "8", ",", "4", "]", ",", "\n", "strides", "=", "strides", "or", "[", "4", ",", "2", "]", ",", "\n", "paddings", "=", "paddings", "or", "[", "0", ",", "1", "]", ",", "\n", "use_maxpool", "=", "use_maxpool", ",", "\n", "hidden_sizes", "=", "fc_sizes", ",", "# Applies nonlinearity at end.", "\n", ")", "\n", "self", ".", "lstm", "=", "torch", ".", "nn", ".", "LSTM", "(", "self", ".", "conv", ".", "output_size", "+", "output_size", "+", "1", ",", "lstm_size", ")", "\n", "self", ".", "pi", "=", "torch", ".", "nn", ".", "Linear", "(", "lstm_size", ",", "output_size", ")", "\n", "self", ".", "value", "=", "torch", ".", "nn", ".", "Linear", "(", "lstm_size", ",", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.pg.atari_lstm_model.AtariLstmModel.forward": [[45, 79], ["image.type", "img.mul_.mul_.mul_", "rlpyt.utils.tensor.infer_leading_dims", "atari_lstm_model.AtariLstmModel.conv", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "atari_lstm_model.AtariLstmModel.lstm", "torch.softmax", "torch.softmax", "atari_lstm_model.AtariLstmModel.value().squeeze", "rlpyt.utils.tensor.restore_leading_dims", "RnnState", "img.mul_.mul_.view", "tuple", "atari_lstm_model.AtariLstmModel.pi", "atari_lstm_model.AtariLstmModel.view", "prev_action.view", "prev_reward.view", "lstm_out.view", "atari_lstm_model.AtariLstmModel.value", "lstm_out.view"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.utils.tensor.infer_leading_dims", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.tensor.restore_leading_dims", "home.repos.pwc.inspect_result.astooke_rlpyt.agents.dmc_sac_agent.SacAgent.pi", "home.repos.pwc.inspect_result.astooke_rlpyt.safe.cppo_agent.CppoLstmAgent.value"], ["", "def", "forward", "(", "self", ",", "image", ",", "prev_action", ",", "prev_reward", ",", "init_rnn_state", ")", ":", "\n", "        ", "\"\"\"\n        Compute action probabilities and value estimate from input state.\n        Infers leading dimensions of input: can be [T,B], [B], or []; provides\n        returns with same leading dims.  Convolution layers process as [T*B,\n        *image_shape], with T=1,B=1 when not given.  Expects uint8 images in\n        [0,255] and converts them to float32 in [0,1] (to minimize image data\n        storage and transfer).  Recurrent layers processed as [T,B,H]. Used in\n        both sampler and in algorithm (both via the agent).  Also returns the\n        next RNN state.\n        \"\"\"", "\n", "img", "=", "image", ".", "type", "(", "torch", ".", "float", ")", "# Expect torch.uint8 inputs", "\n", "img", "=", "img", ".", "mul_", "(", "1.", "/", "255", ")", "# From [0-255] to [0-1], in place.", "\n", "\n", "# Infer (presence of) leading dimensions: [T,B], [B], or [].", "\n", "lead_dim", ",", "T", ",", "B", ",", "img_shape", "=", "infer_leading_dims", "(", "img", ",", "3", ")", "\n", "\n", "fc_out", "=", "self", ".", "conv", "(", "img", ".", "view", "(", "T", "*", "B", ",", "*", "img_shape", ")", ")", "\n", "lstm_input", "=", "torch", ".", "cat", "(", "[", "\n", "fc_out", ".", "view", "(", "T", ",", "B", ",", "-", "1", ")", ",", "\n", "prev_action", ".", "view", "(", "T", ",", "B", ",", "-", "1", ")", ",", "# Assumed onehot.", "\n", "prev_reward", ".", "view", "(", "T", ",", "B", ",", "1", ")", ",", "\n", "]", ",", "dim", "=", "2", ")", "\n", "init_rnn_state", "=", "None", "if", "init_rnn_state", "is", "None", "else", "tuple", "(", "init_rnn_state", ")", "\n", "lstm_out", ",", "(", "hn", ",", "cn", ")", "=", "self", ".", "lstm", "(", "lstm_input", ",", "init_rnn_state", ")", "\n", "pi", "=", "F", ".", "softmax", "(", "self", ".", "pi", "(", "lstm_out", ".", "view", "(", "T", "*", "B", ",", "-", "1", ")", ")", ",", "dim", "=", "-", "1", ")", "\n", "v", "=", "self", ".", "value", "(", "lstm_out", ".", "view", "(", "T", "*", "B", ",", "-", "1", ")", ")", ".", "squeeze", "(", "-", "1", ")", "\n", "\n", "# Restore leading dimensions: [T,B], [B], or [], as input.", "\n", "pi", ",", "v", "=", "restore_leading_dims", "(", "(", "pi", ",", "v", ")", ",", "lead_dim", ",", "T", ",", "B", ")", "\n", "# Model should always leave B-dimension in rnn state: [N,B,H].", "\n", "next_rnn_state", "=", "RnnState", "(", "h", "=", "hn", ",", "c", "=", "cn", ")", "\n", "\n", "return", "pi", ",", "v", ",", "next_rnn_state", "\n", "", "", ""]], "home.repos.pwc.inspect_result.astooke_rlpyt.pg.mujoco_lstm_model.MujocoLstmModel.__init__": [[18, 48], ["super().__init__", "len", "int", "rlpyt.models.mlp.MlpModel", "torch.nn.LSTM", "torch.nn.Linear", "numpy.prod", "rlpyt.models.running_mean_std.RunningMeanStdModel"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.spaces.gym_wrapper.GymSpaceWrapper.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "observation_shape", ",", "\n", "action_size", ",", "\n", "hidden_sizes", "=", "None", ",", "# None for default (see below).", "\n", "lstm_size", "=", "256", ",", "\n", "nonlinearity", "=", "torch", ".", "nn", ".", "ReLU", ",", "\n", "normalize_observation", "=", "False", ",", "\n", "norm_obs_clip", "=", "10", ",", "\n", "norm_obs_var_clip", "=", "1e-6", ",", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "_obs_n_dim", "=", "len", "(", "observation_shape", ")", "\n", "self", ".", "_action_size", "=", "action_size", "\n", "hidden_sizes", "=", "hidden_sizes", "or", "[", "256", ",", "256", "]", "\n", "mlp_input_size", "=", "int", "(", "np", ".", "prod", "(", "observation_shape", ")", ")", "\n", "self", ".", "mlp", "=", "MlpModel", "(", "\n", "input_size", "=", "mlp_input_size", ",", "\n", "hidden_sizes", "=", "hidden_sizes", ",", "\n", "output_size", "=", "None", ",", "\n", "nonlinearity", "=", "nonlinearity", ",", "\n", ")", "\n", "mlp_output_size", "=", "hidden_sizes", "[", "-", "1", "]", "if", "hidden_sizes", "else", "mlp_input_size", "\n", "self", ".", "lstm", "=", "torch", ".", "nn", ".", "LSTM", "(", "mlp_output_size", "+", "action_size", "+", "1", ",", "lstm_size", ")", "\n", "self", ".", "head", "=", "torch", ".", "nn", ".", "Linear", "(", "lstm_size", ",", "action_size", "*", "2", "+", "1", ")", "\n", "if", "normalize_observation", ":", "\n", "            ", "self", ".", "obs_rms", "=", "RunningMeanStdModel", "(", "observation_shape", ")", "\n", "self", ".", "norm_obs_clip", "=", "norm_obs_clip", "\n", "self", ".", "norm_obs_var_clip", "=", "norm_obs_var_clip", "\n", "", "self", ".", "normalize_observation", "=", "normalize_observation", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.pg.mujoco_lstm_model.MujocoLstmModel.forward": [[51, 89], ["rlpyt.utils.tensor.infer_leading_dims", "mujoco_lstm_model.MujocoLstmModel.mlp", "torch.cat", "mujoco_lstm_model.MujocoLstmModel.lstm", "mujoco_lstm_model.MujocoLstmModel.head", "rlpyt.utils.tensor.restore_leading_dims", "RnnState", "torch.clamp", "torch.clamp.view", "tuple", "lstm_out.view", "torch.clamp", "mujoco_lstm_model.MujocoLstmModel.view", "prev_action.view", "prev_reward.view", "torch.clamp.sqrt"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.utils.tensor.infer_leading_dims", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.tensor.restore_leading_dims"], ["", "def", "forward", "(", "self", ",", "observation", ",", "prev_action", ",", "prev_reward", ",", "init_rnn_state", ")", ":", "\n", "        ", "\"\"\"\n        Compute mean, log_std, and value estimate from input state. Infer\n        leading dimensions of input: can be [T,B], [B], or []; provides\n        returns with same leading dims.  Intermediate feedforward layers\n        process as [T*B,H], and recurrent layers as [T,B,H], with T=1,B=1 when\n        not given. Used both in sampler and in algorithm (both via the agent).\n        Also returns the next RNN state.\n        \"\"\"", "\n", "# Infer (presence of) leading dimensions: [T,B], [B], or [].", "\n", "lead_dim", ",", "T", ",", "B", ",", "_", "=", "infer_leading_dims", "(", "observation", ",", "self", ".", "_obs_n_dim", ")", "\n", "\n", "if", "self", ".", "normalize_observation", ":", "\n", "            ", "obs_var", "=", "self", ".", "obs_rms", ".", "var", "\n", "if", "self", ".", "norm_obs_var_clip", "is", "not", "None", ":", "\n", "                ", "obs_var", "=", "torch", ".", "clamp", "(", "obs_var", ",", "min", "=", "self", ".", "norm_obs_var_clip", ")", "\n", "", "observation", "=", "torch", ".", "clamp", "(", "(", "observation", "-", "self", ".", "obs_rms", ".", "mean", ")", "/", "\n", "obs_var", ".", "sqrt", "(", ")", ",", "-", "self", ".", "norm_obs_clip", ",", "self", ".", "norm_obs_clip", ")", "\n", "\n", "", "mlp_out", "=", "self", ".", "mlp", "(", "observation", ".", "view", "(", "T", "*", "B", ",", "-", "1", ")", ")", "\n", "lstm_input", "=", "torch", ".", "cat", "(", "[", "\n", "mlp_out", ".", "view", "(", "T", ",", "B", ",", "-", "1", ")", ",", "\n", "prev_action", ".", "view", "(", "T", ",", "B", ",", "-", "1", ")", ",", "\n", "prev_reward", ".", "view", "(", "T", ",", "B", ",", "1", ")", ",", "\n", "]", ",", "dim", "=", "2", ")", "\n", "init_rnn_state", "=", "None", "if", "init_rnn_state", "is", "None", "else", "tuple", "(", "init_rnn_state", ")", "\n", "lstm_out", ",", "(", "hn", ",", "cn", ")", "=", "self", ".", "lstm", "(", "lstm_input", ",", "init_rnn_state", ")", "\n", "outputs", "=", "self", ".", "head", "(", "lstm_out", ".", "view", "(", "T", "*", "B", ",", "-", "1", ")", ")", "\n", "mu", "=", "outputs", "[", ":", ",", ":", "self", ".", "_action_size", "]", "\n", "log_std", "=", "outputs", "[", ":", ",", "self", ".", "_action_size", ":", "-", "1", "]", "\n", "v", "=", "outputs", "[", ":", ",", "-", "1", "]", "\n", "\n", "# Restore leading dimensions: [T,B], [B], or [], as input.", "\n", "mu", ",", "log_std", ",", "v", "=", "restore_leading_dims", "(", "(", "mu", ",", "log_std", ",", "v", ")", ",", "lead_dim", ",", "T", ",", "B", ")", "\n", "# Model should always leave B-dimension in rnn state: [N,B,H]", "\n", "next_rnn_state", "=", "RnnState", "(", "h", "=", "hn", ",", "c", "=", "cn", ")", "\n", "\n", "return", "mu", ",", "log_std", ",", "v", ",", "next_rnn_state", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.pg.mujoco_lstm_model.MujocoLstmModel.update_obs_rms": [[90, 93], ["mujoco_lstm_model.MujocoLstmModel.obs_rms.update"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.models.running_mean_std.RunningMeanStdModel.update"], ["", "def", "update_obs_rms", "(", "self", ",", "observation", ")", ":", "\n", "        ", "if", "self", ".", "normalize_observation", ":", "\n", "            ", "self", ".", "obs_rms", ".", "update", "(", "observation", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.astooke_rlpyt.pg.mujoco_ff_model.MujocoFfModel.__init__": [[17, 56], ["super().__init__", "len", "int", "rlpyt.models.mlp.MlpModel", "rlpyt.models.mlp.MlpModel", "torch.nn.Parameter", "numpy.prod", "torch.nn.Sequential", "rlpyt.models.running_mean_std.RunningMeanStdModel", "mu_nonlinearity", "torch.ones"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.spaces.gym_wrapper.GymSpaceWrapper.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "observation_shape", ",", "\n", "action_size", ",", "\n", "hidden_sizes", "=", "None", ",", "# None for default (see below).", "\n", "hidden_nonlinearity", "=", "torch", ".", "nn", ".", "Tanh", ",", "# Module form.", "\n", "mu_nonlinearity", "=", "torch", ".", "nn", ".", "Tanh", ",", "# Module form.", "\n", "init_log_std", "=", "0.", ",", "\n", "normalize_observation", "=", "False", ",", "\n", "norm_obs_clip", "=", "10", ",", "\n", "norm_obs_var_clip", "=", "1e-6", ",", "\n", ")", ":", "\n", "        ", "\"\"\"Instantiate neural net modules according to inputs.\"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "_obs_ndim", "=", "len", "(", "observation_shape", ")", "\n", "input_size", "=", "int", "(", "np", ".", "prod", "(", "observation_shape", ")", ")", "\n", "hidden_sizes", "=", "hidden_sizes", "or", "[", "64", ",", "64", "]", "\n", "mu_mlp", "=", "MlpModel", "(", "\n", "input_size", "=", "input_size", ",", "\n", "hidden_sizes", "=", "hidden_sizes", ",", "\n", "output_size", "=", "action_size", ",", "\n", "nonlinearity", "=", "hidden_nonlinearity", ",", "\n", ")", "\n", "if", "mu_nonlinearity", "is", "not", "None", ":", "\n", "            ", "self", ".", "mu", "=", "torch", ".", "nn", ".", "Sequential", "(", "mu_mlp", ",", "mu_nonlinearity", "(", ")", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "mu", "=", "mu_mlp", "\n", "", "self", ".", "v", "=", "MlpModel", "(", "\n", "input_size", "=", "input_size", ",", "\n", "hidden_sizes", "=", "hidden_sizes", ",", "\n", "output_size", "=", "1", ",", "\n", "nonlinearity", "=", "hidden_nonlinearity", ",", "\n", ")", "\n", "self", ".", "log_std", "=", "torch", ".", "nn", ".", "Parameter", "(", "init_log_std", "*", "torch", ".", "ones", "(", "action_size", ")", ")", "\n", "if", "normalize_observation", ":", "\n", "            ", "self", ".", "obs_rms", "=", "RunningMeanStdModel", "(", "observation_shape", ")", "\n", "self", ".", "norm_obs_clip", "=", "norm_obs_clip", "\n", "self", ".", "norm_obs_var_clip", "=", "norm_obs_var_clip", "\n", "", "self", ".", "normalize_observation", "=", "normalize_observation", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.pg.mujoco_ff_model.MujocoFfModel.forward": [[57, 84], ["rlpyt.utils.tensor.infer_leading_dims", "torch.clamp.view", "mujoco_ff_model.MujocoFfModel.mu", "mujoco_ff_model.MujocoFfModel.v().squeeze", "mujoco_ff_model.MujocoFfModel.log_std.repeat", "rlpyt.utils.tensor.restore_leading_dims", "torch.clamp", "torch.clamp", "mujoco_ff_model.MujocoFfModel.v", "torch.clamp.sqrt"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.utils.tensor.infer_leading_dims", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.tensor.restore_leading_dims", "home.repos.pwc.inspect_result.astooke_rlpyt.qpg.sac_v_agent.SacAgent.v"], ["", "def", "forward", "(", "self", ",", "observation", ",", "prev_action", ",", "prev_reward", ")", ":", "\n", "        ", "\"\"\"\n        Compute mean, log_std, and value estimate from input state. Infers\n        leading dimensions of input: can be [T,B], [B], or []; provides\n        returns with same leading dims.  Intermediate feedforward layers\n        process as [T*B,H], with T=1,B=1 when not given. Used both in sampler\n        and in algorithm (both via the agent).\n        \"\"\"", "\n", "# Infer (presence of) leading dimensions: [T,B], [B], or [].", "\n", "lead_dim", ",", "T", ",", "B", ",", "_", "=", "infer_leading_dims", "(", "observation", ",", "self", ".", "_obs_ndim", ")", "\n", "\n", "if", "self", ".", "normalize_observation", ":", "\n", "            ", "obs_var", "=", "self", ".", "obs_rms", ".", "var", "\n", "if", "self", ".", "norm_obs_var_clip", "is", "not", "None", ":", "\n", "                ", "obs_var", "=", "torch", ".", "clamp", "(", "obs_var", ",", "min", "=", "self", ".", "norm_obs_var_clip", ")", "\n", "", "observation", "=", "torch", ".", "clamp", "(", "(", "observation", "-", "self", ".", "obs_rms", ".", "mean", ")", "/", "\n", "obs_var", ".", "sqrt", "(", ")", ",", "-", "self", ".", "norm_obs_clip", ",", "self", ".", "norm_obs_clip", ")", "\n", "\n", "", "obs_flat", "=", "observation", ".", "view", "(", "T", "*", "B", ",", "-", "1", ")", "\n", "mu", "=", "self", ".", "mu", "(", "obs_flat", ")", "\n", "v", "=", "self", ".", "v", "(", "obs_flat", ")", ".", "squeeze", "(", "-", "1", ")", "\n", "log_std", "=", "self", ".", "log_std", ".", "repeat", "(", "T", "*", "B", ",", "1", ")", "\n", "\n", "# Restore leading dimensions: [T,B], [B], or [], as input.", "\n", "mu", ",", "log_std", ",", "v", "=", "restore_leading_dims", "(", "(", "mu", ",", "log_std", ",", "v", ")", ",", "lead_dim", ",", "T", ",", "B", ")", "\n", "\n", "return", "mu", ",", "log_std", ",", "v", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.pg.mujoco_ff_model.MujocoFfModel.update_obs_rms": [[85, 88], ["mujoco_ff_model.MujocoFfModel.obs_rms.update"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.models.running_mean_std.RunningMeanStdModel.update"], ["", "def", "update_obs_rms", "(", "self", ",", "observation", ")", ":", "\n", "        ", "if", "self", ".", "normalize_observation", ":", "\n", "            ", "self", ".", "obs_rms", ".", "update", "(", "observation", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.astooke_rlpyt.dqn.dqn.DQN.__init__": [[28, 76], ["int", "int", "int", "int", "rlpyt.utils.quick_args.save__init__args", "dict", "locals"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.utils.quick_args.save__init__args"], ["def", "__init__", "(", "\n", "self", ",", "\n", "discount", "=", "0.99", ",", "\n", "batch_size", "=", "32", ",", "\n", "min_steps_learn", "=", "int", "(", "5e4", ")", ",", "\n", "delta_clip", "=", "1.", ",", "\n", "replay_size", "=", "int", "(", "1e6", ")", ",", "\n", "replay_ratio", "=", "8", ",", "# data_consumption / data_generation.", "\n", "target_update_tau", "=", "1", ",", "\n", "target_update_interval", "=", "312", ",", "# 312 * 32 = 1e4 env steps.", "\n", "n_step_return", "=", "1", ",", "\n", "learning_rate", "=", "2.5e-4", ",", "\n", "OptimCls", "=", "torch", ".", "optim", ".", "Adam", ",", "\n", "optim_kwargs", "=", "None", ",", "\n", "initial_optim_state_dict", "=", "None", ",", "\n", "clip_grad_norm", "=", "10.", ",", "\n", "# eps_init=1,  # NOW IN AGENT.", "\n", "# eps_final=0.01,", "\n", "# eps_final_min=None,  # set < eps_final to use vector-valued eps.", "\n", "# eps_eval=0.001,", "\n", "eps_steps", "=", "int", "(", "1e6", ")", ",", "# STILL IN ALGO (to convert to itr).", "\n", "double_dqn", "=", "False", ",", "\n", "prioritized_replay", "=", "False", ",", "\n", "pri_alpha", "=", "0.6", ",", "\n", "pri_beta_init", "=", "0.4", ",", "\n", "pri_beta_final", "=", "1.", ",", "\n", "pri_beta_steps", "=", "int", "(", "50e6", ")", ",", "\n", "default_priority", "=", "None", ",", "\n", "ReplayBufferCls", "=", "None", ",", "# Leave None to select by above options.", "\n", "updates_per_sync", "=", "1", ",", "# For async mode only.", "\n", ")", ":", "\n", "        ", "\"\"\"Saves input arguments.  \n\n        ``delta_clip`` selects the Huber loss; if ``None``, uses MSE.\n\n        ``replay_ratio`` determines the ratio of data-consumption\n        to data-generation.  For example, original DQN sampled 4 environment steps between\n        each training update with batch-size 32, for a replay ratio of 8.\n\n        \"\"\"", "\n", "if", "optim_kwargs", "is", "None", ":", "\n", "            ", "optim_kwargs", "=", "dict", "(", "eps", "=", "0.01", "/", "batch_size", ")", "\n", "", "if", "default_priority", "is", "None", ":", "\n", "            ", "default_priority", "=", "delta_clip", "\n", "", "self", ".", "_batch_size", "=", "batch_size", "\n", "del", "batch_size", "# Property.", "\n", "save__init__args", "(", "locals", "(", ")", ")", "\n", "self", ".", "update_counter", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.dqn.dqn.DQN.initialize": [[77, 98], ["max", "rlpyt.utils.logging.logger.log", "int", "max", "agent.set_epsilon_itr_min_max", "dqn.DQN.initialize_replay_buffer", "dqn.DQN.optim_initialize", "round", "int"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.logging.console.log", "home.repos.pwc.inspect_result.astooke_rlpyt.dqn.epsilon_greedy.EpsilonGreedyAgentMixin.set_epsilon_itr_min_max", "home.repos.pwc.inspect_result.astooke_rlpyt.rl_with_ul.ppo_with_ul.PpoUl.initialize_replay_buffer", "home.repos.pwc.inspect_result.astooke_rlpyt.rl_with_ul.sac_with_ul.SacWithUl.optim_initialize"], ["", "def", "initialize", "(", "self", ",", "agent", ",", "n_itr", ",", "batch_spec", ",", "mid_batch_reset", ",", "examples", ",", "\n", "world_size", "=", "1", ",", "rank", "=", "0", ")", ":", "\n", "        ", "\"\"\"Stores input arguments and initializes replay buffer and optimizer.\n        Use in non-async runners.  Computes number of gradient updates per\n        optimization iteration as `(replay_ratio * sampler-batch-size /\n        training-batch_size)`.\"\"\"", "\n", "self", ".", "agent", "=", "agent", "\n", "self", ".", "n_itr", "=", "n_itr", "\n", "self", ".", "sampler_bs", "=", "sampler_bs", "=", "batch_spec", ".", "size", "\n", "self", ".", "mid_batch_reset", "=", "mid_batch_reset", "\n", "self", ".", "updates_per_optimize", "=", "max", "(", "1", ",", "round", "(", "self", ".", "replay_ratio", "*", "sampler_bs", "/", "\n", "self", ".", "batch_size", ")", ")", "\n", "logger", ".", "log", "(", "f\"From sampler batch size {batch_spec.size}, training \"", "\n", "f\"batch size {self.batch_size}, and replay ratio \"", "\n", "f\"{self.replay_ratio}, computed {self.updates_per_optimize} \"", "\n", "f\"updates per iteration.\"", ")", "\n", "self", ".", "min_itr_learn", "=", "int", "(", "self", ".", "min_steps_learn", "//", "sampler_bs", ")", "\n", "eps_itr_max", "=", "max", "(", "1", ",", "int", "(", "self", ".", "eps_steps", "//", "sampler_bs", ")", ")", "\n", "agent", ".", "set_epsilon_itr_min_max", "(", "self", ".", "min_itr_learn", ",", "eps_itr_max", ")", "\n", "self", ".", "initialize_replay_buffer", "(", "examples", ",", "batch_spec", ")", "\n", "self", ".", "optim_initialize", "(", "rank", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.dqn.dqn.DQN.async_initialize": [[99, 114], ["dqn.DQN.initialize_replay_buffer", "int", "max", "agent.set_epsilon_itr_min_max", "int"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.rl_with_ul.ppo_with_ul.PpoUl.initialize_replay_buffer", "home.repos.pwc.inspect_result.astooke_rlpyt.dqn.epsilon_greedy.EpsilonGreedyAgentMixin.set_epsilon_itr_min_max"], ["", "def", "async_initialize", "(", "self", ",", "agent", ",", "sampler_n_itr", ",", "batch_spec", ",", "mid_batch_reset", ",", "\n", "examples", ",", "world_size", "=", "1", ")", ":", "\n", "        ", "\"\"\"Used in async runner only; returns replay buffer allocated in shared\n        memory, does not instantiate optimizer. \"\"\"", "\n", "self", ".", "agent", "=", "agent", "\n", "self", ".", "n_itr", "=", "sampler_n_itr", "\n", "self", ".", "initialize_replay_buffer", "(", "examples", ",", "batch_spec", ",", "async_", "=", "True", ")", "\n", "self", ".", "mid_batch_reset", "=", "mid_batch_reset", "\n", "self", ".", "sampler_bs", "=", "sampler_bs", "=", "batch_spec", ".", "size", "\n", "self", ".", "updates_per_optimize", "=", "self", ".", "updates_per_sync", "\n", "self", ".", "min_itr_learn", "=", "int", "(", "self", ".", "min_steps_learn", "//", "sampler_bs", ")", "\n", "eps_itr_max", "=", "max", "(", "1", ",", "int", "(", "self", ".", "eps_steps", "//", "sampler_bs", ")", ")", "\n", "# Before any forking so all sub processes have epsilon schedule:", "\n", "agent", ".", "set_epsilon_itr_min_max", "(", "self", ".", "min_itr_learn", ",", "eps_itr_max", ")", "\n", "return", "self", ".", "replay_buffer", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.dqn.dqn.DQN.optim_initialize": [[115, 124], ["dqn.DQN.OptimCls", "dqn.DQN.agent.parameters", "dqn.DQN.optimizer.load_state_dict", "max"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.rl.atari_rl_models.AtariDqnModel.parameters", "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.augmented_temporal_similarity.AugmentedTemporalSimilarity.load_state_dict"], ["", "def", "optim_initialize", "(", "self", ",", "rank", "=", "0", ")", ":", "\n", "        ", "\"\"\"Called in initilize or by async runner after forking sampler.\"\"\"", "\n", "self", ".", "rank", "=", "rank", "\n", "self", ".", "optimizer", "=", "self", ".", "OptimCls", "(", "self", ".", "agent", ".", "parameters", "(", ")", ",", "\n", "lr", "=", "self", ".", "learning_rate", ",", "**", "self", ".", "optim_kwargs", ")", "\n", "if", "self", ".", "initial_optim_state_dict", "is", "not", "None", ":", "\n", "            ", "self", ".", "optimizer", ".", "load_state_dict", "(", "self", ".", "initial_optim_state_dict", ")", "\n", "", "if", "self", ".", "prioritized_replay", ":", "\n", "            ", "self", ".", "pri_beta_itr", "=", "max", "(", "1", ",", "self", ".", "pri_beta_steps", "//", "self", ".", "sampler_bs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.dqn.dqn.DQN.initialize_replay_buffer": [[125, 157], ["dqn.DQN.examples_to_buffer", "dict", "ReplayCls", "dict.update", "rlpyt.utils.logging.logger.log", "dict"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.rl_with_ul.ppo_with_ul.PpoUl.examples_to_buffer", "home.repos.pwc.inspect_result.astooke_rlpyt.models.running_mean_std.RunningMeanStdModel.update", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.console.log"], ["", "", "def", "initialize_replay_buffer", "(", "self", ",", "examples", ",", "batch_spec", ",", "async_", "=", "False", ")", ":", "\n", "        ", "\"\"\"\n        Allocates replay buffer using examples and with the fields in `SamplesToBuffer`\n        namedarraytuple.  Uses frame-wise buffers, so that only unique frames are stored,\n        using less memory (usual observations are 4 most recent frames, with only newest\n        frame distince from previous observation).\n        \"\"\"", "\n", "example_to_buffer", "=", "self", ".", "examples_to_buffer", "(", "examples", ")", "\n", "replay_kwargs", "=", "dict", "(", "\n", "example", "=", "example_to_buffer", ",", "\n", "size", "=", "self", ".", "replay_size", ",", "\n", "B", "=", "batch_spec", ".", "B", ",", "\n", "discount", "=", "self", ".", "discount", ",", "\n", "n_step_return", "=", "self", ".", "n_step_return", ",", "\n", ")", "\n", "if", "self", ".", "prioritized_replay", ":", "\n", "            ", "replay_kwargs", ".", "update", "(", "dict", "(", "\n", "alpha", "=", "self", ".", "pri_alpha", ",", "\n", "beta", "=", "self", ".", "pri_beta_init", ",", "\n", "default_priority", "=", "self", ".", "default_priority", ",", "\n", ")", ")", "\n", "ReplayCls", "=", "(", "AsyncPrioritizedReplayFrameBuffer", "if", "async_", "else", "\n", "PrioritizedReplayFrameBuffer", ")", "\n", "", "else", ":", "\n", "            ", "ReplayCls", "=", "(", "AsyncUniformReplayFrameBuffer", "if", "async_", "else", "\n", "UniformReplayFrameBuffer", ")", "\n", "", "if", "self", ".", "ReplayBufferCls", "is", "not", "None", ":", "\n", "            ", "ReplayCls", "=", "self", ".", "ReplayBufferCls", "\n", "logger", ".", "log", "(", "f\"WARNING: ignoring internal selection logic and using\"", "\n", "f\" input replay buffer class: {ReplayCls} -- compatibility not\"", "\n", "\" guaranteed.\"", ")", "\n", "", "self", ".", "replay_buffer", "=", "ReplayCls", "(", "**", "replay_kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.dqn.dqn.DQN.optimize_agent": [[158, 191], ["OptInfo", "range", "dqn.DQN.update_itr_hyperparams", "dqn.DQN.samples_to_buffer", "dqn.DQN.replay_buffer.append_samples", "dqn.DQN.replay_buffer.sample_batch", "dqn.DQN.optimizer.zero_grad", "dqn.DQN.loss", "loss.backward", "torch.nn.utils.clip_grad_norm_", "dqn.DQN.optimizer.step", "OptInfo.loss.append", "OptInfo.gradNorm.append", "OptInfo.tdAbsErr.extend", "dqn.DQN.agent.parameters", "dqn.DQN.replay_buffer.update_batch_priorities", "loss.item", "torch.tensor().item", "td_abs_errors[].numpy", "dqn.DQN.agent.update_target", "range", "torch.tensor", "len"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.rl_with_ul.dqn_with_ul.DqnUl.update_itr_hyperparams", "home.repos.pwc.inspect_result.astooke_rlpyt.rl_with_ul.ppo_with_ul.PpoUl.samples_to_buffer", "home.repos.pwc.inspect_result.astooke_rlpyt.sequence.prioritized.PrioritizedSequenceReplay.append_samples", "home.repos.pwc.inspect_result.astooke_rlpyt.sequence.uniform.UniformSequenceReplay.sample_batch", "home.repos.pwc.inspect_result.astooke_rlpyt.safe.cppo_pid.CppoPID.loss", "home.repos.pwc.inspect_result.astooke_rlpyt.models.utils.ScaleGrad.backward", "home.repos.pwc.inspect_result.astooke_rlpyt.safe.safety_gym_env.SafetyGymTrajInfo.step", "home.repos.pwc.inspect_result.astooke_rlpyt.rl.atari_rl_models.AtariDqnModel.parameters", "home.repos.pwc.inspect_result.astooke_rlpyt.sequence.prioritized.PrioritizedSequenceReplay.update_batch_priorities", "home.repos.pwc.inspect_result.astooke_rlpyt.agents.atari_dqn_agent.AtariDqnAgent.update_target"], ["", "def", "optimize_agent", "(", "self", ",", "itr", ",", "samples", "=", "None", ",", "sampler_itr", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Extracts the needed fields from input samples and stores them in the \n        replay buffer.  Then samples from the replay buffer to train the agent\n        by gradient updates (with the number of updates determined by replay\n        ratio, sampler batch size, and training batch size).  If using prioritized\n        replay, updates the priorities for sampled training batches.\n        \"\"\"", "\n", "itr", "=", "itr", "if", "sampler_itr", "is", "None", "else", "sampler_itr", "# Async uses sampler_itr.", "\n", "if", "samples", "is", "not", "None", ":", "\n", "            ", "samples_to_buffer", "=", "self", ".", "samples_to_buffer", "(", "samples", ")", "\n", "self", ".", "replay_buffer", ".", "append_samples", "(", "samples_to_buffer", ")", "\n", "", "opt_info", "=", "OptInfo", "(", "*", "(", "[", "]", "for", "_", "in", "range", "(", "len", "(", "OptInfo", ".", "_fields", ")", ")", ")", ")", "\n", "if", "itr", "<", "self", ".", "min_itr_learn", ":", "\n", "            ", "return", "opt_info", "\n", "", "for", "_", "in", "range", "(", "self", ".", "updates_per_optimize", ")", ":", "\n", "            ", "samples_from_replay", "=", "self", ".", "replay_buffer", ".", "sample_batch", "(", "self", ".", "batch_size", ")", "\n", "self", ".", "optimizer", ".", "zero_grad", "(", ")", "\n", "loss", ",", "td_abs_errors", "=", "self", ".", "loss", "(", "samples_from_replay", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "grad_norm", "=", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "\n", "self", ".", "agent", ".", "parameters", "(", ")", ",", "self", ".", "clip_grad_norm", ")", "\n", "self", ".", "optimizer", ".", "step", "(", ")", "\n", "if", "self", ".", "prioritized_replay", ":", "\n", "                ", "self", ".", "replay_buffer", ".", "update_batch_priorities", "(", "td_abs_errors", ")", "\n", "", "opt_info", ".", "loss", ".", "append", "(", "loss", ".", "item", "(", ")", ")", "\n", "opt_info", ".", "gradNorm", ".", "append", "(", "torch", ".", "tensor", "(", "grad_norm", ")", ".", "item", "(", ")", ")", "# backwards compatible", "\n", "opt_info", ".", "tdAbsErr", ".", "extend", "(", "td_abs_errors", "[", ":", ":", "8", "]", ".", "numpy", "(", ")", ")", "# Downsample.", "\n", "self", ".", "update_counter", "+=", "1", "\n", "if", "self", ".", "update_counter", "%", "self", ".", "target_update_interval", "==", "0", ":", "\n", "                ", "self", ".", "agent", ".", "update_target", "(", "self", ".", "target_update_tau", ")", "\n", "", "", "self", ".", "update_itr_hyperparams", "(", "itr", ")", "\n", "return", "opt_info", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.dqn.dqn.DQN.examples_to_buffer": [[192, 198], ["SamplesToBuffer"], "methods", ["None"], ["", "def", "examples_to_buffer", "(", "self", ",", "examples", ")", ":", "\n", "        ", "return", "SamplesToBuffer", "(", "\n", "observation", "=", "examples", "[", "\"observation\"", "]", ",", "\n", "action", "=", "examples", "[", "\"action\"", "]", ",", "\n", "reward", "=", "examples", "[", "\"reward\"", "]", ",", "\n", "done", "=", "examples", "[", "\"done\"", "]", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.dqn.dqn.DQN.samples_to_buffer": [[200, 209], ["SamplesToBuffer"], "methods", ["None"], ["", "def", "samples_to_buffer", "(", "self", ",", "samples", ")", ":", "\n", "        ", "\"\"\"Defines how to add data from sampler into the replay buffer. Called\n        in optimize_agent() if samples are provided to that method.  In \n        asynchronous mode, will be called in the memory_copier process.\"\"\"", "\n", "return", "SamplesToBuffer", "(", "\n", "observation", "=", "samples", ".", "env", ".", "observation", ",", "\n", "action", "=", "samples", ".", "agent", ".", "action", ",", "\n", "reward", "=", "samples", ".", "env", ".", "reward", ",", "\n", "done", "=", "samples", ".", "env", ".", "done", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.dqn.dqn.DQN.loss": [[211, 266], ["dqn.DQN.agent", "rlpyt.utils.tensor.select_at_indexes", "abs", "abs.detach", "torch.no_grad", "dqn.DQN.agent.target", "torch.where", "torch.clamp", "torch.mean", "dqn.DQN.agent", "torch.argmax", "rlpyt.utils.tensor.select_at_indexes", "torch.max", "samples.done_n.float"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.utils.tensor.select_at_indexes", "home.repos.pwc.inspect_result.astooke_rlpyt.agents.atari_dqn_agent.AtariDqnAgent.target", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.tensor.select_at_indexes"], ["", "def", "loss", "(", "self", ",", "samples", ")", ":", "\n", "        ", "\"\"\"\n        Computes the Q-learning loss, based on: 0.5 * (Q - target_Q) ^ 2.\n        Implements regular DQN or Double-DQN for computing target_Q values\n        using the agent's target network.  Computes the Huber loss using \n        ``delta_clip``, or if ``None``, uses MSE.  When using prioritized\n        replay, multiplies losses by importance sample weights.\n\n        Input ``samples`` have leading batch dimension [B,..] (but not time).\n\n        Calls the agent to compute forward pass on training inputs, and calls\n        ``agent.target()`` to compute target values.\n\n        Returns loss and TD-absolute-errors for use in prioritization.\n\n        Warning: \n            If not using mid_batch_reset, the sampler will only reset environments\n            between iterations, so some samples in the replay buffer will be\n            invalid.  This case is not supported here currently.\n        \"\"\"", "\n", "qs", "=", "self", ".", "agent", "(", "*", "samples", ".", "agent_inputs", ")", "\n", "q", "=", "select_at_indexes", "(", "samples", ".", "action", ",", "qs", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "target_qs", "=", "self", ".", "agent", ".", "target", "(", "*", "samples", ".", "target_inputs", ")", "\n", "if", "self", ".", "double_dqn", ":", "\n", "                ", "next_qs", "=", "self", ".", "agent", "(", "*", "samples", ".", "target_inputs", ")", "\n", "next_a", "=", "torch", ".", "argmax", "(", "next_qs", ",", "dim", "=", "-", "1", ")", "\n", "target_q", "=", "select_at_indexes", "(", "next_a", ",", "target_qs", ")", "\n", "", "else", ":", "\n", "                ", "target_q", "=", "torch", ".", "max", "(", "target_qs", ",", "dim", "=", "-", "1", ")", ".", "values", "\n", "", "", "disc_target_q", "=", "(", "self", ".", "discount", "**", "self", ".", "n_step_return", ")", "*", "target_q", "\n", "y", "=", "samples", ".", "return_", "+", "(", "1", "-", "samples", ".", "done_n", ".", "float", "(", ")", ")", "*", "disc_target_q", "\n", "delta", "=", "y", "-", "q", "\n", "losses", "=", "0.5", "*", "delta", "**", "2", "\n", "abs_delta", "=", "abs", "(", "delta", ")", "\n", "if", "self", ".", "delta_clip", "is", "not", "None", ":", "# Huber loss.", "\n", "            ", "b", "=", "self", ".", "delta_clip", "*", "(", "abs_delta", "-", "self", ".", "delta_clip", "/", "2", ")", "\n", "losses", "=", "torch", ".", "where", "(", "abs_delta", "<=", "self", ".", "delta_clip", ",", "losses", ",", "b", ")", "\n", "", "if", "self", ".", "prioritized_replay", ":", "\n", "            ", "losses", "*=", "samples", ".", "is_weights", "\n", "", "td_abs_errors", "=", "abs_delta", ".", "detach", "(", ")", "\n", "if", "self", ".", "delta_clip", "is", "not", "None", ":", "\n", "            ", "td_abs_errors", "=", "torch", ".", "clamp", "(", "td_abs_errors", ",", "0", ",", "self", ".", "delta_clip", ")", "\n", "", "if", "not", "self", ".", "mid_batch_reset", ":", "\n", "# FIXME: I think this is wrong, because the first \"done\" sample", "\n", "# is valid, but here there is no [T] dim, so there's no way to", "\n", "# know if a \"done\" sample is the first \"done\" in the sequence.", "\n", "            ", "raise", "NotImplementedError", "\n", "# valid = valid_from_done(samples.done)", "\n", "# loss = valid_mean(losses, valid)", "\n", "# td_abs_errors *= valid", "\n", "", "else", ":", "\n", "            ", "loss", "=", "torch", ".", "mean", "(", "losses", ")", "\n", "\n", "", "return", "loss", ",", "td_abs_errors", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.dqn.dqn.DQN.update_itr_hyperparams": [[267, 280], ["min", "dqn.DQN.replay_buffer.set_beta", "max"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.sequence.prioritized.PrioritizedSequenceReplay.set_beta"], ["", "def", "update_itr_hyperparams", "(", "self", ",", "itr", ")", ":", "\n", "# EPS NOW IN AGENT.", "\n", "# if itr <= self.eps_itr:  # Epsilon can be vector-valued.", "\n", "#     prog = min(1, max(0, itr - self.min_itr_learn) /", "\n", "#       (self.eps_itr - self.min_itr_learn))", "\n", "#     new_eps = prog * self.eps_final + (1 - prog) * self.eps_init", "\n", "#     self.agent.set_sample_epsilon_greedy(new_eps)", "\n", "        ", "if", "self", ".", "prioritized_replay", "and", "itr", "<=", "self", ".", "pri_beta_itr", ":", "\n", "            ", "prog", "=", "min", "(", "1", ",", "max", "(", "0", ",", "itr", "-", "self", ".", "min_itr_learn", ")", "/", "\n", "(", "self", ".", "pri_beta_itr", "-", "self", ".", "min_itr_learn", ")", ")", "\n", "new_beta", "=", "(", "prog", "*", "self", ".", "pri_beta_final", "+", "\n", "(", "1", "-", "prog", ")", "*", "self", ".", "pri_beta_init", ")", "\n", "self", ".", "replay_buffer", ".", "set_beta", "(", "new_beta", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.astooke_rlpyt.dqn.cat_dqn.CategoricalDQN.__init__": [[16, 24], ["rlpyt.algos.dqn.dqn.DQN.__init__"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.spaces.gym_wrapper.GymSpaceWrapper.__init__"], ["def", "__init__", "(", "self", ",", "V_min", "=", "-", "10", ",", "V_max", "=", "10", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"Standard __init__() plus Q-value limits; the agent configures\n        the number of atoms (bins).\"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "self", ".", "V_min", "=", "V_min", "\n", "self", ".", "V_max", "=", "V_max", "\n", "if", "\"eps\"", "not", "in", "self", ".", "optim_kwargs", ":", "# Assume optim.Adam", "\n", "            ", "self", ".", "optim_kwargs", "[", "\"eps\"", "]", "=", "0.01", "/", "self", ".", "batch_size", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.dqn.cat_dqn.CategoricalDQN.initialize": [[25, 28], ["super().initialize", "cat_dqn.CategoricalDQN.agent.give_V_min_max"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.safe.cppo_agent.CppoLstmAgent.initialize", "home.repos.pwc.inspect_result.astooke_rlpyt.dqn.catdqn_agent.CatDqnAgent.give_V_min_max"], ["", "", "def", "initialize", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "initialize", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "self", ".", "agent", ".", "give_V_min_max", "(", "self", ".", "V_min", ",", "self", ".", "V_max", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.dqn.cat_dqn.CategoricalDQN.async_initialize": [[29, 33], ["super().async_initialize", "cat_dqn.CategoricalDQN.agent.give_V_min_max"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.rl_with_ul.sac_with_ul.SacWithUl.async_initialize", "home.repos.pwc.inspect_result.astooke_rlpyt.dqn.catdqn_agent.CatDqnAgent.give_V_min_max"], ["", "def", "async_initialize", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "buffer", "=", "super", "(", ")", ".", "async_initialize", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "self", ".", "agent", ".", "give_V_min_max", "(", "self", ".", "V_min", ",", "self", ".", "V_max", ")", "\n", "return", "buffer", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.dqn.cat_dqn.CategoricalDQN.loss": [[34, 94], ["torch.linspace", "torch.ger", "samples.return_.unsqueeze", "torch.clamp", "torch.linspace.view", "torch.clamp.unsqueeze", "torch.clamp", "cat_dqn.CategoricalDQN.agent", "rlpyt.utils.tensor.select_at_indexes", "torch.clamp", "torch.clamp", "torch.sum", "torch.clamp", "abs", "torch.no_grad", "cat_dqn.CategoricalDQN.agent.target", "rlpyt.utils.tensor.select_at_indexes", "target_p_unproj.unsqueeze.unsqueeze.unsqueeze", "torch.sum", "rlpyt.algos.utils.valid_from_done", "rlpyt.utils.tensor.valid_mean", "torch.mean", "samples.done_n.float", "cat_dqn.CategoricalDQN.agent", "torch.tensordot", "torch.argmax", "torch.tensordot", "torch.argmax", "torch.log", "torch.log", "torch.log", "torch.clamp.detach"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.utils.tensor.select_at_indexes", "home.repos.pwc.inspect_result.astooke_rlpyt.agents.atari_dqn_agent.AtariDqnAgent.target", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.tensor.select_at_indexes", "home.repos.pwc.inspect_result.astooke_rlpyt.algos.utils.valid_from_done", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.tensor.valid_mean", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.console.log", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.console.log", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.console.log"], ["", "def", "loss", "(", "self", ",", "samples", ")", ":", "\n", "        ", "\"\"\"\n        Computes the Distributional Q-learning loss, based on projecting the\n        discounted rewards + target Q-distribution into the current Q-domain,\n        with cross-entropy loss.  \n\n        Returns loss and KL-divergence-errors for use in prioritization.\n        \"\"\"", "\n", "\n", "delta_z", "=", "(", "self", ".", "V_max", "-", "self", ".", "V_min", ")", "/", "(", "self", ".", "agent", ".", "n_atoms", "-", "1", ")", "\n", "z", "=", "torch", ".", "linspace", "(", "self", ".", "V_min", ",", "self", ".", "V_max", ",", "self", ".", "agent", ".", "n_atoms", ")", "\n", "# Makde 2-D tensor of contracted z_domain for each data point,", "\n", "# with zeros where next value should not be added.", "\n", "next_z", "=", "z", "*", "(", "self", ".", "discount", "**", "self", ".", "n_step_return", ")", "# [P']", "\n", "next_z", "=", "torch", ".", "ger", "(", "1", "-", "samples", ".", "done_n", ".", "float", "(", ")", ",", "next_z", ")", "# [B,P']", "\n", "ret", "=", "samples", ".", "return_", ".", "unsqueeze", "(", "1", ")", "# [B,1]", "\n", "next_z", "=", "torch", ".", "clamp", "(", "ret", "+", "next_z", ",", "self", ".", "V_min", ",", "self", ".", "V_max", ")", "# [B,P']", "\n", "\n", "z_bc", "=", "z", ".", "view", "(", "1", ",", "-", "1", ",", "1", ")", "# [1,P,1]", "\n", "next_z_bc", "=", "next_z", ".", "unsqueeze", "(", "1", ")", "# [B,1,P']", "\n", "abs_diff_on_delta", "=", "abs", "(", "next_z_bc", "-", "z_bc", ")", "/", "delta_z", "\n", "projection_coeffs", "=", "torch", ".", "clamp", "(", "1", "-", "abs_diff_on_delta", ",", "0", ",", "1", ")", "# Most 0.", "\n", "# projection_coeffs is a 3-D tensor: [B,P,P']", "\n", "# dim-0: independent data entries", "\n", "# dim-1: base_z atoms (remains after projection)", "\n", "# dim-2: next_z atoms (summed in projection)", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "target_ps", "=", "self", ".", "agent", ".", "target", "(", "*", "samples", ".", "target_inputs", ")", "# [B,A,P']", "\n", "if", "self", ".", "double_dqn", ":", "\n", "                ", "next_ps", "=", "self", ".", "agent", "(", "*", "samples", ".", "target_inputs", ")", "# [B,A,P']", "\n", "next_qs", "=", "torch", ".", "tensordot", "(", "next_ps", ",", "z", ",", "dims", "=", "1", ")", "# [B,A]", "\n", "next_a", "=", "torch", ".", "argmax", "(", "next_qs", ",", "dim", "=", "-", "1", ")", "# [B]", "\n", "", "else", ":", "\n", "                ", "target_qs", "=", "torch", ".", "tensordot", "(", "target_ps", ",", "z", ",", "dims", "=", "1", ")", "# [B,A]", "\n", "next_a", "=", "torch", ".", "argmax", "(", "target_qs", ",", "dim", "=", "-", "1", ")", "# [B]", "\n", "", "target_p_unproj", "=", "select_at_indexes", "(", "next_a", ",", "target_ps", ")", "# [B,P']", "\n", "target_p_unproj", "=", "target_p_unproj", ".", "unsqueeze", "(", "1", ")", "# [B,1,P']", "\n", "target_p", "=", "(", "target_p_unproj", "*", "projection_coeffs", ")", ".", "sum", "(", "-", "1", ")", "# [B,P]", "\n", "", "ps", "=", "self", ".", "agent", "(", "*", "samples", ".", "agent_inputs", ")", "# [B,A,P]", "\n", "p", "=", "select_at_indexes", "(", "samples", ".", "action", ",", "ps", ")", "# [B,P]", "\n", "p", "=", "torch", ".", "clamp", "(", "p", ",", "EPS", ",", "1", ")", "# NaN-guard.", "\n", "losses", "=", "-", "torch", ".", "sum", "(", "target_p", "*", "torch", ".", "log", "(", "p", ")", ",", "dim", "=", "1", ")", "# Cross-entropy.", "\n", "\n", "if", "self", ".", "prioritized_replay", ":", "\n", "            ", "losses", "*=", "samples", ".", "is_weights", "\n", "\n", "", "target_p", "=", "torch", ".", "clamp", "(", "target_p", ",", "EPS", ",", "1", ")", "\n", "KL_div", "=", "torch", ".", "sum", "(", "target_p", "*", "\n", "(", "torch", ".", "log", "(", "target_p", ")", "-", "torch", ".", "log", "(", "p", ".", "detach", "(", ")", ")", ")", ",", "dim", "=", "1", ")", "\n", "KL_div", "=", "torch", ".", "clamp", "(", "KL_div", ",", "EPS", ",", "1", "/", "EPS", ")", "# Avoid <0 from NaN-guard.", "\n", "\n", "if", "not", "self", ".", "mid_batch_reset", ":", "\n", "            ", "valid", "=", "valid_from_done", "(", "samples", ".", "done", ")", "\n", "loss", "=", "valid_mean", "(", "losses", ",", "valid", ")", "\n", "KL_div", "*=", "valid", "\n", "", "else", ":", "\n", "            ", "loss", "=", "torch", ".", "mean", "(", "losses", ")", "\n", "\n", "", "return", "loss", ",", "KL_div", "\n", "", "", ""]], "home.repos.pwc.inspect_result.astooke_rlpyt.dqn.r2d1.R2D1.__init__": [[30, 85], ["int", "int", "int", "int", "rlpyt.utils.quick_args.save__init__args", "dict", "locals"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.utils.quick_args.save__init__args"], ["def", "__init__", "(", "\n", "self", ",", "\n", "discount", "=", "0.997", ",", "\n", "batch_T", "=", "80", ",", "\n", "batch_B", "=", "64", ",", "\n", "warmup_T", "=", "40", ",", "\n", "store_rnn_state_interval", "=", "40", ",", "# 0 for none, 1 for all.", "\n", "min_steps_learn", "=", "int", "(", "1e5", ")", ",", "\n", "delta_clip", "=", "None", ",", "# Typically use squared-error loss (Steven).", "\n", "replay_size", "=", "int", "(", "1e6", ")", ",", "\n", "replay_ratio", "=", "1", ",", "\n", "target_update_interval", "=", "2500", ",", "# (Steven says 2500 but maybe faster.)", "\n", "n_step_return", "=", "5", ",", "\n", "learning_rate", "=", "1e-4", ",", "\n", "OptimCls", "=", "torch", ".", "optim", ".", "Adam", ",", "\n", "optim_kwargs", "=", "None", ",", "\n", "initial_optim_state_dict", "=", "None", ",", "\n", "clip_grad_norm", "=", "80.", ",", "# 80 (Steven).", "\n", "# eps_init=1,  # NOW IN AGENT.", "\n", "# eps_final=0.1,", "\n", "# eps_final_min=0.0005,", "\n", "# eps_eval=0.001,", "\n", "eps_steps", "=", "int", "(", "1e6", ")", ",", "# STILL IN ALGO; conver to itr, give to agent.", "\n", "double_dqn", "=", "True", ",", "\n", "prioritized_replay", "=", "True", ",", "\n", "pri_alpha", "=", "0.6", ",", "\n", "pri_beta_init", "=", "0.9", ",", "\n", "pri_beta_final", "=", "0.9", ",", "\n", "pri_beta_steps", "=", "int", "(", "50e6", ")", ",", "\n", "pri_eta", "=", "0.9", ",", "\n", "default_priority", "=", "None", ",", "\n", "input_priorities", "=", "True", ",", "\n", "input_priority_shift", "=", "None", ",", "\n", "value_scale_eps", "=", "1e-3", ",", "# 1e-3 (Steven).", "\n", "ReplayBufferCls", "=", "None", ",", "# leave None to select by above options", "\n", "updates_per_sync", "=", "1", ",", "# For async mode only.", "\n", ")", ":", "\n", "        ", "\"\"\"Saves input arguments.\n\n        Args:\n            store_rnn_state_interval (int): store RNN state only once this many steps, to reduce memory usage; replay sequences will only begin at the steps with stored recurrent state.\n        \n        Note:\n            Typically ran with ``store_rnn_state_interval`` equal to the sampler's ``batch_T``, 40.  Then every 40 steps\n            can be the beginning of a replay sequence, and will be guaranteed to start with a valid RNN state.  Only reset\n            the RNN state (and env) at the end of the sampler batch, so that the beginnings of episodes are trained on.\n        \"\"\"", "\n", "if", "optim_kwargs", "is", "None", ":", "\n", "            ", "optim_kwargs", "=", "dict", "(", "eps", "=", "1e-3", ")", "# Assumes Adam.", "\n", "", "if", "default_priority", "is", "None", ":", "\n", "            ", "default_priority", "=", "delta_clip", "or", "1.", "\n", "", "if", "input_priority_shift", "is", "None", ":", "\n", "            ", "input_priority_shift", "=", "warmup_T", "//", "store_rnn_state_interval", "\n", "", "save__init__args", "(", "locals", "(", ")", ")", "\n", "self", ".", "_batch_size", "=", "(", "self", ".", "batch_T", "+", "self", ".", "warmup_T", ")", "*", "self", ".", "batch_B", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.dqn.r2d1.R2D1.initialize_replay_buffer": [[86, 129], ["rlpyt.algos.dqn.dqn.SamplesToBuffer", "dict", "ReplayCls", "SamplesToBufferRnn", "dict.update", "rlpyt.utils.logging.logger.log", "dict"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.models.running_mean_std.RunningMeanStdModel.update", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.console.log"], ["", "def", "initialize_replay_buffer", "(", "self", ",", "examples", ",", "batch_spec", ",", "async_", "=", "False", ")", ":", "\n", "        ", "\"\"\"Similar to DQN but uses replay buffers which return sequences, and\n        stores the agent's recurrent state.\"\"\"", "\n", "example_to_buffer", "=", "SamplesToBuffer", "(", "\n", "observation", "=", "examples", "[", "\"observation\"", "]", ",", "\n", "action", "=", "examples", "[", "\"action\"", "]", ",", "\n", "reward", "=", "examples", "[", "\"reward\"", "]", ",", "\n", "done", "=", "examples", "[", "\"done\"", "]", ",", "\n", ")", "\n", "if", "self", ".", "store_rnn_state_interval", ">", "0", ":", "\n", "            ", "example_to_buffer", "=", "SamplesToBufferRnn", "(", "*", "example_to_buffer", ",", "\n", "prev_rnn_state", "=", "examples", "[", "\"agent_info\"", "]", ".", "prev_rnn_state", ",", "\n", ")", "\n", "", "replay_kwargs", "=", "dict", "(", "\n", "example", "=", "example_to_buffer", ",", "\n", "size", "=", "self", ".", "replay_size", ",", "\n", "B", "=", "batch_spec", ".", "B", ",", "\n", "discount", "=", "self", ".", "discount", ",", "\n", "n_step_return", "=", "self", ".", "n_step_return", ",", "\n", "rnn_state_interval", "=", "self", ".", "store_rnn_state_interval", ",", "\n", "# batch_T fixed for prioritized, (relax if rnn_state_interval=1 or 0).", "\n", "batch_T", "=", "self", ".", "batch_T", "+", "self", ".", "warmup_T", ",", "\n", ")", "\n", "if", "self", ".", "prioritized_replay", ":", "\n", "            ", "replay_kwargs", ".", "update", "(", "dict", "(", "\n", "alpha", "=", "self", ".", "pri_alpha", ",", "\n", "beta", "=", "self", ".", "pri_beta_init", ",", "\n", "default_priority", "=", "self", ".", "default_priority", ",", "\n", "input_priorities", "=", "self", ".", "input_priorities", ",", "# True/False.", "\n", "input_priority_shift", "=", "self", ".", "input_priority_shift", ",", "\n", ")", ")", "\n", "ReplayCls", "=", "(", "AsyncPrioritizedSequenceReplayFrameBuffer", "if", "async_", "\n", "else", "PrioritizedSequenceReplayFrameBuffer", ")", "\n", "", "else", ":", "\n", "            ", "ReplayCls", "=", "(", "AsyncUniformSequenceReplayFrameBuffer", "if", "async_", "\n", "else", "UniformSequenceReplayFrameBuffer", ")", "\n", "", "if", "self", ".", "ReplayBufferCls", "is", "not", "None", ":", "\n", "            ", "ReplayCls", "=", "self", ".", "ReplayBufferCls", "\n", "logger", ".", "log", "(", "f\"WARNING: ignoring internal selection logic and using\"", "\n", "f\" input replay buffer class: {ReplayCls} -- compatibility not\"", "\n", "\" guaranteed.\"", ")", "\n", "", "self", ".", "replay_buffer", "=", "ReplayCls", "(", "**", "replay_kwargs", ")", "\n", "return", "self", ".", "replay_buffer", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.dqn.r2d1.R2D1.optimize_agent": [[130, 169], ["OptInfo", "range", "r2d1.R2D1.update_itr_hyperparams", "r2d1.R2D1.samples_to_buffer", "r2d1.R2D1.replay_buffer.append_samples", "r2d1.R2D1.replay_buffer.sample_batch", "r2d1.R2D1.optimizer.zero_grad", "r2d1.R2D1.loss", "loss.backward", "torch.nn.utils.clip_grad_norm_", "r2d1.R2D1.optimizer.step", "OptInfo.loss.append", "OptInfo.gradNorm.append", "OptInfo.tdAbsErr.extend", "OptInfo.priority.extend", "r2d1.R2D1.agent.parameters", "r2d1.R2D1.replay_buffer.update_batch_priorities", "loss.item", "torch.tensor().item", "td_abs_errors[].numpy", "r2d1.R2D1.agent.update_target", "range", "torch.tensor", "len"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.rl_with_ul.dqn_with_ul.DqnUl.update_itr_hyperparams", "home.repos.pwc.inspect_result.astooke_rlpyt.rl_with_ul.ppo_with_ul.PpoUl.samples_to_buffer", "home.repos.pwc.inspect_result.astooke_rlpyt.sequence.prioritized.PrioritizedSequenceReplay.append_samples", "home.repos.pwc.inspect_result.astooke_rlpyt.sequence.uniform.UniformSequenceReplay.sample_batch", "home.repos.pwc.inspect_result.astooke_rlpyt.safe.cppo_pid.CppoPID.loss", "home.repos.pwc.inspect_result.astooke_rlpyt.models.utils.ScaleGrad.backward", "home.repos.pwc.inspect_result.astooke_rlpyt.safe.safety_gym_env.SafetyGymTrajInfo.step", "home.repos.pwc.inspect_result.astooke_rlpyt.rl.atari_rl_models.AtariDqnModel.parameters", "home.repos.pwc.inspect_result.astooke_rlpyt.sequence.prioritized.PrioritizedSequenceReplay.update_batch_priorities", "home.repos.pwc.inspect_result.astooke_rlpyt.agents.atari_dqn_agent.AtariDqnAgent.update_target"], ["", "def", "optimize_agent", "(", "self", ",", "itr", ",", "samples", "=", "None", ",", "sampler_itr", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Similar to DQN, except allows to compute the priorities of new samples\n        as they enter the replay buffer (input priorities), instead of only once they are\n        used in training (important because the replay-ratio is quite low, about 1,\n        so must avoid un-informative samples).\n        \"\"\"", "\n", "\n", "# TODO: estimate priorities for samples entering the replay buffer.", "\n", "# Steven says: workers did this approximately by using the online", "\n", "# network only for td-errors (not the target network).", "\n", "# This could be tough since add samples before the priorities are ready", "\n", "# (next batch), and in async case workers must do it.", "\n", "itr", "=", "itr", "if", "sampler_itr", "is", "None", "else", "sampler_itr", "# Async uses sampler_itr", "\n", "if", "samples", "is", "not", "None", ":", "\n", "            ", "samples_to_buffer", "=", "self", ".", "samples_to_buffer", "(", "samples", ")", "\n", "self", ".", "replay_buffer", ".", "append_samples", "(", "samples_to_buffer", ")", "\n", "", "opt_info", "=", "OptInfo", "(", "*", "(", "[", "]", "for", "_", "in", "range", "(", "len", "(", "OptInfo", ".", "_fields", ")", ")", ")", ")", "\n", "if", "itr", "<", "self", ".", "min_itr_learn", ":", "\n", "            ", "return", "opt_info", "\n", "", "for", "_", "in", "range", "(", "self", ".", "updates_per_optimize", ")", ":", "\n", "            ", "samples_from_replay", "=", "self", ".", "replay_buffer", ".", "sample_batch", "(", "self", ".", "batch_B", ")", "\n", "self", ".", "optimizer", ".", "zero_grad", "(", ")", "\n", "loss", ",", "td_abs_errors", ",", "priorities", "=", "self", ".", "loss", "(", "samples_from_replay", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "grad_norm", "=", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "\n", "self", ".", "agent", ".", "parameters", "(", ")", ",", "self", ".", "clip_grad_norm", ")", "\n", "self", ".", "optimizer", ".", "step", "(", ")", "\n", "if", "self", ".", "prioritized_replay", ":", "\n", "                ", "self", ".", "replay_buffer", ".", "update_batch_priorities", "(", "priorities", ")", "\n", "", "opt_info", ".", "loss", ".", "append", "(", "loss", ".", "item", "(", ")", ")", "\n", "opt_info", ".", "gradNorm", ".", "append", "(", "torch", ".", "tensor", "(", "grad_norm", ")", ".", "item", "(", ")", ")", "# backwards compatible", "\n", "opt_info", ".", "tdAbsErr", ".", "extend", "(", "td_abs_errors", "[", ":", ":", "8", "]", ".", "numpy", "(", ")", ")", "\n", "opt_info", ".", "priority", ".", "extend", "(", "priorities", ")", "\n", "self", ".", "update_counter", "+=", "1", "\n", "if", "self", ".", "update_counter", "%", "self", ".", "target_update_interval", "==", "0", ":", "\n", "                ", "self", ".", "agent", ".", "update_target", "(", ")", "\n", "", "", "self", ".", "update_itr_hyperparams", "(", "itr", ")", "\n", "return", "opt_info", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.dqn.r2d1.R2D1.samples_to_buffer": [[170, 180], ["super().samples_to_buffer", "SamplesToBufferRnn", "r2d1.R2D1.compute_input_priorities", "PrioritiesSamplesToBuffer"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.rl_with_ul.ppo_with_ul.PpoUl.samples_to_buffer", "home.repos.pwc.inspect_result.astooke_rlpyt.dqn.r2d1.R2D1.compute_input_priorities"], ["", "def", "samples_to_buffer", "(", "self", ",", "samples", ")", ":", "\n", "        ", "samples_to_buffer", "=", "super", "(", ")", ".", "samples_to_buffer", "(", "samples", ")", "\n", "if", "self", ".", "store_rnn_state_interval", ">", "0", ":", "\n", "            ", "samples_to_buffer", "=", "SamplesToBufferRnn", "(", "*", "samples_to_buffer", ",", "\n", "prev_rnn_state", "=", "samples", ".", "agent", ".", "agent_info", ".", "prev_rnn_state", ")", "\n", "", "if", "self", ".", "input_priorities", ":", "\n", "            ", "priorities", "=", "self", ".", "compute_input_priorities", "(", "samples", ")", "\n", "samples_to_buffer", "=", "PrioritiesSamplesToBuffer", "(", "\n", "priorities", "=", "priorities", ",", "samples", "=", "samples_to_buffer", ")", "\n", "", "return", "samples_to_buffer", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.dqn.r2d1.R2D1.compute_input_priorities": [[181, 243], ["rlpyt.utils.buffer.torchify_buffer", "rlpyt.utils.tensor.select_at_indexes", "rlpyt.algos.utils.discount_return_n_step", "max", "r2d1.R2D1.value_scale", "abs", "rlpyt.algos.utils.valid_from_done", "rlpyt.utils.tensor.valid_mean", "priorities.numpy", "torch.max", "torch.clamp", "torch.max", "r2d1.R2D1.inv_value_scale", "done_n.float"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.utils.buffer.torchify_buffer", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.tensor.select_at_indexes", "home.repos.pwc.inspect_result.astooke_rlpyt.algos.utils.discount_return_n_step", "home.repos.pwc.inspect_result.astooke_rlpyt.dqn.r2d1.R2D1.value_scale", "home.repos.pwc.inspect_result.astooke_rlpyt.algos.utils.valid_from_done", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.tensor.valid_mean", "home.repos.pwc.inspect_result.astooke_rlpyt.dqn.r2d1.R2D1.inv_value_scale"], ["", "def", "compute_input_priorities", "(", "self", ",", "samples", ")", ":", "\n", "        ", "\"\"\"Used when putting new samples into the replay buffer.  Computes\n        n-step TD-errors using recorded Q-values from online network and\n        value scaling.  Weights the max and the mean TD-error over each sequence\n        to make a single priority value for that sequence.  \n\n        Note:\n            Although the original R2D2 implementation used the entire\n            80-step sequence to compute the input priorities, we ran R2D1 with 40\n            time-step sample batches, and so computed the priority for each\n            80-step training sequence based on one of the two 40-step halves.\n            Algorithm argument ``input_priority_shift`` determines which 40-step\n            half is used as the priority for the 80-step sequence.  (Since this \n            method might get executed by alternating memory copiers in async mode,\n            don't carry internal state here, do all computation with only the samples\n            available in input.  Could probably reduce to one memory copier and keep\n            state there, if needed.)\n        \"\"\"", "\n", "\n", "# \"\"\"Just for first input into replay buffer.", "\n", "# Simple 1-step return TD-errors using recorded Q-values from online", "\n", "# network and value scaling, with the T dimension reduced away (same", "\n", "# priority applied to all samples in this batch; whereever the rnn state", "\n", "# is kept--hopefully the first step--this priority will apply there).", "\n", "# The samples duration T might be less than the training segment, so", "\n", "# this is an approximation of an approximation, but hopefully will", "\n", "# capture the right behavior.", "\n", "# UPDATE 20190826: Trying using n-step returns.  For now using samples", "\n", "# with full n-step return available...later could also use partial", "\n", "# returns for samples at end of batch.  35/40 ain't bad tho.", "\n", "# Might not carry/use internal state here, because might get executed", "\n", "# by alternating memory copiers in async mode; do all with only the", "\n", "# samples avialable from input.\"\"\"", "\n", "samples", "=", "torchify_buffer", "(", "samples", ")", "\n", "q", "=", "samples", ".", "agent", ".", "agent_info", ".", "q", "\n", "action", "=", "samples", ".", "agent", ".", "action", "\n", "q_max", "=", "torch", ".", "max", "(", "q", ",", "dim", "=", "-", "1", ")", ".", "values", "\n", "q_at_a", "=", "select_at_indexes", "(", "action", ",", "q", ")", "\n", "return_n", ",", "done_n", "=", "discount_return_n_step", "(", "\n", "reward", "=", "samples", ".", "env", ".", "reward", ",", "\n", "done", "=", "samples", ".", "env", ".", "done", ",", "\n", "n_step", "=", "self", ".", "n_step_return", ",", "\n", "discount", "=", "self", ".", "discount", ",", "\n", "do_truncated", "=", "False", ",", "# Only samples with full n-step return.", "\n", ")", "\n", "# y = self.value_scale(", "\n", "#     samples.env.reward[:-1] +", "\n", "#     (self.discount * (1 - samples.env.done[:-1].float()) *  # probably done.float()", "\n", "#         self.inv_value_scale(q_max[1:]))", "\n", "# )", "\n", "nm1", "=", "max", "(", "1", ",", "self", ".", "n_step_return", "-", "1", ")", "# At least 1 bc don't have next Q.", "\n", "y", "=", "self", ".", "value_scale", "(", "return_n", "+", "\n", "(", "1", "-", "done_n", ".", "float", "(", ")", ")", "*", "self", ".", "inv_value_scale", "(", "q_max", "[", "nm1", ":", "]", ")", ")", "\n", "delta", "=", "abs", "(", "q_at_a", "[", ":", "-", "nm1", "]", "-", "y", ")", "\n", "# NOTE: by default, with R2D1, use squared-error loss, delta_clip=None.", "\n", "if", "self", ".", "delta_clip", "is", "not", "None", ":", "# Huber loss.", "\n", "            ", "delta", "=", "torch", ".", "clamp", "(", "delta", ",", "0", ",", "self", ".", "delta_clip", ")", "\n", "", "valid", "=", "valid_from_done", "(", "samples", ".", "env", ".", "done", "[", ":", "-", "nm1", "]", ")", "\n", "max_d", "=", "torch", ".", "max", "(", "delta", "*", "valid", ",", "dim", "=", "0", ")", ".", "values", "\n", "mean_d", "=", "valid_mean", "(", "delta", ",", "valid", ",", "dim", "=", "0", ")", "# Still high if less valid.", "\n", "priorities", "=", "self", ".", "pri_eta", "*", "max_d", "+", "(", "1", "-", "self", ".", "pri_eta", ")", "*", "mean_d", "# [B]", "\n", "return", "priorities", ".", "numpy", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.dqn.r2d1.R2D1.loss": [[244, 335], ["rlpyt.utils.buffer.buffer_to", "slice", "rlpyt.agents.base.AgentInputs", "slice", "rlpyt.agents.base.AgentInputs", "r2d1.R2D1.agent", "rlpyt.utils.tensor.select_at_indexes", "r2d1.R2D1.value_scale", "abs", "rlpyt.algos.utils.valid_from_done", "rlpyt.utils.tensor.valid_mean", "abs.detach", "rlpyt.utils.tensor.valid_mean", "slice", "rlpyt.agents.base.AgentInputs", "rlpyt.utils.buffer.buffer_method", "rlpyt.utils.buffer.buffer_method", "torch.no_grad", "r2d1.R2D1.agent.target", "torch.where", "samples.is_weights.unsqueeze", "torch.clamp", "torch.max", "torch.no_grad", "r2d1.R2D1.agent.target", "r2d1.R2D1.agent", "r2d1.R2D1.agent", "torch.argmax", "rlpyt.utils.tensor.select_at_indexes", "rlpyt.algos.utils.valid_from_done", "torch.max", "r2d1.R2D1.inv_value_scale", "done_n.float"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.utils.buffer.buffer_to", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.tensor.select_at_indexes", "home.repos.pwc.inspect_result.astooke_rlpyt.dqn.r2d1.R2D1.value_scale", "home.repos.pwc.inspect_result.astooke_rlpyt.algos.utils.valid_from_done", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.tensor.valid_mean", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.tensor.valid_mean", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.buffer.buffer_method", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.buffer.buffer_method", "home.repos.pwc.inspect_result.astooke_rlpyt.agents.atari_dqn_agent.AtariDqnAgent.target", "home.repos.pwc.inspect_result.astooke_rlpyt.agents.atari_dqn_agent.AtariDqnAgent.target", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.tensor.select_at_indexes", "home.repos.pwc.inspect_result.astooke_rlpyt.algos.utils.valid_from_done", "home.repos.pwc.inspect_result.astooke_rlpyt.dqn.r2d1.R2D1.inv_value_scale"], ["", "def", "loss", "(", "self", ",", "samples", ")", ":", "\n", "        ", "\"\"\"Samples have leading Time and Batch dimentions [T,B,..]. Move all\n        samples to device first, and then slice for sub-sequences.  Use same\n        init_rnn_state for agent and target; start both at same t.  Warmup the\n        RNN state first on the warmup subsequence, then train on the remaining\n        subsequence.\n\n        Returns loss (usually use MSE, not Huber), TD-error absolute values,\n        and new sequence-wise priorities, based on weighted sum of max and mean\n        TD-error over the sequence.\"\"\"", "\n", "all_observation", ",", "all_action", ",", "all_reward", "=", "buffer_to", "(", "\n", "(", "samples", ".", "all_observation", ",", "samples", ".", "all_action", ",", "samples", ".", "all_reward", ")", ",", "\n", "device", "=", "self", ".", "agent", ".", "device", ")", "\n", "wT", ",", "bT", ",", "nsr", "=", "self", ".", "warmup_T", ",", "self", ".", "batch_T", ",", "self", ".", "n_step_return", "\n", "if", "wT", ">", "0", ":", "\n", "            ", "warmup_slice", "=", "slice", "(", "None", ",", "wT", ")", "# Same for agent and target.", "\n", "warmup_inputs", "=", "AgentInputs", "(", "\n", "observation", "=", "all_observation", "[", "warmup_slice", "]", ",", "\n", "prev_action", "=", "all_action", "[", "warmup_slice", "]", ",", "\n", "prev_reward", "=", "all_reward", "[", "warmup_slice", "]", ",", "\n", ")", "\n", "", "agent_slice", "=", "slice", "(", "wT", ",", "wT", "+", "bT", ")", "\n", "agent_inputs", "=", "AgentInputs", "(", "\n", "observation", "=", "all_observation", "[", "agent_slice", "]", ",", "\n", "prev_action", "=", "all_action", "[", "agent_slice", "]", ",", "\n", "prev_reward", "=", "all_reward", "[", "agent_slice", "]", ",", "\n", ")", "\n", "target_slice", "=", "slice", "(", "wT", ",", "None", ")", "# Same start t as agent. (wT + bT + nsr)", "\n", "target_inputs", "=", "AgentInputs", "(", "\n", "observation", "=", "all_observation", "[", "target_slice", "]", ",", "\n", "prev_action", "=", "all_action", "[", "target_slice", "]", ",", "\n", "prev_reward", "=", "all_reward", "[", "target_slice", "]", ",", "\n", ")", "\n", "action", "=", "samples", ".", "all_action", "[", "wT", "+", "1", ":", "wT", "+", "1", "+", "bT", "]", "# CPU.", "\n", "return_", "=", "samples", ".", "return_", "[", "wT", ":", "wT", "+", "bT", "]", "\n", "done_n", "=", "samples", ".", "done_n", "[", "wT", ":", "wT", "+", "bT", "]", "\n", "if", "self", ".", "store_rnn_state_interval", "==", "0", ":", "\n", "            ", "init_rnn_state", "=", "None", "\n", "", "else", ":", "\n", "# [B,N,H]-->[N,B,H] cudnn.", "\n", "            ", "init_rnn_state", "=", "buffer_method", "(", "samples", ".", "init_rnn_state", ",", "\"transpose\"", ",", "0", ",", "1", ")", "\n", "init_rnn_state", "=", "buffer_method", "(", "init_rnn_state", ",", "\"contiguous\"", ")", "\n", "", "if", "wT", ">", "0", ":", "# Do warmup.", "\n", "            ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "_", ",", "target_rnn_state", "=", "self", ".", "agent", ".", "target", "(", "*", "warmup_inputs", ",", "init_rnn_state", ")", "\n", "_", ",", "init_rnn_state", "=", "self", ".", "agent", "(", "*", "warmup_inputs", ",", "init_rnn_state", ")", "\n", "# Recommend aligning sampling batch_T and store_rnn_interval with", "\n", "# warmup_T (and no mid_batch_reset), so that end of trajectory", "\n", "# during warmup leads to new trajectory beginning at start of", "\n", "# training segment of replay.", "\n", "", "warmup_invalid_mask", "=", "valid_from_done", "(", "samples", ".", "done", "[", ":", "wT", "]", ")", "[", "-", "1", "]", "==", "0", "# [B]", "\n", "init_rnn_state", "[", ":", ",", "warmup_invalid_mask", "]", "=", "0", "# [N,B,H] (cudnn)", "\n", "target_rnn_state", "[", ":", ",", "warmup_invalid_mask", "]", "=", "0", "\n", "", "else", ":", "\n", "            ", "target_rnn_state", "=", "init_rnn_state", "\n", "\n", "", "qs", ",", "_", "=", "self", ".", "agent", "(", "*", "agent_inputs", ",", "init_rnn_state", ")", "# [T,B,A]", "\n", "q", "=", "select_at_indexes", "(", "action", ",", "qs", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "target_qs", ",", "_", "=", "self", ".", "agent", ".", "target", "(", "*", "target_inputs", ",", "target_rnn_state", ")", "\n", "if", "self", ".", "double_dqn", ":", "\n", "                ", "next_qs", ",", "_", "=", "self", ".", "agent", "(", "*", "target_inputs", ",", "init_rnn_state", ")", "\n", "next_a", "=", "torch", ".", "argmax", "(", "next_qs", ",", "dim", "=", "-", "1", ")", "\n", "target_q", "=", "select_at_indexes", "(", "next_a", ",", "target_qs", ")", "\n", "", "else", ":", "\n", "                ", "target_q", "=", "torch", ".", "max", "(", "target_qs", ",", "dim", "=", "-", "1", ")", ".", "values", "\n", "", "target_q", "=", "target_q", "[", "-", "bT", ":", "]", "# Same length as q.", "\n", "\n", "", "disc", "=", "self", ".", "discount", "**", "self", ".", "n_step_return", "\n", "y", "=", "self", ".", "value_scale", "(", "return_", "+", "(", "1", "-", "done_n", ".", "float", "(", ")", ")", "*", "disc", "*", "\n", "self", ".", "inv_value_scale", "(", "target_q", ")", ")", "# [T,B]", "\n", "delta", "=", "y", "-", "q", "\n", "losses", "=", "0.5", "*", "delta", "**", "2", "\n", "abs_delta", "=", "abs", "(", "delta", ")", "\n", "# NOTE: by default, with R2D1, use squared-error loss, delta_clip=None.", "\n", "if", "self", ".", "delta_clip", "is", "not", "None", ":", "# Huber loss.", "\n", "            ", "b", "=", "self", ".", "delta_clip", "*", "(", "abs_delta", "-", "self", ".", "delta_clip", "/", "2", ")", "\n", "losses", "=", "torch", ".", "where", "(", "abs_delta", "<=", "self", ".", "delta_clip", ",", "losses", ",", "b", ")", "\n", "", "if", "self", ".", "prioritized_replay", ":", "\n", "            ", "losses", "*=", "samples", ".", "is_weights", ".", "unsqueeze", "(", "0", ")", "# weights: [B] --> [1,B]", "\n", "", "valid", "=", "valid_from_done", "(", "samples", ".", "done", "[", "wT", ":", "]", ")", "# 0 after first done.", "\n", "loss", "=", "valid_mean", "(", "losses", ",", "valid", ")", "\n", "td_abs_errors", "=", "abs_delta", ".", "detach", "(", ")", "\n", "if", "self", ".", "delta_clip", "is", "not", "None", ":", "\n", "            ", "td_abs_errors", "=", "torch", ".", "clamp", "(", "td_abs_errors", ",", "0", ",", "self", ".", "delta_clip", ")", "# [T,B]", "\n", "", "valid_td_abs_errors", "=", "td_abs_errors", "*", "valid", "\n", "max_d", "=", "torch", ".", "max", "(", "valid_td_abs_errors", ",", "dim", "=", "0", ")", ".", "values", "\n", "mean_d", "=", "valid_mean", "(", "td_abs_errors", ",", "valid", ",", "dim", "=", "0", ")", "# Still high if less valid.", "\n", "priorities", "=", "self", ".", "pri_eta", "*", "max_d", "+", "(", "1", "-", "self", ".", "pri_eta", ")", "*", "mean_d", "# [B]", "\n", "\n", "return", "loss", ",", "valid_td_abs_errors", ",", "priorities", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.dqn.r2d1.R2D1.value_scale": [[336, 340], ["torch.sign", "torch.sqrt", "abs"], "methods", ["None"], ["", "def", "value_scale", "(", "self", ",", "x", ")", ":", "\n", "        ", "\"\"\"Value scaling function to handle raw rewards across games (not clipped).\"\"\"", "\n", "return", "(", "torch", ".", "sign", "(", "x", ")", "*", "(", "torch", ".", "sqrt", "(", "abs", "(", "x", ")", "+", "1", ")", "-", "1", ")", "+", "\n", "self", ".", "value_scale_eps", "*", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.dqn.r2d1.R2D1.inv_value_scale": [[341, 346], ["torch.sign", "torch.sqrt", "abs"], "methods", ["None"], ["", "def", "inv_value_scale", "(", "self", ",", "z", ")", ":", "\n", "        ", "\"\"\"Invert the value scaling.\"\"\"", "\n", "return", "torch", ".", "sign", "(", "z", ")", "*", "(", "(", "(", "torch", ".", "sqrt", "(", "1", "+", "4", "*", "self", ".", "value_scale_eps", "*", "\n", "(", "abs", "(", "z", ")", "+", "1", "+", "self", ".", "value_scale_eps", ")", ")", "-", "1", ")", "/", "\n", "(", "2", "*", "self", ".", "value_scale_eps", ")", ")", "**", "2", "-", "1", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.astooke_rlpyt.dqn.epsilon_greedy.EpsilonGreedyAgentMixin.__init__": [[20, 40], ["super().__init__", "rlpyt.utils.quick_args.save__init__args", "rlpyt.utils.buffer.np_mp_array", "locals"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.spaces.gym_wrapper.GymSpaceWrapper.__init__", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.quick_args.save__init__args", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.buffer.np_mp_array"], ["def", "__init__", "(", "\n", "self", ",", "\n", "eps_init", "=", "1", ",", "\n", "eps_final", "=", "0.01", ",", "\n", "eps_final_min", "=", "None", ",", "# Give < eps_final for vector epsilon.", "\n", "eps_itr_min", "=", "50", ",", "# Algo may overwrite.", "\n", "eps_itr_max", "=", "1000", ",", "\n", "eps_eval", "=", "0.001", ",", "\n", "*", "args", ",", "\n", "**", "kwargs", "\n", ")", ":", "\n", "        ", "\"\"\"Saves input arguments.  ``eps_final_min`` other than ``None`` will use \n        vector-valued epsilon, log-spaced.\"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "save__init__args", "(", "locals", "(", ")", ")", "\n", "self", ".", "_eps_final_scalar", "=", "eps_final", "# In case multiple vec_eps calls.", "\n", "self", ".", "_eps_init_scalar", "=", "eps_init", "\n", "self", ".", "_eps_itr_min_max", "=", "np_mp_array", "(", "2", ",", "\"int\"", ")", "# Shared memory for CpuSampler", "\n", "self", ".", "_eps_itr_min_max", "[", "0", "]", "=", "eps_itr_min", "\n", "self", ".", "_eps_itr_min_max", "[", "1", "]", "=", "eps_itr_max", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.dqn.epsilon_greedy.EpsilonGreedyAgentMixin.collector_initialize": [[41, 46], ["epsilon_greedy.EpsilonGreedyAgentMixin.make_vec_eps"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.dqn.epsilon_greedy.EpsilonGreedyAgentMixin.make_vec_eps"], ["", "def", "collector_initialize", "(", "self", ",", "global_B", "=", "1", ",", "env_ranks", "=", "None", ")", ":", "\n", "        ", "\"\"\"For vector-valued epsilon, the agent inside the sampler worker process\n        must initialize with its own epsilon values.\"\"\"", "\n", "if", "env_ranks", "is", "not", "None", ":", "\n", "            ", "self", ".", "make_vec_eps", "(", "global_B", ",", "env_ranks", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.dqn.epsilon_greedy.EpsilonGreedyAgentMixin.make_vec_eps": [[47, 64], ["torch.logspace", "list", "torch.ones", "torch.log10", "torch.log10", "set", "len", "torch.tensor", "torch.tensor"], "methods", ["None"], ["", "", "def", "make_vec_eps", "(", "self", ",", "global_B", ",", "env_ranks", ")", ":", "\n", "        ", "\"\"\"Construct log-spaced epsilon values and select local assignments\n        from the global number of sampler environment instances (for SyncRl\n        and AsyncRl).\"\"\"", "\n", "if", "(", "self", ".", "eps_final_min", "is", "not", "None", "and", "\n", "self", ".", "eps_final_min", "!=", "self", ".", "_eps_final_scalar", ")", ":", "# vector epsilon.", "\n", "            ", "if", "self", ".", "alternating", ":", "# In FF case, sampler sets agent.alternating.", "\n", "                ", "assert", "global_B", "%", "2", "==", "0", "\n", "global_B", "=", "global_B", "//", "2", "# Env pairs will share epsilon.", "\n", "env_ranks", "=", "list", "(", "set", "(", "[", "i", "//", "2", "for", "i", "in", "env_ranks", "]", ")", ")", "\n", "", "self", ".", "eps_init", "=", "self", ".", "_eps_init_scalar", "*", "torch", ".", "ones", "(", "len", "(", "env_ranks", ")", ")", "\n", "global_eps_final", "=", "torch", ".", "logspace", "(", "\n", "torch", ".", "log10", "(", "torch", ".", "tensor", "(", "self", ".", "eps_final_min", ")", ")", ",", "\n", "torch", ".", "log10", "(", "torch", ".", "tensor", "(", "self", ".", "_eps_final_scalar", ")", ")", ",", "\n", "global_B", ")", "\n", "self", ".", "eps_final", "=", "global_eps_final", "[", "env_ranks", "]", "\n", "", "self", ".", "eps_sample", "=", "self", ".", "eps_init", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.dqn.epsilon_greedy.EpsilonGreedyAgentMixin.set_epsilon_itr_min_max": [[65, 73], ["rlpyt.utils.logging.logger.log"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.logging.console.log"], ["", "def", "set_epsilon_itr_min_max", "(", "self", ",", "eps_itr_min", ",", "eps_itr_max", ")", ":", "\n", "# Beginning and end of linear ramp down of epsilon.", "\n", "        ", "logger", ".", "log", "(", "f\"Agent setting min/max epsilon itrs: {eps_itr_min}, \"", "\n", "f\"{eps_itr_max}\"", ")", "\n", "self", ".", "eps_itr_min", "=", "eps_itr_min", "\n", "self", ".", "eps_itr_max", "=", "eps_itr_max", "\n", "self", ".", "_eps_itr_min_max", "[", "0", "]", "=", "eps_itr_min", "# Shared memory for CpuSampler", "\n", "self", ".", "_eps_itr_min_max", "[", "1", "]", "=", "eps_itr_max", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.dqn.epsilon_greedy.EpsilonGreedyAgentMixin.set_sample_epsilon_greedy": [[82, 84], ["epsilon_greedy.EpsilonGreedyAgentMixin.distribution.set_epsilon"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.distributions.epsilon_greedy.EpsilonGreedy.set_epsilon"], ["", "def", "set_sample_epsilon_greedy", "(", "self", ",", "epsilon", ")", ":", "\n", "        ", "self", ".", "distribution", ".", "set_epsilon", "(", "epsilon", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.dqn.epsilon_greedy.EpsilonGreedyAgentMixin.sample_mode": [[100, 112], ["super().sample_mode", "epsilon_greedy.EpsilonGreedyAgentMixin.distribution.set_epsilon", "min", "rlpyt.utils.logging.logger.log", "max"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.agents.dmc_sac_agent.SacAgent.sample_mode", "home.repos.pwc.inspect_result.astooke_rlpyt.distributions.epsilon_greedy.EpsilonGreedy.set_epsilon", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.console.log"], ["", "def", "sample_mode", "(", "self", ",", "itr", ")", ":", "\n", "        ", "\"\"\"Extend method to set epsilon for sampling (including annealing).\"\"\"", "\n", "super", "(", ")", ".", "sample_mode", "(", "itr", ")", "\n", "itr_min", "=", "self", ".", "_eps_itr_min_max", "[", "0", "]", "# Shared memory for CpuSampler", "\n", "itr_max", "=", "self", ".", "_eps_itr_min_max", "[", "1", "]", "\n", "if", "itr", "<=", "itr_max", ":", "\n", "            ", "prog", "=", "min", "(", "1", ",", "max", "(", "0", ",", "itr", "-", "itr_min", ")", "/", "(", "itr_max", "-", "itr_min", ")", ")", "\n", "self", ".", "eps_sample", "=", "prog", "*", "self", ".", "eps_final", "+", "(", "1", "-", "prog", ")", "*", "self", ".", "eps_init", "\n", "if", "itr", "%", "(", "itr_max", "//", "10", ")", "==", "0", "or", "itr", "==", "itr_max", ":", "\n", "                ", "logger", ".", "log", "(", "f\"Agent at itr {itr}, sample eps {self.eps_sample}\"", "\n", "f\" (min itr: {itr_min}, max_itr: {itr_max})\"", ")", "\n", "", "", "self", ".", "distribution", ".", "set_epsilon", "(", "self", ".", "eps_sample", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.dqn.epsilon_greedy.EpsilonGreedyAgentMixin.eval_mode": [[120, 127], ["super().eval_mode", "rlpyt.utils.logging.logger.log", "epsilon_greedy.EpsilonGreedyAgentMixin.distribution.set_epsilon"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.agents.dmc_sac_agent.SacAgent.eval_mode", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.console.log", "home.repos.pwc.inspect_result.astooke_rlpyt.distributions.epsilon_greedy.EpsilonGreedy.set_epsilon"], ["", "def", "eval_mode", "(", "self", ",", "itr", ")", ":", "\n", "        ", "\"\"\"Extend method to set epsilon for evaluation, using 1 for\n        pre-training eval.\"\"\"", "\n", "super", "(", ")", ".", "eval_mode", "(", "itr", ")", "\n", "logger", ".", "log", "(", "f\"Agent at itr {itr}, eval eps \"", "\n", "f\"{self.eps_eval if itr > 0 else 1.}\"", ")", "\n", "self", ".", "distribution", ".", "set_epsilon", "(", "self", ".", "eps_eval", "if", "itr", ">", "0", "else", "1.", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.dqn.r2d1_agent.R2d1AgentBase.__call__": [[17, 24], ["r2d1_agent.R2d1AgentBase.distribution.to_onehot", "rlpyt.utils.buffer.buffer_to", "r2d1_agent.R2d1AgentBase.model", "q.cpu"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.distributions.discrete.DiscreteMixin.to_onehot", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.buffer.buffer_to"], ["def", "__call__", "(", "self", ",", "observation", ",", "prev_action", ",", "prev_reward", ",", "init_rnn_state", ")", ":", "\n", "# Assume init_rnn_state already shaped: [N,B,H]", "\n", "        ", "prev_action", "=", "self", ".", "distribution", ".", "to_onehot", "(", "prev_action", ")", "\n", "model_inputs", "=", "buffer_to", "(", "(", "observation", ",", "prev_action", ",", "prev_reward", ",", "\n", "init_rnn_state", ")", ",", "device", "=", "self", ".", "device", ")", "\n", "q", ",", "rnn_state", "=", "self", ".", "model", "(", "*", "model_inputs", ")", "\n", "return", "q", ".", "cpu", "(", ")", ",", "rnn_state", "# Leave rnn state on device.", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.dqn.r2d1_agent.R2d1AgentBase.step": [[25, 43], ["torch.no_grad", "r2d1_agent.R2d1AgentBase.distribution.to_onehot", "rlpyt.utils.buffer.buffer_to", "r2d1_agent.R2d1AgentBase.model", "q.cpu.cpu.cpu", "r2d1_agent.R2d1AgentBase.distribution.sample", "rlpyt.utils.buffer.buffer_method", "rlpyt.utils.buffer.buffer_to", "AgentInfo", "r2d1_agent.R2d1AgentBase.advance_rnn_state", "rlpyt.agents.base.AgentStep", "rlpyt.utils.buffer.buffer_func"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.distributions.discrete.DiscreteMixin.to_onehot", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.buffer.buffer_to", "home.repos.pwc.inspect_result.astooke_rlpyt.spaces.gym_wrapper.GymSpaceWrapper.sample", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.buffer.buffer_method", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.buffer.buffer_to", "home.repos.pwc.inspect_result.astooke_rlpyt.agents.base.AlternatingRecurrentAgentMixin.advance_rnn_state", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.buffer.buffer_func"], ["", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "step", "(", "self", ",", "observation", ",", "prev_action", ",", "prev_reward", ")", ":", "\n", "        ", "\"\"\"Computes Q-values for states/observations and selects actions by\n        epsilon-greedy (no grad).  Advances RNN state.\"\"\"", "\n", "prev_action", "=", "self", ".", "distribution", ".", "to_onehot", "(", "prev_action", ")", "\n", "agent_inputs", "=", "buffer_to", "(", "(", "observation", ",", "prev_action", ",", "prev_reward", ")", ",", "\n", "device", "=", "self", ".", "device", ")", "\n", "q", ",", "rnn_state", "=", "self", ".", "model", "(", "*", "agent_inputs", ",", "self", ".", "prev_rnn_state", ")", "# Model handles None.", "\n", "q", "=", "q", ".", "cpu", "(", ")", "\n", "action", "=", "self", ".", "distribution", ".", "sample", "(", "q", ")", "\n", "prev_rnn_state", "=", "self", ".", "prev_rnn_state", "or", "buffer_func", "(", "rnn_state", ",", "torch", ".", "zeros_like", ")", "\n", "# Transpose the rnn_state from [N,B,H] --> [B,N,H] for storage.", "\n", "# (Special case, model should always leave B dimension in.)", "\n", "prev_rnn_state", "=", "buffer_method", "(", "prev_rnn_state", ",", "\"transpose\"", ",", "0", ",", "1", ")", "\n", "prev_rnn_state", "=", "buffer_to", "(", "prev_rnn_state", ",", "device", "=", "\"cpu\"", ")", "\n", "agent_info", "=", "AgentInfo", "(", "q", "=", "q", ",", "prev_rnn_state", "=", "prev_rnn_state", ")", "\n", "self", ".", "advance_rnn_state", "(", "rnn_state", ")", "# Keep on device.", "\n", "return", "AgentStep", "(", "action", "=", "action", ",", "agent_info", "=", "agent_info", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.dqn.r2d1_agent.R2d1AgentBase.target": [[44, 51], ["r2d1_agent.R2d1AgentBase.distribution.to_onehot", "rlpyt.utils.buffer.buffer_to", "r2d1_agent.R2d1AgentBase.target_model", "target_q.cpu"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.distributions.discrete.DiscreteMixin.to_onehot", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.buffer.buffer_to"], ["", "def", "target", "(", "self", ",", "observation", ",", "prev_action", ",", "prev_reward", ",", "init_rnn_state", ")", ":", "\n", "# Assume init_rnn_state already shaped: [N,B,H]", "\n", "        ", "prev_action", "=", "self", ".", "distribution", ".", "to_onehot", "(", "prev_action", ")", "\n", "model_inputs", "=", "buffer_to", "(", "(", "observation", ",", "prev_action", ",", "prev_reward", ",", "init_rnn_state", ")", ",", "\n", "device", "=", "self", ".", "device", ")", "\n", "target_q", ",", "rnn_state", "=", "self", ".", "target_model", "(", "*", "model_inputs", ")", "\n", "return", "target_q", ".", "cpu", "(", ")", ",", "rnn_state", "# Leave rnn state on device.", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.dqn.catdqn_agent.CatDqnAgent.__init__": [[16, 20], ["rlpyt.agents.dqn.dqn_agent.DqnAgent.__init__"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.spaces.gym_wrapper.GymSpaceWrapper.__init__"], ["def", "__init__", "(", "self", ",", "n_atoms", "=", "51", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"Standard init, and set the number of probability atoms (bins).\"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "self", ".", "n_atoms", "=", "self", ".", "model_kwargs", "[", "\"n_atoms\"", "]", "=", "n_atoms", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.dqn.catdqn_agent.CatDqnAgent.initialize": [[21, 27], ["super().initialize", "rlpyt.distributions.epsilon_greedy.CategoricalEpsilonGreedy", "torch.linspace"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.safe.cppo_agent.CppoLstmAgent.initialize"], ["", "def", "initialize", "(", "self", ",", "env_spaces", ",", "share_memory", "=", "False", ",", "\n", "global_B", "=", "1", ",", "env_ranks", "=", "None", ")", ":", "\n", "        ", "super", "(", ")", ".", "initialize", "(", "env_spaces", ",", "share_memory", ",", "global_B", ",", "env_ranks", ")", "\n", "# Overwrite distribution.", "\n", "self", ".", "distribution", "=", "CategoricalEpsilonGreedy", "(", "dim", "=", "env_spaces", ".", "action", ".", "n", ",", "\n", "z", "=", "torch", ".", "linspace", "(", "-", "1", ",", "1", ",", "self", ".", "n_atoms", ")", ")", "# z placeholder for init.", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.dqn.catdqn_agent.CatDqnAgent.give_V_min_max": [[28, 32], ["catdqn_agent.CatDqnAgent.distribution.set_z", "torch.linspace"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.distributions.epsilon_greedy.CategoricalEpsilonGreedy.set_z"], ["", "def", "give_V_min_max", "(", "self", ",", "V_min", ",", "V_max", ")", ":", "\n", "        ", "self", ".", "V_min", "=", "V_min", "\n", "self", ".", "V_max", "=", "V_max", "\n", "self", ".", "distribution", ".", "set_z", "(", "torch", ".", "linspace", "(", "V_min", ",", "V_max", ",", "self", ".", "n_atoms", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.dqn.catdqn_agent.CatDqnAgent.step": [[33, 46], ["torch.no_grad", "catdqn_agent.CatDqnAgent.distribution.to_onehot", "rlpyt.utils.buffer.buffer_to", "catdqn_agent.CatDqnAgent.model", "p.cpu.cpu.cpu", "catdqn_agent.CatDqnAgent.distribution.sample", "AgentInfo", "rlpyt.utils.buffer.buffer_to", "rlpyt.agents.base.AgentStep"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.distributions.discrete.DiscreteMixin.to_onehot", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.buffer.buffer_to", "home.repos.pwc.inspect_result.astooke_rlpyt.spaces.gym_wrapper.GymSpaceWrapper.sample", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.buffer.buffer_to"], ["", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "step", "(", "self", ",", "observation", ",", "prev_action", ",", "prev_reward", ")", ":", "\n", "        ", "\"\"\"Compute the discrete distribution for the Q-value for each\n        action for each state/observation (no grad).\"\"\"", "\n", "prev_action", "=", "self", ".", "distribution", ".", "to_onehot", "(", "prev_action", ")", "\n", "model_inputs", "=", "buffer_to", "(", "(", "observation", ",", "prev_action", ",", "prev_reward", ")", ",", "\n", "device", "=", "self", ".", "device", ")", "\n", "p", "=", "self", ".", "model", "(", "*", "model_inputs", ")", "\n", "p", "=", "p", ".", "cpu", "(", ")", "\n", "action", "=", "self", ".", "distribution", ".", "sample", "(", "p", ")", "\n", "agent_info", "=", "AgentInfo", "(", "p", "=", "p", ")", "# Only change from DQN: q -> p.", "\n", "action", ",", "agent_info", "=", "buffer_to", "(", "(", "action", ",", "agent_info", ")", ",", "device", "=", "\"cpu\"", ")", "\n", "return", "AgentStep", "(", "action", "=", "action", ",", "agent_info", "=", "agent_info", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.astooke_rlpyt.dqn.dqn_agent.DqnAgent.__call__": [[23, 30], ["dqn_agent.DqnAgent.distribution.to_onehot", "rlpyt.utils.buffer.buffer_to", "dqn_agent.DqnAgent.model", "dqn_agent.DqnAgent.cpu"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.distributions.discrete.DiscreteMixin.to_onehot", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.buffer.buffer_to"], ["def", "__call__", "(", "self", ",", "observation", ",", "prev_action", ",", "prev_reward", ")", ":", "\n", "        ", "\"\"\"Returns Q-values for states/observations (with grad).\"\"\"", "\n", "prev_action", "=", "self", ".", "distribution", ".", "to_onehot", "(", "prev_action", ")", "\n", "model_inputs", "=", "buffer_to", "(", "(", "observation", ",", "prev_action", ",", "prev_reward", ")", ",", "\n", "device", "=", "self", ".", "device", ")", "\n", "q", "=", "self", ".", "model", "(", "*", "model_inputs", ")", "\n", "return", "q", ".", "cpu", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.dqn.dqn_agent.DqnAgent.initialize": [[31, 48], ["super().initialize", "dqn_agent.DqnAgent.ModelCls", "rlpyt.distributions.epsilon_greedy.EpsilonGreedy", "dqn_agent.DqnAgent.model.load_state_dict", "dqn_agent.DqnAgent.target_model.load_state_dict", "dqn_agent.DqnAgent.make_vec_eps"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.safe.cppo_agent.CppoLstmAgent.initialize", "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.augmented_temporal_similarity.AugmentedTemporalSimilarity.load_state_dict", "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.augmented_temporal_similarity.AugmentedTemporalSimilarity.load_state_dict", "home.repos.pwc.inspect_result.astooke_rlpyt.dqn.epsilon_greedy.EpsilonGreedyAgentMixin.make_vec_eps"], ["", "def", "initialize", "(", "self", ",", "env_spaces", ",", "share_memory", "=", "False", ",", "\n", "global_B", "=", "1", ",", "env_ranks", "=", "None", ")", ":", "\n", "        ", "\"\"\"Along with standard initialization, creates vector-valued epsilon\n        for exploration, if applicable, with a different epsilon for each\n        environment instance.\"\"\"", "\n", "_initial_model_state_dict", "=", "self", ".", "initial_model_state_dict", "\n", "self", ".", "initial_model_state_dict", "=", "None", "# don't let base agent try to initialize model", "\n", "super", "(", ")", ".", "initialize", "(", "env_spaces", ",", "share_memory", ",", "\n", "global_B", "=", "global_B", ",", "env_ranks", "=", "env_ranks", ")", "\n", "self", ".", "target_model", "=", "self", ".", "ModelCls", "(", "**", "self", ".", "env_model_kwargs", ",", "\n", "**", "self", ".", "model_kwargs", ")", "\n", "if", "_initial_model_state_dict", "is", "not", "None", ":", "\n", "            ", "self", ".", "model", ".", "load_state_dict", "(", "_initial_model_state_dict", "[", "'model'", "]", ")", "\n", "self", ".", "target_model", ".", "load_state_dict", "(", "_initial_model_state_dict", "[", "'model'", "]", ")", "\n", "", "self", ".", "distribution", "=", "EpsilonGreedy", "(", "dim", "=", "env_spaces", ".", "action", ".", "n", ")", "\n", "if", "env_ranks", "is", "not", "None", ":", "\n", "            ", "self", ".", "make_vec_eps", "(", "global_B", ",", "env_ranks", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.dqn.dqn_agent.DqnAgent.to_device": [[49, 52], ["super().to_device", "dqn_agent.DqnAgent.target_model.to"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.safe.cppo_agent.CppoLstmAgent.to_device"], ["", "", "def", "to_device", "(", "self", ",", "cuda_idx", "=", "None", ")", ":", "\n", "        ", "super", "(", ")", ".", "to_device", "(", "cuda_idx", ")", "\n", "self", ".", "target_model", ".", "to", "(", "self", ".", "device", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.dqn.dqn_agent.DqnAgent.state_dict": [[53, 56], ["dict", "dqn_agent.DqnAgent.model.state_dict", "dqn_agent.DqnAgent.target_model.state_dict"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.replay_saver.DummyOptimizer.state_dict", "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.replay_saver.DummyOptimizer.state_dict"], ["", "def", "state_dict", "(", "self", ")", ":", "\n", "        ", "return", "dict", "(", "model", "=", "self", ".", "model", ".", "state_dict", "(", ")", ",", "\n", "target", "=", "self", ".", "target_model", ".", "state_dict", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.dqn.dqn_agent.DqnAgent.step": [[57, 70], ["torch.no_grad", "dqn_agent.DqnAgent.distribution.to_onehot", "rlpyt.utils.buffer.buffer_to", "dqn_agent.DqnAgent.model", "q.cpu.cpu.cpu", "dqn_agent.DqnAgent.distribution.sample", "AgentInfo", "rlpyt.agents.base.AgentStep"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.distributions.discrete.DiscreteMixin.to_onehot", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.buffer.buffer_to", "home.repos.pwc.inspect_result.astooke_rlpyt.spaces.gym_wrapper.GymSpaceWrapper.sample"], ["", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "step", "(", "self", ",", "observation", ",", "prev_action", ",", "prev_reward", ")", ":", "\n", "        ", "\"\"\"Computes Q-values for states/observations and selects actions by\n        epsilon-greedy. (no grad)\"\"\"", "\n", "prev_action", "=", "self", ".", "distribution", ".", "to_onehot", "(", "prev_action", ")", "\n", "model_inputs", "=", "buffer_to", "(", "(", "observation", ",", "prev_action", ",", "prev_reward", ")", ",", "\n", "device", "=", "self", ".", "device", ")", "\n", "q", "=", "self", ".", "model", "(", "*", "model_inputs", ")", "\n", "q", "=", "q", ".", "cpu", "(", ")", "\n", "action", "=", "self", ".", "distribution", ".", "sample", "(", "q", ")", "\n", "agent_info", "=", "AgentInfo", "(", "q", "=", "q", ")", "\n", "# action, agent_info = buffer_to((action, agent_info), device=\"cpu\")", "\n", "return", "AgentStep", "(", "action", "=", "action", ",", "agent_info", "=", "agent_info", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.dqn.dqn_agent.DqnAgent.target": [[71, 78], ["dqn_agent.DqnAgent.distribution.to_onehot", "rlpyt.utils.buffer.buffer_to", "dqn_agent.DqnAgent.target_model", "dqn_agent.DqnAgent.cpu"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.distributions.discrete.DiscreteMixin.to_onehot", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.buffer.buffer_to"], ["", "def", "target", "(", "self", ",", "observation", ",", "prev_action", ",", "prev_reward", ")", ":", "\n", "        ", "\"\"\"Returns the target Q-values for states/observations.\"\"\"", "\n", "prev_action", "=", "self", ".", "distribution", ".", "to_onehot", "(", "prev_action", ")", "\n", "model_inputs", "=", "buffer_to", "(", "(", "observation", ",", "prev_action", ",", "prev_reward", ")", ",", "\n", "device", "=", "self", ".", "device", ")", "\n", "target_q", "=", "self", ".", "target_model", "(", "*", "model_inputs", ")", "\n", "return", "target_q", ".", "cpu", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.dqn.dqn_agent.DqnAgent.update_target": [[79, 82], ["rlpyt.models.utils.update_state_dict", "dqn_agent.DqnAgent.model.state_dict"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.models.utils.update_state_dict", "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.replay_saver.DummyOptimizer.state_dict"], ["", "def", "update_target", "(", "self", ",", "tau", "=", "1", ")", ":", "\n", "        ", "\"\"\"Copies the model parameters into the target model.\"\"\"", "\n", "update_state_dict", "(", "self", ".", "target_model", ",", "self", ".", "model", ".", "state_dict", "(", ")", ",", "tau", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.astooke_rlpyt.dqn.atari_catdqn_model.DistributionalHeadModel.__init__": [[14, 19], ["super().__init__", "rlpyt.models.mlp.MlpModel"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.spaces.gym_wrapper.GymSpaceWrapper.__init__"], ["def", "__init__", "(", "self", ",", "input_size", ",", "layer_sizes", ",", "output_size", ",", "n_atoms", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "mlp", "=", "MlpModel", "(", "input_size", ",", "layer_sizes", ",", "output_size", "*", "n_atoms", ")", "\n", "self", ".", "_output_size", "=", "output_size", "\n", "self", ".", "_n_atoms", "=", "n_atoms", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.dqn.atari_catdqn_model.DistributionalHeadModel.forward": [[20, 22], ["atari_catdqn_model.DistributionalHeadModel.mlp().view", "atari_catdqn_model.DistributionalHeadModel.mlp"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input", ")", ":", "\n", "        ", "return", "self", ".", "mlp", "(", "input", ")", ".", "view", "(", "-", "1", ",", "self", ".", "_output_size", ",", "self", ".", "_n_atoms", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.dqn.atari_catdqn_model.AtariCatDqnModel.__init__": [[28, 61], ["super().__init__", "rlpyt.models.conv2d.Conv2dModel", "atari_catdqn_model.AtariCatDqnModel.conv.conv_out_size", "rlpyt.models.dqn.dueling.DistributionalDuelingHeadModel", "atari_catdqn_model.DistributionalHeadModel"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.spaces.gym_wrapper.GymSpaceWrapper.__init__", "home.repos.pwc.inspect_result.astooke_rlpyt.rl.atari_rl_models.AtariDqnModel.conv_out_size"], ["def", "__init__", "(", "\n", "self", ",", "\n", "image_shape", ",", "\n", "output_size", ",", "\n", "n_atoms", "=", "51", ",", "\n", "fc_sizes", "=", "512", ",", "\n", "dueling", "=", "False", ",", "\n", "use_maxpool", "=", "False", ",", "\n", "channels", "=", "None", ",", "# None uses default.", "\n", "kernel_sizes", "=", "None", ",", "\n", "strides", "=", "None", ",", "\n", "paddings", "=", "None", ",", "\n", ")", ":", "\n", "        ", "\"\"\"Instantiates the neural network according to arguments; network defaults\n        stored within this method.\"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dueling", "=", "dueling", "\n", "c", ",", "h", ",", "w", "=", "image_shape", "\n", "self", ".", "conv", "=", "Conv2dModel", "(", "\n", "in_channels", "=", "c", ",", "\n", "channels", "=", "channels", "or", "[", "32", ",", "64", ",", "64", "]", ",", "\n", "kernel_sizes", "=", "kernel_sizes", "or", "[", "8", ",", "4", ",", "3", "]", ",", "\n", "strides", "=", "strides", "or", "[", "4", ",", "2", ",", "1", "]", ",", "\n", "paddings", "=", "paddings", "or", "[", "0", ",", "1", ",", "1", "]", ",", "\n", "use_maxpool", "=", "use_maxpool", ",", "\n", ")", "\n", "conv_out_size", "=", "self", ".", "conv", ".", "conv_out_size", "(", "h", ",", "w", ")", "\n", "if", "dueling", ":", "\n", "            ", "self", ".", "head", "=", "DistributionalDuelingHeadModel", "(", "conv_out_size", ",", "fc_sizes", ",", "\n", "output_size", "=", "output_size", ",", "n_atoms", "=", "n_atoms", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "head", "=", "DistributionalHeadModel", "(", "conv_out_size", ",", "fc_sizes", ",", "\n", "output_size", "=", "output_size", ",", "n_atoms", "=", "n_atoms", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.dqn.atari_catdqn_model.AtariCatDqnModel.forward": [[62, 78], ["observation.type", "img.mul_.mul_.mul_", "rlpyt.utils.tensor.infer_leading_dims", "atari_catdqn_model.AtariCatDqnModel.conv", "atari_catdqn_model.AtariCatDqnModel.head", "torch.softmax", "torch.softmax", "rlpyt.utils.tensor.restore_leading_dims", "img.mul_.mul_.view", "atari_catdqn_model.AtariCatDqnModel.view"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.utils.tensor.infer_leading_dims", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.tensor.restore_leading_dims"], ["", "", "def", "forward", "(", "self", ",", "observation", ",", "prev_action", ",", "prev_reward", ")", ":", "\n", "        ", "\"\"\"Returns the probability masses ``num_atoms x num_actions`` for the Q-values\n        for each state/observation, using softmax output nonlinearity.\"\"\"", "\n", "img", "=", "observation", ".", "type", "(", "torch", ".", "float", ")", "# Expect torch.uint8 inputs", "\n", "img", "=", "img", ".", "mul_", "(", "1.", "/", "255", ")", "# From [0-255] to [0-1], in place.", "\n", "\n", "# Infer (presence of) leading dimensions: [T,B], [B], or [].", "\n", "lead_dim", ",", "T", ",", "B", ",", "img_shape", "=", "infer_leading_dims", "(", "img", ",", "3", ")", "\n", "\n", "conv_out", "=", "self", ".", "conv", "(", "img", ".", "view", "(", "T", "*", "B", ",", "*", "img_shape", ")", ")", "# Fold if T dimension.", "\n", "p", "=", "self", ".", "head", "(", "conv_out", ".", "view", "(", "T", "*", "B", ",", "-", "1", ")", ")", "\n", "p", "=", "F", ".", "softmax", "(", "p", ",", "dim", "=", "-", "1", ")", "\n", "\n", "# Restore leading dimensions: [T,B], [B], or [], as input.", "\n", "p", "=", "restore_leading_dims", "(", "p", ",", "lead_dim", ",", "T", ",", "B", ")", "\n", "return", "p", "\n", "", "", ""]], "home.repos.pwc.inspect_result.astooke_rlpyt.dqn.atari_r2d1_model.AtariR2d1Model.__init__": [[18, 50], ["super().__init__", "rlpyt.models.conv2d.Conv2dHeadModel", "torch.nn.LSTM", "rlpyt.models.dqn.dueling.DuelingHeadModel", "rlpyt.models.mlp.MlpModel"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.spaces.gym_wrapper.GymSpaceWrapper.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "image_shape", ",", "\n", "output_size", ",", "\n", "fc_size", "=", "512", ",", "# Between conv and lstm.", "\n", "lstm_size", "=", "512", ",", "\n", "head_size", "=", "512", ",", "\n", "dueling", "=", "False", ",", "\n", "use_maxpool", "=", "False", ",", "\n", "channels", "=", "None", ",", "# None uses default.", "\n", "kernel_sizes", "=", "None", ",", "\n", "strides", "=", "None", ",", "\n", "paddings", "=", "None", ",", "\n", ")", ":", "\n", "        ", "\"\"\"Instantiates the neural network according to arguments; network defaults\n        stored within this method.\"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dueling", "=", "dueling", "\n", "self", ".", "conv", "=", "Conv2dHeadModel", "(", "\n", "image_shape", "=", "image_shape", ",", "\n", "channels", "=", "channels", "or", "[", "32", ",", "64", ",", "64", "]", ",", "\n", "kernel_sizes", "=", "kernel_sizes", "or", "[", "8", ",", "4", ",", "3", "]", ",", "\n", "strides", "=", "strides", "or", "[", "4", ",", "2", ",", "1", "]", ",", "\n", "paddings", "=", "paddings", "or", "[", "0", ",", "1", ",", "1", "]", ",", "\n", "use_maxpool", "=", "use_maxpool", ",", "\n", "hidden_sizes", "=", "fc_size", ",", "# ReLU applied here (Steven).", "\n", ")", "\n", "self", ".", "lstm", "=", "torch", ".", "nn", ".", "LSTM", "(", "self", ".", "conv", ".", "output_size", "+", "output_size", "+", "1", ",", "lstm_size", ")", "\n", "if", "dueling", ":", "\n", "            ", "self", ".", "head", "=", "DuelingHeadModel", "(", "lstm_size", ",", "head_size", ",", "output_size", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "head", "=", "MlpModel", "(", "lstm_size", ",", "head_size", ",", "output_size", "=", "output_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.dqn.atari_r2d1_model.AtariR2d1Model.forward": [[51, 78], ["observation.type", "img.mul_.mul_.mul_", "rlpyt.utils.tensor.infer_leading_dims", "atari_r2d1_model.AtariR2d1Model.conv", "torch.cat", "atari_r2d1_model.AtariR2d1Model.lstm", "atari_r2d1_model.AtariR2d1Model.head", "rlpyt.utils.tensor.restore_leading_dims", "RnnState", "img.mul_.mul_.view", "tuple", "lstm_out.view", "atari_r2d1_model.AtariR2d1Model.view", "prev_action.view", "prev_reward.view"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.utils.tensor.infer_leading_dims", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.tensor.restore_leading_dims"], ["", "", "def", "forward", "(", "self", ",", "observation", ",", "prev_action", ",", "prev_reward", ",", "init_rnn_state", ")", ":", "\n", "        ", "\"\"\"Feedforward layers process as [T*B,H]. Return same leading dims as\n        input, can be [T,B], [B], or [].\"\"\"", "\n", "img", "=", "observation", ".", "type", "(", "torch", ".", "float", ")", "# Expect torch.uint8 inputs", "\n", "img", "=", "img", ".", "mul_", "(", "1.", "/", "255", ")", "# From [0-255] to [0-1], in place.", "\n", "\n", "# Infer (presence of) leading dimensions: [T,B], [B], or [].", "\n", "lead_dim", ",", "T", ",", "B", ",", "img_shape", "=", "infer_leading_dims", "(", "img", ",", "3", ")", "\n", "\n", "conv_out", "=", "self", ".", "conv", "(", "img", ".", "view", "(", "T", "*", "B", ",", "*", "img_shape", ")", ")", "# Fold if T dimension.", "\n", "\n", "lstm_input", "=", "torch", ".", "cat", "(", "[", "\n", "conv_out", ".", "view", "(", "T", ",", "B", ",", "-", "1", ")", ",", "\n", "prev_action", ".", "view", "(", "T", ",", "B", ",", "-", "1", ")", ",", "# Assumed onehot.", "\n", "prev_reward", ".", "view", "(", "T", ",", "B", ",", "1", ")", ",", "\n", "]", ",", "dim", "=", "2", ")", "\n", "init_rnn_state", "=", "None", "if", "init_rnn_state", "is", "None", "else", "tuple", "(", "init_rnn_state", ")", "\n", "lstm_out", ",", "(", "hn", ",", "cn", ")", "=", "self", ".", "lstm", "(", "lstm_input", ",", "init_rnn_state", ")", "\n", "\n", "q", "=", "self", ".", "head", "(", "lstm_out", ".", "view", "(", "T", "*", "B", ",", "-", "1", ")", ")", "\n", "\n", "# Restore leading dimensions: [T,B], [B], or [], as input.", "\n", "q", "=", "restore_leading_dims", "(", "q", ",", "lead_dim", ",", "T", ",", "B", ")", "\n", "# Model should always leave B-dimension in rnn state: [N,B,H].", "\n", "next_rnn_state", "=", "RnnState", "(", "h", "=", "hn", ",", "c", "=", "cn", ")", "\n", "\n", "return", "q", ",", "next_rnn_state", "\n", "", "", ""]], "home.repos.pwc.inspect_result.astooke_rlpyt.dqn.dueling.DuelingHeadModel.__init__": [[17, 33], ["super().__init__", "isinstance", "rlpyt.models.mlp.MlpModel", "torch.nn.Linear", "torch.nn.Parameter", "rlpyt.models.mlp.MlpModel", "torch.zeros"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.spaces.gym_wrapper.GymSpaceWrapper.__init__", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.misc.zeros"], ["def", "__init__", "(", "\n", "self", ",", "\n", "input_size", ",", "\n", "hidden_sizes", ",", "\n", "output_size", ",", "\n", "grad_scale", "=", "2", "**", "(", "-", "1", "/", "2", ")", ",", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "if", "isinstance", "(", "hidden_sizes", ",", "int", ")", ":", "\n", "            ", "hidden_sizes", "=", "[", "hidden_sizes", "]", "\n", "", "self", ".", "advantage_hidden", "=", "MlpModel", "(", "input_size", ",", "hidden_sizes", ")", "\n", "self", ".", "advantage_out", "=", "torch", ".", "nn", ".", "Linear", "(", "hidden_sizes", "[", "-", "1", "]", ",", "output_size", ",", "\n", "bias", "=", "False", ")", "\n", "self", ".", "advantage_bias", "=", "torch", ".", "nn", ".", "Parameter", "(", "torch", ".", "zeros", "(", "1", ")", ")", "\n", "self", ".", "value", "=", "MlpModel", "(", "input_size", ",", "hidden_sizes", ",", "output_size", "=", "1", ")", "\n", "self", ".", "_grad_scale", "=", "grad_scale", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.dqn.dueling.DuelingHeadModel.forward": [[34, 41], ["rlpyt.models.utils.scale_grad", "dueling.DuelingHeadModel.advantage", "dueling.DuelingHeadModel.value", "dueling.DuelingHeadModel.mean"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.dqn.dueling.DistributionalDuelingHeadModel.advantage", "home.repos.pwc.inspect_result.astooke_rlpyt.safe.cppo_agent.CppoLstmAgent.value"], ["", "def", "forward", "(", "self", ",", "input", ")", ":", "\n", "        ", "\"\"\"Computes Q-values through value and advantage heads; applies gradient\n        scaling.\"\"\"", "\n", "x", "=", "scale_grad", "(", "input", ",", "self", ".", "_grad_scale", ")", "\n", "advantage", "=", "self", ".", "advantage", "(", "x", ")", "\n", "value", "=", "self", ".", "value", "(", "x", ")", "\n", "return", "value", "+", "(", "advantage", "-", "advantage", ".", "mean", "(", "dim", "=", "-", "1", ",", "keepdim", "=", "True", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.dqn.dueling.DuelingHeadModel.advantage": [[42, 46], ["dueling.DuelingHeadModel.advantage_hidden", "dueling.DuelingHeadModel.advantage_out"], "methods", ["None"], ["", "def", "advantage", "(", "self", ",", "input", ")", ":", "\n", "        ", "\"\"\"Computes shared-bias advantages.\"\"\"", "\n", "x", "=", "self", ".", "advantage_hidden", "(", "input", ")", "\n", "return", "self", ".", "advantage_out", "(", "x", ")", "+", "self", ".", "advantage_bias", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.dqn.dueling.DistributionalDuelingHeadModel.__init__": [[54, 73], ["super().__init__", "isinstance", "rlpyt.models.mlp.MlpModel", "torch.nn.Linear", "torch.nn.Parameter", "rlpyt.models.mlp.MlpModel", "torch.zeros"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.spaces.gym_wrapper.GymSpaceWrapper.__init__", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.misc.zeros"], ["def", "__init__", "(", "\n", "self", ",", "\n", "input_size", ",", "\n", "hidden_sizes", ",", "\n", "output_size", ",", "\n", "n_atoms", ",", "\n", "grad_scale", "=", "2", "**", "(", "-", "1", "/", "2", ")", ",", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "if", "isinstance", "(", "hidden_sizes", ",", "int", ")", ":", "\n", "            ", "hidden_sizes", "=", "[", "hidden_sizes", "]", "\n", "", "self", ".", "advantage_hidden", "=", "MlpModel", "(", "input_size", ",", "hidden_sizes", ")", "\n", "self", ".", "advantage_out", "=", "torch", ".", "nn", ".", "Linear", "(", "hidden_sizes", "[", "-", "1", "]", ",", "\n", "output_size", "*", "n_atoms", ",", "bias", "=", "False", ")", "\n", "self", ".", "advantage_bias", "=", "torch", ".", "nn", ".", "Parameter", "(", "torch", ".", "zeros", "(", "n_atoms", ")", ")", "\n", "self", ".", "value", "=", "MlpModel", "(", "input_size", ",", "hidden_sizes", ",", "output_size", "=", "n_atoms", ")", "\n", "self", ".", "_grad_scale", "=", "grad_scale", "\n", "self", ".", "_output_size", "=", "output_size", "\n", "self", ".", "_n_atoms", "=", "n_atoms", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.dqn.dueling.DistributionalDuelingHeadModel.forward": [[74, 79], ["rlpyt.models.utils.scale_grad", "dueling.DistributionalDuelingHeadModel.advantage", "dueling.DistributionalDuelingHeadModel.value().view", "dueling.DistributionalDuelingHeadModel.value", "dueling.DistributionalDuelingHeadModel.mean"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.dqn.dueling.DistributionalDuelingHeadModel.advantage", "home.repos.pwc.inspect_result.astooke_rlpyt.safe.cppo_agent.CppoLstmAgent.value"], ["", "def", "forward", "(", "self", ",", "input", ")", ":", "\n", "        ", "x", "=", "scale_grad", "(", "input", ",", "self", ".", "_grad_scale", ")", "\n", "advantage", "=", "self", ".", "advantage", "(", "x", ")", "\n", "value", "=", "self", ".", "value", "(", "x", ")", ".", "view", "(", "-", "1", ",", "1", ",", "self", ".", "_n_atoms", ")", "\n", "return", "value", "+", "(", "advantage", "-", "advantage", ".", "mean", "(", "dim", "=", "1", ",", "keepdim", "=", "True", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.dqn.dueling.DistributionalDuelingHeadModel.advantage": [[80, 85], ["dueling.DistributionalDuelingHeadModel.advantage_hidden", "dueling.DistributionalDuelingHeadModel.advantage_out", "x.view.view.view"], "methods", ["None"], ["", "def", "advantage", "(", "self", ",", "input", ")", ":", "\n", "        ", "x", "=", "self", ".", "advantage_hidden", "(", "input", ")", "\n", "x", "=", "self", ".", "advantage_out", "(", "x", ")", "\n", "x", "=", "x", ".", "view", "(", "-", "1", ",", "self", ".", "_output_size", ",", "self", ".", "_n_atoms", ")", "\n", "return", "x", "+", "self", ".", "advantage_bias", "\n", "", "", ""]], "home.repos.pwc.inspect_result.astooke_rlpyt.dqn.atari_dqn_model.AtariDqnModel.__init__": [[16, 46], ["super().__init__", "rlpyt.models.conv2d.Conv2dModel", "atari_dqn_model.AtariDqnModel.conv.conv_out_size", "rlpyt.models.dqn.dueling.DuelingHeadModel", "rlpyt.models.mlp.MlpModel"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.spaces.gym_wrapper.GymSpaceWrapper.__init__", "home.repos.pwc.inspect_result.astooke_rlpyt.rl.atari_rl_models.AtariDqnModel.conv_out_size"], ["def", "__init__", "(", "\n", "self", ",", "\n", "image_shape", ",", "\n", "output_size", ",", "\n", "fc_sizes", "=", "512", ",", "\n", "dueling", "=", "False", ",", "\n", "use_maxpool", "=", "False", ",", "\n", "channels", "=", "None", ",", "# None uses default.", "\n", "kernel_sizes", "=", "None", ",", "\n", "strides", "=", "None", ",", "\n", "paddings", "=", "None", ",", "\n", ")", ":", "\n", "        ", "\"\"\"Instantiates the neural network according to arguments; network defaults\n        stored within this method.\"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dueling", "=", "dueling", "\n", "c", ",", "h", ",", "w", "=", "image_shape", "\n", "self", ".", "conv", "=", "Conv2dModel", "(", "\n", "in_channels", "=", "c", ",", "\n", "channels", "=", "channels", "or", "[", "32", ",", "64", ",", "64", "]", ",", "\n", "kernel_sizes", "=", "kernel_sizes", "or", "[", "8", ",", "4", ",", "3", "]", ",", "\n", "strides", "=", "strides", "or", "[", "4", ",", "2", ",", "1", "]", ",", "\n", "paddings", "=", "paddings", "or", "[", "0", ",", "1", ",", "1", "]", ",", "\n", "use_maxpool", "=", "use_maxpool", ",", "\n", ")", "\n", "conv_out_size", "=", "self", ".", "conv", ".", "conv_out_size", "(", "h", ",", "w", ")", "\n", "if", "dueling", ":", "\n", "            ", "self", ".", "head", "=", "DuelingHeadModel", "(", "conv_out_size", ",", "fc_sizes", ",", "output_size", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "head", "=", "MlpModel", "(", "conv_out_size", ",", "fc_sizes", ",", "output_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.dqn.atari_dqn_model.AtariDqnModel.forward": [[47, 69], ["observation.type", "img.mul_.mul_.mul_", "rlpyt.utils.tensor.infer_leading_dims", "atari_dqn_model.AtariDqnModel.conv", "atari_dqn_model.AtariDqnModel.head", "rlpyt.utils.tensor.restore_leading_dims", "img.mul_.mul_.view", "atari_dqn_model.AtariDqnModel.view"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.utils.tensor.infer_leading_dims", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.tensor.restore_leading_dims"], ["", "", "def", "forward", "(", "self", ",", "observation", ",", "prev_action", ",", "prev_reward", ")", ":", "\n", "        ", "\"\"\"\n        Compute action Q-value estimates from input state.\n        Infers leading dimensions of input: can be [T,B], [B], or []; provides\n        returns with same leading dims.  Convolution layers process as [T*B,\n        image_shape[0], image_shape[1],...,image_shape[-1]], with T=1,B=1 when not given.  Expects uint8 images in\n        [0,255] and converts them to float32 in [0,1] (to minimize image data\n        storage and transfer).  Used in both sampler and in algorithm (both\n        via the agent).\n        \"\"\"", "\n", "img", "=", "observation", ".", "type", "(", "torch", ".", "float", ")", "# Expect torch.uint8 inputs", "\n", "img", "=", "img", ".", "mul_", "(", "1.", "/", "255", ")", "# From [0-255] to [0-1], in place.", "\n", "\n", "# Infer (presence of) leading dimensions: [T,B], [B], or [].", "\n", "lead_dim", ",", "T", ",", "B", ",", "img_shape", "=", "infer_leading_dims", "(", "img", ",", "3", ")", "\n", "\n", "conv_out", "=", "self", ".", "conv", "(", "img", ".", "view", "(", "T", "*", "B", ",", "*", "img_shape", ")", ")", "# Fold if T dimension.", "\n", "q", "=", "self", ".", "head", "(", "conv_out", ".", "view", "(", "T", "*", "B", ",", "-", "1", ")", ")", "\n", "\n", "# Restore leading dimensions: [T,B], [B], or [], as input.", "\n", "q", "=", "restore_leading_dims", "(", "q", ",", "lead_dim", ",", "T", ",", "B", ")", "\n", "return", "q", "\n", "", "", ""]], "home.repos.pwc.inspect_result.astooke_rlpyt.utils.array.select_at_indexes": [[5, 17], ["len", "int", "array.reshape", "s_flat.reshape", "numpy.prod", "numpy.arange", "indexes.reshape"], "function", ["None"], ["def", "select_at_indexes", "(", "indexes", ",", "array", ")", ":", "\n", "    ", "\"\"\"Returns the contents of ``array`` at the multi-dimensional integer\n    array ``indexes``. Leading dimensions of ``array`` must match the\n    dimensions of ``indexes``.\n    \"\"\"", "\n", "dim", "=", "len", "(", "indexes", ".", "shape", ")", "\n", "assert", "indexes", ".", "shape", "==", "array", ".", "shape", "[", ":", "dim", "]", "\n", "num", "=", "int", "(", "np", ".", "prod", "(", "indexes", ".", "shape", ")", ")", "\n", "a_flat", "=", "array", ".", "reshape", "(", "(", "num", ",", ")", "+", "array", ".", "shape", "[", "dim", ":", "]", ")", "\n", "s_flat", "=", "a_flat", "[", "np", ".", "arange", "(", "num", ")", ",", "indexes", ".", "reshape", "(", "-", "1", ")", "]", "\n", "selected", "=", "s_flat", ".", "reshape", "(", "array", ".", "shape", "[", ":", "dim", "]", "+", "array", ".", "shape", "[", "dim", "+", "1", ":", "]", ")", "\n", "return", "selected", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.utils.array.to_onehot": [[19, 27], ["numpy.zeros", "np.zeros.reshape", "numpy.arange", "indexes.reshape"], "function", ["home.repos.pwc.inspect_result.astooke_rlpyt.utils.misc.zeros"], ["", "def", "to_onehot", "(", "indexes", ",", "dim", ",", "dtype", "=", "None", ")", ":", "\n", "    ", "\"\"\"Converts integer values in multi-dimensional array ``indexes``\n    to one-hot values of size ``dim``; expanded in an additional\n    trailing dimension.\"\"\"", "\n", "dtype", "=", "indexes", ".", "dtype", "if", "dtype", "is", "None", "else", "dtype", "\n", "onehot", "=", "np", ".", "zeros", "(", "(", "indexes", ".", "size", ",", "dim", ")", ",", "dtype", "=", "dtype", ")", "\n", "onehot", "[", "np", ".", "arange", "(", "indexes", ".", "size", ")", ",", "indexes", ".", "reshape", "(", "-", "1", ")", "]", "=", "1", "\n", "return", "onehot", ".", "reshape", "(", "indexes", ".", "shape", "+", "(", "dim", ",", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.utils.array.from_onehot": [[29, 33], ["numpy.asarray", "numpy.argmax"], "function", ["None"], ["", "def", "from_onehot", "(", "onehot", ",", "dtype", "=", "None", ")", ":", "\n", "    ", "\"\"\"Argmax over trailing dimension of array ``onehot``. Optional return\n    dtype specification.\"\"\"", "\n", "return", "np", ".", "asarray", "(", "np", ".", "argmax", "(", "onehot", ",", "axis", "=", "-", "1", ")", ",", "dtype", "=", "dtype", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.utils.array.valid_mean": [[35, 41], ["array.mean", "valid.sum"], "function", ["None"], ["", "def", "valid_mean", "(", "array", ",", "valid", "=", "None", ",", "axis", "=", "None", ")", ":", "\n", "    ", "\"\"\"Mean of ``array``, accounting for optional mask ``valid``,\n    optionally along an axis.\"\"\"", "\n", "if", "valid", "is", "None", ":", "\n", "        ", "return", "array", ".", "mean", "(", "axis", "=", "axis", ")", "\n", "", "return", "(", "array", "*", "valid", ")", ".", "sum", "(", "axis", "=", "axis", ")", "/", "valid", ".", "sum", "(", "axis", "=", "axis", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.utils.array.infer_leading_dims": [[43, 61], ["len"], "function", ["None"], ["", "def", "infer_leading_dims", "(", "array", ",", "dim", ")", ":", "\n", "    ", "\"\"\"Determine any leading dimensions of ``array``, which can have up to two\n    leading dimensions more than the number of data dimensions, ``dim``.  Used\n    to check for [B] or [T,B] leading.  Returns size of leading dimensions (or\n    1 if they don't exist), the data shape, and whether the leading dimensions\n    where found.\n    \"\"\"", "\n", "assert", "array", ".", "ndim", "in", "(", "dim", ",", "dim", "+", "1", ",", "dim", "+", "2", ")", "\n", "shape", "=", "array", ".", "shape", "[", "len", "(", "array", ".", "shape", ")", "-", "dim", ":", "]", "\n", "T", "=", "B", "=", "1", "\n", "has_T", "=", "has_B", "=", "False", "\n", "if", "array", ".", "ndim", "==", "dim", "+", "2", ":", "\n", "        ", "T", ",", "B", "=", "array", ".", "shape", "[", ":", "2", "]", "\n", "has_T", "=", "has_B", "=", "True", "# Might have T=1 or B=1.", "\n", "", "elif", "array", ".", "ndim", "==", "dim", "+", "1", ":", "\n", "        ", "B", "=", "array", ".", "shape", "[", "0", "]", "\n", "has_B", "=", "True", "\n", "", "return", "T", ",", "B", ",", "shape", ",", "has_T", ",", "has_B", "\n", "", ""]], "home.repos.pwc.inspect_result.astooke_rlpyt.utils.prog_bar.ProgBarCounter.__init__": [[13, 22], ["rlpyt.utils.logging.logger.get_log_tabular_only", "pyprind.ProgBar"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.logging.logger.get_log_tabular_only"], ["def", "__init__", "(", "self", ",", "total_count", ")", ":", "\n", "        ", "self", ".", "total_count", "=", "total_count", "\n", "self", ".", "max_progress", "=", "1000000", "\n", "self", ".", "cur_progress", "=", "0", "\n", "self", ".", "cur_count", "=", "0", "\n", "if", "not", "logger", ".", "get_log_tabular_only", "(", ")", ":", "\n", "            ", "self", ".", "pbar", "=", "pyprind", ".", "ProgBar", "(", "self", ".", "max_progress", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "pbar", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.utils.prog_bar.ProgBarCounter.update": [[23, 30], ["rlpyt.utils.logging.logger.get_log_tabular_only", "prog_bar.ProgBarCounter.pbar.update"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.logging.logger.get_log_tabular_only", "home.repos.pwc.inspect_result.astooke_rlpyt.models.running_mean_std.RunningMeanStdModel.update"], ["", "", "def", "update", "(", "self", ",", "current_count", ")", ":", "\n", "        ", "if", "not", "logger", ".", "get_log_tabular_only", "(", ")", ":", "\n", "            ", "self", ".", "cur_count", "=", "current_count", "\n", "new_progress", "=", "self", ".", "cur_count", "*", "self", ".", "max_progress", "/", "self", ".", "total_count", "\n", "if", "new_progress", "<", "self", ".", "max_progress", ":", "\n", "                ", "self", ".", "pbar", ".", "update", "(", "new_progress", "-", "self", ".", "cur_progress", ")", "\n", "", "self", ".", "cur_progress", "=", "new_progress", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.utils.prog_bar.ProgBarCounter.stop": [[31, 34], ["prog_bar.ProgBarCounter.pbar.stop"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.utils.prog_bar.ProgBarCounter.stop"], ["", "", "def", "stop", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "pbar", "is", "not", "None", "and", "self", ".", "pbar", ".", "active", ":", "\n", "                ", "self", ".", "pbar", ".", "stop", "(", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.astooke_rlpyt.utils.buffer.np_mp_array_spawn.__new__": [[74, 99], ["numpy.ndarray.__new__", "int", "multiprocessing.RawArray", "isinstance", "numpy.prod", "ValueError", "numpy.dtype"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.utils.collections.NamedTuple.__new__", "home.repos.pwc.inspect_result.astooke_rlpyt.spaces.gym_wrapper.GymSpaceWrapper.dtype"], ["def", "__new__", "(", "cls", ",", "shape", ",", "dtype", "=", "None", ",", "buffer", "=", "None", ",", "offset", "=", "None", ",", "strides", "=", "None", ",", "\n", "order", "=", "None", ")", ":", "\n", "# init buffer", "\n", "        ", "if", "buffer", "is", "None", ":", "\n", "            ", "assert", "offset", "is", "None", "\n", "assert", "strides", "is", "None", "\n", "size", "=", "int", "(", "np", ".", "prod", "(", "shape", ")", ")", "\n", "nbytes", "=", "size", "*", "np", ".", "dtype", "(", "dtype", ")", ".", "itemsize", "\n", "# this is the part that can be passed between processes", "\n", "shmem", "=", "mp", ".", "RawArray", "(", "ctypes", ".", "c_char", ",", "nbytes", ")", "\n", "offset", "=", "0", "\n", "", "elif", "isinstance", "(", "buffer", ",", "ctypes", ".", "Array", ")", ":", "\n", "# restoring from a pickle", "\n", "            ", "shmem", "=", "buffer", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "f\"{cls.__name__} does not support specifying custom \"", "\n", "f\" buffers, but was given {buffer!r}\"", ")", "\n", "\n", "# init array", "\n", "", "obj", "=", "np", ".", "ndarray", ".", "__new__", "(", "cls", ",", "shape", ",", "dtype", "=", "dtype", ",", "buffer", "=", "shmem", ",", "\n", "offset", "=", "offset", ",", "strides", "=", "strides", ",", "order", "=", "order", ")", "\n", "obj", ".", "_shmem", "=", "shmem", "\n", "\n", "return", "obj", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.utils.buffer.np_mp_array_spawn.__array_finalize__": [[100, 103], ["None"], "methods", ["None"], ["", "def", "__array_finalize__", "(", "self", ",", "obj", ")", ":", "\n", "        ", "if", "obj", "is", "not", "None", ":", "\n", "            ", "self", ".", "_shmem", "=", "obj", ".", "_shmem", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.utils.buffer.np_mp_array_spawn.__reduce__": [[104, 118], ["ctypes.addressof", "len", "len", "type"], "methods", ["None"], ["", "", "def", "__reduce__", "(", "self", ")", ":", "\n", "# credit to https://stackoverflow.com/a/53534485 for awful/wonderful", "\n", "# __array_interface__ hack", "\n", "        ", "absolute_offset", "=", "self", ".", "__array_interface__", "[", "'data'", "]", "[", "0", "]", "\n", "base_address", "=", "ctypes", ".", "addressof", "(", "self", ".", "_shmem", ")", "\n", "offset", "=", "absolute_offset", "-", "base_address", "\n", "assert", "offset", "<=", "len", "(", "self", ".", "_shmem", ")", ",", "(", "offset", ",", "len", "(", "self", ".", "_shmem", ")", ")", "\n", "order", "=", "'FC'", "[", "self", ".", "flags", "[", "'C_CONTIGUOUS'", "]", "]", "\n", "# buffer should get pickled by np", "\n", "assert", "self", ".", "_shmem", "is", "not", "None", ",", "\"somehow this lost its _shmem reference\"", "\n", "newargs", "=", "(", "self", ".", "shape", ",", "self", ".", "dtype", ",", "self", ".", "_shmem", ",", "offset", ",", "self", ".", "strides", ",", "\n", "order", ")", "\n", "return", "(", "type", "(", "self", ")", ",", "newargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.utils.buffer.buffer_from_example": [[11, 39], ["rlpyt.utils.collections.namedarraytuple_like.", "isinstance", "rlpyt.utils.collections.NamedArrayTupleSchema_like", "rlpyt.utils.collections.namedarraytuple_like", "buffer.build_array", "buffer.buffer_from_example"], "function", ["home.repos.pwc.inspect_result.astooke_rlpyt.utils.collections.NamedArrayTupleSchema_like", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.collections.namedarraytuple_like", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.buffer.build_array", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.buffer.buffer_from_example"], ["def", "buffer_from_example", "(", "example", ",", "leading_dims", ",", "share_memory", "=", "False", ",", "\n", "use_NatSchema", "=", "None", ")", ":", "\n", "    ", "\"\"\"Allocates memory and returns it in `namedarraytuple` with same\n    structure as ``examples``, which should be a `namedtuple` or\n    `namedarraytuple`. Applies the same leading dimensions ``leading_dims`` to\n    every entry, and otherwise matches their shapes and dtypes. The examples\n    should have no leading dimensions.  ``None`` fields will stay ``None``.\n    Optionally allocate on OS shared memory. Uses ``build_array()``.\n    \n    New: can use NamedArrayTuple types by the `use_NatSchema` flag, which\n    may be easier for pickling/unpickling when using spawn instead\n    of fork. If use_NatSchema is None, the type of ``example`` will be used to\n    infer what type to return (this is the default)\n    \"\"\"", "\n", "if", "example", "is", "None", ":", "\n", "        ", "return", "\n", "", "if", "use_NatSchema", "is", "None", ":", "\n", "        ", "use_NatSchema", "=", "isinstance", "(", "example", ",", "(", "NamedTuple", ",", "NamedArrayTuple", ")", ")", "\n", "", "try", ":", "\n", "        ", "if", "use_NatSchema", ":", "\n", "            ", "buffer_type", "=", "NamedArrayTupleSchema_like", "(", "example", ")", "\n", "", "else", ":", "\n", "            ", "buffer_type", "=", "namedarraytuple_like", "(", "example", ")", "\n", "", "", "except", "TypeError", ":", "# example was not a namedtuple or namedarraytuple", "\n", "        ", "return", "build_array", "(", "example", ",", "leading_dims", ",", "share_memory", ")", "\n", "", "return", "buffer_type", "(", "*", "(", "buffer_from_example", "(", "v", ",", "leading_dims", ",", "\n", "share_memory", "=", "share_memory", ",", "use_NatSchema", "=", "use_NatSchema", ")", "\n", "for", "v", "in", "example", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.utils.buffer.build_array": [[41, 53], ["numpy.asarray", "constructor", "TypeError", "isinstance"], "function", ["None"], ["", "def", "build_array", "(", "example", ",", "leading_dims", ",", "share_memory", "=", "False", ")", ":", "\n", "    ", "\"\"\"Allocate a numpy array matchin the dtype and shape of example, possibly\n    with additional leading dimensions.  Optionally allocate on OS shared\n    memory.\n    \"\"\"", "\n", "a", "=", "np", ".", "asarray", "(", "example", ")", "\n", "if", "a", ".", "dtype", "==", "\"object\"", ":", "\n", "        ", "raise", "TypeError", "(", "\"Buffer example value cannot cast as np.dtype==object.\"", ")", "\n", "", "constructor", "=", "np_mp_array", "if", "share_memory", "else", "np", ".", "zeros", "\n", "if", "not", "isinstance", "(", "leading_dims", ",", "(", "list", ",", "tuple", ")", ")", ":", "\n", "        ", "leading_dims", "=", "(", "leading_dims", ",", ")", "\n", "", "return", "constructor", "(", "shape", "=", "leading_dims", "+", "a", ".", "shape", ",", "dtype", "=", "a", ".", "dtype", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.utils.buffer.np_mp_array": [[55, 63], ["int", "multiprocessing.RawArray", "numpy.frombuffer().reshape", "multiprocessing.get_start_method", "buffer.np_mp_array_spawn", "numpy.prod", "numpy.dtype", "numpy.frombuffer"], "function", ["home.repos.pwc.inspect_result.astooke_rlpyt.spaces.gym_wrapper.GymSpaceWrapper.dtype"], ["", "def", "np_mp_array", "(", "shape", ",", "dtype", ")", ":", "\n", "    ", "\"\"\"Allocate a numpy array on OS shared memory.\"\"\"", "\n", "if", "mp", ".", "get_start_method", "(", ")", "==", "\"spawn\"", ":", "\n", "        ", "return", "np_mp_array_spawn", "(", "shape", ",", "dtype", ")", "\n", "", "size", "=", "int", "(", "np", ".", "prod", "(", "shape", ")", ")", "\n", "nbytes", "=", "size", "*", "np", ".", "dtype", "(", "dtype", ")", ".", "itemsize", "\n", "mp_array", "=", "mp", ".", "RawArray", "(", "ctypes", ".", "c_char", ",", "nbytes", ")", "\n", "return", "np", ".", "frombuffer", "(", "mp_array", ",", "dtype", "=", "dtype", ",", "count", "=", "size", ")", ".", "reshape", "(", "shape", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.utils.buffer.torchify_buffer": [[120, 136], ["isinstance", "tuple", "buffer_._make", "torch.from_numpy", "isinstance", "type", "buffer.torchify_buffer"], "function", ["home.repos.pwc.inspect_result.astooke_rlpyt.utils.collections.NamedArrayTupleSchema._make", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.buffer.torchify_buffer"], ["", "", "def", "torchify_buffer", "(", "buffer_", ")", ":", "\n", "    ", "\"\"\"Convert contents of ``buffer_`` from numpy arrays to torch tensors.\n    ``buffer_`` can be an arbitrary structure of tuples, namedtuples,\n    namedarraytuples, NamedTuples, and NamedArrayTuples, and a new, matching\n    structure will be returned. ``None`` fields remain ``None``, and torch\n    tensors are left alone.\"\"\"", "\n", "if", "buffer_", "is", "None", ":", "\n", "        ", "return", "\n", "", "if", "isinstance", "(", "buffer_", ",", "np", ".", "ndarray", ")", ":", "\n", "        ", "return", "torch", ".", "from_numpy", "(", "buffer_", ")", "\n", "", "elif", "isinstance", "(", "buffer_", ",", "torch", ".", "Tensor", ")", ":", "\n", "        ", "return", "buffer_", "\n", "", "contents", "=", "tuple", "(", "torchify_buffer", "(", "b", ")", "for", "b", "in", "buffer_", ")", "\n", "if", "type", "(", "buffer_", ")", "is", "tuple", ":", "# tuple, namedtuple instantiate differently.", "\n", "        ", "return", "contents", "\n", "", "return", "buffer_", ".", "_make", "(", "contents", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.utils.buffer.numpify_buffer": [[138, 154], ["isinstance", "tuple", "buffer_._make", "buffer_.cpu().numpy", "isinstance", "type", "buffer.numpify_buffer", "buffer_.cpu"], "function", ["home.repos.pwc.inspect_result.astooke_rlpyt.utils.collections.NamedArrayTupleSchema._make", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.buffer.numpify_buffer"], ["", "def", "numpify_buffer", "(", "buffer_", ")", ":", "\n", "    ", "\"\"\"Convert contents of ``buffer_`` from torch tensors to numpy arrays.\n    ``buffer_`` can be an arbitrary structure of tuples, namedtuples,\n    namedarraytuples, NamedTuples, and NamedArrayTuples, and a new, matching\n    structure will be returned. ``None`` fields remain ``None``, and numpy\n    arrays are left alone.\"\"\"", "\n", "if", "buffer_", "is", "None", ":", "\n", "        ", "return", "\n", "", "if", "isinstance", "(", "buffer_", ",", "torch", ".", "Tensor", ")", ":", "\n", "        ", "return", "buffer_", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "", "elif", "isinstance", "(", "buffer_", ",", "np", ".", "ndarray", ")", ":", "\n", "        ", "return", "buffer_", "\n", "", "contents", "=", "tuple", "(", "numpify_buffer", "(", "b", ")", "for", "b", "in", "buffer_", ")", "\n", "if", "type", "(", "buffer_", ")", "is", "tuple", ":", "\n", "        ", "return", "contents", "\n", "", "return", "buffer_", ".", "_make", "(", "contents", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.utils.buffer.buffer_to": [[156, 171], ["isinstance", "tuple", "buffer_._make", "buffer_.to", "isinstance", "type", "TypeError", "buffer.buffer_to"], "function", ["home.repos.pwc.inspect_result.astooke_rlpyt.utils.collections.NamedArrayTupleSchema._make", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.buffer.buffer_to"], ["", "def", "buffer_to", "(", "buffer_", ",", "device", "=", "None", ")", ":", "\n", "    ", "\"\"\"Send contents of ``buffer_`` to specified device (contents must be\n    torch tensors.). ``buffer_`` can be an arbitrary structure of tuples,\n    namedtuples, namedarraytuples, NamedTuples and NamedArrayTuples, and a\n    new, matching structure will be returned.\"\"\"", "\n", "if", "buffer_", "is", "None", ":", "\n", "        ", "return", "\n", "", "if", "isinstance", "(", "buffer_", ",", "torch", ".", "Tensor", ")", ":", "\n", "        ", "return", "buffer_", ".", "to", "(", "device", ")", "\n", "", "elif", "isinstance", "(", "buffer_", ",", "np", ".", "ndarray", ")", ":", "\n", "        ", "raise", "TypeError", "(", "\"Cannot move numpy array to device.\"", ")", "\n", "", "contents", "=", "tuple", "(", "buffer_to", "(", "b", ",", "device", "=", "device", ")", "for", "b", "in", "buffer_", ")", "\n", "if", "type", "(", "buffer_", ")", "is", "tuple", ":", "\n", "        ", "return", "contents", "\n", "", "return", "buffer_", ".", "_make", "(", "contents", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.utils.buffer.buffer_method": [[173, 188], ["isinstance", "tuple", "buffer_._make", "type", "getattr", "buffer.buffer_method"], "function", ["home.repos.pwc.inspect_result.astooke_rlpyt.utils.collections.NamedArrayTupleSchema._make", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.buffer.buffer_method"], ["", "def", "buffer_method", "(", "buffer_", ",", "method_name", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Call method ``method_name(*args, **kwargs)`` on all contents of\n    ``buffer_``, and return the results. ``buffer_`` can be an arbitrary\n    structure of tuples, namedtuples, namedarraytuples, NamedTuples, and\n    NamedArrayTuples, and a new, matching structure will be returned.\n    ``None`` fields remain ``None``.\n    \"\"\"", "\n", "if", "buffer_", "is", "None", ":", "\n", "        ", "return", "\n", "", "if", "isinstance", "(", "buffer_", ",", "(", "torch", ".", "Tensor", ",", "np", ".", "ndarray", ")", ")", ":", "\n", "        ", "return", "getattr", "(", "buffer_", ",", "method_name", ")", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "", "contents", "=", "tuple", "(", "buffer_method", "(", "b", ",", "method_name", ",", "*", "args", ",", "**", "kwargs", ")", "for", "b", "in", "buffer_", ")", "\n", "if", "type", "(", "buffer_", ")", "is", "tuple", ":", "\n", "        ", "return", "contents", "\n", "", "return", "buffer_", ".", "_make", "(", "contents", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.utils.buffer.buffer_func": [[190, 206], ["isinstance", "tuple", "buffer_._make", "func", "type", "buffer.buffer_func"], "function", ["home.repos.pwc.inspect_result.astooke_rlpyt.utils.collections.NamedArrayTupleSchema._make", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.buffer.buffer_func"], ["", "def", "buffer_func", "(", "buffer_", ",", "func", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Call function ``func(buf, *args, **kwargs)`` on all contents of\n    ``buffer_``, and return the results.  ``buffer_`` can be an arbitrary\n    structure of tuples, namedtuples, namedarraytuples, NamedTuples, and\n    NamedArrayTuples, and a new, matching structure will be returned.\n    ``None`` fields remain ``None``.\n    \"\"\"", "\n", "if", "buffer_", "is", "None", ":", "\n", "        ", "return", "\n", "", "if", "isinstance", "(", "buffer_", ",", "(", "torch", ".", "Tensor", ",", "np", ".", "ndarray", ")", ")", ":", "\n", "        ", "return", "func", "(", "buffer_", ",", "*", "args", ",", "**", "kwargs", ")", "\n", "# contents = tuple(buffer_func(b, func, *args, **kwargs) for b in buffer_)", "\n", "", "contents", "=", "tuple", "(", "buffer_func", "(", "b", ",", "func", ",", "*", "args", ",", "**", "kwargs", ")", "for", "b", "in", "buffer_", ")", "\n", "if", "type", "(", "buffer_", ")", "is", "tuple", ":", "\n", "        ", "return", "contents", "\n", "", "return", "buffer_", ".", "_make", "(", "contents", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.utils.buffer.get_leading_dims": [[208, 221], ["isinstance", "tuple", "ValueError", "buffer.get_leading_dims", "len", "set"], "function", ["home.repos.pwc.inspect_result.astooke_rlpyt.utils.buffer.get_leading_dims"], ["", "def", "get_leading_dims", "(", "buffer_", ",", "n_dim", "=", "1", ")", ":", "\n", "    ", "\"\"\"Return the ``n_dim`` number of leading dimensions of the contents of\n    ``buffer_``. Checks to make sure the leading dimensions match for all\n    tensors/arrays, except ignores ``None`` fields.\n    \"\"\"", "\n", "if", "buffer_", "is", "None", ":", "\n", "        ", "return", "\n", "", "if", "isinstance", "(", "buffer_", ",", "(", "torch", ".", "Tensor", ",", "np", ".", "ndarray", ")", ")", ":", "\n", "        ", "return", "buffer_", ".", "shape", "[", ":", "n_dim", "]", "\n", "", "contents", "=", "tuple", "(", "get_leading_dims", "(", "b", ",", "n_dim", ")", "for", "b", "in", "buffer_", "if", "b", "is", "not", "None", ")", "\n", "if", "not", "len", "(", "set", "(", "contents", ")", ")", "==", "1", ":", "\n", "        ", "raise", "ValueError", "(", "f\"Found mismatched leading dimensions: {contents}\"", ")", "\n", "", "return", "contents", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.utils.shmemarray.ShmemBufferWrapper.__init__": [[55, 67], ["posix_ipc.SharedMemory", "mmap.mmap", "shmemarray.ShmemBufferWrapper._mem.close_fd"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "tag", ",", "size", ",", "create", "=", "True", ")", ":", "\n", "# default vals so __del__ doesn't fail if __init__ fails to complete", "\n", "        ", "self", ".", "_mem", "=", "None", "\n", "self", ".", "_map", "=", "None", "\n", "self", ".", "_owner", "=", "create", "\n", "self", ".", "size", "=", "size", "\n", "\n", "assert", "0", "<=", "size", "<", "sys", ".", "maxsize", "# sys.maxint  (python 3)", "\n", "flag", "=", "(", "0", ",", "posix_ipc", ".", "O_CREX", ")", "[", "create", "]", "\n", "self", ".", "_mem", "=", "posix_ipc", ".", "SharedMemory", "(", "tag", ",", "flags", "=", "flag", ",", "size", "=", "size", ")", "\n", "self", ".", "_map", "=", "mmap", ".", "mmap", "(", "self", ".", "_mem", ".", "fd", ",", "self", ".", "_mem", ".", "size", ")", "\n", "self", ".", "_mem", ".", "close_fd", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.utils.shmemarray.ShmemBufferWrapper.get_address": [[68, 74], ["shmemarray.address_of_buffer", "shmemarray.ShmemBufferWrapper._map.size"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.utils.shmemarray.address_of_buffer", "home.repos.pwc.inspect_result.astooke_rlpyt.samplers.collections.BatchSpec.size"], ["", "def", "get_address", "(", "self", ")", ":", "\n", "# addr, size = address_of_buffer(self._map)", "\n", "# assert size == self.size", "\n", "        ", "assert", "self", ".", "_map", ".", "size", "(", ")", "==", "self", ".", "size", "# (changed for python 3)", "\n", "addr", "=", "address_of_buffer", "(", "self", ".", "_map", ")", "\n", "return", "addr", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.utils.shmemarray.ShmemBufferWrapper.__del__": [[75, 80], ["shmemarray.ShmemBufferWrapper._map.close", "shmemarray.ShmemBufferWrapper._mem.unlink"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.envs.dmlab.DmlabEnv.close"], ["", "def", "__del__", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "_map", "is", "not", "None", ":", "\n", "            ", "self", ".", "_map", ".", "close", "(", ")", "\n", "", "if", "self", ".", "_mem", "is", "not", "None", "and", "self", ".", "_owner", ":", "\n", "            ", "self", ".", "_mem", ".", "unlink", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.utils.shmemarray.address_of_buffer": [[49, 51], ["ctypes.addressof", "ctypes.c_char.from_buffer"], "function", ["None"], ["def", "address_of_buffer", "(", "buf", ")", ":", "# (python 3)", "\n", "    ", "return", "ctypes", ".", "addressof", "(", "ctypes", ".", "c_char", ".", "from_buffer", "(", "buf", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.utils.shmemarray.ShmemRawArray": [[82, 101], ["frozenset().issubset", "typecode_to_type.get", "isinstance", "shmemarray.ShmemBufferWrapper", "typecode_to_type.get.from_address", "ctypes.sizeof", "shmemarray.ShmemBufferWrapper.get_address", "isinstance", "type_.from_address.__init__", "frozenset", "len", "ctypes.c_char"], "function", ["home.repos.pwc.inspect_result.astooke_rlpyt.utils.collections.NamedArrayTuple.get", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.shmemarray.ShmemBufferWrapper.get_address", "home.repos.pwc.inspect_result.astooke_rlpyt.spaces.gym_wrapper.GymSpaceWrapper.__init__"], ["", "", "", "def", "ShmemRawArray", "(", "typecode_or_type", ",", "size_or_initializer", ",", "tag", ",", "create", "=", "True", ")", ":", "\n", "    ", "assert", "frozenset", "(", "tag", ")", ".", "issubset", "(", "valid_chars", ")", "\n", "if", "tag", "[", "0", "]", "!=", "\"/\"", ":", "\n", "        ", "tag", "=", "\"/%s\"", "%", "(", "tag", ",", ")", "\n", "\n", "", "type_", "=", "typecode_to_type", ".", "get", "(", "typecode_or_type", ",", "typecode_or_type", ")", "\n", "if", "isinstance", "(", "size_or_initializer", ",", "int", ")", ":", "\n", "        ", "type_", "=", "type_", "*", "size_or_initializer", "\n", "", "else", ":", "\n", "        ", "type_", "=", "type_", "*", "len", "(", "size_or_initializer", ")", "\n", "\n", "", "buffer", "=", "ShmemBufferWrapper", "(", "tag", ",", "ctypes", ".", "sizeof", "(", "type_", ")", ",", "create", "=", "create", ")", "\n", "obj", "=", "type_", ".", "from_address", "(", "buffer", ".", "get_address", "(", ")", ")", "\n", "obj", ".", "_buffer", "=", "buffer", "\n", "\n", "if", "not", "isinstance", "(", "size_or_initializer", ",", "int", ")", ":", "\n", "        ", "obj", ".", "__init__", "(", "*", "size_or_initializer", ")", "\n", "\n", "", "return", "obj", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.utils.shmemarray.NpShmemArray": [[107, 112], ["int", "shmemarray.ShmemRawArray", "numpy.frombuffer().reshape", "numpy.prod", "numpy.dtype", "numpy.frombuffer"], "function", ["home.repos.pwc.inspect_result.astooke_rlpyt.utils.shmemarray.ShmemRawArray", "home.repos.pwc.inspect_result.astooke_rlpyt.spaces.gym_wrapper.GymSpaceWrapper.dtype"], ["", "def", "NpShmemArray", "(", "shape", ",", "dtype", ",", "tag", ",", "create", "=", "True", ")", ":", "\n", "    ", "size", "=", "int", "(", "np", ".", "prod", "(", "shape", ")", ")", "\n", "nbytes", "=", "size", "*", "np", ".", "dtype", "(", "dtype", ")", ".", "itemsize", "\n", "shmem", "=", "ShmemRawArray", "(", "ctypes", ".", "c_char", ",", "nbytes", ",", "tag", ",", "create", ")", "\n", "return", "np", ".", "frombuffer", "(", "shmem", ",", "dtype", "=", "dtype", ",", "count", "=", "size", ")", ".", "reshape", "(", "shape", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.utils.shmemarray.get_random_tag": [[114, 116], ["str().replace", "str", "time.time"], "function", ["None"], ["", "def", "get_random_tag", "(", ")", ":", "\n", "    ", "return", "str", "(", "time", ".", "time", "(", ")", ")", ".", "replace", "(", "\".\"", ",", "\"\"", ")", "[", "-", "9", ":", "]", "\n", "", ""]], "home.repos.pwc.inspect_result.astooke_rlpyt.utils.synchronize.RWLock.__init__": [[9, 13], ["multiprocessing.Lock", "multiprocessing.Lock", "multiprocessing.RawValue"], "methods", ["None"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "self", ".", "write_lock", "=", "mp", ".", "Lock", "(", ")", "\n", "self", ".", "_read_lock", "=", "mp", ".", "Lock", "(", ")", "\n", "self", ".", "_read_count", "=", "mp", ".", "RawValue", "(", "\"i\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.utils.synchronize.RWLock.__enter__": [[14, 16], ["synchronize.RWLock.acquire_read"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.utils.synchronize.RWLock.acquire_read"], ["", "def", "__enter__", "(", "self", ")", ":", "\n", "        ", "self", ".", "acquire_read", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.utils.synchronize.RWLock.__exit__": [[17, 19], ["synchronize.RWLock.release_read"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.utils.synchronize.RWLock.release_read"], ["", "def", "__exit__", "(", "self", ",", "*", "args", ")", ":", "\n", "        ", "self", ".", "release_read", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.utils.synchronize.RWLock.acquire_write": [[20, 22], ["synchronize.RWLock.write_lock.acquire"], "methods", ["None"], ["", "def", "acquire_write", "(", "self", ")", ":", "\n", "        ", "self", ".", "write_lock", ".", "acquire", "(", ")", "# or use `with rw_lock.write_lock:`.", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.utils.synchronize.RWLock.release_write": [[23, 25], ["synchronize.RWLock.write_lock.release"], "methods", ["None"], ["", "def", "release_write", "(", "self", ")", ":", "\n", "        ", "self", ".", "write_lock", ".", "release", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.utils.synchronize.RWLock.acquire_read": [[26, 31], ["synchronize.RWLock.write_lock.acquire"], "methods", ["None"], ["", "def", "acquire_read", "(", "self", ")", ":", "\n", "        ", "with", "self", ".", "_read_lock", ":", "\n", "            ", "self", ".", "_read_count", ".", "value", "+=", "1", "\n", "if", "self", ".", "_read_count", ".", "value", "==", "1", ":", "\n", "                ", "self", ".", "write_lock", ".", "acquire", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.utils.synchronize.RWLock.release_read": [[32, 37], ["synchronize.RWLock.write_lock.release"], "methods", ["None"], ["", "", "", "def", "release_read", "(", "self", ")", ":", "\n", "        ", "with", "self", ".", "_read_lock", ":", "\n", "            ", "self", ".", "_read_count", ".", "value", "-=", "1", "\n", "if", "self", ".", "_read_count", ".", "value", "==", "0", ":", "\n", "                ", "self", ".", "write_lock", ".", "release", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.utils.synchronize.drain_queue": [[39, 77], ["list", "queue_obj.get", "queue_obj.get", "queue_obj.put", "list.append", "list.append"], "function", ["home.repos.pwc.inspect_result.astooke_rlpyt.utils.collections.NamedArrayTuple.get", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.collections.NamedArrayTuple.get"], ["", "", "", "", "def", "drain_queue", "(", "queue_obj", ",", "n_sentinel", "=", "0", ",", "guard_sentinel", "=", "False", ")", ":", "\n", "    ", "\"\"\"Empty a multiprocessing queue object, with options to protect against\n    the delay between ``queue.put()`` and ``queue.get()``.  Returns a list of\n    the queue contents.\n\n    With ``n_sentinel=0``, simply call ``queue.get(block=False)`` until\n    ``queue.Empty`` exception (which can still happen slightly *after* another\n    process called ``queue.put()``).\n\n    With ``n_sentinel>1``, call ``queue.get()`` until `n_sentinel` ``None``\n    objects have been returned (marking that each ``put()`` process has finished).\n\n    With ``guard_sentinel=True`` (need ``n_sentinel=0``), stops if a ``None``\n    is retrieved, and puts it back into the queue, so it can do a blocking\n    drain later with ``n_sentinel>1``.\n    \"\"\"", "\n", "contents", "=", "list", "(", ")", "\n", "if", "n_sentinel", ">", "0", ":", "# Block until this many None (sentinels) received.", "\n", "        ", "sentinel_counter", "=", "0", "\n", "while", "True", ":", "\n", "            ", "obj", "=", "queue_obj", ".", "get", "(", ")", "\n", "if", "obj", "is", "None", ":", "\n", "                ", "sentinel_counter", "+=", "1", "\n", "if", "sentinel_counter", ">=", "n_sentinel", ":", "\n", "                    ", "return", "contents", "\n", "", "", "else", ":", "\n", "                ", "contents", ".", "append", "(", "obj", ")", "\n", "", "", "", "while", "True", ":", "# Non-blocking, beware of delay between put() and get().", "\n", "        ", "try", ":", "\n", "            ", "obj", "=", "queue_obj", ".", "get", "(", "block", "=", "False", ")", "\n", "", "except", "queue", ".", "Empty", ":", "\n", "            ", "return", "contents", "\n", "", "if", "guard_sentinel", "and", "obj", "is", "None", ":", "\n", "# Restore sentinel, intend to do blocking drain later.", "\n", "            ", "queue_obj", ".", "put", "(", "None", ")", "\n", "return", "contents", "\n", "", "elif", "obj", "is", "not", "None", ":", "# Ignore sentinel.", "\n", "            ", "contents", ".", "append", "(", "obj", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.utils.synchronize.find_port": [[79, 92], ["range", "torch.distributed.TCPStore"], "function", ["None"], ["", "", "", "def", "find_port", "(", "offset", ")", ":", "\n", "    ", "\"\"\"Find a unique open port, for initializing `torch.distributed` in\n    multiple separate multi-GPU runs on one machine.\"\"\"", "\n", "import", "torch", ".", "distributed", "\n", "assert", "offset", "<", "100", "\n", "for", "port", "in", "range", "(", "29500", "+", "offset", ",", "65000", ",", "100", ")", ":", "\n", "        ", "try", ":", "\n", "            ", "store", "=", "torch", ".", "distributed", ".", "TCPStore", "(", "\"127.0.0.1\"", ",", "port", ",", "1", ",", "True", ")", "\n", "break", "\n", "", "except", "RuntimeError", ":", "\n", "            ", "pass", "# Port taken.", "\n", "", "", "del", "store", "# Before fork (small time gap; could be re-taken, hence offset).", "\n", "return", "port", "\n", "", ""]], "home.repos.pwc.inspect_result.astooke_rlpyt.utils.collections.AttrDict.__init__": [[215, 218], ["dict.__init__"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.spaces.gym_wrapper.GymSpaceWrapper.__init__"], ["def", "__init__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "dict", ".", "__init__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", "\n", "self", ".", "__dict__", "=", "self", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.utils.collections.AttrDict.copy": [[219, 226], ["type", "isinstance", "v.copy", "collections.AttrDict.items"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.utils.collections.AttrDict.copy", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.collections.NamedArrayTuple.items"], ["", "def", "copy", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Provides a \"deep\" copy of all unbroken chains of types AttrDict, but\n        shallow copies otherwise, (e.g. numpy arrays are NOT copied).\n        \"\"\"", "\n", "return", "type", "(", "self", ")", "(", "**", "{", "k", ":", "v", ".", "copy", "(", ")", "if", "isinstance", "(", "v", ",", "AttrDict", ")", "else", "v", "\n", "for", "k", ",", "v", "in", "self", ".", "items", "(", ")", "}", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.utils.collections.NamedTupleSchema.__init__": [[240, 270], ["isinstance", "tuple", "inspect.Signature", "isinstance", "TypeError", "any", "field.startswith", "ValueError", "isinstance", "ValueError", "ValueError", "ValueError", "inspect.Parameter", "fields.split.split.split", "type", "fields.split.split.split"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "typename", ",", "fields", ")", ":", "\n", "        ", "if", "not", "isinstance", "(", "typename", ",", "str", ")", ":", "\n", "            ", "raise", "TypeError", "(", "f\"type name must be string, not {type(typename)}\"", ")", "\n", "\n", "", "if", "isinstance", "(", "fields", ",", "str", ")", ":", "\n", "            ", "spaces", "=", "any", "(", "[", "whitespace", "in", "fields", "for", "whitespace", "in", "string", ".", "whitespace", "]", ")", "\n", "commas", "=", "\",\"", "in", "fields", "\n", "if", "spaces", "and", "commas", ":", "\n", "                ", "raise", "ValueError", "(", "f\"Single string fields={fields} cannot have both spaces and commas.\"", ")", "\n", "", "elif", "spaces", ":", "\n", "                ", "fields", "=", "fields", ".", "split", "(", ")", "\n", "", "elif", "commas", ":", "\n", "                ", "fields", "=", "fields", ".", "split", "(", "\",\"", ")", "\n", "", "else", ":", "\n", "# If there are neither spaces nor commas, then there is only one field.", "\n", "                ", "fields", "=", "(", "fields", ",", ")", "\n", "", "", "fields", "=", "tuple", "(", "fields", ")", "\n", "\n", "for", "field", "in", "fields", ":", "\n", "            ", "if", "not", "isinstance", "(", "field", ",", "str", ")", ":", "\n", "                ", "raise", "ValueError", "(", "f\"field names must be strings: {field}\"", ")", "\n", "", "if", "field", ".", "startswith", "(", "\"_\"", ")", ":", "\n", "                ", "raise", "ValueError", "(", "f\"field names cannot start with an \"", "\n", "f\"underscore: {field}\"", ")", "\n", "", "if", "field", "in", "(", "\"index\"", ",", "\"count\"", ")", ":", "\n", "                ", "raise", "ValueError", "(", "f\"can't name field 'index' or 'count'\"", ")", "\n", "", "", "self", ".", "__dict__", "[", "\"_typename\"", "]", "=", "typename", "\n", "self", ".", "__dict__", "[", "\"_fields\"", "]", "=", "fields", "\n", "self", ".", "__dict__", "[", "\"_signature\"", "]", "=", "Sig", "(", "Param", "(", "field", ",", "\n", "Param", ".", "POSITIONAL_OR_KEYWORD", ")", "for", "field", "in", "fields", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.utils.collections.NamedTupleSchema.__call__": [[271, 275], ["collections.NamedTupleSchema._make", "collections.NamedTupleSchema._signature.bind"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.utils.collections.NamedArrayTupleSchema._make"], ["", "def", "__call__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"Allows instances to act like `namedtuple` constructors.\"\"\"", "\n", "args", "=", "self", ".", "_signature", ".", "bind", "(", "*", "args", ",", "**", "kwargs", ")", ".", "args", "# Mimic signature.", "\n", "return", "self", ".", "_make", "(", "args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.utils.collections.NamedTupleSchema._make": [[276, 279], ["collections.NamedTuple"], "methods", ["None"], ["", "def", "_make", "(", "self", ",", "iterable", ")", ":", "\n", "        ", "\"\"\"Allows instances to act like `namedtuple` constructors.\"\"\"", "\n", "return", "NamedTuple", "(", "self", ".", "_typename", ",", "self", ".", "_fields", ",", "iterable", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.utils.collections.NamedTupleSchema.__setattr__": [[280, 283], ["TypeError", "type"], "methods", ["None"], ["", "def", "__setattr__", "(", "self", ",", "name", ",", "value", ")", ":", "\n", "        ", "\"\"\"Make the type-like object immutable.\"\"\"", "\n", "raise", "TypeError", "(", "f\"can't set attributes of '{type(self).__name__}' \"", "\n", "\"instance\"", ")", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.utils.collections.NamedTupleSchema.__repr__": [[285, 287], ["type"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "return", "f\"{type(self).__name__}({self._typename!r}, {self._fields!r})\"", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.utils.collections.NamedTuple.__new__": [[311, 319], ["tuple.__new__", "len", "len", "ValueError", "len", "len"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.utils.collections.NamedTuple.__new__"], ["def", "__new__", "(", "cls", ",", "typename", ",", "fields", ",", "values", ")", ":", "\n", "        ", "result", "=", "tuple", ".", "__new__", "(", "cls", ",", "values", ")", "\n", "if", "len", "(", "fields", ")", "!=", "len", "(", "result", ")", ":", "\n", "            ", "raise", "ValueError", "(", "f\"Expected {len(fields)} arguments, got \"", "\n", "f\"{len(result)}\"", ")", "\n", "", "result", ".", "__dict__", "[", "\"_typename\"", "]", "=", "typename", "\n", "result", ".", "__dict__", "[", "\"_fields\"", "]", "=", "fields", "\n", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.utils.collections.NamedTuple.__getattr__": [[320, 326], ["tuple.__getitem__", "collections.NamedTuple._fields.index", "AttributeError"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.utils.collections.NamedArrayTuple.__getitem__"], ["", "def", "__getattr__", "(", "self", ",", "name", ")", ":", "\n", "        ", "\"\"\"Look in `_fields` when `name` is not in `dir(self)`.\"\"\"", "\n", "try", ":", "\n", "            ", "return", "tuple", ".", "__getitem__", "(", "self", ",", "self", ".", "_fields", ".", "index", "(", "name", ")", ")", "\n", "", "except", "ValueError", ":", "\n", "            ", "raise", "AttributeError", "(", "f\"'{self._typename}' object has no attribute \"", "\n", "f\"'{name}'\"", ")", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.utils.collections.NamedTuple.__setattr__": [[328, 331], ["AttributeError", "type"], "methods", ["None"], ["", "", "def", "__setattr__", "(", "self", ",", "name", ",", "value", ")", ":", "\n", "        ", "\"\"\"Make the object immutable, like a tuple.\"\"\"", "\n", "raise", "AttributeError", "(", "f\"can't set attributes of \"", "\n", "f\"'{type(self).__name__}' instance\"", ")", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.utils.collections.NamedTuple._make": [[333, 337], ["type"], "methods", ["None"], ["", "def", "_make", "(", "self", ",", "iterable", ")", ":", "\n", "        ", "\"\"\"Make a new object of same typename and fields from a sequence or\n        iterable.\"\"\"", "\n", "return", "type", "(", "self", ")", "(", "self", ".", "_typename", ",", "self", ".", "_fields", ",", "iterable", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.utils.collections.NamedTuple._replace": [[338, 346], ["collections.NamedTuple._make", "map", "ValueError", "str", "list"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.utils.collections.NamedArrayTupleSchema._make"], ["", "def", "_replace", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"Return a new object of same typename and fields, replacing specified\n        fields with new values.\"\"\"", "\n", "result", "=", "self", ".", "_make", "(", "map", "(", "kwargs", ".", "pop", ",", "self", ".", "_fields", ",", "self", ")", ")", "\n", "if", "kwargs", ":", "\n", "            ", "raise", "ValueError", "(", "f\"Got unexpected field names: \"", "\n", "f\"{str(list(kwargs))[1:-1]}\"", ")", "\n", "", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.utils.collections.NamedTuple._asdict": [[347, 350], ["collections.OrderedDict", "zip"], "methods", ["None"], ["", "def", "_asdict", "(", "self", ")", ":", "\n", "        ", "\"\"\"Return an ordered dictionary mapping field names to their values.\"\"\"", "\n", "return", "OrderedDict", "(", "zip", "(", "self", ".", "_fields", ",", "self", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.utils.collections.NamedTuple.__getnewargs__": [[351, 355], ["tuple"], "methods", ["None"], ["", "def", "__getnewargs__", "(", "self", ")", ":", "\n", "        ", "\"\"\"Returns typename, fields, and values as plain tuple. Used by copy\n        and pickle.\"\"\"", "\n", "return", "self", ".", "_typename", ",", "self", ".", "_fields", ",", "tuple", "(", "self", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.utils.collections.NamedTuple.__repr__": [[356, 360], ["zip"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "\"\"\"Return a nicely formatted string showing the typename.\"\"\"", "\n", "return", "self", ".", "_typename", "+", "'('", "+", "', '", ".", "join", "(", "f'{name}={value}'", "\n", "for", "name", ",", "value", "in", "zip", "(", "self", ".", "_fields", ",", "self", ")", ")", "+", "')'", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.utils.collections.NamedArrayTupleSchema.__init__": [[366, 371], ["collections.NamedTupleSchema.__init__", "ValueError"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.spaces.gym_wrapper.GymSpaceWrapper.__init__"], ["def", "__init__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "for", "name", "in", "self", ".", "_fields", ":", "\n", "            ", "if", "name", "in", "RESERVED_NAMES", ":", "\n", "                ", "raise", "ValueError", "(", "f\"Disallowed field name: '{name}'\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.utils.collections.NamedArrayTupleSchema._make": [[372, 374], ["collections.NamedArrayTuple"], "methods", ["None"], ["", "", "", "def", "_make", "(", "self", ",", "iterable", ")", ":", "\n", "        ", "return", "NamedArrayTuple", "(", "self", ".", "_typename", ",", "self", ".", "_fields", ",", "iterable", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.utils.collections.NamedArrayTuple.__getitem__": [[378, 392], ["collections.NamedArrayTuple._make", "enumerate", "Exception"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.utils.collections.NamedArrayTupleSchema._make"], ["    ", "def", "__getitem__", "(", "self", ",", "loc", ")", ":", "\n", "        ", "\"\"\"Return a new object of the same typename and fields containing the\n        selected index or slice from each value.\"\"\"", "\n", "try", ":", "\n", "            ", "return", "self", ".", "_make", "(", "None", "if", "s", "is", "None", "else", "s", "[", "loc", "]", "for", "s", "in", "self", ")", "\n", "", "except", "IndexError", "as", "e", ":", "\n", "            ", "for", "j", ",", "s", "in", "enumerate", "(", "self", ")", ":", "\n", "                ", "if", "s", "is", "None", ":", "\n", "                    ", "continue", "\n", "", "try", ":", "\n", "                    ", "_", "=", "s", "[", "loc", "]", "\n", "", "except", "IndexError", ":", "\n", "                    ", "raise", "Exception", "(", "f\"Occured in '{self._typename}' at field \"", "\n", "f\"'{self._fields[j]}'.\"", ")", "from", "e", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.utils.collections.NamedArrayTuple.__setitem__": [[393, 411], ["tuple", "enumerate", "isinstance", "zip", "Exception", "getattr"], "methods", ["None"], ["", "", "", "", "def", "__setitem__", "(", "self", ",", "loc", ",", "value", ")", ":", "\n", "        ", "\"\"\"\n        If input value is the same named[array]tuple type, iterate through its\n        fields and assign values into selected index or slice of corresponding\n        value.  Else, assign whole of value to selected index or slice of\n        all fields.  Ignore fields that are both None.\n        \"\"\"", "\n", "if", "not", "(", "isinstance", "(", "value", ",", "tuple", ")", "and", "# Check for matching structure.", "\n", "getattr", "(", "value", ",", "\"_fields\"", ",", "None", ")", "==", "self", ".", "_fields", ")", ":", "\n", "# Repeat value for each but respect any None.", "\n", "            ", "value", "=", "tuple", "(", "None", "if", "s", "is", "None", "else", "value", "for", "s", "in", "self", ")", "\n", "", "try", ":", "\n", "            ", "for", "j", ",", "(", "s", ",", "v", ")", "in", "enumerate", "(", "zip", "(", "self", ",", "value", ")", ")", ":", "\n", "                ", "if", "s", "is", "not", "None", "or", "v", "is", "not", "None", ":", "\n", "                    ", "s", "[", "loc", "]", "=", "v", "\n", "", "", "", "except", "(", "ValueError", ",", "IndexError", ",", "TypeError", ")", "as", "e", ":", "\n", "            ", "raise", "Exception", "(", "f\"Occured in {self.__class__} at field \"", "\n", "f\"'{self._fields[j]}'.\"", ")", "from", "e", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.utils.collections.NamedArrayTuple.__contains__": [[412, 415], ["None"], "methods", ["None"], ["", "", "def", "__contains__", "(", "self", ",", "key", ")", ":", "\n", "        ", "\"\"\"Checks presence of field name (unlike tuple; like dict).\"\"\"", "\n", "return", "key", "in", "self", ".", "_fields", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.utils.collections.NamedArrayTuple.get": [[416, 419], ["tuple.__getitem__"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.utils.collections.NamedArrayTuple.__getitem__"], ["", "def", "get", "(", "self", ",", "index", ")", ":", "\n", "        ", "\"\"\"Retrieve value as if indexing into regular tuple.\"\"\"", "\n", "return", "tuple", ".", "__getitem__", "(", "self", ",", "index", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.utils.collections.NamedArrayTuple.items": [[420, 424], ["zip"], "methods", ["None"], ["", "def", "items", "(", "self", ")", ":", "\n", "        ", "\"\"\"Iterate ordered (field_name, value) pairs (like OrderedDict).\"\"\"", "\n", "for", "k", ",", "v", "in", "zip", "(", "self", ".", "_fields", ",", "self", ")", ":", "\n", "            ", "yield", "k", ",", "v", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.utils.collections.tuple_itemgetter": [[10, 14], ["tuple.__getitem__"], "function", ["home.repos.pwc.inspect_result.astooke_rlpyt.utils.collections.NamedArrayTuple.__getitem__"], ["def", "tuple_itemgetter", "(", "i", ")", ":", "\n", "    ", "def", "_tuple_itemgetter", "(", "obj", ")", ":", "\n", "        ", "return", "tuple", ".", "__getitem__", "(", "obj", ",", "i", ")", "\n", "", "return", "_tuple_itemgetter", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.utils.collections.namedarraytuple": [[16, 134], ["collections.namedtuple", "enumerate", "type", "sys._getframe().f_globals.get", "tuple.__getitem__", "zip", "repr().replace", "collections.tuple_itemgetter", "property", "tuple", "enumerate", "ValueError", "type", "enumerate", "isinstance", "zip", "Exception", "repr", "sys._getframe", "getattr", "Exception"], "function", ["home.repos.pwc.inspect_result.astooke_rlpyt.utils.collections.NamedArrayTuple.get", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.collections.NamedArrayTuple.__getitem__", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.collections.tuple_itemgetter"], ["", "def", "namedarraytuple", "(", "typename", ",", "field_names", ",", "return_namedtuple_cls", "=", "False", ",", "\n", "classname_suffix", "=", "False", ")", ":", "\n", "    ", "\"\"\"\n    Returns a new subclass of a namedtuple which exposes indexing / slicing\n    reads and writes applied to all contained objects, which must share\n    indexing (__getitem__) behavior (e.g. numpy arrays or torch tensors).\n\n    (Code follows pattern of collections.namedtuple.)\n\n    >>> PointsCls = namedarraytuple('Points', ['x', 'y'])\n    >>> p = PointsCls(np.array([0, 1]), y=np.array([10, 11]))\n    >>> p\n    Points(x=array([0, 1]), y=array([10, 11]))\n    >>> p.x                         # fields accessible by name\n    array([0, 1])\n    >>> p[0]                        # get location across all fields\n    Points(x=0, y=10)               # (location can be index or slice)\n    >>> p.get(0)                    # regular tuple-indexing into field\n    array([0, 1])\n    >>> x, y = p                    # unpack like a regular tuple\n    >>> x\n    array([0, 1])\n    >>> p[1] = 2                    # assign value to location of all fields\n    >>> p\n    Points(x=array([0, 2]), y=array([10, 2]))\n    >>> p[1] = PointsCls(3, 30)     # assign to location field-by-field\n    >>> p\n    Points(x=array([0, 3]), y=array([10, 30]))\n    >>> 'x' in p                    # check field name instead of object\n    True\n    \"\"\"", "\n", "nt_typename", "=", "typename", "\n", "if", "classname_suffix", ":", "\n", "        ", "nt_typename", "+=", "\"_nt\"", "# Helpful to identify which style of tuple.", "\n", "typename", "+=", "\"_nat\"", "\n", "\n", "", "try", ":", "# For pickling, get location where this function was called.", "\n", "# NOTE: (pickling might not work for nested class definition.)", "\n", "        ", "module", "=", "sys", ".", "_getframe", "(", "1", ")", ".", "f_globals", ".", "get", "(", "'__name__'", ",", "'__main__'", ")", "\n", "", "except", "(", "AttributeError", ",", "ValueError", ")", ":", "\n", "        ", "module", "=", "None", "\n", "", "NtCls", "=", "namedtuple", "(", "nt_typename", ",", "field_names", ",", "module", "=", "module", ")", "\n", "\n", "def", "__getitem__", "(", "self", ",", "loc", ")", ":", "\n", "        ", "try", ":", "\n", "            ", "return", "type", "(", "self", ")", "(", "*", "(", "None", "if", "s", "is", "None", "else", "s", "[", "loc", "]", "for", "s", "in", "self", ")", ")", "\n", "", "except", "IndexError", "as", "e", ":", "\n", "            ", "for", "j", ",", "s", "in", "enumerate", "(", "self", ")", ":", "\n", "                ", "if", "s", "is", "None", ":", "\n", "                    ", "continue", "\n", "", "try", ":", "\n", "                    ", "_", "=", "s", "[", "loc", "]", "\n", "", "except", "IndexError", ":", "\n", "                    ", "raise", "Exception", "(", "f\"Occured in {self.__class__} at field \"", "\n", "f\"'{self._fields[j]}'.\"", ")", "from", "e", "\n", "\n", "", "", "", "", "__getitem__", ".", "__doc__", "=", "(", "f\"Return a new {typename} instance containing \"", "\n", "\"the selected index or slice from each field.\"", ")", "\n", "\n", "def", "__setitem__", "(", "self", ",", "loc", ",", "value", ")", ":", "\n", "        ", "\"\"\"\n        If input value is the same named[array]tuple type, iterate through its\n        fields and assign values into selected index or slice of corresponding\n        field.  Else, assign whole of value to selected index or slice of\n        all fields.  Ignore fields that are both None.\n        \"\"\"", "\n", "if", "not", "(", "isinstance", "(", "value", ",", "tuple", ")", "and", "# Check for matching structure.", "\n", "getattr", "(", "value", ",", "\"_fields\"", ",", "None", ")", "==", "self", ".", "_fields", ")", ":", "\n", "# Repeat value for each but respect any None.", "\n", "            ", "value", "=", "tuple", "(", "None", "if", "s", "is", "None", "else", "value", "for", "s", "in", "self", ")", "\n", "", "try", ":", "\n", "            ", "for", "j", ",", "(", "s", ",", "v", ")", "in", "enumerate", "(", "zip", "(", "self", ",", "value", ")", ")", ":", "\n", "                ", "if", "s", "is", "not", "None", "or", "v", "is", "not", "None", ":", "\n", "                    ", "s", "[", "loc", "]", "=", "v", "\n", "", "", "", "except", "(", "ValueError", ",", "IndexError", ",", "TypeError", ")", "as", "e", ":", "\n", "            ", "raise", "Exception", "(", "f\"Occured in {self.__class__} at field \"", "\n", "f\"'{self._fields[j]}'.\"", ")", "from", "e", "\n", "\n", "", "", "def", "__contains__", "(", "self", ",", "key", ")", ":", "\n", "        ", "\"Checks presence of field name (unlike tuple; like dict).\"", "\n", "return", "key", "in", "self", ".", "_fields", "\n", "\n", "", "def", "get", "(", "self", ",", "index", ")", ":", "\n", "        ", "\"Retrieve value as if indexing into regular tuple.\"", "\n", "return", "tuple", ".", "__getitem__", "(", "self", ",", "index", ")", "\n", "\n", "", "def", "items", "(", "self", ")", ":", "\n", "        ", "\"Iterate ordered (field_name, value) pairs (like OrderedDict).\"", "\n", "for", "k", ",", "v", "in", "zip", "(", "self", ".", "_fields", ",", "self", ")", ":", "\n", "            ", "yield", "k", ",", "v", "\n", "\n", "", "", "for", "method", "in", "(", "__getitem__", ",", "__setitem__", ",", "get", ",", "items", ")", ":", "\n", "        ", "method", ".", "__qualname__", "=", "f'{typename}.{method.__name__}'", "\n", "\n", "", "arg_list", "=", "repr", "(", "NtCls", ".", "_fields", ")", ".", "replace", "(", "\"'\"", ",", "\"\"", ")", "[", "1", ":", "-", "1", "]", "\n", "class_namespace", "=", "{", "\n", "'__doc__'", ":", "f'{typename}({arg_list})'", ",", "\n", "'__slots__'", ":", "(", ")", ",", "\n", "'__getitem__'", ":", "__getitem__", ",", "\n", "'__setitem__'", ":", "__setitem__", ",", "\n", "'__contains__'", ":", "__contains__", ",", "\n", "'get'", ":", "get", ",", "\n", "'items'", ":", "items", ",", "\n", "}", "\n", "\n", "for", "index", ",", "name", "in", "enumerate", "(", "NtCls", ".", "_fields", ")", ":", "\n", "        ", "if", "name", "in", "RESERVED_NAMES", ":", "\n", "            ", "raise", "ValueError", "(", "f\"Disallowed field name: {name}.\"", ")", "\n", "", "itemgetter_object", "=", "tuple_itemgetter", "(", "index", ")", "\n", "doc", "=", "f'Alias for field number {index}'", "\n", "class_namespace", "[", "name", "]", "=", "property", "(", "itemgetter_object", ",", "doc", "=", "doc", ")", "\n", "\n", "", "result", "=", "type", "(", "typename", ",", "(", "NtCls", ",", ")", ",", "class_namespace", ")", "\n", "result", ".", "__module__", "=", "NtCls", ".", "__module__", "\n", "\n", "if", "return_namedtuple_cls", ":", "\n", "        ", "return", "result", ",", "NtCls", "\n", "", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.utils.collections.is_namedtuple_class": [[139, 152], ["len", "all", "type", "obj.mro", "obj.mro", "hasattr"], "function", ["None"], ["def", "is_namedtuple_class", "(", "obj", ")", ":", "\n", "    ", "\"\"\"Heuristic, might be spoofed.\n    Returns False if obj is namedarraytuple class.\"\"\"", "\n", "if", "type", "(", "obj", ")", "is", "not", "type", "or", "obj", "is", "type", ":", "\n", "        ", "return", "False", "\n", "", "if", "len", "(", "obj", ".", "mro", "(", ")", ")", "!=", "3", ":", "\n", "        ", "return", "False", "\n", "", "if", "obj", ".", "mro", "(", ")", "[", "1", "]", "is", "not", "tuple", ":", "\n", "        ", "return", "False", "\n", "", "if", "not", "all", "(", "hasattr", "(", "obj", ",", "attr", ")", "\n", "for", "attr", "in", "[", "\"_fields\"", ",", "\"_asdict\"", ",", "\"_make\"", ",", "\"_replace\"", "]", ")", ":", "\n", "        ", "return", "False", "\n", "", "return", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.utils.collections.is_namedarraytuple_class": [[154, 166], ["len", "collections.is_namedtuple_class", "all", "type", "obj.mro", "obj.mro", "hasattr"], "function", ["home.repos.pwc.inspect_result.astooke_rlpyt.utils.collections.is_namedtuple_class"], ["", "def", "is_namedarraytuple_class", "(", "obj", ")", ":", "\n", "    ", "\"\"\"Heuristic, might be spoofed.\n    Returns False if obj is namedtuple class.\"\"\"", "\n", "if", "type", "(", "obj", ")", "is", "not", "type", "or", "obj", "is", "type", ":", "\n", "        ", "return", "False", "\n", "", "if", "len", "(", "obj", ".", "mro", "(", ")", ")", "!=", "4", ":", "\n", "        ", "return", "False", "\n", "", "if", "not", "is_namedtuple_class", "(", "obj", ".", "mro", "(", ")", "[", "1", "]", ")", ":", "\n", "        ", "return", "False", "\n", "", "if", "not", "all", "(", "hasattr", "(", "obj", ",", "attr", ")", "for", "attr", "in", "RESERVED_NAMES", ")", ":", "\n", "        ", "return", "False", "\n", "", "return", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.utils.collections.is_namedtuple": [[168, 172], ["collections.is_namedtuple_class", "type"], "function", ["home.repos.pwc.inspect_result.astooke_rlpyt.utils.collections.is_namedtuple_class"], ["", "def", "is_namedtuple", "(", "obj", ")", ":", "\n", "    ", "\"\"\"Heuristic, might be spoofed.\n    Returns False if obj is namedarraytuple.\"\"\"", "\n", "return", "is_namedtuple_class", "(", "type", "(", "obj", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.utils.collections.is_namedarraytuple": [[174, 178], ["collections.is_namedarraytuple_class", "type"], "function", ["home.repos.pwc.inspect_result.astooke_rlpyt.utils.collections.is_namedarraytuple_class"], ["", "def", "is_namedarraytuple", "(", "obj", ")", ":", "\n", "    ", "\"\"\"Heuristic, might be spoofed.\n    Returns False if obj is namedtuple.\"\"\"", "\n", "return", "is_namedarraytuple_class", "(", "type", "(", "obj", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.utils.collections.namedarraytuple_like": [[180, 203], ["collections.is_namedtuple", "collections.namedarraytuple", "collections.is_namedtuple_class", "collections.namedarraytuple", "collections.is_namedarraytuple", "type", "type", "collections.is_namedarraytuple_class", "isinstance", "collections.namedarraytuple", "TypeError", "type"], "function", ["home.repos.pwc.inspect_result.astooke_rlpyt.utils.collections.is_namedtuple", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.collections.namedarraytuple", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.collections.is_namedtuple_class", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.collections.namedarraytuple", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.collections.is_namedarraytuple", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.collections.is_namedarraytuple_class", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.collections.namedarraytuple"], ["", "def", "namedarraytuple_like", "(", "namedtuple_or_class", ",", "classname_suffix", "=", "False", ")", ":", "\n", "    ", "\"\"\"Returns namedarraytuple class with same name and fields as input\n    namedtuple or namedarraytuple instance or class.  If input is\n    namedarraytuple instance or class, the same class is returned directly.\n    Input can also be from the new Schema format, instances of the four:\n    Named[Array]Tuple[Schema].\"\"\"", "\n", "ntc", "=", "namedtuple_or_class", "\n", "if", "is_namedtuple", "(", "ntc", ")", ":", "\n", "        ", "return", "namedarraytuple", "(", "type", "(", "ntc", ")", ".", "__name__", ",", "ntc", ".", "_fields", ",", "\n", "classname_suffix", "=", "classname_suffix", ")", "\n", "", "elif", "is_namedtuple_class", "(", "ntc", ")", ":", "\n", "        ", "return", "namedarraytuple", "(", "ntc", ".", "__name__", ",", "ntc", ".", "_fields", ",", "\n", "classname_suffix", "=", "classname_suffix", ")", "\n", "", "elif", "is_namedarraytuple", "(", "ntc", ")", ":", "\n", "        ", "return", "type", "(", "ntc", ")", "\n", "", "elif", "is_namedarraytuple_class", "(", "ntc", ")", ":", "\n", "        ", "return", "ntc", "\n", "", "elif", "isinstance", "(", "ntc", ",", "(", "NamedTupleSchema", ",", "NamedTuple", ",", "NamedArrayTupleSchema", ",", "\n", "NamedArrayTuple", ")", ")", ":", "\n", "        ", "return", "namedarraytuple", "(", "ntc", ".", "_typename", ",", "ntc", ".", "_fields", ",", "\n", "classname_suffix", "=", "classname_suffix", ")", "\n", "", "else", ":", "\n", "        ", "raise", "TypeError", "(", "\"Input must be namedtuple or namedarraytuple instance\"", "\n", "f\" or class, got {type(ntc)}.\"", ")", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.utils.collections.NamedArrayTupleSchema_like": [[426, 441], ["isinstance", "isinstance", "collections.NamedArrayTupleSchema", "collections.is_namedtuple", "collections.is_namedarraytuple", "collections.NamedArrayTupleSchema", "collections.is_namedtuple_class", "collections.is_namedarraytuple_class", "collections.NamedArrayTupleSchema", "TypeError", "type", "type"], "function", ["home.repos.pwc.inspect_result.astooke_rlpyt.utils.collections.is_namedtuple", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.collections.is_namedarraytuple", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.collections.is_namedtuple_class", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.collections.is_namedarraytuple_class"], ["", "", "", "def", "NamedArrayTupleSchema_like", "(", "example", ")", ":", "\n", "    ", "\"\"\"Returns a NamedArrayTupleSchema instance  with the same name and fields\n    as input, which can be a class or instance of namedtuple or\n    namedarraytuple, or an instance of NamedTupleSchema, NamedTuple,\n    NamedArrayTupleSchema, or NamedArrayTuple.\"\"\"", "\n", "if", "isinstance", "(", "example", ",", "NamedArrayTupleSchema", ")", ":", "\n", "        ", "return", "example", "\n", "", "elif", "isinstance", "(", "example", ",", "(", "NamedArrayTuple", ",", "NamedTuple", ",", "NamedTupleSchema", ")", ")", ":", "\n", "        ", "return", "NamedArrayTupleSchema", "(", "example", ".", "_typename", ",", "example", ".", "_fields", ")", "\n", "", "elif", "is_namedtuple", "(", "example", ")", "or", "is_namedarraytuple", "(", "example", ")", ":", "\n", "        ", "return", "NamedArrayTupleSchema", "(", "type", "(", "example", ")", ".", "__name__", ",", "example", ".", "_fields", ")", "\n", "", "elif", "is_namedtuple_class", "(", "example", ")", "or", "is_namedarraytuple_class", "(", "example", ")", ":", "\n", "        ", "return", "NamedArrayTupleSchema", "(", "example", ".", "__name__", ",", "example", ".", "_fields", ")", "\n", "", "else", ":", "\n", "        ", "raise", "TypeError", "(", "\"Input must be namedtuple or namedarraytuple instance\"", "\n", "f\" or class, or Named[Array]Tuple[Schema] instance, got \"", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.utils.misc.iterate_mb_idxs": [[6, 18], ["range", "numpy.arange", "numpy.random.shuffle", "slice"], "function", ["None"], ["def", "iterate_mb_idxs", "(", "data_length", ",", "minibatch_size", ",", "shuffle", "=", "False", ")", ":", "# , horizon=1)", "\n", "    ", "\"\"\"Yields minibatches of indexes, to use as a for-loop iterator, with\n    option to shuffle.\n    \"\"\"", "\n", "if", "shuffle", ":", "\n", "        ", "indexes", "=", "np", ".", "arange", "(", "data_length", ")", "\n", "np", ".", "random", ".", "shuffle", "(", "indexes", ")", "\n", "", "for", "start_idx", "in", "range", "(", "0", ",", "data_length", "-", "minibatch_size", "+", "1", ",", "minibatch_size", ")", ":", "\n", "        ", "batch", "=", "slice", "(", "start_idx", ",", "start_idx", "+", "minibatch_size", ")", "\n", "if", "shuffle", ":", "\n", "            ", "batch", "=", "indexes", "[", "batch", "]", "\n", "", "yield", "batch", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.utils.misc.zeros": [[20, 27], ["torch.zeros", "numpy.zeros"], "function", ["home.repos.pwc.inspect_result.astooke_rlpyt.utils.misc.zeros", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.misc.zeros"], ["", "", "def", "zeros", "(", "shape", ",", "dtype", ")", ":", "\n", "    ", "\"\"\"Attempt to return torch tensor of zeros, or if numpy dtype provided,\n    return numpy array or zeros.\"\"\"", "\n", "try", ":", "\n", "        ", "return", "torch", ".", "zeros", "(", "shape", ",", "dtype", "=", "dtype", ")", "\n", "", "except", "TypeError", ":", "\n", "        ", "return", "np", ".", "zeros", "(", "shape", ",", "dtype", "=", "dtype", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.utils.misc.empty": [[29, 36], ["torch.empty", "numpy.empty"], "function", ["home.repos.pwc.inspect_result.astooke_rlpyt.utils.misc.empty", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.misc.empty"], ["", "", "def", "empty", "(", "shape", ",", "dtype", ")", ":", "\n", "    ", "\"\"\"Attempt to return empty torch tensor, or if numpy dtype provided,\n    return empty numpy array.\"\"\"", "\n", "try", ":", "\n", "        ", "return", "torch", ".", "empty", "(", "shape", ",", "dtype", "=", "dtype", ")", "\n", "", "except", "TypeError", ":", "\n", "        ", "return", "np", ".", "empty", "(", "shape", ",", "dtype", "=", "dtype", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.utils.misc.extract_sequences": [[38, 57], ["misc.empty", "enumerate", "zip", "len", "len", "len"], "function", ["home.repos.pwc.inspect_result.astooke_rlpyt.utils.misc.empty"], ["", "", "def", "extract_sequences", "(", "array_or_tensor", ",", "T_idxs", ",", "B_idxs", ",", "T", ")", ":", "\n", "    ", "\"\"\"Assumes `array_or_tensor` has [T,B] leading dims.  Returns new\n    array/tensor which contains sequences of length [T] taken from the\n    starting indexes [T_idxs, B_idxs], where T_idxs (and B_idxs) is a list or\n    vector of integers. Handles wrapping automatically. (Return shape: [T,\n    len(B_idxs),...]).\"\"\"", "\n", "shape", "=", "(", "T", ",", "len", "(", "B_idxs", ")", ")", "+", "array_or_tensor", ".", "shape", "[", "2", ":", "]", "\n", "sequences", "=", "empty", "(", "shape", ",", "dtype", "=", "array_or_tensor", ".", "dtype", ")", "\n", "for", "i", ",", "(", "t", ",", "b", ")", "in", "enumerate", "(", "zip", "(", "T_idxs", ",", "B_idxs", ")", ")", ":", "\n", "        ", "if", "t", "+", "T", ">", "len", "(", "array_or_tensor", ")", ":", "# Wrap end.", "\n", "            ", "m", "=", "len", "(", "array_or_tensor", ")", "-", "t", "\n", "sequences", "[", ":", "m", ",", "i", "]", "=", "array_or_tensor", "[", "t", ":", ",", "b", "]", "# [m,..]", "\n", "sequences", "[", "m", ":", ",", "i", "]", "=", "array_or_tensor", "[", ":", "T", "-", "m", ",", "b", "]", "# [w,..]", "\n", "", "elif", "t", "<", "0", ":", "# Wrap beginning.", "\n", "            ", "sequences", "[", "t", ":", ",", "i", "]", "=", "array_or_tensor", "[", "t", ":", ",", "b", "]", "\n", "sequences", "[", ":", "t", ",", "i", "]", "=", "array_or_tensor", "[", ":", "t", "+", "T", ",", "b", "]", "\n", "", "else", ":", "\n", "            ", "sequences", "[", ":", ",", "i", "]", "=", "array_or_tensor", "[", "t", ":", "t", "+", "T", ",", "b", "]", "# [T,..]", "\n", "", "", "return", "sequences", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.utils.seed.set_seed": [[10, 23], ["random.seed", "numpy.random.seed", "torch.manual_seed", "torch.cuda.manual_seed", "print", "rlpyt.utils.logging.console.colorize"], "function", ["home.repos.pwc.inspect_result.astooke_rlpyt.spaces.gym_wrapper.GymSpaceWrapper.seed", "home.repos.pwc.inspect_result.astooke_rlpyt.spaces.gym_wrapper.GymSpaceWrapper.seed", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.console.colorize"], ["def", "set_seed", "(", "seed", ")", ":", "\n", "    ", "\"\"\"Sets random.seed, np.random.seed, torch.manual_seed,\n    torch.cuda.manual_seed.\"\"\"", "\n", "seed", "%=", "4294967294", "\n", "global", "seed_", "\n", "seed_", "=", "seed", "\n", "import", "random", "\n", "random", ".", "seed", "(", "seed", ")", "\n", "np", ".", "random", ".", "seed", "(", "seed", ")", "\n", "import", "torch", "\n", "torch", ".", "manual_seed", "(", "seed", ")", "\n", "torch", ".", "cuda", ".", "manual_seed", "(", "seed", ")", "\n", "print", "(", "colorize", "(", "f\"using seed {seed}\"", ",", "\"green\"", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.utils.seed.get_seed": [[25, 27], ["None"], "function", ["None"], ["", "def", "get_seed", "(", ")", ":", "\n", "    ", "return", "seed_", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.utils.seed.make_seed": [[29, 52], ["time.time", "time.sleep", "time.time", "time.sleep", "time.time", "int", "int", "int", "int", "int", "int"], "function", ["None"], ["", "def", "make_seed", "(", ")", ":", "\n", "    ", "\"\"\"\n    Returns a random number between [0, 10000], using timing jitter.\n\n    This has a white noise spectrum and gives unique values for multiple\n    simultaneous processes...some simpler attempts did not achieve that, but\n    there's probably a better way.\n    \"\"\"", "\n", "d", "=", "10000", "\n", "t", "=", "time", ".", "time", "(", ")", "\n", "sub1", "=", "int", "(", "t", "*", "d", ")", "%", "d", "\n", "sub2", "=", "int", "(", "t", "*", "d", "**", "2", ")", "%", "d", "\n", "s", "=", "1e-3", "\n", "s_inv", "=", "1.", "/", "s", "\n", "time", ".", "sleep", "(", "s", "*", "sub2", "/", "d", ")", "\n", "t2", "=", "time", ".", "time", "(", ")", "\n", "t2", "=", "t2", "-", "int", "(", "t2", ")", "\n", "t2", "=", "int", "(", "t2", "*", "d", "*", "s_inv", ")", "%", "d", "\n", "time", ".", "sleep", "(", "s", "*", "sub1", "/", "d", ")", "\n", "t3", "=", "time", ".", "time", "(", ")", "\n", "t3", "=", "t3", "-", "int", "(", "t3", ")", "\n", "t3", "=", "int", "(", "t3", "*", "d", "*", "s_inv", "*", "10", ")", "%", "d", "\n", "return", "(", "t3", "-", "t2", ")", "%", "d", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.utils.seed.set_envs_seeds": [[54, 66], ["enumerate", "hasattr", "hasattr", "hasattr", "env.seed", "env.action_space.seed", "env.observation_space.seed"], "function", ["home.repos.pwc.inspect_result.astooke_rlpyt.spaces.gym_wrapper.GymSpaceWrapper.seed", "home.repos.pwc.inspect_result.astooke_rlpyt.spaces.gym_wrapper.GymSpaceWrapper.seed", "home.repos.pwc.inspect_result.astooke_rlpyt.spaces.gym_wrapper.GymSpaceWrapper.seed"], ["", "def", "set_envs_seeds", "(", "envs", ",", "seed", ")", ":", "\n", "    ", "\"\"\"Set different seeds for a collection of envs, if applicable. Standard\n    rlpyt envs and spaces don't necessarily have this method, but gym envs\n    and spaces do.\"\"\"", "\n", "if", "seed", "is", "not", "None", ":", "\n", "        ", "for", "i", ",", "env", "in", "enumerate", "(", "envs", ")", ":", "\n", "            ", "if", "hasattr", "(", "env", ",", "\"seed\"", ")", ":", "# e.g. Gym environments have seed.", "\n", "                ", "env", ".", "seed", "(", "seed", "+", "i", ")", "\n", "", "if", "hasattr", "(", "env", ".", "action_space", ",", "\"seed\"", ")", ":", "# e.g. Gym spaces have seed.", "\n", "                ", "env", ".", "action_space", ".", "seed", "(", "seed", "+", "i", ")", "\n", "", "if", "hasattr", "(", "env", ".", "observation_space", ",", "\"seed\"", ")", ":", "\n", "                ", "env", ".", "observation_space", ".", "seed", "(", "seed", "+", "i", ")", "\n", "", "", "", "", ""]], "home.repos.pwc.inspect_result.astooke_rlpyt.utils.quick_args.save__init__args": [[5, 26], ["list", "type().mro", "type", "vars", "setattr", "inspect.getfullargspec", "hasattr"], "function", ["None"], ["def", "save__init__args", "(", "values", ",", "underscore", "=", "False", ",", "overwrite", "=", "False", ",", "subclass_only", "=", "False", ")", ":", "\n", "    ", "\"\"\"\n    Use in `__init__()` only; assign all args/kwargs to instance attributes.\n    To maintain precedence of args provided to subclasses, call this in the\n    subclass before `super().__init__()` if `save__init__args()` also appears\n    in base class, or use `overwrite=True`.  With `subclass_only==True`, only\n    args/kwargs listed in current subclass apply.\n    \"\"\"", "\n", "prefix", "=", "\"_\"", "if", "underscore", "else", "\"\"", "\n", "self", "=", "values", "[", "'self'", "]", "\n", "args", "=", "list", "(", ")", "\n", "Classes", "=", "type", "(", "self", ")", ".", "mro", "(", ")", "\n", "if", "subclass_only", ":", "\n", "        ", "Classes", "=", "Classes", "[", ":", "1", "]", "\n", "", "for", "Cls", "in", "Classes", ":", "# class inheritances", "\n", "        ", "if", "'__init__'", "in", "vars", "(", "Cls", ")", ":", "\n", "            ", "args", "+=", "getfullargspec", "(", "Cls", ".", "__init__", ")", ".", "args", "[", "1", ":", "]", "\n", "", "", "for", "arg", "in", "args", ":", "\n", "        ", "attr", "=", "prefix", "+", "arg", "\n", "if", "arg", "in", "values", "and", "(", "not", "hasattr", "(", "self", ",", "attr", ")", "or", "overwrite", ")", ":", "\n", "            ", "setattr", "(", "self", ",", "attr", ",", "values", "[", "arg", "]", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.astooke_rlpyt.utils.tensor.select_at_indexes": [[5, 16], ["len", "indexes.numel", "tensor.view", "s_flat.view", "torch.arange", "indexes.view"], "function", ["None"], ["def", "select_at_indexes", "(", "indexes", ",", "tensor", ")", ":", "\n", "    ", "\"\"\"Returns the contents of ``tensor`` at the multi-dimensional integer\n    array ``indexes``. Leading dimensions of ``tensor`` must match the\n    dimensions of ``indexes``.\n    \"\"\"", "\n", "dim", "=", "len", "(", "indexes", ".", "shape", ")", "\n", "assert", "indexes", ".", "shape", "==", "tensor", ".", "shape", "[", ":", "dim", "]", "\n", "num", "=", "indexes", ".", "numel", "(", ")", "\n", "t_flat", "=", "tensor", ".", "view", "(", "(", "num", ",", ")", "+", "tensor", ".", "shape", "[", "dim", ":", "]", ")", "\n", "s_flat", "=", "t_flat", "[", "torch", ".", "arange", "(", "num", ")", ",", "indexes", ".", "view", "(", "-", "1", ")", "]", "\n", "return", "s_flat", ".", "view", "(", "tensor", ".", "shape", "[", ":", "dim", "]", "+", "tensor", ".", "shape", "[", "dim", "+", "1", ":", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.utils.tensor.to_onehot": [[18, 28], ["torch.zeros", "torch.zeros.scatter_", "indexes.unsqueeze().type", "indexes.unsqueeze"], "function", ["home.repos.pwc.inspect_result.astooke_rlpyt.utils.misc.zeros"], ["", "def", "to_onehot", "(", "indexes", ",", "num", ",", "dtype", "=", "None", ")", ":", "\n", "    ", "\"\"\"Converts integer values in multi-dimensional tensor ``indexes``\n    to one-hot values of size ``num``; expanded in an additional\n    trailing dimension.\"\"\"", "\n", "if", "dtype", "is", "None", ":", "\n", "        ", "dtype", "=", "indexes", ".", "dtype", "\n", "", "onehot", "=", "torch", ".", "zeros", "(", "indexes", ".", "shape", "+", "(", "num", ",", ")", ",", "\n", "dtype", "=", "dtype", ",", "device", "=", "indexes", ".", "device", ")", "\n", "onehot", ".", "scatter_", "(", "-", "1", ",", "indexes", ".", "unsqueeze", "(", "-", "1", ")", ".", "type", "(", "torch", ".", "long", ")", ",", "1", ")", "\n", "return", "onehot", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.utils.tensor.from_onehot": [[30, 37], ["torch.argmax", "indexes.type.type"], "function", ["None"], ["", "def", "from_onehot", "(", "onehot", ",", "dim", "=", "-", "1", ",", "dtype", "=", "None", ")", ":", "\n", "    ", "\"\"\"Argmax over trailing dimension of tensor ``onehot``. Optional return\n    dtype specification.\"\"\"", "\n", "indexes", "=", "torch", ".", "argmax", "(", "onehot", ",", "dim", "=", "dim", ")", "\n", "if", "dtype", "is", "not", "None", ":", "\n", "        ", "indexes", "=", "indexes", ".", "type", "(", "dtype", ")", "\n", "", "return", "indexes", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.utils.tensor.valid_mean": [[39, 47], ["valid.type.type", "tensor.mean", "valid.type.sum"], "function", ["None"], ["", "def", "valid_mean", "(", "tensor", ",", "valid", "=", "None", ",", "dim", "=", "None", ")", ":", "\n", "    ", "\"\"\"Mean of ``tensor``, accounting for optional mask ``valid``,\n    optionally along a dimension.\"\"\"", "\n", "dim", "=", "(", ")", "if", "dim", "is", "None", "else", "dim", "\n", "if", "valid", "is", "None", ":", "\n", "        ", "return", "tensor", ".", "mean", "(", "dim", "=", "dim", ")", "\n", "", "valid", "=", "valid", ".", "type", "(", "tensor", ".", "dtype", ")", "# Convert as needed.", "\n", "return", "(", "tensor", "*", "valid", ")", ".", "sum", "(", "dim", "=", "dim", ")", "/", "valid", ".", "sum", "(", "dim", "=", "dim", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.utils.tensor.infer_leading_dims": [[49, 69], ["tensor.dim"], "function", ["home.repos.pwc.inspect_result.astooke_rlpyt.distributions.discrete.DiscreteMixin.dim"], ["", "def", "infer_leading_dims", "(", "tensor", ",", "dim", ")", ":", "\n", "    ", "\"\"\"Looks for up to two leading dimensions in ``tensor``, before\n    the data dimensions, of which there are assumed to be ``dim`` number.\n    For use at beginning of model's ``forward()`` method, which should \n    finish with ``restore_leading_dims()`` (see that function for help.)\n    Returns:\n    lead_dim: int --number of leading dims found.\n    T: int --size of first leading dim, if two leading dims, o/w 1.\n    B: int --size of first leading dim if one, second leading dim if two, o/w 1.\n    shape: tensor shape after leading dims.\n    \"\"\"", "\n", "lead_dim", "=", "tensor", ".", "dim", "(", ")", "-", "dim", "\n", "assert", "lead_dim", "in", "(", "0", ",", "1", ",", "2", ")", "\n", "if", "lead_dim", "==", "2", ":", "\n", "        ", "T", ",", "B", "=", "tensor", ".", "shape", "[", ":", "2", "]", "\n", "", "else", ":", "\n", "        ", "T", "=", "1", "\n", "B", "=", "1", "if", "lead_dim", "==", "0", "else", "tensor", ".", "shape", "[", "0", "]", "\n", "", "shape", "=", "tensor", ".", "shape", "[", "lead_dim", ":", "]", "\n", "return", "lead_dim", ",", "T", ",", "B", ",", "shape", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.utils.tensor.restore_leading_dims": [[71, 87], ["isinstance", "tuple", "tuple", "t.view", "t.squeeze"], "function", ["None"], ["", "def", "restore_leading_dims", "(", "tensors", ",", "lead_dim", ",", "T", "=", "1", ",", "B", "=", "1", ")", ":", "\n", "    ", "\"\"\"Reshapes ``tensors`` (one or `tuple`, `list`) to to have ``lead_dim``\n    leading dimensions, which will become [], [B], or [T,B].  Assumes input\n    tensors already have a leading Batch dimension, which might need to be\n    removed. (Typically the last layer of model will compute with leading\n    batch dimension.)  For use in model ``forward()`` method, so that output\n    dimensions match input dimensions, and the same model can be used for any\n    such case.  Use with outputs from ``infer_leading_dims()``.\"\"\"", "\n", "is_seq", "=", "isinstance", "(", "tensors", ",", "(", "tuple", ",", "list", ")", ")", "\n", "tensors", "=", "tensors", "if", "is_seq", "else", "(", "tensors", ",", ")", "\n", "if", "lead_dim", "==", "2", ":", "# (Put T dim.)", "\n", "        ", "tensors", "=", "tuple", "(", "t", ".", "view", "(", "(", "T", ",", "B", ")", "+", "t", ".", "shape", "[", "1", ":", "]", ")", "for", "t", "in", "tensors", ")", "\n", "", "if", "lead_dim", "==", "0", ":", "# (Remove B=1 dim.)", "\n", "        ", "assert", "B", "==", "1", "\n", "tensors", "=", "tuple", "(", "t", ".", "squeeze", "(", "0", ")", "for", "t", "in", "tensors", ")", "\n", "", "return", "tensors", "if", "is_seq", "else", "tensors", "[", "0", "]", "\n", "", ""]], "home.repos.pwc.inspect_result.astooke_rlpyt.utils.data_augs.numpify": [[14, 32], ["isinstance", "func", "imgs.numpy.numpy", "isinstance", "torch.from_numpy", "torch.from_numpy"], "function", ["None"], ["def", "numpify", "(", "func", ")", ":", "\n", "    ", "\"\"\"Wrapper so that the augmentation function always works on a numpy\n    array, but if the input `imgs` is a torch tensor, a torch tensor will be\n    returned. Assumes first input and first output of the function is the\n    images array/tensor, and only operates on that.\"\"\"", "\n", "def", "numpified_aug", "(", "imgs", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "_numpify", "=", "isinstance", "(", "imgs", ",", "torch", ".", "Tensor", ")", "\n", "if", "_numpify", ":", "\n", "            ", "imgs", "=", "imgs", ".", "numpy", "(", ")", "\n", "", "ret", "=", "func", "(", "imgs", ",", "*", "args", ",", "**", "kwargs", ")", "\n", "if", "_numpify", ":", "\n", "            ", "if", "isinstance", "(", "ret", ",", "tuple", ")", ":", "\n", "# Assume first is the augmented images.", "\n", "                ", "ret", "=", "(", "torch", ".", "from_numpy", "(", "ret", "[", "0", "]", ")", ",", "*", "ret", "[", "1", ":", "]", ")", "\n", "", "else", ":", "\n", "                ", "ret", "=", "torch", ".", "from_numpy", "(", "ret", ")", "\n", "", "", "return", "ret", "\n", "", "return", "numpified_aug", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.utils.data_augs.subpixel_shift": [[39, 72], ["numpy.pad", "numpy.array", "numpy.maximum", "numpy.maximum", "numpy.zeros_like", "np.maximum.reshape", "np.maximum.reshape", "numpy.abs", "numpy.abs", "numpy.random.rand", "numpy.random.rand", "weight[].reshape"], "function", ["None"], ["", "@", "numpify", "\n", "def", "subpixel_shift", "(", "imgs", ",", "max_shift", "=", "1.", ")", ":", "\n", "    ", "\"\"\"\n    Pad input images by 1 using \"edge\" mode, and then do a nearest-neighbor\n    averaging scheme, centered at a random location for each image, up to\n    max_shift away from the origin in each x and y.  Each output pixel will\n    be a linear interpolation of the surrounding 2x2 input pixels.\n    \"\"\"", "\n", "if", "imgs", ".", "dtype", "==", "np", ".", "uint8", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "", "assert", "max_shift", "<=", "1.", "\n", "b", ",", "c", ",", "h", ",", "w", "=", "imgs", ".", "shape", "\n", "padded", "=", "np", ".", "pad", "(", "\n", "imgs", ",", "\n", "pad_width", "=", "(", "(", "0", ",", "0", ")", ",", "(", "0", ",", "0", ")", ",", "(", "1", ",", "1", ")", ",", "(", "1", ",", "1", ")", ")", ",", "\n", "mode", "=", "\"edge\"", ",", "\n", ")", "\n", "xx", "=", "np", ".", "array", "(", "[", "[", "-", "1.", ",", "0.", ",", "1.", "]", "]", ")", "# [1,3]", "\n", "\n", "rand_x", "=", "max_shift", "*", "(", "2", "*", "np", ".", "random", ".", "rand", "(", "b", ",", "1", ")", "-", "1", ")", "# [B,1]", "\n", "rand_y", "=", "max_shift", "*", "(", "2", "*", "np", ".", "random", ".", "rand", "(", "b", ",", "1", ")", "-", "1", ")", "# [B,1]", "\n", "\n", "wx", "=", "np", ".", "maximum", "(", "0.", ",", "1", "-", "np", ".", "abs", "(", "xx", "-", "rand_x", ")", ")", "# [B,3]", "\n", "wy", "=", "np", ".", "maximum", "(", "0.", ",", "1", "-", "np", ".", "abs", "(", "xx", "-", "rand_y", ")", ")", "# [B,3]", "\n", "weight", "=", "wx", ".", "reshape", "(", "b", ",", "1", ",", "3", ")", "*", "wy", ".", "reshape", "(", "b", ",", "3", ",", "1", ")", "# [B,1,3]x[B,3,1]->[B,3,3]", "\n", "\n", "shifted", "=", "np", ".", "zeros_like", "(", "imgs", ")", "\n", "for", "dy", "in", "[", "0", ",", "1", ",", "2", "]", ":", "\n", "        ", "for", "dx", "in", "[", "0", ",", "1", ",", "2", "]", ":", "\n", "            ", "shifted", "+=", "(", "weight", "[", ":", ",", "dy", ",", "dx", "]", ".", "reshape", "(", "-", "1", ",", "1", ",", "1", ",", "1", ")", "*", "\n", "padded", "[", ":", ",", ":", ",", "dy", ":", "h", "+", "dy", ",", "dx", ":", "w", "+", "dx", "]", ")", "\n", "\n", "", "", "return", "shifted", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.utils.data_augs.random_shift": [[74, 124], ["len", "imgs.transpose.reshape", "numpy.pad", "numpy.random.randint", "numpy.random.randint", "numpy.zeros_like", "enumerate", "zip", "shifted.transpose.reshape", "numpy.random.rand", "shifted.transpose.reshape", "shifted.transpose.reshape", "shifted.transpose.transpose", "imgs.transpose.transpose"], "function", ["None"], ["", "@", "numpify", "\n", "def", "random_shift", "(", "imgs", ",", "pad", "=", "1", ",", "prob", "=", "1.", ")", ":", "\n", "    ", "t", "=", "b", "=", "c", "=", "1", "\n", "shape_len", "=", "len", "(", "imgs", ".", "shape", ")", "\n", "if", "shape_len", "==", "2", ":", "# Could also make all this logic into a wrapper.", "\n", "        ", "h", ",", "w", "=", "imgs", ".", "shape", "\n", "", "elif", "shape_len", "==", "3", ":", "\n", "        ", "c", ",", "h", ",", "w", "=", "imgs", ".", "shape", "\n", "", "elif", "shape_len", "==", "4", ":", "\n", "        ", "b", ",", "c", ",", "h", ",", "w", "=", "imgs", ".", "shape", "\n", "", "elif", "shape_len", "==", "5", ":", "\n", "        ", "t", ",", "b", ",", "c", ",", "h", ",", "w", "=", "imgs", ".", "shape", "# Apply same crop to all T", "\n", "imgs", "=", "imgs", ".", "transpose", "(", "1", ",", "0", ",", "2", ",", "3", ",", "4", ")", "\n", "_c", "=", "c", "\n", "c", "=", "t", "*", "c", "\n", "# imgs = imgs.reshape(b, t * c, h, w)", "\n", "", "imgs", "=", "imgs", ".", "reshape", "(", "b", ",", "c", ",", "h", ",", "w", ")", "\n", "\n", "crop_h", "=", "h", "\n", "crop_w", "=", "w", "\n", "\n", "padded", "=", "np", ".", "pad", "(", "\n", "imgs", ",", "\n", "pad_width", "=", "(", "(", "0", ",", "0", ")", ",", "(", "0", ",", "0", ")", ",", "(", "pad", ",", "pad", ")", ",", "(", "pad", ",", "pad", ")", ")", ",", "\n", "mode", "=", "\"edge\"", ",", "\n", ")", "\n", "b", ",", "c", ",", "h", ",", "w", "=", "padded", ".", "shape", "\n", "\n", "h_max", "=", "h", "-", "crop_h", "+", "1", "\n", "w_max", "=", "w", "-", "crop_w", "+", "1", "\n", "h1s", "=", "np", ".", "random", ".", "randint", "(", "0", ",", "h_max", ",", "b", ")", "\n", "w1s", "=", "np", ".", "random", ".", "randint", "(", "0", ",", "w_max", ",", "b", ")", "\n", "if", "prob", "<", "1.", ":", "\n", "        ", "which_no_crop", "=", "np", ".", "random", ".", "rand", "(", "b", ")", ">", "prob", "\n", "h1s", "[", "which_no_crop", "]", "=", "pad", "\n", "w1s", "[", "which_no_crop", "]", "=", "pad", "\n", "\n", "", "shifted", "=", "np", ".", "zeros_like", "(", "imgs", ")", "\n", "for", "i", ",", "(", "pad_img", ",", "h1", ",", "w1", ")", "in", "enumerate", "(", "zip", "(", "padded", ",", "h1s", ",", "w1s", ")", ")", ":", "\n", "        ", "shifted", "[", "i", "]", "=", "pad_img", "[", ":", ",", "h1", ":", "h1", "+", "crop_h", ",", "w1", ":", "w1", "+", "crop_w", "]", "\n", "\n", "", "if", "shape_len", "==", "2", ":", "\n", "        ", "shifted", "=", "shifted", ".", "reshape", "(", "crop_h", ",", "crop_w", ")", "\n", "", "elif", "shape_len", "==", "3", ":", "\n", "        ", "shifted", "=", "shifted", ".", "reshape", "(", "c", ",", "crop_h", ",", "crop_w", ")", "\n", "", "elif", "shape_len", "==", "5", ":", "\n", "        ", "shifted", "=", "shifted", ".", "reshape", "(", "b", ",", "t", ",", "_c", ",", "crop_h", ",", "crop_w", ")", "\n", "shifted", "=", "shifted", ".", "transpose", "(", "1", ",", "0", ",", "2", ",", "3", ",", "4", ")", "\n", "\n", "", "return", "shifted", "\n", "", ""]], "home.repos.pwc.inspect_result.astooke_rlpyt.utils.warmup_scheduler.GradualWarmupScheduler.__init__": [[18, 26], ["torch.optim.lr_scheduler._LRScheduler.__init__", "ValueError"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.spaces.gym_wrapper.GymSpaceWrapper.__init__"], ["def", "__init__", "(", "self", ",", "optimizer", ",", "multiplier", ",", "total_epoch", ",", "after_scheduler", "=", "None", ")", ":", "\n", "        ", "self", ".", "multiplier", "=", "multiplier", "\n", "if", "self", ".", "multiplier", "<", "1.", ":", "\n", "            ", "raise", "ValueError", "(", "'multiplier should be greater thant or equal to 1.'", ")", "\n", "", "self", ".", "total_epoch", "=", "total_epoch", "\n", "self", ".", "after_scheduler", "=", "after_scheduler", "\n", "self", ".", "finished", "=", "False", "\n", "super", "(", ")", ".", "__init__", "(", "optimizer", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.utils.warmup_scheduler.GradualWarmupScheduler.get_lr": [[27, 40], ["warmup_scheduler.GradualWarmupScheduler.after_scheduler.get_lr", "float"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.utils.warmup_scheduler.GradualWarmupScheduler.get_lr"], ["", "def", "get_lr", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "last_epoch", ">", "self", ".", "total_epoch", ":", "\n", "            ", "if", "self", ".", "after_scheduler", ":", "\n", "                ", "if", "not", "self", ".", "finished", ":", "\n", "                    ", "self", ".", "after_scheduler", ".", "base_lrs", "=", "[", "base_lr", "*", "self", ".", "multiplier", "for", "base_lr", "in", "self", ".", "base_lrs", "]", "\n", "self", ".", "finished", "=", "True", "\n", "", "return", "self", ".", "after_scheduler", ".", "get_lr", "(", ")", "\n", "", "return", "[", "base_lr", "*", "self", ".", "multiplier", "for", "base_lr", "in", "self", ".", "base_lrs", "]", "\n", "\n", "", "if", "self", ".", "multiplier", "==", "1.0", ":", "\n", "            ", "return", "[", "base_lr", "*", "(", "float", "(", "self", ".", "last_epoch", ")", "/", "self", ".", "total_epoch", ")", "for", "base_lr", "in", "self", ".", "base_lrs", "]", "\n", "", "else", ":", "\n", "            ", "return", "[", "base_lr", "*", "(", "(", "self", ".", "multiplier", "-", "1.", ")", "*", "self", ".", "last_epoch", "/", "self", ".", "total_epoch", "+", "1.", ")", "for", "base_lr", "in", "self", ".", "base_lrs", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.utils.warmup_scheduler.GradualWarmupScheduler.step": [[41, 49], ["super().step", "warmup_scheduler.GradualWarmupScheduler.after_scheduler.step", "warmup_scheduler.GradualWarmupScheduler.after_scheduler.step"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.safe.safety_gym_env.SafetyGymTrajInfo.step", "home.repos.pwc.inspect_result.astooke_rlpyt.safe.safety_gym_env.SafetyGymTrajInfo.step", "home.repos.pwc.inspect_result.astooke_rlpyt.safe.safety_gym_env.SafetyGymTrajInfo.step"], ["", "", "def", "step", "(", "self", ",", "epoch", "=", "None", ",", "metrics", "=", "None", ")", ":", "\n", "        ", "if", "self", ".", "finished", "and", "self", ".", "after_scheduler", ":", "\n", "            ", "if", "epoch", "is", "None", ":", "\n", "                ", "self", ".", "after_scheduler", ".", "step", "(", "None", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "after_scheduler", ".", "step", "(", "epoch", "-", "self", ".", "total_epoch", ")", "\n", "", "", "else", ":", "\n", "            ", "return", "super", "(", ")", ".", "step", "(", "epoch", ")", "", "", "", "", ""]], "home.repos.pwc.inspect_result.astooke_rlpyt.utils.weight_decay.add_weight_decay": [[9, 30], ["model.named_parameters", "model.parameters", "no_decay.append", "decay.append", "len"], "function", ["home.repos.pwc.inspect_result.astooke_rlpyt.rl.atari_rl_models.AtariDqnModel.named_parameters", "home.repos.pwc.inspect_result.astooke_rlpyt.rl.atari_rl_models.AtariDqnModel.parameters"], ["def", "add_weight_decay", "(", "model", ",", "weight_decay", "=", "0.", ",", "filter_ndim_1", "=", "True", ",", "\n", "skip_list", "=", "None", ")", ":", "\n", "    ", "\"\"\"Returns parameters and weight_decay args for optimizer.\"\"\"", "\n", "skip_list", "=", "[", "]", "if", "skip_list", "is", "None", "else", "skip_list", "\n", "if", "weight_decay", "==", "0", "or", "(", "not", "filter_ndim_1", "and", "not", "skip_list", ")", ":", "\n", "        ", "return", "model", ".", "parameters", "(", ")", ",", "weight_decay", "\n", "", "decay", "=", "[", "]", "\n", "no_decay", "=", "[", "]", "\n", "for", "name", ",", "param", "in", "model", ".", "named_parameters", "(", ")", ":", "\n", "        ", "if", "not", "param", ".", "requires_grad", ":", "\n", "            ", "continue", "\n", "", "if", "(", "filter_ndim_1", "and", "len", "(", "param", ".", "shape", ")", "==", "1", ")", "or", "name", "in", "skip_list", ":", "\n", "            ", "no_decay", ".", "append", "(", "param", ")", "\n", "", "else", ":", "\n", "            ", "decay", ".", "append", "(", "param", ")", "\n", "", "", "params", "=", "[", "\n", "{", "'params'", ":", "no_decay", ",", "'weight_decay'", ":", "0.", "}", ",", "\n", "{", "'params'", ":", "decay", ",", "'weight_decay'", ":", "weight_decay", "}", ",", "\n", "]", "\n", "weight_decay", "=", "0.", "\n", "return", "params", ",", "weight_decay", "\n", "", ""]], "home.repos.pwc.inspect_result.astooke_rlpyt.launching.affinity.quick_affinity_code": [[31, 65], ["ValueError", "psutil.cpu_count", "torch.cuda.device_count", "affinity.encode_affinity", "min", "affinity.encode_affinity", "min", "ValueError"], "function", ["home.repos.pwc.inspect_result.astooke_rlpyt.launching.affinity.encode_affinity", "home.repos.pwc.inspect_result.astooke_rlpyt.launching.affinity.encode_affinity"], ["def", "quick_affinity_code", "(", "n_parallel", "=", "None", ",", "use_gpu", "=", "True", ",", "contexts_per_gpu", "=", "1", ")", ":", "\n", "    ", "\"\"\"Tried to autodetect hardware resources and divide them evenly among learning runs.\n\n    Args:\n        n_parallel (int or None): Can specify the number of concurrent learning runs; if using GPU, leave as ``None`` to use all GPUs, 1 per run\n        use_gpu (bool): self-explanatory\n    \"\"\"", "\n", "if", "not", "(", "use_gpu", "or", "n_parallel", ")", ":", "\n", "        ", "raise", "ValueError", "(", "\"Either use_gpu must be True or n_parallel > 0 must be given.\"", ")", "\n", "", "import", "psutil", "\n", "# n_cpu_core = psutil.cpu_count(logical=False)  # sometimes gives bad results", "\n", "n_cpu_core", "=", "psutil", ".", "cpu_count", "(", ")", "//", "2", "# assume hyperthreads will be counted", "\n", "if", "use_gpu", ":", "\n", "        ", "import", "torch", "\n", "n_gpu", "=", "torch", ".", "cuda", ".", "device_count", "(", ")", "\n", "", "else", ":", "\n", "        ", "n_gpu", "=", "0", "\n", "", "if", "n_gpu", ">", "0", ":", "\n", "        ", "if", "n_parallel", "is", "not", "None", ":", "\n", "            ", "n_gpu", "=", "min", "(", "n_parallel", ",", "n_gpu", ")", "\n", "", "n_runs", "=", "n_gpu", "*", "contexts_per_gpu", "\n", "n_cpu_core", "=", "(", "n_cpu_core", "//", "n_runs", ")", "*", "n_runs", "# Same for all.", "\n", "return", "encode_affinity", "(", "n_cpu_core", "=", "n_cpu_core", ",", "n_gpu", "=", "n_gpu", ",", "\n", "contexts_per_gpu", "=", "contexts_per_gpu", ")", "\n", "", "else", ":", "\n", "        ", "if", "not", "n_parallel", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "\"n_parallel > 0 must be given if use_gpu=False or no GPUs are present.\"", "\n", ")", "\n", "", "n_parallel", "=", "min", "(", "n_parallel", ",", "n_cpu_core", ")", "\n", "n_cpu_core", "=", "(", "n_cpu_core", "//", "n_parallel", ")", "*", "n_parallel", "# Same for all.", "\n", "cpu_per_run", "=", "n_cpu_core", "//", "n_parallel", "\n", "return", "encode_affinity", "(", "n_cpu_core", "=", "n_cpu_core", ",", "n_gpu", "=", "0", ",", "\n", "cpu_per_run", "=", "cpu_per_run", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.launching.affinity.encode_affinity": [[67, 143], ["affinity.get_hyperthread_offset", "affinity.get_n_socket"], "function", ["home.repos.pwc.inspect_result.astooke_rlpyt.launching.affinity.get_hyperthread_offset", "home.repos.pwc.inspect_result.astooke_rlpyt.launching.affinity.get_n_socket"], ["", "", "def", "encode_affinity", "(", "\n", "n_cpu_core", "=", "1", ",", "# Total number to use on machine (not virtual).", "\n", "n_gpu", "=", "0", ",", "# Total number to use on machine.", "\n", "contexts_per_gpu", "=", "1", ",", "# e.g. 2 will put two experiments per GPU.", "\n", "gpu_per_run", "=", "1", ",", "# For multi-GPU optimizaion.", "\n", "cpu_per_run", "=", "1", ",", "# Specify if not using GPU.", "\n", "cpu_per_worker", "=", "1", ",", "# Use 1 unless environment is multi-threaded.", "\n", "cpu_reserved", "=", "0", ",", "# Number CPU to reserve per GPU.", "\n", "hyperthread_offset", "=", "None", ",", "# Leave None for auto-detect.", "\n", "n_socket", "=", "None", ",", "# Leave None for auto-detect.", "\n", "run_slot", "=", "None", ",", "# Leave None in `run` script, but specified in `train` script.", "\n", "async_sample", "=", "False", ",", "# True if asynchronous sampling / optimization.", "\n", "sample_gpu_per_run", "=", "0", ",", "# For asynchronous sampling.", "\n", "optim_sample_share_gpu", "=", "False", ",", "# Async sampling, overrides sample_gpu.", "\n", "alternating", "=", "False", ",", "# True for altenating sampler.", "\n", "set_affinity", "=", "True", ",", "# Everything same except psutil.Process().cpu_affinity(cpus)", "\n", ")", ":", "\n", "    ", "\"\"\"Encodes the hardware configuration into a string (with meanings defined\n    in this file) which can be passed as a command line argument to call the\n    training script. Use in overall experiments setup script to specify\n    computer and experiment resources into ``run_experiments()``.\n\n    We refer to an \"experiment\" as an individual learning run, i.e. one set of\n    hyperparameters and which does not interact with other runs.\n\n    Args:\n        n_cpu_core (int): Total number of phyical cores to use on machine (not virtual)\n        n_gpu (int): Total number of GPUs to use on machine\n        contexts_per_gpu (int): How many experiment to share each GPU\n        gpu_per_run (int): How many GPUs to use per experiment (for multi-GPU optimization)\n        cpu_per_run (int): If not using GPU, specify how macores per experiment\n        cpu_per_worker (int): CPU cores per sampler worker; 1 unless environment is multi-threaded\n        cpu_reserved (int): Number of CPUs to reserve per GPU, and not allow sampler to use them\n        hyperthread_offset (int): Typically the number of physical cores, since they are labeled 0-x, and hyperthreads as (x+1)-2x; use 0 to disable hyperthreads, None to auto-detect\n        n_socket (int): Number of CPU sockets in machine; tries to keep CPUs grouped on same socket, and match socket-to-GPU affinity\n        run_slot (int): Which hardware slot to use; leave ``None`` into ``run_experiments()``, but specified for inidividual train script\n        async_sample (bool): True if asynchronous sampling/optimization mode; different affinity structure needed\n        sample_gpu_per_run (int): In asynchronous mode only, number of action-server GPUs per experiment\n        optim_sample_share_gpu (bool): In asynchronous mode only, whether to use same GPU(s) for both training and sampling\n        alternating (bool):  True if using alternating sampler (will make more worker assignments)\n        set_affinity (bool): False to disable runner and sampler from setting cpu affinity via `psutil`, maybe inappropriate in cloud machines.\n\n    \"\"\"", "\n", "affinity_code", "=", "f\"{n_cpu_core}{N_CPU_CORE}_{n_gpu}{N_GPU}\"", "\n", "if", "hyperthread_offset", "is", "None", ":", "\n", "        ", "hyperthread_offset", "=", "get_hyperthread_offset", "(", ")", "\n", "", "if", "n_socket", "is", "None", ":", "\n", "        ", "n_socket", "=", "get_n_socket", "(", ")", "\n", "", "if", "contexts_per_gpu", ">", "1", ":", "\n", "        ", "affinity_code", "+=", "f\"_{contexts_per_gpu}{CONTEXTS_PER_GPU}\"", "\n", "", "if", "gpu_per_run", ">", "1", ":", "\n", "        ", "affinity_code", "+=", "f\"_{gpu_per_run}{GPU_PER_RUN}\"", "\n", "", "if", "n_gpu", "==", "0", ":", "\n", "        ", "affinity_code", "+=", "f\"_{cpu_per_run}{CPU_PER_RUN}\"", "\n", "", "if", "cpu_per_worker", ">", "1", ":", "\n", "        ", "affinity_code", "+=", "f\"_{cpu_per_worker}{CPU_PER_WORKER}\"", "\n", "", "if", "hyperthread_offset", "!=", "n_cpu_core", ":", "\n", "        ", "affinity_code", "+=", "f\"_{hyperthread_offset}{HYPERTHREAD_OFFSET}\"", "\n", "", "if", "n_socket", ">", "1", ":", "\n", "        ", "affinity_code", "+=", "f\"_{n_socket}{N_SOCKET}\"", "\n", "", "if", "cpu_reserved", ">", "0", ":", "\n", "        ", "affinity_code", "+=", "f\"_{cpu_reserved}{CPU_RESERVED}\"", "\n", "", "if", "async_sample", ":", "\n", "        ", "affinity_code", "+=", "f\"_1{ASYNC_SAMPLE}\"", "\n", "", "if", "sample_gpu_per_run", ">", "0", ":", "\n", "        ", "affinity_code", "+=", "f\"_{sample_gpu_per_run}{SAMPLE_GPU_PER_RUN}\"", "\n", "", "if", "optim_sample_share_gpu", ":", "\n", "        ", "affinity_code", "+=", "f\"_1{OPTIM_SAMPLE_SHARE_GPU}\"", "\n", "", "if", "alternating", ":", "\n", "        ", "affinity_code", "+=", "f\"_1{ALTERNATING}\"", "\n", "", "if", "not", "set_affinity", ":", "\n", "        ", "affinity_code", "+=", "f\"_0{SET_AFFINITY}\"", "\n", "", "if", "run_slot", "is", "not", "None", ":", "\n", "        ", "assert", "run_slot", "<=", "(", "n_gpu", "*", "contexts_per_gpu", ")", "//", "gpu_per_run", "\n", "affinity_code", "=", "f\"{run_slot}{RUN_SLOT}_\"", "+", "affinity_code", "\n", "", "return", "affinity_code", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.launching.affinity.prepend_run_slot": [[145, 148], ["None"], "function", ["None"], ["", "def", "prepend_run_slot", "(", "run_slot", ",", "affinity_code", ")", ":", "\n", "    ", "\"\"\"Use in launch manager when assigning run slot.\"\"\"", "\n", "return", "f\"{run_slot}{RUN_SLOT}_\"", "+", "affinity_code", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.launching.affinity.affinity_from_code": [[150, 161], ["affinity.remove_run_slot", "affinity.decode_affinity", "affinity.build_cpu_affinity", "decode_affinity.get", "affinity.build_gpu_affinity", "decode_affinity.pop", "affinity.build_async_affinity", "decode_affinity.get", "affinity.build_multigpu_affinity"], "function", ["home.repos.pwc.inspect_result.astooke_rlpyt.launching.affinity.remove_run_slot", "home.repos.pwc.inspect_result.astooke_rlpyt.launching.affinity.decode_affinity", "home.repos.pwc.inspect_result.astooke_rlpyt.launching.affinity.build_cpu_affinity", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.collections.NamedArrayTuple.get", "home.repos.pwc.inspect_result.astooke_rlpyt.launching.affinity.build_gpu_affinity", "home.repos.pwc.inspect_result.astooke_rlpyt.launching.affinity.build_async_affinity", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.collections.NamedArrayTuple.get", "home.repos.pwc.inspect_result.astooke_rlpyt.launching.affinity.build_multigpu_affinity"], ["", "def", "affinity_from_code", "(", "run_slot_affinity_code", ")", ":", "\n", "    ", "\"\"\"Use in individual experiment script; pass output to Runner.\"\"\"", "\n", "run_slot", ",", "aff_code", "=", "remove_run_slot", "(", "run_slot_affinity_code", ")", "\n", "aff_params", "=", "decode_affinity", "(", "aff_code", ")", "\n", "if", "aff_params", ".", "get", "(", "N_GPU", ",", "0", ")", ">", "0", ":", "\n", "        ", "if", "aff_params", ".", "pop", "(", "ASYNC_SAMPLE", ",", "0", ")", ">", "0", ":", "\n", "            ", "return", "build_async_affinity", "(", "run_slot", ",", "**", "aff_params", ")", "\n", "", "elif", "aff_params", ".", "get", "(", "GPU_PER_RUN", ",", "1", ")", ">", "1", ":", "\n", "            ", "return", "build_multigpu_affinity", "(", "run_slot", ",", "**", "aff_params", ")", "\n", "", "return", "build_gpu_affinity", "(", "run_slot", ",", "**", "aff_params", ")", "\n", "", "return", "build_cpu_affinity", "(", "run_slot", ",", "**", "aff_params", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.launching.affinity.make_affinity": [[163, 166], ["affinity.affinity_from_code", "affinity.encode_affinity"], "function", ["home.repos.pwc.inspect_result.astooke_rlpyt.launching.affinity.affinity_from_code", "home.repos.pwc.inspect_result.astooke_rlpyt.launching.affinity.encode_affinity"], ["", "def", "make_affinity", "(", "run_slot", "=", "0", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Input same kwargs as ``encode_affinity()``, returns the AttrDict form.\"\"\"", "\n", "return", "affinity_from_code", "(", "encode_affinity", "(", "run_slot", "=", "run_slot", ",", "**", "kwargs", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.launching.affinity.get_n_socket": [[170, 175], ["max", "int", "subprocess.check_output"], "function", ["None"], ["", "def", "get_n_socket", "(", ")", ":", "\n", "    ", "import", "subprocess", "\n", "return", "max", "(", "1", ",", "int", "(", "subprocess", ".", "check_output", "(", "\n", "'cat /proc/cpuinfo | grep \"physical id\" | sort -u | wc -l'", ",", "\n", "shell", "=", "True", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.launching.affinity.get_hyperthread_offset": [[177, 186], ["psutil.cpu_count", "psutil.cpu_count"], "function", ["None"], ["", "def", "get_hyperthread_offset", "(", ")", ":", "\n", "    ", "import", "psutil", "# (If returns 0, will not try to use hyperthreads.)", "\n", "# UNRELIABLE:", "\n", "# hto = psutil.cpu_count() - psutil.cpu_count(logical=False)", "\n", "vcpu", "=", "psutil", ".", "cpu_count", "(", ")", "\n", "if", "vcpu", "!=", "psutil", ".", "cpu_count", "(", "logical", "=", "False", ")", "and", "vcpu", "%", "2", "==", "0", ":", "\n", "# Best guess?", "\n", "        ", "return", "vcpu", "//", "2", "\n", "", "return", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.launching.affinity.get_n_run_slots": [[188, 198], ["affinity.decode_affinity", "decode_affinity.get", "decode_affinity.get", "decode_affinity.get", "decode_affinity.get", "decode_affinity.get", "decode_affinity.get", "decode_affinity.get"], "function", ["home.repos.pwc.inspect_result.astooke_rlpyt.launching.affinity.decode_affinity", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.collections.NamedArrayTuple.get", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.collections.NamedArrayTuple.get", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.collections.NamedArrayTuple.get", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.collections.NamedArrayTuple.get", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.collections.NamedArrayTuple.get", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.collections.NamedArrayTuple.get", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.collections.NamedArrayTuple.get"], ["", "def", "get_n_run_slots", "(", "affinity_code", ")", ":", "\n", "    ", "aff", "=", "decode_affinity", "(", "affinity_code", ")", "\n", "if", "aff", ".", "get", "(", "\"ass\"", ",", "0", ")", ">", "0", ":", "# Asynchronous sample mode.", "\n", "        ", "total_gpu", "=", "aff", ".", "get", "(", "\"gpr\"", ",", "1", ")", "+", "aff", ".", "get", "(", "\"sgr\"", ",", "0", ")", "*", "(", "1", "-", "aff", ".", "get", "(", "\"oss\"", ",", "0", ")", ")", "\n", "n_run_slots", "=", "aff", "[", "\"gpu\"", "]", "//", "total_gpu", "# NOTE: no cxg yet.", "\n", "", "elif", "aff", ".", "get", "(", "\"gpu\"", ",", "0", ")", ">", "0", ":", "\n", "        ", "n_run_slots", "=", "(", "aff", "[", "\"gpu\"", "]", "*", "aff", ".", "get", "(", "\"cxg\"", ",", "1", ")", ")", "//", "aff", ".", "get", "(", "\"gpr\"", ",", "1", ")", "\n", "", "else", ":", "\n", "        ", "n_run_slots", "=", "aff", "[", "\"cpu\"", "]", "//", "aff", "[", "\"cpr\"", "]", "\n", "", "return", "n_run_slots", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.launching.affinity.remove_run_slot": [[200, 205], ["run_slot_affinity_code.split", "int"], "function", ["None"], ["", "def", "remove_run_slot", "(", "run_slot_affinity_code", ")", ":", "\n", "    ", "run_slot_str", ",", "aff_code", "=", "run_slot_affinity_code", ".", "split", "(", "\"_\"", ",", "1", ")", "\n", "assert", "run_slot_str", "[", "-", "3", ":", "]", "==", "RUN_SLOT", "\n", "run_slot", "=", "int", "(", "run_slot_str", "[", ":", "-", "3", "]", ")", "\n", "return", "run_slot", ",", "aff_code", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.launching.affinity.decode_affinity": [[207, 217], ["affinity_code.split", "dict", "int", "ValueError"], "function", ["None"], ["", "def", "decode_affinity", "(", "affinity_code", ")", ":", "\n", "    ", "codes", "=", "affinity_code", ".", "split", "(", "\"_\"", ")", "\n", "aff_kwargs", "=", "dict", "(", ")", "\n", "for", "code", "in", "codes", ":", "\n", "        ", "abrv", "=", "code", "[", "-", "3", ":", "]", "\n", "if", "abrv", "not", "in", "ABBREVS", ":", "\n", "            ", "raise", "ValueError", "(", "f\"Unrecognized affinity code abbreviation: {abrv}\"", ")", "\n", "", "value", "=", "int", "(", "code", "[", ":", "-", "3", "]", ")", "\n", "aff_kwargs", "[", "abrv", "]", "=", "value", "\n", "", "return", "aff_kwargs", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.launching.affinity.build_cpu_affinity": [[219, 257], ["affinity.get_master_cpus", "affinity.get_workers_cpus", "rlpyt.utils.collections.AttrDict", "max", "tuple", "list", "range", "tuple", "range", "tuple.extend", "len", "len", "bool", "bool", "list", "range"], "function", ["home.repos.pwc.inspect_result.astooke_rlpyt.launching.affinity.get_master_cpus", "home.repos.pwc.inspect_result.astooke_rlpyt.launching.affinity.get_workers_cpus"], ["", "def", "build_cpu_affinity", "(", "slt", ",", "cpu", ",", "cpr", ",", "cpw", "=", "1", ",", "hto", "=", "None", ",", "res", "=", "0", ",", "skt", "=", "1", ",", "gpu", "=", "0", ",", "\n", "alt", "=", "0", ",", "saf", "=", "1", ")", ":", "\n", "    ", "assert", "gpu", "==", "0", "\n", "assert", "cpu", "%", "cpr", "==", "0", "\n", "hto", "=", "cpu", "if", "hto", "is", "None", "else", "hto", "# Default is None, 0 is OFF.", "\n", "assert", "(", "hto", "-", "cpu", ")", "%", "skt", "==", "0", "\n", "n_run_slots", "=", "cpu", "//", "cpr", "\n", "assert", "slt", "<=", "n_run_slots", "\n", "cpu_per_skt", "=", "max", "(", "cpu", ",", "hto", ")", "//", "skt", "\n", "if", "n_run_slots", ">=", "skt", ":", "\n", "        ", "slt_per_skt", "=", "n_run_slots", "//", "skt", "\n", "my_skt", "=", "slt", "//", "slt_per_skt", "\n", "slt_in_skt", "=", "slt", "%", "slt_per_skt", "\n", "min_core", "=", "my_skt", "*", "cpu_per_skt", "+", "slt_in_skt", "*", "cpr", "\n", "cores", "=", "tuple", "(", "range", "(", "min_core", ",", "min_core", "+", "cpr", ")", ")", "\n", "", "else", ":", "# One run multiple sockets.", "\n", "        ", "skt_per_slt", "=", "skt", "//", "n_run_slots", "\n", "cores", "=", "list", "(", ")", "\n", "low_skt", "=", "slt", "*", "skt_per_slt", "\n", "for", "s", "in", "range", "(", "skt_per_slt", ")", ":", "\n", "            ", "min_core", "=", "(", "low_skt", "+", "s", ")", "*", "cpu_per_skt", "\n", "high_core", "=", "min_core", "+", "cpr", "//", "skt_per_slt", "\n", "cores", ".", "extend", "(", "list", "(", "range", "(", "min_core", ",", "high_core", ")", ")", ")", "\n", "", "cores", "=", "tuple", "(", "cores", ")", "\n", "", "worker_cores", "=", "cores", "[", "res", ":", "]", "\n", "assert", "len", "(", "worker_cores", ")", "%", "cpw", "==", "0", "\n", "master_cpus", "=", "get_master_cpus", "(", "cores", ",", "hto", ")", "\n", "workers_cpus", "=", "get_workers_cpus", "(", "worker_cores", ",", "cpw", ",", "hto", ",", "alt", ")", "\n", "affinity", "=", "AttrDict", "(", "\n", "all_cpus", "=", "master_cpus", ",", "\n", "master_cpus", "=", "master_cpus", ",", "\n", "workers_cpus", "=", "workers_cpus", ",", "\n", "master_torch_threads", "=", "len", "(", "cores", ")", ",", "\n", "worker_torch_threads", "=", "cpw", ",", "\n", "alternating", "=", "bool", "(", "alt", ")", ",", "# Just to pass through a check.", "\n", "set_affinity", "=", "bool", "(", "saf", ")", ",", "\n", ")", "\n", "return", "affinity", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.launching.affinity.build_gpu_affinity": [[259, 272], ["affinity.build_cpu_affinity"], "function", ["home.repos.pwc.inspect_result.astooke_rlpyt.launching.affinity.build_cpu_affinity"], ["", "def", "build_gpu_affinity", "(", "slt", ",", "gpu", ",", "cpu", ",", "cxg", "=", "1", ",", "cpw", "=", "1", ",", "hto", "=", "None", ",", "res", "=", "0", ",", "skt", "=", "1", ",", "\n", "alt", "=", "0", ",", "saf", "=", "1", ")", ":", "\n", "    ", "\"\"\"Divides CPUs evenly among GPUs.\"\"\"", "\n", "n_ctx", "=", "gpu", "*", "cxg", "\n", "assert", "slt", "<", "n_ctx", "\n", "assert", "cpu", "%", "n_ctx", "==", "0", "\n", "cpr", "=", "cpu", "//", "n_ctx", "\n", "if", "cxg", ">", "1", ":", "\n", "        ", "slt", "=", "(", "slt", "%", "gpu", ")", "*", "cxg", "+", "slt", "//", "gpu", "# Spread over GPUs first.", "\n", "", "affinity", "=", "build_cpu_affinity", "(", "slt", ",", "cpu", ",", "cpr", ",", "\n", "cpw", "=", "cpw", ",", "hto", "=", "hto", ",", "res", "=", "res", ",", "skt", "=", "skt", ",", "gpu", "=", "0", ",", "alt", "=", "alt", ",", "saf", "=", "saf", ")", "\n", "affinity", "[", "\"cuda_idx\"", "]", "=", "slt", "//", "cxg", "\n", "return", "affinity", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.launching.affinity.build_multigpu_affinity": [[274, 278], ["affinity.build_gpu_affinity", "range"], "function", ["home.repos.pwc.inspect_result.astooke_rlpyt.launching.affinity.build_gpu_affinity"], ["", "def", "build_multigpu_affinity", "(", "run_slot", ",", "gpu", ",", "cpu", ",", "gpr", "=", "1", ",", "cpw", "=", "1", ",", "hto", "=", "None", ",", "res", "=", "0", ",", "\n", "skt", "=", "1", ",", "alt", "=", "0", ",", "saf", "=", "1", ")", ":", "\n", "    ", "return", "[", "build_gpu_affinity", "(", "slt", ",", "gpu", ",", "cpu", ",", "cxg", "=", "1", ",", "cpw", "=", "cpw", ",", "hto", "=", "hto", ",", "res", "=", "res", ",", "\n", "skt", "=", "skt", ",", "alt", "=", "alt", ",", "saf", "=", "saf", ")", "for", "slt", "in", "range", "(", "run_slot", "*", "gpr", ",", "(", "run_slot", "+", "1", ")", "*", "gpr", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.launching.affinity.build_async_affinity": [[280, 395], ["bool", "list", "list", "tuple", "enumerate", "enumerate", "rlpyt.utils.collections.AttrDict", "max", "list", "list", "list", "range", "tuple", "affinity.get_master_cpus", "dict", "list.append", "max", "tuple", "affinity.get_master_cpus", "affinity.get_workers_cpus", "rlpyt.utils.collections.AttrDict", "rlpyt.utils.collections.AttrDict.append", "affinity.get_master_cpus", "affinity.get_workers_cpus", "rlpyt.utils.collections.AttrDict", "range", "list", "list.extend", "range", "range", "tuple", "tuple", "range", "bool", "range", "list", "list.extend", "len", "bool", "len", "bool", "bool", "range", "tuple", "len", "bool", "bool", "range", "list", "range", "range"], "function", ["home.repos.pwc.inspect_result.astooke_rlpyt.launching.affinity.get_master_cpus", "home.repos.pwc.inspect_result.astooke_rlpyt.launching.affinity.get_master_cpus", "home.repos.pwc.inspect_result.astooke_rlpyt.launching.affinity.get_workers_cpus", "home.repos.pwc.inspect_result.astooke_rlpyt.launching.affinity.get_master_cpus", "home.repos.pwc.inspect_result.astooke_rlpyt.launching.affinity.get_workers_cpus"], ["", "def", "build_async_affinity", "(", "run_slot", ",", "gpu", ",", "cpu", ",", "gpr", "=", "1", ",", "sgr", "=", "0", ",", "oss", "=", "0", ",", "cpw", "=", "1", ",", "\n", "hto", "=", "None", ",", "res", "=", "1", ",", "skt", "=", "1", ",", "alt", "=", "0", ",", "saf", "=", "1", ")", ":", "\n", "    ", "oss", "=", "bool", "(", "oss", ")", "\n", "sgr", "=", "gpr", "if", "oss", "else", "sgr", "\n", "total_gpr", "=", "(", "gpr", "+", "sgr", "*", "(", "not", "oss", ")", ")", "\n", "n_run_slots", "=", "gpu", "//", "total_gpr", "\n", "assert", "run_slot", "<", "n_run_slots", "\n", "cpr", "=", "cpu", "//", "n_run_slots", "\n", "smp_cpr", "=", "cpr", "-", "res", "*", "gpr", "\n", "gpu_per_skt", "=", "gpu", "//", "skt", "\n", "hto", "=", "cpu", "if", "hto", "is", "None", "else", "hto", "# Default is None, 0 is OFF.", "\n", "cpu_per_skt", "=", "max", "(", "cpu", ",", "hto", ")", "//", "skt", "\n", "opt_affinities", "=", "list", "(", ")", "\n", "smp_affinities", "=", "list", "(", ")", "\n", "all_cpus", "=", "tuple", "(", ")", "\n", "if", "total_gpr", "<=", "gpu_per_skt", ":", "\n", "        ", "run_per_skt", "=", "n_run_slots", "//", "skt", "\n", "assert", "n_run_slots", "%", "skt", "==", "0", "# Relax later?", "\n", "skt_per_run", "=", "1", "\n", "run_in_skt", "=", "run_slot", "%", "run_per_skt", "\n", "my_skt", "=", "run_slot", "//", "run_per_skt", "\n", "low_opt_gpu", "=", "my_skt", "*", "gpu_per_skt", "+", "run_in_skt", "*", "total_gpr", "\n", "high_opt_gpu", "=", "low_opt_gpu", "+", "gpr", "\n", "my_opt_gpus", "=", "list", "(", "range", "(", "low_opt_gpu", ",", "high_opt_gpu", ")", ")", "\n", "my_smp_gpus", "=", "(", "my_opt_gpus", "if", "oss", "else", "\n", "list", "(", "range", "(", "high_opt_gpu", ",", "high_opt_gpu", "+", "sgr", ")", ")", ")", "\n", "", "else", ":", "# One run takes more than one socket: spread opt gpus across sockets.", "\n", "        ", "skt_per_run", "=", "skt", "//", "n_run_slots", "\n", "low_skt", "=", "run_slot", "*", "skt_per_run", "\n", "assert", "gpr", "%", "skt_per_run", "==", "0", ",", "\"Maybe try n_socket=1.\"", "\n", "assert", "sgr", "%", "skt_per_run", "==", "0", ",", "\"Maybe try n_socket=1.\"", "\n", "my_opt_gpus", "=", "list", "(", ")", "\n", "my_smp_gpus", "=", "list", "(", ")", "\n", "run_in_skt", "=", "run_per_skt", "=", "0", "\n", "for", "s", "in", "range", "(", "skt_per_run", ")", ":", "\n", "            ", "low_opt_gpu", "=", "(", "low_skt", "+", "s", ")", "*", "gpu_per_skt", "\n", "high_opt_gpu", "=", "low_opt_gpu", "+", "gpr", "//", "skt_per_run", "\n", "my_opt_gpus", ".", "extend", "(", "list", "(", "range", "(", "low_opt_gpu", ",", "high_opt_gpu", ")", ")", ")", "\n", "if", "oss", ":", "\n", "                ", "my_smp_gpus", "=", "my_opt_gpus", "\n", "", "else", ":", "\n", "                ", "high_smp_gpu", "=", "high_opt_gpu", "+", "sgr", "//", "skt_per_run", "\n", "my_smp_gpus", ".", "extend", "(", "list", "(", "range", "(", "high_opt_gpu", ",", "high_smp_gpu", ")", ")", ")", "\n", "", "", "", "for", "i", ",", "opt_gpu", "in", "enumerate", "(", "my_opt_gpus", ")", ":", "\n", "        ", "gpu_in_skt", "=", "opt_gpu", "%", "gpu_per_skt", "\n", "gpu_skt", "=", "opt_gpu", "//", "gpu_per_skt", "\n", "gpu_res", "=", "i", "if", "run_per_skt", ">=", "1", "else", "gpu_in_skt", "\n", "low_opt_core", "=", "(", "gpu_skt", "*", "cpu_per_skt", "+", "run_in_skt", "*", "cpr", "+", "\n", "gpu_res", "*", "res", ")", "\n", "high_opt_core", "=", "low_opt_core", "+", "res", "\n", "opt_cores", "=", "tuple", "(", "range", "(", "low_opt_core", ",", "high_opt_core", ")", ")", "\n", "opt_cpus", "=", "get_master_cpus", "(", "opt_cores", ",", "hto", ")", "\n", "opt_affinity", "=", "dict", "(", "cpus", "=", "opt_cpus", ",", "cuda_idx", "=", "opt_gpu", ",", "\n", "torch_threads", "=", "len", "(", "opt_cores", ")", ",", "set_affinity", "=", "bool", "(", "saf", ")", ")", "\n", "opt_affinities", ".", "append", "(", "opt_affinity", ")", "\n", "all_cpus", "+=", "opt_cpus", "\n", "", "wrkr_per_smp", "=", "smp_cpr", "//", "cpw", "\n", "smp_cpr", "=", "wrkr_per_smp", "*", "cpw", "\n", "smp_cpg", "=", "smp_cpr", "//", "max", "(", "1", ",", "sgr", ")", "\n", "for", "i", ",", "smp_gpu", "in", "enumerate", "(", "my_smp_gpus", ")", ":", "\n", "        ", "gpu_skt", "=", "smp_gpu", "//", "gpu_per_skt", "\n", "gpu_in_skt", "=", "smp_gpu", "%", "gpu_per_skt", "\n", "smp_cpu_off", "=", "(", "i", "if", "run_per_skt", ">=", "1", "else", "\n", "gpu_in_skt", "-", "(", "gpr", "//", "skt_per_run", ")", ")", "\n", "low_smp_core", "=", "(", "gpu_skt", "*", "cpu_per_skt", "+", "run_in_skt", "*", "cpr", "+", "\n", "(", "gpr", "//", "skt_per_run", ")", "*", "res", "+", "smp_cpu_off", "*", "smp_cpg", ")", "\n", "high_smp_core", "=", "low_smp_core", "+", "smp_cpg", "\n", "master_cores", "=", "tuple", "(", "range", "(", "low_smp_core", ",", "high_smp_core", ")", ")", "\n", "master_cpus", "=", "get_master_cpus", "(", "master_cores", ",", "hto", ")", "\n", "workers_cpus", "=", "get_workers_cpus", "(", "master_cores", ",", "cpw", ",", "hto", ",", "alt", ")", "\n", "smp_affinity", "=", "AttrDict", "(", "\n", "all_cpus", "=", "master_cpus", ",", "\n", "master_cpus", "=", "master_cpus", ",", "\n", "workers_cpus", "=", "workers_cpus", ",", "\n", "master_torch_threads", "=", "len", "(", "master_cores", ")", ",", "\n", "worker_torch_threads", "=", "cpw", ",", "\n", "cuda_idx", "=", "smp_gpu", ",", "\n", "alternating", "=", "bool", "(", "alt", ")", ",", "# Just to pass through a check.", "\n", "set_affinity", "=", "bool", "(", "saf", ")", ",", "\n", ")", "\n", "smp_affinities", ".", "append", "(", "smp_affinity", ")", "\n", "all_cpus", "+=", "master_cpus", "\n", "", "if", "not", "smp_affinities", ":", "# sgr==0; CPU sampler.", "\n", "        ", "if", "total_gpr", "<=", "gpu_per_skt", ":", "\n", "            ", "low_smp_core", "=", "(", "my_skt", "*", "cpu_per_skt", "+", "run_in_skt", "*", "cpr", "+", "\n", "gpr", "*", "res", ")", "\n", "master_cores", "=", "tuple", "(", "range", "(", "low_smp_core", ",", "low_smp_core", "+", "smp_cpr", ")", ")", "\n", "", "else", ":", "\n", "            ", "master_cores", "=", "tuple", "(", ")", "\n", "for", "s", "in", "range", "(", "skt_per_run", ")", ":", "\n", "                ", "low_smp_core", "=", "(", "(", "low_skt", "+", "s", ")", "*", "cpu_per_skt", "+", "\n", "(", "gpr", "//", "gpu_per_skt", ")", "*", "res", ")", "\n", "master_cores", "+=", "tuple", "(", "range", "(", "low_smp_core", ",", "low_smp_core", "+", "\n", "smp_cpr", "//", "skt_per_run", ")", ")", "\n", "", "", "master_cpus", "=", "get_master_cpus", "(", "master_cores", ",", "hto", ")", "\n", "workers_cpus", "=", "get_workers_cpus", "(", "master_cores", ",", "cpw", ",", "hto", ",", "alt", ")", "\n", "smp_affinities", "=", "AttrDict", "(", "\n", "all_cpus", "=", "master_cpus", ",", "\n", "master_cpus", "=", "master_cpus", ",", "\n", "workers_cpus", "=", "workers_cpus", ",", "\n", "master_torch_threads", "=", "len", "(", "master_cores", ")", ",", "\n", "worker_torch_threads", "=", "cpw", ",", "\n", "cuda_idx", "=", "None", ",", "\n", "alternating", "=", "bool", "(", "alt", ")", ",", "# Just to pass through a check.", "\n", "set_affinity", "=", "bool", "(", "saf", ")", ",", "\n", ")", "\n", "all_cpus", "+=", "master_cpus", "\n", "", "affinity", "=", "AttrDict", "(", "\n", "all_cpus", "=", "all_cpus", ",", "# For exp launcher to use taskset.", "\n", "optimizer", "=", "opt_affinities", ",", "\n", "sampler", "=", "smp_affinities", ",", "\n", "set_affinity", "=", "bool", "(", "saf", ")", ",", "\n", ")", "\n", "\n", "return", "affinity", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.launching.affinity.get_master_cpus": [[406, 409], ["tuple", "tuple"], "function", ["None"], ["", "def", "get_master_cpus", "(", "cores", ",", "hto", ")", ":", "\n", "    ", "hyperthreads", "=", "tuple", "(", "c", "+", "hto", "for", "c", "in", "cores", ")", "if", "hto", ">", "0", "else", "(", ")", "\n", "return", "tuple", "(", "cores", ")", "+", "hyperthreads", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.launching.affinity.get_workers_cpus": [[411, 426], ["tuple", "tuple", "tuple", "tuple", "range", "len", "len", "range", "len", "zip"], "function", ["None"], ["", "def", "get_workers_cpus", "(", "cores", ",", "cpw", ",", "hto", ",", "alt", ")", ":", "\n", "    ", "cores", "=", "cores", "[", ":", "(", "len", "(", "cores", ")", "//", "cpw", ")", "*", "cpw", "]", "# No worker less than cpw.", "\n", "cpus", "=", "tuple", "(", "cores", "[", "i", ":", "i", "+", "cpw", "]", "\n", "for", "i", "in", "range", "(", "0", ",", "len", "(", "cores", ")", ",", "cpw", ")", ")", "\n", "if", "hto", ">", "0", ":", "\n", "        ", "hyperthreads", "=", "tuple", "(", "c", "+", "hto", "for", "c", "in", "cores", ")", "\n", "hyperthreads", "=", "tuple", "(", "hyperthreads", "[", "i", ":", "i", "+", "cpw", "]", "\n", "for", "i", "in", "range", "(", "0", ",", "len", "(", "cores", ")", ",", "cpw", ")", ")", "\n", "if", "alt", ":", "\n", "            ", "cpus", "+=", "hyperthreads", "\n", "", "else", ":", "\n", "            ", "cpus", "=", "tuple", "(", "c", "+", "h", "for", "c", ",", "h", "in", "zip", "(", "cpus", ",", "hyperthreads", ")", ")", "\n", "", "", "elif", "alt", ":", "\n", "        ", "cpus", "+=", "cpus", "\n", "", "return", "cpus", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.launching.affinity.build_affinities_gpu_1cpu_drive": [[428, 486], ["tuple", "rlpyt.utils.collections.AttrDict", "range", "tuple", "tuple", "tuple", "len", "range", "range", "len", "len"], "function", ["None"], ["", "def", "build_affinities_gpu_1cpu_drive", "(", "slt", ",", "gpu", ",", "cpu", ",", "cxg", "=", "1", ",", "gpr", "=", "1", ",", "cpw", "=", "1", ",", "\n", "hto", "=", "None", ",", "skt", "=", "1", ")", ":", "\n", "    ", "\"\"\"OLD.\n    Divides CPUs evenly among GPUs, with one CPU held open for each GPU, to\n    drive it.  Workers assigned on the remaining CPUs.  Master permitted to use\n    driver core + worker cores (good in case of multi-context per GPU and old\n    alternating action server sampler, from accel_rl). GPU-driving CPUs grouped\n    at the lowest numbered cores of each CPU socket.\n    \"\"\"", "\n", "if", "gpr", ">", "1", ":", "\n", "        ", "raise", "NotImplementedError", "# (parallel training)", "\n", "", "n_ctx", "=", "gpu", "*", "cxg", "\n", "n_run_slots", "=", "n_ctx", "//", "gpr", "\n", "assert", "slt", "<", "n_run_slots", "\n", "cpu_per_gpu", "=", "cpu", "//", "gpu", "\n", "sim_cpu_per_gpu", "=", "cpu_per_gpu", "-", "1", "\n", "n_sim_cpu", "=", "cpu", "-", "gpu", "\n", "sim_cpu_per_ctx", "=", "n_sim_cpu", "//", "n_ctx", "\n", "\n", "assert", "gpu", ">=", "skt", "\n", "assert", "gpu", "%", "skt", "==", "0", "\n", "gpu_per_skt", "=", "gpu", "//", "skt", "\n", "assert", "cpu", "%", "skt", "==", "0", "\n", "cpu_per_skt", "=", "cpu", "//", "skt", "\n", "\n", "my_ctx", "=", "slt", "# Different for multi-context run, not implemented.", "\n", "my_gpu", "=", "my_ctx", "//", "cxg", "\n", "my_skt", "=", "my_gpu", "//", "gpu_per_skt", "\n", "gpu_in_skt", "=", "my_gpu", "%", "gpu_per_skt", "\n", "gpu_core", "=", "gpu_in_skt", "+", "my_skt", "*", "cpu_per_skt", "\n", "ctx_in_gpu", "=", "my_ctx", "%", "cxg", "\n", "\n", "min_sim_core", "=", "(", "my_skt", "*", "cpu_per_skt", "+", "gpu_per_skt", "+", "\n", "gpu_in_skt", "*", "sim_cpu_per_gpu", "+", "ctx_in_gpu", "*", "sim_cpu_per_ctx", ")", "\n", "sim_cores", "=", "tuple", "(", "range", "(", "min_sim_core", ",", "min_sim_core", "+", "sim_cpu_per_ctx", ")", ")", "\n", "\n", "assert", "len", "(", "sim_cores", ")", "%", "cpw", "==", "0", "\n", "if", "hto", "is", "None", ":", "\n", "        ", "hto", "=", "cpu", "\n", "", "if", "hto", ">", "0", ":", "\n", "        ", "hyperthreads", "=", "tuple", "(", "c", "+", "hto", "for", "c", "in", "sim_cores", ")", "\n", "workers_cpus", "=", "tuple", "(", "sim_cores", "[", "i", ":", "i", "+", "cpw", "]", "+", "hyperthreads", "[", "i", ":", "i", "+", "cpw", "]", "\n", "for", "i", "in", "range", "(", "0", ",", "len", "(", "sim_cores", ")", ",", "cpw", ")", ")", "\n", "master_cpus", "=", "(", "gpu_core", ",", ")", "+", "sim_cores", "+", "(", "gpu_core", "+", "hto", ",", ")", "+", "hyperthreads", "\n", "", "else", ":", "\n", "        ", "workers_cpus", "=", "tuple", "(", "sim_cores", "[", "i", ":", "i", "+", "cpw", "]", "\n", "for", "i", "in", "range", "(", "0", ",", "len", "(", "sim_cores", ")", ",", "cpw", ")", ")", "\n", "master_cpus", "=", "(", "gpu_core", ",", ")", "+", "sim_cores", "\n", "\n", "", "affinity", "=", "AttrDict", "(", "\n", "all_cpus", "=", "master_cpus", ",", "\n", "master_cpus", "=", "master_cpus", ",", "\n", "workers_cpus", "=", "workers_cpus", ",", "\n", "master_torch_threads", "=", "1", ",", "\n", "worker_torch_threads", "=", "cpw", ",", "\n", "cuda_idx", "=", "my_gpu", ",", "\n", ")", "\n", "return", "affinity", "\n", "", ""]], "home.repos.pwc.inspect_result.astooke_rlpyt.launching.exp_launcher.log_exps_tree": [[13, 20], ["os.makedirs", "os.makedirs", "open", "f.write", "f.write", "os.join", "f.write", "os.getpid", "os.getpid", "len", "len"], "function", ["home.repos.pwc.inspect_result.astooke_rlpyt.envs.dmlab.LevelCache.write", "home.repos.pwc.inspect_result.astooke_rlpyt.envs.dmlab.LevelCache.write", "home.repos.pwc.inspect_result.astooke_rlpyt.envs.dmlab.LevelCache.write"], ["def", "log_exps_tree", "(", "exp_dir", ",", "log_dirs", ",", "runs_per_setting", ")", ":", "\n", "    ", "os", ".", "makedirs", "(", "exp_dir", ",", "exist_ok", "=", "True", ")", "\n", "with", "open", "(", "osp", ".", "join", "(", "exp_dir", ",", "\"experiments_tree.txt\"", ")", ",", "\"w\"", ")", "as", "f", ":", "\n", "        ", "f", ".", "write", "(", "f\"Experiment manager process ID: {os.getpid()}.\\n\"", ")", "\n", "f", ".", "write", "(", "\"Number of settings (experiments) to run: \"", "\n", "f\"{len(log_dirs)}  ({runs_per_setting * len(log_dirs)}).\\n\\n\"", ")", "\n", "[", "f", ".", "write", "(", "log_dir", "+", "\"\\n\"", ")", "for", "log_dir", "in", "log_dirs", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.launching.exp_launcher.log_num_launched": [[22, 25], ["open", "f.write", "os.join"], "function", ["home.repos.pwc.inspect_result.astooke_rlpyt.envs.dmlab.LevelCache.write"], ["", "", "def", "log_num_launched", "(", "exp_dir", ",", "n", ",", "total", ")", ":", "\n", "    ", "with", "open", "(", "osp", ".", "join", "(", "exp_dir", ",", "\"num_launched.txt\"", ")", ",", "\"w\"", ")", "as", "f", ":", "\n", "        ", "f", ".", "write", "(", "f\"Experiments launched so far: {n} out of {total}.\\n\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.launching.exp_launcher.launch_experiment": [[27, 78], ["rlpyt.utils.launching.affinity.prepend_run_slot", "rlpyt.utils.launching.affinity.affinity_from_code", "list", "rlpyt.utils.launching.variant.save_variant", "print", "isinstance", "rlpyt.utils.launching.affinity.affinity_from_code.get", "str", "str", "str", "os.environ.copy", "os.environ.copy", "print", "subprocess.Popen", "subprocess.Popen", "isinstance", "affinity[].get", "rlpyt.utils.launching.affinity.affinity_from_code.get", "str", "str"], "function", ["home.repos.pwc.inspect_result.astooke_rlpyt.launching.affinity.prepend_run_slot", "home.repos.pwc.inspect_result.astooke_rlpyt.launching.affinity.affinity_from_code", "home.repos.pwc.inspect_result.astooke_rlpyt.launching.variant.save_variant", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.collections.NamedArrayTuple.get", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.collections.AttrDict.copy", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.collections.AttrDict.copy", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.collections.NamedArrayTuple.get", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.collections.NamedArrayTuple.get"], ["", "", "def", "launch_experiment", "(", "\n", "script", ",", "\n", "run_slot", ",", "\n", "affinity_code", ",", "\n", "log_dir", ",", "\n", "variant", ",", "\n", "run_ID", ",", "\n", "args", ",", "\n", "python_executable", "=", "None", ",", "\n", "set_egl_device", "=", "False", ",", "\n", ")", ":", "\n", "    ", "\"\"\"Launches one learning run using ``subprocess.Popen()`` to call the\n    python script.  Calls the script as:\n    ``python {script} {slot_affinity_code} {log_dir} {run_ID} {*args}``\n\n    If ``affinity_code[\"all_cpus\"]`` is provided, then the call is prepended\n    with ``tasket -c ..`` and the listed cpus (this is the most sure way to\n    keep the run limited to these CPU cores).  Also saves the `variant` file.\n    Returns the process handle, which can be monitored.\n   \n    Use ``set_egl_device=True`` to set an environment variable\n    ``EGL_DEVICE_ID`` equal to the same value as the cuda index for the\n    algorithm.  For example, can use with DMControl environment modified\n    to look for this environment variable when selecting a GPU for headless\n    rendering.\n    \"\"\"", "\n", "slot_affinity_code", "=", "prepend_run_slot", "(", "run_slot", ",", "affinity_code", ")", "\n", "affinity", "=", "affinity_from_code", "(", "slot_affinity_code", ")", "\n", "call_list", "=", "list", "(", ")", "\n", "if", "isinstance", "(", "affinity", ",", "dict", ")", "and", "affinity", ".", "get", "(", "\"all_cpus\"", ",", "False", ")", ":", "\n", "        ", "cpus", "=", "\",\"", ".", "join", "(", "str", "(", "c", ")", "for", "c", "in", "affinity", "[", "\"all_cpus\"", "]", ")", "\n", "", "elif", "isinstance", "(", "affinity", ",", "list", ")", "and", "affinity", "[", "0", "]", ".", "get", "(", "\"all_cpus\"", ",", "False", ")", ":", "\n", "        ", "cpus", "=", "\",\"", ".", "join", "(", "str", "(", "c", ")", "for", "aff", "in", "affinity", "for", "c", "in", "aff", "[", "\"all_cpus\"", "]", ")", "\n", "", "else", ":", "\n", "        ", "cpus", "=", "(", ")", "\n", "", "if", "cpus", ":", "\n", "        ", "call_list", "+=", "[", "\"taskset\"", ",", "\"-c\"", ",", "cpus", "]", "# PyTorch obeys better than just psutil.", "\n", "", "py", "=", "python_executable", "if", "python_executable", "else", "sys", ".", "executable", "or", "\"python\"", "\n", "call_list", "+=", "[", "py", ",", "script", ",", "slot_affinity_code", ",", "log_dir", ",", "str", "(", "run_ID", ")", "]", "\n", "call_list", "+=", "[", "str", "(", "a", ")", "for", "a", "in", "args", "]", "\n", "save_variant", "(", "variant", ",", "log_dir", ")", "\n", "print", "(", "\"\\ncall string:\\n\"", ",", "\" \"", ".", "join", "(", "call_list", ")", ")", "\n", "if", "set_egl_device", "and", "affinity", ".", "get", "(", "\"cuda_idx\"", ",", "None", ")", "is", "not", "None", ":", "\n", "        ", "egl_device_id", "=", "str", "(", "affinity", "[", "\"cuda_idx\"", "]", ")", "\n", "egl_env", "=", "os", ".", "environ", ".", "copy", "(", ")", "\n", "egl_env", "[", "\"EGL_DEVICE_ID\"", "]", "=", "egl_device_id", "\n", "print", "(", "f\"Assigning EGL_DEVICE_ID={egl_device_id}\"", ")", "\n", "p", "=", "subprocess", ".", "Popen", "(", "call_list", ",", "env", "=", "egl_env", ")", "\n", "", "else", ":", "\n", "        ", "p", "=", "subprocess", ".", "Popen", "(", "call_list", ")", "\n", "", "return", "p", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.launching.exp_launcher.run_experiments": [[80, 136], ["rlpyt.utils.launching.affinity.get_n_run_slots", "rlpyt.utils.logging.context.get_log_dir", "exp_launcher.log_exps_tree", "range", "len", "len", "len", "len", "zip", "len", "len", "os.join", "os.makedirs", "os.makedirs", "p.wait", "enumerate", "time.sleep", "exp_launcher.launch_experiment", "exp_launcher.log_num_launched", "p.poll"], "function", ["home.repos.pwc.inspect_result.astooke_rlpyt.launching.affinity.get_n_run_slots", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.context.get_log_dir", "home.repos.pwc.inspect_result.astooke_rlpyt.launching.exp_launcher.log_exps_tree", "home.repos.pwc.inspect_result.astooke_rlpyt.launching.exp_launcher.launch_experiment", "home.repos.pwc.inspect_result.astooke_rlpyt.launching.exp_launcher.log_num_launched"], ["", "def", "run_experiments", "(", "script", ",", "affinity_code", ",", "experiment_title", ",", "runs_per_setting", ",", "\n", "variants", ",", "log_dirs", ",", "common_args", "=", "None", ",", "runs_args", "=", "None", ",", "\n", "set_egl_device", "=", "False", ")", ":", "\n", "    ", "\"\"\"Call in a script to run a set of experiments locally on a machine.  Uses\n    the ``launch_experiment()`` function for each individual run, which is a \n    call to the ``script`` file.  The number of experiments to run at the same\n    time is determined from the ``affinity_code``, which expresses the hardware\n    resources of the machine and how much resource each run gets (e.g. 4 GPU\n    machine, 2 GPUs per run).  Experiments are queued and run in sequence, with\n    the intention to avoid hardware overlap.  Inputs ``variants`` and ``log_dirs``\n    should be lists of the same length, containing each experiment configuration\n    and where to save its log files (which have the same name, so can't exist\n    in the same folder).\n\n    Hint:\n        To monitor progress, view the `num_launched.txt` file and `experiments_tree.txt`\n        file in the experiment root directory, and also check the length of each\n        `progress.csv` file, e.g. ``wc -l experiment-directory/.../run_*/progress.csv``.\n    \"\"\"", "\n", "n_run_slots", "=", "get_n_run_slots", "(", "affinity_code", ")", "\n", "exp_dir", "=", "get_log_dir", "(", "experiment_title", ")", "\n", "procs", "=", "[", "None", "]", "*", "n_run_slots", "\n", "common_args", "=", "(", ")", "if", "common_args", "is", "None", "else", "common_args", "\n", "assert", "len", "(", "variants", ")", "==", "len", "(", "log_dirs", ")", "\n", "if", "runs_args", "is", "None", ":", "\n", "        ", "runs_args", "=", "[", "(", ")", "]", "*", "len", "(", "variants", ")", "\n", "", "assert", "len", "(", "runs_args", ")", "==", "len", "(", "variants", ")", "\n", "log_exps_tree", "(", "exp_dir", ",", "log_dirs", ",", "runs_per_setting", ")", "\n", "num_launched", ",", "total", "=", "0", ",", "runs_per_setting", "*", "len", "(", "variants", ")", "\n", "for", "run_ID", "in", "range", "(", "runs_per_setting", ")", ":", "\n", "        ", "for", "variant", ",", "log_dir", ",", "run_args", "in", "zip", "(", "variants", ",", "log_dirs", ",", "runs_args", ")", ":", "\n", "            ", "launched", "=", "False", "\n", "log_dir", "=", "osp", ".", "join", "(", "exp_dir", ",", "log_dir", ")", "\n", "os", ".", "makedirs", "(", "log_dir", ",", "exist_ok", "=", "True", ")", "\n", "while", "not", "launched", ":", "\n", "                ", "for", "run_slot", ",", "p", "in", "enumerate", "(", "procs", ")", ":", "\n", "                    ", "if", "p", "is", "None", "or", "p", ".", "poll", "(", ")", "is", "not", "None", ":", "\n", "                        ", "procs", "[", "run_slot", "]", "=", "launch_experiment", "(", "\n", "script", "=", "script", ",", "\n", "run_slot", "=", "run_slot", ",", "\n", "affinity_code", "=", "affinity_code", ",", "\n", "log_dir", "=", "log_dir", ",", "\n", "variant", "=", "variant", ",", "\n", "run_ID", "=", "run_ID", ",", "\n", "args", "=", "common_args", "+", "run_args", ",", "\n", "set_egl_device", "=", "set_egl_device", ",", "\n", ")", "\n", "launched", "=", "True", "\n", "num_launched", "+=", "1", "\n", "log_num_launched", "(", "exp_dir", ",", "num_launched", ",", "total", ")", "\n", "break", "\n", "", "", "if", "not", "launched", ":", "\n", "                    ", "time", ".", "sleep", "(", "10", ")", "\n", "", "", "", "", "for", "p", "in", "procs", ":", "\n", "        ", "if", "p", "is", "not", "None", ":", "\n", "            ", "p", ".", "wait", "(", ")", "# Don't return until they are all done.", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.astooke_rlpyt.launching.variant.make_variants": [[25, 38], ["variant._cross_variants", "dict"], "function", ["home.repos.pwc.inspect_result.astooke_rlpyt.launching.variant._cross_variants"], ["def", "make_variants", "(", "*", "variant_levels", ")", ":", "\n", "    ", "\"\"\"Takes in any number of ``VariantLevel`` objects and crosses them in order.\n    Returns the resulting lists of full variant and log directories.  Every\n    set of values in one level is paired with every set of values in the next\n    level, e.g. if two combinations are specified in one level and three\n    combinations in the next, then six total configuations will result.\n\n    Use in the script to create and run a set of learning runs.\n    \"\"\"", "\n", "variants", ",", "log_dirs", "=", "[", "dict", "(", ")", "]", ",", "[", "\"\"", "]", "\n", "for", "variant_level", "in", "variant_levels", ":", "\n", "        ", "variants", ",", "log_dirs", "=", "_cross_variants", "(", "variants", ",", "log_dirs", ",", "variant_level", ")", "\n", "", "return", "variants", ",", "log_dirs", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.launching.variant._cross_variants": [[40, 66], ["all", "list", "list", "zip", "len", "len", "len", "len", "len", "len", "zip", "copy.deepcopy", "os.join", "zip", "list.append", "list.append", "len", "len", "ValueError", "dict"], "function", ["None"], ["", "def", "_cross_variants", "(", "prev_variants", ",", "prev_log_dirs", ",", "variant_level", ")", ":", "\n", "    ", "\"\"\"For every previous variant, make all combinations with new values.\"\"\"", "\n", "keys", ",", "values", ",", "dir_names", "=", "variant_level", "\n", "assert", "len", "(", "prev_variants", ")", "==", "len", "(", "prev_log_dirs", ")", "\n", "assert", "len", "(", "values", ")", "==", "len", "(", "dir_names", ")", "\n", "assert", "len", "(", "keys", ")", "==", "len", "(", "values", "[", "0", "]", ")", "\n", "assert", "all", "(", "len", "(", "values", "[", "0", "]", ")", "==", "len", "(", "v", ")", "for", "v", "in", "values", ")", "\n", "\n", "variants", "=", "list", "(", ")", "\n", "log_dirs", "=", "list", "(", ")", "\n", "for", "prev_variant", ",", "prev_log_dir", "in", "zip", "(", "prev_variants", ",", "prev_log_dirs", ")", ":", "\n", "        ", "for", "vs", ",", "n", "in", "zip", "(", "values", ",", "dir_names", ")", ":", "\n", "            ", "variant", "=", "deepcopy", "(", "prev_variant", ")", "\n", "log_dir", "=", "osp", ".", "join", "(", "prev_log_dir", ",", "n", ")", "\n", "if", "log_dir", "in", "log_dirs", ":", "\n", "                ", "raise", "ValueError", "(", "\"Names must be unique.\"", ")", "\n", "", "for", "v", ",", "key_path", "in", "zip", "(", "vs", ",", "keys", ")", ":", "\n", "                ", "current", "=", "variant", "\n", "for", "k", "in", "key_path", "[", ":", "-", "1", "]", ":", "\n", "                    ", "if", "k", "not", "in", "current", ":", "\n", "                        ", "current", "[", "k", "]", "=", "dict", "(", ")", "\n", "", "current", "=", "current", "[", "k", "]", "\n", "", "current", "[", "key_path", "[", "-", "1", "]", "]", "=", "v", "\n", "", "variants", ".", "append", "(", "variant", ")", "\n", "log_dirs", ".", "append", "(", "log_dir", ")", "\n", "", "", "return", "variants", ",", "log_dirs", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.launching.variant.load_variant": [[68, 73], ["open", "json.load", "os.join"], "function", ["None"], ["", "def", "load_variant", "(", "log_dir", ")", ":", "\n", "    ", "\"\"\"Loads the `variant.json` file from the directory.\"\"\"", "\n", "with", "open", "(", "osp", ".", "join", "(", "log_dir", ",", "VARIANT", ")", ",", "\"r\"", ")", "as", "f", ":", "\n", "        ", "variant", "=", "json", ".", "load", "(", "f", ")", "\n", "", "return", "variant", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.launching.variant.save_variant": [[75, 79], ["open", "json.dump", "os.join"], "function", ["None"], ["", "def", "save_variant", "(", "variant", ",", "log_dir", ")", ":", "\n", "    ", "\"\"\"Saves a `variant.json` file to the directory.\"\"\"", "\n", "with", "open", "(", "osp", ".", "join", "(", "log_dir", ",", "VARIANT", ")", ",", "\"w\"", ")", "as", "f", ":", "\n", "        ", "json", ".", "dump", "(", "variant", ",", "f", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.launching.variant.update_config": [[81, 95], ["default.copy", "variant.items", "KeyError", "isinstance", "isinstance", "TypeError", "isinstance", "variant.update_config"], "function", ["home.repos.pwc.inspect_result.astooke_rlpyt.utils.collections.AttrDict.copy", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.collections.NamedArrayTuple.items", "home.repos.pwc.inspect_result.astooke_rlpyt.launching.variant.update_config"], ["", "", "def", "update_config", "(", "default", ",", "variant", ")", ":", "\n", "    ", "\"\"\"Performs deep update on all dict structures from ``variant``, updating only\n    individual fields.  Any field in ``variant`` must be present in ``default``,\n    else raises ``KeyError`` (helps prevent mistakes).  Operates recursively to\n    return a new dictionary.\"\"\"", "\n", "new", "=", "default", ".", "copy", "(", ")", "\n", "for", "k", ",", "v", "in", "variant", ".", "items", "(", ")", ":", "\n", "        ", "if", "k", "not", "in", "new", ":", "\n", "            ", "raise", "KeyError", "(", "f\"Variant key {k} not found in default config.\"", ")", "\n", "", "if", "isinstance", "(", "v", ",", "dict", ")", "!=", "isinstance", "(", "new", "[", "k", "]", ",", "dict", ")", ":", "\n", "            ", "raise", "TypeError", "(", "f\"Variant dict structure at key {k} mismatched with\"", "\n", "\" default.\"", ")", "\n", "", "new", "[", "k", "]", "=", "update_config", "(", "new", "[", "k", "]", ",", "v", ")", "if", "isinstance", "(", "v", ",", "dict", ")", "else", "v", "\n", "", "return", "new", "\n", "", ""]], "home.repos.pwc.inspect_result.astooke_rlpyt.logging.context.get_log_dir": [[16, 22], ["datetime.datetime.today().strftime", "datetime.datetime.today().strftime.split", "os.join", "datetime.datetime.today"], "function", ["None"], ["def", "get_log_dir", "(", "experiment_name", ",", "root_log_dir", "=", "None", ",", "date", "=", "True", ")", ":", "\n", "    ", "yyyymmdd_hhmmss", "=", "datetime", ".", "datetime", ".", "today", "(", ")", ".", "strftime", "(", "\"%Y%m%d-%H%M%S\"", ")", "\n", "yyyymmdd", ",", "hhmmss", "=", "yyyymmdd_hhmmss", ".", "split", "(", "\"-\"", ")", "\n", "root_log_dir", "=", "LOG_DIR", "if", "root_log_dir", "is", "None", "else", "root_log_dir", "\n", "log_dir", "=", "osp", ".", "join", "(", "root_log_dir", ",", "\"local\"", ",", "yyyymmdd", ",", "hhmmss", ",", "experiment_name", ")", "\n", "return", "log_dir", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.logging.context.logger_context": [[24, 84], ["rlpyt.utils.logging.logger.set_snapshot_mode", "rlpyt.utils.logging.logger.set_log_tabular_only", "os.join", "os.abspath", "os.join", "os.join", "os.join", "rlpyt.utils.logging.logger.set_snapshot_dir", "rlpyt.utils.logging.logger.add_text_output", "rlpyt.utils.logging.logger.add_tabular_output", "rlpyt.utils.logging.logger.push_prefix", "rlpyt.utils.logging.logger.remove_tabular_output", "rlpyt.utils.logging.logger.remove_text_output", "rlpyt.utils.logging.logger.pop_prefix", "print", "context.get_log_dir", "rlpyt.utils.logging.logger.set_tf_summary_writer", "dict", "open", "json.dump", "os.commonpath", "SummaryWriter", "type"], "function", ["home.repos.pwc.inspect_result.astooke_rlpyt.logging.logger.set_snapshot_mode", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.logger.set_log_tabular_only", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.logger.set_snapshot_dir", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.logger.add_text_output", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.logger.add_tabular_output", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.logger.push_prefix", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.logger.remove_tabular_output", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.logger.remove_text_output", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.logger.pop_prefix", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.context.get_log_dir", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.logger.set_tf_summary_writer"], ["", "@", "contextmanager", "\n", "def", "logger_context", "(", "\n", "log_dir", ",", "run_ID", ",", "name", ",", "log_params", "=", "None", ",", "snapshot_mode", "=", "\"none\"", ",", "override_prefix", "=", "False", ",", "\n", "use_summary_writer", "=", "False", ",", "\n", ")", ":", "\n", "    ", "\"\"\"Use as context manager around calls to the runner's ``train()`` method.\n    Sets up the logger directory and filenames.  Unless override_prefix is\n    True, this function automatically prepends ``log_dir`` with the rlpyt\n    logging directory and the date: `path-to-rlpyt/data/yyyymmdd/hhmmss`\n    (`data/` is in the gitignore), and appends with `/run_{run_ID}` to\n    separate multiple runs of the same settings. Saves hyperparameters\n    provided in ``log_params`` to `params.json`, along with experiment `name`\n    and `run_ID`.\n\n    Input ``snapshot_mode`` refers to how often the logger actually saves the\n    snapshot (e.g. may include agent parameters).  The runner calls on the\n    logger to save the snapshot at every iteration, but the input\n    ``snapshot_mode`` sets how often the logger actually saves (e.g. snapshot\n    may include agent parameters). Possible modes include (but check inside\n    the logger itself):\n        * \"none\": don't save at all\n        * \"last\": always save and overwrite the previous\n        * \"all\": always save and keep each iteration\n        * \"gap\": save periodically and keep each (will also need to set the gap, not done here) \n\n    The cleanup operations after the ``yield`` close files but might not be\n    strictly necessary if not launching another training session in the same\n    python process.\n    \"\"\"", "\n", "logger", ".", "set_snapshot_mode", "(", "snapshot_mode", ")", "\n", "logger", ".", "set_log_tabular_only", "(", "False", ")", "\n", "log_dir", "=", "osp", ".", "join", "(", "log_dir", ",", "f\"run_{run_ID}\"", ")", "\n", "exp_dir", "=", "osp", ".", "abspath", "(", "log_dir", ")", "\n", "if", "LOG_DIR", "!=", "osp", ".", "commonpath", "(", "[", "exp_dir", ",", "LOG_DIR", "]", ")", "and", "not", "override_prefix", ":", "\n", "        ", "print", "(", "f\"logger_context received log_dir outside of {LOG_DIR}: \"", "\n", "f\"prepending by {LOG_DIR}/local/<yyyymmdd>/<hhmmss>/\"", ")", "\n", "exp_dir", "=", "get_log_dir", "(", "log_dir", ")", "\n", "", "tabular_log_file", "=", "osp", ".", "join", "(", "exp_dir", ",", "\"progress.csv\"", ")", "\n", "text_log_file", "=", "osp", ".", "join", "(", "exp_dir", ",", "\"debug.log\"", ")", "\n", "params_log_file", "=", "osp", ".", "join", "(", "exp_dir", ",", "\"params.json\"", ")", "\n", "\n", "logger", ".", "set_snapshot_dir", "(", "exp_dir", ")", "\n", "if", "use_summary_writer", ":", "\n", "        ", "logger", ".", "set_tf_summary_writer", "(", "SummaryWriter", "(", "exp_dir", ")", ")", "\n", "", "logger", ".", "add_text_output", "(", "text_log_file", ")", "\n", "logger", ".", "add_tabular_output", "(", "tabular_log_file", ")", "\n", "logger", ".", "push_prefix", "(", "f\"{name}_{run_ID} \"", ")", "\n", "\n", "if", "log_params", "is", "None", ":", "\n", "        ", "log_params", "=", "dict", "(", ")", "\n", "", "log_params", "[", "\"name\"", "]", "=", "name", "\n", "log_params", "[", "\"run_ID\"", "]", "=", "run_ID", "\n", "with", "open", "(", "params_log_file", ",", "\"w\"", ")", "as", "f", ":", "\n", "        ", "json", ".", "dump", "(", "log_params", ",", "f", ",", "default", "=", "lambda", "o", ":", "type", "(", "o", ")", ".", "__name__", ")", "\n", "\n", "", "yield", "\n", "\n", "logger", ".", "remove_tabular_output", "(", "tabular_log_file", ")", "\n", "logger", ".", "remove_text_output", "(", "text_log_file", ")", "\n", "logger", ".", "pop_prefix", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.logging.context.add_exp_param": [[86, 115], ["os.walk", "os.walk", "os.getcwd", "os.getcwd", "os.join", "open", "json.load", "os.remove", "os.remove", "isinstance", "isinstance", "print", "params[].update", "open", "json.dump", "print", "print", "type"], "function", ["home.repos.pwc.inspect_result.astooke_rlpyt.models.running_mean_std.RunningMeanStdModel.update"], ["", "def", "add_exp_param", "(", "param_name", ",", "param_val", ",", "exp_dir", "=", "None", ",", "overwrite", "=", "False", ")", ":", "\n", "    ", "\"\"\"Puts a param in all experiments in immediate subdirectories.\n    So you can write a new distinguising param after the fact, perhaps\n    reflecting a combination of settings.\"\"\"", "\n", "if", "exp_dir", "is", "None", ":", "\n", "        ", "exp_dir", "=", "os", ".", "getcwd", "(", ")", "\n", "", "for", "sub_dir", "in", "os", ".", "walk", "(", "exp_dir", ")", ":", "\n", "        ", "if", "\"params.json\"", "in", "sub_dir", "[", "2", "]", ":", "\n", "            ", "update_param", "=", "True", "\n", "params_f", "=", "osp", ".", "join", "(", "sub_dir", "[", "0", "]", ",", "\"params.json\"", ")", "\n", "with", "open", "(", "params_f", ",", "\"r\"", ")", "as", "f", ":", "\n", "                ", "params", "=", "json", ".", "load", "(", "f", ")", "\n", "if", "param_name", "in", "params", ":", "\n", "                    ", "if", "overwrite", ":", "\n", "                        ", "print", "(", "\"Overwriting param: {}, old val: {}, new val: {}\"", ".", "format", "(", "\n", "param_name", ",", "params", "[", "param_name", "]", ",", "param_val", ")", ")", "\n", "", "else", ":", "\n", "                        ", "print", "(", "\"Param {} already found & overwrite set to False; \"", "\n", "\"leaving old val: {}.\"", ".", "format", "(", "param_name", ",", "params", "[", "param_name", "]", ")", ")", "\n", "update_param", "=", "False", "\n", "", "", "", "if", "update_param", ":", "\n", "                ", "os", ".", "remove", "(", "params_f", ")", "\n", "if", "param_name", "in", "params", "and", "isinstance", "(", "params", "[", "param_name", "]", ",", "dict", ")", "and", "isinstance", "(", "param_val", ",", "dict", ")", ":", "\n", "                    ", "print", "(", "f\"Param {param_name} is a dict and so is val, just updating.\"", ")", "\n", "params", "[", "param_name", "]", ".", "update", "(", "param_val", ")", "\n", "", "else", ":", "\n", "                    ", "params", "[", "param_name", "]", "=", "param_val", "\n", "", "with", "open", "(", "params_f", ",", "\"w\"", ")", "as", "f", ":", "\n", "                    ", "json", ".", "dump", "(", "params", ",", "f", ",", "default", "=", "lambda", "o", ":", "type", "(", "o", ")", ".", "__name__", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.logging.context.check_progress": [[117, 129], ["os.walk", "os.walk", "os.getcwd", "os.getcwd", "os.join", "os.system", "os.system"], "function", ["None"], ["", "", "", "", "", "def", "check_progress", "(", "exp_dir", "=", "None", ")", ":", "\n", "    ", "\"\"\"Print to stdout the number of lines in all ``progress.csv`` files in\n    the directory.  Call like:\n     ``python -c 'from rlpyt.util.logging.context import check_progress;\n     check_progress('path_to_dir')``\n    \"\"\"", "\n", "if", "exp_dir", "is", "None", ":", "\n", "        ", "exp_dir", "=", "os", ".", "getcwd", "(", ")", "\n", "", "for", "sub_dir", "in", "os", ".", "walk", "(", "exp_dir", ")", ":", "\n", "        ", "if", "\"progress.csv\"", "in", "sub_dir", "[", "2", "]", ":", "\n", "            ", "progress_f", "=", "osp", ".", "join", "(", "sub_dir", "[", "0", "]", ",", "\"progress.csv\"", ")", "\n", "os", ".", "system", "(", "f\"wc -l {progress_f}\"", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.astooke_rlpyt.logging.autoargs.arg": [[9, 24], ["dict", "hasattr", "dict"], "function", ["None"], ["def", "arg", "(", "name", ",", "type", "=", "None", ",", "help", "=", "None", ",", "nargs", "=", "None", ",", "mapper", "=", "None", ",", "choices", "=", "None", ",", "\n", "prefix", "=", "True", ")", ":", "\n", "    ", "def", "wrap", "(", "fn", ")", ":", "\n", "        ", "assert", "fn", ".", "__name__", "==", "'__init__'", "\n", "if", "not", "hasattr", "(", "fn", ",", "'_autoargs_info'", ")", ":", "\n", "            ", "fn", ".", "_autoargs_info", "=", "dict", "(", ")", "\n", "", "fn", ".", "_autoargs_info", "[", "name", "]", "=", "dict", "(", "\n", "type", "=", "type", ",", "\n", "help", "=", "help", ",", "\n", "nargs", "=", "nargs", ",", "\n", "choices", "=", "choices", ",", "\n", "mapper", "=", "mapper", ",", "\n", ")", "\n", "return", "fn", "\n", "", "return", "wrap", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.logging.autoargs.prefix": [[26, 32], ["None"], "function", ["None"], ["", "def", "prefix", "(", "prefix_", ")", ":", "\n", "    ", "def", "wrap", "(", "fn", ")", ":", "\n", "        ", "assert", "fn", ".", "__name__", "==", "'__init__'", "\n", "fn", ".", "_autoargs_prefix", "=", "prefix_", "\n", "return", "fn", "\n", "", "return", "wrap", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.logging.autoargs._get_prefix": [[34, 52], ["hasattr", "issubclass", "issubclass", "issubclass", "issubclass"], "function", ["None"], ["", "def", "_get_prefix", "(", "cls", ")", ":", "\n", "    ", "from", "rllab", ".", "mdp", ".", "base", "import", "MDP", "\n", "from", "rllab", ".", "policies", ".", "base", "import", "Policy", "\n", "from", "rllab", ".", "baselines", ".", "base", "import", "Baseline", "\n", "from", "rllab", ".", "algos", ".", "base", "import", "Algorithm", "\n", "\n", "if", "hasattr", "(", "cls", ".", "__init__", ",", "'_autoargs_prefix'", ")", ":", "\n", "        ", "return", "cls", ".", "__init__", ".", "_autoargs_prefix", "\n", "", "elif", "issubclass", "(", "cls", ",", "MDP", ")", ":", "\n", "        ", "return", "'mdp_'", "\n", "", "elif", "issubclass", "(", "cls", ",", "Algorithm", ")", ":", "\n", "        ", "return", "'algo_'", "\n", "", "elif", "issubclass", "(", "cls", ",", "Baseline", ")", ":", "\n", "        ", "return", "'baseline_'", "\n", "", "elif", "issubclass", "(", "cls", ",", "Policy", ")", ":", "\n", "        ", "return", "'policy_'", "\n", "", "else", ":", "\n", "        ", "return", "\"\"", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.logging.autoargs._get_info": [[54, 63], ["isinstance", "hasattr", "hasattr"], "function", ["None"], ["", "", "def", "_get_info", "(", "cls_or_fn", ")", ":", "\n", "    ", "if", "isinstance", "(", "cls_or_fn", ",", "type", ")", ":", "\n", "        ", "if", "hasattr", "(", "cls_or_fn", ".", "__init__", ",", "'_autoargs_info'", ")", ":", "\n", "            ", "return", "cls_or_fn", ".", "__init__", ".", "_autoargs_info", "\n", "", "return", "{", "}", "\n", "", "else", ":", "\n", "        ", "if", "hasattr", "(", "cls_or_fn", ",", "'_autoargs_info'", ")", ":", "\n", "            ", "return", "cls_or_fn", ".", "_autoargs_info", "\n", "", "return", "{", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.logging.autoargs._t_or_f": [[65, 73], ["str().upper", "str", "ValueError", "len", "len"], "function", ["None"], ["", "", "def", "_t_or_f", "(", "s", ")", ":", "\n", "    ", "ua", "=", "str", "(", "s", ")", ".", "upper", "(", ")", "\n", "if", "ua", "==", "'TRUE'", "[", ":", "len", "(", "ua", ")", "]", ":", "\n", "        ", "return", "True", "\n", "", "elif", "ua", "==", "'FALSE'", "[", ":", "len", "(", "ua", ")", "]", ":", "\n", "        ", "return", "False", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "'Unrecognized boolean value: %s'", "%", "s", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.logging.autoargs.add_args": [[75, 91], ["autoargs._get_info", "autoargs._get_prefix", "_get_info.items", "parser.add_argument"], "function", ["home.repos.pwc.inspect_result.astooke_rlpyt.logging.autoargs._get_info", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.autoargs._get_prefix", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.collections.NamedArrayTuple.items"], ["", "", "def", "add_args", "(", "_", ")", ":", "\n", "    ", "def", "_add_args", "(", "cls", ",", "parser", ")", ":", "\n", "        ", "args_info", "=", "_get_info", "(", "cls", ")", "\n", "prefix_", "=", "_get_prefix", "(", "cls", ")", "\n", "for", "arg_name", ",", "arg_info", "in", "args_info", ".", "items", "(", ")", ":", "\n", "            ", "type", "=", "arg_info", "[", "'type'", "]", "\n", "# unfortunately boolean type doesn't work", "\n", "if", "type", "==", "bool", ":", "\n", "                ", "type", "=", "_t_or_f", "\n", "", "parser", ".", "add_argument", "(", "\n", "'--'", "+", "prefix_", "+", "arg_name", ",", "\n", "help", "=", "arg_info", "[", "'help'", "]", ",", "\n", "choices", "=", "arg_info", "[", "'choices'", "]", ",", "\n", "type", "=", "type", ",", "\n", "nargs", "=", "arg_info", "[", "'nargs'", "]", ")", "\n", "", "", "return", "_add_args", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.logging.autoargs.new_from_args": [[93, 114], ["params.pop", "autoargs._get_info", "autoargs._get_prefix", "_get_info.items", "cls", "hasattr", "getattr", "print", "rlpyt.utils.logging.console.colorize"], "function", ["home.repos.pwc.inspect_result.astooke_rlpyt.logging.autoargs._get_info", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.autoargs._get_prefix", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.collections.NamedArrayTuple.items", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.console.colorize"], ["", "def", "new_from_args", "(", "_", ")", ":", "\n", "    ", "def", "_new_from_args", "(", "cls", ",", "parsed_args", ",", "*", "args", ",", "**", "params", ")", ":", "\n", "        ", "silent", "=", "params", ".", "pop", "(", "\"_silent\"", ",", "False", ")", "\n", "args_info", "=", "_get_info", "(", "cls", ")", "\n", "prefix_", "=", "_get_prefix", "(", "cls", ")", "\n", "#     params = dict()", "\n", "for", "arg_name", ",", "arg_info", "in", "args_info", ".", "items", "(", ")", ":", "\n", "            ", "prefixed_arg_name", "=", "prefix_", "+", "arg_name", "\n", "if", "hasattr", "(", "parsed_args", ",", "prefixed_arg_name", ")", ":", "\n", "                ", "val", "=", "getattr", "(", "parsed_args", ",", "prefixed_arg_name", ")", "\n", "if", "val", "is", "not", "None", ":", "\n", "                    ", "if", "arg_info", "[", "'mapper'", "]", ":", "\n", "                        ", "params", "[", "arg_name", "]", "=", "arg_info", "[", "'mapper'", "]", "(", "val", ")", "\n", "", "else", ":", "\n", "                        ", "params", "[", "arg_name", "]", "=", "val", "\n", "", "if", "not", "silent", ":", "\n", "                        ", "print", "(", "colorize", "(", "\n", "\"using argument %s with value %s\"", "%", "(", "arg_name", ",", "val", ")", ",", "\n", "\"yellow\"", ")", ")", "\n", "", "", "", "", "return", "cls", "(", "*", "args", ",", "**", "params", ")", "\n", "", "return", "_new_from_args", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.logging.autoargs.inherit": [[116, 127], ["dict", "autoargs._get_info", "autoargs._get_info"], "function", ["home.repos.pwc.inspect_result.astooke_rlpyt.logging.autoargs._get_info", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.autoargs._get_info"], ["", "def", "inherit", "(", "base_func", ")", ":", "\n", "    ", "assert", "base_func", ".", "__name__", "==", "'__init__'", "\n", "\n", "def", "wrap", "(", "func", ")", ":", "\n", "        ", "assert", "func", ".", "__name__", "==", "'__init__'", "\n", "func", ".", "_autoargs_info", "=", "dict", "(", "\n", "_get_info", "(", "base_func", ")", ",", "\n", "**", "_get_info", "(", "func", ")", "\n", ")", "\n", "return", "func", "\n", "", "return", "wrap", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.logging.autoargs.get_all_parameters": [[129, 153], ["autoargs._get_prefix", "autoargs._get_info", "inspect.ismethod", "_get_info.items", "ValueError", "inspect.getargspec", "hasattr", "len", "dict", "getattr", "list", "zip"], "function", ["home.repos.pwc.inspect_result.astooke_rlpyt.logging.autoargs._get_prefix", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.autoargs._get_info", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.collections.NamedArrayTuple.items"], ["", "def", "get_all_parameters", "(", "cls", ",", "parsed_args", ")", ":", "\n", "    ", "prefix", "=", "_get_prefix", "(", "cls", ")", "\n", "if", "prefix", "is", "None", "or", "len", "(", "prefix", ")", "==", "0", ":", "\n", "        ", "raise", "ValueError", "(", "'Cannot retrieve parameters without prefix'", ")", "\n", "", "info", "=", "_get_info", "(", "cls", ")", "\n", "if", "inspect", ".", "ismethod", "(", "cls", ".", "__init__", ")", ":", "\n", "        ", "spec", "=", "inspect", ".", "getargspec", "(", "cls", ".", "__init__", ")", "\n", "if", "spec", ".", "defaults", "is", "None", ":", "\n", "            ", "arg_defaults", "=", "{", "}", "\n", "", "else", ":", "\n", "            ", "arg_defaults", "=", "dict", "(", "list", "(", "zip", "(", "spec", ".", "args", "[", ":", ":", "-", "1", "]", ",", "spec", ".", "defaults", "[", ":", ":", "-", "1", "]", ")", ")", ")", "\n", "", "", "else", ":", "\n", "        ", "arg_defaults", "=", "{", "}", "\n", "", "all_params", "=", "{", "}", "\n", "for", "arg_name", ",", "arg_info", "in", "info", ".", "items", "(", ")", ":", "\n", "        ", "prefixed_name", "=", "prefix", "+", "arg_name", "\n", "arg_value", "=", "None", "\n", "if", "hasattr", "(", "parsed_args", ",", "prefixed_name", ")", ":", "\n", "            ", "arg_value", "=", "getattr", "(", "parsed_args", ",", "prefixed_name", ")", "\n", "", "if", "arg_value", "is", "None", "and", "arg_name", "in", "arg_defaults", ":", "\n", "            ", "arg_value", "=", "arg_defaults", "[", "arg_name", "]", "\n", "", "if", "arg_value", "is", "not", "None", ":", "\n", "            ", "all_params", "[", "arg_name", "]", "=", "arg_value", "\n", "", "", "return", "all_params", "\n", "", ""]], "home.repos.pwc.inspect_result.astooke_rlpyt.logging.tabulate._pipe_segment_with_colons": [[78, 90], ["None"], "function", ["None"], ["def", "_pipe_segment_with_colons", "(", "align", ",", "colwidth", ")", ":", "\n", "    ", "\"\"\"Return a segment of a horizontal line with optional colons which\n    indicate column's alignment (as in `pipe` output format).\"\"\"", "\n", "w", "=", "colwidth", "\n", "if", "align", "in", "[", "\"right\"", ",", "\"decimal\"", "]", ":", "\n", "        ", "return", "(", "'-'", "*", "(", "w", "-", "1", ")", ")", "+", "\":\"", "\n", "", "elif", "align", "==", "\"center\"", ":", "\n", "        ", "return", "\":\"", "+", "(", "'-'", "*", "(", "w", "-", "2", ")", ")", "+", "\":\"", "\n", "", "elif", "align", "==", "\"left\"", ":", "\n", "        ", "return", "\":\"", "+", "(", "'-'", "*", "(", "w", "-", "1", ")", ")", "\n", "", "else", ":", "\n", "        ", "return", "'-'", "*", "w", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.logging.tabulate._pipe_line_with_colons": [[92, 97], ["tabulate._pipe_segment_with_colons", "zip"], "function", ["home.repos.pwc.inspect_result.astooke_rlpyt.logging.tabulate._pipe_segment_with_colons"], ["", "", "def", "_pipe_line_with_colons", "(", "colwidths", ",", "colaligns", ")", ":", "\n", "    ", "\"\"\"Return a horizontal line with optional colons to indicate column's\n    alignment (as in `pipe` output format).\"\"\"", "\n", "segments", "=", "[", "_pipe_segment_with_colons", "(", "a", ",", "w", ")", "for", "a", ",", "w", "in", "zip", "(", "colaligns", ",", "colwidths", ")", "]", "\n", "return", "\"|\"", "+", "\"|\"", ".", "join", "(", "segments", ")", "+", "\"|\"", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.logging.tabulate._mediawiki_row_with_attrs": [[99, 110], ["zip", "colsep.join", "alignment.get"], "function", ["home.repos.pwc.inspect_result.astooke_rlpyt.utils.collections.NamedArrayTuple.get"], ["", "def", "_mediawiki_row_with_attrs", "(", "separator", ",", "cell_values", ",", "colwidths", ",", "colaligns", ")", ":", "\n", "    ", "alignment", "=", "{", "\"left\"", ":", "''", ",", "\n", "\"right\"", ":", "'align=\"right\"| '", ",", "\n", "\"center\"", ":", "'align=\"center\"| '", ",", "\n", "\"decimal\"", ":", "'align=\"right\"| '", "}", "\n", "# hard-coded padding _around_ align attribute and value together", "\n", "# rather than padding parameter which affects only the value", "\n", "values_with_attrs", "=", "[", "' '", "+", "alignment", ".", "get", "(", "a", ",", "''", ")", "+", "c", "+", "' '", "\n", "for", "c", ",", "a", "in", "zip", "(", "cell_values", ",", "colaligns", ")", "]", "\n", "colsep", "=", "separator", "*", "2", "\n", "return", "(", "separator", "+", "colsep", ".", "join", "(", "values_with_attrs", ")", ")", ".", "rstrip", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.logging.tabulate._latex_line_begin_tabular": [[112, 116], ["alignment.get"], "function", ["home.repos.pwc.inspect_result.astooke_rlpyt.utils.collections.NamedArrayTuple.get"], ["", "def", "_latex_line_begin_tabular", "(", "colwidths", ",", "colaligns", ")", ":", "\n", "    ", "alignment", "=", "{", "\"left\"", ":", "\"l\"", ",", "\"right\"", ":", "\"r\"", ",", "\"center\"", ":", "\"c\"", ",", "\"decimal\"", ":", "\"r\"", "}", "\n", "tabular_columns_fmt", "=", "\"\"", ".", "join", "(", "[", "alignment", ".", "get", "(", "a", ",", "\"l\"", ")", "for", "a", "in", "colaligns", "]", ")", "\n", "return", "\"\\\\begin{tabular}{\"", "+", "tabular_columns_fmt", "+", "\"}\\n\\hline\"", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.logging.tabulate.simple_separated_format": [[198, 210], ["TableFormat", "DataRow", "DataRow"], "function", ["None"], ["def", "simple_separated_format", "(", "separator", ")", ":", "\n", "    ", "\"\"\"Construct a simple TableFormat with columns separated by a separator.\n\n    >>> tsv = simple_separated_format(\"\\\\t\") ; \\\n        tabulate([[\"foo\", 1], [\"spam\", 23]], tablefmt=tsv) == 'foo \\\\t 1\\\\nspam\\\\t23'\n    True\n\n    \"\"\"", "\n", "return", "TableFormat", "(", "None", ",", "None", ",", "None", ",", "None", ",", "\n", "headerrow", "=", "DataRow", "(", "''", ",", "separator", ",", "''", ")", ",", "\n", "datarow", "=", "DataRow", "(", "''", ",", "separator", ",", "''", ")", ",", "\n", "padding", "=", "0", ",", "with_header_hide", "=", "None", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.logging.tabulate._isconvertible": [[212, 218], ["conv"], "function", ["None"], ["", "def", "_isconvertible", "(", "conv", ",", "string", ")", ":", "\n", "    ", "try", ":", "\n", "        ", "n", "=", "conv", "(", "string", ")", "\n", "return", "True", "\n", "", "except", "ValueError", ":", "\n", "        ", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.logging.tabulate._isnumber": [[220, 230], ["tabulate._isconvertible"], "function", ["home.repos.pwc.inspect_result.astooke_rlpyt.logging.tabulate._isconvertible"], ["", "", "def", "_isnumber", "(", "string", ")", ":", "\n", "    ", "\"\"\"\n    >>> _isnumber(\"123.45\")\n    True\n    >>> _isnumber(\"123\")\n    True\n    >>> _isnumber(\"spam\")\n    False\n    \"\"\"", "\n", "return", "_isconvertible", "(", "float", ",", "string", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.logging.tabulate._isint": [[232, 242], ["type", "tabulate._isconvertible", "isinstance", "isinstance"], "function", ["home.repos.pwc.inspect_result.astooke_rlpyt.logging.tabulate._isconvertible"], ["", "def", "_isint", "(", "string", ")", ":", "\n", "    ", "\"\"\"\n    >>> _isint(\"123\")\n    True\n    >>> _isint(\"123.45\")\n    False\n    \"\"\"", "\n", "return", "type", "(", "string", ")", "is", "int", "or", "(", "isinstance", "(", "string", ",", "_binary_type", ")", "or", "isinstance", "(", "string", ",", "_text_type", ")", ")", "and", "_isconvertible", "(", "int", ",", "string", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.logging.tabulate._type": [[244, 276], ["tabulate._strip_invisible", "hasattr", "isinstance", "isinstance", "tabulate._isint", "tabulate._isnumber", "isinstance"], "function", ["home.repos.pwc.inspect_result.astooke_rlpyt.logging.tabulate._strip_invisible", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.tabulate._isint", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.tabulate._isnumber"], ["", "def", "_type", "(", "string", ",", "has_invisible", "=", "True", ")", ":", "\n", "    ", "\"\"\"The least generic type (type(None), int, float, str, unicode).\n\n    >>> _type(None) is type(None)\n    True\n    >>> _type(\"foo\") is type(\"\")\n    True\n    >>> _type(\"1\") is type(1)\n    True\n    >>> _type('\\x1b[31m42\\x1b[0m') is type(42)\n    True\n    >>> _type('\\x1b[31m42\\x1b[0m') is type(42)\n    True\n\n    \"\"\"", "\n", "\n", "if", "has_invisible", "and", "(", "isinstance", "(", "string", ",", "_text_type", ")", "or", "isinstance", "(", "string", ",", "_binary_type", ")", ")", ":", "\n", "        ", "string", "=", "_strip_invisible", "(", "string", ")", "\n", "\n", "", "if", "string", "is", "None", ":", "\n", "        ", "return", "_none_type", "\n", "", "elif", "hasattr", "(", "string", ",", "\"isoformat\"", ")", ":", "# datetime.datetime, date, and time", "\n", "        ", "return", "_text_type", "\n", "", "elif", "_isint", "(", "string", ")", ":", "\n", "        ", "return", "int", "\n", "", "elif", "_isnumber", "(", "string", ")", ":", "\n", "        ", "return", "float", "\n", "", "elif", "isinstance", "(", "string", ",", "_binary_type", ")", ":", "\n", "        ", "return", "_binary_type", "\n", "", "else", ":", "\n", "        ", "return", "_text_type", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.logging.tabulate._afterpoint": [[278, 303], ["tabulate._isnumber", "tabulate._isint", "string.rfind", "string.lower().rfind", "string.lower", "len"], "function", ["home.repos.pwc.inspect_result.astooke_rlpyt.logging.tabulate._isnumber", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.tabulate._isint"], ["", "", "def", "_afterpoint", "(", "string", ")", ":", "\n", "    ", "\"\"\"Symbols after a decimal point, -1 if the string lacks the decimal point.\n\n    >>> _afterpoint(\"123.45\")\n    2\n    >>> _afterpoint(\"1001\")\n    -1\n    >>> _afterpoint(\"eggs\")\n    -1\n    >>> _afterpoint(\"123e45\")\n    2\n\n    \"\"\"", "\n", "if", "_isnumber", "(", "string", ")", ":", "\n", "        ", "if", "_isint", "(", "string", ")", ":", "\n", "            ", "return", "-", "1", "\n", "", "else", ":", "\n", "            ", "pos", "=", "string", ".", "rfind", "(", "\".\"", ")", "\n", "pos", "=", "string", ".", "lower", "(", ")", ".", "rfind", "(", "\"e\"", ")", "if", "pos", "<", "0", "else", "pos", "\n", "if", "pos", ">=", "0", ":", "\n", "                ", "return", "len", "(", "string", ")", "-", "pos", "-", "1", "\n", "", "else", ":", "\n", "                ", "return", "-", "1", "# no point", "\n", "", "", "", "else", ":", "\n", "        ", "return", "-", "1", "# not a number", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.logging.tabulate._padleft": [[305, 315], ["fmt.format", "len", "len", "tabulate._strip_invisible"], "function", ["home.repos.pwc.inspect_result.astooke_rlpyt.logging.tabulate._strip_invisible"], ["", "", "def", "_padleft", "(", "width", ",", "s", ",", "has_invisible", "=", "True", ")", ":", "\n", "    ", "\"\"\"Flush right.\n\n    >>> _padleft(6, '\\u044f\\u0439\\u0446\\u0430') == '  \\u044f\\u0439\\u0446\\u0430'\n    True\n\n    \"\"\"", "\n", "iwidth", "=", "width", "+", "len", "(", "s", ")", "-", "len", "(", "_strip_invisible", "(", "s", ")", ")", "if", "has_invisible", "else", "width", "\n", "fmt", "=", "\"{0:>%ds}\"", "%", "iwidth", "\n", "return", "fmt", ".", "format", "(", "s", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.logging.tabulate._padright": [[317, 327], ["fmt.format", "len", "len", "tabulate._strip_invisible"], "function", ["home.repos.pwc.inspect_result.astooke_rlpyt.logging.tabulate._strip_invisible"], ["", "def", "_padright", "(", "width", ",", "s", ",", "has_invisible", "=", "True", ")", ":", "\n", "    ", "\"\"\"Flush left.\n\n    >>> _padright(6, '\\u044f\\u0439\\u0446\\u0430') == '\\u044f\\u0439\\u0446\\u0430  '\n    True\n\n    \"\"\"", "\n", "iwidth", "=", "width", "+", "len", "(", "s", ")", "-", "len", "(", "_strip_invisible", "(", "s", ")", ")", "if", "has_invisible", "else", "width", "\n", "fmt", "=", "\"{0:<%ds}\"", "%", "iwidth", "\n", "return", "fmt", ".", "format", "(", "s", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.logging.tabulate._padboth": [[329, 339], ["fmt.format", "len", "len", "tabulate._strip_invisible"], "function", ["home.repos.pwc.inspect_result.astooke_rlpyt.logging.tabulate._strip_invisible"], ["", "def", "_padboth", "(", "width", ",", "s", ",", "has_invisible", "=", "True", ")", ":", "\n", "    ", "\"\"\"Center string.\n\n    >>> _padboth(6, '\\u044f\\u0439\\u0446\\u0430') == ' \\u044f\\u0439\\u0446\\u0430 '\n    True\n\n    \"\"\"", "\n", "iwidth", "=", "width", "+", "len", "(", "s", ")", "-", "len", "(", "_strip_invisible", "(", "s", ")", ")", "if", "has_invisible", "else", "width", "\n", "fmt", "=", "\"{0:^%ds}\"", "%", "iwidth", "\n", "return", "fmt", ".", "format", "(", "s", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.logging.tabulate._strip_invisible": [[341, 347], ["isinstance", "re.sub", "re.sub"], "function", ["None"], ["", "def", "_strip_invisible", "(", "s", ")", ":", "\n", "    ", "\"Remove invisible ANSI color codes.\"", "\n", "if", "isinstance", "(", "s", ",", "_text_type", ")", ":", "\n", "        ", "return", "re", ".", "sub", "(", "_invisible_codes", ",", "\"\"", ",", "s", ")", "\n", "", "else", ":", "# a bytestring", "\n", "        ", "return", "re", ".", "sub", "(", "_invisible_codes_bytes", ",", "\"\"", ",", "s", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.logging.tabulate._visible_width": [[349, 360], ["isinstance", "isinstance", "len", "len", "tabulate._strip_invisible", "_text_type"], "function", ["home.repos.pwc.inspect_result.astooke_rlpyt.logging.tabulate._strip_invisible"], ["", "", "def", "_visible_width", "(", "s", ")", ":", "\n", "    ", "\"\"\"Visible width of a printed string. ANSI color codes are removed.\n\n    >>> _visible_width('\\x1b[31mhello\\x1b[0m'), _visible_width(\"world\")\n    (5, 5)\n\n    \"\"\"", "\n", "if", "isinstance", "(", "s", ",", "_text_type", ")", "or", "isinstance", "(", "s", ",", "_binary_type", ")", ":", "\n", "        ", "return", "len", "(", "_strip_invisible", "(", "s", ")", ")", "\n", "", "else", ":", "\n", "        ", "return", "len", "(", "_text_type", "(", "s", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.logging.tabulate._align_column": [[362, 398], ["max", "max", "padfn", "s.strip", "list", "s.strip", "max", "map", "tabulate._afterpoint", "zip", "s.strip"], "function", ["home.repos.pwc.inspect_result.astooke_rlpyt.logging.tabulate._afterpoint"], ["", "", "def", "_align_column", "(", "strings", ",", "alignment", ",", "minwidth", "=", "0", ",", "has_invisible", "=", "True", ")", ":", "\n", "    ", "\"\"\"[string] -> [padded_string]\n\n    >>> list(map(str,_align_column([\"12.345\", \"-1234.5\", \"1.23\", \"1234.5\", \"1e+234\", \"1.0e234\"], \"decimal\")))\n    ['   12.345  ', '-1234.5    ', '    1.23   ', ' 1234.5    ', '    1e+234 ', '    1.0e234']\n\n    >>> list(map(str,_align_column(['123.4', '56.7890'], None)))\n    ['123.4', '56.7890']\n\n    \"\"\"", "\n", "if", "alignment", "==", "\"right\"", ":", "\n", "        ", "strings", "=", "[", "s", ".", "strip", "(", ")", "for", "s", "in", "strings", "]", "\n", "padfn", "=", "_padleft", "\n", "", "elif", "alignment", "==", "\"center\"", ":", "\n", "        ", "strings", "=", "[", "s", ".", "strip", "(", ")", "for", "s", "in", "strings", "]", "\n", "padfn", "=", "_padboth", "\n", "", "elif", "alignment", "==", "\"decimal\"", ":", "\n", "        ", "decimals", "=", "[", "_afterpoint", "(", "s", ")", "for", "s", "in", "strings", "]", "\n", "maxdecimals", "=", "max", "(", "decimals", ")", "\n", "strings", "=", "[", "s", "+", "(", "maxdecimals", "-", "decs", ")", "*", "\" \"", "\n", "for", "s", ",", "decs", "in", "zip", "(", "strings", ",", "decimals", ")", "]", "\n", "padfn", "=", "_padleft", "\n", "", "elif", "not", "alignment", ":", "\n", "        ", "return", "strings", "\n", "", "else", ":", "\n", "        ", "strings", "=", "[", "s", ".", "strip", "(", ")", "for", "s", "in", "strings", "]", "\n", "padfn", "=", "_padright", "\n", "\n", "", "if", "has_invisible", ":", "\n", "        ", "width_fn", "=", "_visible_width", "\n", "", "else", ":", "\n", "        ", "width_fn", "=", "len", "\n", "\n", "", "maxwidth", "=", "max", "(", "max", "(", "list", "(", "map", "(", "width_fn", ",", "strings", ")", ")", ")", ",", "minwidth", ")", "\n", "padded_strings", "=", "[", "padfn", "(", "maxwidth", ",", "s", ",", "has_invisible", ")", "for", "s", "in", "strings", "]", "\n", "return", "padded_strings", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.logging.tabulate._more_generic": [[400, 405], ["max", "types.get", "types.get"], "function", ["home.repos.pwc.inspect_result.astooke_rlpyt.utils.collections.NamedArrayTuple.get", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.collections.NamedArrayTuple.get"], ["", "def", "_more_generic", "(", "type1", ",", "type2", ")", ":", "\n", "    ", "types", "=", "{", "_none_type", ":", "0", ",", "int", ":", "1", ",", "float", ":", "2", ",", "_binary_type", ":", "3", ",", "_text_type", ":", "4", "}", "\n", "invtypes", "=", "{", "4", ":", "_text_type", ",", "3", ":", "_binary_type", ",", "2", ":", "float", ",", "1", ":", "int", ",", "0", ":", "_none_type", "}", "\n", "moregeneric", "=", "max", "(", "types", ".", "get", "(", "type1", ",", "4", ")", ",", "types", ".", "get", "(", "type2", ",", "4", ")", ")", "\n", "return", "invtypes", "[", "moregeneric", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.logging.tabulate._column_type": [[407, 429], ["reduce", "tabulate._type"], "function", ["home.repos.pwc.inspect_result.astooke_rlpyt.logging.tabulate._type"], ["", "def", "_column_type", "(", "strings", ",", "has_invisible", "=", "True", ")", ":", "\n", "    ", "\"\"\"The least generic type all column values are convertible to.\n\n    >>> _column_type([\"1\", \"2\"]) is _int_type\n    True\n    >>> _column_type([\"1\", \"2.3\"]) is _float_type\n    True\n    >>> _column_type([\"1\", \"2.3\", \"four\"]) is _text_type\n    True\n    >>> _column_type([\"four\", '\\u043f\\u044f\\u0442\\u044c']) is _text_type\n    True\n    >>> _column_type([None, \"brux\"]) is _text_type\n    True\n    >>> _column_type([1, 2, None]) is _int_type\n    True\n    >>> import datetime as dt\n    >>> _column_type([dt.datetime(1991,2,19), dt.time(17,35)]) is _text_type\n    True\n\n    \"\"\"", "\n", "types", "=", "[", "_type", "(", "s", ",", "has_invisible", ")", "for", "s", "in", "strings", "]", "\n", "return", "reduce", "(", "_more_generic", ",", "types", ",", "int", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.logging.tabulate._format": [[431, 454], ["_text_type", "format", "float"], "function", ["None"], ["", "def", "_format", "(", "val", ",", "valtype", ",", "floatfmt", ",", "missingval", "=", "\"\"", ")", ":", "\n", "    ", "\"\"\"Format a value accoding to its type.\n\n    Unicode is supported:\n\n    >>> hrow = ['\\u0431\\u0443\\u043a\\u0432\\u0430', '\\u0446\\u0438\\u0444\\u0440\\u0430'] ; \\\n        tbl = [['\\u0430\\u0437', 2], ['\\u0431\\u0443\\u043a\\u0438', 4]] ; \\\n        good_result = '\\\\u0431\\\\u0443\\\\u043a\\\\u0432\\\\u0430      \\\\u0446\\\\u0438\\\\u0444\\\\u0440\\\\u0430\\\\n-------  -------\\\\n\\\\u0430\\\\u0437             2\\\\n\\\\u0431\\\\u0443\\\\u043a\\\\u0438           4' ; \\\n        tabulate(tbl, headers=hrow) == good_result\n    True\n\n    \"\"\"", "\n", "if", "val", "is", "None", ":", "\n", "        ", "return", "missingval", "\n", "\n", "", "if", "valtype", "in", "[", "int", ",", "_text_type", "]", ":", "\n", "        ", "return", "\"{0}\"", ".", "format", "(", "val", ")", "\n", "", "elif", "valtype", "is", "_binary_type", ":", "\n", "        ", "return", "_text_type", "(", "val", ",", "\"ascii\"", ")", "\n", "", "elif", "valtype", "is", "float", ":", "\n", "        ", "return", "format", "(", "float", "(", "val", ")", ",", "floatfmt", ")", "\n", "", "else", ":", "\n", "        ", "return", "\"{0}\"", ".", "format", "(", "val", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.logging.tabulate._align_header": [[456, 465], ["tabulate._padright", "tabulate._padboth", "tabulate._padleft"], "function", ["home.repos.pwc.inspect_result.astooke_rlpyt.logging.tabulate._padright", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.tabulate._padboth", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.tabulate._padleft"], ["", "", "def", "_align_header", "(", "header", ",", "alignment", ",", "width", ")", ":", "\n", "    ", "if", "alignment", "==", "\"left\"", ":", "\n", "        ", "return", "_padright", "(", "width", ",", "header", ")", "\n", "", "elif", "alignment", "==", "\"center\"", ":", "\n", "        ", "return", "_padboth", "(", "width", ",", "header", ")", "\n", "", "elif", "not", "alignment", ":", "\n", "        ", "return", "\"{0}\"", ".", "format", "(", "header", ")", "\n", "", "else", ":", "\n", "        ", "return", "_padleft", "(", "width", ",", "header", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.logging.tabulate._normalize_tabular_data": [[467, 539], ["list", "list", "hasattr", "hasattr", "hasattr", "list", "list", "map", "len", "len", "list", "list", "hasattr", "list", "hasattr", "getattr", "len", "map", "len", "tabular_data.keys", "izip_longest", "list", "ValueError", "map", "isinstance", "hasattr", "list", "tabular_data.keys", "len", "map", "list", "list", "list", "zip", "len", "map", "tabular_data.values", "list", "range", "len"], "function", ["None"], ["", "", "def", "_normalize_tabular_data", "(", "tabular_data", ",", "headers", ")", ":", "\n", "    ", "\"\"\"Transform a supported data type to a list of lists, and a list of headers.\n\n    Supported tabular data types:\n\n    * list-of-lists or another iterable of iterables\n\n    * list of named tuples (usually used with headers=\"keys\")\n\n    * 2D NumPy arrays\n\n    * NumPy record arrays (usually used with headers=\"keys\")\n\n    * dict of iterables (usually used with headers=\"keys\")\n\n    * pandas.DataFrame (usually used with headers=\"keys\")\n\n    The first row can be used as headers if headers=\"firstrow\",\n    column indices can be used as headers if headers=\"keys\".\n\n    \"\"\"", "\n", "\n", "if", "hasattr", "(", "tabular_data", ",", "\"keys\"", ")", "and", "hasattr", "(", "tabular_data", ",", "\"values\"", ")", ":", "\n", "# dict-like and pandas.DataFrame?", "\n", "        ", "if", "hasattr", "(", "tabular_data", ".", "values", ",", "\"__call__\"", ")", ":", "\n", "# likely a conventional dict", "\n", "            ", "keys", "=", "list", "(", "tabular_data", ".", "keys", "(", ")", ")", "\n", "rows", "=", "list", "(", "izip_longest", "(", "*", "list", "(", "tabular_data", ".", "values", "(", ")", ")", ")", ")", "# columns have to be transposed", "\n", "", "elif", "hasattr", "(", "tabular_data", ",", "\"index\"", ")", ":", "\n", "# values is a property, has .index => it's likely a pandas.DataFrame (pandas 0.11.0)", "\n", "            ", "keys", "=", "list", "(", "tabular_data", ".", "keys", "(", ")", ")", "\n", "vals", "=", "tabular_data", ".", "values", "# values matrix doesn't need to be transposed", "\n", "names", "=", "tabular_data", ".", "index", "\n", "rows", "=", "[", "[", "v", "]", "+", "list", "(", "row", ")", "for", "v", ",", "row", "in", "zip", "(", "names", ",", "vals", ")", "]", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\"tabular data doesn't appear to be a dict or a DataFrame\"", ")", "\n", "\n", "", "if", "headers", "==", "\"keys\"", ":", "\n", "            ", "headers", "=", "list", "(", "map", "(", "_text_type", ",", "keys", ")", ")", "# headers should be strings", "\n", "\n", "", "", "else", ":", "# it's a usual an iterable of iterables, or a NumPy array", "\n", "        ", "rows", "=", "list", "(", "tabular_data", ")", "\n", "\n", "if", "(", "headers", "==", "\"keys\"", "and", "\n", "hasattr", "(", "tabular_data", ",", "\"dtype\"", ")", "and", "\n", "getattr", "(", "tabular_data", ".", "dtype", ",", "\"names\"", ")", ")", ":", "\n", "# numpy record array", "\n", "            ", "headers", "=", "tabular_data", ".", "dtype", ".", "names", "\n", "", "elif", "(", "headers", "==", "\"keys\"", "\n", "and", "len", "(", "rows", ")", ">", "0", "\n", "and", "isinstance", "(", "rows", "[", "0", "]", ",", "tuple", ")", "\n", "and", "hasattr", "(", "rows", "[", "0", "]", ",", "\"_fields\"", ")", ")", ":", "# namedtuple", "\n", "            ", "headers", "=", "list", "(", "map", "(", "_text_type", ",", "rows", "[", "0", "]", ".", "_fields", ")", ")", "\n", "", "elif", "headers", "==", "\"keys\"", "and", "len", "(", "rows", ")", ">", "0", ":", "# keys are column indices", "\n", "            ", "headers", "=", "list", "(", "map", "(", "_text_type", ",", "list", "(", "range", "(", "len", "(", "rows", "[", "0", "]", ")", ")", ")", ")", ")", "\n", "\n", "# take headers from the first row if necessary", "\n", "", "", "if", "headers", "==", "\"firstrow\"", "and", "len", "(", "rows", ")", ">", "0", ":", "\n", "        ", "headers", "=", "list", "(", "map", "(", "_text_type", ",", "rows", "[", "0", "]", ")", ")", "# headers should be strings", "\n", "rows", "=", "rows", "[", "1", ":", "]", "\n", "\n", "", "headers", "=", "list", "(", "headers", ")", "\n", "rows", "=", "list", "(", "map", "(", "list", ",", "rows", ")", ")", "\n", "\n", "# pad with empty headers for initial columns if necessary", "\n", "if", "headers", "and", "len", "(", "rows", ")", ">", "0", ":", "\n", "       ", "nhs", "=", "len", "(", "headers", ")", "\n", "ncols", "=", "len", "(", "rows", "[", "0", "]", ")", "\n", "if", "nhs", "<", "ncols", ":", "\n", "           ", "headers", "=", "[", "\"\"", "]", "*", "(", "ncols", "-", "nhs", ")", "+", "headers", "\n", "\n", "", "", "return", "rows", ",", "headers", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.logging.tabulate.tabulate": [[541, 778], ["tabulate._normalize_tabular_data", "re.search", "list", "list", "tabulate._format_table", "zip", "map", "tabulate._align_column", "list", "list", "isinstance", "_table_formats.get", "tabulate._format", "zip", "len", "zip", "max", "tabulate._align_header", "zip", "width_fn", "zip", "width_fn", "width_fn", "zip", "zip", "map", "map"], "function", ["home.repos.pwc.inspect_result.astooke_rlpyt.logging.tabulate._normalize_tabular_data", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.tabulate._format_table", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.tabulate._align_column", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.collections.NamedArrayTuple.get", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.tabulate._format", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.tabulate._align_header"], ["", "def", "tabulate", "(", "tabular_data", ",", "headers", "=", "[", "]", ",", "tablefmt", "=", "\"simple\"", ",", "\n", "floatfmt", "=", "\"g\"", ",", "numalign", "=", "\"decimal\"", ",", "stralign", "=", "\"left\"", ",", "\n", "missingval", "=", "\"\"", ")", ":", "\n", "    ", "\"\"\"Format a fixed width table for pretty printing.\n\n    >>> print(tabulate([[1, 2.34], [-56, \"8.999\"], [\"2\", \"10001\"]]))\n    ---  ---------\n      1      2.34\n    -56      8.999\n      2  10001\n    ---  ---------\n\n    The first required argument (`tabular_data`) can be a\n    list-of-lists (or another iterable of iterables), a list of named\n    tuples, a dictionary of iterables, a two-dimensional NumPy array,\n    NumPy record array, or a Pandas' dataframe.\n\n\n    Table headers\n    -------------\n\n    To print nice column headers, supply the second argument (`headers`):\n\n      - `headers` can be an explicit list of column headers\n      - if `headers=\"firstrow\"`, then the first row of data is used\n      - if `headers=\"keys\"`, then dictionary keys or column indices are used\n\n    Otherwise a headerless table is produced.\n\n    If the number of headers is less than the number of columns, they\n    are supposed to be names of the last columns. This is consistent\n    with the plain-text format of R and Pandas' dataframes.\n\n    >>> print(tabulate([[\"sex\",\"age\"],[\"Alice\",\"F\",24],[\"Bob\",\"M\",19]],\n    ...       headers=\"firstrow\"))\n           sex      age\n    -----  -----  -----\n    Alice  F         24\n    Bob    M         19\n\n\n    Column alignment\n    ----------------\n\n    `tabulate` tries to detect column types automatically, and aligns\n    the values properly. By default it aligns decimal points of the\n    numbers (or flushes integer numbers to the right), and flushes\n    everything else to the left. Possible column alignments\n    (`numalign`, `stralign`) are: \"right\", \"center\", \"left\", \"decimal\"\n    (only for `numalign`), and None (to disable alignment).\n\n\n    Table formats\n    -------------\n\n    `floatfmt` is a format specification used for columns which\n    contain numeric data with a decimal point.\n\n    `None` values are replaced with a `missingval` string:\n\n    >>> print(tabulate([[\"spam\", 1, None],\n    ...                 [\"eggs\", 42, 3.14],\n    ...                 [\"other\", None, 2.7]], missingval=\"?\"))\n    -----  --  ----\n    spam    1  ?\n    eggs   42  3.14\n    other   ?  2.7\n    -----  --  ----\n\n    Various plain-text table formats (`tablefmt`) are supported:\n    'plain', 'simple', 'grid', 'pipe', 'orgtbl', 'rst', 'mediawiki',\n    and 'latex'. Variable `tabulate_formats` contains the list of\n    currently supported formats.\n\n    \"plain\" format doesn't use any pseudographics to draw tables,\n    it separates columns with a double space:\n\n    >>> print(tabulate([[\"spam\", 41.9999], [\"eggs\", \"451.0\"]],\n    ...                 [\"strings\", \"numbers\"], \"plain\"))\n    strings      numbers\n    spam         41.9999\n    eggs        451\n\n    >>> print(tabulate([[\"spam\", 41.9999], [\"eggs\", \"451.0\"]], tablefmt=\"plain\"))\n    spam   41.9999\n    eggs  451\n\n    \"simple\" format is like Pandoc simple_tables:\n\n    >>> print(tabulate([[\"spam\", 41.9999], [\"eggs\", \"451.0\"]],\n    ...                 [\"strings\", \"numbers\"], \"simple\"))\n    strings      numbers\n    ---------  ---------\n    spam         41.9999\n    eggs        451\n\n    >>> print(tabulate([[\"spam\", 41.9999], [\"eggs\", \"451.0\"]], tablefmt=\"simple\"))\n    ----  --------\n    spam   41.9999\n    eggs  451\n    ----  --------\n\n    \"grid\" is similar to tables produced by Emacs table.el package or\n    Pandoc grid_tables:\n\n    >>> print(tabulate([[\"spam\", 41.9999], [\"eggs\", \"451.0\"]],\n    ...                [\"strings\", \"numbers\"], \"grid\"))\n    +-----------+-----------+\n    | strings   |   numbers |\n    +===========+===========+\n    | spam      |   41.9999 |\n    +-----------+-----------+\n    | eggs      |  451      |\n    +-----------+-----------+\n\n    >>> print(tabulate([[\"spam\", 41.9999], [\"eggs\", \"451.0\"]], tablefmt=\"grid\"))\n    +------+----------+\n    | spam |  41.9999 |\n    +------+----------+\n    | eggs | 451      |\n    +------+----------+\n\n    \"pipe\" is like tables in PHP Markdown Extra extension or Pandoc\n    pipe_tables:\n\n    >>> print(tabulate([[\"spam\", 41.9999], [\"eggs\", \"451.0\"]],\n    ...                [\"strings\", \"numbers\"], \"pipe\"))\n    | strings   |   numbers |\n    |:----------|----------:|\n    | spam      |   41.9999 |\n    | eggs      |  451      |\n\n    >>> print(tabulate([[\"spam\", 41.9999], [\"eggs\", \"451.0\"]], tablefmt=\"pipe\"))\n    |:-----|---------:|\n    | spam |  41.9999 |\n    | eggs | 451      |\n\n    \"orgtbl\" is like tables in Emacs org-mode and orgtbl-mode. They\n    are slightly different from \"pipe\" format by not using colons to\n    define column alignment, and using a \"+\" sign to indicate line\n    intersections:\n\n    >>> print(tabulate([[\"spam\", 41.9999], [\"eggs\", \"451.0\"]],\n    ...                [\"strings\", \"numbers\"], \"orgtbl\"))\n    | strings   |   numbers |\n    |-----------+-----------|\n    | spam      |   41.9999 |\n    | eggs      |  451      |\n\n\n    >>> print(tabulate([[\"spam\", 41.9999], [\"eggs\", \"451.0\"]], tablefmt=\"orgtbl\"))\n    | spam |  41.9999 |\n    | eggs | 451      |\n\n    \"rst\" is like a simple table format from reStructuredText; please\n    note that reStructuredText accepts also \"grid\" tables:\n\n    >>> print(tabulate([[\"spam\", 41.9999], [\"eggs\", \"451.0\"]],\n    ...                [\"strings\", \"numbers\"], \"rst\"))\n    =========  =========\n    strings      numbers\n    =========  =========\n    spam         41.9999\n    eggs        451\n    =========  =========\n\n    >>> print(tabulate([[\"spam\", 41.9999], [\"eggs\", \"451.0\"]], tablefmt=\"rst\"))\n    ====  ========\n    spam   41.9999\n    eggs  451\n    ====  ========\n\n    \"mediawiki\" produces a table markup used in Wikipedia and on other\n    MediaWiki-based sites:\n\n    >>> print(tabulate([[\"strings\", \"numbers\"], [\"spam\", 41.9999], [\"eggs\", \"451.0\"]],\n    ...                headers=\"firstrow\", tablefmt=\"mediawiki\"))\n    {| class=\"wikitable\" style=\"text-align: left;\"\n    |+ <!-- caption -->\n    |-\n    ! strings   !! align=\"right\"|   numbers\n    |-\n    | spam      || align=\"right\"|   41.9999\n    |-\n    | eggs      || align=\"right\"|  451\n    |}\n\n    \"latex\" produces a tabular environment of LaTeX document markup:\n\n    >>> print(tabulate([[\"spam\", 41.9999], [\"eggs\", \"451.0\"]], tablefmt=\"latex\"))\n    \\\\begin{tabular}{lr}\n    \\\\hline\n     spam &  41.9999 \\\\\\\\\n     eggs & 451      \\\\\\\\\n    \\\\hline\n    \\\\end{tabular}\n\n    \"\"\"", "\n", "\n", "list_of_lists", ",", "headers", "=", "_normalize_tabular_data", "(", "tabular_data", ",", "headers", ")", "\n", "\n", "# optimization: look for ANSI control codes once,", "\n", "# enable smart width functions only if a control code is found", "\n", "plain_text", "=", "'\\n'", ".", "join", "(", "[", "'\\t'", ".", "join", "(", "map", "(", "_text_type", ",", "headers", ")", ")", "]", "+", "[", "'\\t'", ".", "join", "(", "map", "(", "_text_type", ",", "row", ")", ")", "for", "row", "in", "list_of_lists", "]", ")", "\n", "has_invisible", "=", "re", ".", "search", "(", "_invisible_codes", ",", "plain_text", ")", "\n", "if", "has_invisible", ":", "\n", "        ", "width_fn", "=", "_visible_width", "\n", "", "else", ":", "\n", "        ", "width_fn", "=", "len", "\n", "\n", "# format rows and columns, convert numeric values to strings", "\n", "", "cols", "=", "list", "(", "zip", "(", "*", "list_of_lists", ")", ")", "\n", "coltypes", "=", "list", "(", "map", "(", "_column_type", ",", "cols", ")", ")", "\n", "cols", "=", "[", "[", "_format", "(", "v", ",", "ct", ",", "floatfmt", ",", "missingval", ")", "for", "v", "in", "c", "]", "\n", "for", "c", ",", "ct", "in", "zip", "(", "cols", ",", "coltypes", ")", "]", "\n", "\n", "# align columns", "\n", "aligns", "=", "[", "numalign", "if", "ct", "in", "[", "int", ",", "float", "]", "else", "stralign", "for", "ct", "in", "coltypes", "]", "\n", "minwidths", "=", "[", "width_fn", "(", "h", ")", "+", "2", "for", "h", "in", "headers", "]", "if", "headers", "else", "[", "0", "]", "*", "len", "(", "cols", ")", "\n", "cols", "=", "[", "_align_column", "(", "c", ",", "a", ",", "minw", ",", "has_invisible", ")", "\n", "for", "c", ",", "a", ",", "minw", "in", "zip", "(", "cols", ",", "aligns", ",", "minwidths", ")", "]", "\n", "\n", "if", "headers", ":", "\n", "# align headers and add headers", "\n", "        ", "minwidths", "=", "[", "max", "(", "minw", ",", "width_fn", "(", "c", "[", "0", "]", ")", ")", "for", "minw", ",", "c", "in", "zip", "(", "minwidths", ",", "cols", ")", "]", "\n", "headers", "=", "[", "_align_header", "(", "h", ",", "a", ",", "minw", ")", "\n", "for", "h", ",", "a", ",", "minw", "in", "zip", "(", "headers", ",", "aligns", ",", "minwidths", ")", "]", "\n", "rows", "=", "list", "(", "zip", "(", "*", "cols", ")", ")", "\n", "", "else", ":", "\n", "        ", "minwidths", "=", "[", "width_fn", "(", "c", "[", "0", "]", ")", "for", "c", "in", "cols", "]", "\n", "rows", "=", "list", "(", "zip", "(", "*", "cols", ")", ")", "\n", "\n", "", "if", "not", "isinstance", "(", "tablefmt", ",", "TableFormat", ")", ":", "\n", "        ", "tablefmt", "=", "_table_formats", ".", "get", "(", "tablefmt", ",", "_table_formats", "[", "\"simple\"", "]", ")", "\n", "\n", "", "return", "_format_table", "(", "tablefmt", ",", "headers", ",", "rows", ",", "minwidths", ",", "aligns", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.logging.tabulate._build_simple_row": [[780, 784], ["sep.join"], "function", ["None"], ["", "def", "_build_simple_row", "(", "padded_cells", ",", "rowfmt", ")", ":", "\n", "    ", "\"Format row according to DataRow format without padding.\"", "\n", "begin", ",", "sep", ",", "end", "=", "rowfmt", "\n", "return", "(", "begin", "+", "sep", ".", "join", "(", "padded_cells", ")", "+", "end", ")", ".", "rstrip", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.logging.tabulate._build_row": [[786, 794], ["hasattr", "rowfmt", "tabulate._build_simple_row"], "function", ["home.repos.pwc.inspect_result.astooke_rlpyt.logging.tabulate._build_simple_row"], ["", "def", "_build_row", "(", "padded_cells", ",", "colwidths", ",", "colaligns", ",", "rowfmt", ")", ":", "\n", "    ", "\"Return a string which represents a row of data cells.\"", "\n", "if", "not", "rowfmt", ":", "\n", "        ", "return", "None", "\n", "", "if", "hasattr", "(", "rowfmt", ",", "\"__call__\"", ")", ":", "\n", "        ", "return", "rowfmt", "(", "padded_cells", ",", "colwidths", ",", "colaligns", ")", "\n", "", "else", ":", "\n", "        ", "return", "_build_simple_row", "(", "padded_cells", ",", "rowfmt", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.logging.tabulate._build_line": [[796, 806], ["hasattr", "linefmt", "tabulate._build_simple_row"], "function", ["home.repos.pwc.inspect_result.astooke_rlpyt.logging.tabulate._build_simple_row"], ["", "", "def", "_build_line", "(", "colwidths", ",", "colaligns", ",", "linefmt", ")", ":", "\n", "    ", "\"Return a string which represents a horizontal line.\"", "\n", "if", "not", "linefmt", ":", "\n", "        ", "return", "None", "\n", "", "if", "hasattr", "(", "linefmt", ",", "\"__call__\"", ")", ":", "\n", "        ", "return", "linefmt", "(", "colwidths", ",", "colaligns", ")", "\n", "", "else", ":", "\n", "        ", "begin", ",", "fill", ",", "sep", ",", "end", "=", "linefmt", "\n", "cells", "=", "[", "fill", "*", "w", "for", "w", "in", "colwidths", "]", "\n", "return", "_build_simple_row", "(", "cells", ",", "(", "begin", ",", "sep", ",", "end", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.logging.tabulate._pad_row": [[808, 815], ["None"], "function", ["None"], ["", "", "def", "_pad_row", "(", "cells", ",", "padding", ")", ":", "\n", "    ", "if", "cells", ":", "\n", "        ", "pad", "=", "\" \"", "*", "padding", "\n", "padded_cells", "=", "[", "pad", "+", "cell", "+", "pad", "for", "cell", "in", "cells", "]", "\n", "return", "padded_cells", "\n", "", "else", ":", "\n", "        ", "return", "cells", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.logging.tabulate._format_table": [[817, 851], ["tabulate._pad_row", "tabulate._pad_row", "lines.append", "lines.append", "lines.append", "lines.append", "tabulate._build_line", "tabulate._build_row", "lines.append", "lines.append", "lines.append", "tabulate._build_row", "lines.append", "tabulate._build_line", "tabulate._build_line", "tabulate._build_row", "tabulate._build_line", "tabulate._build_row"], "function", ["home.repos.pwc.inspect_result.astooke_rlpyt.logging.tabulate._pad_row", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.tabulate._pad_row", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.tabulate._build_line", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.tabulate._build_row", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.tabulate._build_row", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.tabulate._build_line", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.tabulate._build_line", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.tabulate._build_row", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.tabulate._build_line", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.tabulate._build_row"], ["", "", "def", "_format_table", "(", "fmt", ",", "headers", ",", "rows", ",", "colwidths", ",", "colaligns", ")", ":", "\n", "    ", "\"\"\"Produce a plain-text representation of the table.\"\"\"", "\n", "lines", "=", "[", "]", "\n", "hidden", "=", "fmt", ".", "with_header_hide", "if", "(", "headers", "and", "fmt", ".", "with_header_hide", ")", "else", "[", "]", "\n", "pad", "=", "fmt", ".", "padding", "\n", "headerrow", "=", "fmt", ".", "headerrow", "\n", "\n", "padded_widths", "=", "[", "(", "w", "+", "2", "*", "pad", ")", "for", "w", "in", "colwidths", "]", "\n", "padded_headers", "=", "_pad_row", "(", "headers", ",", "pad", ")", "\n", "padded_rows", "=", "[", "_pad_row", "(", "row", ",", "pad", ")", "for", "row", "in", "rows", "]", "\n", "\n", "if", "fmt", ".", "lineabove", "and", "\"lineabove\"", "not", "in", "hidden", ":", "\n", "        ", "lines", ".", "append", "(", "_build_line", "(", "padded_widths", ",", "colaligns", ",", "fmt", ".", "lineabove", ")", ")", "\n", "\n", "", "if", "padded_headers", ":", "\n", "        ", "lines", ".", "append", "(", "_build_row", "(", "padded_headers", ",", "padded_widths", ",", "colaligns", ",", "headerrow", ")", ")", "\n", "if", "fmt", ".", "linebelowheader", "and", "\"linebelowheader\"", "not", "in", "hidden", ":", "\n", "            ", "lines", ".", "append", "(", "_build_line", "(", "padded_widths", ",", "colaligns", ",", "fmt", ".", "linebelowheader", ")", ")", "\n", "\n", "", "", "if", "padded_rows", "and", "fmt", ".", "linebetweenrows", "and", "\"linebetweenrows\"", "not", "in", "hidden", ":", "\n", "# initial rows with a line below", "\n", "        ", "for", "row", "in", "padded_rows", "[", ":", "-", "1", "]", ":", "\n", "            ", "lines", ".", "append", "(", "_build_row", "(", "row", ",", "padded_widths", ",", "colaligns", ",", "fmt", ".", "datarow", ")", ")", "\n", "lines", ".", "append", "(", "_build_line", "(", "padded_widths", ",", "colaligns", ",", "fmt", ".", "linebetweenrows", ")", ")", "\n", "# the last row without a line below", "\n", "", "lines", ".", "append", "(", "_build_row", "(", "padded_rows", "[", "-", "1", "]", ",", "padded_widths", ",", "colaligns", ",", "fmt", ".", "datarow", ")", ")", "\n", "", "else", ":", "\n", "        ", "for", "row", "in", "padded_rows", ":", "\n", "            ", "lines", ".", "append", "(", "_build_row", "(", "row", ",", "padded_widths", ",", "colaligns", ",", "fmt", ".", "datarow", ")", ")", "\n", "\n", "", "", "if", "fmt", ".", "linebelow", "and", "\"linebelow\"", "not", "in", "hidden", ":", "\n", "        ", "lines", ".", "append", "(", "_build_line", "(", "padded_widths", ",", "colaligns", ",", "fmt", ".", "linebelow", ")", ")", "\n", "\n", "", "return", "\"\\n\"", ".", "join", "(", "lines", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.astooke_rlpyt.logging.logger.TerminalTablePrinter.__init__": [[248, 251], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "self", ".", "headers", "=", "None", "\n", "self", ".", "tabulars", "=", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.logging.logger.TerminalTablePrinter.print_tabular": [[252, 259], ["logger.TerminalTablePrinter.tabulars.append", "logger.TerminalTablePrinter.refresh", "len", "len"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.logging.logger.TerminalTablePrinter.refresh"], ["", "def", "print_tabular", "(", "self", ",", "new_tabular", ")", ":", "\n", "        ", "if", "self", ".", "headers", "is", "None", ":", "\n", "            ", "self", ".", "headers", "=", "[", "x", "[", "0", "]", "for", "x", "in", "new_tabular", "]", "\n", "", "else", ":", "\n", "            ", "assert", "len", "(", "self", ".", "headers", ")", "==", "len", "(", "new_tabular", ")", "\n", "", "self", ".", "tabulars", ".", "append", "(", "[", "x", "[", "1", "]", "for", "x", "in", "new_tabular", "]", ")", "\n", "self", ".", "refresh", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.logging.logger.TerminalTablePrinter.refresh": [[260, 267], ["os.popen().read().split", "os.popen().read().split", "os.popen().read().split", "os.popen().read().split", "sys.stdout.write", "sys.stdout.write", "sys.stdout.write", "rlpyt.utils.logging.tabulate.tabulate", "os.popen().read", "os.popen().read", "os.popen().read", "os.popen().read", "os.popen", "os.popen", "os.popen", "os.popen", "int"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.envs.dmlab.LevelCache.write", "home.repos.pwc.inspect_result.astooke_rlpyt.envs.dmlab.LevelCache.write", "home.repos.pwc.inspect_result.astooke_rlpyt.envs.dmlab.LevelCache.write", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.tabulate.tabulate"], ["", "def", "refresh", "(", "self", ")", ":", "\n", "        ", "import", "os", "\n", "rows", ",", "columns", "=", "os", ".", "popen", "(", "'stty size'", ",", "'r'", ")", ".", "read", "(", ")", ".", "split", "(", ")", "\n", "tabulars", "=", "self", ".", "tabulars", "[", "-", "(", "int", "(", "rows", ")", "-", "3", ")", ":", "]", "\n", "sys", ".", "stdout", ".", "write", "(", "\"\\x1b[2J\\x1b[H\"", ")", "\n", "sys", ".", "stdout", ".", "write", "(", "tabulate", "(", "tabulars", ",", "self", ".", "headers", ")", ")", "\n", "sys", ".", "stdout", ".", "write", "(", "\"\\n\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.logging.logger.MyEncoder.default": [[415, 421], ["isinstance", "json.JSONEncoder.default", "isinstance"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.logging.logger.MyEncoder.default"], ["    ", "def", "default", "(", "self", ",", "o", ")", ":", "\n", "        ", "if", "isinstance", "(", "o", ",", "type", ")", ":", "\n", "            ", "return", "{", "'$class'", ":", "o", ".", "__module__", "+", "\".\"", "+", "o", ".", "__name__", "}", "\n", "", "elif", "isinstance", "(", "o", ",", "Enum", ")", ":", "\n", "            ", "return", "{", "'$enum'", ":", "o", ".", "__module__", "+", "\".\"", "+", "o", ".", "__class__", ".", "__name__", "+", "'.'", "+", "o", ".", "name", "}", "\n", "", "return", "json", ".", "JSONEncoder", ".", "default", "(", "self", ",", "o", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.logging.logger.disable": [[53, 56], ["None"], "function", ["None"], ["def", "disable", "(", ")", ":", "\n", "    ", "global", "_disabled", "\n", "_disabled", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.logging.logger.disable_tabular": [[58, 61], ["None"], "function", ["None"], ["", "def", "disable_tabular", "(", ")", ":", "\n", "    ", "global", "_tabular_disabled", "\n", "_tabular_disabled", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.logging.logger.enable": [[63, 66], ["None"], "function", ["None"], ["", "def", "enable", "(", ")", ":", "\n", "    ", "global", "_disabled", "\n", "_disabled", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.logging.logger.enable_tabular": [[68, 71], ["None"], "function", ["None"], ["", "def", "enable_tabular", "(", ")", ":", "\n", "    ", "global", "_tabular_disabled", "\n", "_tabular_disabled", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.logging.logger.set_iteration": [[73, 76], ["None"], "function", ["None"], ["", "def", "set_iteration", "(", "iteration", ")", ":", "\n", "    ", "global", "_iteration", "\n", "_iteration", "=", "iteration", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.logging.logger._add_output": [[78, 83], ["rlpyt.utils.logging.console.mkdir_p", "arr.append", "open", "os.path.dirname", "os.path.dirname"], "function", ["home.repos.pwc.inspect_result.astooke_rlpyt.logging.console.mkdir_p"], ["", "def", "_add_output", "(", "file_name", ",", "arr", ",", "fds", ",", "mode", "=", "'a'", ")", ":", "\n", "    ", "if", "file_name", "not", "in", "arr", ":", "\n", "        ", "mkdir_p", "(", "os", ".", "path", ".", "dirname", "(", "file_name", ")", ")", "\n", "arr", ".", "append", "(", "file_name", ")", "\n", "fds", "[", "file_name", "]", "=", "open", "(", "file_name", ",", "mode", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.logging.logger._remove_output": [[85, 90], ["fds[].close", "arr.remove"], "function", ["home.repos.pwc.inspect_result.astooke_rlpyt.envs.dmlab.DmlabEnv.close"], ["", "", "def", "_remove_output", "(", "file_name", ",", "arr", ",", "fds", ")", ":", "\n", "    ", "if", "file_name", "in", "arr", ":", "\n", "        ", "fds", "[", "file_name", "]", ".", "close", "(", ")", "\n", "del", "fds", "[", "file_name", "]", "\n", "arr", ".", "remove", "(", "file_name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.logging.logger.push_prefix": [[92, 96], ["_prefixes.append"], "function", ["None"], ["", "", "def", "push_prefix", "(", "prefix", ")", ":", "\n", "    ", "_prefixes", ".", "append", "(", "prefix", ")", "\n", "global", "_prefix_str", "\n", "_prefix_str", "=", "''", ".", "join", "(", "_prefixes", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.logging.logger.add_text_output": [[98, 100], ["logger._add_output"], "function", ["home.repos.pwc.inspect_result.astooke_rlpyt.logging.logger._add_output"], ["", "def", "add_text_output", "(", "file_name", ")", ":", "\n", "    ", "_add_output", "(", "file_name", ",", "_text_outputs", ",", "_text_fds", ",", "mode", "=", "'a'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.logging.logger.remove_text_output": [[102, 104], ["logger._remove_output"], "function", ["home.repos.pwc.inspect_result.astooke_rlpyt.logging.logger._remove_output"], ["", "def", "remove_text_output", "(", "file_name", ")", ":", "\n", "    ", "_remove_output", "(", "file_name", ",", "_text_outputs", ",", "_text_fds", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.logging.logger.add_tabular_output": [[106, 112], ["_tabular_fds_hold.keys", "_tabular_outputs.append", "logger._add_output"], "function", ["home.repos.pwc.inspect_result.astooke_rlpyt.logging.logger._add_output"], ["", "def", "add_tabular_output", "(", "file_name", ")", ":", "\n", "    ", "if", "file_name", "in", "_tabular_fds_hold", ".", "keys", "(", ")", ":", "\n", "        ", "_tabular_outputs", ".", "append", "(", "file_name", ")", "\n", "_tabular_fds", "[", "file_name", "]", "=", "_tabular_fds_hold", "[", "file_name", "]", "\n", "", "else", ":", "\n", "        ", "_add_output", "(", "file_name", ",", "_tabular_outputs", ",", "_tabular_fds", ",", "mode", "=", "'w'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.logging.logger.remove_tabular_output": [[114, 118], ["logger._remove_output", "_tabular_header_written.remove"], "function", ["home.repos.pwc.inspect_result.astooke_rlpyt.logging.logger._remove_output"], ["", "", "def", "remove_tabular_output", "(", "file_name", ")", ":", "\n", "    ", "if", "file_name", "in", "_tabular_header_written", ":", "\n", "        ", "_tabular_header_written", ".", "remove", "(", "file_name", ")", "\n", "", "_remove_output", "(", "file_name", ",", "_tabular_outputs", ",", "_tabular_fds", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.logging.logger.hold_tabular_output": [[120, 125], ["_tabular_outputs.remove", "_tabular_fds.pop"], "function", ["None"], ["", "def", "hold_tabular_output", "(", "file_name", ")", ":", "\n", "# what about _tabular_header_written?", "\n", "    ", "if", "file_name", "in", "_tabular_outputs", ":", "\n", "        ", "_tabular_outputs", ".", "remove", "(", "file_name", ")", "\n", "_tabular_fds_hold", "[", "file_name", "]", "=", "_tabular_fds", ".", "pop", "(", "file_name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.logging.logger.set_snapshot_dir": [[127, 131], ["rlpyt.utils.logging.console.mkdir_p"], "function", ["home.repos.pwc.inspect_result.astooke_rlpyt.logging.console.mkdir_p"], ["", "", "def", "set_snapshot_dir", "(", "dir_name", ")", ":", "\n", "    ", "mkdir_p", "(", "dir_name", ")", "\n", "global", "_snapshot_dir", "\n", "_snapshot_dir", "=", "dir_name", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.logging.logger.get_snapshot_dir": [[133, 135], ["None"], "function", ["None"], ["", "def", "get_snapshot_dir", "(", ")", ":", "\n", "    ", "return", "_snapshot_dir", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.logging.logger.set_tf_summary_dir": [[137, 140], ["None"], "function", ["None"], ["", "def", "set_tf_summary_dir", "(", "dir_name", ")", ":", "\n", "    ", "global", "_tf_summary_dir", "\n", "_tf_summary_dir", "=", "dir_name", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.logging.logger.get_tf_summary_dir": [[142, 144], ["None"], "function", ["None"], ["", "def", "get_tf_summary_dir", "(", ")", ":", "\n", "    ", "return", "_tf_summary_dir", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.logging.logger.set_tf_summary_writer": [[146, 149], ["None"], "function", ["None"], ["", "def", "set_tf_summary_writer", "(", "writer_name", ")", ":", "\n", "    ", "global", "_tf_summary_writer", "\n", "_tf_summary_writer", "=", "writer_name", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.logging.logger.get_tf_summary_writer": [[151, 153], ["None"], "function", ["None"], ["", "def", "get_tf_summary_writer", "(", ")", ":", "\n", "    ", "return", "_tf_summary_writer", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.logging.logger.get_snapshot_mode": [[155, 157], ["None"], "function", ["None"], ["", "def", "get_snapshot_mode", "(", ")", ":", "\n", "    ", "return", "_snapshot_mode", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.logging.logger.set_snapshot_mode": [[159, 162], ["None"], "function", ["None"], ["", "def", "set_snapshot_mode", "(", "mode", ")", ":", "\n", "    ", "global", "_snapshot_mode", "\n", "_snapshot_mode", "=", "mode", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.logging.logger.get_snapshot_gap": [[164, 166], ["None"], "function", ["None"], ["", "def", "get_snapshot_gap", "(", ")", ":", "\n", "    ", "return", "_snapshot_gap", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.logging.logger.set_snapshot_gap": [[168, 171], ["None"], "function", ["None"], ["", "def", "set_snapshot_gap", "(", "gap", ")", ":", "\n", "    ", "global", "_snapshot_gap", "\n", "_snapshot_gap", "=", "gap", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.logging.logger.set_log_tabular_only": [[173, 176], ["None"], "function", ["None"], ["", "def", "set_log_tabular_only", "(", "log_tabular_only", ")", ":", "\n", "    ", "global", "_log_tabular_only", "\n", "_log_tabular_only", "=", "log_tabular_only", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.logging.logger.get_log_tabular_only": [[178, 180], ["None"], "function", ["None"], ["", "def", "get_log_tabular_only", "(", ")", ":", "\n", "    ", "return", "_log_tabular_only", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.logging.logger.set_disable_prefix": [[182, 185], ["None"], "function", ["None"], ["", "def", "set_disable_prefix", "(", "disable_prefix", ")", ":", "\n", "    ", "global", "_disable_prefix", "\n", "_disable_prefix", "=", "disable_prefix", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.logging.logger.get_disable_prefix": [[187, 189], ["None"], "function", ["None"], ["", "def", "get_disable_prefix", "(", ")", ":", "\n", "    ", "return", "_disable_prefix", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.logging.logger.log": [[191, 209], ["datetime.datetime.now", "datetime.datetime.now.strftime", "rlpyt.utils.logging.console.colorize", "print", "list", "sys.stdout.flush", "_text_fds.values", "fd.write", "fd.flush"], "function", ["home.repos.pwc.inspect_result.astooke_rlpyt.logging.console.colorize", "home.repos.pwc.inspect_result.astooke_rlpyt.envs.dmlab.LevelCache.write"], ["", "def", "log", "(", "s", ",", "with_prefix", "=", "True", ",", "with_timestamp", "=", "True", ",", "color", "=", "None", ")", ":", "\n", "    ", "if", "not", "_disabled", ":", "\n", "        ", "out", "=", "s", "\n", "if", "with_prefix", "and", "not", "_disable_prefix", ":", "\n", "            ", "out", "=", "_prefix_str", "+", "out", "\n", "", "if", "with_timestamp", ":", "\n", "            ", "now", "=", "datetime", ".", "datetime", ".", "now", "(", ")", "# dateutil.tz.tzlocal())", "\n", "timestamp", "=", "now", ".", "strftime", "(", "'%Y-%m-%d %H:%M:%S.%f %Z'", ")", "\n", "out", "=", "\"%s | %s\"", "%", "(", "timestamp", ",", "out", ")", "\n", "", "if", "color", "is", "not", "None", ":", "\n", "            ", "out", "=", "colorize", "(", "out", ",", "color", ")", "\n", "", "if", "not", "_log_tabular_only", ":", "\n", "# Also log to stdout", "\n", "            ", "print", "(", "out", ")", "\n", "for", "fd", "in", "list", "(", "_text_fds", ".", "values", "(", ")", ")", ":", "\n", "                ", "fd", ".", "write", "(", "out", "+", "'\\n'", ")", "\n", "fd", ".", "flush", "(", ")", "\n", "", "sys", ".", "stdout", ".", "flush", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.logging.logger.record_tabular": [[211, 217], ["_tabular.append", "str", "_tf_summary_writer.add_scalar", "str", "numpy.np.nan", "numpy.np.nan", "numpy.np.nan", "numpy.np.nan", "numpy.np.nan"], "function", ["None"], ["", "", "", "def", "record_tabular", "(", "key", ",", "val", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "# if not _disabled and not _tabular_disabled:", "\n", "    ", "key", "=", "_tabular_prefix_str", "+", "str", "(", "key", ")", "\n", "_tabular", ".", "append", "(", "(", "key", ",", "str", "(", "val", ")", ")", ")", "\n", "if", "_tf_summary_writer", "is", "not", "None", ":", "\n", "        ", "_tf_summary_writer", ".", "add_scalar", "(", "key", ",", "val", ",", "_iteration", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.logging.logger.push_tabular_prefix": [[219, 223], ["_tabular_prefixes.append"], "function", ["None"], ["", "", "def", "push_tabular_prefix", "(", "key", ")", ":", "\n", "    ", "_tabular_prefixes", ".", "append", "(", "key", ")", "\n", "global", "_tabular_prefix_str", "\n", "_tabular_prefix_str", "=", "''", ".", "join", "(", "_tabular_prefixes", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.logging.logger.pop_tabular_prefix": [[225, 229], ["None"], "function", ["None"], ["", "def", "pop_tabular_prefix", "(", ")", ":", "\n", "    ", "del", "_tabular_prefixes", "[", "-", "1", "]", "\n", "global", "_tabular_prefix_str", "\n", "_tabular_prefix_str", "=", "''", ".", "join", "(", "_tabular_prefixes", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.logging.logger.prefix": [[231, 238], ["logger.push_prefix", "logger.pop_prefix"], "function", ["home.repos.pwc.inspect_result.astooke_rlpyt.logging.logger.push_prefix", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.logger.pop_prefix"], ["", "@", "contextmanager", "\n", "def", "prefix", "(", "key", ")", ":", "\n", "    ", "push_prefix", "(", "key", ")", "\n", "try", ":", "\n", "        ", "yield", "\n", "", "finally", ":", "\n", "        ", "pop_prefix", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.logging.logger.tabular_prefix": [[240, 245], ["logger.push_tabular_prefix", "logger.pop_tabular_prefix"], "function", ["home.repos.pwc.inspect_result.astooke_rlpyt.logging.logger.push_tabular_prefix", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.logger.pop_tabular_prefix"], ["", "", "@", "contextmanager", "\n", "def", "tabular_prefix", "(", "key", ")", ":", "\n", "    ", "push_tabular_prefix", "(", "key", ")", "\n", "yield", "\n", "pop_tabular_prefix", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.logging.logger.dump_tabular": [[274, 324], ["kwargs.pop", "len", "table_printer.print_tabular", "rlpyt.utils.logging.tabulate.tabulate().split", "dict", "list", "logger.log", "_tabular_fds.items", "dict.keys", "csv.DictWriter", "csv.DictWriter.writerow", "open.flush", "rlpyt.utils.logging.tabulate.tabulate", "csv.DictWriter.writeheader", "_tabular_header_written.add", "set().issuperset", "set().union", "open.flush", "open", "csv.DictReader", "list", "open.close", "open.close", "open", "csv.DictWriter", "csv.DictWriter.writeheader", "csv.DictWriter.writerows", "list", "set", "set", "set", "set", "list"], "function", ["home.repos.pwc.inspect_result.astooke_rlpyt.logging.logger.TerminalTablePrinter.print_tabular", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.console.log", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.collections.NamedArrayTuple.items", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.tabulate.tabulate", "home.repos.pwc.inspect_result.astooke_rlpyt.envs.dmlab.DmlabEnv.close", "home.repos.pwc.inspect_result.astooke_rlpyt.envs.dmlab.DmlabEnv.close"], ["def", "dump_tabular", "(", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "    ", "if", "not", "_disabled", ":", "# and not _tabular_disabled:", "\n", "        ", "wh", "=", "kwargs", ".", "pop", "(", "\"write_header\"", ",", "None", ")", "\n", "if", "len", "(", "_tabular", ")", ">", "0", ":", "\n", "            ", "if", "_log_tabular_only", ":", "\n", "                ", "table_printer", ".", "print_tabular", "(", "_tabular", ")", "\n", "", "else", ":", "\n", "                ", "for", "line", "in", "tabulate", "(", "_tabular", ")", ".", "split", "(", "'\\n'", ")", ":", "\n", "                    ", "log", "(", "line", ",", "*", "args", ",", "**", "kwargs", ")", "\n", "", "", "if", "not", "_tabular_disabled", ":", "\n", "                ", "tabular_dict", "=", "dict", "(", "_tabular", ")", "\n", "# Also write to the csv files", "\n", "# This assumes that the keys in each iteration won't change!", "\n", "for", "tabular_file_name", ",", "tabular_fd", "in", "list", "(", "_tabular_fds", ".", "items", "(", ")", ")", ":", "\n", "                    ", "keys", "=", "tabular_dict", ".", "keys", "(", ")", "\n", "if", "tabular_file_name", "in", "_tabular_headers", ":", "\n", "# check against existing keys: if new keys re-write Header and pad with NaNs", "\n", "                        ", "existing_keys", "=", "_tabular_headers", "[", "tabular_file_name", "]", "\n", "if", "not", "set", "(", "existing_keys", ")", ".", "issuperset", "(", "set", "(", "keys", ")", ")", ":", "\n", "                            ", "joint_keys", "=", "set", "(", "keys", ")", ".", "union", "(", "set", "(", "existing_keys", ")", ")", "\n", "tabular_fd", ".", "flush", "(", ")", "\n", "read_fd", "=", "open", "(", "tabular_file_name", ",", "'r'", ")", "\n", "reader", "=", "csv", ".", "DictReader", "(", "read_fd", ")", "\n", "rows", "=", "list", "(", "reader", ")", "\n", "read_fd", ".", "close", "(", ")", "\n", "tabular_fd", ".", "close", "(", ")", "\n", "tabular_fd", "=", "_tabular_fds", "[", "tabular_file_name", "]", "=", "open", "(", "tabular_file_name", ",", "'w'", ")", "\n", "new_writer", "=", "csv", ".", "DictWriter", "(", "tabular_fd", ",", "fieldnames", "=", "list", "(", "joint_keys", ")", ")", "\n", "new_writer", ".", "writeheader", "(", ")", "\n", "for", "row", "in", "rows", ":", "\n", "                                ", "for", "key", "in", "joint_keys", ":", "\n", "                                    ", "if", "key", "not", "in", "row", ":", "\n", "                                        ", "row", "[", "key", "]", "=", "np", ".", "nan", "\n", "", "", "", "new_writer", ".", "writerows", "(", "rows", ")", "\n", "_tabular_headers", "[", "tabular_file_name", "]", "=", "list", "(", "joint_keys", ")", "\n", "", "", "else", ":", "\n", "                        ", "_tabular_headers", "[", "tabular_file_name", "]", "=", "keys", "\n", "\n", "", "writer", "=", "csv", ".", "DictWriter", "(", "tabular_fd", ",", "fieldnames", "=", "_tabular_headers", "[", "tabular_file_name", "]", ")", "# list(", "\n", "if", "wh", "or", "(", "wh", "is", "None", "and", "tabular_file_name", "not", "in", "_tabular_header_written", ")", ":", "\n", "                        ", "writer", ".", "writeheader", "(", ")", "\n", "_tabular_header_written", ".", "add", "(", "tabular_file_name", ")", "\n", "_tabular_headers", "[", "tabular_file_name", "]", "=", "keys", "\n", "# add NaNs in all empty fields from the header", "\n", "", "for", "key", "in", "_tabular_headers", "[", "tabular_file_name", "]", ":", "\n", "                        ", "if", "key", "not", "in", "tabular_dict", ":", "\n", "                            ", "tabular_dict", "[", "key", "]", "=", "np", ".", "nan", "\n", "", "", "writer", ".", "writerow", "(", "tabular_dict", ")", "\n", "tabular_fd", ".", "flush", "(", ")", "\n", "", "", "del", "_tabular", "[", ":", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.logging.logger.pop_prefix": [[326, 330], ["None"], "function", ["None"], ["", "", "", "def", "pop_prefix", "(", ")", ":", "\n", "    ", "del", "_prefixes", "[", "-", "1", "]", "\n", "global", "_prefix_str", "\n", "_prefix_str", "=", "''", ".", "join", "(", "_prefixes", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.logging.logger.save_itr_params": [[332, 354], ["torch.save", "os.join", "logger.get_snapshot_dir", "os.join", "logger.get_snapshot_dir", "os.join", "os.join", "logger.get_snapshot_dir", "os.join", "torch.save", "logger.get_snapshot_dir", "logger.get_snapshot_dir"], "function", ["home.repos.pwc.inspect_result.astooke_rlpyt.logging.logger.get_snapshot_dir", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.logger.get_snapshot_dir", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.logger.get_snapshot_dir", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.logger.get_snapshot_dir", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.logger.get_snapshot_dir"], ["", "def", "save_itr_params", "(", "itr", ",", "params", ")", ":", "\n", "    ", "if", "_snapshot_dir", ":", "\n", "        ", "if", "_snapshot_mode", "==", "'all'", ":", "\n", "            ", "file_name", "=", "osp", ".", "join", "(", "get_snapshot_dir", "(", ")", ",", "'itr_%d.pkl'", "%", "itr", ")", "\n", "", "elif", "_snapshot_mode", "==", "'last'", ":", "\n", "# override previous params", "\n", "            ", "file_name", "=", "osp", ".", "join", "(", "get_snapshot_dir", "(", ")", ",", "'params.pkl'", ")", "\n", "", "elif", "_snapshot_mode", "==", "\"gap\"", ":", "\n", "            ", "if", "itr", "==", "0", "or", "(", "itr", "+", "1", ")", "%", "_snapshot_gap", "==", "0", ":", "\n", "                ", "file_name", "=", "osp", ".", "join", "(", "get_snapshot_dir", "(", ")", ",", "'itr_%d.pkl'", "%", "itr", ")", "\n", "", "else", ":", "\n", "                ", "return", "\n", "", "", "elif", "_snapshot_mode", "==", "\"last+gap\"", ":", "\n", "            ", "if", "itr", "==", "0", "or", "(", "itr", "+", "1", ")", "%", "_snapshot_gap", "==", "0", ":", "\n", "                ", "file_name", "=", "osp", ".", "join", "(", "get_snapshot_dir", "(", ")", ",", "'itr_%d.pkl'", "%", "itr", ")", "\n", "torch", ".", "save", "(", "params", ",", "file_name", ")", "\n", "", "file_name", "=", "osp", ".", "join", "(", "get_snapshot_dir", "(", ")", ",", "'params.pkl'", ")", "\n", "", "elif", "_snapshot_mode", "==", "'none'", ":", "\n", "            ", "return", "\n", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "\n", "", "torch", ".", "save", "(", "params", ",", "file_name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.logging.logger.log_parameters": [[356, 373], ["args.__dict__.items", "classes.items", "rlpyt.utils.logging.console.mkdir_p", "any", "isinstance", "os.path.dirname", "os.path.dirname", "open", "json.dump", "rlpyt.utils.logging.autoargs.get_all_parameters", "getattr", "getattr", "param_name.startswith", "dict", "list", "classes.keys"], "function", ["home.repos.pwc.inspect_result.astooke_rlpyt.utils.collections.NamedArrayTuple.items", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.collections.NamedArrayTuple.items", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.console.mkdir_p", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.autoargs.get_all_parameters"], ["", "", "def", "log_parameters", "(", "log_file", ",", "args", ",", "classes", ")", ":", "\n", "    ", "log_params", "=", "{", "}", "\n", "for", "param_name", ",", "param_value", "in", "args", ".", "__dict__", ".", "items", "(", ")", ":", "\n", "        ", "if", "any", "(", "[", "param_name", ".", "startswith", "(", "x", ")", "for", "x", "in", "list", "(", "classes", ".", "keys", "(", ")", ")", "]", ")", ":", "\n", "            ", "continue", "\n", "", "log_params", "[", "param_name", "]", "=", "param_value", "\n", "", "for", "name", ",", "cls", "in", "classes", ".", "items", "(", ")", ":", "\n", "        ", "if", "isinstance", "(", "cls", ",", "type", ")", ":", "\n", "            ", "params", "=", "get_all_parameters", "(", "cls", ",", "args", ")", "\n", "params", "[", "\"_name\"", "]", "=", "getattr", "(", "args", ",", "name", ")", "\n", "log_params", "[", "name", "]", "=", "params", "\n", "", "else", ":", "\n", "            ", "log_params", "[", "name", "]", "=", "getattr", "(", "cls", ",", "\"__kwargs\"", ",", "dict", "(", ")", ")", "\n", "log_params", "[", "name", "]", "[", "\"_name\"", "]", "=", "cls", ".", "__module__", "+", "\".\"", "+", "cls", ".", "__class__", ".", "__name__", "\n", "", "", "mkdir_p", "(", "os", ".", "path", ".", "dirname", "(", "log_file", ")", ")", "\n", "with", "open", "(", "log_file", ",", "\"w\"", ")", "as", "f", ":", "\n", "        ", "json", ".", "dump", "(", "log_params", ",", "f", ",", "indent", "=", "2", ",", "sort_keys", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.logging.logger.stub_to_json": [[375, 412], ["isinstance", "isinstance", "dict", "stub_sth.kwargs.items", "len", "logger.stub_to_json", "isinstance", "isinstance", "dict", "isinstance", "isinstance", "dict", "logger.stub_to_json", "logger.stub_to_json", "isinstance", "isinstance", "logger.stub_to_json", "logger.stub_to_json", "logger.stub_to_json", "logger.stub_to_json", "isinstance", "isinstance", "isinstance", "isinstance", "logger.stub_to_json", "logger.stub_to_json", "list", "stub_sth.items", "map", "type", "type", "str", "repr", "type"], "function", ["home.repos.pwc.inspect_result.astooke_rlpyt.utils.collections.NamedArrayTuple.items", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.logger.stub_to_json", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.logger.stub_to_json", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.logger.stub_to_json", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.logger.stub_to_json", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.logger.stub_to_json", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.logger.stub_to_json", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.logger.stub_to_json", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.logger.stub_to_json", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.logger.stub_to_json", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.collections.NamedArrayTuple.items"], ["", "", "def", "stub_to_json", "(", "stub_sth", ")", ":", "\n", "    ", "from", "rllab", ".", "misc", "import", "instrument", "\n", "from", "rllab", ".", "misc", "import", "instrument2", "\n", "if", "isinstance", "(", "stub_sth", ",", "instrument", ".", "StubObject", ")", "or", "isinstance", "(", "stub_sth", ",", "instrument2", ".", "StubObject", ")", ":", "\n", "        ", "assert", "len", "(", "stub_sth", ".", "args", ")", "==", "0", "\n", "data", "=", "dict", "(", ")", "\n", "for", "k", ",", "v", "in", "stub_sth", ".", "kwargs", ".", "items", "(", ")", ":", "\n", "            ", "data", "[", "k", "]", "=", "stub_to_json", "(", "v", ")", "\n", "", "data", "[", "\"_name\"", "]", "=", "stub_sth", ".", "proxy_class", ".", "__module__", "+", "\".\"", "+", "stub_sth", ".", "proxy_class", ".", "__name__", "\n", "return", "data", "\n", "", "elif", "isinstance", "(", "stub_sth", ",", "instrument", ".", "StubAttr", ")", "or", "isinstance", "(", "stub_sth", ",", "instrument2", ".", "StubAttr", ")", ":", "\n", "        ", "return", "dict", "(", "\n", "obj", "=", "stub_to_json", "(", "stub_sth", ".", "obj", ")", ",", "\n", "attr", "=", "stub_to_json", "(", "stub_sth", ".", "attr_name", ")", "\n", ")", "\n", "", "elif", "isinstance", "(", "stub_sth", ",", "instrument", ".", "StubMethodCall", ")", "or", "isinstance", "(", "stub_sth", ",", "instrument2", ".", "StubMethodCall", ")", ":", "\n", "        ", "return", "dict", "(", "\n", "obj", "=", "stub_to_json", "(", "stub_sth", ".", "obj", ")", ",", "\n", "method_name", "=", "stub_to_json", "(", "stub_sth", ".", "method_name", ")", ",", "\n", "args", "=", "stub_to_json", "(", "stub_sth", ".", "args", ")", ",", "\n", "kwargs", "=", "stub_to_json", "(", "stub_sth", ".", "kwargs", ")", ",", "\n", ")", "\n", "", "elif", "isinstance", "(", "stub_sth", ",", "instrument", ".", "BinaryOp", ")", "or", "isinstance", "(", "stub_sth", ",", "instrument2", ".", "BinaryOp", ")", ":", "\n", "        ", "return", "\"binary_op\"", "\n", "", "elif", "isinstance", "(", "stub_sth", ",", "instrument", ".", "StubClass", ")", "or", "isinstance", "(", "stub_sth", ",", "instrument2", ".", "StubClass", ")", ":", "\n", "        ", "return", "stub_sth", ".", "proxy_class", ".", "__module__", "+", "\".\"", "+", "stub_sth", ".", "proxy_class", ".", "__name__", "\n", "", "elif", "isinstance", "(", "stub_sth", ",", "dict", ")", ":", "\n", "        ", "return", "{", "stub_to_json", "(", "k", ")", ":", "stub_to_json", "(", "v", ")", "for", "k", ",", "v", "in", "stub_sth", ".", "items", "(", ")", "}", "\n", "", "elif", "isinstance", "(", "stub_sth", ",", "(", "list", ",", "tuple", ")", ")", ":", "\n", "        ", "return", "list", "(", "map", "(", "stub_to_json", ",", "stub_sth", ")", ")", "\n", "", "elif", "type", "(", "stub_sth", ")", "==", "type", "(", "lambda", ":", "None", ")", ":", "\n", "        ", "if", "stub_sth", ".", "__module__", "is", "not", "None", ":", "\n", "            ", "return", "stub_sth", ".", "__module__", "+", "\".\"", "+", "stub_sth", ".", "__name__", "\n", "", "return", "stub_sth", ".", "__name__", "\n", "", "elif", "\"theano\"", "in", "str", "(", "type", "(", "stub_sth", ")", ")", ":", "\n", "        ", "return", "repr", "(", "stub_sth", ")", "\n", "", "return", "stub_sth", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.logging.logger.log_parameters_lite": [[423, 441], ["args.__dict__.items", "rlpyt.utils.logging.console.mkdir_p", "pickle.loads", "dict", "list", "logger.stub_to_json", "os.path.dirname", "os.path.dirname", "open", "json.dump", "base64.b64decode", "method_args.items", "logger.stub_to_json", "logger.stub_to_json", "kwargs.pop"], "function", ["home.repos.pwc.inspect_result.astooke_rlpyt.utils.collections.NamedArrayTuple.items", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.console.mkdir_p", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.logger.stub_to_json", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.collections.NamedArrayTuple.items", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.logger.stub_to_json", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.logger.stub_to_json"], ["", "", "def", "log_parameters_lite", "(", "log_file", ",", "args", ")", ":", "\n", "    ", "log_params", "=", "{", "}", "\n", "for", "param_name", ",", "param_value", "in", "args", ".", "__dict__", ".", "items", "(", ")", ":", "\n", "        ", "log_params", "[", "param_name", "]", "=", "param_value", "\n", "", "if", "args", ".", "args_data", "is", "not", "None", ":", "\n", "        ", "stub_method", "=", "pickle", ".", "loads", "(", "base64", ".", "b64decode", "(", "args", ".", "args_data", ")", ")", "\n", "method_args", "=", "stub_method", ".", "kwargs", "\n", "log_params", "[", "\"json_args\"", "]", "=", "dict", "(", ")", "\n", "for", "k", ",", "v", "in", "list", "(", "method_args", ".", "items", "(", ")", ")", ":", "\n", "            ", "log_params", "[", "\"json_args\"", "]", "[", "k", "]", "=", "stub_to_json", "(", "v", ")", "\n", "", "kwargs", "=", "stub_method", ".", "obj", ".", "kwargs", "\n", "for", "k", "in", "[", "\"baseline\"", ",", "\"env\"", ",", "\"policy\"", "]", ":", "\n", "            ", "if", "k", "in", "kwargs", ":", "\n", "                ", "log_params", "[", "\"json_args\"", "]", "[", "k", "]", "=", "stub_to_json", "(", "kwargs", ".", "pop", "(", "k", ")", ")", "\n", "", "", "log_params", "[", "\"json_args\"", "]", "[", "\"algo\"", "]", "=", "stub_to_json", "(", "stub_method", ".", "obj", ")", "\n", "", "mkdir_p", "(", "os", ".", "path", ".", "dirname", "(", "log_file", ")", ")", "\n", "with", "open", "(", "log_file", ",", "\"w\"", ")", "as", "f", ":", "\n", "        ", "json", ".", "dump", "(", "log_params", ",", "f", ",", "indent", "=", "2", ",", "sort_keys", "=", "True", ",", "cls", "=", "MyEncoder", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.logging.logger.log_variant": [[443, 450], ["rlpyt.utils.logging.console.mkdir_p", "hasattr", "logger.stub_to_json", "os.path.dirname", "os.path.dirname", "variant_data.dump.dump", "open", "json.dump"], "function", ["home.repos.pwc.inspect_result.astooke_rlpyt.logging.console.mkdir_p", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.logger.stub_to_json"], ["", "", "def", "log_variant", "(", "log_file", ",", "variant_data", ")", ":", "\n", "    ", "mkdir_p", "(", "os", ".", "path", ".", "dirname", "(", "log_file", ")", ")", "\n", "if", "hasattr", "(", "variant_data", ",", "\"dump\"", ")", ":", "\n", "        ", "variant_data", "=", "variant_data", ".", "dump", "(", ")", "\n", "", "variant_json", "=", "stub_to_json", "(", "variant_data", ")", "\n", "with", "open", "(", "log_file", ",", "\"w\"", ")", "as", "f", ":", "\n", "        ", "json", ".", "dump", "(", "variant_json", ",", "f", ",", "indent", "=", "2", ",", "sort_keys", "=", "True", ",", "cls", "=", "MyEncoder", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.logging.logger.record_tabular_misc_stat": [[452, 473], ["len", "logger.record_tabular", "logger.record_tabular", "logger.record_tabular", "logger.record_tabular", "logger.record_tabular", "logger.record_tabular", "logger.record_tabular", "logger.record_tabular", "logger.record_tabular", "logger.record_tabular", "numpy.average", "numpy.std", "numpy.median", "numpy.min", "numpy.max"], "function", ["home.repos.pwc.inspect_result.astooke_rlpyt.logging.logger.record_tabular", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.logger.record_tabular", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.logger.record_tabular", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.logger.record_tabular", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.logger.record_tabular", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.logger.record_tabular", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.logger.record_tabular", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.logger.record_tabular", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.logger.record_tabular", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.logger.record_tabular"], ["", "", "def", "record_tabular_misc_stat", "(", "key", ",", "values", ",", "placement", "=", "'back'", ")", ":", "\n", "    ", "if", "placement", "==", "'front'", ":", "\n", "        ", "prefix", "=", "\"\"", "\n", "suffix", "=", "key", "\n", "", "else", ":", "\n", "        ", "prefix", "=", "key", "\n", "suffix", "=", "\"\"", "\n", "if", "_tf_summary_writer", "is", "not", "None", ":", "\n", "            ", "prefix", "+=", "\"/\"", "# Group stats together in Tensorboard.", "\n", "", "", "if", "len", "(", "values", ")", ">", "0", ":", "\n", "        ", "record_tabular", "(", "prefix", "+", "\"Average\"", "+", "suffix", ",", "np", ".", "average", "(", "values", ")", ")", "\n", "record_tabular", "(", "prefix", "+", "\"Std\"", "+", "suffix", ",", "np", ".", "std", "(", "values", ")", ")", "\n", "record_tabular", "(", "prefix", "+", "\"Median\"", "+", "suffix", ",", "np", ".", "median", "(", "values", ")", ")", "\n", "record_tabular", "(", "prefix", "+", "\"Min\"", "+", "suffix", ",", "np", ".", "min", "(", "values", ")", ")", "\n", "record_tabular", "(", "prefix", "+", "\"Max\"", "+", "suffix", ",", "np", ".", "max", "(", "values", ")", ")", "\n", "", "else", ":", "\n", "        ", "record_tabular", "(", "prefix", "+", "\"Average\"", "+", "suffix", ",", "np", ".", "nan", ")", "\n", "record_tabular", "(", "prefix", "+", "\"Std\"", "+", "suffix", ",", "np", ".", "nan", ")", "\n", "record_tabular", "(", "prefix", "+", "\"Median\"", "+", "suffix", ",", "np", ".", "nan", ")", "\n", "record_tabular", "(", "prefix", "+", "\"Min\"", "+", "suffix", ",", "np", ".", "nan", ")", "\n", "record_tabular", "(", "prefix", "+", "\"Max\"", "+", "suffix", ",", "np", ".", "nan", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.astooke_rlpyt.logging.console.SimpleMessage.__init__": [[44, 47], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "msg", ",", "logger", "=", "log", ")", ":", "\n", "        ", "self", ".", "msg", "=", "msg", "\n", "self", ".", "logger", "=", "logger", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.logging.console.SimpleMessage.__enter__": [[48, 51], ["print", "time.time"], "methods", ["None"], ["", "def", "__enter__", "(", "self", ")", ":", "\n", "        ", "print", "(", "self", ".", "msg", ")", "\n", "self", ".", "tstart", "=", "time", ".", "time", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.logging.console.SimpleMessage.__exit__": [[52, 56], ["console.SimpleMessage.logger", "time.time"], "methods", ["None"], ["", "def", "__exit__", "(", "self", ",", "etype", ",", "*", "args", ")", ":", "\n", "        ", "maybe_exc", "=", "\"\"", "if", "etype", "is", "None", "else", "\" (with exception)\"", "\n", "self", ".", "logger", "(", "\"done%s in %.3f seconds\"", "%", "\n", "(", "maybe_exc", ",", "time", ".", "time", "(", ")", "-", "self", ".", "tstart", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.logging.console.Message.__init__": [[63, 65], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "msg", ")", ":", "\n", "        ", "self", ".", "msg", "=", "msg", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.logging.console.Message.__enter__": [[66, 71], ["print", "time.time", "console.colorize"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.logging.console.colorize"], ["", "def", "__enter__", "(", "self", ")", ":", "\n", "        ", "global", "MESSAGE_DEPTH", "# pylint: disable=W0603", "\n", "print", "(", "colorize", "(", "'\\t'", "*", "MESSAGE_DEPTH", "+", "'=: '", "+", "self", ".", "msg", ",", "'magenta'", ")", ")", "\n", "self", ".", "tstart", "=", "time", ".", "time", "(", ")", "\n", "MESSAGE_DEPTH", "+=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.logging.console.Message.__exit__": [[72, 77], ["print", "console.colorize", "time.time"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.logging.console.colorize"], ["", "def", "__exit__", "(", "self", ",", "etype", ",", "*", "args", ")", ":", "\n", "        ", "global", "MESSAGE_DEPTH", "# pylint: disable=W0603", "\n", "MESSAGE_DEPTH", "-=", "1", "\n", "maybe_exc", "=", "\"\"", "if", "etype", "is", "None", "else", "\" (with exception)\"", "\n", "print", "(", "colorize", "(", "'\\t'", "*", "MESSAGE_DEPTH", "+", "\"done%s in %.3f seconds\"", "%", "(", "maybe_exc", ",", "time", ".", "time", "(", ")", "-", "self", ".", "tstart", ")", ",", "'magenta'", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.logging.console.colorize": [[22, 31], ["attr.append", "str", "attr.append"], "function", ["None"], ["def", "colorize", "(", "string", ",", "color", ",", "bold", "=", "False", ",", "highlight", "=", "False", ")", ":", "\n", "    ", "attr", "=", "[", "]", "\n", "num", "=", "color2num", "[", "color", "]", "\n", "if", "highlight", ":", "\n", "        ", "num", "+=", "10", "\n", "", "attr", ".", "append", "(", "str", "(", "num", ")", ")", "\n", "if", "bold", ":", "\n", "        ", "attr", ".", "append", "(", "'1'", ")", "\n", "", "return", "'\\x1b[%sm%s\\x1b[0m'", "%", "(", "';'", ".", "join", "(", "attr", ")", ",", "string", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.logging.console.mkdir_p": [[33, 35], ["os.makedirs"], "function", ["None"], ["", "def", "mkdir_p", "(", "path", ")", ":", "\n", "    ", "os", ".", "makedirs", "(", "path", ",", "exist_ok", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.logging.console.log": [[37, 40], ["print", "sys.stdout.flush"], "function", ["None"], ["", "def", "log", "(", "s", ")", ":", "# , send_telegram=False):", "\n", "    ", "print", "(", "s", ")", "\n", "sys", ".", "stdout", ".", "flush", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.logging.console.prefix_log": [[79, 81], ["console.tee_log.logger"], "function", ["None"], ["", "", "def", "prefix_log", "(", "prefix", ",", "logger", "=", "log", ")", ":", "\n", "    ", "return", "lambda", "s", ":", "logger", "(", "prefix", "+", "s", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.logging.console.tee_log": [[83, 92], ["open", "console.log", "open.write", "open.write", "open.flush"], "function", ["home.repos.pwc.inspect_result.astooke_rlpyt.logging.console.log", "home.repos.pwc.inspect_result.astooke_rlpyt.envs.dmlab.LevelCache.write", "home.repos.pwc.inspect_result.astooke_rlpyt.envs.dmlab.LevelCache.write"], ["", "def", "tee_log", "(", "file_name", ")", ":", "\n", "    ", "f", "=", "open", "(", "file_name", ",", "'w+'", ")", "\n", "\n", "def", "logger", "(", "s", ")", ":", "\n", "        ", "log", "(", "s", ")", "\n", "f", ".", "write", "(", "s", ")", "\n", "f", ".", "write", "(", "'\\n'", ")", "\n", "f", ".", "flush", "(", ")", "\n", "", "return", "logger", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.logging.console.collect_args": [[94, 98], ["shlex.split", "zip"], "function", ["None"], ["", "def", "collect_args", "(", ")", ":", "\n", "    ", "splitted", "=", "shlex", ".", "split", "(", "' '", ".", "join", "(", "sys", ".", "argv", "[", "1", ":", "]", ")", ")", "\n", "return", "{", "arg_name", "[", "2", ":", "]", ":", "arg_val", "\n", "for", "arg_name", ",", "arg_val", "in", "zip", "(", "splitted", "[", ":", ":", "2", "]", ",", "splitted", "[", "1", ":", ":", "2", "]", ")", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.logging.console.type_hint": [[100, 108], ["getattr"], "function", ["None"], ["", "def", "type_hint", "(", "arg_name", ",", "arg_type", ")", ":", "\n", "    ", "def", "wrap", "(", "f", ")", ":", "\n", "        ", "meta", "=", "getattr", "(", "f", ",", "'__tweak_type_hint_meta__'", ",", "None", ")", "\n", "if", "meta", "is", "None", ":", "\n", "            ", "f", ".", "__tweak_type_hint_meta__", "=", "meta", "=", "{", "}", "\n", "", "meta", "[", "arg_name", "]", "=", "arg_type", "\n", "return", "f", "\n", "", "return", "wrap", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.logging.console.tweak": [[110, 114], ["isinstance", "console.tweakval", "console.tweakfun"], "function", ["home.repos.pwc.inspect_result.astooke_rlpyt.logging.console.tweakval", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.console.tweakfun"], ["", "def", "tweak", "(", "fun_or_val", ",", "identifier", "=", "None", ")", ":", "\n", "    ", "if", "isinstance", "(", "fun_or_val", ",", "collections", ".", "Callable", ")", ":", "\n", "        ", "return", "tweakfun", "(", "fun_or_val", ",", "identifier", ")", "\n", "", "return", "tweakval", "(", "fun_or_val", ",", "identifier", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.logging.console.tweakval": [[116, 126], ["console.collect_args", "collect_args.items", "ValueError", "k.replace", "console.log", "type", "str", "str"], "function", ["home.repos.pwc.inspect_result.astooke_rlpyt.logging.console.collect_args", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.collections.NamedArrayTuple.items", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.console.log"], ["", "def", "tweakval", "(", "val", ",", "identifier", ")", ":", "\n", "    ", "if", "not", "identifier", ":", "\n", "        ", "raise", "ValueError", "(", "'Must provide an identifier for tweakval to work'", ")", "\n", "", "args", "=", "collect_args", "(", ")", "\n", "for", "k", ",", "v", "in", "args", ".", "items", "(", ")", ":", "\n", "        ", "stripped", "=", "k", ".", "replace", "(", "'-'", ",", "'_'", ")", "\n", "if", "stripped", "==", "identifier", ":", "\n", "            ", "log", "(", "'replacing %s in %s with %s'", "%", "(", "stripped", ",", "str", "(", "val", ")", ",", "str", "(", "v", ")", ")", ")", "\n", "return", "type", "(", "val", ")", "(", "v", ")", "\n", "", "", "return", "val", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.logging.console.tweakfun": [[128, 186], ["getattr", "cmd_prefix.lower.lower", "console.collect_args", "dict", "collect_args.items", "pydoc.locate", "type", "inspect.getargspec", "inspect.getargspec", "list", "type", "getattr", "getattr", "k.startswith", "dict", "pydoc.locate.", "zip", "k[].replace", "console.log", "list", "ValueError", "list", "list", "replaced_kwargs.items", "ValueError", "zip", "kwargs.items", "len", "len", "str", "str", "ValueError", "console.log", "str", "type", "str", "str", "str", "str"], "function", ["home.repos.pwc.inspect_result.astooke_rlpyt.logging.console.collect_args", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.collections.NamedArrayTuple.items", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.console.log", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.collections.NamedArrayTuple.items", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.collections.NamedArrayTuple.items", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.console.log"], ["", "def", "tweakfun", "(", "fun", ",", "alt", "=", "None", ")", ":", "\n", "    ", "\"\"\"Make the arguments (or the function itself) tweakable from command line.\n    See tests/test_misc_console.py for examples.\n\n    NOTE: this only works for the initial launched process, since other processes\n    will get different argv. What this means is that tweak() calls wrapped in a function\n    to be invoked in a child process might not behave properly.\n    \"\"\"", "\n", "cls", "=", "getattr", "(", "fun", ",", "'im_class'", ",", "None", ")", "\n", "method_name", "=", "fun", ".", "__name__", "\n", "if", "alt", ":", "\n", "        ", "cmd_prefix", "=", "alt", "\n", "", "elif", "cls", ":", "\n", "        ", "cmd_prefix", "=", "cls", "+", "'.'", "+", "method_name", "\n", "", "else", ":", "\n", "        ", "cmd_prefix", "=", "method_name", "\n", "", "cmd_prefix", "=", "cmd_prefix", ".", "lower", "(", ")", "\n", "args", "=", "collect_args", "(", ")", "\n", "if", "cmd_prefix", "in", "args", ":", "\n", "        ", "fun", "=", "pydoc", ".", "locate", "(", "args", "[", "cmd_prefix", "]", ")", "\n", "", "if", "type", "(", "fun", ")", "==", "type", ":", "\n", "        ", "argspec", "=", "inspect", ".", "getargspec", "(", "fun", ".", "__init__", ")", "\n", "", "else", ":", "\n", "        ", "argspec", "=", "inspect", ".", "getargspec", "(", "fun", ")", "\n", "# TODO handle list arguments", "\n", "", "defaults", "=", "dict", "(", "\n", "list", "(", "zip", "(", "argspec", ".", "args", "[", "-", "len", "(", "argspec", ".", "defaults", "or", "[", "]", ")", ":", "]", ",", "argspec", ".", "defaults", "or", "[", "]", ")", ")", ")", "\n", "replaced_kwargs", "=", "{", "}", "\n", "cmd_prefix", "+=", "'-'", "\n", "if", "type", "(", "fun", ")", "==", "type", ":", "\n", "        ", "meta", "=", "getattr", "(", "fun", ".", "__init__", ",", "'__tweak_type_hint_meta__'", ",", "{", "}", ")", "\n", "", "else", ":", "\n", "        ", "meta", "=", "getattr", "(", "fun", ",", "'__tweak_type_hint_meta__'", ",", "{", "}", ")", "\n", "", "for", "k", ",", "v", "in", "args", ".", "items", "(", ")", ":", "\n", "        ", "if", "k", ".", "startswith", "(", "cmd_prefix", ")", ":", "\n", "            ", "stripped", "=", "k", "[", "len", "(", "cmd_prefix", ")", ":", "]", ".", "replace", "(", "'-'", ",", "'_'", ")", "\n", "if", "stripped", "in", "meta", ":", "\n", "                ", "log", "(", "'replacing %s in %s with %s'", "%", "(", "stripped", ",", "str", "(", "fun", ")", ",", "str", "(", "v", ")", ")", ")", "\n", "replaced_kwargs", "[", "stripped", "]", "=", "meta", "[", "stripped", "]", "(", "v", ")", "\n", "", "elif", "stripped", "not", "in", "argspec", ".", "args", ":", "\n", "                ", "raise", "ValueError", "(", "\n", "'%s is not an explicit parameter of %s'", "%", "(", "stripped", ",", "str", "(", "fun", ")", ")", ")", "\n", "", "elif", "stripped", "not", "in", "defaults", ":", "\n", "                ", "raise", "ValueError", "(", "\n", "'%s does not have a default value in method %s'", "%", "(", "stripped", ",", "str", "(", "fun", ")", ")", ")", "\n", "", "elif", "defaults", "[", "stripped", "]", "is", "None", ":", "\n", "                ", "raise", "ValueError", "(", "\n", "'Cannot infer type of %s in method %s from None value'", "%", "(", "stripped", ",", "str", "(", "fun", ")", ")", ")", "\n", "", "else", ":", "\n", "                ", "log", "(", "'replacing %s in %s with %s'", "%", "(", "stripped", ",", "str", "(", "fun", ")", ",", "str", "(", "v", ")", ")", ")", "\n", "# TODO more proper conversions", "\n", "replaced_kwargs", "[", "stripped", "]", "=", "type", "(", "defaults", "[", "stripped", "]", ")", "(", "v", ")", "\n", "\n", "", "", "", "def", "tweaked", "(", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "all_kw", "=", "dict", "(", "list", "(", "zip", "(", "argspec", "[", "0", "]", ",", "args", ")", ")", "+", "\n", "list", "(", "kwargs", ".", "items", "(", ")", ")", "+", "list", "(", "replaced_kwargs", ".", "items", "(", ")", ")", ")", "\n", "return", "fun", "(", "**", "all_kw", ")", "\n", "", "return", "tweaked", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.logging.console.query_yes_no": [[188, 218], ["sys.stdout.write", "input().lower", "ValueError", "input", "sys.stdout.write"], "function", ["home.repos.pwc.inspect_result.astooke_rlpyt.envs.dmlab.LevelCache.write", "home.repos.pwc.inspect_result.astooke_rlpyt.envs.dmlab.LevelCache.write"], ["", "def", "query_yes_no", "(", "question", ",", "default", "=", "\"yes\"", ")", ":", "\n", "    ", "\"\"\"Ask a yes/no question via raw_input() and return their answer.\n\n    \"question\" is a string that is presented to the user.\n    \"default\" is the presumed answer if the user just hits <Enter>.\n        It must be \"yes\" (the default), \"no\" or None (meaning\n        an answer is required of the user).\n\n    The \"answer\" return value is True for \"yes\" or False for \"no\".\n    \"\"\"", "\n", "valid", "=", "{", "\"yes\"", ":", "True", ",", "\"y\"", ":", "True", ",", "\"ye\"", ":", "True", ",", "\n", "\"no\"", ":", "False", ",", "\"n\"", ":", "False", "}", "\n", "if", "default", "is", "None", ":", "\n", "        ", "prompt", "=", "\" [y/n] \"", "\n", "", "elif", "default", "==", "\"yes\"", ":", "\n", "        ", "prompt", "=", "\" [Y/n] \"", "\n", "", "elif", "default", "==", "\"no\"", ":", "\n", "        ", "prompt", "=", "\" [y/N] \"", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "\"invalid default answer: '%s'\"", "%", "default", ")", "\n", "\n", "", "while", "True", ":", "\n", "        ", "sys", ".", "stdout", ".", "write", "(", "question", "+", "prompt", ")", "\n", "choice", "=", "input", "(", ")", ".", "lower", "(", ")", "\n", "if", "default", "is", "not", "None", "and", "choice", "==", "''", ":", "\n", "            ", "return", "valid", "[", "default", "]", "\n", "", "elif", "choice", "in", "valid", ":", "\n", "            ", "return", "valid", "[", "choice", "]", "\n", "", "else", ":", "\n", "            ", "sys", ".", "stdout", ".", "write", "(", "\"Please respond with 'yes' or 'no' \"", "\n", "\"(or 'y' or 'n').\\n\"", ")", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.train.mujoco_ddpg_serial.build_and_train": [[17, 43], ["rlpyt.utils.launching.affinity.affinity_from_code", "rlpyt.utils.launching.variant.load_variant", "rlpyt.utils.launching.variant.update_config", "rlpyt.samplers.serial.sampler.SerialSampler", "rlpyt.algos.qpg.ddpg.DDPG", "rlpyt.agents.qpg.ddpg_agent.DdpgAgent", "rlpyt.runners.minibatch_rl.MinibatchRlEval", "rlpyt.utils.logging.context.logger_context", "rlpyt.runners.minibatch_rl.MinibatchRlEval.train"], "function", ["home.repos.pwc.inspect_result.astooke_rlpyt.launching.affinity.affinity_from_code", "home.repos.pwc.inspect_result.astooke_rlpyt.launching.variant.load_variant", "home.repos.pwc.inspect_result.astooke_rlpyt.launching.variant.update_config", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.context.logger_context", "home.repos.pwc.inspect_result.astooke_rlpyt.runners.minibatch_rl.MinibatchRlEval.train"], ["def", "build_and_train", "(", "slot_affinity_code", ",", "log_dir", ",", "run_ID", ",", "config_key", ")", ":", "\n", "    ", "affinity", "=", "affinity_from_code", "(", "slot_affinity_code", ")", "\n", "config", "=", "configs", "[", "config_key", "]", "\n", "variant", "=", "load_variant", "(", "log_dir", ")", "\n", "config", "=", "update_config", "(", "config", ",", "variant", ")", "\n", "# config[\"eval_env\"] = config[\"env\"]", "\n", "\n", "sampler", "=", "SerialSampler", "(", "\n", "EnvCls", "=", "gym_make", ",", "\n", "env_kwargs", "=", "config", "[", "\"env\"", "]", ",", "\n", "CollectorCls", "=", "CpuResetCollector", ",", "\n", "eval_env_kwargs", "=", "config", "[", "\"env\"", "]", ",", "\n", "**", "config", "[", "\"sampler\"", "]", "\n", ")", "\n", "algo", "=", "DDPG", "(", "optim_kwargs", "=", "config", "[", "\"optim\"", "]", ",", "**", "config", "[", "\"algo\"", "]", ")", "\n", "agent", "=", "DdpgAgent", "(", "**", "config", "[", "\"agent\"", "]", ")", "\n", "runner", "=", "MinibatchRlEval", "(", "\n", "algo", "=", "algo", ",", "\n", "agent", "=", "agent", ",", "\n", "sampler", "=", "sampler", ",", "\n", "affinity", "=", "affinity", ",", "\n", "**", "config", "[", "\"runner\"", "]", "\n", ")", "\n", "name", "=", "\"ddpg_\"", "+", "config", "[", "\"env\"", "]", "[", "\"id\"", "]", "\n", "with", "logger_context", "(", "log_dir", ",", "run_ID", ",", "name", ",", "config", ")", ":", "\n", "        ", "runner", ".", "train", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.train.mujoco_sac_async_gpu.build_and_train": [[20, 45], ["rlpyt.utils.launching.affinity.affinity_from_code", "rlpyt.utils.launching.variant.load_variant", "rlpyt.utils.launching.variant.update_config", "rlpyt.samplers.async_.async_gpu_sampler.AsyncGpuSampler", "rlpyt.algos.qpg.sac.SAC", "rlpyt.agents.qpg.sac_agent.SacAgent", "rlpyt.runners.async_rl.AsyncRlEval", "rlpyt.utils.logging.context.logger_context", "rlpyt.runners.async_rl.AsyncRlEval.train"], "function", ["home.repos.pwc.inspect_result.astooke_rlpyt.launching.affinity.affinity_from_code", "home.repos.pwc.inspect_result.astooke_rlpyt.launching.variant.load_variant", "home.repos.pwc.inspect_result.astooke_rlpyt.launching.variant.update_config", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.context.logger_context", "home.repos.pwc.inspect_result.astooke_rlpyt.runners.minibatch_rl.MinibatchRlEval.train"], ["def", "build_and_train", "(", "slot_affinity_code", ",", "log_dir", ",", "run_ID", ",", "config_key", ")", ":", "\n", "    ", "affinity", "=", "affinity_from_code", "(", "slot_affinity_code", ")", "\n", "config", "=", "configs", "[", "config_key", "]", "\n", "variant", "=", "load_variant", "(", "log_dir", ")", "\n", "config", "=", "update_config", "(", "config", ",", "variant", ")", "\n", "\n", "sampler", "=", "AsyncGpuSampler", "(", "\n", "EnvCls", "=", "gym_make", ",", "\n", "env_kwargs", "=", "config", "[", "\"env\"", "]", ",", "\n", "CollectorCls", "=", "DbGpuResetCollector", ",", "\n", "eval_env_kwargs", "=", "config", "[", "\"env\"", "]", ",", "\n", "**", "config", "[", "\"sampler\"", "]", "\n", ")", "\n", "algo", "=", "SAC", "(", "optim_kwargs", "=", "config", "[", "\"optim\"", "]", ",", "**", "config", "[", "\"algo\"", "]", ")", "\n", "agent", "=", "SacAgent", "(", "**", "config", "[", "\"agent\"", "]", ")", "\n", "runner", "=", "AsyncRlEval", "(", "\n", "algo", "=", "algo", ",", "\n", "agent", "=", "agent", ",", "\n", "sampler", "=", "sampler", ",", "\n", "affinity", "=", "affinity", ",", "\n", "**", "config", "[", "\"runner\"", "]", "\n", ")", "\n", "name", "=", "\"sac_async_gpu_\"", "+", "config", "[", "\"env\"", "]", "[", "\"id\"", "]", "\n", "with", "logger_context", "(", "log_dir", ",", "run_ID", ",", "name", ",", "config", ")", ":", "\n", "        ", "runner", ".", "train", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.train.mujoco_ddpg_cpu.build_and_train": [[17, 41], ["rlpyt.utils.launching.affinity.affinity_from_code", "rlpyt.utils.launching.variant.load_variant", "rlpyt.utils.launching.variant.update_config", "rlpyt.samplers.cpu.parallel_sampler.CpuParallelSampler", "rlpyt.algos.qpg.ddpg.DDPG", "rlpyt.agents.qpg.ddpg_agent.DdpgAgent", "rlpyt.runners.minibatch_rl.MinibatchRl", "rlpyt.utils.logging.context.logger_context", "rlpyt.runners.minibatch_rl.MinibatchRl.train"], "function", ["home.repos.pwc.inspect_result.astooke_rlpyt.launching.affinity.affinity_from_code", "home.repos.pwc.inspect_result.astooke_rlpyt.launching.variant.load_variant", "home.repos.pwc.inspect_result.astooke_rlpyt.launching.variant.update_config", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.context.logger_context", "home.repos.pwc.inspect_result.astooke_rlpyt.runners.minibatch_rl.MinibatchRlEval.train"], ["def", "build_and_train", "(", "slot_affinity_code", ",", "log_dir", ",", "run_ID", ",", "config_key", ")", ":", "\n", "    ", "affinity", "=", "affinity_from_code", "(", "slot_affinity_code", ")", "\n", "config", "=", "configs", "[", "config_key", "]", "\n", "variant", "=", "load_variant", "(", "log_dir", ")", "\n", "config", "=", "update_config", "(", "config", ",", "variant", ")", "\n", "\n", "sampler", "=", "CpuParallelSampler", "(", "\n", "EnvCls", "=", "gym_make", ",", "\n", "env_kwargs", "=", "config", "[", "\"env\"", "]", ",", "\n", "CollectorCls", "=", "ResetCollector", ",", "\n", "**", "config", "[", "\"sampler\"", "]", "\n", ")", "\n", "algo", "=", "DDPG", "(", "optim_kwargs", "=", "config", "[", "\"optim\"", "]", ",", "**", "config", "[", "\"algo\"", "]", ")", "\n", "agent", "=", "DdpgAgent", "(", "**", "config", "[", "\"agent\"", "]", ")", "\n", "runner", "=", "MinibatchRl", "(", "\n", "algo", "=", "algo", ",", "\n", "agent", "=", "agent", ",", "\n", "sampler", "=", "sampler", ",", "\n", "affinity", "=", "affinity", ",", "\n", "**", "config", "[", "\"runner\"", "]", "\n", ")", "\n", "name", "=", "config", "[", "\"env\"", "]", "[", "\"id\"", "]", "\n", "with", "logger_context", "(", "log_dir", ",", "run_ID", ",", "name", ",", "config", ")", ":", "\n", "        ", "runner", ".", "train", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.train.mujoco_td3_async_cpu.build_and_train": [[20, 45], ["rlpyt.utils.launching.affinity.affinity_from_code", "rlpyt.utils.launching.variant.load_variant", "rlpyt.utils.launching.variant.update_config", "rlpyt.samplers.async_.async_cpu_sampler.AsyncCpuSampler", "rlpyt.algos.qpg.td3.TD3", "rlpyt.agents.qpg.td3_agent.Td3Agent", "rlpyt.runners.async_rl.AsyncRlEval", "rlpyt.utils.logging.context.logger_context", "rlpyt.runners.async_rl.AsyncRlEval.train"], "function", ["home.repos.pwc.inspect_result.astooke_rlpyt.launching.affinity.affinity_from_code", "home.repos.pwc.inspect_result.astooke_rlpyt.launching.variant.load_variant", "home.repos.pwc.inspect_result.astooke_rlpyt.launching.variant.update_config", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.context.logger_context", "home.repos.pwc.inspect_result.astooke_rlpyt.runners.minibatch_rl.MinibatchRlEval.train"], ["def", "build_and_train", "(", "slot_affinity_code", ",", "log_dir", ",", "run_ID", ",", "config_key", ")", ":", "\n", "    ", "affinity", "=", "affinity_from_code", "(", "slot_affinity_code", ")", "\n", "config", "=", "configs", "[", "config_key", "]", "\n", "variant", "=", "load_variant", "(", "log_dir", ")", "\n", "config", "=", "update_config", "(", "config", ",", "variant", ")", "\n", "\n", "sampler", "=", "AsyncCpuSampler", "(", "\n", "EnvCls", "=", "gym_make", ",", "\n", "env_kwargs", "=", "config", "[", "\"env\"", "]", ",", "\n", "CollectorCls", "=", "DbCpuResetCollector", ",", "\n", "eval_env_kwargs", "=", "config", "[", "\"env\"", "]", ",", "\n", "**", "config", "[", "\"sampler\"", "]", "\n", ")", "\n", "algo", "=", "TD3", "(", "optim_kwargs", "=", "config", "[", "\"optim\"", "]", ",", "**", "config", "[", "\"algo\"", "]", ")", "\n", "agent", "=", "Td3Agent", "(", "**", "config", "[", "\"agent\"", "]", ")", "\n", "runner", "=", "AsyncRlEval", "(", "\n", "algo", "=", "algo", ",", "\n", "agent", "=", "agent", ",", "\n", "sampler", "=", "sampler", ",", "\n", "affinity", "=", "affinity", ",", "\n", "**", "config", "[", "\"runner\"", "]", "\n", ")", "\n", "name", "=", "\"async_td3_\"", "+", "config", "[", "\"env\"", "]", "[", "\"id\"", "]", "\n", "with", "logger_context", "(", "log_dir", ",", "run_ID", ",", "name", ",", "config", ")", ":", "\n", "        ", "runner", ".", "train", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.train.mujoco_sac_serial.build_and_train": [[17, 43], ["rlpyt.utils.launching.affinity.affinity_from_code", "rlpyt.utils.launching.variant.load_variant", "rlpyt.utils.launching.variant.update_config", "rlpyt.samplers.serial.sampler.SerialSampler", "rlpyt.algos.qpg.sac.SAC", "rlpyt.agents.qpg.sac_agent.SacAgent", "rlpyt.runners.minibatch_rl.MinibatchRlEval", "rlpyt.utils.logging.context.logger_context", "rlpyt.runners.minibatch_rl.MinibatchRlEval.train"], "function", ["home.repos.pwc.inspect_result.astooke_rlpyt.launching.affinity.affinity_from_code", "home.repos.pwc.inspect_result.astooke_rlpyt.launching.variant.load_variant", "home.repos.pwc.inspect_result.astooke_rlpyt.launching.variant.update_config", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.context.logger_context", "home.repos.pwc.inspect_result.astooke_rlpyt.runners.minibatch_rl.MinibatchRlEval.train"], ["def", "build_and_train", "(", "slot_affinity_code", ",", "log_dir", ",", "run_ID", ",", "config_key", ")", ":", "\n", "    ", "affinity", "=", "affinity_from_code", "(", "slot_affinity_code", ")", "\n", "config", "=", "configs", "[", "config_key", "]", "\n", "variant", "=", "load_variant", "(", "log_dir", ")", "\n", "config", "=", "update_config", "(", "config", ",", "variant", ")", "\n", "# config[\"eval_env\"][\"id\"] = config[\"env\"][\"id\"]", "\n", "\n", "sampler", "=", "SerialSampler", "(", "\n", "EnvCls", "=", "gym_make", ",", "\n", "env_kwargs", "=", "config", "[", "\"env\"", "]", ",", "\n", "CollectorCls", "=", "CpuResetCollector", ",", "\n", "eval_env_kwargs", "=", "config", "[", "\"env\"", "]", ",", "\n", "**", "config", "[", "\"sampler\"", "]", "\n", ")", "\n", "algo", "=", "SAC", "(", "optim_kwargs", "=", "config", "[", "\"optim\"", "]", ",", "**", "config", "[", "\"algo\"", "]", ")", "\n", "agent", "=", "SacAgent", "(", "**", "config", "[", "\"agent\"", "]", ")", "\n", "runner", "=", "MinibatchRlEval", "(", "\n", "algo", "=", "algo", ",", "\n", "agent", "=", "agent", ",", "\n", "sampler", "=", "sampler", ",", "\n", "affinity", "=", "affinity", ",", "\n", "**", "config", "[", "\"runner\"", "]", "\n", ")", "\n", "name", "=", "\"sac_\"", "+", "config", "[", "\"env\"", "]", "[", "\"id\"", "]", "\n", "with", "logger_context", "(", "log_dir", ",", "run_ID", ",", "name", ",", "config", ")", ":", "\n", "        ", "runner", ".", "train", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.train.mujoco_ddpg_async_serial.build_and_train": [[20, 45], ["rlpyt.utils.launching.affinity.affinity_from_code", "rlpyt.utils.launching.variant.load_variant", "rlpyt.utils.launching.variant.update_config", "rlpyt.samplers.async_.serial_sampler.AsyncSerialSampler", "rlpyt.algos.qpg.ddpg.DDPG", "rlpyt.agents.qpg.ddpg_agent.DdpgAgent", "rlpyt.runners.async_rl.AsyncRlEval", "rlpyt.utils.logging.context.logger_context", "rlpyt.runners.async_rl.AsyncRlEval.train"], "function", ["home.repos.pwc.inspect_result.astooke_rlpyt.launching.affinity.affinity_from_code", "home.repos.pwc.inspect_result.astooke_rlpyt.launching.variant.load_variant", "home.repos.pwc.inspect_result.astooke_rlpyt.launching.variant.update_config", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.context.logger_context", "home.repos.pwc.inspect_result.astooke_rlpyt.runners.minibatch_rl.MinibatchRlEval.train"], ["def", "build_and_train", "(", "slot_affinity_code", ",", "log_dir", ",", "run_ID", ",", "config_key", ")", ":", "\n", "    ", "affinity", "=", "affinity_from_code", "(", "slot_affinity_code", ")", "\n", "config", "=", "configs", "[", "config_key", "]", "\n", "variant", "=", "load_variant", "(", "log_dir", ")", "\n", "config", "=", "update_config", "(", "config", ",", "variant", ")", "\n", "\n", "sampler", "=", "AsyncSerialSampler", "(", "\n", "EnvCls", "=", "gym_make", ",", "\n", "env_kwargs", "=", "config", "[", "\"env\"", "]", ",", "\n", "eval_env_kwargs", "=", "config", "[", "\"env\"", "]", ",", "\n", "CollectorCls", "=", "DbCpuResetCollector", ",", "\n", "**", "config", "[", "\"sampler\"", "]", "\n", ")", "\n", "algo", "=", "DDPG", "(", "optim_kwargs", "=", "config", "[", "\"optim\"", "]", ",", "**", "config", "[", "\"algo\"", "]", ")", "\n", "agent", "=", "DdpgAgent", "(", "**", "config", "[", "\"agent\"", "]", ")", "\n", "runner", "=", "AsyncRlEval", "(", "\n", "algo", "=", "algo", ",", "\n", "agent", "=", "agent", ",", "\n", "sampler", "=", "sampler", ",", "\n", "affinity", "=", "affinity", ",", "\n", "**", "config", "[", "\"runner\"", "]", "\n", ")", "\n", "name", "=", "\"async_ddpg_\"", "+", "config", "[", "\"env\"", "]", "[", "\"id\"", "]", "\n", "with", "logger_context", "(", "log_dir", ",", "run_ID", ",", "name", ",", "config", ")", ":", "\n", "        ", "runner", ".", "train", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.train.mujoco_td3_serial.build_and_train": [[17, 43], ["rlpyt.utils.launching.affinity.affinity_from_code", "rlpyt.utils.launching.variant.load_variant", "rlpyt.utils.launching.variant.update_config", "rlpyt.samplers.serial.sampler.SerialSampler", "rlpyt.algos.qpg.td3.TD3", "rlpyt.agents.qpg.td3_agent.Td3Agent", "rlpyt.runners.minibatch_rl.MinibatchRlEval", "rlpyt.utils.logging.context.logger_context", "rlpyt.runners.minibatch_rl.MinibatchRlEval.train"], "function", ["home.repos.pwc.inspect_result.astooke_rlpyt.launching.affinity.affinity_from_code", "home.repos.pwc.inspect_result.astooke_rlpyt.launching.variant.load_variant", "home.repos.pwc.inspect_result.astooke_rlpyt.launching.variant.update_config", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.context.logger_context", "home.repos.pwc.inspect_result.astooke_rlpyt.runners.minibatch_rl.MinibatchRlEval.train"], ["def", "build_and_train", "(", "slot_affinity_code", ",", "log_dir", ",", "run_ID", ",", "config_key", ")", ":", "\n", "    ", "affinity", "=", "affinity_from_code", "(", "slot_affinity_code", ")", "\n", "config", "=", "configs", "[", "config_key", "]", "\n", "variant", "=", "load_variant", "(", "log_dir", ")", "\n", "config", "=", "update_config", "(", "config", ",", "variant", ")", "\n", "# config[\"eval_env\"][\"id\"] = config[\"env\"][\"id\"]", "\n", "\n", "sampler", "=", "SerialSampler", "(", "\n", "EnvCls", "=", "gym_make", ",", "\n", "env_kwargs", "=", "config", "[", "\"env\"", "]", ",", "\n", "CollectorCls", "=", "CpuResetCollector", ",", "\n", "eval_env_kwargs", "=", "config", "[", "\"env\"", "]", ",", "\n", "**", "config", "[", "\"sampler\"", "]", "\n", ")", "\n", "algo", "=", "TD3", "(", "optim_kwargs", "=", "config", "[", "\"optim\"", "]", ",", "**", "config", "[", "\"algo\"", "]", ")", "\n", "agent", "=", "Td3Agent", "(", "**", "config", "[", "\"agent\"", "]", ")", "\n", "runner", "=", "MinibatchRlEval", "(", "\n", "algo", "=", "algo", ",", "\n", "agent", "=", "agent", ",", "\n", "sampler", "=", "sampler", ",", "\n", "affinity", "=", "affinity", ",", "\n", "**", "config", "[", "\"runner\"", "]", "\n", ")", "\n", "name", "=", "\"td3_\"", "+", "config", "[", "\"env\"", "]", "[", "\"id\"", "]", "\n", "with", "logger_context", "(", "log_dir", ",", "run_ID", ",", "name", ",", "config", ")", ":", "\n", "        ", "runner", ".", "train", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.train.mujoco_ff_ppo_serial.build_and_train": [[17, 41], ["rlpyt.utils.launching.affinity.affinity_from_code", "rlpyt.utils.launching.variant.load_variant", "rlpyt.utils.launching.variant.update_config", "rlpyt.samplers.serial.sampler.SerialSampler", "rlpyt.algos.pg.ppo.PPO", "rlpyt.agents.pg.mujoco.MujocoFfAgent", "rlpyt.runners.minibatch_rl.MinibatchRl", "rlpyt.utils.logging.context.logger_context", "rlpyt.runners.minibatch_rl.MinibatchRl.train"], "function", ["home.repos.pwc.inspect_result.astooke_rlpyt.launching.affinity.affinity_from_code", "home.repos.pwc.inspect_result.astooke_rlpyt.launching.variant.load_variant", "home.repos.pwc.inspect_result.astooke_rlpyt.launching.variant.update_config", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.context.logger_context", "home.repos.pwc.inspect_result.astooke_rlpyt.runners.minibatch_rl.MinibatchRlEval.train"], ["def", "build_and_train", "(", "slot_affinity_code", ",", "log_dir", ",", "run_ID", ",", "config_key", ")", ":", "\n", "    ", "affinity", "=", "affinity_from_code", "(", "slot_affinity_code", ")", "\n", "config", "=", "configs", "[", "config_key", "]", "\n", "variant", "=", "load_variant", "(", "log_dir", ")", "\n", "config", "=", "update_config", "(", "config", ",", "variant", ")", "\n", "\n", "sampler", "=", "SerialSampler", "(", "\n", "EnvCls", "=", "gym_make", ",", "\n", "env_kwargs", "=", "config", "[", "\"env\"", "]", ",", "\n", "CollectorCls", "=", "CpuResetCollector", ",", "\n", "**", "config", "[", "\"sampler\"", "]", "\n", ")", "\n", "algo", "=", "PPO", "(", "optim_kwargs", "=", "config", "[", "\"optim\"", "]", ",", "**", "config", "[", "\"algo\"", "]", ")", "\n", "agent", "=", "MujocoFfAgent", "(", "model_kwargs", "=", "config", "[", "\"model\"", "]", ",", "**", "config", "[", "\"agent\"", "]", ")", "\n", "runner", "=", "MinibatchRl", "(", "\n", "algo", "=", "algo", ",", "\n", "agent", "=", "agent", ",", "\n", "sampler", "=", "sampler", ",", "\n", "affinity", "=", "affinity", ",", "\n", "**", "config", "[", "\"runner\"", "]", "\n", ")", "\n", "name", "=", "\"ppo_\"", "+", "config", "[", "\"env\"", "]", "[", "\"id\"", "]", "\n", "with", "logger_context", "(", "log_dir", ",", "run_ID", ",", "name", ",", "config", ")", ":", "\n", "        ", "runner", ".", "train", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.train.mujoco_ff_ppo_cpu.build_and_train": [[17, 41], ["rlpyt.utils.launching.affinity.affinity_from_code", "rlpyt.utils.launching.variant.load_variant", "rlpyt.utils.launching.variant.update_config", "rlpyt.samplers.parallel.cpu.sampler.CpuSampler", "rlpyt.algos.pg.ppo.PPO", "rlpyt.agents.pg.mujoco.MujocoFfAgent", "rlpyt.runners.minibatch_rl.MinibatchRl", "rlpyt.utils.logging.context.logger_context", "rlpyt.runners.minibatch_rl.MinibatchRl.train"], "function", ["home.repos.pwc.inspect_result.astooke_rlpyt.launching.affinity.affinity_from_code", "home.repos.pwc.inspect_result.astooke_rlpyt.launching.variant.load_variant", "home.repos.pwc.inspect_result.astooke_rlpyt.launching.variant.update_config", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.context.logger_context", "home.repos.pwc.inspect_result.astooke_rlpyt.runners.minibatch_rl.MinibatchRlEval.train"], ["def", "build_and_train", "(", "slot_affinity_code", ",", "log_dir", ",", "run_ID", ",", "config_key", ")", ":", "\n", "    ", "affinity", "=", "affinity_from_code", "(", "slot_affinity_code", ")", "\n", "config", "=", "configs", "[", "config_key", "]", "\n", "variant", "=", "load_variant", "(", "log_dir", ")", "\n", "config", "=", "update_config", "(", "config", ",", "variant", ")", "\n", "\n", "sampler", "=", "CpuSampler", "(", "\n", "EnvCls", "=", "gym_make", ",", "\n", "env_kwargs", "=", "config", "[", "\"env\"", "]", ",", "\n", "CollectorCls", "=", "CpuResetCollector", ",", "\n", "**", "config", "[", "\"sampler\"", "]", "\n", ")", "\n", "algo", "=", "PPO", "(", "optim_kwargs", "=", "config", "[", "\"optim\"", "]", ",", "**", "config", "[", "\"algo\"", "]", ")", "\n", "agent", "=", "MujocoFfAgent", "(", "model_kwargs", "=", "config", "[", "\"model\"", "]", ",", "**", "config", "[", "\"agent\"", "]", ")", "\n", "runner", "=", "MinibatchRl", "(", "\n", "algo", "=", "algo", ",", "\n", "agent", "=", "agent", ",", "\n", "sampler", "=", "sampler", ",", "\n", "affinity", "=", "affinity", ",", "\n", "**", "config", "[", "\"runner\"", "]", "\n", ")", "\n", "name", "=", "config", "[", "\"env\"", "]", "[", "\"id\"", "]", "\n", "with", "logger_context", "(", "log_dir", ",", "run_ID", ",", "name", ",", "config", ")", ":", "\n", "        ", "runner", ".", "train", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.train.mujoco_ff_ppo_gpu.build_and_train": [[17, 41], ["rlpyt.utils.launching.affinity.affinity_from_code", "rlpyt.utils.launching.variant.load_variant", "rlpyt.utils.launching.variant.update_config", "rlpyt.samplers.gpu.parallel_sampler.GpuSampler", "rlpyt.algos.pg.ppo.PPO", "rlpyt.agents.pg.mujoco.MujocoFfAgent", "rlpyt.runners.minibatch_rl.MinibatchRl", "rlpyt.utils.logging.context.logger_context", "rlpyt.runners.minibatch_rl.MinibatchRl.train"], "function", ["home.repos.pwc.inspect_result.astooke_rlpyt.launching.affinity.affinity_from_code", "home.repos.pwc.inspect_result.astooke_rlpyt.launching.variant.load_variant", "home.repos.pwc.inspect_result.astooke_rlpyt.launching.variant.update_config", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.context.logger_context", "home.repos.pwc.inspect_result.astooke_rlpyt.runners.minibatch_rl.MinibatchRlEval.train"], ["def", "build_and_train", "(", "slot_affinity_code", ",", "log_dir", ",", "run_ID", ",", "config_key", ")", ":", "\n", "    ", "affinity", "=", "affinity_from_code", "(", "slot_affinity_code", ")", "\n", "config", "=", "configs", "[", "config_key", "]", "\n", "variant", "=", "load_variant", "(", "log_dir", ")", "\n", "config", "=", "update_config", "(", "config", ",", "variant", ")", "\n", "\n", "sampler", "=", "GpuSampler", "(", "\n", "EnvCls", "=", "gym_make", ",", "\n", "env_kwargs", "=", "config", "[", "\"env\"", "]", ",", "\n", "CollectorCls", "=", "ResetCollector", ",", "\n", "**", "config", "[", "\"sampler\"", "]", "\n", ")", "\n", "algo", "=", "PPO", "(", "optim_kwargs", "=", "config", "[", "\"optim\"", "]", ",", "**", "config", "[", "\"algo\"", "]", ")", "\n", "agent", "=", "MujocoFfAgent", "(", "model_kwargs", "=", "config", "[", "\"model\"", "]", ",", "**", "config", "[", "\"agent\"", "]", ")", "\n", "runner", "=", "MinibatchRl", "(", "\n", "algo", "=", "algo", ",", "\n", "agent", "=", "agent", ",", "\n", "sampler", "=", "sampler", ",", "\n", "affinity", "=", "affinity", ",", "\n", "**", "config", "[", "\"runner\"", "]", "\n", ")", "\n", "name", "=", "config", "[", "\"env\"", "]", "[", "\"id\"", "]", "\n", "with", "logger_context", "(", "log_dir", ",", "run_ID", ",", "name", ",", "config", ")", ":", "\n", "        ", "runner", ".", "train", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.train.mujoco_ff_a2c_cpu.build_and_train": [[17, 41], ["rlpyt.utils.launching.affinity.affinity_from_code", "rlpyt.utils.launching.variant.load_variant", "rlpyt.utils.launching.variant.update_config", "rlpyt.samplers.parallel.cpu.sampler.CpuSampler", "rlpyt.algos.pg.a2c.A2C", "rlpyt.agents.pg.mujoco.MujocoFfAgent", "rlpyt.runners.minibatch_rl.MinibatchRl", "rlpyt.utils.logging.context.logger_context", "rlpyt.runners.minibatch_rl.MinibatchRl.train"], "function", ["home.repos.pwc.inspect_result.astooke_rlpyt.launching.affinity.affinity_from_code", "home.repos.pwc.inspect_result.astooke_rlpyt.launching.variant.load_variant", "home.repos.pwc.inspect_result.astooke_rlpyt.launching.variant.update_config", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.context.logger_context", "home.repos.pwc.inspect_result.astooke_rlpyt.runners.minibatch_rl.MinibatchRlEval.train"], ["def", "build_and_train", "(", "slot_affinity_code", ",", "log_dir", ",", "run_ID", ",", "config_key", ")", ":", "\n", "    ", "affinity", "=", "affinity_from_code", "(", "slot_affinity_code", ")", "\n", "config", "=", "configs", "[", "config_key", "]", "\n", "variant", "=", "load_variant", "(", "log_dir", ")", "\n", "config", "=", "update_config", "(", "config", ",", "variant", ")", "\n", "\n", "sampler", "=", "CpuSampler", "(", "\n", "EnvCls", "=", "gym_make", ",", "\n", "env_kwargs", "=", "config", "[", "\"env\"", "]", ",", "\n", "CollectorCls", "=", "CpuResetCollector", ",", "\n", "**", "config", "[", "\"sampler\"", "]", "\n", ")", "\n", "algo", "=", "A2C", "(", "optim_kwargs", "=", "config", "[", "\"optim\"", "]", ",", "**", "config", "[", "\"algo\"", "]", ")", "\n", "agent", "=", "MujocoFfAgent", "(", "model_kwargs", "=", "config", "[", "\"model\"", "]", ",", "**", "config", "[", "\"agent\"", "]", ")", "\n", "runner", "=", "MinibatchRl", "(", "\n", "algo", "=", "algo", ",", "\n", "agent", "=", "agent", ",", "\n", "sampler", "=", "sampler", ",", "\n", "affinity", "=", "affinity", ",", "\n", "**", "config", "[", "\"runner\"", "]", "\n", ")", "\n", "name", "=", "config", "[", "\"env\"", "]", "[", "\"id\"", "]", "\n", "with", "logger_context", "(", "log_dir", ",", "run_ID", ",", "name", ",", "config", ")", ":", "\n", "        ", "runner", ".", "train", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.train.atari_ff_ppo_gpu.build_and_train": [[17, 42], ["rlpyt.utils.launching.affinity.affinity_from_code", "rlpyt.utils.launching.variant.load_variant", "rlpyt.utils.launching.variant.update_config", "rlpyt.samplers.parallel.gpu.sampler.GpuSampler", "rlpyt.algos.pg.ppo.PPO", "rlpyt.agents.pg.atari.AtariFfAgent", "rlpyt.runners.minibatch_rl.MinibatchRl", "rlpyt.utils.logging.context.logger_context", "rlpyt.runners.minibatch_rl.MinibatchRl.train"], "function", ["home.repos.pwc.inspect_result.astooke_rlpyt.launching.affinity.affinity_from_code", "home.repos.pwc.inspect_result.astooke_rlpyt.launching.variant.load_variant", "home.repos.pwc.inspect_result.astooke_rlpyt.launching.variant.update_config", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.context.logger_context", "home.repos.pwc.inspect_result.astooke_rlpyt.runners.minibatch_rl.MinibatchRlEval.train"], ["def", "build_and_train", "(", "slot_affinity_code", ",", "log_dir", ",", "run_ID", ",", "config_key", ")", ":", "\n", "    ", "affinity", "=", "affinity_from_code", "(", "slot_affinity_code", ")", "\n", "config", "=", "configs", "[", "config_key", "]", "\n", "variant", "=", "load_variant", "(", "log_dir", ")", "\n", "config", "=", "update_config", "(", "config", ",", "variant", ")", "\n", "\n", "sampler", "=", "GpuSampler", "(", "\n", "EnvCls", "=", "AtariEnv", ",", "\n", "env_kwargs", "=", "config", "[", "\"env\"", "]", ",", "\n", "CollectorCls", "=", "GpuWaitResetCollector", ",", "\n", "TrajInfoCls", "=", "AtariTrajInfo", ",", "\n", "**", "config", "[", "\"sampler\"", "]", "\n", ")", "\n", "algo", "=", "PPO", "(", "optim_kwargs", "=", "config", "[", "\"optim\"", "]", ",", "**", "config", "[", "\"algo\"", "]", ")", "\n", "agent", "=", "AtariFfAgent", "(", "model_kwargs", "=", "config", "[", "\"model\"", "]", ",", "**", "config", "[", "\"agent\"", "]", ")", "\n", "runner", "=", "MinibatchRl", "(", "\n", "algo", "=", "algo", ",", "\n", "agent", "=", "agent", ",", "\n", "sampler", "=", "sampler", ",", "\n", "affinity", "=", "affinity", ",", "\n", "**", "config", "[", "\"runner\"", "]", "\n", ")", "\n", "name", "=", "config", "[", "\"env\"", "]", "[", "\"game\"", "]", "\n", "with", "logger_context", "(", "log_dir", ",", "run_ID", ",", "name", ",", "config", ")", ":", "\n", "        ", "runner", ".", "train", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.train.atari_ff_a2c_gpu_multi.build_and_train": [[17, 43], ["rlpyt.utils.launching.affinity.affinity_from_code", "isinstance", "rlpyt.utils.launching.variant.load_variant", "rlpyt.utils.launching.variant.update_config", "rlpyt.samplers.parallel.gpu.sampler.GpuSampler", "rlpyt.algos.pg.a2c.A2C", "rlpyt.agents.pg.atari.AtariFfAgent", "rlpyt.runners.sync_rl.SyncRl", "rlpyt.utils.logging.context.logger_context", "rlpyt.runners.sync_rl.SyncRl.train"], "function", ["home.repos.pwc.inspect_result.astooke_rlpyt.launching.affinity.affinity_from_code", "home.repos.pwc.inspect_result.astooke_rlpyt.launching.variant.load_variant", "home.repos.pwc.inspect_result.astooke_rlpyt.launching.variant.update_config", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.context.logger_context", "home.repos.pwc.inspect_result.astooke_rlpyt.runners.minibatch_rl.MinibatchRlEval.train"], ["def", "build_and_train", "(", "slot_affinity_code", ",", "log_dir", ",", "run_ID", ",", "config_key", ")", ":", "\n", "    ", "affinity", "=", "affinity_from_code", "(", "slot_affinity_code", ")", "\n", "assert", "isinstance", "(", "affinity", ",", "list", ")", "# One for each GPU.", "\n", "config", "=", "configs", "[", "config_key", "]", "\n", "variant", "=", "load_variant", "(", "log_dir", ")", "\n", "config", "=", "update_config", "(", "config", ",", "variant", ")", "\n", "\n", "sampler", "=", "GpuSampler", "(", "\n", "EnvCls", "=", "AtariEnv", ",", "\n", "env_kwargs", "=", "config", "[", "\"env\"", "]", ",", "\n", "CollectorCls", "=", "GpuWaitResetCollector", ",", "\n", "TrajInfoCls", "=", "AtariTrajInfo", ",", "\n", "**", "config", "[", "\"sampler\"", "]", "\n", ")", "\n", "algo", "=", "A2C", "(", "optim_kwargs", "=", "config", "[", "\"optim\"", "]", ",", "**", "config", "[", "\"algo\"", "]", ")", "\n", "agent", "=", "AtariFfAgent", "(", "model_kwargs", "=", "config", "[", "\"model\"", "]", ",", "**", "config", "[", "\"agent\"", "]", ")", "\n", "runner", "=", "SyncRl", "(", "\n", "algo", "=", "algo", ",", "\n", "agent", "=", "agent", ",", "\n", "sampler", "=", "sampler", ",", "\n", "affinity", "=", "affinity", ",", "\n", "**", "config", "[", "\"runner\"", "]", "\n", ")", "\n", "name", "=", "config", "[", "\"env\"", "]", "[", "\"game\"", "]", "\n", "with", "logger_context", "(", "log_dir", ",", "run_ID", ",", "name", ",", "config", ")", ":", "\n", "        ", "runner", ".", "train", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.train.atari_ff_a2c_gpu.build_and_train": [[17, 42], ["rlpyt.utils.launching.affinity.affinity_from_code", "rlpyt.utils.launching.variant.load_variant", "rlpyt.utils.launching.variant.update_config", "rlpyt.samplers.parallel.gpu.sampler.GpuSampler", "rlpyt.algos.pg.a2c.A2C", "rlpyt.agents.pg.atari.AtariFfAgent", "rlpyt.runners.minibatch_rl.MinibatchRl", "rlpyt.utils.logging.context.logger_context", "rlpyt.runners.minibatch_rl.MinibatchRl.train"], "function", ["home.repos.pwc.inspect_result.astooke_rlpyt.launching.affinity.affinity_from_code", "home.repos.pwc.inspect_result.astooke_rlpyt.launching.variant.load_variant", "home.repos.pwc.inspect_result.astooke_rlpyt.launching.variant.update_config", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.context.logger_context", "home.repos.pwc.inspect_result.astooke_rlpyt.runners.minibatch_rl.MinibatchRlEval.train"], ["def", "build_and_train", "(", "slot_affinity_code", ",", "log_dir", ",", "run_ID", ",", "config_key", ")", ":", "\n", "    ", "affinity", "=", "affinity_from_code", "(", "slot_affinity_code", ")", "\n", "config", "=", "configs", "[", "config_key", "]", "\n", "variant", "=", "load_variant", "(", "log_dir", ")", "\n", "config", "=", "update_config", "(", "config", ",", "variant", ")", "\n", "\n", "sampler", "=", "GpuSampler", "(", "\n", "EnvCls", "=", "AtariEnv", ",", "\n", "env_kwargs", "=", "config", "[", "\"env\"", "]", ",", "\n", "CollectorCls", "=", "GpuWaitResetCollector", ",", "\n", "TrajInfoCls", "=", "AtariTrajInfo", ",", "\n", "**", "config", "[", "\"sampler\"", "]", "\n", ")", "\n", "algo", "=", "A2C", "(", "optim_kwargs", "=", "config", "[", "\"optim\"", "]", ",", "**", "config", "[", "\"algo\"", "]", ")", "\n", "agent", "=", "AtariFfAgent", "(", "model_kwargs", "=", "config", "[", "\"model\"", "]", ",", "**", "config", "[", "\"agent\"", "]", ")", "\n", "runner", "=", "MinibatchRl", "(", "\n", "algo", "=", "algo", ",", "\n", "agent", "=", "agent", ",", "\n", "sampler", "=", "sampler", ",", "\n", "affinity", "=", "affinity", ",", "\n", "**", "config", "[", "\"runner\"", "]", "\n", ")", "\n", "name", "=", "config", "[", "\"env\"", "]", "[", "\"game\"", "]", "\n", "with", "logger_context", "(", "log_dir", ",", "run_ID", ",", "name", ",", "config", ")", ":", "\n", "        ", "runner", ".", "train", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.train.atari_lstm_a2c_gpu.build_and_train": [[17, 42], ["rlpyt.utils.launching.affinity.affinity_from_code", "rlpyt.utils.launching.variant.load_variant", "rlpyt.utils.launching.variant.update_config", "rlpyt.samplers.parallel.gpu.sampler.GpuSampler", "rlpyt.algos.pg.a2c.A2C", "rlpyt.agents.pg.atari.AtariLstmAgent", "rlpyt.runners.minibatch_rl.MinibatchRl", "rlpyt.utils.logging.context.logger_context", "rlpyt.runners.minibatch_rl.MinibatchRl.train"], "function", ["home.repos.pwc.inspect_result.astooke_rlpyt.launching.affinity.affinity_from_code", "home.repos.pwc.inspect_result.astooke_rlpyt.launching.variant.load_variant", "home.repos.pwc.inspect_result.astooke_rlpyt.launching.variant.update_config", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.context.logger_context", "home.repos.pwc.inspect_result.astooke_rlpyt.runners.minibatch_rl.MinibatchRlEval.train"], ["def", "build_and_train", "(", "slot_affinity_code", ",", "log_dir", ",", "run_ID", ",", "config_key", ")", ":", "\n", "    ", "affinity", "=", "affinity_from_code", "(", "slot_affinity_code", ")", "\n", "config", "=", "configs", "[", "config_key", "]", "\n", "variant", "=", "load_variant", "(", "log_dir", ")", "\n", "config", "=", "update_config", "(", "config", ",", "variant", ")", "\n", "\n", "sampler", "=", "GpuSampler", "(", "\n", "EnvCls", "=", "AtariEnv", ",", "\n", "env_kwargs", "=", "config", "[", "\"env\"", "]", ",", "\n", "CollectorCls", "=", "GpuWaitResetCollector", ",", "\n", "TrajInfoCls", "=", "AtariTrajInfo", ",", "\n", "**", "config", "[", "\"sampler\"", "]", "\n", ")", "\n", "algo", "=", "A2C", "(", "optim_kwargs", "=", "config", "[", "\"optim\"", "]", ",", "**", "config", "[", "\"algo\"", "]", ")", "\n", "agent", "=", "AtariLstmAgent", "(", "model_kwargs", "=", "config", "[", "\"model\"", "]", ",", "**", "config", "[", "\"agent\"", "]", ")", "\n", "runner", "=", "MinibatchRl", "(", "\n", "algo", "=", "algo", ",", "\n", "agent", "=", "agent", ",", "\n", "sampler", "=", "sampler", ",", "\n", "affinity", "=", "affinity", ",", "\n", "**", "config", "[", "\"runner\"", "]", "\n", ")", "\n", "name", "=", "config", "[", "\"env\"", "]", "[", "\"game\"", "]", "\n", "with", "logger_context", "(", "log_dir", ",", "run_ID", ",", "name", ",", "config", ")", ":", "\n", "        ", "runner", ".", "train", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.train.atari_lstm_ppo_gpu.build_and_train": [[17, 42], ["rlpyt.utils.launching.affinity.affinity_from_code", "rlpyt.utils.launching.variant.load_variant", "rlpyt.utils.launching.variant.update_config", "rlpyt.samplers.gpu.sampler.GpuSampler", "rlpyt.algos.pg.ppo.PPO", "rlpyt.agents.pg.atari.AtariLstmAgent", "rlpyt.runners.minibatch_rl.MinibatchRl", "rlpyt.utils.logging.context.logger_context", "rlpyt.runners.minibatch_rl.MinibatchRl.train"], "function", ["home.repos.pwc.inspect_result.astooke_rlpyt.launching.affinity.affinity_from_code", "home.repos.pwc.inspect_result.astooke_rlpyt.launching.variant.load_variant", "home.repos.pwc.inspect_result.astooke_rlpyt.launching.variant.update_config", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.context.logger_context", "home.repos.pwc.inspect_result.astooke_rlpyt.runners.minibatch_rl.MinibatchRlEval.train"], ["def", "build_and_train", "(", "slot_affinity_code", ",", "log_dir", ",", "run_ID", ",", "config_key", ")", ":", "\n", "    ", "affinity", "=", "affinity_from_code", "(", "slot_affinity_code", ")", "\n", "config", "=", "configs", "[", "config_key", "]", "\n", "variant", "=", "load_variant", "(", "log_dir", ")", "\n", "config", "=", "update_config", "(", "config", ",", "variant", ")", "\n", "\n", "sampler", "=", "GpuSampler", "(", "\n", "EnvCls", "=", "AtariEnv", ",", "\n", "env_kwargs", "=", "config", "[", "\"env\"", "]", ",", "\n", "CollectorCls", "=", "GpuWaitResetCollector", ",", "\n", "TrajInfoCls", "=", "AtariTrajInfo", ",", "\n", "**", "config", "[", "\"sampler\"", "]", "\n", ")", "\n", "algo", "=", "PPO", "(", "optim_kwargs", "=", "config", "[", "\"optim\"", "]", ",", "**", "config", "[", "\"algo\"", "]", ")", "\n", "agent", "=", "AtariLstmAgent", "(", "model_kwargs", "=", "config", "[", "\"model\"", "]", ",", "**", "config", "[", "\"agent\"", "]", ")", "\n", "runner", "=", "MinibatchRl", "(", "\n", "algo", "=", "algo", ",", "\n", "agent", "=", "agent", ",", "\n", "sampler", "=", "sampler", ",", "\n", "affinity", "=", "affinity", ",", "\n", "**", "config", "[", "\"runner\"", "]", "\n", ")", "\n", "name", "=", "config", "[", "\"env\"", "]", "[", "\"game\"", "]", "\n", "with", "logger_context", "(", "log_dir", ",", "run_ID", ",", "name", ",", "config", ")", ":", "\n", "        ", "runner", ".", "train", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.train.atari_lstm_a2c_cpu.build_and_train": [[17, 42], ["rlpyt.utils.launching.affinity.affinity_from_code", "rlpyt.utils.launching.variant.load_variant", "rlpyt.utils.launching.variant.update_config", "rlpyt.samplers.parallel.cpu.sampler.CpuSampler", "rlpyt.algos.pg.a2c.A2C", "rlpyt.agents.pg.atari.AtariLstmAgent", "rlpyt.runners.minibatch_rl.MinibatchRl", "str", "rlpyt.utils.logging.context.logger_context", "rlpyt.runners.minibatch_rl.MinibatchRl.train"], "function", ["home.repos.pwc.inspect_result.astooke_rlpyt.launching.affinity.affinity_from_code", "home.repos.pwc.inspect_result.astooke_rlpyt.launching.variant.load_variant", "home.repos.pwc.inspect_result.astooke_rlpyt.launching.variant.update_config", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.context.logger_context", "home.repos.pwc.inspect_result.astooke_rlpyt.runners.minibatch_rl.MinibatchRlEval.train"], ["def", "build_and_train", "(", "slot_affinity_code", ",", "log_dir", ",", "run_ID", ",", "config_key", ")", ":", "\n", "    ", "affinity", "=", "affinity_from_code", "(", "slot_affinity_code", ")", "\n", "config", "=", "configs", "[", "config_key", "]", "\n", "variant", "=", "load_variant", "(", "log_dir", ")", "\n", "config", "=", "update_config", "(", "config", ",", "variant", ")", "\n", "\n", "sampler", "=", "CpuSampler", "(", "\n", "EnvCls", "=", "AtariEnv", ",", "\n", "env_kwargs", "=", "config", "[", "\"env\"", "]", ",", "\n", "CollectorCls", "=", "CpuWaitResetCollector", ",", "\n", "TrajInfoCls", "=", "AtariTrajInfo", ",", "\n", "**", "config", "[", "\"sampler\"", "]", "\n", ")", "\n", "algo", "=", "A2C", "(", "optim_kwargs", "=", "config", "[", "\"optim\"", "]", ",", "**", "config", "[", "\"algo\"", "]", ")", "\n", "agent", "=", "AtariLstmAgent", "(", "model_kwargs", "=", "config", "[", "\"model\"", "]", ",", "**", "config", "[", "\"agent\"", "]", ")", "\n", "runner", "=", "MinibatchRl", "(", "\n", "algo", "=", "algo", ",", "\n", "agent", "=", "agent", ",", "\n", "sampler", "=", "sampler", ",", "\n", "affinity", "=", "affinity", ",", "\n", "**", "config", "[", "\"runner\"", "]", "\n", ")", "\n", "name", "=", "config", "[", "\"env\"", "]", "[", "\"game\"", "]", "+", "str", "(", "config", "[", "\"sampler\"", "]", "[", "\"batch_T\"", "]", ")", "\n", "with", "logger_context", "(", "log_dir", ",", "run_ID", ",", "name", ",", "config", ")", ":", "\n", "        ", "runner", ".", "train", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.train.atari_ff_a2c_cpu.build_and_train": [[17, 42], ["rlpyt.utils.launching.affinity.affinity_from_code", "rlpyt.utils.launching.variant.load_variant", "rlpyt.utils.launching.variant.update_config", "rlpyt.samplers.parallel.cpu.sampler.CpuSampler", "rlpyt.algos.pg.a2c.A2C", "rlpyt.agents.pg.atari.AtariFfAgent", "rlpyt.runners.minibatch_rl.MinibatchRl", "rlpyt.utils.logging.context.logger_context", "rlpyt.runners.minibatch_rl.MinibatchRl.train"], "function", ["home.repos.pwc.inspect_result.astooke_rlpyt.launching.affinity.affinity_from_code", "home.repos.pwc.inspect_result.astooke_rlpyt.launching.variant.load_variant", "home.repos.pwc.inspect_result.astooke_rlpyt.launching.variant.update_config", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.context.logger_context", "home.repos.pwc.inspect_result.astooke_rlpyt.runners.minibatch_rl.MinibatchRlEval.train"], ["def", "build_and_train", "(", "slot_affinity_code", ",", "log_dir", ",", "run_ID", ",", "config_key", ")", ":", "\n", "    ", "affinity", "=", "affinity_from_code", "(", "slot_affinity_code", ")", "\n", "config", "=", "configs", "[", "config_key", "]", "\n", "variant", "=", "load_variant", "(", "log_dir", ")", "\n", "config", "=", "update_config", "(", "config", ",", "variant", ")", "\n", "\n", "sampler", "=", "CpuSampler", "(", "\n", "EnvCls", "=", "AtariEnv", ",", "\n", "env_kwargs", "=", "config", "[", "\"env\"", "]", ",", "\n", "CollectorCls", "=", "CpuWaitResetCollector", ",", "\n", "TrajInfoCls", "=", "AtariTrajInfo", ",", "\n", "**", "config", "[", "\"sampler\"", "]", "\n", ")", "\n", "algo", "=", "A2C", "(", "optim_kwargs", "=", "config", "[", "\"optim\"", "]", ",", "**", "config", "[", "\"algo\"", "]", ")", "\n", "agent", "=", "AtariFfAgent", "(", "model_kwargs", "=", "config", "[", "\"model\"", "]", ",", "**", "config", "[", "\"agent\"", "]", ")", "\n", "runner", "=", "MinibatchRl", "(", "\n", "algo", "=", "algo", ",", "\n", "agent", "=", "agent", ",", "\n", "sampler", "=", "sampler", ",", "\n", "affinity", "=", "affinity", ",", "\n", "**", "config", "[", "\"runner\"", "]", "\n", ")", "\n", "name", "=", "config", "[", "\"env\"", "]", "[", "\"game\"", "]", "\n", "with", "logger_context", "(", "log_dir", ",", "run_ID", ",", "name", ",", "config", ")", ":", "\n", "        ", "runner", ".", "train", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.train.atari_dqn_async_gpu.build_and_train": [[17, 44], ["rlpyt.utils.launching.affinity.affinity_from_code", "rlpyt.utils.launching.variant.load_variant", "rlpyt.utils.launching.variant.update_config", "rlpyt.samplers.async_.gpu_sampler.AsyncGpuSampler", "rlpyt.algos.dqn.dqn.DQN", "rlpyt.agents.dqn.atari.atari_dqn_agent.AtariDqnAgent", "rlpyt.runners.async_rl.AsyncRlEval", "rlpyt.utils.logging.context.logger_context", "rlpyt.runners.async_rl.AsyncRlEval.train"], "function", ["home.repos.pwc.inspect_result.astooke_rlpyt.launching.affinity.affinity_from_code", "home.repos.pwc.inspect_result.astooke_rlpyt.launching.variant.load_variant", "home.repos.pwc.inspect_result.astooke_rlpyt.launching.variant.update_config", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.context.logger_context", "home.repos.pwc.inspect_result.astooke_rlpyt.runners.minibatch_rl.MinibatchRlEval.train"], ["# Change these inputs to match local machine and desired parallelism.", "\n", "    ", "affinity", "=", "make_affinity", "(", "\n", "run_slot", "=", "0", ",", "\n", "n_cpu_core", "=", "8", ",", "# Use 16 cores across all experiments.", "\n", "n_gpu", "=", "2", ",", "# Use 8 gpus across all experiments.", "\n", "gpu_per_run", "=", "1", ",", "\n", "sample_gpu_per_run", "=", "1", ",", "\n", "async_sample", "=", "True", ",", "\n", "optim_sample_share_gpu", "=", "False", ",", "\n", "# hyperthread_offset=24,  # If machine has 24 cores.", "\n", "# n_socket=2,  # Presume CPU socket affinity to lower/upper half GPUs.", "\n", "# gpu_per_run=2,  # How many GPUs to parallelize one run across.", "\n", "# cpu_per_run=1,", "\n", ")", "\n", "\n", "sampler", "=", "AsyncGpuSampler", "(", "\n", "EnvCls", "=", "AtariEnv", ",", "\n", "TrajInfoCls", "=", "AtariTrajInfo", ",", "\n", "env_kwargs", "=", "dict", "(", "game", "=", "game", ")", ",", "\n", "batch_T", "=", "5", ",", "\n", "batch_B", "=", "36", ",", "\n", "max_decorrelation_steps", "=", "100", ",", "\n", "eval_env_kwargs", "=", "dict", "(", "game", "=", "game", ")", ",", "\n", "eval_n_envs", "=", "2", ",", "\n", "eval_max_steps", "=", "int", "(", "10e3", ")", ",", "\n", "eval_max_trajectories", "=", "4", ",", "\n", ")", "\n", "algo", "=", "DQN", "(", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.train.atari_dqn_gpu.build_and_train": [[17, 44], ["rlpyt.utils.launching.affinity.affinity_from_code", "rlpyt.utils.launching.variant.load_variant", "rlpyt.utils.launching.variant.update_config", "rlpyt.samplers.parallel.gpu.sampler.GpuSampler", "rlpyt.algos.dqn.dqn.DQN", "rlpyt.agents.dqn.atari.atari_dqn_agent.AtariDqnAgent", "rlpyt.runners.minibatch_rl.MinibatchRlEval", "rlpyt.utils.logging.context.logger_context", "rlpyt.runners.minibatch_rl.MinibatchRlEval.train"], "function", ["home.repos.pwc.inspect_result.astooke_rlpyt.launching.affinity.affinity_from_code", "home.repos.pwc.inspect_result.astooke_rlpyt.launching.variant.load_variant", "home.repos.pwc.inspect_result.astooke_rlpyt.launching.variant.update_config", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.context.logger_context", "home.repos.pwc.inspect_result.astooke_rlpyt.runners.minibatch_rl.MinibatchRlEval.train"], ["def", "build_and_train", "(", "slot_affinity_code", ",", "log_dir", ",", "run_ID", ",", "config_key", ")", ":", "\n", "    ", "affinity", "=", "affinity_from_code", "(", "slot_affinity_code", ")", "\n", "config", "=", "configs", "[", "config_key", "]", "\n", "variant", "=", "load_variant", "(", "log_dir", ")", "\n", "config", "=", "update_config", "(", "config", ",", "variant", ")", "\n", "config", "[", "\"eval_env\"", "]", "[", "\"game\"", "]", "=", "config", "[", "\"env\"", "]", "[", "\"game\"", "]", "\n", "\n", "sampler", "=", "GpuSampler", "(", "\n", "EnvCls", "=", "AtariEnv", ",", "\n", "env_kwargs", "=", "config", "[", "\"env\"", "]", ",", "\n", "CollectorCls", "=", "GpuWaitResetCollector", ",", "\n", "TrajInfoCls", "=", "AtariTrajInfo", ",", "\n", "eval_env_kwargs", "=", "config", "[", "\"eval_env\"", "]", ",", "\n", "**", "config", "[", "\"sampler\"", "]", "\n", ")", "\n", "algo", "=", "DQN", "(", "optim_kwargs", "=", "config", "[", "\"optim\"", "]", ",", "**", "config", "[", "\"algo\"", "]", ")", "\n", "agent", "=", "AtariDqnAgent", "(", "model_kwargs", "=", "config", "[", "\"model\"", "]", ",", "**", "config", "[", "\"agent\"", "]", ")", "\n", "runner", "=", "MinibatchRlEval", "(", "\n", "algo", "=", "algo", ",", "\n", "agent", "=", "agent", ",", "\n", "sampler", "=", "sampler", ",", "\n", "affinity", "=", "affinity", ",", "\n", "**", "config", "[", "\"runner\"", "]", "\n", ")", "\n", "name", "=", "config", "[", "\"env\"", "]", "[", "\"game\"", "]", "\n", "with", "logger_context", "(", "log_dir", ",", "run_ID", ",", "name", ",", "config", ")", ":", "\n", "        ", "runner", ".", "train", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.train.atari_dqn_gpu_noeval.build_and_train": [[17, 44], ["rlpyt.utils.launching.affinity.affinity_from_code", "rlpyt.utils.launching.variant.load_variant", "rlpyt.utils.launching.variant.update_config", "rlpyt.samplers.parallel.gpu.sampler.GpuSampler", "rlpyt.algos.dqn.dqn.DQN", "rlpyt.agents.dqn.atari.atari_dqn_agent.AtariDqnAgent", "rlpyt.runners.minibatch_rl.MinibatchRl", "rlpyt.utils.logging.context.logger_context", "rlpyt.runners.minibatch_rl.MinibatchRl.train"], "function", ["home.repos.pwc.inspect_result.astooke_rlpyt.launching.affinity.affinity_from_code", "home.repos.pwc.inspect_result.astooke_rlpyt.launching.variant.load_variant", "home.repos.pwc.inspect_result.astooke_rlpyt.launching.variant.update_config", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.context.logger_context", "home.repos.pwc.inspect_result.astooke_rlpyt.runners.minibatch_rl.MinibatchRlEval.train"], ["def", "build_and_train", "(", "slot_affinity_code", ",", "log_dir", ",", "run_ID", ",", "config_key", ")", ":", "\n", "    ", "affinity", "=", "affinity_from_code", "(", "slot_affinity_code", ")", "\n", "config", "=", "configs", "[", "config_key", "]", "\n", "variant", "=", "load_variant", "(", "log_dir", ")", "\n", "config", "=", "update_config", "(", "config", ",", "variant", ")", "\n", "config", "[", "\"eval_env\"", "]", "[", "\"game\"", "]", "=", "config", "[", "\"env\"", "]", "[", "\"game\"", "]", "\n", "\n", "sampler", "=", "GpuSampler", "(", "\n", "EnvCls", "=", "AtariEnv", ",", "\n", "env_kwargs", "=", "config", "[", "\"env\"", "]", ",", "\n", "CollectorCls", "=", "GpuWaitResetCollector", ",", "\n", "TrajInfoCls", "=", "AtariTrajInfo", ",", "\n", "eval_env_kwargs", "=", "config", "[", "\"eval_env\"", "]", ",", "\n", "**", "config", "[", "\"sampler\"", "]", "\n", ")", "\n", "algo", "=", "DQN", "(", "optim_kwargs", "=", "config", "[", "\"optim\"", "]", ",", "**", "config", "[", "\"algo\"", "]", ")", "\n", "agent", "=", "AtariDqnAgent", "(", "model_kwargs", "=", "config", "[", "\"model\"", "]", ",", "**", "config", "[", "\"agent\"", "]", ")", "\n", "runner", "=", "MinibatchRl", "(", "\n", "algo", "=", "algo", ",", "\n", "agent", "=", "agent", ",", "\n", "sampler", "=", "sampler", ",", "\n", "affinity", "=", "affinity", ",", "\n", "**", "config", "[", "\"runner\"", "]", "\n", ")", "\n", "name", "=", "config", "[", "\"env\"", "]", "[", "\"game\"", "]", "\n", "with", "logger_context", "(", "log_dir", ",", "run_ID", ",", "name", ",", "config", ")", ":", "\n", "        ", "runner", ".", "train", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.train.atari_dqn_cpu.build_and_train": [[17, 45], ["rlpyt.utils.launching.affinity.affinity_from_code", "rlpyt.utils.launching.variant.load_variant", "rlpyt.utils.launching.variant.update_config", "config[].pop", "rlpyt.samplers.parallel.cpu.sampler.CpuSampler", "rlpyt.algos.dqn.dqn.DQN", "rlpyt.agents.dqn.atari.atari_dqn_agent.AtariDqnAgent", "rlpyt.runners.minibatch_rl.MinibatchRlEval", "rlpyt.utils.logging.context.logger_context", "rlpyt.runners.minibatch_rl.MinibatchRlEval.train"], "function", ["home.repos.pwc.inspect_result.astooke_rlpyt.launching.affinity.affinity_from_code", "home.repos.pwc.inspect_result.astooke_rlpyt.launching.variant.load_variant", "home.repos.pwc.inspect_result.astooke_rlpyt.launching.variant.update_config", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.context.logger_context", "home.repos.pwc.inspect_result.astooke_rlpyt.runners.minibatch_rl.MinibatchRlEval.train"], ["def", "build_and_train", "(", "slot_affinity_code", ",", "log_dir", ",", "run_ID", ",", "config_key", ")", ":", "\n", "    ", "affinity", "=", "affinity_from_code", "(", "slot_affinity_code", ")", "\n", "config", "=", "configs", "[", "config_key", "]", "\n", "variant", "=", "load_variant", "(", "log_dir", ")", "\n", "config", "=", "update_config", "(", "config", ",", "variant", ")", "\n", "config", "[", "\"eval_env\"", "]", "[", "\"game\"", "]", "=", "config", "[", "\"env\"", "]", "[", "\"game\"", "]", "\n", "\n", "CollectorCls", "=", "config", "[", "\"sampler\"", "]", ".", "pop", "(", "\"CollectorCls\"", ",", "None", ")", "\n", "sampler", "=", "CpuSampler", "(", "\n", "EnvCls", "=", "AtariEnv", ",", "\n", "env_kwargs", "=", "config", "[", "\"env\"", "]", ",", "\n", "CollectorCls", "=", "CollectorCls", "or", "CpuWaitResetCollector", ",", "\n", "TrajInfoCls", "=", "AtariTrajInfo", ",", "\n", "eval_env_kwargs", "=", "config", "[", "\"eval_env\"", "]", ",", "\n", "**", "config", "[", "\"sampler\"", "]", "\n", ")", "\n", "algo", "=", "DQN", "(", "optim_kwargs", "=", "config", "[", "\"optim\"", "]", ",", "**", "config", "[", "\"algo\"", "]", ")", "\n", "agent", "=", "AtariDqnAgent", "(", "model_kwargs", "=", "config", "[", "\"model\"", "]", ",", "**", "config", "[", "\"agent\"", "]", ")", "\n", "runner", "=", "MinibatchRlEval", "(", "\n", "algo", "=", "algo", ",", "\n", "agent", "=", "agent", ",", "\n", "sampler", "=", "sampler", ",", "\n", "affinity", "=", "affinity", ",", "\n", "**", "config", "[", "\"runner\"", "]", "\n", ")", "\n", "name", "=", "config", "[", "\"env\"", "]", "[", "\"game\"", "]", "\n", "with", "logger_context", "(", "log_dir", ",", "run_ID", ",", "name", ",", "config", ")", ":", "\n", "        ", "runner", ".", "train", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.train.atari_r2d1_async_gpu.build_and_train": [[17, 44], ["rlpyt.utils.launching.affinity.affinity_from_code", "rlpyt.utils.launching.variant.load_variant", "rlpyt.utils.launching.variant.update_config", "rlpyt.samplers.async_.gpu_sampler.AsyncGpuSampler", "rlpyt.algos.dqn.r2d1.R2D1", "rlpyt.agents.dqn.atari.atari_r2d1_agent.AtariR2d1Agent", "rlpyt.runners.async_rl.AsyncRlEval", "rlpyt.utils.logging.context.logger_context", "rlpyt.runners.async_rl.AsyncRlEval.train"], "function", ["home.repos.pwc.inspect_result.astooke_rlpyt.launching.affinity.affinity_from_code", "home.repos.pwc.inspect_result.astooke_rlpyt.launching.variant.load_variant", "home.repos.pwc.inspect_result.astooke_rlpyt.launching.variant.update_config", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.context.logger_context", "home.repos.pwc.inspect_result.astooke_rlpyt.runners.minibatch_rl.MinibatchRlEval.train"], ["def", "build_and_train", "(", "slot_affinity_code", ",", "log_dir", ",", "run_ID", ",", "config_key", ")", ":", "\n", "    ", "affinity", "=", "affinity_from_code", "(", "slot_affinity_code", ")", "\n", "config", "=", "configs", "[", "config_key", "]", "\n", "variant", "=", "load_variant", "(", "log_dir", ")", "\n", "config", "=", "update_config", "(", "config", ",", "variant", ")", "\n", "config", "[", "\"eval_env\"", "]", "[", "\"game\"", "]", "=", "config", "[", "\"env\"", "]", "[", "\"game\"", "]", "\n", "\n", "sampler", "=", "AsyncGpuSampler", "(", "\n", "EnvCls", "=", "AtariEnv", ",", "\n", "env_kwargs", "=", "config", "[", "\"env\"", "]", ",", "\n", "CollectorCls", "=", "DbGpuResetCollector", ",", "\n", "TrajInfoCls", "=", "AtariTrajInfo", ",", "\n", "eval_env_kwargs", "=", "config", "[", "\"eval_env\"", "]", ",", "\n", "**", "config", "[", "\"sampler\"", "]", "\n", ")", "\n", "algo", "=", "R2D1", "(", "optim_kwargs", "=", "config", "[", "\"optim\"", "]", ",", "**", "config", "[", "\"algo\"", "]", ")", "\n", "agent", "=", "AtariR2d1Agent", "(", "model_kwargs", "=", "config", "[", "\"model\"", "]", ",", "**", "config", "[", "\"agent\"", "]", ")", "\n", "runner", "=", "AsyncRlEval", "(", "\n", "algo", "=", "algo", ",", "\n", "agent", "=", "agent", ",", "\n", "sampler", "=", "sampler", ",", "\n", "affinity", "=", "affinity", ",", "\n", "**", "config", "[", "\"runner\"", "]", "\n", ")", "\n", "name", "=", "\"async_gpu_\"", "+", "config", "[", "\"env\"", "]", "[", "\"game\"", "]", "\n", "with", "logger_context", "(", "log_dir", ",", "run_ID", ",", "name", ",", "config", ")", ":", "\n", "        ", "runner", ".", "train", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.train.atari_dqn_serial.build_and_train": [[17, 44], ["rlpyt.utils.launching.affinity.affinity_from_code", "rlpyt.utils.launching.variant.load_variant", "rlpyt.utils.launching.variant.update_config", "rlpyt.samplers.serial_sampler.SerialSampler", "rlpyt.algos.dqn.dqn.DQN", "rlpyt.agents.dqn.atari.atari_dqn_agent.AtariDqnAgent", "rlpyt.runners.minibatch_rl.MinibatchRlEval", "rlpyt.utils.logging.context.logger_context", "rlpyt.runners.minibatch_rl.MinibatchRlEval.train"], "function", ["home.repos.pwc.inspect_result.astooke_rlpyt.launching.affinity.affinity_from_code", "home.repos.pwc.inspect_result.astooke_rlpyt.launching.variant.load_variant", "home.repos.pwc.inspect_result.astooke_rlpyt.launching.variant.update_config", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.context.logger_context", "home.repos.pwc.inspect_result.astooke_rlpyt.runners.minibatch_rl.MinibatchRlEval.train"], ["def", "build_and_train", "(", "slot_affinity_code", ",", "log_dir", ",", "run_ID", ",", "config_key", ")", ":", "\n", "    ", "affinity", "=", "affinity_from_code", "(", "slot_affinity_code", ")", "\n", "config", "=", "configs", "[", "config_key", "]", "\n", "variant", "=", "load_variant", "(", "log_dir", ")", "\n", "config", "=", "update_config", "(", "config", ",", "variant", ")", "\n", "config", "[", "\"eval_env\"", "]", "[", "\"game\"", "]", "=", "config", "[", "\"env\"", "]", "[", "\"game\"", "]", "\n", "\n", "sampler", "=", "SerialSampler", "(", "\n", "EnvCls", "=", "AtariEnv", ",", "\n", "env_kwargs", "=", "config", "[", "\"env\"", "]", ",", "\n", "CollectorCls", "=", "CpuResetCollector", ",", "\n", "TrajInfoCls", "=", "AtariTrajInfo", ",", "\n", "eval_env_kwargs", "=", "config", "[", "\"eval_env\"", "]", ",", "\n", "**", "config", "[", "\"sampler\"", "]", "\n", ")", "\n", "algo", "=", "DQN", "(", "optim_kwargs", "=", "config", "[", "\"optim\"", "]", ",", "**", "config", "[", "\"algo\"", "]", ")", "\n", "agent", "=", "AtariDqnAgent", "(", "model_kwargs", "=", "config", "[", "\"model\"", "]", ",", "**", "config", "[", "\"agent\"", "]", ")", "\n", "runner", "=", "MinibatchRlEval", "(", "\n", "algo", "=", "algo", ",", "\n", "agent", "=", "agent", ",", "\n", "sampler", "=", "sampler", ",", "\n", "affinity", "=", "affinity", ",", "\n", "**", "config", "[", "\"runner\"", "]", "\n", ")", "\n", "name", "=", "config", "[", "\"env\"", "]", "[", "\"game\"", "]", "\n", "with", "logger_context", "(", "log_dir", ",", "run_ID", ",", "name", ",", "config", ")", ":", "\n", "        ", "runner", ".", "train", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.train.atari_dqn_async_serial.build_and_train": [[17, 44], ["rlpyt.utils.launching.affinity.affinity_from_code", "rlpyt.utils.launching.variant.load_variant", "rlpyt.utils.launching.variant.update_config", "rlpyt.samplers.async_.serial_sampler.AsyncSerialSampler", "rlpyt.algos.dqn.dqn.DQN", "rlpyt.agents.dqn.atari.atari_dqn_agent.AtariDqnAgent", "rlpyt.runners.async_rl.AsyncRlEval", "rlpyt.utils.logging.context.logger_context", "rlpyt.runners.async_rl.AsyncRlEval.train"], "function", ["home.repos.pwc.inspect_result.astooke_rlpyt.launching.affinity.affinity_from_code", "home.repos.pwc.inspect_result.astooke_rlpyt.launching.variant.load_variant", "home.repos.pwc.inspect_result.astooke_rlpyt.launching.variant.update_config", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.context.logger_context", "home.repos.pwc.inspect_result.astooke_rlpyt.runners.minibatch_rl.MinibatchRlEval.train"], ["\n", "\n", "def", "build_and_train", "(", "game", "=", "\"pong\"", ",", "run_ID", "=", "0", ")", ":", "\n", "# Change these inputs to match local machine and desired parallelism.", "\n", "    ", "affinity", "=", "make_affinity", "(", "\n", "run_slot", "=", "0", ",", "\n", "n_cpu_core", "=", "2", ",", "# Use 16 cores across all experiments.", "\n", "n_gpu", "=", "1", ",", "# Use 8 gpus across all experiments.", "\n", "sample_gpu_per_run", "=", "0", ",", "\n", "async_sample", "=", "True", ",", "# Different affinity structure fo async.", "\n", "# hyperthread_offset=24,  # If machine has 24 cores.", "\n", "# n_socket=2,  # Presume CPU socket affinity to lower/upper half GPUs.", "\n", "# gpu_per_run=2,  # How many optimizer GPUs to parallelize one run.", "\n", "# cpu_per_run=1,", "\n", ")", "\n", "\n", "sampler", "=", "AsyncSerialSampler", "(", "\n", "EnvCls", "=", "AtariEnv", ",", "\n", "TrajInfoCls", "=", "AtariTrajInfo", ",", "\n", "env_kwargs", "=", "dict", "(", "game", "=", "game", ")", ",", "\n", "CollectorCls", "=", "DbCpuResetCollector", ",", "\n", "batch_T", "=", "5", ",", "\n", "batch_B", "=", "4", ",", "\n", "max_decorrelation_steps", "=", "100", ",", "\n", "eval_env_kwargs", "=", "dict", "(", "game", "=", "game", ")", ",", "\n", "eval_n_envs", "=", "1", ",", "\n", "eval_max_steps", "=", "int", "(", "10e3", ")", ",", "\n", "eval_max_trajectories", "=", "2", ",", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.train.atari_dqn_async_cpu.build_and_train": [[17, 44], ["rlpyt.utils.launching.affinity.affinity_from_code", "rlpyt.utils.launching.variant.load_variant", "rlpyt.utils.launching.variant.update_config", "rlpyt.samplers.async_.cpu_sampler.AsyncCpuSampler", "rlpyt.algos.dqn.dqn.DQN", "rlpyt.agents.dqn.atari.atari_dqn_agent.AtariDqnAgent", "rlpyt.runners.async_rl.AsyncRlEval", "rlpyt.utils.logging.context.logger_context", "rlpyt.runners.async_rl.AsyncRlEval.train"], "function", ["home.repos.pwc.inspect_result.astooke_rlpyt.launching.affinity.affinity_from_code", "home.repos.pwc.inspect_result.astooke_rlpyt.launching.variant.load_variant", "home.repos.pwc.inspect_result.astooke_rlpyt.launching.variant.update_config", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.context.logger_context", "home.repos.pwc.inspect_result.astooke_rlpyt.runners.minibatch_rl.MinibatchRlEval.train"], ["# Change these inputs to match local machine and desired parallelism.", "\n", "    ", "affinity", "=", "make_affinity", "(", "\n", "run_slot", "=", "0", ",", "\n", "n_cpu_core", "=", "3", ",", "# Use 16 cores across all experiments.", "\n", "n_gpu", "=", "1", ",", "# Use 8 gpus across all experiments.", "\n", "sample_gpu_per_run", "=", "0", ",", "\n", "async_sample", "=", "True", ",", "\n", "# hyperthread_offset=24,  # If machine has 24 cores.", "\n", "# n_socket=2,  # Presume CPU socket affinity to lower/upper half GPUs.", "\n", "# gpu_per_run=2,  # How many GPUs to parallelize one run across.", "\n", "# cpu_per_run=1,", "\n", ")", "\n", "\n", "sampler", "=", "AsyncCpuSampler", "(", "\n", "EnvCls", "=", "AtariEnv", ",", "\n", "TrajInfoCls", "=", "AtariTrajInfo", ",", "\n", "env_kwargs", "=", "dict", "(", "game", "=", "game", ")", ",", "\n", "batch_T", "=", "5", ",", "\n", "batch_B", "=", "8", ",", "\n", "max_decorrelation_steps", "=", "100", ",", "\n", "eval_env_kwargs", "=", "dict", "(", "game", "=", "game", ")", ",", "\n", "eval_n_envs", "=", "2", ",", "\n", "eval_max_steps", "=", "int", "(", "10e3", ")", ",", "\n", "eval_max_trajectories", "=", "4", ",", "\n", ")", "\n", "algo", "=", "DQN", "(", "\n", "replay_ratio", "=", "8", ",", "\n", "min_steps_learn", "=", "1e4", ",", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.train.atari_r2d1_gpu.build_and_train": [[17, 44], ["rlpyt.utils.launching.affinity.affinity_from_code", "rlpyt.utils.launching.variant.load_variant", "rlpyt.utils.launching.variant.update_config", "rlpyt.samplers.parallel.gpu.sampler.GpuSampler", "rlpyt.algos.dqn.r2d1.R2D1", "rlpyt.agents.dqn.atari.atari_r2d1_agent.AtariR2d1Agent", "rlpyt.runners.minibatch_rl.MinibatchRlEval", "rlpyt.utils.logging.context.logger_context", "rlpyt.runners.minibatch_rl.MinibatchRlEval.train"], "function", ["home.repos.pwc.inspect_result.astooke_rlpyt.launching.affinity.affinity_from_code", "home.repos.pwc.inspect_result.astooke_rlpyt.launching.variant.load_variant", "home.repos.pwc.inspect_result.astooke_rlpyt.launching.variant.update_config", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.context.logger_context", "home.repos.pwc.inspect_result.astooke_rlpyt.runners.minibatch_rl.MinibatchRlEval.train"], ["def", "build_and_train", "(", "slot_affinity_code", ",", "log_dir", ",", "run_ID", ",", "config_key", ")", ":", "\n", "    ", "affinity", "=", "affinity_from_code", "(", "slot_affinity_code", ")", "\n", "config", "=", "configs", "[", "config_key", "]", "\n", "variant", "=", "load_variant", "(", "log_dir", ")", "\n", "config", "=", "update_config", "(", "config", ",", "variant", ")", "\n", "config", "[", "\"eval_env\"", "]", "[", "\"game\"", "]", "=", "config", "[", "\"env\"", "]", "[", "\"game\"", "]", "\n", "\n", "sampler", "=", "GpuSampler", "(", "\n", "EnvCls", "=", "AtariEnv", ",", "\n", "env_kwargs", "=", "config", "[", "\"env\"", "]", ",", "\n", "CollectorCls", "=", "GpuWaitResetCollector", ",", "\n", "TrajInfoCls", "=", "AtariTrajInfo", ",", "\n", "eval_env_kwargs", "=", "config", "[", "\"eval_env\"", "]", ",", "\n", "**", "config", "[", "\"sampler\"", "]", "\n", ")", "\n", "algo", "=", "R2D1", "(", "optim_kwargs", "=", "config", "[", "\"optim\"", "]", ",", "**", "config", "[", "\"algo\"", "]", ")", "\n", "agent", "=", "AtariR2d1Agent", "(", "model_kwargs", "=", "config", "[", "\"model\"", "]", ",", "**", "config", "[", "\"agent\"", "]", ")", "\n", "runner", "=", "MinibatchRlEval", "(", "\n", "algo", "=", "algo", ",", "\n", "agent", "=", "agent", ",", "\n", "sampler", "=", "sampler", ",", "\n", "affinity", "=", "affinity", ",", "\n", "**", "config", "[", "\"runner\"", "]", "\n", ")", "\n", "name", "=", "config", "[", "\"env\"", "]", "[", "\"game\"", "]", "\n", "with", "logger_context", "(", "log_dir", ",", "run_ID", ",", "name", ",", "config", ")", ":", "\n", "        ", "runner", ".", "train", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.train.atari_catdqn_gpu.build_and_train": [[17, 44], ["rlpyt.utils.launching.affinity.affinity_from_code", "rlpyt.utils.launching.variant.load_variant", "rlpyt.utils.launching.variant.update_config", "rlpyt.samplers.parallel.gpu.sampler.GpuSampler", "rlpyt.algos.dqn.cat_dqn.CategoricalDQN", "rlpyt.agents.dqn.atari.atari_catdqn_agent.AtariCatDqnAgent", "rlpyt.runners.minibatch_rl.MinibatchRlEval", "rlpyt.utils.logging.context.logger_context", "rlpyt.runners.minibatch_rl.MinibatchRlEval.train"], "function", ["home.repos.pwc.inspect_result.astooke_rlpyt.launching.affinity.affinity_from_code", "home.repos.pwc.inspect_result.astooke_rlpyt.launching.variant.load_variant", "home.repos.pwc.inspect_result.astooke_rlpyt.launching.variant.update_config", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.context.logger_context", "home.repos.pwc.inspect_result.astooke_rlpyt.runners.minibatch_rl.MinibatchRlEval.train"], ["def", "build_and_train", "(", "slot_affinity_code", ",", "log_dir", ",", "run_ID", ",", "config_key", ")", ":", "\n", "    ", "affinity", "=", "affinity_from_code", "(", "slot_affinity_code", ")", "\n", "config", "=", "configs", "[", "config_key", "]", "\n", "variant", "=", "load_variant", "(", "log_dir", ")", "\n", "config", "=", "update_config", "(", "config", ",", "variant", ")", "\n", "config", "[", "\"eval_env\"", "]", "[", "\"game\"", "]", "=", "config", "[", "\"env\"", "]", "[", "\"game\"", "]", "\n", "\n", "sampler", "=", "GpuSampler", "(", "\n", "EnvCls", "=", "AtariEnv", ",", "\n", "env_kwargs", "=", "config", "[", "\"env\"", "]", ",", "\n", "CollectorCls", "=", "GpuWaitResetCollector", ",", "\n", "TrajInfoCls", "=", "AtariTrajInfo", ",", "\n", "eval_env_kwargs", "=", "config", "[", "\"eval_env\"", "]", ",", "\n", "**", "config", "[", "\"sampler\"", "]", "\n", ")", "\n", "algo", "=", "CategoricalDQN", "(", "optim_kwargs", "=", "config", "[", "\"optim\"", "]", ",", "**", "config", "[", "\"algo\"", "]", ")", "\n", "agent", "=", "AtariCatDqnAgent", "(", "model_kwargs", "=", "config", "[", "\"model\"", "]", ",", "**", "config", "[", "\"agent\"", "]", ")", "\n", "runner", "=", "MinibatchRlEval", "(", "\n", "algo", "=", "algo", ",", "\n", "agent", "=", "agent", ",", "\n", "sampler", "=", "sampler", ",", "\n", "affinity", "=", "affinity", ",", "\n", "**", "config", "[", "\"runner\"", "]", "\n", ")", "\n", "name", "=", "config", "[", "\"env\"", "]", "[", "\"game\"", "]", "\n", "with", "logger_context", "(", "log_dir", ",", "run_ID", ",", "name", ",", "config", ")", ":", "\n", "        ", "runner", ".", "train", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.train.atari_r2d1_async_alt.build_and_train": [[17, 45], ["rlpyt.utils.launching.affinity.affinity_from_code", "rlpyt.utils.launching.variant.load_variant", "rlpyt.utils.launching.variant.update_config", "rlpyt.samplers.async_.alternating_sampler.AsyncAlternatingSampler", "rlpyt.algos.dqn.r2d1.R2D1", "rlpyt.agents.dqn.atari.atari_r2d1_agent.AtariR2d1AlternatingAgent", "rlpyt.runners.async_rl.AsyncRlEval", "rlpyt.utils.logging.context.logger_context", "rlpyt.runners.async_rl.AsyncRlEval.train"], "function", ["home.repos.pwc.inspect_result.astooke_rlpyt.launching.affinity.affinity_from_code", "home.repos.pwc.inspect_result.astooke_rlpyt.launching.variant.load_variant", "home.repos.pwc.inspect_result.astooke_rlpyt.launching.variant.update_config", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.context.logger_context", "home.repos.pwc.inspect_result.astooke_rlpyt.runners.minibatch_rl.MinibatchRlEval.train"], ["def", "build_and_train", "(", "slot_affinity_code", ",", "log_dir", ",", "run_ID", ",", "config_key", ")", ":", "\n", "    ", "affinity", "=", "affinity_from_code", "(", "slot_affinity_code", ")", "\n", "config", "=", "configs", "[", "config_key", "]", "\n", "variant", "=", "load_variant", "(", "log_dir", ")", "\n", "config", "=", "update_config", "(", "config", ",", "variant", ")", "\n", "config", "[", "\"eval_env\"", "]", "[", "\"game\"", "]", "=", "config", "[", "\"env\"", "]", "[", "\"game\"", "]", "\n", "\n", "sampler", "=", "AsyncAlternatingSampler", "(", "\n", "EnvCls", "=", "AtariEnv", ",", "\n", "env_kwargs", "=", "config", "[", "\"env\"", "]", ",", "\n", "CollectorCls", "=", "DbGpuResetCollector", ",", "\n", "TrajInfoCls", "=", "AtariTrajInfo", ",", "\n", "eval_env_kwargs", "=", "config", "[", "\"eval_env\"", "]", ",", "\n", "**", "config", "[", "\"sampler\"", "]", "\n", ")", "\n", "algo", "=", "R2D1", "(", "optim_kwargs", "=", "config", "[", "\"optim\"", "]", ",", "**", "config", "[", "\"algo\"", "]", ")", "\n", "agent", "=", "AtariR2d1AlternatingAgent", "(", "model_kwargs", "=", "config", "[", "\"model\"", "]", ",", "\n", "**", "config", "[", "\"agent\"", "]", ")", "\n", "runner", "=", "AsyncRlEval", "(", "\n", "algo", "=", "algo", ",", "\n", "agent", "=", "agent", ",", "\n", "sampler", "=", "sampler", ",", "\n", "affinity", "=", "affinity", ",", "\n", "**", "config", "[", "\"runner\"", "]", "\n", ")", "\n", "name", "=", "\"async_alt_\"", "+", "config", "[", "\"env\"", "]", "[", "\"game\"", "]", "\n", "with", "logger_context", "(", "log_dir", ",", "run_ID", ",", "name", ",", "config", ")", ":", "\n", "        ", "runner", ".", "train", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.train.atari_ppo_from_ul_serial.build_and_train": [[22, 63], ["rlpyt.utils.launching.affinity.affinity_from_code", "rlpyt.utils.launching.variant.load_variant", "rlpyt.utils.launching.variant.update_config", "pprint.pprint", "rlpyt.samplers.serial.sampler.SerialSampler", "rlpyt.algos.pg.ppo.PPO", "rlpyt.ul.agents.atari_pg_agent.AtariPgAgent", "rlpyt.runners.minibatch_rl.MinibatchRl", "[].lstrip", "os.join", "rlpyt.utils.logging.context.logger_context", "rlpyt.runners.minibatch_rl.MinibatchRl.train", "[].lstrip.split", "log_dir.split"], "function", ["home.repos.pwc.inspect_result.astooke_rlpyt.launching.affinity.affinity_from_code", "home.repos.pwc.inspect_result.astooke_rlpyt.launching.variant.load_variant", "home.repos.pwc.inspect_result.astooke_rlpyt.launching.variant.update_config", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.context.logger_context", "home.repos.pwc.inspect_result.astooke_rlpyt.runners.minibatch_rl.MinibatchRlEval.train"], ["def", "build_and_train", "(", "\n", "slot_affinity_code", "=", "\"0slt_1gpu_1cpu\"", ",", "\n", "log_dir", "=", "\"test\"", ",", "\n", "run_ID", "=", "\"0\"", ",", "\n", "config_key", "=", "\"ppo_16env\"", ",", "\n", "experiment_title", "=", "\"exp\"", ",", "\n", ")", ":", "\n", "    ", "affinity", "=", "affinity_from_code", "(", "slot_affinity_code", ")", "\n", "config", "=", "configs", "[", "config_key", "]", "\n", "variant", "=", "load_variant", "(", "log_dir", ")", "\n", "config", "=", "update_config", "(", "config", ",", "variant", ")", "\n", "\n", "# Hack that the first part of the log_dir matches the source of the model", "\n", "model_base_dir", "=", "config", "[", "\"pretrain\"", "]", "[", "\"model_dir\"", "]", "\n", "if", "model_base_dir", "is", "not", "None", ":", "\n", "        ", "raw_log_dir", "=", "log_dir", ".", "split", "(", "experiment_title", ")", "[", "-", "1", "]", ".", "lstrip", "(", "\"/\"", ")", "# get rid of ~/GitRepos/adam/rlpyt/data/local/<timestamp>/", "\n", "model_sub_dir", "=", "raw_log_dir", ".", "split", "(", "\"/RlFromUl/\"", ")", "[", "0", "]", "# keep the UL part, which comes first", "\n", "config", "[", "\"agent\"", "]", "[", "\"state_dict_filename\"", "]", "=", "osp", ".", "join", "(", "model_base_dir", ",", "\n", "model_sub_dir", ",", "\"run_0/params.pkl\"", ")", "\n", "", "pprint", ".", "pprint", "(", "config", ")", "\n", "\n", "sampler", "=", "SerialSampler", "(", "\n", "EnvCls", "=", "AtariEnv84", ",", "\n", "env_kwargs", "=", "config", "[", "\"env\"", "]", ",", "\n", "CollectorCls", "=", "CpuResetCollector", ",", "\n", "TrajInfoCls", "=", "AtariTrajInfo", ",", "\n", "eval_env_kwargs", "=", "config", "[", "\"env\"", "]", ",", "# Same args!", "\n", "**", "config", "[", "\"sampler\"", "]", "\n", ")", "\n", "algo", "=", "PPO", "(", "optim_kwargs", "=", "config", "[", "\"optim\"", "]", ",", "**", "config", "[", "\"algo\"", "]", ")", "\n", "agent", "=", "AtariPgAgent", "(", "model_kwargs", "=", "config", "[", "\"model\"", "]", ",", "**", "config", "[", "\"agent\"", "]", ")", "\n", "runner", "=", "MinibatchRl", "(", "\n", "algo", "=", "algo", ",", "\n", "agent", "=", "agent", ",", "\n", "sampler", "=", "sampler", ",", "\n", "affinity", "=", "affinity", ",", "\n", "**", "config", "[", "\"runner\"", "]", "\n", ")", "\n", "name", "=", "config", "[", "\"env\"", "]", "[", "\"game\"", "]", "\n", "with", "logger_context", "(", "log_dir", ",", "run_ID", ",", "name", ",", "config", ")", ":", "\n", "        ", "runner", ".", "train", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.train.dmc_sac_from_ul_serial.build_and_train": [[19, 67], ["rlpyt.utils.launching.affinity.affinity_from_code", "rlpyt.utils.launching.variant.load_variant", "rlpyt.utils.launching.variant.update_config", "pprint.pprint", "rlpyt.samplers.serial.sampler.SerialSampler", "rlpyt.ul.algos.rl_from_ul.rad_sac_from_ul.RadSacFromUl", "rlpyt.ul.agents.dmc_sac_agent.SacAgent", "rlpyt.adam.envstep_runner.MinibatchRlEvalEnvStep", "[].lstrip", "os.join", "rlpyt.utils.logging.context.logger_context", "rlpyt.adam.envstep_runner.MinibatchRlEvalEnvStep.train", "[].lstrip.split", "log_dir.split"], "function", ["home.repos.pwc.inspect_result.astooke_rlpyt.launching.affinity.affinity_from_code", "home.repos.pwc.inspect_result.astooke_rlpyt.launching.variant.load_variant", "home.repos.pwc.inspect_result.astooke_rlpyt.launching.variant.update_config", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.context.logger_context", "home.repos.pwc.inspect_result.astooke_rlpyt.runners.minibatch_rl.MinibatchRlEval.train"], ["def", "build_and_train", "(", "\n", "slot_affinity_code", "=", "\"0slt_1gpu_1cpu\"", ",", "\n", "log_dir", "=", "\"test\"", ",", "\n", "run_ID", "=", "\"0\"", ",", "\n", "config_key", "=", "\"serial_radsac\"", ",", "\n", "experiment_title", "=", "\"exp\"", ",", "\n", ")", ":", "\n", "    ", "affinity", "=", "affinity_from_code", "(", "slot_affinity_code", ")", "\n", "config", "=", "configs", "[", "config_key", "]", "\n", "variant", "=", "load_variant", "(", "log_dir", ")", "\n", "config", "=", "update_config", "(", "config", ",", "variant", ")", "\n", "\n", "# Hack that the first part of the log_dir matches the source of the model", "\n", "model_base_dir", "=", "config", "[", "\"pretrain\"", "]", "[", "\"model_dir\"", "]", "\n", "if", "model_base_dir", "is", "not", "None", ":", "\n", "        ", "raw_log_dir", "=", "log_dir", ".", "split", "(", "experiment_title", ")", "[", "-", "1", "]", ".", "lstrip", "(", "\"/\"", ")", "# get rid of ~/GitRepos/adam/rlpyt/data/local/<timestamp>/", "\n", "model_sub_dir", "=", "raw_log_dir", ".", "split", "(", "\"/RlFromUl/\"", ")", "[", "0", "]", "# keep the UL part, which comes first", "\n", "pretrain_ID", "=", "config", "[", "\"pretrain\"", "]", "[", "\"run_ID\"", "]", "\n", "config", "[", "\"agent\"", "]", "[", "\"state_dict_filename\"", "]", "=", "osp", ".", "join", "(", "model_base_dir", ",", "\n", "model_sub_dir", ",", "f\"run_{pretrain_ID}/params.pkl\"", ")", "\n", "\n", "", "pprint", ".", "pprint", "(", "config", ")", "\n", "\n", "sampler", "=", "SerialSampler", "(", "\n", "EnvCls", "=", "make", ",", "\n", "env_kwargs", "=", "config", "[", "\"env\"", "]", ",", "\n", "CollectorCls", "=", "CpuResetCollector", ",", "\n", "eval_env_kwargs", "=", "config", "[", "\"env\"", "]", ",", "# Same args!", "\n", "**", "config", "[", "\"sampler\"", "]", "\n", ")", "\n", "algo", "=", "RadSacFromUl", "(", "**", "config", "[", "\"algo\"", "]", ")", "\n", "agent", "=", "SacAgent", "(", "\n", "conv_kwargs", "=", "config", "[", "\"conv\"", "]", ",", "\n", "fc1_kwargs", "=", "config", "[", "\"fc1\"", "]", ",", "\n", "pi_model_kwargs", "=", "config", "[", "\"pi_model\"", "]", ",", "\n", "q_model_kwargs", "=", "config", "[", "\"q_model\"", "]", ",", "\n", "**", "config", "[", "\"agent\"", "]", ")", "\n", "runner", "=", "MinibatchRlEvalEnvStep", "(", "\n", "algo", "=", "algo", ",", "\n", "agent", "=", "agent", ",", "\n", "sampler", "=", "sampler", ",", "\n", "affinity", "=", "affinity", ",", "\n", "frame_skip", "=", "config", "[", "\"env\"", "]", "[", "\"frame_skip\"", "]", ",", "\n", "**", "config", "[", "\"runner\"", "]", "\n", ")", "\n", "name", "=", "config", "[", "\"env\"", "]", "[", "\"domain_name\"", "]", "+", "\"_\"", "+", "config", "[", "\"env\"", "]", "[", "\"task_name\"", "]", "\n", "with", "logger_context", "(", "log_dir", ",", "run_ID", ",", "name", ",", "config", ")", ":", "\n", "        ", "runner", ".", "train", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.train.dmlab_ppo_from_ul_alt.build_and_train": [[24, 70], ["rlpyt.utils.launching.affinity.affinity_from_code", "rlpyt.utils.launching.variant.load_variant", "rlpyt.utils.launching.variant.update_config", "pprint.pprint", "rlpyt.samplers.parallel.gpu.alternating_sampler.AlternatingSampler", "rlpyt.algos.pg.ppo.PPO", "rlpyt.ul.agents.dmlab_pg_agent.DmlabPgLstmAlternatingAgent", "rlpyt.runners.minibatch_rl.MinibatchRl", "[].lstrip", "os.join", "int", "rlpyt.utils.logging.context.logger_context", "rlpyt.runners.minibatch_rl.MinibatchRl.train", "[].lstrip.split", "log_dir.split"], "function", ["home.repos.pwc.inspect_result.astooke_rlpyt.launching.affinity.affinity_from_code", "home.repos.pwc.inspect_result.astooke_rlpyt.launching.variant.load_variant", "home.repos.pwc.inspect_result.astooke_rlpyt.launching.variant.update_config", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.context.logger_context", "home.repos.pwc.inspect_result.astooke_rlpyt.runners.minibatch_rl.MinibatchRlEval.train"], ["def", "build_and_train", "(", "\n", "slot_affinity_code", "=", "\"0slt_1gpu_1cpu\"", ",", "\n", "log_dir", "=", "\"test\"", ",", "\n", "run_ID", "=", "\"0\"", ",", "\n", "config_key", "=", "\"ppo_16env\"", ",", "\n", "experiment_title", "=", "\"exp\"", ",", "\n", "snapshot_mode", "=", "\"none\"", ",", "\n", "snapshot_gap", "=", "None", ",", "\n", ")", ":", "\n", "    ", "affinity", "=", "affinity_from_code", "(", "slot_affinity_code", ")", "\n", "config", "=", "configs", "[", "config_key", "]", "\n", "variant", "=", "load_variant", "(", "log_dir", ")", "\n", "config", "=", "update_config", "(", "config", ",", "variant", ")", "\n", "\n", "# Hack that the first part of the log_dir matches the source of the model", "\n", "model_base_dir", "=", "config", "[", "\"pretrain\"", "]", "[", "\"model_dir\"", "]", "\n", "if", "model_base_dir", "is", "not", "None", ":", "\n", "        ", "raw_log_dir", "=", "log_dir", ".", "split", "(", "experiment_title", ")", "[", "-", "1", "]", ".", "lstrip", "(", "\"/\"", ")", "# get rid of ~/GitRepos/adam/rlpyt/data/local/<timestamp>/", "\n", "model_sub_dir", "=", "raw_log_dir", ".", "split", "(", "\"/RlFromUl/\"", ")", "[", "0", "]", "# keep the UL part, which comes first", "\n", "config", "[", "\"agent\"", "]", "[", "\"state_dict_filename\"", "]", "=", "osp", ".", "join", "(", "model_base_dir", ",", "\n", "model_sub_dir", ",", "\"run_0/params.pkl\"", ")", "\n", "", "pprint", ".", "pprint", "(", "config", ")", "\n", "\n", "sampler", "=", "AlternatingSampler", "(", "\n", "EnvCls", "=", "DmlabEnv", ",", "\n", "env_kwargs", "=", "config", "[", "\"env\"", "]", ",", "\n", "CollectorCls", "=", "GpuWaitResetCollector", ",", "\n", "# TrajInfoCls=AtariTrajInfo,", "\n", "# eval_env_kwargs=config[\"env\"],  # Same args!", "\n", "**", "config", "[", "\"sampler\"", "]", "\n", ")", "\n", "algo", "=", "PPO", "(", "optim_kwargs", "=", "config", "[", "\"optim\"", "]", ",", "**", "config", "[", "\"algo\"", "]", ")", "\n", "agent", "=", "DmlabPgLstmAlternatingAgent", "(", "model_kwargs", "=", "config", "[", "\"model\"", "]", ",", "**", "config", "[", "\"agent\"", "]", ")", "\n", "runner", "=", "MinibatchRl", "(", "\n", "algo", "=", "algo", ",", "\n", "agent", "=", "agent", ",", "\n", "sampler", "=", "sampler", ",", "\n", "affinity", "=", "affinity", ",", "\n", "**", "config", "[", "\"runner\"", "]", "\n", ")", "\n", "name", "=", "config", "[", "\"env\"", "]", "[", "\"level\"", "]", "\n", "if", "snapshot_gap", "is", "not", "None", ":", "\n", "        ", "snapshot_gap", "=", "int", "(", "snapshot_gap", ")", "\n", "", "with", "logger_context", "(", "log_dir", ",", "run_ID", ",", "name", ",", "config", ",", "\n", "snapshot_mode", "=", "snapshot_mode", ",", "snapshot_gap", "=", "snapshot_gap", ")", ":", "\n", "        ", "runner", ".", "train", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.train.atari_dqn_with_ul_serial.build_and_train": [[19, 52], ["rlpyt.utils.launching.affinity.affinity_from_code", "rlpyt.utils.launching.variant.load_variant", "rlpyt.utils.launching.variant.update_config", "pprint.pprint", "rlpyt.samplers.serial.sampler.SerialSampler", "rlpyt.ul.algos.rl_with_ul.dqn_with_ul.DqnUl", "rlpyt.ul.agents.atari_dqn_agent.AtariDqnAgent", "rlpyt.runners.minibatch_rl.MinibatchRlEval", "rlpyt.utils.logging.context.logger_context", "rlpyt.runners.minibatch_rl.MinibatchRlEval.train"], "function", ["home.repos.pwc.inspect_result.astooke_rlpyt.launching.affinity.affinity_from_code", "home.repos.pwc.inspect_result.astooke_rlpyt.launching.variant.load_variant", "home.repos.pwc.inspect_result.astooke_rlpyt.launching.variant.update_config", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.context.logger_context", "home.repos.pwc.inspect_result.astooke_rlpyt.runners.minibatch_rl.MinibatchRlEval.train"], ["def", "build_and_train", "(", "\n", "slot_affinity_code", "=", "\"0slt_1gpu_1cpu\"", ",", "\n", "log_dir", "=", "\"test\"", ",", "\n", "run_ID", "=", "\"0\"", ",", "\n", "config_key", "=", "\"scaled_ddqn_ul\"", ",", "\n", ")", ":", "\n", "    ", "affinity", "=", "affinity_from_code", "(", "slot_affinity_code", ")", "\n", "config", "=", "configs", "[", "config_key", "]", "\n", "variant", "=", "load_variant", "(", "log_dir", ")", "\n", "config", "=", "update_config", "(", "config", ",", "variant", ")", "\n", "\n", "pprint", ".", "pprint", "(", "config", ")", "\n", "\n", "sampler", "=", "SerialSampler", "(", "\n", "EnvCls", "=", "AtariEnv84", ",", "\n", "env_kwargs", "=", "config", "[", "\"env\"", "]", ",", "\n", "CollectorCls", "=", "CpuResetCollector", ",", "\n", "TrajInfoCls", "=", "AtariTrajInfo", ",", "\n", "eval_env_kwargs", "=", "config", "[", "\"env\"", "]", ",", "# Same args!", "\n", "**", "config", "[", "\"sampler\"", "]", "\n", ")", "\n", "algo", "=", "DqnUl", "(", "optim_kwargs", "=", "config", "[", "\"optim\"", "]", ",", "**", "config", "[", "\"algo\"", "]", ")", "\n", "agent", "=", "AtariDqnAgent", "(", "model_kwargs", "=", "config", "[", "\"model\"", "]", ",", "**", "config", "[", "\"agent\"", "]", ")", "\n", "runner", "=", "MinibatchRlEval", "(", "\n", "algo", "=", "algo", ",", "\n", "agent", "=", "agent", ",", "\n", "sampler", "=", "sampler", ",", "\n", "affinity", "=", "affinity", ",", "\n", "**", "config", "[", "\"runner\"", "]", "\n", ")", "\n", "name", "=", "config", "[", "\"env\"", "]", "[", "\"game\"", "]", "\n", "with", "logger_context", "(", "log_dir", ",", "run_ID", ",", "name", ",", "config", ")", ":", "\n", "        ", "runner", ".", "train", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.train.atari_ppo_with_ul_serial_test.build_and_train": [[23, 74], ["rlpyt.utils.launching.affinity.affinity_from_code", "pprint.pprint", "rlpyt.samplers.serial.sampler.SerialSampler", "rlpyt.ul.algos.ppo_ul.PpoUl", "rlpyt.ul.agents.atari_pg_rl_with_ul_agent.AtariPgRlWithUlAgent", "rlpyt.runners.minibatch_rl.MinibatchRl", "rlpyt.utils.logging.context.logger_context", "rlpyt.runners.minibatch_rl.MinibatchRl.train"], "function", ["home.repos.pwc.inspect_result.astooke_rlpyt.launching.affinity.affinity_from_code", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.context.logger_context", "home.repos.pwc.inspect_result.astooke_rlpyt.runners.minibatch_rl.MinibatchRlEval.train"], ["def", "build_and_train", "(", "\n", "slot_affinity_code", "=", "\"0slt_0gpu_4cpu_4cpr\"", ",", "\n", "log_dir", "=", "\"test\"", ",", "\n", "run_ID", "=", "\"0\"", ",", "\n", "config_key", "=", "\"ppo_ul_16env\"", "\n", ")", ":", "\n", "    ", "affinity", "=", "affinity_from_code", "(", "slot_affinity_code", ")", "\n", "config", "=", "configs", "[", "config_key", "]", "\n", "# variant = load_variant(log_dir)", "\n", "# config = update_config(config, variant)", "\n", "\n", "\n", "# config[\"sampler\"][\"batch_B\"] = 4", "\n", "# config[\"sampler\"][\"batch_T\"] = 5", "\n", "# config[\"runner\"][\"log_interval_steps\"] = 100", "\n", "# config[\"runner\"][\"n_steps\"] = 1000", "\n", "config", "[", "\"algo\"", "]", "[", "\"ul_update_schedule\"", "]", "=", "\"constant_1\"", "\n", "config", "[", "\"algo\"", "]", "[", "\"min_steps_rl\"", "]", "=", "1e3", "\n", "config", "[", "\"algo\"", "]", "[", "\"min_steps_ul\"", "]", "=", "200", "\n", "config", "[", "\"algo\"", "]", "[", "\"max_steps_ul\"", "]", "=", "20e6", "\n", "config", "[", "\"model\"", "]", "[", "\"stop_conv_grad\"", "]", "=", "True", "\n", "config", "[", "\"sampler\"", "]", "[", "\"max_decorrelation_steps\"", "]", "=", "0", "\n", "config", "[", "\"sampler\"", "]", "[", "\"batch_B\"", "]", "=", "3", "\n", "config", "[", "\"sampler\"", "]", "[", "\"batch_T\"", "]", "=", "20", "\n", "config", "[", "\"algo\"", "]", "[", "\"ul_pri_alpha\"", "]", "=", "1.", "\n", "config", "[", "\"algo\"", "]", "[", "\"ul_pri_n_step_return\"", "]", "=", "10", "\n", "config", "[", "\"algo\"", "]", "[", "\"ul_replay_size\"", "]", "=", "900", "\n", "\n", "\n", "pprint", ".", "pprint", "(", "config", ")", "\n", "\n", "sampler", "=", "SerialSampler", "(", "\n", "EnvCls", "=", "AtariEnv84", ",", "\n", "env_kwargs", "=", "config", "[", "\"env\"", "]", ",", "\n", "CollectorCls", "=", "CpuResetCollector", ",", "\n", "TrajInfoCls", "=", "AtariTrajInfo", ",", "\n", "eval_env_kwargs", "=", "config", "[", "\"env\"", "]", ",", "# Same args!", "\n", "**", "config", "[", "\"sampler\"", "]", "\n", ")", "\n", "algo", "=", "PpoUl", "(", "optim_kwargs", "=", "config", "[", "\"optim\"", "]", ",", "**", "config", "[", "\"algo\"", "]", ")", "\n", "agent", "=", "AtariPgRlWithUlAgent", "(", "model_kwargs", "=", "config", "[", "\"model\"", "]", ",", "**", "config", "[", "\"agent\"", "]", ")", "\n", "runner", "=", "MinibatchRl", "(", "\n", "algo", "=", "algo", ",", "\n", "agent", "=", "agent", ",", "\n", "sampler", "=", "sampler", ",", "\n", "affinity", "=", "affinity", ",", "\n", "**", "config", "[", "\"runner\"", "]", "\n", ")", "\n", "name", "=", "config", "[", "\"env\"", "]", "[", "\"game\"", "]", "\n", "with", "logger_context", "(", "log_dir", ",", "run_ID", ",", "name", ",", "config", ")", ":", "\n", "        ", "runner", ".", "train", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.train.atari_ppo_with_ul_serial.build_and_train": [[19, 52], ["rlpyt.utils.launching.affinity.affinity_from_code", "rlpyt.utils.launching.variant.load_variant", "rlpyt.utils.launching.variant.update_config", "pprint.pprint", "rlpyt.samplers.serial.sampler.SerialSampler", "rlpyt.ul.algos.rl_with_ul.ppo_with_ul.PpoUl", "rlpyt.ul.agents.atari_pg_agent.AtariPgAgent", "rlpyt.runners.minibatch_rl.MinibatchRl", "rlpyt.utils.logging.context.logger_context", "rlpyt.runners.minibatch_rl.MinibatchRl.train"], "function", ["home.repos.pwc.inspect_result.astooke_rlpyt.launching.affinity.affinity_from_code", "home.repos.pwc.inspect_result.astooke_rlpyt.launching.variant.load_variant", "home.repos.pwc.inspect_result.astooke_rlpyt.launching.variant.update_config", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.context.logger_context", "home.repos.pwc.inspect_result.astooke_rlpyt.runners.minibatch_rl.MinibatchRlEval.train"], ["def", "build_and_train", "(", "\n", "slot_affinity_code", "=", "\"0slt_1gpu_1cpu\"", ",", "\n", "log_dir", "=", "\"test\"", ",", "\n", "run_ID", "=", "\"0\"", ",", "\n", "config_key", "=", "\"ppo_ul_16env\"", ",", "\n", ")", ":", "\n", "    ", "affinity", "=", "affinity_from_code", "(", "slot_affinity_code", ")", "\n", "config", "=", "configs", "[", "config_key", "]", "\n", "variant", "=", "load_variant", "(", "log_dir", ")", "\n", "config", "=", "update_config", "(", "config", ",", "variant", ")", "\n", "\n", "pprint", ".", "pprint", "(", "config", ")", "\n", "\n", "sampler", "=", "SerialSampler", "(", "\n", "EnvCls", "=", "AtariEnv84", ",", "\n", "env_kwargs", "=", "config", "[", "\"env\"", "]", ",", "\n", "CollectorCls", "=", "CpuResetCollector", ",", "\n", "TrajInfoCls", "=", "AtariTrajInfo", ",", "\n", "eval_env_kwargs", "=", "config", "[", "\"env\"", "]", ",", "# Same args!", "\n", "**", "config", "[", "\"sampler\"", "]", "\n", ")", "\n", "algo", "=", "PpoUl", "(", "optim_kwargs", "=", "config", "[", "\"optim\"", "]", ",", "**", "config", "[", "\"algo\"", "]", ")", "\n", "agent", "=", "AtariPgAgent", "(", "model_kwargs", "=", "config", "[", "\"model\"", "]", ",", "**", "config", "[", "\"agent\"", "]", ")", "\n", "runner", "=", "MinibatchRl", "(", "\n", "algo", "=", "algo", ",", "\n", "agent", "=", "agent", ",", "\n", "sampler", "=", "sampler", ",", "\n", "affinity", "=", "affinity", ",", "\n", "**", "config", "[", "\"runner\"", "]", "\n", ")", "\n", "name", "=", "config", "[", "\"env\"", "]", "[", "\"game\"", "]", "\n", "with", "logger_context", "(", "log_dir", ",", "run_ID", ",", "name", ",", "config", ")", ":", "\n", "        ", "runner", ".", "train", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.train.dmc_sac_with_ul_serial.build_and_train": [[18, 57], ["rlpyt.utils.launching.affinity.affinity_from_code", "rlpyt.utils.launching.variant.load_variant", "rlpyt.utils.launching.variant.update_config", "pprint.pprint", "rlpyt.samplers.serial.sampler.SerialSampler", "rlpyt.ul.algos.rl_with_ul.sac_with_ul.SacWithUl", "rlpyt.ul.agents.dmc_sac_agent.SacAgent", "rlpyt.adam.envstep_runner.MinibatchRlEvalEnvStep", "rlpyt.utils.logging.context.logger_context", "rlpyt.adam.envstep_runner.MinibatchRlEvalEnvStep.train"], "function", ["home.repos.pwc.inspect_result.astooke_rlpyt.launching.affinity.affinity_from_code", "home.repos.pwc.inspect_result.astooke_rlpyt.launching.variant.load_variant", "home.repos.pwc.inspect_result.astooke_rlpyt.launching.variant.update_config", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.context.logger_context", "home.repos.pwc.inspect_result.astooke_rlpyt.runners.minibatch_rl.MinibatchRlEval.train"], ["def", "build_and_train", "(", "\n", "slot_affinity_code", "=", "\"0slt_1gpu_1cpu\"", ",", "\n", "log_dir", "=", "\"test\"", ",", "\n", "run_ID", "=", "\"0\"", ",", "\n", "config_key", "=", "\"sac_with_ul\"", ",", "\n", ")", ":", "\n", "    ", "affinity", "=", "affinity_from_code", "(", "slot_affinity_code", ")", "\n", "config", "=", "configs", "[", "config_key", "]", "\n", "variant", "=", "load_variant", "(", "log_dir", ")", "\n", "config", "=", "update_config", "(", "config", ",", "variant", ")", "\n", "\n", "pprint", ".", "pprint", "(", "config", ")", "\n", "\n", "sampler", "=", "SerialSampler", "(", "\n", "EnvCls", "=", "make", ",", "\n", "env_kwargs", "=", "config", "[", "\"env\"", "]", ",", "\n", "CollectorCls", "=", "CpuResetCollector", ",", "\n", "# TrajInfoCls=AtariTrajInfo,", "\n", "eval_env_kwargs", "=", "config", "[", "\"env\"", "]", ",", "# Same args!", "\n", "**", "config", "[", "\"sampler\"", "]", "\n", ")", "\n", "algo", "=", "SacWithUl", "(", "**", "config", "[", "\"algo\"", "]", ")", "\n", "agent", "=", "SacAgent", "(", "\n", "conv_kwargs", "=", "config", "[", "\"conv\"", "]", ",", "\n", "fc1_kwargs", "=", "config", "[", "\"fc1\"", "]", ",", "\n", "pi_model_kwargs", "=", "config", "[", "\"pi_model\"", "]", ",", "\n", "q_model_kwargs", "=", "config", "[", "\"q_model\"", "]", ",", "\n", "**", "config", "[", "\"agent\"", "]", ")", "\n", "runner", "=", "MinibatchRlEvalEnvStep", "(", "\n", "algo", "=", "algo", ",", "\n", "agent", "=", "agent", ",", "\n", "sampler", "=", "sampler", ",", "\n", "affinity", "=", "affinity", ",", "\n", "frame_skip", "=", "config", "[", "\"env\"", "]", "[", "\"frame_skip\"", "]", ",", "\n", "**", "config", "[", "\"runner\"", "]", "\n", ")", "\n", "name", "=", "config", "[", "\"env\"", "]", "[", "\"domain_name\"", "]", "+", "\"_\"", "+", "config", "[", "\"env\"", "]", "[", "\"task_name\"", "]", "\n", "with", "logger_context", "(", "log_dir", ",", "run_ID", ",", "name", ",", "config", ")", ":", "\n", "        ", "runner", ".", "train", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.train.dmc_sac_with_ul_serial_test.build_and_train": [[18, 69], ["rlpyt.utils.launching.affinity.affinity_from_code", "pprint.pprint", "rlpyt.samplers.serial.sampler.SerialSampler", "rlpyt.ul.algos.sac_ul.SacUl", "rlpyt.ul.agents.dmc_sac_with_ul_agent.SacWithUlAgent", "rlpyt.adam.envstep_runner.MinibatchRlEvalEnvStep", "rlpyt.utils.logging.context.logger_context", "rlpyt.adam.envstep_runner.MinibatchRlEvalEnvStep.train"], "function", ["home.repos.pwc.inspect_result.astooke_rlpyt.launching.affinity.affinity_from_code", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.context.logger_context", "home.repos.pwc.inspect_result.astooke_rlpyt.runners.minibatch_rl.MinibatchRlEval.train"], ["def", "build_and_train", "(", "\n", "slot_affinity_code", "=", "\"0slt_0gpu_4cpu_4cpr\"", ",", "\n", "log_dir", "=", "\"test\"", ",", "\n", "run_ID", "=", "\"0\"", ",", "\n", "config_key", "=", "\"sac_ul_compress\"", ",", "\n", ")", ":", "\n", "    ", "affinity", "=", "affinity_from_code", "(", "slot_affinity_code", ")", "\n", "config", "=", "configs", "[", "config_key", "]", "\n", "# variant = load_variant(log_dir)", "\n", "# config = update_config(config, variant)", "\n", "\n", "config", "[", "\"algo\"", "]", "[", "\"min_steps_rl\"", "]", "=", "100", "\n", "config", "[", "\"algo\"", "]", "[", "\"min_steps_ul\"", "]", "=", "150", "\n", "config", "[", "\"algo\"", "]", "[", "\"replay_size\"", "]", "=", "1e4", "\n", "config", "[", "\"algo\"", "]", "[", "\"batch_size\"", "]", "=", "64", "\n", "config", "[", "\"algo\"", "]", "[", "\"ul_batch_size\"", "]", "=", "32", "\n", "config", "[", "\"runner\"", "]", "[", "\"n_steps\"", "]", "=", "1e3", "\n", "config", "[", "\"runner\"", "]", "[", "\"log_interval_steps\"", "]", "=", "1e2", "\n", "config", "[", "\"sampler\"", "]", "[", "\"eval_n_envs\"", "]", "=", "1", "\n", "config", "[", "\"sampler\"", "]", "[", "\"eval_max_steps\"", "]", "=", "500", "\n", "config", "[", "\"algo\"", "]", "[", "\"stop_rl_conv_grad\"", "]", "=", "True", "\n", "config", "[", "\"algo\"", "]", "[", "\"ul_update_schedule\"", "]", "=", "\"cosine_8\"", "\n", "\n", "pprint", ".", "pprint", "(", "config", ")", "\n", "\n", "sampler", "=", "SerialSampler", "(", "\n", "EnvCls", "=", "make", ",", "\n", "env_kwargs", "=", "config", "[", "\"env\"", "]", ",", "\n", "CollectorCls", "=", "CpuResetCollector", ",", "\n", "# TrajInfoCls=AtariTrajInfo,", "\n", "eval_env_kwargs", "=", "config", "[", "\"env\"", "]", ",", "# Same args!", "\n", "**", "config", "[", "\"sampler\"", "]", "\n", ")", "\n", "algo", "=", "SacUl", "(", "**", "config", "[", "\"algo\"", "]", ")", "\n", "agent", "=", "SacWithUlAgent", "(", "\n", "conv_kwargs", "=", "config", "[", "\"conv\"", "]", ",", "\n", "fc1_kwargs", "=", "config", "[", "\"fc1\"", "]", ",", "\n", "pi_model_kwargs", "=", "config", "[", "\"pi_model\"", "]", ",", "\n", "q_model_kwargs", "=", "config", "[", "\"q_model\"", "]", ",", "\n", "**", "config", "[", "\"agent\"", "]", ")", "\n", "runner", "=", "MinibatchRlEvalEnvStep", "(", "\n", "algo", "=", "algo", ",", "\n", "agent", "=", "agent", ",", "\n", "sampler", "=", "sampler", ",", "\n", "affinity", "=", "affinity", ",", "\n", "frame_skip", "=", "config", "[", "\"env\"", "]", "[", "\"frame_skip\"", "]", ",", "\n", "**", "config", "[", "\"runner\"", "]", "\n", ")", "\n", "name", "=", "config", "[", "\"env\"", "]", "[", "\"domain_name\"", "]", "+", "\"_\"", "+", "config", "[", "\"env\"", "]", "[", "\"task_name\"", "]", "\n", "with", "logger_context", "(", "log_dir", ",", "run_ID", ",", "name", ",", "config", ")", ":", "\n", "        ", "runner", ".", "train", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.train.dmlab_ppo_with_ul_alt.build_and_train": [[18, 54], ["rlpyt.utils.launching.affinity.affinity_from_code", "rlpyt.utils.launching.variant.load_variant", "rlpyt.utils.launching.variant.update_config", "pprint.pprint", "rlpyt.samplers.parallel.gpu.alternating_sampler.AlternatingSampler", "rlpyt.ul.algos.rl_with_ul.ppo_with_ul.PpoUl", "rlpyt.ul.agents.dmlab_pg_agent.DmlabPgLstmAlternatingAgent", "rlpyt.runners.minibatch_rl.MinibatchRl", "int", "rlpyt.utils.logging.context.logger_context", "rlpyt.runners.minibatch_rl.MinibatchRl.train"], "function", ["home.repos.pwc.inspect_result.astooke_rlpyt.launching.affinity.affinity_from_code", "home.repos.pwc.inspect_result.astooke_rlpyt.launching.variant.load_variant", "home.repos.pwc.inspect_result.astooke_rlpyt.launching.variant.update_config", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.context.logger_context", "home.repos.pwc.inspect_result.astooke_rlpyt.runners.minibatch_rl.MinibatchRlEval.train"], ["def", "build_and_train", "(", "\n", "slot_affinity_code", "=", "\"0slt_1gpu_1cpu\"", ",", "\n", "log_dir", "=", "\"test\"", ",", "\n", "run_ID", "=", "\"0\"", ",", "\n", "config_key", "=", "\"ppo_ul_16env\"", ",", "\n", "snapshot_mode", "=", "\"none\"", ",", "\n", "snapshot_gap", "=", "None", ",", "\n", ")", ":", "\n", "    ", "affinity", "=", "affinity_from_code", "(", "slot_affinity_code", ")", "\n", "config", "=", "configs", "[", "config_key", "]", "\n", "variant", "=", "load_variant", "(", "log_dir", ")", "\n", "config", "=", "update_config", "(", "config", ",", "variant", ")", "\n", "\n", "pprint", ".", "pprint", "(", "config", ")", "\n", "\n", "sampler", "=", "AlternatingSampler", "(", "\n", "EnvCls", "=", "DmlabEnv", ",", "\n", "env_kwargs", "=", "config", "[", "\"env\"", "]", ",", "\n", "CollectorCls", "=", "GpuWaitResetCollector", ",", "\n", "**", "config", "[", "\"sampler\"", "]", "\n", ")", "\n", "algo", "=", "PpoUl", "(", "optim_kwargs", "=", "config", "[", "\"optim\"", "]", ",", "**", "config", "[", "\"algo\"", "]", ")", "\n", "agent", "=", "DmlabPgLstmAlternatingAgent", "(", "model_kwargs", "=", "config", "[", "\"model\"", "]", ",", "**", "config", "[", "\"agent\"", "]", ")", "\n", "runner", "=", "MinibatchRl", "(", "\n", "algo", "=", "algo", ",", "\n", "agent", "=", "agent", ",", "\n", "sampler", "=", "sampler", ",", "\n", "affinity", "=", "affinity", ",", "\n", "**", "config", "[", "\"runner\"", "]", "\n", ")", "\n", "name", "=", "config", "[", "\"env\"", "]", "[", "\"level\"", "]", "\n", "if", "snapshot_gap", "is", "not", "None", ":", "\n", "        ", "snapshot_gap", "=", "int", "(", "snapshot_gap", ")", "\n", "", "with", "logger_context", "(", "log_dir", ",", "run_ID", ",", "name", ",", "config", ",", "\n", "snapshot_mode", "=", "snapshot_mode", ",", "snapshot_gap", "=", "snapshot_gap", ")", ":", "\n", "        ", "runner", ".", "train", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.train.train_cppo.build_and_train": [[18, 49], ["rlpyt.utils.launching.affinity.affinity_from_code", "rlpyt.utils.launching.variant.load_variant", "rlpyt.utils.launching.variant.update_config", "pprint.pprint", "rlpyt.samplers.parallel.cpu.sampler.CpuSampler", "rlpyt.projects.safe.cppo_pid.CppoPID", "rlpyt.projects.safe.cppo_agent.CppoLstmAgent", "rlpyt.runners.minibatch_rl.MinibatchRl", "rlpyt.utils.logging.context.logger_context", "rlpyt.runners.minibatch_rl.MinibatchRl.train"], "function", ["home.repos.pwc.inspect_result.astooke_rlpyt.launching.affinity.affinity_from_code", "home.repos.pwc.inspect_result.astooke_rlpyt.launching.variant.load_variant", "home.repos.pwc.inspect_result.astooke_rlpyt.launching.variant.update_config", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.context.logger_context", "home.repos.pwc.inspect_result.astooke_rlpyt.runners.minibatch_rl.MinibatchRlEval.train"], ["def", "build_and_train", "(", "\n", "slot_affinity_code", "=", "\"0slt_0gpu_1cpu_1cpr\"", ",", "\n", "log_dir", "=", "\"test\"", ",", "\n", "run_ID", "=", "\"0\"", ",", "\n", "config_key", "=", "\"LSTM\"", ",", "\n", ")", ":", "\n", "    ", "affinity", "=", "affinity_from_code", "(", "slot_affinity_code", ")", "\n", "config", "=", "configs", "[", "config_key", "]", "\n", "variant", "=", "load_variant", "(", "log_dir", ")", "\n", "config", "=", "update_config", "(", "config", ",", "variant", ")", "\n", "\n", "pprint", ".", "pprint", "(", "config", ")", "\n", "\n", "sampler", "=", "CpuSampler", "(", "\n", "EnvCls", "=", "safety_gym_make", ",", "\n", "env_kwargs", "=", "config", "[", "\"env\"", "]", ",", "\n", "TrajInfoCls", "=", "SafetyGymTrajInfo", ",", "\n", "**", "config", "[", "\"sampler\"", "]", "\n", ")", "\n", "algo", "=", "CppoPID", "(", "**", "config", "[", "\"algo\"", "]", ")", "\n", "agent", "=", "CppoLstmAgent", "(", "model_kwargs", "=", "config", "[", "\"model\"", "]", ",", "**", "config", "[", "\"agent\"", "]", ")", "\n", "runner", "=", "MinibatchRl", "(", "\n", "algo", "=", "algo", ",", "\n", "agent", "=", "agent", ",", "\n", "sampler", "=", "sampler", ",", "\n", "affinity", "=", "affinity", ",", "\n", "**", "config", "[", "\"runner\"", "]", ",", "\n", ")", "\n", "name", "=", "\"cppo_\"", "+", "config", "[", "\"env\"", "]", "[", "\"id\"", "]", "\n", "with", "logger_context", "(", "log_dir", ",", "run_ID", ",", "name", ",", "config", ")", ":", "\n", "        ", "runner", ".", "train", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.atari.mixin.AtariMixin.make_env_to_model_kwargs": [[5, 8], ["dict"], "methods", ["None"], ["    ", "def", "make_env_to_model_kwargs", "(", "self", ",", "env_spaces", ")", ":", "\n", "        ", "return", "dict", "(", "image_shape", "=", "env_spaces", ".", "observation", ".", "shape", ",", "\n", "output_size", "=", "env_spaces", ".", "action", ".", "n", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.astooke_rlpyt.atari.atari_r2d1_agent.AtariR2d1Agent.__init__": [[8, 10], ["rlpyt.agents.dqn.atari.mixin.AtariMixin.__init__"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.spaces.gym_wrapper.GymSpaceWrapper.__init__"], ["    ", "def", "__init__", "(", "self", ",", "ModelCls", "=", "AtariR2d1Model", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "ModelCls", "=", "ModelCls", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.atari.atari_r2d1_agent.AtariR2d1AlternatingAgent.__init__": [[14, 16], ["rlpyt.agents.dqn.atari.mixin.AtariMixin.__init__"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.spaces.gym_wrapper.GymSpaceWrapper.__init__"], ["    ", "def", "__init__", "(", "self", ",", "ModelCls", "=", "AtariR2d1Model", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "ModelCls", "=", "ModelCls", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.atari.atari_dqn_agent.AtariDqnAgent.__init__": [[9, 11], ["rlpyt.agents.dqn.atari.mixin.AtariMixin.__init__"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.spaces.gym_wrapper.GymSpaceWrapper.__init__"], ["    ", "def", "__init__", "(", "self", ",", "ModelCls", "=", "AtariDqnModel", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "ModelCls", "=", "ModelCls", ",", "**", "kwargs", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.astooke_rlpyt.atari.atari_catdqn_agent.AtariCatDqnAgent.__init__": [[8, 10], ["rlpyt.agents.dqn.atari.mixin.AtariMixin.__init__"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.spaces.gym_wrapper.GymSpaceWrapper.__init__"], ["    ", "def", "__init__", "(", "self", ",", "ModelCls", "=", "AtariCatDqnModel", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "ModelCls", "=", "ModelCls", ",", "**", "kwargs", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.astooke_rlpyt.atari.atari_env.AtariTrajInfo.__init__": [[24, 27], ["rlpyt.samplers.collections.TrajInfo.__init__"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.spaces.gym_wrapper.GymSpaceWrapper.__init__"], ["def", "__init__", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "self", ".", "GameScore", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.atari.atari_env.AtariTrajInfo.step": [[28, 31], ["super().step", "getattr"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.safe.safety_gym_env.SafetyGymTrajInfo.step"], ["", "def", "step", "(", "self", ",", "observation", ",", "action", ",", "reward", ",", "done", ",", "agent_info", ",", "env_info", ")", ":", "\n", "        ", "super", "(", ")", ".", "step", "(", "observation", ",", "action", ",", "reward", ",", "done", ",", "agent_info", ",", "env_info", ")", "\n", "self", ".", "GameScore", "+=", "getattr", "(", "env_info", ",", "\"game_score\"", ",", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.atari.atari_env.AtariEnv.__init__": [[67, 104], ["rlpyt.utils.quick_args.save__init__args", "atari_py.get_game_path", "atari_py.ALEInterface", "atari_env.AtariEnv.ale.setFloat", "atari_env.AtariEnv.ale.loadROM", "atari_env.AtariEnv.ale.getMinimalActionSet", "rlpyt.spaces.int_box.IntBox", "rlpyt.spaces.int_box.IntBox", "atari_env.AtariEnv.ale.getScreenGrayscale", "atari_env.AtariEnv._max_frame.copy", "atari_env.AtariEnv._max_frame.copy", "numpy.zeros", "int", "atari_env.AtariEnv.reset", "locals", "os.path.exists", "IOError", "atari_env.AtariEnv.get_action_meanings", "atari_env.AtariEnv.get_action_meanings", "len"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.utils.quick_args.save__init__args", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.collections.AttrDict.copy", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.collections.AttrDict.copy", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.misc.zeros", "home.repos.pwc.inspect_result.astooke_rlpyt.safe.safety_gym_env.SafetyGymEnvWrapper.reset", "home.repos.pwc.inspect_result.astooke_rlpyt.atari.atari_env.AtariEnv.get_action_meanings", "home.repos.pwc.inspect_result.astooke_rlpyt.atari.atari_env.AtariEnv.get_action_meanings"], ["def", "__init__", "(", "self", ",", "\n", "game", "=", "\"pong\"", ",", "\n", "frame_skip", "=", "4", ",", "# Frames per step (>=1).", "\n", "num_img_obs", "=", "4", ",", "# Number of (past) frames in observation (>=1).", "\n", "clip_reward", "=", "True", ",", "\n", "episodic_lives", "=", "True", ",", "\n", "fire_on_reset", "=", "False", ",", "\n", "max_start_noops", "=", "30", ",", "\n", "repeat_action_probability", "=", "0.", ",", "\n", "horizon", "=", "27000", ",", "\n", ")", ":", "\n", "        ", "save__init__args", "(", "locals", "(", ")", ",", "underscore", "=", "True", ")", "\n", "# ALE", "\n", "game_path", "=", "atari_py", ".", "get_game_path", "(", "game", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "game_path", ")", ":", "\n", "            ", "raise", "IOError", "(", "\"You asked for game {} but path {} does not \"", "\n", "\" exist\"", ".", "format", "(", "game", ",", "game_path", ")", ")", "\n", "", "self", ".", "ale", "=", "atari_py", ".", "ALEInterface", "(", ")", "\n", "self", ".", "ale", ".", "setFloat", "(", "b'repeat_action_probability'", ",", "repeat_action_probability", ")", "\n", "self", ".", "ale", ".", "loadROM", "(", "game_path", ")", "\n", "\n", "# Spaces", "\n", "self", ".", "_action_set", "=", "self", ".", "ale", ".", "getMinimalActionSet", "(", ")", "\n", "self", ".", "_action_space", "=", "IntBox", "(", "low", "=", "0", ",", "high", "=", "len", "(", "self", ".", "_action_set", ")", ")", "\n", "obs_shape", "=", "(", "num_img_obs", ",", "H", ",", "W", ")", "\n", "self", ".", "_observation_space", "=", "IntBox", "(", "low", "=", "0", ",", "high", "=", "255", ",", "shape", "=", "obs_shape", ",", "\n", "dtype", "=", "\"uint8\"", ")", "\n", "self", ".", "_max_frame", "=", "self", ".", "ale", ".", "getScreenGrayscale", "(", ")", "\n", "self", ".", "_raw_frame_1", "=", "self", ".", "_max_frame", ".", "copy", "(", ")", "\n", "self", ".", "_raw_frame_2", "=", "self", ".", "_max_frame", ".", "copy", "(", ")", "\n", "self", ".", "_obs", "=", "np", ".", "zeros", "(", "shape", "=", "obs_shape", ",", "dtype", "=", "\"uint8\"", ")", "\n", "\n", "# Settings", "\n", "self", ".", "_has_fire", "=", "\"FIRE\"", "in", "self", ".", "get_action_meanings", "(", ")", "\n", "self", ".", "_has_up", "=", "\"UP\"", "in", "self", ".", "get_action_meanings", "(", ")", "\n", "self", ".", "_horizon", "=", "int", "(", "horizon", ")", "\n", "self", ".", "reset", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.atari.atari_env.AtariEnv.reset": [[105, 117], ["atari_env.AtariEnv.ale.reset_game", "atari_env.AtariEnv._reset_obs", "atari_env.AtariEnv._life_reset", "range", "atari_env.AtariEnv._update_obs", "atari_env.AtariEnv.get_obs", "numpy.random.randint", "atari_env.AtariEnv.ale.act", "atari_env.AtariEnv.fire_and_up"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.atari.atari_env.AtariEnv._reset_obs", "home.repos.pwc.inspect_result.astooke_rlpyt.envs.atari.AtariEnv84._life_reset", "home.repos.pwc.inspect_result.astooke_rlpyt.envs.atari.AtariEnv84._update_obs", "home.repos.pwc.inspect_result.astooke_rlpyt.atari.atari_env.AtariEnv.get_obs", "home.repos.pwc.inspect_result.astooke_rlpyt.envs.atari.AtariEnv84.fire_and_up"], ["", "def", "reset", "(", "self", ")", ":", "\n", "        ", "\"\"\"Performs hard reset of ALE game.\"\"\"", "\n", "self", ".", "ale", ".", "reset_game", "(", ")", "\n", "self", ".", "_reset_obs", "(", ")", "\n", "self", ".", "_life_reset", "(", ")", "\n", "for", "_", "in", "range", "(", "np", ".", "random", ".", "randint", "(", "0", ",", "self", ".", "_max_start_noops", "+", "1", ")", ")", ":", "\n", "            ", "self", ".", "ale", ".", "act", "(", "0", ")", "\n", "", "if", "self", ".", "_fire_on_reset", ":", "\n", "            ", "self", ".", "fire_and_up", "(", ")", "\n", "", "self", ".", "_update_obs", "(", ")", "# (don't bother to populate any frame history)", "\n", "self", ".", "_step_counter", "=", "0", "\n", "return", "self", ".", "get_obs", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.atari.atari_env.AtariEnv.step": [[118, 135], ["numpy.array", "range", "atari_env.AtariEnv._get_screen", "atari_env.AtariEnv.ale.act", "atari_env.AtariEnv._check_life", "atari_env.AtariEnv._update_obs", "EnvInfo", "rlpyt.envs.base.EnvStep", "atari_env.AtariEnv.ale.act", "atari_env.AtariEnv._reset_obs", "numpy.sign", "atari_env.AtariEnv.ale.game_over", "atari_env.AtariEnv.get_obs"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.atari.atari_env.AtariEnv._get_screen", "home.repos.pwc.inspect_result.astooke_rlpyt.atari.atari_env.AtariEnv._check_life", "home.repos.pwc.inspect_result.astooke_rlpyt.envs.atari.AtariEnv84._update_obs", "home.repos.pwc.inspect_result.astooke_rlpyt.atari.atari_env.AtariEnv._reset_obs", "home.repos.pwc.inspect_result.astooke_rlpyt.atari.atari_env.AtariEnv.get_obs"], ["", "def", "step", "(", "self", ",", "action", ")", ":", "\n", "        ", "a", "=", "self", ".", "_action_set", "[", "action", "]", "\n", "game_score", "=", "np", ".", "array", "(", "0.", ",", "dtype", "=", "\"float32\"", ")", "\n", "for", "_", "in", "range", "(", "self", ".", "_frame_skip", "-", "1", ")", ":", "\n", "            ", "game_score", "+=", "self", ".", "ale", ".", "act", "(", "a", ")", "\n", "", "self", ".", "_get_screen", "(", "1", ")", "\n", "game_score", "+=", "self", ".", "ale", ".", "act", "(", "a", ")", "\n", "lost_life", "=", "self", ".", "_check_life", "(", ")", "# Advances from lost_life state.", "\n", "if", "lost_life", "and", "self", ".", "_episodic_lives", ":", "\n", "            ", "self", ".", "_reset_obs", "(", ")", "# Internal reset.", "\n", "", "self", ".", "_update_obs", "(", ")", "\n", "reward", "=", "np", ".", "sign", "(", "game_score", ")", "if", "self", ".", "_clip_reward", "else", "game_score", "\n", "game_over", "=", "self", ".", "ale", ".", "game_over", "(", ")", "or", "self", ".", "_step_counter", ">=", "self", ".", "horizon", "\n", "done", "=", "game_over", "or", "(", "self", ".", "_episodic_lives", "and", "lost_life", ")", "\n", "info", "=", "EnvInfo", "(", "game_score", "=", "game_score", ",", "traj_done", "=", "game_over", ")", "\n", "self", ".", "_step_counter", "+=", "1", "\n", "return", "EnvStep", "(", "self", ".", "get_obs", "(", ")", ",", "reward", ",", "done", ",", "info", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.atari.atari_env.AtariEnv.render": [[136, 146], ["atari_env.AtariEnv.get_obs", "cv2.imshow", "cv2.waitKey", "img.reshape.reshape.reshape"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.atari.atari_env.AtariEnv.get_obs"], ["", "def", "render", "(", "self", ",", "wait", "=", "10", ",", "show_full_obs", "=", "False", ")", ":", "\n", "        ", "\"\"\"Shows game screen via cv2, with option to show all frames in observation.\"\"\"", "\n", "img", "=", "self", ".", "get_obs", "(", ")", "\n", "if", "show_full_obs", ":", "\n", "            ", "shape", "=", "img", ".", "shape", "\n", "img", "=", "img", ".", "reshape", "(", "shape", "[", "0", "]", "*", "shape", "[", "1", "]", ",", "shape", "[", "2", "]", ")", "\n", "", "else", ":", "\n", "            ", "img", "=", "img", "[", "-", "1", "]", "\n", "", "cv2", ".", "imshow", "(", "self", ".", "_game", ",", "img", ")", "\n", "cv2", ".", "waitKey", "(", "wait", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.atari.atari_env.AtariEnv.get_obs": [[147, 149], ["atari_env.AtariEnv._obs.copy"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.utils.collections.AttrDict.copy"], ["", "def", "get_obs", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_obs", ".", "copy", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.atari.atari_env.AtariEnv._get_screen": [[153, 156], ["atari_env.AtariEnv.ale.getScreenGrayscale"], "methods", ["None"], ["", "def", "_get_screen", "(", "self", ",", "frame", "=", "1", ")", ":", "\n", "        ", "frame", "=", "self", ".", "_raw_frame_1", "if", "frame", "==", "1", "else", "self", ".", "_raw_frame_2", "\n", "self", ".", "ale", ".", "getScreenGrayscale", "(", "frame", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.atari.atari_env.AtariEnv._update_obs": [[157, 164], ["atari_env.AtariEnv._get_screen", "numpy.maximum", "cv2.resize", "numpy.concatenate"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.atari.atari_env.AtariEnv._get_screen"], ["", "def", "_update_obs", "(", "self", ")", ":", "\n", "        ", "\"\"\"Max of last two frames; crop two rows; downsample by 2x.\"\"\"", "\n", "self", ".", "_get_screen", "(", "2", ")", "\n", "np", ".", "maximum", "(", "self", ".", "_raw_frame_1", ",", "self", ".", "_raw_frame_2", ",", "self", ".", "_max_frame", ")", "\n", "img", "=", "cv2", ".", "resize", "(", "self", ".", "_max_frame", "[", "1", ":", "-", "1", "]", ",", "(", "W", ",", "H", ")", ",", "cv2", ".", "INTER_NEAREST", ")", "\n", "# NOTE: order OLDEST to NEWEST should match use in frame-wise buffer.", "\n", "self", ".", "_obs", "=", "np", ".", "concatenate", "(", "[", "self", ".", "_obs", "[", "1", ":", "]", ",", "img", "[", "np", ".", "newaxis", "]", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.atari.atari_env.AtariEnv._reset_obs": [[165, 170], ["None"], "methods", ["None"], ["", "def", "_reset_obs", "(", "self", ")", ":", "\n", "        ", "self", ".", "_obs", "[", ":", "]", "=", "0", "\n", "self", ".", "_max_frame", "[", ":", "]", "=", "0", "\n", "self", ".", "_raw_frame_1", "[", ":", "]", "=", "0", "\n", "self", ".", "_raw_frame_2", "[", ":", "]", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.atari.atari_env.AtariEnv._check_life": [[171, 177], ["atari_env.AtariEnv.ale.lives", "atari_env.AtariEnv._life_reset"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.envs.atari.AtariEnv84._life_reset"], ["", "def", "_check_life", "(", "self", ")", ":", "\n", "        ", "lives", "=", "self", ".", "ale", ".", "lives", "(", ")", "\n", "lost_life", "=", "(", "lives", "<", "self", ".", "_lives", ")", "and", "(", "lives", ">", "0", ")", "\n", "if", "lost_life", ":", "\n", "            ", "self", ".", "_life_reset", "(", ")", "\n", "", "return", "lost_life", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.atari.atari_env.AtariEnv._life_reset": [[178, 181], ["atari_env.AtariEnv.ale.act", "atari_env.AtariEnv.ale.lives"], "methods", ["None"], ["", "def", "_life_reset", "(", "self", ")", ":", "\n", "        ", "self", ".", "ale", ".", "act", "(", "0", ")", "# (advance from lost life state)", "\n", "self", ".", "_lives", "=", "self", ".", "ale", ".", "lives", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.atari.atari_env.AtariEnv.fire_and_up": [[182, 188], ["atari_env.AtariEnv.ale.act", "atari_env.AtariEnv.ale.act"], "methods", ["None"], ["", "def", "fire_and_up", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "_has_fire", ":", "\n", "# TODO: for sticky actions, make sure fire is actually pressed", "\n", "            ", "self", ".", "ale", ".", "act", "(", "1", ")", "# (e.g. needed in Breakout, not sure what others)", "\n", "", "if", "self", ".", "_has_up", ":", "\n", "            ", "self", ".", "ale", ".", "act", "(", "2", ")", "# (not sure if this is necessary, saw it somewhere)", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.atari.atari_env.AtariEnv.game": [[193, 196], ["None"], "methods", ["None"], ["", "", "@", "property", "\n", "def", "game", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_game", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.atari.atari_env.AtariEnv.frame_skip": [[197, 200], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "frame_skip", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_frame_skip", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.atari.atari_env.AtariEnv.num_img_obs": [[201, 204], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "num_img_obs", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_num_img_obs", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.atari.atari_env.AtariEnv.clip_reward": [[205, 208], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "clip_reward", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_clip_reward", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.atari.atari_env.AtariEnv.max_start_noops": [[209, 212], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "max_start_noops", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_max_start_noops", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.atari.atari_env.AtariEnv.episodic_lives": [[213, 216], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "episodic_lives", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_episodic_lives", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.atari.atari_env.AtariEnv.repeat_action_probability": [[217, 220], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "repeat_action_probability", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_repeat_action_probability", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.atari.atari_env.AtariEnv.horizon": [[221, 224], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "horizon", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_horizon", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.atari.atari_env.AtariEnv.get_action_meanings": [[225, 227], ["None"], "methods", ["None"], ["", "def", "get_action_meanings", "(", "self", ")", ":", "\n", "        ", "return", "[", "ACTION_MEANING", "[", "i", "]", "for", "i", "in", "self", ".", "_action_set", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.agents.base.BaseAgent.__init__": [[36, 58], ["rlpyt.utils.quick_args.save__init__args", "torch.device", "rlpyt.utils.synchronize.RWLock", "multiprocessing.RawValue", "locals", "dict"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.utils.quick_args.save__init__args"], ["\n", "", "def", "optim_initialize", "(", "self", ",", "rank", "=", "0", ")", ":", "\n", "        ", "\"\"\"Called in async runner which requires two stages of initialization;\n        might also be used in ``initialize()`` to avoid redundant code.\"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n", "", "def", "optimize_agent", "(", "self", ",", "itr", ",", "samples", "=", "None", ",", "sampler_itr", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Train the agent for some number of parameter updates, e.g. either\n        using new samples or a replay buffer.\n\n        Typically called in the runner's training loop.\n\n        Args:\n            itr (int): Iteration of the training loop.\n            samples: New samples from the sampler (for ``None`` case, see async runner).\n            sampler_itr:  For case other than ``None``, see async runner.\n        \"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n", "", "def", "optim_state_dict", "(", "self", ")", ":", "\n", "        ", "\"\"\"Return the optimizer state dict (e.g. Adam); overwrite if using\n        multiple optimizers.\"\"\"", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.agents.base.BaseAgent.__call__": [[59, 63], ["None"], "methods", ["None"], ["return", "self", ".", "optimizer", ".", "state_dict", "(", ")", "\n", "\n", "", "def", "load_optim_state_dict", "(", "self", ",", "state_dict", ")", ":", "\n", "        ", "\"\"\"Load an optimizer state dict; should expect the format returned\n        from ``optim_state_dict().``\"\"\"", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.agents.base.BaseAgent.initialize": [[64, 94], ["base.BaseAgent.make_env_to_model_kwargs", "base.BaseAgent.ModelCls", "base.BaseAgent.model.share_memory", "base.BaseAgent.model.load_state_dict"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.agents.base.BaseAgent.make_env_to_model_kwargs", "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.augmented_temporal_similarity.AugmentedTemporalSimilarity.load_state_dict"], ["self", ".", "optimizer", ".", "load_state_dict", "(", "state_dict", ")", "\n", "\n", "", "@", "property", "\n", "def", "batch_size", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_batch_size", "# For logging at least.", "\n", "", "", ""]], "home.repos.pwc.inspect_result.astooke_rlpyt.agents.base.BaseAgent.make_env_to_model_kwargs": [[95, 98], ["None"], "methods", ["None"], []], "home.repos.pwc.inspect_result.astooke_rlpyt.agents.base.BaseAgent.to_device": [[99, 117], ["torch.device", "base.BaseAgent.model.to", "rlpyt.utils.logging.logger.log", "base.BaseAgent.ModelCls", "base.BaseAgent.model.load_state_dict", "base.BaseAgent.shared_model.state_dict"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.logging.console.log", "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.augmented_temporal_similarity.AugmentedTemporalSimilarity.load_state_dict", "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.replay_saver.DummyOptimizer.state_dict"], []], "home.repos.pwc.inspect_result.astooke_rlpyt.agents.base.BaseAgent.data_parallel": [[118, 137], ["torch.nn.parallel.DistributedDataParallel", "rlpyt.utils.logging.logger.log"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.logging.console.log"], []], "home.repos.pwc.inspect_result.astooke_rlpyt.agents.base.BaseAgent.async_cpu": [[138, 161], ["base.BaseAgent.ModelCls", "base.BaseAgent.model.load_state_dict", "rlpyt.utils.logging.logger.log", "base.BaseAgent.shared_model.state_dict", "base.BaseAgent.model.share_memory"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.augmented_temporal_similarity.AugmentedTemporalSimilarity.load_state_dict", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.console.log", "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.replay_saver.DummyOptimizer.state_dict"], []], "home.repos.pwc.inspect_result.astooke_rlpyt.agents.base.BaseAgent.collector_initialize": [[162, 166], ["None"], "methods", ["None"], []], "home.repos.pwc.inspect_result.astooke_rlpyt.agents.base.BaseAgent.step": [[167, 171], ["torch.no_grad"], "methods", ["None"], []], "home.repos.pwc.inspect_result.astooke_rlpyt.agents.base.BaseAgent.reset": [[172, 174], ["None"], "methods", ["None"], []], "home.repos.pwc.inspect_result.astooke_rlpyt.agents.base.BaseAgent.reset_one": [[175, 177], ["None"], "methods", ["None"], []], "home.repos.pwc.inspect_result.astooke_rlpyt.agents.base.BaseAgent.parameters": [[178, 181], ["base.BaseAgent.model.parameters"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.rl.atari_rl_models.AtariDqnModel.parameters"], []], "home.repos.pwc.inspect_result.astooke_rlpyt.agents.base.BaseAgent.state_dict": [[182, 185], ["base.BaseAgent.model.state_dict"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.replay_saver.DummyOptimizer.state_dict"], []], "home.repos.pwc.inspect_result.astooke_rlpyt.agents.base.BaseAgent.load_state_dict": [[186, 189], ["base.BaseAgent.model.load_state_dict"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.augmented_temporal_similarity.AugmentedTemporalSimilarity.load_state_dict"], []], "home.repos.pwc.inspect_result.astooke_rlpyt.agents.base.BaseAgent.train_mode": [[190, 194], ["base.BaseAgent.model.train"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.runners.minibatch_rl.MinibatchRlEval.train"], []], "home.repos.pwc.inspect_result.astooke_rlpyt.agents.base.BaseAgent.sample_mode": [[195, 199], ["base.BaseAgent.model.eval"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.augmented_temporal_similarity.AugmentedTemporalSimilarity.eval"], []], "home.repos.pwc.inspect_result.astooke_rlpyt.agents.base.BaseAgent.eval_mode": [[200, 204], ["base.BaseAgent.model.eval"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.augmented_temporal_similarity.AugmentedTemporalSimilarity.eval"], []], "home.repos.pwc.inspect_result.astooke_rlpyt.agents.base.BaseAgent.sync_shared_memory": [[205, 217], ["base.BaseAgent.shared_model.load_state_dict", "rlpyt.models.utils.strip_ddp_state_dict", "base.BaseAgent.model.state_dict"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.augmented_temporal_similarity.AugmentedTemporalSimilarity.load_state_dict", "home.repos.pwc.inspect_result.astooke_rlpyt.models.utils.strip_ddp_state_dict", "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.replay_saver.DummyOptimizer.state_dict"], []], "home.repos.pwc.inspect_result.astooke_rlpyt.agents.base.BaseAgent.send_shared_memory": [[218, 230], ["base.BaseAgent.shared_model.load_state_dict", "rlpyt.models.utils.strip_ddp_state_dict", "base.BaseAgent.model.state_dict"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.augmented_temporal_similarity.AugmentedTemporalSimilarity.load_state_dict", "home.repos.pwc.inspect_result.astooke_rlpyt.models.utils.strip_ddp_state_dict", "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.replay_saver.DummyOptimizer.state_dict"], []], "home.repos.pwc.inspect_result.astooke_rlpyt.agents.base.BaseAgent.recv_shared_memory": [[231, 243], ["base.BaseAgent.model.load_state_dict", "base.BaseAgent.shared_model.state_dict"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.augmented_temporal_similarity.AugmentedTemporalSimilarity.load_state_dict", "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.replay_saver.DummyOptimizer.state_dict"], []], "home.repos.pwc.inspect_result.astooke_rlpyt.agents.base.BaseAgent.toggle_alt": [[244, 246], ["None"], "methods", ["None"], []], "home.repos.pwc.inspect_result.astooke_rlpyt.agents.base.RecurrentAgentMixin.__init__": [[260, 264], ["super().__init__"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.spaces.gym_wrapper.GymSpaceWrapper.__init__"], []], "home.repos.pwc.inspect_result.astooke_rlpyt.agents.base.RecurrentAgentMixin.reset": [[265, 269], ["None"], "methods", ["None"], []], "home.repos.pwc.inspect_result.astooke_rlpyt.agents.base.RecurrentAgentMixin.reset_one": [[270, 276], ["None"], "methods", ["None"], []], "home.repos.pwc.inspect_result.astooke_rlpyt.agents.base.RecurrentAgentMixin.advance_rnn_state": [[277, 281], ["None"], "methods", ["None"], []], "home.repos.pwc.inspect_result.astooke_rlpyt.agents.base.RecurrentAgentMixin.prev_rnn_state": [[282, 285], ["None"], "methods", ["None"], []], "home.repos.pwc.inspect_result.astooke_rlpyt.agents.base.RecurrentAgentMixin.train_mode": [[286, 292], ["super().train_mode"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.agents.dmc_sac_agent.SacAgent.train_mode"], []], "home.repos.pwc.inspect_result.astooke_rlpyt.agents.base.RecurrentAgentMixin.sample_mode": [[293, 298], ["super().sample_mode"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.agents.dmc_sac_agent.SacAgent.sample_mode"], []], "home.repos.pwc.inspect_result.astooke_rlpyt.agents.base.RecurrentAgentMixin.eval_mode": [[299, 305], ["super().eval_mode"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.agents.dmc_sac_agent.SacAgent.eval_mode"], []], "home.repos.pwc.inspect_result.astooke_rlpyt.agents.base.AlternatingRecurrentAgentMixin.__init__": [[320, 326], ["super().__init__"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.spaces.gym_wrapper.GymSpaceWrapper.__init__"], []], "home.repos.pwc.inspect_result.astooke_rlpyt.agents.base.AlternatingRecurrentAgentMixin.reset": [[327, 331], ["None"], "methods", ["None"], []], "home.repos.pwc.inspect_result.astooke_rlpyt.agents.base.AlternatingRecurrentAgentMixin.advance_rnn_state": [[333, 338], ["None"], "methods", ["None"], []], "home.repos.pwc.inspect_result.astooke_rlpyt.agents.base.AlternatingRecurrentAgentMixin.prev_rnn_state": [[339, 342], ["None"], "methods", ["None"], []], "home.repos.pwc.inspect_result.astooke_rlpyt.agents.base.AlternatingRecurrentAgentMixin.train_mode": [[343, 350], ["super().train_mode"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.agents.dmc_sac_agent.SacAgent.train_mode"], []], "home.repos.pwc.inspect_result.astooke_rlpyt.agents.base.AlternatingRecurrentAgentMixin.sample_mode": [[351, 357], ["super().sample_mode"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.agents.dmc_sac_agent.SacAgent.sample_mode"], []], "home.repos.pwc.inspect_result.astooke_rlpyt.agents.base.AlternatingRecurrentAgentMixin.eval_mode": [[358, 365], ["super().eval_mode"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.agents.dmc_sac_agent.SacAgent.eval_mode"], []], "home.repos.pwc.inspect_result.astooke_rlpyt.agents.base.AlternatingRecurrentAgentMixin.get_alt": [[366, 368], ["None"], "methods", ["None"], []], "home.repos.pwc.inspect_result.astooke_rlpyt.agents.base.AlternatingRecurrentAgentMixin.toggle_alt": [[369, 372], ["None"], "methods", ["None"], []], "home.repos.pwc.inspect_result.astooke_rlpyt.agents.dmc_sac_agent.SacAgent.__init__": [[22, 53], ["rlpyt.utils.quick_args.save__init__args", "rlpyt.agents.base.BaseAgent.__init__", "dict", "dict", "dict", "dict", "locals"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.utils.quick_args.save__init__args", "home.repos.pwc.inspect_result.astooke_rlpyt.spaces.gym_wrapper.GymSpaceWrapper.__init__"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "ModelCls", "=", "SacModel", ",", "\n", "ConvModelCls", "=", "SacConvModel", ",", "\n", "Fc1ModelCls", "=", "SacFc1Model", ",", "\n", "PiModelCls", "=", "SacActorModel", ",", "\n", "QModelCls", "=", "SacCriticModel", ",", "\n", "conv_kwargs", "=", "None", ",", "\n", "fc1_kwargs", "=", "None", ",", "\n", "pi_model_kwargs", "=", "None", ",", "\n", "q_model_kwargs", "=", "None", ",", "\n", "initial_state_dict", "=", "None", ",", "\n", "action_squash", "=", "1.", ",", "\n", "pretrain_std", "=", "0.75", ",", "# 0.75 gets pretty uniform squashed actions", "\n", "load_conv", "=", "False", ",", "\n", "load_all", "=", "False", ",", "\n", "state_dict_filename", "=", "None", ",", "\n", "store_latent", "=", "False", ",", "\n", ")", ":", "\n", "        ", "if", "conv_kwargs", "is", "None", ":", "\n", "            ", "conv_kwargs", "=", "dict", "(", ")", "\n", "", "if", "fc1_kwargs", "is", "None", ":", "\n", "            ", "fc1_kwargs", "=", "dict", "(", "latent_size", "=", "50", ")", "# default", "\n", "", "if", "pi_model_kwargs", "is", "None", ":", "\n", "            ", "pi_model_kwargs", "=", "dict", "(", "hidden_sizes", "=", "[", "1024", ",", "1024", "]", ")", "# default", "\n", "", "if", "q_model_kwargs", "is", "None", ":", "\n", "            ", "q_model_kwargs", "=", "dict", "(", "hidden_sizes", "=", "[", "1024", ",", "1024", "]", ")", "# default", "\n", "", "save__init__args", "(", "locals", "(", ")", ")", "\n", "super", "(", ")", ".", "__init__", "(", "ModelCls", "=", "SacModel", ")", "\n", "self", ".", "min_itr_learn", "=", "0", "# Get from algo.", "\n", "assert", "not", "(", "load_conv", "and", "load_all", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.agents.dmc_sac_agent.SacAgent.initialize": [[54, 127], ["dmc_sac_agent.SacAgent.ConvModelCls", "dmc_sac_agent.SacAgent.Fc1ModelCls", "dmc_sac_agent.SacAgent.Fc1ModelCls", "dmc_sac_agent.SacAgent.PiModelCls", "dmc_sac_agent.SacAgent.QModelCls", "copy.deepcopy", "rlpyt.ul.models.rl.sac_rl_models.SacModel", "copy.deepcopy", "copy.deepcopy", "rlpyt.distributions.gaussian.Gaussian", "rlpyt.utils.logging.logger.log", "torch.load", "torch.load.get", "torch.load.get", "collections.OrderedDict", "dmc_sac_agent.SacAgent.conv.load_state_dict", "rlpyt.utils.logging.logger.log", "dmc_sac_agent.SacAgent.model.share_memory", "len", "torch.load", "dmc_sac_agent.SacAgent.load_state_dict", "rlpyt.utils.logging.logger.log", "rlpyt.utils.logging.logger.log", "torch.device", "torch.load.items", "k.startswith", "torch.device"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.logging.console.log", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.collections.NamedArrayTuple.get", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.collections.NamedArrayTuple.get", "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.augmented_temporal_similarity.AugmentedTemporalSimilarity.load_state_dict", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.console.log", "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.augmented_temporal_similarity.AugmentedTemporalSimilarity.load_state_dict", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.console.log", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.console.log", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.collections.NamedArrayTuple.items"], ["", "def", "initialize", "(", "self", ",", "env_spaces", ",", "share_memory", "=", "False", ",", "\n", "global_B", "=", "1", ",", "env_ranks", "=", "None", ")", ":", "\n", "        ", "self", ".", "conv", "=", "self", ".", "ConvModelCls", "(", "\n", "image_shape", "=", "env_spaces", ".", "observation", ".", "shape", ",", "\n", "**", "self", ".", "conv_kwargs", ")", "\n", "self", ".", "q_fc1", "=", "self", ".", "Fc1ModelCls", "(", "\n", "input_size", "=", "self", ".", "conv", ".", "output_size", ",", "\n", "**", "self", ".", "fc1_kwargs", ")", "\n", "self", ".", "pi_fc1", "=", "self", ".", "Fc1ModelCls", "(", "\n", "input_size", "=", "self", ".", "conv", ".", "output_size", ",", "\n", "**", "self", ".", "fc1_kwargs", ")", "\n", "\n", "latent_size", "=", "self", ".", "q_fc1", ".", "output_size", "\n", "action_size", "=", "env_spaces", ".", "action", ".", "shape", "[", "0", "]", "\n", "\n", "# These are just MLPs", "\n", "self", ".", "pi_mlp", "=", "self", ".", "PiModelCls", "(", "\n", "input_size", "=", "latent_size", ",", "\n", "action_size", "=", "action_size", ",", "\n", "**", "self", ".", "pi_model_kwargs", ")", "\n", "self", ".", "q_mlps", "=", "self", ".", "QModelCls", "(", "\n", "input_size", "=", "latent_size", ",", "\n", "action_size", "=", "action_size", ",", "\n", "**", "self", ".", "q_model_kwargs", ")", "\n", "self", ".", "target_q_mlps", "=", "copy", ".", "deepcopy", "(", "self", ".", "q_mlps", ")", "# Separate params.", "\n", "\n", "# Make reference to the full actor model including encoder.", "\n", "# CAREFUL ABOUT TRAIN MODE FOR LAYER NORM IF CHANGING THIS?", "\n", "self", ".", "model", "=", "SacModel", "(", "conv", "=", "self", ".", "conv", ",", "pi_fc1", "=", "self", ".", "pi_fc1", ",", "\n", "pi_mlp", "=", "self", ".", "pi_mlp", ")", "\n", "\n", "if", "self", ".", "load_conv", ":", "\n", "            ", "logger", ".", "log", "(", "\"Agent loading state dict: \"", "+", "self", ".", "state_dict_filename", ")", "\n", "loaded_state_dict", "=", "torch", ".", "load", "(", "self", ".", "state_dict_filename", ",", "\n", "map_location", "=", "torch", ".", "device", "(", "\"cpu\"", ")", ")", "\n", "# From UL, saves snapshot: params[\"algo_state_dict\"][\"encoder\"]", "\n", "if", "\"algo_state_dict\"", "in", "loaded_state_dict", ":", "\n", "                ", "loaded_state_dict", "=", "loaded_state_dict", "\n", "", "loaded_state_dict", "=", "loaded_state_dict", ".", "get", "(", "\"algo_state_dict\"", ",", "loaded_state_dict", ")", "\n", "loaded_state_dict", "=", "loaded_state_dict", ".", "get", "(", "\"encoder\"", ",", "loaded_state_dict", ")", "\n", "# A bit onerous, but ensures that state dicts match:", "\n", "conv_state_dict", "=", "OrderedDict", "(", "[", "(", "k", ",", "v", ")", "# .replace(\"conv.\", \"\", 1)", "\n", "for", "k", ",", "v", "in", "loaded_state_dict", ".", "items", "(", ")", "if", "k", ".", "startswith", "(", "\"conv.\"", ")", "]", ")", "\n", "self", ".", "conv", ".", "load_state_dict", "(", "conv_state_dict", ")", "\n", "# Double check it gets into the q_encoder as well.", "\n", "logger", ".", "log", "(", "\"Agent loaded CONV state dict.\"", ")", "\n", "", "elif", "self", ".", "load_all", ":", "\n", "# From RL, saves snapshot: params[\"agent_state_dict\"]", "\n", "            ", "loaded_state_dict", "=", "torch", ".", "load", "(", "self", ".", "state_dict_filename", ",", "\n", "map_location", "=", "torch", ".", "device", "(", "'cpu'", ")", ")", "\n", "self", ".", "load_state_dict", "(", "loaded_state_dict", "[", "\"agent_state_dict\"", "]", ")", "\n", "logger", ".", "log", "(", "\"Agnet loaded FULL state dict.\"", ")", "\n", "", "else", ":", "\n", "            ", "logger", ".", "log", "(", "\"Agent NOT loading state dict.\"", ")", "\n", "\n", "", "self", ".", "target_conv", "=", "copy", ".", "deepcopy", "(", "self", ".", "conv", ")", "\n", "self", ".", "target_q_fc1", "=", "copy", ".", "deepcopy", "(", "self", ".", "q_fc1", ")", "\n", "\n", "if", "share_memory", ":", "\n", "# The actor model needs to share memory to sampler workers, and", "\n", "# this includes handling the encoder!", "\n", "# (Almost always just run serial anyway, no sharing.)", "\n", "            ", "self", ".", "model", ".", "share_memory", "(", ")", "\n", "self", ".", "shared_model", "=", "self", ".", "model", "\n", "", "if", "self", ".", "initial_state_dict", "is", "not", "None", ":", "\n", "            ", "raise", "NotImplementedError", "\n", "", "self", ".", "env_spaces", "=", "env_spaces", "\n", "self", ".", "share_memory", "=", "share_memory", "\n", "\n", "assert", "len", "(", "env_spaces", ".", "action", ".", "shape", ")", "==", "1", "\n", "self", ".", "distribution", "=", "Gaussian", "(", "\n", "dim", "=", "env_spaces", ".", "action", ".", "shape", "[", "0", "]", ",", "\n", "squash", "=", "self", ".", "action_squash", ",", "\n", "# min_std=np.exp(MIN_LOG_STD),  # NOPE IN PI_MODEL NOW", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.agents.dmc_sac_agent.SacAgent.to_device": [[131, 141], ["super().to_device", "dmc_sac_agent.SacAgent.conv.to", "dmc_sac_agent.SacAgent.q_fc1.to", "dmc_sac_agent.SacAgent.pi_fc1.to", "dmc_sac_agent.SacAgent.q_mlps.to", "dmc_sac_agent.SacAgent.pi_mlp.to", "dmc_sac_agent.SacAgent.target_conv.to", "dmc_sac_agent.SacAgent.target_q_fc1.to", "dmc_sac_agent.SacAgent.target_q_mlps.to"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.safe.cppo_agent.CppoLstmAgent.to_device"], ["", "def", "to_device", "(", "self", ",", "cuda_idx", "=", "None", ")", ":", "\n", "        ", "super", "(", ")", ".", "to_device", "(", "cuda_idx", ")", "# Takes care of self.model only.", "\n", "self", ".", "conv", ".", "to", "(", "self", ".", "device", ")", "# should already be done", "\n", "self", ".", "q_fc1", ".", "to", "(", "self", ".", "device", ")", "\n", "self", ".", "pi_fc1", ".", "to", "(", "self", ".", "device", ")", "# should already be done", "\n", "self", ".", "q_mlps", ".", "to", "(", "self", ".", "device", ")", "\n", "self", ".", "pi_mlp", ".", "to", "(", "self", ".", "device", ")", "# should already be done", "\n", "self", ".", "target_conv", ".", "to", "(", "self", ".", "device", ")", "\n", "self", ".", "target_q_fc1", ".", "to", "(", "self", ".", "device", ")", "\n", "self", ".", "target_q_mlps", ".", "to", "(", "self", ".", "device", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.agents.dmc_sac_agent.SacAgent.give_min_itr_learn": [[142, 144], ["None"], "methods", ["None"], ["", "def", "give_min_itr_learn", "(", "self", ",", "min_itr_learn", ")", ":", "\n", "        ", "self", ".", "min_itr_learn", "=", "min_itr_learn", "# From algo.", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.agents.dmc_sac_agent.SacAgent.step": [[145, 158], ["torch.no_grad", "rlpyt.utils.buffer.buffer_to", "dmc_sac_agent.SacAgent.model", "rlpyt.distributions.gaussian.DistInfoStd", "dmc_sac_agent.SacAgent.distribution.sample", "AgentInfo", "rlpyt.utils.buffer.buffer_to", "rlpyt.agents.base.AgentStep"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.utils.buffer.buffer_to", "home.repos.pwc.inspect_result.astooke_rlpyt.spaces.gym_wrapper.GymSpaceWrapper.sample", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.buffer.buffer_to"], ["", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "step", "(", "self", ",", "observation", ",", "prev_action", ",", "prev_reward", ")", ":", "\n", "        ", "observation", ",", "prev_action", ",", "prev_reward", "=", "buffer_to", "(", "\n", "(", "observation", ",", "prev_action", ",", "prev_reward", ")", ",", "\n", "device", "=", "self", ".", "device", ")", "\n", "# self.model includes encoder + actor MLP.", "\n", "mean", ",", "log_std", ",", "latent", ",", "conv", "=", "self", ".", "model", "(", "observation", ",", "prev_action", ",", "prev_reward", ")", "\n", "dist_info", "=", "DistInfoStd", "(", "mean", "=", "mean", ",", "log_std", "=", "log_std", ")", "\n", "action", "=", "self", ".", "distribution", ".", "sample", "(", "dist_info", ")", "\n", "agent_info", "=", "AgentInfo", "(", "dist_info", "=", "dist_info", ",", "\n", "conv", "=", "conv", "if", "self", ".", "store_latent", "else", "None", ")", "\n", "action", ",", "agent_info", "=", "buffer_to", "(", "(", "action", ",", "agent_info", ")", ",", "device", "=", "\"cpu\"", ")", "\n", "return", "AgentStep", "(", "action", "=", "action", ",", "agent_info", "=", "agent_info", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.agents.dmc_sac_agent.SacAgent.q": [[159, 166], ["dmc_sac_agent.SacAgent.q_fc1", "dmc_sac_agent.SacAgent.q_mlps", "q1.cpu", "q2.cpu"], "methods", ["None"], ["", "def", "q", "(", "self", ",", "conv_out", ",", "prev_action", ",", "prev_reward", ",", "action", ")", ":", "\n", "        ", "\"\"\"Compute twin Q-values for state/observation and input action\n        (with grad).\n        Assume variables already on device.\"\"\"", "\n", "latent", "=", "self", ".", "q_fc1", "(", "conv_out", ")", "\n", "q1", ",", "q2", "=", "self", ".", "q_mlps", "(", "latent", ",", "action", ",", "prev_action", ",", "prev_reward", ")", "\n", "return", "q1", ".", "cpu", "(", ")", ",", "q2", ".", "cpu", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.agents.dmc_sac_agent.SacAgent.target_q": [[167, 175], ["dmc_sac_agent.SacAgent.target_q_fc1", "dmc_sac_agent.SacAgent.target_q_mlps", "target_q1.cpu", "target_q2.cpu"], "methods", ["None"], ["", "def", "target_q", "(", "self", ",", "conv_out", ",", "prev_action", ",", "prev_reward", ",", "action", ")", ":", "\n", "        ", "\"\"\"Compute twin target Q-values for state/observation and input\n        action.\n        Assume variables already on device.\"\"\"", "\n", "latent", "=", "self", ".", "target_q_fc1", "(", "conv_out", ")", "\n", "target_q1", ",", "target_q2", "=", "self", ".", "target_q_mlps", "(", "latent", ",", "action", ",", "prev_action", ",", "\n", "prev_reward", ")", "\n", "return", "target_q1", ".", "cpu", "(", ")", ",", "target_q2", ".", "cpu", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.agents.dmc_sac_agent.SacAgent.pi": [[176, 191], ["dmc_sac_agent.SacAgent.pi_fc1", "dmc_sac_agent.SacAgent.pi_mlp", "rlpyt.distributions.gaussian.DistInfoStd", "dmc_sac_agent.SacAgent.distribution.sample_loglikelihood", "rlpyt.utils.buffer.buffer_to"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.distributions.gaussian.Gaussian.sample_loglikelihood", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.buffer.buffer_to"], ["", "def", "pi", "(", "self", ",", "conv_out", ",", "prev_action", ",", "prev_reward", ")", ":", "\n", "        ", "\"\"\"Compute action log-probabilities for state/observation, and\n        sample new action (with grad).  Uses special ``sample_loglikelihood()``\n        method of Gaussian distriution, which handles action squashing\n        through this process.\n        Assume variables already on device.\"\"\"", "\n", "# Call just the actor mlp, not the encoder.", "\n", "latent", "=", "self", ".", "pi_fc1", "(", "conv_out", ")", "\n", "mean", ",", "log_std", "=", "self", ".", "pi_mlp", "(", "latent", ",", "prev_action", ",", "prev_reward", ")", "\n", "dist_info", "=", "DistInfoStd", "(", "mean", "=", "mean", ",", "log_std", "=", "log_std", ")", "\n", "action", ",", "log_pi", "=", "self", ".", "distribution", ".", "sample_loglikelihood", "(", "dist_info", ")", "\n", "# action = self.distribution.sample(dist_info)", "\n", "# log_pi = self.distribution.log_likelihood(action, dist_info)", "\n", "log_pi", ",", "dist_info", "=", "buffer_to", "(", "(", "log_pi", ",", "dist_info", ")", ",", "device", "=", "\"cpu\"", ")", "\n", "return", "action", ",", "log_pi", ",", "dist_info", "# Action stays on device for q models.", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.agents.dmc_sac_agent.SacAgent.train_mode": [[192, 199], ["super().train_mode", "dmc_sac_agent.SacAgent.conv.train", "dmc_sac_agent.SacAgent.q_fc1.train", "dmc_sac_agent.SacAgent.pi_fc1.train", "dmc_sac_agent.SacAgent.q_mlps.train", "dmc_sac_agent.SacAgent.pi_mlp.train"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.agents.dmc_sac_agent.SacAgent.train_mode", "home.repos.pwc.inspect_result.astooke_rlpyt.runners.minibatch_rl.MinibatchRlEval.train", "home.repos.pwc.inspect_result.astooke_rlpyt.runners.minibatch_rl.MinibatchRlEval.train", "home.repos.pwc.inspect_result.astooke_rlpyt.runners.minibatch_rl.MinibatchRlEval.train", "home.repos.pwc.inspect_result.astooke_rlpyt.runners.minibatch_rl.MinibatchRlEval.train", "home.repos.pwc.inspect_result.astooke_rlpyt.runners.minibatch_rl.MinibatchRlEval.train"], ["", "def", "train_mode", "(", "self", ",", "itr", ")", ":", "\n", "        ", "super", "(", ")", ".", "train_mode", "(", "itr", ")", "# pi_encoder in here in model", "\n", "self", ".", "conv", ".", "train", "(", ")", "# should already be done", "\n", "self", ".", "q_fc1", ".", "train", "(", ")", "\n", "self", ".", "pi_fc1", ".", "train", "(", ")", "# should already be done", "\n", "self", ".", "q_mlps", ".", "train", "(", ")", "\n", "self", ".", "pi_mlp", ".", "train", "(", ")", "# should already be done", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.agents.dmc_sac_agent.SacAgent.sample_mode": [[200, 213], ["super().sample_mode", "dmc_sac_agent.SacAgent.conv.eval", "dmc_sac_agent.SacAgent.q_fc1.eval", "dmc_sac_agent.SacAgent.pi_fc1.eval", "dmc_sac_agent.SacAgent.q_mlps.eval", "dmc_sac_agent.SacAgent.pi_mlp.eval", "dmc_sac_agent.SacAgent.distribution.set_std", "rlpyt.utils.logging.logger.log", "rlpyt.utils.logging.logger.log"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.agents.dmc_sac_agent.SacAgent.sample_mode", "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.augmented_temporal_similarity.AugmentedTemporalSimilarity.eval", "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.augmented_temporal_similarity.AugmentedTemporalSimilarity.eval", "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.augmented_temporal_similarity.AugmentedTemporalSimilarity.eval", "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.augmented_temporal_similarity.AugmentedTemporalSimilarity.eval", "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.augmented_temporal_similarity.AugmentedTemporalSimilarity.eval", "home.repos.pwc.inspect_result.astooke_rlpyt.distributions.gaussian.Gaussian.set_std", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.console.log", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.console.log"], ["", "def", "sample_mode", "(", "self", ",", "itr", ")", ":", "\n", "        ", "super", "(", ")", ".", "sample_mode", "(", "itr", ")", "# pi_encoder in here in model", "\n", "self", ".", "conv", ".", "eval", "(", ")", "# should already be done", "\n", "self", ".", "q_fc1", ".", "eval", "(", ")", "\n", "self", ".", "pi_fc1", ".", "eval", "(", ")", "# should already be done", "\n", "self", ".", "q_mlps", ".", "eval", "(", ")", "# not used anyway", "\n", "self", ".", "pi_mlp", ".", "eval", "(", ")", "# should already be done", "\n", "if", "itr", "==", "0", ":", "\n", "            ", "logger", ".", "log", "(", "f\"Agent at itr {itr}, sample std: {self.pretrain_std}\"", ")", "\n", "", "if", "itr", "==", "self", ".", "min_itr_learn", ":", "\n", "            ", "logger", ".", "log", "(", "f\"Agent at itr {itr}, sample std: learned.\"", ")", "\n", "", "std", "=", "None", "if", "itr", ">=", "self", ".", "min_itr_learn", "else", "self", ".", "pretrain_std", "\n", "self", ".", "distribution", ".", "set_std", "(", "std", ")", "# If None: std from policy dist_info.", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.agents.dmc_sac_agent.SacAgent.eval_mode": [[214, 222], ["super().eval_mode", "dmc_sac_agent.SacAgent.conv.eval", "dmc_sac_agent.SacAgent.q_fc1.eval", "dmc_sac_agent.SacAgent.pi_fc1.eval", "dmc_sac_agent.SacAgent.q_mlps.eval", "dmc_sac_agent.SacAgent.pi_mlp.eval", "dmc_sac_agent.SacAgent.distribution.set_std"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.agents.dmc_sac_agent.SacAgent.eval_mode", "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.augmented_temporal_similarity.AugmentedTemporalSimilarity.eval", "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.augmented_temporal_similarity.AugmentedTemporalSimilarity.eval", "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.augmented_temporal_similarity.AugmentedTemporalSimilarity.eval", "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.augmented_temporal_similarity.AugmentedTemporalSimilarity.eval", "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.augmented_temporal_similarity.AugmentedTemporalSimilarity.eval", "home.repos.pwc.inspect_result.astooke_rlpyt.distributions.gaussian.Gaussian.set_std"], ["", "def", "eval_mode", "(", "self", ",", "itr", ")", ":", "\n", "        ", "super", "(", ")", ".", "eval_mode", "(", "itr", ")", "# pi_encoder in here in model", "\n", "self", ".", "conv", ".", "eval", "(", ")", "# should already be done", "\n", "self", ".", "q_fc1", ".", "eval", "(", ")", "\n", "self", ".", "pi_fc1", ".", "eval", "(", ")", "# should already be done", "\n", "self", ".", "q_mlps", ".", "eval", "(", ")", "# not used anyway", "\n", "self", ".", "pi_mlp", ".", "eval", "(", ")", "# should already be done", "\n", "self", ".", "distribution", ".", "set_std", "(", "0.", ")", "# Deterministic (dist_info std ignored).", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.agents.dmc_sac_agent.SacAgent.state_dict": [[223, 233], ["dict", "dmc_sac_agent.SacAgent.conv.state_dict", "dmc_sac_agent.SacAgent.q_fc1.state_dict", "dmc_sac_agent.SacAgent.pi_fc1.state_dict", "dmc_sac_agent.SacAgent.q_mlps.state_dict", "dmc_sac_agent.SacAgent.pi_mlp.state_dict", "dmc_sac_agent.SacAgent.target_conv.state_dict", "dmc_sac_agent.SacAgent.target_q_fc1.state_dict", "dmc_sac_agent.SacAgent.target_q_mlps.state_dict"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.replay_saver.DummyOptimizer.state_dict", "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.replay_saver.DummyOptimizer.state_dict", "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.replay_saver.DummyOptimizer.state_dict", "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.replay_saver.DummyOptimizer.state_dict", "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.replay_saver.DummyOptimizer.state_dict", "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.replay_saver.DummyOptimizer.state_dict", "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.replay_saver.DummyOptimizer.state_dict", "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.replay_saver.DummyOptimizer.state_dict"], ["", "def", "state_dict", "(", "self", ")", ":", "\n", "        ", "return", "dict", "(", "\n", "conv", "=", "self", ".", "conv", ".", "state_dict", "(", ")", ",", "\n", "q_fc1", "=", "self", ".", "q_fc1", ".", "state_dict", "(", ")", ",", "\n", "pi_fc1", "=", "self", ".", "pi_fc1", ".", "state_dict", "(", ")", ",", "\n", "q_mlps", "=", "self", ".", "q_mlps", ".", "state_dict", "(", ")", ",", "\n", "pi_mlp", "=", "self", ".", "pi_mlp", ".", "state_dict", "(", ")", ",", "\n", "target_conv", "=", "self", ".", "target_conv", ".", "state_dict", "(", ")", ",", "\n", "target_q_fc1", "=", "self", ".", "target_q_fc1", ".", "state_dict", "(", ")", ",", "\n", "target_q_mlps", "=", "self", ".", "target_q_mlps", ".", "state_dict", "(", ")", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.agents.dmc_sac_agent.SacAgent.load_state_dict": [[235, 244], ["dmc_sac_agent.SacAgent.conv.load_state_dict", "dmc_sac_agent.SacAgent.q_fc1.load_state_dict", "dmc_sac_agent.SacAgent.pi_fc1.load_state_dict", "dmc_sac_agent.SacAgent.q_mlps.load_state_dict", "dmc_sac_agent.SacAgent.pi_mlp.load_state_dict", "dmc_sac_agent.SacAgent.target_conv.load_state_dict", "dmc_sac_agent.SacAgent.target_q_fc1.load_state_dict", "dmc_sac_agent.SacAgent.target_q_mlps.load_state_dict"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.augmented_temporal_similarity.AugmentedTemporalSimilarity.load_state_dict", "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.augmented_temporal_similarity.AugmentedTemporalSimilarity.load_state_dict", "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.augmented_temporal_similarity.AugmentedTemporalSimilarity.load_state_dict", "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.augmented_temporal_similarity.AugmentedTemporalSimilarity.load_state_dict", "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.augmented_temporal_similarity.AugmentedTemporalSimilarity.load_state_dict", "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.augmented_temporal_similarity.AugmentedTemporalSimilarity.load_state_dict", "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.augmented_temporal_similarity.AugmentedTemporalSimilarity.load_state_dict", "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.augmented_temporal_similarity.AugmentedTemporalSimilarity.load_state_dict"], ["", "def", "load_state_dict", "(", "self", ",", "state_dict", ")", ":", "\n", "        ", "self", ".", "conv", ".", "load_state_dict", "(", "state_dict", "[", "\"conv\"", "]", ")", "\n", "self", ".", "q_fc1", ".", "load_state_dict", "(", "state_dict", "[", "\"q_fc1\"", "]", ")", "\n", "self", ".", "pi_fc1", ".", "load_state_dict", "(", "state_dict", "[", "\"pi_fc1\"", "]", ")", "\n", "self", ".", "q_mlps", ".", "load_state_dict", "(", "state_dict", "[", "\"q_mlps\"", "]", ")", "\n", "self", ".", "pi_mlp", ".", "load_state_dict", "(", "state_dict", "[", "\"pi_mlp\"", "]", ")", "\n", "self", ".", "target_conv", ".", "load_state_dict", "(", "state_dict", "[", "\"target_conv\"", "]", ")", "\n", "self", ".", "target_q_fc1", ".", "load_state_dict", "(", "state_dict", "[", "\"target_q_fc1\"", "]", ")", "\n", "self", ".", "target_q_mlps", ".", "load_state_dict", "(", "state_dict", "[", "\"target_q_mlps\"", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.agents.dmc_sac_agent.SacAgent.data_parallel": [[245, 247], ["None"], "methods", ["None"], ["", "def", "data_parallel", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "raise", "NotImplementedError", "# Do it later.", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.agents.dmc_sac_agent.SacAgent.async_cpu": [[248, 250], ["None"], "methods", ["None"], ["", "def", "async_cpu", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "raise", "NotImplementedError", "# Double check this...", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.agents.dmc_sac_agent.SacAgent.update_targets": [[251, 256], ["rlpyt.models.utils.update_state_dict", "rlpyt.models.utils.update_state_dict", "rlpyt.models.utils.update_state_dict", "dmc_sac_agent.SacAgent.conv.state_dict", "dmc_sac_agent.SacAgent.q_fc1.state_dict", "dmc_sac_agent.SacAgent.q_mlps.state_dict"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.models.utils.update_state_dict", "home.repos.pwc.inspect_result.astooke_rlpyt.models.utils.update_state_dict", "home.repos.pwc.inspect_result.astooke_rlpyt.models.utils.update_state_dict", "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.replay_saver.DummyOptimizer.state_dict", "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.replay_saver.DummyOptimizer.state_dict", "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.replay_saver.DummyOptimizer.state_dict"], ["", "def", "update_targets", "(", "self", ",", "q_tau", "=", "1", ",", "encoder_tau", "=", "1", ")", ":", "\n", "        ", "\"\"\"Do each parameter ONLY ONCE.\"\"\"", "\n", "update_state_dict", "(", "self", ".", "target_conv", ",", "self", ".", "conv", ".", "state_dict", "(", ")", ",", "encoder_tau", ")", "\n", "update_state_dict", "(", "self", ".", "target_q_fc1", ",", "self", ".", "q_fc1", ".", "state_dict", "(", ")", ",", "encoder_tau", ")", "\n", "update_state_dict", "(", "self", ".", "target_q_mlps", ",", "self", ".", "q_mlps", ".", "state_dict", "(", ")", ",", "q_tau", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.astooke_rlpyt.agents.dmlab_pg_agent.DmlabPgBaseAgent.__init__": [[22, 38], ["rlpyt.agents.base.BaseAgent.__init__"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.spaces.gym_wrapper.GymSpaceWrapper.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "ModelCls", "=", "DmlabPgLstmModel", ",", "\n", "store_latent", "=", "False", ",", "\n", "state_dict_filename", "=", "None", ",", "\n", "load_conv", "=", "False", ",", "\n", "load_all", "=", "False", ",", "\n", "**", "kwargs", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "ModelCls", "=", "ModelCls", ",", "**", "kwargs", ")", "\n", "self", ".", "store_latent", "=", "store_latent", "\n", "self", ".", "state_dict_filename", "=", "state_dict_filename", "\n", "self", ".", "load_conv", "=", "load_conv", "\n", "self", ".", "load_all", "=", "load_all", "\n", "assert", "not", "(", "load_all", "and", "load_conv", ")", "\n", "self", ".", "_act_uniform", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.agents.dmlab_pg_agent.DmlabPgBaseAgent.__call__": [[39, 47], ["dmlab_pg_agent.DmlabPgBaseAgent.distribution.to_onehot", "rlpyt.utils.buffer.buffer_to", "dmlab_pg_agent.DmlabPgBaseAgent.model", "rlpyt.utils.buffer.buffer_to", "rlpyt.distributions.categorical.DistInfo"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.distributions.discrete.DiscreteMixin.to_onehot", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.buffer.buffer_to", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.buffer.buffer_to"], ["", "def", "__call__", "(", "self", ",", "observation", ",", "prev_action", ",", "prev_reward", ",", "init_rnn_state", ")", ":", "\n", "        ", "prev_action", "=", "self", ".", "distribution", ".", "to_onehot", "(", "prev_action", ")", "\n", "model_inputs", "=", "buffer_to", "(", "(", "observation", ",", "prev_action", ",", "prev_reward", ",", "\n", "init_rnn_state", ")", ",", "\n", "device", "=", "self", ".", "device", ")", "\n", "pi", ",", "value", ",", "next_rnn_state", ",", "_", "=", "self", ".", "model", "(", "*", "model_inputs", ")", "# Ignore conv out", "\n", "dist_info", ",", "value", "=", "buffer_to", "(", "(", "DistInfo", "(", "prob", "=", "pi", ")", ",", "value", ")", ",", "device", "=", "\"cpu\"", ")", "\n", "return", "dist_info", ",", "value", ",", "next_rnn_state", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.agents.dmlab_pg_agent.DmlabPgBaseAgent.initialize": [[48, 84], ["dmlab_pg_agent.DmlabPgBaseAgent.ModelCls", "rlpyt.distributions.categorical.Categorical", "rlpyt.utils.logging.logger.log", "torch.load", "torch.load.get", "torch.load.get", "collections.OrderedDict", "dmlab_pg_agent.DmlabPgBaseAgent.model.conv.load_state_dict", "rlpyt.utils.logging.logger.log", "dmlab_pg_agent.DmlabPgBaseAgent.model.share_memory", "torch.load", "dmlab_pg_agent.DmlabPgBaseAgent.load_state_dict", "rlpyt.utils.logging.logger.log", "rlpyt.utils.logging.logger.log", "torch.device", "k.replace", "torch.load.items", "k.startswith", "torch.device"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.logging.console.log", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.collections.NamedArrayTuple.get", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.collections.NamedArrayTuple.get", "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.augmented_temporal_similarity.AugmentedTemporalSimilarity.load_state_dict", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.console.log", "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.augmented_temporal_similarity.AugmentedTemporalSimilarity.load_state_dict", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.console.log", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.console.log", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.collections.NamedArrayTuple.items"], ["", "def", "initialize", "(", "self", ",", "env_spaces", ",", "share_memory", "=", "False", ",", "\n", "global_B", "=", "1", ",", "env_ranks", "=", "None", ")", ":", "\n", "        ", "self", ".", "model", "=", "self", ".", "ModelCls", "(", "\n", "image_shape", "=", "env_spaces", ".", "observation", ".", "shape", ",", "\n", "output_size", "=", "env_spaces", ".", "action", ".", "n", ",", "\n", "**", "self", ".", "model_kwargs", "\n", ")", "# Model will have stop_grad inside it.", "\n", "if", "self", ".", "load_conv", ":", "\n", "            ", "logger", ".", "log", "(", "\"Agent loading state dict: \"", "+", "self", ".", "state_dict_filename", ")", "\n", "loaded_state_dict", "=", "torch", ".", "load", "(", "self", ".", "state_dict_filename", ",", "\n", "map_location", "=", "torch", ".", "device", "(", "'cpu'", ")", ")", "\n", "# From UL, saves snapshot: params[\"algo_state_dict\"][\"encoder\"]", "\n", "loaded_state_dict", "=", "loaded_state_dict", ".", "get", "(", "\"algo_state_dict\"", ",", "loaded_state_dict", ")", "\n", "loaded_state_dict", "=", "loaded_state_dict", ".", "get", "(", "\"encoder\"", ",", "loaded_state_dict", ")", "\n", "# A bit onerous, but ensures that state dicts match:", "\n", "conv_state_dict", "=", "OrderedDict", "(", "[", "(", "k", ".", "replace", "(", "\"conv.\"", ",", "\"\"", ",", "1", ")", ",", "v", ")", "\n", "for", "k", ",", "v", "in", "loaded_state_dict", ".", "items", "(", ")", "if", "k", ".", "startswith", "(", "\"conv.\"", ")", "]", ")", "\n", "self", ".", "model", ".", "conv", ".", "load_state_dict", "(", "conv_state_dict", ")", "\n", "logger", ".", "log", "(", "\"Agent loaded CONV state dict.\"", ")", "\n", "", "elif", "self", ".", "load_all", ":", "\n", "# From RL, saves snapshot: params[\"agent_state_dict\"]", "\n", "            ", "loaded_state_dict", "=", "torch", ".", "load", "(", "self", ".", "state_dict_filename", ",", "\n", "map_location", "=", "torch", ".", "device", "(", "'cpu'", ")", ")", "\n", "self", ".", "load_state_dict", "(", "loaded_state_dict", "[", "\"agent_state_dict\"", "]", ")", "\n", "logger", ".", "log", "(", "\"Agnet loaded FULL state dict.\"", ")", "\n", "", "else", ":", "\n", "            ", "logger", ".", "log", "(", "\"Agent NOT loading state dict.\"", ")", "\n", "\n", "", "if", "share_memory", ":", "\n", "            ", "self", ".", "model", ".", "share_memory", "(", ")", "\n", "self", ".", "shared_model", "=", "self", ".", "model", "\n", "", "if", "self", ".", "initial_model_state_dict", "is", "not", "None", ":", "\n", "            ", "raise", "NotImplementedError", "\n", "", "self", ".", "distribution", "=", "Categorical", "(", "dim", "=", "env_spaces", ".", "action", ".", "n", ")", "\n", "self", ".", "env_spaces", "=", "env_spaces", "\n", "self", ".", "share_memory", "=", "share_memory", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.agents.dmlab_pg_agent.DmlabPgBaseAgent.step": [[85, 106], ["torch.no_grad", "dmlab_pg_agent.DmlabPgBaseAgent.distribution.to_onehot", "rlpyt.utils.buffer.buffer_to", "dmlab_pg_agent.DmlabPgBaseAgent.model", "rlpyt.distributions.categorical.DistInfo", "dmlab_pg_agent.DmlabPgBaseAgent.distribution.sample", "rlpyt.utils.buffer.buffer_method", "AgentInfoRnnConv", "rlpyt.utils.buffer.buffer_to", "dmlab_pg_agent.DmlabPgBaseAgent.advance_rnn_state", "rlpyt.agents.base.AgentStep", "rlpyt.utils.buffer.buffer_func"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.distributions.discrete.DiscreteMixin.to_onehot", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.buffer.buffer_to", "home.repos.pwc.inspect_result.astooke_rlpyt.spaces.gym_wrapper.GymSpaceWrapper.sample", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.buffer.buffer_method", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.buffer.buffer_to", "home.repos.pwc.inspect_result.astooke_rlpyt.agents.base.AlternatingRecurrentAgentMixin.advance_rnn_state", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.buffer.buffer_func"], ["", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "step", "(", "self", ",", "observation", ",", "prev_action", ",", "prev_reward", ")", ":", "\n", "        ", "prev_action", "=", "self", ".", "distribution", ".", "to_onehot", "(", "prev_action", ")", "\n", "model_inputs", "=", "buffer_to", "(", "(", "observation", ",", "prev_action", ",", "prev_reward", ")", ",", "\n", "device", "=", "self", ".", "device", ")", "\n", "pi", ",", "value", ",", "rnn_state", ",", "conv", "=", "self", ".", "model", "(", "*", "model_inputs", ",", "self", ".", "prev_rnn_state", ")", "\n", "if", "self", ".", "_act_uniform", ":", "\n", "            ", "pi", "[", ":", "]", "=", "1.", "/", "pi", ".", "shape", "[", "-", "1", "]", "# uniform", "\n", "", "dist_info", "=", "DistInfo", "(", "prob", "=", "pi", ")", "\n", "action", "=", "self", ".", "distribution", ".", "sample", "(", "dist_info", ")", "\n", "# Model handles None, but Buffer does not, make zeros if needed:", "\n", "prev_rnn_state", "=", "self", ".", "prev_rnn_state", "or", "buffer_func", "(", "rnn_state", ",", "torch", ".", "zeros_like", ")", "\n", "# Transpose the rnn_state from [N,B,H] --> [B,N,H] for storage.", "\n", "# (Special case: model should always leave B dimension in.)", "\n", "prev_rnn_state", "=", "buffer_method", "(", "prev_rnn_state", ",", "\"transpose\"", ",", "0", ",", "1", ")", "\n", "agent_info", "=", "AgentInfoRnnConv", "(", "dist_info", "=", "dist_info", ",", "value", "=", "value", ",", "\n", "prev_rnn_state", "=", "prev_rnn_state", ",", "\n", "conv", "=", "conv", "if", "self", ".", "store_latent", "else", "None", ")", "# Don't write the extra data.", "\n", "action", ",", "agent_info", "=", "buffer_to", "(", "(", "action", ",", "agent_info", ")", ",", "device", "=", "\"cpu\"", ")", "\n", "self", ".", "advance_rnn_state", "(", "rnn_state", ")", "\n", "return", "AgentStep", "(", "action", "=", "action", ",", "agent_info", "=", "agent_info", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.agents.dmlab_pg_agent.DmlabPgBaseAgent.value": [[107, 114], ["torch.no_grad", "dmlab_pg_agent.DmlabPgBaseAgent.distribution.to_onehot", "rlpyt.utils.buffer.buffer_to", "dmlab_pg_agent.DmlabPgBaseAgent.model", "value.to"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.distributions.discrete.DiscreteMixin.to_onehot", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.buffer.buffer_to"], ["", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "value", "(", "self", ",", "observation", ",", "prev_action", ",", "prev_reward", ")", ":", "\n", "        ", "prev_action", "=", "self", ".", "distribution", ".", "to_onehot", "(", "prev_action", ")", "\n", "agent_inputs", "=", "buffer_to", "(", "(", "observation", ",", "prev_action", ",", "prev_reward", ")", ",", "\n", "device", "=", "self", ".", "device", ")", "\n", "_pi", ",", "value", ",", "_rnn_state", ",", "_conv", "=", "self", ".", "model", "(", "*", "agent_inputs", ",", "self", ".", "prev_rnn_state", ")", "\n", "return", "value", ".", "to", "(", "\"cpu\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.agents.dmlab_pg_agent.DmlabPgBaseAgent.set_act_uniform": [[115, 117], ["None"], "methods", ["None"], ["", "def", "set_act_uniform", "(", "self", ",", "act_uniform", "=", "True", ")", ":", "\n", "        ", "self", ".", "_act_uniform", "=", "act_uniform", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.agents.atari_dqn_agent.AtariDqnAgent.__init__": [[26, 41], ["rlpyt.utils.quick_args.save__init__args", "rlpyt.agents.dqn.epsilon_greedy.EpsilonGreedyAgentMixin.__init__", "dict", "locals"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.utils.quick_args.save__init__args", "home.repos.pwc.inspect_result.astooke_rlpyt.spaces.gym_wrapper.GymSpaceWrapper.__init__"], []], "home.repos.pwc.inspect_result.astooke_rlpyt.agents.atari_dqn_agent.AtariDqnAgent.__call__": [[42, 49], ["atari_dqn_agent.AtariDqnAgent.distribution.to_onehot", "rlpyt.utils.buffer.buffer_to", "atari_dqn_agent.AtariDqnAgent.model", "q.cpu"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.distributions.discrete.DiscreteMixin.to_onehot", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.buffer.buffer_to"], []], "home.repos.pwc.inspect_result.astooke_rlpyt.agents.atari_dqn_agent.AtariDqnAgent.initialize": [[50, 92], ["atari_dqn_agent.AtariDqnAgent.ModelCls", "copy.deepcopy", "rlpyt.distributions.epsilon_greedy.EpsilonGreedy", "rlpyt.utils.logging.logger.log", "torch.load", "torch.load.get", "torch.load.get", "collections.OrderedDict", "atari_dqn_agent.AtariDqnAgent.model.conv.load_state_dict", "rlpyt.utils.logging.logger.log", "atari_dqn_agent.AtariDqnAgent.make_vec_eps", "atari_dqn_agent.AtariDqnAgent.model.share_memory", "torch.load", "atari_dqn_agent.AtariDqnAgent.load_state_dict", "rlpyt.utils.logging.logger.log", "rlpyt.utils.logging.logger.log", "torch.device", "k.replace", "torch.load.items", "k.startswith", "torch.device"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.logging.console.log", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.collections.NamedArrayTuple.get", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.collections.NamedArrayTuple.get", "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.augmented_temporal_similarity.AugmentedTemporalSimilarity.load_state_dict", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.console.log", "home.repos.pwc.inspect_result.astooke_rlpyt.dqn.epsilon_greedy.EpsilonGreedyAgentMixin.make_vec_eps", "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.augmented_temporal_similarity.AugmentedTemporalSimilarity.load_state_dict", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.console.log", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.console.log", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.collections.NamedArrayTuple.items"], []], "home.repos.pwc.inspect_result.astooke_rlpyt.agents.atari_dqn_agent.AtariDqnAgent.to_device": [[93, 96], ["super().to_device", "atari_dqn_agent.AtariDqnAgent.target_model.to"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.safe.cppo_agent.CppoLstmAgent.to_device"], []], "home.repos.pwc.inspect_result.astooke_rlpyt.agents.atari_dqn_agent.AtariDqnAgent.state_dict": [[97, 100], ["dict", "atari_dqn_agent.AtariDqnAgent.model.state_dict", "atari_dqn_agent.AtariDqnAgent.target_model.state_dict"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.replay_saver.DummyOptimizer.state_dict", "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.replay_saver.DummyOptimizer.state_dict"], []], "home.repos.pwc.inspect_result.astooke_rlpyt.agents.atari_dqn_agent.AtariDqnAgent.step": [[101, 115], ["torch.no_grad", "atari_dqn_agent.AtariDqnAgent.distribution.to_onehot", "rlpyt.utils.buffer.buffer_to", "atari_dqn_agent.AtariDqnAgent.model", "q.cpu.cpu.cpu", "atari_dqn_agent.AtariDqnAgent.distribution.sample", "AgentInfoConv", "rlpyt.agents.base.AgentStep"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.distributions.discrete.DiscreteMixin.to_onehot", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.buffer.buffer_to", "home.repos.pwc.inspect_result.astooke_rlpyt.spaces.gym_wrapper.GymSpaceWrapper.sample"], []], "home.repos.pwc.inspect_result.astooke_rlpyt.agents.atari_dqn_agent.AtariDqnAgent.target": [[116, 123], ["atari_dqn_agent.AtariDqnAgent.distribution.to_onehot", "rlpyt.utils.buffer.buffer_to", "atari_dqn_agent.AtariDqnAgent.target_model", "target_q.cpu"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.distributions.discrete.DiscreteMixin.to_onehot", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.buffer.buffer_to"], []], "home.repos.pwc.inspect_result.astooke_rlpyt.agents.atari_dqn_agent.AtariDqnAgent.update_target": [[124, 127], ["rlpyt.models.utils.update_state_dict", "atari_dqn_agent.AtariDqnAgent.model.state_dict"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.models.utils.update_state_dict", "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.replay_saver.DummyOptimizer.state_dict"], []], "home.repos.pwc.inspect_result.astooke_rlpyt.agents.atari_pg_agent.AtariPgAgent.__init__": [[19, 35], ["rlpyt.agents.base.BaseAgent.__init__"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.spaces.gym_wrapper.GymSpaceWrapper.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "ModelCls", "=", "AtariPgModel", ",", "\n", "store_latent", "=", "False", ",", "\n", "state_dict_filename", "=", "None", ",", "\n", "load_conv", "=", "False", ",", "\n", "load_all", "=", "False", ",", "\n", "**", "kwargs", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "ModelCls", "=", "ModelCls", ",", "**", "kwargs", ")", "\n", "self", ".", "store_latent", "=", "store_latent", "\n", "self", ".", "state_dict_filename", "=", "state_dict_filename", "\n", "self", ".", "load_conv", "=", "load_conv", "\n", "self", ".", "load_all", "=", "load_all", "\n", "assert", "not", "(", "load_all", "and", "load_conv", ")", "\n", "self", ".", "_act_uniform", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.agents.atari_pg_agent.AtariPgAgent.__call__": [[36, 42], ["atari_pg_agent.AtariPgAgent.distribution.to_onehot", "rlpyt.utils.buffer.buffer_to", "atari_pg_agent.AtariPgAgent.model", "rlpyt.utils.buffer.buffer_to", "rlpyt.distributions.categorical.DistInfo"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.distributions.discrete.DiscreteMixin.to_onehot", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.buffer.buffer_to", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.buffer.buffer_to"], ["", "def", "__call__", "(", "self", ",", "observation", ",", "prev_action", ",", "prev_reward", ")", ":", "\n", "        ", "prev_action", "=", "self", ".", "distribution", ".", "to_onehot", "(", "prev_action", ")", "\n", "model_inputs", "=", "buffer_to", "(", "(", "observation", ",", "prev_action", ",", "prev_reward", ")", ",", "\n", "device", "=", "self", ".", "device", ")", "\n", "pi", ",", "value", ",", "_", "=", "self", ".", "model", "(", "*", "model_inputs", ")", "# ignore conv output", "\n", "return", "buffer_to", "(", "(", "DistInfo", "(", "prob", "=", "pi", ")", ",", "value", ")", ",", "device", "=", "\"cpu\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.agents.atari_pg_agent.AtariPgAgent.initialize": [[43, 79], ["atari_pg_agent.AtariPgAgent.ModelCls", "rlpyt.distributions.categorical.Categorical", "rlpyt.utils.logging.logger.log", "torch.load", "torch.load.get", "torch.load.get", "collections.OrderedDict", "atari_pg_agent.AtariPgAgent.model.conv.load_state_dict", "rlpyt.utils.logging.logger.log", "atari_pg_agent.AtariPgAgent.model.share_memory", "torch.load", "atari_pg_agent.AtariPgAgent.load_state_dict", "rlpyt.utils.logging.logger.log", "rlpyt.utils.logging.logger.log", "torch.device", "k.replace", "torch.load.items", "k.startswith", "torch.device"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.logging.console.log", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.collections.NamedArrayTuple.get", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.collections.NamedArrayTuple.get", "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.augmented_temporal_similarity.AugmentedTemporalSimilarity.load_state_dict", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.console.log", "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.augmented_temporal_similarity.AugmentedTemporalSimilarity.load_state_dict", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.console.log", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.console.log", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.collections.NamedArrayTuple.items"], ["", "def", "initialize", "(", "self", ",", "env_spaces", ",", "share_memory", "=", "False", ",", "\n", "global_B", "=", "1", ",", "env_ranks", "=", "None", ")", ":", "\n", "        ", "self", ".", "model", "=", "self", ".", "ModelCls", "(", "\n", "image_shape", "=", "env_spaces", ".", "observation", ".", "shape", ",", "\n", "action_size", "=", "env_spaces", ".", "action", ".", "n", ",", "\n", "**", "self", ".", "model_kwargs", "\n", ")", "# Model will have stop_grad inside it.", "\n", "if", "self", ".", "load_conv", ":", "\n", "            ", "logger", ".", "log", "(", "\"Agent loading state dict: \"", "+", "self", ".", "state_dict_filename", ")", "\n", "loaded_state_dict", "=", "torch", ".", "load", "(", "self", ".", "state_dict_filename", ",", "\n", "map_location", "=", "torch", ".", "device", "(", "'cpu'", ")", ")", "\n", "# From UL, saves snapshot: params[\"algo_state_dict\"][\"encoder\"]", "\n", "loaded_state_dict", "=", "loaded_state_dict", ".", "get", "(", "\"algo_state_dict\"", ",", "loaded_state_dict", ")", "\n", "loaded_state_dict", "=", "loaded_state_dict", ".", "get", "(", "\"encoder\"", ",", "loaded_state_dict", ")", "\n", "# A bit onerous, but ensures that state dicts match:", "\n", "conv_state_dict", "=", "OrderedDict", "(", "[", "(", "k", ".", "replace", "(", "\"conv.\"", ",", "\"\"", ",", "1", ")", ",", "v", ")", "\n", "for", "k", ",", "v", "in", "loaded_state_dict", ".", "items", "(", ")", "if", "k", ".", "startswith", "(", "\"conv.\"", ")", "]", ")", "\n", "self", ".", "model", ".", "conv", ".", "load_state_dict", "(", "conv_state_dict", ")", "\n", "logger", ".", "log", "(", "\"Agent loaded CONV state dict.\"", ")", "\n", "", "elif", "self", ".", "load_all", ":", "\n", "# From RL, saves snapshot: params[\"agent_state_dict\"]", "\n", "            ", "loaded_state_dict", "=", "torch", ".", "load", "(", "self", ".", "state_dict_filename", ",", "\n", "map_location", "=", "torch", ".", "device", "(", "'cpu'", ")", ")", "\n", "self", ".", "load_state_dict", "(", "loaded_state_dict", "[", "\"agent_state_dict\"", "]", ")", "\n", "logger", ".", "log", "(", "\"Agnet loaded FULL state dict.\"", ")", "\n", "", "else", ":", "\n", "            ", "logger", ".", "log", "(", "\"Agent NOT loading state dict.\"", ")", "\n", "\n", "", "if", "share_memory", ":", "\n", "            ", "self", ".", "model", ".", "share_memory", "(", ")", "\n", "self", ".", "shared_model", "=", "self", ".", "model", "\n", "", "if", "self", ".", "initial_model_state_dict", "is", "not", "None", ":", "\n", "            ", "raise", "NotImplementedError", "\n", "", "self", ".", "distribution", "=", "Categorical", "(", "dim", "=", "env_spaces", ".", "action", ".", "n", ")", "\n", "self", ".", "env_spaces", "=", "env_spaces", "\n", "self", ".", "share_memory", "=", "share_memory", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.agents.atari_pg_agent.AtariPgAgent.step": [[80, 94], ["torch.no_grad", "atari_pg_agent.AtariPgAgent.distribution.to_onehot", "rlpyt.utils.buffer.buffer_to", "atari_pg_agent.AtariPgAgent.model", "rlpyt.distributions.categorical.DistInfo", "atari_pg_agent.AtariPgAgent.distribution.sample", "AgentInfoConv", "rlpyt.utils.buffer.buffer_to", "rlpyt.agents.base.AgentStep"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.distributions.discrete.DiscreteMixin.to_onehot", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.buffer.buffer_to", "home.repos.pwc.inspect_result.astooke_rlpyt.spaces.gym_wrapper.GymSpaceWrapper.sample", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.buffer.buffer_to"], ["", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "step", "(", "self", ",", "observation", ",", "prev_action", ",", "prev_reward", ")", ":", "\n", "        ", "prev_action", "=", "self", ".", "distribution", ".", "to_onehot", "(", "prev_action", ")", "\n", "model_inputs", "=", "buffer_to", "(", "(", "observation", ",", "prev_action", ",", "prev_reward", ")", ",", "\n", "device", "=", "self", ".", "device", ")", "\n", "pi", ",", "value", ",", "conv", "=", "self", ".", "model", "(", "*", "model_inputs", ")", "\n", "if", "self", ".", "_act_uniform", ":", "\n", "            ", "pi", "[", ":", "]", "=", "1.", "/", "pi", ".", "shape", "[", "-", "1", "]", "# uniform", "\n", "", "dist_info", "=", "DistInfo", "(", "prob", "=", "pi", ")", "\n", "action", "=", "self", ".", "distribution", ".", "sample", "(", "dist_info", ")", "\n", "agent_info", "=", "AgentInfoConv", "(", "dist_info", "=", "dist_info", ",", "value", "=", "value", ",", "\n", "conv", "=", "conv", "if", "self", ".", "store_latent", "else", "None", ")", "# Don't write extra data.", "\n", "action", ",", "agent_info", "=", "buffer_to", "(", "(", "action", ",", "agent_info", ")", ",", "device", "=", "\"cpu\"", ")", "\n", "return", "AgentStep", "(", "action", "=", "action", ",", "agent_info", "=", "agent_info", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.agents.atari_pg_agent.AtariPgAgent.value": [[95, 102], ["torch.no_grad", "atari_pg_agent.AtariPgAgent.distribution.to_onehot", "rlpyt.utils.buffer.buffer_to", "atari_pg_agent.AtariPgAgent.model", "value.to"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.distributions.discrete.DiscreteMixin.to_onehot", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.buffer.buffer_to"], ["", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "value", "(", "self", ",", "observation", ",", "prev_action", ",", "prev_reward", ")", ":", "\n", "        ", "prev_action", "=", "self", ".", "distribution", ".", "to_onehot", "(", "prev_action", ")", "\n", "model_inputs", "=", "buffer_to", "(", "(", "observation", ",", "prev_action", ",", "prev_reward", ")", ",", "\n", "device", "=", "self", ".", "device", ")", "\n", "_pi", ",", "value", ",", "_", "=", "self", ".", "model", "(", "*", "model_inputs", ")", "# Ignore conv out", "\n", "return", "value", ".", "to", "(", "\"cpu\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.agents.atari_pg_agent.AtariPgAgent.set_act_uniform": [[103, 105], ["None"], "methods", ["None"], ["", "def", "set_act_uniform", "(", "self", ",", "act_uniform", "=", "True", ")", ":", "\n", "        ", "self", ".", "_act_uniform", "=", "act_uniform", "\n", "", "", ""]], "home.repos.pwc.inspect_result.astooke_rlpyt.replays.base.BaseReplayBuffer.append_samples": [[7, 10], ["None"], "methods", ["None"], ["\n", "\n", "opt_info_fields", "=", "(", ")", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.replays.base.BaseReplayBuffer.sample_batch": [[11, 14], ["None"], "methods", ["None"], ["bootstrap_value", "=", "False", "\n", "update_counter", "=", "0", "\n", "\n", "def", "initialize", "(", "self", ",", "agent", ",", "n_itr", ",", "batch_spec", ",", "mid_batch_reset", ",", "examples", ",", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.replays.frame.FrameBufferMixin.__init__": [[27, 45], ["rlpyt.utils.collections.namedarraytuple", "rlpyt.utils.collections.namedarraytuple.", "super().__init__", "rlpyt.utils.logging.logger.log", "rlpyt.utils.buffer.buffer_from_example", "max", "rlpyt.utils.buffer.get_leading_dims", "example.items"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.utils.collections.namedarraytuple", "home.repos.pwc.inspect_result.astooke_rlpyt.spaces.gym_wrapper.GymSpaceWrapper.__init__", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.console.log", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.buffer.buffer_from_example", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.buffer.get_leading_dims", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.collections.NamedArrayTuple.items"], ["def", "__init__", "(", "self", ",", "example", ",", "**", "kwargs", ")", ":", "\n", "        ", "field_names", "=", "[", "f", "for", "f", "in", "example", ".", "_fields", "if", "f", "!=", "\"observation\"", "]", "\n", "global", "BufferSamples", "\n", "BufferSamples", "=", "namedarraytuple", "(", "\"BufferSamples\"", ",", "field_names", ")", "\n", "buffer_example", "=", "BufferSamples", "(", "*", "(", "v", "for", "k", ",", "v", "in", "example", ".", "items", "(", ")", "\n", "if", "k", "!=", "\"observation\"", ")", ")", "\n", "super", "(", ")", ".", "__init__", "(", "example", "=", "buffer_example", ",", "**", "kwargs", ")", "\n", "# Equivalent to image.shape[0] if observation is image array (C,H,W):", "\n", "self", ".", "n_frames", "=", "n_frames", "=", "get_leading_dims", "(", "example", ".", "observation", ",", "\n", "n_dim", "=", "1", ")", "[", "0", "]", "\n", "logger", ".", "log", "(", "f\"Frame-based buffer using {n_frames}-frame sequences.\"", ")", "\n", "# frames: oldest stored at t; duplicate n_frames - 1 beginning & end.", "\n", "self", ".", "samples_frames", "=", "buffer_from_example", "(", "example", ".", "observation", "[", "0", "]", ",", "\n", "(", "self", ".", "T", "+", "n_frames", "-", "1", ",", "self", ".", "B", ")", ",", "\n", "share_memory", "=", "self", ".", "async_", ")", "# [T+n_frames-1,B,H,W]", "\n", "# new_frames: shifted so newest stored at t; no duplication.", "\n", "self", ".", "samples_new_frames", "=", "self", ".", "samples_frames", "[", "n_frames", "-", "1", ":", "]", "# [T,B,H,W]", "\n", "self", ".", "off_forward", "=", "max", "(", "self", ".", "off_forward", ",", "n_frames", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.replays.frame.FrameBufferMixin.append_samples": [[46, 60], ["BufferSamples", "super().append_samples", "range", "samples.items"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.sequence.prioritized.PrioritizedSequenceReplay.append_samples", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.collections.NamedArrayTuple.items"], ["", "def", "append_samples", "(", "self", ",", "samples", ")", ":", "\n", "        ", "\"\"\"Appends all samples except for the `observation` as normal.\n        Only the new frame in each observation is recorded.\"\"\"", "\n", "t", ",", "fm1", "=", "self", ".", "t", ",", "self", ".", "n_frames", "-", "1", "\n", "buffer_samples", "=", "BufferSamples", "(", "*", "(", "v", "for", "k", ",", "v", "in", "samples", ".", "items", "(", ")", "\n", "if", "k", "!=", "\"observation\"", ")", ")", "\n", "T", ",", "idxs", "=", "super", "(", ")", ".", "append_samples", "(", "buffer_samples", ")", "\n", "self", ".", "samples_new_frames", "[", "idxs", "]", "=", "samples", ".", "observation", "[", ":", ",", ":", ",", "-", "1", "]", "\n", "if", "t", "==", "0", ":", "# Starting: write early frames", "\n", "            ", "for", "f", "in", "range", "(", "fm1", ")", ":", "\n", "                ", "self", ".", "samples_frames", "[", "f", "]", "=", "samples", ".", "observation", "[", "0", ",", ":", ",", "f", "]", "\n", "", "", "elif", "self", ".", "t", "<", "t", "and", "fm1", ">", "0", ":", "# Wrapped: copy any duplicate frames.", "\n", "            ", "self", ".", "samples_frames", "[", ":", "fm1", "]", "=", "self", ".", "samples_frames", "[", "-", "fm1", ":", "]", "\n", "", "return", "T", ",", "idxs", "\n", "", "", ""]], "home.repos.pwc.inspect_result.astooke_rlpyt.replays.async_.AsyncReplayBufferMixin.__init__": [[19, 24], ["super().__init__", "multiprocessing.RawValue", "rlpyt.utils.synchronize.RWLock", "multiprocessing.RawValue"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.spaces.gym_wrapper.GymSpaceWrapper.__init__"], ["def", "__init__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "self", ".", "async_t", "=", "mp", ".", "RawValue", "(", "\"l\"", ")", "# Type c_long.", "\n", "self", ".", "rw_lock", "=", "RWLock", "(", ")", "\n", "self", ".", "_async_buffer_full", "=", "mp", ".", "RawValue", "(", "ctypes", ".", "c_bool", ",", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.replays.async_.AsyncReplayBufferMixin.append_samples": [[25, 31], ["async_.AsyncReplayBufferMixin._async_pull", "super().append_samples", "async_.AsyncReplayBufferMixin._async_push"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.replays.async_.AsyncReplayBufferMixin._async_pull", "home.repos.pwc.inspect_result.astooke_rlpyt.sequence.prioritized.PrioritizedSequenceReplay.append_samples", "home.repos.pwc.inspect_result.astooke_rlpyt.replays.async_.AsyncReplayBufferMixin._async_push"], ["", "def", "append_samples", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "with", "self", ".", "rw_lock", ".", "write_lock", ":", "\n", "            ", "self", ".", "_async_pull", "(", ")", "# Updates from other writers.", "\n", "ret", "=", "super", "(", ")", ".", "append_samples", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "self", ".", "_async_push", "(", ")", "# Updates to other writers + readers.", "\n", "", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.replays.async_.AsyncReplayBufferMixin.sample_batch": [[32, 36], ["async_.AsyncReplayBufferMixin._async_pull", "super().sample_batch"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.replays.async_.AsyncReplayBufferMixin._async_pull", "home.repos.pwc.inspect_result.astooke_rlpyt.sequence.uniform.UniformSequenceReplay.sample_batch"], ["", "def", "sample_batch", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "with", "self", ".", "rw_lock", ":", "# Read lock.", "\n", "            ", "self", ".", "_async_pull", "(", ")", "# Updates from writers.", "\n", "return", "super", "(", ")", ".", "sample_batch", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.replays.async_.AsyncReplayBufferMixin.update_batch_priorities": [[37, 40], ["super().update_batch_priorities"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.sequence.prioritized.PrioritizedSequenceReplay.update_batch_priorities"], ["", "", "def", "update_batch_priorities", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "with", "self", ".", "rw_lock", ".", "write_lock", ":", "\n", "            ", "return", "super", "(", ")", ".", "update_batch_priorities", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.replays.async_.AsyncReplayBufferMixin._async_pull": [[41, 44], ["None"], "methods", ["None"], ["", "", "def", "_async_pull", "(", "self", ")", ":", "\n", "        ", "self", ".", "t", "=", "self", ".", "async_t", ".", "value", "\n", "self", ".", "_buffer_full", "=", "self", ".", "_async_buffer_full", ".", "value", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.replays.async_.AsyncReplayBufferMixin._async_push": [[45, 48], ["None"], "methods", ["None"], ["", "def", "_async_push", "(", "self", ")", ":", "\n", "        ", "self", ".", "async_t", ".", "value", "=", "self", ".", "t", "\n", "self", ".", "_async_buffer_full", ".", "value", "=", "self", ".", "_buffer_full", "\n", "", "", ""]], "home.repos.pwc.inspect_result.astooke_rlpyt.replays.n_step.BaseNStepReturnBuffer.__init__": [[41, 61], ["math.ceil", "rlpyt.utils.buffer.buffer_from_example", "rlpyt.utils.buffer.buffer_from_example", "rlpyt.utils.buffer.buffer_from_example"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.utils.buffer.buffer_from_example", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.buffer.buffer_from_example", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.buffer.buffer_from_example"], ["def", "__init__", "(", "self", ",", "example", ",", "size", ",", "B", ",", "discount", "=", "1", ",", "n_step_return", "=", "1", ")", ":", "\n", "        ", "self", ".", "T", "=", "T", "=", "math", ".", "ceil", "(", "size", "/", "B", ")", "\n", "self", ".", "B", "=", "B", "\n", "self", ".", "size", "=", "T", "*", "B", "\n", "self", ".", "discount", "=", "discount", "\n", "self", ".", "n_step_return", "=", "n_step_return", "\n", "self", ".", "t", "=", "0", "# Cursor (in T dimension).", "\n", "self", ".", "samples", "=", "buffer_from_example", "(", "example", ",", "(", "T", ",", "B", ")", ",", "\n", "share_memory", "=", "self", ".", "async_", ")", "\n", "if", "n_step_return", ">", "1", ":", "\n", "            ", "self", ".", "samples_return_", "=", "buffer_from_example", "(", "example", ".", "reward", ",", "(", "T", ",", "B", ")", ",", "\n", "share_memory", "=", "self", ".", "async_", ")", "\n", "self", ".", "samples_done_n", "=", "buffer_from_example", "(", "example", ".", "done", ",", "(", "T", ",", "B", ")", ",", "\n", "share_memory", "=", "self", ".", "async_", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "samples_return_", "=", "self", ".", "samples", ".", "reward", "\n", "self", ".", "samples_done_n", "=", "self", ".", "samples", ".", "done", "\n", "", "self", ".", "_buffer_full", "=", "False", "\n", "self", ".", "off_backward", "=", "n_step_return", "# Current invalid samples.", "\n", "self", ".", "off_forward", "=", "1", "# i.e. current cursor, prev_action overwritten.", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.replays.n_step.BaseNStepReturnBuffer.append_samples": [[62, 80], ["rlpyt.utils.buffer.get_leading_dims", "n_step.BaseNStepReturnBuffer.compute_returns", "slice", "numpy.arange"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.utils.buffer.get_leading_dims", "home.repos.pwc.inspect_result.astooke_rlpyt.non_sequence.time_limit.NStepTimeLimitBuffer.compute_returns"], ["", "def", "append_samples", "(", "self", ",", "samples", ")", ":", "\n", "        ", "\"\"\"Write the samples into the buffer and advance the time cursor.\n        Handle wrapping of the cursor if necessary (boundary doesn't need to\n        align with length of ``samples``).  Compute and store returns with\n        newly available rewards.\"\"\"", "\n", "T", ",", "B", "=", "get_leading_dims", "(", "samples", ",", "n_dim", "=", "2", ")", "# samples.env.reward.shape[:2]", "\n", "assert", "B", "==", "self", ".", "B", "\n", "t", "=", "self", ".", "t", "\n", "if", "t", "+", "T", ">", "self", ".", "T", ":", "# Wrap.", "\n", "            ", "idxs", "=", "np", ".", "arange", "(", "t", ",", "t", "+", "T", ")", "%", "self", ".", "T", "\n", "", "else", ":", "\n", "            ", "idxs", "=", "slice", "(", "t", ",", "t", "+", "T", ")", "\n", "", "self", ".", "samples", "[", "idxs", "]", "=", "samples", "\n", "self", ".", "compute_returns", "(", "T", ")", "\n", "if", "not", "self", ".", "_buffer_full", "and", "t", "+", "T", ">=", "self", ".", "T", ":", "\n", "            ", "self", ".", "_buffer_full", "=", "True", "# Only changes on first around.", "\n", "", "self", ".", "t", "=", "(", "t", "+", "T", ")", "%", "self", ".", "T", "\n", "return", "T", ",", "idxs", "# Pass these on to subclass.", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.replays.n_step.BaseNStepReturnBuffer.compute_returns": [[81, 109], ["rlpyt.algos.utils.discount_return_n_step", "rlpyt.algos.utils.discount_return_n_step", "numpy.arange"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.algos.utils.discount_return_n_step", "home.repos.pwc.inspect_result.astooke_rlpyt.algos.utils.discount_return_n_step"], ["", "def", "compute_returns", "(", "self", ",", "T", ")", ":", "\n", "        ", "\"\"\"Compute the n-step returns using the new rewards just written into\n        the buffer, but before the buffer cursor is advanced.  Input ``T`` is\n        the number of new timesteps which were just written.\n        Does nothing if `n-step==1`. e.g. if 2-step return, t-1\n        is first return written here, using reward at t-1 and new reward at t\n        (up through t-1+T from t+T).\"\"\"", "\n", "if", "self", ".", "n_step_return", "==", "1", ":", "\n", "            ", "return", "# return = reward, done_n = done", "\n", "", "t", ",", "s", "=", "self", ".", "t", ",", "self", ".", "samples", "\n", "nm1", "=", "self", ".", "n_step_return", "-", "1", "\n", "if", "t", "-", "nm1", ">=", "0", "and", "t", "+", "T", "<=", "self", ".", "T", ":", "# No wrap (operate in-place).", "\n", "            ", "reward", "=", "s", ".", "reward", "[", "t", "-", "nm1", ":", "t", "+", "T", "]", "\n", "done", "=", "s", ".", "done", "[", "t", "-", "nm1", ":", "t", "+", "T", "]", "\n", "return_dest", "=", "self", ".", "samples_return_", "[", "t", "-", "nm1", ":", "t", "-", "nm1", "+", "T", "]", "\n", "done_n_dest", "=", "self", ".", "samples_done_n", "[", "t", "-", "nm1", ":", "t", "-", "nm1", "+", "T", "]", "\n", "discount_return_n_step", "(", "reward", ",", "done", ",", "n_step", "=", "self", ".", "n_step_return", ",", "\n", "discount", "=", "self", ".", "discount", ",", "return_dest", "=", "return_dest", ",", "\n", "done_n_dest", "=", "done_n_dest", ")", "\n", "", "else", ":", "# Wrap (copies); Let it (wrongly) wrap at first call.", "\n", "            ", "idxs", "=", "np", ".", "arange", "(", "t", "-", "nm1", ",", "t", "+", "T", ")", "%", "self", ".", "T", "\n", "reward", "=", "s", ".", "reward", "[", "idxs", "]", "\n", "done", "=", "s", ".", "done", "[", "idxs", "]", "\n", "dest_idxs", "=", "idxs", "[", ":", "-", "nm1", "]", "\n", "return_", ",", "done_n", "=", "discount_return_n_step", "(", "reward", ",", "done", ",", "\n", "n_step", "=", "self", ".", "n_step_return", ",", "discount", "=", "self", ".", "discount", ")", "\n", "self", ".", "samples_return_", "[", "dest_idxs", "]", "=", "return_", "\n", "self", ".", "samples_done_n", "[", "dest_idxs", "]", "=", "done_n", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.astooke_rlpyt.replays.sum_tree.SumTree.__init__": [[27, 49], ["int", "sum_tree.SumTree._allocate_tree", "sum_tree.SumTree.tree[].reshape", "sum_tree.SumTree.reset", "numpy.ceil", "numpy.ones", "numpy.log2"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.replays.sum_tree.AsyncSumTree._allocate_tree", "home.repos.pwc.inspect_result.astooke_rlpyt.safe.safety_gym_env.SafetyGymEnvWrapper.reset"], ["def", "__init__", "(", "self", ",", "T", ",", "B", ",", "off_backward", ",", "off_forward", ",", "\n", "default_value", "=", "1", ",", "\n", "enable_input_priorities", "=", "False", ",", "\n", "input_priority_shift", "=", "0", ",", "# Does not apply to update_batch_pri.", "\n", ")", ":", "\n", "        ", "self", ".", "T", "=", "T", "\n", "self", ".", "B", "=", "B", "\n", "self", ".", "size", "=", "T", "*", "B", "\n", "self", ".", "off_backward", "=", "off_backward", "\n", "self", ".", "off_forward", "=", "off_forward", "\n", "self", ".", "default_value", "=", "default_value", "\n", "self", ".", "input_priority_shift", "=", "input_priority_shift", "# (See self.sample()).", "\n", "self", ".", "tree_levels", "=", "int", "(", "np", ".", "ceil", "(", "np", ".", "log2", "(", "self", ".", "size", "+", "1", ")", ")", "+", "1", ")", "\n", "self", ".", "_allocate_tree", "(", ")", "\n", "self", ".", "low_idx", "=", "2", "**", "(", "self", ".", "tree_levels", "-", "1", ")", "-", "1", "# pri_idx + low_idx -> tree_idx", "\n", "self", ".", "high_idx", "=", "self", ".", "size", "+", "self", ".", "low_idx", "\n", "self", ".", "priorities", "=", "self", ".", "tree", "[", "self", ".", "low_idx", ":", "self", ".", "high_idx", "]", ".", "reshape", "(", "T", ",", "B", ")", "\n", "if", "enable_input_priorities", ":", "\n", "            ", "self", ".", "input_priorities", "=", "default_value", "*", "np", ".", "ones", "(", "(", "T", ",", "B", ")", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "input_priorities", "=", "None", "# Save memory.", "\n", "", "self", ".", "reset", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.replays.sum_tree.SumTree._allocate_tree": [[50, 52], ["numpy.zeros"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.utils.misc.zeros"], ["", "def", "_allocate_tree", "(", "self", ")", ":", "\n", "        ", "self", ".", "tree", "=", "np", ".", "zeros", "(", "2", "**", "self", ".", "tree_levels", "-", "1", ")", "# Double precision.", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.replays.sum_tree.SumTree.reset": [[53, 59], ["sum_tree.SumTree.tree.fill"], "methods", ["None"], ["", "def", "reset", "(", "self", ")", ":", "\n", "        ", "self", ".", "tree", ".", "fill", "(", "0", ")", "\n", "self", ".", "t", "=", "0", "\n", "self", ".", "_initial_wrap_guard", "=", "True", "\n", "if", "self", ".", "input_priorities", "is", "not", "None", ":", "\n", "            ", "self", ".", "input_priorities", "[", ":", "]", "=", "self", ".", "default_value", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.replays.sum_tree.SumTree.advance": [[60, 100], ["sum_tree.SumTree.reconstruct_advance", "max", "max", "slice", "numpy.arange"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.replays.sum_tree.SumTree.reconstruct_advance"], ["", "", "def", "advance", "(", "self", ",", "T", ",", "priorities", "=", "None", ")", ":", "\n", "        ", "\"\"\"Cursor advances by T: set priorities to zero in vicinity of new\n        cursor position and turn priorities on for new samples since previous\n        cursor position.\n        Optional param ``priorities`` can be None for default, or of\n        dimensions [T, B], or [B] or scalar will broadcast. (Must have enabled\n        ``input_priorities=True`` when instantiating the tree.)  These will be\n        stored at the current cursor position, meaning these priorities\n        correspond to the current values being added to the buffer, even\n        though their priority might temporarily be set to zero until future\n        advances.\n        \"\"\"", "\n", "if", "T", "==", "0", ":", "\n", "            ", "return", "\n", "", "t", ",", "b", ",", "f", "=", "self", ".", "t", ",", "self", ".", "off_backward", ",", "self", ".", "off_forward", "\n", "low_on_t", "=", "(", "t", "-", "b", ")", "%", "self", ".", "T", "# inclusive range: [0, self.T-1]", "\n", "high_on_t", "=", "(", "(", "t", "+", "T", "-", "b", "-", "1", ")", "%", "self", ".", "T", ")", "+", "1", "# inclusive: [1, self.T]", "\n", "low_off_t", "=", "(", "t", "+", "T", "-", "b", ")", "%", "self", ".", "T", "\n", "high_off_t", "=", "(", "(", "t", "+", "T", "+", "f", "-", "1", ")", "%", "self", ".", "T", ")", "+", "1", "\n", "if", "self", ".", "_initial_wrap_guard", ":", "\n", "            ", "low_on_t", "=", "max", "(", "f", ",", "t", "-", "b", ")", "# Don't wrap back to end, and off_forward.", "\n", "high_on_t", "=", "low_off_t", "=", "max", "(", "low_on_t", ",", "t", "+", "T", "-", "b", ")", "\n", "if", "t", "+", "T", "-", "b", ">=", "f", ":", "# Next low_on_t >= f.", "\n", "                ", "self", ".", "_initial_wrap_guard", "=", "False", "\n", "", "", "if", "priorities", "is", "not", "None", ":", "\n", "            ", "assert", "self", ".", "input_priorities", "is", "not", "None", ",", "\"Must enable input priorities.\"", "\n", "# e.g. Use input_priority_shift = warmup_T // rnn_state_interval", "\n", "# to make the fresh priority at t be the one input with the later", "\n", "# samples at t + shift, which would be the start of training", "\n", "# (priorities are aligned with start of warmup sequence).", "\n", "input_t", "=", "t", "-", "self", ".", "input_priority_shift", "\n", "if", "input_t", "<", "0", "or", "input_t", "+", "T", ">", "self", ".", "T", ":", "# Wrap (even at very first).", "\n", "                ", "idxs", "=", "np", ".", "arange", "(", "input_t", ",", "input_t", "+", "T", ")", "%", "self", ".", "T", "\n", "", "else", ":", "\n", "                ", "idxs", "=", "slice", "(", "input_t", ",", "input_t", "+", "T", ")", "\n", "", "self", ".", "input_priorities", "[", "idxs", "]", "=", "priorities", "\n", "if", "self", ".", "_initial_wrap_guard", "and", "input_t", "<", "0", ":", "\n", "                ", "self", ".", "input_priorities", "[", "input_t", ":", "]", "=", "self", ".", "default_value", "# Restore.", "\n", "", "", "self", ".", "reconstruct_advance", "(", "low_on_t", ",", "high_on_t", ",", "low_off_t", ",", "high_off_t", ")", "\n", "self", ".", "t", "=", "(", "t", "+", "T", ")", "%", "self", ".", "T", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.replays.sum_tree.SumTree.sample": [[101, 129], ["numpy.random.rand", "sum_tree.SumTree.find", "numpy.divmod", "int", "numpy.unique", "len", "RuntimeError", "len", "sum_tree.SumTree.find", "numpy.concatenate", "numpy.concatenate", "numpy.random.rand", "len"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.replays.sum_tree.SumTree.find", "home.repos.pwc.inspect_result.astooke_rlpyt.replays.sum_tree.SumTree.find"], ["", "def", "sample", "(", "self", ",", "n", ",", "unique", "=", "False", ")", ":", "\n", "        ", "\"\"\"Get `n` samples, with replacement (default) or without.  Use \n        ``np.random.rand()`` to generate random values with which to descend\n        the tree to each sampled leaf node. Returns `T_idxs` and `B_idxs`, and sample\n        priorities.\"\"\"", "\n", "self", ".", "_sampled_unique", "=", "unique", "\n", "random_values", "=", "np", ".", "random", ".", "rand", "(", "int", "(", "n", "*", "1", "if", "unique", "else", "n", ")", ")", "\n", "tree_idxs", ",", "scaled_random_values", "=", "self", ".", "find", "(", "random_values", ")", "\n", "if", "unique", ":", "\n", "            ", "i", "=", "0", "\n", "while", "i", "<", "100", ":", "\n", "                ", "tree_idxs", ",", "unique_idx", "=", "np", ".", "unique", "(", "tree_idxs", ",", "return_index", "=", "True", ")", "\n", "scaled_random_values", "=", "scaled_random_values", "[", "unique_idx", "]", "\n", "if", "len", "(", "tree_idxs", ")", "<", "n", ":", "\n", "                    ", "new_idxs", ",", "new_values", "=", "self", ".", "find", "(", "np", ".", "random", ".", "rand", "(", "2", "*", "(", "n", "-", "len", "(", "tree_idxs", ")", ")", ")", ")", "\n", "tree_idxs", "=", "np", ".", "concatenate", "(", "[", "tree_idxs", ",", "new_idxs", "]", ")", "\n", "scaled_random_values", "=", "np", ".", "concatenate", "(", "[", "scaled_random_values", ",", "new_values", "]", ")", "\n", "", "else", ":", "\n", "                    ", "break", "\n", "", "i", "+=", "1", "\n", "", "if", "len", "(", "tree_idxs", ")", "<", "n", ":", "\n", "                ", "raise", "RuntimeError", "(", "\"After 100 tries, unable to get unique indexes.\"", ")", "\n", "", "tree_idxs", "=", "tree_idxs", "[", ":", "n", "]", "\n", "\n", "", "priorities", "=", "self", ".", "tree", "[", "tree_idxs", "]", "\n", "self", ".", "prev_tree_idxs", "=", "tree_idxs", "\n", "T_idxs", ",", "B_idxs", "=", "np", ".", "divmod", "(", "tree_idxs", "-", "self", ".", "low_idx", ",", "self", ".", "B", ")", "\n", "return", "(", "T_idxs", ",", "B_idxs", ")", ",", "priorities", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.replays.sum_tree.SumTree.update_batch_priorities": [[130, 139], ["sum_tree.SumTree.reconstruct", "numpy.unique"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.replays.sum_tree.SumTree.reconstruct"], ["", "def", "update_batch_priorities", "(", "self", ",", "priorities", ")", ":", "\n", "        ", "\"\"\"Apply new priorities to tree at the leaf positions where the last\n        batch was returned from the ``sample()`` method.\n        \"\"\"", "\n", "if", "not", "self", ".", "_sampled_unique", ":", "# Must remove duplicates", "\n", "            ", "self", ".", "prev_tree_idxs", ",", "unique_idxs", "=", "np", ".", "unique", "(", "self", ".", "prev_tree_idxs", ",", "\n", "return_index", "=", "True", ")", "\n", "priorities", "=", "priorities", "[", "unique_idxs", "]", "\n", "", "self", ".", "reconstruct", "(", "self", ".", "prev_tree_idxs", ",", "priorities", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.replays.sum_tree.SumTree.print_tree": [[140, 147], ["range", "range", "print", "print"], "methods", ["None"], ["", "def", "print_tree", "(", "self", ",", "level", "=", "None", ")", ":", "\n", "        ", "\"\"\"Print values for whole tree or at specified level.\"\"\"", "\n", "levels", "=", "range", "(", "self", ".", "tree_levels", ")", "if", "level", "is", "None", "else", "[", "level", "]", "\n", "for", "k", "in", "levels", ":", "\n", "            ", "for", "j", "in", "range", "(", "2", "**", "k", "-", "1", ",", "2", "**", "(", "k", "+", "1", ")", "-", "1", ")", ":", "\n", "                ", "print", "(", "self", ".", "tree", "[", "j", "]", ",", "end", "=", "' '", ")", "\n", "", "print", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.replays.sum_tree.SumTree.reconstruct": [[150, 154], ["sum_tree.SumTree.propagate_diffs"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.replays.sum_tree.SumTree.propagate_diffs"], ["", "", "def", "reconstruct", "(", "self", ",", "tree_idxs", ",", "values", ")", ":", "\n", "        ", "diffs", "=", "values", "-", "self", ".", "tree", "[", "tree_idxs", "]", "# Numpy upcasts to float64.", "\n", "self", ".", "tree", "[", "tree_idxs", "]", "=", "values", "\n", "self", ".", "propagate_diffs", "(", "tree_idxs", ",", "diffs", ",", "min_level", "=", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.replays.sum_tree.SumTree.reconstruct_advance": [[155, 205], ["list", "list", "numpy.concatenate().reshape.append", "numpy.concatenate.append", "numpy.concatenate().reshape.append", "numpy.concatenate.append", "numpy.concatenate().reshape.extend", "numpy.concatenate.extend", "numpy.concatenate().reshape", "numpy.concatenate", "sum_tree.SumTree.propagate_diffs", "numpy.arange", "numpy.concatenate.extend", "numpy.arange", "numpy.concatenate().reshape.append", "numpy.concatenate().reshape.append", "numpy.arange", "numpy.arange", "numpy.concatenate", "numpy.arange", "numpy.arange", "numpy.concatenate", "numpy.concatenate", "numpy.concatenate"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.replays.sum_tree.SumTree.propagate_diffs"], ["", "def", "reconstruct_advance", "(", "self", ",", "low_on_t", ",", "high_on_t", ",", "low_off_t", ",", "high_off_t", ")", ":", "\n", "        ", "\"\"\"Efficiently write new values / zeros into tree.\"\"\"", "\n", "low_on_idx", "=", "low_on_t", "*", "self", ".", "B", "+", "self", ".", "low_idx", "\n", "high_on_idx", "=", "high_on_t", "*", "self", ".", "B", "+", "self", ".", "low_idx", "\n", "low_off_idx", "=", "low_off_t", "*", "self", ".", "B", "+", "self", ".", "low_idx", "\n", "high_off_idx", "=", "high_off_t", "*", "self", ".", "B", "+", "self", ".", "low_idx", "\n", "idxs", ",", "diffs", "=", "list", "(", ")", ",", "list", "(", ")", "\n", "if", "high_on_t", ">", "low_on_t", ":", "\n", "            ", "if", "self", ".", "input_priorities", "is", "None", ":", "\n", "                ", "input_priorities", "=", "self", ".", "default_value", "\n", "", "else", ":", "\n", "                ", "input_priorities", "=", "self", ".", "input_priorities", "[", "low_on_t", ":", "high_on_t", "]", "\n", "", "diffs", ".", "append", "(", "input_priorities", "-", "self", ".", "priorities", "[", "low_on_t", ":", "high_on_t", "]", ")", "\n", "self", ".", "priorities", "[", "low_on_t", ":", "high_on_t", "]", "=", "input_priorities", "\n", "idxs", ".", "append", "(", "np", ".", "arange", "(", "low_on_idx", ",", "high_on_idx", ")", ")", "\n", "", "elif", "high_on_t", "<", "low_on_t", ":", "# Wrap", "\n", "            ", "if", "self", ".", "input_priorities", "is", "None", ":", "\n", "                ", "diffs", ".", "append", "(", "self", ".", "default_value", "-", "np", ".", "concatenate", "(", "[", "\n", "self", ".", "priorities", "[", "low_on_t", ":", "]", ",", "self", ".", "priorities", "[", ":", "high_on_t", "]", "]", ",", "\n", "axis", "=", "0", ")", ")", "\n", "self", ".", "priorities", "[", "low_on_t", ":", "]", "=", "self", ".", "default_value", "\n", "self", ".", "priorities", "[", ":", "high_on_t", "]", "=", "self", ".", "default_value", "\n", "", "else", ":", "\n", "                ", "diffs", ".", "append", "(", "\n", "np", ".", "concatenate", "(", "\n", "[", "self", ".", "input_priorities", "[", "low_on_t", ":", "]", ",", "\n", "self", ".", "input_priorities", "[", ":", "high_on_t", "]", "]", ",", "axis", "=", "0", ")", "-", "\n", "np", ".", "concatenate", "(", "\n", "[", "self", ".", "priorities", "[", "low_on_t", ":", "]", ",", "\n", "self", ".", "priorities", "[", ":", "high_on_t", "]", "]", ",", "axis", "=", "0", ")", "\n", ")", "\n", "self", ".", "priorities", "[", "low_on_t", ":", "]", "=", "self", ".", "input_priorities", "[", "low_on_t", ":", "]", "\n", "self", ".", "priorities", "[", ":", "high_on_t", "]", "=", "self", ".", "input_priorities", "[", ":", "high_on_t", "]", "\n", "", "idxs", ".", "extend", "(", "[", "np", ".", "arange", "(", "low_on_idx", ",", "self", ".", "high_idx", ")", ",", "\n", "np", ".", "arange", "(", "self", ".", "low_idx", ",", "high_on_idx", ")", "]", ")", "\n", "", "if", "high_off_t", ">", "low_off_t", ":", "\n", "            ", "diffs", ".", "append", "(", "-", "self", ".", "priorities", "[", "low_off_t", ":", "high_off_t", "]", ")", "\n", "self", ".", "priorities", "[", "low_off_t", ":", "high_off_t", "]", "=", "0", "\n", "idxs", ".", "append", "(", "np", ".", "arange", "(", "low_off_idx", ",", "high_off_idx", ")", ")", "\n", "", "else", ":", "# Wrap.", "\n", "            ", "diffs", ".", "extend", "(", "[", "-", "self", ".", "priorities", "[", "low_off_t", ":", "]", ",", "\n", "-", "self", ".", "priorities", "[", ":", "high_off_t", "]", "]", ")", "\n", "self", ".", "priorities", "[", "low_off_t", ":", "]", "=", "0", "\n", "self", ".", "priorities", "[", ":", "high_off_t", "]", "=", "0", "\n", "idxs", ".", "extend", "(", "[", "np", ".", "arange", "(", "low_off_idx", ",", "self", ".", "high_idx", ")", ",", "\n", "np", ".", "arange", "(", "self", ".", "low_idx", ",", "high_off_idx", ")", "]", ")", "\n", "", "if", "diffs", ":", "\n", "            ", "diffs", "=", "np", ".", "concatenate", "(", "diffs", ")", ".", "reshape", "(", "-", "1", ")", "\n", "idxs", "=", "np", ".", "concatenate", "(", "idxs", ")", "\n", "self", ".", "propagate_diffs", "(", "idxs", ",", "diffs", ",", "min_level", "=", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.replays.sum_tree.SumTree.propagate_diffs": [[206, 210], ["range", "numpy.add.at"], "methods", ["None"], ["", "", "def", "propagate_diffs", "(", "self", ",", "tree_idxs", ",", "diffs", ",", "min_level", "=", "1", ")", ":", "\n", "        ", "for", "_", "in", "range", "(", "min_level", ",", "self", ".", "tree_levels", ")", ":", "\n", "            ", "tree_idxs", "=", "(", "tree_idxs", "-", "1", ")", "//", "2", "# Rise a level", "\n", "np", ".", "add", ".", "at", "(", "self", ".", "tree", ",", "tree_idxs", ",", "diffs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.replays.sum_tree.SumTree.find": [[211, 223], ["random_values.copy", "numpy.zeros", "range", "len", "numpy.where"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.utils.collections.AttrDict.copy", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.misc.zeros"], ["", "", "def", "find", "(", "self", ",", "random_values", ")", ":", "\n", "        ", "\"\"\"Param random_values: numpy array of floats in range [0, 1] \"\"\"", "\n", "random_values", "=", "self", ".", "tree", "[", "0", "]", "*", "random_values", "# Double precision.", "\n", "scaled_random_values", "=", "random_values", ".", "copy", "(", ")", "\n", "tree_idxs", "=", "np", ".", "zeros", "(", "len", "(", "random_values", ")", ",", "dtype", "=", "np", ".", "int64", ")", "\n", "for", "_", "in", "range", "(", "self", ".", "tree_levels", "-", "1", ")", ":", "\n", "            ", "tree_idxs", "=", "2", "*", "tree_idxs", "+", "1", "\n", "left_values", "=", "self", ".", "tree", "[", "tree_idxs", "]", "\n", "where_right", "=", "np", ".", "where", "(", "random_values", ">", "left_values", ")", "[", "0", "]", "\n", "tree_idxs", "[", "where_right", "]", "+=", "1", "\n", "random_values", "[", "where_right", "]", "-=", "left_values", "[", "where_right", "]", "\n", "", "return", "tree_idxs", ",", "scaled_random_values", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.replays.sum_tree.AsyncSumTree.__init__": [[233, 236], ["multiprocessing.RawValue", "sum_tree.SumTree.__init__"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.spaces.gym_wrapper.GymSpaceWrapper.__init__"], ["def", "__init__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "self", ".", "async_t", "=", "mp", ".", "RawValue", "(", "\"l\"", ",", "0", ")", "\n", "super", "(", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "# Wrap guard behavior should be fine without async--each will catch it.", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.replays.sum_tree.AsyncSumTree._allocate_tree": [[238, 241], ["rlpyt.utils.buffer.np_mp_array", "sum_tree.AsyncSumTree.tree.fill"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.utils.buffer.np_mp_array"], ["", "def", "_allocate_tree", "(", "self", ")", ":", "\n", "        ", "self", ".", "tree", "=", "np_mp_array", "(", "2", "**", "self", ".", "tree_levels", "-", "1", ",", "np", ".", "float64", ")", "# Shared memory.", "\n", "self", ".", "tree", ".", "fill", "(", "0", ")", "# Just in case.", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.replays.sum_tree.AsyncSumTree.reset": [[242, 245], ["sum_tree.SumTree.reset"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.safe.safety_gym_env.SafetyGymEnvWrapper.reset"], ["", "def", "reset", "(", "self", ")", ":", "\n", "        ", "super", "(", ")", ".", "reset", "(", ")", "\n", "self", ".", "async_t", ".", "value", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.replays.sum_tree.AsyncSumTree.advance": [[246, 250], ["sum_tree.SumTree.advance"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.replays.sum_tree.AsyncSumTree.advance"], ["", "def", "advance", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "self", ".", "t", "=", "self", ".", "async_t", ".", "value", "\n", "super", "(", ")", ".", "advance", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "self", ".", "async_t", ".", "value", "=", "self", ".", "t", "\n", "", "", ""]], "home.repos.pwc.inspect_result.astooke_rlpyt.replays.ul_for_rl_replay.UlForRlReplayBuffer.__init__": [[21, 33], ["ul_for_rl_replay.UlForRlReplayBuffer.load_replay", "int", "rlpyt.utils.logging.logger.log"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.pixel_control.PixelControl.load_replay", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.console.log"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "replay_buffer", ",", "\n", "replay_T", "=", "1", ",", "\n", "validation_split", "=", "0.0", ",", "\n", "pixel_control_buffer", "=", "None", ",", "\n", ")", ":", "\n", "        ", "self", ".", "load_replay", "(", "replay_buffer", ",", "pixel_control_buffer", ")", "\n", "self", ".", "replay_T", "=", "replay_T", "\n", "self", ".", "validation_t", "=", "int", "(", "(", "self", ".", "T", "-", "replay_T", ")", "*", "(", "1", "-", "validation_split", ")", ")", "\n", "if", "pixel_control_buffer", "is", "not", "None", ":", "\n", "            ", "logger", ".", "log", "(", "\"Replay buffer receiving pixel control returns.\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.replays.ul_for_rl_replay.UlForRlReplayBuffer.load_replay": [[34, 39], ["isinstance", "ul_for_rl_replay.UlForRlReplayBuffer._load_multiple_replays", "ul_for_rl_replay.UlForRlReplayBuffer._load_single_replay"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.replays.ul_for_rl_replay.UlForRlReplayBuffer._load_multiple_replays", "home.repos.pwc.inspect_result.astooke_rlpyt.replays.ul_for_rl_replay.UlForRlReplayBuffer._load_single_replay"], ["", "", "def", "load_replay", "(", "self", ",", "replay_buffer", ",", "pixel_control_buffer", "=", "None", ")", ":", "\n", "        ", "if", "isinstance", "(", "replay_buffer", ",", "(", "tuple", ",", "list", ")", ")", ":", "\n", "            ", "self", ".", "_load_multiple_replays", "(", "replay_buffer", ",", "pixel_control_buffer", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "_load_single_replay", "(", "replay_buffer", ",", "pixel_control_buffer", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.replays.ul_for_rl_replay.UlForRlReplayBuffer._load_single_replay": [[40, 54], ["hasattr"], "methods", ["None"], ["", "", "def", "_load_single_replay", "(", "self", ",", "replay_buffer", ",", "pixel_control_buffer", "=", "None", ")", ":", "\n", "# Make sure the unpickled replay buffer is exactly full.", "\n", "        ", "assert", "replay_buffer", ".", "t", "==", "0", "# no wrapping", "\n", "assert", "replay_buffer", ".", "_buffer_full", "\n", "self", ".", "loaded_buffer", "=", "replay_buffer", "\n", "self", ".", "_samples", "=", "self", ".", "loaded_buffer", ".", "samples", "\n", "self", ".", "_is_frame_buffer", "=", "hasattr", "(", "replay_buffer", ",", "\"samples_frames\"", ")", "\n", "if", "self", ".", "_is_frame_buffer", ":", "\n", "            ", "self", ".", "n_frames", "=", "self", ".", "loaded_buffer", ".", "n_frames", "\n", "self", ".", "_samples_frames", "=", "self", ".", "loaded_buffer", ".", "samples_frames", "\n", "\n", "", "self", ".", "T", ",", "self", ".", "B", "=", "self", ".", "samples", ".", "reward", ".", "shape", "\n", "self", ".", "size", "=", "self", ".", "T", "*", "self", ".", "B", "\n", "self", ".", "pixel_control_buffer", "=", "pixel_control_buffer", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.replays.ul_for_rl_replay.UlForRlReplayBuffer._load_multiple_replays": [[55, 97], ["isinstance", "hasattr", "ul_for_rl_replay.buffer_concatenate", "isinstance", "tuple", "ul_for_rl_replay.buffer_concatenate", "ul_for_rl_replay.buffer_concatenate", "ul_for_rl_replay.buffer_concatenate", "dict", "len", "len", "hasattr", "tuple", "tuple", "tuple"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.replays.ul_for_rl_replay.buffer_concatenate", "home.repos.pwc.inspect_result.astooke_rlpyt.replays.ul_for_rl_replay.buffer_concatenate", "home.repos.pwc.inspect_result.astooke_rlpyt.replays.ul_for_rl_replay.buffer_concatenate", "home.repos.pwc.inspect_result.astooke_rlpyt.replays.ul_for_rl_replay.buffer_concatenate"], ["", "def", "_load_multiple_replays", "(", "self", ",", "replay_buffers", ",", "pixel_control_buffers", "=", "None", ")", ":", "\n", "        ", "\"\"\"Now replay_buffer is actually a tuple of them.\"\"\"", "\n", "assert", "isinstance", "(", "replay_buffers", ",", "(", "tuple", ",", "list", ")", ")", "\n", "if", "pixel_control_buffers", "is", "not", "None", ":", "\n", "            ", "assert", "isinstance", "(", "pixel_control_buffers", ",", "(", "tuple", ",", "list", ")", ")", "\n", "assert", "len", "(", "replay_buffers", ")", "==", "len", "(", "pixel_control_buffers", ")", "\n", "\n", "# Make sure the unpickled replay buffers are exactly full.", "\n", "", "T", "=", "replay_buffers", "[", "0", "]", ".", "T", "\n", "self", ".", "_is_frame_buffer", "=", "hasattr", "(", "replay_buffers", "[", "0", "]", ",", "\"samples_frames\"", ")", "\n", "if", "self", ".", "_is_frame_buffer", ":", "\n", "            ", "self", ".", "n_frames", "=", "replay_buffers", "[", "0", "]", ".", "n_frames", "\n", "", "for", "rep", "in", "replay_buffers", ":", "\n", "            ", "assert", "rep", ".", "t", "==", "0", "# no wrapping", "\n", "assert", "rep", ".", "_buffer_full", "# try to make sure it's real data", "\n", "assert", "rep", ".", "T", "==", "T", "# make sure they are the same time length", "\n", "assert", "hasattr", "(", "rep", ",", "\"samples_frames\"", ")", "==", "self", ".", "_is_frame_buffer", "\n", "if", "self", ".", "_is_frame_buffer", ":", "\n", "                ", "assert", "rep", ".", "n_frames", "==", "self", ".", "n_frames", "\n", "# (can be different B, though)", "\n", "# Load from each replay for each field, concatenating along B dimension.", "\n", "", "", "self", ".", "_samples", "=", "buffer_concatenate", "(", "# main samples", "\n", "tuple", "(", "rep", ".", "samples", "for", "rep", "in", "replay_buffers", ")", ",", "axis", "=", "1", ")", "\n", "if", "self", ".", "_is_frame_buffer", ":", "\n", "            ", "self", ".", "_samples_frames", "=", "buffer_concatenate", "(", "\n", "tuple", "(", "rep", ".", "samples_frames", "for", "rep", "in", "replay_buffers", ")", ",", "axis", "=", "1", ")", "\n", "", "del", "replay_buffers", "# Otherwise would hold double memory", "\n", "self", ".", "T", ",", "self", ".", "B", "=", "self", ".", "samples", ".", "reward", ".", "shape", "\n", "# self.B = sum(rep.B for rep in replay_buffers)", "\n", "self", ".", "size", "=", "self", ".", "T", "*", "self", ".", "B", "\n", "\n", "self", ".", "pixel_control_buffer", "=", "None", "\n", "if", "pixel_control_buffers", "is", "not", "None", ":", "\n", "            ", "pixctl_reward", "=", "buffer_concatenate", "(", "tuple", "(", "pcb", "[", "\"reward\"", "]", "\n", "for", "pcb", "in", "pixel_control_buffers", ")", ",", "axis", "=", "1", ")", "\n", "pixctl_return", "=", "buffer_concatenate", "(", "tuple", "(", "pcb", "[", "\"return_\"", "]", "\n", "for", "pcb", "in", "pixel_control_buffers", ")", ",", "axis", "=", "1", ")", "\n", "self", ".", "pixel_control_buffer", "=", "dict", "(", "\n", "reward", "=", "pixctl_reward", ",", "\n", "return_", "=", "pixctl_return", ",", "\n", ")", "\n", "del", "pixel_control_buffers", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.replays.ul_for_rl_replay.UlForRlReplayBuffer.samples": [[98, 101], ["None"], "methods", ["None"], ["", "", "@", "property", "\n", "def", "samples", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_samples", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.replays.ul_for_rl_replay.UlForRlReplayBuffer.samples_frames": [[102, 105], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "samples_frames", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_samples_frames", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.replays.ul_for_rl_replay.UlForRlReplayBuffer.get_examples": [[106, 123], ["SamplesFromReplay", "SamplesFromReplayPC"], "methods", ["None"], ["", "def", "get_examples", "(", "self", ")", ":", "\n", "        ", "\"\"\"To use when initializing NN model.\"\"\"", "\n", "observation", "=", "(", "self", ".", "samples_frames", "[", ":", "self", ".", "n_frames", ",", "0", "]", "\n", "if", "self", ".", "_is_frame_buffer", "else", "\n", "self", ".", "samples", ".", "observation", "[", "0", ",", "0", "]", ")", "\n", "examples", "=", "SamplesFromReplay", "(", "\n", "observation", "=", "observation", ",", "\n", "action", "=", "self", ".", "samples", ".", "action", "[", "0", ",", "0", "]", ",", "\n", "reward", "=", "self", ".", "samples", ".", "reward", "[", "0", ",", "0", "]", ",", "\n", "done", "=", "self", ".", "samples", ".", "done", "[", "0", ",", "0", "]", ",", "\n", "prev_action", "=", "self", ".", "samples", ".", "action", "[", "0", ",", "0", "]", ",", "\n", "prev_reward", "=", "self", ".", "samples", ".", "reward", "[", "0", ",", "0", "]", ",", "\n", ")", "\n", "if", "self", ".", "pixel_control_buffer", "is", "not", "None", ":", "\n", "            ", "examples", "=", "SamplesFromReplayPC", "(", "*", "examples", ",", "\n", "pixctl_return", "=", "self", ".", "pixel_control_buffer", "[", "\"return_\"", "]", "[", "0", ",", "0", "]", ")", "\n", "", "return", "examples", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.replays.ul_for_rl_replay.UlForRlReplayBuffer.sample_batch": [[124, 127], ["ul_for_rl_replay.UlForRlReplayBuffer.sample_idxs", "ul_for_rl_replay.UlForRlReplayBuffer.extract_batch"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.sequence.uniform.UniformSequenceReplay.sample_idxs", "home.repos.pwc.inspect_result.astooke_rlpyt.sequence.n_step.SequenceNStepReturnBuffer.extract_batch"], ["", "def", "sample_batch", "(", "self", ",", "batch_B", ",", "validation", "=", "False", ")", ":", "\n", "        ", "T_idxs", ",", "B_idxs", "=", "self", ".", "sample_idxs", "(", "batch_B", ",", "validation", "=", "False", ")", "\n", "return", "self", ".", "extract_batch", "(", "T_idxs", ",", "B_idxs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.replays.ul_for_rl_replay.UlForRlReplayBuffer.sample_idxs": [[128, 140], ["numpy.random.randint", "numpy.random.randint"], "methods", ["None"], ["", "def", "sample_idxs", "(", "self", ",", "batch_B", ",", "validation", "=", "False", ")", ":", "\n", "        ", "\"\"\"Uniform replay.\"\"\"", "\n", "if", "validation", ":", "\n", "            ", "low", "=", "self", ".", "validation_t", "\n", "high", "=", "self", ".", "T", "-", "self", ".", "replay_T", "\n", "", "else", ":", "\n", "            ", "low", "=", "self", ".", "n_frames", "-", "1", "if", "self", ".", "_is_frame_buffer", "else", "0", "\n", "high", "=", "self", ".", "validation_t", "-", "self", ".", "replay_T", "\n", "", "high", "=", "self", ".", "T", "-", "self", ".", "replay_T", "\n", "T_idxs", "=", "np", ".", "random", ".", "randint", "(", "low", "=", "low", ",", "high", "=", "high", ",", "size", "=", "(", "batch_B", ",", ")", ")", "\n", "B_idxs", "=", "np", ".", "random", ".", "randint", "(", "low", "=", "0", ",", "high", "=", "self", ".", "B", ",", "size", "=", "(", "batch_B", ",", ")", ")", "\n", "return", "T_idxs", ",", "B_idxs", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.replays.ul_for_rl_replay.UlForRlReplayBuffer.extract_batch": [[141, 162], ["rlpyt.utils.buffer.buffer_func", "rlpyt.utils.misc.extract_sequences", "SamplesFromReplay", "rlpyt.utils.buffer.torchify_buffer", "rlpyt.utils.misc.extract_sequences", "SamplesFromReplayPC", "ul_for_rl_replay.UlForRlReplayBuffer.extract_observation", "rlpyt.utils.misc.extract_sequences"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.utils.buffer.buffer_func", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.misc.extract_sequences", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.buffer.torchify_buffer", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.misc.extract_sequences", "home.repos.pwc.inspect_result.astooke_rlpyt.sequence.n_step.SequenceNStepReturnBuffer.extract_observation", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.misc.extract_sequences"], ["", "def", "extract_batch", "(", "self", ",", "T_idxs", ",", "B_idxs", ")", ":", "\n", "        ", "T", "=", "self", ".", "replay_T", "\n", "all_action", "=", "buffer_func", "(", "self", ".", "samples", ".", "action", ",", "extract_sequences", ",", "\n", "T_idxs", "-", "1", ",", "B_idxs", ",", "T", "+", "1", ")", "\n", "all_reward", "=", "extract_sequences", "(", "self", ".", "samples", ".", "reward", ",", "\n", "T_idxs", "-", "1", ",", "B_idxs", ",", "T", "+", "1", ")", "\n", "batch", "=", "SamplesFromReplay", "(", "\n", "observation", "=", "self", ".", "extract_observation", "(", "T_idxs", ",", "B_idxs", ")", ",", "\n", "action", "=", "all_action", "[", "1", ":", "]", ",", "\n", "reward", "=", "all_reward", "[", "1", ":", "]", ",", "\n", "done", "=", "extract_sequences", "(", "self", ".", "samples", ".", "done", ",", "T_idxs", ",", "B_idxs", ",", "T", ")", ",", "\n", "prev_action", "=", "all_action", "[", ":", "-", "1", "]", ",", "\n", "prev_reward", "=", "all_reward", "[", ":", "-", "1", "]", ",", "\n", ")", "\n", "if", "self", ".", "pixel_control_buffer", "is", "not", "None", ":", "\n", "            ", "pixctl_return", "=", "extract_sequences", "(", "\n", "self", ".", "pixel_control_buffer", "[", "\"return_\"", "]", ",", "\n", "T_idxs", ",", "B_idxs", ",", "T", ")", "\n", "batch", "=", "SamplesFromReplayPC", "(", "*", "batch", ",", "\n", "pixctl_return", "=", "pixctl_return", ")", "\n", "", "return", "torchify_buffer", "(", "batch", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.replays.ul_for_rl_replay.UlForRlReplayBuffer.extract_observation": [[163, 190], ["numpy.empty", "enumerate", "rlpyt.utils.buffer.buffer_func", "zip", "range", "slice", "numpy.any", "range", "len", "numpy.where"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.utils.misc.empty", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.buffer.buffer_func"], ["", "def", "extract_observation", "(", "self", ",", "T_idxs", ",", "B_idxs", ")", ":", "\n", "        ", "T", "=", "self", ".", "replay_T", "\n", "if", "not", "self", ".", "_is_frame_buffer", ":", "\n", "            ", "return", "buffer_func", "(", "self", ".", "samples", ".", "observation", ",", "\n", "extract_sequences", ",", "T_idxs", ",", "B_idxs", ",", "T", ")", "\n", "", "frames", "=", "self", ".", "samples_frames", "\n", "observation", "=", "np", ".", "empty", "(", "\n", "shape", "=", "(", "T", ",", "len", "(", "B_idxs", ")", ",", "self", ".", "n_frames", ")", "+", "frames", ".", "shape", "[", "2", ":", "]", ",", "# [T,B,C,H,W]", "\n", "dtype", "=", "frames", ".", "dtype", ",", "\n", ")", "\n", "fm1", "=", "self", ".", "n_frames", "-", "1", "\n", "for", "i", ",", "(", "t", ",", "b", ")", "in", "enumerate", "(", "zip", "(", "T_idxs", ",", "B_idxs", ")", ")", ":", "\n", "            ", "assert", "t", "+", "T", "<=", "self", ".", "T", "# no wrapping allowed", "\n", "for", "f", "in", "range", "(", "self", ".", "n_frames", ")", ":", "\n", "                ", "observation", "[", ":", ",", "i", ",", "f", "]", "=", "frames", "[", "t", "+", "f", ":", "t", "+", "f", "+", "T", ",", "b", "]", "\n", "\n", "# Populate empty (zero) frames after environment done.", "\n", "", "assert", "t", "-", "fm1", ">=", "0", "# no wrapping allowed", "\n", "done_idxs", "=", "slice", "(", "t", "-", "fm1", ",", "t", "+", "T", ")", "\n", "done_fm1", "=", "self", ".", "samples", ".", "done", "[", "done_idxs", ",", "b", "]", "\n", "if", "np", ".", "any", "(", "done_fm1", ")", ":", "\n", "                ", "where_done_t", "=", "np", ".", "where", "(", "done_fm1", ")", "[", "0", "]", "-", "fm1", "# Might be negative...", "\n", "for", "f", "in", "range", "(", "1", ",", "self", ".", "n_frames", ")", ":", "\n", "                    ", "t_blanks", "=", "where_done_t", "+", "f", "# ...might be > T...", "\n", "t_blanks", "=", "t_blanks", "[", "(", "t_blanks", ">=", "0", ")", "&", "(", "t_blanks", "<", "T", ")", "]", "# ..don't let it wrap.", "\n", "observation", "[", "t_blanks", ",", "i", ",", ":", "self", ".", "n_frames", "-", "f", "]", "=", "0", "\n", "", "", "", "return", "observation", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.replays.ul_for_rl_replay.buffer_concatenate": [[192, 211], ["isinstance", "new_buf._make._make", "type", "tuple", "numpy.concatenate", "rlpyt.utils.logging.logger.log", "rlpyt.utils.logging.logger.log", "numpy.zeros", "ul_for_rl_replay.buffer_concatenate", "tuple", "sum", "getattr"], "function", ["home.repos.pwc.inspect_result.astooke_rlpyt.utils.collections.NamedArrayTupleSchema._make", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.console.log", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.console.log", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.misc.zeros", "home.repos.pwc.inspect_result.astooke_rlpyt.replays.ul_for_rl_replay.buffer_concatenate"], ["", "", "def", "buffer_concatenate", "(", "buffers", ",", "axis", "=", "0", ")", ":", "\n", "    ", "assert", "type", "(", "buffers", ")", "==", "tuple", "\n", "if", "isinstance", "(", "buffers", "[", "0", "]", ",", "np", ".", "ndarray", ")", ":", "\n", "        ", "try", ":", "\n", "            ", "return", "np", ".", "concatenate", "(", "buffers", ",", "axis", "=", "axis", ")", "\n", "", "except", "ValueError", ":", "\n", "            ", "logger", ".", "log", "(", "\"Had a ValueError in buffer concat, probably action dimensions that don't line up, populating with zeros.\"", ")", "\n", "logger", ".", "log", "(", "f\"buffer shapes: {[buf.shape for buf in buffers]}\"", ")", "\n", "return", "np", ".", "zeros", "(", "(", "buffers", "[", "0", "]", ".", "shape", "[", "0", "]", ",", "sum", "(", "buf", ".", "shape", "[", "1", "]", "for", "buf", "in", "buffers", ")", ")", ")", "\n", "", "", "fields", "=", "buffers", "[", "0", "]", ".", "_fields", "\n", "for", "buf", "in", "buffers", ":", "\n", "# try to make sure they're the same structure", "\n", "        ", "assert", "buf", ".", "_fields", "==", "fields", "\n", "", "new_buf", "=", "buffers", "[", "0", "]", "\n", "fields", "=", "new_buf", ".", "_fields", "\n", "new_buf", "=", "new_buf", ".", "_make", "(", "tuple", "(", "\n", "buffer_concatenate", "(", "tuple", "(", "getattr", "(", "buf", ",", "field", ")", "for", "buf", "in", "buffers", ")", ",", "axis", "=", "1", ")", "\n", "for", "field", "in", "fields", ")", ")", "\n", "return", "new_buf", "\n", "", ""]], "home.repos.pwc.inspect_result.astooke_rlpyt.replays.rl_with_ul_replay.RlWithUlUniformReplayBuffer.__init__": [[21, 30], ["math.ceil", "rlpyt.utils.buffer.buffer_from_example"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.utils.buffer.buffer_from_example"], ["    ", "def", "__init__", "(", "self", ",", "example", ",", "size", ",", "B", ",", "replay_T", ")", ":", "\n", "        ", "self", ".", "T", "=", "T", "=", "math", ".", "ceil", "(", "size", "/", "B", ")", "\n", "self", ".", "B", "=", "B", "\n", "self", ".", "size", "=", "T", "*", "B", "\n", "self", ".", "t", "=", "0", "# cursor", "\n", "self", ".", "replay_T", "=", "replay_T", "\n", "self", ".", "samples", "=", "buffer_from_example", "(", "example", ",", "(", "T", ",", "B", ")", ",", "\n", "share_memory", "=", "self", ".", "async_", ")", "\n", "self", ".", "_buffer_full", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.replays.rl_with_ul_replay.RlWithUlUniformReplayBuffer.append_samples": [[31, 44], ["rlpyt.utils.buffer.get_leading_dims", "slice", "numpy.arange"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.utils.buffer.get_leading_dims"], ["", "def", "append_samples", "(", "self", ",", "samples", ")", ":", "\n", "        ", "T", ",", "B", "=", "get_leading_dims", "(", "samples", ",", "n_dim", "=", "2", ")", "\n", "assert", "B", "==", "self", ".", "B", "\n", "t", "=", "self", ".", "t", "\n", "if", "t", "+", "T", ">", "self", ".", "T", ":", "# Wrap.", "\n", "            ", "idxs", "=", "np", ".", "arange", "(", "t", ",", "t", "+", "T", ")", "%", "self", ".", "T", "\n", "", "else", ":", "\n", "            ", "idxs", "=", "slice", "(", "t", ",", "t", "+", "T", ")", "\n", "", "self", ".", "samples", "[", "idxs", "]", "=", "samples", "\n", "if", "not", "self", ".", "_buffer_full", "and", "t", "+", "T", ">=", "self", ".", "T", ":", "\n", "            ", "self", ".", "_buffer_full", "=", "True", "\n", "", "self", ".", "t", "=", "(", "t", "+", "T", ")", "%", "self", ".", "T", "\n", "return", "T", ",", "idxs", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.replays.rl_with_ul_replay.RlWithUlUniformReplayBuffer.sample_batch": [[45, 48], ["rl_with_ul_replay.RlWithUlUniformReplayBuffer.sample_idxs", "rl_with_ul_replay.RlWithUlUniformReplayBuffer.extract_batch"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.sequence.uniform.UniformSequenceReplay.sample_idxs", "home.repos.pwc.inspect_result.astooke_rlpyt.sequence.n_step.SequenceNStepReturnBuffer.extract_batch"], ["", "def", "sample_batch", "(", "self", ",", "batch_B", ")", ":", "\n", "        ", "T_idxs", ",", "B_idxs", "=", "self", ".", "sample_idxs", "(", "batch_B", ")", "\n", "return", "self", ".", "extract_batch", "(", "T_idxs", ",", "B_idxs", ",", "self", ".", "replay_T", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.replays.rl_with_ul_replay.RlWithUlUniformReplayBuffer.sample_idxs": [[49, 56], ["numpy.random.randint", "numpy.random.randint", "min"], "methods", ["None"], ["", "def", "sample_idxs", "(", "self", ",", "batch_B", ")", ":", "\n", "        ", "t", ",", "b", ",", "f", "=", "self", ".", "t", ",", "self", ".", "replay_T", ",", "0", "# cursor, off_backward, off_forward", "\n", "high", "=", "self", ".", "T", "-", "b", "-", "f", "if", "self", ".", "_buffer_full", "else", "t", "-", "b", "-", "f", "\n", "T_idxs", "=", "np", ".", "random", ".", "randint", "(", "low", "=", "0", ",", "high", "=", "high", ",", "size", "=", "(", "batch_B", ",", ")", ")", "\n", "T_idxs", "[", "T_idxs", ">=", "t", "-", "b", "]", "+=", "min", "(", "t", ",", "b", ")", "+", "f", "\n", "B_idxs", "=", "np", ".", "random", ".", "randint", "(", "low", "=", "0", ",", "high", "=", "self", ".", "B", ",", "size", "=", "(", "batch_B", ",", ")", ")", "\n", "return", "T_idxs", ",", "B_idxs", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.replays.rl_with_ul_replay.RlWithUlUniformReplayBuffer.extract_batch": [[57, 66], ["SamplesFromReplay", "rlpyt.utils.buffer.torchify_buffer", "rl_with_ul_replay.RlWithUlUniformReplayBuffer.extract_observation", "rlpyt.utils.buffer.buffer_func", "rlpyt.utils.misc.extract_sequences", "rlpyt.utils.misc.extract_sequences"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.utils.buffer.torchify_buffer", "home.repos.pwc.inspect_result.astooke_rlpyt.sequence.n_step.SequenceNStepReturnBuffer.extract_observation", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.buffer.buffer_func", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.misc.extract_sequences", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.misc.extract_sequences"], ["", "def", "extract_batch", "(", "self", ",", "T_idxs", ",", "B_idxs", ",", "T", ")", ":", "\n", "        ", "s", "=", "self", ".", "samples", "\n", "batch", "=", "SamplesFromReplay", "(", "\n", "observation", "=", "self", ".", "extract_observation", "(", "T_idxs", ",", "B_idxs", ",", "T", ")", ",", "\n", "action", "=", "buffer_func", "(", "s", ".", "action", ",", "extract_sequences", ",", "T_idxs", ",", "B_idxs", ",", "T", ")", ",", "\n", "reward", "=", "extract_sequences", "(", "s", ".", "reward", ",", "T_idxs", ",", "B_idxs", ",", "T", ")", ",", "\n", "done", "=", "extract_sequences", "(", "s", ".", "done", ",", "T_idxs", ",", "B_idxs", ",", "T", ")", ",", "\n", ")", "\n", "return", "torchify_buffer", "(", "batch", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.replays.rl_with_ul_replay.RlWithUlUniformReplayBuffer.extract_observation": [[67, 70], ["rlpyt.utils.buffer.buffer_func"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.utils.buffer.buffer_func"], ["", "def", "extract_observation", "(", "self", ",", "T_idxs", ",", "B_idxs", ",", "T", ")", ":", "\n", "        ", "return", "buffer_func", "(", "self", ".", "samples", ".", "observation", ",", "extract_sequences", ",", "\n", "T_idxs", ",", "B_idxs", ",", "T", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.replays.rl_with_ul_replay.RlWithUlPrioritizedReplayBuffer.__init__": [[75, 98], ["math.ceil", "rlpyt.utils.buffer.buffer_from_example", "rl_with_ul_replay.RlWithUlPrioritizedReplayBuffer.init_priority_tree", "rlpyt.utils.buffer.buffer_from_example", "rlpyt.utils.buffer.buffer_from_example"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.utils.buffer.buffer_from_example", "home.repos.pwc.inspect_result.astooke_rlpyt.sequence.prioritized.PrioritizedSequenceReplay.init_priority_tree", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.buffer.buffer_from_example", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.buffer.buffer_from_example"], ["def", "__init__", "(", "self", ",", "example", ",", "size", ",", "B", ",", "replay_T", ",", "discount", ",", "n_step_return", ",", "\n", "alpha", ",", "beta", ")", ":", "\n", "        ", "self", ".", "T", "=", "T", "=", "math", ".", "ceil", "(", "size", "/", "B", ")", "\n", "self", ".", "B", "=", "B", "\n", "self", ".", "size", "=", "T", "*", "B", "\n", "self", ".", "t", "=", "0", "# cursor", "\n", "self", ".", "replay_T", "=", "replay_T", "\n", "self", ".", "discount", "=", "discount", "\n", "self", ".", "n_step_return", "=", "n_step_return", "\n", "self", ".", "alpha", "=", "alpha", "\n", "self", ".", "beta", "=", "beta", "\n", "self", ".", "samples", "=", "buffer_from_example", "(", "example", ",", "(", "T", ",", "B", ")", ",", "\n", "share_memory", "=", "self", ".", "async_", ")", "\n", "if", "n_step_return", ">", "1", ":", "\n", "            ", "self", ".", "samples_return_", "=", "buffer_from_example", "(", "example", ".", "reward", ",", "\n", "(", "T", ",", "B", ")", ")", "\n", "self", ".", "samples_done_n", "=", "buffer_from_example", "(", "example", ".", "done", ",", "\n", "(", "T", ",", "B", ")", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "samples_return_", "=", "self", ".", "samples", ".", "reward", "\n", "self", ".", "samples_done_n", "=", "self", ".", "samples", ".", "done", "\n", "", "self", ".", "_buffer_full", "=", "False", "\n", "self", ".", "init_priority_tree", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.replays.rl_with_ul_replay.RlWithUlPrioritizedReplayBuffer.append_samples": [[99, 115], ["rlpyt.utils.buffer.get_leading_dims", "rl_with_ul_replay.RlWithUlPrioritizedReplayBuffer.compute_returns", "rl_with_ul_replay.RlWithUlPrioritizedReplayBuffer.priority_tree.advance", "slice", "numpy.arange"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.utils.buffer.get_leading_dims", "home.repos.pwc.inspect_result.astooke_rlpyt.non_sequence.time_limit.NStepTimeLimitBuffer.compute_returns", "home.repos.pwc.inspect_result.astooke_rlpyt.replays.sum_tree.AsyncSumTree.advance"], ["", "def", "append_samples", "(", "self", ",", "samples", ")", ":", "\n", "        ", "T", ",", "B", "=", "get_leading_dims", "(", "samples", ",", "n_dim", "=", "2", ")", "\n", "assert", "B", "==", "self", ".", "B", "\n", "t", "=", "self", ".", "t", "\n", "if", "t", "+", "T", ">", "self", ".", "T", ":", "# Wrap.", "\n", "            ", "idxs", "=", "np", ".", "arange", "(", "t", ",", "t", "+", "T", ")", "%", "self", ".", "T", "\n", "", "else", ":", "\n", "            ", "idxs", "=", "slice", "(", "t", ",", "t", "+", "T", ")", "\n", "", "self", ".", "samples", "[", "idxs", "]", "=", "samples", "\n", "new_returns", "=", "self", ".", "compute_returns", "(", "T", ")", "\n", "if", "not", "self", ".", "_buffer_full", "and", "t", "+", "T", ">=", "self", ".", "T", ":", "\n", "            ", "self", ".", "_buffer_full", "=", "True", "\n", "", "self", ".", "t", "=", "(", "t", "+", "T", ")", "%", "self", ".", "T", "\n", "priorities", "=", "1", "+", "self", ".", "alpha", "*", "new_returns", "**", "self", ".", "beta", "\n", "self", ".", "priority_tree", ".", "advance", "(", "T", ",", "priorities", "=", "priorities", ")", "\n", "return", "T", ",", "idxs", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.replays.rl_with_ul_replay.RlWithUlPrioritizedReplayBuffer.sample_batch": [[116, 119], ["rl_with_ul_replay.RlWithUlPrioritizedReplayBuffer.sample_idxs", "rl_with_ul_replay.RlWithUlPrioritizedReplayBuffer.extract_batch"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.sequence.uniform.UniformSequenceReplay.sample_idxs", "home.repos.pwc.inspect_result.astooke_rlpyt.sequence.n_step.SequenceNStepReturnBuffer.extract_batch"], ["", "def", "sample_batch", "(", "self", ",", "batch_B", ")", ":", "\n", "        ", "T_idxs", ",", "B_idxs", "=", "self", ".", "sample_idxs", "(", "batch_B", ")", "\n", "return", "self", ".", "extract_batch", "(", "T_idxs", ",", "B_idxs", ",", "self", ".", "replay_T", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.replays.rl_with_ul_replay.RlWithUlPrioritizedReplayBuffer.compute_returns": [[120, 154], ["numpy.abs", "numpy.abs", "rlpyt.algos.utils.discount_return_n_step", "return_dest.copy", "numpy.abs", "rlpyt.algos.utils.discount_return_n_step", "numpy.arange", "numpy.arange"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.algos.utils.discount_return_n_step", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.collections.AttrDict.copy", "home.repos.pwc.inspect_result.astooke_rlpyt.algos.utils.discount_return_n_step"], ["", "def", "compute_returns", "(", "self", ",", "T", ")", ":", "\n", "        ", "\"\"\"Compute the n-step returns using the new rewards just written into\n        the buffer, but before the buffer cursor is advanced.  Input ``T`` is\n        the number of new timesteps which were just written.\n        Does nothing if `n-step==1`. e.g. if 2-step return, t-1\n        is first return written here, using reward at t-1 and new reward at t\n        (up through t-1+T from t+T).]\n\n        Use ABSOLUTE VALUE of rewards...it's all good signal for prioritization.\n        \"\"\"", "\n", "t", ",", "s", ",", "nm1", "=", "self", ".", "t", ",", "self", ".", "samples", ",", "self", ".", "n_step_return", "-", "1", "\n", "if", "self", ".", "n_step_return", "==", "1", ":", "\n", "            ", "idxs", "=", "np", ".", "arange", "(", "t", "-", "nm1", ",", "t", "+", "T", ")", "%", "self", ".", "T", "\n", "return_", "=", "np", ".", "abs", "(", "s", ".", "reward", "[", "idxs", "]", ")", "\n", "return", "return_", "# return = reward, done_n = done", "\n", "", "if", "t", "-", "nm1", ">=", "0", "and", "t", "+", "T", "<=", "self", ".", "T", ":", "# No wrap (operate in-place).", "\n", "            ", "reward", "=", "np", ".", "abs", "(", "s", ".", "reward", "[", "t", "-", "nm1", ":", "t", "+", "T", "]", ")", "\n", "done", "=", "s", ".", "done", "[", "t", "-", "nm1", ":", "t", "+", "T", "]", "\n", "return_dest", "=", "self", ".", "samples_return_", "[", "t", "-", "nm1", ":", "t", "-", "nm1", "+", "T", "]", "\n", "done_n_dest", "=", "self", ".", "samples_done_n", "[", "t", "-", "nm1", ":", "t", "-", "nm1", "+", "T", "]", "\n", "discount_return_n_step", "(", "reward", ",", "done", ",", "n_step", "=", "self", ".", "n_step_return", ",", "\n", "discount", "=", "self", ".", "discount", ",", "return_dest", "=", "return_dest", ",", "\n", "done_n_dest", "=", "done_n_dest", ")", "\n", "return", "return_dest", ".", "copy", "(", ")", "\n", "", "else", ":", "# Wrap (copies); Let it (wrongly) wrap at first call.", "\n", "            ", "idxs", "=", "np", ".", "arange", "(", "t", "-", "nm1", ",", "t", "+", "T", ")", "%", "self", ".", "T", "\n", "reward", "=", "np", ".", "abs", "(", "s", ".", "reward", "[", "idxs", "]", ")", "\n", "done", "=", "s", ".", "done", "[", "idxs", "]", "\n", "dest_idxs", "=", "idxs", "[", ":", "-", "nm1", "]", "\n", "return_", ",", "done_n", "=", "discount_return_n_step", "(", "reward", ",", "done", ",", "\n", "n_step", "=", "self", ".", "n_step_return", ",", "discount", "=", "self", ".", "discount", ")", "\n", "self", ".", "samples_return_", "[", "dest_idxs", "]", "=", "return_", "\n", "self", ".", "samples_done_n", "[", "dest_idxs", "]", "=", "done_n", "\n", "return", "return_", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.replays.rl_with_ul_replay.RlWithUlPrioritizedReplayBuffer.init_priority_tree": [[155, 164], ["rlpyt.replays.sum_tree.SumTree"], "methods", ["None"], ["", "", "def", "init_priority_tree", "(", "self", ")", ":", "\n", "        ", "self", ".", "priority_tree", "=", "SumTree", "(", "\n", "T", "=", "self", ".", "T", ",", "\n", "B", "=", "self", ".", "B", ",", "\n", "off_backward", "=", "self", ".", "n_step_return", ",", "\n", "off_forward", "=", "0", ",", "\n", "default_value", "=", "1", ",", "\n", "enable_input_priorities", "=", "True", ",", "\n", "input_priority_shift", "=", "self", ".", "n_step_return", "-", "1", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.replays.rl_with_ul_replay.RlWithUlPrioritizedReplayBuffer.sample_idxs": [[166, 170], ["rl_with_ul_replay.RlWithUlPrioritizedReplayBuffer.priority_tree.sample"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.spaces.gym_wrapper.GymSpaceWrapper.sample"], ["", "def", "sample_idxs", "(", "self", ",", "batch_B", ")", ":", "\n", "        ", "(", "T_idxs", ",", "B_idxs", ")", ",", "priorities", "=", "self", ".", "priority_tree", ".", "sample", "(", "batch_B", ",", "\n", "unique", "=", "True", ")", "\n", "return", "T_idxs", ",", "B_idxs", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.replays.rl_with_ul_replay.RlWithUlPrioritizedReplayBuffer.extract_batch": [[171, 180], ["SamplesFromReplay", "rlpyt.utils.buffer.torchify_buffer", "rl_with_ul_replay.RlWithUlPrioritizedReplayBuffer.extract_observation", "rlpyt.utils.buffer.buffer_func", "rlpyt.utils.misc.extract_sequences", "rlpyt.utils.misc.extract_sequences"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.utils.buffer.torchify_buffer", "home.repos.pwc.inspect_result.astooke_rlpyt.sequence.n_step.SequenceNStepReturnBuffer.extract_observation", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.buffer.buffer_func", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.misc.extract_sequences", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.misc.extract_sequences"], ["", "def", "extract_batch", "(", "self", ",", "T_idxs", ",", "B_idxs", ",", "T", ")", ":", "\n", "        ", "s", "=", "self", ".", "samples", "\n", "batch", "=", "SamplesFromReplay", "(", "\n", "observation", "=", "self", ".", "extract_observation", "(", "T_idxs", ",", "B_idxs", ",", "T", ")", ",", "\n", "action", "=", "buffer_func", "(", "s", ".", "action", ",", "extract_sequences", ",", "T_idxs", ",", "B_idxs", ",", "T", ")", ",", "\n", "reward", "=", "extract_sequences", "(", "s", ".", "reward", ",", "T_idxs", ",", "B_idxs", ",", "T", ")", ",", "\n", "done", "=", "extract_sequences", "(", "s", ".", "done", ",", "T_idxs", ",", "B_idxs", ",", "T", ")", ",", "\n", ")", "\n", "return", "torchify_buffer", "(", "batch", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.replays.rl_with_ul_replay.RlWithUlPrioritizedReplayBuffer.extract_observation": [[181, 184], ["rlpyt.utils.buffer.buffer_func"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.utils.buffer.buffer_func"], ["", "def", "extract_observation", "(", "self", ",", "T_idxs", ",", "B_idxs", ",", "T", ")", ":", "\n", "        ", "return", "buffer_func", "(", "self", ".", "samples", ".", "observation", ",", "extract_sequences", ",", "\n", "T_idxs", ",", "B_idxs", ",", "T", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.replays.rl_with_ul_replay.RlWithUlPrioritizedReplayWrapper.__init__": [[189, 199], ["replay_buffer.samples.reward.copy", "replay_buffer.samples_return_.copy", "replay_buffer.samples.done.copy", "replay_buffer.samples_done_n.copy", "rl_with_ul_replay.RlWithUlPrioritizedReplayWrapper.init_priority_tree"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.utils.collections.AttrDict.copy", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.collections.AttrDict.copy", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.collections.AttrDict.copy", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.collections.AttrDict.copy", "home.repos.pwc.inspect_result.astooke_rlpyt.sequence.prioritized.PrioritizedSequenceReplay.init_priority_tree"], ["def", "__init__", "(", "self", ",", "replay_buffer", ",", "n_step_return", ",", "alpha", ",", "beta", ")", ":", "\n", "        ", "self", ".", "replay_buffer", "=", "replay_buffer", "# the actual one, already init'd", "\n", "self", ".", "n_step_return", "=", "n_step_return", "\n", "self", ".", "alpha", "=", "alpha", "\n", "self", ".", "beta", "=", "beta", "\n", "self", ".", "samples_reward", "=", "replay_buffer", ".", "samples", ".", "reward", ".", "copy", "(", ")", "\n", "self", ".", "samples_return_", "=", "replay_buffer", ".", "samples_return_", ".", "copy", "(", ")", "\n", "self", ".", "samples_done", "=", "replay_buffer", ".", "samples", ".", "done", ".", "copy", "(", ")", "\n", "self", ".", "samples_done_n", "=", "replay_buffer", ".", "samples_done_n", ".", "copy", "(", ")", "\n", "self", ".", "init_priority_tree", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.replays.rl_with_ul_replay.RlWithUlPrioritizedReplayWrapper.sample_batch": [[200, 211], ["rl_with_ul_replay.RlWithUlPrioritizedReplayWrapper.replay_buffer.sample_batch", "rl_with_ul_replay.RlWithUlPrioritizedReplayWrapper.priority_tree.sample", "rl_with_ul_replay.RlWithUlPrioritizedReplayWrapper.replay_buffer.extract_batch"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.sequence.uniform.UniformSequenceReplay.sample_batch", "home.repos.pwc.inspect_result.astooke_rlpyt.spaces.gym_wrapper.GymSpaceWrapper.sample", "home.repos.pwc.inspect_result.astooke_rlpyt.sequence.n_step.SequenceNStepReturnBuffer.extract_batch"], ["", "def", "sample_batch", "(", "self", ",", "batch_B", ",", "mode", "=", "\"RL\"", ")", ":", "\n", "        ", "if", "mode", "==", "\"RL\"", ":", "\n", "# Do the normal thing for SAC.", "\n", "            ", "return", "self", ".", "replay_buffer", ".", "sample_batch", "(", "batch_B", ")", "\n", "", "elif", "mode", "==", "\"UL\"", ":", "\n", "# Prioritized sampling for UL.", "\n", "            ", "(", "T_idxs", ",", "B_idxs", ")", ",", "priorities", "=", "self", ".", "priority_tree", ".", "sample", "(", "batch_B", ",", "\n", "unique", "=", "True", ")", "\n", "return", "self", ".", "replay_buffer", ".", "extract_batch", "(", "T_idxs", ",", "B_idxs", ")", "\n", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.replays.rl_with_ul_replay.RlWithUlPrioritizedReplayWrapper.append_samples": [[212, 226], ["rlpyt.utils.buffer.get_leading_dims", "rl_with_ul_replay.RlWithUlPrioritizedReplayWrapper.compute_ul_returns", "rl_with_ul_replay.RlWithUlPrioritizedReplayWrapper.priority_tree.advance", "rl_with_ul_replay.RlWithUlPrioritizedReplayWrapper.replay_buffer.append_samples", "slice", "numpy.arange"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.utils.buffer.get_leading_dims", "home.repos.pwc.inspect_result.astooke_rlpyt.replays.rl_with_ul_replay.RlWithUlPrioritizedReplayWrapper.compute_ul_returns", "home.repos.pwc.inspect_result.astooke_rlpyt.replays.sum_tree.AsyncSumTree.advance", "home.repos.pwc.inspect_result.astooke_rlpyt.sequence.prioritized.PrioritizedSequenceReplay.append_samples"], ["", "", "def", "append_samples", "(", "self", ",", "samples", ")", ":", "\n", "        ", "T", ",", "B", "=", "get_leading_dims", "(", "samples", ",", "n_dim", "=", "2", ")", "\n", "assert", "B", "==", "self", ".", "replay_buffer", ".", "B", "\n", "t", "=", "self", ".", "replay_buffer", ".", "t", "\n", "if", "t", "+", "T", ">", "self", ".", "replay_buffer", ".", "T", ":", "# Wrap.", "\n", "            ", "idxs", "=", "np", ".", "arange", "(", "t", ",", "t", "+", "T", ")", "%", "self", ".", "T", "\n", "", "else", ":", "\n", "            ", "idxs", "=", "slice", "(", "t", ",", "t", "+", "T", ")", "\n", "", "self", ".", "samples_reward", "[", "idxs", "]", "=", "samples", ".", "reward", "\n", "self", ".", "samples_done", "[", "idxs", "]", "=", "samples", ".", "done", "\n", "new_returns", "=", "self", ".", "compute_ul_returns", "(", "T", ")", "\n", "priorities", "=", "1", "+", "self", ".", "alpha", "*", "new_returns", "**", "self", ".", "beta", "\n", "self", ".", "priority_tree", ".", "advance", "(", "T", ",", "priorities", "=", "priorities", ")", "\n", "return", "self", ".", "replay_buffer", ".", "append_samples", "(", "samples", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.replays.rl_with_ul_replay.RlWithUlPrioritizedReplayWrapper.init_priority_tree": [[227, 236], ["rlpyt.replays.sum_tree.SumTree"], "methods", ["None"], ["", "def", "init_priority_tree", "(", "self", ")", ":", "\n", "        ", "self", ".", "priority_tree", "=", "SumTree", "(", "\n", "T", "=", "self", ".", "replay_buffer", ".", "T", ",", "\n", "B", "=", "self", ".", "replay_buffer", ".", "B", ",", "\n", "off_backward", "=", "self", ".", "n_step_return", ",", "# NOT from replay_buffer.", "\n", "off_forward", "=", "0", ",", "\n", "default_value", "=", "1", ",", "\n", "enable_input_priorities", "=", "True", ",", "\n", "input_priority_shift", "=", "self", ".", "n_step_return", "-", "1", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.replays.rl_with_ul_replay.RlWithUlPrioritizedReplayWrapper.compute_ul_returns": [[238, 272], ["numpy.abs", "numpy.abs", "rlpyt.algos.utils.discount_return_n_step", "return_dest.copy", "numpy.abs", "rlpyt.algos.utils.discount_return_n_step", "numpy.arange", "numpy.arange"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.algos.utils.discount_return_n_step", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.collections.AttrDict.copy", "home.repos.pwc.inspect_result.astooke_rlpyt.algos.utils.discount_return_n_step"], ["", "def", "compute_ul_returns", "(", "self", ",", "T", ")", ":", "\n", "        ", "\"\"\"Compute the n-step returns using the new rewards just written into\n        the buffer, but before the buffer cursor is advanced.  Input ``T`` is\n        the number of new timesteps which were just written.\n        Does nothing if `n-step==1`. e.g. if 2-step return, t-1\n        is first return written here, using reward at t-1 and new reward at t\n        (up through t-1+T from t+T).]\n\n        Use ABSOLUTE VALUE of rewards...it's all good signal for prioritization.\n        \"\"\"", "\n", "t", ",", "nm1", "=", "self", ".", "replay_buffer", ".", "t", ",", "self", ".", "n_step_return", "-", "1", "\n", "if", "self", ".", "n_step_return", "==", "1", ":", "\n", "            ", "idxs", "=", "np", ".", "arange", "(", "t", "-", "nm1", ",", "t", "+", "T", ")", "%", "self", ".", "replay_buffer", ".", "T", "\n", "return_", "=", "np", ".", "abs", "(", "self", ".", "samples_reward", "[", "idxs", "]", ")", "\n", "return", "return_", "# return = reward, done_n = done", "\n", "", "if", "t", "-", "nm1", ">=", "0", "and", "t", "+", "T", "<=", "self", ".", "replay_buffer", ".", "T", ":", "# No wrap (operate in-place).", "\n", "            ", "reward", "=", "np", ".", "abs", "(", "self", ".", "samples_reward", "[", "t", "-", "nm1", ":", "t", "+", "T", "]", ")", "\n", "done", "=", "self", ".", "samples_done", "[", "t", "-", "nm1", ":", "t", "+", "T", "]", "\n", "return_dest", "=", "self", ".", "samples_return_", "[", "t", "-", "nm1", ":", "t", "-", "nm1", "+", "T", "]", "\n", "done_n_dest", "=", "self", ".", "samples_done_n", "[", "t", "-", "nm1", ":", "t", "-", "nm1", "+", "T", "]", "\n", "discount_return_n_step", "(", "reward", ",", "done", ",", "n_step", "=", "self", ".", "n_step_return", ",", "\n", "discount", "=", "self", ".", "replay_buffer", ".", "discount", ",", "return_dest", "=", "return_dest", ",", "\n", "done_n_dest", "=", "done_n_dest", ")", "\n", "return", "return_dest", ".", "copy", "(", ")", "\n", "", "else", ":", "# Wrap (copies); Let it (wrongly) wrap at first call.", "\n", "            ", "idxs", "=", "np", ".", "arange", "(", "t", "-", "nm1", ",", "t", "+", "T", ")", "%", "self", ".", "replay_buffer", ".", "T", "\n", "reward", "=", "np", ".", "abs", "(", "self", ".", "samples_reward", "[", "idxs", "]", ")", "\n", "done", "=", "self", ".", "samples_done", "[", "idxs", "]", "\n", "dest_idxs", "=", "idxs", "[", ":", "-", "nm1", "]", "\n", "return_", ",", "done_n", "=", "discount_return_n_step", "(", "reward", ",", "done", ",", "\n", "n_step", "=", "self", ".", "n_step_return", ",", "discount", "=", "self", ".", "replay_buffer", ".", "discount", ")", "\n", "self", ".", "samples_return_", "[", "dest_idxs", "]", "=", "return_", "\n", "self", ".", "samples_done_n", "[", "dest_idxs", "]", "=", "done_n", "\n", "return", "return_", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.replays.rl_with_ul_replay.DqnWithUlReplayBufferMixin.__init__": [[278, 281], ["super().__init__"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.spaces.gym_wrapper.GymSpaceWrapper.__init__"], ["def", "__init__", "(", "self", ",", "ul_replay_T", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "self", ".", "ul_replay_T", "=", "ul_replay_T", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.replays.rl_with_ul_replay.DqnWithUlReplayBufferMixin.ul_sample_batch": [[282, 285], ["rl_with_ul_replay.DqnWithUlReplayBufferMixin.ul_sample_idxs", "rl_with_ul_replay.DqnWithUlReplayBufferMixin.ul_extract_batch"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.replays.rl_with_ul_replay.DqnWithUlReplayBufferMixin.ul_sample_idxs", "home.repos.pwc.inspect_result.astooke_rlpyt.replays.rl_with_ul_replay.DqnWithUlReplayBufferMixin.ul_extract_batch"], ["", "def", "ul_sample_batch", "(", "self", ",", "batch_B", ")", ":", "\n", "        ", "T_idxs", ",", "B_idxs", "=", "self", ".", "ul_sample_idxs", "(", "batch_B", ")", "\n", "return", "self", ".", "ul_extract_batch", "(", "T_idxs", ",", "B_idxs", ",", "self", ".", "ul_replay_T", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.replays.rl_with_ul_replay.DqnWithUlReplayBufferMixin.ul_sample_idxs": [[286, 293], ["numpy.random.randint", "numpy.random.randint", "min"], "methods", ["None"], ["", "def", "ul_sample_idxs", "(", "self", ",", "batch_B", ")", ":", "\n", "        ", "t", ",", "b", ",", "f", "=", "self", ".", "t", ",", "self", ".", "ul_replay_T", ",", "0", "# cursor, off_backward, off_forward", "\n", "high", "=", "self", ".", "T", "-", "b", "-", "f", "if", "self", ".", "_buffer_full", "else", "t", "-", "b", "-", "f", "\n", "T_idxs", "=", "np", ".", "random", ".", "randint", "(", "low", "=", "0", ",", "high", "=", "high", ",", "size", "=", "(", "batch_B", ",", ")", ")", "\n", "T_idxs", "[", "T_idxs", ">=", "t", "-", "b", "]", "+=", "min", "(", "t", ",", "b", ")", "+", "f", "\n", "B_idxs", "=", "np", ".", "random", ".", "randint", "(", "low", "=", "0", ",", "high", "=", "self", ".", "B", ",", "size", "=", "(", "batch_B", ",", ")", ")", "\n", "return", "T_idxs", ",", "B_idxs", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.replays.rl_with_ul_replay.DqnWithUlReplayBufferMixin.ul_extract_batch": [[294, 303], ["SamplesFromReplay", "rlpyt.utils.buffer.torchify_buffer", "rl_with_ul_replay.DqnWithUlReplayBufferMixin.ul_extract_observation", "rlpyt.utils.buffer.buffer_func", "rlpyt.utils.misc.extract_sequences", "rlpyt.utils.misc.extract_sequences"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.utils.buffer.torchify_buffer", "home.repos.pwc.inspect_result.astooke_rlpyt.replays.rl_with_ul_replay.DqnWithUlReplayBufferMixin.ul_extract_observation", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.buffer.buffer_func", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.misc.extract_sequences", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.misc.extract_sequences"], ["", "def", "ul_extract_batch", "(", "self", ",", "T_idxs", ",", "B_idxs", ",", "T", ")", ":", "\n", "        ", "s", "=", "self", ".", "samples", "\n", "batch", "=", "SamplesFromReplay", "(", "\n", "observation", "=", "self", ".", "ul_extract_observation", "(", "T_idxs", ",", "B_idxs", ",", "T", ")", ",", "\n", "action", "=", "buffer_func", "(", "s", ".", "action", ",", "extract_sequences", ",", "T_idxs", ",", "B_idxs", ",", "T", ")", ",", "\n", "reward", "=", "extract_sequences", "(", "s", ".", "reward", ",", "T_idxs", ",", "B_idxs", ",", "T", ")", ",", "\n", "done", "=", "extract_sequences", "(", "s", ".", "done", ",", "T_idxs", ",", "B_idxs", ",", "T", ")", ",", "\n", ")", "\n", "return", "torchify_buffer", "(", "batch", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.replays.rl_with_ul_replay.DqnWithUlReplayBufferMixin.ul_extract_observation": [[308, 342], ["numpy.empty", "enumerate", "zip", "numpy.any", "range", "range", "slice", "range", "numpy.arange", "len", "numpy.where"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.utils.misc.empty"], ["", "def", "ul_extract_observation", "(", "self", ",", "T_idxs", ",", "B_idxs", ",", "T", ")", ":", "\n", "        ", "\"\"\"Observations are re-assembled from frame-wise buffer as [T,B,C,H,W],\n        where C is the frame-history channels, which will have redundancy across the\n        T dimension.  Frames are returned OLDEST to NEWEST along the C dimension.\n\n        Frames are zero-ed after environment resets.\"\"\"", "\n", "observation", "=", "np", ".", "empty", "(", "shape", "=", "(", "T", ",", "len", "(", "B_idxs", ")", ",", "self", ".", "n_frames", ")", "+", "# [T,B,C,H,W]", "\n", "self", ".", "samples_frames", ".", "shape", "[", "2", ":", "]", ",", "dtype", "=", "self", ".", "samples_frames", ".", "dtype", ")", "\n", "fm1", "=", "self", ".", "n_frames", "-", "1", "\n", "for", "i", ",", "(", "t", ",", "b", ")", "in", "enumerate", "(", "zip", "(", "T_idxs", ",", "B_idxs", ")", ")", ":", "\n", "            ", "if", "t", "+", "T", ">", "self", ".", "T", ":", "# wrap (n_frames duplicated)", "\n", "                ", "m", "=", "self", ".", "T", "-", "t", "\n", "w", "=", "T", "-", "m", "\n", "for", "f", "in", "range", "(", "self", ".", "n_frames", ")", ":", "\n", "                    ", "observation", "[", ":", "m", ",", "i", ",", "f", "]", "=", "self", ".", "samples_frames", "[", "t", "+", "f", ":", "t", "+", "f", "+", "m", ",", "b", "]", "\n", "observation", "[", "m", ":", ",", "i", ",", "f", "]", "=", "self", ".", "samples_frames", "[", "f", ":", "w", "+", "f", ",", "b", "]", "\n", "", "", "else", ":", "\n", "                ", "for", "f", "in", "range", "(", "self", ".", "n_frames", ")", ":", "\n", "                    ", "observation", "[", ":", ",", "i", ",", "f", "]", "=", "self", ".", "samples_frames", "[", "t", "+", "f", ":", "t", "+", "f", "+", "T", ",", "b", "]", "\n", "\n", "# Populate empty (zero) frames after environment done.", "\n", "", "", "if", "t", "-", "fm1", "<", "0", "or", "t", "+", "T", ">", "self", ".", "T", ":", "# Wrap.", "\n", "                ", "done_idxs", "=", "np", ".", "arange", "(", "t", "-", "fm1", ",", "t", "+", "T", ")", "%", "self", ".", "T", "\n", "", "else", ":", "\n", "                ", "done_idxs", "=", "slice", "(", "t", "-", "fm1", ",", "t", "+", "T", ")", "\n", "", "done_fm1", "=", "self", ".", "samples", ".", "done", "[", "done_idxs", ",", "b", "]", "\n", "if", "np", ".", "any", "(", "done_fm1", ")", ":", "\n", "                ", "where_done_t", "=", "np", ".", "where", "(", "done_fm1", ")", "[", "0", "]", "-", "fm1", "# Might be negative...", "\n", "for", "f", "in", "range", "(", "1", ",", "self", ".", "n_frames", ")", ":", "\n", "                    ", "t_blanks", "=", "where_done_t", "+", "f", "# ...might be > T...", "\n", "t_blanks", "=", "t_blanks", "[", "(", "t_blanks", ">=", "0", ")", "&", "(", "t_blanks", "<", "T", ")", "]", "# ..don't let it wrap.", "\n", "observation", "[", "t_blanks", ",", "i", ",", ":", "self", ".", "n_frames", "-", "f", "]", "=", "0", "\n", "\n", "", "", "", "return", "observation", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.non_sequence.frame.NStepFrameBuffer.extract_observation": [[14, 31], ["numpy.stack", "range", "numpy.where", "zip"], "methods", ["None"], ["\n", "\n", "def", "__init__", "(", "self", ",", "example", ",", "**", "kwargs", ")", ":", "\n", "        ", "field_names", "=", "[", "f", "for", "f", "in", "example", ".", "_fields", "if", "f", "!=", "\"observation\"", "]", "\n", "global", "BufferSamples", "\n", "BufferSamples", "=", "namedarraytuple", "(", "\"BufferSamples\"", ",", "field_names", ")", "\n", "buffer_example", "=", "BufferSamples", "(", "*", "(", "v", "for", "k", ",", "v", "in", "example", ".", "items", "(", ")", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.non_sequence.time_limit.NStepTimeLimitBuffer.__init__": [[23, 31], ["rlpyt.replays.non_sequence.n_step.NStepReturnBuffer.__init__", "rlpyt.utils.buffer.buffer_from_example"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.spaces.gym_wrapper.GymSpaceWrapper.__init__", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.buffer.buffer_from_example"], ["def", "__init__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "if", "self", ".", "n_step_return", ">", "1", ":", "\n", "            ", "self", ".", "samples_timeout_n", "=", "buffer_from_example", "(", "\n", "self", ".", "samples", ".", "timeout", "[", "0", ",", "0", "]", ",", "(", "self", ".", "T", ",", "self", ".", "B", ")", ",", "\n", "share_memory", "=", "self", ".", "async_", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "samples_timeout_n", "=", "self", ".", "samples", ".", "timeout", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.non_sequence.time_limit.NStepTimeLimitBuffer.extract_batch": [[32, 39], ["super().extract_batch", "SamplesFromReplayTL", "rlpyt.utils.buffer.torchify_buffer"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.sequence.n_step.SequenceNStepReturnBuffer.extract_batch", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.buffer.torchify_buffer"], ["", "", "def", "extract_batch", "(", "self", ",", "T_idxs", ",", "B_idxs", ")", ":", "\n", "        ", "batch", "=", "super", "(", ")", ".", "extract_batch", "(", "T_idxs", ",", "B_idxs", ")", "\n", "batch", "=", "SamplesFromReplayTL", "(", "*", "batch", ",", "\n", "timeout", "=", "self", ".", "samples", ".", "timeout", "[", "T_idxs", ",", "B_idxs", "]", ",", "\n", "timeout_n", "=", "self", ".", "samples_timeout_n", "[", "T_idxs", ",", "B_idxs", "]", ",", "\n", ")", "\n", "return", "torchify_buffer", "(", "batch", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.non_sequence.time_limit.NStepTimeLimitBuffer.compute_returns": [[40, 54], ["super().compute_returns", "slice", "slice", "numpy.arange", "numpy.arange"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.non_sequence.time_limit.NStepTimeLimitBuffer.compute_returns"], ["", "def", "compute_returns", "(", "self", ",", "T", ")", ":", "\n", "        ", "super", "(", ")", ".", "compute_returns", "(", "T", ")", "\n", "if", "self", ".", "n_step_return", "==", "1", ":", "\n", "            ", "return", "# timeout_n = timeout", "\n", "# Propagate timeout backwards into timeout_n, like done and done_n.", "\n", "", "t", ",", "nm1", "=", "self", ".", "t", ",", "self", ".", "n_step_return", "-", "1", "\n", "if", "t", "-", "nm1", ">=", "0", "and", "t", "+", "T", "<=", "self", ".", "T", ":", "\n", "            ", "idxs", "=", "slice", "(", "t", "-", "nm1", ",", "t", "-", "nm1", "+", "T", ")", "\n", "to_idxs", "=", "slice", "(", "t", ",", "t", "+", "T", ")", "\n", "", "else", ":", "\n", "            ", "idxs", "=", "np", ".", "arange", "(", "t", "-", "nm1", ",", "t", "-", "nm1", "+", "T", ")", "%", "T", "\n", "to_idxs", "=", "np", ".", "arange", "(", "t", ",", "t", "+", "T", ")", "%", "T", "\n", "", "self", ".", "samples_timeout_n", "[", "idxs", "]", "=", "(", "self", ".", "samples_done_n", "[", "idxs", "]", "*", "\n", "self", ".", "samples", ".", "timeout", "[", "to_idxs", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.non_sequence.n_step.NStepReturnBuffer.extract_batch": [[16, 44], ["SamplesFromReplay", "rlpyt.utils.buffer.torchify_buffer", "numpy.where", "rlpyt.agents.base.AgentInputs", "rlpyt.agents.base.AgentInputs", "n_step.NStepReturnBuffer.extract_observation", "n_step.NStepReturnBuffer.extract_observation"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.utils.buffer.torchify_buffer", "home.repos.pwc.inspect_result.astooke_rlpyt.sequence.n_step.SequenceNStepReturnBuffer.extract_observation", "home.repos.pwc.inspect_result.astooke_rlpyt.sequence.n_step.SequenceNStepReturnBuffer.extract_observation"], ["\n", "\n", "def", "__init__", "(", "self", ",", "example", ",", "size", ",", "B", ",", "discount", "=", "1", ",", "n_step_return", "=", "1", ")", ":", "\n", "        ", "self", ".", "T", "=", "T", "=", "math", ".", "ceil", "(", "size", "/", "B", ")", "\n", "self", ".", "B", "=", "B", "\n", "self", ".", "size", "=", "T", "*", "B", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.non_sequence.n_step.NStepReturnBuffer.extract_observation": [[45, 49], ["None"], "methods", ["None"], ["self", ".", "discount", "=", "discount", "\n", "self", ".", "n_step_return", "=", "n_step_return", "\n", "self", ".", "t", "=", "0", "# Cursor (in T dimension).", "\n", "self", ".", "samples", "=", "buffer_from_example", "(", "example", ",", "(", "T", ",", "B", ")", ",", "\n", "share_memory", "=", "self", ".", "async_", ")", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.non_sequence.prioritized.PrioritizedReplay.__init__": [[24, 29], ["super().__init__", "rlpyt.utils.quick_args.save__init__args", "prioritized.PrioritizedReplay.init_priority_tree", "locals"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.spaces.gym_wrapper.GymSpaceWrapper.__init__", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.quick_args.save__init__args", "home.repos.pwc.inspect_result.astooke_rlpyt.sequence.prioritized.PrioritizedSequenceReplay.init_priority_tree"], ["def", "__init__", "(", "self", ",", "alpha", "=", "0.6", ",", "beta", "=", "0.4", ",", "default_priority", "=", "1", ",", "unique", "=", "False", ",", "\n", "input_priorities", "=", "False", ",", "input_priority_shift", "=", "0", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "save__init__args", "(", "locals", "(", ")", ")", "\n", "self", ".", "init_priority_tree", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.non_sequence.prioritized.PrioritizedReplay.init_priority_tree": [[30, 41], ["SumTreeCls"], "methods", ["None"], ["", "def", "init_priority_tree", "(", "self", ")", ":", "\n", "        ", "\"\"\"Organized here for clean inheritance.\"\"\"", "\n", "SumTreeCls", "=", "AsyncSumTree", "if", "self", ".", "async_", "else", "SumTree", "\n", "self", ".", "priority_tree", "=", "SumTreeCls", "(", "\n", "T", "=", "self", ".", "T", ",", "\n", "B", "=", "self", ".", "B", ",", "\n", "off_backward", "=", "self", ".", "off_backward", ",", "\n", "off_forward", "=", "self", ".", "off_forward", ",", "\n", "default_value", "=", "self", ".", "default_priority", "**", "self", ".", "alpha", ",", "\n", "enable_input_priorities", "=", "self", ".", "input_priorities", ",", "\n", "input_priority_shift", "=", "self", ".", "input_priority_shift", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.non_sequence.prioritized.PrioritizedReplay.set_beta": [[43, 45], ["None"], "methods", ["None"], ["", "def", "set_beta", "(", "self", ",", "beta", ")", ":", "\n", "        ", "self", ".", "beta", "=", "beta", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.non_sequence.prioritized.PrioritizedReplay.append_samples": [[46, 59], ["hasattr", "super().append_samples", "prioritized.PrioritizedReplay.priority_tree.advance"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.sequence.prioritized.PrioritizedSequenceReplay.append_samples", "home.repos.pwc.inspect_result.astooke_rlpyt.replays.sum_tree.AsyncSumTree.advance"], ["", "def", "append_samples", "(", "self", ",", "samples", ")", ":", "\n", "        ", "\"\"\"Looks for ``samples.priorities``; if not found, uses default priority.  Writes\n        samples using super class's ``append_samples``, and advances matching cursor in\n        priority tree.\n        \"\"\"", "\n", "if", "hasattr", "(", "samples", ",", "\"priorities\"", ")", ":", "\n", "            ", "priorities", "=", "samples", ".", "priorities", "**", "self", ".", "alpha", "\n", "samples", "=", "samples", ".", "samples", "\n", "", "else", ":", "\n", "            ", "priorities", "=", "None", "\n", "", "T", ",", "idxs", "=", "super", "(", ")", ".", "append_samples", "(", "samples", ")", "\n", "self", ".", "priority_tree", ".", "advance", "(", "T", ",", "priorities", "=", "priorities", ")", "# Progress priority_tree cursor.", "\n", "return", "T", ",", "idxs", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.non_sequence.prioritized.PrioritizedReplay.sample_batch": [[60, 72], ["prioritized.PrioritizedReplay.priority_tree.sample", "prioritized.PrioritizedReplay.extract_batch", "max", "rlpyt.utils.buffer.torchify_buffer().float", "SamplesFromReplayPri", "rlpyt.utils.buffer.torchify_buffer"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.spaces.gym_wrapper.GymSpaceWrapper.sample", "home.repos.pwc.inspect_result.astooke_rlpyt.sequence.n_step.SequenceNStepReturnBuffer.extract_batch", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.buffer.torchify_buffer"], ["", "def", "sample_batch", "(", "self", ",", "batch_B", ")", ":", "\n", "        ", "\"\"\"Calls on the priority tree to generate random samples.  Returns\n        samples data and normalized importance-sampling weights:\n        ``is_weights=priorities ** -beta``\n        \"\"\"", "\n", "(", "T_idxs", ",", "B_idxs", ")", ",", "priorities", "=", "self", ".", "priority_tree", ".", "sample", "(", "batch_B", ",", "\n", "unique", "=", "self", ".", "unique", ")", "\n", "batch", "=", "self", ".", "extract_batch", "(", "T_idxs", ",", "B_idxs", ")", "\n", "is_weights", "=", "(", "1.", "/", "(", "priorities", "+", "EPS", ")", ")", "**", "self", ".", "beta", "# Unnormalized.", "\n", "is_weights", "/=", "max", "(", "is_weights", ")", "# Normalize.", "\n", "is_weights", "=", "torchify_buffer", "(", "is_weights", ")", ".", "float", "(", ")", "\n", "return", "SamplesFromReplayPri", "(", "*", "batch", ",", "is_weights", "=", "is_weights", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.non_sequence.prioritized.PrioritizedReplay.update_batch_priorities": [[73, 80], ["rlpyt.utils.buffer.numpify_buffer", "prioritized.PrioritizedReplay.priority_tree.update_batch_priorities"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.utils.buffer.numpify_buffer", "home.repos.pwc.inspect_result.astooke_rlpyt.sequence.prioritized.PrioritizedSequenceReplay.update_batch_priorities"], ["", "def", "update_batch_priorities", "(", "self", ",", "priorities", ")", ":", "\n", "        ", "\"\"\"Takes in new priorities (i.e. from the algorithm after a training\n        step) and sends them to priority tree as ``priorities ** alpha``; the\n        tree internally remembers which indexes were sampled for this batch.\n        \"\"\"", "\n", "priorities", "=", "numpify_buffer", "(", "priorities", ")", "\n", "self", ".", "priority_tree", ".", "update_batch_priorities", "(", "priorities", "**", "self", ".", "alpha", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.non_sequence.uniform.UniformReplay.sample_batch": [[11, 16], ["uniform.UniformReplay.sample_idxs", "uniform.UniformReplay.extract_batch"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.sequence.uniform.UniformSequenceReplay.sample_idxs", "home.repos.pwc.inspect_result.astooke_rlpyt.sequence.n_step.SequenceNStepReturnBuffer.extract_batch"], ["def", "sample_batch", "(", "self", ",", "batch_B", ")", ":", "\n", "        ", "\"\"\"Randomly select desired batch size of samples to return, uses\n        ``sample_idxs()`` and ``extract_batch()``.\"\"\"", "\n", "T_idxs", ",", "B_idxs", "=", "self", ".", "sample_idxs", "(", "batch_B", ")", "\n", "return", "self", ".", "extract_batch", "(", "T_idxs", ",", "B_idxs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.non_sequence.uniform.UniformReplay.sample_idxs": [[17, 29], ["numpy.random.randint", "numpy.random.randint", "min"], "methods", ["None"], ["", "def", "sample_idxs", "(", "self", ",", "batch_B", ")", ":", "\n", "        ", "\"\"\"Randomly choose the indexes of data to return using\n        ``np.random.randint()``.  Disallow samples within certain proximity to\n        the current cursor which hold invalid data.\n        \"\"\"", "\n", "t", ",", "b", ",", "f", "=", "self", ".", "t", ",", "self", ".", "off_backward", ",", "self", ".", "off_forward", "\n", "high", "=", "self", ".", "T", "-", "b", "-", "f", "if", "self", ".", "_buffer_full", "else", "t", "-", "b", "\n", "low", "=", "0", "if", "self", ".", "_buffer_full", "else", "f", "\n", "T_idxs", "=", "np", ".", "random", ".", "randint", "(", "low", "=", "low", ",", "high", "=", "high", ",", "size", "=", "(", "batch_B", ",", ")", ")", "\n", "T_idxs", "[", "T_idxs", ">=", "t", "-", "b", "]", "+=", "min", "(", "t", ",", "b", ")", "+", "f", "# min for invalid high t.", "\n", "B_idxs", "=", "np", ".", "random", ".", "randint", "(", "low", "=", "0", ",", "high", "=", "self", ".", "B", ",", "size", "=", "(", "batch_B", ",", ")", ")", "\n", "return", "T_idxs", ",", "B_idxs", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.sequence.frame.SequenceNStepFrameBuffer.extract_observation": [[17, 51], ["numpy.empty", "enumerate", "zip", "numpy.any", "range", "range", "slice", "range", "numpy.arange", "len", "numpy.where"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.utils.misc.empty"], ["\n", "\n", "def", "__init__", "(", "self", ",", "example", ",", "**", "kwargs", ")", ":", "\n", "        ", "field_names", "=", "[", "f", "for", "f", "in", "example", ".", "_fields", "if", "f", "!=", "\"observation\"", "]", "\n", "global", "BufferSamples", "\n", "BufferSamples", "=", "namedarraytuple", "(", "\"BufferSamples\"", ",", "field_names", ")", "\n", "buffer_example", "=", "BufferSamples", "(", "*", "(", "v", "for", "k", ",", "v", "in", "example", ".", "items", "(", ")", "\n", "if", "k", "!=", "\"observation\"", ")", ")", "\n", "super", "(", ")", ".", "__init__", "(", "example", "=", "buffer_example", ",", "**", "kwargs", ")", "\n", "# Equivalent to image.shape[0] if observation is image array (C,H,W):", "\n", "self", ".", "n_frames", "=", "n_frames", "=", "get_leading_dims", "(", "example", ".", "observation", ",", "\n", "n_dim", "=", "1", ")", "[", "0", "]", "\n", "logger", ".", "log", "(", "f\"Frame-based buffer using {n_frames}-frame sequences.\"", ")", "\n", "# frames: oldest stored at t; duplicate n_frames - 1 beginning & end.", "\n", "self", ".", "samples_frames", "=", "buffer_from_example", "(", "example", ".", "observation", "[", "0", "]", ",", "\n", "(", "self", ".", "T", "+", "n_frames", "-", "1", ",", "self", ".", "B", ")", ",", "\n", "share_memory", "=", "self", ".", "async_", ")", "# [T+n_frames-1,B,H,W]", "\n", "# new_frames: shifted so newest stored at t; no duplication.", "\n", "self", ".", "samples_new_frames", "=", "self", ".", "samples_frames", "[", "n_frames", "-", "1", ":", "]", "# [T,B,H,W]", "\n", "self", ".", "off_forward", "=", "max", "(", "self", ".", "off_forward", ",", "n_frames", "-", "1", ")", "\n", "\n", "", "def", "append_samples", "(", "self", ",", "samples", ")", ":", "\n", "        ", "\"\"\"Appends all samples except for the `observation` as normal.\n        Only the new frame in each observation is recorded.\"\"\"", "\n", "t", ",", "fm1", "=", "self", ".", "t", ",", "self", ".", "n_frames", "-", "1", "\n", "buffer_samples", "=", "BufferSamples", "(", "*", "(", "v", "for", "k", ",", "v", "in", "samples", ".", "items", "(", ")", "\n", "if", "k", "!=", "\"observation\"", ")", ")", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.sequence.n_step.SequenceNStepReturnBuffer.__init__": [[27, 48], ["rlpyt.replays.n_step.BaseNStepReturnBuffer.__init__", "rlpyt.utils.collections.namedarraytuple", "rlpyt.utils.collections.namedarraytuple.", "rlpyt.utils.buffer.buffer_from_example", "math.ceil", "math.ceil", "example.items"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.spaces.gym_wrapper.GymSpaceWrapper.__init__", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.collections.namedarraytuple", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.buffer.buffer_from_example", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.collections.NamedArrayTuple.items"], ["\n", "\n", "def", "__init__", "(", "self", ",", "example", ",", "size", ",", "B", ",", "discount", "=", "1", ",", "n_step_return", "=", "1", ")", ":", "\n", "        ", "self", ".", "T", "=", "T", "=", "math", ".", "ceil", "(", "size", "/", "B", ")", "\n", "self", ".", "B", "=", "B", "\n", "self", ".", "size", "=", "T", "*", "B", "\n", "self", ".", "discount", "=", "discount", "\n", "self", ".", "n_step_return", "=", "n_step_return", "\n", "self", ".", "t", "=", "0", "# Cursor (in T dimension).", "\n", "self", ".", "samples", "=", "buffer_from_example", "(", "example", ",", "(", "T", ",", "B", ")", ",", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.sequence.n_step.SequenceNStepReturnBuffer.append_samples": [[49, 67], ["SamplesToBuffer", "super().append_samples", "super().append_samples", "math.ceil", "slice", "numpy.arange", "samples.items"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.sequence.prioritized.PrioritizedSequenceReplay.append_samples", "home.repos.pwc.inspect_result.astooke_rlpyt.sequence.prioritized.PrioritizedSequenceReplay.append_samples", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.collections.NamedArrayTuple.items"], ["share_memory", "=", "self", ".", "async_", ")", "\n", "if", "n_step_return", ">", "1", ":", "\n", "            ", "self", ".", "samples_return_", "=", "buffer_from_example", "(", "example", ".", "reward", ",", "(", "T", ",", "B", ")", ",", "\n", "share_memory", "=", "self", ".", "async_", ")", "\n", "self", ".", "samples_done_n", "=", "buffer_from_example", "(", "example", ".", "done", ",", "(", "T", ",", "B", ")", ",", "\n", "share_memory", "=", "self", ".", "async_", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "samples_return_", "=", "self", ".", "samples", ".", "reward", "\n", "self", ".", "samples_done_n", "=", "self", ".", "samples", ".", "done", "\n", "", "self", ".", "_buffer_full", "=", "False", "\n", "self", ".", "off_backward", "=", "n_step_return", "# Current invalid samples.", "\n", "self", ".", "off_forward", "=", "1", "# i.e. current cursor, prev_action overwritten.", "\n", "\n", "", "def", "append_samples", "(", "self", ",", "samples", ")", ":", "\n", "        ", "\"\"\"Write the samples into the buffer and advance the time cursor.\n        Handle wrapping of the cursor if necessary (boundary doesn't need to\n        align with length of ``samples``).  Compute and store returns with\n        newly available rewards.\"\"\"", "\n", "T", ",", "B", "=", "get_leading_dims", "(", "samples", ",", "n_dim", "=", "2", ")", "# samples.env.reward.shape[:2]", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.sequence.n_step.SequenceNStepReturnBuffer.extract_batch": [[68, 101], ["SamplesFromReplay", "rlpyt.utils.buffer.torchify_buffer", "numpy.all", "n_step.SequenceNStepReturnBuffer.extract_observation", "rlpyt.utils.buffer.buffer_func", "rlpyt.utils.misc.extract_sequences", "rlpyt.utils.misc.extract_sequences", "rlpyt.utils.misc.extract_sequences", "rlpyt.utils.misc.extract_sequences", "numpy.asarray"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.utils.buffer.torchify_buffer", "home.repos.pwc.inspect_result.astooke_rlpyt.sequence.n_step.SequenceNStepReturnBuffer.extract_observation", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.buffer.buffer_func", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.misc.extract_sequences", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.misc.extract_sequences", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.misc.extract_sequences", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.misc.extract_sequences"], ["assert", "B", "==", "self", ".", "B", "\n", "t", "=", "self", ".", "t", "\n", "if", "t", "+", "T", ">", "self", ".", "T", ":", "# Wrap.", "\n", "            ", "idxs", "=", "np", ".", "arange", "(", "t", ",", "t", "+", "T", ")", "%", "self", ".", "T", "\n", "", "else", ":", "\n", "            ", "idxs", "=", "slice", "(", "t", ",", "t", "+", "T", ")", "\n", "", "self", ".", "samples", "[", "idxs", "]", "=", "samples", "\n", "self", ".", "compute_returns", "(", "T", ")", "\n", "if", "not", "self", ".", "_buffer_full", "and", "t", "+", "T", ">=", "self", ".", "T", ":", "\n", "            ", "self", ".", "_buffer_full", "=", "True", "# Only changes on first around.", "\n", "", "self", ".", "t", "=", "(", "t", "+", "T", ")", "%", "self", ".", "T", "\n", "return", "T", ",", "idxs", "# Pass these on to subclass.", "\n", "\n", "", "def", "compute_returns", "(", "self", ",", "T", ")", ":", "\n", "        ", "\"\"\"Compute the n-step returns using the new rewards just written into\n        the buffer, but before the buffer cursor is advanced.  Input ``T`` is\n        the number of new timesteps which were just written.\n        Does nothing if `n-step==1`. e.g. if 2-step return, t-1\n        is first return written here, using reward at t-1 and new reward at t\n        (up through t-1+T from t+T).\"\"\"", "\n", "if", "self", ".", "n_step_return", "==", "1", ":", "\n", "            ", "return", "# return = reward, done_n = done", "\n", "", "t", ",", "s", "=", "self", ".", "t", ",", "self", ".", "samples", "\n", "nm1", "=", "self", ".", "n_step_return", "-", "1", "\n", "if", "t", "-", "nm1", ">=", "0", "and", "t", "+", "T", "<=", "self", ".", "T", ":", "# No wrap (operate in-place).", "\n", "            ", "reward", "=", "s", ".", "reward", "[", "t", "-", "nm1", ":", "t", "+", "T", "]", "\n", "done", "=", "s", ".", "done", "[", "t", "-", "nm1", ":", "t", "+", "T", "]", "\n", "return_dest", "=", "self", ".", "samples_return_", "[", "t", "-", "nm1", ":", "t", "-", "nm1", "+", "T", "]", "\n", "done_n_dest", "=", "self", ".", "samples_done_n", "[", "t", "-", "nm1", ":", "t", "-", "nm1", "+", "T", "]", "\n", "discount_return_n_step", "(", "reward", ",", "done", ",", "n_step", "=", "self", ".", "n_step_return", ",", "\n", "discount", "=", "self", ".", "discount", ",", "return_dest", "=", "return_dest", ",", "\n", "done_n_dest", "=", "done_n_dest", ")", "\n", "", "else", ":", "# Wrap (copies); Let it (wrongly) wrap at first call.", "\n", "            ", "idxs", "=", "np", ".", "arange", "(", "t", "-", "nm1", ",", "t", "+", "T", ")", "%", "self", ".", "T", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.sequence.n_step.SequenceNStepReturnBuffer.extract_observation": [[102, 106], ["rlpyt.utils.buffer.buffer_func"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.utils.buffer.buffer_func"], ["reward", "=", "s", ".", "reward", "[", "idxs", "]", "\n", "done", "=", "s", ".", "done", "[", "idxs", "]", "\n", "dest_idxs", "=", "idxs", "[", ":", "-", "nm1", "]", "\n", "return_", ",", "done_n", "=", "discount_return_n_step", "(", "reward", ",", "done", ",", "\n", "n_step", "=", "self", ".", "n_step_return", ",", "discount", "=", "self", ".", "discount", ")", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.sequence.prioritized.PrioritizedSequenceReplay.__init__": [[49, 55], ["super().__init__", "rlpyt.utils.quick_args.save__init__args", "prioritized.PrioritizedSequenceReplay.init_priority_tree", "locals"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.spaces.gym_wrapper.GymSpaceWrapper.__init__", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.quick_args.save__init__args", "home.repos.pwc.inspect_result.astooke_rlpyt.sequence.prioritized.PrioritizedSequenceReplay.init_priority_tree"], ["\n", "if", "hasattr", "(", "samples", ",", "\"priorities\"", ")", ":", "\n", "            ", "priorities", "=", "samples", ".", "priorities", "**", "self", ".", "alpha", "\n", "samples", "=", "samples", ".", "samples", "\n", "", "else", ":", "\n", "            ", "priorities", "=", "None", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.sequence.prioritized.PrioritizedSequenceReplay.init_priority_tree": [[56, 68], ["max", "math.ceil", "SumTreeCls", "math.ceil"], "methods", ["None"], ["", "T", ",", "idxs", "=", "super", "(", ")", ".", "append_samples", "(", "samples", ")", "\n", "self", ".", "priority_tree", ".", "advance", "(", "T", ",", "priorities", "=", "priorities", ")", "# Progress priority_tree cursor.", "\n", "return", "T", ",", "idxs", "\n", "\n", "", "def", "sample_batch", "(", "self", ",", "batch_B", ")", ":", "\n", "        ", "\"\"\"Calls on the priority tree to generate random samples.  Returns\n        samples data and normalized importance-sampling weights:\n        ``is_weights=priorities ** -beta``\n        \"\"\"", "\n", "(", "T_idxs", ",", "B_idxs", ")", ",", "priorities", "=", "self", ".", "priority_tree", ".", "sample", "(", "batch_B", ",", "\n", "unique", "=", "self", ".", "unique", ")", "\n", "batch", "=", "self", ".", "extract_batch", "(", "T_idxs", ",", "B_idxs", ")", "\n", "is_weights", "=", "(", "1.", "/", "(", "priorities", "+", "EPS", ")", ")", "**", "self", ".", "beta", "# Unnormalized.", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.sequence.prioritized.PrioritizedSequenceReplay.set_beta": [[70, 72], ["None"], "methods", ["None"], ["is_weights", "=", "torchify_buffer", "(", "is_weights", ")", ".", "float", "(", ")", "\n", "return", "SamplesFromReplayPri", "(", "*", "batch", ",", "is_weights", "=", "is_weights", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.sequence.prioritized.PrioritizedSequenceReplay.append_samples": [[73, 98], ["hasattr", "super().append_samples", "prioritized.PrioritizedSequenceReplay.priority_tree.advance", "prioritized.PrioritizedSequenceReplay.priority_tree.advance"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.sequence.prioritized.PrioritizedSequenceReplay.append_samples", "home.repos.pwc.inspect_result.astooke_rlpyt.replays.sum_tree.AsyncSumTree.advance", "home.repos.pwc.inspect_result.astooke_rlpyt.replays.sum_tree.AsyncSumTree.advance"], ["", "def", "update_batch_priorities", "(", "self", ",", "priorities", ")", ":", "\n", "        ", "\"\"\"Takes in new priorities (i.e. from the algorithm after a training\n        step) and sends them to priority tree as ``priorities ** alpha``; the\n        tree internally remembers which indexes were sampled for this batch.\n        \"\"\"", "\n", "priorities", "=", "numpify_buffer", "(", "priorities", ")", "\n", "self", ".", "priority_tree", ".", "update_batch_priorities", "(", "priorities", "**", "self", ".", "alpha", ")", "\n", "\n", "\n", "", "", "class", "PrioritizedReplayBuffer", "(", "PrioritizedReplay", ",", "NStepReturnBuffer", ")", ":", "\n", "    ", "pass", "\n", "\n", "\n", "", "class", "AsyncPrioritizedReplayBuffer", "(", "AsyncReplayBufferMixin", ",", "\n", "PrioritizedReplayBuffer", ")", ":", "\n", "    ", "pass", "\n", "", ""]], "home.repos.pwc.inspect_result.astooke_rlpyt.sequence.prioritized.PrioritizedSequenceReplay.sample_batch": [[99, 112], ["prioritized.PrioritizedSequenceReplay.priority_tree.sample", "prioritized.PrioritizedSequenceReplay.extract_batch", "max", "rlpyt.utils.buffer.torchify_buffer().float", "SamplesFromReplayPri", "rlpyt.utils.buffer.torchify_buffer"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.spaces.gym_wrapper.GymSpaceWrapper.sample", "home.repos.pwc.inspect_result.astooke_rlpyt.sequence.n_step.SequenceNStepReturnBuffer.extract_batch", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.buffer.torchify_buffer"], []], "home.repos.pwc.inspect_result.astooke_rlpyt.sequence.prioritized.PrioritizedSequenceReplay.update_batch_priorities": [[113, 116], ["rlpyt.utils.buffer.numpify_buffer", "prioritized.PrioritizedSequenceReplay.priority_tree.update_batch_priorities"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.utils.buffer.numpify_buffer", "home.repos.pwc.inspect_result.astooke_rlpyt.sequence.prioritized.PrioritizedSequenceReplay.update_batch_priorities"], []], "home.repos.pwc.inspect_result.astooke_rlpyt.sequence.uniform.UniformSequenceReplay.set_batch_T": [[12, 14], ["None"], "methods", ["None"], ["        ", "\"\"\"Randomly select desired batch size of samples to return, uses\n        ``sample_idxs()`` and ``extract_batch()``.\"\"\"", "\n", "T_idxs", ",", "B_idxs", "=", "self", ".", "sample_idxs", "(", "batch_B", ")", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.sequence.uniform.UniformSequenceReplay.sample_batch": [[15, 23], ["uniform.UniformSequenceReplay.sample_idxs", "uniform.UniformSequenceReplay.extract_batch"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.sequence.uniform.UniformSequenceReplay.sample_idxs", "home.repos.pwc.inspect_result.astooke_rlpyt.sequence.n_step.SequenceNStepReturnBuffer.extract_batch"], ["return", "self", ".", "extract_batch", "(", "T_idxs", ",", "B_idxs", ")", "\n", "\n", "", "def", "sample_idxs", "(", "self", ",", "batch_B", ")", ":", "\n", "        ", "\"\"\"Randomly choose the indexes of data to return using\n        ``np.random.randint()``.  Disallow samples within certain proximity to\n        the current cursor which hold invalid data.\n        \"\"\"", "\n", "t", ",", "b", ",", "f", "=", "self", ".", "t", ",", "self", ".", "off_backward", ",", "self", ".", "off_forward", "\n", "high", "=", "self", ".", "T", "-", "b", "-", "f", "if", "self", ".", "_buffer_full", "else", "t", "-", "b", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.sequence.uniform.UniformSequenceReplay.sample_idxs": [[24, 40], ["numpy.random.randint", "numpy.random.randint", "min"], "methods", ["None"], ["low", "=", "0", "if", "self", ".", "_buffer_full", "else", "f", "\n", "T_idxs", "=", "np", ".", "random", ".", "randint", "(", "low", "=", "low", ",", "high", "=", "high", ",", "size", "=", "(", "batch_B", ",", ")", ")", "\n", "T_idxs", "[", "T_idxs", ">=", "t", "-", "b", "]", "+=", "min", "(", "t", ",", "b", ")", "+", "f", "# min for invalid high t.", "\n", "B_idxs", "=", "np", ".", "random", ".", "randint", "(", "low", "=", "0", ",", "high", "=", "self", ".", "B", ",", "size", "=", "(", "batch_B", ",", ")", ")", "\n", "return", "T_idxs", ",", "B_idxs", "\n", "\n", "\n", "", "", "class", "UniformReplayBuffer", "(", "UniformReplay", ",", "NStepReturnBuffer", ")", ":", "\n", "    ", "pass", "\n", "\n", "\n", "", "class", "AsyncUniformReplayBuffer", "(", "AsyncReplayBufferMixin", ",", "UniformReplayBuffer", ")", ":", "\n", "    ", "pass", "\n", "", ""]], "home.repos.pwc.inspect_result.astooke_rlpyt.samplers.buffer.build_samples_buffer": [[11, 58], ["rlpyt.utils.buffer.buffer_from_example", "rlpyt.utils.buffer.buffer_from_example", "rlpyt.samplers.collections.AgentSamples", "rlpyt.utils.buffer.buffer_from_example", "rlpyt.utils.buffer.buffer_from_example", "rlpyt.utils.buffer.buffer_from_example", "rlpyt.utils.buffer.buffer_from_example", "rlpyt.samplers.collections.EnvSamples", "rlpyt.samplers.collections.Samples", "rlpyt.utils.buffer.torchify_buffer", "rlpyt.utils.buffer.buffer_from_example", "rlpyt.samplers.collections.AgentSamplesBsv", "multiprocessing.Manager", "mp.Manager.dict", "multiprocessing.Process", "mp.Process.start", "mp.Process.join", "dict", "buffer.get_example_outputs"], "function", ["home.repos.pwc.inspect_result.astooke_rlpyt.utils.buffer.buffer_from_example", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.buffer.buffer_from_example", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.buffer.buffer_from_example", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.buffer.buffer_from_example", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.buffer.buffer_from_example", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.buffer.buffer_from_example", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.buffer.torchify_buffer", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.buffer.buffer_from_example", "home.repos.pwc.inspect_result.astooke_rlpyt.samplers.buffer.get_example_outputs"], ["def", "buffer_from_example", "(", "example", ",", "leading_dims", ",", "share_memory", "=", "False", ",", "\n", "use_NatSchema", "=", "None", ")", ":", "\n", "    ", "\"\"\"Allocates memory and returns it in `namedarraytuple` with same\n    structure as ``examples``, which should be a `namedtuple` or\n    `namedarraytuple`. Applies the same leading dimensions ``leading_dims`` to\n    every entry, and otherwise matches their shapes and dtypes. The examples\n    should have no leading dimensions.  ``None`` fields will stay ``None``.\n    Optionally allocate on OS shared memory. Uses ``build_array()``.\n    \n    New: can use NamedArrayTuple types by the `use_NatSchema` flag, which\n    may be easier for pickling/unpickling when using spawn instead\n    of fork. If use_NatSchema is None, the type of ``example`` will be used to\n    infer what type to return (this is the default)\n    \"\"\"", "\n", "if", "example", "is", "None", ":", "\n", "        ", "return", "\n", "", "if", "use_NatSchema", "is", "None", ":", "\n", "        ", "use_NatSchema", "=", "isinstance", "(", "example", ",", "(", "NamedTuple", ",", "NamedArrayTuple", ")", ")", "\n", "", "try", ":", "\n", "        ", "if", "use_NatSchema", ":", "\n", "            ", "buffer_type", "=", "NamedArrayTupleSchema_like", "(", "example", ")", "\n", "", "else", ":", "\n", "            ", "buffer_type", "=", "namedarraytuple_like", "(", "example", ")", "\n", "", "", "except", "TypeError", ":", "# example was not a namedtuple or namedarraytuple", "\n", "        ", "return", "build_array", "(", "example", ",", "leading_dims", ",", "share_memory", ")", "\n", "", "return", "buffer_type", "(", "*", "(", "buffer_from_example", "(", "v", ",", "leading_dims", ",", "\n", "share_memory", "=", "share_memory", ",", "use_NatSchema", "=", "use_NatSchema", ")", "\n", "for", "v", "in", "example", ")", ")", "\n", "\n", "\n", "", "def", "build_array", "(", "example", ",", "leading_dims", ",", "share_memory", "=", "False", ")", ":", "\n", "    ", "\"\"\"Allocate a numpy array matchin the dtype and shape of example, possibly\n    with additional leading dimensions.  Optionally allocate on OS shared\n    memory.\n    \"\"\"", "\n", "a", "=", "np", ".", "asarray", "(", "example", ")", "\n", "if", "a", ".", "dtype", "==", "\"object\"", ":", "\n", "        ", "raise", "TypeError", "(", "\"Buffer example value cannot cast as np.dtype==object.\"", ")", "\n", "", "constructor", "=", "np_mp_array", "if", "share_memory", "else", "np", ".", "zeros", "\n", "if", "not", "isinstance", "(", "leading_dims", ",", "(", "list", ",", "tuple", ")", ")", ":", "\n", "        ", "leading_dims", "=", "(", "leading_dims", ",", ")", "\n", "", "return", "constructor", "(", "shape", "=", "leading_dims", "+", "a", ".", "shape", ",", "dtype", "=", "a", ".", "dtype", ")", "\n", "\n", "\n", "", "def", "np_mp_array", "(", "shape", ",", "dtype", ")", ":", "\n", "    ", "\"\"\"Allocate a numpy array on OS shared memory.\"\"\"", "\n", "if", "mp", ".", "get_start_method", "(", ")", "==", "\"spawn\"", ":", "\n", "        ", "return", "np_mp_array_spawn", "(", "shape", ",", "dtype", ")", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.samplers.buffer.get_example_outputs": [[60, 82], ["env.reset", "env.action_space.sample", "env.step", "numpy.asarray", "agent.reset", "rlpyt.utils.buffer.torchify_buffer", "agent.step", "torch.set_num_threads", "rlpyt.agents.base.AgentInputs", "agent_info._replace._replace"], "function", ["home.repos.pwc.inspect_result.astooke_rlpyt.safe.safety_gym_env.SafetyGymEnvWrapper.reset", "home.repos.pwc.inspect_result.astooke_rlpyt.spaces.gym_wrapper.GymSpaceWrapper.sample", "home.repos.pwc.inspect_result.astooke_rlpyt.safe.safety_gym_env.SafetyGymTrajInfo.step", "home.repos.pwc.inspect_result.astooke_rlpyt.safe.safety_gym_env.SafetyGymEnvWrapper.reset", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.buffer.torchify_buffer", "home.repos.pwc.inspect_result.astooke_rlpyt.safe.safety_gym_env.SafetyGymTrajInfo.step", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.collections.NamedTuple._replace"], ["nbytes", "=", "size", "*", "np", ".", "dtype", "(", "dtype", ")", ".", "itemsize", "\n", "mp_array", "=", "mp", ".", "RawArray", "(", "ctypes", ".", "c_char", ",", "nbytes", ")", "\n", "return", "np", ".", "frombuffer", "(", "mp_array", ",", "dtype", "=", "dtype", ",", "count", "=", "size", ")", ".", "reshape", "(", "shape", ")", "\n", "\n", "\n", "", "class", "np_mp_array_spawn", "(", "np", ".", "ndarray", ")", ":", "\n", "    ", "\"\"\"Shared ndarray for use with multiprocessing's 'spawn' start method.\n\n    This array can be shared between processes by passing it to a `Process`\n    init function (or similar). Note that this can only be shared _on process\n    startup_; it can't be passed through, e.g., a queue at runtime. Also it\n    cannot be pickled outside of multiprocessing's internals.\"\"\"", "\n", "_shmem", "=", "None", "\n", "\n", "def", "__new__", "(", "cls", ",", "shape", ",", "dtype", "=", "None", ",", "buffer", "=", "None", ",", "offset", "=", "None", ",", "strides", "=", "None", ",", "\n", "order", "=", "None", ")", ":", "\n", "# init buffer", "\n", "        ", "if", "buffer", "is", "None", ":", "\n", "            ", "assert", "offset", "is", "None", "\n", "assert", "strides", "is", "None", "\n", "size", "=", "int", "(", "np", ".", "prod", "(", "shape", ")", ")", "\n", "nbytes", "=", "size", "*", "np", ".", "dtype", "(", "dtype", ")", ".", "itemsize", "\n", "# this is the part that can be passed between processes", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.samplers.base.BaseSampler.__init__": [[27, 48], ["rlpyt.utils.quick_args.save__init__args", "rlpyt.samplers.collections.BatchSpec", "int", "int", "locals"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.utils.quick_args.save__init__args"], ["\n", "raise", "NotImplementedError", "\n", "\n", "", "def", "async_initialize", "(", "self", ",", "agent", ",", "sampler_n_itr", ",", "batch_spec", ",", "mid_batch_reset", ",", "\n", "examples", ",", "world_size", "=", "1", ")", ":", "\n", "        ", "\"\"\"Called instead of ``initialize()`` in async runner (not needed unless\n        using async runner). Should return async replay_buffer using shared\n        memory.\"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n", "", "def", "optim_initialize", "(", "self", ",", "rank", "=", "0", ")", ":", "\n", "        ", "\"\"\"Called in async runner which requires two stages of initialization;\n        might also be used in ``initialize()`` to avoid redundant code.\"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n", "", "def", "optimize_agent", "(", "self", ",", "itr", ",", "samples", "=", "None", ",", "sampler_itr", "=", "None", ")", ":", "\n", "        "]], "home.repos.pwc.inspect_result.astooke_rlpyt.samplers.base.BaseSampler.initialize": [[49, 53], ["None"], "methods", ["None"], ["\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.samplers.base.BaseSampler.obtain_samples": [[54, 57], ["None"], "methods", ["None"], ["raise", "NotImplementedError", "\n", "\n", "", "def", "optim_state_dict", "(", "self", ")", ":", "\n", "        "]], "home.repos.pwc.inspect_result.astooke_rlpyt.samplers.base.BaseSampler.evaluate_agent": [[58, 61], ["None"], "methods", ["None"], ["\n", "return", "self", ".", "optimizer", ".", "state_dict", "(", ")", "\n", "\n", "", "def", "load_optim_state_dict", "(", "self", ",", "state_dict", ")", ":", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.samplers.base.BaseSampler.shutdown": [[62, 64], ["None"], "methods", ["None"], ["        ", "\"\"\"Load an optimizer state dict; should expect the format returned\n        from ``optim_state_dict().``\"\"\"", "\n", "self", ".", "optimizer", ".", "load_state_dict", "(", "state_dict", ")", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.samplers.base.BaseSampler.batch_size": [[65, 68], ["None"], "methods", ["None"], ["\n", "", "@", "property", "\n", "def", "batch_size", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_batch_size", "# For logging at least.", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.samplers.collectors.BaseCollector.__init__": [[13, 27], ["rlpyt.utils.quick_args.save__init__args", "locals"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.utils.quick_args.save__init__args"], ["def", "__init__", "(", "\n", "self", ",", "\n", "rank", ",", "\n", "envs", ",", "\n", "samples_np", ",", "\n", "batch_T", ",", "\n", "TrajInfoCls", ",", "\n", "agent", "=", "None", ",", "# Present or not, depending on collector class.", "\n", "sync", "=", "None", ",", "\n", "step_buffer_np", "=", "None", ",", "\n", "global_B", "=", "1", ",", "\n", "env_ranks", "=", "None", ",", "\n", ")", ":", "\n", "        ", "save__init__args", "(", "locals", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.samplers.collectors.BaseCollector.start_envs": [[28, 31], ["None"], "methods", ["None"], ["", "def", "start_envs", "(", "self", ")", ":", "\n", "        ", "\"\"\"e.g. calls reset() on every env.\"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.samplers.collectors.BaseCollector.start_agent": [[32, 43], ["getattr", "collectors.BaseCollector.agent.collector_initialize", "collectors.BaseCollector.agent.reset", "collectors.BaseCollector.agent.sample_mode"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.agents.base.BaseAgent.collector_initialize", "home.repos.pwc.inspect_result.astooke_rlpyt.safe.safety_gym_env.SafetyGymEnvWrapper.reset", "home.repos.pwc.inspect_result.astooke_rlpyt.agents.dmc_sac_agent.SacAgent.sample_mode"], ["", "def", "start_agent", "(", "self", ")", ":", "\n", "        ", "\"\"\"In CPU-collectors, call ``agent.collector_initialize()`` e.g. to set up\n        vector epsilon-greedy, and reset the agent.\n        \"\"\"", "\n", "if", "getattr", "(", "self", ",", "\"agent\"", ",", "None", ")", "is", "not", "None", ":", "# Not in GPU collectors.", "\n", "            ", "self", ".", "agent", ".", "collector_initialize", "(", "\n", "global_B", "=", "self", ".", "global_B", ",", "# Args used e.g. for vector epsilon greedy.", "\n", "env_ranks", "=", "self", ".", "env_ranks", ",", "\n", ")", "\n", "self", ".", "agent", ".", "reset", "(", ")", "\n", "self", ".", "agent", ".", "sample_mode", "(", "itr", "=", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.samplers.collectors.BaseCollector.collect_batch": [[44, 47], ["None"], "methods", ["None"], ["", "", "def", "collect_batch", "(", "self", ",", "agent_inputs", ",", "traj_infos", ")", ":", "\n", "        ", "\"\"\"Main data collection loop.\"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.samplers.collectors.BaseCollector.reset_if_needed": [[48, 51], ["None"], "methods", ["None"], ["", "def", "reset_if_needed", "(", "self", ",", "agent_inputs", ")", ":", "\n", "        ", "\"\"\"Reset agent and or env as needed, if doing between batches.\"\"\"", "\n", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.samplers.collectors.BaseEvalCollector.__init__": [[56, 68], ["rlpyt.utils.quick_args.save__init__args", "locals"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.utils.quick_args.save__init__args"], ["def", "__init__", "(", "\n", "self", ",", "\n", "rank", ",", "\n", "envs", ",", "\n", "TrajInfoCls", ",", "\n", "traj_infos_queue", ",", "\n", "max_T", ",", "\n", "agent", "=", "None", ",", "\n", "sync", "=", "None", ",", "\n", "step_buffer_np", "=", "None", ",", "\n", ")", ":", "\n", "        ", "save__init__args", "(", "locals", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.samplers.collectors.BaseEvalCollector.collect_evaluation": [[69, 73], ["None"], "methods", ["None"], ["", "def", "collect_evaluation", "(", "self", ")", ":", "\n", "        ", "\"\"\"Run agent evaluation in environment and return completed trajectory\n        infos.\"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.samplers.collectors.DecorrelatingStartCollector.start_envs": [[80, 120], ["list", "rlpyt.utils.buffer.buffer_from_example", "enumerate", "numpy.stack", "numpy.zeros", "collectors.DecorrelatingStartCollector.TrajInfoCls", "list.append", "len", "len", "rlpyt.utils.logging.logger.log", "enumerate", "hasattr", "rlpyt.agents.base.AgentInputs", "range", "env.reset", "env.action_space.null_value", "range", "len", "int", "env.action_space.sample", "env.step", "traj_infos[].step", "getattr", "env.reset", "collectors.DecorrelatingStartCollector.TrajInfoCls", "env.action_space.null_value", "numpy.random.rand"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.utils.buffer.buffer_from_example", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.misc.zeros", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.console.log", "home.repos.pwc.inspect_result.astooke_rlpyt.safe.safety_gym_env.SafetyGymEnvWrapper.reset", "home.repos.pwc.inspect_result.astooke_rlpyt.spaces.gym_wrapper.GymSpaceWrapper.null_value", "home.repos.pwc.inspect_result.astooke_rlpyt.spaces.gym_wrapper.GymSpaceWrapper.sample", "home.repos.pwc.inspect_result.astooke_rlpyt.safe.safety_gym_env.SafetyGymTrajInfo.step", "home.repos.pwc.inspect_result.astooke_rlpyt.safe.safety_gym_env.SafetyGymTrajInfo.step", "home.repos.pwc.inspect_result.astooke_rlpyt.safe.safety_gym_env.SafetyGymEnvWrapper.reset", "home.repos.pwc.inspect_result.astooke_rlpyt.spaces.gym_wrapper.GymSpaceWrapper.null_value"], ["def", "start_envs", "(", "self", ",", "max_decorrelation_steps", "=", "0", ")", ":", "\n", "        ", "\"\"\"Calls ``reset()`` on every environment instance, then steps each\n        one through a random number of random actions, and returns the\n        resulting agent_inputs buffer (`observation`, `prev_action`,\n        `prev_reward`).\"\"\"", "\n", "traj_infos", "=", "[", "self", ".", "TrajInfoCls", "(", ")", "for", "_", "in", "range", "(", "len", "(", "self", ".", "envs", ")", ")", "]", "\n", "observations", "=", "list", "(", ")", "\n", "for", "env", "in", "self", ".", "envs", ":", "\n", "            ", "observations", ".", "append", "(", "env", ".", "reset", "(", ")", ")", "\n", "", "observation", "=", "buffer_from_example", "(", "observations", "[", "0", "]", ",", "len", "(", "self", ".", "envs", ")", ")", "\n", "for", "b", ",", "obs", "in", "enumerate", "(", "observations", ")", ":", "\n", "            ", "observation", "[", "b", "]", "=", "obs", "# numpy array or namedarraytuple", "\n", "", "prev_action", "=", "np", ".", "stack", "(", "[", "env", ".", "action_space", ".", "null_value", "(", ")", "\n", "for", "env", "in", "self", ".", "envs", "]", ")", "\n", "prev_reward", "=", "np", ".", "zeros", "(", "len", "(", "self", ".", "envs", ")", ",", "dtype", "=", "\"float32\"", ")", "\n", "if", "self", ".", "rank", "==", "0", ":", "\n", "            ", "logger", ".", "log", "(", "\"Sampler decorrelating envs, max steps: \"", "\n", "f\"{max_decorrelation_steps}\"", ")", "\n", "", "if", "max_decorrelation_steps", "!=", "0", ":", "\n", "            ", "for", "b", ",", "env", "in", "enumerate", "(", "self", ".", "envs", ")", ":", "\n", "                ", "n_steps", "=", "1", "+", "int", "(", "np", ".", "random", ".", "rand", "(", ")", "*", "max_decorrelation_steps", ")", "\n", "for", "_", "in", "range", "(", "n_steps", ")", ":", "\n", "                    ", "a", "=", "env", ".", "action_space", ".", "sample", "(", ")", "\n", "o", ",", "r", ",", "d", ",", "info", "=", "env", ".", "step", "(", "a", ")", "\n", "traj_infos", "[", "b", "]", ".", "step", "(", "o", ",", "a", ",", "r", ",", "d", ",", "None", ",", "info", ")", "\n", "if", "getattr", "(", "info", ",", "\"traj_done\"", ",", "d", ")", ":", "\n", "                        ", "o", "=", "env", ".", "reset", "(", ")", "\n", "traj_infos", "[", "b", "]", "=", "self", ".", "TrajInfoCls", "(", ")", "\n", "", "if", "d", ":", "\n", "                        ", "a", "=", "env", ".", "action_space", ".", "null_value", "(", ")", "\n", "r", "=", "0", "\n", "", "", "observation", "[", "b", "]", "=", "o", "\n", "prev_action", "[", "b", "]", "=", "a", "\n", "prev_reward", "[", "b", "]", "=", "r", "\n", "# For action-server samplers.", "\n", "", "", "if", "hasattr", "(", "self", ",", "\"step_buffer_np\"", ")", "and", "self", ".", "step_buffer_np", "is", "not", "None", ":", "\n", "            ", "self", ".", "step_buffer_np", ".", "observation", "[", ":", "]", "=", "observation", "\n", "self", ".", "step_buffer_np", ".", "action", "[", ":", "]", "=", "prev_action", "\n", "self", ".", "step_buffer_np", ".", "reward", "[", ":", "]", "=", "prev_reward", "\n", "", "return", "AgentInputs", "(", "observation", ",", "prev_action", ",", "prev_reward", ")", ",", "traj_infos", "\n", "", "", ""]], "home.repos.pwc.inspect_result.astooke_rlpyt.samplers.collections.BatchSpec.size": [[24, 27], ["None"], "methods", ["None"], []], "home.repos.pwc.inspect_result.astooke_rlpyt.samplers.collections.TrajInfo.__init__": [[40, 47], ["rlpyt.utils.collections.AttrDict.__init__"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.spaces.gym_wrapper.GymSpaceWrapper.__init__"], ["\n", "nt_typename", "=", "typename", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.samplers.collections.TrajInfo.step": [[48, 54], ["None"], "methods", ["None"], ["if", "classname_suffix", ":", "\n", "        ", "nt_typename", "+=", "\"_nt\"", "# Helpful to identify which style of tuple.", "\n", "typename", "+=", "\"_nat\"", "\n", "\n", "", "try", ":", "# For pickling, get location where this function was called.", "\n", "# NOTE: (pickling might not work for nested class definition.)", "\n", "        ", "module", "=", "sys", ".", "_getframe", "(", "1", ")", ".", "f_globals", ".", "get", "(", "'__name__'", ",", "'__main__'", ")", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.samplers.collections.TrajInfo.terminate": [[55, 57], ["None"], "methods", ["None"], ["", "except", "(", "AttributeError", ",", "ValueError", ")", ":", "\n", "        ", "module", "=", "None", "\n", "", "NtCls", "=", "namedtuple", "(", "nt_typename", ",", "field_names", ",", "module", "=", "module", ")", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.parallel.base.ParallelSamplerBase.initialize": [[28, 100], ["base.ParallelSamplerBase._get_n_envs_list", "len", "list", "base.ParallelSamplerBase.EnvCls", "base.ParallelSamplerBase._agent_init", "base.ParallelSamplerBase._build_buffers", "base.ParallelSamplerBase.close", "base.ParallelSamplerBase._build_parallel_ctrl", "base.ParallelSamplerBase._assemble_common_kwargs", "base.ParallelSamplerBase._assemble_workers_kwargs", "base.ParallelSamplerBase.ctrl.barrier_out.wait", "range", "max", "rlpyt.utils.logging.logger.log", "int", "traj_info_kwargs.items", "multiprocessing.Process", "w.start", "setattr", "dict"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.async_.alternating_sampler.AsyncAlternatingSamplerBase._get_n_envs_list", "home.repos.pwc.inspect_result.astooke_rlpyt.async_.base.AsyncParallelSamplerMixin._agent_init", "home.repos.pwc.inspect_result.astooke_rlpyt.async_.base.AsyncParallelSamplerMixin._build_buffers", "home.repos.pwc.inspect_result.astooke_rlpyt.envs.dmlab.DmlabEnv.close", "home.repos.pwc.inspect_result.astooke_rlpyt.async_.gpu_sampler.AsyncGpuSamplerBase._build_parallel_ctrl", "home.repos.pwc.inspect_result.astooke_rlpyt.gpu.sampler.GpuSamplerBase._assemble_common_kwargs", "home.repos.pwc.inspect_result.astooke_rlpyt.async_.gpu_sampler.AsyncGpuSamplerBase._assemble_workers_kwargs", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.console.log", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.collections.NamedArrayTuple.items"], ["raise", "NotImplementedError", "\n", "\n", "", "def", "async_initialize", "(", "self", ",", "agent", ",", "sampler_n_itr", ",", "batch_spec", ",", "mid_batch_reset", ",", "\n", "examples", ",", "world_size", "=", "1", ")", ":", "\n", "        ", "\"\"\"Called instead of ``initialize()`` in async runner (not needed unless\n        using async runner). Should return async replay_buffer using shared\n        memory.\"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n", "", "def", "optim_initialize", "(", "self", ",", "rank", "=", "0", ")", ":", "\n", "        ", "\"\"\"Called in async runner which requires two stages of initialization;\n        might also be used in ``initialize()`` to avoid redundant code.\"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n", "", "def", "optimize_agent", "(", "self", ",", "itr", ",", "samples", "=", "None", ",", "sampler_itr", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Train the agent for some number of parameter updates, e.g. either\n        using new samples or a replay buffer.\n\n        Typically called in the runner's training loop.\n\n        Args:\n            itr (int): Iteration of the training loop.\n            samples: New samples from the sampler (for ``None`` case, see async runner).\n            sampler_itr:  For case other than ``None``, see async runner.\n        \"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n", "", "def", "optim_state_dict", "(", "self", ")", ":", "\n", "        ", "\"\"\"Return the optimizer state dict (e.g. Adam); overwrite if using\n        multiple optimizers.\"\"\"", "\n", "return", "self", ".", "optimizer", ".", "state_dict", "(", ")", "\n", "\n", "", "def", "load_optim_state_dict", "(", "self", ",", "state_dict", ")", ":", "\n", "        ", "\"\"\"Load an optimizer state dict; should expect the format returned\n        from ``optim_state_dict().``\"\"\"", "\n", "self", ".", "optimizer", ".", "load_state_dict", "(", "state_dict", ")", "\n", "\n", "", "@", "property", "\n", "def", "batch_size", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_batch_size", "# For logging at least.", "\n", "", "", ""]], "home.repos.pwc.inspect_result.astooke_rlpyt.parallel.base.ParallelSamplerBase.obtain_samples": [[101, 114], ["base.ParallelSamplerBase.ctrl.barrier_in.wait", "base.ParallelSamplerBase.ctrl.barrier_out.wait", "rlpyt.utils.synchronize.drain_queue"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.utils.synchronize.drain_queue"], []], "home.repos.pwc.inspect_result.astooke_rlpyt.parallel.base.ParallelSamplerBase.evaluate_agent": [[115, 146], ["base.ParallelSamplerBase.ctrl.barrier_in.wait", "list", "base.ParallelSamplerBase.ctrl.barrier_out.wait", "list.extend", "rlpyt.utils.synchronize.drain_queue", "time.sleep", "list.extend", "rlpyt.utils.synchronize.drain_queue", "len", "rlpyt.utils.logging.logger.log", "rlpyt.utils.logging.logger.log"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.utils.synchronize.drain_queue", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.synchronize.drain_queue", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.console.log", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.console.log"], []], "home.repos.pwc.inspect_result.astooke_rlpyt.parallel.base.ParallelSamplerBase.shutdown": [[147, 152], ["base.ParallelSamplerBase.ctrl.barrier_in.wait", "w.join"], "methods", ["None"], []], "home.repos.pwc.inspect_result.astooke_rlpyt.parallel.base.ParallelSamplerBase._get_n_envs_list": [[157, 173], ["len", "rlpyt.utils.logging.logger.log", "rlpyt.utils.logging.logger.log", "range"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.logging.console.log", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.console.log"], []], "home.repos.pwc.inspect_result.astooke_rlpyt.parallel.base.ParallelSamplerBase._agent_init": [[174, 178], ["agent.initialize"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.safe.cppo_agent.CppoLstmAgent.initialize"], []], "home.repos.pwc.inspect_result.astooke_rlpyt.parallel.base.ParallelSamplerBase._build_buffers": [[179, 184], ["rlpyt.samplers.buffer.build_samples_buffer"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.samplers.buffer.build_samples_buffer"], []], "home.repos.pwc.inspect_result.astooke_rlpyt.parallel.base.ParallelSamplerBase._build_parallel_ctrl": [[185, 196], ["rlpyt.utils.collections.AttrDict", "multiprocessing.Queue", "multiprocessing.Queue", "rlpyt.utils.collections.AttrDict", "multiprocessing.RawValue", "multiprocessing.Barrier", "multiprocessing.Barrier", "multiprocessing.RawValue", "multiprocessing.RawValue", "multiprocessing.RawValue"], "methods", ["None"], []], "home.repos.pwc.inspect_result.astooke_rlpyt.parallel.base.ParallelSamplerBase._assemble_common_kwargs": [[197, 221], ["dict", "dict.update", "affinity.get", "dict"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.models.running_mean_std.RunningMeanStdModel.update", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.collections.NamedArrayTuple.get"], []], "home.repos.pwc.inspect_result.astooke_rlpyt.parallel.base.ParallelSamplerBase._assemble_workers_kwargs": [[222, 244], ["list", "range", "sum", "len", "slice", "list", "dict", "list.append", "range", "affinity.get"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.utils.collections.NamedArrayTuple.get"], []], "home.repos.pwc.inspect_result.astooke_rlpyt.parallel.worker.initialize_worker": [[11, 35], ["psutil.Process", "rlpyt.utils.logging.logger.log", "isinstance", "psutil.Process.cpu_affinity", "torch.set_num_threads", "rlpyt.utils.seed.set_seed", "time.sleep", "psutil.Process.cpu_affinity", "torch.get_num_threads"], "function", ["home.repos.pwc.inspect_result.astooke_rlpyt.logging.console.log", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.seed.set_seed"], ["def", "initialize_worker", "(", "rank", ",", "seed", "=", "None", ",", "cpu", "=", "None", ",", "torch_threads", "=", "None", ")", ":", "\n", "    ", "\"\"\"Assign CPU affinity, set random seed, set torch_threads if needed to\n    prevent MKL deadlock.\n    \"\"\"", "\n", "log_str", "=", "f\"Sampler rank {rank} initialized\"", "\n", "cpu", "=", "[", "cpu", "]", "if", "isinstance", "(", "cpu", ",", "int", ")", "else", "cpu", "\n", "p", "=", "psutil", ".", "Process", "(", ")", "\n", "try", ":", "\n", "        ", "if", "cpu", "is", "not", "None", ":", "\n", "            ", "p", ".", "cpu_affinity", "(", "cpu", ")", "\n", "", "cpu_affin", "=", "p", ".", "cpu_affinity", "(", ")", "\n", "", "except", "AttributeError", ":", "\n", "        ", "cpu_affin", "=", "\"UNAVAILABLE MacOS\"", "\n", "", "log_str", "+=", "f\", CPU affinity {cpu_affin}\"", "\n", "torch_threads", "=", "(", "1", "if", "torch_threads", "is", "None", "and", "cpu", "is", "not", "None", "else", "\n", "torch_threads", ")", "# Default to 1 to avoid possible MKL hang.", "\n", "if", "torch_threads", "is", "not", "None", ":", "\n", "        ", "torch", ".", "set_num_threads", "(", "torch_threads", ")", "\n", "", "log_str", "+=", "f\", Torch threads {torch.get_num_threads()}\"", "\n", "if", "seed", "is", "not", "None", ":", "\n", "        ", "set_seed", "(", "seed", ")", "\n", "time", ".", "sleep", "(", "0.3", ")", "# (so the printing from set_seed is not intermixed)", "\n", "log_str", "+=", "f\", Seed {seed}\"", "\n", "", "logger", ".", "log", "(", "log_str", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.parallel.worker.sampling_process": [[37, 102], ["worker.initialize_worker", "rlpyt.utils.seed.set_envs_seeds", "c.CollectorCls", "c.CollectorCls.start_envs", "c.CollectorCls.start_agent", "ctrl.barrier_out.wait", "rlpyt.utils.collections.AttrDict", "rlpyt.utils.collections.AttrDict", "c.EnvCls", "c.get", "rlpyt.utils.seed.set_envs_seeds", "c.eval_CollectorCls", "list", "c.CollectorCls.reset_if_needed", "ctrl.barrier_in.wait", "ctrl.barrier_out.wait", "env.close", "range", "c.get", "w.get", "w.get", "c.get", "w.get", "c.EnvCls", "c.eval_CollectorCls.collect_evaluation", "c.CollectorCls.collect_batch", "range", "c.get", "w.get", "w.get", "c.traj_infos_queue.put"], "function", ["home.repos.pwc.inspect_result.astooke_rlpyt.parallel.worker.initialize_worker", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.seed.set_envs_seeds", "home.repos.pwc.inspect_result.astooke_rlpyt.samplers.collectors.DecorrelatingStartCollector.start_envs", "home.repos.pwc.inspect_result.astooke_rlpyt.samplers.collectors.BaseCollector.start_agent", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.collections.NamedArrayTuple.get", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.seed.set_envs_seeds", "home.repos.pwc.inspect_result.astooke_rlpyt.gpu.collectors.GpuWaitResetCollector.reset_if_needed", "home.repos.pwc.inspect_result.astooke_rlpyt.envs.dmlab.DmlabEnv.close", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.collections.NamedArrayTuple.get", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.collections.NamedArrayTuple.get", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.collections.NamedArrayTuple.get", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.collections.NamedArrayTuple.get", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.collections.NamedArrayTuple.get", "home.repos.pwc.inspect_result.astooke_rlpyt.serial.collectors.SerialEvalCollector.collect_evaluation", "home.repos.pwc.inspect_result.astooke_rlpyt.async_.collectors.DoubleBufferCollectorMixin.collect_batch", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.collections.NamedArrayTuple.get", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.collections.NamedArrayTuple.get", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.collections.NamedArrayTuple.get"], ["", "def", "sampling_process", "(", "common_kwargs", ",", "worker_kwargs", ")", ":", "\n", "    ", "\"\"\"Target function used for forking parallel worker processes in the\n    samplers. After ``initialize_worker()``, it creates the specified number\n    of environment instances and gives them to the collector when\n    instantiating it.  It then calls collector startup methods for\n    environments and agent.  If applicable, instantiates evaluation\n    environment instances and evaluation collector.\n\n    Then enters infinite loop, waiting for signals from master to collect\n    training samples or else run evaluation, until signaled to exit.\n    \"\"\"", "\n", "c", ",", "w", "=", "AttrDict", "(", "**", "common_kwargs", ")", ",", "AttrDict", "(", "**", "worker_kwargs", ")", "\n", "initialize_worker", "(", "w", ".", "rank", ",", "w", ".", "seed", ",", "w", ".", "cpus", ",", "c", ".", "torch_threads", ")", "\n", "envs", "=", "[", "c", ".", "EnvCls", "(", "**", "c", ".", "env_kwargs", ")", "for", "_", "in", "range", "(", "w", ".", "n_envs", ")", "]", "\n", "set_envs_seeds", "(", "envs", ",", "w", ".", "seed", ")", "\n", "\n", "collector", "=", "c", ".", "CollectorCls", "(", "\n", "rank", "=", "w", ".", "rank", ",", "\n", "envs", "=", "envs", ",", "\n", "samples_np", "=", "w", ".", "samples_np", ",", "\n", "batch_T", "=", "c", ".", "batch_T", ",", "\n", "TrajInfoCls", "=", "c", ".", "TrajInfoCls", ",", "\n", "agent", "=", "c", ".", "get", "(", "\"agent\"", ",", "None", ")", ",", "# Optional depending on parallel setup.", "\n", "sync", "=", "w", ".", "get", "(", "\"sync\"", ",", "None", ")", ",", "\n", "step_buffer_np", "=", "w", ".", "get", "(", "\"step_buffer_np\"", ",", "None", ")", ",", "\n", "global_B", "=", "c", ".", "get", "(", "\"global_B\"", ",", "1", ")", ",", "\n", "env_ranks", "=", "w", ".", "get", "(", "\"env_ranks\"", ",", "None", ")", ",", "\n", ")", "\n", "agent_inputs", ",", "traj_infos", "=", "collector", ".", "start_envs", "(", "c", ".", "max_decorrelation_steps", ")", "\n", "collector", ".", "start_agent", "(", ")", "\n", "\n", "if", "c", ".", "get", "(", "\"eval_n_envs\"", ",", "0", ")", ">", "0", ":", "\n", "        ", "eval_envs", "=", "[", "c", ".", "EnvCls", "(", "**", "c", ".", "eval_env_kwargs", ")", "for", "_", "in", "range", "(", "c", ".", "eval_n_envs", ")", "]", "\n", "set_envs_seeds", "(", "eval_envs", ",", "w", ".", "seed", ")", "\n", "eval_collector", "=", "c", ".", "eval_CollectorCls", "(", "\n", "rank", "=", "w", ".", "rank", ",", "\n", "envs", "=", "eval_envs", ",", "\n", "TrajInfoCls", "=", "c", ".", "TrajInfoCls", ",", "\n", "traj_infos_queue", "=", "c", ".", "eval_traj_infos_queue", ",", "\n", "max_T", "=", "c", ".", "eval_max_T", ",", "\n", "agent", "=", "c", ".", "get", "(", "\"agent\"", ",", "None", ")", ",", "\n", "sync", "=", "w", ".", "get", "(", "\"sync\"", ",", "None", ")", ",", "\n", "step_buffer_np", "=", "w", ".", "get", "(", "\"eval_step_buffer_np\"", ",", "None", ")", ",", "\n", ")", "\n", "", "else", ":", "\n", "        ", "eval_envs", "=", "list", "(", ")", "\n", "\n", "", "ctrl", "=", "c", ".", "ctrl", "\n", "ctrl", ".", "barrier_out", ".", "wait", "(", ")", "\n", "while", "True", ":", "\n", "        ", "collector", ".", "reset_if_needed", "(", "agent_inputs", ")", "# Outside barrier?", "\n", "ctrl", ".", "barrier_in", ".", "wait", "(", ")", "\n", "if", "ctrl", ".", "quit", ".", "value", ":", "\n", "            ", "break", "\n", "", "if", "ctrl", ".", "do_eval", ".", "value", ":", "\n", "            ", "eval_collector", ".", "collect_evaluation", "(", "ctrl", ".", "itr", ".", "value", ")", "# Traj_infos to queue inside.", "\n", "", "else", ":", "\n", "            ", "agent_inputs", ",", "traj_infos", ",", "completed_infos", "=", "collector", ".", "collect_batch", "(", "\n", "agent_inputs", ",", "traj_infos", ",", "ctrl", ".", "itr", ".", "value", ")", "\n", "for", "info", "in", "completed_infos", ":", "\n", "                ", "c", ".", "traj_infos_queue", ".", "put", "(", "info", ")", "\n", "", "", "ctrl", ".", "barrier_out", ".", "wait", "(", ")", "\n", "\n", "", "for", "env", "in", "envs", "+", "eval_envs", ":", "\n", "        ", "env", ".", "close", "(", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.astooke_rlpyt.cpu.collectors.CpuResetCollector.collect_batch": [[25, 66], ["list", "rlpyt.utils.buffer.torchify_buffer", "collectors.CpuResetCollector.agent.sample_mode", "range", "collectors.CpuResetCollector.agent.step", "rlpyt.utils.buffer.numpify_buffer", "enumerate", "collectors.CpuResetCollector.agent.value", "rlpyt.agents.base.AgentInputs", "env.step", "traj_infos[].step", "getattr", "list.append", "collectors.CpuResetCollector.TrajInfoCls", "env.reset", "collectors.CpuResetCollector.agent.reset_one", "traj_infos[].terminate"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.utils.buffer.torchify_buffer", "home.repos.pwc.inspect_result.astooke_rlpyt.agents.dmc_sac_agent.SacAgent.sample_mode", "home.repos.pwc.inspect_result.astooke_rlpyt.safe.safety_gym_env.SafetyGymTrajInfo.step", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.buffer.numpify_buffer", "home.repos.pwc.inspect_result.astooke_rlpyt.safe.cppo_agent.CppoLstmAgent.value", "home.repos.pwc.inspect_result.astooke_rlpyt.safe.safety_gym_env.SafetyGymTrajInfo.step", "home.repos.pwc.inspect_result.astooke_rlpyt.safe.safety_gym_env.SafetyGymTrajInfo.step", "home.repos.pwc.inspect_result.astooke_rlpyt.safe.safety_gym_env.SafetyGymEnvWrapper.reset", "home.repos.pwc.inspect_result.astooke_rlpyt.agents.base.RecurrentAgentMixin.reset_one", "home.repos.pwc.inspect_result.astooke_rlpyt.safe.safety_gym_env.SafetyGymTrajInfo.terminate"], [")", ":", "\n", "        ", "save__init__args", "(", "locals", "(", ")", ")", "\n", "\n", "", "def", "start_envs", "(", "self", ")", ":", "\n", "        ", "\"\"\"e.g. calls reset() on every env.\"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n", "", "def", "start_agent", "(", "self", ")", ":", "\n", "        ", "\"\"\"In CPU-collectors, call ``agent.collector_initialize()`` e.g. to set up\n        vector epsilon-greedy, and reset the agent.\n        \"\"\"", "\n", "if", "getattr", "(", "self", ",", "\"agent\"", ",", "None", ")", "is", "not", "None", ":", "# Not in GPU collectors.", "\n", "            ", "self", ".", "agent", ".", "collector_initialize", "(", "\n", "global_B", "=", "self", ".", "global_B", ",", "# Args used e.g. for vector epsilon greedy.", "\n", "env_ranks", "=", "self", ".", "env_ranks", ",", "\n", ")", "\n", "self", ".", "agent", ".", "reset", "(", ")", "\n", "self", ".", "agent", ".", "sample_mode", "(", "itr", "=", "0", ")", "\n", "\n", "", "", "def", "collect_batch", "(", "self", ",", "agent_inputs", ",", "traj_infos", ")", ":", "\n", "        ", "\"\"\"Main data collection loop.\"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n", "", "def", "reset_if_needed", "(", "self", ",", "agent_inputs", ")", ":", "\n", "        ", "\"\"\"Reset agent and or env as needed, if doing between batches.\"\"\"", "\n", "pass", "\n", "\n", "\n", "", "", "class", "BaseEvalCollector", ":", "\n", "    ", "\"\"\"Collectors for offline agent evalution; not to record intermediate samples.\"\"\"", "\n", "\n", "def", "__init__", "(", "\n", "self", ",", "\n", "rank", ",", "\n", "envs", ",", "\n", "TrajInfoCls", ",", "\n", "traj_infos_queue", ",", "\n", "max_T", ",", "\n", "agent", "=", "None", ",", "\n", "sync", "=", "None", ",", "\n", "step_buffer_np", "=", "None", ",", "\n", ")", ":", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.cpu.collectors.CpuWaitResetCollector.__init__": [[88, 94], ["rlpyt.samplers.collectors.DecorrelatingStartCollector.__init__", "numpy.zeros", "numpy.zeros", "rlpyt.utils.buffer.buffer_method", "len", "len", "len"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.spaces.gym_wrapper.GymSpaceWrapper.__init__", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.misc.zeros", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.misc.zeros", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.buffer.buffer_method"], ["            ", "observations", ".", "append", "(", "env", ".", "reset", "(", ")", ")", "\n", "", "observation", "=", "buffer_from_example", "(", "observations", "[", "0", "]", ",", "len", "(", "self", ".", "envs", ")", ")", "\n", "for", "b", ",", "obs", "in", "enumerate", "(", "observations", ")", ":", "\n", "            ", "observation", "[", "b", "]", "=", "obs", "# numpy array or namedarraytuple", "\n", "", "prev_action", "=", "np", ".", "stack", "(", "[", "env", ".", "action_space", ".", "null_value", "(", ")", "\n", "for", "env", "in", "self", ".", "envs", "]", ")", "\n", "prev_reward", "=", "np", ".", "zeros", "(", "len", "(", "self", ".", "envs", ")", ",", "dtype", "=", "\"float32\"", ")", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.cpu.collectors.CpuWaitResetCollector.collect_batch": [[95, 148], ["list", "rlpyt.utils.buffer.torchify_buffer", "collectors.CpuWaitResetCollector.agent.sample_mode", "range", "numpy.where", "collectors.CpuWaitResetCollector.agent.step", "rlpyt.utils.buffer.numpify_buffer", "enumerate", "collectors.CpuWaitResetCollector.agent.value", "rlpyt.agents.base.AgentInputs", "env.step", "traj_infos[].step", "getattr", "list.append", "collectors.CpuWaitResetCollector.TrajInfoCls", "traj_infos[].terminate"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.utils.buffer.torchify_buffer", "home.repos.pwc.inspect_result.astooke_rlpyt.agents.dmc_sac_agent.SacAgent.sample_mode", "home.repos.pwc.inspect_result.astooke_rlpyt.safe.safety_gym_env.SafetyGymTrajInfo.step", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.buffer.numpify_buffer", "home.repos.pwc.inspect_result.astooke_rlpyt.safe.cppo_agent.CppoLstmAgent.value", "home.repos.pwc.inspect_result.astooke_rlpyt.safe.safety_gym_env.SafetyGymTrajInfo.step", "home.repos.pwc.inspect_result.astooke_rlpyt.safe.safety_gym_env.SafetyGymTrajInfo.step", "home.repos.pwc.inspect_result.astooke_rlpyt.safe.safety_gym_env.SafetyGymTrajInfo.terminate"], ["if", "self", ".", "rank", "==", "0", ":", "\n", "            ", "logger", ".", "log", "(", "\"Sampler decorrelating envs, max steps: \"", "\n", "f\"{max_decorrelation_steps}\"", ")", "\n", "", "if", "max_decorrelation_steps", "!=", "0", ":", "\n", "            ", "for", "b", ",", "env", "in", "enumerate", "(", "self", ".", "envs", ")", ":", "\n", "                ", "n_steps", "=", "1", "+", "int", "(", "np", ".", "random", ".", "rand", "(", ")", "*", "max_decorrelation_steps", ")", "\n", "for", "_", "in", "range", "(", "n_steps", ")", ":", "\n", "                    ", "a", "=", "env", ".", "action_space", ".", "sample", "(", ")", "\n", "o", ",", "r", ",", "d", ",", "info", "=", "env", ".", "step", "(", "a", ")", "\n", "traj_infos", "[", "b", "]", ".", "step", "(", "o", ",", "a", ",", "r", ",", "d", ",", "None", ",", "info", ")", "\n", "if", "getattr", "(", "info", ",", "\"traj_done\"", ",", "d", ")", ":", "\n", "                        ", "o", "=", "env", ".", "reset", "(", ")", "\n", "traj_infos", "[", "b", "]", "=", "self", ".", "TrajInfoCls", "(", ")", "\n", "", "if", "d", ":", "\n", "                        ", "a", "=", "env", ".", "action_space", ".", "null_value", "(", ")", "\n", "r", "=", "0", "\n", "", "", "observation", "[", "b", "]", "=", "o", "\n", "prev_action", "[", "b", "]", "=", "a", "\n", "prev_reward", "[", "b", "]", "=", "r", "\n", "# For action-server samplers.", "\n", "", "", "if", "hasattr", "(", "self", ",", "\"step_buffer_np\"", ")", "and", "self", ".", "step_buffer_np", "is", "not", "None", ":", "\n", "            ", "self", ".", "step_buffer_np", ".", "observation", "[", ":", "]", "=", "observation", "\n", "self", ".", "step_buffer_np", ".", "action", "[", ":", "]", "=", "prev_action", "\n", "self", ".", "step_buffer_np", ".", "reward", "[", ":", "]", "=", "prev_reward", "\n", "", "return", "AgentInputs", "(", "observation", ",", "prev_action", ",", "prev_reward", ")", ",", "traj_infos", "\n", "", "", ""]], "home.repos.pwc.inspect_result.astooke_rlpyt.cpu.collectors.CpuWaitResetCollector.reset_if_needed": [[149, 155], ["numpy.where", "collectors.CpuWaitResetCollector.envs[].reset", "collectors.CpuWaitResetCollector.agent.reset_one"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.safe.safety_gym_env.SafetyGymEnvWrapper.reset", "home.repos.pwc.inspect_result.astooke_rlpyt.agents.base.RecurrentAgentMixin.reset_one"], []], "home.repos.pwc.inspect_result.astooke_rlpyt.cpu.collectors.CpuEvalCollector.collect_evaluation": [[165, 199], ["list", "rlpyt.utils.buffer.buffer_from_example", "enumerate", "rlpyt.utils.buffer.buffer_from_example", "numpy.zeros", "rlpyt.utils.buffer.torchify_buffer", "collectors.CpuEvalCollector.agent.reset", "collectors.CpuEvalCollector.agent.eval_mode", "range", "collectors.CpuEvalCollector.traj_infos_queue.put", "collectors.CpuEvalCollector.TrajInfoCls", "list.append", "len", "collectors.CpuEvalCollector.envs[].action_space.null_value", "len", "len", "collectors.CpuEvalCollector.agent.step", "rlpyt.utils.buffer.numpify_buffer", "enumerate", "range", "env.reset", "env.step", "traj_infos[].step", "getattr", "len", "collectors.CpuEvalCollector.traj_infos_queue.put", "collectors.CpuEvalCollector.TrajInfoCls", "env.reset", "collectors.CpuEvalCollector.agent.reset_one", "traj_infos[].terminate"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.utils.buffer.buffer_from_example", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.buffer.buffer_from_example", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.misc.zeros", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.buffer.torchify_buffer", "home.repos.pwc.inspect_result.astooke_rlpyt.safe.safety_gym_env.SafetyGymEnvWrapper.reset", "home.repos.pwc.inspect_result.astooke_rlpyt.agents.dmc_sac_agent.SacAgent.eval_mode", "home.repos.pwc.inspect_result.astooke_rlpyt.spaces.gym_wrapper.GymSpaceWrapper.null_value", "home.repos.pwc.inspect_result.astooke_rlpyt.safe.safety_gym_env.SafetyGymTrajInfo.step", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.buffer.numpify_buffer", "home.repos.pwc.inspect_result.astooke_rlpyt.safe.safety_gym_env.SafetyGymEnvWrapper.reset", "home.repos.pwc.inspect_result.astooke_rlpyt.safe.safety_gym_env.SafetyGymTrajInfo.step", "home.repos.pwc.inspect_result.astooke_rlpyt.safe.safety_gym_env.SafetyGymTrajInfo.step", "home.repos.pwc.inspect_result.astooke_rlpyt.safe.safety_gym_env.SafetyGymEnvWrapper.reset", "home.repos.pwc.inspect_result.astooke_rlpyt.agents.base.RecurrentAgentMixin.reset_one", "home.repos.pwc.inspect_result.astooke_rlpyt.safe.safety_gym_env.SafetyGymTrajInfo.terminate"], []], "home.repos.pwc.inspect_result.astooke_rlpyt.cpu.sampler.CpuSampler.__init__": [[16, 21], ["rlpyt.samplers.parallel.base.ParallelSamplerBase.__init__"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.spaces.gym_wrapper.GymSpaceWrapper.__init__"], ["def", "__init__", "(", "self", ",", "*", "args", ",", "CollectorCls", "=", "CpuResetCollector", ",", "\n", "eval_CollectorCls", "=", "CpuEvalCollector", ",", "**", "kwargs", ")", ":", "\n", "# e.g. or use CpuWaitResetCollector, etc...", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "*", "args", ",", "CollectorCls", "=", "CollectorCls", ",", "\n", "eval_CollectorCls", "=", "eval_CollectorCls", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.cpu.sampler.CpuSampler.obtain_samples": [[22, 30], ["sampler.CpuSampler.agent.sync_shared_memory", "super().obtain_samples"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.agents.base.BaseAgent.sync_shared_memory", "home.repos.pwc.inspect_result.astooke_rlpyt.async_.serial_sampler.AsyncSerialSampler.obtain_samples"], ["", "def", "obtain_samples", "(", "self", ",", "itr", ")", ":", "\n", "        ", "\"\"\"First, have the agent sync shared memory; in case training uses a\n        GPU, the agent needs to copy its (new) GPU model parameters to the\n        shared-memory CPU model which all the workers use.  Then call super\n        class's method.\n        \"\"\"", "\n", "self", ".", "agent", ".", "sync_shared_memory", "(", ")", "# New weights in workers, if needed.", "\n", "return", "super", "(", ")", ".", "obtain_samples", "(", "itr", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.cpu.sampler.CpuSampler.evaluate_agent": [[31, 35], ["sampler.CpuSampler.agent.sync_shared_memory", "super().evaluate_agent"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.agents.base.BaseAgent.sync_shared_memory", "home.repos.pwc.inspect_result.astooke_rlpyt.runners.minibatch_rl.MinibatchRlEval.evaluate_agent"], ["", "def", "evaluate_agent", "(", "self", ",", "itr", ")", ":", "\n", "        ", "\"\"\"Like in ``obtain_samples()``, first sync agent shared memory.\"\"\"", "\n", "self", ".", "agent", ".", "sync_shared_memory", "(", ")", "\n", "return", "super", "(", ")", ".", "evaluate_agent", "(", "itr", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.astooke_rlpyt.gpu.action_server.ActionServer.serve_actions": [[17, 75], ["range", "numpy.any", "action_server.ActionServer.agent.step", "b.acquire", "action_server.ActionServer.agent.value", "b.acquire", "numpy.any", "w.release", "b.acquire", "numpy.where", "action_server.ActionServer.agent.reset_one", "w.acquire", "numpy.where", "action_server.ActionServer.agent.reset_one"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.safe.safety_gym_env.SafetyGymTrajInfo.step", "home.repos.pwc.inspect_result.astooke_rlpyt.safe.cppo_agent.CppoLstmAgent.value", "home.repos.pwc.inspect_result.astooke_rlpyt.agents.base.RecurrentAgentMixin.reset_one", "home.repos.pwc.inspect_result.astooke_rlpyt.agents.base.RecurrentAgentMixin.reset_one"], ["def", "serve_actions", "(", "self", ",", "itr", ")", ":", "\n", "        ", "\"\"\"Called in master process during ``obtain_samples()``.\n\n        Performs agent action- selection loop in concert with workers\n        executing environment steps.  Uses shared memory buffers to\n        communicate agent/environment data at each time step.  Uses semaphores\n        for synchronization: one per worker to acquire when they finish\n        writing the next step of observations, one per worker to release when\n        master has written the next actions.  Resets the agent one B-index at a time when the\n        corresponding environment resets (i.e. agent's recurrent state, with\n        leading dimension ``batch_B``).\n\n        Also communicates ``agent_info`` to workers, which are responsible\n        for recording all data into the batch buffer.\n\n        If requested, collects additional agent value estimation of final\n        observation for bootstrapping (the one thing written to the batch\n        buffer here).\n\n\n        .. warning::\n            If trying to modify, must be careful to keep correct logic of the semaphores,\n            to make sure they drain properly.  If a semaphore ends up with an extra release,\n            synchronization can be lost silently, leading to wrong and confusing results.\n        \"\"\"", "\n", "obs_ready", ",", "act_ready", "=", "self", ".", "sync", ".", "obs_ready", ",", "self", ".", "sync", ".", "act_ready", "\n", "step_np", ",", "agent_inputs", "=", "self", ".", "step_buffer_np", ",", "self", ".", "agent_inputs", "\n", "\n", "for", "t", "in", "range", "(", "self", ".", "batch_spec", ".", "T", ")", ":", "\n", "            ", "for", "b", "in", "obs_ready", ":", "\n", "                ", "b", ".", "acquire", "(", ")", "# Workers written obs and rew, first prev_act.", "\n", "# assert not b.acquire(block=False)  # Debug check.", "\n", "", "if", "self", ".", "mid_batch_reset", "and", "np", ".", "any", "(", "step_np", ".", "done", ")", ":", "\n", "                ", "for", "b_reset", "in", "np", ".", "where", "(", "step_np", ".", "done", ")", "[", "0", "]", ":", "\n", "                    ", "step_np", ".", "action", "[", "b_reset", "]", "=", "0", "# Null prev_action into agent.", "\n", "step_np", ".", "reward", "[", "b_reset", "]", "=", "0", "# Null prev_reward into agent.", "\n", "self", ".", "agent", ".", "reset_one", "(", "idx", "=", "b_reset", ")", "\n", "", "", "action", ",", "agent_info", "=", "self", ".", "agent", ".", "step", "(", "*", "agent_inputs", ")", "\n", "step_np", ".", "action", "[", ":", "]", "=", "action", "# Worker applies to env.", "\n", "step_np", ".", "agent_info", "[", ":", "]", "=", "agent_info", "# Worker sends to traj_info.", "\n", "for", "w", "in", "act_ready", ":", "\n", "# assert not w.acquire(block=False)  # Debug check.", "\n", "                ", "w", ".", "release", "(", ")", "# Signal to worker.", "\n", "\n", "", "", "for", "b", "in", "obs_ready", ":", "\n", "            ", "b", ".", "acquire", "(", ")", "\n", "assert", "not", "b", ".", "acquire", "(", "block", "=", "False", ")", "# Debug check.", "\n", "", "if", "\"bootstrap_value\"", "in", "self", ".", "samples_np", ".", "agent", ":", "\n", "            ", "self", ".", "samples_np", ".", "agent", ".", "bootstrap_value", "[", ":", "]", "=", "self", ".", "agent", ".", "value", "(", "\n", "*", "agent_inputs", ")", "\n", "", "if", "np", ".", "any", "(", "step_np", ".", "done", ")", ":", "# Reset at end of batch; ready for next.", "\n", "            ", "for", "b_reset", "in", "np", ".", "where", "(", "step_np", ".", "done", ")", "[", "0", "]", ":", "\n", "                ", "step_np", ".", "action", "[", "b_reset", "]", "=", "0", "# Null prev_action into agent.", "\n", "step_np", ".", "reward", "[", "b_reset", "]", "=", "0", "# Null prev_reward into agent.", "\n", "self", ".", "agent", ".", "reset_one", "(", "idx", "=", "b_reset", ")", "\n", "# step_np.done[:] = False  # Worker resets at start of next.", "\n", "", "", "for", "w", "in", "act_ready", ":", "\n", "            ", "assert", "not", "w", ".", "acquire", "(", "block", "=", "False", ")", "# Debug check.", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.gpu.action_server.ActionServer.serve_actions_evaluation": [[76, 121], ["list", "action_server.ActionServer.agent.reset", "rlpyt.agents.base.AgentInputs", "range", "action_server.ActionServer.agent.step", "rlpyt.utils.logging.logger.log", "b.acquire", "list.extend", "b.acquire", "numpy.where", "action_server.ActionServer.agent.reset_one", "w.release", "rlpyt.utils.logging.logger.log", "b.acquire", "w.acquire", "rlpyt.utils.synchronize.drain_queue", "len"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.safe.safety_gym_env.SafetyGymEnvWrapper.reset", "home.repos.pwc.inspect_result.astooke_rlpyt.safe.safety_gym_env.SafetyGymTrajInfo.step", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.console.log", "home.repos.pwc.inspect_result.astooke_rlpyt.agents.base.RecurrentAgentMixin.reset_one", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.console.log", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.synchronize.drain_queue"], ["", "", "def", "serve_actions_evaluation", "(", "self", ",", "itr", ")", ":", "\n", "        ", "\"\"\"Similar to ``serve_actions()``.  If a maximum number of eval trajectories\n        was specified, keeps track of the number completed and terminates evaluation\n        if the max is reached.  Returns a list of completed trajectory-info objects.\n        \"\"\"", "\n", "obs_ready", ",", "act_ready", "=", "self", ".", "sync", ".", "obs_ready", ",", "self", ".", "sync", ".", "act_ready", "\n", "step_np", ",", "step_pyt", "=", "self", ".", "eval_step_buffer_np", ",", "self", ".", "eval_step_buffer_pyt", "\n", "traj_infos", "=", "list", "(", ")", "\n", "self", ".", "agent", ".", "reset", "(", ")", "\n", "agent_inputs", "=", "AgentInputs", "(", "step_pyt", ".", "observation", ",", "step_pyt", ".", "action", ",", "\n", "step_pyt", ".", "reward", ")", "# Fixed buffer objects.", "\n", "\n", "for", "t", "in", "range", "(", "self", ".", "eval_max_T", ")", ":", "\n", "            ", "if", "t", "%", "EVAL_TRAJ_CHECK", "==", "0", ":", "# (While workers stepping.)", "\n", "                ", "traj_infos", ".", "extend", "(", "drain_queue", "(", "self", ".", "eval_traj_infos_queue", ",", "\n", "guard_sentinel", "=", "True", ")", ")", "\n", "", "for", "b", "in", "obs_ready", ":", "\n", "                ", "b", ".", "acquire", "(", ")", "\n", "# assert not b.acquire(block=False)  # Debug check.", "\n", "", "for", "b_reset", "in", "np", ".", "where", "(", "step_np", ".", "done", ")", "[", "0", "]", ":", "\n", "                ", "step_np", ".", "action", "[", "b_reset", "]", "=", "0", "# Null prev_action.", "\n", "step_np", ".", "reward", "[", "b_reset", "]", "=", "0", "# Null prev_reward.", "\n", "self", ".", "agent", ".", "reset_one", "(", "idx", "=", "b_reset", ")", "\n", "", "action", ",", "agent_info", "=", "self", ".", "agent", ".", "step", "(", "*", "agent_inputs", ")", "\n", "step_np", ".", "action", "[", ":", "]", "=", "action", "\n", "step_np", ".", "agent_info", "[", ":", "]", "=", "agent_info", "\n", "if", "self", ".", "eval_max_trajectories", "is", "not", "None", "and", "t", "%", "EVAL_TRAJ_CHECK", "==", "0", ":", "\n", "                ", "self", ".", "sync", ".", "stop_eval", ".", "value", "=", "len", "(", "traj_infos", ")", ">=", "self", ".", "eval_max_trajectories", "\n", "", "for", "w", "in", "act_ready", ":", "\n", "# assert not w.acquire(block=False)  # Debug check.", "\n", "                ", "w", ".", "release", "(", ")", "\n", "", "if", "self", ".", "sync", ".", "stop_eval", ".", "value", ":", "\n", "                ", "logger", ".", "log", "(", "\"Evaluation reach max num trajectories \"", "\n", "f\"({self.eval_max_trajectories}).\"", ")", "\n", "break", "\n", "", "", "if", "t", "==", "self", ".", "eval_max_T", "-", "1", "and", "self", ".", "eval_max_trajectories", "is", "not", "None", ":", "\n", "            ", "logger", ".", "log", "(", "\"Evaluation reached max num time steps \"", "\n", "f\"({self.eval_max_T}).\"", ")", "\n", "", "for", "b", "in", "obs_ready", ":", "\n", "            ", "b", ".", "acquire", "(", ")", "# Workers always do extra release; drain it.", "\n", "assert", "not", "b", ".", "acquire", "(", "block", "=", "False", ")", "# Debug check.", "\n", "", "for", "w", "in", "act_ready", ":", "\n", "            ", "assert", "not", "w", ".", "acquire", "(", "block", "=", "False", ")", "# Debug check.", "\n", "\n", "", "return", "traj_infos", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.gpu.action_server.AlternatingActionServer.serve_actions": [[131, 174], ["range", "range", "range", "numpy.any", "action_server.AlternatingActionServer.agent.toggle_alt", "action_server.AlternatingActionServer.agent.step", "b.acquire", "action_server.AlternatingActionServer.agent.value", "b.acquire", "w.acquire", "b.acquire", "numpy.any", "w.release", "numpy.where", "action_server.AlternatingActionServer.agent.reset_one", "numpy.where", "action_server.AlternatingActionServer.agent.reset_one"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.agents.base.AlternatingRecurrentAgentMixin.toggle_alt", "home.repos.pwc.inspect_result.astooke_rlpyt.safe.safety_gym_env.SafetyGymTrajInfo.step", "home.repos.pwc.inspect_result.astooke_rlpyt.safe.cppo_agent.CppoLstmAgent.value", "home.repos.pwc.inspect_result.astooke_rlpyt.agents.base.RecurrentAgentMixin.reset_one", "home.repos.pwc.inspect_result.astooke_rlpyt.agents.base.RecurrentAgentMixin.reset_one"], ["def", "serve_actions", "(", "self", ",", "itr", ")", ":", "\n", "        ", "obs_ready_pair", "=", "self", ".", "obs_ready_pair", "\n", "act_ready_pair", "=", "self", ".", "act_ready_pair", "\n", "step_np_pair", "=", "self", ".", "step_buffer_np_pair", "\n", "agent_inputs_pair", "=", "self", ".", "agent_inputs_pair", "\n", "\n", "# Can easily write overlap and no overlap of workers versions.", "\n", "for", "t", "in", "range", "(", "self", ".", "batch_spec", ".", "T", ")", ":", "\n", "            ", "for", "alt", "in", "range", "(", "2", ")", ":", "\n", "                ", "step_h", "=", "step_np_pair", "[", "alt", "]", "\n", "for", "b", "in", "obs_ready_pair", "[", "alt", "]", ":", "\n", "                    ", "b", ".", "acquire", "(", ")", "# Workers written obs and rew, first prev_act.", "\n", "# assert not b.acquire(block=False)  # Debug check.", "\n", "", "if", "self", ".", "mid_batch_reset", "and", "np", ".", "any", "(", "step_h", ".", "done", ")", ":", "\n", "                    ", "for", "b_reset", "in", "np", ".", "where", "(", "step_h", ".", "done", ")", "[", "0", "]", ":", "\n", "                        ", "step_h", ".", "action", "[", "b_reset", "]", "=", "0", "# Null prev_action into agent.", "\n", "step_h", ".", "reward", "[", "b_reset", "]", "=", "0", "# Null prev_reward into agent.", "\n", "self", ".", "agent", ".", "reset_one", "(", "idx", "=", "b_reset", ")", "\n", "", "", "action", ",", "agent_info", "=", "self", ".", "agent", ".", "step", "(", "*", "agent_inputs_pair", "[", "alt", "]", ")", "\n", "step_h", ".", "action", "[", ":", "]", "=", "action", "# Worker applies to env.", "\n", "step_h", ".", "agent_info", "[", ":", "]", "=", "agent_info", "# Worker sends to traj_info.", "\n", "for", "w", "in", "act_ready_pair", "[", "alt", "]", ":", "# Final release.", "\n", "# assert not w.acquire(block=False)  # Debug check.", "\n", "                    ", "w", ".", "release", "(", ")", "# Signal to worker.", "\n", "\n", "", "", "", "for", "alt", "in", "range", "(", "2", ")", ":", "\n", "            ", "step_h", "=", "step_np_pair", "[", "alt", "]", "\n", "for", "b", "in", "obs_ready_pair", "[", "alt", "]", ":", "\n", "                ", "b", ".", "acquire", "(", ")", "\n", "# assert not b.acquire(block=False)  # Debug check.", "\n", "", "if", "\"bootstrap_value\"", "in", "self", ".", "samples_np", ".", "agent", ":", "\n", "                ", "self", ".", "bootstrap_value_pair", "[", "alt", "]", "[", ":", "]", "=", "self", ".", "agent", ".", "value", "(", "*", "agent_inputs_pair", "[", "alt", "]", ")", "\n", "", "if", "np", ".", "any", "(", "step_h", ".", "done", ")", ":", "\n", "                ", "for", "b_reset", "in", "np", ".", "where", "(", "step_h", ".", "done", ")", "[", "0", "]", ":", "\n", "                    ", "step_h", ".", "action", "[", "b_reset", "]", "=", "0", "\n", "step_h", ".", "reward", "[", "b_reset", "]", "=", "0", "\n", "self", ".", "agent", ".", "reset_one", "(", "idx", "=", "b_reset", ")", "\n", "", "", "self", ".", "agent", ".", "toggle_alt", "(", ")", "# Value and reset method do not advance rnn state.", "\n", "\n", "", "for", "b", "in", "self", ".", "sync", ".", "obs_ready", ":", "\n", "            ", "assert", "not", "b", ".", "acquire", "(", "block", "=", "False", ")", "# Debug check.", "\n", "", "for", "w", "in", "self", ".", "sync", ".", "act_ready", ":", "\n", "            ", "assert", "not", "w", ".", "acquire", "(", "block", "=", "False", ")", "# Debug check.", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.gpu.action_server.AlternatingActionServer.serve_actions_evaluation": [[175, 230], ["list", "action_server.AlternatingActionServer.agent.reset", "range", "range", "rlpyt.utils.logging.logger.log", "b.acquire", "list.extend", "action_server.AlternatingActionServer.agent.step", "rlpyt.utils.logging.logger.log", "b.acquire", "w.acquire", "rlpyt.utils.synchronize.drain_queue", "b.acquire", "numpy.where", "action_server.AlternatingActionServer.agent.reset_one", "w.release", "len", "b.acquire", "w.release"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.safe.safety_gym_env.SafetyGymEnvWrapper.reset", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.console.log", "home.repos.pwc.inspect_result.astooke_rlpyt.safe.safety_gym_env.SafetyGymTrajInfo.step", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.console.log", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.synchronize.drain_queue", "home.repos.pwc.inspect_result.astooke_rlpyt.agents.base.RecurrentAgentMixin.reset_one"], ["", "", "def", "serve_actions_evaluation", "(", "self", ",", "itr", ")", ":", "\n", "        ", "obs_ready", ",", "act_ready", "=", "self", ".", "sync", ".", "obs_ready", ",", "self", ".", "sync", ".", "act_ready", "\n", "obs_ready_pair", "=", "self", ".", "obs_ready_pair", "\n", "act_ready_pair", "=", "self", ".", "act_ready_pair", "\n", "step_np_pair", "=", "self", ".", "eval_step_buffer_np_pair", "\n", "agent_inputs_pair", "=", "self", ".", "eval_agent_inputs_pair", "\n", "traj_infos", "=", "list", "(", ")", "\n", "self", ".", "agent", ".", "reset", "(", ")", "\n", "stop", "=", "False", "\n", "\n", "for", "t", "in", "range", "(", "self", ".", "eval_max_T", ")", ":", "\n", "            ", "if", "t", "%", "EVAL_TRAJ_CHECK", "==", "0", ":", "# (While workers stepping.)", "\n", "                ", "traj_infos", ".", "extend", "(", "drain_queue", "(", "self", ".", "eval_traj_infos_queue", ",", "\n", "guard_sentinel", "=", "True", ")", ")", "\n", "", "for", "alt", "in", "range", "(", "2", ")", ":", "\n", "                ", "step_h", "=", "step_np_pair", "[", "alt", "]", "\n", "for", "b", "in", "obs_ready_pair", "[", "alt", "]", ":", "\n", "                    ", "b", ".", "acquire", "(", ")", "\n", "# assert not b.acquire(block=False)  # Debug check.", "\n", "", "for", "b_reset", "in", "np", ".", "where", "(", "step_h", ".", "done", ")", "[", "0", "]", ":", "\n", "                    ", "step_h", ".", "action", "[", "b_reset", "]", "=", "0", "# Null prev_action.", "\n", "step_h", ".", "reward", "[", "b_reset", "]", "=", "0", "# Null prev_reward.", "\n", "self", ".", "agent", ".", "reset_one", "(", "idx", "=", "b_reset", ")", "\n", "", "action", ",", "agent_info", "=", "self", ".", "agent", ".", "step", "(", "*", "agent_inputs_pair", "[", "alt", "]", ")", "\n", "step_h", ".", "action", "[", ":", "]", "=", "action", "\n", "step_h", ".", "agent_info", "[", ":", "]", "=", "agent_info", "\n", "if", "(", "self", ".", "eval_max_trajectories", "is", "not", "None", "and", "\n", "t", "%", "EVAL_TRAJ_CHECK", "==", "0", "and", "alt", "==", "0", ")", ":", "\n", "                    ", "if", "len", "(", "traj_infos", ")", ">=", "self", ".", "eval_max_trajectories", ":", "\n", "                        ", "for", "b", "in", "obs_ready_pair", "[", "1", "-", "alt", "]", ":", "\n", "                            ", "b", ".", "acquire", "(", ")", "# Now all workers waiting.", "\n", "", "self", ".", "sync", ".", "stop_eval", ".", "value", "=", "stop", "=", "True", "\n", "for", "w", "in", "act_ready", "[", "alt", "]", ":", "\n", "                            ", "w", ".", "release", "(", ")", "\n", "", "break", "\n", "", "", "for", "w", "in", "act_ready_pair", "[", "alt", "]", ":", "\n", "# assert not w.acquire(block=False)  # Debug check.", "\n", "                    ", "w", ".", "release", "(", ")", "\n", "", "", "if", "stop", ":", "\n", "                ", "logger", ".", "log", "(", "\"Evaluation reached max num trajectories \"", "\n", "f\"({self.eval_max_trajectories}).\"", ")", "\n", "break", "\n", "\n", "# TODO: check exit logic for/while ..?", "\n", "", "", "if", "not", "stop", ":", "\n", "            ", "logger", ".", "log", "(", "\"Evaluation reached max num time steps \"", "\n", "f\"({self.eval_max_T}).\"", ")", "\n", "\n", "", "for", "b", "in", "obs_ready", ":", "\n", "            ", "b", ".", "acquire", "(", ")", "# Workers always do extra release; drain it.", "\n", "assert", "not", "b", ".", "acquire", "(", "block", "=", "False", ")", "# Debug check.", "\n", "", "for", "w", "in", "act_ready", ":", "\n", "            ", "assert", "not", "w", ".", "acquire", "(", "block", "=", "False", ")", "# Debug check.", "\n", "\n", "", "return", "traj_infos", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.gpu.action_server.NoOverlapAlternatingActionServer.serve_actions": [[243, 288], ["range", "range", "range", "numpy.any", "action_server.NoOverlapAlternatingActionServer.agent.toggle_alt", "action_server.NoOverlapAlternatingActionServer.agent.step", "b.acquire", "action_server.NoOverlapAlternatingActionServer.agent.value", "b.acquire", "numpy.any", "w.release", "numpy.where", "action_server.NoOverlapAlternatingActionServer.agent.reset_one", "w.release", "numpy.where", "action_server.NoOverlapAlternatingActionServer.agent.reset_one"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.agents.base.AlternatingRecurrentAgentMixin.toggle_alt", "home.repos.pwc.inspect_result.astooke_rlpyt.safe.safety_gym_env.SafetyGymTrajInfo.step", "home.repos.pwc.inspect_result.astooke_rlpyt.safe.cppo_agent.CppoLstmAgent.value", "home.repos.pwc.inspect_result.astooke_rlpyt.agents.base.RecurrentAgentMixin.reset_one", "home.repos.pwc.inspect_result.astooke_rlpyt.agents.base.RecurrentAgentMixin.reset_one"], ["def", "serve_actions", "(", "self", ",", "itr", ")", ":", "\n", "        ", "obs_ready", "=", "self", ".", "sync", ".", "obs_ready", "\n", "obs_ready_pair", "=", "self", ".", "obs_ready_pair", "\n", "act_ready_pair", "=", "self", ".", "act_ready_pair", "\n", "step_np", ",", "step_np_pair", "=", "self", ".", "step_buffer_np", ",", "self", ".", "step_buffer_np_pair", "\n", "agent_inputs", ",", "agent_inputs_pair", "=", "self", ".", "agent_inputs", ",", "self", ".", "agent_inputs_pair", "\n", "\n", "for", "t", "in", "range", "(", "self", ".", "batch_spec", ".", "T", ")", ":", "\n", "            ", "for", "alt", "in", "range", "(", "2", ")", ":", "\n", "                ", "step_h", "=", "step_np_pair", "[", "alt", "]", "\n", "for", "b", "in", "obs_ready_pair", "[", "alt", "]", ":", "\n", "                    ", "b", ".", "acquire", "(", ")", "# Workers written obs and rew, first prev_act.", "\n", "# assert not b.acquire(block=False)  # Debug check.", "\n", "", "if", "t", ">", "0", "or", "alt", ">", "0", ":", "# Just don't do the very first one.", "\n", "# Only let `alt` workers go after `1-alt` workers done stepping.", "\n", "                    ", "for", "w", "in", "act_ready_pair", "[", "1", "-", "alt", "]", ":", "\n", "# assert not w.acquire(block=False)  # Debug check.", "\n", "                        ", "w", ".", "release", "(", ")", "\n", "\n", "", "", "if", "self", ".", "mid_batch_reset", "and", "np", ".", "any", "(", "step_h", ".", "done", ")", ":", "\n", "                    ", "for", "b_reset", "in", "np", ".", "where", "(", "step_h", ".", "done", ")", "[", "0", "]", ":", "\n", "                        ", "step_h", ".", "action", "[", "b_reset", "]", "=", "0", "# Null prev_action into agent.", "\n", "step_h", ".", "reward", "[", "b_reset", "]", "=", "0", "# Null prev_reward into agent.", "\n", "self", ".", "agent", ".", "reset_one", "(", "idx", "=", "b_reset", ")", "\n", "", "", "action", ",", "agent_info", "=", "self", ".", "agent", ".", "step", "(", "*", "agent_inputs_pair", "[", "alt", "]", ")", "\n", "step_h", ".", "action", "[", ":", "]", "=", "action", "# Worker applies to env.", "\n", "step_h", ".", "agent_info", "[", ":", "]", "=", "agent_info", "# Worker sends to traj_info.", "\n", "\n", "", "", "for", "alt", "in", "range", "(", "2", ")", ":", "\n", "            ", "step_h", "=", "step_np_pair", "[", "alt", "]", "\n", "for", "b", "in", "obs_ready_pair", "[", "alt", "]", ":", "\n", "                ", "b", ".", "acquire", "(", ")", "\n", "# assert not b.acquire(block=False)  # Debug check.", "\n", "", "if", "alt", "==", "0", ":", "\n", "                ", "for", "w", "in", "act_ready_pair", "[", "1", "]", ":", "\n", "# assert not w.acquire(block=False)  # Debug check.", "\n", "                    ", "w", ".", "release", "(", ")", "\n", "", "", "if", "\"bootstrap_value\"", "in", "self", ".", "samples_np", ".", "agent", ":", "\n", "                ", "self", ".", "bootstrap_value_pair", "[", "alt", "]", "[", ":", "]", "=", "self", ".", "agent", ".", "value", "(", "*", "agent_inputs_pair", "[", "alt", "]", ")", "\n", "", "if", "np", ".", "any", "(", "step_h", ".", "done", ")", ":", "\n", "                ", "for", "b_reset", "in", "np", ".", "where", "(", "step_h", ".", "done", ")", "[", "0", "]", ":", "\n", "                    ", "step_h", ".", "action", "[", "b_reset", "]", "=", "0", "\n", "step_h", ".", "reward", "[", "b_reset", "]", "=", "0", "\n", "self", ".", "agent", ".", "reset_one", "(", "idx", "=", "b_reset", ")", "\n", "", "", "self", ".", "agent", ".", "toggle_alt", "(", ")", "# Value and reset method do not advance rnn state.", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.gpu.action_server.NoOverlapAlternatingActionServer.serve_actions_evaluation": [[289, 364], ["list", "action_server.NoOverlapAlternatingActionServer.agent.reset", "action_server.NoOverlapAlternatingActionServer.agent.step", "action_server.NoOverlapAlternatingActionServer.agent.step", "range", "b.acquire", "b.acquire", "w.release", "range", "w.release", "rlpyt.utils.logging.logger.log", "b.acquire", "list.extend", "action_server.NoOverlapAlternatingActionServer.agent.step", "rlpyt.utils.logging.logger.log", "rlpyt.utils.synchronize.drain_queue", "b.acquire", "w.release", "numpy.where", "action_server.NoOverlapAlternatingActionServer.agent.reset_one", "len", "w.release"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.safe.safety_gym_env.SafetyGymEnvWrapper.reset", "home.repos.pwc.inspect_result.astooke_rlpyt.safe.safety_gym_env.SafetyGymTrajInfo.step", "home.repos.pwc.inspect_result.astooke_rlpyt.safe.safety_gym_env.SafetyGymTrajInfo.step", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.console.log", "home.repos.pwc.inspect_result.astooke_rlpyt.safe.safety_gym_env.SafetyGymTrajInfo.step", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.console.log", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.synchronize.drain_queue", "home.repos.pwc.inspect_result.astooke_rlpyt.agents.base.RecurrentAgentMixin.reset_one"], ["", "", "def", "serve_actions_evaluation", "(", "self", ",", "itr", ")", ":", "\n", "        ", "obs_ready", ",", "act_ready", "=", "self", ".", "sync", ".", "obs_ready", ",", "self", ".", "sync", ".", "act_ready", "\n", "obs_ready_pair", "=", "self", ".", "obs_ready_pair", "\n", "act_ready_pair", "=", "self", ".", "act_ready_pair", "\n", "step_np", ",", "step_np_pair", "=", "self", ".", "eval_step_buffer_np", ",", "self", ".", "eval_step_buffer_np_pair", "\n", "agent_inputs", "=", "self", ".", "eval_agent_inputs", "\n", "agent_inputs_pair", "=", "self", ".", "eval_agent_inputs_pair", "\n", "traj_infos", "=", "list", "(", ")", "\n", "self", ".", "agent", ".", "reset", "(", ")", "\n", "step_np", ".", "action", "[", ":", "]", "=", "0", "# Null prev_action.", "\n", "step_np", ".", "reward", "[", ":", "]", "=", "0", "# Null prev_reward.", "\n", "\n", "# First step of both.", "\n", "alt", "=", "0", "\n", "step_h", "=", "step_np_pair", "[", "alt", "]", "\n", "for", "b", "in", "obs_ready_pair", "[", "alt", "]", ":", "\n", "            ", "b", ".", "acquire", "(", ")", "\n", "# assert not b.acquire(block=False)  # Debug check.", "\n", "", "action", ",", "agent_info", "=", "self", ".", "agent", ".", "step", "(", "*", "agent_inputs_pair", "[", "alt", "]", ")", "\n", "step_h", ".", "action", "[", ":", "]", "=", "action", "\n", "step_h", ".", "agent_info", "[", ":", "]", "=", "agent_info", "\n", "alt", "=", "1", "\n", "step_h", "=", "step_np_pair", "[", "alt", "]", "\n", "for", "b", "in", "obs_ready_pair", "[", "alt", "]", ":", "\n", "            ", "b", ".", "acquire", "(", ")", "\n", "# assert not b.acquire(block=False)  # Debug check.", "\n", "", "for", "w", "in", "act_ready_pair", "[", "1", "-", "alt", "]", ":", "\n", "# assert not w.acquire(block=False)  # Debug check.", "\n", "            ", "w", ".", "release", "(", ")", "\n", "", "action", ",", "agent_info", "=", "self", ".", "agent", ".", "step", "(", "*", "agent_inputs_pair", "[", "alt", "]", ")", "\n", "step_h", ".", "action", "[", ":", "]", "=", "action", "\n", "step_h", ".", "agent_info", "[", ":", "]", "=", "agent_info", "\n", "\n", "for", "t", "in", "range", "(", "1", ",", "self", ".", "eval_max_T", ")", ":", "\n", "            ", "if", "t", "%", "EVAL_TRAJ_CHECK", "==", "0", ":", "# (While workers stepping.)", "\n", "                ", "traj_infos", ".", "extend", "(", "drain_queue", "(", "self", ".", "eval_traj_infos_queue", ",", "\n", "guard_sentinel", "=", "True", ")", ")", "\n", "", "for", "alt", "in", "range", "(", "2", ")", ":", "\n", "                ", "step_h", "=", "step_np_pair", "[", "alt", "]", "\n", "for", "b", "in", "obs_ready_pair", "[", "alt", "]", ":", "\n", "                    ", "b", ".", "acquire", "(", ")", "\n", "# assert not b.acquire(block=False)  # Debug check.", "\n", "", "for", "w", "in", "act_ready_pair", "[", "1", "-", "alt", "]", ":", "\n", "# assert not w.acquire(block=False)  # Debug check.", "\n", "                    ", "w", ".", "release", "(", ")", "\n", "", "for", "b_reset", "in", "np", ".", "where", "(", "step_h", ".", "done", ")", "[", "0", "]", ":", "\n", "                    ", "step_h", ".", "action", "[", "b_reset", "]", "=", "0", "# Null prev_action.", "\n", "step_h", ".", "reward", "[", "b_reset", "]", "=", "0", "# Null prev_reward.", "\n", "self", ".", "agent", ".", "reset_one", "(", "idx", "=", "b_reset", ")", "\n", "", "action", ",", "agent_info", "=", "self", ".", "agent", ".", "step", "(", "*", "agent_inputs_pair", "[", "alt", "]", ")", "\n", "step_h", ".", "action", "[", ":", "]", "=", "action", "\n", "step_h", ".", "agent_info", "[", ":", "]", "=", "agent_info", "\n", "", "if", "self", ".", "eval_max_trajectories", "is", "not", "None", "and", "t", "%", "EVAL_TRAJ_CHECK", "==", "0", ":", "\n", "                ", "self", ".", "sync", ".", "stop_eval", ".", "value", "=", "len", "(", "traj_infos", ")", ">=", "self", ".", "eval_max_trajectories", "\n", "", "if", "self", ".", "sync", ".", "stop_eval", ".", "value", ":", "\n", "                ", "for", "w", "in", "act_ready_pair", "[", "1", "-", "alt", "]", ":", "# Other released past loop.", "\n", "# assert not w.acquire(block=False)  # Debug check.", "\n", "                    ", "w", ".", "release", "(", ")", "\n", "", "logger", ".", "log", "(", "\"Evaluation reached max num trajectories \"", "\n", "f\"({self.eval_max_trajectories}).\"", ")", "\n", "break", "\n", "\n", "# TODO: check logic when traj limit hits at natural end of loop?", "\n", "", "", "for", "w", "in", "act_ready_pair", "[", "alt", "]", ":", "\n", "# assert not w.acquire(block=False)  # Debug check.", "\n", "            ", "w", ".", "release", "(", ")", "\n", "", "if", "t", "==", "self", ".", "eval_max_T", "-", "1", "and", "self", ".", "eval_max_trajectories", "is", "not", "None", ":", "\n", "            ", "logger", ".", "log", "(", "\"Evaluation reached max num time steps \"", "\n", "f\"({self.eval_max_T}).\"", ")", "\n", "\n", "", "for", "b", "in", "obs_ready", ":", "\n", "            ", "b", ".", "acquire", "(", ")", "# Workers always do extra release; drain it.", "\n", "# assert not b.acquire(block=False)  # Debug check.", "\n", "\n", "", "return", "traj_infos", "\n", "", "", ""]], "home.repos.pwc.inspect_result.astooke_rlpyt.gpu.collectors.GpuResetCollector.collect_batch": [[18, 51], ["obs_ready.release", "list", "range", "act_ready.acquire", "enumerate", "obs_ready.release", "env.step", "traj_infos[].step", "getattr", "list.append", "collectors.GpuResetCollector.TrajInfoCls", "env.reset", "traj_infos[].terminate"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.safe.safety_gym_env.SafetyGymTrajInfo.step", "home.repos.pwc.inspect_result.astooke_rlpyt.safe.safety_gym_env.SafetyGymTrajInfo.step", "home.repos.pwc.inspect_result.astooke_rlpyt.safe.safety_gym_env.SafetyGymEnvWrapper.reset", "home.repos.pwc.inspect_result.astooke_rlpyt.safe.safety_gym_env.SafetyGymTrajInfo.terminate"], ["batch_T", ",", "\n", "TrajInfoCls", ",", "\n", "agent", "=", "None", ",", "# Present or not, depending on collector class.", "\n", "sync", "=", "None", ",", "\n", "step_buffer_np", "=", "None", ",", "\n", "global_B", "=", "1", ",", "\n", "env_ranks", "=", "None", ",", "\n", ")", ":", "\n", "        ", "save__init__args", "(", "locals", "(", ")", ")", "\n", "\n", "", "def", "start_envs", "(", "self", ")", ":", "\n", "        ", "\"\"\"e.g. calls reset() on every env.\"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n", "", "def", "start_agent", "(", "self", ")", ":", "\n", "        ", "\"\"\"In CPU-collectors, call ``agent.collector_initialize()`` e.g. to set up\n        vector epsilon-greedy, and reset the agent.\n        \"\"\"", "\n", "if", "getattr", "(", "self", ",", "\"agent\"", ",", "None", ")", "is", "not", "None", ":", "# Not in GPU collectors.", "\n", "            ", "self", ".", "agent", ".", "collector_initialize", "(", "\n", "global_B", "=", "self", ".", "global_B", ",", "# Args used e.g. for vector epsilon greedy.", "\n", "env_ranks", "=", "self", ".", "env_ranks", ",", "\n", ")", "\n", "self", ".", "agent", ".", "reset", "(", ")", "\n", "self", ".", "agent", ".", "sample_mode", "(", "itr", "=", "0", ")", "\n", "\n", "", "", "def", "collect_batch", "(", "self", ",", "agent_inputs", ",", "traj_infos", ")", ":", "\n", "        ", "\"\"\"Main data collection loop.\"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n", "", "def", "reset_if_needed", "(", "self", ",", "agent_inputs", ")", ":", "\n", "        ", "\"\"\"Reset agent and or env as needed, if doing between batches.\"\"\"", "\n", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.gpu.collectors.GpuWaitResetCollector.__init__": [[62, 69], ["rlpyt.samplers.collectors.DecorrelatingStartCollector.__init__", "numpy.zeros", "rlpyt.utils.buffer.buffer_method", "len"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.spaces.gym_wrapper.GymSpaceWrapper.__init__", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.misc.zeros", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.buffer.buffer_method"], ["max_T", ",", "\n", "agent", "=", "None", ",", "\n", "sync", "=", "None", ",", "\n", "step_buffer_np", "=", "None", ",", "\n", ")", ":", "\n", "        ", "save__init__args", "(", "locals", "(", ")", ")", "\n", "\n", "", "def", "collect_evaluation", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.gpu.collectors.GpuWaitResetCollector.collect_batch": [[70, 116], ["obs_ready.release", "list", "range", "numpy.where", "act_ready.acquire", "enumerate", "obs_ready.release", "env.step", "traj_infos[].step", "getattr", "list.append", "collectors.GpuWaitResetCollector.TrajInfoCls", "traj_infos[].terminate"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.safe.safety_gym_env.SafetyGymTrajInfo.step", "home.repos.pwc.inspect_result.astooke_rlpyt.safe.safety_gym_env.SafetyGymTrajInfo.step", "home.repos.pwc.inspect_result.astooke_rlpyt.safe.safety_gym_env.SafetyGymTrajInfo.terminate"], ["        ", "\"\"\"Run agent evaluation in environment and return completed trajectory\n        infos.\"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n", "\n", "", "", "class", "DecorrelatingStartCollector", "(", "BaseCollector", ")", ":", "\n", "    ", "\"\"\"Collector which can step all environments through a random number of random\n    actions during startup, to decorrelate the states in training batches.\n    \"\"\"", "\n", "\n", "def", "start_envs", "(", "self", ",", "max_decorrelation_steps", "=", "0", ")", ":", "\n", "        ", "\"\"\"Calls ``reset()`` on every environment instance, then steps each\n        one through a random number of random actions, and returns the\n        resulting agent_inputs buffer (`observation`, `prev_action`,\n        `prev_reward`).\"\"\"", "\n", "traj_infos", "=", "[", "self", ".", "TrajInfoCls", "(", ")", "for", "_", "in", "range", "(", "len", "(", "self", ".", "envs", ")", ")", "]", "\n", "observations", "=", "list", "(", ")", "\n", "for", "env", "in", "self", ".", "envs", ":", "\n", "            ", "observations", ".", "append", "(", "env", ".", "reset", "(", ")", ")", "\n", "", "observation", "=", "buffer_from_example", "(", "observations", "[", "0", "]", ",", "len", "(", "self", ".", "envs", ")", ")", "\n", "for", "b", ",", "obs", "in", "enumerate", "(", "observations", ")", ":", "\n", "            ", "observation", "[", "b", "]", "=", "obs", "# numpy array or namedarraytuple", "\n", "", "prev_action", "=", "np", ".", "stack", "(", "[", "env", ".", "action_space", ".", "null_value", "(", ")", "\n", "for", "env", "in", "self", ".", "envs", "]", ")", "\n", "prev_reward", "=", "np", ".", "zeros", "(", "len", "(", "self", ".", "envs", ")", ",", "dtype", "=", "\"float32\"", ")", "\n", "if", "self", ".", "rank", "==", "0", ":", "\n", "            ", "logger", ".", "log", "(", "\"Sampler decorrelating envs, max steps: \"", "\n", "f\"{max_decorrelation_steps}\"", ")", "\n", "", "if", "max_decorrelation_steps", "!=", "0", ":", "\n", "            ", "for", "b", ",", "env", "in", "enumerate", "(", "self", ".", "envs", ")", ":", "\n", "                ", "n_steps", "=", "1", "+", "int", "(", "np", ".", "random", ".", "rand", "(", ")", "*", "max_decorrelation_steps", ")", "\n", "for", "_", "in", "range", "(", "n_steps", ")", ":", "\n", "                    ", "a", "=", "env", ".", "action_space", ".", "sample", "(", ")", "\n", "o", ",", "r", ",", "d", ",", "info", "=", "env", ".", "step", "(", "a", ")", "\n", "traj_infos", "[", "b", "]", ".", "step", "(", "o", ",", "a", ",", "r", ",", "d", ",", "None", ",", "info", ")", "\n", "if", "getattr", "(", "info", ",", "\"traj_done\"", ",", "d", ")", ":", "\n", "                        ", "o", "=", "env", ".", "reset", "(", ")", "\n", "traj_infos", "[", "b", "]", "=", "self", ".", "TrajInfoCls", "(", ")", "\n", "", "if", "d", ":", "\n", "                        ", "a", "=", "env", ".", "action_space", ".", "null_value", "(", ")", "\n", "r", "=", "0", "\n", "", "", "observation", "[", "b", "]", "=", "o", "\n", "prev_action", "[", "b", "]", "=", "a", "\n", "prev_reward", "[", "b", "]", "=", "r", "\n", "# For action-server samplers.", "\n", "", "", "if", "hasattr", "(", "self", ",", "\"step_buffer_np\"", ")", "and", "self", ".", "step_buffer_np", "is", "not", "None", ":", "\n", "            ", "self", ".", "step_buffer_np", ".", "observation", "[", ":", "]", "=", "observation", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.gpu.collectors.GpuWaitResetCollector.reset_if_needed": [[117, 127], ["numpy.any", "numpy.where", "collectors.GpuWaitResetCollector.envs[].reset"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.safe.safety_gym_env.SafetyGymEnvWrapper.reset"], ["self", ".", "step_buffer_np", ".", "action", "[", ":", "]", "=", "prev_action", "\n", "self", ".", "step_buffer_np", ".", "reward", "[", ":", "]", "=", "prev_reward", "\n", "", "return", "AgentInputs", "(", "observation", ",", "prev_action", ",", "prev_reward", ")", ",", "traj_infos", "\n", "", "", ""]], "home.repos.pwc.inspect_result.astooke_rlpyt.gpu.collectors.GpuEvalCollector.collect_evaluation": [[134, 162], ["enumerate", "obs_ready.release", "range", "collectors.GpuEvalCollector.traj_infos_queue.put", "collectors.GpuEvalCollector.TrajInfoCls", "env.reset", "act_ready.acquire", "enumerate", "obs_ready.release", "range", "obs_ready.release", "env.step", "traj_infos[].step", "getattr", "len", "collectors.GpuEvalCollector.traj_infos_queue.put", "collectors.GpuEvalCollector.TrajInfoCls", "env.reset", "traj_infos[].terminate"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.safe.safety_gym_env.SafetyGymEnvWrapper.reset", "home.repos.pwc.inspect_result.astooke_rlpyt.safe.safety_gym_env.SafetyGymTrajInfo.step", "home.repos.pwc.inspect_result.astooke_rlpyt.safe.safety_gym_env.SafetyGymTrajInfo.step", "home.repos.pwc.inspect_result.astooke_rlpyt.safe.safety_gym_env.SafetyGymEnvWrapper.reset", "home.repos.pwc.inspect_result.astooke_rlpyt.safe.safety_gym_env.SafetyGymTrajInfo.terminate"], []], "home.repos.pwc.inspect_result.astooke_rlpyt.gpu.sampler.GpuSamplerBase.__init__": [[39, 44], ["rlpyt.samplers.parallel.base.ParallelSamplerBase.__init__"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.spaces.gym_wrapper.GymSpaceWrapper.__init__"], []], "home.repos.pwc.inspect_result.astooke_rlpyt.gpu.sampler.GpuSamplerBase.obtain_samples": [[45, 57], ["sampler.GpuSamplerBase.agent.sample_mode", "sampler.GpuSamplerBase.ctrl.barrier_in.wait", "sampler.GpuSamplerBase.serve_actions", "sampler.GpuSamplerBase.ctrl.barrier_out.wait", "rlpyt.utils.synchronize.drain_queue"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.agents.dmc_sac_agent.SacAgent.sample_mode", "home.repos.pwc.inspect_result.astooke_rlpyt.gpu.action_server.NoOverlapAlternatingActionServer.serve_actions", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.synchronize.drain_queue"], []], "home.repos.pwc.inspect_result.astooke_rlpyt.gpu.sampler.GpuSamplerBase.evaluate_agent": [[58, 73], ["sampler.GpuSamplerBase.agent.eval_mode", "sampler.GpuSamplerBase.ctrl.barrier_in.wait", "sampler.GpuSamplerBase.serve_actions_evaluation", "sampler.GpuSamplerBase.ctrl.barrier_out.wait", "sampler.GpuSamplerBase.extend", "rlpyt.utils.synchronize.drain_queue"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.agents.dmc_sac_agent.SacAgent.eval_mode", "home.repos.pwc.inspect_result.astooke_rlpyt.async_.action_server.AsyncNoOverlapAlternatingActionServer.serve_actions_evaluation", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.synchronize.drain_queue"], []], "home.repos.pwc.inspect_result.astooke_rlpyt.gpu.sampler.GpuSamplerBase._agent_init": [[74, 81], ["agent.initialize"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.safe.cppo_agent.CppoLstmAgent.initialize"], []], "home.repos.pwc.inspect_result.astooke_rlpyt.gpu.sampler.GpuSamplerBase._build_buffers": [[82, 97], ["super()._build_buffers", "sampler.build_step_buffer", "rlpyt.agents.base.AgentInputs", "sampler.build_step_buffer", "rlpyt.agents.base.AgentInputs"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.async_.base.AsyncParallelSamplerMixin._build_buffers", "home.repos.pwc.inspect_result.astooke_rlpyt.gpu.sampler.build_step_buffer", "home.repos.pwc.inspect_result.astooke_rlpyt.gpu.sampler.build_step_buffer"], []], "home.repos.pwc.inspect_result.astooke_rlpyt.gpu.sampler.GpuSamplerBase._build_parallel_ctrl": [[98, 102], ["super()._build_parallel_ctrl", "multiprocessing.Semaphore", "multiprocessing.Semaphore", "range", "range"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.async_.gpu_sampler.AsyncGpuSamplerBase._build_parallel_ctrl"], []], "home.repos.pwc.inspect_result.astooke_rlpyt.gpu.sampler.GpuSamplerBase._assemble_common_kwargs": [[103, 107], ["super()._assemble_common_kwargs"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.gpu.sampler.GpuSamplerBase._assemble_common_kwargs"], []], "home.repos.pwc.inspect_result.astooke_rlpyt.gpu.sampler.GpuSamplerBase._assemble_workers_kwargs": [[108, 128], ["super()._assemble_workers_kwargs", "enumerate", "slice", "rlpyt.utils.collections.AttrDict", "slice"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.async_.gpu_sampler.AsyncGpuSamplerBase._assemble_workers_kwargs"], []], "home.repos.pwc.inspect_result.astooke_rlpyt.gpu.sampler.build_step_buffer": [[134, 140], ["StepBuffer", "rlpyt.utils.buffer.torchify_buffer", "rlpyt.utils.buffer.buffer_from_example"], "function", ["home.repos.pwc.inspect_result.astooke_rlpyt.utils.buffer.torchify_buffer", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.buffer.buffer_from_example"], []], "home.repos.pwc.inspect_result.astooke_rlpyt.gpu.alternating_sampler.AlternatingSamplerBase.__init__": [[26, 29], ["rlpyt.samplers.parallel.gpu.sampler.GpuSamplerBase.__init__"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.spaces.gym_wrapper.GymSpaceWrapper.__init__"], ["def", "__init__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "assert", "self", ".", "batch_spec", ".", "B", "%", "2", "==", "0", ",", "\"Need even number for sampler batch_B.\"", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.gpu.alternating_sampler.AlternatingSamplerBase.initialize": [[30, 40], ["super().initialize", "alternating_sampler.AlternatingSamplerBase._make_alternating_pairs", "TypeError"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.safe.cppo_agent.CppoLstmAgent.initialize", "home.repos.pwc.inspect_result.astooke_rlpyt.async_.alternating_sampler.AsyncAlternatingSamplerBase._make_alternating_pairs"], ["", "def", "initialize", "(", "self", ",", "agent", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"Like the super class's ``initialize()``, but creates additional set of\n        synchronization and communication objects for the alternate workers.\"\"\"", "\n", "if", "agent", ".", "recurrent", "and", "not", "agent", ".", "alternating", ":", "\n", "            ", "raise", "TypeError", "(", "\"If agent is recurrent, must be 'alternating' to use here.\"", ")", "\n", "", "elif", "not", "agent", ".", "recurrent", ":", "\n", "            ", "agent", ".", "alternating", "=", "True", "# FF agent doesn't need special class, but tell it so.", "\n", "", "examples", "=", "super", "(", ")", ".", "initialize", "(", "agent", ",", "*", "args", ",", "**", "kwargs", ")", "\n", "self", ".", "_make_alternating_pairs", "(", ")", "\n", "return", "examples", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.gpu.alternating_sampler.AlternatingSamplerBase._make_alternating_pairs": [[41, 58], ["None"], "methods", ["None"], ["", "def", "_make_alternating_pairs", "(", "self", ")", ":", "\n", "        ", "half_w", "=", "self", ".", "n_worker", "//", "2", "# Half of workers.", "\n", "self", ".", "half_B", "=", "half_B", "=", "self", ".", "batch_spec", ".", "B", "//", "2", "# Half of envs.", "\n", "self", ".", "obs_ready_pair", "=", "(", "self", ".", "sync", ".", "obs_ready", "[", ":", "half_w", "]", ",", "self", ".", "sync", ".", "obs_ready", "[", "half_w", ":", "]", ")", "\n", "self", ".", "act_ready_pair", "=", "(", "self", ".", "sync", ".", "act_ready", "[", ":", "half_w", "]", ",", "self", ".", "sync", ".", "act_ready", "[", "half_w", ":", "]", ")", "\n", "self", ".", "step_buffer_np_pair", "=", "(", "self", ".", "step_buffer_np", "[", ":", "half_B", "]", ",", "self", ".", "step_buffer_np", "[", "half_B", ":", "]", ")", "\n", "self", ".", "agent_inputs_pair", "=", "(", "self", ".", "agent_inputs", "[", ":", "half_B", "]", ",", "self", ".", "agent_inputs", "[", "half_B", ":", "]", ")", "\n", "if", "self", ".", "eval_n_envs", ">", "0", ":", "\n", "            ", "assert", "self", ".", "eval_n_envs", "%", "2", "==", "0", "\n", "eval_half_B", "=", "self", ".", "eval_n_envs", "//", "2", "\n", "self", ".", "eval_step_buffer_np_pair", "=", "(", "self", ".", "eval_step_buffer_np", "[", ":", "eval_half_B", "]", ",", "\n", "self", ".", "eval_step_buffer_np", "[", "eval_half_B", ":", "]", ")", "\n", "self", ".", "eval_agent_inputs_pair", "=", "(", "self", ".", "eval_agent_inputs", "[", ":", "eval_half_B", "]", ",", "\n", "self", ".", "eval_agent_inputs", "[", "eval_half_B", ":", "]", ")", "\n", "", "if", "\"bootstrap_value\"", "in", "self", ".", "samples_np", ".", "agent", ":", "\n", "            ", "self", ".", "bootstrap_value_pair", "=", "(", "self", ".", "samples_np", ".", "agent", ".", "bootstrap_value", "[", "0", ",", ":", "half_B", "]", ",", "\n", "self", ".", "samples_np", ".", "agent", ".", "bootstrap_value", "[", "0", ",", "half_B", ":", "]", ")", "# (leading dim T=1)", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.gpu.alternating_sampler.AlternatingSamplerBase._get_n_envs_list": [[59, 75], ["super()._get_n_envs_list", "affinity.get", "len", "range"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.async_.alternating_sampler.AsyncAlternatingSamplerBase._get_n_envs_list", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.collections.NamedArrayTuple.get"], ["", "", "def", "_get_n_envs_list", "(", "self", ",", "affinity", "=", "None", ",", "n_worker", "=", "None", ",", "B", "=", "None", ")", ":", "\n", "        ", "if", "affinity", "is", "not", "None", ":", "\n", "            ", "assert", "affinity", ".", "get", "(", "\"alternating\"", ",", "False", ")", ",", "\"Need alternating affinity.\"", "\n", "", "n_worker", "=", "len", "(", "affinity", "[", "\"workers_cpus\"", "]", ")", "if", "n_worker", "is", "None", "else", "n_worker", "\n", "assert", "n_worker", "%", "2", "==", "0", ",", "\"Need even number workers.\"", "\n", "B", "=", "self", ".", "batch_spec", ".", "B", "if", "B", "is", "None", "else", "B", "\n", "assert", "B", "%", "2", "==", "0", "\n", "# To log warnings:", "\n", "n_envs_list", "=", "super", "(", ")", ".", "_get_n_envs_list", "(", "n_worker", "=", "n_worker", ",", "B", "=", "B", ")", "\n", "if", "B", "%", "n_worker", ">", "0", ":", "\n", "# Redistribute extra envs.", "\n", "            ", "n_envs_list", "=", "[", "B", "//", "n_worker", "]", "*", "n_worker", "\n", "for", "w", "in", "range", "(", "(", "B", "%", "n_worker", ")", "//", "2", ")", ":", "\n", "                ", "n_envs_list", "[", "w", "]", "+=", "1", "\n", "n_envs_list", "[", "w", "+", "n_worker", "//", "2", "]", "+=", "1", "# Paired worker.", "\n", "", "", "return", "n_envs_list", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.serial.collectors.SerialEvalCollector.__init__": [[16, 25], ["rlpyt.utils.quick_args.save__init__args", "locals"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.utils.quick_args.save__init__args"], ["envs", ",", "\n", "samples_np", ",", "\n", "batch_T", ",", "\n", "TrajInfoCls", ",", "\n", "agent", "=", "None", ",", "# Present or not, depending on collector class.", "\n", "sync", "=", "None", ",", "\n", "step_buffer_np", "=", "None", ",", "\n", "global_B", "=", "1", ",", "\n", "env_ranks", "=", "None", ",", "\n", ")", ":", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.serial.collectors.SerialEvalCollector.collect_evaluation": [[26, 67], ["list", "list", "rlpyt.utils.buffer.buffer_from_example", "enumerate", "rlpyt.utils.buffer.buffer_from_example", "numpy.zeros", "rlpyt.utils.buffer.torchify_buffer", "collectors.SerialEvalCollector.agent.reset", "collectors.SerialEvalCollector.agent.eval_mode", "range", "collectors.SerialEvalCollector.TrajInfoCls", "list.append", "len", "collectors.SerialEvalCollector.envs[].action_space.null_value", "len", "len", "collectors.SerialEvalCollector.agent.step", "rlpyt.utils.buffer.numpify_buffer", "enumerate", "rlpyt.utils.logging.logger.log", "range", "env.reset", "env.step", "traj_infos[].step", "getattr", "rlpyt.utils.logging.logger.log", "len", "list.append", "collectors.SerialEvalCollector.TrajInfoCls", "env.reset", "collectors.SerialEvalCollector.agent.reset_one", "len", "traj_infos[].terminate"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.utils.buffer.buffer_from_example", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.buffer.buffer_from_example", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.misc.zeros", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.buffer.torchify_buffer", "home.repos.pwc.inspect_result.astooke_rlpyt.safe.safety_gym_env.SafetyGymEnvWrapper.reset", "home.repos.pwc.inspect_result.astooke_rlpyt.agents.dmc_sac_agent.SacAgent.eval_mode", "home.repos.pwc.inspect_result.astooke_rlpyt.spaces.gym_wrapper.GymSpaceWrapper.null_value", "home.repos.pwc.inspect_result.astooke_rlpyt.safe.safety_gym_env.SafetyGymTrajInfo.step", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.buffer.numpify_buffer", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.console.log", "home.repos.pwc.inspect_result.astooke_rlpyt.safe.safety_gym_env.SafetyGymEnvWrapper.reset", "home.repos.pwc.inspect_result.astooke_rlpyt.safe.safety_gym_env.SafetyGymTrajInfo.step", "home.repos.pwc.inspect_result.astooke_rlpyt.safe.safety_gym_env.SafetyGymTrajInfo.step", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.console.log", "home.repos.pwc.inspect_result.astooke_rlpyt.safe.safety_gym_env.SafetyGymEnvWrapper.reset", "home.repos.pwc.inspect_result.astooke_rlpyt.agents.base.RecurrentAgentMixin.reset_one", "home.repos.pwc.inspect_result.astooke_rlpyt.safe.safety_gym_env.SafetyGymTrajInfo.terminate"], ["        ", "save__init__args", "(", "locals", "(", ")", ")", "\n", "\n", "", "def", "start_envs", "(", "self", ")", ":", "\n", "        ", "\"\"\"e.g. calls reset() on every env.\"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n", "", "def", "start_agent", "(", "self", ")", ":", "\n", "        ", "\"\"\"In CPU-collectors, call ``agent.collector_initialize()`` e.g. to set up\n        vector epsilon-greedy, and reset the agent.\n        \"\"\"", "\n", "if", "getattr", "(", "self", ",", "\"agent\"", ",", "None", ")", "is", "not", "None", ":", "# Not in GPU collectors.", "\n", "            ", "self", ".", "agent", ".", "collector_initialize", "(", "\n", "global_B", "=", "self", ".", "global_B", ",", "# Args used e.g. for vector epsilon greedy.", "\n", "env_ranks", "=", "self", ".", "env_ranks", ",", "\n", ")", "\n", "self", ".", "agent", ".", "reset", "(", ")", "\n", "self", ".", "agent", ".", "sample_mode", "(", "itr", "=", "0", ")", "\n", "\n", "", "", "def", "collect_batch", "(", "self", ",", "agent_inputs", ",", "traj_infos", ")", ":", "\n", "        ", "\"\"\"Main data collection loop.\"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n", "", "def", "reset_if_needed", "(", "self", ",", "agent_inputs", ")", ":", "\n", "        ", "\"\"\"Reset agent and or env as needed, if doing between batches.\"\"\"", "\n", "pass", "\n", "\n", "\n", "", "", "class", "BaseEvalCollector", ":", "\n", "    ", "\"\"\"Collectors for offline agent evalution; not to record intermediate samples.\"\"\"", "\n", "\n", "def", "__init__", "(", "\n", "self", ",", "\n", "rank", ",", "\n", "envs", ",", "\n", "TrajInfoCls", ",", "\n", "traj_infos_queue", ",", "\n", "max_T", ",", "\n", "agent", "=", "None", ",", "\n", "sync", "=", "None", ",", "\n", "step_buffer_np", "=", "None", ",", "\n", ")", ":", "\n", "        ", "save__init__args", "(", "locals", "(", ")", ")", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.serial.sampler.SerialSampler.__init__": [[19, 23], ["rlpyt.samplers.base.BaseSampler.__init__"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.spaces.gym_wrapper.GymSpaceWrapper.__init__"], ["        ", "super", "(", ")", ".", "__init__", "(", "*", "args", ",", "CollectorCls", "=", "CollectorCls", ",", "\n", "eval_CollectorCls", "=", "eval_CollectorCls", ",", "**", "kwargs", ")", "\n", "\n", "", "def", "obtain_samples", "(", "self", ",", "itr", ")", ":", "\n", "        "]], "home.repos.pwc.inspect_result.astooke_rlpyt.serial.sampler.SerialSampler.initialize": [[24, 93], ["rlpyt.utils.seed.set_envs_seeds", "list", "agent.initialize", "rlpyt.samplers.buffer.build_samples_buffer", "sampler.SerialSampler.CollectorCls", "sampler.SerialSampler.start_envs", "sampler.SerialSampler.start_agent", "rlpyt.utils.logging.logger.log", "sampler.SerialSampler.EnvCls", "range", "traj_info_kwargs.items", "rlpyt.utils.seed.set_envs_seeds", "eval_CollectorCls", "range", "setattr", "sampler.SerialSampler.EnvCls", "range"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.utils.seed.set_envs_seeds", "home.repos.pwc.inspect_result.astooke_rlpyt.safe.cppo_agent.CppoLstmAgent.initialize", "home.repos.pwc.inspect_result.astooke_rlpyt.samplers.buffer.build_samples_buffer", "home.repos.pwc.inspect_result.astooke_rlpyt.samplers.collectors.DecorrelatingStartCollector.start_envs", "home.repos.pwc.inspect_result.astooke_rlpyt.samplers.collectors.BaseCollector.start_agent", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.console.log", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.collections.NamedArrayTuple.items", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.seed.set_envs_seeds"], ["\n", "self", ".", "agent", ".", "sync_shared_memory", "(", ")", "# New weights in workers, if needed.", "\n", "return", "super", "(", ")", ".", "obtain_samples", "(", "itr", ")", "\n", "\n", "", "def", "evaluate_agent", "(", "self", ",", "itr", ")", ":", "\n", "        ", "\"\"\"Like in ``obtain_samples()``, first sync agent shared memory.\"\"\"", "\n", "self", ".", "agent", ".", "sync_shared_memory", "(", ")", "\n", "return", "super", "(", ")", ".", "evaluate_agent", "(", "itr", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.astooke_rlpyt.serial.sampler.SerialSampler.obtain_samples": [[94, 106], ["sampler.SerialSampler.collector.collect_batch", "sampler.SerialSampler.collector.reset_if_needed"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.async_.collectors.DoubleBufferCollectorMixin.collect_batch", "home.repos.pwc.inspect_result.astooke_rlpyt.gpu.collectors.GpuWaitResetCollector.reset_if_needed"], []], "home.repos.pwc.inspect_result.astooke_rlpyt.serial.sampler.SerialSampler.evaluate_agent": [[107, 110], ["sampler.SerialSampler.eval_collector.collect_evaluation"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.serial.collectors.SerialEvalCollector.collect_evaluation"], []], "home.repos.pwc.inspect_result.astooke_rlpyt.async_.action_server.AsyncActionServer.serve_actions_evaluation": [[11, 44], ["action_server.AsyncActionServer.agent.reset", "rlpyt.agents.base.AgentInputs", "range", "action_server.AsyncActionServer.agent.step", "b.acquire", "b.acquire", "numpy.where", "action_server.AsyncActionServer.agent.reset_one", "w.release", "b.acquire", "w.acquire"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.safe.safety_gym_env.SafetyGymEnvWrapper.reset", "home.repos.pwc.inspect_result.astooke_rlpyt.safe.safety_gym_env.SafetyGymTrajInfo.step", "home.repos.pwc.inspect_result.astooke_rlpyt.agents.base.RecurrentAgentMixin.reset_one"], ["\n", "class", "ActionServer", ":", "\n", "    ", "\"\"\"Mixin class with methods for serving actions to worker processes which execute\n    environment steps.\n    \"\"\"", "\n", "\n", "def", "serve_actions", "(", "self", ",", "itr", ")", ":", "\n", "        ", "\"\"\"Called in master process during ``obtain_samples()``.\n\n        Performs agent action- selection loop in concert with workers\n        executing environment steps.  Uses shared memory buffers to\n        communicate agent/environment data at each time step.  Uses semaphores\n        for synchronization: one per worker to acquire when they finish\n        writing the next step of observations, one per worker to release when\n        master has written the next actions.  Resets the agent one B-index at a time when the\n        corresponding environment resets (i.e. agent's recurrent state, with\n        leading dimension ``batch_B``).\n\n        Also communicates ``agent_info`` to workers, which are responsible\n        for recording all data into the batch buffer.\n\n        If requested, collects additional agent value estimation of final\n        observation for bootstrapping (the one thing written to the batch\n        buffer here).\n\n\n        .. warning::\n            If trying to modify, must be careful to keep correct logic of the semaphores,\n            to make sure they drain properly.  If a semaphore ends up with an extra release,\n            synchronization can be lost silently, leading to wrong and confusing results.\n        \"\"\"", "\n", "obs_ready", ",", "act_ready", "=", "self", ".", "sync", ".", "obs_ready", ",", "self", ".", "sync", ".", "act_ready", "\n", "step_np", ",", "agent_inputs", "=", "self", ".", "step_buffer_np", ",", "self", ".", "agent_inputs", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.async_.action_server.AsyncAlternatingActionServer.serve_actions_evaluation": [[48, 95], ["action_server.AsyncAlternatingActionServer.agent.reset", "range", "range", "b.acquire", "action_server.AsyncAlternatingActionServer.agent.step", "b.acquire", "w.acquire", "b.acquire", "numpy.where", "action_server.AsyncAlternatingActionServer.agent.reset_one", "w.release", "b.acquire", "w.release"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.safe.safety_gym_env.SafetyGymEnvWrapper.reset", "home.repos.pwc.inspect_result.astooke_rlpyt.safe.safety_gym_env.SafetyGymTrajInfo.step", "home.repos.pwc.inspect_result.astooke_rlpyt.agents.base.RecurrentAgentMixin.reset_one"], ["# assert not b.acquire(block=False)  # Debug check.", "\n", "", "if", "self", ".", "mid_batch_reset", "and", "np", ".", "any", "(", "step_np", ".", "done", ")", ":", "\n", "                ", "for", "b_reset", "in", "np", ".", "where", "(", "step_np", ".", "done", ")", "[", "0", "]", ":", "\n", "                    ", "step_np", ".", "action", "[", "b_reset", "]", "=", "0", "# Null prev_action into agent.", "\n", "step_np", ".", "reward", "[", "b_reset", "]", "=", "0", "# Null prev_reward into agent.", "\n", "self", ".", "agent", ".", "reset_one", "(", "idx", "=", "b_reset", ")", "\n", "", "", "action", ",", "agent_info", "=", "self", ".", "agent", ".", "step", "(", "*", "agent_inputs", ")", "\n", "step_np", ".", "action", "[", ":", "]", "=", "action", "# Worker applies to env.", "\n", "step_np", ".", "agent_info", "[", ":", "]", "=", "agent_info", "# Worker sends to traj_info.", "\n", "for", "w", "in", "act_ready", ":", "\n", "# assert not w.acquire(block=False)  # Debug check.", "\n", "                ", "w", ".", "release", "(", ")", "# Signal to worker.", "\n", "\n", "", "", "for", "b", "in", "obs_ready", ":", "\n", "            ", "b", ".", "acquire", "(", ")", "\n", "assert", "not", "b", ".", "acquire", "(", "block", "=", "False", ")", "# Debug check.", "\n", "", "if", "\"bootstrap_value\"", "in", "self", ".", "samples_np", ".", "agent", ":", "\n", "            ", "self", ".", "samples_np", ".", "agent", ".", "bootstrap_value", "[", ":", "]", "=", "self", ".", "agent", ".", "value", "(", "\n", "*", "agent_inputs", ")", "\n", "", "if", "np", ".", "any", "(", "step_np", ".", "done", ")", ":", "# Reset at end of batch; ready for next.", "\n", "            ", "for", "b_reset", "in", "np", ".", "where", "(", "step_np", ".", "done", ")", "[", "0", "]", ":", "\n", "                ", "step_np", ".", "action", "[", "b_reset", "]", "=", "0", "# Null prev_action into agent.", "\n", "step_np", ".", "reward", "[", "b_reset", "]", "=", "0", "# Null prev_reward into agent.", "\n", "self", ".", "agent", ".", "reset_one", "(", "idx", "=", "b_reset", ")", "\n", "# step_np.done[:] = False  # Worker resets at start of next.", "\n", "", "", "for", "w", "in", "act_ready", ":", "\n", "            ", "assert", "not", "w", ".", "acquire", "(", "block", "=", "False", ")", "# Debug check.", "\n", "\n", "", "", "def", "serve_actions_evaluation", "(", "self", ",", "itr", ")", ":", "\n", "        ", "\"\"\"Similar to ``serve_actions()``.  If a maximum number of eval trajectories\n        was specified, keeps track of the number completed and terminates evaluation\n        if the max is reached.  Returns a list of completed trajectory-info objects.\n        \"\"\"", "\n", "obs_ready", ",", "act_ready", "=", "self", ".", "sync", ".", "obs_ready", ",", "self", ".", "sync", ".", "act_ready", "\n", "step_np", ",", "step_pyt", "=", "self", ".", "eval_step_buffer_np", ",", "self", ".", "eval_step_buffer_pyt", "\n", "traj_infos", "=", "list", "(", ")", "\n", "self", ".", "agent", ".", "reset", "(", ")", "\n", "agent_inputs", "=", "AgentInputs", "(", "step_pyt", ".", "observation", ",", "step_pyt", ".", "action", ",", "\n", "step_pyt", ".", "reward", ")", "# Fixed buffer objects.", "\n", "\n", "for", "t", "in", "range", "(", "self", ".", "eval_max_T", ")", ":", "\n", "            ", "if", "t", "%", "EVAL_TRAJ_CHECK", "==", "0", ":", "# (While workers stepping.)", "\n", "                ", "traj_infos", ".", "extend", "(", "drain_queue", "(", "self", ".", "eval_traj_infos_queue", ",", "\n", "guard_sentinel", "=", "True", ")", ")", "\n", "", "for", "b", "in", "obs_ready", ":", "\n", "                ", "b", ".", "acquire", "(", ")", "\n", "# assert not b.acquire(block=False)  # Debug check.", "\n", "", "for", "b_reset", "in", "np", ".", "where", "(", "step_np", ".", "done", ")", "[", "0", "]", ":", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.async_.action_server.AsyncNoOverlapAlternatingActionServer.serve_actions_evaluation": [[101, 170], ["action_server.AsyncNoOverlapAlternatingActionServer.agent.reset", "action_server.AsyncNoOverlapAlternatingActionServer.agent.step", "action_server.AsyncNoOverlapAlternatingActionServer.agent.step", "range", "b.acquire", "b.acquire", "w.release", "range", "w.release", "b.acquire", "action_server.AsyncNoOverlapAlternatingActionServer.agent.step", "b.acquire", "w.acquire", "b.acquire", "w.release", "numpy.where", "action_server.AsyncNoOverlapAlternatingActionServer.agent.reset_one"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.safe.safety_gym_env.SafetyGymEnvWrapper.reset", "home.repos.pwc.inspect_result.astooke_rlpyt.safe.safety_gym_env.SafetyGymTrajInfo.step", "home.repos.pwc.inspect_result.astooke_rlpyt.safe.safety_gym_env.SafetyGymTrajInfo.step", "home.repos.pwc.inspect_result.astooke_rlpyt.safe.safety_gym_env.SafetyGymTrajInfo.step", "home.repos.pwc.inspect_result.astooke_rlpyt.agents.base.RecurrentAgentMixin.reset_one"], ["step_np", ".", "agent_info", "[", ":", "]", "=", "agent_info", "\n", "if", "self", ".", "eval_max_trajectories", "is", "not", "None", "and", "t", "%", "EVAL_TRAJ_CHECK", "==", "0", ":", "\n", "                ", "self", ".", "sync", ".", "stop_eval", ".", "value", "=", "len", "(", "traj_infos", ")", ">=", "self", ".", "eval_max_trajectories", "\n", "", "for", "w", "in", "act_ready", ":", "\n", "# assert not w.acquire(block=False)  # Debug check.", "\n", "                ", "w", ".", "release", "(", ")", "\n", "", "if", "self", ".", "sync", ".", "stop_eval", ".", "value", ":", "\n", "                ", "logger", ".", "log", "(", "\"Evaluation reach max num trajectories \"", "\n", "f\"({self.eval_max_trajectories}).\"", ")", "\n", "break", "\n", "", "", "if", "t", "==", "self", ".", "eval_max_T", "-", "1", "and", "self", ".", "eval_max_trajectories", "is", "not", "None", ":", "\n", "            ", "logger", ".", "log", "(", "\"Evaluation reached max num time steps \"", "\n", "f\"({self.eval_max_T}).\"", ")", "\n", "", "for", "b", "in", "obs_ready", ":", "\n", "            ", "b", ".", "acquire", "(", ")", "# Workers always do extra release; drain it.", "\n", "assert", "not", "b", ".", "acquire", "(", "block", "=", "False", ")", "# Debug check.", "\n", "", "for", "w", "in", "act_ready", ":", "\n", "            ", "assert", "not", "w", ".", "acquire", "(", "block", "=", "False", ")", "# Debug check.", "\n", "\n", "", "return", "traj_infos", "\n", "\n", "\n", "", "", "class", "AlternatingActionServer", ":", "\n", "    ", "\"\"\"Mixin class for serving actions in the alternating GPU sampler.  The\n    synchronization format in this class allows the two worker groups to\n    execute partially simultaneously; workers wait to step for their new\n    action to be ready but do not wait for the other set of workers to be done\n    stepping.\n    \"\"\"", "\n", "\n", "def", "serve_actions", "(", "self", ",", "itr", ")", ":", "\n", "        ", "obs_ready_pair", "=", "self", ".", "obs_ready_pair", "\n", "act_ready_pair", "=", "self", ".", "act_ready_pair", "\n", "step_np_pair", "=", "self", ".", "step_buffer_np_pair", "\n", "agent_inputs_pair", "=", "self", ".", "agent_inputs_pair", "\n", "\n", "# Can easily write overlap and no overlap of workers versions.", "\n", "for", "t", "in", "range", "(", "self", ".", "batch_spec", ".", "T", ")", ":", "\n", "            ", "for", "alt", "in", "range", "(", "2", ")", ":", "\n", "                ", "step_h", "=", "step_np_pair", "[", "alt", "]", "\n", "for", "b", "in", "obs_ready_pair", "[", "alt", "]", ":", "\n", "                    ", "b", ".", "acquire", "(", ")", "# Workers written obs and rew, first prev_act.", "\n", "# assert not b.acquire(block=False)  # Debug check.", "\n", "", "if", "self", ".", "mid_batch_reset", "and", "np", ".", "any", "(", "step_h", ".", "done", ")", ":", "\n", "                    ", "for", "b_reset", "in", "np", ".", "where", "(", "step_h", ".", "done", ")", "[", "0", "]", ":", "\n", "                        ", "step_h", ".", "action", "[", "b_reset", "]", "=", "0", "# Null prev_action into agent.", "\n", "step_h", ".", "reward", "[", "b_reset", "]", "=", "0", "# Null prev_reward into agent.", "\n", "self", ".", "agent", ".", "reset_one", "(", "idx", "=", "b_reset", ")", "\n", "", "", "action", ",", "agent_info", "=", "self", ".", "agent", ".", "step", "(", "*", "agent_inputs_pair", "[", "alt", "]", ")", "\n", "step_h", ".", "action", "[", ":", "]", "=", "action", "# Worker applies to env.", "\n", "step_h", ".", "agent_info", "[", ":", "]", "=", "agent_info", "# Worker sends to traj_info.", "\n", "for", "w", "in", "act_ready_pair", "[", "alt", "]", ":", "# Final release.", "\n", "# assert not w.acquire(block=False)  # Debug check.", "\n", "                    ", "w", ".", "release", "(", ")", "# Signal to worker.", "\n", "\n", "", "", "", "for", "alt", "in", "range", "(", "2", ")", ":", "\n", "            ", "step_h", "=", "step_np_pair", "[", "alt", "]", "\n", "for", "b", "in", "obs_ready_pair", "[", "alt", "]", ":", "\n", "                ", "b", ".", "acquire", "(", ")", "\n", "# assert not b.acquire(block=False)  # Debug check.", "\n", "", "if", "\"bootstrap_value\"", "in", "self", ".", "samples_np", ".", "agent", ":", "\n", "                ", "self", ".", "bootstrap_value_pair", "[", "alt", "]", "[", ":", "]", "=", "self", ".", "agent", ".", "value", "(", "*", "agent_inputs_pair", "[", "alt", "]", ")", "\n", "", "if", "np", ".", "any", "(", "step_h", ".", "done", ")", ":", "\n", "                ", "for", "b_reset", "in", "np", ".", "where", "(", "step_h", ".", "done", ")", "[", "0", "]", ":", "\n", "                    ", "step_h", ".", "action", "[", "b_reset", "]", "=", "0", "\n", "step_h", ".", "reward", "[", "b_reset", "]", "=", "0", "\n", "self", ".", "agent", ".", "reset_one", "(", "idx", "=", "b_reset", ")", "\n", "", "", "self", ".", "agent", ".", "toggle_alt", "(", ")", "# Value and reset method do not advance rnn state.", "\n", "\n", "", "for", "b", "in", "self", ".", "sync", ".", "obs_ready", ":", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.async_.base.AsyncSamplerMixin.async_initialize": [[19, 47], ["base.AsyncSamplerMixin.EnvCls", "agent.initialize", "rlpyt.samplers.buffer.build_samples_buffer", "rlpyt.samplers.buffer.build_samples_buffer", "base.AsyncSamplerMixin.close", "rlpyt.utils.seed.make_seed", "traj_info_kwargs.items", "list", "setattr", "range"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.safe.cppo_agent.CppoLstmAgent.initialize", "home.repos.pwc.inspect_result.astooke_rlpyt.samplers.buffer.build_samples_buffer", "home.repos.pwc.inspect_result.astooke_rlpyt.samplers.buffer.build_samples_buffer", "home.repos.pwc.inspect_result.astooke_rlpyt.envs.dmlab.DmlabEnv.close", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.seed.make_seed", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.collections.NamedArrayTuple.items"], ["\n", "raise", "NotImplementedError", "\n", "\n", "", "def", "async_initialize", "(", "self", ",", "agent", ",", "sampler_n_itr", ",", "batch_spec", ",", "mid_batch_reset", ",", "\n", "examples", ",", "world_size", "=", "1", ")", ":", "\n", "        ", "\"\"\"Called instead of ``initialize()`` in async runner (not needed unless\n        using async runner). Should return async replay_buffer using shared\n        memory.\"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n", "", "def", "optim_initialize", "(", "self", ",", "rank", "=", "0", ")", ":", "\n", "        ", "\"\"\"Called in async runner which requires two stages of initialization;\n        might also be used in ``initialize()`` to avoid redundant code.\"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n", "", "def", "optimize_agent", "(", "self", ",", "itr", ",", "samples", "=", "None", ",", "sampler_itr", "=", "None", ")", ":", "\n", "        "]], "home.repos.pwc.inspect_result.astooke_rlpyt.async_.base.AsyncParallelSamplerMixin.obtain_samples": [[59, 72], ["base.AsyncParallelSamplerMixin.ctrl.barrier_in.wait", "base.AsyncParallelSamplerMixin.ctrl.barrier_out.wait", "rlpyt.utils.synchronize.drain_queue"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.utils.synchronize.drain_queue"], ["return", "self", ".", "optimizer", ".", "state_dict", "(", ")", "\n", "\n", "", "def", "load_optim_state_dict", "(", "self", ",", "state_dict", ")", ":", "\n", "        ", "\"\"\"Load an optimizer state dict; should expect the format returned\n        from ``optim_state_dict().``\"\"\"", "\n", "self", ".", "optimizer", ".", "load_state_dict", "(", "state_dict", ")", "\n", "\n", "", "@", "property", "\n", "def", "batch_size", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_batch_size", "# For logging at least.", "\n", "", "", ""]], "home.repos.pwc.inspect_result.astooke_rlpyt.async_.base.AsyncParallelSamplerMixin._agent_init": [[73, 75], ["None"], "methods", ["None"], []], "home.repos.pwc.inspect_result.astooke_rlpyt.async_.base.AsyncParallelSamplerMixin._build_buffers": [[76, 78], ["None"], "methods", ["None"], []], "home.repos.pwc.inspect_result.astooke_rlpyt.async_.base.AsyncParallelSamplerMixin._build_parallel_ctrl": [[79, 83], ["super()._build_parallel_ctrl", "multiprocessing.RawValue"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.async_.gpu_sampler.AsyncGpuSamplerBase._build_parallel_ctrl"], []], "home.repos.pwc.inspect_result.astooke_rlpyt.async_.base.AsyncParallelSamplerMixin._assemble_workers_kwargs": [[85, 96], ["super()._assemble_workers_kwargs", "enumerate", "slice", "tuple"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.async_.gpu_sampler.AsyncGpuSamplerBase._assemble_workers_kwargs"], []], "home.repos.pwc.inspect_result.astooke_rlpyt.async_.cpu_sampler.AsyncCpuSampler.__init__": [[24, 28], ["rlpyt.samplers.async_.base.AsyncParallelSamplerMixin.__init__"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.spaces.gym_wrapper.GymSpaceWrapper.__init__"], ["def", "__init__", "(", "self", ",", "*", "args", ",", "CollectorCls", "=", "DbCpuResetCollector", ",", "\n", "eval_CollectorCls", "=", "CpuEvalCollector", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "*", "args", ",", "CollectorCls", "=", "CollectorCls", ",", "\n", "eval_CollectorCls", "=", "eval_CollectorCls", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.async_.cpu_sampler.AsyncCpuSampler.initialize": [[33, 52], ["psutil.Process", "affinity.get", "torch.set_num_threads", "cpu_sampler.AsyncCpuSampler.agent.async_cpu", "super().initialize", "psutil.Process.cpu_affinity"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.utils.collections.NamedArrayTuple.get", "home.repos.pwc.inspect_result.astooke_rlpyt.agents.dmc_sac_agent.SacAgent.async_cpu", "home.repos.pwc.inspect_result.astooke_rlpyt.safe.cppo_agent.CppoLstmAgent.initialize"], ["", "def", "initialize", "(", "self", ",", "affinity", ")", ":", "\n", "        ", "\"\"\"\n        Runs inside the main sampler process.  Sets process hardware affinity\n        and calls the ``agent.async_cpu()`` initialization.  Then proceeds with\n        usual parallel sampler initialization.\n        \"\"\"", "\n", "p", "=", "psutil", ".", "Process", "(", ")", "\n", "if", "affinity", ".", "get", "(", "\"set_affinity\"", ",", "True", ")", ":", "\n", "            ", "p", ".", "cpu_affinity", "(", "affinity", "[", "\"master_cpus\"", "]", ")", "\n", "", "torch", ".", "set_num_threads", "(", "1", ")", "# Needed to prevent MKL hang :( .", "\n", "self", ".", "agent", ".", "async_cpu", "(", "share_memory", "=", "True", ")", "\n", "super", "(", ")", ".", "initialize", "(", "\n", "agent", "=", "self", ".", "agent", ",", "\n", "affinity", "=", "affinity", ",", "\n", "seed", "=", "self", ".", "seed", ",", "\n", "bootstrap_value", "=", "None", ",", "# Don't need here.", "\n", "traj_info_kwargs", "=", "None", ",", "# Already done.", "\n", "world_size", "=", "1", ",", "\n", "rank", "=", "0", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.async_.cpu_sampler.AsyncCpuSampler.obtain_samples": [[54, 60], ["cpu_sampler.AsyncCpuSampler.agent.recv_shared_memory", "super().obtain_samples"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.agents.base.BaseAgent.recv_shared_memory", "home.repos.pwc.inspect_result.astooke_rlpyt.async_.serial_sampler.AsyncSerialSampler.obtain_samples"], ["", "def", "obtain_samples", "(", "self", ",", "itr", ",", "db_idx", ")", ":", "\n", "        ", "\"\"\"Calls the agent to retrieve new parameter values from the training\n        process, then proceeds with base async parallel method.\n        \"\"\"", "\n", "self", ".", "agent", ".", "recv_shared_memory", "(", ")", "\n", "return", "super", "(", ")", ".", "obtain_samples", "(", "itr", ",", "db_idx", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.async_.cpu_sampler.AsyncCpuSampler.evaluate_agent": [[61, 67], ["cpu_sampler.AsyncCpuSampler.agent.recv_shared_memory", "super().evaluate_agent"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.agents.base.BaseAgent.recv_shared_memory", "home.repos.pwc.inspect_result.astooke_rlpyt.runners.minibatch_rl.MinibatchRlEval.evaluate_agent"], ["", "def", "evaluate_agent", "(", "self", ",", "itr", ")", ":", "\n", "        ", "\"\"\"Calls the agent to retrieve new parameter values from the training\n        process, then proceeds with base async parallel method.\n        \"\"\"", "\n", "self", ".", "agent", ".", "recv_shared_memory", "(", ")", "\n", "return", "super", "(", ")", ".", "evaluate_agent", "(", "itr", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.astooke_rlpyt.async_.gpu_sampler.AsyncGpuSamplerBase.__init__": [[30, 34], ["rlpyt.samplers.async_.base.AsyncParallelSamplerMixin.__init__"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.spaces.gym_wrapper.GymSpaceWrapper.__init__"], ["def", "__init__", "(", "self", ",", "*", "args", ",", "CollectorCls", "=", "DbGpuResetCollector", ",", "\n", "eval_CollectorCls", "=", "GpuEvalCollector", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "*", "args", ",", "CollectorCls", "=", "CollectorCls", ",", "\n", "eval_CollectorCls", "=", "eval_CollectorCls", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.async_.gpu_sampler.AsyncGpuSamplerBase.initialize": [[39, 68], ["torch.set_num_threads", "len", "gpu_sampler.AsyncGpuSamplerBase._get_n_envs_lists", "len", "sum", "gpu_sampler.AsyncGpuSamplerBase._build_parallel_ctrl", "gpu_sampler.AsyncGpuSamplerBase._assemble_servers_kwargs", "gpu_sampler.AsyncGpuSamplerBase.ctrl.barrier_out.wait", "max", "rlpyt.utils.logging.logger.log", "int", "multiprocessing.Process", "s.start", "len"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.async_.alternating_sampler.AsyncAlternatingSamplerBase._get_n_envs_lists", "home.repos.pwc.inspect_result.astooke_rlpyt.async_.gpu_sampler.AsyncGpuSamplerBase._build_parallel_ctrl", "home.repos.pwc.inspect_result.astooke_rlpyt.async_.gpu_sampler.AsyncGpuSamplerBase._assemble_servers_kwargs", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.console.log"], ["", "def", "initialize", "(", "self", ",", "affinity", ")", ":", "\n", "        ", "\"\"\"Initialization inside the main sampler process.  Builds one level\n        of parallel synchronization objects, and forks action-server processes,\n        one per GPU to be used.\n        \"\"\"", "\n", "torch", ".", "set_num_threads", "(", "1", ")", "# Needed to avoid MKL hang :( .", "\n", "self", ".", "world_size", "=", "n_server", "=", "len", "(", "affinity", ")", "\n", "n_envs_lists", "=", "self", ".", "_get_n_envs_lists", "(", "affinity", ")", "\n", "n_server", "=", "len", "(", "n_envs_lists", ")", "\n", "n_worker", "=", "sum", "(", "[", "len", "(", "n_envs_list", ")", "for", "n_envs_list", "in", "n_envs_lists", "]", ")", "\n", "self", ".", "n_worker", "=", "n_worker", "\n", "\n", "if", "self", ".", "eval_n_envs", ">", "0", ":", "\n", "            ", "self", ".", "eval_n_envs_per", "=", "max", "(", "1", ",", "self", ".", "eval_n_envs", "//", "n_worker", ")", "\n", "self", ".", "eval_n_envs", "=", "eval_n_envs", "=", "self", ".", "eval_n_envs_per", "*", "n_worker", "\n", "logger", ".", "log", "(", "f\"Total parallel evaluation envs: {eval_n_envs}.\"", ")", "\n", "self", ".", "eval_max_T", "=", "eval_max_T", "=", "int", "(", "self", ".", "eval_max_steps", "//", "eval_n_envs", ")", "\n", "\n", "", "self", ".", "_build_parallel_ctrl", "(", "n_server", ",", "n_worker", ")", "\n", "\n", "servers_kwargs", "=", "self", ".", "_assemble_servers_kwargs", "(", "affinity", ",", "self", ".", "seed", ",", "\n", "n_envs_lists", ")", "\n", "servers", "=", "[", "mp", ".", "Process", "(", "target", "=", "self", ".", "action_server_process", ",", "\n", "kwargs", "=", "s_kwargs", ")", "\n", "for", "s_kwargs", "in", "servers_kwargs", "]", "\n", "for", "s", "in", "servers", ":", "\n", "            ", "s", ".", "start", "(", ")", "\n", "", "self", ".", "servers", "=", "servers", "\n", "self", ".", "ctrl", ".", "barrier_out", ".", "wait", "(", ")", "# Wait for workers to decorrelate envs.", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.async_.gpu_sampler.AsyncGpuSamplerBase.shutdown": [[71, 76], ["gpu_sampler.AsyncGpuSamplerBase.ctrl.barrier_in.wait", "s.join"], "methods", ["None"], ["", "def", "shutdown", "(", "self", ")", ":", "\n", "        ", "self", ".", "ctrl", ".", "quit", ".", "value", "=", "True", "\n", "self", ".", "ctrl", ".", "barrier_in", ".", "wait", "(", ")", "\n", "for", "s", "in", "self", ".", "servers", ":", "\n", "            ", "s", ".", "join", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.async_.gpu_sampler.AsyncGpuSamplerBase._get_n_envs_lists": [[77, 98], ["len", "list", "zip", "len", "ValueError", "n_workers.count", "len", "rlpyt.utils.logging.logger.log", "range", "list.append", "gpu_sampler.AsyncGpuSamplerBase._get_n_envs_list"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.logging.console.log", "home.repos.pwc.inspect_result.astooke_rlpyt.async_.alternating_sampler.AsyncAlternatingSamplerBase._get_n_envs_list"], ["", "", "def", "_get_n_envs_lists", "(", "self", ",", "affinity", ")", ":", "\n", "        ", "B", "=", "self", ".", "batch_spec", ".", "B", "\n", "n_server", "=", "len", "(", "affinity", ")", "\n", "n_workers", "=", "[", "len", "(", "aff", "[", "\"workers_cpus\"", "]", ")", "for", "aff", "in", "affinity", "]", "\n", "if", "B", "<", "n_server", ":", "\n", "            ", "raise", "ValueError", "(", "f\"Request fewer envs ({B}) than action servers \"", "\n", "f\"({n_server}).\"", ")", "\n", "", "server_Bs", "=", "[", "B", "//", "n_server", "]", "*", "n_server", "\n", "if", "n_workers", ".", "count", "(", "n_workers", "[", "0", "]", ")", "!=", "len", "(", "n_workers", ")", ":", "\n", "            ", "logger", ".", "log", "(", "\"WARNING: affinity requested different number of \"", "\n", "\"environment workers per action server, but environments \"", "\n", "\"will be assigned equally across action servers anyway.\"", ")", "\n", "", "if", "B", "%", "n_server", ">", "0", ":", "\n", "            ", "for", "s", "in", "range", "(", "B", "%", "n_server", ")", ":", "\n", "                ", "server_Bs", "[", "s", "]", "+=", "1", "# Spread across action servers.", "\n", "\n", "", "", "n_envs_lists", "=", "list", "(", ")", "\n", "for", "s_worker", ",", "s_B", "in", "zip", "(", "n_workers", ",", "server_Bs", ")", ":", "\n", "            ", "n_envs_lists", ".", "append", "(", "self", ".", "_get_n_envs_list", "(", "n_worker", "=", "s_worker", ",", "B", "=", "s_B", ")", ")", "\n", "\n", "", "return", "n_envs_lists", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.async_.gpu_sampler.AsyncGpuSamplerBase._build_parallel_ctrl": [[99, 101], ["super()._build_parallel_ctrl"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.async_.gpu_sampler.AsyncGpuSamplerBase._build_parallel_ctrl"], ["", "def", "_build_parallel_ctrl", "(", "self", ",", "n_server", ",", "n_worker", ")", ":", "\n", "        ", "super", "(", ")", ".", "_build_parallel_ctrl", "(", "n_worker", "+", "n_server", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.async_.gpu_sampler.AsyncGpuSamplerBase._assemble_servers_kwargs": [[102, 123], ["list", "range", "len", "len", "sum", "slice", "dict", "list.append", "list", "tuple", "range"], "methods", ["None"], ["", "def", "_assemble_servers_kwargs", "(", "self", ",", "affinity", ",", "seed", ",", "n_envs_lists", ")", ":", "\n", "        ", "servers_kwargs", "=", "list", "(", ")", "\n", "i_env", "=", "0", "\n", "i_worker", "=", "0", "\n", "for", "rank", "in", "range", "(", "len", "(", "affinity", ")", ")", ":", "\n", "            ", "n_worker", "=", "len", "(", "affinity", "[", "rank", "]", "[", "\"workers_cpus\"", "]", ")", "\n", "n_env", "=", "sum", "(", "n_envs_lists", "[", "rank", "]", ")", "\n", "slice_B", "=", "slice", "(", "i_env", ",", "i_env", "+", "n_env", ")", "\n", "server_kwargs", "=", "dict", "(", "\n", "rank", "=", "rank", ",", "\n", "env_ranks", "=", "list", "(", "range", "(", "i_env", ",", "i_env", "+", "n_env", ")", ")", ",", "\n", "double_buffer_slice", "=", "tuple", "(", "buf", "[", ":", ",", "slice_B", "]", "\n", "for", "buf", "in", "self", ".", "double_buffer", ")", ",", "\n", "affinity", "=", "affinity", "[", "rank", "]", ",", "\n", "n_envs_list", "=", "n_envs_lists", "[", "rank", "]", ",", "\n", "seed", "=", "seed", "+", "i_worker", ",", "\n", ")", "\n", "servers_kwargs", ".", "append", "(", "server_kwargs", ")", "\n", "i_worker", "+=", "n_worker", "\n", "i_env", "+=", "n_env", "\n", "", "return", "servers_kwargs", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.async_.gpu_sampler.AsyncGpuSamplerBase.action_server_process": [[128, 173], ["psutil.Process", "affinity.get", "torch.set_num_threads", "gpu_sampler.AsyncGpuSamplerBase.launch_workers", "gpu_sampler.AsyncGpuSamplerBase.agent.to_device", "gpu_sampler.AsyncGpuSamplerBase.agent.collector_initialize", "gpu_sampler.AsyncGpuSamplerBase.ctrl.barrier_out.wait", "gpu_sampler.AsyncGpuSamplerBase.shutdown_workers", "psutil.Process.cpu_affinity", "gpu_sampler.AsyncGpuSamplerBase.ctrl.barrier_in.wait", "gpu_sampler.AsyncGpuSamplerBase.agent.recv_shared_memory", "gpu_sampler.AsyncGpuSamplerBase.ctrl.barrier_out.wait", "gpu_sampler.AsyncGpuSamplerBase.agent.eval_mode", "gpu_sampler.AsyncGpuSamplerBase.serve_actions_evaluation", "gpu_sampler.AsyncGpuSamplerBase.agent.sample_mode", "hasattr", "gpu_sampler.AsyncGpuSamplerBase.serve_actions"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.utils.collections.NamedArrayTuple.get", "home.repos.pwc.inspect_result.astooke_rlpyt.runners.sync_rl.SyncRlMixin.launch_workers", "home.repos.pwc.inspect_result.astooke_rlpyt.safe.cppo_agent.CppoLstmAgent.to_device", "home.repos.pwc.inspect_result.astooke_rlpyt.agents.base.BaseAgent.collector_initialize", "home.repos.pwc.inspect_result.astooke_rlpyt.async_.gpu_sampler.AsyncGpuSamplerBase.shutdown_workers", "home.repos.pwc.inspect_result.astooke_rlpyt.agents.base.BaseAgent.recv_shared_memory", "home.repos.pwc.inspect_result.astooke_rlpyt.agents.dmc_sac_agent.SacAgent.eval_mode", "home.repos.pwc.inspect_result.astooke_rlpyt.async_.action_server.AsyncNoOverlapAlternatingActionServer.serve_actions_evaluation", "home.repos.pwc.inspect_result.astooke_rlpyt.agents.dmc_sac_agent.SacAgent.sample_mode", "home.repos.pwc.inspect_result.astooke_rlpyt.gpu.action_server.NoOverlapAlternatingActionServer.serve_actions"], ["", "def", "action_server_process", "(", "self", ",", "rank", ",", "env_ranks", ",", "double_buffer_slice", ",", "\n", "affinity", ",", "seed", ",", "n_envs_list", ")", ":", "\n", "        ", "\"\"\"Target method used for forking action-server process(es) from the\n        main sampler process.  By inheriting the sampler object from the\n        sampler process, can more easily pass args to the environment worker\n        processes, which are forked from here.\n\n        Assigns hardware affinity, and then forks parallel worker processes\n        and moves agent model to device.  Then enters infinite loop: waits for\n        signals from main sampler process to collect training samples or\n        perform evaluation, and then serves actions during collection.  At\n        every loop, calls agent to retrieve new parameter values from the\n        training process, which are communicated through shared CPU memory.\n        \"\"\"", "\n", "self", ".", "rank", "=", "rank", "\n", "p", "=", "psutil", ".", "Process", "(", ")", "\n", "if", "affinity", ".", "get", "(", "\"set_affinity\"", ",", "True", ")", ":", "\n", "            ", "p", ".", "cpu_affinity", "(", "affinity", "[", "\"master_cpus\"", "]", ")", "\n", "# torch.set_num_threads(affinity[\"master_torch_threads\"])", "\n", "", "torch", ".", "set_num_threads", "(", "1", ")", "# Possibly needed to avoid MKL hang.", "\n", "self", ".", "launch_workers", "(", "double_buffer_slice", ",", "affinity", ",", "seed", ",", "n_envs_list", ")", "\n", "self", ".", "agent", ".", "to_device", "(", "cuda_idx", "=", "affinity", "[", "\"cuda_idx\"", "]", ")", "\n", "self", ".", "agent", ".", "collector_initialize", "(", "global_B", "=", "self", ".", "batch_spec", ".", "B", ",", "# Not updated.", "\n", "env_ranks", "=", "env_ranks", ")", "# For vector eps-greedy.", "\n", "self", ".", "ctrl", ".", "barrier_out", ".", "wait", "(", ")", "# Wait for workers to decorrelate envs.", "\n", "\n", "while", "True", ":", "\n", "            ", "self", ".", "sync", ".", "stop_eval", ".", "value", "=", "False", "# Reset.", "\n", "self", ".", "ctrl", ".", "barrier_in", ".", "wait", "(", ")", "\n", "if", "self", ".", "ctrl", ".", "quit", ".", "value", ":", "\n", "                ", "break", "\n", "", "self", ".", "agent", ".", "recv_shared_memory", "(", ")", "\n", "if", "self", ".", "ctrl", ".", "do_eval", ".", "value", ":", "\n", "                ", "self", ".", "agent", ".", "eval_mode", "(", "self", ".", "ctrl", ".", "itr", ".", "value", ")", "\n", "self", ".", "serve_actions_evaluation", "(", "self", ".", "ctrl", ".", "itr", ".", "value", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "agent", ".", "sample_mode", "(", "self", ".", "ctrl", ".", "itr", ".", "value", ")", "\n", "# Only for bootstrap_value:", "\n", "self", ".", "samples_np", "=", "self", ".", "double_buffer", "[", "self", ".", "ctrl", ".", "db_idx", ".", "value", "]", "\n", "if", "hasattr", "(", "self", ",", "\"double_bootstrap_value_pair\"", ")", ":", "# Alternating sampler.", "\n", "                    ", "self", ".", "bootstrap_value_pair", "=", "self", ".", "double_bootstrap_value_pair", "[", "self", ".", "ctrl", ".", "db_idx", ".", "value", "]", "\n", "", "self", ".", "serve_actions", "(", "self", ".", "ctrl", ".", "itr", ".", "value", ")", "\n", "", "self", ".", "ctrl", ".", "barrier_out", ".", "wait", "(", ")", "\n", "", "self", ".", "shutdown_workers", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.async_.gpu_sampler.AsyncGpuSamplerBase.launch_workers": [[174, 215], ["len", "rlpyt.utils.collections.AttrDict", "rlpyt.samplers.parallel.gpu.sampler.build_step_buffer", "rlpyt.agents.base.AgentInputs", "gpu_sampler.AsyncGpuSamplerBase._assemble_common_kwargs", "gpu_sampler.AsyncGpuSamplerBase._assemble_workers_kwargs", "sum", "rlpyt.samplers.parallel.gpu.sampler.build_step_buffer", "rlpyt.agents.base.AgentInputs", "multiprocessing.Process", "w.start", "multiprocessing.RawValue", "multiprocessing.Semaphore", "multiprocessing.Semaphore", "dict", "range", "range"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.gpu.sampler.build_step_buffer", "home.repos.pwc.inspect_result.astooke_rlpyt.gpu.sampler.GpuSamplerBase._assemble_common_kwargs", "home.repos.pwc.inspect_result.astooke_rlpyt.async_.gpu_sampler.AsyncGpuSamplerBase._assemble_workers_kwargs", "home.repos.pwc.inspect_result.astooke_rlpyt.gpu.sampler.build_step_buffer"], ["", "def", "launch_workers", "(", "self", ",", "double_buffer_slice", ",", "affinity", ",", "seed", ",", "n_envs_list", ")", ":", "\n", "        ", "self", ".", "n_worker", "=", "n_worker", "=", "len", "(", "n_envs_list", ")", "\n", "# A little slight-of-hand to make 2-level signal:", "\n", "self", ".", "ctrl", ".", "stop_eval", "=", "self", ".", "sync", ".", "stop_eval", "\n", "self", ".", "sync", "=", "AttrDict", "(", "\n", "obs_ready", "=", "[", "mp", ".", "Semaphore", "(", "0", ")", "for", "_", "in", "range", "(", "n_worker", ")", "]", ",", "\n", "act_ready", "=", "[", "mp", ".", "Semaphore", "(", "0", ")", "for", "_", "in", "range", "(", "n_worker", ")", "]", ",", "\n", "stop_eval", "=", "mp", ".", "RawValue", "(", "ctypes", ".", "c_bool", ",", "False", ")", ",", "# Overwrite.", "\n", "# stop_eval=self.ctrl.stop_eval,  # No, make 2-level signal.", "\n", "db_idx", "=", "self", ".", "ctrl", ".", "db_idx", ",", "# Copy into sync which passes to Collector.", "\n", ")", "\n", "self", ".", "step_buffer_pyt", ",", "self", ".", "step_buffer_np", "=", "build_step_buffer", "(", "\n", "self", ".", "examples", ",", "sum", "(", "n_envs_list", ")", ")", "\n", "self", ".", "agent_inputs", "=", "AgentInputs", "(", "self", ".", "step_buffer_pyt", ".", "observation", ",", "\n", "self", ".", "step_buffer_pyt", ".", "action", ",", "self", ".", "step_buffer_pyt", ".", "reward", ")", "\n", "\n", "if", "self", ".", "eval_n_envs", ">", "0", ":", "\n", "            ", "eval_n_envs", "=", "self", ".", "eval_n_envs_per", "*", "n_worker", "\n", "eval_step_buffer_pyt", ",", "eval_step_buffer_np", "=", "build_step_buffer", "(", "\n", "self", ".", "examples", ",", "eval_n_envs", ")", "\n", "self", ".", "eval_step_buffer_pyt", "=", "eval_step_buffer_pyt", "\n", "self", ".", "eval_step_buffer_np", "=", "eval_step_buffer_np", "\n", "self", ".", "eval_agent_inputs", "=", "AgentInputs", "(", "\n", "self", ".", "eval_step_buffer_pyt", ".", "observation", ",", "\n", "self", ".", "eval_step_buffer_pyt", ".", "action", ",", "\n", "self", ".", "eval_step_buffer_pyt", ".", "reward", ",", "\n", ")", "\n", "# eval_max_T already made in earlier initialize.", "\n", "\n", "", "self", ".", "double_buffer", "=", "double_buffer_slice", "# Now only see my part.", "\n", "common_kwargs", "=", "self", ".", "_assemble_common_kwargs", "(", "affinity", ")", "\n", "common_kwargs", "[", "\"agent\"", "]", "=", "None", "# Remove.", "\n", "workers_kwargs", "=", "self", ".", "_assemble_workers_kwargs", "(", "affinity", ",", "seed", ",", "\n", "n_envs_list", ")", "\n", "\n", "# Yes, fork again.", "\n", "self", ".", "workers", "=", "[", "mp", ".", "Process", "(", "target", "=", "sampling_process", ",", "\n", "kwargs", "=", "dict", "(", "common_kwargs", "=", "common_kwargs", ",", "worker_kwargs", "=", "w_kwargs", ")", ")", "\n", "for", "w_kwargs", "in", "workers_kwargs", "]", "\n", "for", "w", "in", "self", ".", "workers", ":", "\n", "            ", "w", ".", "start", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.async_.gpu_sampler.AsyncGpuSamplerBase.shutdown_workers": [[216, 219], ["w.join"], "methods", ["None"], ["", "", "def", "shutdown_workers", "(", "self", ")", ":", "\n", "        ", "for", "w", "in", "self", ".", "workers", ":", "\n", "            ", "w", ".", "join", "(", ")", "# Already signaled to quit by central master.", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.async_.gpu_sampler.AsyncGpuSamplerBase._assemble_workers_kwargs": [[220, 241], ["super()._assemble_workers_kwargs", "enumerate", "slice", "rlpyt.utils.collections.AttrDict", "slice"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.async_.gpu_sampler.AsyncGpuSamplerBase._assemble_workers_kwargs"], ["", "", "def", "_assemble_workers_kwargs", "(", "self", ",", "affinity", ",", "seed", ",", "n_envs_list", ")", ":", "\n", "        ", "workers_kwargs", "=", "super", "(", ")", ".", "_assemble_workers_kwargs", "(", "affinity", ",", "seed", ",", "\n", "n_envs_list", ")", "\n", "i_env", "=", "0", "\n", "for", "rank", ",", "w_kwargs", "in", "enumerate", "(", "workers_kwargs", ")", ":", "\n", "            ", "n_envs", "=", "n_envs_list", "[", "rank", "]", "\n", "slice_B", "=", "slice", "(", "i_env", ",", "i_env", "+", "n_envs", ")", "\n", "w_kwargs", "[", "\"sync\"", "]", "=", "AttrDict", "(", "\n", "stop_eval", "=", "self", ".", "sync", ".", "stop_eval", ",", "\n", "obs_ready", "=", "self", ".", "sync", ".", "obs_ready", "[", "rank", "]", ",", "\n", "act_ready", "=", "self", ".", "sync", ".", "act_ready", "[", "rank", "]", ",", "\n", "db_idx", "=", "self", ".", "sync", ".", "db_idx", ",", "\n", ")", "\n", "w_kwargs", "[", "\"step_buffer_np\"", "]", "=", "self", ".", "step_buffer_np", "[", "slice_B", "]", "\n", "if", "self", ".", "eval_n_envs", ">", "0", ":", "\n", "                ", "eval_slice_B", "=", "slice", "(", "self", ".", "eval_n_envs_per", "*", "rank", ",", "\n", "self", ".", "eval_n_envs_per", "*", "(", "rank", "+", "1", ")", ")", "\n", "w_kwargs", "[", "\"eval_step_buffer_np\"", "]", "=", "self", ".", "eval_step_buffer_np", "[", "eval_slice_B", "]", "\n", "", "i_env", "+=", "n_envs", "\n", "", "return", "workers_kwargs", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.async_.collectors.DoubleBufferCollectorMixin.__init__": [[10, 14], ["super().__init__"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.spaces.gym_wrapper.GymSpaceWrapper.__init__"], ["class", "BaseCollector", ":", "\n", "    ", "\"\"\"Class that steps environments, possibly in worker process.\"\"\"", "\n", "\n", "def", "__init__", "(", "\n", "self", ",", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.async_.collectors.DoubleBufferCollectorMixin.collect_batch": [[15, 19], ["super().collect_batch"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.async_.collectors.DoubleBufferCollectorMixin.collect_batch"], ["rank", ",", "\n", "envs", ",", "\n", "samples_np", ",", "\n", "batch_T", ",", "\n", "TrajInfoCls", ",", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.async_.serial_sampler.AsyncSerialSampler.__init__": [[18, 22], ["rlpyt.samplers.async_.base.AsyncSamplerMixin.__init__"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.spaces.gym_wrapper.GymSpaceWrapper.__init__"], ["def", "__init__", "(", "self", ",", "*", "args", ",", "CollectorCls", "=", "DbCpuResetCollector", ",", "\n", "eval_CollectorCls", "=", "SerialEvalCollector", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "*", "args", ",", "CollectorCls", "=", "CollectorCls", ",", "\n", "eval_CollectorCls", "=", "eval_CollectorCls", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.async_.serial_sampler.AsyncSerialSampler.initialize": [[27, 74], ["psutil.Process", "affinity.get", "torch.set_num_threads", "rlpyt.utils.collections.AttrDict", "serial_sampler.AsyncSerialSampler.CollectorCls", "serial_sampler.AsyncSerialSampler.agent.to_device", "serial_sampler.AsyncSerialSampler.agent.async_cpu", "serial_sampler.AsyncSerialSampler.start_envs", "serial_sampler.AsyncSerialSampler.start_agent", "rlpyt.utils.logging.logger.log", "psutil.Process.cpu_affinity", "serial_sampler.AsyncSerialSampler.EnvCls", "eval_CollectorCls", "range", "rlpyt.utils.collections.AttrDict", "serial_sampler.AsyncSerialSampler.EnvCls", "affinity.get", "range"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.utils.collections.NamedArrayTuple.get", "home.repos.pwc.inspect_result.astooke_rlpyt.safe.cppo_agent.CppoLstmAgent.to_device", "home.repos.pwc.inspect_result.astooke_rlpyt.agents.dmc_sac_agent.SacAgent.async_cpu", "home.repos.pwc.inspect_result.astooke_rlpyt.samplers.collectors.DecorrelatingStartCollector.start_envs", "home.repos.pwc.inspect_result.astooke_rlpyt.samplers.collectors.BaseCollector.start_agent", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.console.log", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.collections.NamedArrayTuple.get"], ["", "def", "initialize", "(", "self", ",", "affinity", ")", ":", "\n", "        ", "\"\"\"Initialization inside the main sampler process.  Sets process hardware\n        affinities, creates specified number of environment instances and instantiates\n        the collector with them.  If applicable, does the same for evaluation\n        environment instances.  Moves the agent to device (could be GPU), and \n        calls on ``agent.async_cpu()`` initialization.  Starts up collector.\n        \"\"\"", "\n", "p", "=", "psutil", ".", "Process", "(", ")", "\n", "if", "affinity", ".", "get", "(", "\"set_affinity\"", ",", "True", ")", ":", "\n", "            ", "p", ".", "cpu_affinity", "(", "affinity", "[", "\"master_cpus\"", "]", ")", "\n", "# torch.set_num_threads(affinity[\"master_torch_threads\"])", "\n", "", "torch", ".", "set_num_threads", "(", "1", ")", "# Needed to prevent MKL hang :( .", "\n", "B", "=", "self", ".", "batch_spec", ".", "B", "\n", "envs", "=", "[", "self", ".", "EnvCls", "(", "**", "self", ".", "env_kwargs", ")", "for", "_", "in", "range", "(", "B", ")", "]", "\n", "sync", "=", "AttrDict", "(", "db_idx", "=", "AttrDict", "(", "value", "=", "0", ")", ")", "# Mimic the mp.RawValue format.", "\n", "collector", "=", "self", ".", "CollectorCls", "(", "\n", "rank", "=", "0", ",", "\n", "envs", "=", "envs", ",", "\n", "samples_np", "=", "self", ".", "double_buffer", ",", "\n", "batch_T", "=", "self", ".", "batch_spec", ".", "T", ",", "\n", "TrajInfoCls", "=", "self", ".", "TrajInfoCls", ",", "\n", "agent", "=", "self", ".", "agent", ",", "\n", "sync", "=", "sync", ",", "\n", ")", "\n", "if", "self", ".", "eval_n_envs", ">", "0", ":", "\n", "            ", "eval_envs", "=", "[", "self", ".", "EnvCls", "(", "**", "self", ".", "eval_env_kwargs", ")", "\n", "for", "_", "in", "range", "(", "self", ".", "eval_n_envs", ")", "]", "\n", "eval_CollectorCls", "=", "self", ".", "eval_CollectorCls", "or", "SerialEvalCollector", "\n", "self", ".", "eval_collector", "=", "eval_CollectorCls", "(", "\n", "envs", "=", "eval_envs", ",", "\n", "agent", "=", "self", ".", "agent", ",", "\n", "TrajInfoCls", "=", "self", ".", "TrajInfoCls", ",", "\n", "max_T", "=", "self", ".", "eval_max_steps", "//", "self", ".", "eval_n_envs", ",", "\n", "max_trajectories", "=", "self", ".", "eval_max_trajectories", ",", "\n", ")", "\n", "", "self", ".", "agent", ".", "to_device", "(", "cuda_idx", "=", "affinity", ".", "get", "(", "\"cuda_idx\"", ",", "None", ")", ")", "\n", "self", ".", "agent", ".", "async_cpu", "(", "share_memory", "=", "False", ")", "\n", "\n", "agent_inputs", ",", "traj_infos", "=", "collector", ".", "start_envs", "(", "\n", "self", ".", "max_decorrelation_steps", ")", "\n", "collector", ".", "start_agent", "(", ")", "\n", "\n", "self", ".", "collector", "=", "collector", "\n", "self", ".", "agent_inputs", "=", "agent_inputs", "\n", "self", ".", "traj_infos", "=", "traj_infos", "\n", "self", ".", "sync", "=", "sync", "\n", "logger", ".", "log", "(", "\"Serial sampler initialized.\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.async_.serial_sampler.AsyncSerialSampler.obtain_samples": [[75, 89], ["serial_sampler.AsyncSerialSampler.agent.recv_shared_memory", "serial_sampler.AsyncSerialSampler.collector.collect_batch", "serial_sampler.AsyncSerialSampler.collector.reset_if_needed"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.agents.base.BaseAgent.recv_shared_memory", "home.repos.pwc.inspect_result.astooke_rlpyt.async_.collectors.DoubleBufferCollectorMixin.collect_batch", "home.repos.pwc.inspect_result.astooke_rlpyt.gpu.collectors.GpuWaitResetCollector.reset_if_needed"], ["", "def", "obtain_samples", "(", "self", ",", "itr", ",", "db_idx", ")", ":", "\n", "        ", "\"\"\"First calls the agent to retrieve new parameter values from the\n        training process's agent.  Then passes the double-buffer index to the\n        collector and collects training sample batch.  Returns list of\n        completed trajectory-info objects.\n        \"\"\"", "\n", "self", ".", "agent", ".", "recv_shared_memory", "(", ")", "\n", "self", ".", "sync", ".", "db_idx", ".", "value", "=", "db_idx", "# Tell the collector which buffer.", "\n", "agent_inputs", ",", "traj_infos", ",", "completed_infos", "=", "self", ".", "collector", ".", "collect_batch", "(", "\n", "self", ".", "agent_inputs", ",", "self", ".", "traj_infos", ",", "itr", ")", "\n", "self", ".", "collector", ".", "reset_if_needed", "(", "agent_inputs", ")", "\n", "self", ".", "agent_inputs", "=", "agent_inputs", "\n", "self", ".", "traj_infos", "=", "traj_infos", "\n", "return", "completed_infos", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.async_.serial_sampler.AsyncSerialSampler.evaluate_agent": [[90, 96], ["serial_sampler.AsyncSerialSampler.agent.recv_shared_memory", "serial_sampler.AsyncSerialSampler.eval_collector.collect_evaluation"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.agents.base.BaseAgent.recv_shared_memory", "home.repos.pwc.inspect_result.astooke_rlpyt.serial.collectors.SerialEvalCollector.collect_evaluation"], ["", "def", "evaluate_agent", "(", "self", ",", "itr", ")", ":", "\n", "        ", "\"\"\"First calls the agent to retrieve new parameter values from\n        the training process's agent.\n        \"\"\"", "\n", "self", ".", "agent", ".", "recv_shared_memory", "(", ")", "\n", "return", "self", ".", "eval_collector", ".", "collect_evaluation", "(", "itr", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.astooke_rlpyt.async_.alternating_sampler.AsyncAlternatingSamplerBase.__init__": [[15, 18], ["rlpyt.samplers.async_.gpu_sampler.AsyncGpuSamplerBase.__init__"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.spaces.gym_wrapper.GymSpaceWrapper.__init__"], []], "home.repos.pwc.inspect_result.astooke_rlpyt.async_.alternating_sampler.AsyncAlternatingSamplerBase.async_initialize": [[19, 25], ["super().async_initialize", "TypeError"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.rl_with_ul.sac_with_ul.SacWithUl.async_initialize"], ["\n", "\n", "alternating", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.async_.alternating_sampler.AsyncAlternatingSamplerBase.launch_workers": [[26, 29], ["super().launch_workers", "alternating_sampler.AsyncAlternatingSamplerBase._make_alternating_pairs"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.runners.sync_rl.SyncRlMixin.launch_workers", "home.repos.pwc.inspect_result.astooke_rlpyt.async_.alternating_sampler.AsyncAlternatingSamplerBase._make_alternating_pairs"], ["def", "__init__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "assert", "self", ".", "batch_spec", ".", "B", "%", "2", "==", "0", ",", "\"Need even number for sampler batch_B.\"", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.async_.alternating_sampler.AsyncAlternatingSamplerBase._make_alternating_pairs": [[30, 51], ["len", "sum", "tuple", "len", "sum", "len", "len"], "methods", ["None"], ["", "def", "initialize", "(", "self", ",", "agent", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"Like the super class's ``initialize()``, but creates additional set of\n        synchronization and communication objects for the alternate workers.\"\"\"", "\n", "if", "agent", ".", "recurrent", "and", "not", "agent", ".", "alternating", ":", "\n", "            ", "raise", "TypeError", "(", "\"If agent is recurrent, must be 'alternating' to use here.\"", ")", "\n", "", "elif", "not", "agent", ".", "recurrent", ":", "\n", "            ", "agent", ".", "alternating", "=", "True", "# FF agent doesn't need special class, but tell it so.", "\n", "", "examples", "=", "super", "(", ")", ".", "initialize", "(", "agent", ",", "*", "args", ",", "**", "kwargs", ")", "\n", "self", ".", "_make_alternating_pairs", "(", ")", "\n", "return", "examples", "\n", "\n", "", "def", "_make_alternating_pairs", "(", "self", ")", ":", "\n", "        ", "half_w", "=", "self", ".", "n_worker", "//", "2", "# Half of workers.", "\n", "self", ".", "half_B", "=", "half_B", "=", "self", ".", "batch_spec", ".", "B", "//", "2", "# Half of envs.", "\n", "self", ".", "obs_ready_pair", "=", "(", "self", ".", "sync", ".", "obs_ready", "[", ":", "half_w", "]", ",", "self", ".", "sync", ".", "obs_ready", "[", "half_w", ":", "]", ")", "\n", "self", ".", "act_ready_pair", "=", "(", "self", ".", "sync", ".", "act_ready", "[", ":", "half_w", "]", ",", "self", ".", "sync", ".", "act_ready", "[", "half_w", ":", "]", ")", "\n", "self", ".", "step_buffer_np_pair", "=", "(", "self", ".", "step_buffer_np", "[", ":", "half_B", "]", ",", "self", ".", "step_buffer_np", "[", "half_B", ":", "]", ")", "\n", "self", ".", "agent_inputs_pair", "=", "(", "self", ".", "agent_inputs", "[", ":", "half_B", "]", ",", "self", ".", "agent_inputs", "[", "half_B", ":", "]", ")", "\n", "if", "self", ".", "eval_n_envs", ">", "0", ":", "\n", "            ", "assert", "self", ".", "eval_n_envs", "%", "2", "==", "0", "\n", "eval_half_B", "=", "self", ".", "eval_n_envs", "//", "2", "\n", "self", ".", "eval_step_buffer_np_pair", "=", "(", "self", ".", "eval_step_buffer_np", "[", ":", "eval_half_B", "]", ",", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.async_.alternating_sampler.AsyncAlternatingSamplerBase._get_n_envs_lists": [[52, 76], ["len", "list", "zip", "aff.get", "len", "ValueError", "n_workers.count", "len", "rlpyt.utils.logging.logger.log", "range", "list.append", "alternating_sampler.AsyncAlternatingSamplerBase._get_n_envs_list"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.utils.collections.NamedArrayTuple.get", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.console.log", "home.repos.pwc.inspect_result.astooke_rlpyt.async_.alternating_sampler.AsyncAlternatingSamplerBase._get_n_envs_list"], ["self", ".", "eval_step_buffer_np", "[", "eval_half_B", ":", "]", ")", "\n", "self", ".", "eval_agent_inputs_pair", "=", "(", "self", ".", "eval_agent_inputs", "[", ":", "eval_half_B", "]", ",", "\n", "self", ".", "eval_agent_inputs", "[", "eval_half_B", ":", "]", ")", "\n", "", "if", "\"bootstrap_value\"", "in", "self", ".", "samples_np", ".", "agent", ":", "\n", "            ", "self", ".", "bootstrap_value_pair", "=", "(", "self", ".", "samples_np", ".", "agent", ".", "bootstrap_value", "[", "0", ",", ":", "half_B", "]", ",", "\n", "self", ".", "samples_np", ".", "agent", ".", "bootstrap_value", "[", "0", ",", "half_B", ":", "]", ")", "# (leading dim T=1)", "\n", "\n", "", "", "def", "_get_n_envs_list", "(", "self", ",", "affinity", "=", "None", ",", "n_worker", "=", "None", ",", "B", "=", "None", ")", ":", "\n", "        ", "if", "affinity", "is", "not", "None", ":", "\n", "            ", "assert", "affinity", ".", "get", "(", "\"alternating\"", ",", "False", ")", ",", "\"Need alternating affinity.\"", "\n", "", "n_worker", "=", "len", "(", "affinity", "[", "\"workers_cpus\"", "]", ")", "if", "n_worker", "is", "None", "else", "n_worker", "\n", "assert", "n_worker", "%", "2", "==", "0", ",", "\"Need even number workers.\"", "\n", "B", "=", "self", ".", "batch_spec", ".", "B", "if", "B", "is", "None", "else", "B", "\n", "assert", "B", "%", "2", "==", "0", "\n", "# To log warnings:", "\n", "n_envs_list", "=", "super", "(", ")", ".", "_get_n_envs_list", "(", "n_worker", "=", "n_worker", ",", "B", "=", "B", ")", "\n", "if", "B", "%", "n_worker", ">", "0", ":", "\n", "# Redistribute extra envs.", "\n", "            ", "n_envs_list", "=", "[", "B", "//", "n_worker", "]", "*", "n_worker", "\n", "for", "w", "in", "range", "(", "(", "B", "%", "n_worker", ")", "//", "2", ")", ":", "\n", "                ", "n_envs_list", "[", "w", "]", "+=", "1", "\n", "n_envs_list", "[", "w", "+", "n_worker", "//", "2", "]", "+=", "1", "# Paired worker.", "\n", "", "", "return", "n_envs_list", "\n", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.async_.alternating_sampler.AsyncAlternatingSamplerBase._get_n_envs_list": [[77, 91], ["super()._get_n_envs_list", "len", "range"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.async_.alternating_sampler.AsyncAlternatingSamplerBase._get_n_envs_list"], ["", "", "class", "AlternatingSampler", "(", "AlternatingActionServer", ",", "AlternatingSamplerBase", ")", ":", "\n", "    ", "pass", "# These use the same Gpu collectors.", "\n", "\n", "\n", "", "class", "NoOverlapAlternatingSampler", "(", "NoOverlapAlternatingActionServer", ",", "\n", "AlternatingSamplerBase", ")", ":", "\n", "    ", "pass", "\n", "", ""]], "home.repos.pwc.inspect_result.astooke_rlpyt.envs.base.Env.step": [[17, 33], ["None"], "methods", ["None"], ["\n", "raise", "NotImplementedError", "\n", "\n", "", "def", "async_initialize", "(", "self", ",", "agent", ",", "sampler_n_itr", ",", "batch_spec", ",", "mid_batch_reset", ",", "\n", "examples", ",", "world_size", "=", "1", ")", ":", "\n", "        "]], "home.repos.pwc.inspect_result.astooke_rlpyt.envs.base.Env.reset": [[34, 42], ["None"], "methods", ["None"], ["\n", "raise", "NotImplementedError", "\n", "\n", "", "def", "optim_initialize", "(", "self", ",", "rank", "=", "0", ")", ":", "\n", "        ", "\"\"\"Called in async runner which requires two stages of initialization;\n        might also be used in ``initialize()`` to avoid redundant code.\"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n", "", "def", "optimize_agent", "(", "self", ",", "itr", ",", "samples", "=", "None", ",", "sampler_itr", "=", "None", ")", ":", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.envs.base.Env.action_space": [[43, 46], ["None"], "methods", ["None"], ["        "]], "home.repos.pwc.inspect_result.astooke_rlpyt.envs.base.Env.observation_space": [[47, 50], ["None"], "methods", ["None"], []], "home.repos.pwc.inspect_result.astooke_rlpyt.envs.base.Env.spaces": [[51, 56], ["EnvSpaces"], "methods", ["None"], ["\n", "raise", "NotImplementedError", "\n", "\n", "", "def", "optim_state_dict", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.envs.base.Env.horizon": [[58, 62], ["None"], "methods", ["None"], ["\n", "return", "self", ".", "optimizer", ".", "state_dict", "(", ")", "\n", "\n", "", "def", "load_optim_state_dict", "(", "self", ",", "state_dict", ")", ":", "\n", "        "]], "home.repos.pwc.inspect_result.astooke_rlpyt.envs.base.Env.close": [[63, 66], ["None"], "methods", ["None"], ["\n", "self", ".", "optimizer", ".", "load_state_dict", "(", "state_dict", ")", "\n", "\n", "", "@", "property", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.envs.gym.GymEnvWrapper.__init__": [[34, 60], ["gym.Wrapper.__init__", "gym.GymEnvWrapper.env.reset", "gym.GymEnvWrapper.env.step", "isinstance", "rlpyt.spaces.gym_wrapper.GymSpaceWrapper", "rlpyt.spaces.gym_wrapper.GymSpaceWrapper", "gym.build_info_tuples", "gym.GymEnvWrapper.env.action_space.sample", "hasattr", "isinstance"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.spaces.gym_wrapper.GymSpaceWrapper.__init__", "home.repos.pwc.inspect_result.astooke_rlpyt.safe.safety_gym_env.SafetyGymEnvWrapper.reset", "home.repos.pwc.inspect_result.astooke_rlpyt.safe.safety_gym_env.SafetyGymTrajInfo.step", "home.repos.pwc.inspect_result.astooke_rlpyt.envs.gym.build_info_tuples", "home.repos.pwc.inspect_result.astooke_rlpyt.spaces.gym_wrapper.GymSpaceWrapper.sample"], ["def", "__init__", "(", "self", ",", "env", ",", "\n", "act_null_value", "=", "0", ",", "obs_null_value", "=", "0", ",", "force_float32", "=", "True", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "env", ")", "\n", "o", "=", "self", ".", "env", ".", "reset", "(", ")", "\n", "o", ",", "r", ",", "d", ",", "info", "=", "self", ".", "env", ".", "step", "(", "self", ".", "env", ".", "action_space", ".", "sample", "(", ")", ")", "\n", "env_", "=", "self", ".", "env", "\n", "time_limit", "=", "isinstance", "(", "self", ".", "env", ",", "TimeLimit", ")", "\n", "while", "not", "time_limit", "and", "hasattr", "(", "env_", ",", "\"env\"", ")", ":", "\n", "            ", "env_", "=", "env_", ".", "env", "\n", "time_limit", "=", "isinstance", "(", "env_", ",", "TimeLimit", ")", "\n", "", "if", "time_limit", ":", "\n", "            ", "info", "[", "\"timeout\"", "]", "=", "False", "# gym's TimeLimit.truncated invalid name.", "\n", "", "self", ".", "_time_limit", "=", "time_limit", "\n", "self", ".", "action_space", "=", "GymSpaceWrapper", "(", "\n", "space", "=", "self", ".", "env", ".", "action_space", ",", "\n", "name", "=", "\"act\"", ",", "\n", "null_value", "=", "act_null_value", ",", "\n", "force_float32", "=", "force_float32", ",", "\n", ")", "\n", "self", ".", "observation_space", "=", "GymSpaceWrapper", "(", "\n", "space", "=", "self", ".", "env", ".", "observation_space", ",", "\n", "name", "=", "\"obs\"", ",", "\n", "null_value", "=", "obs_null_value", ",", "\n", "force_float32", "=", "force_float32", ",", "\n", ")", "\n", "build_info_tuples", "(", "info", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.envs.gym.GymEnvWrapper.step": [[61, 78], ["gym.GymEnvWrapper.action_space.revert", "gym.GymEnvWrapper.env.step", "gym.GymEnvWrapper.observation_space.convert", "gym.info_to_nt", "isinstance", "rlpyt.envs.base.EnvStep", "numpy.dtype().type", "info_to_nt.pop", "numpy.dtype"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.spaces.gym_wrapper.GymSpaceWrapper.revert", "home.repos.pwc.inspect_result.astooke_rlpyt.safe.safety_gym_env.SafetyGymTrajInfo.step", "home.repos.pwc.inspect_result.astooke_rlpyt.spaces.gym_wrapper.GymSpaceWrapper.convert", "home.repos.pwc.inspect_result.astooke_rlpyt.envs.gym_schema.info_to_nt", "home.repos.pwc.inspect_result.astooke_rlpyt.spaces.gym_wrapper.GymSpaceWrapper.dtype"], ["", "def", "step", "(", "self", ",", "action", ")", ":", "\n", "        ", "\"\"\"Reverts the action from rlpyt format to gym format (i.e. if composite-to-\n        dictionary spaces), steps the gym environment, converts the observation\n        from gym to rlpyt format (i.e. if dict-to-composite), and converts the\n        env_info from dictionary into namedtuple.\"\"\"", "\n", "a", "=", "self", ".", "action_space", ".", "revert", "(", "action", ")", "\n", "o", ",", "r", ",", "d", ",", "info", "=", "self", ".", "env", ".", "step", "(", "a", ")", "\n", "obs", "=", "self", ".", "observation_space", ".", "convert", "(", "o", ")", "\n", "if", "self", ".", "_time_limit", ":", "\n", "            ", "if", "\"TimeLimit.truncated\"", "in", "info", ":", "\n", "                ", "info", "[", "\"timeout\"", "]", "=", "info", ".", "pop", "(", "\"TimeLimit.truncated\"", ")", "\n", "", "else", ":", "\n", "                ", "info", "[", "\"timeout\"", "]", "=", "False", "\n", "", "", "info", "=", "info_to_nt", "(", "info", ")", "\n", "if", "isinstance", "(", "r", ",", "float", ")", ":", "\n", "            ", "r", "=", "np", ".", "dtype", "(", "\"float32\"", ")", ".", "type", "(", "r", ")", "# Scalar float32.", "\n", "", "return", "EnvStep", "(", "obs", ",", "r", ",", "d", ",", "info", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.envs.gym.GymEnvWrapper.reset": [[79, 82], ["gym.GymEnvWrapper.observation_space.convert", "gym.GymEnvWrapper.env.reset"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.spaces.gym_wrapper.GymSpaceWrapper.convert", "home.repos.pwc.inspect_result.astooke_rlpyt.safe.safety_gym_env.SafetyGymEnvWrapper.reset"], ["", "def", "reset", "(", "self", ")", ":", "\n", "        ", "\"\"\"Returns converted observation from gym env reset.\"\"\"", "\n", "return", "self", ".", "observation_space", ".", "convert", "(", "self", ".", "env", ".", "reset", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.envs.gym.GymEnvWrapper.spaces": [[83, 89], ["rlpyt.envs.base.EnvSpaces"], "methods", ["None"], ["", "@", "property", "\n", "def", "spaces", "(", "self", ")", ":", "\n", "        ", "\"\"\"Returns the rlpyt spaces for the wrapped env.\"\"\"", "\n", "return", "EnvSpaces", "(", "\n", "observation", "=", "self", ".", "observation_space", ",", "\n", "action", "=", "self", ".", "action_space", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.envs.gym.EnvInfoWrapper.__init__": [[141, 145], ["gym.Wrapper.__init__"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.spaces.gym_wrapper.GymSpaceWrapper.__init__"], ["def", "__init__", "(", "self", ",", "env", ",", "info_example", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "env", ")", "\n", "# self._sometimes_info = sometimes_info(**sometimes_info_kwargs)", "\n", "self", ".", "_sometimes_info", "=", "info_example", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.envs.gym.EnvInfoWrapper.step": [[146, 152], ["super().step", "gym.infill_info"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.safe.safety_gym_env.SafetyGymTrajInfo.step", "home.repos.pwc.inspect_result.astooke_rlpyt.safe.safety_gym_env.infill_info"], ["", "def", "step", "(", "self", ",", "action", ")", ":", "\n", "        ", "\"\"\"If need be, put extra fields into the `env_info` dict returned.\n        See file for function ``infill_info()`` for details.\"\"\"", "\n", "o", ",", "r", ",", "d", ",", "info", "=", "super", "(", ")", ".", "step", "(", "action", ")", "\n", "# Try to make info dict same key structure at every step.", "\n", "return", "o", ",", "r", ",", "d", ",", "infill_info", "(", "info", ",", "self", ".", "_sometimes_info", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.envs.gym.build_info_tuples": [[92, 108], ["globals().get", "info.items", "str().replace", "collections.namedtuple", "isinstance", "globals", "info.keys", "globals", "ValueError", "gym.build_info_tuples", "str", "rlpyt.utils.collections.is_namedtuple_class", "sorted", "sorted"], "function", ["home.repos.pwc.inspect_result.astooke_rlpyt.utils.collections.NamedArrayTuple.get", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.collections.NamedArrayTuple.items", "home.repos.pwc.inspect_result.astooke_rlpyt.envs.gym.build_info_tuples", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.collections.is_namedtuple_class"], ["", "", "def", "build_info_tuples", "(", "info", ",", "name", "=", "\"info\"", ")", ":", "\n", "# Define namedtuples at module level for pickle.", "\n", "# Only place rlpyt uses pickle is in the sampler, when getting the", "\n", "# first examples, to avoid MKL threading issues...can probably turn", "\n", "# that off, (look for subprocess=True --> False), and then might", "\n", "# be able to define these directly within the class.", "\n", "    ", "ntc", "=", "globals", "(", ")", ".", "get", "(", "name", ")", "# Define at module level for pickle.", "\n", "info_keys", "=", "[", "str", "(", "k", ")", ".", "replace", "(", "\".\"", ",", "\"_\"", ")", "for", "k", "in", "info", ".", "keys", "(", ")", "]", "\n", "if", "ntc", "is", "None", ":", "\n", "        ", "globals", "(", ")", "[", "name", "]", "=", "namedtuple", "(", "name", ",", "info_keys", ")", "\n", "", "elif", "not", "(", "is_namedtuple_class", "(", "ntc", ")", "and", "\n", "sorted", "(", "ntc", ".", "_fields", ")", "==", "sorted", "(", "info_keys", ")", ")", ":", "\n", "        ", "raise", "ValueError", "(", "f\"Name clash in globals: {name}.\"", ")", "\n", "", "for", "k", ",", "v", "in", "info", ".", "items", "(", ")", ":", "\n", "        ", "if", "isinstance", "(", "v", ",", "dict", ")", ":", "\n", "            ", "build_info_tuples", "(", "v", ",", "\"_\"", ".", "join", "(", "[", "name", ",", "k", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.envs.gym.info_to_nt": [[110, 120], ["values.update", "ntc", "isinstance", "globals", "gym.info_to_nt", "value.items"], "function", ["home.repos.pwc.inspect_result.astooke_rlpyt.models.running_mean_std.RunningMeanStdModel.update", "home.repos.pwc.inspect_result.astooke_rlpyt.envs.gym_schema.info_to_nt", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.collections.NamedArrayTuple.items"], ["", "", "", "def", "info_to_nt", "(", "value", ",", "name", "=", "\"info\"", ")", ":", "\n", "    ", "if", "not", "isinstance", "(", "value", ",", "dict", ")", ":", "\n", "        ", "return", "value", "\n", "", "ntc", "=", "globals", "(", ")", "[", "name", "]", "\n", "# Disregard unrecognized keys:", "\n", "values", "=", "{", "k", ":", "info_to_nt", "(", "v", ",", "\"_\"", ".", "join", "(", "[", "name", ",", "k", "]", ")", ")", "\n", "for", "k", ",", "v", "in", "value", ".", "items", "(", ")", "if", "k", "in", "ntc", ".", "_fields", "}", "\n", "# Can catch some missing values (doesn't nest):", "\n", "values", ".", "update", "(", "{", "k", ":", "0", "for", "k", "in", "ntc", ".", "_fields", "if", "k", "not", "in", "values", "}", ")", "\n", "return", "ntc", "(", "**", "values", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.envs.gym.infill_info": [[154, 161], ["sometimes_info.items", "isinstance", "gym.infill_info"], "function", ["home.repos.pwc.inspect_result.astooke_rlpyt.utils.collections.NamedArrayTuple.items", "home.repos.pwc.inspect_result.astooke_rlpyt.safe.safety_gym_env.infill_info"], ["", "", "def", "infill_info", "(", "info", ",", "sometimes_info", ")", ":", "\n", "    ", "for", "k", ",", "v", "in", "sometimes_info", ".", "items", "(", ")", ":", "\n", "        ", "if", "k", "not", "in", "info", ":", "\n", "            ", "info", "[", "k", "]", "=", "v", "\n", "", "elif", "isinstance", "(", "v", ",", "dict", ")", ":", "\n", "            ", "infill_info", "(", "info", "[", "k", "]", ",", "v", ")", "\n", "", "", "return", "info", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.envs.gym.make": [[163, 173], ["gym.GymEnvWrapper", "gym.GymEnvWrapper", "gym.make", "gym.EnvInfoWrapper", "gym.make"], "function", ["home.repos.pwc.inspect_result.astooke_rlpyt.envs.dmcontrol.make", "home.repos.pwc.inspect_result.astooke_rlpyt.envs.dmcontrol.make"], ["", "def", "make", "(", "*", "args", ",", "info_example", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Use as factory function for making instances of gym environment with\n    rlpyt's ``GymEnvWrapper``, using ``gym.make(*args, **kwargs)``.  If\n    ``info_example`` is not ``None``, will include the ``EnvInfoWrapper``.\n    \"\"\"", "\n", "if", "info_example", "is", "None", ":", "\n", "        ", "return", "GymEnvWrapper", "(", "gym", ".", "make", "(", "*", "args", ",", "**", "kwargs", ")", ")", "\n", "", "else", ":", "\n", "        ", "return", "GymEnvWrapper", "(", "EnvInfoWrapper", "(", "\n", "gym", ".", "make", "(", "*", "args", ",", "**", "kwargs", ")", ",", "info_example", ")", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.astooke_rlpyt.envs.gym_schema.GymEnvWrapper.__init__": [[33, 60], ["gym.Wrapper.__init__", "gym_schema.GymEnvWrapper.env.reset", "gym_schema.GymEnvWrapper.env.step", "isinstance", "rlpyt.spaces.gym_wrapper_schema.GymSpaceWrapper", "rlpyt.spaces.gym_wrapper_schema.GymSpaceWrapper", "gym_schema.GymEnvWrapper._build_info_schemas", "gym_schema.GymEnvWrapper.env.action_space.sample", "hasattr", "isinstance"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.spaces.gym_wrapper.GymSpaceWrapper.__init__", "home.repos.pwc.inspect_result.astooke_rlpyt.safe.safety_gym_env.SafetyGymEnvWrapper.reset", "home.repos.pwc.inspect_result.astooke_rlpyt.safe.safety_gym_env.SafetyGymTrajInfo.step", "home.repos.pwc.inspect_result.astooke_rlpyt.envs.gym_schema.GymEnvWrapper._build_info_schemas", "home.repos.pwc.inspect_result.astooke_rlpyt.spaces.gym_wrapper.GymSpaceWrapper.sample"], ["def", "__init__", "(", "self", ",", "env", ",", "\n", "act_null_value", "=", "0", ",", "obs_null_value", "=", "0", ",", "force_float32", "=", "True", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "env", ")", "\n", "o", "=", "self", ".", "env", ".", "reset", "(", ")", "\n", "o", ",", "r", ",", "d", ",", "info", "=", "self", ".", "env", ".", "step", "(", "self", ".", "env", ".", "action_space", ".", "sample", "(", ")", ")", "\n", "env_", "=", "self", ".", "env", "\n", "time_limit", "=", "isinstance", "(", "self", ".", "env", ",", "TimeLimit", ")", "\n", "while", "not", "time_limit", "and", "hasattr", "(", "env_", ",", "\"env\"", ")", ":", "\n", "            ", "env_", "=", "env_", ".", "env", "\n", "time_limit", "=", "isinstance", "(", "self", ".", "env", ",", "TimeLimit", ")", "\n", "", "if", "time_limit", ":", "\n", "            ", "info", "[", "\"timeout\"", "]", "=", "False", "# gym's TimeLimit.truncated invalid name.", "\n", "", "self", ".", "_time_limit", "=", "time_limit", "\n", "self", ".", "action_space", "=", "GymSpaceWrapper", "(", "\n", "space", "=", "self", ".", "env", ".", "action_space", ",", "\n", "name", "=", "\"act\"", ",", "\n", "null_value", "=", "act_null_value", ",", "\n", "force_float32", "=", "force_float32", ",", "\n", ")", "\n", "self", ".", "observation_space", "=", "GymSpaceWrapper", "(", "\n", "space", "=", "self", ".", "env", ".", "observation_space", ",", "\n", "name", "=", "\"obs\"", ",", "\n", "null_value", "=", "obs_null_value", ",", "\n", "force_float32", "=", "force_float32", ",", "\n", ")", "\n", "self", ".", "_info_schemas", "=", "{", "}", "\n", "self", ".", "_build_info_schemas", "(", "info", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.envs.gym_schema.GymEnvWrapper._build_info_schemas": [[61, 73], ["gym_schema.GymEnvWrapper._info_schemas.get", "info.items", "str().replace", "rlpyt.utils.collections.NamedTupleSchema", "isinstance", "info.keys", "list", "ValueError", "gym_schema.GymEnvWrapper._build_info_schemas", "str", "isinstance", "sorted", "sorted"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.utils.collections.NamedArrayTuple.get", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.collections.NamedArrayTuple.items", "home.repos.pwc.inspect_result.astooke_rlpyt.envs.gym_schema.GymEnvWrapper._build_info_schemas"], ["", "def", "_build_info_schemas", "(", "self", ",", "info", ",", "name", "=", "\"info\"", ")", ":", "\n", "        ", "ntc", "=", "self", ".", "_info_schemas", ".", "get", "(", "name", ")", "\n", "info_keys", "=", "[", "str", "(", "k", ")", ".", "replace", "(", "\".\"", ",", "\"_\"", ")", "for", "k", "in", "info", ".", "keys", "(", ")", "]", "\n", "if", "ntc", "is", "None", ":", "\n", "            ", "self", ".", "_info_schemas", "[", "name", "]", "=", "NamedTupleSchema", "(", "\n", "name", ",", "list", "(", "info_keys", ")", ")", "\n", "", "elif", "not", "(", "isinstance", "(", "ntc", ",", "NamedTupleSchema", ")", "and", "\n", "sorted", "(", "ntc", ".", "_fields", ")", "==", "sorted", "(", "info_keys", ")", ")", ":", "\n", "            ", "raise", "ValueError", "(", "f\"Name clash in schema index: {name}.\"", ")", "\n", "", "for", "k", ",", "v", "in", "info", ".", "items", "(", ")", ":", "\n", "            ", "if", "isinstance", "(", "v", ",", "dict", ")", ":", "\n", "                ", "self", ".", "_build_info_schemas", "(", "v", ",", "\"_\"", ".", "join", "(", "[", "name", ",", "k", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.envs.gym_schema.GymEnvWrapper.step": [[74, 89], ["gym_schema.GymEnvWrapper.action_space.revert", "gym_schema.GymEnvWrapper.env.step", "gym_schema.GymEnvWrapper.observation_space.convert", "gym_schema.info_to_nt", "rlpyt.envs.base.EnvStep", "info_to_nt.pop"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.spaces.gym_wrapper.GymSpaceWrapper.revert", "home.repos.pwc.inspect_result.astooke_rlpyt.safe.safety_gym_env.SafetyGymTrajInfo.step", "home.repos.pwc.inspect_result.astooke_rlpyt.spaces.gym_wrapper.GymSpaceWrapper.convert", "home.repos.pwc.inspect_result.astooke_rlpyt.envs.gym_schema.info_to_nt"], ["", "", "", "def", "step", "(", "self", ",", "action", ")", ":", "\n", "        ", "\"\"\"Reverts the action from rlpyt format to gym format (i.e. if composite-to-\n        dictionary spaces), steps the gym environment, converts the observation\n        from gym to rlpyt format (i.e. if dict-to-composite), and converts the\n        env_info from dictionary into namedtuple.\"\"\"", "\n", "a", "=", "self", ".", "action_space", ".", "revert", "(", "action", ")", "\n", "o", ",", "r", ",", "d", ",", "info", "=", "self", ".", "env", ".", "step", "(", "a", ")", "\n", "obs", "=", "self", ".", "observation_space", ".", "convert", "(", "o", ")", "\n", "if", "self", ".", "_time_limit", ":", "\n", "            ", "if", "\"TimeLimit.truncated\"", "in", "info", ":", "\n", "                ", "info", "[", "\"timeout\"", "]", "=", "info", ".", "pop", "(", "\"TimeLimit.truncated\"", ")", "\n", "", "else", ":", "\n", "                ", "info", "[", "\"timeout\"", "]", "=", "False", "\n", "", "", "info", "=", "info_to_nt", "(", "info", ",", "self", ".", "_info_schemas", ")", "\n", "return", "EnvStep", "(", "obs", ",", "r", ",", "d", ",", "info", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.envs.gym_schema.GymEnvWrapper.reset": [[90, 93], ["gym_schema.GymEnvWrapper.observation_space.convert", "gym_schema.GymEnvWrapper.env.reset"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.spaces.gym_wrapper.GymSpaceWrapper.convert", "home.repos.pwc.inspect_result.astooke_rlpyt.safe.safety_gym_env.SafetyGymEnvWrapper.reset"], ["", "def", "reset", "(", "self", ")", ":", "\n", "        ", "\"\"\"Returns converted observation from gym env reset.\"\"\"", "\n", "return", "self", ".", "observation_space", ".", "convert", "(", "self", ".", "env", ".", "reset", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.envs.gym_schema.GymEnvWrapper.spaces": [[94, 100], ["rlpyt.envs.base.EnvSpaces"], "methods", ["None"], ["", "@", "property", "\n", "def", "spaces", "(", "self", ")", ":", "\n", "        ", "\"\"\"Returns the rlpyt spaces for the wrapped env.\"\"\"", "\n", "return", "EnvSpaces", "(", "\n", "observation", "=", "self", ".", "observation_space", ",", "\n", "action", "=", "self", ".", "action_space", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.envs.gym_schema.EnvInfoWrapper.__init__": [[134, 138], ["gym.Wrapper.__init__"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.spaces.gym_wrapper.GymSpaceWrapper.__init__"], ["def", "__init__", "(", "self", ",", "env", ",", "info_example", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "env", ")", "\n", "# self._sometimes_info = sometimes_info(**sometimes_info_kwargs)", "\n", "self", ".", "_sometimes_info", "=", "info_example", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.envs.gym_schema.EnvInfoWrapper.step": [[139, 145], ["super().step", "gym_schema.infill_info"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.safe.safety_gym_env.SafetyGymTrajInfo.step", "home.repos.pwc.inspect_result.astooke_rlpyt.safe.safety_gym_env.infill_info"], ["", "def", "step", "(", "self", ",", "action", ")", ":", "\n", "        ", "\"\"\"If need be, put extra fields into the `env_info` dict returned.\n        See file for function ``infill_info()`` for details.\"\"\"", "\n", "o", ",", "r", ",", "d", ",", "info", "=", "super", "(", ")", ".", "step", "(", "action", ")", "\n", "# Try to make info dict same key structure at every step.", "\n", "return", "o", ",", "r", ",", "d", ",", "infill_info", "(", "info", ",", "self", ".", "_sometimes_info", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.envs.gym_schema.info_to_nt": [[103, 113], ["values.update", "ntc", "isinstance", "gym_schema.info_to_nt", "value.items"], "function", ["home.repos.pwc.inspect_result.astooke_rlpyt.models.running_mean_std.RunningMeanStdModel.update", "home.repos.pwc.inspect_result.astooke_rlpyt.envs.gym_schema.info_to_nt", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.collections.NamedArrayTuple.items"], ["", "", "def", "info_to_nt", "(", "value", ",", "schemas", ",", "name", "=", "\"info\"", ")", ":", "\n", "    ", "if", "not", "isinstance", "(", "value", ",", "dict", ")", ":", "\n", "        ", "return", "value", "\n", "", "ntc", "=", "schemas", "[", "name", "]", "\n", "# Disregard unrecognized keys:", "\n", "values", "=", "{", "k", ":", "info_to_nt", "(", "v", ",", "schemas", ",", "\"_\"", ".", "join", "(", "[", "name", ",", "k", "]", ")", ")", "\n", "for", "k", ",", "v", "in", "value", ".", "items", "(", ")", "if", "k", "in", "ntc", ".", "_fields", "}", "\n", "# Can catch some missing values (doesn't nest):", "\n", "values", ".", "update", "(", "{", "k", ":", "0", "for", "k", "in", "ntc", ".", "_fields", "if", "k", "not", "in", "values", "}", ")", "\n", "return", "ntc", "(", "**", "values", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.envs.gym_schema.infill_info": [[147, 154], ["sometimes_info.items", "isinstance", "gym_schema.infill_info"], "function", ["home.repos.pwc.inspect_result.astooke_rlpyt.utils.collections.NamedArrayTuple.items", "home.repos.pwc.inspect_result.astooke_rlpyt.safe.safety_gym_env.infill_info"], ["", "", "def", "infill_info", "(", "info", ",", "sometimes_info", ")", ":", "\n", "    ", "for", "k", ",", "v", "in", "sometimes_info", ".", "items", "(", ")", ":", "\n", "        ", "if", "k", "not", "in", "info", ":", "\n", "            ", "info", "[", "k", "]", "=", "v", "\n", "", "elif", "isinstance", "(", "v", ",", "dict", ")", ":", "\n", "            ", "infill_info", "(", "info", "[", "k", "]", ",", "v", ")", "\n", "", "", "return", "info", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.envs.gym_schema.make": [[156, 166], ["gym_schema.GymEnvWrapper", "gym_schema.GymEnvWrapper", "gym.make", "gym_schema.EnvInfoWrapper", "gym.make"], "function", ["home.repos.pwc.inspect_result.astooke_rlpyt.envs.dmcontrol.make", "home.repos.pwc.inspect_result.astooke_rlpyt.envs.dmcontrol.make"], ["", "def", "make", "(", "*", "args", ",", "info_example", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Use as factory function for making instances of gym environment with\n    rlpyt's ``GymEnvWrapper``, using ``gym.make(*args, **kwargs)``.  If\n    ``info_example`` is not ``None``, will include the ``EnvInfoWrapper``.\n    \"\"\"", "\n", "if", "info_example", "is", "None", ":", "\n", "        ", "return", "GymEnvWrapper", "(", "gym", ".", "make", "(", "*", "args", ",", "**", "kwargs", ")", ")", "\n", "", "else", ":", "\n", "        ", "return", "GymEnvWrapper", "(", "EnvInfoWrapper", "(", "\n", "gym", ".", "make", "(", "*", "args", ",", "**", "kwargs", ")", ",", "info_example", ")", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.astooke_rlpyt.envs.atari.AtariEnv84.__init__": [[19, 58], ["rlpyt.utils.quick_args.save__init__args", "atari_py.get_game_path", "atari_py.ALEInterface", "atari.AtariEnv84.ale.setFloat", "atari.AtariEnv84.ale.loadROM", "atari.AtariEnv84.ale.getMinimalActionSet", "rlpyt.spaces.int_box.IntBox", "rlpyt.spaces.int_box.IntBox", "atari.AtariEnv84.ale.getScreenGrayscale", "atari.AtariEnv84._max_frame.copy", "atari.AtariEnv84._max_frame.copy", "numpy.zeros", "int", "atari.AtariEnv84.reset", "locals", "os.path.exists", "IOError", "atari.AtariEnv84.get_action_meanings", "atari.AtariEnv84.get_action_meanings", "len"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.utils.quick_args.save__init__args", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.collections.AttrDict.copy", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.collections.AttrDict.copy", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.misc.zeros", "home.repos.pwc.inspect_result.astooke_rlpyt.safe.safety_gym_env.SafetyGymEnvWrapper.reset", "home.repos.pwc.inspect_result.astooke_rlpyt.atari.atari_env.AtariEnv.get_action_meanings", "home.repos.pwc.inspect_result.astooke_rlpyt.atari.atari_env.AtariEnv.get_action_meanings"], ["\n", "\n", "", "", "class", "AtariFfAgent", "(", "AtariMixin", ",", "CategoricalPgAgent", ")", ":", "\n", "\n", "    ", "def", "__init__", "(", "self", ",", "ModelCls", "=", "AtariFfModel", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "ModelCls", "=", "ModelCls", ",", "**", "kwargs", ")", "\n", "\n", "\n", "", "", "class", "AtariLstmAgent", "(", "AtariMixin", ",", "RecurrentCategoricalPgAgent", ")", ":", "\n", "\n", "    ", "def", "__init__", "(", "self", ",", "ModelCls", "=", "AtariLstmModel", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "ModelCls", "=", "ModelCls", ",", "**", "kwargs", ")", "\n", "\n", "\n", "", "", "class", "AlternatingAtariLstmAgent", "(", "AtariMixin", ",", "\n", "AlternatingRecurrentCategoricalPgAgent", ")", ":", "\n", "\n", "    ", "def", "__init__", "(", "self", ",", "ModelCls", "=", "AtariLstmModel", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "ModelCls", "=", "ModelCls", ",", "**", "kwargs", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.astooke_rlpyt.envs.atari.AtariEnv84.reset": [[59, 71], ["atari.AtariEnv84.ale.reset_game", "atari.AtariEnv84._reset_obs", "atari.AtariEnv84._life_reset", "range", "atari.AtariEnv84._update_obs", "atari.AtariEnv84.get_obs", "numpy.random.randint", "atari.AtariEnv84.ale.act", "atari.AtariEnv84.fire_and_up"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.atari.atari_env.AtariEnv._reset_obs", "home.repos.pwc.inspect_result.astooke_rlpyt.envs.atari.AtariEnv84._life_reset", "home.repos.pwc.inspect_result.astooke_rlpyt.envs.atari.AtariEnv84._update_obs", "home.repos.pwc.inspect_result.astooke_rlpyt.atari.atari_env.AtariEnv.get_obs", "home.repos.pwc.inspect_result.astooke_rlpyt.envs.atari.AtariEnv84.fire_and_up"], []], "home.repos.pwc.inspect_result.astooke_rlpyt.envs.atari.AtariEnv84._update_obs": [[72, 79], ["atari.AtariEnv84._get_screen", "numpy.maximum", "cv2.resize", "numpy.concatenate"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.atari.atari_env.AtariEnv._get_screen"], []], "home.repos.pwc.inspect_result.astooke_rlpyt.envs.atari.AtariEnv84._life_reset": [[80, 83], ["atari.AtariEnv84.ale.act", "atari.AtariEnv84.ale.lives"], "methods", ["None"], []], "home.repos.pwc.inspect_result.astooke_rlpyt.envs.atari.AtariEnv84.fire_and_up": [[84, 90], ["atari.AtariEnv84.ale.act", "atari.AtariEnv84.ale.act"], "methods", ["None"], []], "home.repos.pwc.inspect_result.astooke_rlpyt.envs.dmcontrol.TimeLimitMinusOne.step": [[17, 25], ["dmcontrol.TimeLimitMinusOne.env.step"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.safe.safety_gym_env.SafetyGymTrajInfo.step"], ["def", "step", "(", "self", ",", "action", ")", ":", "\n", "        ", "assert", "self", ".", "_elapsed_steps", "is", "not", "None", ",", "\"Cannot call env.step() before calling reset()\"", "\n", "observation", ",", "reward", ",", "done", ",", "info", "=", "self", ".", "env", ".", "step", "(", "action", ")", "\n", "self", ".", "_elapsed_steps", "+=", "1", "\n", "if", "self", ".", "_elapsed_steps", ">=", "self", ".", "_max_episode_steps", "-", "1", ":", "\n", "            ", "info", "[", "'TimeLimit.truncated'", "]", "=", "not", "done", "\n", "done", "=", "True", "\n", "", "return", "observation", ",", "reward", ",", "done", ",", "info", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.envs.dmcontrol.FrameStack.__init__": [[28, 40], ["gym.Wrapper.__init__", "collections.deque", "gym.spaces.Box"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.spaces.gym_wrapper.GymSpaceWrapper.__init__"], ["    ", "def", "__init__", "(", "self", ",", "env", ",", "k", ")", ":", "\n", "        ", "gym", ".", "Wrapper", ".", "__init__", "(", "self", ",", "env", ")", "\n", "self", ".", "_k", "=", "k", "\n", "self", ".", "_frames", "=", "deque", "(", "[", "]", ",", "maxlen", "=", "k", ")", "\n", "shp", "=", "env", ".", "observation_space", ".", "shape", "\n", "self", ".", "observation_space", "=", "gym", ".", "spaces", ".", "Box", "(", "\n", "low", "=", "0", ",", "\n", "high", "=", "1", ",", "\n", "shape", "=", "(", "(", "shp", "[", "0", "]", "*", "k", ",", ")", "+", "shp", "[", "1", ":", "]", ")", ",", "\n", "dtype", "=", "env", ".", "observation_space", ".", "dtype", "\n", ")", "\n", "self", ".", "_max_episode_steps", "=", "env", ".", "_max_episode_steps", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.envs.dmcontrol.FrameStack.reset": [[41, 46], ["dmcontrol.FrameStack.env.reset", "range", "dmcontrol.FrameStack._get_obs", "dmcontrol.FrameStack._frames.append"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.safe.safety_gym_env.SafetyGymEnvWrapper.reset", "home.repos.pwc.inspect_result.astooke_rlpyt.envs.dmcontrol.FrameStack._get_obs"], ["", "def", "reset", "(", "self", ")", ":", "\n", "        ", "obs", "=", "self", ".", "env", ".", "reset", "(", ")", "\n", "for", "_", "in", "range", "(", "self", ".", "_k", ")", ":", "\n", "            ", "self", ".", "_frames", ".", "append", "(", "obs", ")", "\n", "", "return", "self", ".", "_get_obs", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.envs.dmcontrol.FrameStack.step": [[47, 51], ["dmcontrol.FrameStack.env.step", "dmcontrol.FrameStack._frames.append", "dmcontrol.FrameStack._get_obs"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.safe.safety_gym_env.SafetyGymTrajInfo.step", "home.repos.pwc.inspect_result.astooke_rlpyt.envs.dmcontrol.FrameStack._get_obs"], ["", "def", "step", "(", "self", ",", "action", ")", ":", "\n", "        ", "obs", ",", "reward", ",", "done", ",", "info", "=", "self", ".", "env", ".", "step", "(", "action", ")", "\n", "self", ".", "_frames", ".", "append", "(", "obs", ")", "\n", "return", "self", ".", "_get_obs", "(", ")", ",", "reward", ",", "done", ",", "info", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.envs.dmcontrol.FrameStack._get_obs": [[52, 55], ["numpy.concatenate", "len", "list"], "methods", ["None"], ["", "def", "_get_obs", "(", "self", ")", ":", "\n", "        ", "assert", "len", "(", "self", ".", "_frames", ")", "==", "self", ".", "_k", "\n", "return", "np", ".", "concatenate", "(", "list", "(", "self", ".", "_frames", ")", ",", "axis", "=", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.envs.dmcontrol.make": [[57, 81], ["dmc2gym.make", "isinstance", "rlpyt.envs.gym.GymEnvWrapper", "print", "dmcontrol.TimeLimitMinusOne", "dmcontrol.FrameStack", "print"], "function", ["home.repos.pwc.inspect_result.astooke_rlpyt.envs.dmcontrol.make"], ["", "", "def", "make", "(", "*", "args", ",", "frame_stack", "=", "3", ",", "from_pixels", "=", "True", ",", "height", "=", "84", ",", "width", "=", "84", ",", "\n", "frame_skip", "=", "4", ",", "**", "kwargs", ")", ":", "\n", "    ", "env", "=", "dmc2gym", ".", "make", "(", "*", "args", ",", "\n", "frame_skip", "=", "frame_skip", ",", "\n", "visualize_reward", "=", "False", ",", "\n", "from_pixels", "=", "from_pixels", ",", "\n", "height", "=", "height", ",", "\n", "width", "=", "width", ",", "\n", "**", "kwargs", ")", "\n", "if", "isinstance", "(", "env", ",", "TimeLimit", ")", ":", "\n", "# Strip the gym TimeLimit wrapper and replace with one which", "\n", "# outputs TimeLimit.truncated=True at max_episode_steps - 1,", "\n", "# because that's when the dmc2gym env seems to end the episode.", "\n", "        ", "print", "(", "\"WARNING: replacing Gym TimeLimit wrapper by TimeLimitMinusOne\"", ")", "\n", "env", "=", "TimeLimitMinusOne", "(", "env", ".", "env", ")", "\n", "", "if", "from_pixels", ":", "\n", "        ", "env", "=", "FrameStack", "(", "env", ",", "k", "=", "frame_stack", ")", "\n", "", "elif", "frame_stack", "!=", "1", ":", "\n", "        ", "print", "(", "\"WARNING: dmcontrol.make() requested with frame_stack>1, but not\"", "\n", "\" doing it on state.\"", ")", "\n", "", "env", "=", "GymEnvWrapper", "(", "env", ")", "\n", "env", ".", "_frame_skip", "=", "frame_skip", "\n", "\n", "return", "env", "\n", "", ""]], "home.repos.pwc.inspect_result.astooke_rlpyt.envs.dmlab.DmlabEnv.__init__": [[15, 74], ["dict", "deepmind_lab.Lab", "numpy.array", "rlpyt.spaces.int_box.IntBox", "rlpyt.spaces.int_box.IntBox", "numpy.zeros", "dmlab.LevelCache", "str", "str", "isinstance", "dict.update", "collections.deque", "str", "str", "str", "os.environ.get", "os.environ.get", "os.environ.get", "os.environ.get", "dict.keys", "config_kwargs.keys", "KeyError", "len", "dict.keys", "config_kwargs.keys"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.utils.misc.zeros", "home.repos.pwc.inspect_result.astooke_rlpyt.models.running_mean_std.RunningMeanStdModel.update", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.collections.NamedArrayTuple.get", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.collections.NamedArrayTuple.get", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.collections.NamedArrayTuple.get", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.collections.NamedArrayTuple.get"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "level", ",", "\n", "height", "=", "72", ",", "\n", "width", "=", "96", ",", "\n", "action_repeat", "=", "4", ",", "\n", "frame_history", "=", "1", ",", "\n", "renderer", "=", "\"hardware\"", ",", "\n", "fps", "=", "None", ",", "\n", "episode_length_seconds", "=", "None", ",", "\n", "config_kwargs", "=", "None", ",", "\n", "cache_dir", "=", "\"/data/adam/dmlab_cache\"", ",", "\n", "gpu_device_index", "=", "\"EGL_DEVICE_ID\"", ",", "\n", ")", ":", "\n", "        ", "if", "level", "in", "DMLAB30", ":", "\n", "            ", "level", "=", "\"/contributed/dmlab30/\"", "+", "level", "\n", "", "level_cache", "=", "None", "if", "cache_dir", "is", "None", "else", "LevelCache", "(", "cache_dir", ")", "\n", "config", "=", "dict", "(", "height", "=", "str", "(", "height", ")", ",", "width", "=", "str", "(", "width", ")", ")", "\n", "if", "fps", "is", "not", "None", ":", "\n", "            ", "config", "[", "\"fps\"", "]", "=", "str", "(", "fps", ")", "\n", "", "if", "episode_length_seconds", "is", "not", "None", ":", "\n", "            ", "config", "[", "\"episodeLengthSeconds\"", "]", "=", "str", "(", "episode_length_seconds", ")", "\n", "", "if", "gpu_device_index", "is", "not", "None", ":", "\n", "            ", "if", "isinstance", "(", "gpu_device_index", ",", "int", ")", ":", "\n", "                ", "gpu_device_index", "=", "str", "(", "gpu_device_index", ")", "\n", "", "else", ":", "\n", "                ", "gpu_device_index", "=", "os", ".", "environ", ".", "get", "(", "gpu_device_index", ",", "\"0\"", ")", "\n", "", "config", "[", "\"gpuDeviceIndex\"", "]", "=", "gpu_device_index", "\n", "", "if", "config_kwargs", "is", "not", "None", ":", "\n", "            ", "if", "config", ".", "keys", "(", ")", "&", "config_kwargs", ".", "keys", "(", ")", ":", "\n", "                ", "raise", "KeyError", "(", "f\"Had duplicate key(s) in config_kwargs: \"", "\n", "f\"{config.keys() & config_kwargs.keys()}\"", ")", "\n", "", "config", ".", "update", "(", "config_kwargs", ")", "\n", "", "self", ".", "dmlab_env", "=", "deepmind_lab", ".", "Lab", "(", "\n", "level", "=", "level", ",", "\n", "observations", "=", "[", "\"RGB\"", "]", ",", "\n", "config", "=", "config", ",", "\n", "renderer", "=", "renderer", ",", "\n", "level_cache", "=", "level_cache", ",", "\n", ")", "\n", "self", ".", "_action_map", "=", "np", ".", "array", "(", "[", "\n", "[", "0", ",", "0", ",", "0", ",", "1", ",", "0", ",", "0", ",", "0", "]", ",", "# Forward", "\n", "[", "0", ",", "0", ",", "0", ",", "-", "1", ",", "0", ",", "0", ",", "0", "]", ",", "# Backward", "\n", "[", "0", ",", "0", ",", "-", "1", ",", "0", ",", "0", ",", "0", ",", "0", "]", ",", "# Move Left", "\n", "[", "0", ",", "0", ",", "1", ",", "0", ",", "0", ",", "0", ",", "0", "]", ",", "# Move Right", "\n", "[", "-", "20", ",", "0", ",", "0", ",", "0", ",", "0", ",", "0", ",", "0", "]", ",", "# Look Left", "\n", "[", "20", ",", "0", ",", "0", ",", "0", ",", "0", ",", "0", ",", "0", "]", ",", "# Look Right", "\n", "[", "-", "20", ",", "0", ",", "0", ",", "1", ",", "0", ",", "0", ",", "0", "]", ",", "# Left Forward", "\n", "[", "20", ",", "0", ",", "0", ",", "1", ",", "0", ",", "0", ",", "0", "]", ",", "# Right Forward", "\n", "[", "0", ",", "0", ",", "0", ",", "0", ",", "1", ",", "0", ",", "0", "]", ",", "# Fire", "\n", "]", ",", "dtype", "=", "np", ".", "int32", ")", "\n", "self", ".", "_action_space", "=", "IntBox", "(", "low", "=", "0", ",", "high", "=", "len", "(", "self", ".", "_action_map", ")", ")", "\n", "self", ".", "_observation_space", "=", "IntBox", "(", "low", "=", "0", ",", "high", "=", "256", ",", "\n", "shape", "=", "(", "3", "*", "frame_history", ",", "height", ",", "width", ")", ",", "dtype", "=", "np", ".", "uint8", ")", "\n", "self", ".", "_zero_obs", "=", "np", ".", "zeros", "(", "(", "3", ",", "height", ",", "width", ")", ",", "dtype", "=", "np", ".", "uint8", ")", "\n", "if", "frame_history", ">", "1", ":", "\n", "            ", "self", ".", "_obs_deque", "=", "deque", "(", "maxlen", "=", "frame_history", ")", "\n", "", "self", ".", "_frame_history", "=", "frame_history", "\n", "self", ".", "_action_repeat", "=", "action_repeat", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.envs.dmlab.DmlabEnv.reset": [[75, 81], ["dmlab.DmlabEnv.dmlab_env.reset", "range", "dmlab.DmlabEnv.update_obs", "dmlab.DmlabEnv._obs_deque.append"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.safe.safety_gym_env.SafetyGymEnvWrapper.reset", "home.repos.pwc.inspect_result.astooke_rlpyt.envs.dmlab.DmlabEnv.update_obs"], ["", "def", "reset", "(", "self", ")", ":", "\n", "        ", "self", ".", "dmlab_env", ".", "reset", "(", ")", "\n", "for", "_", "in", "range", "(", "self", ".", "_frame_history", "-", "1", ")", ":", "\n", "            ", "self", ".", "_obs_deque", ".", "append", "(", "self", ".", "_zero_obs", ")", "\n", "", "obs", ",", "_", "=", "self", ".", "update_obs", "(", ")", "\n", "return", "obs", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.envs.dmlab.DmlabEnv.step": [[82, 87], ["dmlab.DmlabEnv.dmlab_env.step", "dmlab.DmlabEnv.update_obs"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.safe.safety_gym_env.SafetyGymTrajInfo.step", "home.repos.pwc.inspect_result.astooke_rlpyt.envs.dmlab.DmlabEnv.update_obs"], ["", "def", "step", "(", "self", ",", "action", ")", ":", "\n", "        ", "reward", "=", "self", ".", "dmlab_env", ".", "step", "(", "self", ".", "_action_map", "[", "action", "]", ",", "\n", "num_steps", "=", "self", ".", "_action_repeat", ")", "\n", "obs", ",", "done", "=", "self", ".", "update_obs", "(", ")", "\n", "return", "obs", ",", "reward", ",", "done", ",", "(", ")", "# Might need to make dummy namedtuple?", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.envs.dmlab.DmlabEnv.update_obs": [[88, 95], ["dmlab.DmlabEnv.dmlab_env.is_running", "dmlab.DmlabEnv._obs_deque.append", "numpy.concatenate", "dmlab.DmlabEnv.dmlab_env.observations"], "methods", ["None"], ["", "def", "update_obs", "(", "self", ")", ":", "\n", "        ", "done", "=", "not", "self", ".", "dmlab_env", ".", "is_running", "(", ")", "\n", "obs", "=", "self", ".", "_zero_obs", "if", "done", "else", "self", ".", "dmlab_env", ".", "observations", "(", ")", "[", "\"RGB\"", "]", "\n", "if", "self", ".", "_frame_history", ">", "1", ":", "\n", "            ", "self", ".", "_obs_deque", ".", "append", "(", "obs", ")", "\n", "obs", "=", "np", ".", "concatenate", "(", "self", ".", "_obs_deque", ")", "# OLDEST to NEWEST", "\n", "", "return", "obs", ",", "done", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.envs.dmlab.DmlabEnv.close": [[96, 98], ["dmlab.DmlabEnv.dmlab_env.close"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.envs.dmlab.DmlabEnv.close"], ["", "def", "close", "(", "self", ")", ":", "\n", "        ", "self", ".", "dmlab_env", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.envs.dmlab.LevelCache.__init__": [[103, 105], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "cache_dir", ")", ":", "\n", "        ", "self", ".", "_cache_dir", "=", "cache_dir", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.envs.dmlab.LevelCache.fetch": [[106, 114], ["os.join", "os.join", "os.isfile", "os.isfile", "shutil.copyfile"], "methods", ["None"], ["", "def", "fetch", "(", "self", ",", "key", ",", "pk3_path", ")", ":", "\n", "        ", "path", "=", "osp", ".", "join", "(", "self", ".", "_cache_dir", ",", "key", ")", "\n", "\n", "if", "osp", ".", "isfile", "(", "path", ")", ":", "\n", "# Copy the cached file to the path expected by DeepMind Lab.", "\n", "            ", "shutil", ".", "copyfile", "(", "path", ",", "pk3_path", ")", "\n", "return", "True", "\n", "", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.envs.dmlab.LevelCache.write": [[115, 121], ["os.join", "os.join", "os.isfile", "os.isfile", "shutil.copyfile"], "methods", ["None"], ["", "def", "write", "(", "self", ",", "key", ",", "pk3_path", ")", ":", "\n", "        ", "path", "=", "osp", ".", "join", "(", "self", ".", "_cache_dir", ",", "key", ")", "\n", "\n", "if", "not", "osp", ".", "isfile", "(", "path", ")", ":", "\n", "# Copy the cached file DeepMind Lab has written to the cache directory.", "\n", "            ", "shutil", ".", "copyfile", "(", "pk3_path", ",", "path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.distributions.base.Distribution.dim": [[13, 16], ["None"], "methods", ["None"], ["\n", "def", "initialize", "(", "self", ",", "agent", ",", "n_itr", ",", "batch_spec", ",", "mid_batch_reset", ",", "examples", ",", "\n", "world_size", "=", "1", ",", "rank", "=", "0", ")", ":", "\n", "        "]], "home.repos.pwc.inspect_result.astooke_rlpyt.distributions.base.Distribution.sample": [[17, 20], ["None"], "methods", ["None"], []], "home.repos.pwc.inspect_result.astooke_rlpyt.distributions.base.Distribution.kl": [[21, 27], ["None"], "methods", ["None"], ["\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.distributions.base.Distribution.mean_kl": [[28, 34], ["None"], "methods", ["None"], ["raise", "NotImplementedError", "\n", "\n", "", "def", "async_initialize", "(", "self", ",", "agent", ",", "sampler_n_itr", ",", "batch_spec", ",", "mid_batch_reset", ",", "\n", "examples", ",", "world_size", "=", "1", ")", ":", "\n", "        ", "\"\"\"Called instead of ``initialize()`` in async runner (not needed unless\n        using async runner). Should return async replay_buffer using shared\n        memory.\"\"\"", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.distributions.base.Distribution.log_likelihood": [[35, 41], ["None"], "methods", ["None"], ["raise", "NotImplementedError", "\n", "\n", "", "def", "optim_initialize", "(", "self", ",", "rank", "=", "0", ")", ":", "\n", "        ", "\"\"\"Called in async runner which requires two stages of initialization;\n        might also be used in ``initialize()`` to avoid redundant code.\"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.distributions.base.Distribution.likelihood_ratio": [[42, 49], ["None"], "methods", ["None"], ["", "def", "optimize_agent", "(", "self", ",", "itr", ",", "samples", "=", "None", ",", "sampler_itr", "=", "None", ")", ":", "\n", "        "]], "home.repos.pwc.inspect_result.astooke_rlpyt.distributions.base.Distribution.entropy": [[50, 56], ["None"], "methods", ["None"], ["\n", "raise", "NotImplementedError", "\n", "\n", "", "def", "optim_state_dict", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.distributions.base.Distribution.perplexity": [[57, 60], ["torch.exp", "base.Distribution.entropy"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.distributions.gaussian.Gaussian.entropy"], ["        ", "\"\"\"Return the optimizer state dict (e.g. Adam); overwrite if using\n        multiple optimizers.\"\"\"", "\n", "return", "self", ".", "optimizer", ".", "state_dict", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.distributions.base.Distribution.mean_entropy": [[61, 65], ["rlpyt.utils.tensor.valid_mean", "base.Distribution.entropy"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.utils.tensor.valid_mean", "home.repos.pwc.inspect_result.astooke_rlpyt.distributions.gaussian.Gaussian.entropy"], ["", "def", "load_optim_state_dict", "(", "self", ",", "state_dict", ")", ":", "\n", "        ", "\"\"\"Load an optimizer state dict; should expect the format returned\n        from ``optim_state_dict().``\"\"\"", "\n", "self", ".", "optimizer", ".", "load_state_dict", "(", "state_dict", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.distributions.base.Distribution.mean_perplexity": [[66, 69], ["rlpyt.utils.tensor.valid_mean", "base.Distribution.perplexity"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.utils.tensor.valid_mean", "home.repos.pwc.inspect_result.astooke_rlpyt.distributions.gaussian.Gaussian.perplexity"], ["", "@", "property", "\n", "def", "batch_size", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_batch_size", "# For logging at least.", "\n", "", "", ""]], "home.repos.pwc.inspect_result.astooke_rlpyt.distributions.epsilon_greedy.EpsilonGreedy.__init__": [[11, 14], ["rlpyt.distributions.discrete.DiscreteMixin.__init__"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.spaces.gym_wrapper.GymSpaceWrapper.__init__"], ["\n", "class", "EpsilonGreedyAgentMixin", ":", "\n", "    "]], "home.repos.pwc.inspect_result.astooke_rlpyt.distributions.epsilon_greedy.EpsilonGreedy.sample": [[15, 23], ["torch.argmax", "torch.randint", "torch.rand", "mask.sum"], "methods", ["None"], ["\n", "\n", "def", "__init__", "(", "\n", "self", ",", "\n", "eps_init", "=", "1", ",", "\n", "eps_final", "=", "0.01", ",", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.distributions.epsilon_greedy.EpsilonGreedy.epsilon": [[24, 27], ["None"], "methods", ["None"], ["eps_final_min", "=", "None", ",", "# Give < eps_final for vector epsilon.", "\n", "eps_itr_min", "=", "50", ",", "# Algo may overwrite.", "\n", "eps_itr_max", "=", "1000", ",", "\n", "eps_eval", "=", "0.001", ",", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.distributions.epsilon_greedy.EpsilonGreedy.set_epsilon": [[28, 31], ["None"], "methods", ["None"], ["*", "args", ",", "\n", "**", "kwargs", "\n", ")", ":", "\n", "        "]], "home.repos.pwc.inspect_result.astooke_rlpyt.distributions.epsilon_greedy.CategoricalEpsilonGreedy.__init__": [[37, 40], ["epsilon_greedy.EpsilonGreedy.__init__"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.spaces.gym_wrapper.GymSpaceWrapper.__init__"], ["self", ".", "_eps_itr_min_max", "=", "np_mp_array", "(", "2", ",", "\"int\"", ")", "# Shared memory for CpuSampler", "\n", "self", ".", "_eps_itr_min_max", "[", "0", "]", "=", "eps_itr_min", "\n", "self", ".", "_eps_itr_min_max", "[", "1", "]", "=", "eps_itr_max", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.distributions.epsilon_greedy.CategoricalEpsilonGreedy.sample": [[41, 47], ["torch.tensordot", "epsilon_greedy.EpsilonGreedy.sample"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.spaces.gym_wrapper.GymSpaceWrapper.sample"], ["", "def", "collector_initialize", "(", "self", ",", "global_B", "=", "1", ",", "env_ranks", "=", "None", ")", ":", "\n", "        ", "\"\"\"For vector-valued epsilon, the agent inside the sampler worker process\n        must initialize with its own epsilon values.\"\"\"", "\n", "if", "env_ranks", "is", "not", "None", ":", "\n", "            ", "self", ".", "make_vec_eps", "(", "global_B", ",", "env_ranks", ")", "\n", "\n", "", "", "def", "make_vec_eps", "(", "self", ",", "global_B", ",", "env_ranks", ")", ":", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.distributions.epsilon_greedy.CategoricalEpsilonGreedy.set_z": [[48, 51], ["None"], "methods", ["None"], ["        ", "\"\"\"Construct log-spaced epsilon values and select local assignments\n        from the global number of sampler environment instances (for SyncRl\n        and AsyncRl).\"\"\"", "\n", "if", "(", "self", ".", "eps_final_min", "is", "not", "None", "and", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.distributions.categorical.Categorical.kl": [[17, 21], ["torch.sum", "torch.log", "torch.log"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.logging.console.log", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.console.log"], ["\n", "\n", "def", "__call__", "(", "self", ",", "observation", ",", "prev_action", ",", "prev_reward", ")", ":", "\n", "        ", "prev_action", "=", "self", ".", "distribution", ".", "to_onehot", "(", "prev_action", ")", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.distributions.categorical.Categorical.mean_kl": [[22, 24], ["rlpyt.utils.tensor.valid_mean", "categorical.Categorical.kl"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.utils.tensor.valid_mean", "home.repos.pwc.inspect_result.astooke_rlpyt.distributions.gaussian.Gaussian.kl"], ["model_inputs", "=", "buffer_to", "(", "(", "observation", ",", "prev_action", ",", "prev_reward", ")", ",", "\n", "device", "=", "self", ".", "device", ")", "\n", "pi", ",", "value", "=", "self", ".", "model", "(", "*", "model_inputs", ")", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.distributions.categorical.Categorical.sample": [[25, 31], ["torch.multinomial", "torch.multinomial.view().type", "p.view", "torch.multinomial.view"], "methods", ["None"], ["return", "buffer_to", "(", "(", "DistInfo", "(", "prob", "=", "pi", ")", ",", "value", ")", ",", "device", "=", "\"cpu\"", ")", "\n", "\n", "", "def", "initialize", "(", "self", ",", "env_spaces", ",", "share_memory", "=", "False", ",", "\n", "global_B", "=", "1", ",", "env_ranks", "=", "None", ")", ":", "\n", "        ", "super", "(", ")", ".", "initialize", "(", "env_spaces", ",", "share_memory", ",", "\n", "global_B", "=", "global_B", ",", "env_ranks", "=", "env_ranks", ")", "\n", "self", ".", "distribution", "=", "Categorical", "(", "dim", "=", "env_spaces", ".", "action", ".", "n", ")", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.distributions.categorical.Categorical.entropy": [[32, 35], ["torch.sum", "torch.log"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.logging.console.log"], ["\n", "", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "step", "(", "self", ",", "observation", ",", "prev_action", ",", "prev_reward", ")", ":", "\n", "        ", "prev_action", "=", "self", ".", "distribution", ".", "to_onehot", "(", "prev_action", ")", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.distributions.categorical.Categorical.log_likelihood": [[36, 39], ["rlpyt.utils.tensor.select_at_indexes", "torch.log"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.utils.tensor.select_at_indexes", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.console.log"], ["model_inputs", "=", "buffer_to", "(", "(", "observation", ",", "prev_action", ",", "prev_reward", ")", ",", "\n", "device", "=", "self", ".", "device", ")", "\n", "pi", ",", "value", "=", "self", ".", "model", "(", "*", "model_inputs", ")", "\n", "dist_info", "=", "DistInfo", "(", "prob", "=", "pi", ")", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.distributions.categorical.Categorical.likelihood_ratio": [[40, 44], ["rlpyt.utils.tensor.select_at_indexes", "rlpyt.utils.tensor.select_at_indexes"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.utils.tensor.select_at_indexes", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.tensor.select_at_indexes"], ["action", "=", "self", ".", "distribution", ".", "sample", "(", "dist_info", ")", "\n", "agent_info", "=", "AgentInfo", "(", "dist_info", "=", "dist_info", ",", "value", "=", "value", ")", "\n", "action", ",", "agent_info", "=", "buffer_to", "(", "(", "action", ",", "agent_info", ")", ",", "device", "=", "\"cpu\"", ")", "\n", "return", "AgentStep", "(", "action", "=", "action", ",", "agent_info", "=", "agent_info", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.distributions.gaussian.Gaussian.__init__": [[27, 48], ["gaussian.Gaussian.set_std", "math.log", "math.log"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.distributions.gaussian.Gaussian.set_std", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.console.log", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.console.log"], ["global_B", "=", "1", ",", "env_ranks", "=", "None", ")", ":", "\n", "        ", "\"\"\"Extends base method to build Gaussian distribution.\"\"\"", "\n", "super", "(", ")", ".", "initialize", "(", "env_spaces", ",", "share_memory", ",", "\n", "global_B", "=", "global_B", ",", "env_ranks", "=", "env_ranks", ")", "\n", "assert", "len", "(", "env_spaces", ".", "action", ".", "shape", ")", "==", "1", "\n", "assert", "len", "(", "np", ".", "unique", "(", "env_spaces", ".", "action", ".", "high", ")", ")", "==", "1", "\n", "assert", "np", ".", "all", "(", "env_spaces", ".", "action", ".", "low", "==", "-", "env_spaces", ".", "action", ".", "high", ")", "\n", "self", ".", "distribution", "=", "Gaussian", "(", "\n", "dim", "=", "env_spaces", ".", "action", ".", "shape", "[", "0", "]", ",", "\n", "# min_std=MIN_STD,", "\n", "# clip=env_spaces.action.high[0],  # Probably +1?", "\n", ")", "\n", "\n", "", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "step", "(", "self", ",", "observation", ",", "prev_action", ",", "prev_reward", ")", ":", "\n", "        ", "\"\"\"\n        Compute policy's action distribution from inputs, and sample an\n        action. Calls the model to produce mean, log_std, and value estimate.\n        Moves inputs to device and returns outputs back to CPU, for the\n        sampler.  (no grad)\n        \"\"\"", "\n", "model_inputs", "=", "buffer_to", "(", "(", "observation", ",", "prev_action", ",", "prev_reward", ")", ",", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.distributions.gaussian.Gaussian.dim": [[49, 52], ["None"], "methods", ["None"], ["device", "=", "self", ".", "device", ")", "\n", "mu", ",", "log_std", ",", "value", "=", "self", ".", "model", "(", "*", "model_inputs", ")", "\n", "dist_info", "=", "DistInfoStd", "(", "mean", "=", "mu", ",", "log_std", "=", "log_std", ")", "\n", "action", "=", "self", ".", "distribution", ".", "sample", "(", "dist_info", ")", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.distributions.gaussian.Gaussian.kl": [[53, 77], ["torch.sum", "torch.exp", "torch.exp", "torch.clamp", "torch.clamp"], "methods", ["None"], ["agent_info", "=", "AgentInfo", "(", "dist_info", "=", "dist_info", ",", "value", "=", "value", ")", "\n", "action", ",", "agent_info", "=", "buffer_to", "(", "(", "action", ",", "agent_info", ")", ",", "device", "=", "\"cpu\"", ")", "\n", "return", "AgentStep", "(", "action", "=", "action", ",", "agent_info", "=", "agent_info", ")", "\n", "\n", "", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "value", "(", "self", ",", "observation", ",", "prev_action", ",", "prev_reward", ")", ":", "\n", "        ", "\"\"\"\n        Compute the value estimate for the environment state, e.g. for the\n        bootstrap value, V(s_{T+1}), in the sampler.  (no grad)\n        \"\"\"", "\n", "model_inputs", "=", "buffer_to", "(", "(", "observation", ",", "prev_action", ",", "prev_reward", ")", ",", "\n", "device", "=", "self", ".", "device", ")", "\n", "_mu", ",", "_log_std", ",", "value", "=", "self", ".", "model", "(", "*", "model_inputs", ")", "\n", "return", "value", ".", "to", "(", "\"cpu\"", ")", "\n", "\n", "\n", "", "", "class", "RecurrentGaussianPgAgentBase", "(", "BaseAgent", ")", ":", "\n", "\n", "    ", "def", "__call__", "(", "self", ",", "observation", ",", "prev_action", ",", "prev_reward", ",", "init_rnn_state", ")", ":", "\n", "        ", "\"\"\"Performs forward pass on training data, for algorithm (requires\n        recurrent state input).\"\"\"", "\n", "# Assume init_rnn_state already shaped: [N,B,H]", "\n", "model_inputs", "=", "buffer_to", "(", "(", "observation", ",", "prev_action", ",", "prev_reward", ",", "\n", "init_rnn_state", ")", ",", "device", "=", "self", ".", "device", ")", "\n", "mu", ",", "log_std", ",", "value", ",", "next_rnn_state", "=", "self", ".", "model", "(", "*", "model_inputs", ")", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.distributions.gaussian.Gaussian.mean_kl": [[78, 80], ["rlpyt.utils.tensor.valid_mean", "gaussian.Gaussian.kl"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.utils.tensor.valid_mean", "home.repos.pwc.inspect_result.astooke_rlpyt.distributions.gaussian.Gaussian.kl"], ["dist_info", ",", "value", "=", "buffer_to", "(", "(", "DistInfoStd", "(", "mean", "=", "mu", ",", "log_std", "=", "log_std", ")", ",", "value", ")", ",", "device", "=", "\"cpu\"", ")", "\n", "return", "dist_info", ",", "value", ",", "next_rnn_state", "# Leave rnn_state on device.", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.distributions.gaussian.Gaussian.entropy": [[81, 98], ["torch.sum", "torch.log", "torch.clamp", "math.log", "math.sqrt"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.logging.console.log", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.console.log"], ["", "def", "initialize", "(", "self", ",", "env_spaces", ",", "share_memory", "=", "False", ",", "\n", "global_B", "=", "1", ",", "env_ranks", "=", "None", ")", ":", "\n", "        ", "super", "(", ")", ".", "initialize", "(", "env_spaces", ",", "share_memory", ")", "\n", "assert", "len", "(", "env_spaces", ".", "action", ".", "shape", ")", "==", "1", "\n", "self", ".", "distribution", "=", "Gaussian", "(", "\n", "dim", "=", "env_spaces", ".", "action", ".", "shape", "[", "0", "]", ",", "\n", "# min_std=MIN_STD,", "\n", "# clip=env_spaces.action.high[0],  # Probably +1?", "\n", ")", "\n", "\n", "", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "step", "(", "self", ",", "observation", ",", "prev_action", ",", "prev_reward", ")", ":", "\n", "        "]], "home.repos.pwc.inspect_result.astooke_rlpyt.distributions.gaussian.Gaussian.perplexity": [[99, 101], ["torch.exp", "gaussian.Gaussian.entropy"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.distributions.gaussian.Gaussian.entropy"], ["\n", "agent_inputs", "=", "buffer_to", "(", "(", "observation", ",", "prev_action", ",", "prev_reward", ")", ",", "\n", "device", "=", "self", ".", "device", ")", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.distributions.gaussian.Gaussian.mean_entropy": [[102, 104], ["rlpyt.utils.tensor.valid_mean", "gaussian.Gaussian.entropy"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.utils.tensor.valid_mean", "home.repos.pwc.inspect_result.astooke_rlpyt.distributions.gaussian.Gaussian.entropy"], ["mu", ",", "log_std", ",", "value", ",", "rnn_state", "=", "self", ".", "model", "(", "*", "agent_inputs", ",", "self", ".", "prev_rnn_state", ")", "\n", "dist_info", "=", "DistInfoStd", "(", "mean", "=", "mu", ",", "log_std", "=", "log_std", ")", "\n", "action", "=", "self", ".", "distribution", ".", "sample", "(", "dist_info", ")", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.distributions.gaussian.Gaussian.mean_perplexity": [[105, 107], ["rlpyt.utils.tensor.valid_mean", "gaussian.Gaussian.perplexity"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.utils.tensor.valid_mean", "home.repos.pwc.inspect_result.astooke_rlpyt.distributions.gaussian.Gaussian.perplexity"], ["# Model handles None, but Buffer does not, make zeros if needed:", "\n", "prev_rnn_state", "=", "self", ".", "prev_rnn_state", "or", "buffer_func", "(", "rnn_state", ",", "torch", ".", "zeros_like", ")", "\n", "# Transpose the rnn_state from [N,B,H] --> [B,N,H] for storage.", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.distributions.gaussian.Gaussian.log_likelihood": [[108, 135], ["torch.exp", "torch.sum", "torch.clamp", "torch.log", "torch.sum", "torch.log", "math.log", "torch.tanh"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.logging.console.log", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.console.log", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.console.log"], ["# (Special case: model should always leave B dimension in.)", "\n", "prev_rnn_state", "=", "buffer_method", "(", "prev_rnn_state", ",", "\"transpose\"", ",", "0", ",", "1", ")", "\n", "agent_info", "=", "AgentInfoRnn", "(", "dist_info", "=", "dist_info", ",", "value", "=", "value", ",", "\n", "prev_rnn_state", "=", "prev_rnn_state", ")", "\n", "action", ",", "agent_info", "=", "buffer_to", "(", "(", "action", ",", "agent_info", ")", ",", "device", "=", "\"cpu\"", ")", "\n", "self", ".", "advance_rnn_state", "(", "rnn_state", ")", "# Keep on device.", "\n", "return", "AgentStep", "(", "action", "=", "action", ",", "agent_info", "=", "agent_info", ")", "\n", "\n", "", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "value", "(", "self", ",", "observation", ",", "prev_action", ",", "prev_reward", ")", ":", "\n", "        ", "\"\"\"\n        Compute the value estimate for the environment state using the\n        currently held recurrent state, without advancing the recurrent state,\n        e.g. for the bootstrap value V(s_{T+1}), in the sampler.  (no grad)\n        \"\"\"", "\n", "agent_inputs", "=", "buffer_to", "(", "(", "observation", ",", "prev_action", ",", "prev_reward", ")", ",", "\n", "device", "=", "self", ".", "device", ")", "\n", "_mu", ",", "_log_std", ",", "value", ",", "_rnn_state", "=", "self", ".", "model", "(", "*", "agent_inputs", ",", "self", ".", "prev_rnn_state", ")", "\n", "return", "value", ".", "to", "(", "\"cpu\"", ")", "\n", "\n", "\n", "", "", "class", "RecurrentGaussianPgAgent", "(", "RecurrentAgentMixin", ",", "RecurrentGaussianPgAgentBase", ")", ":", "\n", "    ", "pass", "\n", "\n", "\n", "", "class", "AlternatingRecurrentGaussianPgAgent", "(", "AlternatingRecurrentAgentMixin", ",", "\n", "RecurrentGaussianPgAgentBase", ")", ":", "\n", "    ", "pass", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.distributions.gaussian.Gaussian.likelihood_ratio": [[136, 140], ["gaussian.Gaussian.log_likelihood", "gaussian.Gaussian.log_likelihood", "torch.exp"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.distributions.gaussian.Gaussian.log_likelihood", "home.repos.pwc.inspect_result.astooke_rlpyt.distributions.gaussian.Gaussian.log_likelihood"], ["", ""]], "home.repos.pwc.inspect_result.astooke_rlpyt.distributions.gaussian.Gaussian.sample_loglikelihood": [[141, 156], ["gaussian.Gaussian.sample", "gaussian.Gaussian.log_likelihood", "torch.tanh"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.spaces.gym_wrapper.GymSpaceWrapper.sample", "home.repos.pwc.inspect_result.astooke_rlpyt.distributions.gaussian.Gaussian.log_likelihood"], []], "home.repos.pwc.inspect_result.astooke_rlpyt.distributions.gaussian.Gaussian.sample": [[185, 217], ["torch.exp", "gaussian.Gaussian.std.to", "torch.normal", "torch.clamp", "torch.clamp", "torch.clamp", "torch.zeros_like", "torch.ones_like", "torch.tanh"], "methods", ["None"], []], "home.repos.pwc.inspect_result.astooke_rlpyt.distributions.gaussian.Gaussian.set_clip": [[218, 222], ["None"], "methods", ["None"], []], "home.repos.pwc.inspect_result.astooke_rlpyt.distributions.gaussian.Gaussian.set_squash": [[223, 228], ["None"], "methods", ["None"], []], "home.repos.pwc.inspect_result.astooke_rlpyt.distributions.gaussian.Gaussian.set_noise_clip": [[229, 232], ["None"], "methods", ["None"], []], "home.repos.pwc.inspect_result.astooke_rlpyt.distributions.gaussian.Gaussian.set_std": [[233, 247], ["isinstance", "torch.tensor().float", "torch.tensor().float.numel", "torch.tensor"], "methods", ["None"], []], "home.repos.pwc.inspect_result.astooke_rlpyt.distributions.discrete.DiscreteMixin.__init__": [[10, 14], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "dim", ",", "dtype", "=", "torch", ".", "long", ",", "onehot_dtype", "=", "torch", ".", "float", ")", ":", "\n", "        ", "self", ".", "_dim", "=", "dim", "\n", "self", ".", "dtype", "=", "dtype", "\n", "self", ".", "onehot_dtype", "=", "onehot_dtype", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.distributions.discrete.DiscreteMixin.dim": [[15, 18], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "dim", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_dim", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.distributions.discrete.DiscreteMixin.to_onehot": [[19, 22], ["rlpyt.utils.tensor.to_onehot"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.distributions.discrete.DiscreteMixin.to_onehot"], ["", "def", "to_onehot", "(", "self", ",", "indexes", ",", "dtype", "=", "None", ")", ":", "\n", "        ", "\"\"\"Convert from integer indexes to one-hot, preserving leading dimensions.\"\"\"", "\n", "return", "to_onehot", "(", "indexes", ",", "self", ".", "_dim", ",", "dtype", "=", "dtype", "or", "self", ".", "onehot_dtype", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.distributions.discrete.DiscreteMixin.from_onehot": [[23, 26], ["rlpyt.utils.tensor.from_onehot"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.distributions.discrete.DiscreteMixin.from_onehot"], ["", "def", "from_onehot", "(", "self", ",", "onehot", ",", "dtype", "=", "None", ")", ":", "\n", "        ", "\"\"\"Convert from one-hot to integer indexes, preserving leading dimensions.\"\"\"", "\n", "return", "from_onehot", "(", "onehot", ",", "dtpye", "=", "dtype", "or", "self", ".", "dtype", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.astooke_rlpyt.models.conv2d.Conv2dModel.__init__": [[14, 45], ["super().__init__", "list", "zip", "torch.nn.Sequential", "len", "len", "len", "len", "torch.nn.Conv2d", "list.extend", "range", "zip", "list.append", "range", "len", "nonlinearity", "torch.nn.MaxPool2d", "len"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.spaces.gym_wrapper.GymSpaceWrapper.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "in_channels", ",", "\n", "channels", ",", "\n", "kernel_sizes", ",", "\n", "strides", ",", "\n", "paddings", "=", "None", ",", "\n", "nonlinearity", "=", "torch", ".", "nn", ".", "ReLU", ",", "# Module, not Functional.", "\n", "use_maxpool", "=", "False", ",", "# if True: convs use stride 1, maxpool downsample.", "\n", "head_sizes", "=", "None", ",", "# Put an MLP head on top.", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "if", "paddings", "is", "None", ":", "\n", "            ", "paddings", "=", "[", "0", "for", "_", "in", "range", "(", "len", "(", "channels", ")", ")", "]", "\n", "", "assert", "len", "(", "channels", ")", "==", "len", "(", "kernel_sizes", ")", "==", "len", "(", "strides", ")", "==", "len", "(", "paddings", ")", "\n", "in_channels", "=", "[", "in_channels", "]", "+", "channels", "[", ":", "-", "1", "]", "\n", "ones", "=", "[", "1", "for", "_", "in", "range", "(", "len", "(", "strides", ")", ")", "]", "\n", "if", "use_maxpool", ":", "\n", "            ", "maxp_strides", "=", "strides", "\n", "strides", "=", "ones", "\n", "", "else", ":", "\n", "            ", "maxp_strides", "=", "ones", "\n", "", "conv_layers", "=", "[", "torch", ".", "nn", ".", "Conv2d", "(", "in_channels", "=", "ic", ",", "out_channels", "=", "oc", ",", "\n", "kernel_size", "=", "k", ",", "stride", "=", "s", ",", "padding", "=", "p", ")", "for", "(", "ic", ",", "oc", ",", "k", ",", "s", ",", "p", ")", "in", "\n", "zip", "(", "in_channels", ",", "channels", ",", "kernel_sizes", ",", "strides", ",", "paddings", ")", "]", "\n", "sequence", "=", "list", "(", ")", "\n", "for", "conv_layer", ",", "maxp_stride", "in", "zip", "(", "conv_layers", ",", "maxp_strides", ")", ":", "\n", "            ", "sequence", ".", "extend", "(", "[", "conv_layer", ",", "nonlinearity", "(", ")", "]", ")", "\n", "if", "maxp_stride", ">", "1", ":", "\n", "                ", "sequence", ".", "append", "(", "torch", ".", "nn", ".", "MaxPool2d", "(", "maxp_stride", ")", ")", "# No padding.", "\n", "", "", "self", ".", "conv", "=", "torch", ".", "nn", ".", "Sequential", "(", "*", "sequence", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.models.conv2d.Conv2dModel.forward": [[46, 50], ["conv2d.Conv2dModel.conv"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input", ")", ":", "\n", "        ", "\"\"\"Computes the convolution stack on the input; assumes correct shape\n        already: [B,C,H,W].\"\"\"", "\n", "return", "self", ".", "conv", "(", "input", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.models.conv2d.Conv2dModel.conv_out_size": [[51, 65], ["conv2d.Conv2dModel.conv.children", "rlpyt.models.utils.conv2d_output_shape"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.models.utils.conv2d_output_shape"], ["", "def", "conv_out_size", "(", "self", ",", "h", ",", "w", ",", "c", "=", "None", ")", ":", "\n", "        ", "\"\"\"Helper function ot return the output size for a given input shape,\n        without actually performing a forward pass through the model.\"\"\"", "\n", "for", "child", "in", "self", ".", "conv", ".", "children", "(", ")", ":", "\n", "            ", "try", ":", "\n", "                ", "h", ",", "w", "=", "conv2d_output_shape", "(", "h", ",", "w", ",", "child", ".", "kernel_size", ",", "\n", "child", ".", "stride", ",", "child", ".", "padding", ")", "\n", "", "except", "AttributeError", ":", "\n", "                ", "pass", "# Not a conv or maxpool layer.", "\n", "", "try", ":", "\n", "                ", "c", "=", "child", ".", "out_channels", "\n", "", "except", "AttributeError", ":", "\n", "                ", "pass", "# Not a conv layer.", "\n", "", "", "return", "h", "*", "w", "*", "c", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.models.conv2d.Conv2dHeadModel.__init__": [[73, 108], ["super().__init__", "conv2d.Conv2dModel", "conv2d.Conv2dHeadModel.conv.conv_out_size", "rlpyt.models.mlp.MlpModel", "isinstance"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.spaces.gym_wrapper.GymSpaceWrapper.__init__", "home.repos.pwc.inspect_result.astooke_rlpyt.rl.atari_rl_models.AtariDqnModel.conv_out_size"], ["def", "__init__", "(", "\n", "self", ",", "\n", "image_shape", ",", "\n", "channels", ",", "\n", "kernel_sizes", ",", "\n", "strides", ",", "\n", "hidden_sizes", ",", "\n", "output_size", "=", "None", ",", "# if None: nonlinearity applied to output.", "\n", "paddings", "=", "None", ",", "\n", "nonlinearity", "=", "torch", ".", "nn", ".", "ReLU", ",", "\n", "use_maxpool", "=", "False", ",", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "c", ",", "h", ",", "w", "=", "image_shape", "\n", "self", ".", "conv", "=", "Conv2dModel", "(", "\n", "in_channels", "=", "c", ",", "\n", "channels", "=", "channels", ",", "\n", "kernel_sizes", "=", "kernel_sizes", ",", "\n", "strides", "=", "strides", ",", "\n", "paddings", "=", "paddings", ",", "\n", "nonlinearity", "=", "nonlinearity", ",", "\n", "use_maxpool", "=", "use_maxpool", ",", "\n", ")", "\n", "conv_out_size", "=", "self", ".", "conv", ".", "conv_out_size", "(", "h", ",", "w", ")", "\n", "if", "hidden_sizes", "or", "output_size", ":", "\n", "            ", "self", ".", "head", "=", "MlpModel", "(", "conv_out_size", ",", "hidden_sizes", ",", "\n", "output_size", "=", "output_size", ",", "nonlinearity", "=", "nonlinearity", ")", "\n", "if", "output_size", "is", "not", "None", ":", "\n", "                ", "self", ".", "_output_size", "=", "output_size", "\n", "", "else", ":", "\n", "                ", "self", ".", "_output_size", "=", "(", "hidden_sizes", "if", "\n", "isinstance", "(", "hidden_sizes", ",", "int", ")", "else", "hidden_sizes", "[", "-", "1", "]", ")", "\n", "", "", "else", ":", "\n", "            ", "self", ".", "head", "=", "lambda", "x", ":", "x", "\n", "self", ".", "_output_size", "=", "conv_out_size", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.models.conv2d.Conv2dHeadModel.forward": [[109, 113], ["conv2d.Conv2dHeadModel.head", "conv2d.Conv2dHeadModel.conv().view", "conv2d.Conv2dHeadModel.conv"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "input", ")", ":", "\n", "        ", "\"\"\"Compute the convolution and fully connected head on the input;\n        assumes correct input shape: [B,C,H,W].\"\"\"", "\n", "return", "self", ".", "head", "(", "self", ".", "conv", "(", "input", ")", ".", "view", "(", "input", ".", "shape", "[", "0", "]", ",", "-", "1", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.models.conv2d.Conv2dHeadModel.output_size": [[114, 118], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "output_size", "(", "self", ")", ":", "\n", "        ", "\"\"\"Returns the final output size after MLP head.\"\"\"", "\n", "return", "self", ".", "_output_size", "\n", "", "", ""]], "home.repos.pwc.inspect_result.astooke_rlpyt.models.running_mean_std.RunningMeanStdModel.__init__": [[14, 20], ["super().__init__", "running_mean_std.RunningMeanStdModel.register_buffer", "running_mean_std.RunningMeanStdModel.register_buffer", "running_mean_std.RunningMeanStdModel.register_buffer", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.spaces.gym_wrapper.GymSpaceWrapper.__init__", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.misc.zeros", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.misc.zeros", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.misc.zeros", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.misc.zeros", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.misc.zeros", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.misc.zeros", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.misc.zeros", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.misc.zeros"], ["def", "__init__", "(", "self", ",", "shape", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "register_buffer", "(", "\"mean\"", ",", "torch", ".", "zeros", "(", "shape", ")", ")", "\n", "self", ".", "register_buffer", "(", "\"var\"", ",", "torch", ".", "ones", "(", "shape", ")", ")", "\n", "self", ".", "register_buffer", "(", "\"count\"", ",", "torch", ".", "zeros", "(", "(", ")", ")", ")", "\n", "self", ".", "shape", "=", "shape", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.models.running_mean_std.RunningMeanStdModel.update": [[21, 46], ["rlpyt.utils.tensor.infer_leading_dims", "x.view.view.view", "x.view.view.mean", "x.view.view.var", "torch.is_initialized", "torch.is_initialized", "len", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.all_reduce", "torch.all_reduce", "torch.get_world_size", "torch.get_world_size"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.utils.tensor.infer_leading_dims"], ["", "def", "update", "(", "self", ",", "x", ")", ":", "\n", "        ", "_", ",", "T", ",", "B", ",", "_", "=", "infer_leading_dims", "(", "x", ",", "len", "(", "self", ".", "shape", ")", ")", "\n", "x", "=", "x", ".", "view", "(", "T", "*", "B", ",", "*", "self", ".", "shape", ")", "\n", "batch_mean", "=", "x", ".", "mean", "(", "dim", "=", "0", ")", "\n", "batch_var", "=", "x", ".", "var", "(", "dim", "=", "0", ",", "unbiased", "=", "False", ")", "\n", "batch_count", "=", "T", "*", "B", "\n", "if", "dist", ".", "is_initialized", "(", ")", ":", "# Assume need all-reduce.", "\n", "            ", "mean_var", "=", "torch", ".", "stack", "(", "[", "batch_mean", ",", "batch_var", "]", ")", "\n", "dist", ".", "all_reduce", "(", "mean_var", ")", "\n", "world_size", "=", "dist", ".", "get_world_size", "(", ")", "\n", "mean_var", "/=", "world_size", "\n", "batch_count", "*=", "world_size", "\n", "batch_mean", ",", "batch_var", "=", "mean_var", "[", "0", "]", ",", "mean_var", "[", "1", "]", "\n", "", "if", "self", ".", "count", "==", "0", ":", "\n", "            ", "self", ".", "mean", "[", ":", "]", "=", "batch_mean", "\n", "self", ".", "var", "[", ":", "]", "=", "batch_var", "\n", "", "else", ":", "\n", "            ", "delta", "=", "batch_mean", "-", "self", ".", "mean", "\n", "total", "=", "self", ".", "count", "+", "batch_count", "\n", "self", ".", "mean", "[", ":", "]", "=", "self", ".", "mean", "+", "delta", "*", "batch_count", "/", "total", "\n", "m_a", "=", "self", ".", "var", "*", "self", ".", "count", "\n", "m_b", "=", "batch_var", "*", "batch_count", "\n", "M2", "=", "m_a", "+", "m_b", "+", "delta", "**", "2", "*", "self", ".", "count", "*", "batch_count", "/", "total", "\n", "self", ".", "var", "[", ":", "]", "=", "M2", "/", "total", "\n", "", "self", ".", "count", "+=", "batch_count", "\n", "", "", ""]], "home.repos.pwc.inspect_result.astooke_rlpyt.models.mlp.MlpModel.__init__": [[15, 38], ["super().__init__", "isinstance", "list", "torch.nn.Sequential", "torch.nn.Linear", "list.extend", "list.append", "zip", "torch.nn.Linear", "nonlinearity"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.spaces.gym_wrapper.GymSpaceWrapper.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "input_size", ",", "\n", "hidden_sizes", ",", "# Can be empty list or None for none.", "\n", "output_size", "=", "None", ",", "# if None, last layer has nonlinearity applied.", "\n", "nonlinearity", "=", "torch", ".", "nn", ".", "ReLU", ",", "# Module, not Functional.", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "if", "isinstance", "(", "hidden_sizes", ",", "int", ")", ":", "\n", "            ", "hidden_sizes", "=", "[", "hidden_sizes", "]", "\n", "", "elif", "hidden_sizes", "is", "None", ":", "\n", "            ", "hidden_sizes", "=", "[", "]", "\n", "", "hidden_layers", "=", "[", "torch", ".", "nn", ".", "Linear", "(", "n_in", ",", "n_out", ")", "for", "n_in", ",", "n_out", "in", "\n", "zip", "(", "[", "input_size", "]", "+", "hidden_sizes", "[", ":", "-", "1", "]", ",", "hidden_sizes", ")", "]", "\n", "sequence", "=", "list", "(", ")", "\n", "for", "layer", "in", "hidden_layers", ":", "\n", "            ", "sequence", ".", "extend", "(", "[", "layer", ",", "nonlinearity", "(", ")", "]", ")", "\n", "", "if", "output_size", "is", "not", "None", ":", "\n", "            ", "last_size", "=", "hidden_sizes", "[", "-", "1", "]", "if", "hidden_sizes", "else", "input_size", "\n", "sequence", ".", "append", "(", "torch", ".", "nn", ".", "Linear", "(", "last_size", ",", "output_size", ")", ")", "\n", "", "self", ".", "model", "=", "torch", ".", "nn", ".", "Sequential", "(", "*", "sequence", ")", "\n", "self", ".", "_output_size", "=", "(", "hidden_sizes", "[", "-", "1", "]", "if", "output_size", "is", "None", "\n", "else", "output_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.models.mlp.MlpModel.forward": [[39, 42], ["mlp.MlpModel.model"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input", ")", ":", "\n", "        ", "\"\"\"Compute the model on the input, assuming input shape [B,input_size].\"\"\"", "\n", "return", "self", ".", "model", "(", "input", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.models.mlp.MlpModel.output_size": [[43, 47], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "output_size", "(", "self", ")", ":", "\n", "        ", "\"\"\"Retuns the output size of the model.\"\"\"", "\n", "return", "self", ".", "_output_size", "\n", "", "", ""]], "home.repos.pwc.inspect_result.astooke_rlpyt.models.utils.ScaleGrad.forward": [[22, 28], ["None"], "methods", ["None"], ["\n", "\n", "", "def", "generalized_advantage_estimation", "(", "reward", ",", "value", ",", "done", ",", "bootstrap_value", ",", "\n", "discount", ",", "gae_lambda", ",", "advantage_dest", "=", "None", ",", "return_dest", "=", "None", ")", ":", "\n", "    ", "\"\"\"Time-major inputs, optional other dimensions: [T], [T,B], etc.  Similar\n    to `discount_return()` but using Generalized Advantage Estimation to\n    compute advantages and returns.\"\"\"", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.models.utils.ScaleGrad.backward": [[29, 35], ["None"], "methods", ["None"], ["advantage", "=", "advantage_dest", "if", "advantage_dest", "is", "not", "None", "else", "zeros", "(", "\n", "reward", ".", "shape", ",", "dtype", "=", "reward", ".", "dtype", ")", "\n", "return_", "=", "return_dest", "if", "return_dest", "is", "not", "None", "else", "zeros", "(", "\n", "reward", ".", "shape", ",", "dtype", "=", "reward", ".", "dtype", ")", "\n", "nd", "=", "1", "-", "done", "\n", "nd", "=", "nd", ".", "type", "(", "reward", ".", "dtype", ")", "if", "isinstance", "(", "nd", ",", "torch", ".", "Tensor", ")", "else", "nd", "\n", "advantage", "[", "-", "1", "]", "=", "reward", "[", "-", "1", "]", "+", "discount", "*", "bootstrap_value", "*", "nd", "[", "-", "1", "]", "-", "value", "[", "-", "1", "]", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.models.utils.conv2d_output_shape": [[5, 16], ["isinstance", "isinstance", "isinstance"], "function", ["None"], ["from", "rlpyt", ".", "utils", ".", "misc", "import", "zeros", "\n", "\n", "\n", "def", "discount_return", "(", "reward", ",", "done", ",", "bootstrap_value", ",", "discount", ",", "return_dest", "=", "None", ")", ":", "\n", "    ", "\"\"\"Time-major inputs, optional other dimensions: [T], [T,B], etc. Computes\n    discounted sum of future rewards from each time-step to the end of the\n    batch, including bootstrapping value.  Sum resets where `done` is 1.\n    Optionally, writes to buffer `return_dest`, if provided.  Operations\n    vectorized across all trailing dimensions after the first [T,].\"\"\"", "\n", "return_", "=", "return_dest", "if", "return_dest", "is", "not", "None", "else", "zeros", "(", "\n", "reward", ".", "shape", ",", "dtype", "=", "reward", ".", "dtype", ")", "\n", "nd", "=", "1", "-", "done", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.models.utils.update_state_dict": [[42, 55], ["utils.strip_ddp_state_dict", "model.load_state_dict", "model.load_state_dict", "model.state_dict().items", "model.state_dict"], "function", ["home.repos.pwc.inspect_result.astooke_rlpyt.models.utils.strip_ddp_state_dict", "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.augmented_temporal_similarity.AugmentedTemporalSimilarity.load_state_dict", "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.augmented_temporal_similarity.AugmentedTemporalSimilarity.load_state_dict", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.collections.NamedArrayTuple.items", "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.replay_saver.DummyOptimizer.state_dict"], ["\n", "# def discount_return_n_step(reward, done, n_step, discount, return_dest=None,", "\n", "#         done_n_dest=None):", "\n", "#     \"\"\"Time-major inputs, optional other dimension: [T], [T,B], etc.\"\"\"", "\n", "#     rlen = reward.shape[0] - (n_step - 1)", "\n", "#     return_ = return_dest if return_dest is not None else zeros(", "\n", "#         (rlen,) + reward.shape[1:], dtype=reward.dtype)", "\n", "#     done_n = done_n_dest if done_n_dest is not None else zeros(", "\n", "#         (rlen,) + reward.shape[1:], dtype=done.dtype)", "\n", "#     return_[:] = reward[:rlen]  # 1-step return is current reward.", "\n", "#     done_n[:] = done[:rlen]  # True at time t if done any time by t + n - 1", "\n", "#     is_torch = isinstance(done, torch.Tensor)", "\n", "#     if is_torch:", "\n", "#         done_dtype = done.dtype", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.models.utils.strip_ddp_state_dict": [[57, 66], ["state_dict.items", "type"], "function", ["home.repos.pwc.inspect_result.astooke_rlpyt.utils.collections.NamedArrayTuple.items"], ["#         done = done.dtype(reward.dtype)", "\n", "#     if n_step > 1:", "\n", "#         for n in range(1, n_step):", "\n", "#             return_ += (discount ** n) * reward[n:n + rlen] * (1 - done_n)", "\n", "#             done_n = np.maximum(done_n, done[n:n + rlen])  # Supports tensors.", "\n", "#     if is_torch:", "\n", "#         done_n = done_n.type(done_dtype)", "\n", "#     return return_, done_n", "\n", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.models.dmlab_conv2d.DmlabConv2dModel.__init__": [[12, 66], ["super().__init__", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.MaxPool2d", "torch.nn.MaxPool2d", "torch.nn.MaxPool2d", "torch.nn.MaxPool2d", "torch.nn.MaxPool2d", "torch.nn.MaxPool2d", "torch.nn.MaxPool2d", "torch.nn.MaxPool2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.spaces.gym_wrapper.GymSpaceWrapper.__init__"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "in_channels", ",", "\n", "use_fourth_layer", "=", "True", ",", "\n", "skip_connections", "=", "True", ",", "\n", "use_maxpool", "=", "False", ",", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "conv1", "=", "torch", ".", "nn", ".", "Conv2d", "(", "\n", "in_channels", "=", "in_channels", ",", "\n", "out_channels", "=", "32", ",", "\n", "kernel_size", "=", "8", ",", "\n", "stride", "=", "1", "if", "use_maxpool", "else", "4", ",", "\n", "padding", "=", "2", "if", "use_maxpool", "else", "0", ",", "\n", ")", "\n", "self", ".", "maxpool1", "=", "torch", ".", "nn", ".", "MaxPool2d", "(", "kernel_size", "=", "4", ",", "stride", "=", "4", ")", "if", "use_maxpool", "else", "None", "\n", "self", ".", "conv2", "=", "torch", ".", "nn", ".", "Conv2d", "(", "\n", "in_channels", "=", "32", ",", "\n", "out_channels", "=", "64", ",", "\n", "kernel_size", "=", "4", ",", "\n", "stride", "=", "1", "if", "use_maxpool", "else", "2", ",", "\n", "padding", "=", "1", "if", "use_maxpool", "else", "0", ",", "\n", ")", "\n", "self", ".", "maxpool2", "=", "torch", ".", "nn", ".", "MaxPool2d", "(", "kernel_size", "=", "2", ",", "stride", "=", "2", ")", "if", "use_maxpool", "else", "None", "\n", "self", ".", "conv3", "=", "torch", ".", "nn", ".", "Conv2d", "(", "\n", "in_channels", "=", "64", ",", "\n", "out_channels", "=", "64", ",", "\n", "kernel_size", "=", "3", ",", "\n", "stride", "=", "1", ",", "\n", "padding", "=", "1", ",", "\n", ")", "\n", "if", "use_fourth_layer", ":", "\n", "            ", "self", ".", "conv4", "=", "torch", ".", "nn", ".", "Conv2d", "(", "\n", "in_channels", "=", "64", ",", "\n", "out_channels", "=", "64", ",", "\n", "kernel_size", "=", "3", ",", "\n", "stride", "=", "1", ",", "\n", "padding", "=", "1", ",", "\n", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "conv4", "=", "None", "\n", "# if skip_connections:", "\n", "#     if self.conv4 is not None and channels4 != c3:", "\n", "#         self.skip4 = torch.nn.Conv2d(", "\n", "#             in_channels=c3,", "\n", "#             out_channels=channels4,", "\n", "#             kernel_size=1,", "\n", "#             stride=1,", "\n", "#             padding=0,", "\n", "#         )", "\n", "#     else:", "\n", "#         self.skip4 = None", "\n", "", "self", ".", "skip_connections", "=", "skip_connections", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.models.dmlab_conv2d.DmlabConv2dModel.forward": [[67, 87], ["torch.relu", "torch.relu", "torch.relu", "torch.relu", "dmlab_conv2d.DmlabConv2dModel.conv3", "torch.relu", "torch.relu", "dmlab_conv2d.DmlabConv2dModel.conv4", "torch.relu", "torch.relu", "dmlab_conv2d.DmlabConv2dModel.conv1", "dmlab_conv2d.DmlabConv2dModel.maxpool1", "dmlab_conv2d.DmlabConv2dModel.conv2", "dmlab_conv2d.DmlabConv2dModel.maxpool2"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input", ")", ":", "\n", "        ", "conv1", "=", "F", ".", "relu", "(", "self", ".", "conv1", "(", "input", ")", ")", "\n", "if", "self", ".", "maxpool1", "is", "not", "None", ":", "\n", "            ", "conv1", "=", "self", ".", "maxpool1", "(", "conv1", ")", "\n", "", "conv2", "=", "F", ".", "relu", "(", "self", ".", "conv2", "(", "conv1", ")", ")", "\n", "if", "self", ".", "maxpool2", "is", "not", "None", ":", "\n", "            ", "conv2", "=", "self", ".", "maxpool2", "(", "conv2", ")", "\n", "", "conv3_pre", "=", "self", ".", "conv3", "(", "conv2", ")", "\n", "if", "self", ".", "skip_connections", ":", "\n", "            ", "conv3_pre", "=", "conv3_pre", "+", "conv2", "\n", "", "conv3", "=", "F", ".", "relu", "(", "conv3_pre", ")", "\n", "if", "self", ".", "conv4", "is", "None", ":", "\n", "            ", "return", "conv3", "\n", "", "conv4_pre", "=", "self", ".", "conv4", "(", "conv3", ")", "\n", "if", "self", ".", "skip_connections", ":", "\n", "# if self.skip4 is not None:", "\n", "#     conv3_pre = self.skip4(conv3_pre)", "\n", "            ", "conv4_pre", "=", "conv4_pre", "+", "conv3_pre", "\n", "", "conv4", "=", "F", ".", "relu", "(", "conv4_pre", ")", "\n", "return", "conv4", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.models.dmlab_conv2d.DmlabConv2dModel.output_shape": [[88, 102], ["dmlab_conv2d.DmlabConv2dModel.children", "rlpyt.models.utils.conv2d_output_shape"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.models.utils.conv2d_output_shape"], ["", "def", "output_shape", "(", "self", ",", "h", ",", "w", ",", "c", "=", "None", ")", ":", "\n", "        ", "\"\"\"Helper function ot return the output shape for a given input shape,\n        without actually performing a forward pass through the model.\"\"\"", "\n", "for", "child", "in", "self", ".", "children", "(", ")", ":", "\n", "            ", "try", ":", "\n", "                ", "h", ",", "w", "=", "conv2d_output_shape", "(", "h", ",", "w", ",", "child", ".", "kernel_size", ",", "\n", "child", ".", "stride", ",", "child", ".", "padding", ")", "\n", "", "except", "AttributeError", ":", "\n", "                ", "pass", "# Not a conv or maxpool layer.", "\n", "", "try", ":", "\n", "                ", "c", "=", "child", ".", "out_channels", "\n", "", "except", "AttributeError", ":", "\n", "                ", "pass", "# Not a conv layer.", "\n", "", "", "return", "c", ",", "h", ",", "w", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.models.dmlab_conv2d.DmlabConv2dModel.output_size": [[103, 108], ["dmlab_conv2d.DmlabConv2dModel.output_shape"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.rl.sac_rl_models.SacConvModel.output_shape"], ["", "def", "output_size", "(", "self", ",", "h", ",", "w", ",", "c", "=", "None", ")", ":", "\n", "        ", "\"\"\"Helper function ot return the output size for a given input shape,\n        without actually performing a forward pass through the model.\"\"\"", "\n", "c", ",", "h", ",", "w", "=", "self", ".", "output_shape", "(", "h", "=", "h", ",", "w", "=", "w", ",", "c", "=", "c", ")", "\n", "return", "c", "*", "h", "*", "w", "\n", "", "", ""]], "home.repos.pwc.inspect_result.astooke_rlpyt.ul.vae_models.VaeHeadModel.__init__": [[11, 19], ["super().__init__", "rlpyt.models.mlp.MlpModel"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.spaces.gym_wrapper.GymSpaceWrapper.__init__"], ["    ", "def", "__init__", "(", "self", ",", "latent_size", ",", "action_size", ",", "hidden_sizes", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "head", "=", "MlpModel", "(", "\n", "input_size", "=", "latent_size", "+", "action_size", ",", "\n", "hidden_sizes", "=", "hidden_sizes", ",", "\n", "output_size", "=", "latent_size", "*", "2", ",", "\n", ")", "\n", "self", ".", "_latent_size", "=", "latent_size", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.ul.vae_models.VaeHeadModel.forward": [[20, 32], ["torch.relu", "torch.relu", "vae_models.VaeHeadModel.head", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.randn_like", "torch.randn_like", "torch.randn_like", "torch.randn_like", "torch.cat", "torch.cat", "torch.cat", "torch.cat"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "h", ",", "action", "=", "None", ")", ":", "\n", "        ", "\"\"\"Assume [B] leading dimension.\"\"\"", "\n", "h", "=", "F", ".", "relu", "(", "h", ")", "\n", "x", "=", "h", "if", "action", "is", "None", "else", "torch", ".", "cat", "(", "[", "h", ",", "action", "]", ",", "dim", "=", "-", "1", ")", "\n", "head", "=", "self", ".", "head", "(", "x", ")", "\n", "mu", "=", "head", "[", ":", ",", ":", "-", "self", ".", "_latent_size", "]", "\n", "logvar", "=", "head", "[", ":", ",", "self", ".", "_latent_size", ":", "]", "\n", "\n", "std", "=", "torch", ".", "exp", "(", "0.5", "*", "logvar", ")", "\n", "eps", "=", "torch", ".", "randn_like", "(", "std", ")", "\n", "z", "=", "eps", "*", "std", "+", "mu", "\n", "return", "z", ",", "mu", ",", "logvar", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.ul.vae_models.VaeDecoderModel.__init__": [[36, 58], ["super().__init__", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "vae_models.ConvTranspose2dModel", "int", "numpy.prod"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.spaces.gym_wrapper.GymSpaceWrapper.__init__"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "latent_size", ",", "\n", "reshape", ",", "\n", "channels", "=", "None", ",", "\n", "kernel_sizes", "=", "None", ",", "\n", "strides", "=", "None", ",", "\n", "paddings", "=", "None", ",", "\n", "output_paddings", "=", "None", ",", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "linear", "=", "torch", ".", "nn", ".", "Linear", "(", "latent_size", ",", "int", "(", "np", ".", "prod", "(", "reshape", ")", ")", ")", "\n", "self", ".", "convt", "=", "ConvTranspose2dModel", "(", "\n", "in_channels", "=", "reshape", "[", "0", "]", ",", "\n", "channels", "=", "channels", "or", "[", "32", ",", "32", ",", "32", ",", "9", "]", ",", "# defaults for DMControl?", "\n", "kernel_sizes", "=", "kernel_sizes", "or", "[", "3", ",", "3", ",", "3", ",", "3", "]", ",", "\n", "strides", "=", "strides", "or", "[", "2", ",", "2", ",", "2", ",", "1", "]", ",", "\n", "paddings", "=", "paddings", "or", "[", "0", ",", "0", ",", "0", ",", "0", "]", ",", "\n", "output_paddings", "=", "output_paddings", "or", "[", "0", ",", "1", ",", "1", ",", "0", "]", ",", "\n", "sigmoid_output", "=", "True", ",", "\n", ")", "\n", "self", ".", "reshape", "=", "reshape", "# [e.g. (32, 9, 9)]", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.ul.vae_models.VaeDecoderModel.forward": [[59, 66], ["vae_models.VaeDecoderModel.linear", "x.reshape.reshape.reshape", "vae_models.VaeDecoderModel.convt"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "latent", ")", ":", "\n", "        ", "\"\"\"Assume [B] leading dimension.\"\"\"", "\n", "x", "=", "self", ".", "linear", "(", "latent", ")", "\n", "b", ",", "h", "=", "x", ".", "shape", "\n", "x", "=", "x", ".", "reshape", "(", "b", ",", "*", "self", ".", "reshape", ")", "\n", "convt", "=", "self", ".", "convt", "(", "x", ")", "\n", "return", "convt", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.ul.vae_models.ConvTranspose2dModel.__init__": [[70, 105], ["super().__init__", "list", "list.pop", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "len", "len", "len", "len", "len", "list", "torch.nn.ConvTranspose2d", "torch.nn.ConvTranspose2d", "torch.nn.ConvTranspose2d", "torch.nn.ConvTranspose2d", "list.append", "list.append", "list.append", "zip", "nonlinearity", "torch.nn.Sigmoid", "torch.nn.Sigmoid", "torch.nn.Sigmoid", "torch.nn.Sigmoid", "range", "range", "len", "len"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.spaces.gym_wrapper.GymSpaceWrapper.__init__"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "in_channels", ",", "\n", "channels", ",", "\n", "kernel_sizes", ",", "\n", "strides", ",", "\n", "paddings", "=", "None", ",", "\n", "output_paddings", "=", "None", ",", "\n", "nonlinearity", "=", "torch", ".", "nn", ".", "ReLU", ",", "\n", "sigmoid_output", "=", "False", ",", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "if", "paddings", "is", "None", ":", "\n", "            ", "paddings", "=", "[", "0", "for", "_", "in", "range", "(", "len", "(", "channels", ")", ")", "]", "\n", "", "if", "output_paddings", "is", "None", ":", "\n", "            ", "output_paddings", "=", "[", "0", "for", "_", "in", "range", "(", "len", "(", "channels", ")", ")", "]", "\n", "", "assert", "len", "(", "channels", ")", "==", "len", "(", "kernel_sizes", ")", "==", "len", "(", "strides", ")", "==", "len", "(", "paddings", ")", "==", "len", "(", "output_paddings", ")", "\n", "in_channels", "=", "[", "in_channels", "]", "+", "list", "(", "channels", "[", ":", "-", "1", "]", ")", "\n", "convt_layers", "=", "[", "torch", ".", "nn", ".", "ConvTranspose2d", "(", "\n", "in_channels", "=", "ic", ",", "\n", "out_channels", "=", "oc", ",", "\n", "kernel_size", "=", "k", ",", "\n", "stride", "=", "s", ",", "\n", "padding", "=", "p", ",", "\n", "output_padding", "=", "op", ",", ")", "\n", "for", "(", "ic", ",", "oc", ",", "k", ",", "s", ",", "p", ",", "op", ")", "in", "zip", "(", "\n", "in_channels", ",", "channels", ",", "kernel_sizes", ",", "strides", ",", "paddings", ",", "output_paddings", ")", "]", "\n", "sequence", "=", "list", "(", ")", "\n", "for", "convt_layer", "in", "convt_layers", ":", "\n", "            ", "sequence", ".", "append", "(", "convt_layer", ")", "\n", "sequence", ".", "append", "(", "nonlinearity", "(", ")", ")", "\n", "", "sequence", ".", "pop", "(", "-", "1", ")", "# Remove the last nonlinearity", "\n", "if", "sigmoid_output", ":", "\n", "            ", "sequence", ".", "append", "(", "torch", ".", "nn", ".", "Sigmoid", "(", ")", ")", "\n", "", "self", ".", "convt", "=", "torch", ".", "nn", ".", "Sequential", "(", "*", "sequence", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.ul.vae_models.ConvTranspose2dModel.forward": [[106, 109], ["vae_models.ConvTranspose2dModel.convt"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input", ")", ":", "\n", "        ", "\"\"\"Assumes shape is already [B,C,H,W].\"\"\"", "\n", "return", "self", ".", "convt", "(", "input", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.astooke_rlpyt.ul.atc_models.ContrastModel.__init__": [[10, 21], ["super().__init__", "torch.nn.Linear", "rlpyt.models.mlp.MlpModel"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.spaces.gym_wrapper.GymSpaceWrapper.__init__"], ["    ", "def", "__init__", "(", "self", ",", "latent_size", ",", "anchor_hidden_sizes", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "if", "anchor_hidden_sizes", "is", "not", "None", ":", "\n", "            ", "self", ".", "anchor_mlp", "=", "MlpModel", "(", "\n", "input_size", "=", "latent_size", ",", "\n", "hidden_sizes", "=", "anchor_hidden_sizes", ",", "\n", "output_size", "=", "latent_size", ",", "\n", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "anchor_mlp", "=", "None", "\n", "", "self", ".", "W", "=", "torch", ".", "nn", ".", "Linear", "(", "latent_size", ",", "latent_size", ",", "bias", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.ul.atc_models.ContrastModel.forward": [[22, 31], ["rlpyt.utils.tensor.infer_leading_dims", "atc_models.ContrastModel.W", "torch.matmul", "atc_models.ContrastModel.anchor_mlp", "torch.max"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.utils.tensor.infer_leading_dims"], ["", "def", "forward", "(", "self", ",", "anchor", ",", "positive", ")", ":", "\n", "        ", "lead_dim", ",", "T", ",", "B", ",", "_", "=", "infer_leading_dims", "(", "anchor", ",", "1", ")", "\n", "assert", "lead_dim", "==", "1", "# Assume [B,C] shape", "\n", "if", "self", ".", "anchor_mlp", "is", "not", "None", ":", "\n", "            ", "anchor", "=", "anchor", "+", "self", ".", "anchor_mlp", "(", "anchor", ")", "# skip probably helps", "\n", "", "pred", "=", "self", ".", "W", "(", "anchor", ")", "\n", "logits", "=", "torch", ".", "matmul", "(", "pred", ",", "positive", ".", "T", ")", "\n", "logits", "=", "logits", "-", "torch", ".", "max", "(", "logits", ",", "dim", "=", "1", ",", "keepdim", "=", "True", ")", "[", "0", "]", "# normalize", "\n", "return", "logits", "\n", "", "", ""]], "home.repos.pwc.inspect_result.astooke_rlpyt.ul.inverse_models.InverseModel.__init__": [[10, 31], ["super().__init__", "rlpyt.ul.models.mlp.MlpModel"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.spaces.gym_wrapper.GymSpaceWrapper.__init__"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "input_size", ",", "\n", "hidden_sizes", ",", "\n", "action_size", ",", "\n", "num_actions", ",", "\n", "subtract", "=", "False", ",", "\n", "use_input", "=", "\"conv\"", ",", "# [\"conv\", \"z\"]", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "if", "use_input", "!=", "\"conv\"", ":", "\n", "            ", "raise", "NotImplementedError", "\n", "", "self", ".", "mlp", "=", "MlpModel", "(", "\n", "input_size", "=", "2", "*", "input_size", ",", "\n", "hidden_sizes", "=", "hidden_sizes", ",", "\n", "output_size", "=", "action_size", "*", "num_actions", ",", "\n", ")", "\n", "self", ".", "_action_size", "=", "action_size", "\n", "self", ".", "_num_actions", "=", "num_actions", "\n", "self", ".", "_use_input", "=", "use_input", "\n", "self", ".", "_subtract", "=", "subtract", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.ul.inverse_models.InverseModel.forward": [[32, 43], ["rlpyt.utils.tensor.infer_leading_dims", "conv_obs.view", "conv_last.view", "torch.cat", "inverse_models.InverseModel.mlp", "act_logits.view.view.view"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.utils.tensor.infer_leading_dims"], ["", "def", "forward", "(", "self", ",", "conv_obs", ",", "conv_last", ")", ":", "\n", "        ", "lead_dim", ",", "T", ",", "B", ",", "_", "=", "infer_leading_dims", "(", "conv_obs", ",", "3", ")", "\n", "assert", "lead_dim", "==", "1", "# has [B], not [B,T]", "\n", "obs", "=", "conv_obs", ".", "view", "(", "B", ",", "-", "1", ")", "\n", "last", "=", "conv_last", ".", "view", "(", "B", ",", "-", "1", ")", "\n", "if", "self", ".", "_subtract", ":", "\n", "            ", "last", "=", "last", "-", "obs", "\n", "", "mlp_input", "=", "torch", ".", "cat", "(", "[", "obs", ",", "last", "]", ",", "dim", "=", "-", "1", ")", "\n", "act_logits", "=", "self", ".", "mlp", "(", "mlp_input", ")", "\n", "act_logits", "=", "act_logits", ".", "view", "(", "B", ",", "self", ".", "_num_actions", ",", "self", ".", "_action_size", ")", "\n", "return", "act_logits", "\n", "", "", ""]], "home.repos.pwc.inspect_result.astooke_rlpyt.ul.pixel_control_models.PixelControlModel.__init__": [[12, 55], ["super().__init__", "isinstance", "int", "pixel_control_models.ConvTranspose2dModel", "numpy.prod", "rlpyt.models.mlp.MlpModel", "int", "len", "int", "numpy.prod", "numpy.prod"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.spaces.gym_wrapper.GymSpaceWrapper.__init__"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "input_shape", ",", "\n", "fc_sizes", ",", "\n", "reshape", ",", "\n", "channels", ",", "\n", "kernel_sizes", ",", "\n", "strides", ",", "\n", "paddings", "=", "None", ",", "\n", "output_paddings", "=", "None", ",", "\n", "dueling", "=", "True", ",", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "if", "isinstance", "(", "input_shape", ",", "int", ")", ":", "\n", "            ", "input_shape", "=", "(", "input_shape", ",", ")", "\n", "", "self", ".", "input_shape", "=", "input_shape", "\n", "input_size", "=", "int", "(", "np", ".", "prod", "(", "input_shape", ")", ")", "\n", "if", "fc_sizes", "is", "None", ":", "\n", "            ", "self", ".", "mlp", "=", "None", "\n", "if", "reshape", "is", "None", ":", "# Then receiving conv input [C,H,W]", "\n", "                ", "assert", "len", "(", "input_shape", ")", "==", "3", "\n", "in_channels", "=", "input_shape", "[", "0", "]", "\n", "", "else", ":", "\n", "                ", "assert", "input_size", "==", "int", "(", "np", ".", "prod", "(", "reshape", ")", ")", "\n", "", "", "else", ":", "\n", "            ", "self", ".", "mlp", "=", "MlpModel", "(", "\n", "input_size", "=", "input_size", ",", "\n", "hidden_sizes", "=", "fc_sizes", ",", "\n", ")", "\n", "assert", "self", ".", "mlp", ".", "output_size", "==", "int", "(", "np", ".", "prod", "(", "reshape", ")", ")", "\n", "in_channels", "=", "reshape", "[", "0", "]", "\n", "", "self", ".", "reshape", "=", "reshape", "\n", "self", ".", "dueling", "=", "dueling", "\n", "if", "dueling", ":", "\n", "            ", "channels", "[", "-", "1", "]", "=", "channels", "[", "-", "1", "]", "+", "1", "# Add a Value channel (+ Advantages)", "\n", "", "self", ".", "convt", "=", "ConvTranspose2dModel", "(", "\n", "in_channels", "=", "in_channels", ",", "\n", "channels", "=", "channels", ",", "\n", "kernel_sizes", "=", "kernel_sizes", ",", "\n", "strides", "=", "strides", ",", "\n", "paddings", "=", "paddings", ",", "\n", "output_paddings", "=", "output_paddings", ",", "\n", "sigmoid_output", "=", "False", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.ul.pixel_control_models.PixelControlModel.forward": [[57, 71], ["rlpyt.utils.tensor.infer_leading_dims", "input.view", "pixel_control_models.PixelControlModel.convt", "rlpyt.utils.tensor.restore_leading_dims", "len", "pixel_control_models.PixelControlModel.mlp", "x.view.view.view", "input.view", "advantage.mean"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.utils.tensor.infer_leading_dims", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.tensor.restore_leading_dims"], ["", "def", "forward", "(", "self", ",", "input", ")", ":", "\n", "        ", "lead_dim", ",", "T", ",", "B", ",", "in_shape", "=", "infer_leading_dims", "(", "input", ",", "len", "(", "self", ".", "input_shape", ")", ")", "\n", "x", "=", "input", ".", "view", "(", "T", "*", "B", ",", "*", "in_shape", ")", "\n", "if", "self", ".", "mlp", "is", "not", "None", ":", "\n", "            ", "x", "=", "self", ".", "mlp", "(", "input", ".", "view", "(", "T", "*", "B", ",", "-", "1", ")", ")", "\n", "", "if", "self", ".", "reshape", "is", "not", "None", ":", "\n", "            ", "x", "=", "x", ".", "view", "(", "T", "*", "B", ",", "*", "self", ".", "reshape", ")", "\n", "", "x", "=", "self", ".", "convt", "(", "x", ")", "\n", "if", "self", ".", "dueling", ":", "# then x is shaped: [T*B,A+1,H,W]", "\n", "            ", "value", "=", "x", "[", ":", ",", ":", "1", "]", "# zeroth channel  [T*B,1,H,W]", "\n", "advantage", "=", "x", "[", ":", ",", "1", ":", "]", "# other channels [T*B,A,H,W]", "\n", "x", "=", "value", "+", "(", "advantage", "-", "advantage", ".", "mean", "(", "dim", "=", "1", ",", "keepdim", "=", "True", ")", ")", "\n", "", "x", "=", "restore_leading_dims", "(", "x", ",", "lead_dim", ",", "T", ",", "B", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.ul.pixel_control_models.ConvTranspose2dModel.__init__": [[75, 110], ["super().__init__", "list", "list.pop", "torch.nn.Sequential", "len", "len", "len", "len", "len", "torch.nn.ConvTranspose2d", "list.append", "list.append", "list.append", "zip", "nonlinearity", "torch.nn.Sigmoid", "range", "range", "len", "len"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.spaces.gym_wrapper.GymSpaceWrapper.__init__"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "in_channels", ",", "\n", "channels", ",", "\n", "kernel_sizes", ",", "\n", "strides", ",", "\n", "paddings", "=", "None", ",", "\n", "output_paddings", "=", "None", ",", "\n", "nonlinearity", "=", "torch", ".", "nn", ".", "ReLU", ",", "\n", "sigmoid_output", "=", "False", ",", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "if", "paddings", "is", "None", ":", "\n", "            ", "paddings", "=", "[", "0", "for", "_", "in", "range", "(", "len", "(", "channels", ")", ")", "]", "\n", "", "if", "output_paddings", "is", "None", ":", "\n", "            ", "output_paddings", "=", "[", "0", "for", "_", "in", "range", "(", "len", "(", "channels", ")", ")", "]", "\n", "", "assert", "len", "(", "channels", ")", "==", "len", "(", "kernel_sizes", ")", "==", "len", "(", "strides", ")", "==", "len", "(", "paddings", ")", "==", "len", "(", "output_paddings", ")", "\n", "in_channels", "=", "[", "in_channels", "]", "+", "channels", "[", ":", "-", "1", "]", "\n", "convt_layers", "=", "[", "torch", ".", "nn", ".", "ConvTranspose2d", "(", "\n", "in_channels", "=", "ic", ",", "\n", "out_channels", "=", "oc", ",", "\n", "kernel_size", "=", "k", ",", "\n", "stride", "=", "s", ",", "\n", "padding", "=", "p", ",", "\n", "output_padding", "=", "op", ",", ")", "\n", "for", "(", "ic", ",", "oc", ",", "k", ",", "s", ",", "p", ",", "op", ")", "in", "zip", "(", "\n", "in_channels", ",", "channels", ",", "kernel_sizes", ",", "strides", ",", "paddings", ",", "output_paddings", ")", "]", "\n", "sequence", "=", "list", "(", ")", "\n", "for", "convt_layer", "in", "convt_layers", ":", "\n", "            ", "sequence", ".", "append", "(", "convt_layer", ")", "\n", "sequence", ".", "append", "(", "nonlinearity", "(", ")", ")", "\n", "", "sequence", ".", "pop", "(", "-", "1", ")", "# Remove the last nonlinearity", "\n", "if", "sigmoid_output", ":", "\n", "            ", "sequence", ".", "append", "(", "torch", ".", "nn", ".", "Sigmoid", "(", ")", ")", "\n", "", "self", ".", "convt", "=", "torch", ".", "nn", ".", "Sequential", "(", "*", "sequence", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.ul.pixel_control_models.ConvTranspose2dModel.forward": [[111, 114], ["pixel_control_models.ConvTranspose2dModel.convt"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input", ")", ":", "\n", "        ", "\"\"\"Assumes shape is already [B,C,H,W].\"\"\"", "\n", "return", "self", ".", "convt", "(", "input", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.astooke_rlpyt.ul.encoders.EncoderModel.__init__": [[20, 50], ["super().__init__", "rlpyt.models.conv2d.Conv2dModel", "encoders.EncoderModel.conv.conv_out_size", "encoders.EncoderModel.conv.conv_out_shape", "rlpyt.models.mlp.MlpModel", "encoders.EncoderModel.apply"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.spaces.gym_wrapper.GymSpaceWrapper.__init__", "home.repos.pwc.inspect_result.astooke_rlpyt.rl.atari_rl_models.AtariDqnModel.conv_out_size", "home.repos.pwc.inspect_result.astooke_rlpyt.ul.stdim_models.Conv2dStdimModel.conv_out_shape"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "image_shape", ",", "\n", "latent_size", ",", "\n", "channels", ",", "\n", "kernel_sizes", ",", "\n", "strides", ",", "\n", "paddings", "=", "None", ",", "\n", "hidden_sizes", "=", "None", ",", "# usually None; NOT the same as anchor MLP", "\n", "kiaming_init", "=", "True", ",", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "c", ",", "h", ",", "w", "=", "image_shape", "\n", "self", ".", "conv", "=", "Conv2dModel", "(", "\n", "in_channels", "=", "c", ",", "\n", "channels", "=", "channels", ",", "\n", "kernel_sizes", "=", "kernel_sizes", ",", "\n", "strides", "=", "strides", ",", "\n", "paddings", "=", "paddings", ",", "\n", "use_maxpool", "=", "False", ",", "\n", ")", "\n", "self", ".", "_output_size", "=", "self", ".", "conv", ".", "conv_out_size", "(", "h", ",", "w", ")", "\n", "self", ".", "_output_shape", "=", "self", ".", "conv", ".", "conv_out_shape", "(", "h", ",", "w", ")", "\n", "self", ".", "head", "=", "MlpModel", "(", "\n", "input_size", "=", "self", ".", "_output_size", ",", "\n", "hidden_sizes", "=", "hidden_sizes", ",", "\n", "output_size", "=", "latent_size", ",", "\n", ")", "\n", "if", "kiaming_init", ":", "\n", "            ", "self", ".", "apply", "(", "weight_init", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.ul.encoders.EncoderModel.forward": [[51, 64], ["rlpyt.utils.tensor.infer_leading_dims", "encoders.EncoderModel.conv", "encoders.EncoderModel.head", "rlpyt.utils.tensor.restore_leading_dims", "observation.type", "img.mul_.mul_.mul_", "img.mul_.mul_.view", "encoders.EncoderModel.view"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.utils.tensor.infer_leading_dims", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.tensor.restore_leading_dims"], ["", "", "def", "forward", "(", "self", ",", "observation", ")", ":", "\n", "        ", "lead_dim", ",", "T", ",", "B", ",", "img_shape", "=", "infer_leading_dims", "(", "observation", ",", "3", ")", "\n", "if", "observation", ".", "dtype", "==", "torch", ".", "uint8", ":", "\n", "            ", "img", "=", "observation", ".", "type", "(", "torch", ".", "float", ")", "\n", "img", "=", "img", ".", "mul_", "(", "1.", "/", "255", ")", "\n", "", "else", ":", "\n", "            ", "img", "=", "observation", "\n", "", "conv", "=", "self", ".", "conv", "(", "img", ".", "view", "(", "T", "*", "B", ",", "*", "img_shape", ")", ")", "\n", "c", "=", "self", ".", "head", "(", "conv", ".", "view", "(", "T", "*", "B", ",", "-", "1", ")", ")", "\n", "\n", "c", ",", "conv", "=", "restore_leading_dims", "(", "(", "c", ",", "conv", ")", ",", "lead_dim", ",", "T", ",", "B", ")", "\n", "\n", "return", "c", ",", "conv", "# In case wanting to do something with conv output", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.ul.encoders.EncoderModel.output_size": [[65, 68], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "output_size", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_output_size", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.ul.encoders.EncoderModel.output_shape": [[69, 72], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "output_shape", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_output_shape", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.ul.encoders.DmlabEncoderModel.__init__": [[76, 103], ["super().__init__", "rlpyt.ul.models.dmlab_conv2d.DmlabConv2dModel", "encoders.DmlabEncoderModel.conv.output_size", "encoders.DmlabEncoderModel.conv.output_shape", "rlpyt.models.mlp.MlpModel", "encoders.DmlabEncoderModel.apply"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.spaces.gym_wrapper.GymSpaceWrapper.__init__", "home.repos.pwc.inspect_result.astooke_rlpyt.rl.sac_rl_models.SacFc1Model.output_size", "home.repos.pwc.inspect_result.astooke_rlpyt.rl.sac_rl_models.SacConvModel.output_shape"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "image_shape", ",", "\n", "latent_size", ",", "\n", "use_fourth_layer", "=", "True", ",", "\n", "skip_connections", "=", "True", ",", "\n", "hidden_sizes", "=", "None", ",", "\n", "kiaming_init", "=", "True", ",", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "c", ",", "h", ",", "w", "=", "image_shape", "\n", "self", ".", "conv", "=", "DmlabConv2dModel", "(", "\n", "in_channels", "=", "c", ",", "\n", "use_fourth_layer", "=", "True", ",", "\n", "skip_connections", "=", "skip_connections", ",", "\n", "use_maxpool", "=", "False", ",", "\n", ")", "\n", "self", ".", "_output_size", "=", "self", ".", "conv", ".", "output_size", "(", "h", ",", "w", ")", "\n", "self", ".", "_output_shape", "=", "self", ".", "conv", ".", "output_shape", "(", "h", ",", "w", ")", "\n", "\n", "self", ".", "head", "=", "MlpModel", "(", "# gets to z_t, not necessarily c_t", "\n", "input_size", "=", "self", ".", "_output_size", ",", "\n", "hidden_sizes", "=", "hidden_sizes", ",", "\n", "output_size", "=", "latent_size", ",", "\n", ")", "\n", "if", "kiaming_init", ":", "\n", "            ", "self", ".", "apply", "(", "weight_init", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.ul.encoders.DmlabEncoderModel.forward": [[104, 117], ["rlpyt.utils.tensor.infer_leading_dims", "encoders.DmlabEncoderModel.conv", "encoders.DmlabEncoderModel.head", "rlpyt.utils.tensor.restore_leading_dims", "observation.type", "img.mul_.mul_.mul_", "img.mul_.mul_.view", "encoders.DmlabEncoderModel.view"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.utils.tensor.infer_leading_dims", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.tensor.restore_leading_dims"], ["", "", "def", "forward", "(", "self", ",", "observation", ")", ":", "\n", "        ", "lead_dim", ",", "T", ",", "B", ",", "img_shape", "=", "infer_leading_dims", "(", "observation", ",", "3", ")", "\n", "if", "observation", ".", "dtype", "==", "torch", ".", "uint8", ":", "\n", "            ", "img", "=", "observation", ".", "type", "(", "torch", ".", "float", ")", "\n", "img", "=", "img", ".", "mul_", "(", "1.", "/", "255", ")", "\n", "", "else", ":", "\n", "            ", "img", "=", "observation", "\n", "", "conv", "=", "self", ".", "conv", "(", "img", ".", "view", "(", "T", "*", "B", ",", "*", "img_shape", ")", ")", "\n", "c", "=", "self", ".", "head", "(", "conv", ".", "view", "(", "T", "*", "B", ",", "-", "1", ")", ")", "\n", "\n", "c", ",", "conv", "=", "restore_leading_dims", "(", "(", "c", ",", "conv", ")", ",", "lead_dim", ",", "T", ",", "B", ")", "\n", "\n", "return", "c", ",", "conv", "# In case wanting to do something with conv output", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.ul.encoders.DmlabEncoderModel.output_size": [[118, 121], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "output_size", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_output_size", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.ul.encoders.DmlabEncoderModel.output_shape": [[122, 125], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "output_shape", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_output_shape", "\n", "", "", ""]], "home.repos.pwc.inspect_result.astooke_rlpyt.ul.encoders.weight_init": [[10, 16], ["isinstance", "torch.nn.init.kaiming_normal_", "torch.nn.init.zeros_"], "function", ["None"], ["def", "weight_init", "(", "m", ")", ":", "\n", "    ", "\"\"\"Kaiming_normal is standard for relu networks, sometimes.\"\"\"", "\n", "if", "isinstance", "(", "m", ",", "(", "torch", ".", "nn", ".", "Linear", ",", "torch", ".", "nn", ".", "Conv2d", ")", ")", ":", "\n", "        ", "torch", ".", "nn", ".", "init", ".", "kaiming_normal_", "(", "m", ".", "weight", ",", "mode", "=", "\"fan_in\"", ",", "\n", "nonlinearity", "=", "\"relu\"", ")", "\n", "torch", ".", "nn", ".", "init", ".", "zeros_", "(", "m", ".", "bias", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.ul.stdim_models.StDimEncoderModel.__init__": [[20, 51], ["super().__init__", "stdim_models.Conv2dStdimModel", "stdim_models.StDimEncoderModel.conv.conv_out_size", "stdim_models.StDimEncoderModel.conv.conv_out_shape", "stdim_models.StDimEncoderModel.conv.conv_layer_shapes", "rlpyt.models.mlp.MlpModel", "stdim_models.StDimEncoderModel.apply"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.spaces.gym_wrapper.GymSpaceWrapper.__init__", "home.repos.pwc.inspect_result.astooke_rlpyt.rl.atari_rl_models.AtariDqnModel.conv_out_size", "home.repos.pwc.inspect_result.astooke_rlpyt.ul.stdim_models.Conv2dStdimModel.conv_out_shape", "home.repos.pwc.inspect_result.astooke_rlpyt.ul.stdim_models.Conv2dStdimModel.conv_layer_shapes"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "image_shape", ",", "\n", "latent_size", ",", "\n", "channels", "=", "None", ",", "\n", "kernel_sizes", "=", "None", ",", "\n", "strides", "=", "None", ",", "\n", "paddings", "=", "None", ",", "\n", "hidden_sizes", "=", "None", ",", "\n", "kiaming_init", "=", "True", ",", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "c", ",", "h", ",", "w", "=", "image_shape", "\n", "self", ".", "conv", "=", "Conv2dStdimModel", "(", "\n", "in_channels", "=", "c", ",", "\n", "channels", "=", "channels", "or", "[", "32", ",", "64", ",", "64", "]", ",", "\n", "kernel_sizes", "=", "kernel_sizes", "or", "[", "8", ",", "4", ",", "3", "]", ",", "\n", "strides", "=", "strides", "or", "[", "4", ",", "2", ",", "1", "]", ",", "\n", "paddings", "=", "paddings", ",", "\n", "use_maxpool", "=", "False", ",", "\n", ")", "\n", "self", ".", "_output_size", "=", "self", ".", "conv", ".", "conv_out_size", "(", "h", ",", "w", ")", "\n", "self", ".", "_output_shape", "=", "self", ".", "conv", ".", "conv_out_shape", "(", "h", ",", "w", ")", "\n", "self", ".", "_conv_layer_shapes", "=", "self", ".", "conv", ".", "conv_layer_shapes", "(", "h", ",", "w", ")", "\n", "self", ".", "head", "=", "MlpModel", "(", "\n", "input_size", "=", "self", ".", "_output_size", ",", "\n", "hidden_sizes", "=", "hidden_sizes", ",", "\n", "output_size", "=", "latent_size", ",", "\n", ")", "\n", "if", "kiaming_init", ":", "\n", "            ", "self", ".", "apply", "(", "weight_init", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.ul.stdim_models.StDimEncoderModel.forward": [[52, 65], ["rlpyt.utils.tensor.infer_leading_dims", "stdim_models.StDimEncoderModel.conv", "stdim_models.StDimEncoderModel.head", "rlpyt.utils.tensor.restore_leading_dims", "rlpyt.utils.tensor.restore_leading_dims", "observation.type", "img.mul_.mul_.mul_", "img.mul_.mul_.view", "conv_layers[].view"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.utils.tensor.infer_leading_dims", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.tensor.restore_leading_dims", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.tensor.restore_leading_dims"], ["", "", "def", "forward", "(", "self", ",", "observation", ")", ":", "\n", "        ", "lead_dim", ",", "T", ",", "B", ",", "img_shape", "=", "infer_leading_dims", "(", "observation", ",", "3", ")", "\n", "if", "observation", ".", "dtype", "==", "torch", ".", "uint8", ":", "\n", "            ", "img", "=", "observation", ".", "type", "(", "torch", ".", "float", ")", "\n", "img", "=", "img", ".", "mul_", "(", "1.", "/", "255", ")", "\n", "", "else", ":", "\n", "            ", "img", "=", "observation", "\n", "", "conv", ",", "conv_layers", "=", "self", ".", "conv", "(", "img", ".", "view", "(", "T", "*", "B", ",", "*", "img_shape", ")", ")", "# lists all layers", "\n", "c", "=", "self", ".", "head", "(", "conv_layers", "[", "-", "1", "]", ".", "view", "(", "T", "*", "B", ",", "-", "1", ")", ")", "\n", "\n", "c", ",", "conv", "=", "restore_leading_dims", "(", "(", "c", ",", "conv", ")", ",", "lead_dim", ",", "T", ",", "B", ")", "\n", "conv_layers", "=", "restore_leading_dims", "(", "conv_layers", ",", "lead_dim", ",", "T", ",", "B", ")", "\n", "return", "c", ",", "conv", ",", "conv_layers", "# include conv_outs for local-stdim losses", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.ul.stdim_models.StDimEncoderModel.conv_layer_shapes": [[66, 69], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "conv_layer_shapes", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_conv_layer_shapes", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.ul.stdim_models.StDimEncoderModel.conv_out_shapes": [[70, 73], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "conv_out_shapes", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_conv_layer_shapes", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.ul.stdim_models.StDimEncoderModel.output_size": [[74, 77], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "output_size", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_output_size", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.ul.stdim_models.StDimEncoderModel.output_shape": [[78, 81], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "output_shape", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_output_shape", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.ul.stdim_models.StDimGlobalLocalContrastModel.__init__": [[87, 95], ["super().__init__", "rlpyt.models.mlp.MlpModel", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.spaces.gym_wrapper.GymSpaceWrapper.__init__"], ["def", "__init__", "(", "self", ",", "latent_size", ",", "local_size", ",", "anchor_hidden_sizes", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "anchor_mlp", "=", "MlpModel", "(", "\n", "input_size", "=", "latent_size", ",", "\n", "hidden_sizes", "=", "anchor_hidden_sizes", ",", "\n", "output_size", "=", "latent_size", ",", "\n", ")", "\n", "self", ".", "W", "=", "torch", ".", "nn", ".", "Linear", "(", "latent_size", ",", "local_size", ",", "bias", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.ul.stdim_models.StDimGlobalLocalContrastModel.forward": [[96, 118], ["list", "stdim_models.StDimGlobalLocalContrastModel.W", "range", "stdim_models.StDimGlobalLocalContrastModel.anchor_mlp", "range", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "list.append", "torch.max", "torch.max", "torch.max", "torch.max"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "anchor", ",", "positive", ")", ":", "\n", "# anchor shape is [B,Z], positive shape is [B,C,H,W]", "\n", "        ", "anchor", "=", "anchor", "+", "self", ".", "anchor_mlp", "(", "anchor", ")", "\n", "b", ",", "c", ",", "h", ",", "w", "=", "positive", ".", "shape", "\n", "\n", "# Vectorized form, way OOM:", "\n", "# positive = positive.permute(0, 2, 3, 1).reshape(b * h * w, c)", "\n", "# Wz = torch.matmul(self.W, positive.T)", "\n", "# logits = torch.matmul(anchor.repeat(h * w, 1), Wz)", "\n", "# logits = logits - torch.max(logits, dim=1, keepdim=True)[0]", "\n", "# logits = logits.view(b, h * w, -1)", "\n", "# logits_list = [logits[:, i] for i in range(h * w)]", "\n", "\n", "# Non-vectorized form -- fits in memory, more readable:", "\n", "logits_list", "=", "list", "(", ")", "\n", "pred", "=", "self", ".", "W", "(", "anchor", ")", "\n", "for", "y", "in", "range", "(", "h", ")", ":", "\n", "            ", "for", "x", "in", "range", "(", "w", ")", ":", "\n", "                ", "logits", "=", "torch", ".", "matmul", "(", "pred", ",", "positive", "[", ":", ",", ":", ",", "y", ",", "x", "]", ".", "T", ")", "\n", "logits", "=", "logits", "-", "torch", ".", "max", "(", "logits", ",", "dim", "=", "1", ",", "keepdim", "=", "True", ")", "[", "0", "]", "\n", "logits_list", ".", "append", "(", "logits", ")", "\n", "", "", "return", "logits_list", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.ul.stdim_models.StDimLocalLocalContrastModel.__init__": [[122, 130], ["super().__init__", "rlpyt.models.mlp.MlpModel", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.spaces.gym_wrapper.GymSpaceWrapper.__init__"], ["    ", "def", "__init__", "(", "self", ",", "local_size", ",", "anchor_hidden_sizes", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "anchor_mlp", "=", "MlpModel", "(", "\n", "input_size", "=", "local_size", ",", "\n", "hidden_sizes", "=", "anchor_hidden_sizes", ",", "\n", "output_size", "=", "local_size", ",", "\n", ")", "\n", "self", ".", "W", "=", "torch", ".", "nn", ".", "Linear", "(", "local_size", ",", "local_size", ",", "bias", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.ul.stdim_models.StDimLocalLocalContrastModel.forward": [[131, 158], ["list", "range", "range", "stdim_models.StDimLocalLocalContrastModel.W", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "list.append", "stdim_models.StDimLocalLocalContrastModel.anchor_mlp", "torch.max", "torch.max", "torch.max", "torch.max"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "anchor", ",", "positive", ")", ":", "\n", "# Every location in the anchor gets contrasted over the batch of", "\n", "# positives at the same location.", "\n", "# anchor and positive both [B,C,H,W]", "\n", "        ", "b", ",", "c", ",", "h", ",", "w", "=", "anchor", ".", "shape", "\n", "\n", "# Vectorized form, way OOM:", "\n", "# anchor = anchor.permute(0, 2, 3, 1).reshape(b * h * w, c)", "\n", "# positive = positive.permute(0, 2, 3, 1).reshape(b * h * w, c)", "\n", "# anchor = anchor + self.anchor_mlp(anchor)", "\n", "# Wz = torch.matmul(self.W, positive.T)", "\n", "# logits = torch.matmul(anchor, Wz)", "\n", "# logits = logits - torch.max(logits, dim=1, keepdim=True)[0]", "\n", "# logits = logits.view(b, h * w, -1)", "\n", "# logits_list = [logits[:, i] for i in range(h * w)]", "\n", "\n", "# Non-vectorized form -- fits in memory, more readable:", "\n", "logits_list", "=", "list", "(", ")", "\n", "for", "y", "in", "range", "(", "h", ")", ":", "\n", "            ", "for", "x", "in", "range", "(", "w", ")", ":", "\n", "                ", "anchor_xy", "=", "anchor", "[", ":", ",", ":", ",", "y", ",", "x", "]", "\n", "anchor_xy", "=", "anchor_xy", "+", "self", ".", "anchor_mlp", "(", "anchor_xy", ")", "\n", "pred_xy", "=", "self", ".", "W", "(", "anchor_xy", ")", "\n", "logits", "=", "torch", ".", "matmul", "(", "pred_xy", ",", "positive", "[", ":", ",", ":", ",", "y", ",", "x", "]", ".", "T", ")", "\n", "logits", "=", "logits", "-", "torch", ".", "max", "(", "logits", ",", "dim", "=", "1", ",", "keepdim", "=", "True", ")", "[", "0", "]", "\n", "logits_list", ".", "append", "(", "logits", ")", "\n", "", "", "return", "logits_list", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.ul.stdim_models.Conv2dStdimModel.__init__": [[162, 205], ["super().__init__", "list", "list", "zip", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "len", "len", "len", "len", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "list.append", "list.append", "range", "zip", "nonlinearity", "torch.nn.MaxPool2d", "torch.nn.MaxPool2d", "torch.nn.MaxPool2d", "torch.nn.MaxPool2d", "list.append", "list.append", "list.append", "range", "len", "len"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.spaces.gym_wrapper.GymSpaceWrapper.__init__"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "in_channels", ",", "\n", "channels", ",", "\n", "kernel_sizes", ",", "\n", "strides", ",", "\n", "paddings", "=", "None", ",", "\n", "nonlinearity", "=", "torch", ".", "nn", ".", "ReLU", ",", "\n", "use_maxpool", "=", "False", ",", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "if", "paddings", "is", "None", ":", "\n", "            ", "paddings", "=", "[", "0", "for", "_", "in", "range", "(", "len", "(", "channels", ")", ")", "]", "\n", "", "assert", "len", "(", "channels", ")", "==", "len", "(", "kernel_sizes", ")", "==", "len", "(", "strides", ")", "==", "len", "(", "paddings", ")", "\n", "in_channels", "=", "[", "in_channels", "]", "+", "channels", "[", ":", "-", "1", "]", "\n", "ones", "=", "[", "1", "for", "_", "in", "range", "(", "len", "(", "strides", ")", ")", "]", "\n", "if", "use_maxpool", ":", "\n", "            ", "maxp_strides", "=", "strides", "\n", "strides", "=", "ones", "\n", "", "else", ":", "\n", "            ", "maxp_strides", "=", "ones", "\n", "", "conv_layers", "=", "[", "torch", ".", "nn", ".", "Conv2d", "(", "in_channels", "=", "ic", ",", "out_channels", "=", "oc", ",", "\n", "kernel_size", "=", "k", ",", "stride", "=", "s", ",", "padding", "=", "p", ")", "for", "(", "ic", ",", "oc", ",", "k", ",", "s", ",", "p", ")", "in", "\n", "zip", "(", "in_channels", ",", "channels", ",", "kernel_sizes", ",", "strides", ",", "paddings", ")", "]", "\n", "sequence", "=", "list", "(", ")", "\n", "maxp_layers", "=", "list", "(", ")", "\n", "for", "conv_layer", ",", "maxp_stride", "in", "zip", "(", "conv_layers", ",", "maxp_strides", ")", ":", "\n", "            ", "sequence", ".", "append", "(", "conv_layer", ")", "\n", "sequence", ".", "append", "(", "nonlinearity", "(", ")", ")", "\n", "if", "maxp_stride", ">", "1", ":", "\n", "                ", "maxp_layer", "=", "torch", ".", "nn", ".", "MaxPool2d", "(", "maxp_stride", ")", "\n", "sequence", ".", "append", "(", "maxp_layer", ")", "# No padding.", "\n", "maxp_layers", ".", "append", "(", "maxp_layer", ")", "\n", "", "else", ":", "\n", "                ", "maxp_layers", ".", "append", "(", "None", ")", "\n", "# Register parameters this way, so can still use the same state_dict", "\n", "# format for loading in the RL agent:", "\n", "", "", "self", ".", "conv", "=", "torch", ".", "nn", ".", "Sequential", "(", "*", "sequence", ")", "\n", "# But will actually use these lists for the forward pass", "\n", "# (they shouldn't register as parameters, would be duplicates,", "\n", "# hopefully this still works.)", "\n", "self", ".", "conv_layers", "=", "conv_layers", "# without registering", "\n", "self", ".", "maxp_layers", "=", "maxp_layers", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.ul.stdim_models.Conv2dStdimModel.forward": [[206, 215], ["list", "zip", "torch.relu", "torch.relu", "list.append", "conv", "maxp"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input", ")", ":", "\n", "        ", "conv_outs", "=", "list", "(", ")", "\n", "x", "=", "input", "\n", "for", "conv", ",", "maxp", "in", "zip", "(", "self", ".", "conv_layers", ",", "self", ".", "maxp_layers", ")", ":", "\n", "            ", "x", "=", "F", ".", "relu", "(", "conv", "(", "x", ")", ")", "\n", "conv_outs", ".", "append", "(", "x", ")", "\n", "if", "maxp", "is", "not", "None", ":", "\n", "                ", "x", "=", "maxp", "(", "x", ")", "\n", "", "", "return", "x", ",", "conv_outs", "# Return the post-ReLU conv at every layer.", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.ul.stdim_models.Conv2dStdimModel.conv_out_size": [[216, 230], ["stdim_models.Conv2dStdimModel.conv.children", "rlpyt.models.utils.conv2d_output_shape"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.models.utils.conv2d_output_shape"], ["", "def", "conv_out_size", "(", "self", ",", "h", ",", "w", ",", "c", "=", "None", ")", ":", "\n", "        ", "\"\"\"Helper function ot return the output size for a given input shape,\n        without actually performing a forward pass through the model.\"\"\"", "\n", "for", "child", "in", "self", ".", "conv", ".", "children", "(", ")", ":", "\n", "            ", "try", ":", "\n", "                ", "h", ",", "w", "=", "conv2d_output_shape", "(", "h", ",", "w", ",", "child", ".", "kernel_size", ",", "\n", "child", ".", "stride", ",", "child", ".", "padding", ")", "\n", "", "except", "AttributeError", ":", "\n", "                ", "pass", "# Not a conv or maxpool layer.", "\n", "", "try", ":", "\n", "                ", "c", "=", "child", ".", "out_channels", "\n", "", "except", "AttributeError", ":", "\n", "                ", "pass", "# Not a conv layer.", "\n", "", "", "return", "h", "*", "w", "*", "c", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.ul.stdim_models.Conv2dStdimModel.conv_layer_shapes": [[231, 247], ["list", "stdim_models.Conv2dStdimModel.conv.children", "rlpyt.models.utils.conv2d_output_shape", "list.append"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.models.utils.conv2d_output_shape"], ["", "def", "conv_layer_shapes", "(", "self", ",", "h", ",", "w", ",", "c", "=", "None", ")", ":", "\n", "        ", "\"\"\"Helper function ot return the output size for a given input shape,\n        without actually performing a forward pass through the model.\"\"\"", "\n", "shapes", "=", "list", "(", ")", "\n", "for", "child", "in", "self", ".", "conv", ".", "children", "(", ")", ":", "\n", "            ", "try", ":", "\n", "                ", "h", ",", "w", "=", "conv2d_output_shape", "(", "h", ",", "w", ",", "child", ".", "kernel_size", ",", "\n", "child", ".", "stride", ",", "child", ".", "padding", ")", "\n", "", "except", "AttributeError", ":", "\n", "                ", "pass", "# Not a conv or maxpool layer.", "\n", "", "try", ":", "\n", "                ", "c", "=", "child", ".", "out_channels", "\n", "shapes", ".", "append", "(", "(", "c", ",", "h", ",", "w", ")", ")", "\n", "", "except", "AttributeError", ":", "\n", "                ", "pass", "# Not a conv layer.", "\n", "", "", "return", "shapes", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.ul.stdim_models.Conv2dStdimModel.conv_out_shape": [[248, 251], ["stdim_models.Conv2dStdimModel.conv_layer_shapes"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.ul.stdim_models.Conv2dStdimModel.conv_layer_shapes"], ["", "def", "conv_out_shape", "(", "self", ",", "h", ",", "w", ",", "c", "=", "None", ")", ":", "\n", "        ", "shapes", "=", "self", ".", "conv_layer_shapes", "(", "h", "=", "h", ",", "w", "=", "w", ",", "c", "=", "c", ")", "\n", "return", "shapes", "[", "-", "1", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.ul.stdim_models.Conv2dStdimModel.conv_out_shapes": [[252, 254], ["stdim_models.Conv2dStdimModel.conv_layer_shapes"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.ul.stdim_models.Conv2dStdimModel.conv_layer_shapes"], ["", "def", "conv_out_shapes", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "return", "self", ".", "conv_layer_shapes", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.astooke_rlpyt.ul.stdim_models.weight_init": [[10, 16], ["isinstance", "torch.nn.init.kaiming_normal_", "torch.nn.init.kaiming_normal_", "torch.nn.init.zeros_", "torch.nn.init.zeros_"], "function", ["None"], ["def", "weight_init", "(", "m", ")", ":", "\n", "    ", "\"\"\"Kaiming_normal is standard for relu networks, sometimes.\"\"\"", "\n", "if", "isinstance", "(", "m", ",", "(", "torch", ".", "nn", ".", "Linear", ",", "torch", ".", "nn", ".", "Conv2d", ")", ")", ":", "\n", "        ", "torch", ".", "nn", ".", "init", ".", "kaiming_normal_", "(", "m", ".", "weight", ",", "mode", "=", "\"fan_in\"", ",", "\n", "nonlinearity", "=", "\"relu\"", ")", "\n", "torch", ".", "nn", ".", "init", ".", "zeros_", "(", "m", ".", "bias", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.base.UlAlgorithm.initialize": [[15, 17], ["None"], "methods", ["None"], ["world_size", "=", "1", ",", "rank", "=", "0", ")", ":", "\n", "        "]], "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.base.UlAlgorithm.load_replay": [[18, 20], ["None"], "methods", ["None"], []], "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.base.UlAlgorithm.optimize": [[21, 23], ["None"], "methods", ["None"], []], "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.base.UlAlgorithm.state_dict": [[24, 26], ["None"], "methods", ["None"], []], "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.base.UlAlgorithm.load_state_dict": [[27, 29], ["None"], "methods", ["None"], ["\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.base.UlAlgorithm.eval": [[30, 33], ["None"], "methods", ["None"], ["", "def", "async_initialize", "(", "self", ",", "agent", ",", "sampler_n_itr", ",", "batch_spec", ",", "mid_batch_reset", ",", "\n", "examples", ",", "world_size", "=", "1", ")", ":", "\n", "        "]], "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.base.UlAlgorithm.train": [[34, 37], ["None"], "methods", ["None"], ["\n", "raise", "NotImplementedError", "\n", "\n", "", "def", "optim_initialize", "(", "self", ",", "rank", "=", "0", ")", ":", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.base.UlAlgorithm.validation": [[38, 40], ["None"], "methods", ["None"], ["        ", "\"\"\"Called in async runner which requires two stages of initialization;\n        might also be used in ``initialize()`` to avoid redundant code.\"\"\"", "\n", "raise", "NotImplementedError", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.base.BaseUlAlgorithm.load_replay": [[45, 70], ["isinstance", "base.BaseUlAlgorithm.ReplayCls", "isinstance", "base.BaseUlAlgorithm.replay_buffer.get_examples", "rlpyt.utils.logging.logger.log", "list", "rlpyt.utils.logging.logger.log", "rlpyt.utils.logging.logger.log", "rlpyt.utils.logging.logger.log", "rlpyt.utils.logging.logger.log", "open", "pickle.load", "open", "pickle.load.append", "pickle.load"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.replays.ul_for_rl_replay.UlForRlReplayBuffer.get_examples", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.console.log", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.console.log", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.console.log", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.console.log", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.console.log"], ["\n", "raise", "NotImplementedError", "\n", "\n", "", "def", "optim_state_dict", "(", "self", ")", ":", "\n", "        ", "\"\"\"Return the optimizer state dict (e.g. Adam); overwrite if using\n        multiple optimizers.\"\"\"", "\n", "return", "self", ".", "optimizer", ".", "state_dict", "(", ")", "\n", "\n", "", "def", "load_optim_state_dict", "(", "self", ",", "state_dict", ")", ":", "\n", "        ", "\"\"\"Load an optimizer state dict; should expect the format returned\n        from ``optim_state_dict().``\"\"\"", "\n", "self", ".", "optimizer", ".", "load_state_dict", "(", "state_dict", ")", "\n", "\n", "", "@", "property", "\n", "def", "batch_size", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_batch_size", "# For logging at least.", "\n", "", "", ""]], "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.base.BaseUlAlgorithm.replay_T": [[71, 75], ["None"], "methods", ["None"], []], "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.base.BaseUlAlgorithm.optim_initialize": [[76, 107], ["base.BaseUlAlgorithm.optim_kwargs.pop", "rlpyt.ul.algos.utils.weight_decay.add_weight_decay", "base.BaseUlAlgorithm.OptimCls", "torch.optim.lr_scheduler.CosineAnnealingLR", "rlpyt.ul.algos.utils.warmup_scheduler.GradualWarmupScheduler", "base.BaseUlAlgorithm.optimizer.zero_grad", "base.BaseUlAlgorithm.optimizer.step"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.utils.weight_decay.add_weight_decay", "home.repos.pwc.inspect_result.astooke_rlpyt.safe.safety_gym_env.SafetyGymTrajInfo.step"], []], "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.base.BaseUlAlgorithm.activation_loss": [[108, 117], ["torch.clamp", "torch.clamp.pow().mean", "getattr", "torch.tensor", "conv_output.view", "torch.clamp.pow"], "methods", ["None"], []], "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.pixel_control.PixelControl.__init__": [[26, 58], ["rlpyt.utils.quick_args.save__init__args", "dict", "dict", "dict", "locals"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.utils.quick_args.save__init__args"], ["def", "__init__", "(", "\n", "self", ",", "\n", "batch_T", ",", "\n", "batch_B", ",", "\n", "learning_rate", ",", "\n", "replay_filepath", ",", "\n", "OptimCls", "=", "torch", ".", "optim", ".", "Adam", ",", "\n", "optim_kwargs", "=", "None", ",", "\n", "initial_state_dict", "=", "None", ",", "\n", "clip_grad_norm", "=", "10.", ",", "\n", "EncoderCls", "=", "EncoderModel", ",", "\n", "encoder_kwargs", "=", "None", ",", "\n", "ReplayCls", "=", "UlForRlReplayBuffer", ",", "\n", "onehot_actions", "=", "True", ",", "\n", "activation_loss_coefficient", "=", "0.0", ",", "\n", "learning_rate_anneal", "=", "None", ",", "# cosine", "\n", "learning_rate_warmup", "=", "0", ",", "# number of updates", "\n", "PixCtlModelCls", "=", "PixelControlModel", ",", "\n", "pixel_control_model_kwargs", "=", "None", ",", "\n", "pixel_control_filename", "=", "\"pixel_control_80x80_4x4.pkl\"", ",", "# Looks in replay path.", "\n", "validation_split", "=", "0.0", ",", "\n", "n_validation_batches", "=", "0", ",", "\n", ")", ":", "\n", "        ", "optim_kwargs", "=", "dict", "(", ")", "if", "optim_kwargs", "is", "None", "else", "optim_kwargs", "\n", "encoder_kwargs", "=", "dict", "(", ")", "if", "encoder_kwargs", "is", "None", "else", "encoder_kwargs", "\n", "pixel_control_model_kwargs", "=", "(", "dict", "(", ")", "if", "\n", "pixel_control_model_kwargs", "is", "None", "\n", "else", "pixel_control_model_kwargs", ")", "\n", "save__init__args", "(", "locals", "(", ")", ")", "\n", "assert", "learning_rate_anneal", "in", "[", "None", ",", "\"cosine\"", "]", "\n", "self", ".", "_replay_T", "=", "batch_T", "\n", "self", ".", "batch_size", "=", "batch_T", "*", "batch_B", "# for logging", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.pixel_control.PixelControl.initialize": [[59, 91], ["pixel_control.PixelControl.load_replay", "pixel_control.PixelControl.EncoderCls", "pixel_control.PixelControl.encoder.to", "pixel_control.PixelControl.pixel_control_model_kwargs.pop", "pixel_control.PixelControl.append", "pixel_control.PixelControl.PixCtlModelCls", "pixel_control.PixelControl.pixel_control_model.to", "pixel_control.PixelControl.optim_initialize", "torch.device", "torch.device", "pixel_control.PixelControl.replay_buffer.samples.action.max", "pixel_control.PixelControl.load_state_dict"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.pixel_control.PixelControl.load_replay", "home.repos.pwc.inspect_result.astooke_rlpyt.rl_with_ul.sac_with_ul.SacWithUl.optim_initialize", "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.augmented_temporal_similarity.AugmentedTemporalSimilarity.load_state_dict"], ["", "def", "initialize", "(", "self", ",", "n_updates", ",", "cuda_idx", "=", "None", ")", ":", "\n", "        ", "self", ".", "device", "=", "torch", ".", "device", "(", "\"cpu\"", ")", "if", "cuda_idx", "is", "None", "else", "torch", ".", "device", "(", "\n", "\"cuda\"", ",", "index", "=", "cuda_idx", ")", "\n", "\n", "examples", "=", "self", ".", "load_replay", "(", ")", "\n", "self", ".", "encoder", "=", "self", ".", "EncoderCls", "(", "\n", "image_shape", "=", "examples", ".", "observation", ".", "shape", ",", "\n", "latent_size", "=", "10", ",", "# UNUSED", "\n", "**", "self", ".", "encoder_kwargs", "\n", ")", "\n", "self", ".", "encoder", ".", "to", "(", "self", ".", "device", ")", "\n", "\n", "if", "self", ".", "onehot_actions", ":", "\n", "            ", "max_act", "=", "self", ".", "replay_buffer", ".", "samples", ".", "action", ".", "max", "(", ")", "\n", "self", ".", "_act_dim", "=", "max_act", "+", "1", "# To use for 1-hot encoding", "\n", "", "else", ":", "\n", "# Would need to make pixel control with action as INPUT to Q-network.", "\n", "            ", "raise", "NotImplementedError", "\n", "\n", "", "channels", "=", "self", ".", "pixel_control_model_kwargs", ".", "pop", "(", "\"channels\"", ",", "[", "]", ")", "\n", "channels", ".", "append", "(", "self", ".", "_act_dim", ")", "\n", "self", ".", "pixel_control_model", "=", "self", ".", "PixCtlModelCls", "(", "\n", "input_shape", "=", "self", ".", "encoder", ".", "conv_out_shape", ",", "\n", "channels", "=", "channels", ",", "\n", "**", "self", ".", "pixel_control_model_kwargs", "\n", ")", "\n", "self", ".", "pixel_control_model", ".", "to", "(", "self", ".", "device", ")", "\n", "\n", "self", ".", "optim_initialize", "(", "n_updates", ")", "\n", "\n", "if", "self", ".", "initial_state_dict", "is", "not", "None", ":", "\n", "            ", "self", ".", "load_state_dict", "(", "self", ".", "initial_state_dict", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.pixel_control.PixelControl.load_replay": [[92, 105], ["isinstance", "super().load_replay", "list", "open", "pickle.load", "open", "pickle.load.append", "pickle.load", "pixel_control.PixelControl.replay_filepath.rsplit", "filepath.rsplit"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.pixel_control.PixelControl.load_replay"], ["", "", "def", "load_replay", "(", "self", ")", ":", "\n", "        ", "if", "isinstance", "(", "self", ".", "replay_filepath", ",", "(", "list", ",", "tuple", ")", ")", ":", "\n", "            ", "pixel_control_buffer", "=", "list", "(", ")", "\n", "for", "filepath", "in", "self", ".", "replay_filepath", ":", "\n", "                ", "pc_file", "=", "filepath", ".", "rsplit", "(", "\"/\"", ",", "1", ")", "[", "0", "]", "+", "\"/\"", "+", "self", ".", "pixel_control_filename", "\n", "with", "open", "(", "pc_file", ",", "\"rb\"", ")", "as", "fh", ":", "\n", "                    ", "pixel_control_buffer", ".", "append", "(", "pickle", ".", "load", "(", "fh", ")", ")", "\n", "", "", "", "else", ":", "\n", "            ", "pc_file", "=", "self", ".", "replay_filepath", ".", "rsplit", "(", "\"/\"", ",", "1", ")", "[", "0", "]", "+", "\"/\"", "+", "self", ".", "pixel_control_filename", "\n", "with", "open", "(", "pc_file", ",", "\"rb\"", ")", "as", "fh", ":", "\n", "                ", "pixel_control_buffer", "=", "pickle", ".", "load", "(", "fh", ")", "\n", "", "", "examples", "=", "super", "(", ")", ".", "load_replay", "(", "pixel_control_buffer", "=", "pixel_control_buffer", ")", "\n", "return", "examples", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.pixel_control.PixelControl.optimize": [[106, 128], ["OptInfo", "pixel_control.PixelControl.replay_buffer.sample_batch", "pixel_control.PixelControl.optimizer.zero_grad", "pixel_control.PixelControl.pixel_control_loss", "pixel_control.PixelControl.activation_loss", "loss.backward", "pixel_control.PixelControl.optimizer.step", "OptInfo.pcLoss.append", "OptInfo.activationLoss.append", "OptInfo.gradNorm.append", "OptInfo.convActivation.append", "pixel_control.PixelControl.lr_scheduler.step", "torch.nn.utils.clip_grad_norm_", "pc_loss.item", "pixel_control.PixelControl.item", "torch.nn.utils.clip_grad_norm_.item", "conv_output[].detach().cpu().view().numpy", "pixel_control.PixelControl.parameters", "conv_output[].detach().cpu().view", "range", "len", "conv_output[].detach().cpu", "conv_output[].detach"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.sequence.uniform.UniformSequenceReplay.sample_batch", "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.pixel_control.PixelControl.pixel_control_loss", "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.base.BaseUlAlgorithm.activation_loss", "home.repos.pwc.inspect_result.astooke_rlpyt.models.utils.ScaleGrad.backward", "home.repos.pwc.inspect_result.astooke_rlpyt.safe.safety_gym_env.SafetyGymTrajInfo.step", "home.repos.pwc.inspect_result.astooke_rlpyt.safe.safety_gym_env.SafetyGymTrajInfo.step", "home.repos.pwc.inspect_result.astooke_rlpyt.rl.atari_rl_models.AtariDqnModel.parameters"], ["", "def", "optimize", "(", "self", ",", "itr", ")", ":", "\n", "        ", "opt_info", "=", "OptInfo", "(", "*", "(", "[", "]", "for", "_", "in", "range", "(", "len", "(", "OptInfo", ".", "_fields", ")", ")", ")", ")", "\n", "samples", "=", "self", ".", "replay_buffer", ".", "sample_batch", "(", "self", ".", "batch_B", ")", "\n", "if", "self", ".", "lr_scheduler", "is", "not", "None", ":", "\n", "            ", "self", ".", "lr_scheduler", ".", "step", "(", "itr", ")", "# Do every itr instead of every epoch", "\n", "", "self", ".", "optimizer", ".", "zero_grad", "(", ")", "\n", "pc_loss", ",", "conv_output", "=", "self", ".", "pixel_control_loss", "(", "samples", ")", "\n", "act_loss", "=", "self", ".", "activation_loss", "(", "conv_output", ")", "\n", "loss", "=", "pc_loss", "+", "act_loss", "# was getting a cuda vs cpu backprop error?", "\n", "loss", ".", "backward", "(", ")", "\n", "if", "self", ".", "clip_grad_norm", "is", "None", ":", "\n", "            ", "grad_norm", "=", "0.", "\n", "", "else", ":", "\n", "            ", "grad_norm", "=", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "\n", "self", ".", "parameters", "(", ")", ",", "self", ".", "clip_grad_norm", ")", "\n", "", "self", ".", "optimizer", ".", "step", "(", ")", "\n", "opt_info", ".", "pcLoss", ".", "append", "(", "pc_loss", ".", "item", "(", ")", ")", "\n", "opt_info", ".", "activationLoss", ".", "append", "(", "act_loss", ".", "item", "(", ")", ")", "\n", "opt_info", ".", "gradNorm", ".", "append", "(", "grad_norm", ".", "item", "(", ")", ")", "\n", "opt_info", ".", "convActivation", ".", "append", "(", "\n", "conv_output", "[", "0", "]", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "view", "(", "-", "1", ")", ".", "numpy", "(", ")", ")", "# Keep 1 full one.", "\n", "return", "opt_info", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.pixel_control.PixelControl.pixel_control_loss": [[129, 147], ["samples.observation.view", "samples.pixctl_return.view", "samples.action.view", "rlpyt.utils.buffer.buffer_to", "pixel_control.PixelControl.encoder", "pixel_control.PixelControl.pixel_control_model", "pc_losses.sum.sum.sum", "pc_losses.sum.sum.mean", "torch.arange"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.utils.buffer.buffer_to"], ["", "def", "pixel_control_loss", "(", "self", ",", "samples", ")", ":", "\n", "        ", "t", ",", "b", ",", "c", ",", "h", ",", "w", "=", "samples", ".", "observation", ".", "shape", "\n", "observation", "=", "samples", ".", "observation", ".", "view", "(", "t", "*", "b", ",", "c", ",", "h", ",", "w", ")", "\n", "t", ",", "b", ",", "hp", ",", "wp", "=", "samples", ".", "pixctl_return", ".", "shape", "\n", "pc_return", "=", "samples", ".", "pixctl_return", ".", "view", "(", "t", "*", "b", ",", "hp", ",", "wp", ")", "\n", "action", "=", "samples", ".", "action", ".", "view", "(", "t", "*", "b", ")", "\n", "\n", "observation", ",", "pc_return", ",", "action", "=", "buffer_to", "(", "\n", "(", "observation", ",", "pc_return", ",", "action", ")", ",", "device", "=", "self", ".", "device", ")", "\n", "\n", "_", ",", "conv_output", "=", "self", ".", "encoder", "(", "observation", ")", "\n", "\n", "q_pc", "=", "self", ".", "pixel_control_model", "(", "conv_output", ")", "# [B,A,H',W']", "\n", "q_pc_at_a", "=", "q_pc", "[", "torch", ".", "arange", "(", "t", "*", "b", ")", ",", "action", "]", "# [B,H',W']", "\n", "pc_losses", "=", "0.5", "*", "(", "q_pc_at_a", "-", "pc_return", ")", "**", "2", "# [B,H',W']", "\n", "pc_losses", "=", "pc_losses", ".", "sum", "(", "dim", "=", "(", "1", ",", "2", ")", ")", "# [B] SUM over cells", "\n", "pc_loss", "=", "pc_losses", ".", "mean", "(", ")", "# MEAN over batch", "\n", "return", "pc_loss", ",", "conv_output", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.pixel_control.PixelControl.validation": [[148, 163], ["rlpyt.utils.logging.logger.log", "ValInfo", "pixel_control.PixelControl.optimizer.zero_grad", "range", "pixel_control.PixelControl.optimizer.zero_grad", "rlpyt.utils.logging.logger.log", "pixel_control.PixelControl.replay_buffer.sample_batch", "ValInfo.pcLoss.append", "ValInfo.convActivation.append", "torch.no_grad", "pixel_control.PixelControl.pixel_control_loss", "pc_loss.item", "conv_output[].detach().cpu().view().numpy", "range", "conv_output[].detach().cpu().view", "len", "conv_output[].detach().cpu", "conv_output[].detach"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.logging.console.log", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.console.log", "home.repos.pwc.inspect_result.astooke_rlpyt.sequence.uniform.UniformSequenceReplay.sample_batch", "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.pixel_control.PixelControl.pixel_control_loss"], ["", "def", "validation", "(", "self", ",", "itr", ")", ":", "\n", "        ", "logger", ".", "log", "(", "\"Computing validation loss...\"", ")", "\n", "val_info", "=", "ValInfo", "(", "*", "(", "[", "]", "for", "_", "in", "range", "(", "len", "(", "ValInfo", ".", "_fields", ")", ")", ")", ")", "\n", "self", ".", "optimizer", ".", "zero_grad", "(", ")", "\n", "for", "_", "in", "range", "(", "self", ".", "n_validation_batches", ")", ":", "\n", "            ", "samples", "=", "self", ".", "replay_buffer", ".", "sample_batch", "(", "self", ".", "batch_B", ",", "\n", "validation", "=", "True", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "pc_loss", ",", "conv_output", "=", "self", ".", "pixel_control_loss", "(", "samples", ")", "\n", "", "val_info", ".", "pcLoss", ".", "append", "(", "pc_loss", ".", "item", "(", ")", ")", "\n", "val_info", ".", "convActivation", ".", "append", "(", "\n", "conv_output", "[", "0", "]", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "view", "(", "-", "1", ")", ".", "numpy", "(", ")", ")", "# Keep 1 full one.", "\n", "", "self", ".", "optimizer", ".", "zero_grad", "(", ")", "\n", "logger", ".", "log", "(", "\"...validation loss completed.\"", ")", "\n", "return", "val_info", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.pixel_control.PixelControl.state_dict": [[164, 169], ["dict", "pixel_control.PixelControl.encoder.state_dict", "pixel_control.PixelControl.pixel_control_model.state_dict", "pixel_control.PixelControl.optimizer.state_dict"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.replay_saver.DummyOptimizer.state_dict", "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.replay_saver.DummyOptimizer.state_dict", "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.replay_saver.DummyOptimizer.state_dict"], ["", "def", "state_dict", "(", "self", ")", ":", "\n", "        ", "return", "dict", "(", "\n", "encoder", "=", "self", ".", "encoder", ".", "state_dict", "(", ")", ",", "\n", "pixel_control", "=", "self", ".", "pixel_control_model", ".", "state_dict", "(", ")", ",", "\n", "optimizer", "=", "self", ".", "optimizer", ".", "state_dict", "(", ")", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.pixel_control.PixelControl.load_state_dict": [[171, 175], ["pixel_control.PixelControl.encoder.load_state_dict", "pixel_control.PixelControl.pixel_control_model.load_state_dict", "pixel_control.PixelControl.optimizer.load_state_dict"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.augmented_temporal_similarity.AugmentedTemporalSimilarity.load_state_dict", "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.augmented_temporal_similarity.AugmentedTemporalSimilarity.load_state_dict", "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.augmented_temporal_similarity.AugmentedTemporalSimilarity.load_state_dict"], ["", "def", "load_state_dict", "(", "self", ",", "state_dict", ")", ":", "\n", "        ", "self", ".", "encoder", ".", "load_state_dict", "(", "state_dict", "[", "\"encoder\"", "]", ")", "\n", "self", ".", "pixel_control_model", ".", "load_state_dict", "(", "state_dict", "[", "\"pixel_control\"", "]", ")", "\n", "self", ".", "optimizer", ".", "load_state_dict", "(", "state_dict", "[", "\"optimizer\"", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.pixel_control.PixelControl.parameters": [[176, 179], ["pixel_control.PixelControl.encoder.parameters", "pixel_control.PixelControl.pixel_control_model.parameters"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.rl.atari_rl_models.AtariDqnModel.parameters", "home.repos.pwc.inspect_result.astooke_rlpyt.rl.atari_rl_models.AtariDqnModel.parameters"], ["", "def", "parameters", "(", "self", ")", ":", "\n", "        ", "yield", "from", "self", ".", "encoder", ".", "parameters", "(", ")", "\n", "yield", "from", "self", ".", "pixel_control_model", ".", "parameters", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.pixel_control.PixelControl.named_parameters": [[180, 184], ["pixel_control.PixelControl.encoder.named_parameters", "pixel_control.PixelControl.pixel_control_model.named_parameters"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.rl.atari_rl_models.AtariDqnModel.named_parameters", "home.repos.pwc.inspect_result.astooke_rlpyt.rl.atari_rl_models.AtariDqnModel.named_parameters"], ["", "def", "named_parameters", "(", "self", ")", ":", "\n", "        ", "\"\"\"To allow filtering by name in weight decay.\"\"\"", "\n", "yield", "from", "self", ".", "encoder", ".", "named_parameters", "(", ")", "\n", "yield", "from", "self", ".", "pixel_control_model", ".", "named_parameters", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.pixel_control.PixelControl.eval": [[185, 188], ["pixel_control.PixelControl.encoder.eval", "pixel_control.PixelControl.pixel_control_model.eval"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.augmented_temporal_similarity.AugmentedTemporalSimilarity.eval", "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.augmented_temporal_similarity.AugmentedTemporalSimilarity.eval"], ["", "def", "eval", "(", "self", ")", ":", "\n", "        ", "self", ".", "encoder", ".", "eval", "(", ")", "# in case of batch norm", "\n", "self", ".", "pixel_control_model", ".", "eval", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.pixel_control.PixelControl.train": [[189, 192], ["pixel_control.PixelControl.encoder.train", "pixel_control.PixelControl.pixel_control_model.train"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.runners.minibatch_rl.MinibatchRlEval.train", "home.repos.pwc.inspect_result.astooke_rlpyt.runners.minibatch_rl.MinibatchRlEval.train"], ["", "def", "train", "(", "self", ")", ":", "\n", "        ", "self", ".", "encoder", ".", "train", "(", ")", "\n", "self", ".", "pixel_control_model", ".", "train", "(", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.cpc.CPC.__init__": [[31, 61], ["rlpyt.utils.quick_args.save__init__args", "torch.nn.CrossEntropyLoss", "dict", "dict", "locals"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.utils.quick_args.save__init__args"], ["def", "__init__", "(", "\n", "self", ",", "\n", "batch_B", ",", "\n", "batch_T", ",", "\n", "learning_rate", ",", "\n", "replay_filepath", ",", "\n", "warmup_T", "=", "0", ",", "\n", "rnn_size", "=", "256", ",", "\n", "latent_size", "=", "256", ",", "\n", "OptimCls", "=", "torch", ".", "optim", ".", "Adam", ",", "\n", "optim_kwargs", "=", "None", ",", "\n", "initial_state_dict", "=", "None", ",", "\n", "clip_grad_norm", "=", "1000.", ",", "\n", "validation_split", "=", "0.0", ",", "\n", "n_validation_batches", "=", "0", ",", "\n", "EncoderCls", "=", "EncoderModel", ",", "\n", "encoder_kwargs", "=", "None", ",", "\n", "ReplayCls", "=", "UlForRlReplayBuffer", ",", "\n", "onehot_actions", "=", "True", ",", "\n", "activation_loss_coefficient", "=", "0.", ",", "# 0 for OFF", "\n", "learning_rate_anneal", "=", "None", ",", "# cosine", "\n", "learning_rate_warmup", "=", "0", ",", "# number of updates", "\n", ")", ":", "\n", "        ", "optim_kwargs", "=", "dict", "(", ")", "if", "optim_kwargs", "is", "None", "else", "optim_kwargs", "\n", "encoder_kwargs", "=", "dict", "(", ")", "if", "encoder_kwargs", "is", "None", "else", "encoder_kwargs", "\n", "save__init__args", "(", "locals", "(", ")", ")", "\n", "self", ".", "c_e_loss", "=", "torch", ".", "nn", ".", "CrossEntropyLoss", "(", "ignore_index", "=", "IGNORE_INDEX", ")", "\n", "assert", "learning_rate_anneal", "in", "[", "None", ",", "\"cosine\"", "]", "\n", "self", ".", "batch_size", "=", "batch_B", "*", "batch_T", "# for logging only", "\n", "self", ".", "_replay_T", "=", "batch_T", "+", "warmup_T", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.cpc.CPC.initialize": [[62, 98], ["cpc.CPC.load_replay", "cpc.CPC.EncoderCls", "cpc.CPC.encoder.to", "torch.nn.LSTM", "cpc.CPC.prediction_rnn.to", "torch.nn.ModuleList", "cpc.CPC.transforms.to", "cpc.CPC.optim_initialize", "torch.device", "torch.device", "cpc.CPC.replay_buffer.samples.action.max", "cpc.CPC.load_state_dict", "len", "int", "torch.nn.Linear", "range"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.pixel_control.PixelControl.load_replay", "home.repos.pwc.inspect_result.astooke_rlpyt.rl_with_ul.sac_with_ul.SacWithUl.optim_initialize", "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.augmented_temporal_similarity.AugmentedTemporalSimilarity.load_state_dict"], ["", "def", "initialize", "(", "self", ",", "n_updates", ",", "cuda_idx", "=", "None", ")", ":", "\n", "        ", "self", ".", "device", "=", "torch", ".", "device", "(", "\"cpu\"", ")", "if", "cuda_idx", "is", "None", "else", "torch", ".", "device", "(", "\n", "\"cuda\"", ",", "index", "=", "cuda_idx", ")", "\n", "\n", "examples", "=", "self", ".", "load_replay", "(", ")", "\n", "self", ".", "encoder", "=", "self", ".", "EncoderCls", "(", "\n", "image_shape", "=", "examples", ".", "observation", ".", "shape", ",", "\n", "latent_size", "=", "self", ".", "latent_size", ",", "\n", "**", "self", ".", "encoder_kwargs", "\n", ")", "\n", "self", ".", "encoder", ".", "to", "(", "self", ".", "device", ")", "\n", "\n", "if", "self", ".", "onehot_actions", ":", "\n", "            ", "max_act", "=", "self", ".", "replay_buffer", ".", "samples", ".", "action", ".", "max", "(", ")", "\n", "self", ".", "_act_dim", "=", "max_act", "+", "1", "# To use for 1-hot encoding", "\n", "ar_input_size", "=", "self", ".", "_act_dim", "+", "1", "# for 1 step, + 1 reward", "\n", "", "else", ":", "\n", "            ", "assert", "len", "(", "self", ".", "replay_buffer", ".", "samples", ".", "action", ".", "shape", ")", "==", "3", "# [T,B,A]", "\n", "ar_input_size", "=", "self", ".", "replay", ".", "samples", ".", "action", ".", "shape", "[", "-", "1", "]", "+", "1", "\n", "\n", "", "self", ".", "prediction_rnn", "=", "torch", ".", "nn", ".", "LSTM", "(", "\n", "input_size", "=", "int", "(", "self", ".", "latent_size", "+", "ar_input_size", ")", ",", "\n", "hidden_size", "=", "self", ".", "rnn_size", ",", "\n", ")", "\n", "self", ".", "prediction_rnn", ".", "to", "(", "self", ".", "device", ")", "\n", "\n", "transforms", "=", "[", "None", "]", "+", "[", "torch", ".", "nn", ".", "Linear", "(", "\n", "in_features", "=", "self", ".", "rnn_size", ",", "out_features", "=", "self", ".", "latent_size", ")", "\n", "for", "_", "in", "range", "(", "self", ".", "batch_T", "-", "1", ")", "]", "# no W for delta_t=0", "\n", "self", ".", "transforms", "=", "torch", ".", "nn", ".", "ModuleList", "(", "transforms", ")", "\n", "self", ".", "transforms", ".", "to", "(", "self", ".", "device", ")", "\n", "\n", "self", ".", "optim_initialize", "(", "n_updates", ")", "\n", "\n", "if", "self", ".", "initial_state_dict", "is", "not", "None", ":", "\n", "            ", "self", ".", "load_state_dict", "(", "self", ".", "initial_state_dict", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.cpc.CPC.optimize": [[99, 126], ["OptInfo", "cpc.CPC.replay_buffer.sample_batch", "cpc.CPC.optimizer.zero_grad", "cpc.CPC.cpc_loss", "cpc.CPC.activation_loss", "loss.backward", "cpc.CPC.optimizer.step", "OptInfo.cpcLoss.append", "OptInfo.cpcAccuracy1.append", "OptInfo.cpcAccuracy2.append", "OptInfo.cpcAccuracyTm1.append", "OptInfo.cpcAccuracyTm2.append", "OptInfo.activationLoss.append", "OptInfo.gradNorm.append", "OptInfo.convActivation.append", "cpc.CPC.lr_scheduler.step", "torch.nn.utils.clip_grad_norm_", "cpc_loss.item", "cpc_accuracies[].item", "cpc_accuracies[].item", "cpc_accuracies[].item", "cpc_accuracies[].item", "cpc.CPC.item", "torch.nn.utils.clip_grad_norm_.item", "conv_output[].detach().cpu().view().numpy", "cpc.CPC.parameters", "conv_output[].detach().cpu().view", "range", "len", "conv_output[].detach().cpu", "conv_output[].detach"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.sequence.uniform.UniformSequenceReplay.sample_batch", "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.cpc.CPC.cpc_loss", "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.base.BaseUlAlgorithm.activation_loss", "home.repos.pwc.inspect_result.astooke_rlpyt.models.utils.ScaleGrad.backward", "home.repos.pwc.inspect_result.astooke_rlpyt.safe.safety_gym_env.SafetyGymTrajInfo.step", "home.repos.pwc.inspect_result.astooke_rlpyt.safe.safety_gym_env.SafetyGymTrajInfo.step", "home.repos.pwc.inspect_result.astooke_rlpyt.rl.atari_rl_models.AtariDqnModel.parameters"], ["", "", "def", "optimize", "(", "self", ",", "itr", ")", ":", "\n", "        ", "opt_info", "=", "OptInfo", "(", "*", "(", "[", "]", "for", "_", "in", "range", "(", "len", "(", "OptInfo", ".", "_fields", ")", ")", ")", ")", "\n", "samples", "=", "self", ".", "replay_buffer", ".", "sample_batch", "(", "self", ".", "batch_B", ")", "\n", "if", "self", ".", "lr_scheduler", "is", "not", "None", ":", "\n", "            ", "self", ".", "lr_scheduler", ".", "step", "(", "itr", ")", "# Do every itr instead of every epoch", "\n", "", "self", ".", "optimizer", ".", "zero_grad", "(", ")", "\n", "cpc_loss", ",", "cpc_accuracies", ",", "conv_output", "=", "self", ".", "cpc_loss", "(", "samples", ")", "\n", "act_loss", "=", "self", ".", "activation_loss", "(", "conv_output", ")", "\n", "loss", "=", "cpc_loss", "+", "act_loss", "\n", "\n", "loss", ".", "backward", "(", ")", "\n", "if", "self", ".", "clip_grad_norm", "is", "None", ":", "\n", "            ", "grad_norm", "=", "0.", "\n", "", "else", ":", "\n", "            ", "grad_norm", "=", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "\n", "self", ".", "parameters", "(", ")", ",", "self", ".", "clip_grad_norm", ")", "\n", "", "self", ".", "optimizer", ".", "step", "(", ")", "\n", "opt_info", ".", "cpcLoss", ".", "append", "(", "cpc_loss", ".", "item", "(", ")", ")", "\n", "opt_info", ".", "cpcAccuracy1", ".", "append", "(", "cpc_accuracies", "[", "0", "]", ".", "item", "(", ")", ")", "\n", "opt_info", ".", "cpcAccuracy2", ".", "append", "(", "cpc_accuracies", "[", "1", "]", ".", "item", "(", ")", ")", "\n", "opt_info", ".", "cpcAccuracyTm1", ".", "append", "(", "cpc_accuracies", "[", "2", "]", ".", "item", "(", ")", ")", "\n", "opt_info", ".", "cpcAccuracyTm2", ".", "append", "(", "cpc_accuracies", "[", "3", "]", ".", "item", "(", ")", ")", "\n", "opt_info", ".", "activationLoss", ".", "append", "(", "act_loss", ".", "item", "(", ")", ")", "\n", "opt_info", ".", "gradNorm", ".", "append", "(", "grad_norm", ".", "item", "(", ")", ")", "\n", "opt_info", ".", "convActivation", ".", "append", "(", "\n", "conv_output", "[", "0", ",", "0", "]", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "view", "(", "-", "1", ")", ".", "numpy", "(", ")", ")", "# Keep 1 full one.", "\n", "return", "opt_info", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.cpc.CPC.cpc_loss": [[127, 223], ["rlpyt.utils.buffer.buffer_to", "cpc.CPC.encoder", "torch.cat", "cpc.CPC.prediction_rnn", "rlpyt.algos.utils.valid_from_done().type", "z_latent.view().transpose", "torch.arange().view", "list", "list", "range", "torch.cumsum", "torch.cat", "torch.cat", "torch.matmul", "cpc.CPC.c_e_loss", "torch.matmul.detach", "rlpyt.utils.tensor.valid_mean", "rlpyt.utils.tensor.valid_mean", "rlpyt.utils.tensor.valid_mean", "rlpyt.utils.tensor.valid_mean", "rlpyt.utils.tensor.to_onehot", "list.append", "list.append", "torch.tensor", "torch.argmax", "correct1.float", "torch.argmax", "correct2.float", "torch.argmax", "correctT1.float", "torch.argmax", "correctT2.float", "prev_reward.unsqueeze", "rlpyt.algos.utils.valid_from_done", "z_latent.view", "torch.arange", "base_labels[].view", "len", "torch.max"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.utils.buffer.buffer_to", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.tensor.valid_mean", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.tensor.valid_mean", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.tensor.valid_mean", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.tensor.valid_mean", "home.repos.pwc.inspect_result.astooke_rlpyt.distributions.discrete.DiscreteMixin.to_onehot", "home.repos.pwc.inspect_result.astooke_rlpyt.algos.utils.valid_from_done"], ["", "def", "cpc_loss", "(", "self", ",", "samples", ")", ":", "\n", "##################################", "\n", "# Compute all the network outputs:", "\n", "\n", "        ", "observation", "=", "samples", ".", "observation", "\n", "\n", "prev_action", "=", "samples", ".", "prev_action", "\n", "if", "self", ".", "onehot_actions", ":", "\n", "            ", "prev_action", "=", "to_onehot", "(", "prev_action", ",", "\n", "self", ".", "_act_dim", ",", "dtype", "=", "torch", ".", "float", ")", "\n", "", "prev_reward", "=", "samples", ".", "prev_reward", "\n", "observation", ",", "prev_action", ",", "prev_reward", "=", "buffer_to", "(", "\n", "(", "observation", ",", "prev_action", ",", "prev_reward", ")", ",", "\n", "device", "=", "self", ".", "device", ")", "\n", "\n", "z_latent", ",", "conv_output", "=", "self", ".", "encoder", "(", "observation", ")", "# [T,B,..]", "\n", "rnn_input", "=", "torch", ".", "cat", "(", "\n", "[", "z_latent", ",", "prev_action", ",", "prev_reward", ".", "unsqueeze", "(", "-", "1", ")", "]", ",", "# [T,B,..]", "\n", "dim", "=", "-", "1", ")", "\n", "context", ",", "_", "=", "self", ".", "prediction_rnn", "(", "rnn_input", ")", "\n", "\n", "valid", "=", "valid_from_done", "(", "samples", ".", "done", ")", ".", "type", "(", "torch", ".", "bool", ")", "\n", "\n", "# Extract only the ones to train (all were needed to compute).", "\n", "z_latent", "=", "z_latent", "[", "self", ".", "warmup_T", ":", "]", "\n", "conv_output", "=", "conv_output", "[", "self", ".", "warmup_T", ":", "]", "\n", "context", "=", "context", "[", "self", ".", "warmup_T", ":", "]", "\n", "valid", "=", "valid", "[", "self", ".", "warmup_T", ":", "]", "\n", "\n", "###############################", "\n", "# Contrast the network outputs:", "\n", "\n", "# Should have T,B,C=context.shape, T,B=valid.shape, T,B,Z=z_latent.shape", "\n", "T", ",", "B", ",", "Z", "=", "z_latent", ".", "shape", "\n", "target_trans", "=", "z_latent", ".", "view", "(", "-", "1", ",", "Z", ")", ".", "transpose", "(", "1", ",", "0", ")", "# [T,B,H]->[T*B,H]->[H,T*B]", "\n", "\n", "# Draw from base_labels according to the location of the corresponding", "\n", "# positive latent for contrast, using [T,B]; will give the location", "\n", "# within T*B.", "\n", "base_labels", "=", "torch", ".", "arange", "(", "T", "*", "B", ",", "dtype", "=", "torch", ".", "long", ",", "\n", "device", "=", "self", ".", "device", ")", ".", "view", "(", "T", ",", "B", ")", "\n", "base_labels", "[", "~", "valid", "]", "=", "IGNORE_INDEX", "# By location of z_latent.", "\n", "\n", "# All predictions and labels into one tensor for efficient contrasting.", "\n", "prediction_list", "=", "list", "(", ")", "\n", "label_list", "=", "list", "(", ")", "\n", "for", "delta_t", "in", "range", "(", "1", ",", "T", ")", ":", "\n", "# Predictions based on context starting from t=0 up to the point where", "\n", "# there isn't a future latent within the timesteps of the minibatch.", "\n", "# [T-dt,B,C] -> [T-dt,B,H] -> [(T-dt)*B,H]", "\n", "            ", "prediction_list", ".", "append", "(", "self", ".", "transforms", "[", "delta_t", "]", "(", "context", "[", ":", "-", "delta_t", "]", ")", ".", "view", "(", "-", "1", ",", "Z", ")", ")", "\n", "# The correct latent is delta_t time steps ahead:", "\n", "# [T-dt,B] -> [(T-dt)*B]", "\n", "label_list", ".", "append", "(", "base_labels", "[", "delta_t", ":", "]", ".", "view", "(", "-", "1", ")", ")", "\n", "\n", "# Before cat, to isolate delta_t for diagnostic accuracy check later:", "\n", "", "dt_lengths", "=", "[", "0", "]", "+", "[", "len", "(", "label", ")", "for", "label", "in", "label_list", "]", "\n", "dtb", "=", "torch", ".", "cumsum", "(", "torch", ".", "tensor", "(", "dt_lengths", ")", ",", "dim", "=", "0", ")", "# delta_t_boundaries", "\n", "\n", "# Total number of predictions: P = T*(T-1)/2*B", "\n", "# from: \\sum_{dt=1}^T ((T-dt) * B)", "\n", "predictions", "=", "torch", ".", "cat", "(", "prediction_list", ")", "# [P,H]", "\n", "labels", "=", "torch", ".", "cat", "(", "label_list", ")", "# [P]", "\n", "# contrast against ALL latents, not just the \"future\" ones:", "\n", "logits", "=", "torch", ".", "matmul", "(", "predictions", ",", "target_trans", ")", "# [P,H]*[H,T*B] -> [P,T*B]", "\n", "logits", "=", "logits", "-", "torch", ".", "max", "(", "logits", ",", "dim", "=", "1", ",", "keepdim", "=", "True", ")", "[", "0", "]", "# [P,T*B] normalize", "\n", "cpc_loss", "=", "self", ".", "c_e_loss", "(", "logits", ",", "labels", ")", "# every logit weighted equally", "\n", "\n", "##################################################", "\n", "# Compute some downsampled accuracies for diagnostics:", "\n", "\n", "logits_d", "=", "logits", ".", "detach", "(", ")", "\n", "# begin, end, step (downsample):", "\n", "b", ",", "e", ",", "s", "=", "dtb", "[", "0", "]", ",", "dtb", "[", "1", "]", ",", "4", "# delta_t = 1", "\n", "logits1", ",", "labels1", "=", "logits_d", "[", "b", ":", "e", ":", "s", "]", ",", "labels", "[", "b", ":", "e", ":", "s", "]", "\n", "correct1", "=", "torch", ".", "argmax", "(", "logits1", ",", "dim", "=", "1", ")", "==", "labels1", "\n", "accuracy1", "=", "valid_mean", "(", "correct1", ".", "float", "(", ")", ",", "valid", "=", "labels1", ">=", "0", ")", "# IGNORE=-100", "\n", "\n", "b", ",", "e", ",", "s", "=", "dtb", "[", "1", "]", ",", "dtb", "[", "2", "]", ",", "4", "# delta_t = 2", "\n", "logits2", ",", "labels2", "=", "logits_d", "[", "b", ":", "e", ":", "s", "]", ",", "labels", "[", "b", ":", "e", ":", "s", "]", "\n", "correct2", "=", "torch", ".", "argmax", "(", "logits2", ",", "dim", "=", "1", ")", "==", "labels2", "\n", "accuracy2", "=", "valid_mean", "(", "correct2", ".", "float", "(", ")", ",", "valid", "=", "labels2", ">=", "0", ")", "\n", "\n", "b", ",", "e", ",", "s", "=", "dtb", "[", "-", "2", "]", ",", "dtb", "[", "-", "1", "]", ",", "1", "# delta_t = T - 1", "\n", "logitsT1", ",", "labelsT1", "=", "logits_d", "[", "b", ":", "e", ":", "s", "]", ",", "labels", "[", "b", ":", "e", ":", "s", "]", "\n", "correctT1", "=", "torch", ".", "argmax", "(", "logitsT1", ",", "dim", "=", "1", ")", "==", "labelsT1", "\n", "accuracyT1", "=", "valid_mean", "(", "correctT1", ".", "float", "(", ")", ",", "valid", "=", "labelsT1", ">=", "0", ")", "\n", "\n", "b", ",", "e", ",", "s", "=", "dtb", "[", "-", "3", "]", ",", "dtb", "[", "-", "2", "]", ",", "1", "# delta_t = T - 2", "\n", "logitsT2", ",", "labelsT2", "=", "logits_d", "[", "b", ":", "e", ":", "s", "]", ",", "labels", "[", "b", ":", "e", ":", "s", "]", "\n", "correctT2", "=", "torch", ".", "argmax", "(", "logitsT2", ",", "dim", "=", "1", ")", "==", "labelsT2", "\n", "accuracyT2", "=", "valid_mean", "(", "correctT2", ".", "float", "(", ")", ",", "valid", "=", "labelsT2", ">=", "0", ")", "\n", "\n", "accuracies", "=", "(", "accuracy1", ",", "accuracy2", ",", "accuracyT1", ",", "accuracyT2", ")", "\n", "\n", "return", "cpc_loss", ",", "accuracies", ",", "conv_output", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.cpc.CPC.validation": [[224, 243], ["rlpyt.utils.logging.logger.log", "ValInfo", "cpc.CPC.optimizer.zero_grad", "range", "cpc.CPC.optimizer.zero_grad", "rlpyt.utils.logging.logger.log", "cpc.CPC.replay_buffer.sample_batch", "ValInfo.cpcLoss.append", "ValInfo.cpcAccuracy1.append", "ValInfo.cpcAccuracy2.append", "ValInfo.cpcAccuracyTm1.append", "ValInfo.cpcAccuracyTm2.append", "ValInfo.convActivation.append", "torch.no_grad", "cpc.CPC.cpc_loss", "cpc_loss.item", "cpc_accuracies[].item", "cpc_accuracies[].item", "cpc_accuracies[].item", "cpc_accuracies[].item", "conv_output[].detach().cpu().view().numpy", "range", "conv_output[].detach().cpu().view", "len", "conv_output[].detach().cpu", "conv_output[].detach"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.logging.console.log", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.console.log", "home.repos.pwc.inspect_result.astooke_rlpyt.sequence.uniform.UniformSequenceReplay.sample_batch", "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.cpc.CPC.cpc_loss"], ["", "def", "validation", "(", "self", ",", "itr", ")", ":", "\n", "        ", "logger", ".", "log", "(", "\"Computing validation loss...\"", ")", "\n", "val_info", "=", "ValInfo", "(", "*", "(", "[", "]", "for", "_", "in", "range", "(", "len", "(", "ValInfo", ".", "_fields", ")", ")", ")", ")", "\n", "self", ".", "optimizer", ".", "zero_grad", "(", ")", "\n", "for", "_", "in", "range", "(", "self", ".", "n_validation_batches", ")", ":", "\n", "            ", "samples", "=", "self", ".", "replay_buffer", ".", "sample_batch", "(", "self", ".", "validation_batch_B", ",", "\n", "validation", "=", "True", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "cpc_loss", ",", "cpc_accuracies", ",", "conv_output", "=", "self", ".", "cpc_loss", "(", "samples", ")", "\n", "", "val_info", ".", "cpcLoss", ".", "append", "(", "cpc_loss", ".", "item", "(", ")", ")", "\n", "val_info", ".", "cpcAccuracy1", ".", "append", "(", "cpc_accuracies", "[", "0", "]", ".", "item", "(", ")", ")", "\n", "val_info", ".", "cpcAccuracy2", ".", "append", "(", "cpc_accuracies", "[", "1", "]", ".", "item", "(", ")", ")", "\n", "val_info", ".", "cpcAccuracyTm1", ".", "append", "(", "cpc_accuracies", "[", "2", "]", ".", "item", "(", ")", ")", "\n", "val_info", ".", "cpcAccuracyTm2", ".", "append", "(", "cpc_accuracies", "[", "3", "]", ".", "item", "(", ")", ")", "\n", "val_info", ".", "convActivation", ".", "append", "(", "\n", "conv_output", "[", "0", ",", "0", "]", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "view", "(", "-", "1", ")", ".", "numpy", "(", ")", ")", "\n", "", "self", ".", "optimizer", ".", "zero_grad", "(", ")", "\n", "logger", ".", "log", "(", "\"...validation loss completed.\"", ")", "\n", "return", "val_info", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.cpc.CPC.state_dict": [[244, 250], ["dict", "cpc.CPC.encoder.state_dict", "cpc.CPC.prediction_rnn.state_dict", "cpc.CPC.transforms.state_dict", "cpc.CPC.optimizer.state_dict"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.replay_saver.DummyOptimizer.state_dict", "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.replay_saver.DummyOptimizer.state_dict", "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.replay_saver.DummyOptimizer.state_dict", "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.replay_saver.DummyOptimizer.state_dict"], ["", "def", "state_dict", "(", "self", ")", ":", "\n", "        ", "return", "dict", "(", "\n", "encoder", "=", "self", ".", "encoder", ".", "state_dict", "(", ")", ",", "\n", "prediction_rnn", "=", "self", ".", "prediction_rnn", ".", "state_dict", "(", ")", ",", "\n", "transforms", "=", "self", ".", "transforms", ".", "state_dict", "(", ")", ",", "\n", "optimizer", "=", "self", ".", "optimizer", ".", "state_dict", "(", ")", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.cpc.CPC.load_state_dict": [[252, 257], ["cpc.CPC.encoder.load_state_dict", "cpc.CPC.prediction_rnn.load_state_dict", "cpc.CPC.transforms.load_state_dict", "cpc.CPC.optimizer.load_state_dict"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.augmented_temporal_similarity.AugmentedTemporalSimilarity.load_state_dict", "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.augmented_temporal_similarity.AugmentedTemporalSimilarity.load_state_dict", "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.augmented_temporal_similarity.AugmentedTemporalSimilarity.load_state_dict", "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.augmented_temporal_similarity.AugmentedTemporalSimilarity.load_state_dict"], ["", "def", "load_state_dict", "(", "self", ",", "state_dict", ")", ":", "\n", "        ", "self", ".", "encoder", ".", "load_state_dict", "(", "state_dict", "[", "\"encoder\"", "]", ")", "\n", "self", ".", "prediction_rnn", ".", "load_state_dict", "(", "state_dict", "[", "\"prediction_rnn\"", "]", ")", "\n", "self", ".", "transforms", ".", "load_state_dict", "(", "state_dict", "[", "\"transforms\"", "]", ")", "\n", "self", ".", "optimizer", ".", "load_state_dict", "(", "state_dict", "[", "\"optimizer\"", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.cpc.CPC.parameters": [[258, 262], ["cpc.CPC.encoder.parameters", "cpc.CPC.prediction_rnn.parameters", "cpc.CPC.transforms.parameters"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.rl.atari_rl_models.AtariDqnModel.parameters", "home.repos.pwc.inspect_result.astooke_rlpyt.rl.atari_rl_models.AtariDqnModel.parameters", "home.repos.pwc.inspect_result.astooke_rlpyt.rl.atari_rl_models.AtariDqnModel.parameters"], ["", "def", "parameters", "(", "self", ")", ":", "\n", "        ", "yield", "from", "self", ".", "encoder", ".", "parameters", "(", ")", "\n", "yield", "from", "self", ".", "prediction_rnn", ".", "parameters", "(", ")", "\n", "yield", "from", "self", ".", "transforms", ".", "parameters", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.cpc.CPC.named_parameters": [[263, 268], ["cpc.CPC.encoder.named_parameters", "cpc.CPC.prediction_rnn.named_parameters", "cpc.CPC.transforms.named_parameters"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.rl.atari_rl_models.AtariDqnModel.named_parameters", "home.repos.pwc.inspect_result.astooke_rlpyt.rl.atari_rl_models.AtariDqnModel.named_parameters", "home.repos.pwc.inspect_result.astooke_rlpyt.rl.atari_rl_models.AtariDqnModel.named_parameters"], ["", "def", "named_parameters", "(", "self", ")", ":", "\n", "        ", "\"\"\"To allow filtering by name in weight decay.\"\"\"", "\n", "yield", "from", "self", ".", "encoder", ".", "named_parameters", "(", ")", "\n", "yield", "from", "self", ".", "prediction_rnn", ".", "named_parameters", "(", ")", "\n", "yield", "from", "self", ".", "transforms", ".", "named_parameters", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.cpc.CPC.eval": [[269, 273], ["cpc.CPC.encoder.eval", "cpc.CPC.prediction_rnn.eval", "cpc.CPC.transforms.eval"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.augmented_temporal_similarity.AugmentedTemporalSimilarity.eval", "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.augmented_temporal_similarity.AugmentedTemporalSimilarity.eval", "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.augmented_temporal_similarity.AugmentedTemporalSimilarity.eval"], ["", "def", "eval", "(", "self", ")", ":", "\n", "        ", "self", ".", "encoder", ".", "eval", "(", ")", "# in case of batch norm", "\n", "self", ".", "prediction_rnn", ".", "eval", "(", ")", "\n", "self", ".", "transforms", ".", "eval", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.cpc.CPC.train": [[274, 278], ["cpc.CPC.encoder.train", "cpc.CPC.prediction_rnn.train", "cpc.CPC.transforms.train"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.runners.minibatch_rl.MinibatchRlEval.train", "home.repos.pwc.inspect_result.astooke_rlpyt.runners.minibatch_rl.MinibatchRlEval.train", "home.repos.pwc.inspect_result.astooke_rlpyt.runners.minibatch_rl.MinibatchRlEval.train"], ["", "def", "train", "(", "self", ")", ":", "\n", "        ", "self", ".", "encoder", ".", "train", "(", ")", "\n", "self", ".", "prediction_rnn", ".", "train", "(", ")", "\n", "self", ".", "transforms", ".", "train", "(", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.stdim.STDIM.__init__": [[34, 69], ["rlpyt.utils.quick_args.save__init__args", "torch.nn.CrossEntropyLoss", "dict", "dict", "locals"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.utils.quick_args.save__init__args"], ["def", "__init__", "(", "\n", "self", ",", "\n", "replay_filepath", ",", "\n", "learning_rate", ",", "\n", "batch_B", "=", "64", ",", "\n", "batch_T", "=", "1", ",", "\n", "delta_T", "=", "1", ",", "\n", "use_global_global", "=", "False", ",", "\n", "use_global_local", "=", "True", ",", "\n", "use_local_local", "=", "True", ",", "\n", "local_conv_layer", "=", "1", ",", "# 0-based indexing", "\n", "latent_size", "=", "256", ",", "\n", "target_update_tau", "=", "0.01", ",", "# 1 for hard update", "\n", "target_update_interval", "=", "1", ",", "\n", "OptimCls", "=", "torch", ".", "optim", ".", "Adam", ",", "\n", "optim_kwargs", "=", "None", ",", "\n", "initial_state_dict", "=", "None", ",", "\n", "clip_grad_norm", "=", "100.", ",", "\n", "EncoderCls", "=", "StDimEncoderModel", ",", "\n", "encoder_kwargs", "=", "None", ",", "\n", "ReplayCls", "=", "UlForRlReplayBuffer", ",", "\n", "anchor_hidden_sizes", "=", "512", ",", "\n", "activation_loss_coefficient", "=", "0.0", ",", "\n", "learning_rate_anneal", "=", "None", ",", "# cosine", "\n", "learning_rate_warmup", "=", "0", ",", "# number of updates", "\n", "validation_split", "=", "0.0", ",", "\n", "n_validation_batches", "=", "0", ",", "\n", ")", ":", "\n", "        ", "optim_kwargs", "=", "dict", "(", ")", "if", "optim_kwargs", "is", "None", "else", "optim_kwargs", "\n", "encoder_kwargs", "=", "dict", "(", ")", "if", "encoder_kwargs", "is", "None", "else", "encoder_kwargs", "\n", "save__init__args", "(", "locals", "(", ")", ")", "\n", "self", ".", "c_e_loss", "=", "torch", ".", "nn", ".", "CrossEntropyLoss", "(", "ignore_index", "=", "IGNORE_INDEX", ")", "\n", "assert", "learning_rate_anneal", "in", "[", "None", ",", "\"cosine\"", "]", "\n", "self", ".", "_replay_T", "=", "batch_T", "+", "delta_T", "\n", "self", ".", "batch_size", "=", "batch_B", "*", "batch_T", "# for logging", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.stdim.STDIM.initialize": [[70, 109], ["stdim.STDIM.load_replay", "stdim.STDIM.EncoderCls", "copy.deepcopy", "stdim.STDIM.encoder.to", "stdim.STDIM.target_encoder.to", "stdim.STDIM.optim_initialize", "torch.device", "torch.device", "rlpyt.ul.models.ul.atc_models.ContrastModel", "stdim.STDIM.gg_contrast.to", "rlpyt.ul.models.ul.stdim_models.StDimGlobalLocalContrastModel", "stdim.STDIM.gl_contrast.to", "rlpyt.ul.models.ul.stdim_models.StDimLocalLocalContrastModel", "stdim.STDIM.ll_contrast.to", "stdim.STDIM.load_state_dict"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.pixel_control.PixelControl.load_replay", "home.repos.pwc.inspect_result.astooke_rlpyt.rl_with_ul.sac_with_ul.SacWithUl.optim_initialize", "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.augmented_temporal_similarity.AugmentedTemporalSimilarity.load_state_dict"], ["", "def", "initialize", "(", "self", ",", "n_updates", ",", "cuda_idx", "=", "None", ")", ":", "\n", "        ", "self", ".", "device", "=", "torch", ".", "device", "(", "\"cpu\"", ")", "if", "cuda_idx", "is", "None", "else", "torch", ".", "device", "(", "\n", "\"cuda\"", ",", "index", "=", "cuda_idx", ")", "\n", "\n", "examples", "=", "self", ".", "load_replay", "(", ")", "\n", "self", ".", "encoder", "=", "self", ".", "EncoderCls", "(", "\n", "image_shape", "=", "examples", ".", "observation", ".", "shape", ",", "\n", "latent_size", "=", "self", ".", "latent_size", ",", "\n", "**", "self", ".", "encoder_kwargs", "\n", ")", "\n", "self", ".", "target_encoder", "=", "copy", ".", "deepcopy", "(", "self", ".", "encoder", ")", "\n", "self", ".", "encoder", ".", "to", "(", "self", ".", "device", ")", "\n", "self", ".", "target_encoder", ".", "to", "(", "self", ".", "device", ")", "\n", "\n", "local_size", "=", "self", ".", "encoder", ".", "conv_out_shapes", "[", "self", ".", "local_conv_layer", "]", "[", "0", "]", "# C from [C,H,W]", "\n", "if", "self", ".", "use_global_global", ":", "\n", "            ", "self", ".", "gg_contrast", "=", "ContrastModel", "(", "\n", "latent_size", "=", "self", ".", "latent_size", ",", "\n", "anchor_hidden_sizes", "=", "self", ".", "anchor_hidden_sizes", ",", "\n", ")", "\n", "self", ".", "gg_contrast", ".", "to", "(", "self", ".", "device", ")", "\n", "", "if", "self", ".", "use_global_local", ":", "\n", "            ", "self", ".", "gl_contrast", "=", "StDimGlobalLocalContrastModel", "(", "\n", "latent_size", "=", "self", ".", "latent_size", ",", "\n", "anchor_hidden_sizes", "=", "self", ".", "anchor_hidden_sizes", ",", "\n", "local_size", "=", "local_size", ",", "\n", ")", "\n", "self", ".", "gl_contrast", ".", "to", "(", "self", ".", "device", ")", "\n", "", "if", "self", ".", "use_local_local", ":", "\n", "            ", "self", ".", "ll_contrast", "=", "StDimLocalLocalContrastModel", "(", "\n", "anchor_hidden_sizes", "=", "self", ".", "anchor_hidden_sizes", ",", "\n", "local_size", "=", "local_size", ",", "\n", ")", "\n", "self", ".", "ll_contrast", ".", "to", "(", "self", ".", "device", ")", "\n", "\n", "", "self", ".", "optim_initialize", "(", "n_updates", ")", "\n", "\n", "if", "self", ".", "initial_state_dict", "is", "not", "None", ":", "\n", "            ", "self", ".", "load_state_dict", "(", "self", ".", "initial_state_dict", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.stdim.STDIM.optimize": [[110, 141], ["OptInfo", "stdim.STDIM.replay_buffer.sample_batch", "stdim.STDIM.optimizer.zero_grad", "stdim.STDIM.stdim_loss", "stdim.STDIM.activation_loss", "loss.backward", "stdim.STDIM.optimizer.step", "OptInfo.stdimLoss.append", "OptInfo.ggLoss.append", "OptInfo.glLoss.append", "OptInfo.llLoss.append", "OptInfo.ggAccuracy.append", "OptInfo.glAccuracy.append", "OptInfo.llAccuracy.append", "OptInfo.activationLoss.append", "OptInfo.gradNorm.append", "OptInfo.convActivation.append", "stdim.STDIM.lr_scheduler.step", "torch.nn.utils.clip_grad_norm_", "stdim_loss.item", "stdim.STDIM.item", "torch.nn.utils.clip_grad_norm_.item", "conv_output[].detach().cpu().view().numpy", "rlpyt.models.utils.update_state_dict", "stdim.STDIM.parameters", "stdim.STDIM.encoder.state_dict", "conv_output[].detach().cpu().view", "range", "len", "conv_output[].detach().cpu", "conv_output[].detach"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.sequence.uniform.UniformSequenceReplay.sample_batch", "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.stdim.STDIM.stdim_loss", "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.base.BaseUlAlgorithm.activation_loss", "home.repos.pwc.inspect_result.astooke_rlpyt.models.utils.ScaleGrad.backward", "home.repos.pwc.inspect_result.astooke_rlpyt.safe.safety_gym_env.SafetyGymTrajInfo.step", "home.repos.pwc.inspect_result.astooke_rlpyt.safe.safety_gym_env.SafetyGymTrajInfo.step", "home.repos.pwc.inspect_result.astooke_rlpyt.models.utils.update_state_dict", "home.repos.pwc.inspect_result.astooke_rlpyt.rl.atari_rl_models.AtariDqnModel.parameters", "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.replay_saver.DummyOptimizer.state_dict"], ["", "", "def", "optimize", "(", "self", ",", "itr", ")", ":", "\n", "        ", "opt_info", "=", "OptInfo", "(", "*", "(", "[", "]", "for", "_", "in", "range", "(", "len", "(", "OptInfo", ".", "_fields", ")", ")", ")", ")", "\n", "samples", "=", "self", ".", "replay_buffer", ".", "sample_batch", "(", "self", ".", "batch_size", ")", "\n", "if", "self", ".", "lr_scheduler", "is", "not", "None", ":", "\n", "            ", "self", ".", "lr_scheduler", ".", "step", "(", "itr", ")", "# Do every itr instead of every epoch", "\n", "", "self", ".", "optimizer", ".", "zero_grad", "(", ")", "\n", "stdim_loss", ",", "loss_vals", ",", "accuracies", ",", "conv_output", "=", "self", ".", "stdim_loss", "(", "samples", ")", "\n", "act_loss", "=", "self", ".", "activation_loss", "(", "conv_output", ")", "\n", "loss", "=", "stdim_loss", "+", "act_loss", "\n", "loss", ".", "backward", "(", ")", "\n", "if", "self", ".", "clip_grad_norm", "is", "None", ":", "\n", "            ", "grad_norm", "=", "0.", "\n", "", "else", ":", "\n", "            ", "grad_norm", "=", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "\n", "self", ".", "parameters", "(", ")", ",", "self", ".", "clip_grad_norm", ")", "\n", "", "self", ".", "optimizer", ".", "step", "(", ")", "\n", "opt_info", ".", "stdimLoss", ".", "append", "(", "stdim_loss", ".", "item", "(", ")", ")", "\n", "opt_info", ".", "ggLoss", ".", "append", "(", "loss_vals", "[", "0", "]", ")", "\n", "opt_info", ".", "glLoss", ".", "append", "(", "loss_vals", "[", "1", "]", ")", "\n", "opt_info", ".", "llLoss", ".", "append", "(", "loss_vals", "[", "2", "]", ")", "\n", "opt_info", ".", "ggAccuracy", ".", "append", "(", "accuracies", "[", "0", "]", ")", "\n", "opt_info", ".", "glAccuracy", ".", "append", "(", "accuracies", "[", "1", "]", ")", "\n", "opt_info", ".", "llAccuracy", ".", "append", "(", "accuracies", "[", "2", "]", ")", "\n", "opt_info", ".", "activationLoss", ".", "append", "(", "act_loss", ".", "item", "(", ")", ")", "\n", "opt_info", ".", "gradNorm", ".", "append", "(", "grad_norm", ".", "item", "(", ")", ")", "\n", "opt_info", ".", "convActivation", ".", "append", "(", "\n", "conv_output", "[", "0", "]", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "view", "(", "-", "1", ")", ".", "numpy", "(", ")", ")", "# Keep 1 full one.", "\n", "if", "itr", "%", "self", ".", "target_update_interval", "==", "0", ":", "\n", "            ", "update_state_dict", "(", "self", ".", "target_encoder", ",", "self", ".", "encoder", ".", "state_dict", "(", ")", ",", "\n", "self", ".", "target_update_tau", ")", "\n", "", "return", "opt_info", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.stdim.STDIM.stdim_loss": [[142, 199], ["anchor.view.view.view", "positive.view.view.view", "rlpyt.utils.buffer.buffer_to", "stdim.STDIM.encoder", "torch.arange", "rlpyt.algos.utils.valid_from_done().type", "valid[].reshape", "torch.no_grad", "stdim.STDIM.target_encoder", "stdim.STDIM.gg_contrast", "stdim.STDIM.c_e_loss", "torch.mean", "stdim.STDIM.gl_contrast", "torch.stack", "torch.mean", "torch.mean", "stdim.STDIM.ll_contrast", "torch.stack", "torch.mean", "torch.mean", "stdim.STDIM.item", "torch.mean.item", "torch.mean.item", "torch.mean.item", "torch.mean.item", "torch.mean.item", "rlpyt.algos.utils.valid_from_done", "torch.tensor", "torch.tensor", "torch.argmax", "gg_correct[].float", "torch.mean", "torch.stack", "torch.mean", "torch.stack", "stdim.STDIM.detach", "stdim.STDIM.c_e_loss", "torch.argmax", "gl_correct[].float", "stdim.STDIM.c_e_loss", "torch.argmax", "ll_correct[].float", "gl_logits.detach", "ll_logits.detach"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.utils.buffer.buffer_to", "home.repos.pwc.inspect_result.astooke_rlpyt.algos.utils.valid_from_done"], ["", "def", "stdim_loss", "(", "self", ",", "samples", ")", ":", "\n", "        ", "\"\"\"Contrast over the batch dimension for every location, but not across\n        locations.\"\"\"", "\n", "anchor", "=", "samples", ".", "observation", "[", ":", "-", "self", ".", "delta_T", "]", "\n", "positive", "=", "samples", ".", "observation", "[", "self", ".", "delta_T", ":", "]", "\n", "t", ",", "b", ",", "c", ",", "h", ",", "w", "=", "anchor", ".", "shape", "\n", "anchor", "=", "anchor", ".", "view", "(", "t", "*", "b", ",", "c", ",", "h", ",", "w", ")", "# Treat all T,B as separate.", "\n", "positive", "=", "positive", ".", "view", "(", "t", "*", "b", ",", "c", ",", "h", ",", "w", ")", "\n", "\n", "anchor", ",", "positive", "=", "buffer_to", "(", "(", "anchor", ",", "positive", ")", ",", "\n", "device", "=", "self", ".", "device", ")", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "c_positive", ",", "_", ",", "positive_conv_layers", "=", "self", ".", "target_encoder", "(", "positive", ")", "\n", "", "c_anchor", ",", "anchor_conv_out", ",", "anchor_conv_layers", "=", "self", ".", "encoder", "(", "anchor", ")", "\n", "\n", "labels", "=", "torch", ".", "arange", "(", "c_anchor", ".", "shape", "[", "0", "]", ",", "# batch size", "\n", "dtype", "=", "torch", ".", "long", ",", "device", "=", "self", ".", "device", ")", "\n", "valid", "=", "valid_from_done", "(", "samples", ".", "done", ")", ".", "type", "(", "torch", ".", "bool", ")", "\n", "valid", "=", "valid", "[", "self", ".", "delta_T", ":", "]", ".", "reshape", "(", "-", "1", ")", "\n", "labels", "[", "~", "valid", "]", "=", "IGNORE_INDEX", "\n", "\n", "gg_loss", ",", "gl_loss", ",", "ll_loss", "=", "[", "torch", ".", "tensor", "(", "0.", ",", "device", "=", "self", ".", "device", ")", "]", "*", "3", "\n", "gg_accuracy", ",", "gl_accuracy", ",", "ll_accuracy", "=", "[", "torch", ".", "tensor", "(", "0.", ",", "device", "=", "self", ".", "device", ")", "]", "*", "3", "\n", "if", "self", ".", "use_global_global", ":", "\n", "            ", "gg_logits", "=", "self", ".", "gg_contrast", "(", "c_anchor", ",", "c_positive", ")", "\n", "gg_loss", "=", "self", ".", "c_e_loss", "(", "gg_logits", ",", "labels", ")", "\n", "gg_correct", "=", "torch", ".", "argmax", "(", "gg_logits", ".", "detach", "(", ")", ",", "dim", "=", "1", ")", "==", "labels", "\n", "gg_accuracy", "=", "torch", ".", "mean", "(", "gg_correct", "[", "valid", "]", ".", "float", "(", ")", ")", "\n", "", "if", "self", ".", "use_global_local", ":", "\n", "            ", "positive_local", "=", "positive_conv_layers", "[", "self", ".", "local_conv_layer", "]", "\n", "gl_logits_list", "=", "self", ".", "gl_contrast", "(", "c_anchor", ",", "positive_local", ")", "\n", "gl_losses", "=", "torch", ".", "stack", "(", "[", "self", ".", "c_e_loss", "(", "gl_logits", ",", "labels", ")", "\n", "for", "gl_logits", "in", "gl_logits_list", "]", ")", "\n", "gl_loss", "=", "torch", ".", "mean", "(", "gl_losses", ")", "\n", "gl_corrects", "=", "[", "torch", ".", "argmax", "(", "gl_logits", ".", "detach", "(", ")", ",", "dim", "=", "1", ")", "==", "labels", "\n", "for", "gl_logits", "in", "gl_logits_list", "]", "\n", "gl_accuracies", "=", "[", "torch", ".", "mean", "(", "gl_correct", "[", "valid", "]", ".", "float", "(", ")", ")", "\n", "for", "gl_correct", "in", "gl_corrects", "]", "\n", "gl_accuracy", "=", "torch", ".", "mean", "(", "torch", ".", "stack", "(", "gl_accuracies", ")", ")", "\n", "", "if", "self", ".", "use_local_local", ":", "\n", "            ", "anchor_local", "=", "anchor_conv_layers", "[", "self", ".", "local_conv_layer", "]", "\n", "positive_local", "=", "positive_conv_layers", "[", "self", ".", "local_conv_layer", "]", "\n", "ll_logits_list", "=", "self", ".", "ll_contrast", "(", "anchor_local", ",", "positive_local", ")", "\n", "ll_losses", "=", "torch", ".", "stack", "(", "[", "self", ".", "c_e_loss", "(", "ll_logits", ",", "labels", ")", "\n", "for", "ll_logits", "in", "ll_logits_list", "]", ")", "\n", "ll_loss", "=", "torch", ".", "mean", "(", "ll_losses", ")", "\n", "ll_corrects", "=", "[", "torch", ".", "argmax", "(", "ll_logits", ".", "detach", "(", ")", ",", "dim", "=", "1", ")", "==", "labels", "\n", "for", "ll_logits", "in", "ll_logits_list", "]", "\n", "ll_accuracies", "=", "[", "torch", ".", "mean", "(", "ll_correct", "[", "valid", "]", ".", "float", "(", ")", ")", "\n", "for", "ll_correct", "in", "ll_corrects", "]", "\n", "ll_accuracy", "=", "torch", ".", "mean", "(", "torch", ".", "stack", "(", "ll_accuracies", ")", ")", "\n", "", "stdim_loss", "=", "gg_loss", "+", "gl_loss", "+", "ll_loss", "\n", "\n", "loss_vals", "=", "(", "gg_loss", ".", "item", "(", ")", ",", "gl_loss", ".", "item", "(", ")", ",", "ll_loss", ".", "item", "(", ")", ")", "\n", "accuracies", "=", "(", "gg_accuracy", ".", "item", "(", ")", ",", "gl_accuracy", ".", "item", "(", ")", ",", "ll_accuracy", ".", "item", "(", ")", ")", "\n", "return", "stdim_loss", ",", "loss_vals", ",", "accuracies", ",", "anchor_conv_out", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.stdim.STDIM.validation": [[200, 222], ["rlpyt.utils.logging.logger.log", "ValInfo", "stdim.STDIM.optimizer.zero_grad", "range", "stdim.STDIM.optimizer.zero_grad", "rlpyt.utils.logging.logger.log", "stdim.STDIM.replay_buffer.sample_batch", "ValInfo.stdimLoss.append", "ValInfo.ggLoss.append", "ValInfo.glLoss.append", "ValInfo.llLoss.append", "ValInfo.ggAccuracy.append", "ValInfo.glAccuracy.append", "ValInfo.llAccuracy.append", "ValInfo.convActivation.append", "torch.no_grad", "stdim.STDIM.stdim_loss", "stdim_loss.item", "conv_output[].detach().cpu().view().numpy", "range", "conv_output[].detach().cpu().view", "len", "conv_output[].detach().cpu", "conv_output[].detach"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.logging.console.log", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.console.log", "home.repos.pwc.inspect_result.astooke_rlpyt.sequence.uniform.UniformSequenceReplay.sample_batch", "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.stdim.STDIM.stdim_loss"], ["", "def", "validation", "(", "self", ",", "itr", ")", ":", "\n", "        ", "logger", ".", "log", "(", "\"Computing validation loss...\"", ")", "\n", "val_info", "=", "ValInfo", "(", "*", "(", "[", "]", "for", "_", "in", "range", "(", "len", "(", "ValInfo", ".", "_fields", ")", ")", ")", ")", "\n", "self", ".", "optimizer", ".", "zero_grad", "(", ")", "\n", "for", "_", "in", "range", "(", "self", ".", "n_validation_batches", ")", ":", "\n", "            ", "samples", "=", "self", ".", "replay_buffer", ".", "sample_batch", "(", "self", ".", "batch_B", ",", "\n", "validation", "=", "True", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "stdim_loss", ",", "loss_vals", ",", "accuracies", ",", "conv_output", "=", "self", ".", "stdim_loss", "(", "samples", ")", "\n", "", "val_info", ".", "stdimLoss", ".", "append", "(", "stdim_loss", ".", "item", "(", ")", ")", "\n", "val_info", ".", "ggLoss", ".", "append", "(", "loss_vals", "[", "0", "]", ")", "\n", "val_info", ".", "glLoss", ".", "append", "(", "loss_vals", "[", "1", "]", ")", "\n", "val_info", ".", "llLoss", ".", "append", "(", "loss_vals", "[", "2", "]", ")", "\n", "val_info", ".", "ggAccuracy", ".", "append", "(", "accuracies", "[", "0", "]", ")", "\n", "val_info", ".", "glAccuracy", ".", "append", "(", "accuracies", "[", "1", "]", ")", "\n", "val_info", ".", "llAccuracy", ".", "append", "(", "accuracies", "[", "2", "]", ")", "\n", "val_info", ".", "convActivation", ".", "append", "(", "\n", "conv_output", "[", "0", "]", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "view", "(", "-", "1", ")", ".", "numpy", "(", ")", ")", "# Keep 1 full one.", "\n", "\n", "", "self", ".", "optimizer", ".", "zero_grad", "(", ")", "\n", "logger", ".", "log", "(", "\"...validation loss completed.\"", ")", "\n", "return", "val_info", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.stdim.STDIM.state_dict": [[223, 236], ["dict", "stdim.STDIM.gg_contrast.state_dict", "stdim.STDIM.gl_contrast.state_dict", "stdim.STDIM.ll_contrast.state_dict", "stdim.STDIM.encoder.state_dict", "stdim.STDIM.target_encoder.state_dict", "stdim.STDIM.optimizer.state_dict"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.replay_saver.DummyOptimizer.state_dict", "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.replay_saver.DummyOptimizer.state_dict", "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.replay_saver.DummyOptimizer.state_dict", "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.replay_saver.DummyOptimizer.state_dict", "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.replay_saver.DummyOptimizer.state_dict", "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.replay_saver.DummyOptimizer.state_dict"], ["", "def", "state_dict", "(", "self", ")", ":", "\n", "        ", "state_dict", "=", "dict", "(", "\n", "encoder", "=", "self", ".", "encoder", ".", "state_dict", "(", ")", ",", "\n", "target_encoder", "=", "self", ".", "target_encoder", ".", "state_dict", "(", ")", ",", "\n", "optimizer", "=", "self", ".", "optimizer", ".", "state_dict", "(", ")", ",", "\n", ")", "\n", "if", "self", ".", "use_global_global", ":", "\n", "            ", "state_dict", "[", "\"gg_contrast\"", "]", "=", "self", ".", "gg_contrast", ".", "state_dict", "(", ")", "\n", "", "if", "self", ".", "use_global_local", ":", "\n", "            ", "state_dict", "[", "\"gl_contrast\"", "]", "=", "self", ".", "gl_contrast", ".", "state_dict", "(", ")", "\n", "", "if", "self", ".", "use_local_local", ":", "\n", "            ", "state_dict", "[", "\"ll_contrast\"", "]", "=", "self", ".", "ll_contrast", ".", "state_dict", "(", ")", "\n", "", "return", "state_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.stdim.STDIM.load_state_dict": [[237, 247], ["stdim.STDIM.encoder.load_state_dict", "stdim.STDIM.target_encoder.load_state_dict", "stdim.STDIM.optimizer.load_state_dict", "stdim.STDIM.gg_contrast.load_state_dict", "stdim.STDIM.gl_contrast.load_state_dict", "stdim.STDIM.ll_contrast.load_state_dict"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.augmented_temporal_similarity.AugmentedTemporalSimilarity.load_state_dict", "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.augmented_temporal_similarity.AugmentedTemporalSimilarity.load_state_dict", "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.augmented_temporal_similarity.AugmentedTemporalSimilarity.load_state_dict", "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.augmented_temporal_similarity.AugmentedTemporalSimilarity.load_state_dict", "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.augmented_temporal_similarity.AugmentedTemporalSimilarity.load_state_dict", "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.augmented_temporal_similarity.AugmentedTemporalSimilarity.load_state_dict"], ["", "def", "load_state_dict", "(", "self", ",", "state_dict", ")", ":", "\n", "        ", "self", ".", "encoder", ".", "load_state_dict", "(", "state_dict", "[", "\"encoder\"", "]", ")", "\n", "self", ".", "target_encoder", ".", "load_state_dict", "(", "state_dict", "[", "\"target_encoder\"", "]", ")", "\n", "self", ".", "optimizer", ".", "load_state_dict", "(", "state_dict", "[", "\"optimizer\"", "]", ")", "\n", "if", "self", ".", "use_global_global", ":", "\n", "            ", "self", ".", "gg_contrast", ".", "load_state_dict", "(", "state_dict", "[", "\"gg_contrast\"", "]", ")", "\n", "", "if", "self", ".", "use_global_local", ":", "\n", "            ", "self", ".", "gl_contrast", ".", "load_state_dict", "(", "state_dict", "[", "\"gl_contrast\"", "]", ")", "\n", "", "if", "self", ".", "use_local_local", ":", "\n", "            ", "self", ".", "ll_contrast", ".", "load_state_dict", "(", "state_dict", "[", "\"ll_contrast\"", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.stdim.STDIM.parameters": [[248, 256], ["stdim.STDIM.encoder.parameters", "stdim.STDIM.gg_contrast.parameters", "stdim.STDIM.gl_contrast.parameters", "stdim.STDIM.ll_contrast.parameters"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.rl.atari_rl_models.AtariDqnModel.parameters", "home.repos.pwc.inspect_result.astooke_rlpyt.rl.atari_rl_models.AtariDqnModel.parameters", "home.repos.pwc.inspect_result.astooke_rlpyt.rl.atari_rl_models.AtariDqnModel.parameters", "home.repos.pwc.inspect_result.astooke_rlpyt.rl.atari_rl_models.AtariDqnModel.parameters"], ["", "", "def", "parameters", "(", "self", ")", ":", "\n", "        ", "yield", "from", "self", ".", "encoder", ".", "parameters", "(", ")", "\n", "if", "self", ".", "use_global_global", ":", "\n", "            ", "yield", "from", "self", ".", "gg_contrast", ".", "parameters", "(", ")", "\n", "", "if", "self", ".", "use_global_local", ":", "\n", "            ", "yield", "from", "self", ".", "gl_contrast", ".", "parameters", "(", ")", "\n", "", "if", "self", ".", "use_local_local", ":", "\n", "            ", "yield", "from", "self", ".", "ll_contrast", ".", "parameters", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.stdim.STDIM.named_parameters": [[257, 266], ["stdim.STDIM.encoder.named_parameters", "stdim.STDIM.gg_contrast.named_parameters", "stdim.STDIM.gl_contrast.named_parameters", "stdim.STDIM.ll_contrast.named_parameters"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.rl.atari_rl_models.AtariDqnModel.named_parameters", "home.repos.pwc.inspect_result.astooke_rlpyt.rl.atari_rl_models.AtariDqnModel.named_parameters", "home.repos.pwc.inspect_result.astooke_rlpyt.rl.atari_rl_models.AtariDqnModel.named_parameters", "home.repos.pwc.inspect_result.astooke_rlpyt.rl.atari_rl_models.AtariDqnModel.named_parameters"], ["", "", "def", "named_parameters", "(", "self", ")", ":", "\n", "        ", "\"\"\"To allow filtering by name in weight decay.\"\"\"", "\n", "yield", "from", "self", ".", "encoder", ".", "named_parameters", "(", ")", "\n", "if", "self", ".", "use_global_global", ":", "\n", "            ", "yield", "from", "self", ".", "gg_contrast", ".", "named_parameters", "(", ")", "\n", "", "if", "self", ".", "use_global_local", ":", "\n", "            ", "yield", "from", "self", ".", "gl_contrast", ".", "named_parameters", "(", ")", "\n", "", "if", "self", ".", "use_local_local", ":", "\n", "            ", "yield", "from", "self", ".", "ll_contrast", ".", "named_parameters", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.stdim.STDIM.eval": [[267, 275], ["stdim.STDIM.encoder.eval", "stdim.STDIM.gg_contrast.eval", "stdim.STDIM.gl_contrast.eval", "stdim.STDIM.ll_contrast.eval"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.augmented_temporal_similarity.AugmentedTemporalSimilarity.eval", "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.augmented_temporal_similarity.AugmentedTemporalSimilarity.eval", "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.augmented_temporal_similarity.AugmentedTemporalSimilarity.eval", "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.augmented_temporal_similarity.AugmentedTemporalSimilarity.eval"], ["", "", "def", "eval", "(", "self", ")", ":", "\n", "        ", "self", ".", "encoder", ".", "eval", "(", ")", "# in case of batch norm", "\n", "if", "self", ".", "use_global_global", ":", "\n", "            ", "self", ".", "gg_contrast", ".", "eval", "(", ")", "\n", "", "if", "self", ".", "use_global_local", ":", "\n", "            ", "self", ".", "gl_contrast", ".", "eval", "(", ")", "\n", "", "if", "self", ".", "use_local_local", ":", "\n", "            ", "self", ".", "ll_contrast", ".", "eval", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.stdim.STDIM.train": [[276, 284], ["stdim.STDIM.encoder.train", "stdim.STDIM.gg_contrast.train", "stdim.STDIM.gl_contrast.train", "stdim.STDIM.ll_contrast.train"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.runners.minibatch_rl.MinibatchRlEval.train", "home.repos.pwc.inspect_result.astooke_rlpyt.runners.minibatch_rl.MinibatchRlEval.train", "home.repos.pwc.inspect_result.astooke_rlpyt.runners.minibatch_rl.MinibatchRlEval.train", "home.repos.pwc.inspect_result.astooke_rlpyt.runners.minibatch_rl.MinibatchRlEval.train"], ["", "", "def", "train", "(", "self", ")", ":", "\n", "        ", "self", ".", "encoder", ".", "train", "(", ")", "\n", "if", "self", ".", "use_global_global", ":", "\n", "            ", "self", ".", "gg_contrast", ".", "train", "(", ")", "\n", "", "if", "self", ".", "use_global_local", ":", "\n", "            ", "self", ".", "gl_contrast", ".", "train", "(", ")", "\n", "", "if", "self", ".", "use_local_local", ":", "\n", "            ", "self", ".", "ll_contrast", ".", "train", "(", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.inverse.Inverse.__init__": [[32, 66], ["rlpyt.utils.quick_args.save__init__args", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "dict", "dict", "dict", "locals"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.utils.quick_args.save__init__args"], ["def", "__init__", "(", "\n", "self", ",", "\n", "batch_size", ",", "\n", "learning_rate", ",", "\n", "replay_filepath", ",", "\n", "delta_T", "=", "1", ",", "\n", "OptimCls", "=", "torch", ".", "optim", ".", "Adam", ",", "\n", "optim_kwargs", "=", "None", ",", "\n", "initial_state_dict", "=", "None", ",", "\n", "clip_grad_norm", "=", "10.", ",", "\n", "EncoderCls", "=", "EncoderModel", ",", "\n", "encoder_kwargs", "=", "None", ",", "\n", "ReplayCls", "=", "UlForRlReplayBuffer", ",", "\n", "onehot_actions", "=", "True", ",", "\n", "activation_loss_coefficient", "=", "0.0", ",", "\n", "learning_rate_anneal", "=", "None", ",", "# cosine", "\n", "learning_rate_warmup", "=", "0", ",", "# number of updates", "\n", "random_shift_prob", "=", "0.", ",", "\n", "random_shift_pad", "=", "4", ",", "\n", "InverseModelCls", "=", "InverseModel", ",", "\n", "inverse_model_kwargs", "=", "None", ",", "\n", "entropy_loss_coeff", "=", "0.01", ",", "\n", "validation_split", "=", "0.0", ",", "\n", "n_validation_batches", "=", "0", ",", "\n", ")", ":", "\n", "        ", "optim_kwargs", "=", "dict", "(", ")", "if", "optim_kwargs", "is", "None", "else", "optim_kwargs", "\n", "encoder_kwargs", "=", "dict", "(", ")", "if", "encoder_kwargs", "is", "None", "else", "encoder_kwargs", "\n", "inverse_model_kwargs", "=", "dict", "(", ")", "if", "inverse_model_kwargs", "is", "None", "else", "inverse_model_kwargs", "\n", "save__init__args", "(", "locals", "(", ")", ")", "\n", "self", ".", "c_e_loss", "=", "torch", ".", "nn", ".", "CrossEntropyLoss", "(", "ignore_index", "=", "IGNORE_INDEX", ")", "\n", "assert", "learning_rate_anneal", "in", "[", "None", ",", "\"cosine\"", "]", "\n", "assert", "onehot_actions", "# needs discrete action space for now.", "\n", "assert", "delta_T", ">", "0", "\n", "self", ".", "_replay_T", "=", "delta_T", "+", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.inverse.Inverse.initialize": [[67, 98], ["inverse.Inverse.load_replay", "inverse.Inverse.EncoderCls", "inverse.Inverse.InverseModelCls", "inverse.Inverse.encoder.to", "inverse.Inverse.inverse_model.to", "inverse.Inverse.optim_initialize", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "rlpyt.distributions.categorical.Categorical", "len", "inverse.Inverse.load_state_dict", "inverse.Inverse.replay_buffer.samples.action.max"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.pixel_control.PixelControl.load_replay", "home.repos.pwc.inspect_result.astooke_rlpyt.rl_with_ul.sac_with_ul.SacWithUl.optim_initialize", "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.augmented_temporal_similarity.AugmentedTemporalSimilarity.load_state_dict"], ["", "def", "initialize", "(", "self", ",", "n_updates", ",", "cuda_idx", "=", "None", ")", ":", "\n", "        ", "self", ".", "device", "=", "torch", ".", "device", "(", "\"cpu\"", ")", "if", "cuda_idx", "is", "None", "else", "torch", ".", "device", "(", "\n", "\"cuda\"", ",", "index", "=", "cuda_idx", ")", "\n", "\n", "examples", "=", "self", ".", "load_replay", "(", ")", "\n", "self", ".", "encoder", "=", "self", ".", "EncoderCls", "(", "\n", "image_shape", "=", "examples", ".", "observation", ".", "shape", ",", "\n", "latent_size", "=", "10", ",", "# UNUSED", "\n", "**", "self", ".", "encoder_kwargs", "\n", ")", "\n", "\n", "if", "self", ".", "onehot_actions", ":", "\n", "            ", "act_dim", "=", "self", ".", "replay_buffer", ".", "samples", ".", "action", ".", "max", "(", ")", "+", "1", "\n", "self", ".", "distribution", "=", "Categorical", "(", "act_dim", ")", "\n", "", "else", ":", "\n", "            ", "assert", "len", "(", "self", ".", "replay_buffer", ".", "samples", ".", "action", ".", "shape", "==", "3", ")", "\n", "act_dim", "=", "self", ".", "replay_buffer", ".", "samples", ".", "action", ".", "shape", "[", "2", "]", "\n", "", "self", ".", "inverse_model", "=", "self", ".", "InverseModelCls", "(", "\n", "input_size", "=", "self", ".", "encoder", ".", "conv_out_size", ",", "\n", "action_size", "=", "act_dim", ",", "\n", "num_actions", "=", "self", ".", "delta_T", ",", "\n", "use_input", "=", "\"conv\"", ",", "\n", "**", "self", ".", "inverse_model_kwargs", "\n", ")", "\n", "self", ".", "encoder", ".", "to", "(", "self", ".", "device", ")", "\n", "self", ".", "inverse_model", ".", "to", "(", "self", ".", "device", ")", "\n", "\n", "self", ".", "optim_initialize", "(", "n_updates", ")", "\n", "\n", "if", "self", ".", "initial_state_dict", "is", "not", "None", ":", "\n", "            ", "self", ".", "load_state_dict", "(", "self", ".", "initial_state_dict", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.inverse.Inverse.optimize": [[99, 124], ["OptInfo", "inverse.Inverse.replay_buffer.sample_batch", "inverse.Inverse.optimizer.zero_grad", "inverse.Inverse.inverse_loss", "inverse.Inverse.activation_loss", "loss.backward", "inverse.Inverse.optimizer.step", "OptInfo.invLoss.append", "OptInfo.entLoss.append", "OptInfo.accuracy.append", "OptInfo.perplexity.append", "OptInfo.activationLoss.append", "OptInfo.gradNorm.append", "OptInfo.convActivation.append", "inverse.Inverse.lr_scheduler.step", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "inv_loss.item", "ent_loss.item", "accuracy.item", "perplexity.item", "inverse.Inverse.item", "torch.nn.utils.clip_grad_norm_.item", "torch.nn.utils.clip_grad_norm_.item", "conv_output[].detach().cpu().view().numpy", "inverse.Inverse.parameters", "conv_output[].detach().cpu().view", "range", "len", "conv_output[].detach().cpu", "conv_output[].detach"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.sequence.uniform.UniformSequenceReplay.sample_batch", "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.inverse.Inverse.inverse_loss", "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.base.BaseUlAlgorithm.activation_loss", "home.repos.pwc.inspect_result.astooke_rlpyt.models.utils.ScaleGrad.backward", "home.repos.pwc.inspect_result.astooke_rlpyt.safe.safety_gym_env.SafetyGymTrajInfo.step", "home.repos.pwc.inspect_result.astooke_rlpyt.safe.safety_gym_env.SafetyGymTrajInfo.step", "home.repos.pwc.inspect_result.astooke_rlpyt.rl.atari_rl_models.AtariDqnModel.parameters"], ["", "", "def", "optimize", "(", "self", ",", "itr", ")", ":", "\n", "        ", "opt_info", "=", "OptInfo", "(", "*", "(", "[", "]", "for", "_", "in", "range", "(", "len", "(", "OptInfo", ".", "_fields", ")", ")", ")", ")", "\n", "samples", "=", "self", ".", "replay_buffer", ".", "sample_batch", "(", "self", ".", "batch_size", ")", "\n", "if", "self", ".", "lr_scheduler", "is", "not", "None", ":", "\n", "            ", "self", ".", "lr_scheduler", ".", "step", "(", "itr", ")", "# Do every itr instead of every epoch", "\n", "", "self", ".", "optimizer", ".", "zero_grad", "(", ")", "\n", "inv_loss", ",", "ent_loss", ",", "accuracy", ",", "perplexity", ",", "conv_output", "=", "self", ".", "inverse_loss", "(", "samples", ")", "\n", "act_loss", "=", "self", ".", "activation_loss", "(", "conv_output", ")", "\n", "loss", "=", "inv_loss", "+", "ent_loss", "+", "act_loss", "\n", "loss", ".", "backward", "(", ")", "\n", "if", "self", ".", "clip_grad_norm", "is", "None", ":", "\n", "            ", "grad_norm", "=", "0.", "\n", "", "else", ":", "\n", "            ", "grad_norm", "=", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "\n", "self", ".", "parameters", "(", ")", ",", "self", ".", "clip_grad_norm", ")", "\n", "", "self", ".", "optimizer", ".", "step", "(", ")", "\n", "opt_info", ".", "invLoss", ".", "append", "(", "inv_loss", ".", "item", "(", ")", ")", "\n", "opt_info", ".", "entLoss", ".", "append", "(", "ent_loss", ".", "item", "(", ")", ")", "\n", "opt_info", ".", "accuracy", ".", "append", "(", "accuracy", ".", "item", "(", ")", ")", "\n", "opt_info", ".", "perplexity", ".", "append", "(", "perplexity", ".", "item", "(", ")", ")", "\n", "opt_info", ".", "activationLoss", ".", "append", "(", "act_loss", ".", "item", "(", ")", ")", "\n", "opt_info", ".", "gradNorm", ".", "append", "(", "grad_norm", ".", "item", "(", ")", ")", "\n", "opt_info", ".", "convActivation", ".", "append", "(", "\n", "conv_output", "[", "0", "]", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "view", "(", "-", "1", ")", ".", "numpy", "(", ")", ")", "# Keep 1 full one.", "\n", "return", "opt_info", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.inverse.Inverse.inverse_loss": [[125, 184], ["rlpyt.utils.buffer.buffer_to", "inverse.Inverse.encoder", "inverse.Inverse.encoder", "rlpyt.algos.utils.valid_from_done().type", "valid[].repeat().transpose", "inverse.Inverse.distribution.mean_perplexity", "rlpyt.ul.algos.utils.data_augs.random_shift", "rlpyt.ul.algos.utils.data_augs.random_shift", "inverse.Inverse.inverse_model", "action[].transpose", "logits.view.view.view", "labels.reshape.reshape.reshape", "inverse.Inverse.c_e_loss", "valid.reshape().to.reshape().to.reshape().to", "rlpyt.distributions.categorical.DistInfo", "inverse.Inverse.distribution.mean_entropy", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "valid.reshape().to.reshape().to.to", "rlpyt.algos.utils.valid_from_done", "valid[].repeat", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "correct[].float", "torch.max", "torch.max", "torch.max", "torch.max", "valid.reshape().to.reshape().to.reshape", "torch.softmax", "torch.softmax", "logits.view.view.detach"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.utils.buffer.buffer_to", "home.repos.pwc.inspect_result.astooke_rlpyt.distributions.gaussian.Gaussian.mean_perplexity", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.data_augs.random_shift", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.data_augs.random_shift", "home.repos.pwc.inspect_result.astooke_rlpyt.distributions.gaussian.Gaussian.mean_entropy", "home.repos.pwc.inspect_result.astooke_rlpyt.algos.utils.valid_from_done"], ["", "def", "inverse_loss", "(", "self", ",", "samples", ")", ":", "\n", "        ", "observation", "=", "samples", ".", "observation", "[", "0", "]", "# [T,B,C,H,W]->[B,C,H,W]", "\n", "last_observation", "=", "samples", ".", "observation", "[", "-", "1", "]", "\n", "\n", "if", "self", ".", "random_shift_prob", ">", "0.", ":", "\n", "            ", "observation", "=", "random_shift", "(", "\n", "imgs", "=", "observation", ",", "\n", "pad", "=", "self", ".", "random_shift_pad", ",", "\n", "prob", "=", "self", ".", "random_shift_prob", ",", "\n", ")", "\n", "last_observation", "=", "random_shift", "(", "\n", "imgs", "=", "last_observation", ",", "\n", "pad", "=", "self", ".", "random_shift_pad", ",", "\n", "prob", "=", "self", ".", "random_shift_prob", ",", "\n", ")", "\n", "\n", "", "action", "=", "samples", ".", "action", "# [T,B,A]", "\n", "# if self.onehot_actions:", "\n", "#     action = to_onehot(action, self._act_dim, dtype=torch.float)", "\n", "observation", ",", "last_observation", ",", "action", "=", "buffer_to", "(", "\n", "(", "observation", ",", "last_observation", ",", "action", ")", ",", "\n", "device", "=", "self", ".", "device", ")", "\n", "\n", "_", ",", "conv_obs", "=", "self", ".", "encoder", "(", "observation", ")", "\n", "_", ",", "conv_last", "=", "self", ".", "encoder", "(", "last_observation", ")", "\n", "\n", "valid", "=", "valid_from_done", "(", "samples", ".", "done", ")", ".", "type", "(", "torch", ".", "bool", ")", "# [T,B]", "\n", "# All timesteps invalid if the last_observation is:", "\n", "valid", "=", "valid", "[", "-", "1", "]", ".", "repeat", "(", "self", ".", "delta_T", ",", "1", ")", ".", "transpose", "(", "1", ",", "0", ")", "# [B,T-1]", "\n", "\n", "if", "self", ".", "onehot_actions", ":", "\n", "            ", "logits", "=", "self", ".", "inverse_model", "(", "conv_obs", ",", "conv_last", ")", "# [B,T-1,A]", "\n", "labels", "=", "action", "[", ":", "-", "1", "]", ".", "transpose", "(", "1", ",", "0", ")", "# [B,T-1], not the last action", "\n", "labels", "[", "~", "valid", "]", "=", "IGNORE_INDEX", "\n", "\n", "b", ",", "t", ",", "a", "=", "logits", ".", "shape", "\n", "logits", "=", "logits", ".", "view", "(", "b", "*", "t", ",", "a", ")", "\n", "labels", "=", "labels", ".", "reshape", "(", "b", "*", "t", ")", "\n", "logits", "=", "logits", "-", "torch", ".", "max", "(", "logits", ",", "dim", "=", "1", ",", "keepdim", "=", "True", ")", "[", "0", "]", "\n", "inv_loss", "=", "self", ".", "c_e_loss", "(", "logits", ",", "labels", ")", "\n", "\n", "valid", "=", "valid", ".", "reshape", "(", "b", "*", "t", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "dist_info", "=", "DistInfo", "(", "prob", "=", "F", ".", "softmax", "(", "logits", ",", "dim", "=", "1", ")", ")", "\n", "entropy", "=", "self", ".", "distribution", ".", "mean_entropy", "(", "\n", "dist_info", "=", "dist_info", ",", "\n", "valid", "=", "valid", ",", "\n", ")", "\n", "entropy_loss", "=", "-", "self", ".", "entropy_loss_coeff", "*", "entropy", "\n", "\n", "correct", "=", "torch", ".", "argmax", "(", "logits", ".", "detach", "(", ")", ",", "dim", "=", "1", ")", "==", "labels", "\n", "accuracy", "=", "torch", ".", "mean", "(", "correct", "[", "valid", "]", ".", "float", "(", ")", ")", "\n", "\n", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "\n", "\n", "", "perplexity", "=", "self", ".", "distribution", ".", "mean_perplexity", "(", "dist_info", ",", "\n", "valid", ".", "to", "(", "self", ".", "device", ")", ")", "\n", "\n", "return", "inv_loss", ",", "entropy_loss", ",", "accuracy", ",", "perplexity", ",", "conv_obs", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.inverse.Inverse.validation": [[185, 203], ["rlpyt.utils.logging.logger.log", "ValInfo", "inverse.Inverse.optimizer.zero_grad", "range", "inverse.Inverse.optimizer.zero_grad", "rlpyt.utils.logging.logger.log", "inverse.Inverse.replay_buffer.sample_batch", "ValInfo.invLoss.append", "ValInfo.entLoss.append", "ValInfo.accuracy.append", "ValInfo.perplexity.append", "ValInfo.convActivation.append", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "inverse.Inverse.inverse_loss", "inv_loss.item", "ent_loss.item", "accuracy.item", "perplexity.item", "conv_output[].detach().cpu().view().numpy", "range", "conv_output[].detach().cpu().view", "len", "conv_output[].detach().cpu", "conv_output[].detach"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.logging.console.log", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.console.log", "home.repos.pwc.inspect_result.astooke_rlpyt.sequence.uniform.UniformSequenceReplay.sample_batch", "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.inverse.Inverse.inverse_loss"], ["", "def", "validation", "(", "self", ",", "itr", ")", ":", "\n", "        ", "logger", ".", "log", "(", "\"Computing validation loss...\"", ")", "\n", "val_info", "=", "ValInfo", "(", "*", "(", "[", "]", "for", "_", "in", "range", "(", "len", "(", "ValInfo", ".", "_fields", ")", ")", ")", ")", "\n", "self", ".", "optimizer", ".", "zero_grad", "(", ")", "\n", "for", "_", "in", "range", "(", "self", ".", "n_validation_batches", ")", ":", "\n", "            ", "samples", "=", "self", ".", "replay_buffer", ".", "sample_batch", "(", "self", ".", "batch_size", ",", "\n", "validation", "=", "True", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "inv_loss", ",", "ent_loss", ",", "accuracy", ",", "perplexity", ",", "conv_output", "=", "self", ".", "inverse_loss", "(", "samples", ")", "\n", "", "val_info", ".", "invLoss", ".", "append", "(", "inv_loss", ".", "item", "(", ")", ")", "\n", "val_info", ".", "entLoss", ".", "append", "(", "ent_loss", ".", "item", "(", ")", ")", "\n", "val_info", ".", "accuracy", ".", "append", "(", "accuracy", ".", "item", "(", ")", ")", "\n", "val_info", ".", "perplexity", ".", "append", "(", "perplexity", ".", "item", "(", ")", ")", "\n", "val_info", ".", "convActivation", ".", "append", "(", "\n", "conv_output", "[", "0", "]", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "view", "(", "-", "1", ")", ".", "numpy", "(", ")", ")", "# Keep 1 full one.", "\n", "", "self", ".", "optimizer", ".", "zero_grad", "(", ")", "\n", "logger", ".", "log", "(", "\"...validation loss completed.\"", ")", "\n", "return", "val_info", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.inverse.Inverse.state_dict": [[204, 209], ["dict", "inverse.Inverse.encoder.state_dict", "inverse.Inverse.inverse_model.state_dict", "inverse.Inverse.optimizer.state_dict"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.replay_saver.DummyOptimizer.state_dict", "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.replay_saver.DummyOptimizer.state_dict", "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.replay_saver.DummyOptimizer.state_dict"], ["", "def", "state_dict", "(", "self", ")", ":", "\n", "        ", "return", "dict", "(", "\n", "encoder", "=", "self", ".", "encoder", ".", "state_dict", "(", ")", ",", "\n", "inverse", "=", "self", ".", "inverse_model", ".", "state_dict", "(", ")", ",", "\n", "optimizer", "=", "self", ".", "optimizer", ".", "state_dict", "(", ")", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.inverse.Inverse.load_state_dict": [[211, 215], ["inverse.Inverse.encoder.load_state_dict", "inverse.Inverse.inverse_model.load_state_dict", "inverse.Inverse.optimizer.load_state_dict"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.augmented_temporal_similarity.AugmentedTemporalSimilarity.load_state_dict", "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.augmented_temporal_similarity.AugmentedTemporalSimilarity.load_state_dict", "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.augmented_temporal_similarity.AugmentedTemporalSimilarity.load_state_dict"], ["", "def", "load_state_dict", "(", "self", ",", "state_dict", ")", ":", "\n", "        ", "self", ".", "encoder", ".", "load_state_dict", "(", "state_dict", "[", "\"encoder\"", "]", ")", "\n", "self", ".", "inverse_model", ".", "load_state_dict", "(", "state_dict", "[", "\"inverse\"", "]", ")", "\n", "self", ".", "optimizer", ".", "load_state_dict", "(", "state_dict", "[", "\"optimizer\"", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.inverse.Inverse.parameters": [[216, 219], ["inverse.Inverse.encoder.parameters", "inverse.Inverse.inverse_model.parameters"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.rl.atari_rl_models.AtariDqnModel.parameters", "home.repos.pwc.inspect_result.astooke_rlpyt.rl.atari_rl_models.AtariDqnModel.parameters"], ["", "def", "parameters", "(", "self", ")", ":", "\n", "        ", "yield", "from", "self", ".", "encoder", ".", "parameters", "(", ")", "\n", "yield", "from", "self", ".", "inverse_model", ".", "parameters", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.inverse.Inverse.named_parameters": [[220, 224], ["inverse.Inverse.encoder.named_parameters", "inverse.Inverse.inverse_model.named_parameters"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.rl.atari_rl_models.AtariDqnModel.named_parameters", "home.repos.pwc.inspect_result.astooke_rlpyt.rl.atari_rl_models.AtariDqnModel.named_parameters"], ["", "def", "named_parameters", "(", "self", ")", ":", "\n", "        ", "\"\"\"To allow filtering by name in weight decay.\"\"\"", "\n", "yield", "from", "self", ".", "encoder", ".", "named_parameters", "(", ")", "\n", "yield", "from", "self", ".", "inverse_model", ".", "named_parameters", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.inverse.Inverse.eval": [[225, 228], ["inverse.Inverse.encoder.eval", "inverse.Inverse.inverse_model.eval"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.augmented_temporal_similarity.AugmentedTemporalSimilarity.eval", "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.augmented_temporal_similarity.AugmentedTemporalSimilarity.eval"], ["", "def", "eval", "(", "self", ")", ":", "\n", "        ", "self", ".", "encoder", ".", "eval", "(", ")", "# in case of batch norm", "\n", "self", ".", "inverse_model", ".", "eval", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.inverse.Inverse.train": [[229, 232], ["inverse.Inverse.encoder.train", "inverse.Inverse.inverse_model.train"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.runners.minibatch_rl.MinibatchRlEval.train", "home.repos.pwc.inspect_result.astooke_rlpyt.runners.minibatch_rl.MinibatchRlEval.train"], ["", "def", "train", "(", "self", ")", ":", "\n", "        ", "self", ".", "encoder", ".", "train", "(", ")", "\n", "self", ".", "inverse_model", ".", "train", "(", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.augmented_temporal_contrast.AugmentedTemporalContrast.__init__": [[31, 64], ["rlpyt.utils.quick_args.save__init__args", "torch.nn.CrossEntropyLoss", "dict", "locals"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.utils.quick_args.save__init__args"], ["def", "__init__", "(", "\n", "self", ",", "\n", "replay_filepath", ",", "\n", "ReplayCls", "=", "UlForRlReplayBuffer", ",", "\n", "delta_T", "=", "1", ",", "\n", "batch_T", "=", "1", ",", "\n", "batch_B", "=", "512", ",", "\n", "learning_rate", "=", "1e-3", ",", "\n", "learning_rate_anneal", "=", "None", ",", "# cosine", "\n", "learning_rate_warmup", "=", "0", ",", "# number of updates", "\n", "OptimCls", "=", "torch", ".", "optim", ".", "Adam", ",", "\n", "optim_kwargs", "=", "None", ",", "\n", "clip_grad_norm", "=", "10.", ",", "\n", "target_update_tau", "=", "0.01", ",", "# 1 for hard update", "\n", "target_update_interval", "=", "1", ",", "\n", "EncoderCls", "=", "EncoderModel", ",", "\n", "ContrastCls", "=", "ContrastModel", ",", "\n", "encoder_kwargs", "=", "None", ",", "\n", "latent_size", "=", "256", ",", "\n", "anchor_hidden_sizes", "=", "512", ",", "\n", "initial_state_dict", "=", "None", ",", "\n", "random_shift_prob", "=", "1.", ",", "\n", "random_shift_pad", "=", "4", ",", "\n", "activation_loss_coefficient", "=", "0.", ",", "# rarely if ever use", "\n", "validation_split", "=", "0.0", ",", "\n", "n_validation_batches", "=", "0", ",", "# usually don't do it.", "\n", ")", ":", "\n", "        ", "encoder_kwargs", "=", "dict", "(", ")", "if", "encoder_kwargs", "is", "None", "else", "encoder_kwargs", "\n", "save__init__args", "(", "locals", "(", ")", ")", "\n", "self", ".", "c_e_loss", "=", "torch", ".", "nn", ".", "CrossEntropyLoss", "(", "ignore_index", "=", "IGNORE_INDEX", ")", "\n", "assert", "learning_rate_anneal", "in", "[", "None", ",", "\"cosine\"", "]", "\n", "self", ".", "batch_size", "=", "batch_B", "*", "batch_T", "# for logging only", "\n", "self", ".", "_replay_T", "=", "delta_T", "+", "batch_T", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.augmented_temporal_contrast.AugmentedTemporalContrast.initialize": [[65, 90], ["augmented_temporal_contrast.AugmentedTemporalContrast.load_replay", "augmented_temporal_contrast.AugmentedTemporalContrast.EncoderCls", "copy.deepcopy", "augmented_temporal_contrast.AugmentedTemporalContrast.ContrastCls", "augmented_temporal_contrast.AugmentedTemporalContrast.encoder.to", "augmented_temporal_contrast.AugmentedTemporalContrast.target_encoder.to", "augmented_temporal_contrast.AugmentedTemporalContrast.contrast.to", "augmented_temporal_contrast.AugmentedTemporalContrast.optim_initialize", "torch.device", "torch.device", "augmented_temporal_contrast.AugmentedTemporalContrast.load_state_dict"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.pixel_control.PixelControl.load_replay", "home.repos.pwc.inspect_result.astooke_rlpyt.rl_with_ul.sac_with_ul.SacWithUl.optim_initialize", "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.augmented_temporal_similarity.AugmentedTemporalSimilarity.load_state_dict"], ["", "def", "initialize", "(", "self", ",", "n_updates", ",", "cuda_idx", "=", "None", ")", ":", "\n", "        ", "self", ".", "device", "=", "torch", ".", "device", "(", "\"cpu\"", ")", "if", "cuda_idx", "is", "None", "else", "torch", ".", "device", "(", "\n", "\"cuda\"", ",", "index", "=", "cuda_idx", ")", "\n", "\n", "examples", "=", "self", ".", "load_replay", "(", ")", "\n", "self", ".", "image_shape", "=", "image_shape", "=", "examples", ".", "observation", ".", "shape", "\n", "\n", "self", ".", "encoder", "=", "self", ".", "EncoderCls", "(", "\n", "image_shape", "=", "image_shape", ",", "\n", "latent_size", "=", "self", ".", "latent_size", ",", "\n", "**", "self", ".", "encoder_kwargs", "\n", ")", "\n", "self", ".", "target_encoder", "=", "copy", ".", "deepcopy", "(", "self", ".", "encoder", ")", "\n", "self", ".", "contrast", "=", "self", ".", "ContrastCls", "(", "\n", "latent_size", "=", "self", ".", "latent_size", ",", "\n", "anchor_hidden_sizes", "=", "self", ".", "anchor_hidden_sizes", ",", "\n", ")", "\n", "self", ".", "encoder", ".", "to", "(", "self", ".", "device", ")", "\n", "self", ".", "target_encoder", ".", "to", "(", "self", ".", "device", ")", "\n", "self", ".", "contrast", ".", "to", "(", "self", ".", "device", ")", "\n", "\n", "self", ".", "optim_initialize", "(", "n_updates", ")", "\n", "\n", "if", "self", ".", "initial_state_dict", "is", "not", "None", ":", "\n", "            ", "self", ".", "load_state_dict", "(", "self", ".", "initial_state_dict", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.augmented_temporal_contrast.AugmentedTemporalContrast.optimize": [[91, 117], ["OptInfo", "augmented_temporal_contrast.AugmentedTemporalContrast.replay_buffer.sample_batch", "augmented_temporal_contrast.AugmentedTemporalContrast.optimizer.zero_grad", "augmented_temporal_contrast.AugmentedTemporalContrast.atc_loss", "augmented_temporal_contrast.AugmentedTemporalContrast.activation_loss", "loss.backward", "augmented_temporal_contrast.AugmentedTemporalContrast.optimizer.step", "OptInfo.atcLoss.append", "OptInfo.accuracy.append", "OptInfo.activationLoss.append", "OptInfo.gradNorm.append", "OptInfo.convActivation.append", "augmented_temporal_contrast.AugmentedTemporalContrast.lr_scheduler.step", "torch.nn.utils.clip_grad_norm_", "atc_loss.item", "accuracy.item", "augmented_temporal_contrast.AugmentedTemporalContrast.item", "torch.nn.utils.clip_grad_norm_.item", "conv_output[].detach().cpu().view().numpy", "rlpyt.models.utils.update_state_dict", "augmented_temporal_contrast.AugmentedTemporalContrast.parameters", "augmented_temporal_contrast.AugmentedTemporalContrast.encoder.state_dict", "conv_output[].detach().cpu().view", "range", "len", "conv_output[].detach().cpu", "conv_output[].detach"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.sequence.uniform.UniformSequenceReplay.sample_batch", "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.augmented_temporal_contrast.AugmentedTemporalContrast.atc_loss", "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.base.BaseUlAlgorithm.activation_loss", "home.repos.pwc.inspect_result.astooke_rlpyt.models.utils.ScaleGrad.backward", "home.repos.pwc.inspect_result.astooke_rlpyt.safe.safety_gym_env.SafetyGymTrajInfo.step", "home.repos.pwc.inspect_result.astooke_rlpyt.safe.safety_gym_env.SafetyGymTrajInfo.step", "home.repos.pwc.inspect_result.astooke_rlpyt.models.utils.update_state_dict", "home.repos.pwc.inspect_result.astooke_rlpyt.rl.atari_rl_models.AtariDqnModel.parameters", "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.replay_saver.DummyOptimizer.state_dict"], ["", "", "def", "optimize", "(", "self", ",", "itr", ")", ":", "\n", "        ", "opt_info", "=", "OptInfo", "(", "*", "(", "[", "]", "for", "_", "in", "range", "(", "len", "(", "OptInfo", ".", "_fields", ")", ")", ")", ")", "\n", "samples", "=", "self", ".", "replay_buffer", ".", "sample_batch", "(", "self", ".", "batch_B", ")", "\n", "if", "self", ".", "lr_scheduler", "is", "not", "None", ":", "\n", "            ", "self", ".", "lr_scheduler", ".", "step", "(", "itr", ")", "# Do every itr instead of every epoch", "\n", "", "self", ".", "optimizer", ".", "zero_grad", "(", ")", "\n", "atc_loss", ",", "accuracy", ",", "conv_output", "=", "self", ".", "atc_loss", "(", "samples", ")", "\n", "act_loss", "=", "self", ".", "activation_loss", "(", "conv_output", ")", "\n", "loss", "=", "atc_loss", "+", "act_loss", "\n", "loss", ".", "backward", "(", ")", "\n", "if", "self", ".", "clip_grad_norm", "is", "None", ":", "\n", "            ", "grad_norm", "=", "0.", "\n", "", "else", ":", "\n", "            ", "grad_norm", "=", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "\n", "self", ".", "parameters", "(", ")", ",", "self", ".", "clip_grad_norm", ")", "\n", "", "self", ".", "optimizer", ".", "step", "(", ")", "\n", "opt_info", ".", "atcLoss", ".", "append", "(", "atc_loss", ".", "item", "(", ")", ")", "\n", "opt_info", ".", "accuracy", ".", "append", "(", "accuracy", ".", "item", "(", ")", ")", "\n", "opt_info", ".", "activationLoss", ".", "append", "(", "act_loss", ".", "item", "(", ")", ")", "\n", "opt_info", ".", "gradNorm", ".", "append", "(", "grad_norm", ".", "item", "(", ")", ")", "\n", "opt_info", ".", "convActivation", ".", "append", "(", "\n", "conv_output", "[", "0", "]", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "view", "(", "-", "1", ")", ".", "numpy", "(", ")", ")", "# Keep 1 full one.", "\n", "if", "itr", "%", "self", ".", "target_update_interval", "==", "0", ":", "\n", "            ", "update_state_dict", "(", "self", ".", "target_encoder", ",", "self", ".", "encoder", ".", "state_dict", "(", ")", ",", "\n", "self", ".", "target_update_tau", ")", "\n", "", "return", "opt_info", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.augmented_temporal_contrast.AugmentedTemporalContrast.atc_loss": [[118, 157], ["rlpyt.ul.algos.utils.data_augs.random_shift.view", "rlpyt.ul.algos.utils.data_augs.random_shift.view", "rlpyt.utils.buffer.buffer_to", "augmented_temporal_contrast.AugmentedTemporalContrast.encoder", "augmented_temporal_contrast.AugmentedTemporalContrast.contrast", "torch.arange", "rlpyt.algos.utils.valid_from_done().type", "valid[].reshape", "augmented_temporal_contrast.AugmentedTemporalContrast.c_e_loss", "torch.mean", "rlpyt.ul.algos.utils.data_augs.random_shift", "rlpyt.ul.algos.utils.data_augs.random_shift", "torch.no_grad", "augmented_temporal_contrast.AugmentedTemporalContrast.target_encoder", "torch.argmax", "correct[].float", "rlpyt.algos.utils.valid_from_done", "augmented_temporal_contrast.AugmentedTemporalContrast.detach"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.utils.buffer.buffer_to", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.data_augs.random_shift", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.data_augs.random_shift", "home.repos.pwc.inspect_result.astooke_rlpyt.algos.utils.valid_from_done"], ["", "def", "atc_loss", "(", "self", ",", "samples", ")", ":", "\n", "        ", "anchor", "=", "(", "samples", ".", "observation", "if", "self", ".", "delta_T", "==", "0", "else", "\n", "samples", ".", "observation", "[", ":", "-", "self", ".", "delta_T", "]", ")", "\n", "positive", "=", "samples", ".", "observation", "[", "self", ".", "delta_T", ":", "]", "\n", "t", ",", "b", ",", "c", ",", "h", ",", "w", "=", "anchor", ".", "shape", "\n", "anchor", "=", "anchor", ".", "view", "(", "t", "*", "b", ",", "c", ",", "h", ",", "w", ")", "# Treat all T,B as separate.", "\n", "positive", "=", "positive", ".", "view", "(", "t", "*", "b", ",", "c", ",", "h", ",", "w", ")", "\n", "\n", "if", "self", ".", "random_shift_prob", ">", "0.", ":", "\n", "            ", "anchor", "=", "random_shift", "(", "\n", "imgs", "=", "anchor", ",", "\n", "pad", "=", "self", ".", "random_shift_pad", ",", "\n", "prob", "=", "self", ".", "random_shift_prob", ",", "\n", ")", "\n", "positive", "=", "random_shift", "(", "\n", "imgs", "=", "positive", ",", "\n", "pad", "=", "self", ".", "random_shift_pad", ",", "\n", "prob", "=", "self", ".", "random_shift_prob", ",", "\n", ")", "\n", "\n", "", "anchor", ",", "positive", "=", "buffer_to", "(", "(", "anchor", ",", "positive", ")", ",", "\n", "device", "=", "self", ".", "device", ")", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "c_positive", ",", "_", "=", "self", ".", "target_encoder", "(", "positive", ")", "\n", "", "c_anchor", ",", "conv_output", "=", "self", ".", "encoder", "(", "anchor", ")", "\n", "\n", "logits", "=", "self", ".", "contrast", "(", "anchor", "=", "c_anchor", ",", "positive", "=", "c_positive", ")", "\n", "labels", "=", "torch", ".", "arange", "(", "c_anchor", ".", "shape", "[", "0", "]", ",", "\n", "dtype", "=", "torch", ".", "long", ",", "device", "=", "self", ".", "device", ")", "\n", "valid", "=", "valid_from_done", "(", "samples", ".", "done", ")", ".", "type", "(", "torch", ".", "bool", ")", "\n", "valid", "=", "valid", "[", "self", ".", "delta_T", ":", "]", ".", "reshape", "(", "-", "1", ")", "# at location of positive", "\n", "labels", "[", "~", "valid", "]", "=", "IGNORE_INDEX", "\n", "atc_loss", "=", "self", ".", "c_e_loss", "(", "logits", ",", "labels", ")", "\n", "\n", "correct", "=", "torch", ".", "argmax", "(", "logits", ".", "detach", "(", ")", ",", "dim", "=", "1", ")", "==", "labels", "\n", "accuracy", "=", "torch", ".", "mean", "(", "correct", "[", "valid", "]", ".", "float", "(", ")", ")", "\n", "\n", "return", "atc_loss", ",", "accuracy", ",", "conv_output", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.augmented_temporal_contrast.AugmentedTemporalContrast.validation": [[158, 174], ["rlpyt.utils.logging.logger.log", "ValInfo", "augmented_temporal_contrast.AugmentedTemporalContrast.optimizer.zero_grad", "range", "augmented_temporal_contrast.AugmentedTemporalContrast.optimizer.zero_grad", "rlpyt.utils.logging.logger.log", "augmented_temporal_contrast.AugmentedTemporalContrast.replay_buffer.sample_batch", "ValInfo.atcLoss.append", "ValInfo.accuracy.append", "ValInfo.convActivation.append", "torch.no_grad", "augmented_temporal_contrast.AugmentedTemporalContrast.atc_loss", "atc_loss.item", "accuracy.item", "conv_output[].detach().cpu().view().numpy", "range", "conv_output[].detach().cpu().view", "len", "conv_output[].detach().cpu", "conv_output[].detach"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.logging.console.log", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.console.log", "home.repos.pwc.inspect_result.astooke_rlpyt.sequence.uniform.UniformSequenceReplay.sample_batch", "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.augmented_temporal_contrast.AugmentedTemporalContrast.atc_loss"], ["", "def", "validation", "(", "self", ",", "itr", ")", ":", "\n", "        ", "logger", ".", "log", "(", "\"Computing validation loss...\"", ")", "\n", "val_info", "=", "ValInfo", "(", "*", "(", "[", "]", "for", "_", "in", "range", "(", "len", "(", "ValInfo", ".", "_fields", ")", ")", ")", ")", "\n", "self", ".", "optimizer", ".", "zero_grad", "(", ")", "\n", "for", "_", "in", "range", "(", "self", ".", "n_validation_batches", ")", ":", "\n", "            ", "samples", "=", "self", ".", "replay_buffer", ".", "sample_batch", "(", "self", ".", "batch_B", ",", "\n", "validation", "=", "True", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "atc_loss", ",", "accuracy", ",", "conv_output", "=", "self", ".", "atc_loss", "(", "samples", ")", "\n", "", "val_info", ".", "atcLoss", ".", "append", "(", "atc_loss", ".", "item", "(", ")", ")", "\n", "val_info", ".", "accuracy", ".", "append", "(", "accuracy", ".", "item", "(", ")", ")", "\n", "val_info", ".", "convActivation", ".", "append", "(", "\n", "conv_output", "[", "0", "]", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "view", "(", "-", "1", ")", ".", "numpy", "(", ")", ")", "\n", "", "self", ".", "optimizer", ".", "zero_grad", "(", ")", "\n", "logger", ".", "log", "(", "\"...validation loss completed.\"", ")", "\n", "return", "val_info", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.augmented_temporal_contrast.AugmentedTemporalContrast.state_dict": [[175, 181], ["dict", "augmented_temporal_contrast.AugmentedTemporalContrast.encoder.state_dict", "augmented_temporal_contrast.AugmentedTemporalContrast.target_encoder.state_dict", "augmented_temporal_contrast.AugmentedTemporalContrast.contrast.state_dict", "augmented_temporal_contrast.AugmentedTemporalContrast.optimizer.state_dict"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.replay_saver.DummyOptimizer.state_dict", "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.replay_saver.DummyOptimizer.state_dict", "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.replay_saver.DummyOptimizer.state_dict", "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.replay_saver.DummyOptimizer.state_dict"], ["", "def", "state_dict", "(", "self", ")", ":", "\n", "        ", "return", "dict", "(", "\n", "encoder", "=", "self", ".", "encoder", ".", "state_dict", "(", ")", ",", "\n", "target_encoder", "=", "self", ".", "target_encoder", ".", "state_dict", "(", ")", ",", "\n", "contrast", "=", "self", ".", "contrast", ".", "state_dict", "(", ")", ",", "\n", "optimizer", "=", "self", ".", "optimizer", ".", "state_dict", "(", ")", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.augmented_temporal_contrast.AugmentedTemporalContrast.load_state_dict": [[183, 188], ["augmented_temporal_contrast.AugmentedTemporalContrast.encoder.load_state_dict", "augmented_temporal_contrast.AugmentedTemporalContrast.target_encoder.load_state_dict", "augmented_temporal_contrast.AugmentedTemporalContrast.contrast.load_state_dict", "augmented_temporal_contrast.AugmentedTemporalContrast.optimizer.load_state_dict"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.augmented_temporal_similarity.AugmentedTemporalSimilarity.load_state_dict", "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.augmented_temporal_similarity.AugmentedTemporalSimilarity.load_state_dict", "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.augmented_temporal_similarity.AugmentedTemporalSimilarity.load_state_dict", "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.augmented_temporal_similarity.AugmentedTemporalSimilarity.load_state_dict"], ["", "def", "load_state_dict", "(", "self", ",", "state_dict", ")", ":", "\n", "        ", "self", ".", "encoder", ".", "load_state_dict", "(", "state_dict", "[", "\"encoder\"", "]", ")", "\n", "self", ".", "target_encoder", ".", "load_state_dict", "(", "state_dict", "[", "\"target_encoder\"", "]", ")", "\n", "self", ".", "contrast", ".", "load_state_dict", "(", "state_dict", "[", "\"contrast\"", "]", ")", "\n", "self", ".", "optimizer", ".", "load_state_dict", "(", "state_dict", "[", "\"optimizer\"", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.augmented_temporal_contrast.AugmentedTemporalContrast.parameters": [[189, 192], ["augmented_temporal_contrast.AugmentedTemporalContrast.encoder.parameters", "augmented_temporal_contrast.AugmentedTemporalContrast.contrast.parameters"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.rl.atari_rl_models.AtariDqnModel.parameters", "home.repos.pwc.inspect_result.astooke_rlpyt.rl.atari_rl_models.AtariDqnModel.parameters"], ["", "def", "parameters", "(", "self", ")", ":", "\n", "        ", "yield", "from", "self", ".", "encoder", ".", "parameters", "(", ")", "\n", "yield", "from", "self", ".", "contrast", ".", "parameters", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.augmented_temporal_contrast.AugmentedTemporalContrast.named_parameters": [[193, 197], ["augmented_temporal_contrast.AugmentedTemporalContrast.encoder.named_parameters", "augmented_temporal_contrast.AugmentedTemporalContrast.contrast.named_parameters"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.rl.atari_rl_models.AtariDqnModel.named_parameters", "home.repos.pwc.inspect_result.astooke_rlpyt.rl.atari_rl_models.AtariDqnModel.named_parameters"], ["", "def", "named_parameters", "(", "self", ")", ":", "\n", "        ", "\"\"\"To allow filtering by name in weight decay.\"\"\"", "\n", "yield", "from", "self", ".", "encoder", ".", "named_parameters", "(", ")", "\n", "yield", "from", "self", ".", "contrast", ".", "named_parameters", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.augmented_temporal_contrast.AugmentedTemporalContrast.eval": [[198, 201], ["augmented_temporal_contrast.AugmentedTemporalContrast.encoder.eval", "augmented_temporal_contrast.AugmentedTemporalContrast.contrast.eval"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.augmented_temporal_similarity.AugmentedTemporalSimilarity.eval", "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.augmented_temporal_similarity.AugmentedTemporalSimilarity.eval"], ["", "def", "eval", "(", "self", ")", ":", "\n", "        ", "self", ".", "encoder", ".", "eval", "(", ")", "# in case of batch norm", "\n", "self", ".", "contrast", ".", "eval", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.augmented_temporal_contrast.AugmentedTemporalContrast.train": [[202, 205], ["augmented_temporal_contrast.AugmentedTemporalContrast.encoder.train", "augmented_temporal_contrast.AugmentedTemporalContrast.contrast.train"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.runners.minibatch_rl.MinibatchRlEval.train", "home.repos.pwc.inspect_result.astooke_rlpyt.runners.minibatch_rl.MinibatchRlEval.train"], ["", "def", "train", "(", "self", ")", ":", "\n", "        ", "self", ".", "encoder", ".", "train", "(", ")", "\n", "self", ".", "contrast", ".", "train", "(", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.vae.VAE.__init__": [[34, 67], ["rlpyt.utils.quick_args.save__init__args", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "dict", "dict", "dict", "locals"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.utils.quick_args.save__init__args"], ["def", "__init__", "(", "\n", "self", ",", "\n", "batch_size", ",", "\n", "learning_rate", ",", "\n", "replay_filepath", ",", "\n", "delta_T", "=", "0", ",", "\n", "OptimCls", "=", "torch", ".", "optim", ".", "Adam", ",", "\n", "optim_kwargs", "=", "None", ",", "\n", "initial_state_dict", "=", "None", ",", "\n", "clip_grad_norm", "=", "1000.", ",", "\n", "EncoderCls", "=", "EncoderModel", ",", "\n", "encoder_kwargs", "=", "None", ",", "\n", "latent_size", "=", "128", ",", "\n", "ReplayCls", "=", "UlForRlReplayBuffer", ",", "\n", "activation_loss_coefficient", "=", "0.0", ",", "\n", "learning_rate_anneal", "=", "None", ",", "# cosine", "\n", "learning_rate_warmup", "=", "0", ",", "# number of updates", "\n", "VaeHeadCls", "=", "VaeHeadModel", ",", "\n", "hidden_sizes", "=", "None", ",", "# But maybe use for forward prediction", "\n", "DecoderCls", "=", "VaeDecoderModel", ",", "\n", "decoder_kwargs", "=", "None", ",", "\n", "kl_coeff", "=", "1.", ",", "\n", "onehot_action", "=", "True", ",", "\n", "validation_split", "=", "0.0", ",", "\n", "n_validation_batches", "=", "0", ",", "\n", ")", ":", "\n", "        ", "optim_kwargs", "=", "dict", "(", ")", "if", "optim_kwargs", "is", "None", "else", "optim_kwargs", "\n", "encoder_kwargs", "=", "dict", "(", ")", "if", "encoder_kwargs", "is", "None", "else", "encoder_kwargs", "\n", "decoder_kwargs", "=", "dict", "(", ")", "if", "decoder_kwargs", "is", "None", "else", "decoder_kwargs", "\n", "save__init__args", "(", "locals", "(", ")", ")", "\n", "self", ".", "c_e_loss", "=", "torch", ".", "nn", ".", "CrossEntropyLoss", "(", "ignore_index", "=", "IGNORE_INDEX", ")", "\n", "assert", "learning_rate_anneal", "in", "[", "None", ",", "\"cosine\"", "]", "\n", "self", ".", "_replay_T", "=", "delta_T", "+", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.vae.VAE.initialize": [[68, 102], ["vae.VAE.load_replay", "vae.VAE.EncoderCls", "vae.VAE.VaeHeadCls", "vae.VAE.DecoderCls", "vae.VAE.encoder.to", "vae.VAE.vae_head.to", "vae.VAE.decoder.to", "vae.VAE.optim_initialize", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "rlpyt.distributions.categorical.Categorical", "vae.VAE.load_state_dict", "vae.VAE.replay_buffer.samples.action.max", "len"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.pixel_control.PixelControl.load_replay", "home.repos.pwc.inspect_result.astooke_rlpyt.rl_with_ul.sac_with_ul.SacWithUl.optim_initialize", "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.augmented_temporal_similarity.AugmentedTemporalSimilarity.load_state_dict"], ["", "def", "initialize", "(", "self", ",", "n_updates", ",", "cuda_idx", "=", "None", ")", ":", "\n", "        ", "self", ".", "device", "=", "torch", ".", "device", "(", "\"cpu\"", ")", "if", "cuda_idx", "is", "None", "else", "torch", ".", "device", "(", "\n", "\"cuda\"", ",", "index", "=", "cuda_idx", ")", "\n", "\n", "examples", "=", "self", ".", "load_replay", "(", ")", "\n", "self", ".", "encoder", "=", "self", ".", "EncoderCls", "(", "\n", "image_shape", "=", "examples", ".", "observation", ".", "shape", ",", "\n", "latent_size", "=", "self", ".", "latent_size", ",", "# UNUSED", "\n", "**", "self", ".", "encoder_kwargs", "\n", ")", "\n", "if", "self", ".", "onehot_action", ":", "\n", "            ", "act_dim", "=", "self", ".", "replay_buffer", ".", "samples", ".", "action", ".", "max", "(", ")", "+", "1", "# discrete only", "\n", "self", ".", "distribution", "=", "Categorical", "(", "act_dim", ")", "\n", "", "else", ":", "\n", "            ", "act_shape", "=", "self", ".", "replay_buffer", ".", "samples", ".", "action", ".", "shape", "[", "2", ":", "]", "\n", "assert", "len", "(", "act_shape", ")", "==", "1", "\n", "act_dim", "=", "act_shape", "[", "0", "]", "\n", "", "self", ".", "vae_head", "=", "self", ".", "VaeHeadCls", "(", "\n", "latent_size", "=", "self", ".", "latent_size", ",", "\n", "action_size", "=", "act_dim", "*", "self", ".", "delta_T", ",", "\n", "hidden_sizes", "=", "self", ".", "hidden_sizes", ",", "\n", ")", "\n", "self", ".", "decoder", "=", "self", ".", "DecoderCls", "(", "\n", "latent_size", "=", "self", ".", "latent_size", ",", "\n", "**", "self", ".", "decoder_kwargs", "\n", ")", "\n", "self", ".", "encoder", ".", "to", "(", "self", ".", "device", ")", "\n", "self", ".", "vae_head", ".", "to", "(", "self", ".", "device", ")", "\n", "self", ".", "decoder", ".", "to", "(", "self", ".", "device", ")", "\n", "\n", "self", ".", "optim_initialize", "(", "n_updates", ")", "\n", "\n", "if", "self", ".", "initial_state_dict", "is", "not", "None", ":", "\n", "            ", "self", ".", "load_state_dict", "(", "self", ".", "initial_state_dict", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.vae.VAE.optimize": [[103, 126], ["OptInfo", "vae.VAE.replay_buffer.sample_batch", "vae.VAE.optimizer.zero_grad", "vae.VAE.vae_loss", "vae.VAE.activation_loss", "loss.backward", "vae.VAE.optimizer.step", "OptInfo.reconLoss.append", "OptInfo.klLoss.append", "OptInfo.activationLoss.append", "OptInfo.gradNorm.append", "OptInfo.convActivation.append", "vae.VAE.lr_scheduler.step", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "recon_loss.item", "kl_loss.item", "vae.VAE.item", "torch.nn.utils.clip_grad_norm_.item", "torch.nn.utils.clip_grad_norm_.item", "conv_output[].detach().cpu().view().numpy", "vae.VAE.parameters", "conv_output[].detach().cpu().view", "range", "len", "conv_output[].detach().cpu", "conv_output[].detach"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.sequence.uniform.UniformSequenceReplay.sample_batch", "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.vae.VAE.vae_loss", "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.base.BaseUlAlgorithm.activation_loss", "home.repos.pwc.inspect_result.astooke_rlpyt.models.utils.ScaleGrad.backward", "home.repos.pwc.inspect_result.astooke_rlpyt.safe.safety_gym_env.SafetyGymTrajInfo.step", "home.repos.pwc.inspect_result.astooke_rlpyt.safe.safety_gym_env.SafetyGymTrajInfo.step", "home.repos.pwc.inspect_result.astooke_rlpyt.rl.atari_rl_models.AtariDqnModel.parameters"], ["", "", "def", "optimize", "(", "self", ",", "itr", ")", ":", "\n", "        ", "opt_info", "=", "OptInfo", "(", "*", "(", "[", "]", "for", "_", "in", "range", "(", "len", "(", "OptInfo", ".", "_fields", ")", ")", ")", ")", "\n", "samples", "=", "self", ".", "replay_buffer", ".", "sample_batch", "(", "self", ".", "batch_size", ")", "\n", "if", "self", ".", "lr_scheduler", "is", "not", "None", ":", "\n", "            ", "self", ".", "lr_scheduler", ".", "step", "(", "itr", ")", "# Do every itr instead of every epoch", "\n", "", "self", ".", "optimizer", ".", "zero_grad", "(", ")", "\n", "recon_loss", ",", "kl_loss", ",", "conv_output", "=", "self", ".", "vae_loss", "(", "samples", ")", "\n", "act_loss", "=", "self", ".", "activation_loss", "(", "conv_output", ")", "\n", "loss", "=", "recon_loss", "+", "kl_loss", "+", "act_loss", "\n", "loss", ".", "backward", "(", ")", "\n", "if", "self", ".", "clip_grad_norm", "is", "None", ":", "\n", "            ", "grad_norm", "=", "0.", "\n", "", "else", ":", "\n", "            ", "grad_norm", "=", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "\n", "self", ".", "parameters", "(", ")", ",", "self", ".", "clip_grad_norm", ")", "\n", "", "self", ".", "optimizer", ".", "step", "(", ")", "\n", "opt_info", ".", "reconLoss", ".", "append", "(", "recon_loss", ".", "item", "(", ")", ")", "\n", "opt_info", ".", "klLoss", ".", "append", "(", "kl_loss", ".", "item", "(", ")", ")", "\n", "opt_info", ".", "activationLoss", ".", "append", "(", "act_loss", ".", "item", "(", ")", ")", "\n", "opt_info", ".", "gradNorm", ".", "append", "(", "grad_norm", ".", "item", "(", ")", ")", "\n", "opt_info", ".", "convActivation", ".", "append", "(", "\n", "conv_output", "[", "0", "]", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "view", "(", "-", "1", ")", ".", "numpy", "(", ")", ")", "# Keep 1 full one.", "\n", "return", "opt_info", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.vae.VAE.vae_loss": [[127, 174], ["rlpyt.utils.buffer.buffer_to", "vae.VAE.encoder", "vae.VAE.vae_head", "vae.VAE.decoder", "torch.binary_cross_entropy", "torch.binary_cross_entropy", "recon_losses.mean.mean.view().sum", "recon_losses.mean.mean.mean", "rlpyt.utils.tensor.valid_mean", "kl_losses.sum.sum.sum", "vae.VAE.transpose", "vae.VAE.reshape", "target_observation.mul_.mul_.type", "target_observation.mul_.mul_.mul_", "rlpyt.algos.utils.valid_from_done().type", "valid.to.to.to", "logvar.exp", "rlpyt.utils.tensor.valid_mean", "vae.VAE.distribution.to_onehot", "vae.VAE.reshape", "target_observation.mul_.mul_.reshape", "recon_losses.mean.mean.view", "mu.pow", "rlpyt.algos.utils.valid_from_done"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.utils.buffer.buffer_to", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.tensor.valid_mean", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.tensor.valid_mean", "home.repos.pwc.inspect_result.astooke_rlpyt.distributions.discrete.DiscreteMixin.to_onehot", "home.repos.pwc.inspect_result.astooke_rlpyt.algos.utils.valid_from_done"], ["", "def", "vae_loss", "(", "self", ",", "samples", ")", ":", "\n", "        ", "observation", "=", "samples", ".", "observation", "[", "0", "]", "# [T,B,C,H,W]->[B,C,H,W]", "\n", "target_observation", "=", "samples", ".", "observation", "[", "self", ".", "delta_T", "]", "\n", "if", "self", ".", "delta_T", ">", "0", ":", "\n", "            ", "action", "=", "samples", ".", "action", "[", ":", "-", "1", "]", "# [T-1,B,A]  don't need the last one", "\n", "if", "self", ".", "onehot_action", ":", "\n", "                ", "action", "=", "self", ".", "distribution", ".", "to_onehot", "(", "action", ")", "\n", "", "t", ",", "b", "=", "action", ".", "shape", "[", ":", "2", "]", "\n", "action", "=", "action", ".", "transpose", "(", "1", ",", "0", ")", "# [B,T-1,A]", "\n", "action", "=", "action", ".", "reshape", "(", "b", ",", "-", "1", ")", "\n", "", "else", ":", "\n", "            ", "action", "=", "None", "\n", "", "observation", ",", "target_observation", ",", "action", "=", "buffer_to", "(", "\n", "(", "observation", ",", "target_observation", ",", "action", ")", ",", "\n", "device", "=", "self", ".", "device", "\n", ")", "\n", "\n", "h", ",", "conv_out", "=", "self", ".", "encoder", "(", "observation", ")", "\n", "z", ",", "mu", ",", "logvar", "=", "self", ".", "vae_head", "(", "h", ",", "action", ")", "\n", "recon_z", "=", "self", ".", "decoder", "(", "z", ")", "\n", "\n", "if", "target_observation", ".", "dtype", "==", "torch", ".", "uint8", ":", "\n", "            ", "target_observation", "=", "target_observation", ".", "type", "(", "torch", ".", "float", ")", "\n", "target_observation", "=", "target_observation", ".", "mul_", "(", "1", "/", "255.", ")", "\n", "\n", "", "b", ",", "c", ",", "h", ",", "w", "=", "target_observation", ".", "shape", "\n", "recon_losses", "=", "F", ".", "binary_cross_entropy", "(", "\n", "input", "=", "recon_z", ".", "reshape", "(", "b", "*", "c", ",", "h", ",", "w", ")", ",", "\n", "target", "=", "target_observation", ".", "reshape", "(", "b", "*", "c", ",", "h", ",", "w", ")", ",", "\n", "reduction", "=", "\"none\"", ",", "\n", ")", "\n", "if", "self", ".", "delta_T", ">", "0", ":", "\n", "            ", "valid", "=", "valid_from_done", "(", "samples", ".", "done", ")", ".", "type", "(", "torch", ".", "bool", ")", "# [T,B]", "\n", "valid", "=", "valid", "[", "-", "1", "]", "# [B]", "\n", "valid", "=", "valid", ".", "to", "(", "self", ".", "device", ")", "\n", "", "else", ":", "\n", "            ", "valid", "=", "None", "# all are valid", "\n", "", "recon_losses", "=", "recon_losses", ".", "view", "(", "b", ",", "c", ",", "h", ",", "w", ")", ".", "sum", "(", "dim", "=", "(", "2", ",", "3", ")", ")", "# sum over H,W", "\n", "recon_losses", "=", "recon_losses", ".", "mean", "(", "dim", "=", "1", ")", "# mean over C (o/w loss is HUGE)", "\n", "recon_loss", "=", "valid_mean", "(", "recon_losses", ",", "valid", "=", "valid", ")", "# mean over batch", "\n", "\n", "kl_losses", "=", "1", "+", "logvar", "-", "mu", ".", "pow", "(", "2", ")", "-", "logvar", ".", "exp", "(", ")", "\n", "kl_losses", "=", "kl_losses", ".", "sum", "(", "dim", "=", "-", "1", ")", "# sum over latent dimension", "\n", "kl_loss", "=", "-", "0.5", "*", "valid_mean", "(", "kl_losses", ",", "valid", "=", "valid", ")", "# mean over batch", "\n", "kl_loss", "=", "self", ".", "kl_coeff", "*", "kl_loss", "\n", "\n", "return", "recon_loss", ",", "kl_loss", ",", "conv_out", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.vae.VAE.validation": [[175, 191], ["rlpyt.utils.logging.logger.log", "ValInfo", "vae.VAE.optimizer.zero_grad", "range", "vae.VAE.optimizer.zero_grad", "rlpyt.utils.logging.logger.log", "vae.VAE.replay_buffer.sample_batch", "ValInfo.reconLoss.append", "ValInfo.klLoss.append", "ValInfo.convActivation.append", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "vae.VAE.vae_loss", "recon_loss.item", "kl_loss.item", "conv_output[].detach().cpu().view().numpy", "range", "conv_output[].detach().cpu().view", "len", "conv_output[].detach().cpu", "conv_output[].detach"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.logging.console.log", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.console.log", "home.repos.pwc.inspect_result.astooke_rlpyt.sequence.uniform.UniformSequenceReplay.sample_batch", "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.vae.VAE.vae_loss"], ["", "def", "validation", "(", "self", ",", "itr", ")", ":", "\n", "        ", "logger", ".", "log", "(", "\"Computing validation loss...\"", ")", "\n", "val_info", "=", "ValInfo", "(", "*", "(", "[", "]", "for", "_", "in", "range", "(", "len", "(", "ValInfo", ".", "_fields", ")", ")", ")", ")", "\n", "self", ".", "optimizer", ".", "zero_grad", "(", ")", "\n", "for", "_", "in", "range", "(", "self", ".", "n_validation_batches", ")", ":", "\n", "            ", "samples", "=", "self", ".", "replay_buffer", ".", "sample_batch", "(", "self", ".", "batch_size", ",", "\n", "validation", "=", "True", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "recon_loss", ",", "kl_loss", ",", "conv_output", "=", "self", ".", "vae_loss", "(", "samples", ")", "\n", "", "val_info", ".", "reconLoss", ".", "append", "(", "recon_loss", ".", "item", "(", ")", ")", "\n", "val_info", ".", "klLoss", ".", "append", "(", "kl_loss", ".", "item", "(", ")", ")", "\n", "val_info", ".", "convActivation", ".", "append", "(", "\n", "conv_output", "[", "0", "]", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "view", "(", "-", "1", ")", ".", "numpy", "(", ")", ")", "# Keep 1 full one.", "\n", "", "self", ".", "optimizer", ".", "zero_grad", "(", ")", "\n", "logger", ".", "log", "(", "\"...validation loss completed.\"", ")", "\n", "return", "val_info", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.vae.VAE.state_dict": [[192, 198], ["dict", "vae.VAE.encoder.state_dict", "vae.VAE.vae_head.state_dict", "vae.VAE.decoder.state_dict", "vae.VAE.optimizer.state_dict"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.replay_saver.DummyOptimizer.state_dict", "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.replay_saver.DummyOptimizer.state_dict", "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.replay_saver.DummyOptimizer.state_dict", "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.replay_saver.DummyOptimizer.state_dict"], ["", "def", "state_dict", "(", "self", ")", ":", "\n", "        ", "return", "dict", "(", "\n", "encoder", "=", "self", ".", "encoder", ".", "state_dict", "(", ")", ",", "\n", "vae_head", "=", "self", ".", "vae_head", ".", "state_dict", "(", ")", ",", "\n", "decoder", "=", "self", ".", "decoder", ".", "state_dict", "(", ")", ",", "\n", "optimizer", "=", "self", ".", "optimizer", ".", "state_dict", "(", ")", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.vae.VAE.load_state_dict": [[200, 205], ["vae.VAE.encoder.load_state_dict", "vae.VAE.vae_head.load_state_dict", "vae.VAE.decoder.load_state_dict", "vae.VAE.optimizer.load_state_dict"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.augmented_temporal_similarity.AugmentedTemporalSimilarity.load_state_dict", "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.augmented_temporal_similarity.AugmentedTemporalSimilarity.load_state_dict", "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.augmented_temporal_similarity.AugmentedTemporalSimilarity.load_state_dict", "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.augmented_temporal_similarity.AugmentedTemporalSimilarity.load_state_dict"], ["", "def", "load_state_dict", "(", "self", ",", "state_dict", ")", ":", "\n", "        ", "self", ".", "encoder", ".", "load_state_dict", "(", "state_dict", "[", "\"encoder\"", "]", ")", "\n", "self", ".", "vae_head", ".", "load_state_dict", "(", "state_dict", "[", "\"vae_head\"", "]", ")", "\n", "self", ".", "decoder", ".", "load_state_dict", "(", "state_dict", "[", "\"decoder\"", "]", ")", "\n", "self", ".", "optimizer", ".", "load_state_dict", "(", "state_dict", "[", "\"optimizer\"", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.vae.VAE.parameters": [[206, 210], ["vae.VAE.encoder.parameters", "vae.VAE.vae_head.parameters", "vae.VAE.decoder.parameters"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.rl.atari_rl_models.AtariDqnModel.parameters", "home.repos.pwc.inspect_result.astooke_rlpyt.rl.atari_rl_models.AtariDqnModel.parameters", "home.repos.pwc.inspect_result.astooke_rlpyt.rl.atari_rl_models.AtariDqnModel.parameters"], ["", "def", "parameters", "(", "self", ")", ":", "\n", "        ", "yield", "from", "self", ".", "encoder", ".", "parameters", "(", ")", "\n", "yield", "from", "self", ".", "vae_head", ".", "parameters", "(", ")", "\n", "yield", "from", "self", ".", "decoder", ".", "parameters", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.vae.VAE.named_parameters": [[211, 216], ["vae.VAE.encoder.named_parameters", "vae.VAE.vae_head.named_parameters", "vae.VAE.decoder.named_parameters"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.rl.atari_rl_models.AtariDqnModel.named_parameters", "home.repos.pwc.inspect_result.astooke_rlpyt.rl.atari_rl_models.AtariDqnModel.named_parameters", "home.repos.pwc.inspect_result.astooke_rlpyt.rl.atari_rl_models.AtariDqnModel.named_parameters"], ["", "def", "named_parameters", "(", "self", ")", ":", "\n", "        ", "\"\"\"To allow filtering by name in weight decay.\"\"\"", "\n", "yield", "from", "self", ".", "encoder", ".", "named_parameters", "(", ")", "\n", "yield", "from", "self", ".", "vae_head", ".", "named_parameters", "(", ")", "\n", "yield", "from", "self", ".", "decoder", ".", "named_parameters", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.vae.VAE.eval": [[217, 221], ["vae.VAE.encoder.eval", "vae.VAE.vae_head.eval", "vae.VAE.decoder.eval"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.augmented_temporal_similarity.AugmentedTemporalSimilarity.eval", "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.augmented_temporal_similarity.AugmentedTemporalSimilarity.eval", "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.augmented_temporal_similarity.AugmentedTemporalSimilarity.eval"], ["", "def", "eval", "(", "self", ")", ":", "\n", "        ", "self", ".", "encoder", ".", "eval", "(", ")", "# in case of batch norm", "\n", "self", ".", "vae_head", ".", "eval", "(", ")", "\n", "self", ".", "decoder", ".", "eval", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.vae.VAE.train": [[222, 226], ["vae.VAE.encoder.train", "vae.VAE.vae_head.train", "vae.VAE.decoder.train"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.runners.minibatch_rl.MinibatchRlEval.train", "home.repos.pwc.inspect_result.astooke_rlpyt.runners.minibatch_rl.MinibatchRlEval.train", "home.repos.pwc.inspect_result.astooke_rlpyt.runners.minibatch_rl.MinibatchRlEval.train"], ["", "def", "train", "(", "self", ")", ":", "\n", "        ", "self", ".", "encoder", ".", "train", "(", ")", "\n", "self", ".", "vae_head", ".", "train", "(", ")", "\n", "self", ".", "decoder", ".", "train", "(", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.augmented_temporal_similarity.AugmentedTemporalSimilarity.__init__": [[31, 62], ["rlpyt.utils.quick_args.save__init__args", "dict", "locals"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.utils.quick_args.save__init__args"], ["def", "__init__", "(", "\n", "self", ",", "\n", "replay_filepath", ",", "\n", "ReplayCls", "=", "UlForRlReplayBuffer", ",", "\n", "delta_T", "=", "1", ",", "\n", "batch_T", "=", "1", ",", "\n", "batch_B", "=", "256", ",", "\n", "learning_rate", "=", "1e-3", ",", "\n", "learning_rate_anneal", "=", "None", ",", "# cosine", "\n", "learning_rate_warmup", "=", "0", ",", "# number of updates", "\n", "OptimCls", "=", "torch", ".", "optim", ".", "Adam", ",", "\n", "optim_kwargs", "=", "None", ",", "\n", "clip_grad_norm", "=", "10.", ",", "\n", "target_update_tau", "=", "0.01", ",", "# 1 for hard update", "\n", "target_update_interval", "=", "1", ",", "\n", "EncoderCls", "=", "EncoderModel", ",", "\n", "encoder_kwargs", "=", "None", ",", "\n", "latent_size", "=", "256", ",", "\n", "anchor_hidden_sizes", "=", "512", ",", "\n", "initial_state_dict", "=", "None", ",", "\n", "random_shift_prob", "=", "1.", ",", "\n", "random_shift_pad", "=", "4", ",", "\n", "activation_loss_coefficient", "=", "0.", ",", "# rarely if ever use", "\n", "validation_split", "=", "0.0", ",", "\n", "n_validation_batches", "=", "0", ",", "# usually don't do it.", "\n", ")", ":", "\n", "        ", "encoder_kwargs", "=", "dict", "(", ")", "if", "encoder_kwargs", "is", "None", "else", "encoder_kwargs", "\n", "save__init__args", "(", "locals", "(", ")", ")", "\n", "assert", "learning_rate_anneal", "in", "[", "None", ",", "\"cosine\"", "]", "\n", "self", ".", "batch_size", "=", "batch_B", "*", "batch_T", "# for logging only", "\n", "self", ".", "_replay_T", "=", "batch_T", "+", "delta_T", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.augmented_temporal_similarity.AugmentedTemporalSimilarity.initialize": [[63, 87], ["augmented_temporal_similarity.AugmentedTemporalSimilarity.load_replay", "augmented_temporal_similarity.AugmentedTemporalSimilarity.EncoderCls", "copy.deepcopy", "rlpyt.models.mlp.MlpModel", "augmented_temporal_similarity.AugmentedTemporalSimilarity.encoder.to", "augmented_temporal_similarity.AugmentedTemporalSimilarity.target_encoder.to", "augmented_temporal_similarity.AugmentedTemporalSimilarity.predictor.to", "augmented_temporal_similarity.AugmentedTemporalSimilarity.optim_initialize", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "augmented_temporal_similarity.AugmentedTemporalSimilarity.load_state_dict"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.pixel_control.PixelControl.load_replay", "home.repos.pwc.inspect_result.astooke_rlpyt.rl_with_ul.sac_with_ul.SacWithUl.optim_initialize", "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.augmented_temporal_similarity.AugmentedTemporalSimilarity.load_state_dict"], ["", "def", "initialize", "(", "self", ",", "n_updates", ",", "cuda_idx", "=", "None", ")", ":", "\n", "        ", "self", ".", "device", "=", "torch", ".", "device", "(", "\"cpu\"", ")", "if", "cuda_idx", "is", "None", "else", "torch", ".", "device", "(", "\n", "\"cuda\"", ",", "index", "=", "cuda_idx", ")", "\n", "\n", "examples", "=", "self", ".", "load_replay", "(", ")", "\n", "self", ".", "encoder", "=", "self", ".", "EncoderCls", "(", "\n", "image_shape", "=", "examples", ".", "observation", ".", "shape", ",", "\n", "latent_size", "=", "self", ".", "latent_size", ",", "\n", "**", "self", ".", "encoder_kwargs", "\n", ")", "\n", "self", ".", "target_encoder", "=", "copy", ".", "deepcopy", "(", "self", ".", "encoder", ")", "\n", "self", ".", "predictor", "=", "MlpModel", "(", "\n", "input_size", "=", "self", ".", "latent_size", ",", "\n", "hidden_sizes", "=", "self", ".", "anchor_hidden_sizes", ",", "\n", "output_size", "=", "self", ".", "latent_size", ",", "\n", ")", "\n", "self", ".", "encoder", ".", "to", "(", "self", ".", "device", ")", "\n", "self", ".", "target_encoder", ".", "to", "(", "self", ".", "device", ")", "\n", "self", ".", "predictor", ".", "to", "(", "self", ".", "device", ")", "\n", "\n", "self", ".", "optim_initialize", "(", "n_updates", ")", "\n", "\n", "if", "self", ".", "initial_state_dict", "is", "not", "None", ":", "\n", "            ", "self", ".", "load_state_dict", "(", "self", ".", "initial_state_dict", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.augmented_temporal_similarity.AugmentedTemporalSimilarity.optimize": [[88, 113], ["OptInfo", "augmented_temporal_similarity.AugmentedTemporalSimilarity.replay_buffer.sample_batch", "augmented_temporal_similarity.AugmentedTemporalSimilarity.optimizer.zero_grad", "augmented_temporal_similarity.AugmentedTemporalSimilarity.ats_loss", "augmented_temporal_similarity.AugmentedTemporalSimilarity.activation_loss", "loss.backward", "augmented_temporal_similarity.AugmentedTemporalSimilarity.optimizer.step", "OptInfo.atsLoss.append", "OptInfo.activationLoss.append", "OptInfo.gradNorm.append", "OptInfo.convActivation.append", "augmented_temporal_similarity.AugmentedTemporalSimilarity.lr_scheduler.step", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "ats_loss.item", "augmented_temporal_similarity.AugmentedTemporalSimilarity.item", "torch.nn.utils.clip_grad_norm_.item", "torch.nn.utils.clip_grad_norm_.item", "conv_output[].detach().cpu().view().numpy", "rlpyt.models.utils.update_state_dict", "augmented_temporal_similarity.AugmentedTemporalSimilarity.parameters", "augmented_temporal_similarity.AugmentedTemporalSimilarity.encoder.state_dict", "conv_output[].detach().cpu().view", "range", "len", "conv_output[].detach().cpu", "conv_output[].detach"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.sequence.uniform.UniformSequenceReplay.sample_batch", "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.augmented_temporal_similarity.AugmentedTemporalSimilarity.ats_loss", "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.base.BaseUlAlgorithm.activation_loss", "home.repos.pwc.inspect_result.astooke_rlpyt.models.utils.ScaleGrad.backward", "home.repos.pwc.inspect_result.astooke_rlpyt.safe.safety_gym_env.SafetyGymTrajInfo.step", "home.repos.pwc.inspect_result.astooke_rlpyt.safe.safety_gym_env.SafetyGymTrajInfo.step", "home.repos.pwc.inspect_result.astooke_rlpyt.models.utils.update_state_dict", "home.repos.pwc.inspect_result.astooke_rlpyt.rl.atari_rl_models.AtariDqnModel.parameters", "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.replay_saver.DummyOptimizer.state_dict"], ["", "", "def", "optimize", "(", "self", ",", "itr", ")", ":", "\n", "        ", "opt_info", "=", "OptInfo", "(", "*", "(", "[", "]", "for", "_", "in", "range", "(", "len", "(", "OptInfo", ".", "_fields", ")", ")", ")", ")", "\n", "samples", "=", "self", ".", "replay_buffer", ".", "sample_batch", "(", "self", ".", "batch_B", ")", "\n", "if", "self", ".", "lr_scheduler", "is", "not", "None", ":", "\n", "            ", "self", ".", "lr_scheduler", ".", "step", "(", "itr", ")", "# Do every itr instead of every epoch", "\n", "", "self", ".", "optimizer", ".", "zero_grad", "(", ")", "\n", "ats_loss", ",", "conv_output", "=", "self", ".", "ats_loss", "(", "samples", ")", "\n", "act_loss", "=", "self", ".", "activation_loss", "(", "conv_output", ")", "\n", "loss", "=", "ats_loss", "+", "act_loss", "\n", "loss", ".", "backward", "(", ")", "\n", "if", "self", ".", "clip_grad_norm", "is", "None", ":", "\n", "            ", "grad_norm", "=", "0.", "\n", "", "else", ":", "\n", "            ", "grad_norm", "=", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "\n", "self", ".", "parameters", "(", ")", ",", "self", ".", "clip_grad_norm", ")", "\n", "", "self", ".", "optimizer", ".", "step", "(", ")", "\n", "opt_info", ".", "atsLoss", ".", "append", "(", "ats_loss", ".", "item", "(", ")", ")", "\n", "opt_info", ".", "activationLoss", ".", "append", "(", "act_loss", ".", "item", "(", ")", ")", "\n", "opt_info", ".", "gradNorm", ".", "append", "(", "grad_norm", ".", "item", "(", ")", ")", "\n", "opt_info", ".", "convActivation", ".", "append", "(", "\n", "conv_output", "[", "0", "]", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "view", "(", "-", "1", ")", ".", "numpy", "(", ")", ")", "# Keep 1 full one.", "\n", "if", "itr", "%", "self", ".", "target_update_interval", "==", "0", ":", "\n", "            ", "update_state_dict", "(", "self", ".", "target_encoder", ",", "self", ".", "encoder", ".", "state_dict", "(", ")", ",", "\n", "self", ".", "target_update_tau", ")", "\n", "", "return", "opt_info", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.augmented_temporal_similarity.AugmentedTemporalSimilarity.ats_loss": [[114, 152], ["rlpyt.ul.algos.utils.data_augs.random_shift.view", "rlpyt.ul.algos.utils.data_augs.random_shift.view", "rlpyt.utils.buffer.buffer_to", "augmented_temporal_similarity.AugmentedTemporalSimilarity.encoder", "augmented_temporal_similarity.AugmentedTemporalSimilarity.predictor", "torch.normalize", "torch.normalize", "torch.normalize", "torch.normalize", "rlpyt.algos.utils.valid_from_done", "valid[].reshape", "valid.to.to.to", "rlpyt.utils.tensor.valid_mean", "rlpyt.ul.algos.utils.data_augs.random_shift", "rlpyt.ul.algos.utils.data_augs.random_shift", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "augmented_temporal_similarity.AugmentedTemporalSimilarity.target_encoder", "samples.done.type"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.utils.buffer.buffer_to", "home.repos.pwc.inspect_result.astooke_rlpyt.algos.utils.valid_from_done", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.tensor.valid_mean", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.data_augs.random_shift", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.data_augs.random_shift"], ["", "def", "ats_loss", "(", "self", ",", "samples", ")", ":", "\n", "        ", "anchor", "=", "(", "samples", ".", "observation", "if", "self", ".", "delta_T", "==", "0", "else", "\n", "samples", ".", "observation", "[", ":", "-", "self", ".", "delta_T", "]", ")", "\n", "positive", "=", "samples", ".", "observation", "[", "self", ".", "delta_T", ":", "]", "\n", "t", ",", "b", ",", "c", ",", "h", ",", "w", "=", "anchor", ".", "shape", "\n", "anchor", "=", "anchor", ".", "view", "(", "t", "*", "b", ",", "c", ",", "h", ",", "w", ")", "# Treat all T,B as separate.", "\n", "positive", "=", "positive", ".", "view", "(", "t", "*", "b", ",", "c", ",", "h", ",", "w", ")", "\n", "\n", "if", "self", ".", "random_shift_prob", ">", "0.", ":", "\n", "            ", "anchor", "=", "random_shift", "(", "\n", "imgs", "=", "anchor", ",", "\n", "pad", "=", "self", ".", "random_shift_pad", ",", "\n", "prob", "=", "self", ".", "random_shift_prob", ",", "\n", ")", "\n", "positive", "=", "random_shift", "(", "\n", "imgs", "=", "positive", ",", "\n", "pad", "=", "self", ".", "random_shift_pad", ",", "\n", "prob", "=", "self", ".", "random_shift_prob", ",", "\n", ")", "\n", "\n", "", "anchor", ",", "positive", "=", "buffer_to", "(", "(", "anchor", ",", "positive", ")", ",", "\n", "device", "=", "self", ".", "device", ")", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "z_positive", ",", "_", "=", "self", ".", "target_encoder", "(", "positive", ")", "\n", "", "z_anchor", ",", "conv_output", "=", "self", ".", "encoder", "(", "anchor", ")", "\n", "q_anchor", "=", "self", ".", "predictor", "(", "z_anchor", ")", "\n", "\n", "q", "=", "F", ".", "normalize", "(", "q_anchor", ",", "dim", "=", "-", "1", ",", "p", "=", "2", ")", "\n", "z", "=", "F", ".", "normalize", "(", "z_positive", ",", "dim", "=", "-", "1", ",", "p", "=", "2", ")", "\n", "ats_losses", "=", "2.", "-", "2", "*", "(", "q", "*", "z", ")", ".", "sum", "(", "dim", "=", "-", "1", ")", "# from BYOL", "\n", "\n", "valid", "=", "valid_from_done", "(", "samples", ".", "done", ".", "type", "(", "torch", ".", "bool", ")", ")", "\n", "valid", "=", "valid", "[", "self", ".", "delta_T", ":", "]", ".", "reshape", "(", "-", "1", ")", "\n", "valid", "=", "valid", ".", "to", "(", "self", ".", "device", ")", "\n", "ats_loss", "=", "valid_mean", "(", "ats_losses", ",", "valid", ")", "\n", "\n", "return", "ats_loss", ",", "conv_output", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.augmented_temporal_similarity.AugmentedTemporalSimilarity.validation": [[153, 168], ["rlpyt.utils.logging.logger.log", "ValInfo", "augmented_temporal_similarity.AugmentedTemporalSimilarity.optimizer.zero_grad", "range", "augmented_temporal_similarity.AugmentedTemporalSimilarity.optimizer.zero_grad", "rlpyt.utils.logging.logger.log", "augmented_temporal_similarity.AugmentedTemporalSimilarity.replay_buffer.sample_batch", "ValInfo.atsLoss.append", "ValInfo.convActivation.append", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "augmented_temporal_similarity.AugmentedTemporalSimilarity.ats_loss", "ats_loss.item", "conv_output[].detach().cpu().view().numpy", "range", "conv_output[].detach().cpu().view", "len", "conv_output[].detach().cpu", "conv_output[].detach"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.logging.console.log", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.console.log", "home.repos.pwc.inspect_result.astooke_rlpyt.sequence.uniform.UniformSequenceReplay.sample_batch", "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.augmented_temporal_similarity.AugmentedTemporalSimilarity.ats_loss"], ["", "def", "validation", "(", "self", ",", "itr", ")", ":", "\n", "        ", "logger", ".", "log", "(", "\"Computing validation loss...\"", ")", "\n", "val_info", "=", "ValInfo", "(", "*", "(", "[", "]", "for", "_", "in", "range", "(", "len", "(", "ValInfo", ".", "_fields", ")", ")", ")", ")", "\n", "self", ".", "optimizer", ".", "zero_grad", "(", ")", "\n", "for", "_", "in", "range", "(", "self", ".", "n_validation_batches", ")", ":", "\n", "            ", "samples", "=", "self", ".", "replay_buffer", ".", "sample_batch", "(", "self", ".", "batch_B", ",", "\n", "validation", "=", "True", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "ats_loss", ",", "conv_output", "=", "self", ".", "ats_loss", "(", "samples", ")", "\n", "", "val_info", ".", "atsLoss", ".", "append", "(", "ats_loss", ".", "item", "(", ")", ")", "\n", "val_info", ".", "convActivation", ".", "append", "(", "\n", "conv_output", "[", "0", "]", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "view", "(", "-", "1", ")", ".", "numpy", "(", ")", ")", "\n", "", "self", ".", "optimizer", ".", "zero_grad", "(", ")", "\n", "logger", ".", "log", "(", "\"...validation loss completed.\"", ")", "\n", "return", "val_info", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.augmented_temporal_similarity.AugmentedTemporalSimilarity.state_dict": [[169, 175], ["dict", "augmented_temporal_similarity.AugmentedTemporalSimilarity.encoder.state_dict", "augmented_temporal_similarity.AugmentedTemporalSimilarity.target_encoder.state_dict", "augmented_temporal_similarity.AugmentedTemporalSimilarity.predictor.state_dict", "augmented_temporal_similarity.AugmentedTemporalSimilarity.optimizer.state_dict"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.replay_saver.DummyOptimizer.state_dict", "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.replay_saver.DummyOptimizer.state_dict", "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.replay_saver.DummyOptimizer.state_dict", "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.replay_saver.DummyOptimizer.state_dict"], ["", "def", "state_dict", "(", "self", ")", ":", "\n", "        ", "return", "dict", "(", "\n", "encoder", "=", "self", ".", "encoder", ".", "state_dict", "(", ")", ",", "\n", "target_encoder", "=", "self", ".", "target_encoder", ".", "state_dict", "(", ")", ",", "\n", "predictor", "=", "self", ".", "predictor", ".", "state_dict", "(", ")", ",", "\n", "optimizer", "=", "self", ".", "optimizer", ".", "state_dict", "(", ")", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.augmented_temporal_similarity.AugmentedTemporalSimilarity.load_state_dict": [[177, 182], ["augmented_temporal_similarity.AugmentedTemporalSimilarity.encoder.load_state_dict", "augmented_temporal_similarity.AugmentedTemporalSimilarity.target_encoder.load_state_dict", "augmented_temporal_similarity.AugmentedTemporalSimilarity.predictor.load_state_dict", "augmented_temporal_similarity.AugmentedTemporalSimilarity.optimizer.load_state_dict"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.augmented_temporal_similarity.AugmentedTemporalSimilarity.load_state_dict", "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.augmented_temporal_similarity.AugmentedTemporalSimilarity.load_state_dict", "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.augmented_temporal_similarity.AugmentedTemporalSimilarity.load_state_dict", "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.augmented_temporal_similarity.AugmentedTemporalSimilarity.load_state_dict"], ["", "def", "load_state_dict", "(", "self", ",", "state_dict", ")", ":", "\n", "        ", "self", ".", "encoder", ".", "load_state_dict", "(", "state_dict", "[", "\"encoder\"", "]", ")", "\n", "self", ".", "target_encoder", ".", "load_state_dict", "(", "state_dict", "[", "\"target_encoder\"", "]", ")", "\n", "self", ".", "predictor", ".", "load_state_dict", "(", "state_dict", "[", "\"predictor\"", "]", ")", "\n", "self", ".", "optimizer", ".", "load_state_dict", "(", "state_dict", "[", "\"optimizer\"", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.augmented_temporal_similarity.AugmentedTemporalSimilarity.parameters": [[183, 186], ["augmented_temporal_similarity.AugmentedTemporalSimilarity.encoder.parameters", "augmented_temporal_similarity.AugmentedTemporalSimilarity.predictor.parameters"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.rl.atari_rl_models.AtariDqnModel.parameters", "home.repos.pwc.inspect_result.astooke_rlpyt.rl.atari_rl_models.AtariDqnModel.parameters"], ["", "def", "parameters", "(", "self", ")", ":", "\n", "        ", "yield", "from", "self", ".", "encoder", ".", "parameters", "(", ")", "\n", "yield", "from", "self", ".", "predictor", ".", "parameters", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.augmented_temporal_similarity.AugmentedTemporalSimilarity.named_parameters": [[187, 191], ["augmented_temporal_similarity.AugmentedTemporalSimilarity.encoder.named_parameters", "augmented_temporal_similarity.AugmentedTemporalSimilarity.predictor.named_parameters"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.rl.atari_rl_models.AtariDqnModel.named_parameters", "home.repos.pwc.inspect_result.astooke_rlpyt.rl.atari_rl_models.AtariDqnModel.named_parameters"], ["", "def", "named_parameters", "(", "self", ")", ":", "\n", "        ", "\"\"\"To allow filtering by name in weight decay.\"\"\"", "\n", "yield", "from", "self", ".", "encoder", ".", "named_parameters", "(", ")", "\n", "yield", "from", "self", ".", "predictor", ".", "named_parameters", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.augmented_temporal_similarity.AugmentedTemporalSimilarity.eval": [[192, 195], ["augmented_temporal_similarity.AugmentedTemporalSimilarity.encoder.eval", "augmented_temporal_similarity.AugmentedTemporalSimilarity.predictor.eval"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.augmented_temporal_similarity.AugmentedTemporalSimilarity.eval", "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.augmented_temporal_similarity.AugmentedTemporalSimilarity.eval"], ["", "def", "eval", "(", "self", ")", ":", "\n", "        ", "self", ".", "encoder", ".", "eval", "(", ")", "# in case of batch norm", "\n", "self", ".", "predictor", ".", "eval", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.augmented_temporal_similarity.AugmentedTemporalSimilarity.train": [[196, 199], ["augmented_temporal_similarity.AugmentedTemporalSimilarity.encoder.train", "augmented_temporal_similarity.AugmentedTemporalSimilarity.predictor.train"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.runners.minibatch_rl.MinibatchRlEval.train", "home.repos.pwc.inspect_result.astooke_rlpyt.runners.minibatch_rl.MinibatchRlEval.train"], ["", "def", "train", "(", "self", ")", ":", "\n", "        ", "self", ".", "encoder", ".", "train", "(", ")", "\n", "self", ".", "predictor", ".", "train", "(", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.replay_saver.ReplaySaverAlgo.__init__": [[19, 25], ["replay_saver.DummyOptimizer"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "replay_size", ",", "discount", "=", "0.99", ",", "n_step_return", "=", "1", ",", "frame_buffer", "=", "False", ")", ":", "\n", "        ", "self", ".", "replay_size", "=", "replay_size", "\n", "self", ".", "discount", "=", "discount", "\n", "self", ".", "n_step_return", "=", "n_step_return", "\n", "self", ".", "frame_buffer", "=", "frame_buffer", "\n", "self", ".", "optimizer", "=", "DummyOptimizer", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.replay_saver.ReplaySaverAlgo.initialize": [[26, 38], ["replay_saver.ReplaySaverAlgo.examples_to_buffer", "ReplayCls"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.rl_with_ul.ppo_with_ul.PpoUl.examples_to_buffer"], ["", "def", "initialize", "(", "self", ",", "agent", ",", "n_itr", ",", "batch_spec", ",", "mid_batch_reset", "=", "False", ",", "\n", "examples", "=", "None", ",", "world_size", "=", "1", ",", "rank", "=", "0", ")", ":", "\n", "        ", "example_to_buffer", "=", "self", ".", "examples_to_buffer", "(", "examples", ")", "\n", "ReplayCls", "=", "UniformReplayFrameBuffer", "if", "self", ".", "frame_buffer", "else", "UniformReplayBuffer", "\n", "self", ".", "replay_buffer", "=", "ReplayCls", "(", "\n", "example", "=", "example_to_buffer", ",", "\n", "size", "=", "self", ".", "replay_size", ",", "\n", "B", "=", "batch_spec", ".", "B", ",", "\n", "discount", "=", "self", ".", "discount", ",", "\n", "n_step_return", "=", "self", ".", "n_step_return", ",", "\n", ")", "\n", "self", ".", "_batch_size", "=", "batch_spec", ".", "B", "*", "batch_spec", ".", "T", "# snapshot saving", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.replay_saver.ReplaySaverAlgo.optimize_agent": [[39, 42], ["replay_saver.ReplaySaverAlgo.samples_to_buffer", "replay_saver.ReplaySaverAlgo.replay_buffer.append_samples"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.rl_with_ul.ppo_with_ul.PpoUl.samples_to_buffer", "home.repos.pwc.inspect_result.astooke_rlpyt.sequence.prioritized.PrioritizedSequenceReplay.append_samples"], ["", "def", "optimize_agent", "(", "self", ",", "itr", ",", "samples", ")", ":", "\n", "        ", "samples_to_buffer", "=", "self", ".", "samples_to_buffer", "(", "samples", ")", "\n", "self", ".", "replay_buffer", ".", "append_samples", "(", "samples_to_buffer", ")", "\n", "# maybe return empyt tuple? rather than None", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.replay_saver.ReplaySaverAlgo.examples_to_buffer": [[44, 50], ["SamplesToBuffer"], "methods", ["None"], ["", "def", "examples_to_buffer", "(", "self", ",", "examples", ")", ":", "\n", "        ", "return", "SamplesToBuffer", "(", "\n", "observation", "=", "examples", "[", "\"observation\"", "]", ",", "\n", "action", "=", "examples", "[", "\"action\"", "]", ",", "\n", "reward", "=", "examples", "[", "\"reward\"", "]", ",", "\n", "done", "=", "examples", "[", "\"done\"", "]", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.replay_saver.ReplaySaverAlgo.samples_to_buffer": [[52, 61], ["SamplesToBuffer"], "methods", ["None"], ["", "def", "samples_to_buffer", "(", "self", ",", "samples", ")", ":", "\n", "        ", "\"\"\"Defines how to add data from sampler into the replay buffer. Called\n        in optimize_agent() if samples are provided to that method.  In \n        asynchronous mode, will be called in the memory_copier process.\"\"\"", "\n", "return", "SamplesToBuffer", "(", "\n", "observation", "=", "samples", ".", "env", ".", "observation", ",", "\n", "action", "=", "samples", ".", "agent", ".", "action", ",", "\n", "reward", "=", "samples", ".", "env", ".", "reward", ",", "\n", "done", "=", "samples", ".", "env", ".", "done", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.replay_saver.DummyOptimizer.state_dict": [[66, 68], ["None"], "methods", ["None"], ["def", "state_dict", "(", "self", ")", ":", "\n", "        ", "return", "None", "\n", "", "", ""]], "home.repos.pwc.inspect_result.astooke_rlpyt.rl_from_ul.dqn_from_ul.DqnFromUl.initialize": [[8, 13], ["super().initialize"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.safe.cppo_agent.CppoLstmAgent.initialize"], ["    ", "def", "initialize", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "initialize", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "self", ".", "store_latent", "=", "self", ".", "agent", ".", "store_latent", "\n", "if", "self", ".", "store_latent", ":", "\n", "            ", "self", ".", "use_frame_buffer", "=", "False", "# simple UniformReplayBuffer", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.rl_from_ul.dqn_from_ul.DqnFromUl.samples_to_buffer": [[14, 27], ["rlpyt.algos.dqn.dqn.SamplesToBuffer"], "methods", ["None"], ["", "", "def", "samples_to_buffer", "(", "self", ",", "samples", ")", ":", "\n", "        ", "\"\"\"Defines how to add data from sampler into the replay buffer. Called\n        in optimize_agent() if samples are provided to that method.  In \n        asynchronous mode, will be called in the memory_copier process.\"\"\"", "\n", "if", "self", ".", "store_latent", ":", "\n", "            ", "observation", "=", "samples", ".", "agent", ".", "agent_info", ".", "conv", "\n", "", "else", ":", "\n", "            ", "observation", "=", "samples", ".", "env", ".", "observation", "\n", "", "return", "SamplesToBuffer", "(", "\n", "observation", "=", "observation", ",", "\n", "action", "=", "samples", ".", "agent", ".", "action", ",", "\n", "reward", "=", "samples", ".", "env", ".", "reward", ",", "\n", "done", "=", "samples", ".", "env", ".", "done", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.rl_from_ul.dqn_from_ul.DqnFromUl.examples_to_buffer": [[29, 39], ["rlpyt.algos.dqn.dqn.SamplesToBuffer"], "methods", ["None"], ["", "def", "examples_to_buffer", "(", "self", ",", "examples", ")", ":", "\n", "        ", "if", "self", ".", "store_latent", ":", "\n", "            ", "observation", "=", "examples", "[", "\"agent_info\"", "]", ".", "conv", "\n", "", "else", ":", "\n", "            ", "observation", "=", "examples", "[", "\"observation\"", "]", "\n", "", "return", "SamplesToBuffer", "(", "\n", "observation", "=", "observation", ",", "\n", "action", "=", "examples", "[", "\"action\"", "]", ",", "\n", "reward", "=", "examples", "[", "\"reward\"", "]", ",", "\n", "done", "=", "examples", "[", "\"done\"", "]", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.rl_from_ul.rad_sac_from_ul.RadSacFromUl.__init__": [[45, 83], ["int", "int", "rlpyt.utils.quick_args.save__init__args", "locals"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.utils.quick_args.save__init__args"], ["def", "__init__", "(", "\n", "self", ",", "\n", "discount", "=", "0.99", ",", "\n", "batch_size", "=", "512", ",", "\n", "# replay_ratio=512,  # data_consumption / data_generation", "\n", "min_steps_learn", "=", "int", "(", "1e4", ")", ",", "\n", "replay_size", "=", "int", "(", "1e5", ")", ",", "\n", "target_update_tau", "=", "0.01", ",", "# tau=1 for hard update.", "\n", "target_update_interval", "=", "2", ",", "\n", "actor_update_interval", "=", "2", ",", "\n", "OptimCls", "=", "torch", ".", "optim", ".", "Adam", ",", "\n", "initial_optim_state_dict", "=", "None", ",", "# for all of them.", "\n", "action_prior", "=", "\"uniform\"", ",", "# or \"gaussian\"", "\n", "reward_scale", "=", "1", ",", "\n", "target_entropy", "=", "\"auto\"", ",", "# \"auto\", float, or None", "\n", "reparameterize", "=", "True", ",", "\n", "clip_grad_norm", "=", "1e6", ",", "\n", "n_step_return", "=", "1", ",", "\n", "bootstrap_timelimit", "=", "True", ",", "\n", "q_lr", "=", "1e-3", ",", "\n", "pi_lr", "=", "1e-3", ",", "\n", "alpha_lr", "=", "1e-4", ",", "\n", "q_beta", "=", "0.9", ",", "\n", "pi_beta", "=", "0.9", ",", "\n", "alpha_beta", "=", "0.5", ",", "\n", "alpha_init", "=", "0.1", ",", "\n", "encoder_update_tau", "=", "0.05", ",", "\n", "augmentation", "=", "\"random_shift\"", ",", "# [None, \"random_shift\", \"subpixel_shift\"]", "\n", "random_shift_pad", "=", "4", ",", "# how much to pad on each direction (like DrQ style)", "\n", "random_shift_prob", "=", "1.", ",", "\n", "stop_conv_grad", "=", "False", ",", "\n", "max_pixel_shift", "=", "1.", ",", "\n", ")", ":", "\n", "        ", "self", ".", "replay_ratio", "=", "batch_size", "# Unless you want to change it.", "\n", "self", ".", "_batch_size", "=", "batch_size", "\n", "del", "batch_size", "\n", "assert", "augmentation", "in", "[", "None", ",", "\"random_shift\"", ",", "\"subpixel_shift\"", "]", "\n", "save__init__args", "(", "locals", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.rl_from_ul.rad_sac_from_ul.RadSacFromUl.initialize": [[84, 107], ["int", "rlpyt.utils.logging.logger.log", "agent.give_min_itr_learn", "rad_sac_from_ul.RadSacFromUl.initialize_replay_buffer", "rad_sac_from_ul.RadSacFromUl.optim_initialize"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.logging.console.log", "home.repos.pwc.inspect_result.astooke_rlpyt.agents.dmc_sac_agent.SacAgent.give_min_itr_learn", "home.repos.pwc.inspect_result.astooke_rlpyt.rl_with_ul.ppo_with_ul.PpoUl.initialize_replay_buffer", "home.repos.pwc.inspect_result.astooke_rlpyt.rl_with_ul.sac_with_ul.SacWithUl.optim_initialize"], ["", "def", "initialize", "(", "self", ",", "agent", ",", "n_itr", ",", "batch_spec", ",", "mid_batch_reset", ",", "examples", ",", "\n", "world_size", "=", "1", ",", "rank", "=", "0", ")", ":", "\n", "        ", "\"\"\"Stores input arguments and initializes replay buffer and optimizer.\n        Use in non-async runners.  Computes number of gradient updates per\n        optimization iteration as `(replay_ratio * sampler-batch-size /\n        training-batch_size)`.\"\"\"", "\n", "self", ".", "agent", "=", "agent", "\n", "self", ".", "n_itr", "=", "n_itr", "\n", "self", ".", "mid_batch_reset", "=", "mid_batch_reset", "\n", "self", ".", "sampler_bs", "=", "sampler_bs", "=", "batch_spec", ".", "size", "\n", "self", ".", "updates_per_optimize", "=", "int", "(", "self", ".", "replay_ratio", "*", "sampler_bs", "/", "\n", "self", ".", "batch_size", ")", "\n", "logger", ".", "log", "(", "f\"From sampler batch size {sampler_bs}, training \"", "\n", "f\"batch size {self.batch_size}, and replay ratio \"", "\n", "f\"{self.replay_ratio}, computed {self.updates_per_optimize} \"", "\n", "f\"updates per iteration.\"", ")", "\n", "self", ".", "min_itr_learn", "=", "self", ".", "min_steps_learn", "//", "sampler_bs", "\n", "agent", ".", "give_min_itr_learn", "(", "self", ".", "min_itr_learn", ")", "\n", "self", ".", "store_latent", "=", "agent", ".", "store_latent", "\n", "if", "self", ".", "store_latent", ":", "\n", "            ", "assert", "self", ".", "stop_conv_grad", "\n", "", "self", ".", "initialize_replay_buffer", "(", "examples", ",", "batch_spec", ")", "\n", "self", ".", "optim_initialize", "(", "rank", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.rl_from_ul.rad_sac_from_ul.RadSacFromUl.async_initialize": [[108, 110], ["None"], "methods", ["None"], ["", "def", "async_initialize", "(", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.rl_from_ul.rad_sac_from_ul.RadSacFromUl.optim_initialize": [[111, 142], ["rad_sac_from_ul.RadSacFromUl.OptimCls", "rad_sac_from_ul.RadSacFromUl.OptimCls", "torch.tensor", "torch.exp", "rad_sac_from_ul.RadSacFromUl.OptimCls", "rad_sac_from_ul.chain", "rad_sac_from_ul.chain", "numpy.log", "rad_sac_from_ul.RadSacFromUl._log_alpha.detach", "rad_sac_from_ul.RadSacFromUl.load_optim_state_dict", "rlpyt.distributions.gaussian.Gaussian", "rad_sac_from_ul.RadSacFromUl.agent.pi_fc1.parameters", "rad_sac_from_ul.RadSacFromUl.agent.pi_mlp.parameters", "rad_sac_from_ul.RadSacFromUl.agent.q_fc1.parameters", "rad_sac_from_ul.RadSacFromUl.agent.q_mlps.parameters", "numpy.prod", "rad_sac_from_ul.RadSacFromUl.agent.conv.parameters", "numpy.prod"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.rl_with_ul.sac_with_ul.chain", "home.repos.pwc.inspect_result.astooke_rlpyt.rl_with_ul.sac_with_ul.chain", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.console.log", "home.repos.pwc.inspect_result.astooke_rlpyt.rl_with_ul.sac_with_ul.SacWithUl.load_optim_state_dict", "home.repos.pwc.inspect_result.astooke_rlpyt.rl.atari_rl_models.AtariDqnModel.parameters", "home.repos.pwc.inspect_result.astooke_rlpyt.rl.atari_rl_models.AtariDqnModel.parameters", "home.repos.pwc.inspect_result.astooke_rlpyt.rl.atari_rl_models.AtariDqnModel.parameters", "home.repos.pwc.inspect_result.astooke_rlpyt.rl.atari_rl_models.AtariDqnModel.parameters", "home.repos.pwc.inspect_result.astooke_rlpyt.rl.atari_rl_models.AtariDqnModel.parameters"], ["", "def", "optim_initialize", "(", "self", ",", "rank", "=", "0", ")", ":", "\n", "        ", "\"\"\"Called in initilize or by async runner after forking sampler.\"\"\"", "\n", "self", ".", "rank", "=", "rank", "\n", "\n", "# Be very explicit about which parameters are optimized where.", "\n", "self", ".", "pi_optimizer", "=", "self", ".", "OptimCls", "(", "chain", "(", "\n", "self", ".", "agent", ".", "pi_fc1", ".", "parameters", "(", ")", ",", "# No conv.", "\n", "self", ".", "agent", ".", "pi_mlp", ".", "parameters", "(", ")", ",", "\n", ")", ",", "\n", "lr", "=", "self", ".", "pi_lr", ",", "betas", "=", "(", "self", ".", "pi_beta", ",", "0.999", ")", ")", "\n", "self", ".", "q_optimizer", "=", "self", ".", "OptimCls", "(", "chain", "(", "\n", "(", ")", "if", "self", ".", "stop_conv_grad", "else", "self", ".", "agent", ".", "conv", ".", "parameters", "(", ")", ",", "\n", "self", ".", "agent", ".", "q_fc1", ".", "parameters", "(", ")", ",", "\n", "self", ".", "agent", ".", "q_mlps", ".", "parameters", "(", ")", ",", "\n", ")", ",", "\n", "lr", "=", "self", ".", "q_lr", ",", "betas", "=", "(", "self", ".", "q_beta", ",", "0.999", ")", ",", "\n", ")", "\n", "\n", "self", ".", "_log_alpha", "=", "torch", ".", "tensor", "(", "np", ".", "log", "(", "self", ".", "alpha_init", ")", ",", "\n", "requires_grad", "=", "True", ")", "\n", "self", ".", "_alpha", "=", "torch", ".", "exp", "(", "self", ".", "_log_alpha", ".", "detach", "(", ")", ")", "\n", "self", ".", "alpha_optimizer", "=", "self", ".", "OptimCls", "(", "(", "self", ".", "_log_alpha", ",", ")", ",", "\n", "lr", "=", "self", ".", "alpha_lr", ",", "betas", "=", "(", "self", ".", "alpha_beta", ",", "0.999", ")", ")", "\n", "\n", "if", "self", ".", "target_entropy", "==", "\"auto\"", ":", "\n", "            ", "self", ".", "target_entropy", "=", "-", "np", ".", "prod", "(", "self", ".", "agent", ".", "env_spaces", ".", "action", ".", "shape", ")", "\n", "", "if", "self", ".", "initial_optim_state_dict", "is", "not", "None", ":", "\n", "            ", "self", ".", "load_optim_state_dict", "(", "self", ".", "initial_optim_state_dict", ")", "\n", "", "if", "self", ".", "action_prior", "==", "\"gaussian\"", ":", "\n", "            ", "self", ".", "action_prior_distribution", "=", "Gaussian", "(", "\n", "dim", "=", "np", ".", "prod", "(", "self", ".", "agent", ".", "env_spaces", ".", "action", ".", "shape", ")", ",", "std", "=", "1.", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.rl_from_ul.rad_sac_from_ul.RadSacFromUl.initialize_replay_buffer": [[143, 160], ["rad_sac_from_ul.RadSacFromUl.examples_to_buffer", "dict", "ReplayCls"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.rl_with_ul.ppo_with_ul.PpoUl.examples_to_buffer"], ["", "", "def", "initialize_replay_buffer", "(", "self", ",", "examples", ",", "batch_spec", ",", "async_", "=", "False", ")", ":", "\n", "        ", "\"\"\"\n        Allocates replay buffer using examples and with the fields in `SamplesToBuffer`\n        namedarraytuple.\n        POSSIBLY CHANGE TO FRAME-BASED BUFFER (only if need memory, speed is fine).\n        \"\"\"", "\n", "if", "async_", ":", "\n", "            ", "raise", "NotImplementedError", "\n", "", "example_to_buffer", "=", "self", ".", "examples_to_buffer", "(", "examples", ")", "\n", "ReplayCls", "=", "TlUniformReplayBuffer", "if", "self", ".", "bootstrap_timelimit", "else", "UniformReplayBuffer", "\n", "replay_kwargs", "=", "dict", "(", "\n", "example", "=", "example_to_buffer", ",", "\n", "size", "=", "self", ".", "replay_size", ",", "\n", "B", "=", "batch_spec", ".", "B", ",", "\n", "n_step_return", "=", "self", ".", "n_step_return", ",", "\n", ")", "\n", "self", ".", "replay_buffer", "=", "ReplayCls", "(", "**", "replay_kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.rl_from_ul.rad_sac_from_ul.RadSacFromUl.optimize_agent": [[161, 236], ["OptInfo", "range", "rad_sac_from_ul.RadSacFromUl.samples_to_buffer", "rad_sac_from_ul.RadSacFromUl.replay_buffer.append_samples", "rad_sac_from_ul.RadSacFromUl.replay_buffer.sample_batch", "rad_sac_from_ul.RadSacFromUl.data_aug_loss_samples", "rad_sac_from_ul.RadSacFromUl.samples_to_device", "rad_sac_from_ul.RadSacFromUl.q_loss", "rad_sac_from_ul.RadSacFromUl.q_optimizer.zero_grad", "q_loss.backward", "torch.nn.utils.clip_grad_norm_", "rad_sac_from_ul.RadSacFromUl.q_optimizer.step", "OptInfo.q1Loss.append", "OptInfo.q2Loss.append", "OptInfo.qGradNorm.append", "OptInfo.q1.extend", "OptInfo.q2.extend", "OptInfo.qMeanDiff.append", "rad_sac_from_ul.RadSacFromUl.pi_alpha_loss", "rad_sac_from_ul.RadSacFromUl.pi_optimizer.zero_grad", "pi_loss.backward", "torch.nn.utils.clip_grad_norm_", "rad_sac_from_ul.RadSacFromUl.pi_optimizer.step", "OptInfo.piLoss.append", "OptInfo.piGradNorm.append", "OptInfo.piMu.extend", "OptInfo.piLogStd.extend", "rad_sac_from_ul.chain", "q1_loss.item", "q2_loss.item", "torch.nn.utils.clip_grad_norm_.item", "q1[].numpy", "q2[].numpy", "torch.mean().item", "rad_sac_from_ul.RadSacFromUl.agent.update_targets", "rad_sac_from_ul.RadSacFromUl.alpha_optimizer.zero_grad", "alpha_loss.backward", "rad_sac_from_ul.RadSacFromUl.alpha_optimizer.step", "torch.exp", "OptInfo.alpha.append", "rad_sac_from_ul.chain", "pi_loss.item", "torch.nn.utils.clip_grad_norm_.item", "pi_mean[].numpy", "pi_log_std[].numpy", "rad_sac_from_ul.RadSacFromUl.agent.q_fc1.parameters", "rad_sac_from_ul.RadSacFromUl.agent.q_mlps.parameters", "range", "rad_sac_from_ul.RadSacFromUl._log_alpha.detach", "rad_sac_from_ul.RadSacFromUl._alpha.item", "rad_sac_from_ul.RadSacFromUl.agent.pi_fc1.parameters", "rad_sac_from_ul.RadSacFromUl.agent.pi_mlp.parameters", "rad_sac_from_ul.RadSacFromUl.agent.conv.parameters", "torch.mean", "len", "abs"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.rl_with_ul.ppo_with_ul.PpoUl.samples_to_buffer", "home.repos.pwc.inspect_result.astooke_rlpyt.sequence.prioritized.PrioritizedSequenceReplay.append_samples", "home.repos.pwc.inspect_result.astooke_rlpyt.sequence.uniform.UniformSequenceReplay.sample_batch", "home.repos.pwc.inspect_result.astooke_rlpyt.rl_from_ul.rad_sac_from_ul.RadSacFromUl.data_aug_loss_samples", "home.repos.pwc.inspect_result.astooke_rlpyt.rl_with_ul.sac_with_ul.SacWithUl.samples_to_device", "home.repos.pwc.inspect_result.astooke_rlpyt.rl_with_ul.sac_with_ul.SacWithUl.q_loss", "home.repos.pwc.inspect_result.astooke_rlpyt.models.utils.ScaleGrad.backward", "home.repos.pwc.inspect_result.astooke_rlpyt.safe.safety_gym_env.SafetyGymTrajInfo.step", "home.repos.pwc.inspect_result.astooke_rlpyt.rl_with_ul.sac_with_ul.SacWithUl.pi_alpha_loss", "home.repos.pwc.inspect_result.astooke_rlpyt.models.utils.ScaleGrad.backward", "home.repos.pwc.inspect_result.astooke_rlpyt.safe.safety_gym_env.SafetyGymTrajInfo.step", "home.repos.pwc.inspect_result.astooke_rlpyt.rl_with_ul.sac_with_ul.chain", "home.repos.pwc.inspect_result.astooke_rlpyt.agents.dmc_sac_agent.SacAgent.update_targets", "home.repos.pwc.inspect_result.astooke_rlpyt.models.utils.ScaleGrad.backward", "home.repos.pwc.inspect_result.astooke_rlpyt.safe.safety_gym_env.SafetyGymTrajInfo.step", "home.repos.pwc.inspect_result.astooke_rlpyt.rl_with_ul.sac_with_ul.chain", "home.repos.pwc.inspect_result.astooke_rlpyt.rl.atari_rl_models.AtariDqnModel.parameters", "home.repos.pwc.inspect_result.astooke_rlpyt.rl.atari_rl_models.AtariDqnModel.parameters", "home.repos.pwc.inspect_result.astooke_rlpyt.rl.atari_rl_models.AtariDqnModel.parameters", "home.repos.pwc.inspect_result.astooke_rlpyt.rl.atari_rl_models.AtariDqnModel.parameters", "home.repos.pwc.inspect_result.astooke_rlpyt.rl.atari_rl_models.AtariDqnModel.parameters"], ["", "def", "optimize_agent", "(", "self", ",", "itr", ",", "samples", "=", "None", ",", "sampler_itr", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Extracts the needed fields from input samples and stores them in the \n        replay buffer.  Then samples from the replay buffer to train the agent\n        by gradient updates (with the number of updates determined by replay\n        ratio, sampler batch size, and training batch size).\n\n        DIFFERENCES FROM SAC:\n          -Organizes optimizers a little differently, clarifies which parameters.\n        \"\"\"", "\n", "itr", "=", "itr", "if", "sampler_itr", "is", "None", "else", "sampler_itr", "# Async uses sampler_itr.", "\n", "if", "samples", "is", "not", "None", ":", "\n", "            ", "samples_to_buffer", "=", "self", ".", "samples_to_buffer", "(", "samples", ")", "\n", "self", ".", "replay_buffer", ".", "append_samples", "(", "samples_to_buffer", ")", "\n", "", "opt_info", "=", "OptInfo", "(", "*", "(", "[", "]", "for", "_", "in", "range", "(", "len", "(", "OptInfo", ".", "_fields", ")", ")", ")", ")", "\n", "if", "itr", "<", "self", ".", "min_itr_learn", ":", "\n", "            ", "return", "opt_info", "\n", "", "for", "_", "in", "range", "(", "self", ".", "updates_per_optimize", ")", ":", "\n", "# Sample from the replay buffer, center crop, and move to GPU.", "\n", "            ", "samples_from_replay", "=", "self", ".", "replay_buffer", ".", "sample_batch", "(", "self", ".", "batch_size", ")", "\n", "loss_samples", "=", "self", ".", "data_aug_loss_samples", "(", "samples_from_replay", ")", "\n", "loss_samples", "=", "self", ".", "samples_to_device", "(", "loss_samples", ")", "\n", "\n", "# Q-loss includes computing some values used in pi-loss.", "\n", "q1_loss", ",", "q2_loss", ",", "valid", ",", "conv_out", ",", "q1", ",", "q2", "=", "self", ".", "q_loss", "(", "loss_samples", ")", "\n", "\n", "if", "self", ".", "update_counter", "%", "self", ".", "actor_update_interval", "==", "0", ":", "\n", "                ", "pi_loss", ",", "alpha_loss", ",", "pi_mean", ",", "pi_log_std", "=", "self", ".", "pi_alpha_loss", "(", "\n", "loss_samples", ",", "valid", ",", "conv_out", ")", "\n", "if", "alpha_loss", "is", "not", "None", ":", "\n", "                    ", "self", ".", "alpha_optimizer", ".", "zero_grad", "(", ")", "\n", "alpha_loss", ".", "backward", "(", ")", "\n", "self", ".", "alpha_optimizer", ".", "step", "(", ")", "\n", "self", ".", "_alpha", "=", "torch", ".", "exp", "(", "self", ".", "_log_alpha", ".", "detach", "(", ")", ")", "\n", "opt_info", ".", "alpha", ".", "append", "(", "self", ".", "_alpha", ".", "item", "(", ")", ")", "\n", "\n", "", "self", ".", "pi_optimizer", ".", "zero_grad", "(", ")", "\n", "pi_loss", ".", "backward", "(", ")", "\n", "pi_grad_norm", "=", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "chain", "(", "\n", "self", ".", "agent", ".", "pi_fc1", ".", "parameters", "(", ")", ",", "\n", "self", ".", "agent", ".", "pi_mlp", ".", "parameters", "(", ")", ",", "\n", ")", ",", "\n", "self", ".", "clip_grad_norm", ")", "\n", "self", ".", "pi_optimizer", ".", "step", "(", ")", "\n", "opt_info", ".", "piLoss", ".", "append", "(", "pi_loss", ".", "item", "(", ")", ")", "\n", "opt_info", ".", "piGradNorm", ".", "append", "(", "pi_grad_norm", ".", "item", "(", ")", ")", "\n", "opt_info", ".", "piMu", ".", "extend", "(", "pi_mean", "[", ":", ":", "10", "]", ".", "numpy", "(", ")", ")", "\n", "opt_info", ".", "piLogStd", ".", "extend", "(", "pi_log_std", "[", ":", ":", "10", "]", ".", "numpy", "(", ")", ")", "\n", "\n", "# Step Q's last because pi_loss.backward() uses them.", "\n", "", "self", ".", "q_optimizer", ".", "zero_grad", "(", ")", "\n", "q_loss", "=", "q1_loss", "+", "q2_loss", "\n", "q_loss", ".", "backward", "(", ")", "\n", "q_grad_norm", "=", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "chain", "(", "\n", "(", ")", "if", "self", ".", "stop_conv_grad", "else", "self", ".", "agent", ".", "conv", ".", "parameters", "(", ")", ",", "\n", "self", ".", "agent", ".", "q_fc1", ".", "parameters", "(", ")", ",", "\n", "self", ".", "agent", ".", "q_mlps", ".", "parameters", "(", ")", ",", "\n", ")", ",", "\n", "self", ".", "clip_grad_norm", ")", "\n", "self", ".", "q_optimizer", ".", "step", "(", ")", "\n", "opt_info", ".", "q1Loss", ".", "append", "(", "q1_loss", ".", "item", "(", ")", ")", "\n", "opt_info", ".", "q2Loss", ".", "append", "(", "q2_loss", ".", "item", "(", ")", ")", "\n", "opt_info", ".", "qGradNorm", ".", "append", "(", "q_grad_norm", ".", "item", "(", ")", ")", "\n", "opt_info", ".", "q1", ".", "extend", "(", "q1", "[", ":", ":", "10", "]", ".", "numpy", "(", ")", ")", "# Downsample for stats.", "\n", "opt_info", ".", "q2", ".", "extend", "(", "q2", "[", ":", ":", "10", "]", ".", "numpy", "(", ")", ")", "\n", "opt_info", ".", "qMeanDiff", ".", "append", "(", "torch", ".", "mean", "(", "abs", "(", "q1", "-", "q2", ")", ")", ".", "item", "(", ")", ")", "\n", "\n", "self", ".", "update_counter", "+=", "1", "\n", "if", "self", ".", "update_counter", "%", "self", ".", "target_update_interval", "==", "0", ":", "\n", "                ", "self", ".", "agent", ".", "update_targets", "(", "\n", "q_tau", "=", "self", ".", "target_update_tau", ",", "\n", "encoder_tau", "=", "self", ".", "encoder_update_tau", ",", "\n", ")", "\n", "\n", "", "", "return", "opt_info", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.rl_from_ul.rad_sac_from_ul.RadSacFromUl.samples_to_buffer": [[237, 254], ["SamplesToBuffer", "SamplesToBufferTl"], "methods", ["None"], ["", "def", "samples_to_buffer", "(", "self", ",", "samples", ")", ":", "\n", "        ", "\"\"\"Defines how to add data from sampler into the replay buffer. Called\n        in optimize_agent() if samples are provided to that method.\"\"\"", "\n", "if", "self", ".", "store_latent", ":", "\n", "            ", "observation", "=", "samples", ".", "agent", ".", "agent_info", ".", "conv", "\n", "", "else", ":", "\n", "            ", "observation", "=", "samples", ".", "env", ".", "observation", "\n", "", "samples_to_buffer", "=", "SamplesToBuffer", "(", "\n", "observation", "=", "observation", ",", "\n", "action", "=", "samples", ".", "agent", ".", "action", ",", "\n", "reward", "=", "samples", ".", "env", ".", "reward", ",", "\n", "done", "=", "samples", ".", "env", ".", "done", ",", "\n", ")", "\n", "if", "self", ".", "bootstrap_timelimit", ":", "\n", "            ", "samples_to_buffer", "=", "SamplesToBufferTl", "(", "*", "samples_to_buffer", ",", "\n", "timeout", "=", "samples", ".", "env", ".", "env_info", ".", "timeout", ")", "\n", "", "return", "samples_to_buffer", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.rl_from_ul.rad_sac_from_ul.RadSacFromUl.examples_to_buffer": [[255, 270], ["SamplesToBuffer", "SamplesToBufferTl"], "methods", ["None"], ["", "def", "examples_to_buffer", "(", "self", ",", "examples", ")", ":", "\n", "        ", "if", "self", ".", "store_latent", ":", "\n", "            ", "observation", "=", "examples", "[", "\"agent_info\"", "]", ".", "conv", "\n", "", "else", ":", "\n", "            ", "observation", "=", "examples", "[", "\"observation\"", "]", "\n", "", "example_to_buffer", "=", "SamplesToBuffer", "(", "\n", "observation", "=", "observation", ",", "\n", "action", "=", "examples", "[", "\"action\"", "]", ",", "\n", "reward", "=", "examples", "[", "\"reward\"", "]", ",", "\n", "done", "=", "examples", "[", "\"done\"", "]", ",", "\n", ")", "\n", "if", "self", ".", "bootstrap_timelimit", ":", "\n", "            ", "example_to_buffer", "=", "SamplesToBufferTl", "(", "*", "example_to_buffer", ",", "\n", "timeout", "=", "examples", "[", "\"env_info\"", "]", ".", "timeout", ")", "\n", "", "return", "example_to_buffer", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.rl_from_ul.rad_sac_from_ul.RadSacFromUl.samples_to_device": [[271, 283], ["rlpyt.utils.buffer.buffer_to", "samples._replace"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.utils.buffer.buffer_to", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.collections.NamedTuple._replace"], ["", "def", "samples_to_device", "(", "self", ",", "samples", ")", ":", "\n", "        ", "\"\"\"Only move the parts of samples which need to go to GPU.\"\"\"", "\n", "agent_inputs", ",", "target_inputs", ",", "action", "=", "buffer_to", "(", "\n", "(", "samples", ".", "agent_inputs", ",", "samples", ".", "target_inputs", ",", "samples", ".", "action", ")", ",", "\n", "device", "=", "self", ".", "agent", ".", "device", ",", "\n", ")", "\n", "device_samples", "=", "samples", ".", "_replace", "(", "\n", "agent_inputs", "=", "agent_inputs", ",", "\n", "target_inputs", "=", "target_inputs", ",", "\n", "action", "=", "action", ",", "\n", ")", "\n", "return", "device_samples", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.rl_from_ul.rad_sac_from_ul.RadSacFromUl.data_aug_loss_samples": [[284, 321], ["samples._replace", "rlpyt.ul.algos.utils.data_augs.random_shift", "rlpyt.ul.algos.utils.data_augs.random_shift", "rlpyt.ul.algos.utils.data_augs.subpixel_shift", "rlpyt.ul.algos.utils.data_augs.subpixel_shift", "samples.agent_inputs._replace", "samples.target_inputs._replace"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.utils.collections.NamedTuple._replace", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.data_augs.random_shift", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.data_augs.random_shift", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.data_augs.subpixel_shift", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.data_augs.subpixel_shift", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.collections.NamedTuple._replace", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.collections.NamedTuple._replace"], ["", "def", "data_aug_loss_samples", "(", "self", ",", "samples", ")", ":", "\n", "        ", "\"\"\"Perform data augmentation (on CPU).\"\"\"", "\n", "if", "self", ".", "augmentation", "is", "None", ":", "\n", "            ", "return", "samples", "\n", "\n", "", "obs", "=", "samples", ".", "agent_inputs", ".", "observation", "\n", "target_obs", "=", "samples", ".", "target_inputs", ".", "observation", "\n", "\n", "if", "self", ".", "augmentation", "==", "\"random_shift\"", ":", "\n", "            ", "aug_obs", "=", "random_shift", "(", "\n", "imgs", "=", "obs", ",", "\n", "pad", "=", "self", ".", "random_shift_pad", ",", "\n", "prob", "=", "self", ".", "random_shift_prob", ",", "\n", ")", "\n", "aug_target_obs", "=", "random_shift", "(", "\n", "imgs", "=", "target_obs", ",", "\n", "pad", "=", "self", ".", "random_shift_pad", ",", "\n", "prob", "=", "self", ".", "random_shift_prob", ",", "\n", ")", "\n", "", "elif", "self", ".", "augmentation", "==", "\"subpixel_shift\"", ":", "\n", "            ", "aug_obs", "=", "subpixel_shift", "(", "\n", "imgs", "=", "obs", ",", "\n", "max_shift", "=", "self", ".", "max_pixel_shift", ",", "\n", ")", "\n", "aug_target_obs", "=", "subpixel_shift", "(", "\n", "imgs", "=", "target_obs", ",", "\n", "max_shift", "=", "self", ".", "max_pixel_shift", ",", "\n", ")", "\n", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "\n", "\n", "", "aug_samples", "=", "samples", ".", "_replace", "(", "\n", "agent_inputs", "=", "samples", ".", "agent_inputs", ".", "_replace", "(", "observation", "=", "aug_obs", ")", ",", "\n", "target_inputs", "=", "samples", ".", "target_inputs", ".", "_replace", "(", "observation", "=", "aug_target_obs", ")", ",", "\n", ")", "\n", "\n", "return", "aug_samples", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.rl_from_ul.rad_sac_from_ul.RadSacFromUl.q_loss": [[322, 362], ["rad_sac_from_ul.RadSacFromUl.agent.q", "torch.ones_like", "rlpyt.algos.utils.valid_from_done", "rad_sac_from_ul.RadSacFromUl.agent.conv", "samples.agent_inputs._replace", "torch.no_grad", "rad_sac_from_ul.RadSacFromUl.agent.pi", "rad_sac_from_ul.RadSacFromUl.agent.target_q", "torch.min", "rlpyt.utils.tensor.valid_mean", "rlpyt.utils.tensor.valid_mean", "q1.detach", "q2.detach", "samples.timeout_n.float", "conv_out.detach.detach.detach", "rad_sac_from_ul.RadSacFromUl.agent.target_conv", "samples.target_inputs._replace", "samples.done_n.float"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.agents.dmc_sac_agent.SacAgent.q", "home.repos.pwc.inspect_result.astooke_rlpyt.algos.utils.valid_from_done", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.collections.NamedTuple._replace", "home.repos.pwc.inspect_result.astooke_rlpyt.agents.dmc_sac_agent.SacAgent.pi", "home.repos.pwc.inspect_result.astooke_rlpyt.agents.dmc_sac_agent.SacAgent.target_q", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.tensor.valid_mean", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.tensor.valid_mean", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.collections.NamedTuple._replace"], ["", "def", "q_loss", "(", "self", ",", "samples", ")", ":", "\n", "        ", "if", "self", ".", "mid_batch_reset", "and", "not", "self", ".", "agent", ".", "recurrent", ":", "\n", "            ", "valid", "=", "torch", ".", "ones_like", "(", "samples", ".", "done", ",", "dtype", "=", "torch", ".", "float", ")", "# or None", "\n", "", "else", ":", "\n", "            ", "valid", "=", "valid_from_done", "(", "samples", ".", "done", ")", "\n", "", "if", "self", ".", "bootstrap_timelimit", ":", "\n", "# To avoid non-use of bootstrap when environment is 'done' due to", "\n", "# time-limit, turn off training on these samples.", "\n", "            ", "valid", "*=", "(", "1", "-", "samples", ".", "timeout_n", ".", "float", "(", ")", ")", "\n", "\n", "# Run the convolution only once, return so pi_loss can use it.", "\n", "", "if", "self", ".", "store_latent", ":", "\n", "            ", "conv_out", "=", "None", "\n", "q_inputs", "=", "samples", ".", "agent_inputs", "\n", "", "else", ":", "\n", "            ", "conv_out", "=", "self", ".", "agent", ".", "conv", "(", "samples", ".", "agent_inputs", ".", "observation", ")", "\n", "if", "self", ".", "stop_conv_grad", ":", "\n", "                ", "conv_out", "=", "conv_out", ".", "detach", "(", ")", "\n", "", "q_inputs", "=", "samples", ".", "agent_inputs", ".", "_replace", "(", "observation", "=", "conv_out", ")", "\n", "\n", "# Q LOSS.", "\n", "", "q1", ",", "q2", "=", "self", ".", "agent", ".", "q", "(", "*", "q_inputs", ",", "samples", ".", "action", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "# Run the target convolution only once.", "\n", "            ", "if", "self", ".", "store_latent", ":", "\n", "                ", "target_inputs", "=", "samples", ".", "target_inputs", "\n", "", "else", ":", "\n", "                ", "target_conv_out", "=", "self", ".", "agent", ".", "target_conv", "(", "samples", ".", "target_inputs", ".", "observation", ")", "\n", "target_inputs", "=", "samples", ".", "target_inputs", ".", "_replace", "(", "observation", "=", "target_conv_out", ")", "\n", "", "target_action", ",", "target_log_pi", ",", "_", "=", "self", ".", "agent", ".", "pi", "(", "*", "target_inputs", ")", "\n", "target_q1", ",", "target_q2", "=", "self", ".", "agent", ".", "target_q", "(", "*", "target_inputs", ",", "target_action", ")", "\n", "min_target_q", "=", "torch", ".", "min", "(", "target_q1", ",", "target_q2", ")", "\n", "target_value", "=", "min_target_q", "-", "self", ".", "_alpha", "*", "target_log_pi", "\n", "", "disc", "=", "self", ".", "discount", "**", "self", ".", "n_step_return", "\n", "y", "=", "(", "self", ".", "reward_scale", "*", "samples", ".", "return_", "+", "\n", "(", "1", "-", "samples", ".", "done_n", ".", "float", "(", ")", ")", "*", "disc", "*", "target_value", ")", "\n", "q1_loss", "=", "0.5", "*", "valid_mean", "(", "(", "y", "-", "q1", ")", "**", "2", ",", "valid", ")", "\n", "q2_loss", "=", "0.5", "*", "valid_mean", "(", "(", "y", "-", "q2", ")", "**", "2", ",", "valid", ")", "\n", "\n", "return", "q1_loss", ",", "q2_loss", ",", "valid", ",", "conv_out", ",", "q1", ".", "detach", "(", ")", ",", "q2", ".", "detach", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.rl_from_ul.rad_sac_from_ul.RadSacFromUl.pi_alpha_loss": [[363, 397], ["rad_sac_from_ul.RadSacFromUl.agent.pi", "rad_sac_from_ul.RadSacFromUl.agent.q", "torch.min", "rad_sac_from_ul.RadSacFromUl.get_action_prior", "rlpyt.utils.tensor.valid_mean", "conv_out.detach", "samples.agent_inputs._replace", "new_action.cpu", "rlpyt.utils.tensor.valid_mean", "pi_mean.detach", "pi_log_std.detach", "log_pi.detach"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.agents.dmc_sac_agent.SacAgent.pi", "home.repos.pwc.inspect_result.astooke_rlpyt.agents.dmc_sac_agent.SacAgent.q", "home.repos.pwc.inspect_result.astooke_rlpyt.rl_with_ul.sac_with_ul.SacWithUl.get_action_prior", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.tensor.valid_mean", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.collections.NamedTuple._replace", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.tensor.valid_mean"], ["", "def", "pi_alpha_loss", "(", "self", ",", "samples", ",", "valid", ",", "conv_out", ")", ":", "\n", "# PI LOSS.", "\n", "# Uses detached conv; avoid re-computing.", "\n", "        ", "if", "self", ".", "store_latent", ":", "\n", "            ", "agent_inputs", "=", "samples", ".", "agent_inputs", "\n", "", "else", ":", "\n", "            ", "conv_detach", "=", "conv_out", ".", "detach", "(", ")", "# Always detached in actor.", "\n", "agent_inputs", "=", "samples", ".", "agent_inputs", ".", "_replace", "(", "observation", "=", "conv_detach", ")", "\n", "\n", "", "new_action", ",", "log_pi", ",", "(", "pi_mean", ",", "pi_log_std", ")", "=", "self", ".", "agent", ".", "pi", "(", "*", "agent_inputs", ")", "\n", "if", "not", "self", ".", "reparameterize", ":", "\n", "# new_action = new_action.detach()  # No grad.", "\n", "            ", "raise", "NotImplementedError", "\n", "# Re-use the detached latent.", "\n", "", "log_target1", ",", "log_target2", "=", "self", ".", "agent", ".", "q", "(", "*", "agent_inputs", ",", "new_action", ")", "\n", "min_log_target", "=", "torch", ".", "min", "(", "log_target1", ",", "log_target2", ")", "\n", "prior_log_pi", "=", "self", ".", "get_action_prior", "(", "new_action", ".", "cpu", "(", ")", ")", "\n", "if", "self", ".", "reparameterize", ":", "\n", "            ", "pi_losses", "=", "self", ".", "_alpha", "*", "log_pi", "-", "min_log_target", "-", "prior_log_pi", "\n", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "\n", "# if self.policy_output_regularization > 0:", "\n", "#     pi_losses += self.policy_output_regularization * torch.mean(", "\n", "#         0.5 * pi_mean ** 2 + 0.5 * pi_log_std ** 2, dim=-1)", "\n", "", "pi_loss", "=", "valid_mean", "(", "pi_losses", ",", "valid", ")", "\n", "\n", "# ALPHA LOSS.", "\n", "if", "self", ".", "target_entropy", "is", "not", "None", ":", "\n", "            ", "alpha_losses", "=", "-", "self", ".", "_log_alpha", "*", "(", "log_pi", ".", "detach", "(", ")", "+", "self", ".", "target_entropy", ")", "\n", "alpha_loss", "=", "valid_mean", "(", "alpha_losses", ",", "valid", ")", "\n", "", "else", ":", "\n", "            ", "alpha_loss", "=", "None", "\n", "\n", "", "return", "pi_loss", ",", "alpha_loss", ",", "pi_mean", ".", "detach", "(", ")", ",", "pi_log_std", ".", "detach", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.rl_from_ul.rad_sac_from_ul.RadSacFromUl.get_action_prior": [[398, 405], ["rad_sac_from_ul.RadSacFromUl.action_prior_distribution.log_likelihood", "rlpyt.distributions.gaussian.DistInfo", "torch.zeros_like"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.distributions.gaussian.Gaussian.log_likelihood"], ["", "def", "get_action_prior", "(", "self", ",", "action", ")", ":", "\n", "        ", "if", "self", ".", "action_prior", "==", "\"uniform\"", ":", "\n", "            ", "prior_log_pi", "=", "0.0", "\n", "", "elif", "self", ".", "action_prior", "==", "\"gaussian\"", ":", "\n", "            ", "prior_log_pi", "=", "self", ".", "action_prior_distribution", ".", "log_likelihood", "(", "\n", "action", ",", "GaussianDistInfo", "(", "mean", "=", "torch", ".", "zeros_like", "(", "action", ")", ")", ")", "\n", "", "return", "prior_log_pi", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.rl_from_ul.rad_sac_from_ul.RadSacFromUl.optim_state_dict": [[406, 412], ["dict", "rad_sac_from_ul.RadSacFromUl.pi_optimizer.state_dict", "rad_sac_from_ul.RadSacFromUl.q_optimizer.state_dict", "rad_sac_from_ul.RadSacFromUl.alpha_optimizer.state_dict", "rad_sac_from_ul.RadSacFromUl._log_alpha.detach().item", "rad_sac_from_ul.RadSacFromUl._log_alpha.detach"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.replay_saver.DummyOptimizer.state_dict", "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.replay_saver.DummyOptimizer.state_dict", "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.replay_saver.DummyOptimizer.state_dict"], ["", "def", "optim_state_dict", "(", "self", ")", ":", "\n", "        ", "return", "dict", "(", "\n", "pi", "=", "self", ".", "pi_optimizer", ".", "state_dict", "(", ")", ",", "\n", "q", "=", "self", ".", "q_optimizer", ".", "state_dict", "(", ")", ",", "\n", "alpha", "=", "self", ".", "alpha_optimizer", ".", "state_dict", "(", ")", ",", "\n", "log_alpha_value", "=", "self", ".", "_log_alpha", ".", "detach", "(", ")", ".", "item", "(", ")", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.rl_from_ul.rad_sac_from_ul.RadSacFromUl.load_optim_state_dict": [[414, 421], ["rad_sac_from_ul.RadSacFromUl.pi_optimizer.load_state_dict", "rad_sac_from_ul.RadSacFromUl.q_optimizer.load_state_dict", "rad_sac_from_ul.RadSacFromUl.alpha_optimizer.load_state_dict", "torch.no_grad", "torch.exp", "rad_sac_from_ul.RadSacFromUl._log_alpha.detach"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.augmented_temporal_similarity.AugmentedTemporalSimilarity.load_state_dict", "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.augmented_temporal_similarity.AugmentedTemporalSimilarity.load_state_dict", "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.augmented_temporal_similarity.AugmentedTemporalSimilarity.load_state_dict"], ["", "def", "load_optim_state_dict", "(", "self", ",", "state_dict", ")", ":", "\n", "        ", "self", ".", "pi_optimizer", ".", "load_state_dict", "(", "state_dict", "[", "\"pi\"", "]", ")", "\n", "self", ".", "q_optimizer", ".", "load_state_dict", "(", "state_dict", "[", "\"q\"", "]", ")", "\n", "self", ".", "alpha_optimizer", ".", "load_state_dict", "(", "state_dict", "[", "\"alpha\"", "]", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "self", ".", "_log_alpha", "[", ":", "]", "=", "state_dict", "[", "\"log_alpha_value\"", "]", "\n", "self", ".", "_alpha", "=", "torch", ".", "exp", "(", "self", ".", "_log_alpha", ".", "detach", "(", ")", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.astooke_rlpyt.rl_from_ul.rad_sac_from_ul.chain": [[36, 39], ["None"], "function", ["None"], ["def", "chain", "(", "*", "iterables", ")", ":", "\n", "    ", "for", "itr", "in", "iterables", ":", "\n", "        ", "yield", "from", "itr", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.rl_with_ul.dqn_with_ul.DqnUl.__init__": [[47, 120], ["int", "int", "int", "int", "int", "rlpyt.utils.quick_args.save__init__args", "dict", "dict", "locals"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.utils.quick_args.save__init__args"], ["def", "__init__", "(", "\n", "self", ",", "\n", "discount", "=", "0.99", ",", "\n", "batch_size", "=", "256", ",", "\n", "min_steps_rl", "=", "int", "(", "1e5", ")", ",", "\n", "delta_clip", "=", "1.", ",", "\n", "replay_size", "=", "int", "(", "1e6", ")", ",", "\n", "replay_ratio", "=", "8", ",", "# data_consumption / data_generation.", "\n", "target_update_tau", "=", "1", ",", "\n", "target_update_interval", "=", "1000", ",", "\n", "n_step_return", "=", "1", ",", "\n", "learning_rate", "=", "1.5e-4", ",", "\n", "OptimCls", "=", "torch", ".", "optim", ".", "Adam", ",", "\n", "optim_kwargs", "=", "None", ",", "\n", "initial_optim_state_dict", "=", "None", ",", "\n", "clip_grad_norm", "=", "40.", ",", "\n", "# eps_init=1,  # NOW IN AGENT.", "\n", "# eps_final=0.01,", "\n", "# eps_final_min=None,  # set < eps_final to use vector-valued eps.", "\n", "# eps_eval=0.001,", "\n", "eps_steps", "=", "int", "(", "1e6", ")", ",", "# STILL IN ALGO (to convert to itr).", "\n", "double_dqn", "=", "False", ",", "\n", "prioritized_replay", "=", "False", ",", "\n", "pri_alpha", "=", "0.6", ",", "\n", "pri_beta_init", "=", "0.4", ",", "\n", "pri_beta_final", "=", "1.", ",", "\n", "pri_beta_steps", "=", "int", "(", "50e6", ")", ",", "\n", "default_priority", "=", "None", ",", "\n", "ReplayBufferCls", "=", "None", ",", "# Leave None to select by above options.", "\n", "updates_per_sync", "=", "1", ",", "# For async mode only.", "\n", "use_frame_buffer", "=", "True", ",", "\n", "min_steps_ul", "=", "int", "(", "5e4", ")", ",", "\n", "max_steps_ul", "=", "None", ",", "\n", "ul_learning_rate", "=", "1e-3", ",", "\n", "ul_update_schedule", "=", "None", ",", "\n", "ul_lr_schedule", "=", "None", ",", "\n", "ul_lr_warmup", "=", "0", ",", "\n", "ul_delta_T", "=", "3", ",", "\n", "ul_batch_B", "=", "32", ",", "\n", "ul_batch_T", "=", "16", ",", "\n", "ul_random_shift_prob", "=", "0.1", ",", "\n", "ul_random_shift_pad", "=", "4", ",", "\n", "ul_target_update_interval", "=", "1", ",", "\n", "ul_target_update_tau", "=", "0.01", ",", "\n", "ul_latent_size", "=", "256", ",", "\n", "ul_anchor_hidden_sizes", "=", "512", ",", "\n", "ul_clip_grad_norm", "=", "10.", ",", "\n", "ul_optim_kwargs", "=", "None", ",", "\n", "# ul_pri_alpha=0.,  # No prioritization for now", "\n", "# ul_pri_beta=1.,", "\n", "# ul_pri_n_step_return=1,", "\n", "UlEncoderCls", "=", "UlEncoderModel", ",", "\n", "UlContrastCls", "=", "ContrastModel", ",", "\n", ")", ":", "\n", "        ", "\"\"\"Saves input arguments.  \n\n        ``delta_clip`` selects the Huber loss; if ``None``, uses MSE.\n\n        ``replay_ratio`` determines the ratio of data-consumption\n        to data-generation.  For example, original DQN sampled 4 environment steps between\n        each training update with batch-size 32, for a replay ratio of 8.\n\n        \"\"\"", "\n", "if", "optim_kwargs", "is", "None", ":", "\n", "            ", "optim_kwargs", "=", "dict", "(", "eps", "=", "0.01", "/", "batch_size", ")", "\n", "", "if", "ul_optim_kwargs", "is", "None", ":", "\n", "            ", "ul_optim_kwargs", "=", "dict", "(", ")", "\n", "", "if", "default_priority", "is", "None", ":", "\n", "            ", "default_priority", "=", "delta_clip", "\n", "", "self", ".", "_batch_size", "=", "batch_size", "\n", "del", "batch_size", "# Property.", "\n", "save__init__args", "(", "locals", "(", ")", ")", "\n", "self", ".", "update_counter", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.rl_with_ul.dqn_with_ul.DqnUl.initialize": [[121, 162], ["max", "rlpyt.utils.logging.logger.log", "int", "int", "max", "agent.set_epsilon_itr_min_max", "dqn_with_ul.DqnUl.initialize_replay_buffer", "dqn_with_ul.DqnUl.UlEncoderCls", "copy.deepcopy", "dqn_with_ul.DqnUl.UlContrastCls", "dqn_with_ul.DqnUl.ul_encoder.to", "dqn_with_ul.DqnUl.ul_target_encoder.to", "dqn_with_ul.DqnUl.ul_contrast.to", "dqn_with_ul.DqnUl.optim_initialize", "round", "int"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.logging.console.log", "home.repos.pwc.inspect_result.astooke_rlpyt.dqn.epsilon_greedy.EpsilonGreedyAgentMixin.set_epsilon_itr_min_max", "home.repos.pwc.inspect_result.astooke_rlpyt.rl_with_ul.ppo_with_ul.PpoUl.initialize_replay_buffer", "home.repos.pwc.inspect_result.astooke_rlpyt.rl_with_ul.sac_with_ul.SacWithUl.optim_initialize"], ["", "def", "initialize", "(", "self", ",", "agent", ",", "n_itr", ",", "batch_spec", ",", "mid_batch_reset", ",", "examples", ",", "\n", "world_size", "=", "1", ",", "rank", "=", "0", ")", ":", "\n", "        ", "\"\"\"Stores input arguments and initializes replay buffer and optimizer.\n        Use in non-async runners.  Computes number of gradient updates per\n        optimization iteration as `(replay_ratio * sampler-batch-size /\n        training-batch_size)`.\"\"\"", "\n", "self", ".", "agent", "=", "agent", "\n", "self", ".", "n_itr", "=", "n_itr", "\n", "self", ".", "sampler_bs", "=", "sampler_bs", "=", "batch_spec", ".", "size", "\n", "self", ".", "mid_batch_reset", "=", "mid_batch_reset", "\n", "self", ".", "updates_per_optimize", "=", "max", "(", "1", ",", "round", "(", "self", ".", "replay_ratio", "*", "sampler_bs", "/", "\n", "self", ".", "batch_size", ")", ")", "\n", "logger", ".", "log", "(", "f\"From sampler batch size {batch_spec.size}, training \"", "\n", "f\"batch size {self.batch_size}, and replay ratio \"", "\n", "f\"{self.replay_ratio}, computed {self.updates_per_optimize} \"", "\n", "f\"updates per iteration.\"", ")", "\n", "self", ".", "min_itr_rl", "=", "int", "(", "self", ".", "min_steps_rl", "//", "sampler_bs", ")", "\n", "self", ".", "min_itr_ul", "=", "int", "(", "self", ".", "min_steps_ul", "//", "sampler_bs", ")", "\n", "self", ".", "max_itr_ul", "=", "(", "self", ".", "n_itr", "+", "1", "if", "self", ".", "max_steps_ul", "is", "None", "else", "\n", "self", ".", "max_steps_ul", "//", "sampler_bs", ")", "\n", "if", "self", ".", "min_itr_rl", "==", "self", ".", "min_itr_ul", ":", "\n", "            ", "self", ".", "min_itr_rl", "+=", "1", "# wait until next?", "\n", "", "eps_itr_max", "=", "max", "(", "1", ",", "int", "(", "self", ".", "eps_steps", "//", "sampler_bs", ")", ")", "\n", "agent", ".", "set_epsilon_itr_min_max", "(", "self", ".", "min_itr_rl", ",", "eps_itr_max", ")", "\n", "self", ".", "initialize_replay_buffer", "(", "examples", ",", "batch_spec", ")", "\n", "\n", "self", ".", "ul_encoder", "=", "self", ".", "UlEncoderCls", "(", "\n", "conv", "=", "self", ".", "agent", ".", "model", ".", "conv", ",", "\n", "latent_size", "=", "self", ".", "ul_latent_size", ",", "\n", "conv_out_size", "=", "self", ".", "agent", ".", "model", ".", "conv_out_size", ",", "\n", ")", "\n", "self", ".", "ul_target_encoder", "=", "copy", ".", "deepcopy", "(", "self", ".", "ul_encoder", ")", "\n", "self", ".", "ul_contrast", "=", "self", ".", "UlContrastCls", "(", "\n", "latent_size", "=", "self", ".", "ul_latent_size", ",", "\n", "anchor_hidden_sizes", "=", "self", ".", "ul_anchor_hidden_sizes", ",", "\n", ")", "\n", "self", ".", "ul_encoder", ".", "to", "(", "self", ".", "agent", ".", "device", ")", "\n", "self", ".", "ul_target_encoder", ".", "to", "(", "self", ".", "agent", ".", "device", ")", "\n", "self", ".", "ul_contrast", ".", "to", "(", "self", ".", "agent", ".", "device", ")", "\n", "\n", "self", ".", "optim_initialize", "(", "rank", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.rl_with_ul.dqn_with_ul.DqnUl.async_initialize": [[163, 179], ["None"], "methods", ["None"], ["", "def", "async_initialize", "(", "self", ",", "agent", ",", "sampler_n_itr", ",", "batch_spec", ",", "mid_batch_reset", ",", "\n", "examples", ",", "world_size", "=", "1", ")", ":", "\n", "        ", "\"\"\"Used in async runner only; returns replay buffer allocated in shared\n        memory, does not instantiate optimizer. \"\"\"", "\n", "# self.agent = agent", "\n", "# self.n_itr = sampler_n_itr", "\n", "# self.initialize_replay_buffer(examples, batch_spec, async_=True)", "\n", "# self.mid_batch_reset = mid_batch_reset", "\n", "# self.sampler_bs = sampler_bs = batch_spec.size", "\n", "# self.updates_per_optimize = self.updates_per_sync", "\n", "# self.min_itr_rl = int(self.min_steps_rl // sampler_bs)", "\n", "# eps_itr_max = max(1, int(self.eps_steps // sampler_bs))", "\n", "# # Before any forking so all sub processes have epsilon schedule:", "\n", "# agent.set_epsilon_itr_min_max(self.min_itr_rl, eps_itr_max)", "\n", "# return self.replay_buffer", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.rl_with_ul.dqn_with_ul.DqnUl.optim_initialize": [[180, 226], ["dqn_with_ul.DqnUl.OptimCls", "dqn_with_ul.DqnUl.OptimCls", "sum", "rlpyt.utils.logging.logger.log", "dqn_with_ul.DqnUl.agent.parameters", "dqn_with_ul.DqnUl.optimizer.load_state_dict", "max", "dqn_with_ul.DqnUl.ul_parameters", "torch.nn.CrossEntropyLoss", "dqn_with_ul.DqnUl.compute_ul_update_schedule", "torch.optim.lr_scheduler.LambdaLR", "rlpyt.ul.algos.utils.warmup_scheduler.GradualWarmupScheduler", "dqn_with_ul.DqnUl.ul_optimizer.zero_grad", "dqn_with_ul.DqnUl.ul_optimizer.step", "range", "torch.optim.lr_scheduler.CosineAnnealingLR"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.logging.console.log", "home.repos.pwc.inspect_result.astooke_rlpyt.rl.atari_rl_models.AtariDqnModel.parameters", "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.augmented_temporal_similarity.AugmentedTemporalSimilarity.load_state_dict", "home.repos.pwc.inspect_result.astooke_rlpyt.rl_with_ul.ppo_with_ul.PpoUl.ul_parameters", "home.repos.pwc.inspect_result.astooke_rlpyt.rl_with_ul.ppo_with_ul.PpoUl.compute_ul_update_schedule", "home.repos.pwc.inspect_result.astooke_rlpyt.safe.safety_gym_env.SafetyGymTrajInfo.step"], ["", "def", "optim_initialize", "(", "self", ",", "rank", "=", "0", ")", ":", "\n", "        ", "\"\"\"Called in initilize or by async runner after forking sampler.\"\"\"", "\n", "self", ".", "rank", "=", "rank", "\n", "self", ".", "optimizer", "=", "self", ".", "OptimCls", "(", "self", ".", "agent", ".", "parameters", "(", ")", ",", "\n", "lr", "=", "self", ".", "learning_rate", ",", "**", "self", ".", "optim_kwargs", ")", "\n", "if", "self", ".", "initial_optim_state_dict", "is", "not", "None", ":", "\n", "            ", "self", ".", "optimizer", ".", "load_state_dict", "(", "self", ".", "initial_optim_state_dict", ")", "\n", "", "if", "self", ".", "prioritized_replay", ":", "\n", "            ", "self", ".", "pri_beta_itr", "=", "max", "(", "1", ",", "self", ".", "pri_beta_steps", "//", "self", ".", "sampler_bs", ")", "\n", "\n", "", "self", ".", "ul_optimizer", "=", "self", ".", "OptimCls", "(", "\n", "self", ".", "ul_parameters", "(", ")", ",", "\n", "lr", "=", "self", ".", "ul_learning_rate", ",", "**", "self", ".", "ul_optim_kwargs", ")", "\n", "\n", "self", ".", "total_ul_updates", "=", "sum", "(", "[", "self", ".", "compute_ul_update_schedule", "(", "itr", ")", "\n", "for", "itr", "in", "range", "(", "self", ".", "n_itr", ")", "]", ")", "\n", "logger", ".", "log", "(", "f\"Total number of UL updates to do: {self.total_ul_updates}.\"", ")", "\n", "self", ".", "ul_update_counter", "=", "0", "\n", "self", ".", "ul_lr_scheduler", "=", "None", "\n", "if", "self", ".", "total_ul_updates", ">", "0", ":", "\n", "            ", "if", "self", ".", "ul_lr_schedule", "==", "\"linear\"", ":", "\n", "                ", "self", ".", "ul_lr_scheduler", "=", "torch", ".", "optim", ".", "lr_scheduler", ".", "LambdaLR", "(", "\n", "optimizer", "=", "self", ".", "ul_optimizer", ",", "\n", "lr_lambda", "=", "lambda", "upd", ":", "(", "self", ".", "total_ul_updates", "-", "upd", ")", "/", "self", ".", "total_ul_updates", ",", "\n", ")", "\n", "", "elif", "self", ".", "ul_lr_schedule", "==", "\"cosine\"", ":", "\n", "                ", "self", ".", "ul_lr_scheduler", "=", "torch", ".", "optim", ".", "lr_scheduler", ".", "CosineAnnealingLR", "(", "\n", "optimizer", "=", "self", ".", "ul_optimizer", ",", "\n", "T_max", "=", "self", ".", "total_ul_updates", "-", "self", ".", "ul_lr_warmup", ",", "\n", ")", "\n", "", "elif", "self", ".", "ul_lr_schedule", "is", "not", "None", ":", "\n", "                ", "raise", "NotImplementedError", "\n", "\n", "", "if", "self", ".", "ul_lr_warmup", ">", "0", ":", "\n", "                ", "self", ".", "ul_lr_scheduler", "=", "GradualWarmupScheduler", "(", "\n", "self", ".", "ul_optimizer", ",", "\n", "multiplier", "=", "1", ",", "\n", "total_epoch", "=", "self", ".", "ul_lr_warmup", ",", "# actually n_updates", "\n", "after_scheduler", "=", "self", ".", "ul_lr_scheduler", ",", "\n", ")", "\n", "\n", "", "if", "self", ".", "ul_lr_scheduler", "is", "not", "None", ":", "\n", "                ", "self", ".", "ul_optimizer", ".", "zero_grad", "(", ")", "\n", "self", ".", "ul_optimizer", ".", "step", "(", ")", "\n", "\n", "", "self", ".", "c_e_loss", "=", "torch", ".", "nn", ".", "CrossEntropyLoss", "(", "ignore_index", "=", "IGNORE_INDEX", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.rl_with_ul.dqn_with_ul.DqnUl.initialize_replay_buffer": [[227, 259], ["dqn_with_ul.DqnUl.examples_to_buffer", "dict", "ReplayCls", "dict.update", "rlpyt.utils.logging.logger.log", "dict"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.rl_with_ul.ppo_with_ul.PpoUl.examples_to_buffer", "home.repos.pwc.inspect_result.astooke_rlpyt.models.running_mean_std.RunningMeanStdModel.update", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.console.log"], ["", "", "def", "initialize_replay_buffer", "(", "self", ",", "examples", ",", "batch_spec", ",", "async_", "=", "False", ")", ":", "\n", "        ", "\"\"\"\n        Allocates replay buffer using examples and with the fields in `SamplesToBuffer`\n        namedarraytuple.  Uses frame-wise buffers, so that only unique frames are stored,\n        using less memory (usual observations are 4 most recent frames, with only newest\n        frame distince from previous observation).\n        \"\"\"", "\n", "if", "async_", ":", "\n", "            ", "raise", "NotImplementedError", "\n", "", "example_to_buffer", "=", "self", ".", "examples_to_buffer", "(", "examples", ")", "\n", "replay_kwargs", "=", "dict", "(", "\n", "example", "=", "example_to_buffer", ",", "\n", "size", "=", "self", ".", "replay_size", ",", "\n", "B", "=", "batch_spec", ".", "B", ",", "\n", "discount", "=", "self", ".", "discount", ",", "\n", "n_step_return", "=", "self", ".", "n_step_return", ",", "\n", ")", "\n", "if", "self", ".", "prioritized_replay", ":", "\n", "            ", "replay_kwargs", ".", "update", "(", "dict", "(", "\n", "alpha", "=", "self", ".", "pri_alpha", ",", "\n", "beta", "=", "self", ".", "pri_beta_init", ",", "\n", "default_priority", "=", "self", ".", "default_priority", ",", "\n", ")", ")", "\n", "ReplayCls", "=", "DqnWithUlPrioritizedReplayFrameBuffer", "\n", "", "else", ":", "\n", "            ", "ReplayCls", "=", "DqnWithUlUniformReplayFrameBuffer", "\n", "", "if", "not", "self", ".", "use_frame_buffer", ":", "\n", "            ", "logger", ".", "log", "(", "\"Overriding, using non-frame uniform replay buffer\"", ")", "\n", "ReplayCls", "=", "UniformReplayBuffer", "\n", "", "self", ".", "replay_buffer", "=", "ReplayCls", "(", "\n", "ul_replay_T", "=", "self", ".", "ul_delta_T", "+", "self", ".", "ul_batch_T", ",", "\n", "**", "replay_kwargs", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.rl_with_ul.dqn_with_ul.DqnUl.optimize_agent": [[261, 281], ["dqn_with_ul.DqnUl.samples_to_buffer", "dqn_with_ul.DqnUl.replay_buffer.append_samples", "OptInfo", "dqn_with_ul.DqnUl.rl_optimize", "opt_info._replace._replace._replace", "dqn_with_ul.DqnUl.ul_optimize", "opt_info._replace._replace._replace", "opt_info._replace._replace.ulUpdates.append", "dqn_with_ul.DqnUl._asdict", "dqn_with_ul.DqnUl._asdict", "range", "len"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.rl_with_ul.ppo_with_ul.PpoUl.samples_to_buffer", "home.repos.pwc.inspect_result.astooke_rlpyt.sequence.prioritized.PrioritizedSequenceReplay.append_samples", "home.repos.pwc.inspect_result.astooke_rlpyt.rl_with_ul.sac_with_ul.SacWithUl.rl_optimize", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.collections.NamedTuple._replace", "home.repos.pwc.inspect_result.astooke_rlpyt.rl_with_ul.ppo_with_ul.PpoUl.ul_optimize", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.collections.NamedTuple._replace", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.collections.NamedTuple._asdict", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.collections.NamedTuple._asdict"], ["", "def", "optimize_agent", "(", "self", ",", "itr", ",", "samples", ")", ":", "\n", "        ", "\"\"\"\n        Extracts the needed fields from input samples and stores them in the \n        replay buffer.  Then samples from the replay buffer to train the agent\n        by gradient updates (with the number of updates determined by replay\n        ratio, sampler batch size, and training batch size).  If using prioritized\n        replay, updates the priorities for sampled training batches.\n        \"\"\"", "\n", "samples_to_buffer", "=", "self", ".", "samples_to_buffer", "(", "samples", ")", "\n", "self", ".", "replay_buffer", ".", "append_samples", "(", "samples_to_buffer", ")", "\n", "opt_info", "=", "OptInfo", "(", "*", "(", "[", "]", "for", "_", "in", "range", "(", "len", "(", "OptInfo", ".", "_fields", ")", ")", ")", ")", "\n", "if", "itr", ">=", "self", ".", "min_itr_rl", ":", "\n", "            ", "opt_info_rl", "=", "self", ".", "rl_optimize", "(", "itr", ")", "\n", "opt_info", "=", "opt_info", ".", "_replace", "(", "**", "opt_info_rl", ".", "_asdict", "(", ")", ")", "\n", "", "if", "itr", ">=", "self", ".", "min_itr_ul", ":", "\n", "            ", "opt_info_ul", "=", "self", ".", "ul_optimize", "(", "itr", ")", "\n", "opt_info", "=", "opt_info", ".", "_replace", "(", "**", "opt_info_ul", ".", "_asdict", "(", ")", ")", "\n", "", "else", ":", "\n", "            ", "opt_info", ".", "ulUpdates", ".", "append", "(", "0", ")", "\n", "", "return", "opt_info", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.rl_with_ul.dqn_with_ul.DqnUl.rl_optimize": [[282, 302], ["OptInfoRl", "range", "dqn_with_ul.DqnUl.update_itr_hyperparams", "dqn_with_ul.DqnUl.replay_buffer.sample_batch", "dqn_with_ul.DqnUl.optimizer.zero_grad", "dqn_with_ul.DqnUl.loss", "loss.backward", "torch.nn.utils.clip_grad_norm_", "dqn_with_ul.DqnUl.optimizer.step", "OptInfoRl.loss.append", "OptInfoRl.gradNorm.append", "OptInfoRl.tdAbsErr.extend", "dqn_with_ul.DqnUl.agent.parameters", "dqn_with_ul.DqnUl.replay_buffer.update_batch_priorities", "loss.item", "torch.nn.utils.clip_grad_norm_.item", "td_abs_errors[].numpy", "dqn_with_ul.DqnUl.agent.update_target", "range", "len"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.rl_with_ul.dqn_with_ul.DqnUl.update_itr_hyperparams", "home.repos.pwc.inspect_result.astooke_rlpyt.sequence.uniform.UniformSequenceReplay.sample_batch", "home.repos.pwc.inspect_result.astooke_rlpyt.safe.cppo_pid.CppoPID.loss", "home.repos.pwc.inspect_result.astooke_rlpyt.models.utils.ScaleGrad.backward", "home.repos.pwc.inspect_result.astooke_rlpyt.safe.safety_gym_env.SafetyGymTrajInfo.step", "home.repos.pwc.inspect_result.astooke_rlpyt.rl.atari_rl_models.AtariDqnModel.parameters", "home.repos.pwc.inspect_result.astooke_rlpyt.sequence.prioritized.PrioritizedSequenceReplay.update_batch_priorities", "home.repos.pwc.inspect_result.astooke_rlpyt.agents.atari_dqn_agent.AtariDqnAgent.update_target"], ["", "def", "rl_optimize", "(", "self", ",", "itr", ")", ":", "\n", "        ", "opt_info_rl", "=", "OptInfoRl", "(", "*", "(", "[", "]", "for", "_", "in", "range", "(", "len", "(", "OptInfoRl", ".", "_fields", ")", ")", ")", ")", "\n", "for", "_", "in", "range", "(", "self", ".", "updates_per_optimize", ")", ":", "\n", "            ", "samples_from_replay", "=", "self", ".", "replay_buffer", ".", "sample_batch", "(", "self", ".", "batch_size", ")", "\n", "self", ".", "optimizer", ".", "zero_grad", "(", ")", "\n", "loss", ",", "td_abs_errors", "=", "self", ".", "loss", "(", "samples_from_replay", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "grad_norm", "=", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "\n", "self", ".", "agent", ".", "parameters", "(", ")", ",", "self", ".", "clip_grad_norm", ")", "\n", "self", ".", "optimizer", ".", "step", "(", ")", "\n", "if", "self", ".", "prioritized_replay", ":", "\n", "                ", "self", ".", "replay_buffer", ".", "update_batch_priorities", "(", "td_abs_errors", ")", "\n", "", "opt_info_rl", ".", "loss", ".", "append", "(", "loss", ".", "item", "(", ")", ")", "\n", "opt_info_rl", ".", "gradNorm", ".", "append", "(", "grad_norm", ".", "item", "(", ")", ")", "\n", "opt_info_rl", ".", "tdAbsErr", ".", "extend", "(", "td_abs_errors", "[", ":", ":", "8", "]", ".", "numpy", "(", ")", ")", "# Downsample.", "\n", "self", ".", "update_counter", "+=", "1", "\n", "if", "self", ".", "update_counter", "%", "self", ".", "target_update_interval", "==", "0", ":", "\n", "                ", "self", ".", "agent", ".", "update_target", "(", "self", ".", "target_update_tau", ")", "\n", "", "", "self", ".", "update_itr_hyperparams", "(", "itr", ")", "\n", "return", "opt_info_rl", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.rl_with_ul.dqn_with_ul.DqnUl.ul_optimize": [[303, 319], ["OptInfoUl", "dqn_with_ul.DqnUl.compute_ul_update_schedule", "range", "OptInfoUl.ulUpdates.append", "dqn_with_ul.DqnUl.ul_optimize_one_step", "OptInfoUl.ulLoss.append", "OptInfoUl.ulAccuracy.append", "OptInfoUl.ulGradNorm.append", "dqn_with_ul.DqnUl.ul_lr_scheduler.step", "ul_loss.item", "ul_accuracy.item", "grad_norm.item", "rlpyt.models.utils.update_state_dict", "dqn_with_ul.DqnUl.ul_encoder.state_dict", "range", "len"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.rl_with_ul.ppo_with_ul.PpoUl.compute_ul_update_schedule", "home.repos.pwc.inspect_result.astooke_rlpyt.rl_with_ul.ppo_with_ul.PpoUl.ul_optimize_one_step", "home.repos.pwc.inspect_result.astooke_rlpyt.safe.safety_gym_env.SafetyGymTrajInfo.step", "home.repos.pwc.inspect_result.astooke_rlpyt.models.utils.update_state_dict", "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.replay_saver.DummyOptimizer.state_dict"], ["", "def", "ul_optimize", "(", "self", ",", "itr", ")", ":", "\n", "        ", "opt_info_ul", "=", "OptInfoUl", "(", "*", "(", "[", "]", "for", "_", "in", "range", "(", "len", "(", "OptInfoUl", ".", "_fields", ")", ")", ")", ")", "\n", "n_ul_updates", "=", "self", ".", "compute_ul_update_schedule", "(", "itr", ")", "\n", "for", "i", "in", "range", "(", "n_ul_updates", ")", ":", "\n", "            ", "self", ".", "ul_update_counter", "+=", "1", "\n", "if", "self", ".", "ul_lr_scheduler", "is", "not", "None", ":", "\n", "                ", "self", ".", "ul_lr_scheduler", ".", "step", "(", "self", ".", "ul_update_counter", ")", "\n", "", "ul_loss", ",", "ul_accuracy", ",", "grad_norm", "=", "self", ".", "ul_optimize_one_step", "(", ")", "\n", "opt_info_ul", ".", "ulLoss", ".", "append", "(", "ul_loss", ".", "item", "(", ")", ")", "\n", "opt_info_ul", ".", "ulAccuracy", ".", "append", "(", "ul_accuracy", ".", "item", "(", ")", ")", "\n", "opt_info_ul", ".", "ulGradNorm", ".", "append", "(", "grad_norm", ".", "item", "(", ")", ")", "\n", "if", "self", ".", "ul_update_counter", "%", "self", ".", "ul_target_update_interval", "==", "0", ":", "\n", "                ", "update_state_dict", "(", "self", ".", "ul_target_encoder", ",", "self", ".", "ul_encoder", ".", "state_dict", "(", ")", ",", "\n", "self", ".", "ul_target_update_tau", ")", "\n", "", "", "opt_info_ul", ".", "ulUpdates", ".", "append", "(", "self", ".", "ul_update_counter", ")", "\n", "return", "opt_info_ul", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.rl_with_ul.dqn_with_ul.DqnUl.ul_optimize_one_step": [[320, 369], ["dqn_with_ul.DqnUl.ul_optimizer.zero_grad", "dqn_with_ul.DqnUl.replay_buffer.ul_sample_batch", "rlpyt.ul.algos.utils.data_augs.random_shift.reshape", "rlpyt.ul.algos.utils.data_augs.random_shift.reshape", "rlpyt.utils.buffer.buffer_to", "dqn_with_ul.DqnUl.ul_encoder", "dqn_with_ul.DqnUl.ul_contrast", "torch.arange", "rlpyt.algos.utils.valid_from_done().type", "valid[].reshape", "dqn_with_ul.DqnUl.c_e_loss", "dqn_with_ul.DqnUl.backward", "dqn_with_ul.DqnUl.ul_optimizer.step", "torch.mean", "rlpyt.ul.algos.utils.data_augs.random_shift", "rlpyt.ul.algos.utils.data_augs.random_shift", "torch.no_grad", "dqn_with_ul.DqnUl.ul_target_encoder", "torch.nn.utils.clip_grad_norm_", "torch.argmax", "correct[].float", "rlpyt.algos.utils.valid_from_done", "dqn_with_ul.DqnUl.ul_parameters", "dqn_with_ul.DqnUl.detach"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.replays.rl_with_ul_replay.DqnWithUlReplayBufferMixin.ul_sample_batch", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.buffer.buffer_to", "home.repos.pwc.inspect_result.astooke_rlpyt.models.utils.ScaleGrad.backward", "home.repos.pwc.inspect_result.astooke_rlpyt.safe.safety_gym_env.SafetyGymTrajInfo.step", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.data_augs.random_shift", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.data_augs.random_shift", "home.repos.pwc.inspect_result.astooke_rlpyt.algos.utils.valid_from_done", "home.repos.pwc.inspect_result.astooke_rlpyt.rl_with_ul.ppo_with_ul.PpoUl.ul_parameters"], ["", "def", "ul_optimize_one_step", "(", "self", ")", ":", "\n", "        ", "self", ".", "ul_optimizer", ".", "zero_grad", "(", ")", "\n", "samples", "=", "self", ".", "replay_buffer", ".", "ul_sample_batch", "(", "self", ".", "ul_batch_B", ")", "\n", "\n", "anchor", "=", "samples", ".", "observation", "[", ":", "-", "self", ".", "ul_delta_T", "]", "\n", "positive", "=", "samples", ".", "observation", "[", "self", ".", "ul_delta_T", ":", "]", "\n", "t", ",", "b", ",", "c", ",", "h", ",", "w", "=", "anchor", ".", "shape", "\n", "anchor", "=", "anchor", ".", "reshape", "(", "t", "*", "b", ",", "c", ",", "h", ",", "w", ")", "\n", "positive", "=", "positive", ".", "reshape", "(", "t", "*", "b", ",", "c", ",", "h", ",", "w", ")", "\n", "\n", "if", "self", ".", "ul_random_shift_prob", ">", "0.", ":", "\n", "            ", "anchor", "=", "random_shift", "(", "\n", "imgs", "=", "anchor", ",", "\n", "pad", "=", "self", ".", "ul_random_shift_pad", ",", "\n", "prob", "=", "self", ".", "ul_random_shift_prob", ",", "\n", ")", "\n", "positive", "=", "random_shift", "(", "\n", "imgs", "=", "positive", ",", "\n", "pad", "=", "self", ".", "ul_random_shift_pad", ",", "\n", "prob", "=", "self", ".", "ul_random_shift_prob", ",", "\n", ")", "\n", "\n", "", "anchor", ",", "positive", "=", "buffer_to", "(", "(", "anchor", ",", "positive", ")", ",", "\n", "device", "=", "self", ".", "agent", ".", "device", ")", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "c_positive", ",", "_pos_conv", "=", "self", ".", "ul_target_encoder", "(", "positive", ")", "\n", "", "c_anchor", ",", "_anc_conv", "=", "self", ".", "ul_encoder", "(", "anchor", ")", "\n", "logits", "=", "self", ".", "ul_contrast", "(", "c_anchor", ",", "c_positive", ")", "# anchor mlp in here.", "\n", "\n", "labels", "=", "torch", ".", "arange", "(", "c_anchor", ".", "shape", "[", "0", "]", ",", "\n", "dtype", "=", "torch", ".", "long", ",", "device", "=", "self", ".", "agent", ".", "device", ")", "\n", "valid", "=", "valid_from_done", "(", "samples", ".", "done", ")", ".", "type", "(", "torch", ".", "bool", ")", "# use all", "\n", "valid", "=", "valid", "[", "self", ".", "ul_delta_T", ":", "]", ".", "reshape", "(", "-", "1", ")", "# at positions of positive", "\n", "labels", "[", "~", "valid", "]", "=", "IGNORE_INDEX", "\n", "\n", "ul_loss", "=", "self", ".", "c_e_loss", "(", "logits", ",", "labels", ")", "\n", "ul_loss", ".", "backward", "(", ")", "\n", "if", "self", ".", "ul_clip_grad_norm", "is", "None", ":", "\n", "            ", "grad_norm", "=", "0.", "\n", "", "else", ":", "\n", "            ", "grad_norm", "=", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "\n", "self", ".", "ul_parameters", "(", ")", ",", "self", ".", "ul_clip_grad_norm", ")", "\n", "", "self", ".", "ul_optimizer", ".", "step", "(", ")", "\n", "\n", "correct", "=", "torch", ".", "argmax", "(", "logits", ".", "detach", "(", ")", ",", "dim", "=", "1", ")", "==", "labels", "\n", "accuracy", "=", "torch", ".", "mean", "(", "correct", "[", "valid", "]", ".", "float", "(", ")", ")", "\n", "\n", "return", "ul_loss", ",", "accuracy", ",", "grad_norm", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.rl_with_ul.dqn_with_ul.DqnUl.samples_to_buffer": [[370, 379], ["SamplesToBuffer"], "methods", ["None"], ["", "def", "samples_to_buffer", "(", "self", ",", "samples", ")", ":", "\n", "        ", "\"\"\"Defines how to add data from sampler into the replay buffer. Called\n        in optimize_agent() if samples are provided to that method.  In \n        asynchronous mode, will be called in the memory_copier process.\"\"\"", "\n", "return", "SamplesToBuffer", "(", "\n", "observation", "=", "samples", ".", "env", ".", "observation", ",", "\n", "action", "=", "samples", ".", "agent", ".", "action", ",", "\n", "reward", "=", "samples", ".", "env", ".", "reward", ",", "\n", "done", "=", "samples", ".", "env", ".", "done", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.rl_with_ul.dqn_with_ul.DqnUl.examples_to_buffer": [[381, 387], ["SamplesToBuffer"], "methods", ["None"], ["", "def", "examples_to_buffer", "(", "self", ",", "examples", ")", ":", "\n", "        ", "return", "SamplesToBuffer", "(", "\n", "observation", "=", "examples", "[", "\"observation\"", "]", ",", "\n", "action", "=", "examples", "[", "\"action\"", "]", ",", "\n", "reward", "=", "examples", "[", "\"reward\"", "]", ",", "\n", "done", "=", "examples", "[", "\"done\"", "]", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.rl_with_ul.dqn_with_ul.DqnUl.loss": [[389, 444], ["dqn_with_ul.DqnUl.agent", "rlpyt.utils.tensor.select_at_indexes", "abs", "abs.detach", "torch.no_grad", "dqn_with_ul.DqnUl.agent.target", "torch.where", "torch.clamp", "torch.mean", "dqn_with_ul.DqnUl.agent", "torch.argmax", "rlpyt.utils.tensor.select_at_indexes", "torch.max", "samples.done_n.float"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.utils.tensor.select_at_indexes", "home.repos.pwc.inspect_result.astooke_rlpyt.agents.atari_dqn_agent.AtariDqnAgent.target", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.tensor.select_at_indexes"], ["", "def", "loss", "(", "self", ",", "samples", ")", ":", "\n", "        ", "\"\"\"\n        Computes the Q-learning loss, based on: 0.5 * (Q - target_Q) ^ 2.\n        Implements regular DQN or Double-DQN for computing target_Q values\n        using the agent's target network.  Computes the Huber loss using \n        ``delta_clip``, or if ``None``, uses MSE.  When using prioritized\n        replay, multiplies losses by importance sample weights.\n\n        Input ``samples`` have leading batch dimension [B,..] (but not time).\n\n        Calls the agent to compute forward pass on training inputs, and calls\n        ``agent.target()`` to compute target values.\n\n        Returns loss and TD-absolute-errors for use in prioritization.\n\n        Warning: \n            If not using mid_batch_reset, the sampler will only reset environments\n            between iterations, so some samples in the replay buffer will be\n            invalid.  This case is not supported here currently.\n        \"\"\"", "\n", "qs", "=", "self", ".", "agent", "(", "*", "samples", ".", "agent_inputs", ")", "\n", "q", "=", "select_at_indexes", "(", "samples", ".", "action", ",", "qs", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "target_qs", "=", "self", ".", "agent", ".", "target", "(", "*", "samples", ".", "target_inputs", ")", "\n", "if", "self", ".", "double_dqn", ":", "\n", "                ", "next_qs", "=", "self", ".", "agent", "(", "*", "samples", ".", "target_inputs", ")", "\n", "next_a", "=", "torch", ".", "argmax", "(", "next_qs", ",", "dim", "=", "-", "1", ")", "\n", "target_q", "=", "select_at_indexes", "(", "next_a", ",", "target_qs", ")", "\n", "", "else", ":", "\n", "                ", "target_q", "=", "torch", ".", "max", "(", "target_qs", ",", "dim", "=", "-", "1", ")", ".", "values", "\n", "", "", "disc_target_q", "=", "(", "self", ".", "discount", "**", "self", ".", "n_step_return", ")", "*", "target_q", "\n", "y", "=", "samples", ".", "return_", "+", "(", "1", "-", "samples", ".", "done_n", ".", "float", "(", ")", ")", "*", "disc_target_q", "\n", "delta", "=", "y", "-", "q", "\n", "losses", "=", "0.5", "*", "delta", "**", "2", "\n", "abs_delta", "=", "abs", "(", "delta", ")", "\n", "if", "self", ".", "delta_clip", "is", "not", "None", ":", "# Huber loss.", "\n", "            ", "b", "=", "self", ".", "delta_clip", "*", "(", "abs_delta", "-", "self", ".", "delta_clip", "/", "2", ")", "\n", "losses", "=", "torch", ".", "where", "(", "abs_delta", "<=", "self", ".", "delta_clip", ",", "losses", ",", "b", ")", "\n", "", "if", "self", ".", "prioritized_replay", ":", "\n", "            ", "losses", "*=", "samples", ".", "is_weights", "\n", "", "td_abs_errors", "=", "abs_delta", ".", "detach", "(", ")", "\n", "if", "self", ".", "delta_clip", "is", "not", "None", ":", "\n", "            ", "td_abs_errors", "=", "torch", ".", "clamp", "(", "td_abs_errors", ",", "0", ",", "self", ".", "delta_clip", ")", "\n", "", "if", "not", "self", ".", "mid_batch_reset", ":", "\n", "# FIXME: I think this is wrong, because the first \"done\" sample", "\n", "# is valid, but here there is no [T] dim, so there's no way to", "\n", "# know if a \"done\" sample is the first \"done\" in the sequence.", "\n", "            ", "raise", "NotImplementedError", "\n", "# valid = valid_from_done(samples.done)", "\n", "# loss = valid_mean(losses, valid)", "\n", "# td_abs_errors *= valid", "\n", "", "else", ":", "\n", "            ", "loss", "=", "torch", ".", "mean", "(", "losses", ")", "\n", "\n", "", "return", "loss", ",", "td_abs_errors", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.rl_with_ul.dqn_with_ul.DqnUl.update_itr_hyperparams": [[445, 458], ["min", "dqn_with_ul.DqnUl.replay_buffer.set_beta", "max"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.sequence.prioritized.PrioritizedSequenceReplay.set_beta"], ["", "def", "update_itr_hyperparams", "(", "self", ",", "itr", ")", ":", "\n", "# EPS NOW IN AGENT.", "\n", "# if itr <= self.eps_itr:  # Epsilon can be vector-valued.", "\n", "#     prog = min(1, max(0, itr - self.min_itr_rl) /", "\n", "#       (self.eps_itr - self.min_itr_rl))", "\n", "#     new_eps = prog * self.eps_final + (1 - prog) * self.eps_init", "\n", "#     self.agent.set_sample_epsilon_greedy(new_eps)", "\n", "        ", "if", "self", ".", "prioritized_replay", "and", "itr", "<=", "self", ".", "pri_beta_itr", ":", "\n", "            ", "prog", "=", "min", "(", "1", ",", "max", "(", "0", ",", "itr", "-", "self", ".", "min_itr_rl", ")", "/", "\n", "(", "self", ".", "pri_beta_itr", "-", "self", ".", "min_itr_rl", ")", ")", "\n", "new_beta", "=", "(", "prog", "*", "self", ".", "pri_beta_final", "+", "\n", "(", "1", "-", "prog", ")", "*", "self", ".", "pri_beta_init", ")", "\n", "self", ".", "replay_buffer", ".", "set_beta", "(", "new_beta", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.rl_with_ul.dqn_with_ul.DqnUl.ul_parameters": [[459, 462], ["dqn_with_ul.DqnUl.ul_encoder.parameters", "dqn_with_ul.DqnUl.ul_contrast.parameters"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.rl.atari_rl_models.AtariDqnModel.parameters", "home.repos.pwc.inspect_result.astooke_rlpyt.rl.atari_rl_models.AtariDqnModel.parameters"], ["", "", "def", "ul_parameters", "(", "self", ")", ":", "\n", "        ", "yield", "from", "self", ".", "ul_encoder", ".", "parameters", "(", ")", "\n", "yield", "from", "self", ".", "ul_contrast", ".", "parameters", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.rl_with_ul.dqn_with_ul.DqnUl.ul_named_parameters": [[463, 466], ["dqn_with_ul.DqnUl.ul_encoder.named_parameters", "dqn_with_ul.DqnUl.ul_contrast.named_parameters"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.rl.atari_rl_models.AtariDqnModel.named_parameters", "home.repos.pwc.inspect_result.astooke_rlpyt.rl.atari_rl_models.AtariDqnModel.named_parameters"], ["", "def", "ul_named_parameters", "(", "self", ")", ":", "\n", "        ", "yield", "from", "self", ".", "ul_encoder", ".", "named_parameters", "(", ")", "\n", "yield", "from", "self", ".", "ul_contrast", ".", "named_parameters", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.rl_with_ul.dqn_with_ul.DqnUl.compute_ul_update_schedule": [[467, 494], ["int", "dqn_with_ul.DqnUl.ul_update_schedule.split", "dqn_with_ul.DqnUl.ul_update_schedule.split", "int", "int", "int", "int", "numpy.round", "int", "int", "dqn_with_ul.DqnUl.ul_update_schedule.split", "numpy.round", "int", "int", "dqn_with_ul.DqnUl.ul_update_schedule.split", "numpy.round", "int", "dqn_with_ul.DqnUl.ul_update_schedule.split", "math.sin", "dqn_with_ul.DqnUl.ul_update_schedule.split"], "methods", ["None"], ["", "def", "compute_ul_update_schedule", "(", "self", ",", "itr", ")", ":", "\n", "        ", "if", "itr", "<", "self", ".", "min_itr_ul", "or", "itr", ">", "self", ".", "max_itr_ul", ":", "\n", "            ", "return", "0", "\n", "", "remaining", "=", "(", "self", ".", "max_itr_ul", "-", "itr", ")", "/", "(", "self", ".", "max_itr_ul", "-", "self", ".", "min_itr_ul", ")", "# from 1 to 0", "\n", "if", "\"constant\"", "in", "self", ".", "ul_update_schedule", ":", "\n", "# Format: \"constant_X\", for X num updates per RL itr.", "\n", "            ", "n_ul_updates", "=", "int", "(", "self", ".", "ul_update_schedule", ".", "split", "(", "\"_\"", ")", "[", "1", "]", ")", "\n", "", "elif", "\"front\"", "in", "self", ".", "ul_update_schedule", ":", "\n", "# Format: \"front_X_Y\", for X updates first itr, Y updates rest.", "\n", "            ", "entries", "=", "self", ".", "ul_update_schedule", ".", "split", "(", "\"_\"", ")", "\n", "if", "itr", "==", "self", ".", "min_itr_ul", ":", "\n", "                ", "n_ul_updates", "=", "int", "(", "entries", "[", "1", "]", ")", "\n", "", "else", ":", "\n", "                ", "n_ul_updates", "=", "int", "(", "entries", "[", "2", "]", ")", "\n", "", "", "elif", "\"linear\"", "in", "self", ".", "ul_update_schedule", ":", "\n", "            ", "first", "=", "int", "(", "self", ".", "ul_update_schedule", ".", "split", "(", "\"_\"", ")", "[", "1", "]", ")", "\n", "n_ul_updates", "=", "int", "(", "np", ".", "round", "(", "first", "*", "remaining", ")", ")", "\n", "", "elif", "\"quadratic\"", "in", "self", ".", "ul_update_schedule", ":", "\n", "            ", "first", "=", "int", "(", "self", ".", "ul_update_schedule", ".", "split", "(", "\"_\"", ")", "[", "1", "]", ")", "\n", "n_ul_updates", "=", "int", "(", "np", ".", "round", "(", "first", "*", "remaining", "**", "2", ")", ")", "\n", "", "elif", "\"cosine\"", "in", "self", ".", "ul_update_schedule", ":", "\n", "            ", "first", "=", "int", "(", "self", ".", "ul_update_schedule", ".", "split", "(", "\"_\"", ")", "[", "1", "]", ")", "\n", "n_ul_updates", "=", "int", "(", "np", ".", "round", "(", "first", "*", "math", ".", "sin", "(", "math", ".", "pi", "/", "2", "*", "remaining", ")", ")", ")", "\n", "", "elif", "\"mod\"", "in", "self", ".", "ul_update_schedule", ":", "\n", "            ", "first", "=", "int", "(", "self", ".", "ul_update_schedule", ".", "split", "(", "\"_\"", ")", "[", "1", "]", ")", "\n", "n_ul_updates", "=", "1", "if", "itr", "%", "first", "==", "0", "else", "0", "\n", "", "return", "n_ul_updates", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.rl_with_ul.dqn_with_ul.DqnUl.optim_state_dict": [[495, 499], ["dict", "dqn_with_ul.DqnUl.optimizer.state_dict", "dqn_with_ul.DqnUl.ul_optimizer.state_dict"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.replay_saver.DummyOptimizer.state_dict", "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.replay_saver.DummyOptimizer.state_dict"], ["", "def", "optim_state_dict", "(", "self", ")", ":", "\n", "        ", "return", "dict", "(", "\n", "model", "=", "self", ".", "optimizer", ".", "state_dict", "(", ")", ",", "\n", "ul", "=", "self", ".", "ul_optimizer", ".", "state_dict", "(", ")", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.rl_with_ul.dqn_with_ul.DqnUl.load_optim_state_dict": [[501, 504], ["dqn_with_ul.DqnUl.optimizer.load_state_dict", "dqn_with_ul.DqnUl.ul_optimizer.load_state_dict"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.augmented_temporal_similarity.AugmentedTemporalSimilarity.load_state_dict", "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.augmented_temporal_similarity.AugmentedTemporalSimilarity.load_state_dict"], ["", "def", "load_optim_state_dict", "(", "self", ",", "state_dict", ")", ":", "\n", "        ", "self", ".", "optimizer", ".", "load_state_dict", "(", "state_dict", "[", "\"model\"", "]", ")", "\n", "self", ".", "ul_optimizer", ".", "load_state_dict", "(", "state_dict", "[", "\"ul\"", "]", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.astooke_rlpyt.rl_with_ul.sac_with_ul.SacWithUl.__init__": [[51, 115], ["int", "int", "int", "rlpyt.utils.quick_args.save__init__args", "dict", "locals"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.utils.quick_args.save__init__args"], ["def", "__init__", "(", "\n", "self", ",", "\n", "discount", "=", "0.99", ",", "\n", "batch_size", "=", "512", ",", "\n", "# replay_ratio=512,  # data_consumption / data_generation", "\n", "# min_steps_learn=int(1e4),", "\n", "replay_size", "=", "int", "(", "1e5", ")", ",", "\n", "target_update_tau", "=", "0.01", ",", "# tau=1 for hard update.", "\n", "target_update_interval", "=", "2", ",", "\n", "actor_update_interval", "=", "2", ",", "\n", "OptimCls", "=", "torch", ".", "optim", ".", "Adam", ",", "\n", "initial_optim_state_dict", "=", "None", ",", "# for all of them.", "\n", "action_prior", "=", "\"uniform\"", ",", "# or \"gaussian\"", "\n", "reward_scale", "=", "1", ",", "\n", "target_entropy", "=", "\"auto\"", ",", "# \"auto\", float, or None", "\n", "reparameterize", "=", "True", ",", "\n", "clip_grad_norm", "=", "1e6", ",", "\n", "n_step_return", "=", "1", ",", "\n", "bootstrap_timelimit", "=", "True", ",", "\n", "q_lr", "=", "1e-3", ",", "\n", "pi_lr", "=", "1e-3", ",", "\n", "alpha_lr", "=", "1e-4", ",", "\n", "q_beta", "=", "0.9", ",", "\n", "pi_beta", "=", "0.9", ",", "\n", "alpha_beta", "=", "0.5", ",", "\n", "alpha_init", "=", "0.1", ",", "\n", "encoder_update_tau", "=", "0.05", ",", "\n", "random_shift_prob", "=", "1.", ",", "\n", "random_shift_pad", "=", "4", ",", "# how much to pad on each direction (like DrQ style)", "\n", "stop_rl_conv_grad", "=", "False", ",", "\n", "min_steps_rl", "=", "int", "(", "1e4", ")", ",", "\n", "min_steps_ul", "=", "int", "(", "1e4", ")", ",", "\n", "max_steps_ul", "=", "None", ",", "\n", "ul_learning_rate", "=", "7e-4", ",", "\n", "ul_optim_kwargs", "=", "None", ",", "\n", "# ul_replay_size=1e5,", "\n", "ul_update_schedule", "=", "None", ",", "\n", "ul_lr_schedule", "=", "None", ",", "\n", "ul_lr_warmup", "=", "0", ",", "\n", "# ul_delta_T=1,  # Always 1", "\n", "# ul_batch_B=512,", "\n", "# ul_batch_T=1,  # Always 1", "\n", "ul_batch_size", "=", "512", ",", "\n", "ul_random_shift_prob", "=", "1.", ",", "\n", "ul_random_shift_pad", "=", "4", ",", "\n", "ul_target_update_interval", "=", "1", ",", "\n", "ul_target_update_tau", "=", "0.01", ",", "\n", "ul_latent_size", "=", "128", ",", "\n", "ul_anchor_hidden_sizes", "=", "512", ",", "\n", "ul_clip_grad_norm", "=", "10.", ",", "\n", "ul_pri_alpha", "=", "0.", ",", "\n", "ul_pri_beta", "=", "1.", ",", "\n", "ul_pri_n_step_return", "=", "1", ",", "\n", "ul_use_rl_samples", "=", "False", ",", "\n", "UlEncoderCls", "=", "UlEncoderModel", ",", "\n", "UlContrastCls", "=", "ContrastModel", ",", "\n", ")", ":", "\n", "# assert replay_ratio == batch_size  # Unless I want to change it.", "\n", "        ", "self", ".", "_batch_size", "=", "batch_size", "\n", "del", "batch_size", "\n", "if", "ul_optim_kwargs", "is", "None", ":", "\n", "            ", "ul_optim_kwargs", "=", "dict", "(", ")", "\n", "", "save__init__args", "(", "locals", "(", ")", ")", "\n", "self", ".", "replay_ratio", "=", "self", ".", "batch_size", "# standard 1 update per itr.", "\n", "# assert ul_delta_T == n_step_return  # Just use the same replay buffer", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.rl_with_ul.sac_with_ul.SacWithUl.initialize": [[118, 158], ["int", "rlpyt.utils.logging.logger.log", "agent.give_min_itr_learn", "sac_with_ul.SacWithUl.initialize_replay_buffer", "sac_with_ul.SacWithUl.UlEncoderCls", "copy.deepcopy", "sac_with_ul.SacWithUl.UlContrastCls", "sac_with_ul.SacWithUl.ul_encoder.to", "sac_with_ul.SacWithUl.ul_target_encoder.to", "sac_with_ul.SacWithUl.ul_contrast.to", "sac_with_ul.SacWithUl.optim_initialize"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.logging.console.log", "home.repos.pwc.inspect_result.astooke_rlpyt.agents.dmc_sac_agent.SacAgent.give_min_itr_learn", "home.repos.pwc.inspect_result.astooke_rlpyt.rl_with_ul.ppo_with_ul.PpoUl.initialize_replay_buffer", "home.repos.pwc.inspect_result.astooke_rlpyt.rl_with_ul.sac_with_ul.SacWithUl.optim_initialize"], ["", "def", "initialize", "(", "self", ",", "agent", ",", "n_itr", ",", "batch_spec", ",", "mid_batch_reset", ",", "examples", ",", "\n", "world_size", "=", "1", ",", "rank", "=", "0", ")", ":", "\n", "        ", "\"\"\"Stores input arguments and initializes replay buffer and optimizer.\n        Use in non-async runners.  Computes number of gradient updates per\n        optimization iteration as `(replay_ratio * sampler-batch-size /\n        training-batch_size)`.\"\"\"", "\n", "self", ".", "agent", "=", "agent", "\n", "self", ".", "n_itr", "=", "n_itr", "\n", "self", ".", "mid_batch_reset", "=", "mid_batch_reset", "\n", "self", ".", "sampler_bs", "=", "sampler_bs", "=", "batch_spec", ".", "size", "\n", "self", ".", "updates_per_optimize", "=", "int", "(", "self", ".", "replay_ratio", "*", "sampler_bs", "/", "\n", "self", ".", "batch_size", ")", "\n", "logger", ".", "log", "(", "f\"From sampler batch size {sampler_bs}, training \"", "\n", "f\"batch size {self.batch_size}, and replay ratio \"", "\n", "f\"{self.replay_ratio}, computed {self.updates_per_optimize} \"", "\n", "f\"updates per iteration.\"", ")", "\n", "self", ".", "min_itr_rl", "=", "self", ".", "min_steps_rl", "//", "sampler_bs", "\n", "self", ".", "min_itr_ul", "=", "self", ".", "min_steps_ul", "//", "sampler_bs", "\n", "self", ".", "max_itr_ul", "=", "(", "self", ".", "n_itr", "+", "1", "if", "self", ".", "max_steps_ul", "is", "None", "else", "\n", "self", ".", "max_steps_ul", "//", "sampler_bs", ")", "\n", "if", "self", ".", "min_itr_rl", "==", "self", ".", "min_itr_ul", ":", "\n", "            ", "self", ".", "min_itr_rl", "+=", "1", "# Wait until the next", "\n", "", "agent", ".", "give_min_itr_learn", "(", "self", ".", "min_itr_rl", ")", "\n", "self", ".", "initialize_replay_buffer", "(", "examples", ",", "batch_spec", ")", "\n", "\n", "self", ".", "ul_encoder", "=", "self", ".", "UlEncoderCls", "(", "\n", "conv", "=", "self", ".", "agent", ".", "conv", ",", "\n", "latent_size", "=", "self", ".", "ul_latent_size", ",", "\n", "conv_out_size", "=", "self", ".", "agent", ".", "conv", ".", "output_size", ",", "\n", ")", "\n", "self", ".", "ul_target_encoder", "=", "copy", ".", "deepcopy", "(", "self", ".", "ul_encoder", ")", "\n", "self", ".", "ul_contrast", "=", "self", ".", "UlContrastCls", "(", "\n", "latent_size", "=", "self", ".", "ul_latent_size", ",", "\n", "anchor_hidden_sizes", "=", "self", ".", "ul_anchor_hidden_sizes", ",", "\n", ")", "\n", "self", ".", "ul_encoder", ".", "to", "(", "self", ".", "agent", ".", "device", ")", "\n", "self", ".", "ul_target_encoder", ".", "to", "(", "self", ".", "agent", ".", "device", ")", "\n", "self", ".", "ul_contrast", ".", "to", "(", "self", ".", "agent", ".", "device", ")", "\n", "\n", "self", ".", "optim_initialize", "(", "rank", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.rl_with_ul.sac_with_ul.SacWithUl.async_initialize": [[159, 161], ["None"], "methods", ["None"], ["", "def", "async_initialize", "(", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.rl_with_ul.sac_with_ul.SacWithUl.optim_initialize": [[162, 230], ["sac_with_ul.SacWithUl.OptimCls", "sac_with_ul.SacWithUl.OptimCls", "torch.tensor", "torch.exp", "sac_with_ul.SacWithUl.OptimCls", "sac_with_ul.SacWithUl.OptimCls", "sum", "rlpyt.utils.logging.logger.log", "sac_with_ul.chain", "sac_with_ul.chain", "numpy.log", "sac_with_ul.SacWithUl._log_alpha.detach", "sac_with_ul.SacWithUl.load_optim_state_dict", "rlpyt.distributions.gaussian.Gaussian", "sac_with_ul.SacWithUl.ul_parameters", "torch.nn.CrossEntropyLoss", "sac_with_ul.SacWithUl.agent.pi_fc1.parameters", "sac_with_ul.SacWithUl.agent.pi_mlp.parameters", "sac_with_ul.SacWithUl.agent.q_fc1.parameters", "sac_with_ul.SacWithUl.agent.q_mlps.parameters", "numpy.prod", "sac_with_ul.SacWithUl.compute_ul_update_schedule", "torch.optim.lr_scheduler.LambdaLR", "rlpyt.ul.algos.utils.warmup_scheduler.GradualWarmupScheduler", "sac_with_ul.SacWithUl.ul_optimizer.zero_grad", "sac_with_ul.SacWithUl.ul_optimizer.step", "sac_with_ul.SacWithUl.agent.conv.parameters", "numpy.prod", "range", "torch.optim.lr_scheduler.CosineAnnealingLR"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.logging.console.log", "home.repos.pwc.inspect_result.astooke_rlpyt.rl_with_ul.sac_with_ul.chain", "home.repos.pwc.inspect_result.astooke_rlpyt.rl_with_ul.sac_with_ul.chain", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.console.log", "home.repos.pwc.inspect_result.astooke_rlpyt.rl_with_ul.sac_with_ul.SacWithUl.load_optim_state_dict", "home.repos.pwc.inspect_result.astooke_rlpyt.rl_with_ul.ppo_with_ul.PpoUl.ul_parameters", "home.repos.pwc.inspect_result.astooke_rlpyt.rl.atari_rl_models.AtariDqnModel.parameters", "home.repos.pwc.inspect_result.astooke_rlpyt.rl.atari_rl_models.AtariDqnModel.parameters", "home.repos.pwc.inspect_result.astooke_rlpyt.rl.atari_rl_models.AtariDqnModel.parameters", "home.repos.pwc.inspect_result.astooke_rlpyt.rl.atari_rl_models.AtariDqnModel.parameters", "home.repos.pwc.inspect_result.astooke_rlpyt.rl_with_ul.ppo_with_ul.PpoUl.compute_ul_update_schedule", "home.repos.pwc.inspect_result.astooke_rlpyt.safe.safety_gym_env.SafetyGymTrajInfo.step", "home.repos.pwc.inspect_result.astooke_rlpyt.rl.atari_rl_models.AtariDqnModel.parameters"], ["", "def", "optim_initialize", "(", "self", ",", "rank", "=", "0", ")", ":", "\n", "        ", "\"\"\"Called in initilize or by async runner after forking sampler.\"\"\"", "\n", "self", ".", "rank", "=", "rank", "\n", "\n", "# Be very explicit about which parameters are optimized where.", "\n", "self", ".", "pi_optimizer", "=", "self", ".", "OptimCls", "(", "chain", "(", "\n", "self", ".", "agent", ".", "pi_fc1", ".", "parameters", "(", ")", ",", "# No conv.", "\n", "self", ".", "agent", ".", "pi_mlp", ".", "parameters", "(", ")", ",", "\n", ")", ",", "\n", "lr", "=", "self", ".", "pi_lr", ",", "betas", "=", "(", "self", ".", "pi_beta", ",", "0.999", ")", ")", "\n", "self", ".", "q_optimizer", "=", "self", ".", "OptimCls", "(", "chain", "(", "\n", "(", ")", "if", "self", ".", "stop_rl_conv_grad", "else", "self", ".", "agent", ".", "conv", ".", "parameters", "(", ")", ",", "\n", "self", ".", "agent", ".", "q_fc1", ".", "parameters", "(", ")", ",", "\n", "self", ".", "agent", ".", "q_mlps", ".", "parameters", "(", ")", ",", "\n", ")", ",", "\n", "lr", "=", "self", ".", "q_lr", ",", "betas", "=", "(", "self", ".", "q_beta", ",", "0.999", ")", ",", "\n", ")", "\n", "\n", "self", ".", "_log_alpha", "=", "torch", ".", "tensor", "(", "np", ".", "log", "(", "self", ".", "alpha_init", ")", ",", "\n", "requires_grad", "=", "True", ")", "\n", "self", ".", "_alpha", "=", "torch", ".", "exp", "(", "self", ".", "_log_alpha", ".", "detach", "(", ")", ")", "\n", "self", ".", "alpha_optimizer", "=", "self", ".", "OptimCls", "(", "(", "self", ".", "_log_alpha", ",", ")", ",", "\n", "lr", "=", "self", ".", "alpha_lr", ",", "betas", "=", "(", "self", ".", "alpha_beta", ",", "0.999", ")", ")", "\n", "\n", "if", "self", ".", "target_entropy", "==", "\"auto\"", ":", "\n", "            ", "self", ".", "target_entropy", "=", "-", "np", ".", "prod", "(", "self", ".", "agent", ".", "env_spaces", ".", "action", ".", "shape", ")", "\n", "", "if", "self", ".", "initial_optim_state_dict", "is", "not", "None", ":", "\n", "            ", "self", ".", "load_optim_state_dict", "(", "self", ".", "initial_optim_state_dict", ")", "\n", "", "if", "self", ".", "action_prior", "==", "\"gaussian\"", ":", "\n", "            ", "self", ".", "action_prior_distribution", "=", "Gaussian", "(", "\n", "dim", "=", "np", ".", "prod", "(", "self", ".", "agent", ".", "env_spaces", ".", "action", ".", "shape", ")", ",", "std", "=", "1.", ")", "\n", "\n", "", "self", ".", "ul_optimizer", "=", "self", ".", "OptimCls", "(", "\n", "self", ".", "ul_parameters", "(", ")", ",", "\n", "lr", "=", "self", ".", "ul_learning_rate", ",", "**", "self", ".", "ul_optim_kwargs", ")", "\n", "\n", "self", ".", "total_ul_updates", "=", "sum", "(", "[", "self", ".", "compute_ul_update_schedule", "(", "itr", ")", "\n", "for", "itr", "in", "range", "(", "self", ".", "n_itr", ")", "]", ")", "\n", "logger", ".", "log", "(", "f\"Total number of UL updates to do: {self.total_ul_updates}.\"", ")", "\n", "self", ".", "ul_update_counter", "=", "0", "\n", "self", ".", "ul_lr_scheduler", "=", "None", "\n", "if", "self", ".", "total_ul_updates", ">", "0", ":", "\n", "            ", "if", "self", ".", "ul_lr_schedule", "==", "\"linear\"", ":", "\n", "                ", "self", ".", "ul_lr_scheduler", "=", "torch", ".", "optim", ".", "lr_scheduler", ".", "LambdaLR", "(", "\n", "optimizer", "=", "self", ".", "ul_optimizer", ",", "\n", "lr_lambda", "=", "lambda", "upd", ":", "(", "self", ".", "total_ul_updates", "-", "upd", ")", "/", "self", ".", "total_ul_updates", ",", "\n", ")", "\n", "", "elif", "self", ".", "ul_lr_schedule", "==", "\"cosine\"", ":", "\n", "                ", "self", ".", "ul_lr_scheduler", "=", "torch", ".", "optim", ".", "lr_scheduler", ".", "CosineAnnealingLR", "(", "\n", "optimizer", "=", "self", ".", "ul_optimizer", ",", "\n", "T_max", "=", "self", ".", "total_ul_updates", "-", "self", ".", "ul_lr_warmup", ",", "\n", ")", "\n", "", "elif", "self", ".", "ul_lr_schedule", "is", "not", "None", ":", "\n", "                ", "raise", "NotImplementedError", "\n", "\n", "", "if", "self", ".", "ul_lr_warmup", ">", "0", ":", "\n", "                ", "self", ".", "ul_lr_scheduler", "=", "GradualWarmupScheduler", "(", "\n", "self", ".", "ul_optimizer", ",", "\n", "multiplier", "=", "1", ",", "\n", "total_epoch", "=", "self", ".", "ul_lr_warmup", ",", "# actually n_updates", "\n", "after_scheduler", "=", "self", ".", "ul_lr_scheduler", ",", "\n", ")", "\n", "\n", "", "if", "self", ".", "ul_lr_scheduler", "is", "not", "None", ":", "\n", "                ", "self", ".", "ul_optimizer", ".", "zero_grad", "(", ")", "\n", "self", ".", "ul_optimizer", ".", "step", "(", ")", "\n", "\n", "", "self", ".", "c_e_loss", "=", "torch", ".", "nn", ".", "CrossEntropyLoss", "(", "ignore_index", "=", "IGNORE_INDEX", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.rl_with_ul.sac_with_ul.SacWithUl.initialize_replay_buffer": [[231, 254], ["sac_with_ul.SacWithUl.examples_to_buffer", "dict", "ReplayCls", "rlpyt.ul.replays.rl_with_ul_replay.RlWithUlPrioritizedReplayWrapper"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.rl_with_ul.ppo_with_ul.PpoUl.examples_to_buffer"], ["", "", "def", "initialize_replay_buffer", "(", "self", ",", "examples", ",", "batch_spec", ",", "async_", "=", "False", ")", ":", "\n", "        ", "\"\"\"\n        Allocates replay buffer using examples and with the fields in `SamplesToBuffer`\n        namedarraytuple.\n        POSSIBLY CHANGE TO FRAME-BASED BUFFER (only if need memory, speed is fine).\n        \"\"\"", "\n", "if", "async_", ":", "\n", "            ", "raise", "NotImplementedError", "\n", "", "example_to_buffer", "=", "self", ".", "examples_to_buffer", "(", "examples", ")", "\n", "ReplayCls", "=", "TlUniformReplayBuffer", "if", "self", ".", "bootstrap_timelimit", "else", "UniformReplayBuffer", "\n", "replay_kwargs", "=", "dict", "(", "\n", "example", "=", "example_to_buffer", ",", "\n", "size", "=", "self", ".", "replay_size", ",", "\n", "B", "=", "batch_spec", ".", "B", ",", "\n", "n_step_return", "=", "self", ".", "n_step_return", ",", "\n", ")", "\n", "self", ".", "replay_buffer", "=", "ReplayCls", "(", "**", "replay_kwargs", ")", "\n", "if", "self", ".", "ul_pri_alpha", ">", "0.", ":", "\n", "            ", "self", ".", "replay_buffer", "=", "RlWithUlPrioritizedReplayWrapper", "(", "\n", "replay_buffer", "=", "self", ".", "replay_buffer", ",", "\n", "n_step_return", "=", "self", ".", "ul_pri_n_step_return", ",", "\n", "alpha", "=", "self", ".", "ul_pri_alpha", ",", "\n", "beta", "=", "self", ".", "ul_pri_beta", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.rl_with_ul.sac_with_ul.SacWithUl.optimize_agent": [[256, 279], ["sac_with_ul.SacWithUl.samples_to_buffer", "sac_with_ul.SacWithUl.replay_buffer.append_samples", "OptInfo", "sac_with_ul.SacWithUl.rl_optimize", "opt_info._replace._replace._replace", "sac_with_ul.SacWithUl.ul_optimize", "opt_info._replace._replace._replace", "opt_info._replace._replace.ulUpdates.append", "opt_info_rl._asdict", "sac_with_ul.SacWithUl._asdict", "range", "len"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.rl_with_ul.ppo_with_ul.PpoUl.samples_to_buffer", "home.repos.pwc.inspect_result.astooke_rlpyt.sequence.prioritized.PrioritizedSequenceReplay.append_samples", "home.repos.pwc.inspect_result.astooke_rlpyt.rl_with_ul.sac_with_ul.SacWithUl.rl_optimize", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.collections.NamedTuple._replace", "home.repos.pwc.inspect_result.astooke_rlpyt.rl_with_ul.ppo_with_ul.PpoUl.ul_optimize", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.collections.NamedTuple._replace", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.collections.NamedTuple._asdict", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.collections.NamedTuple._asdict"], ["", "", "def", "optimize_agent", "(", "self", ",", "itr", ",", "samples", ")", ":", "\n", "        ", "\"\"\"\n        Extracts the needed fields from input samples and stores them in the \n        replay buffer.  Then samples from the replay buffer to train the agent\n        by gradient updates (with the number of updates determined by replay\n        ratio, sampler batch size, and training batch size).\n\n        DIFFERENCES FROM SAC:\n          -Organizes optimizers a little differently, clarifies which parameters.\n        \"\"\"", "\n", "samples_to_buffer", "=", "self", ".", "samples_to_buffer", "(", "samples", ")", "\n", "self", ".", "replay_buffer", ".", "append_samples", "(", "samples_to_buffer", ")", "\n", "opt_info", "=", "OptInfo", "(", "*", "(", "[", "]", "for", "_", "in", "range", "(", "len", "(", "OptInfo", ".", "_fields", ")", ")", ")", ")", "\n", "rl_samples", "=", "None", "\n", "if", "itr", ">=", "self", ".", "min_itr_rl", ":", "\n", "            ", "opt_info_rl", ",", "rl_samples", "=", "self", ".", "rl_optimize", "(", "itr", ")", "\n", "opt_info", "=", "opt_info", ".", "_replace", "(", "**", "opt_info_rl", ".", "_asdict", "(", ")", ")", "\n", "", "if", "itr", ">=", "self", ".", "min_itr_ul", ":", "\n", "            ", "opt_info_ul", "=", "self", ".", "ul_optimize", "(", "itr", ",", "rl_samples", ")", "\n", "opt_info", "=", "opt_info", ".", "_replace", "(", "**", "opt_info_ul", ".", "_asdict", "(", ")", ")", "\n", "", "else", ":", "\n", "            ", "opt_info", ".", "ulUpdates", ".", "append", "(", "0", ")", "\n", "", "return", "opt_info", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.rl_with_ul.sac_with_ul.SacWithUl.rl_optimize": [[280, 340], ["OptInfoRl", "range", "sac_with_ul.SacWithUl.replay_buffer.sample_batch", "sac_with_ul.SacWithUl.random_shift_rl_samples", "sac_with_ul.SacWithUl.samples_to_device", "sac_with_ul.SacWithUl.q_loss", "sac_with_ul.SacWithUl.q_optimizer.zero_grad", "q_loss.backward", "torch.nn.utils.clip_grad_norm_", "sac_with_ul.SacWithUl.q_optimizer.step", "OptInfoRl.q1Loss.append", "OptInfoRl.q2Loss.append", "OptInfoRl.qGradNorm.append", "OptInfoRl.q1.extend", "OptInfoRl.q2.extend", "OptInfoRl.qMeanDiff.append", "sac_with_ul.SacWithUl.pi_alpha_loss", "sac_with_ul.SacWithUl.pi_optimizer.zero_grad", "pi_loss.backward", "torch.nn.utils.clip_grad_norm_", "sac_with_ul.SacWithUl.pi_optimizer.step", "OptInfoRl.piLoss.append", "OptInfoRl.piGradNorm.append", "OptInfoRl.piMu.extend", "OptInfoRl.piLogStd.extend", "sac_with_ul.chain", "q1_loss.item", "q2_loss.item", "torch.nn.utils.clip_grad_norm_.item", "q1[].numpy", "q2[].numpy", "torch.mean().item", "sac_with_ul.SacWithUl.agent.update_targets", "sac_with_ul.SacWithUl.alpha_optimizer.zero_grad", "alpha_loss.backward", "sac_with_ul.SacWithUl.alpha_optimizer.step", "torch.exp", "OptInfoRl.alpha.append", "sac_with_ul.chain", "pi_loss.item", "torch.nn.utils.clip_grad_norm_.item", "pi_mean[].numpy", "pi_log_std[].numpy", "sac_with_ul.SacWithUl.agent.q_fc1.parameters", "sac_with_ul.SacWithUl.agent.q_mlps.parameters", "range", "sac_with_ul.SacWithUl._log_alpha.detach", "sac_with_ul.SacWithUl._alpha.item", "sac_with_ul.SacWithUl.agent.pi_fc1.parameters", "sac_with_ul.SacWithUl.agent.pi_mlp.parameters", "sac_with_ul.SacWithUl.agent.conv.parameters", "torch.mean", "len", "abs"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.sequence.uniform.UniformSequenceReplay.sample_batch", "home.repos.pwc.inspect_result.astooke_rlpyt.rl_with_ul.sac_with_ul.SacWithUl.random_shift_rl_samples", "home.repos.pwc.inspect_result.astooke_rlpyt.rl_with_ul.sac_with_ul.SacWithUl.samples_to_device", "home.repos.pwc.inspect_result.astooke_rlpyt.rl_with_ul.sac_with_ul.SacWithUl.q_loss", "home.repos.pwc.inspect_result.astooke_rlpyt.models.utils.ScaleGrad.backward", "home.repos.pwc.inspect_result.astooke_rlpyt.safe.safety_gym_env.SafetyGymTrajInfo.step", "home.repos.pwc.inspect_result.astooke_rlpyt.rl_with_ul.sac_with_ul.SacWithUl.pi_alpha_loss", "home.repos.pwc.inspect_result.astooke_rlpyt.models.utils.ScaleGrad.backward", "home.repos.pwc.inspect_result.astooke_rlpyt.safe.safety_gym_env.SafetyGymTrajInfo.step", "home.repos.pwc.inspect_result.astooke_rlpyt.rl_with_ul.sac_with_ul.chain", "home.repos.pwc.inspect_result.astooke_rlpyt.agents.dmc_sac_agent.SacAgent.update_targets", "home.repos.pwc.inspect_result.astooke_rlpyt.models.utils.ScaleGrad.backward", "home.repos.pwc.inspect_result.astooke_rlpyt.safe.safety_gym_env.SafetyGymTrajInfo.step", "home.repos.pwc.inspect_result.astooke_rlpyt.rl_with_ul.sac_with_ul.chain", "home.repos.pwc.inspect_result.astooke_rlpyt.rl.atari_rl_models.AtariDqnModel.parameters", "home.repos.pwc.inspect_result.astooke_rlpyt.rl.atari_rl_models.AtariDqnModel.parameters", "home.repos.pwc.inspect_result.astooke_rlpyt.rl.atari_rl_models.AtariDqnModel.parameters", "home.repos.pwc.inspect_result.astooke_rlpyt.rl.atari_rl_models.AtariDqnModel.parameters", "home.repos.pwc.inspect_result.astooke_rlpyt.rl.atari_rl_models.AtariDqnModel.parameters"], ["", "def", "rl_optimize", "(", "self", ",", "itr", ")", ":", "\n", "        ", "opt_info_rl", "=", "OptInfoRl", "(", "*", "(", "[", "]", "for", "_", "in", "range", "(", "len", "(", "OptInfoRl", ".", "_fields", ")", ")", ")", ")", "\n", "for", "_", "in", "range", "(", "self", ".", "updates_per_optimize", ")", ":", "\n", "# Sample from the replay buffer, center crop, and move to GPU.", "\n", "            ", "samples_from_replay", "=", "self", ".", "replay_buffer", ".", "sample_batch", "(", "self", ".", "batch_size", ")", "\n", "rl_samples", "=", "self", ".", "random_shift_rl_samples", "(", "samples_from_replay", ")", "\n", "rl_samples", "=", "self", ".", "samples_to_device", "(", "rl_samples", ")", "\n", "\n", "# Q-loss includes computing some values used in pi-loss.", "\n", "q1_loss", ",", "q2_loss", ",", "valid", ",", "conv_out", ",", "q1", ",", "q2", "=", "self", ".", "q_loss", "(", "rl_samples", ")", "\n", "\n", "if", "self", ".", "update_counter", "%", "self", ".", "actor_update_interval", "==", "0", ":", "\n", "                ", "pi_loss", ",", "alpha_loss", ",", "pi_mean", ",", "pi_log_std", "=", "self", ".", "pi_alpha_loss", "(", "\n", "rl_samples", ",", "valid", ",", "conv_out", ")", "\n", "if", "alpha_loss", "is", "not", "None", ":", "\n", "                    ", "self", ".", "alpha_optimizer", ".", "zero_grad", "(", ")", "\n", "alpha_loss", ".", "backward", "(", ")", "\n", "self", ".", "alpha_optimizer", ".", "step", "(", ")", "\n", "self", ".", "_alpha", "=", "torch", ".", "exp", "(", "self", ".", "_log_alpha", ".", "detach", "(", ")", ")", "\n", "opt_info_rl", ".", "alpha", ".", "append", "(", "self", ".", "_alpha", ".", "item", "(", ")", ")", "\n", "\n", "", "self", ".", "pi_optimizer", ".", "zero_grad", "(", ")", "\n", "pi_loss", ".", "backward", "(", ")", "\n", "pi_grad_norm", "=", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "chain", "(", "\n", "self", ".", "agent", ".", "pi_fc1", ".", "parameters", "(", ")", ",", "\n", "self", ".", "agent", ".", "pi_mlp", ".", "parameters", "(", ")", ",", "\n", ")", ",", "\n", "self", ".", "clip_grad_norm", ")", "\n", "self", ".", "pi_optimizer", ".", "step", "(", ")", "\n", "opt_info_rl", ".", "piLoss", ".", "append", "(", "pi_loss", ".", "item", "(", ")", ")", "\n", "opt_info_rl", ".", "piGradNorm", ".", "append", "(", "pi_grad_norm", ".", "item", "(", ")", ")", "\n", "opt_info_rl", ".", "piMu", ".", "extend", "(", "pi_mean", "[", ":", ":", "10", "]", ".", "numpy", "(", ")", ")", "\n", "opt_info_rl", ".", "piLogStd", ".", "extend", "(", "pi_log_std", "[", ":", ":", "10", "]", ".", "numpy", "(", ")", ")", "\n", "\n", "# Step Q's last because pi_loss.backward() uses them.", "\n", "", "self", ".", "q_optimizer", ".", "zero_grad", "(", ")", "\n", "q_loss", "=", "q1_loss", "+", "q2_loss", "\n", "q_loss", ".", "backward", "(", ")", "\n", "q_grad_norm", "=", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "chain", "(", "\n", "(", ")", "if", "self", ".", "stop_rl_conv_grad", "else", "self", ".", "agent", ".", "conv", ".", "parameters", "(", ")", ",", "\n", "self", ".", "agent", ".", "q_fc1", ".", "parameters", "(", ")", ",", "\n", "self", ".", "agent", ".", "q_mlps", ".", "parameters", "(", ")", ",", "\n", ")", ",", "\n", "self", ".", "clip_grad_norm", ")", "\n", "self", ".", "q_optimizer", ".", "step", "(", ")", "\n", "opt_info_rl", ".", "q1Loss", ".", "append", "(", "q1_loss", ".", "item", "(", ")", ")", "\n", "opt_info_rl", ".", "q2Loss", ".", "append", "(", "q2_loss", ".", "item", "(", ")", ")", "\n", "opt_info_rl", ".", "qGradNorm", ".", "append", "(", "q_grad_norm", ".", "item", "(", ")", ")", "\n", "opt_info_rl", ".", "q1", ".", "extend", "(", "q1", "[", ":", ":", "10", "]", ".", "numpy", "(", ")", ")", "# Downsample for stats.", "\n", "opt_info_rl", ".", "q2", ".", "extend", "(", "q2", "[", ":", ":", "10", "]", ".", "numpy", "(", ")", ")", "\n", "opt_info_rl", ".", "qMeanDiff", ".", "append", "(", "torch", ".", "mean", "(", "abs", "(", "q1", "-", "q2", ")", ")", ".", "item", "(", ")", ")", "\n", "\n", "self", ".", "update_counter", "+=", "1", "\n", "if", "self", ".", "update_counter", "%", "self", ".", "target_update_interval", "==", "0", ":", "\n", "                ", "self", ".", "agent", ".", "update_targets", "(", "\n", "q_tau", "=", "self", ".", "target_update_tau", ",", "\n", "encoder_tau", "=", "self", ".", "encoder_update_tau", ",", "\n", ")", "\n", "\n", "", "", "return", "opt_info_rl", ",", "rl_samples", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.rl_with_ul.sac_with_ul.SacWithUl.ul_optimize": [[341, 363], ["OptInfoUl", "sac_with_ul.SacWithUl.compute_ul_update_schedule", "range", "OptInfoUl.ulUpdates.append", "len", "sac_with_ul.SacWithUl.ul_optimize_one_step", "OptInfoUl.ulLoss.append", "OptInfoUl.ulAccuracy.append", "OptInfoUl.ulGradNorm.append", "sac_with_ul.SacWithUl.ul_lr_scheduler.step", "ul_loss.item", "ul_accuracy.item", "grad_norm.item", "rlpyt.models.utils.update_state_dict", "sac_with_ul.SacWithUl.ul_encoder.state_dict", "range", "len"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.rl_with_ul.ppo_with_ul.PpoUl.compute_ul_update_schedule", "home.repos.pwc.inspect_result.astooke_rlpyt.rl_with_ul.ppo_with_ul.PpoUl.ul_optimize_one_step", "home.repos.pwc.inspect_result.astooke_rlpyt.safe.safety_gym_env.SafetyGymTrajInfo.step", "home.repos.pwc.inspect_result.astooke_rlpyt.models.utils.update_state_dict", "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.replay_saver.DummyOptimizer.state_dict"], ["", "def", "ul_optimize", "(", "self", ",", "itr", ",", "rl_samples", "=", "None", ")", ":", "\n", "        ", "opt_info_ul", "=", "OptInfoUl", "(", "*", "(", "[", "]", "for", "_", "in", "range", "(", "len", "(", "OptInfoUl", ".", "_fields", ")", ")", ")", ")", "\n", "n_ul_updates", "=", "self", ".", "compute_ul_update_schedule", "(", "itr", ")", "\n", "ul_bs", "=", "self", ".", "ul_batch_size", "\n", "n_rl_samples", "=", "0", "if", "rl_samples", "is", "None", "else", "len", "(", "rl_samples", ".", "agent_inputs", ".", "observation", ")", "\n", "for", "i", "in", "range", "(", "n_ul_updates", ")", ":", "\n", "            ", "self", ".", "ul_update_counter", "+=", "1", "\n", "if", "self", ".", "ul_lr_scheduler", "is", "not", "None", ":", "\n", "                ", "self", ".", "ul_lr_scheduler", ".", "step", "(", "self", ".", "ul_update_counter", ")", "\n", "", "if", "n_rl_samples", ">=", "self", ".", "ul_batch_size", "*", "(", "i", "+", "1", ")", ":", "\n", "                ", "ul_samples", "=", "rl_samples", "[", "i", "*", "ul_bs", ":", "(", "i", "+", "1", ")", "*", "ul_bs", "]", "\n", "", "else", ":", "\n", "                ", "ul_samples", "=", "None", "\n", "", "ul_loss", ",", "ul_accuracy", ",", "grad_norm", "=", "self", ".", "ul_optimize_one_step", "(", "ul_samples", ")", "\n", "opt_info_ul", ".", "ulLoss", ".", "append", "(", "ul_loss", ".", "item", "(", ")", ")", "\n", "opt_info_ul", ".", "ulAccuracy", ".", "append", "(", "ul_accuracy", ".", "item", "(", ")", ")", "\n", "opt_info_ul", ".", "ulGradNorm", ".", "append", "(", "grad_norm", ".", "item", "(", ")", ")", "\n", "if", "self", ".", "ul_update_counter", "%", "self", ".", "ul_target_update_interval", "==", "0", ":", "\n", "                ", "update_state_dict", "(", "self", ".", "ul_target_encoder", ",", "self", ".", "ul_encoder", ".", "state_dict", "(", ")", ",", "\n", "self", ".", "ul_target_update_tau", ")", "\n", "", "", "opt_info_ul", ".", "ulUpdates", ".", "append", "(", "self", ".", "ul_update_counter", ")", "\n", "return", "opt_info_ul", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.rl_with_ul.sac_with_ul.SacWithUl.ul_optimize_one_step": [[364, 419], ["sac_with_ul.SacWithUl.ul_optimizer.zero_grad", "sac_with_ul.SacWithUl.ul_encoder", "sac_with_ul.SacWithUl.ul_contrast", "torch.arange", "sac_with_ul.SacWithUl.c_e_loss", "sac_with_ul.SacWithUl.backward", "sac_with_ul.SacWithUl.ul_optimizer.step", "torch.mean", "rlpyt.utils.buffer.buffer_to", "torch.no_grad", "sac_with_ul.SacWithUl.ul_target_encoder", "torch.nn.utils.clip_grad_norm_", "torch.argmax", "correct[].float", "sac_with_ul.SacWithUl.replay_buffer.sample_batch", "sac_with_ul.SacWithUl.replay_buffer.sample_batch", "rlpyt.ul.algos.utils.data_augs.random_shift", "rlpyt.ul.algos.utils.data_augs.random_shift", "sac_with_ul.SacWithUl.ul_parameters", "sac_with_ul.SacWithUl.detach"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.models.utils.ScaleGrad.backward", "home.repos.pwc.inspect_result.astooke_rlpyt.safe.safety_gym_env.SafetyGymTrajInfo.step", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.buffer.buffer_to", "home.repos.pwc.inspect_result.astooke_rlpyt.sequence.uniform.UniformSequenceReplay.sample_batch", "home.repos.pwc.inspect_result.astooke_rlpyt.sequence.uniform.UniformSequenceReplay.sample_batch", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.data_augs.random_shift", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.data_augs.random_shift", "home.repos.pwc.inspect_result.astooke_rlpyt.rl_with_ul.ppo_with_ul.PpoUl.ul_parameters"], ["", "def", "ul_optimize_one_step", "(", "self", ",", "samples", "=", "None", ")", ":", "\n", "        ", "self", ".", "ul_optimizer", ".", "zero_grad", "(", ")", "\n", "if", "samples", "is", "None", ":", "\n", "            ", "if", "self", ".", "ul_pri_alpha", ">", "0", ":", "\n", "                ", "samples", "=", "self", ".", "replay_buffer", ".", "sample_batch", "(", "self", ".", "ul_batch_size", ",", "\n", "mode", "=", "\"UL\"", ")", "\n", "", "else", ":", "\n", "                ", "samples", "=", "self", ".", "replay_buffer", ".", "sample_batch", "(", "self", ".", "ul_batch_size", ")", "\n", "\n", "# This is why need ul_delta_T == n_step_return, usually == 1;", "\n", "", "anchor", "=", "samples", ".", "agent_inputs", ".", "observation", "\n", "positive", "=", "samples", ".", "target_inputs", ".", "observation", "\n", "\n", "if", "self", ".", "ul_random_shift_prob", ">", "0.", ":", "\n", "                ", "anchor", "=", "random_shift", "(", "\n", "imgs", "=", "anchor", ",", "\n", "pad", "=", "self", ".", "ul_random_shift_pad", ",", "\n", "prob", "=", "self", ".", "ul_random_shift_prob", ",", "\n", ")", "\n", "positive", "=", "random_shift", "(", "\n", "imgs", "=", "positive", ",", "\n", "pad", "=", "self", ".", "ul_random_shift_pad", ",", "\n", "prob", "=", "self", ".", "ul_random_shift_prob", ",", "\n", ")", "\n", "\n", "", "anchor", ",", "positive", "=", "buffer_to", "(", "(", "anchor", ",", "positive", ")", ",", "\n", "device", "=", "self", ".", "agent", ".", "device", ")", "\n", "\n", "", "else", ":", "\n", "# Assume samples were already augmented in the RL loss.", "\n", "            ", "anchor", "=", "samples", ".", "agent_inputs", ".", "observation", "\n", "positive", "=", "samples", ".", "target_inputs", ".", "observation", "\n", "\n", "", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "c_positive", ",", "_pos_conv", "=", "self", ".", "ul_target_encoder", "(", "positive", ")", "\n", "", "c_anchor", ",", "_anc_conv", "=", "self", ".", "ul_encoder", "(", "anchor", ")", "\n", "logits", "=", "self", ".", "ul_contrast", "(", "c_anchor", ",", "c_positive", ")", "# anchor mlp in here.", "\n", "\n", "labels", "=", "torch", ".", "arange", "(", "c_anchor", ".", "shape", "[", "0", "]", ",", "\n", "dtype", "=", "torch", ".", "long", ",", "device", "=", "self", ".", "agent", ".", "device", ")", "\n", "invalid", "=", "samples", ".", "done", "# shape: [B], if done, following state invalid", "\n", "labels", "[", "invalid", "]", "=", "IGNORE_INDEX", "\n", "ul_loss", "=", "self", ".", "c_e_loss", "(", "logits", ",", "labels", ")", "\n", "ul_loss", ".", "backward", "(", ")", "\n", "if", "self", ".", "ul_clip_grad_norm", "is", "None", ":", "\n", "            ", "grad_norm", "=", "0.", "\n", "", "else", ":", "\n", "            ", "grad_norm", "=", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "\n", "self", ".", "ul_parameters", "(", ")", ",", "self", ".", "ul_clip_grad_norm", ")", "\n", "", "self", ".", "ul_optimizer", ".", "step", "(", ")", "\n", "\n", "correct", "=", "torch", ".", "argmax", "(", "logits", ".", "detach", "(", ")", ",", "dim", "=", "1", ")", "==", "labels", "\n", "accuracy", "=", "torch", ".", "mean", "(", "correct", "[", "~", "invalid", "]", ".", "float", "(", ")", ")", "\n", "\n", "return", "ul_loss", ",", "accuracy", ",", "grad_norm", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.rl_with_ul.sac_with_ul.SacWithUl.samples_to_buffer": [[420, 434], ["SamplesToBuffer", "SamplesToBufferTl"], "methods", ["None"], ["", "def", "samples_to_buffer", "(", "self", ",", "samples", ")", ":", "\n", "        ", "\"\"\"Defines how to add data from sampler into the replay buffer. Called\n        in optimize_agent() if samples are provided to that method.\"\"\"", "\n", "observation", "=", "samples", ".", "env", ".", "observation", "\n", "samples_to_buffer", "=", "SamplesToBuffer", "(", "\n", "observation", "=", "observation", ",", "\n", "action", "=", "samples", ".", "agent", ".", "action", ",", "\n", "reward", "=", "samples", ".", "env", ".", "reward", ",", "\n", "done", "=", "samples", ".", "env", ".", "done", ",", "\n", ")", "\n", "if", "self", ".", "bootstrap_timelimit", ":", "\n", "            ", "samples_to_buffer", "=", "SamplesToBufferTl", "(", "*", "samples_to_buffer", ",", "\n", "timeout", "=", "samples", ".", "env", ".", "env_info", ".", "timeout", ")", "\n", "", "return", "samples_to_buffer", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.rl_with_ul.sac_with_ul.SacWithUl.examples_to_buffer": [[435, 447], ["SamplesToBuffer", "SamplesToBufferTl"], "methods", ["None"], ["", "def", "examples_to_buffer", "(", "self", ",", "examples", ")", ":", "\n", "        ", "observation", "=", "examples", "[", "\"observation\"", "]", "\n", "example_to_buffer", "=", "SamplesToBuffer", "(", "\n", "observation", "=", "observation", ",", "\n", "action", "=", "examples", "[", "\"action\"", "]", ",", "\n", "reward", "=", "examples", "[", "\"reward\"", "]", ",", "\n", "done", "=", "examples", "[", "\"done\"", "]", ",", "\n", ")", "\n", "if", "self", ".", "bootstrap_timelimit", ":", "\n", "            ", "example_to_buffer", "=", "SamplesToBufferTl", "(", "*", "example_to_buffer", ",", "\n", "timeout", "=", "examples", "[", "\"env_info\"", "]", ".", "timeout", ")", "\n", "", "return", "example_to_buffer", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.rl_with_ul.sac_with_ul.SacWithUl.samples_to_device": [[448, 460], ["rlpyt.utils.buffer.buffer_to", "samples._replace"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.utils.buffer.buffer_to", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.collections.NamedTuple._replace"], ["", "def", "samples_to_device", "(", "self", ",", "samples", ")", ":", "\n", "        ", "\"\"\"Only move the parts of samples which need to go to GPU.\"\"\"", "\n", "agent_inputs", ",", "target_inputs", ",", "action", "=", "buffer_to", "(", "\n", "(", "samples", ".", "agent_inputs", ",", "samples", ".", "target_inputs", ",", "samples", ".", "action", ")", ",", "\n", "device", "=", "self", ".", "agent", ".", "device", ",", "\n", ")", "\n", "device_samples", "=", "samples", ".", "_replace", "(", "\n", "agent_inputs", "=", "agent_inputs", ",", "\n", "target_inputs", "=", "target_inputs", ",", "\n", "action", "=", "action", ",", "\n", ")", "\n", "return", "device_samples", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.rl_with_ul.sac_with_ul.SacWithUl.random_shift_rl_samples": [[461, 481], ["rlpyt.ul.algos.utils.data_augs.random_shift", "rlpyt.ul.algos.utils.data_augs.random_shift", "samples._replace", "samples.agent_inputs._replace", "samples.target_inputs._replace"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.utils.data_augs.random_shift", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.data_augs.random_shift", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.collections.NamedTuple._replace", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.collections.NamedTuple._replace", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.collections.NamedTuple._replace"], ["", "def", "random_shift_rl_samples", "(", "self", ",", "samples", ")", ":", "\n", "        ", "if", "self", ".", "random_shift_prob", "==", "0.", ":", "\n", "            ", "return", "samples", "\n", "", "obs", "=", "samples", ".", "agent_inputs", ".", "observation", "\n", "target_obs", "=", "samples", ".", "target_inputs", ".", "observation", "\n", "aug_obs", "=", "random_shift", "(", "\n", "imgs", "=", "obs", ",", "\n", "pad", "=", "self", ".", "random_shift_pad", ",", "\n", "prob", "=", "self", ".", "random_shift_prob", ",", "\n", ")", "\n", "aug_target_obs", "=", "random_shift", "(", "\n", "imgs", "=", "target_obs", ",", "\n", "pad", "=", "self", ".", "random_shift_pad", ",", "\n", "prob", "=", "self", ".", "random_shift_prob", ",", "\n", ")", "\n", "aug_samples", "=", "samples", ".", "_replace", "(", "\n", "agent_inputs", "=", "samples", ".", "agent_inputs", ".", "_replace", "(", "observation", "=", "aug_obs", ")", ",", "\n", "target_inputs", "=", "samples", ".", "target_inputs", ".", "_replace", "(", "observation", "=", "aug_target_obs", ")", ",", "\n", ")", "\n", "return", "aug_samples", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.rl_with_ul.sac_with_ul.SacWithUl.q_loss": [[482, 515], ["sac_with_ul.SacWithUl.agent.conv", "samples.agent_inputs._replace", "sac_with_ul.SacWithUl.agent.q", "torch.ones_like", "rlpyt.algos.utils.valid_from_done", "conv_out.detach.detach.detach", "torch.no_grad", "sac_with_ul.SacWithUl.agent.target_conv", "samples.target_inputs._replace", "sac_with_ul.SacWithUl.agent.pi", "sac_with_ul.SacWithUl.agent.target_q", "torch.min", "rlpyt.utils.tensor.valid_mean", "rlpyt.utils.tensor.valid_mean", "q1.detach", "q2.detach", "samples.timeout_n.float", "samples.done_n.float"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.utils.collections.NamedTuple._replace", "home.repos.pwc.inspect_result.astooke_rlpyt.agents.dmc_sac_agent.SacAgent.q", "home.repos.pwc.inspect_result.astooke_rlpyt.algos.utils.valid_from_done", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.collections.NamedTuple._replace", "home.repos.pwc.inspect_result.astooke_rlpyt.agents.dmc_sac_agent.SacAgent.pi", "home.repos.pwc.inspect_result.astooke_rlpyt.agents.dmc_sac_agent.SacAgent.target_q", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.tensor.valid_mean", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.tensor.valid_mean"], ["", "def", "q_loss", "(", "self", ",", "samples", ")", ":", "\n", "        ", "if", "self", ".", "mid_batch_reset", "and", "not", "self", ".", "agent", ".", "recurrent", ":", "\n", "            ", "valid", "=", "torch", ".", "ones_like", "(", "samples", ".", "done", ",", "dtype", "=", "torch", ".", "float", ")", "# or None", "\n", "", "else", ":", "\n", "            ", "valid", "=", "valid_from_done", "(", "samples", ".", "done", ")", "\n", "", "if", "self", ".", "bootstrap_timelimit", ":", "\n", "# To avoid non-use of bootstrap when environment is 'done' due to", "\n", "# time-limit, turn off training on these samples.", "\n", "            ", "valid", "*=", "(", "1", "-", "samples", ".", "timeout_n", ".", "float", "(", ")", ")", "\n", "\n", "# Run the convolution only once, return so pi_loss can use it.", "\n", "", "conv_out", "=", "self", ".", "agent", ".", "conv", "(", "samples", ".", "agent_inputs", ".", "observation", ")", "\n", "if", "self", ".", "stop_rl_conv_grad", ":", "\n", "            ", "conv_out", "=", "conv_out", ".", "detach", "(", ")", "\n", "", "q_inputs", "=", "samples", ".", "agent_inputs", ".", "_replace", "(", "observation", "=", "conv_out", ")", "\n", "\n", "# Q LOSS.", "\n", "q1", ",", "q2", "=", "self", ".", "agent", ".", "q", "(", "*", "q_inputs", ",", "samples", ".", "action", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "# Run the target convolution only once.", "\n", "            ", "target_conv_out", "=", "self", ".", "agent", ".", "target_conv", "(", "samples", ".", "target_inputs", ".", "observation", ")", "\n", "target_inputs", "=", "samples", ".", "target_inputs", ".", "_replace", "(", "observation", "=", "target_conv_out", ")", "\n", "target_action", ",", "target_log_pi", ",", "_", "=", "self", ".", "agent", ".", "pi", "(", "*", "target_inputs", ")", "\n", "target_q1", ",", "target_q2", "=", "self", ".", "agent", ".", "target_q", "(", "*", "target_inputs", ",", "target_action", ")", "\n", "min_target_q", "=", "torch", ".", "min", "(", "target_q1", ",", "target_q2", ")", "\n", "target_value", "=", "min_target_q", "-", "self", ".", "_alpha", "*", "target_log_pi", "\n", "", "disc", "=", "self", ".", "discount", "**", "self", ".", "n_step_return", "\n", "y", "=", "(", "self", ".", "reward_scale", "*", "samples", ".", "return_", "+", "\n", "(", "1", "-", "samples", ".", "done_n", ".", "float", "(", ")", ")", "*", "disc", "*", "target_value", ")", "\n", "q1_loss", "=", "0.5", "*", "valid_mean", "(", "(", "y", "-", "q1", ")", "**", "2", ",", "valid", ")", "\n", "q2_loss", "=", "0.5", "*", "valid_mean", "(", "(", "y", "-", "q2", ")", "**", "2", ",", "valid", ")", "\n", "\n", "return", "q1_loss", ",", "q2_loss", ",", "valid", ",", "conv_out", ",", "q1", ".", "detach", "(", ")", ",", "q2", ".", "detach", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.rl_with_ul.sac_with_ul.SacWithUl.pi_alpha_loss": [[516, 546], ["conv_out.detach", "samples.agent_inputs._replace", "sac_with_ul.SacWithUl.agent.pi", "sac_with_ul.SacWithUl.agent.q", "torch.min", "sac_with_ul.SacWithUl.get_action_prior", "rlpyt.utils.tensor.valid_mean", "new_action.cpu", "rlpyt.utils.tensor.valid_mean", "pi_mean.detach", "pi_log_std.detach", "log_pi.detach"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.utils.collections.NamedTuple._replace", "home.repos.pwc.inspect_result.astooke_rlpyt.agents.dmc_sac_agent.SacAgent.pi", "home.repos.pwc.inspect_result.astooke_rlpyt.agents.dmc_sac_agent.SacAgent.q", "home.repos.pwc.inspect_result.astooke_rlpyt.rl_with_ul.sac_with_ul.SacWithUl.get_action_prior", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.tensor.valid_mean", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.tensor.valid_mean"], ["", "def", "pi_alpha_loss", "(", "self", ",", "samples", ",", "valid", ",", "conv_out", ")", ":", "\n", "# PI LOSS.", "\n", "# Uses detached conv out; avoid re-computing.", "\n", "        ", "conv_detach", "=", "conv_out", ".", "detach", "(", ")", "\n", "agent_inputs", "=", "samples", ".", "agent_inputs", ".", "_replace", "(", "observation", "=", "conv_detach", ")", "\n", "new_action", ",", "log_pi", ",", "(", "pi_mean", ",", "pi_log_std", ")", "=", "self", ".", "agent", ".", "pi", "(", "*", "agent_inputs", ")", "\n", "if", "not", "self", ".", "reparameterize", ":", "\n", "# new_action = new_action.detach()  # No grad.", "\n", "            ", "raise", "NotImplementedError", "\n", "# Re-use the detached latent.", "\n", "", "log_target1", ",", "log_target2", "=", "self", ".", "agent", ".", "q", "(", "*", "agent_inputs", ",", "new_action", ")", "\n", "min_log_target", "=", "torch", ".", "min", "(", "log_target1", ",", "log_target2", ")", "\n", "prior_log_pi", "=", "self", ".", "get_action_prior", "(", "new_action", ".", "cpu", "(", ")", ")", "\n", "if", "self", ".", "reparameterize", ":", "\n", "            ", "pi_losses", "=", "self", ".", "_alpha", "*", "log_pi", "-", "min_log_target", "-", "prior_log_pi", "\n", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "\n", "# if self.policy_output_regularization > 0:", "\n", "#     pi_losses += self.policy_output_regularization * torch.mean(", "\n", "#         0.5 * pi_mean ** 2 + 0.5 * pi_log_std ** 2, dim=-1)", "\n", "", "pi_loss", "=", "valid_mean", "(", "pi_losses", ",", "valid", ")", "\n", "\n", "# ALPHA LOSS.", "\n", "if", "self", ".", "target_entropy", "is", "not", "None", ":", "\n", "            ", "alpha_losses", "=", "-", "self", ".", "_log_alpha", "*", "(", "log_pi", ".", "detach", "(", ")", "+", "self", ".", "target_entropy", ")", "\n", "alpha_loss", "=", "valid_mean", "(", "alpha_losses", ",", "valid", ")", "\n", "", "else", ":", "\n", "            ", "alpha_loss", "=", "None", "\n", "\n", "", "return", "pi_loss", ",", "alpha_loss", ",", "pi_mean", ".", "detach", "(", ")", ",", "pi_log_std", ".", "detach", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.rl_with_ul.sac_with_ul.SacWithUl.get_action_prior": [[547, 554], ["sac_with_ul.SacWithUl.action_prior_distribution.log_likelihood", "rlpyt.distributions.gaussian.DistInfo", "torch.zeros_like"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.distributions.gaussian.Gaussian.log_likelihood"], ["", "def", "get_action_prior", "(", "self", ",", "action", ")", ":", "\n", "        ", "if", "self", ".", "action_prior", "==", "\"uniform\"", ":", "\n", "            ", "prior_log_pi", "=", "0.0", "\n", "", "elif", "self", ".", "action_prior", "==", "\"gaussian\"", ":", "\n", "            ", "prior_log_pi", "=", "self", ".", "action_prior_distribution", ".", "log_likelihood", "(", "\n", "action", ",", "GaussianDistInfo", "(", "mean", "=", "torch", ".", "zeros_like", "(", "action", ")", ")", ")", "\n", "", "return", "prior_log_pi", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.rl_with_ul.sac_with_ul.SacWithUl.optim_state_dict": [[555, 562], ["dict", "sac_with_ul.SacWithUl.pi_optimizer.state_dict", "sac_with_ul.SacWithUl.q_optimizer.state_dict", "sac_with_ul.SacWithUl.alpha_optimizer.state_dict", "sac_with_ul.SacWithUl._log_alpha.detach().item", "sac_with_ul.SacWithUl.ul_optimizer.state_dict", "sac_with_ul.SacWithUl._log_alpha.detach"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.replay_saver.DummyOptimizer.state_dict", "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.replay_saver.DummyOptimizer.state_dict", "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.replay_saver.DummyOptimizer.state_dict", "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.replay_saver.DummyOptimizer.state_dict"], ["", "def", "optim_state_dict", "(", "self", ")", ":", "\n", "        ", "return", "dict", "(", "\n", "pi", "=", "self", ".", "pi_optimizer", ".", "state_dict", "(", ")", ",", "\n", "q", "=", "self", ".", "q_optimizer", ".", "state_dict", "(", ")", ",", "\n", "alpha", "=", "self", ".", "alpha_optimizer", ".", "state_dict", "(", ")", ",", "\n", "log_alpha_value", "=", "self", ".", "_log_alpha", ".", "detach", "(", ")", ".", "item", "(", ")", ",", "\n", "ul", "=", "self", ".", "ul_optimizer", ".", "state_dict", "(", ")", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.rl_with_ul.sac_with_ul.SacWithUl.load_optim_state_dict": [[564, 572], ["sac_with_ul.SacWithUl.pi_optimizer.load_state_dict", "sac_with_ul.SacWithUl.q_optimizer.load_state_dict", "sac_with_ul.SacWithUl.alpha_optimizer.load_state_dict", "sac_with_ul.SacWithUl.ul_optimizer.load_state_dict", "torch.no_grad", "torch.exp", "sac_with_ul.SacWithUl._log_alpha.detach"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.augmented_temporal_similarity.AugmentedTemporalSimilarity.load_state_dict", "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.augmented_temporal_similarity.AugmentedTemporalSimilarity.load_state_dict", "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.augmented_temporal_similarity.AugmentedTemporalSimilarity.load_state_dict", "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.augmented_temporal_similarity.AugmentedTemporalSimilarity.load_state_dict"], ["", "def", "load_optim_state_dict", "(", "self", ",", "state_dict", ")", ":", "\n", "        ", "self", ".", "pi_optimizer", ".", "load_state_dict", "(", "state_dict", "[", "\"pi\"", "]", ")", "\n", "self", ".", "q_optimizer", ".", "load_state_dict", "(", "state_dict", "[", "\"q\"", "]", ")", "\n", "self", ".", "alpha_optimizer", ".", "load_state_dict", "(", "state_dict", "[", "\"alpha\"", "]", ")", "\n", "self", ".", "ul_optimizer", ".", "load_state_dict", "(", "state_dict", "[", "\"ul\"", "]", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "self", ".", "_log_alpha", "[", ":", "]", "=", "state_dict", "[", "\"log_alpha_value\"", "]", "\n", "self", ".", "_alpha", "=", "torch", ".", "exp", "(", "self", ".", "_log_alpha", ".", "detach", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.rl_with_ul.sac_with_ul.SacWithUl.ul_parameters": [[573, 576], ["sac_with_ul.SacWithUl.ul_encoder.parameters", "sac_with_ul.SacWithUl.ul_contrast.parameters"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.rl.atari_rl_models.AtariDqnModel.parameters", "home.repos.pwc.inspect_result.astooke_rlpyt.rl.atari_rl_models.AtariDqnModel.parameters"], ["", "", "def", "ul_parameters", "(", "self", ")", ":", "\n", "        ", "yield", "from", "self", ".", "ul_encoder", ".", "parameters", "(", ")", "\n", "yield", "from", "self", ".", "ul_contrast", ".", "parameters", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.rl_with_ul.sac_with_ul.SacWithUl.ul_named_parameters": [[577, 580], ["sac_with_ul.SacWithUl.ul_encoder.named_parameters", "sac_with_ul.SacWithUl.ul_contrast.named_parameters"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.rl.atari_rl_models.AtariDqnModel.named_parameters", "home.repos.pwc.inspect_result.astooke_rlpyt.rl.atari_rl_models.AtariDqnModel.named_parameters"], ["", "def", "ul_named_parameters", "(", "self", ")", ":", "\n", "        ", "yield", "from", "self", ".", "ul_encoder", ".", "named_parameters", "(", ")", "\n", "yield", "from", "self", ".", "ul_contrast", ".", "named_parameters", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.rl_with_ul.sac_with_ul.SacWithUl.compute_ul_update_schedule": [[581, 605], ["int", "sac_with_ul.SacWithUl.ul_update_schedule.split", "sac_with_ul.SacWithUl.ul_update_schedule.split", "int", "int", "int", "int", "numpy.round", "int", "int", "sac_with_ul.SacWithUl.ul_update_schedule.split", "numpy.round", "int", "int", "sac_with_ul.SacWithUl.ul_update_schedule.split", "numpy.round", "sac_with_ul.SacWithUl.ul_update_schedule.split", "math.sin"], "methods", ["None"], ["", "def", "compute_ul_update_schedule", "(", "self", ",", "itr", ")", ":", "\n", "        ", "if", "itr", "<", "self", ".", "min_itr_ul", "or", "itr", ">", "self", ".", "max_itr_ul", ":", "\n", "            ", "return", "0", "\n", "", "remaining", "=", "(", "self", ".", "max_itr_ul", "-", "itr", ")", "/", "(", "self", ".", "max_itr_ul", "-", "self", ".", "min_itr_ul", ")", "# from 1 to 0", "\n", "if", "\"constant\"", "in", "self", ".", "ul_update_schedule", ":", "\n", "# Format: \"constant_X\", for X num updates per RL itr.", "\n", "            ", "n_ul_updates", "=", "int", "(", "self", ".", "ul_update_schedule", ".", "split", "(", "\"_\"", ")", "[", "1", "]", ")", "\n", "", "elif", "\"front\"", "in", "self", ".", "ul_update_schedule", ":", "\n", "# Format: \"front_X_Y\", for X updates first itr, Y updates rest.", "\n", "            ", "entries", "=", "self", ".", "ul_update_schedule", ".", "split", "(", "\"_\"", ")", "\n", "if", "itr", "==", "self", ".", "min_itr_ul", ":", "\n", "                ", "n_ul_updates", "=", "int", "(", "entries", "[", "1", "]", ")", "\n", "", "else", ":", "\n", "                ", "n_ul_updates", "=", "int", "(", "entries", "[", "2", "]", ")", "\n", "", "", "elif", "\"linear\"", "in", "self", ".", "ul_update_schedule", ":", "\n", "            ", "first", "=", "int", "(", "self", ".", "ul_update_schedule", ".", "split", "(", "\"_\"", ")", "[", "1", "]", ")", "\n", "n_ul_updates", "=", "int", "(", "np", ".", "round", "(", "first", "*", "remaining", ")", ")", "\n", "", "elif", "\"quadratic\"", "in", "self", ".", "ul_update_schedule", ":", "\n", "            ", "first", "=", "int", "(", "self", ".", "ul_update_schedule", ".", "split", "(", "\"_\"", ")", "[", "1", "]", ")", "\n", "n_ul_updates", "=", "int", "(", "np", ".", "round", "(", "first", "*", "remaining", "**", "2", ")", ")", "\n", "", "elif", "\"cosine\"", "in", "self", ".", "ul_update_schedule", ":", "\n", "            ", "first", "=", "int", "(", "self", ".", "ul_update_schedule", ".", "split", "(", "\"_\"", ")", "[", "1", "]", ")", "\n", "n_ul_updates", "=", "int", "(", "np", ".", "round", "(", "first", "*", "math", ".", "sin", "(", "math", ".", "pi", "/", "2", "*", "remaining", ")", ")", ")", "\n", "", "return", "n_ul_updates", "\n", "", "", ""]], "home.repos.pwc.inspect_result.astooke_rlpyt.rl_with_ul.sac_with_ul.chain": [[42, 45], ["None"], "function", ["None"], ["def", "chain", "(", "*", "iterables", ")", ":", "\n", "    ", "for", "itr", "in", "iterables", ":", "\n", "        ", "yield", "from", "itr", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.rl_with_ul.ppo_with_ul.PpoUl.__init__": [[38, 85], ["rlpyt.utils.quick_args.save__init__args", "dict", "dict", "locals"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.utils.quick_args.save__init__args"], ["def", "__init__", "(", "\n", "self", ",", "\n", "discount", "=", "0.99", ",", "\n", "learning_rate", "=", "0.001", ",", "\n", "value_loss_coeff", "=", "1.", ",", "\n", "entropy_loss_coeff", "=", "0.01", ",", "\n", "OptimCls", "=", "torch", ".", "optim", ".", "Adam", ",", "\n", "optim_kwargs", "=", "None", ",", "\n", "clip_grad_norm", "=", "10.", ",", "\n", "initial_optim_state_dict", "=", "None", ",", "\n", "gae_lambda", "=", "1", ",", "\n", "minibatches", "=", "4", ",", "\n", "epochs", "=", "4", ",", "\n", "ratio_clip", "=", "0.1", ",", "\n", "linear_lr_schedule", "=", "True", ",", "\n", "normalize_advantage", "=", "False", ",", "\n", "min_steps_rl", "=", "0", ",", "\n", "min_steps_ul", "=", "0", ",", "\n", "max_steps_ul", "=", "None", ",", "\n", "ul_learning_rate", "=", "0.001", ",", "\n", "ul_optim_kwargs", "=", "None", ",", "\n", "ul_replay_size", "=", "1e5", ",", "\n", "ul_update_schedule", "=", "None", ",", "\n", "ul_lr_schedule", "=", "None", ",", "\n", "ul_lr_warmup", "=", "0", ",", "\n", "ul_delta_T", "=", "1", ",", "\n", "ul_batch_B", "=", "512", ",", "\n", "ul_batch_T", "=", "1", ",", "\n", "ul_random_shift_prob", "=", "1.", ",", "\n", "ul_random_shift_pad", "=", "4", ",", "\n", "ul_target_update_interval", "=", "1", ",", "\n", "ul_target_update_tau", "=", "0.01", ",", "\n", "ul_latent_size", "=", "256", ",", "\n", "ul_anchor_hidden_sizes", "=", "512", ",", "\n", "ul_clip_grad_norm", "=", "10.", ",", "\n", "ul_pri_alpha", "=", "0.", ",", "\n", "ul_pri_beta", "=", "1.", ",", "\n", "ul_pri_n_step_return", "=", "1", ",", "\n", "UlEncoderCls", "=", "UlEncoderModel", ",", "\n", "UlContrastCls", "=", "ContrastModel", ",", "\n", ")", ":", "\n", "        ", "\"\"\"Saves input settings.\"\"\"", "\n", "if", "optim_kwargs", "is", "None", ":", "\n", "            ", "optim_kwargs", "=", "dict", "(", ")", "\n", "", "if", "ul_optim_kwargs", "is", "None", ":", "\n", "            ", "ul_optim_kwargs", "=", "dict", "(", ")", "\n", "", "save__init__args", "(", "locals", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.rl_with_ul.ppo_with_ul.PpoUl.initialize": [[86, 178], ["ppo_with_ul.PpoUl.OptimCls", "ppo_with_ul.PpoUl.UlEncoderCls", "copy.deepcopy", "ppo_with_ul.PpoUl.UlContrastCls", "ppo_with_ul.PpoUl.ul_encoder.to", "ppo_with_ul.PpoUl.ul_target_encoder.to", "ppo_with_ul.PpoUl.ul_contrast.to", "ppo_with_ul.PpoUl.OptimCls", "ppo_with_ul.PpoUl.initialize_replay_buffer", "max", "rlpyt.utils.logging.logger.log", "sum", "rlpyt.utils.logging.logger.log", "ppo_with_ul.PpoUl.agent.parameters", "ppo_with_ul.PpoUl.ul_parameters", "torch.optim.lr_scheduler.LambdaLR", "ppo_with_ul.PpoUl.agent.set_act_uniform", "torch.nn.CrossEntropyLoss", "ppo_with_ul.PpoUl.optimizer.load_state_dict", "ppo_with_ul.PpoUl.compute_ul_update_schedule", "torch.optim.lr_scheduler.LambdaLR", "rlpyt.ul.algos.utils.warmup_scheduler.GradualWarmupScheduler", "ppo_with_ul.PpoUl.ul_optimizer.zero_grad", "ppo_with_ul.PpoUl.ul_optimizer.step", "range", "torch.optim.lr_scheduler.CosineAnnealingLR"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.rl_with_ul.ppo_with_ul.PpoUl.initialize_replay_buffer", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.console.log", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.console.log", "home.repos.pwc.inspect_result.astooke_rlpyt.rl.atari_rl_models.AtariDqnModel.parameters", "home.repos.pwc.inspect_result.astooke_rlpyt.rl_with_ul.ppo_with_ul.PpoUl.ul_parameters", "home.repos.pwc.inspect_result.astooke_rlpyt.agents.atari_pg_agent.AtariPgAgent.set_act_uniform", "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.augmented_temporal_similarity.AugmentedTemporalSimilarity.load_state_dict", "home.repos.pwc.inspect_result.astooke_rlpyt.rl_with_ul.ppo_with_ul.PpoUl.compute_ul_update_schedule", "home.repos.pwc.inspect_result.astooke_rlpyt.safe.safety_gym_env.SafetyGymTrajInfo.step"], ["", "def", "initialize", "(", "self", ",", "agent", ",", "n_itr", ",", "batch_spec", ",", "mid_batch_reset", ",", "examples", ",", "\n", "world_size", "=", "1", ",", "rank", "=", "0", ")", ":", "\n", "        ", "\"\"\"\n        Extends base ``initialize()`` to initialize learning rate schedule, if\n        applicable.\n        \"\"\"", "\n", "self", ".", "agent", "=", "agent", "\n", "self", ".", "n_itr", "=", "n_itr", "\n", "self", ".", "batch_spec", "=", "batch_spec", "\n", "self", ".", "mid_batch_reset", "=", "mid_batch_reset", "\n", "\n", "self", ".", "optimizer", "=", "self", ".", "OptimCls", "(", "# Keep same name as base PPO algo.", "\n", "self", ".", "agent", ".", "parameters", "(", ")", ",", "# Model knows whether to include conv.", "\n", "lr", "=", "self", ".", "learning_rate", ",", "**", "self", ".", "optim_kwargs", ")", "\n", "\n", "self", ".", "ul_encoder", "=", "self", ".", "UlEncoderCls", "(", "\n", "conv", "=", "self", ".", "agent", ".", "model", ".", "conv", ",", "\n", "latent_size", "=", "self", ".", "ul_latent_size", ",", "\n", "conv_out_size", "=", "self", ".", "agent", ".", "model", ".", "conv_out_size", ",", "\n", ")", "\n", "self", ".", "ul_target_encoder", "=", "copy", ".", "deepcopy", "(", "self", ".", "ul_encoder", ")", "\n", "self", ".", "ul_contrast", "=", "self", ".", "UlContrastCls", "(", "\n", "latent_size", "=", "self", ".", "ul_latent_size", ",", "\n", "anchor_hidden_sizes", "=", "self", ".", "ul_anchor_hidden_sizes", ",", "\n", ")", "\n", "self", ".", "ul_encoder", ".", "to", "(", "self", ".", "agent", ".", "device", ")", "\n", "self", ".", "ul_target_encoder", ".", "to", "(", "self", ".", "agent", ".", "device", ")", "\n", "self", ".", "ul_contrast", ".", "to", "(", "self", ".", "agent", ".", "device", ")", "\n", "\n", "self", ".", "ul_optimizer", "=", "self", ".", "OptimCls", "(", "\n", "self", ".", "ul_parameters", "(", ")", ",", "\n", "lr", "=", "self", ".", "ul_learning_rate", ",", "**", "self", ".", "ul_optim_kwargs", ")", "\n", "\n", "self", ".", "_batch_size", "=", "self", ".", "batch_spec", ".", "size", "//", "self", ".", "minibatches", "# For logging.", "\n", "self", ".", "initialize_replay_buffer", "(", "examples", ",", "batch_spec", ")", "\n", "\n", "if", "self", ".", "linear_lr_schedule", ":", "\n", "            ", "self", ".", "lr_scheduler", "=", "torch", ".", "optim", ".", "lr_scheduler", ".", "LambdaLR", "(", "\n", "optimizer", "=", "self", ".", "optimizer", ",", "\n", "lr_lambda", "=", "lambda", "itr", ":", "(", "self", ".", "n_itr", "-", "itr", ")", "/", "self", ".", "n_itr", ")", "# Step once per itr.", "\n", "self", ".", "_ratio_clip", "=", "self", ".", "ratio_clip", "# Save base value.", "\n", "\n", "", "self", ".", "min_itr_rl", "=", "self", ".", "min_steps_rl", "//", "(", "batch_spec", ".", "size", "*", "world_size", ")", "\n", "self", ".", "min_itr_ul", "=", "self", ".", "min_steps_ul", "//", "(", "batch_spec", ".", "size", "*", "world_size", ")", "\n", "self", ".", "min_itr_ul", "=", "max", "(", "\n", "self", ".", "min_itr_ul", ",", "\n", "1", "+", "(", "self", ".", "ul_batch_T", "+", "self", ".", "ul_delta_T", ")", "//", "batch_spec", ".", "T", ",", "\n", ")", "\n", "self", ".", "max_itr_ul", "=", "(", "self", ".", "n_itr", "+", "1", "if", "self", ".", "max_steps_ul", "is", "None", "else", "\n", "self", ".", "max_steps_ul", "//", "(", "batch_spec", ".", "size", "*", "world_size", ")", ")", "\n", "if", "self", ".", "min_itr_rl", "==", "self", ".", "min_itr_ul", ":", "\n", "            ", "self", ".", "min_itr_rl", "+=", "1", "\n", "", "logger", ".", "log", "(", "f\"Min itr RL: {self.min_itr_rl},  Min itr UL: {self.min_itr_ul}. \"", "\n", "f\"Max itr UL: {self.max_itr_ul} (n_itr: {self.n_itr}).\"", ")", "\n", "if", "self", ".", "min_itr_rl", ">", "0", ":", "\n", "            ", "self", ".", "agent", ".", "set_act_uniform", "(", "True", ")", "\n", "\n", "", "self", ".", "ul_lr_scheduler", "=", "None", "\n", "self", ".", "ul_update_counter", "=", "0", "\n", "self", ".", "total_ul_updates", "=", "sum", "(", "[", "self", ".", "compute_ul_update_schedule", "(", "itr", ")", "\n", "for", "itr", "in", "range", "(", "self", ".", "n_itr", ")", "]", ")", "\n", "logger", ".", "log", "(", "f\"Total number of UL updates to do: {self.total_ul_updates}.\"", ")", "\n", "if", "self", ".", "total_ul_updates", ">", "0", ":", "\n", "            ", "if", "self", ".", "ul_lr_schedule", "==", "\"linear\"", ":", "\n", "                ", "self", ".", "ul_lr_scheduler", "=", "torch", ".", "optim", ".", "lr_scheduler", ".", "LambdaLR", "(", "\n", "optimizer", "=", "self", ".", "ul_optimizer", ",", "\n", "lr_lambda", "=", "lambda", "upd", ":", "(", "self", ".", "total_ul_updates", "-", "upd", ")", "/", "self", ".", "total_ul_updates", ",", "\n", ")", "\n", "", "elif", "self", ".", "ul_lr_schedule", "==", "\"cosine\"", ":", "\n", "                ", "self", ".", "ul_lr_scheduler", "=", "torch", ".", "optim", ".", "lr_scheduler", ".", "CosineAnnealingLR", "(", "\n", "optimizer", "=", "self", ".", "ul_optimizer", ",", "\n", "T_max", "=", "self", ".", "total_ul_updates", "-", "self", ".", "ul_lr_warmup", ",", "\n", ")", "\n", "", "elif", "self", ".", "ul_lr_schedule", "is", "not", "None", ":", "\n", "                ", "raise", "NotImplementedError", "\n", "\n", "", "if", "self", ".", "ul_lr_warmup", ">", "0", ":", "\n", "                ", "self", ".", "ul_lr_scheduler", "=", "GradualWarmupScheduler", "(", "\n", "self", ".", "ul_optimizer", ",", "\n", "multiplier", "=", "1", ",", "\n", "total_epoch", "=", "self", ".", "ul_lr_warmup", ",", "# actually n_updates", "\n", "after_scheduler", "=", "self", ".", "ul_lr_scheduler", ",", "\n", ")", "\n", "\n", "", "if", "self", ".", "ul_lr_scheduler", "is", "not", "None", ":", "\n", "                ", "self", ".", "ul_optimizer", ".", "zero_grad", "(", ")", "\n", "self", ".", "ul_optimizer", ".", "step", "(", ")", "\n", "\n", "", "self", ".", "c_e_loss", "=", "torch", ".", "nn", ".", "CrossEntropyLoss", "(", "ignore_index", "=", "IGNORE_INDEX", ")", "\n", "\n", "", "if", "self", ".", "initial_optim_state_dict", "is", "not", "None", ":", "\n", "            ", "self", ".", "optimizer", ".", "load_state_dict", "(", "self", ".", "initial_optim_state_dict", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.rl_with_ul.ppo_with_ul.PpoUl.initialize_replay_buffer": [[179, 199], ["ppo_with_ul.PpoUl.examples_to_buffer", "rlpyt.ul.replays.rl_with_ul_replay.RlWithUlUniformReplayBuffer", "rlpyt.ul.replays.rl_with_ul_replay.RlWithUlPrioritizedReplayBuffer"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.rl_with_ul.ppo_with_ul.PpoUl.examples_to_buffer"], ["", "", "def", "initialize_replay_buffer", "(", "self", ",", "examples", ",", "batch_spec", ")", ":", "\n", "        ", "example_to_buffer", "=", "self", ".", "examples_to_buffer", "(", "examples", ")", "\n", "replay_T", "=", "self", ".", "ul_delta_T", "+", "self", ".", "ul_batch_T", "\n", "if", "self", ".", "ul_pri_alpha", "==", "0.", ":", "\n", "            ", "self", ".", "replay_buffer", "=", "RlWithUlUniformReplayBuffer", "(", "\n", "example", "=", "example_to_buffer", ",", "\n", "size", "=", "self", ".", "ul_replay_size", ",", "\n", "B", "=", "batch_spec", ".", "B", ",", "\n", "replay_T", "=", "replay_T", ",", "\n", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "replay_buffer", "=", "RlWithUlPrioritizedReplayBuffer", "(", "\n", "example", "=", "example_to_buffer", ",", "\n", "size", "=", "self", ".", "ul_replay_size", ",", "\n", "B", "=", "batch_spec", ".", "B", ",", "\n", "replay_T", "=", "replay_T", ",", "\n", "discount", "=", "self", ".", "discount", ",", "\n", "n_step_return", "=", "self", ".", "ul_pri_n_step_return", ",", "\n", "alpha", "=", "self", ".", "ul_pri_alpha", ",", "\n", "beta", "=", "self", ".", "ul_pri_beta", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.rl_with_ul.ppo_with_ul.PpoUl.samples_to_buffer": [[201, 210], ["SamplesToBuffer"], "methods", ["None"], ["", "", "def", "samples_to_buffer", "(", "self", ",", "samples", ")", ":", "\n", "        ", "\"\"\"Defines how to add data from sampler into the replay buffer. Called\n        in optimize_agent() if samples are provided to that method.  In \n        asynchronous mode, will be called in the memory_copier process.\"\"\"", "\n", "return", "SamplesToBuffer", "(", "\n", "observation", "=", "samples", ".", "env", ".", "observation", ",", "\n", "action", "=", "samples", ".", "agent", ".", "action", ",", "\n", "reward", "=", "samples", ".", "env", ".", "reward", ",", "\n", "done", "=", "samples", ".", "env", ".", "done", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.rl_with_ul.ppo_with_ul.PpoUl.examples_to_buffer": [[212, 218], ["SamplesToBuffer"], "methods", ["None"], ["", "def", "examples_to_buffer", "(", "self", ",", "examples", ")", ":", "\n", "        ", "return", "SamplesToBuffer", "(", "\n", "observation", "=", "examples", "[", "\"observation\"", "]", ",", "\n", "action", "=", "examples", "[", "\"action\"", "]", ",", "\n", "reward", "=", "examples", "[", "\"reward\"", "]", ",", "\n", "done", "=", "examples", "[", "\"done\"", "]", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.rl_with_ul.ppo_with_ul.PpoUl.optimize_agent": [[220, 242], ["ppo_with_ul.PpoUl.samples_to_buffer", "ppo_with_ul.PpoUl.replay_buffer.append_samples", "rlpyt.algos.pg.base.OptInfo", "ppo_with_ul.PpoUl.agent.set_act_uniform", "super().optimize_agent", "opt_info._replace._replace._replace", "ppo_with_ul.PpoUl.ul_optimize", "opt_info._replace._replace._replace", "opt_info._replace._replace.ulUpdates.append", "samples._replace", "super().optimize_agent._asdict", "ppo_with_ul.PpoUl._asdict", "range", "samples.env_.replace", "len"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.rl_with_ul.ppo_with_ul.PpoUl.samples_to_buffer", "home.repos.pwc.inspect_result.astooke_rlpyt.sequence.prioritized.PrioritizedSequenceReplay.append_samples", "home.repos.pwc.inspect_result.astooke_rlpyt.agents.atari_pg_agent.AtariPgAgent.set_act_uniform", "home.repos.pwc.inspect_result.astooke_rlpyt.safe.cppo_pid.CppoPID.optimize_agent", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.collections.NamedTuple._replace", "home.repos.pwc.inspect_result.astooke_rlpyt.rl_with_ul.ppo_with_ul.PpoUl.ul_optimize", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.collections.NamedTuple._replace", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.collections.NamedTuple._replace", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.collections.NamedTuple._asdict", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.collections.NamedTuple._asdict"], ["", "def", "optimize_agent", "(", "self", ",", "itr", ",", "samples", ")", ":", "\n", "        ", "samples_to_buffer", "=", "self", ".", "samples_to_buffer", "(", "samples", ")", "\n", "self", ".", "replay_buffer", ".", "append_samples", "(", "samples_to_buffer", ")", "\n", "opt_info", "=", "OptInfo", "(", "*", "(", "[", "]", "for", "_", "in", "range", "(", "len", "(", "OptInfo", ".", "_fields", ")", ")", ")", ")", "\n", "if", "itr", "==", "self", ".", "min_itr_rl", ":", "\n", "            ", "self", ".", "agent", ".", "set_act_uniform", "(", "False", ")", "# Start using the policy network.", "\n", "", "if", "itr", ">=", "self", ".", "min_itr_rl", ":", "# Do RL update first, \"on-policy\"?", "\n", "            ", "if", "self", ".", "agent", ".", "store_latent", "==", "\"conv\"", ":", "# agent expects it for training", "\n", "                ", "rl_samples", "=", "samples", ".", "_replace", "(", "\n", "env", "=", "samples", ".", "env_", ".", "replace", "(", "\n", "observation", "=", "samples", ".", "agent", ".", "agent_info", ".", "conv", ")", "\n", ")", "\n", "", "else", ":", "\n", "                ", "rl_samples", "=", "samples", "\n", "", "opt_info_rl", "=", "super", "(", ")", ".", "optimize_agent", "(", "itr", ",", "rl_samples", ")", "# Regular PPO", "\n", "opt_info", "=", "opt_info", ".", "_replace", "(", "**", "opt_info_rl", ".", "_asdict", "(", ")", ")", "\n", "", "if", "itr", ">=", "self", ".", "min_itr_ul", ":", "\n", "            ", "opt_info_ul", "=", "self", ".", "ul_optimize", "(", "itr", ")", "\n", "opt_info", "=", "opt_info", ".", "_replace", "(", "**", "opt_info_ul", ".", "_asdict", "(", ")", ")", "\n", "", "else", ":", "\n", "            ", "opt_info", ".", "ulUpdates", ".", "append", "(", "0", ")", "\n", "", "return", "opt_info", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.rl_with_ul.ppo_with_ul.PpoUl.ul_optimize": [[243, 259], ["OptInfoUl", "ppo_with_ul.PpoUl.compute_ul_update_schedule", "range", "OptInfoUl.ulUpdates.append", "ppo_with_ul.PpoUl.ul_optimize_one_step", "OptInfoUl.ulLoss.append", "OptInfoUl.ulAccuracy.append", "OptInfoUl.ulGradNorm.append", "ppo_with_ul.PpoUl.ul_lr_scheduler.step", "ul_loss.item", "ul_accuracy.item", "grad_norm.item", "rlpyt.models.utils.update_state_dict", "ppo_with_ul.PpoUl.ul_encoder.state_dict", "range", "len"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.rl_with_ul.ppo_with_ul.PpoUl.compute_ul_update_schedule", "home.repos.pwc.inspect_result.astooke_rlpyt.rl_with_ul.ppo_with_ul.PpoUl.ul_optimize_one_step", "home.repos.pwc.inspect_result.astooke_rlpyt.safe.safety_gym_env.SafetyGymTrajInfo.step", "home.repos.pwc.inspect_result.astooke_rlpyt.models.utils.update_state_dict", "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.replay_saver.DummyOptimizer.state_dict"], ["", "def", "ul_optimize", "(", "self", ",", "itr", ")", ":", "\n", "        ", "opt_info_ul", "=", "OptInfoUl", "(", "*", "(", "[", "]", "for", "_", "in", "range", "(", "len", "(", "OptInfoUl", ".", "_fields", ")", ")", ")", ")", "\n", "n_ul_updates", "=", "self", ".", "compute_ul_update_schedule", "(", "itr", ")", "\n", "for", "_", "in", "range", "(", "n_ul_updates", ")", ":", "\n", "            ", "self", ".", "ul_update_counter", "+=", "1", "\n", "if", "self", ".", "ul_lr_scheduler", "is", "not", "None", ":", "\n", "                ", "self", ".", "ul_lr_scheduler", ".", "step", "(", "self", ".", "ul_update_counter", ")", "\n", "", "ul_loss", ",", "ul_accuracy", ",", "grad_norm", "=", "self", ".", "ul_optimize_one_step", "(", ")", "\n", "opt_info_ul", ".", "ulLoss", ".", "append", "(", "ul_loss", ".", "item", "(", ")", ")", "\n", "opt_info_ul", ".", "ulAccuracy", ".", "append", "(", "ul_accuracy", ".", "item", "(", ")", ")", "\n", "opt_info_ul", ".", "ulGradNorm", ".", "append", "(", "grad_norm", ".", "item", "(", ")", ")", "\n", "if", "self", ".", "ul_update_counter", "%", "self", ".", "ul_target_update_interval", "==", "0", ":", "\n", "                ", "update_state_dict", "(", "self", ".", "ul_target_encoder", ",", "self", ".", "ul_encoder", ".", "state_dict", "(", ")", ",", "\n", "self", ".", "ul_target_update_tau", ")", "\n", "", "", "opt_info_ul", ".", "ulUpdates", ".", "append", "(", "self", ".", "ul_update_counter", ")", "\n", "return", "opt_info_ul", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.rl_with_ul.ppo_with_ul.PpoUl.compute_ul_update_schedule": [[260, 293], ["int", "ppo_with_ul.PpoUl.ul_update_schedule.split", "ppo_with_ul.PpoUl.ul_update_schedule.split", "int", "int", "ppo_with_ul.PpoUl.ul_update_schedule.split", "int", "int", "int", "int", "numpy.round", "int", "int", "ppo_with_ul.PpoUl.ul_update_schedule.split", "numpy.round", "int", "int", "ppo_with_ul.PpoUl.ul_update_schedule.split", "numpy.round", "ppo_with_ul.PpoUl.ul_update_schedule.split", "math.sin"], "methods", ["None"], ["", "def", "compute_ul_update_schedule", "(", "self", ",", "itr", ")", ":", "\n", "        ", "if", "itr", "<", "self", ".", "min_itr_ul", "or", "itr", ">", "self", ".", "max_itr_ul", ":", "\n", "            ", "return", "0", "\n", "", "remaining", "=", "(", "self", ".", "max_itr_ul", "-", "itr", ")", "/", "(", "self", ".", "max_itr_ul", "-", "self", ".", "min_itr_ul", ")", "# from 1 to 0", "\n", "if", "\"constant\"", "in", "self", ".", "ul_update_schedule", ":", "\n", "# Format: \"constant_X\", for X num updates per RL itr.", "\n", "            ", "n_ul_updates", "=", "int", "(", "self", ".", "ul_update_schedule", ".", "split", "(", "\"_\"", ")", "[", "1", "]", ")", "\n", "", "elif", "\"front\"", "in", "self", ".", "ul_update_schedule", ":", "\n", "# Format: \"front_X_Y\", for X updates first itr, Y updates rest.", "\n", "            ", "entries", "=", "self", ".", "ul_update_schedule", ".", "split", "(", "\"_\"", ")", "\n", "if", "itr", "==", "self", ".", "min_itr_ul", ":", "\n", "                ", "n_ul_updates", "=", "int", "(", "entries", "[", "1", "]", ")", "\n", "", "else", ":", "\n", "                ", "n_ul_updates", "=", "int", "(", "entries", "[", "2", "]", ")", "\n", "", "", "elif", "\"pulse\"", "in", "self", ".", "ul_update_schedule", ":", "\n", "# Format: \"pulse_X_Y\", for Y updates every X steps.", "\n", "            ", "entries", "=", "self", ".", "ul_update_schedule", ".", "split", "(", "\"_\"", ")", "\n", "n_steps_skip", "=", "int", "(", "entries", "[", "1", "]", ")", "\n", "n_itr_skip", "=", "n_steps_skip", "//", "self", ".", "batch_spec", ".", "size", "\n", "if", "(", "itr", "-", "self", ".", "min_itr_ul", ")", "%", "n_itr_skip", "==", "0", ":", "\n", "                ", "n_ul_updates", "=", "int", "(", "entries", "[", "2", "]", ")", "\n", "", "else", ":", "\n", "                ", "n_ul_updates", "=", "0", "\n", "", "", "elif", "\"linear\"", "in", "self", ".", "ul_update_schedule", ":", "\n", "            ", "first", "=", "int", "(", "self", ".", "ul_update_schedule", ".", "split", "(", "\"_\"", ")", "[", "1", "]", ")", "\n", "n_ul_updates", "=", "int", "(", "np", ".", "round", "(", "first", "*", "remaining", ")", ")", "\n", "", "elif", "\"quadratic\"", "in", "self", ".", "ul_update_schedule", ":", "\n", "            ", "first", "=", "int", "(", "self", ".", "ul_update_schedule", ".", "split", "(", "\"_\"", ")", "[", "1", "]", ")", "\n", "n_ul_updates", "=", "int", "(", "np", ".", "round", "(", "first", "*", "remaining", "**", "2", ")", ")", "\n", "", "elif", "\"cosine\"", "in", "self", ".", "ul_update_schedule", ":", "\n", "            ", "first", "=", "int", "(", "self", ".", "ul_update_schedule", ".", "split", "(", "\"_\"", ")", "[", "1", "]", ")", "\n", "n_ul_updates", "=", "int", "(", "np", ".", "round", "(", "first", "*", "math", ".", "sin", "(", "math", ".", "pi", "/", "2", "*", "remaining", ")", ")", ")", "\n", "", "return", "n_ul_updates", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.rl_with_ul.ppo_with_ul.PpoUl.ul_optimize_one_step": [[294, 342], ["ppo_with_ul.PpoUl.ul_optimizer.zero_grad", "ppo_with_ul.PpoUl.replay_buffer.sample_batch", "rlpyt.ul.algos.utils.data_augs.random_shift.reshape", "rlpyt.ul.algos.utils.data_augs.random_shift.reshape", "rlpyt.utils.buffer.buffer_to", "ppo_with_ul.PpoUl.ul_encoder", "ppo_with_ul.PpoUl.ul_contrast", "torch.arange", "rlpyt.algos.utils.valid_from_done().type", "valid[].reshape", "ppo_with_ul.PpoUl.c_e_loss", "ppo_with_ul.PpoUl.backward", "ppo_with_ul.PpoUl.ul_optimizer.step", "torch.mean", "rlpyt.ul.algos.utils.data_augs.random_shift", "rlpyt.ul.algos.utils.data_augs.random_shift", "torch.no_grad", "ppo_with_ul.PpoUl.ul_target_encoder", "torch.nn.utils.clip_grad_norm_", "torch.argmax", "correct[].float", "rlpyt.algos.utils.valid_from_done", "ppo_with_ul.PpoUl.ul_parameters", "ppo_with_ul.PpoUl.detach"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.sequence.uniform.UniformSequenceReplay.sample_batch", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.buffer.buffer_to", "home.repos.pwc.inspect_result.astooke_rlpyt.models.utils.ScaleGrad.backward", "home.repos.pwc.inspect_result.astooke_rlpyt.safe.safety_gym_env.SafetyGymTrajInfo.step", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.data_augs.random_shift", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.data_augs.random_shift", "home.repos.pwc.inspect_result.astooke_rlpyt.algos.utils.valid_from_done", "home.repos.pwc.inspect_result.astooke_rlpyt.rl_with_ul.ppo_with_ul.PpoUl.ul_parameters"], ["", "def", "ul_optimize_one_step", "(", "self", ")", ":", "\n", "        ", "self", ".", "ul_optimizer", ".", "zero_grad", "(", ")", "\n", "samples", "=", "self", ".", "replay_buffer", ".", "sample_batch", "(", "batch_B", "=", "self", ".", "ul_batch_B", ")", "\n", "\n", "anchor", "=", "samples", ".", "observation", "[", ":", "-", "self", ".", "ul_delta_T", "]", "\n", "positive", "=", "samples", ".", "observation", "[", "self", ".", "ul_delta_T", ":", "]", "\n", "t", ",", "b", ",", "c", ",", "h", ",", "w", "=", "anchor", ".", "shape", "\n", "anchor", "=", "anchor", ".", "reshape", "(", "t", "*", "b", ",", "c", ",", "h", ",", "w", ")", "\n", "positive", "=", "positive", ".", "reshape", "(", "t", "*", "b", ",", "c", ",", "h", ",", "w", ")", "\n", "\n", "if", "self", ".", "ul_random_shift_prob", ">", "0.", ":", "\n", "            ", "anchor", "=", "random_shift", "(", "\n", "imgs", "=", "anchor", ",", "\n", "pad", "=", "self", ".", "ul_random_shift_pad", ",", "\n", "prob", "=", "self", ".", "ul_random_shift_prob", ",", "\n", ")", "\n", "positive", "=", "random_shift", "(", "\n", "imgs", "=", "positive", ",", "\n", "pad", "=", "self", ".", "ul_random_shift_pad", ",", "\n", "prob", "=", "self", ".", "ul_random_shift_prob", ",", "\n", ")", "\n", "\n", "", "anchor", ",", "positive", "=", "buffer_to", "(", "(", "anchor", ",", "positive", ")", ",", "\n", "device", "=", "self", ".", "agent", ".", "device", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "c_positive", ",", "_pos_conv", "=", "self", ".", "ul_target_encoder", "(", "positive", ")", "\n", "", "c_anchor", ",", "_anc_conv", "=", "self", ".", "ul_encoder", "(", "anchor", ")", "\n", "logits", "=", "self", ".", "ul_contrast", "(", "c_anchor", ",", "c_positive", ")", "# anchor mlp in here.", "\n", "\n", "labels", "=", "torch", ".", "arange", "(", "c_anchor", ".", "shape", "[", "0", "]", ",", "\n", "dtype", "=", "torch", ".", "long", ",", "device", "=", "self", ".", "agent", ".", "device", ")", "\n", "valid", "=", "valid_from_done", "(", "samples", ".", "done", ")", ".", "type", "(", "torch", ".", "bool", ")", "# use all", "\n", "valid", "=", "valid", "[", "self", ".", "ul_delta_T", ":", "]", ".", "reshape", "(", "-", "1", ")", "# at positions of positive", "\n", "labels", "[", "~", "valid", "]", "=", "IGNORE_INDEX", "\n", "\n", "ul_loss", "=", "self", ".", "c_e_loss", "(", "logits", ",", "labels", ")", "\n", "ul_loss", ".", "backward", "(", ")", "\n", "if", "self", ".", "ul_clip_grad_norm", "is", "None", ":", "\n", "            ", "grad_norm", "=", "0.", "\n", "", "else", ":", "\n", "            ", "grad_norm", "=", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "\n", "self", ".", "ul_parameters", "(", ")", ",", "self", ".", "ul_clip_grad_norm", ")", "\n", "", "self", ".", "ul_optimizer", ".", "step", "(", ")", "\n", "\n", "correct", "=", "torch", ".", "argmax", "(", "logits", ".", "detach", "(", ")", ",", "dim", "=", "1", ")", "==", "labels", "\n", "accuracy", "=", "torch", ".", "mean", "(", "correct", "[", "valid", "]", ".", "float", "(", ")", ")", "\n", "\n", "return", "ul_loss", ",", "accuracy", ",", "grad_norm", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.rl_with_ul.ppo_with_ul.PpoUl.ul_parameters": [[343, 346], ["ppo_with_ul.PpoUl.ul_encoder.parameters", "ppo_with_ul.PpoUl.ul_contrast.parameters"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.rl.atari_rl_models.AtariDqnModel.parameters", "home.repos.pwc.inspect_result.astooke_rlpyt.rl.atari_rl_models.AtariDqnModel.parameters"], ["", "def", "ul_parameters", "(", "self", ")", ":", "\n", "        ", "yield", "from", "self", ".", "ul_encoder", ".", "parameters", "(", ")", "\n", "yield", "from", "self", ".", "ul_contrast", ".", "parameters", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.rl_with_ul.ppo_with_ul.PpoUl.ul_named_parameters": [[347, 350], ["ppo_with_ul.PpoUl.ul_encoder.named_parameters", "ppo_with_ul.PpoUl.ul_contrast.named_parameters"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.rl.atari_rl_models.AtariDqnModel.named_parameters", "home.repos.pwc.inspect_result.astooke_rlpyt.rl.atari_rl_models.AtariDqnModel.named_parameters"], ["", "def", "ul_named_parameters", "(", "self", ")", ":", "\n", "        ", "yield", "from", "self", ".", "ul_encoder", ".", "named_parameters", "(", ")", "\n", "yield", "from", "self", ".", "ul_contrast", ".", "named_parameters", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.train_ul.atari_atc.build_and_train": [[14, 41], ["rlpyt.utils.launching.affinity.affinity_from_code", "rlpyt.utils.launching.variant.load_variant", "rlpyt.utils.launching.variant.update_config", "pprint.pprint", "rlpyt.ul.algos.ul_for_rl.augmented_temporal_contrast.AugmentedTemporalContrast", "rlpyt.ul.runners.unsupervised_learning.UnsupervisedLearning", "rlpyt.utils.logging.context.logger_context", "rlpyt.ul.runners.unsupervised_learning.UnsupervisedLearning.train"], "function", ["home.repos.pwc.inspect_result.astooke_rlpyt.launching.affinity.affinity_from_code", "home.repos.pwc.inspect_result.astooke_rlpyt.launching.variant.load_variant", "home.repos.pwc.inspect_result.astooke_rlpyt.launching.variant.update_config", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.context.logger_context", "home.repos.pwc.inspect_result.astooke_rlpyt.runners.minibatch_rl.MinibatchRlEval.train"], ["def", "build_and_train", "(", "\n", "slot_affinity_code", "=", "\"0slt_1gpu_1cpu\"", ",", "\n", "log_dir", "=", "\"test\"", ",", "\n", "run_ID", "=", "\"0\"", ",", "\n", "config_key", "=", "\"atari_atc\"", ",", "\n", ")", ":", "\n", "    ", "affinity", "=", "affinity_from_code", "(", "slot_affinity_code", ")", "\n", "config", "=", "configs", "[", "config_key", "]", "\n", "variant", "=", "load_variant", "(", "log_dir", ")", "\n", "config", "=", "update_config", "(", "config", ",", "variant", ")", "\n", "\n", "pprint", ".", "pprint", "(", "config", ")", "\n", "\n", "algo", "=", "AugmentedTemporalContrast", "(", "\n", "optim_kwargs", "=", "config", "[", "\"optim\"", "]", ",", "\n", "encoder_kwargs", "=", "config", "[", "\"encoder\"", "]", ",", "\n", "**", "config", "[", "\"algo\"", "]", "\n", ")", "\n", "runner", "=", "UnsupervisedLearning", "(", "\n", "algo", "=", "algo", ",", "\n", "affinity", "=", "affinity", ",", "\n", "**", "config", "[", "\"runner\"", "]", "\n", ")", "\n", "name", "=", "config", "[", "\"name\"", "]", "\n", "with", "logger_context", "(", "log_dir", ",", "run_ID", ",", "name", ",", "config", ",", "\n", "snapshot_mode", "=", "\"last\"", ")", ":", "\n", "        ", "runner", ".", "train", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.train_ul.atari_ats.build_and_train": [[14, 41], ["rlpyt.utils.launching.affinity.affinity_from_code", "rlpyt.utils.launching.variant.load_variant", "rlpyt.utils.launching.variant.update_config", "pprint.pprint", "rlpyt.ul.algos.ul_for_rl.augmented_temporal_similarity.AugmentedTemporalSimilarity", "rlpyt.ul.runners.unsupervised_learning.UnsupervisedLearning", "rlpyt.utils.logging.context.logger_context", "rlpyt.ul.runners.unsupervised_learning.UnsupervisedLearning.train"], "function", ["home.repos.pwc.inspect_result.astooke_rlpyt.launching.affinity.affinity_from_code", "home.repos.pwc.inspect_result.astooke_rlpyt.launching.variant.load_variant", "home.repos.pwc.inspect_result.astooke_rlpyt.launching.variant.update_config", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.context.logger_context", "home.repos.pwc.inspect_result.astooke_rlpyt.runners.minibatch_rl.MinibatchRlEval.train"], ["def", "build_and_train", "(", "\n", "slot_affinity_code", "=", "\"0slt_1gpu_1cpu\"", ",", "\n", "log_dir", "=", "\"test\"", ",", "\n", "run_ID", "=", "\"0\"", ",", "\n", "config_key", "=", "\"atari_ats\"", ",", "\n", ")", ":", "\n", "    ", "affinity", "=", "affinity_from_code", "(", "slot_affinity_code", ")", "\n", "config", "=", "configs", "[", "config_key", "]", "\n", "variant", "=", "load_variant", "(", "log_dir", ")", "\n", "config", "=", "update_config", "(", "config", ",", "variant", ")", "\n", "\n", "pprint", ".", "pprint", "(", "config", ")", "\n", "\n", "algo", "=", "AugmentedTemporalSimilarity", "(", "\n", "optim_kwargs", "=", "config", "[", "\"optim\"", "]", ",", "\n", "encoder_kwargs", "=", "config", "[", "\"encoder\"", "]", ",", "\n", "**", "config", "[", "\"algo\"", "]", "\n", ")", "\n", "runner", "=", "UnsupervisedLearning", "(", "\n", "algo", "=", "algo", ",", "\n", "affinity", "=", "affinity", ",", "\n", "**", "config", "[", "\"runner\"", "]", "\n", ")", "\n", "name", "=", "config", "[", "\"name\"", "]", "\n", "with", "logger_context", "(", "log_dir", ",", "run_ID", ",", "name", ",", "config", ",", "\n", "snapshot_mode", "=", "\"last\"", ")", ":", "\n", "        ", "runner", ".", "train", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.train_ul.atari_stdim.build_and_train": [[14, 41], ["rlpyt.utils.launching.affinity.affinity_from_code", "rlpyt.utils.launching.variant.load_variant", "rlpyt.utils.launching.variant.update_config", "pprint.pprint", "rlpyt.ul.algos.ul_for_rl.stdim.STDIM", "rlpyt.ul.runners.unsupervised_learning.UnsupervisedLearning", "rlpyt.utils.logging.context.logger_context", "rlpyt.ul.runners.unsupervised_learning.UnsupervisedLearning.train"], "function", ["home.repos.pwc.inspect_result.astooke_rlpyt.launching.affinity.affinity_from_code", "home.repos.pwc.inspect_result.astooke_rlpyt.launching.variant.load_variant", "home.repos.pwc.inspect_result.astooke_rlpyt.launching.variant.update_config", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.context.logger_context", "home.repos.pwc.inspect_result.astooke_rlpyt.runners.minibatch_rl.MinibatchRlEval.train"], ["def", "build_and_train", "(", "\n", "slot_affinity_code", "=", "\"0slt_1gpu_1cpu\"", ",", "\n", "log_dir", "=", "\"test\"", ",", "\n", "run_ID", "=", "\"0\"", ",", "\n", "config_key", "=", "\"atari_stdim\"", ",", "\n", ")", ":", "\n", "    ", "affinity", "=", "affinity_from_code", "(", "slot_affinity_code", ")", "\n", "config", "=", "configs", "[", "config_key", "]", "\n", "variant", "=", "load_variant", "(", "log_dir", ")", "\n", "config", "=", "update_config", "(", "config", ",", "variant", ")", "\n", "\n", "pprint", ".", "pprint", "(", "config", ")", "\n", "\n", "algo", "=", "STDIM", "(", "\n", "optim_kwargs", "=", "config", "[", "\"optim\"", "]", ",", "\n", "encoder_kwargs", "=", "config", "[", "\"encoder\"", "]", ",", "\n", "**", "config", "[", "\"algo\"", "]", "\n", ")", "\n", "runner", "=", "UnsupervisedLearning", "(", "\n", "algo", "=", "algo", ",", "\n", "affinity", "=", "affinity", ",", "\n", "**", "config", "[", "\"runner\"", "]", "\n", ")", "\n", "name", "=", "config", "[", "\"name\"", "]", "\n", "with", "logger_context", "(", "log_dir", ",", "run_ID", ",", "name", ",", "config", ",", "\n", "snapshot_mode", "=", "\"last\"", ")", ":", "\n", "        ", "runner", ".", "train", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.train_ul.atari_vae.build_and_train": [[14, 42], ["rlpyt.utils.launching.affinity.affinity_from_code", "rlpyt.utils.launching.variant.load_variant", "rlpyt.utils.launching.variant.update_config", "pprint.pprint", "rlpyt.ul.algos.ul_for_rl.vae.VAE", "rlpyt.ul.runners.unsupervised_learning.UnsupervisedLearning", "rlpyt.utils.logging.context.logger_context", "rlpyt.ul.runners.unsupervised_learning.UnsupervisedLearning.train"], "function", ["home.repos.pwc.inspect_result.astooke_rlpyt.launching.affinity.affinity_from_code", "home.repos.pwc.inspect_result.astooke_rlpyt.launching.variant.load_variant", "home.repos.pwc.inspect_result.astooke_rlpyt.launching.variant.update_config", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.context.logger_context", "home.repos.pwc.inspect_result.astooke_rlpyt.runners.minibatch_rl.MinibatchRlEval.train"], ["def", "build_and_train", "(", "\n", "slot_affinity_code", "=", "\"0slt_1gpu_1cpu\"", ",", "\n", "log_dir", "=", "\"test\"", ",", "\n", "run_ID", "=", "\"0\"", ",", "\n", "config_key", "=", "\"atari_vae\"", ",", "\n", ")", ":", "\n", "    ", "affinity", "=", "affinity_from_code", "(", "slot_affinity_code", ")", "\n", "config", "=", "configs", "[", "config_key", "]", "\n", "variant", "=", "load_variant", "(", "log_dir", ")", "\n", "config", "=", "update_config", "(", "config", ",", "variant", ")", "\n", "\n", "pprint", ".", "pprint", "(", "config", ")", "\n", "\n", "algo", "=", "VAE", "(", "\n", "optim_kwargs", "=", "config", "[", "\"optim\"", "]", ",", "\n", "encoder_kwargs", "=", "config", "[", "\"encoder\"", "]", ",", "\n", "decoder_kwargs", "=", "config", "[", "\"decoder\"", "]", ",", "\n", "**", "config", "[", "\"algo\"", "]", "\n", ")", "\n", "runner", "=", "UnsupervisedLearning", "(", "\n", "algo", "=", "algo", ",", "\n", "affinity", "=", "affinity", ",", "\n", "**", "config", "[", "\"runner\"", "]", "\n", ")", "\n", "name", "=", "config", "[", "\"name\"", "]", "\n", "with", "logger_context", "(", "log_dir", ",", "run_ID", ",", "name", ",", "config", ",", "\n", "snapshot_mode", "=", "\"last\"", ")", ":", "\n", "        ", "runner", ".", "train", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.train_ul.atari_pixel_control.build_and_train": [[14, 42], ["rlpyt.utils.launching.affinity.affinity_from_code", "rlpyt.utils.launching.variant.load_variant", "rlpyt.utils.launching.variant.update_config", "pprint.pprint", "rlpyt.ul.algos.ul_for_rl.pixel_control.PixelControl", "rlpyt.ul.runners.unsupervised_learning.UnsupervisedLearning", "rlpyt.utils.logging.context.logger_context", "rlpyt.ul.runners.unsupervised_learning.UnsupervisedLearning.train"], "function", ["home.repos.pwc.inspect_result.astooke_rlpyt.launching.affinity.affinity_from_code", "home.repos.pwc.inspect_result.astooke_rlpyt.launching.variant.load_variant", "home.repos.pwc.inspect_result.astooke_rlpyt.launching.variant.update_config", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.context.logger_context", "home.repos.pwc.inspect_result.astooke_rlpyt.runners.minibatch_rl.MinibatchRlEval.train"], ["def", "build_and_train", "(", "\n", "slot_affinity_code", "=", "\"0slt_1gpu_1cpu\"", ",", "\n", "log_dir", "=", "\"test\"", ",", "\n", "run_ID", "=", "\"0\"", ",", "\n", "config_key", "=", "\"atari_pc\"", ",", "\n", ")", ":", "\n", "    ", "affinity", "=", "affinity_from_code", "(", "slot_affinity_code", ")", "\n", "config", "=", "configs", "[", "config_key", "]", "\n", "variant", "=", "load_variant", "(", "log_dir", ")", "\n", "config", "=", "update_config", "(", "config", ",", "variant", ")", "\n", "\n", "pprint", ".", "pprint", "(", "config", ")", "\n", "\n", "algo", "=", "PixelControl", "(", "\n", "optim_kwargs", "=", "config", "[", "\"optim\"", "]", ",", "\n", "encoder_kwargs", "=", "config", "[", "\"encoder\"", "]", ",", "\n", "pixel_control_model_kwargs", "=", "config", "[", "\"pixel_control_model\"", "]", ",", "\n", "**", "config", "[", "\"algo\"", "]", "\n", ")", "\n", "runner", "=", "UnsupervisedLearning", "(", "\n", "algo", "=", "algo", ",", "\n", "affinity", "=", "affinity", ",", "\n", "**", "config", "[", "\"runner\"", "]", "\n", ")", "\n", "name", "=", "config", "[", "\"name\"", "]", "\n", "with", "logger_context", "(", "log_dir", ",", "run_ID", ",", "name", ",", "config", ",", "\n", "snapshot_mode", "=", "\"last\"", ")", ":", "\n", "        ", "runner", ".", "train", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.train_ul.atari_inverse.build_and_train": [[14, 42], ["rlpyt.utils.launching.affinity.affinity_from_code", "rlpyt.utils.launching.variant.load_variant", "rlpyt.utils.launching.variant.update_config", "pprint.pprint", "rlpyt.ul.algos.ul_for_rl.inverse.Inverse", "rlpyt.ul.runners.unsupervised_learning.UnsupervisedLearning", "rlpyt.utils.logging.context.logger_context", "rlpyt.ul.runners.unsupervised_learning.UnsupervisedLearning.train"], "function", ["home.repos.pwc.inspect_result.astooke_rlpyt.launching.affinity.affinity_from_code", "home.repos.pwc.inspect_result.astooke_rlpyt.launching.variant.load_variant", "home.repos.pwc.inspect_result.astooke_rlpyt.launching.variant.update_config", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.context.logger_context", "home.repos.pwc.inspect_result.astooke_rlpyt.runners.minibatch_rl.MinibatchRlEval.train"], ["def", "build_and_train", "(", "\n", "slot_affinity_code", "=", "\"0slt_1gpu_1cpu\"", ",", "\n", "log_dir", "=", "\"test\"", ",", "\n", "run_ID", "=", "\"0\"", ",", "\n", "config_key", "=", "\"atari_inv\"", ",", "\n", ")", ":", "\n", "    ", "affinity", "=", "affinity_from_code", "(", "slot_affinity_code", ")", "\n", "config", "=", "configs", "[", "config_key", "]", "\n", "variant", "=", "load_variant", "(", "log_dir", ")", "\n", "config", "=", "update_config", "(", "config", ",", "variant", ")", "\n", "\n", "pprint", ".", "pprint", "(", "config", ")", "\n", "\n", "algo", "=", "Inverse", "(", "\n", "optim_kwargs", "=", "config", "[", "\"optim\"", "]", ",", "\n", "encoder_kwargs", "=", "config", "[", "\"encoder\"", "]", ",", "\n", "inverse_model_kwargs", "=", "config", "[", "\"inverse_model\"", "]", ",", "\n", "**", "config", "[", "\"algo\"", "]", "\n", ")", "\n", "runner", "=", "UnsupervisedLearning", "(", "\n", "algo", "=", "algo", ",", "\n", "affinity", "=", "affinity", ",", "\n", "**", "config", "[", "\"runner\"", "]", "\n", ")", "\n", "name", "=", "config", "[", "\"name\"", "]", "\n", "with", "logger_context", "(", "log_dir", ",", "run_ID", ",", "name", ",", "config", ",", "\n", "snapshot_mode", "=", "\"last\"", ")", ":", "\n", "        ", "runner", ".", "train", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.train_ul.dmc_vae.build_and_train": [[15, 43], ["rlpyt.utils.launching.affinity.affinity_from_code", "rlpyt.utils.launching.variant.load_variant", "rlpyt.utils.launching.variant.update_config", "pprint.pprint", "rlpyt.ul.algos.ul_for_rl.vae.VAE", "rlpyt.ul.runners.unsupervised_learning.UnsupervisedLearning", "rlpyt.utils.logging.context.logger_context", "rlpyt.ul.runners.unsupervised_learning.UnsupervisedLearning.train"], "function", ["home.repos.pwc.inspect_result.astooke_rlpyt.launching.affinity.affinity_from_code", "home.repos.pwc.inspect_result.astooke_rlpyt.launching.variant.load_variant", "home.repos.pwc.inspect_result.astooke_rlpyt.launching.variant.update_config", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.context.logger_context", "home.repos.pwc.inspect_result.astooke_rlpyt.runners.minibatch_rl.MinibatchRlEval.train"], ["def", "build_and_train", "(", "\n", "slot_affinity_code", "=", "\"0slt_1gpu_1cpu\"", ",", "\n", "log_dir", "=", "\"test\"", ",", "\n", "run_ID", "=", "\"0\"", ",", "\n", "config_key", "=", "\"dmc_vae\"", ",", "\n", ")", ":", "\n", "    ", "affinity", "=", "affinity_from_code", "(", "slot_affinity_code", ")", "\n", "config", "=", "configs", "[", "config_key", "]", "\n", "variant", "=", "load_variant", "(", "log_dir", ")", "\n", "config", "=", "update_config", "(", "config", ",", "variant", ")", "\n", "\n", "pprint", ".", "pprint", "(", "config", ")", "\n", "\n", "algo", "=", "VAE", "(", "\n", "optim_kwargs", "=", "config", "[", "\"optim\"", "]", ",", "\n", "encoder_kwargs", "=", "config", "[", "\"encoder\"", "]", ",", "\n", "decoder_kwargs", "=", "config", "[", "\"decoder\"", "]", ",", "\n", "**", "config", "[", "\"algo\"", "]", "\n", ")", "\n", "runner", "=", "UnsupervisedLearning", "(", "\n", "algo", "=", "algo", ",", "\n", "affinity", "=", "affinity", ",", "\n", "**", "config", "[", "\"runner\"", "]", "\n", ")", "\n", "name", "=", "config", "[", "\"name\"", "]", "\n", "with", "logger_context", "(", "log_dir", ",", "run_ID", ",", "name", ",", "config", ",", "\n", "snapshot_mode", "=", "\"last\"", ")", ":", "\n", "        ", "runner", ".", "train", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.train_ul.dmc_atc.build_and_train": [[14, 41], ["rlpyt.utils.launching.affinity.affinity_from_code", "rlpyt.utils.launching.variant.load_variant", "rlpyt.utils.launching.variant.update_config", "pprint.pprint", "rlpyt.ul.algos.ul_for_rl.augmented_temporal_contrast.AugmentedTemporalContrast", "rlpyt.ul.runners.unsupervised_learning.UnsupervisedLearning", "rlpyt.utils.logging.context.logger_context", "rlpyt.ul.runners.unsupervised_learning.UnsupervisedLearning.train"], "function", ["home.repos.pwc.inspect_result.astooke_rlpyt.launching.affinity.affinity_from_code", "home.repos.pwc.inspect_result.astooke_rlpyt.launching.variant.load_variant", "home.repos.pwc.inspect_result.astooke_rlpyt.launching.variant.update_config", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.context.logger_context", "home.repos.pwc.inspect_result.astooke_rlpyt.runners.minibatch_rl.MinibatchRlEval.train"], ["def", "build_and_train", "(", "\n", "slot_affinity_code", "=", "\"0slt_1gpu_1cpu\"", ",", "\n", "log_dir", "=", "\"test\"", ",", "\n", "run_ID", "=", "\"0\"", ",", "\n", "config_key", "=", "\"dmc_atc\"", ",", "\n", ")", ":", "\n", "    ", "affinity", "=", "affinity_from_code", "(", "slot_affinity_code", ")", "\n", "config", "=", "configs", "[", "config_key", "]", "\n", "variant", "=", "load_variant", "(", "log_dir", ")", "\n", "config", "=", "update_config", "(", "config", ",", "variant", ")", "\n", "\n", "pprint", ".", "pprint", "(", "config", ")", "\n", "\n", "algo", "=", "AugmentedTemporalContrast", "(", "\n", "optim_kwargs", "=", "config", "[", "\"optim\"", "]", ",", "\n", "encoder_kwargs", "=", "config", "[", "\"encoder\"", "]", ",", "\n", "**", "config", "[", "\"algo\"", "]", "\n", ")", "\n", "runner", "=", "UnsupervisedLearning", "(", "\n", "algo", "=", "algo", ",", "\n", "affinity", "=", "affinity", ",", "\n", "**", "config", "[", "\"runner\"", "]", "\n", ")", "\n", "name", "=", "config", "[", "\"name\"", "]", "\n", "with", "logger_context", "(", "log_dir", ",", "run_ID", ",", "name", ",", "config", ",", "\n", "snapshot_mode", "=", "\"last\"", ")", ":", "\n", "        ", "runner", ".", "train", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.train_ul.dmlab_pc.build_and_train": [[15, 44], ["rlpyt.utils.launching.affinity.affinity_from_code", "rlpyt.utils.launching.variant.load_variant", "rlpyt.utils.launching.variant.update_config", "pprint.pprint", "rlpyt.ul.algos.ul_for_rl.pixel_control.PixelControl", "rlpyt.ul.runners.unsupervised_learning.UnsupervisedLearning", "rlpyt.utils.logging.context.logger_context", "rlpyt.ul.runners.unsupervised_learning.UnsupervisedLearning.train"], "function", ["home.repos.pwc.inspect_result.astooke_rlpyt.launching.affinity.affinity_from_code", "home.repos.pwc.inspect_result.astooke_rlpyt.launching.variant.load_variant", "home.repos.pwc.inspect_result.astooke_rlpyt.launching.variant.update_config", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.context.logger_context", "home.repos.pwc.inspect_result.astooke_rlpyt.runners.minibatch_rl.MinibatchRlEval.train"], ["def", "build_and_train", "(", "\n", "slot_affinity_code", "=", "\"0slt_1gpu_1cpu\"", ",", "\n", "log_dir", "=", "\"test\"", ",", "\n", "run_ID", "=", "\"0\"", ",", "\n", "config_key", "=", "\"dmlab_pc\"", ",", "\n", ")", ":", "\n", "    ", "affinity", "=", "affinity_from_code", "(", "slot_affinity_code", ")", "\n", "config", "=", "configs", "[", "config_key", "]", "\n", "variant", "=", "load_variant", "(", "log_dir", ")", "\n", "config", "=", "update_config", "(", "config", ",", "variant", ")", "\n", "\n", "pprint", ".", "pprint", "(", "config", ")", "\n", "\n", "algo", "=", "PixelControl", "(", "\n", "optim_kwargs", "=", "config", "[", "\"optim\"", "]", ",", "\n", "EncoderCls", "=", "DmlabAtcEncoderModel", ",", "\n", "encoder_kwargs", "=", "config", "[", "\"encoder\"", "]", ",", "\n", "pixel_control_model_kwargs", "=", "config", "[", "\"pixel_control_model\"", "]", ",", "\n", "**", "config", "[", "\"algo\"", "]", "\n", ")", "\n", "runner", "=", "UnsupervisedLearning", "(", "\n", "algo", "=", "algo", ",", "\n", "affinity", "=", "affinity", ",", "\n", "**", "config", "[", "\"runner\"", "]", "\n", ")", "\n", "name", "=", "config", "[", "\"name\"", "]", "\n", "with", "logger_context", "(", "log_dir", ",", "run_ID", ",", "name", ",", "config", ",", "\n", "snapshot_mode", "=", "\"last\"", ")", ":", "\n", "        ", "runner", ".", "train", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.train_ul.dmlab_atc.build_and_train": [[15, 43], ["rlpyt.utils.launching.affinity.affinity_from_code", "rlpyt.utils.launching.variant.load_variant", "rlpyt.utils.launching.variant.update_config", "pprint.pprint", "rlpyt.ul.algos.ul_for_rl.augmented_temporal_contrast.AugmentedTemporalContrast", "rlpyt.ul.runners.unsupervised_learning.UnsupervisedLearning", "rlpyt.utils.logging.context.logger_context", "rlpyt.ul.runners.unsupervised_learning.UnsupervisedLearning.train"], "function", ["home.repos.pwc.inspect_result.astooke_rlpyt.launching.affinity.affinity_from_code", "home.repos.pwc.inspect_result.astooke_rlpyt.launching.variant.load_variant", "home.repos.pwc.inspect_result.astooke_rlpyt.launching.variant.update_config", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.context.logger_context", "home.repos.pwc.inspect_result.astooke_rlpyt.runners.minibatch_rl.MinibatchRlEval.train"], ["def", "build_and_train", "(", "\n", "slot_affinity_code", "=", "\"0slt_1gpu_1cpu\"", ",", "\n", "log_dir", "=", "\"test\"", ",", "\n", "run_ID", "=", "\"0\"", ",", "\n", "config_key", "=", "\"dmlab_atc\"", ",", "\n", ")", ":", "\n", "    ", "affinity", "=", "affinity_from_code", "(", "slot_affinity_code", ")", "\n", "config", "=", "configs", "[", "config_key", "]", "\n", "variant", "=", "load_variant", "(", "log_dir", ")", "\n", "config", "=", "update_config", "(", "config", ",", "variant", ")", "\n", "\n", "pprint", ".", "pprint", "(", "config", ")", "\n", "\n", "algo", "=", "AugmentedTemporalContrast", "(", "\n", "optim_kwargs", "=", "config", "[", "\"optim\"", "]", ",", "\n", "EncoderCls", "=", "DmlabAtcEncoderModel", ",", "\n", "encoder_kwargs", "=", "config", "[", "\"encoder\"", "]", ",", "\n", "**", "config", "[", "\"algo\"", "]", "\n", ")", "\n", "runner", "=", "UnsupervisedLearning", "(", "\n", "algo", "=", "algo", ",", "\n", "affinity", "=", "affinity", ",", "\n", "**", "config", "[", "\"runner\"", "]", "\n", ")", "\n", "name", "=", "config", "[", "\"name\"", "]", "\n", "with", "logger_context", "(", "log_dir", ",", "run_ID", ",", "name", ",", "config", ",", "\n", "snapshot_mode", "=", "\"last\"", ")", ":", "\n", "        ", "runner", ".", "train", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.train_ul.dmlab_cpc.build_and_train": [[15, 43], ["rlpyt.utils.launching.affinity.affinity_from_code", "rlpyt.utils.launching.variant.load_variant", "rlpyt.utils.launching.variant.update_config", "pprint.pprint", "rlpyt.ul.algos.ul_for_rl.cpc.CPC", "rlpyt.ul.runners.unsupervised_learning.UnsupervisedLearning", "rlpyt.utils.logging.context.logger_context", "rlpyt.ul.runners.unsupervised_learning.UnsupervisedLearning.train"], "function", ["home.repos.pwc.inspect_result.astooke_rlpyt.launching.affinity.affinity_from_code", "home.repos.pwc.inspect_result.astooke_rlpyt.launching.variant.load_variant", "home.repos.pwc.inspect_result.astooke_rlpyt.launching.variant.update_config", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.context.logger_context", "home.repos.pwc.inspect_result.astooke_rlpyt.runners.minibatch_rl.MinibatchRlEval.train"], ["def", "build_and_train", "(", "\n", "slot_affinity_code", "=", "\"0slt_1gpu_1cpu\"", ",", "\n", "log_dir", "=", "\"test\"", ",", "\n", "run_ID", "=", "\"0\"", ",", "\n", "config_key", "=", "\"dmlab_cpc\"", ",", "\n", ")", ":", "\n", "    ", "affinity", "=", "affinity_from_code", "(", "slot_affinity_code", ")", "\n", "config", "=", "configs", "[", "config_key", "]", "\n", "variant", "=", "load_variant", "(", "log_dir", ")", "\n", "config", "=", "update_config", "(", "config", ",", "variant", ")", "\n", "\n", "pprint", ".", "pprint", "(", "config", ")", "\n", "\n", "algo", "=", "CPC", "(", "\n", "optim_kwargs", "=", "config", "[", "\"optim\"", "]", ",", "\n", "EncoderCls", "=", "DmlabEncoderModel", ",", "\n", "encoder_kwargs", "=", "config", "[", "\"encoder\"", "]", ",", "\n", "**", "config", "[", "\"algo\"", "]", "\n", ")", "\n", "runner", "=", "UnsupervisedLearning", "(", "\n", "algo", "=", "algo", ",", "\n", "affinity", "=", "affinity", ",", "\n", "**", "config", "[", "\"runner\"", "]", "\n", ")", "\n", "name", "=", "config", "[", "\"name\"", "]", "\n", "with", "logger_context", "(", "log_dir", ",", "run_ID", ",", "name", ",", "config", ",", "\n", "snapshot_mode", "=", "\"last\"", ")", ":", "\n", "        ", "runner", ".", "train", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.rl.dmlab_rl_models.DmlabPgLstmModel.__init__": [[24, 63], ["super().__init__", "rlpyt.ul.models.dmlab_conv2d.DmlabConv2dModel", "dmlab_rl_models.DmlabPgLstmModel.conv.output_size", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.LSTM", "torch.nn.LSTM", "torch.nn.LSTM", "torch.nn.LSTM", "rlpyt.models.mlp.MlpModel", "rlpyt.utils.logging.logger.log", "dmlab_rl_models.DmlabPgLstmModel.apply"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.spaces.gym_wrapper.GymSpaceWrapper.__init__", "home.repos.pwc.inspect_result.astooke_rlpyt.rl.sac_rl_models.SacFc1Model.output_size", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.console.log"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "image_shape", ",", "\n", "output_size", ",", "\n", "lstm_size", ",", "\n", "skip_connections", "=", "True", ",", "\n", "hidden_sizes", "=", "None", ",", "\n", "kiaming_init", "=", "True", ",", "\n", "stop_conv_grad", "=", "False", ",", "\n", "skip_lstm", "=", "True", ",", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "c", ",", "h", ",", "w", "=", "image_shape", "\n", "self", ".", "conv", "=", "DmlabConv2dModel", "(", "\n", "in_channels", "=", "c", ",", "\n", "use_fourth_layer", "=", "True", ",", "\n", "use_maxpool", "=", "False", ",", "\n", "skip_connections", "=", "skip_connections", ",", "\n", ")", "\n", "self", ".", "_conv_out_size", "=", "self", ".", "conv", ".", "output_size", "(", "h", "=", "h", ",", "w", "=", "w", ")", "\n", "self", ".", "fc1", "=", "torch", ".", "nn", ".", "Linear", "(", "\n", "in_features", "=", "self", ".", "_conv_out_size", ",", "\n", "out_features", "=", "lstm_size", ",", "\n", ")", "\n", "self", ".", "lstm", "=", "torch", ".", "nn", ".", "LSTM", "(", "lstm_size", "+", "output_size", "+", "1", ",", "lstm_size", ")", "\n", "self", ".", "pi_v_head", "=", "MlpModel", "(", "\n", "input_size", "=", "lstm_size", ",", "\n", "hidden_sizes", "=", "hidden_sizes", ",", "\n", "output_size", "=", "output_size", "+", "1", ",", "\n", ")", "\n", "if", "kiaming_init", ":", "\n", "            ", "self", ".", "apply", "(", "weight_init", ")", "\n", "", "self", ".", "stop_conv_grad", "=", "stop_conv_grad", "\n", "logger", ".", "log", "(", "\n", "\"Model stopping gradient at CONV.\"", "\n", "if", "stop_conv_grad", "else", "\n", "\"Modeul using gradients on all parameters.\"", "\n", ")", "\n", "self", ".", "_skip_lstm", "=", "skip_lstm", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.rl.dmlab_rl_models.DmlabPgLstmModel.forward": [[64, 93], ["rlpyt.utils.tensor.infer_leading_dims", "dmlab_rl_models.DmlabPgLstmModel.conv", "torch.relu", "torch.relu", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "dmlab_rl_models.DmlabPgLstmModel.lstm", "dmlab_rl_models.DmlabPgLstmModel.pi_v_head", "torch.softmax", "torch.softmax", "rlpyt.utils.tensor.restore_leading_dims", "RnnState", "observation.type", "img.mul_.mul_.mul_", "img.mul_.mul_.view", "conv.detach.detach.detach", "dmlab_rl_models.DmlabPgLstmModel.fc1", "tuple", "lstm_out.view", "conv.detach.detach.view", "torch.relu.view", "prev_action.view", "prev_reward.view", "lstm_out.view"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.utils.tensor.infer_leading_dims", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.tensor.restore_leading_dims"], ["", "def", "forward", "(", "self", ",", "observation", ",", "prev_action", ",", "prev_reward", ",", "init_rnn_state", ")", ":", "\n", "        ", "if", "observation", ".", "dtype", "==", "torch", ".", "uint8", ":", "\n", "            ", "img", "=", "observation", ".", "type", "(", "torch", ".", "float", ")", "\n", "img", "=", "img", ".", "mul_", "(", "1.", "/", "255", ")", "\n", "", "else", ":", "\n", "            ", "img", "=", "observation", "\n", "\n", "", "lead_dim", ",", "T", ",", "B", ",", "img_shape", "=", "infer_leading_dims", "(", "img", ",", "3", ")", "\n", "conv", "=", "self", ".", "conv", "(", "img", ".", "view", "(", "T", "*", "B", ",", "*", "img_shape", ")", ")", "\n", "\n", "if", "self", ".", "stop_conv_grad", ":", "\n", "            ", "conv", "=", "conv", ".", "detach", "(", ")", "\n", "\n", "", "fc1", "=", "F", ".", "relu", "(", "self", ".", "fc1", "(", "conv", ".", "view", "(", "T", "*", "B", ",", "-", "1", ")", ")", ")", "\n", "lstm_input", "=", "torch", ".", "cat", "(", "[", "\n", "fc1", ".", "view", "(", "T", ",", "B", ",", "-", "1", ")", ",", "\n", "prev_action", ".", "view", "(", "T", ",", "B", ",", "-", "1", ")", ",", "# Assumed onehot", "\n", "prev_reward", ".", "view", "(", "T", ",", "B", ",", "1", ")", ",", "\n", "]", ",", "dim", "=", "2", ")", "\n", "init_rnn_state", "=", "None", "if", "init_rnn_state", "is", "None", "else", "tuple", "(", "init_rnn_state", ")", "\n", "lstm_out", ",", "(", "hn", ",", "cn", ")", "=", "self", ".", "lstm", "(", "lstm_input", ",", "init_rnn_state", ")", "\n", "if", "self", ".", "_skip_lstm", ":", "\n", "            ", "lstm_out", "=", "lstm_out", ".", "view", "(", "T", "*", "B", ",", "-", "1", ")", "+", "fc1", "\n", "", "pi_v", "=", "self", ".", "pi_v_head", "(", "lstm_out", ".", "view", "(", "T", "*", "B", ",", "-", "1", ")", ")", "\n", "pi", "=", "F", ".", "softmax", "(", "pi_v", "[", ":", ",", ":", "-", "1", "]", ",", "dim", "=", "-", "1", ")", "\n", "v", "=", "pi_v", "[", ":", ",", "-", "1", "]", "\n", "pi", ",", "v", ",", "conv", "=", "restore_leading_dims", "(", "(", "pi", ",", "v", ",", "conv", ")", ",", "lead_dim", ",", "T", ",", "B", ")", "\n", "next_rnn_state", "=", "RnnState", "(", "h", "=", "hn", ",", "c", "=", "cn", ")", "\n", "return", "pi", ",", "v", ",", "next_rnn_state", ",", "conv", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.rl.dmlab_rl_models.DmlabPgLstmModel.parameters": [[94, 100], ["dmlab_rl_models.DmlabPgLstmModel.fc1.parameters", "dmlab_rl_models.DmlabPgLstmModel.lstm.parameters", "dmlab_rl_models.DmlabPgLstmModel.pi_v_head.parameters", "dmlab_rl_models.DmlabPgLstmModel.conv.parameters"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.rl.atari_rl_models.AtariDqnModel.parameters", "home.repos.pwc.inspect_result.astooke_rlpyt.rl.atari_rl_models.AtariDqnModel.parameters", "home.repos.pwc.inspect_result.astooke_rlpyt.rl.atari_rl_models.AtariDqnModel.parameters", "home.repos.pwc.inspect_result.astooke_rlpyt.rl.atari_rl_models.AtariDqnModel.parameters"], ["", "def", "parameters", "(", "self", ")", ":", "\n", "        ", "if", "not", "self", ".", "stop_conv_grad", ":", "\n", "            ", "yield", "from", "self", ".", "conv", ".", "parameters", "(", ")", "\n", "", "yield", "from", "self", ".", "fc1", ".", "parameters", "(", ")", "\n", "yield", "from", "self", ".", "lstm", ".", "parameters", "(", ")", "\n", "yield", "from", "self", ".", "pi_v_head", ".", "parameters", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.rl.dmlab_rl_models.DmlabPgLstmModel.named_parameters": [[101, 107], ["dmlab_rl_models.DmlabPgLstmModel.fc1.named_parameters", "dmlab_rl_models.DmlabPgLstmModel.lstm.named_parameters", "dmlab_rl_models.DmlabPgLstmModel.pi_v_head.named_parameters", "dmlab_rl_models.DmlabPgLstmModel.conv.named_parameters"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.rl.atari_rl_models.AtariDqnModel.named_parameters", "home.repos.pwc.inspect_result.astooke_rlpyt.rl.atari_rl_models.AtariDqnModel.named_parameters", "home.repos.pwc.inspect_result.astooke_rlpyt.rl.atari_rl_models.AtariDqnModel.named_parameters", "home.repos.pwc.inspect_result.astooke_rlpyt.rl.atari_rl_models.AtariDqnModel.named_parameters"], ["", "def", "named_parameters", "(", "self", ")", ":", "\n", "        ", "if", "not", "self", ".", "stop_conv_grad", ":", "\n", "            ", "yield", "from", "self", ".", "conv", ".", "named_parameters", "(", ")", "\n", "", "yield", "from", "self", ".", "fc1", ".", "named_parameters", "(", ")", "\n", "yield", "from", "self", ".", "lstm", ".", "named_parameters", "(", ")", "\n", "yield", "from", "self", ".", "pi_v_head", ".", "named_parameters", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.rl.dmlab_rl_models.DmlabPgLstmModel.conv_out_size": [[108, 111], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "conv_out_size", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_conv_out_size", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.rl.dmlab_rl_models.weight_init": [[16, 20], ["isinstance", "torch.nn.init.kaiming_normal_", "torch.nn.init.kaiming_normal_", "torch.nn.init.zeros_", "torch.nn.init.zeros_"], "function", ["None"], ["def", "weight_init", "(", "m", ")", ":", "\n", "    ", "if", "isinstance", "(", "m", ",", "(", "torch", ".", "nn", ".", "Linear", ",", "torch", ".", "nn", ".", "Conv2d", ")", ")", ":", "\n", "        ", "torch", ".", "nn", ".", "init", ".", "kaiming_normal_", "(", "m", ".", "weight", ",", "mode", "=", "\"fan_in\"", ",", "nonlinearity", "=", "\"relu\"", ")", "\n", "torch", ".", "nn", ".", "init", ".", "zeros_", "(", "m", ".", "bias", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.rl.ul_models.UlEncoderModel.__init__": [[9, 13], ["super().__init__", "torch.nn.Linear"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.spaces.gym_wrapper.GymSpaceWrapper.__init__"], ["    ", "def", "__init__", "(", "self", ",", "conv", ",", "latent_size", ",", "conv_out_size", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "conv", "=", "conv", "# Get from RL agent's model.", "\n", "self", ".", "head", "=", "torch", ".", "nn", ".", "Linear", "(", "conv_out_size", ",", "latent_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.rl.ul_models.UlEncoderModel.forward": [[14, 25], ["rlpyt.utils.tensor.infer_leading_dims", "ul_models.UlEncoderModel.conv", "ul_models.UlEncoderModel.head", "rlpyt.utils.tensor.restore_leading_dims", "observation.type", "img.mul_.mul_.mul_", "img.mul_.mul_.view", "ul_models.UlEncoderModel.view"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.utils.tensor.infer_leading_dims", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.tensor.restore_leading_dims"], ["", "def", "forward", "(", "self", ",", "observation", ")", ":", "\n", "        ", "lead_dim", ",", "T", ",", "B", ",", "img_shape", "=", "infer_leading_dims", "(", "observation", ",", "3", ")", "\n", "if", "observation", ".", "dtype", "==", "torch", ".", "uint8", ":", "\n", "            ", "img", "=", "observation", ".", "type", "(", "torch", ".", "float", ")", "\n", "img", "=", "img", ".", "mul_", "(", "1.", "/", "255", ")", "\n", "", "else", ":", "\n", "            ", "img", "=", "observation", "\n", "", "conv", "=", "self", ".", "conv", "(", "img", ".", "view", "(", "T", "*", "B", ",", "*", "img_shape", ")", ")", "\n", "c", "=", "self", ".", "head", "(", "conv", ".", "view", "(", "T", "*", "B", ",", "-", "1", ")", ")", "\n", "c", ",", "conv", "=", "restore_leading_dims", "(", "(", "c", ",", "conv", ")", ",", "lead_dim", ",", "T", ",", "B", ")", "\n", "return", "c", ",", "conv", "\n", "", "", ""]], "home.repos.pwc.inspect_result.astooke_rlpyt.rl.atari_rl_models.AtariPgModel.__init__": [[23, 66], ["super().__init__", "rlpyt.models.conv2d.Conv2dModel", "atari_rl_models.AtariPgModel.conv.conv_out_size", "rlpyt.models.mlp.MlpModel", "rlpyt.utils.logging.logger.log", "atari_rl_models.AtariPgModel.apply", "rlpyt.utils.logging.logger.log", "rlpyt.models.running_mean_std.RunningMeanStdModel"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.spaces.gym_wrapper.GymSpaceWrapper.__init__", "home.repos.pwc.inspect_result.astooke_rlpyt.rl.atari_rl_models.AtariDqnModel.conv_out_size", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.console.log", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.console.log"], ["def", "__init__", "(", "\n", "self", ",", "\n", "image_shape", ",", "\n", "action_size", ",", "\n", "hidden_sizes", "=", "512", ",", "\n", "stop_conv_grad", "=", "False", ",", "\n", "channels", "=", "None", ",", "# Defaults below.", "\n", "kernel_sizes", "=", "None", ",", "\n", "strides", "=", "None", ",", "\n", "paddings", "=", "None", ",", "\n", "kiaming_init", "=", "True", ",", "\n", "normalize_conv_out", "=", "False", ",", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "c", ",", "h", ",", "w", "=", "image_shape", "\n", "self", ".", "conv", "=", "Conv2dModel", "(", "\n", "in_channels", "=", "c", ",", "\n", "channels", "=", "channels", "or", "[", "32", ",", "64", ",", "64", "]", ",", "\n", "kernel_sizes", "=", "kernel_sizes", "or", "[", "8", ",", "4", ",", "3", "]", ",", "\n", "strides", "=", "strides", "or", "[", "4", ",", "2", ",", "1", "]", ",", "\n", "paddings", "=", "paddings", ",", "\n", ")", "\n", "self", ".", "_conv_out_size", "=", "self", ".", "conv", ".", "conv_out_size", "(", "h", "=", "h", ",", "w", "=", "w", ")", "\n", "self", ".", "pi_v_mlp", "=", "MlpModel", "(", "\n", "input_size", "=", "self", ".", "_conv_out_size", ",", "\n", "hidden_sizes", "=", "hidden_sizes", ",", "\n", "output_size", "=", "action_size", "+", "1", ",", "\n", ")", "\n", "if", "kiaming_init", ":", "\n", "            ", "self", ".", "apply", "(", "weight_init", ")", "\n", "\n", "", "self", ".", "stop_conv_grad", "=", "stop_conv_grad", "\n", "logger", ".", "log", "(", "\n", "\"Model stopping gradient at CONV.\"", "\n", "if", "stop_conv_grad", "else", "\n", "\"Modeul using gradients on all parameters.\"", "\n", ")", "\n", "if", "normalize_conv_out", ":", "\n", "# Havent' seen this make a difference yet.", "\n", "            ", "logger", ".", "log", "(", "\"Model normalizing conv output across all pixels.\"", ")", "\n", "self", ".", "conv_rms", "=", "RunningMeanStdModel", "(", "(", "1", ",", ")", ")", "\n", "self", ".", "var_clip", "=", "1e-6", "\n", "", "self", ".", "normalize_conv_out", "=", "normalize_conv_out", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.rl.atari_rl_models.AtariPgModel.forward": [[67, 92], ["rlpyt.utils.tensor.infer_leading_dims", "atari_rl_models.AtariPgModel.conv", "atari_rl_models.AtariPgModel.pi_v_mlp", "torch.softmax", "torch.softmax", "rlpyt.utils.tensor.restore_leading_dims", "observation.type", "img.mul_.mul_.mul_", "img.mul_.mul_.view", "torch.clamp.detach", "torch.clamp.detach", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp.view", "torch.clamp.view", "torch.clamp.sqrt", "torch.clamp.sqrt"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.utils.tensor.infer_leading_dims", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.tensor.restore_leading_dims"], ["", "def", "forward", "(", "self", ",", "observation", ",", "prev_action", ",", "prev_reward", ")", ":", "\n", "        ", "if", "observation", ".", "dtype", "==", "torch", ".", "uint8", ":", "\n", "            ", "img", "=", "observation", ".", "type", "(", "torch", ".", "float", ")", "\n", "img", "=", "img", ".", "mul_", "(", "1.", "/", "255", ")", "\n", "", "else", ":", "\n", "            ", "img", "=", "observation", "\n", "\n", "", "lead_dim", ",", "T", ",", "B", ",", "img_shape", "=", "infer_leading_dims", "(", "img", ",", "3", ")", "\n", "conv", "=", "self", ".", "conv", "(", "img", ".", "view", "(", "T", "*", "B", ",", "*", "img_shape", ")", ")", "\n", "\n", "if", "self", ".", "stop_conv_grad", ":", "\n", "            ", "conv", "=", "conv", ".", "detach", "(", ")", "\n", "", "if", "self", ".", "normalize_conv_out", ":", "\n", "            ", "conv_var", "=", "self", ".", "conv_rms", ".", "var", "\n", "conv_var", "=", "torch", ".", "clamp", "(", "conv_var", ",", "min", "=", "self", ".", "var_clip", ")", "\n", "# stddev of uniform [a,b] = (b-a)/sqrt(12), 1/sqrt(12)~0.29", "\n", "# then allow [0, 10]?", "\n", "conv", "=", "torch", ".", "clamp", "(", "0.29", "*", "conv", "/", "conv_var", ".", "sqrt", "(", ")", ",", "0", ",", "10", ")", "\n", "\n", "", "pi_v", "=", "self", ".", "pi_v_mlp", "(", "conv", ".", "view", "(", "T", "*", "B", ",", "-", "1", ")", ")", "\n", "pi", "=", "F", ".", "softmax", "(", "pi_v", "[", ":", ",", ":", "-", "1", "]", ",", "dim", "=", "-", "1", ")", "\n", "v", "=", "pi_v", "[", ":", ",", "-", "1", "]", "\n", "\n", "pi", ",", "v", ",", "conv", "=", "restore_leading_dims", "(", "(", "pi", ",", "v", ",", "conv", ")", ",", "lead_dim", ",", "T", ",", "B", ")", "\n", "return", "pi", ",", "v", ",", "conv", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.rl.atari_rl_models.AtariPgModel.update_conv_rms": [[93, 104], ["torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "rlpyt.utils.tensor.infer_leading_dims", "atari_rl_models.AtariPgModel.conv", "atari_rl_models.AtariPgModel.conv_rms.update", "observation.type", "img.mul_.mul_.mul_", "img.mul_.mul_.view", "atari_rl_models.AtariPgModel.view"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.utils.tensor.infer_leading_dims", "home.repos.pwc.inspect_result.astooke_rlpyt.models.running_mean_std.RunningMeanStdModel.update"], ["", "def", "update_conv_rms", "(", "self", ",", "observation", ")", ":", "\n", "        ", "if", "self", ".", "normalize_conv_out", ":", "\n", "            ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "if", "observation", ".", "dtype", "==", "torch", ".", "uint8", ":", "\n", "                    ", "img", "=", "observation", ".", "type", "(", "torch", ".", "float", ")", "\n", "img", "=", "img", ".", "mul_", "(", "1.", "/", "255", ")", "\n", "", "else", ":", "\n", "                    ", "img", "=", "observation", "\n", "", "lead_dim", ",", "T", ",", "B", ",", "img_shape", "=", "infer_leading_dims", "(", "img", ",", "3", ")", "\n", "conv", "=", "self", ".", "conv", "(", "img", ".", "view", "(", "T", "*", "B", ",", "*", "img_shape", ")", ")", "\n", "self", ".", "conv_rms", ".", "update", "(", "conv", ".", "view", "(", "-", "1", ",", "1", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.rl.atari_rl_models.AtariPgModel.parameters": [[105, 109], ["atari_rl_models.AtariPgModel.pi_v_mlp.parameters", "atari_rl_models.AtariPgModel.conv.parameters"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.rl.atari_rl_models.AtariDqnModel.parameters", "home.repos.pwc.inspect_result.astooke_rlpyt.rl.atari_rl_models.AtariDqnModel.parameters"], ["", "", "", "def", "parameters", "(", "self", ")", ":", "\n", "        ", "if", "not", "self", ".", "stop_conv_grad", ":", "\n", "            ", "yield", "from", "self", ".", "conv", ".", "parameters", "(", ")", "\n", "", "yield", "from", "self", ".", "pi_v_mlp", ".", "parameters", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.rl.atari_rl_models.AtariPgModel.named_parameters": [[110, 114], ["atari_rl_models.AtariPgModel.pi_v_mlp.named_parameters", "atari_rl_models.AtariPgModel.conv.named_parameters"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.rl.atari_rl_models.AtariDqnModel.named_parameters", "home.repos.pwc.inspect_result.astooke_rlpyt.rl.atari_rl_models.AtariDqnModel.named_parameters"], ["", "def", "named_parameters", "(", "self", ")", ":", "\n", "        ", "if", "not", "self", ".", "stop_conv_grad", ":", "\n", "            ", "yield", "from", "self", ".", "conv", ".", "named_parameters", "(", ")", "\n", "", "yield", "from", "self", ".", "pi_v_mlp", ".", "named_parameters", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.rl.atari_rl_models.AtariPgModel.conv_out_size": [[115, 118], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "conv_out_size", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_conv_out_size", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.rl.atari_rl_models.AtariDqnModel.__init__": [[125, 167], ["super().__init__", "rlpyt.models.conv2d.Conv2dModel", "atari_rl_models.AtariDqnModel.conv.conv_out_size", "rlpyt.models.mlp.MlpModel", "rlpyt.utils.logging.logger.log", "atari_rl_models.AtariDqnModel.apply", "rlpyt.utils.logging.logger.log", "rlpyt.models.running_mean_std.RunningMeanStdModel"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.spaces.gym_wrapper.GymSpaceWrapper.__init__", "home.repos.pwc.inspect_result.astooke_rlpyt.rl.atari_rl_models.AtariDqnModel.conv_out_size", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.console.log", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.console.log"], ["def", "__init__", "(", "\n", "self", ",", "\n", "image_shape", ",", "\n", "action_size", ",", "\n", "hidden_sizes", "=", "512", ",", "\n", "stop_conv_grad", "=", "False", ",", "\n", "channels", "=", "None", ",", "# Defaults below.", "\n", "kernel_sizes", "=", "None", ",", "\n", "strides", "=", "None", ",", "\n", "paddings", "=", "None", ",", "\n", "kiaming_init", "=", "True", ",", "\n", "normalize_conv_out", "=", "False", ",", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "c", ",", "h", ",", "w", "=", "image_shape", "\n", "self", ".", "conv", "=", "Conv2dModel", "(", "\n", "in_channels", "=", "c", ",", "\n", "channels", "=", "channels", "or", "[", "32", ",", "64", ",", "64", "]", ",", "\n", "kernel_sizes", "=", "kernel_sizes", "or", "[", "8", ",", "4", ",", "3", "]", ",", "\n", "strides", "=", "strides", "or", "[", "4", ",", "2", ",", "1", "]", ",", "\n", "paddings", "=", "paddings", ",", "\n", ")", "\n", "self", ".", "_conv_out_size", "=", "self", ".", "conv", ".", "conv_out_size", "(", "h", "=", "h", ",", "w", "=", "w", ")", "\n", "self", ".", "q_mlp", "=", "MlpModel", "(", "\n", "input_size", "=", "self", ".", "_conv_out_size", ",", "\n", "hidden_sizes", "=", "hidden_sizes", ",", "\n", "output_size", "=", "action_size", ",", "\n", ")", "\n", "if", "kiaming_init", ":", "\n", "            ", "self", ".", "apply", "(", "weight_init", ")", "\n", "\n", "", "self", ".", "stop_conv_grad", "=", "stop_conv_grad", "\n", "logger", ".", "log", "(", "\n", "\"Model stopping gradient at CONV.\"", "\n", "if", "stop_conv_grad", "else", "\n", "\"Modeul using gradients on all parameters.\"", "\n", ")", "\n", "if", "normalize_conv_out", ":", "\n", "            ", "logger", ".", "log", "(", "\"Model normalizing conv output across all pixels.\"", ")", "\n", "self", ".", "conv_rms", "=", "RunningMeanStdModel", "(", "(", "1", ",", ")", ")", "\n", "self", ".", "var_clip", "=", "1e-6", "\n", "", "self", ".", "normalize_conv_out", "=", "normalize_conv_out", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.rl.atari_rl_models.AtariDqnModel.forward": [[168, 191], ["rlpyt.utils.tensor.infer_leading_dims", "atari_rl_models.AtariDqnModel.conv", "atari_rl_models.AtariDqnModel.q_mlp", "rlpyt.utils.tensor.restore_leading_dims", "observation.type", "img.mul_.mul_.mul_", "img.mul_.mul_.view", "torch.clamp.detach", "torch.clamp.detach", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp.view", "torch.clamp.view", "torch.clamp.sqrt", "torch.clamp.sqrt"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.utils.tensor.infer_leading_dims", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.tensor.restore_leading_dims"], ["", "def", "forward", "(", "self", ",", "observation", ",", "prev_action", ",", "prev_reward", ")", ":", "\n", "        ", "if", "observation", ".", "dtype", "==", "torch", ".", "uint8", ":", "\n", "            ", "img", "=", "observation", ".", "type", "(", "torch", ".", "float", ")", "\n", "img", "=", "img", ".", "mul_", "(", "1.", "/", "255", ")", "\n", "", "else", ":", "\n", "            ", "img", "=", "observation", "\n", "\n", "", "lead_dim", ",", "T", ",", "B", ",", "img_shape", "=", "infer_leading_dims", "(", "img", ",", "3", ")", "\n", "conv", "=", "self", ".", "conv", "(", "img", ".", "view", "(", "T", "*", "B", ",", "*", "img_shape", ")", ")", "\n", "\n", "if", "self", ".", "stop_conv_grad", ":", "\n", "            ", "conv", "=", "conv", ".", "detach", "(", ")", "\n", "", "if", "self", ".", "normalize_conv_out", ":", "\n", "            ", "conv_var", "=", "self", ".", "conv_rms", ".", "var", "\n", "conv_var", "=", "torch", ".", "clamp", "(", "conv_var", ",", "min", "=", "self", ".", "var_clip", ")", "\n", "# stddev of uniform [a,b] = (b-a)/sqrt(12), 1/sqrt(12)~0.29", "\n", "# then allow [0, 10]?", "\n", "conv", "=", "torch", ".", "clamp", "(", "0.29", "*", "conv", "/", "conv_var", ".", "sqrt", "(", ")", ",", "0", ",", "10", ")", "\n", "\n", "", "q", "=", "self", ".", "q_mlp", "(", "conv", ".", "view", "(", "T", "*", "B", ",", "-", "1", ")", ")", "\n", "\n", "q", ",", "conv", "=", "restore_leading_dims", "(", "(", "q", ",", "conv", ")", ",", "lead_dim", ",", "T", ",", "B", ")", "\n", "return", "q", ",", "conv", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.rl.atari_rl_models.AtariDqnModel.update_conv_rms": [[192, 203], ["torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "rlpyt.utils.tensor.infer_leading_dims", "atari_rl_models.AtariDqnModel.conv", "atari_rl_models.AtariDqnModel.conv_rms.update", "observation.type", "img.mul_.mul_.mul_", "img.mul_.mul_.view", "atari_rl_models.AtariDqnModel.view"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.utils.tensor.infer_leading_dims", "home.repos.pwc.inspect_result.astooke_rlpyt.models.running_mean_std.RunningMeanStdModel.update"], ["", "def", "update_conv_rms", "(", "self", ",", "observation", ")", ":", "\n", "        ", "if", "self", ".", "normalize_conv_out", ":", "\n", "            ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "if", "observation", ".", "dtype", "==", "torch", ".", "uint8", ":", "\n", "                    ", "img", "=", "observation", ".", "type", "(", "torch", ".", "float", ")", "\n", "img", "=", "img", ".", "mul_", "(", "1.", "/", "255", ")", "\n", "", "else", ":", "\n", "                    ", "img", "=", "observation", "\n", "", "lead_dim", ",", "T", ",", "B", ",", "img_shape", "=", "infer_leading_dims", "(", "img", ",", "3", ")", "\n", "conv", "=", "self", ".", "conv", "(", "img", ".", "view", "(", "T", "*", "B", ",", "*", "img_shape", ")", ")", "\n", "self", ".", "conv_rms", ".", "update", "(", "conv", ".", "view", "(", "-", "1", ",", "1", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.rl.atari_rl_models.AtariDqnModel.parameters": [[204, 208], ["atari_rl_models.AtariDqnModel.q_mlp.parameters", "atari_rl_models.AtariDqnModel.conv.parameters"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.rl.atari_rl_models.AtariDqnModel.parameters", "home.repos.pwc.inspect_result.astooke_rlpyt.rl.atari_rl_models.AtariDqnModel.parameters"], ["", "", "", "def", "parameters", "(", "self", ")", ":", "\n", "        ", "if", "not", "self", ".", "stop_conv_grad", ":", "\n", "            ", "yield", "from", "self", ".", "conv", ".", "parameters", "(", ")", "\n", "", "yield", "from", "self", ".", "q_mlp", ".", "parameters", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.rl.atari_rl_models.AtariDqnModel.named_parameters": [[209, 213], ["atari_rl_models.AtariDqnModel.q_mlp.named_parameters", "atari_rl_models.AtariDqnModel.conv.named_parameters"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.rl.atari_rl_models.AtariDqnModel.named_parameters", "home.repos.pwc.inspect_result.astooke_rlpyt.rl.atari_rl_models.AtariDqnModel.named_parameters"], ["", "def", "named_parameters", "(", "self", ")", ":", "\n", "        ", "if", "not", "self", ".", "stop_conv_grad", ":", "\n", "            ", "yield", "from", "self", ".", "conv", ".", "named_parameters", "(", ")", "\n", "", "yield", "from", "self", ".", "q_mlp", ".", "named_parameters", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.rl.atari_rl_models.AtariDqnModel.conv_out_size": [[214, 217], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "conv_out_size", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_conv_out_size", "\n", "", "", ""]], "home.repos.pwc.inspect_result.astooke_rlpyt.rl.atari_rl_models.weight_init": [[13, 17], ["isinstance", "torch.nn.init.kaiming_normal_", "torch.nn.init.kaiming_normal_", "torch.nn.init.zeros_", "torch.nn.init.zeros_"], "function", ["None"], ["def", "weight_init", "(", "m", ")", ":", "\n", "    ", "if", "isinstance", "(", "m", ",", "(", "torch", ".", "nn", ".", "Linear", ",", "torch", ".", "nn", ".", "Conv2d", ")", ")", ":", "\n", "        ", "torch", ".", "nn", ".", "init", ".", "kaiming_normal_", "(", "m", ".", "weight", ",", "mode", "=", "\"fan_in\"", ",", "nonlinearity", "=", "\"relu\"", ")", "\n", "torch", ".", "nn", ".", "init", ".", "zeros_", "(", "m", ".", "bias", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.rl.sac_rl_models.SacModel.__init__": [[30, 35], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.spaces.gym_wrapper.GymSpaceWrapper.__init__"], ["def", "__init__", "(", "self", ",", "conv", ",", "pi_fc1", ",", "pi_mlp", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "conv", "=", "conv", "\n", "self", ".", "pi_fc1", "=", "pi_fc1", "\n", "self", ".", "pi_mlp", "=", "pi_mlp", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.rl.sac_rl_models.SacModel.forward": [[36, 42], ["sac_rl_models.SacModel.conv", "sac_rl_models.SacModel.pi_fc1", "sac_rl_models.SacModel.pi_mlp"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "observation", ",", "prev_action", ",", "prev_reward", ")", ":", "\n", "        ", "\"\"\"Just to keep the standard obs, prev_action, prev_rew interface.\"\"\"", "\n", "conv", "=", "self", ".", "conv", "(", "observation", ")", "\n", "latent", "=", "self", ".", "pi_fc1", "(", "conv", ")", "\n", "mu", ",", "log_std", "=", "self", ".", "pi_mlp", "(", "latent", ",", "prev_action", ",", "prev_reward", ")", "\n", "return", "mu", ",", "log_std", ",", "latent", ",", "conv", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.rl.sac_rl_models.SacConvModel.__init__": [[46, 67], ["torch.Module.__init__", "rlpyt.models.conv2d.Conv2dModel", "sac_rl_models.SacConvModel.conv.conv_out_shape", "sac_rl_models.SacConvModel.conv.conv_out_size"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.spaces.gym_wrapper.GymSpaceWrapper.__init__", "home.repos.pwc.inspect_result.astooke_rlpyt.ul.stdim_models.Conv2dStdimModel.conv_out_shape", "home.repos.pwc.inspect_result.astooke_rlpyt.rl.atari_rl_models.AtariDqnModel.conv_out_size"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "image_shape", ",", "\n", "channels", "=", "None", ",", "\n", "kernel_sizes", "=", "None", ",", "\n", "strides", "=", "None", ",", "\n", "paddings", "=", "None", ",", "\n", "final_nonlinearity", "=", "True", ",", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "c", ",", "h", ",", "w", "=", "image_shape", "\n", "self", ".", "conv", "=", "Conv2dModel", "(", "\n", "in_channels", "=", "c", ",", "\n", "channels", "=", "channels", "or", "[", "32", ",", "32", ",", "32", ",", "32", "]", ",", "\n", "kernel_sizes", "=", "kernel_sizes", "or", "[", "3", ",", "3", ",", "3", ",", "3", "]", ",", "\n", "strides", "=", "strides", "or", "[", "2", ",", "1", ",", "1", ",", "1", "]", ",", "\n", "paddings", "=", "paddings", ",", "\n", "final_nonlinearity", "=", "final_nonlinearity", ",", "\n", ")", "\n", "self", ".", "_output_shape", "=", "self", ".", "conv", ".", "conv_out_shape", "(", "h", "=", "h", ",", "w", "=", "w", ",", "c", "=", "c", ")", "\n", "self", ".", "_output_size", "=", "self", ".", "conv", ".", "conv_out_size", "(", "h", "=", "h", ",", "w", "=", "w", ",", "c", "=", "c", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.rl.sac_rl_models.SacConvModel.forward": [[68, 79], ["rlpyt.utils.tensor.infer_leading_dims", "sac_rl_models.SacConvModel.conv", "rlpyt.utils.tensor.restore_leading_dims", "observation.type", "img.mul_.mul_.mul_", "img.mul_.mul_.view"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.utils.tensor.infer_leading_dims", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.tensor.restore_leading_dims"], ["", "def", "forward", "(", "self", ",", "observation", ")", ":", "\n", "        ", "if", "observation", ".", "dtype", "==", "torch", ".", "uint8", ":", "\n", "            ", "img", "=", "observation", ".", "type", "(", "torch", ".", "float", ")", "\n", "img", "=", "img", ".", "mul_", "(", "1.", "/", "255", ")", "\n", "", "else", ":", "\n", "            ", "img", "=", "observation", "\n", "\n", "", "lead_dim", ",", "T", ",", "B", ",", "img_shape", "=", "infer_leading_dims", "(", "img", ",", "3", ")", "\n", "conv", "=", "self", ".", "conv", "(", "img", ".", "view", "(", "T", "*", "B", ",", "*", "img_shape", ")", ")", "\n", "conv", "=", "restore_leading_dims", "(", "conv", ",", "lead_dim", ",", "T", ",", "B", ")", "\n", "return", "conv", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.rl.sac_rl_models.SacConvModel.output_shape": [[80, 83], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "output_shape", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_output_shape", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.rl.sac_rl_models.SacConvModel.output_size": [[84, 87], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "output_size", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_output_size", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.rl.sac_rl_models.SacFc1Model.__init__": [[91, 101], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear", "torch.LayerNorm", "torch.LayerNorm", "torch.LayerNorm"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.spaces.gym_wrapper.GymSpaceWrapper.__init__"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "input_size", ",", "\n", "latent_size", ",", "\n", "layer_norm", "=", "True", ",", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "linear", "=", "nn", ".", "Linear", "(", "input_size", ",", "latent_size", ")", "\n", "self", ".", "layer_norm", "=", "nn", ".", "LayerNorm", "(", "latent_size", ")", "if", "layer_norm", "else", "None", "\n", "self", ".", "_output_size", "=", "latent_size", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.rl.sac_rl_models.SacFc1Model.forward": [[102, 113], ["rlpyt.utils.tensor.infer_leading_dims", "torch.relu", "torch.relu", "torch.relu", "sac_rl_models.SacFc1Model.linear", "rlpyt.utils.tensor.restore_leading_dims", "conv_out.mul_.mul_.type", "conv_out.mul_.mul_.mul_", "conv_out.mul_.mul_.view", "sac_rl_models.SacFc1Model.layer_norm"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.utils.tensor.infer_leading_dims", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.tensor.restore_leading_dims"], ["", "def", "forward", "(", "self", ",", "conv_out", ")", ":", "\n", "        ", "if", "conv_out", ".", "dtype", "==", "torch", ".", "uint8", ":", "# Testing NoConv model", "\n", "            ", "conv_out", "=", "conv_out", ".", "type", "(", "torch", ".", "float", ")", "\n", "conv_out", "=", "conv_out", ".", "mul_", "(", "1.", "/", "255", ")", "\n", "", "lead_dim", ",", "T", ",", "B", ",", "_", "=", "infer_leading_dims", "(", "conv_out", ",", "3", ")", "\n", "conv_out", "=", "F", ".", "relu", "(", "conv_out", ".", "view", "(", "T", "*", "B", ",", "-", "1", ")", ")", "# bc conv_out might be pre-activation", "\n", "latent", "=", "self", ".", "linear", "(", "conv_out", ")", "\n", "if", "self", ".", "layer_norm", "is", "not", "None", ":", "\n", "            ", "latent", "=", "self", ".", "layer_norm", "(", "latent", ")", "\n", "", "latent", "=", "restore_leading_dims", "(", "latent", ",", "lead_dim", ",", "T", ",", "B", ")", "\n", "return", "latent", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.rl.sac_rl_models.SacFc1Model.output_size": [[114, 117], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "output_size", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_output_size", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.rl.sac_rl_models.SacActorModel.__init__": [[121, 138], ["torch.Module.__init__", "rlpyt.models.mlp.MlpModel", "sac_rl_models.SacActorModel.apply"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.spaces.gym_wrapper.GymSpaceWrapper.__init__"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "input_size", ",", "\n", "action_size", ",", "\n", "hidden_sizes", ",", "\n", "min_log_std", "=", "-", "10.", ",", "\n", "max_log_std", "=", "2.", ",", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "mlp", "=", "MlpModel", "(", "\n", "input_size", "=", "input_size", ",", "\n", "hidden_sizes", "=", "hidden_sizes", ",", "\n", "output_size", "=", "action_size", "*", "2", ",", "\n", ")", "\n", "self", ".", "apply", "(", "weight_init", ")", "\n", "self", ".", "min_log_std", "=", "min_log_std", "\n", "self", ".", "max_log_std", "=", "max_log_std", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.rl.sac_rl_models.SacActorModel.forward": [[139, 150], ["rlpyt.utils.tensor.infer_leading_dims", "sac_rl_models.SacActorModel.mlp", "sac_rl_models.SacActorModel.chunk", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "rlpyt.utils.tensor.restore_leading_dims", "latent.view"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.utils.tensor.infer_leading_dims", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.tensor.restore_leading_dims"], ["", "def", "forward", "(", "self", ",", "latent", ",", "prev_action", "=", "None", ",", "prev_reward", "=", "None", ")", ":", "\n", "        ", "lead_dim", ",", "T", ",", "B", ",", "_", "=", "infer_leading_dims", "(", "latent", ",", "1", ")", "# latent is vector", "\n", "\n", "out", "=", "self", ".", "mlp", "(", "latent", ".", "view", "(", "T", "*", "B", ",", "-", "1", ")", ")", "\n", "mu", ",", "log_std", "=", "out", ".", "chunk", "(", "chunks", "=", "2", ",", "dim", "=", "-", "1", ")", "\n", "# Squash log_std into range.", "\n", "log_std", "=", "torch", ".", "tanh", "(", "log_std", ")", "\n", "log_std", "=", "self", ".", "min_log_std", "+", "0.5", "*", "(", "\n", "self", ".", "max_log_std", "-", "self", ".", "min_log_std", ")", "*", "(", "1", "+", "log_std", ")", "\n", "mu", ",", "log_std", "=", "restore_leading_dims", "(", "(", "mu", ",", "log_std", ")", ",", "lead_dim", ",", "T", ",", "B", ")", "\n", "return", "mu", ",", "log_std", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.rl.sac_rl_models.SacCriticModel.__init__": [[154, 172], ["torch.Module.__init__", "rlpyt.models.mlp.MlpModel", "rlpyt.models.mlp.MlpModel", "sac_rl_models.SacCriticModel.apply"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.spaces.gym_wrapper.GymSpaceWrapper.__init__"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "input_size", ",", "\n", "action_size", ",", "\n", "hidden_sizes", ",", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "mlp1", "=", "MlpModel", "(", "\n", "input_size", "=", "input_size", "+", "action_size", ",", "\n", "hidden_sizes", "=", "hidden_sizes", ",", "\n", "output_size", "=", "1", ",", "\n", ")", "\n", "self", ".", "mlp2", "=", "MlpModel", "(", "\n", "input_size", "=", "input_size", "+", "action_size", ",", "\n", "hidden_sizes", "=", "hidden_sizes", ",", "\n", "output_size", "=", "1", ",", "\n", ")", "\n", "self", ".", "apply", "(", "weight_init", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.rl.sac_rl_models.SacCriticModel.forward": [[173, 184], ["rlpyt.utils.tensor.infer_leading_dims", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "sac_rl_models.SacCriticModel.mlp1().squeeze", "sac_rl_models.SacCriticModel.mlp2().squeeze", "rlpyt.utils.tensor.restore_leading_dims", "latent.view", "action.view", "sac_rl_models.SacCriticModel.mlp1", "sac_rl_models.SacCriticModel.mlp2"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.utils.tensor.infer_leading_dims", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.tensor.restore_leading_dims"], ["", "def", "forward", "(", "self", ",", "latent", ",", "action", ",", "prev_action", "=", "None", ",", "prev_reward", "=", "None", ")", ":", "\n", "        ", "lead_dim", ",", "T", ",", "B", ",", "_", "=", "infer_leading_dims", "(", "latent", ",", "1", ")", "# latent is vector", "\n", "\n", "q_input", "=", "torch", ".", "cat", "(", "[", "\n", "latent", ".", "view", "(", "T", "*", "B", ",", "-", "1", ")", ",", "\n", "action", ".", "view", "(", "T", "*", "B", ",", "-", "1", ")", ",", "\n", "]", ",", "dim", "=", "1", ")", "\n", "q1", "=", "self", ".", "mlp1", "(", "q_input", ")", ".", "squeeze", "(", "-", "1", ")", "\n", "q2", "=", "self", ".", "mlp2", "(", "q_input", ")", ".", "squeeze", "(", "-", "1", ")", "\n", "q1", ",", "q2", "=", "restore_leading_dims", "(", "(", "q1", ",", "q2", ")", ",", "lead_dim", ",", "T", ",", "B", ")", "\n", "return", "q1", ",", "q2", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.rl.sac_rl_models.SacNoConvModel.__init__": [[192, 197], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.spaces.gym_wrapper.GymSpaceWrapper.__init__"], ["def", "__init__", "(", "self", ",", "pi_fc1", ",", "pi_mlp", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "# self.conv = conv", "\n", "self", ".", "pi_fc1", "=", "pi_fc1", "\n", "self", ".", "pi_mlp", "=", "pi_mlp", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.rl.sac_rl_models.SacNoConvModel.forward": [[198, 205], ["sac_rl_models.SacNoConvModel.pi_fc1", "sac_rl_models.SacNoConvModel.pi_mlp"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "observation", ",", "prev_action", ",", "prev_reward", ")", ":", "\n", "        ", "\"\"\"Just to keep the standard obs, prev_action, prev_rew interface.\"\"\"", "\n", "# conv = self.conv(observation)", "\n", "conv", "=", "observation", "\n", "latent", "=", "self", ".", "pi_fc1", "(", "conv", ")", "\n", "mu", ",", "log_std", "=", "self", ".", "pi_mlp", "(", "latent", ",", "prev_action", ",", "prev_reward", ")", "\n", "return", "mu", ",", "log_std", ",", "latent", "\n", "", "", ""]], "home.repos.pwc.inspect_result.astooke_rlpyt.rl.sac_rl_models.weight_init": [[12, 25], ["isinstance", "torch.init.orthogonal_", "m.bias.data.fill_", "isinstance", "isinstance", "m.weight.data.fill_", "m.bias.data.fill_", "torch.init.calculate_gain", "torch.init.orthogonal_", "m.weight.size", "m.weight.size", "m.weight.size"], "function", ["home.repos.pwc.inspect_result.astooke_rlpyt.samplers.collections.BatchSpec.size", "home.repos.pwc.inspect_result.astooke_rlpyt.samplers.collections.BatchSpec.size", "home.repos.pwc.inspect_result.astooke_rlpyt.samplers.collections.BatchSpec.size"], ["def", "weight_init", "(", "m", ")", ":", "\n", "    ", "\"\"\"Custom weight init for Conv2D and Linear layers.\"\"\"", "\n", "if", "isinstance", "(", "m", ",", "nn", ".", "Linear", ")", ":", "\n", "        ", "nn", ".", "init", ".", "orthogonal_", "(", "m", ".", "weight", ".", "data", ")", "\n", "m", ".", "bias", ".", "data", ".", "fill_", "(", "0.0", ")", "\n", "", "elif", "isinstance", "(", "m", ",", "nn", ".", "Conv2d", ")", "or", "isinstance", "(", "m", ",", "nn", ".", "ConvTranspose2d", ")", ":", "\n", "# delta-orthogonal init from https://arxiv.org/pdf/1806.05393.pdf", "\n", "        ", "assert", "m", ".", "weight", ".", "size", "(", "2", ")", "==", "m", ".", "weight", ".", "size", "(", "3", ")", "\n", "m", ".", "weight", ".", "data", ".", "fill_", "(", "0.0", ")", "\n", "m", ".", "bias", ".", "data", ".", "fill_", "(", "0.0", ")", "\n", "mid", "=", "m", ".", "weight", ".", "size", "(", "2", ")", "//", "2", "\n", "gain", "=", "nn", ".", "init", ".", "calculate_gain", "(", "'relu'", ")", "\n", "nn", ".", "init", ".", "orthogonal_", "(", "m", ".", "weight", ".", "data", "[", ":", ",", ":", ",", "mid", ",", "mid", "]", ",", "gain", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.runners.envstep_runner.MinibatchRlEvalEnvStep.__init__": [[11, 14], ["rlpyt.runners.minibatch_rl.MinibatchRlEval.__init__"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.spaces.gym_wrapper.GymSpaceWrapper.__init__"], ["    ", "def", "__init__", "(", "self", ",", "*", "args", ",", "frame_skip", "=", "1", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "self", ".", "_frame_skip", "=", "frame_skip", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.runners.envstep_runner.MinibatchRlEvalEnvStep.log_diagnostics": [[15, 69], ["sum", "rlpyt.utils.logging.logger.record_tabular", "rlpyt.utils.logging.logger.record_tabular", "rlpyt.utils.logging.logger.record_tabular", "time.time", "rlpyt.utils.logging.logger.record_tabular", "rlpyt.utils.logging.logger.record_tabular", "rlpyt.utils.logging.logger.record_tabular", "rlpyt.utils.logging.logger.record_tabular", "rlpyt.utils.logging.logger.record_tabular", "rlpyt.utils.logging.logger.record_tabular", "rlpyt.utils.logging.logger.record_tabular", "rlpyt.utils.logging.logger.record_tabular", "rlpyt.utils.logging.logger.record_tabular", "rlpyt.utils.logging.logger.record_tabular", "envstep_runner.MinibatchRlEvalEnvStep._log_infos", "rlpyt.utils.logging.logger.dump_tabular", "rlpyt.utils.logging.logger.log", "len", "envstep_runner.MinibatchRlEvalEnvStep.pbar.stop", "envstep_runner.MinibatchRlEvalEnvStep.save_itr_snapshot", "float", "float", "rlpyt.utils.logging.logger.record_tabular", "rlpyt.utils.logging.logger.log", "rlpyt.utils.prog_bar.ProgBarCounter"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.logging.logger.record_tabular", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.logger.record_tabular", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.logger.record_tabular", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.logger.record_tabular", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.logger.record_tabular", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.logger.record_tabular", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.logger.record_tabular", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.logger.record_tabular", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.logger.record_tabular", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.logger.record_tabular", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.logger.record_tabular", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.logger.record_tabular", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.logger.record_tabular", "home.repos.pwc.inspect_result.astooke_rlpyt.runners.minibatch_rl.MinibatchRlBase._log_infos", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.logger.dump_tabular", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.console.log", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.prog_bar.ProgBarCounter.stop", "home.repos.pwc.inspect_result.astooke_rlpyt.runners.minibatch_rl.MinibatchRlBase.save_itr_snapshot", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.logger.record_tabular", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.console.log"], ["", "def", "log_diagnostics", "(", "self", ",", "itr", ",", "eval_traj_infos", ",", "eval_time", ")", ":", "\n", "        ", "\"\"\"\n        Write diagnostics (including stored ones) to csv via the logger.\n        ONE NEW LINE VS REGULAR RUNNER, TO LOG ENV STEPS = steps*frame_skip\n        \"\"\"", "\n", "if", "not", "eval_traj_infos", ":", "\n", "            ", "logger", ".", "log", "(", "\"WARNING: had no complete trajectories in eval.\"", ")", "\n", "", "steps_in_eval", "=", "sum", "(", "[", "info", "[", "\"Length\"", "]", "for", "info", "in", "eval_traj_infos", "]", ")", "\n", "logger", ".", "record_tabular", "(", "'StepsInEval'", ",", "steps_in_eval", ")", "\n", "logger", ".", "record_tabular", "(", "'TrajsInEval'", ",", "len", "(", "eval_traj_infos", ")", ")", "\n", "self", ".", "_cum_eval_time", "+=", "eval_time", "\n", "logger", ".", "record_tabular", "(", "'CumEvalTime'", ",", "self", ".", "_cum_eval_time", ")", "\n", "\n", "if", "itr", ">", "0", ":", "\n", "            ", "self", ".", "pbar", ".", "stop", "(", ")", "\n", "", "if", "itr", ">=", "self", ".", "min_itr_learn", "-", "1", ":", "\n", "            ", "self", ".", "save_itr_snapshot", "(", "itr", ")", "\n", "", "new_time", "=", "time", ".", "time", "(", ")", "\n", "self", ".", "_cum_time", "=", "new_time", "-", "self", ".", "_start_time", "\n", "train_time_elapsed", "=", "new_time", "-", "self", ".", "_last_time", "-", "eval_time", "\n", "new_updates", "=", "self", ".", "algo", ".", "update_counter", "-", "self", ".", "_last_update_counter", "\n", "new_samples", "=", "(", "self", ".", "sampler", ".", "batch_size", "*", "self", ".", "world_size", "*", "\n", "self", ".", "log_interval_itrs", ")", "\n", "updates_per_second", "=", "(", "float", "(", "'nan'", ")", "if", "itr", "==", "0", "else", "\n", "new_updates", "/", "train_time_elapsed", ")", "\n", "samples_per_second", "=", "(", "float", "(", "'nan'", ")", "if", "itr", "==", "0", "else", "\n", "new_samples", "/", "train_time_elapsed", ")", "\n", "replay_ratio", "=", "(", "new_updates", "*", "self", ".", "algo", ".", "batch_size", "*", "self", ".", "world_size", "/", "\n", "new_samples", ")", "\n", "cum_replay_ratio", "=", "(", "self", ".", "algo", ".", "batch_size", "*", "self", ".", "algo", ".", "update_counter", "/", "\n", "(", "(", "itr", "+", "1", ")", "*", "self", ".", "sampler", ".", "batch_size", ")", ")", "# world_size cancels.", "\n", "cum_steps", "=", "(", "itr", "+", "1", ")", "*", "self", ".", "sampler", ".", "batch_size", "*", "self", ".", "world_size", "\n", "\n", "if", "self", ".", "_eval", ":", "\n", "            ", "logger", ".", "record_tabular", "(", "'CumTrainTime'", ",", "\n", "self", ".", "_cum_time", "-", "self", ".", "_cum_eval_time", ")", "# Already added new eval_time.", "\n", "", "logger", ".", "record_tabular", "(", "'Iteration'", ",", "itr", ")", "\n", "logger", ".", "record_tabular", "(", "'CumTime (s)'", ",", "self", ".", "_cum_time", ")", "\n", "logger", ".", "record_tabular", "(", "'CumSteps'", ",", "cum_steps", ")", "\n", "logger", ".", "record_tabular", "(", "'EnvSteps'", ",", "cum_steps", "*", "self", ".", "_frame_skip", ")", "# NEW LINE", "\n", "logger", ".", "record_tabular", "(", "'CumCompletedTrajs'", ",", "self", ".", "_cum_completed_trajs", ")", "\n", "logger", ".", "record_tabular", "(", "'CumUpdates'", ",", "self", ".", "algo", ".", "update_counter", ")", "\n", "logger", ".", "record_tabular", "(", "'StepsPerSecond'", ",", "samples_per_second", ")", "\n", "logger", ".", "record_tabular", "(", "'UpdatesPerSecond'", ",", "updates_per_second", ")", "\n", "logger", ".", "record_tabular", "(", "'ReplayRatio'", ",", "replay_ratio", ")", "\n", "logger", ".", "record_tabular", "(", "'CumReplayRatio'", ",", "cum_replay_ratio", ")", "\n", "self", ".", "_log_infos", "(", "eval_traj_infos", ")", "\n", "logger", ".", "dump_tabular", "(", "with_prefix", "=", "False", ")", "\n", "\n", "self", ".", "_last_time", "=", "new_time", "\n", "self", ".", "_last_update_counter", "=", "self", ".", "algo", ".", "update_counter", "\n", "if", "itr", "<", "self", ".", "n_itr", "-", "1", ":", "\n", "            ", "logger", ".", "log", "(", "f\"Optimizing over {self.log_interval_itrs} iterations.\"", ")", "\n", "self", ".", "pbar", "=", "ProgBarCounter", "(", "self", ".", "log_interval_itrs", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.astooke_rlpyt.runners.minibatch_rl_replaysaver.ReplaySaverMixin.log_diagnostics": [[14, 30], ["super().log_diagnostics", "rlpyt.utils.logging.logger.log", "rlpyt.utils.logging.logger.get_snapshot_mode", "os.join", "rlpyt.utils.logging.logger.log", "rlpyt.utils.logging.logger.get_snapshot_dir", "open", "pickle.dump"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.runners.minibatch_rl.MinibatchRlEval.log_diagnostics", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.console.log", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.logger.get_snapshot_mode", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.console.log", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.logger.get_snapshot_dir"], ["    ", "def", "log_diagnostics", "(", "self", ",", "itr", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "if", "itr", ">", "0", ":", "\n", "            ", "logger", ".", "log", "(", "\"Saving replay buffer...\"", ")", "\n", "cum_steps", "=", "(", "itr", "+", "1", ")", "*", "self", ".", "sampler", ".", "batch_size", "*", "self", ".", "world_size", "\n", "snapshot_mode", "=", "logger", ".", "get_snapshot_mode", "(", ")", "\n", "if", "snapshot_mode", "==", "\"all\"", ":", "\n", "                ", "filename", "=", "f\"replaybuffer_{cum_steps}.pkl\"", "\n", "", "elif", "snapshot_mode", "==", "\"last\"", ":", "\n", "                ", "filename", "=", "\"replaybuffer.pkl\"", "\n", "", "else", ":", "\n", "                ", "raise", "NotImplementedError", "\n", "", "filename", "=", "osp", ".", "join", "(", "logger", ".", "get_snapshot_dir", "(", ")", ",", "filename", ")", "\n", "with", "open", "(", "filename", ",", "\"wb\"", ")", "as", "fh", ":", "\n", "                ", "pickle", ".", "dump", "(", "self", ".", "algo", ".", "replay_buffer", ",", "fh", ",", "protocol", "=", "4", ")", "\n", "", "logger", ".", "log", "(", "\"Replay buffer saved.\"", ")", "\n", "", "super", "(", ")", ".", "log_diagnostics", "(", "itr", ",", "*", "args", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.runners.unsupervised_learning.UnsupervisedLearning.__init__": [[15, 27], ["int", "rlpyt.utils.quick_args.save__init__args", "dict", "locals"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.utils.quick_args.save__init__args"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "algo", ",", "\n", "n_updates", ",", "\n", "seed", "=", "None", ",", "\n", "affinity", "=", "None", ",", "\n", "log_interval_updates", "=", "1e3", ",", "\n", "snapshot_gap_intervals", "=", "None", ",", "# units: log_intervals", "\n", ")", ":", "\n", "        ", "n_updates", "=", "int", "(", "n_updates", ")", "\n", "affinity", "=", "dict", "(", ")", "if", "affinity", "is", "None", "else", "affinity", "\n", "save__init__args", "(", "locals", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.runners.unsupervised_learning.UnsupervisedLearning.startup": [[28, 53], ["psutil.Process", "rlpyt.utils.logging.logger.log", "rlpyt.utils.logging.logger.log", "rlpyt.utils.seed.set_seed", "unsupervised_learning.UnsupervisedLearning.algo.initialize", "unsupervised_learning.UnsupervisedLearning.initialize_logging", "psutil.Process.cpu_affinity", "unsupervised_learning.UnsupervisedLearning.affinity.get", "torch.set_num_threads", "rlpyt.utils.seed.make_seed", "unsupervised_learning.UnsupervisedLearning.affinity.get", "psutil.Process.cpu_affinity", "unsupervised_learning.UnsupervisedLearning.affinity.get", "unsupervised_learning.UnsupervisedLearning.affinity.get", "getattr", "getattr", "torch.get_num_threads"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.logging.console.log", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.console.log", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.seed.set_seed", "home.repos.pwc.inspect_result.astooke_rlpyt.safe.cppo_agent.CppoLstmAgent.initialize", "home.repos.pwc.inspect_result.astooke_rlpyt.runners.minibatch_rl.MinibatchRlEval.initialize_logging", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.collections.NamedArrayTuple.get", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.seed.make_seed", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.collections.NamedArrayTuple.get", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.collections.NamedArrayTuple.get", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.collections.NamedArrayTuple.get"], ["", "def", "startup", "(", "self", ")", ":", "\n", "        ", "p", "=", "psutil", ".", "Process", "(", ")", "\n", "try", ":", "\n", "            ", "if", "(", "self", ".", "affinity", ".", "get", "(", "\"master_cpus\"", ",", "None", ")", "is", "not", "None", "and", "\n", "self", ".", "affinity", ".", "get", "(", "\"set_affinity\"", ",", "True", ")", ")", ":", "\n", "                ", "p", ".", "cpu_affinity", "(", "self", ".", "affinity", "[", "\"master_cpus\"", "]", ")", "\n", "", "cpu_affin", "=", "p", ".", "cpu_affinity", "(", ")", "\n", "", "except", "AttributeError", ":", "\n", "            ", "cpu_affin", "=", "\"UNAVAILABLE MacOS\"", "\n", "", "logger", ".", "log", "(", "f\"Runner {getattr(self, 'rank', '')} master CPU affinity: \"", "\n", "f\"{cpu_affin}.\"", ")", "\n", "if", "self", ".", "affinity", ".", "get", "(", "\"master_torch_threads\"", ",", "None", ")", "is", "not", "None", ":", "\n", "            ", "torch", ".", "set_num_threads", "(", "self", ".", "affinity", "[", "\"master_torch_threads\"", "]", ")", "\n", "", "logger", ".", "log", "(", "f\"Runner {getattr(self, 'rank', '')} master Torch threads: \"", "\n", "f\"{torch.get_num_threads()}.\"", ")", "\n", "if", "self", ".", "seed", "is", "None", ":", "\n", "            ", "self", ".", "seed", "=", "make_seed", "(", ")", "\n", "", "set_seed", "(", "self", ".", "seed", ")", "\n", "# self.rank = rank = getattr(self, \"rank\", 0)", "\n", "# self.world_size = world_size = getattr(self, \"world_size\", 1)", "\n", "self", ".", "algo", ".", "initialize", "(", "\n", "n_updates", "=", "self", ".", "n_updates", ",", "\n", "cuda_idx", "=", "self", ".", "affinity", ".", "get", "(", "\"cuda_idx\"", ",", "None", ")", ",", "\n", ")", "\n", "self", ".", "initialize_logging", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.runners.unsupervised_learning.UnsupervisedLearning.initialize_logging": [[54, 62], ["time.time", "rlpyt.utils.prog_bar.ProgBarCounter", "list", "rlpyt.utils.logging.logger.set_snapshot_gap"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.logging.logger.set_snapshot_gap"], ["", "def", "initialize_logging", "(", "self", ")", ":", "\n", "        ", "self", ".", "_opt_infos", "=", "{", "k", ":", "list", "(", ")", "for", "k", "in", "self", ".", "algo", ".", "opt_info_fields", "}", "\n", "self", ".", "_start_time", "=", "self", ".", "_last_time", "=", "time", ".", "time", "(", ")", "\n", "self", ".", "_cum_time", "=", "0.", "\n", "if", "self", ".", "snapshot_gap_intervals", "is", "not", "None", ":", "\n", "            ", "logger", ".", "set_snapshot_gap", "(", "\n", "self", ".", "snapshot_gap_intervals", "*", "self", ".", "log_interval_updates", ")", "\n", "", "self", ".", "pbar", "=", "ProgBarCounter", "(", "self", ".", "log_interval_updates", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.runners.unsupervised_learning.UnsupervisedLearning.shutdown": [[63, 66], ["rlpyt.utils.logging.logger.log", "unsupervised_learning.UnsupervisedLearning.pbar.stop"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.logging.console.log", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.prog_bar.ProgBarCounter.stop"], ["", "def", "shutdown", "(", "self", ")", ":", "\n", "        ", "logger", ".", "log", "(", "\"Pretraining complete.\"", ")", "\n", "self", ".", "pbar", ".", "stop", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.runners.unsupervised_learning.UnsupervisedLearning.get_itr_snapshot": [[67, 71], ["dict", "unsupervised_learning.UnsupervisedLearning.algo.state_dict"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.replay_saver.DummyOptimizer.state_dict"], ["", "def", "get_itr_snapshot", "(", "self", ",", "itr", ")", ":", "\n", "        ", "return", "dict", "(", "\n", "itr", "=", "itr", ",", "\n", "algo_state_dict", "=", "self", ".", "algo", ".", "state_dict", "(", ")", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.runners.unsupervised_learning.UnsupervisedLearning.save_itr_snapshot": [[73, 82], ["rlpyt.utils.logging.logger.log", "unsupervised_learning.UnsupervisedLearning.get_itr_snapshot", "rlpyt.utils.logging.logger.save_itr_params", "rlpyt.utils.logging.logger.log"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.logging.console.log", "home.repos.pwc.inspect_result.astooke_rlpyt.runners.minibatch_rl.MinibatchRlBase.get_itr_snapshot", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.logger.save_itr_params", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.console.log"], ["", "def", "save_itr_snapshot", "(", "self", ",", "itr", ")", ":", "\n", "        ", "\"\"\"\n        Calls the logger to save training checkpoint/snapshot (logger itself\n        may or may not save, depending on mode selected).\n        \"\"\"", "\n", "logger", ".", "log", "(", "\"saving snapshot...\"", ")", "\n", "params", "=", "self", ".", "get_itr_snapshot", "(", "itr", ")", "\n", "logger", ".", "save_itr_params", "(", "itr", ",", "params", ")", "\n", "logger", ".", "log", "(", "\"saved\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.runners.unsupervised_learning.UnsupervisedLearning.store_diagnostics": [[83, 88], ["unsupervised_learning.UnsupervisedLearning._opt_infos.items", "unsupervised_learning.UnsupervisedLearning.pbar.update", "getattr", "v.extend", "isinstance"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.utils.collections.NamedArrayTuple.items", "home.repos.pwc.inspect_result.astooke_rlpyt.models.running_mean_std.RunningMeanStdModel.update"], ["", "def", "store_diagnostics", "(", "self", ",", "itr", ",", "opt_info", ")", ":", "\n", "        ", "for", "k", ",", "v", "in", "self", ".", "_opt_infos", ".", "items", "(", ")", ":", "\n", "            ", "new_v", "=", "getattr", "(", "opt_info", ",", "k", ",", "[", "]", ")", "\n", "v", ".", "extend", "(", "new_v", "if", "isinstance", "(", "new_v", ",", "list", ")", "else", "[", "new_v", "]", ")", "\n", "", "self", ".", "pbar", ".", "update", "(", "(", "itr", "+", "1", ")", "%", "self", ".", "log_interval_updates", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.runners.unsupervised_learning.UnsupervisedLearning.log_diagnostics": [[89, 109], ["unsupervised_learning.UnsupervisedLearning.save_itr_snapshot", "time.time", "rlpyt.utils.logging.logger.record_tabular", "rlpyt.utils.logging.logger.record_tabular", "rlpyt.utils.logging.logger.record_tabular", "rlpyt.utils.logging.logger.record_tabular", "zip", "rlpyt.utils.logging.logger.dump_tabular", "unsupervised_learning.UnsupervisedLearning._opt_infos.items", "rlpyt.utils.logging.logger.record_tabular_misc_stat", "list", "rlpyt.utils.logging.logger.log", "rlpyt.utils.prog_bar.ProgBarCounter", "rlpyt.utils.logging.logger.record_tabular_misc_stat"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.runners.minibatch_rl.MinibatchRlBase.save_itr_snapshot", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.logger.record_tabular", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.logger.record_tabular", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.logger.record_tabular", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.logger.record_tabular", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.logger.dump_tabular", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.collections.NamedArrayTuple.items", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.logger.record_tabular_misc_stat", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.console.log", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.logger.record_tabular_misc_stat"], ["", "def", "log_diagnostics", "(", "self", ",", "itr", ",", "val_info", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "self", ".", "save_itr_snapshot", "(", "itr", ")", "\n", "new_time", "=", "time", ".", "time", "(", ")", "\n", "self", ".", "_cum_time", "=", "new_time", "-", "self", ".", "_start_time", "\n", "epochs", "=", "itr", "*", "self", ".", "algo", ".", "batch_size", "/", "(", "\n", "self", ".", "algo", ".", "replay_buffer", ".", "size", "*", "(", "1", "-", "self", ".", "algo", ".", "validation_split", ")", ")", "\n", "logger", ".", "record_tabular", "(", "\"Iteration\"", ",", "itr", ")", "\n", "logger", ".", "record_tabular", "(", "\"Epochs\"", ",", "epochs", ")", "\n", "logger", ".", "record_tabular", "(", "\"CumTime (s)\"", ",", "self", ".", "_cum_time", ")", "\n", "logger", ".", "record_tabular", "(", "\"UpdatesPerSecond\"", ",", "itr", "/", "self", ".", "_cum_time", ")", "\n", "if", "self", ".", "_opt_infos", ":", "\n", "            ", "for", "k", ",", "v", "in", "self", ".", "_opt_infos", ".", "items", "(", ")", ":", "\n", "                ", "logger", ".", "record_tabular_misc_stat", "(", "k", ",", "v", ")", "\n", "", "", "for", "k", ",", "v", "in", "zip", "(", "val_info", ".", "_fields", ",", "val_info", ")", ":", "\n", "            ", "logger", ".", "record_tabular_misc_stat", "(", "\"val_\"", "+", "k", ",", "v", ")", "\n", "", "self", ".", "_opt_infos", "=", "{", "k", ":", "list", "(", ")", "for", "k", "in", "self", ".", "_opt_infos", "}", "# (reset)", "\n", "logger", ".", "dump_tabular", "(", "with_prefix", "=", "False", ")", "\n", "if", "itr", "<", "self", ".", "n_updates", "-", "1", ":", "\n", "            ", "logger", ".", "log", "(", "f\"Optimizing over {self.log_interval_updates} iterations.\"", ")", "\n", "self", ".", "pbar", "=", "ProgBarCounter", "(", "self", ".", "log_interval_updates", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.runners.unsupervised_learning.UnsupervisedLearning.train": [[110, 124], ["unsupervised_learning.UnsupervisedLearning.startup", "unsupervised_learning.UnsupervisedLearning.algo.train", "range", "unsupervised_learning.UnsupervisedLearning.shutdown", "rlpyt.utils.logging.logger.set_iteration", "rlpyt.utils.logging.logger.prefix", "unsupervised_learning.UnsupervisedLearning.algo.optimize", "unsupervised_learning.UnsupervisedLearning.store_diagnostics", "unsupervised_learning.UnsupervisedLearning.algo.eval", "unsupervised_learning.UnsupervisedLearning.algo.validation", "unsupervised_learning.UnsupervisedLearning.log_diagnostics", "unsupervised_learning.UnsupervisedLearning.algo.train"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.runners.minibatch_rl.MinibatchRlBase.startup", "home.repos.pwc.inspect_result.astooke_rlpyt.runners.minibatch_rl.MinibatchRlEval.train", "home.repos.pwc.inspect_result.astooke_rlpyt.runners.minibatch_rl.MinibatchRlBase.shutdown", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.logger.set_iteration", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.logger.prefix", "home.repos.pwc.inspect_result.astooke_rlpyt.runners.async_rl.AsyncOptWorker.optimize", "home.repos.pwc.inspect_result.astooke_rlpyt.runners.minibatch_rl.MinibatchRl.store_diagnostics", "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.augmented_temporal_similarity.AugmentedTemporalSimilarity.eval", "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.augmented_temporal_similarity.AugmentedTemporalSimilarity.validation", "home.repos.pwc.inspect_result.astooke_rlpyt.runners.minibatch_rl.MinibatchRlEval.log_diagnostics", "home.repos.pwc.inspect_result.astooke_rlpyt.runners.minibatch_rl.MinibatchRlEval.train"], ["", "", "def", "train", "(", "self", ")", ":", "\n", "        ", "self", ".", "startup", "(", ")", "\n", "self", ".", "algo", ".", "train", "(", ")", "\n", "for", "itr", "in", "range", "(", "self", ".", "n_updates", ")", ":", "\n", "            ", "logger", ".", "set_iteration", "(", "itr", ")", "\n", "with", "logger", ".", "prefix", "(", "f\"itr #{itr} \"", ")", ":", "\n", "                ", "opt_info", "=", "self", ".", "algo", ".", "optimize", "(", "itr", ")", "# perform one update", "\n", "self", ".", "store_diagnostics", "(", "itr", ",", "opt_info", ")", "\n", "if", "(", "itr", "+", "1", ")", "%", "self", ".", "log_interval_updates", "==", "0", ":", "\n", "                    ", "self", ".", "algo", ".", "eval", "(", ")", "\n", "val_info", "=", "self", ".", "algo", ".", "validation", "(", "itr", ")", "\n", "self", ".", "log_diagnostics", "(", "itr", ",", "val_info", ")", "\n", "self", ".", "algo", ".", "train", "(", ")", "\n", "", "", "", "self", ".", "shutdown", "(", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.astooke_rlpyt.runners.base.BaseRunner.train": [[10, 16], ["None"], "methods", ["None"], ["opt_info_fields", "=", "(", ")", "\n", "bootstrap_value", "=", "False", "\n", "update_counter", "=", "0", "\n", "\n", "def", "initialize", "(", "self", ",", "agent", ",", "n_itr", ",", "batch_spec", ",", "mid_batch_reset", ",", "examples", ",", "\n", "world_size", "=", "1", ",", "rank", "=", "0", ")", ":", "\n", "        "]], "home.repos.pwc.inspect_result.astooke_rlpyt.runners.async_rl.AsyncRlBase.__init__": [[66, 79], ["int", "int", "rlpyt.utils.quick_args.save__init__args", "locals"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.utils.quick_args.save__init__args"], ["def", "__init__", "(", "\n", "self", ",", "\n", "algo", ",", "\n", "agent", ",", "\n", "sampler", ",", "\n", "n_steps", ",", "\n", "affinity", ",", "\n", "seed", "=", "None", ",", "\n", "log_interval_steps", "=", "1e5", ",", "\n", ")", ":", "\n", "        ", "n_steps", "=", "int", "(", "n_steps", ")", "\n", "log_interval_steps", "=", "int", "(", "log_interval_steps", ")", "\n", "save__init__args", "(", "locals", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.runners.async_rl.AsyncRlBase.train": [[80, 133], ["async_rl.AsyncRlBase.startup", "rlpyt.utils.synchronize.drain_queue", "async_rl.AsyncRlBase.shutdown", "rlpyt.utils.synchronize.drain_queue", "async_rl.AsyncRlBase.store_diagnostics", "async_rl.AsyncRlBase.log_diagnostics", "rlpyt.utils.logging.logger.set_iteration", "async_rl.AsyncRlBase.store_diagnostics", "async_rl.AsyncRlBase.log_diagnostics", "time.sleep", "rlpyt.utils.logging.logger.prefix", "async_rl.AsyncRlBase.algo.optimize_agent", "async_rl.AsyncRlBase.agent.send_shared_memory", "async_rl.AsyncRlBase.store_diagnostics", "time.sleep", "async_rl.AsyncRlBase.ctrl.opt_throttle.wait", "list", "rlpyt.utils.synchronize.drain_queue", "async_rl.AsyncRlBase.log_diagnostics", "async_rl.AsyncRlBase.store_diagnostics", "async_rl.AsyncRlBase.ctrl.sampler_itr.get_lock", "rlpyt.utils.synchronize.drain_queue"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.runners.minibatch_rl.MinibatchRlBase.startup", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.synchronize.drain_queue", "home.repos.pwc.inspect_result.astooke_rlpyt.runners.minibatch_rl.MinibatchRlBase.shutdown", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.synchronize.drain_queue", "home.repos.pwc.inspect_result.astooke_rlpyt.runners.minibatch_rl.MinibatchRl.store_diagnostics", "home.repos.pwc.inspect_result.astooke_rlpyt.runners.minibatch_rl.MinibatchRlEval.log_diagnostics", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.logger.set_iteration", "home.repos.pwc.inspect_result.astooke_rlpyt.runners.minibatch_rl.MinibatchRl.store_diagnostics", "home.repos.pwc.inspect_result.astooke_rlpyt.runners.minibatch_rl.MinibatchRlEval.log_diagnostics", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.logger.prefix", "home.repos.pwc.inspect_result.astooke_rlpyt.safe.cppo_pid.CppoPID.optimize_agent", "home.repos.pwc.inspect_result.astooke_rlpyt.agents.base.BaseAgent.send_shared_memory", "home.repos.pwc.inspect_result.astooke_rlpyt.runners.minibatch_rl.MinibatchRl.store_diagnostics", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.synchronize.drain_queue", "home.repos.pwc.inspect_result.astooke_rlpyt.runners.minibatch_rl.MinibatchRlEval.log_diagnostics", "home.repos.pwc.inspect_result.astooke_rlpyt.runners.minibatch_rl.MinibatchRl.store_diagnostics", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.synchronize.drain_queue"], ["", "def", "train", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Run the optimizer in a loop.  Check whether enough new samples have\n        been generated, and throttle down if necessary at each iteration.  Log\n        at an interval in the number of sampler iterations, not optimizer\n        iterations.\n        \"\"\"", "\n", "throttle_itr", ",", "delta_throttle_itr", "=", "self", ".", "startup", "(", ")", "\n", "throttle_time", "=", "0.", "\n", "sampler_itr", "=", "itr", "=", "0", "\n", "if", "self", ".", "_eval", ":", "\n", "            ", "while", "self", ".", "ctrl", ".", "sampler_itr", ".", "value", "<", "1", ":", "# Sampler does eval first.", "\n", "                ", "time", ".", "sleep", "(", "THROTTLE_WAIT", ")", "\n", "", "traj_infos", "=", "drain_queue", "(", "self", ".", "traj_infos_queue", ",", "n_sentinel", "=", "1", ")", "\n", "self", ".", "store_diagnostics", "(", "0", ",", "0", ",", "traj_infos", ",", "(", ")", ")", "\n", "self", ".", "log_diagnostics", "(", "0", ",", "0", ",", "0", ")", "\n", "", "log_counter", "=", "0", "\n", "while", "True", ":", "# Run until sampler hits n_steps and sets ctrl.quit=True.", "\n", "            ", "logger", ".", "set_iteration", "(", "itr", ")", "\n", "with", "logger", ".", "prefix", "(", "f\"opt_itr #{itr} \"", ")", ":", "\n", "                ", "while", "self", ".", "ctrl", ".", "sampler_itr", ".", "value", "<", "throttle_itr", ":", "\n", "                    ", "if", "self", ".", "ctrl", ".", "quit", ".", "value", ":", "\n", "                        ", "break", "\n", "", "time", ".", "sleep", "(", "THROTTLE_WAIT", ")", "\n", "throttle_time", "+=", "THROTTLE_WAIT", "\n", "", "if", "self", ".", "ctrl", ".", "quit", ".", "value", ":", "\n", "                    ", "break", "\n", "", "if", "self", ".", "ctrl", ".", "opt_throttle", "is", "not", "None", ":", "\n", "                    ", "self", ".", "ctrl", ".", "opt_throttle", ".", "wait", "(", ")", "\n", "", "throttle_itr", "+=", "delta_throttle_itr", "\n", "opt_info", "=", "self", ".", "algo", ".", "optimize_agent", "(", "itr", ",", "\n", "sampler_itr", "=", "self", ".", "ctrl", ".", "sampler_itr", ".", "value", ")", "\n", "self", ".", "agent", ".", "send_shared_memory", "(", ")", "# To sampler.", "\n", "sampler_itr", "=", "self", ".", "ctrl", ".", "sampler_itr", ".", "value", "\n", "traj_infos", "=", "(", "list", "(", ")", "if", "self", ".", "_eval", "else", "\n", "drain_queue", "(", "self", ".", "traj_infos_queue", ")", ")", "\n", "self", ".", "store_diagnostics", "(", "itr", ",", "sampler_itr", ",", "traj_infos", ",", "opt_info", ")", "\n", "if", "(", "sampler_itr", "//", "self", ".", "log_interval_itrs", ">", "log_counter", ")", ":", "\n", "                    ", "if", "self", ".", "_eval", ":", "\n", "                        ", "with", "self", ".", "ctrl", ".", "sampler_itr", ".", "get_lock", "(", ")", ":", "\n", "                            ", "traj_infos", "=", "drain_queue", "(", "self", ".", "traj_infos_queue", ",", "n_sentinel", "=", "1", ")", "\n", "", "self", ".", "store_diagnostics", "(", "itr", ",", "sampler_itr", ",", "traj_infos", ",", "(", ")", ")", "\n", "", "self", ".", "log_diagnostics", "(", "itr", ",", "sampler_itr", ",", "throttle_time", ")", "\n", "log_counter", "+=", "1", "\n", "throttle_time", "=", "0.", "\n", "", "", "itr", "+=", "1", "\n", "# Final log:", "\n", "", "sampler_itr", "=", "self", ".", "ctrl", ".", "sampler_itr", ".", "value", "\n", "traj_infos", "=", "drain_queue", "(", "self", ".", "traj_infos_queue", ")", "\n", "if", "traj_infos", "or", "not", "self", ".", "_eval", ":", "\n", "            ", "self", ".", "store_diagnostics", "(", "itr", ",", "sampler_itr", ",", "traj_infos", ",", "(", ")", ")", "\n", "self", ".", "log_diagnostics", "(", "itr", ",", "sampler_itr", ",", "throttle_time", ")", "\n", "", "self", ".", "shutdown", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.runners.async_rl.AsyncRlBase.startup": [[134, 163], ["rlpyt.utils.seed.set_seed", "async_rl.AsyncRlBase.sampler.async_initialize", "len", "async_rl.AsyncRlBase.get_n_itr", "async_rl.AsyncRlBase.algo.async_initialize", "async_rl.AsyncRlBase.launch_workers", "async_rl.AsyncRlBase.optim_startup", "rlpyt.utils.seed.make_seed", "getattr", "async_rl.AsyncRlBase.get_traj_info_kwargs"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.utils.seed.set_seed", "home.repos.pwc.inspect_result.astooke_rlpyt.rl_with_ul.sac_with_ul.SacWithUl.async_initialize", "home.repos.pwc.inspect_result.astooke_rlpyt.runners.minibatch_rl.MinibatchRlBase.get_n_itr", "home.repos.pwc.inspect_result.astooke_rlpyt.rl_with_ul.sac_with_ul.SacWithUl.async_initialize", "home.repos.pwc.inspect_result.astooke_rlpyt.runners.sync_rl.SyncRlMixin.launch_workers", "home.repos.pwc.inspect_result.astooke_rlpyt.runners.async_rl.AsyncRlBase.optim_startup", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.seed.make_seed", "home.repos.pwc.inspect_result.astooke_rlpyt.runners.minibatch_rl.MinibatchRlBase.get_traj_info_kwargs"], ["", "def", "startup", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Calls ``sampler.async_initialize()`` to get a double buffer for minibatches,\n        followed by ``algo.async_initialize()`` to get a replay buffer on shared memory,\n        then launches all workers (sampler, optimizer, memory copier).\n        \"\"\"", "\n", "if", "self", ".", "seed", "is", "None", ":", "\n", "            ", "self", ".", "seed", "=", "make_seed", "(", ")", "\n", "", "set_seed", "(", "self", ".", "seed", ")", "\n", "double_buffer", ",", "examples", "=", "self", ".", "sampler", ".", "async_initialize", "(", "\n", "agent", "=", "self", ".", "agent", ",", "\n", "bootstrap_value", "=", "getattr", "(", "self", ".", "algo", ",", "\"bootstrap_value\"", ",", "False", ")", ",", "\n", "traj_info_kwargs", "=", "self", ".", "get_traj_info_kwargs", "(", ")", ",", "\n", "seed", "=", "self", ".", "seed", ",", "\n", ")", "\n", "self", ".", "sampler_batch_size", "=", "self", ".", "sampler", ".", "batch_spec", ".", "size", "\n", "self", ".", "world_size", "=", "len", "(", "self", ".", "affinity", ".", "optimizer", ")", "\n", "n_itr", "=", "self", ".", "get_n_itr", "(", ")", "# Number of sampler iterations.", "\n", "replay_buffer", "=", "self", ".", "algo", ".", "async_initialize", "(", "\n", "agent", "=", "self", ".", "agent", ",", "\n", "sampler_n_itr", "=", "n_itr", ",", "\n", "batch_spec", "=", "self", ".", "sampler", ".", "batch_spec", ",", "\n", "mid_batch_reset", "=", "self", ".", "sampler", ".", "mid_batch_reset", ",", "\n", "examples", "=", "examples", ",", "\n", "world_size", "=", "self", ".", "world_size", ",", "\n", ")", "\n", "self", ".", "launch_workers", "(", "n_itr", ",", "double_buffer", ",", "replay_buffer", ")", "\n", "throttle_itr", ",", "delta_throttle_itr", "=", "self", ".", "optim_startup", "(", ")", "\n", "return", "throttle_itr", ",", "delta_throttle_itr", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.runners.async_rl.AsyncRlBase.optim_startup": [[164, 188], ["psutil.Process", "main_affinity.get", "rlpyt.utils.logging.logger.log", "torch.set_num_threads", "rlpyt.utils.logging.logger.log", "async_rl.AsyncRlBase.agent.to_device", "async_rl.AsyncRlBase.algo.optim_initialize", "async_rl.AsyncRlBase.initialize_logging", "psutil.Process.cpu_affinity", "main_affinity.get", "async_rl.AsyncRlBase.agent.data_parallel", "getattr", "psutil.Process.cpu_affinity", "torch.get_num_threads"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.utils.collections.NamedArrayTuple.get", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.console.log", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.console.log", "home.repos.pwc.inspect_result.astooke_rlpyt.safe.cppo_agent.CppoLstmAgent.to_device", "home.repos.pwc.inspect_result.astooke_rlpyt.rl_with_ul.sac_with_ul.SacWithUl.optim_initialize", "home.repos.pwc.inspect_result.astooke_rlpyt.runners.minibatch_rl.MinibatchRlEval.initialize_logging", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.collections.NamedArrayTuple.get", "home.repos.pwc.inspect_result.astooke_rlpyt.safe.cppo_agent.CppoLstmAgent.data_parallel"], ["", "def", "optim_startup", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Sets the hardware affinity, moves the agent's model parameters onto\n        device and initialize data-parallel agent, if applicable.  Computes\n        optimizer throttling settings.\n        \"\"\"", "\n", "main_affinity", "=", "self", ".", "affinity", ".", "optimizer", "[", "0", "]", "\n", "p", "=", "psutil", ".", "Process", "(", ")", "\n", "if", "main_affinity", ".", "get", "(", "\"set_affinity\"", ",", "True", ")", ":", "\n", "            ", "p", ".", "cpu_affinity", "(", "main_affinity", "[", "\"cpus\"", "]", ")", "\n", "", "logger", ".", "log", "(", "f\"Optimizer master CPU affinity: {p.cpu_affinity()}.\"", ")", "\n", "torch", ".", "set_num_threads", "(", "main_affinity", "[", "\"torch_threads\"", "]", ")", "\n", "logger", ".", "log", "(", "f\"Optimizer master Torch threads: {torch.get_num_threads()}.\"", ")", "\n", "self", ".", "agent", ".", "to_device", "(", "main_affinity", ".", "get", "(", "\"cuda_idx\"", ",", "None", ")", ")", "\n", "if", "self", ".", "world_size", ">", "1", ":", "\n", "            ", "self", ".", "agent", ".", "data_parallel", "(", ")", "\n", "", "self", ".", "algo", ".", "optim_initialize", "(", "rank", "=", "0", ")", "\n", "throttle_itr", "=", "1", "+", "getattr", "(", "self", ".", "algo", ",", "\n", "\"min_steps_learn\"", ",", "0", ")", "//", "self", ".", "sampler_batch_size", "\n", "delta_throttle_itr", "=", "(", "self", ".", "algo", ".", "batch_size", "*", "self", ".", "world_size", "*", "\n", "self", ".", "algo", ".", "updates_per_optimize", "/", "# (is updates_per_sync)", "\n", "(", "self", ".", "sampler_batch_size", "*", "self", ".", "algo", ".", "replay_ratio", ")", ")", "\n", "self", ".", "initialize_logging", "(", ")", "\n", "return", "throttle_itr", ",", "delta_throttle_itr", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.runners.async_rl.AsyncRlBase.launch_workers": [[189, 195], ["multiprocessing.Queue", "async_rl.AsyncRlBase.build_ctrl", "async_rl.AsyncRlBase.launch_sampler", "async_rl.AsyncRlBase.launch_memcpy", "async_rl.AsyncRlBase.launch_optimizer_workers"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.runners.async_rl.AsyncRlBase.build_ctrl", "home.repos.pwc.inspect_result.astooke_rlpyt.runners.async_rl.AsyncRlBase.launch_sampler", "home.repos.pwc.inspect_result.astooke_rlpyt.runners.async_rl.AsyncRlBase.launch_memcpy", "home.repos.pwc.inspect_result.astooke_rlpyt.runners.async_rl.AsyncRlBase.launch_optimizer_workers"], ["", "def", "launch_workers", "(", "self", ",", "n_itr", ",", "double_buffer", ",", "replay_buffer", ")", ":", "\n", "        ", "self", ".", "traj_infos_queue", "=", "mp", ".", "Queue", "(", ")", "\n", "self", ".", "ctrl", "=", "self", ".", "build_ctrl", "(", "self", ".", "world_size", ")", "\n", "self", ".", "launch_sampler", "(", "n_itr", ")", "\n", "self", ".", "launch_memcpy", "(", "double_buffer", ",", "replay_buffer", ")", "\n", "self", ".", "launch_optimizer_workers", "(", "n_itr", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.runners.async_rl.AsyncRlBase.get_n_itr": [[196, 204], ["max", "rlpyt.utils.logging.logger.log", "math.ceil"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.logging.console.log"], ["", "def", "get_n_itr", "(", "self", ")", ":", "\n", "        ", "log_interval_itrs", "=", "max", "(", "self", ".", "log_interval_steps", "//", "\n", "self", ".", "sampler_batch_size", ",", "1", ")", "\n", "n_itr", "=", "math", ".", "ceil", "(", "self", ".", "n_steps", "/", "self", ".", "log_interval_steps", ")", "*", "log_interval_itrs", "\n", "self", ".", "log_interval_itrs", "=", "log_interval_itrs", "\n", "self", ".", "n_itr", "=", "n_itr", "\n", "logger", ".", "log", "(", "f\"Running {n_itr} sampler iterations.\"", ")", "\n", "return", "n_itr", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.runners.async_rl.AsyncRlBase.build_ctrl": [[205, 220], ["rlpyt.utils.collections.AttrDict", "multiprocessing.Barrier", "multiprocessing.Value", "multiprocessing.RawValue", "multiprocessing.Value", "multiprocessing.Value", "multiprocessing.Semaphore", "multiprocessing.Semaphore", "range", "range"], "methods", ["None"], ["", "def", "build_ctrl", "(", "self", ",", "world_size", ")", ":", "\n", "        ", "\"\"\"\n        Builds several parallel communication mechanisms for controlling the\n        workflow across processes.\n        \"\"\"", "\n", "opt_throttle", "=", "(", "mp", ".", "Barrier", "(", "world_size", ")", "if", "world_size", ">", "1", "else", "\n", "None", ")", "\n", "return", "AttrDict", "(", "\n", "quit", "=", "mp", ".", "Value", "(", "'b'", ",", "lock", "=", "True", ")", ",", "\n", "quit_opt", "=", "mp", ".", "RawValue", "(", "'b'", ")", ",", "\n", "sample_ready", "=", "[", "mp", ".", "Semaphore", "(", "0", ")", "for", "_", "in", "range", "(", "2", ")", "]", ",", "# Double buffer.", "\n", "sample_copied", "=", "[", "mp", ".", "Semaphore", "(", "1", ")", "for", "_", "in", "range", "(", "2", ")", "]", ",", "\n", "sampler_itr", "=", "mp", ".", "Value", "(", "'l'", ",", "lock", "=", "True", ")", ",", "\n", "opt_throttle", "=", "opt_throttle", ",", "\n", "eval_time", "=", "mp", ".", "Value", "(", "'d'", ",", "lock", "=", "True", ")", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.runners.async_rl.AsyncRlBase.launch_optimizer_workers": [[222, 253], ["rlpyt.utils.synchronize.find_port", "torch.distributed.init_process_group", "async_rl.AsyncRlBase.affinity.optimizer[].get", "async_rl.AsyncOptWorker", "multiprocessing.Process", "p.start", "range", "len"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.utils.synchronize.find_port", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.collections.NamedArrayTuple.get"], ["", "def", "launch_optimizer_workers", "(", "self", ",", "n_itr", ")", ":", "\n", "        ", "\"\"\"\n        If multi-GPU optimization, launches an optimizer worker for each GPU\n        and initializes ``torch.distributed.``\n        \"\"\"", "\n", "if", "self", ".", "world_size", "==", "1", ":", "\n", "            ", "return", "\n", "", "offset", "=", "self", ".", "affinity", ".", "optimizer", "[", "0", "]", ".", "get", "(", "\"master_cpus\"", ",", "[", "0", "]", ")", "[", "0", "]", "\n", "port", "=", "find_port", "(", "offset", "=", "offset", ")", "\n", "affinities", "=", "self", ".", "affinity", ".", "optimizer", "\n", "runners", "=", "[", "AsyncOptWorker", "(", "\n", "rank", "=", "rank", ",", "\n", "world_size", "=", "self", ".", "world_size", ",", "\n", "algo", "=", "self", ".", "algo", ",", "\n", "agent", "=", "self", ".", "agent", ",", "\n", "n_itr", "=", "n_itr", ",", "\n", "affinity", "=", "affinities", "[", "rank", "]", ",", "\n", "seed", "=", "self", ".", "seed", "+", "100", ",", "\n", "ctrl", "=", "self", ".", "ctrl", ",", "\n", "port", "=", "port", ",", "\n", ")", "for", "rank", "in", "range", "(", "1", ",", "len", "(", "affinities", ")", ")", "]", "\n", "procs", "=", "[", "mp", ".", "Process", "(", "target", "=", "r", ".", "optimize", ",", "args", "=", "(", ")", ")", "for", "r", "in", "runners", "]", "\n", "for", "p", "in", "procs", ":", "\n", "            ", "p", ".", "start", "(", ")", "\n", "", "torch", ".", "distributed", ".", "init_process_group", "(", "\n", "backend", "=", "\"nccl\"", ",", "\n", "rank", "=", "0", ",", "\n", "world_size", "=", "self", ".", "world_size", ",", "\n", "init_method", "=", "f\"tcp://127.0.0.1:{port}\"", ",", "\n", ")", "\n", "self", ".", "optimizer_procs", "=", "procs", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.runners.async_rl.AsyncRlBase.launch_memcpy": [[254, 273], ["list", "range", "len", "rlpyt.utils.collections.AttrDict", "list.append", "p.start", "multiprocessing.Process"], "methods", ["None"], ["", "def", "launch_memcpy", "(", "self", ",", "sample_buffers", ",", "replay_buffer", ")", ":", "\n", "        ", "\"\"\"\n        Fork a Python process for each of the sampler double buffers.  (It may\n        be overkill to use two separate processes here, may be able to simplify\n        to one and still get good performance.)\n        \"\"\"", "\n", "procs", "=", "list", "(", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "sample_buffers", ")", ")", ":", "# (2 for double-buffer.)", "\n", "            ", "ctrl", "=", "AttrDict", "(", "\n", "quit", "=", "self", ".", "ctrl", ".", "quit", ",", "\n", "sample_ready", "=", "self", ".", "ctrl", ".", "sample_ready", "[", "i", "]", ",", "\n", "sample_copied", "=", "self", ".", "ctrl", ".", "sample_copied", "[", "i", "]", ",", "\n", ")", "\n", "procs", ".", "append", "(", "mp", ".", "Process", "(", "target", "=", "memory_copier", ",", "\n", "args", "=", "(", "sample_buffers", "[", "i", "]", ",", "self", ".", "algo", ".", "samples_to_buffer", ",", "\n", "replay_buffer", ",", "ctrl", ")", ")", ")", "\n", "", "for", "p", "in", "procs", ":", "\n", "            ", "p", ".", "start", "(", ")", "\n", "", "self", ".", "memcpy_procs", "=", "procs", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.runners.async_rl.AsyncRlBase.launch_sampler": [[274, 288], ["dict", "multiprocessing.Process", "async_rl.AsyncRlBase.sampler_proc.start"], "methods", ["None"], ["", "def", "launch_sampler", "(", "self", ",", "n_itr", ")", ":", "\n", "        ", "target", "=", "run_async_sampler", "\n", "kwargs", "=", "dict", "(", "\n", "sampler", "=", "self", ".", "sampler", ",", "\n", "affinity", "=", "self", ".", "affinity", ".", "sampler", ",", "\n", "ctrl", "=", "self", ".", "ctrl", ",", "\n", "traj_infos_queue", "=", "self", ".", "traj_infos_queue", ",", "\n", "n_itr", "=", "n_itr", ",", "\n", ")", "\n", "if", "self", ".", "_eval", ":", "\n", "            ", "target", "=", "run_async_sampler_eval", "\n", "kwargs", "[", "\"eval_itrs\"", "]", "=", "self", ".", "log_interval_itrs", "\n", "", "self", ".", "sampler_proc", "=", "mp", ".", "Process", "(", "target", "=", "target", ",", "kwargs", "=", "kwargs", ")", "\n", "self", ".", "sampler_proc", ".", "start", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.runners.async_rl.AsyncRlBase.shutdown": [[289, 303], ["async_rl.AsyncRlBase.pbar.stop", "rlpyt.utils.logging.logger.log", "async_rl.AsyncRlBase.sampler_proc.join", "rlpyt.utils.logging.logger.log", "rlpyt.utils.logging.logger.log", "p.join", "rlpyt.utils.logging.logger.log", "async_rl.AsyncRlBase.ctrl.opt_throttle.wait", "p.join"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.utils.prog_bar.ProgBarCounter.stop", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.console.log", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.console.log", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.console.log", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.console.log"], ["", "def", "shutdown", "(", "self", ")", ":", "\n", "        ", "self", ".", "pbar", ".", "stop", "(", ")", "\n", "logger", ".", "log", "(", "\"Master optimizer shutting down, joining sampler process...\"", ")", "\n", "self", ".", "sampler_proc", ".", "join", "(", ")", "\n", "logger", ".", "log", "(", "\"Joining memory copiers...\"", ")", "\n", "for", "p", "in", "self", ".", "memcpy_procs", ":", "\n", "            ", "p", ".", "join", "(", ")", "\n", "", "if", "self", ".", "ctrl", ".", "opt_throttle", "is", "not", "None", ":", "\n", "            ", "logger", ".", "log", "(", "\"Joining optimizer processes...\"", ")", "\n", "self", ".", "ctrl", ".", "quit_opt", ".", "value", "=", "True", "\n", "self", ".", "ctrl", ".", "opt_throttle", ".", "wait", "(", ")", "\n", "for", "p", "in", "self", ".", "optimizer_procs", ":", "\n", "                ", "p", ".", "join", "(", ")", "\n", "", "", "logger", ".", "log", "(", "\"All processes shutdown.  Training complete.\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.runners.async_rl.AsyncRlBase.initialize_logging": [[304, 310], ["time.time", "list"], "methods", ["None"], ["", "def", "initialize_logging", "(", "self", ")", ":", "\n", "        ", "self", ".", "_opt_infos", "=", "{", "k", ":", "list", "(", ")", "for", "k", "in", "self", ".", "algo", ".", "opt_info_fields", "}", "\n", "self", ".", "_start_time", "=", "self", ".", "_last_time", "=", "time", ".", "time", "(", ")", "\n", "self", ".", "_last_itr", "=", "0", "\n", "self", ".", "_last_sampler_itr", "=", "0", "\n", "self", ".", "_last_update_counter", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.runners.async_rl.AsyncRlBase.get_itr_snapshot": [[311, 319], ["dict", "async_rl.AsyncRlBase.agent.state_dict", "async_rl.AsyncRlBase.algo.optim_state_dict"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.replay_saver.DummyOptimizer.state_dict", "home.repos.pwc.inspect_result.astooke_rlpyt.rl_with_ul.sac_with_ul.SacWithUl.optim_state_dict"], ["", "def", "get_itr_snapshot", "(", "self", ",", "itr", ",", "sampler_itr", ")", ":", "\n", "        ", "return", "dict", "(", "\n", "itr", "=", "itr", ",", "\n", "sampler_itr", "=", "sampler_itr", ",", "\n", "cum_steps", "=", "sampler_itr", "*", "self", ".", "sampler_batch_size", ",", "\n", "cum_updates", "=", "self", ".", "algo", ".", "update_counter", ",", "\n", "agent_state_dict", "=", "self", ".", "agent", ".", "state_dict", "(", ")", ",", "\n", "optimizer_state_dict", "=", "self", ".", "algo", ".", "optim_state_dict", "(", ")", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.runners.async_rl.AsyncRlBase.save_itr_snapshot": [[321, 326], ["rlpyt.utils.logging.logger.log", "async_rl.AsyncRlBase.get_itr_snapshot", "rlpyt.utils.logging.logger.save_itr_params", "rlpyt.utils.logging.logger.log"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.logging.console.log", "home.repos.pwc.inspect_result.astooke_rlpyt.runners.minibatch_rl.MinibatchRlBase.get_itr_snapshot", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.logger.save_itr_params", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.console.log"], ["", "def", "save_itr_snapshot", "(", "self", ",", "itr", ",", "sample_itr", ")", ":", "\n", "        ", "logger", ".", "log", "(", "\"saving snapshot...\"", ")", "\n", "params", "=", "self", ".", "get_itr_snapshot", "(", "itr", ",", "sample_itr", ")", "\n", "logger", ".", "save_itr_params", "(", "itr", ",", "params", ")", "\n", "logger", ".", "log", "(", "\"saved\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.runners.async_rl.AsyncRlBase.get_traj_info_kwargs": [[327, 329], ["dict", "getattr"], "methods", ["None"], ["", "def", "get_traj_info_kwargs", "(", "self", ")", ":", "\n", "        ", "return", "dict", "(", "discount", "=", "getattr", "(", "self", ".", "algo", ",", "\"discount\"", ",", "1", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.runners.async_rl.AsyncRlBase.store_diagnostics": [[330, 336], ["async_rl.AsyncRlBase._traj_infos.extend", "async_rl.AsyncRlBase._opt_infos.items", "async_rl.AsyncRlBase.pbar.update", "getattr", "v.extend", "isinstance"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.utils.collections.NamedArrayTuple.items", "home.repos.pwc.inspect_result.astooke_rlpyt.models.running_mean_std.RunningMeanStdModel.update"], ["", "def", "store_diagnostics", "(", "self", ",", "itr", ",", "sampler_itr", ",", "traj_infos", ",", "opt_info", ")", ":", "\n", "        ", "self", ".", "_traj_infos", ".", "extend", "(", "traj_infos", ")", "\n", "for", "k", ",", "v", "in", "self", ".", "_opt_infos", ".", "items", "(", ")", ":", "\n", "            ", "new_v", "=", "getattr", "(", "opt_info", ",", "k", ",", "[", "]", ")", "\n", "v", ".", "extend", "(", "new_v", "if", "isinstance", "(", "new_v", ",", "list", ")", "else", "[", "new_v", "]", ")", "\n", "", "self", ".", "pbar", ".", "update", "(", "(", "sampler_itr", "+", "1", ")", "%", "self", ".", "log_interval_itrs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.runners.async_rl.AsyncRlBase.log_diagnostics": [[337, 385], ["async_rl.AsyncRlBase.pbar.stop", "async_rl.AsyncRlBase.save_itr_snapshot", "time.time", "async_rl.AsyncRlBase._log_infos", "rlpyt.utils.logging.logger.dump_tabular", "rlpyt.utils.logging.logger.log", "rlpyt.utils.prog_bar.ProgBarCounter", "float", "float", "max", "max", "rlpyt.utils.logging.logger.tabular_prefix", "rlpyt.utils.logging.logger.record_tabular", "rlpyt.utils.logging.logger.record_tabular", "rlpyt.utils.logging.logger.record_tabular", "rlpyt.utils.logging.logger.record_tabular", "rlpyt.utils.logging.logger.record_tabular", "rlpyt.utils.logging.logger.record_tabular", "rlpyt.utils.logging.logger.record_tabular", "rlpyt.utils.logging.logger.record_tabular", "rlpyt.utils.logging.logger.record_tabular", "rlpyt.utils.logging.logger.record_tabular", "float", "rlpyt.utils.logging.logger.record_tabular"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.utils.prog_bar.ProgBarCounter.stop", "home.repos.pwc.inspect_result.astooke_rlpyt.runners.minibatch_rl.MinibatchRlBase.save_itr_snapshot", "home.repos.pwc.inspect_result.astooke_rlpyt.runners.minibatch_rl.MinibatchRlBase._log_infos", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.logger.dump_tabular", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.console.log", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.logger.tabular_prefix", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.logger.record_tabular", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.logger.record_tabular", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.logger.record_tabular", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.logger.record_tabular", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.logger.record_tabular", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.logger.record_tabular", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.logger.record_tabular", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.logger.record_tabular", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.logger.record_tabular", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.logger.record_tabular", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.logger.record_tabular"], ["", "def", "log_diagnostics", "(", "self", ",", "itr", ",", "sampler_itr", ",", "throttle_time", ",", "prefix", "=", "'Diagnostics/'", ")", ":", "\n", "        ", "self", ".", "pbar", ".", "stop", "(", ")", "\n", "self", ".", "save_itr_snapshot", "(", "itr", ",", "sampler_itr", ")", "\n", "new_time", "=", "time", ".", "time", "(", ")", "\n", "time_elapsed", "=", "new_time", "-", "self", ".", "_last_time", "\n", "new_updates", "=", "self", ".", "algo", ".", "update_counter", "-", "self", ".", "_last_update_counter", "\n", "new_samples", "=", "self", ".", "sampler", ".", "batch_size", "*", "(", "sampler_itr", "-", "self", ".", "_last_sampler_itr", ")", "\n", "updates_per_second", "=", "(", "float", "(", "'nan'", ")", "if", "itr", "==", "0", "else", "\n", "new_updates", "/", "time_elapsed", ")", "\n", "samples_per_second", "=", "(", "float", "(", "'nan'", ")", "if", "itr", "==", "0", "else", "\n", "new_samples", "/", "time_elapsed", ")", "\n", "if", "self", ".", "_eval", ":", "\n", "            ", "new_eval_time", "=", "self", ".", "ctrl", ".", "eval_time", ".", "value", "\n", "eval_time_elapsed", "=", "new_eval_time", "-", "self", ".", "_last_eval_time", "\n", "non_eval_time_elapsed", "=", "time_elapsed", "-", "eval_time_elapsed", "\n", "non_eval_samples_per_second", "=", "(", "float", "(", "'nan'", ")", "if", "itr", "==", "0", "else", "\n", "new_samples", "/", "non_eval_time_elapsed", ")", "\n", "self", ".", "_last_eval_time", "=", "new_eval_time", "\n", "", "cum_steps", "=", "sampler_itr", "*", "self", ".", "sampler", ".", "batch_size", "# No * world_size.", "\n", "replay_ratio", "=", "(", "new_updates", "*", "self", ".", "algo", ".", "batch_size", "*", "self", ".", "world_size", "/", "\n", "max", "(", "1", ",", "new_samples", ")", ")", "\n", "cum_replay_ratio", "=", "(", "self", ".", "algo", ".", "update_counter", "*", "self", ".", "algo", ".", "batch_size", "*", "\n", "self", ".", "world_size", "/", "max", "(", "1", ",", "cum_steps", ")", ")", "\n", "\n", "with", "logger", ".", "tabular_prefix", "(", "prefix", ")", ":", "\n", "            ", "logger", ".", "record_tabular", "(", "'Iteration'", ",", "itr", ")", "\n", "logger", ".", "record_tabular", "(", "'SamplerIteration'", ",", "sampler_itr", ")", "\n", "logger", ".", "record_tabular", "(", "'CumTime (s)'", ",", "new_time", "-", "self", ".", "_start_time", ")", "\n", "logger", ".", "record_tabular", "(", "'CumSteps'", ",", "cum_steps", ")", "\n", "logger", ".", "record_tabular", "(", "'CumUpdates'", ",", "self", ".", "algo", ".", "update_counter", ")", "\n", "logger", ".", "record_tabular", "(", "'ReplayRatio'", ",", "replay_ratio", ")", "\n", "logger", ".", "record_tabular", "(", "'CumReplayRatio'", ",", "cum_replay_ratio", ")", "\n", "logger", ".", "record_tabular", "(", "'StepsPerSecond'", ",", "samples_per_second", ")", "\n", "if", "self", ".", "_eval", ":", "\n", "                ", "logger", ".", "record_tabular", "(", "'NonEvalSamplesPerSecond'", ",", "non_eval_samples_per_second", ")", "\n", "", "logger", ".", "record_tabular", "(", "'UpdatesPerSecond'", ",", "updates_per_second", ")", "\n", "logger", ".", "record_tabular", "(", "'OptThrottle'", ",", "(", "time_elapsed", "-", "throttle_time", ")", "/", "\n", "time_elapsed", ")", "\n", "\n", "", "self", ".", "_log_infos", "(", ")", "\n", "self", ".", "_last_time", "=", "new_time", "\n", "self", ".", "_last_itr", "=", "itr", "\n", "self", ".", "_last_sampler_itr", "=", "sampler_itr", "\n", "self", ".", "_last_update_counter", "=", "self", ".", "algo", ".", "update_counter", "\n", "logger", ".", "dump_tabular", "(", "with_prefix", "=", "False", ")", "\n", "logger", ".", "log", "(", "f\"Optimizing over {self.log_interval_itrs} sampler \"", "\n", "\"iterations.\"", ")", "\n", "self", ".", "pbar", "=", "ProgBarCounter", "(", "self", ".", "log_interval_itrs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.runners.async_rl.AsyncRlBase._log_infos": [[386, 399], ["async_rl.AsyncRlBase._opt_infos.items", "list", "rlpyt.utils.logging.logger.record_tabular_misc_stat", "k.startswith", "rlpyt.utils.logging.logger.record_tabular_misc_stat"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.utils.collections.NamedArrayTuple.items", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.logger.record_tabular_misc_stat", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.logger.record_tabular_misc_stat"], ["", "def", "_log_infos", "(", "self", ",", "traj_infos", "=", "None", ")", ":", "\n", "        ", "if", "traj_infos", "is", "None", ":", "\n", "            ", "traj_infos", "=", "self", ".", "_traj_infos", "\n", "", "if", "traj_infos", ":", "\n", "            ", "for", "k", "in", "traj_infos", "[", "0", "]", ":", "\n", "                ", "if", "not", "k", ".", "startswith", "(", "\"_\"", ")", ":", "\n", "                    ", "logger", ".", "record_tabular_misc_stat", "(", "k", ",", "\n", "[", "info", "[", "k", "]", "for", "info", "in", "traj_infos", "]", ")", "\n", "\n", "", "", "", "if", "self", ".", "_opt_infos", ":", "\n", "            ", "for", "k", ",", "v", "in", "self", ".", "_opt_infos", ".", "items", "(", ")", ":", "\n", "                ", "logger", ".", "record_tabular_misc_stat", "(", "k", ",", "v", ")", "\n", "", "", "self", ".", "_opt_infos", "=", "{", "k", ":", "list", "(", ")", "for", "k", "in", "self", ".", "_opt_infos", "}", "# (reset)", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.runners.async_rl.AsyncRl.__init__": [[406, 409], ["async_rl.AsyncRlBase.__init__", "int"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.spaces.gym_wrapper.GymSpaceWrapper.__init__"], ["def", "__init__", "(", "self", ",", "*", "args", ",", "log_traj_window", "=", "100", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "self", ".", "log_traj_window", "=", "int", "(", "log_traj_window", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.runners.async_rl.AsyncRl.initialize_logging": [[410, 418], ["collections.deque", "async_rl.AsyncRlBase.initialize_logging", "rlpyt.utils.logging.logger.log", "rlpyt.utils.prog_bar.ProgBarCounter"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.runners.minibatch_rl.MinibatchRlEval.initialize_logging", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.console.log"], ["", "def", "initialize_logging", "(", "self", ")", ":", "\n", "        ", "self", ".", "_traj_infos", "=", "deque", "(", "maxlen", "=", "self", ".", "log_traj_window", ")", "\n", "self", ".", "_cum_completed_trajs", "=", "0", "\n", "self", ".", "_new_completed_trajs", "=", "0", "\n", "super", "(", ")", ".", "initialize_logging", "(", ")", "\n", "logger", ".", "log", "(", "f\"Optimizing over {self.log_interval_itrs} sampler \"", "\n", "\"iterations.\"", ")", "\n", "self", ".", "pbar", "=", "ProgBarCounter", "(", "self", ".", "log_interval_itrs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.runners.async_rl.AsyncRl.store_diagnostics": [[419, 423], ["len", "len", "async_rl.AsyncRlBase.store_diagnostics"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.runners.minibatch_rl.MinibatchRl.store_diagnostics"], ["", "def", "store_diagnostics", "(", "self", ",", "itr", ",", "sampler_itr", ",", "traj_infos", ",", "opt_info", ")", ":", "\n", "        ", "self", ".", "_cum_completed_trajs", "+=", "len", "(", "traj_infos", ")", "\n", "self", ".", "_new_completed_trajs", "+=", "len", "(", "traj_infos", ")", "\n", "super", "(", ")", ".", "store_diagnostics", "(", "itr", ",", "sampler_itr", ",", "traj_infos", ",", "opt_info", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.runners.async_rl.AsyncRl.log_diagnostics": [[424, 432], ["async_rl.AsyncRlBase.log_diagnostics", "rlpyt.utils.logging.logger.tabular_prefix", "rlpyt.utils.logging.logger.record_tabular", "rlpyt.utils.logging.logger.record_tabular", "rlpyt.utils.logging.logger.record_tabular", "sum"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.runners.minibatch_rl.MinibatchRlEval.log_diagnostics", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.logger.tabular_prefix", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.logger.record_tabular", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.logger.record_tabular", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.logger.record_tabular"], ["", "def", "log_diagnostics", "(", "self", ",", "itr", ",", "sampler_itr", ",", "throttle_time", ",", "prefix", "=", "'Diagnostics/'", ")", ":", "\n", "        ", "with", "logger", ".", "tabular_prefix", "(", "prefix", ")", ":", "\n", "            ", "logger", ".", "record_tabular", "(", "'CumCompletedTrajs'", ",", "self", ".", "_cum_completed_trajs", ")", "\n", "logger", ".", "record_tabular", "(", "'NewCompletedTrajs'", ",", "self", ".", "_new_completed_trajs", ")", "\n", "logger", ".", "record_tabular", "(", "'StepsInTrajWindow'", ",", "\n", "sum", "(", "info", "[", "\"Length\"", "]", "for", "info", "in", "self", ".", "_traj_infos", ")", ")", "\n", "", "super", "(", ")", ".", "log_diagnostics", "(", "itr", ",", "sampler_itr", ",", "throttle_time", ",", "prefix", "=", "prefix", ")", "\n", "self", ".", "_new_completed_trajs", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.runners.async_rl.AsyncRlEval.initialize_logging": [[441, 446], ["list", "async_rl.AsyncRlBase.initialize_logging", "rlpyt.utils.prog_bar.ProgBarCounter"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.runners.minibatch_rl.MinibatchRlEval.initialize_logging"], ["def", "initialize_logging", "(", "self", ")", ":", "\n", "        ", "self", ".", "_traj_infos", "=", "list", "(", ")", "\n", "self", ".", "_last_eval_time", "=", "0.", "\n", "super", "(", ")", ".", "initialize_logging", "(", ")", "\n", "self", ".", "pbar", "=", "ProgBarCounter", "(", "self", ".", "log_interval_itrs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.runners.async_rl.AsyncRlEval.log_diagnostics": [[447, 457], ["sum", "async_rl.AsyncRlBase.log_diagnostics", "list", "rlpyt.utils.logging.logger.log", "rlpyt.utils.logging.logger.tabular_prefix", "rlpyt.utils.logging.logger.record_tabular", "rlpyt.utils.logging.logger.record_tabular", "rlpyt.utils.logging.logger.record_tabular", "len"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.runners.minibatch_rl.MinibatchRlEval.log_diagnostics", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.console.log", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.logger.tabular_prefix", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.logger.record_tabular", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.logger.record_tabular", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.logger.record_tabular"], ["", "def", "log_diagnostics", "(", "self", ",", "itr", ",", "sampler_itr", ",", "throttle_time", ",", "prefix", "=", "'Diagnostics/'", ")", ":", "\n", "        ", "if", "not", "self", ".", "_traj_infos", ":", "\n", "            ", "logger", ".", "log", "(", "\"WARNING: had no complete trajectories in eval.\"", ")", "\n", "", "steps_in_eval", "=", "sum", "(", "[", "info", "[", "\"Length\"", "]", "for", "info", "in", "self", ".", "_traj_infos", "]", ")", "\n", "with", "logger", ".", "tabular_prefix", "(", "prefix", ")", ":", "\n", "            ", "logger", ".", "record_tabular", "(", "'StepsInEval'", ",", "steps_in_eval", ")", "\n", "logger", ".", "record_tabular", "(", "'TrajsInEval'", ",", "len", "(", "self", ".", "_traj_infos", ")", ")", "\n", "logger", ".", "record_tabular", "(", "'CumEvalTime'", ",", "self", ".", "ctrl", ".", "eval_time", ".", "value", ")", "\n", "", "super", "(", ")", ".", "log_diagnostics", "(", "itr", ",", "sampler_itr", ",", "throttle_time", ",", "prefix", "=", "prefix", ")", "\n", "self", ".", "_traj_infos", "=", "list", "(", ")", "# Clear after each eval.", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.runners.async_rl.AsyncOptWorker.__init__": [[466, 479], ["rlpyt.utils.quick_args.save__init__args", "locals"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.utils.quick_args.save__init__args"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "rank", ",", "\n", "world_size", ",", "\n", "algo", ",", "\n", "agent", ",", "\n", "n_itr", ",", "\n", "affinity", ",", "\n", "seed", ",", "\n", "ctrl", ",", "\n", "port", "\n", ")", ":", "\n", "        ", "save__init__args", "(", "locals", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.runners.async_rl.AsyncOptWorker.optimize": [[480, 490], ["async_rl.AsyncOptWorker.startup", "async_rl.AsyncOptWorker.shutdown", "async_rl.AsyncOptWorker.ctrl.opt_throttle.wait", "async_rl.AsyncOptWorker.algo.optimize_agent"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.runners.minibatch_rl.MinibatchRlBase.startup", "home.repos.pwc.inspect_result.astooke_rlpyt.runners.minibatch_rl.MinibatchRlBase.shutdown", "home.repos.pwc.inspect_result.astooke_rlpyt.safe.cppo_pid.CppoPID.optimize_agent"], ["", "def", "optimize", "(", "self", ")", ":", "\n", "        ", "self", ".", "startup", "(", ")", "\n", "itr", "=", "0", "\n", "while", "True", ":", "\n", "            ", "self", ".", "ctrl", ".", "opt_throttle", ".", "wait", "(", ")", "\n", "if", "self", ".", "ctrl", ".", "quit_opt", ".", "value", ":", "\n", "                ", "break", "\n", "", "self", ".", "algo", ".", "optimize_agent", "(", "itr", ",", "sampler_itr", "=", "self", ".", "ctrl", ".", "sampler_itr", ".", "value", ")", "# Leave un-logged.", "\n", "itr", "+=", "1", "\n", "", "self", ".", "shutdown", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.runners.async_rl.AsyncOptWorker.startup": [[491, 510], ["torch.distributed.init_process_group", "psutil.Process", "async_rl.AsyncOptWorker.affinity.get", "rlpyt.utils.logging.logger.log", "torch.set_num_threads", "rlpyt.utils.logging.logger.log", "rlpyt.utils.logging.logger.log", "rlpyt.utils.seed.set_seed", "async_rl.AsyncOptWorker.agent.to_device", "async_rl.AsyncOptWorker.agent.data_parallel", "async_rl.AsyncOptWorker.algo.optim_initialize", "psutil.Process.cpu_affinity", "async_rl.AsyncOptWorker.affinity.get", "psutil.Process.cpu_affinity", "torch.get_num_threads", "async_rl.AsyncOptWorker.affinity.get"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.utils.collections.NamedArrayTuple.get", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.console.log", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.console.log", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.console.log", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.seed.set_seed", "home.repos.pwc.inspect_result.astooke_rlpyt.safe.cppo_agent.CppoLstmAgent.to_device", "home.repos.pwc.inspect_result.astooke_rlpyt.safe.cppo_agent.CppoLstmAgent.data_parallel", "home.repos.pwc.inspect_result.astooke_rlpyt.rl_with_ul.sac_with_ul.SacWithUl.optim_initialize", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.collections.NamedArrayTuple.get", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.collections.NamedArrayTuple.get"], ["", "def", "startup", "(", "self", ")", ":", "\n", "        ", "torch", ".", "distributed", ".", "init_process_group", "(", "\n", "backend", "=", "\"nccl\"", ",", "\n", "rank", "=", "self", ".", "rank", ",", "\n", "world_size", "=", "self", ".", "world_size", ",", "\n", "init_method", "=", "f\"tcp://127.0.0.1:{self.port}\"", ",", "\n", ")", "\n", "p", "=", "psutil", ".", "Process", "(", ")", "\n", "if", "self", ".", "affinity", ".", "get", "(", "\"set_affinity\"", ",", "True", ")", ":", "\n", "            ", "p", ".", "cpu_affinity", "(", "self", ".", "affinity", "[", "\"cpus\"", "]", ")", "\n", "", "logger", ".", "log", "(", "f\"Optimizer rank {self.rank} CPU affinity: {p.cpu_affinity()}.\"", ")", "\n", "torch", ".", "set_num_threads", "(", "self", ".", "affinity", "[", "\"torch_threads\"", "]", ")", "\n", "logger", ".", "log", "(", "f\"Optimizer rank {self.rank} Torch threads: {torch.get_num_threads()}.\"", ")", "\n", "logger", ".", "log", "(", "f\"Optimizer rank {self.rank} CUDA index: \"", "\n", "f\"{self.affinity.get('cuda_idx', None)}.\"", ")", "\n", "set_seed", "(", "self", ".", "seed", ")", "\n", "self", ".", "agent", ".", "to_device", "(", "cuda_idx", "=", "self", ".", "affinity", ".", "get", "(", "\"cuda_idx\"", ",", "None", ")", ")", "\n", "self", ".", "agent", ".", "data_parallel", "(", ")", "\n", "self", ".", "algo", ".", "optim_initialize", "(", "rank", "=", "self", ".", "rank", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.runners.async_rl.AsyncOptWorker.shutdown": [[511, 513], ["rlpyt.utils.logging.logger.log"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.logging.console.log"], ["", "def", "shutdown", "(", "self", ")", ":", "\n", "        ", "logger", ".", "log", "(", "f\"Async optimization worker {self.rank} shutting down.\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.runners.async_rl.run_async_sampler": [[515, 539], ["sampler.initialize", "range", "rlpyt.utils.logging.logger.log", "sampler.shutdown", "ctrl.sample_copied[].acquire", "sampler.obtain_samples", "ctrl.sample_ready[].release", "s.release", "ctrl.sampler_itr.get_lock", "traj_infos_queue.put"], "function", ["home.repos.pwc.inspect_result.astooke_rlpyt.safe.cppo_agent.CppoLstmAgent.initialize", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.console.log", "home.repos.pwc.inspect_result.astooke_rlpyt.runners.minibatch_rl.MinibatchRlBase.shutdown", "home.repos.pwc.inspect_result.astooke_rlpyt.async_.serial_sampler.AsyncSerialSampler.obtain_samples"], ["", "", "def", "run_async_sampler", "(", "sampler", ",", "affinity", ",", "ctrl", ",", "traj_infos_queue", ",", "n_itr", ")", ":", "\n", "    ", "\"\"\"\n    Target function for the process which will run the sampler, in the case of\n    online performance logging.  Toggles the sampler's double-buffer for each\n    iteration, waits for the memory copier to finish before writing into that\n    buffer, and signals the memory copier when the sampler is done writing a\n    minibatch.\n    \"\"\"", "\n", "sampler", ".", "initialize", "(", "affinity", ")", "\n", "db_idx", "=", "0", "\n", "for", "itr", "in", "range", "(", "n_itr", ")", ":", "\n", "        ", "ctrl", ".", "sample_copied", "[", "db_idx", "]", ".", "acquire", "(", ")", "\n", "traj_infos", "=", "sampler", ".", "obtain_samples", "(", "itr", ",", "db_idx", ")", "\n", "ctrl", ".", "sample_ready", "[", "db_idx", "]", ".", "release", "(", ")", "\n", "with", "ctrl", ".", "sampler_itr", ".", "get_lock", "(", ")", ":", "\n", "            ", "for", "traj_info", "in", "traj_infos", ":", "\n", "                ", "traj_infos_queue", ".", "put", "(", "traj_info", ")", "\n", "", "ctrl", ".", "sampler_itr", ".", "value", "=", "itr", "\n", "", "db_idx", "^=", "1", "# Double buffer.", "\n", "", "logger", ".", "log", "(", "f\"Async sampler reached final itr: {itr + 1}, quitting.\"", ")", "\n", "ctrl", ".", "quit", ".", "value", "=", "True", "# This ends the experiment.", "\n", "sampler", ".", "shutdown", "(", ")", "\n", "for", "s", "in", "ctrl", ".", "sample_ready", ":", "\n", "        ", "s", ".", "release", "(", ")", "# Let memcpy workers finish and quit.", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.runners.async_rl.run_async_sampler_eval": [[541, 571], ["sampler.initialize", "range", "rlpyt.utils.logging.logger.log", "sampler.shutdown", "ctrl.sample_copied[].acquire", "sampler.obtain_samples", "ctrl.sample_ready[].release", "s.release", "sampler.evaluate_agent", "time.time", "time.time", "ctrl.sampler_itr.get_lock", "traj_infos_queue.put", "traj_infos_queue.put"], "function", ["home.repos.pwc.inspect_result.astooke_rlpyt.safe.cppo_agent.CppoLstmAgent.initialize", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.console.log", "home.repos.pwc.inspect_result.astooke_rlpyt.runners.minibatch_rl.MinibatchRlBase.shutdown", "home.repos.pwc.inspect_result.astooke_rlpyt.async_.serial_sampler.AsyncSerialSampler.obtain_samples", "home.repos.pwc.inspect_result.astooke_rlpyt.runners.minibatch_rl.MinibatchRlEval.evaluate_agent"], ["", "", "def", "run_async_sampler_eval", "(", "sampler", ",", "affinity", ",", "ctrl", ",", "traj_infos_queue", ",", "\n", "n_itr", ",", "eval_itrs", ")", ":", "\n", "    ", "\"\"\"\n    Target function running the sampler with offline performance evaluation.\n    \"\"\"", "\n", "sampler", ".", "initialize", "(", "affinity", ")", "\n", "db_idx", "=", "0", "\n", "for", "itr", "in", "range", "(", "n_itr", "+", "1", ")", ":", "# +1 to get last eval :)", "\n", "        ", "ctrl", ".", "sample_copied", "[", "db_idx", "]", ".", "acquire", "(", ")", "\n", "# assert not ctrl.sample_copied[db_idx].acquire(block=False)  # Debug check.", "\n", "sampler", ".", "obtain_samples", "(", "itr", ",", "db_idx", ")", "\n", "ctrl", ".", "sample_ready", "[", "db_idx", "]", ".", "release", "(", ")", "\n", "if", "itr", "%", "eval_itrs", "==", "0", ":", "\n", "            ", "eval_time", "=", "-", "time", ".", "time", "(", ")", "\n", "traj_infos", "=", "sampler", ".", "evaluate_agent", "(", "itr", ")", "\n", "eval_time", "+=", "time", ".", "time", "(", ")", "\n", "ctrl", ".", "eval_time", ".", "value", "+=", "eval_time", "# Not atomic but only writer.", "\n", "with", "ctrl", ".", "sampler_itr", ".", "get_lock", "(", ")", ":", "\n", "                ", "for", "traj_info", "in", "traj_infos", ":", "\n", "                    ", "traj_infos_queue", ".", "put", "(", "traj_info", ")", "\n", "", "traj_infos_queue", ".", "put", "(", "None", ")", "# Master will get until None sentinel.", "\n", "ctrl", ".", "sampler_itr", ".", "value", "=", "itr", "\n", "", "", "else", ":", "\n", "            ", "ctrl", ".", "sampler_itr", ".", "value", "=", "itr", "\n", "", "db_idx", "^=", "1", "# Double buffer", "\n", "", "logger", ".", "log", "(", "f\"Async sampler reached final itr: {itr + 1}, quitting.\"", ")", "\n", "ctrl", ".", "quit", ".", "value", "=", "True", "# This ends the experiment.", "\n", "sampler", ".", "shutdown", "(", ")", "\n", "for", "s", "in", "ctrl", ".", "sample_ready", ":", "\n", "        ", "s", ".", "release", "(", ")", "# Let memcpy workers finish and quit.", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.runners.async_rl.memory_copier": [[573, 609], ["torch.set_num_threads", "rlpyt.utils.logging.logger.log", "ctrl.sample_ready.acquire", "replay_buffer.append_samples", "ctrl.sample_copied.release", "samples_to_buffer"], "function", ["home.repos.pwc.inspect_result.astooke_rlpyt.logging.console.log", "home.repos.pwc.inspect_result.astooke_rlpyt.sequence.prioritized.PrioritizedSequenceReplay.append_samples", "home.repos.pwc.inspect_result.astooke_rlpyt.rl_with_ul.ppo_with_ul.PpoUl.samples_to_buffer"], ["", "", "def", "memory_copier", "(", "sample_buffer", ",", "samples_to_buffer", ",", "replay_buffer", ",", "ctrl", ")", ":", "\n", "    ", "\"\"\"\n    Target function for the process which will copy the sampler's minibatch buffer\n    into the algorithm's main replay buffer.\n\n    Args:\n        sample_buffer: The (single) minibatch buffer from the sampler, on shared memory.\n        samples_to_buffer:  A function/method from the algorithm to process samples from the minibatch buffer into the replay buffer (e.g. select which fields, compute some prioritization).\n        replay_buffer: Algorithm's main replay buffer, on shared memory.\n        ctrl: Structure for communicating when the minibatch is ready to copy/done copying.\n    Warning:\n        Although this function may use the algorithm's ``samples_to_buffer()``\n        method, here it is running in a separate process, so will not be aware\n        of changes in the algorithm from the optimizer process.  Furthermore,\n        it may not be able to store state across iterations--in the\n        implemented setup, two separate memory copier processes are used, so\n        each one only sees every other minibatch.  (Could easily change to\n        single copier if desired, and probably without peformance loss.)\n\n    \"\"\"", "\n", "# Needed on some systems to avoid mysterious hang:", "\n", "torch", ".", "set_num_threads", "(", "1", ")", "\n", "# (Without torch.set_num_threads, experienced hang on Ubuntu Server 16.04", "\n", "# machines (but not Desktop) when appending samples to make replay buffer", "\n", "# full, but only for batch_B > 84 (dqn + r2d1 atari), regardless of replay", "\n", "# size or batch_T.  Would seem to progress through all code in", "\n", "# replay.append_samples() but simply would not return from it.  Some", "\n", "# tipping point for MKL threading?)", "\n", "while", "True", ":", "\n", "        ", "ctrl", ".", "sample_ready", ".", "acquire", "(", ")", "\n", "# assert not ctrl.sample_ready.acquire(block=False)  # Debug check.", "\n", "if", "ctrl", ".", "quit", ".", "value", ":", "\n", "            ", "break", "\n", "", "replay_buffer", ".", "append_samples", "(", "samples_to_buffer", "(", "sample_buffer", ")", ")", "\n", "ctrl", ".", "sample_copied", ".", "release", "(", ")", "\n", "", "logger", ".", "log", "(", "\"Memory copier shutting down.\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.runners.async_rl.placeholder": [[611, 614], ["None"], "function", ["None"], ["", "def", "placeholder", "(", "x", ")", ":", "\n", "\n", "    ", "pass", "", "", ""]], "home.repos.pwc.inspect_result.astooke_rlpyt.runners.sync_rl.SyncRlMixin.startup": [[53, 59], ["sync_rl.SyncRlMixin.launch_workers", "super().startup", "sync_rl.SyncRlMixin.par.barrier.wait", "time.time"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.runners.sync_rl.SyncRlMixin.launch_workers", "home.repos.pwc.inspect_result.astooke_rlpyt.runners.minibatch_rl.MinibatchRlBase.startup"], ["def", "startup", "(", "self", ")", ":", "\n", "        ", "self", ".", "launch_workers", "(", ")", "\n", "n_itr", "=", "super", "(", ")", ".", "startup", "(", ")", "\n", "self", ".", "par", ".", "barrier", ".", "wait", "(", ")", "\n", "self", ".", "_start_time", "=", "self", ".", "_last_time", "=", "time", ".", "time", "(", ")", "# (Overwrite)", "\n", "return", "n_itr", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.runners.sync_rl.SyncRlMixin.launch_workers": [[60, 101], ["len", "sync_rl.SyncRlMixin.build_par_objs", "rlpyt.utils.synchronize.find_port", "torch.distributed.init_process_group", "rlpyt.utils.seed.make_seed", "dict", "sync_rl.SyncRlMixin.WorkerCls", "multiprocessing.Process", "w.start", "sync_rl.SyncRlMixin.affinity.get", "range", "sync_rl.SyncRlMixin.affinity.get"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.runners.sync_rl.SyncRlMixin.build_par_objs", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.synchronize.find_port", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.seed.make_seed", "home.repos.pwc.inspect_result.astooke_rlpyt.runners.sync_rl.SyncRlEval.WorkerCls", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.collections.NamedArrayTuple.get", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.collections.NamedArrayTuple.get"], ["", "def", "launch_workers", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        As part of startup, fork a separate Python process for each additional\n        GPU; the master process runs on the first GPU.  Initialize\n        ``torch.distributed`` so the ``DistributedDataParallel`` wrapper can\n        work--also makes ``torch.distributed`` avaiable for other\n        communication.\n        \"\"\"", "\n", "self", ".", "affinities", "=", "self", ".", "affinity", "\n", "self", ".", "affinity", "=", "self", ".", "affinities", "[", "0", "]", "\n", "self", ".", "world_size", "=", "world_size", "=", "len", "(", "self", ".", "affinities", ")", "\n", "self", ".", "rank", "=", "rank", "=", "0", "\n", "self", ".", "par", "=", "par", "=", "self", ".", "build_par_objs", "(", "world_size", ")", "\n", "if", "self", ".", "seed", "is", "None", ":", "\n", "            ", "self", ".", "seed", "=", "make_seed", "(", ")", "\n", "", "port", "=", "find_port", "(", "offset", "=", "self", ".", "affinity", ".", "get", "(", "\"master_cpus\"", ",", "[", "0", "]", ")", "[", "0", "]", ")", "\n", "backend", "=", "\"gloo\"", "if", "self", ".", "affinity", ".", "get", "(", "\"cuda_idx\"", ",", "None", ")", "is", "None", "else", "\"nccl\"", "\n", "workers_kwargs", "=", "[", "dict", "(", "\n", "algo", "=", "self", ".", "algo", ",", "\n", "agent", "=", "self", ".", "agent", ",", "\n", "sampler", "=", "self", ".", "sampler", ",", "\n", "n_steps", "=", "self", ".", "n_steps", ",", "\n", "seed", "=", "self", ".", "seed", "+", "100", "*", "rank", ",", "\n", "affinity", "=", "self", ".", "affinities", "[", "rank", "]", ",", "\n", "log_interval_steps", "=", "self", ".", "log_interval_steps", ",", "\n", "rank", "=", "rank", ",", "\n", "world_size", "=", "world_size", ",", "\n", "port", "=", "port", ",", "\n", "backend", "=", "backend", ",", "\n", "par", "=", "par", ",", "\n", ")", "\n", "for", "rank", "in", "range", "(", "1", ",", "world_size", ")", "]", "\n", "workers", "=", "[", "self", ".", "WorkerCls", "(", "**", "w_kwargs", ")", "for", "w_kwargs", "in", "workers_kwargs", "]", "\n", "self", ".", "workers", "=", "[", "mp", ".", "Process", "(", "target", "=", "w", ".", "train", ",", "args", "=", "(", ")", ")", "for", "w", "in", "workers", "]", "\n", "for", "w", "in", "self", ".", "workers", ":", "\n", "            ", "w", ".", "start", "(", ")", "\n", "", "torch", ".", "distributed", ".", "init_process_group", "(", "\n", "backend", "=", "backend", ",", "\n", "rank", "=", "rank", ",", "\n", "world_size", "=", "world_size", ",", "\n", "init_method", "=", "f\"tcp://127.0.0.1:{port}\"", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.runners.sync_rl.SyncRlMixin.build_par_objs": [[103, 111], ["multiprocessing.Barrier", "multiprocessing.Queue", "rlpyt.utils.collections.AttrDict"], "methods", ["None"], ["", "def", "build_par_objs", "(", "self", ",", "world_size", ")", ":", "\n", "        ", "barrier", "=", "mp", ".", "Barrier", "(", "world_size", ")", "\n", "traj_infos_queue", "=", "mp", ".", "Queue", "(", ")", "\n", "par", "=", "AttrDict", "(", "\n", "barrier", "=", "barrier", ",", "\n", "traj_infos_queue", "=", "traj_infos_queue", ",", "\n", ")", "\n", "return", "par", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.runners.sync_rl.SyncRl.WorkerCls": [[119, 122], ["None"], "methods", ["None"], ["@", "property", "\n", "def", "WorkerCls", "(", "self", ")", ":", "\n", "        ", "return", "SyncWorker", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.runners.sync_rl.SyncRl.store_diagnostics": [[123, 126], ["traj_infos.extend", "super().store_diagnostics", "rlpyt.utils.synchronize.drain_queue"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.runners.minibatch_rl.MinibatchRl.store_diagnostics", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.synchronize.drain_queue"], ["", "def", "store_diagnostics", "(", "self", ",", "itr", ",", "traj_infos", ",", "opt_info", ")", ":", "\n", "        ", "traj_infos", ".", "extend", "(", "drain_queue", "(", "self", ".", "par", ".", "traj_infos_queue", ")", ")", "\n", "super", "(", ")", ".", "store_diagnostics", "(", "itr", ",", "traj_infos", ",", "opt_info", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.runners.sync_rl.SyncRlEval.WorkerCls": [[134, 137], ["None"], "methods", ["None"], ["@", "property", "\n", "def", "WorkerCls", "(", "self", ")", ":", "\n", "        ", "return", "SyncWorkerEval", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.runners.sync_rl.SyncRlEval.log_diagnostics": [[138, 141], ["super().log_diagnostics", "sync_rl.SyncRlEval.par.barrier.wait"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.runners.minibatch_rl.MinibatchRlEval.log_diagnostics"], ["", "def", "log_diagnostics", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "log_diagnostics", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "self", ".", "par", ".", "barrier", ".", "wait", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.runners.sync_rl.SyncWorkerMixin.__init__": [[150, 166], ["rlpyt.utils.quick_args.save__init__args", "locals"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.utils.quick_args.save__init__args"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "algo", ",", "\n", "agent", ",", "\n", "sampler", ",", "\n", "n_steps", ",", "\n", "seed", ",", "\n", "affinity", ",", "\n", "log_interval_steps", ",", "\n", "rank", ",", "\n", "world_size", ",", "\n", "port", ",", "\n", "backend", ",", "\n", "par", ",", "\n", ")", ":", "\n", "        ", "save__init__args", "(", "locals", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.runners.sync_rl.SyncWorkerMixin.startup": [[167, 177], ["torch.distributed.init_process_group", "super().startup", "sync_rl.SyncWorkerMixin.par.barrier.wait"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.runners.minibatch_rl.MinibatchRlBase.startup"], ["", "def", "startup", "(", "self", ")", ":", "\n", "        ", "torch", ".", "distributed", ".", "init_process_group", "(", "\n", "backend", "=", "self", ".", "backend", ",", "\n", "rank", "=", "self", ".", "rank", ",", "\n", "world_size", "=", "self", ".", "world_size", ",", "\n", "init_method", "=", "f\"tcp://127.0.0.1:{self.port}\"", ",", "\n", ")", "\n", "n_itr", "=", "super", "(", ")", ".", "startup", "(", ")", "\n", "self", ".", "par", ".", "barrier", ".", "wait", "(", ")", "\n", "return", "n_itr", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.runners.sync_rl.SyncWorkerMixin.initialize_logging": [[178, 180], ["None"], "methods", ["None"], ["", "def", "initialize_logging", "(", "self", ")", ":", "\n", "        ", "pass", "# Don't log in workers.", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.runners.sync_rl.SyncWorkerMixin.shutdown": [[181, 183], ["sync_rl.SyncWorkerMixin.sampler.shutdown"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.runners.minibatch_rl.MinibatchRlBase.shutdown"], ["", "def", "shutdown", "(", "self", ")", ":", "\n", "        ", "self", ".", "sampler", ".", "shutdown", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.runners.sync_rl.SyncWorker.store_diagnostics": [[187, 190], ["sync_rl.SyncWorker.par.traj_infos_queue.put"], "methods", ["None"], ["    ", "def", "store_diagnostics", "(", "self", ",", "itr", ",", "traj_infos", ",", "opt_info", ")", ":", "\n", "        ", "for", "traj_info", "in", "traj_infos", ":", "\n", "            ", "self", ".", "par", ".", "traj_infos_queue", ".", "put", "(", "traj_info", ")", "\n", "# Leave worker opt_info un-recorded.", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.runners.sync_rl.SyncWorker.log_diagnostics": [[192, 194], ["None"], "methods", ["None"], ["", "", "def", "log_diagnostics", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.runners.sync_rl.SyncWorkerEval.store_diagnostics": [[198, 200], ["None"], "methods", ["None"], ["    ", "def", "store_diagnostics", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.runners.sync_rl.SyncWorkerEval.log_diagnostics": [[201, 203], ["sync_rl.SyncWorkerEval.par.barrier.wait"], "methods", ["None"], ["", "def", "log_diagnostics", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "self", ".", "par", ".", "barrier", ".", "wait", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.runners.sync_rl.SyncWorkerEval.evaluate_agent": [[204, 206], ["None"], "methods", ["None"], ["", "def", "evaluate_agent", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "return", "None", ",", "None", "\n", "", "", ""]], "home.repos.pwc.inspect_result.astooke_rlpyt.runners.minibatch_rl.MinibatchRlBase.__init__": [[33, 48], ["int", "int", "rlpyt.utils.quick_args.save__init__args", "getattr", "dict", "locals"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.utils.quick_args.save__init__args"], ["def", "__init__", "(", "\n", "self", ",", "\n", "algo", ",", "\n", "agent", ",", "\n", "sampler", ",", "\n", "n_steps", ",", "\n", "seed", "=", "None", ",", "\n", "affinity", "=", "None", ",", "\n", "log_interval_steps", "=", "1e5", ",", "\n", ")", ":", "\n", "        ", "n_steps", "=", "int", "(", "n_steps", ")", "\n", "log_interval_steps", "=", "int", "(", "log_interval_steps", ")", "\n", "affinity", "=", "dict", "(", ")", "if", "affinity", "is", "None", "else", "affinity", "\n", "save__init__args", "(", "locals", "(", ")", ")", "\n", "self", ".", "min_itr_learn", "=", "getattr", "(", "self", ".", "algo", ",", "'min_itr_learn'", ",", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.runners.minibatch_rl.MinibatchRlBase.startup": [[49, 99], ["psutil.Process", "rlpyt.utils.logging.logger.log", "rlpyt.utils.logging.logger.log", "rlpyt.utils.seed.set_seed", "getattr", "getattr", "minibatch_rl.MinibatchRlBase.sampler.initialize", "minibatch_rl.MinibatchRlBase.get_n_itr", "minibatch_rl.MinibatchRlBase.agent.to_device", "minibatch_rl.MinibatchRlBase.algo.initialize", "minibatch_rl.MinibatchRlBase.initialize_logging", "psutil.Process.cpu_affinity", "minibatch_rl.MinibatchRlBase.affinity.get", "torch.set_num_threads", "rlpyt.utils.seed.make_seed", "minibatch_rl.MinibatchRlBase.affinity.get", "minibatch_rl.MinibatchRlBase.agent.data_parallel", "minibatch_rl.MinibatchRlBase.affinity.get", "psutil.Process.cpu_affinity", "getattr", "minibatch_rl.MinibatchRlBase.get_traj_info_kwargs", "minibatch_rl.MinibatchRlBase.affinity.get", "getattr", "getattr", "torch.get_num_threads"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.logging.console.log", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.console.log", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.seed.set_seed", "home.repos.pwc.inspect_result.astooke_rlpyt.safe.cppo_agent.CppoLstmAgent.initialize", "home.repos.pwc.inspect_result.astooke_rlpyt.runners.minibatch_rl.MinibatchRlBase.get_n_itr", "home.repos.pwc.inspect_result.astooke_rlpyt.safe.cppo_agent.CppoLstmAgent.to_device", "home.repos.pwc.inspect_result.astooke_rlpyt.safe.cppo_agent.CppoLstmAgent.initialize", "home.repos.pwc.inspect_result.astooke_rlpyt.runners.minibatch_rl.MinibatchRlEval.initialize_logging", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.collections.NamedArrayTuple.get", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.seed.make_seed", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.collections.NamedArrayTuple.get", "home.repos.pwc.inspect_result.astooke_rlpyt.safe.cppo_agent.CppoLstmAgent.data_parallel", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.collections.NamedArrayTuple.get", "home.repos.pwc.inspect_result.astooke_rlpyt.runners.minibatch_rl.MinibatchRlBase.get_traj_info_kwargs", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.collections.NamedArrayTuple.get"], ["", "def", "startup", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Sets hardware affinities, initializes the following: 1) sampler (which\n        should initialize the agent), 2) agent device and data-parallel wrapper (if applicable),\n        3) algorithm, 4) logger.\n        \"\"\"", "\n", "p", "=", "psutil", ".", "Process", "(", ")", "\n", "try", ":", "\n", "            ", "if", "(", "self", ".", "affinity", ".", "get", "(", "\"master_cpus\"", ",", "None", ")", "is", "not", "None", "and", "\n", "self", ".", "affinity", ".", "get", "(", "\"set_affinity\"", ",", "True", ")", ")", ":", "\n", "                ", "p", ".", "cpu_affinity", "(", "self", ".", "affinity", "[", "\"master_cpus\"", "]", ")", "\n", "", "cpu_affin", "=", "p", ".", "cpu_affinity", "(", ")", "\n", "", "except", "AttributeError", ":", "\n", "            ", "cpu_affin", "=", "\"UNAVAILABLE MacOS\"", "\n", "", "logger", ".", "log", "(", "f\"Runner {getattr(self, 'rank', '')} master CPU affinity: \"", "\n", "f\"{cpu_affin}.\"", ")", "\n", "if", "self", ".", "affinity", ".", "get", "(", "\"master_torch_threads\"", ",", "None", ")", "is", "not", "None", ":", "\n", "            ", "torch", ".", "set_num_threads", "(", "self", ".", "affinity", "[", "\"master_torch_threads\"", "]", ")", "\n", "", "logger", ".", "log", "(", "f\"Runner {getattr(self, 'rank', '')} master Torch threads: \"", "\n", "f\"{torch.get_num_threads()}.\"", ")", "\n", "if", "self", ".", "seed", "is", "None", ":", "\n", "            ", "self", ".", "seed", "=", "make_seed", "(", ")", "\n", "", "set_seed", "(", "self", ".", "seed", ")", "\n", "self", ".", "rank", "=", "rank", "=", "getattr", "(", "self", ",", "\"rank\"", ",", "0", ")", "\n", "self", ".", "world_size", "=", "world_size", "=", "getattr", "(", "self", ",", "\"world_size\"", ",", "1", ")", "\n", "examples", "=", "self", ".", "sampler", ".", "initialize", "(", "\n", "agent", "=", "self", ".", "agent", ",", "# Agent gets initialized in sampler.", "\n", "affinity", "=", "self", ".", "affinity", ",", "\n", "seed", "=", "self", ".", "seed", "+", "1", ",", "\n", "bootstrap_value", "=", "getattr", "(", "self", ".", "algo", ",", "\"bootstrap_value\"", ",", "False", ")", ",", "\n", "traj_info_kwargs", "=", "self", ".", "get_traj_info_kwargs", "(", ")", ",", "\n", "rank", "=", "rank", ",", "\n", "world_size", "=", "world_size", ",", "\n", ")", "\n", "self", ".", "itr_batch_size", "=", "self", ".", "sampler", ".", "batch_spec", ".", "size", "*", "world_size", "\n", "n_itr", "=", "self", ".", "get_n_itr", "(", ")", "\n", "self", ".", "agent", ".", "to_device", "(", "self", ".", "affinity", ".", "get", "(", "\"cuda_idx\"", ",", "None", ")", ")", "\n", "if", "world_size", ">", "1", ":", "\n", "            ", "self", ".", "agent", ".", "data_parallel", "(", ")", "\n", "", "self", ".", "algo", ".", "initialize", "(", "\n", "agent", "=", "self", ".", "agent", ",", "\n", "n_itr", "=", "n_itr", ",", "\n", "batch_spec", "=", "self", ".", "sampler", ".", "batch_spec", ",", "\n", "mid_batch_reset", "=", "self", ".", "sampler", ".", "mid_batch_reset", ",", "\n", "examples", "=", "examples", ",", "\n", "world_size", "=", "world_size", ",", "\n", "rank", "=", "rank", ",", "\n", ")", "\n", "self", ".", "initialize_logging", "(", ")", "\n", "return", "n_itr", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.runners.minibatch_rl.MinibatchRlBase.get_traj_info_kwargs": [[100, 106], ["dict", "getattr"], "methods", ["None"], ["", "def", "get_traj_info_kwargs", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Pre-defines any TrajInfo attributes needed from elsewhere e.g.\n        algorithm discount factor.\n        \"\"\"", "\n", "return", "dict", "(", "discount", "=", "getattr", "(", "self", ".", "algo", ",", "\"discount\"", ",", "1", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.runners.minibatch_rl.MinibatchRlBase.get_n_itr": [[107, 122], ["max", "rlpyt.utils.logging.logger.log"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.logging.console.log"], ["", "def", "get_n_itr", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Determine number of train loop iterations to run.  Converts logging\n        interval units from environment steps to iterations.\n        \"\"\"", "\n", "# Log at least as often as requested (round down itrs):", "\n", "log_interval_itrs", "=", "max", "(", "self", ".", "log_interval_steps", "//", "\n", "self", ".", "itr_batch_size", ",", "1", ")", "\n", "n_itr", "=", "self", ".", "n_steps", "//", "self", ".", "itr_batch_size", "\n", "if", "n_itr", "%", "log_interval_itrs", ">", "0", ":", "# Keep going to next log itr.", "\n", "            ", "n_itr", "+=", "log_interval_itrs", "-", "(", "n_itr", "%", "log_interval_itrs", ")", "\n", "", "self", ".", "log_interval_itrs", "=", "log_interval_itrs", "\n", "self", ".", "n_itr", "=", "n_itr", "\n", "logger", ".", "log", "(", "f\"Running {n_itr} iterations of minibatch RL.\"", ")", "\n", "return", "n_itr", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.runners.minibatch_rl.MinibatchRlBase.initialize_logging": [[123, 129], ["time.time", "list"], "methods", ["None"], ["", "def", "initialize_logging", "(", "self", ")", ":", "\n", "        ", "self", ".", "_opt_infos", "=", "{", "k", ":", "list", "(", ")", "for", "k", "in", "self", ".", "algo", ".", "opt_info_fields", "}", "\n", "self", ".", "_start_time", "=", "self", ".", "_last_time", "=", "time", ".", "time", "(", ")", "\n", "self", ".", "_cum_time", "=", "0.", "\n", "self", ".", "_cum_completed_trajs", "=", "0", "\n", "self", ".", "_last_update_counter", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.runners.minibatch_rl.MinibatchRlBase.shutdown": [[130, 134], ["rlpyt.utils.logging.logger.log", "minibatch_rl.MinibatchRlBase.pbar.stop", "minibatch_rl.MinibatchRlBase.sampler.shutdown"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.logging.console.log", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.prog_bar.ProgBarCounter.stop", "home.repos.pwc.inspect_result.astooke_rlpyt.runners.minibatch_rl.MinibatchRlBase.shutdown"], ["", "def", "shutdown", "(", "self", ")", ":", "\n", "        ", "logger", ".", "log", "(", "\"Training complete.\"", ")", "\n", "self", ".", "pbar", ".", "stop", "(", ")", "\n", "self", ".", "sampler", ".", "shutdown", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.runners.minibatch_rl.MinibatchRlBase.get_itr_snapshot": [[135, 145], ["dict", "minibatch_rl.MinibatchRlBase.agent.state_dict", "minibatch_rl.MinibatchRlBase.algo.optim_state_dict"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.replay_saver.DummyOptimizer.state_dict", "home.repos.pwc.inspect_result.astooke_rlpyt.rl_with_ul.sac_with_ul.SacWithUl.optim_state_dict"], ["", "def", "get_itr_snapshot", "(", "self", ",", "itr", ")", ":", "\n", "        ", "\"\"\"\n        Returns all state needed for full checkpoint/snapshot of training run,\n        including agent parameters and optimizer parameters.\n        \"\"\"", "\n", "return", "dict", "(", "\n", "itr", "=", "itr", ",", "\n", "cum_steps", "=", "itr", "*", "self", ".", "sampler", ".", "batch_size", "*", "self", ".", "world_size", ",", "\n", "agent_state_dict", "=", "self", ".", "agent", ".", "state_dict", "(", ")", ",", "\n", "optimizer_state_dict", "=", "self", ".", "algo", ".", "optim_state_dict", "(", ")", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.runners.minibatch_rl.MinibatchRlBase.save_itr_snapshot": [[147, 156], ["rlpyt.utils.logging.logger.log", "minibatch_rl.MinibatchRlBase.get_itr_snapshot", "rlpyt.utils.logging.logger.save_itr_params", "rlpyt.utils.logging.logger.log"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.logging.console.log", "home.repos.pwc.inspect_result.astooke_rlpyt.runners.minibatch_rl.MinibatchRlBase.get_itr_snapshot", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.logger.save_itr_params", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.console.log"], ["", "def", "save_itr_snapshot", "(", "self", ",", "itr", ")", ":", "\n", "        ", "\"\"\"\n        Calls the logger to save training checkpoint/snapshot (logger itself\n        may or may not save, depending on mode selected).\n        \"\"\"", "\n", "logger", ".", "log", "(", "\"saving snapshot...\"", ")", "\n", "params", "=", "self", ".", "get_itr_snapshot", "(", "itr", ")", "\n", "logger", ".", "save_itr_params", "(", "itr", ",", "params", ")", "\n", "logger", ".", "log", "(", "\"saved\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.runners.minibatch_rl.MinibatchRlBase.store_diagnostics": [[157, 167], ["len", "minibatch_rl.MinibatchRlBase._opt_infos.items", "minibatch_rl.MinibatchRlBase.pbar.update", "getattr", "v.extend", "isinstance"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.utils.collections.NamedArrayTuple.items", "home.repos.pwc.inspect_result.astooke_rlpyt.models.running_mean_std.RunningMeanStdModel.update"], ["", "def", "store_diagnostics", "(", "self", ",", "itr", ",", "traj_infos", ",", "opt_info", ")", ":", "\n", "        ", "\"\"\"\n        Store any diagnostic information from a training iteration that should\n        be kept for the next logging iteration.\n        \"\"\"", "\n", "self", ".", "_cum_completed_trajs", "+=", "len", "(", "traj_infos", ")", "\n", "for", "k", ",", "v", "in", "self", ".", "_opt_infos", ".", "items", "(", ")", ":", "\n", "            ", "new_v", "=", "getattr", "(", "opt_info", ",", "k", ",", "[", "]", ")", "\n", "v", ".", "extend", "(", "new_v", "if", "isinstance", "(", "new_v", ",", "list", ")", "else", "[", "new_v", "]", ")", "\n", "", "self", ".", "pbar", ".", "update", "(", "(", "itr", "+", "1", ")", "%", "self", ".", "log_interval_itrs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.runners.minibatch_rl.MinibatchRlBase.log_diagnostics": [[168, 213], ["time.time", "minibatch_rl.MinibatchRlBase._log_infos", "rlpyt.utils.logging.logger.dump_tabular", "minibatch_rl.MinibatchRlBase.pbar.stop", "minibatch_rl.MinibatchRlBase.save_itr_snapshot", "float", "float", "rlpyt.utils.logging.logger.tabular_prefix", "rlpyt.utils.logging.logger.record_tabular", "rlpyt.utils.logging.logger.record_tabular", "rlpyt.utils.logging.logger.record_tabular", "rlpyt.utils.logging.logger.record_tabular", "rlpyt.utils.logging.logger.record_tabular", "rlpyt.utils.logging.logger.record_tabular", "rlpyt.utils.logging.logger.record_tabular", "rlpyt.utils.logging.logger.record_tabular", "rlpyt.utils.logging.logger.record_tabular", "rlpyt.utils.logging.logger.log", "rlpyt.utils.prog_bar.ProgBarCounter", "rlpyt.utils.logging.logger.record_tabular"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.runners.minibatch_rl.MinibatchRlBase._log_infos", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.logger.dump_tabular", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.prog_bar.ProgBarCounter.stop", "home.repos.pwc.inspect_result.astooke_rlpyt.runners.minibatch_rl.MinibatchRlBase.save_itr_snapshot", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.logger.tabular_prefix", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.logger.record_tabular", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.logger.record_tabular", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.logger.record_tabular", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.logger.record_tabular", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.logger.record_tabular", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.logger.record_tabular", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.logger.record_tabular", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.logger.record_tabular", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.logger.record_tabular", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.console.log", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.logger.record_tabular"], ["", "def", "log_diagnostics", "(", "self", ",", "itr", ",", "traj_infos", "=", "None", ",", "eval_time", "=", "0", ",", "prefix", "=", "'Diagnostics/'", ")", ":", "\n", "        ", "\"\"\"\n        Write diagnostics (including stored ones) to csv via the logger.\n        \"\"\"", "\n", "if", "itr", ">", "0", ":", "\n", "            ", "self", ".", "pbar", ".", "stop", "(", ")", "\n", "", "if", "itr", ">=", "self", ".", "min_itr_learn", "-", "1", ":", "\n", "            ", "self", ".", "save_itr_snapshot", "(", "itr", ")", "\n", "", "new_time", "=", "time", ".", "time", "(", ")", "\n", "self", ".", "_cum_time", "=", "new_time", "-", "self", ".", "_start_time", "\n", "train_time_elapsed", "=", "new_time", "-", "self", ".", "_last_time", "-", "eval_time", "\n", "new_updates", "=", "self", ".", "algo", ".", "update_counter", "-", "self", ".", "_last_update_counter", "\n", "new_samples", "=", "(", "self", ".", "sampler", ".", "batch_size", "*", "self", ".", "world_size", "*", "\n", "self", ".", "log_interval_itrs", ")", "\n", "updates_per_second", "=", "(", "float", "(", "'nan'", ")", "if", "itr", "==", "0", "else", "\n", "new_updates", "/", "train_time_elapsed", ")", "\n", "samples_per_second", "=", "(", "float", "(", "'nan'", ")", "if", "itr", "==", "0", "else", "\n", "new_samples", "/", "train_time_elapsed", ")", "\n", "replay_ratio", "=", "(", "new_updates", "*", "self", ".", "algo", ".", "batch_size", "*", "self", ".", "world_size", "/", "\n", "new_samples", ")", "\n", "cum_replay_ratio", "=", "(", "self", ".", "algo", ".", "batch_size", "*", "self", ".", "algo", ".", "update_counter", "/", "\n", "(", "(", "itr", "+", "1", ")", "*", "self", ".", "sampler", ".", "batch_size", ")", ")", "# world_size cancels.", "\n", "cum_steps", "=", "(", "itr", "+", "1", ")", "*", "self", ".", "sampler", ".", "batch_size", "*", "self", ".", "world_size", "\n", "\n", "with", "logger", ".", "tabular_prefix", "(", "prefix", ")", ":", "\n", "            ", "if", "self", ".", "_eval", ":", "\n", "                ", "logger", ".", "record_tabular", "(", "'CumTrainTime'", ",", "\n", "self", ".", "_cum_time", "-", "self", ".", "_cum_eval_time", ")", "# Already added new eval_time.", "\n", "", "logger", ".", "record_tabular", "(", "'Iteration'", ",", "itr", ")", "\n", "logger", ".", "record_tabular", "(", "'CumTime (s)'", ",", "self", ".", "_cum_time", ")", "\n", "logger", ".", "record_tabular", "(", "'CumSteps'", ",", "cum_steps", ")", "\n", "logger", ".", "record_tabular", "(", "'CumCompletedTrajs'", ",", "self", ".", "_cum_completed_trajs", ")", "\n", "logger", ".", "record_tabular", "(", "'CumUpdates'", ",", "self", ".", "algo", ".", "update_counter", ")", "\n", "logger", ".", "record_tabular", "(", "'StepsPerSecond'", ",", "samples_per_second", ")", "\n", "logger", ".", "record_tabular", "(", "'UpdatesPerSecond'", ",", "updates_per_second", ")", "\n", "logger", ".", "record_tabular", "(", "'ReplayRatio'", ",", "replay_ratio", ")", "\n", "logger", ".", "record_tabular", "(", "'CumReplayRatio'", ",", "cum_replay_ratio", ")", "\n", "", "self", ".", "_log_infos", "(", "traj_infos", ")", "\n", "logger", ".", "dump_tabular", "(", "with_prefix", "=", "False", ")", "\n", "\n", "self", ".", "_last_time", "=", "new_time", "\n", "self", ".", "_last_update_counter", "=", "self", ".", "algo", ".", "update_counter", "\n", "if", "itr", "<", "self", ".", "n_itr", "-", "1", ":", "\n", "            ", "logger", ".", "log", "(", "f\"Optimizing over {self.log_interval_itrs} iterations.\"", ")", "\n", "self", ".", "pbar", "=", "ProgBarCounter", "(", "self", ".", "log_interval_itrs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.runners.minibatch_rl.MinibatchRlBase._log_infos": [[214, 230], ["minibatch_rl.MinibatchRlBase._opt_infos.items", "list", "rlpyt.utils.logging.logger.record_tabular_misc_stat", "k.startswith", "rlpyt.utils.logging.logger.record_tabular_misc_stat"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.utils.collections.NamedArrayTuple.items", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.logger.record_tabular_misc_stat", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.logger.record_tabular_misc_stat"], ["", "", "def", "_log_infos", "(", "self", ",", "traj_infos", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Writes trajectory info and optimizer info into csv via the logger.\n        Resets stored optimizer info.\n        \"\"\"", "\n", "if", "traj_infos", "is", "None", ":", "\n", "            ", "traj_infos", "=", "self", ".", "_traj_infos", "\n", "", "if", "traj_infos", ":", "\n", "            ", "for", "k", "in", "traj_infos", "[", "0", "]", ":", "\n", "                ", "if", "not", "k", ".", "startswith", "(", "\"_\"", ")", ":", "\n", "                    ", "logger", ".", "record_tabular_misc_stat", "(", "k", ",", "[", "info", "[", "k", "]", "for", "info", "in", "traj_infos", "]", ")", "\n", "\n", "", "", "", "if", "self", ".", "_opt_infos", ":", "\n", "            ", "for", "k", ",", "v", "in", "self", ".", "_opt_infos", ".", "items", "(", ")", ":", "\n", "                ", "logger", ".", "record_tabular_misc_stat", "(", "k", ",", "v", ")", "\n", "", "", "self", ".", "_opt_infos", "=", "{", "k", ":", "list", "(", ")", "for", "k", "in", "self", ".", "_opt_infos", "}", "# (reset)", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.runners.minibatch_rl.MinibatchRl.__init__": [[238, 245], ["minibatch_rl.MinibatchRlBase.__init__", "int"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.spaces.gym_wrapper.GymSpaceWrapper.__init__"], ["def", "__init__", "(", "self", ",", "log_traj_window", "=", "100", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"\n        Args: \n            log_traj_window (int): How many trajectories to hold in deque for computing performance statistics.\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "self", ".", "log_traj_window", "=", "int", "(", "log_traj_window", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.runners.minibatch_rl.MinibatchRl.train": [[246, 264], ["minibatch_rl.MinibatchRl.startup", "range", "minibatch_rl.MinibatchRl.shutdown", "rlpyt.utils.logging.logger.set_iteration", "rlpyt.utils.logging.logger.prefix", "minibatch_rl.MinibatchRl.agent.sample_mode", "minibatch_rl.MinibatchRl.sampler.obtain_samples", "minibatch_rl.MinibatchRl.agent.train_mode", "minibatch_rl.MinibatchRl.algo.optimize_agent", "minibatch_rl.MinibatchRl.store_diagnostics", "minibatch_rl.MinibatchRl.log_diagnostics"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.runners.minibatch_rl.MinibatchRlBase.startup", "home.repos.pwc.inspect_result.astooke_rlpyt.runners.minibatch_rl.MinibatchRlBase.shutdown", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.logger.set_iteration", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.logger.prefix", "home.repos.pwc.inspect_result.astooke_rlpyt.agents.dmc_sac_agent.SacAgent.sample_mode", "home.repos.pwc.inspect_result.astooke_rlpyt.async_.serial_sampler.AsyncSerialSampler.obtain_samples", "home.repos.pwc.inspect_result.astooke_rlpyt.agents.dmc_sac_agent.SacAgent.train_mode", "home.repos.pwc.inspect_result.astooke_rlpyt.safe.cppo_pid.CppoPID.optimize_agent", "home.repos.pwc.inspect_result.astooke_rlpyt.runners.minibatch_rl.MinibatchRl.store_diagnostics", "home.repos.pwc.inspect_result.astooke_rlpyt.runners.minibatch_rl.MinibatchRlEval.log_diagnostics"], ["", "def", "train", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Performs startup, then loops by alternating between\n        ``sampler.obtain_samples()`` and ``algo.optimize_agent()``, logging\n        diagnostics at the specified interval.\n        \"\"\"", "\n", "n_itr", "=", "self", ".", "startup", "(", ")", "\n", "for", "itr", "in", "range", "(", "n_itr", ")", ":", "\n", "            ", "logger", ".", "set_iteration", "(", "itr", ")", "\n", "with", "logger", ".", "prefix", "(", "f\"itr #{itr} \"", ")", ":", "\n", "                ", "self", ".", "agent", ".", "sample_mode", "(", "itr", ")", "# Might not be this agent sampling.", "\n", "samples", ",", "traj_infos", "=", "self", ".", "sampler", ".", "obtain_samples", "(", "itr", ")", "\n", "self", ".", "agent", ".", "train_mode", "(", "itr", ")", "\n", "opt_info", "=", "self", ".", "algo", ".", "optimize_agent", "(", "itr", ",", "samples", ")", "\n", "self", ".", "store_diagnostics", "(", "itr", ",", "traj_infos", ",", "opt_info", ")", "\n", "if", "(", "itr", "+", "1", ")", "%", "self", ".", "log_interval_itrs", "==", "0", ":", "\n", "                    ", "self", ".", "log_diagnostics", "(", "itr", ")", "\n", "", "", "", "self", ".", "shutdown", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.runners.minibatch_rl.MinibatchRl.initialize_logging": [[265, 271], ["collections.deque", "rlpyt.utils.logging.logger.log", "minibatch_rl.MinibatchRlBase.initialize_logging", "rlpyt.utils.prog_bar.ProgBarCounter"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.logging.console.log", "home.repos.pwc.inspect_result.astooke_rlpyt.runners.minibatch_rl.MinibatchRlEval.initialize_logging"], ["", "def", "initialize_logging", "(", "self", ")", ":", "\n", "        ", "self", ".", "_traj_infos", "=", "deque", "(", "maxlen", "=", "self", ".", "log_traj_window", ")", "\n", "self", ".", "_new_completed_trajs", "=", "0", "\n", "logger", ".", "log", "(", "f\"Optimizing over {self.log_interval_itrs} iterations.\"", ")", "\n", "super", "(", ")", ".", "initialize_logging", "(", ")", "\n", "self", ".", "pbar", "=", "ProgBarCounter", "(", "self", ".", "log_interval_itrs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.runners.minibatch_rl.MinibatchRl.store_diagnostics": [[272, 276], ["len", "minibatch_rl.MinibatchRl._traj_infos.extend", "minibatch_rl.MinibatchRlBase.store_diagnostics"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.runners.minibatch_rl.MinibatchRl.store_diagnostics"], ["", "def", "store_diagnostics", "(", "self", ",", "itr", ",", "traj_infos", ",", "opt_info", ")", ":", "\n", "        ", "self", ".", "_new_completed_trajs", "+=", "len", "(", "traj_infos", ")", "\n", "self", ".", "_traj_infos", ".", "extend", "(", "traj_infos", ")", "\n", "super", "(", ")", ".", "store_diagnostics", "(", "itr", ",", "traj_infos", ",", "opt_info", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.runners.minibatch_rl.MinibatchRl.log_diagnostics": [[277, 284], ["minibatch_rl.MinibatchRlBase.log_diagnostics", "rlpyt.utils.logging.logger.tabular_prefix", "rlpyt.utils.logging.logger.record_tabular", "rlpyt.utils.logging.logger.record_tabular", "sum"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.runners.minibatch_rl.MinibatchRlEval.log_diagnostics", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.logger.tabular_prefix", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.logger.record_tabular", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.logger.record_tabular"], ["", "def", "log_diagnostics", "(", "self", ",", "itr", ",", "prefix", "=", "'Diagnostics/'", ")", ":", "\n", "        ", "with", "logger", ".", "tabular_prefix", "(", "prefix", ")", ":", "\n", "            ", "logger", ".", "record_tabular", "(", "'NewCompletedTrajs'", ",", "self", ".", "_new_completed_trajs", ")", "\n", "logger", ".", "record_tabular", "(", "'StepsInTrajWindow'", ",", "\n", "sum", "(", "info", "[", "\"Length\"", "]", "for", "info", "in", "self", ".", "_traj_infos", ")", ")", "\n", "", "super", "(", ")", ".", "log_diagnostics", "(", "itr", ",", "prefix", "=", "prefix", ")", "\n", "self", ".", "_new_completed_trajs", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.runners.minibatch_rl.MinibatchRlEval.train": [[294, 317], ["minibatch_rl.MinibatchRlEval.startup", "range", "minibatch_rl.MinibatchRlEval.shutdown", "rlpyt.utils.logging.logger.prefix", "minibatch_rl.MinibatchRlEval.evaluate_agent", "minibatch_rl.MinibatchRlEval.log_diagnostics", "rlpyt.utils.logging.logger.set_iteration", "rlpyt.utils.logging.logger.prefix", "minibatch_rl.MinibatchRlEval.agent.sample_mode", "minibatch_rl.MinibatchRlEval.sampler.obtain_samples", "minibatch_rl.MinibatchRlEval.agent.train_mode", "minibatch_rl.MinibatchRlEval.algo.optimize_agent", "minibatch_rl.MinibatchRlEval.store_diagnostics", "minibatch_rl.MinibatchRlEval.evaluate_agent", "minibatch_rl.MinibatchRlEval.log_diagnostics"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.runners.minibatch_rl.MinibatchRlBase.startup", "home.repos.pwc.inspect_result.astooke_rlpyt.runners.minibatch_rl.MinibatchRlBase.shutdown", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.logger.prefix", "home.repos.pwc.inspect_result.astooke_rlpyt.runners.minibatch_rl.MinibatchRlEval.evaluate_agent", "home.repos.pwc.inspect_result.astooke_rlpyt.runners.minibatch_rl.MinibatchRlEval.log_diagnostics", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.logger.set_iteration", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.logger.prefix", "home.repos.pwc.inspect_result.astooke_rlpyt.agents.dmc_sac_agent.SacAgent.sample_mode", "home.repos.pwc.inspect_result.astooke_rlpyt.async_.serial_sampler.AsyncSerialSampler.obtain_samples", "home.repos.pwc.inspect_result.astooke_rlpyt.agents.dmc_sac_agent.SacAgent.train_mode", "home.repos.pwc.inspect_result.astooke_rlpyt.safe.cppo_pid.CppoPID.optimize_agent", "home.repos.pwc.inspect_result.astooke_rlpyt.runners.minibatch_rl.MinibatchRl.store_diagnostics", "home.repos.pwc.inspect_result.astooke_rlpyt.runners.minibatch_rl.MinibatchRlEval.evaluate_agent", "home.repos.pwc.inspect_result.astooke_rlpyt.runners.minibatch_rl.MinibatchRlEval.log_diagnostics"], ["def", "train", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Performs startup, evaluates the initial agent, then loops by\n        alternating between ``sampler.obtain_samples()`` and\n        ``algo.optimize_agent()``.  Pauses to evaluate the agent at the\n        specified log interval.\n        \"\"\"", "\n", "n_itr", "=", "self", ".", "startup", "(", ")", "\n", "with", "logger", ".", "prefix", "(", "f\"itr #0 \"", ")", ":", "\n", "            ", "eval_traj_infos", ",", "eval_time", "=", "self", ".", "evaluate_agent", "(", "0", ")", "\n", "self", ".", "log_diagnostics", "(", "0", ",", "eval_traj_infos", ",", "eval_time", ")", "\n", "", "for", "itr", "in", "range", "(", "n_itr", ")", ":", "\n", "            ", "logger", ".", "set_iteration", "(", "itr", ")", "\n", "with", "logger", ".", "prefix", "(", "f\"itr #{itr} \"", ")", ":", "\n", "                ", "self", ".", "agent", ".", "sample_mode", "(", "itr", ")", "\n", "samples", ",", "traj_infos", "=", "self", ".", "sampler", ".", "obtain_samples", "(", "itr", ")", "\n", "self", ".", "agent", ".", "train_mode", "(", "itr", ")", "\n", "opt_info", "=", "self", ".", "algo", ".", "optimize_agent", "(", "itr", ",", "samples", ")", "\n", "self", ".", "store_diagnostics", "(", "itr", ",", "traj_infos", ",", "opt_info", ")", "\n", "if", "(", "itr", "+", "1", ")", "%", "self", ".", "log_interval_itrs", "==", "0", ":", "\n", "                    ", "eval_traj_infos", ",", "eval_time", "=", "self", ".", "evaluate_agent", "(", "itr", ")", "\n", "self", ".", "log_diagnostics", "(", "itr", ",", "eval_traj_infos", ",", "eval_time", ")", "\n", "", "", "", "self", ".", "shutdown", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.runners.minibatch_rl.MinibatchRlEval.evaluate_agent": [[318, 336], ["rlpyt.utils.logging.logger.log", "minibatch_rl.MinibatchRlEval.pbar.stop", "rlpyt.utils.logging.logger.log", "minibatch_rl.MinibatchRlEval.agent.eval_mode", "minibatch_rl.MinibatchRlEval.sampler.evaluate_agent", "time.time", "time.time"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.logging.console.log", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.prog_bar.ProgBarCounter.stop", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.console.log", "home.repos.pwc.inspect_result.astooke_rlpyt.agents.dmc_sac_agent.SacAgent.eval_mode", "home.repos.pwc.inspect_result.astooke_rlpyt.runners.minibatch_rl.MinibatchRlEval.evaluate_agent"], ["", "def", "evaluate_agent", "(", "self", ",", "itr", ")", ":", "\n", "        ", "\"\"\"\n        Record offline evaluation of agent performance, by ``sampler.evaluate_agent()``.\n        \"\"\"", "\n", "if", "itr", ">", "0", ":", "\n", "            ", "self", ".", "pbar", ".", "stop", "(", ")", "\n", "\n", "", "if", "itr", ">=", "self", ".", "min_itr_learn", "-", "1", "or", "itr", "==", "0", ":", "\n", "            ", "logger", ".", "log", "(", "\"Evaluating agent...\"", ")", "\n", "self", ".", "agent", ".", "eval_mode", "(", "itr", ")", "# Might be agent in sampler.", "\n", "eval_time", "=", "-", "time", ".", "time", "(", ")", "\n", "traj_infos", "=", "self", ".", "sampler", ".", "evaluate_agent", "(", "itr", ")", "\n", "eval_time", "+=", "time", ".", "time", "(", ")", "\n", "", "else", ":", "\n", "            ", "traj_infos", "=", "[", "]", "\n", "eval_time", "=", "0.0", "\n", "", "logger", ".", "log", "(", "\"Evaluation runs complete.\"", ")", "\n", "return", "traj_infos", ",", "eval_time", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.runners.minibatch_rl.MinibatchRlEval.initialize_logging": [[337, 340], ["minibatch_rl.MinibatchRlBase.initialize_logging"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.runners.minibatch_rl.MinibatchRlEval.initialize_logging"], ["", "def", "initialize_logging", "(", "self", ")", ":", "\n", "        ", "super", "(", ")", ".", "initialize_logging", "(", ")", "\n", "self", ".", "_cum_eval_time", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.runners.minibatch_rl.MinibatchRlEval.log_diagnostics": [[341, 351], ["sum", "minibatch_rl.MinibatchRlBase.log_diagnostics", "rlpyt.utils.logging.logger.log", "rlpyt.utils.logging.logger.tabular_prefix", "rlpyt.utils.logging.logger.record_tabular", "rlpyt.utils.logging.logger.record_tabular", "rlpyt.utils.logging.logger.record_tabular", "len"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.runners.minibatch_rl.MinibatchRlEval.log_diagnostics", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.console.log", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.logger.tabular_prefix", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.logger.record_tabular", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.logger.record_tabular", "home.repos.pwc.inspect_result.astooke_rlpyt.logging.logger.record_tabular"], ["", "def", "log_diagnostics", "(", "self", ",", "itr", ",", "eval_traj_infos", ",", "eval_time", ",", "prefix", "=", "'Diagnostics/'", ")", ":", "\n", "        ", "if", "not", "eval_traj_infos", ":", "\n", "            ", "logger", ".", "log", "(", "\"WARNING: had no complete trajectories in eval.\"", ")", "\n", "", "steps_in_eval", "=", "sum", "(", "[", "info", "[", "\"Length\"", "]", "for", "info", "in", "eval_traj_infos", "]", ")", "\n", "with", "logger", ".", "tabular_prefix", "(", "prefix", ")", ":", "\n", "            ", "logger", ".", "record_tabular", "(", "'StepsInEval'", ",", "steps_in_eval", ")", "\n", "logger", ".", "record_tabular", "(", "'TrajsInEval'", ",", "len", "(", "eval_traj_infos", ")", ")", "\n", "self", ".", "_cum_eval_time", "+=", "eval_time", "\n", "logger", ".", "record_tabular", "(", "'CumEvalTime'", ",", "self", ".", "_cum_eval_time", ")", "\n", "", "super", "(", ")", ".", "log_diagnostics", "(", "itr", ",", "eval_traj_infos", ",", "eval_time", ",", "prefix", "=", "prefix", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.astooke_rlpyt.safe.cppo_model.CppoModel.__init__": [[16, 74], ["super().__init__", "len", "int", "rlpyt.models.mlp.MlpModel", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Parameter", "numpy.prod", "torch.nn.LSTM", "torch.nn.Sequential", "torch.nn.Linear", "rlpyt.models.running_mean_std.RunningMeanStdModel", "ValueError", "ValueError", "mu_nonlinearity", "torch.ones"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.spaces.gym_wrapper.GymSpaceWrapper.__init__"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "observation_shape", ",", "\n", "action_size", ",", "\n", "hidden_sizes", "=", "None", ",", "\n", "lstm_size", "=", "None", ",", "\n", "lstm_skip", "=", "True", ",", "\n", "constraint", "=", "True", ",", "\n", "hidden_nonlinearity", "=", "\"tanh\"", ",", "# or \"relu\"", "\n", "mu_nonlinearity", "=", "\"tanh\"", ",", "\n", "init_log_std", "=", "0.", ",", "\n", "normalize_observation", "=", "True", ",", "\n", "var_clip", "=", "1e-6", ",", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "if", "hidden_nonlinearity", "==", "\"tanh\"", ":", "# So these can be strings in config file.", "\n", "            ", "hidden_nonlinearity", "=", "torch", ".", "nn", ".", "Tanh", "\n", "", "elif", "hidden_nonlinearity", "==", "\"relu\"", ":", "\n", "            ", "hidden_nonlinearity", "=", "torch", ".", "nn", ".", "ReLU", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "f\"Unrecognized hidden_nonlinearity string: {hidden_nonlinearity}\"", ")", "\n", "", "if", "mu_nonlinearity", "==", "\"tanh\"", ":", "# So these can be strings in config file.", "\n", "            ", "mu_nonlinearity", "=", "torch", ".", "nn", ".", "Tanh", "\n", "", "elif", "mu_nonlinearity", "==", "\"relu\"", ":", "\n", "            ", "mu_nonlinearity", "=", "torch", ".", "nn", ".", "ReLU", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "f\"Unrecognized mu_nonlinearity string: {mu_nonlinearity}\"", ")", "\n", "", "self", ".", "_obs_ndim", "=", "len", "(", "observation_shape", ")", "\n", "input_size", "=", "int", "(", "np", ".", "prod", "(", "observation_shape", ")", ")", "\n", "self", ".", "body", "=", "MlpModel", "(", "\n", "input_size", "=", "input_size", ",", "\n", "hidden_sizes", "=", "hidden_sizes", "or", "[", "256", ",", "256", "]", ",", "\n", "nonlinearity", "=", "hidden_nonlinearity", ",", "\n", ")", "\n", "last_size", "=", "self", ".", "body", ".", "output_size", "\n", "if", "lstm_size", ":", "\n", "            ", "lstm_input_size", "=", "last_size", "+", "action_size", "+", "1", "\n", "self", ".", "lstm", "=", "torch", ".", "nn", ".", "LSTM", "(", "lstm_input_size", ",", "lstm_size", ")", "\n", "last_size", "=", "lstm_size", "\n", "", "else", ":", "\n", "            ", "self", ".", "lstm", "=", "None", "\n", "", "mu_linear", "=", "torch", ".", "nn", ".", "Linear", "(", "last_size", ",", "action_size", ")", "\n", "if", "mu_nonlinearity", "is", "not", "None", ":", "\n", "            ", "self", ".", "mu", "=", "torch", ".", "nn", ".", "Sequential", "(", "mu_linear", ",", "mu_nonlinearity", "(", ")", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "mu", "=", "mu_linear", "\n", "", "self", ".", "value", "=", "torch", ".", "nn", ".", "Linear", "(", "last_size", ",", "1", ")", "\n", "if", "constraint", ":", "\n", "            ", "self", ".", "constraint", "=", "torch", ".", "nn", ".", "Linear", "(", "last_size", ",", "1", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "constraint", "=", "None", "\n", "", "self", ".", "log_std", "=", "torch", ".", "nn", ".", "Parameter", "(", "init_log_std", "*", "\n", "torch", ".", "ones", "(", "action_size", ")", ")", "\n", "self", ".", "_lstm_skip", "=", "lstm_skip", "\n", "if", "normalize_observation", ":", "\n", "            ", "self", ".", "obs_rms", "=", "RunningMeanStdModel", "(", "observation_shape", ")", "\n", "self", ".", "var_clip", "=", "var_clip", "\n", "", "self", ".", "normalize_observation", "=", "normalize_observation", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.safe.cppo_model.CppoModel.forward": [[75, 118], ["rlpyt.utils.tensor.infer_leading_dims", "cppo_model.CppoModel.body", "cppo_model.CppoModel.mu", "cppo_model.CppoModel.log_std.repeat", "cppo_model.CppoModel.value().squeeze", "rlpyt.utils.tensor.restore_leading_dims", "torch.clamp", "torch.clamp.view", "torch.cat", "cppo_model.CppoModel.lstm", "lstm_out.view.view.view", "ValueInfo", "cppo_model.CppoModel.constraint().squeeze", "rlpyt.utils.tensor.restore_leading_dims", "ValueInfo", "torch.clamp", "tuple", "cppo_model.CppoModel.value", "RnnState", "torch.clamp.sqrt", "x.view", "cppo_model.CppoModel.constraint"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.utils.tensor.infer_leading_dims", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.tensor.restore_leading_dims", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.tensor.restore_leading_dims", "home.repos.pwc.inspect_result.astooke_rlpyt.safe.cppo_agent.CppoLstmAgent.value"], ["", "def", "forward", "(", "self", ",", "observation", ",", "prev_action", ",", "prev_reward", ",", "init_rnn_state", "=", "None", ")", ":", "\n", "        ", "lead_dim", ",", "T", ",", "B", ",", "_", "=", "infer_leading_dims", "(", "observation", ",", "self", ".", "_obs_ndim", ")", "\n", "if", "self", ".", "normalize_observation", ":", "\n", "            ", "obs_var", "=", "self", ".", "obs_rms", ".", "var", "\n", "if", "self", ".", "var_clip", "is", "not", "None", ":", "\n", "                ", "obs_var", "=", "torch", ".", "clamp", "(", "obs_var", ",", "min", "=", "self", ".", "var_clip", ")", "\n", "", "observation", "=", "torch", ".", "clamp", "(", "(", "observation", "-", "self", ".", "obs_rms", ".", "mean", ")", "/", "\n", "obs_var", ".", "sqrt", "(", ")", ",", "-", "10", ",", "10", ")", "\n", "", "fc_x", "=", "self", ".", "body", "(", "observation", ".", "view", "(", "T", "*", "B", ",", "-", "1", ")", ")", "\n", "if", "self", ".", "lstm", "is", "not", "None", ":", "\n", "            ", "lstm_inputs", "=", "[", "fc_x", ",", "prev_action", ",", "prev_reward", "]", "\n", "lstm_input", "=", "torch", ".", "cat", "(", "[", "x", ".", "view", "(", "T", ",", "B", ",", "-", "1", ")", "for", "x", "in", "lstm_inputs", "]", ",", "\n", "dim", "=", "2", ")", "\n", "# lstm_input = torch.cat([", "\n", "#     fc_x.view(T, B, -1),", "\n", "#     prev_action.view(T, B, -1),", "\n", "#     prev_reward.view(T, B, -1),", "\n", "#     ], dim=2)", "\n", "init_rnn_state", "=", "None", "if", "init_rnn_state", "is", "None", "else", "tuple", "(", "init_rnn_state", ")", "\n", "lstm_out", ",", "(", "hn", ",", "cn", ")", "=", "self", ".", "lstm", "(", "lstm_input", ",", "init_rnn_state", ")", "\n", "lstm_out", "=", "lstm_out", ".", "view", "(", "T", "*", "B", ",", "-", "1", ")", "\n", "if", "self", ".", "_lstm_skip", ":", "\n", "                ", "fc_x", "=", "fc_x", "+", "lstm_out", "\n", "", "else", ":", "\n", "                ", "fc_x", "=", "lstm_out", "\n", "\n", "", "", "mu", "=", "self", ".", "mu", "(", "fc_x", ")", "\n", "log_std", "=", "self", ".", "log_std", ".", "repeat", "(", "T", "*", "B", ",", "1", ")", "\n", "v", "=", "self", ".", "value", "(", "fc_x", ")", ".", "squeeze", "(", "-", "1", ")", "\n", "mu", ",", "log_std", ",", "v", "=", "restore_leading_dims", "(", "(", "mu", ",", "log_std", ",", "v", ")", ",", "lead_dim", ",", "T", ",", "B", ")", "\n", "\n", "if", "self", ".", "constraint", "is", "None", ":", "\n", "            ", "value", "=", "ValueInfo", "(", "value", "=", "v", ",", "c_value", "=", "None", ")", "\n", "", "else", ":", "\n", "            ", "c", "=", "self", ".", "constraint", "(", "fc_x", ")", ".", "squeeze", "(", "-", "1", ")", "\n", "c", "=", "restore_leading_dims", "(", "c", ",", "lead_dim", ",", "T", ",", "B", ")", "\n", "value", "=", "ValueInfo", "(", "value", "=", "v", ",", "c_value", "=", "c", ")", "\n", "\n", "", "outputs", "=", "(", "mu", ",", "log_std", ",", "value", ")", "\n", "if", "self", ".", "lstm", "is", "not", "None", ":", "\n", "            ", "outputs", "+=", "(", "RnnState", "(", "h", "=", "hn", ",", "c", "=", "cn", ")", ",", ")", "\n", "\n", "", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.safe.cppo_model.CppoModel.update_obs_rms": [[119, 123], ["cppo_model.CppoModel.obs_rms.update"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.models.running_mean_std.RunningMeanStdModel.update"], ["", "def", "update_obs_rms", "(", "self", ",", "observation", ")", ":", "\n", "        ", "if", "not", "self", ".", "normalize_observation", ":", "\n", "            ", "return", "\n", "", "self", ".", "obs_rms", ".", "update", "(", "observation", ")", "", "", "", ""]], "home.repos.pwc.inspect_result.astooke_rlpyt.safe.cppo_pid.CppoPID.__init__": [[36, 102], ["rlpyt.utils.quick_args.save__init__args", "dict", "locals"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.utils.quick_args.save__init__args"], ["def", "__init__", "(", "\n", "self", ",", "\n", "discount", "=", "0.99", ",", "\n", "learning_rate", "=", "0.001", ",", "\n", "value_loss_coeff", "=", "1.", ",", "\n", "entropy_loss_coeff", "=", "0.", ",", "\n", "OptimCls", "=", "torch", ".", "optim", ".", "Adam", ",", "\n", "optim_kwargs", "=", "None", ",", "\n", "clip_grad_norm", "=", "1.", ",", "\n", "initial_optim_state_dict", "=", "None", ",", "\n", "gae_lambda", "=", "0.97", ",", "\n", "minibatches", "=", "1", ",", "\n", "epochs", "=", "8", ",", "\n", "ratio_clip", "=", "0.1", ",", "\n", "linear_lr_schedule", "=", "False", ",", "\n", "normalize_advantage", "=", "False", ",", "\n", "cost_discount", "=", "None", ",", "# if None, defaults to discount.", "\n", "cost_gae_lambda", "=", "None", ",", "\n", "cost_value_loss_coeff", "=", "None", ",", "\n", "ep_cost_ema_alpha", "=", "0", ",", "# 0 for hard update, 1 for no update.", "\n", "objective_penalized", "=", "True", ",", "# False for reward-only learning", "\n", "learn_c_value", "=", "True", ",", "# Also False for reward-only learning", "\n", "penalty_init", "=", "1.", ",", "\n", "cost_limit", "=", "25", ",", "\n", "cost_scale", "=", "1.", ",", "# divides; applied to raw cost and cost_limit", "\n", "normalize_cost_advantage", "=", "False", ",", "\n", "pid_Kp", "=", "0", ",", "\n", "pid_Ki", "=", "1", ",", "\n", "pid_Kd", "=", "0", ",", "\n", "pid_d_delay", "=", "10", ",", "\n", "pid_delta_p_ema_alpha", "=", "0.95", ",", "# 0 for hard update, 1 for no update", "\n", "pid_delta_d_ema_alpha", "=", "0.95", ",", "\n", "sum_norm", "=", "True", ",", "# L = (J_r - lam * J_c) / (1 + lam); lam <= 0", "\n", "diff_norm", "=", "False", ",", "# L = (1 - lam) * J_r - lam * J_c; 0 <= lam <= 1", "\n", "penalty_max", "=", "100", ",", "# only used if sum_norm=diff_norm=False", "\n", "step_cost_limit_steps", "=", "None", ",", "# Change the cost limit partway through", "\n", "step_cost_limit_value", "=", "None", ",", "# New value.", "\n", "use_beta_kl", "=", "False", ",", "\n", "use_beta_grad", "=", "False", ",", "\n", "record_beta_kl", "=", "False", ",", "\n", "record_beta_grad", "=", "False", ",", "\n", "beta_max", "=", "10", ",", "\n", "beta_ema_alpha", "=", "0.9", ",", "\n", "beta_kl_epochs", "=", "1", ",", "\n", "reward_scale", "=", "1", ",", "# multiplicative (unlike cost_scale)", "\n", "lagrange_quadratic_penalty", "=", "False", ",", "\n", "quadratic_penalty_coeff", "=", "1", ",", "\n", ")", ":", "\n", "        ", "assert", "learn_c_value", "or", "not", "objective_penalized", "\n", "assert", "(", "step_cost_limit_steps", "is", "None", ")", "==", "(", "step_cost_limit_value", "is", "None", ")", "\n", "assert", "not", "(", "sum_norm", "and", "diff_norm", ")", "\n", "assert", "not", "(", "use_beta_kl", "and", "use_beta_grad", ")", "\n", "cost_discount", "=", "discount", "if", "cost_discount", "is", "None", "else", "cost_discount", "\n", "cost_gae_lambda", "=", "(", "gae_lambda", "if", "cost_gae_lambda", "is", "None", "else", "\n", "cost_gae_lambda", ")", "\n", "cost_value_loss_coeff", "=", "(", "value_loss_coeff", "if", "cost_value_loss_coeff", "is", "\n", "None", "else", "cost_value_loss_coeff", ")", "\n", "if", "optim_kwargs", "is", "None", ":", "\n", "            ", "optim_kwargs", "=", "dict", "(", ")", "\n", "", "save__init__args", "(", "locals", "(", ")", ")", "\n", "self", ".", "cost_limit", "/=", "self", ".", "cost_scale", "\n", "if", "step_cost_limit_value", "is", "not", "None", ":", "\n", "            ", "self", ".", "step_cost_limit_value", "/=", "self", ".", "cost_scale", "\n", "", "self", ".", "_beta_kl", "=", "1.", "\n", "self", ".", "_beta_grad", "=", "1.", "\n", "self", ".", "beta_min", "=", "1.", "/", "self", ".", "beta_max", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.safe.cppo_pid.CppoPID.initialize": [[103, 131], ["super().initialize", "collections.deque", "cppo_pid.CppoPID.cost_ds.append", "torch.optim.lr_scheduler.LambdaLR", "int", "cppo_pid.CppoPID.OptimCls", "cppo_pid.CppoPID.OptimCls", "cppo_pid.CppoPID.agent.beta_r_model.parameters", "cppo_pid.CppoPID.agent.beta_c_model.parameters"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.safe.cppo_agent.CppoLstmAgent.initialize", "home.repos.pwc.inspect_result.astooke_rlpyt.rl.atari_rl_models.AtariDqnModel.parameters", "home.repos.pwc.inspect_result.astooke_rlpyt.rl.atari_rl_models.AtariDqnModel.parameters"], ["", "def", "initialize", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "initialize", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "self", ".", "_batch_size", "=", "self", ".", "batch_spec", ".", "size", "//", "self", ".", "minibatches", "# For logging.", "\n", "if", "self", ".", "linear_lr_schedule", ":", "\n", "            ", "self", ".", "lr_scheduler", "=", "torch", ".", "optim", ".", "lr_scheduler", ".", "LambdaLR", "(", "\n", "optimizer", "=", "self", ".", "optimizer", ",", "\n", "lr_lambda", "=", "lambda", "itr", ":", "(", "self", ".", "n_itr", "-", "itr", ")", "/", "self", ".", "n_itr", ")", "# Step once per itr.", "\n", "self", ".", "_ratio_clip", "=", "self", ".", "ratio_clip", "# Save base value.", "\n", "", "if", "self", ".", "step_cost_limit_steps", "is", "None", ":", "\n", "            ", "self", ".", "step_cost_limit_itr", "=", "None", "\n", "", "else", ":", "\n", "            ", "self", ".", "step_cost_limit_itr", "=", "int", "(", "self", ".", "step_cost_limit_steps", "//", "\n", "(", "self", ".", "batch_spec", ".", "size", "*", "self", ".", "world_size", ")", ")", "\n", "# print(\"\\n\\n step cost itr: \", self.step_cost_limit_itr, \"\\n\\n\")", "\n", "", "self", ".", "_ep_cost_ema", "=", "self", ".", "cost_limit", "# No derivative at start.", "\n", "self", ".", "_ddp", "=", "self", ".", "agent", ".", "_ddp", "\n", "self", ".", "pid_i", "=", "self", ".", "cost_penalty", "=", "self", ".", "penalty_init", "\n", "self", ".", "cost_ds", "=", "deque", "(", "maxlen", "=", "self", ".", "pid_d_delay", ")", "\n", "self", ".", "cost_ds", ".", "append", "(", "0", ")", "\n", "self", ".", "_delta_p", "=", "0", "\n", "self", ".", "_cost_d", "=", "0", "\n", "if", "self", ".", "use_beta_kl", "or", "self", ".", "record_beta_kl", ":", "\n", "            ", "self", ".", "beta_r_optimizer", "=", "self", ".", "OptimCls", "(", "\n", "self", ".", "agent", ".", "beta_r_model", ".", "parameters", "(", ")", ",", "\n", "lr", "=", "self", ".", "learning_rate", ",", "**", "self", ".", "optim_kwargs", ")", "\n", "self", ".", "beta_c_optimizer", "=", "self", ".", "OptimCls", "(", "\n", "self", ".", "agent", ".", "beta_c_model", ".", "parameters", "(", ")", ",", "\n", "lr", "=", "self", ".", "learning_rate", ",", "**", "self", ".", "optim_kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.safe.cppo_pid.CppoPID.optimize_agent": [[132, 250], ["rlpyt.agents.base.AgentInputs", "rlpyt.utils.buffer.buffer_to", "cppo_pid.CppoPID.process_returns", "LossInputs", "OptInfoCost", "OptInfoCost.costLimit.append", "float", "max", "max", "max", "cppo_pid.CppoPID.cost_ds.append", "OptInfoCost.pid_i.append", "OptInfoCost.pid_p.append", "OptInfoCost.pid_d.append", "OptInfoCost.pid_o.append", "OptInfoCost.costPenalty.append", "hasattr", "range", "max", "float", "min", "min", "cppo_pid.CppoPID.agent.update_obs_rms", "cppo_pid.CppoPID.compute_beta_kl", "min", "OptInfoCost.betaKlRaw.append", "OptInfoCost.betaKL.append", "OptInfoCost.betaKlR.append", "OptInfoCost.betaKlC.append", "cppo_pid.CppoPID.compute_beta_grad", "min", "OptInfoCost.betaGradRaw.append", "OptInfoCost.betaGrad.append", "rlpyt.utils.misc.iterate_mb_idxs", "cppo_pid.CppoPID.lr_scheduler.step", "min", "max", "max", "cppo_pid.CppoPID.optimizer.zero_grad", "cppo_pid.CppoPID.loss", "loss.backward", "torch.nn.utils.clip_grad_norm_", "cppo_pid.CppoPID.optimizer.step", "OptInfoCost.loss.append", "OptInfoCost.gradNorm.append", "OptInfoCost.entropy.append", "OptInfoCost.perplexity.append", "OptInfoCost.valueError.extend", "OptInfoCost.cvalueError.extend", "OptInfoCost.valueAbsError.extend", "OptInfoCost.cvalueAbsError.extend", "slice", "cppo_pid.CppoPID.agent.parameters", "loss.item", "entropy.item", "perplexity.item", "[].numpy", "[].numpy", "[].numpy", "[].numpy", "range", "len"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.utils.buffer.buffer_to", "home.repos.pwc.inspect_result.astooke_rlpyt.safe.cppo_pid.CppoPID.process_returns", "home.repos.pwc.inspect_result.astooke_rlpyt.safe.cppo_agent.CppoLstmAgent.update_obs_rms", "home.repos.pwc.inspect_result.astooke_rlpyt.safe.cppo_pid.CppoPID.compute_beta_kl", "home.repos.pwc.inspect_result.astooke_rlpyt.safe.cppo_pid.CppoPID.compute_beta_grad", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.misc.iterate_mb_idxs", "home.repos.pwc.inspect_result.astooke_rlpyt.safe.safety_gym_env.SafetyGymTrajInfo.step", "home.repos.pwc.inspect_result.astooke_rlpyt.safe.cppo_pid.CppoPID.loss", "home.repos.pwc.inspect_result.astooke_rlpyt.models.utils.ScaleGrad.backward", "home.repos.pwc.inspect_result.astooke_rlpyt.safe.safety_gym_env.SafetyGymTrajInfo.step", "home.repos.pwc.inspect_result.astooke_rlpyt.rl.atari_rl_models.AtariDqnModel.parameters"], ["", "", "def", "optimize_agent", "(", "self", ",", "itr", ",", "samples", ")", ":", "\n", "        ", "recurrent", "=", "self", ".", "agent", ".", "recurrent", "\n", "agent_inputs", "=", "AgentInputs", "(", "# Move inputs to device once, index there.", "\n", "observation", "=", "samples", ".", "env", ".", "observation", ",", "\n", "prev_action", "=", "samples", ".", "agent", ".", "prev_action", ",", "\n", "prev_reward", "=", "samples", ".", "env", ".", "prev_reward", ",", "\n", ")", "\n", "agent_inputs", "=", "buffer_to", "(", "agent_inputs", ",", "device", "=", "self", ".", "agent", ".", "device", ")", "\n", "# return_, advantage, valid = self.process_returns(samples)", "\n", "(", "return_", ",", "advantage", ",", "valid", ",", "c_return", ",", "c_advantage", ",", "\n", "ep_cost_avg", ")", "=", "self", ".", "process_returns", "(", "itr", ",", "samples", ")", "\n", "loss_inputs", "=", "LossInputs", "(", "# So can slice all.", "\n", "agent_inputs", "=", "agent_inputs", ",", "\n", "action", "=", "samples", ".", "agent", ".", "action", ",", "\n", "return_", "=", "return_", ",", "\n", "advantage", "=", "advantage", ",", "\n", "valid", "=", "valid", ",", "\n", "old_dist_info", "=", "samples", ".", "agent", ".", "agent_info", ".", "dist_info", ",", "\n", "c_return", "=", "c_return", ",", "# Can be None.", "\n", "c_advantage", "=", "c_advantage", ",", "\n", ")", "\n", "opt_info", "=", "OptInfoCost", "(", "*", "(", "[", "]", "for", "_", "in", "range", "(", "len", "(", "OptInfoCost", ".", "_fields", ")", ")", ")", ")", "\n", "\n", "if", "(", "self", ".", "step_cost_limit_itr", "is", "not", "None", "and", "\n", "self", ".", "step_cost_limit_itr", "==", "itr", ")", ":", "\n", "            ", "self", ".", "cost_limit", "=", "self", ".", "step_cost_limit_value", "\n", "", "opt_info", ".", "costLimit", ".", "append", "(", "self", ".", "cost_limit", ")", "\n", "\n", "# PID update here:", "\n", "delta", "=", "float", "(", "ep_cost_avg", "-", "self", ".", "cost_limit", ")", "# ep_cost_avg: tensor", "\n", "self", ".", "pid_i", "=", "max", "(", "0.", ",", "self", ".", "pid_i", "+", "delta", "*", "self", ".", "pid_Ki", ")", "\n", "if", "self", ".", "diff_norm", ":", "\n", "            ", "self", ".", "pid_i", "=", "max", "(", "0.", ",", "min", "(", "1.", ",", "self", ".", "pid_i", ")", ")", "\n", "", "a_p", "=", "self", ".", "pid_delta_p_ema_alpha", "\n", "self", ".", "_delta_p", "*=", "a_p", "\n", "self", ".", "_delta_p", "+=", "(", "1", "-", "a_p", ")", "*", "delta", "\n", "a_d", "=", "self", ".", "pid_delta_d_ema_alpha", "\n", "self", ".", "_cost_d", "*=", "a_d", "\n", "self", ".", "_cost_d", "+=", "(", "1", "-", "a_d", ")", "*", "float", "(", "ep_cost_avg", ")", "\n", "pid_d", "=", "max", "(", "0.", ",", "self", ".", "_cost_d", "-", "self", ".", "cost_ds", "[", "0", "]", ")", "\n", "pid_o", "=", "(", "self", ".", "pid_Kp", "*", "self", ".", "_delta_p", "+", "self", ".", "pid_i", "+", "\n", "self", ".", "pid_Kd", "*", "pid_d", ")", "\n", "self", ".", "cost_penalty", "=", "max", "(", "0.", ",", "pid_o", ")", "\n", "if", "self", ".", "diff_norm", ":", "\n", "            ", "self", ".", "cost_penalty", "=", "min", "(", "1.", ",", "self", ".", "cost_penalty", ")", "\n", "", "if", "not", "(", "self", ".", "diff_norm", "or", "self", ".", "sum_norm", ")", ":", "\n", "            ", "self", ".", "cost_penalty", "=", "min", "(", "self", ".", "cost_penalty", ",", "self", ".", "penalty_max", ")", "\n", "", "self", ".", "cost_ds", ".", "append", "(", "self", ".", "_cost_d", ")", "\n", "opt_info", ".", "pid_i", ".", "append", "(", "self", ".", "pid_i", ")", "\n", "opt_info", ".", "pid_p", ".", "append", "(", "self", ".", "_delta_p", ")", "\n", "opt_info", ".", "pid_d", ".", "append", "(", "pid_d", ")", "\n", "opt_info", ".", "pid_o", ".", "append", "(", "pid_o", ")", "\n", "\n", "opt_info", ".", "costPenalty", ".", "append", "(", "self", ".", "cost_penalty", ")", "\n", "\n", "if", "hasattr", "(", "self", ".", "agent", ",", "\"update_obs_rms\"", ")", ":", "\n", "            ", "self", ".", "agent", ".", "update_obs_rms", "(", "agent_inputs", ".", "observation", ")", "\n", "if", "itr", "==", "0", ":", "\n", "                ", "return", "opt_info", "# Sacrifice the first batch to get obs stats.", "\n", "\n", "", "", "if", "recurrent", ":", "\n", "# Leave in [B,N,H] for slicing to minibatches.", "\n", "            ", "init_rnn_state", "=", "samples", ".", "agent", ".", "agent_info", ".", "prev_rnn_state", "[", "0", "]", "# T=0.", "\n", "", "T", ",", "B", "=", "samples", ".", "env", ".", "reward", ".", "shape", "[", ":", "2", "]", "\n", "# If recurrent, use whole trajectories, only shuffle B; else shuffle all.", "\n", "batch_size", "=", "B", "if", "self", ".", "agent", ".", "recurrent", "else", "T", "*", "B", "\n", "mb_size", "=", "batch_size", "//", "self", ".", "minibatches", "\n", "\n", "if", "self", ".", "use_beta_kl", "or", "self", ".", "record_beta_kl", ":", "\n", "            ", "raw_beta_kl", ",", "beta_r_kl", ",", "beta_c_kl", "=", "self", ".", "compute_beta_kl", "(", "\n", "loss_inputs", ",", "init_rnn_state", ",", "batch_size", ",", "mb_size", ",", "T", ")", "\n", "beta_KL", "=", "min", "(", "self", ".", "beta_max", ",", "max", "(", "self", ".", "beta_min", ",", "raw_beta_kl", ")", ")", "\n", "self", ".", "_beta_kl", "*=", "self", ".", "beta_ema_alpha", "\n", "self", ".", "_beta_kl", "+=", "(", "1", "-", "self", ".", "beta_ema_alpha", ")", "*", "beta_KL", "\n", "opt_info", ".", "betaKlRaw", ".", "append", "(", "raw_beta_kl", ")", "\n", "opt_info", ".", "betaKL", ".", "append", "(", "self", ".", "_beta_kl", ")", "\n", "opt_info", ".", "betaKlR", ".", "append", "(", "beta_r_kl", ")", "\n", "opt_info", ".", "betaKlC", ".", "append", "(", "beta_c_kl", ")", "\n", "# print(\"raw_beta_kl: \", raw_beta_kl)", "\n", "# print(\"self._beta_kl: \", self._beta_kl, \"\\n\\n\")", "\n", "\n", "", "if", "self", ".", "use_beta_grad", "or", "self", ".", "record_beta_grad", ":", "\n", "            ", "raw_beta_grad", "=", "self", ".", "compute_beta_grad", "(", "loss_inputs", ",", "init_rnn_state", ")", "\n", "beta_grad", "=", "min", "(", "self", ".", "beta_max", ",", "max", "(", "self", ".", "beta_min", ",", "raw_beta_grad", ")", ")", "\n", "self", ".", "_beta_grad", "*=", "self", ".", "beta_ema_alpha", "\n", "self", ".", "_beta_grad", "+=", "(", "1", "-", "self", ".", "beta_ema_alpha", ")", "*", "beta_grad", "\n", "opt_info", ".", "betaGradRaw", ".", "append", "(", "raw_beta_grad", ")", "\n", "opt_info", ".", "betaGrad", ".", "append", "(", "self", ".", "_beta_grad", ")", "\n", "\n", "", "for", "_", "in", "range", "(", "self", ".", "epochs", ")", ":", "\n", "            ", "for", "idxs", "in", "iterate_mb_idxs", "(", "batch_size", ",", "mb_size", ",", "shuffle", "=", "True", ")", ":", "\n", "                ", "T_idxs", "=", "slice", "(", "None", ")", "if", "recurrent", "else", "idxs", "%", "T", "\n", "B_idxs", "=", "idxs", "if", "recurrent", "else", "idxs", "//", "T", "\n", "self", ".", "optimizer", ".", "zero_grad", "(", ")", "\n", "rnn_state", "=", "init_rnn_state", "[", "B_idxs", "]", "if", "recurrent", "else", "None", "\n", "# NOTE: if not recurrent, will lose leading T dim, should be OK.", "\n", "loss", ",", "entropy", ",", "perplexity", ",", "value_errors", ",", "abs_value_errors", "=", "self", ".", "loss", "(", "\n", "*", "loss_inputs", "[", "T_idxs", ",", "B_idxs", "]", ",", "rnn_state", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "grad_norm", "=", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "\n", "self", ".", "agent", ".", "parameters", "(", ")", ",", "self", ".", "clip_grad_norm", ")", "\n", "self", ".", "optimizer", ".", "step", "(", ")", "\n", "\n", "opt_info", ".", "loss", ".", "append", "(", "loss", ".", "item", "(", ")", ")", "\n", "opt_info", ".", "gradNorm", ".", "append", "(", "grad_norm", ")", "\n", "opt_info", ".", "entropy", ".", "append", "(", "entropy", ".", "item", "(", ")", ")", "\n", "opt_info", ".", "perplexity", ".", "append", "(", "perplexity", ".", "item", "(", ")", ")", "\n", "opt_info", ".", "valueError", ".", "extend", "(", "value_errors", "[", "0", "]", "[", ":", ":", "10", "]", ".", "numpy", "(", ")", ")", "\n", "opt_info", ".", "cvalueError", ".", "extend", "(", "value_errors", "[", "1", "]", "[", ":", ":", "10", "]", ".", "numpy", "(", ")", ")", "\n", "opt_info", ".", "valueAbsError", ".", "extend", "(", "abs_value_errors", "[", "0", "]", "[", ":", ":", "10", "]", ".", "numpy", "(", ")", ")", "\n", "opt_info", ".", "cvalueAbsError", ".", "extend", "(", "abs_value_errors", "[", "1", "]", "[", ":", ":", "10", "]", ".", "numpy", "(", ")", ")", "\n", "\n", "self", ".", "update_counter", "+=", "1", "\n", "", "", "if", "self", ".", "linear_lr_schedule", ":", "\n", "            ", "self", ".", "lr_scheduler", ".", "step", "(", ")", "\n", "self", ".", "ratio_clip", "=", "self", ".", "_ratio_clip", "*", "(", "self", ".", "n_itr", "-", "itr", ")", "/", "self", ".", "n_itr", "\n", "\n", "", "return", "opt_info", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.safe.cppo_pid.CppoPID.loss": [[251, 328], ["dist.likelihood_ratio", "torch.clamp", "torch.min", "dist.mean_entropy", "tuple", "dist.mean_perplexity", "rlpyt.utils.buffer.buffer_method", "rlpyt.utils.buffer.buffer_method", "cppo_pid.CppoPID.agent", "cppo_pid.CppoPID.agent", "rlpyt.utils.tensor.valid_mean", "rlpyt.utils.tensor.valid_mean", "torch.max", "value_error.detach", "c_value_error.detach", "tuple", "tuple", "rlpyt.utils.tensor.valid_mean", "rlpyt.utils.tensor.valid_mean", "abs", "torch.max", "v.view", "rlpyt.utils.tensor.valid_mean", "torch.tensor"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.distributions.gaussian.Gaussian.likelihood_ratio", "home.repos.pwc.inspect_result.astooke_rlpyt.distributions.gaussian.Gaussian.mean_entropy", "home.repos.pwc.inspect_result.astooke_rlpyt.distributions.gaussian.Gaussian.mean_perplexity", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.buffer.buffer_method", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.buffer.buffer_method", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.tensor.valid_mean", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.tensor.valid_mean", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.tensor.valid_mean", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.tensor.valid_mean", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.tensor.valid_mean"], ["", "def", "loss", "(", "self", ",", "agent_inputs", ",", "action", ",", "return_", ",", "advantage", ",", "valid", ",", "old_dist_info", ",", "\n", "c_return", ",", "c_advantage", ",", "init_rnn_state", "=", "None", ")", ":", "\n", "        ", "if", "init_rnn_state", "is", "not", "None", ":", "\n", "# [B,N,H] --> [N,B,H] (for cudnn).", "\n", "            ", "init_rnn_state", "=", "buffer_method", "(", "init_rnn_state", ",", "\"transpose\"", ",", "0", ",", "1", ")", "\n", "init_rnn_state", "=", "buffer_method", "(", "init_rnn_state", ",", "\"contiguous\"", ")", "\n", "dist_info", ",", "value", ",", "_rnn_state", "=", "self", ".", "agent", "(", "*", "agent_inputs", ",", "init_rnn_state", ")", "\n", "", "else", ":", "\n", "            ", "dist_info", ",", "value", "=", "self", ".", "agent", "(", "*", "agent_inputs", ")", "\n", "", "dist", "=", "self", ".", "agent", ".", "distribution", "\n", "\n", "ratio", "=", "dist", ".", "likelihood_ratio", "(", "action", ",", "old_dist_info", "=", "old_dist_info", ",", "\n", "new_dist_info", "=", "dist_info", ")", "\n", "surr_1", "=", "ratio", "*", "advantage", "\n", "clipped_ratio", "=", "torch", ".", "clamp", "(", "ratio", ",", "1.", "-", "self", ".", "ratio_clip", ",", "\n", "1.", "+", "self", ".", "ratio_clip", ")", "\n", "surr_2", "=", "clipped_ratio", "*", "advantage", "\n", "surrogate", "=", "torch", ".", "min", "(", "surr_1", ",", "surr_2", ")", "\n", "pi_loss", "=", "-", "valid_mean", "(", "surrogate", ",", "valid", ")", "\n", "\n", "if", "self", ".", "reward_scale", "==", "1.", ":", "\n", "            ", "value_error", "=", "value", ".", "value", "-", "return_", "\n", "", "else", ":", "\n", "            ", "value_error", "=", "value", ".", "value", "-", "(", "return_", "/", "self", ".", "reward_scale", ")", "# Undo the scaling", "\n", "", "value_se", "=", "0.5", "*", "value_error", "**", "2", "\n", "value_loss", "=", "self", ".", "value_loss_coeff", "*", "valid_mean", "(", "value_se", ",", "valid", ")", "\n", "# Hmm, but with reward scaling, now the value gradient will be relatively smaller", "\n", "# than the pi gradient, unless we also change the value_loss_coeff??  Eh, leave it.", "\n", "\n", "entropy", "=", "dist", ".", "mean_entropy", "(", "dist_info", ",", "valid", ")", "\n", "entropy_loss", "=", "-", "self", ".", "entropy_loss_coeff", "*", "entropy", "\n", "\n", "if", "self", ".", "objective_penalized", ":", "\n", "# This, or just add c_advantage into advantage?", "\n", "            ", "c_surr_1", "=", "ratio", "*", "c_advantage", "\n", "c_surr_2", "=", "clipped_ratio", "*", "c_advantage", "\n", "c_surrogate", "=", "torch", ".", "max", "(", "c_surr_1", ",", "c_surr_2", ")", "\n", "c_loss", "=", "self", ".", "cost_penalty", "*", "valid_mean", "(", "c_surrogate", ",", "valid", ")", "\n", "if", "self", ".", "use_beta_kl", ":", "\n", "                ", "c_loss", "*=", "self", ".", "_beta_kl", "\n", "", "elif", "self", ".", "use_beta_grad", ":", "\n", "                ", "c_loss", "*=", "self", ".", "_beta_grad", "\n", "", "if", "self", ".", "diff_norm", ":", "# (1 - lam) * R + lam * C", "\n", "                ", "pi_loss", "*=", "(", "1", "-", "self", ".", "cost_penalty", ")", "\n", "pi_loss", "+=", "c_loss", "\n", "", "elif", "self", ".", "sum_norm", ":", "# 1 / (1 + lam) * (R + lam * C)", "\n", "                ", "pi_loss", "+=", "c_loss", "\n", "pi_loss", "/=", "(", "1", "+", "self", ".", "cost_penalty", ")", "\n", "", "else", ":", "\n", "                ", "pi_loss", "+=", "c_loss", "\n", "\n", "", "if", "self", ".", "lagrange_quadratic_penalty", ":", "\n", "                ", "quad_loss", "=", "(", "self", ".", "quadratic_penalty_coeff", "\n", "*", "valid_mean", "(", "c_surrogate", ",", "valid", ")", "\n", "*", "torch", ".", "max", "(", "torch", ".", "tensor", "(", "0.", ")", ",", "self", ".", "_ep_cost_ema", "-", "self", ".", "cost_limit", ")", ")", "\n", "pi_loss", "+=", "quad_loss", "\n", "\n", "", "", "loss", "=", "pi_loss", "+", "value_loss", "+", "entropy_loss", "\n", "\n", "if", "self", ".", "learn_c_value", ":", "# Then separate cost value estimate.", "\n", "            ", "assert", "value", ".", "c_value", "is", "not", "None", "\n", "assert", "c_return", "is", "not", "None", "\n", "c_value_error", "=", "value", ".", "c_value", "-", "c_return", "\n", "c_value_se", "=", "0.5", "*", "c_value_error", "**", "2", "\n", "c_value_loss", "=", "self", ".", "cost_value_loss_coeff", "*", "valid_mean", "(", "\n", "c_value_se", ",", "valid", ")", "\n", "loss", "+=", "c_value_loss", "\n", "\n", "", "value_errors", "=", "(", "value_error", ".", "detach", "(", ")", ",", "c_value_error", ".", "detach", "(", ")", ")", "\n", "if", "valid", "is", "not", "None", ":", "\n", "            ", "valid_mask", "=", "valid", ">", "0", "\n", "value_errors", "=", "tuple", "(", "v", "[", "valid_mask", "]", "for", "v", "in", "value_errors", ")", "\n", "", "else", ":", "\n", "            ", "value_errors", "=", "tuple", "(", "v", ".", "view", "(", "-", "1", ")", "for", "v", "in", "value_errors", ")", "\n", "", "abs_value_errors", "=", "tuple", "(", "abs", "(", "v", ")", "for", "v", "in", "value_errors", ")", "\n", "perplexity", "=", "dist", ".", "mean_perplexity", "(", "dist_info", ",", "valid", ")", "\n", "return", "loss", ",", "entropy", ",", "perplexity", ",", "value_errors", ",", "abs_value_errors", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.safe.cppo_pid.CppoPID.process_returns": [[329, 425], ["done.type.type.type", "rlpyt.algos.utils.discount_return", "rlpyt.algos.utils.generalized_advantage_estimation", "rlpyt.algos.utils.valid_from_done", "torch.distributed.get_world_size", "ep_costs.numel", "ep_costs.mean", "rlpyt.algos.utils.discount_return", "rlpyt.algos.utils.generalized_advantage_estimation", "ep_cost_mask.type", "ep_cost_avg.to.to.to", "torch.distributed.all_reduce", "eca.to.to.to", "advantage[].mean", "advantage[].std", "advantage.mean", "advantage.std", "torch.stack", "mean_std.to.to.to", "torch.distributed.all_reduce", "mean_std.to.to.to", "max", "c_advantage[].mean", "c_advantage[].std", "c_advantage.mean", "c_advantage.std", "torch.stack", "mean_std.to.to.to", "torch.distributed.all_reduce", "mean_std.to.to.to", "max", "torch.cat", "torch.ones_like"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.algos.utils.discount_return", "home.repos.pwc.inspect_result.astooke_rlpyt.algos.utils.generalized_advantage_estimation", "home.repos.pwc.inspect_result.astooke_rlpyt.algos.utils.valid_from_done", "home.repos.pwc.inspect_result.astooke_rlpyt.algos.utils.discount_return", "home.repos.pwc.inspect_result.astooke_rlpyt.algos.utils.generalized_advantage_estimation"], ["", "def", "process_returns", "(", "self", ",", "itr", ",", "samples", ")", ":", "\n", "        ", "reward", ",", "cost", "=", "samples", ".", "env", ".", "reward", ",", "samples", ".", "env", ".", "env_info", ".", "cost", "\n", "cost", "/=", "self", ".", "cost_scale", "\n", "done", "=", "samples", ".", "env", ".", "done", "\n", "value", ",", "c_value", "=", "samples", ".", "agent", ".", "agent_info", ".", "value", "# A named 2-tuple.", "\n", "bv", ",", "c_bv", "=", "samples", ".", "agent", ".", "bootstrap_value", "# A named 2-tuple.", "\n", "\n", "if", "self", ".", "reward_scale", "!=", "1", ":", "\n", "            ", "reward", "*=", "self", ".", "reward_scale", "\n", "value", "*=", "self", ".", "reward_scale", "# Keep the value learning the same.", "\n", "bv", "*=", "self", ".", "reward_scale", "\n", "\n", "", "done", "=", "done", ".", "type", "(", "reward", ".", "dtype", ")", "# rlpyt does this in discount_returns?", "\n", "\n", "if", "c_value", "is", "not", "None", ":", "# Learning c_value, even if reward penalized.", "\n", "            ", "if", "self", ".", "cost_gae_lambda", "==", "1", ":", "# GAE reduces to empirical discount.", "\n", "                ", "c_return", "=", "discount_return", "(", "cost", ",", "done", ",", "c_bv", ",", "\n", "self", ".", "cost_discount", ")", "\n", "c_advantage", "=", "c_return", "-", "c_value", "\n", "", "else", ":", "\n", "                ", "c_advantage", ",", "c_return", "=", "generalized_advantage_estimation", "(", "\n", "cost", ",", "c_value", ",", "done", ",", "c_bv", ",", "self", ".", "cost_discount", ",", "\n", "self", ".", "cost_gae_lambda", ")", "\n", "", "", "else", ":", "\n", "            ", "c_advantage", "=", "c_return", "=", "None", "\n", "\n", "", "if", "self", ".", "gae_lambda", "==", "1", ":", "# GAE reduces to empirical discounted.", "\n", "            ", "return_", "=", "discount_return", "(", "reward", ",", "done", ",", "bv", ",", "self", ".", "discount", ")", "\n", "advantage", "=", "return_", "-", "value", "\n", "", "else", ":", "\n", "            ", "advantage", ",", "return_", "=", "generalized_advantage_estimation", "(", "\n", "reward", ",", "value", ",", "done", ",", "bv", ",", "self", ".", "discount", ",", "self", ".", "gae_lambda", ")", "\n", "\n", "", "if", "not", "self", ".", "mid_batch_reset", "or", "self", ".", "agent", ".", "recurrent", ":", "\n", "            ", "valid", "=", "valid_from_done", "(", "done", ")", "# Recurrent: no reset during training.", "\n", "# \"done\" might stay True until env resets next batch.", "\n", "# Could probably do this formula directly on (1 - done) and use it", "\n", "# regardless of mid_batch_reset.", "\n", "ep_cost_mask", "=", "valid", "*", "(", "1", "-", "torch", ".", "cat", "(", "[", "valid", "[", "1", ":", "]", ",", "\n", "torch", ".", "ones_like", "(", "valid", "[", "-", "1", ":", "]", ")", "]", ")", ")", "# Find where valid turns OFF.", "\n", "", "else", ":", "\n", "            ", "valid", "=", "None", "# OR: torch.ones_like(done)", "\n", "ep_cost_mask", "=", "done", "# Everywhere a done, is episode final cost.", "\n", "", "ep_costs", "=", "samples", ".", "env", ".", "env_info", ".", "cum_cost", "[", "ep_cost_mask", ".", "type", "(", "torch", ".", "bool", ")", "]", "\n", "\n", "if", "self", ".", "_ddp", ":", "\n", "            ", "world_size", "=", "torch", ".", "distributed", ".", "get_world_size", "(", ")", "# already have self.world_size", "\n", "", "if", "ep_costs", ".", "numel", "(", ")", ">", "0", ":", "# Might not have any completed trajectories.", "\n", "            ", "ep_cost_avg", "=", "ep_costs", ".", "mean", "(", ")", "\n", "ep_cost_avg", "/=", "self", ".", "cost_scale", "\n", "if", "self", ".", "_ddp", ":", "\n", "                ", "eca", "=", "ep_cost_avg", ".", "to", "(", "self", ".", "agent", ".", "device", ")", "\n", "torch", ".", "distributed", ".", "all_reduce", "(", "eca", ")", "\n", "ep_cost_avg", "=", "eca", ".", "to", "(", "\"cpu\"", ")", "\n", "ep_cost_avg", "/=", "world_size", "\n", "", "a", "=", "self", ".", "ep_cost_ema_alpha", "\n", "self", ".", "_ep_cost_ema", "*=", "a", "\n", "self", ".", "_ep_cost_ema", "+=", "(", "1", "-", "a", ")", "*", "ep_cost_avg", "\n", "\n", "", "if", "self", ".", "normalize_advantage", ":", "\n", "            ", "if", "valid", "is", "not", "None", ":", "\n", "                ", "valid_mask", "=", "valid", ">", "0", "\n", "adv_mean", "=", "advantage", "[", "valid_mask", "]", ".", "mean", "(", ")", "\n", "adv_std", "=", "advantage", "[", "valid_mask", "]", ".", "std", "(", ")", "\n", "", "else", ":", "\n", "                ", "adv_mean", "=", "advantage", ".", "mean", "(", ")", "\n", "adv_std", "=", "advantage", ".", "std", "(", ")", "\n", "", "if", "self", ".", "_ddp", ":", "\n", "                ", "mean_std", "=", "torch", ".", "stack", "(", "[", "adv_mean", ",", "adv_std", "]", ")", "\n", "mean_std", "=", "mean_std", ".", "to", "(", "self", ".", "agent", ".", "device", ")", "\n", "torch", ".", "distributed", ".", "all_reduce", "(", "mean_std", ")", "\n", "mean_std", "=", "mean_std", ".", "to", "(", "\"cpu\"", ")", "\n", "mean_std", "/=", "world_size", "\n", "adv_mean", ",", "adv_std", "=", "mean_std", "[", "0", "]", ",", "mean_std", "[", "1", "]", "\n", "", "advantage", "[", ":", "]", "=", "(", "advantage", "-", "adv_mean", ")", "/", "max", "(", "adv_std", ",", "1e-6", ")", "\n", "\n", "# Pretty sure not supposed to normalized c_advantage.", "\n", "", "if", "self", ".", "normalize_cost_advantage", ":", "\n", "            ", "if", "valid", "is", "not", "None", ":", "\n", "                ", "valid_mask", "=", "valid", ">", "0", "\n", "cadv_mean", "=", "c_advantage", "[", "valid_mask", "]", ".", "mean", "(", ")", "\n", "cadv_std", "=", "c_advantage", "[", "valid_mask", "]", ".", "std", "(", ")", "\n", "", "else", ":", "\n", "                ", "cadv_mean", "=", "c_advantage", ".", "mean", "(", ")", "\n", "cadv_std", "=", "c_advantage", ".", "std", "(", ")", "\n", "", "if", "self", ".", "_ddp", ":", "\n", "                ", "mean_std", "=", "torch", ".", "stack", "(", "[", "cadv_mean", ",", "cadv_std", "]", ")", "\n", "mean_std", "=", "mean_std", ".", "to", "(", "self", ".", "agent", ".", "device", ")", "\n", "torch", ".", "distributed", ".", "all_reduce", "(", "mean_std", ")", "\n", "mean_std", "=", "mean_std", ".", "to", "(", "\"cpu\"", ")", "\n", "mean_std", "/=", "world_size", "\n", "cadv_mean", ",", "cadv_std", "=", "mean_std", "[", "0", "]", ",", "mean_std", "[", "1", "]", "\n", "", "c_advantage", "[", ":", "]", "=", "(", "c_advantage", "-", "cadv_mean", ")", "/", "max", "(", "cadv_std", ",", "1e-6", ")", "\n", "\n", "", "return", "(", "return_", ",", "advantage", ",", "valid", ",", "c_return", ",", "c_advantage", ",", "\n", "self", ".", "_ep_cost_ema", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.safe.cppo_pid.CppoPID.compute_beta_kl": [[426, 488], ["cppo_pid.CppoPID.agent.beta_r_model.load_state_dict", "cppo_pid.CppoPID.agent.beta_c_model.load_state_dict", "cppo_pid.CppoPID.beta_r_optimizer.load_state_dict", "cppo_pid.CppoPID.beta_c_optimizer.load_state_dict", "range", "dist.mean_kl", "dist.mean_kl", "float", "rlpyt.models.utils.strip_ddp_state_dict", "rlpyt.models.utils.strip_ddp_state_dict", "cppo_pid.CppoPID.optimizer.state_dict", "cppo_pid.CppoPID.optimizer.state_dict", "rlpyt.utils.misc.iterate_mb_idxs", "rlpyt.utils.buffer.buffer_method", "rlpyt.utils.buffer.buffer_method", "torch.stack", "beta_KLs.to.to.to", "torch.distributed.all_reduce", "beta_KLs.to.to.to", "torch.distributed.get_world_size", "float", "float", "cppo_pid.CppoPID.agent.model.state_dict", "cppo_pid.CppoPID.agent.model.state_dict", "cppo_pid.CppoPID.beta_r_optimizer.zero_grad", "cppo_pid.CppoPID.beta_c_optimizer.zero_grad", "cppo_pid.CppoPID.beta_kl_losses", "beta_r_loss.backward", "torch.nn.utils.clip_grad_norm_", "cppo_pid.CppoPID.beta_r_optimizer.step", "beta_c_loss.backward", "torch.nn.utils.clip_grad_norm_", "cppo_pid.CppoPID.beta_c_optimizer.step", "torch.no_grad", "cppo_pid.CppoPID.agent.beta_dist_infos", "torch.no_grad", "cppo_pid.CppoPID.agent.beta_dist_infos", "max", "slice", "cppo_pid.CppoPID.agent.beta_r_model.parameters", "cppo_pid.CppoPID.agent.beta_c_model.parameters"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.augmented_temporal_similarity.AugmentedTemporalSimilarity.load_state_dict", "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.augmented_temporal_similarity.AugmentedTemporalSimilarity.load_state_dict", "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.augmented_temporal_similarity.AugmentedTemporalSimilarity.load_state_dict", "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.augmented_temporal_similarity.AugmentedTemporalSimilarity.load_state_dict", "home.repos.pwc.inspect_result.astooke_rlpyt.distributions.gaussian.Gaussian.mean_kl", "home.repos.pwc.inspect_result.astooke_rlpyt.distributions.gaussian.Gaussian.mean_kl", "home.repos.pwc.inspect_result.astooke_rlpyt.models.utils.strip_ddp_state_dict", "home.repos.pwc.inspect_result.astooke_rlpyt.models.utils.strip_ddp_state_dict", "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.replay_saver.DummyOptimizer.state_dict", "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.replay_saver.DummyOptimizer.state_dict", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.misc.iterate_mb_idxs", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.buffer.buffer_method", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.buffer.buffer_method", "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.replay_saver.DummyOptimizer.state_dict", "home.repos.pwc.inspect_result.astooke_rlpyt.ul_for_rl.replay_saver.DummyOptimizer.state_dict", "home.repos.pwc.inspect_result.astooke_rlpyt.safe.cppo_pid.CppoPID.beta_kl_losses", "home.repos.pwc.inspect_result.astooke_rlpyt.models.utils.ScaleGrad.backward", "home.repos.pwc.inspect_result.astooke_rlpyt.safe.safety_gym_env.SafetyGymTrajInfo.step", "home.repos.pwc.inspect_result.astooke_rlpyt.models.utils.ScaleGrad.backward", "home.repos.pwc.inspect_result.astooke_rlpyt.safe.safety_gym_env.SafetyGymTrajInfo.step", "home.repos.pwc.inspect_result.astooke_rlpyt.safe.cppo_agent.CppoLstmAgent.beta_dist_infos", "home.repos.pwc.inspect_result.astooke_rlpyt.safe.cppo_agent.CppoLstmAgent.beta_dist_infos", "home.repos.pwc.inspect_result.astooke_rlpyt.rl.atari_rl_models.AtariDqnModel.parameters", "home.repos.pwc.inspect_result.astooke_rlpyt.rl.atari_rl_models.AtariDqnModel.parameters"], ["", "def", "compute_beta_kl", "(", "self", ",", "loss_inputs", ",", "init_rnn_state", ",", "\n", "batch_size", ",", "mb_size", ",", "T", ")", ":", "\n", "        ", "\"\"\"Ratio of KL divergences from reward-only vs cost-only updates.\"\"\"", "\n", "self", ".", "agent", ".", "beta_r_model", ".", "load_state_dict", "(", "strip_ddp_state_dict", "(", "\n", "self", ".", "agent", ".", "model", ".", "state_dict", "(", ")", ")", ")", "\n", "self", ".", "agent", ".", "beta_c_model", ".", "load_state_dict", "(", "strip_ddp_state_dict", "(", "\n", "self", ".", "agent", ".", "model", ".", "state_dict", "(", ")", ")", ")", "\n", "self", ".", "beta_r_optimizer", ".", "load_state_dict", "(", "self", ".", "optimizer", ".", "state_dict", "(", ")", ")", "\n", "self", ".", "beta_c_optimizer", ".", "load_state_dict", "(", "self", ".", "optimizer", ".", "state_dict", "(", ")", ")", "\n", "\n", "recurrent", "=", "self", ".", "agent", ".", "recurrent", "\n", "for", "_", "in", "range", "(", "self", ".", "beta_kl_epochs", ")", ":", "\n", "            ", "for", "idxs", "in", "iterate_mb_idxs", "(", "batch_size", ",", "mb_size", ",", "\n", "shuffle", "=", "batch_size", ">", "mb_size", ")", ":", "\n", "                ", "T_idxs", "=", "slice", "(", "None", ")", "if", "recurrent", "else", "idxs", "%", "T", "\n", "B_idxs", "=", "idxs", "if", "recurrent", "else", "idxs", "//", "T", "\n", "rnn_state", "=", "init_rnn_state", "[", "B_idxs", "]", "if", "recurrent", "else", "None", "\n", "self", ".", "beta_r_optimizer", ".", "zero_grad", "(", ")", "\n", "self", ".", "beta_c_optimizer", ".", "zero_grad", "(", ")", "\n", "\n", "beta_r_loss", ",", "beta_c_loss", "=", "self", ".", "beta_kl_losses", "(", "\n", "*", "loss_inputs", "[", "T_idxs", ",", "B_idxs", "]", ",", "rnn_state", ")", "\n", "\n", "beta_r_loss", ".", "backward", "(", ")", "\n", "_", "=", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "\n", "self", ".", "agent", ".", "beta_r_model", ".", "parameters", "(", ")", ",", "self", ".", "clip_grad_norm", ")", "\n", "self", ".", "beta_r_optimizer", ".", "step", "(", ")", "\n", "\n", "beta_c_loss", ".", "backward", "(", ")", "\n", "_", "=", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "\n", "self", ".", "agent", ".", "beta_c_model", ".", "parameters", "(", ")", ",", "self", ".", "clip_grad_norm", ")", "\n", "self", ".", "beta_c_optimizer", ".", "step", "(", ")", "\n", "\n", "", "", "if", "init_rnn_state", "is", "not", "None", ":", "\n", "# [B,N,H] --> [N,B,H] (for cudnn).", "\n", "            ", "init_rnn_state", "=", "buffer_method", "(", "init_rnn_state", ",", "\"transpose\"", ",", "0", ",", "1", ")", "\n", "init_rnn_state", "=", "buffer_method", "(", "init_rnn_state", ",", "\"contiguous\"", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "r_dist_info", ",", "c_dist_info", "=", "self", ".", "agent", ".", "beta_dist_infos", "(", "\n", "*", "loss_inputs", ".", "agent_inputs", ",", "init_rnn_state", ")", "\n", "", "", "else", ":", "\n", "            ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "r_dist_info", ",", "c_dist_info", "=", "self", ".", "agent", ".", "beta_dist_infos", "(", "\n", "*", "loss_inputs", ".", "agent_inputs", ",", "init_rnn_state", ")", "\n", "\n", "", "", "dist", "=", "self", ".", "agent", ".", "distribution", "\n", "beta_r_KL", "=", "dist", ".", "mean_kl", "(", "new_dist_info", "=", "r_dist_info", ",", "\n", "old_dist_info", "=", "loss_inputs", ".", "old_dist_info", ",", "valid", "=", "loss_inputs", ".", "valid", ")", "\n", "beta_c_KL", "=", "dist", ".", "mean_kl", "(", "new_dist_info", "=", "c_dist_info", ",", "\n", "old_dist_info", "=", "loss_inputs", ".", "old_dist_info", ",", "valid", "=", "loss_inputs", ".", "valid", ")", "\n", "\n", "if", "self", ".", "_ddp", ":", "\n", "            ", "beta_KLs", "=", "torch", ".", "stack", "(", "[", "beta_r_KL", ",", "beta_c_KL", "]", ")", "\n", "beta_KLs", "=", "beta_KLs", ".", "to", "(", "self", ".", "agent", ".", "device", ")", "\n", "torch", ".", "distributed", ".", "all_reduce", "(", "beta_KLs", ")", "\n", "beta_KLs", "=", "beta_KLs", ".", "to", "(", "\"cpu\"", ")", "\n", "beta_KLs", "/=", "torch", ".", "distributed", ".", "get_world_size", "(", ")", "\n", "beta_r_KL", ",", "beta_c_KL", "=", "beta_KLs", "[", "0", "]", ",", "beta_KLs", "[", "1", "]", "\n", "\n", "", "raw_beta_KL", "=", "float", "(", "beta_r_KL", "/", "max", "(", "beta_c_KL", ",", "1e-8", ")", ")", "\n", "\n", "return", "raw_beta_KL", ",", "float", "(", "beta_r_KL", ")", ",", "float", "(", "beta_c_KL", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.safe.cppo_pid.CppoPID.beta_kl_losses": [[489, 521], ["dist.likelihood_ratio", "torch.clamp", "torch.min", "dist.likelihood_ratio", "torch.clamp", "torch.max", "rlpyt.utils.tensor.valid_mean", "rlpyt.utils.buffer.buffer_method", "rlpyt.utils.buffer.buffer_method", "cppo_pid.CppoPID.agent.beta_dist_infos", "cppo_pid.CppoPID.agent.beta_dist_infos", "rlpyt.utils.tensor.valid_mean"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.distributions.gaussian.Gaussian.likelihood_ratio", "home.repos.pwc.inspect_result.astooke_rlpyt.distributions.gaussian.Gaussian.likelihood_ratio", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.tensor.valid_mean", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.buffer.buffer_method", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.buffer.buffer_method", "home.repos.pwc.inspect_result.astooke_rlpyt.safe.cppo_agent.CppoLstmAgent.beta_dist_infos", "home.repos.pwc.inspect_result.astooke_rlpyt.safe.cppo_agent.CppoLstmAgent.beta_dist_infos", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.tensor.valid_mean"], ["", "def", "beta_kl_losses", "(", "self", ",", "agent_inputs", ",", "action", ",", "return_", ",", "advantage", ",", "valid", ",", "\n", "old_dist_info", ",", "c_return", ",", "c_advantage", ",", "init_rnn_state", "=", "None", ")", ":", "\n", "        ", "if", "init_rnn_state", "is", "not", "None", ":", "\n", "# [B,N,H] --> [N,B,H] (for cudnn).", "\n", "            ", "init_rnn_state", "=", "buffer_method", "(", "init_rnn_state", ",", "\"transpose\"", ",", "0", ",", "1", ")", "\n", "init_rnn_state", "=", "buffer_method", "(", "init_rnn_state", ",", "\"contiguous\"", ")", "\n", "r_dist_info", ",", "c_dist_info", "=", "self", ".", "agent", ".", "beta_dist_infos", "(", "\n", "*", "agent_inputs", ",", "init_rnn_state", ")", "\n", "", "else", ":", "\n", "            ", "r_dist_info", ",", "c_dist_info", "=", "self", ".", "agent", ".", "beta_dist_infos", "(", "\n", "*", "agent_inputs", ")", "\n", "", "dist", "=", "self", ".", "agent", ".", "distribution", "\n", "\n", "r_ratio", "=", "dist", ".", "likelihood_ratio", "(", "action", ",", "old_dist_info", "=", "old_dist_info", ",", "\n", "new_dist_info", "=", "r_dist_info", ")", "\n", "surr_1", "=", "r_ratio", "*", "advantage", "\n", "r_clipped_ratio", "=", "torch", ".", "clamp", "(", "r_ratio", ",", "1.", "-", "self", ".", "ratio_clip", ",", "\n", "1.", "+", "self", ".", "ratio_clip", ")", "\n", "surr_2", "=", "r_clipped_ratio", "*", "advantage", "\n", "surrogate", "=", "torch", ".", "min", "(", "surr_1", ",", "surr_2", ")", "\n", "beta_r_loss", "=", "-", "valid_mean", "(", "surrogate", ",", "valid", ")", "\n", "\n", "c_ratio", "=", "dist", ".", "likelihood_ratio", "(", "action", ",", "old_dist_info", "=", "old_dist_info", ",", "\n", "new_dist_info", "=", "c_dist_info", ")", "\n", "c_surr_1", "=", "c_ratio", "*", "c_advantage", "\n", "c_clipped_ratio", "=", "torch", ".", "clamp", "(", "c_ratio", ",", "1.", "-", "self", ".", "ratio_clip", ",", "\n", "1.", "+", "self", ".", "ratio_clip", ")", "\n", "c_surr_2", "=", "c_clipped_ratio", "*", "c_advantage", "\n", "c_surrogate", "=", "torch", ".", "max", "(", "c_surr_1", ",", "c_surr_2", ")", "\n", "beta_c_loss", "=", "valid_mean", "(", "c_surrogate", ",", "valid", ")", "\n", "\n", "return", "beta_r_loss", ",", "beta_c_loss", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.safe.cppo_pid.CppoPID.compute_beta_grad": [[522, 544], ["cppo_pid.CppoPID.optimizer.zero_grad", "cppo_pid.CppoPID.beta_grad_losses", "r_loss.backward", "torch.nn.utils.clip_grad_norm_", "min", "cppo_pid.CppoPID.optimizer.zero_grad", "c_loss.backward", "torch.nn.utils.clip_grad_norm_", "min", "cppo_pid.CppoPID.optimizer.zero_grad", "cppo_pid.CppoPID.agent.parameters", "cppo_pid.CppoPID.agent.parameters", "float", "float"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.safe.cppo_pid.CppoPID.beta_grad_losses", "home.repos.pwc.inspect_result.astooke_rlpyt.models.utils.ScaleGrad.backward", "home.repos.pwc.inspect_result.astooke_rlpyt.models.utils.ScaleGrad.backward", "home.repos.pwc.inspect_result.astooke_rlpyt.rl.atari_rl_models.AtariDqnModel.parameters", "home.repos.pwc.inspect_result.astooke_rlpyt.rl.atari_rl_models.AtariDqnModel.parameters"], ["", "def", "compute_beta_grad", "(", "self", ",", "loss_inputs", ",", "init_rnn_state", ")", ":", "\n", "        ", "\"\"\"Ratio of KL grad-norms from reward vs cost objectives.\"\"\"", "\n", "# Assume minibatches=1.", "\n", "self", ".", "optimizer", ".", "zero_grad", "(", ")", "\n", "\n", "r_loss", ",", "c_loss", "=", "self", ".", "beta_grad_losses", "(", "*", "loss_inputs", ",", "init_rnn_state", ")", "\n", "\n", "r_loss", ".", "backward", "(", "retain_graph", "=", "True", ")", "\n", "r_grad_norm", "=", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "\n", "self", ".", "agent", ".", "parameters", "(", ")", ",", "self", ".", "clip_grad_norm", ")", "\n", "r_grad_norm", "=", "min", "(", "r_grad_norm", ",", "self", ".", "clip_grad_norm", ")", "\n", "self", ".", "optimizer", ".", "zero_grad", "(", ")", "\n", "c_loss", ".", "backward", "(", ")", "\n", "c_grad_norm", "=", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "\n", "self", ".", "agent", ".", "parameters", "(", ")", ",", "self", ".", "clip_grad_norm", ")", "\n", "c_grad_norm", "=", "min", "(", "c_grad_norm", ",", "self", ".", "clip_grad_norm", ")", "\n", "self", ".", "optimizer", ".", "zero_grad", "(", ")", "\n", "\n", "if", "self", ".", "_ddp", ":", "\n", "            ", "raise", "NotImplementedError", "\n", "\n", "", "return", "float", "(", "r_grad_norm", ")", "/", "float", "(", "c_grad_norm", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.safe.cppo_pid.CppoPID.beta_grad_losses": [[545, 571], ["dist.likelihood_ratio", "torch.clamp", "torch.min", "torch.max", "rlpyt.utils.tensor.valid_mean", "rlpyt.utils.buffer.buffer_method", "rlpyt.utils.buffer.buffer_method", "cppo_pid.CppoPID.agent", "cppo_pid.CppoPID.agent", "rlpyt.utils.tensor.valid_mean"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.distributions.gaussian.Gaussian.likelihood_ratio", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.tensor.valid_mean", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.buffer.buffer_method", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.buffer.buffer_method", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.tensor.valid_mean"], ["", "def", "beta_grad_losses", "(", "self", ",", "agent_inputs", ",", "action", ",", "return_", ",", "advantage", ",", "valid", ",", "\n", "old_dist_info", ",", "c_return", ",", "c_advantage", ",", "init_rnn_state", "=", "None", ")", ":", "\n", "        ", "if", "init_rnn_state", "is", "not", "None", ":", "\n", "# [B,N,H] --> [N,B,H] (for cudnn).", "\n", "            ", "init_rnn_state", "=", "buffer_method", "(", "init_rnn_state", ",", "\"transpose\"", ",", "0", ",", "1", ")", "\n", "init_rnn_state", "=", "buffer_method", "(", "init_rnn_state", ",", "\"contiguous\"", ")", "\n", "dist_info", ",", "value", ",", "_rnn_state", "=", "self", ".", "agent", "(", "*", "agent_inputs", ",", "init_rnn_state", ")", "\n", "", "else", ":", "\n", "            ", "dist_info", ",", "value", "=", "self", ".", "agent", "(", "*", "agent_inputs", ")", "\n", "", "dist", "=", "self", ".", "agent", ".", "distribution", "\n", "\n", "ratio", "=", "dist", ".", "likelihood_ratio", "(", "action", ",", "old_dist_info", "=", "old_dist_info", ",", "\n", "new_dist_info", "=", "dist_info", ")", "\n", "surr_1", "=", "ratio", "*", "advantage", "\n", "clipped_ratio", "=", "torch", ".", "clamp", "(", "ratio", ",", "1.", "-", "self", ".", "ratio_clip", ",", "\n", "1.", "+", "self", ".", "ratio_clip", ")", "\n", "surr_2", "=", "clipped_ratio", "*", "advantage", "\n", "surrogate", "=", "torch", ".", "min", "(", "surr_1", ",", "surr_2", ")", "\n", "r_loss", "=", "-", "valid_mean", "(", "surrogate", ",", "valid", ")", "\n", "\n", "c_surr_1", "=", "ratio", "*", "c_advantage", "\n", "c_surr_2", "=", "clipped_ratio", "*", "c_advantage", "\n", "c_surrogate", "=", "torch", ".", "max", "(", "c_surr_1", ",", "c_surr_2", ")", "\n", "c_loss", "=", "valid_mean", "(", "c_surrogate", ",", "valid", ")", "\n", "\n", "return", "r_loss", ",", "c_loss", "\n", "", "", ""]], "home.repos.pwc.inspect_result.astooke_rlpyt.safe.cppo_agent.CppoAgent.__init__": [[20, 29], ["rlpyt.agents.pg.mujoco.MujocoFfAgent.__init__"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.spaces.gym_wrapper.GymSpaceWrapper.__init__"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "ModelCls", "=", "CppoModel", ",", "\n", "model_kwargs", "=", "None", ",", "\n", "initial_model_state_dict", "=", "None", ",", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "ModelCls", "=", "ModelCls", ",", "model_kwargs", "=", "model_kwargs", ",", "\n", "initial_model_state_dict", "=", "initial_model_state_dict", ")", "\n", "self", ".", "_ddp", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.safe.cppo_agent.CppoAgent.value": [[30, 36], ["torch.no_grad", "rlpyt.utils.buffer.buffer_to", "cppo_agent.CppoAgent.model", "rlpyt.utils.buffer.buffer_to"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.utils.buffer.buffer_to", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.buffer.buffer_to"], ["", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "value", "(", "self", ",", "observation", ",", "prev_action", ",", "prev_reward", ")", ":", "\n", "        ", "agent_inputs", "=", "buffer_to", "(", "(", "observation", ",", "prev_action", ",", "prev_reward", ")", ",", "\n", "device", "=", "self", ".", "device", ")", "\n", "_mu", ",", "_log_std", ",", "value", "=", "self", ".", "model", "(", "*", "agent_inputs", ")", "\n", "return", "buffer_to", "(", "value", ",", "device", "=", "\"cpu\"", ")", "# TODO: apply this to rlpyt.", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.safe.cppo_agent.CppoAgent.update_obs_rms": [[37, 43], ["rlpyt.utils.buffer.buffer_to", "cppo_agent.CppoAgent.model.module.update_obs_rms", "cppo_agent.CppoAgent.model.update_obs_rms"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.utils.buffer.buffer_to", "home.repos.pwc.inspect_result.astooke_rlpyt.safe.cppo_agent.CppoLstmAgent.update_obs_rms", "home.repos.pwc.inspect_result.astooke_rlpyt.safe.cppo_agent.CppoLstmAgent.update_obs_rms"], ["", "def", "update_obs_rms", "(", "self", ",", "observation", ")", ":", "\n", "        ", "observation", "=", "buffer_to", "(", "observation", ",", "device", "=", "self", ".", "device", ")", "\n", "if", "self", ".", "_ddp", ":", "\n", "            ", "self", ".", "model", ".", "module", ".", "update_obs_rms", "(", "observation", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "model", ".", "update_obs_rms", "(", "observation", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.safe.cppo_agent.CppoAgent.data_parallel": [[44, 48], ["super().data_parallel"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.safe.cppo_agent.CppoLstmAgent.data_parallel"], ["", "", "def", "data_parallel", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "device_id", "=", "super", "(", ")", ".", "data_parallel", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "self", ".", "_ddp", "=", "True", "\n", "return", "device_id", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.safe.cppo_agent.CppoLstmAgent.__init__": [[53, 62], ["rlpyt.agents.pg.mujoco.MujocoLstmAgent.__init__"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.spaces.gym_wrapper.GymSpaceWrapper.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "ModelCls", "=", "CppoModel", ",", "# I think can just swap in CppoConv", "\n", "model_kwargs", "=", "None", ",", "\n", "initial_model_state_dict", "=", "None", ",", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "ModelCls", "=", "ModelCls", ",", "model_kwargs", "=", "model_kwargs", ",", "\n", "initial_model_state_dict", "=", "initial_model_state_dict", ")", "\n", "self", ".", "_ddp", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.safe.cppo_agent.CppoLstmAgent.initialize": [[63, 70], ["super().initialize", "cppo_agent.CppoLstmAgent.ModelCls", "cppo_agent.CppoLstmAgent.ModelCls"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.safe.cppo_agent.CppoLstmAgent.initialize"], ["", "def", "initialize", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "initialize", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "# self.distribution.set_std(0.)", "\n", "self", ".", "beta_r_model", "=", "self", ".", "ModelCls", "(", "**", "self", ".", "model_kwargs", ",", "\n", "**", "self", ".", "env_model_kwargs", ")", "\n", "self", ".", "beta_c_model", "=", "self", ".", "ModelCls", "(", "**", "self", ".", "model_kwargs", ",", "\n", "**", "self", ".", "env_model_kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.safe.cppo_agent.CppoLstmAgent.to_device": [[71, 76], ["super().to_device", "cppo_agent.CppoLstmAgent.beta_r_model.to", "cppo_agent.CppoLstmAgent.beta_c_model.to"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.safe.cppo_agent.CppoLstmAgent.to_device"], ["", "def", "to_device", "(", "self", ",", "cuda_idx", "=", "None", ")", ":", "\n", "        ", "super", "(", ")", ".", "to_device", "(", "cuda_idx", "=", "cuda_idx", ")", "\n", "if", "cuda_idx", "is", "not", "None", ":", "\n", "            ", "self", ".", "beta_r_model", ".", "to", "(", "self", ".", "device", ")", "\n", "self", ".", "beta_c_model", ".", "to", "(", "self", ".", "device", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.safe.cppo_agent.CppoLstmAgent.value": [[77, 84], ["torch.no_grad", "rlpyt.utils.buffer.buffer_to", "cppo_agent.CppoLstmAgent.model", "rlpyt.utils.buffer.buffer_to"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.utils.buffer.buffer_to", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.buffer.buffer_to"], ["", "", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "value", "(", "self", ",", "observation", ",", "prev_action", ",", "prev_reward", ")", ":", "\n", "        ", "agent_inputs", "=", "buffer_to", "(", "(", "observation", ",", "prev_action", ",", "prev_reward", ")", ",", "\n", "device", "=", "self", ".", "device", ")", "\n", "_mu", ",", "_log_std", ",", "value", ",", "_rnn_state", "=", "self", ".", "model", "(", "*", "agent_inputs", ",", "\n", "self", ".", "prev_rnn_state", ")", "\n", "return", "buffer_to", "(", "value", ",", "device", "=", "\"cpu\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.safe.cppo_agent.CppoLstmAgent.update_obs_rms": [[85, 91], ["rlpyt.utils.buffer.buffer_to", "cppo_agent.CppoLstmAgent.model.module.update_obs_rms", "cppo_agent.CppoLstmAgent.model.update_obs_rms"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.utils.buffer.buffer_to", "home.repos.pwc.inspect_result.astooke_rlpyt.safe.cppo_agent.CppoLstmAgent.update_obs_rms", "home.repos.pwc.inspect_result.astooke_rlpyt.safe.cppo_agent.CppoLstmAgent.update_obs_rms"], ["", "def", "update_obs_rms", "(", "self", ",", "observation", ")", ":", "\n", "        ", "observation", "=", "buffer_to", "(", "observation", ",", "device", "=", "self", ".", "device", ")", "\n", "if", "self", ".", "_ddp", ":", "\n", "            ", "self", ".", "model", ".", "module", ".", "update_obs_rms", "(", "observation", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "model", ".", "update_obs_rms", "(", "observation", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.safe.cppo_agent.CppoLstmAgent.data_parallel": [[92, 96], ["super().data_parallel"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.safe.cppo_agent.CppoLstmAgent.data_parallel"], ["", "", "def", "data_parallel", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "device_id", "=", "super", "(", ")", ".", "data_parallel", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "self", ".", "_ddp", "=", "True", "\n", "return", "device_id", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.safe.cppo_agent.CppoLstmAgent.beta_dist_infos": [[97, 105], ["rlpyt.utils.buffer.buffer_to", "cppo_agent.CppoLstmAgent.beta_r_model", "cppo_agent.CppoLstmAgent.beta_c_model", "rlpyt.utils.buffer.buffer_to", "rlpyt.distributions.gaussian.DistInfoStd", "rlpyt.distributions.gaussian.DistInfoStd"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.utils.buffer.buffer_to", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.buffer.buffer_to"], ["", "def", "beta_dist_infos", "(", "self", ",", "observation", ",", "prev_action", ",", "prev_reward", ",", "\n", "init_rnn_state", ")", ":", "\n", "        ", "model_inputs", "=", "buffer_to", "(", "(", "observation", ",", "prev_action", ",", "prev_reward", ",", "\n", "init_rnn_state", ")", ",", "device", "=", "self", ".", "device", ")", "\n", "r_mu", ",", "r_log_std", ",", "_", ",", "_", "=", "self", ".", "beta_r_model", "(", "*", "model_inputs", ")", "\n", "c_mu", ",", "c_log_std", ",", "_", ",", "_", "=", "self", ".", "beta_c_model", "(", "*", "model_inputs", ")", "\n", "return", "buffer_to", "(", "(", "DistInfoStd", "(", "mean", "=", "r_mu", ",", "log_std", "=", "r_log_std", ")", ",", "\n", "DistInfoStd", "(", "mean", "=", "c_mu", ",", "log_std", "=", "c_log_std", ")", ")", ",", "device", "=", "\"cpu\"", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.astooke_rlpyt.safe.safety_gym_env.SafetyGymEnvWrapper.__init__": [[27, 62], ["gym.Wrapper.__init__", "safety_gym_env.sometimes_info", "env.reset", "isinstance", "safety_gym_env.SafetyGymEnvWrapper.observation", "dict", "gym.spaces.Dict", "gym.spaces.Box", "isinstance", "safety_gym_env.SafetyGymEnvWrapper.keys", "gym.spaces.Box", "gym.spaces.Box", "gym.spaces.Box", "len"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.spaces.gym_wrapper.GymSpaceWrapper.__init__", "home.repos.pwc.inspect_result.astooke_rlpyt.safe.safety_gym_env.sometimes_info", "home.repos.pwc.inspect_result.astooke_rlpyt.safe.safety_gym_env.SafetyGymEnvWrapper.reset", "home.repos.pwc.inspect_result.astooke_rlpyt.safe.safety_gym_env.SafetyGymEnvWrapper.observation"], ["    ", "def", "__init__", "(", "self", ",", "env", ",", "sometimes_info_kwargs", ",", "obs_prev_cost", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "env", ")", "\n", "self", ".", "_sometimes_info", "=", "sometimes_info", "(", "**", "sometimes_info_kwargs", ")", "\n", "self", ".", "_obs_prev_cost", "=", "obs_prev_cost", "\n", "self", ".", "_prev_cost", "=", "0.", "# Concat this into the observation.", "\n", "obs", "=", "env", ".", "reset", "(", ")", "\n", "# Some edited version of safexp envs defines observation space only", "\n", "# after reset, so expose it here (what base Wrapper does):", "\n", "self", ".", "observation_space", "=", "env", ".", "observation_space", "\n", "if", "isinstance", "(", "obs", ",", "dict", ")", ":", "# and \"vision\" in obs:", "\n", "            ", "self", ".", "_prop_keys", "=", "[", "k", "for", "k", "in", "obs", ".", "keys", "(", ")", "if", "k", "!=", "\"vision\"", "]", "\n", "obs", "=", "self", ".", "observation", "(", "obs", ")", "\n", "prop_shape", "=", "obs", "[", "\"prop\"", "]", ".", "shape", "\n", "# if obs_prev_cost:", "\n", "#     assert len(prop_shape) == 1", "\n", "#     prop_shape = (prop_shape[0] + 1,)", "\n", "obs_space", "=", "dict", "(", "\n", "prop", "=", "gym", ".", "spaces", ".", "Box", "(", "-", "1e6", ",", "1e6", ",", "prop_shape", ",", "\n", "obs", "[", "\"prop\"", "]", ".", "dtype", ")", ")", "\n", "if", "\"vision\"", "in", "obs", ":", "\n", "                ", "obs_space", "[", "\"vision\"", "]", "=", "gym", ".", "spaces", ".", "Box", "(", "0", ",", "1", ",", "obs", "[", "\"vision\"", "]", ".", "shape", ",", "\n", "obs", "[", "\"vision\"", "]", ".", "dtype", ")", "\n", "# GymWrapper will in turn convert this to rlpyt.spaces.Composite.", "\n", "", "self", ".", "observation_space", "=", "gym", ".", "spaces", ".", "Dict", "(", "obs_space", ")", "\n", "", "elif", "obs_prev_cost", ":", "\n", "            ", "if", "isinstance", "(", "obs", ",", "dict", ")", ":", "\n", "                ", "self", ".", "observation_space", ".", "spaces", "[", "\"prev_cost\"", "]", "=", "gym", ".", "spaces", ".", "Box", "(", "\n", "-", "1e6", ",", "1e6", ",", "(", "1", ",", ")", ",", "np", ".", "float32", ")", "\n", "", "else", ":", "\n", "                ", "obs_shape", "=", "obs", ".", "shape", "\n", "assert", "len", "(", "obs_shape", ")", "==", "1", "\n", "obs_shape", "=", "(", "obs_shape", "[", "0", "]", "+", "1", ",", ")", "\n", "self", ".", "observation_space", "=", "gym", ".", "spaces", ".", "Box", "(", "-", "1e6", ",", "1e6", ",", "obs_shape", ",", "\n", "obs", ".", "dtype", ")", "\n", "", "", "self", ".", "_cum_cost", "=", "0.", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.safe.safety_gym_env.SafetyGymEnvWrapper.step": [[63, 79], ["safety_gym_env.SafetyGymEnvWrapper.env.step", "safety_gym_env.SafetyGymEnvWrapper.observation", "infill_info.get", "safety_gym_env.infill_info", "infill_info.items", "isinstance", "numpy.dtype().type", "numpy.dtype"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.safe.safety_gym_env.SafetyGymTrajInfo.step", "home.repos.pwc.inspect_result.astooke_rlpyt.safe.safety_gym_env.SafetyGymEnvWrapper.observation", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.collections.NamedArrayTuple.get", "home.repos.pwc.inspect_result.astooke_rlpyt.safe.safety_gym_env.infill_info", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.collections.NamedArrayTuple.items", "home.repos.pwc.inspect_result.astooke_rlpyt.spaces.gym_wrapper.GymSpaceWrapper.dtype"], ["", "def", "step", "(", "self", ",", "action", ")", ":", "\n", "        ", "o", ",", "r", ",", "d", ",", "info", "=", "self", ".", "env", ".", "step", "(", "action", ")", "\n", "o", "=", "self", ".", "observation", "(", "o", ")", "# Uses self._prev_cost", "\n", "self", ".", "_prev_cost", "=", "info", ".", "get", "(", "\"cost\"", ",", "0", ")", "\n", "self", ".", "_cum_cost", "+=", "self", ".", "_prev_cost", "\n", "info", "[", "\"cum_cost\"", "]", "=", "self", ".", "_cum_cost", "\n", "# Try to make info dict same key structure at every step.", "\n", "info", "=", "infill_info", "(", "info", ",", "self", ".", "_sometimes_info", ")", "\n", "for", "k", ",", "v", "in", "info", ".", "items", "(", ")", ":", "\n", "            ", "if", "isinstance", "(", "v", ",", "float", ")", ":", "\n", "                ", "info", "[", "k", "]", "=", "np", ".", "dtype", "(", "\"float32\"", ")", ".", "type", "(", "v", ")", "# In case computing on.", "\n", "# Look inside safexp physics env for this logic on env horizon:", "\n", "", "", "info", "[", "\"timeout\"", "]", "=", "d", "and", "(", "self", ".", "env", ".", "steps", ">=", "self", ".", "env", ".", "num_steps", ")", "\n", "# info[\"timeout_next\"] = not d and (", "\n", "#     self.env.steps == self.env.num_steps - 1)", "\n", "return", "o", ",", "r", ",", "d", ",", "info", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.safe.safety_gym_env.SafetyGymEnvWrapper.reset": [[80, 84], ["safety_gym_env.SafetyGymEnvWrapper.observation", "safety_gym_env.SafetyGymEnvWrapper.env.reset"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.safe.safety_gym_env.SafetyGymEnvWrapper.observation", "home.repos.pwc.inspect_result.astooke_rlpyt.safe.safety_gym_env.SafetyGymEnvWrapper.reset"], ["", "def", "reset", "(", "self", ")", ":", "\n", "        ", "self", ".", "_prev_cost", "=", "0.", "\n", "self", ".", "_cum_cost", "=", "0.", "\n", "return", "self", ".", "observation", "(", "self", ".", "env", ".", "reset", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.safe.safety_gym_env.SafetyGymEnvWrapper.observation": [[85, 101], ["isinstance", "dict", "numpy.transpose", "numpy.append", "numpy.append", "numpy.concatenate", "obs[].reshape"], "methods", ["None"], ["", "def", "observation", "(", "self", ",", "obs", ")", ":", "\n", "        ", "if", "isinstance", "(", "obs", ",", "dict", ")", ":", "# and \"vision\" in obs:", "\n", "# flatten everything else than vision.", "\n", "            ", "obs_", "=", "dict", "(", "\n", "prop", "=", "np", ".", "concatenate", "(", "[", "obs", "[", "k", "]", ".", "reshape", "(", "-", "1", ")", "\n", "for", "k", "in", "self", ".", "_prop_keys", "]", ")", "\n", ")", "\n", "if", "\"vision\"", "in", "obs", ":", "\n", "# [H,W,C] --> [C,H,W]", "\n", "                ", "obs_", "[", "\"vision\"", "]", "=", "np", ".", "transpose", "(", "obs", "[", "\"vision\"", "]", ",", "(", "2", ",", "0", ",", "1", ")", ")", "\n", "", "if", "self", ".", "_obs_prev_cost", ":", "\n", "                ", "obs_", "[", "\"prop\"", "]", "=", "np", ".", "append", "(", "obs_", "[", "\"prop\"", "]", ",", "self", ".", "_prev_cost", ")", "\n", "", "obs", "=", "obs_", "\n", "", "elif", "self", ".", "_obs_prev_cost", ":", "\n", "            ", "obs", "=", "np", ".", "append", "(", "obs", ",", "self", ".", "_prev_cost", ")", "\n", "", "return", "obs", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.safe.safety_gym_env.SafetyGymTrajInfo.__init__": [[136, 139], ["rlpyt.samplers.collections.TrajInfo.__init__"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.spaces.gym_wrapper.GymSpaceWrapper.__init__"], ["    ", "def", "__init__", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "self", ".", "Cost", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.safe.safety_gym_env.SafetyGymTrajInfo.step": [[140, 143], ["super().step", "getattr"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.safe.safety_gym_env.SafetyGymTrajInfo.step"], ["", "def", "step", "(", "self", ",", "observation", ",", "action", ",", "reward", ",", "done", ",", "agent_info", ",", "env_info", ")", ":", "\n", "        ", "super", "(", ")", ".", "step", "(", "observation", ",", "action", ",", "reward", ",", "done", ",", "agent_info", ",", "env_info", ")", "\n", "self", ".", "Cost", "+=", "getattr", "(", "env_info", ",", "\"cost\"", ",", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.safe.safety_gym_env.SafetyGymTrajInfo.terminate": [[144, 147], ["super().terminate"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.safe.safety_gym_env.SafetyGymTrajInfo.terminate"], ["", "def", "terminate", "(", "self", ",", "observation", ")", ":", "\n", "        ", "del", "self", ".", "NonzeroRewards", "\n", "return", "super", "(", ")", ".", "terminate", "(", "observation", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.astooke_rlpyt.safe.safety_gym_env.sometimes_info": [[18, 23], ["dict"], "function", ["None"], ["def", "sometimes_info", "(", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "# e.g. Feed the env_id.", "\n", "# Return a dictionary (possibly nested) of keys: default_values", "\n", "# for this env.", "\n", "    ", "return", "dict", "(", "cost_exception", "=", "0", ",", "goal_met", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.safe.safety_gym_env.infill_info": [[103, 110], ["sometimes_info.items", "isinstance", "safety_gym_env.infill_info"], "function", ["home.repos.pwc.inspect_result.astooke_rlpyt.utils.collections.NamedArrayTuple.items", "home.repos.pwc.inspect_result.astooke_rlpyt.safe.safety_gym_env.infill_info"], ["", "", "def", "infill_info", "(", "info", ",", "sometimes_info", ")", ":", "\n", "    ", "for", "k", ",", "v", "in", "sometimes_info", ".", "items", "(", ")", ":", "\n", "        ", "if", "k", "not", "in", "info", ":", "\n", "            ", "info", "[", "k", "]", "=", "v", "\n", "", "elif", "isinstance", "(", "v", ",", "dict", ")", ":", "\n", "            ", "infill_info", "(", "info", "[", "k", "]", ",", "v", ")", "\n", "", "", "return", "info", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.safe.safety_gym_env.safety_gym_make": [[112, 131], ["rlpyt.envs.gym.GymEnvWrapper", "dict", "safety_gym_env.SafetyGymEnvWrapper", "gym.make", "dict"], "function", ["home.repos.pwc.inspect_result.astooke_rlpyt.envs.dmcontrol.make"], ["", "def", "safety_gym_make", "(", "*", "args", ",", "sometimes_info_kwargs", "=", "None", ",", "obs_prev_cost", "=", "True", ",", "\n", "obs_version", "=", "\"default\"", ",", "**", "kwargs", ")", ":", "\n", "    ", "assert", "obs_version", "in", "[", "\"default\"", ",", "\"vision\"", ",", "\"vision_only\"", ",", "\"no_lidar\"", ",", "\n", "\"no_constraints\"", "]", "\n", "if", "obs_version", "!=", "\"default\"", ":", "\n", "        ", "eid", "=", "kwargs", "[", "\"id\"", "]", "# Must provide as kwarg, not arg.", "\n", "names", "=", "dict", "(", "# Map to my modification in safety-gym suite.", "\n", "vision", "=", "\"Vision\"", ",", "\n", "vision_only", "=", "\"Visonly\"", ",", "\n", "no_lidar", "=", "\"NoLidar\"", ",", "\n", "no_constraints", "=", "\"NoConstr\"", ",", "\n", ")", "\n", "name", "=", "names", "[", "obs_version", "]", "\n", "# e.g. Safexp-PointGoal1-v0 --> Safexp-PointGoal1Vision-v0", "\n", "kwargs", "[", "\"id\"", "]", "=", "eid", "[", ":", "-", "3", "]", "+", "name", "+", "eid", "[", "-", "3", ":", "]", "\n", "", "return", "GymEnvWrapper", "(", "SafetyGymEnvWrapper", "(", "\n", "gym", ".", "make", "(", "*", "args", ",", "**", "kwargs", ")", ",", "\n", "sometimes_info_kwargs", "=", "sometimes_info_kwargs", "or", "dict", "(", ")", ",", "\n", "obs_prev_cost", "=", "obs_prev_cost", ")", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.spaces.base.Space.sample": [[8, 13], ["None"], "methods", ["None"], ["\n", "\n", "opt_info_fields", "=", "(", ")", "\n", "bootstrap_value", "=", "False", "\n", "update_counter", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.spaces.base.Space.null_value": [[14, 19], ["None"], "methods", ["None"], ["def", "initialize", "(", "self", ",", "agent", ",", "n_itr", ",", "batch_spec", ",", "mid_batch_reset", ",", "examples", ",", "\n", "world_size", "=", "1", ",", "rank", "=", "0", ")", ":", "\n", "        "]], "home.repos.pwc.inspect_result.astooke_rlpyt.spaces.float_box.FloatBox.__init__": [[10, 27], ["numpy.dtype", "numpy.issubdtype", "numpy.asarray", "numpy.asarray", "numpy.asarray", "numpy.asarray", "numpy.isscalar", "numpy.isscalar", "numpy.zeros", "numpy.zeros"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.spaces.gym_wrapper.GymSpaceWrapper.dtype", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.misc.zeros", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.misc.zeros"], ["def", "__init__", "(", "self", ",", "low", ",", "high", ",", "shape", "=", "None", ",", "null_value", "=", "0.", ",", "dtype", "=", "\"float32\"", ")", ":", "\n", "        ", "\"\"\"\n        Two kinds of valid input:\n            * low and high are scalars, and shape is provided: Box(-1.0, 1.0, (3,4))\n            * low and high are arrays of the same shape: Box(np.array([-1.0,-2.0]), np.array([2.0,4.0]))\n        \"\"\"", "\n", "self", ".", "dtype", "=", "np", ".", "dtype", "(", "dtype", ")", "\n", "assert", "np", ".", "issubdtype", "(", "self", ".", "dtype", ",", "np", ".", "floating", ")", "\n", "if", "shape", "is", "None", ":", "\n", "            ", "self", ".", "low", "=", "np", ".", "asarray", "(", "low", ",", "dtype", "=", "dtype", ")", "\n", "self", ".", "high", "=", "np", ".", "asarray", "(", "high", ",", "dtype", "=", "dtype", ")", "\n", "assert", "self", ".", "low", ".", "shape", "==", "self", ".", "high", ".", "shape", "\n", "", "else", ":", "\n", "            ", "assert", "np", ".", "isscalar", "(", "low", ")", "and", "np", ".", "isscalar", "(", "high", ")", "\n", "self", ".", "low", "=", "np", ".", "asarray", "(", "low", "+", "np", ".", "zeros", "(", "shape", ")", ",", "dtype", "=", "dtype", ")", "\n", "self", ".", "high", "=", "np", ".", "asarray", "(", "high", "+", "np", ".", "zeros", "(", "shape", ")", ",", "dtype", "=", "dtype", ")", "\n", "", "self", ".", "_null_value", "=", "null_value", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.spaces.float_box.FloatBox.sample": [[28, 32], ["numpy.asarray", "numpy.random.uniform"], "methods", ["None"], ["", "def", "sample", "(", "self", ")", ":", "\n", "        ", "\"\"\"Return a single sample from ``np.random.uniform``.\"\"\"", "\n", "return", "np", ".", "asarray", "(", "np", ".", "random", ".", "uniform", "(", "low", "=", "self", ".", "low", ",", "high", "=", "self", ".", "high", ",", "\n", "size", "=", "self", ".", "shape", ")", ",", "dtype", "=", "self", ".", "dtype", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.spaces.float_box.FloatBox.null_value": [[33, 41], ["numpy.zeros", "numpy.zeros.fill"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.utils.misc.zeros"], ["", "def", "null_value", "(", "self", ")", ":", "\n", "        ", "null", "=", "np", ".", "zeros", "(", "self", ".", "shape", ",", "dtype", "=", "self", ".", "dtype", ")", "\n", "if", "self", ".", "_null_value", "is", "not", "None", ":", "\n", "            ", "try", ":", "\n", "                ", "null", "[", ":", "]", "=", "self", ".", "_null_value", "\n", "", "except", "IndexError", ":", "\n", "                ", "null", ".", "fill", "(", "self", ".", "_null_value", ")", "\n", "", "", "return", "null", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.spaces.float_box.FloatBox.shape": [[42, 45], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "shape", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "low", ".", "shape", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.spaces.float_box.FloatBox.bounds": [[46, 49], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "bounds", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "low", ",", "self", ".", "high", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.spaces.float_box.FloatBox.__repr__": [[50, 52], ["None"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "return", "f\"FloatBox{self.shape}\"", "\n", "", "", ""]], "home.repos.pwc.inspect_result.astooke_rlpyt.spaces.gym_wrapper_schema.GymSpaceWrapper.__init__": [[16, 51], ["isinstance", "gym_wrapper_schema.GymSpaceWrapper._schemas.get", "rlpyt.spaces.composite.Composite", "rlpyt.utils.collections.NamedTupleSchema", "gym_wrapper_schema.GymSpaceWrapper", "ValueError", "space.spaces.items", "isinstance", "space.spaces.keys", "sorted", "sorted", "space.spaces.keys"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.utils.collections.NamedArrayTuple.get", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.collections.NamedArrayTuple.items"], ["def", "__init__", "(", "self", ",", "space", ",", "null_value", "=", "0", ",", "name", "=", "\"obs\"", ",", "force_float32", "=", "True", ",", "\n", "schemas", "=", "None", ")", ":", "\n", "        ", "\"\"\"Input ``space`` is a gym space instance.  \n        \n        Input ``name`` governs naming of internal NamedTupleSchemas used to\n        store Gym info.\n        \"\"\"", "\n", "self", ".", "_gym_space", "=", "space", "\n", "self", ".", "_base_name", "=", "name", "\n", "self", ".", "_null_value", "=", "null_value", "\n", "if", "schemas", "is", "None", ":", "\n", "            ", "schemas", "=", "{", "}", "\n", "", "self", ".", "_schemas", "=", "schemas", "\n", "if", "isinstance", "(", "space", ",", "GymDict", ")", ":", "\n", "            ", "nt", "=", "self", ".", "_schemas", ".", "get", "(", "name", ")", "\n", "if", "nt", "is", "None", ":", "\n", "                ", "nt", "=", "NamedTupleSchema", "(", "name", ",", "[", "k", "for", "k", "in", "space", ".", "spaces", ".", "keys", "(", ")", "]", ")", "\n", "schemas", "[", "name", "]", "=", "nt", "# Put at module level for pickle.", "\n", "", "elif", "not", "(", "isinstance", "(", "nt", ",", "NamedTupleSchema", ")", "and", "\n", "sorted", "(", "nt", ".", "_fields", ")", "==", "\n", "sorted", "(", "[", "k", "for", "k", "in", "space", ".", "spaces", ".", "keys", "(", ")", "]", ")", ")", ":", "\n", "                ", "raise", "ValueError", "(", "f\"Name clash in schemas: {name}.\"", ")", "\n", "", "spaces", "=", "[", "GymSpaceWrapper", "(", "\n", "space", "=", "v", ",", "\n", "null_value", "=", "null_value", ",", "\n", "name", "=", "\"_\"", ".", "join", "(", "[", "name", ",", "k", "]", ")", ",", "\n", "force_float32", "=", "force_float32", ",", "\n", "schemas", "=", "schemas", ")", "\n", "for", "k", ",", "v", "in", "space", ".", "spaces", ".", "items", "(", ")", "]", "\n", "self", ".", "space", "=", "Composite", "(", "spaces", ",", "nt", ")", "\n", "self", ".", "_dtype", "=", "None", "\n", "", "else", ":", "\n", "            ", "self", ".", "space", "=", "space", "\n", "self", ".", "_dtype", "=", "np", ".", "float32", "if", "(", "space", ".", "dtype", "==", "np", ".", "float64", "and", "\n", "force_float32", ")", "else", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.spaces.gym_wrapper_schema.GymSpaceWrapper.sample": [[52, 61], ["gym_wrapper_schema.GymSpaceWrapper.space.sample", "numpy.asarray"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.spaces.gym_wrapper.GymSpaceWrapper.sample"], ["", "", "def", "sample", "(", "self", ")", ":", "\n", "        ", "\"\"\"Returns a single sample in a namedtuple (for composite) or numpy\n        array using the the ``sample()`` method of the underlying gym\n        space(s).\"\"\"", "\n", "sample", "=", "self", ".", "space", ".", "sample", "(", ")", "\n", "if", "self", ".", "space", "is", "self", ".", "_gym_space", ":", "# Not Composite.", "\n", "# Force numpy array, might force float64->float32.", "\n", "            ", "sample", "=", "np", ".", "asarray", "(", "sample", ",", "dtype", "=", "self", ".", "_dtype", ")", "\n", "", "return", "sample", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.spaces.gym_wrapper_schema.GymSpaceWrapper.null_value": [[62, 76], ["numpy.asarray", "gym_wrapper_schema.GymSpaceWrapper.space.null_value", "gym_wrapper_schema.GymSpaceWrapper.space.sample", "gym_wrapper_schema.GymSpaceWrapper.fill", "gym_wrapper_schema.GymSpaceWrapper.fill"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.spaces.gym_wrapper.GymSpaceWrapper.null_value", "home.repos.pwc.inspect_result.astooke_rlpyt.spaces.gym_wrapper.GymSpaceWrapper.sample"], ["", "def", "null_value", "(", "self", ")", ":", "\n", "        ", "\"\"\"Similar to ``sample()`` but returning a null value.\"\"\"", "\n", "if", "self", ".", "space", "is", "self", ".", "_gym_space", ":", "\n", "            ", "null", "=", "np", ".", "asarray", "(", "self", ".", "space", ".", "sample", "(", ")", ",", "dtype", "=", "self", ".", "_dtype", ")", "\n", "if", "self", ".", "_null_value", "is", "not", "None", ":", "\n", "                ", "try", ":", "\n", "                    ", "null", "[", ":", "]", "=", "self", ".", "_null_value", "\n", "", "except", "IndexError", ":", "# e.g. scalar.", "\n", "                    ", "null", ".", "fill", "(", "self", ".", "_null_value", ")", "\n", "", "", "else", ":", "\n", "                ", "null", ".", "fill", "(", "0", ")", "\n", "", "", "else", ":", "# Is composite.", "\n", "            ", "null", "=", "self", ".", "space", ".", "null_value", "(", ")", "\n", "", "return", "null", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.spaces.gym_wrapper_schema.GymSpaceWrapper.convert": [[77, 83], ["gym_wrapper_schema.dict_to_nt"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.spaces.gym_wrapper.dict_to_nt"], ["", "def", "convert", "(", "self", ",", "value", ")", ":", "\n", "        ", "\"\"\"For dictionary space, use to convert wrapped env's dict to rlpyt\n        namedtuple, i.e. inside the environment wrapper's ``step()``, for\n        observation output to the rlpyt sampler (see helper function in\n        file)\"\"\"", "\n", "return", "dict_to_nt", "(", "value", ",", "name", "=", "self", ".", "_base_name", ",", "schemas", "=", "self", ".", "_schemas", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.spaces.gym_wrapper_schema.GymSpaceWrapper.revert": [[84, 89], ["gym_wrapper_schema.nt_to_dict"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.spaces.gym_wrapper.nt_to_dict"], ["", "def", "revert", "(", "self", ",", "value", ")", ":", "\n", "        ", "\"\"\"For dictionary space, use to revert namedtuple action into wrapped\n        env's dict, i.e. inside the environment wrappers ``step()``, for input\n        to the underlying gym environment (see helper function in file).\"\"\"", "\n", "return", "nt_to_dict", "(", "value", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.spaces.gym_wrapper_schema.GymSpaceWrapper.dtype": [[90, 93], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "dtype", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_dtype", "or", "self", ".", "space", ".", "dtype", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.spaces.gym_wrapper_schema.GymSpaceWrapper.shape": [[94, 97], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "shape", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "space", ".", "shape", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.spaces.gym_wrapper_schema.GymSpaceWrapper.contains": [[98, 100], ["gym_wrapper_schema.GymSpaceWrapper.space.contains"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.spaces.gym_wrapper.GymSpaceWrapper.contains"], ["", "def", "contains", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "self", ".", "space", ".", "contains", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.spaces.gym_wrapper_schema.GymSpaceWrapper.__repr__": [[101, 103], ["gym_wrapper_schema.GymSpaceWrapper.space.__repr__"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.spaces.gym_wrapper.GymSpaceWrapper.__repr__"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "space", ".", "__repr__", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.spaces.gym_wrapper_schema.GymSpaceWrapper.__eq__": [[104, 106], ["gym_wrapper_schema.GymSpaceWrapper.space.__eq__"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.spaces.gym_wrapper.GymSpaceWrapper.__eq__"], ["", "def", "__eq__", "(", "self", ",", "other", ")", ":", "\n", "        ", "return", "self", ".", "space", ".", "__eq__", "(", "other", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.spaces.gym_wrapper_schema.GymSpaceWrapper.low": [[107, 110], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "low", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "space", ".", "low", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.spaces.gym_wrapper_schema.GymSpaceWrapper.high": [[111, 114], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "high", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "space", ".", "high", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.spaces.gym_wrapper_schema.GymSpaceWrapper.n": [[115, 118], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "n", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "space", ".", "n", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.spaces.gym_wrapper_schema.GymSpaceWrapper.seed": [[119, 124], ["type", "gym_wrapper_schema.GymSpaceWrapper.space.seed", "space.seed"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.spaces.gym_wrapper.GymSpaceWrapper.seed", "home.repos.pwc.inspect_result.astooke_rlpyt.spaces.gym_wrapper.GymSpaceWrapper.seed"], ["", "def", "seed", "(", "self", ",", "seed", "=", "None", ")", ":", "\n", "        ", "if", "type", "(", "self", ".", "space", ")", "is", "Composite", ":", "\n", "            ", "return", "[", "space", ".", "seed", "(", "seed", "=", "seed", ")", "for", "space", "in", "self", ".", "space", ".", "spaces", "]", "\n", "", "else", ":", "\n", "            ", "return", "self", ".", "space", ".", "seed", "(", "seed", "=", "seed", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.spaces.gym_wrapper_schema.dict_to_nt": [[126, 134], ["isinstance", "isinstance", "numpy.asarray", "gym_wrapper_schema.dict_to_nt", "value.items"], "function", ["home.repos.pwc.inspect_result.astooke_rlpyt.spaces.gym_wrapper.dict_to_nt", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.collections.NamedArrayTuple.items"], ["", "", "", "def", "dict_to_nt", "(", "value", ",", "name", ",", "schemas", ")", ":", "\n", "    ", "if", "isinstance", "(", "value", ",", "dict", ")", ":", "\n", "        ", "values", "=", "{", "k", ":", "dict_to_nt", "(", "v", ",", "\"_\"", ".", "join", "(", "[", "name", ",", "k", "]", ")", ")", "\n", "for", "k", ",", "v", "in", "value", ".", "items", "(", ")", "}", "\n", "return", "schemas", "[", "name", "]", "(", "**", "values", ")", "\n", "", "if", "isinstance", "(", "value", ",", "np", ".", "ndarray", ")", "and", "value", ".", "dtype", "==", "np", ".", "float64", ":", "\n", "        ", "return", "np", ".", "asarray", "(", "value", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "", "return", "value", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.spaces.gym_wrapper_schema.nt_to_dict": [[136, 140], ["isinstance", "gym_wrapper_schema.nt_to_dict", "zip"], "function", ["home.repos.pwc.inspect_result.astooke_rlpyt.spaces.gym_wrapper.nt_to_dict"], ["", "def", "nt_to_dict", "(", "value", ")", ":", "\n", "    ", "if", "isinstance", "(", "value", ",", "NamedTuple", ")", ":", "\n", "        ", "return", "{", "k", ":", "nt_to_dict", "(", "v", ")", "for", "k", ",", "v", "in", "zip", "(", "value", ".", "_fields", ",", "value", ")", "}", "\n", "", "return", "value", "\n", "", ""]], "home.repos.pwc.inspect_result.astooke_rlpyt.spaces.int_box.IntBox.__init__": [[10, 24], ["numpy.dtype", "numpy.issubdtype", "numpy.isscalar", "numpy.isscalar"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.spaces.gym_wrapper.GymSpaceWrapper.dtype"], ["def", "__init__", "(", "self", ",", "low", ",", "high", ",", "shape", "=", "None", ",", "dtype", "=", "\"int32\"", ",", "null_value", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Params ``low`` and ``high`` are scalars, applied across all dimensions\n        of shape; valid values will be those in ``range(low, high)``.\n        \"\"\"", "\n", "assert", "np", ".", "isscalar", "(", "low", ")", "and", "np", ".", "isscalar", "(", "high", ")", "\n", "self", ".", "low", "=", "low", "\n", "self", ".", "high", "=", "high", "\n", "self", ".", "shape", "=", "shape", "if", "shape", "is", "not", "None", "else", "(", ")", "# np.ndarray sample", "\n", "self", ".", "dtype", "=", "np", ".", "dtype", "(", "dtype", ")", "\n", "assert", "np", ".", "issubdtype", "(", "self", ".", "dtype", ",", "np", ".", "integer", ")", "\n", "null_value", "=", "low", "if", "null_value", "is", "None", "else", "null_value", "\n", "assert", "null_value", ">=", "low", "and", "null_value", "<", "high", "\n", "self", ".", "_null_value", "=", "null_value", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.spaces.int_box.IntBox.sample": [[25, 29], ["numpy.random.randint"], "methods", ["None"], ["", "def", "sample", "(", "self", ")", ":", "\n", "        ", "\"\"\"Return a single sample from ``np.random.randint``.\"\"\"", "\n", "return", "np", ".", "random", ".", "randint", "(", "low", "=", "self", ".", "low", ",", "high", "=", "self", ".", "high", ",", "\n", "size", "=", "self", ".", "shape", ",", "dtype", "=", "self", ".", "dtype", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.spaces.int_box.IntBox.null_value": [[30, 38], ["numpy.zeros", "numpy.zeros.fill"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.utils.misc.zeros"], ["", "def", "null_value", "(", "self", ")", ":", "\n", "        ", "null", "=", "np", ".", "zeros", "(", "self", ".", "shape", ",", "dtype", "=", "self", ".", "dtype", ")", "\n", "if", "self", ".", "_null_value", "is", "not", "None", ":", "\n", "            ", "try", ":", "\n", "                ", "null", "[", ":", "]", "=", "self", ".", "_null_value", "\n", "", "except", "IndexError", ":", "\n", "                ", "null", ".", "fill", "(", "self", ".", "_null_value", ")", "\n", "", "", "return", "null", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.spaces.int_box.IntBox.bounds": [[39, 42], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "bounds", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "low", ",", "self", ".", "high", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.spaces.int_box.IntBox.n": [[43, 47], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "n", "(", "self", ")", ":", "\n", "        ", "\"\"\"The number of elements in the space.\"\"\"", "\n", "return", "self", ".", "high", "-", "self", ".", "low", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.spaces.int_box.IntBox.__repr__": [[48, 50], ["None"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "return", "f\"IntBox({self.low}-{self.high - 1} shape={self.shape})\"", "\n", "", "", ""]], "home.repos.pwc.inspect_result.astooke_rlpyt.spaces.composite.Composite.__init__": [[9, 18], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "spaces", ",", "NamedTupleCls", ")", ":", "\n", "        ", "\"\"\"Must input the instantiated sub-spaces in order (e.g. list or\n        tuple), and a named tuple class with whch to organize the sub-spaces\n        and resulting samples.  The ``NamedTupleCls`` should be defined in \n        the module (file) which defines the composite space.\n        \"\"\"", "\n", "self", ".", "_spaces", "=", "spaces", "\n", "# Should define NamedTupleCls in the module creating this space.", "\n", "self", ".", "_NamedTupleCls", "=", "NamedTupleCls", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.spaces.composite.Composite.sample": [[19, 23], ["composite.Composite._NamedTupleCls", "s.sample"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.spaces.gym_wrapper.GymSpaceWrapper.sample"], ["", "def", "sample", "(", "self", ")", ":", "\n", "        ", "\"\"\"Return a single sample which is a named tuple composed of samples \n        from all sub-spaces.\"\"\"", "\n", "return", "self", ".", "_NamedTupleCls", "(", "*", "(", "s", ".", "sample", "(", ")", "for", "s", "in", "self", ".", "_spaces", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.spaces.composite.Composite.null_value": [[24, 28], ["composite.Composite._NamedTupleCls", "s.null_value"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.spaces.gym_wrapper.GymSpaceWrapper.null_value"], ["", "def", "null_value", "(", "self", ")", ":", "\n", "        ", "\"\"\"Return a null value which is a named tuple composed of null\n        values from all sub-spaces.\"\"\"", "\n", "return", "self", ".", "_NamedTupleCls", "(", "*", "(", "s", ".", "null_value", "(", ")", "for", "s", "in", "self", ".", "_spaces", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.spaces.composite.Composite.shape": [[29, 33], ["composite.Composite._NamedTupleCls"], "methods", ["None"], ["", "@", "property", "\n", "def", "shape", "(", "self", ")", ":", "\n", "        ", "\"\"\"Return a named tuple composed of shapes of every sub-space.\"\"\"", "\n", "return", "self", ".", "_NamedTupleCls", "(", "*", "(", "s", ".", "shape", "for", "s", "in", "self", ".", "_spaces", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.spaces.composite.Composite.names": [[34, 38], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "names", "(", "self", ")", ":", "\n", "        ", "\"\"\"Return names of sub-spaces.\"\"\"", "\n", "return", "self", ".", "_NamedTupleCls", ".", "_fields", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.spaces.composite.Composite.spaces": [[39, 43], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "spaces", "(", "self", ")", ":", "\n", "        ", "\"\"\"Return the bare sub-spaces.\"\"\"", "\n", "return", "self", ".", "_spaces", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.spaces.composite.Composite.__repr__": [[44, 46], ["space.__repr__"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.spaces.gym_wrapper.GymSpaceWrapper.__repr__"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "return", "\", \"", ".", "join", "(", "space", ".", "__repr__", "(", ")", "for", "space", "in", "self", ".", "_spaces", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.astooke_rlpyt.spaces.gym_wrapper.GymSpaceWrapper.__init__": [[17, 50], ["isinstance", "globals().get", "rlpyt.spaces.composite.Composite", "collections.namedtuple", "gym_wrapper.GymSpaceWrapper", "globals", "globals", "ValueError", "space.spaces.items", "rlpyt.utils.collections.is_namedtuple_class", "space.spaces.keys", "sorted", "sorted", "space.spaces.keys"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.utils.collections.NamedArrayTuple.get", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.collections.NamedArrayTuple.items", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.collections.is_namedtuple_class"], ["def", "__init__", "(", "self", ",", "space", ",", "null_value", "=", "0", ",", "name", "=", "\"obs\"", ",", "force_float32", "=", "True", ")", ":", "\n", "        ", "\"\"\"Input ``space`` is a gym space instance.  \n        \n        Input ``name`` is used to disambiguate different gym spaces being\n        wrapped, which is necessary if more than one GymDict space is to be\n        wrapped in the same file.  The reason is that the associated\n        namedtuples must be defined in the globals of this file, so they must\n        have distinct names.\n        \"\"\"", "\n", "self", ".", "_gym_space", "=", "space", "\n", "self", ".", "_base_name", "=", "name", "\n", "self", ".", "_null_value", "=", "null_value", "\n", "if", "isinstance", "(", "space", ",", "GymDict", ")", ":", "\n", "            ", "nt", "=", "globals", "(", ")", ".", "get", "(", "name", ")", "\n", "if", "nt", "is", "None", ":", "\n", "                ", "nt", "=", "namedtuple", "(", "name", ",", "[", "k", "for", "k", "in", "space", ".", "spaces", ".", "keys", "(", ")", "]", ")", "\n", "globals", "(", ")", "[", "name", "]", "=", "nt", "# Put at module level for pickle.", "\n", "", "elif", "not", "(", "is_namedtuple_class", "(", "nt", ")", "and", "\n", "sorted", "(", "nt", ".", "_fields", ")", "==", "\n", "sorted", "(", "[", "k", "for", "k", "in", "space", ".", "spaces", ".", "keys", "(", ")", "]", ")", ")", ":", "\n", "                ", "raise", "ValueError", "(", "f\"Name clash in globals: {name}.\"", ")", "\n", "", "spaces", "=", "[", "GymSpaceWrapper", "(", "\n", "space", "=", "v", ",", "\n", "null_value", "=", "null_value", ",", "\n", "name", "=", "\"_\"", ".", "join", "(", "[", "name", ",", "k", "]", ")", ",", "\n", "force_float32", "=", "force_float32", ")", "\n", "for", "k", ",", "v", "in", "space", ".", "spaces", ".", "items", "(", ")", "]", "\n", "self", ".", "space", "=", "Composite", "(", "spaces", ",", "nt", ")", "\n", "self", ".", "_dtype", "=", "None", "\n", "", "else", ":", "\n", "            ", "self", ".", "space", "=", "space", "\n", "self", ".", "_dtype", "=", "np", ".", "float32", "if", "(", "space", ".", "dtype", "==", "np", ".", "float64", "and", "\n", "force_float32", ")", "else", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.spaces.gym_wrapper.GymSpaceWrapper.sample": [[51, 60], ["gym_wrapper.GymSpaceWrapper.space.sample", "numpy.asarray"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.spaces.gym_wrapper.GymSpaceWrapper.sample"], ["", "", "def", "sample", "(", "self", ")", ":", "\n", "        ", "\"\"\"Returns a single sample in a namedtuple (for composite) or numpy\n        array using the the ``sample()`` method of the underlying gym\n        space(s).\"\"\"", "\n", "sample", "=", "self", ".", "space", ".", "sample", "(", ")", "\n", "if", "self", ".", "space", "is", "self", ".", "_gym_space", ":", "# Not Composite.", "\n", "# Force numpy array, might force float64->float32.", "\n", "            ", "sample", "=", "np", ".", "asarray", "(", "sample", ",", "dtype", "=", "self", ".", "_dtype", ")", "\n", "", "return", "sample", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.spaces.gym_wrapper.GymSpaceWrapper.null_value": [[61, 75], ["numpy.asarray", "gym_wrapper.GymSpaceWrapper.space.null_value", "gym_wrapper.GymSpaceWrapper.space.sample", "gym_wrapper.GymSpaceWrapper.fill", "gym_wrapper.GymSpaceWrapper.fill"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.spaces.gym_wrapper.GymSpaceWrapper.null_value", "home.repos.pwc.inspect_result.astooke_rlpyt.spaces.gym_wrapper.GymSpaceWrapper.sample"], ["", "def", "null_value", "(", "self", ")", ":", "\n", "        ", "\"\"\"Similar to ``sample()`` but returning a null value.\"\"\"", "\n", "if", "self", ".", "space", "is", "self", ".", "_gym_space", ":", "\n", "            ", "null", "=", "np", ".", "asarray", "(", "self", ".", "space", ".", "sample", "(", ")", ",", "dtype", "=", "self", ".", "_dtype", ")", "\n", "if", "self", ".", "_null_value", "is", "not", "None", ":", "\n", "                ", "try", ":", "\n", "                    ", "null", "[", ":", "]", "=", "self", ".", "_null_value", "\n", "", "except", "IndexError", ":", "# e.g. scalar.", "\n", "                    ", "null", ".", "fill", "(", "self", ".", "_null_value", ")", "\n", "", "", "else", ":", "\n", "                ", "null", ".", "fill", "(", "0", ")", "\n", "", "", "else", ":", "# Is composite.", "\n", "            ", "null", "=", "self", ".", "space", ".", "null_value", "(", ")", "\n", "", "return", "null", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.spaces.gym_wrapper.GymSpaceWrapper.convert": [[76, 82], ["gym_wrapper.dict_to_nt"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.spaces.gym_wrapper.dict_to_nt"], ["", "def", "convert", "(", "self", ",", "value", ")", ":", "\n", "        ", "\"\"\"For dictionary space, use to convert wrapped env's dict to rlpyt\n        namedtuple, i.e. inside the environment wrapper's ``step()``, for\n        observation output to the rlpyt sampler (see helper function in\n        file)\"\"\"", "\n", "return", "dict_to_nt", "(", "value", ",", "name", "=", "self", ".", "_base_name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.spaces.gym_wrapper.GymSpaceWrapper.revert": [[83, 88], ["gym_wrapper.nt_to_dict"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.spaces.gym_wrapper.nt_to_dict"], ["", "def", "revert", "(", "self", ",", "value", ")", ":", "\n", "        ", "\"\"\"For dictionary space, use to revert namedtuple action into wrapped\n        env's dict, i.e. inside the environment wrappers ``step()``, for input\n        to the underlying gym environment (see helper function in file).\"\"\"", "\n", "return", "nt_to_dict", "(", "value", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.spaces.gym_wrapper.GymSpaceWrapper.dtype": [[89, 92], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "dtype", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_dtype", "or", "self", ".", "space", ".", "dtype", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.spaces.gym_wrapper.GymSpaceWrapper.shape": [[93, 96], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "shape", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "space", ".", "shape", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.spaces.gym_wrapper.GymSpaceWrapper.contains": [[97, 99], ["gym_wrapper.GymSpaceWrapper.space.contains"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.spaces.gym_wrapper.GymSpaceWrapper.contains"], ["", "def", "contains", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "self", ".", "space", ".", "contains", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.spaces.gym_wrapper.GymSpaceWrapper.__repr__": [[100, 102], ["gym_wrapper.GymSpaceWrapper.space.__repr__"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.spaces.gym_wrapper.GymSpaceWrapper.__repr__"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "space", ".", "__repr__", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.spaces.gym_wrapper.GymSpaceWrapper.__eq__": [[103, 105], ["gym_wrapper.GymSpaceWrapper.space.__eq__"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.spaces.gym_wrapper.GymSpaceWrapper.__eq__"], ["", "def", "__eq__", "(", "self", ",", "other", ")", ":", "\n", "        ", "return", "self", ".", "space", ".", "__eq__", "(", "other", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.spaces.gym_wrapper.GymSpaceWrapper.low": [[106, 109], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "low", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "space", ".", "low", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.spaces.gym_wrapper.GymSpaceWrapper.high": [[110, 113], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "high", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "space", ".", "high", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.spaces.gym_wrapper.GymSpaceWrapper.n": [[114, 117], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "n", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "space", ".", "n", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.spaces.gym_wrapper.GymSpaceWrapper.seed": [[118, 123], ["type", "gym_wrapper.GymSpaceWrapper.space.seed", "space.seed"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.spaces.gym_wrapper.GymSpaceWrapper.seed", "home.repos.pwc.inspect_result.astooke_rlpyt.spaces.gym_wrapper.GymSpaceWrapper.seed"], ["", "def", "seed", "(", "self", ",", "seed", "=", "None", ")", ":", "\n", "        ", "if", "type", "(", "self", ".", "space", ")", "is", "Composite", ":", "\n", "            ", "return", "[", "space", ".", "seed", "(", "seed", "=", "seed", ")", "for", "space", "in", "self", ".", "space", ".", "spaces", "]", "\n", "", "else", ":", "\n", "            ", "return", "self", ".", "space", ".", "seed", "(", "seed", "=", "seed", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.spaces.gym_wrapper.dict_to_nt": [[125, 133], ["isinstance", "isinstance", "numpy.asarray", "gym_wrapper.dict_to_nt", "value.items", "globals"], "function", ["home.repos.pwc.inspect_result.astooke_rlpyt.spaces.gym_wrapper.dict_to_nt", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.collections.NamedArrayTuple.items"], ["", "", "", "def", "dict_to_nt", "(", "value", ",", "name", ")", ":", "\n", "    ", "if", "isinstance", "(", "value", ",", "dict", ")", ":", "\n", "        ", "values", "=", "{", "k", ":", "dict_to_nt", "(", "v", ",", "\"_\"", ".", "join", "(", "[", "name", ",", "k", "]", ")", ")", "\n", "for", "k", ",", "v", "in", "value", ".", "items", "(", ")", "}", "\n", "return", "globals", "(", ")", "[", "name", "]", "(", "**", "values", ")", "\n", "", "if", "isinstance", "(", "value", ",", "np", ".", "ndarray", ")", "and", "value", ".", "dtype", "==", "np", ".", "float64", ":", "\n", "        ", "return", "np", ".", "asarray", "(", "value", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "", "return", "value", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.spaces.gym_wrapper.nt_to_dict": [[135, 139], ["rlpyt.utils.collections.is_namedtuple", "gym_wrapper.nt_to_dict", "zip"], "function", ["home.repos.pwc.inspect_result.astooke_rlpyt.utils.collections.is_namedtuple", "home.repos.pwc.inspect_result.astooke_rlpyt.spaces.gym_wrapper.nt_to_dict"], ["", "def", "nt_to_dict", "(", "value", ")", ":", "\n", "    ", "if", "is_namedtuple", "(", "value", ")", ":", "\n", "        ", "return", "{", "k", ":", "nt_to_dict", "(", "v", ")", "for", "k", ",", "v", "in", "zip", "(", "value", ".", "_fields", ",", "value", ")", "}", "\n", "", "return", "value", "\n", "", ""]], "home.repos.pwc.inspect_result.astooke_rlpyt.tests.test_serial_sampler.TestGymWrapper.test_seed": [[10, 34], ["rlpyt.samplers.serial.sampler.SerialSampler", "rlpyt.agents.qpg.sac_agent.SacAgent", "rlpyt.agents.qpg.sac_agent.SacAgent.give_min_itr_learn", "rlpyt.utils.seed.set_seed", "rlpyt.samplers.serial.sampler.SerialSampler.initialize", "rlpyt.samplers.serial.sampler.SerialSampler.obtain_samples", "rlpyt.utils.seed.set_seed", "rlpyt.samplers.serial.sampler.SerialSampler.initialize", "rlpyt.samplers.serial.sampler.SerialSampler.obtain_samples", "test_serial_sampler.TestGymWrapper.assertEqual", "rlpyt.samplers.serial.sampler.SerialSampler.obtain_samples", "test_serial_sampler.TestGymWrapper.assertNotEqual", "str", "str"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.agents.dmc_sac_agent.SacAgent.give_min_itr_learn", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.seed.set_seed", "home.repos.pwc.inspect_result.astooke_rlpyt.safe.cppo_agent.CppoLstmAgent.initialize", "home.repos.pwc.inspect_result.astooke_rlpyt.async_.serial_sampler.AsyncSerialSampler.obtain_samples", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.seed.set_seed", "home.repos.pwc.inspect_result.astooke_rlpyt.safe.cppo_agent.CppoLstmAgent.initialize", "home.repos.pwc.inspect_result.astooke_rlpyt.async_.serial_sampler.AsyncSerialSampler.obtain_samples", "home.repos.pwc.inspect_result.astooke_rlpyt.async_.serial_sampler.AsyncSerialSampler.obtain_samples"], ["    ", "def", "test_seed", "(", "self", ")", ":", "\n", "        ", "sampler", "=", "SerialSampler", "(", "\n", "EnvCls", "=", "gym_make", ",", "\n", "env_kwargs", "=", "{", "\"id\"", ":", "\"MountainCarContinuous-v0\"", "}", ",", "\n", "batch_T", "=", "1", ",", "\n", "batch_B", "=", "1", ",", "\n", ")", "\n", "\n", "agent", "=", "SacAgent", "(", "pretrain_std", "=", "0.0", ")", "\n", "agent", ".", "give_min_itr_learn", "(", "10000", ")", "\n", "\n", "set_seed", "(", "0", ")", "\n", "sampler", ".", "initialize", "(", "agent", ",", "seed", "=", "0", ")", "\n", "samples_1", "=", "sampler", ".", "obtain_samples", "(", "0", ")", "\n", "\n", "set_seed", "(", "0", ")", "\n", "sampler", ".", "initialize", "(", "agent", ",", "seed", "=", "0", ")", "\n", "samples_2", "=", "sampler", ".", "obtain_samples", "(", "0", ")", "\n", "\n", "# Dirty hack to compare objects containing tensors.", "\n", "self", ".", "assertEqual", "(", "str", "(", "samples_1", ")", ",", "str", "(", "samples_2", ")", ")", "\n", "\n", "samples_3", "=", "sampler", ".", "obtain_samples", "(", "0", ")", "\n", "self", ".", "assertNotEqual", "(", "samples_1", ",", "samples_3", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astooke_rlpyt.tests.test_rlpyt.test_rlpyt_simple": [[9, 43], ["rlpyt.samplers.serial.sampler.SerialSampler", "rlpyt.algos.dqn.dqn.DQN", "rlpyt.agents.dqn.atari.atari_dqn_agent.AtariDqnAgent", "rlpyt.runners.minibatch_rl.MinibatchRl", "dict", "rlpyt.utils.logging.context.logger_context", "rlpyt.runners.minibatch_rl.MinibatchRl.train", "dict", "dict", "int", "dict"], "function", ["home.repos.pwc.inspect_result.astooke_rlpyt.logging.context.logger_context", "home.repos.pwc.inspect_result.astooke_rlpyt.runners.minibatch_rl.MinibatchRlEval.train"], ["def", "test_rlpyt_simple", "(", ")", ":", "\n", "    ", "\"\"\" partially copied from example 1 \"\"\"", "\n", "game", "=", "\"pong\"", "\n", "run_ID", "=", "0", "\n", "cuda_idx", "=", "None", "\n", "n_steps", "=", "1", "\n", "sampler", "=", "SerialSampler", "(", "\n", "EnvCls", "=", "AtariEnv", ",", "\n", "TrajInfoCls", "=", "AtariTrajInfo", ",", "# default traj info + GameScore", "\n", "env_kwargs", "=", "dict", "(", "game", "=", "game", ")", ",", "\n", "eval_env_kwargs", "=", "dict", "(", "game", "=", "game", ")", ",", "\n", "batch_T", "=", "4", ",", "# Four time-steps per sampler iteration.", "\n", "batch_B", "=", "1", ",", "\n", "max_decorrelation_steps", "=", "0", ",", "\n", "eval_n_envs", "=", "10", ",", "\n", "eval_max_steps", "=", "int", "(", "10e3", ")", ",", "\n", "eval_max_trajectories", "=", "5", ",", "\n", ")", "\n", "algo", "=", "DQN", "(", "min_steps_learn", "=", "1e3", ",", "\n", "replay_size", "=", "1e3", ")", "# remove memory issues", "\n", "agent", "=", "AtariDqnAgent", "(", ")", "\n", "runner", "=", "MinibatchRl", "(", "\n", "algo", "=", "algo", ",", "\n", "agent", "=", "agent", ",", "\n", "sampler", "=", "sampler", ",", "\n", "n_steps", "=", "n_steps", ",", "\n", "log_interval_steps", "=", "1e3", ",", "\n", "affinity", "=", "dict", "(", "cuda_idx", "=", "cuda_idx", ")", ",", "\n", ")", "\n", "config", "=", "dict", "(", "game", "=", "game", ")", "\n", "name", "=", "\"dqn_\"", "+", "game", "\n", "log_dir", "=", "\"test_example_1\"", "\n", "with", "logger_context", "(", "log_dir", ",", "run_ID", ",", "name", ",", "config", ",", "snapshot_mode", "=", "\"last\"", ")", ":", "\n", "        ", "runner", ".", "train", "(", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.astooke_rlpyt.tests.test_gym_wrapper.TestGymWrapper.test_seed": [[10, 20], ["rlpyt.spaces.gym_wrapper.GymSpaceWrapper", "rlpyt.spaces.gym_wrapper.GymSpaceWrapper.seed", "rlpyt.spaces.gym_wrapper.GymSpaceWrapper.sample", "rlpyt.spaces.gym_wrapper.GymSpaceWrapper.seed", "rlpyt.spaces.gym_wrapper.GymSpaceWrapper.sample", "test_gym_wrapper.TestGymWrapper.assertEqual", "rlpyt.spaces.gym_wrapper.GymSpaceWrapper.sample", "test_gym_wrapper.TestGymWrapper.assertNotEqual", "gym.spaces.Box", "numpy.zeros", "numpy.ones"], "methods", ["home.repos.pwc.inspect_result.astooke_rlpyt.spaces.gym_wrapper.GymSpaceWrapper.seed", "home.repos.pwc.inspect_result.astooke_rlpyt.spaces.gym_wrapper.GymSpaceWrapper.sample", "home.repos.pwc.inspect_result.astooke_rlpyt.spaces.gym_wrapper.GymSpaceWrapper.seed", "home.repos.pwc.inspect_result.astooke_rlpyt.spaces.gym_wrapper.GymSpaceWrapper.sample", "home.repos.pwc.inspect_result.astooke_rlpyt.spaces.gym_wrapper.GymSpaceWrapper.sample", "home.repos.pwc.inspect_result.astooke_rlpyt.utils.misc.zeros"], ["    ", "def", "test_seed", "(", "self", ")", ":", "\n", "        ", "space", "=", "GymSpaceWrapper", "(", "gym", ".", "spaces", ".", "Box", "(", "low", "=", "np", ".", "zeros", "(", "1", ")", ",", "high", "=", "np", ".", "ones", "(", "1", ")", ")", ")", "\n", "space", ".", "seed", "(", "0", ")", "\n", "sample_1", "=", "space", ".", "sample", "(", ")", "\n", "space", ".", "seed", "(", "0", ")", "\n", "sample_2", "=", "space", ".", "sample", "(", ")", "\n", "self", ".", "assertEqual", "(", "sample_1", ",", "sample_2", ")", "\n", "\n", "sample_3", "=", "space", ".", "sample", "(", ")", "\n", "self", ".", "assertNotEqual", "(", "sample_1", ",", "sample_3", ")", "\n", "\n"]]}