{"home.repos.pwc.inspect_result.jakezhaojb_ARAE.yelp.models.MLP_Classify.__init__": [[14, 42], ["torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Module.__init__", "range", "torch.Linear", "torch.Linear", "torch.Linear", "models.MLP_Classify.layers.append", "models.MLP_Classify.add_module", "models.MLP_Classify.init_weights", "torch.Linear", "torch.Linear", "torch.Linear", "models.MLP_Classify.layers.append", "models.MLP_Classify.add_module", "models.MLP_Classify.layers.append", "models.MLP_Classify.add_module", "int", "len", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.BatchNorm1d", "models.MLP_Classify.layers.append", "models.MLP_Classify.add_module", "str", "layers.split", "str", "str", "len", "str"], "methods", ["home.repos.pwc.inspect_result.jakezhaojb_ARAE.lang.utils.Corpus.__init__", "home.repos.pwc.inspect_result.jakezhaojb_ARAE.lang.models.Seq2Seq.init_weights"], ["    ", "def", "__init__", "(", "self", ",", "ninput", ",", "noutput", ",", "layers", ",", "\n", "activation", "=", "nn", ".", "ReLU", "(", ")", ",", "gpu", "=", "False", ")", ":", "\n", "        ", "super", "(", "MLP_Classify", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "ninput", "=", "ninput", "\n", "self", ".", "noutput", "=", "noutput", "\n", "\n", "layer_sizes", "=", "[", "ninput", "]", "+", "[", "int", "(", "x", ")", "for", "x", "in", "layers", ".", "split", "(", "'-'", ")", "]", "\n", "self", ".", "layers", "=", "[", "]", "\n", "\n", "for", "i", "in", "range", "(", "len", "(", "layer_sizes", ")", "-", "1", ")", ":", "\n", "            ", "layer", "=", "nn", ".", "Linear", "(", "layer_sizes", "[", "i", "]", ",", "layer_sizes", "[", "i", "+", "1", "]", ")", "\n", "self", ".", "layers", ".", "append", "(", "layer", ")", "\n", "self", ".", "add_module", "(", "\"layer\"", "+", "str", "(", "i", "+", "1", ")", ",", "layer", ")", "\n", "\n", "# No batch normalization in first layer", "\n", "if", "i", "!=", "0", ":", "\n", "                ", "bn", "=", "nn", ".", "BatchNorm1d", "(", "layer_sizes", "[", "i", "+", "1", "]", ")", "\n", "self", ".", "layers", ".", "append", "(", "bn", ")", "\n", "self", ".", "add_module", "(", "\"bn\"", "+", "str", "(", "i", "+", "1", ")", ",", "bn", ")", "\n", "\n", "", "self", ".", "layers", ".", "append", "(", "activation", ")", "\n", "self", ".", "add_module", "(", "\"activation\"", "+", "str", "(", "i", "+", "1", ")", ",", "activation", ")", "\n", "\n", "", "layer", "=", "nn", ".", "Linear", "(", "layer_sizes", "[", "-", "1", "]", ",", "noutput", ")", "\n", "self", ".", "layers", ".", "append", "(", "layer", ")", "\n", "self", ".", "add_module", "(", "\"layer\"", "+", "str", "(", "len", "(", "self", ".", "layers", ")", ")", ",", "layer", ")", "\n", "\n", "self", ".", "init_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jakezhaojb_ARAE.yelp.models.MLP_Classify.forward": [[43, 48], ["enumerate", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "layer"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "for", "i", ",", "layer", "in", "enumerate", "(", "self", ".", "layers", ")", ":", "\n", "            ", "x", "=", "layer", "(", "x", ")", "\n", "", "x", "=", "F", ".", "sigmoid", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.jakezhaojb_ARAE.yelp.models.MLP_Classify.init_weights": [[49, 57], ["layer.weight.data.normal_", "layer.bias.data.fill_"], "methods", ["None"], ["", "def", "init_weights", "(", "self", ")", ":", "\n", "        ", "init_std", "=", "0.02", "\n", "for", "layer", "in", "self", ".", "layers", ":", "\n", "            ", "try", ":", "\n", "                ", "layer", ".", "weight", ".", "data", ".", "normal_", "(", "0", ",", "init_std", ")", "\n", "layer", ".", "bias", ".", "data", ".", "fill_", "(", "0", ")", "\n", "", "except", ":", "\n", "                ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.jakezhaojb_ARAE.yelp.models.Seq2Seq2Decoder.__init__": [[60, 105], ["torch.Module.__init__", "utils.to_gpu", "torch.Embedding", "torch.Embedding", "torch.Embedding", "torch.Embedding", "torch.Embedding", "torch.Embedding", "torch.Embedding", "torch.Embedding", "torch.Embedding", "torch.LSTM", "torch.LSTM", "torch.LSTM", "torch.LSTM", "torch.LSTM", "torch.LSTM", "torch.LSTM", "torch.LSTM", "torch.LSTM", "torch.Linear", "torch.Linear", "torch.Linear", "models.Seq2Seq2Decoder.init_weights", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.ones().long", "torch.ones().long", "torch.ones().long", "torch.ones().long", "torch.ones().long", "torch.ones().long", "torch.ones().long", "torch.ones().long", "torch.ones().long", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones"], "methods", ["home.repos.pwc.inspect_result.jakezhaojb_ARAE.lang.utils.Corpus.__init__", "home.repos.pwc.inspect_result.jakezhaojb_ARAE.lang.utils.to_gpu", "home.repos.pwc.inspect_result.jakezhaojb_ARAE.lang.models.Seq2Seq.init_weights"], ["    ", "def", "__init__", "(", "self", ",", "emsize", ",", "nhidden", ",", "ntokens", ",", "nlayers", ",", "noise_r", "=", "0.2", ",", "\n", "share_decoder_emb", "=", "False", ",", "hidden_init", "=", "False", ",", "dropout", "=", "0", ",", "gpu", "=", "False", ")", ":", "\n", "        ", "super", "(", "Seq2Seq2Decoder", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "nhidden", "=", "nhidden", "\n", "self", ".", "emsize", "=", "emsize", "\n", "self", ".", "ntokens", "=", "ntokens", "\n", "self", ".", "nlayers", "=", "nlayers", "\n", "self", ".", "noise_r", "=", "noise_r", "\n", "self", ".", "hidden_init", "=", "hidden_init", "\n", "self", ".", "dropout", "=", "dropout", "\n", "self", ".", "gpu", "=", "gpu", "\n", "\n", "self", ".", "start_symbols", "=", "to_gpu", "(", "gpu", ",", "Variable", "(", "torch", ".", "ones", "(", "10", ",", "1", ")", ".", "long", "(", ")", ")", ")", "\n", "\n", "# Vocabulary embedding", "\n", "self", ".", "embedding", "=", "nn", ".", "Embedding", "(", "ntokens", ",", "emsize", ")", "\n", "self", ".", "embedding_decoder1", "=", "nn", ".", "Embedding", "(", "ntokens", ",", "emsize", ")", "\n", "self", ".", "embedding_decoder2", "=", "nn", ".", "Embedding", "(", "ntokens", ",", "emsize", ")", "\n", "\n", "# RNN Encoder and Decoder", "\n", "self", ".", "encoder", "=", "nn", ".", "LSTM", "(", "input_size", "=", "emsize", ",", "\n", "hidden_size", "=", "nhidden", ",", "\n", "num_layers", "=", "nlayers", ",", "\n", "dropout", "=", "dropout", ",", "\n", "batch_first", "=", "True", ")", "\n", "\n", "decoder_input_size", "=", "emsize", "+", "nhidden", "\n", "self", ".", "decoder1", "=", "nn", ".", "LSTM", "(", "input_size", "=", "decoder_input_size", ",", "\n", "hidden_size", "=", "nhidden", ",", "\n", "num_layers", "=", "1", ",", "\n", "dropout", "=", "dropout", ",", "\n", "batch_first", "=", "True", ")", "\n", "self", ".", "decoder2", "=", "nn", ".", "LSTM", "(", "input_size", "=", "decoder_input_size", ",", "\n", "hidden_size", "=", "nhidden", ",", "\n", "num_layers", "=", "1", ",", "\n", "dropout", "=", "dropout", ",", "\n", "batch_first", "=", "True", ")", "\n", "\n", "# Initialize Linear Transformation", "\n", "self", ".", "linear", "=", "nn", ".", "Linear", "(", "nhidden", ",", "ntokens", ")", "\n", "\n", "self", ".", "init_weights", "(", ")", "\n", "\n", "if", "share_decoder_emb", ":", "\n", "            ", "self", ".", "embedding_decoder2", ".", "weight", "=", "self", ".", "embedding_decoder1", ".", "weight", "\n", "\n"]], "home.repos.pwc.inspect_result.jakezhaojb_ARAE.yelp.models.Seq2Seq2Decoder.init_weights": [[106, 125], ["models.Seq2Seq2Decoder.embedding.weight.data.uniform_", "models.Seq2Seq2Decoder.embedding_decoder1.weight.data.uniform_", "models.Seq2Seq2Decoder.embedding_decoder2.weight.data.uniform_", "models.Seq2Seq2Decoder.encoder.parameters", "models.Seq2Seq2Decoder.decoder1.parameters", "models.Seq2Seq2Decoder.decoder2.parameters", "models.Seq2Seq2Decoder.linear.weight.data.uniform_", "models.Seq2Seq2Decoder.linear.bias.data.fill_", "p.data.uniform_", "p.data.uniform_", "p.data.uniform_"], "methods", ["None"], ["", "", "def", "init_weights", "(", "self", ")", ":", "\n", "        ", "initrange", "=", "0.1", "\n", "\n", "# Initialize Vocabulary Matrix Weight", "\n", "self", ".", "embedding", ".", "weight", ".", "data", ".", "uniform_", "(", "-", "initrange", ",", "initrange", ")", "\n", "self", ".", "embedding_decoder1", ".", "weight", ".", "data", ".", "uniform_", "(", "-", "initrange", ",", "initrange", ")", "\n", "self", ".", "embedding_decoder2", ".", "weight", ".", "data", ".", "uniform_", "(", "-", "initrange", ",", "initrange", ")", "\n", "\n", "# Initialize Encoder and Decoder Weights", "\n", "for", "p", "in", "self", ".", "encoder", ".", "parameters", "(", ")", ":", "\n", "            ", "p", ".", "data", ".", "uniform_", "(", "-", "initrange", ",", "initrange", ")", "\n", "", "for", "p", "in", "self", ".", "decoder1", ".", "parameters", "(", ")", ":", "\n", "            ", "p", ".", "data", ".", "uniform_", "(", "-", "initrange", ",", "initrange", ")", "\n", "", "for", "p", "in", "self", ".", "decoder2", ".", "parameters", "(", ")", ":", "\n", "            ", "p", ".", "data", ".", "uniform_", "(", "-", "initrange", ",", "initrange", ")", "\n", "\n", "# Initialize Linear Weight", "\n", "", "self", ".", "linear", ".", "weight", ".", "data", ".", "uniform_", "(", "-", "initrange", ",", "initrange", ")", "\n", "self", ".", "linear", ".", "bias", ".", "data", ".", "fill_", "(", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jakezhaojb_ARAE.yelp.models.Seq2Seq2Decoder.init_hidden": [[126, 130], ["torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "utils.to_gpu", "utils.to_gpu"], "methods", ["home.repos.pwc.inspect_result.jakezhaojb_ARAE.lang.utils.to_gpu", "home.repos.pwc.inspect_result.jakezhaojb_ARAE.lang.utils.to_gpu"], ["", "def", "init_hidden", "(", "self", ",", "bsz", ")", ":", "\n", "        ", "zeros1", "=", "Variable", "(", "torch", ".", "zeros", "(", "self", ".", "nlayers", ",", "bsz", ",", "self", ".", "nhidden", ")", ")", "\n", "zeros2", "=", "Variable", "(", "torch", ".", "zeros", "(", "self", ".", "nlayers", ",", "bsz", ",", "self", ".", "nhidden", ")", ")", "\n", "return", "(", "to_gpu", "(", "self", ".", "gpu", ",", "zeros1", ")", ",", "to_gpu", "(", "self", ".", "gpu", ",", "zeros2", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jakezhaojb_ARAE.yelp.models.Seq2Seq2Decoder.init_state": [[131, 134], ["torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "utils.to_gpu", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros"], "methods", ["home.repos.pwc.inspect_result.jakezhaojb_ARAE.lang.utils.to_gpu"], ["", "def", "init_state", "(", "self", ",", "bsz", ")", ":", "\n", "        ", "zeros", "=", "Variable", "(", "torch", ".", "zeros", "(", "self", ".", "nlayers", ",", "bsz", ",", "self", ".", "nhidden", ")", ")", "\n", "return", "to_gpu", "(", "self", ".", "gpu", ",", "zeros", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jakezhaojb_ARAE.yelp.models.Seq2Seq2Decoder.store_grad_norm": [[135, 139], ["torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm.detach().data.mean", "torch.norm.detach().data.mean", "torch.norm.detach().data.mean", "torch.norm.detach", "torch.norm.detach", "torch.norm.detach"], "methods", ["None"], ["", "def", "store_grad_norm", "(", "self", ",", "grad", ")", ":", "\n", "        ", "norm", "=", "torch", ".", "norm", "(", "grad", ",", "2", ",", "1", ")", "\n", "self", ".", "grad_norm", "=", "norm", ".", "detach", "(", ")", ".", "data", ".", "mean", "(", ")", "\n", "return", "grad", "\n", "\n"]], "home.repos.pwc.inspect_result.jakezhaojb_ARAE.yelp.models.Seq2Seq2Decoder.forward": [[140, 155], ["indices.size", "models.Seq2Seq2Decoder.encode", "models.Seq2Seq2Decoder.decode", "models.Seq2Seq2Decoder.register_hook"], "methods", ["home.repos.pwc.inspect_result.jakezhaojb_ARAE.lang.models.Seq2Seq.encode", "home.repos.pwc.inspect_result.jakezhaojb_ARAE.lang.models.Seq2Seq.decode"], ["", "def", "forward", "(", "self", ",", "whichdecoder", ",", "indices", ",", "lengths", ",", "noise", "=", "False", ",", "encode_only", "=", "False", ")", ":", "\n", "        ", "batch_size", ",", "maxlen", "=", "indices", ".", "size", "(", ")", "\n", "\n", "hidden", "=", "self", ".", "encode", "(", "indices", ",", "lengths", ",", "noise", ")", "\n", "\n", "if", "hidden", ".", "requires_grad", ":", "\n", "            ", "hidden", ".", "register_hook", "(", "self", ".", "store_grad_norm", ")", "\n", "\n", "", "if", "encode_only", ":", "\n", "            ", "return", "hidden", "\n", "\n", "", "decoded", "=", "self", ".", "decode", "(", "whichdecoder", ",", "hidden", ",", "batch_size", ",", "maxlen", ",", "\n", "indices", "=", "indices", ",", "lengths", "=", "lengths", ")", "\n", "\n", "return", "decoded", "\n", "\n"]], "home.repos.pwc.inspect_result.jakezhaojb_ARAE.yelp.models.Seq2Seq2Decoder.encode": [[156, 183], ["models.Seq2Seq2Decoder.embedding", "torch.nn.utils.rnn.pack_padded_sequence", "torch.nn.utils.rnn.pack_padded_sequence", "torch.nn.utils.rnn.pack_padded_sequence", "models.Seq2Seq2Decoder.encoder", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.norm.unsqueeze().expand_as", "torch.norm.unsqueeze().expand_as", "torch.norm.unsqueeze().expand_as", "torch.normal", "torch.normal", "torch.normal", "torch.normal", "torch.normal", "torch.normal", "torch.normal", "torch.normal", "torch.normal", "utils.to_gpu", "torch.norm.unsqueeze", "torch.norm.unsqueeze", "torch.norm.unsqueeze", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.div.size", "torch.div.size", "torch.div.size"], "methods", ["home.repos.pwc.inspect_result.jakezhaojb_ARAE.lang.utils.to_gpu"], ["", "def", "encode", "(", "self", ",", "indices", ",", "lengths", ",", "noise", ")", ":", "\n", "        ", "embeddings", "=", "self", ".", "embedding", "(", "indices", ")", "\n", "packed_embeddings", "=", "pack_padded_sequence", "(", "input", "=", "embeddings", ",", "\n", "lengths", "=", "lengths", ",", "\n", "batch_first", "=", "True", ")", "\n", "\n", "# Encode", "\n", "packed_output", ",", "state", "=", "self", ".", "encoder", "(", "packed_embeddings", ")", "\n", "hidden", ",", "cell", "=", "state", "\n", "\n", "# batch_size x nhidden", "\n", "hidden", "=", "hidden", "[", "-", "1", "]", "# get hidden state of last layer of encoder", "\n", "\n", "# normalize to unit ball (l2 norm of 1) - p=2, dim=1", "\n", "norms", "=", "torch", ".", "norm", "(", "hidden", ",", "2", ",", "1", ")", "\n", "\n", "# For older versions of PyTorch use:", "\n", "hidden", "=", "torch", ".", "div", "(", "hidden", ",", "norms", ".", "unsqueeze", "(", "1", ")", ".", "expand_as", "(", "hidden", ")", ")", "\n", "# For newest version of PyTorch (as of 8/25) use this:", "\n", "# hidden = torch.div(hidden, norms.unsqueeze(1).expand_as(hidden))", "\n", "\n", "if", "noise", "and", "self", ".", "noise_r", ">", "0", ":", "\n", "            ", "gauss_noise", "=", "torch", ".", "normal", "(", "means", "=", "torch", ".", "zeros", "(", "hidden", ".", "size", "(", ")", ")", ",", "\n", "std", "=", "self", ".", "noise_r", ")", "\n", "hidden", "=", "hidden", "+", "to_gpu", "(", "self", ".", "gpu", ",", "Variable", "(", "gauss_noise", ")", ")", "\n", "\n", "", "return", "hidden", "\n", "\n"]], "home.repos.pwc.inspect_result.jakezhaojb_ARAE.yelp.models.Seq2Seq2Decoder.decode": [[184, 215], ["hidden.unsqueeze().repeat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.nn.utils.rnn.pack_padded_sequence", "torch.nn.utils.rnn.pack_padded_sequence", "torch.nn.utils.rnn.pack_padded_sequence", "torch.nn.utils.rnn.pad_packed_sequence", "torch.nn.utils.rnn.pad_packed_sequence", "torch.nn.utils.rnn.pad_packed_sequence", "models.Seq2Seq2Decoder.linear", "decoded.view.view.view", "models.Seq2Seq2Decoder.init_hidden", "models.Seq2Seq2Decoder.embedding_decoder1", "models.Seq2Seq2Decoder.embedding_decoder2", "models.Seq2Seq2Decoder.decoder1", "models.Seq2Seq2Decoder.decoder2", "output.contiguous().view", "hidden.unsqueeze", "hidden.unsqueeze", "models.Seq2Seq2Decoder.init_state", "output.contiguous"], "methods", ["home.repos.pwc.inspect_result.jakezhaojb_ARAE.lang.models.Seq2Seq.init_hidden", "home.repos.pwc.inspect_result.jakezhaojb_ARAE.lang.models.Seq2Seq.init_state"], ["", "def", "decode", "(", "self", ",", "whichdecoder", ",", "hidden", ",", "batch_size", ",", "maxlen", ",", "indices", "=", "None", ",", "lengths", "=", "None", ")", ":", "\n", "# batch x hidden", "\n", "        ", "all_hidden", "=", "hidden", ".", "unsqueeze", "(", "1", ")", ".", "repeat", "(", "1", ",", "maxlen", ",", "1", ")", "\n", "\n", "if", "self", ".", "hidden_init", ":", "\n", "# initialize decoder hidden state to encoder output", "\n", "            ", "state", "=", "(", "hidden", ".", "unsqueeze", "(", "0", ")", ",", "self", ".", "init_state", "(", "batch_size", ")", ")", "\n", "", "else", ":", "\n", "            ", "state", "=", "self", ".", "init_hidden", "(", "batch_size", ")", "\n", "\n", "", "if", "whichdecoder", "==", "1", ":", "\n", "            ", "embeddings", "=", "self", ".", "embedding_decoder1", "(", "indices", ")", "\n", "", "else", ":", "\n", "            ", "embeddings", "=", "self", ".", "embedding_decoder2", "(", "indices", ")", "\n", "\n", "", "augmented_embeddings", "=", "torch", ".", "cat", "(", "[", "embeddings", ",", "all_hidden", "]", ",", "2", ")", "\n", "packed_embeddings", "=", "pack_padded_sequence", "(", "input", "=", "augmented_embeddings", ",", "\n", "lengths", "=", "lengths", ",", "\n", "batch_first", "=", "True", ")", "\n", "\n", "if", "whichdecoder", "==", "1", ":", "\n", "            ", "packed_output", ",", "state", "=", "self", ".", "decoder1", "(", "packed_embeddings", ",", "state", ")", "\n", "", "else", ":", "\n", "            ", "packed_output", ",", "state", "=", "self", ".", "decoder2", "(", "packed_embeddings", ",", "state", ")", "\n", "", "output", ",", "lengths", "=", "pad_packed_sequence", "(", "packed_output", ",", "batch_first", "=", "True", ")", "\n", "\n", "# reshape to batch_size*maxlen x nhidden before linear over vocab", "\n", "decoded", "=", "self", ".", "linear", "(", "output", ".", "contiguous", "(", ")", ".", "view", "(", "-", "1", ",", "self", ".", "nhidden", ")", ")", "\n", "decoded", "=", "decoded", ".", "view", "(", "batch_size", ",", "maxlen", ",", "self", ".", "ntokens", ")", "\n", "\n", "return", "decoded", "\n", "\n"]], "home.repos.pwc.inspect_result.jakezhaojb_ARAE.yelp.models.Seq2Seq2Decoder.generate": [[216, 268], ["hidden.size", "models.Seq2Seq2Decoder.start_symbols.data.resize_", "models.Seq2Seq2Decoder.start_symbols.data.fill_", "utils.to_gpu", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "range", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "models.Seq2Seq2Decoder.init_hidden", "models.Seq2Seq2Decoder.embedding_decoder1", "models.Seq2Seq2Decoder.embedding_decoder2", "models.Seq2Seq2Decoder.linear", "all_indices.append", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "hidden.unsqueeze", "models.Seq2Seq2Decoder.init_state", "hidden.unsqueeze", "models.Seq2Seq2Decoder.decoder1", "models.Seq2Seq2Decoder.decoder2", "output.squeeze", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.multinomial.unsqueeze", "torch.multinomial.unsqueeze", "torch.multinomial.unsqueeze", "torch.softmax", "torch.softmax", "torch.softmax", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "models.Seq2Seq2Decoder.embedding_decoder1", "models.Seq2Seq2Decoder.embedding_decoder2", "hidden.unsqueeze"], "methods", ["home.repos.pwc.inspect_result.jakezhaojb_ARAE.lang.utils.to_gpu", "home.repos.pwc.inspect_result.jakezhaojb_ARAE.lang.models.Seq2Seq.init_hidden", "home.repos.pwc.inspect_result.jakezhaojb_ARAE.lang.models.Seq2Seq.init_state"], ["", "def", "generate", "(", "self", ",", "whichdecoder", ",", "hidden", ",", "maxlen", ",", "sample", "=", "False", ",", "temp", "=", "1.0", ")", ":", "\n", "        ", "\"\"\"Generate through decoder; no backprop\"\"\"", "\n", "\n", "batch_size", "=", "hidden", ".", "size", "(", "0", ")", "\n", "\n", "if", "self", ".", "hidden_init", ":", "\n", "# initialize decoder hidden state to encoder output", "\n", "            ", "state", "=", "(", "hidden", ".", "unsqueeze", "(", "0", ")", ",", "self", ".", "init_state", "(", "batch_size", ")", ")", "\n", "", "else", ":", "\n", "            ", "state", "=", "self", ".", "init_hidden", "(", "batch_size", ")", "\n", "\n", "# <sos>", "\n", "", "self", ".", "start_symbols", ".", "data", ".", "resize_", "(", "batch_size", ",", "1", ")", "\n", "self", ".", "start_symbols", ".", "data", ".", "fill_", "(", "1", ")", "\n", "self", ".", "start_symbols", "=", "to_gpu", "(", "self", ".", "gpu", ",", "self", ".", "start_symbols", ")", "\n", "\n", "if", "whichdecoder", "==", "1", ":", "\n", "            ", "embedding", "=", "self", ".", "embedding_decoder1", "(", "self", ".", "start_symbols", ")", "\n", "", "else", ":", "\n", "            ", "embedding", "=", "self", ".", "embedding_decoder2", "(", "self", ".", "start_symbols", ")", "\n", "\n", "", "inputs", "=", "torch", ".", "cat", "(", "[", "embedding", ",", "hidden", ".", "unsqueeze", "(", "1", ")", "]", ",", "2", ")", "\n", "\n", "# unroll", "\n", "all_indices", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "maxlen", ")", ":", "\n", "            ", "if", "whichdecoder", "==", "1", ":", "\n", "                ", "output", ",", "state", "=", "self", ".", "decoder1", "(", "inputs", ",", "state", ")", "\n", "", "else", ":", "\n", "                ", "output", ",", "state", "=", "self", ".", "decoder2", "(", "inputs", ",", "state", ")", "\n", "", "overvocab", "=", "self", ".", "linear", "(", "output", ".", "squeeze", "(", "1", ")", ")", "\n", "\n", "if", "not", "sample", ":", "\n", "                ", "vals", ",", "indices", "=", "torch", ".", "max", "(", "overvocab", ",", "1", ")", "\n", "indices", "=", "indices", ".", "unsqueeze", "(", "1", ")", "\n", "", "else", ":", "\n", "                ", "assert", "1", "==", "0", "\n", "# sampling", "\n", "probs", "=", "F", ".", "softmax", "(", "overvocab", "/", "temp", ")", "\n", "indices", "=", "torch", ".", "multinomial", "(", "probs", ",", "1", ")", "\n", "\n", "", "all_indices", ".", "append", "(", "indices", ")", "\n", "\n", "if", "whichdecoder", "==", "1", ":", "\n", "                ", "embedding", "=", "self", ".", "embedding_decoder1", "(", "indices", ")", "\n", "", "else", ":", "\n", "                ", "embedding", "=", "self", ".", "embedding_decoder2", "(", "indices", ")", "\n", "", "inputs", "=", "torch", ".", "cat", "(", "[", "embedding", ",", "hidden", ".", "unsqueeze", "(", "1", ")", "]", ",", "2", ")", "\n", "\n", "", "max_indices", "=", "torch", ".", "cat", "(", "all_indices", ",", "1", ")", "\n", "\n", "return", "max_indices", "\n", "\n"]], "home.repos.pwc.inspect_result.jakezhaojb_ARAE.yelp.models.MLP_D.__init__": [[271, 299], ["torch.LeakyReLU", "torch.LeakyReLU", "torch.LeakyReLU", "torch.Module.__init__", "range", "torch.Linear", "torch.Linear", "torch.Linear", "models.MLP_D.layers.append", "models.MLP_D.add_module", "models.MLP_D.init_weights", "torch.Linear", "torch.Linear", "torch.Linear", "models.MLP_D.layers.append", "models.MLP_D.add_module", "models.MLP_D.layers.append", "models.MLP_D.add_module", "int", "len", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.BatchNorm1d", "models.MLP_D.layers.append", "models.MLP_D.add_module", "str", "layers.split", "str", "str", "len", "str"], "methods", ["home.repos.pwc.inspect_result.jakezhaojb_ARAE.lang.utils.Corpus.__init__", "home.repos.pwc.inspect_result.jakezhaojb_ARAE.lang.models.Seq2Seq.init_weights"], ["    ", "def", "__init__", "(", "self", ",", "ninput", ",", "noutput", ",", "layers", ",", "\n", "activation", "=", "nn", ".", "LeakyReLU", "(", "0.2", ")", ",", "gpu", "=", "False", ")", ":", "\n", "        ", "super", "(", "MLP_D", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "ninput", "=", "ninput", "\n", "self", ".", "noutput", "=", "noutput", "\n", "\n", "layer_sizes", "=", "[", "ninput", "]", "+", "[", "int", "(", "x", ")", "for", "x", "in", "layers", ".", "split", "(", "'-'", ")", "]", "\n", "self", ".", "layers", "=", "[", "]", "\n", "\n", "for", "i", "in", "range", "(", "len", "(", "layer_sizes", ")", "-", "1", ")", ":", "\n", "            ", "layer", "=", "nn", ".", "Linear", "(", "layer_sizes", "[", "i", "]", ",", "layer_sizes", "[", "i", "+", "1", "]", ")", "\n", "self", ".", "layers", ".", "append", "(", "layer", ")", "\n", "self", ".", "add_module", "(", "\"layer\"", "+", "str", "(", "i", "+", "1", ")", ",", "layer", ")", "\n", "\n", "# No batch normalization after first layer", "\n", "if", "i", "!=", "0", ":", "\n", "                ", "bn", "=", "nn", ".", "BatchNorm1d", "(", "layer_sizes", "[", "i", "+", "1", "]", ",", "eps", "=", "1e-05", ",", "momentum", "=", "0.1", ")", "\n", "self", ".", "layers", ".", "append", "(", "bn", ")", "\n", "self", ".", "add_module", "(", "\"bn\"", "+", "str", "(", "i", "+", "1", ")", ",", "bn", ")", "\n", "\n", "", "self", ".", "layers", ".", "append", "(", "activation", ")", "\n", "self", ".", "add_module", "(", "\"activation\"", "+", "str", "(", "i", "+", "1", ")", ",", "activation", ")", "\n", "\n", "", "layer", "=", "nn", ".", "Linear", "(", "layer_sizes", "[", "-", "1", "]", ",", "noutput", ")", "\n", "self", ".", "layers", ".", "append", "(", "layer", ")", "\n", "self", ".", "add_module", "(", "\"layer\"", "+", "str", "(", "len", "(", "self", ".", "layers", ")", ")", ",", "layer", ")", "\n", "\n", "self", ".", "init_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jakezhaojb_ARAE.yelp.models.MLP_D.forward": [[300, 305], ["enumerate", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "layer"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "for", "i", ",", "layer", "in", "enumerate", "(", "self", ".", "layers", ")", ":", "\n", "            ", "x", "=", "layer", "(", "x", ")", "\n", "", "x", "=", "torch", ".", "mean", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.jakezhaojb_ARAE.yelp.models.MLP_D.init_weights": [[306, 314], ["layer.weight.data.normal_", "layer.bias.data.fill_"], "methods", ["None"], ["", "def", "init_weights", "(", "self", ")", ":", "\n", "        ", "init_std", "=", "0.02", "\n", "for", "layer", "in", "self", ".", "layers", ":", "\n", "            ", "try", ":", "\n", "                ", "layer", ".", "weight", ".", "data", ".", "normal_", "(", "0", ",", "init_std", ")", "\n", "layer", ".", "bias", ".", "data", ".", "fill_", "(", "0", ")", "\n", "", "except", ":", "\n", "                ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.jakezhaojb_ARAE.yelp.models.MLP_G.__init__": [[317, 343], ["torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Module.__init__", "range", "torch.Linear", "torch.Linear", "torch.Linear", "models.MLP_G.layers.append", "models.MLP_G.add_module", "models.MLP_G.init_weights", "torch.Linear", "torch.Linear", "torch.Linear", "models.MLP_G.layers.append", "models.MLP_G.add_module", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.BatchNorm1d", "models.MLP_G.layers.append", "models.MLP_G.add_module", "models.MLP_G.layers.append", "models.MLP_G.add_module", "int", "len", "str", "layers.split", "str", "str", "str", "len"], "methods", ["home.repos.pwc.inspect_result.jakezhaojb_ARAE.lang.utils.Corpus.__init__", "home.repos.pwc.inspect_result.jakezhaojb_ARAE.lang.models.Seq2Seq.init_weights"], ["    ", "def", "__init__", "(", "self", ",", "ninput", ",", "noutput", ",", "layers", ",", "\n", "activation", "=", "nn", ".", "ReLU", "(", ")", ",", "gpu", "=", "False", ")", ":", "\n", "        ", "super", "(", "MLP_G", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "ninput", "=", "ninput", "\n", "self", ".", "noutput", "=", "noutput", "\n", "\n", "layer_sizes", "=", "[", "ninput", "]", "+", "[", "int", "(", "x", ")", "for", "x", "in", "layers", ".", "split", "(", "'-'", ")", "]", "\n", "self", ".", "layers", "=", "[", "]", "\n", "\n", "for", "i", "in", "range", "(", "len", "(", "layer_sizes", ")", "-", "1", ")", ":", "\n", "            ", "layer", "=", "nn", ".", "Linear", "(", "layer_sizes", "[", "i", "]", ",", "layer_sizes", "[", "i", "+", "1", "]", ")", "\n", "self", ".", "layers", ".", "append", "(", "layer", ")", "\n", "self", ".", "add_module", "(", "\"layer\"", "+", "str", "(", "i", "+", "1", ")", ",", "layer", ")", "\n", "\n", "bn", "=", "nn", ".", "BatchNorm1d", "(", "layer_sizes", "[", "i", "+", "1", "]", ",", "eps", "=", "1e-05", ",", "momentum", "=", "0.1", ")", "\n", "self", ".", "layers", ".", "append", "(", "bn", ")", "\n", "self", ".", "add_module", "(", "\"bn\"", "+", "str", "(", "i", "+", "1", ")", ",", "bn", ")", "\n", "\n", "self", ".", "layers", ".", "append", "(", "activation", ")", "\n", "self", ".", "add_module", "(", "\"activation\"", "+", "str", "(", "i", "+", "1", ")", ",", "activation", ")", "\n", "\n", "", "layer", "=", "nn", ".", "Linear", "(", "layer_sizes", "[", "-", "1", "]", ",", "noutput", ")", "\n", "self", ".", "layers", ".", "append", "(", "layer", ")", "\n", "self", ".", "add_module", "(", "\"layer\"", "+", "str", "(", "len", "(", "self", ".", "layers", ")", ")", ",", "layer", ")", "\n", "\n", "self", ".", "init_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jakezhaojb_ARAE.yelp.models.MLP_G.forward": [[344, 348], ["enumerate", "layer"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "for", "i", ",", "layer", "in", "enumerate", "(", "self", ".", "layers", ")", ":", "\n", "            ", "x", "=", "layer", "(", "x", ")", "\n", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.jakezhaojb_ARAE.yelp.models.MLP_G.init_weights": [[349, 357], ["layer.weight.data.normal_", "layer.bias.data.fill_"], "methods", ["None"], ["", "def", "init_weights", "(", "self", ")", ":", "\n", "        ", "init_std", "=", "0.02", "\n", "for", "layer", "in", "self", ".", "layers", ":", "\n", "            ", "try", ":", "\n", "                ", "layer", ".", "weight", ".", "data", ".", "normal_", "(", "0", ",", "init_std", ")", "\n", "layer", ".", "bias", ".", "data", ".", "fill_", "(", "0", ")", "\n", "", "except", ":", "\n", "                ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.jakezhaojb_ARAE.yelp.models.Seq2Seq.__init__": [[360, 396], ["torch.Module.__init__", "utils.to_gpu", "torch.Embedding", "torch.Embedding", "torch.Embedding", "torch.Embedding", "torch.Embedding", "torch.Embedding", "torch.LSTM", "torch.LSTM", "torch.LSTM", "torch.LSTM", "torch.LSTM", "torch.LSTM", "torch.Linear", "torch.Linear", "torch.Linear", "models.Seq2Seq.init_weights", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.ones().long", "torch.ones().long", "torch.ones().long", "torch.ones().long", "torch.ones().long", "torch.ones().long", "torch.ones().long", "torch.ones().long", "torch.ones().long", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones"], "methods", ["home.repos.pwc.inspect_result.jakezhaojb_ARAE.lang.utils.Corpus.__init__", "home.repos.pwc.inspect_result.jakezhaojb_ARAE.lang.utils.to_gpu", "home.repos.pwc.inspect_result.jakezhaojb_ARAE.lang.models.Seq2Seq.init_weights"], ["    ", "def", "__init__", "(", "self", ",", "emsize", ",", "nhidden", ",", "ntokens", ",", "nlayers", ",", "noise_r", "=", "0.2", ",", "\n", "hidden_init", "=", "False", ",", "dropout", "=", "0", ",", "gpu", "=", "False", ")", ":", "\n", "        ", "super", "(", "Seq2Seq", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "nhidden", "=", "nhidden", "\n", "self", ".", "emsize", "=", "emsize", "\n", "self", ".", "ntokens", "=", "ntokens", "\n", "self", ".", "nlayers", "=", "nlayers", "\n", "self", ".", "noise_r", "=", "noise_r", "\n", "self", ".", "hidden_init", "=", "hidden_init", "\n", "self", ".", "dropout", "=", "dropout", "\n", "self", ".", "gpu", "=", "gpu", "\n", "\n", "self", ".", "start_symbols", "=", "to_gpu", "(", "gpu", ",", "Variable", "(", "torch", ".", "ones", "(", "10", ",", "1", ")", ".", "long", "(", ")", ")", ")", "\n", "\n", "# Vocabulary embedding", "\n", "self", ".", "embedding", "=", "nn", ".", "Embedding", "(", "ntokens", ",", "emsize", ")", "\n", "self", ".", "embedding_decoder", "=", "nn", ".", "Embedding", "(", "ntokens", ",", "emsize", ")", "\n", "\n", "# RNN Encoder and Decoder", "\n", "self", ".", "encoder", "=", "nn", ".", "LSTM", "(", "input_size", "=", "emsize", ",", "\n", "hidden_size", "=", "nhidden", ",", "\n", "num_layers", "=", "nlayers", ",", "\n", "dropout", "=", "dropout", ",", "\n", "batch_first", "=", "True", ")", "\n", "\n", "decoder_input_size", "=", "emsize", "+", "nhidden", "\n", "self", ".", "decoder", "=", "nn", ".", "LSTM", "(", "input_size", "=", "decoder_input_size", ",", "\n", "hidden_size", "=", "nhidden", ",", "\n", "num_layers", "=", "1", ",", "\n", "dropout", "=", "dropout", ",", "\n", "batch_first", "=", "True", ")", "\n", "\n", "# Initialize Linear Transformation", "\n", "self", ".", "linear", "=", "nn", ".", "Linear", "(", "nhidden", ",", "ntokens", ")", "\n", "\n", "self", ".", "init_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jakezhaojb_ARAE.yelp.models.Seq2Seq.init_weights": [[397, 413], ["models.Seq2Seq.embedding.weight.data.uniform_", "models.Seq2Seq.embedding_decoder.weight.data.uniform_", "models.Seq2Seq.encoder.parameters", "models.Seq2Seq.decoder.parameters", "models.Seq2Seq.linear.weight.data.uniform_", "models.Seq2Seq.linear.bias.data.fill_", "p.data.uniform_", "p.data.uniform_"], "methods", ["None"], ["", "def", "init_weights", "(", "self", ")", ":", "\n", "        ", "initrange", "=", "0.1", "\n", "\n", "# Initialize Vocabulary Matrix Weight", "\n", "self", ".", "embedding", ".", "weight", ".", "data", ".", "uniform_", "(", "-", "initrange", ",", "initrange", ")", "\n", "self", ".", "embedding_decoder", ".", "weight", ".", "data", ".", "uniform_", "(", "-", "initrange", ",", "initrange", ")", "\n", "\n", "# Initialize Encoder and Decoder Weights", "\n", "for", "p", "in", "self", ".", "encoder", ".", "parameters", "(", ")", ":", "\n", "            ", "p", ".", "data", ".", "uniform_", "(", "-", "initrange", ",", "initrange", ")", "\n", "", "for", "p", "in", "self", ".", "decoder", ".", "parameters", "(", ")", ":", "\n", "            ", "p", ".", "data", ".", "uniform_", "(", "-", "initrange", ",", "initrange", ")", "\n", "\n", "# Initialize Linear Weight", "\n", "", "self", ".", "linear", ".", "weight", ".", "data", ".", "uniform_", "(", "-", "initrange", ",", "initrange", ")", "\n", "self", ".", "linear", ".", "bias", ".", "data", ".", "fill_", "(", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jakezhaojb_ARAE.yelp.models.Seq2Seq.init_hidden": [[414, 418], ["torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "utils.to_gpu", "utils.to_gpu"], "methods", ["home.repos.pwc.inspect_result.jakezhaojb_ARAE.lang.utils.to_gpu", "home.repos.pwc.inspect_result.jakezhaojb_ARAE.lang.utils.to_gpu"], ["", "def", "init_hidden", "(", "self", ",", "bsz", ")", ":", "\n", "        ", "zeros1", "=", "Variable", "(", "torch", ".", "zeros", "(", "self", ".", "nlayers", ",", "bsz", ",", "self", ".", "nhidden", ")", ")", "\n", "zeros2", "=", "Variable", "(", "torch", ".", "zeros", "(", "self", ".", "nlayers", ",", "bsz", ",", "self", ".", "nhidden", ")", ")", "\n", "return", "(", "to_gpu", "(", "self", ".", "gpu", ",", "zeros1", ")", ",", "to_gpu", "(", "self", ".", "gpu", ",", "zeros2", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jakezhaojb_ARAE.yelp.models.Seq2Seq.init_state": [[419, 422], ["torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "utils.to_gpu", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros"], "methods", ["home.repos.pwc.inspect_result.jakezhaojb_ARAE.lang.utils.to_gpu"], ["", "def", "init_state", "(", "self", ",", "bsz", ")", ":", "\n", "        ", "zeros", "=", "Variable", "(", "torch", ".", "zeros", "(", "self", ".", "nlayers", ",", "bsz", ",", "self", ".", "nhidden", ")", ")", "\n", "return", "to_gpu", "(", "self", ".", "gpu", ",", "zeros", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jakezhaojb_ARAE.yelp.models.Seq2Seq.store_grad_norm": [[423, 427], ["torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm.detach().data.mean", "torch.norm.detach().data.mean", "torch.norm.detach().data.mean", "torch.norm.detach", "torch.norm.detach", "torch.norm.detach"], "methods", ["None"], ["", "def", "store_grad_norm", "(", "self", ",", "grad", ")", ":", "\n", "        ", "norm", "=", "torch", ".", "norm", "(", "grad", ",", "2", ",", "1", ")", "\n", "self", ".", "grad_norm", "=", "norm", ".", "detach", "(", ")", ".", "data", ".", "mean", "(", ")", "\n", "return", "grad", "\n", "\n"]], "home.repos.pwc.inspect_result.jakezhaojb_ARAE.yelp.models.Seq2Seq.forward": [[428, 443], ["indices.size", "models.Seq2Seq.encode", "models.Seq2Seq.decode", "models.Seq2Seq.register_hook"], "methods", ["home.repos.pwc.inspect_result.jakezhaojb_ARAE.lang.models.Seq2Seq.encode", "home.repos.pwc.inspect_result.jakezhaojb_ARAE.lang.models.Seq2Seq.decode"], ["", "def", "forward", "(", "self", ",", "indices", ",", "lengths", ",", "noise", ",", "encode_only", "=", "False", ")", ":", "\n", "        ", "batch_size", ",", "maxlen", "=", "indices", ".", "size", "(", ")", "\n", "\n", "hidden", "=", "self", ".", "encode", "(", "indices", ",", "lengths", ",", "noise", ")", "\n", "\n", "if", "encode_only", ":", "\n", "            ", "return", "hidden", "\n", "\n", "", "if", "hidden", ".", "requires_grad", ":", "\n", "            ", "hidden", ".", "register_hook", "(", "self", ".", "store_grad_norm", ")", "\n", "\n", "", "decoded", "=", "self", ".", "decode", "(", "hidden", ",", "batch_size", ",", "maxlen", ",", "\n", "indices", "=", "indices", ",", "lengths", "=", "lengths", ")", "\n", "\n", "return", "decoded", "\n", "\n"]], "home.repos.pwc.inspect_result.jakezhaojb_ARAE.yelp.models.Seq2Seq.encode": [[444, 471], ["models.Seq2Seq.embedding", "torch.nn.utils.rnn.pack_padded_sequence", "torch.nn.utils.rnn.pack_padded_sequence", "torch.nn.utils.rnn.pack_padded_sequence", "models.Seq2Seq.encoder", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.norm.expand_as", "torch.norm.expand_as", "torch.norm.expand_as", "torch.normal", "torch.normal", "torch.normal", "torch.normal", "torch.normal", "torch.normal", "torch.normal", "torch.normal", "torch.normal", "utils.to_gpu", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.div.size", "torch.div.size", "torch.div.size"], "methods", ["home.repos.pwc.inspect_result.jakezhaojb_ARAE.lang.utils.to_gpu"], ["", "def", "encode", "(", "self", ",", "indices", ",", "lengths", ",", "noise", ")", ":", "\n", "        ", "embeddings", "=", "self", ".", "embedding", "(", "indices", ")", "\n", "packed_embeddings", "=", "pack_padded_sequence", "(", "input", "=", "embeddings", ",", "\n", "lengths", "=", "lengths", ",", "\n", "batch_first", "=", "True", ")", "\n", "\n", "# Encode", "\n", "packed_output", ",", "state", "=", "self", ".", "encoder", "(", "packed_embeddings", ")", "\n", "\n", "hidden", ",", "cell", "=", "state", "\n", "# batch_size x nhidden", "\n", "hidden", "=", "hidden", "[", "-", "1", "]", "# get hidden state of last layer of encoder", "\n", "\n", "# normalize to unit ball (l2 norm of 1) - p=2, dim=1", "\n", "norms", "=", "torch", ".", "norm", "(", "hidden", ",", "2", ",", "1", ")", "\n", "\n", "# For older versions of PyTorch use:", "\n", "hidden", "=", "torch", ".", "div", "(", "hidden", ",", "norms", ".", "expand_as", "(", "hidden", ")", ")", "\n", "# For newest version of PyTorch (as of 8/25) use this:", "\n", "# hidden = torch.div(hidden, norms.unsqueeze(1).expand_as(hidden))", "\n", "\n", "if", "noise", "and", "self", ".", "noise_r", ">", "0", ":", "\n", "            ", "gauss_noise", "=", "torch", ".", "normal", "(", "means", "=", "torch", ".", "zeros", "(", "hidden", ".", "size", "(", ")", ")", ",", "\n", "std", "=", "self", ".", "noise_r", ")", "\n", "hidden", "=", "hidden", "+", "to_gpu", "(", "self", ".", "gpu", ",", "Variable", "(", "gauss_noise", ")", ")", "\n", "\n", "", "return", "hidden", "\n", "\n"]], "home.repos.pwc.inspect_result.jakezhaojb_ARAE.yelp.models.Seq2Seq.decode": [[472, 496], ["hidden.unsqueeze().repeat", "models.Seq2Seq.embedding_decoder", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.nn.utils.rnn.pack_padded_sequence", "torch.nn.utils.rnn.pack_padded_sequence", "torch.nn.utils.rnn.pack_padded_sequence", "models.Seq2Seq.decoder", "torch.nn.utils.rnn.pad_packed_sequence", "torch.nn.utils.rnn.pad_packed_sequence", "torch.nn.utils.rnn.pad_packed_sequence", "models.Seq2Seq.linear", "decoded.view.view.view", "models.Seq2Seq.init_hidden", "output.contiguous().view", "hidden.unsqueeze", "hidden.unsqueeze", "models.Seq2Seq.init_state", "output.contiguous"], "methods", ["home.repos.pwc.inspect_result.jakezhaojb_ARAE.lang.models.Seq2Seq.init_hidden", "home.repos.pwc.inspect_result.jakezhaojb_ARAE.lang.models.Seq2Seq.init_state"], ["", "def", "decode", "(", "self", ",", "hidden", ",", "batch_size", ",", "maxlen", ",", "indices", "=", "None", ",", "lengths", "=", "None", ")", ":", "\n", "# batch x hidden", "\n", "        ", "all_hidden", "=", "hidden", ".", "unsqueeze", "(", "1", ")", ".", "repeat", "(", "1", ",", "maxlen", ",", "1", ")", "\n", "\n", "if", "self", ".", "hidden_init", ":", "\n", "# initialize decoder hidden state to encoder output", "\n", "            ", "state", "=", "(", "hidden", ".", "unsqueeze", "(", "0", ")", ",", "self", ".", "init_state", "(", "batch_size", ")", ")", "\n", "", "else", ":", "\n", "            ", "state", "=", "self", ".", "init_hidden", "(", "batch_size", ")", "\n", "\n", "", "embeddings", "=", "self", ".", "embedding_decoder", "(", "indices", ")", "\n", "augmented_embeddings", "=", "torch", ".", "cat", "(", "[", "embeddings", ",", "all_hidden", "]", ",", "2", ")", "\n", "packed_embeddings", "=", "pack_padded_sequence", "(", "input", "=", "augmented_embeddings", ",", "\n", "lengths", "=", "lengths", ",", "\n", "batch_first", "=", "True", ")", "\n", "\n", "packed_output", ",", "state", "=", "self", ".", "decoder", "(", "packed_embeddings", ",", "state", ")", "\n", "output", ",", "lengths", "=", "pad_packed_sequence", "(", "packed_output", ",", "batch_first", "=", "True", ")", "\n", "\n", "# reshape to batch_size*maxlen x nhidden before linear over vocab", "\n", "decoded", "=", "self", ".", "linear", "(", "output", ".", "contiguous", "(", ")", ".", "view", "(", "-", "1", ",", "self", ".", "nhidden", ")", ")", "\n", "decoded", "=", "decoded", ".", "view", "(", "batch_size", ",", "maxlen", ",", "self", ".", "ntokens", ")", "\n", "\n", "return", "decoded", "\n", "\n"]], "home.repos.pwc.inspect_result.jakezhaojb_ARAE.yelp.models.Seq2Seq.generate": [[497, 536], ["hidden.size", "models.Seq2Seq.start_symbols.data.resize_", "models.Seq2Seq.start_symbols.data.fill_", "models.Seq2Seq.embedding_decoder", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "range", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "models.Seq2Seq.init_hidden", "models.Seq2Seq.decoder", "models.Seq2Seq.linear", "all_indices.append", "models.Seq2Seq.embedding_decoder", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "hidden.unsqueeze", "models.Seq2Seq.init_state", "hidden.unsqueeze", "output.squeeze", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.softmax", "torch.softmax", "torch.softmax", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "hidden.unsqueeze"], "methods", ["home.repos.pwc.inspect_result.jakezhaojb_ARAE.lang.models.Seq2Seq.init_hidden", "home.repos.pwc.inspect_result.jakezhaojb_ARAE.lang.models.Seq2Seq.init_state"], ["", "def", "generate", "(", "self", ",", "hidden", ",", "maxlen", ",", "sample", "=", "False", ",", "temp", "=", "1.0", ")", ":", "\n", "        ", "\"\"\"Generate through decoder; no backprop\"\"\"", "\n", "\n", "batch_size", "=", "hidden", ".", "size", "(", "0", ")", "\n", "\n", "if", "self", ".", "hidden_init", ":", "\n", "# initialize decoder hidden state to encoder output", "\n", "            ", "state", "=", "(", "hidden", ".", "unsqueeze", "(", "0", ")", ",", "self", ".", "init_state", "(", "batch_size", ")", ")", "\n", "", "else", ":", "\n", "            ", "state", "=", "self", ".", "init_hidden", "(", "batch_size", ")", "\n", "\n", "# <sos>", "\n", "", "self", ".", "start_symbols", ".", "data", ".", "resize_", "(", "batch_size", ",", "1", ")", "\n", "self", ".", "start_symbols", ".", "data", ".", "fill_", "(", "1", ")", "\n", "\n", "embedding", "=", "self", ".", "embedding_decoder", "(", "self", ".", "start_symbols", ")", "\n", "inputs", "=", "torch", ".", "cat", "(", "[", "embedding", ",", "hidden", ".", "unsqueeze", "(", "1", ")", "]", ",", "2", ")", "\n", "\n", "# unroll", "\n", "all_indices", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "maxlen", ")", ":", "\n", "            ", "output", ",", "state", "=", "self", ".", "decoder", "(", "inputs", ",", "state", ")", "\n", "overvocab", "=", "self", ".", "linear", "(", "output", ".", "squeeze", "(", "1", ")", ")", "\n", "\n", "if", "not", "sample", ":", "\n", "                ", "vals", ",", "indices", "=", "torch", ".", "max", "(", "overvocab", ",", "1", ")", "\n", "", "else", ":", "\n", "# sampling", "\n", "                ", "probs", "=", "F", ".", "softmax", "(", "overvocab", "/", "temp", ")", "\n", "indices", "=", "torch", ".", "multinomial", "(", "probs", ",", "1", ")", "\n", "\n", "", "all_indices", ".", "append", "(", "indices", ")", "\n", "\n", "embedding", "=", "self", ".", "embedding_decoder", "(", "indices", ")", "\n", "inputs", "=", "torch", ".", "cat", "(", "[", "embedding", ",", "hidden", ".", "unsqueeze", "(", "1", ")", "]", ",", "2", ")", "\n", "\n", "", "max_indices", "=", "torch", ".", "cat", "(", "all_indices", ",", "1", ")", "\n", "\n", "return", "max_indices", "\n", "\n"]], "home.repos.pwc.inspect_result.jakezhaojb_ARAE.yelp.models.load_models": [[538, 572], ["json.load", "json.load", "models.MLP_G", "models.MLP_D", "print", "os.path.join", "os.path.join", "os.path.join", "Seq2Seq2Decoder.load_state_dict", "MLP_G.load_state_dict", "MLP_D.load_state_dict", "open", "open", "models.Seq2Seq", "models.Seq2Seq2Decoder", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "json.load.items"], "function", ["None"], ["", "", "def", "load_models", "(", "load_path", ",", "epoch", ",", "twodecoders", "=", "False", ")", ":", "\n", "    ", "model_args", "=", "json", ".", "load", "(", "open", "(", "\"{}/args.json\"", ".", "format", "(", "load_path", ")", ",", "\"r\"", ")", ")", "\n", "word2idx", "=", "json", ".", "load", "(", "open", "(", "\"{}/vocab.json\"", ".", "format", "(", "load_path", ")", ",", "\"r\"", ")", ")", "\n", "idx2word", "=", "{", "v", ":", "k", "for", "k", ",", "v", "in", "word2idx", ".", "items", "(", ")", "}", "\n", "\n", "if", "not", "twodecoders", ":", "\n", "        ", "autoencoder", "=", "Seq2Seq", "(", "emsize", "=", "model_args", "[", "'emsize'", "]", ",", "\n", "nhidden", "=", "model_args", "[", "'nhidden'", "]", ",", "\n", "ntokens", "=", "model_args", "[", "'ntokens'", "]", ",", "\n", "nlayers", "=", "model_args", "[", "'nlayers'", "]", ",", "\n", "hidden_init", "=", "model_args", "[", "'hidden_init'", "]", ")", "\n", "", "else", ":", "\n", "        ", "autoencoder", "=", "Seq2Seq2Decoder", "(", "emsize", "=", "model_args", "[", "'emsize'", "]", ",", "\n", "nhidden", "=", "model_args", "[", "'nhidden'", "]", ",", "\n", "ntokens", "=", "model_args", "[", "'ntokens'", "]", ",", "\n", "nlayers", "=", "model_args", "[", "'nlayers'", "]", ",", "\n", "hidden_init", "=", "model_args", "[", "'hidden_init'", "]", ")", "\n", "\n", "", "gan_gen", "=", "MLP_G", "(", "ninput", "=", "model_args", "[", "'z_size'", "]", ",", "\n", "noutput", "=", "model_args", "[", "'nhidden'", "]", ",", "\n", "layers", "=", "model_args", "[", "'arch_g'", "]", ")", "\n", "gan_disc", "=", "MLP_D", "(", "ninput", "=", "model_args", "[", "'nhidden'", "]", ",", "\n", "noutput", "=", "1", ",", "\n", "layers", "=", "model_args", "[", "'arch_d'", "]", ")", "\n", "\n", "print", "(", "'Loading models from'", "+", "load_path", ")", "\n", "ae_path", "=", "os", ".", "path", ".", "join", "(", "load_path", ",", "\"autoencoder_model_{}.pt\"", ".", "format", "(", "epoch", ")", ")", "\n", "gen_path", "=", "os", ".", "path", ".", "join", "(", "load_path", ",", "\"gan_gen_model_{}.pt\"", ".", "format", "(", "epoch", ")", ")", "\n", "disc_path", "=", "os", ".", "path", ".", "join", "(", "load_path", ",", "\"gan_disc_model_{}.pt\"", ".", "format", "(", "epoch", ")", ")", "\n", "\n", "autoencoder", ".", "load_state_dict", "(", "torch", ".", "load", "(", "ae_path", ")", ")", "\n", "gan_gen", ".", "load_state_dict", "(", "torch", ".", "load", "(", "gen_path", ")", ")", "\n", "gan_disc", ".", "load_state_dict", "(", "torch", ".", "load", "(", "disc_path", ")", ")", "\n", "return", "model_args", ",", "idx2word", ",", "autoencoder", ",", "gan_gen", ",", "gan_disc", "\n", "\n"]], "home.repos.pwc.inspect_result.jakezhaojb_ARAE.yelp.models.generate": [[574, 612], ["gan_gen.eval", "autoencoder.eval", "gan_gen", "autoencoder.generate", "max_indices.data.cpu().numpy.data.cpu().numpy", "type", "sentences.append", "torch.autograd.Variable", "max_indices.data.cpu().numpy.data.cpu", "type", "type", "type", "torch.autograd.Variable", "ValueError", "truncated_sent.append", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "type", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy"], "function", ["home.repos.pwc.inspect_result.jakezhaojb_ARAE.lang.models.generate"], ["", "def", "generate", "(", "autoencoder", ",", "gan_gen", ",", "z", ",", "vocab", ",", "sample", ",", "maxlen", ")", ":", "\n", "    ", "\"\"\"\n    Assume noise is batch_size x z_size\n    \"\"\"", "\n", "if", "type", "(", "z", ")", "==", "Variable", ":", "\n", "        ", "noise", "=", "z", "\n", "", "elif", "type", "(", "z", ")", "==", "torch", ".", "FloatTensor", "or", "type", "(", "z", ")", "==", "torch", ".", "cuda", ".", "FloatTensor", ":", "\n", "        ", "noise", "=", "Variable", "(", "z", ",", "volatile", "=", "True", ")", "\n", "", "elif", "type", "(", "z", ")", "==", "np", ".", "ndarray", ":", "\n", "        ", "noise", "=", "Variable", "(", "torch", ".", "from_numpy", "(", "z", ")", ".", "float", "(", ")", ",", "volatile", "=", "True", ")", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "\"Unsupported input type (noise): {}\"", ".", "format", "(", "type", "(", "z", ")", ")", ")", "\n", "\n", "", "gan_gen", ".", "eval", "(", ")", "\n", "autoencoder", ".", "eval", "(", ")", "\n", "\n", "# generate from random noise", "\n", "fake_hidden", "=", "gan_gen", "(", "noise", ")", "\n", "max_indices", "=", "autoencoder", ".", "generate", "(", "hidden", "=", "fake_hidden", ",", "\n", "maxlen", "=", "maxlen", ",", "\n", "sample", "=", "sample", ")", "\n", "\n", "max_indices", "=", "max_indices", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "sentences", "=", "[", "]", "\n", "for", "idx", "in", "max_indices", ":", "\n", "# generated sentence", "\n", "        ", "words", "=", "[", "vocab", "[", "x", "]", "for", "x", "in", "idx", "]", "\n", "# truncate sentences to first occurrence of <eos>", "\n", "truncated_sent", "=", "[", "]", "\n", "for", "w", "in", "words", ":", "\n", "            ", "if", "w", "!=", "'<eos>'", ":", "\n", "                ", "truncated_sent", ".", "append", "(", "w", ")", "\n", "", "else", ":", "\n", "                ", "break", "\n", "", "", "sent", "=", "\" \"", ".", "join", "(", "truncated_sent", ")", "\n", "sentences", ".", "append", "(", "sent", ")", "\n", "\n", "", "return", "sentences", "\n", "", ""]], "home.repos.pwc.inspect_result.jakezhaojb_ARAE.yelp.train.save_model": [[234, 242], ["print", "open", "torch.save", "torch.save", "torch.save", "torch.save", "open", "torch.save", "torch.save", "torch.save", "torch.save", "open", "torch.save", "torch.save", "torch.save", "torch.save", "autoencoder.state_dict", "gan_gen.state_dict", "gan_disc.state_dict"], "function", ["None"], ["", "def", "save_model", "(", ")", ":", "\n", "    ", "print", "(", "\"Saving models\"", ")", "\n", "with", "open", "(", "'{}/autoencoder_model.pt'", ".", "format", "(", "args", ".", "outf", ")", ",", "'wb'", ")", "as", "f", ":", "\n", "        ", "torch", ".", "save", "(", "autoencoder", ".", "state_dict", "(", ")", ",", "f", ")", "\n", "", "with", "open", "(", "'{}/gan_gen_model.pt'", ".", "format", "(", "args", ".", "outf", ")", ",", "'wb'", ")", "as", "f", ":", "\n", "        ", "torch", ".", "save", "(", "gan_gen", ".", "state_dict", "(", ")", ",", "f", ")", "\n", "", "with", "open", "(", "'{}/gan_disc_model.pt'", ".", "format", "(", "args", ".", "outf", ")", ",", "'wb'", ")", "as", "f", ":", "\n", "        ", "torch", ".", "save", "(", "gan_disc", ".", "state_dict", "(", ")", ",", "f", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jakezhaojb_ARAE.yelp.train.train_classifier": [[244, 264], ["classifier.train", "classifier.zero_grad", "utils.to_gpu", "utils.to_gpu", "autoencoder().detach", "classifier", "torch.binary_cross_entropy", "F.binary_cross_entropy.backward", "optimizer_classify.step", "classifier.data.round().squeeze", "scores.data.round().squeeze.eq().float().mean", "torch.autograd.Variable", "torch.autograd.Variable", "classifier.squeeze", "torch.zeros().fill_", "torch.zeros().fill_", "torch.zeros().fill_", "torch.zeros().fill_", "autoencoder", "F.binary_cross_entropy.cpu", "classifier.data.round", "scores.data.round().squeeze.eq().float", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "scores.data.round().squeeze.eq", "utils.to_gpu.size"], "function", ["home.repos.pwc.inspect_result.jakezhaojb_ARAE.lang.train.train", "home.repos.pwc.inspect_result.jakezhaojb_ARAE.lang.utils.to_gpu", "home.repos.pwc.inspect_result.jakezhaojb_ARAE.lang.utils.to_gpu"], ["", "", "def", "train_classifier", "(", "whichclass", ",", "batch", ")", ":", "\n", "    ", "classifier", ".", "train", "(", ")", "\n", "classifier", ".", "zero_grad", "(", ")", "\n", "\n", "source", ",", "target", ",", "lengths", "=", "batch", "\n", "source", "=", "to_gpu", "(", "args", ".", "cuda", ",", "Variable", "(", "source", ")", ")", "\n", "labels", "=", "to_gpu", "(", "args", ".", "cuda", ",", "Variable", "(", "torch", ".", "zeros", "(", "source", ".", "size", "(", "0", ")", ")", ".", "fill_", "(", "whichclass", "-", "1", ")", ")", ")", "\n", "\n", "# Train", "\n", "code", "=", "autoencoder", "(", "0", ",", "source", ",", "lengths", ",", "noise", "=", "False", ",", "encode_only", "=", "True", ")", ".", "detach", "(", ")", "\n", "scores", "=", "classifier", "(", "code", ")", "\n", "classify_loss", "=", "F", ".", "binary_cross_entropy", "(", "scores", ".", "squeeze", "(", "1", ")", ",", "labels", ")", "\n", "classify_loss", ".", "backward", "(", ")", "\n", "optimizer_classify", ".", "step", "(", ")", "\n", "classify_loss", "=", "classify_loss", ".", "cpu", "(", ")", ".", "data", "[", "0", "]", "\n", "\n", "pred", "=", "scores", ".", "data", ".", "round", "(", ")", ".", "squeeze", "(", "1", ")", "\n", "accuracy", "=", "pred", ".", "eq", "(", "labels", ".", "data", ")", ".", "float", "(", ")", ".", "mean", "(", ")", "\n", "\n", "return", "classify_loss", ",", "accuracy", "\n", "\n"]], "home.repos.pwc.inspect_result.jakezhaojb_ARAE.yelp.train.grad_hook_cla": [[266, 268], ["None"], "function", ["None"], ["", "def", "grad_hook_cla", "(", "grad", ")", ":", "\n", "    ", "return", "grad", "*", "args", ".", "lambda_class", "\n", "\n"]], "home.repos.pwc.inspect_result.jakezhaojb_ARAE.yelp.train.classifier_regularize": [[270, 291], ["autoencoder.train", "autoencoder.zero_grad", "utils.to_gpu", "utils.to_gpu", "abs", "utils.to_gpu", "autoencoder", "autoencoder.register_hook", "classifier", "torch.binary_cross_entropy", "F.binary_cross_entropy.backward", "torch.nn.utils.clip_grad_norm", "torch.nn.utils.clip_grad_norm", "torch.nn.utils.clip_grad_norm", "torch.nn.utils.clip_grad_norm", "optimizer_ae.step", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "classifier.squeeze", "autoencoder.parameters", "torch.zeros().fill_", "torch.zeros().fill_", "torch.zeros().fill_", "torch.zeros().fill_", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "utils.to_gpu.size"], "function", ["home.repos.pwc.inspect_result.jakezhaojb_ARAE.lang.train.train", "home.repos.pwc.inspect_result.jakezhaojb_ARAE.lang.utils.to_gpu", "home.repos.pwc.inspect_result.jakezhaojb_ARAE.lang.utils.to_gpu", "home.repos.pwc.inspect_result.jakezhaojb_ARAE.lang.utils.to_gpu"], ["", "def", "classifier_regularize", "(", "whichclass", ",", "batch", ")", ":", "\n", "    ", "autoencoder", ".", "train", "(", ")", "\n", "autoencoder", ".", "zero_grad", "(", ")", "\n", "\n", "source", ",", "target", ",", "lengths", "=", "batch", "\n", "source", "=", "to_gpu", "(", "args", ".", "cuda", ",", "Variable", "(", "source", ")", ")", "\n", "target", "=", "to_gpu", "(", "args", ".", "cuda", ",", "Variable", "(", "target", ")", ")", "\n", "flippedclass", "=", "abs", "(", "2", "-", "whichclass", ")", "\n", "labels", "=", "to_gpu", "(", "args", ".", "cuda", ",", "Variable", "(", "torch", ".", "zeros", "(", "source", ".", "size", "(", "0", ")", ")", ".", "fill_", "(", "flippedclass", ")", ")", ")", "\n", "\n", "# Train", "\n", "code", "=", "autoencoder", "(", "0", ",", "source", ",", "lengths", ",", "noise", "=", "False", ",", "encode_only", "=", "True", ")", "\n", "code", ".", "register_hook", "(", "grad_hook_cla", ")", "\n", "scores", "=", "classifier", "(", "code", ")", "\n", "classify_reg_loss", "=", "F", ".", "binary_cross_entropy", "(", "scores", ".", "squeeze", "(", "1", ")", ",", "labels", ")", "\n", "classify_reg_loss", ".", "backward", "(", ")", "\n", "\n", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm", "(", "autoencoder", ".", "parameters", "(", ")", ",", "args", ".", "clip", ")", "\n", "optimizer_ae", ".", "step", "(", ")", "\n", "\n", "return", "classify_reg_loss", "\n", "\n"]], "home.repos.pwc.inspect_result.jakezhaojb_ARAE.yelp.train.evaluate_autoencoder": [[293, 361], ["autoencoder.eval", "len", "enumerate", "utils.to_gpu", "utils.to_gpu", "target.view().data.cpu().numpy.gt", "target.view().data.cpu().numpy.masked_select", "target.gt.unsqueeze().expand", "autoencoder", "torch.autograd.Variable", "torch.autograd.Variable", "target.gt.size", "autoencoder", "autoencoder.view", "output.view.masked_select().view", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "autoencoder.generate", "autoencoder", "autoencoder.view", "output.view.masked_select().view", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "autoencoder.generate", "criterion_ce", "open", "open", "max_indices1.view().data.cpu().numpy.view().data.cpu().numpy", "max_indices2.view().data.cpu().numpy.view().data.cpu().numpy", "target.view().data.cpu().numpy.view().data.cpu().numpy", "zip", "len", "target.gt.unsqueeze", "f_from.write", "f_from.write", "f_trans.write", "f_trans.write", "output.view.masked_select", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "output.view.masked_select", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "max_indices1.view().data.cpu().numpy.view().data.cpu", "max_indices2.view().data.cpu().numpy.view().data.cpu", "target.view().data.cpu().numpy.view().data.cpu", "max_indices1.view().data.cpu().numpy.eq().float", "max_indices2.view().data.cpu().numpy.eq().float", "max_indices1.view().data.cpu().numpy.eq", "max_indices2.view().data.cpu().numpy.eq", "max_indices1.view().data.cpu().numpy.view", "max_indices2.view().data.cpu().numpy.view", "target.view().data.cpu().numpy.view", "autoencoder.size", "autoencoder.size", "autoencoder.size"], "function", ["home.repos.pwc.inspect_result.jakezhaojb_ARAE.lang.utils.to_gpu", "home.repos.pwc.inspect_result.jakezhaojb_ARAE.lang.utils.to_gpu", "home.repos.pwc.inspect_result.jakezhaojb_ARAE.lang.models.generate", "home.repos.pwc.inspect_result.jakezhaojb_ARAE.lang.models.generate", "home.repos.pwc.inspect_result.jakezhaojb_ARAE.lang.preprocess_lm.Indexer.write", "home.repos.pwc.inspect_result.jakezhaojb_ARAE.lang.preprocess_lm.Indexer.write", "home.repos.pwc.inspect_result.jakezhaojb_ARAE.lang.preprocess_lm.Indexer.write", "home.repos.pwc.inspect_result.jakezhaojb_ARAE.lang.preprocess_lm.Indexer.write"], ["", "def", "evaluate_autoencoder", "(", "whichdecoder", ",", "data_source", ",", "epoch", ")", ":", "\n", "# Turn on evaluation mode which disables dropout.", "\n", "    ", "autoencoder", ".", "eval", "(", ")", "\n", "total_loss", "=", "0", "\n", "ntokens", "=", "len", "(", "corpus", ".", "dictionary", ".", "word2idx", ")", "\n", "all_accuracies", "=", "0", "\n", "bcnt", "=", "0", "\n", "for", "i", ",", "batch", "in", "enumerate", "(", "data_source", ")", ":", "\n", "        ", "source", ",", "target", ",", "lengths", "=", "batch", "\n", "source", "=", "to_gpu", "(", "args", ".", "cuda", ",", "Variable", "(", "source", ",", "volatile", "=", "True", ")", ")", "\n", "target", "=", "to_gpu", "(", "args", ".", "cuda", ",", "Variable", "(", "target", ",", "volatile", "=", "True", ")", ")", "\n", "\n", "mask", "=", "target", ".", "gt", "(", "0", ")", "\n", "masked_target", "=", "target", ".", "masked_select", "(", "mask", ")", "\n", "# examples x ntokens", "\n", "output_mask", "=", "mask", ".", "unsqueeze", "(", "1", ")", ".", "expand", "(", "mask", ".", "size", "(", "0", ")", ",", "ntokens", ")", "\n", "\n", "hidden", "=", "autoencoder", "(", "0", ",", "source", ",", "lengths", ",", "noise", "=", "False", ",", "encode_only", "=", "True", ")", "\n", "\n", "# output: batch x seq_len x ntokens", "\n", "if", "whichdecoder", "==", "1", ":", "\n", "            ", "output", "=", "autoencoder", "(", "1", ",", "source", ",", "lengths", ",", "noise", "=", "False", ")", "\n", "flattened_output", "=", "output", ".", "view", "(", "-", "1", ",", "ntokens", ")", "\n", "masked_output", "=", "flattened_output", ".", "masked_select", "(", "output_mask", ")", ".", "view", "(", "-", "1", ",", "ntokens", ")", "\n", "# accuracy", "\n", "max_vals1", ",", "max_indices1", "=", "torch", ".", "max", "(", "masked_output", ",", "1", ")", "\n", "all_accuracies", "+=", "torch", ".", "mean", "(", "max_indices1", ".", "eq", "(", "masked_target", ")", ".", "float", "(", ")", ")", ".", "data", "[", "0", "]", "\n", "\n", "max_values1", ",", "max_indices1", "=", "torch", ".", "max", "(", "output", ",", "2", ")", "\n", "max_indices2", "=", "autoencoder", ".", "generate", "(", "2", ",", "hidden", ",", "maxlen", "=", "50", ")", "\n", "", "else", ":", "\n", "            ", "output", "=", "autoencoder", "(", "2", ",", "source", ",", "lengths", ",", "noise", "=", "False", ")", "\n", "flattened_output", "=", "output", ".", "view", "(", "-", "1", ",", "ntokens", ")", "\n", "masked_output", "=", "flattened_output", ".", "masked_select", "(", "output_mask", ")", ".", "view", "(", "-", "1", ",", "ntokens", ")", "\n", "# accuracy", "\n", "max_vals2", ",", "max_indices2", "=", "torch", ".", "max", "(", "masked_output", ",", "1", ")", "\n", "all_accuracies", "+=", "torch", ".", "mean", "(", "max_indices2", ".", "eq", "(", "masked_target", ")", ".", "float", "(", ")", ")", ".", "data", "[", "0", "]", "\n", "\n", "max_values2", ",", "max_indices2", "=", "torch", ".", "max", "(", "output", ",", "2", ")", "\n", "max_indices1", "=", "autoencoder", ".", "generate", "(", "1", ",", "hidden", ",", "maxlen", "=", "50", ")", "\n", "\n", "", "total_loss", "+=", "criterion_ce", "(", "masked_output", "/", "args", ".", "temp", ",", "masked_target", ")", ".", "data", "\n", "bcnt", "+=", "1", "\n", "\n", "aeoutf_from", "=", "\"{}/{}_output_decoder_{}_from.txt\"", ".", "format", "(", "args", ".", "outf", ",", "epoch", ",", "whichdecoder", ")", "\n", "aeoutf_tran", "=", "\"{}/{}_output_decoder_{}_tran.txt\"", ".", "format", "(", "args", ".", "outf", ",", "epoch", ",", "whichdecoder", ")", "\n", "with", "open", "(", "aeoutf_from", ",", "'w'", ")", "as", "f_from", ",", "open", "(", "aeoutf_tran", ",", "'w'", ")", "as", "f_trans", ":", "\n", "            ", "max_indices1", "=", "max_indices1", ".", "view", "(", "output", ".", "size", "(", "0", ")", ",", "-", "1", ")", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "max_indices2", "=", "max_indices2", ".", "view", "(", "output", ".", "size", "(", "0", ")", ",", "-", "1", ")", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "target", "=", "target", ".", "view", "(", "output", ".", "size", "(", "0", ")", ",", "-", "1", ")", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "tran_indices", "=", "max_indices2", "if", "whichdecoder", "==", "1", "else", "max_indices1", "\n", "for", "t", ",", "tran_idx", "in", "zip", "(", "target", ",", "tran_indices", ")", ":", "\n", "# real sentence", "\n", "                ", "chars", "=", "\" \"", ".", "join", "(", "[", "corpus", ".", "dictionary", ".", "idx2word", "[", "x", "]", "for", "x", "in", "t", "]", ")", "\n", "f_from", ".", "write", "(", "chars", ")", "\n", "f_from", ".", "write", "(", "\"\\n\"", ")", "\n", "# transfer sentence", "\n", "chars", "=", "\" \"", ".", "join", "(", "[", "corpus", ".", "dictionary", ".", "idx2word", "[", "x", "]", "for", "x", "in", "tran_idx", "]", ")", "\n", "f_trans", ".", "write", "(", "chars", ")", "\n", "f_trans", ".", "write", "(", "\"\\n\"", ")", "\n", "\n", "", "", "", "return", "total_loss", "[", "0", "]", "/", "len", "(", "data_source", ")", ",", "all_accuracies", "/", "bcnt", "\n", "\n"]], "home.repos.pwc.inspect_result.jakezhaojb_ARAE.yelp.train.evaluate_generator": [[363, 387], ["gan_gen.eval", "autoencoder.eval", "gan_gen", "autoencoder.generate", "open", "max_indices.data.cpu().numpy.data.cpu().numpy", "f.write", "f.write", "max_indices.data.cpu().numpy.data.cpu", "truncated_sent.append"], "function", ["home.repos.pwc.inspect_result.jakezhaojb_ARAE.lang.models.generate", "home.repos.pwc.inspect_result.jakezhaojb_ARAE.lang.preprocess_lm.Indexer.write", "home.repos.pwc.inspect_result.jakezhaojb_ARAE.lang.preprocess_lm.Indexer.write"], ["", "def", "evaluate_generator", "(", "whichdecoder", ",", "noise", ",", "epoch", ")", ":", "\n", "    ", "gan_gen", ".", "eval", "(", ")", "\n", "autoencoder", ".", "eval", "(", ")", "\n", "\n", "# generate from fixed random noise", "\n", "fake_hidden", "=", "gan_gen", "(", "noise", ")", "\n", "max_indices", "=", "autoencoder", ".", "generate", "(", "whichdecoder", ",", "fake_hidden", ",", "maxlen", "=", "50", ",", "sample", "=", "args", ".", "sample", ")", "\n", "\n", "with", "open", "(", "\"%s/%s_generated%d.txt\"", "%", "(", "args", ".", "outf", ",", "epoch", ",", "whichdecoder", ")", ",", "\"w\"", ")", "as", "f", ":", "\n", "        ", "max_indices", "=", "max_indices", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "for", "idx", "in", "max_indices", ":", "\n", "# generated sentence", "\n", "            ", "words", "=", "[", "corpus", ".", "dictionary", ".", "idx2word", "[", "x", "]", "for", "x", "in", "idx", "]", "\n", "# truncate sentences to first occurrence of <eos>", "\n", "truncated_sent", "=", "[", "]", "\n", "for", "w", "in", "words", ":", "\n", "                ", "if", "w", "!=", "'<eos>'", ":", "\n", "                    ", "truncated_sent", ".", "append", "(", "w", ")", "\n", "", "else", ":", "\n", "                    ", "break", "\n", "", "", "chars", "=", "\" \"", ".", "join", "(", "truncated_sent", ")", "\n", "f", ".", "write", "(", "chars", ")", "\n", "f", ".", "write", "(", "\"\\n\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jakezhaojb_ARAE.yelp.train.train_ae": [[389, 436], ["autoencoder.train", "optimizer_ae.zero_grad", "utils.to_gpu", "utils.to_gpu", "utils.to_gpu.gt", "utils.to_gpu.masked_select", "target.gt.unsqueeze().expand", "autoencoder", "autoencoder.view", "output.view.masked_select().view", "criterion_ce", "criterion_ce.backward", "torch.nn.utils.clip_grad_norm", "torch.nn.utils.clip_grad_norm", "torch.nn.utils.clip_grad_norm", "torch.nn.utils.clip_grad_norm", "optimizer_ae.step", "torch.autograd.Variable", "torch.autograd.Variable", "target.gt.size", "autoencoder.parameters", "torch.softmax", "torch.max", "torch.max", "torch.max", "torch.max", "print", "time.time", "target.gt.unsqueeze", "output.view.masked_select", "time.time", "open", "f.write", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "len", "math.exp", "max_indices.eq().float", "len", "math.exp", "max_indices.eq"], "function", ["home.repos.pwc.inspect_result.jakezhaojb_ARAE.lang.train.train", "home.repos.pwc.inspect_result.jakezhaojb_ARAE.lang.utils.to_gpu", "home.repos.pwc.inspect_result.jakezhaojb_ARAE.lang.utils.to_gpu", "home.repos.pwc.inspect_result.jakezhaojb_ARAE.lang.preprocess_lm.Indexer.write"], ["", "", "", "def", "train_ae", "(", "whichdecoder", ",", "batch", ",", "total_loss_ae", ",", "start_time", ",", "i", ")", ":", "\n", "    ", "autoencoder", ".", "train", "(", ")", "\n", "optimizer_ae", ".", "zero_grad", "(", ")", "\n", "\n", "source", ",", "target", ",", "lengths", "=", "batch", "\n", "source", "=", "to_gpu", "(", "args", ".", "cuda", ",", "Variable", "(", "source", ")", ")", "\n", "target", "=", "to_gpu", "(", "args", ".", "cuda", ",", "Variable", "(", "target", ")", ")", "\n", "\n", "mask", "=", "target", ".", "gt", "(", "0", ")", "\n", "masked_target", "=", "target", ".", "masked_select", "(", "mask", ")", "\n", "output_mask", "=", "mask", ".", "unsqueeze", "(", "1", ")", ".", "expand", "(", "mask", ".", "size", "(", "0", ")", ",", "ntokens", ")", "\n", "output", "=", "autoencoder", "(", "whichdecoder", ",", "source", ",", "lengths", ",", "noise", "=", "True", ")", "\n", "flat_output", "=", "output", ".", "view", "(", "-", "1", ",", "ntokens", ")", "\n", "masked_output", "=", "flat_output", ".", "masked_select", "(", "output_mask", ")", ".", "view", "(", "-", "1", ",", "ntokens", ")", "\n", "loss", "=", "criterion_ce", "(", "masked_output", "/", "args", ".", "temp", ",", "masked_target", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "\n", "# `clip_grad_norm` to prevent exploding gradient in RNNs / LSTMs", "\n", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm", "(", "autoencoder", ".", "parameters", "(", ")", ",", "args", ".", "clip", ")", "\n", "optimizer_ae", ".", "step", "(", ")", "\n", "\n", "total_loss_ae", "+=", "loss", ".", "data", "\n", "\n", "accuracy", "=", "None", "\n", "if", "i", "%", "args", ".", "log_interval", "==", "0", "and", "i", ">", "0", ":", "\n", "        ", "probs", "=", "F", ".", "softmax", "(", "masked_output", ",", "dim", "=", "-", "1", ")", "\n", "max_vals", ",", "max_indices", "=", "torch", ".", "max", "(", "probs", ",", "1", ")", "\n", "accuracy", "=", "torch", ".", "mean", "(", "max_indices", ".", "eq", "(", "masked_target", ")", ".", "float", "(", ")", ")", ".", "data", "[", "0", "]", "\n", "cur_loss", "=", "total_loss_ae", "[", "0", "]", "/", "args", ".", "log_interval", "\n", "elapsed", "=", "time", ".", "time", "(", ")", "-", "start_time", "\n", "print", "(", "'| epoch {:3d} | {:5d}/{:5d} batches | ms/batch {:5.2f} | '", "\n", "'loss {:5.2f} | ppl {:8.2f} | acc {:8.2f}'", "\n", ".", "format", "(", "epoch", ",", "i", ",", "len", "(", "train1_data", ")", ",", "\n", "elapsed", "*", "1000", "/", "args", ".", "log_interval", ",", "\n", "cur_loss", ",", "math", ".", "exp", "(", "cur_loss", ")", ",", "accuracy", ")", ")", "\n", "\n", "with", "open", "(", "\"{}/log.txt\"", ".", "format", "(", "args", ".", "outf", ")", ",", "'a'", ")", "as", "f", ":", "\n", "            ", "f", ".", "write", "(", "'| epoch {:3d} | {:5d}/{:5d} batches | ms/batch {:5.2f} | '", "\n", "'loss {:5.2f} | ppl {:8.2f} | acc {:8.2f}\\n'", ".", "\n", "format", "(", "epoch", ",", "i", ",", "len", "(", "train1_data", ")", ",", "\n", "elapsed", "*", "1000", "/", "args", ".", "log_interval", ",", "\n", "cur_loss", ",", "math", ".", "exp", "(", "cur_loss", ")", ",", "accuracy", ")", ")", "\n", "\n", "", "total_loss_ae", "=", "0", "\n", "start_time", "=", "time", ".", "time", "(", ")", "\n", "\n", "", "return", "total_loss_ae", ",", "start_time", "\n", "\n"]], "home.repos.pwc.inspect_result.jakezhaojb_ARAE.yelp.train.train_gan_g": [[438, 451], ["gan_gen.train", "gan_gen.zero_grad", "utils.to_gpu", "utils.to_gpu.data.normal_", "gan_gen", "gan_disc", "gan_disc.backward", "optimizer_gan_g.step", "torch.autograd.Variable", "torch.ones", "torch.ones", "torch.ones", "torch.ones"], "function", ["home.repos.pwc.inspect_result.jakezhaojb_ARAE.lang.train.train", "home.repos.pwc.inspect_result.jakezhaojb_ARAE.lang.utils.to_gpu"], ["", "def", "train_gan_g", "(", ")", ":", "\n", "    ", "gan_gen", ".", "train", "(", ")", "\n", "gan_gen", ".", "zero_grad", "(", ")", "\n", "\n", "noise", "=", "to_gpu", "(", "args", ".", "cuda", ",", "\n", "Variable", "(", "torch", ".", "ones", "(", "args", ".", "batch_size", ",", "args", ".", "z_size", ")", ")", ")", "\n", "noise", ".", "data", ".", "normal_", "(", "0", ",", "1", ")", "\n", "fake_hidden", "=", "gan_gen", "(", "noise", ")", "\n", "errG", "=", "gan_disc", "(", "fake_hidden", ")", "\n", "errG", ".", "backward", "(", "one", ")", "\n", "optimizer_gan_g", ".", "step", "(", ")", "\n", "\n", "return", "errG", "\n", "\n"]], "home.repos.pwc.inspect_result.jakezhaojb_ARAE.yelp.train.grad_hook": [[453, 455], ["None"], "function", ["None"], ["", "def", "grad_hook", "(", "grad", ")", ":", "\n", "    ", "return", "grad", "*", "args", ".", "grad_lambda", "\n", "\n"]], "home.repos.pwc.inspect_result.jakezhaojb_ARAE.yelp.train.calc_gradient_penalty": [[458, 474], ["real_data.size", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "alpha.cuda.expand", "alpha.cuda.cuda", "torch.autograd.Variable", "netD", "gradients.view.view", "real_data.size", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "gradients.view.size", "torch.ones().cuda", "torch.ones().cuda", "torch.ones().cuda", "torch.ones().cuda", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "gradients.view.norm", "netD.size"], "function", ["None"], ["def", "calc_gradient_penalty", "(", "netD", ",", "real_data", ",", "fake_data", ")", ":", "\n", "    ", "bsz", "=", "real_data", ".", "size", "(", "0", ")", "\n", "alpha", "=", "torch", ".", "rand", "(", "bsz", ",", "1", ")", "\n", "alpha", "=", "alpha", ".", "expand", "(", "bsz", ",", "real_data", ".", "size", "(", "1", ")", ")", "# only works for 2D XXX", "\n", "alpha", "=", "alpha", ".", "cuda", "(", ")", "\n", "interpolates", "=", "alpha", "*", "real_data", "+", "(", "(", "1", "-", "alpha", ")", "*", "fake_data", ")", "\n", "interpolates", "=", "Variable", "(", "interpolates", ",", "requires_grad", "=", "True", ")", "\n", "disc_interpolates", "=", "netD", "(", "interpolates", ")", "\n", "\n", "gradients", "=", "torch", ".", "autograd", ".", "grad", "(", "outputs", "=", "disc_interpolates", ",", "inputs", "=", "interpolates", ",", "\n", "grad_outputs", "=", "torch", ".", "ones", "(", "disc_interpolates", ".", "size", "(", ")", ")", ".", "cuda", "(", ")", ",", "\n", "create_graph", "=", "True", ",", "retain_graph", "=", "True", ",", "only_inputs", "=", "True", ")", "[", "0", "]", "\n", "gradients", "=", "gradients", ".", "view", "(", "gradients", ".", "size", "(", "0", ")", ",", "-", "1", ")", "\n", "\n", "gradient_penalty", "=", "(", "(", "gradients", ".", "norm", "(", "2", ",", "dim", "=", "1", ")", "-", "1", ")", "**", "2", ")", ".", "mean", "(", ")", "*", "args", ".", "gan_gp_lambda", "\n", "return", "gradient_penalty", "\n", "\n"]], "home.repos.pwc.inspect_result.jakezhaojb_ARAE.yelp.train.train_gan_d": [[476, 512], ["gan_disc.train", "optimizer_gan_d.zero_grad", "utils.to_gpu", "utils.to_gpu", "autoencoder", "gan_disc", "gan_disc.backward", "utils.to_gpu", "utils.to_gpu.data.normal_", "gan_gen", "gan_disc", "gan_disc.backward", "train.calc_gradient_penalty", "calc_gradient_penalty.backward", "optimizer_gan_d.step", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "gan_gen.detach", "torch.ones", "torch.ones", "torch.ones", "torch.ones"], "function", ["home.repos.pwc.inspect_result.jakezhaojb_ARAE.lang.train.train", "home.repos.pwc.inspect_result.jakezhaojb_ARAE.lang.utils.to_gpu", "home.repos.pwc.inspect_result.jakezhaojb_ARAE.lang.utils.to_gpu", "home.repos.pwc.inspect_result.jakezhaojb_ARAE.lang.utils.to_gpu", "home.repos.pwc.inspect_result.jakezhaojb_ARAE.lang.train.calc_gradient_penalty"], ["", "def", "train_gan_d", "(", "whichdecoder", ",", "batch", ")", ":", "\n", "    ", "gan_disc", ".", "train", "(", ")", "\n", "optimizer_gan_d", ".", "zero_grad", "(", ")", "\n", "\n", "# positive samples ----------------------------", "\n", "# generate real codes", "\n", "source", ",", "target", ",", "lengths", "=", "batch", "\n", "source", "=", "to_gpu", "(", "args", ".", "cuda", ",", "Variable", "(", "source", ")", ")", "\n", "target", "=", "to_gpu", "(", "args", ".", "cuda", ",", "Variable", "(", "target", ")", ")", "\n", "\n", "# batch_size x nhidden", "\n", "real_hidden", "=", "autoencoder", "(", "whichdecoder", ",", "source", ",", "lengths", ",", "noise", "=", "False", ",", "encode_only", "=", "True", ")", "\n", "\n", "# loss / backprop", "\n", "errD_real", "=", "gan_disc", "(", "real_hidden", ")", "\n", "errD_real", ".", "backward", "(", "one", ")", "\n", "\n", "# negative samples ----------------------------", "\n", "# generate fake codes", "\n", "noise", "=", "to_gpu", "(", "args", ".", "cuda", ",", "\n", "Variable", "(", "torch", ".", "ones", "(", "args", ".", "batch_size", ",", "args", ".", "z_size", ")", ")", ")", "\n", "noise", ".", "data", ".", "normal_", "(", "0", ",", "1", ")", "\n", "\n", "# loss / backprop", "\n", "fake_hidden", "=", "gan_gen", "(", "noise", ")", "\n", "errD_fake", "=", "gan_disc", "(", "fake_hidden", ".", "detach", "(", ")", ")", "\n", "errD_fake", ".", "backward", "(", "mone", ")", "\n", "\n", "# gradient penalty", "\n", "gradient_penalty", "=", "calc_gradient_penalty", "(", "gan_disc", ",", "real_hidden", ".", "data", ",", "fake_hidden", ".", "data", ")", "\n", "gradient_penalty", ".", "backward", "(", ")", "\n", "\n", "optimizer_gan_d", ".", "step", "(", ")", "\n", "errD", "=", "-", "(", "errD_real", "-", "errD_fake", ")", "\n", "\n", "return", "errD", ",", "errD_real", ",", "errD_fake", "\n", "\n"]], "home.repos.pwc.inspect_result.jakezhaojb_ARAE.yelp.train.train_gan_d_into_ae": [[514, 530], ["autoencoder.train", "optimizer_ae.zero_grad", "utils.to_gpu", "utils.to_gpu", "autoencoder", "autoencoder.register_hook", "gan_disc", "gan_disc.backward", "torch.nn.utils.clip_grad_norm", "torch.nn.utils.clip_grad_norm", "torch.nn.utils.clip_grad_norm", "torch.nn.utils.clip_grad_norm", "optimizer_ae.step", "torch.autograd.Variable", "torch.autograd.Variable", "autoencoder.parameters"], "function", ["home.repos.pwc.inspect_result.jakezhaojb_ARAE.lang.train.train", "home.repos.pwc.inspect_result.jakezhaojb_ARAE.lang.utils.to_gpu", "home.repos.pwc.inspect_result.jakezhaojb_ARAE.lang.utils.to_gpu"], ["", "def", "train_gan_d_into_ae", "(", "whichdecoder", ",", "batch", ")", ":", "\n", "    ", "autoencoder", ".", "train", "(", ")", "\n", "optimizer_ae", ".", "zero_grad", "(", ")", "\n", "\n", "source", ",", "target", ",", "lengths", "=", "batch", "\n", "source", "=", "to_gpu", "(", "args", ".", "cuda", ",", "Variable", "(", "source", ")", ")", "\n", "target", "=", "to_gpu", "(", "args", ".", "cuda", ",", "Variable", "(", "target", ")", ")", "\n", "real_hidden", "=", "autoencoder", "(", "whichdecoder", ",", "source", ",", "lengths", ",", "noise", "=", "False", ",", "encode_only", "=", "True", ")", "\n", "real_hidden", ".", "register_hook", "(", "grad_hook", ")", "\n", "errD_real", "=", "gan_disc", "(", "real_hidden", ")", "\n", "errD_real", ".", "backward", "(", "mone", ")", "\n", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm", "(", "autoencoder", ".", "parameters", "(", ")", ",", "args", ".", "clip", ")", "\n", "\n", "optimizer_ae", ".", "step", "(", ")", "\n", "\n", "return", "errD_real", "\n", "\n"]], "home.repos.pwc.inspect_result.jakezhaojb_ARAE.yelp.utils.Dictionary.__init__": [[23, 35], ["word2idx.items"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "word2idx", "=", "None", ")", ":", "\n", "        ", "if", "word2idx", "is", "None", ":", "\n", "            ", "self", ".", "word2idx", "=", "{", "}", "\n", "self", ".", "idx2word", "=", "{", "}", "\n", "self", ".", "word2idx", "[", "PAD_WORD", "]", "=", "0", "\n", "self", ".", "word2idx", "[", "BOS_WORD", "]", "=", "1", "\n", "self", ".", "word2idx", "[", "EOS_WORD", "]", "=", "2", "\n", "self", ".", "word2idx", "[", "UNK", "]", "=", "3", "\n", "self", ".", "wordcounts", "=", "{", "}", "\n", "", "else", ":", "\n", "            ", "self", ".", "word2idx", "=", "word2idx", "\n", "self", ".", "idx2word", "=", "{", "v", ":", "k", "for", "k", ",", "v", "in", "word2idx", ".", "items", "(", ")", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.jakezhaojb_ARAE.yelp.utils.Dictionary.add_word": [[37, 42], ["None"], "methods", ["None"], ["", "", "def", "add_word", "(", "self", ",", "word", ")", ":", "\n", "        ", "if", "word", "not", "in", "self", ".", "wordcounts", ":", "\n", "            ", "self", ".", "wordcounts", "[", "word", "]", "=", "1", "\n", "", "else", ":", "\n", "            ", "self", ".", "wordcounts", "[", "word", "]", "+=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.jakezhaojb_ARAE.yelp.utils.Dictionary.prune_vocab": [[44, 66], ["utils.Dictionary.pruned_vocab.sort", "print", "vocab_list.sort", "min", "utils.Dictionary.wordcounts.items", "len", "len", "len", "len", "utils.Dictionary.word2idx.items"], "methods", ["None"], ["", "", "def", "prune_vocab", "(", "self", ",", "k", "=", "5", ",", "cnt", "=", "False", ")", ":", "\n", "# get all words and their respective counts", "\n", "        ", "vocab_list", "=", "[", "(", "word", ",", "count", ")", "for", "word", ",", "count", "in", "self", ".", "wordcounts", ".", "items", "(", ")", "]", "\n", "if", "cnt", ":", "\n", "# prune by count", "\n", "            ", "self", ".", "pruned_vocab", "=", "{", "pair", "[", "0", "]", ":", "pair", "[", "1", "]", "for", "pair", "in", "vocab_list", "if", "pair", "[", "1", "]", ">", "k", "}", "\n", "", "else", ":", "\n", "# prune by most frequently seen words", "\n", "            ", "vocab_list", ".", "sort", "(", "key", "=", "lambda", "x", ":", "(", "x", "[", "1", "]", ",", "x", "[", "0", "]", ")", ",", "reverse", "=", "True", ")", "\n", "k", "=", "min", "(", "k", ",", "len", "(", "vocab_list", ")", ")", "\n", "self", ".", "pruned_vocab", "=", "[", "pair", "[", "0", "]", "for", "pair", "in", "vocab_list", "[", ":", "k", "]", "]", "\n", "# sort to make vocabulary determistic", "\n", "", "self", ".", "pruned_vocab", ".", "sort", "(", ")", "\n", "\n", "# add all chosen words to new vocabulary/dict", "\n", "for", "word", "in", "self", ".", "pruned_vocab", ":", "\n", "            ", "if", "word", "not", "in", "self", ".", "word2idx", ":", "\n", "                ", "self", ".", "word2idx", "[", "word", "]", "=", "len", "(", "self", ".", "word2idx", ")", "\n", "", "", "print", "(", "\"Original vocab {}; Pruned to {}\"", ".", "\n", "format", "(", "len", "(", "self", ".", "wordcounts", ")", ",", "len", "(", "self", ".", "word2idx", ")", ")", ")", "\n", "self", ".", "idx2word", "=", "{", "v", ":", "k", "for", "k", ",", "v", "in", "self", ".", "word2idx", ".", "items", "(", ")", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.jakezhaojb_ARAE.yelp.utils.Dictionary.__len__": [[67, 69], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "word2idx", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jakezhaojb_ARAE.yelp.utils.Corpus.__init__": [[72, 89], ["utils.Dictionary", "utils.Corpus.make_vocab", "utils.Corpus.tokenize", "utils.Corpus.forvocab.append"], "methods", ["home.repos.pwc.inspect_result.jakezhaojb_ARAE.lang.utils.Corpus.make_vocab", "home.repos.pwc.inspect_result.jakezhaojb_ARAE.lang.utils.Corpus.tokenize"], ["    ", "def", "__init__", "(", "self", ",", "datafiles", ",", "maxlen", ",", "vocab_size", "=", "11000", ",", "lowercase", "=", "False", ",", "vocab", "=", "None", ",", "debug", "=", "False", ")", ":", "\n", "        ", "self", ".", "dictionary", "=", "Dictionary", "(", "vocab", ")", "\n", "self", ".", "maxlen", "=", "maxlen", "\n", "self", ".", "lowercase", "=", "lowercase", "\n", "self", ".", "vocab_size", "=", "vocab_size", "\n", "self", ".", "datafiles", "=", "datafiles", "\n", "self", ".", "forvocab", "=", "[", "]", "\n", "self", ".", "data", "=", "{", "}", "\n", "\n", "if", "vocab", "is", "None", ":", "\n", "            ", "for", "path", ",", "name", ",", "fvocab", "in", "datafiles", ":", "\n", "                ", "if", "fvocab", "or", "debug", ":", "\n", "                    ", "self", ".", "forvocab", ".", "append", "(", "path", ")", "\n", "", "", "self", ".", "make_vocab", "(", ")", "\n", "\n", "", "for", "path", ",", "name", ",", "_", "in", "datafiles", ":", "\n", "            ", "self", ".", "data", "[", "name", "]", "=", "self", ".", "tokenize", "(", "path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jakezhaojb_ARAE.yelp.utils.Corpus.make_vocab": [[91, 104], ["utils.Corpus.dictionary.prune_vocab", "os.path.exists", "open", "L.strip().split", "line.lower", "utils.Corpus.dictionary.add_word", "L.strip"], "methods", ["home.repos.pwc.inspect_result.jakezhaojb_ARAE.lang.utils.Dictionary.prune_vocab", "home.repos.pwc.inspect_result.jakezhaojb_ARAE.lang.utils.Dictionary.add_word"], ["", "", "def", "make_vocab", "(", "self", ")", ":", "\n", "        ", "for", "path", "in", "self", ".", "forvocab", ":", "\n", "            ", "assert", "os", ".", "path", ".", "exists", "(", "path", ")", "\n", "# Add words to the dictionary", "\n", "with", "open", "(", "path", ",", "'r'", ")", "as", "f", ":", "\n", "                ", "for", "line", "in", "f", ":", "\n", "                    ", "L", "=", "line", ".", "lower", "(", ")", "if", "self", ".", "lowercase", "else", "line", "\n", "words", "=", "L", ".", "strip", "(", ")", ".", "split", "(", "\" \"", ")", "\n", "for", "word", "in", "words", ":", "\n", "                        ", "self", ".", "dictionary", ".", "add_word", "(", "word", ")", "\n", "\n", "# prune the vocabulary", "\n", "", "", "", "", "self", ".", "dictionary", ".", "prune_vocab", "(", "k", "=", "self", ".", "vocab_size", ",", "cnt", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jakezhaojb_ARAE.yelp.utils.Corpus.tokenize": [[105, 128], ["print", "open", "L.strip().split", "lines.append", "line.lower", "L.strip", "len"], "methods", ["None"], ["", "def", "tokenize", "(", "self", ",", "path", ")", ":", "\n", "        ", "\"\"\"Tokenizes a text file.\"\"\"", "\n", "dropped", "=", "0", "\n", "with", "open", "(", "path", ",", "'r'", ")", "as", "f", ":", "\n", "            ", "linecount", "=", "0", "\n", "lines", "=", "[", "]", "\n", "for", "line", "in", "f", ":", "\n", "                ", "linecount", "+=", "1", "\n", "L", "=", "line", ".", "lower", "(", ")", "if", "self", ".", "lowercase", "else", "line", "\n", "words", "=", "L", ".", "strip", "(", ")", ".", "split", "(", "\" \"", ")", "\n", "if", "self", ".", "maxlen", ">", "0", "and", "len", "(", "words", ")", ">", "self", ".", "maxlen", ":", "\n", "                    ", "dropped", "+=", "1", "\n", "continue", "\n", "", "words", "=", "[", "BOS_WORD", "]", "+", "words", "+", "[", "EOS_WORD", "]", "\n", "# vectorize", "\n", "vocab", "=", "self", ".", "dictionary", ".", "word2idx", "\n", "unk_idx", "=", "vocab", "[", "UNK", "]", "\n", "indices", "=", "[", "vocab", "[", "w", "]", "if", "w", "in", "vocab", "else", "unk_idx", "for", "w", "in", "words", "]", "\n", "lines", ".", "append", "(", "indices", ")", "\n", "\n", "", "", "print", "(", "\"Number of sentences dropped from {}: {} out of {} total\"", ".", "\n", "format", "(", "path", ",", "dropped", ",", "linecount", ")", ")", "\n", "return", "lines", "\n", "\n"]], "home.repos.pwc.inspect_result.jakezhaojb_ARAE.yelp.utils.load_kenlm": [[11, 14], ["None"], "function", ["None"], ["def", "load_kenlm", "(", ")", ":", "\n", "    ", "global", "kenlm", "\n", "import", "kenlm", "\n", "\n"]], "home.repos.pwc.inspect_result.jakezhaojb_ARAE.yelp.utils.to_gpu": [[16, 20], ["var.cuda"], "function", ["None"], ["", "def", "to_gpu", "(", "gpu", ",", "var", ")", ":", "\n", "    ", "if", "gpu", ":", "\n", "        ", "return", "var", ".", "cuda", "(", ")", "\n", "", "return", "var", "\n", "\n"]], "home.repos.pwc.inspect_result.jakezhaojb_ARAE.yelp.utils.batchify": [[130, 167], ["range", "print", "random.shuffle", "len", "utils.length_sort", "max", "zip", "torch.LongTensor", "torch.LongTensor().view", "batches.append", "numpy.array", "len", "len", "torch.LongTensor", "len", "numpy.array"], "function", ["home.repos.pwc.inspect_result.jakezhaojb_ARAE.lang.utils.length_sort"], ["", "", "def", "batchify", "(", "data", ",", "bsz", ",", "shuffle", "=", "False", ",", "gpu", "=", "False", ")", ":", "\n", "    ", "if", "shuffle", ":", "\n", "        ", "random", ".", "shuffle", "(", "data", ")", "\n", "\n", "", "nbatch", "=", "len", "(", "data", ")", "//", "bsz", "\n", "batches", "=", "[", "]", "\n", "\n", "for", "i", "in", "range", "(", "nbatch", ")", ":", "\n", "# Pad batches to maximum sequence length in batch", "\n", "        ", "batch", "=", "data", "[", "i", "*", "bsz", ":", "(", "i", "+", "1", ")", "*", "bsz", "]", "\n", "\n", "# subtract 1 from lengths b/c includes BOTH starts & end symbols", "\n", "words", "=", "batch", "\n", "lengths", "=", "[", "len", "(", "x", ")", "-", "1", "for", "x", "in", "words", "]", "\n", "\n", "# sort items by length (decreasing)", "\n", "batch", ",", "lengths", "=", "length_sort", "(", "batch", ",", "lengths", ")", "\n", "words", "=", "batch", "\n", "\n", "# source has no end symbol", "\n", "source", "=", "[", "x", "[", ":", "-", "1", "]", "for", "x", "in", "words", "]", "\n", "# target has no start symbol", "\n", "target", "=", "[", "x", "[", "1", ":", "]", "for", "x", "in", "words", "]", "\n", "\n", "# find length to pad to", "\n", "maxlen", "=", "max", "(", "lengths", ")", "\n", "for", "x", ",", "y", "in", "zip", "(", "source", ",", "target", ")", ":", "\n", "            ", "zeros", "=", "(", "maxlen", "-", "len", "(", "x", ")", ")", "*", "[", "0", "]", "\n", "x", "+=", "zeros", "\n", "y", "+=", "zeros", "\n", "\n", "", "source", "=", "torch", ".", "LongTensor", "(", "np", ".", "array", "(", "source", ")", ")", "\n", "target", "=", "torch", ".", "LongTensor", "(", "np", ".", "array", "(", "target", ")", ")", ".", "view", "(", "-", "1", ")", "\n", "\n", "batches", ".", "append", "(", "(", "source", ",", "target", ",", "lengths", ")", ")", "\n", "", "print", "(", "'{} batches'", ".", "format", "(", "len", "(", "batches", ")", ")", ")", "\n", "return", "batches", "\n", "\n"]], "home.repos.pwc.inspect_result.jakezhaojb_ARAE.yelp.utils.length_sort": [[169, 175], ["list", "list.sort", "zip", "zip", "list", "list"], "function", ["None"], ["", "def", "length_sort", "(", "items", ",", "lengths", ",", "descending", "=", "True", ")", ":", "\n", "    ", "\"\"\"In order to use pytorch variable length sequence package\"\"\"", "\n", "items", "=", "list", "(", "zip", "(", "items", ",", "lengths", ")", ")", "\n", "items", ".", "sort", "(", "key", "=", "lambda", "x", ":", "x", "[", "1", "]", ",", "reverse", "=", "True", ")", "\n", "items", ",", "lengths", "=", "zip", "(", "*", "items", ")", "\n", "return", "list", "(", "items", ")", ",", "list", "(", "lengths", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jakezhaojb_ARAE.yelp.utils.truncate": [[177, 187], ["truncated_sent.append"], "function", ["None"], ["", "def", "truncate", "(", "words", ")", ":", "\n", "# truncate sentences to first occurrence of <eos>", "\n", "    ", "truncated_sent", "=", "[", "]", "\n", "for", "w", "in", "words", ":", "\n", "        ", "if", "w", "!=", "EOS_WORD", ":", "\n", "            ", "truncated_sent", ".", "append", "(", "w", ")", "\n", "", "else", ":", "\n", "            ", "break", "\n", "", "", "sent", "=", "\" \"", ".", "join", "(", "truncated_sent", ")", "\n", "return", "sent", "\n", "\n"]], "home.repos.pwc.inspect_result.jakezhaojb_ARAE.yelp.utils.train_ngram_lm": [[189, 206], ["os.path.abspath", "os.system", "utils.load_kenlm", "kenlm.Model", "os.path.join", "os.path.join", "os.path.join", "str"], "function", ["home.repos.pwc.inspect_result.jakezhaojb_ARAE.lang.utils.load_kenlm"], ["", "def", "train_ngram_lm", "(", "kenlm_path", ",", "data_path", ",", "output_path", ",", "N", ")", ":", "\n", "    ", "\"\"\"\n    Trains a modified Kneser-Ney n-gram KenLM from a text file.\n    Creates a .arpa file to store n-grams.\n    \"\"\"", "\n", "# create .arpa file of n-grams", "\n", "curdir", "=", "os", ".", "path", ".", "abspath", "(", "os", ".", "path", ".", "curdir", ")", "\n", "\n", "command", "=", "\"bin/lmplz -o \"", "+", "str", "(", "N", ")", "+", "\" <\"", "+", "os", ".", "path", ".", "join", "(", "curdir", ",", "data_path", ")", "+", "\" >\"", "+", "os", ".", "path", ".", "join", "(", "curdir", ",", "output_path", ")", "\n", "os", ".", "system", "(", "\"cd \"", "+", "os", ".", "path", ".", "join", "(", "kenlm_path", ",", "'build'", ")", "+", "\" && \"", "+", "command", ")", "\n", "\n", "load_kenlm", "(", ")", "\n", "# create language model", "\n", "model", "=", "kenlm", ".", "Model", "(", "output_path", ")", "\n", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.jakezhaojb_ARAE.yelp.utils.get_ppl": [[208, 222], ["sent.strip().split", "lm.score", "len", "sent.strip"], "function", ["None"], ["", "def", "get_ppl", "(", "lm", ",", "sentences", ")", ":", "\n", "    ", "\"\"\"\n    Assume sentences is a list of strings (space delimited sentences)\n    \"\"\"", "\n", "total_nll", "=", "0", "\n", "total_wc", "=", "0", "\n", "for", "sent", "in", "sentences", ":", "\n", "        ", "words", "=", "sent", ".", "strip", "(", ")", ".", "split", "(", ")", "\n", "score", "=", "lm", ".", "score", "(", "sent", ",", "bos", "=", "True", ",", "eos", "=", "False", ")", "\n", "word_count", "=", "len", "(", "words", ")", "\n", "total_wc", "+=", "word_count", "\n", "total_nll", "+=", "score", "\n", "", "ppl", "=", "10", "**", "-", "(", "total_nll", "/", "total_wc", ")", "\n", "return", "ppl", "\n", "", ""]], "home.repos.pwc.inspect_result.jakezhaojb_ARAE.lang.models.MLP_D.__init__": [[14, 42], ["torch.LeakyReLU", "torch.LeakyReLU", "torch.LeakyReLU", "torch.Module.__init__", "range", "torch.Linear", "torch.Linear", "torch.Linear", "models.MLP_D.layers.append", "models.MLP_D.add_module", "models.MLP_D.init_weights", "torch.Linear", "torch.Linear", "torch.Linear", "models.MLP_D.layers.append", "models.MLP_D.add_module", "models.MLP_D.layers.append", "models.MLP_D.add_module", "int", "len", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.BatchNorm1d", "models.MLP_D.layers.append", "models.MLP_D.add_module", "str", "layers.split", "str", "str", "len", "str"], "methods", ["home.repos.pwc.inspect_result.jakezhaojb_ARAE.lang.utils.Corpus.__init__", "home.repos.pwc.inspect_result.jakezhaojb_ARAE.lang.models.Seq2Seq.init_weights"], ["    ", "def", "__init__", "(", "self", ",", "ninput", ",", "noutput", ",", "layers", ",", "\n", "activation", "=", "nn", ".", "ReLU", "(", ")", ",", "gpu", "=", "False", ")", ":", "\n", "        ", "super", "(", "MLP_Classify", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "ninput", "=", "ninput", "\n", "self", ".", "noutput", "=", "noutput", "\n", "\n", "layer_sizes", "=", "[", "ninput", "]", "+", "[", "int", "(", "x", ")", "for", "x", "in", "layers", ".", "split", "(", "'-'", ")", "]", "\n", "self", ".", "layers", "=", "[", "]", "\n", "\n", "for", "i", "in", "range", "(", "len", "(", "layer_sizes", ")", "-", "1", ")", ":", "\n", "            ", "layer", "=", "nn", ".", "Linear", "(", "layer_sizes", "[", "i", "]", ",", "layer_sizes", "[", "i", "+", "1", "]", ")", "\n", "self", ".", "layers", ".", "append", "(", "layer", ")", "\n", "self", ".", "add_module", "(", "\"layer\"", "+", "str", "(", "i", "+", "1", ")", ",", "layer", ")", "\n", "\n", "# No batch normalization in first layer", "\n", "if", "i", "!=", "0", ":", "\n", "                ", "bn", "=", "nn", ".", "BatchNorm1d", "(", "layer_sizes", "[", "i", "+", "1", "]", ")", "\n", "self", ".", "layers", ".", "append", "(", "bn", ")", "\n", "self", ".", "add_module", "(", "\"bn\"", "+", "str", "(", "i", "+", "1", ")", ",", "bn", ")", "\n", "\n", "", "self", ".", "layers", ".", "append", "(", "activation", ")", "\n", "self", ".", "add_module", "(", "\"activation\"", "+", "str", "(", "i", "+", "1", ")", ",", "activation", ")", "\n", "\n", "", "layer", "=", "nn", ".", "Linear", "(", "layer_sizes", "[", "-", "1", "]", ",", "noutput", ")", "\n", "self", ".", "layers", ".", "append", "(", "layer", ")", "\n", "self", ".", "add_module", "(", "\"layer\"", "+", "str", "(", "len", "(", "self", ".", "layers", ")", ")", ",", "layer", ")", "\n", "\n", "self", ".", "init_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jakezhaojb_ARAE.lang.models.MLP_D.forward": [[43, 48], ["enumerate", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "layer"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "for", "i", ",", "layer", "in", "enumerate", "(", "self", ".", "layers", ")", ":", "\n", "            ", "x", "=", "layer", "(", "x", ")", "\n", "", "x", "=", "F", ".", "sigmoid", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.jakezhaojb_ARAE.lang.models.MLP_D.init_weights": [[49, 57], ["layer.weight.data.normal_", "layer.bias.data.fill_"], "methods", ["None"], ["", "def", "init_weights", "(", "self", ")", ":", "\n", "        ", "init_std", "=", "0.02", "\n", "for", "layer", "in", "self", ".", "layers", ":", "\n", "            ", "try", ":", "\n", "                ", "layer", ".", "weight", ".", "data", ".", "normal_", "(", "0", ",", "init_std", ")", "\n", "layer", ".", "bias", ".", "data", ".", "fill_", "(", "0", ")", "\n", "", "except", ":", "\n", "                ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.jakezhaojb_ARAE.lang.models.MLP_G.__init__": [[60, 86], ["torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Module.__init__", "range", "torch.Linear", "torch.Linear", "torch.Linear", "models.MLP_G.layers.append", "models.MLP_G.add_module", "models.MLP_G.init_weights", "torch.Linear", "torch.Linear", "torch.Linear", "models.MLP_G.layers.append", "models.MLP_G.add_module", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.BatchNorm1d", "models.MLP_G.layers.append", "models.MLP_G.add_module", "models.MLP_G.layers.append", "models.MLP_G.add_module", "int", "len", "str", "layers.split", "str", "str", "str", "len"], "methods", ["home.repos.pwc.inspect_result.jakezhaojb_ARAE.lang.utils.Corpus.__init__", "home.repos.pwc.inspect_result.jakezhaojb_ARAE.lang.models.Seq2Seq.init_weights"], ["    ", "def", "__init__", "(", "self", ",", "emsize", ",", "nhidden", ",", "ntokens", ",", "nlayers", ",", "noise_r", "=", "0.2", ",", "\n", "share_decoder_emb", "=", "False", ",", "hidden_init", "=", "False", ",", "dropout", "=", "0", ",", "gpu", "=", "False", ")", ":", "\n", "        ", "super", "(", "Seq2Seq2Decoder", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "nhidden", "=", "nhidden", "\n", "self", ".", "emsize", "=", "emsize", "\n", "self", ".", "ntokens", "=", "ntokens", "\n", "self", ".", "nlayers", "=", "nlayers", "\n", "self", ".", "noise_r", "=", "noise_r", "\n", "self", ".", "hidden_init", "=", "hidden_init", "\n", "self", ".", "dropout", "=", "dropout", "\n", "self", ".", "gpu", "=", "gpu", "\n", "\n", "self", ".", "start_symbols", "=", "to_gpu", "(", "gpu", ",", "Variable", "(", "torch", ".", "ones", "(", "10", ",", "1", ")", ".", "long", "(", ")", ")", ")", "\n", "\n", "# Vocabulary embedding", "\n", "self", ".", "embedding", "=", "nn", ".", "Embedding", "(", "ntokens", ",", "emsize", ")", "\n", "self", ".", "embedding_decoder1", "=", "nn", ".", "Embedding", "(", "ntokens", ",", "emsize", ")", "\n", "self", ".", "embedding_decoder2", "=", "nn", ".", "Embedding", "(", "ntokens", ",", "emsize", ")", "\n", "\n", "# RNN Encoder and Decoder", "\n", "self", ".", "encoder", "=", "nn", ".", "LSTM", "(", "input_size", "=", "emsize", ",", "\n", "hidden_size", "=", "nhidden", ",", "\n", "num_layers", "=", "nlayers", ",", "\n", "dropout", "=", "dropout", ",", "\n", "batch_first", "=", "True", ")", "\n", "\n", "decoder_input_size", "=", "emsize", "+", "nhidden", "\n"]], "home.repos.pwc.inspect_result.jakezhaojb_ARAE.lang.models.MLP_G.forward": [[87, 91], ["enumerate", "layer"], "methods", ["None"], ["self", ".", "decoder1", "=", "nn", ".", "LSTM", "(", "input_size", "=", "decoder_input_size", ",", "\n", "hidden_size", "=", "nhidden", ",", "\n", "num_layers", "=", "1", ",", "\n", "dropout", "=", "dropout", ",", "\n", "batch_first", "=", "True", ")", "\n"]], "home.repos.pwc.inspect_result.jakezhaojb_ARAE.lang.models.MLP_G.init_weights": [[92, 100], ["layer.weight.data.normal_", "layer.bias.data.fill_"], "methods", ["None"], ["self", ".", "decoder2", "=", "nn", ".", "LSTM", "(", "input_size", "=", "decoder_input_size", ",", "\n", "hidden_size", "=", "nhidden", ",", "\n", "num_layers", "=", "1", ",", "\n", "dropout", "=", "dropout", ",", "\n", "batch_first", "=", "True", ")", "\n", "\n", "# Initialize Linear Transformation", "\n", "self", ".", "linear", "=", "nn", ".", "Linear", "(", "nhidden", ",", "ntokens", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jakezhaojb_ARAE.lang.models.Seq2Seq.__init__": [[103, 139], ["torch.Module.__init__", "utils.to_gpu", "torch.Embedding", "torch.Embedding", "torch.Embedding", "torch.Embedding", "torch.Embedding", "torch.Embedding", "torch.LSTM", "torch.LSTM", "torch.LSTM", "torch.LSTM", "torch.LSTM", "torch.LSTM", "torch.Linear", "torch.Linear", "torch.Linear", "models.Seq2Seq.init_weights", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.ones().long", "torch.ones().long", "torch.ones().long", "torch.ones().long", "torch.ones().long", "torch.ones().long", "torch.ones().long", "torch.ones().long", "torch.ones().long", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones"], "methods", ["home.repos.pwc.inspect_result.jakezhaojb_ARAE.lang.utils.Corpus.__init__", "home.repos.pwc.inspect_result.jakezhaojb_ARAE.lang.utils.to_gpu", "home.repos.pwc.inspect_result.jakezhaojb_ARAE.lang.models.Seq2Seq.init_weights"], ["if", "share_decoder_emb", ":", "\n", "            ", "self", ".", "embedding_decoder2", ".", "weight", "=", "self", ".", "embedding_decoder1", ".", "weight", "\n", "\n", "", "", "def", "init_weights", "(", "self", ")", ":", "\n", "        ", "initrange", "=", "0.1", "\n", "\n", "# Initialize Vocabulary Matrix Weight", "\n", "self", ".", "embedding", ".", "weight", ".", "data", ".", "uniform_", "(", "-", "initrange", ",", "initrange", ")", "\n", "self", ".", "embedding_decoder1", ".", "weight", ".", "data", ".", "uniform_", "(", "-", "initrange", ",", "initrange", ")", "\n", "self", ".", "embedding_decoder2", ".", "weight", ".", "data", ".", "uniform_", "(", "-", "initrange", ",", "initrange", ")", "\n", "\n", "# Initialize Encoder and Decoder Weights", "\n", "for", "p", "in", "self", ".", "encoder", ".", "parameters", "(", ")", ":", "\n", "            ", "p", ".", "data", ".", "uniform_", "(", "-", "initrange", ",", "initrange", ")", "\n", "", "for", "p", "in", "self", ".", "decoder1", ".", "parameters", "(", ")", ":", "\n", "            ", "p", ".", "data", ".", "uniform_", "(", "-", "initrange", ",", "initrange", ")", "\n", "", "for", "p", "in", "self", ".", "decoder2", ".", "parameters", "(", ")", ":", "\n", "            ", "p", ".", "data", ".", "uniform_", "(", "-", "initrange", ",", "initrange", ")", "\n", "\n", "# Initialize Linear Weight", "\n", "", "self", ".", "linear", ".", "weight", ".", "data", ".", "uniform_", "(", "-", "initrange", ",", "initrange", ")", "\n", "self", ".", "linear", ".", "bias", ".", "data", ".", "fill_", "(", "0", ")", "\n", "\n", "", "def", "init_hidden", "(", "self", ",", "bsz", ")", ":", "\n", "        ", "zeros1", "=", "Variable", "(", "torch", ".", "zeros", "(", "self", ".", "nlayers", ",", "bsz", ",", "self", ".", "nhidden", ")", ")", "\n", "zeros2", "=", "Variable", "(", "torch", ".", "zeros", "(", "self", ".", "nlayers", ",", "bsz", ",", "self", ".", "nhidden", ")", ")", "\n", "return", "(", "to_gpu", "(", "self", ".", "gpu", ",", "zeros1", ")", ",", "to_gpu", "(", "self", ".", "gpu", ",", "zeros2", ")", ")", "\n", "\n", "", "def", "init_state", "(", "self", ",", "bsz", ")", ":", "\n", "        ", "zeros", "=", "Variable", "(", "torch", ".", "zeros", "(", "self", ".", "nlayers", ",", "bsz", ",", "self", ".", "nhidden", ")", ")", "\n", "return", "to_gpu", "(", "self", ".", "gpu", ",", "zeros", ")", "\n", "\n", "", "def", "store_grad_norm", "(", "self", ",", "grad", ")", ":", "\n", "        ", "norm", "=", "torch", ".", "norm", "(", "grad", ",", "2", ",", "1", ")", "\n", "self", ".", "grad_norm", "=", "norm", ".", "detach", "(", ")", ".", "data", ".", "mean", "(", ")", "\n", "return", "grad", "\n", "\n"]], "home.repos.pwc.inspect_result.jakezhaojb_ARAE.lang.models.Seq2Seq.init_weights": [[140, 156], ["models.Seq2Seq.embedding.weight.data.uniform_", "models.Seq2Seq.embedding_decoder.weight.data.uniform_", "models.Seq2Seq.encoder.parameters", "models.Seq2Seq.decoder.parameters", "models.Seq2Seq.linear.weight.data.uniform_", "models.Seq2Seq.linear.bias.data.fill_", "p.data.uniform_", "p.data.uniform_"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "whichdecoder", ",", "indices", ",", "lengths", ",", "noise", "=", "False", ",", "encode_only", "=", "False", ")", ":", "\n", "        ", "batch_size", ",", "maxlen", "=", "indices", ".", "size", "(", ")", "\n", "\n", "hidden", "=", "self", ".", "encode", "(", "indices", ",", "lengths", ",", "noise", ")", "\n", "\n", "if", "hidden", ".", "requires_grad", ":", "\n", "            ", "hidden", ".", "register_hook", "(", "self", ".", "store_grad_norm", ")", "\n", "\n", "", "if", "encode_only", ":", "\n", "            ", "return", "hidden", "\n", "\n", "", "decoded", "=", "self", ".", "decode", "(", "whichdecoder", ",", "hidden", ",", "batch_size", ",", "maxlen", ",", "\n", "indices", "=", "indices", ",", "lengths", "=", "lengths", ")", "\n", "\n", "return", "decoded", "\n", "\n", "", "def", "encode", "(", "self", ",", "indices", ",", "lengths", ",", "noise", ")", ":", "\n"]], "home.repos.pwc.inspect_result.jakezhaojb_ARAE.lang.models.Seq2Seq.init_hidden": [[157, 161], ["torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "utils.to_gpu", "utils.to_gpu"], "methods", ["home.repos.pwc.inspect_result.jakezhaojb_ARAE.lang.utils.to_gpu", "home.repos.pwc.inspect_result.jakezhaojb_ARAE.lang.utils.to_gpu"], ["        ", "embeddings", "=", "self", ".", "embedding", "(", "indices", ")", "\n", "packed_embeddings", "=", "pack_padded_sequence", "(", "input", "=", "embeddings", ",", "\n", "lengths", "=", "lengths", ",", "\n", "batch_first", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jakezhaojb_ARAE.lang.models.Seq2Seq.init_state": [[162, 165], ["torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "utils.to_gpu", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros"], "methods", ["home.repos.pwc.inspect_result.jakezhaojb_ARAE.lang.utils.to_gpu"], ["# Encode", "\n", "packed_output", ",", "state", "=", "self", ".", "encoder", "(", "packed_embeddings", ")", "\n", "hidden", ",", "cell", "=", "state", "\n", "\n"]], "home.repos.pwc.inspect_result.jakezhaojb_ARAE.lang.models.Seq2Seq.store_grad_norm": [[166, 170], ["torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm.detach().data.mean", "torch.norm.detach().data.mean", "torch.norm.detach().data.mean", "torch.norm.detach", "torch.norm.detach", "torch.norm.detach"], "methods", ["None"], ["# batch_size x nhidden", "\n", "hidden", "=", "hidden", "[", "-", "1", "]", "# get hidden state of last layer of encoder", "\n", "\n", "# normalize to unit ball (l2 norm of 1) - p=2, dim=1", "\n", "norms", "=", "torch", ".", "norm", "(", "hidden", ",", "2", ",", "1", ")", "\n"]], "home.repos.pwc.inspect_result.jakezhaojb_ARAE.lang.models.Seq2Seq.forward": [[171, 186], ["indices.size", "models.Seq2Seq.encode", "models.Seq2Seq.decode", "models.Seq2Seq.register_hook"], "methods", ["home.repos.pwc.inspect_result.jakezhaojb_ARAE.lang.models.Seq2Seq.encode", "home.repos.pwc.inspect_result.jakezhaojb_ARAE.lang.models.Seq2Seq.decode"], ["\n", "# For older versions of PyTorch use:", "\n", "hidden", "=", "torch", ".", "div", "(", "hidden", ",", "norms", ".", "unsqueeze", "(", "1", ")", ".", "expand_as", "(", "hidden", ")", ")", "\n", "# For newest version of PyTorch (as of 8/25) use this:", "\n", "# hidden = torch.div(hidden, norms.unsqueeze(1).expand_as(hidden))", "\n", "\n", "if", "noise", "and", "self", ".", "noise_r", ">", "0", ":", "\n", "            ", "gauss_noise", "=", "torch", ".", "normal", "(", "means", "=", "torch", ".", "zeros", "(", "hidden", ".", "size", "(", ")", ")", ",", "\n", "std", "=", "self", ".", "noise_r", ")", "\n", "hidden", "=", "hidden", "+", "to_gpu", "(", "self", ".", "gpu", ",", "Variable", "(", "gauss_noise", ")", ")", "\n", "\n", "", "return", "hidden", "\n", "\n", "", "def", "decode", "(", "self", ",", "whichdecoder", ",", "hidden", ",", "batch_size", ",", "maxlen", ",", "indices", "=", "None", ",", "lengths", "=", "None", ")", ":", "\n", "# batch x hidden", "\n", "        ", "all_hidden", "=", "hidden", ".", "unsqueeze", "(", "1", ")", ".", "repeat", "(", "1", ",", "maxlen", ",", "1", ")", "\n"]], "home.repos.pwc.inspect_result.jakezhaojb_ARAE.lang.models.Seq2Seq.encode": [[187, 203], ["models.Seq2Seq.embedding", "torch.nn.utils.rnn.pack_padded_sequence", "torch.nn.utils.rnn.pack_padded_sequence", "torch.nn.utils.rnn.pack_padded_sequence", "models.Seq2Seq.encoder", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.normal", "torch.normal", "torch.normal", "torch.normal", "torch.normal", "torch.normal", "torch.normal", "torch.normal", "torch.normal", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.normal.cuda", "torch.normal.cuda", "torch.normal.cuda", "hidden.size"], "methods", ["None"], ["\n", "if", "self", ".", "hidden_init", ":", "\n", "# initialize decoder hidden state to encoder output", "\n", "            ", "state", "=", "(", "hidden", ".", "unsqueeze", "(", "0", ")", ",", "self", ".", "init_state", "(", "batch_size", ")", ")", "\n", "", "else", ":", "\n", "            ", "state", "=", "self", ".", "init_hidden", "(", "batch_size", ")", "\n", "\n", "", "if", "whichdecoder", "==", "1", ":", "\n", "            ", "embeddings", "=", "self", ".", "embedding_decoder1", "(", "indices", ")", "\n", "", "else", ":", "\n", "            ", "embeddings", "=", "self", ".", "embedding_decoder2", "(", "indices", ")", "\n", "\n", "", "augmented_embeddings", "=", "torch", ".", "cat", "(", "[", "embeddings", ",", "all_hidden", "]", ",", "2", ")", "\n", "packed_embeddings", "=", "pack_padded_sequence", "(", "input", "=", "augmented_embeddings", ",", "\n", "lengths", "=", "lengths", ",", "\n", "batch_first", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jakezhaojb_ARAE.lang.models.Seq2Seq.decode": [[204, 228], ["hidden.unsqueeze().repeat", "models.Seq2Seq.embedding_decoder", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.nn.utils.rnn.pack_padded_sequence", "torch.nn.utils.rnn.pack_padded_sequence", "torch.nn.utils.rnn.pack_padded_sequence", "models.Seq2Seq.decoder", "torch.nn.utils.rnn.pad_packed_sequence", "torch.nn.utils.rnn.pad_packed_sequence", "torch.nn.utils.rnn.pad_packed_sequence", "models.Seq2Seq.linear", "decoded.view.view.view", "models.Seq2Seq.init_hidden", "output.contiguous().view", "hidden.unsqueeze", "hidden.unsqueeze", "models.Seq2Seq.init_state", "output.contiguous"], "methods", ["home.repos.pwc.inspect_result.jakezhaojb_ARAE.lang.models.Seq2Seq.init_hidden", "home.repos.pwc.inspect_result.jakezhaojb_ARAE.lang.models.Seq2Seq.init_state"], ["if", "whichdecoder", "==", "1", ":", "\n", "            ", "packed_output", ",", "state", "=", "self", ".", "decoder1", "(", "packed_embeddings", ",", "state", ")", "\n", "", "else", ":", "\n", "            ", "packed_output", ",", "state", "=", "self", ".", "decoder2", "(", "packed_embeddings", ",", "state", ")", "\n", "", "output", ",", "lengths", "=", "pad_packed_sequence", "(", "packed_output", ",", "batch_first", "=", "True", ")", "\n", "\n", "# reshape to batch_size*maxlen x nhidden before linear over vocab", "\n", "decoded", "=", "self", ".", "linear", "(", "output", ".", "contiguous", "(", ")", ".", "view", "(", "-", "1", ",", "self", ".", "nhidden", ")", ")", "\n", "decoded", "=", "decoded", ".", "view", "(", "batch_size", ",", "maxlen", ",", "self", ".", "ntokens", ")", "\n", "\n", "return", "decoded", "\n", "\n", "", "def", "generate", "(", "self", ",", "whichdecoder", ",", "hidden", ",", "maxlen", ",", "sample", "=", "False", ",", "temp", "=", "1.0", ")", ":", "\n", "        ", "\"\"\"Generate through decoder; no backprop\"\"\"", "\n", "\n", "batch_size", "=", "hidden", ".", "size", "(", "0", ")", "\n", "\n", "if", "self", ".", "hidden_init", ":", "\n", "# initialize decoder hidden state to encoder output", "\n", "            ", "state", "=", "(", "hidden", ".", "unsqueeze", "(", "0", ")", ",", "self", ".", "init_state", "(", "batch_size", ")", ")", "\n", "", "else", ":", "\n", "            ", "state", "=", "self", ".", "init_hidden", "(", "batch_size", ")", "\n", "\n", "# <sos>", "\n", "", "self", ".", "start_symbols", ".", "data", ".", "resize_", "(", "batch_size", ",", "1", ")", "\n"]], "home.repos.pwc.inspect_result.jakezhaojb_ARAE.lang.models.Seq2Seq.generate": [[229, 265], ["hidden.size", "models.Seq2Seq.start_symbols.data.resize_", "models.Seq2Seq.start_symbols.data.fill_", "models.Seq2Seq.embedding_decoder", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "range", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "models.Seq2Seq.init_hidden", "models.Seq2Seq.decoder", "models.Seq2Seq.linear", "torch.multinomial.unsqueeze", "torch.multinomial.unsqueeze", "torch.multinomial.unsqueeze", "all_indices.append", "models.Seq2Seq.embedding_decoder", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "hidden.unsqueeze", "models.Seq2Seq.init_state", "hidden.unsqueeze", "output.squeeze", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.softmax", "torch.softmax", "torch.softmax", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "hidden.unsqueeze"], "methods", ["home.repos.pwc.inspect_result.jakezhaojb_ARAE.lang.models.Seq2Seq.init_hidden", "home.repos.pwc.inspect_result.jakezhaojb_ARAE.lang.models.Seq2Seq.init_state"], ["self", ".", "start_symbols", ".", "data", ".", "fill_", "(", "1", ")", "\n", "self", ".", "start_symbols", "=", "to_gpu", "(", "self", ".", "gpu", ",", "self", ".", "start_symbols", ")", "\n", "\n", "if", "whichdecoder", "==", "1", ":", "\n", "            ", "embedding", "=", "self", ".", "embedding_decoder1", "(", "self", ".", "start_symbols", ")", "\n", "", "else", ":", "\n", "            ", "embedding", "=", "self", ".", "embedding_decoder2", "(", "self", ".", "start_symbols", ")", "\n", "\n", "", "inputs", "=", "torch", ".", "cat", "(", "[", "embedding", ",", "hidden", ".", "unsqueeze", "(", "1", ")", "]", ",", "2", ")", "\n", "\n", "# unroll", "\n", "all_indices", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "maxlen", ")", ":", "\n", "            ", "if", "whichdecoder", "==", "1", ":", "\n", "                ", "output", ",", "state", "=", "self", ".", "decoder1", "(", "inputs", ",", "state", ")", "\n", "", "else", ":", "\n", "                ", "output", ",", "state", "=", "self", ".", "decoder2", "(", "inputs", ",", "state", ")", "\n", "", "overvocab", "=", "self", ".", "linear", "(", "output", ".", "squeeze", "(", "1", ")", ")", "\n", "\n", "if", "not", "sample", ":", "\n", "                ", "vals", ",", "indices", "=", "torch", ".", "max", "(", "overvocab", ",", "1", ")", "\n", "indices", "=", "indices", ".", "unsqueeze", "(", "1", ")", "\n", "", "else", ":", "\n", "                ", "assert", "1", "==", "0", "\n", "# sampling", "\n", "probs", "=", "F", ".", "softmax", "(", "overvocab", "/", "temp", ")", "\n", "indices", "=", "torch", ".", "multinomial", "(", "probs", ",", "1", ")", "\n", "\n", "", "all_indices", ".", "append", "(", "indices", ")", "\n", "\n", "if", "whichdecoder", "==", "1", ":", "\n", "                ", "embedding", "=", "self", ".", "embedding_decoder1", "(", "indices", ")", "\n", "", "else", ":", "\n", "                ", "embedding", "=", "self", ".", "embedding_decoder2", "(", "indices", ")", "\n", "", "inputs", "=", "torch", ".", "cat", "(", "[", "embedding", ",", "hidden", ".", "unsqueeze", "(", "1", ")", "]", ",", "2", ")", "\n", "\n", "", "max_indices", "=", "torch", ".", "cat", "(", "all_indices", ",", "1", ")", "\n"]], "home.repos.pwc.inspect_result.jakezhaojb_ARAE.lang.models.Seq2Seq.noise_anneal": [[266, 268], ["None"], "methods", ["None"], ["\n", "return", "max_indices", "\n", "\n"]], "home.repos.pwc.inspect_result.jakezhaojb_ARAE.lang.models.generate": [[270, 308], ["gan_gen.eval", "autoencoder.eval", "gan_gen", "autoencoder.generate", "max_indices.data.cpu().numpy.data.cpu().numpy", "type", "sentences.append", "torch.autograd.Variable", "max_indices.data.cpu().numpy.data.cpu", "type", "type", "type", "torch.autograd.Variable", "ValueError", "truncated_sent.append", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "type", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy"], "function", ["home.repos.pwc.inspect_result.jakezhaojb_ARAE.lang.models.generate"], ["", "", "class", "MLP_D", "(", "nn", ".", "Module", ")", ":", "\n", "    ", "def", "__init__", "(", "self", ",", "ninput", ",", "noutput", ",", "layers", ",", "\n", "activation", "=", "nn", ".", "LeakyReLU", "(", "0.2", ")", ",", "gpu", "=", "False", ")", ":", "\n", "        ", "super", "(", "MLP_D", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "ninput", "=", "ninput", "\n", "self", ".", "noutput", "=", "noutput", "\n", "\n", "layer_sizes", "=", "[", "ninput", "]", "+", "[", "int", "(", "x", ")", "for", "x", "in", "layers", ".", "split", "(", "'-'", ")", "]", "\n", "self", ".", "layers", "=", "[", "]", "\n", "\n", "for", "i", "in", "range", "(", "len", "(", "layer_sizes", ")", "-", "1", ")", ":", "\n", "            ", "layer", "=", "nn", ".", "Linear", "(", "layer_sizes", "[", "i", "]", ",", "layer_sizes", "[", "i", "+", "1", "]", ")", "\n", "self", ".", "layers", ".", "append", "(", "layer", ")", "\n", "self", ".", "add_module", "(", "\"layer\"", "+", "str", "(", "i", "+", "1", ")", ",", "layer", ")", "\n", "\n", "# No batch normalization after first layer", "\n", "if", "i", "!=", "0", ":", "\n", "                ", "bn", "=", "nn", ".", "BatchNorm1d", "(", "layer_sizes", "[", "i", "+", "1", "]", ",", "eps", "=", "1e-05", ",", "momentum", "=", "0.1", ")", "\n", "self", ".", "layers", ".", "append", "(", "bn", ")", "\n", "self", ".", "add_module", "(", "\"bn\"", "+", "str", "(", "i", "+", "1", ")", ",", "bn", ")", "\n", "\n", "", "self", ".", "layers", ".", "append", "(", "activation", ")", "\n", "self", ".", "add_module", "(", "\"activation\"", "+", "str", "(", "i", "+", "1", ")", ",", "activation", ")", "\n", "\n", "", "layer", "=", "nn", ".", "Linear", "(", "layer_sizes", "[", "-", "1", "]", ",", "noutput", ")", "\n", "self", ".", "layers", ".", "append", "(", "layer", ")", "\n", "self", ".", "add_module", "(", "\"layer\"", "+", "str", "(", "len", "(", "self", ".", "layers", ")", ")", ",", "layer", ")", "\n", "\n", "self", ".", "init_weights", "(", ")", "\n", "\n", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "for", "i", ",", "layer", "in", "enumerate", "(", "self", ".", "layers", ")", ":", "\n", "            ", "x", "=", "layer", "(", "x", ")", "\n", "", "x", "=", "torch", ".", "mean", "(", "x", ")", "\n", "return", "x", "\n", "\n", "", "def", "init_weights", "(", "self", ")", ":", "\n", "        ", "init_std", "=", "0.02", "\n", "for", "layer", "in", "self", ".", "layers", ":", "\n"]], "home.repos.pwc.inspect_result.jakezhaojb_ARAE.lang.generate.interpolate": [[34, 64], ["range", "type", "gens.append", "len", "interpolations.append", "torch.autograd.Variable", "torch.autograd.Variable", "range", "models.generate", "type", "type", "type", "torch.autograd.Variable", "torch.autograd.Variable", "ValueError", "torch.from_numpy().float", "torch.from_numpy().float", "type", "torch.from_numpy", "torch.from_numpy"], "function", ["home.repos.pwc.inspect_result.jakezhaojb_ARAE.lang.models.generate"], ["def", "interpolate", "(", "ae", ",", "gg", ",", "z1", ",", "z2", ",", "vocab", ",", "\n", "steps", "=", "5", ",", "sample", "=", "None", ",", "maxlen", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    Interpolating in z space\n    Assumes that type(z1) == type(z2)\n    \"\"\"", "\n", "if", "type", "(", "z1", ")", "==", "Variable", ":", "\n", "        ", "noise1", "=", "z1", "\n", "noise2", "=", "z2", "\n", "", "elif", "type", "(", "z1", ")", "==", "torch", ".", "FloatTensor", "or", "type", "(", "z1", ")", "==", "torch", ".", "cuda", ".", "FloatTensor", ":", "\n", "        ", "noise1", "=", "Variable", "(", "z1", ",", "volatile", "=", "True", ")", "\n", "noise2", "=", "Variable", "(", "z2", ",", "volatile", "=", "True", ")", "\n", "", "elif", "type", "(", "z1", ")", "==", "np", ".", "ndarray", ":", "\n", "        ", "noise1", "=", "Variable", "(", "torch", ".", "from_numpy", "(", "z1", ")", ".", "float", "(", ")", ",", "volatile", "=", "True", ")", "\n", "noise2", "=", "Variable", "(", "torch", ".", "from_numpy", "(", "z2", ")", ".", "float", "(", ")", ",", "volatile", "=", "True", ")", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "\"Unsupported input type (noise): {}\"", ".", "format", "(", "type", "(", "z1", ")", ")", ")", "\n", "\n", "# interpolation weights", "\n", "", "lambdas", "=", "[", "x", "*", "1.0", "/", "(", "steps", "-", "1", ")", "for", "x", "in", "range", "(", "steps", ")", "]", "\n", "\n", "gens", "=", "[", "]", "\n", "for", "L", "in", "lambdas", ":", "\n", "        ", "gens", ".", "append", "(", "generate", "(", "ae", ",", "gg", ",", "(", "1", "-", "L", ")", "*", "noise1", "+", "L", "*", "noise2", ",", "\n", "vocab", ",", "sample", ",", "maxlen", ")", ")", "\n", "\n", "", "interpolations", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "gens", "[", "0", "]", ")", ")", ":", "\n", "        ", "interpolations", ".", "append", "(", "[", "s", "[", "i", "]", "for", "s", "in", "gens", "]", ")", "\n", "", "return", "interpolations", "\n", "\n"]], "home.repos.pwc.inspect_result.jakezhaojb_ARAE.lang.generate.load_models": [[66, 93], ["json.load", "vars().update", "models.Seq2Seq", "models.MLP_G", "models.MLP_D", "autoencoder.cuda.cuda", "gan_gen.cuda.cuda", "gan_disc.cuda.cuda", "json.load", "print", "torch.load", "autoencoder.cuda.load_state_dict", "gan_gen.cuda.load_state_dict", "gan_disc.cuda.load_state_dict", "open", "open", "os.path.join", "torch.load.get", "torch.load.get", "torch.load.get", "os.path.join", "vars", "os.path.join", "json.load.items"], "function", ["None"], ["", "def", "load_models", "(", "load_path", ")", ":", "\n", "    ", "model_args", "=", "json", ".", "load", "(", "open", "(", "os", ".", "path", ".", "join", "(", "load_path", ",", "'options.json'", ")", ",", "'r'", ")", ")", "\n", "vars", "(", "args", ")", ".", "update", "(", "model_args", ")", "\n", "autoencoder", "=", "Seq2Seq", "(", "emsize", "=", "args", ".", "emsize", ",", "\n", "nhidden", "=", "args", ".", "nhidden", ",", "\n", "ntokens", "=", "args", ".", "ntokens", ",", "\n", "nlayers", "=", "args", ".", "nlayers", ",", "\n", "noise_r", "=", "args", ".", "noise_r", ",", "\n", "hidden_init", "=", "args", ".", "hidden_init", ",", "\n", "dropout", "=", "args", ".", "dropout", ",", "\n", "gpu", "=", "args", ".", "cuda", ")", "\n", "gan_gen", "=", "MLP_G", "(", "ninput", "=", "args", ".", "z_size", ",", "noutput", "=", "args", ".", "nhidden", ",", "layers", "=", "args", ".", "arch_g", ")", "\n", "gan_disc", "=", "MLP_D", "(", "ninput", "=", "args", ".", "nhidden", ",", "noutput", "=", "1", ",", "layers", "=", "args", ".", "arch_d", ")", "\n", "\n", "autoencoder", "=", "autoencoder", ".", "cuda", "(", ")", "\n", "gan_gen", "=", "gan_gen", ".", "cuda", "(", ")", "\n", "gan_disc", "=", "gan_disc", ".", "cuda", "(", ")", "\n", "\n", "word2idx", "=", "json", ".", "load", "(", "open", "(", "os", ".", "path", ".", "join", "(", "args", ".", "save", ",", "'vocab.json'", ")", ",", "'r'", ")", ")", "\n", "idx2word", "=", "{", "v", ":", "k", "for", "k", ",", "v", "in", "word2idx", ".", "items", "(", ")", "}", "\n", "\n", "print", "(", "'Loading models from {}'", ".", "format", "(", "args", ".", "save", ")", ")", "\n", "loaded", "=", "torch", ".", "load", "(", "os", ".", "path", ".", "join", "(", "args", ".", "save", ",", "\"model.pt\"", ")", ")", "\n", "autoencoder", ".", "load_state_dict", "(", "loaded", ".", "get", "(", "'ae'", ")", ")", "\n", "gan_gen", ".", "load_state_dict", "(", "loaded", ".", "get", "(", "'gan_g'", ")", ")", "\n", "gan_disc", ".", "load_state_dict", "(", "loaded", ".", "get", "(", "'gan_d'", ")", ")", "\n", "return", "model_args", ",", "idx2word", ",", "autoencoder", ",", "gan_gen", ",", "gan_disc", "\n", "\n"]], "home.repos.pwc.inspect_result.jakezhaojb_ARAE.lang.generate.main": [[95, 149], ["random.seed", "numpy.random.seed", "torch.manual_seed", "torch.cuda.is_available", "generate.load_models", "torch.cuda.manual_seed", "print", "torch.ones", "noise.normal_().cuda.normal_().cuda", "models.generate", "torch.ones", "noise1.normal_().cuda.normal_().cuda", "torch.ones", "noise2.normal_().cuda.normal_().cuda", "generate.interpolate", "print", "open", "f.write", "print", "open", "f.write", "noise.normal_().cuda.normal_", "print", "f.write", "noise1.normal_().cuda.normal_", "noise2.normal_().cuda.normal_", "print", "f.write", "print", "f.write"], "function", ["home.repos.pwc.inspect_result.jakezhaojb_ARAE.lang.train.load_models", "home.repos.pwc.inspect_result.jakezhaojb_ARAE.lang.models.generate", "home.repos.pwc.inspect_result.jakezhaojb_ARAE.lang.generate.interpolate", "home.repos.pwc.inspect_result.jakezhaojb_ARAE.lang.preprocess_lm.Indexer.write", "home.repos.pwc.inspect_result.jakezhaojb_ARAE.lang.preprocess_lm.Indexer.write", "home.repos.pwc.inspect_result.jakezhaojb_ARAE.lang.preprocess_lm.Indexer.write", "home.repos.pwc.inspect_result.jakezhaojb_ARAE.lang.preprocess_lm.Indexer.write", "home.repos.pwc.inspect_result.jakezhaojb_ARAE.lang.preprocess_lm.Indexer.write"], ["", "def", "main", "(", "args", ")", ":", "\n", "# Set the random seed manually for reproducibility.", "\n", "    ", "random", ".", "seed", "(", "args", ".", "seed", ")", "\n", "np", ".", "random", ".", "seed", "(", "args", ".", "seed", ")", "\n", "torch", ".", "manual_seed", "(", "args", ".", "seed", ")", "\n", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "        ", "torch", ".", "cuda", ".", "manual_seed", "(", "args", ".", "seed", ")", "\n", "", "else", ":", "\n", "        ", "print", "(", "\"Note that our pre-trained models require CUDA to evaluate.\"", ")", "\n", "\n", "", "model_args", ",", "idx2word", ",", "autoencoder", ",", "gan_gen", ",", "gan_disc", "=", "load_models", "(", "args", ".", "load_path", ")", "\n", "\n", "if", "args", ".", "ngenerations", ">", "0", ":", "\n", "        ", "noise", "=", "torch", ".", "ones", "(", "args", ".", "ngenerations", ",", "model_args", "[", "'z_size'", "]", ")", "\n", "noise", "=", "noise", ".", "normal_", "(", ")", ".", "cuda", "(", ")", "\n", "sentences", "=", "generate", "(", "autoencoder", ",", "gan_gen", ",", "z", "=", "noise", ",", "\n", "vocab", "=", "idx2word", ",", "sample", "=", "args", ".", "sample", ",", "\n", "maxlen", "=", "model_args", "[", "'maxlen'", "]", ")", "\n", "\n", "if", "not", "args", ".", "noprint", ":", "\n", "            ", "print", "(", "\"\\nSentence generations:\\n\"", ")", "\n", "for", "sent", "in", "sentences", ":", "\n", "                ", "print", "(", "sent", ")", "\n", "", "", "with", "open", "(", "args", ".", "outf", ",", "\"w\"", ")", "as", "f", ":", "\n", "            ", "f", ".", "write", "(", "\"Sentence generations:\\n\\n\"", ")", "\n", "for", "sent", "in", "sentences", ":", "\n", "                ", "f", ".", "write", "(", "sent", "+", "\"\\n\"", ")", "\n", "\n", "", "", "", "if", "args", ".", "ninterpolations", ">", "0", ":", "\n", "        ", "noise1", "=", "torch", ".", "ones", "(", "args", ".", "ninterpolations", ",", "model_args", "[", "'z_size'", "]", ")", "\n", "noise1", "=", "noise1", ".", "normal_", "(", ")", ".", "cuda", "(", ")", "\n", "noise2", "=", "torch", ".", "ones", "(", "args", ".", "ninterpolations", ",", "model_args", "[", "'z_size'", "]", ")", "\n", "noise2", "=", "noise2", ".", "normal_", "(", ")", ".", "cuda", "(", ")", "\n", "interps", "=", "interpolate", "(", "autoencoder", ",", "gan_gen", ",", "\n", "z1", "=", "noise1", ",", "\n", "z2", "=", "noise2", ",", "\n", "vocab", "=", "idx2word", ",", "\n", "steps", "=", "args", ".", "steps", ",", "\n", "sample", "=", "args", ".", "sample", ",", "\n", "maxlen", "=", "model_args", "[", "'maxlen'", "]", ")", "\n", "\n", "if", "not", "args", ".", "noprint", ":", "\n", "            ", "print", "(", "\"\\nSentence interpolations:\\n\"", ")", "\n", "for", "interp", "in", "interps", ":", "\n", "                ", "for", "sent", "in", "interp", ":", "\n", "                    ", "print", "(", "sent", ")", "\n", "", "print", "(", "\"\"", ")", "\n", "", "", "with", "open", "(", "args", ".", "outf", ",", "\"a\"", ")", "as", "f", ":", "\n", "            ", "f", ".", "write", "(", "\"\\nSentence interpolations:\\n\\n\"", ")", "\n", "for", "interp", "in", "interps", ":", "\n", "                ", "for", "sent", "in", "interp", ":", "\n", "                    ", "f", ".", "write", "(", "sent", "+", "\"\\n\"", ")", "\n", "", "f", ".", "write", "(", "'\\n'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jakezhaojb_ARAE.lang.train.logging": [[45, 50], ["open", "f.write", "print", "os.path.join"], "function", ["home.repos.pwc.inspect_result.jakezhaojb_ARAE.lang.preprocess_lm.Indexer.write"], ["help", "=", "'number of hidden units per layer'", ")", "\n", "parser", ".", "add_argument", "(", "'--nlayers'", ",", "type", "=", "int", ",", "default", "=", "1", ",", "\n", "help", "=", "'number of layers'", ")", "\n", "parser", ".", "add_argument", "(", "'--noise_r'", ",", "type", "=", "float", ",", "default", "=", "0.1", ",", "\n", "help", "=", "'stdev of noise for autoencoder (regularizer)'", ")", "\n", "parser", ".", "add_argument", "(", "'--noise_anneal'", ",", "type", "=", "float", ",", "default", "=", "0.9995", ",", "\n"]], "home.repos.pwc.inspect_result.jakezhaojb_ARAE.lang.train.save_model": [[93, 101], ["print", "torch.save", "torch.save", "torch.save", "torch.save", "os.path.join", "autoencoder.state_dict", "gan_gen.state_dict", "gan_disc.state_dict"], "function", ["None"], ["help", "=", "'beta1 for adam. default=0.5'", ")", "\n", "parser", ".", "add_argument", "(", "'--clip'", ",", "type", "=", "float", ",", "default", "=", "1", ",", "\n", "help", "=", "'gradient clipping, max norm'", ")", "\n", "parser", ".", "add_argument", "(", "'--gan_gp_lambda'", ",", "type", "=", "float", ",", "default", "=", "0.1", ",", "\n", "help", "=", "'WGAN GP penalty lambda'", ")", "\n", "parser", ".", "add_argument", "(", "'--grad_lambda'", ",", "type", "=", "float", ",", "default", "=", "0.01", ",", "\n", "help", "=", "'WGAN into AE lambda'", ")", "\n", "parser", ".", "add_argument", "(", "'--lambda_class'", ",", "type", "=", "float", ",", "default", "=", "1", ",", "\n", "help", "=", "'lambda on classifier'", ")", "\n"]], "home.repos.pwc.inspect_result.jakezhaojb_ARAE.lang.train.load_models": [[102, 113], ["json.load", "json.load", "print", "torch.load", "torch.load", "torch.load", "torch.load", "autoencoder.load_state_dict", "gan_gen.load_state_dict", "gan_disc.load_state_dict", "open", "open", "os.path.join", "torch.load.get", "torch.load.get", "torch.load.get", "os.path.join", "os.path.join", "json.load.items"], "function", ["None"], ["\n", "# Evaluation Arguments", "\n", "parser", ".", "add_argument", "(", "'--sample'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "'sample when decoding for generation'", ")", "\n", "parser", ".", "add_argument", "(", "'--log_interval'", ",", "type", "=", "int", ",", "default", "=", "200", ",", "\n", "help", "=", "'interval to log autoencoder training results'", ")", "\n", "\n", "# Other", "\n", "parser", ".", "add_argument", "(", "'--seed'", ",", "type", "=", "int", ",", "default", "=", "1111", ",", "\n", "help", "=", "'random seed'", ")", "\n", "parser", ".", "add_argument", "(", "'--cuda'", ",", "dest", "=", "'cuda'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "'use CUDA'", ")", "\n"]], "home.repos.pwc.inspect_result.jakezhaojb_ARAE.lang.train.evaluate_autoencoder": [[114, 160], ["autoencoder.eval", "len", "enumerate", "torch.autograd.Variable", "torch.autograd.Variable", "target.view().data.cpu().numpy.gt", "target.view().data.cpu().numpy.masked_select", "target.gt.unsqueeze().expand", "autoencoder", "autoencoder.view", "output.view.masked_select().view", "torch.max", "torch.max", "torch.max", "torch.max", "os.path.join", "torch.autograd.Variable.cuda", "target.view().data.cpu().numpy.cuda", "target.gt.size", "torch.cross_entropy", "open", "torch.max", "torch.max", "torch.max", "torch.max", "max_indices.view().data.cpu().numpy.view().data.cpu().numpy", "target.view().data.cpu().numpy.view().data.cpu().numpy", "zip", "len", "target.gt.unsqueeze", "output.view.masked_select", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "f.write", "f.write", "max_indices.view().data.cpu().numpy.eq().float", "max_indices.view().data.cpu().numpy.view().data.cpu", "target.view().data.cpu().numpy.view().data.cpu", "max_indices.view().data.cpu().numpy.eq", "max_indices.view().data.cpu().numpy.view", "target.view().data.cpu().numpy.view", "autoencoder.size", "autoencoder.size"], "function", ["home.repos.pwc.inspect_result.jakezhaojb_ARAE.lang.preprocess_lm.Indexer.write", "home.repos.pwc.inspect_result.jakezhaojb_ARAE.lang.preprocess_lm.Indexer.write"], ["parser", ".", "add_argument", "(", "'--no-cuda'", ",", "dest", "=", "'cuda'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "'not using CUDA'", ")", "\n", "parser", ".", "set_defaults", "(", "cuda", "=", "True", ")", "\n", "parser", ".", "add_argument", "(", "'--device_id'", ",", "type", "=", "str", ",", "default", "=", "'0'", ")", "\n", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "print", "(", "vars", "(", "args", ")", ")", "\n", "\n", "os", ".", "environ", "[", "'CUDA_VISIBLE_DEVICES'", "]", "=", "args", ".", "device_id", "\n", "\n", "# make output directory if it doesn't already exist", "\n", "if", "os", ".", "path", ".", "isdir", "(", "args", ".", "outf", ")", ":", "\n", "    ", "shutil", ".", "rmtree", "(", "args", ".", "outf", ")", "\n", "", "os", ".", "makedirs", "(", "args", ".", "outf", ")", "\n", "\n", "# Set the random seed manually for reproducibility.", "\n", "random", ".", "seed", "(", "args", ".", "seed", ")", "\n", "np", ".", "random", ".", "seed", "(", "args", ".", "seed", ")", "\n", "torch", ".", "manual_seed", "(", "args", ".", "seed", ")", "\n", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "    ", "if", "not", "args", ".", "cuda", ":", "\n", "        ", "print", "(", "\"WARNING: You have a CUDA device, \"", "\n", "\"so you should probably run with --cuda\"", ")", "\n", "", "else", ":", "\n", "        ", "torch", ".", "cuda", ".", "manual_seed", "(", "args", ".", "seed", ")", "\n", "\n", "###############################################################################", "\n", "# Load data", "\n", "###############################################################################", "\n", "\n", "", "", "label_ids", "=", "{", "\"pos\"", ":", "1", ",", "\"neg\"", ":", "0", "}", "\n", "id2label", "=", "{", "1", ":", "\"pos\"", ",", "0", ":", "\"neg\"", "}", "\n", "\n", "# (Path to textfile, Name, Use4Vocab)", "\n", "datafiles", "=", "[", "(", "os", ".", "path", ".", "join", "(", "args", ".", "data_path", ",", "\"valid1.txt\"", ")", ",", "\"valid1\"", ",", "False", ")", ",", "\n", "(", "os", ".", "path", ".", "join", "(", "args", ".", "data_path", ",", "\"valid2.txt\"", ")", ",", "\"valid2\"", ",", "False", ")", ",", "\n", "(", "os", ".", "path", ".", "join", "(", "args", ".", "data_path", ",", "\"train1.txt\"", ")", ",", "\"train1\"", ",", "True", ")", ",", "\n", "(", "os", ".", "path", ".", "join", "(", "args", ".", "data_path", ",", "\"train2.txt\"", ")", ",", "\"train2\"", ",", "True", ")", "]", "\n", "vocabdict", "=", "None", "\n", "if", "args", ".", "load_vocab", "!=", "\"\"", ":", "\n", "    ", "vocabdict", "=", "json", ".", "load", "(", "args", ".", "vocab", ")", "\n", "vocabdict", "=", "{", "k", ":", "int", "(", "v", ")", "for", "k", ",", "v", "in", "vocabdict", ".", "items", "(", ")", "}", "\n", "", "corpus", "=", "Corpus", "(", "datafiles", ",", "\n", "maxlen", "=", "args", ".", "maxlen", ",", "\n", "vocab_size", "=", "args", ".", "vocab_size", ",", "\n", "lowercase", "=", "args", ".", "lowercase", ",", "\n", "vocab", "=", "vocabdict", ")", "\n"]], "home.repos.pwc.inspect_result.jakezhaojb_ARAE.lang.train.gen_fixed_noise": [[162, 183], ["gan_gen.eval", "autoencoder.eval", "gan_gen", "autoencoder.generate", "open", "max_indices.data.cpu().numpy.data.cpu().numpy", "f.write", "max_indices.data.cpu().numpy.data.cpu", "truncated_sent.append"], "function", ["home.repos.pwc.inspect_result.jakezhaojb_ARAE.lang.models.generate", "home.repos.pwc.inspect_result.jakezhaojb_ARAE.lang.preprocess_lm.Indexer.write"], ["# dumping vocabulary", "\n", "with", "open", "(", "'{}/vocab.json'", ".", "format", "(", "args", ".", "outf", ")", ",", "'w'", ")", "as", "f", ":", "\n", "    ", "json", ".", "dump", "(", "corpus", ".", "dictionary", ".", "word2idx", ",", "f", ")", "\n", "\n", "# save arguments", "\n", "", "ntokens", "=", "len", "(", "corpus", ".", "dictionary", ".", "word2idx", ")", "\n", "print", "(", "\"Vocabulary Size: {}\"", ".", "format", "(", "ntokens", ")", ")", "\n", "args", ".", "ntokens", "=", "ntokens", "\n", "with", "open", "(", "'{}/args.json'", ".", "format", "(", "args", ".", "outf", ")", ",", "'w'", ")", "as", "f", ":", "\n", "    ", "json", ".", "dump", "(", "vars", "(", "args", ")", ",", "f", ")", "\n", "", "with", "open", "(", "\"{}/log.txt\"", ".", "format", "(", "args", ".", "outf", ")", ",", "'w'", ")", "as", "f", ":", "\n", "    ", "f", ".", "write", "(", "str", "(", "vars", "(", "args", ")", ")", ")", "\n", "f", ".", "write", "(", "\"\\n\\n\"", ")", "\n", "\n", "", "eval_batch_size", "=", "100", "\n", "test1_data", "=", "batchify", "(", "corpus", ".", "data", "[", "'valid1'", "]", ",", "eval_batch_size", ",", "shuffle", "=", "False", ")", "\n", "test2_data", "=", "batchify", "(", "corpus", ".", "data", "[", "'valid2'", "]", ",", "eval_batch_size", ",", "shuffle", "=", "False", ")", "\n", "train1_data", "=", "batchify", "(", "corpus", ".", "data", "[", "'train1'", "]", ",", "args", ".", "batch_size", ",", "shuffle", "=", "True", ")", "\n", "train2_data", "=", "batchify", "(", "corpus", ".", "data", "[", "'train2'", "]", ",", "args", ".", "batch_size", ",", "shuffle", "=", "True", ")", "\n", "\n", "print", "(", "\"Loaded data!\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jakezhaojb_ARAE.lang.train.train_lm": [[185, 238], ["os.path.join", "torch.autograd.Variable", "range", "numpy.concatenate", "utils.train_ngram_lm", "utils.get_ppl", "torch.ones().cuda", "torch.ones().cuda", "torch.ones().cuda", "torch.ones().cuda", "torch.autograd.Variable.data.normal_", "gan_gen", "autoencoder.generate", "np.concatenate.append", "open", "corpus.dictionary.word2idx.keys", "utils.train_ngram_lm", "utils.get_ppl", "open", "f.readlines", "l.replace", "autoencoder.generate.data.cpu().numpy", "f.write", "f.write", "open", "f.readlines", "list", "l.replace", "print", "os.path.join", "random.choice", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "os.path.join", "map", "range", "autoencoder.generate.data.cpu", "truncated_sent.append", "x.lower"], "function", ["home.repos.pwc.inspect_result.jakezhaojb_ARAE.lang.utils.train_ngram_lm", "home.repos.pwc.inspect_result.jakezhaojb_ARAE.lang.utils.get_ppl", "home.repos.pwc.inspect_result.jakezhaojb_ARAE.lang.models.generate", "home.repos.pwc.inspect_result.jakezhaojb_ARAE.lang.utils.train_ngram_lm", "home.repos.pwc.inspect_result.jakezhaojb_ARAE.lang.utils.get_ppl", "home.repos.pwc.inspect_result.jakezhaojb_ARAE.lang.preprocess_lm.Indexer.write", "home.repos.pwc.inspect_result.jakezhaojb_ARAE.lang.preprocess_lm.Indexer.write"], ["# Build the models", "\n", "###############################################################################", "\n", "\n", "ntokens", "=", "len", "(", "corpus", ".", "dictionary", ".", "word2idx", ")", "\n", "autoencoder", "=", "Seq2Seq2Decoder", "(", "emsize", "=", "args", ".", "emsize", ",", "\n", "nhidden", "=", "args", ".", "nhidden", ",", "\n", "ntokens", "=", "ntokens", ",", "\n", "nlayers", "=", "args", ".", "nlayers", ",", "\n", "noise_r", "=", "args", ".", "noise_r", ",", "\n", "hidden_init", "=", "args", ".", "hidden_init", ",", "\n", "dropout", "=", "args", ".", "dropout", ",", "\n", "gpu", "=", "args", ".", "cuda", ")", "\n", "\n", "gan_gen", "=", "MLP_G", "(", "ninput", "=", "args", ".", "z_size", ",", "noutput", "=", "args", ".", "nhidden", ",", "layers", "=", "args", ".", "arch_g", ")", "\n", "gan_disc", "=", "MLP_D", "(", "ninput", "=", "args", ".", "nhidden", ",", "noutput", "=", "1", ",", "layers", "=", "args", ".", "arch_d", ")", "\n", "classifier", "=", "MLP_Classify", "(", "ninput", "=", "args", ".", "nhidden", ",", "noutput", "=", "1", ",", "layers", "=", "args", ".", "arch_classify", ")", "\n", "g_factor", "=", "None", "\n", "\n", "print", "(", "autoencoder", ")", "\n", "print", "(", "gan_gen", ")", "\n", "print", "(", "gan_disc", ")", "\n", "print", "(", "classifier", ")", "\n", "\n", "optimizer_ae", "=", "optim", ".", "SGD", "(", "autoencoder", ".", "parameters", "(", ")", ",", "lr", "=", "args", ".", "lr_ae", ")", "\n", "optimizer_gan_g", "=", "optim", ".", "Adam", "(", "gan_gen", ".", "parameters", "(", ")", ",", "\n", "lr", "=", "args", ".", "lr_gan_g", ",", "\n", "betas", "=", "(", "args", ".", "beta1", ",", "0.999", ")", ")", "\n", "optimizer_gan_d", "=", "optim", ".", "Adam", "(", "gan_disc", ".", "parameters", "(", ")", ",", "\n", "lr", "=", "args", ".", "lr_gan_d", ",", "\n", "betas", "=", "(", "args", ".", "beta1", ",", "0.999", ")", ")", "\n", "#### classify", "\n", "optimizer_classify", "=", "optim", ".", "Adam", "(", "classifier", ".", "parameters", "(", ")", ",", "\n", "lr", "=", "args", ".", "lr_classify", ",", "\n", "betas", "=", "(", "args", ".", "beta1", ",", "0.999", ")", ")", "\n", "\n", "criterion_ce", "=", "nn", ".", "CrossEntropyLoss", "(", ")", "\n", "\n", "if", "args", ".", "cuda", ":", "\n", "    ", "autoencoder", "=", "autoencoder", ".", "cuda", "(", ")", "\n", "gan_gen", "=", "gan_gen", ".", "cuda", "(", ")", "\n", "gan_disc", "=", "gan_disc", ".", "cuda", "(", ")", "\n", "classifier", "=", "classifier", ".", "cuda", "(", ")", "\n", "criterion_ce", "=", "criterion_ce", ".", "cuda", "(", ")", "\n", "\n", "###############################################################################", "\n", "# Training code", "\n", "###############################################################################", "\n", "\n", "\n", "", "def", "save_model", "(", ")", ":", "\n", "    ", "print", "(", "\"Saving models\"", ")", "\n", "with", "open", "(", "'{}/autoencoder_model.pt'", ".", "format", "(", "args", ".", "outf", ")", ",", "'wb'", ")", "as", "f", ":", "\n", "        ", "torch", ".", "save", "(", "autoencoder", ".", "state_dict", "(", ")", ",", "f", ")", "\n", "", "with", "open", "(", "'{}/gan_gen_model.pt'", ".", "format", "(", "args", ".", "outf", ")", ",", "'wb'", ")", "as", "f", ":", "\n"]], "home.repos.pwc.inspect_result.jakezhaojb_ARAE.lang.train.train_ae": [[240, 274], ["autoencoder.train", "optimizer_ae.zero_grad", "torch.autograd.Variable", "torch.autograd.Variable", "autoencoder", "torch.autograd.Variable.gt", "torch.autograd.Variable.masked_select", "target.gt.unsqueeze().expand", "autoencoder.view", "output.view.masked_select().view", "torch.cross_entropy", "F.cross_entropy.backward", "torch.nn.utils.clip_grad_norm", "torch.nn.utils.clip_grad_norm", "torch.nn.utils.clip_grad_norm", "torch.nn.utils.clip_grad_norm", "optimizer_ae.step", "torch.autograd.Variable.cuda", "torch.autograd.Variable.cuda", "target.gt.size", "autoencoder.parameters", "torch.softmax", "torch.max", "torch.max", "torch.max", "torch.max", "train.logging", "time.time", "target.gt.unsqueeze", "output.view.masked_select", "time.time", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "len", "math.exp", "max_indices.eq().float", "max_indices.eq"], "function", ["home.repos.pwc.inspect_result.jakezhaojb_ARAE.lang.train.train", "home.repos.pwc.inspect_result.jakezhaojb_ARAE.lang.train.logging"], ["", "with", "open", "(", "'{}/gan_disc_model.pt'", ".", "format", "(", "args", ".", "outf", ")", ",", "'wb'", ")", "as", "f", ":", "\n", "        ", "torch", ".", "save", "(", "gan_disc", ".", "state_dict", "(", ")", ",", "f", ")", "\n", "\n", "\n", "", "", "def", "train_classifier", "(", "whichclass", ",", "batch", ")", ":", "\n", "    ", "classifier", ".", "train", "(", ")", "\n", "classifier", ".", "zero_grad", "(", ")", "\n", "\n", "source", ",", "target", ",", "lengths", "=", "batch", "\n", "source", "=", "to_gpu", "(", "args", ".", "cuda", ",", "Variable", "(", "source", ")", ")", "\n", "labels", "=", "to_gpu", "(", "args", ".", "cuda", ",", "Variable", "(", "torch", ".", "zeros", "(", "source", ".", "size", "(", "0", ")", ")", ".", "fill_", "(", "whichclass", "-", "1", ")", ")", ")", "\n", "\n", "# Train", "\n", "code", "=", "autoencoder", "(", "0", ",", "source", ",", "lengths", ",", "noise", "=", "False", ",", "encode_only", "=", "True", ")", ".", "detach", "(", ")", "\n", "scores", "=", "classifier", "(", "code", ")", "\n", "classify_loss", "=", "F", ".", "binary_cross_entropy", "(", "scores", ".", "squeeze", "(", "1", ")", ",", "labels", ")", "\n", "classify_loss", ".", "backward", "(", ")", "\n", "optimizer_classify", ".", "step", "(", ")", "\n", "classify_loss", "=", "classify_loss", ".", "cpu", "(", ")", ".", "data", "[", "0", "]", "\n", "\n", "pred", "=", "scores", ".", "data", ".", "round", "(", ")", ".", "squeeze", "(", "1", ")", "\n", "accuracy", "=", "pred", ".", "eq", "(", "labels", ".", "data", ")", ".", "float", "(", ")", ".", "mean", "(", ")", "\n", "\n", "return", "classify_loss", ",", "accuracy", "\n", "\n", "\n", "", "def", "grad_hook_cla", "(", "grad", ")", ":", "\n", "    ", "return", "grad", "*", "args", ".", "lambda_class", "\n", "\n", "\n", "", "def", "classifier_regularize", "(", "whichclass", ",", "batch", ")", ":", "\n", "    ", "autoencoder", ".", "train", "(", ")", "\n", "autoencoder", ".", "zero_grad", "(", ")", "\n", "\n", "source", ",", "target", ",", "lengths", "=", "batch", "\n"]], "home.repos.pwc.inspect_result.jakezhaojb_ARAE.lang.train.train_gan_g": [[276, 287], ["gan_gen.train", "optimizer_gan_g.zero_grad", "torch.autograd.Variable", "gan_gen", "gan_disc", "gan_disc.backward", "optimizer_gan_g.step", "torch.Tensor().normal_().cuda", "torch.Tensor().normal_().cuda", "torch.Tensor().normal_().cuda", "torch.Tensor().normal_().cuda", "torch.Tensor().normal_", "torch.Tensor().normal_", "torch.Tensor().normal_", "torch.Tensor().normal_", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor"], "function", ["home.repos.pwc.inspect_result.jakezhaojb_ARAE.lang.train.train"], ["target", "=", "to_gpu", "(", "args", ".", "cuda", ",", "Variable", "(", "target", ")", ")", "\n", "flippedclass", "=", "abs", "(", "2", "-", "whichclass", ")", "\n", "labels", "=", "to_gpu", "(", "args", ".", "cuda", ",", "Variable", "(", "torch", ".", "zeros", "(", "source", ".", "size", "(", "0", ")", ")", ".", "fill_", "(", "flippedclass", ")", ")", ")", "\n", "\n", "# Train", "\n", "code", "=", "autoencoder", "(", "0", ",", "source", ",", "lengths", ",", "noise", "=", "False", ",", "encode_only", "=", "True", ")", "\n", "code", ".", "register_hook", "(", "grad_hook_cla", ")", "\n", "scores", "=", "classifier", "(", "code", ")", "\n", "classify_reg_loss", "=", "F", ".", "binary_cross_entropy", "(", "scores", ".", "squeeze", "(", "1", ")", ",", "labels", ")", "\n", "classify_reg_loss", ".", "backward", "(", ")", "\n", "\n", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm", "(", "autoencoder", ".", "parameters", "(", ")", ",", "args", ".", "clip", ")", "\n"]], "home.repos.pwc.inspect_result.jakezhaojb_ARAE.lang.train.grad_hook": [[289, 293], ["None"], "function", ["None"], ["\n", "return", "classify_reg_loss", "\n", "\n", "\n", "", "def", "evaluate_autoencoder", "(", "whichdecoder", ",", "data_source", ",", "epoch", ")", ":", "\n"]], "home.repos.pwc.inspect_result.jakezhaojb_ARAE.lang.train.calc_gradient_penalty": [[296, 312], ["real_data.size", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "alpha.cuda.expand", "alpha.cuda.cuda", "torch.autograd.Variable", "netD", "gradients.view.view", "real_data.size", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "gradients.view.size", "torch.ones().cuda", "torch.ones().cuda", "torch.ones().cuda", "torch.ones().cuda", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "gradients.view.norm", "netD.size"], "function", ["None"], ["total_loss", "=", "0", "\n", "ntokens", "=", "len", "(", "corpus", ".", "dictionary", ".", "word2idx", ")", "\n", "all_accuracies", "=", "0", "\n", "bcnt", "=", "0", "\n", "for", "i", ",", "batch", "in", "enumerate", "(", "data_source", ")", ":", "\n", "        ", "source", ",", "target", ",", "lengths", "=", "batch", "\n", "source", "=", "to_gpu", "(", "args", ".", "cuda", ",", "Variable", "(", "source", ",", "volatile", "=", "True", ")", ")", "\n", "target", "=", "to_gpu", "(", "args", ".", "cuda", ",", "Variable", "(", "target", ",", "volatile", "=", "True", ")", ")", "\n", "\n", "mask", "=", "target", ".", "gt", "(", "0", ")", "\n", "masked_target", "=", "target", ".", "masked_select", "(", "mask", ")", "\n", "# examples x ntokens", "\n", "output_mask", "=", "mask", ".", "unsqueeze", "(", "1", ")", ".", "expand", "(", "mask", ".", "size", "(", "0", ")", ",", "ntokens", ")", "\n", "\n", "hidden", "=", "autoencoder", "(", "0", ",", "source", ",", "lengths", ",", "noise", "=", "False", ",", "encode_only", "=", "True", ")", "\n", "\n", "# output: batch x seq_len x ntokens", "\n"]], "home.repos.pwc.inspect_result.jakezhaojb_ARAE.lang.train.train_gan_d": [[314, 338], ["gan_disc.train", "optimizer_gan_d.zero_grad", "torch.autograd.Variable", "torch.autograd.Variable", "autoencoder", "gan_disc", "gan_disc.backward", "torch.autograd.Variable", "gan_gen", "gan_disc", "gan_disc.backward", "train.calc_gradient_penalty", "calc_gradient_penalty.backward", "optimizer_gan_d.step", "torch.autograd.Variable.cuda", "torch.autograd.Variable.cuda", "autoencoder.detach", "torch.Tensor().normal_().cuda", "torch.Tensor().normal_().cuda", "torch.Tensor().normal_().cuda", "torch.Tensor().normal_().cuda", "gan_gen.detach", "torch.Tensor().normal_", "torch.Tensor().normal_", "torch.Tensor().normal_", "torch.Tensor().normal_", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor"], "function", ["home.repos.pwc.inspect_result.jakezhaojb_ARAE.lang.train.train", "home.repos.pwc.inspect_result.jakezhaojb_ARAE.lang.train.calc_gradient_penalty"], ["            ", "output", "=", "autoencoder", "(", "1", ",", "source", ",", "lengths", ",", "noise", "=", "False", ")", "\n", "flattened_output", "=", "output", ".", "view", "(", "-", "1", ",", "ntokens", ")", "\n", "masked_output", "=", "flattened_output", ".", "masked_select", "(", "output_mask", ")", ".", "view", "(", "-", "1", ",", "ntokens", ")", "\n", "# accuracy", "\n", "max_vals1", ",", "max_indices1", "=", "torch", ".", "max", "(", "masked_output", ",", "1", ")", "\n", "all_accuracies", "+=", "torch", ".", "mean", "(", "max_indices1", ".", "eq", "(", "masked_target", ")", ".", "float", "(", ")", ")", ".", "data", "[", "0", "]", "\n", "\n", "max_values1", ",", "max_indices1", "=", "torch", ".", "max", "(", "output", ",", "2", ")", "\n", "max_indices2", "=", "autoencoder", ".", "generate", "(", "2", ",", "hidden", ",", "maxlen", "=", "50", ")", "\n", "", "else", ":", "\n", "            ", "output", "=", "autoencoder", "(", "2", ",", "source", ",", "lengths", ",", "noise", "=", "False", ")", "\n", "flattened_output", "=", "output", ".", "view", "(", "-", "1", ",", "ntokens", ")", "\n", "masked_output", "=", "flattened_output", ".", "masked_select", "(", "output_mask", ")", ".", "view", "(", "-", "1", ",", "ntokens", ")", "\n", "# accuracy", "\n", "max_vals2", ",", "max_indices2", "=", "torch", ".", "max", "(", "masked_output", ",", "1", ")", "\n", "all_accuracies", "+=", "torch", ".", "mean", "(", "max_indices2", ".", "eq", "(", "masked_target", ")", ".", "float", "(", ")", ")", ".", "data", "[", "0", "]", "\n", "\n", "max_values2", ",", "max_indices2", "=", "torch", ".", "max", "(", "output", ",", "2", ")", "\n", "max_indices1", "=", "autoencoder", ".", "generate", "(", "1", ",", "hidden", ",", "maxlen", "=", "50", ")", "\n", "\n", "", "total_loss", "+=", "criterion_ce", "(", "masked_output", "/", "args", ".", "temp", ",", "masked_target", ")", ".", "data", "\n"]], "home.repos.pwc.inspect_result.jakezhaojb_ARAE.lang.train.train_gan_d_into_ae": [[340, 355], ["autoencoder.train", "optimizer_ae.zero_grad", "torch.autograd.Variable", "torch.autograd.Variable", "autoencoder", "autoencoder.register_hook", "gan_disc", "gan_disc.backward", "torch.nn.utils.clip_grad_norm", "torch.nn.utils.clip_grad_norm", "torch.nn.utils.clip_grad_norm", "torch.nn.utils.clip_grad_norm", "optimizer_ae.step", "torch.autograd.Variable.cuda", "torch.autograd.Variable.cuda", "autoencoder.parameters"], "function", ["home.repos.pwc.inspect_result.jakezhaojb_ARAE.lang.train.train"], ["\n", "aeoutf_from", "=", "\"{}/{}_output_decoder_{}_from.txt\"", ".", "format", "(", "args", ".", "outf", ",", "epoch", ",", "whichdecoder", ")", "\n", "aeoutf_tran", "=", "\"{}/{}_output_decoder_{}_tran.txt\"", ".", "format", "(", "args", ".", "outf", ",", "epoch", ",", "whichdecoder", ")", "\n", "with", "open", "(", "aeoutf_from", ",", "'w'", ")", "as", "f_from", ",", "open", "(", "aeoutf_tran", ",", "'w'", ")", "as", "f_trans", ":", "\n", "            ", "max_indices1", "=", "max_indices1", ".", "view", "(", "output", ".", "size", "(", "0", ")", ",", "-", "1", ")", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "max_indices2", "=", "max_indices2", ".", "view", "(", "output", ".", "size", "(", "0", ")", ",", "-", "1", ")", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "target", "=", "target", ".", "view", "(", "output", ".", "size", "(", "0", ")", ",", "-", "1", ")", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "tran_indices", "=", "max_indices2", "if", "whichdecoder", "==", "1", "else", "max_indices1", "\n", "for", "t", ",", "tran_idx", "in", "zip", "(", "target", ",", "tran_indices", ")", ":", "\n", "# real sentence", "\n", "                ", "chars", "=", "\" \"", ".", "join", "(", "[", "corpus", ".", "dictionary", ".", "idx2word", "[", "x", "]", "for", "x", "in", "t", "]", ")", "\n", "f_from", ".", "write", "(", "chars", ")", "\n", "f_from", ".", "write", "(", "\"\\n\"", ")", "\n", "# transfer sentence", "\n"]], "home.repos.pwc.inspect_result.jakezhaojb_ARAE.lang.train.train": [[357, 433], ["train.logging", "utils.batchify", "torch.autograd.Variable", "range", "torch.ones().normal_().cuda", "torch.ones().normal_().cuda", "torch.ones().normal_().cuda", "torch.ones().normal_().cuda", "time.time", "time.time", "train.evaluate_autoencoder", "train.logging", "train.gen_fixed_noise", "train.train_lm", "train.logging", "train.logging", "int", "train.logging", "len", "range", "range", "os.path.join", "train.logging", "train.save_model", "args.niters_gan_schedule.split", "torch.ones().normal_", "torch.ones().normal_", "torch.ones().normal_", "torch.ones().normal_", "train.train_ae", "range", "range", "range", "autoencoder.noise_anneal", "train.logging", "math.exp", "len", "train.train_gan_d", "train.train_gan_d_into_ae", "train.train_gan_g", "time.time", "train.logging", "sys.exit", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "len", "random.randint", "random.randint", "len", "len"], "function", ["home.repos.pwc.inspect_result.jakezhaojb_ARAE.lang.train.logging", "home.repos.pwc.inspect_result.jakezhaojb_ARAE.lang.utils.batchify", "home.repos.pwc.inspect_result.jakezhaojb_ARAE.lang.train.evaluate_autoencoder", "home.repos.pwc.inspect_result.jakezhaojb_ARAE.lang.train.logging", "home.repos.pwc.inspect_result.jakezhaojb_ARAE.lang.train.gen_fixed_noise", "home.repos.pwc.inspect_result.jakezhaojb_ARAE.lang.train.train_lm", "home.repos.pwc.inspect_result.jakezhaojb_ARAE.lang.train.logging", "home.repos.pwc.inspect_result.jakezhaojb_ARAE.lang.train.logging", "home.repos.pwc.inspect_result.jakezhaojb_ARAE.lang.train.logging", "home.repos.pwc.inspect_result.jakezhaojb_ARAE.lang.train.logging", "home.repos.pwc.inspect_result.jakezhaojb_ARAE.lang.train.save_model", "home.repos.pwc.inspect_result.jakezhaojb_ARAE.lang.train.train_ae", "home.repos.pwc.inspect_result.jakezhaojb_ARAE.lang.models.Seq2Seq.noise_anneal", "home.repos.pwc.inspect_result.jakezhaojb_ARAE.lang.train.logging", "home.repos.pwc.inspect_result.jakezhaojb_ARAE.lang.train.train_gan_d", "home.repos.pwc.inspect_result.jakezhaojb_ARAE.lang.train.train_gan_d_into_ae", "home.repos.pwc.inspect_result.jakezhaojb_ARAE.lang.train.train_gan_g", "home.repos.pwc.inspect_result.jakezhaojb_ARAE.lang.train.logging"], ["f_trans", ".", "write", "(", "chars", ")", "\n", "f_trans", ".", "write", "(", "\"\\n\"", ")", "\n", "\n", "", "", "", "return", "total_loss", "[", "0", "]", "/", "len", "(", "data_source", ")", ",", "all_accuracies", "/", "bcnt", "\n", "\n", "\n", "", "def", "evaluate_generator", "(", "whichdecoder", ",", "noise", ",", "epoch", ")", ":", "\n", "    ", "gan_gen", ".", "eval", "(", ")", "\n", "autoencoder", ".", "eval", "(", ")", "\n", "\n", "# generate from fixed random noise", "\n", "fake_hidden", "=", "gan_gen", "(", "noise", ")", "\n", "max_indices", "=", "autoencoder", ".", "generate", "(", "whichdecoder", ",", "fake_hidden", ",", "maxlen", "=", "50", ",", "sample", "=", "args", ".", "sample", ")", "\n", "\n", "with", "open", "(", "\"%s/%s_generated%d.txt\"", "%", "(", "args", ".", "outf", ",", "epoch", ",", "whichdecoder", ")", ",", "\"w\"", ")", "as", "f", ":", "\n", "        ", "max_indices", "=", "max_indices", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "for", "idx", "in", "max_indices", ":", "\n", "# generated sentence", "\n", "            ", "words", "=", "[", "corpus", ".", "dictionary", ".", "idx2word", "[", "x", "]", "for", "x", "in", "idx", "]", "\n", "# truncate sentences to first occurrence of <eos>", "\n", "truncated_sent", "=", "[", "]", "\n", "for", "w", "in", "words", ":", "\n", "                ", "if", "w", "!=", "'<eos>'", ":", "\n", "                    ", "truncated_sent", ".", "append", "(", "w", ")", "\n", "", "else", ":", "\n", "                    ", "break", "\n", "", "", "chars", "=", "\" \"", ".", "join", "(", "truncated_sent", ")", "\n", "f", ".", "write", "(", "chars", ")", "\n", "f", ".", "write", "(", "\"\\n\"", ")", "\n", "\n", "\n", "", "", "", "def", "train_ae", "(", "whichdecoder", ",", "batch", ",", "total_loss_ae", ",", "start_time", ",", "i", ")", ":", "\n", "    ", "autoencoder", ".", "train", "(", ")", "\n", "optimizer_ae", ".", "zero_grad", "(", ")", "\n", "\n", "source", ",", "target", ",", "lengths", "=", "batch", "\n", "source", "=", "to_gpu", "(", "args", ".", "cuda", ",", "Variable", "(", "source", ")", ")", "\n", "target", "=", "to_gpu", "(", "args", ".", "cuda", ",", "Variable", "(", "target", ")", ")", "\n", "\n", "mask", "=", "target", ".", "gt", "(", "0", ")", "\n", "masked_target", "=", "target", ".", "masked_select", "(", "mask", ")", "\n", "output_mask", "=", "mask", ".", "unsqueeze", "(", "1", ")", ".", "expand", "(", "mask", ".", "size", "(", "0", ")", ",", "ntokens", ")", "\n", "output", "=", "autoencoder", "(", "whichdecoder", ",", "source", ",", "lengths", ",", "noise", "=", "True", ")", "\n", "flat_output", "=", "output", ".", "view", "(", "-", "1", ",", "ntokens", ")", "\n", "masked_output", "=", "flat_output", ".", "masked_select", "(", "output_mask", ")", ".", "view", "(", "-", "1", ",", "ntokens", ")", "\n", "loss", "=", "criterion_ce", "(", "masked_output", "/", "args", ".", "temp", ",", "masked_target", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "\n", "# `clip_grad_norm` to prevent exploding gradient in RNNs / LSTMs", "\n", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm", "(", "autoencoder", ".", "parameters", "(", ")", ",", "args", ".", "clip", ")", "\n", "optimizer_ae", ".", "step", "(", ")", "\n", "\n", "total_loss_ae", "+=", "loss", ".", "data", "\n", "\n", "accuracy", "=", "None", "\n", "if", "i", "%", "args", ".", "log_interval", "==", "0", "and", "i", ">", "0", ":", "\n", "        ", "probs", "=", "F", ".", "softmax", "(", "masked_output", ",", "dim", "=", "-", "1", ")", "\n", "max_vals", ",", "max_indices", "=", "torch", ".", "max", "(", "probs", ",", "1", ")", "\n", "accuracy", "=", "torch", ".", "mean", "(", "max_indices", ".", "eq", "(", "masked_target", ")", ".", "float", "(", ")", ")", ".", "data", "[", "0", "]", "\n", "cur_loss", "=", "total_loss_ae", "[", "0", "]", "/", "args", ".", "log_interval", "\n", "elapsed", "=", "time", ".", "time", "(", ")", "-", "start_time", "\n", "print", "(", "'| epoch {:3d} | {:5d}/{:5d} batches | ms/batch {:5.2f} | '", "\n", "'loss {:5.2f} | ppl {:8.2f} | acc {:8.2f}'", "\n", ".", "format", "(", "epoch", ",", "i", ",", "len", "(", "train1_data", ")", ",", "\n", "elapsed", "*", "1000", "/", "args", ".", "log_interval", ",", "\n", "cur_loss", ",", "math", ".", "exp", "(", "cur_loss", ")", ",", "accuracy", ")", ")", "\n", "\n", "with", "open", "(", "\"{}/log.txt\"", ".", "format", "(", "args", ".", "outf", ")", ",", "'a'", ")", "as", "f", ":", "\n", "            ", "f", ".", "write", "(", "'| epoch {:3d} | {:5d}/{:5d} batches | ms/batch {:5.2f} | '", "\n", "'loss {:5.2f} | ppl {:8.2f} | acc {:8.2f}\\n'", ".", "\n", "format", "(", "epoch", ",", "i", ",", "len", "(", "train1_data", ")", ",", "\n", "elapsed", "*", "1000", "/", "args", ".", "log_interval", ",", "\n", "cur_loss", ",", "math", ".", "exp", "(", "cur_loss", ")", ",", "accuracy", ")", ")", "\n", "\n", "", "total_loss_ae", "=", "0", "\n", "start_time", "=", "time", ".", "time", "(", ")", "\n"]], "home.repos.pwc.inspect_result.jakezhaojb_ARAE.lang.preprocess_lm.Indexer.__init__": [[16, 24], ["collections.defaultdict"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "symbols", "=", "[", "\"<pad>\"", ",", "\"<unk>\"", ",", "\"<s>\"", ",", "\"</s>\"", "]", ")", ":", "\n", "        ", "self", ".", "vocab", "=", "defaultdict", "(", "int", ")", "\n", "self", ".", "PAD", "=", "symbols", "[", "0", "]", "\n", "self", ".", "UNK", "=", "symbols", "[", "1", "]", "\n", "self", ".", "BOS", "=", "symbols", "[", "2", "]", "\n", "self", ".", "EOS", "=", "symbols", "[", "3", "]", "\n", "self", ".", "d", "=", "{", "self", ".", "PAD", ":", "0", ",", "self", ".", "UNK", ":", "1", ",", "self", ".", "BOS", ":", "2", ",", "self", ".", "EOS", ":", "3", "}", "\n", "self", ".", "idx2word", "=", "{", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.jakezhaojb_ARAE.lang.preprocess_lm.Indexer.add_w": [[25, 29], ["len"], "methods", ["None"], ["", "def", "add_w", "(", "self", ",", "ws", ")", ":", "\n", "        ", "for", "w", "in", "ws", ":", "\n", "            ", "if", "w", "not", "in", "self", ".", "d", ":", "\n", "                ", "self", ".", "d", "[", "w", "]", "=", "len", "(", "self", ".", "d", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jakezhaojb_ARAE.lang.preprocess_lm.Indexer.convert": [[30, 32], ["None"], "methods", ["None"], ["", "", "", "def", "convert", "(", "self", ",", "w", ")", ":", "\n", "        ", "return", "self", ".", "d", "[", "w", "]", "if", "w", "in", "self", ".", "d", "else", "self", ".", "d", "[", "self", ".", "UNK", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.jakezhaojb_ARAE.lang.preprocess_lm.Indexer.convert_sequence": [[33, 35], ["preprocess_lm.Indexer.convert"], "methods", ["home.repos.pwc.inspect_result.jakezhaojb_ARAE.lang.preprocess_lm.Indexer.convert"], ["", "def", "convert_sequence", "(", "self", ",", "ls", ")", ":", "\n", "        ", "return", "[", "self", ".", "convert", "(", "l", ")", "for", "l", "in", "ls", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.jakezhaojb_ARAE.lang.preprocess_lm.Indexer.write": [[36, 43], ["open", "items.sort", "open.close", "open.write", "preprocess_lm.Indexer.d.items", "str"], "methods", ["home.repos.pwc.inspect_result.jakezhaojb_ARAE.lang.preprocess_lm.Indexer.write"], ["", "def", "write", "(", "self", ",", "outfile", ")", ":", "\n", "        ", "out", "=", "open", "(", "outfile", ",", "\"w\"", ")", "\n", "items", "=", "[", "(", "v", ",", "k", ")", "for", "k", ",", "v", "in", "self", ".", "d", ".", "items", "(", ")", "]", "\n", "items", ".", "sort", "(", ")", "\n", "for", "v", ",", "k", "in", "items", ":", "\n", "            ", "out", ".", "write", "(", "\" \"", ".", "join", "(", "[", "k", ",", "str", "(", "v", ")", "]", ")", "+", "\"\\n\"", ")", "\n", "", "out", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jakezhaojb_ARAE.lang.preprocess_lm.Indexer.prune_vocab": [[44, 57], ["preprocess_lm.Indexer.d.items", "vocab_list.sort", "min", "preprocess_lm.Indexer.vocab.items", "len", "len"], "methods", ["None"], ["", "def", "prune_vocab", "(", "self", ",", "k", ",", "cnt", "=", "False", ")", ":", "\n", "        ", "vocab_list", "=", "[", "(", "word", ",", "count", ")", "for", "word", ",", "count", "in", "self", ".", "vocab", ".", "items", "(", ")", "]", "\n", "if", "cnt", ":", "\n", "            ", "self", ".", "pruned_vocab", "=", "{", "pair", "[", "0", "]", ":", "pair", "[", "1", "]", "for", "pair", "in", "vocab_list", "if", "pair", "[", "1", "]", ">", "k", "}", "\n", "", "else", ":", "\n", "            ", "vocab_list", ".", "sort", "(", "key", "=", "lambda", "x", ":", "x", "[", "1", "]", ",", "reverse", "=", "True", ")", "\n", "k", "=", "min", "(", "k", ",", "len", "(", "vocab_list", ")", ")", "\n", "self", ".", "pruned_vocab", "=", "{", "pair", "[", "0", "]", ":", "pair", "[", "1", "]", "for", "pair", "in", "vocab_list", "[", ":", "k", "]", "}", "\n", "", "for", "word", "in", "self", ".", "pruned_vocab", ":", "\n", "            ", "if", "word", "not", "in", "self", ".", "d", ":", "\n", "                ", "self", ".", "d", "[", "word", "]", "=", "len", "(", "self", ".", "d", ")", "\n", "", "", "for", "word", ",", "idx", "in", "self", ".", "d", ".", "items", "(", ")", ":", "\n", "            ", "self", ".", "idx2word", "[", "idx", "]", "=", "word", "\n", "\n"]], "home.repos.pwc.inspect_result.jakezhaojb_ARAE.lang.preprocess_lm.Indexer.load_vocab": [[58, 65], ["open", "preprocess_lm.Indexer.d.items", "line.strip().split", "int", "line.strip"], "methods", ["None"], ["", "", "def", "load_vocab", "(", "self", ",", "vocab_file", ")", ":", "\n", "        ", "self", ".", "d", "=", "{", "}", "\n", "for", "line", "in", "open", "(", "vocab_file", ",", "'r'", ")", ":", "\n", "            ", "v", ",", "k", "=", "line", ".", "strip", "(", ")", ".", "split", "(", ")", "\n", "self", ".", "d", "[", "v", "]", "=", "int", "(", "k", ")", "\n", "", "for", "word", ",", "idx", "in", "self", ".", "d", ".", "items", "(", ")", ":", "\n", "            ", "self", ".", "idx2word", "[", "idx", "]", "=", "word", "\n", "\n"]], "home.repos.pwc.inspect_result.jakezhaojb_ARAE.lang.preprocess_lm.pad": [[66, 70], ["len", "len"], "function", ["None"], ["", "", "", "def", "pad", "(", "ls", ",", "length", ",", "symbol", ")", ":", "\n", "    ", "if", "len", "(", "ls", ")", ">=", "length", ":", "\n", "        ", "return", "ls", "[", ":", "length", "]", "\n", "", "return", "ls", "+", "[", "symbol", "]", "*", "(", "length", "-", "len", "(", "ls", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jakezhaojb_ARAE.lang.preprocess_lm.get_data": [[71, 179], ["preprocess_lm.Indexer", "print", "preprocess_lm.get_data.make_vocab"], "function", ["home.repos.pwc.inspect_result.jakezhaojb_ARAE.lang.utils.Corpus.make_vocab"], ["", "def", "get_data", "(", "args", ")", ":", "\n", "    ", "indexer", "=", "Indexer", "(", "[", "\"<pad>\"", ",", "\"<unk>\"", ",", "\"<s>\"", ",", "\"</s>\"", "]", ")", "\n", "\n", "def", "make_vocab", "(", "textfile", ",", "seqlength", ",", "train", "=", "1", ")", ":", "\n", "        ", "num_sents", "=", "0", "\n", "for", "sent", "in", "open", "(", "textfile", ",", "'r'", ")", ":", "\n", "            ", "sent", "=", "sent", ".", "strip", "(", ")", ".", "split", "(", ")", "\n", "if", "len", "(", "sent", ")", ">", "seqlength", "or", "len", "(", "sent", ")", "<", "1", ":", "\n", "                ", "continue", "\n", "", "num_sents", "+=", "1", "\n", "if", "train", "==", "1", ":", "\n", "                ", "for", "word", "in", "sent", ":", "\n", "                    ", "indexer", ".", "vocab", "[", "word", "]", "+=", "1", "\n", "", "", "", "return", "num_sents", "\n", "\n", "", "def", "convert", "(", "textfile", ",", "batchsize", ",", "seqlength", ",", "outfile", ",", "num_sents", ",", "max_sent_l", "=", "0", ",", "shuffle", "=", "0", ")", ":", "\n", "        ", "newseqlength", "=", "seqlength", "+", "2", "#add 2 for EOS and BOS", "\n", "sents", "=", "np", ".", "zeros", "(", "(", "num_sents", ",", "newseqlength", ")", ",", "dtype", "=", "int", ")", "\n", "sent_lengths", "=", "np", ".", "zeros", "(", "(", "num_sents", ",", ")", ",", "dtype", "=", "int", ")", "\n", "dropped", "=", "0", "\n", "sent_id", "=", "0", "\n", "for", "sent", "in", "open", "(", "textfile", ",", "'r'", ")", ":", "\n", "            ", "sent", "=", "[", "indexer", ".", "BOS", "]", "+", "sent", ".", "strip", "(", ")", ".", "split", "(", ")", "+", "[", "indexer", ".", "EOS", "]", "\n", "max_sent_l", "=", "max", "(", "len", "(", "sent", ")", ",", "max_sent_l", ")", "\n", "if", "len", "(", "sent", ")", ">", "seqlength", "+", "2", "or", "len", "(", "sent", ")", "<", "3", ":", "\n", "                ", "dropped", "+=", "1", "\n", "continue", "\n", "", "sent_pad", "=", "pad", "(", "sent", ",", "newseqlength", ",", "indexer", ".", "PAD", ")", "\n", "sents", "[", "sent_id", "]", "=", "np", ".", "array", "(", "indexer", ".", "convert_sequence", "(", "sent_pad", ")", ",", "dtype", "=", "int", ")", "\n", "sent_lengths", "[", "sent_id", "]", "=", "(", "sents", "[", "sent_id", "]", "!=", "0", ")", ".", "sum", "(", ")", "\n", "sent_id", "+=", "1", "\n", "if", "sent_id", "%", "100000", "==", "0", ":", "\n", "                ", "print", "(", "\"{}/{} sentences processed\"", ".", "format", "(", "sent_id", ",", "num_sents", ")", ")", "\n", "", "", "print", "(", "sent_id", ",", "num_sents", ")", "\n", "if", "shuffle", "==", "1", ":", "\n", "            ", "rand_idx", "=", "np", ".", "random", ".", "permutation", "(", "sent_id", ")", "\n", "sents", "=", "sents", "[", "rand_idx", "]", "\n", "sent_lengths", "=", "sent_lengths", "[", "rand_idx", "]", "\n", "\n", "#break up batches based on source lengths", "\n", "", "sent_lengths", "=", "sent_lengths", "[", ":", "sent_id", "]", "\n", "sent_sort", "=", "np", ".", "argsort", "(", "sent_lengths", ")", "\n", "sents", "=", "sents", "[", "sent_sort", "]", "\n", "sent_l", "=", "sent_lengths", "[", "sent_sort", "]", "\n", "curr_l", "=", "1", "\n", "l_location", "=", "[", "]", "#idx where sent length changes", "\n", "\n", "for", "j", ",", "i", "in", "enumerate", "(", "sent_sort", ")", ":", "\n", "            ", "if", "sent_lengths", "[", "i", "]", ">", "curr_l", ":", "\n", "                ", "curr_l", "=", "sent_lengths", "[", "i", "]", "\n", "l_location", ".", "append", "(", "j", ")", "\n", "", "", "l_location", ".", "append", "(", "len", "(", "sents", ")", ")", "\n", "#get batch sizes", "\n", "curr_idx", "=", "0", "\n", "batch_idx", "=", "[", "0", "]", "\n", "nonzeros", "=", "[", "]", "\n", "batch_l", "=", "[", "]", "\n", "batch_w", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "l_location", ")", "-", "1", ")", ":", "\n", "            ", "while", "curr_idx", "<", "l_location", "[", "i", "+", "1", "]", ":", "\n", "                ", "curr_idx", "=", "min", "(", "curr_idx", "+", "batchsize", ",", "l_location", "[", "i", "+", "1", "]", ")", "\n", "batch_idx", ".", "append", "(", "curr_idx", ")", "\n", "", "", "for", "i", "in", "range", "(", "len", "(", "batch_idx", ")", "-", "1", ")", ":", "\n", "            ", "batch_l", ".", "append", "(", "batch_idx", "[", "i", "+", "1", "]", "-", "batch_idx", "[", "i", "]", ")", "\n", "batch_w", ".", "append", "(", "sent_l", "[", "batch_idx", "[", "i", "]", "]", ")", "\n", "\n", "# Write output", "\n", "", "f", "=", "h5py", ".", "File", "(", "outfile", ",", "\"w\"", ")", "\n", "\n", "f", "[", "\"source\"", "]", "=", "sents", "\n", "f", "[", "\"batch_l\"", "]", "=", "np", ".", "array", "(", "batch_l", ",", "dtype", "=", "int", ")", "\n", "f", "[", "\"source_l\"", "]", "=", "np", ".", "array", "(", "batch_w", ",", "dtype", "=", "int", ")", "\n", "f", "[", "\"sents_l\"", "]", "=", "np", ".", "array", "(", "sent_l", ",", "dtype", "=", "int", ")", "\n", "f", "[", "\"batch_idx\"", "]", "=", "np", ".", "array", "(", "batch_idx", "[", ":", "-", "1", "]", ",", "dtype", "=", "int", ")", "\n", "f", "[", "\"vocab_size\"", "]", "=", "np", ".", "array", "(", "[", "len", "(", "indexer", ".", "d", ")", "]", ")", "\n", "print", "(", "\"Saved {} sentences (dropped {} due to length/unk filter)\"", ".", "format", "(", "\n", "len", "(", "f", "[", "\"source\"", "]", ")", ",", "dropped", ")", ")", "\n", "f", ".", "close", "(", ")", "\n", "return", "max_sent_l", "\n", "\n", "", "print", "(", "\"First pass through data to get vocab...\"", ")", "\n", "num_sents_train", "=", "make_vocab", "(", "args", ".", "trainfile", ",", "args", ".", "seqlength", ")", "\n", "print", "(", "\"Number of sentences in training: {}\"", ".", "format", "(", "num_sents_train", ")", ")", "\n", "num_sents_valid", "=", "make_vocab", "(", "args", ".", "valfile", ",", "args", ".", "seqlength", ",", "0", ")", "\n", "print", "(", "\"Number of sentences in valid: {}\"", ".", "format", "(", "num_sents_valid", ")", ")", "\n", "num_sents_test", "=", "make_vocab", "(", "args", ".", "testfile", ",", "args", ".", "seqlength", ",", "0", ")", "\n", "print", "(", "\"Number of sentences in test: {}\"", ".", "format", "(", "num_sents_test", ")", ")", "\n", "if", "args", ".", "vocabminfreq", ">=", "0", ":", "\n", "        ", "indexer", ".", "prune_vocab", "(", "args", ".", "vocabminfreq", ",", "True", ")", "\n", "", "else", ":", "\n", "        ", "indexer", ".", "prune_vocab", "(", "args", ".", "vocabsize", ",", "False", ")", "\n", "", "if", "args", ".", "vocabfile", "!=", "''", ":", "\n", "        ", "print", "(", "'Loading pre-specified source vocab from '", "+", "args", ".", "vocabfile", ")", "\n", "indexer", ".", "load_vocab", "(", "args", ".", "vocabfile", ")", "\n", "", "indexer", ".", "write", "(", "args", ".", "outputfile", "+", "\".dict\"", ")", "\n", "print", "(", "\"Vocab size: Original = {}, Pruned = {}\"", ".", "format", "(", "len", "(", "indexer", ".", "vocab", ")", ",", "\n", "len", "(", "indexer", ".", "d", ")", ")", ")", "\n", "max_sent_l", "=", "0", "\n", "max_sent_l", "=", "convert", "(", "args", ".", "valfile", ",", "args", ".", "batchsize", ",", "args", ".", "seqlength", ",", "\n", "args", ".", "outputfile", "+", "\"-val.hdf5\"", ",", "num_sents_valid", ",", "\n", "max_sent_l", ",", "args", ".", "shuffle", ")", "\n", "max_sent_l", "=", "convert", "(", "args", ".", "testfile", ",", "args", ".", "batchsize", ",", "args", ".", "seqlength", ",", "\n", "args", ".", "outputfile", "+", "\"-test.hdf5\"", ",", "num_sents_test", ",", "\n", "max_sent_l", ",", "args", ".", "shuffle", ")", "\n", "max_sent_l", "=", "convert", "(", "args", ".", "trainfile", ",", "args", ".", "batchsize", ",", "args", ".", "seqlength", ",", "\n", "args", ".", "outputfile", "+", "\"-train.hdf5\"", ",", "num_sents_train", ",", "\n", "max_sent_l", ",", "args", ".", "shuffle", ")", "\n", "print", "(", "\"Max sent length (before dropping): {}\"", ".", "format", "(", "max_sent_l", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jakezhaojb_ARAE.lang.preprocess_lm.main": [[180, 207], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "preprocess_lm.get_data"], "function", ["home.repos.pwc.inspect_result.jakezhaojb_ARAE.lang.preprocess_lm.get_data"], ["", "def", "main", "(", "arguments", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "\n", "description", "=", "__doc__", ",", "\n", "formatter_class", "=", "argparse", ".", "ArgumentDefaultsHelpFormatter", ")", "\n", "parser", ".", "add_argument", "(", "'--vocabsize'", ",", "help", "=", "\"Size of source vocabulary, constructed \"", "\n", "\"by taking the top X most frequent words. \"", "\n", "\" Rest are replaced with special UNK tokens.\"", ",", "\n", "type", "=", "int", ",", "default", "=", "70000", ")", "\n", "parser", ".", "add_argument", "(", "'--vocabminfreq'", ",", "help", "=", "\"Minimum frequency for vocab, if using frequency cutoff\"", ",", "\n", "type", "=", "int", ",", "default", "=", "-", "1", ")", "\n", "parser", ".", "add_argument", "(", "'--trainfile'", ",", "help", "=", "\"Path to training data.\"", ",", "required", "=", "True", ")", "\n", "parser", ".", "add_argument", "(", "'--valfile'", ",", "help", "=", "\"Path validation data.\"", ",", "required", "=", "True", ")", "\n", "parser", ".", "add_argument", "(", "'--testfile'", ",", "help", "=", "\"Path to test data.\"", ",", "required", "=", "True", ")", "\n", "parser", ".", "add_argument", "(", "'--batchsize'", ",", "help", "=", "\"Size of each minibatch.\"", ",", "type", "=", "int", ",", "default", "=", "32", ")", "\n", "parser", ".", "add_argument", "(", "'--seqlength'", ",", "help", "=", "\"Maximum source sequence length. Sequences longer \"", "\n", "\"than this are dropped.\"", ",", "type", "=", "int", ",", "default", "=", "200", ")", "\n", "parser", ".", "add_argument", "(", "'--outputfile'", ",", "help", "=", "\"Prefix of the output file names. \"", ",", "type", "=", "str", ")", "\n", "parser", ".", "add_argument", "(", "'--vocabfile'", ",", "help", "=", "\"If working with a preset vocab, \"", "\n", "\"then including this will ignore srcvocabsize and use the\"", "\n", "\"vocab provided here.\"", ",", "\n", "type", "=", "str", ",", "default", "=", "''", ")", "\n", "parser", ".", "add_argument", "(", "'--shuffle'", ",", "help", "=", "\"If = 1, shuffle sentences before sorting (based on  \"", "\n", "\"source length).\"", ",", "\n", "type", "=", "int", ",", "default", "=", "1", ")", "\n", "\n", "args", "=", "parser", ".", "parse_args", "(", "arguments", ")", "\n", "get_data", "(", "args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jakezhaojb_ARAE.lang.snli_preprocessing.transform_data": [[13, 51], ["print", "codecs.open", "json.loads", "loaded_example[].split", "loaded_example[].split", "hypotheses.append", "premises.append", "premise_words.append", "hypothesis_words.append"], "function", ["None"], ["def", "transform_data", "(", "in_path", ")", ":", "\n", "    ", "print", "(", "\"Loading\"", ",", "in_path", ")", "\n", "\n", "premises", "=", "[", "]", "\n", "hypotheses", "=", "[", "]", "\n", "\n", "last_premise", "=", "None", "\n", "with", "codecs", ".", "open", "(", "in_path", ",", "encoding", "=", "'utf-8'", ")", "as", "f", ":", "\n", "        ", "for", "line", "in", "f", ":", "\n", "            ", "loaded_example", "=", "json", ".", "loads", "(", "line", ")", "\n", "\n", "# load premise", "\n", "raw_premise", "=", "loaded_example", "[", "'sentence1_binary_parse'", "]", ".", "split", "(", "\" \"", ")", "\n", "premise_words", "=", "[", "]", "\n", "# loop through words of premise binary parse", "\n", "for", "word", "in", "raw_premise", ":", "\n", "# don't add parse brackets", "\n", "                ", "if", "word", "!=", "\"(\"", "and", "word", "!=", "\")\"", ":", "\n", "                    ", "premise_words", ".", "append", "(", "word", ")", "\n", "", "", "premise", "=", "\" \"", ".", "join", "(", "premise_words", ")", "\n", "\n", "# load hypothesis", "\n", "raw_hypothesis", "=", "loaded_example", "[", "'sentence2_binary_parse'", "]", ".", "split", "(", "\" \"", ")", "\n", "hypothesis_words", "=", "[", "]", "\n", "for", "word", "in", "raw_hypothesis", ":", "\n", "                ", "if", "word", "!=", "\"(\"", "and", "word", "!=", "\")\"", ":", "\n", "                    ", "hypothesis_words", ".", "append", "(", "word", ")", "\n", "", "", "hypothesis", "=", "\" \"", ".", "join", "(", "hypothesis_words", ")", "\n", "\n", "# make sure to not repeat premiess", "\n", "if", "premise", "!=", "last_premise", ":", "\n", "                ", "premises", ".", "append", "(", "premise", ")", "\n", "", "hypotheses", ".", "append", "(", "hypothesis", ")", "\n", "\n", "last_premise", "=", "premise", "\n", "\n", "", "", "return", "premises", ",", "hypotheses", "\n", "\n"]], "home.repos.pwc.inspect_result.jakezhaojb_ARAE.lang.snli_preprocessing.write_sentences": [[53, 71], ["print", "open", "open", "f.write", "f.write", "f.write", "f.write", "f.write", "f.write", "f.write", "f.write"], "function", ["home.repos.pwc.inspect_result.jakezhaojb_ARAE.lang.preprocess_lm.Indexer.write", "home.repos.pwc.inspect_result.jakezhaojb_ARAE.lang.preprocess_lm.Indexer.write", "home.repos.pwc.inspect_result.jakezhaojb_ARAE.lang.preprocess_lm.Indexer.write", "home.repos.pwc.inspect_result.jakezhaojb_ARAE.lang.preprocess_lm.Indexer.write", "home.repos.pwc.inspect_result.jakezhaojb_ARAE.lang.preprocess_lm.Indexer.write", "home.repos.pwc.inspect_result.jakezhaojb_ARAE.lang.preprocess_lm.Indexer.write", "home.repos.pwc.inspect_result.jakezhaojb_ARAE.lang.preprocess_lm.Indexer.write", "home.repos.pwc.inspect_result.jakezhaojb_ARAE.lang.preprocess_lm.Indexer.write"], ["", "def", "write_sentences", "(", "write_path", ",", "premises", ",", "hypotheses", ",", "append", "=", "False", ")", ":", "\n", "    ", "print", "(", "\"Writing to {}\\n\"", ".", "format", "(", "write_path", ")", ")", "\n", "if", "append", ":", "\n", "        ", "with", "open", "(", "write_path", ",", "\"a\"", ")", "as", "f", ":", "\n", "            ", "for", "p", "in", "premises", ":", "\n", "                ", "f", ".", "write", "(", "p", ")", "\n", "f", ".", "write", "(", "\"\\n\"", ")", "\n", "", "for", "h", "in", "hypotheses", ":", "\n", "                ", "f", ".", "write", "(", "h", ")", "\n", "f", ".", "write", "(", "'\\n'", ")", "\n", "", "", "", "else", ":", "\n", "        ", "with", "open", "(", "write_path", ",", "\"w\"", ")", "as", "f", ":", "\n", "            ", "for", "p", "in", "premises", ":", "\n", "                ", "f", ".", "write", "(", "p", ")", "\n", "f", ".", "write", "(", "\"\\n\"", ")", "\n", "", "for", "h", "in", "hypotheses", ":", "\n", "                ", "f", ".", "write", "(", "h", ")", "\n", "f", ".", "write", "(", "'\\n'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jakezhaojb_ARAE.lang.utils.Dictionary.__init__": [[21, 29], ["None"], "methods", ["None"], ["\n", "", "class", "Dictionary", "(", "object", ")", ":", "\n", "    ", "def", "__init__", "(", "self", ",", "word2idx", "=", "None", ")", ":", "\n", "        ", "if", "word2idx", "is", "None", ":", "\n", "            ", "self", ".", "word2idx", "=", "{", "}", "\n", "self", ".", "idx2word", "=", "{", "}", "\n", "self", ".", "word2idx", "[", "PAD_WORD", "]", "=", "0", "\n", "self", ".", "word2idx", "[", "BOS_WORD", "]", "=", "1", "\n", "self", ".", "word2idx", "[", "EOS_WORD", "]", "=", "2", "\n"]], "home.repos.pwc.inspect_result.jakezhaojb_ARAE.lang.utils.Dictionary.add_word": [[31, 36], ["None"], "methods", ["None"], ["self", ".", "wordcounts", "=", "{", "}", "\n", "", "else", ":", "\n", "            ", "self", ".", "word2idx", "=", "word2idx", "\n", "self", ".", "idx2word", "=", "{", "v", ":", "k", "for", "k", ",", "v", "in", "word2idx", ".", "items", "(", ")", "}", "\n", "\n", "# to track word counts", "\n"]], "home.repos.pwc.inspect_result.jakezhaojb_ARAE.lang.utils.Dictionary.prune_vocab": [[38, 60], ["utils.Dictionary.pruned_vocab.sort", "print", "vocab_list.sort", "min", "utils.Dictionary.wordcounts.items", "len", "len", "len", "len", "utils.Dictionary.word2idx.items"], "methods", ["None"], ["        ", "if", "word", "not", "in", "self", ".", "wordcounts", ":", "\n", "            ", "self", ".", "wordcounts", "[", "word", "]", "=", "1", "\n", "", "else", ":", "\n", "            ", "self", ".", "wordcounts", "[", "word", "]", "+=", "1", "\n", "\n", "# prune vocab based on count k cutoff or most frequently seen k words", "\n", "", "", "def", "prune_vocab", "(", "self", ",", "k", "=", "5", ",", "cnt", "=", "False", ")", ":", "\n", "# get all words and their respective counts", "\n", "        ", "vocab_list", "=", "[", "(", "word", ",", "count", ")", "for", "word", ",", "count", "in", "self", ".", "wordcounts", ".", "items", "(", ")", "]", "\n", "if", "cnt", ":", "\n", "# prune by count", "\n", "            ", "self", ".", "pruned_vocab", "=", "{", "pair", "[", "0", "]", ":", "pair", "[", "1", "]", "for", "pair", "in", "vocab_list", "if", "pair", "[", "1", "]", ">", "k", "}", "\n", "", "else", ":", "\n", "# prune by most frequently seen words", "\n", "            ", "vocab_list", ".", "sort", "(", "key", "=", "lambda", "x", ":", "(", "x", "[", "1", "]", ",", "x", "[", "0", "]", ")", ",", "reverse", "=", "True", ")", "\n", "k", "=", "min", "(", "k", ",", "len", "(", "vocab_list", ")", ")", "\n", "self", ".", "pruned_vocab", "=", "[", "pair", "[", "0", "]", "for", "pair", "in", "vocab_list", "[", ":", "k", "]", "]", "\n", "# sort to make vocabulary determistic", "\n", "", "self", ".", "pruned_vocab", ".", "sort", "(", ")", "\n", "\n", "# add all chosen words to new vocabulary/dict", "\n", "for", "word", "in", "self", ".", "pruned_vocab", ":", "\n"]], "home.repos.pwc.inspect_result.jakezhaojb_ARAE.lang.utils.Dictionary.__len__": [[61, 63], ["len"], "methods", ["None"], ["            ", "if", "word", "not", "in", "self", ".", "word2idx", ":", "\n", "                ", "self", ".", "word2idx", "[", "word", "]", "=", "len", "(", "self", ".", "word2idx", ")", "\n", "", "", "print", "(", "\"Original vocab {}; Pruned to {}\"", ".", "\n"]], "home.repos.pwc.inspect_result.jakezhaojb_ARAE.lang.utils.Corpus.__init__": [[66, 79], ["utils.Dictionary", "os.path.join", "os.path.join", "utils.Corpus.make_vocab", "utils.Corpus.tokenize", "utils.Corpus.tokenize"], "methods", ["home.repos.pwc.inspect_result.jakezhaojb_ARAE.lang.utils.Corpus.make_vocab", "home.repos.pwc.inspect_result.jakezhaojb_ARAE.lang.utils.Corpus.tokenize", "home.repos.pwc.inspect_result.jakezhaojb_ARAE.lang.utils.Corpus.tokenize"], ["\n", "", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "word2idx", ")", "\n", "\n", "\n", "", "", "class", "Corpus", "(", "object", ")", ":", "\n", "    ", "def", "__init__", "(", "self", ",", "datafiles", ",", "maxlen", ",", "vocab_size", "=", "11000", ",", "lowercase", "=", "False", ",", "vocab", "=", "None", ",", "debug", "=", "False", ")", ":", "\n", "        ", "self", ".", "dictionary", "=", "Dictionary", "(", "vocab", ")", "\n", "self", ".", "maxlen", "=", "maxlen", "\n", "self", ".", "lowercase", "=", "lowercase", "\n", "self", ".", "vocab_size", "=", "vocab_size", "\n", "self", ".", "datafiles", "=", "datafiles", "\n", "self", ".", "forvocab", "=", "[", "]", "\n", "self", ".", "data", "=", "{", "}", "\n"]], "home.repos.pwc.inspect_result.jakezhaojb_ARAE.lang.utils.Corpus.make_vocab": [[80, 95], ["os.path.exists", "utils.Corpus.dictionary.prune_vocab", "open", "line[].lower().split", "line[].split", "utils.Corpus.dictionary.add_word", "line[].lower"], "methods", ["home.repos.pwc.inspect_result.jakezhaojb_ARAE.lang.utils.Dictionary.prune_vocab", "home.repos.pwc.inspect_result.jakezhaojb_ARAE.lang.utils.Dictionary.add_word"], ["\n", "if", "vocab", "is", "None", ":", "\n", "            ", "for", "path", ",", "name", ",", "fvocab", "in", "datafiles", ":", "\n", "                ", "if", "fvocab", "or", "debug", ":", "\n", "                    ", "self", ".", "forvocab", ".", "append", "(", "path", ")", "\n", "", "", "self", ".", "make_vocab", "(", ")", "\n", "\n", "", "for", "path", ",", "name", ",", "_", "in", "datafiles", ":", "\n", "            ", "self", ".", "data", "[", "name", "]", "=", "self", ".", "tokenize", "(", "path", ")", "\n", "\n", "\n", "", "", "def", "make_vocab", "(", "self", ")", ":", "\n", "        ", "for", "path", "in", "self", ".", "forvocab", ":", "\n", "            ", "assert", "os", ".", "path", ".", "exists", "(", "path", ")", "\n", "# Add words to the dictionary", "\n", "with", "open", "(", "path", ",", "'r'", ")", "as", "f", ":", "\n"]], "home.repos.pwc.inspect_result.jakezhaojb_ARAE.lang.utils.Corpus.tokenize": [[96, 122], ["print", "open", "lines.append", "line[].lower().strip().split", "line[].strip().split", "len", "line[].lower().strip", "line[].strip", "line[].lower"], "methods", ["None"], ["                ", "for", "line", "in", "f", ":", "\n", "                    ", "L", "=", "line", ".", "lower", "(", ")", "if", "self", ".", "lowercase", "else", "line", "\n", "words", "=", "L", ".", "strip", "(", ")", ".", "split", "(", "\" \"", ")", "\n", "for", "word", "in", "words", ":", "\n", "                        ", "self", ".", "dictionary", ".", "add_word", "(", "word", ")", "\n", "\n", "# prune the vocabulary", "\n", "", "", "", "", "self", ".", "dictionary", ".", "prune_vocab", "(", "k", "=", "self", ".", "vocab_size", ",", "cnt", "=", "False", ")", "\n", "\n", "", "def", "tokenize", "(", "self", ",", "path", ")", ":", "\n", "        ", "\"\"\"Tokenizes a text file.\"\"\"", "\n", "dropped", "=", "0", "\n", "with", "open", "(", "path", ",", "'r'", ")", "as", "f", ":", "\n", "            ", "linecount", "=", "0", "\n", "lines", "=", "[", "]", "\n", "for", "line", "in", "f", ":", "\n", "                ", "linecount", "+=", "1", "\n", "L", "=", "line", ".", "lower", "(", ")", "if", "self", ".", "lowercase", "else", "line", "\n", "words", "=", "L", ".", "strip", "(", ")", ".", "split", "(", "\" \"", ")", "\n", "if", "self", ".", "maxlen", ">", "0", "and", "len", "(", "words", ")", ">", "self", ".", "maxlen", ":", "\n", "                    ", "dropped", "+=", "1", "\n", "continue", "\n", "", "words", "=", "[", "BOS_WORD", "]", "+", "words", "+", "[", "EOS_WORD", "]", "\n", "# vectorize", "\n", "vocab", "=", "self", ".", "dictionary", ".", "word2idx", "\n", "unk_idx", "=", "vocab", "[", "UNK", "]", "\n", "indices", "=", "[", "vocab", "[", "w", "]", "if", "w", "in", "vocab", "else", "unk_idx", "for", "w", "in", "words", "]", "\n"]], "home.repos.pwc.inspect_result.jakezhaojb_ARAE.lang.utils.load_kenlm": [[9, 12], ["None"], "function", ["None"], ["UNK", "=", "\"<unk>\"", "\n", "\n", "def", "load_kenlm", "(", ")", ":", "\n", "    ", "global", "kenlm", "\n"]], "home.repos.pwc.inspect_result.jakezhaojb_ARAE.lang.utils.to_gpu": [[14, 18], ["var.cuda"], "function", ["None"], ["\n", "\n", "", "def", "to_gpu", "(", "gpu", ",", "var", ")", ":", "\n", "    ", "if", "gpu", ":", "\n", "        ", "return", "var", ".", "cuda", "(", ")", "\n"]], "home.repos.pwc.inspect_result.jakezhaojb_ARAE.lang.utils.batchify": [[124, 160], ["range", "random.shuffle", "len", "utils.length_sort", "max", "zip", "torch.LongTensor", "torch.LongTensor().view", "batches.append", "numpy.array", "source.cuda.cuda", "target.cuda.cuda", "len", "torch.LongTensor", "len", "numpy.array"], "function", ["home.repos.pwc.inspect_result.jakezhaojb_ARAE.lang.utils.length_sort"], ["\n", "", "", "print", "(", "\"Number of sentences dropped from {}: {} out of {} total\"", ".", "\n", "format", "(", "path", ",", "dropped", ",", "linecount", ")", ")", "\n", "return", "lines", "\n", "\n", "\n", "", "", "def", "batchify", "(", "data", ",", "bsz", ",", "shuffle", "=", "False", ",", "gpu", "=", "False", ")", ":", "\n", "    ", "if", "shuffle", ":", "\n", "        ", "random", ".", "shuffle", "(", "data", ")", "\n", "\n", "", "nbatch", "=", "len", "(", "data", ")", "//", "bsz", "\n", "batches", "=", "[", "]", "\n", "\n", "for", "i", "in", "range", "(", "nbatch", ")", ":", "\n", "# Pad batches to maximum sequence length in batch", "\n", "        ", "batch", "=", "data", "[", "i", "*", "bsz", ":", "(", "i", "+", "1", ")", "*", "bsz", "]", "\n", "\n", "# subtract 1 from lengths b/c includes BOTH starts & end symbols", "\n", "words", "=", "batch", "\n", "lengths", "=", "[", "len", "(", "x", ")", "-", "1", "for", "x", "in", "words", "]", "\n", "\n", "# sort items by length (decreasing)", "\n", "batch", ",", "lengths", "=", "length_sort", "(", "batch", ",", "lengths", ")", "\n", "words", "=", "batch", "\n", "\n", "# source has no end symbol", "\n", "source", "=", "[", "x", "[", ":", "-", "1", "]", "for", "x", "in", "words", "]", "\n", "# target has no start symbol", "\n", "target", "=", "[", "x", "[", "1", ":", "]", "for", "x", "in", "words", "]", "\n", "\n", "# find length to pad to", "\n", "maxlen", "=", "max", "(", "lengths", ")", "\n", "for", "x", ",", "y", "in", "zip", "(", "source", ",", "target", ")", ":", "\n", "            ", "zeros", "=", "(", "maxlen", "-", "len", "(", "x", ")", ")", "*", "[", "0", "]", "\n", "x", "+=", "zeros", "\n", "y", "+=", "zeros", "\n", "\n"]], "home.repos.pwc.inspect_result.jakezhaojb_ARAE.lang.utils.length_sort": [[162, 168], ["list", "list.sort", "zip", "zip", "list", "list"], "function", ["None"], ["target", "=", "torch", ".", "LongTensor", "(", "np", ".", "array", "(", "target", ")", ")", ".", "view", "(", "-", "1", ")", "\n", "\n", "batches", ".", "append", "(", "(", "source", ",", "target", ",", "lengths", ")", ")", "\n", "", "print", "(", "'{} batches'", ".", "format", "(", "len", "(", "batches", ")", ")", ")", "\n", "return", "batches", "\n", "\n", "\n"]], "home.repos.pwc.inspect_result.jakezhaojb_ARAE.lang.utils.train_ngram_lm": [[170, 188], ["os.path.abspath", "os.system", "utils.load_kenlm", "kenlm.Model", "os.path.join", "os.path.join", "os.path.join", "str"], "function", ["home.repos.pwc.inspect_result.jakezhaojb_ARAE.lang.utils.load_kenlm"], ["    ", "\"\"\"In order to use pytorch variable length sequence package\"\"\"", "\n", "items", "=", "list", "(", "zip", "(", "items", ",", "lengths", ")", ")", "\n", "items", ".", "sort", "(", "key", "=", "lambda", "x", ":", "x", "[", "1", "]", ",", "reverse", "=", "True", ")", "\n", "items", ",", "lengths", "=", "zip", "(", "*", "items", ")", "\n", "return", "list", "(", "items", ")", ",", "list", "(", "lengths", ")", "\n", "\n", "\n", "", "def", "truncate", "(", "words", ")", ":", "\n", "# truncate sentences to first occurrence of <eos>", "\n", "    ", "truncated_sent", "=", "[", "]", "\n", "for", "w", "in", "words", ":", "\n", "        ", "if", "w", "!=", "EOS_WORD", ":", "\n", "            ", "truncated_sent", ".", "append", "(", "w", ")", "\n", "", "else", ":", "\n", "            ", "break", "\n", "", "", "sent", "=", "\" \"", ".", "join", "(", "truncated_sent", ")", "\n", "return", "sent", "\n", "\n", "\n"]], "home.repos.pwc.inspect_result.jakezhaojb_ARAE.lang.utils.get_ppl": [[190, 204], ["numpy.exp", "sent.strip().split", "numpy.sum", "len", "sent.strip", "math.log", "lm.full_scores", "math.pow"], "function", ["None"], ["    ", "\"\"\"\n    Trains a modified Kneser-Ney n-gram KenLM from a text file.\n    Creates a .arpa file to store n-grams.\n    \"\"\"", "\n", "# create .arpa file of n-grams", "\n", "curdir", "=", "os", ".", "path", ".", "abspath", "(", "os", ".", "path", ".", "curdir", ")", "\n", "\n", "command", "=", "\"bin/lmplz -o \"", "+", "str", "(", "N", ")", "+", "\" <\"", "+", "os", ".", "path", ".", "join", "(", "curdir", ",", "data_path", ")", "+", "\" >\"", "+", "os", ".", "path", ".", "join", "(", "curdir", ",", "output_path", ")", "\n", "os", ".", "system", "(", "\"cd \"", "+", "os", ".", "path", ".", "join", "(", "kenlm_path", ",", "'build'", ")", "+", "\" && \"", "+", "command", ")", "\n", "\n", "load_kenlm", "(", ")", "\n", "# create language model", "\n", "model", "=", "kenlm", ".", "Model", "(", "output_path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jakezhaojb_ARAE.lang.utils.create_exp_dir": [[206, 230], ["print", "os.path.exists", "os.mkdir", "shutil.rmtree", "os.mkdir", "os.path.exists", "os.mkdir", "os.path.join", "shutil.copyfile", "open", "json.dump", "open", "json.dump", "os.path.join", "os.path.join", "os.path.basename", "os.path.join", "os.path.join", "vars"], "function", ["None"], ["\n", "\n", "", "def", "get_ppl", "(", "lm", ",", "sentences", ")", ":", "\n", "    ", "\"\"\"\n    Assume sentences is a list of strings (space delimited sentences)\n    \"\"\"", "\n", "total_nll", "=", "0", "\n", "total_wc", "=", "0", "\n", "for", "sent", "in", "sentences", ":", "\n", "        ", "words", "=", "sent", ".", "strip", "(", ")", ".", "split", "(", ")", "\n", "score", "=", "lm", ".", "score", "(", "sent", ",", "bos", "=", "True", ",", "eos", "=", "False", ")", "\n", "word_count", "=", "len", "(", "words", ")", "\n", "total_wc", "+=", "word_count", "\n", "total_nll", "+=", "score", "\n", "", "ppl", "=", "10", "**", "-", "(", "total_nll", "/", "total_wc", ")", "\n", "return", "ppl", "\n", "", ""]], "home.repos.pwc.inspect_result.jakezhaojb_ARAE.experiments.noise.main": [[11, 39], ["torch.ones", "range", "noise[].normal_", "range", "noise.gen", "print", "set", "set.add", "range", "print", "noise[].normal_", "set.add", "sents[].split", "sents[].split", "difflib.SequenceMatcher", "difflib.SequenceMatcher.get_opcodes", "print", "numpy.linalg.norm", "print", "print"], "function", ["home.repos.pwc.inspect_result.jakezhaojb_ARAE.experiments.vector.gen"], ["def", "main", "(", "args", ")", ":", "\n", "    ", "noise", "=", "torch", ".", "ones", "(", "100", ",", "model_args", "[", "'z_size'", "]", ")", "\n", "\n", "for", "k", "in", "range", "(", "10", ")", ":", "\n", "        ", "noise", "[", "0", "]", ".", "normal_", "(", ")", "\n", "for", "i", "in", "range", "(", "1", ",", "100", ")", ":", "\n", "            ", "noise", "[", "i", "]", ".", "normal_", "(", ")", "\n", "noise", "[", "i", "]", "=", "noise", "[", "i", "]", "/", "(", "10", "*", "numpy", ".", "linalg", ".", "norm", "(", "noise", "[", "i", "]", ")", ")", "\n", "noise", "[", "i", "]", "+=", "noise", "[", "0", "]", "\n", "", "sents", "=", "gen", "(", "noise", ")", "\n", "print", "(", "sents", "[", "0", "]", ")", "\n", "seen", "=", "set", "(", ")", "\n", "seen", ".", "add", "(", "sents", "[", "0", "]", ")", "\n", "for", "i", "in", "range", "(", "40", ")", ":", "\n", "            ", "if", "sents", "[", "i", "]", "not", "in", "seen", ":", "\n", "                ", "seen", ".", "add", "(", "sents", "[", "i", "]", ")", "\n", "a", "=", "sents", "[", "0", "]", ".", "split", "(", ")", "\n", "b", "=", "sents", "[", "i", "]", ".", "split", "(", ")", "\n", "sm", "=", "difflib", ".", "SequenceMatcher", "(", "a", "=", "a", ",", "b", "=", "b", ")", "\n", "\n", "for", "tag", ",", "i1", ",", "i2", ",", "j1", ",", "j2", "in", "sm", ".", "get_opcodes", "(", ")", ":", "\n", "                    ", "if", "tag", "==", "\"equal\"", ":", "\n", "                        ", "print", "(", "\" \"", ".", "join", "(", "b", "[", "j1", ":", "j2", "]", ")", ",", "end", "=", "\" \"", ")", "\n", "", "if", "tag", "==", "\"replace\"", ":", "\n", "                        ", "print", "(", "BOLD", "+", "\" \"", ".", "join", "(", "b", "[", "j1", ":", "j2", "]", ")", "+", "ENDC", ",", "end", "=", "\" \"", ")", "\n", "# print(\"*\" + \" \".join(b[j1:j2]) + \"*\", end=\" \")", "\n", "", "", "print", "(", ")", "\n", "", "", "print", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jakezhaojb_ARAE.experiments.noise.gen": [[40, 45], ["models.generate"], "function", ["home.repos.pwc.inspect_result.jakezhaojb_ARAE.lang.models.generate"], ["", "", "def", "gen", "(", "vec", ")", ":", "\n", "    ", "\"Generate argmax sentence from vector.\"", "\n", "return", "generate", "(", "autoencoder", ",", "gan_gen", ",", "z", "=", "vec", ",", "\n", "vocab", "=", "idx2word", ",", "sample", "=", "False", ",", "\n", "maxlen", "=", "model_args", "[", "'maxlen'", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jakezhaojb_ARAE.experiments.vector.get_subj_verb": [[13, 31], ["set", "set", "set", "enumerate", "set.add", "list", "set.add", "set.add", "str", "set.add", "set.add", "str", "str", "str", "str"], "function", ["None"], ["def", "get_subj_verb", "(", "sent", ")", ":", "\n", "    ", "\"Given a parsed sentence, find subject, verb, and subject modifiers.\"", "\n", "sub", "=", "set", "(", ")", "\n", "verbs", "=", "set", "(", ")", "\n", "mod", "=", "set", "(", ")", "\n", "for", "i", ",", "possible_subject", "in", "enumerate", "(", "sent", ")", ":", "\n", "        ", "if", "possible_subject", ".", "dep", "==", "nsubj", "and", "possible_subject", ".", "head", ".", "pos", "==", "VERB", ":", "\n", "            ", "if", "possible_subject", ".", "head", ".", "head", ".", "pos", "==", "VERB", ":", "\n", "                ", "verbs", ".", "add", "(", "str", "(", "possible_subject", ".", "head", ".", "head", ")", ")", "\n", "", "else", ":", "\n", "                ", "verbs", ".", "add", "(", "str", "(", "possible_subject", ".", "head", ")", ")", "\n", "", "sub", ".", "add", "(", "str", "(", "possible_subject", ")", ")", "\n", "c", "=", "list", "(", "possible_subject", ".", "children", ")", "\n", "for", "w", "in", "c", ":", "\n", "                ", "mod", ".", "add", "(", "str", "(", "w", ")", ")", "\n", "", "if", "not", "c", ":", "\n", "                ", "mod", ".", "add", "(", "str", "(", "sent", "[", "i", "-", "1", "]", ")", "if", "i", "!=", "0", "else", "\"NONE\"", ")", "\n", "", "", "", "return", "verbs", ",", "sub", ",", "mod", "\n", "\n"]], "home.repos.pwc.inspect_result.jakezhaojb_ARAE.experiments.vector.featurize": [[33, 45], ["vector.get_subj_verb", "vector.featurize.add"], "function", ["home.repos.pwc.inspect_result.jakezhaojb_ARAE.experiments.vector.get_subj_verb"], ["", "def", "featurize", "(", "sent", ")", ":", "\n", "    ", "\"Given a sentence construct a feature rep\"", "\n", "verb", ",", "sub", ",", "mod", "=", "get_subj_verb", "(", "sent", ")", "\n", "d", "=", "{", "}", "\n", "\n", "def", "add", "(", "d", ",", "pre", ",", "ls", ")", ":", "\n", "        ", "for", "l", "in", "ls", ":", "\n", "            ", "d", "[", "pre", "+", "\"_\"", "+", "l", "]", "=", "1", "\n", "", "", "add", "(", "d", ",", "\"VERB\"", ",", "list", "(", "verb", ")", "[", ":", "1", "]", ")", "\n", "add", "(", "d", ",", "\"MOD\"", ",", "list", "(", "mod", ")", ")", "\n", "add", "(", "d", ",", "\"NOUN\"", ",", "list", "(", "sub", ")", "[", ":", "1", "]", ")", "\n", "return", "d", "\n", "\n"]], "home.repos.pwc.inspect_result.jakezhaojb_ARAE.experiments.vector.gen": [[47, 52], ["models.generate", "torch.FloatTensor().view", "torch.FloatTensor"], "function", ["home.repos.pwc.inspect_result.jakezhaojb_ARAE.lang.models.generate"], ["", "def", "gen", "(", "vec", ")", ":", "\n", "    ", "\"Generate argmax sentence from vector.\"", "\n", "return", "generate", "(", "autoencoder", ",", "gan_gen", ",", "z", "=", "torch", ".", "FloatTensor", "(", "vec", ")", ".", "view", "(", "1", ",", "-", "1", ")", ",", "\n", "vocab", "=", "idx2word", ",", "sample", "=", "False", ",", "\n", "maxlen", "=", "model_args", "[", "'maxlen'", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jakezhaojb_ARAE.experiments.vector.gen_samples": [[54, 62], ["models.generate", "torch.FloatTensor().view().expand", "torch.FloatTensor().view", "torch.FloatTensor"], "function", ["home.repos.pwc.inspect_result.jakezhaojb_ARAE.lang.models.generate"], ["", "def", "gen_samples", "(", "vec", ")", ":", "\n", "    ", "\"Generate sample sentences from vector.\"", "\n", "sentences", "=", "[", "]", "\n", "sentences", "=", "generate", "(", "autoencoder", ",", "gan_gen", ",", "z", "=", "torch", ".", "FloatTensor", "(", "vec", ")", "\n", ".", "view", "(", "1", ",", "-", "1", ")", ".", "expand", "(", "20", ",", "vec", ".", "shape", "[", "0", "]", ")", ",", "\n", "vocab", "=", "idx2word", ",", "sample", "=", "True", ",", "\n", "maxlen", "=", "model_args", "[", "'maxlen'", "]", ")", "[", "0", "]", "\n", "return", "sentences", "\n", "\n"]], "home.repos.pwc.inspect_result.jakezhaojb_ARAE.experiments.vector.switch": [[64, 75], ["numpy.mean", "list", "numpy.mean", "numpy.zeros", "means.append", "list", "numpy.mean", "list"], "function", ["None"], ["", "def", "switch", "(", "vec", ",", "mat", ",", "rev", ",", "f1", ",", "f2", ")", ":", "\n", "    ", "\"Update vec away from feature1 and towards feature2.\"", "\n", "means", "=", "[", "]", "\n", "m2", "=", "np", ".", "mean", "(", "mat", "[", "list", "(", "rev", "[", "f2", "]", ")", "]", ",", "axis", "=", "0", ")", "\n", "for", "f", "in", "f1", ":", "\n", "        ", "if", "list", "(", "rev", "[", "f", "]", ")", ":", "\n", "            ", "means", ".", "append", "(", "np", ".", "mean", "(", "mat", "[", "list", "(", "rev", "[", "f", "]", ")", "]", ",", "axis", "=", "0", ")", ")", "\n", "", "", "m1", "=", "np", ".", "mean", "(", "means", ")", "if", "f1", "else", "np", ".", "zeros", "(", "m2", ".", "shape", ")", "\n", "\n", "val", "=", "vec", "+", "(", "m2", "-", "m1", ")", "\n", "return", "val", ",", "vec", "-", "m1", "\n", "\n"]], "home.repos.pwc.inspect_result.jakezhaojb_ARAE.experiments.vector.alter": [[77, 118], ["pickle.load", "mat.numpy.numpy", "range", "open", "new_feat.split", "new_feat.split", "range", "print", "print", "vector.featurize", "print", "vector.gen_samples", "vector.switch", "vector.gen", "nlp", "feats.append", "vector.featurize", "feature.startswith", "nlp", "mod.append"], "function", ["home.repos.pwc.inspect_result.jakezhaojb_ARAE.experiments.vector.featurize", "home.repos.pwc.inspect_result.jakezhaojb_ARAE.experiments.vector.gen_samples", "home.repos.pwc.inspect_result.jakezhaojb_ARAE.experiments.vector.switch", "home.repos.pwc.inspect_result.jakezhaojb_ARAE.experiments.vector.gen", "home.repos.pwc.inspect_result.jakezhaojb_ARAE.experiments.vector.featurize"], ["", "def", "alter", "(", "args", ")", ":", "\n", "    ", "sents", ",", "features", ",", "rev", ",", "mat", "=", "pickle", ".", "load", "(", "open", "(", "args", ".", "dump", ",", "\"br\"", ")", ")", "\n", "mat", "=", "mat", ".", "numpy", "(", ")", "\n", "\n", "# Find examples to alter toward new feat.", "\n", "new_feat", "=", "args", ".", "alter", "\n", "\n", "pre", "=", "new_feat", ".", "split", "(", "\"_\"", ")", "[", "0", "]", "\n", "word", "=", "new_feat", ".", "split", "(", "\"_\"", ")", "[", "1", "]", "\n", "for", "i", "in", "range", "(", "args", ".", "nsent", ")", ":", "\n", "        ", "vec", "=", "mat", "[", "i", "]", "\n", "\n", "for", "j", "in", "range", "(", "10", ")", ":", "\n", "            ", "sent", "=", "gen", "(", "vec", ")", "[", "0", "]", "\n", "f", "=", "featurize", "(", "nlp", "(", "sent", ")", ")", "\n", "print", "(", "\"Sent \"", ",", "j", ",", "\": \\t \"", ",", "sent", ",", "\"\\t\"", ")", "\n", "if", "word", "in", "sent", ":", "\n", "                ", "break", "\n", "\n", "# Compute the feature distribution associated with this point.", "\n", "", "samples", "=", "gen_samples", "(", "vec", ")", "\n", "feats", "=", "[", "f", "]", "*", "50", "\n", "for", "s", "in", "samples", ":", "\n", "                ", "feats", ".", "append", "(", "featurize", "(", "nlp", "(", "s", ")", ")", ")", "\n", "\n", "", "mod", "=", "[", "]", "\n", "for", "feat", "in", "feats", ":", "\n", "                ", "for", "feature", "in", "feat", ":", "\n", "                    ", "if", "feature", ".", "startswith", "(", "pre", ")", ":", "\n", "                        ", "mod", ".", "append", "(", "feature", ")", "\n", "\n", "# Try to updated the vector towards new_feat", "\n", "", "", "", "update", ",", "temp", "=", "switch", "(", "vec", ",", "mat", ",", "rev", ",", "mod", ",", "new_feat", ")", "\n", "if", "j", "==", "0", ":", "\n", "                ", "orig", "=", "temp", "\n", "\n", "# Interpolate with original.", "\n", "", "vec", "=", "0.2", "*", "orig", "+", "0.8", "*", "update", "\n", "\n", "", "print", "(", ")", "\n", "print", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jakezhaojb_ARAE.experiments.vector.dump_samples": [[120, 155], ["torch.FloatTensor", "collections.defaultdict", "range", "pickle.dump", "print", "torch.ones", "noise.view().expand().contiguous().view.normal_", "noise.view().expand().contiguous().view.view().expand().contiguous().view", "models.generate", "range", "open", "len", "nlp", "vector.featurize", "all_sents.append", "all_features.append", "noise.view().expand().contiguous().view.view().expand().contiguous", "rev[].add", "noise.view().expand().contiguous().view.view().expand", "noise.view().expand().contiguous().view.view"], "function", ["home.repos.pwc.inspect_result.jakezhaojb_ARAE.lang.models.generate", "home.repos.pwc.inspect_result.jakezhaojb_ARAE.experiments.vector.featurize"], ["", "", "def", "dump_samples", "(", "args", ")", ":", "\n", "    ", "\"Construct a large number of samples with features and dump to file.\"", "\n", "all_features", "=", "[", "]", "\n", "all_sents", "=", "[", "]", "\n", "\n", "batches", "=", "args", ".", "nbatches", "\n", "batch", "=", "args", ".", "batch_size", "\n", "samples", "=", "1", "\n", "total", "=", "batches", "*", "batch", "*", "samples", "\n", "all_zs", "=", "torch", ".", "FloatTensor", "(", "total", ",", "model_args", "[", "'z_size'", "]", ")", "\n", "rev", "=", "defaultdict", "(", "set", ")", "\n", "\n", "for", "j", "in", "range", "(", "batches", ")", ":", "\n", "        ", "print", "(", "\"%d / %d batches \"", "%", "(", "j", ",", "batches", ")", ")", "\n", "noise", "=", "torch", ".", "ones", "(", "batch", ",", "model_args", "[", "'z_size'", "]", ")", "\n", "noise", ".", "normal_", "(", ")", "\n", "noise", "=", "noise", ".", "view", "(", "batch", ",", "1", ",", "model_args", "[", "'z_size'", "]", ")", ".", "expand", "(", "batch", ",", "samples", ",", "\n", "model_args", "[", "'z_size'", "]", ")", ".", "contiguous", "(", ")", ".", "view", "(", "batch", "*", "samples", ",", "\n", "model_args", "[", "'z_size'", "]", ")", "\n", "sentences", "=", "generate", "(", "autoencoder", ",", "gan_gen", ",", "z", "=", "noise", ",", "\n", "vocab", "=", "idx2word", ",", "sample", "=", "True", ",", "\n", "maxlen", "=", "model_args", "[", "'maxlen'", "]", ")", "\n", "\n", "for", "i", "in", "range", "(", "batch", "*", "samples", ")", ":", "\n", "            ", "k", "=", "len", "(", "all_features", ")", "\n", "nlp_sent", "=", "nlp", "(", "sentences", "[", "i", "]", ")", "\n", "feats", "=", "featurize", "(", "nlp_sent", ")", "\n", "all_sents", ".", "append", "(", "sentences", "[", "i", "]", ")", "\n", "all_features", ".", "append", "(", "feats", ")", "\n", "for", "f", "in", "feats", ":", "\n", "                ", "rev", "[", "f", "]", ".", "add", "(", "k", ")", "\n", "", "all_zs", "[", "k", "]", "=", "noise", "[", "i", "]", "\n", "", "", "pickle", ".", "dump", "(", "(", "all_sents", ",", "all_features", ",", "rev", ",", "all_zs", ")", ",", "open", "(", "args", ".", "dump", ",", "\"bw\"", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jakezhaojb_ARAE.experiments.vector.main": [[157, 162], ["vector.dump_samples", "vector.alter"], "function", ["home.repos.pwc.inspect_result.jakezhaojb_ARAE.experiments.vector.dump_samples", "home.repos.pwc.inspect_result.jakezhaojb_ARAE.experiments.vector.alter"], ["", "def", "main", "(", "args", ")", ":", "\n", "    ", "if", "args", ".", "mode", "==", "'gen'", ":", "\n", "        ", "dump_samples", "(", "args", ")", "\n", "", "elif", "args", ".", "mode", "==", "'alter'", ":", "\n", "        ", "alter", "(", "args", ")", "\n", "\n"]]}