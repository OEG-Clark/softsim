{"home.repos.pwc.inspect_result.tomjur_ModelBasedDDPG.None.pre_trained_reward.PreTrainedReward.__init__": [[15, 41], ["tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder_with_default", "tensorflow.placeholder_with_default", "len", "pre_trained_reward.PreTrainedReward.create_reward_network", "os.path.join", "os.path.exists", "tensorflow.train.Saver", "tensorflow.train.Saver", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.expand_dims", "tensorflow.expand_dims", "tensorflow.trainable_variables", "tensorflow.trainable_variables", "tensorflow.trainable_variables", "tensorflow.trainable_variables", "os.getcwd"], "methods", ["home.repos.pwc.inspect_result.tomjur_ModelBasedDDPG.None.pre_trained_reward.PreTrainedReward.create_reward_network"], ["    ", "def", "__init__", "(", "self", ",", "model_name", ",", "config", ")", ":", "\n", "        ", "self", ".", "_reuse_flag", "=", "False", "\n", "\n", "self", ".", "config", "=", "config", "\n", "self", ".", "is_vision_enabled", "=", "'vision'", "in", "config", "[", "'general'", "]", "[", "'scenario'", "]", "\n", "\n", "self", ".", "joints_inputs", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "(", "None", ",", "4", ")", ",", "name", "=", "'joints_inputs'", ")", "\n", "self", ".", "goal_joints_inputs", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "(", "None", ",", "4", ")", ",", "name", "=", "'goal_joints_inputs'", ")", "\n", "self", ".", "workspace_image_inputs", ",", "self", ".", "images_3d", "=", "None", ",", "None", "\n", "if", "self", ".", "is_vision_enabled", ":", "\n", "            ", "self", ".", "workspace_image_inputs", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "(", "None", ",", "55", ",", "111", ")", ",", "name", "=", "'workspace_image_inputs'", ")", "\n", "self", ".", "images_3d", "=", "tf", ".", "expand_dims", "(", "self", ".", "workspace_image_inputs", ",", "axis", "=", "-", "1", ")", "\n", "", "self", ".", "goal_pose_inputs", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "(", "None", ",", "2", ")", ",", "name", "=", "'goal_pose_inputs'", ")", "\n", "self", ".", "action_inputs", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "(", "None", ",", "4", ")", ",", "name", "=", "'action_inputs'", ")", "\n", "self", ".", "transition_label", "=", "tf", ".", "placeholder_with_default", "(", "[", "[", "0.0", "]", "*", "3", "]", ",", "(", "None", ",", "3", ")", ",", "name", "=", "'labeled_transition'", ")", "\n", "current_variables_count", "=", "len", "(", "tf", ".", "trainable_variables", "(", ")", ")", "\n", "self", ".", "reward_prediction", ",", "self", ".", "status_softmax_logits", "=", "self", ".", "create_reward_network", "(", "\n", "self", ".", "joints_inputs", ",", "self", ".", "action_inputs", ",", "self", ".", "goal_joints_inputs", ",", "self", ".", "goal_pose_inputs", ",", "self", ".", "images_3d", "\n", ")", "\n", "reward_variables", "=", "tf", ".", "trainable_variables", "(", ")", "[", "current_variables_count", ":", "]", "\n", "\n", "# model path to load", "\n", "self", ".", "model_name", "=", "model_name", "\n", "self", ".", "saver_dir", "=", "os", ".", "path", ".", "join", "(", "os", ".", "getcwd", "(", ")", ",", "'data'", ",", "'reward'", ",", "'model'", ",", "model_name", ")", "\n", "assert", "os", ".", "path", ".", "exists", "(", "self", ".", "saver_dir", ")", "\n", "self", ".", "saver", "=", "tf", ".", "train", ".", "Saver", "(", "reward_variables", ",", "max_to_keep", "=", "4", ",", "save_relative_paths", "=", "self", ".", "saver_dir", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tomjur_ModelBasedDDPG.None.pre_trained_reward.PreTrainedReward._generate_goal_features": [[42, 48], ["tensorflow.concat", "tensorflow.concat", "features.append"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_generate_goal_features", "(", "goal_joints_inputs", ",", "goal_pose_inputs", ")", ":", "\n", "        ", "features", "=", "[", "goal_joints_inputs", "]", "\n", "if", "goal_pose_inputs", "is", "not", "None", ":", "\n", "            ", "features", ".", "append", "(", "goal_pose_inputs", ")", "\n", "", "return", "tf", ".", "concat", "(", "features", ",", "axis", "=", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tomjur_ModelBasedDDPG.None.pre_trained_reward.PreTrainedReward._next_state_model": [[49, 64], ["tensorflow.maximum", "tensorflow.maximum", "tensorflow.minimum", "tensorflow.minimum"], "methods", ["None"], ["", "def", "_next_state_model", "(", "self", ",", "joints_inputs", ",", "action_inputs", ")", ":", "\n", "# next step is a deterministic computation", "\n", "        ", "action_step_size", "=", "self", ".", "config", "[", "'openrave_rl'", "]", "[", "'action_step_size'", "]", "\n", "step", "=", "action_inputs", "*", "action_step_size", "\n", "unclipped_result", "=", "joints_inputs", "+", "step", "\n", "# we initiate an openrave manager to get the robot, to get the joint bounds and the safety", "\n", "joint_safety", "=", "0.0001", "\n", "lower_bounds", "=", "[", "-", "2.617", ",", "-", "1.571", ",", "-", "1.571", ",", "-", "1.745", ",", "-", "2.617", "]", "\n", "lower_bounds", "=", "[", "b", "+", "joint_safety", "for", "b", "in", "lower_bounds", "[", "1", ":", "]", "]", "\n", "upper_bounds", "=", "[", "-", "b", "for", "b", "in", "lower_bounds", "]", "\n", "\n", "# clip the result", "\n", "clipped_result", "=", "tf", ".", "maximum", "(", "unclipped_result", ",", "lower_bounds", ")", "\n", "clipped_result", "=", "tf", ".", "minimum", "(", "clipped_result", ",", "upper_bounds", ")", "\n", "return", "clipped_result", ",", "unclipped_result", "\n", "\n"]], "home.repos.pwc.inspect_result.tomjur_ModelBasedDDPG.None.pre_trained_reward.PreTrainedReward.create_reward_network": [[65, 114], ["pre_trained_reward.PreTrainedReward._next_state_model", "tensorflow.concat", "tensorflow.concat", "enumerate", "tensorflow.nn.softmax", "tensorflow.nn.softmax", "tensorflow.expand_dims", "tensorflow.expand_dims", "tensorflow.layers.dense", "tensorflow.layers.dense", "tensorflow.expand_dims", "tensorflow.expand_dims", "tensorflow.layers.dense", "tensorflow.layers.dense", "dqn_model.DqnModel().predict", "tensorflow.concat", "tensorflow.concat", "tensorflow.layers.dense", "tensorflow.layers.dense", "tensorflow.reduce_max", "tensorflow.reduce_max", "tensorflow.multiply", "tensorflow.multiply", "tensorflow.reduce_sum", "tensorflow.reduce_sum", "pre_trained_reward.PreTrainedReward._generate_goal_features", "modeling_utils.get_activation", "tensorflow.abs", "tensorflow.abs", "dqn_model.DqnModel", "tensorflow.l2_regularizer", "tensorflow.l2_regularizer", "len"], "methods", ["home.repos.pwc.inspect_result.tomjur_ModelBasedDDPG.None.pre_trained_reward.PreTrainedReward._next_state_model", "home.repos.pwc.inspect_result.tomjur_ModelBasedDDPG.None.dqn_model.DqnModel.predict", "home.repos.pwc.inspect_result.tomjur_ModelBasedDDPG.None.pre_trained_reward.PreTrainedReward._generate_goal_features", "home.repos.pwc.inspect_result.tomjur_ModelBasedDDPG.None.modeling_utils.get_activation"], ["", "def", "create_reward_network", "(", "\n", "self", ",", "joints_inputs", ",", "action_inputs", ",", "goal_joints_inputs", ",", "goal_pose_inputs", ",", "images_3d", ")", ":", "\n", "        ", "name_prefix", "=", "'reward'", "\n", "# get the next joints", "\n", "clipped_next_joints", ",", "unclipped_next_joints", "=", "self", ".", "_next_state_model", "(", "joints_inputs", ",", "action_inputs", ")", "\n", "\n", "# predict the transition classification", "\n", "layers", "=", "self", ".", "config", "[", "'reward'", "]", "[", "'layers'", "]", "+", "[", "3", "]", "\n", "scale", "=", "0.0", "\n", "if", "'l2_regularization_coefficient'", "in", "self", ".", "config", "[", "'reward'", "]", ":", "\n", "            ", "scale", "=", "self", ".", "config", "[", "'reward'", "]", "[", "'l2_regularization_coefficient'", "]", "\n", "", "current", "=", "tf", ".", "concat", "(", "\n", "(", "clipped_next_joints", ",", "self", ".", "_generate_goal_features", "(", "goal_joints_inputs", ",", "goal_pose_inputs", ")", ")", ",", "axis", "=", "1", ")", "\n", "# add vision if needed", "\n", "if", "self", ".", "is_vision_enabled", ":", "\n", "            ", "visual_inputs", "=", "DqnModel", "(", "name_prefix", ")", ".", "predict", "(", "images_3d", ",", "self", ".", "_reuse_flag", ")", "\n", "current", "=", "tf", ".", "concat", "(", "(", "current", ",", "visual_inputs", ")", ",", "axis", "=", "1", ")", "\n", "", "for", "i", ",", "layer_size", "in", "enumerate", "(", "layers", ")", ":", "\n", "            ", "_activation", "=", "None", "if", "i", "==", "len", "(", "layers", ")", "-", "1", "else", "get_activation", "(", "self", ".", "config", "[", "'reward'", "]", "[", "'activation'", "]", ")", "\n", "current", "=", "tf", ".", "layers", ".", "dense", "(", "\n", "current", ",", "layer_size", ",", "activation", "=", "_activation", ",", "name", "=", "'{}_layers_{}'", ".", "format", "(", "name_prefix", ",", "i", ")", ",", "\n", "kernel_regularizer", "=", "tf_layers", ".", "l2_regularizer", "(", "scale", ")", ",", "reuse", "=", "self", ".", "_reuse_flag", "\n", ")", "\n", "", "softmax_logits", "=", "current", "\n", "softmax_res", "=", "tf", ".", "nn", ".", "softmax", "(", "softmax_logits", ")", "\n", "\n", "# if the one-hot input is fed, is labeled will be 1.0 otherwise it will be zero", "\n", "is_labeled", "=", "tf", ".", "expand_dims", "(", "tf", ".", "reduce_max", "(", "self", ".", "transition_label", ",", "axis", "=", "1", ")", ",", "axis", "=", "1", ")", "\n", "reward_calculation_input", "=", "self", ".", "transition_label", "+", "tf", ".", "multiply", "(", "1.0", "-", "is_labeled", ",", "softmax_res", ")", "\n", "\n", "# get the classification reward", "\n", "classification_reward", "=", "tf", ".", "layers", ".", "dense", "(", "\n", "reward_calculation_input", ",", "1", ",", "activation", "=", "None", ",", "use_bias", "=", "False", ",", "\n", "name", "=", "'{}_classification_reward'", ".", "format", "(", "name_prefix", ")", ",", "reuse", "=", "self", ".", "_reuse_flag", "\n", ")", "\n", "\n", "# get the clipping-related reward", "\n", "# clipped_difference = tf.expand_dims(tf.norm(unclipped_next_joints - clipped_next_joints, axis=1), axis=1)  # this is the original", "\n", "# clipped_difference = tf.expand_dims(tf.reduce_sum(tf.zeros_like(clipped_next_joints), axis=1), axis=1)  # this will have no gradient backlash", "\n", "clipped_difference", "=", "tf", ".", "expand_dims", "(", "tf", ".", "reduce_sum", "(", "tf", ".", "abs", "(", "unclipped_next_joints", "-", "clipped_next_joints", ")", ",", "axis", "=", "1", ")", ",", "axis", "=", "1", ")", "\n", "\n", "clipping_reward", "=", "tf", ".", "layers", ".", "dense", "(", "\n", "clipped_difference", ",", "1", ",", "activation", "=", "None", ",", "use_bias", "=", "False", ",", "name", "=", "'{}_clipping_weight'", ".", "format", "(", "name_prefix", ")", ",", "\n", "reuse", "=", "self", ".", "_reuse_flag", "\n", ")", "\n", "\n", "total_reward", "=", "classification_reward", "+", "clipping_reward", "\n", "self", ".", "_reuse_flag", "=", "True", "\n", "return", "total_reward", ",", "softmax_logits", "\n", "\n"]], "home.repos.pwc.inspect_result.tomjur_ModelBasedDDPG.None.pre_trained_reward.PreTrainedReward.load_weights": [[115, 117], ["pre_trained_reward.PreTrainedReward.saver.restore", "tensorflow.train.latest_checkpoint", "tensorflow.train.latest_checkpoint"], "methods", ["None"], ["", "def", "load_weights", "(", "self", ",", "sess", ")", ":", "\n", "        ", "self", ".", "saver", ".", "restore", "(", "sess", ",", "tf", ".", "train", ".", "latest_checkpoint", "(", "self", ".", "saver_dir", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tomjur_ModelBasedDDPG.None.pre_trained_reward.PreTrainedReward.make_prediction": [[118, 123], ["pre_trained_reward.PreTrainedReward.make_feed", "sess.run"], "methods", ["home.repos.pwc.inspect_result.tomjur_ModelBasedDDPG.None.pre_trained_reward.PreTrainedReward.make_feed", "home.repos.pwc.inspect_result.tomjur_ModelBasedDDPG.None.data_collector.CollectorProcess.run"], ["", "def", "make_prediction", "(", "self", ",", "sess", ",", "all_start_joints", ",", "all_goal_joints", ",", "all_actions", ",", "all_goal_poses", ",", "\n", "all_transition_labels", "=", "None", ",", "images", "=", "None", ")", ":", "\n", "        ", "feed", "=", "self", ".", "make_feed", "(", "all_start_joints", ",", "all_goal_joints", ",", "all_actions", ",", "all_goal_poses", ",", "images", "=", "images", ",", "\n", "all_transition_labels", "=", "all_transition_labels", ")", "\n", "return", "sess", ".", "run", "(", "[", "self", ".", "reward_prediction", ",", "self", ".", "status_softmax_logits", "]", ",", "feed", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tomjur_ModelBasedDDPG.None.pre_trained_reward.PreTrainedReward.make_feed": [[124, 140], ["None"], "methods", ["None"], ["", "def", "make_feed", "(", "self", ",", "all_start_joints", ",", "all_goal_joints", ",", "all_actions", ",", "all_goal_poses", ",", "images", "=", "None", ",", "\n", "all_transition_labels", "=", "None", ")", ":", "\n", "        ", "feed", "=", "{", "\n", "self", ".", "joints_inputs", ":", "all_start_joints", ",", "\n", "self", ".", "goal_joints_inputs", ":", "all_goal_joints", ",", "\n", "self", ".", "action_inputs", ":", "all_actions", ",", "\n", "}", "\n", "if", "self", ".", "goal_pose_inputs", "is", "not", "None", ":", "\n", "            ", "feed", "[", "self", ".", "goal_pose_inputs", "]", "=", "all_goal_poses", "\n", "", "if", "self", ".", "is_vision_enabled", ":", "\n", "            ", "assert", "images", "is", "not", "None", "\n", "assert", "images", "[", "0", "]", "is", "not", "None", "\n", "feed", "[", "self", ".", "workspace_image_inputs", "]", "=", "images", "\n", "", "if", "all_transition_labels", "is", "not", "None", ":", "\n", "            ", "feed", "[", "self", ".", "transition_label", "]", "=", "all_transition_labels", "\n", "", "return", "feed", "\n", "\n"]], "home.repos.pwc.inspect_result.tomjur_ModelBasedDDPG.None.pre_trained_reward.oversample_batch": [[142, 167], ["len", "int", "list", "batch_indices.extend", "int", "list", "batch_indices.extend", "len", "len", "len", "numpy.random.choice", "numpy.random.choice", "enumerate", "enumerate", "enumerate", "len", "len", "len"], "function", ["None"], ["", "", "def", "oversample_batch", "(", "current_batch", ",", "oversample_large_magnitude", "=", "None", ")", ":", "\n", "    ", "if", "oversample_large_magnitude", "is", "None", ":", "\n", "        ", "return", "current_batch", "\n", "", "oversample_success", "=", "oversample_large_magnitude", "[", "0", "]", "\n", "oversample_collision", "=", "oversample_large_magnitude", "[", "1", "]", "\n", "status", "=", "[", "b", "[", "-", "1", "]", "for", "b", "in", "current_batch", "]", "\n", "success_reward_indices", "=", "[", "i", "for", "i", ",", "s", "in", "enumerate", "(", "status", ")", "if", "s", "==", "3", "]", "\n", "if", "len", "(", "success_reward_indices", ")", "<", "3", ":", "\n", "        ", "return", "None", "\n", "", "collision_reward_indices", "=", "[", "i", "for", "i", ",", "s", "in", "enumerate", "(", "status", ")", "if", "s", "==", "2", "]", "\n", "if", "len", "(", "collision_reward_indices", ")", "<", "3", ":", "\n", "        ", "return", "None", "\n", "", "other_reward_indices", "=", "[", "i", "for", "i", ",", "s", "in", "enumerate", "(", "status", ")", "if", "s", "==", "1", "]", "\n", "assert", "len", "(", "success_reward_indices", ")", "+", "len", "(", "collision_reward_indices", ")", "+", "len", "(", "other_reward_indices", ")", "==", "len", "(", "current_batch", ")", "\n", "sample_size", "=", "len", "(", "other_reward_indices", ")", "\n", "batch_indices", "=", "other_reward_indices", "\n", "# sample_size = min(100, len(other_reward_indices))", "\n", "# batch_indices = list(np.random.choice(other_reward_indices, sample_size))", "\n", "success_sample_size", "=", "int", "(", "oversample_success", "*", "sample_size", ")", "\n", "success_super_sample", "=", "list", "(", "np", ".", "random", ".", "choice", "(", "success_reward_indices", ",", "success_sample_size", ")", ")", "\n", "batch_indices", ".", "extend", "(", "success_super_sample", ")", "\n", "collision_sample_size", "=", "int", "(", "oversample_collision", "*", "sample_size", ")", "\n", "collision_super_sample", "=", "list", "(", "np", ".", "random", ".", "choice", "(", "collision_reward_indices", ",", "collision_sample_size", ")", ")", "\n", "batch_indices", ".", "extend", "(", "collision_super_sample", ")", "\n", "return", "[", "current_batch", "[", "i", "]", "for", "i", "in", "batch_indices", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.tomjur_ModelBasedDDPG.None.pre_trained_reward.get_batch_and_labels": [[169, 196], ["range", "len", "openrave_manager.get_target_pose", "all_start_joints.append", "all_goal_joints.append", "all_actions.append", "all_rewards.append", "all_status.append", "all_goal_poses.append", "all_images.append"], "function", ["None"], ["", "def", "get_batch_and_labels", "(", "batch", ",", "openrave_manager", ",", "image_cache", ")", ":", "\n", "    ", "all_start_joints", "=", "[", "]", "\n", "all_goal_joints", "=", "[", "]", "\n", "all_actions", "=", "[", "]", "\n", "all_rewards", "=", "[", "]", "\n", "all_goal_poses", "=", "[", "]", "\n", "all_status", "=", "[", "]", "\n", "all_images", "=", "None", "\n", "if", "image_cache", "is", "not", "None", ":", "\n", "        ", "all_images", "=", "[", "]", "\n", "", "for", "i", "in", "range", "(", "len", "(", "batch", ")", ")", ":", "\n", "        ", "if", "image_cache", "is", "None", ":", "\n", "            ", "workspace_id", "=", "None", "\n", "start_joints", ",", "goal_joints", ",", "action", ",", "next_joints", ",", "reward", ",", "terminated", ",", "status", "=", "batch", "[", "i", "]", "\n", "", "else", ":", "\n", "            ", "workspace_id", ",", "start_joints", ",", "goal_joints", ",", "action", ",", "next_joints", ",", "reward", ",", "terminated", ",", "status", "=", "batch", "[", "i", "]", "\n", "", "goal_pose", "=", "openrave_manager", ".", "get_target_pose", "(", "goal_joints", ")", "\n", "all_start_joints", ".", "append", "(", "start_joints", "[", "1", ":", "]", ")", "\n", "all_goal_joints", ".", "append", "(", "goal_joints", "[", "1", ":", "]", ")", "\n", "all_actions", ".", "append", "(", "action", "[", "1", ":", "]", ")", "\n", "all_rewards", ".", "append", "(", "reward", ")", "\n", "all_status", ".", "append", "(", "status", ")", "\n", "all_goal_poses", ".", "append", "(", "goal_pose", ")", "\n", "if", "image_cache", "is", "not", "None", ":", "\n", "            ", "image", "=", "image_cache", ".", "items", "[", "workspace_id", "]", ".", "np_array", "\n", "all_images", ".", "append", "(", "image", ")", "\n", "", "", "return", "[", "all_start_joints", ",", "all_goal_joints", ",", "all_actions", ",", "all_goal_poses", ",", "all_images", "]", ",", "all_rewards", ",", "all_status", "\n", "\n"]], "home.repos.pwc.inspect_result.tomjur_ModelBasedDDPG.None.pre_trained_reward.compute_stats_single_class": [[198, 214], ["len", "numpy.argmax", "len", "numpy.mean", "numpy.max", "enumerate", "float", "len", "numpy.abs", "enumerate"], "function", ["None"], ["", "def", "compute_stats_single_class", "(", "real_status", ",", "real_reward", ",", "status_prediction", ",", "reward_prediction", ",", "class_indicator", ")", ":", "\n", "    ", "class_indices", "=", "[", "i", "for", "i", ",", "s", "in", "enumerate", "(", "real_status", ")", "if", "s", "==", "class_indicator", "]", "\n", "if", "len", "(", "class_indices", ")", "==", "0", ":", "\n", "        ", "accuracy", "=", "0.0", "\n", "class_average_absolute_error", "=", "0.0", "\n", "class_max_absolute_error", "=", "0.0", "\n", "", "else", ":", "\n", "        ", "my_status_prediction", "=", "[", "status_prediction", "[", "i", "]", "for", "i", "in", "class_indices", "]", "\n", "best_label", "=", "np", ".", "argmax", "(", "my_status_prediction", ",", "axis", "=", "1", ")", "\n", "best_label", "+=", "1", "\n", "hit_cont", "=", "len", "(", "[", "i", "for", "i", ",", "b", "in", "enumerate", "(", "best_label", ")", "if", "b", "==", "class_indicator", "]", ")", "\n", "accuracy", "=", "float", "(", "hit_cont", ")", "/", "len", "(", "class_indices", ")", "\n", "difference", "=", "[", "np", ".", "abs", "(", "real_reward", "[", "i", "]", "-", "reward_prediction", "[", "i", "]", ")", "for", "i", "in", "class_indices", "]", "\n", "class_average_absolute_error", "=", "np", ".", "mean", "(", "difference", ")", "\n", "class_max_absolute_error", "=", "np", ".", "max", "(", "difference", ")", "\n", "", "return", "class_indices", ",", "[", "class_average_absolute_error", ",", "class_max_absolute_error", ",", "accuracy", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.tomjur_ModelBasedDDPG.None.pre_trained_reward.compute_stats_per_class": [[216, 225], ["pre_trained_reward.compute_stats_single_class", "pre_trained_reward.compute_stats_single_class", "pre_trained_reward.compute_stats_single_class", "len", "len", "len", "len"], "function", ["home.repos.pwc.inspect_result.tomjur_ModelBasedDDPG.None.pre_trained_reward.compute_stats_single_class", "home.repos.pwc.inspect_result.tomjur_ModelBasedDDPG.None.pre_trained_reward.compute_stats_single_class", "home.repos.pwc.inspect_result.tomjur_ModelBasedDDPG.None.pre_trained_reward.compute_stats_single_class"], ["", "def", "compute_stats_per_class", "(", "real_status", ",", "real_reward", ",", "status_prediction", ",", "reward_prediction", ")", ":", "\n", "    ", "goal_rewards_indices", ",", "goal_stats", "=", "compute_stats_single_class", "(", "\n", "real_status", ",", "real_reward", ",", "status_prediction", ",", "reward_prediction", ",", "3", ")", "\n", "collision_rewards_indices", ",", "collision_stats", "=", "compute_stats_single_class", "(", "\n", "real_status", ",", "real_reward", ",", "status_prediction", ",", "reward_prediction", ",", "2", ")", "\n", "other_rewards_indices", ",", "other_stats", "=", "compute_stats_single_class", "(", "\n", "real_status", ",", "real_reward", ",", "status_prediction", ",", "reward_prediction", ",", "1", ")", "\n", "assert", "len", "(", "goal_rewards_indices", ")", "+", "len", "(", "collision_rewards_indices", ")", "+", "len", "(", "other_rewards_indices", ")", "==", "len", "(", "real_reward", ")", "\n", "return", "goal_stats", ",", "collision_stats", ",", "other_stats", "\n", "\n"]], "home.repos.pwc.inspect_result.tomjur_ModelBasedDDPG.None.pre_trained_reward.load_data_from": [[227, 245], ["os.path.exists", "random.shuffle", "len", "bz2.BZ2File", "pickle.load", "bz2.BZ2File.close", "total_buffer.extend", "os.listdir", "file.endswith", "os.path.join", "file.split", "len", "tuple", "list"], "function", ["None"], ["", "def", "load_data_from", "(", "data_dir", ",", "max_read", "=", "None", ",", "is_vision", "=", "False", ")", ":", "\n", "    ", "assert", "os", ".", "path", ".", "exists", "(", "data_dir", ")", "\n", "files", "=", "[", "file", "for", "file", "in", "os", ".", "listdir", "(", "data_dir", ")", "if", "file", ".", "endswith", "(", "\".pkl\"", ")", "]", "\n", "assert", "len", "(", "files", ")", ">", "0", "\n", "random", ".", "shuffle", "(", "files", ")", "\n", "total_buffer", "=", "[", "]", "\n", "for", "file", "in", "files", ":", "\n", "        ", "if", "max_read", "is", "not", "None", "and", "len", "(", "total_buffer", ")", ">", "max_read", ":", "\n", "            ", "break", "\n", "", "compressed_file", "=", "bz2", ".", "BZ2File", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "file", ")", ",", "'r'", ")", "\n", "current_buffer", "=", "pickle", ".", "load", "(", "compressed_file", ")", "\n", "compressed_file", ".", "close", "(", ")", "\n", "if", "is_vision", ":", "\n", "            ", "parts", "=", "file", ".", "split", "(", "'_'", ")", "\n", "workspace_id", "=", "'{}_{}.pkl'", ".", "format", "(", "parts", "[", "0", "]", ",", "parts", "[", "1", "]", ")", "\n", "current_buffer", "=", "[", "tuple", "(", "[", "workspace_id", "]", "+", "list", "(", "t", ")", ")", "for", "t", "in", "current_buffer", "]", "\n", "", "total_buffer", ".", "extend", "(", "current_buffer", ")", "\n", "", "return", "total_buffer", "\n", "", ""]], "home.repos.pwc.inspect_result.tomjur_ModelBasedDDPG.None.summaries_collector.SummariesCollector.__init__": [[6, 14], ["tensorflow.summary.FileWriter", "summaries_collector.SummariesCollector._init_episode_summaries", "summaries_collector.SummariesCollector._init_curriculum_summaries", "tensorflow.summary.FileWriter", "summaries_collector.SummariesCollector._init_episode_summaries", "summaries_collector.SummariesCollector._init_curriculum_summaries", "os.path.join", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.tomjur_ModelBasedDDPG.None.summaries_collector.SummariesCollector._init_episode_summaries", "home.repos.pwc.inspect_result.tomjur_ModelBasedDDPG.None.summaries_collector.SummariesCollector._init_curriculum_summaries", "home.repos.pwc.inspect_result.tomjur_ModelBasedDDPG.None.summaries_collector.SummariesCollector._init_episode_summaries", "home.repos.pwc.inspect_result.tomjur_ModelBasedDDPG.None.summaries_collector.SummariesCollector._init_curriculum_summaries"], ["    ", "def", "__init__", "(", "self", ",", "summaries_dir", ",", "model_name", ")", ":", "\n", "        ", "self", ".", "_train_summary_writer", "=", "tf", ".", "summary", ".", "FileWriter", "(", "os", ".", "path", ".", "join", "(", "summaries_dir", ",", "'train_'", "+", "model_name", ")", ")", "\n", "self", ".", "write_train_episode_summaries", "=", "self", ".", "_init_episode_summaries", "(", "'train'", ",", "self", ".", "_train_summary_writer", ")", "\n", "self", ".", "write_train_curriculum_summaries", "=", "self", ".", "_init_curriculum_summaries", "(", "'train'", ",", "self", ".", "_train_summary_writer", ")", "\n", "\n", "self", ".", "_test_summary_writer", "=", "tf", ".", "summary", ".", "FileWriter", "(", "os", ".", "path", ".", "join", "(", "summaries_dir", ",", "'test_'", "+", "model_name", ")", ")", "\n", "self", ".", "write_test_episode_summaries", "=", "self", ".", "_init_episode_summaries", "(", "'test'", ",", "self", ".", "_test_summary_writer", ")", "\n", "self", ".", "write_test_curriculum_summaries", "=", "self", ".", "_init_curriculum_summaries", "(", "'test'", ",", "self", ".", "_test_summary_writer", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tomjur_ModelBasedDDPG.None.summaries_collector.SummariesCollector._init_episode_summaries": [[15, 42], ["tensorflow.Variable", "tensorflow.Variable", "tensorflow.Variable", "tensorflow.Variable", "tensorflow.summary.merge", "sess.run", "summary_writer.add_summary", "summary_writer.flush", "tensorflow.summary.scalar", "tensorflow.summary.scalar", "tensorflow.summary.scalar", "tensorflow.summary.scalar"], "methods", ["home.repos.pwc.inspect_result.tomjur_ModelBasedDDPG.None.data_collector.CollectorProcess.run"], ["", "@", "staticmethod", "\n", "def", "_init_episode_summaries", "(", "prefix", ",", "summary_writer", ")", ":", "\n", "        ", "episodes_played_var", "=", "tf", ".", "Variable", "(", "0", ",", "trainable", "=", "False", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "successful_episodes_var", "=", "tf", ".", "Variable", "(", "0", ",", "trainable", "=", "False", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "collision_episodes_var", "=", "tf", ".", "Variable", "(", "0", ",", "trainable", "=", "False", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "max_length_episodes_var", "=", "tf", ".", "Variable", "(", "0", ",", "trainable", "=", "False", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "\n", "summaries", "=", "tf", ".", "summary", ".", "merge", "(", "[", "\n", "tf", ".", "summary", ".", "scalar", "(", "prefix", "+", "'_episodes_played'", ",", "episodes_played_var", ")", ",", "\n", "tf", ".", "summary", ".", "scalar", "(", "prefix", "+", "'_successful_episodes'", ",", "successful_episodes_var", "/", "episodes_played_var", ")", ",", "\n", "tf", ".", "summary", ".", "scalar", "(", "prefix", "+", "'_collision_episodes'", ",", "collision_episodes_var", "/", "episodes_played_var", ")", ",", "\n", "tf", ".", "summary", ".", "scalar", "(", "prefix", "+", "'_max_len_episodes'", ",", "max_length_episodes_var", "/", "episodes_played_var", ")", "\n", "]", ")", "\n", "\n", "def", "write_episode_summaries", "(", "sess", ",", "global_step", ",", "episodes_played", ",", "successful_episodes", ",", "collision_episodes", ",", "\n", "max_len_episodes", ")", ":", "\n", "            ", "summary_str", "=", "sess", ".", "run", "(", "summaries", ",", "feed_dict", "=", "{", "\n", "episodes_played_var", ":", "episodes_played", ",", "\n", "successful_episodes_var", ":", "successful_episodes", ",", "\n", "collision_episodes_var", ":", "collision_episodes", ",", "\n", "max_length_episodes_var", ":", "max_len_episodes", "\n", "}", ")", "\n", "\n", "summary_writer", ".", "add_summary", "(", "summary_str", ",", "global_step", ")", "\n", "summary_writer", ".", "flush", "(", ")", "\n", "\n", "", "return", "write_episode_summaries", "\n", "\n"]], "home.repos.pwc.inspect_result.tomjur_ModelBasedDDPG.None.summaries_collector.SummariesCollector._init_curriculum_summaries": [[43, 57], ["tensorflow.Variable", "tensorflow.summary.scalar", "sess.run", "summary_writer.add_summary", "summary_writer.flush"], "methods", ["home.repos.pwc.inspect_result.tomjur_ModelBasedDDPG.None.data_collector.CollectorProcess.run"], ["", "@", "staticmethod", "\n", "def", "_init_curriculum_summaries", "(", "prefix", ",", "summary_writer", ")", ":", "\n", "        ", "curriculum_status_var", "=", "tf", ".", "Variable", "(", "0", ",", "trainable", "=", "False", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "summaries", "=", "tf", ".", "summary", ".", "scalar", "(", "prefix", "+", "'_curriculum_status'", ",", "curriculum_status_var", ")", "\n", "\n", "def", "write_curriculum_summaries", "(", "sess", ",", "global_step", ",", "status", ")", ":", "\n", "            ", "if", "status", "is", "None", ":", "\n", "                ", "return", "\n", "", "summary_str", "=", "sess", ".", "run", "(", "summaries", ",", "feed_dict", "=", "{", "curriculum_status_var", ":", "status", "}", ")", "\n", "\n", "summary_writer", ".", "add_summary", "(", "summary_str", ",", "global_step", ")", "\n", "summary_writer", ".", "flush", "(", ")", "\n", "\n", "", "return", "write_curriculum_summaries", "\n", "\n"]], "home.repos.pwc.inspect_result.tomjur_ModelBasedDDPG.None.summaries_collector.SummariesCollector.write_train_optimization_summaries": [[58, 63], ["summaries_collector.SummariesCollector._train_summary_writer.flush", "summaries_collector.SummariesCollector._train_summary_writer.add_summary"], "methods", ["None"], ["", "def", "write_train_optimization_summaries", "(", "self", ",", "summaries", ",", "global_step", ")", ":", "\n", "        ", "for", "s", "in", "summaries", ":", "\n", "            ", "if", "s", "is", "not", "None", ":", "\n", "                ", "self", ".", "_train_summary_writer", ".", "add_summary", "(", "s", ",", "global_step", ")", "\n", "", "", "self", ".", "_train_summary_writer", ".", "flush", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tomjur_ModelBasedDDPG.None.openrave_trajectory_generator.OpenraveTrajectoryGenerator.__init__": [[8, 19], ["openrave_manager.OpenraveManager", "potential_point.PotentialPoint.from_config"], "methods", ["home.repos.pwc.inspect_result.tomjur_ModelBasedDDPG.None.potential_point.PotentialPoint.from_config"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "self", ".", "action_step_size", "=", "config", "[", "'openrave_rl'", "]", "[", "'action_step_size'", "]", "\n", "self", ".", "goal_sensitivity", "=", "config", "[", "'openrave_rl'", "]", "[", "'goal_sensitivity'", "]", "\n", "self", ".", "challenging_trajectories_only", "=", "config", "[", "'openrave_planner'", "]", "[", "'challenging_trajectories_only'", "]", "\n", "self", ".", "planner_iterations_start", "=", "config", "[", "'openrave_planner'", "]", "[", "'planner_iterations_start'", "]", "\n", "self", ".", "planner_iterations_increase", "=", "config", "[", "'openrave_planner'", "]", "[", "'planner_iterations_increase'", "]", "\n", "self", ".", "planner_iterations_decrease", "=", "config", "[", "'openrave_planner'", "]", "[", "'planner_iterations_decrease'", "]", "\n", "self", ".", "max_planner_iterations", "=", "self", ".", "planner_iterations_start", "\n", "\n", "self", ".", "openrave_manager", "=", "OpenraveManager", "(", "\n", "config", "[", "'openrave_rl'", "]", "[", "'segment_validity_step'", "]", ",", "PotentialPoint", ".", "from_config", "(", "config", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tomjur_ModelBasedDDPG.None.openrave_trajectory_generator.OpenraveTrajectoryGenerator.is_below_goal_sensitivity": [[20, 25], ["openrave_trajectory_generator.OpenraveTrajectoryGenerator.openrave_manager.get_target_pose", "openrave_trajectory_generator.OpenraveTrajectoryGenerator.openrave_manager.get_target_pose", "numpy.linalg.norm", "numpy.array", "numpy.array"], "methods", ["None"], ["", "def", "is_below_goal_sensitivity", "(", "self", ",", "start_joints", ",", "goal_joints", ")", ":", "\n", "        ", "start_pose", "=", "self", ".", "openrave_manager", ".", "get_target_pose", "(", "start_joints", ")", "\n", "goal_pose", "=", "self", ".", "openrave_manager", ".", "get_target_pose", "(", "goal_joints", ")", "\n", "pose_distance", "=", "np", ".", "linalg", ".", "norm", "(", "np", ".", "array", "(", "start_pose", ")", "-", "np", ".", "array", "(", "goal_pose", ")", ")", "\n", "return", "pose_distance", "<", "self", ".", "goal_sensitivity", "\n", "\n"]], "home.repos.pwc.inspect_result.tomjur_ModelBasedDDPG.None.openrave_trajectory_generator.OpenraveTrajectoryGenerator.find_random_trajectory_single_try": [[26, 43], ["openrave_trajectory_generator.OpenraveTrajectoryGenerator.openrave_manager.get_random_joints", "openrave_trajectory_generator.OpenraveTrajectoryGenerator.openrave_manager.get_random_joints", "openrave_trajectory_generator.OpenraveTrajectoryGenerator.is_below_goal_sensitivity", "openrave_trajectory_generator.OpenraveTrajectoryGenerator.openrave_manager.get_target_pose", "openrave_trajectory_generator.OpenraveTrajectoryGenerator.openrave_manager.get_target_pose", "openrave_trajectory_generator.OpenraveTrajectoryGenerator.openrave_manager.plan", "openrave_trajectory_generator.OpenraveTrajectoryGenerator._is_valid_region", "openrave_trajectory_generator.OpenraveTrajectoryGenerator._is_challenging"], "methods", ["home.repos.pwc.inspect_result.tomjur_ModelBasedDDPG.None.openrave_rl_interface.OpenraveRLInterface.is_below_goal_sensitivity", "home.repos.pwc.inspect_result.tomjur_ModelBasedDDPG.None.openrave_rl_interface.OpenraveRLInterface._is_valid_region", "home.repos.pwc.inspect_result.tomjur_ModelBasedDDPG.None.openrave_rl_interface.OpenraveRLInterface._is_challenging"], ["", "def", "find_random_trajectory_single_try", "(", "self", ")", ":", "\n", "# select at random", "\n", "        ", "start_joints", "=", "self", ".", "openrave_manager", ".", "get_random_joints", "(", "{", "0", ":", "0.0", "}", ")", "\n", "goal_joints", "=", "self", ".", "openrave_manager", ".", "get_random_joints", "(", "{", "0", ":", "0.0", "}", ")", "\n", "# if the start and goal are too close, re-sample", "\n", "if", "self", ".", "is_below_goal_sensitivity", "(", "start_joints", ",", "goal_joints", ")", ":", "\n", "            ", "return", "None", "\n", "", "start_pose", "=", "self", ".", "openrave_manager", ".", "get_target_pose", "(", "start_joints", ")", "\n", "goal_pose", "=", "self", ".", "openrave_manager", ".", "get_target_pose", "(", "goal_joints", ")", "\n", "# valid region:", "\n", "if", "not", "self", ".", "_is_valid_region", "(", "start_pose", ",", "goal_pose", ")", ":", "\n", "            ", "return", "None", "\n", "# trajectories that must cross an obstacle", "\n", "", "if", "self", ".", "challenging_trajectories_only", "and", "not", "self", ".", "_is_challenging", "(", "start_pose", ",", "goal_pose", ")", ":", "\n", "            ", "return", "None", "\n", "", "traj", "=", "self", ".", "openrave_manager", ".", "plan", "(", "start_joints", ",", "goal_joints", ",", "self", ".", "max_planner_iterations", ")", "\n", "return", "traj", "\n", "\n"]], "home.repos.pwc.inspect_result.tomjur_ModelBasedDDPG.None.openrave_trajectory_generator.OpenraveTrajectoryGenerator.find_random_trajectory": [[44, 55], ["openrave_trajectory_generator.OpenraveTrajectoryGenerator.find_random_trajectory_single_try", "openrave_trajectory_generator.OpenraveTrajectoryGenerator.split_trajectory"], "methods", ["home.repos.pwc.inspect_result.tomjur_ModelBasedDDPG.None.openrave_trajectory_generator.OpenraveTrajectoryGenerator.find_random_trajectory_single_try", "home.repos.pwc.inspect_result.tomjur_ModelBasedDDPG.None.openrave_trajectory_generator.OpenraveTrajectoryGenerator.split_trajectory"], ["", "def", "find_random_trajectory", "(", "self", ")", ":", "\n", "# lower_size = 0.0  # when doing curriculum, this this is the lowest possible distance between start and goal", "\n", "        ", "while", "True", ":", "\n", "            ", "traj", "=", "self", ".", "find_random_trajectory_single_try", "(", ")", "\n", "if", "traj", "is", "None", ":", "\n", "# if failed to plan, give more power", "\n", "                ", "self", ".", "max_planner_iterations", "+=", "self", ".", "planner_iterations_increase", "\n", "", "elif", "self", ".", "max_planner_iterations", ">", "self", ".", "planner_iterations_start", "+", "self", ".", "planner_iterations_decrease", ":", "\n", "# if plan was found, maybe we need less iterations", "\n", "                ", "self", ".", "max_planner_iterations", "-=", "self", ".", "planner_iterations_decrease", "\n", "return", "self", ".", "split_trajectory", "(", "traj", ",", "self", ".", "action_step_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tomjur_ModelBasedDDPG.None.openrave_trajectory_generator.OpenraveTrajectoryGenerator._is_valid_region": [[56, 59], ["None"], "methods", ["None"], ["", "", "", "@", "staticmethod", "\n", "def", "_is_valid_region", "(", "start_pose", ",", "goal_pose", ")", ":", "\n", "        ", "return", "start_pose", "[", "1", "]", ">", "0.0", "and", "goal_pose", "[", "1", "]", ">", "0.0", "\n", "\n"]], "home.repos.pwc.inspect_result.tomjur_ModelBasedDDPG.None.openrave_trajectory_generator.OpenraveTrajectoryGenerator._is_challenging": [[60, 78], ["numpy.array", "numpy.array", "numpy.linalg.norm", "range", "numpy.array", "numpy.linalg.norm", "numpy.linalg.norm"], "methods", ["None"], ["", "def", "_is_challenging", "(", "self", ",", "start_pose", ",", "goal_pose", ")", ":", "\n", "        ", "workspace_params", "=", "self", ".", "openrave_manager", ".", "loaded_params", "\n", "if", "workspace_params", "is", "None", "or", "workspace_params", ".", "number_of_obstacles", "==", "0", ":", "\n", "            ", "return", "True", "\n", "# check if the distance from any obstacle is smaller that the start-goal-distance", "\n", "", "start", "=", "np", ".", "array", "(", "start_pose", ")", "\n", "goal", "=", "np", ".", "array", "(", "goal_pose", ")", "\n", "start_goal_distance", "=", "np", ".", "linalg", ".", "norm", "(", "start", "-", "goal", ")", "\n", "for", "i", "in", "range", "(", "workspace_params", ".", "number_of_obstacles", ")", ":", "\n", "            ", "obstacle", "=", "np", ".", "array", "(", "\n", "[", "workspace_params", ".", "centers_position_x", "[", "i", "]", ",", "workspace_params", ".", "centers_position_z", "[", "i", "]", "]", "\n", ")", "\n", "start_obstacle_distance", "=", "np", ".", "linalg", ".", "norm", "(", "start", "-", "obstacle", ")", "\n", "goal_obstacle_distance", "=", "np", ".", "linalg", ".", "norm", "(", "goal", "-", "obstacle", ")", "\n", "if", "start_obstacle_distance", "<", "start_goal_distance", "and", "goal_obstacle_distance", "<", "start_goal_distance", ":", "\n", "                ", "return", "True", "\n", "# all tests failed", "\n", "", "", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.tomjur_ModelBasedDDPG.None.openrave_trajectory_generator.OpenraveTrajectoryGenerator.split_trajectory": [[79, 103], ["range", "tuple", "numpy.array", "numpy.array", "numpy.linalg.norm", "range", "numpy.linalg.norm", "len", "res.append", "int", "steps.append", "steps.append", "tuple", "tuple", "numpy.floor"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "split_trajectory", "(", "trajectory", ",", "action_step_size", ")", ":", "\n", "        ", "res", "=", "[", "tuple", "(", "trajectory", "[", "0", "]", ")", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "trajectory", ")", "-", "1", ")", ":", "\n", "            ", "current_step", "=", "np", ".", "array", "(", "trajectory", "[", "i", "]", ")", "\n", "next_step", "=", "np", ".", "array", "(", "trajectory", "[", "i", "+", "1", "]", ")", "\n", "difference", "=", "next_step", "-", "current_step", "\n", "difference_norm", "=", "np", ".", "linalg", ".", "norm", "(", "difference", ")", "\n", "if", "difference_norm", "<", "action_step_size", ":", "\n", "# if smaller than allowed step just append the next step", "\n", "                ", "res", ".", "append", "(", "tuple", "(", "trajectory", "[", "i", "+", "1", "]", ")", ")", "\n", "continue", "\n", "", "scaled_step", "=", "(", "action_step_size", "/", "difference_norm", ")", "*", "difference", "\n", "steps", "=", "[", "]", "\n", "for", "alpha", "in", "range", "(", "int", "(", "np", ".", "floor", "(", "difference_norm", "/", "action_step_size", ")", ")", ")", ":", "\n", "                ", "processed_step", "=", "current_step", "+", "(", "1", "+", "alpha", ")", "*", "scaled_step", "\n", "steps", ".", "append", "(", "processed_step", ")", "\n", "# we probably have a leftover section, append it to res", "\n", "", "last_step_difference", "=", "np", ".", "linalg", ".", "norm", "(", "steps", "[", "-", "1", "]", "-", "next_step", ")", "\n", "if", "last_step_difference", ">", "0.0", ":", "\n", "                ", "steps", ".", "append", "(", "next_step", ")", "\n", "# append to path", "\n", "", "res", "+=", "[", "tuple", "(", "s", ")", "for", "s", "in", "steps", "]", "\n", "", "return", "res", "\n", "", "", ""]], "home.repos.pwc.inspect_result.tomjur_ModelBasedDDPG.None.visualize_test_results.load_file_as_series": [[111, 123], ["bz2.BZ2File", "cPickle.load", "episodes_res.append", "success_rate_res.append", "float"], "function", ["None"], ["def", "load_file_as_series", "(", "test_results_file", ")", ":", "\n", "    ", "with", "bz2", ".", "BZ2File", "(", "test_results_file", ",", "'r'", ")", "as", "compressed_file", ":", "\n", "        ", "test_results", "=", "pickle", ".", "load", "(", "compressed_file", ")", "\n", "", "episodes_res", "=", "[", "]", "\n", "success_rate_res", "=", "[", "]", "\n", "for", "t", "in", "test_results", ":", "\n", "        ", "global_step", ",", "episodes", ",", "test_successful_episodes", ",", "test_collision_episodes", ",", "test_max_len_episodes", ",", "test_mean_reward", "=", "t", "\n", "if", "global_step", "==", "-", "1", ":", "\n", "            ", "continue", "\n", "", "episodes_res", ".", "append", "(", "episodes", ")", "\n", "success_rate_res", ".", "append", "(", "float", "(", "test_successful_episodes", ")", "/", "(", "test_successful_episodes", "+", "test_collision_episodes", "+", "test_max_len_episodes", ")", ")", "\n", "", "return", "episodes_res", ",", "success_rate_res", "\n", "\n"]], "home.repos.pwc.inspect_result.tomjur_ModelBasedDDPG.None.visualize_test_results.load_several_files": [[125, 158], ["visualize_test_results.load_file_as_series", "enumerate", "numpy.expand_dims", "len", "len", "numpy.array", "numpy.concatenate"], "function", ["home.repos.pwc.inspect_result.tomjur_ModelBasedDDPG.None.visualize_test_results.load_file_as_series"], ["", "def", "load_several_files", "(", "test_results_files", ")", ":", "\n", "# collect from each file", "\n", "    ", "all_results", "=", "{", "}", "\n", "longest_res", "=", "None", "\n", "for", "f", "in", "test_results_files", ":", "\n", "        ", "episodes_res", ",", "success_rate_res", "=", "load_file_as_series", "(", "f", ")", "\n", "# once 1.0 reached consider the suffix as 1.0 also", "\n", "i", "=", "0", "\n", "for", "i", ",", "r", "in", "enumerate", "(", "success_rate_res", ")", ":", "\n", "            ", "if", "r", "==", "1.0", ":", "\n", "                ", "break", "\n", "", "", "prefix_size", "=", "i", "+", "1", "\n", "episodes_res", "=", "episodes_res", "[", ":", "prefix_size", "]", "\n", "success_rate_res", "=", "success_rate_res", "[", ":", "prefix_size", "]", "\n", "all_results", "[", "f", "]", "=", "success_rate_res", "\n", "# see which is the longest:", "\n", "if", "longest_res", "is", "None", "or", "episodes_res", "[", "-", "1", "]", ">", "longest_res", "[", "-", "1", "]", ":", "\n", "            ", "longest_res", "=", "episodes_res", "\n", "# merge", "\n", "", "", "data", "=", "None", "\n", "for", "f", "in", "all_results", ":", "\n", "        ", "success_rate_res", "=", "all_results", "[", "f", "]", "\n", "# need to add 1.0 elements", "\n", "count", "=", "len", "(", "longest_res", ")", "-", "len", "(", "success_rate_res", ")", "\n", "if", "count", ">", "0", ":", "\n", "            ", "success_rate_res", "=", "success_rate_res", "+", "[", "1.0", "]", "*", "count", "\n", "", "new_data", "=", "np", ".", "expand_dims", "(", "np", ".", "array", "(", "success_rate_res", ")", ",", "axis", "=", "0", ")", "\n", "if", "data", "is", "None", ":", "\n", "            ", "data", "=", "new_data", "\n", "", "else", ":", "\n", "            ", "data", "=", "np", ".", "concatenate", "(", "(", "data", ",", "new_data", ")", ",", "axis", "=", "0", ")", "\n", "\n", "", "", "return", "longest_res", ",", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.tomjur_ModelBasedDDPG.None.visualize_test_results.plot_group": [[160, 168], ["numpy.mean", "ax.plot", "numpy.min", "numpy.max", "ax.fill_between"], "function", ["None"], ["", "def", "plot_group", "(", "episode_axis", ",", "data", ",", "ax", ",", "label", ",", "color", ")", ":", "\n", "# get data bounds", "\n", "    ", "data_mean", "=", "np", ".", "mean", "(", "data", ",", "axis", "=", "0", ")", "\n", "ax", ".", "plot", "(", "episode_axis", ",", "data_mean", ",", "lw", "=", "2", ",", "label", "=", "label", ",", "color", "=", "color", ")", "\n", "if", "data", ".", "shape", "[", "0", "]", ">", "1", ":", "\n", "        ", "data_min", "=", "np", ".", "min", "(", "data", ",", "axis", "=", "0", ")", "\n", "data_max", "=", "np", ".", "max", "(", "data", ",", "axis", "=", "0", ")", "\n", "ax", ".", "fill_between", "(", "episode_axis", ",", "data_max", ",", "data_min", ",", "facecolor", "=", "color", ",", "alpha", "=", "0.5", ")", "\n", "# if data.shape[0] > 1:", "\n"]], "home.repos.pwc.inspect_result.tomjur_ModelBasedDDPG.None.trajectory_eval.TrajectoryEval.__init__": [[8, 16], ["trajectory_eval.TrajectoryEval._make_dir", "os.path.join", "pickle.dump", "potential_point.PotentialPoint.from_config", "open"], "methods", ["home.repos.pwc.inspect_result.tomjur_ModelBasedDDPG.None.trajectory_eval.TrajectoryEval._make_dir", "home.repos.pwc.inspect_result.tomjur_ModelBasedDDPG.None.potential_point.PotentialPoint.from_config"], ["    ", "def", "__init__", "(", "self", ",", "config", ",", "rollout_manager", ",", "results_directory", ")", ":", "\n", "        ", "self", ".", "config", "=", "config", "\n", "self", ".", "rollout_manager", "=", "rollout_manager", "\n", "self", ".", "results_directory", "=", "results_directory", "\n", "self", ".", "_make_dir", "(", "self", ".", "results_directory", ")", "\n", "potential_points_path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "results_directory", ",", "'potential_points.p'", ")", "\n", "pickle", ".", "dump", "(", "PotentialPoint", ".", "from_config", "(", "config", ")", ",", "open", "(", "potential_points_path", ",", "'w'", ")", ")", "\n", "self", ".", "_is_vision", "=", "config", "[", "'model'", "]", "[", "'consider_image'", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.tomjur_ModelBasedDDPG.None.trajectory_eval.TrajectoryEval.eval": [[17, 48], ["trajectory_eval.TrajectoryEval.rollout_manager.generate_episodes", "sum", "trajectory_eval.TrajectoryEval.save_trajectory", "trajectory_eval.TrajectoryEval.save_trajectory", "trajectory_eval.TrajectoryEval.save_trajectory"], "methods", ["home.repos.pwc.inspect_result.tomjur_ModelBasedDDPG.None.rollout_manager.FixedRolloutManager.generate_episodes", "home.repos.pwc.inspect_result.tomjur_ModelBasedDDPG.None.trajectory_eval.TrajectoryEval.save_trajectory", "home.repos.pwc.inspect_result.tomjur_ModelBasedDDPG.None.trajectory_eval.TrajectoryEval.save_trajectory", "home.repos.pwc.inspect_result.tomjur_ModelBasedDDPG.None.trajectory_eval.TrajectoryEval.save_trajectory"], ["", "def", "eval", "(", "self", ",", "global_step", ",", "number_of_episodes", ",", "is_train", "=", "False", ",", "return_episodes", "=", "False", ")", ":", "\n", "        ", "successful_episodes", "=", "0", "\n", "collision_episodes", "=", "0", "\n", "max_len_episodes", "=", "0", "\n", "episodes", "=", "0", "\n", "mean_total_reward", "=", "0.0", "\n", "episode_results", "=", "self", ".", "rollout_manager", ".", "generate_episodes", "(", "number_of_episodes", ",", "is_train", ")", "\n", "for", "episode_result", "in", "episode_results", ":", "\n", "            ", "episode_agent_trajectory", "=", "episode_result", "[", "0", "]", "\n", "status", "=", "episode_agent_trajectory", "[", "0", "]", "\n", "states", "=", "episode_agent_trajectory", "[", "1", "]", "\n", "rewards", "=", "episode_agent_trajectory", "[", "3", "]", "\n", "goal_pose", "=", "episode_agent_trajectory", "[", "4", "]", "\n", "workspace_id", "=", "episode_agent_trajectory", "[", "6", "]", "if", "self", ".", "_is_vision", "else", "None", "\n", "mean_total_reward", "+=", "sum", "(", "rewards", ")", "\n", "# at the end of episode", "\n", "episodes", "+=", "1", "\n", "if", "status", "==", "1", ":", "\n", "                ", "self", ".", "save_trajectory", "(", "states", ",", "goal_pose", ",", "max_len_episodes", ",", "'max_len'", ",", "global_step", ",", "workspace_id", ")", "\n", "max_len_episodes", "+=", "1", "\n", "", "elif", "status", "==", "2", ":", "\n", "                ", "self", ".", "save_trajectory", "(", "states", ",", "goal_pose", ",", "collision_episodes", ",", "'collision'", ",", "global_step", ",", "workspace_id", ")", "\n", "collision_episodes", "+=", "1", "\n", "", "elif", "status", "==", "3", ":", "\n", "                ", "self", ".", "save_trajectory", "(", "states", ",", "goal_pose", ",", "successful_episodes", ",", "'success'", ",", "global_step", ",", "workspace_id", ")", "\n", "successful_episodes", "+=", "1", "\n", "", "", "mean_total_reward", "/=", "number_of_episodes", "\n", "if", "return_episodes", ":", "\n", "            ", "return", "episodes", ",", "successful_episodes", ",", "collision_episodes", ",", "max_len_episodes", ",", "mean_total_reward", ",", "episode_results", "\n", "", "else", ":", "\n", "            ", "return", "episodes", ",", "successful_episodes", ",", "collision_episodes", ",", "max_len_episodes", ",", "mean_total_reward", "\n", "\n"]], "home.repos.pwc.inspect_result.tomjur_ModelBasedDDPG.None.trajectory_eval.TrajectoryEval.save_trajectory": [[49, 58], ["os.path.join", "trajectory_eval.TrajectoryEval._make_dir", "os.path.join", "pickle.dump", "str", "open"], "methods", ["home.repos.pwc.inspect_result.tomjur_ModelBasedDDPG.None.trajectory_eval.TrajectoryEval._make_dir"], ["", "", "def", "save_trajectory", "(", "self", ",", "trajectory", ",", "goal_pose", ",", "path_index", ",", "header", ",", "global_step", ",", "workspace_id", ")", ":", "\n", "# get the joints", "\n", "        ", "joints", "=", "[", "state", "[", "0", "]", "for", "state", "in", "trajectory", "]", "\n", "to_save", "=", "(", "goal_pose", ",", "joints", ",", "workspace_id", ")", "\n", "step_dir", "=", "os", ".", "path", ".", "join", "(", "self", ".", "results_directory", ",", "str", "(", "global_step", ")", ")", "\n", "self", ".", "_make_dir", "(", "step_dir", ")", "\n", "filename", "=", "'{}_{}.p'", ".", "format", "(", "header", ",", "path_index", ")", "\n", "trajectory_path", "=", "os", ".", "path", ".", "join", "(", "step_dir", ",", "filename", ")", "\n", "pickle", ".", "dump", "(", "to_save", ",", "open", "(", "trajectory_path", ",", "'w'", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tomjur_ModelBasedDDPG.None.trajectory_eval.TrajectoryEval._make_dir": [[59, 63], ["os.path.exists", "os.makedirs"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_make_dir", "(", "dir_location", ")", ":", "\n", "        ", "if", "not", "os", ".", "path", ".", "exists", "(", "dir_location", ")", ":", "\n", "            ", "os", ".", "makedirs", "(", "dir_location", ")", "", "", "", "", ""]], "home.repos.pwc.inspect_result.tomjur_ModelBasedDDPG.None.data_filepaths.get_all_workspaces_directories": [[5, 8], ["os.walk", "len", "w.replace().split", "w.replace"], "function", ["None"], ["def", "get_all_workspaces_directories", "(", "directory", ")", ":", "\n", "    ", "workspaces", "=", "[", "s", "[", "0", "]", "for", "s", "in", "os", ".", "walk", "(", "directory", ")", "]", "\n", "return", "[", "w", "for", "w", "in", "workspaces", "if", "len", "(", "w", ".", "replace", "(", "directory", ",", "''", ")", ".", "split", "(", "'/'", ")", ")", "==", "2", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.tomjur_ModelBasedDDPG.None.data_filepaths.get_workspace_params_path": [[10, 12], ["os.path.join"], "function", ["None"], ["", "def", "get_workspace_params_path", "(", "workspace_dir", ")", ":", "\n", "    ", "return", "os", ".", "path", ".", "join", "(", "workspace_dir", ",", "'params.pkl'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tomjur_ModelBasedDDPG.None.data_filepaths.get_image_path": [[14, 16], ["os.path.join"], "function", ["None"], ["", "def", "get_image_path", "(", "workspace_dir", ")", ":", "\n", "    ", "return", "os", ".", "path", ".", "join", "(", "workspace_dir", ",", "'img.png'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tomjur_ModelBasedDDPG.None.data_filepaths.get_trajectory_path": [[18, 20], ["os.path.join"], "function", ["None"], ["", "def", "get_trajectory_path", "(", "directory", ",", "path_id", ")", ":", "\n", "    ", "return", "os", ".", "path", ".", "join", "(", "directory", ",", "'{}.p'", ".", "format", "(", "path_id", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tomjur_ModelBasedDDPG.None.data_filepaths.get_paths_in_dir": [[22, 25], ["os.path.join", "glob.glob"], "function", ["None"], ["", "def", "get_paths_in_dir", "(", "workspace_dir", ")", ":", "\n", "    ", "search_key", "=", "os", ".", "path", ".", "join", "(", "workspace_dir", ",", "'[0-9]*.p'", ")", "\n", "return", "glob", ".", "glob", "(", "search_key", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.tomjur_ModelBasedDDPG.None.hindsight_policy.HindsightPolicy.__init__": [[6, 13], ["potential_point.PotentialPoint.from_config"], "methods", ["home.repos.pwc.inspect_result.tomjur_ModelBasedDDPG.None.potential_point.PotentialPoint.from_config"], ["    ", "def", "__init__", "(", "self", ",", "config", ",", "replay_buffer", ",", "predict_reward_and_status_func", ")", ":", "\n", "        ", "self", ".", "config", "=", "config", "\n", "self", ".", "replay_buffer", "=", "replay_buffer", "\n", "self", ".", "target_potential_point", "=", "PotentialPoint", ".", "from_config", "(", "config", ")", "[", "-", "1", "]", "\n", "self", ".", "predict_reward_and_status_func", "=", "predict_reward_and_status_func", "\n", "# the following buffer saves the transition we are about to add", "\n", "self", ".", "augmented_buffer", "=", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.tomjur_ModelBasedDDPG.None.hindsight_policy.HindsightPolicy.append_to_replay_buffer": [[14, 19], ["hindsight_policy.HindsightPolicy._score_extra_data_and_add_to_buffer", "hindsight_policy.HindsightPolicy._append_to_replay_buffer_single_episode"], "methods", ["home.repos.pwc.inspect_result.tomjur_ModelBasedDDPG.None.hindsight_policy.HindsightPolicy._score_extra_data_and_add_to_buffer", "home.repos.pwc.inspect_result.tomjur_ModelBasedDDPG.None.hindsight_policy.HindsightPolicy._append_to_replay_buffer_single_episode"], ["", "def", "append_to_replay_buffer", "(", "self", ",", "episodes", ")", ":", "\n", "        ", "self", ".", "augmented_buffer", "=", "[", "]", "\n", "for", "episode", "in", "episodes", ":", "\n", "            ", "self", ".", "_append_to_replay_buffer_single_episode", "(", "episode", ")", "\n", "", "self", ".", "_score_extra_data_and_add_to_buffer", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tomjur_ModelBasedDDPG.None.hindsight_policy.HindsightPolicy._append_to_replay_buffer_single_episode": [[20, 34], ["range", "len", "hindsight_policy.HindsightPolicy.replay_buffer.add", "hindsight_policy.HindsightPolicy._add_extra_data", "len"], "methods", ["home.repos.pwc.inspect_result.tomjur_ModelBasedDDPG.None.replay_buffer.ReplayBuffer.add", "home.repos.pwc.inspect_result.tomjur_ModelBasedDDPG.None.hindsight_policy.HindsightPolicy._add_extra_data"], ["", "def", "_append_to_replay_buffer_single_episode", "(", "self", ",", "episode", ")", ":", "\n", "        ", "status", ",", "states", ",", "actions", ",", "rewards", ",", "goal_pose", ",", "goal_joints", ",", "workspace_id", "=", "episode", "\n", "for", "i", "in", "range", "(", "len", "(", "actions", ")", ")", ":", "\n", "            ", "current_state", "=", "states", "[", "i", "]", "\n", "next_state", "=", "states", "[", "i", "+", "1", "]", "\n", "action_used", "=", "actions", "[", "i", "]", "\n", "current_reward", "=", "rewards", "[", "i", "]", "\n", "# only the last state is a terminal state", "\n", "is_terminal", "=", "i", "==", "len", "(", "actions", ")", "-", "1", "and", "status", "!=", "1", "\n", "self", ".", "replay_buffer", ".", "add", "(", "\n", "goal_pose", ",", "goal_joints", ",", "workspace_id", ",", "current_state", ",", "action_used", ",", "current_reward", ",", "is_terminal", ",", "\n", "next_state", "\n", ")", "\n", "self", ".", "_add_extra_data", "(", "i", ",", "status", ",", "states", ",", "actions", ",", "rewards", ",", "workspace_id", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tomjur_ModelBasedDDPG.None.hindsight_policy.HindsightPolicy._score_extra_data_and_add_to_buffer": [[35, 54], ["len", "hindsight_policy.HindsightPolicy.predict_reward_and_status_func", "enumerate", "hindsight_policy.HindsightPolicy.replay_buffer.add", "hindsight_policy.HindsightPolicy.replay_buffer.add"], "methods", ["home.repos.pwc.inspect_result.tomjur_ModelBasedDDPG.None.replay_buffer.ReplayBuffer.add", "home.repos.pwc.inspect_result.tomjur_ModelBasedDDPG.None.replay_buffer.ReplayBuffer.add"], ["", "", "def", "_score_extra_data_and_add_to_buffer", "(", "self", ")", ":", "\n", "        ", "if", "len", "(", "self", ".", "augmented_buffer", ")", "==", "0", ":", "\n", "            ", "return", "\n", "", "if", "self", ".", "config", "[", "'hindsight'", "]", "[", "'score_with_reward_model'", "]", ":", "\n", "            ", "rewards", "=", "self", ".", "predict_reward_and_status_func", "(", "self", ".", "augmented_buffer", ")", "\n", "for", "i", ",", "transition", "in", "enumerate", "(", "self", ".", "augmented_buffer", ")", ":", "\n", "                ", "goal_pose", ",", "goal_joints", ",", "workspace_id", ",", "current_state", ",", "action_used", ",", "current_reward", ",", "is_terminal", ",", "next_state", "=", "transition", "\n", "self", ".", "replay_buffer", ".", "add", "(", "\n", "goal_pose", ",", "goal_joints", ",", "workspace_id", ",", "current_state", ",", "action_used", ",", "rewards", "[", "i", "]", ",", "is_terminal", ",", "\n", "next_state", "\n", ")", "\n", "", "", "else", ":", "\n", "            ", "for", "transition", "in", "self", ".", "augmented_buffer", ":", "\n", "                ", "goal_pose", ",", "goal_joints", ",", "workspace_id", ",", "current_state", ",", "action_used", ",", "current_reward", ",", "is_terminal", ",", "next_state", "=", "transition", "\n", "self", ".", "replay_buffer", ".", "add", "(", "\n", "goal_pose", ",", "goal_joints", ",", "workspace_id", ",", "current_state", ",", "action_used", ",", "current_reward", ",", "is_terminal", ",", "\n", "next_state", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.tomjur_ModelBasedDDPG.None.hindsight_policy.HindsightPolicy._add_extra_data": [[58, 67], ["hindsight_policy.HindsightPolicy._execute_goal_policy", "hindsight_policy.HindsightPolicy._execute_future_policy"], "methods", ["home.repos.pwc.inspect_result.tomjur_ModelBasedDDPG.None.hindsight_policy.HindsightPolicy._execute_goal_policy", "home.repos.pwc.inspect_result.tomjur_ModelBasedDDPG.None.hindsight_policy.HindsightPolicy._execute_future_policy"], ["", "", "", "def", "_add_extra_data", "(", "self", ",", "current_state_index", ",", "status", ",", "states", ",", "actions", ",", "rewards", ",", "workspace_id", ")", ":", "\n", "        ", "if", "not", "self", ".", "config", "[", "'hindsight'", "]", "[", "'enable'", "]", ":", "\n", "            ", "return", "\n", "", "if", "self", ".", "config", "[", "'hindsight'", "]", "[", "'type'", "]", "==", "'goal'", ":", "\n", "            ", "self", ".", "_execute_goal_policy", "(", "current_state_index", ",", "status", ",", "states", ",", "actions", ",", "rewards", ",", "workspace_id", ")", "\n", "", "elif", "self", ".", "config", "[", "'hindsight'", "]", "[", "'type'", "]", "==", "'future'", ":", "\n", "            ", "self", ".", "_execute_future_policy", "(", "current_state_index", ",", "status", ",", "states", ",", "actions", ",", "rewards", ",", "workspace_id", ")", "\n", "", "else", ":", "\n", "            ", "assert", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.tomjur_ModelBasedDDPG.None.hindsight_policy.HindsightPolicy._execute_goal_policy": [[68, 80], ["len", "hindsight_policy.HindsightPolicy._add_goal_at_index", "len", "hindsight_policy.HindsightPolicy._add_goal_at_index", "len", "len"], "methods", ["home.repos.pwc.inspect_result.tomjur_ModelBasedDDPG.None.hindsight_policy.HindsightPolicy._add_goal_at_index", "home.repos.pwc.inspect_result.tomjur_ModelBasedDDPG.None.hindsight_policy.HindsightPolicy._add_goal_at_index"], ["", "", "def", "_execute_goal_policy", "(", "self", ",", "current_state_index", ",", "status", ",", "states", ",", "actions", ",", "rewards", ",", "workspace_id", ")", ":", "\n", "# if the last state is already close to the goal, don't need to include a similar state", "\n", "        ", "if", "status", "==", "3", ":", "\n", "            ", "return", "\n", "# if the trajectory ended free, the goal is the last state", "\n", "", "if", "status", "==", "1", ":", "\n", "            ", "if", "len", "(", "states", ")", ">", "1", ":", "\n", "                ", "self", ".", "_add_goal_at_index", "(", "current_state_index", ",", "len", "(", "states", ")", "-", "1", ",", "states", ",", "actions", ",", "rewards", ",", "workspace_id", ")", "\n", "# if the trajectory ended in collision, the goal is the before last state", "\n", "", "", "elif", "status", "==", "2", ":", "\n", "            ", "if", "len", "(", "states", ")", ">", "2", ":", "\n", "                ", "self", ".", "_add_goal_at_index", "(", "current_state_index", ",", "len", "(", "states", ")", "-", "2", ",", "states", ",", "actions", ",", "rewards", ",", "workspace_id", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tomjur_ModelBasedDDPG.None.hindsight_policy.HindsightPolicy._execute_future_policy": [[81, 92], ["list", "len", "range", "len", "numpy.random.choice", "hindsight_policy.HindsightPolicy._add_goal_at_index", "len"], "methods", ["home.repos.pwc.inspect_result.tomjur_ModelBasedDDPG.None.hindsight_policy.HindsightPolicy._add_goal_at_index"], ["", "", "", "def", "_execute_future_policy", "(", "self", ",", "current_state_index", ",", "status", ",", "states", ",", "actions", ",", "rewards", ",", "workspace_id", ")", ":", "\n", "# the last possible index depends if the trajectory ended in collision", "\n", "        ", "last_index", "=", "len", "(", "states", ")", "if", "status", "!=", "2", "else", "len", "(", "states", ")", "-", "1", "\n", "times", "=", "self", ".", "config", "[", "'hindsight'", "]", "[", "'k'", "]", "\n", "candidates", "=", "list", "(", "range", "(", "current_state_index", "+", "1", ",", "last_index", ")", ")", "\n", "if", "len", "(", "candidates", ")", ">", "times", ":", "\n", "            ", "goal_indices", "=", "np", ".", "random", ".", "choice", "(", "candidates", ",", "times", ",", "replace", "=", "False", ")", "\n", "", "else", ":", "\n", "            ", "goal_indices", "=", "candidates", "\n", "", "for", "goal_state_index", "in", "goal_indices", ":", "\n", "            ", "self", ".", "_add_goal_at_index", "(", "current_state_index", ",", "goal_state_index", ",", "states", ",", "actions", ",", "rewards", ",", "workspace_id", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tomjur_ModelBasedDDPG.None.hindsight_policy.HindsightPolicy._add_goal_at_index": [[93, 107], ["hindsight_policy.HindsightPolicy.augmented_buffer.append"], "methods", ["None"], ["", "", "def", "_add_goal_at_index", "(", "self", ",", "current_state_index", ",", "goal_state_index", ",", "states", ",", "actions", ",", "rewards", ",", "workspace_id", ")", ":", "\n", "        ", "if", "current_state_index", ">=", "goal_state_index", ":", "\n", "            ", "return", "\n", "", "goal_state", "=", "states", "[", "goal_state_index", "]", "\n", "goal_joints", "=", "goal_state", "[", "0", "]", "\n", "goal_pose", "=", "goal_state", "[", "1", "]", "[", "self", ".", "target_potential_point", ".", "tuple", "]", "\n", "current_state", "=", "states", "[", "current_state_index", "]", "\n", "action_used", "=", "actions", "[", "current_state_index", "]", "\n", "next_state", "=", "states", "[", "current_state_index", "+", "1", "]", "\n", "current_reward", "=", "1.0", "if", "current_state_index", "+", "1", "==", "goal_state_index", "else", "rewards", "[", "current_state_index", "]", "\n", "is_terminal", "=", "True", "if", "current_state_index", "+", "1", "==", "goal_state_index", "else", "False", "\n", "transition", "=", "goal_pose", ",", "goal_joints", ",", "workspace_id", ",", "current_state", ",", "action_used", ",", "current_reward", ",", "is_terminal", ",", "next_state", "\n", "self", ".", "augmented_buffer", ".", "append", "(", "transition", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.tomjur_ModelBasedDDPG.None.image_cache.ImageCacheItem.__init__": [[11, 16], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "workspace_id", ",", "full_filename", ",", "params", ",", "np_array", ")", ":", "\n", "        ", "self", ".", "workspace_id", "=", "workspace_id", "\n", "self", ".", "full_filename", "=", "full_filename", "\n", "self", ".", "params", "=", "params", "\n", "self", ".", "np_array", "=", "np_array", "\n", "\n"]], "home.repos.pwc.inspect_result.tomjur_ModelBasedDDPG.None.image_cache.ImageCache.__init__": [[19, 41], ["os.path.expanduser", "os.walk", "os.path.join", "workspace_generation_utils.WorkspaceParams.load_from_file", "image_cache.ImageCacheItem", "filename.endswith", "filename.replace", "os.path.join", "os.path.isfile", "cPickle.load", "image_cache.ImageCache._get_image_as_numpy", "cPickle.dump", "open", "open"], "methods", ["home.repos.pwc.inspect_result.tomjur_ModelBasedDDPG.None.image_cache.ImageCache._get_image_as_numpy"], ["    ", "def", "__init__", "(", "self", ",", "params_directory", ",", "create_images", "=", "True", ")", ":", "\n", "        ", "self", ".", "items", "=", "{", "}", "\n", "self", ".", "_create_images", "=", "create_images", "\n", "\n", "source_dir", "=", "os", ".", "path", ".", "expanduser", "(", "params_directory", ")", "\n", "for", "dirpath", ",", "dirnames", ",", "filenames", "in", "os", ".", "walk", "(", "source_dir", ")", ":", "\n", "            ", "for", "filename", "in", "filenames", ":", "\n", "                ", "if", "not", "filename", ".", "endswith", "(", "'.pkl'", ")", ":", "\n", "                    ", "continue", "\n", "", "full_file_path", "=", "os", ".", "path", ".", "join", "(", "source_dir", ",", "filename", ")", "\n", "params", "=", "WorkspaceParams", ".", "load_from_file", "(", "full_file_path", ")", "\n", "np_array", "=", "None", "\n", "if", "create_images", ":", "\n", "                    ", "image_filename", "=", "filename", ".", "replace", "(", "'.pkl'", ",", "'.image_pkl'", ")", "\n", "full_image_file_path", "=", "os", ".", "path", ".", "join", "(", "source_dir", ",", "image_filename", ")", "\n", "if", "os", ".", "path", ".", "isfile", "(", "full_image_file_path", ")", ":", "\n", "                        ", "np_array", "=", "pickle", ".", "load", "(", "open", "(", "full_image_file_path", ",", "'r'", ")", ")", "\n", "", "else", ":", "\n", "                        ", "np_array", "=", "self", ".", "_get_image_as_numpy", "(", "params", ")", "\n", "pickle", ".", "dump", "(", "np_array", ",", "open", "(", "full_image_file_path", ",", "'w'", ")", ")", "\n", "\n", "", "", "self", ".", "items", "[", "filename", "]", "=", "ImageCacheItem", "(", "filename", ",", "full_file_path", ",", "params", ",", "np_array", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tomjur_ModelBasedDDPG.None.image_cache.ImageCache.get_image": [[42, 45], ["None"], "methods", ["None"], ["", "", "", "def", "get_image", "(", "self", ",", "workspace_id", ")", ":", "\n", "        ", "assert", "self", ".", "_create_images", "\n", "return", "self", ".", "items", "[", "workspace_id", "]", ".", "np_array", "\n", "\n"]], "home.repos.pwc.inspect_result.tomjur_ModelBasedDDPG.None.image_cache.ImageCache._figure_to_nparray": [[46, 54], ["fig.canvas.draw", "fig.canvas.get_width_height", "numpy.fromstring", "numpy.roll", "fig.canvas.tostring_argb"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_figure_to_nparray", "(", "fig", ")", ":", "\n", "        ", "fig", ".", "canvas", ".", "draw", "(", ")", "\n", "w", ",", "h", "=", "fig", ".", "canvas", ".", "get_width_height", "(", ")", "\n", "buf", "=", "np", ".", "fromstring", "(", "fig", ".", "canvas", ".", "tostring_argb", "(", ")", ",", "dtype", "=", "np", ".", "uint8", ")", "\n", "buf", ".", "shape", "=", "(", "w", ",", "h", ",", "4", ")", "\n", "buf", "=", "np", ".", "roll", "(", "buf", ",", "3", ",", "axis", "=", "2", ")", "\n", "return", "buf", "\n", "\n"]], "home.repos.pwc.inspect_result.tomjur_ModelBasedDDPG.None.image_cache.ImageCache._figure_to_image": [[55, 60], ["image_cache.ImageCache._figure_to_nparray", "PIL.Image.frombytes", "image_cache.ImageCache._figure_to_nparray"], "methods", ["home.repos.pwc.inspect_result.tomjur_ModelBasedDDPG.None.image_cache.ImageCache._figure_to_nparray", "home.repos.pwc.inspect_result.tomjur_ModelBasedDDPG.None.image_cache.ImageCache._figure_to_nparray"], ["", "@", "staticmethod", "\n", "def", "_figure_to_image", "(", "fig", ")", ":", "\n", "        ", "buf", "=", "ImageCache", ".", "_figure_to_nparray", "(", "fig", ")", "\n", "w", ",", "h", ",", "d", "=", "buf", ".", "shape", "\n", "return", "Image", ".", "frombytes", "(", "\"RGBA\"", ",", "(", "w", ",", "h", ")", ",", "buf", ".", "tobytes", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tomjur_ModelBasedDDPG.None.image_cache.ImageCache._remove_transparency": [[61, 77], ["PIL.Image.new", "PIL.Image.new.paste", "im.convert().split", "im.convert"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_remove_transparency", "(", "im", ",", "bg_colour", "=", "(", "255", ",", "255", ",", "255", ")", ")", ":", "\n", "        ", "if", "im", ".", "mode", "in", "(", "'RGBA'", ",", "'LA'", ")", "or", "(", "im", ".", "mode", "==", "'P'", "and", "'transparency'", "in", "im", ".", "info", ")", ":", "\n", "\n", "# Need to convert to RGBA if LA format due to a bug in PIL", "\n", "            ", "alpha", "=", "im", ".", "convert", "(", "'RGBA'", ")", ".", "split", "(", ")", "[", "-", "1", "]", "\n", "\n", "# Create a new background image of our matt color.", "\n", "# Must be RGBA because paste requires both images have the same format", "\n", "\n", "bg", "=", "Image", ".", "new", "(", "\"RGBA\"", ",", "im", ".", "size", ",", "bg_colour", "+", "(", "255", ",", ")", ")", "\n", "bg", ".", "paste", "(", "im", ",", "mask", "=", "alpha", ")", "\n", "return", "bg", "\n", "\n", "", "else", ":", "\n", "            ", "return", "im", "\n", "\n"]], "home.repos.pwc.inspect_result.tomjur_ModelBasedDDPG.None.image_cache.ImageCache._get_image_as_numpy": [[78, 90], ["params.print_image", "image_cache.ImageCache._figure_to_image", "ImageCache._remove_transparency().convert", "im.crop.crop.crop", "im.crop.crop.thumbnail", "numpy.asarray", "matplotlib.clf", "image_cache.ImageCache._remove_transparency"], "methods", ["home.repos.pwc.inspect_result.tomjur_ModelBasedDDPG.None.image_cache.ImageCache._figure_to_image", "home.repos.pwc.inspect_result.tomjur_ModelBasedDDPG.None.image_cache.ImageCache._remove_transparency"], ["", "", "@", "staticmethod", "\n", "def", "_get_image_as_numpy", "(", "params", ")", ":", "\n", "        ", "f", "=", "params", ".", "print_image", "(", ")", "\n", "im", "=", "ImageCache", ".", "_figure_to_image", "(", "f", ")", "\n", "im", "=", "ImageCache", ".", "_remove_transparency", "(", "im", ")", ".", "convert", "(", "'L'", ")", "\n", "im", "=", "im", ".", "crop", "(", "(", "73", ",", "108", ",", "517", ",", "330", ")", ")", "\n", "width", "=", "im", ".", "width", "/", "4", "\n", "height", "=", "im", ".", "height", "/", "4", "\n", "im", ".", "thumbnail", "(", "(", "width", ",", "height", ")", ",", "Image", ".", "ANTIALIAS", ")", "\n", "res", "=", "np", ".", "asarray", "(", "im", ")", "\n", "plt", ".", "clf", "(", ")", "\n", "return", "res", "\n", "\n"]], "home.repos.pwc.inspect_result.tomjur_ModelBasedDDPG.None.replay_buffer.ReplayBuffer.__init__": [[6, 10], ["collections.deque"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "self", ".", "buffer_size", "=", "config", "[", "'model'", "]", "[", "'buffer_size'", "]", "\n", "self", ".", "count", "=", "0", "\n", "self", ".", "buffer", "=", "deque", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tomjur_ModelBasedDDPG.None.replay_buffer.ReplayBuffer.add": [[11, 19], ["replay_buffer.ReplayBuffer.buffer.append", "replay_buffer.ReplayBuffer.buffer.popleft", "replay_buffer.ReplayBuffer.buffer.append"], "methods", ["None"], ["", "def", "add", "(", "self", ",", "goal_pose", ",", "goal_joints", ",", "workspace_id", ",", "current_state", ",", "action", ",", "reward", ",", "terminated", ",", "next_state", ")", ":", "\n", "        ", "experience", "=", "(", "goal_pose", ",", "goal_joints", ",", "workspace_id", ",", "current_state", ",", "action", ",", "reward", ",", "terminated", ",", "next_state", ")", "\n", "if", "self", ".", "count", "<", "self", ".", "buffer_size", ":", "\n", "            ", "self", ".", "buffer", ".", "append", "(", "experience", ")", "\n", "self", ".", "count", "+=", "1", "\n", "", "else", ":", "\n", "            ", "self", ".", "buffer", ".", "popleft", "(", ")", "\n", "self", ".", "buffer", ".", "append", "(", "experience", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tomjur_ModelBasedDDPG.None.replay_buffer.ReplayBuffer.size": [[20, 22], ["None"], "methods", ["None"], ["", "", "def", "size", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "count", "\n", "\n"]], "home.repos.pwc.inspect_result.tomjur_ModelBasedDDPG.None.replay_buffer.ReplayBuffer.sample_batch": [[23, 27], ["min", "random.sample", "zip"], "methods", ["None"], ["", "def", "sample_batch", "(", "self", ",", "batch_size", ")", ":", "\n", "        ", "count", "=", "min", "(", "[", "batch_size", ",", "self", ".", "count", "]", ")", "\n", "batch", "=", "random", ".", "sample", "(", "self", ".", "buffer", ",", "count", ")", "\n", "return", "zip", "(", "*", "batch", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tomjur_ModelBasedDDPG.None.rollout_manager.FixedQueryCollectorProcess.__init__": [[18, 34], ["multiprocessing.Process.__init__", "os.walk", "filename.endswith", "os.path.join", "rollout_manager.FixedQueryCollectorProcess.source_files.append"], "methods", ["home.repos.pwc.inspect_result.tomjur_ModelBasedDDPG.None.openrave_rl_interface.OpenraveRLInterface.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ",", "result_queue", ",", "collector_specific_queue", ",", "source_directory", ")", ":", "\n", "        ", "multiprocessing", ".", "Process", ".", "__init__", "(", "self", ")", "\n", "self", ".", "result_queue", "=", "result_queue", "\n", "self", ".", "collector_specific_queue", "=", "collector_specific_queue", "\n", "self", ".", "config", "=", "config", "\n", "self", ".", "source_directory", "=", "source_directory", "\n", "\n", "self", ".", "source_files", "=", "[", "]", "\n", "for", "dirpath", ",", "dirnames", ",", "filenames", "in", "os", ".", "walk", "(", "self", ".", "source_directory", ")", ":", "\n", "            ", "for", "filename", "in", "filenames", ":", "\n", "                ", "if", "filename", ".", "endswith", "(", "'.path_pkl'", ")", ":", "\n", "                    ", "full_file_path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "source_directory", ",", "filename", ")", "\n", "self", ".", "source_files", ".", "append", "(", "full_file_path", ")", "\n", "\n", "", "", "", "self", ".", "current_files", "=", "[", "]", "\n", "self", ".", "current_trajectories", "=", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.tomjur_ModelBasedDDPG.None.rollout_manager.FixedQueryCollectorProcess.run": [[35, 51], ["rollout_manager.FixedQueryCollectorProcess.collector_specific_queue.get", "rollout_manager.FixedQueryCollectorProcess.collector_specific_queue.task_done", "rollout_manager.FixedQueryCollectorProcess.result_queue.qsize", "rollout_manager.FixedQueryCollectorProcess._get_next", "rollout_manager.FixedQueryCollectorProcess.result_queue.put"], "methods", ["home.repos.pwc.inspect_result.tomjur_ModelBasedDDPG.None.rollout_manager.FixedQueryCollectorProcess._get_next"], ["", "def", "run", "(", "self", ")", ":", "\n", "        ", "episodes_per_update", "=", "self", ".", "config", "[", "'general'", "]", "[", "'episodes_per_update'", "]", "\n", "required_trajectories", "=", "episodes_per_update", "*", "10", "\n", "\n", "while", "True", ":", "\n", "            ", "try", ":", "\n", "                ", "next_collector_specific_task", "=", "self", ".", "collector_specific_queue", ".", "get", "(", "block", "=", "True", ",", "timeout", "=", "0.1", ")", "\n", "task_type", "=", "next_collector_specific_task", "[", "0", "]", "\n", "# can only terminate", "\n", "self", ".", "collector_specific_queue", ".", "task_done", "(", ")", "\n", "break", "\n", "", "except", "Queue", ".", "Empty", ":", "\n", "                ", "pass", "\n", "", "if", "self", ".", "result_queue", ".", "qsize", "(", ")", "<", "required_trajectories", ":", "\n", "                ", "result", "=", "self", ".", "_get_next", "(", ")", "\n", "self", ".", "result_queue", ".", "put", "(", "result", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tomjur_ModelBasedDDPG.None.rollout_manager.FixedQueryCollectorProcess._get_next": [[52, 66], ["rollout_manager.FixedQueryCollectorProcess.current_trajectories.pop", "len", "rollout_manager.FixedQueryCollectorProcess.current_files.pop", "bz2.BZ2File", "cPickle.load", "bz2.BZ2File.close", "random.shuffle", "len", "copy.deepcopy", "random.shuffle"], "methods", ["None"], ["", "", "", "def", "_get_next", "(", "self", ")", ":", "\n", "        ", "if", "len", "(", "self", ".", "current_trajectories", ")", "==", "0", ":", "\n", "# needs to load a new file with trajectories", "\n", "            ", "if", "len", "(", "self", ".", "current_files", ")", "==", "0", ":", "\n", "# needs to load all the files again (and shuffle)", "\n", "                ", "self", ".", "current_files", "=", "copy", ".", "deepcopy", "(", "self", ".", "source_files", ")", "\n", "random", ".", "shuffle", "(", "self", ".", "current_files", ")", "\n", "", "trajectories_file", "=", "self", ".", "current_files", ".", "pop", "(", ")", "\n", "compressed_file", "=", "bz2", ".", "BZ2File", "(", "trajectories_file", ",", "'r'", ")", "\n", "self", ".", "current_trajectories", "=", "pickle", ".", "load", "(", "compressed_file", ")", "\n", "compressed_file", ".", "close", "(", ")", "\n", "random", ".", "shuffle", "(", "self", ".", "current_trajectories", ")", "\n", "# return the first trajectory", "\n", "", "return", "self", ".", "current_trajectories", ".", "pop", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tomjur_ModelBasedDDPG.None.rollout_manager.ActorProcess.__init__": [[69, 80], ["multiprocessing.Process.__init__"], "methods", ["home.repos.pwc.inspect_result.tomjur_ModelBasedDDPG.None.openrave_rl_interface.OpenraveRLInterface.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ",", "generate_episode_queue", ",", "result_queue", ",", "actor_specific_queue", ",", "image_cache", "=", "None", ")", ":", "\n", "        ", "multiprocessing", ".", "Process", ".", "__init__", "(", "self", ")", "\n", "self", ".", "generate_episode_queue", "=", "generate_episode_queue", "\n", "self", ".", "result_queue", "=", "result_queue", "\n", "self", ".", "actor_specific_queue", "=", "actor_specific_queue", "\n", "self", ".", "config", "=", "config", "\n", "self", ".", "image_cache", "=", "image_cache", "\n", "self", ".", "use_vision", "=", "image_cache", "is", "not", "None", "\n", "# members to set at runtime", "\n", "self", ".", "openrave_interface", "=", "None", "\n", "self", ".", "actor", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.tomjur_ModelBasedDDPG.None.rollout_manager.ActorProcess._get_sampled_action": [[81, 92], ["numpy.linalg.norm", "numpy.random.binomial", "numpy.random.uniform", "numpy.shape", "numpy.random.normal", "numpy.shape"], "methods", ["None"], ["", "def", "_get_sampled_action", "(", "self", ",", "action", ")", ":", "\n", "        ", "totally_random", "=", "np", ".", "random", ".", "binomial", "(", "1", ",", "self", ".", "config", "[", "'model'", "]", "[", "'random_action_probability'", "]", ",", "1", ")", "[", "0", "]", "\n", "if", "totally_random", ":", "\n", "# take a completely random action", "\n", "            ", "result", "=", "np", ".", "random", ".", "uniform", "(", "-", "1.0", ",", "1.0", ",", "np", ".", "shape", "(", "action", ")", ")", "\n", "", "else", ":", "\n", "# modify existing step", "\n", "            ", "result", "=", "action", "+", "np", ".", "random", ".", "normal", "(", "0.0", ",", "self", ".", "config", "[", "'model'", "]", "[", "'random_noise_std'", "]", ",", "np", ".", "shape", "(", "action", ")", ")", "\n", "# normalize", "\n", "", "result", "/=", "np", ".", "linalg", ".", "norm", "(", "result", ")", "\n", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.tomjur_ModelBasedDDPG.None.rollout_manager.ActorProcess._compute_state": [[93, 102], ["openrave_manager.get_potential_points_poses"], "methods", ["None"], ["", "def", "_compute_state", "(", "self", ",", "joints", ")", ":", "\n", "        ", "openrave_manager", "=", "self", ".", "openrave_interface", ".", "openrave_manager", "\n", "# get the poses", "\n", "poses", "=", "openrave_manager", ".", "get_potential_points_poses", "(", "joints", ")", "\n", "# get the jacobians", "\n", "jacobians", "=", "None", "\n", "# preprocess the joints (remove first joint value)", "\n", "joints", "=", "joints", "[", "1", ":", "]", "\n", "return", "joints", ",", "poses", ",", "jacobians", "\n", "\n"]], "home.repos.pwc.inspect_result.tomjur_ModelBasedDDPG.None.rollout_manager.ActorProcess._run_episode": [[103, 163], ["datetime.datetime.now", "rollout_manager.ActorProcess.openrave_interface.start_specific", "rollout_manager.ActorProcess.openrave_interface.openrave_manager.get_target_pose", "rollout_manager.ActorProcess._compute_state", "states.append", "datetime.datetime.now", "int", "range", "datetime.datetime.now", "rollout_manager.ActorProcess.openrave_interface.openrave_manager.set_params", "numpy.insert", "rollout_manager.ActorProcess.openrave_interface.step", "rollout_manager.ActorProcess._compute_state", "states.append", "actions.append", "rewards.append", "len", "len", "rollout_manager.ActorProcess.actor.predict_action", "rollout_manager.ActorProcess._get_sampled_action", "len", "len"], "methods", ["home.repos.pwc.inspect_result.tomjur_ModelBasedDDPG.None.openrave_rl_interface.OpenraveRLInterface.start_specific", "home.repos.pwc.inspect_result.tomjur_ModelBasedDDPG.None.rollout_manager.ActorProcess._compute_state", "home.repos.pwc.inspect_result.tomjur_ModelBasedDDPG.None.openrave_rl_interface.OpenraveRLInterface.step", "home.repos.pwc.inspect_result.tomjur_ModelBasedDDPG.None.rollout_manager.ActorProcess._compute_state", "home.repos.pwc.inspect_result.tomjur_ModelBasedDDPG.None.rollout_manager.ActorProcess._get_sampled_action"], ["", "def", "_run_episode", "(", "self", ",", "sess", ",", "query_params", ",", "is_train", ")", ":", "\n", "        ", "trajectory", "=", "query_params", "[", "0", "]", "\n", "trajectory_poses", "=", "query_params", "[", "1", "]", "\n", "if", "self", ".", "use_vision", ":", "\n", "# if we are doing multiple workspaces needs to load the correct one from the cache", "\n", "            ", "workspace_id", "=", "query_params", "[", "2", "]", "\n", "cache_item", "=", "self", ".", "image_cache", ".", "items", "[", "workspace_id", "]", "\n", "workspace_image", "=", "cache_item", ".", "np_array", "\n", "self", ".", "openrave_interface", ".", "openrave_manager", ".", "set_params", "(", "cache_item", ".", "full_filename", ")", "\n", "", "else", ":", "\n", "            ", "workspace_id", "=", "None", "\n", "workspace_image", "=", "None", "\n", "\n", "# the trajectory data structures to return", "\n", "", "start_episode_time", "=", "datetime", ".", "datetime", ".", "now", "(", ")", "\n", "states", "=", "[", "]", "\n", "actions", "=", "[", "]", "\n", "rewards", "=", "[", "]", "\n", "# start the new query", "\n", "current_joints", ",", "goal_joints", ",", "steps_required_for_motion_plan", "=", "self", ".", "openrave_interface", ".", "start_specific", "(", "\n", "trajectory", ")", "\n", "goal_pose", "=", "self", ".", "openrave_interface", ".", "openrave_manager", ".", "get_target_pose", "(", "goal_joints", ")", "\n", "goal_joints", "=", "goal_joints", "[", "1", ":", "]", "\n", "# set the start state", "\n", "current_state", "=", "self", ".", "_compute_state", "(", "current_joints", ")", "\n", "states", ".", "append", "(", "current_state", ")", "\n", "start_rollout_time", "=", "datetime", ".", "datetime", ".", "now", "(", ")", "\n", "# the result of the episode", "\n", "status", "=", "None", "\n", "# compute the maximal number of steps to execute", "\n", "max_steps", "=", "int", "(", "steps_required_for_motion_plan", "*", "self", ".", "config", "[", "'general'", "]", "[", "'max_path_slack'", "]", ")", "\n", "for", "j", "in", "range", "(", "max_steps", ")", ":", "\n", "# do a single step prediction", "\n", "            ", "action_mean", "=", "self", ".", "actor", ".", "predict_action", "(", "\n", "[", "current_state", "[", "0", "]", "]", ",", "[", "workspace_image", "]", ",", "[", "goal_pose", "]", ",", "[", "goal_joints", "]", ",", "sess", ",", "use_online_network", "=", "is_train", "\n", ")", "[", "0", "]", "\n", "sampled_action", "=", "self", ".", "_get_sampled_action", "(", "action_mean", ")", "if", "is_train", "else", "action_mean", "\n", "# make an environment step", "\n", "openrave_step", "=", "np", ".", "insert", "(", "sampled_action", ",", "0", ",", "[", "0.0", "]", ")", "\n", "next_joints", ",", "current_reward", ",", "is_terminal", ",", "status", "=", "self", ".", "openrave_interface", ".", "step", "(", "openrave_step", ")", "\n", "# set a new current state", "\n", "current_state", "=", "self", ".", "_compute_state", "(", "next_joints", ")", "\n", "# update return data structures", "\n", "states", ".", "append", "(", "current_state", ")", "\n", "actions", ".", "append", "(", "sampled_action", ")", "\n", "rewards", ".", "append", "(", "current_reward", ")", "\n", "# break if needed", "\n", "if", "is_terminal", ":", "\n", "                ", "break", "\n", "# return the trajectory along with query info", "\n", "", "", "assert", "len", "(", "states", ")", "==", "len", "(", "actions", ")", "+", "1", "\n", "assert", "len", "(", "states", ")", "==", "len", "(", "rewards", ")", "+", "1", "\n", "end_episode_time", "=", "datetime", ".", "datetime", ".", "now", "(", ")", "\n", "find_trajectory_time", "=", "start_rollout_time", "-", "start_episode_time", "\n", "rollout_time", "=", "end_episode_time", "-", "start_rollout_time", "\n", "\n", "episode_agent_trajectory", "=", "(", "status", ",", "states", ",", "actions", ",", "rewards", ",", "goal_pose", ",", "goal_joints", ",", "workspace_id", ")", "\n", "episode_times", "=", "(", "find_trajectory_time", ",", "rollout_time", ")", "\n", "episode_example_trajectory", "=", "(", "trajectory", ",", "trajectory_poses", ")", "\n", "return", "episode_agent_trajectory", ",", "episode_times", ",", "episode_example_trajectory", "\n", "\n"]], "home.repos.pwc.inspect_result.tomjur_ModelBasedDDPG.None.rollout_manager.ActorProcess._run_main_loop": [[164, 198], ["rollout_manager.ActorProcess.generate_episode_queue.get", "rollout_manager.ActorProcess._run_episode", "rollout_manager.ActorProcess.result_queue.put", "rollout_manager.ActorProcess.generate_episode_queue.task_done", "rollout_manager.ActorProcess.actor_specific_queue.get", "network.Network", "sess.run", "rollout_manager.ActorProcess.actor_specific_queue.task_done", "tensorflow.global_variables_initializer", "rollout_manager.ActorProcess.actor_specific_queue.task_done", "rollout_manager.ActorProcess.actor.set_actor_weights", "rollout_manager.ActorProcess.actor_specific_queue.task_done"], "methods", ["home.repos.pwc.inspect_result.tomjur_ModelBasedDDPG.None.rollout_manager.ActorProcess._run_episode", "home.repos.pwc.inspect_result.tomjur_ModelBasedDDPG.None.data_collector.CollectorProcess.run"], ["", "def", "_run_main_loop", "(", "self", ",", "sess", ")", ":", "\n", "        ", "while", "True", ":", "\n", "            ", "try", ":", "\n", "# wait 1 second for a trajectory request", "\n", "                ", "next_episode_request", "=", "self", ".", "generate_episode_queue", ".", "get", "(", "block", "=", "True", ",", "timeout", "=", "1", ")", "\n", "query_params", "=", "next_episode_request", "[", "0", "]", "\n", "is_train", "=", "next_episode_request", "[", "1", "]", "\n", "path", "=", "self", ".", "_run_episode", "(", "sess", ",", "query_params", ",", "is_train", ")", "\n", "self", ".", "result_queue", ".", "put", "(", "path", ")", "\n", "self", ".", "generate_episode_queue", ".", "task_done", "(", ")", "\n", "", "except", "Queue", ".", "Empty", ":", "\n", "                ", "pass", "\n", "", "try", ":", "\n", "                ", "next_actor_specific_task", "=", "self", ".", "actor_specific_queue", ".", "get", "(", "block", "=", "True", ",", "timeout", "=", "0.001", ")", "\n", "task_type", "=", "next_actor_specific_task", "[", "0", "]", "\n", "if", "task_type", "==", "0", ":", "\n", "# need to init the actor, called once.", "\n", "                    ", "assert", "self", ".", "actor", "is", "None", "\n", "# on init, we only create a part of the graph (online actor model)", "\n", "self", ".", "actor", "=", "Network", "(", "self", ".", "config", ",", "is_rollout_agent", "=", "True", ")", "\n", "sess", ".", "run", "(", "tf", ".", "global_variables_initializer", "(", ")", ")", "\n", "self", ".", "actor_specific_queue", ".", "task_done", "(", ")", "\n", "", "elif", "task_type", "==", "1", ":", "\n", "# need to terminate", "\n", "                    ", "self", ".", "actor_specific_queue", ".", "task_done", "(", ")", "\n", "break", "\n", "", "elif", "task_type", "==", "2", ":", "\n", "# update the weights", "\n", "                    ", "new_weights", "=", "next_actor_specific_task", "[", "1", "]", "\n", "is_online", "=", "next_actor_specific_task", "[", "2", "]", "\n", "self", ".", "actor", ".", "set_actor_weights", "(", "sess", ",", "new_weights", ",", "is_online", "=", "is_online", ")", "\n", "self", ".", "actor_specific_queue", ".", "task_done", "(", ")", "\n", "", "", "except", "Queue", ".", "Empty", ":", "\n", "                ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.tomjur_ModelBasedDDPG.None.rollout_manager.ActorProcess.run": [[199, 213], ["os.path.abspath", "openrave_rl_interface.OpenraveRLInterface", "os.path.expanduser", "os.path.isdir", "tensorflow.Session", "rollout_manager.ActorProcess._run_main_loop", "rollout_manager.ActorProcess.openrave_interface.openrave_manager.set_params", "tensorflow.ConfigProto", "tensorflow.GPUOptions"], "methods", ["home.repos.pwc.inspect_result.tomjur_ModelBasedDDPG.None.data_collector.CollectorProcess._run_main_loop"], ["", "", "", "def", "run", "(", "self", ")", ":", "\n", "        ", "params_file", "=", "os", ".", "path", ".", "abspath", "(", "os", ".", "path", ".", "expanduser", "(", "self", ".", "config", "[", "'general'", "]", "[", "'params_file'", "]", ")", ")", "\n", "self", ".", "openrave_interface", "=", "OpenraveRLInterface", "(", "self", ".", "config", ")", "\n", "if", "not", "os", ".", "path", ".", "isdir", "(", "params_file", ")", ":", "\n", "            ", "if", "params_file", "is", "not", "None", ":", "\n", "# we have a single params file - just load it", "\n", "                ", "self", ".", "openrave_interface", ".", "openrave_manager", ".", "set_params", "(", "params_file", ")", "\n", "\n", "", "", "with", "tf", ".", "Session", "(", "\n", "config", "=", "tf", ".", "ConfigProto", "(", "\n", "gpu_options", "=", "tf", ".", "GPUOptions", "(", "per_process_gpu_memory_fraction", "=", "self", ".", "config", "[", "'general'", "]", "[", "'actor_gpu_usage'", "]", ")", "\n", ")", "\n", ")", "as", "sess", ":", "\n", "            ", "self", ".", "_run_main_loop", "(", "sess", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tomjur_ModelBasedDDPG.None.rollout_manager.FixedRolloutManager.__init__": [[216, 259], ["multiprocessing.JoinableQueue", "multiprocessing.Queue", "multiprocessing.Queue", "multiprocessing.Queue", "multiprocessing.JoinableQueue", "multiprocessing.JoinableQueue", "rollout_manager.FixedQueryCollectorProcess", "rollout_manager.FixedQueryCollectorProcess", "rollout_manager.FixedRolloutManager.train_collector.start", "rollout_manager.FixedRolloutManager.test_collector.start", "multiprocessing.JoinableQueue", "copy.deepcopy", "os.path.expanduser", "copy.deepcopy", "os.path.expanduser", "rollout_manager.ActorProcess", "a.start", "actor_queue.put", "actor_queue.join", "multiprocessing.cpu_count", "range", "os.path.join", "os.path.join", "copy.deepcopy", "range"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "config", ",", "actor_processes", "=", "None", ",", "image_cache", "=", "None", ")", ":", "\n", "        ", "self", ".", "episode_generation_queue", "=", "multiprocessing", ".", "JoinableQueue", "(", ")", "\n", "self", ".", "episode_results_queue", "=", "multiprocessing", ".", "Queue", "(", ")", "\n", "self", ".", "train_query_results_queue", "=", "multiprocessing", ".", "Queue", "(", ")", "\n", "self", ".", "test_query_results_queue", "=", "multiprocessing", ".", "Queue", "(", ")", "\n", "\n", "if", "actor_processes", "is", "None", ":", "\n", "            ", "actor_processes", "=", "config", "[", "'general'", "]", "[", "'actor_processes'", "]", "\n", "if", "actor_processes", "is", "None", ":", "\n", "                ", "actor_processes", "=", "multiprocessing", ".", "cpu_count", "(", ")", "\n", "\n", "", "", "self", ".", "train_collector_specific_queue", "=", "multiprocessing", ".", "JoinableQueue", "(", ")", "\n", "self", ".", "test_collector_specific_queue", "=", "multiprocessing", ".", "JoinableQueue", "(", ")", "\n", "self", ".", "actor_specific_queues", "=", "[", "multiprocessing", ".", "JoinableQueue", "(", ")", "for", "_", "in", "range", "(", "actor_processes", ")", "]", "\n", "\n", "base_dir", "=", "config", "[", "'general'", "]", "[", "'trajectory_directory'", "]", "\n", "\n", "self", ".", "train_collector", "=", "FixedQueryCollectorProcess", "(", "\n", "copy", ".", "deepcopy", "(", "config", ")", ",", "self", ".", "train_query_results_queue", ",", "self", ".", "train_collector_specific_queue", ",", "\n", "os", ".", "path", ".", "expanduser", "(", "os", ".", "path", ".", "join", "(", "base_dir", ",", "'train'", ")", ")", "\n", ")", "\n", "self", ".", "test_collector", "=", "FixedQueryCollectorProcess", "(", "\n", "copy", ".", "deepcopy", "(", "config", ")", ",", "self", ".", "test_query_results_queue", ",", "self", ".", "test_collector_specific_queue", ",", "\n", "os", ".", "path", ".", "expanduser", "(", "os", ".", "path", ".", "join", "(", "base_dir", ",", "'test'", ")", ")", "\n", "\n", ")", "\n", "\n", "self", ".", "actors", "=", "[", "\n", "ActorProcess", "(", "copy", ".", "deepcopy", "(", "config", ")", ",", "self", ".", "episode_generation_queue", ",", "self", ".", "episode_results_queue", ",", "\n", "self", ".", "actor_specific_queues", "[", "i", "]", ",", "image_cache", ")", "\n", "for", "i", "in", "range", "(", "actor_processes", ")", "\n", "]", "\n", "# start all the collector processes", "\n", "self", ".", "train_collector", ".", "start", "(", ")", "\n", "self", ".", "test_collector", ".", "start", "(", ")", "\n", "\n", "# start all the actor processes", "\n", "for", "a", "in", "self", ".", "actors", ":", "\n", "            ", "a", ".", "start", "(", ")", "\n", "# for every actor process, post a message to initialize the actor network", "\n", "", "for", "actor_queue", "in", "self", ".", "actor_specific_queues", ":", "\n", "            ", "actor_queue", ".", "put", "(", "(", "0", ",", ")", ")", "\n", "actor_queue", ".", "join", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tomjur_ModelBasedDDPG.None.rollout_manager.FixedRolloutManager.generate_episodes": [[260, 278], ["range", "rollout_manager.FixedRolloutManager.episode_generation_queue.join", "results_queue.get", "rollout_manager.FixedRolloutManager.episode_generation_queue.put", "episodes.append", "rollout_manager.FixedRolloutManager.episode_results_queue.get"], "methods", ["None"], ["", "", "def", "generate_episodes", "(", "self", ",", "number_of_episodes", ",", "is_train", ")", ":", "\n", "# use collectors to generate queries", "\n", "        ", "for", "i", "in", "range", "(", "number_of_episodes", ")", ":", "\n", "# get a query", "\n", "            ", "results_queue", "=", "self", ".", "train_query_results_queue", "if", "is_train", "else", "self", ".", "test_query_results_queue", "\n", "query", "=", "results_queue", ".", "get", "(", ")", "\n", "message", "=", "(", "query", ",", "is_train", ")", "\n", "# place in queue", "\n", "self", ".", "episode_generation_queue", ".", "put", "(", "message", ")", "\n", "\n", "", "self", ".", "episode_generation_queue", ".", "join", "(", ")", "\n", "\n", "episodes", "=", "[", "]", "\n", "while", "number_of_episodes", ":", "\n", "            ", "number_of_episodes", "-=", "1", "\n", "episodes", ".", "append", "(", "self", ".", "episode_results_queue", ".", "get", "(", ")", ")", "\n", "\n", "", "return", "episodes", "\n", "\n"]], "home.repos.pwc.inspect_result.tomjur_ModelBasedDDPG.None.rollout_manager.FixedRolloutManager.set_policy_weights": [[279, 282], ["rollout_manager.FixedRolloutManager._post_private_message"], "methods", ["home.repos.pwc.inspect_result.tomjur_ModelBasedDDPG.None.data_collector.DataCollector._post_private_message"], ["", "def", "set_policy_weights", "(", "self", ",", "weights", ",", "is_online", ")", ":", "\n", "        ", "message", "=", "(", "2", ",", "weights", ",", "is_online", ")", "\n", "self", ".", "_post_private_message", "(", "message", ",", "self", ".", "actor_specific_queues", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tomjur_ModelBasedDDPG.None.rollout_manager.FixedRolloutManager.end": [[283, 293], ["rollout_manager.FixedRolloutManager._post_private_message", "rollout_manager.FixedRolloutManager._post_private_message", "time.sleep", "rollout_manager.FixedRolloutManager.train_collector.terminate", "rollout_manager.FixedRolloutManager.test_collector.terminate", "time.sleep", "a.terminate"], "methods", ["home.repos.pwc.inspect_result.tomjur_ModelBasedDDPG.None.data_collector.DataCollector._post_private_message", "home.repos.pwc.inspect_result.tomjur_ModelBasedDDPG.None.data_collector.DataCollector._post_private_message"], ["", "def", "end", "(", "self", ")", ":", "\n", "        ", "message", "=", "(", "1", ",", ")", "\n", "self", ".", "_post_private_message", "(", "message", ",", "self", ".", "actor_specific_queues", ")", "\n", "self", ".", "_post_private_message", "(", "message", ",", "[", "self", ".", "train_collector_specific_queue", ",", "self", ".", "test_collector_specific_queue", "]", ")", "\n", "time", ".", "sleep", "(", "10", ")", "\n", "for", "a", "in", "self", ".", "actors", ":", "\n", "            ", "a", ".", "terminate", "(", ")", "\n", "", "self", ".", "train_collector", ".", "terminate", "(", ")", "\n", "self", ".", "test_collector", ".", "terminate", "(", ")", "\n", "time", ".", "sleep", "(", "10", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tomjur_ModelBasedDDPG.None.rollout_manager.FixedRolloutManager._post_private_message": [[294, 300], ["queue.put", "queue.join"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_post_private_message", "(", "message", ",", "queues", ")", ":", "\n", "        ", "for", "queue", "in", "queues", ":", "\n", "            ", "queue", ".", "put", "(", "message", ")", "\n", "", "for", "queue", "in", "queues", ":", "\n", "            ", "queue", ".", "join", "(", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.tomjur_ModelBasedDDPG.None.modeling_utils.get_activation": [[4, 12], ["None"], "function", ["None"], ["def", "get_activation", "(", "activation", ")", ":", "\n", "    ", "if", "activation", "==", "'relu'", ":", "\n", "        ", "return", "tf", ".", "nn", ".", "relu", "\n", "", "if", "activation", "==", "'tanh'", ":", "\n", "        ", "return", "tf", ".", "nn", ".", "tanh", "\n", "", "if", "activation", "==", "'elu'", ":", "\n", "        ", "return", "tf", ".", "nn", ".", "elu", "\n", "", "return", "None", "", "", ""]], "home.repos.pwc.inspect_result.tomjur_ModelBasedDDPG.None.data_collector.CollectorProcess.__init__": [[11, 25], ["multiprocessing.Process.__init__"], "methods", ["home.repos.pwc.inspect_result.tomjur_ModelBasedDDPG.None.openrave_rl_interface.OpenraveRLInterface.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ",", "queued_data_points", ",", "result_queue", ",", "collector_specific_queue", ",", "params_file", "=", "None", ",", "\n", "query_parameters_queue", "=", "None", ",", "init_rl_interface", "=", "False", ",", "init_trajectory_collector", "=", "False", ")", ":", "\n", "        ", "multiprocessing", ".", "Process", ".", "__init__", "(", "self", ")", "\n", "self", ".", "result_queue", "=", "result_queue", "\n", "self", ".", "collector_specific_queue", "=", "collector_specific_queue", "\n", "self", ".", "config", "=", "config", "\n", "self", ".", "params_file", "=", "params_file", "\n", "self", ".", "query_parameters_queue", "=", "query_parameters_queue", "\n", "self", ".", "init_rl_interface", "=", "init_rl_interface", "\n", "self", ".", "init_trajectory_collector", "=", "init_trajectory_collector", "\n", "# members to set at runtime", "\n", "self", ".", "openrave_trajectory_generator", "=", "None", "\n", "self", ".", "openrave_interface", "=", "None", "\n", "self", ".", "queued_data_points", "=", "queued_data_points", "\n", "\n"]], "home.repos.pwc.inspect_result.tomjur_ModelBasedDDPG.None.data_collector.CollectorProcess._get_tuple": [[26, 28], ["None"], "methods", ["None"], ["", "def", "_get_tuple", "(", "self", ",", "query_params", "=", "None", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.tomjur_ModelBasedDDPG.None.data_collector.CollectorProcess._run_main_loop": [[29, 50], ["data_collector.CollectorProcess.collector_specific_queue.get", "data_collector.CollectorProcess.result_queue.qsize", "time.sleep", "data_collector.CollectorProcess.collector_specific_queue.task_done", "data_collector.CollectorProcess.result_queue.put", "data_collector.CollectorProcess._get_tuple", "data_collector.CollectorProcess.query_parameters_queue.get", "data_collector.CollectorProcess.result_queue.put", "data_collector.CollectorProcess._get_tuple"], "methods", ["home.repos.pwc.inspect_result.tomjur_ModelBasedDDPG.None.data_collector.CollectorProcess._get_tuple", "home.repos.pwc.inspect_result.tomjur_ModelBasedDDPG.None.data_collector.CollectorProcess._get_tuple"], ["", "def", "_run_main_loop", "(", "self", ")", ":", "\n", "        ", "while", "True", ":", "\n", "            ", "try", ":", "\n", "                ", "next_collector_specific_task", "=", "self", ".", "collector_specific_queue", ".", "get", "(", "block", "=", "True", ",", "timeout", "=", "0.001", ")", "\n", "task_type", "=", "next_collector_specific_task", "[", "0", "]", "\n", "if", "task_type", "==", "1", ":", "\n", "# need to terminate", "\n", "                    ", "self", ".", "collector_specific_queue", ".", "task_done", "(", ")", "\n", "break", "\n", "", "", "except", "Queue", ".", "Empty", ":", "\n", "                ", "pass", "\n", "", "if", "self", ".", "result_queue", ".", "qsize", "(", ")", "<", "self", ".", "queued_data_points", ":", "\n", "                ", "if", "self", ".", "query_parameters_queue", "is", "None", ":", "\n", "                    ", "self", ".", "result_queue", ".", "put", "(", "self", ".", "_get_tuple", "(", ")", ")", "\n", "", "else", ":", "\n", "                    ", "try", ":", "\n", "                        ", "query_parameters", "=", "self", ".", "query_parameters_queue", ".", "get", "(", "block", "=", "True", ",", "timeout", "=", "0.001", ")", "\n", "self", ".", "result_queue", ".", "put", "(", "self", ".", "_get_tuple", "(", "query_parameters", ")", ")", "\n", "", "except", "Queue", ".", "Empty", ":", "\n", "                        ", "pass", "\n", "", "", "time", ".", "sleep", "(", "1.0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tomjur_ModelBasedDDPG.None.data_collector.CollectorProcess.run": [[51, 62], ["data_collector.CollectorProcess._run_main_loop", "openrave_trajectory_generator.OpenraveTrajectoryGenerator", "openrave_rl_interface.OpenraveRLInterface", "data_collector.CollectorProcess.openrave_trajectory_generator.openrave_manager.set_params", "data_collector.CollectorProcess.openrave_interface.openrave_manager.set_params"], "methods", ["home.repos.pwc.inspect_result.tomjur_ModelBasedDDPG.None.data_collector.CollectorProcess._run_main_loop"], ["", "", "", "def", "run", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "init_trajectory_collector", ":", "\n", "            ", "self", ".", "openrave_trajectory_generator", "=", "OpenraveTrajectoryGenerator", "(", "self", ".", "config", ")", "\n", "", "if", "self", ".", "init_rl_interface", ":", "\n", "            ", "self", ".", "openrave_interface", "=", "OpenraveRLInterface", "(", "self", ".", "config", ")", "\n", "", "if", "self", ".", "params_file", "is", "not", "None", ":", "\n", "            ", "if", "self", ".", "init_trajectory_collector", ":", "\n", "                ", "self", ".", "openrave_trajectory_generator", ".", "openrave_manager", ".", "set_params", "(", "self", ".", "params_file", ")", "\n", "", "if", "self", ".", "init_rl_interface", ":", "\n", "                ", "self", ".", "openrave_interface", ".", "openrave_manager", ".", "set_params", "(", "self", ".", "params_file", ")", "\n", "", "", "self", ".", "_run_main_loop", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tomjur_ModelBasedDDPG.None.data_collector.DataCollector.__init__": [[65, 88], ["multiprocessing.Queue", "data_collector.DataCollector._get_queue_size", "multiprocessing.Queue", "multiprocessing.JoinableQueue", "data_collector.DataCollector._get_collector", "c.start", "data_collector.DataCollector.query_parameters_queue.put", "range", "copy.deepcopy", "range", "len"], "methods", ["home.repos.pwc.inspect_result.tomjur_ModelBasedDDPG.None.data_collector.DataCollector._get_queue_size", "home.repos.pwc.inspect_result.tomjur_ModelBasedDDPG.None.data_collector.DataCollector._get_collector"], ["    ", "def", "__init__", "(", "self", ",", "config", ",", "number_of_threads", ",", "params_file", "=", "None", ",", "query_parameters", "=", "None", ")", ":", "\n", "        ", "self", ".", "number_of_threads", "=", "number_of_threads", "\n", "self", ".", "results_queue", "=", "multiprocessing", ".", "Queue", "(", ")", "\n", "self", ".", "query_parameters_queue", "=", "None", "\n", "if", "query_parameters", "is", "not", "None", ":", "\n", "# put all the query parameters in the designated queue", "\n", "            ", "self", ".", "query_parameters_queue", "=", "multiprocessing", ".", "Queue", "(", "maxsize", "=", "len", "(", "query_parameters", ")", ")", "\n", "for", "t", "in", "query_parameters", ":", "\n", "                ", "self", ".", "query_parameters_queue", ".", "put", "(", "t", ",", "True", ")", "\n", "", "", "self", ".", "collector_specific_queues", "=", "[", "\n", "multiprocessing", ".", "JoinableQueue", "(", ")", "for", "_", "in", "range", "(", "self", ".", "number_of_threads", ")", "\n", "]", "\n", "\n", "queue_size", "=", "self", ".", "_get_queue_size", "(", "number_of_threads", ")", "\n", "self", ".", "collectors", "=", "[", "\n", "self", ".", "_get_collector", "(", "\n", "copy", ".", "deepcopy", "(", "config", ")", ",", "queue_size", ",", "self", ".", "collector_specific_queues", "[", "i", "]", ",", "params_file", "\n", ")", "\n", "for", "i", "in", "range", "(", "self", ".", "number_of_threads", ")", "\n", "]", "\n", "# start all the processes", "\n", "for", "c", "in", "self", ".", "collectors", ":", "\n", "            ", "c", ".", "start", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tomjur_ModelBasedDDPG.None.data_collector.DataCollector._get_queue_size": [[89, 91], ["None"], "methods", ["None"], ["", "", "def", "_get_queue_size", "(", "self", ",", "number_of_threads", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.tomjur_ModelBasedDDPG.None.data_collector.DataCollector._get_collector": [[92, 94], ["None"], "methods", ["None"], ["", "def", "_get_collector", "(", "self", ",", "config", ",", "queued_data_points", ",", "collector_specific_queue", ",", "params_file", "=", "None", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.tomjur_ModelBasedDDPG.None.data_collector.DataCollector.generate_samples": [[95, 102], ["result_buffer.append", "data_collector.DataCollector.results_queue.get"], "methods", ["None"], ["", "def", "generate_samples", "(", "self", ",", "number_of_samples", ")", ":", "\n", "        ", "result_buffer", "=", "[", "]", "\n", "while", "number_of_samples", ":", "\n", "            ", "number_of_samples", "-=", "1", "\n", "result_buffer", ".", "append", "(", "self", ".", "results_queue", ".", "get", "(", ")", ")", "\n", "\n", "", "return", "result_buffer", "\n", "\n"]], "home.repos.pwc.inspect_result.tomjur_ModelBasedDDPG.None.data_collector.DataCollector.end": [[103, 110], ["data_collector.DataCollector._post_private_message", "time.sleep", "time.sleep", "c.terminate"], "methods", ["home.repos.pwc.inspect_result.tomjur_ModelBasedDDPG.None.data_collector.DataCollector._post_private_message"], ["", "def", "end", "(", "self", ")", ":", "\n", "        ", "message", "=", "(", "1", ",", ")", "\n", "self", ".", "_post_private_message", "(", "message", ")", "\n", "time", ".", "sleep", "(", "10", ")", "\n", "for", "c", "in", "self", ".", "collectors", ":", "\n", "            ", "c", ".", "terminate", "(", ")", "\n", "", "time", ".", "sleep", "(", "10", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tomjur_ModelBasedDDPG.None.data_collector.DataCollector._post_private_message": [[111, 116], ["collector_queue.put", "collector_queue.join"], "methods", ["None"], ["", "def", "_post_private_message", "(", "self", ",", "message", ")", ":", "\n", "        ", "for", "collector_queue", "in", "self", ".", "collector_specific_queues", ":", "\n", "            ", "collector_queue", ".", "put", "(", "message", ")", "\n", "", "for", "collector_queue", "in", "self", ".", "collector_specific_queues", ":", "\n", "            ", "collector_queue", ".", "join", "(", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.tomjur_ModelBasedDDPG.None.potential_point.PotentialPoint.__init__": [[7, 14], ["numpy.array"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "tuple_from_config", ")", ":", "\n", "        ", "self", ".", "tuple", "=", "tuple_from_config", "\n", "self", ".", "link", "=", "tuple_from_config", "[", "0", "]", "\n", "self", ".", "x", "=", "tuple_from_config", "[", "1", "]", "\n", "self", ".", "z", "=", "tuple_from_config", "[", "2", "]", "\n", "self", ".", "coordinate", "=", "np", ".", "array", "(", "[", "self", ".", "tuple", "[", "1", "]", ",", "0.0", ",", "self", ".", "tuple", "[", "2", "]", ",", "1.0", "]", ")", "\n", "self", ".", "str", "=", "'l{}_x{}_z{}'", ".", "format", "(", "self", ".", "link", ",", "self", ".", "x", ",", "self", ".", "z", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tomjur_ModelBasedDDPG.None.potential_point.PotentialPoint.from_config": [[15, 22], ["tuple", "potential_point.PotentialPoint", "range", "len"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "from_config", "(", "config", ")", ":", "\n", "        ", "if", "PotentialPoint", ".", "_instance", "is", "None", ":", "\n", "            ", "potential_points", "=", "config", "[", "'model'", "]", "[", "'potential_points'", "]", "\n", "potential_points", "=", "[", "tuple", "(", "potential_points", "[", "i", ":", "i", "+", "3", "]", ")", "for", "i", "in", "range", "(", "0", ",", "len", "(", "potential_points", ")", ",", "3", ")", "]", "\n", "PotentialPoint", ".", "_instance", "=", "[", "PotentialPoint", "(", "t", ")", "for", "t", "in", "potential_points", "]", "\n", "", "return", "PotentialPoint", ".", "_instance", "\n", "", "", ""]], "home.repos.pwc.inspect_result.tomjur_ModelBasedDDPG.None.dqn_model.DqnModel.__init__": [[5, 7], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "prefix", ")", ":", "\n", "        ", "self", ".", "prefix", "=", "'{}_dqn'", ".", "format", "(", "prefix", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tomjur_ModelBasedDDPG.None.dqn_model.DqnModel.predict": [[8, 20], ["tensorflow.layers.conv2d", "tensorflow.layers.conv2d", "tensorflow.layers.flatten", "tensorflow.layers.dense", "tensorflow.layers.dense"], "methods", ["None"], ["", "def", "predict", "(", "self", ",", "workspace_image", ",", "reuse_flag", ")", ":", "\n", "        ", "conv1", "=", "tf", ".", "layers", ".", "conv2d", "(", "workspace_image", ",", "32", ",", "8", ",", "4", ",", "padding", "=", "'same'", ",", "activation", "=", "tf", ".", "nn", ".", "relu", ",", "use_bias", "=", "True", ",", "\n", "name", "=", "'{}_conv1'", ".", "format", "(", "self", ".", "prefix", ")", ",", "reuse", "=", "reuse_flag", ")", "\n", "conv2", "=", "tf", ".", "layers", ".", "conv2d", "(", "conv1", ",", "64", ",", "4", ",", "2", ",", "padding", "=", "'same'", ",", "activation", "=", "tf", ".", "nn", ".", "relu", ",", "use_bias", "=", "True", ",", "\n", "name", "=", "'{}_conv2'", ".", "format", "(", "self", ".", "prefix", ")", ",", "reuse", "=", "reuse_flag", ")", "\n", "# conv3 = tf.layers.conv2d(conv2, 64, 3, 1, padding='same', activation=tf.nn.relu, use_bias=True)", "\n", "# flat = tf.layers.flatten(conv3)", "\n", "flat", "=", "tf", ".", "layers", ".", "flatten", "(", "conv2", ",", "name", "=", "'{}_flat'", ".", "format", "(", "self", ".", "prefix", ")", ")", "\n", "dense1", "=", "tf", ".", "layers", ".", "dense", "(", "flat", ",", "512", ",", "activation", "=", "tf", ".", "nn", ".", "relu", ",", "name", "=", "'{}_dense1'", ".", "format", "(", "self", ".", "prefix", ")", ",", "\n", "reuse", "=", "reuse_flag", ")", "\n", "dense2", "=", "tf", ".", "layers", ".", "dense", "(", "dense1", ",", "512", ",", "activation", "=", "None", ",", "name", "=", "'{}_dense2'", ".", "format", "(", "self", ".", "prefix", ")", ",", "reuse", "=", "reuse_flag", ")", "\n", "return", "dense2", "\n", "\n"]], "home.repos.pwc.inspect_result.tomjur_ModelBasedDDPG.None.episode_editor.EpisodeEditor.__init__": [[5, 22], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "alter_episode_mode", ",", "pre_trained_reward", ",", "image_cache", ",", "joints_dimension", "=", "4", ",", "pose_dimension", "=", "2", ",", "\n", "status_dimension", "=", "3", ",", "image_dimension", "=", "(", "55", ",", "111", ")", ",", "allowed_batch", "=", "None", ")", ":", "\n", "        ", "self", ".", "alter_episode_mode", "=", "alter_episode_mode", "\n", "self", ".", "pre_trained_reward", "=", "pre_trained_reward", "\n", "self", ".", "image_cache", "=", "image_cache", "\n", "self", ".", "joints_dimension", "=", "joints_dimension", "\n", "self", ".", "pose_dimension", "=", "pose_dimension", "\n", "self", ".", "status_dimension", "=", "status_dimension", "\n", "self", ".", "image_dimension", "=", "image_dimension", "\n", "self", ".", "allowed_batch", "=", "allowed_batch", "\n", "\n", "self", ".", "current_joints_buffer", "=", "None", "\n", "self", ".", "goal_joints_buffer", "=", "None", "\n", "self", ".", "actions_buffer", "=", "None", "\n", "self", ".", "goal_poses_buffer", "=", "None", "\n", "self", ".", "status_buffer", "=", "None", "\n", "self", ".", "images_buffer", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.tomjur_ModelBasedDDPG.None.episode_editor.EpisodeEditor._clear_buffers": [[23, 32], ["numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros"], "methods", ["None"], ["", "def", "_clear_buffers", "(", "self", ")", ":", "\n", "        ", "self", ".", "current_joints_buffer", "=", "np", ".", "zeros", "(", "(", "0", ",", "self", ".", "joints_dimension", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "self", ".", "goal_joints_buffer", "=", "np", ".", "zeros", "(", "(", "0", ",", "self", ".", "joints_dimension", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "self", ".", "actions_buffer", "=", "np", ".", "zeros", "(", "(", "0", ",", "self", ".", "joints_dimension", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "self", ".", "goal_poses_buffer", "=", "np", ".", "zeros", "(", "(", "0", ",", "self", ".", "pose_dimension", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "if", "self", ".", "alter_episode_mode", "==", "2", ":", "\n", "            ", "self", ".", "status_buffer", "=", "np", ".", "zeros", "(", "(", "0", ",", "self", ".", "status_dimension", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "", "if", "self", ".", "image_cache", "is", "not", "None", ":", "\n", "            ", "self", ".", "images_buffer", "=", "np", ".", "zeros", "(", "(", "0", ",", "self", ".", "image_dimension", "[", "0", "]", ",", "self", ".", "image_dimension", "[", "1", "]", ")", ",", "dtype", "=", "np", ".", "int32", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tomjur_ModelBasedDDPG.None.episode_editor.EpisodeEditor._append_to_buffers": [[33, 42], ["numpy.append", "numpy.append", "numpy.append", "numpy.append", "numpy.append", "numpy.append"], "methods", ["None"], ["", "", "def", "_append_to_buffers", "(", "self", ",", "current_joints", ",", "goal_joints", ",", "actions", ",", "goal_poses", ",", "status", ",", "images", ")", ":", "\n", "        ", "self", ".", "current_joints_buffer", "=", "np", ".", "append", "(", "self", ".", "current_joints_buffer", ",", "current_joints", ",", "axis", "=", "0", ")", "\n", "self", ".", "goal_joints_buffer", "=", "np", ".", "append", "(", "self", ".", "goal_joints_buffer", ",", "goal_joints", ",", "axis", "=", "0", ")", "\n", "self", ".", "actions_buffer", "=", "np", ".", "append", "(", "self", ".", "actions_buffer", ",", "actions", ",", "axis", "=", "0", ")", "\n", "self", ".", "goal_poses_buffer", "=", "np", ".", "append", "(", "self", ".", "goal_poses_buffer", ",", "goal_poses", ",", "axis", "=", "0", ")", "\n", "if", "self", ".", "status_buffer", "is", "not", "None", ":", "\n", "            ", "self", ".", "status_buffer", "=", "np", ".", "append", "(", "self", ".", "status_buffer", ",", "status", ",", "axis", "=", "0", ")", "\n", "", "if", "self", ".", "images_buffer", "is", "not", "None", ":", "\n", "            ", "self", ".", "images_buffer", "=", "np", ".", "append", "(", "self", ".", "images_buffer", ",", "images", ",", "axis", "=", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tomjur_ModelBasedDDPG.None.episode_editor.EpisodeEditor._predict_buffers_by_batches": [[43, 67], ["numpy.zeros", "numpy.zeros", "episode_editor.EpisodeEditor.pre_trained_reward.make_prediction", "len", "episode_editor.EpisodeEditor.pre_trained_reward.make_prediction", "numpy.append", "numpy.append"], "methods", ["home.repos.pwc.inspect_result.tomjur_ModelBasedDDPG.None.pre_trained_reward.PreTrainedReward.make_prediction", "home.repos.pwc.inspect_result.tomjur_ModelBasedDDPG.None.pre_trained_reward.PreTrainedReward.make_prediction"], ["", "", "def", "_predict_buffers_by_batches", "(", "self", ",", "sess", ")", ":", "\n", "        ", "if", "self", ".", "allowed_batch", "is", "None", ":", "\n", "# predict for all the episodes in the same time", "\n", "            ", "return", "self", ".", "pre_trained_reward", ".", "make_prediction", "(", "\n", "sess", ",", "self", ".", "current_joints_buffer", ",", "self", ".", "goal_joints_buffer", ",", "self", ".", "actions_buffer", ",", "self", ".", "goal_poses_buffer", ",", "\n", "self", ".", "status_buffer", ",", "images", "=", "self", ".", "images_buffer", "\n", ")", "\n", "", "current_index", "=", "0", "\n", "fake_rewards", "=", "np", ".", "zeros", "(", "(", "0", ",", "1", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "fake_status_prob", "=", "np", ".", "zeros", "(", "(", "0", ",", "self", ".", "status_dimension", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "while", "current_index", "<", "len", "(", "self", ".", "current_joints_buffer", ")", ":", "\n", "            ", "current_prediction_result", "=", "self", ".", "pre_trained_reward", ".", "make_prediction", "(", "\n", "sess", ",", "\n", "self", ".", "current_joints_buffer", "[", "current_index", ":", "current_index", "+", "self", ".", "allowed_batch", "]", ",", "\n", "self", ".", "goal_joints_buffer", "[", "current_index", ":", "current_index", "+", "self", ".", "allowed_batch", "]", ",", "\n", "self", ".", "actions_buffer", "[", "current_index", ":", "current_index", "+", "self", ".", "allowed_batch", "]", ",", "\n", "self", ".", "goal_poses_buffer", "[", "current_index", ":", "current_index", "+", "self", ".", "allowed_batch", "]", ",", "\n", "self", ".", "status_buffer", "[", "current_index", ":", "current_index", "+", "self", ".", "allowed_batch", "]", ",", "\n", "images", "=", "self", ".", "images_buffer", "[", "current_index", ":", "current_index", "+", "self", ".", "allowed_batch", "]", "\n", ")", "\n", "current_index", "+=", "self", ".", "allowed_batch", "\n", "fake_rewards", "=", "np", ".", "append", "(", "fake_rewards", ",", "current_prediction_result", "[", "0", "]", ",", "axis", "=", "0", ")", "\n", "fake_status_prob", "=", "np", ".", "append", "(", "fake_status_prob", ",", "current_prediction_result", "[", "1", "]", ",", "axis", "=", "0", ")", "\n", "", "return", "fake_rewards", ",", "fake_status_prob", "\n", "\n"]], "home.repos.pwc.inspect_result.tomjur_ModelBasedDDPG.None.episode_editor.EpisodeEditor.process_episodes": [[68, 125], ["episode_editor.EpisodeEditor._clear_buffers", "episode_editor.EpisodeEditor._predict_buffers_by_batches", "zip", "episode_start_indices.append", "episode_editor.EpisodeEditor._append_to_buffers", "resulting_episodes.append", "len", "numpy.zeros", "episode_editor.EpisodeEditor.image_cache.get_image", "len", "len", "len", "numpy.argmax", "range", "len", "len", "numpy.array", "len", "len"], "methods", ["home.repos.pwc.inspect_result.tomjur_ModelBasedDDPG.None.episode_editor.EpisodeEditor._clear_buffers", "home.repos.pwc.inspect_result.tomjur_ModelBasedDDPG.None.episode_editor.EpisodeEditor._predict_buffers_by_batches", "home.repos.pwc.inspect_result.tomjur_ModelBasedDDPG.None.episode_editor.EpisodeEditor._append_to_buffers", "home.repos.pwc.inspect_result.tomjur_ModelBasedDDPG.None.image_cache.ImageCache.get_image"], ["", "def", "process_episodes", "(", "self", ",", "episodes", ",", "sess", ")", ":", "\n", "# no alteration", "\n", "        ", "if", "self", ".", "alter_episode_mode", "==", "0", ":", "\n", "            ", "return", "episodes", "\n", "", "assert", "self", ".", "pre_trained_reward", "is", "not", "None", "\n", "# clear reward network input buffers", "\n", "self", ".", "_clear_buffers", "(", ")", "\n", "episode_start_indices", "=", "[", "]", "\n", "for", "episode_agent_trajectory", "in", "episodes", ":", "\n", "# save the start index for every episode", "\n", "            ", "episode_start_indices", ".", "append", "(", "len", "(", "self", ".", "current_joints_buffer", ")", ")", "\n", "# add data to buffers", "\n", "status", ",", "states", ",", "actions", ",", "rewards", ",", "goal_pose", ",", "goal_joints", ",", "workspace_id", "=", "episode_agent_trajectory", "\n", "current_joints", "=", "[", "state", "[", "0", "]", "for", "state", "in", "states", "[", ":", "-", "1", "]", "]", "\n", "one_hot_status", "=", "None", "\n", "if", "self", ".", "alter_episode_mode", "==", "2", ":", "\n", "                ", "one_hot_status", "=", "np", ".", "zeros", "(", "(", "len", "(", "rewards", ")", ",", "3", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "one_hot_status", "[", ":", "-", "1", ",", "0", "]", "=", "1.0", "\n", "one_hot_status", "[", "-", "1", ",", "2", "]", "=", "1.0", "\n", "", "images", "=", "None", "\n", "if", "self", ".", "images_buffer", "is", "not", "None", ":", "\n", "                ", "image", "=", "self", ".", "image_cache", ".", "get_image", "(", "workspace_id", ")", "\n", "images", "=", "[", "image", "]", "*", "len", "(", "actions", ")", "\n", "", "self", ".", "_append_to_buffers", "(", "current_joints", ",", "[", "goal_joints", "]", "*", "len", "(", "actions", ")", ",", "actions", ",", "[", "goal_pose", "]", "*", "len", "(", "actions", ")", ",", "\n", "one_hot_status", ",", "images", ")", "\n", "# get the results by batch:", "\n", "", "fake_rewards", ",", "fake_status_prob", "=", "self", ".", "_predict_buffers_by_batches", "(", "sess", ")", "\n", "\n", "# partition the results by episode", "\n", "resulting_episodes", "=", "[", "]", "\n", "for", "episode_start_index", ",", "episode_agent_trajectory", "in", "zip", "(", "episode_start_indices", ",", "episodes", ")", ":", "\n", "            ", "status", ",", "states", ",", "actions", ",", "rewards", ",", "goal_pose", ",", "goal_joints", ",", "workspace_id", "=", "episode_agent_trajectory", "\n", "# get the relevant rewards", "\n", "relevant_rewards", "=", "fake_rewards", "[", "episode_start_index", ":", "episode_start_index", "+", "len", "(", "rewards", ")", "]", "\n", "if", "self", ".", "alter_episode_mode", "==", "2", ":", "\n", "                ", "altered_result", "=", "status", ",", "states", ",", "actions", ",", "relevant_rewards", ",", "goal_pose", ",", "goal_joints", ",", "workspace_id", "\n", "", "elif", "self", ".", "alter_episode_mode", "==", "1", ":", "\n", "                ", "relevant_fake_status", "=", "fake_status_prob", "[", "episode_start_index", ":", "episode_start_index", "+", "len", "(", "rewards", ")", "]", "\n", "fake_status", "=", "np", ".", "argmax", "(", "np", ".", "array", "(", "relevant_fake_status", ")", ",", "axis", "=", "1", ")", "\n", "fake_status", "+=", "1", "\n", "# iterate over approximated episode and see if truncation is needed", "\n", "truncation_index", "=", "0", "\n", "for", "truncation_index", "in", "range", "(", "len", "(", "fake_status", ")", ")", ":", "\n", "                    ", "if", "fake_status", "[", "truncation_index", "]", "!=", "1", ":", "\n", "                        ", "break", "\n", "# return the status of the last transition, truncated list of states and actions, the fake rewards (also", "\n", "# truncated) and the goal parameters as-is.", "\n", "", "", "altered_status", "=", "fake_status", "[", "truncation_index", "]", "\n", "altered_states", "=", "states", "[", ":", "truncation_index", "+", "2", "]", "\n", "altered_actions", "=", "actions", "[", ":", "truncation_index", "+", "1", "]", "\n", "altered_rewards", "=", "[", "r", "[", "0", "]", "for", "r", "in", "relevant_rewards", "[", ":", "truncation_index", "+", "1", "]", "]", "\n", "altered_result", "=", "altered_status", ",", "altered_states", ",", "altered_actions", ",", "altered_rewards", ",", "goal_pose", ",", "goal_joints", ",", "workspace_id", "\n", "", "else", ":", "\n", "                ", "assert", "False", "\n", "", "resulting_episodes", ".", "append", "(", "altered_result", ")", "\n", "", "return", "resulting_episodes", "\n", "", "", ""]], "home.repos.pwc.inspect_result.tomjur_ModelBasedDDPG.None.openrave_rl_interface.OpenraveRLInterface.__init__": [[12, 25], ["openrave_manager.OpenraveManager", "potential_point.PotentialPoint.from_config"], "methods", ["home.repos.pwc.inspect_result.tomjur_ModelBasedDDPG.None.potential_point.PotentialPoint.from_config"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "self", ".", "action_step_size", "=", "config", "[", "'openrave_rl'", "]", "[", "'action_step_size'", "]", "\n", "self", ".", "goal_sensitivity", "=", "config", "[", "'openrave_rl'", "]", "[", "'goal_sensitivity'", "]", "\n", "self", ".", "keep_alive_penalty", "=", "config", "[", "'openrave_rl'", "]", "[", "'keep_alive_penalty'", "]", "\n", "self", ".", "truncate_penalty", "=", "config", "[", "'openrave_rl'", "]", "[", "'truncate_penalty'", "]", "\n", "\n", "self", ".", "openrave_manager", "=", "OpenraveManager", "(", "\n", "config", "[", "'openrave_rl'", "]", "[", "'segment_validity_step'", "]", ",", "PotentialPoint", ".", "from_config", "(", "config", ")", ")", "\n", "\n", "self", ".", "current_joints", "=", "None", "\n", "self", ".", "goal_joints", "=", "None", "\n", "self", ".", "start_joints", "=", "None", "\n", "self", ".", "traj", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.tomjur_ModelBasedDDPG.None.openrave_rl_interface.OpenraveRLInterface.is_below_goal_sensitivity": [[26, 31], ["openrave_rl_interface.OpenraveRLInterface.openrave_manager.get_target_pose", "openrave_rl_interface.OpenraveRLInterface.openrave_manager.get_target_pose", "numpy.linalg.norm", "numpy.array", "numpy.array"], "methods", ["None"], ["", "def", "is_below_goal_sensitivity", "(", "self", ",", "start_joints", ",", "goal_joints", ")", ":", "\n", "        ", "start_pose", "=", "self", ".", "openrave_manager", ".", "get_target_pose", "(", "start_joints", ")", "\n", "goal_pose", "=", "self", ".", "openrave_manager", ".", "get_target_pose", "(", "goal_joints", ")", "\n", "pose_distance", "=", "np", ".", "linalg", ".", "norm", "(", "np", ".", "array", "(", "start_pose", ")", "-", "np", ".", "array", "(", "goal_pose", ")", ")", "\n", "return", "pose_distance", "<", "self", ".", "goal_sensitivity", "\n", "\n"]], "home.repos.pwc.inspect_result.tomjur_ModelBasedDDPG.None.openrave_rl_interface.OpenraveRLInterface.start_specific": [[32, 47], ["len", "numpy.array", "numpy.array", "numpy.array", "range", "numpy.linalg.norm", "len", "numpy.array", "numpy.array"], "methods", ["None"], ["", "def", "start_specific", "(", "self", ",", "traj", ",", "verify_traj", "=", "True", ")", ":", "\n", "        ", "self", ".", "traj", "=", "traj", "\n", "start_joints", "=", "traj", "[", "0", "]", "\n", "goal_joints", "=", "traj", "[", "-", "1", "]", "\n", "# assert path is legal", "\n", "if", "verify_traj", ":", "\n", "            ", "step_size", "=", "self", ".", "action_step_size", "+", "0.00001", "\n", "for", "i", "in", "range", "(", "len", "(", "traj", ")", "-", "1", ")", ":", "\n", "                ", "step_i_size", "=", "np", ".", "linalg", ".", "norm", "(", "np", ".", "array", "(", "traj", "[", "i", "]", ")", "-", "np", ".", "array", "(", "traj", "[", "i", "+", "1", "]", ")", ")", "\n", "assert", "step_i_size", "<", "step_size", ",", "'step_i_size {}'", ".", "format", "(", "step_i_size", ")", "\n", "", "", "steps_required_for_motion_plan", "=", "len", "(", "traj", ")", "\n", "self", ".", "current_joints", "=", "np", ".", "array", "(", "start_joints", ")", "\n", "self", ".", "start_joints", "=", "np", ".", "array", "(", "start_joints", ")", "\n", "self", ".", "goal_joints", "=", "np", ".", "array", "(", "goal_joints", ")", "\n", "return", "start_joints", ",", "goal_joints", ",", "steps_required_for_motion_plan", "\n", "\n"]], "home.repos.pwc.inspect_result.tomjur_ModelBasedDDPG.None.openrave_rl_interface.OpenraveRLInterface._is_valid_region": [[48, 51], ["None"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_is_valid_region", "(", "start_pose", ",", "goal_pose", ")", ":", "\n", "        ", "return", "start_pose", "[", "1", "]", ">", "0.0", "and", "goal_pose", "[", "1", "]", ">", "0.0", "\n", "\n"]], "home.repos.pwc.inspect_result.tomjur_ModelBasedDDPG.None.openrave_rl_interface.OpenraveRLInterface._is_challenging": [[52, 70], ["numpy.array", "numpy.array", "numpy.linalg.norm", "range", "numpy.array", "numpy.linalg.norm", "numpy.linalg.norm"], "methods", ["None"], ["", "def", "_is_challenging", "(", "self", ",", "start_pose", ",", "goal_pose", ")", ":", "\n", "        ", "workspace_params", "=", "self", ".", "openrave_manager", ".", "loaded_params", "\n", "if", "workspace_params", "is", "None", "or", "workspace_params", ".", "number_of_obstacles", "==", "0", ":", "\n", "            ", "return", "True", "\n", "# check if the distance from any obstacle is smaller that the start-goal-distance", "\n", "", "start", "=", "np", ".", "array", "(", "start_pose", ")", "\n", "goal", "=", "np", ".", "array", "(", "goal_pose", ")", "\n", "start_goal_distance", "=", "np", ".", "linalg", ".", "norm", "(", "start", "-", "goal", ")", "\n", "for", "i", "in", "range", "(", "workspace_params", ".", "number_of_obstacles", ")", ":", "\n", "            ", "obstacle", "=", "np", ".", "array", "(", "\n", "[", "workspace_params", ".", "centers_position_x", "[", "i", "]", ",", "workspace_params", ".", "centers_position_z", "[", "i", "]", "]", "\n", ")", "\n", "start_obstacle_distance", "=", "np", ".", "linalg", ".", "norm", "(", "start", "-", "obstacle", ")", "\n", "goal_obstacle_distance", "=", "np", ".", "linalg", ".", "norm", "(", "goal", "-", "obstacle", ")", "\n", "if", "start_obstacle_distance", "<", "start_goal_distance", "and", "goal_obstacle_distance", "<", "start_goal_distance", ":", "\n", "                ", "return", "True", "\n", "# all tests failed", "\n", "", "", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.tomjur_ModelBasedDDPG.None.openrave_rl_interface.OpenraveRLInterface.step": [[71, 90], ["openrave_rl_interface.OpenraveRLInterface.openrave_manager.truncate_joints", "openrave_rl_interface.OpenraveRLInterface.is_below_goal_sensitivity", "openrave_rl_interface.OpenraveRLInterface._get_step_result", "openrave_rl_interface.OpenraveRLInterface.openrave_manager.check_segment_validity", "openrave_rl_interface.OpenraveRLInterface._get_step_result", "openrave_rl_interface.OpenraveRLInterface._get_step_result", "numpy.linalg.norm"], "methods", ["home.repos.pwc.inspect_result.tomjur_ModelBasedDDPG.None.openrave_rl_interface.OpenraveRLInterface.is_below_goal_sensitivity", "home.repos.pwc.inspect_result.tomjur_ModelBasedDDPG.None.openrave_rl_interface.OpenraveRLInterface._get_step_result", "home.repos.pwc.inspect_result.tomjur_ModelBasedDDPG.None.openrave_rl_interface.OpenraveRLInterface._get_step_result", "home.repos.pwc.inspect_result.tomjur_ModelBasedDDPG.None.openrave_rl_interface.OpenraveRLInterface._get_step_result"], ["", "def", "step", "(", "self", ",", "joints_action", ")", ":", "\n", "# compute next joints", "\n", "        ", "step", "=", "joints_action", "*", "self", ".", "action_step_size", "\n", "next_joints_before_truncate", "=", "self", ".", "current_joints", "+", "step", "\n", "next_joints", "=", "self", ".", "openrave_manager", ".", "truncate_joints", "(", "next_joints_before_truncate", ")", "\n", "\n", "reward", "=", "0.0", "\n", "if", "self", ".", "truncate_penalty", ">", "0.0", ":", "\n", "            ", "reward", "-=", "self", ".", "truncate_penalty", "*", "np", ".", "linalg", ".", "norm", "(", "next_joints_before_truncate", "-", "next_joints", ")", "/", "self", ".", "action_step_size", "\n", "\n", "# if segment not valid return collision result", "\n", "", "if", "not", "self", ".", "openrave_manager", ".", "check_segment_validity", "(", "self", ".", "current_joints", ",", "next_joints", ")", ":", "\n", "            ", "return", "self", ".", "_get_step_result", "(", "next_joints", ",", "-", "1.0", "+", "reward", ",", "True", ",", "2", ")", "\n", "# if close enough to goal, return positive reward", "\n", "", "if", "self", ".", "is_below_goal_sensitivity", "(", "next_joints", ",", "self", ".", "goal_joints", ")", ":", "\n", "            ", "return", "self", ".", "_get_step_result", "(", "next_joints", ",", "1.0", "+", "reward", ",", "True", ",", "3", ")", "\n", "# else, just a normal step...", "\n", "", "return", "self", ".", "_get_step_result", "(", "next_joints", ",", "-", "self", ".", "keep_alive_penalty", "+", "reward", ",", "False", ",", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tomjur_ModelBasedDDPG.None.openrave_rl_interface.OpenraveRLInterface._get_step_result": [[91, 97], ["list"], "methods", ["None"], ["", "def", "_get_step_result", "(", "self", ",", "next_joints", ",", "reward", ",", "is_terminal", ",", "enum_res", ")", ":", "\n", "        ", "if", "is_terminal", ":", "\n", "            ", "self", ".", "current_joints", "=", "None", "\n", "", "else", ":", "\n", "            ", "self", ".", "current_joints", "=", "next_joints", "\n", "", "return", "list", "(", "next_joints", ")", ",", "reward", ",", "is_terminal", ",", "enum_res", "\n", "", "", ""]]}