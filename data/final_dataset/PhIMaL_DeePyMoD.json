{"home.repos.pwc.inspect_result.PhIMaL_DeePyMoD.utils.utilities.string_matmul": [[7, 11], ["itertools.product"], "function", ["None"], ["def", "string_matmul", "(", "list_1", ",", "list_2", ")", ":", "\n", "    ", "\"\"\"Matrix multiplication with strings.\"\"\"", "\n", "prod", "=", "[", "element", "[", "0", "]", "+", "element", "[", "1", "]", "for", "element", "in", "product", "(", "list_1", ",", "list_2", ")", "]", "\n", "return", "prod", "\n", "\n"]], "home.repos.pwc.inspect_result.PhIMaL_DeePyMoD.utils.utilities.terms_definition": [[13, 40], ["len", "utilities.string_matmul", "list", "list", "list", "itertools.chain.from_iterable", "itertools.chain.from_iterable", "itertools.chain.from_iterable", "utilities.string_matmul", "utilities.string_matmul", "itertools.combinations", "utilities.string_matmul", "itertools.combinations", "itertools.product"], "function", ["home.repos.pwc.inspect_result.PhIMaL_DeePyMoD.utils.utilities.string_matmul", "home.repos.pwc.inspect_result.PhIMaL_DeePyMoD.utils.utilities.string_matmul", "home.repos.pwc.inspect_result.PhIMaL_DeePyMoD.utils.utilities.string_matmul", "home.repos.pwc.inspect_result.PhIMaL_DeePyMoD.utils.utilities.string_matmul"], ["", "def", "terms_definition", "(", "poly_list", ",", "deriv_list", ")", ":", "\n", "    ", "\"\"\"Calculates which terms are in the library.\"\"\"", "\n", "if", "len", "(", "poly_list", ")", "==", "1", ":", "\n", "        ", "theta", "=", "string_matmul", "(", "\n", "poly_list", "[", "0", "]", ",", "deriv_list", "[", "0", "]", "\n", ")", "# If we have a single output, we simply calculate and flatten matrix product between polynomials and derivatives to get library", "\n", "", "else", ":", "\n", "        ", "theta_uv", "=", "list", "(", "\n", "chain", ".", "from_iterable", "(", "\n", "[", "string_matmul", "(", "u", ",", "v", ")", "for", "u", ",", "v", "in", "combinations", "(", "poly_list", ",", "2", ")", "]", "\n", ")", "\n", ")", "# calculate all unique combinations between polynomials", "\n", "theta_dudv", "=", "list", "(", "\n", "chain", ".", "from_iterable", "(", "\n", "[", "string_matmul", "(", "du", ",", "dv", ")", "[", "1", ":", "]", "for", "du", ",", "dv", "in", "combinations", "(", "deriv_list", ",", "2", ")", "]", "\n", ")", "\n", ")", "# calculate all unique combinations of derivatives", "\n", "theta_udu", "=", "list", "(", "\n", "chain", ".", "from_iterable", "(", "\n", "[", "\n", "string_matmul", "(", "u", "[", "1", ":", "]", ",", "du", "[", "1", ":", "]", ")", "\n", "for", "u", ",", "du", "in", "product", "(", "poly_list", ",", "deriv_list", ")", "\n", "]", "\n", ")", "\n", ")", "# calculate all unique combinations of derivatives", "\n", "theta", "=", "theta_uv", "+", "theta_dudv", "+", "theta_udu", "\n", "", "return", "theta", "\n", "", ""]], "home.repos.pwc.inspect_result.PhIMaL_DeePyMoD.utils.logger.Logger.__init__": [[9, 20], ["torch.utils.tensorboard.SummaryWriter", "logger.Logger.writer.get_logdir"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "exp_ID", ",", "log_dir", ")", ":", "\n", "        ", "\"\"\"Log the training process of Deepymod.\n        Args:\n            exp_ID (str): name or ID of the this experiment\n            log_dir (str): directory to save the log files to disk.\n\n        \"\"\"", "\n", "self", ".", "writer", "=", "SummaryWriter", "(", "\n", "comment", "=", "exp_ID", ",", "log_dir", "=", "log_dir", ",", "max_queue", "=", "5", ",", "flush_secs", "=", "10", "\n", ")", "\n", "self", ".", "log_dir", "=", "self", ".", "writer", ".", "get_logdir", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.PhIMaL_DeePyMoD.utils.logger.Logger.__call__": [[21, 46], ["torch.sum", "logger.Logger.update_tensorboard", "logger.Logger.update_terminal", "torch.abs", "torch.cat"], "methods", ["home.repos.pwc.inspect_result.PhIMaL_DeePyMoD.utils.logger.Logger.update_tensorboard", "home.repos.pwc.inspect_result.PhIMaL_DeePyMoD.utils.logger.Logger.update_terminal"], ["", "def", "__call__", "(", "\n", "self", ",", "\n", "iteration", ",", "\n", "loss", ",", "\n", "MSE", ",", "\n", "Reg", ",", "\n", "constraint_coeffs", ",", "\n", "unscaled_constraint_coeffs", ",", "\n", "estimator_coeffs", ",", "\n", "**", "kwargs", ",", "\n", ")", ":", "\n", "        ", "l1_norm", "=", "torch", ".", "sum", "(", "torch", ".", "abs", "(", "torch", ".", "cat", "(", "constraint_coeffs", ",", "dim", "=", "1", ")", ")", ",", "dim", "=", "0", ")", "\n", "\n", "self", ".", "update_tensorboard", "(", "\n", "iteration", ",", "\n", "loss", ",", "\n", "MSE", ",", "\n", "Reg", ",", "\n", "l1_norm", ",", "\n", "constraint_coeffs", ",", "\n", "unscaled_constraint_coeffs", ",", "\n", "estimator_coeffs", ",", "\n", "**", "kwargs", ",", "\n", ")", "\n", "self", ".", "update_terminal", "(", "iteration", ",", "MSE", ",", "Reg", ",", "l1_norm", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.PhIMaL_DeePyMoD.utils.logger.Logger.update_tensorboard": [[47, 129], ["logger.Logger.writer.add_scalar", "logger.Logger.writer.add_scalars", "logger.Logger.writer.add_scalars", "logger.Logger.writer.add_scalars", "enumerate", "kwargs.items", "zip", "logger.Logger.writer.add_scalars", "logger.Logger.writer.add_scalars", "logger.Logger.writer.add_scalars", "value.numel", "logger.Logger.writer.add_scalar", "logger.Logger.writer.add_scalars", "enumerate", "enumerate", "enumerate", "enumerate", "enumerate", "enumerate", "val.squeeze", "coeffs.squeeze", "unscaled_coeffs.squeeze", "estimator_coeffs.squeeze", "enumerate", "value.squeeze"], "methods", ["None"], ["", "def", "update_tensorboard", "(", "\n", "self", ",", "\n", "iteration", ",", "\n", "loss", ",", "\n", "loss_mse", ",", "\n", "loss_reg", ",", "\n", "loss_l1", ",", "\n", "constraint_coeff_vectors", ",", "\n", "unscaled_constraint_coeff_vectors", ",", "\n", "estimator_coeff_vectors", ",", "\n", "**", "kwargs", ",", "\n", ")", ":", "\n", "        ", "\"\"\"Write the current state of training to Tensorboard\n        Args:\n            iteration (int): iteration number\n            loss (float): loss value\n            loss_mse (float): loss of the Mean Squared Error term\n            loss_reg (float): loss of the regularization term\n            loss_l1 (float): loss of the L1 penalty term\n            constraint_coeff_vectors (np.array): vector with constraint coefficients\n            unscaled_constraint_coeff_vectors (np.array): unscaled vector with constraint coefficients\n            estimator_coeff_vectors (np.array): coefficients as computed by the estimator.\n        \"\"\"", "\n", "# Costs and coeff vectors", "\n", "self", ".", "writer", ".", "add_scalar", "(", "\"loss/loss\"", ",", "loss", ",", "iteration", ")", "\n", "self", ".", "writer", ".", "add_scalars", "(", "\n", "\"loss/mse\"", ",", "\n", "{", "f\"output_{idx}\"", ":", "val", "for", "idx", ",", "val", "in", "enumerate", "(", "loss_mse", ")", "}", ",", "\n", "iteration", ",", "\n", ")", "\n", "self", ".", "writer", ".", "add_scalars", "(", "\n", "\"loss/reg\"", ",", "\n", "{", "f\"output_{idx}\"", ":", "val", "for", "idx", ",", "val", "in", "enumerate", "(", "loss_reg", ")", "}", ",", "\n", "iteration", ",", "\n", ")", "\n", "self", ".", "writer", ".", "add_scalars", "(", "\n", "\"loss/l1\"", ",", "\n", "{", "f\"output_{idx}\"", ":", "val", "for", "idx", ",", "val", "in", "enumerate", "(", "loss_l1", ")", "}", ",", "\n", "iteration", ",", "\n", ")", "\n", "\n", "for", "output_idx", ",", "(", "coeffs", ",", "unscaled_coeffs", ",", "estimator_coeffs", ")", "in", "enumerate", "(", "\n", "zip", "(", "\n", "constraint_coeff_vectors", ",", "\n", "unscaled_constraint_coeff_vectors", ",", "\n", "estimator_coeff_vectors", ",", "\n", ")", "\n", ")", ":", "\n", "            ", "self", ".", "writer", ".", "add_scalars", "(", "\n", "f\"coeffs/output_{output_idx}\"", ",", "\n", "{", "f\"coeff_{idx}\"", ":", "val", "for", "idx", ",", "val", "in", "enumerate", "(", "coeffs", ".", "squeeze", "(", ")", ")", "}", ",", "\n", "iteration", ",", "\n", ")", "\n", "self", ".", "writer", ".", "add_scalars", "(", "\n", "f\"unscaled_coeffs/output_{output_idx}\"", ",", "\n", "{", "\n", "f\"coeff_{idx}\"", ":", "val", "\n", "for", "idx", ",", "val", "in", "enumerate", "(", "unscaled_coeffs", ".", "squeeze", "(", ")", ")", "\n", "}", ",", "\n", "iteration", ",", "\n", ")", "\n", "self", ".", "writer", ".", "add_scalars", "(", "\n", "f\"estimator_coeffs/output_{output_idx}\"", ",", "\n", "{", "\n", "f\"coeff_{idx}\"", ":", "val", "\n", "for", "idx", ",", "val", "in", "enumerate", "(", "estimator_coeffs", ".", "squeeze", "(", ")", ")", "\n", "}", ",", "\n", "iteration", ",", "\n", ")", "\n", "\n", "# Writing remaining kwargs", "\n", "", "for", "key", ",", "value", "in", "kwargs", ".", "items", "(", ")", ":", "\n", "            ", "if", "value", ".", "numel", "(", ")", "==", "1", ":", "\n", "                ", "self", ".", "writer", ".", "add_scalar", "(", "f\"remaining/{key}\"", ",", "value", ",", "iteration", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "writer", ".", "add_scalars", "(", "\n", "f\"remaining/{key}\"", ",", "\n", "{", "\n", "f\"val_{idx}\"", ":", "val", ".", "squeeze", "(", ")", "\n", "for", "idx", ",", "val", "in", "enumerate", "(", "value", ".", "squeeze", "(", ")", ")", "\n", "}", ",", "\n", "iteration", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.PhIMaL_DeePyMoD.utils.logger.Logger.update_terminal": [[131, 137], ["sys.stdout.write", "sys.stdout.flush", "torch.sum().item", "torch.sum().item", "torch.sum().item", "torch.sum", "torch.sum", "torch.sum"], "methods", ["None"], ["", "", "", "def", "update_terminal", "(", "self", ",", "iteration", ",", "MSE", ",", "Reg", ",", "L1", ")", ":", "\n", "        ", "\"\"\"Prints and updates progress of training cycle in command line.\"\"\"", "\n", "sys", ".", "stdout", ".", "write", "(", "\n", "f\"\\r{iteration:>6}  MSE: {torch.sum(MSE).item():>8.2e}  Reg: {torch.sum(Reg).item():>8.2e}  L1: {torch.sum(L1).item():>8.2e} \"", "\n", ")", "\n", "sys", ".", "stdout", ".", "flush", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.PhIMaL_DeePyMoD.utils.logger.Logger.close": [[138, 147], ["print", "logger.Logger.writer.flush", "logger.Logger.writer.close", "torch.save", "model.state_dict"], "methods", ["home.repos.pwc.inspect_result.PhIMaL_DeePyMoD.utils.logger.Logger.close"], ["", "def", "close", "(", "self", ",", "model", ")", ":", "\n", "        ", "\"\"\"Close the Tensorboard writer\"\"\"", "\n", "print", "(", "\"Algorithm converged. Writing model to disk.\"", ")", "\n", "self", ".", "writer", ".", "flush", "(", ")", "# flush remaining stuff to disk", "\n", "self", ".", "writer", ".", "close", "(", ")", "# close writer", "\n", "\n", "# Save model", "\n", "model_path", "=", "self", ".", "log_dir", "+", "\"model.pt\"", "\n", "torch", ".", "save", "(", "model", ".", "state_dict", "(", ")", ",", "model_path", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.PhIMaL_DeePyMoD.model.deepmod.Constraint.__init__": [[18, 22], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.PhIMaL_DeePyMoD.data.base.Loader.__init__"], ["    ", "def", "__init__", "(", "self", ")", "->", "None", ":", "\n", "        ", "\"\"\"Abstract baseclass for the constraint module.\"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "sparsity_masks", ":", "TensorList", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.PhIMaL_DeePyMoD.model.deepmod.Constraint.forward": [[23, 57], ["deepmod.Constraint.apply_mask", "deepmod.Constraint.fit", "torch.ones().to", "torch.ones().to", "torch.ones().to", "torch.ones().to", "deepmod.Constraint.map_coeffs", "zip", "torch.ones", "torch.ones", "torch.ones", "torch.ones"], "methods", ["home.repos.pwc.inspect_result.PhIMaL_DeePyMoD.model.deepmod.Constraint.apply_mask", "home.repos.pwc.inspect_result.PhIMaL_DeePyMoD.model.constraint.Ridge.fit", "home.repos.pwc.inspect_result.PhIMaL_DeePyMoD.model.deepmod.Constraint.map_coeffs"], ["", "def", "forward", "(", "self", ",", "input", ":", "Tuple", "[", "TensorList", ",", "TensorList", "]", ")", "->", "TensorList", ":", "\n", "        ", "\"\"\"The forward pass of the constraint module applies the sparsity mask to the\n        feature matrix theta, and then calculates the coefficients according to the\n        method in the child.\n\n        Args:\n            input (Tuple[TensorList, TensorList]): (time_derivs, library) tuple of size\n                    ([(n_samples, 1) X n_outputs], [(n_samples, n_features) x n_outputs]).\n        Returns:\n            coeff_vectors (TensorList): List with coefficient vectors of size ([(n_features, 1) x n_outputs])\n        \"\"\"", "\n", "\n", "time_derivs", ",", "thetas", "=", "input", "\n", "\n", "if", "self", ".", "sparsity_masks", "is", "None", ":", "\n", "            ", "self", ".", "sparsity_masks", "=", "[", "\n", "torch", ".", "ones", "(", "theta", ".", "shape", "[", "1", "]", ",", "dtype", "=", "torch", ".", "bool", ")", ".", "to", "(", "theta", ".", "device", ")", "\n", "for", "theta", "in", "thetas", "\n", "]", "\n", "\n", "", "sparse_thetas", "=", "self", ".", "apply_mask", "(", "thetas", ",", "self", ".", "sparsity_masks", ")", "\n", "\n", "# Constraint grad. desc style doesn't allow to change shape, so we return full coeff", "\n", "# and multiply by mask to set zeros. For least squares-style, we need to put in", "\n", "# zeros in the right spot to get correct shape.", "\n", "coeff_vectors", "=", "self", ".", "fit", "(", "sparse_thetas", ",", "time_derivs", ")", "\n", "self", ".", "coeff_vectors", "=", "[", "\n", "self", ".", "map_coeffs", "(", "mask", ",", "coeff", ")", "\n", "if", "mask", ".", "shape", "[", "0", "]", "!=", "coeff", ".", "shape", "[", "0", "]", "\n", "else", "coeff", "*", "mask", "[", ":", ",", "None", "]", "\n", "for", "mask", ",", "coeff", "in", "zip", "(", "self", ".", "sparsity_masks", ",", "coeff_vectors", ")", "\n", "]", "\n", "\n", "return", "self", ".", "coeff_vectors", "\n", "\n"]], "home.repos.pwc.inspect_result.PhIMaL_DeePyMoD.model.deepmod.Constraint.apply_mask": [[58, 70], ["zip"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "apply_mask", "(", "thetas", ":", "TensorList", ",", "masks", ":", "TensorList", ")", "->", "TensorList", ":", "\n", "        ", "\"\"\"Applies the sparsity mask to the feature (library) matrix.\n\n        Args:\n            thetas (TensorList): List of all library matrices of size [(n_samples, n_features) x n_outputs].\n\n        Returns:\n            TensorList: The sparse version of the library matrices of size [(n_samples, n_active_features) x n_outputs].\n        \"\"\"", "\n", "sparse_thetas", "=", "[", "theta", "[", ":", ",", "mask", "]", "for", "theta", ",", "mask", "in", "zip", "(", "thetas", ",", "masks", ")", "]", "\n", "return", "sparse_thetas", "\n", "\n"]], "home.repos.pwc.inspect_result.PhIMaL_DeePyMoD.model.deepmod.Constraint.map_coeffs": [[71, 89], ["torch.zeros().to().masked_scatter_", "torch.zeros().to().masked_scatter_", "torch.zeros().to().masked_scatter_", "torch.zeros().to().masked_scatter_", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "map_coeffs", "(", "mask", ":", "torch", ".", "Tensor", ",", "coeff_vector", ":", "torch", ".", "Tensor", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\"Places the coeff_vector components in the true positions of the mask.\n        I.e. maps ((0, 1, 1, 0), (0.5, 1.5)) -> (0, 0.5, 1.5, 0).\n\n        Args:\n            mask (torch.Tensor): Boolean mask describing active components.\n            coeff_vector (torch.Tensor): Vector with active-components.\n\n        Returns:\n            mapped_coeffs (torch.Tensor): mapped coefficients.\n        \"\"\"", "\n", "mapped_coeffs", "=", "(", "\n", "torch", ".", "zeros", "(", "(", "mask", ".", "shape", "[", "0", "]", ",", "1", ")", ")", "\n", ".", "to", "(", "coeff_vector", ".", "device", ")", "\n", ".", "masked_scatter_", "(", "mask", "[", ":", ",", "None", "]", ",", "coeff_vector", ")", "\n", ")", "\n", "return", "mapped_coeffs", "\n", "\n"]], "home.repos.pwc.inspect_result.PhIMaL_DeePyMoD.model.deepmod.Constraint.fit": [[90, 103], ["None"], "methods", ["None"], ["", "@", "abstractmethod", "\n", "def", "fit", "(", "self", ",", "sparse_thetas", ":", "TensorList", ",", "time_derivs", ":", "TensorList", ")", "->", "TensorList", ":", "\n", "        ", "\"\"\"Abstract method. Specific method should return the coefficients as calculated from the sparse feature\n        matrices and temporal derivatives.\n\n        Args:\n            sparse_thetas (TensorList): List containing the sparse feature tensors of size (n_samples, n_active_features).\n            time_derivs (TensorList): List containing the time derivatives of size (n_samples, n_outputs).\n\n        Returns:\n            (TensorList): Calculated coefficients of size (n_active_features, n_outputs).\n        \"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.PhIMaL_DeePyMoD.model.deepmod.Estimator.__init__": [[106, 110], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.PhIMaL_DeePyMoD.data.base.Loader.__init__"], ["    ", "def", "__init__", "(", "self", ")", "->", "None", ":", "\n", "        ", "\"\"\"Abstract baseclass for the sparse estimator module.\"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "coeff_vectors", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.PhIMaL_DeePyMoD.model.deepmod.Estimator.forward": [[111, 148], ["torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.tensor().squeeze().to", "torch.tensor().squeeze().to", "torch.tensor().squeeze().to", "torch.tensor().squeeze().to", "deepmod.Estimator.fit", "zip", "time_deriv.squeeze", "torch.tensor().squeeze", "torch.tensor().squeeze", "torch.tensor().squeeze", "torch.tensor().squeeze", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm"], "methods", ["home.repos.pwc.inspect_result.PhIMaL_DeePyMoD.model.constraint.Ridge.fit"], ["", "def", "forward", "(", "self", ",", "thetas", ":", "TensorList", ",", "time_derivs", ":", "TensorList", ")", "->", "TensorList", ":", "\n", "        ", "\"\"\"The forward pass of the sparse estimator module first normalizes the library matrices\n        and time derivatives by dividing each column (i.e. feature) by their l2 norm, than calculate the coefficient vectors\n        according to the sparse estimation algorithm supplied by the child and finally returns the sparsity\n        mask (i.e. which terms are active) based on these coefficients.\n\n        Args:\n            thetas (TensorList): List containing the sparse feature tensors of size  [(n_samples, n_active_features) x n_outputs].\n            time_derivs (TensorList): List containing the time derivatives of size  [(n_samples, 1) x n_outputs].\n\n        Returns:\n            (TensorList): List containting the sparsity masks of a boolean type and size  [(n_samples, n_features) x n_outputs].\n        \"\"\"", "\n", "\n", "# we first normalize theta and the time deriv", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "normed_time_derivs", "=", "[", "\n", "(", "time_deriv", "/", "torch", ".", "norm", "(", "time_deriv", ")", ")", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "for", "time_deriv", "in", "time_derivs", "\n", "]", "\n", "normed_thetas", "=", "[", "\n", "(", "theta", "/", "torch", ".", "norm", "(", "theta", ",", "dim", "=", "0", ",", "keepdim", "=", "True", ")", ")", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "for", "theta", "in", "thetas", "\n", "]", "\n", "\n", "", "self", ".", "coeff_vectors", "=", "[", "\n", "self", ".", "fit", "(", "theta", ",", "time_deriv", ".", "squeeze", "(", ")", ")", "[", ":", ",", "None", "]", "\n", "for", "theta", ",", "time_deriv", "in", "zip", "(", "normed_thetas", ",", "normed_time_derivs", ")", "\n", "]", "\n", "sparsity_masks", "=", "[", "\n", "torch", ".", "tensor", "(", "coeff_vector", "!=", "0.0", ",", "dtype", "=", "torch", ".", "bool", ")", "\n", ".", "squeeze", "(", ")", "\n", ".", "to", "(", "thetas", "[", "0", "]", ".", "device", ")", "# move to gpu if required", "\n", "for", "coeff_vector", "in", "self", ".", "coeff_vectors", "\n", "]", "\n", "\n", "return", "sparsity_masks", "\n", "\n"]], "home.repos.pwc.inspect_result.PhIMaL_DeePyMoD.model.deepmod.Estimator.fit": [[149, 162], ["None"], "methods", ["None"], ["", "@", "abstractmethod", "\n", "def", "fit", "(", "self", ",", "X", ":", "np", ".", "ndarray", ",", "y", ":", "np", ".", "ndarray", ")", "->", "np", ".", "ndarray", ":", "\n", "        ", "\"\"\"Abstract method. Specific method should compute the coefficient based on feature matrix X and observations y.\n        Note that we expect X and y to be numpy arrays, i.e. this module is non-differentiable.\n\n        Args:\n            x (np.ndarray): Feature matrix of size (n_samples, n_features)\n            y (np.ndarray): observations of size (n_samples, n_outputs)\n\n        Returns:\n            (np.ndarray): Coefficients of size (n_samples, n_outputs)\n        \"\"\"", "\n", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.PhIMaL_DeePyMoD.model.deepmod.Library.__init__": [[165, 169], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.PhIMaL_DeePyMoD.data.base.Loader.__init__"], ["    ", "def", "__init__", "(", "self", ")", "->", "None", ":", "\n", "        ", "\"\"\"Abstract baseclass for the library module.\"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "norms", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.PhIMaL_DeePyMoD.model.deepmod.Library.forward": [[170, 190], ["deepmod.Library.library", "zip", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm"], "methods", ["home.repos.pwc.inspect_result.PhIMaL_DeePyMoD.model.library.Library2D.library"], ["", "def", "forward", "(", "\n", "self", ",", "input", ":", "Tuple", "[", "torch", ".", "Tensor", ",", "torch", ".", "Tensor", "]", "\n", ")", "->", "Tuple", "[", "TensorList", ",", "TensorList", "]", ":", "\n", "        ", "\"\"\"Compute the library (time derivatives and thetas) from a given dataset. Also calculates the norms\n        of these, later used to calculate the normalized coefficients.\n\n        Args:\n            input (Tuple[TensorList, TensorList]): (prediction, data) tuple of size ((n_samples, n_outputs), (n_samples, n_dims))\n\n        Returns:\n            Tuple[TensorList, TensorList]: Temporal derivative and libraries of size ([(n_samples, 1) x n_outputs]), [(n_samples, n_features)x n_outputs])\n        \"\"\"", "\n", "time_derivs", ",", "thetas", "=", "self", ".", "library", "(", "input", ")", "\n", "self", ".", "norms", "=", "[", "\n", "(", "torch", ".", "norm", "(", "time_deriv", ")", "/", "torch", ".", "norm", "(", "theta", ",", "dim", "=", "0", ",", "keepdim", "=", "True", ")", ")", "\n", ".", "detach", "(", ")", "\n", ".", "squeeze", "(", ")", "\n", "for", "time_deriv", ",", "theta", "in", "zip", "(", "time_derivs", ",", "thetas", ")", "\n", "]", "\n", "return", "time_derivs", ",", "thetas", "\n", "\n"]], "home.repos.pwc.inspect_result.PhIMaL_DeePyMoD.model.deepmod.Library.library": [[191, 205], ["None"], "methods", ["None"], ["", "@", "abstractmethod", "\n", "def", "library", "(", "\n", "self", ",", "input", ":", "Tuple", "[", "torch", ".", "Tensor", ",", "torch", ".", "Tensor", "]", "\n", ")", "->", "Tuple", "[", "TensorList", ",", "TensorList", "]", ":", "\n", "        ", "\"\"\"Abstract method. Specific method should calculate the temporal derivative and feature matrices.\n        These should be a list; one temporal derivative and feature matrix per output.\n\n        Args:\n        input (Tuple[TensorList, TensorList]): (prediction, data) tuple of size ((n_samples, n_outputs), (n_samples, n_dims))\n\n        Returns:\n        Tuple[TensorList, TensorList]: Temporal derivative and libraries of size ([(n_samples, 1) x n_outputs]), [(n_samples, n_features)x n_outputs])\n        \"\"\"", "\n", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.PhIMaL_DeePyMoD.model.deepmod.DeepMoD.__init__": [[208, 230], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.PhIMaL_DeePyMoD.data.base.Loader.__init__"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "function_approximator", ":", "torch", ".", "nn", ".", "Sequential", ",", "\n", "library", ":", "Library", ",", "\n", "sparsity_estimator", ":", "Estimator", ",", "\n", "constraint", ":", "Constraint", ",", "\n", ")", "->", "None", ":", "\n", "        ", "\"\"\"The DeepMoD class integrates the various buiding blocks into one module. The function approximator approximates the data,\n        the library than builds a feature matrix from its output and the constraint constrains these. The sparsity estimator is called\n        during training to update the sparsity mask (i.e. which terms the constraint is allowed to use.)\n\n        Args:\n            function_approximator (torch.nn.Sequential): [description]\n            library (Library): [description]\n            sparsity_estimator (Estimator): [description]\n            constraint (Constraint): [description]\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "func_approx", "=", "function_approximator", "\n", "self", ".", "library", "=", "library", "\n", "self", ".", "sparse_estimator", "=", "sparsity_estimator", "\n", "self", ".", "constraint", "=", "constraint", "\n", "\n"]], "home.repos.pwc.inspect_result.PhIMaL_DeePyMoD.model.deepmod.DeepMoD.forward": [[231, 251], ["deepmod.DeepMoD.func_approx", "deepmod.DeepMoD.library", "deepmod.DeepMoD.constraint"], "methods", ["home.repos.pwc.inspect_result.PhIMaL_DeePyMoD.model.library.Library2D.library"], ["", "def", "forward", "(", "\n", "self", ",", "input", ":", "torch", ".", "Tensor", "\n", ")", "->", "Tuple", "[", "torch", ".", "Tensor", ",", "TensorList", ",", "TensorList", "]", ":", "\n", "        ", "\"\"\"The forward pass approximates the data, builds the time derivative and feature matrices\n        and applies the constraint.\n\n        It returns the prediction of the network, the time derivatives and the feature matrices.\n\n        Args:\n            input (torch.Tensor):  Tensor of shape (n_samples, n_outputs) containing the coordinates, first column should be the time coordinate.\n\n        Returns:\n            Tuple[torch.Tensor, TensorList, TensorList]: The prediction, time derivatives and and feature matrices of respective sizes\n                                                       ((n_samples, n_outputs), [(n_samples, 1) x n_outputs]), [(n_samples, n_features) x n_outputs])\n\n        \"\"\"", "\n", "prediction", ",", "coordinates", "=", "self", ".", "func_approx", "(", "input", ")", "\n", "time_derivs", ",", "thetas", "=", "self", ".", "library", "(", "(", "prediction", ",", "coordinates", ")", ")", "\n", "coeff_vectors", "=", "self", ".", "constraint", "(", "(", "time_derivs", ",", "thetas", ")", ")", "\n", "return", "prediction", ",", "time_derivs", ",", "thetas", "\n", "\n"]], "home.repos.pwc.inspect_result.PhIMaL_DeePyMoD.model.deepmod.DeepMoD.sparsity_masks": [[252, 256], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "sparsity_masks", "(", "self", ")", ":", "\n", "        ", "\"\"\"Returns the sparsity masks which contain the active terms.\"\"\"", "\n", "return", "self", ".", "constraint", ".", "sparsity_masks", "\n", "\n"]], "home.repos.pwc.inspect_result.PhIMaL_DeePyMoD.model.deepmod.DeepMoD.estimator_coeffs": [[257, 265], ["None"], "methods", ["None"], ["", "def", "estimator_coeffs", "(", "self", ")", "->", "TensorList", ":", "\n", "        ", "\"\"\"Calculate the coefficients as estimated by the sparse estimator.\n\n        Returns:\n            (TensorList): List of coefficients of size [(n_features, 1) x n_outputs]\n        \"\"\"", "\n", "coeff_vectors", "=", "self", ".", "sparse_estimator", ".", "coeff_vectors", "\n", "return", "coeff_vectors", "\n", "\n"]], "home.repos.pwc.inspect_result.PhIMaL_DeePyMoD.model.deepmod.DeepMoD.constraint_coeffs": [[266, 290], ["zip", "zip"], "methods", ["None"], ["", "def", "constraint_coeffs", "(", "self", ",", "scaled", "=", "False", ",", "sparse", "=", "False", ")", "->", "TensorList", ":", "\n", "        ", "\"\"\"Calculate the coefficients as estimated by the constraint.\n\n        Args:\n            scaled (bool): Determine whether or not the coefficients should be normalized\n            sparse (bool): Whether to apply the sparsity mask to the coefficients.\n\n        Returns:\n            (TensorList): List of coefficients of size [(n_features, 1) x n_outputs]\n        \"\"\"", "\n", "coeff_vectors", "=", "self", ".", "constraint", ".", "coeff_vectors", "\n", "if", "scaled", ":", "\n", "            ", "coeff_vectors", "=", "[", "\n", "coeff", "/", "norm", "[", ":", ",", "None", "]", "\n", "for", "coeff", ",", "norm", ",", "mask", "in", "zip", "(", "\n", "coeff_vectors", ",", "self", ".", "library", ".", "norms", ",", "self", ".", "sparsity_masks", "\n", ")", "\n", "]", "\n", "", "if", "sparse", ":", "\n", "            ", "coeff_vectors", "=", "[", "\n", "sparsity_mask", "[", ":", ",", "None", "]", "*", "coeff", "\n", "for", "sparsity_mask", ",", "coeff", "in", "zip", "(", "self", ".", "sparsity_masks", ",", "coeff_vectors", ")", "\n", "]", "\n", "", "return", "coeff_vectors", "\n", "", "", ""]], "home.repos.pwc.inspect_result.PhIMaL_DeePyMoD.model.sparse_estimators.Base.__init__": [[21, 31], ["deepmod.Estimator.__init__", "sparse_estimators.Base.estimator.set_params"], "methods", ["home.repos.pwc.inspect_result.PhIMaL_DeePyMoD.data.base.Loader.__init__"], ["    ", "def", "__init__", "(", "self", ",", "estimator", ":", "BaseEstimator", ")", "->", "None", ":", "\n", "        ", "\"\"\"Basic sparse estimator class; simply a wrapper around the supplied sk-learn compatible estimator.\n\n        Args:\n            estimator (BaseEstimator): Sci-kit learn estimator.\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "estimator", "=", "estimator", "\n", "self", ".", "estimator", ".", "set_params", "(", "\n", "fit_intercept", "=", "False", "\n", ")", "# Library contains offset so turn off the intercept", "\n"]], "home.repos.pwc.inspect_result.PhIMaL_DeePyMoD.model.sparse_estimators.Base.fit": [[33, 45], ["sparse_estimators.Base.estimator.fit"], "methods", ["home.repos.pwc.inspect_result.PhIMaL_DeePyMoD.model.constraint.Ridge.fit"], ["", "def", "fit", "(", "self", ",", "X", ":", "np", ".", "ndarray", ",", "y", ":", "np", ".", "ndarray", ")", "->", "np", ".", "ndarray", ":", "\n", "        ", "\"\"\"Returns an array with the coefficient verctor after sparsity estimation.\n\n        Args:\n            X (np.ndarray): Training input data of shape (n_samples, n_features).\n            y (np.ndarray): Training target data of shape (n_samples, n_outputs).\n\n        Returns:\n            np.ndarray: Coefficient vector (n_features, n_outputs).\n        \"\"\"", "\n", "coeffs", "=", "self", ".", "estimator", ".", "fit", "(", "X", ",", "y", ")", ".", "coef_", "\n", "return", "coeffs", "\n", "\n"]], "home.repos.pwc.inspect_result.PhIMaL_DeePyMoD.model.sparse_estimators.Threshold.__init__": [[48, 65], ["sklearn.linear_model.LassoCV", "deepmod.Estimator.__init__", "sparse_estimators.Threshold.estimator.set_params"], "methods", ["home.repos.pwc.inspect_result.PhIMaL_DeePyMoD.data.base.Loader.__init__"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "threshold", ":", "float", "=", "0.1", ",", "\n", "estimator", ":", "BaseEstimator", "=", "LassoCV", "(", "cv", "=", "5", ",", "fit_intercept", "=", "False", ")", ",", "\n", ")", "->", "None", ":", "\n", "        ", "\"\"\"Performs additional thresholding on coefficient result from supplied estimator.\n\n        Args:\n            threshold (float, optional): Value of the threshold above which the terms are selected. Defaults to 0.1.\n            estimator (BaseEstimator, optional): Sparsity estimator. Defaults to LassoCV(cv=5, fit_intercept=False).\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "estimator", "=", "estimator", "\n", "self", ".", "threshold", "=", "threshold", "\n", "\n", "# Library contains offset so turn off the intercept", "\n", "self", ".", "estimator", ".", "set_params", "(", "fit_intercept", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.PhIMaL_DeePyMoD.model.sparse_estimators.Threshold.fit": [[66, 80], ["sparse_estimators.Threshold.estimator.fit", "numpy.abs"], "methods", ["home.repos.pwc.inspect_result.PhIMaL_DeePyMoD.model.constraint.Ridge.fit"], ["", "def", "fit", "(", "self", ",", "X", ":", "np", ".", "ndarray", ",", "y", ":", "np", ".", "ndarray", ")", "->", "np", ".", "ndarray", ":", "\n", "        ", "\"\"\"Returns an array with the coefficient verctor after sparsity estimation.\n\n        Args:\n            X (np.ndarray): Training input data of shape (n_samples, n_features).\n            y (np.ndarray): Training target data of shape (n_samples, n_outputs).\n\n        Returns:\n            np.ndarray: Coefficient vector (n_features, n_outputs).\n        \"\"\"", "\n", "coeffs", "=", "self", ".", "estimator", ".", "fit", "(", "X", ",", "y", ")", ".", "coef_", "\n", "coeffs", "[", "np", ".", "abs", "(", "coeffs", ")", "<", "self", ".", "threshold", "]", "=", "0.0", "\n", "\n", "return", "coeffs", "\n", "\n"]], "home.repos.pwc.inspect_result.PhIMaL_DeePyMoD.model.sparse_estimators.Clustering.__init__": [[83, 97], ["sklearn.linear_model.LassoCV", "deepmod.Estimator.__init__", "sklearn.cluster.KMeans", "sparse_estimators.Clustering.estimator.set_params"], "methods", ["home.repos.pwc.inspect_result.PhIMaL_DeePyMoD.data.base.Loader.__init__"], ["    ", "def", "__init__", "(", "\n", "self", ",", "estimator", ":", "BaseEstimator", "=", "LassoCV", "(", "cv", "=", "5", ",", "fit_intercept", "=", "False", ")", "\n", ")", "->", "None", ":", "\n", "        ", "\"\"\"Performs additional thresholding by Kmeans-clustering on coefficient result from estimator.\n\n        Args:\n            estimator (BaseEstimator, optional): Estimator class. Defaults to LassoCV(cv=5, fit_intercept=False).\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "estimator", "=", "estimator", "\n", "self", ".", "kmeans", "=", "KMeans", "(", "n_clusters", "=", "2", ")", "\n", "\n", "# Library contains offset so turn off the intercept", "\n", "self", ".", "estimator", ".", "set_params", "(", "fit_intercept", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.PhIMaL_DeePyMoD.model.sparse_estimators.Clustering.fit": [[98, 118], ["sparse_estimators.Clustering.kmeans.fit_predict().astype", "numpy.argmax", "sparse_estimators.Clustering.astype", "numpy.abs", "sparse_estimators.Clustering.estimator.fit", "sparse_estimators.Clustering.kmeans.fit_predict", "numpy.abs"], "methods", ["home.repos.pwc.inspect_result.PhIMaL_DeePyMoD.model.constraint.Ridge.fit"], ["", "def", "fit", "(", "self", ",", "X", ":", "np", ".", "ndarray", ",", "y", ":", "np", ".", "ndarray", ")", "->", "np", ".", "ndarray", ":", "\n", "        ", "\"\"\"Returns an array with the coefficient verctor after sparsity estimation.\n\n        Args:\n            X (np.ndarray): Training input data of shape (n_samples, n_features).\n            y (np.ndarray): Training target data of shape (n_samples, n_outputs).\n\n        Returns:\n            np.ndarray: Coefficient vector (n_features, n_outputs).\n        \"\"\"", "\n", "coeffs", "=", "self", ".", "estimator", ".", "fit", "(", "X", ",", "y", ")", ".", "coef_", "[", ":", ",", "None", "]", "# sklearn returns 1D", "\n", "clusters", "=", "self", ".", "kmeans", ".", "fit_predict", "(", "np", ".", "abs", "(", "coeffs", ")", ")", ".", "astype", "(", "np", ".", "bool", ")", "\n", "\n", "# make sure terms to keep are 1 and to remove are 0", "\n", "max_idx", "=", "np", ".", "argmax", "(", "np", ".", "abs", "(", "coeffs", ")", ")", "\n", "if", "clusters", "[", "max_idx", "]", "!=", "1", ":", "\n", "            ", "clusters", "=", "~", "clusters", "\n", "\n", "", "coeffs", "=", "clusters", ".", "astype", "(", "np", ".", "float32", ")", "\n", "return", "coeffs", "\n", "\n"]], "home.repos.pwc.inspect_result.PhIMaL_DeePyMoD.model.sparse_estimators.PDEFIND.__init__": [[121, 131], ["deepmod.Estimator.__init__"], "methods", ["home.repos.pwc.inspect_result.PhIMaL_DeePyMoD.data.base.Loader.__init__"], ["    ", "def", "__init__", "(", "self", ",", "lam", ":", "float", "=", "1e-3", ",", "dtol", ":", "float", "=", "0.1", ")", "->", "None", ":", "\n", "        ", "\"\"\"Implements PDEFIND as a sparse estimator.\n\n        Args:\n            lam (float, optional): Magnitude of the L2 regularization. Defaults to 1e-3.\n            dtol (float, optional): Initial stepsize for the search of the thresholdDefaults to 0.1.\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "lam", "=", "lam", "\n", "self", ".", "dtol", "=", "dtol", "\n", "\n"]], "home.repos.pwc.inspect_result.PhIMaL_DeePyMoD.model.sparse_estimators.PDEFIND.fit": [[132, 145], ["sparse_estimators.PDEFIND.TrainSTLSQ", "sparse_estimators.PDEFIND.TrainSTLSQ"], "methods", ["home.repos.pwc.inspect_result.PhIMaL_DeePyMoD.model.sparse_estimators.PDEFIND.TrainSTLSQ", "home.repos.pwc.inspect_result.PhIMaL_DeePyMoD.model.sparse_estimators.PDEFIND.TrainSTLSQ"], ["", "def", "fit", "(", "self", ",", "X", ":", "np", ".", "ndarray", ",", "y", ":", "np", ".", "ndarray", ")", "->", "np", ".", "ndarray", ":", "\n", "        ", "\"\"\"Returns an array with the coefficient verctor after sparsity estimation.\n\n        Args:\n            X (np.ndarray): Training input data of shape (n_samples, n_features).\n            y (np.ndarray): Training target data of shape (n_samples, n_outputs).\n\n        Returns:\n            np.ndarray: Coefficient vector (n_features, n_outputs).\n        \"\"\"", "\n", "\n", "coeffs", "=", "PDEFIND", ".", "TrainSTLSQ", "(", "X", ",", "y", "[", ":", ",", "None", "]", ",", "self", ".", "lam", ",", "self", ".", "dtol", ")", "\n", "return", "coeffs", ".", "squeeze", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.PhIMaL_DeePyMoD.model.sparse_estimators.PDEFIND.TrainSTLSQ": [[146, 213], ["sklearn.model_selection.train_test_split", "pysindy.optimizers.STLSQ", "pysindy.optimizers.STLSQ.fit().predict", "numpy.arange", "pysindy.optimizers.STLSQ.set_params", "pysindy.optimizers.STLSQ.fit", "numpy.linalg.cond", "numpy.linalg.norm", "pysindy.optimizers.STLSQ.set_params", "pysindy.optimizers.STLSQ.fit().predict", "pysindy.optimizers.STLSQ.fit", "numpy.count_nonzero", "numpy.linalg.norm", "numpy.max", "pysindy.optimizers.STLSQ.fit", "numpy.count_nonzero", "numpy.all"], "methods", ["home.repos.pwc.inspect_result.PhIMaL_DeePyMoD.model.constraint.Ridge.fit", "home.repos.pwc.inspect_result.PhIMaL_DeePyMoD.model.constraint.Ridge.fit", "home.repos.pwc.inspect_result.PhIMaL_DeePyMoD.model.constraint.Ridge.fit"], ["", "@", "staticmethod", "\n", "def", "TrainSTLSQ", "(", "\n", "X", ":", "np", ".", "ndarray", ",", "\n", "y", ":", "np", ".", "ndarray", ",", "\n", "alpha", ":", "float", ",", "\n", "delta_threshold", ":", "float", ",", "\n", "max_iterations", ":", "int", "=", "100", ",", "\n", "test_size", ":", "float", "=", "0.2", ",", "\n", "random_state", ":", "int", "=", "0", ",", "\n", ")", "->", "np", ".", "ndarray", ":", "\n", "        ", "\"\"\"PDE-FIND sparsity selection algorithm. Based on method described by Rudy et al. (10.1126/sciadv.1602614).\n\n        Args:\n            X (np.ndarray): Training input data of shape (n_samples, n_features).\n            y (np.ndarray): Training target data of shape (n_samples, n_outputs).\n            alpha (float): Magnitude of the L2 regularization.\n            delta_threshold (float): Initial stepsize for the search of the threshold\n            max_iterations (int, optional): Maximum number of iterations. Defaults to 100.\n            test_size (float, optional): Fraction of the data that is assigned to the test-set. Defaults to 0.2.\n            random_state (int, optional): Defaults to 0.\n\n        Returns:\n            np.ndarray: Coefficient vector.\n        \"\"\"", "\n", "# Split data", "\n", "X_train", ",", "X_test", ",", "y_train", ",", "y_test", "=", "train_test_split", "(", "\n", "X", ",", "y", ",", "test_size", "=", "test_size", ",", "random_state", "=", "random_state", "\n", ")", "\n", "\n", "# Set up the initial tolerance l0 penalty and estimates", "\n", "l0", "=", "1e-3", "*", "np", ".", "linalg", ".", "cond", "(", "X", ")", "\n", "delta_t", "=", "delta_threshold", "# for interal use, can be updated", "\n", "\n", "# Initial estimate", "\n", "optimizer", "=", "STLSQ", "(", "\n", "threshold", "=", "0", ",", "alpha", "=", "0.0", ",", "fit_intercept", "=", "False", "\n", ")", "# Now similar to LSTSQ", "\n", "y_predict", "=", "optimizer", ".", "fit", "(", "X_train", ",", "y_train", ")", ".", "predict", "(", "X_test", ")", "\n", "min_loss", "=", "np", ".", "linalg", ".", "norm", "(", "y_predict", "-", "y_test", ",", "2", ")", "+", "l0", "*", "np", ".", "count_nonzero", "(", "\n", "optimizer", ".", "coef_", "\n", ")", "\n", "\n", "# Setting alpha and tolerance", "\n", "best_threshold", "=", "delta_t", "\n", "threshold", "=", "delta_t", "\n", "\n", "for", "iteration", "in", "np", ".", "arange", "(", "max_iterations", ")", ":", "\n", "            ", "optimizer", ".", "set_params", "(", "alpha", "=", "alpha", ",", "threshold", "=", "threshold", ")", "\n", "y_predict", "=", "optimizer", ".", "fit", "(", "X_train", ",", "y_train", ")", ".", "predict", "(", "X_test", ")", "\n", "loss", "=", "np", ".", "linalg", ".", "norm", "(", "y_predict", "-", "y_test", ",", "2", ")", "+", "l0", "*", "np", ".", "count_nonzero", "(", "\n", "optimizer", ".", "coef_", "\n", ")", "\n", "\n", "if", "(", "loss", "<=", "min_loss", ")", "and", "not", "(", "np", ".", "all", "(", "optimizer", ".", "coef_", "==", "0", ")", ")", ":", "\n", "                ", "min_loss", "=", "loss", "\n", "best_threshold", "=", "threshold", "\n", "threshold", "+=", "delta_threshold", "\n", "\n", "", "else", ":", "# if loss increases, we need to a) lower the current threshold and/or decrease step size", "\n", "                ", "new_lower_threshold", "=", "np", ".", "max", "(", "[", "0", ",", "threshold", "-", "2", "*", "delta_t", "]", ")", "\n", "delta_t", "=", "2", "*", "delta_t", "/", "(", "max_iterations", "-", "iteration", ")", "\n", "threshold", "=", "new_lower_threshold", "+", "delta_t", "\n", "\n", "", "", "optimizer", ".", "set_params", "(", "alpha", "=", "alpha", ",", "threshold", "=", "best_threshold", ")", "\n", "optimizer", ".", "fit", "(", "X_train", ",", "y_train", ")", "\n", "\n", "return", "optimizer", ".", "coef_", "\n", "", "", ""]], "home.repos.pwc.inspect_result.PhIMaL_DeePyMoD.model.library.Library1D.__init__": [[73, 92], ["deepmod.Library.__init__"], "methods", ["home.repos.pwc.inspect_result.PhIMaL_DeePyMoD.data.base.Loader.__init__"], ["    ", "def", "__init__", "(", "self", ",", "poly_order", ":", "int", ",", "diff_order", ":", "int", ")", "->", "None", ":", "\n", "        ", "\"\"\"Calculates the temporal derivative a library/feature matrix consisting of\n        1) polynomials up to order poly_order, i.e. u, u^2...\n        2) derivatives up to order diff_order, i.e. u_x, u_xx\n        3) cross terms of 1) and 2), i.e. $uu_x$, $u^2u_xx$\n\n        Order of terms is derivative first, i.e. [$1, u_x, u, uu_x, u^2, ...$]\n\n        Only works for 1D+1 data. Also works for multiple outputs but in that case doesn't calculate\n        polynomial and derivative cross terms.\n\n        Args:\n            poly_order (int): maximum order of the polynomial in the library\n            diff_order (int): maximum order of the differentials in the library\n        \"\"\"", "\n", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "poly_order", "=", "poly_order", "\n", "self", ".", "diff_order", "=", "diff_order", "\n", "\n"]], "home.repos.pwc.inspect_result.PhIMaL_DeePyMoD.model.library.Library1D.library": [[93, 150], ["numpy.arange", "library.library_deriv", "library.library_poly", "poly_list.append", "deriv_list.append", "time_deriv_list.append", "len", "torch.matmul().view", "functools.reduce", "torch.cat", "torch.cat", "torch.matmul", "torch.matmul().view", "itertools.combinations", "torch.matmul"], "methods", ["home.repos.pwc.inspect_result.PhIMaL_DeePyMoD.model.library.library_deriv", "home.repos.pwc.inspect_result.PhIMaL_DeePyMoD.model.library.library_poly"], ["", "def", "library", "(", "\n", "self", ",", "input", ":", "Tuple", "[", "torch", ".", "Tensor", ",", "torch", ".", "Tensor", "]", "\n", ")", "->", "Tuple", "[", "TensorList", ",", "TensorList", "]", ":", "\n", "        ", "\"\"\"Compute the temporal derivative and library for the given prediction at locations given by data.\n            Data should have t in first column, x in second.\n\n        Args:\n            input (Tuple[torch.Tensor, torch.Tensor]): A prediction u (n_samples, n_outputs) and spatiotemporal locations (n_samples, 2).\n\n        Returns:\n            Tuple[TensorList, TensorList]: The time derivatives [(n_samples, 1) x n_outputs] and the thetas [(n_samples, (poly_order + 1)(deriv_order + 1))]\n            computed from the library and data.\n        \"\"\"", "\n", "prediction", ",", "data", "=", "input", "\n", "poly_list", "=", "[", "]", "\n", "deriv_list", "=", "[", "]", "\n", "time_deriv_list", "=", "[", "]", "\n", "\n", "# Creating lists for all outputs", "\n", "for", "output", "in", "np", ".", "arange", "(", "prediction", ".", "shape", "[", "1", "]", ")", ":", "\n", "            ", "time_deriv", ",", "du", "=", "library_deriv", "(", "\n", "data", ",", "prediction", "[", ":", ",", "output", ":", "output", "+", "1", "]", ",", "self", ".", "diff_order", "\n", ")", "\n", "u", "=", "library_poly", "(", "prediction", "[", ":", ",", "output", ":", "output", "+", "1", "]", ",", "self", ".", "poly_order", ")", "\n", "\n", "poly_list", ".", "append", "(", "u", ")", "\n", "deriv_list", ".", "append", "(", "du", ")", "\n", "time_deriv_list", ".", "append", "(", "time_deriv", ")", "\n", "\n", "", "samples", "=", "time_deriv_list", "[", "0", "]", ".", "shape", "[", "0", "]", "\n", "total_terms", "=", "poly_list", "[", "0", "]", ".", "shape", "[", "1", "]", "*", "deriv_list", "[", "0", "]", ".", "shape", "[", "1", "]", "\n", "\n", "# Calculating theta", "\n", "if", "len", "(", "poly_list", ")", "==", "1", ":", "\n", "# If we have a single output, we simply calculate and flatten matrix product", "\n", "# between polynomials and derivatives to get library", "\n", "            ", "theta", "=", "torch", ".", "matmul", "(", "\n", "poly_list", "[", "0", "]", "[", ":", ",", ":", ",", "None", "]", ",", "deriv_list", "[", "0", "]", "[", ":", ",", "None", ",", ":", "]", "\n", ")", ".", "view", "(", "samples", ",", "total_terms", ")", "\n", "", "else", ":", "\n", "            ", "theta_uv", "=", "reduce", "(", "\n", "(", "lambda", "x", ",", "y", ":", "(", "x", "[", ":", ",", ":", ",", "None", "]", "@", "y", "[", ":", ",", "None", ",", ":", "]", ")", ".", "view", "(", "samples", ",", "-", "1", ")", ")", ",", "\n", "poly_list", ",", "\n", ")", "\n", "# calculate all unique combinations of derivatives", "\n", "theta_dudv", "=", "torch", ".", "cat", "(", "\n", "[", "\n", "torch", ".", "matmul", "(", "du", "[", ":", ",", ":", ",", "None", "]", ",", "dv", "[", ":", ",", "None", ",", ":", "]", ")", ".", "view", "(", "samples", ",", "-", "1", ")", "[", "\n", ":", ",", "1", ":", "\n", "]", "\n", "for", "du", ",", "dv", "in", "combinations", "(", "deriv_list", ",", "2", ")", "\n", "]", ",", "\n", "1", ",", "\n", ")", "\n", "theta", "=", "torch", ".", "cat", "(", "[", "theta_uv", ",", "theta_dudv", "]", ",", "dim", "=", "1", ")", "\n", "\n", "", "return", "time_deriv_list", ",", "[", "theta", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.PhIMaL_DeePyMoD.model.library.Library2D.__init__": [[153, 161], ["deepmod.Library.__init__"], "methods", ["home.repos.pwc.inspect_result.PhIMaL_DeePyMoD.data.base.Loader.__init__"], ["    ", "def", "__init__", "(", "self", ",", "poly_order", ":", "int", ")", "->", "None", ":", "\n", "        ", "\"\"\"Create a 2D library up to given polynomial order with second order derivatives\n         i.e. for poly_order=1: [$1, u_x, u_y, u_{xx}, u_{yy}, u_{xy}$]\n        Args:\n            poly_order (int): maximum order of the polynomial in the library\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "poly_order", "=", "poly_order", "\n", "\n"]], "home.repos.pwc.inspect_result.PhIMaL_DeePyMoD.model.library.Library2D.library": [[162, 208], ["torch.ones_like", "numpy.arange", "torch.cat", "torch.matmul().view", "torch.cat", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "torch.ones_like", "torch.matmul", "torch.ones_like", "torch.ones_like", "torch.ones_like"], "methods", ["None"], ["", "def", "library", "(", "\n", "self", ",", "input", ":", "Tuple", "[", "torch", ".", "Tensor", ",", "torch", ".", "Tensor", "]", "\n", ")", "->", "Tuple", "[", "TensorList", ",", "TensorList", "]", ":", "\n", "        ", "\"\"\"Compute the library for the given a prediction and data\n\n        Args:\n            input (Tuple[torch.Tensor, torch.Tensor]): A prediction and its data\n\n        Returns:\n            Tuple[TensorList, TensorList]: The time derivatives and the thetas\n            computed from the library and data.\n        \"\"\"", "\n", "\n", "prediction", ",", "data", "=", "input", "\n", "# Polynomial", "\n", "\n", "u", "=", "torch", ".", "ones_like", "(", "prediction", ")", "\n", "for", "order", "in", "np", ".", "arange", "(", "1", ",", "self", ".", "poly_order", "+", "1", ")", ":", "\n", "            ", "u", "=", "torch", ".", "cat", "(", "(", "u", ",", "u", "[", ":", ",", "order", "-", "1", ":", "order", "]", "*", "prediction", ")", ",", "dim", "=", "1", ")", "\n", "\n", "# Gradients", "\n", "", "du", "=", "grad", "(", "\n", "prediction", ",", "\n", "data", ",", "\n", "grad_outputs", "=", "torch", ".", "ones_like", "(", "prediction", ")", ",", "\n", "create_graph", "=", "True", ",", "\n", ")", "[", "0", "]", "\n", "u_t", "=", "du", "[", ":", ",", "0", ":", "1", "]", "\n", "u_x", "=", "du", "[", ":", ",", "1", ":", "2", "]", "\n", "u_y", "=", "du", "[", ":", ",", "2", ":", "3", "]", "\n", "du2", "=", "grad", "(", "\n", "u_x", ",", "data", ",", "grad_outputs", "=", "torch", ".", "ones_like", "(", "prediction", ")", ",", "create_graph", "=", "True", "\n", ")", "[", "0", "]", "\n", "u_xx", "=", "du2", "[", ":", ",", "1", ":", "2", "]", "\n", "u_xy", "=", "du2", "[", ":", ",", "2", ":", "3", "]", "\n", "u_yy", "=", "grad", "(", "\n", "u_y", ",", "data", ",", "grad_outputs", "=", "torch", ".", "ones_like", "(", "prediction", ")", ",", "create_graph", "=", "True", "\n", ")", "[", "0", "]", "[", ":", ",", "2", ":", "3", "]", "\n", "\n", "du", "=", "torch", ".", "cat", "(", "(", "torch", ".", "ones_like", "(", "u_x", ")", ",", "u_x", ",", "u_y", ",", "u_xx", ",", "u_yy", ",", "u_xy", ")", ",", "dim", "=", "1", ")", "\n", "\n", "samples", "=", "du", ".", "shape", "[", "0", "]", "\n", "# Bringing it together", "\n", "theta", "=", "torch", ".", "matmul", "(", "u", "[", ":", ",", ":", ",", "None", "]", ",", "du", "[", ":", ",", "None", ",", ":", "]", ")", ".", "view", "(", "samples", ",", "-", "1", ")", "\n", "\n", "return", "[", "u_t", "]", ",", "[", "theta", "]", "\n", "", "", ""]], "home.repos.pwc.inspect_result.PhIMaL_DeePyMoD.model.library.library_poly": [[13, 28], ["torch.ones_like", "numpy.arange", "torch.cat"], "function", ["None"], ["def", "library_poly", "(", "prediction", ":", "torch", ".", "Tensor", ",", "max_order", ":", "int", ")", "->", "torch", ".", "Tensor", ":", "\n", "    ", "\"\"\"Given a prediction u, returns u^n up to max_order, including ones as first column.\n\n    Args:\n        prediction (torch.Tensor): the data u for which to evaluate the library (n_samples x 1)\n        max_order (int): the maximum polynomial order up to which compute the library\n\n    Returns:\n        torch.Tensor: Tensor with polynomials (n_samples, max_order + 1)\n    \"\"\"", "\n", "u", "=", "torch", ".", "ones_like", "(", "prediction", ")", "\n", "for", "order", "in", "np", ".", "arange", "(", "1", ",", "max_order", "+", "1", ")", ":", "\n", "        ", "u", "=", "torch", ".", "cat", "(", "(", "u", ",", "u", "[", ":", ",", "order", "-", "1", ":", "order", "]", "*", "prediction", ")", ",", "dim", "=", "1", ")", "\n", "\n", "", "return", "u", "\n", "\n"]], "home.repos.pwc.inspect_result.PhIMaL_DeePyMoD.model.library.library_deriv": [[30, 69], ["torch.autograd.grad", "torch.ones_like", "torch.cat", "numpy.arange", "torch.ones_like", "torch.ones_like", "torch.cat", "torch.autograd.grad", "torch.ones_like"], "function", ["None"], ["", "def", "library_deriv", "(", "\n", "data", ":", "torch", ".", "Tensor", ",", "prediction", ":", "torch", ".", "Tensor", ",", "max_order", ":", "int", "\n", ")", "->", "Tuple", "[", "torch", ".", "Tensor", ",", "torch", ".", "Tensor", "]", ":", "\n", "    ", "\"\"\"Given a prediction u evaluated at data (t, x), returns du/dt and du/dx up to max_order, including ones\n    as first column.\n\n    Args:\n        data (torch.Tensor): (t, x) locations of where to evaluate derivatives (n_samples x 2)\n        prediction (torch.Tensor): the data u for which to evaluate the library (n_samples x 1)\n        max_order (int): maximum order of derivatives to be calculated.\n\n    Returns:\n        Tuple[torch.Tensor, torch.Tensor]: time derivative and feature library ((n_samples, 1), (n_samples,  max_order + 1))\n    \"\"\"", "\n", "dy", "=", "grad", "(", "\n", "prediction", ",", "data", ",", "grad_outputs", "=", "torch", ".", "ones_like", "(", "prediction", ")", ",", "create_graph", "=", "True", "\n", ")", "[", "0", "]", "\n", "time_deriv", "=", "dy", "[", ":", ",", "0", ":", "1", "]", "\n", "\n", "if", "max_order", "==", "0", ":", "\n", "        ", "du", "=", "torch", ".", "ones_like", "(", "time_deriv", ")", "\n", "", "else", ":", "\n", "        ", "du", "=", "torch", ".", "cat", "(", "(", "torch", ".", "ones_like", "(", "time_deriv", ")", ",", "dy", "[", ":", ",", "1", ":", "2", "]", ")", ",", "dim", "=", "1", ")", "\n", "if", "max_order", ">", "1", ":", "\n", "            ", "for", "order", "in", "np", ".", "arange", "(", "1", ",", "max_order", ")", ":", "\n", "                ", "du", "=", "torch", ".", "cat", "(", "\n", "(", "\n", "du", ",", "\n", "grad", "(", "\n", "du", "[", ":", ",", "order", ":", "order", "+", "1", "]", ",", "\n", "data", ",", "\n", "grad_outputs", "=", "torch", ".", "ones_like", "(", "prediction", ")", ",", "\n", "create_graph", "=", "True", ",", "\n", ")", "[", "0", "]", "[", ":", ",", "1", ":", "2", "]", ",", "\n", ")", ",", "\n", "dim", "=", "1", ",", "\n", ")", "\n", "\n", "", "", "", "return", "time_deriv", ",", "du", "\n", "\n"]], "home.repos.pwc.inspect_result.PhIMaL_DeePyMoD.model.func_approx.NN.__init__": [[12, 22], ["torch.Module.__init__", "func_approx.NN.build_network"], "methods", ["home.repos.pwc.inspect_result.PhIMaL_DeePyMoD.data.base.Loader.__init__", "home.repos.pwc.inspect_result.PhIMaL_DeePyMoD.model.func_approx.Siren.build_network"], ["    ", "def", "__init__", "(", "self", ",", "n_in", ":", "int", ",", "n_hidden", ":", "List", "[", "int", "]", ",", "n_out", ":", "int", ")", "->", "None", ":", "\n", "        ", "\"\"\"Constructs a feed-forward neural network with tanh activation.\n\n        Args:\n            n_in (int): Number of input features.\n            n_hidden (List[int]): Number of neurons in each layer.\n            n_out (int): Number of output features.\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "network", "=", "self", ".", "build_network", "(", "n_in", ",", "n_hidden", ",", "n_out", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.PhIMaL_DeePyMoD.model.func_approx.NN.forward": [[23, 35], ["input.clone().detach().requires_grad_", "func_approx.NN.network", "input.clone().detach", "input.clone"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input", ":", "torch", ".", "Tensor", ")", "->", "Tuple", "[", "torch", ".", "Tensor", ",", "torch", ".", "Tensor", "]", ":", "\n", "        ", "\"\"\"Forward pass through the network. Returns prediction and the differentiable input\n        so we can construct the library.\n\n        Args:\n            input (torch.Tensor): Input tensor of size (n_samples, n_inputs).\n\n        Returns:\n            (torch.Tensor, torch.Tensor): prediction of size (n_samples, n_outputs) and coordinates of size (n_samples, n_inputs).\n        \"\"\"", "\n", "coordinates", "=", "input", ".", "clone", "(", ")", ".", "detach", "(", ")", ".", "requires_grad_", "(", "True", ")", "\n", "return", "self", ".", "network", "(", "coordinates", ")", ",", "coordinates", "\n", "\n"]], "home.repos.pwc.inspect_result.PhIMaL_DeePyMoD.model.func_approx.NN.build_network": [[36, 57], ["zip", "network.pop", "torch.Sequential", "torch.Sequential", "network.append", "network.append", "torch.Linear", "torch.Linear", "torch.Tanh", "torch.Tanh"], "methods", ["None"], ["", "def", "build_network", "(", "\n", "self", ",", "n_in", ":", "int", ",", "n_hidden", ":", "List", "[", "int", "]", ",", "n_out", ":", "int", "\n", ")", "->", "torch", ".", "nn", ".", "Sequential", ":", "\n", "        ", "\"\"\"Constructs a feed-forward neural network.\n\n        Args:\n            n_in (int): Number of input features.\n            n_hidden (list[int]): Number of neurons in each layer.\n            n_out (int): Number of output features.\n\n        Returns:\n            torch.Sequential: Pytorch module\n        \"\"\"", "\n", "\n", "network", "=", "[", "]", "\n", "architecture", "=", "[", "n_in", "]", "+", "n_hidden", "+", "[", "n_out", "]", "\n", "for", "layer_i", ",", "layer_j", "in", "zip", "(", "architecture", ",", "architecture", "[", "1", ":", "]", ")", ":", "\n", "            ", "network", ".", "append", "(", "nn", ".", "Linear", "(", "layer_i", ",", "layer_j", ")", ")", "\n", "network", ".", "append", "(", "nn", ".", "Tanh", "(", ")", ")", "\n", "", "network", ".", "pop", "(", ")", "# get rid of last activation function", "\n", "return", "nn", ".", "Sequential", "(", "*", "network", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.PhIMaL_DeePyMoD.model.func_approx.SineLayer.__init__": [[60, 83], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "func_approx.SineLayer.init_weights"], "methods", ["home.repos.pwc.inspect_result.PhIMaL_DeePyMoD.data.base.Loader.__init__", "home.repos.pwc.inspect_result.PhIMaL_DeePyMoD.model.func_approx.SineLayer.init_weights"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "in_features", ":", "int", ",", "\n", "out_features", ":", "int", ",", "\n", "omega_0", ":", "float", "=", "30", ",", "\n", "is_first", ":", "bool", "=", "False", ",", "\n", ")", "->", "None", ":", "\n", "        ", "\"\"\"Sine activation function layer with omega_0 scaling.\n\n        Args:\n            in_features (int): Number of input features.\n            out_features (int): Number of output features.\n            omega_0 (float, optional): Scaling factor of the Sine function. Defaults to 30.\n            is_first (bool, optional): Defaults to False.\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "omega_0", "=", "omega_0", "\n", "self", ".", "is_first", "=", "is_first", "\n", "\n", "self", ".", "in_features", "=", "in_features", "\n", "self", ".", "linear", "=", "nn", ".", "Linear", "(", "in_features", ",", "out_features", ")", "\n", "\n", "self", ".", "init_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.PhIMaL_DeePyMoD.model.func_approx.SineLayer.init_weights": [[84, 93], ["torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "func_approx.SineLayer.linear.weight.uniform_", "func_approx.SineLayer.linear.weight.uniform_", "numpy.sqrt", "numpy.sqrt"], "methods", ["None"], ["", "def", "init_weights", "(", "self", ")", "->", "None", ":", "\n", "        ", "\"\"\"Initialization of the weigths.\"\"\"", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "if", "self", ".", "is_first", ":", "\n", "                ", "self", ".", "linear", ".", "weight", ".", "uniform_", "(", "-", "1", "/", "self", ".", "in_features", ",", "1", "/", "self", ".", "in_features", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "linear", ".", "weight", ".", "uniform_", "(", "\n", "-", "np", ".", "sqrt", "(", "6", "/", "self", ".", "in_features", ")", "/", "self", ".", "omega_0", ",", "\n", "np", ".", "sqrt", "(", "6", "/", "self", ".", "in_features", ")", "/", "self", ".", "omega_0", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.PhIMaL_DeePyMoD.model.func_approx.SineLayer.forward": [[95, 105], ["torch.sin", "torch.sin", "torch.sin", "torch.sin", "func_approx.SineLayer.linear"], "methods", ["None"], ["", "", "", "def", "forward", "(", "self", ",", "input", ":", "torch", ".", "Tensor", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\"Forward pass through the layer.\n\n        Args:\n            input (torch.Tensor): Input tensor of shape (n_samples, n_inputs).\n\n        Returns:\n            torch.Tensor: Prediction of shape (n_samples, n_outputs)\n        \"\"\"", "\n", "return", "torch", ".", "sin", "(", "self", ".", "omega_0", "*", "self", ".", "linear", "(", "input", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.PhIMaL_DeePyMoD.model.func_approx.Siren.__init__": [[108, 129], ["torch.Module.__init__", "func_approx.Siren.build_network"], "methods", ["home.repos.pwc.inspect_result.PhIMaL_DeePyMoD.data.base.Loader.__init__", "home.repos.pwc.inspect_result.PhIMaL_DeePyMoD.model.func_approx.Siren.build_network"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "n_in", ":", "int", ",", "\n", "n_hidden", ":", "List", "[", "int", "]", ",", "\n", "n_out", ":", "int", ",", "\n", "first_omega_0", ":", "float", "=", "30.0", ",", "\n", "hidden_omega_0", ":", "float", "=", "30.0", ",", "\n", ")", "->", "None", ":", "\n", "        ", "\"\"\"SIREN model from the paper [Implicit Neural Representations with\n        Periodic Activation Functions](https://arxiv.org/abs/2006.09661).\n\n        Args:\n            n_in (int): Number of input features.\n            n_hidden (list[int]): Number of neurons in each layer.\n            n_out (int): Number of output features.\n            first_omega_0 (float, optional): Scaling factor of the Sine function of the first layer. Defaults to 30.\n            hidden_omega_0 (float, optional): Scaling factor of the Sine function of the hidden layers. Defaults to 30.\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "network", "=", "self", ".", "build_network", "(", "\n", "n_in", ",", "n_hidden", ",", "n_out", ",", "first_omega_0", ",", "hidden_omega_0", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.PhIMaL_DeePyMoD.model.func_approx.Siren.forward": [[131, 142], ["input.clone().detach().requires_grad_", "func_approx.Siren.network", "input.clone().detach", "input.clone"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input", ":", "torch", ".", "Tensor", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\"Forward pass through the network.\n\n        Args:\n            input (torch.Tensor): Input tensor of shape (n_samples, n_inputs).\n\n        Returns:\n            torch.Tensor: Prediction of shape (n_samples, n_outputs)\n        \"\"\"", "\n", "coordinates", "=", "input", ".", "clone", "(", ")", ".", "detach", "(", ")", ".", "requires_grad_", "(", "True", ")", "\n", "return", "self", ".", "network", "(", "coordinates", ")", ",", "coordinates", "\n", "\n"]], "home.repos.pwc.inspect_result.PhIMaL_DeePyMoD.model.func_approx.Siren.build_network": [[143, 184], ["network.append", "zip", "torch.Linear", "torch.Linear", "torch.Sequential", "torch.Sequential", "func_approx.SineLayer", "network.append", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.Linear.weight.uniform_", "network.append", "func_approx.SineLayer", "numpy.sqrt", "numpy.sqrt"], "methods", ["None"], ["", "def", "build_network", "(", "\n", "self", ",", "\n", "n_in", ":", "int", ",", "\n", "n_hidden", ":", "List", "[", "int", "]", ",", "\n", "n_out", ":", "int", ",", "\n", "first_omega_0", ":", "float", ",", "\n", "hidden_omega_0", ":", "float", ",", "\n", ")", "->", "torch", ".", "nn", ".", "Sequential", ":", "\n", "        ", "\"\"\"Constructs the Siren neural network.\n\n        Args:\n            n_in (int): Number of input features.\n            n_hidden (list[int]): Number of neurons in each layer.\n            n_out (int): Number of output features.\n            first_omega_0 (float, optional): Scaling factor of the Sine function of the first layer. Defaults to 30.\n            hidden_omega_0 (float, optional): Scaling factor of the Sine function of the hidden layers. Defaults to 30.\n        Returns:\n            torch.Sequential: Pytorch module\n        \"\"\"", "\n", "network", "=", "[", "]", "\n", "# Input layer", "\n", "network", ".", "append", "(", "\n", "SineLayer", "(", "n_in", ",", "n_hidden", "[", "0", "]", ",", "is_first", "=", "True", ",", "omega_0", "=", "first_omega_0", ")", "\n", ")", "\n", "\n", "# Hidden layers", "\n", "for", "layer_i", ",", "layer_j", "in", "zip", "(", "n_hidden", ",", "n_hidden", "[", "1", ":", "]", ")", ":", "\n", "            ", "network", ".", "append", "(", "\n", "SineLayer", "(", "layer_i", ",", "layer_j", ",", "is_first", "=", "False", ",", "omega_0", "=", "hidden_omega_0", ")", "\n", ")", "\n", "\n", "# Output layer", "\n", "", "final_linear", "=", "nn", ".", "Linear", "(", "n_hidden", "[", "-", "1", "]", ",", "n_out", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "final_linear", ".", "weight", ".", "uniform_", "(", "\n", "-", "np", ".", "sqrt", "(", "6", "/", "n_hidden", "[", "-", "1", "]", ")", "/", "hidden_omega_0", ",", "\n", "np", ".", "sqrt", "(", "6", "/", "n_hidden", "[", "-", "1", "]", ")", "/", "hidden_omega_0", ",", "\n", ")", "\n", "network", ".", "append", "(", "final_linear", ")", "\n", "\n", "", "return", "nn", ".", "Sequential", "(", "*", "network", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.PhIMaL_DeePyMoD.model.constraint.LeastSquares.__init__": [[12, 15], ["deepmod.Constraint.__init__"], "methods", ["home.repos.pwc.inspect_result.PhIMaL_DeePyMoD.data.base.Loader.__init__"], ["    ", "def", "__init__", "(", "self", ")", "->", "None", ":", "\n", "        ", "\"\"\"Least Squares Constraint solved by QR decomposition\"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.PhIMaL_DeePyMoD.model.constraint.LeastSquares.fit": [[16, 32], ["zip", "torch.qr", "coeff_vectors.append", "torch.inverse"], "methods", ["None"], ["", "def", "fit", "(", "self", ",", "sparse_thetas", ":", "TensorList", ",", "time_derivs", ":", "TensorList", ")", "->", "TensorList", ":", "\n", "        ", "\"\"\"Calculates the coefficients of the constraint using the QR decomposition for every pair\n        of sparse feature matrix and time derivative.\n\n        Args:\n            sparse_thetas (TensorList): List containing the sparse feature tensors of size (n_samples, n_active_features).\n            time_derivs (TensorList): List containing the time derivatives of size (n_samples, n_outputs).\n\n        Returns:\n            (TensorList): List of calculated coefficients of size [(n_active_features, 1) x n_outputs].\n        \"\"\"", "\n", "coeff_vectors", "=", "[", "]", "\n", "for", "theta", ",", "dt", "in", "zip", "(", "sparse_thetas", ",", "time_derivs", ")", ":", "\n", "            ", "Q", ",", "R", "=", "torch", ".", "qr", "(", "theta", ")", "# solution of lst. sq. by QR decomp.", "\n", "coeff_vectors", ".", "append", "(", "torch", ".", "inverse", "(", "R", ")", "@", "Q", ".", "T", "@", "dt", ")", "\n", "", "return", "coeff_vectors", "\n", "\n"]], "home.repos.pwc.inspect_result.PhIMaL_DeePyMoD.model.constraint.GradParams.__init__": [[35, 46], ["deepmod.Constraint.__init__", "torch.nn.ParameterList", "torch.nn.Parameter", "torch.randn", "torch.arange"], "methods", ["home.repos.pwc.inspect_result.PhIMaL_DeePyMoD.data.base.Loader.__init__"], ["    ", "def", "__init__", "(", "self", ",", "n_params", ":", "int", ",", "n_eqs", ":", "int", ")", "->", "None", ":", "\n", "        ", "\"\"\"Constrains the neural network by optimizing over the coefficients together with the network.\n           Coefficient vectors are randomly initialized from a standard Gaussian.\n\n        Args:\n            n_params (int): number of features in feature matrix.\n            n_eqs (int): number of outputs / equations to be discovered.\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "coeffs", "=", "torch", ".", "nn", ".", "ParameterList", "(", "\n", "[", "torch", ".", "nn", ".", "Parameter", "(", "torch", ".", "randn", "(", "n_params", ",", "1", ")", ")", "for", "_", "in", "torch", ".", "arange", "(", "n_eqs", ")", "]", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.PhIMaL_DeePyMoD.model.constraint.GradParams.fit": [[48, 60], ["None"], "methods", ["None"], ["", "def", "fit", "(", "self", ",", "sparse_thetas", ":", "TensorList", ",", "time_derivs", ":", "TensorList", ")", ":", "\n", "        ", "\"\"\"Returns the coefficients of the constraint, since we're optimizing them by\n           gradient descent.\n\n        Args:\n            sparse_thetas (TensorList): List containing the sparse feature tensors of size (n_samples, n_active_features).\n            time_derivs (TensorList): List containing the time derivatives of size (n_samples, n_outputs).\n\n        Returns:\n            (TensorList): Calculated coefficients of size (n_features, n_outputs).\n        \"\"\"", "\n", "return", "self", ".", "coeffs", "\n", "\n"]], "home.repos.pwc.inspect_result.PhIMaL_DeePyMoD.model.constraint.Ridge.__init__": [[65, 68], ["deepmod.Constraint.__init__", "torch.tensor"], "methods", ["home.repos.pwc.inspect_result.PhIMaL_DeePyMoD.data.base.Loader.__init__"], ["def", "__init__", "(", "self", ",", "l", "=", "1e-3", ")", "->", "None", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "l", "=", "torch", ".", "tensor", "(", "l", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.PhIMaL_DeePyMoD.model.constraint.Ridge.fit": [[69, 94], ["zip", "torch.norm", "torch.diag", "torch.cat", "torch.cat", "torch.qr", "coeff_vectors.append", "torch.sqrt", "torch.zeros", "torch.inverse"], "methods", ["None"], ["", "def", "fit", "(", "self", ",", "sparse_thetas", ":", "TensorList", ",", "time_derivs", ":", "TensorList", ")", "->", "TensorList", ":", "\n", "        ", "\"\"\"Calculates the coefficients of the constraint using the QR decomposition for every pair\n        of sparse feature matrix and time derivative.\n\n        Args:\n            sparse_thetas (TensorList): List containing the sparse feature tensors.\n            time_derivs (TensorList): List containing the time derivatives.\n\n        Returns:\n            (TensorList): Calculated coefficients.\n        \"\"\"", "\n", "coeff_vectors", "=", "[", "]", "\n", "for", "theta", ",", "dt", "in", "zip", "(", "sparse_thetas", ",", "time_derivs", ")", ":", "\n", "# We use the augmented data method", "\n", "            ", "norm", "=", "torch", ".", "norm", "(", "theta", ",", "dim", "=", "0", ")", "\n", "l_normed", "=", "torch", ".", "diag", "(", "\n", "torch", ".", "sqrt", "(", "self", ".", "l", ")", "*", "norm", "\n", ")", "# we norm l rather than theta cause we want unnormed coeffs out", "\n", "X", "=", "torch", ".", "cat", "(", "(", "theta", ",", "l_normed", ")", ",", "dim", "=", "0", ")", "\n", "y", "=", "torch", ".", "cat", "(", "(", "dt", ",", "torch", ".", "zeros", "(", "(", "theta", ".", "shape", "[", "1", "]", ",", "1", ")", ")", ")", ",", "dim", "=", "0", ")", "\n", "# Now solve like normal OLS prob lem", "\n", "Q", ",", "R", "=", "torch", ".", "qr", "(", "X", ")", "# solution of lst. sq. by QR decomp.", "\n", "coeff_vectors", ".", "append", "(", "torch", ".", "inverse", "(", "R", ")", "@", "Q", ".", "T", "@", "y", ")", "\n", "\n", "", "return", "coeff_vectors", "\n", "", "", ""]], "home.repos.pwc.inspect_result.PhIMaL_DeePyMoD.training.sparsity_scheduler.Periodic.__init__": [[11, 20], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "periodicity", "=", "50", ",", "initial_iteration", "=", "1000", ")", ":", "\n", "        ", "\"\"\"Periodically applies sparsity every periodicity iterations\n        after initial_epoch.\n        Args:\n            periodicity (int): after initial_iterations, apply sparsity mask per periodicity epochs\n            initial_iteration (int): wait initial_iterations before applying sparsity\n        \"\"\"", "\n", "self", ".", "periodicity", "=", "periodicity", "\n", "self", ".", "initial_iteration", "=", "initial_iteration", "\n", "\n"]], "home.repos.pwc.inspect_result.PhIMaL_DeePyMoD.training.sparsity_scheduler.Periodic.__call__": [[21, 29], ["None"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "iteration", ",", "loss", ",", "model", ",", "optimizer", ")", ":", "\n", "# Update periodically", "\n", "        ", "apply_sparsity", "=", "False", "# we overwrite it if we need to update", "\n", "\n", "if", "(", "iteration", "-", "self", ".", "initial_iteration", ")", "%", "self", ".", "periodicity", "==", "0", ":", "\n", "            ", "apply_sparsity", "=", "True", "\n", "\n", "", "return", "apply_sparsity", "\n", "\n"]], "home.repos.pwc.inspect_result.PhIMaL_DeePyMoD.training.sparsity_scheduler.TrainTest.__init__": [[35, 49], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "patience", "=", "200", ",", "delta", "=", "1e-5", ",", "path", "=", "\"checkpoint.pt\"", ")", ":", "\n", "        ", "\"\"\"Early stops the training if validation loss doesn't improve after a given patience.\n        Note that periodicity should be multitude of write_iterations.\n        Args:\n            patience (int): wait patience epochs before checking TrainTest\n            delta (float): desired accuracy\n            path (str): pathname where to store the savepoints, must have \".pt\" extension\n        \"\"\"", "\n", "self", ".", "path", "=", "path", "\n", "self", ".", "patience", "=", "patience", "\n", "self", ".", "delta", "=", "delta", "\n", "\n", "self", ".", "best_iteration", "=", "None", "\n", "self", ".", "best_loss", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.PhIMaL_DeePyMoD.training.sparsity_scheduler.TrainTest.__call__": [[50, 75], ["sparsity_scheduler.TrainTest.save_checkpoint", "sparsity_scheduler.TrainTest.save_checkpoint", "sparsity_scheduler.TrainTest.load_checkpoint"], "methods", ["home.repos.pwc.inspect_result.PhIMaL_DeePyMoD.training.sparsity_scheduler.TrainTestPeriodic.save_checkpoint", "home.repos.pwc.inspect_result.PhIMaL_DeePyMoD.training.sparsity_scheduler.TrainTestPeriodic.save_checkpoint", "home.repos.pwc.inspect_result.PhIMaL_DeePyMoD.training.sparsity_scheduler.TrainTestPeriodic.load_checkpoint"], ["", "def", "__call__", "(", "self", ",", "iteration", ",", "loss", ",", "model", ",", "optimizer", ")", ":", "\n", "        ", "apply_sparsity", "=", "False", "# we overwrite it if we need to update", "\n", "\n", "# Initialize if doesnt exist yet", "\n", "if", "self", ".", "best_loss", "is", "None", ":", "\n", "            ", "self", ".", "best_loss", "=", "loss", "\n", "self", ".", "best_iteration", "=", "iteration", "\n", "self", ".", "save_checkpoint", "(", "model", ",", "optimizer", ")", "\n", "\n", "# If it didnt improve, check if we're past patience", "\n", "", "elif", "(", "self", ".", "best_loss", "-", "loss", ")", "<", "self", ".", "delta", ":", "\n", "            ", "if", "(", "iteration", "-", "self", ".", "best_iteration", ")", ">=", "self", ".", "patience", ":", "\n", "# We reload the model to the best point and reset the scheduler", "\n", "                ", "self", ".", "load_checkpoint", "(", "model", ",", "optimizer", ")", "# reload model to best point", "\n", "self", ".", "best_loss", "=", "None", "\n", "self", ".", "best_iteration", "=", "None", "\n", "apply_sparsity", "=", "True", "\n", "\n", "# If not, keep going", "\n", "", "", "else", ":", "\n", "            ", "self", ".", "best_loss", "=", "loss", "\n", "self", ".", "best_iteration", "=", "iteration", "\n", "self", ".", "save_checkpoint", "(", "model", ",", "optimizer", ")", "\n", "\n", "", "return", "apply_sparsity", "\n", "\n"]], "home.repos.pwc.inspect_result.PhIMaL_DeePyMoD.training.sparsity_scheduler.TrainTest.save_checkpoint": [[76, 85], ["torch.save", "model.state_dict", "optimizer.state_dict"], "methods", ["None"], ["", "def", "save_checkpoint", "(", "self", ",", "model", ",", "optimizer", ")", ":", "\n", "        ", "\"\"\"Saves model when validation loss decrease.\"\"\"", "\n", "checkpoint_path", "=", "self", ".", "path", "+", "\"checkpoint.pt\"", "\n", "torch", ".", "save", "(", "\n", "{", "\n", "\"model_state_dict\"", ":", "model", ".", "state_dict", "(", ")", ",", "\n", "\"optimizer_state_dict\"", ":", "optimizer", ".", "state_dict", "(", ")", ",", "\n", "}", ",", "\n", "checkpoint_path", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.PhIMaL_DeePyMoD.training.sparsity_scheduler.TrainTest.load_checkpoint": [[87, 93], ["torch.load", "model.load_state_dict", "optimizer.load_state_dict"], "methods", ["None"], ["", "def", "load_checkpoint", "(", "self", ",", "model", ",", "optimizer", ")", ":", "\n", "        ", "\"\"\"Loads model from disk\"\"\"", "\n", "checkpoint_path", "=", "self", ".", "path", "+", "\"checkpoint.pt\"", "\n", "checkpoint", "=", "torch", ".", "load", "(", "checkpoint_path", ")", "\n", "model", ".", "load_state_dict", "(", "checkpoint", "[", "\"model_state_dict\"", "]", ")", "\n", "optimizer", ".", "load_state_dict", "(", "checkpoint", "[", "\"optimizer_state_dict\"", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.PhIMaL_DeePyMoD.training.sparsity_scheduler.TrainTestPeriodic.__init__": [[99, 115], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "periodicity", "=", "50", ",", "patience", "=", "200", ",", "delta", "=", "1e-5", ",", "path", "=", "\"checkpoint.pt\"", ")", ":", "\n", "        ", "\"\"\"Early stops the training if validation loss doesn't improve after a given patience.\n        Note that periodicity should be multitude of write_iterations.\n        Args:\n            periodicity (int): apply sparsity mask per periodicity epochs\n            patience (int): wait patience epochs before checking TrainTest\n            delta (float): desired accuracy\n            path (str): pathname where to store the savepoints, must have \".pt\" extension\"\"\"", "\n", "self", ".", "path", "=", "path", "\n", "self", ".", "patience", "=", "patience", "\n", "self", ".", "delta", "=", "delta", "\n", "self", ".", "periodicity", "=", "periodicity", "\n", "\n", "self", ".", "best_iteration", "=", "None", "\n", "self", ".", "best_loss", "=", "None", "\n", "self", ".", "periodic", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.PhIMaL_DeePyMoD.training.sparsity_scheduler.TrainTestPeriodic.__call__": [[116, 146], ["sparsity_scheduler.TrainTestPeriodic.save_checkpoint", "sparsity_scheduler.TrainTestPeriodic.save_checkpoint", "sparsity_scheduler.TrainTestPeriodic.load_checkpoint"], "methods", ["home.repos.pwc.inspect_result.PhIMaL_DeePyMoD.training.sparsity_scheduler.TrainTestPeriodic.save_checkpoint", "home.repos.pwc.inspect_result.PhIMaL_DeePyMoD.training.sparsity_scheduler.TrainTestPeriodic.save_checkpoint", "home.repos.pwc.inspect_result.PhIMaL_DeePyMoD.training.sparsity_scheduler.TrainTestPeriodic.load_checkpoint"], ["", "def", "__call__", "(", "self", ",", "iteration", ",", "loss", ",", "model", ",", "optimizer", ")", ":", "\n", "# Update periodically if we have updated once", "\n", "        ", "apply_sparsity", "=", "False", "# we overwrite it if we need to update", "\n", "\n", "if", "self", ".", "periodic", "is", "True", ":", "\n", "            ", "if", "(", "iteration", "-", "self", ".", "best_iteration", ")", "%", "self", ".", "periodicity", "==", "0", ":", "\n", "                ", "apply_sparsity", "=", "True", "\n", "\n", "# Check for improvements if we havent updated yet.", "\n", "# Initialize if doesnt exist yet", "\n", "", "", "elif", "self", ".", "best_loss", "is", "None", ":", "\n", "            ", "self", ".", "best_loss", "=", "loss", "\n", "self", ".", "best_iteration", "=", "iteration", "\n", "self", ".", "save_checkpoint", "(", "model", ",", "optimizer", ")", "\n", "\n", "# If it didnt improve, check if we're past patience", "\n", "", "elif", "(", "self", ".", "best_loss", "-", "loss", ")", "<", "self", ".", "delta", ":", "\n", "            ", "if", "(", "iteration", "-", "self", ".", "best_iteration", ")", ">=", "self", ".", "patience", ":", "\n", "                ", "self", ".", "load_checkpoint", "(", "model", ",", "optimizer", ")", "# reload model to best point", "\n", "self", ".", "periodic", "=", "True", "# switch to periodic regime", "\n", "self", ".", "best_iteration", "=", "iteration", "# because the iterator doesnt reset", "\n", "apply_sparsity", "=", "True", "\n", "\n", "# If not, keep going", "\n", "", "", "else", ":", "\n", "            ", "self", ".", "best_loss", "=", "loss", "\n", "self", ".", "best_iteration", "=", "iteration", "\n", "self", ".", "save_checkpoint", "(", "model", ",", "optimizer", ")", "\n", "\n", "", "return", "apply_sparsity", "\n", "\n"]], "home.repos.pwc.inspect_result.PhIMaL_DeePyMoD.training.sparsity_scheduler.TrainTestPeriodic.save_checkpoint": [[147, 156], ["torch.save", "model.state_dict", "optimizer.state_dict"], "methods", ["None"], ["", "def", "save_checkpoint", "(", "self", ",", "model", ",", "optimizer", ")", ":", "\n", "        ", "\"\"\"Saves model when validation loss decrease.\"\"\"", "\n", "checkpoint_path", "=", "self", ".", "path", "+", "\"checkpoint.pt\"", "\n", "torch", ".", "save", "(", "\n", "{", "\n", "\"model_state_dict\"", ":", "model", ".", "state_dict", "(", ")", ",", "\n", "\"optimizer_state_dict\"", ":", "optimizer", ".", "state_dict", "(", ")", ",", "\n", "}", ",", "\n", "checkpoint_path", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.PhIMaL_DeePyMoD.training.sparsity_scheduler.TrainTestPeriodic.load_checkpoint": [[158, 164], ["torch.load", "model.load_state_dict", "optimizer.load_state_dict"], "methods", ["None"], ["", "def", "load_checkpoint", "(", "self", ",", "model", ",", "optimizer", ")", ":", "\n", "        ", "\"\"\"Loads model from disk\"\"\"", "\n", "checkpoint_path", "=", "self", ".", "path", "+", "\"checkpoint.pt\"", "\n", "checkpoint", "=", "torch", ".", "load", "(", "checkpoint_path", ")", "\n", "model", ".", "load_state_dict", "(", "checkpoint", "[", "\"model_state_dict\"", "]", ")", "\n", "optimizer", ".", "load_state_dict", "(", "checkpoint", "[", "\"optimizer_state_dict\"", "]", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.PhIMaL_DeePyMoD.training.training.train": [[9, 126], ["utils.logger.Logger", "convergence.Convergence", "torch.arange", "utils.logger.Logger.close", "torch.zeros", "enumerate", "torch.mean", "model", "torch.mean", "torch.stack", "optimizer.zero_grad", "batch_losses[].sum().backward", "optimizer.step", "torch.zeros.cpu().detach", "torch.zeros.cpu().detach().mean", "model.sparse_estimator", "utils.logger.Logger.", "sparsity_scheduler", "torch.sum", "convergence.Convergence.", "len", "torch.no_grad", "torch.zeros", "enumerate", "loss.view().mean", "mse.view", "reg.view", "model.constraint_coeffs", "model.constraint_coeffs", "model.estimator_coeffs", "torch.sum", "model.sparse_estimator", "torch.abs", "torch.mean", "batch_losses[].sum", "torch.zeros.cpu", "torch.mean", "torch.zeros.cpu().detach", "torch.cat", "zip", "len", "model.func_approx", "loss.view", "model.constraint_coeffs", "model.constraint_coeffs", "torch.zeros.cpu"], "function", ["home.repos.pwc.inspect_result.PhIMaL_DeePyMoD.utils.logger.Logger.close", "home.repos.pwc.inspect_result.PhIMaL_DeePyMoD.model.deepmod.DeepMoD.constraint_coeffs", "home.repos.pwc.inspect_result.PhIMaL_DeePyMoD.model.deepmod.DeepMoD.constraint_coeffs", "home.repos.pwc.inspect_result.PhIMaL_DeePyMoD.model.deepmod.DeepMoD.estimator_coeffs", "home.repos.pwc.inspect_result.PhIMaL_DeePyMoD.model.deepmod.DeepMoD.constraint_coeffs", "home.repos.pwc.inspect_result.PhIMaL_DeePyMoD.model.deepmod.DeepMoD.constraint_coeffs"], ["def", "train", "(", "\n", "model", ":", "DeepMoD", ",", "\n", "train_dataloader", ":", "DataLoader", ",", "\n", "test_dataloader", ":", "DataLoader", ",", "\n", "optimizer", ",", "\n", "sparsity_scheduler", ",", "\n", "split", ":", "float", "=", "0.8", ",", "\n", "exp_ID", ":", "str", "=", "None", ",", "\n", "log_dir", ":", "str", "=", "None", ",", "\n", "max_iterations", ":", "int", "=", "10000", ",", "\n", "write_iterations", ":", "int", "=", "25", ",", "\n", "**", "convergence_kwargs", "\n", ")", "->", "None", ":", "\n", "    ", "\"\"\"Trains the DeepMoD model. This function automatically splits the data set in a train and test set.\n\n    Args:\n        model (DeepMoD):  A DeepMoD object.\n        data (torch.Tensor):  Tensor of shape (n_samples x (n_spatial + 1)) containing the coordinates, first column should be the time coordinate.\n        target (torch.Tensor): Tensor of shape (n_samples x n_features) containing the target data.\n        optimizer ([type]):  Pytorch optimizer.\n        sparsity_scheduler ([type]):  Decides when to update the sparsity mask.\n        split (float, optional):  Fraction of the train set, by default 0.8.\n        exp_ID (str, optional): Unique ID to identify tensorboard file. Not used if log_dir is given, see pytorch documentation.\n        log_dir (str, optional): Directory where tensorboard file is written, by default None.\n        max_iterations (int, optional): [description]. Max number of epochs , by default 10000.\n        write_iterations (int, optional): [description]. Sets how often data is written to tensorboard and checks train loss , by default 25.\n    \"\"\"", "\n", "logger", "=", "Logger", "(", "exp_ID", ",", "log_dir", ")", "\n", "sparsity_scheduler", ".", "path", "=", "(", "\n", "logger", ".", "log_dir", "\n", ")", "# write checkpoint to same folder as tb output.", "\n", "n_features", "=", "train_dataloader", "[", "0", "]", "[", "1", "]", ".", "shape", "[", "-", "1", "]", "\n", "# n_features = model.func_approx.modules()", "\n", "# Training", "\n", "convergence", "=", "Convergence", "(", "**", "convergence_kwargs", ")", "\n", "for", "iteration", "in", "torch", ".", "arange", "(", "0", ",", "max_iterations", ")", ":", "\n", "# Training variables defined as: loss, mse, regularisation", "\n", "        ", "batch_losses", "=", "torch", ".", "zeros", "(", "\n", "(", "3", ",", "n_features", ",", "len", "(", "train_dataloader", ")", ")", ",", "\n", "device", "=", "train_dataloader", ".", "device", ",", "\n", ")", "\n", "for", "batch_idx", ",", "train_sample", "in", "enumerate", "(", "train_dataloader", ")", ":", "\n", "            ", "data_train", ",", "target_train", "=", "train_sample", "\n", "# ================== Training Model ============================", "\n", "prediction", ",", "time_derivs", ",", "thetas", "=", "model", "(", "data_train", ")", "\n", "batch_losses", "[", "1", ",", ":", ",", "batch_idx", "]", "=", "torch", ".", "mean", "(", "\n", "(", "prediction", "-", "target_train", ")", "**", "2", ",", "dim", "=", "-", "2", "\n", ")", "# loss per output", "\n", "batch_losses", "[", "2", ",", ":", ",", "batch_idx", "]", "=", "torch", ".", "stack", "(", "\n", "[", "\n", "torch", ".", "mean", "(", "(", "dt", "-", "theta", "@", "coeff_vector", ")", "**", "2", ")", "\n", "for", "dt", ",", "theta", ",", "coeff_vector", "in", "zip", "(", "\n", "time_derivs", ",", "\n", "thetas", ",", "\n", "model", ".", "constraint_coeffs", "(", "scaled", "=", "False", ",", "sparse", "=", "True", ")", ",", "\n", ")", "\n", "]", "\n", ")", "\n", "batch_losses", "[", "0", ",", ":", ",", "batch_idx", "]", "=", "(", "\n", "batch_losses", "[", "1", ",", ":", ",", "batch_idx", "]", "+", "batch_losses", "[", "2", ",", ":", ",", "batch_idx", "]", "\n", ")", "\n", "\n", "# Optimizer step", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "batch_losses", "[", "0", ",", ":", ",", "batch_idx", "]", ".", "sum", "(", ")", ".", "backward", "(", ")", "\n", "optimizer", ".", "step", "(", ")", "\n", "\n", "", "loss", ",", "mse", ",", "reg", "=", "torch", ".", "mean", "(", "batch_losses", ".", "cpu", "(", ")", ".", "detach", "(", ")", ",", "axis", "=", "-", "1", ")", "\n", "\n", "if", "iteration", "%", "write_iterations", "==", "0", ":", "\n", "# ================== Validation costs ================", "\n", "            ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "batch_mse_test", "=", "torch", ".", "zeros", "(", "\n", "(", "n_features", ",", "len", "(", "test_dataloader", ")", ")", ",", "device", "=", "test_dataloader", ".", "device", "\n", ")", "\n", "for", "batch_idx", ",", "test_sample", "in", "enumerate", "(", "test_dataloader", ")", ":", "\n", "                    ", "data_test", ",", "target_test", "=", "test_sample", "\n", "prediction_test", "=", "model", ".", "func_approx", "(", "data_test", ")", "[", "0", "]", "\n", "batch_mse_test", "[", ":", ",", "batch_idx", "]", "=", "torch", ".", "mean", "(", "\n", "(", "prediction_test", "-", "target_test", ")", "**", "2", ",", "dim", "=", "-", "2", "\n", ")", "# loss per output", "\n", "", "", "mse_test", "=", "batch_mse_test", ".", "cpu", "(", ")", ".", "detach", "(", ")", ".", "mean", "(", "dim", "=", "-", "1", ")", "\n", "# ====================== Logging =======================", "\n", "_", "=", "model", ".", "sparse_estimator", "(", "\n", "thetas", ",", "time_derivs", "\n", ")", "# calculating estimator coeffs but not setting mask", "\n", "logger", "(", "\n", "iteration", ",", "\n", "loss", ".", "view", "(", "-", "1", ")", ".", "mean", "(", ")", ",", "\n", "mse", ".", "view", "(", "-", "1", ")", ",", "\n", "reg", ".", "view", "(", "-", "1", ")", ",", "\n", "model", ".", "constraint_coeffs", "(", "sparse", "=", "True", ",", "scaled", "=", "True", ")", ",", "\n", "model", ".", "constraint_coeffs", "(", "sparse", "=", "True", ",", "scaled", "=", "False", ")", ",", "\n", "model", ".", "estimator_coeffs", "(", ")", ",", "\n", "MSE_test", "=", "mse_test", ",", "\n", ")", "\n", "\n", "# ================== Sparsity update =============", "\n", "# Updating sparsity", "\n", "update_sparsity", "=", "sparsity_scheduler", "(", "\n", "iteration", ",", "torch", ".", "sum", "(", "mse_test", ")", ",", "model", ",", "optimizer", "\n", ")", "\n", "if", "update_sparsity", ":", "\n", "                ", "model", ".", "constraint", ".", "sparsity_masks", "=", "model", ".", "sparse_estimator", "(", "\n", "thetas", ",", "time_derivs", "\n", ")", "\n", "\n", "# ================= Checking convergence", "\n", "", "l1_norm", "=", "torch", ".", "sum", "(", "\n", "torch", ".", "abs", "(", "\n", "torch", ".", "cat", "(", "model", ".", "constraint_coeffs", "(", "sparse", "=", "True", ",", "scaled", "=", "True", ")", ",", "dim", "=", "1", ")", "\n", ")", "\n", ")", "\n", "converged", "=", "convergence", "(", "iteration", ",", "l1_norm", ")", "\n", "if", "converged", ":", "\n", "                ", "break", "\n", "", "", "", "logger", ".", "close", "(", "model", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.PhIMaL_DeePyMoD.training.convergence.Convergence.__init__": [[10, 21], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "patience", ":", "int", "=", "200", ",", "delta", ":", "float", "=", "1e-3", ")", "->", "None", ":", "\n", "        ", "\"\"\"Implements convergence criterium. Convergence is when change in patience\n        epochs is smaller than delta.\n        Args:\n            patience (int): how often to check for convergence\n            delta (float): desired accuracy\n        \"\"\"", "\n", "self", ".", "patience", "=", "patience", "\n", "self", ".", "delta", "=", "delta", "\n", "self", ".", "start_iteration", "=", "None", "\n", "self", ".", "start_l1", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.PhIMaL_DeePyMoD.training.convergence.Convergence.__call__": [[22, 47], ["torch.abs().item", "torch.abs"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "iteration", ":", "int", ",", "l1_norm", ":", "torch", ".", "Tensor", ")", "->", "bool", ":", "\n", "        ", "\"\"\"\n\n        Args:\n            epoch (int): Current epoch of the optimization\n            l1_norm (torch.Tensor): Value of the L1 norm\n        \"\"\"", "\n", "converged", "=", "False", "# overwrite later", "\n", "\n", "# Initialize if doesn't exist", "\n", "if", "self", ".", "start_l1", "is", "None", ":", "\n", "            ", "self", ".", "start_l1", "=", "l1_norm", "\n", "self", ".", "start_iteration", "=", "iteration", "\n", "\n", "# Check if change is smaller than delta and if we've exceeded patience", "\n", "", "elif", "torch", ".", "abs", "(", "self", ".", "start_l1", "-", "l1_norm", ")", ".", "item", "(", ")", "<", "self", ".", "delta", ":", "\n", "            ", "if", "(", "iteration", "-", "self", ".", "start_iteration", ")", ">=", "self", ".", "patience", ":", "\n", "                ", "converged", "=", "True", "\n", "\n", "# If not, reset and keep going", "\n", "", "", "else", ":", "\n", "            ", "self", ".", "start_l1", "=", "l1_norm", "\n", "self", ".", "start_iteration", "=", "iteration", "\n", "\n", "", "return", "converged", "\n", "", "", ""]], "home.repos.pwc.inspect_result.PhIMaL_DeePyMoD.analysis.load_tensorboard.load_tensorboard": [[10, 49], ["pandas.DataFrame", "enumerate", "tensorboard.backend.event_processing.event_accumulator.EventAccumulator().Reload", "enumerate", "os.walk", "EventAccumulator().Reload.Tags", "tag.replace", "tensorboard.backend.event_processing.event_accumulator.EventAccumulator", "os.path.join", "EventAccumulator().Reload.Scalars", "EventAccumulator().Reload.Scalars", "path[].split", "len"], "function", ["None"], ["def", "load_tensorboard", "(", "path", ":", "str", ")", "->", "pd", ".", "DataFrame", ":", "\n", "    ", "\"\"\"Loads tensorboard files into a pandas dataframe. Assumes one run per folder!\n\n    Args:\n        path (string): path of folder with tensorboard files.\n\n    Returns:\n        DataFrame: Pandas dataframe with all run data.\n    \"\"\"", "\n", "\n", "event_paths", "=", "[", "\n", "file", "\n", "for", "file", "in", "os", ".", "walk", "(", "path", ",", "topdown", "=", "True", ")", "\n", "if", "file", "[", "2", "]", "[", "0", "]", "[", ":", "len", "(", "\"events\"", ")", "]", "==", "\"events\"", "\n", "]", "\n", "\n", "df", "=", "pd", ".", "DataFrame", "(", ")", "\n", "steps", "=", "None", "# steps are the same for all files", "\n", "\n", "for", "event_idx", ",", "path", "in", "enumerate", "(", "event_paths", ")", ":", "\n", "        ", "summary_iterator", "=", "EventAccumulator", "(", "os", ".", "path", ".", "join", "(", "path", "[", "0", "]", ",", "path", "[", "2", "]", "[", "0", "]", ")", ")", ".", "Reload", "(", ")", "\n", "tags", "=", "summary_iterator", ".", "Tags", "(", ")", "[", "\"scalars\"", "]", "\n", "data", "=", "[", "\n", "[", "event", ".", "value", "for", "event", "in", "summary_iterator", ".", "Scalars", "(", "tag", ")", "]", "for", "tag", "in", "tags", "\n", "]", "\n", "if", "steps", "is", "None", ":", "\n", "            ", "steps", "=", "[", "event", ".", "step", "for", "event", "in", "summary_iterator", ".", "Scalars", "(", "tags", "[", "0", "]", ")", "]", "\n", "\n", "# Adding to dataframe", "\n", "", "tags", "=", "[", "tag", ".", "replace", "(", "\"/\"", ",", "\"_\"", ")", "for", "tag", "in", "tags", "]", "# for name consistency", "\n", "if", "(", "\n", "event_idx", ">", "0", "\n", ")", ":", "# We have one file in the top level, so after we need to use folder name", "\n", "            ", "tags", "=", "[", "path", "[", "0", "]", ".", "split", "(", "\"/\"", ")", "[", "-", "1", "]", "]", "\n", "\n", "", "for", "idx", ",", "tag", "in", "enumerate", "(", "tags", ")", ":", "\n", "            ", "df", "[", "tag", "]", "=", "data", "[", "idx", "]", "\n", "", "df", ".", "index", "=", "steps", "\n", "", "return", "df", "\n", "", ""]], "home.repos.pwc.inspect_result.PhIMaL_DeePyMoD.data.base.Dataset.__init__": [[14, 87], ["base.Dataset.load", "base.Dataset.preprocess", "print", "len", "len", "base.Dataset.subsampler.sample", "base.Dataset._reshape", "base.Dataset.apply_shuffle", "base.Dataset.coords.to", "base.Dataset.data.to", "len", "len"], "methods", ["home.repos.pwc.inspect_result.PhIMaL_DeePyMoD.data.base.Dataset.preprocess", "home.repos.pwc.inspect_result.PhIMaL_DeePyMoD.data.samples.Subsample_random.sample", "home.repos.pwc.inspect_result.PhIMaL_DeePyMoD.data.base.Dataset._reshape", "home.repos.pwc.inspect_result.PhIMaL_DeePyMoD.data.base.Dataset.apply_shuffle"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "load_function", ",", "\n", "apply_normalize", "=", "None", ",", "\n", "apply_noise", "=", "None", ",", "\n", "apply_shuffle", "=", "None", ",", "\n", "shuffle", "=", "True", ",", "\n", "subsampler", ":", "Subsampler", "=", "None", ",", "\n", "load_kwargs", ":", "dict", "=", "{", "}", ",", "\n", "preprocess_kwargs", ":", "dict", "=", "{", "\n", "\"random_state\"", ":", "42", ",", "\n", "\"noise_level\"", ":", "0.0", ",", "\n", "\"normalize_coords\"", ":", "False", ",", "\n", "\"normalize_data\"", ":", "False", ",", "\n", "}", ",", "\n", "subsampler_kwargs", ":", "dict", "=", "{", "}", ",", "\n", "device", ":", "str", "=", "None", ",", "\n", ")", ":", "\n", "        ", "\"\"\"A dataset class that loads the data, preprocesses it and lastly applies subsampling to it\n\n        Args:\n            load_function (func):Must return torch tensors in the format coordinates, data\n            shuffle (bool, optional): Shuffle the data. Defaults to True.\n            apply_normalize (func)\n            subsampler (Subsampler, optional): Add some subsampling function. Defaults to None.\n            load_kwargs (dict, optional): kwargs to pass to the load_function. Defaults to {}.\n            preprocess_kwargs (dict, optional): (optional) arguments to pass to the preprocess method. Defaults to { \"random_state\": 42, \"noise_level\": 0.0, \"normalize_coords\": False, \"normalize_data\": False, }.\n            subsampler_kwargs (dict, optional): (optional) arguments to pass to the subsampler method. Defaults to {}.\n            device (str, optional): which device to send the data to. Defaults to None.\n        \"\"\"", "\n", "self", ".", "load", "=", "load_function", "\n", "self", ".", "subsampler", "=", "subsampler", "\n", "self", ".", "load_kwargs", "=", "load_kwargs", "\n", "self", ".", "preprocess_kwargs", "=", "preprocess_kwargs", "\n", "self", ".", "subsampler_kwargs", "=", "subsampler_kwargs", "# so total number of samples is size(self.t_domain) * n_samples_per_frame", "\n", "# If some override function is provided, use that instead of the default.", "\n", "if", "apply_normalize", "!=", "None", ":", "\n", "            ", "self", ".", "apply_normalize", "=", "apply_normalize", "\n", "", "if", "apply_noise", "!=", "None", ":", "\n", "            ", "self", ".", "apply_normalize", "=", "apply_noise", "\n", "", "if", "apply_shuffle", "!=", "None", ":", "\n", "            ", "self", ".", "apply_shuffle", "=", "apply_shuffle", "\n", "", "self", ".", "device", "=", "device", "\n", "self", ".", "shuffle", "=", "shuffle", "\n", "self", ".", "coords", ",", "self", ".", "data", "=", "self", ".", "load", "(", "**", "self", ".", "load_kwargs", ")", "\n", "# Ensure the data that loaded is not 0D/1D", "\n", "assert", "(", "\n", "len", "(", "self", ".", "coords", ".", "shape", ")", ">=", "2", "\n", ")", ",", "\"Please explicitely specify a feature axis for the coordinates\"", "\n", "assert", "(", "\n", "len", "(", "self", ".", "data", ".", "shape", ")", ">=", "2", "\n", ")", ",", "\"Please explicitely specify a feature axis for the data\"", "\n", "# Preprocess (add noise and normalization)", "\n", "self", ".", "coords", ",", "self", ".", "data", "=", "self", ".", "preprocess", "(", "\n", "self", ".", "coords", ",", "self", ".", "data", ",", "**", "self", ".", "preprocess_kwargs", "\n", ")", "\n", "# Apply the subsampler if there is one", "\n", "if", "self", ".", "subsampler", ":", "\n", "            ", "self", ".", "coords", ",", "self", ".", "data", "=", "self", ".", "subsampler", ".", "sample", "(", "\n", "self", ".", "coords", ",", "self", ".", "data", ",", "**", "self", ".", "subsampler_kwargs", "\n", ")", "\n", "# Reshaping the data to a (number_of_samples, number_of_features) shape if needed", "\n", "", "if", "len", "(", "self", ".", "data", ".", "shape", ")", "!=", "2", "or", "len", "(", "self", ".", "coords", ".", "shape", ")", "!=", "2", ":", "\n", "            ", "self", ".", "coords", ",", "self", ".", "data", "=", "self", ".", "_reshape", "(", "self", ".", "coords", ",", "self", ".", "data", ")", "\n", "", "if", "self", ".", "shuffle", ":", "\n", "            ", "self", ".", "coords", ",", "self", ".", "data", "=", "self", ".", "apply_shuffle", "(", "self", ".", "coords", ",", "self", ".", "data", ")", "\n", "# Now we know the data are shape (number_of_samples, number_of_features) we can set the number_of_samples", "\n", "", "self", ".", "number_of_samples", "=", "self", ".", "data", ".", "shape", "[", "0", "]", "\n", "\n", "print", "(", "\"Dataset is using device: \"", ",", "self", ".", "device", ")", "\n", "if", "self", ".", "device", ":", "\n", "            ", "self", ".", "coords", "=", "self", ".", "coords", ".", "to", "(", "self", ".", "device", ")", "\n", "self", ".", "data", "=", "self", ".", "data", ".", "to", "(", "self", ".", "device", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.PhIMaL_DeePyMoD.data.base.Dataset.__len__": [[89, 92], ["None"], "methods", ["None"], ["", "", "def", "__len__", "(", "self", ")", "->", "int", ":", "\n", "        ", "\"\"\"Returns length of dataset. Required by pytorch\"\"\"", "\n", "return", "self", ".", "number_of_samples", "\n", "\n"]], "home.repos.pwc.inspect_result.PhIMaL_DeePyMoD.data.base.Dataset.__getitem__": [[93, 96], ["None"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "idx", ":", "int", ")", "->", "int", ":", "\n", "        ", "\"\"\"Returns coordinate and value. First axis of coordinate should be time.\"\"\"", "\n", "return", "self", ".", "coords", "[", "idx", "]", ",", "self", ".", "data", "[", "idx", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.PhIMaL_DeePyMoD.data.base.Dataset.get_coords": [[98, 101], ["None"], "methods", ["None"], ["", "def", "get_coords", "(", "self", ")", ":", "\n", "        ", "\"\"\"Retrieve all the coordinate features\"\"\"", "\n", "return", "self", ".", "coords", "\n", "\n"]], "home.repos.pwc.inspect_result.PhIMaL_DeePyMoD.data.base.Dataset.get_data": [[102, 105], ["None"], "methods", ["None"], ["", "def", "get_data", "(", "self", ")", ":", "\n", "        ", "\"\"\"Retrieve all the data features\"\"\"", "\n", "return", "self", ".", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.PhIMaL_DeePyMoD.data.base.Dataset.preprocess": [[107, 139], ["base.Dataset.apply_noise", "base.Dataset.apply_normalize", "base.Dataset.apply_normalize"], "methods", ["home.repos.pwc.inspect_result.PhIMaL_DeePyMoD.data.base.Dataset.apply_noise", "home.repos.pwc.inspect_result.PhIMaL_DeePyMoD.data.base.Dataset.apply_normalize", "home.repos.pwc.inspect_result.PhIMaL_DeePyMoD.data.base.Dataset.apply_normalize"], ["", "def", "preprocess", "(", "\n", "self", ",", "\n", "X", ":", "torch", ".", "tensor", ",", "\n", "y", ":", "torch", ".", "tensor", ",", "\n", "random_state", ":", "int", "=", "42", ",", "\n", "noise_level", ":", "float", "=", "0.0", ",", "\n", "normalize_coords", ":", "bool", "=", "False", ",", "\n", "normalize_data", ":", "bool", "=", "False", ",", "\n", ")", ":", "\n", "        ", "\"\"\"Add noise to the data and normalize the features\n        Arguments:\n            X (torch.tensor) : coordinates of the dataset\n            y (torch.tensor) : values of the dataset\n            random_state (int) : state for random number geerator\n            noise (float) : standard deviations of noise to add\n            normalize_coords (bool): apply normalization to the coordinates\n            normalize_data (bool): apply normalization to the data\n        \"\"\"", "\n", "\n", "# add noise", "\n", "y_processed", "=", "y", "+", "self", ".", "apply_noise", "(", "y", ",", "noise_level", ",", "random_state", ")", "\n", "# normalize coordinates", "\n", "if", "normalize_coords", ":", "\n", "            ", "X_processed", "=", "self", ".", "apply_normalize", "(", "X", ")", "\n", "", "else", ":", "\n", "            ", "X_processed", "=", "X", "\n", "# normalize data", "\n", "", "if", "normalize_data", ":", "\n", "            ", "y_processed", "=", "self", ".", "apply_normalize", "(", "y_processed", ")", "\n", "", "else", ":", "\n", "            ", "y_processed", "=", "y", "\n", "", "return", "X_processed", ",", "y_processed", "\n", "\n"]], "home.repos.pwc.inspect_result.PhIMaL_DeePyMoD.data.base.Dataset.apply_noise": [[140, 154], ["torch.tensor", "torch.std", "numpy.random.default_rng().normal", "numpy.random.default_rng"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "apply_noise", "(", "y", ",", "noise_level", ",", "random_state", ")", ":", "\n", "        ", "\"\"\"Adds gaussian white noise of noise_level standard deviation.\n        Args:\n            y (torch.tensor): the data to which noise should be added\n            noise_level (float): add white noise as a function of standard deviation\n            random_state (int): the random state used for random number generation\n        \"\"\"", "\n", "noise", "=", "noise_level", "*", "torch", ".", "std", "(", "y", ")", ".", "data", "\n", "y_noisy", "=", "y", "+", "torch", ".", "tensor", "(", "\n", "default_rng", "(", "random_state", ")", ".", "normal", "(", "loc", "=", "0.0", ",", "scale", "=", "noise", ",", "size", "=", "y", ".", "shape", ")", ",", "\n", "dtype", "=", "torch", ".", "float32", ",", "\n", ")", "# TO DO: switch to pytorch rng", "\n", "return", "y_noisy", "\n", "\n"]], "home.repos.pwc.inspect_result.PhIMaL_DeePyMoD.data.base.Dataset.apply_normalize": [[155, 167], ["X.view().min", "X.view().max", "X.view().min", "X.view", "X.view", "X.view"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "apply_normalize", "(", "X", ")", ":", "\n", "        ", "\"\"\"minmax Normalize the data along the zeroth axis. Per feature\n        Args:\n            X (torch.tensor): data to be minmax normalized\n        Returns:\n            (torch.tensor): minmaxed data\"\"\"", "\n", "X_norm", "=", "(", "X", "-", "X", ".", "view", "(", "-", "1", ",", "X", ".", "shape", "[", "-", "1", "]", ")", ".", "min", "(", "dim", "=", "0", ")", ".", "values", ")", "/", "(", "\n", "X", ".", "view", "(", "-", "1", ",", "X", ".", "shape", "[", "-", "1", "]", ")", ".", "max", "(", "dim", "=", "0", ")", ".", "values", "\n", "-", "X", ".", "view", "(", "-", "1", ",", "X", ".", "shape", "[", "-", "1", "]", ")", ".", "min", "(", "dim", "=", "0", ")", ".", "values", "\n", ")", "*", "2", "-", "1", "\n", "return", "X_norm", "\n", "\n"]], "home.repos.pwc.inspect_result.PhIMaL_DeePyMoD.data.base.Dataset.apply_shuffle": [[168, 173], ["numpy.random.permutation", "numpy.arange", "len"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "apply_shuffle", "(", "coords", ",", "data", ")", ":", "\n", "        ", "\"\"\"Shuffle the coordinates and data\"\"\"", "\n", "permutation", "=", "np", ".", "random", ".", "permutation", "(", "np", ".", "arange", "(", "len", "(", "data", ")", ")", ")", "\n", "return", "coords", "[", "permutation", "]", ",", "data", "[", "permutation", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.PhIMaL_DeePyMoD.data.base.Dataset._reshape": [[174, 180], ["coords.reshape.reshape.reshape", "data.reshape.reshape.reshape"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_reshape", "(", "coords", ",", "data", ")", ":", "\n", "        ", "\"\"\"Reshape the coordinates and data to the format [number_of_samples, number_of_features]\"\"\"", "\n", "coords", "=", "coords", ".", "reshape", "(", "[", "-", "1", ",", "coords", ".", "shape", "[", "-", "1", "]", "]", ")", "\n", "data", "=", "data", ".", "reshape", "(", "[", "-", "1", ",", "data", ".", "shape", "[", "-", "1", "]", "]", ")", "\n", "return", "coords", ",", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.PhIMaL_DeePyMoD.data.base.Loader.__init__": [[183, 193], ["isinstance"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "dataset", ")", ":", "\n", "        ", "\"\"\"Loader created to follow the workflow of PyTorch Dataset and Dataloader\n        Leaves all data where it currently is.\"\"\"", "\n", "if", "isinstance", "(", "dataset", ",", "torch", ".", "utils", ".", "data", ".", "Subset", ")", ":", "\n", "            ", "self", ".", "device", "=", "dataset", ".", "dataset", ".", "device", "\n", "", "else", ":", "\n", "            ", "self", ".", "device", "=", "dataset", ".", "device", "\n", "", "self", ".", "dataset", "=", "dataset", "\n", "self", ".", "_count", "=", "0", "\n", "self", ".", "_length", "=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.PhIMaL_DeePyMoD.data.base.Loader.__getitem__": [[194, 199], ["None"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "idx", ")", ":", "\n", "        ", "if", "idx", "<", "self", ".", "_length", ":", "\n", "            ", "return", "self", ".", "dataset", "[", ":", "]", "\n", "", "else", ":", "\n", "            ", "raise", "StopIteration", "\n", "\n"]], "home.repos.pwc.inspect_result.PhIMaL_DeePyMoD.data.base.Loader.__len__": [[200, 202], ["None"], "methods", ["None"], ["", "", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_length", "\n", "\n"]], "home.repos.pwc.inspect_result.PhIMaL_DeePyMoD.data.base.get_train_test_loader": [[204, 228], ["numpy.arange", "numpy.random.shuffle", "int", "torch.utils.data.Subset", "torch.utils.data.Subset", "loader", "loader"], "function", ["None"], ["", "", "def", "get_train_test_loader", "(", "\n", "dataset", ",", "train_test_split", "=", "0.8", ",", "loader", "=", "Loader", ",", "loader_kwargs", "=", "{", "}", "\n", ")", ":", "\n", "    ", "\"\"\"Take a dataset, shuffle it, split it into a train and test and then\n    return two loaders that are compatible with PyTorch.\n\n    Args:\n        dataset (torch.utils.data.Dataset): The dataset to use\n        train_test_split (float, optional): The fraction of data used for train. Defaults to 0.8.\n        loader (torch.utils.data.Dataloader, optional): The type of Dataloader to use. Defaults to GPULoader.\n        loader_kwargs (dict, optional): Any kwargs to be passed to the loader]. Defaults to {}.\n\n    Returns:\n        Dataloader, Dataloader: The train and test dataloader\n    \"\"\"", "\n", "length", "=", "dataset", ".", "number_of_samples", "\n", "indices", "=", "np", ".", "arange", "(", "0", ",", "length", ",", "dtype", "=", "int", ")", "\n", "np", ".", "random", ".", "shuffle", "(", "indices", ")", "\n", "split", "=", "int", "(", "train_test_split", "*", "length", ")", "\n", "train_indices", "=", "indices", "[", ":", "split", "]", "\n", "test_indices", "=", "indices", "[", "split", ":", "]", "\n", "train_data", "=", "torch", ".", "utils", ".", "data", ".", "Subset", "(", "dataset", ",", "train_indices", ")", "\n", "test_data", "=", "torch", ".", "utils", ".", "data", ".", "Subset", "(", "dataset", ",", "test_indices", ")", "\n", "return", "loader", "(", "train_data", ",", "**", "loader_kwargs", ")", ",", "loader", "(", "test_data", ",", "**", "loader_kwargs", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.PhIMaL_DeePyMoD.data.examples.sinc_2d": [[6, 20], ["numpy.linspace", "numpy.linspace", "numpy.meshgrid", "numpy.sinc", "torch.tensor", "torch.tensor().unsqueeze", "numpy.stack", "torch.tensor"], "function", ["None"], ["def", "sinc_2d", "(", ")", ":", "\n", "    ", "\"\"\"Output: Grid[N x M x L],  Data[N x M x O],\n    N = Coordinate dimension 0\n    M = Coordinate dimension 1\n    L = Input data dimension\n    O = Output data dimension\n    \"\"\"", "\n", "x0", "=", "np", ".", "linspace", "(", "0", ",", "2", "*", "np", ".", "pi", ",", "100", ")", "\n", "x1", "=", "np", ".", "linspace", "(", "-", "np", ".", "pi", ",", "np", ".", "pi", ",", "100", ")", "\n", "X0", ",", "X1", "=", "np", ".", "meshgrid", "(", "x0", ",", "x1", ")", "\n", "y", "=", "np", ".", "sinc", "(", "X0", "*", "X1", ")", "\n", "coords", "=", "torch", ".", "tensor", "(", "np", ".", "stack", "(", "(", "X0", ",", "X1", ")", ")", ")", "\n", "data", "=", "torch", ".", "tensor", "(", "y", ")", ".", "unsqueeze", "(", "0", ")", "\n", "return", "coords", ",", "data", "\n", "", ""]], "home.repos.pwc.inspect_result.PhIMaL_DeePyMoD.data.samples.Subsampler.sample": [[9, 12], ["None"], "methods", ["None"], ["    ", "@", "abstractmethod", "\n", "def", "sample", "(", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.PhIMaL_DeePyMoD.data.samples.Subsample_time.sample": [[15, 24], ["torch.linspace"], "methods", ["None"], ["    ", "@", "staticmethod", "\n", "def", "sample", "(", "coords", ",", "data", ",", "number_of_slices", ")", ":", "\n", "        ", "\"\"\"Subsample on the time axis for that has shape [t,x,y,z,...,feature] for both data and features.\"\"\"", "\n", "# getting indices of samples", "\n", "x_idx", "=", "torch", ".", "linspace", "(", "\n", "0", ",", "coords", ".", "shape", "[", "0", "]", "-", "1", ",", "number_of_slices", ",", "dtype", "=", "torch", ".", "long", "\n", ")", "# getting x locations", "\n", "# getting sample locations from indices", "\n", "return", "coords", "[", "x_idx", "]", ",", "data", "[", "x_idx", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.PhIMaL_DeePyMoD.data.samples.Subsample_axis.sample": [[27, 38], ["torch.linspace", "torch.index_select", "torch.index_select"], "methods", ["None"], ["    ", "@", "staticmethod", "\n", "def", "sample", "(", "coords", ",", "data", ",", "axis", ",", "number_of_slices", ")", ":", "\n", "        ", "\"\"\"Subsample on the specified axis to the number of slices specified\"\"\"", "\n", "# getting indices of samples", "\n", "feature_idx", "=", "torch", ".", "linspace", "(", "\n", "0", ",", "coords", ".", "shape", "[", "axis", "]", "-", "1", ",", "number_of_slices", ",", "dtype", "=", "torch", ".", "long", "\n", ")", "# getting x locations", "\n", "# use the indices to subsample along the axis", "\n", "subsampled_coords", "=", "torch", ".", "index_select", "(", "coords", ",", "axis", ",", "feature_idx", ")", "\n", "subsampled_data", "=", "torch", ".", "index_select", "(", "data", ",", "axis", ",", "feature_idx", ")", "\n", "return", "subsampled_coords", ",", "subsampled_data", "\n", "\n"]], "home.repos.pwc.inspect_result.PhIMaL_DeePyMoD.data.samples.Subsample_shifted_grid.sample": [[42, 45], ["None"], "methods", ["None"], ["    ", "@", "staticmethod", "\n", "def", "sample", "(", "coords", ",", "data", ",", "number_of_samples", ")", ":", "\n", "        ", "return", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.PhIMaL_DeePyMoD.data.samples.Subsample_random.sample": [[48, 64], ["coords.reshape.reshape.reshape", "data.reshape.reshape.reshape", "torch.randperm", "len", "len"], "methods", ["None"], ["    ", "@", "staticmethod", "\n", "def", "sample", "(", "coords", ",", "data", ",", "number_of_samples", ")", ":", "\n", "        ", "\"\"\"Apply random subsampling to a dataset, if it is not already in the\n        (number_of_samples, number_of features) format, reshape it to it.\"\"\"", "\n", "# Ensure that both are of the shape (number_of_samples, number_of_features) before random sampling.", "\n", "if", "len", "(", "data", ".", "shape", ")", ">", "2", "or", "len", "(", "coords", ".", "shape", ")", ">", "2", ":", "\n", "            ", "coords", "=", "coords", ".", "reshape", "(", "(", "-", "1", ",", "coords", ".", "shape", "[", "-", "1", "]", ")", ")", "\n", "data", "=", "data", ".", "reshape", "(", "(", "-", "1", ",", "data", ".", "shape", "[", "-", "1", "]", ")", ")", "\n", "# getting indices of samples", "\n", "", "x_idx", "=", "torch", ".", "randperm", "(", "coords", ".", "shape", "[", "0", "]", ")", "[", "\n", ":", "number_of_samples", "\n", "]", "# getting x locations", "\n", "# getting sample locations from indices", "\n", "subsampled_coords", "=", "coords", "[", "x_idx", "]", "\n", "subsampled_data", "=", "data", "[", "x_idx", "]", "\n", "return", "subsampled_coords", ",", "subsampled_data", "\n", "", "", ""]], "home.repos.pwc.inspect_result.PhIMaL_DeePyMoD.kdv.kdv.single_soliton": [[10, 27], ["torch.cat", "u.view", "numpy.sqrt", "torch.cosh", "t.reshape", "x.reshape"], "function", ["None"], ["def", "single_soliton", "(", "\n", "x", ":", "torch", ".", "tensor", ",", "t", ":", "torch", ".", "tensor", ",", "c", ":", "float", ",", "x0", ":", "float", "\n", ")", "->", "torch", ".", "tensor", ":", "\n", "    ", "\"\"\"Single soliton solution of the KdV equation (u_t + u_{xxx} - 6 u u_x = 0)\n\n    Args:\n        x ([Tensor]): Input vector of spatial coordinates.\n        t ([Tensor]): Input vector of temporal coordinates.\n        c ([Float]): Velocity.\n        x0 ([Float]): Offset.\n    Returns:\n        [Tensor]: Solution.\n    \"\"\"", "\n", "xi", "=", "np", ".", "sqrt", "(", "c", ")", "/", "2", "*", "(", "x", "-", "c", "*", "t", "-", "x0", ")", "# switch to moving coordinate frame", "\n", "u", "=", "c", "/", "2", "*", "1", "/", "torch", ".", "cosh", "(", "xi", ")", "**", "2", "\n", "coords", "=", "torch", ".", "cat", "(", "(", "t", ".", "reshape", "(", "-", "1", ",", "1", ")", ",", "x", ".", "reshape", "(", "-", "1", ",", "1", ")", ")", ",", "dim", "=", "1", ")", "\n", "return", "coords", ",", "u", ".", "view", "(", "-", "1", ",", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.PhIMaL_DeePyMoD.kdv.kdv.double_soliton": [[29, 58], ["torch.cat", "torch.cosh", "torch.cosh", "u.view", "numpy.sqrt", "numpy.sqrt", "numpy.sqrt", "numpy.sqrt", "numpy.sqrt", "numpy.sqrt", "t.reshape", "x.reshape", "torch.cosh", "torch.sinh"], "function", ["None"], ["", "def", "double_soliton", "(", "\n", "x", ":", "torch", ".", "tensor", ",", "t", ":", "torch", ".", "tensor", ",", "c", ":", "float", ",", "x0", ":", "float", "\n", ")", "->", "torch", ".", "tensor", ":", "\n", "    ", "\"\"\"Single soliton solution of the KdV equation (u_t + u_{xxx} - 6 u u_x = 0)\n    source: http://lie.math.brocku.ca/~sanco/solitons/kdv_solitons.php\n\n    Args:\n        x ([Tensor]): Input vector of spatial coordinates.\n        t ([Tensor]): Input vector of temporal coordinates.\n        c ([Array]): Array containing the velocities of the two solitons, note that c[0] > c[1].\n        x0 ([Array]):  Array containing the offsets of the two solitons.\n\n    Returns:\n        [Tensor]: Solution.\n    \"\"\"", "\n", "assert", "c", "[", "0", "]", ">", "c", "[", "1", "]", ",", "\"c1 has to be bigger than c[2]\"", "\n", "\n", "xi0", "=", "(", "\n", "np", ".", "sqrt", "(", "c", "[", "0", "]", ")", "/", "2", "*", "(", "x", "-", "c", "[", "0", "]", "*", "t", "-", "x0", "[", "0", "]", ")", "\n", ")", "#  switch to moving coordinate frame", "\n", "xi1", "=", "np", ".", "sqrt", "(", "c", "[", "1", "]", ")", "/", "2", "*", "(", "x", "-", "c", "[", "1", "]", "*", "t", "-", "x0", "[", "1", "]", ")", "\n", "\n", "part_1", "=", "2", "*", "(", "c", "[", "0", "]", "-", "c", "[", "1", "]", ")", "\n", "numerator", "=", "c", "[", "0", "]", "*", "torch", ".", "cosh", "(", "xi1", ")", "**", "2", "+", "c", "[", "1", "]", "*", "torch", ".", "sinh", "(", "xi0", ")", "**", "2", "\n", "denominator_1", "=", "(", "np", ".", "sqrt", "(", "c", "[", "0", "]", ")", "-", "np", ".", "sqrt", "(", "c", "[", "1", "]", ")", ")", "*", "torch", ".", "cosh", "(", "xi0", "+", "xi1", ")", "\n", "denominator_2", "=", "(", "np", ".", "sqrt", "(", "c", "[", "0", "]", ")", "+", "np", ".", "sqrt", "(", "c", "[", "1", "]", ")", ")", "*", "torch", ".", "cosh", "(", "xi0", "-", "xi1", ")", "\n", "u", "=", "part_1", "*", "numerator", "/", "(", "denominator_1", "+", "denominator_2", ")", "**", "2", "\n", "coords", "=", "torch", ".", "cat", "(", "(", "t", ".", "reshape", "(", "-", "1", ",", "1", ")", ",", "x", ".", "reshape", "(", "-", "1", ",", "1", ")", ")", ",", "dim", "=", "1", ")", "\n", "return", "coords", ",", "u", ".", "view", "(", "-", "1", ",", "1", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.PhIMaL_DeePyMoD.burgers.burgers.burgers_delta": [[12, 38], ["torch.meshgrid", "torch.tensor", "torch.cat", "torch.sqrt", "u.view", "torch.sqrt", "t.reshape", "x.reshape", "torch.exp", "torch.erfc", "torch.exp", "torch.exp"], "function", ["None"], ["def", "burgers_delta", "(", "x", ":", "torch", ".", "tensor", ",", "t", ":", "torch", ".", "tensor", ",", "v", ":", "float", ",", "A", ":", "float", ")", ":", "\n", "    ", "\"\"\"Function to load the analytical solutions of Burgers equation with delta peak initial condition: u(x, 0) = A delta(x)\n\n    Source: https://www.iist.ac.in/sites/default/files/people/IN08026/Burgers_equation_viscous.pdf\n    Note that this source has an error in the erfc prefactor, should be sqrt(pi)/2, not sqrt(pi/2).\n\n    Args:\n        x ([Tensor]): Input vector of spatial coordinates.\n        t ([Tensor]): Input vector of temporal coordinates.\n        v (Float): Velocity.\n        A (Float): Amplitude of the initial condition.\n\n    Returns:\n        [Tensor]: solution.\n    \"\"\"", "\n", "x", ",", "t", "=", "torch", ".", "meshgrid", "(", "x", ",", "t", ")", "\n", "R", "=", "torch", ".", "tensor", "(", "A", "/", "(", "2", "*", "v", ")", ")", "# otherwise throws error", "\n", "z", "=", "x", "/", "torch", ".", "sqrt", "(", "4", "*", "v", "*", "t", ")", "\n", "\n", "u", "=", "(", "\n", "torch", ".", "sqrt", "(", "v", "/", "(", "pi", "*", "t", ")", ")", "\n", "*", "(", "(", "torch", ".", "exp", "(", "R", ")", "-", "1", ")", "*", "torch", ".", "exp", "(", "-", "(", "z", "**", "2", ")", ")", ")", "\n", "/", "(", "1", "+", "(", "torch", ".", "exp", "(", "R", ")", "-", "1", ")", "/", "2", "*", "torch", ".", "erfc", "(", "z", ")", ")", "\n", ")", "\n", "coords", "=", "torch", ".", "cat", "(", "(", "t", ".", "reshape", "(", "-", "1", ",", "1", ")", ",", "x", ".", "reshape", "(", "-", "1", ",", "1", ")", ")", ",", "dim", "=", "1", ")", "\n", "return", "coords", ",", "u", ".", "view", "(", "-", "1", ",", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.PhIMaL_DeePyMoD.burgers.burgers.burgers_cos": [[40, 67], ["torch.cat", "u.view", "torch.sin", "t.reshape", "x.reshape", "torch.exp", "torch.cos", "torch.exp"], "function", ["None"], ["", "def", "burgers_cos", "(", "\n", "x", ":", "torch", ".", "tensor", ",", "t", ":", "torch", ".", "tensor", ",", "v", ":", "float", ",", "a", ":", "float", ",", "b", ":", "float", ",", "k", ":", "float", "\n", ")", ":", "\n", "    ", "\"\"\"Function to generate analytical solutions of Burgers equation with cosine initial condition:\n    $u(x, 0) = b + a \\cos(kx)$\n\n    Source: https://www.iist.ac.in/sites/default/files/people/IN08026/Burgers_equation_viscous.pdf\n\n    Args:\n        x ([Tensor]): Input vector of spatial coordinates.\n        t ([Tensor]): Input vector of temporal coordinates.\n        v (Float): Velocity.\n        a ([Float]): Amplitude of the initial periodic condition.\n        b ([Float]): Offset of the initial condition.\n        k ([Float]): Wavenumber of the initial condition.\n\n    Returns:\n        [Tensor]: solution.\n    \"\"\"", "\n", "\n", "z", "=", "v", "*", "k", "**", "2", "*", "t", "\n", "\n", "u", "=", "(", "2", "*", "v", "*", "a", "*", "k", "*", "torch", ".", "exp", "(", "-", "z", ")", "*", "torch", ".", "sin", "(", "k", "*", "x", ")", ")", "/", "(", "\n", "b", "+", "a", "*", "torch", ".", "exp", "(", "-", "z", ")", "*", "torch", ".", "cos", "(", "k", "*", "x", ")", "\n", ")", "\n", "coords", "=", "torch", ".", "cat", "(", "(", "t", ".", "reshape", "(", "-", "1", ",", "1", ")", ",", "x", ".", "reshape", "(", "-", "1", ",", "1", ")", ")", ",", "dim", "=", "1", ")", "\n", "return", "coords", ",", "u", ".", "view", "(", "-", "1", ",", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.PhIMaL_DeePyMoD.burgers.burgers.burgers_sawtooth": [[69, 95], ["torch.cat", "torch.exp", "torch.exp", "u.view", "torch.exp", "torch.exp", "t.reshape", "x.reshape"], "function", ["None"], ["", "def", "burgers_sawtooth", "(", "x", ":", "torch", ".", "tensor", ",", "t", ":", "torch", ".", "tensor", ",", "v", ":", "float", ")", "->", "torch", ".", "tensor", ":", "\n", "    ", "\"\"\"Function to generate analytical solutions of Burgers equation with sawtooth initial condition (see soruce for exact expression). Solution only\n    valid between for x in [0, 2pi] and t in [0, 0.5]\n\n    http://www.thevisualroom.com/02_barba_projects/burgers_equation.html\n\n    Args:\n        x ([Tensor]): Input vector of spatial coordinates.\n        t ([Tensor]): Input vector of temporal coordinates.\n        v (Float): Velocity.\n\n    Returns:\n        [Tensor]: solution.\n    \"\"\"", "\n", "\n", "z_left", "=", "x", "-", "4", "*", "t", "\n", "z_right", "=", "x", "-", "4", "*", "t", "-", "2", "*", "pi", "\n", "l", "=", "4", "*", "v", "*", "(", "t", "+", "1", ")", "\n", "\n", "phi", "=", "torch", ".", "exp", "(", "-", "(", "z_left", "**", "2", ")", "/", "l", ")", "+", "torch", ".", "exp", "(", "-", "(", "z_right", "**", "2", ")", "/", "l", ")", "\n", "dphi_x", "=", "-", "2", "*", "z_left", "/", "l", "*", "torch", ".", "exp", "(", "\n", "-", "(", "z_left", "**", "2", ")", "/", "l", "\n", ")", "-", "2", "*", "z_right", "/", "l", "*", "torch", ".", "exp", "(", "-", "(", "z_right", "**", "2", ")", "/", "l", ")", "\n", "u", "=", "-", "2", "*", "v", "*", "dphi_x", "/", "phi", "+", "4", "\n", "coords", "=", "torch", ".", "cat", "(", "(", "t", ".", "reshape", "(", "-", "1", ",", "1", ")", ",", "x", ".", "reshape", "(", "-", "1", ",", "1", ")", ")", ",", "dim", "=", "1", ")", "\n", "return", "coords", ",", "u", ".", "view", "(", "-", "1", ",", "1", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.PhIMaL_DeePyMoD.diffusion.diffusion.diffusion_gaussian": [[10, 32], ["torch.cat", "torch.exp", "u.view", "t.reshape", "x.reshape"], "function", ["None"], ["def", "diffusion_gaussian", "(", "\n", "x", ":", "torch", ".", "tensor", ",", "t", ":", "torch", ".", "tensor", ",", "D", ":", "float", ",", "x0", ":", "float", ",", "sigma", ":", "float", "\n", ")", "->", "torch", ".", "tensor", ":", "\n", "    ", "\"\"\"Function to generate the solution to the 1D diffusion equation.\n\n    REFERENCE\n\n    Args:\n        x ([Tensor]): Input vector of spatial coordinates.\n        t ([Tensor]): Input vector of temporal coordinates.\n        D (Float): Diffusion coefficient\n        x0 (Float): Spatial coordinate where the gaussian is centered\n        sigma (Float): Scale parameter that adjusts the initial shape of the parameter\n\n    Returns:\n        [Tensor]: solution.\n    \"\"\"", "\n", "u", "=", "(", "2", "*", "pi", "*", "sigma", "**", "2", "+", "4", "*", "pi", "*", "D", "*", "t", ")", "**", "(", "-", "1", "/", "2", ")", "*", "torch", ".", "exp", "(", "\n", "-", "(", "(", "x", "-", "x0", ")", "**", "2", ")", "/", "(", "2", "*", "sigma", "**", "2", "+", "4", "*", "D", "*", "t", ")", "\n", ")", "\n", "coords", "=", "torch", ".", "cat", "(", "(", "t", ".", "reshape", "(", "-", "1", ",", "1", ")", ",", "x", ".", "reshape", "(", "-", "1", ",", "1", ")", ")", ",", "dim", "=", "1", ")", "\n", "return", "coords", ",", "u", ".", "view", "(", "-", "1", ",", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.PhIMaL_DeePyMoD.diffusion.diffusion.advection_diffusion_gaussian_2d": [[34, 63], ["torch.cat", "torch.exp", "u.view", "t.reshape", "x.reshape"], "function", ["None"], ["", "def", "advection_diffusion_gaussian_2d", "(", "\n", "x", ":", "torch", ".", "tensor", ",", "\n", "t", ":", "torch", ".", "tensor", ",", "\n", "D", ":", "float", ",", "\n", "x0", ":", "torch", ".", "tensor", ",", "\n", "sigma", ":", "float", ",", "\n", "v", ":", "torch", ".", "tensor", ",", "\n", ")", "->", "torch", ".", "tensor", ":", "\n", "    ", "\"\"\"Function to generate the solution to the 2D diffusion equation.\n\n    REFERENCE\n\n    Args:\n        x ([Tensor]): [N, 2] Input vector of spatial coordinates.\n        t ([Tensor]): Input vector of temporal coordinates.\n        D (Float): Diffusion coefficient\n        x0 ([Tensor]): Spatial coordinate where the gaussian is centered\n        sigma (Float): Scale parameter that adjusts the initial shape of the parameter\n        v ([Tensor]): [2] Initial velocity of the gaussian.\n\n    Returns:\n        [Tensor]: solution.\n    \"\"\"", "\n", "u", "=", "(", "2", "*", "pi", "*", "sigma", "**", "2", "+", "4", "*", "pi", "*", "D", "*", "t", ")", "**", "(", "-", "1", ")", "*", "torch", ".", "exp", "(", "\n", "-", "(", "(", "x", "[", ":", ",", "0", ":", "1", "]", "-", "x0", "[", "0", "]", "-", "v", "[", "0", "]", "*", "t", ")", "**", "2", "+", "(", "x", "[", ":", ",", "1", ":", "2", "]", "-", "x0", "[", "1", "]", "-", "v", "[", "1", "]", "*", "t", ")", "**", "2", ")", "\n", "/", "(", "2", "*", "sigma", "**", "2", "+", "4", "*", "D", "*", "t", ")", "\n", ")", "\n", "coords", "=", "torch", ".", "cat", "(", "(", "t", ".", "reshape", "(", "-", "1", ",", "1", ")", ",", "x", ".", "reshape", "(", "-", "1", ",", "2", ")", ")", ",", "dim", "=", "1", ")", "\n", "return", "coords", ",", "u", ".", "view", "(", "-", "1", ",", "1", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.PhIMaL_DeePyMoD.examples.VE_datagen.calculate_strain_stress": [[5, 55], ["VE_datagen.relax_creep", "numpy.array", "numpy.array", "strain_array.reshape.reshape", "stress_array.reshape.reshape", "integral_lambda", "numpy.append", "numpy.append", "relax_creep.", "D_input_lambda", "scipy.quad", "input_lambda", "relax_creep.", "input_lambda"], "function", ["home.repos.pwc.inspect_result.PhIMaL_DeePyMoD.examples.VE_datagen.relax_creep"], ["def", "calculate_strain_stress", "(", "\n", "input_type", ",", "time_array", ",", "input_expr", ",", "E_mods", ",", "viscs", ",", "D_input_lambda", "=", "None", "\n", ")", ":", "\n", "# In this incarnation, the kwarg is non-optional.", "\n", "\n", "#     if D_input_lambda:", "\n", "    ", "input_lambda", "=", "input_expr", "\n", "#     else:", "\n", "#         t = sym.symbols('t', real=True)", "\n", "#         D_input_expr = input_expr.diff(t)", "\n", "\n", "#         input_lambda = sym.lambdify(t, input_expr)", "\n", "#         D_input_lambda = sym.lambdify(t, D_input_expr)", "\n", "\n", "# The following function interprets the provided model parameters differently depending on the input_type.", "\n", "# If the input_type is 'Strain' then the parameters are assumed to refer to a Maxwell model, whereas", "\n", "# if the input_type is 'Stress' then the parameters are assumed to refer to a Kelvin model.", "\n", "relax_creep_lambda", "=", "relax_creep", "(", "E_mods", ",", "viscs", ",", "input_type", ")", "\n", "\n", "if", "relax_creep_lambda", "==", "False", ":", "\n", "        ", "return", "False", ",", "False", "\n", "\n", "", "start_time_point", "=", "time_array", "[", "0", "]", "\n", "\n", "integrand_lambda", "=", "lambda", "x", ",", "t", ":", "relax_creep_lambda", "(", "t", "-", "x", ")", "*", "D_input_lambda", "(", "x", ")", "\n", "integral_lambda", "=", "lambda", "t", ":", "integ", ".", "quad", "(", "\n", "integrand_lambda", ",", "start_time_point", ",", "t", ",", "args", "=", "(", "t", ")", "\n", ")", "[", "0", "]", "\n", "\n", "output_array", "=", "np", ".", "array", "(", "[", "]", ")", "\n", "input_array", "=", "np", ".", "array", "(", "[", "]", ")", "\n", "for", "time_point", "in", "time_array", ":", "\n", "        ", "first_term", "=", "input_lambda", "(", "start_time_point", ")", "*", "relax_creep_lambda", "(", "\n", "time_point", "-", "start_time_point", "\n", ")", "\n", "second_term", "=", "integral_lambda", "(", "time_point", ")", "\n", "output_array", "=", "np", ".", "append", "(", "output_array", ",", "first_term", "+", "second_term", ")", "\n", "input_array", "=", "np", ".", "append", "(", "input_array", ",", "input_lambda", "(", "time_point", ")", ")", "\n", "\n", "", "if", "input_type", "==", "\"Strain\"", ":", "\n", "        ", "strain_array", "=", "input_array", "\n", "stress_array", "=", "output_array", "\n", "", "else", ":", "\n", "        ", "strain_array", "=", "output_array", "\n", "stress_array", "=", "input_array", "\n", "\n", "", "strain_array", "=", "strain_array", ".", "reshape", "(", "time_array", ".", "shape", ")", "\n", "stress_array", "=", "stress_array", ".", "reshape", "(", "time_array", ".", "shape", ")", "\n", "\n", "return", "strain_array", ",", "stress_array", "\n", "\n"]], "home.repos.pwc.inspect_result.PhIMaL_DeePyMoD.examples.VE_datagen.relax_creep": [[57, 82], ["numpy.array().reshape", "numpy.array().reshape", "numpy.array", "numpy.array", "print", "numpy.sum", "numpy.sum", "numpy.exp", "numpy.exp"], "function", ["None"], ["", "def", "relax_creep", "(", "E_mods", ",", "viscs", ",", "input_type", ")", ":", "\n", "\n", "# The following function interprets the provided model parameters differently depending on the input_type.", "\n", "# If the input_type is 'Strain' then the parameters are assumed to refer to a Maxwell model, whereas", "\n", "# if the input_type is 'Stress' then the parameters are assumed to refer to a Kelvin model.", "\n", "# The equations used thus allow the data to be generated according to the model now designated.", "\n", "\n", "    ", "E_mods_1plus_array", "=", "np", ".", "array", "(", "E_mods", "[", "1", ":", "]", ")", ".", "reshape", "(", "-", "1", ",", "1", ")", "\n", "viscs_array", "=", "np", ".", "array", "(", "viscs", ")", ".", "reshape", "(", "-", "1", ",", "1", ")", "\n", "\n", "taus", "=", "viscs_array", "/", "E_mods_1plus_array", "\n", "\n", "if", "input_type", "==", "\"Strain\"", ":", "\n", "        ", "relax_creep_lambda", "=", "lambda", "t", ":", "E_mods", "[", "0", "]", "+", "np", ".", "sum", "(", "\n", "np", ".", "exp", "(", "-", "t", "/", "taus", ")", "*", "E_mods_1plus_array", "\n", ")", "\n", "", "elif", "input_type", "==", "\"Stress\"", ":", "\n", "        ", "relax_creep_lambda", "=", "lambda", "t", ":", "1", "/", "E_mods", "[", "0", "]", "+", "np", ".", "sum", "(", "\n", "(", "1", "-", "np", ".", "exp", "(", "-", "t", "/", "taus", ")", ")", "/", "E_mods_1plus_array", "\n", ")", "\n", "", "else", ":", "\n", "        ", "print", "(", "\"Incorrect input_type\"", ")", "\n", "relax_creep_lambda", "=", "False", "\n", "\n", "", "return", "relax_creep_lambda", "\n", "", ""]]}