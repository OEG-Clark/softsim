{"home.repos.pwc.inspect_result.allenai_label_rationale_association.None.custom_args.compute_metrics": [[91, 147], ["os.path.join", "os.path.join", "os.path.isfile", "os.path.isfile", "custom_args.parse_wt5_no_label", "open", "tqdm.tqdm", "open", "f.readlines", "custom_args.parse_wt5_label_only", "custom_args.parse_wt5_output", "os.path.join.split", "os.path.join.split", "enumerate", "torch.tensor().reshape", "model.generate", "tokenizer.decode", "words.replace().strip.replace().strip", "w.write", "f.readlines.append", "len", "out[].tolist", "torch.tensor", "words.replace().strip.replace"], "function", ["home.repos.pwc.inspect_result.allenai_label_rationale_association.None.custom_args.parse_wt5_no_label", "home.repos.pwc.inspect_result.allenai_label_rationale_association.None.custom_args.parse_wt5_label_only", "home.repos.pwc.inspect_result.allenai_label_rationale_association.None.custom_args.parse_wt5_output"], ["", "def", "compute_metrics", "(", "\n", "save_path", ",", "\n", "dataset", ",", "\n", "model", ",", "\n", "tokenizer", ",", "\n", "split", ",", "\n", "task", ",", "\n", "device", ",", "\n", "rationale_only", "=", "False", ",", "\n", "label_only", "=", "False", ",", "\n", "generations_file", "=", "None", ",", "\n", ")", ":", "\n", "\n", "    ", "fname", "=", "os", ".", "path", ".", "join", "(", "save_path", ",", "\"%s_generations.txt\"", "%", "split", ")", "\n", "analysis_file", "=", "os", ".", "path", ".", "join", "(", "save_path", ",", "\"%s_posthoc_analysis.txt\"", "%", "split", ")", "\n", "if", "os", ".", "path", ".", "isfile", "(", "fname", ")", ":", "\n", "        ", "fname", "=", "fname", ".", "split", "(", "\".txt\"", ")", "[", "0", "]", "+", "\"_1.txt\"", "\n", "", "if", "os", ".", "path", ".", "isfile", "(", "analysis_file", ")", ":", "\n", "        ", "analysis_file", "=", "analysis_file", ".", "split", "(", "\".txt\"", ")", "[", "0", "]", "+", "\"_1.txt\"", "\n", "\n", "", "if", "generations_file", "is", "None", ":", "\n", "        ", "generations_list", "=", "[", "]", "\n", "with", "open", "(", "fname", ",", "\"w\"", ")", "as", "w", ":", "\n", "            ", "for", "i", ",", "element", "in", "tqdm", "(", "enumerate", "(", "dataset", ")", ",", "total", "=", "len", "(", "dataset", ")", ")", ":", "\n", "                ", "inpt_tensor", "=", "torch", ".", "tensor", "(", "\n", "element", "[", "\"question_encoding\"", "]", ",", "device", "=", "device", "\n", ")", ".", "reshape", "(", "1", ",", "-", "1", ")", "\n", "# to improve performance, set the min length to 100 tokens", "\n", "out", "=", "model", ".", "generate", "(", "\n", "inpt_tensor", ",", "\n", "max_length", "=", "20", ",", "\n", "pad_token_id", "=", "tokenizer", ".", "pad_token_id", ",", "\n", "eos_token_id", "=", "tokenizer", ".", "eos_token_id", ",", "\n", ")", "\n", "words", "=", "tokenizer", ".", "decode", "(", "out", "[", "0", "]", ".", "tolist", "(", ")", ")", "\n", "# write out all generated tokens (strip newlines)", "\n", "words", "=", "words", ".", "replace", "(", "\"\\n\"", ",", "\" \"", ")", ".", "strip", "(", ")", "\n", "w", ".", "write", "(", "words", "+", "\"\\n\"", ")", "\n", "generations_list", ".", "append", "(", "words", ")", "\n", "", "", "", "else", ":", "\n", "# load from file", "\n", "        ", "with", "open", "(", "generations_file", ",", "\"r\"", ")", "as", "f", ":", "\n", "            ", "generations_list", "=", "f", ".", "readlines", "(", ")", "\n", "", "analysis_file", "=", "os", ".", "devnull", "\n", "\n", "", "if", "rationale_only", ":", "\n", "        ", "return", "parse_wt5_no_label", "(", "\n", "analysis_file", ",", "generations_list", ",", "dataset", ",", "task", ",", "tokenizer", ".", "eos_token", "\n", ")", "\n", "", "elif", "label_only", ":", "\n", "        ", "return", "parse_wt5_label_only", "(", "\n", "analysis_file", ",", "generations_list", ",", "dataset", ",", "task", ",", "tokenizer", ".", "eos_token", "\n", ")", "\n", "", "else", ":", "\n", "        ", "return", "parse_wt5_output", "(", "\n", "analysis_file", ",", "generations_list", ",", "dataset", ",", "task", ",", "tokenizer", ".", "eos_token", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.allenai_label_rationale_association.None.custom_args.parse_wt5_output": [[150, 201], ["open", "tqdm.tqdm", "len", "len", "enumerate", "[].strip", "g.write", "acc.append", "g.write", "g.write", "sum", "len", "zip", "len", "len", "[].strip", "[].strip", "g.write", "g.write", "line.split", "[].strip", "g.write", "g.write", "line.split", "str", "line.split", "[].strip.split", "[].strip.split"], "function", ["None"], ["", "", "def", "parse_wt5_output", "(", "f", ",", "generations_list", ",", "dataset", ",", "task", ",", "eos_token", ")", ":", "\n", "\n", "    ", "acc", "=", "[", "]", "\n", "with", "open", "(", "f", ",", "\"w\"", ")", "as", "g", ":", "\n", "        ", "for", "i", ",", "(", "line", ",", "gold", ")", "in", "tqdm", "(", "\n", "enumerate", "(", "zip", "(", "generations_list", ",", "dataset", ")", ")", ",", "total", "=", "len", "(", "dataset", ")", "\n", ")", ":", "\n", "            ", "pred_l", "=", "line", ".", "split", "(", "\"explanation:\"", ")", "[", "0", "]", ".", "strip", "(", ")", "\n", "if", "len", "(", "line", ".", "split", "(", "\"explanation:\"", ")", ")", ">", "1", ":", "\n", "                ", "pred_e", "=", "line", ".", "split", "(", "\"explanation:\"", ")", "[", "1", "]", ".", "strip", "(", ")", "\n", "if", "eos_token", "in", "pred_e", ":", "\n", "                    ", "pred_e", "=", "pred_e", ".", "split", "(", "eos_token", ")", "[", "0", "]", ".", "strip", "(", ")", "\n", "# also split on extra id token (which tends to appear as a delimiter frequently)", "\n", "", "pred_e", "=", "pred_e", ".", "split", "(", "\"<extra_id\"", ")", "[", "0", "]", ".", "strip", "(", ")", "\n", "", "else", ":", "\n", "                ", "pred_e", "=", "\"\"", "\n", "\n", "", "if", "task", "==", "\"cos_e\"", ":", "\n", "                ", "gold_l", "=", "gold", "[", "\"answer\"", "]", "\n", "gold_e1", "=", "gold", "[", "\"abstractive_explanation\"", "]", "\n", "g", ".", "write", "(", "gold", "[", "\"question\"", "]", "+", "\"\\n\"", ")", "\n", "", "elif", "task", "==", "\"esnli\"", ":", "\n", "                ", "gold_l", "=", "gold", "[", "\"label\"", "]", "\n", "gold_e1", "=", "gold", "[", "\"explanation_1\"", "]", "\n", "gold_e2", "=", "gold", "[", "\"explanation_2\"", "]", "\n", "# convert to string", "\n", "if", "gold_l", "==", "0", ":", "\n", "                    ", "gold_l", "=", "\"entailment\"", "\n", "", "elif", "gold_l", "==", "1", ":", "\n", "                    ", "gold_l", "=", "\"neutral\"", "\n", "", "elif", "gold_l", "==", "2", ":", "\n", "                    ", "gold_l", "=", "\"contradiction\"", "\n", "", "g", ".", "write", "(", "gold", "[", "\"premise\"", "]", "+", "\" \"", "+", "gold", "[", "\"hypothesis\"", "]", "+", "\"\\n\"", ")", "\n", "\n", "", "if", "task", "==", "\"esnli\"", ":", "\n", "                ", "g", ".", "write", "(", "\n", "\"Correct: \"", "+", "gold_l", "+", "\" | \"", "+", "gold_e1", "+", "\" [SEP] \"", "+", "gold_e2", "+", "\"\\n\"", "\n", ")", "\n", "", "elif", "task", "==", "\"cos_e\"", ":", "\n", "                ", "g", ".", "write", "(", "\"Correct: \"", "+", "gold_l", "+", "\" | \"", "+", "gold_e1", "+", "\"\\n\"", ")", "\n", "\n", "", "g", ".", "write", "(", "\"Predicted: \"", "+", "pred_l", "+", "\" | \"", "+", "pred_e", "+", "\"\\n\"", ")", "\n", "\n", "# calculate metrics", "\n", "met", "=", "gold_l", "==", "pred_l", "\n", "acc", ".", "append", "(", "met", ")", "\n", "g", ".", "write", "(", "\"Label Considered Correct: \"", "+", "str", "(", "met", ")", "+", "\"\\n\"", ")", "\n", "g", ".", "write", "(", "\"\\n\"", ")", "\n", "\n", "", "", "assert", "len", "(", "acc", ")", "==", "len", "(", "generations_list", ")", "\n", "return", "sum", "(", "acc", ")", "/", "len", "(", "acc", ")", "*", "100", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_label_rationale_association.None.custom_args.parse_wt5_label_only": [[203, 245], ["open", "tqdm.tqdm", "len", "len", "enumerate", "g.write", "g.write", "acc.append", "g.write", "g.write", "sum", "len", "zip", "len", "[].strip", "[].strip", "g.write", "g.write", "str", "[].split", "[].split", "line.split", "line.split"], "function", ["None"], ["", "def", "parse_wt5_label_only", "(", "f", ",", "generations_list", ",", "dataset", ",", "task", ",", "eos_token", ")", ":", "\n", "    ", "acc", "=", "[", "]", "\n", "with", "open", "(", "f", ",", "\"w\"", ")", "as", "g", ":", "\n", "        ", "for", "i", ",", "(", "line", ",", "gold", ")", "in", "tqdm", "(", "\n", "enumerate", "(", "zip", "(", "generations_list", ",", "dataset", ")", ")", ",", "total", "=", "len", "(", "dataset", ")", "\n", ")", ":", "\n", "\n", "            ", "if", "eos_token", "not", "in", "line", ":", "\n", "# split on period or extra id token (which tends to appear as a delimiter frequently)", "\n", "                ", "pred_l", "=", "line", ".", "split", "(", "\".\"", ")", "[", "0", "]", ".", "split", "(", "\"<extra_id\"", ")", "[", "0", "]", ".", "strip", "(", ")", "\n", "", "else", ":", "\n", "# split on EOS token or extra id token", "\n", "                ", "pred_l", "=", "(", "\n", "line", ".", "split", "(", "eos_token", ")", "[", "0", "]", ".", "split", "(", "\"<extra_id\"", ")", "[", "0", "]", ".", "strip", "(", ")", "\n", ")", "\n", "\n", "", "if", "task", "==", "\"cos_e\"", ":", "\n", "                ", "gold_l", "=", "gold", "[", "\"answer\"", "]", "\n", "g", ".", "write", "(", "gold", "[", "\"question\"", "]", "+", "\"\\n\"", ")", "\n", "", "elif", "task", "==", "\"esnli\"", ":", "\n", "                ", "gold_l", "=", "gold", "[", "\"label\"", "]", "\n", "# convert to string", "\n", "if", "gold_l", "==", "0", ":", "\n", "                    ", "gold_l", "=", "\"entailment\"", "\n", "", "elif", "gold_l", "==", "1", ":", "\n", "                    ", "gold_l", "=", "\"neutral\"", "\n", "", "elif", "gold_l", "==", "2", ":", "\n", "                    ", "gold_l", "=", "\"contradiction\"", "\n", "", "g", ".", "write", "(", "gold", "[", "\"premise\"", "]", "+", "\" \"", "+", "gold", "[", "\"hypothesis\"", "]", "+", "\"\\n\"", ")", "\n", "\n", "", "g", ".", "write", "(", "\"Correct: \"", "+", "gold_l", "+", "\" | \"", "+", "\"\\n\"", ")", "\n", "g", ".", "write", "(", "\"Predicted: \"", "+", "pred_l", "+", "\" | \"", "+", "\"\\n\"", ")", "\n", "\n", "# calculate metrics", "\n", "met", "=", "gold_l", "==", "pred_l", "\n", "\n", "acc", ".", "append", "(", "met", ")", "\n", "g", ".", "write", "(", "\"Considered Correct: \"", "+", "str", "(", "met", ")", "+", "\"\\n\"", ")", "\n", "g", ".", "write", "(", "\"\\n\"", ")", "\n", "\n", "", "", "assert", "len", "(", "acc", ")", "==", "len", "(", "generations_list", ")", "\n", "return", "sum", "(", "acc", ")", "/", "len", "(", "acc", ")", "*", "100", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_label_rationale_association.None.custom_args.parse_wt5_no_label": [[247, 278], ["open", "tqdm.tqdm", "enumerate", "g.write", "g.write", "zip", "len", "len", "[].strip", "[].strip", "g.write", "g.write", "line.split", "[].strip", "g.write", "g.write", "line.split", "[].strip.split", "[].strip.split"], "function", ["None"], ["", "def", "parse_wt5_no_label", "(", "f", ",", "generations_list", ",", "dataset", ",", "task", ",", "eos_token", ")", ":", "\n", "\n", "    ", "with", "open", "(", "f", ",", "\"w\"", ")", "as", "g", ":", "\n", "        ", "for", "i", ",", "(", "line", ",", "gold", ")", "in", "tqdm", "(", "\n", "enumerate", "(", "zip", "(", "generations_list", ",", "dataset", ")", ")", ",", "total", "=", "len", "(", "dataset", ")", "\n", ")", ":", "\n", "            ", "if", "len", "(", "line", ".", "split", "(", "\"explanation:\"", ")", ")", ">", "1", ":", "\n", "                ", "pred_e", "=", "line", ".", "split", "(", "\"explanation:\"", ")", "[", "1", "]", ".", "strip", "(", ")", "\n", "if", "eos_token", "in", "pred_e", ":", "\n", "                    ", "pred_e", "=", "pred_e", ".", "split", "(", "eos_token", ")", "[", "0", "]", ".", "strip", "(", ")", "\n", "# also split on extra id token (which tends to appear as a delimiter frequently)", "\n", "", "pred_e", "=", "pred_e", ".", "split", "(", "\"<extra_id\"", ")", "[", "0", "]", ".", "strip", "(", ")", "\n", "", "else", ":", "\n", "                ", "pred_e", "=", "\"\"", "\n", "\n", "", "if", "task", "==", "\"cos_e\"", ":", "\n", "                ", "gold_e1", "=", "gold", "[", "\"abstractive_explanation\"", "]", "\n", "g", ".", "write", "(", "gold", "[", "\"question\"", "]", "+", "\"\\n\"", ")", "\n", "", "elif", "task", "==", "\"esnli\"", ":", "\n", "                ", "gold_e1", "=", "gold", "[", "\"explanation_1\"", "]", "\n", "gold_e2", "=", "gold", "[", "\"explanation_2\"", "]", "\n", "g", ".", "write", "(", "gold", "[", "\"premise\"", "]", "+", "\" \"", "+", "gold", "[", "\"hypothesis\"", "]", "+", "\"\\n\"", ")", "\n", "\n", "", "if", "task", "==", "\"esnli\"", ":", "\n", "                ", "g", ".", "write", "(", "\"Correct: | \"", "+", "gold_e1", "+", "\" [SEP] \"", "+", "gold_e2", "+", "\"\\n\"", ")", "\n", "", "elif", "task", "==", "\"cos_e\"", ":", "\n", "                ", "g", ".", "write", "(", "\"Correct: | \"", "+", "gold_e1", "+", "\"\\n\"", ")", "\n", "", "g", ".", "write", "(", "\"Predicted: \"", "+", "\" | \"", "+", "pred_e", "+", "\"\\n\"", ")", "\n", "g", ".", "write", "(", "\"\\n\"", ")", "\n", "\n", "", "", "return", "\"n/a\"", "\n", "", ""]], "home.repos.pwc.inspect_result.allenai_label_rationale_association.None.rationale_to_label.SequenceCollator.__init__": [[52, 64], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "pad_token", ")", ":", "\n", "        ", "self", ".", "pad_token_mapping", "=", "{", "\n", "\"lm_labels\"", ":", "-", "100", ",", "\n", "\"attention_mask\"", ":", "0", ",", "\n", "\"decoder_attention_mask\"", ":", "0", ",", "\n", "\"input_ids\"", ":", "pad_token", ",", "\n", "}", "\n", "self", ".", "columns", "=", "[", "\n", "\"input_ids\"", ",", "\n", "\"attention_mask\"", ",", "\n", "\"lm_labels\"", ",", "\n", "\"decoder_attention_mask\"", ",", "\n", "]", "\n"]], "home.repos.pwc.inspect_result.allenai_label_rationale_association.None.rationale_to_label.SequenceCollator.collate_batch": [[66, 86], ["examples[].keys", "isinstance", "torch.tensor", "tmp_list.append", "max", "map", "len"], "methods", ["None"], ["", "def", "collate_batch", "(", "self", ",", "examples", ")", ":", "\n", "\n", "# batch inputs for training", "\n", "        ", "batch", "=", "{", "}", "\n", "for", "key", "in", "examples", "[", "0", "]", ".", "keys", "(", ")", ":", "\n", "            ", "if", "key", "in", "self", ".", "columns", ":", "\n", "                ", "tmp_list", "=", "[", "]", "\n", "for", "item", "in", "examples", ":", "\n", "                    ", "tmp_list", ".", "append", "(", "item", "[", "key", "]", ")", "\n", "\n", "# pad lists to max length", "\n", "", "if", "isinstance", "(", "tmp_list", "[", "0", "]", ",", "list", ")", ":", "\n", "                    ", "max_length", "=", "max", "(", "map", "(", "len", ",", "tmp_list", ")", ")", "\n", "tmp_list", "=", "[", "\n", "el", "+", "[", "self", ".", "pad_token_mapping", "[", "key", "]", "]", "*", "(", "max_length", "-", "len", "(", "el", ")", ")", "\n", "for", "el", "in", "tmp_list", "\n", "]", "\n", "\n", "", "batch", "[", "key", "]", "=", "torch", ".", "tensor", "(", "tmp_list", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "", "", "return", "batch", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_label_rationale_association.None.rationale_to_label.main": [[88, 523], ["time.time", "transformers.HfArgumentParser", "transformers.HfArgumentParser.parse_args_into_dataclasses", "logging.basicConfig", "logger.warning", "logger.info", "git.Repo", "logger.info", "logger.info", "int", "transformers.set_seed", "logger.info", "T5Tokenizer.from_pretrained.add_special_tokens", "nlp.load_dataset", "nlp.load_dataset.keys", "logger.info", "logger.info", "logger.info", "time.time", "logger.info", "logger.info", "logger.info", "logger.info", "Exception", "Exception", "os.path.join", "os.path.exists", "os.makedirs", "bool", "Exception", "transformers.T5Tokenizer.from_pretrained", "transformers.T5Tokenizer.from_pretrained", "T5ForConditionalGeneration.from_pretrained.resize_token_embeddings", "len", "len", "logger.info", "trainer.Trainer", "time.time", "trainer.Trainer.train", "trainer.Trainer.save_model", "T5Tokenizer.from_pretrained.save_pretrained", "T5ForConditionalGeneration.from_pretrained.eval", "time.time", "logger.info", "trainer.Trainer.evaluate", "math.exp", "logger.info", "trainer.Trainer.evaluate", "math.exp", "os.path.dirname", "logger.info", "custom_args.compute_metrics", "logger.info", "custom_args.compute_metrics", "logger.info", "custom_args.compute_metrics", "os.path.join", "os.path.join", "time.time", "logger.info", "logger.info", "logger.info", "Exception", "datetime.datetime.now().strftime", "os.path.exists", "os.path.exists", "os.listdir", "ValueError", "logging.FileHandler", "logging.StreamHandler", "logging.StreamHandler", "open", "f.write", "f.write", "f.write", "f.write", "f.write", "tmp.pop", "tmp.pop", "tmp.pop", "tmp.pop", "tmp.pop", "json.dump", "f.write", "json.dump", "f.write", "json.dump", "len", "T5Tokenizer.from_pretrained.encode", "os.path.join", "transformers.T5ForConditionalGeneration.from_pretrained", "logger.info", "len", "model_args.predictions_model_file.replace", "dataset[].map", "dataset[].map", "len", "len", "len", "len", "time.time", "logger.info", "trainer.Trainer.evaluate", "logger.info", "math.exp", "time.time", "os.path.join", "logger.info", "logger.info", "logger.info", "os.path.dirname", "open", "sorted", "os.path.join", "os.path.join", "len", "Exception", "Exception", "transformers.T5ForConditionalGeneration.from_pretrained", "transformers.T5ForConditionalGeneration.from_pretrained", "open", "len", "len", "rationale_to_label.SequenceCollator", "len", "Exception", "os.path.dirname", "results.keys", "datetime.datetime.now", "os.listdir", "line.strip.strip", "feature_conversion_method", "feature_conversion_method", "len", "len", "os.listdir", "logger.info", "writer.write", "[].strip", "predictions.append", "len", "len", "str", "time.time", "[].strip.strip", "str", "[].split", "line.strip.split"], "function", ["home.repos.pwc.inspect_result.allenai_label_rationale_association.None.trainer.set_seed", "home.repos.pwc.inspect_result.allenai_label_rationale_association.None.trainer.Trainer.train", "home.repos.pwc.inspect_result.allenai_label_rationale_association.None.trainer.Trainer.save_model", "home.repos.pwc.inspect_result.allenai_label_rationale_association.None.trainer.Trainer.evaluate", "home.repos.pwc.inspect_result.allenai_label_rationale_association.None.trainer.Trainer.evaluate", "home.repos.pwc.inspect_result.allenai_label_rationale_association.None.custom_args.compute_metrics", "home.repos.pwc.inspect_result.allenai_label_rationale_association.None.custom_args.compute_metrics", "home.repos.pwc.inspect_result.allenai_label_rationale_association.None.custom_args.compute_metrics", "home.repos.pwc.inspect_result.allenai_label_rationale_association.None.trainer.Trainer.evaluate"], ["", "", "def", "main", "(", ")", ":", "\n", "# See all possible arguments in src/transformers/training_args.py", "\n", "# or by passing the --help flag to this script.", "\n", "\n", "    ", "og_start_time", "=", "time", ".", "time", "(", ")", "\n", "\n", "parser", "=", "HfArgumentParser", "(", "\n", "(", "ModelArguments", ",", "DataTrainingArguments", ",", "TrainingArguments", ")", "\n", ")", "\n", "model_args", ",", "data_args", ",", "training_args", "=", "parser", ".", "parse_args_into_dataclasses", "(", ")", "\n", "\n", "if", "model_args", ".", "rationale_only", ":", "\n", "        ", "raise", "Exception", "(", "\"can't have such a model\"", ")", "\n", "\n", "", "if", "not", "(", "model_args", ".", "predictions_model_file", "or", "model_args", ".", "use_dev_real_expls", ")", ":", "\n", "        ", "raise", "Exception", "(", "\n", "\"must specify a directory where generation predictions exist to use during inference\"", "\n", ")", "\n", "\n", "", "if", "not", "training_args", ".", "do_train", ":", "\n", "        ", "if", "(", "not", "model_args", ".", "pretrained_model_file", ")", "and", "(", "\n", "not", "data_args", ".", "generations_filepath", "\n", ")", ":", "\n", "            ", "raise", "Exception", "(", "\n", "\"if not training a model from scratch, must specify a trained model to load for evaluation or generations in a file to evaluate\"", "\n", ")", "\n", "\n", "# make sure only one dataset split pick if manually specifying evaluation file", "\n", "", "", "if", "data_args", ".", "generations_filepath", "is", "not", "None", ":", "\n", "        ", "training_args", ".", "do_train", "=", "False", "\n", "training_args", ".", "do_eval", "=", "False", "\n", "if", "\"train\"", "in", "data_args", ".", "generations_filepath", ":", "\n", "            ", "data_args", ".", "train_predict", "=", "True", "\n", "data_args", ".", "test_predict", "=", "False", "\n", "data_args", ".", "dev_predict", "=", "False", "\n", "", "elif", "\"test\"", "in", "data_args", ".", "generations_filepath", ":", "\n", "            ", "data_args", ".", "train_predict", "=", "False", "\n", "data_args", ".", "test_predict", "=", "True", "\n", "data_args", ".", "dev_predict", "=", "False", "\n", "", "elif", "\"validation\"", "in", "data_args", ".", "generations_filepath", ":", "\n", "            ", "data_args", ".", "train_predict", "=", "False", "\n", "data_args", ".", "test_predict", "=", "False", "\n", "data_args", ".", "dev_predict", "=", "True", "\n", "\n", "# create a new directory if fine-tuning an existing checkpoint or training/evaluating a HF pretrained model", "\n", "# do not do this when re-evaluating a pretrained_model_file", "\n", "", "", "if", "training_args", ".", "do_train", "or", "(", "\n", "not", "model_args", ".", "pretrained_model_file", "and", "not", "data_args", ".", "generations_filepath", "\n", ")", ":", "\n", "# create a save directory and a logfile", "\n", "        ", "save_path", "=", "training_args", ".", "output_dir", "\n", "training_args", ".", "output_dir", "=", "os", ".", "path", ".", "join", "(", "\n", "save_path", ",", "datetime", ".", "now", "(", ")", ".", "strftime", "(", "\"%m%d%y_%H%M%S\"", ")", "\n", ")", "\n", "training_args", ".", "logging_dir", "=", "training_args", ".", "output_dir", "\n", "assert", "os", ".", "path", ".", "exists", "(", "save_path", ")", "\n", "assert", "not", "os", ".", "path", ".", "exists", "(", "training_args", ".", "output_dir", ")", "\n", "os", ".", "makedirs", "(", "training_args", ".", "output_dir", ")", "\n", "\n", "if", "(", "\n", "os", ".", "path", ".", "exists", "(", "training_args", ".", "output_dir", ")", "\n", "and", "os", ".", "listdir", "(", "training_args", ".", "output_dir", ")", "\n", "and", "training_args", ".", "do_train", "\n", "and", "not", "training_args", ".", "overwrite_output_dir", "\n", ")", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "f\"Output directory ({training_args.output_dir}) already exists and is not empty. Use --overwrite_output_dir to overcome.\"", "\n", ")", "\n", "", "handlers", "=", "[", "\n", "logging", ".", "FileHandler", "(", "os", ".", "path", ".", "join", "(", "training_args", ".", "output_dir", ",", "\"logger.log\"", ")", ")", ",", "\n", "logging", ".", "StreamHandler", "(", ")", ",", "\n", "]", "\n", "", "else", ":", "\n", "# don't overwrite existing logfile or create new directory", "\n", "        ", "training_args", ".", "output_dir", "=", "model_args", ".", "pretrained_model_file", "\n", "handlers", "=", "[", "logging", ".", "StreamHandler", "(", ")", "]", "\n", "\n", "# Setup logging", "\n", "", "logging", ".", "basicConfig", "(", "\n", "format", "=", "\"%(asctime)s - %(levelname)s - %(name)s -   %(message)s\"", ",", "\n", "datefmt", "=", "\"%m/%d/%Y %H:%M:%S\"", ",", "\n", "level", "=", "logging", ".", "INFO", "if", "training_args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", "else", "logging", ".", "WARN", ",", "\n", "handlers", "=", "handlers", ",", "\n", ")", "\n", "logger", ".", "warning", "(", "\n", "\"Process rank: %s, device: %s, n_gpu: %s, distributed training: %s, 16-bits training: %s\"", ",", "\n", "training_args", ".", "local_rank", ",", "\n", "training_args", ".", "device", ",", "\n", "training_args", ".", "n_gpu", ",", "\n", "bool", "(", "training_args", ".", "local_rank", "!=", "-", "1", ")", ",", "\n", "training_args", ".", "fp16", ",", "\n", ")", "\n", "logger", ".", "info", "(", "\"Save path: %s\"", "%", "training_args", ".", "output_dir", ")", "\n", "\n", "# get git hash and branch where deployed", "\n", "repo", "=", "git", ".", "Repo", "(", "search_parent_directories", "=", "True", ")", "\n", "git_hash", "=", "repo", ".", "head", ".", "object", ".", "hexsha", "\n", "git_branch", "=", "repo", ".", "active_branch", ".", "name", "\n", "logger", ".", "info", "(", "\"Git branch: %s\"", "%", "git_branch", ")", "\n", "logger", ".", "info", "(", "\"Git hash: %s\"", "%", "git_hash", ")", "\n", "\n", "assert", "data_args", ".", "task_name", "in", "{", "\"cos_e\"", ",", "\"esnli\"", "}", "\n", "\n", "# set gradient accumulation steps to always use batch size == 64", "\n", "if", "64", "%", "training_args", ".", "per_gpu_train_batch_size", "!=", "0", ":", "\n", "        ", "raise", "Exception", "(", "\n", "\"Batch size is not a divisor of 64, resulting in inconsistent gradient-accumulation behavior\"", "\n", ")", "\n", "", "training_args", ".", "gradient_accumulation_steps", "=", "int", "(", "\n", "64", "/", "training_args", ".", "per_gpu_train_batch_size", "\n", ")", "\n", "\n", "if", "training_args", ".", "do_train", ":", "\n", "# write command and args to file", "\n", "        ", "with", "open", "(", "\n", "os", ".", "path", ".", "join", "(", "training_args", ".", "output_dir", ",", "\"commandline_args.txt\"", ")", ",", "\"w\"", "\n", ")", "as", "f", ":", "\n", "            ", "f", ".", "write", "(", "\"Git branch: \"", "+", "git_branch", "+", "\"\\n\"", ")", "\n", "f", ".", "write", "(", "\"Git hash: \"", "+", "git_hash", "+", "\"\\n\"", ")", "\n", "f", ".", "write", "(", "\"Command:\\n\"", ")", "\n", "f", ".", "write", "(", "\"\\n\"", ".", "join", "(", "sys", ".", "argv", "[", "1", ":", "]", ")", ")", "\n", "f", ".", "write", "(", "\"Training args:\\n\"", ")", "\n", "# make training_args dict writeable", "\n", "tmp", "=", "training_args", ".", "__dict__", "\n", "tmp", ".", "pop", "(", "\"__cached__setup_devices\"", ",", "None", ")", "\n", "tmp", ".", "pop", "(", "\"evaluation_strategy\"", ",", "None", ")", "\n", "tmp", ".", "pop", "(", "\"lr_scheduler_type\"", ",", "None", ")", "\n", "tmp", ".", "pop", "(", "\"logging_strategy\"", ",", "None", ")", "\n", "tmp", ".", "pop", "(", "\"save_strategy\"", ",", "None", ")", "\n", "json", ".", "dump", "(", "tmp", ",", "f", ",", "indent", "=", "2", ")", "\n", "f", ".", "write", "(", "\"Data args:\\n\"", ")", "\n", "json", ".", "dump", "(", "data_args", ".", "__dict__", ",", "f", ",", "indent", "=", "2", ")", "\n", "f", ".", "write", "(", "\"Model args:\\n\"", ")", "\n", "json", ".", "dump", "(", "model_args", ".", "__dict__", ",", "f", ",", "indent", "=", "2", ")", "\n", "\n", "# Set seed", "\n", "", "", "set_seed", "(", "training_args", ".", "seed", ")", "\n", "\n", "# Load pretrained model and tokenizer", "\n", "logger", ".", "info", "(", "\"Loading pretrained tokenizer...\"", ")", "\n", "if", "model_args", ".", "pretrained_model_file", ":", "\n", "# load pretrained tokenizer from directory", "\n", "        ", "tokenizer", "=", "T5Tokenizer", ".", "from_pretrained", "(", "model_args", ".", "pretrained_model_file", ")", "\n", "", "else", ":", "\n", "# load pretrained tokenizer from Huggingface", "\n", "        ", "tokenizer", "=", "T5Tokenizer", ".", "from_pretrained", "(", "\"t5-base\"", ")", "\n", "\n", "# found better/more controllable generation using own EOS token", "\n", "", "tokenizer", ".", "add_special_tokens", "(", "{", "\"eos_token\"", ":", "\"[EOS]\"", "}", ")", "\n", "assert", "(", "\n", "len", "(", "tokenizer", ")", "-", "1", "\n", "==", "tokenizer", ".", "eos_token_id", "\n", "==", "tokenizer", ".", "encode", "(", "[", "\"[EOS]\"", "]", ")", "[", "0", "]", "\n", "==", "32100", "\n", ")", "\n", "\n", "if", "data_args", ".", "generations_filepath", "is", "None", ":", "\n", "        ", "if", "model_args", ".", "pretrained_model_file", ":", "\n", "# load pretrained model from directory at best checkpoint", "\n", "            ", "ckpts", "=", "[", "\n", "name", "\n", "for", "name", "in", "os", ".", "listdir", "(", "model_args", ".", "pretrained_model_file", ")", "\n", "if", "PREFIX_CHECKPOINT_DIR", "in", "name", "\n", "]", "\n", "if", "len", "(", "ckpts", ")", "!=", "1", ":", "\n", "                ", "raise", "Exception", "(", "\n", "\"more than 1 checkpoint file stored in pretrained path. revisit save directory\"", "\n", ")", "\n", "", "model_load_path", "=", "os", ".", "path", ".", "join", "(", "model_args", ".", "pretrained_model_file", ",", "ckpts", "[", "0", "]", ")", "\n", "model", "=", "T5ForConditionalGeneration", ".", "from_pretrained", "(", "model_load_path", ")", "\n", "if", "model_args", ".", "dropout_rate", ":", "\n", "                ", "raise", "Exception", "(", "\n", "\"can't update/specify dropout currently when load pretrained model from directory\"", "\n", ")", "\n", "\n", "", "", "else", ":", "\n", "# load pretrained model from HuggingFace", "\n", "            ", "logger", ".", "info", "(", "\"Loading pretrained model\"", ")", "\n", "if", "model_args", ".", "dropout_rate", ":", "\n", "                ", "model", "=", "T5ForConditionalGeneration", ".", "from_pretrained", "(", "\n", "\"t5-base\"", ",", "dropout_rate", "=", "model_args", ".", "dropout_rate", "\n", ")", "\n", "", "else", ":", "\n", "                ", "model", "=", "T5ForConditionalGeneration", ".", "from_pretrained", "(", "\"t5-base\"", ")", "\n", "\n", "", "", "model", ".", "resize_token_embeddings", "(", "len", "(", "tokenizer", ")", ")", "\n", "", "else", ":", "\n", "        ", "model", "=", "None", "\n", "\n", "", "feature_conversion_method", "=", "data_formatter", "[", "data_args", ".", "task_name", "]", "\n", "\n", "# load (new) cos-e version", "\n", "if", "data_args", ".", "task_name", "==", "\"cos_e\"", ":", "\n", "        ", "assert", "data_args", ".", "version_name", "in", "{", "\"v1.11\"", ",", "\"v1.0\"", "}", "\n", "version_arg", "=", "data_args", ".", "version_name", "\n", "", "else", ":", "\n", "        ", "version_arg", "=", "None", "\n", "\n", "# Get datasets", "\n", "", "dataset", "=", "nlp", ".", "load_dataset", "(", "data_args", ".", "task_name", ",", "version_arg", ")", "\n", "\n", "# Apply method, and format dataset to torch.Tensor outputs", "\n", "for", "split", "in", "dataset", ".", "keys", "(", ")", ":", "\n", "\n", "        ", "if", "split", "in", "{", "\"validation\"", ",", "\"test\"", "}", "and", "not", "model_args", ".", "use_dev_real_expls", ":", "\n", "# read in predictions file", "\n", "            ", "predictions", "=", "[", "]", "\n", "predictions_file", "=", "model_args", ".", "predictions_model_file", ".", "replace", "(", "\"train\"", ",", "split", ")", "\n", "with", "open", "(", "predictions_file", ",", "\"r\"", ")", "as", "f", ":", "\n", "                ", "for", "line", "in", "f", ":", "\n", "                    ", "line", "=", "line", ".", "strip", "(", "\"\\n\"", ")", "\n", "if", "\"Predicted:\"", "in", "line", ":", "\n", "                        ", "pred_string", "=", "line", ".", "split", "(", "\"Predicted: \"", ")", "[", "1", "]", ".", "split", "(", "\"|\"", ")", "[", "1", "]", ".", "strip", "(", ")", "\n", "predictions", ".", "append", "(", "pred_string", ".", "strip", "(", ")", ")", "\n", "\n", "", "", "", "assert", "len", "(", "predictions", ")", "==", "len", "(", "dataset", "[", "split", "]", ")", "\n", "\n", "# apply independently to each example", "\n", "dataset", "[", "split", "]", "=", "dataset", "[", "split", "]", ".", "map", "(", "\n", "lambda", "i", ",", "x", ":", "feature_conversion_method", "(", "\n", "i", ",", "\n", "x", ",", "\n", "tokenizer", ",", "\n", "pred_only", "=", "True", ",", "\n", "predictions_file", "=", "predictions", ",", "\n", "include_input", "=", "model_args", ".", "include_input", ",", "\n", ")", ",", "\n", "# had some replicability issues with batch/cache set to True", "\n", "batched", "=", "False", ",", "\n", "load_from_cache_file", "=", "False", ",", "\n", "with_indices", "=", "True", ",", "\n", ")", "\n", "\n", "", "else", ":", "\n", "# don't use predictions file", "\n", "            ", "dataset", "[", "split", "]", "=", "dataset", "[", "split", "]", ".", "map", "(", "\n", "lambda", "i", ",", "x", ":", "feature_conversion_method", "(", "\n", "i", ",", "\n", "x", ",", "\n", "tokenizer", ",", "\n", "pred_only", "=", "False", ",", "\n", "predictions_file", "=", "None", ",", "\n", "include_input", "=", "model_args", ".", "include_input", ",", "\n", ")", ",", "\n", "# had some replicability issues with batch/cache set to True", "\n", "batched", "=", "False", ",", "\n", "load_from_cache_file", "=", "False", ",", "\n", "with_indices", "=", "True", ",", "\n", ")", "\n", "\n", "", "", "train_dataset", "=", "dataset", "[", "\"train\"", "]", "\n", "eval_dataset", "=", "dataset", "[", "\"validation\"", "]", "\n", "test_dataset", "=", "dataset", "[", "\"test\"", "]", "if", "data_args", ".", "task_name", "==", "\"esnli\"", "else", "None", "\n", "\n", "if", "data_args", ".", "task_name", "==", "\"esnli\"", ":", "\n", "        ", "assert", "len", "(", "train_dataset", ")", "==", "549367", "\n", "assert", "len", "(", "eval_dataset", ")", "==", "9842", "\n", "assert", "len", "(", "test_dataset", ")", "==", "9824", "\n", "", "elif", "data_args", ".", "task_name", "==", "\"cos_e\"", ":", "\n", "        ", "if", "data_args", ".", "version_name", "==", "\"v1.11\"", ":", "\n", "            ", "assert", "len", "(", "train_dataset", ")", "==", "9741", "\n", "assert", "len", "(", "eval_dataset", ")", "==", "1221", "\n", "", "elif", "data_args", ".", "version_name", "==", "\"v1.0\"", ":", "\n", "            ", "assert", "len", "(", "train_dataset", ")", "==", "7610", "\n", "assert", "len", "(", "eval_dataset", ")", "==", "950", "\n", "", "assert", "test_dataset", "is", "None", "\n", "\n", "", "logger", ".", "info", "(", "\"****LOG****\"", ")", "\n", "logger", ".", "info", "(", "len", "(", "train_dataset", ")", ")", "\n", "logger", ".", "info", "(", "len", "(", "eval_dataset", ")", ")", "\n", "if", "data_args", ".", "task_name", "==", "\"esnli\"", ":", "\n", "        ", "logger", ".", "info", "(", "len", "(", "test_dataset", ")", ")", "\n", "\n", "", "if", "data_args", ".", "generations_filepath", "is", "None", ":", "\n", "# Initialize Trainer", "\n", "        ", "trainer", "=", "Trainer", "(", "\n", "model", "=", "model", ",", "\n", "args", "=", "training_args", ",", "\n", "data_args", "=", "data_args", ",", "\n", "train_dataset", "=", "train_dataset", ",", "\n", "eval_dataset", "=", "eval_dataset", ",", "\n", "prediction_loss_only", "=", "True", ",", "\n", "data_collator", "=", "SequenceCollator", "(", "pad_token", "=", "tokenizer", ".", "pad_token_id", ")", ",", "\n", ")", "\n", "\n", "# Training", "\n", "", "if", "training_args", ".", "do_train", ":", "\n", "        ", "start_time", "=", "time", ".", "time", "(", ")", "\n", "trainer", ".", "train", "(", ")", "\n", "trainer", ".", "save_model", "(", ")", "\n", "# For convenience, we also re-save the tokenizer to the same directory", "\n", "tokenizer", ".", "save_pretrained", "(", "training_args", ".", "output_dir", ")", "\n", "train_time", "=", "time", ".", "time", "(", ")", "-", "start_time", "\n", "model", "=", "trainer", ".", "model", "\n", "\n", "# Evaluation", "\n", "", "results", "=", "{", "}", "\n", "if", "model", "is", "not", "None", ":", "\n", "        ", "model", ".", "eval", "(", ")", "\n", "\n", "", "if", "training_args", ".", "do_eval", ":", "\n", "        ", "start_time", "=", "time", ".", "time", "(", ")", "\n", "\n", "logger", ".", "info", "(", "\"*** Evaluate on train set***\"", ")", "\n", "train_output", "=", "trainer", ".", "evaluate", "(", "train_dataset", ")", "\n", "perplexity", "=", "math", ".", "exp", "(", "train_output", "[", "\"eval_loss\"", "]", ")", "\n", "results", "[", "\"perplexity_train\"", "]", "=", "perplexity", "\n", "\n", "logger", ".", "info", "(", "\"*** Evaluate on dev set***\"", ")", "\n", "eval_output", "=", "trainer", ".", "evaluate", "(", "eval_dataset", ")", "\n", "perplexity", "=", "math", ".", "exp", "(", "eval_output", "[", "\"eval_loss\"", "]", ")", "\n", "results", "[", "\"perplexity_validation\"", "]", "=", "perplexity", "\n", "\n", "if", "data_args", ".", "task_name", "==", "\"esnli\"", ":", "\n", "# also evaluate on test", "\n", "            ", "logger", ".", "info", "(", "\"*** Evaluate on test set***\"", ")", "\n", "test_output", "=", "trainer", ".", "evaluate", "(", "test_dataset", ")", "\n", "logger", ".", "info", "(", "\"test loss @ best dev epoch: %0.4f\"", "%", "test_output", "[", "\"eval_loss\"", "]", ")", "\n", "perplexity", "=", "math", ".", "exp", "(", "test_output", "[", "\"eval_loss\"", "]", ")", "\n", "results", "[", "\"perplexity_test\"", "]", "=", "perplexity", "\n", "\n", "", "eval_time", "=", "time", ".", "time", "(", ")", "-", "start_time", "\n", "\n", "", "if", "data_args", ".", "generations_filepath", "is", "None", ":", "\n", "# only save to checkpoint folder if one exists (i.e. trained a model or loaded a model you previously trained)", "\n", "        ", "if", "training_args", ".", "do_train", "or", "model_args", ".", "pretrained_model_file", ":", "\n", "            ", "ckpts", "=", "[", "\n", "name", "\n", "for", "name", "in", "os", ".", "listdir", "(", "training_args", ".", "output_dir", ")", "\n", "if", "PREFIX_CHECKPOINT_DIR", "in", "name", "\n", "]", "\n", "if", "len", "(", "ckpts", ")", "!=", "1", ":", "\n", "                ", "raise", "Exception", "(", "\n", "\"more than 1 checkpoint file stored in pretrained path. revisit save directory\"", "\n", ")", "\n", "", "save_path", "=", "os", ".", "path", ".", "join", "(", "training_args", ".", "output_dir", ",", "ckpts", "[", "0", "]", ")", "\n", "# else save to main directory (i.e. evaluating existing HF pretrained model)", "\n", "", "else", ":", "\n", "            ", "save_path", "=", "training_args", ".", "output_dir", "\n", "", "", "else", ":", "\n", "        ", "save_path", "=", "os", ".", "path", ".", "dirname", "(", "data_args", ".", "generations_filepath", ")", "\n", "\n", "# store predictions", "\n", "", "start_time", "=", "time", ".", "time", "(", ")", "\n", "if", "data_args", ".", "train_predict", ":", "\n", "        ", "logger", ".", "info", "(", "\"*** Predict on train set***\"", ")", "\n", "if", "data_args", ".", "generations_filepath", "is", "not", "None", ":", "\n", "            ", "assert", "\"train\"", "in", "data_args", ".", "generations_filepath", "\n", "", "acc", "=", "compute_metrics", "(", "\n", "save_path", ",", "\n", "train_dataset", ",", "\n", "model", ",", "\n", "tokenizer", ",", "\n", "\"train\"", ",", "\n", "data_args", ".", "task_name", ",", "\n", "training_args", ".", "device", ",", "\n", "rationale_only", "=", "False", ",", "\n", "label_only", "=", "True", ",", "\n", "generations_file", "=", "data_args", ".", "generations_filepath", ",", "\n", ")", "\n", "results", "[", "\"train_acc\"", "]", "=", "acc", "\n", "if", "acc", "!=", "\"n/a\"", ":", "\n", "            ", "logger", ".", "info", "(", "\"Train Accuracy: %f\"", "%", "acc", ")", "\n", "\n", "", "", "if", "data_args", ".", "test_predict", "and", "data_args", ".", "task_name", "==", "\"esnli\"", ":", "\n", "        ", "logger", ".", "info", "(", "\"*** Predict on test set***\"", ")", "\n", "if", "data_args", ".", "generations_filepath", "is", "not", "None", ":", "\n", "            ", "assert", "\"test\"", "in", "data_args", ".", "generations_filepath", "\n", "", "acc", "=", "compute_metrics", "(", "\n", "save_path", ",", "\n", "test_dataset", ",", "\n", "model", ",", "\n", "tokenizer", ",", "\n", "\"test\"", ",", "\n", "data_args", ".", "task_name", ",", "\n", "training_args", ".", "device", ",", "\n", "rationale_only", "=", "False", ",", "\n", "label_only", "=", "True", ",", "\n", "generations_file", "=", "data_args", ".", "generations_filepath", ",", "\n", ")", "\n", "results", "[", "\"test_acc\"", "]", "=", "acc", "\n", "if", "acc", "!=", "\"n/a\"", ":", "\n", "            ", "logger", ".", "info", "(", "\"Test Accuracy: %f\"", "%", "acc", ")", "\n", "\n", "", "", "if", "data_args", ".", "dev_predict", ":", "\n", "        ", "logger", ".", "info", "(", "\"*** Predict on dev set***\"", ")", "\n", "if", "data_args", ".", "generations_filepath", "is", "not", "None", ":", "\n", "            ", "assert", "\"validation\"", "in", "data_args", ".", "generations_filepath", "\n", "", "acc", "=", "compute_metrics", "(", "\n", "save_path", ",", "\n", "eval_dataset", ",", "\n", "model", ",", "\n", "tokenizer", ",", "\n", "\"validation\"", ",", "\n", "data_args", ".", "task_name", ",", "\n", "training_args", ".", "device", ",", "\n", "rationale_only", "=", "False", ",", "\n", "label_only", "=", "True", ",", "\n", "generations_file", "=", "data_args", ".", "generations_filepath", ",", "\n", ")", "\n", "results", "[", "\"dev_acc\"", "]", "=", "acc", "\n", "if", "acc", "!=", "\"n/a\"", ":", "\n", "            ", "logger", ".", "info", "(", "\"Dev Accuracy: %f\"", "%", "acc", ")", "\n", "\n", "", "", "if", "data_args", ".", "generations_filepath", "is", "None", ":", "\n", "        ", "output_eval_file", "=", "os", ".", "path", ".", "join", "(", "training_args", ".", "output_dir", ",", "\"eval_results_lm.txt\"", ")", "\n", "", "else", ":", "\n", "        ", "output_eval_file", "=", "os", ".", "path", ".", "join", "(", "\n", "os", ".", "path", ".", "dirname", "(", "os", ".", "path", ".", "dirname", "(", "data_args", ".", "generations_filepath", ")", ")", ",", "\n", "\"eval_results_lm.txt\"", ",", "\n", ")", "\n", "with", "open", "(", "output_eval_file", ",", "\"a+\"", ")", "as", "writer", ":", "\n", "            ", "for", "key", "in", "sorted", "(", "results", ".", "keys", "(", ")", ")", ":", "\n", "                ", "if", "results", "[", "key", "]", "is", "not", "None", ":", "\n", "                    ", "logger", ".", "info", "(", "\"  %s = %s\"", ",", "key", ",", "str", "(", "results", "[", "key", "]", ")", ")", "\n", "writer", ".", "write", "(", "\"%s = %s\\n\"", "%", "(", "key", ",", "str", "(", "results", "[", "key", "]", ")", ")", ")", "\n", "\n", "", "", "", "", "predict_time", "=", "time", ".", "time", "(", ")", "-", "start_time", "\n", "\n", "# final logs", "\n", "logger", ".", "info", "(", "\"Git branch: %s\"", "%", "git_branch", ")", "\n", "logger", ".", "info", "(", "\"Git hash: %s\"", "%", "git_hash", ")", "\n", "logger", ".", "info", "(", "\"Save path: %s\"", "%", "training_args", ".", "output_dir", ")", "\n", "if", "training_args", ".", "do_train", ":", "\n", "        ", "logger", ".", "info", "(", "\"total train time: %.4f hours\"", "%", "(", "train_time", "/", "60.0", "/", "60.0", ")", ")", "\n", "", "if", "training_args", ".", "do_eval", ":", "\n", "        ", "logger", ".", "info", "(", "\"total eval time: %.4f hours\"", "%", "(", "eval_time", "/", "60.0", "/", "60.0", ")", ")", "\n", "", "if", "(", "\n", "data_args", ".", "train_predict", "\n", "or", "data_args", ".", "dev_predict", "\n", "or", "(", "data_args", ".", "test_predict", "and", "data_args", ".", "task_name", "==", "\"esnli\"", ")", "\n", ")", ":", "\n", "        ", "logger", ".", "info", "(", "\"total predict time: %.4f hours\"", "%", "(", "predict_time", "/", "60.0", "/", "60.0", ")", ")", "\n", "", "logger", ".", "info", "(", "\n", "\"TOTAL SCRIPT TIME: %.4f hours\"", "%", "(", "(", "time", ".", "time", "(", ")", "-", "og_start_time", ")", "/", "60.0", "/", "60.0", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.allenai_label_rationale_association.None.trainer.Trainer.__init__": [[68, 103], ["model.to", "trainer.set_seed", "os.makedirs", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.allenai_label_rationale_association.None.trainer.set_seed"], ["def", "__init__", "(", "\n", "self", ",", "\n", "model", ":", "PreTrainedModel", ",", "\n", "args", ":", "TrainingArguments", ",", "\n", "data_args", ":", "DataTrainingArguments", ",", "\n", "data_collator", ":", "DataCollator", ",", "\n", "train_dataset", ":", "Optional", "[", "Dataset", "]", "=", "None", ",", "\n", "eval_dataset", ":", "Optional", "[", "Dataset", "]", "=", "None", ",", "\n", "compute_metrics", ":", "Optional", "[", "Callable", "[", "[", "EvalPrediction", "]", ",", "Dict", "]", "]", "=", "None", ",", "\n", "prediction_loss_only", "=", "False", ",", "\n", "optimizers", ":", "Tuple", "[", "\n", "torch", ".", "optim", ".", "Optimizer", ",", "torch", ".", "optim", ".", "lr_scheduler", ".", "LambdaLR", "\n", "]", "=", "None", ",", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Trainer is a simple but feature-complete training and eval loop for PyTorch,\n        optimized for Transformers.\n\n        Args:\n            prediction_loss_only:\n                (Optional) in evaluation and prediction, only return the loss\n        \"\"\"", "\n", "self", ".", "model", "=", "model", ".", "to", "(", "args", ".", "device", ")", "\n", "self", ".", "args", "=", "args", "\n", "self", ".", "data_collator", "=", "data_collator", "\n", "self", ".", "train_dataset", "=", "train_dataset", "\n", "self", ".", "eval_dataset", "=", "eval_dataset", "\n", "self", ".", "compute_metrics", "=", "compute_metrics", "\n", "self", ".", "prediction_loss_only", "=", "prediction_loss_only", "\n", "self", ".", "optimizers", "=", "optimizers", "\n", "set_seed", "(", "self", ".", "args", ".", "seed", ")", "\n", "# Create output directory if needed", "\n", "os", ".", "makedirs", "(", "self", ".", "args", ".", "output_dir", ",", "exist_ok", "=", "True", ")", "\n", "self", ".", "early_stopping_threshold", "=", "data_args", ".", "early_stopping_threshold", "\n", "self", ".", "log", "=", "os", ".", "path", ".", "join", "(", "self", ".", "args", ".", "output_dir", ",", "\"training_log.txt\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_label_rationale_association.None.trainer.Trainer.get_train_dataloader": [[104, 117], ["torch.utils.data.sampler.RandomSampler", "torch.utils.data.dataloader.DataLoader", "ValueError"], "methods", ["None"], ["", "def", "get_train_dataloader", "(", "self", ")", "->", "DataLoader", ":", "\n", "        ", "if", "self", ".", "train_dataset", "is", "None", ":", "\n", "            ", "raise", "ValueError", "(", "\"Trainer: training requires a train_dataset.\"", ")", "\n", "", "train_sampler", "=", "RandomSampler", "(", "self", ".", "train_dataset", ")", "\n", "\n", "data_loader", "=", "DataLoader", "(", "\n", "self", ".", "train_dataset", ",", "\n", "batch_size", "=", "self", ".", "args", ".", "train_batch_size", ",", "\n", "sampler", "=", "train_sampler", ",", "\n", "collate_fn", "=", "self", ".", "data_collator", ".", "collate_batch", ",", "\n", ")", "\n", "\n", "return", "data_loader", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_label_rationale_association.None.trainer.Trainer.get_eval_dataloader": [[118, 133], ["torch.utils.data.sampler.SequentialSampler", "torch.utils.data.dataloader.DataLoader", "ValueError"], "methods", ["None"], ["", "def", "get_eval_dataloader", "(", "self", ",", "eval_dataset", ":", "Optional", "[", "Dataset", "]", "=", "None", ")", "->", "DataLoader", ":", "\n", "        ", "if", "eval_dataset", "is", "None", "and", "self", ".", "eval_dataset", "is", "None", ":", "\n", "            ", "raise", "ValueError", "(", "\"Trainer: evaluation requires an eval_dataset.\"", ")", "\n", "\n", "", "eval_dataset", "=", "eval_dataset", "if", "eval_dataset", "is", "not", "None", "else", "self", ".", "eval_dataset", "\n", "sampler", "=", "SequentialSampler", "(", "eval_dataset", ")", "\n", "\n", "data_loader", "=", "DataLoader", "(", "\n", "eval_dataset", ",", "\n", "sampler", "=", "sampler", ",", "\n", "batch_size", "=", "self", ".", "args", ".", "eval_batch_size", ",", "\n", "collate_fn", "=", "self", ".", "data_collator", ".", "collate_batch", ",", "\n", ")", "\n", "\n", "return", "data_loader", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_label_rationale_association.None.trainer.Trainer.get_test_dataloader": [[134, 146], ["torch.utils.data.sampler.SequentialSampler", "torch.utils.data.dataloader.DataLoader"], "methods", ["None"], ["", "def", "get_test_dataloader", "(", "self", ",", "test_dataset", ":", "Dataset", ")", "->", "DataLoader", ":", "\n", "# We use the same batch_size as for eval.", "\n", "        ", "sampler", "=", "SequentialSampler", "(", "test_dataset", ")", "\n", "\n", "data_loader", "=", "DataLoader", "(", "\n", "test_dataset", ",", "\n", "sampler", "=", "sampler", ",", "\n", "batch_size", "=", "self", ".", "args", ".", "eval_batch_size", ",", "\n", "collate_fn", "=", "self", ".", "data_collator", ".", "collate_batch", ",", "\n", ")", "\n", "\n", "return", "data_loader", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_label_rationale_association.None.trainer.Trainer.get_optimizers": [[147, 190], ["transformers.optimization.AdamW", "transformers.optimization.get_linear_schedule_with_warmup", "trainer.Trainer.model.named_parameters", "trainer.Trainer.model.named_parameters", "any", "any"], "methods", ["None"], ["", "def", "get_optimizers", "(", "\n", "self", ",", "num_training_steps", ":", "int", "\n", ")", "->", "Tuple", "[", "torch", ".", "optim", ".", "Optimizer", ",", "torch", ".", "optim", ".", "lr_scheduler", ".", "LambdaLR", "]", ":", "\n", "        ", "\"\"\"\n        Setup the optimizer and the learning rate scheduler.\n\n        We provide a reasonable default that works well.\n        If you want to use something else, you can pass a tuple in the Trainer's init,\n        or override this method in a subclass.\n        \"\"\"", "\n", "if", "self", ".", "optimizers", "is", "not", "None", ":", "\n", "            ", "return", "self", ".", "optimizers", "\n", "# Prepare optimizer and schedule (linear warmup and decay)", "\n", "", "no_decay", "=", "[", "\"bias\"", ",", "\"LayerNorm.weight\"", "]", "\n", "optimizer_grouped_parameters", "=", "[", "\n", "{", "\n", "\"params\"", ":", "[", "\n", "p", "\n", "for", "n", ",", "p", "in", "self", ".", "model", ".", "named_parameters", "(", ")", "\n", "if", "not", "any", "(", "nd", "in", "n", "for", "nd", "in", "no_decay", ")", "\n", "]", ",", "\n", "\"weight_decay\"", ":", "self", ".", "args", ".", "weight_decay", ",", "\n", "}", ",", "\n", "{", "\n", "\"params\"", ":", "[", "\n", "p", "\n", "for", "n", ",", "p", "in", "self", ".", "model", ".", "named_parameters", "(", ")", "\n", "if", "any", "(", "nd", "in", "n", "for", "nd", "in", "no_decay", ")", "\n", "]", ",", "\n", "\"weight_decay\"", ":", "0.0", ",", "\n", "}", ",", "\n", "]", "\n", "optimizer", "=", "AdamW", "(", "\n", "optimizer_grouped_parameters", ",", "\n", "lr", "=", "self", ".", "args", ".", "learning_rate", ",", "\n", "eps", "=", "self", ".", "args", ".", "adam_epsilon", ",", "\n", ")", "\n", "scheduler", "=", "get_linear_schedule_with_warmup", "(", "\n", "optimizer", ",", "\n", "num_warmup_steps", "=", "self", ".", "args", ".", "warmup_steps", ",", "\n", "num_training_steps", "=", "num_training_steps", ",", "\n", ")", "\n", "return", "optimizer", ",", "scheduler", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_label_rationale_association.None.trainer.Trainer.num_examples": [[191, 196], ["len"], "methods", ["None"], ["", "def", "num_examples", "(", "self", ",", "dataloader", ":", "DataLoader", ")", "->", "int", ":", "\n", "        ", "\"\"\"\n        Helper to get num of examples from a DataLoader, by accessing its Dataset.\n        \"\"\"", "\n", "return", "len", "(", "dataloader", ".", "dataset", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_label_rationale_association.None.trainer.Trainer.train": [[197, 378], ["trainer.Trainer.get_train_dataloader", "trainer.Trainer.get_eval_dataloader", "trainer.Trainer.get_optimizers", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "model.zero_grad", "tqdm.auto.tqdm.auto.trange", "logger.info", "ckpts.remove", "transformers.trainer_utils.TrainOutput", "int", "trainer.Trainer.num_examples", "int", "tqdm.auto.tqdm.auto.tqdm", "enumerate", "dev_losses.append", "shutil.rmtree", "numpy.mean", "tr_loss.append", "numpy.mean", "logger.info", "trainer.Trainer._log", "trainer.Trainer.evaluate", "logger.info", "hasattr", "os.path.join", "trainer.Trainer.save_model", "trainer.Trainer._rotate_checkpoints", "torch.save", "torch.save", "logger.info", "tqdm.auto.tqdm.auto.trange.close", "trainer.Trainer.evaluate", "dev_losses.index", "logger.info", "logger.info", "logger.info", "os.path.join", "logger.info", "transformers.T5ForConditionalGeneration.from_pretrained().to", "os.listdir", "int", "os.path.join", "trainer.Trainer._training_step", "torch.nn.utils.clip_grad_norm_", "optimizer.step", "scheduler.step", "model.zero_grad", "round", "tqdm.auto.tqdm.auto.tqdm.close", "optimizer.state_dict", "os.path.join", "scheduler.state_dict", "os.path.join", "min", "len", "len", "len", "model.parameters", "packaging.version.parse", "packaging.version.parse", "scheduler.get_last_lr", "scheduler.get_lr", "min", "transformers.T5ForConditionalGeneration.from_pretrained", "len", "len", "int", "int", "len"], "methods", ["home.repos.pwc.inspect_result.allenai_label_rationale_association.None.trainer.Trainer.get_train_dataloader", "home.repos.pwc.inspect_result.allenai_label_rationale_association.None.trainer.Trainer.get_eval_dataloader", "home.repos.pwc.inspect_result.allenai_label_rationale_association.None.trainer.Trainer.get_optimizers", "home.repos.pwc.inspect_result.allenai_label_rationale_association.None.trainer.Trainer.num_examples", "home.repos.pwc.inspect_result.allenai_label_rationale_association.None.trainer.Trainer._log", "home.repos.pwc.inspect_result.allenai_label_rationale_association.None.trainer.Trainer.evaluate", "home.repos.pwc.inspect_result.allenai_label_rationale_association.None.trainer.Trainer.save_model", "home.repos.pwc.inspect_result.allenai_label_rationale_association.None.trainer.Trainer._rotate_checkpoints", "home.repos.pwc.inspect_result.allenai_label_rationale_association.None.trainer.Trainer.evaluate", "home.repos.pwc.inspect_result.allenai_label_rationale_association.None.trainer.Trainer._training_step"], ["", "def", "train", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Main training entry point.\n        \"\"\"", "\n", "train_dataloader", "=", "self", ".", "get_train_dataloader", "(", ")", "\n", "eval_dataloader", "=", "self", ".", "get_eval_dataloader", "(", ")", "\n", "if", "self", ".", "args", ".", "max_steps", ">", "0", ":", "\n", "            ", "t_total", "=", "self", ".", "args", ".", "max_steps", "\n", "num_train_epochs", "=", "(", "\n", "self", ".", "args", ".", "max_steps", "\n", "//", "(", "len", "(", "train_dataloader", ")", "//", "self", ".", "args", ".", "gradient_accumulation_steps", ")", "\n", "+", "1", "\n", ")", "\n", "", "else", ":", "\n", "            ", "t_total", "=", "int", "(", "\n", "len", "(", "train_dataloader", ")", "\n", "//", "self", ".", "args", ".", "gradient_accumulation_steps", "\n", "*", "self", ".", "args", ".", "num_train_epochs", "\n", ")", "\n", "num_train_epochs", "=", "self", ".", "args", ".", "num_train_epochs", "\n", "\n", "", "optimizer", ",", "scheduler", "=", "self", ".", "get_optimizers", "(", "num_training_steps", "=", "t_total", ")", "\n", "model", "=", "self", ".", "model", "\n", "\n", "# Train!", "\n", "total_train_batch_size", "=", "(", "\n", "self", ".", "args", ".", "train_batch_size", "*", "self", ".", "args", ".", "gradient_accumulation_steps", "\n", ")", "\n", "logger", ".", "info", "(", "\"***** Running training *****\"", ")", "\n", "logger", ".", "info", "(", "\"  Num examples = %d\"", ",", "self", ".", "num_examples", "(", "train_dataloader", ")", ")", "\n", "logger", ".", "info", "(", "\"  Num Epochs = %d\"", ",", "num_train_epochs", ")", "\n", "logger", ".", "info", "(", "\n", "\"  Instantaneous batch size per device = %d\"", ",", "\n", "self", ".", "args", ".", "per_gpu_train_batch_size", ",", "\n", ")", "\n", "logger", ".", "info", "(", "\n", "\"  Total train batch size (w. accumulation) = %d\"", ",", "\n", "total_train_batch_size", ",", "\n", ")", "\n", "logger", ".", "info", "(", "\n", "\"  Gradient Accumulation steps = %d\"", ",", "self", ".", "args", ".", "gradient_accumulation_steps", "\n", ")", "\n", "logger", ".", "info", "(", "\"  Total optimization steps = %d\"", ",", "t_total", ")", "\n", "\n", "self", ".", "global_step", "=", "0", "\n", "self", ".", "epoch", "=", "0", "\n", "epochs_trained", "=", "0", "\n", "\n", "dev_losses", "=", "[", "]", "\n", "best_epoch", "=", "num_train_epochs", "\n", "model", ".", "zero_grad", "(", ")", "\n", "train_iterator", "=", "trange", "(", "\n", "epochs_trained", ",", "\n", "int", "(", "num_train_epochs", ")", ",", "\n", "desc", "=", "\"Epoch\"", ",", "\n", ")", "\n", "for", "epoch", "in", "train_iterator", ":", "\n", "\n", "# reset training loss per-epoch", "\n", "            ", "tr_loss", "=", "[", "]", "\n", "\n", "epoch_iterator", "=", "tqdm", "(", "\n", "train_dataloader", ",", "\n", "desc", "=", "\"Iteration\"", ",", "\n", ")", "\n", "\n", "for", "step", ",", "inputs", "in", "enumerate", "(", "epoch_iterator", ")", ":", "\n", "\n", "                ", "tr_loss", ".", "append", "(", "self", ".", "_training_step", "(", "model", ",", "inputs", ",", "optimizer", ")", ")", "\n", "\n", "if", "(", "step", "+", "1", ")", "%", "self", ".", "args", ".", "gradient_accumulation_steps", "==", "0", "or", "(", "\n", "# last step in epoch but step is always smaller than gradient_accumulation_steps", "\n", "len", "(", "epoch_iterator", ")", "<=", "self", ".", "args", ".", "gradient_accumulation_steps", "\n", "and", "(", "step", "+", "1", ")", "==", "len", "(", "epoch_iterator", ")", "\n", ")", ":", "\n", "                    ", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "\n", "model", ".", "parameters", "(", ")", ",", "self", ".", "args", ".", "max_grad_norm", "\n", ")", "\n", "\n", "optimizer", ".", "step", "(", ")", "\n", "scheduler", ".", "step", "(", ")", "\n", "model", ".", "zero_grad", "(", ")", "\n", "self", ".", "global_step", "+=", "1", "\n", "self", ".", "epoch", "=", "round", "(", "epoch", "+", "(", "step", "+", "1", ")", "/", "len", "(", "epoch_iterator", ")", ")", "\n", "\n", "", "if", "self", ".", "args", ".", "max_steps", ">", "0", "and", "self", ".", "global_step", ">", "self", ".", "args", ".", "max_steps", ":", "\n", "                    ", "epoch_iterator", ".", "close", "(", ")", "\n", "break", "\n", "\n", "# do saving & logging once epoch is complete", "\n", "", "", "if", "(", "\n", "self", ".", "args", ".", "logging_steps", ">", "0", "\n", "and", "self", ".", "epoch", "%", "self", ".", "args", ".", "logging_steps", "==", "0", "\n", ")", "or", "(", "self", ".", "epoch", "==", "1", "and", "self", ".", "args", ".", "logging_first_step", ")", ":", "\n", "                ", "logs", ":", "Dict", "[", "str", ",", "float", "]", "=", "{", "}", "\n", "# compute avg. epoch loss", "\n", "logs", "[", "\"loss\"", "]", "=", "np", ".", "mean", "(", "tr_loss", ")", "\n", "logger", ".", "info", "(", "\"Training loss: %0.4f\"", "%", "logs", "[", "\"loss\"", "]", ")", "\n", "# backward compatibility for pytorch schedulers", "\n", "logs", "[", "\"learning_rate\"", "]", "=", "(", "\n", "scheduler", ".", "get_last_lr", "(", ")", "[", "0", "]", "\n", "if", "version", ".", "parse", "(", "torch", ".", "__version__", ")", ">=", "version", ".", "parse", "(", "\"1.4\"", ")", "\n", "else", "scheduler", ".", "get_lr", "(", ")", "[", "0", "]", "\n", ")", "\n", "\n", "self", ".", "_log", "(", "logs", ")", "\n", "\n", "# evaluate dev_loss on the dev set", "\n", "self", ".", "evaluate", "(", ")", "\n", "", "else", ":", "\n", "                ", "logger", ".", "info", "(", "\"not logging training loss\"", ")", "\n", "\n", "", "if", "self", ".", "args", ".", "save_steps", ">", "0", "and", "self", ".", "epoch", "%", "self", ".", "args", ".", "save_steps", "==", "0", ":", "\n", "# self.model is always a reference to the model we want to save.", "\n", "                ", "if", "hasattr", "(", "model", ",", "\"module\"", ")", ":", "\n", "                    ", "assert", "model", ".", "module", "is", "self", ".", "model", "\n", "", "else", ":", "\n", "                    ", "assert", "model", "is", "self", ".", "model", "\n", "# Save model checkpoint", "\n", "", "output_dir", "=", "os", ".", "path", ".", "join", "(", "\n", "self", ".", "args", ".", "output_dir", ",", "f\"{PREFIX_CHECKPOINT_DIR}-{int(self.epoch)}\"", "\n", ")", "\n", "\n", "self", ".", "save_model", "(", "output_dir", ")", "\n", "self", ".", "_rotate_checkpoints", "(", ")", "\n", "\n", "torch", ".", "save", "(", "\n", "optimizer", ".", "state_dict", "(", ")", ",", "os", ".", "path", ".", "join", "(", "output_dir", ",", "\"optimizer.pt\"", ")", "\n", ")", "\n", "torch", ".", "save", "(", "\n", "scheduler", ".", "state_dict", "(", ")", ",", "os", ".", "path", ".", "join", "(", "output_dir", ",", "\"scheduler.pt\"", ")", "\n", ")", "\n", "", "else", ":", "\n", "                ", "logger", ".", "info", "(", "\"not saving model\"", ")", "\n", "\n", "", "if", "self", ".", "args", ".", "max_steps", ">", "0", "and", "self", ".", "global_step", ">", "self", ".", "args", ".", "max_steps", ":", "\n", "                ", "train_iterator", ".", "close", "(", ")", "\n", "break", "\n", "\n", "# check if early stopping satisfied", "\n", "", "curr_dev_loss", "=", "self", ".", "evaluate", "(", "self", ".", "eval_dataset", ")", "[", "\"eval_loss\"", "]", "\n", "dev_losses", ".", "append", "(", "curr_dev_loss", ")", "\n", "if", "dev_losses", ".", "index", "(", "min", "(", "dev_losses", ")", ")", "<", "(", "\n", "len", "(", "dev_losses", ")", "-", "self", ".", "early_stopping_threshold", "\n", ")", ":", "\n", "                ", "logger", ".", "info", "(", "\n", "\"Early stopping at epoch %d and saving model...dev loss has not decreased for %d epochs\"", "\n", "%", "(", "epoch", "+", "1", ",", "self", ".", "early_stopping_threshold", ")", "\n", ")", "\n", "logger", ".", "info", "(", "\n", "\"Best epoch = %d\"", "%", "(", "epoch", "+", "1", "-", "self", ".", "early_stopping_threshold", ")", "\n", ")", "\n", "logger", ".", "info", "(", "\"Dev loss at best epoch: %0.4f\"", "%", "min", "(", "dev_losses", ")", ")", "\n", "\n", "# set self.model to the best model so that subsequent evaluation is from this", "\n", "best_epoch", "=", "epoch", "+", "1", "-", "self", ".", "early_stopping_threshold", "\n", "directory", "=", "os", ".", "path", ".", "join", "(", "\n", "self", ".", "args", ".", "output_dir", ",", "f\"{PREFIX_CHECKPOINT_DIR}-{int(best_epoch)}\"", "\n", ")", "\n", "logger", ".", "info", "(", "\"Reloading best-epoch model...\"", ")", "\n", "self", ".", "model", "=", "T5ForConditionalGeneration", ".", "from_pretrained", "(", "directory", ")", ".", "to", "(", "\n", "self", ".", "args", ".", "device", "\n", ")", "\n", "\n", "# stop training", "\n", "break", "\n", "\n", "", "", "logger", ".", "info", "(", "\"\\n\\nTraining completed\\n\\n\"", ")", "\n", "\n", "# delete extra checkpoints", "\n", "ckpts", "=", "[", "\n", "name", "\n", "for", "name", "in", "os", ".", "listdir", "(", "self", ".", "args", ".", "output_dir", ")", "\n", "if", "PREFIX_CHECKPOINT_DIR", "in", "name", "\n", "]", "\n", "keep_model", "=", "f\"{PREFIX_CHECKPOINT_DIR}-{int(best_epoch)}\"", "\n", "ckpts", ".", "remove", "(", "keep_model", ")", "\n", "for", "el", "in", "ckpts", ":", "\n", "            ", "shutil", ".", "rmtree", "(", "os", ".", "path", ".", "join", "(", "self", ".", "args", ".", "output_dir", ",", "el", ")", ")", "\n", "\n", "", "return", "TrainOutput", "(", "self", ".", "epoch", ",", "np", ".", "mean", "(", "tr_loss", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_label_rationale_association.None.trainer.Trainer._log": [[379, 386], ["json.dumps", "open", "f.write", "f.write"], "methods", ["None"], ["", "def", "_log", "(", "self", ",", "logs", ":", "Dict", "[", "str", ",", "float", "]", ")", "->", "None", ":", "\n", "        ", "if", "self", ".", "epoch", "is", "not", "None", ":", "\n", "            ", "logs", "[", "\"epoch\"", "]", "=", "self", ".", "epoch", "\n", "", "output", "=", "json", ".", "dumps", "(", "{", "**", "logs", ",", "**", "{", "\"step\"", ":", "self", ".", "epoch", "}", "}", ")", "\n", "with", "open", "(", "self", ".", "log", ",", "\"a\"", ")", "as", "f", ":", "\n", "            ", "f", ".", "write", "(", "output", ")", "\n", "f", ".", "write", "(", "\"\\n\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_label_rationale_association.None.trainer.Trainer._training_step": [[387, 408], ["model.train", "inputs.items", "model", "loss.backward", "loss.item", "v.to"], "methods", ["home.repos.pwc.inspect_result.allenai_label_rationale_association.None.trainer.Trainer.train"], ["", "", "def", "_training_step", "(", "\n", "self", ",", "\n", "model", ":", "torch", ".", "nn", ".", "Module", ",", "\n", "inputs", ":", "Dict", "[", "str", ",", "torch", ".", "Tensor", "]", ",", "\n", "optimizer", ":", "torch", ".", "optim", ".", "Optimizer", ",", "\n", ")", "->", "float", ":", "\n", "\n", "        ", "model", ".", "train", "(", ")", "\n", "for", "k", ",", "v", "in", "inputs", ".", "items", "(", ")", ":", "\n", "            ", "inputs", "[", "k", "]", "=", "v", ".", "to", "(", "self", ".", "args", ".", "device", ")", "\n", "\n", "", "outputs", "=", "model", "(", "**", "inputs", ")", "\n", "# model outputs are a tuple", "\n", "loss", "=", "outputs", "[", "0", "]", "\n", "\n", "if", "self", ".", "args", ".", "gradient_accumulation_steps", ">", "1", ":", "\n", "            ", "loss", "=", "loss", "/", "self", ".", "args", ".", "gradient_accumulation_steps", "\n", "\n", "", "loss", ".", "backward", "(", ")", "\n", "\n", "return", "loss", ".", "item", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_label_rationale_association.None.trainer.Trainer.save_model": [[409, 420], ["os.makedirs", "logger.info", "trainer.Trainer.model.save_pretrained", "torch.save", "isinstance", "ValueError", "os.path.join"], "methods", ["None"], ["", "def", "save_model", "(", "self", ",", "output_dir", ":", "Optional", "[", "str", "]", "=", "None", ")", ":", "\n", "\n", "        ", "output_dir", "=", "output_dir", "if", "output_dir", "is", "not", "None", "else", "self", ".", "args", ".", "output_dir", "\n", "os", ".", "makedirs", "(", "output_dir", ",", "exist_ok", "=", "True", ")", "\n", "logger", ".", "info", "(", "\"Saving model checkpoint to %s\"", ",", "output_dir", ")", "\n", "if", "not", "isinstance", "(", "self", ".", "model", ",", "PreTrainedModel", ")", ":", "\n", "            ", "raise", "ValueError", "(", "\"Trainer.model appears to not be a PreTrainedModel\"", ")", "\n", "", "self", ".", "model", ".", "save_pretrained", "(", "output_dir", ")", "\n", "\n", "# Good practice: save your training arguments together with the trained model", "\n", "torch", ".", "save", "(", "self", ".", "args", ",", "os", ".", "path", ".", "join", "(", "output_dir", ",", "\"training_args.bin\"", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_label_rationale_association.None.trainer.Trainer._sorted_checkpoints": [[421, 443], ["sorted", "str", "pathlib.Path().glob", "ordering_and_checkpoint_path.append", "re.match", "re.match.groups", "ordering_and_checkpoint_path.append", "pathlib.Path", "os.path.getmtime", "int", "re.match.groups"], "methods", ["None"], ["", "def", "_sorted_checkpoints", "(", "\n", "self", ",", "checkpoint_prefix", "=", "PREFIX_CHECKPOINT_DIR", ",", "use_mtime", "=", "False", "\n", ")", "->", "List", "[", "str", "]", ":", "\n", "        ", "ordering_and_checkpoint_path", "=", "[", "]", "\n", "\n", "glob_checkpoints", "=", "[", "\n", "str", "(", "x", ")", "for", "x", "in", "Path", "(", "self", ".", "args", ".", "output_dir", ")", ".", "glob", "(", "f\"{checkpoint_prefix}-*\"", ")", "\n", "]", "\n", "\n", "for", "path", "in", "glob_checkpoints", ":", "\n", "            ", "if", "use_mtime", ":", "\n", "                ", "ordering_and_checkpoint_path", ".", "append", "(", "(", "os", ".", "path", ".", "getmtime", "(", "path", ")", ",", "path", ")", ")", "\n", "", "else", ":", "\n", "                ", "regex_match", "=", "re", ".", "match", "(", "f\".*{checkpoint_prefix}-([0-9]+)\"", ",", "path", ")", "\n", "if", "regex_match", "and", "regex_match", ".", "groups", "(", ")", ":", "\n", "                    ", "ordering_and_checkpoint_path", ".", "append", "(", "\n", "(", "int", "(", "regex_match", ".", "groups", "(", ")", "[", "0", "]", ")", ",", "path", ")", "\n", ")", "\n", "\n", "", "", "", "checkpoints_sorted", "=", "sorted", "(", "ordering_and_checkpoint_path", ")", "\n", "checkpoints_sorted", "=", "[", "checkpoint", "[", "1", "]", "for", "checkpoint", "in", "checkpoints_sorted", "]", "\n", "return", "checkpoints_sorted", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_label_rationale_association.None.trainer.Trainer._rotate_checkpoints": [[444, 459], ["trainer.Trainer._sorted_checkpoints", "max", "len", "shutil.rmtree", "len"], "methods", ["home.repos.pwc.inspect_result.allenai_label_rationale_association.None.trainer.Trainer._sorted_checkpoints"], ["", "def", "_rotate_checkpoints", "(", "self", ",", "use_mtime", "=", "False", ")", "->", "None", ":", "\n", "        ", "if", "self", ".", "args", ".", "save_total_limit", "is", "None", "or", "self", ".", "args", ".", "save_total_limit", "<=", "0", ":", "\n", "            ", "return", "\n", "\n", "# Check if we should delete older checkpoint(s)", "\n", "", "checkpoints_sorted", "=", "self", ".", "_sorted_checkpoints", "(", "use_mtime", "=", "use_mtime", ")", "\n", "if", "len", "(", "checkpoints_sorted", ")", "<=", "self", ".", "args", ".", "save_total_limit", ":", "\n", "            ", "return", "\n", "\n", "", "number_of_checkpoints_to_delete", "=", "max", "(", "\n", "0", ",", "len", "(", "checkpoints_sorted", ")", "-", "self", ".", "args", ".", "save_total_limit", "\n", ")", "\n", "checkpoints_to_be_deleted", "=", "checkpoints_sorted", "[", ":", "number_of_checkpoints_to_delete", "]", "\n", "for", "checkpoint", "in", "checkpoints_to_be_deleted", ":", "\n", "            ", "shutil", ".", "rmtree", "(", "checkpoint", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_label_rationale_association.None.trainer.Trainer.evaluate": [[460, 486], ["trainer.Trainer.get_eval_dataloader", "trainer.Trainer._prediction_loop", "trainer.Trainer._log"], "methods", ["home.repos.pwc.inspect_result.allenai_label_rationale_association.None.trainer.Trainer.get_eval_dataloader", "home.repos.pwc.inspect_result.allenai_label_rationale_association.None.trainer.Trainer._prediction_loop", "home.repos.pwc.inspect_result.allenai_label_rationale_association.None.trainer.Trainer._log"], ["", "", "def", "evaluate", "(", "\n", "self", ",", "\n", "eval_dataset", ":", "Optional", "[", "Dataset", "]", "=", "None", ",", "\n", "prediction_loss_only", ":", "Optional", "[", "bool", "]", "=", "None", ",", "\n", ")", "->", "Dict", "[", "str", ",", "float", "]", ":", "\n", "        ", "\"\"\"\n        Run evaluation and return metrics.\n\n        The calling script will be responsible for providing a method to compute metrics, as they are\n        task-dependent.\n\n        Args:\n            eval_dataset: (Optional) Pass a dataset if you wish to override\n            the one on the instance.\n        Returns:\n            A dict containing:\n                - the eval loss\n                - the potential metrics computed from the predictions\n        \"\"\"", "\n", "eval_dataloader", "=", "self", ".", "get_eval_dataloader", "(", "eval_dataset", ")", "\n", "\n", "output", "=", "self", ".", "_prediction_loop", "(", "eval_dataloader", ",", "description", "=", "\"Evaluation\"", ")", "\n", "\n", "self", ".", "_log", "(", "output", ".", "metrics", ")", "\n", "\n", "return", "output", ".", "metrics", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_label_rationale_association.None.trainer.Trainer.predict": [[487, 497], ["trainer.Trainer.get_test_dataloader", "trainer.Trainer._prediction_loop"], "methods", ["home.repos.pwc.inspect_result.allenai_label_rationale_association.None.trainer.Trainer.get_test_dataloader", "home.repos.pwc.inspect_result.allenai_label_rationale_association.None.trainer.Trainer._prediction_loop"], ["", "def", "predict", "(", "self", ",", "test_dataset", ":", "Dataset", ")", "->", "PredictionOutput", ":", "\n", "        ", "\"\"\"\n        Run prediction and return predictions and potential metrics.\n\n        Depending on the dataset and your use case, your test dataset may contain labels.\n        In that case, this method will also return metrics, like in evaluate().\n        \"\"\"", "\n", "test_dataloader", "=", "self", ".", "get_test_dataloader", "(", "test_dataset", ")", "\n", "\n", "return", "self", ".", "_prediction_loop", "(", "test_dataloader", ",", "description", "=", "\"Prediction\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_label_rationale_association.None.trainer.Trainer._prediction_loop": [[498, 576], ["model.eval", "tqdm.auto.tqdm.auto.tqdm", "list", "logger.info", "transformers.trainer_utils.PredictionOutput", "inputs.items", "torch.cat.cpu().numpy", "torch.cat.cpu().numpy", "trainer.Trainer.compute_metrics", "len", "numpy.mean", "trainer.Trainer.keys", "inputs.get", "v.to", "torch.no_grad", "model", "transformers.trainer_utils.EvalPrediction", "key.startswith", "trainer.Trainer.pop", "logits.detach", "torch.cat", "inputs.get", "torch.cat.cpu", "torch.cat.cpu", "step_eval_loss.mean().item", "inputs[].detach", "torch.cat", "logits.detach", "step_eval_loss.mean", "inputs[].detach"], "methods", ["home.repos.pwc.inspect_result.allenai_label_rationale_association.None.custom_args.compute_metrics"], ["", "def", "_prediction_loop", "(", "\n", "self", ",", "\n", "dataloader", ":", "DataLoader", ",", "\n", "description", ":", "str", ",", "\n", "prediction_loss_only", ":", "Optional", "[", "bool", "]", "=", "None", ",", "\n", ")", "->", "PredictionOutput", ":", "\n", "        ", "\"\"\"\n        Prediction/evaluation loop, shared by `evaluate()` and `predict()`.\n\n        Works both with or without labels.\n        \"\"\"", "\n", "\n", "prediction_loss_only", "=", "(", "\n", "prediction_loss_only", "\n", "if", "prediction_loss_only", "is", "not", "None", "\n", "else", "self", ".", "prediction_loss_only", "\n", ")", "\n", "\n", "model", "=", "self", ".", "model", "\n", "batch_size", "=", "dataloader", ".", "batch_size", "\n", "eval_losses", ":", "List", "[", "float", "]", "=", "[", "]", "\n", "preds", ":", "torch", ".", "Tensor", "=", "None", "\n", "label_ids", ":", "torch", ".", "Tensor", "=", "None", "\n", "model", ".", "eval", "(", ")", "\n", "\n", "for", "inputs", "in", "tqdm", "(", "dataloader", ",", "desc", "=", "description", ")", ":", "\n", "            ", "has_labels", "=", "inputs", ".", "get", "(", "\"lm_labels\"", ")", "is", "not", "None", "\n", "\n", "for", "k", ",", "v", "in", "inputs", ".", "items", "(", ")", ":", "\n", "                ", "inputs", "[", "k", "]", "=", "v", ".", "to", "(", "self", ".", "args", ".", "device", ")", "\n", "\n", "", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "outputs", "=", "model", "(", "**", "inputs", ")", "\n", "if", "has_labels", ":", "\n", "                    ", "step_eval_loss", ",", "logits", "=", "outputs", "[", ":", "2", "]", "\n", "eval_losses", "+=", "[", "step_eval_loss", ".", "mean", "(", ")", ".", "item", "(", ")", "]", "\n", "", "else", ":", "\n", "                    ", "logits", "=", "outputs", "[", "0", "]", "\n", "\n", "", "", "if", "not", "prediction_loss_only", ":", "\n", "                ", "if", "preds", "is", "None", ":", "\n", "                    ", "preds", "=", "logits", ".", "detach", "(", ")", "\n", "", "else", ":", "\n", "                    ", "preds", "=", "torch", ".", "cat", "(", "(", "preds", ",", "logits", ".", "detach", "(", ")", ")", ",", "dim", "=", "0", ")", "\n", "", "if", "inputs", ".", "get", "(", "\"lm_labels\"", ")", "is", "not", "None", ":", "\n", "                    ", "if", "label_ids", "is", "None", ":", "\n", "                        ", "label_ids", "=", "inputs", "[", "\"lm_labels\"", "]", ".", "detach", "(", ")", "\n", "", "else", ":", "\n", "                        ", "label_ids", "=", "torch", ".", "cat", "(", "\n", "(", "label_ids", ",", "inputs", "[", "\"lm_labels\"", "]", ".", "detach", "(", ")", ")", ",", "dim", "=", "0", "\n", ")", "\n", "\n", "# Finally, turn the aggregated tensors into numpy arrays.", "\n", "", "", "", "", "if", "preds", "is", "not", "None", ":", "\n", "            ", "preds", "=", "preds", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "", "if", "label_ids", "is", "not", "None", ":", "\n", "            ", "label_ids", "=", "label_ids", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "\n", "", "if", "(", "\n", "self", ".", "compute_metrics", "is", "not", "None", "\n", "and", "preds", "is", "not", "None", "\n", "and", "label_ids", "is", "not", "None", "\n", ")", ":", "\n", "            ", "metrics", "=", "self", ".", "compute_metrics", "(", "\n", "EvalPrediction", "(", "predictions", "=", "preds", ",", "label_ids", "=", "label_ids", ")", "\n", ")", "\n", "", "else", ":", "\n", "            ", "metrics", "=", "{", "}", "\n", "", "if", "len", "(", "eval_losses", ")", ">", "0", ":", "\n", "            ", "metrics", "[", "\"eval_loss\"", "]", "=", "np", ".", "mean", "(", "eval_losses", ")", "\n", "\n", "# Prefix all keys with eval_", "\n", "", "for", "key", "in", "list", "(", "metrics", ".", "keys", "(", ")", ")", ":", "\n", "            ", "if", "not", "key", ".", "startswith", "(", "\"eval_\"", ")", ":", "\n", "                ", "metrics", "[", "f\"eval_{key}\"", "]", "=", "metrics", ".", "pop", "(", "key", ")", "\n", "", "", "logger", ".", "info", "(", "\"%s loss: %0.4f\"", "%", "(", "description", ",", "metrics", "[", "\"eval_loss\"", "]", ")", ")", "\n", "\n", "return", "PredictionOutput", "(", "predictions", "=", "preds", ",", "label_ids", "=", "label_ids", ",", "metrics", "=", "metrics", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.allenai_label_rationale_association.None.trainer.set_seed": [[42, 47], ["random.seed", "numpy.random.seed", "torch.manual_seed", "torch.cuda.manual_seed_all"], "function", ["None"], ["def", "set_seed", "(", "seed", ":", "int", ")", ":", "\n", "    ", "random", ".", "seed", "(", "seed", ")", "\n", "np", ".", "random", ".", "seed", "(", "seed", ")", "\n", "torch", ".", "manual_seed", "(", "seed", ")", "\n", "torch", ".", "cuda", ".", "manual_seed_all", "(", "seed", ")", "\n", "# ^^ safe to call this function even if cuda is not available", "\n"]], "home.repos.pwc.inspect_result.allenai_label_rationale_association.None.input_to_label_and_rationale.SequenceCollator.__init__": [[44, 56], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "pad_token", ")", ":", "\n", "        ", "self", ".", "pad_token_mapping", "=", "{", "\n", "\"lm_labels\"", ":", "-", "100", ",", "\n", "\"attention_mask\"", ":", "0", ",", "\n", "\"decoder_attention_mask\"", ":", "0", ",", "\n", "\"input_ids\"", ":", "pad_token", ",", "\n", "}", "\n", "self", ".", "columns", "=", "[", "\n", "\"input_ids\"", ",", "\n", "\"attention_mask\"", ",", "\n", "\"lm_labels\"", ",", "\n", "\"decoder_attention_mask\"", ",", "\n", "]", "\n"]], "home.repos.pwc.inspect_result.allenai_label_rationale_association.None.input_to_label_and_rationale.SequenceCollator.collate_batch": [[58, 78], ["examples[].keys", "isinstance", "torch.tensor", "tmp_list.append", "max", "map", "len"], "methods", ["None"], ["", "def", "collate_batch", "(", "self", ",", "examples", ")", ":", "\n", "\n", "# batch inputs for training", "\n", "        ", "batch", "=", "{", "}", "\n", "for", "key", "in", "examples", "[", "0", "]", ".", "keys", "(", ")", ":", "\n", "            ", "if", "key", "in", "self", ".", "columns", ":", "\n", "                ", "tmp_list", "=", "[", "]", "\n", "for", "item", "in", "examples", ":", "\n", "                    ", "tmp_list", ".", "append", "(", "item", "[", "key", "]", ")", "\n", "\n", "# pad lists to max length", "\n", "", "if", "isinstance", "(", "tmp_list", "[", "0", "]", ",", "list", ")", ":", "\n", "                    ", "max_length", "=", "max", "(", "map", "(", "len", ",", "tmp_list", ")", ")", "\n", "tmp_list", "=", "[", "\n", "el", "+", "[", "self", ".", "pad_token_mapping", "[", "key", "]", "]", "*", "(", "max_length", "-", "len", "(", "el", ")", ")", "\n", "for", "el", "in", "tmp_list", "\n", "]", "\n", "\n", "", "batch", "[", "key", "]", "=", "torch", ".", "tensor", "(", "tmp_list", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "", "", "return", "batch", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_label_rationale_association.None.input_to_label_and_rationale.main": [[80, 473], ["time.time", "transformers.HfArgumentParser", "transformers.HfArgumentParser.parse_args_into_dataclasses", "logging.basicConfig", "logger.warning", "logger.info", "git.Repo", "logger.info", "logger.info", "int", "transformers.set_seed", "logger.info", "T5Tokenizer.from_pretrained.add_special_tokens", "nlp.load_dataset", "nlp.load_dataset.keys", "logger.info", "logger.info", "logger.info", "time.time", "logger.info", "logger.info", "logger.info", "logger.info", "os.path.join", "os.path.exists", "os.makedirs", "bool", "Exception", "transformers.T5Tokenizer.from_pretrained", "transformers.T5Tokenizer.from_pretrained", "T5ForConditionalGeneration.from_pretrained.resize_token_embeddings", "dataset[].map", "len", "len", "logger.info", "trainer.Trainer", "time.time", "trainer.Trainer.train", "trainer.Trainer.save_model", "T5Tokenizer.from_pretrained.save_pretrained", "T5ForConditionalGeneration.from_pretrained.eval", "time.time", "logger.info", "trainer.Trainer.evaluate", "math.exp", "logger.info", "trainer.Trainer.evaluate", "math.exp", "os.path.dirname", "logger.info", "custom_args.compute_metrics", "logger.info", "custom_args.compute_metrics", "logger.info", "custom_args.compute_metrics", "os.path.join", "os.path.join", "open", "sorted", "time.time", "logger.info", "logger.info", "logger.info", "Exception", "datetime.datetime.now().strftime", "os.path.exists", "os.path.exists", "os.listdir", "ValueError", "logging.FileHandler", "logging.StreamHandler", "logging.StreamHandler", "open", "f.write", "f.write", "f.write", "f.write", "f.write", "tmp.pop", "tmp.pop", "tmp.pop", "tmp.pop", "tmp.pop", "json.dump", "f.write", "json.dump", "f.write", "json.dump", "len", "T5Tokenizer.from_pretrained.encode", "os.path.join", "transformers.T5ForConditionalGeneration.from_pretrained", "logger.info", "len", "len", "len", "len", "len", "time.time", "logger.info", "trainer.Trainer.evaluate", "logger.info", "math.exp", "time.time", "os.path.join", "logger.info", "logger.info", "logger.info", "os.path.dirname", "results.keys", "os.path.join", "os.path.join", "len", "Exception", "Exception", "transformers.T5ForConditionalGeneration.from_pretrained", "transformers.T5ForConditionalGeneration.from_pretrained", "feature_conversion_methods.input_to_explanation_plus_label", "input_to_label_and_rationale.SequenceCollator", "len", "Exception", "os.path.dirname", "logger.info", "writer.write", "datetime.datetime.now", "os.listdir", "len", "len", "os.listdir", "str", "len", "len", "time.time", "str"], "function", ["home.repos.pwc.inspect_result.allenai_label_rationale_association.None.trainer.set_seed", "home.repos.pwc.inspect_result.allenai_label_rationale_association.None.trainer.Trainer.train", "home.repos.pwc.inspect_result.allenai_label_rationale_association.None.trainer.Trainer.save_model", "home.repos.pwc.inspect_result.allenai_label_rationale_association.None.trainer.Trainer.evaluate", "home.repos.pwc.inspect_result.allenai_label_rationale_association.None.trainer.Trainer.evaluate", "home.repos.pwc.inspect_result.allenai_label_rationale_association.None.custom_args.compute_metrics", "home.repos.pwc.inspect_result.allenai_label_rationale_association.None.custom_args.compute_metrics", "home.repos.pwc.inspect_result.allenai_label_rationale_association.None.custom_args.compute_metrics", "home.repos.pwc.inspect_result.allenai_label_rationale_association.None.trainer.Trainer.evaluate", "home.repos.pwc.inspect_result.allenai_label_rationale_association.None.feature_conversion_methods.input_to_explanation_plus_label"], ["", "", "def", "main", "(", ")", ":", "\n", "# See all possible arguments in src/transformers/training_args.py", "\n", "# or by passing the --help flag to this script.", "\n", "\n", "    ", "og_start_time", "=", "time", ".", "time", "(", ")", "\n", "\n", "parser", "=", "HfArgumentParser", "(", "\n", "(", "ModelArguments", ",", "DataTrainingArguments", ",", "TrainingArguments", ")", "\n", ")", "\n", "model_args", ",", "data_args", ",", "training_args", "=", "parser", ".", "parse_args_into_dataclasses", "(", ")", "\n", "\n", "if", "not", "training_args", ".", "do_train", ":", "\n", "        ", "if", "(", "not", "model_args", ".", "pretrained_model_file", ")", "and", "(", "\n", "not", "data_args", ".", "generations_filepath", "\n", ")", ":", "\n", "            ", "raise", "Exception", "(", "\n", "\"if not training a model from scratch, must specify a trained model to load for evaluation or generations in a file to evaluate\"", "\n", ")", "\n", "\n", "# make sure only one dataset split pick if manually specifying evaluation file", "\n", "", "", "if", "data_args", ".", "generations_filepath", "is", "not", "None", ":", "\n", "        ", "training_args", ".", "do_train", "=", "False", "\n", "training_args", ".", "do_eval", "=", "False", "\n", "if", "\"train\"", "in", "data_args", ".", "generations_filepath", ":", "\n", "            ", "data_args", ".", "train_predict", "=", "True", "\n", "data_args", ".", "test_predict", "=", "False", "\n", "data_args", ".", "dev_predict", "=", "False", "\n", "", "elif", "\"test\"", "in", "data_args", ".", "generations_filepath", ":", "\n", "            ", "data_args", ".", "train_predict", "=", "False", "\n", "data_args", ".", "test_predict", "=", "True", "\n", "data_args", ".", "dev_predict", "=", "False", "\n", "", "elif", "\"validation\"", "in", "data_args", ".", "generations_filepath", ":", "\n", "            ", "data_args", ".", "train_predict", "=", "False", "\n", "data_args", ".", "test_predict", "=", "False", "\n", "data_args", ".", "dev_predict", "=", "True", "\n", "\n", "# create a new directory if fine-tuning an existing checkpoint or training/evaluating a HF pretrained model", "\n", "# do not do this when re-evaluating a pretrained_model_file", "\n", "", "", "if", "training_args", ".", "do_train", "or", "(", "\n", "not", "model_args", ".", "pretrained_model_file", "and", "not", "data_args", ".", "generations_filepath", "\n", ")", ":", "\n", "# create a save directory and a logfile", "\n", "        ", "save_path", "=", "training_args", ".", "output_dir", "\n", "training_args", ".", "output_dir", "=", "os", ".", "path", ".", "join", "(", "\n", "save_path", ",", "datetime", ".", "now", "(", ")", ".", "strftime", "(", "\"%m%d%y_%H%M%S\"", ")", "\n", ")", "\n", "training_args", ".", "logging_dir", "=", "training_args", ".", "output_dir", "\n", "assert", "os", ".", "path", ".", "exists", "(", "save_path", ")", "\n", "assert", "not", "os", ".", "path", ".", "exists", "(", "training_args", ".", "output_dir", ")", "\n", "os", ".", "makedirs", "(", "training_args", ".", "output_dir", ")", "\n", "\n", "if", "(", "\n", "os", ".", "path", ".", "exists", "(", "training_args", ".", "output_dir", ")", "\n", "and", "os", ".", "listdir", "(", "training_args", ".", "output_dir", ")", "\n", "and", "training_args", ".", "do_train", "\n", "and", "not", "training_args", ".", "overwrite_output_dir", "\n", ")", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "f\"Output directory ({training_args.output_dir}) already exists and is not empty. Use --overwrite_output_dir to overcome.\"", "\n", ")", "\n", "", "handlers", "=", "[", "\n", "logging", ".", "FileHandler", "(", "os", ".", "path", ".", "join", "(", "training_args", ".", "output_dir", ",", "\"logger.log\"", ")", ")", ",", "\n", "logging", ".", "StreamHandler", "(", ")", ",", "\n", "]", "\n", "", "else", ":", "\n", "# don't overwrite existing logfile or create new directory", "\n", "        ", "training_args", ".", "output_dir", "=", "model_args", ".", "pretrained_model_file", "\n", "handlers", "=", "[", "logging", ".", "StreamHandler", "(", ")", "]", "\n", "\n", "# Setup logging", "\n", "", "logging", ".", "basicConfig", "(", "\n", "format", "=", "\"%(asctime)s - %(levelname)s - %(name)s -   %(message)s\"", ",", "\n", "datefmt", "=", "\"%m/%d/%Y %H:%M:%S\"", ",", "\n", "level", "=", "logging", ".", "INFO", "if", "training_args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", "else", "logging", ".", "WARN", ",", "\n", "handlers", "=", "handlers", ",", "\n", ")", "\n", "logger", ".", "warning", "(", "\n", "\"Process rank: %s, device: %s, n_gpu: %s, distributed training: %s, 16-bits training: %s\"", ",", "\n", "training_args", ".", "local_rank", ",", "\n", "training_args", ".", "device", ",", "\n", "training_args", ".", "n_gpu", ",", "\n", "bool", "(", "training_args", ".", "local_rank", "!=", "-", "1", ")", ",", "\n", "training_args", ".", "fp16", ",", "\n", ")", "\n", "logger", ".", "info", "(", "\"Save path: %s\"", "%", "training_args", ".", "output_dir", ")", "\n", "\n", "# get git hash and branch where deployed", "\n", "repo", "=", "git", ".", "Repo", "(", "search_parent_directories", "=", "True", ")", "\n", "git_hash", "=", "repo", ".", "head", ".", "object", ".", "hexsha", "\n", "git_branch", "=", "repo", ".", "active_branch", ".", "name", "\n", "logger", ".", "info", "(", "\"Git branch: %s\"", "%", "git_branch", ")", "\n", "logger", ".", "info", "(", "\"Git hash: %s\"", "%", "git_hash", ")", "\n", "\n", "assert", "data_args", ".", "task_name", "in", "{", "\"cos_e\"", ",", "\"esnli\"", "}", "\n", "\n", "# set gradient accumulation steps to always use batch size == 64", "\n", "if", "64", "%", "training_args", ".", "per_gpu_train_batch_size", "!=", "0", ":", "\n", "        ", "raise", "Exception", "(", "\n", "\"Batch size is not a divisor of 64, resulting in inconsistent gradient-accumulation behavior\"", "\n", ")", "\n", "", "training_args", ".", "gradient_accumulation_steps", "=", "int", "(", "\n", "64", "/", "training_args", ".", "per_gpu_train_batch_size", "\n", ")", "\n", "\n", "if", "training_args", ".", "do_train", ":", "\n", "# write command and args to file", "\n", "        ", "with", "open", "(", "\n", "os", ".", "path", ".", "join", "(", "training_args", ".", "output_dir", ",", "\"commandline_args.txt\"", ")", ",", "\"w\"", "\n", ")", "as", "f", ":", "\n", "            ", "f", ".", "write", "(", "\"Git branch: \"", "+", "git_branch", "+", "\"\\n\"", ")", "\n", "f", ".", "write", "(", "\"Git hash: \"", "+", "git_hash", "+", "\"\\n\"", ")", "\n", "f", ".", "write", "(", "\"Command:\\n\"", ")", "\n", "f", ".", "write", "(", "\"\\n\"", ".", "join", "(", "sys", ".", "argv", "[", "1", ":", "]", ")", ")", "\n", "f", ".", "write", "(", "\"Training args:\\n\"", ")", "\n", "# make training_args dict writeable", "\n", "tmp", "=", "training_args", ".", "__dict__", "\n", "tmp", ".", "pop", "(", "\"__cached__setup_devices\"", ",", "None", ")", "\n", "tmp", ".", "pop", "(", "\"evaluation_strategy\"", ",", "None", ")", "\n", "tmp", ".", "pop", "(", "\"lr_scheduler_type\"", ",", "None", ")", "\n", "tmp", ".", "pop", "(", "\"logging_strategy\"", ",", "None", ")", "\n", "tmp", ".", "pop", "(", "\"save_strategy\"", ",", "None", ")", "\n", "json", ".", "dump", "(", "tmp", ",", "f", ",", "indent", "=", "2", ")", "\n", "f", ".", "write", "(", "\"Data args:\\n\"", ")", "\n", "json", ".", "dump", "(", "data_args", ".", "__dict__", ",", "f", ",", "indent", "=", "2", ")", "\n", "f", ".", "write", "(", "\"Model args:\\n\"", ")", "\n", "json", ".", "dump", "(", "model_args", ".", "__dict__", ",", "f", ",", "indent", "=", "2", ")", "\n", "\n", "# Set seed", "\n", "", "", "set_seed", "(", "training_args", ".", "seed", ")", "\n", "\n", "# Load pretrained model and tokenizer", "\n", "logger", ".", "info", "(", "\"Loading pretrained tokenizer...\"", ")", "\n", "if", "model_args", ".", "pretrained_model_file", ":", "\n", "# load pretrained tokenizer from directory", "\n", "        ", "tokenizer", "=", "T5Tokenizer", ".", "from_pretrained", "(", "model_args", ".", "pretrained_model_file", ")", "\n", "", "else", ":", "\n", "# load pretrained tokenizer from Huggingface", "\n", "        ", "tokenizer", "=", "T5Tokenizer", ".", "from_pretrained", "(", "\"t5-base\"", ")", "\n", "\n", "# found better/more controllable generation using own EOS token", "\n", "", "tokenizer", ".", "add_special_tokens", "(", "{", "\"eos_token\"", ":", "\"[EOS]\"", "}", ")", "\n", "assert", "(", "\n", "len", "(", "tokenizer", ")", "-", "1", "\n", "==", "tokenizer", ".", "eos_token_id", "\n", "==", "tokenizer", ".", "encode", "(", "[", "\"[EOS]\"", "]", ")", "[", "0", "]", "\n", "==", "32100", "\n", ")", "\n", "\n", "if", "data_args", ".", "generations_filepath", "is", "None", ":", "\n", "        ", "if", "model_args", ".", "pretrained_model_file", ":", "\n", "# load pretrained model from directory at best checkpoint", "\n", "            ", "ckpts", "=", "[", "\n", "name", "\n", "for", "name", "in", "os", ".", "listdir", "(", "model_args", ".", "pretrained_model_file", ")", "\n", "if", "PREFIX_CHECKPOINT_DIR", "in", "name", "\n", "]", "\n", "if", "len", "(", "ckpts", ")", "!=", "1", ":", "\n", "                ", "raise", "Exception", "(", "\n", "\"more than 1 checkpoint file stored in pretrained path. revisit save directory\"", "\n", ")", "\n", "", "model_load_path", "=", "os", ".", "path", ".", "join", "(", "model_args", ".", "pretrained_model_file", ",", "ckpts", "[", "0", "]", ")", "\n", "model", "=", "T5ForConditionalGeneration", ".", "from_pretrained", "(", "model_load_path", ")", "\n", "if", "model_args", ".", "dropout_rate", ":", "\n", "                ", "raise", "Exception", "(", "\n", "\"can't update/specify dropout currently when load pretrained model from directory\"", "\n", ")", "\n", "\n", "", "", "else", ":", "\n", "# load pretrained model from HuggingFace", "\n", "            ", "logger", ".", "info", "(", "\"Loading pretrained model\"", ")", "\n", "if", "model_args", ".", "dropout_rate", ":", "\n", "                ", "model", "=", "T5ForConditionalGeneration", ".", "from_pretrained", "(", "\n", "\"t5-base\"", ",", "dropout_rate", "=", "model_args", ".", "dropout_rate", "\n", ")", "\n", "", "else", ":", "\n", "                ", "model", "=", "T5ForConditionalGeneration", ".", "from_pretrained", "(", "\"t5-base\"", ")", "\n", "\n", "", "", "model", ".", "resize_token_embeddings", "(", "len", "(", "tokenizer", ")", ")", "\n", "", "else", ":", "\n", "        ", "model", "=", "None", "\n", "\n", "# load (new) cos-e version", "\n", "", "if", "data_args", ".", "task_name", "==", "\"cos_e\"", ":", "\n", "        ", "assert", "data_args", ".", "version_name", "in", "{", "\"v1.11\"", ",", "\"v1.0\"", "}", "\n", "version_arg", "=", "data_args", ".", "version_name", "\n", "", "else", ":", "\n", "        ", "version_arg", "=", "None", "\n", "\n", "# Get datasets", "\n", "", "dataset", "=", "nlp", ".", "load_dataset", "(", "data_args", ".", "task_name", ",", "version_arg", ")", "\n", "\n", "# Apply method, and format dataset to torch.Tensor outputs", "\n", "for", "split", "in", "dataset", ".", "keys", "(", ")", ":", "\n", "\n", "# apply independently to each example", "\n", "        ", "dataset", "[", "split", "]", "=", "dataset", "[", "split", "]", ".", "map", "(", "\n", "lambda", "x", ":", "input_to_explanation_plus_label", "(", "\n", "x", ",", "\n", "tokenizer", ",", "\n", "datasource", "=", "data_args", ".", "task_name", ",", "\n", "expl_only", "=", "model_args", ".", "rationale_only", ",", "\n", "label_only", "=", "model_args", ".", "label_only", ",", "\n", ")", ",", "\n", "# had some replicability issues with batch/cache set to True", "\n", "batched", "=", "False", ",", "\n", "load_from_cache_file", "=", "False", ",", "\n", ")", "\n", "\n", "", "train_dataset", "=", "dataset", "[", "\"train\"", "]", "\n", "eval_dataset", "=", "dataset", "[", "\"validation\"", "]", "\n", "test_dataset", "=", "dataset", "[", "\"test\"", "]", "if", "data_args", ".", "task_name", "==", "\"esnli\"", "else", "None", "\n", "\n", "if", "data_args", ".", "task_name", "==", "\"esnli\"", ":", "\n", "        ", "assert", "len", "(", "train_dataset", ")", "==", "549367", "\n", "assert", "len", "(", "eval_dataset", ")", "==", "9842", "\n", "assert", "len", "(", "test_dataset", ")", "==", "9824", "\n", "", "elif", "data_args", ".", "task_name", "==", "\"cos_e\"", ":", "\n", "        ", "if", "data_args", ".", "version_name", "==", "\"v1.11\"", ":", "\n", "            ", "assert", "len", "(", "train_dataset", ")", "==", "9741", "\n", "assert", "len", "(", "eval_dataset", ")", "==", "1221", "\n", "", "elif", "data_args", ".", "version_name", "==", "\"v1.0\"", ":", "\n", "            ", "assert", "len", "(", "train_dataset", ")", "==", "7610", "\n", "assert", "len", "(", "eval_dataset", ")", "==", "950", "\n", "", "assert", "test_dataset", "is", "None", "\n", "\n", "", "logger", ".", "info", "(", "\"****LOG****\"", ")", "\n", "logger", ".", "info", "(", "len", "(", "train_dataset", ")", ")", "\n", "logger", ".", "info", "(", "len", "(", "eval_dataset", ")", ")", "\n", "if", "data_args", ".", "task_name", "==", "\"esnli\"", ":", "\n", "        ", "logger", ".", "info", "(", "len", "(", "test_dataset", ")", ")", "\n", "\n", "", "if", "data_args", ".", "generations_filepath", "is", "None", ":", "\n", "# Initialize Trainer", "\n", "        ", "trainer", "=", "Trainer", "(", "\n", "model", "=", "model", ",", "\n", "args", "=", "training_args", ",", "\n", "data_args", "=", "data_args", ",", "\n", "train_dataset", "=", "train_dataset", ",", "\n", "eval_dataset", "=", "eval_dataset", ",", "\n", "prediction_loss_only", "=", "True", ",", "\n", "data_collator", "=", "SequenceCollator", "(", "pad_token", "=", "tokenizer", ".", "pad_token_id", ")", ",", "\n", ")", "\n", "\n", "# Training", "\n", "", "if", "training_args", ".", "do_train", ":", "\n", "        ", "start_time", "=", "time", ".", "time", "(", ")", "\n", "trainer", ".", "train", "(", ")", "\n", "trainer", ".", "save_model", "(", ")", "\n", "# For convenience, we also re-save the tokenizer to the same directory", "\n", "tokenizer", ".", "save_pretrained", "(", "training_args", ".", "output_dir", ")", "\n", "train_time", "=", "time", ".", "time", "(", ")", "-", "start_time", "\n", "model", "=", "trainer", ".", "model", "\n", "\n", "# Evaluation", "\n", "", "results", "=", "{", "}", "\n", "if", "model", "is", "not", "None", ":", "\n", "        ", "model", ".", "eval", "(", ")", "\n", "\n", "", "if", "training_args", ".", "do_eval", ":", "\n", "        ", "start_time", "=", "time", ".", "time", "(", ")", "\n", "\n", "logger", ".", "info", "(", "\"*** Evaluate on train set***\"", ")", "\n", "train_output", "=", "trainer", ".", "evaluate", "(", "train_dataset", ")", "\n", "perplexity", "=", "math", ".", "exp", "(", "train_output", "[", "\"eval_loss\"", "]", ")", "\n", "results", "[", "\"perplexity_train\"", "]", "=", "perplexity", "\n", "\n", "logger", ".", "info", "(", "\"*** Evaluate on dev set***\"", ")", "\n", "eval_output", "=", "trainer", ".", "evaluate", "(", "eval_dataset", ")", "\n", "perplexity", "=", "math", ".", "exp", "(", "eval_output", "[", "\"eval_loss\"", "]", ")", "\n", "results", "[", "\"perplexity_validation\"", "]", "=", "perplexity", "\n", "\n", "if", "data_args", ".", "task_name", "==", "\"esnli\"", ":", "\n", "# also evaluate on test", "\n", "            ", "logger", ".", "info", "(", "\"*** Evaluate on test set***\"", ")", "\n", "test_output", "=", "trainer", ".", "evaluate", "(", "test_dataset", ")", "\n", "logger", ".", "info", "(", "\"test loss @ best dev epoch: %0.4f\"", "%", "test_output", "[", "\"eval_loss\"", "]", ")", "\n", "perplexity", "=", "math", ".", "exp", "(", "test_output", "[", "\"eval_loss\"", "]", ")", "\n", "results", "[", "\"perplexity_test\"", "]", "=", "perplexity", "\n", "\n", "", "eval_time", "=", "time", ".", "time", "(", ")", "-", "start_time", "\n", "\n", "", "if", "data_args", ".", "generations_filepath", "is", "None", ":", "\n", "# only save to checkpoint folder if one exists (i.e. trained a model or loaded a model you previously trained)", "\n", "        ", "if", "training_args", ".", "do_train", "or", "model_args", ".", "pretrained_model_file", ":", "\n", "            ", "ckpts", "=", "[", "\n", "name", "\n", "for", "name", "in", "os", ".", "listdir", "(", "training_args", ".", "output_dir", ")", "\n", "if", "PREFIX_CHECKPOINT_DIR", "in", "name", "\n", "]", "\n", "if", "len", "(", "ckpts", ")", "!=", "1", ":", "\n", "                ", "raise", "Exception", "(", "\n", "\"more than 1 checkpoint file stored in pretrained path. revisit save directory\"", "\n", ")", "\n", "", "save_path", "=", "os", ".", "path", ".", "join", "(", "training_args", ".", "output_dir", ",", "ckpts", "[", "0", "]", ")", "\n", "# else save to main directory (i.e. evaluating existing HF pretrained model)", "\n", "", "else", ":", "\n", "            ", "save_path", "=", "training_args", ".", "output_dir", "\n", "", "", "else", ":", "\n", "        ", "save_path", "=", "os", ".", "path", ".", "dirname", "(", "data_args", ".", "generations_filepath", ")", "\n", "\n", "# store predictions", "\n", "", "start_time", "=", "time", ".", "time", "(", ")", "\n", "if", "data_args", ".", "train_predict", ":", "\n", "        ", "logger", ".", "info", "(", "\"*** Predict on train set***\"", ")", "\n", "if", "data_args", ".", "generations_filepath", "is", "not", "None", ":", "\n", "            ", "assert", "\"train\"", "in", "data_args", ".", "generations_filepath", "\n", "", "acc", "=", "compute_metrics", "(", "\n", "save_path", ",", "\n", "train_dataset", ",", "\n", "model", ",", "\n", "tokenizer", ",", "\n", "\"train\"", ",", "\n", "data_args", ".", "task_name", ",", "\n", "training_args", ".", "device", ",", "\n", "rationale_only", "=", "model_args", ".", "rationale_only", ",", "\n", "label_only", "=", "model_args", ".", "label_only", ",", "\n", "generations_file", "=", "data_args", ".", "generations_filepath", ",", "\n", ")", "\n", "results", "[", "\"train_acc\"", "]", "=", "acc", "\n", "if", "acc", "!=", "\"n/a\"", ":", "\n", "            ", "logger", ".", "info", "(", "\"Train Accuracy: %f\"", "%", "acc", ")", "\n", "\n", "", "", "if", "data_args", ".", "test_predict", "and", "data_args", ".", "task_name", "==", "\"esnli\"", ":", "\n", "        ", "logger", ".", "info", "(", "\"*** Predict on test set***\"", ")", "\n", "if", "data_args", ".", "generations_filepath", "is", "not", "None", ":", "\n", "            ", "assert", "\"test\"", "in", "data_args", ".", "generations_filepath", "\n", "", "acc", "=", "compute_metrics", "(", "\n", "save_path", ",", "\n", "test_dataset", ",", "\n", "model", ",", "\n", "tokenizer", ",", "\n", "\"test\"", ",", "\n", "data_args", ".", "task_name", ",", "\n", "training_args", ".", "device", ",", "\n", "rationale_only", "=", "model_args", ".", "rationale_only", ",", "\n", "label_only", "=", "model_args", ".", "label_only", ",", "\n", "generations_file", "=", "data_args", ".", "generations_filepath", ",", "\n", ")", "\n", "results", "[", "\"test_acc\"", "]", "=", "acc", "\n", "if", "acc", "!=", "\"n/a\"", ":", "\n", "            ", "logger", ".", "info", "(", "\"Test Accuracy: %f\"", "%", "acc", ")", "\n", "\n", "", "", "if", "data_args", ".", "dev_predict", ":", "\n", "        ", "logger", ".", "info", "(", "\"*** Predict on dev set***\"", ")", "\n", "if", "data_args", ".", "generations_filepath", "is", "not", "None", ":", "\n", "            ", "assert", "\"validation\"", "in", "data_args", ".", "generations_filepath", "\n", "", "acc", "=", "compute_metrics", "(", "\n", "save_path", ",", "\n", "eval_dataset", ",", "\n", "model", ",", "\n", "tokenizer", ",", "\n", "\"validation\"", ",", "\n", "data_args", ".", "task_name", ",", "\n", "training_args", ".", "device", ",", "\n", "rationale_only", "=", "model_args", ".", "rationale_only", ",", "\n", "label_only", "=", "model_args", ".", "label_only", ",", "\n", "generations_file", "=", "data_args", ".", "generations_filepath", ",", "\n", ")", "\n", "results", "[", "\"dev_acc\"", "]", "=", "acc", "\n", "if", "acc", "!=", "\"n/a\"", ":", "\n", "            ", "logger", ".", "info", "(", "\"Dev Accuracy: %f\"", "%", "acc", ")", "\n", "\n", "", "", "if", "data_args", ".", "generations_filepath", "is", "None", ":", "\n", "        ", "output_eval_file", "=", "os", ".", "path", ".", "join", "(", "training_args", ".", "output_dir", ",", "\"eval_results_lm.txt\"", ")", "\n", "", "else", ":", "\n", "        ", "output_eval_file", "=", "os", ".", "path", ".", "join", "(", "\n", "os", ".", "path", ".", "dirname", "(", "os", ".", "path", ".", "dirname", "(", "data_args", ".", "generations_filepath", ")", ")", ",", "\n", "\"eval_results_lm.txt\"", ",", "\n", ")", "\n", "", "with", "open", "(", "output_eval_file", ",", "\"a+\"", ")", "as", "writer", ":", "\n", "        ", "for", "key", "in", "sorted", "(", "results", ".", "keys", "(", ")", ")", ":", "\n", "            ", "if", "results", "[", "key", "]", "is", "not", "None", ":", "\n", "                ", "logger", ".", "info", "(", "\"  %s = %s\"", ",", "key", ",", "str", "(", "results", "[", "key", "]", ")", ")", "\n", "writer", ".", "write", "(", "\"%s = %s\\n\"", "%", "(", "key", ",", "str", "(", "results", "[", "key", "]", ")", ")", ")", "\n", "\n", "", "", "", "predict_time", "=", "time", ".", "time", "(", ")", "-", "start_time", "\n", "\n", "# final logs", "\n", "logger", ".", "info", "(", "\"Git branch: %s\"", "%", "git_branch", ")", "\n", "logger", ".", "info", "(", "\"Git hash: %s\"", "%", "git_hash", ")", "\n", "logger", ".", "info", "(", "\"Save path: %s\"", "%", "training_args", ".", "output_dir", ")", "\n", "if", "training_args", ".", "do_train", ":", "\n", "        ", "logger", ".", "info", "(", "\"total train time: %.4f hours\"", "%", "(", "train_time", "/", "60.0", "/", "60.0", ")", ")", "\n", "", "if", "training_args", ".", "do_eval", ":", "\n", "        ", "logger", ".", "info", "(", "\"total eval time: %.4f hours\"", "%", "(", "eval_time", "/", "60.0", "/", "60.0", ")", ")", "\n", "", "if", "(", "\n", "data_args", ".", "train_predict", "\n", "or", "data_args", ".", "dev_predict", "\n", "or", "(", "data_args", ".", "test_predict", "and", "data_args", ".", "task_name", "==", "\"esnli\"", ")", "\n", ")", ":", "\n", "        ", "logger", ".", "info", "(", "\"total predict time: %.4f hours\"", "%", "(", "predict_time", "/", "60.0", "/", "60.0", ")", ")", "\n", "", "logger", ".", "info", "(", "\n", "\"TOTAL SCRIPT TIME: %.4f hours\"", "%", "(", "(", "time", ".", "time", "(", ")", "-", "og_start_time", ")", "/", "60.0", "/", "60.0", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.allenai_label_rationale_association.None.feature_conversion_methods.cose_explanation_to_label": [[11, 66], ["tokenizer.encode_plus", "tokenizer.encode_plus"], "function", ["None"], ["def", "cose_explanation_to_label", "(", "\n", "example", ",", "\n", "index", ",", "\n", "tokenizer", ",", "\n", "pred_only", "=", "False", ",", "\n", "predictions_file", "=", "None", ",", "\n", "include_input", "=", "False", ",", "\n", ")", ":", "\n", "\n", "# Format:", "\n", "# if include_input:", "\n", "# Input: \"cos_e question: [question] choice: [choice_0] choice: [choice_1] choice: [choice_2] explanation: [abstractive_explanation]\"", "\n", "# if not include_input:", "\n", "# Input: \"cos_e choice: [choice_0] choice: [choice_1] choice: [choice_2] explanation: [abstractive_explanation]\"", "\n", "# Output: \"[answer]\"", "\n", "\n", "    ", "if", "pred_only", ":", "\n", "        ", "abstr_expl", "=", "predictions_file", "[", "index", "]", "\n", "", "else", ":", "\n", "        ", "abstr_expl", "=", "example", "[", "\"abstractive_explanation\"", "]", "\n", "\n", "", "if", "include_input", ":", "\n", "        ", "question", "=", "example", "[", "\"question\"", "]", "\n", "input_string", "=", "(", "\n", "f\"cos_e question: {question} choice: \"", "\n", "+", "\" choice: \"", ".", "join", "(", "example", "[", "\"choices\"", "]", ")", "\n", "+", "f\" explanation: {abstr_expl}\"", "\n", ")", "\n", "", "else", ":", "\n", "        ", "input_string", "=", "(", "\n", "f\"cos_e choice: \"", "\n", "+", "\" choice: \"", ".", "join", "(", "example", "[", "\"choices\"", "]", ")", "\n", "+", "f\" explanation: {abstr_expl}\"", "\n", ")", "\n", "\n", "", "answer_string", "=", "example", "[", "\"answer\"", "]", "\n", "\n", "# tokenizer takes care of model-specific special tokens", "\n", "encodings", "=", "tokenizer", ".", "encode_plus", "(", "\n", "input_string", "+", "tokenizer", ".", "eos_token", ",", "\n", "return_attention_mask", "=", "True", ",", "\n", ")", "\n", "\n", "# note even with \"labels.shift_right()\", the decoder attention mask length is still correct since we remove the last token", "\n", "dec", "=", "tokenizer", ".", "encode_plus", "(", "\n", "answer_string", "+", "tokenizer", ".", "eos_token", ",", "\n", "return_attention_mask", "=", "True", ",", "\n", ")", "\n", "\n", "encodings", "[", "\"lm_labels\"", "]", "=", "dec", "[", "\"input_ids\"", "]", "\n", "encodings", "[", "\"decoder_attention_mask\"", "]", "=", "dec", "[", "\"attention_mask\"", "]", "\n", "\n", "encodings", "[", "\"question_encoding\"", "]", "=", "encodings", "[", "\"input_ids\"", "]", "\n", "\n", "return", "encodings", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_label_rationale_association.None.feature_conversion_methods.esnli_explanation_to_label": [[68, 124], ["tokenizer.encode_plus", "tokenizer.encode_plus"], "function", ["None"], ["", "def", "esnli_explanation_to_label", "(", "\n", "example", ",", "\n", "index", ",", "\n", "tokenizer", ",", "\n", "pred_only", "=", "False", ",", "\n", "predictions_file", "=", "None", ",", "\n", "include_input", "=", "False", ",", "\n", ")", ":", "\n", "\n", "# Format:", "\n", "# if include_input:", "\n", "# Input: \"nli hypothesis: [hypothesis] premise: [premise] explanation: [abstractive_explanation]\"", "\n", "# if not include_input:", "\n", "# Input: \"nli explanation: [abstractive_explanation]\"", "\n", "# Output: \"[answer]\"", "\n", "\n", "    ", "hypothesis", "=", "example", "[", "\"hypothesis\"", "]", "\n", "premise", "=", "example", "[", "\"premise\"", "]", "\n", "\n", "if", "pred_only", ":", "\n", "        ", "abstr_expl", "=", "predictions_file", "[", "index", "]", "\n", "", "else", ":", "\n", "        ", "abstr_expl", "=", "example", "[", "\"explanation_1\"", "]", "\n", "\n", "", "if", "include_input", ":", "\n", "        ", "input_string", "=", "(", "\n", "f\"nli hypothesis: {hypothesis} premise: {premise} explanation: {abstr_expl}\"", "\n", ")", "\n", "", "else", ":", "\n", "        ", "input_string", "=", "f\"nli explanation: {abstr_expl}\"", "\n", "\n", "", "if", "example", "[", "\"label\"", "]", "==", "0", ":", "\n", "        ", "answer_string", "=", "\"entailment\"", "\n", "", "elif", "example", "[", "\"label\"", "]", "==", "1", ":", "\n", "        ", "answer_string", "=", "\"neutral\"", "\n", "", "elif", "example", "[", "\"label\"", "]", "==", "2", ":", "\n", "        ", "answer_string", "=", "\"contradiction\"", "\n", "\n", "# tokenizer takes care of model-specific special tokens", "\n", "", "encodings", "=", "tokenizer", ".", "encode_plus", "(", "\n", "input_string", "+", "tokenizer", ".", "eos_token", ",", "\n", "return_attention_mask", "=", "True", ",", "\n", ")", "\n", "\n", "# note even with \"labels.shift_right()\", the decoder attention mask length is still correct since we remove the last token", "\n", "dec", "=", "tokenizer", ".", "encode_plus", "(", "\n", "answer_string", "+", "tokenizer", ".", "eos_token", ",", "\n", "return_attention_mask", "=", "True", ",", "\n", ")", "\n", "\n", "encodings", "[", "\"lm_labels\"", "]", "=", "dec", "[", "\"input_ids\"", "]", "\n", "encodings", "[", "\"decoder_attention_mask\"", "]", "=", "dec", "[", "\"attention_mask\"", "]", "\n", "\n", "encodings", "[", "\"question_encoding\"", "]", "=", "encodings", "[", "\"input_ids\"", "]", "\n", "\n", "return", "encodings", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_label_rationale_association.None.feature_conversion_methods.input_to_explanation_plus_label": [[126, 173], ["tokenizer.encode_plus", "tokenizer.encode_plus", "feature_conversion_methods.cose_wt5_format", "feature_conversion_methods.esnli_wt5_format"], "function", ["home.repos.pwc.inspect_result.allenai_label_rationale_association.None.feature_conversion_methods.cose_wt5_format", "home.repos.pwc.inspect_result.allenai_label_rationale_association.None.feature_conversion_methods.esnli_wt5_format"], ["", "def", "input_to_explanation_plus_label", "(", "\n", "example", ",", "\n", "tokenizer", ",", "\n", "datasource", "=", "None", ",", "\n", "expl_only", "=", "False", ",", "\n", "label_only", "=", "False", ",", "\n", ")", ":", "\n", "\n", "# CoS-E Format:", "\n", "# Input: \"explain cos_e question: [question] choice: [choice_0] choice: [choice_1] choice: [choice_2]\"", "\n", "\n", "# e-SNLI Format:", "\n", "# Input: \"explain nli hypothesis: [hypothesis] premise: [premise]\"", "\n", "\n", "# Output: \"[answer] explanation: [abstractive_explanation]\"", "\n", "# Explanation-only output: \"None explanation: [abstractive_explanation]\"", "\n", "# Label-only output: \"[answer]\"", "\n", "\n", "    ", "assert", "datasource", "in", "{", "\"cos_e\"", ",", "\"esnli\"", "}", "\n", "\n", "if", "datasource", "==", "\"cos_e\"", ":", "\n", "        ", "input_string", ",", "answer_string", "=", "cose_wt5_format", "(", "\n", "example", ",", "expl_only", "=", "expl_only", ",", "label_only", "=", "label_only", "\n", ")", "\n", "", "elif", "datasource", "==", "\"esnli\"", ":", "\n", "        ", "input_string", ",", "answer_string", "=", "esnli_wt5_format", "(", "\n", "example", ",", "expl_only", "=", "expl_only", ",", "label_only", "=", "label_only", "\n", ")", "\n", "\n", "# tokenizer takes care of model-specific special tokens", "\n", "", "encodings", "=", "tokenizer", ".", "encode_plus", "(", "\n", "input_string", "+", "tokenizer", ".", "eos_token", ",", "\n", "return_attention_mask", "=", "True", ",", "\n", ")", "\n", "\n", "# note even with \"labels.shift_right()\", the decoder attention mask length is still correct since we remove the last token", "\n", "dec", "=", "tokenizer", ".", "encode_plus", "(", "\n", "answer_string", "+", "tokenizer", ".", "eos_token", ",", "\n", "return_attention_mask", "=", "True", ",", "\n", ")", "\n", "\n", "encodings", "[", "\"lm_labels\"", "]", "=", "dec", "[", "\"input_ids\"", "]", "\n", "encodings", "[", "\"decoder_attention_mask\"", "]", "=", "dec", "[", "\"attention_mask\"", "]", "\n", "\n", "encodings", "[", "\"question_encoding\"", "]", "=", "encodings", "[", "\"input_ids\"", "]", "\n", "\n", "return", "encodings", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_label_rationale_association.None.feature_conversion_methods.cose_wt5_format": [[175, 192], ["None"], "function", ["None"], ["", "def", "cose_wt5_format", "(", "item", ",", "expl_only", "=", "False", ",", "label_only", "=", "False", ")", ":", "\n", "    ", "question", "=", "item", "[", "\"question\"", "]", "\n", "answer", "=", "item", "[", "\"answer\"", "]", "\n", "abstr_expl", "=", "item", "[", "\"abstractive_explanation\"", "]", "\n", "\n", "input_string", "=", "f\"explain cos_e question: {question} choice: \"", "+", "\" choice: \"", ".", "join", "(", "\n", "item", "[", "\"choices\"", "]", "\n", ")", "\n", "\n", "if", "expl_only", ":", "\n", "        ", "answer_string", "=", "f\"None explanation: {abstr_expl}\"", "\n", "", "elif", "label_only", ":", "\n", "        ", "answer_string", "=", "f\"{answer}\"", "\n", "", "else", ":", "\n", "        ", "answer_string", "=", "f\"{answer} explanation: {abstr_expl}\"", "\n", "\n", "", "return", "input_string", ",", "answer_string", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_label_rationale_association.None.feature_conversion_methods.esnli_wt5_format": [[194, 214], ["None"], "function", ["None"], ["", "def", "esnli_wt5_format", "(", "item", ",", "expl_only", "=", "False", ",", "label_only", "=", "False", ")", ":", "\n", "    ", "premise", "=", "item", "[", "\"premise\"", "]", "\n", "hypothesis", "=", "item", "[", "\"hypothesis\"", "]", "\n", "if", "item", "[", "\"label\"", "]", "==", "0", ":", "\n", "        ", "answer", "=", "\"entailment\"", "\n", "", "elif", "item", "[", "\"label\"", "]", "==", "1", ":", "\n", "        ", "answer", "=", "\"neutral\"", "\n", "", "elif", "item", "[", "\"label\"", "]", "==", "2", ":", "\n", "        ", "answer", "=", "\"contradiction\"", "\n", "", "abstr_expl", "=", "item", "[", "\"explanation_1\"", "]", "\n", "\n", "input_string", "=", "f\"explain nli hypothesis: {hypothesis} premise: {premise}\"", "\n", "if", "expl_only", ":", "\n", "        ", "answer_string", "=", "f\"None explanation: {abstr_expl}\"", "\n", "", "elif", "label_only", ":", "\n", "        ", "answer_string", "=", "f\"{answer}\"", "\n", "", "else", ":", "\n", "        ", "answer_string", "=", "f\"{answer} explanation: {abstr_expl}\"", "\n", "\n", "", "return", "input_string", ",", "answer_string", "\n", "", ""]]}