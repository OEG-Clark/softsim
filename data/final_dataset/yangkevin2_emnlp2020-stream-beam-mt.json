{"home.repos.pwc.inspect_result.yangkevin2_emnlp2020-stream-beam-mt.None.variable_stream.IncrementalState.__init__": [[41, 50], ["torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "set", "set", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "range", "range"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "initial_num_sources", ",", "k", ",", "ensemble_size", ",", "device", ")", ":", "# it'll expand itself when it's initially none", "\n", "        ", "self", ".", "state", "=", "None", "\n", "self", ".", "master_indices", "=", "torch", ".", "LongTensor", "(", "0", ")", ".", "to", "(", "device", ")", "\n", "self", ".", "k", "=", "k", "\n", "self", ".", "ensemble_size", "=", "ensemble_size", "\n", "self", ".", "num_sources", "=", "initial_num_sources", "\n", "self", ".", "decoder_keys", "=", "[", "set", "(", ")", "for", "_", "in", "range", "(", "ensemble_size", ")", "]", "\n", "self", ".", "encoder_keys", "=", "[", "set", "(", ")", "for", "_", "in", "range", "(", "ensemble_size", ")", "]", "\n", "self", ".", "device", "=", "device", "\n", "\n"]], "home.repos.pwc.inspect_result.yangkevin2_emnlp2020-stream-beam-mt.None.variable_stream.IncrementalState.append_new_incremental_state": [[51, 84], ["torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "range", "range", "len", "variable_stream.IncrementalState.state[].keys", "len", "range", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to().bool", "torch.zeros().to().bool", "torch.zeros().to().bool", "torch.zeros().to().bool", "torch.zeros().to().bool", "torch.zeros().to().bool", "torch.zeros().to().bool", "torch.zeros().to().bool", "torch.zeros().to().bool", "len", "len", "util.pad_to_length", "max", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "variable_stream.IncrementalState.decoder_keys[].add", "variable_stream.IncrementalState.encoder_keys[].add", "len", "dummy_state[].keys", "len", "dummy_state[].keys", "torch.zeros().to().bool", "torch.zeros().to().bool", "torch.zeros().to().bool", "torch.zeros().to().bool", "torch.zeros().to().bool", "torch.zeros().to().bool", "torch.zeros().to().bool", "torch.zeros().to().bool", "torch.zeros().to().bool", "util.pad_to_length", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "util.pad_to_length().bool", "util.pad_to_length().bool", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "util.pad_to_length", "util.pad_to_length", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "util.pad_to_length", "util.pad_to_length", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros"], "methods", ["home.repos.pwc.inspect_result.yangkevin2_emnlp2020-stream-beam-mt.None.util.pad_to_length", "home.repos.pwc.inspect_result.yangkevin2_emnlp2020-stream-beam-mt.None.util.pad_to_length", "home.repos.pwc.inspect_result.yangkevin2_emnlp2020-stream-beam-mt.None.util.pad_to_length", "home.repos.pwc.inspect_result.yangkevin2_emnlp2020-stream-beam-mt.None.util.pad_to_length", "home.repos.pwc.inspect_result.yangkevin2_emnlp2020-stream-beam-mt.None.util.pad_to_length", "home.repos.pwc.inspect_result.yangkevin2_emnlp2020-stream-beam-mt.None.util.pad_to_length"], ["", "def", "append_new_incremental_state", "(", "self", ",", "num_new_sources", ",", "dummy_state", ",", "new_master_indices", ")", ":", "\n", "        ", "if", "self", ".", "state", "is", "None", ":", "\n", "            ", "self", ".", "state", "=", "[", "{", "}", "for", "_", "in", "range", "(", "self", ".", "ensemble_size", ")", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "dummy_state", ")", ")", ":", "# initialize decoder keys", "\n", "                ", "for", "key", "in", "dummy_state", "[", "i", "]", ":", "\n", "                    ", "self", ".", "state", "[", "i", "]", "[", "key", "]", "=", "{", "}", "\n", "self", ".", "state", "[", "i", "]", "[", "key", "]", "[", "'prev_key'", "]", "=", "torch", ".", "zeros", "(", "0", ",", "dummy_state", "[", "i", "]", "[", "key", "]", "[", "'prev_key'", "]", ".", "shape", "[", "1", "]", ",", "0", ",", "dummy_state", "[", "i", "]", "[", "key", "]", "[", "'prev_key'", "]", ".", "shape", "[", "3", "]", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "self", ".", "state", "[", "i", "]", "[", "key", "]", "[", "'prev_value'", "]", "=", "torch", ".", "zeros", "(", "0", ",", "dummy_state", "[", "i", "]", "[", "key", "]", "[", "'prev_value'", "]", ".", "shape", "[", "1", "]", ",", "0", ",", "dummy_state", "[", "i", "]", "[", "key", "]", "[", "'prev_value'", "]", ".", "shape", "[", "3", "]", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "self", ".", "state", "[", "i", "]", "[", "key", "]", "[", "'prev_key_padding_mask'", "]", "=", "torch", ".", "zeros", "(", "0", ",", "0", ")", ".", "to", "(", "self", ".", "device", ")", ".", "bool", "(", ")", "\n", "if", "dummy_state", "[", "i", "]", "[", "key", "]", "[", "'prev_key'", "]", ".", "shape", "[", "2", "]", "==", "1", ":", "\n", "                        ", "self", ".", "decoder_keys", "[", "i", "]", ".", "add", "(", "key", ")", "# others are encoder-side keys and we don't need to do any tricks for those", "\n", "", "else", ":", "\n", "                        ", "self", ".", "encoder_keys", "[", "i", "]", ".", "add", "(", "key", ")", "\n", "", "", "assert", "len", "(", "self", ".", "decoder_keys", "[", "i", "]", ")", "*", "2", "==", "len", "(", "dummy_state", "[", "i", "]", ".", "keys", "(", ")", ")", "\n", "assert", "len", "(", "self", ".", "encoder_keys", "[", "i", "]", ")", "*", "2", "==", "len", "(", "dummy_state", "[", "i", "]", ".", "keys", "(", ")", ")", "\n", "\n", "", "", "self", ".", "master_indices", "=", "torch", ".", "cat", "(", "[", "self", ".", "master_indices", ",", "new_master_indices", "]", ",", "dim", "=", "0", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "self", ".", "state", ")", ")", ":", "\n", "            ", "for", "key", "in", "self", ".", "state", "[", "i", "]", ".", "keys", "(", ")", ":", "\n", "                ", "if", "key", "in", "self", ".", "decoder_keys", "[", "i", "]", ":", "\n", "                    ", "if", "self", ".", "state", "[", "i", "]", "[", "key", "]", "[", "'prev_key_padding_mask'", "]", "is", "None", ":", "\n", "                        ", "self", ".", "state", "[", "i", "]", "[", "key", "]", "[", "'prev_key_padding_mask'", "]", "=", "torch", ".", "zeros", "(", "self", ".", "state", "[", "i", "]", "[", "key", "]", "[", "'prev_key'", "]", ".", "shape", "[", "0", "]", ",", "self", ".", "state", "[", "i", "]", "[", "key", "]", "[", "'prev_key'", "]", ".", "shape", "[", "2", "]", ")", ".", "to", "(", "self", ".", "state", "[", "i", "]", "[", "key", "]", "[", "'prev_key'", "]", ".", "device", ")", ".", "bool", "(", ")", "\n", "", "self", ".", "state", "[", "i", "]", "[", "key", "]", "[", "'prev_key_padding_mask'", "]", "=", "pad_to_length", "(", "self", ".", "state", "[", "i", "]", "[", "key", "]", "[", "'prev_key_padding_mask'", "]", ",", "self", ".", "state", "[", "i", "]", "[", "key", "]", "[", "'prev_key_padding_mask'", "]", ".", "shape", "[", "0", "]", "+", "num_new_sources", ",", "0", ",", "value", "=", "True", ")", "\n", "for", "key2", "in", "[", "'prev_key'", ",", "'prev_value'", "]", ":", "\n", "                        ", "self", ".", "state", "[", "i", "]", "[", "key", "]", "[", "key2", "]", "=", "pad_to_length", "(", "self", ".", "state", "[", "i", "]", "[", "key", "]", "[", "key2", "]", ",", "self", ".", "state", "[", "i", "]", "[", "key", "]", "[", "key2", "]", ".", "shape", "[", "0", "]", "+", "num_new_sources", ",", "0", ",", "value", "=", "0", ")", "\n", "", "", "else", ":", "# encoder attn keys", "\n", "                    ", "max_seq", "=", "max", "(", "self", ".", "state", "[", "i", "]", "[", "key", "]", "[", "'prev_key_padding_mask'", "]", ".", "shape", "[", "1", "]", ",", "dummy_state", "[", "i", "]", "[", "key", "]", "[", "'prev_key_padding_mask'", "]", ".", "shape", "[", "1", "]", ")", "\n", "self", ".", "state", "[", "i", "]", "[", "key", "]", "[", "'prev_key_padding_mask'", "]", "=", "torch", ".", "cat", "(", "[", "pad_to_length", "(", "self", ".", "state", "[", "i", "]", "[", "key", "]", "[", "'prev_key_padding_mask'", "]", ",", "max_seq", ",", "1", ",", "side", "=", "'left'", ",", "value", "=", "True", ")", ".", "bool", "(", ")", ",", "\n", "pad_to_length", "(", "dummy_state", "[", "i", "]", "[", "key", "]", "[", "'prev_key_padding_mask'", "]", ",", "max_seq", ",", "1", ",", "side", "=", "'left'", ",", "value", "=", "True", ")", ".", "bool", "(", ")", "]", ",", "dim", "=", "0", ")", "\n", "for", "key2", "in", "[", "'prev_key'", ",", "'prev_value'", "]", ":", "\n", "                        ", "self", ".", "state", "[", "i", "]", "[", "key", "]", "[", "key2", "]", "=", "torch", ".", "cat", "(", "[", "pad_to_length", "(", "self", ".", "state", "[", "i", "]", "[", "key", "]", "[", "key2", "]", ",", "max_seq", ",", "2", ",", "side", "=", "'left'", ",", "value", "=", "0", ")", ",", "\n", "pad_to_length", "(", "dummy_state", "[", "i", "]", "[", "key", "]", "[", "key2", "]", ",", "max_seq", ",", "2", ",", "side", "=", "'left'", ",", "value", "=", "0", ")", "]", ",", "dim", "=", "0", ")", "\n", "", "", "", "", "self", ".", "num_sources", "+=", "num_new_sources", "\n", "\n"]], "home.repos.pwc.inspect_result.yangkevin2_emnlp2020-stream-beam-mt.None.variable_stream.IncrementalState.select_incremental_state": [[85, 118], ["sum().clamp", "sum", "sum().clamp.nonzero().flatten", "unselected_mask.nonzero().flatten", "variable_stream.IncrementalState.master_indices.index_select", "range", "variable_stream.IncrementalState.master_indices.index_select", "len", "return_state.append", "variable_stream.IncrementalState.state[].keys", "len", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "sum", "sum().clamp.nonzero", "unselected_mask.nonzero", "[].keys", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "range", "[].index_select", "[].index_select"], "methods", ["None"], ["", "def", "select_incremental_state", "(", "self", ",", "selected_master_indices", ",", "master_remove_indices", ",", "prog_min", ",", "return_value", "=", "True", ")", ":", "# NOTE deletes the selected indices out of this cached state", "\n", "        ", "if", "len", "(", "selected_master_indices", ")", "==", "0", "or", "self", ".", "state", "is", "None", ":", "\n", "            ", "return", "torch", ".", "LongTensor", "(", "0", ")", ".", "to", "(", "self", ".", "device", ")", ",", "[", "{", "}", "for", "_", "in", "range", "(", "self", ".", "ensemble_size", ")", "]", "\n", "", "state_indices_mask", "=", "sum", "(", "[", "(", "self", ".", "master_indices", "==", "smi", ")", ".", "long", "(", ")", "for", "smi", "in", "selected_master_indices", "]", ")", ".", "clamp", "(", "max", "=", "1", ")", "\n", "remove_indices_mask", "=", "sum", "(", "[", "(", "self", ".", "master_indices", "==", "smi", ")", ".", "long", "(", ")", "for", "smi", "in", "master_remove_indices", "]", ")", "\n", "selected_state_indices", "=", "state_indices_mask", ".", "nonzero", "(", ")", ".", "flatten", "(", ")", "\n", "unselected_mask", "=", "(", "(", "1", "-", "state_indices_mask", ")", "-", "remove_indices_mask", ")", ".", "clamp", "(", "min", "=", "0", ")", "\n", "unselected_state_indices", "=", "unselected_mask", ".", "nonzero", "(", ")", ".", "flatten", "(", ")", "\n", "return_indices", "=", "self", ".", "master_indices", ".", "index_select", "(", "0", ",", "selected_state_indices", ")", "if", "return_value", "else", "None", "\n", "self", ".", "master_indices", "=", "self", ".", "master_indices", ".", "index_select", "(", "0", ",", "unselected_state_indices", ")", "\n", "return_state", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "self", ".", "state", ")", ")", ":", "\n", "            ", "return_state", ".", "append", "(", "{", "}", ")", "\n", "for", "key", "in", "self", ".", "state", "[", "i", "]", ".", "keys", "(", ")", ":", "\n", "                ", "return_state", "[", "i", "]", "[", "key", "]", "=", "{", "}", "\n", "for", "key2", "in", "self", ".", "state", "[", "i", "]", "[", "key", "]", ".", "keys", "(", ")", ":", "\n", "                    ", "return_state", "[", "i", "]", "[", "key", "]", "[", "key2", "]", "=", "None", "\n", "if", "self", ".", "state", "[", "i", "]", "[", "key", "]", "[", "key2", "]", "is", "not", "None", ":", "\n", "                        ", "if", "return_value", ":", "\n", "                            ", "return_state", "[", "i", "]", "[", "key", "]", "[", "key2", "]", "=", "self", ".", "state", "[", "i", "]", "[", "key", "]", "[", "key2", "]", ".", "index_select", "(", "0", ",", "selected_state_indices", ")", "\n", "if", "key", "in", "self", ".", "decoder_keys", "[", "i", "]", ":", "\n", "                                ", "if", "key2", "==", "'prev_key_padding_mask'", ":", "\n", "                                    ", "return_state", "[", "i", "]", "[", "key", "]", "[", "key2", "]", "=", "return_state", "[", "i", "]", "[", "key", "]", "[", "key2", "]", "[", ":", ",", "-", "prog_min", ":", "]", "\n", "if", "prog_min", "==", "0", ":", "\n", "                                        ", "return_state", "[", "i", "]", "[", "key", "]", "[", "key2", "]", "=", "return_state", "[", "i", "]", "[", "key", "]", "[", "key2", "]", "[", ":", ",", ":", "0", "]", "\n", "", "assert", "return_state", "[", "i", "]", "[", "key", "]", "[", "key2", "]", ".", "shape", "[", "1", "]", "==", "prog_min", "\n", "", "else", ":", "\n", "                                    ", "return_state", "[", "i", "]", "[", "key", "]", "[", "key2", "]", "=", "return_state", "[", "i", "]", "[", "key", "]", "[", "key2", "]", "[", ":", ",", ":", ",", "-", "prog_min", ":", "]", "\n", "if", "prog_min", "==", "0", ":", "\n", "                                        ", "return_state", "[", "i", "]", "[", "key", "]", "[", "key2", "]", "=", "return_state", "[", "i", "]", "[", "key", "]", "[", "key2", "]", "[", ":", ",", ":", ",", ":", "0", "]", "\n", "", "assert", "return_state", "[", "i", "]", "[", "key", "]", "[", "key2", "]", ".", "shape", "[", "2", "]", "==", "prog_min", "\n", "", "", "", "self", ".", "state", "[", "i", "]", "[", "key", "]", "[", "key2", "]", "=", "self", ".", "state", "[", "i", "]", "[", "key", "]", "[", "key2", "]", ".", "index_select", "(", "0", ",", "unselected_state_indices", ")", "\n", "", "", "", "", "return", "return_indices", ",", "return_state", "\n", "\n"]], "home.repos.pwc.inspect_result.yangkevin2_emnlp2020-stream-beam-mt.None.variable_stream.IncrementalState.recache": [[120, 148], ["torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "range", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "range", "len", "variable_stream.IncrementalState.state[].keys", "len", "max", "[].keys", "len", "variable_stream.IncrementalState.decoder_keys[].add", "len", "variable_stream.IncrementalState.state[].keys", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "util.pad_to_length", "util.pad_to_length", "util.pad_to_length", "util.pad_to_length", "[].to"], "methods", ["home.repos.pwc.inspect_result.yangkevin2_emnlp2020-stream-beam-mt.None.util.pad_to_length", "home.repos.pwc.inspect_result.yangkevin2_emnlp2020-stream-beam-mt.None.util.pad_to_length", "home.repos.pwc.inspect_result.yangkevin2_emnlp2020-stream-beam-mt.None.util.pad_to_length", "home.repos.pwc.inspect_result.yangkevin2_emnlp2020-stream-beam-mt.None.util.pad_to_length"], ["", "def", "recache", "(", "self", ",", "new_master_indices", ",", "new_state", ")", ":", "\n", "        ", "if", "self", ".", "state", "is", "None", ":", "# for variable beam, not streaming version", "\n", "            ", "self", ".", "state", "=", "new_state", "\n", "self", ".", "master_indices", "=", "torch", ".", "cat", "(", "[", "new_master_indices", ",", "self", ".", "master_indices", "]", ",", "dim", "=", "0", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "self", ".", "state", ")", ")", ":", "# initialize decoder keys", "\n", "                ", "for", "key", "in", "self", ".", "state", "[", "i", "]", ":", "\n", "                    ", "if", "self", ".", "state", "[", "i", "]", "[", "key", "]", "[", "'prev_key'", "]", ".", "shape", "[", "2", "]", "==", "1", ":", "\n", "                        ", "self", ".", "decoder_keys", "[", "i", "]", ".", "add", "(", "key", ")", "# others are encoder-side keys and we don't need to do any tricks for those", "\n", "", "", "assert", "len", "(", "self", ".", "decoder_keys", "[", "i", "]", ")", "*", "2", "==", "len", "(", "self", ".", "state", "[", "i", "]", ".", "keys", "(", ")", ")", "\n", "", "return", "\n", "", "self", ".", "master_indices", "=", "torch", ".", "cat", "(", "[", "new_master_indices", ",", "self", ".", "master_indices", "]", ",", "dim", "=", "0", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "self", ".", "state", ")", ")", ":", "\n", "            ", "for", "key", "in", "self", ".", "state", "[", "i", "]", ".", "keys", "(", ")", ":", "\n", "                ", "max_seq", "=", "max", "(", "self", ".", "state", "[", "i", "]", "[", "key", "]", "[", "'prev_key'", "]", ".", "shape", "[", "2", "]", "+", "1", ",", "new_state", "[", "i", "]", "[", "key", "]", "[", "'prev_key'", "]", ".", "shape", "[", "2", "]", ")", "\n", "for", "key2", "in", "self", ".", "state", "[", "i", "]", "[", "key", "]", ".", "keys", "(", ")", ":", "\n", "                    ", "if", "self", ".", "state", "[", "i", "]", "[", "key", "]", "[", "key2", "]", "is", "not", "None", ":", "\n", "                        ", "assert", "new_state", "[", "i", "]", "[", "key", "]", "[", "key2", "]", "is", "not", "None", "\n", "if", "key", "in", "self", ".", "decoder_keys", "[", "i", "]", ":", "\n", "                            ", "if", "key2", "==", "'prev_key_padding_mask'", ":", "\n", "                                ", "self", ".", "state", "[", "i", "]", "[", "key", "]", "[", "key2", "]", "=", "pad_to_length", "(", "self", ".", "state", "[", "i", "]", "[", "key", "]", "[", "key2", "]", ",", "max_seq", ",", "1", ",", "side", "=", "'left'", ",", "value", "=", "True", ")", "\n", "new_state", "[", "i", "]", "[", "key", "]", "[", "key2", "]", "=", "pad_to_length", "(", "new_state", "[", "i", "]", "[", "key", "]", "[", "key2", "]", ",", "max_seq", ",", "1", ",", "side", "=", "'left'", ",", "value", "=", "True", ")", "\n", "", "else", ":", "\n", "                                ", "self", ".", "state", "[", "i", "]", "[", "key", "]", "[", "key2", "]", "=", "pad_to_length", "(", "self", ".", "state", "[", "i", "]", "[", "key", "]", "[", "key2", "]", ",", "max_seq", ",", "2", ",", "side", "=", "'left'", ",", "value", "=", "0", ")", "\n", "new_state", "[", "i", "]", "[", "key", "]", "[", "key2", "]", "=", "pad_to_length", "(", "new_state", "[", "i", "]", "[", "key", "]", "[", "key2", "]", ",", "max_seq", ",", "2", ",", "side", "=", "'left'", ",", "value", "=", "0", ")", "\n", "", "", "self", ".", "state", "[", "i", "]", "[", "key", "]", "[", "key2", "]", "=", "torch", ".", "cat", "(", "[", "new_state", "[", "i", "]", "[", "key", "]", "[", "key2", "]", ".", "to", "(", "self", ".", "state", "[", "i", "]", "[", "key", "]", "[", "key2", "]", ")", ",", "self", ".", "state", "[", "i", "]", "[", "key", "]", "[", "key2", "]", ",", "]", ",", "dim", "=", "0", ")", "\n", "del", "new_state", "[", "i", "]", "[", "key", "]", "[", "key2", "]", "\n", "", "else", ":", "\n", "                        ", "assert", "new_state", "[", "i", "]", "[", "key", "]", "[", "key2", "]", "is", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.yangkevin2_emnlp2020-stream-beam-mt.None.variable_stream.IncrementalState.clean_padding": [[150, 160], ["range", "len", "[].keys"], "methods", ["None"], ["", "", "", "", "", "def", "clean_padding", "(", "self", ",", "num_pad", ")", ":", "\n", "        ", "for", "i", "in", "range", "(", "len", "(", "self", ".", "state", ")", ")", ":", "\n", "            ", "for", "key", "in", "self", ".", "decoder_keys", "[", "i", "]", ":", "\n", "                ", "if", "self", ".", "state", "[", "i", "]", "[", "key", "]", "[", "'prev_key_padding_mask'", "]", "is", "not", "None", ":", "\n", "                    ", "for", "key2", "in", "self", ".", "state", "[", "i", "]", "[", "key", "]", ".", "keys", "(", ")", ":", "\n", "                        ", "if", "self", ".", "state", "[", "i", "]", "[", "key", "]", "[", "key2", "]", "is", "not", "None", ":", "\n", "                            ", "if", "key2", "==", "'prev_key_padding_mask'", ":", "\n", "                                ", "self", ".", "state", "[", "i", "]", "[", "key", "]", "[", "key2", "]", "=", "self", ".", "state", "[", "i", "]", "[", "key", "]", "[", "key2", "]", "[", ":", ",", "num_pad", ":", "]", "\n", "", "else", ":", "\n", "                                ", "self", ".", "state", "[", "i", "]", "[", "key", "]", "[", "key2", "]", "=", "self", ".", "state", "[", "i", "]", "[", "key", "]", "[", "key2", "]", "[", ":", ",", ":", ",", "num_pad", ":", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.yangkevin2_emnlp2020-stream-beam-mt.None.variable_stream.select_source_indices": [[13, 18], ["torch.arange().to", "torch.arange().to", "torch.arange().to", "progress.min", "torch.arange", "torch.arange", "torch.arange", "len"], "function", ["None"], ["def", "select_source_indices", "(", "num_valid_beams", ",", "progress", ",", "index", ",", "max_indices", ",", "reverse", "=", "False", ",", "sort", "=", "False", ")", ":", "\n", "# select source infos (starting from the least progress made) until we hit max allowed beams", "\n", "    ", "indices", "=", "torch", ".", "arange", "(", "len", "(", "index", ")", ")", ".", "to", "(", "index", ".", "device", ")", "\n", "prog_min", "=", "progress", ".", "min", "(", ")", "\n", "return", "indices", "[", "progress", "==", "prog_min", "]", ",", "indices", "[", "progress", "!=", "prog_min", "]", ",", "prog_min", "\n", "\n"]], "home.repos.pwc.inspect_result.yangkevin2_emnlp2020-stream-beam-mt.None.variable_stream.reorder_incremental_state_no_model": [[20, 27], ["range", "len", "state[].keys", "[].keys", "[].index_select"], "function", ["None"], ["", "def", "reorder_incremental_state_no_model", "(", "state", ",", "reorder_idx", ")", ":", "\n", "    ", "for", "i", "in", "range", "(", "len", "(", "state", ")", ")", ":", "\n", "        ", "for", "key", "in", "state", "[", "i", "]", ".", "keys", "(", ")", ":", "\n", "            ", "for", "key2", "in", "state", "[", "i", "]", "[", "key", "]", ".", "keys", "(", ")", ":", "\n", "                ", "if", "state", "[", "i", "]", "[", "key", "]", "[", "key2", "]", "is", "not", "None", ":", "\n", "                    ", "state", "[", "i", "]", "[", "key", "]", "[", "key2", "]", "=", "state", "[", "i", "]", "[", "key", "]", "[", "key2", "]", ".", "index_select", "(", "0", ",", "reorder_idx", ")", "\n", "", "", "", "", "return", "state", "\n", "\n"]], "home.repos.pwc.inspect_result.yangkevin2_emnlp2020-stream-beam-mt.None.variable_stream.reorder_incremental_state": [[29, 35], ["range", "len", "model.incremental_states[].keys", "[].keys", "[].index_select"], "function", ["None"], ["", "def", "reorder_incremental_state", "(", "model", ",", "reorder_idx", ")", ":", "# because fairseq's is bugged", "\n", "    ", "for", "i", "in", "range", "(", "len", "(", "model", ".", "incremental_states", ")", ")", ":", "\n", "        ", "for", "key", "in", "model", ".", "incremental_states", "[", "i", "]", ".", "keys", "(", ")", ":", "\n", "            ", "for", "key2", "in", "model", ".", "incremental_states", "[", "i", "]", "[", "key", "]", ".", "keys", "(", ")", ":", "\n", "                ", "if", "model", ".", "incremental_states", "[", "i", "]", "[", "key", "]", "[", "key2", "]", "is", "not", "None", ":", "\n", "                    ", "model", ".", "incremental_states", "[", "i", "]", "[", "key", "]", "[", "key2", "]", "=", "model", ".", "incremental_states", "[", "i", "]", "[", "key", "]", "[", "key2", "]", ".", "index_select", "(", "0", ",", "reorder_idx", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yangkevin2_emnlp2020-stream-beam-mt.None.variable_stream.variable_beam_stream_fast": [[162, 464], ["len", "torch.zeros().long().to", "torch.zeros().long().to", "torch.zeros().long().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "variable_stream.IncrementalState", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().long().to", "torch.zeros().long().to", "torch.zeros().long().to", "torch.zeros().long().to", "torch.zeros().long().to", "torch.zeros().long().to", "torch.zeros().long().to", "torch.zeros().long().to", "torch.zeros().long().to", "torch.zeros().long().to", "torch.zeros().long().to", "torch.zeros().long().to", "torch.zeros().long().to", "torch.zeros().long().to", "torch.zeros().long().to", "torch.zeros().long().to", "torch.zeros().long().to", "torch.zeros().long().to", "torch.zeros().long().to", "torch.zeros().long().to", "torch.zeros().long().to", "all", "range", "len", "model._build_batches", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "variable_stream.select_source_indices", "len", "sg.model.reorder_encoder_out", "valid_beam_mask.flatten().nonzero().flatten", "len", "sg.model.reorder_encoder_out", "torch.all", "torch.all", "torch.all", "sg.model.forward_decoder", "next_log_probs[].view", "next_log_probs.view.view", "end_found.unsqueeze().unsqueeze.unsqueeze().unsqueeze", "next_log_probs.view.topk", "mc_probs.flatten().topk", "torch.gather().unsqueeze", "torch.gather().unsqueeze", "torch.gather().unsqueeze", "torch.cumprod", "torch.cumprod", "torch.cumprod", "torch.cumprod.sum().flatten", "torch.cumprod.flatten().nonzero", "torch.cat", "torch.cat", "torch.cat", "torch.gather", "torch.gather", "torch.gather", "shift_indices.clamp.clamp", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather.squeeze", "util.pad_mask().permute", "found_z_mask.flatten().nonzero().flatten().long", "torch.cat", "torch.cat", "torch.cat", "torch.zeros().long().to", "torch.zeros().long().to", "torch.zeros().long().to", "torch.gather", "torch.gather", "torch.gather", "torch.cat", "torch.cat", "torch.cat", "torch.roll", "torch.roll", "torch.roll", "torch.cat.sum().long", "variable_stream.reorder_incremental_state", "sg.model.reorder_encoder_out", "len", "sorted", "range", "range", "torch.zeros().long", "torch.zeros().long", "torch.zeros().long", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros().long", "torch.zeros().long", "torch.zeros().long", "torch.zeros().long", "torch.zeros().long", "torch.zeros().long", "torch.zeros().long", "torch.zeros().long", "torch.zeros().long", "torch.zeros().long", "torch.zeros().long", "torch.zeros().long", "torch.zeros().long", "torch.zeros().long", "torch.zeros().long", "torch.zeros().long", "torch.zeros().long", "torch.zeros().long", "torch.zeros().long", "torch.zeros().long", "torch.zeros().long", "fairseq.utils.apply_to_sample", "enumerate", "len", "sg.model.forward_encoder", "torch.cat.size", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "selected_indices.unsqueeze().expand().flatten", "variable_stream.IncrementalState.clean_padding", "variable_stream.IncrementalState.select_incremental_state", "len", "torch.cat.clone", "len", "len", "decoded_indices.flatten", "torch.zeros_like().to", "torch.zeros_like().to", "torch.zeros_like().to", "top_log_probs.squeeze.unsqueeze().unsqueeze", "torch.cumprod.sum().unsqueeze", "torch.arange().to().unsqueeze().unsqueeze", "torch.arange().to().unsqueeze().unsqueeze", "torch.arange().to().unsqueeze().unsqueeze", "torch.gather.expand", "torch.cat", "torch.cat", "torch.cat", "torch.cat.sum", "variable_stream.IncrementalState.recache", "torch.zeros", "torch.zeros", "torch.zeros", "torch.cat.sum", "batch[].tolist", "len", "range", "sg.model.forward_decoder", "variable_stream.IncrementalState.append_new_incremental_state", "len", "len", "valid_beam_mask.flatten().nonzero", "len", "decoding_selected_indices.flatten().permute", "end_found.unsqueeze().unsqueeze.unsqueeze", "mc_probs.flatten", "torch.gather", "torch.gather", "torch.gather", "torch.cumprod.sum", "torch.cumprod.flatten", "len", "decoded_indices[].flatten", "util.pad_mask", "valid_beam_mask.max", "found_z_mask.long", "found_z_mask.flatten().nonzero().flatten", "torch.zeros().long", "torch.zeros().long", "torch.zeros().long", "torch.cat.sum", "valid_beam_mask.flatten().nonzero().flatten", "len", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "next", "t.to", "util.pad_to_length().long().to", "torch.cat().to", "torch.cat().to", "torch.cat().to", "len", "len", "len", "max", "fairseq.models.fairseq_encoder.EncoderOut", "torch.cat().to", "torch.cat().to", "torch.cat().to", "torch.ones().long().to", "torch.ones().long().to", "torch.ones().long().to", "torch.zeros().long().to", "torch.zeros().long().to", "torch.zeros().long().to", "torch.zeros().long().to", "torch.zeros().long().to", "torch.zeros().long().to", "torch.zeros().long().to", "torch.zeros().long().to", "torch.zeros().long().to", "selected_indices.unsqueeze().expand", "len", "decoding_selected_indices.flatten().permute", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "valid_beam_mask.unsqueeze().unsqueeze", "top_log_probs.squeeze.unsqueeze", "mc_indices.flatten().flatten", "len", "master_done_beams[].append", "max", "master_done_beams[].append", "torch.zeros_like().to", "torch.zeros_like().to", "torch.zeros_like().to", "torch.cumprod.sum", "torch.arange().to().unsqueeze", "torch.arange().to().unsqueeze", "torch.arange().to().unsqueeze", "torch.max", "torch.max", "torch.max", "all_low_prob_mask.bool", "torch.zeros().long().to", "torch.zeros().long().to", "torch.zeros().long().to", "torch.gather", "torch.gather", "torch.gather", "torch.cat.sum().sum", "range", "torch.arange().long().to", "torch.arange().long().to", "torch.arange().long().to", "torch.arange().to", "torch.arange().to", "torch.arange().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "valid_beam_mask.flatten", "torch.cumsum", "torch.cumsum", "torch.cumsum", "valid_beam_mask.flatten", "decoding_selected_indices.flatten", "len", "torch.arange().to().unsqueeze().repeat", "torch.arange().to().unsqueeze().repeat", "torch.arange().to().unsqueeze().repeat", "found_z_mask.flatten().nonzero", "torch.zeros", "torch.zeros", "torch.zeros", "end_found.unsqueeze().unsqueeze.squeeze", "valid_beam_mask.flatten().nonzero", "util.pad_to_length().long", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.ones().long", "torch.ones().long", "torch.ones().long", "torch.zeros().long", "torch.zeros().long", "torch.zeros().long", "torch.zeros().long", "torch.zeros().long", "torch.zeros().long", "torch.zeros().long", "torch.zeros().long", "torch.zeros().long", "selected_indices.unsqueeze", "valid_beam_mask.flatten", "progress.max", "decoding_selected_indices.flatten", "torch.cat.max", "valid_beam_mask.unsqueeze", "mc_indices.flatten", "decoded_indices[].flatten.cpu", "torch.gather.flatten", "decoded_indices[].flatten.cpu", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.arange().to", "torch.arange().to", "torch.arange().to", "torch.cat.size", "torch.zeros().long", "torch.zeros().long", "torch.zeros().long", "torch.cat.sum", "torch.arange().long", "torch.arange().long", "torch.arange().long", "torch.arange", "torch.arange", "torch.arange", "torch.zeros", "torch.zeros", "torch.zeros", "torch.arange().to().unsqueeze", "torch.arange().to().unsqueeze", "torch.arange().to().unsqueeze", "found_z_mask.flatten", "valid_beam_mask.flatten", "util.pad_to_length", "torch.zeros", "torch.zeros", "torch.zeros", "util.pad_to_length", "util.pad_to_length", "util.pad_to_length", "util.pad_to_length", "util.pad_to_length", "util.pad_to_length", "torch.ones", "torch.ones", "torch.ones", "torch.zeros", "torch.zeros", "torch.zeros", "torch.ones", "torch.ones", "torch.ones", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.arange", "torch.arange", "torch.arange", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.arange", "torch.arange", "torch.arange", "torch.arange().to", "torch.arange().to", "torch.arange().to", "torch.cat.size", "torch.zeros", "torch.zeros", "torch.zeros", "torch.gather.flatten", "torch.zeros", "torch.zeros", "torch.zeros", "torch.arange", "torch.arange", "torch.arange"], "function", ["home.repos.pwc.inspect_result.yangkevin2_emnlp2020-stream-beam-mt.None.variable_stream.select_source_indices", "home.repos.pwc.inspect_result.yangkevin2_emnlp2020-stream-beam-mt.None.sequence_generator.EnsembleModel.reorder_encoder_out", "home.repos.pwc.inspect_result.yangkevin2_emnlp2020-stream-beam-mt.None.sequence_generator.EnsembleModel.reorder_encoder_out", "home.repos.pwc.inspect_result.yangkevin2_emnlp2020-stream-beam-mt.None.sequence_generator.EnsembleModel.forward_decoder", "home.repos.pwc.inspect_result.yangkevin2_emnlp2020-stream-beam-mt.None.sequence_generator.EnsembleModel.reorder_incremental_state", "home.repos.pwc.inspect_result.yangkevin2_emnlp2020-stream-beam-mt.None.sequence_generator.EnsembleModel.reorder_encoder_out", "home.repos.pwc.inspect_result.yangkevin2_emnlp2020-stream-beam-mt.None.sequence_generator.EnsembleModel.forward_encoder", "home.repos.pwc.inspect_result.yangkevin2_emnlp2020-stream-beam-mt.None.variable_stream.IncrementalState.clean_padding", "home.repos.pwc.inspect_result.yangkevin2_emnlp2020-stream-beam-mt.None.variable_stream.IncrementalState.select_incremental_state", "home.repos.pwc.inspect_result.yangkevin2_emnlp2020-stream-beam-mt.None.variable_stream.IncrementalState.recache", "home.repos.pwc.inspect_result.yangkevin2_emnlp2020-stream-beam-mt.None.sequence_generator.EnsembleModel.forward_decoder", "home.repos.pwc.inspect_result.yangkevin2_emnlp2020-stream-beam-mt.None.variable_stream.IncrementalState.append_new_incremental_state", "home.repos.pwc.inspect_result.yangkevin2_emnlp2020-stream-beam-mt.None.util.pad_mask", "home.repos.pwc.inspect_result.yangkevin2_emnlp2020-stream-beam-mt.None.util.pad_to_length", "home.repos.pwc.inspect_result.yangkevin2_emnlp2020-stream-beam-mt.None.util.pad_to_length", "home.repos.pwc.inspect_result.yangkevin2_emnlp2020-stream-beam-mt.None.util.pad_to_length", "home.repos.pwc.inspect_result.yangkevin2_emnlp2020-stream-beam-mt.None.util.pad_to_length", "home.repos.pwc.inspect_result.yangkevin2_emnlp2020-stream-beam-mt.None.util.pad_to_length", "home.repos.pwc.inspect_result.yangkevin2_emnlp2020-stream-beam-mt.None.util.pad_to_length", "home.repos.pwc.inspect_result.yangkevin2_emnlp2020-stream-beam-mt.None.util.pad_to_length"], ["", "", "", "", "", "", "", "", "def", "variable_beam_stream_fast", "(", "sg", ",", "model", ",", "tokenized_sentences", ",", "k", "=", "5", ",", "max_length", "=", "100", ",", "rp", "=", "0.6", ",", "ap", "=", "2.5", ",", "rpl", "=", "0.02", ",", "mc", "=", "3", ",", "find_top_z", "=", "1", ",", "max_indices", "=", "32", ",", "encode_batch_size", "=", "64", ",", "max_si_tokens", "=", "7168", ",", "bos_token", "=", "None", ",", "len_penalty", "=", "1", ",", "one_batch", "=", "False", ")", ":", "\n", "    ", "ensemble_size", "=", "len", "(", "model", ".", "models", ")", "\n", "\n", "BOS_ID", "=", "sg", ".", "eos", "if", "bos_token", "is", "None", "else", "bos_token", "\n", "EOS_ID", "=", "sg", ".", "eos", "\n", "\n", "if", "one_batch", ":", "\n", "        ", "full_data_size", "=", "tokenized_sentences", "[", "'net_input'", "]", "[", "'src_tokens'", "]", ".", "shape", "[", "0", "]", "\n", "", "else", ":", "\n", "        ", "full_data_size", "=", "len", "(", "tokenized_sentences", ")", "\n", "batch_iterator", "=", "model", ".", "_build_batches", "(", "tokenized_sentences", ",", "False", ")", "# not streaming", "\n", "", "master_done_beams", "=", "[", "[", "]", "for", "_", "in", "range", "(", "full_data_size", ")", "]", "\n", "master_batch_ids", "=", "[", "None", "for", "_", "in", "range", "(", "full_data_size", ")", "]", "\n", "\n", "parent_model", "=", "model", "\n", "model", "=", "model", ".", "models", "\n", "\n", "master_decoded_indices", "=", "torch", ".", "zeros", "(", "1", ",", "0", ",", "k", ")", ".", "long", "(", ")", ".", "to", "(", "parent_model", ".", "device", ")", "# seq, batch, k", "\n", "master_log_probs", "=", "torch", ".", "zeros", "(", "0", ",", "k", ")", ".", "to", "(", "parent_model", ".", "device", ")", "# batch x k", "\n", "master_enc_out", "=", "[", "]", "\n", "master_state", "=", "IncrementalState", "(", "0", ",", "k", ",", "ensemble_size", ",", "parent_model", ".", "device", ")", "# init incremental state", "\n", "\n", "master_valid_beam_mask", "=", "torch", ".", "zeros", "(", "0", ",", "k", ")", ".", "to", "(", "parent_model", ".", "device", ")", "# batch x k", "\n", "master_num_valid_beams", "=", "torch", ".", "zeros", "(", "0", ")", ".", "long", "(", ")", ".", "to", "(", "parent_model", ".", "device", ")", "# batch", "\n", "master_index", "=", "torch", ".", "zeros", "(", "0", ")", ".", "long", "(", ")", ".", "to", "(", "parent_model", ".", "device", ")", "# batch", "\n", "master_src_lengths", "=", "torch", ".", "zeros", "(", "0", ")", ".", "long", "(", ")", ".", "to", "(", "parent_model", ".", "device", ")", "\n", "master_progress", "=", "torch", ".", "zeros", "(", "0", ")", ".", "long", "(", ")", ".", "to", "(", "parent_model", ".", "device", ")", "# batch", "\n", "master_end_found", "=", "torch", ".", "zeros", "(", "0", ",", "k", ")", ".", "long", "(", ")", ".", "to", "(", "parent_model", ".", "device", ")", "# batch x k", "\n", "master_done_lengths", "=", "torch", ".", "zeros", "(", "0", ")", ".", "long", "(", ")", ".", "to", "(", "parent_model", ".", "device", ")", "# batch", "\n", "master_best_finished_log_probs", "=", "torch", ".", "zeros", "(", "0", ")", ".", "to", "(", "parent_model", ".", "device", ")", "-", "1e8", "# batch", "\n", "\n", "current_idx", "=", "0", "\n", "has_more_batches", "=", "True", "\n", "decode_calls", "=", "0", "\n", "n_expansions", "=", "0", "\n", "master_remove_indices", "=", "torch", ".", "zeros", "(", "0", ")", ".", "long", "(", ")", ".", "to", "(", "parent_model", ".", "device", ")", "\n", "num_pad", "=", "0", "\n", "reselect", "=", "True", "\n", "while", "True", ":", "\n", "        ", "while", "has_more_batches", "and", "master_src_lengths", ".", "sum", "(", ")", "<=", "max_si_tokens", "-", "parent_model", ".", "args", ".", "max_tokens", ":", "# token-based limit", "\n", "            ", "assert", "reselect", "\n", "if", "one_batch", ":", "# not streaming", "\n", "                ", "batch", "=", "tokenized_sentences", "\n", "has_more_batches", "=", "False", "\n", "", "else", ":", "\n", "                ", "try", ":", "\n", "                    ", "batch", "=", "next", "(", "batch_iterator", ")", "\n", "", "except", "StopIteration", ":", "\n", "                    ", "has_more_batches", "=", "False", "\n", "break", "\n", "", "", "batch", "=", "utils", ".", "apply_to_sample", "(", "lambda", "t", ":", "t", ".", "to", "(", "parent_model", ".", "device", ")", ",", "batch", ")", "\n", "for", "i", ",", "id", "in", "enumerate", "(", "batch", "[", "'id'", "]", ".", "tolist", "(", ")", ")", ":", "\n", "                ", "master_batch_ids", "[", "current_idx", "+", "i", "]", "=", "id", "\n", "", "net_input", "=", "batch", "[", "\"net_input\"", "]", "\n", "src_tokens", "=", "net_input", "[", "\"src_tokens\"", "]", "\n", "num_new_sources", "=", "len", "(", "src_tokens", ")", "\n", "\n", "# encode add the next batch of source infos; update the index", "\n", "encoder_outs", "=", "sg", ".", "model", ".", "forward_encoder", "(", "net_input", ")", "\n", "# concatenate to the current master tensors", "\n", "# decoded_indices; note these are left padded", "\n", "current_seqlen", "=", "master_decoded_indices", ".", "size", "(", "0", ")", "\n", "master_decoded_indices", "=", "torch", ".", "cat", "(", "[", "master_decoded_indices", ",", "\n", "pad_to_length", "(", "torch", ".", "zeros", "(", "1", ",", "num_new_sources", ",", "k", ")", "+", "BOS_ID", ",", "current_seqlen", ",", "0", ",", "side", "=", "'left'", ",", "value", "=", "0", ")", ".", "long", "(", ")", ".", "to", "(", "parent_model", ".", "device", ")", "]", ",", "\n", "dim", "=", "1", ")", "\n", "# log_probs", "\n", "master_log_probs", "=", "torch", ".", "cat", "(", "[", "master_log_probs", ",", "\n", "torch", ".", "cat", "(", "[", "torch", ".", "zeros", "(", "num_new_sources", ",", "1", ")", ",", "torch", ".", "zeros", "(", "num_new_sources", ",", "k", "-", "1", ")", "-", "1e8", "]", ",", "dim", "=", "1", ")", ".", "to", "(", "parent_model", ".", "device", ")", "]", ",", "\n", "dim", "=", "0", ")", "\n", "\n", "if", "len", "(", "master_enc_out", ")", "==", "0", ":", "\n", "                ", "assert", "current_idx", "==", "0", "\n", "master_enc_out", "=", "encoder_outs", "\n", "", "else", ":", "\n", "                ", "assert", "len", "(", "master_enc_out", ")", "==", "len", "(", "encoder_outs", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "master_enc_out", ")", ")", ":", "\n", "                    ", "meo", ",", "eo", "=", "master_enc_out", "[", "i", "]", ",", "encoder_outs", "[", "i", "]", "\n", "max_seq", "=", "max", "(", "meo", ".", "encoder_out", ".", "shape", "[", "0", "]", ",", "eo", ".", "encoder_out", ".", "shape", "[", "0", "]", ")", "\n", "new_eo", "=", "EncoderOut", "(", "encoder_out", "=", "torch", ".", "cat", "(", "[", "pad_to_length", "(", "meo", ".", "encoder_out", ",", "max_seq", ",", "0", ",", "side", "=", "'left'", ",", "value", "=", "0", ")", ",", "pad_to_length", "(", "eo", ".", "encoder_out", ",", "max_seq", ",", "0", ",", "side", "=", "'left'", ",", "value", "=", "0", ")", "]", ",", "dim", "=", "1", ")", ",", "\n", "encoder_padding_mask", "=", "torch", ".", "cat", "(", "[", "pad_to_length", "(", "meo", ".", "encoder_padding_mask", ",", "max_seq", ",", "1", ",", "side", "=", "'left'", ",", "value", "=", "True", ")", ",", "pad_to_length", "(", "eo", ".", "encoder_padding_mask", ",", "max_seq", ",", "1", ",", "side", "=", "'left'", ",", "value", "=", "True", ")", "]", ",", "dim", "=", "0", ")", ",", "\n", "encoder_embedding", "=", "torch", ".", "cat", "(", "[", "pad_to_length", "(", "meo", ".", "encoder_embedding", ",", "max_seq", ",", "1", ",", "side", "=", "'left'", ",", "value", "=", "0", ")", ",", "pad_to_length", "(", "eo", ".", "encoder_embedding", ",", "max_seq", ",", "1", ",", "side", "=", "'left'", ",", "value", "=", "0", ")", "]", ",", "dim", "=", "0", ")", ",", "\n", "encoder_states", "=", "None", ",", "\n", "src_tokens", "=", "None", ",", "\n", "src_lengths", "=", "None", ")", "\n", "master_enc_out", "[", "i", "]", "=", "new_eo", "\n", "", "", "if", "not", "one_batch", ":", "\n", "# get the encoder attention keys", "\n", "                ", "sg", ".", "model", ".", "incremental_states", "=", "[", "{", "}", "for", "_", "in", "range", "(", "ensemble_size", ")", "]", "\n", "sg", ".", "model", ".", "forward_decoder", "(", "(", "torch", ".", "zeros", "(", "num_new_sources", ")", "+", "BOS_ID", ")", ".", "long", "(", ")", ".", "to", "(", "parent_model", ".", "device", ")", ".", "unsqueeze", "(", "1", ")", ",", "encoder_outs", ",", "sg", ".", "temperature", ")", "\n", "dummy_state", "=", "sg", ".", "model", ".", "incremental_states", "\n", "master_state", ".", "append_new_incremental_state", "(", "num_new_sources", ",", "dummy_state", ",", "torch", ".", "arange", "(", "num_new_sources", ")", ".", "long", "(", ")", ".", "to", "(", "parent_model", ".", "device", ")", "+", "current_idx", ")", "\n", "\n", "", "master_valid_beam_mask", "=", "torch", ".", "cat", "(", "[", "master_valid_beam_mask", ",", "\n", "torch", ".", "cat", "(", "[", "torch", ".", "ones", "(", "num_new_sources", ",", "1", ")", ",", "torch", ".", "zeros", "(", "num_new_sources", ",", "k", "-", "1", ")", "]", ",", "dim", "=", "1", ")", ".", "to", "(", "parent_model", ".", "device", ")", "]", ",", "\n", "dim", "=", "0", ")", "\n", "# print(net_input['src_lengths'].max())", "\n", "master_src_lengths", "=", "torch", ".", "cat", "(", "[", "master_src_lengths", ",", "net_input", "[", "'src_lengths'", "]", "]", ",", "dim", "=", "0", ")", "\n", "# num_valid_beams", "\n", "master_num_valid_beams", "=", "torch", ".", "cat", "(", "[", "master_num_valid_beams", ",", "torch", ".", "ones", "(", "num_new_sources", ")", ".", "long", "(", ")", ".", "to", "(", "parent_model", ".", "device", ")", "]", ",", "dim", "=", "0", ")", "\n", "# index", "\n", "master_index", "=", "torch", ".", "cat", "(", "[", "master_index", ",", "current_idx", "+", "torch", ".", "arange", "(", "num_new_sources", ")", ".", "to", "(", "parent_model", ".", "device", ")", "]", ",", "dim", "=", "0", ")", "\n", "# progress", "\n", "master_progress", "=", "torch", ".", "cat", "(", "[", "master_progress", ",", "torch", ".", "zeros", "(", "num_new_sources", ")", ".", "long", "(", ")", ".", "to", "(", "parent_model", ".", "device", ")", "]", ",", "dim", "=", "0", ")", "\n", "# end_found", "\n", "master_end_found", "=", "torch", ".", "cat", "(", "[", "master_end_found", ",", "torch", ".", "zeros", "(", "num_new_sources", ",", "k", ")", ".", "long", "(", ")", ".", "to", "(", "parent_model", ".", "device", ")", "]", ",", "dim", "=", "0", ")", "\n", "# done lengths", "\n", "master_done_lengths", "=", "torch", ".", "cat", "(", "[", "master_done_lengths", ",", "torch", ".", "zeros", "(", "num_new_sources", ")", ".", "long", "(", ")", ".", "to", "(", "parent_model", ".", "device", ")", "]", ",", "dim", "=", "0", ")", "\n", "# best done log probs", "\n", "master_best_finished_log_probs", "=", "torch", ".", "cat", "(", "[", "master_best_finished_log_probs", ",", "torch", ".", "zeros", "(", "num_new_sources", ")", ".", "to", "(", "parent_model", ".", "device", ")", "-", "1e8", "]", ",", "dim", "=", "0", ")", "\n", "\n", "current_idx", "+=", "num_new_sources", "\n", "# break # for debugging", "\n", "\n", "# break if none left", "\n", "", "if", "not", "has_more_batches", "and", "len", "(", "master_index", ")", "==", "0", ":", "\n", "            ", "break", "\n", "\n", "# based on max_bs and source_info, select which indices to use (sort source_info), then create:", "\n", "", "selected_indices", ",", "unselected_indices", ",", "prog_min", "=", "select_source_indices", "(", "master_num_valid_beams", ",", "master_progress", ",", "master_index", ",", "max_indices", ",", "reverse", "=", "False", ",", "sort", "=", "False", ")", "\n", "if", "one_batch", ":", "\n", "            ", "assert", "len", "(", "unselected_indices", ")", "==", "0", "# for debugging", "\n", "", "selected_master_indices", "=", "master_index", "[", "selected_indices", "]", "\n", "batch_size", "=", "len", "(", "selected_indices", ")", "\n", "selected_enc_out", "=", "sg", ".", "model", ".", "reorder_encoder_out", "(", "master_enc_out", ",", "selected_indices", ".", "unsqueeze", "(", "1", ")", ".", "expand", "(", "-", "1", ",", "k", ")", ".", "flatten", "(", ")", ")", "\n", "# if decode_calls % 50 == 0:", "\n", "#     print(decode_calls)", "\n", "\n", "valid_beam_mask", "=", "master_valid_beam_mask", "[", "selected_indices", "]", "\n", "valid_beam_indices", "=", "valid_beam_mask", ".", "flatten", "(", ")", ".", "nonzero", "(", ")", ".", "flatten", "(", ")", "# idk why need to flatten again", "\n", "reverse_idx", "=", "(", "torch", ".", "cumsum", "(", "valid_beam_mask", ".", "flatten", "(", ")", ",", "dim", "=", "0", ")", "*", "valid_beam_mask", ".", "flatten", "(", ")", ")", ".", "long", "(", ")", "-", "1", "# it's fine to select whatever position for padding as they'll be removed later", "\n", "if", "num_pad", ">", "0", ":", "\n", "            ", "if", "num_pad", ">=", "len", "(", "master_decoded_indices", ")", ":", "# edge case: we previously ran out of beams, and we are starting fresh now", "\n", "                ", "assert", "num_pad", "==", "len", "(", "master_decoded_indices", ")", "\n", "num_pad", "-=", "1", "\n", "", "master_decoded_indices", "=", "master_decoded_indices", "[", "num_pad", ":", "]", "\n", "master_state", ".", "clean_padding", "(", "num_pad", ")", "\n", "\n", "", "if", "reselect", ":", "\n", "            ", "selected_state_master_indices", ",", "selected_state", "=", "master_state", ".", "select_incremental_state", "(", "selected_master_indices", ",", "master_remove_indices", ",", "prog_min", ")", "\n", "master_state", ".", "num_sources", "-=", "len", "(", "master_remove_indices", ")", "\n", "", "sg", ".", "model", ".", "incremental_states", "=", "selected_state", "\n", "log_probs", "=", "master_log_probs", "[", "selected_indices", "]", "\n", "progress", "=", "master_progress", "[", "selected_indices", "]", "\n", "decoded_indices", "=", "master_decoded_indices", "[", "-", "progress", ".", "max", "(", ")", "-", "1", ":", ",", "selected_indices", ",", ":", "]", "\n", "end_found", "=", "master_end_found", "[", "selected_indices", "]", "\n", "done_lengths", "=", "master_done_lengths", "[", "selected_indices", "]", "\n", "best_finished_log_probs", "=", "master_best_finished_log_probs", "[", "selected_indices", "]", "\n", "\n", "# flattened_indices = last_indices.flatten().unsqueeze(0) # 1 x batch*k", "\n", "# create valid beam indices from valid beam mask", "\n", "if", "one_batch", "and", "decode_calls", "==", "0", ":", "\n", "            ", "selected_state_master_indices", "=", "master_index", ".", "clone", "(", ")", "\n", "", "assert", "len", "(", "selected_state_master_indices", ")", "==", "len", "(", "valid_beam_indices", ")", "\n", "decode_calls", "+=", "1", "\n", "n_expansions", "+=", "len", "(", "valid_beam_indices", ")", "\n", "\n", "# use valid_beam_mask to select valid indices out of decoded_indices, encoder_outs, model incremental state", "\n", "decoding_selected_indices", "=", "decoded_indices", ".", "flatten", "(", "1", ")", "[", ":", ",", "valid_beam_indices", "]", "# seq x selected", "\n", "selected_enc_out", "=", "sg", ".", "model", ".", "reorder_encoder_out", "(", "selected_enc_out", ",", "valid_beam_indices", ")", "\n", "\n", "assert", "torch", ".", "all", "(", "decoding_selected_indices", ".", "flatten", "(", "1", ")", ".", "permute", "(", "1", ",", "0", ")", "[", ":", ",", "0", "]", "==", "2", ")", "\n", "next_log_probs", ",", "_", "=", "sg", ".", "model", ".", "forward_decoder", "(", "\n", "decoding_selected_indices", ".", "flatten", "(", "1", ")", ".", "permute", "(", "1", ",", "0", ")", "[", ":", ",", ":", "master_progress", ".", "max", "(", ")", "+", "1", "]", ",", "selected_enc_out", ",", "sg", ".", "temperature", "\n", ")", "\n", "\n", "# remake next_scores, state with dummies", "\n", "next_log_probs", "=", "next_log_probs", "[", "reverse_idx", "]", ".", "view", "(", "1", ",", "batch_size", ",", "k", ",", "-", "1", ")", "\n", "# reorder incremental model state", "\n", "reorder_idx", "=", "reverse_idx", "\n", "\n", "next_log_probs", "=", "next_log_probs", ".", "view", "(", "1", ",", "batch_size", ",", "k", ",", "-", "1", ")", "\n", "\n", "# for edge case where EOS_ID appears later down in the beam but still needs to be dealt with correctly on the next step!", "\n", "end_found", "=", "end_found", ".", "unsqueeze", "(", "0", ")", ".", "unsqueeze", "(", "3", ")", "# batch_size x k x 1 of whether end index is in tgt_idx already; if so, make prob of padding 1", "\n", "end_found", "=", "(", "end_found", "+", "(", "progress", "+", "1", "==", "max_length", ")", ".", "long", "(", ")", ".", "view", "(", "1", ",", "-", "1", ",", "1", ",", "1", ")", ")", ".", "clamp", "(", "max", "=", "1", ")", "\n", "end_found_scores", "=", "torch", ".", "zeros_like", "(", "next_log_probs", ")", ".", "to", "(", "parent_model", ".", "device", ")", "-", "1e8", "\n", "end_found_scores", "[", ":", ",", ":", ",", ":", ",", "EOS_ID", "]", "=", "0", "# make it so you only pick eos for the sequences that are already done, and don't duplicate them, by making other probs -inf", "\n", "next_log_probs", "=", "end_found", "*", "end_found_scores", "+", "(", "1", "-", "end_found", ")", "*", "next_log_probs", "# ~ is for inverting the mask", "\n", "\n", "next_log_probs", "=", "next_log_probs", "-", "1e8", "*", "(", "1", "-", "valid_beam_mask", ".", "unsqueeze", "(", "0", ")", ".", "unsqueeze", "(", "3", ")", ")", "# get rid of padding positions", "\n", "next_log_probs", "=", "next_log_probs", "+", "log_probs", ".", "unsqueeze", "(", "0", ")", ".", "unsqueeze", "(", "3", ")", "# 1, batch, k, vocab", "\n", "mc_probs", ",", "mc_indices", "=", "next_log_probs", ".", "topk", "(", "mc", ",", "dim", "=", "3", ")", "# 1, batch, k, mc", "\n", "top_log_probs", ",", "top_indices", "=", "mc_probs", ".", "flatten", "(", "2", ")", ".", "topk", "(", "k", ",", "dim", "=", "2", ")", "# 1, batch, k", "\n", "mc_vocab_indices", "=", "top_indices", "%", "mc", "\n", "beam_indices", "=", "top_indices", "//", "mc", "# 1, batch, k", "\n", "vocab_indices", "=", "torch", ".", "gather", "(", "mc_indices", ".", "flatten", "(", "2", ")", ".", "flatten", "(", "0", ",", "1", ")", ",", "1", ",", "(", "mc_vocab_indices", "+", "beam_indices", "*", "mc", ")", ".", "flatten", "(", "0", ",", "1", ")", ")", ".", "unsqueeze", "(", "0", ")", "# 1, batch, k", "\n", "# check which vocab_indices are done (in the first beam position), and add the corresponding beam to an array of done predictions", "\n", "newly_done_all", "=", "(", "vocab_indices", "==", "EOS_ID", ")", ".", "long", "(", ")", "# 1, batch, k", "\n", "newly_done", "=", "torch", ".", "cumprod", "(", "newly_done_all", ",", "dim", "=", "2", ")", "# keep on beam if there's something above it that's not done yet", "\n", "done_lengths", "+=", "newly_done", ".", "sum", "(", "dim", "=", "2", ")", ".", "flatten", "(", ")", "# update this one before others since we'll need it earlier", "\n", "newly_done_indices", "=", "newly_done", ".", "flatten", "(", ")", ".", "nonzero", "(", ")", "# batch*k", "\n", "for", "j", "in", "newly_done_indices", ":", "\n", "            ", "source_idx", "=", "j", "//", "k", "\n", "# add to some master list with an entry for each source", "\n", "if", "len", "(", "master_done_beams", "[", "selected_master_indices", "[", "source_idx", "]", "]", ")", "<", "find_top_z", ":", "\n", "                ", "finished_cand", "=", "decoded_indices", "[", ":", ",", "source_idx", ",", "beam_indices", "[", "0", ",", "source_idx", ",", "j", "%", "k", "]", "]", ".", "flatten", "(", ")", "\n", "finished_cand_length", "=", "progress", "[", "source_idx", "]", "+", "1", "\n", "while", "len", "(", "finished_cand", ")", ">", "0", "and", "finished_cand", "[", "-", "1", "]", "==", "EOS_ID", ":", "\n", "                    ", "finished_cand", "=", "finished_cand", "[", ":", "-", "1", "]", "\n", "finished_cand_length", "-=", "1", "\n", "", "if", "len", "(", "finished_cand", ")", ">", "0", ":", "# avoid length 0", "\n", "                    ", "master_done_beams", "[", "selected_master_indices", "[", "source_idx", "]", "]", ".", "append", "(", "{", "'tokens'", ":", "finished_cand", ".", "cpu", "(", ")", ",", "'score'", ":", "(", "top_log_probs", ".", "flatten", "(", ")", "[", "j", "]", "/", "(", "(", "finished_cand_length", ")", "**", "len_penalty", ")", ")", ".", "item", "(", ")", "}", ")", "\n", "best_finished_log_probs", "[", "source_idx", "]", "=", "max", "(", "best_finished_log_probs", "[", "source_idx", "]", ",", "top_log_probs", ".", "flatten", "(", ")", "[", "j", "]", ")", "\n", "", "else", ":", "# rarely with greedy search (beam size k = 1) you get stuff with length 0... so avoid crashing but give it low score", "\n", "                    ", "master_done_beams", "[", "selected_master_indices", "[", "source_idx", "]", "]", ".", "append", "(", "{", "'tokens'", ":", "finished_cand", ".", "cpu", "(", ")", ",", "'score'", ":", "-", "1e8", "}", ")", "\n", "\n", "# then, shift log_probs and beam_indices for those beams and delete that beam(s); put in placeholder beam and log_prob at the k^th position", "\n", "# need to shift top_log_probs, beam_indices, vocab_indices accordingly", "\n", "", "", "", "top_log_probs", "=", "torch", ".", "cat", "(", "[", "top_log_probs", ",", "torch", ".", "zeros_like", "(", "top_log_probs", ")", ".", "to", "(", "parent_model", ".", "device", ")", "-", "1e8", "]", ",", "dim", "=", "2", ")", "# 1, batch, 2k", "\n", "shift_indices", "=", "newly_done", ".", "sum", "(", "dim", "=", "2", ")", ".", "unsqueeze", "(", "2", ")", "+", "torch", ".", "arange", "(", "k", ")", ".", "to", "(", "parent_model", ".", "device", ")", ".", "unsqueeze", "(", "0", ")", ".", "unsqueeze", "(", "1", ")", "# 1, batch, k", "\n", "top_log_probs", "=", "torch", ".", "gather", "(", "top_log_probs", ",", "2", ",", "shift_indices", ")", "\n", "shift_indices", "=", "shift_indices", ".", "clamp", "(", "max", "=", "k", "-", "1", ")", "\n", "beam_indices", "=", "torch", ".", "gather", "(", "beam_indices", ",", "2", ",", "shift_indices", ")", "\n", "vocab_indices", "=", "torch", ".", "gather", "(", "vocab_indices", ",", "2", ",", "shift_indices", ")", "\n", "newly_done_all", "=", "torch", ".", "gather", "(", "newly_done_all", ",", "2", ",", "shift_indices", ")", "\n", "\n", "log_probs", "=", "top_log_probs", ".", "squeeze", "(", "0", ")", "\n", "state_indices", "=", "(", "beam_indices", "+", "k", "*", "torch", ".", "arange", "(", "batch_size", ")", ".", "to", "(", "parent_model", ".", "device", ")", ".", "unsqueeze", "(", "1", ")", ".", "repeat", "(", "1", ",", "k", ")", ")", ".", "flatten", "(", ")", "\n", "reorder_idx", "=", "reorder_idx", "[", "state_indices", "]", "\n", "\n", "# update valid beam mask", "\n", "ap_thresholds", "=", "(", "torch", ".", "max", "(", "log_probs", "[", ":", ",", "0", "]", ",", "best_finished_log_probs", ")", "-", "ap", ")", ".", "unsqueeze", "(", "1", ")", "# batch x 1", "\n", "valid_beam_mask", "=", "(", "log_probs", ">", "ap_thresholds", ")", ".", "float", "(", ")", "# batch x k", "\n", "# update valid beam mask based on how many beams are left for each source", "\n", "done_mask", "=", "pad_mask", "(", "k", "-", "done_lengths", ",", "parent_model", ".", "device", ",", "max_seqlen", "=", "k", ")", ".", "permute", "(", "1", ",", "0", ")", "# batch x k of beams to keep, up to k - num done already", "\n", "all_low_prob_mask", "=", "1", "-", "valid_beam_mask", ".", "max", "(", "dim", "=", "1", ")", "[", "0", "]", "# NOTE since we filter out by the absolute threshold including previously finished beams, we could get < k finished candidates, but always at least 1", "\n", "found_z_mask", "=", "(", "all_low_prob_mask", ".", "bool", "(", ")", "|", "(", "done_lengths", ">=", "find_top_z", ")", ")", ".", "unsqueeze", "(", "1", ")", "\n", "valid_beam_mask", "=", "valid_beam_mask", "*", "done_mask", "*", "(", "1", "-", "found_z_mask", ".", "long", "(", ")", ")", "\n", "# filter the done ones out of all the master tensors", "\n", "keep_indices", "=", "(", "~", "found_z_mask", ")", ".", "flatten", "(", ")", ".", "nonzero", "(", ")", ".", "flatten", "(", ")", ".", "long", "(", ")", "\n", "remove_indices", "=", "(", "found_z_mask", ")", ".", "flatten", "(", ")", ".", "nonzero", "(", ")", ".", "flatten", "(", ")", ".", "long", "(", ")", "\n", "keep_indices", "=", "torch", ".", "cat", "(", "[", "selected_indices", "[", "keep_indices", "]", ",", "unselected_indices", "]", ",", "dim", "=", "0", ")", "\n", "master_remove_indices", "=", "master_index", "[", "selected_indices", "[", "remove_indices", "]", "]", "\n", "\n", "# update these quantities in their respective source_info objects after computing them", "\n", "# just deleting/concatenating to a single master tensor", "\n", "# master_decoded_indices seq x batch x k", "\n", "new_master_indices", "=", "torch", ".", "zeros", "(", "1", ",", "master_decoded_indices", ".", "size", "(", "1", ")", ",", "k", ")", ".", "long", "(", ")", ".", "to", "(", "parent_model", ".", "device", ")", "# 1 x batch x k", "\n", "new_master_indices", "[", ":", ",", "selected_indices", "]", "=", "vocab_indices", "\n", "master_decoded_indices", "[", ":", ",", "selected_indices", "]", "=", "torch", ".", "gather", "(", "master_decoded_indices", "[", ":", ",", "selected_indices", "]", ",", "2", ",", "beam_indices", ".", "expand", "(", "master_decoded_indices", "[", ":", ",", "selected_indices", "]", ".", "shape", ")", ")", "\n", "master_decoded_indices", "=", "torch", ".", "cat", "(", "[", "master_decoded_indices", ",", "new_master_indices", "]", ",", "dim", "=", "0", ")", "\n", "if", "prog_min", "+", "2", ">=", "master_decoded_indices", ".", "shape", "[", "0", "]", ":", "\n", "            ", "master_decoded_indices", "=", "torch", ".", "cat", "(", "[", "torch", ".", "zeros", "(", "1", ",", "master_decoded_indices", ".", "size", "(", "1", ")", ",", "k", ")", ".", "long", "(", ")", ".", "to", "(", "parent_model", ".", "device", ")", ",", "master_decoded_indices", "]", ",", "dim", "=", "0", ")", "\n", "", "master_decoded_indices", "[", ":", ",", "selected_indices", "]", "=", "torch", ".", "roll", "(", "master_decoded_indices", "[", ":", ",", "selected_indices", "]", ",", "-", "1", ",", "0", ")", "\n", "master_decoded_indices", "=", "master_decoded_indices", "[", ":", "-", "1", "]", "\n", "# master_log_probs batch x k", "\n", "master_log_probs", "[", "selected_indices", "]", "=", "log_probs", "\n", "# master_valid_beam_mask batch x k", "\n", "master_valid_beam_mask", "[", "selected_indices", "]", "=", "valid_beam_mask", "\n", "# master_num_valid_beams batch", "\n", "master_num_valid_beams", "=", "master_valid_beam_mask", ".", "sum", "(", "dim", "=", "1", ")", ".", "long", "(", ")", "\n", "# master_progress batch", "\n", "master_progress", "[", "selected_indices", "]", "+=", "1", "\n", "# master_end_found batch x k", "\n", "master_end_found", "[", "selected_indices", "]", "=", "(", "torch", ".", "gather", "(", "end_found", ".", "squeeze", "(", "3", ")", ",", "2", ",", "beam_indices", ")", "|", "newly_done_all", "[", "0", ",", ":", ",", ":", "]", ")", ".", "squeeze", "(", "0", ")", "\n", "# master_done_lengths batch", "\n", "master_done_lengths", "[", "selected_indices", "]", "=", "done_lengths", "\n", "# master_best_finished_log_probs batch", "\n", "master_best_finished_log_probs", "[", "selected_indices", "]", "=", "best_finished_log_probs", "\n", "# update master versions of sg.model state", "\n", "reorder_idx", "=", "reorder_idx", "[", "valid_beam_mask", ".", "flatten", "(", ")", ".", "nonzero", "(", ")", ".", "flatten", "(", ")", "]", "\n", "selected_state_master_indices", "=", "selected_state_master_indices", "[", "reorder_idx", "]", "\n", "reorder_incremental_state", "(", "sg", ".", "model", ",", "reorder_idx", ")", "\n", "\n", "master_src_lengths", "=", "master_src_lengths", "[", "keep_indices", "]", "\n", "\n", "if", "master_src_lengths", ".", "sum", "(", ")", "<=", "max_si_tokens", "-", "parent_model", ".", "args", ".", "max_tokens", ":", "\n", "            ", "reselect", "=", "True", "\n", "", "elif", "len", "(", "progress", ")", "<", "(", "master_progress", "==", "prog_min", "+", "1", ")", ".", "sum", "(", ")", ":", "\n", "            ", "reselect", "=", "True", "\n", "", "else", ":", "\n", "            ", "reselect", "=", "False", "\n", "", "if", "reselect", ":", "\n", "# if not one_batch:", "\n", "#     print('reselect', decode_calls)", "\n", "            ", "master_state", ".", "recache", "(", "selected_state_master_indices", ",", "sg", ".", "model", ".", "incremental_states", ")", "\n", "\n", "", "master_decoded_indices", "=", "master_decoded_indices", "[", ":", ",", "keep_indices", ",", ":", "]", "\n", "master_log_probs", "=", "master_log_probs", "[", "keep_indices", "]", "\n", "master_enc_out", "=", "sg", ".", "model", ".", "reorder_encoder_out", "(", "master_enc_out", ",", "keep_indices", ")", "\n", "master_valid_beam_mask", "=", "master_valid_beam_mask", "[", "keep_indices", "]", "\n", "master_num_valid_beams", "=", "master_num_valid_beams", "[", "keep_indices", "]", "\n", "master_index", "=", "master_index", "[", "keep_indices", "]", "\n", "master_progress", "=", "master_progress", "[", "keep_indices", "]", "\n", "master_end_found", "=", "master_end_found", "[", "keep_indices", "]", "\n", "master_done_lengths", "=", "master_done_lengths", "[", "keep_indices", "]", "\n", "master_best_finished_log_probs", "=", "master_best_finished_log_probs", "[", "keep_indices", "]", "\n", "\n", "# delete any unnecessary padding so we don't keep increasing padding", "\n", "num_pad", "=", "(", "master_decoded_indices", ".", "sum", "(", "dim", "=", "1", ")", ".", "sum", "(", "dim", "=", "1", ")", "==", "0", ")", ".", "sum", "(", "dim", "=", "0", ")", "\n", "if", "not", "reselect", ":", "\n", "            ", "assert", "num_pad", "==", "0", "\n", "\n", "", "", "assert", "all", "(", "[", "bid", "is", "not", "None", "for", "bid", "in", "master_batch_ids", "]", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "master_done_beams", ")", ")", ":", "\n", "        ", "master_done_beams", "[", "i", "]", "=", "sorted", "(", "master_done_beams", "[", "i", "]", ",", "key", "=", "lambda", "x", ":", "x", "[", "'score'", "]", ",", "reverse", "=", "True", ")", "\n", "", "if", "one_batch", ":", "\n", "        ", "return", "master_done_beams", ",", "decode_calls", ",", "n_expansions", "\n", "", "else", ":", "\n", "        ", "return", "master_batch_ids", ",", "master_done_beams", ",", "decode_calls", ",", "n_expansions", "", "", "", ""]], "home.repos.pwc.inspect_result.yangkevin2_emnlp2020-stream-beam-mt.None.greedy.predict_greedy": [[8, 56], ["len", "sg.model.forward_encoder", "sg.model.reorder_encoder_out", "torch.arange().to", "torch.arange().to", "torch.arange().to", "range", "torch.arange().to", "torch.arange().to", "torch.arange().to", "torch.zeros().long().to", "torch.zeros().long().to", "torch.zeros().long().to", "sg.model.forward_decoder", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "lprobs.max", "torch.cat", "torch.cat", "torch.cat", "end_found.long().nonzero().flatten", "sg.model.reorder_encoder_out", "sg.model.reorder_incremental_state", "torch.arange", "torch.arange", "torch.arange", "range", "preds[].append", "len", "torch.arange", "torch.arange", "torch.arange", "torch.zeros().long", "torch.zeros().long", "torch.zeros().long", "torch.cat.permute", "torch.tensor", "torch.tensor", "torch.tensor", "next_indices.unsqueeze", "end_found.long().nonzero", "torch.zeros", "torch.zeros", "torch.zeros", "end_found.long", "end_found.long"], "function", ["home.repos.pwc.inspect_result.yangkevin2_emnlp2020-stream-beam-mt.None.sequence_generator.EnsembleModel.forward_encoder", "home.repos.pwc.inspect_result.yangkevin2_emnlp2020-stream-beam-mt.None.sequence_generator.EnsembleModel.reorder_encoder_out", "home.repos.pwc.inspect_result.yangkevin2_emnlp2020-stream-beam-mt.None.sequence_generator.EnsembleModel.forward_decoder", "home.repos.pwc.inspect_result.yangkevin2_emnlp2020-stream-beam-mt.None.sequence_generator.EnsembleModel.reorder_encoder_out", "home.repos.pwc.inspect_result.yangkevin2_emnlp2020-stream-beam-mt.None.sequence_generator.EnsembleModel.reorder_incremental_state"], ["def", "predict_greedy", "(", "sg", ",", "model", ",", "batch", ",", "max_len", "=", "100", ",", "bos_token", "=", "None", ")", ":", "\n", "    ", "BOS_ID", "=", "sg", ".", "eos", "if", "bos_token", "is", "None", "else", "bos_token", "\n", "\n", "net_input", "=", "batch", "[", "\"net_input\"", "]", "\n", "src_tokens", "=", "net_input", "[", "\"src_tokens\"", "]", "\n", "batch_size", "=", "len", "(", "src_tokens", ")", "\n", "\n", "# encoder_output, encoder_mask, initial_hidden = model.encode(source)", "\n", "encoder_outs", "=", "sg", ".", "model", ".", "forward_encoder", "(", "net_input", ")", "\n", "encoder_outs", "=", "sg", ".", "model", ".", "reorder_encoder_out", "(", "encoder_outs", ",", "torch", ".", "arange", "(", "batch_size", ")", ".", "to", "(", "src_tokens", ")", ")", "\n", "decoded_indices", "=", "torch", ".", "zeros", "(", "1", ",", "batch_size", ")", ".", "long", "(", ")", ".", "to", "(", "src_tokens", ")", "+", "BOS_ID", "\n", "master_idx", "=", "torch", ".", "arange", "(", "batch_size", ")", ".", "to", "(", "src_tokens", ")", "\n", "\n", "preds", "=", "[", "[", "]", "for", "_", "in", "range", "(", "batch_size", ")", "]", "\n", "\n", "decode_calls", "=", "0", "\n", "for", "step", "in", "range", "(", "max_len", "+", "1", ")", ":", "\n", "        ", "decode_calls", "+=", "1", "\n", "lprobs", ",", "_", "=", "sg", ".", "model", ".", "forward_decoder", "(", "\n", "decoded_indices", ".", "permute", "(", "1", ",", "0", ")", "[", ":", ",", ":", "step", "+", "1", "]", ",", "encoder_outs", ",", "sg", ".", "temperature", "\n", ")", "\n", "lprobs", "[", "lprobs", "!=", "lprobs", "]", "=", "torch", ".", "tensor", "(", "-", "math", ".", "inf", ")", ".", "to", "(", "lprobs", ")", "\n", "lprobs", "[", ":", ",", "sg", ".", "pad", "]", "=", "-", "math", ".", "inf", "# never select pad", "\n", "lprobs", "[", ":", ",", "sg", ".", "unk", "]", "-=", "sg", ".", "unk_penalty", "# apply unk penalty", "\n", "if", "step", ">=", "max_len", ":", "\n", "            ", "lprobs", "[", ":", ",", ":", "sg", ".", "eos", "]", "=", "-", "math", ".", "inf", "\n", "lprobs", "[", ":", ",", "sg", ".", "eos", "+", "1", ":", "]", "=", "-", "math", ".", "inf", "\n", "", "if", "step", "<", "sg", ".", "min_len", ":", "\n", "# minimum length constraint (does not apply if using prefix_tokens)", "\n", "            ", "lprobs", "[", ":", ",", "sg", ".", "eos", "]", "=", "-", "math", ".", "inf", "\n", "\n", "# lprobs is batch*beam x vocab", "\n", "", "_", ",", "next_indices", "=", "lprobs", ".", "max", "(", "dim", "=", "1", ")", "\n", "decoded_indices", "=", "torch", ".", "cat", "(", "[", "decoded_indices", ",", "next_indices", ".", "unsqueeze", "(", "0", ")", "]", ",", "dim", "=", "0", ")", "\n", "\n", "end_found", "=", "(", "next_indices", "==", "sg", ".", "eos", ")", "\n", "for", "idx", "in", "(", "end_found", ".", "long", "(", ")", ")", ".", "nonzero", "(", ")", ".", "flatten", "(", ")", ":", "\n", "            ", "preds", "[", "master_idx", "[", "idx", "]", "]", ".", "append", "(", "{", "'tokens'", ":", "decoded_indices", "[", ":", ",", "idx", "]", "}", ")", "\n", "", "keep_idx", "=", "(", "1", "-", "end_found", ".", "long", "(", ")", ")", ".", "nonzero", "(", ")", ".", "flatten", "(", ")", "\n", "master_idx", "=", "master_idx", "[", "keep_idx", "]", "\n", "decoded_indices", "=", "decoded_indices", "[", ":", ",", "keep_idx", "]", "\n", "encoder_outs", "=", "sg", ".", "model", ".", "reorder_encoder_out", "(", "encoder_outs", ",", "keep_idx", ")", "\n", "sg", ".", "model", ".", "reorder_incremental_state", "(", "keep_idx", ")", "\n", "\n", "if", "len", "(", "master_idx", ")", "==", "0", ":", "\n", "            ", "break", "\n", "\n", "", "", "return", "preds", ",", "decode_calls", ",", "0", "", "", ""]], "home.repos.pwc.inspect_result.yangkevin2_emnlp2020-stream-beam-mt.None.old_sequence_generator.BeamSearch.__init__": [[29, 32], ["fairseq.search.Search.__init__"], "methods", ["home.repos.pwc.inspect_result.yangkevin2_emnlp2020-stream-beam-mt.None.sequence_generator.BeamContainer.__init__"], ["    ", "def", "__init__", "(", "self", ",", "tgt_dict", ",", "mc", "=", "None", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "tgt_dict", ")", "\n", "self", ".", "mc", "=", "mc", "\n", "\n"]], "home.repos.pwc.inspect_result.yangkevin2_emnlp2020-stream-beam-mt.None.old_sequence_generator.BeamSearch.step": [[33, 65], ["lprobs[].contiguous.size", "torch.topk", "torch.topk", "torch.topk", "torch.topk", "torch.div", "torch.div", "torch.div", "torch.div", "indices_buf.fmod.fmod.fmod", "lprobs[].contiguous", "lprobs[].contiguous.topk", "masked_lprobs.scatter_", "lprobs[].contiguous.view", "scores[].unsqueeze", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "min", "lprobs[].contiguous.view().size", "lprobs[].contiguous.view"], "methods", ["None"], ["", "@", "torch", ".", "jit", ".", "export", "\n", "def", "step", "(", "self", ",", "step", ":", "int", ",", "lprobs", ",", "scores", ":", "Optional", "[", "Tensor", "]", ")", ":", "\n", "        ", "bsz", ",", "beam_size", ",", "vocab_size", "=", "lprobs", ".", "size", "(", ")", "\n", "\n", "if", "step", "==", "0", ":", "\n", "# at the first step all hypotheses are equally likely, so use", "\n", "# only the first beam", "\n", "            ", "lprobs", "=", "lprobs", "[", ":", ",", ":", ":", "beam_size", ",", ":", "]", ".", "contiguous", "(", ")", "\n", "", "else", ":", "\n", "# make probs contain cumulative scores for each hypothesis", "\n", "            ", "assert", "scores", "is", "not", "None", "\n", "lprobs", "=", "lprobs", "+", "scores", "[", ":", ",", ":", ",", "step", "-", "1", "]", ".", "unsqueeze", "(", "-", "1", ")", "\n", "", "if", "self", ".", "mc", "is", "not", "None", ":", "\n", "            ", "masked_lprobs", "=", "torch", ".", "zeros_like", "(", "lprobs", ")", "-", "math", ".", "inf", "\n", "keep_lprobs", ",", "keep_idx", "=", "lprobs", ".", "topk", "(", "self", ".", "mc", ",", "dim", "=", "2", ")", "\n", "masked_lprobs", ".", "scatter_", "(", "2", ",", "keep_idx", ",", "keep_lprobs", ")", "\n", "lprobs", "=", "masked_lprobs", "\n", "\n", "", "top_prediction", "=", "torch", ".", "topk", "(", "\n", "lprobs", ".", "view", "(", "bsz", ",", "-", "1", ")", ",", "\n", "k", "=", "min", "(", "\n", "# Take the best 2 x beam_size predictions. We'll choose the first", "\n", "# beam_size of these which don't predict eos to continue with.", "\n", "beam_size", "*", "2", ",", "\n", "lprobs", ".", "view", "(", "bsz", ",", "-", "1", ")", ".", "size", "(", "1", ")", "-", "1", ",", "# -1 so we never select pad", "\n", ")", ",", "\n", ")", "\n", "scores_buf", "=", "top_prediction", "[", "0", "]", "\n", "indices_buf", "=", "top_prediction", "[", "1", "]", "\n", "beams_buf", "=", "torch", ".", "div", "(", "indices_buf", ",", "vocab_size", ")", "\n", "indices_buf", "=", "indices_buf", ".", "fmod", "(", "vocab_size", ")", "\n", "return", "scores_buf", ",", "indices_buf", ",", "beams_buf", "\n", "\n"]], "home.repos.pwc.inspect_result.yangkevin2_emnlp2020-stream-beam-mt.None.old_sequence_generator.SequenceGenerator.__init__": [[154, 226], ["torch.Module.__init__", "isinstance", "tgt_dict.pad", "tgt_dict.unk", "len", "min", "old_sequence_generator.EnsembleModel", "tgt_dict.eos", "fairseq.search.BeamSearch", "old_sequence_generator.SequenceGenerator.model.eval"], "methods", ["home.repos.pwc.inspect_result.yangkevin2_emnlp2020-stream-beam-mt.None.sequence_generator.BeamContainer.__init__"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "models", ",", "\n", "tgt_dict", ",", "\n", "beam_size", "=", "1", ",", "\n", "max_len_a", "=", "0", ",", "\n", "max_len_b", "=", "200", ",", "\n", "min_len", "=", "1", ",", "\n", "normalize_scores", "=", "True", ",", "\n", "len_penalty", "=", "1.0", ",", "\n", "unk_penalty", "=", "0.0", ",", "\n", "retain_dropout", "=", "False", ",", "\n", "temperature", "=", "1.0", ",", "\n", "match_source_len", "=", "False", ",", "\n", "no_repeat_ngram_size", "=", "0", ",", "\n", "search_strategy", "=", "None", ",", "\n", "eos", "=", "None", ",", "\n", ")", ":", "\n", "        ", "\"\"\"Generates translations of a given source sentence.\n\n        Args:\n            models (List[~fairseq.models.FairseqModel]): ensemble of models,\n                currently support fairseq.models.TransformerModel for scripting\n            beam_size (int, optional): beam width (default: 1)\n            max_len_a/b (int, optional): generate sequences of maximum length\n                ax + b, where x is the source length\n            min_len (int, optional): the minimum length of the generated output\n                (not including end-of-sentence)\n            normalize_scores (bool, optional): normalize scores by the length\n                of the output (default: True)\n            len_penalty (float, optional): length penalty, where <1.0 favors\n                shorter, >1.0 favors longer sentences (default: 1.0)\n            unk_penalty (float, optional): unknown word penalty, where <0\n                produces more unks, >0 produces fewer (default: 0.0)\n            retain_dropout (bool, optional): use dropout when generating\n                (default: False)\n            temperature (float, optional): temperature, where values\n                >1.0 produce more uniform samples and values <1.0 produce\n                sharper samples (default: 1.0)\n            match_source_len (bool, optional): outputs should match the source\n                length (default: False)\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "if", "isinstance", "(", "models", ",", "EnsembleModel", ")", ":", "\n", "            ", "self", ".", "model", "=", "models", "\n", "", "else", ":", "\n", "            ", "self", ".", "model", "=", "EnsembleModel", "(", "models", ")", "\n", "", "self", ".", "pad", "=", "tgt_dict", ".", "pad", "(", ")", "\n", "self", ".", "unk", "=", "tgt_dict", ".", "unk", "(", ")", "\n", "self", ".", "eos", "=", "tgt_dict", ".", "eos", "(", ")", "if", "eos", "is", "None", "else", "eos", "\n", "self", ".", "vocab_size", "=", "len", "(", "tgt_dict", ")", "\n", "self", ".", "beam_size", "=", "beam_size", "\n", "# the max beam size is the dictionary size - 1, since we never select pad", "\n", "self", ".", "beam_size", "=", "min", "(", "beam_size", ",", "self", ".", "vocab_size", "-", "1", ")", "\n", "self", ".", "max_len_a", "=", "max_len_a", "\n", "self", ".", "max_len_b", "=", "max_len_b", "\n", "self", ".", "min_len", "=", "min_len", "\n", "\n", "self", ".", "normalize_scores", "=", "normalize_scores", "\n", "self", ".", "len_penalty", "=", "len_penalty", "\n", "self", ".", "unk_penalty", "=", "unk_penalty", "\n", "self", ".", "retain_dropout", "=", "retain_dropout", "\n", "self", ".", "temperature", "=", "temperature", "\n", "self", ".", "match_source_len", "=", "match_source_len", "\n", "self", ".", "no_repeat_ngram_size", "=", "no_repeat_ngram_size", "\n", "assert", "temperature", ">", "0", ",", "\"--temperature must be greater than 0\"", "\n", "\n", "self", ".", "search", "=", "(", "\n", "search", ".", "BeamSearch", "(", "tgt_dict", ")", "if", "search_strategy", "is", "None", "else", "search_strategy", "\n", ")", "\n", "if", "not", "self", ".", "retain_dropout", ":", "\n", "            ", "self", ".", "model", ".", "eval", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yangkevin2_emnlp2020-stream-beam-mt.None.old_sequence_generator.SequenceGenerator.cuda": [[227, 230], ["old_sequence_generator.SequenceGenerator.model.cuda"], "methods", ["home.repos.pwc.inspect_result.yangkevin2_emnlp2020-stream-beam-mt.None.sequence_generator.SequenceGenerator.cuda"], ["", "", "def", "cuda", "(", "self", ")", ":", "\n", "        ", "self", ".", "model", ".", "cuda", "(", ")", "\n", "return", "self", "\n", "\n"]], "home.repos.pwc.inspect_result.yangkevin2_emnlp2020-stream-beam-mt.None.old_sequence_generator.SequenceGenerator.forward": [[231, 249], ["torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "old_sequence_generator.SequenceGenerator.model.reset_incremental_state", "old_sequence_generator.SequenceGenerator._generate"], "methods", ["home.repos.pwc.inspect_result.yangkevin2_emnlp2020-stream-beam-mt.None.sequence_generator.EnsembleModel.reset_incremental_state", "home.repos.pwc.inspect_result.yangkevin2_emnlp2020-stream-beam-mt.None.sequence_generator.SequenceGenerator._generate"], ["", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "forward", "(", "\n", "self", ",", "\n", "sample", ":", "Dict", "[", "str", ",", "Dict", "[", "str", ",", "Tensor", "]", "]", ",", "\n", "prefix_tokens", ":", "Optional", "[", "Tensor", "]", "=", "None", ",", "\n", "bos_token", ":", "Optional", "[", "int", "]", "=", "None", ",", "\n", ")", ":", "\n", "        ", "\"\"\"Generate a batch of translations.\n\n        Args:\n            sample (dict): batch\n            prefix_tokens (torch.LongTensor, optional): force decoder to begin\n                with these tokens\n            bos_token (int, optional): beginning of sentence token\n                (default: self.eos)\n        \"\"\"", "\n", "self", ".", "model", ".", "reset_incremental_state", "(", ")", "\n", "return", "self", ".", "_generate", "(", "sample", ",", "prefix_tokens", ",", "bos_token", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yangkevin2_emnlp2020-stream-beam-mt.None.old_sequence_generator.SequenceGenerator.generate_batched_itr": [[251, 282], ["enumerate", "fairseq.utils.move_to_cuda", "timer.start", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "old_sequence_generator.SequenceGenerator.generate", "timer.stop", "fairseq.utils.strip_pad", "input.items", "sum", "fairseq.utils.strip_pad", "len"], "methods", ["home.repos.pwc.inspect_result.yangkevin2_emnlp2020-stream-beam-mt.None.sequence_generator.SequenceGeneratorWithAlignment.generate"], ["", "def", "generate_batched_itr", "(", "self", ",", "data_itr", ",", "beam_size", "=", "None", ",", "cuda", "=", "False", ",", "timer", "=", "None", ")", ":", "\n", "        ", "\"\"\"Iterate over a batched dataset and yield individual translations.\n        Args:\n            cuda (bool, optional): use GPU for generation\n            timer (StopwatchMeter, optional): time generations\n        \"\"\"", "\n", "for", "sample", "in", "data_itr", ":", "\n", "            ", "s", "=", "utils", ".", "move_to_cuda", "(", "sample", ")", "if", "cuda", "else", "sample", "\n", "if", "\"net_input\"", "not", "in", "s", ":", "\n", "                ", "continue", "\n", "", "input", "=", "s", "[", "\"net_input\"", "]", "\n", "# model.forward normally channels prev_output_tokens into the decoder", "\n", "# separately, but SequenceGenerator directly calls model.encoder", "\n", "encoder_input", "=", "{", "\n", "k", ":", "v", "for", "k", ",", "v", "in", "input", ".", "items", "(", ")", "if", "k", "!=", "\"prev_output_tokens\"", "\n", "}", "\n", "if", "timer", "is", "not", "None", ":", "\n", "                ", "timer", ".", "start", "(", ")", "\n", "", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "hypos", "=", "self", ".", "generate", "(", "encoder_input", ")", "\n", "", "if", "timer", "is", "not", "None", ":", "\n", "                ", "timer", ".", "stop", "(", "sum", "(", "len", "(", "h", "[", "0", "]", "[", "\"tokens\"", "]", ")", "for", "h", "in", "hypos", ")", ")", "\n", "", "for", "i", ",", "id", "in", "enumerate", "(", "s", "[", "\"id\"", "]", ".", "data", ")", ":", "\n", "# remove padding", "\n", "                ", "src", "=", "utils", ".", "strip_pad", "(", "input", "[", "\"src_tokens\"", "]", ".", "data", "[", "i", ",", ":", "]", ",", "self", ".", "pad", ")", "\n", "ref", "=", "(", "\n", "utils", ".", "strip_pad", "(", "s", "[", "\"target\"", "]", ".", "data", "[", "i", ",", ":", "]", ",", "self", ".", "pad", ")", "\n", "if", "s", "[", "\"target\"", "]", "is", "not", "None", "\n", "else", "None", "\n", ")", "\n", "yield", "id", ",", "src", ",", "ref", ",", "hypos", "[", "i", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.yangkevin2_emnlp2020-stream-beam-mt.None.old_sequence_generator.SequenceGenerator.generate": [[283, 297], ["torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "old_sequence_generator.SequenceGenerator.model.reset_incremental_state", "old_sequence_generator.SequenceGenerator._generate"], "methods", ["home.repos.pwc.inspect_result.yangkevin2_emnlp2020-stream-beam-mt.None.sequence_generator.EnsembleModel.reset_incremental_state", "home.repos.pwc.inspect_result.yangkevin2_emnlp2020-stream-beam-mt.None.sequence_generator.SequenceGenerator._generate"], ["", "", "", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "generate", "(", "self", ",", "models", ",", "sample", ":", "Dict", "[", "str", ",", "Dict", "[", "str", ",", "Tensor", "]", "]", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"Generate translations. Match the api of other fairseq generators.\n\n        Args:\n            models (List[~fairseq.models.FairseqModel]): ensemble of models\n            sample (dict): batch\n            prefix_tokens (torch.LongTensor, optional): force decoder to begin\n                with these tokens\n            bos_token (int, optional): beginning of sentence token\n                (default: self.eos)\n        \"\"\"", "\n", "self", ".", "model", ".", "reset_incremental_state", "(", ")", "\n", "return", "self", ".", "_generate", "(", "sample", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yangkevin2_emnlp2020-stream-beam-mt.None.old_sequence_generator.SequenceGenerator._generate": [[298, 585], ["src_tokens.size", "old_sequence_generator.SequenceGenerator.model.forward_encoder", "torch.arange().view().repeat().view", "torch.arange().view().repeat().view", "torch.arange().view().repeat().view", "torch.arange().view().repeat().view", "new_order.to().long.to().long.to().long", "old_sequence_generator.SequenceGenerator.model.reorder_encoder_out", "torch.zeros().to().float", "torch.zeros().to().float", "torch.zeros().to().float", "torch.zeros().to().float", "torch.zeros().to().long().fill_", "torch.zeros().to().long().fill_", "torch.zeros().to().long().fill_", "torch.zeros().to().long().fill_", "torch.zeros().to().eq", "torch.zeros().to().eq", "torch.zeros().to().eq", "torch.zeros().to().eq", "torch.jit.annotate", "torch.jit.annotate", "torch.jit.annotate", "torch.jit.annotate", "torch.arange().type_as", "torch.arange().type_as", "torch.arange().type_as", "torch.arange().type_as", "range", "range", "src_lengths.max().item", "min", "old_sequence_generator.SequenceGenerator.model.forward_decoder", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "[].view.type_as", "torch.empty().to", "torch.empty().to", "torch.empty().to", "torch.empty().to", "torch.empty().to", "torch.empty().to", "torch.empty().to", "torch.empty().to", "old_sequence_generator.SequenceGenerator.search.set_src_lengths", "old_sequence_generator.SequenceGenerator.search.step", "cand_beams.add", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.masked_select", "torch.masked_select", "torch.masked_select", "torch.masked_select", "torch.add", "torch.add", "torch.add", "torch.add", "torch.topk", "torch.topk", "torch.topk", "torch.topk", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "active_bbsz_idx.view.view.view", "active_scores.view.view.view", "torch.index_select", "torch.index_select", "torch.index_select", "torch.index_select", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "len", "BCList.sort", "BCList.reverse", "torch.jit.annotate", "torch.jit.annotate", "torch.jit.annotate", "torch.jit.annotate", "int", "torch.arange().view().repeat", "torch.arange().view().repeat", "torch.arange().view().repeat", "torch.arange().view().repeat", "new_order.to().long.to().long.to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to().long", "torch.zeros().to().long", "torch.zeros().to().long", "torch.zeros().to().long", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.jit.annotate", "torch.jit.annotate", "torch.jit.annotate", "torch.jit.annotate", "range", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "old_sequence_generator.SequenceGenerator.model.reorder_incremental_state", "old_sequence_generator.SequenceGenerator.model.reorder_encoder_out", "old_sequence_generator.SequenceGenerator._prefix_tokens", "attn[].copy_", "old_sequence_generator.SequenceGenerator._no_repeat_ngram", "old_sequence_generator.SequenceGenerator.view", "cand_indices.eq", "cand_scores.ne", "torch.masked_select.numel", "torch.masked_select.numel", "torch.masked_select", "torch.masked_select", "torch.masked_select", "torch.masked_select", "old_sequence_generator.SequenceGenerator.finalize_hypos", "len", "len", "torch.ones().to", "torch.ones().to", "torch.ones().to", "torch.ones().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.ones().to.nonzero().squeeze", "torch.ones().to.nonzero().squeeze", "bbsz_offsets.resize_", "cand_beams.add", "[].view", "[].view", "new_blacklist.ge", "[].view.view", "torch.index_select", "torch.index_select", "torch.index_select", "torch.index_select", "[].view.view", "torch.index_select", "torch.index_select", "torch.index_select", "torch.index_select", "old_sequence_generator.BeamContainer", "src_lengths.max", "old_sequence_generator.SequenceGenerator.model.max_decoder_positions", "range", "reorder_state.view().add_", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "prefix_tokens.size", "torch.empty().to", "torch.empty().to", "torch.empty().to", "torch.empty().to", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "[].view.view", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "len", "[].view", "eos_mask.type_as", "elem[].item", "torch.arange().view", "torch.arange().view", "torch.arange().view", "torch.arange().view", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.arange().type_as", "torch.arange().type_as", "torch.arange().type_as", "torch.arange().type_as", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.ones().to.nonzero", "torch.ones().to.nonzero", "[].view.size", "eos_mask.size", "src_tokens.ne", "src_tokens.ne", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "reorder_state.view", "corr.unsqueeze", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "[].view.view", "[].view.view", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "avg_attn_scores.size", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "[].view.view", "torch.ones().to.nonzero().squeeze.numel"], "methods", ["home.repos.pwc.inspect_result.yangkevin2_emnlp2020-stream-beam-mt.None.sequence_generator.EnsembleModel.forward_encoder", "home.repos.pwc.inspect_result.yangkevin2_emnlp2020-stream-beam-mt.None.sequence_generator.EnsembleModel.reorder_encoder_out", "home.repos.pwc.inspect_result.yangkevin2_emnlp2020-stream-beam-mt.None.sequence_generator.EnsembleModel.forward_decoder", "home.repos.pwc.inspect_result.yangkevin2_emnlp2020-stream-beam-mt.None.sequence_generator.BeamSearch.step", "home.repos.pwc.inspect_result.yangkevin2_emnlp2020-stream-beam-mt.None.sequence_generator.EnsembleModel.reorder_incremental_state", "home.repos.pwc.inspect_result.yangkevin2_emnlp2020-stream-beam-mt.None.sequence_generator.EnsembleModel.reorder_encoder_out", "home.repos.pwc.inspect_result.yangkevin2_emnlp2020-stream-beam-mt.None.sequence_generator.SequenceGenerator._prefix_tokens", "home.repos.pwc.inspect_result.yangkevin2_emnlp2020-stream-beam-mt.None.sequence_generator.SequenceGenerator._no_repeat_ngram", "home.repos.pwc.inspect_result.yangkevin2_emnlp2020-stream-beam-mt.None.sequence_generator.SequenceGenerator.finalize_hypos", "home.repos.pwc.inspect_result.yangkevin2_emnlp2020-stream-beam-mt.None.sequence_generator.EnsembleModel.max_decoder_positions"], ["", "def", "_generate", "(", "\n", "self", ",", "\n", "sample", ":", "Dict", "[", "str", ",", "Dict", "[", "str", ",", "Tensor", "]", "]", ",", "\n", "prefix_tokens", ":", "Optional", "[", "Tensor", "]", "=", "None", ",", "\n", "bos_token", ":", "Optional", "[", "int", "]", "=", "None", ",", "\n", "ap", "=", "1e8", "\n", ")", ":", "\n", "        ", "net_input", "=", "sample", "[", "\"net_input\"", "]", "\n", "src_tokens", "=", "net_input", "[", "\"src_tokens\"", "]", "\n", "# length of the source text being the character length except EndOfSentence and pad", "\n", "src_lengths", "=", "(", "\n", "(", "src_tokens", ".", "ne", "(", "self", ".", "eos", ")", "&", "src_tokens", ".", "ne", "(", "self", ".", "pad", ")", ")", ".", "long", "(", ")", ".", "sum", "(", "dim", "=", "1", ")", "\n", ")", "\n", "# bsz: total number of sentences in beam", "\n", "input_size", "=", "src_tokens", ".", "size", "(", ")", "\n", "bsz", ",", "src_len", "=", "input_size", "[", "0", "]", ",", "input_size", "[", "1", "]", "\n", "beam_size", "=", "self", ".", "beam_size", "\n", "\n", "max_len", ":", "int", "=", "-", "1", "\n", "if", "self", ".", "match_source_len", ":", "\n", "            ", "max_len", "=", "src_lengths", ".", "max", "(", ")", ".", "item", "(", ")", "\n", "", "else", ":", "\n", "            ", "max_len", "=", "min", "(", "\n", "int", "(", "self", ".", "max_len_a", "*", "src_len", "+", "self", ".", "max_len_b", ")", ",", "\n", "# exclude the EOS marker", "\n", "self", ".", "model", ".", "max_decoder_positions", "(", ")", "-", "1", ",", "\n", ")", "\n", "", "assert", "(", "\n", "self", ".", "min_len", "<=", "max_len", "\n", ")", ",", "\"min_len cannot be larger than max_len, please adjust these!\"", "\n", "# compute the encoder output for each beam", "\n", "encoder_outs", "=", "self", ".", "model", ".", "forward_encoder", "(", "net_input", ")", "\n", "\n", "# placeholder of indices for bsz * beam_size to hold tokens and accumulative scores", "\n", "new_order", "=", "torch", ".", "arange", "(", "bsz", ")", ".", "view", "(", "-", "1", ",", "1", ")", ".", "repeat", "(", "1", ",", "beam_size", ")", ".", "view", "(", "-", "1", ")", "\n", "new_order", "=", "new_order", ".", "to", "(", "src_tokens", ".", "device", ")", ".", "long", "(", ")", "\n", "encoder_outs", "=", "self", ".", "model", ".", "reorder_encoder_out", "(", "encoder_outs", ",", "new_order", ")", "\n", "# ensure encoder_outs is a List.", "\n", "assert", "encoder_outs", "is", "not", "None", "\n", "\n", "# initialize buffers", "\n", "scores", "=", "(", "\n", "torch", ".", "zeros", "(", "bsz", "*", "beam_size", ",", "max_len", "+", "1", ")", ".", "to", "(", "src_tokens", ")", ".", "float", "(", ")", "\n", ")", "# +1 for eos; pad is never choosed for scoring", "\n", "tokens", "=", "(", "\n", "torch", ".", "zeros", "(", "bsz", "*", "beam_size", ",", "max_len", "+", "2", ")", "\n", ".", "to", "(", "src_tokens", ")", "\n", ".", "long", "(", ")", "\n", ".", "fill_", "(", "self", ".", "pad", ")", "\n", ")", "# +2 for eos and pad", "\n", "tokens", "[", ":", ",", "0", "]", "=", "self", ".", "eos", "if", "bos_token", "is", "None", "else", "bos_token", "\n", "attn", ":", "Optional", "[", "Tensor", "]", "=", "None", "\n", "\n", "# The blacklist indicates candidates that should be ignored.", "\n", "# For example, suppose we're sampling and have already finalized 2/5", "\n", "# samples. Then the blacklist would mark 2 positions as being ignored,", "\n", "# so that we only finalize the remaining 3 samples.", "\n", "blacklist", "=", "(", "\n", "torch", ".", "zeros", "(", "bsz", ",", "beam_size", ")", ".", "to", "(", "src_tokens", ")", ".", "eq", "(", "-", "1", ")", "\n", ")", "# forward and backward-compatible False mask", "\n", "\n", "# list of completed sentences", "\n", "finalized", "=", "torch", ".", "jit", ".", "annotate", "(", "\n", "List", "[", "List", "[", "Dict", "[", "str", ",", "Tensor", "]", "]", "]", ",", "\n", "[", "torch", ".", "jit", ".", "annotate", "(", "List", "[", "Dict", "[", "str", ",", "Tensor", "]", "]", ",", "[", "]", ")", "for", "i", "in", "range", "(", "bsz", ")", "]", ",", "\n", ")", "# contains lists of dictionaries of infomation about the hypothesis being finalized at each step", "\n", "\n", "finished", "=", "[", "\n", "False", "for", "i", "in", "range", "(", "bsz", ")", "\n", "]", "# a boolean array indicating if the sentence at the index is finished or not", "\n", "num_remaining_sent", "=", "bsz", "# number of sentences remaining", "\n", "\n", "# number of candidate hypos per step", "\n", "cand_size", "=", "2", "*", "beam_size", "# 2 x beam size in case half are EOS", "\n", "\n", "# offset arrays for converting between different indexing schemes", "\n", "bbsz_offsets", "=", "(", "torch", ".", "arange", "(", "0", ",", "bsz", ")", "*", "beam_size", ")", ".", "unsqueeze", "(", "1", ")", ".", "type_as", "(", "tokens", ")", "\n", "cand_offsets", "=", "torch", ".", "arange", "(", "0", ",", "cand_size", ")", ".", "type_as", "(", "tokens", ")", "\n", "\n", "reorder_state", ":", "Optional", "[", "Tensor", "]", "=", "None", "\n", "batch_idxs", ":", "Optional", "[", "Tensor", "]", "=", "None", "\n", "num_expansions", "=", "0", "\n", "for", "step", "in", "range", "(", "max_len", "+", "1", ")", ":", "# one extra step for EOS marker", "\n", "# reorder decoder internal states based on the prev choice of beams", "\n", "# print(f'step: {step}')", "\n", "            ", "if", "reorder_state", "is", "not", "None", ":", "\n", "                ", "if", "batch_idxs", "is", "not", "None", ":", "\n", "# update beam indices to take into account removed sentences", "\n", "                    ", "corr", "=", "batch_idxs", "-", "torch", ".", "arange", "(", "batch_idxs", ".", "numel", "(", ")", ")", ".", "type_as", "(", "\n", "batch_idxs", "\n", ")", "\n", "reorder_state", ".", "view", "(", "-", "1", ",", "beam_size", ")", ".", "add_", "(", "\n", "corr", ".", "unsqueeze", "(", "-", "1", ")", "*", "beam_size", "\n", ")", "\n", "", "self", ".", "model", ".", "reorder_incremental_state", "(", "reorder_state", ")", "\n", "encoder_outs", "=", "self", ".", "model", ".", "reorder_encoder_out", "(", "\n", "encoder_outs", ",", "reorder_state", "\n", ")", "\n", "\n", "", "lprobs", ",", "avg_attn_scores", "=", "self", ".", "model", ".", "forward_decoder", "(", "\n", "tokens", "[", ":", ",", ":", "step", "+", "1", "]", ",", "encoder_outs", ",", "self", ".", "temperature", "\n", ")", "\n", "num_expansions", "+=", "lprobs", ".", "shape", "[", "0", "]", "\n", "lprobs", "[", "lprobs", "!=", "lprobs", "]", "=", "torch", ".", "tensor", "(", "-", "math", ".", "inf", ")", ".", "to", "(", "lprobs", ")", "\n", "\n", "lprobs", "[", ":", ",", "self", ".", "pad", "]", "=", "-", "math", ".", "inf", "# never select pad", "\n", "lprobs", "[", ":", ",", "self", ".", "unk", "]", "-=", "self", ".", "unk_penalty", "# apply unk penalty", "\n", "\n", "# handle max length constraint", "\n", "if", "step", ">=", "max_len", ":", "\n", "                ", "lprobs", "[", ":", ",", ":", "self", ".", "eos", "]", "=", "-", "math", ".", "inf", "\n", "lprobs", "[", ":", ",", "self", ".", "eos", "+", "1", ":", "]", "=", "-", "math", ".", "inf", "\n", "\n", "# handle prefix tokens (possibly with different lengths)", "\n", "", "if", "(", "\n", "prefix_tokens", "is", "not", "None", "\n", "and", "step", "<", "prefix_tokens", ".", "size", "(", "1", ")", "\n", "and", "step", "<", "max_len", "\n", ")", ":", "\n", "                ", "lprobs", ",", "tokens", ",", "scores", "=", "self", ".", "_prefix_tokens", "(", "\n", "step", ",", "lprobs", ",", "scores", ",", "tokens", ",", "prefix_tokens", ",", "beam_size", "\n", ")", "\n", "", "elif", "step", "<", "self", ".", "min_len", ":", "\n", "# minimum length constraint (does not apply if using prefix_tokens)", "\n", "                ", "lprobs", "[", ":", ",", "self", ".", "eos", "]", "=", "-", "math", ".", "inf", "\n", "\n", "# Record attention scores, only support avg_attn_scores is a Tensor", "\n", "", "if", "avg_attn_scores", "is", "not", "None", ":", "\n", "                ", "if", "attn", "is", "None", ":", "\n", "                    ", "attn", "=", "torch", ".", "empty", "(", "\n", "bsz", "*", "beam_size", ",", "avg_attn_scores", ".", "size", "(", "1", ")", ",", "max_len", "+", "2", "\n", ")", ".", "to", "(", "scores", ")", "\n", "", "attn", "[", ":", ",", ":", ",", "step", "+", "1", "]", ".", "copy_", "(", "avg_attn_scores", ")", "\n", "\n", "", "scores", "=", "scores", ".", "type_as", "(", "lprobs", ")", "\n", "eos_bbsz_idx", "=", "torch", ".", "empty", "(", "0", ")", ".", "to", "(", "\n", "tokens", "\n", ")", "# indices of hypothesis ending with eos (finished sentences)", "\n", "eos_scores", "=", "torch", ".", "empty", "(", "0", ")", ".", "to", "(", "\n", "scores", "\n", ")", "# scores of hypothesis ending with eos (finished sentences)", "\n", "\n", "self", ".", "search", ".", "set_src_lengths", "(", "src_lengths", ")", "\n", "\n", "if", "self", ".", "no_repeat_ngram_size", ">", "0", ":", "\n", "                ", "lprobs", "=", "self", ".", "_no_repeat_ngram", "(", "tokens", ",", "lprobs", ",", "bsz", ",", "beam_size", ",", "step", ")", "\n", "\n", "", "cand_scores", ",", "cand_indices", ",", "cand_beams", "=", "self", ".", "search", ".", "step", "(", "\n", "step", ",", "\n", "lprobs", ".", "view", "(", "bsz", ",", "-", "1", ",", "self", ".", "vocab_size", ")", ",", "\n", "scores", ".", "view", "(", "bsz", ",", "beam_size", ",", "-", "1", ")", "[", ":", ",", ":", ",", ":", "step", "]", ",", "\n", ")", "\n", "\n", "# cand_bbsz_idx contains beam indices for the top candidate", "\n", "# hypotheses, with a range of values: [0, bsz*beam_size),", "\n", "# and dimensions: [bsz, cand_size]", "\n", "cand_bbsz_idx", "=", "cand_beams", ".", "add", "(", "bbsz_offsets", ")", "\n", "\n", "# finalize hypotheses that end in eos", "\n", "eos_mask", "=", "cand_indices", ".", "eq", "(", "self", ".", "eos", ")", "&", "cand_scores", ".", "ne", "(", "-", "math", ".", "inf", ")", "\n", "eos_mask", "[", ":", ",", ":", "beam_size", "]", "[", "blacklist", "]", "=", "torch", ".", "tensor", "(", "0", ")", ".", "to", "(", "eos_mask", ")", "\n", "\n", "# only consider eos when it's among the top beam_size indices", "\n", "eos_bbsz_idx", "=", "torch", ".", "masked_select", "(", "\n", "cand_bbsz_idx", "[", ":", ",", ":", "beam_size", "]", ",", "mask", "=", "eos_mask", "[", ":", ",", ":", "beam_size", "]", "\n", ")", "\n", "\n", "finalized_sents", ":", "List", "[", "int", "]", "=", "[", "]", "\n", "if", "eos_bbsz_idx", ".", "numel", "(", ")", ">", "0", ":", "\n", "                ", "eos_scores", "=", "torch", ".", "masked_select", "(", "\n", "cand_scores", "[", ":", ",", ":", "beam_size", "]", ",", "mask", "=", "eos_mask", "[", ":", ",", ":", "beam_size", "]", "\n", ")", "\n", "finalized_sents", "=", "self", ".", "finalize_hypos", "(", "\n", "step", ",", "\n", "eos_bbsz_idx", ",", "\n", "eos_scores", ",", "\n", "tokens", ",", "\n", "scores", ",", "\n", "finalized", ",", "\n", "finished", ",", "\n", "beam_size", ",", "\n", "attn", ",", "\n", "src_lengths", ",", "\n", "max_len", ",", "\n", ")", "\n", "num_remaining_sent", "-=", "len", "(", "finalized_sents", ")", "\n", "\n", "", "assert", "num_remaining_sent", ">=", "0", "\n", "if", "num_remaining_sent", "==", "0", ":", "\n", "                ", "break", "\n", "", "assert", "step", "<", "max_len", "\n", "\n", "if", "len", "(", "finalized_sents", ")", ">", "0", ":", "\n", "                ", "new_bsz", "=", "bsz", "-", "len", "(", "finalized_sents", ")", "\n", "\n", "# construct batch_idxs which holds indices of batches to keep for the next pass", "\n", "batch_mask", "=", "torch", ".", "ones", "(", "bsz", ")", ".", "to", "(", "cand_indices", ")", "\n", "batch_mask", "[", "\n", "torch", ".", "tensor", "(", "finalized_sents", ")", ".", "to", "(", "cand_indices", ")", "\n", "]", "=", "torch", ".", "tensor", "(", "0", ")", ".", "to", "(", "batch_mask", ")", "\n", "batch_idxs", "=", "batch_mask", ".", "nonzero", "(", ")", ".", "squeeze", "(", "-", "1", ")", "\n", "\n", "eos_mask", "=", "eos_mask", "[", "batch_idxs", "]", "\n", "cand_beams", "=", "cand_beams", "[", "batch_idxs", "]", "\n", "bbsz_offsets", ".", "resize_", "(", "new_bsz", ",", "1", ")", "\n", "cand_bbsz_idx", "=", "cand_beams", ".", "add", "(", "bbsz_offsets", ")", "\n", "cand_scores", "=", "cand_scores", "[", "batch_idxs", "]", "\n", "cand_indices", "=", "cand_indices", "[", "batch_idxs", "]", "\n", "\n", "if", "prefix_tokens", "is", "not", "None", ":", "\n", "                    ", "prefix_tokens", "=", "prefix_tokens", "[", "batch_idxs", "]", "\n", "", "src_lengths", "=", "src_lengths", "[", "batch_idxs", "]", "\n", "blacklist", "=", "blacklist", "[", "batch_idxs", "]", "\n", "\n", "scores", "=", "scores", ".", "view", "(", "bsz", ",", "-", "1", ")", "[", "batch_idxs", "]", ".", "view", "(", "new_bsz", "*", "beam_size", ",", "-", "1", ")", "\n", "tokens", "=", "tokens", ".", "view", "(", "bsz", ",", "-", "1", ")", "[", "batch_idxs", "]", ".", "view", "(", "new_bsz", "*", "beam_size", ",", "-", "1", ")", "\n", "if", "attn", "is", "not", "None", ":", "\n", "                    ", "attn", "=", "attn", ".", "view", "(", "bsz", ",", "-", "1", ")", "[", "batch_idxs", "]", ".", "view", "(", "\n", "new_bsz", "*", "beam_size", ",", "attn", ".", "size", "(", "1", ")", ",", "-", "1", "\n", ")", "\n", "", "bsz", "=", "new_bsz", "\n", "", "else", ":", "\n", "                ", "batch_idxs", "=", "None", "\n", "# set active_mask so that values > cand_size indicate eos hypos", "\n", "# and values < cand_size indicate candidate active hypos.", "\n", "# After, the min values per row are the top candidate active hypos", "\n", "\n", "# Rewrite the operator since the element wise or is not supported in torchscript.", "\n", "\n", "", "eos_mask", "[", ":", ",", ":", "beam_size", "]", "=", "~", "(", "(", "~", "blacklist", ")", "&", "(", "~", "eos_mask", "[", ":", ",", ":", "beam_size", "]", ")", ")", "\n", "active_mask", "=", "torch", ".", "add", "(", "\n", "eos_mask", ".", "type_as", "(", "cand_offsets", ")", "*", "cand_size", ",", "\n", "cand_offsets", "[", ":", "eos_mask", ".", "size", "(", "1", ")", "]", ",", "\n", ")", "\n", "\n", "# get the top beam_size active hypotheses, which are just the hypos", "\n", "# with the smallest values in active_mask", "\n", "new_blacklist", ",", "active_hypos", "=", "torch", ".", "topk", "(", "\n", "active_mask", ",", "k", "=", "beam_size", ",", "dim", "=", "1", ",", "largest", "=", "False", "\n", ")", "\n", "\n", "# update blacklist to ignore any finalized hypos", "\n", "blacklist", "=", "new_blacklist", ".", "ge", "(", "cand_size", ")", "[", ":", ",", ":", "beam_size", "]", "\n", "assert", "(", "~", "blacklist", ")", ".", "any", "(", "dim", "=", "1", ")", ".", "all", "(", ")", "\n", "\n", "active_bbsz_idx", "=", "torch", ".", "gather", "(", "cand_bbsz_idx", ",", "dim", "=", "1", ",", "index", "=", "active_hypos", ")", "\n", "active_scores", "=", "torch", ".", "gather", "(", "cand_scores", ",", "dim", "=", "1", ",", "index", "=", "active_hypos", ")", "\n", "\n", "active_bbsz_idx", "=", "active_bbsz_idx", ".", "view", "(", "-", "1", ")", "\n", "active_scores", "=", "active_scores", ".", "view", "(", "-", "1", ")", "\n", "\n", "# copy tokens and scores for active hypotheses", "\n", "tokens", "[", ":", ",", ":", "step", "+", "1", "]", "=", "torch", ".", "index_select", "(", "\n", "tokens", "[", ":", ",", ":", "step", "+", "1", "]", ",", "dim", "=", "0", ",", "index", "=", "active_bbsz_idx", "\n", ")", "\n", "tokens", ".", "view", "(", "bsz", ",", "beam_size", ",", "-", "1", ")", "[", ":", ",", ":", ",", "step", "+", "1", "]", "=", "torch", ".", "gather", "(", "\n", "cand_indices", ",", "dim", "=", "1", ",", "index", "=", "active_hypos", "\n", ")", "\n", "if", "step", ">", "0", ":", "\n", "                ", "scores", "[", ":", ",", ":", "step", "]", "=", "torch", ".", "index_select", "(", "\n", "scores", "[", ":", ",", ":", "step", "]", ",", "dim", "=", "0", ",", "index", "=", "active_bbsz_idx", "\n", ")", "\n", "", "scores", ".", "view", "(", "bsz", ",", "beam_size", ",", "-", "1", ")", "[", ":", ",", ":", ",", "step", "]", "=", "torch", ".", "gather", "(", "\n", "cand_scores", ",", "dim", "=", "1", ",", "index", "=", "active_hypos", "\n", ")", "\n", "\n", "# copy attention for active hypotheses", "\n", "if", "attn", "is", "not", "None", ":", "\n", "                ", "attn", "[", ":", ",", ":", ",", ":", "step", "+", "2", "]", "=", "torch", ".", "index_select", "(", "\n", "attn", "[", ":", ",", ":", ",", ":", "step", "+", "2", "]", ",", "dim", "=", "0", ",", "index", "=", "active_bbsz_idx", "\n", ")", "\n", "\n", "# reorder incremental state in decoder", "\n", "", "reorder_state", "=", "active_bbsz_idx", "\n", "\n", "# sort by score descending", "\n", "", "for", "sent", "in", "range", "(", "len", "(", "finalized", ")", ")", ":", "\n", "# make into beam container", "\n", "            ", "BCList", "=", "[", "\n", "BeamContainer", "(", "elem", "[", "\"score\"", "]", ".", "item", "(", ")", ",", "elem", ")", "for", "elem", "in", "finalized", "[", "sent", "]", "\n", "]", "\n", "BCList", ".", "sort", "(", ")", "\n", "BCList", ".", "reverse", "(", ")", "\n", "finalized", "[", "sent", "]", "=", "torch", ".", "jit", ".", "annotate", "(", "\n", "List", "[", "Dict", "[", "str", ",", "Tensor", "]", "]", ",", "[", "x", ".", "elem", "for", "x", "in", "BCList", "]", "\n", ")", "\n", "", "return", "finalized", ",", "step", "+", "1", ",", "num_expansions", "\n", "\n"]], "home.repos.pwc.inspect_result.yangkevin2_emnlp2020-stream-beam-mt.None.old_sequence_generator.SequenceGenerator._prefix_tokens": [[586, 614], ["prefix_tokens[].unsqueeze().repeat().view", "old_sequence_generator.SequenceGenerator.gather", "prefix_tokens[].unsqueeze().repeat().view.ne", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "lprobs[].scatter", "prefix_tokens[].unsqueeze().repeat().view.eq", "prefix_tokens[].unsqueeze().repeat().view.eq.any", "prefix_tokens[].unsqueeze().repeat().view.unsqueeze", "prefix_toks[].unsqueeze", "old_sequence_generator.SequenceGenerator.replicate_first_beam", "old_sequence_generator.SequenceGenerator.replicate_first_beam", "old_sequence_generator.SequenceGenerator.replicate_first_beam", "prefix_tokens[].unsqueeze().repeat", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "tokens[].view", "prefix_tokens[].unsqueeze().repeat().view.eq.view", "old_sequence_generator.SequenceGenerator.size", "prefix_tokens[].unsqueeze"], "methods", ["home.repos.pwc.inspect_result.yangkevin2_emnlp2020-stream-beam-mt.None.sequence_generator.SequenceGenerator.replicate_first_beam", "home.repos.pwc.inspect_result.yangkevin2_emnlp2020-stream-beam-mt.None.sequence_generator.SequenceGenerator.replicate_first_beam", "home.repos.pwc.inspect_result.yangkevin2_emnlp2020-stream-beam-mt.None.sequence_generator.SequenceGenerator.replicate_first_beam"], ["", "def", "_prefix_tokens", "(", "\n", "self", ",", "step", ":", "int", ",", "lprobs", ",", "scores", ",", "tokens", ",", "prefix_tokens", ",", "beam_size", ":", "int", "\n", ")", ":", "\n", "        ", "\"\"\"Handle prefix tokens\"\"\"", "\n", "prefix_toks", "=", "prefix_tokens", "[", ":", ",", "step", "]", ".", "unsqueeze", "(", "-", "1", ")", ".", "repeat", "(", "1", ",", "beam_size", ")", ".", "view", "(", "-", "1", ")", "\n", "prefix_lprobs", "=", "lprobs", ".", "gather", "(", "-", "1", ",", "prefix_toks", ".", "unsqueeze", "(", "-", "1", ")", ")", "\n", "prefix_mask", "=", "prefix_toks", ".", "ne", "(", "self", ".", "pad", ")", "\n", "lprobs", "[", "prefix_mask", "]", "=", "torch", ".", "tensor", "(", "-", "math", ".", "inf", ")", ".", "to", "(", "lprobs", ")", "\n", "lprobs", "[", "prefix_mask", "]", "=", "lprobs", "[", "prefix_mask", "]", ".", "scatter", "(", "\n", "-", "1", ",", "prefix_toks", "[", "prefix_mask", "]", ".", "unsqueeze", "(", "-", "1", ")", ",", "prefix_lprobs", "[", "prefix_mask", "]", "\n", ")", "\n", "# if prefix includes eos, then we should make sure tokens and", "\n", "# scores are the same across all beams", "\n", "eos_mask", "=", "prefix_toks", ".", "eq", "(", "self", ".", "eos", ")", "\n", "if", "eos_mask", ".", "any", "(", ")", ":", "\n", "# validate that the first beam matches the prefix", "\n", "            ", "first_beam", "=", "tokens", "[", "eos_mask", "]", ".", "view", "(", "-", "1", ",", "beam_size", ",", "tokens", ".", "size", "(", "-", "1", ")", ")", "[", "\n", ":", ",", "0", ",", "1", ":", "step", "+", "1", "\n", "]", "\n", "eos_mask_batch_dim", "=", "eos_mask", ".", "view", "(", "-", "1", ",", "beam_size", ")", "[", ":", ",", "0", "]", "\n", "target_prefix", "=", "prefix_tokens", "[", "eos_mask_batch_dim", "]", "[", ":", ",", ":", "step", "]", "\n", "assert", "(", "first_beam", "==", "target_prefix", ")", ".", "all", "(", ")", "\n", "\n", "# copy tokens, scores and lprobs from the first beam to all beams", "\n", "tokens", "=", "self", ".", "replicate_first_beam", "(", "tokens", ",", "eos_mask_batch_dim", ",", "beam_size", ")", "\n", "scores", "=", "self", ".", "replicate_first_beam", "(", "scores", ",", "eos_mask_batch_dim", ",", "beam_size", ")", "\n", "lprobs", "=", "self", ".", "replicate_first_beam", "(", "lprobs", ",", "eos_mask_batch_dim", ",", "beam_size", ")", "\n", "", "return", "lprobs", ",", "tokens", ",", "scores", "\n", "\n"]], "home.repos.pwc.inspect_result.yangkevin2_emnlp2020-stream-beam-mt.None.old_sequence_generator.SequenceGenerator.replicate_first_beam": [[615, 619], ["tensor.view.view.view", "tensor.view.view.view", "tensor.view.view.size", "tensor.view.view.size"], "methods", ["None"], ["", "def", "replicate_first_beam", "(", "self", ",", "tensor", ",", "mask", ",", "beam_size", ":", "int", ")", ":", "\n", "        ", "tensor", "=", "tensor", ".", "view", "(", "-", "1", ",", "beam_size", ",", "tensor", ".", "size", "(", "-", "1", ")", ")", "\n", "tensor", "[", "mask", "]", "=", "tensor", "[", "mask", "]", "[", ":", ",", ":", "1", ",", ":", "]", "\n", "return", "tensor", ".", "view", "(", "-", "1", ",", "tensor", ".", "size", "(", "-", "1", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yangkevin2_emnlp2020-stream-beam-mt.None.old_sequence_generator.SequenceGenerator.finalize_hypos": [[620, 714], ["range", "sents_seen.keys", "bbsz_idx.numel", "eos_scores.numel", "tokens.index_select", "scores.index_select", "int", "int", "attn.index_select", "cum_unfin.append", "bbsz_idx.size", "str", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "len", "finalized[].append", "float", "float", "old_sequence_generator.SequenceGenerator.is_finished", "newly_finished.append", "str", "unfin_idx.item", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "len", "sent.item", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "seen.split", "seen.split"], "methods", ["home.repos.pwc.inspect_result.yangkevin2_emnlp2020-stream-beam-mt.None.sequence_generator.SequenceGenerator.is_finished"], ["", "def", "finalize_hypos", "(", "\n", "self", ",", "\n", "step", ":", "int", ",", "\n", "bbsz_idx", ",", "\n", "eos_scores", ",", "\n", "tokens", ",", "\n", "scores", ",", "\n", "finalized", ":", "List", "[", "List", "[", "Dict", "[", "str", ",", "Tensor", "]", "]", "]", ",", "\n", "finished", ":", "List", "[", "bool", "]", ",", "\n", "beam_size", ":", "int", ",", "\n", "attn", ":", "Optional", "[", "Tensor", "]", ",", "\n", "src_lengths", ",", "\n", "max_len", ":", "int", ",", "\n", ")", ":", "\n", "        ", "\"\"\"Finalize hypothesis, store finalized information in `finalized`, and change `finished` accordingly.\n        Returns number of sentences being finalized.\n        Args:\n            bbsz_idx (Tensor):\n        \"\"\"", "\n", "assert", "bbsz_idx", ".", "numel", "(", ")", "==", "eos_scores", ".", "numel", "(", ")", "\n", "\n", "# clone relevant token and attention tensors", "\n", "tokens_clone", "=", "tokens", ".", "index_select", "(", "0", ",", "bbsz_idx", ")", "[", "\n", ":", ",", "1", ":", "step", "+", "2", "\n", "]", "# skip the first index, which is EOS", "\n", "\n", "tokens_clone", "[", ":", ",", "step", "]", "=", "self", ".", "eos", "\n", "attn_clone", "=", "(", "\n", "attn", ".", "index_select", "(", "0", ",", "bbsz_idx", ")", "[", ":", ",", ":", ",", "1", ":", "step", "+", "2", "]", "\n", "if", "attn", "is", "not", "None", "\n", "else", "None", "\n", ")", "\n", "\n", "# compute scores per token position", "\n", "pos_scores", "=", "scores", ".", "index_select", "(", "0", ",", "bbsz_idx", ")", "[", ":", ",", ":", "step", "+", "1", "]", "\n", "pos_scores", "[", ":", ",", "step", "]", "=", "eos_scores", "\n", "# convert from cumulative to per-position scores", "\n", "pos_scores", "[", ":", ",", "1", ":", "]", "=", "pos_scores", "[", ":", ",", "1", ":", "]", "-", "pos_scores", "[", ":", ",", ":", "-", "1", "]", "\n", "\n", "# normalize sentence-level scores", "\n", "if", "self", ".", "normalize_scores", ":", "\n", "            ", "eos_scores", "/=", "(", "step", "+", "1", ")", "**", "self", ".", "len_penalty", "\n", "\n", "", "cum_unfin", ":", "List", "[", "int", "]", "=", "[", "]", "\n", "prev", "=", "0", "\n", "for", "f", "in", "finished", ":", "\n", "            ", "if", "f", ":", "\n", "                ", "prev", "+=", "1", "\n", "", "else", ":", "\n", "                ", "cum_unfin", ".", "append", "(", "prev", ")", "\n", "\n", "# set() is not supported in script export", "\n", "", "", "sents_seen", ":", "Dict", "[", "str", ",", "Optional", "[", "Tensor", "]", "]", "=", "{", "}", "\n", "for", "i", "in", "range", "(", "bbsz_idx", ".", "size", "(", ")", "[", "0", "]", ")", ":", "\n", "            ", "idx", "=", "bbsz_idx", "[", "i", "]", "\n", "score", "=", "eos_scores", "[", "i", "]", "\n", "unfin_idx", "=", "idx", "//", "beam_size", "\n", "sent", "=", "unfin_idx", "+", "cum_unfin", "[", "unfin_idx", "]", "\n", "# Cannot create dict for key type '(int, int)' in torchscript.", "\n", "# The workaround is to cast int to string", "\n", "seen", "=", "str", "(", "sent", ".", "item", "(", ")", ")", "+", "\"_\"", "+", "str", "(", "unfin_idx", ".", "item", "(", ")", ")", "\n", "if", "seen", "not", "in", "sents_seen", ":", "\n", "                ", "sents_seen", "[", "seen", "]", "=", "None", "\n", "\n", "", "if", "self", ".", "match_source_len", "and", "step", ">", "src_lengths", "[", "unfin_idx", "]", ":", "\n", "                ", "score", "=", "torch", ".", "tensor", "(", "-", "math", ".", "inf", ")", ".", "to", "(", "score", ")", "\n", "\n", "", "if", "len", "(", "finalized", "[", "sent", "]", ")", "<", "beam_size", ":", "\n", "                ", "if", "attn_clone", "is", "not", "None", ":", "\n", "# remove padding tokens from attn scores", "\n", "                    ", "hypo_attn", "=", "attn_clone", "[", "i", "]", "\n", "", "else", ":", "\n", "                    ", "hypo_attn", "=", "torch", ".", "empty", "(", "0", ")", "\n", "", "finalized", "[", "sent", "]", ".", "append", "(", "\n", "{", "\n", "\"tokens\"", ":", "tokens_clone", "[", "i", "]", ",", "\n", "\"score\"", ":", "score", ",", "\n", "\"attention\"", ":", "hypo_attn", ",", "# src_len x tgt_len", "\n", "\"alignment\"", ":", "torch", ".", "empty", "(", "0", ")", ",", "\n", "\"positional_scores\"", ":", "pos_scores", "[", "i", "]", ",", "\n", "}", "\n", ")", "\n", "\n", "", "", "newly_finished", ":", "List", "[", "int", "]", "=", "[", "]", "\n", "for", "seen", "in", "sents_seen", ".", "keys", "(", ")", ":", "\n", "# check termination conditions for this sentence", "\n", "            ", "sent", ":", "int", "=", "int", "(", "float", "(", "seen", ".", "split", "(", "\"_\"", ")", "[", "0", "]", ")", ")", "\n", "unfin_idx", ":", "int", "=", "int", "(", "float", "(", "seen", ".", "split", "(", "\"_\"", ")", "[", "1", "]", ")", ")", "\n", "if", "not", "finished", "[", "sent", "]", "and", "self", ".", "is_finished", "(", "\n", "step", ",", "unfin_idx", ",", "max_len", ",", "len", "(", "finalized", "[", "sent", "]", ")", ",", "beam_size", "\n", ")", ":", "\n", "                ", "finished", "[", "sent", "]", "=", "True", "\n", "newly_finished", ".", "append", "(", "unfin_idx", ")", "\n", "", "", "return", "newly_finished", "\n", "\n"]], "home.repos.pwc.inspect_result.yangkevin2_emnlp2020-stream-beam-mt.None.old_sequence_generator.SequenceGenerator.is_finished": [[715, 732], ["None"], "methods", ["None"], ["", "def", "is_finished", "(", "\n", "self", ",", "\n", "step", ":", "int", ",", "\n", "unfin_idx", ":", "int", ",", "\n", "max_len", ":", "int", ",", "\n", "finalized_sent_len", ":", "int", ",", "\n", "beam_size", ":", "int", ",", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Check whether we've finished generation for a given sentence, by\n        comparing the worst score among finalized hypotheses to the best\n        possible score among unfinalized hypotheses.\n        \"\"\"", "\n", "assert", "finalized_sent_len", "<=", "beam_size", "\n", "if", "finalized_sent_len", "==", "beam_size", "or", "step", "==", "max_len", ":", "\n", "            ", "return", "True", "\n", "", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.yangkevin2_emnlp2020-stream-beam-mt.None.old_sequence_generator.SequenceGenerator.calculate_banned_tokens": [[733, 747], ["tokens[].tolist", "gen_ngrams[].get", "torch.jit.annotate", "torch.jit.annotate", "torch.jit.annotate", "torch.jit.annotate", "str"], "methods", ["None"], ["", "def", "calculate_banned_tokens", "(", "\n", "self", ",", "\n", "tokens", ",", "\n", "step", ":", "int", ",", "\n", "gen_ngrams", ":", "List", "[", "Dict", "[", "str", ",", "List", "[", "int", "]", "]", "]", ",", "\n", "no_repeat_ngram_size", ":", "int", ",", "\n", "bbsz_idx", ":", "int", ",", "\n", ")", ":", "\n", "        ", "tokens_list", ":", "List", "[", "int", "]", "=", "tokens", "[", "\n", "bbsz_idx", ",", "step", "+", "2", "-", "no_repeat_ngram_size", ":", "step", "+", "1", "\n", "]", ".", "tolist", "(", ")", "\n", "# before decoding the next token, prevent decoding of ngrams that have already appeared", "\n", "ngram_index", "=", "\",\"", ".", "join", "(", "[", "str", "(", "x", ")", "for", "x", "in", "tokens_list", "]", ")", "\n", "return", "gen_ngrams", "[", "bbsz_idx", "]", ".", "get", "(", "ngram_index", ",", "torch", ".", "jit", ".", "annotate", "(", "List", "[", "int", "]", ",", "[", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yangkevin2_emnlp2020-stream-beam-mt.None.old_sequence_generator.SequenceGenerator.transpose_list": [[748, 753], ["min", "len", "range"], "methods", ["None"], ["", "def", "transpose_list", "(", "self", ",", "l", ":", "List", "[", "List", "[", "int", "]", "]", ")", ":", "\n", "# GeneratorExp aren't supported in TS so ignoring the lint", "\n", "        ", "min_len", "=", "min", "(", "[", "len", "(", "x", ")", "for", "x", "in", "l", "]", ")", "# noqa", "\n", "l2", "=", "[", "[", "row", "[", "i", "]", "for", "row", "in", "l", "]", "for", "i", "in", "range", "(", "min_len", ")", "]", "\n", "return", "l2", "\n", "\n"]], "home.repos.pwc.inspect_result.yangkevin2_emnlp2020-stream-beam-mt.None.old_sequence_generator.SequenceGenerator._no_repeat_ngram": [[754, 788], ["tokens.cpu", "range", "range", "torch.jit.annotate", "torch.jit.annotate", "torch.jit.annotate", "torch.jit.annotate", "cpu_tokens[].tolist", "old_sequence_generator.SequenceGenerator.transpose_list", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "range", "old_sequence_generator.SequenceGenerator.calculate_banned_tokens", "torch.jit.annotate", "torch.jit.annotate", "torch.jit.annotate", "torch.jit.annotate", "gen_ngrams[].get", "range", "range", "torch.tensor().long", "torch.tensor().long", "torch.tensor().long", "torch.tensor().long", "range", "str", "torch.jit.annotate", "torch.jit.annotate", "torch.jit.annotate", "torch.jit.annotate", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor"], "methods", ["home.repos.pwc.inspect_result.yangkevin2_emnlp2020-stream-beam-mt.None.sequence_generator.SequenceGenerator.transpose_list", "home.repos.pwc.inspect_result.yangkevin2_emnlp2020-stream-beam-mt.None.sequence_generator.SequenceGenerator.calculate_banned_tokens"], ["", "def", "_no_repeat_ngram", "(", "self", ",", "tokens", ",", "lprobs", ",", "bsz", ":", "int", ",", "beam_size", ":", "int", ",", "step", ":", "int", ")", ":", "\n", "# for each beam and batch sentence, generate a list of previous ngrams", "\n", "        ", "gen_ngrams", ":", "List", "[", "Dict", "[", "str", ",", "List", "[", "int", "]", "]", "]", "=", "[", "\n", "torch", ".", "jit", ".", "annotate", "(", "Dict", "[", "str", ",", "List", "[", "int", "]", "]", ",", "{", "}", ")", "\n", "for", "bbsz_idx", "in", "range", "(", "bsz", "*", "beam_size", ")", "\n", "]", "\n", "cpu_tokens", "=", "tokens", ".", "cpu", "(", ")", "\n", "for", "bbsz_idx", "in", "range", "(", "bsz", "*", "beam_size", ")", ":", "\n", "            ", "gen_tokens", ":", "List", "[", "int", "]", "=", "cpu_tokens", "[", "bbsz_idx", "]", ".", "tolist", "(", ")", "\n", "for", "ngram", "in", "self", ".", "transpose_list", "(", "\n", "[", "gen_tokens", "[", "i", ":", "]", "for", "i", "in", "range", "(", "self", ".", "no_repeat_ngram_size", ")", "]", "\n", ")", ":", "\n", "                ", "key", "=", "\",\"", ".", "join", "(", "[", "str", "(", "x", ")", "for", "x", "in", "ngram", "[", ":", "-", "1", "]", "]", ")", "\n", "gen_ngrams", "[", "bbsz_idx", "]", "[", "key", "]", "=", "gen_ngrams", "[", "bbsz_idx", "]", ".", "get", "(", "\n", "key", ",", "torch", ".", "jit", ".", "annotate", "(", "List", "[", "int", "]", ",", "[", "]", ")", "\n", ")", "+", "[", "ngram", "[", "-", "1", "]", "]", "\n", "\n", "", "", "if", "step", "+", "2", "-", "self", ".", "no_repeat_ngram_size", ">=", "0", ":", "\n", "# no banned tokens if we haven't generated no_repeat_ngram_size tokens yet", "\n", "            ", "banned_tokens", "=", "[", "\n", "self", ".", "calculate_banned_tokens", "(", "\n", "tokens", ",", "step", ",", "gen_ngrams", ",", "self", ".", "no_repeat_ngram_size", ",", "bbsz_idx", "\n", ")", "\n", "for", "bbsz_idx", "in", "range", "(", "bsz", "*", "beam_size", ")", "\n", "]", "\n", "", "else", ":", "\n", "            ", "banned_tokens", "=", "[", "\n", "torch", ".", "jit", ".", "annotate", "(", "List", "[", "int", "]", ",", "[", "]", ")", "for", "bbsz_idx", "in", "range", "(", "bsz", "*", "beam_size", ")", "\n", "]", "\n", "", "for", "bbsz_idx", "in", "range", "(", "bsz", "*", "beam_size", ")", ":", "\n", "            ", "lprobs", "[", "bbsz_idx", "]", "[", "\n", "torch", ".", "tensor", "(", "banned_tokens", "[", "bbsz_idx", "]", ")", ".", "long", "(", ")", "\n", "]", "=", "torch", ".", "tensor", "(", "-", "math", ".", "inf", ",", "dtype", "=", "torch", ".", "float", ")", "\n", "", "return", "lprobs", "\n", "\n"]], "home.repos.pwc.inspect_result.yangkevin2_emnlp2020-stream-beam-mt.None.old_sequence_generator.EnsembleModel.__init__": [[795, 815], ["torch.Module.__init__", "len", "torch.ModuleList", "torch.ModuleList", "torch.jit.annotate", "torch.jit.annotate", "torch.jit.annotate", "torch.jit.annotate", "all", "torch.jit.annotate", "torch.jit.annotate", "torch.jit.annotate", "torch.jit.annotate", "range", "hasattr", "isinstance"], "methods", ["home.repos.pwc.inspect_result.yangkevin2_emnlp2020-stream-beam-mt.None.sequence_generator.BeamContainer.__init__"], ["def", "__init__", "(", "self", ",", "models", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "models_size", "=", "len", "(", "models", ")", "\n", "# method '__len__' is not supported in ModuleList for torch script", "\n", "self", ".", "single_model", "=", "models", "[", "0", "]", "\n", "self", ".", "models", "=", "nn", ".", "ModuleList", "(", "models", ")", "\n", "\n", "self", ".", "incremental_states", "=", "torch", ".", "jit", ".", "annotate", "(", "\n", "List", "[", "Dict", "[", "str", ",", "Dict", "[", "str", ",", "Optional", "[", "Tensor", "]", "]", "]", "]", ",", "\n", "[", "\n", "torch", ".", "jit", ".", "annotate", "(", "Dict", "[", "str", ",", "Dict", "[", "str", ",", "Optional", "[", "Tensor", "]", "]", "]", ",", "{", "}", ")", "\n", "for", "i", "in", "range", "(", "self", ".", "models_size", ")", "\n", "]", ",", "\n", ")", "\n", "self", ".", "has_incremental", ":", "bool", "=", "False", "\n", "if", "all", "(", "\n", "hasattr", "(", "m", ",", "\"decoder\"", ")", "and", "isinstance", "(", "m", ".", "decoder", ",", "FairseqIncrementalDecoder", ")", "\n", "for", "m", "in", "models", "\n", ")", ":", "\n", "            ", "self", ".", "has_incremental", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.yangkevin2_emnlp2020-stream-beam-mt.None.old_sequence_generator.EnsembleModel.forward": [[816, 818], ["None"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.yangkevin2_emnlp2020-stream-beam-mt.None.old_sequence_generator.EnsembleModel.reset_incremental_state": [[819, 829], ["old_sequence_generator.EnsembleModel.has_incremental_states", "torch.jit.annotate", "torch.jit.annotate", "torch.jit.annotate", "torch.jit.annotate", "torch.jit.annotate", "torch.jit.annotate", "torch.jit.annotate", "torch.jit.annotate", "range"], "methods", ["home.repos.pwc.inspect_result.yangkevin2_emnlp2020-stream-beam-mt.None.sequence_generator.EnsembleModel.has_incremental_states"], ["", "def", "reset_incremental_state", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "has_incremental_states", "(", ")", ":", "\n", "            ", "self", ".", "incremental_states", "=", "torch", ".", "jit", ".", "annotate", "(", "\n", "List", "[", "Dict", "[", "str", ",", "Dict", "[", "str", ",", "Optional", "[", "Tensor", "]", "]", "]", "]", ",", "\n", "[", "\n", "torch", ".", "jit", ".", "annotate", "(", "Dict", "[", "str", ",", "Dict", "[", "str", ",", "Optional", "[", "Tensor", "]", "]", "]", ",", "{", "}", ")", "\n", "for", "i", "in", "range", "(", "self", ".", "models_size", ")", "\n", "]", ",", "\n", ")", "\n", "", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.yangkevin2_emnlp2020-stream-beam-mt.None.old_sequence_generator.EnsembleModel.has_encoder": [[830, 832], ["hasattr"], "methods", ["None"], ["", "def", "has_encoder", "(", "self", ")", ":", "\n", "        ", "return", "hasattr", "(", "self", ".", "single_model", ",", "\"encoder\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yangkevin2_emnlp2020-stream-beam-mt.None.old_sequence_generator.EnsembleModel.has_incremental_states": [[833, 835], ["None"], "methods", ["None"], ["", "def", "has_incremental_states", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "has_incremental", "\n", "\n"]], "home.repos.pwc.inspect_result.yangkevin2_emnlp2020-stream-beam-mt.None.old_sequence_generator.EnsembleModel.max_decoder_positions": [[836, 838], ["min", "m.max_decoder_positions"], "methods", ["home.repos.pwc.inspect_result.yangkevin2_emnlp2020-stream-beam-mt.None.sequence_generator.EnsembleModel.max_decoder_positions"], ["", "def", "max_decoder_positions", "(", "self", ")", ":", "\n", "        ", "return", "min", "(", "[", "m", ".", "max_decoder_positions", "(", ")", "for", "m", "in", "self", ".", "models", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yangkevin2_emnlp2020-stream-beam-mt.None.old_sequence_generator.EnsembleModel.forward_encoder": [[839, 846], ["old_sequence_generator.EnsembleModel.has_encoder", "model.encoder.forward_torchscript"], "methods", ["home.repos.pwc.inspect_result.yangkevin2_emnlp2020-stream-beam-mt.None.sequence_generator.EnsembleModel.has_encoder"], ["", "@", "torch", ".", "jit", ".", "export", "\n", "def", "forward_encoder", "(", "self", ",", "net_input", ":", "Dict", "[", "str", ",", "Tensor", "]", ")", ":", "\n", "        ", "if", "not", "self", ".", "has_encoder", "(", ")", ":", "\n", "            ", "return", "None", "\n", "", "return", "[", "\n", "model", ".", "encoder", ".", "forward_torchscript", "(", "net_input", ")", "\n", "for", "model", "in", "self", ".", "models", "\n", "]", "\n"]], "home.repos.pwc.inspect_result.yangkevin2_emnlp2020-stream-beam-mt.None.old_sequence_generator.EnsembleModel.forward_decoder": [[848, 906], ["enumerate", "old_sequence_generator.EnsembleModel.has_encoder", "old_sequence_generator.EnsembleModel.has_incremental_states", "len", "model.get_normalized_probs", "log_probs.append", "torch.logsumexp", "torch.logsumexp", "torch.logsumexp", "torch.logsumexp", "math.log", "avg_attn.div_", "model.decoder.forward", "model.decoder.forward", "isinstance", "[].div_", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "isinstance", "avg_attn.add_"], "methods", ["home.repos.pwc.inspect_result.yangkevin2_emnlp2020-stream-beam-mt.None.sequence_generator.EnsembleModel.has_encoder", "home.repos.pwc.inspect_result.yangkevin2_emnlp2020-stream-beam-mt.None.sequence_generator.EnsembleModel.has_incremental_states", "home.repos.pwc.inspect_result.yangkevin2_emnlp2020-stream-beam-mt.None.sequence_generator.EnsembleModel.forward", "home.repos.pwc.inspect_result.yangkevin2_emnlp2020-stream-beam-mt.None.sequence_generator.EnsembleModel.forward"], ["", "@", "torch", ".", "jit", ".", "export", "\n", "def", "forward_decoder", "(", "\n", "self", ",", "tokens", ",", "encoder_outs", ":", "List", "[", "EncoderOut", "]", ",", "temperature", ":", "float", "=", "1.0", "\n", ")", ":", "\n", "        ", "log_probs", "=", "[", "]", "\n", "avg_attn", ":", "Optional", "[", "Tensor", "]", "=", "None", "\n", "encoder_out", ":", "Optional", "[", "EncoderOut", "]", "=", "None", "\n", "for", "i", ",", "model", "in", "enumerate", "(", "self", ".", "models", ")", ":", "\n", "            ", "if", "self", ".", "has_encoder", "(", ")", ":", "\n", "                ", "encoder_out", "=", "encoder_outs", "[", "i", "]", "\n", "# decode each model", "\n", "", "if", "self", ".", "has_incremental_states", "(", ")", ":", "\n", "                ", "decoder_out", "=", "model", ".", "decoder", ".", "forward", "(", "\n", "tokens", ",", "\n", "encoder_out", "=", "encoder_out", ",", "\n", "incremental_state", "=", "self", ".", "incremental_states", "[", "i", "]", ",", "\n", ")", "\n", "", "else", ":", "\n", "                ", "decoder_out", "=", "model", ".", "decoder", ".", "forward", "(", "tokens", ",", "encoder_out", "=", "encoder_out", ")", "\n", "\n", "", "attn", ":", "Optional", "[", "Tensor", "]", "=", "None", "\n", "decoder_len", "=", "len", "(", "decoder_out", ")", "\n", "if", "decoder_len", ">", "1", "and", "decoder_out", "[", "1", "]", "is", "not", "None", ":", "\n", "                ", "if", "isinstance", "(", "decoder_out", "[", "1", "]", ",", "Tensor", ")", ":", "\n", "                    ", "attn", "=", "decoder_out", "[", "1", "]", "\n", "", "else", ":", "\n", "                    ", "attn_holder", "=", "decoder_out", "[", "1", "]", "[", "\"attn\"", "]", "\n", "if", "isinstance", "(", "attn_holder", ",", "Tensor", ")", ":", "\n", "                        ", "attn", "=", "attn_holder", "\n", "", "elif", "attn_holder", "is", "not", "None", ":", "\n", "                        ", "attn", "=", "attn_holder", "[", "0", "]", "\n", "", "", "if", "attn", "is", "not", "None", ":", "\n", "                    ", "attn", "=", "attn", "[", ":", ",", "-", "1", ",", ":", "]", "\n", "\n", "", "", "decoder_out_tuple", "=", "(", "\n", "decoder_out", "[", "0", "]", "[", ":", ",", "-", "1", ":", ",", ":", "]", ".", "div_", "(", "temperature", ")", ",", "\n", "None", "if", "decoder_len", "<=", "1", "else", "decoder_out", "[", "1", "]", ",", "\n", ")", "\n", "\n", "probs", "=", "model", ".", "get_normalized_probs", "(", "\n", "decoder_out_tuple", ",", "log_probs", "=", "True", ",", "sample", "=", "None", "\n", ")", "\n", "probs", "=", "probs", "[", ":", ",", "-", "1", ",", ":", "]", "\n", "if", "self", ".", "models_size", "==", "1", ":", "\n", "                ", "return", "probs", ",", "attn", "\n", "\n", "", "log_probs", ".", "append", "(", "probs", ")", "\n", "if", "attn", "is", "not", "None", ":", "\n", "                ", "if", "avg_attn", "is", "None", ":", "\n", "                    ", "avg_attn", "=", "attn", "\n", "", "else", ":", "\n", "                    ", "avg_attn", ".", "add_", "(", "attn", ")", "\n", "", "", "", "avg_probs", "=", "torch", ".", "logsumexp", "(", "torch", ".", "stack", "(", "log_probs", ",", "dim", "=", "0", ")", ",", "dim", "=", "0", ")", "-", "math", ".", "log", "(", "\n", "self", ".", "models_size", "\n", ")", "\n", "if", "avg_attn", "is", "not", "None", ":", "\n", "            ", "avg_attn", ".", "div_", "(", "self", ".", "models_size", ")", "\n", "", "return", "avg_probs", ",", "avg_attn", "\n", "\n"]], "home.repos.pwc.inspect_result.yangkevin2_emnlp2020-stream-beam-mt.None.old_sequence_generator.EnsembleModel.reorder_encoder_out": [[907, 928], ["enumerate", "old_sequence_generator.EnsembleModel.has_encoder", "new_outs.append", "model.encoder.reorder_encoder_out"], "methods", ["home.repos.pwc.inspect_result.yangkevin2_emnlp2020-stream-beam-mt.None.sequence_generator.EnsembleModel.has_encoder", "home.repos.pwc.inspect_result.yangkevin2_emnlp2020-stream-beam-mt.None.sequence_generator.EnsembleModel.reorder_encoder_out"], ["", "@", "torch", ".", "jit", ".", "export", "\n", "def", "reorder_encoder_out", "(", "self", ",", "encoder_outs", ":", "Optional", "[", "List", "[", "EncoderOut", "]", "]", ",", "new_order", ")", ":", "\n", "        ", "\"\"\"\n        Reorder encoder output according to *new_order*.\n\n        Args:\n            encoder_out: output from the ``forward()`` method\n            new_order (LongTensor): desired order\n\n        Returns:\n            *encoder_out* rearranged according to *new_order*\n        \"\"\"", "\n", "new_outs", ":", "List", "[", "EncoderOut", "]", "=", "[", "]", "\n", "if", "not", "self", ".", "has_encoder", "(", ")", ":", "\n", "            ", "return", "new_outs", "\n", "", "for", "i", ",", "model", "in", "enumerate", "(", "self", ".", "models", ")", ":", "\n", "            ", "assert", "encoder_outs", "is", "not", "None", "\n", "new_outs", ".", "append", "(", "\n", "model", ".", "encoder", ".", "reorder_encoder_out", "(", "encoder_outs", "[", "i", "]", ",", "new_order", ")", "\n", ")", "\n", "", "return", "new_outs", "\n", "\n"]], "home.repos.pwc.inspect_result.yangkevin2_emnlp2020-stream-beam-mt.None.old_sequence_generator.EnsembleModel.reorder_incremental_state": [[929, 936], ["enumerate", "old_sequence_generator.EnsembleModel.has_incremental_states", "model.decoder.reorder_incremental_state"], "methods", ["home.repos.pwc.inspect_result.yangkevin2_emnlp2020-stream-beam-mt.None.sequence_generator.EnsembleModel.has_incremental_states", "home.repos.pwc.inspect_result.yangkevin2_emnlp2020-stream-beam-mt.None.sequence_generator.EnsembleModel.reorder_incremental_state"], ["", "@", "torch", ".", "jit", ".", "export", "\n", "def", "reorder_incremental_state", "(", "self", ",", "new_order", ")", ":", "\n", "        ", "if", "not", "self", ".", "has_incremental_states", "(", ")", ":", "\n", "            ", "return", "\n", "", "for", "i", ",", "model", "in", "enumerate", "(", "self", ".", "models", ")", ":", "\n", "            ", "model", ".", "decoder", ".", "reorder_incremental_state", "(", "\n", "self", ".", "incremental_states", "[", "i", "]", ",", "new_order", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.yangkevin2_emnlp2020-stream-beam-mt.None.old_sequence_generator.SequenceGeneratorWithAlignment.__init__": [[940, 953], ["old_sequence_generator.SequenceGenerator.__init__", "old_sequence_generator.EnsembleModelWithAlignment"], "methods", ["home.repos.pwc.inspect_result.yangkevin2_emnlp2020-stream-beam-mt.None.sequence_generator.BeamContainer.__init__"], ["    ", "def", "__init__", "(", "self", ",", "models", ",", "tgt_dict", ",", "left_pad_target", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"Generates translations of a given source sentence.\n\n        Produces alignments following \"Jointly Learning to Align and\n        Translate with Transformer Models\" (Garg et al., EMNLP 2019).\n\n        Args:\n            left_pad_target (bool, optional): Whether or not the\n                hypothesis should be left padded or not when they are\n                teacher forced for generating alignments.\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", "EnsembleModelWithAlignment", "(", "models", ")", ",", "tgt_dict", ",", "**", "kwargs", ")", "\n", "self", ".", "left_pad_target", "=", "left_pad_target", "\n", "\n"]], "home.repos.pwc.inspect_result.yangkevin2_emnlp2020-stream-beam-mt.None.old_sequence_generator.SequenceGeneratorWithAlignment.generate": [[954, 980], ["torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "old_sequence_generator.SequenceGeneratorWithAlignment.model.reset_incremental_state", "old_sequence_generator.SequenceGenerator._generate", "old_sequence_generator.SequenceGeneratorWithAlignment._prepare_batch_for_alignment", "any", "range", "old_sequence_generator.SequenceGeneratorWithAlignment.model.forward_align", "fairseq.utils.extract_hard_alignment", "getattr", "[].transpose", "range"], "methods", ["home.repos.pwc.inspect_result.yangkevin2_emnlp2020-stream-beam-mt.None.sequence_generator.EnsembleModel.reset_incremental_state", "home.repos.pwc.inspect_result.yangkevin2_emnlp2020-stream-beam-mt.None.sequence_generator.SequenceGenerator._generate", "home.repos.pwc.inspect_result.yangkevin2_emnlp2020-stream-beam-mt.None.sequence_generator.SequenceGeneratorWithAlignment._prepare_batch_for_alignment", "home.repos.pwc.inspect_result.yangkevin2_emnlp2020-stream-beam-mt.None.sequence_generator.EnsembleModelWithAlignment.forward_align"], ["", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "generate", "(", "self", ",", "models", ",", "sample", ",", "**", "kwargs", ")", ":", "\n", "        ", "self", ".", "model", ".", "reset_incremental_state", "(", ")", "\n", "finalized", "=", "super", "(", ")", ".", "_generate", "(", "sample", ",", "**", "kwargs", ")", "\n", "\n", "src_tokens", "=", "sample", "[", "\"net_input\"", "]", "[", "\"src_tokens\"", "]", "\n", "bsz", "=", "src_tokens", ".", "shape", "[", "0", "]", "\n", "beam_size", "=", "self", ".", "beam_size", "\n", "src_tokens", ",", "src_lengths", ",", "prev_output_tokens", ",", "tgt_tokens", "=", "self", ".", "_prepare_batch_for_alignment", "(", "\n", "sample", ",", "finalized", "\n", ")", "\n", "if", "any", "(", "getattr", "(", "m", ",", "\"full_context_alignment\"", ",", "False", ")", "for", "m", "in", "self", ".", "model", ".", "models", ")", ":", "\n", "            ", "attn", "=", "self", ".", "model", ".", "forward_align", "(", "src_tokens", ",", "src_lengths", ",", "prev_output_tokens", ")", "\n", "", "else", ":", "\n", "            ", "attn", "=", "[", "\n", "finalized", "[", "i", "//", "beam_size", "]", "[", "i", "%", "beam_size", "]", "[", "\"attention\"", "]", ".", "transpose", "(", "1", ",", "0", ")", "\n", "for", "i", "in", "range", "(", "bsz", "*", "beam_size", ")", "\n", "]", "\n", "\n", "# Process the attn matrix to extract hard alignments.", "\n", "", "for", "i", "in", "range", "(", "bsz", "*", "beam_size", ")", ":", "\n", "            ", "alignment", "=", "utils", ".", "extract_hard_alignment", "(", "\n", "attn", "[", "i", "]", ",", "src_tokens", "[", "i", "]", ",", "tgt_tokens", "[", "i", "]", ",", "self", ".", "pad", ",", "self", ".", "eos", "\n", ")", "\n", "finalized", "[", "i", "//", "beam_size", "]", "[", "i", "%", "beam_size", "]", "[", "\"alignment\"", "]", "=", "alignment", "\n", "", "return", "finalized", "\n", "\n"]], "home.repos.pwc.inspect_result.yangkevin2_emnlp2020-stream-beam-mt.None.old_sequence_generator.SequenceGeneratorWithAlignment._prepare_batch_for_alignment": [[981, 1012], ["src_tokens[].expand().contiguous().view", "src_lengths[].expand().contiguous().view", "fairseq.data.data_utils.collate_tokens", "fairseq.data.data_utils.collate_tokens", "src_tokens[].expand().contiguous", "src_lengths[].expand().contiguous", "src_tokens[].expand", "src_lengths[].expand"], "methods", ["None"], ["", "def", "_prepare_batch_for_alignment", "(", "self", ",", "sample", ",", "hypothesis", ")", ":", "\n", "        ", "src_tokens", "=", "sample", "[", "\"net_input\"", "]", "[", "\"src_tokens\"", "]", "\n", "bsz", "=", "src_tokens", ".", "shape", "[", "0", "]", "\n", "src_tokens", "=", "(", "\n", "src_tokens", "[", ":", ",", "None", ",", ":", "]", "\n", ".", "expand", "(", "-", "1", ",", "self", ".", "beam_size", ",", "-", "1", ")", "\n", ".", "contiguous", "(", ")", "\n", ".", "view", "(", "bsz", "*", "self", ".", "beam_size", ",", "-", "1", ")", "\n", ")", "\n", "src_lengths", "=", "sample", "[", "\"net_input\"", "]", "[", "\"src_lengths\"", "]", "\n", "src_lengths", "=", "(", "\n", "src_lengths", "[", ":", ",", "None", "]", "\n", ".", "expand", "(", "-", "1", ",", "self", ".", "beam_size", ")", "\n", ".", "contiguous", "(", ")", "\n", ".", "view", "(", "bsz", "*", "self", ".", "beam_size", ")", "\n", ")", "\n", "prev_output_tokens", "=", "data_utils", ".", "collate_tokens", "(", "\n", "[", "beam", "[", "\"tokens\"", "]", "for", "example", "in", "hypothesis", "for", "beam", "in", "example", "]", ",", "\n", "self", ".", "pad", ",", "\n", "self", ".", "eos", ",", "\n", "self", ".", "left_pad_target", ",", "\n", "move_eos_to_beginning", "=", "True", ",", "\n", ")", "\n", "tgt_tokens", "=", "data_utils", ".", "collate_tokens", "(", "\n", "[", "beam", "[", "\"tokens\"", "]", "for", "example", "in", "hypothesis", "for", "beam", "in", "example", "]", ",", "\n", "self", ".", "pad", ",", "\n", "self", ".", "eos", ",", "\n", "self", ".", "left_pad_target", ",", "\n", "move_eos_to_beginning", "=", "False", ",", "\n", ")", "\n", "return", "src_tokens", ",", "src_lengths", ",", "prev_output_tokens", ",", "tgt_tokens", "\n", "\n"]], "home.repos.pwc.inspect_result.yangkevin2_emnlp2020-stream-beam-mt.None.old_sequence_generator.EnsembleModelWithAlignment.__init__": [[1017, 1019], ["old_sequence_generator.EnsembleModel.__init__"], "methods", ["home.repos.pwc.inspect_result.yangkevin2_emnlp2020-stream-beam-mt.None.sequence_generator.BeamContainer.__init__"], ["def", "__init__", "(", "self", ",", "models", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "models", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yangkevin2_emnlp2020-stream-beam-mt.None.old_sequence_generator.EnsembleModelWithAlignment.forward_align": [[1020, 1032], ["model", "len", "avg_attn.div_", "avg_attn.add_", "len"], "methods", ["None"], ["", "def", "forward_align", "(", "self", ",", "src_tokens", ",", "src_lengths", ",", "prev_output_tokens", ")", ":", "\n", "        ", "avg_attn", "=", "None", "\n", "for", "model", "in", "self", ".", "models", ":", "\n", "            ", "decoder_out", "=", "model", "(", "src_tokens", ",", "src_lengths", ",", "prev_output_tokens", ")", "\n", "attn", "=", "decoder_out", "[", "1", "]", "[", "\"attn\"", "]", "\n", "if", "avg_attn", "is", "None", ":", "\n", "                ", "avg_attn", "=", "attn", "\n", "", "else", ":", "\n", "                ", "avg_attn", ".", "add_", "(", "attn", ")", "\n", "", "", "if", "len", "(", "self", ".", "models", ")", ">", "1", ":", "\n", "            ", "avg_attn", ".", "div_", "(", "len", "(", "self", ".", "models", ")", ")", "\n", "", "return", "avg_attn", "\n", "\n"]], "home.repos.pwc.inspect_result.yangkevin2_emnlp2020-stream-beam-mt.None.old_sequence_generator.BeamContainer.__init__": [[1036, 1039], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "score", ":", "float", ",", "elem", ":", "Dict", "[", "str", ",", "Tensor", "]", ")", ":", "\n", "        ", "self", ".", "score", "=", "score", "\n", "self", ".", "elem", "=", "elem", "\n", "\n"]], "home.repos.pwc.inspect_result.yangkevin2_emnlp2020-stream-beam-mt.None.old_sequence_generator.BeamContainer.__lt__": [[1040, 1046], ["None"], "methods", ["None"], ["", "def", "__lt__", "(", "self", ",", "other", ")", ":", "\n", "# type: (BeamContainer) -> bool", "\n", "# Due to https://github.com/pytorch/pytorch/issues/20388,", "\n", "# this has to use old style type annotations", "\n", "# Match original behavior of sorted function when two scores are equal.", "\n", "        ", "return", "self", ".", "score", "<=", "other", ".", "score", "", "", "", ""]], "home.repos.pwc.inspect_result.yangkevin2_emnlp2020-stream-beam-mt.None.old_sequence_generator._lang_token": [[18, 20], ["None"], "function", ["None"], ["def", "_lang_token", "(", "lang", ":", "str", ")", ":", "\n", "    ", "return", "'__{}__'", ".", "format", "(", "lang", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yangkevin2_emnlp2020-stream-beam-mt.None.old_sequence_generator._lang_token_index": [[21, 27], ["dic.index", "old_sequence_generator._lang_token"], "function", ["home.repos.pwc.inspect_result.yangkevin2_emnlp2020-stream-beam-mt.None.sequence_generator._lang_token"], ["", "def", "_lang_token_index", "(", "dic", ",", "lang", ":", "str", ")", ":", "\n", "    ", "\"\"\"Return language token index.\"\"\"", "\n", "idx", "=", "dic", ".", "index", "(", "_lang_token", "(", "lang", ")", ")", "\n", "assert", "idx", "!=", "dic", ".", "unk_index", ",", "'cannot find language token for lang {}'", ".", "format", "(", "lang", ")", "\n", "return", "idx", "\n", "\n"]], "home.repos.pwc.inspect_result.yangkevin2_emnlp2020-stream-beam-mt.None.old_sequence_generator.build_generator": [[67, 150], ["getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "seq_gen_cls", "SequenceScorer", "sum", "ValueError", "fairseq.search.Sampling", "fairseq.search.DiverseBeamSearch", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "int", "fairseq.search.LengthConstrainedBeamSearch", "getattr", "fairseq.search.DiverseSiblingsSearch", "old_sequence_generator.BeamSearch", "getattr"], "function", ["None"], ["", "", "def", "build_generator", "(", "task", ",", "models", ",", "args", ")", ":", "\n", "    ", "if", "getattr", "(", "args", ",", "\"score_reference\"", ",", "False", ")", ":", "\n", "        ", "from", "fairseq", ".", "sequence_scorer", "import", "SequenceScorer", "\n", "\n", "return", "SequenceScorer", "(", "\n", "task", ".", "target_dictionary", ",", "\n", "compute_alignment", "=", "getattr", "(", "args", ",", "\"print_alignment\"", ",", "False", ")", ",", "\n", ")", "\n", "\n", "# from fairseq.sequence_generator import (", "\n", "#     SequenceGenerator,", "\n", "#     SequenceGeneratorWithAlignment,", "\n", "# )", "\n", "\n", "# Choose search strategy. Defaults to Beam Search.", "\n", "", "sampling", "=", "getattr", "(", "args", ",", "\"sampling\"", ",", "False", ")", "\n", "sampling_topk", "=", "getattr", "(", "args", ",", "\"sampling_topk\"", ",", "-", "1", ")", "\n", "sampling_topp", "=", "getattr", "(", "args", ",", "\"sampling_topp\"", ",", "-", "1.0", ")", "\n", "diverse_beam_groups", "=", "getattr", "(", "args", ",", "\"diverse_beam_groups\"", ",", "-", "1", ")", "\n", "diverse_beam_strength", "=", "getattr", "(", "args", ",", "\"diverse_beam_strength\"", ",", "0.5", ")", "\n", "match_source_len", "=", "getattr", "(", "args", ",", "\"match_source_len\"", ",", "False", ")", "\n", "diversity_rate", "=", "getattr", "(", "args", ",", "\"diversity_rate\"", ",", "-", "1", ")", "\n", "if", "(", "\n", "sum", "(", "\n", "int", "(", "cond", ")", "\n", "for", "cond", "in", "[", "\n", "sampling", ",", "\n", "diverse_beam_groups", ">", "0", ",", "\n", "match_source_len", ",", "\n", "diversity_rate", ">", "0", ",", "\n", "]", "\n", ")", "\n", ">", "1", "\n", ")", ":", "\n", "        ", "raise", "ValueError", "(", "\"Provided Search parameters are mutually exclusive.\"", ")", "\n", "", "assert", "sampling_topk", "<", "0", "or", "sampling", ",", "\"--sampling-topk requires --sampling\"", "\n", "assert", "sampling_topp", "<", "0", "or", "sampling", ",", "\"--sampling-topp requires --sampling\"", "\n", "\n", "if", "sampling", ":", "\n", "        ", "search_strategy", "=", "search", ".", "Sampling", "(", "\n", "task", ".", "target_dictionary", ",", "sampling_topk", ",", "sampling_topp", "\n", ")", "\n", "", "elif", "diverse_beam_groups", ">", "0", ":", "\n", "        ", "search_strategy", "=", "search", ".", "DiverseBeamSearch", "(", "\n", "task", ".", "target_dictionary", ",", "diverse_beam_groups", ",", "diverse_beam_strength", "\n", ")", "\n", "", "elif", "match_source_len", ":", "\n", "# this is useful for tagging applications where the output", "\n", "# length should match the input length, so we hardcode the", "\n", "# length constraints for simplicity", "\n", "        ", "search_strategy", "=", "search", ".", "LengthConstrainedBeamSearch", "(", "\n", "task", ".", "target_dictionary", ",", "\n", "min_len_a", "=", "1", ",", "\n", "min_len_b", "=", "0", ",", "\n", "max_len_a", "=", "1", ",", "\n", "max_len_b", "=", "0", ",", "\n", ")", "\n", "", "elif", "diversity_rate", ">", "-", "1", ":", "\n", "        ", "search_strategy", "=", "search", ".", "DiverseSiblingsSearch", "(", "\n", "task", ".", "target_dictionary", ",", "diversity_rate", "\n", ")", "\n", "", "else", ":", "\n", "        ", "search_strategy", "=", "BeamSearch", "(", "task", ".", "target_dictionary", ",", "getattr", "(", "args", ",", "'mc'", ",", "None", ")", ")", "\n", "\n", "", "if", "getattr", "(", "args", ",", "\"print_alignment\"", ",", "False", ")", ":", "\n", "        ", "seq_gen_cls", "=", "SequenceGeneratorWithAlignment", "\n", "", "else", ":", "\n", "        ", "seq_gen_cls", "=", "SequenceGenerator", "\n", "\n", "", "return", "seq_gen_cls", "(", "\n", "models", ",", "\n", "task", ".", "target_dictionary", ",", "\n", "beam_size", "=", "getattr", "(", "args", ",", "\"beam\"", ",", "5", ")", ",", "\n", "max_len_a", "=", "getattr", "(", "args", ",", "\"max_len_a\"", ",", "0", ")", ",", "\n", "max_len_b", "=", "getattr", "(", "args", ",", "\"max_len_b\"", ",", "200", ")", ",", "\n", "min_len", "=", "getattr", "(", "args", ",", "\"min_len\"", ",", "1", ")", ",", "\n", "normalize_scores", "=", "(", "not", "getattr", "(", "args", ",", "\"unnormalized\"", ",", "False", ")", ")", ",", "\n", "len_penalty", "=", "getattr", "(", "args", ",", "\"lenpen\"", ",", "1", ")", ",", "\n", "unk_penalty", "=", "getattr", "(", "args", ",", "\"unkpen\"", ",", "0", ")", ",", "\n", "temperature", "=", "getattr", "(", "args", ",", "\"temperature\"", ",", "1.0", ")", ",", "\n", "match_source_len", "=", "getattr", "(", "args", ",", "\"match_source_len\"", ",", "False", ")", ",", "\n", "no_repeat_ngram_size", "=", "getattr", "(", "args", ",", "\"no_repeat_ngram_size\"", ",", "0", ")", ",", "\n", "search_strategy", "=", "search_strategy", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.yangkevin2_emnlp2020-stream-beam-mt.None.test.sgm_to_lst": [[17, 22], ["open", "open.read", "bs4.BeautifulSoup", "t.getText", "bs4.BeautifulSoup.findAll"], "function", ["None"], ["def", "sgm_to_lst", "(", "f", ")", ":", "\n", "    ", "f", "=", "open", "(", "f", ",", "'r'", ")", "\n", "data", "=", "f", ".", "read", "(", ")", "\n", "soup", "=", "BeautifulSoup", "(", "data", ")", "\n", "return", "[", "t", ".", "getText", "(", ")", "for", "t", "in", "soup", ".", "findAll", "(", "'seg'", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.yangkevin2_emnlp2020-stream-beam-mt.None.test.evaluate_newstest": [[24, 40], ["model.eval", "print", "torch.no_grad", "model.translate", "sacrebleu.corpus_bleu"], "function", ["None"], ["", "def", "evaluate_newstest", "(", "model", ",", "src", ",", "trg", ",", "beam", "=", "5", ")", ":", "\n", "    ", "\"\"\"\n    fairseq evaluation code: https://github.com/pytorch/fairseq/blob/master/fairseq_cli/score.py#L54\n    if args.sacrebleu:\n        import sacrebleu\n\n        def score(fdsys):\n            with open(args.ref) as fdref:\n                print(sacrebleu.corpus_bleu(fdsys, [fdref]))\n    \"\"\"", "\n", "model", ".", "eval", "(", ")", "\n", "predictions", "=", "[", "]", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "predictions", "=", "model", ".", "translate", "(", "src", ",", "beam", "=", "beam", ")", "\n", "", "print", "(", "predictions", ")", "\n", "return", "sacrebleu", ".", "corpus_bleu", "(", "predictions", ",", "[", "trg", "]", ")", ".", "score", "\n", "\n"]], "home.repos.pwc.inspect_result.yangkevin2_emnlp2020-stream-beam-mt.None.test.custom_eval": [[41, 81], ["model.eval", "torch.no_grad", "copy.copy", "sequence_generator.build_generator", "print", "print", "print", "model.encode", "sequence_generator.build_generator.variable_beam_stream", "zip", "model._build_batches", "model.decode", "sacrebleu.corpus_bleu", "results.append", "fairseq.utils.apply_to_sample", "zip", "sorted", "model.task.target_dictionary.eos", "sequence_generator.build_generator.generate", "batch[].tolist", "results.append", "t.to", "sequence_generator.build_generator.greedy", "model.task.target_dictionary.eos", "sequence_generator.build_generator.variable_beam", "model.task.target_dictionary.eos", "model.task.target_dictionary.eos"], "function", ["home.repos.pwc.inspect_result.yangkevin2_emnlp2020-stream-beam-mt.None.sequence_generator.build_generator", "home.repos.pwc.inspect_result.yangkevin2_emnlp2020-stream-beam-mt.None.sequence_generator.SequenceGenerator.variable_beam_stream", "home.repos.pwc.inspect_result.yangkevin2_emnlp2020-stream-beam-mt.None.sequence_generator.SequenceGeneratorWithAlignment.generate", "home.repos.pwc.inspect_result.yangkevin2_emnlp2020-stream-beam-mt.None.sequence_generator.SequenceGenerator.greedy", "home.repos.pwc.inspect_result.yangkevin2_emnlp2020-stream-beam-mt.None.sequence_generator.SequenceGenerator.variable_beam"], ["", "def", "custom_eval", "(", "model", ",", "src", ",", "trg", ",", "beam", "=", "5", ",", "ap", "=", "math", ".", "inf", ",", "eps", "=", "1.", "/", "6", ",", "mc", "=", "None", ",", "method", "=", "None", ")", ":", "\n", "    ", "model", ".", "eval", "(", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "tokenized_sentences", "=", "[", "model", ".", "encode", "(", "(", "sentence", ")", ")", "for", "sentence", "in", "src", "]", "\n", "gen_args", "=", "copy", ".", "copy", "(", "model", ".", "args", ")", "\n", "gen_args", ".", "beam", "=", "beam", "\n", "gen_args", ".", "mc", "=", "mc", "\n", "generator", "=", "build_generator", "(", "model", ".", "task", ",", "model", ".", "models", ",", "gen_args", ")", "\n", "results", "=", "[", "]", "\n", "# model.args.max_sentences = 64", "\n", "total_loops", ",", "total_expansions", "=", "0", ",", "0", "\n", "if", "method", "==", "'variable_stream'", ":", "\n", "# TODO adjust other parameters; adjust batching params", "\n", "            ", "ids", ",", "translations", ",", "total_loops", ",", "total_expansions", "=", "generator", ".", "variable_beam_stream", "(", "model", ",", "tokenized_sentences", ",", "bos_token", "=", "model", ".", "task", ".", "target_dictionary", ".", "eos", "(", ")", ",", "ap", "=", "ap", ",", "mc", "=", "mc", ",", "eps", "=", "eps", ")", "\n", "for", "id", ",", "hypos", "in", "zip", "(", "ids", ",", "translations", ")", ":", "\n", "                ", "results", ".", "append", "(", "(", "id", ",", "hypos", ")", ")", "\n", "", "", "else", ":", "\n", "            ", "for", "batch", "in", "model", ".", "_build_batches", "(", "tokenized_sentences", ",", "False", ")", ":", "\n", "# print('b')", "\n", "                ", "batch", "=", "utils", ".", "apply_to_sample", "(", "lambda", "t", ":", "t", ".", "to", "(", "model", ".", "device", ")", ",", "batch", ")", "\n", "if", "method", "is", "None", ":", "\n", "                    ", "translations", ",", "n_loops", ",", "n_expansions", "=", "generator", ".", "generate", "(", "model", ".", "models", ",", "batch", ",", "bos_token", "=", "model", ".", "task", ".", "target_dictionary", ".", "eos", "(", ")", ",", "ap", "=", "ap", ")", "\n", "", "elif", "method", "==", "'greedy'", ":", "\n", "                    ", "translations", ",", "n_loops", ",", "n_expansions", "=", "generator", ".", "greedy", "(", "model", ".", "models", ",", "batch", ",", "bos_token", "=", "model", ".", "task", ".", "target_dictionary", ".", "eos", "(", ")", ")", "\n", "", "elif", "method", "==", "'variable_beam'", ":", "\n", "                    ", "translations", ",", "n_loops", ",", "n_expansions", "=", "generator", ".", "variable_beam", "(", "model", ",", "batch", ",", "bos_token", "=", "model", ".", "task", ".", "target_dictionary", ".", "eos", "(", ")", ",", "ap", "=", "ap", ",", "mc", "=", "mc", ")", "\n", "", "total_loops", "+=", "n_loops", "\n", "total_expansions", "+=", "n_expansions", "\n", "for", "id", ",", "hypos", "in", "zip", "(", "batch", "[", "\"id\"", "]", ".", "tolist", "(", ")", ",", "translations", ")", ":", "\n", "                    ", "results", ".", "append", "(", "(", "id", ",", "hypos", ")", ")", "\n", "\n", "# sort output to match input order", "\n", "", "", "", "outputs", "=", "[", "hypos", "for", "_", ",", "hypos", "in", "sorted", "(", "results", ",", "key", "=", "lambda", "x", ":", "x", "[", "0", "]", ")", "]", "\n", "predictions", "=", "[", "model", ".", "decode", "(", "hypos", "[", "0", "]", "[", "'tokens'", "]", ")", "for", "hypos", "in", "outputs", "]", "\n", "bleu", "=", "sacrebleu", ".", "corpus_bleu", "(", "predictions", ",", "[", "trg", "]", ")", ".", "score", "\n", "# print(predictions)", "\n", "print", "(", "'loops'", ",", "total_loops", ")", "\n", "print", "(", "'expansions'", ",", "total_expansions", ")", "\n", "print", "(", "bleu", ")", "\n", "return", "bleu", "\n", "\n"]], "home.repos.pwc.inspect_result.yangkevin2_emnlp2020-stream-beam-mt.None.util.pad_to_max_length": [[5, 11], ["pad_to_length.size", "pad_to_length.size", "util.pad_to_length", "pad_to_length.size", "pad_to_length.size", "pad_to_length.size", "util.pad_to_length", "pad_to_length.size"], "function", ["home.repos.pwc.inspect_result.yangkevin2_emnlp2020-stream-beam-mt.None.util.pad_to_length", "home.repos.pwc.inspect_result.yangkevin2_emnlp2020-stream-beam-mt.None.util.pad_to_length"], ["def", "pad_to_max_length", "(", "t1", ",", "t2", ",", "dim", ",", "side", "=", "'right'", ")", ":", "\n", "    ", "if", "t1", ".", "size", "(", "dim", ")", "<", "t2", ".", "size", "(", "dim", ")", ":", "\n", "        ", "t1", "=", "pad_to_length", "(", "t1", ",", "t2", ".", "size", "(", "dim", ")", ",", "dim", ",", "side", ")", "\n", "", "elif", "t2", ".", "size", "(", "dim", ")", "<", "t1", ".", "size", "(", "dim", ")", ":", "\n", "        ", "t2", "=", "pad_to_length", "(", "t2", ",", "t1", ".", "size", "(", "dim", ")", ",", "dim", ",", "side", ")", "\n", "", "return", "t1", ",", "t2", "\n", "\n"]], "home.repos.pwc.inspect_result.yangkevin2_emnlp2020-stream-beam-mt.None.util.pad_to_length": [[13, 26], ["tensor.size", "tensor.size", "list", "tuple", "tensor.size", "torch.cat", "torch.cat", "torch.zeros().type().to().fill_", "torch.zeros().type().to().fill_", "torch.zeros().type().to", "torch.zeros().type().to", "torch.zeros().type", "torch.zeros().type", "tensor.type", "tensor.type", "torch.zeros", "torch.zeros"], "function", ["None"], ["", "def", "pad_to_length", "(", "tensor", ",", "length", ",", "dim", ",", "side", "=", "'right'", ",", "value", "=", "0", ")", ":", "\n", "    ", "assert", "side", "in", "[", "'left'", ",", "'right'", "]", "\n", "assert", "tensor", ".", "size", "(", "dim", ")", "<=", "length", "\n", "if", "tensor", ".", "size", "(", "dim", ")", "==", "length", ":", "\n", "        ", "return", "tensor", "\n", "", "else", ":", "\n", "        ", "zeros_shape", "=", "list", "(", "tensor", ".", "shape", ")", "\n", "zeros_shape", "[", "dim", "]", "=", "length", "-", "tensor", ".", "size", "(", "dim", ")", "\n", "zeros_shape", "=", "tuple", "(", "zeros_shape", ")", "\n", "if", "side", "==", "'right'", ":", "\n", "            ", "return", "torch", ".", "cat", "(", "[", "tensor", ",", "torch", ".", "zeros", "(", "zeros_shape", ")", ".", "type", "(", "tensor", ".", "type", "(", ")", ")", ".", "to", "(", "tensor", ".", "device", ")", ".", "fill_", "(", "value", ")", "]", ",", "dim", "=", "dim", ")", "\n", "", "else", ":", "\n", "            ", "return", "torch", ".", "cat", "(", "[", "torch", ".", "zeros", "(", "zeros_shape", ")", ".", "type", "(", "tensor", ".", "type", "(", ")", ")", ".", "to", "(", "tensor", ".", "device", ")", ".", "fill_", "(", "value", ")", ",", "tensor", "]", ",", "dim", "=", "dim", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yangkevin2_emnlp2020-stream-beam-mt.None.util.pad_mask": [[28, 36], ["lengths.unsqueeze().repeat", "torch.arange().unsqueeze().repeat().to", "torch.max", "lengths.unsqueeze", "torch.arange().unsqueeze().repeat", "torch.arange().unsqueeze", "lengths.size", "torch.arange"], "function", ["None"], ["", "", "", "def", "pad_mask", "(", "lengths", ":", "torch", ".", "LongTensor", ",", "device", "=", "'cuda'", ",", "max_seqlen", "=", "None", ")", "->", "torch", ".", "ByteTensor", ":", "\n", "# lengths: bs. Ex: [2, 3, 1]", "\n", "    ", "if", "max_seqlen", "is", "None", ":", "\n", "        ", "max_seqlen", "=", "torch", ".", "max", "(", "lengths", ")", "\n", "", "expanded_lengths", "=", "lengths", ".", "unsqueeze", "(", "0", ")", ".", "repeat", "(", "(", "max_seqlen", ",", "1", ")", ")", "# [[2, 3, 1], [2, 3, 1], [2, 3, 1]]", "\n", "indices", "=", "torch", ".", "arange", "(", "max_seqlen", ")", ".", "unsqueeze", "(", "1", ")", ".", "repeat", "(", "(", "1", ",", "lengths", ".", "size", "(", "0", ")", ")", ")", ".", "to", "(", "device", ")", "# [[0, 0, 0], [1, 1, 1], [2, 2, 2]]", "\n", "\n", "return", "expanded_lengths", ">", "indices", "# pad locations are 0. #[[1, 1, 1], [1, 1, 0], [0, 1, 0]]. seqlen x bs", "", "", ""]], "home.repos.pwc.inspect_result.yangkevin2_emnlp2020-stream-beam-mt.None.sequence_generator.BeamSearch.__init__": [[31, 34], ["fairseq.search.Search.__init__"], "methods", ["home.repos.pwc.inspect_result.yangkevin2_emnlp2020-stream-beam-mt.None.sequence_generator.BeamContainer.__init__"], ["    ", "def", "__init__", "(", "self", ",", "tgt_dict", ",", "mc", "=", "None", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "tgt_dict", ")", "\n", "self", ".", "mc", "=", "mc", "\n", "\n"]], "home.repos.pwc.inspect_result.yangkevin2_emnlp2020-stream-beam-mt.None.sequence_generator.BeamSearch.step": [[35, 67], ["lprobs[].contiguous.size", "torch.topk", "torch.topk", "torch.topk", "torch.topk", "torch.div", "torch.div", "torch.div", "torch.div", "indices_buf.fmod.fmod.fmod", "lprobs[].contiguous", "lprobs[].contiguous.topk", "masked_lprobs.scatter_", "lprobs[].contiguous.view", "scores[].unsqueeze", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "min", "lprobs[].contiguous.view().size", "lprobs[].contiguous.view"], "methods", ["None"], ["", "@", "torch", ".", "jit", ".", "export", "\n", "def", "step", "(", "self", ",", "step", ":", "int", ",", "lprobs", ",", "scores", ":", "Optional", "[", "Tensor", "]", ")", ":", "\n", "        ", "bsz", ",", "beam_size", ",", "vocab_size", "=", "lprobs", ".", "size", "(", ")", "\n", "\n", "if", "step", "==", "0", ":", "\n", "# at the first step all hypotheses are equally likely, so use", "\n", "# only the first beam", "\n", "            ", "lprobs", "=", "lprobs", "[", ":", ",", ":", ":", "beam_size", ",", ":", "]", ".", "contiguous", "(", ")", "\n", "", "else", ":", "\n", "# make probs contain cumulative scores for each hypothesis", "\n", "            ", "assert", "scores", "is", "not", "None", "\n", "lprobs", "=", "lprobs", "+", "scores", "[", ":", ",", ":", ",", "step", "-", "1", "]", ".", "unsqueeze", "(", "-", "1", ")", "\n", "", "if", "self", ".", "mc", "is", "not", "None", ":", "\n", "            ", "masked_lprobs", "=", "torch", ".", "zeros_like", "(", "lprobs", ")", "-", "math", ".", "inf", "\n", "keep_lprobs", ",", "keep_idx", "=", "lprobs", ".", "topk", "(", "self", ".", "mc", ",", "dim", "=", "2", ")", "\n", "masked_lprobs", ".", "scatter_", "(", "2", ",", "keep_idx", ",", "keep_lprobs", ")", "\n", "lprobs", "=", "masked_lprobs", "\n", "\n", "", "top_prediction", "=", "torch", ".", "topk", "(", "\n", "lprobs", ".", "view", "(", "bsz", ",", "-", "1", ")", ",", "\n", "k", "=", "min", "(", "\n", "# Take the best 2 x beam_size predictions. We'll choose the first", "\n", "# beam_size of these which don't predict eos to continue with.", "\n", "beam_size", "*", "2", ",", "\n", "lprobs", ".", "view", "(", "bsz", ",", "-", "1", ")", ".", "size", "(", "1", ")", "-", "1", ",", "# -1 so we never select pad", "\n", ")", ",", "\n", ")", "\n", "scores_buf", "=", "top_prediction", "[", "0", "]", "\n", "indices_buf", "=", "top_prediction", "[", "1", "]", "\n", "beams_buf", "=", "torch", ".", "div", "(", "indices_buf", ",", "vocab_size", ")", "\n", "indices_buf", "=", "indices_buf", ".", "fmod", "(", "vocab_size", ")", "\n", "return", "scores_buf", ",", "indices_buf", ",", "beams_buf", "\n", "\n"]], "home.repos.pwc.inspect_result.yangkevin2_emnlp2020-stream-beam-mt.None.sequence_generator.SequenceGenerator.__init__": [[156, 228], ["torch.Module.__init__", "isinstance", "tgt_dict.pad", "tgt_dict.unk", "len", "min", "sequence_generator.EnsembleModel", "tgt_dict.eos", "sequence_generator.BeamSearch", "sequence_generator.SequenceGenerator.model.eval"], "methods", ["home.repos.pwc.inspect_result.yangkevin2_emnlp2020-stream-beam-mt.None.sequence_generator.BeamContainer.__init__"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "models", ",", "\n", "tgt_dict", ",", "\n", "beam_size", "=", "1", ",", "\n", "max_len_a", "=", "0", ",", "\n", "max_len_b", "=", "200", ",", "\n", "min_len", "=", "1", ",", "\n", "normalize_scores", "=", "True", ",", "\n", "len_penalty", "=", "1.0", ",", "\n", "unk_penalty", "=", "0.0", ",", "\n", "retain_dropout", "=", "False", ",", "\n", "temperature", "=", "1.0", ",", "\n", "match_source_len", "=", "False", ",", "\n", "no_repeat_ngram_size", "=", "0", ",", "\n", "search_strategy", "=", "None", ",", "\n", "eos", "=", "None", ",", "\n", ")", ":", "\n", "        ", "\"\"\"Generates translations of a given source sentence.\n\n        Args:\n            models (List[~fairseq.models.FairseqModel]): ensemble of models,\n                currently support fairseq.models.TransformerModel for scripting\n            beam_size (int, optional): beam width (default: 1)\n            max_len_a/b (int, optional): generate sequences of maximum length\n                ax + b, where x is the source length\n            min_len (int, optional): the minimum length of the generated output\n                (not including end-of-sentence)\n            normalize_scores (bool, optional): normalize scores by the length\n                of the output (default: True)\n            len_penalty (float, optional): length penalty, where <1.0 favors\n                shorter, >1.0 favors longer sentences (default: 1.0)\n            unk_penalty (float, optional): unknown word penalty, where <0\n                produces more unks, >0 produces fewer (default: 0.0)\n            retain_dropout (bool, optional): use dropout when generating\n                (default: False)\n            temperature (float, optional): temperature, where values\n                >1.0 produce more uniform samples and values <1.0 produce\n                sharper samples (default: 1.0)\n            match_source_len (bool, optional): outputs should match the source\n                length (default: False)\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "if", "isinstance", "(", "models", ",", "EnsembleModel", ")", ":", "\n", "            ", "self", ".", "model", "=", "models", "\n", "", "else", ":", "\n", "            ", "self", ".", "model", "=", "EnsembleModel", "(", "models", ")", "\n", "", "self", ".", "pad", "=", "tgt_dict", ".", "pad", "(", ")", "\n", "self", ".", "unk", "=", "tgt_dict", ".", "unk", "(", ")", "\n", "self", ".", "eos", "=", "tgt_dict", ".", "eos", "(", ")", "if", "eos", "is", "None", "else", "eos", "\n", "self", ".", "vocab_size", "=", "len", "(", "tgt_dict", ")", "\n", "self", ".", "beam_size", "=", "beam_size", "\n", "# the max beam size is the dictionary size - 1, since we never select pad", "\n", "self", ".", "beam_size", "=", "min", "(", "beam_size", ",", "self", ".", "vocab_size", "-", "1", ")", "\n", "self", ".", "max_len_a", "=", "max_len_a", "\n", "self", ".", "max_len_b", "=", "max_len_b", "\n", "self", ".", "min_len", "=", "min_len", "\n", "\n", "self", ".", "normalize_scores", "=", "normalize_scores", "\n", "self", ".", "len_penalty", "=", "len_penalty", "\n", "self", ".", "unk_penalty", "=", "unk_penalty", "\n", "self", ".", "retain_dropout", "=", "retain_dropout", "\n", "self", ".", "temperature", "=", "temperature", "\n", "self", ".", "match_source_len", "=", "match_source_len", "\n", "self", ".", "no_repeat_ngram_size", "=", "no_repeat_ngram_size", "\n", "assert", "temperature", ">", "0", ",", "\"--temperature must be greater than 0\"", "\n", "\n", "self", ".", "search", "=", "(", "\n", "BeamSearch", "(", "tgt_dict", ")", "if", "search_strategy", "is", "None", "else", "search_strategy", "\n", ")", "\n", "if", "not", "self", ".", "retain_dropout", ":", "\n", "            ", "self", ".", "model", ".", "eval", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yangkevin2_emnlp2020-stream-beam-mt.None.sequence_generator.SequenceGenerator.cuda": [[229, 232], ["sequence_generator.SequenceGenerator.model.cuda"], "methods", ["home.repos.pwc.inspect_result.yangkevin2_emnlp2020-stream-beam-mt.None.sequence_generator.SequenceGenerator.cuda"], ["", "", "def", "cuda", "(", "self", ")", ":", "\n", "        ", "self", ".", "model", ".", "cuda", "(", ")", "\n", "return", "self", "\n", "\n"]], "home.repos.pwc.inspect_result.yangkevin2_emnlp2020-stream-beam-mt.None.sequence_generator.SequenceGenerator.forward": [[233, 251], ["torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "sequence_generator.SequenceGenerator.model.reset_incremental_state", "sequence_generator.SequenceGenerator._generate"], "methods", ["home.repos.pwc.inspect_result.yangkevin2_emnlp2020-stream-beam-mt.None.sequence_generator.EnsembleModel.reset_incremental_state", "home.repos.pwc.inspect_result.yangkevin2_emnlp2020-stream-beam-mt.None.sequence_generator.SequenceGenerator._generate"], ["", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "forward", "(", "\n", "self", ",", "\n", "sample", ":", "Dict", "[", "str", ",", "Dict", "[", "str", ",", "Tensor", "]", "]", ",", "\n", "prefix_tokens", ":", "Optional", "[", "Tensor", "]", "=", "None", ",", "\n", "bos_token", ":", "Optional", "[", "int", "]", "=", "None", ",", "\n", ")", ":", "\n", "        ", "\"\"\"Generate a batch of translations.\n\n        Args:\n            sample (dict): batch\n            prefix_tokens (torch.LongTensor, optional): force decoder to begin\n                with these tokens\n            bos_token (int, optional): beginning of sentence token\n                (default: self.eos)\n        \"\"\"", "\n", "self", ".", "model", ".", "reset_incremental_state", "(", ")", "\n", "return", "self", ".", "_generate", "(", "sample", ",", "prefix_tokens", ",", "bos_token", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yangkevin2_emnlp2020-stream-beam-mt.None.sequence_generator.SequenceGenerator.generate_batched_itr": [[253, 284], ["enumerate", "fairseq.utils.move_to_cuda", "timer.start", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "sequence_generator.SequenceGenerator.generate", "timer.stop", "fairseq.utils.strip_pad", "input.items", "sum", "fairseq.utils.strip_pad", "len"], "methods", ["home.repos.pwc.inspect_result.yangkevin2_emnlp2020-stream-beam-mt.None.sequence_generator.SequenceGeneratorWithAlignment.generate"], ["", "def", "generate_batched_itr", "(", "self", ",", "data_itr", ",", "beam_size", "=", "None", ",", "cuda", "=", "False", ",", "timer", "=", "None", ")", ":", "\n", "        ", "\"\"\"Iterate over a batched dataset and yield individual translations.\n        Args:\n            cuda (bool, optional): use GPU for generation\n            timer (StopwatchMeter, optional): time generations\n        \"\"\"", "\n", "for", "sample", "in", "data_itr", ":", "\n", "            ", "s", "=", "utils", ".", "move_to_cuda", "(", "sample", ")", "if", "cuda", "else", "sample", "\n", "if", "\"net_input\"", "not", "in", "s", ":", "\n", "                ", "continue", "\n", "", "input", "=", "s", "[", "\"net_input\"", "]", "\n", "# model.forward normally channels prev_output_tokens into the decoder", "\n", "# separately, but SequenceGenerator directly calls model.encoder", "\n", "encoder_input", "=", "{", "\n", "k", ":", "v", "for", "k", ",", "v", "in", "input", ".", "items", "(", ")", "if", "k", "!=", "\"prev_output_tokens\"", "\n", "}", "\n", "if", "timer", "is", "not", "None", ":", "\n", "                ", "timer", ".", "start", "(", ")", "\n", "", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "hypos", "=", "self", ".", "generate", "(", "encoder_input", ")", "\n", "", "if", "timer", "is", "not", "None", ":", "\n", "                ", "timer", ".", "stop", "(", "sum", "(", "len", "(", "h", "[", "0", "]", "[", "\"tokens\"", "]", ")", "for", "h", "in", "hypos", ")", ")", "\n", "", "for", "i", ",", "id", "in", "enumerate", "(", "s", "[", "\"id\"", "]", ".", "data", ")", ":", "\n", "# remove padding", "\n", "                ", "src", "=", "utils", ".", "strip_pad", "(", "input", "[", "\"src_tokens\"", "]", ".", "data", "[", "i", ",", ":", "]", ",", "self", ".", "pad", ")", "\n", "ref", "=", "(", "\n", "utils", ".", "strip_pad", "(", "s", "[", "\"target\"", "]", ".", "data", "[", "i", ",", ":", "]", ",", "self", ".", "pad", ")", "\n", "if", "s", "[", "\"target\"", "]", "is", "not", "None", "\n", "else", "None", "\n", ")", "\n", "yield", "id", ",", "src", ",", "ref", ",", "hypos", "[", "i", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.yangkevin2_emnlp2020-stream-beam-mt.None.sequence_generator.SequenceGenerator.greedy": [[285, 293], ["torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "min", "greedy.predict_greedy", "int", "sequence_generator.SequenceGenerator.model.max_decoder_positions"], "methods", ["home.repos.pwc.inspect_result.yangkevin2_emnlp2020-stream-beam-mt.None.greedy.predict_greedy", "home.repos.pwc.inspect_result.yangkevin2_emnlp2020-stream-beam-mt.None.sequence_generator.EnsembleModel.max_decoder_positions"], ["", "", "", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "greedy", "(", "self", ",", "models", ",", "sample", ":", "Dict", "[", "str", ",", "Dict", "[", "str", ",", "Tensor", "]", "]", ",", "**", "kwargs", ")", ":", "\n", "        ", "max_len", "=", "min", "(", "\n", "int", "(", "self", ".", "max_len_b", ")", ",", "\n", "# exclude the EOS marker", "\n", "self", ".", "model", ".", "max_decoder_positions", "(", ")", "-", "1", ",", "\n", ")", "\n", "return", "predict_greedy", "(", "self", ",", "models", ",", "sample", ",", "max_len", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yangkevin2_emnlp2020-stream-beam-mt.None.sequence_generator.SequenceGenerator.variable_beam": [[294, 302], ["torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "min", "variable_stream.variable_beam_stream_fast", "int", "sequence_generator.SequenceGenerator.model.max_decoder_positions"], "methods", ["home.repos.pwc.inspect_result.yangkevin2_emnlp2020-stream-beam-mt.None.variable_stream.variable_beam_stream_fast", "home.repos.pwc.inspect_result.yangkevin2_emnlp2020-stream-beam-mt.None.sequence_generator.EnsembleModel.max_decoder_positions"], ["", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "variable_beam", "(", "self", ",", "model", ",", "sample", ",", "ap", "=", "1e8", ",", "mc", "=", "1", ",", "bos_token", "=", "None", ")", ":", "\n", "        ", "max_len", "=", "min", "(", "\n", "int", "(", "self", ".", "max_len_b", ")", ",", "\n", "# exclude the EOS marker", "\n", "self", ".", "model", ".", "max_decoder_positions", "(", ")", "-", "1", ",", "\n", ")", "\n", "return", "variable_beam_stream_fast", "(", "self", ",", "model", ",", "sample", ",", "self", ".", "beam_size", ",", "max_len", ",", "ap", "=", "ap", ",", "mc", "=", "mc", ",", "find_top_z", "=", "self", ".", "beam_size", ",", "max_indices", "=", "model", ".", "args", ".", "max_tokens", ",", "max_si_tokens", "=", "2", "*", "model", ".", "args", ".", "max_tokens", ",", "len_penalty", "=", "self", ".", "len_penalty", ",", "one_batch", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yangkevin2_emnlp2020-stream-beam-mt.None.sequence_generator.SequenceGenerator.variable_beam_stream": [[303, 311], ["torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "min", "variable_stream.variable_beam_stream_fast", "int", "sequence_generator.SequenceGenerator.model.max_decoder_positions"], "methods", ["home.repos.pwc.inspect_result.yangkevin2_emnlp2020-stream-beam-mt.None.variable_stream.variable_beam_stream_fast", "home.repos.pwc.inspect_result.yangkevin2_emnlp2020-stream-beam-mt.None.sequence_generator.EnsembleModel.max_decoder_positions"], ["", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "variable_beam_stream", "(", "self", ",", "model", ",", "tokenized_sentences", ",", "ap", "=", "1e8", ",", "mc", "=", "1", ",", "eps", "=", "1.", "/", "6", ",", "bos_token", "=", "None", ")", ":", "\n", "        ", "max_len", "=", "min", "(", "\n", "int", "(", "self", ".", "max_len_b", ")", ",", "\n", "# exclude the EOS marker", "\n", "self", ".", "model", ".", "max_decoder_positions", "(", ")", "-", "1", ",", "\n", ")", "\n", "return", "variable_beam_stream_fast", "(", "self", ",", "model", ",", "tokenized_sentences", ",", "self", ".", "beam_size", ",", "max_len", ",", "ap", "=", "ap", ",", "mc", "=", "mc", ",", "find_top_z", "=", "self", ".", "beam_size", ",", "max_indices", "=", "model", ".", "args", ".", "max_tokens", ",", "max_si_tokens", "=", "model", ".", "args", ".", "max_tokens", "*", "(", "1", "/", "(", "1", "-", "eps", ")", ")", ",", "len_penalty", "=", "self", ".", "len_penalty", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yangkevin2_emnlp2020-stream-beam-mt.None.sequence_generator.SequenceGenerator.generate": [[312, 326], ["torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "sequence_generator.SequenceGenerator.model.reset_incremental_state", "sequence_generator.SequenceGenerator._generate"], "methods", ["home.repos.pwc.inspect_result.yangkevin2_emnlp2020-stream-beam-mt.None.sequence_generator.EnsembleModel.reset_incremental_state", "home.repos.pwc.inspect_result.yangkevin2_emnlp2020-stream-beam-mt.None.sequence_generator.SequenceGenerator._generate"], ["", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "generate", "(", "self", ",", "models", ",", "sample", ":", "Dict", "[", "str", ",", "Dict", "[", "str", ",", "Tensor", "]", "]", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"Generate translations. Match the api of other fairseq generators.\n\n        Args:\n            models (List[~fairseq.models.FairseqModel]): ensemble of models\n            sample (dict): batch\n            prefix_tokens (torch.LongTensor, optional): force decoder to begin\n                with these tokens\n            bos_token (int, optional): beginning of sentence token\n                (default: self.eos)\n        \"\"\"", "\n", "self", ".", "model", ".", "reset_incremental_state", "(", ")", "\n", "return", "self", ".", "_generate", "(", "sample", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yangkevin2_emnlp2020-stream-beam-mt.None.sequence_generator.SequenceGenerator._generate": [[327, 641], ["src_tokens.size", "sequence_generator.SequenceGenerator.model.forward_encoder", "torch.arange().view().repeat().view", "torch.arange().view().repeat().view", "torch.arange().view().repeat().view", "torch.arange().view().repeat().view", "new_order.to().long.to().long.to().long", "sequence_generator.SequenceGenerator.model.reorder_encoder_out", "torch.zeros().to().float", "torch.zeros().to().float", "torch.zeros().to().float", "torch.zeros().to().float", "torch.zeros().to().long().fill_", "torch.zeros().to().long().fill_", "torch.zeros().to().long().fill_", "torch.zeros().to().long().fill_", "torch.zeros().to().eq", "torch.zeros().to().eq", "torch.zeros().to().eq", "torch.zeros().to().eq", "torch.jit.annotate", "torch.jit.annotate", "torch.jit.annotate", "torch.jit.annotate", "torch.arange().to", "torch.arange().to", "torch.arange().to", "torch.arange().to", "torch.arange().type_as", "torch.arange().type_as", "torch.arange().type_as", "torch.arange().type_as", "range", "range", "src_lengths.max().item", "min", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "sequence_generator.SequenceGenerator.model.forward_decoder", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "[].view.type_as", "torch.empty().to", "torch.empty().to", "torch.empty().to", "torch.empty().to", "torch.empty().to", "torch.empty().to", "torch.empty().to", "torch.empty().to", "sequence_generator.SequenceGenerator.search.set_src_lengths", "sequence_generator.SequenceGenerator.search.step", "cand_beams.add", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.masked_select", "torch.masked_select", "torch.masked_select", "torch.masked_select", "no_candidates_mask.nonzero().flatten", "set", "sequence_generator.SequenceGenerator.update", "sorted", "len", "torch.add", "torch.add", "torch.add", "torch.add", "torch.topk", "torch.topk", "torch.topk", "torch.topk", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "active_bbsz_idx.view.view.view", "active_scores.view.view.view", "torch.index_select", "torch.index_select", "torch.index_select", "torch.index_select", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "len", "BCList.sort", "BCList.reverse", "torch.jit.annotate", "torch.jit.annotate", "torch.jit.annotate", "torch.jit.annotate", "int", "torch.arange().view().repeat", "torch.arange().view().repeat", "torch.arange().view().repeat", "torch.arange().view().repeat", "new_order.to().long.to().long.to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to().long", "torch.zeros().to().long", "torch.zeros().to().long", "torch.zeros().to().long", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.jit.annotate", "torch.jit.annotate", "torch.jit.annotate", "torch.jit.annotate", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "range", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "sequence_generator.SequenceGenerator.model.reorder_incremental_state", "sequence_generator.SequenceGenerator.model.reorder_encoder_out", "sequence_generator.SequenceGenerator._prefix_tokens", "attn[].copy_", "sequence_generator.SequenceGenerator._no_repeat_ngram", "sequence_generator.SequenceGenerator.view", "cand_indices.eq", "cand_scores.ne", "torch.masked_select.numel", "torch.masked_select.numel", "torch.masked_select", "torch.masked_select", "torch.masked_select", "torch.masked_select", "sequence_generator.SequenceGenerator.finalize_hypos", "torch.max", "torch.max", "torch.max", "torch.max", "no_candidates_mask.nonzero().flatten.tolist", "list", "len", "torch.ones().to", "torch.ones().to", "torch.ones().to", "torch.ones().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.ones().to.nonzero().squeeze", "torch.ones().to.nonzero().squeeze", "bbsz_offsets.resize_", "cand_beams.add", "[].view", "[].view", "new_blacklist.ge", "active_scores.view.view.view", "[].view.view", "torch.index_select", "torch.index_select", "torch.index_select", "torch.index_select", "[].view.view", "torch.index_select", "torch.index_select", "torch.index_select", "torch.index_select", "sequence_generator.BeamContainer", "src_lengths.max", "sequence_generator.SequenceGenerator.model.max_decoder_positions", "range", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "reorder_state.view().add_", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "prefix_tokens.size", "torch.empty().to", "torch.empty().to", "torch.empty().to", "torch.empty().to", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "[].view.view", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "no_candidates_mask.nonzero", "len", "[].view", "eos_mask.type_as", "torch.max", "torch.max", "torch.max", "torch.max", "active_scores.view.view.view", "elem[].item", "torch.arange().view", "torch.arange().view", "torch.arange().view", "torch.arange().view", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.arange().type_as", "torch.arange().type_as", "torch.arange().type_as", "torch.arange().type_as", "active_cand_scores.max", "active_cand_scores.max", "active_cand_scores.max", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.ones().to.nonzero", "torch.ones().to.nonzero", "[].view.size", "eos_mask.size", "master_best_finished_score.unsqueeze", "src_tokens.ne", "src_tokens.ne", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.gather.long", "torch.gather.long", "reorder_state.view", "corr.unsqueeze", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "[].view.view", "[].view.view", "active_scores.view.view.view", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "avg_attn_scores.size", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "[].view.view", "torch.ones().to.nonzero().squeeze.numel"], "methods", ["home.repos.pwc.inspect_result.yangkevin2_emnlp2020-stream-beam-mt.None.sequence_generator.EnsembleModel.forward_encoder", "home.repos.pwc.inspect_result.yangkevin2_emnlp2020-stream-beam-mt.None.sequence_generator.EnsembleModel.reorder_encoder_out", "home.repos.pwc.inspect_result.yangkevin2_emnlp2020-stream-beam-mt.None.sequence_generator.EnsembleModel.forward_decoder", "home.repos.pwc.inspect_result.yangkevin2_emnlp2020-stream-beam-mt.None.sequence_generator.BeamSearch.step", "home.repos.pwc.inspect_result.yangkevin2_emnlp2020-stream-beam-mt.None.sequence_generator.EnsembleModel.reorder_incremental_state", "home.repos.pwc.inspect_result.yangkevin2_emnlp2020-stream-beam-mt.None.sequence_generator.EnsembleModel.reorder_encoder_out", "home.repos.pwc.inspect_result.yangkevin2_emnlp2020-stream-beam-mt.None.sequence_generator.SequenceGenerator._prefix_tokens", "home.repos.pwc.inspect_result.yangkevin2_emnlp2020-stream-beam-mt.None.sequence_generator.SequenceGenerator._no_repeat_ngram", "home.repos.pwc.inspect_result.yangkevin2_emnlp2020-stream-beam-mt.None.sequence_generator.SequenceGenerator.finalize_hypos", "home.repos.pwc.inspect_result.yangkevin2_emnlp2020-stream-beam-mt.None.sequence_generator.EnsembleModel.max_decoder_positions"], ["", "def", "_generate", "(", "\n", "self", ",", "\n", "sample", ":", "Dict", "[", "str", ",", "Dict", "[", "str", ",", "Tensor", "]", "]", ",", "\n", "prefix_tokens", ":", "Optional", "[", "Tensor", "]", "=", "None", ",", "\n", "bos_token", ":", "Optional", "[", "int", "]", "=", "None", ",", "\n", "ap", "=", "math", ".", "inf", ",", "\n", ")", ":", "# an old impl of variable beam search on fairseq infra", "\n", "#BGN", "\n", "        ", "n_loops", "=", "0", "\n", "n_expansions", "=", "0", "\n", "net_input", "=", "sample", "[", "\"net_input\"", "]", "\n", "src_tokens", "=", "net_input", "[", "\"src_tokens\"", "]", "\n", "# length of the source text being the character length except EndOfSentence and pad", "\n", "src_lengths", "=", "(", "\n", "(", "src_tokens", ".", "ne", "(", "self", ".", "eos", ")", "&", "src_tokens", ".", "ne", "(", "self", ".", "pad", ")", ")", ".", "long", "(", ")", ".", "sum", "(", "dim", "=", "1", ")", "\n", ")", "\n", "# bsz: total number of sentences in beam", "\n", "input_size", "=", "src_tokens", ".", "size", "(", ")", "\n", "bsz", ",", "src_len", "=", "input_size", "[", "0", "]", ",", "input_size", "[", "1", "]", "\n", "beam_size", "=", "self", ".", "beam_size", "\n", "\n", "max_len", ":", "int", "=", "-", "1", "\n", "if", "self", ".", "match_source_len", ":", "\n", "            ", "max_len", "=", "src_lengths", ".", "max", "(", ")", ".", "item", "(", ")", "\n", "", "else", ":", "\n", "            ", "max_len", "=", "min", "(", "\n", "int", "(", "self", ".", "max_len_a", "*", "src_len", "+", "self", ".", "max_len_b", ")", ",", "\n", "# exclude the EOS marker", "\n", "self", ".", "model", ".", "max_decoder_positions", "(", ")", "-", "1", ",", "\n", ")", "\n", "", "assert", "(", "\n", "self", ".", "min_len", "<=", "max_len", "\n", ")", ",", "\"min_len cannot be larger than max_len, please adjust these!\"", "\n", "# compute the encoder output for each beam", "\n", "encoder_outs", "=", "self", ".", "model", ".", "forward_encoder", "(", "net_input", ")", "\n", "\n", "# placeholder of indices for bsz * beam_size to hold tokens and accumulative scores", "\n", "new_order", "=", "torch", ".", "arange", "(", "bsz", ")", ".", "view", "(", "-", "1", ",", "1", ")", ".", "repeat", "(", "1", ",", "beam_size", ")", ".", "view", "(", "-", "1", ")", "\n", "new_order", "=", "new_order", ".", "to", "(", "src_tokens", ".", "device", ")", ".", "long", "(", ")", "\n", "encoder_outs", "=", "self", ".", "model", ".", "reorder_encoder_out", "(", "encoder_outs", ",", "new_order", ")", "\n", "# ensure encoder_outs is a List.", "\n", "assert", "encoder_outs", "is", "not", "None", "\n", "\n", "# initialize buffers", "\n", "scores", "=", "(", "\n", "torch", ".", "zeros", "(", "bsz", "*", "beam_size", ",", "max_len", "+", "1", ")", ".", "to", "(", "src_tokens", ")", ".", "float", "(", ")", "\n", ")", "# +1 for eos; pad is never choosed for scoring", "\n", "tokens", "=", "(", "\n", "torch", ".", "zeros", "(", "bsz", "*", "beam_size", ",", "max_len", "+", "2", ")", "\n", ".", "to", "(", "src_tokens", ")", "\n", ".", "long", "(", ")", "\n", ".", "fill_", "(", "self", ".", "pad", ")", "\n", ")", "# +2 for eos and pad", "\n", "tokens", "[", ":", ",", "0", "]", "=", "self", ".", "eos", "if", "bos_token", "is", "None", "else", "bos_token", "\n", "attn", ":", "Optional", "[", "Tensor", "]", "=", "None", "\n", "\n", "# The blacklist indicates candidates that should be ignored.", "\n", "# For example, suppose we're sampling and have already finalized 2/5", "\n", "# samples. Then the blacklist would mark 2 positions as being ignored,", "\n", "# so that we only finalize the remaining 3 samples.", "\n", "blacklist", "=", "(", "\n", "torch", ".", "zeros", "(", "bsz", ",", "beam_size", ")", ".", "to", "(", "src_tokens", ")", ".", "eq", "(", "-", "1", ")", "\n", ")", "# forward and backward-compatible False mask", "\n", "\n", "# list of completed sentences", "\n", "finalized", "=", "torch", ".", "jit", ".", "annotate", "(", "\n", "List", "[", "List", "[", "Dict", "[", "str", ",", "Tensor", "]", "]", "]", ",", "\n", "[", "torch", ".", "jit", ".", "annotate", "(", "List", "[", "Dict", "[", "str", ",", "Tensor", "]", "]", ",", "[", "]", ")", "for", "i", "in", "range", "(", "bsz", ")", "]", ",", "\n", ")", "# contains lists of dictionaries of infomation about the hypothesis being finalized at each step", "\n", "\n", "master_index", "=", "torch", ".", "arange", "(", "bsz", ")", ".", "to", "(", "src_tokens", ")", "\n", "master_best_finished_score", "=", "torch", ".", "zeros", "(", "bsz", ")", ".", "to", "(", "src_tokens", ")", "-", "math", ".", "inf", "\n", "finished", "=", "[", "\n", "False", "for", "i", "in", "range", "(", "bsz", ")", "\n", "]", "# a boolean array indicating if the sentence at the index is finished or not", "\n", "num_remaining_sent", "=", "bsz", "# number of sentences remaining", "\n", "\n", "# number of candidate hypos per step", "\n", "cand_size", "=", "2", "*", "beam_size", "# 2 x beam size in case half are EOS", "\n", "\n", "# offset arrays for converting between different indexing schemes", "\n", "bbsz_offsets", "=", "(", "torch", ".", "arange", "(", "0", ",", "bsz", ")", "*", "beam_size", ")", ".", "unsqueeze", "(", "1", ")", ".", "type_as", "(", "tokens", ")", "\n", "cand_offsets", "=", "torch", ".", "arange", "(", "0", ",", "cand_size", ")", ".", "type_as", "(", "tokens", ")", "\n", "\n", "reorder_state", ":", "Optional", "[", "Tensor", "]", "=", "None", "\n", "batch_idxs", ":", "Optional", "[", "Tensor", "]", "=", "None", "\n", "for", "step", "in", "range", "(", "max_len", "+", "1", ")", ":", "# one extra step for EOS marker", "\n", "            ", "n_loops", "+=", "1", "\n", "if", "step", "==", "0", ":", "\n", "                ", "n_expansions", "+=", "bsz", "\n", "", "else", ":", "\n", "                ", "n_expansions", "+=", "(", "1", "-", "blacklist", ".", "long", "(", ")", ")", ".", "sum", "(", ")", "\n", "# reorder decoder internal states based on the prev choice of beams", "\n", "# print(f'step: {step}')", "\n", "", "if", "reorder_state", "is", "not", "None", ":", "\n", "                ", "if", "batch_idxs", "is", "not", "None", ":", "\n", "# update beam indices to take into account removed sentences", "\n", "                    ", "corr", "=", "batch_idxs", "-", "torch", ".", "arange", "(", "batch_idxs", ".", "numel", "(", ")", ")", ".", "type_as", "(", "\n", "batch_idxs", "\n", ")", "\n", "reorder_state", ".", "view", "(", "-", "1", ",", "beam_size", ")", ".", "add_", "(", "\n", "corr", ".", "unsqueeze", "(", "-", "1", ")", "*", "beam_size", "\n", ")", "\n", "", "self", ".", "model", ".", "reorder_incremental_state", "(", "reorder_state", ")", "\n", "encoder_outs", "=", "self", ".", "model", ".", "reorder_encoder_out", "(", "\n", "encoder_outs", ",", "reorder_state", "\n", ")", "\n", "", "lprobs", ",", "avg_attn_scores", "=", "self", ".", "model", ".", "forward_decoder", "(", "\n", "tokens", "[", ":", ",", ":", "step", "+", "1", "]", ",", "encoder_outs", ",", "self", ".", "temperature", "\n", ")", "\n", "lprobs", "[", "lprobs", "!=", "lprobs", "]", "=", "torch", ".", "tensor", "(", "-", "math", ".", "inf", ")", ".", "to", "(", "lprobs", ")", "\n", "\n", "lprobs", "[", ":", ",", "self", ".", "pad", "]", "=", "-", "math", ".", "inf", "# never select pad", "\n", "lprobs", "[", ":", ",", "self", ".", "unk", "]", "-=", "self", ".", "unk_penalty", "# apply unk penalty", "\n", "\n", "# handle max length constraint", "\n", "if", "step", ">=", "max_len", ":", "\n", "                ", "lprobs", "[", ":", ",", ":", "self", ".", "eos", "]", "=", "-", "math", ".", "inf", "\n", "lprobs", "[", ":", ",", "self", ".", "eos", "+", "1", ":", "]", "=", "-", "math", ".", "inf", "\n", "\n", "# handle prefix tokens (possibly with different lengths)", "\n", "", "if", "(", "\n", "prefix_tokens", "is", "not", "None", "\n", "and", "step", "<", "prefix_tokens", ".", "size", "(", "1", ")", "\n", "and", "step", "<", "max_len", "\n", ")", ":", "\n", "                ", "lprobs", ",", "tokens", ",", "scores", "=", "self", ".", "_prefix_tokens", "(", "\n", "step", ",", "lprobs", ",", "scores", ",", "tokens", ",", "prefix_tokens", ",", "beam_size", "\n", ")", "\n", "", "elif", "step", "<", "self", ".", "min_len", ":", "\n", "# minimum length constraint (does not apply if using prefix_tokens)", "\n", "                ", "lprobs", "[", ":", ",", "self", ".", "eos", "]", "=", "-", "math", ".", "inf", "\n", "\n", "# Record attention scores, only support avg_attn_scores is a Tensor", "\n", "", "if", "avg_attn_scores", "is", "not", "None", ":", "\n", "                ", "if", "attn", "is", "None", ":", "\n", "                    ", "attn", "=", "torch", ".", "empty", "(", "\n", "bsz", "*", "beam_size", ",", "avg_attn_scores", ".", "size", "(", "1", ")", ",", "max_len", "+", "2", "\n", ")", ".", "to", "(", "scores", ")", "\n", "", "attn", "[", ":", ",", ":", ",", "step", "+", "1", "]", ".", "copy_", "(", "avg_attn_scores", ")", "\n", "\n", "", "scores", "=", "scores", ".", "type_as", "(", "lprobs", ")", "\n", "eos_bbsz_idx", "=", "torch", ".", "empty", "(", "0", ")", ".", "to", "(", "\n", "tokens", "\n", ")", "# indices of hypothesis ending with eos (finished sentences)", "\n", "eos_scores", "=", "torch", ".", "empty", "(", "0", ")", ".", "to", "(", "\n", "scores", "\n", ")", "# scores of hypothesis ending with eos (finished sentences)", "\n", "\n", "self", ".", "search", ".", "set_src_lengths", "(", "src_lengths", ")", "\n", "\n", "if", "self", ".", "no_repeat_ngram_size", ">", "0", ":", "\n", "                ", "lprobs", "=", "self", ".", "_no_repeat_ngram", "(", "tokens", ",", "lprobs", ",", "bsz", ",", "beam_size", ",", "step", ")", "\n", "\n", "", "cand_scores", ",", "cand_indices", ",", "cand_beams", "=", "self", ".", "search", ".", "step", "(", "\n", "step", ",", "\n", "lprobs", ".", "view", "(", "bsz", ",", "-", "1", ",", "self", ".", "vocab_size", ")", ",", "\n", "scores", ".", "view", "(", "bsz", ",", "beam_size", ",", "-", "1", ")", "[", ":", ",", ":", ",", ":", "step", "]", ",", "\n", ")", "\n", "\n", "# cand_bbsz_idx contains beam indices for the top candidate", "\n", "# hypotheses, with a range of values: [0, bsz*beam_size),", "\n", "# and dimensions: [bsz, cand_size]", "\n", "cand_bbsz_idx", "=", "cand_beams", ".", "add", "(", "bbsz_offsets", ")", "\n", "\n", "blacklist", "=", "torch", ".", "gather", "(", "blacklist", ",", "1", ",", "cand_beams", ")", "\n", "\n", "# finalize hypotheses that end in eos", "\n", "eos_mask", "=", "cand_indices", ".", "eq", "(", "self", ".", "eos", ")", "&", "cand_scores", ".", "ne", "(", "-", "math", ".", "inf", ")", "\n", "eos_mask", "[", "blacklist", "]", "=", "torch", ".", "tensor", "(", "0", ")", ".", "to", "(", "eos_mask", ")", "\n", "\n", "# only consider eos when it's among the top beam_size indices", "\n", "eos_bbsz_idx", "=", "torch", ".", "masked_select", "(", "\n", "cand_bbsz_idx", "[", ":", ",", ":", "beam_size", "]", ",", "mask", "=", "eos_mask", "[", ":", ",", ":", "beam_size", "]", "\n", ")", "\n", "\n", "finalized_sents", ":", "List", "[", "int", "]", "=", "[", "]", "\n", "if", "eos_bbsz_idx", ".", "numel", "(", ")", ">", "0", ":", "\n", "                ", "eos_scores", "=", "torch", ".", "masked_select", "(", "\n", "cand_scores", "[", ":", ",", ":", "beam_size", "]", ",", "mask", "=", "eos_mask", "[", ":", ",", ":", "beam_size", "]", "\n", ")", "\n", "finalized_sents", "=", "self", ".", "finalize_hypos", "(", "\n", "step", ",", "\n", "eos_bbsz_idx", ",", "\n", "eos_scores", ",", "\n", "tokens", ",", "\n", "scores", ",", "\n", "finalized", ",", "\n", "finished", ",", "\n", "master_best_finished_score", ",", "\n", "beam_size", ",", "\n", "attn", ",", "\n", "src_lengths", ",", "\n", "max_len", ",", "\n", ")", "\n", "\n", "# figure out which sents have no non-EOS with log prob > -math.inf TODO maybe this is repetitive with code below following if block", "\n", "", "active_cand_scores", "=", "(", "(", "cand_indices", "==", "self", ".", "eos", ")", "|", "blacklist", ")", ".", "float", "(", ")", "*", "(", "-", "math", ".", "inf", ")", "\n", "active_cand_scores", "[", "active_cand_scores", "!=", "active_cand_scores", "]", "=", "0", "\n", "active_cand_scores", "+=", "cand_scores", "\n", "ap_threshold", "=", "torch", ".", "max", "(", "master_best_finished_score", ",", "active_cand_scores", ".", "max", "(", "dim", "=", "1", ")", "[", "0", "]", ")", "-", "ap", "\n", "no_candidates_mask", "=", "(", "active_cand_scores", ".", "max", "(", "dim", "=", "1", ")", "[", "0", "]", "==", "-", "math", ".", "inf", ")", "|", "(", "active_cand_scores", ".", "max", "(", "dim", "=", "1", ")", "[", "0", "]", "<", "ap_threshold", ")", "# all pruned out, or will be by ap heuristic", "\n", "no_candidates_indices", "=", "no_candidates_mask", ".", "nonzero", "(", ")", ".", "flatten", "(", ")", "\n", "for", "master_idx", "in", "master_index", "[", "no_candidates_indices", "]", ":", "\n", "              ", "finished", "[", "master_idx", "]", "=", "True", "\n", "", "finalized_sents", "=", "set", "(", "finalized_sents", ")", "\n", "finalized_sents", ".", "update", "(", "no_candidates_indices", ".", "tolist", "(", ")", ")", "\n", "finalized_sents", "=", "sorted", "(", "list", "(", "finalized_sents", ")", ")", "\n", "\n", "num_remaining_sent", "-=", "len", "(", "finalized_sents", ")", "\n", "assert", "num_remaining_sent", ">=", "0", "\n", "if", "num_remaining_sent", "==", "0", ":", "\n", "                ", "break", "\n", "", "assert", "step", "<", "max_len", "\n", "\n", "if", "len", "(", "finalized_sents", ")", ">", "0", ":", "\n", "                ", "new_bsz", "=", "bsz", "-", "len", "(", "finalized_sents", ")", "\n", "\n", "# construct batch_idxs which holds indices of batches to keep for the next pass", "\n", "batch_mask", "=", "torch", ".", "ones", "(", "bsz", ")", ".", "to", "(", "cand_indices", ")", "\n", "batch_mask", "[", "\n", "torch", ".", "tensor", "(", "finalized_sents", ")", ".", "to", "(", "cand_indices", ")", "\n", "]", "=", "torch", ".", "tensor", "(", "0", ")", ".", "to", "(", "batch_mask", ")", "\n", "batch_idxs", "=", "batch_mask", ".", "nonzero", "(", ")", ".", "squeeze", "(", "-", "1", ")", "\n", "\n", "master_index", "=", "master_index", "[", "batch_idxs", "]", "\n", "master_best_finished_score", "=", "master_best_finished_score", "[", "batch_idxs", "]", "\n", "eos_mask", "=", "eos_mask", "[", "batch_idxs", "]", "\n", "cand_beams", "=", "cand_beams", "[", "batch_idxs", "]", "\n", "bbsz_offsets", ".", "resize_", "(", "new_bsz", ",", "1", ")", "\n", "cand_bbsz_idx", "=", "cand_beams", ".", "add", "(", "bbsz_offsets", ")", "\n", "cand_scores", "=", "cand_scores", "[", "batch_idxs", "]", "\n", "cand_indices", "=", "cand_indices", "[", "batch_idxs", "]", "\n", "\n", "if", "prefix_tokens", "is", "not", "None", ":", "\n", "                    ", "prefix_tokens", "=", "prefix_tokens", "[", "batch_idxs", "]", "\n", "", "src_lengths", "=", "src_lengths", "[", "batch_idxs", "]", "\n", "blacklist", "=", "blacklist", "[", "batch_idxs", "]", "\n", "\n", "scores", "=", "scores", ".", "view", "(", "bsz", ",", "-", "1", ")", "[", "batch_idxs", "]", ".", "view", "(", "new_bsz", "*", "beam_size", ",", "-", "1", ")", "\n", "tokens", "=", "tokens", ".", "view", "(", "bsz", ",", "-", "1", ")", "[", "batch_idxs", "]", ".", "view", "(", "new_bsz", "*", "beam_size", ",", "-", "1", ")", "\n", "if", "attn", "is", "not", "None", ":", "\n", "                    ", "attn", "=", "attn", ".", "view", "(", "bsz", ",", "-", "1", ")", "[", "batch_idxs", "]", ".", "view", "(", "\n", "new_bsz", "*", "beam_size", ",", "attn", ".", "size", "(", "1", ")", ",", "-", "1", "\n", ")", "\n", "", "bsz", "=", "new_bsz", "\n", "", "else", ":", "\n", "                ", "batch_idxs", "=", "None", "\n", "# set active_mask so that values > cand_size indicate eos hypos", "\n", "# and values < cand_size indicate candidate active hypos.", "\n", "# After, the min values per row are the top candidate active hypos", "\n", "\n", "# Rewrite the operator since the element wise or is not supported in torchscript.", "\n", "", "eos_mask", "=", "~", "(", "(", "~", "blacklist", ")", "&", "(", "~", "eos_mask", ")", ")", "\n", "active_mask", "=", "torch", ".", "add", "(", "\n", "eos_mask", ".", "type_as", "(", "cand_offsets", ")", "*", "cand_size", ",", "\n", "cand_offsets", "[", ":", "eos_mask", ".", "size", "(", "1", ")", "]", ",", "\n", ")", "\n", "# get the top beam_size active hypotheses, which are just the hypos", "\n", "# with the smallest values in active_mask", "\n", "new_blacklist", ",", "active_hypos", "=", "torch", ".", "topk", "(", "\n", "active_mask", ",", "k", "=", "beam_size", ",", "dim", "=", "1", ",", "largest", "=", "False", "\n", ")", "\n", "\n", "# update blacklist to ignore any finalized hypos", "\n", "blacklist", "=", "new_blacklist", ".", "ge", "(", "cand_size", ")", "[", ":", ",", ":", "beam_size", "]", "\n", "\n", "active_bbsz_idx", "=", "torch", ".", "gather", "(", "cand_bbsz_idx", ",", "dim", "=", "1", ",", "index", "=", "active_hypos", ")", "\n", "active_scores", "=", "torch", ".", "gather", "(", "cand_scores", ",", "dim", "=", "1", ",", "index", "=", "active_hypos", ")", "\n", "active_bbsz_idx", "=", "active_bbsz_idx", ".", "view", "(", "-", "1", ")", "\n", "active_scores", "=", "active_scores", ".", "view", "(", "-", "1", ")", "\n", "\n", "# update blacklist for variable size beam absolute prob heuristic", "\n", "ap_mask", "=", "active_scores", ".", "view", "(", "-", "1", ",", "beam_size", ")", "<", "torch", ".", "max", "(", "master_best_finished_score", ".", "unsqueeze", "(", "1", ")", ",", "active_scores", ".", "view", "(", "-", "1", ",", "beam_size", ")", "[", ":", ",", ":", "1", "]", ")", "-", "ap", "\n", "blacklist", "=", "blacklist", "|", "ap_mask", "|", "(", "active_scores", ".", "view", "(", "-", "1", ",", "beam_size", ")", "==", "-", "math", ".", "inf", ")", "\n", "assert", "(", "~", "blacklist", ")", ".", "any", "(", "dim", "=", "1", ")", ".", "all", "(", ")", "\n", "\n", "# copy tokens and scores for active hypotheses", "\n", "tokens", "[", ":", ",", ":", "step", "+", "1", "]", "=", "torch", ".", "index_select", "(", "\n", "tokens", "[", ":", ",", ":", "step", "+", "1", "]", ",", "dim", "=", "0", ",", "index", "=", "active_bbsz_idx", "\n", ")", "\n", "tokens", ".", "view", "(", "bsz", ",", "beam_size", ",", "-", "1", ")", "[", ":", ",", ":", ",", "step", "+", "1", "]", "=", "torch", ".", "gather", "(", "\n", "cand_indices", ",", "dim", "=", "1", ",", "index", "=", "active_hypos", "\n", ")", "\n", "if", "step", ">", "0", ":", "\n", "                ", "scores", "[", ":", ",", ":", "step", "]", "=", "torch", ".", "index_select", "(", "\n", "scores", "[", ":", ",", ":", "step", "]", ",", "dim", "=", "0", ",", "index", "=", "active_bbsz_idx", "\n", ")", "\n", "", "scores", ".", "view", "(", "bsz", ",", "beam_size", ",", "-", "1", ")", "[", ":", ",", ":", ",", "step", "]", "=", "torch", ".", "gather", "(", "\n", "cand_scores", ",", "dim", "=", "1", ",", "index", "=", "active_hypos", "\n", ")", "\n", "# scores[blacklist.flatten()] - -math.inf", "\n", "# copy attention for active hypotheses", "\n", "if", "attn", "is", "not", "None", ":", "\n", "                ", "attn", "[", ":", ",", ":", ",", ":", "step", "+", "2", "]", "=", "torch", ".", "index_select", "(", "\n", "attn", "[", ":", ",", ":", ",", ":", "step", "+", "2", "]", ",", "dim", "=", "0", ",", "index", "=", "active_bbsz_idx", "\n", ")", "\n", "\n", "# reorder incremental state in decoder", "\n", "", "reorder_state", "=", "active_bbsz_idx", "\n", "\n", "# sort by score descending", "\n", "", "for", "sent", "in", "range", "(", "len", "(", "finalized", ")", ")", ":", "\n", "# make into beam container", "\n", "            ", "BCList", "=", "[", "\n", "BeamContainer", "(", "elem", "[", "\"score\"", "]", ".", "item", "(", ")", ",", "elem", ")", "for", "elem", "in", "finalized", "[", "sent", "]", "\n", "]", "\n", "BCList", ".", "sort", "(", ")", "\n", "BCList", ".", "reverse", "(", ")", "\n", "finalized", "[", "sent", "]", "=", "torch", ".", "jit", ".", "annotate", "(", "\n", "List", "[", "Dict", "[", "str", ",", "Tensor", "]", "]", ",", "[", "x", ".", "elem", "for", "x", "in", "BCList", "]", "\n", ")", "\n", "\n", "", "return", "finalized", ",", "n_loops", ",", "n_expansions", "\n", "\n"]], "home.repos.pwc.inspect_result.yangkevin2_emnlp2020-stream-beam-mt.None.sequence_generator.SequenceGenerator._prefix_tokens": [[642, 670], ["prefix_tokens[].unsqueeze().repeat().view", "sequence_generator.SequenceGenerator.gather", "prefix_tokens[].unsqueeze().repeat().view.ne", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "lprobs[].scatter", "prefix_tokens[].unsqueeze().repeat().view.eq", "prefix_tokens[].unsqueeze().repeat().view.eq.any", "prefix_tokens[].unsqueeze().repeat().view.unsqueeze", "prefix_toks[].unsqueeze", "sequence_generator.SequenceGenerator.replicate_first_beam", "sequence_generator.SequenceGenerator.replicate_first_beam", "sequence_generator.SequenceGenerator.replicate_first_beam", "prefix_tokens[].unsqueeze().repeat", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "tokens[].view", "prefix_tokens[].unsqueeze().repeat().view.eq.view", "sequence_generator.SequenceGenerator.size", "prefix_tokens[].unsqueeze"], "methods", ["home.repos.pwc.inspect_result.yangkevin2_emnlp2020-stream-beam-mt.None.sequence_generator.SequenceGenerator.replicate_first_beam", "home.repos.pwc.inspect_result.yangkevin2_emnlp2020-stream-beam-mt.None.sequence_generator.SequenceGenerator.replicate_first_beam", "home.repos.pwc.inspect_result.yangkevin2_emnlp2020-stream-beam-mt.None.sequence_generator.SequenceGenerator.replicate_first_beam"], ["", "def", "_prefix_tokens", "(", "\n", "self", ",", "step", ":", "int", ",", "lprobs", ",", "scores", ",", "tokens", ",", "prefix_tokens", ",", "beam_size", ":", "int", "\n", ")", ":", "\n", "        ", "\"\"\"Handle prefix tokens\"\"\"", "\n", "prefix_toks", "=", "prefix_tokens", "[", ":", ",", "step", "]", ".", "unsqueeze", "(", "-", "1", ")", ".", "repeat", "(", "1", ",", "beam_size", ")", ".", "view", "(", "-", "1", ")", "\n", "prefix_lprobs", "=", "lprobs", ".", "gather", "(", "-", "1", ",", "prefix_toks", ".", "unsqueeze", "(", "-", "1", ")", ")", "\n", "prefix_mask", "=", "prefix_toks", ".", "ne", "(", "self", ".", "pad", ")", "\n", "lprobs", "[", "prefix_mask", "]", "=", "torch", ".", "tensor", "(", "-", "math", ".", "inf", ")", ".", "to", "(", "lprobs", ")", "\n", "lprobs", "[", "prefix_mask", "]", "=", "lprobs", "[", "prefix_mask", "]", ".", "scatter", "(", "\n", "-", "1", ",", "prefix_toks", "[", "prefix_mask", "]", ".", "unsqueeze", "(", "-", "1", ")", ",", "prefix_lprobs", "[", "prefix_mask", "]", "\n", ")", "\n", "# if prefix includes eos, then we should make sure tokens and", "\n", "# scores are the same across all beams", "\n", "eos_mask", "=", "prefix_toks", ".", "eq", "(", "self", ".", "eos", ")", "\n", "if", "eos_mask", ".", "any", "(", ")", ":", "\n", "# validate that the first beam matches the prefix", "\n", "            ", "first_beam", "=", "tokens", "[", "eos_mask", "]", ".", "view", "(", "-", "1", ",", "beam_size", ",", "tokens", ".", "size", "(", "-", "1", ")", ")", "[", "\n", ":", ",", "0", ",", "1", ":", "step", "+", "1", "\n", "]", "\n", "eos_mask_batch_dim", "=", "eos_mask", ".", "view", "(", "-", "1", ",", "beam_size", ")", "[", ":", ",", "0", "]", "\n", "target_prefix", "=", "prefix_tokens", "[", "eos_mask_batch_dim", "]", "[", ":", ",", ":", "step", "]", "\n", "assert", "(", "first_beam", "==", "target_prefix", ")", ".", "all", "(", ")", "\n", "\n", "# copy tokens, scores and lprobs from the first beam to all beams", "\n", "tokens", "=", "self", ".", "replicate_first_beam", "(", "tokens", ",", "eos_mask_batch_dim", ",", "beam_size", ")", "\n", "scores", "=", "self", ".", "replicate_first_beam", "(", "scores", ",", "eos_mask_batch_dim", ",", "beam_size", ")", "\n", "lprobs", "=", "self", ".", "replicate_first_beam", "(", "lprobs", ",", "eos_mask_batch_dim", ",", "beam_size", ")", "\n", "", "return", "lprobs", ",", "tokens", ",", "scores", "\n", "\n"]], "home.repos.pwc.inspect_result.yangkevin2_emnlp2020-stream-beam-mt.None.sequence_generator.SequenceGenerator.replicate_first_beam": [[671, 675], ["tensor.view.view.view", "tensor.view.view.view", "tensor.view.view.size", "tensor.view.view.size"], "methods", ["None"], ["", "def", "replicate_first_beam", "(", "self", ",", "tensor", ",", "mask", ",", "beam_size", ":", "int", ")", ":", "\n", "        ", "tensor", "=", "tensor", ".", "view", "(", "-", "1", ",", "beam_size", ",", "tensor", ".", "size", "(", "-", "1", ")", ")", "\n", "tensor", "[", "mask", "]", "=", "tensor", "[", "mask", "]", "[", ":", ",", ":", "1", ",", ":", "]", "\n", "return", "tensor", ".", "view", "(", "-", "1", ",", "tensor", ".", "size", "(", "-", "1", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yangkevin2_emnlp2020-stream-beam-mt.None.sequence_generator.SequenceGenerator.finalize_hypos": [[676, 772], ["range", "sents_seen.keys", "bbsz_idx.numel", "eos_scores.numel", "tokens.index_select", "scores.index_select", "int", "int", "attn.index_select", "cum_unfin.append", "bbsz_idx.size", "str", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "len", "finalized[].append", "max", "float", "float", "sequence_generator.SequenceGenerator.is_finished", "newly_finished.append", "str", "unfin_idx.item", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "len", "sent.item", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "seen.split", "seen.split"], "methods", ["home.repos.pwc.inspect_result.yangkevin2_emnlp2020-stream-beam-mt.None.sequence_generator.SequenceGenerator.is_finished"], ["", "def", "finalize_hypos", "(", "\n", "self", ",", "\n", "step", ":", "int", ",", "\n", "bbsz_idx", ",", "\n", "eos_scores", ",", "\n", "tokens", ",", "\n", "scores", ",", "\n", "finalized", ":", "List", "[", "List", "[", "Dict", "[", "str", ",", "Tensor", "]", "]", "]", ",", "\n", "finished", ":", "List", "[", "bool", "]", ",", "\n", "master_best_finished_score", ":", "Tensor", ",", "\n", "beam_size", ":", "int", ",", "\n", "attn", ":", "Optional", "[", "Tensor", "]", ",", "\n", "src_lengths", ",", "\n", "max_len", ":", "int", ",", "\n", ")", ":", "\n", "        ", "\"\"\"Finalize hypothesis, store finalized information in `finalized`, and change `finished` accordingly.\n        Returns number of sentences being finalized.\n        Args:\n            bbsz_idx (Tensor):\n        \"\"\"", "\n", "assert", "bbsz_idx", ".", "numel", "(", ")", "==", "eos_scores", ".", "numel", "(", ")", "\n", "\n", "# clone relevant token and attention tensors", "\n", "tokens_clone", "=", "tokens", ".", "index_select", "(", "0", ",", "bbsz_idx", ")", "[", "\n", ":", ",", "1", ":", "step", "+", "2", "\n", "]", "# skip the first index, which is EOS", "\n", "\n", "tokens_clone", "[", ":", ",", "step", "]", "=", "self", ".", "eos", "\n", "attn_clone", "=", "(", "\n", "attn", ".", "index_select", "(", "0", ",", "bbsz_idx", ")", "[", ":", ",", ":", ",", "1", ":", "step", "+", "2", "]", "\n", "if", "attn", "is", "not", "None", "\n", "else", "None", "\n", ")", "\n", "\n", "# compute scores per token position", "\n", "pos_scores", "=", "scores", ".", "index_select", "(", "0", ",", "bbsz_idx", ")", "[", ":", ",", ":", "step", "+", "1", "]", "\n", "pos_scores", "[", ":", ",", "step", "]", "=", "eos_scores", "\n", "# convert from cumulative to per-position scores", "\n", "pos_scores", "[", ":", ",", "1", ":", "]", "=", "pos_scores", "[", ":", ",", "1", ":", "]", "-", "pos_scores", "[", ":", ",", ":", "-", "1", "]", "\n", "\n", "# normalize sentence-level scores", "\n", "if", "self", ".", "normalize_scores", ":", "\n", "            ", "eos_scores", "/=", "(", "step", "+", "1", ")", "**", "self", ".", "len_penalty", "\n", "\n", "", "cum_unfin", ":", "List", "[", "int", "]", "=", "[", "]", "\n", "prev", "=", "0", "\n", "for", "f", "in", "finished", ":", "\n", "            ", "if", "f", ":", "\n", "                ", "prev", "+=", "1", "\n", "", "else", ":", "\n", "                ", "cum_unfin", ".", "append", "(", "prev", ")", "\n", "\n", "# set() is not supported in script export", "\n", "", "", "sents_seen", ":", "Dict", "[", "str", ",", "Optional", "[", "Tensor", "]", "]", "=", "{", "}", "\n", "for", "i", "in", "range", "(", "bbsz_idx", ".", "size", "(", ")", "[", "0", "]", ")", ":", "\n", "            ", "idx", "=", "bbsz_idx", "[", "i", "]", "\n", "score", "=", "eos_scores", "[", "i", "]", "\n", "unfin_idx", "=", "idx", "//", "beam_size", "\n", "sent", "=", "unfin_idx", "+", "cum_unfin", "[", "unfin_idx", "]", "\n", "# Cannot create dict for key type '(int, int)' in torchscript.", "\n", "# The workaround is to cast int to string", "\n", "seen", "=", "str", "(", "sent", ".", "item", "(", ")", ")", "+", "\"_\"", "+", "str", "(", "unfin_idx", ".", "item", "(", ")", ")", "\n", "if", "seen", "not", "in", "sents_seen", ":", "\n", "                ", "sents_seen", "[", "seen", "]", "=", "None", "\n", "\n", "", "if", "self", ".", "match_source_len", "and", "step", ">", "src_lengths", "[", "unfin_idx", "]", ":", "\n", "                ", "score", "=", "torch", ".", "tensor", "(", "-", "math", ".", "inf", ")", ".", "to", "(", "score", ")", "\n", "\n", "", "if", "len", "(", "finalized", "[", "sent", "]", ")", "<", "beam_size", ":", "\n", "                ", "if", "attn_clone", "is", "not", "None", ":", "\n", "# remove padding tokens from attn scores", "\n", "                    ", "hypo_attn", "=", "attn_clone", "[", "i", "]", "\n", "", "else", ":", "\n", "                    ", "hypo_attn", "=", "torch", ".", "empty", "(", "0", ")", "\n", "", "finalized", "[", "sent", "]", ".", "append", "(", "\n", "{", "\n", "\"tokens\"", ":", "tokens_clone", "[", "i", "]", ",", "\n", "\"score\"", ":", "score", ",", "\n", "\"attention\"", ":", "hypo_attn", ",", "# src_len x tgt_len", "\n", "\"alignment\"", ":", "torch", ".", "empty", "(", "0", ")", ",", "\n", "\"positional_scores\"", ":", "pos_scores", "[", "i", "]", ",", "\n", "}", "\n", ")", "\n", "master_best_finished_score", "[", "unfin_idx", "]", "=", "max", "(", "score", ",", "master_best_finished_score", "[", "unfin_idx", "]", ")", "\n", "\n", "", "", "newly_finished", ":", "List", "[", "int", "]", "=", "[", "]", "\n", "for", "seen", "in", "sents_seen", ".", "keys", "(", ")", ":", "\n", "# check termination conditions for this sentence", "\n", "            ", "sent", ":", "int", "=", "int", "(", "float", "(", "seen", ".", "split", "(", "\"_\"", ")", "[", "0", "]", ")", ")", "\n", "unfin_idx", ":", "int", "=", "int", "(", "float", "(", "seen", ".", "split", "(", "\"_\"", ")", "[", "1", "]", ")", ")", "\n", "if", "not", "finished", "[", "sent", "]", "and", "self", ".", "is_finished", "(", "\n", "step", ",", "unfin_idx", ",", "max_len", ",", "len", "(", "finalized", "[", "sent", "]", ")", ",", "beam_size", "\n", ")", ":", "\n", "                ", "finished", "[", "sent", "]", "=", "True", "\n", "newly_finished", ".", "append", "(", "unfin_idx", ")", "\n", "", "", "return", "newly_finished", "\n", "\n"]], "home.repos.pwc.inspect_result.yangkevin2_emnlp2020-stream-beam-mt.None.sequence_generator.SequenceGenerator.is_finished": [[773, 790], ["None"], "methods", ["None"], ["", "def", "is_finished", "(", "\n", "self", ",", "\n", "step", ":", "int", ",", "\n", "unfin_idx", ":", "int", ",", "\n", "max_len", ":", "int", ",", "\n", "finalized_sent_len", ":", "int", ",", "\n", "beam_size", ":", "int", ",", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Check whether we've finished generation for a given sentence, by\n        comparing the worst score among finalized hypotheses to the best\n        possible score among unfinalized hypotheses.\n        \"\"\"", "\n", "assert", "finalized_sent_len", "<=", "beam_size", "\n", "if", "finalized_sent_len", "==", "beam_size", "or", "step", "==", "max_len", ":", "\n", "            ", "return", "True", "\n", "", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.yangkevin2_emnlp2020-stream-beam-mt.None.sequence_generator.SequenceGenerator.calculate_banned_tokens": [[791, 805], ["tokens[].tolist", "gen_ngrams[].get", "torch.jit.annotate", "torch.jit.annotate", "torch.jit.annotate", "torch.jit.annotate", "str"], "methods", ["None"], ["", "def", "calculate_banned_tokens", "(", "\n", "self", ",", "\n", "tokens", ",", "\n", "step", ":", "int", ",", "\n", "gen_ngrams", ":", "List", "[", "Dict", "[", "str", ",", "List", "[", "int", "]", "]", "]", ",", "\n", "no_repeat_ngram_size", ":", "int", ",", "\n", "bbsz_idx", ":", "int", ",", "\n", ")", ":", "\n", "        ", "tokens_list", ":", "List", "[", "int", "]", "=", "tokens", "[", "\n", "bbsz_idx", ",", "step", "+", "2", "-", "no_repeat_ngram_size", ":", "step", "+", "1", "\n", "]", ".", "tolist", "(", ")", "\n", "# before decoding the next token, prevent decoding of ngrams that have already appeared", "\n", "ngram_index", "=", "\",\"", ".", "join", "(", "[", "str", "(", "x", ")", "for", "x", "in", "tokens_list", "]", ")", "\n", "return", "gen_ngrams", "[", "bbsz_idx", "]", ".", "get", "(", "ngram_index", ",", "torch", ".", "jit", ".", "annotate", "(", "List", "[", "int", "]", ",", "[", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yangkevin2_emnlp2020-stream-beam-mt.None.sequence_generator.SequenceGenerator.transpose_list": [[806, 811], ["min", "len", "range"], "methods", ["None"], ["", "def", "transpose_list", "(", "self", ",", "l", ":", "List", "[", "List", "[", "int", "]", "]", ")", ":", "\n", "# GeneratorExp aren't supported in TS so ignoring the lint", "\n", "        ", "min_len", "=", "min", "(", "[", "len", "(", "x", ")", "for", "x", "in", "l", "]", ")", "# noqa", "\n", "l2", "=", "[", "[", "row", "[", "i", "]", "for", "row", "in", "l", "]", "for", "i", "in", "range", "(", "min_len", ")", "]", "\n", "return", "l2", "\n", "\n"]], "home.repos.pwc.inspect_result.yangkevin2_emnlp2020-stream-beam-mt.None.sequence_generator.SequenceGenerator._no_repeat_ngram": [[812, 846], ["tokens.cpu", "range", "range", "torch.jit.annotate", "torch.jit.annotate", "torch.jit.annotate", "torch.jit.annotate", "cpu_tokens[].tolist", "sequence_generator.SequenceGenerator.transpose_list", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "range", "sequence_generator.SequenceGenerator.calculate_banned_tokens", "torch.jit.annotate", "torch.jit.annotate", "torch.jit.annotate", "torch.jit.annotate", "gen_ngrams[].get", "range", "range", "torch.tensor().long", "torch.tensor().long", "torch.tensor().long", "torch.tensor().long", "range", "str", "torch.jit.annotate", "torch.jit.annotate", "torch.jit.annotate", "torch.jit.annotate", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor"], "methods", ["home.repos.pwc.inspect_result.yangkevin2_emnlp2020-stream-beam-mt.None.sequence_generator.SequenceGenerator.transpose_list", "home.repos.pwc.inspect_result.yangkevin2_emnlp2020-stream-beam-mt.None.sequence_generator.SequenceGenerator.calculate_banned_tokens"], ["", "def", "_no_repeat_ngram", "(", "self", ",", "tokens", ",", "lprobs", ",", "bsz", ":", "int", ",", "beam_size", ":", "int", ",", "step", ":", "int", ")", ":", "\n", "# for each beam and batch sentence, generate a list of previous ngrams", "\n", "        ", "gen_ngrams", ":", "List", "[", "Dict", "[", "str", ",", "List", "[", "int", "]", "]", "]", "=", "[", "\n", "torch", ".", "jit", ".", "annotate", "(", "Dict", "[", "str", ",", "List", "[", "int", "]", "]", ",", "{", "}", ")", "\n", "for", "bbsz_idx", "in", "range", "(", "bsz", "*", "beam_size", ")", "\n", "]", "\n", "cpu_tokens", "=", "tokens", ".", "cpu", "(", ")", "\n", "for", "bbsz_idx", "in", "range", "(", "bsz", "*", "beam_size", ")", ":", "\n", "            ", "gen_tokens", ":", "List", "[", "int", "]", "=", "cpu_tokens", "[", "bbsz_idx", "]", ".", "tolist", "(", ")", "\n", "for", "ngram", "in", "self", ".", "transpose_list", "(", "\n", "[", "gen_tokens", "[", "i", ":", "]", "for", "i", "in", "range", "(", "self", ".", "no_repeat_ngram_size", ")", "]", "\n", ")", ":", "\n", "                ", "key", "=", "\",\"", ".", "join", "(", "[", "str", "(", "x", ")", "for", "x", "in", "ngram", "[", ":", "-", "1", "]", "]", ")", "\n", "gen_ngrams", "[", "bbsz_idx", "]", "[", "key", "]", "=", "gen_ngrams", "[", "bbsz_idx", "]", ".", "get", "(", "\n", "key", ",", "torch", ".", "jit", ".", "annotate", "(", "List", "[", "int", "]", ",", "[", "]", ")", "\n", ")", "+", "[", "ngram", "[", "-", "1", "]", "]", "\n", "\n", "", "", "if", "step", "+", "2", "-", "self", ".", "no_repeat_ngram_size", ">=", "0", ":", "\n", "# no banned tokens if we haven't generated no_repeat_ngram_size tokens yet", "\n", "            ", "banned_tokens", "=", "[", "\n", "self", ".", "calculate_banned_tokens", "(", "\n", "tokens", ",", "step", ",", "gen_ngrams", ",", "self", ".", "no_repeat_ngram_size", ",", "bbsz_idx", "\n", ")", "\n", "for", "bbsz_idx", "in", "range", "(", "bsz", "*", "beam_size", ")", "\n", "]", "\n", "", "else", ":", "\n", "            ", "banned_tokens", "=", "[", "\n", "torch", ".", "jit", ".", "annotate", "(", "List", "[", "int", "]", ",", "[", "]", ")", "for", "bbsz_idx", "in", "range", "(", "bsz", "*", "beam_size", ")", "\n", "]", "\n", "", "for", "bbsz_idx", "in", "range", "(", "bsz", "*", "beam_size", ")", ":", "\n", "            ", "lprobs", "[", "bbsz_idx", "]", "[", "\n", "torch", ".", "tensor", "(", "banned_tokens", "[", "bbsz_idx", "]", ")", ".", "long", "(", ")", "\n", "]", "=", "torch", ".", "tensor", "(", "-", "math", ".", "inf", ",", "dtype", "=", "torch", ".", "float", ")", "\n", "", "return", "lprobs", "\n", "\n"]], "home.repos.pwc.inspect_result.yangkevin2_emnlp2020-stream-beam-mt.None.sequence_generator.EnsembleModel.__init__": [[853, 873], ["torch.Module.__init__", "len", "torch.ModuleList", "torch.ModuleList", "torch.jit.annotate", "torch.jit.annotate", "torch.jit.annotate", "torch.jit.annotate", "all", "torch.jit.annotate", "torch.jit.annotate", "torch.jit.annotate", "torch.jit.annotate", "range", "hasattr", "isinstance"], "methods", ["home.repos.pwc.inspect_result.yangkevin2_emnlp2020-stream-beam-mt.None.sequence_generator.BeamContainer.__init__"], ["def", "__init__", "(", "self", ",", "models", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "models_size", "=", "len", "(", "models", ")", "\n", "# method '__len__' is not supported in ModuleList for torch script", "\n", "self", ".", "single_model", "=", "models", "[", "0", "]", "\n", "self", ".", "models", "=", "nn", ".", "ModuleList", "(", "models", ")", "\n", "\n", "self", ".", "incremental_states", "=", "torch", ".", "jit", ".", "annotate", "(", "\n", "List", "[", "Dict", "[", "str", ",", "Dict", "[", "str", ",", "Optional", "[", "Tensor", "]", "]", "]", "]", ",", "\n", "[", "\n", "torch", ".", "jit", ".", "annotate", "(", "Dict", "[", "str", ",", "Dict", "[", "str", ",", "Optional", "[", "Tensor", "]", "]", "]", ",", "{", "}", ")", "\n", "for", "i", "in", "range", "(", "self", ".", "models_size", ")", "\n", "]", ",", "\n", ")", "\n", "self", ".", "has_incremental", ":", "bool", "=", "False", "\n", "if", "all", "(", "\n", "hasattr", "(", "m", ",", "\"decoder\"", ")", "and", "isinstance", "(", "m", ".", "decoder", ",", "FairseqIncrementalDecoder", ")", "\n", "for", "m", "in", "models", "\n", ")", ":", "\n", "            ", "self", ".", "has_incremental", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.yangkevin2_emnlp2020-stream-beam-mt.None.sequence_generator.EnsembleModel.forward": [[874, 876], ["None"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.yangkevin2_emnlp2020-stream-beam-mt.None.sequence_generator.EnsembleModel.reset_incremental_state": [[877, 887], ["sequence_generator.EnsembleModel.has_incremental_states", "torch.jit.annotate", "torch.jit.annotate", "torch.jit.annotate", "torch.jit.annotate", "torch.jit.annotate", "torch.jit.annotate", "torch.jit.annotate", "torch.jit.annotate", "range"], "methods", ["home.repos.pwc.inspect_result.yangkevin2_emnlp2020-stream-beam-mt.None.sequence_generator.EnsembleModel.has_incremental_states"], ["", "def", "reset_incremental_state", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "has_incremental_states", "(", ")", ":", "\n", "            ", "self", ".", "incremental_states", "=", "torch", ".", "jit", ".", "annotate", "(", "\n", "List", "[", "Dict", "[", "str", ",", "Dict", "[", "str", ",", "Optional", "[", "Tensor", "]", "]", "]", "]", ",", "\n", "[", "\n", "torch", ".", "jit", ".", "annotate", "(", "Dict", "[", "str", ",", "Dict", "[", "str", ",", "Optional", "[", "Tensor", "]", "]", "]", ",", "{", "}", ")", "\n", "for", "i", "in", "range", "(", "self", ".", "models_size", ")", "\n", "]", ",", "\n", ")", "\n", "", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.yangkevin2_emnlp2020-stream-beam-mt.None.sequence_generator.EnsembleModel.has_encoder": [[888, 890], ["hasattr"], "methods", ["None"], ["", "def", "has_encoder", "(", "self", ")", ":", "\n", "        ", "return", "hasattr", "(", "self", ".", "single_model", ",", "\"encoder\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yangkevin2_emnlp2020-stream-beam-mt.None.sequence_generator.EnsembleModel.has_incremental_states": [[891, 893], ["None"], "methods", ["None"], ["", "def", "has_incremental_states", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "has_incremental", "\n", "\n"]], "home.repos.pwc.inspect_result.yangkevin2_emnlp2020-stream-beam-mt.None.sequence_generator.EnsembleModel.max_decoder_positions": [[894, 896], ["min", "m.max_decoder_positions"], "methods", ["home.repos.pwc.inspect_result.yangkevin2_emnlp2020-stream-beam-mt.None.sequence_generator.EnsembleModel.max_decoder_positions"], ["", "def", "max_decoder_positions", "(", "self", ")", ":", "\n", "        ", "return", "min", "(", "[", "m", ".", "max_decoder_positions", "(", ")", "for", "m", "in", "self", ".", "models", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yangkevin2_emnlp2020-stream-beam-mt.None.sequence_generator.EnsembleModel.forward_encoder": [[897, 904], ["sequence_generator.EnsembleModel.has_encoder", "model.encoder.forward_torchscript"], "methods", ["home.repos.pwc.inspect_result.yangkevin2_emnlp2020-stream-beam-mt.None.sequence_generator.EnsembleModel.has_encoder"], ["", "@", "torch", ".", "jit", ".", "export", "\n", "def", "forward_encoder", "(", "self", ",", "net_input", ":", "Dict", "[", "str", ",", "Tensor", "]", ")", ":", "\n", "        ", "if", "not", "self", ".", "has_encoder", "(", ")", ":", "\n", "            ", "return", "None", "\n", "", "return", "[", "\n", "model", ".", "encoder", ".", "forward_torchscript", "(", "net_input", ")", "\n", "for", "model", "in", "self", ".", "models", "\n", "]", "\n"]], "home.repos.pwc.inspect_result.yangkevin2_emnlp2020-stream-beam-mt.None.sequence_generator.EnsembleModel.forward_decoder": [[906, 964], ["enumerate", "sequence_generator.EnsembleModel.has_encoder", "sequence_generator.EnsembleModel.has_incremental_states", "len", "model.get_normalized_probs", "log_probs.append", "torch.logsumexp", "torch.logsumexp", "torch.logsumexp", "torch.logsumexp", "math.log", "avg_attn.div_", "model.decoder.forward", "model.decoder.forward", "isinstance", "[].div_", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "isinstance", "avg_attn.add_"], "methods", ["home.repos.pwc.inspect_result.yangkevin2_emnlp2020-stream-beam-mt.None.sequence_generator.EnsembleModel.has_encoder", "home.repos.pwc.inspect_result.yangkevin2_emnlp2020-stream-beam-mt.None.sequence_generator.EnsembleModel.has_incremental_states", "home.repos.pwc.inspect_result.yangkevin2_emnlp2020-stream-beam-mt.None.sequence_generator.EnsembleModel.forward", "home.repos.pwc.inspect_result.yangkevin2_emnlp2020-stream-beam-mt.None.sequence_generator.EnsembleModel.forward"], ["", "@", "torch", ".", "jit", ".", "export", "\n", "def", "forward_decoder", "(", "\n", "self", ",", "tokens", ",", "encoder_outs", ",", "temperature", ":", "float", "=", "1.0", "\n", ")", ":", "\n", "        ", "log_probs", "=", "[", "]", "\n", "avg_attn", ":", "Optional", "[", "Tensor", "]", "=", "None", "\n", "encoder_out", "=", "None", "\n", "for", "i", ",", "model", "in", "enumerate", "(", "self", ".", "models", ")", ":", "\n", "            ", "if", "self", ".", "has_encoder", "(", ")", ":", "\n", "                ", "encoder_out", "=", "encoder_outs", "[", "i", "]", "\n", "# decode each model", "\n", "", "if", "self", ".", "has_incremental_states", "(", ")", ":", "\n", "                ", "decoder_out", "=", "model", ".", "decoder", ".", "forward", "(", "\n", "tokens", ",", "\n", "encoder_out", "=", "encoder_out", ",", "\n", "incremental_state", "=", "self", ".", "incremental_states", "[", "i", "]", ",", "\n", ")", "\n", "", "else", ":", "\n", "                ", "decoder_out", "=", "model", ".", "decoder", ".", "forward", "(", "tokens", ",", "encoder_out", "=", "encoder_out", ")", "\n", "\n", "", "attn", ":", "Optional", "[", "Tensor", "]", "=", "None", "\n", "decoder_len", "=", "len", "(", "decoder_out", ")", "\n", "if", "decoder_len", ">", "1", "and", "decoder_out", "[", "1", "]", "is", "not", "None", ":", "\n", "                ", "if", "isinstance", "(", "decoder_out", "[", "1", "]", ",", "Tensor", ")", ":", "\n", "                    ", "attn", "=", "decoder_out", "[", "1", "]", "\n", "", "else", ":", "\n", "                    ", "attn_holder", "=", "decoder_out", "[", "1", "]", "[", "\"attn\"", "]", "\n", "if", "isinstance", "(", "attn_holder", ",", "Tensor", ")", ":", "\n", "                        ", "attn", "=", "attn_holder", "\n", "", "elif", "attn_holder", "is", "not", "None", ":", "\n", "                        ", "attn", "=", "attn_holder", "[", "0", "]", "\n", "", "", "if", "attn", "is", "not", "None", ":", "\n", "                    ", "attn", "=", "attn", "[", ":", ",", "-", "1", ",", ":", "]", "\n", "\n", "", "", "decoder_out_tuple", "=", "(", "\n", "decoder_out", "[", "0", "]", "[", ":", ",", "-", "1", ":", ",", ":", "]", ".", "div_", "(", "temperature", ")", ",", "\n", "None", "if", "decoder_len", "<=", "1", "else", "decoder_out", "[", "1", "]", ",", "\n", ")", "\n", "\n", "probs", "=", "model", ".", "get_normalized_probs", "(", "\n", "decoder_out_tuple", ",", "log_probs", "=", "True", ",", "sample", "=", "None", "\n", ")", "\n", "probs", "=", "probs", "[", ":", ",", "-", "1", ",", ":", "]", "\n", "if", "self", ".", "models_size", "==", "1", ":", "\n", "                ", "return", "probs", ",", "attn", "\n", "\n", "", "log_probs", ".", "append", "(", "probs", ")", "\n", "if", "attn", "is", "not", "None", ":", "\n", "                ", "if", "avg_attn", "is", "None", ":", "\n", "                    ", "avg_attn", "=", "attn", "\n", "", "else", ":", "\n", "                    ", "avg_attn", ".", "add_", "(", "attn", ")", "\n", "", "", "", "avg_probs", "=", "torch", ".", "logsumexp", "(", "torch", ".", "stack", "(", "log_probs", ",", "dim", "=", "0", ")", ",", "dim", "=", "0", ")", "-", "math", ".", "log", "(", "\n", "self", ".", "models_size", "\n", ")", "\n", "if", "avg_attn", "is", "not", "None", ":", "\n", "            ", "avg_attn", ".", "div_", "(", "self", ".", "models_size", ")", "\n", "", "return", "avg_probs", ",", "avg_attn", "\n", "\n"]], "home.repos.pwc.inspect_result.yangkevin2_emnlp2020-stream-beam-mt.None.sequence_generator.EnsembleModel.reorder_encoder_out": [[965, 986], ["enumerate", "sequence_generator.EnsembleModel.has_encoder", "new_outs.append", "model.encoder.reorder_encoder_out"], "methods", ["home.repos.pwc.inspect_result.yangkevin2_emnlp2020-stream-beam-mt.None.sequence_generator.EnsembleModel.has_encoder", "home.repos.pwc.inspect_result.yangkevin2_emnlp2020-stream-beam-mt.None.sequence_generator.EnsembleModel.reorder_encoder_out"], ["", "@", "torch", ".", "jit", ".", "export", "\n", "def", "reorder_encoder_out", "(", "self", ",", "encoder_outs", ",", "new_order", ")", ":", "\n", "        ", "\"\"\"\n        Reorder encoder output according to *new_order*.\n\n        Args:\n            encoder_out: output from the ``forward()`` method\n            new_order (LongTensor): desired order\n\n        Returns:\n            *encoder_out* rearranged according to *new_order*\n        \"\"\"", "\n", "new_outs", "=", "[", "]", "\n", "if", "not", "self", ".", "has_encoder", "(", ")", ":", "\n", "            ", "return", "new_outs", "\n", "", "for", "i", ",", "model", "in", "enumerate", "(", "self", ".", "models", ")", ":", "\n", "            ", "assert", "encoder_outs", "is", "not", "None", "\n", "new_outs", ".", "append", "(", "\n", "model", ".", "encoder", ".", "reorder_encoder_out", "(", "encoder_outs", "[", "i", "]", ",", "new_order", ")", "\n", ")", "\n", "", "return", "new_outs", "\n", "\n"]], "home.repos.pwc.inspect_result.yangkevin2_emnlp2020-stream-beam-mt.None.sequence_generator.EnsembleModel.reorder_incremental_state": [[987, 994], ["enumerate", "sequence_generator.EnsembleModel.has_incremental_states", "model.decoder.reorder_incremental_state"], "methods", ["home.repos.pwc.inspect_result.yangkevin2_emnlp2020-stream-beam-mt.None.sequence_generator.EnsembleModel.has_incremental_states", "home.repos.pwc.inspect_result.yangkevin2_emnlp2020-stream-beam-mt.None.sequence_generator.EnsembleModel.reorder_incremental_state"], ["", "@", "torch", ".", "jit", ".", "export", "\n", "def", "reorder_incremental_state", "(", "self", ",", "new_order", ")", ":", "\n", "        ", "if", "not", "self", ".", "has_incremental_states", "(", ")", ":", "\n", "            ", "return", "\n", "", "for", "i", ",", "model", "in", "enumerate", "(", "self", ".", "models", ")", ":", "\n", "            ", "model", ".", "decoder", ".", "reorder_incremental_state", "(", "\n", "self", ".", "incremental_states", "[", "i", "]", ",", "new_order", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.yangkevin2_emnlp2020-stream-beam-mt.None.sequence_generator.SequenceGeneratorWithAlignment.__init__": [[998, 1011], ["sequence_generator.SequenceGenerator.__init__", "sequence_generator.EnsembleModelWithAlignment"], "methods", ["home.repos.pwc.inspect_result.yangkevin2_emnlp2020-stream-beam-mt.None.sequence_generator.BeamContainer.__init__"], ["    ", "def", "__init__", "(", "self", ",", "models", ",", "tgt_dict", ",", "left_pad_target", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"Generates translations of a given source sentence.\n\n        Produces alignments following \"Jointly Learning to Align and\n        Translate with Transformer Models\" (Garg et al., EMNLP 2019).\n\n        Args:\n            left_pad_target (bool, optional): Whether or not the\n                hypothesis should be left padded or not when they are\n                teacher forced for generating alignments.\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", "EnsembleModelWithAlignment", "(", "models", ")", ",", "tgt_dict", ",", "**", "kwargs", ")", "\n", "self", ".", "left_pad_target", "=", "left_pad_target", "\n", "\n"]], "home.repos.pwc.inspect_result.yangkevin2_emnlp2020-stream-beam-mt.None.sequence_generator.SequenceGeneratorWithAlignment.generate": [[1012, 1038], ["torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "sequence_generator.SequenceGeneratorWithAlignment.model.reset_incremental_state", "sequence_generator.SequenceGenerator._generate", "sequence_generator.SequenceGeneratorWithAlignment._prepare_batch_for_alignment", "any", "range", "sequence_generator.SequenceGeneratorWithAlignment.model.forward_align", "fairseq.utils.extract_hard_alignment", "getattr", "[].transpose", "range"], "methods", ["home.repos.pwc.inspect_result.yangkevin2_emnlp2020-stream-beam-mt.None.sequence_generator.EnsembleModel.reset_incremental_state", "home.repos.pwc.inspect_result.yangkevin2_emnlp2020-stream-beam-mt.None.sequence_generator.SequenceGenerator._generate", "home.repos.pwc.inspect_result.yangkevin2_emnlp2020-stream-beam-mt.None.sequence_generator.SequenceGeneratorWithAlignment._prepare_batch_for_alignment", "home.repos.pwc.inspect_result.yangkevin2_emnlp2020-stream-beam-mt.None.sequence_generator.EnsembleModelWithAlignment.forward_align"], ["", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "generate", "(", "self", ",", "models", ",", "sample", ",", "**", "kwargs", ")", ":", "\n", "        ", "self", ".", "model", ".", "reset_incremental_state", "(", ")", "\n", "finalized", "=", "super", "(", ")", ".", "_generate", "(", "sample", ",", "**", "kwargs", ")", "\n", "\n", "src_tokens", "=", "sample", "[", "\"net_input\"", "]", "[", "\"src_tokens\"", "]", "\n", "bsz", "=", "src_tokens", ".", "shape", "[", "0", "]", "\n", "beam_size", "=", "self", ".", "beam_size", "\n", "src_tokens", ",", "src_lengths", ",", "prev_output_tokens", ",", "tgt_tokens", "=", "self", ".", "_prepare_batch_for_alignment", "(", "\n", "sample", ",", "finalized", "\n", ")", "\n", "if", "any", "(", "getattr", "(", "m", ",", "\"full_context_alignment\"", ",", "False", ")", "for", "m", "in", "self", ".", "model", ".", "models", ")", ":", "\n", "            ", "attn", "=", "self", ".", "model", ".", "forward_align", "(", "src_tokens", ",", "src_lengths", ",", "prev_output_tokens", ")", "\n", "", "else", ":", "\n", "            ", "attn", "=", "[", "\n", "finalized", "[", "i", "//", "beam_size", "]", "[", "i", "%", "beam_size", "]", "[", "\"attention\"", "]", ".", "transpose", "(", "1", ",", "0", ")", "\n", "for", "i", "in", "range", "(", "bsz", "*", "beam_size", ")", "\n", "]", "\n", "\n", "# Process the attn matrix to extract hard alignments.", "\n", "", "for", "i", "in", "range", "(", "bsz", "*", "beam_size", ")", ":", "\n", "            ", "alignment", "=", "utils", ".", "extract_hard_alignment", "(", "\n", "attn", "[", "i", "]", ",", "src_tokens", "[", "i", "]", ",", "tgt_tokens", "[", "i", "]", ",", "self", ".", "pad", ",", "self", ".", "eos", "\n", ")", "\n", "finalized", "[", "i", "//", "beam_size", "]", "[", "i", "%", "beam_size", "]", "[", "\"alignment\"", "]", "=", "alignment", "\n", "", "return", "finalized", "\n", "\n"]], "home.repos.pwc.inspect_result.yangkevin2_emnlp2020-stream-beam-mt.None.sequence_generator.SequenceGeneratorWithAlignment._prepare_batch_for_alignment": [[1039, 1070], ["src_tokens[].expand().contiguous().view", "src_lengths[].expand().contiguous().view", "fairseq.data.data_utils.collate_tokens", "fairseq.data.data_utils.collate_tokens", "src_tokens[].expand().contiguous", "src_lengths[].expand().contiguous", "src_tokens[].expand", "src_lengths[].expand"], "methods", ["None"], ["", "def", "_prepare_batch_for_alignment", "(", "self", ",", "sample", ",", "hypothesis", ")", ":", "\n", "        ", "src_tokens", "=", "sample", "[", "\"net_input\"", "]", "[", "\"src_tokens\"", "]", "\n", "bsz", "=", "src_tokens", ".", "shape", "[", "0", "]", "\n", "src_tokens", "=", "(", "\n", "src_tokens", "[", ":", ",", "None", ",", ":", "]", "\n", ".", "expand", "(", "-", "1", ",", "self", ".", "beam_size", ",", "-", "1", ")", "\n", ".", "contiguous", "(", ")", "\n", ".", "view", "(", "bsz", "*", "self", ".", "beam_size", ",", "-", "1", ")", "\n", ")", "\n", "src_lengths", "=", "sample", "[", "\"net_input\"", "]", "[", "\"src_lengths\"", "]", "\n", "src_lengths", "=", "(", "\n", "src_lengths", "[", ":", ",", "None", "]", "\n", ".", "expand", "(", "-", "1", ",", "self", ".", "beam_size", ")", "\n", ".", "contiguous", "(", ")", "\n", ".", "view", "(", "bsz", "*", "self", ".", "beam_size", ")", "\n", ")", "\n", "prev_output_tokens", "=", "data_utils", ".", "collate_tokens", "(", "\n", "[", "beam", "[", "\"tokens\"", "]", "for", "example", "in", "hypothesis", "for", "beam", "in", "example", "]", ",", "\n", "self", ".", "pad", ",", "\n", "self", ".", "eos", ",", "\n", "self", ".", "left_pad_target", ",", "\n", "move_eos_to_beginning", "=", "True", ",", "\n", ")", "\n", "tgt_tokens", "=", "data_utils", ".", "collate_tokens", "(", "\n", "[", "beam", "[", "\"tokens\"", "]", "for", "example", "in", "hypothesis", "for", "beam", "in", "example", "]", ",", "\n", "self", ".", "pad", ",", "\n", "self", ".", "eos", ",", "\n", "self", ".", "left_pad_target", ",", "\n", "move_eos_to_beginning", "=", "False", ",", "\n", ")", "\n", "return", "src_tokens", ",", "src_lengths", ",", "prev_output_tokens", ",", "tgt_tokens", "\n", "\n"]], "home.repos.pwc.inspect_result.yangkevin2_emnlp2020-stream-beam-mt.None.sequence_generator.EnsembleModelWithAlignment.__init__": [[1075, 1077], ["sequence_generator.EnsembleModel.__init__"], "methods", ["home.repos.pwc.inspect_result.yangkevin2_emnlp2020-stream-beam-mt.None.sequence_generator.BeamContainer.__init__"], ["def", "__init__", "(", "self", ",", "models", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "models", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yangkevin2_emnlp2020-stream-beam-mt.None.sequence_generator.EnsembleModelWithAlignment.forward_align": [[1078, 1090], ["model", "len", "avg_attn.div_", "avg_attn.add_", "len"], "methods", ["None"], ["", "def", "forward_align", "(", "self", ",", "src_tokens", ",", "src_lengths", ",", "prev_output_tokens", ")", ":", "\n", "        ", "avg_attn", "=", "None", "\n", "for", "model", "in", "self", ".", "models", ":", "\n", "            ", "decoder_out", "=", "model", "(", "src_tokens", ",", "src_lengths", ",", "prev_output_tokens", ")", "\n", "attn", "=", "decoder_out", "[", "1", "]", "[", "\"attn\"", "]", "\n", "if", "avg_attn", "is", "None", ":", "\n", "                ", "avg_attn", "=", "attn", "\n", "", "else", ":", "\n", "                ", "avg_attn", ".", "add_", "(", "attn", ")", "\n", "", "", "if", "len", "(", "self", ".", "models", ")", ">", "1", ":", "\n", "            ", "avg_attn", ".", "div_", "(", "len", "(", "self", ".", "models", ")", ")", "\n", "", "return", "avg_attn", "\n", "\n"]], "home.repos.pwc.inspect_result.yangkevin2_emnlp2020-stream-beam-mt.None.sequence_generator.BeamContainer.__init__": [[1094, 1097], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "score", ":", "float", ",", "elem", ":", "Dict", "[", "str", ",", "Tensor", "]", ")", ":", "\n", "        ", "self", ".", "score", "=", "score", "\n", "self", ".", "elem", "=", "elem", "\n", "\n"]], "home.repos.pwc.inspect_result.yangkevin2_emnlp2020-stream-beam-mt.None.sequence_generator.BeamContainer.__lt__": [[1098, 1104], ["None"], "methods", ["None"], ["", "def", "__lt__", "(", "self", ",", "other", ")", ":", "\n", "# type: (BeamContainer) -> bool", "\n", "# Due to https://github.com/pytorch/pytorch/issues/20388,", "\n", "# this has to use old style type annotations", "\n", "# Match original behavior of sorted function when two scores are equal.", "\n", "        ", "return", "self", ".", "score", "<=", "other", ".", "score", "", "", "", ""]], "home.repos.pwc.inspect_result.yangkevin2_emnlp2020-stream-beam-mt.None.sequence_generator._lang_token": [[20, 22], ["None"], "function", ["None"], ["def", "_lang_token", "(", "lang", ":", "str", ")", ":", "\n", "    ", "return", "'__{}__'", ".", "format", "(", "lang", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yangkevin2_emnlp2020-stream-beam-mt.None.sequence_generator._lang_token_index": [[23, 29], ["dic.index", "sequence_generator._lang_token"], "function", ["home.repos.pwc.inspect_result.yangkevin2_emnlp2020-stream-beam-mt.None.sequence_generator._lang_token"], ["", "def", "_lang_token_index", "(", "dic", ",", "lang", ":", "str", ")", ":", "\n", "    ", "\"\"\"Return language token index.\"\"\"", "\n", "idx", "=", "dic", ".", "index", "(", "_lang_token", "(", "lang", ")", ")", "\n", "assert", "idx", "!=", "dic", ".", "unk_index", ",", "'cannot find language token for lang {}'", ".", "format", "(", "lang", ")", "\n", "return", "idx", "\n", "\n"]], "home.repos.pwc.inspect_result.yangkevin2_emnlp2020-stream-beam-mt.None.sequence_generator.build_generator": [[69, 152], ["getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "seq_gen_cls", "SequenceScorer", "sum", "ValueError", "fairseq.search.Sampling", "fairseq.search.DiverseBeamSearch", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "int", "fairseq.search.LengthConstrainedBeamSearch", "getattr", "fairseq.search.DiverseSiblingsSearch", "sequence_generator.BeamSearch", "getattr"], "function", ["None"], ["", "", "def", "build_generator", "(", "task", ",", "models", ",", "args", ")", ":", "\n", "    ", "if", "getattr", "(", "args", ",", "\"score_reference\"", ",", "False", ")", ":", "\n", "        ", "from", "fairseq", ".", "sequence_scorer", "import", "SequenceScorer", "\n", "\n", "return", "SequenceScorer", "(", "\n", "task", ".", "target_dictionary", ",", "\n", "compute_alignment", "=", "getattr", "(", "args", ",", "\"print_alignment\"", ",", "False", ")", ",", "\n", ")", "\n", "\n", "# from fairseq.sequence_generator import (", "\n", "#     SequenceGenerator,", "\n", "#     SequenceGeneratorWithAlignment,", "\n", "# )", "\n", "\n", "# Choose search strategy. Defaults to Beam Search.", "\n", "", "sampling", "=", "getattr", "(", "args", ",", "\"sampling\"", ",", "False", ")", "\n", "sampling_topk", "=", "getattr", "(", "args", ",", "\"sampling_topk\"", ",", "-", "1", ")", "\n", "sampling_topp", "=", "getattr", "(", "args", ",", "\"sampling_topp\"", ",", "-", "1.0", ")", "\n", "diverse_beam_groups", "=", "getattr", "(", "args", ",", "\"diverse_beam_groups\"", ",", "-", "1", ")", "\n", "diverse_beam_strength", "=", "getattr", "(", "args", ",", "\"diverse_beam_strength\"", ",", "0.5", ")", "\n", "match_source_len", "=", "getattr", "(", "args", ",", "\"match_source_len\"", ",", "False", ")", "\n", "diversity_rate", "=", "getattr", "(", "args", ",", "\"diversity_rate\"", ",", "-", "1", ")", "\n", "if", "(", "\n", "sum", "(", "\n", "int", "(", "cond", ")", "\n", "for", "cond", "in", "[", "\n", "sampling", ",", "\n", "diverse_beam_groups", ">", "0", ",", "\n", "match_source_len", ",", "\n", "diversity_rate", ">", "0", ",", "\n", "]", "\n", ")", "\n", ">", "1", "\n", ")", ":", "\n", "        ", "raise", "ValueError", "(", "\"Provided Search parameters are mutually exclusive.\"", ")", "\n", "", "assert", "sampling_topk", "<", "0", "or", "sampling", ",", "\"--sampling-topk requires --sampling\"", "\n", "assert", "sampling_topp", "<", "0", "or", "sampling", ",", "\"--sampling-topp requires --sampling\"", "\n", "\n", "if", "sampling", ":", "\n", "        ", "search_strategy", "=", "search", ".", "Sampling", "(", "\n", "task", ".", "target_dictionary", ",", "sampling_topk", ",", "sampling_topp", "\n", ")", "\n", "", "elif", "diverse_beam_groups", ">", "0", ":", "\n", "        ", "search_strategy", "=", "search", ".", "DiverseBeamSearch", "(", "\n", "task", ".", "target_dictionary", ",", "diverse_beam_groups", ",", "diverse_beam_strength", "\n", ")", "\n", "", "elif", "match_source_len", ":", "\n", "# this is useful for tagging applications where the output", "\n", "# length should match the input length, so we hardcode the", "\n", "# length constraints for simplicity", "\n", "        ", "search_strategy", "=", "search", ".", "LengthConstrainedBeamSearch", "(", "\n", "task", ".", "target_dictionary", ",", "\n", "min_len_a", "=", "1", ",", "\n", "min_len_b", "=", "0", ",", "\n", "max_len_a", "=", "1", ",", "\n", "max_len_b", "=", "0", ",", "\n", ")", "\n", "", "elif", "diversity_rate", ">", "-", "1", ":", "\n", "        ", "search_strategy", "=", "search", ".", "DiverseSiblingsSearch", "(", "\n", "task", ".", "target_dictionary", ",", "diversity_rate", "\n", ")", "\n", "", "else", ":", "\n", "        ", "search_strategy", "=", "BeamSearch", "(", "task", ".", "target_dictionary", ",", "getattr", "(", "args", ",", "'mc'", ",", "None", ")", ")", "\n", "\n", "", "if", "getattr", "(", "args", ",", "\"print_alignment\"", ",", "False", ")", ":", "\n", "        ", "seq_gen_cls", "=", "SequenceGeneratorWithAlignment", "\n", "", "else", ":", "\n", "        ", "seq_gen_cls", "=", "SequenceGenerator", "\n", "\n", "", "return", "seq_gen_cls", "(", "\n", "models", ",", "\n", "task", ".", "target_dictionary", ",", "\n", "beam_size", "=", "getattr", "(", "args", ",", "\"beam\"", ",", "5", ")", ",", "\n", "max_len_a", "=", "getattr", "(", "args", ",", "\"max_len_a\"", ",", "0", ")", ",", "\n", "max_len_b", "=", "getattr", "(", "args", ",", "\"max_len_b\"", ",", "200", ")", ",", "\n", "min_len", "=", "getattr", "(", "args", ",", "\"min_len\"", ",", "1", ")", ",", "\n", "normalize_scores", "=", "(", "not", "getattr", "(", "args", ",", "\"unnormalized\"", ",", "False", ")", ")", ",", "\n", "len_penalty", "=", "getattr", "(", "args", ",", "\"lenpen\"", ",", "1", ")", ",", "\n", "unk_penalty", "=", "getattr", "(", "args", ",", "\"unkpen\"", ",", "0", ")", ",", "\n", "temperature", "=", "getattr", "(", "args", ",", "\"temperature\"", ",", "1.0", ")", ",", "\n", "match_source_len", "=", "getattr", "(", "args", ",", "\"match_source_len\"", ",", "False", ")", ",", "\n", "no_repeat_ngram_size", "=", "getattr", "(", "args", ",", "\"no_repeat_ngram_size\"", ",", "0", ")", ",", "\n", "search_strategy", "=", "search_strategy", ",", "\n", ")", "\n"]]}