{"home.repos.pwc.inspect_result.showlab_all-in-one.None.param_and_flop.main": [[9, 20], ["copy.deepcopy", "pytorch_lightning.seed_everything", "AllInOne.datamodules.multitask_datamodule.MTDataModule", "AllInOne.modules.ViLTransformerSS", "torch.randn", "thop.profile", "print"], "function", ["None"], ["@", "ex", ".", "automain", "\n", "def", "main", "(", "_config", ")", ":", "\n", "    ", "_config", "=", "copy", ".", "deepcopy", "(", "_config", ")", "\n", "pl", ".", "seed_everything", "(", "_config", "[", "\"seed\"", "]", ")", "\n", "\n", "dm", "=", "MTDataModule", "(", "_config", ",", "dist", "=", "True", ")", "\n", "\n", "model", "=", "ViLTransformerSS", "(", "_config", ")", "\n", "input", "=", "torch", ".", "randn", "(", "1", ",", "3", ",", "3", ",", "224", ",", "224", ")", "\n", "macs", ",", "params", "=", "profile", "(", "model", ",", "inputs", "=", "(", "input", ",", ")", ")", "\n", "print", "(", "macs", ",", "params", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.None.run.main": [[10, 87], ["copy.deepcopy", "pytorch_lightning.seed_everything", "AllInOne.datamodules.multitask_datamodule.MTDataModule", "AllInOne.modules.AllinoneTransformerSS", "os.makedirs", "pytorch_lightning.callbacks.ModelCheckpoint", "datetime.datetime.now", "pytorch_lightning.loggers.TensorBoardLogger", "pytorch_lightning.callbacks.LearningRateMonitor", "print", "print", "print", "print", "pytorch_lightning.Trainer", "print", "isinstance", "len", "pl.Trainer.fit", "pl.Trainer.test", "_config[].split"], "function", ["None"], ["@", "ex", ".", "automain", "\n", "def", "main", "(", "_config", ")", ":", "\n", "    ", "_config", "=", "copy", ".", "deepcopy", "(", "_config", ")", "\n", "pl", ".", "seed_everything", "(", "_config", "[", "\"seed\"", "]", ")", "\n", "\n", "dm", "=", "MTDataModule", "(", "_config", ",", "dist", "=", "True", ")", "\n", "model", "=", "AllinoneTransformerSS", "(", "_config", ")", "\n", "\n", "exp_name", "=", "f'{_config[\"exp_name\"]}'", "\n", "\n", "os", ".", "makedirs", "(", "_config", "[", "\"log_dir\"", "]", ",", "exist_ok", "=", "True", ")", "\n", "checkpoint_callback", "=", "pl", ".", "callbacks", ".", "ModelCheckpoint", "(", "\n", "save_top_k", "=", "1", ",", "\n", "# every_n_epochs=_config[\"save_checkpoints_interval\"],", "\n", "verbose", "=", "True", ",", "\n", "monitor", "=", "\"val/the_metric\"", ",", "\n", "mode", "=", "\"max\"", ",", "\n", "save_last", "=", "True", ",", "\n", ")", "\n", "now", "=", "datetime", ".", "datetime", ".", "now", "(", ")", "\n", "instance_name", "=", "f'{exp_name}_seed{_config[\"seed\"]}_from_{_config[\"load_path\"].split(\"/\")[-1][:-5]}{now.year}_{now.month}_{now.day}'", "\n", "logger", "=", "pl", ".", "loggers", ".", "TensorBoardLogger", "(", "\n", "_config", "[", "\"log_dir\"", "]", ",", "\n", "name", "=", "instance_name", ",", "\n", ")", "\n", "\n", "lr_callback", "=", "pl", ".", "callbacks", ".", "LearningRateMonitor", "(", "logging_interval", "=", "\"step\"", ")", "\n", "callbacks", "=", "[", "checkpoint_callback", ",", "lr_callback", "]", "\n", "\n", "num_gpus", "=", "(", "\n", "_config", "[", "\"num_gpus\"", "]", "\n", "if", "isinstance", "(", "_config", "[", "\"num_gpus\"", "]", ",", "int", ")", "\n", "else", "len", "(", "_config", "[", "\"num_gpus\"", "]", ")", "\n", ")", "\n", "# print all config at the begin", "\n", "print", "(", "'='", "*", "70", "+", "'Config: '", "+", "'='", "*", "70", ")", "\n", "print", "(", "instance_name", ")", "\n", "print", "(", "_config", ")", "\n", "print", "(", "'='", "*", "150", ")", "\n", "\n", "# notice _config[\"batch_size\"] should be max length for all machines, eg. at least 1024", "\n", "grad_steps", "=", "_config", "[", "\"batch_size\"", "]", "//", "(", "\n", "_config", "[", "\"per_gpu_batchsize\"", "]", "*", "num_gpus", "*", "_config", "[", "\"num_nodes\"", "]", "\n", ")", "\n", "\n", "max_steps", "=", "_config", "[", "\"max_steps\"", "]", "if", "_config", "[", "\"max_steps\"", "]", "is", "not", "None", "else", "None", "\n", "\n", "trainer", "=", "pl", ".", "Trainer", "(", "\n", "gpus", "=", "_config", "[", "\"num_gpus\"", "]", ",", "\n", "num_nodes", "=", "_config", "[", "\"num_nodes\"", "]", ",", "\n", "precision", "=", "_config", "[", "\"precision\"", "]", ",", "\n", "accelerator", "=", "\"ddp\"", ",", "\n", "benchmark", "=", "True", ",", "\n", "deterministic", "=", "True", ",", "\n", "max_epochs", "=", "_config", "[", "\"max_epoch\"", "]", "if", "max_steps", "is", "None", "else", "1000", ",", "\n", "max_steps", "=", "max_steps", ",", "\n", "callbacks", "=", "callbacks", ",", "\n", "logger", "=", "logger", ",", "\n", "# prepare_data_per_node=False,", "\n", "replace_sampler_ddp", "=", "False", ",", "\n", "accumulate_grad_batches", "=", "grad_steps", ",", "\n", "log_every_n_steps", "=", "10", ",", "\n", "flush_logs_every_n_steps", "=", "10", ",", "\n", "resume_from_checkpoint", "=", "_config", "[", "\"resume_from\"", "]", ",", "\n", "weights_summary", "=", "\"top\"", ",", "\n", "fast_dev_run", "=", "_config", "[", "\"fast_dev_run\"", "]", ",", "\n", "val_check_interval", "=", "_config", "[", "\"val_check_interval\"", "]", ",", "\n", "# show_progress_bar=False,", "\n", "# progress_bar_refresh_rate=0", "\n", ")", "\n", "\n", "print", "(", "\"accumulate grad batches is: \"", ",", "trainer", ".", "accumulate_grad_batches", ")", "\n", "\n", "if", "not", "_config", "[", "\"test_only\"", "]", ":", "\n", "        ", "trainer", ".", "fit", "(", "model", ",", "datamodule", "=", "dm", ")", "\n", "", "else", ":", "\n", "        ", "trainer", ".", "test", "(", "model", ",", "datamodule", "=", "dm", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.showlab_all-in-one.CoTraining.run.deterministic_index_select": [[14, 22], ["torch.transpose", "tensor_transpose[].transpose"], "function", ["None"], ["\n", "dm", "=", "MTDataModule", "(", "_config", ",", "dist", "=", "True", ")", "\n", "model", "=", "AllinoneTransformerSS", "(", "_config", ")", "\n", "\n", "exp_name", "=", "f'{_config[\"exp_name\"]}'", "\n", "\n", "os", ".", "makedirs", "(", "_config", "[", "\"log_dir\"", "]", ",", "exist_ok", "=", "True", ")", "\n", "checkpoint_callback", "=", "pl", ".", "callbacks", ".", "ModelCheckpoint", "(", "\n", "save_top_k", "=", "1", ",", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.CoTraining.run.main": [[23, 102], ["copy.deepcopy", "pytorch_lightning.seed_everything", "CoTrain.datamodules.video.multitask_datamodule.MTDataModule", "CoTrain.modules.CoTrainTransformerSS", "os.makedirs", "pytorch_lightning.callbacks.ModelCheckpoint", "datetime.datetime.now", "pytorch_lightning.loggers.TensorBoardLogger", "pytorch_lightning.callbacks.LearningRateMonitor", "print", "print", "print", "print", "pytorch_lightning.Trainer", "print", "isinstance", "len", "pl.Trainer.fit", "pl.Trainer.test", "pytorch_lightning.plugins.DDPPlugin", "_config[].split"], "function", ["None"], ["# every_n_epochs=_config[\"save_checkpoints_interval\"],", "\n", "verbose", "=", "True", ",", "\n", "monitor", "=", "\"val/the_metric\"", ",", "\n", "mode", "=", "\"max\"", ",", "\n", "save_last", "=", "True", ",", "\n", ")", "\n", "now", "=", "datetime", ".", "datetime", ".", "now", "(", ")", "\n", "instance_name", "=", "f'{exp_name}_seed{_config[\"seed\"]}_from_{_config[\"load_path\"].split(\"/\")[-1][:-5]}{now.year}_{now.month}_{now.day}'", "\n", "logger", "=", "pl", ".", "loggers", ".", "TensorBoardLogger", "(", "\n", "_config", "[", "\"log_dir\"", "]", ",", "\n", "name", "=", "instance_name", ",", "\n", ")", "\n", "\n", "lr_callback", "=", "pl", ".", "callbacks", ".", "LearningRateMonitor", "(", "logging_interval", "=", "\"step\"", ")", "\n", "callbacks", "=", "[", "checkpoint_callback", ",", "lr_callback", "]", "\n", "\n", "num_gpus", "=", "(", "\n", "_config", "[", "\"num_gpus\"", "]", "\n", "if", "isinstance", "(", "_config", "[", "\"num_gpus\"", "]", ",", "int", ")", "\n", "else", "len", "(", "_config", "[", "\"num_gpus\"", "]", ")", "\n", ")", "\n", "# print all config at the begin", "\n", "print", "(", "'='", "*", "70", "+", "'Config: '", "+", "'='", "*", "70", ")", "\n", "print", "(", "instance_name", ")", "\n", "print", "(", "_config", ")", "\n", "print", "(", "'='", "*", "150", ")", "\n", "\n", "# notice _config[\"batch_size\"] should be max length for all machines, eg. at least 1024", "\n", "grad_steps", "=", "_config", "[", "\"batch_size\"", "]", "//", "(", "\n", "_config", "[", "\"per_gpu_batchsize\"", "]", "*", "num_gpus", "*", "_config", "[", "\"num_nodes\"", "]", "\n", ")", "\n", "\n", "max_steps", "=", "_config", "[", "\"max_steps\"", "]", "if", "_config", "[", "\"max_steps\"", "]", "is", "not", "None", "else", "None", "\n", "\n", "trainer", "=", "pl", ".", "Trainer", "(", "\n", "gpus", "=", "_config", "[", "\"num_gpus\"", "]", ",", "\n", "num_nodes", "=", "_config", "[", "\"num_nodes\"", "]", ",", "\n", "precision", "=", "_config", "[", "\"precision\"", "]", ",", "\n", "accelerator", "=", "\"ddp\"", ",", "\n", "benchmark", "=", "True", ",", "\n", "deterministic", "=", "True", ",", "\n", "max_epochs", "=", "_config", "[", "\"max_epoch\"", "]", "if", "max_steps", "is", "None", "else", "1000", ",", "\n", "max_steps", "=", "max_steps", ",", "\n", "callbacks", "=", "callbacks", ",", "\n", "logger", "=", "logger", ",", "\n", "# prepare_data_per_node=False,", "\n", "replace_sampler_ddp", "=", "False", ",", "\n", "accumulate_grad_batches", "=", "grad_steps", ",", "\n", "log_every_n_steps", "=", "10", ",", "\n", "flush_logs_every_n_steps", "=", "10", ",", "\n", "resume_from_checkpoint", "=", "_config", "[", "\"resume_from\"", "]", ",", "\n", "weights_summary", "=", "\"top\"", ",", "\n", "fast_dev_run", "=", "_config", "[", "\"fast_dev_run\"", "]", ",", "\n", "val_check_interval", "=", "_config", "[", "\"val_check_interval\"", "]", ",", "\n", "# show_progress_bar=False,", "\n", "# progress_bar_refresh_rate=0", "\n", ")", "\n", "\n", "print", "(", "\"accumulate grad batches is: \"", ",", "trainer", ".", "accumulate_grad_batches", ")", "\n", "\n", "if", "not", "_config", "[", "\"test_only\"", "]", ":", "\n", "        ", "trainer", ".", "fit", "(", "model", ",", "datamodule", "=", "dm", ")", "\n", "", "else", ":", "\n", "        ", "trainer", ".", "test", "(", "model", ",", "datamodule", "=", "dm", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.showlab_all-in-one.CoTrain.config._loss_names": [[6, 27], ["ret.update"], "function", ["home.repos.pwc.inspect_result.showlab_all-in-one.gadgets.my_metrics.VQAScore.update"], ["def", "_loss_names", "(", "d", ")", ":", "\n", "    ", "ret", "=", "{", "\n", "# pretrain", "\n", "\"vtm\"", ":", "0", ",", "\n", "\"mlm\"", ":", "0", ",", "\n", "\"mpp\"", ":", "0", ",", "\n", "\"vtc\"", ":", "0", ",", "\n", "\"vcop\"", ":", "0", ",", "\n", "\"dino\"", ":", "0", ",", "\n", "# downstream", "\n", "\"vqa\"", ":", "0", ",", "\n", "\"openend_vqa\"", ":", "0", ",", "\n", "\"mc_vqa\"", ":", "0", ",", "\n", "\"nlvr2\"", ":", "0", ",", "\n", "\"irtr\"", ":", "0", ",", "\n", "\"multiple_choice\"", ":", "0", ",", "\n", "'vcr_q2a'", ":", "0", ",", "\n", "'zs_classify'", ":", "0", "\n", "}", "\n", "ret", ".", "update", "(", "d", ")", "\n", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.CoTrain.config.config": [[29, 106], ["config._loss_names"], "function", ["home.repos.pwc.inspect_result.showlab_all-in-one.AllInOne.config._loss_names"], ["", "@", "ex", ".", "config", "\n", "def", "config", "(", ")", ":", "\n", "    ", "exp_name", "=", "\"CoTrain\"", "\n", "seed", "=", "0", "\n", "video_datasets", "=", "[", "\"wevid\"", ",", "\"howto100m\"", ",", "\"yttemporal\"", "]", "\n", "image_datasets", "=", "[", "\"cc3m\"", ",", "\"cc12m\"", "]", "\n", "loss_names", "=", "_loss_names", "(", "{", "\"vtm\"", ":", "1", ",", "\"mlm\"", ":", "1", "}", ")", "\n", "batch_size", "=", "4096", "# 128 x 32", "\n", "# this is a desired batch size; pl trainer will accumulate gradients when per step batch is smaller.", "\n", "linear_evaluation", "=", "False", "\n", "\n", "draw_false_image", "=", "1", "\n", "# video setting", "\n", "train_transform_keys", "=", "[", "\"pixelbert\"", "]", "\n", "val_transform_keys", "=", "[", "\"pixelbert\"", "]", "\n", "image_size", "=", "224", "# 384/224", "\n", "patch_size", "=", "16", "# 16/32", "\n", "max_image_len", "=", "-", "1", "\n", "draw_false_video", "=", "1", "\n", "video_only", "=", "False", "\n", "num_frames", "=", "3", "# input video frames", "\n", "\n", "# Text Setting", "\n", "vqav2_label_size", "=", "3129", "\n", "msrvttqa_label_size", "=", "1501", "\n", "max_text_len", "=", "40", "# original: 40, 200: for long sentences/paragraph", "\n", "tokenizer", "=", "\"pretrained/bert-base-uncased\"", "\n", "vocab_size", "=", "30522", "\n", "whole_word_masking", "=", "False", "\n", "mlm_prob", "=", "0.15", "\n", "draw_false_text", "=", "0", "\n", "\n", "draw_options_text", "=", "0", "\n", "# Transformer Setting", "\n", "vit", "=", "\"vit_base_patch16_224\"", "# \"vit_base_patch32_384\" / \"vit_base_patch16_224\"", "\n", "hidden_size", "=", "768", "\n", "num_heads", "=", "12", "\n", "num_layers", "=", "12", "\n", "mlp_ratio", "=", "4", "\n", "drop_rate", "=", "0.1", "\n", "shared_embedding_dim", "=", "512", "#  add for contrastive learning 512/256", "\n", "# model_temporal_frames = 4  #  add for model define\uff0c may not consistent with input data", "\n", "\n", "save_checkpoints_interval", "=", "1", "# save each 5 epochs", "\n", "\n", "# Optimizer Setting", "\n", "optim_type", "=", "\"adamw\"", "\n", "learning_rate", "=", "1e-4", "\n", "weight_decay", "=", "0.01", "\n", "decay_power", "=", "1", "\n", "max_epoch", "=", "100", "\n", "max_steps", "=", "25000", "\n", "warmup_steps", "=", "2500", "\n", "end_lr", "=", "0", "\n", "lr_mult", "=", "1", "# multiply lr for downstream heads", "\n", "backend", "=", "'a100'", "# gpu: a100/v100/others", "\n", "\n", "# Downstream Setting", "\n", "get_recall_metric", "=", "False", "\n", "get_ind_recall_metric", "=", "False", "\n", "retrieval_views", "=", "3", "# how many views for retrieval", "\n", "\n", "# PL Trainer Setting", "\n", "resume_from", "=", "None", "\n", "fast_dev_run", "=", "False", "\n", "val_check_interval", "=", "1.0", "\n", "test_only", "=", "False", "\n", "\n", "# below params varies with the environment", "\n", "data_root", "=", "\"\"", "\n", "log_dir", "=", "\"result\"", "\n", "per_gpu_batchsize", "=", "0", "# you should define this manually with per_gpu_batch_size=#", "\n", "num_gpus", "=", "1", "\n", "num_nodes", "=", "1", "\n", "load_path", "=", "\"\"", "\n", "num_workers", "=", "16", "# 0 will not lead to unstable memory usage but slow training ?", "\n", "precision", "=", "16", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.CoTrain.config.env_dandelin": [[109, 115], ["None"], "function", ["None"], ["", "@", "ex", ".", "named_config", "\n", "def", "env_dandelin", "(", ")", ":", "\n", "    ", "data_root", "=", "\"/data2/dsets/dataset\"", "\n", "log_dir", "=", "\"/data2/CoTrain/result\"", "\n", "num_gpus", "=", "8", "\n", "num_nodes", "=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.CoTrain.config.task_mlm_vtm_cotrain": [[117, 128], ["config._loss_names"], "function", ["home.repos.pwc.inspect_result.showlab_all-in-one.AllInOne.config._loss_names"], ["", "@", "ex", ".", "named_config", "\n", "def", "task_mlm_vtm_cotrain", "(", ")", ":", "\n", "    ", "exp_name", "=", "\"mlm_vtm\"", "\n", "video_datasets", "=", "[", "\"webvid\"", "]", "# \"howto100m\",", "\n", "image_datasets", "=", "[", "\"cc3m\"", "]", "\n", "loss_names", "=", "_loss_names", "(", "{", "\"vtm\"", ":", "1", ",", "\"mlm\"", ":", "1", "}", ")", "\n", "batch_size", "=", "2048", "\n", "max_epoch", "=", "30", "\n", "max_image_len", "=", "-", "1", "\n", "val_check_interval", "=", "1.0", "\n", "save_checkpoints_interval", "=", "3", "# save each 5 epochs", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.CoTrain.config.task_mlm_vtm_cotrain_seven": [[129, 140], ["config._loss_names"], "function", ["home.repos.pwc.inspect_result.showlab_all-in-one.AllInOne.config._loss_names"], ["", "@", "ex", ".", "named_config", "\n", "def", "task_mlm_vtm_cotrain_seven", "(", ")", ":", "\n", "    ", "exp_name", "=", "\"mlm_vtm\"", "\n", "video_datasets", "=", "[", "\"webvid\"", ",", "'yttemporal'", ",", "\"howto100m\"", "]", "# 'yttemporal', \"howto100m\",", "\n", "image_datasets", "=", "[", "\"cc3m\"", ",", "\"cc12m\"", ",", "\"vg\"", ",", "'coco'", "]", "# ,  \"vg\", 'coco'", "\n", "loss_names", "=", "_loss_names", "(", "{", "\"vtm\"", ":", "1", ",", "\"mlm\"", ":", "1", "}", ")", "\n", "batch_size", "=", "2048", "\n", "max_epoch", "=", "30", "\n", "max_image_len", "=", "-", "1", "\n", "val_check_interval", "=", "1.0", "\n", "save_checkpoints_interval", "=", "1", "# save each 5 epochs", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.CoTrain.config.task_mlm_vtm_vcop_cotrain": [[141, 152], ["config._loss_names"], "function", ["home.repos.pwc.inspect_result.showlab_all-in-one.AllInOne.config._loss_names"], ["", "@", "ex", ".", "named_config", "\n", "def", "task_mlm_vtm_vcop_cotrain", "(", ")", ":", "\n", "    ", "exp_name", "=", "\"mlm_vtm\"", "\n", "video_datasets", "=", "[", "\"howto100m\"", ",", "\"webvid\"", "]", "\n", "image_datasets", "=", "[", "\"cc3m\"", "]", "\n", "loss_names", "=", "_loss_names", "(", "{", "\"vtm\"", ":", "1", ",", "\"mlm\"", ":", "1", ",", "\"vcop\"", ":", "1", "}", ")", "\n", "batch_size", "=", "2048", "\n", "max_epoch", "=", "30", "\n", "max_image_len", "=", "-", "1", "\n", "val_check_interval", "=", "1.0", "\n", "save_checkpoints_interval", "=", "5", "# save each 5 epochs", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.CoTrain.config.task_mlm_vtm_dino_cotrain": [[153, 166], ["config._loss_names"], "function", ["home.repos.pwc.inspect_result.showlab_all-in-one.AllInOne.config._loss_names"], ["", "@", "ex", ".", "named_config", "\n", "def", "task_mlm_vtm_dino_cotrain", "(", ")", ":", "\n", "    ", "exp_name", "=", "\"mlm_vtm_dino_1f\"", "\n", "video_datasets", "=", "[", "\"webvid\"", "]", "# \"howto100m\",", "\n", "image_datasets", "=", "[", "\"cc3m\"", "]", "\n", "loss_names", "=", "_loss_names", "(", "{", "\"vtm\"", ":", "1", ",", "\"mlm\"", ":", "1", ",", "\"dino\"", ":", "1", "}", ")", "# already include dino", "\n", "train_transform_keys", "=", "[", "\"pixelbert_randaug\"", "]", "\n", "val_transform_keys", "=", "[", "\"pixelbert_randaug\"", "]", "\n", "batch_size", "=", "1024", "\n", "max_epoch", "=", "100", "\n", "max_image_len", "=", "-", "1", "\n", "val_check_interval", "=", "1.0", "\n", "save_checkpoints_interval", "=", "1", "# save each 5 epochs", "\n", "# ================================ end: pretrain ======================", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.CoTrain.config.task_finetune_lsmdcchoice": [[172, 186], ["config._loss_names"], "function", ["home.repos.pwc.inspect_result.showlab_all-in-one.AllInOne.config._loss_names"], ["", "@", "ex", ".", "named_config", "\n", "def", "task_finetune_lsmdcchoice", "(", ")", ":", "\n", "    ", "exp_name", "=", "\"finetune_lsmdc_choice\"", "\n", "video_datasets", "=", "[", "\"lsmdc_choice\"", "]", "\n", "image_datasets", "=", "[", "]", "\n", "loss_names", "=", "_loss_names", "(", "{", "\"multiple_choice\"", ":", "1", "}", ")", "\n", "batch_size", "=", "256", "\n", "max_epoch", "=", "20", "\n", "max_steps", "=", "None", "\n", "warmup_steps", "=", "0.1", "\n", "draw_false_text", "=", "5", "# 5 choices", "\n", "learning_rate", "=", "1e-5", "\n", "val_check_interval", "=", "0.5", "\n", "lr_mult", "=", "10", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.CoTrain.config.task_finetune_msrvttchoice": [[188, 202], ["config._loss_names"], "function", ["home.repos.pwc.inspect_result.showlab_all-in-one.AllInOne.config._loss_names"], ["", "@", "ex", ".", "named_config", "\n", "def", "task_finetune_msrvttchoice", "(", ")", ":", "\n", "    ", "exp_name", "=", "\"finetune_msrvtt_choice\"", "\n", "video_datasets", "=", "[", "\"msrvtt_choice\"", "]", "\n", "image_datasets", "=", "[", "]", "\n", "loss_names", "=", "_loss_names", "(", "{", "\"multiple_choice\"", ":", "1", "}", ")", "\n", "batch_size", "=", "256", "\n", "max_epoch", "=", "10", "\n", "max_steps", "=", "None", "\n", "warmup_steps", "=", "0.1", "\n", "draw_false_text", "=", "5", "# 5 choices", "\n", "learning_rate", "=", "1e-4", "\n", "val_check_interval", "=", "0.5", "\n", "lr_mult", "=", "10", "\n", "# ========== end: multiple choice ================", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.CoTrain.config.task_finetune_vtc_irtr_msrvtt": [[205, 221], ["config._loss_names"], "function", ["home.repos.pwc.inspect_result.showlab_all-in-one.AllInOne.config._loss_names"], ["", "@", "ex", ".", "named_config", "\n", "def", "task_finetune_vtc_irtr_msrvtt", "(", ")", ":", "\n", "    ", "exp_name", "=", "\"finetune_vtc_irtr_msrvtt\"", "\n", "video_datasets", "=", "[", "\"msrvtt\"", "]", "\n", "image_datasets", "=", "[", "]", "\n", "train_transform_keys", "=", "[", "\"pixelbert_randaug\"", "]", "\n", "loss_names", "=", "_loss_names", "(", "{", "\"vtc\"", ":", "1", "}", ")", "\n", "batch_size", "=", "1024", "\n", "max_epoch", "=", "50", "\n", "max_steps", "=", "None", "\n", "warmup_steps", "=", "0.1", "# 0.1/0.3", "\n", "retrieval_views", "=", "1", "# use 5 views", "\n", "get_recall_metric", "=", "False", "\n", "get_ind_recall_metric", "=", "True", "\n", "draw_false_text", "=", "15", "\n", "learning_rate", "=", "6e-4", "# 1/3e-4", "\n", "# ========== end: retrieval ================", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.CoTrain.config.task_finetune_msvdqa": [[224, 239], ["config._loss_names"], "function", ["home.repos.pwc.inspect_result.showlab_all-in-one.AllInOne.config._loss_names"], ["", "@", "ex", ".", "named_config", "\n", "def", "task_finetune_msvdqa", "(", ")", ":", "\n", "    ", "exp_name", "=", "\"finetune_msvd_qa\"", "\n", "video_datasets", "=", "[", "\"msvdqa\"", "]", "\n", "image_datasets", "=", "[", "]", "\n", "loss_names", "=", "_loss_names", "(", "{", "\"openend_vqa\"", ":", "1", "}", ")", "# msvd have same number of answers with msrvtt", "\n", "batch_size", "=", "512", "\n", "msrvttqa_label_size", "=", "1001", "# vqa voculbary length 1000 + 1 background", "\n", "max_epoch", "=", "20", "\n", "max_steps", "=", "None", "\n", "warmup_steps", "=", "0.1", "\n", "draw_false_image", "=", "0", "\n", "learning_rate", "=", "1e-4", "# 1e-4", "\n", "val_check_interval", "=", "1.0", "\n", "lr_mult", "=", "10", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.CoTrain.config.task_finetune_msrvttqa": [[241, 257], ["config._loss_names"], "function", ["home.repos.pwc.inspect_result.showlab_all-in-one.AllInOne.config._loss_names"], ["", "@", "ex", ".", "named_config", "\n", "def", "task_finetune_msrvttqa", "(", ")", ":", "\n", "    ", "exp_name", "=", "\"finetune_msrvtt_qa\"", "\n", "video_datasets", "=", "[", "\"msrvttqa\"", "]", "\n", "image_datasets", "=", "[", "]", "\n", "loss_names", "=", "_loss_names", "(", "{", "\"openend_vqa\"", ":", "1", "}", ")", "\n", "batch_size", "=", "512", "\n", "msrvttqa_label_size", "=", "1501", "# 1501 / 4540", "\n", "max_epoch", "=", "20", "\n", "max_steps", "=", "None", "\n", "warmup_steps", "=", "0.1", "# 0.1", "\n", "draw_false_image", "=", "1", "\n", "draw_false_text", "=", "1", "\n", "learning_rate", "=", "1e-4", "# 1e-4 normal", "\n", "val_check_interval", "=", "1.0", "\n", "lr_mult", "=", "10", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.CoTrain.config.task_finetune_tgifqa": [[261, 276], ["config._loss_names"], "function", ["home.repos.pwc.inspect_result.showlab_all-in-one.AllInOne.config._loss_names"], ["", "@", "ex", ".", "named_config", "\n", "def", "task_finetune_tgifqa", "(", ")", ":", "\n", "    ", "exp_name", "=", "\"finetune_tgif_qa\"", "\n", "video_datasets", "=", "[", "\"tgif\"", "]", "\n", "image_datasets", "=", "[", "]", "\n", "loss_names", "=", "_loss_names", "(", "{", "\"openend_vqa\"", ":", "1", "}", ")", "\n", "batch_size", "=", "512", "\n", "msrvttqa_label_size", "=", "1541", "# vqa voculbary length 1540 + 1 background", "\n", "max_epoch", "=", "20", "\n", "max_steps", "=", "None", "\n", "warmup_steps", "=", "0.1", "\n", "draw_false_image", "=", "0", "\n", "learning_rate", "=", "1e-4", "# 1e-4", "\n", "val_check_interval", "=", "1.0", "\n", "lr_mult", "=", "10", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.CoTrain.config.task_finetune_tgif_action_trans": [[278, 293], ["config._loss_names"], "function", ["home.repos.pwc.inspect_result.showlab_all-in-one.AllInOne.config._loss_names"], ["", "@", "ex", ".", "named_config", "\n", "def", "task_finetune_tgif_action_trans", "(", ")", ":", "\n", "    ", "exp_name", "=", "\"finetune_tgif_action_trans\"", "\n", "video_datasets", "=", "[", "\"tgifqa\"", "]", "\n", "image_datasets", "=", "[", "]", "\n", "loss_names", "=", "_loss_names", "(", "{", "\"mc_vqa\"", ":", "1", "}", ")", "\n", "batch_size", "=", "512", "\n", "max_epoch", "=", "100", "\n", "max_steps", "=", "None", "\n", "warmup_steps", "=", "0.1", "\n", "draw_false_image", "=", "0", "\n", "draw_options_text", "=", "5", "# 5 choices", "\n", "learning_rate", "=", "1e-4", "# 1e-4", "\n", "val_check_interval", "=", "1.0", "\n", "lr_mult", "=", "10", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.CoTrain.config.task_finetune_action_recognition_hmdb51": [[298, 311], ["config._loss_names"], "function", ["home.repos.pwc.inspect_result.showlab_all-in-one.AllInOne.config._loss_names"], ["", "@", "ex", ".", "named_config", "\n", "def", "task_finetune_action_recognition_hmdb51", "(", ")", ":", "\n", "    ", "exp_name", "=", "\"finetune_action_recognition_hmdb51\"", "\n", "video_datasets", "=", "[", "\"hmdb51\"", "]", "\n", "image_datasets", "=", "[", "]", "\n", "loss_names", "=", "_loss_names", "(", "{", "\"openend_vqa\"", ":", "1", "}", ")", "# have", "\n", "msrvttqa_label_size", "=", "52", "# 51 + 1", "\n", "batch_size", "=", "256", "\n", "max_epoch", "=", "50", "\n", "max_steps", "=", "None", "\n", "warmup_steps", "=", "0.1", "\n", "draw_false_text", "=", "15", "\n", "learning_rate", "=", "1e-4", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.CoTrain.config.task_finetune_action_recognition_k400": [[313, 327], ["config._loss_names"], "function", ["home.repos.pwc.inspect_result.showlab_all-in-one.AllInOne.config._loss_names"], ["", "@", "ex", ".", "named_config", "\n", "def", "task_finetune_action_recognition_k400", "(", ")", ":", "\n", "    ", "exp_name", "=", "\"finetune_action_recognition_k400\"", "\n", "video_datasets", "=", "[", "\"k400\"", "]", "\n", "image_datasets", "=", "[", "]", "\n", "loss_names", "=", "_loss_names", "(", "{", "\"openend_vqa\"", ":", "1", "}", ")", "# have", "\n", "msrvttqa_label_size", "=", "401", "# 400 + 1", "\n", "batch_size", "=", "256", "\n", "max_epoch", "=", "50", "\n", "max_steps", "=", "None", "\n", "warmup_steps", "=", "0.1", "\n", "draw_false_text", "=", "15", "\n", "learning_rate", "=", "3e-4", "\n", "val_check_interval", "=", "1.0", "\n", "# end: ===================== action recognition =====================", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.CoTrain.config.step25k": [[330, 334], ["None"], "function", ["None"], ["", "@", "ex", ".", "named_config", "\n", "def", "step25k", "(", ")", ":", "\n", "    ", "max_epoch", "=", "100", "\n", "max_steps", "=", "25000", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.CoTrain.config.step50k": [[336, 340], ["None"], "function", ["None"], ["", "@", "ex", ".", "named_config", "\n", "def", "step50k", "(", ")", ":", "\n", "    ", "max_epoch", "=", "100", "\n", "max_steps", "=", "50000", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.CoTrain.config.step100k": [[342, 346], ["None"], "function", ["None"], ["", "@", "ex", ".", "named_config", "\n", "def", "step100k", "(", ")", ":", "\n", "    ", "max_epoch", "=", "100", "\n", "max_steps", "=", "100000", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.CoTrain.config.step200k": [[348, 352], ["None"], "function", ["None"], ["", "@", "ex", ".", "named_config", "\n", "def", "step200k", "(", ")", ":", "\n", "    ", "max_epoch", "=", "200", "\n", "max_steps", "=", "200000", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.CoTrain.config.vit32_base": [[354, 361], ["None"], "function", ["None"], ["", "@", "ex", ".", "named_config", "\n", "def", "vit32_base", "(", ")", ":", "\n", "    ", "vit", "=", "\"vit_base_patch32_384\"", "\n", "patch_size", "=", "32", "\n", "hidden_size", "=", "768", "\n", "num_heads", "=", "12", "\n", "num_layers", "=", "12", "\n", "", ""]], "home.repos.pwc.inspect_result.showlab_all-in-one.datamodules.multitask_datamodule.MTDataModule.__init__": [[12, 27], ["pytorch_lightning.LightningDataModule.__init__", "len", "multitask_datamodule.MTDataModule.dm_dicts.items"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.transforms.utils.UnNormalize.__init__"], ["class", "MTDataModule", "(", "LightningDataModule", ")", ":", "\n", "    ", "def", "__init__", "(", "self", ",", "_config", ",", "dist", "=", "False", ")", ":", "\n", "        ", "video_datamodule_keys", "=", "_config", "[", "\"video_datasets\"", "]", "\n", "image_datamodule_keys", "=", "_config", "[", "\"image_datasets\"", "]", "\n", "self", ".", "num_video_datasets", "=", "len", "(", "video_datamodule_keys", ")", "\n", "self", ".", "num_image_datasets", "=", "len", "(", "image_datamodule_keys", ")", "\n", "\n", "assert", "self", ".", "num_video_datasets", ">", "0", "or", "self", ".", "num_image_datasets", ">", "0", "\n", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "if", "self", ".", "num_video_datasets", ">", "0", ":", "\n", "            ", "self", ".", "video_dm_keys", "=", "video_datamodule_keys", "\n", "self", ".", "video_dm_dicts", "=", "{", "key", ":", "_datamodules", "[", "key", "]", "(", "_config", ")", "for", "key", "in", "video_datamodule_keys", "}", "\n", "self", ".", "video_dms", "=", "[", "v", "for", "k", ",", "v", "in", "self", ".", "video_dm_dicts", ".", "items", "(", ")", "]", "\n", "self", ".", "video_batch_size", "=", "self", ".", "video_dms", "[", "0", "]", ".", "batch_size", "\n", "self", ".", "video_vocab_size", "=", "self", ".", "video_dms", "[", "0", "]", ".", "vocab_size", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datamodules.multitask_datamodule.MTDataModule.prepare_data": [[28, 31], ["dm.prepare_data"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.video.multitask_datamodule.MTDataModule.prepare_data"], ["self", ".", "video_num_workers", "=", "self", ".", "video_dms", "[", "0", "]", ".", "num_workers", "\n", "", "if", "self", ".", "num_image_datasets", ":", "\n", "            ", "self", ".", "image_dm_keys", "=", "image_datamodule_keys", "\n", "self", ".", "image_dm_dicts", "=", "{", "key", ":", "_datamodules", "[", "key", "]", "(", "_config", ")", "for", "key", "in", "image_datamodule_keys", "}", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datamodules.multitask_datamodule.MTDataModule.setup": [[32, 53], ["torch.utils.data.dataset.ConcatDataset", "torch.utils.data.dataset.ConcatDataset", "torch.utils.data.dataset.ConcatDataset", "functools.partial", "dm.setup", "torch.utils.data.distributed.DistributedSampler", "torch.utils.data.distributed.DistributedSampler", "torch.utils.data.distributed.DistributedSampler"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.image.vqav2_datamodule.VQAv2DataModule.setup"], ["self", ".", "image_dms", "=", "[", "v", "for", "k", ",", "v", "in", "self", ".", "image_dm_dicts", ".", "items", "(", ")", "]", "\n", "self", ".", "image_batch_size", "=", "self", ".", "image_dms", "[", "0", "]", ".", "batch_size", "\n", "self", ".", "image_vocab_size", "=", "self", ".", "image_dms", "[", "0", "]", ".", "vocab_size", "\n", "self", ".", "image_num_workers", "=", "self", ".", "image_dms", "[", "0", "]", ".", "num_workers", "\n", "", "self", ".", "dist", "=", "dist", "\n", "\n", "", "def", "prepare_data", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "num_video_datasets", ":", "\n", "            ", "for", "dm", "in", "self", ".", "video_dms", ":", "\n", "                ", "dm", ".", "prepare_data", "(", ")", "\n", "", "", "if", "self", ".", "num_image_datasets", ":", "\n", "            ", "for", "dm", "in", "self", ".", "image_dms", ":", "\n", "                ", "dm", ".", "prepare_data", "(", ")", "\n", "\n", "", "", "", "def", "setup", "(", "self", ",", "stage", ")", ":", "\n", "        ", "if", "self", ".", "num_video_datasets", ":", "\n", "            ", "for", "dm", "in", "self", ".", "video_dms", ":", "\n", "                ", "dm", ".", "setup", "(", "stage", ")", "\n", "", "", "if", "self", ".", "num_image_datasets", ":", "\n", "            ", "for", "dm", "in", "self", ".", "image_dms", ":", "\n", "                ", "dm", ".", "setup", "(", "stage", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datamodules.multitask_datamodule.MTDataModule.train_dataloader": [[54, 63], ["torch.utils.data.DataLoader"], "methods", ["None"], ["", "", "if", "self", ".", "num_video_datasets", ":", "\n", "            ", "self", ".", "video_train_dataset", "=", "ConcatDataset", "(", "[", "dm", ".", "train_dataset", "for", "dm", "in", "self", ".", "video_dms", "]", ")", "\n", "self", ".", "video_val_dataset", "=", "ConcatDataset", "(", "[", "dm", ".", "val_dataset", "for", "dm", "in", "self", ".", "video_dms", "]", ")", "\n", "self", ".", "video_test_dataset", "=", "ConcatDataset", "(", "[", "dm", ".", "test_dataset", "for", "dm", "in", "self", ".", "video_dms", "]", ")", "\n", "\n", "", "if", "self", ".", "num_image_datasets", ":", "\n", "            ", "self", ".", "image_train_dataset", "=", "ConcatDataset", "(", "[", "dm", ".", "train_dataset", "for", "dm", "in", "self", ".", "image_dms", "]", ")", "\n", "self", ".", "image_val_dataset", "=", "ConcatDataset", "(", "[", "dm", ".", "val_dataset", "for", "dm", "in", "self", ".", "image_dms", "]", ")", "\n", "self", ".", "image_test_dataset", "=", "ConcatDataset", "(", "[", "dm", ".", "test_dataset", "for", "dm", "in", "self", ".", "image_dms", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datamodules.multitask_datamodule.MTDataModule.val_dataloader": [[64, 73], ["torch.utils.data.DataLoader"], "methods", ["None"], ["", "if", "len", "(", "self", ".", "video_dms", ")", ">", "0", ":", "\n", "            ", "self", ".", "tokenizer", "=", "self", ".", "video_dms", "[", "0", "]", ".", "tokenizer", "\n", "", "else", ":", "\n", "            ", "self", ".", "tokenizer", "=", "self", ".", "image_dms", "[", "0", "]", ".", "tokenizer", "\n", "\n", "", "if", "self", ".", "num_video_datasets", ":", "\n", "            ", "self", ".", "video_collate", "=", "functools", ".", "partial", "(", "\n", "self", ".", "video_dms", "[", "0", "]", ".", "train_dataset", ".", "collate", ",", "mlm_collator", "=", "self", ".", "video_dms", "[", "0", "]", ".", "mlm_collator", ",", "\n", ")", "\n", "", "if", "self", ".", "num_image_datasets", ":", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datamodules.multitask_datamodule.MTDataModule.test_dataloader": [[74, 83], ["torch.utils.data.DataLoader"], "methods", ["None"], ["            ", "self", ".", "image_collate", "=", "functools", ".", "partial", "(", "\n", "self", ".", "image_dms", "[", "0", "]", ".", "train_dataset", ".", "collate", ",", "mlm_collator", "=", "self", ".", "image_dms", "[", "0", "]", ".", "mlm_collator", ",", "\n", ")", "\n", "\n", "", "if", "self", ".", "dist", ":", "\n", "            ", "if", "self", ".", "num_video_datasets", ":", "\n", "                ", "self", ".", "video_train_sampler", "=", "DistributedSampler", "(", "self", ".", "video_train_dataset", ",", "shuffle", "=", "True", ")", "\n", "self", ".", "video_val_sampler", "=", "DistributedSampler", "(", "self", ".", "video_val_dataset", ",", "shuffle", "=", "True", ")", "\n", "self", ".", "video_test_sampler", "=", "DistributedSampler", "(", "self", ".", "video_test_dataset", ",", "shuffle", "=", "False", ")", "\n", "", "if", "self", ".", "num_image_datasets", ":", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datamodules.tgifqa_datamodule.TGIFQADataModule.__init__": [[6, 8], ["datamodule_base.BaseDataModule.__init__"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.transforms.utils.UnNormalize.__init__"], ["    ", "def", "__init__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datamodules.tgifqa_datamodule.TGIFQADataModule.dataset_cls": [[9, 12], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "dataset_cls", "(", "self", ")", ":", "\n", "        ", "return", "TGIFQADataset", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datamodules.tgifqa_datamodule.TGIFQADataModule.dataset_cls_no_false": [[13, 16], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "dataset_cls_no_false", "(", "self", ")", ":", "\n", "        ", "return", "TGIFQADataset", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datamodules.tgifqa_datamodule.TGIFQADataModule.dataset_name": [[17, 20], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "dataset_name", "(", "self", ")", ":", "\n", "        ", "return", "\"tgifqa\"", "\n", "", "", ""]], "home.repos.pwc.inspect_result.showlab_all-in-one.datamodules.vg_caption_datamodule.VisualGenomeCaptionDataModule.__init__": [[6, 8], ["datamodule_base.BaseDataModule.__init__"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.transforms.utils.UnNormalize.__init__"], ["    ", "def", "__init__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datamodules.vg_caption_datamodule.VisualGenomeCaptionDataModule.dataset_cls": [[9, 12], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "dataset_cls", "(", "self", ")", ":", "\n", "        ", "return", "VisualGenomeCaptionDataset", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datamodules.vg_caption_datamodule.VisualGenomeCaptionDataModule.dataset_name": [[13, 16], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "dataset_name", "(", "self", ")", ":", "\n", "        ", "return", "\"vg\"", "\n", "", "", ""]], "home.repos.pwc.inspect_result.showlab_all-in-one.datamodules.coco_caption_karpathy_datamodule.CocoCaptionKarpathyDataModule.__init__": [[6, 8], ["datamodule_base.BaseDataModule.__init__"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.transforms.utils.UnNormalize.__init__"], ["    ", "def", "__init__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datamodules.coco_caption_karpathy_datamodule.CocoCaptionKarpathyDataModule.dataset_cls": [[9, 12], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "dataset_cls", "(", "self", ")", ":", "\n", "        ", "return", "CocoCaptionKarpathyDataset", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datamodules.coco_caption_karpathy_datamodule.CocoCaptionKarpathyDataModule.dataset_cls_no_false": [[13, 16], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "dataset_cls_no_false", "(", "self", ")", ":", "\n", "        ", "return", "CocoCaptionKarpathyDataset", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datamodules.coco_caption_karpathy_datamodule.CocoCaptionKarpathyDataModule.dataset_name": [[17, 20], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "dataset_name", "(", "self", ")", ":", "\n", "        ", "return", "\"coco\"", "\n", "", "", ""]], "home.repos.pwc.inspect_result.showlab_all-in-one.datamodules.didemo_datamodule.DIDEMODataModule.__init__": [[6, 8], ["datamodule_base.BaseDataModule.__init__"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.transforms.utils.UnNormalize.__init__"], ["    ", "def", "__init__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datamodules.didemo_datamodule.DIDEMODataModule.dataset_cls": [[9, 12], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "dataset_cls", "(", "self", ")", ":", "\n", "        ", "return", "DIDEMODataset", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datamodules.didemo_datamodule.DIDEMODataModule.dataset_cls_no_false": [[13, 16], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "dataset_cls_no_false", "(", "self", ")", ":", "\n", "        ", "return", "DIDEMODataset", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datamodules.didemo_datamodule.DIDEMODataModule.dataset_name": [[17, 20], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "dataset_name", "(", "self", ")", ":", "\n", "        ", "return", "\"didemo\"", "\n", "", "", ""]], "home.repos.pwc.inspect_result.showlab_all-in-one.datamodules.tvqa_datamodule.TVQADataModule.__init__": [[6, 8], ["datamodule_base.BaseDataModule.__init__"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.transforms.utils.UnNormalize.__init__"], ["    ", "def", "__init__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datamodules.tvqa_datamodule.TVQADataModule.dataset_cls": [[9, 12], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "dataset_cls", "(", "self", ")", ":", "\n", "        ", "return", "TVQADataset", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datamodules.tvqa_datamodule.TVQADataModule.dataset_cls_no_false": [[13, 16], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "dataset_cls_no_false", "(", "self", ")", ":", "\n", "        ", "return", "TVQADataset", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datamodules.tvqa_datamodule.TVQADataModule.dataset_name": [[17, 20], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "dataset_name", "(", "self", ")", ":", "\n", "        ", "return", "\"tvqa\"", "\n", "", "", ""]], "home.repos.pwc.inspect_result.showlab_all-in-one.datamodules.datamodule_base.BaseDataModule.__init__": [[25, 70], ["pytorch_lightning.LightningDataModule.__init__", "datamodule_base.get_pretrained_tokenizer", "collator", "len", "len"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.transforms.utils.UnNormalize.__init__", "home.repos.pwc.inspect_result.showlab_all-in-one.image.datamodule_base.get_pretrained_tokenizer"], ["    ", "def", "__init__", "(", "self", ",", "_config", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "data_dir", "=", "_config", "[", "\"data_root\"", "]", "\n", "\n", "self", ".", "num_workers", "=", "_config", "[", "\"num_workers\"", "]", "\n", "self", ".", "batch_size", "=", "_config", "[", "\"per_gpu_batchsize\"", "]", "\n", "self", ".", "eval_batch_size", "=", "self", ".", "batch_size", "\n", "\n", "self", ".", "image_size", "=", "_config", "[", "\"image_size\"", "]", "\n", "self", ".", "max_text_len", "=", "_config", "[", "\"max_text_len\"", "]", "\n", "self", ".", "draw_false_video", "=", "_config", "[", "\"draw_false_video\"", "]", "\n", "self", ".", "draw_false_image", "=", "_config", "[", "\"draw_false_image\"", "]", "\n", "self", ".", "draw_false_text", "=", "_config", "[", "\"draw_false_text\"", "]", "\n", "self", ".", "image_only", "=", "_config", "[", "\"video_only\"", "]", "\n", "\n", "\n", "self", ".", "num_frames", "=", "_config", "[", "\"num_frames\"", "]", "\n", "self", ".", "draw_options_text", "=", "_config", "[", "\"draw_options_text\"", "]", "\n", "self", ".", "backend", "=", "_config", "[", "\"backend\"", "]", "\n", "\n", "self", ".", "train_transform_keys", "=", "(", "\n", "[", "\"default_train\"", "]", "\n", "if", "len", "(", "_config", "[", "\"train_transform_keys\"", "]", ")", "==", "0", "\n", "else", "_config", "[", "\"train_transform_keys\"", "]", "\n", ")", "\n", "\n", "self", ".", "val_transform_keys", "=", "(", "\n", "[", "\"default_val\"", "]", "\n", "if", "len", "(", "_config", "[", "\"val_transform_keys\"", "]", ")", "==", "0", "\n", "else", "_config", "[", "\"val_transform_keys\"", "]", "\n", ")", "\n", "\n", "tokenizer", "=", "_config", "[", "\"tokenizer\"", "]", "\n", "self", ".", "tokenizer", "=", "get_pretrained_tokenizer", "(", "tokenizer", ")", "\n", "self", ".", "vocab_size", "=", "self", ".", "tokenizer", ".", "vocab_size", "\n", "\n", "collator", "=", "(", "\n", "DataCollatorForWholeWordMask", "\n", "if", "_config", "[", "\"whole_word_masking\"", "]", "\n", "else", "DataCollatorForLanguageModeling", "\n", ")", "\n", "\n", "self", ".", "mlm_collator", "=", "collator", "(", "\n", "tokenizer", "=", "self", ".", "tokenizer", ",", "mlm", "=", "True", ",", "mlm_probability", "=", "_config", "[", "\"mlm_prob\"", "]", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datamodules.datamodule_base.BaseDataModule.dataset_cls": [[71, 74], ["NotImplementedError"], "methods", ["None"], ["self", ".", "setup_flag", "=", "False", "\n", "\n", "", "@", "property", "\n", "def", "dataset_cls", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datamodules.datamodule_base.BaseDataModule.dataset_name": [[75, 78], ["NotImplementedError"], "methods", ["None"], ["        ", "raise", "NotImplementedError", "(", "\"return tuple of dataset class\"", ")", "\n", "\n", "", "@", "property", "\n", "def", "dataset_name", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datamodules.datamodule_base.BaseDataModule.set_train_dataset": [[79, 92], ["datamodule_base.BaseDataModule.dataset_cls"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.image.conceptual_caption_datamodule.ConceptualCaptionDataModule.dataset_cls"], ["        ", "raise", "NotImplementedError", "(", "\"return name of dataset\"", ")", "\n", "\n", "", "def", "set_train_dataset", "(", "self", ")", ":", "\n", "        ", "self", ".", "train_dataset", "=", "self", ".", "dataset_cls", "(", "\n", "self", ".", "data_dir", ",", "\n", "self", ".", "train_transform_keys", ",", "\n", "split", "=", "\"train\"", ",", "\n", "image_size", "=", "self", ".", "image_size", ",", "\n", "max_text_len", "=", "self", ".", "max_text_len", ",", "\n", "draw_false_image", "=", "self", ".", "draw_false_image", ",", "\n", "draw_false_video", "=", "self", ".", "draw_false_video", ",", "\n", "draw_false_text", "=", "self", ".", "draw_false_text", ",", "\n", "image_only", "=", "self", ".", "image_only", ",", "\n", "num_frames", "=", "self", ".", "num_frames", ",", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datamodules.datamodule_base.BaseDataModule.set_val_dataset": [[94, 122], ["datamodule_base.BaseDataModule.dataset_cls", "hasattr", "datamodule_base.BaseDataModule.dataset_cls_no_false"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.image.conceptual_caption_datamodule.ConceptualCaptionDataModule.dataset_cls", "home.repos.pwc.inspect_result.showlab_all-in-one.image.f30k_caption_karpathy_datamodule.F30KCaptionKarpathyDataModule.dataset_cls_no_false"], ["backend", "=", "self", ".", "backend", "\n", ")", "\n", "\n", "", "def", "set_val_dataset", "(", "self", ")", ":", "\n", "        ", "self", ".", "val_dataset", "=", "self", ".", "dataset_cls", "(", "\n", "self", ".", "data_dir", ",", "\n", "self", ".", "val_transform_keys", ",", "\n", "split", "=", "\"val\"", ",", "\n", "image_size", "=", "self", ".", "image_size", ",", "\n", "max_text_len", "=", "self", ".", "max_text_len", ",", "\n", "draw_false_image", "=", "self", ".", "draw_false_image", ",", "\n", "draw_false_video", "=", "self", ".", "draw_false_video", ",", "\n", "draw_false_text", "=", "self", ".", "draw_false_text", ",", "\n", "image_only", "=", "self", ".", "image_only", ",", "\n", "num_frames", "=", "self", ".", "num_frames", ",", "\n", "draw_options_text", "=", "self", ".", "draw_options_text", ",", "\n", "backend", "=", "self", ".", "backend", "\n", ")", "\n", "\n", "if", "hasattr", "(", "self", ",", "\"dataset_cls_no_false\"", ")", ":", "\n", "            ", "self", ".", "val_dataset_no_false", "=", "self", ".", "dataset_cls_no_false", "(", "\n", "self", ".", "data_dir", ",", "\n", "self", ".", "val_transform_keys", ",", "\n", "split", "=", "\"val\"", ",", "\n", "image_size", "=", "self", ".", "image_size", ",", "\n", "max_text_len", "=", "self", ".", "max_text_len", ",", "\n", "draw_false_image", "=", "0", ",", "\n", "draw_false_video", "=", "0", ",", "\n", "draw_false_text", "=", "0", ",", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datamodules.datamodule_base.BaseDataModule.make_no_false_val_dset": [[124, 137], ["datamodule_base.BaseDataModule.dataset_cls_no_false"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.image.f30k_caption_karpathy_datamodule.F30KCaptionKarpathyDataModule.dataset_cls_no_false"], ["num_frames", "=", "self", ".", "num_frames", ",", "\n", "draw_options_text", "=", "self", ".", "draw_options_text", ",", "\n", "backend", "=", "self", ".", "backend", "\n", ")", "\n", "\n", "", "", "def", "make_no_false_val_dset", "(", "self", ",", "image_only", "=", "False", ")", ":", "\n", "        ", "return", "self", ".", "dataset_cls_no_false", "(", "\n", "self", ".", "data_dir", ",", "\n", "self", ".", "val_transform_keys", ",", "\n", "split", "=", "\"val\"", ",", "\n", "image_size", "=", "self", ".", "image_size", ",", "\n", "max_text_len", "=", "self", ".", "max_text_len", ",", "\n", "draw_false_image", "=", "0", ",", "\n", "draw_false_video", "=", "0", ",", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datamodules.datamodule_base.BaseDataModule.set_test_dataset": [[139, 152], ["datamodule_base.BaseDataModule.dataset_cls"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.image.conceptual_caption_datamodule.ConceptualCaptionDataModule.dataset_cls"], ["image_only", "=", "image_only", ",", "\n", "num_frames", "=", "self", ".", "num_frames", ",", "\n", "draw_options_text", "=", "self", ".", "draw_options_text", ",", "\n", "backend", "=", "self", ".", "backend", "\n", ")", "\n", "\n", "", "def", "set_test_dataset", "(", "self", ")", ":", "\n", "        ", "self", ".", "test_dataset", "=", "self", ".", "dataset_cls", "(", "\n", "self", ".", "data_dir", ",", "\n", "self", ".", "val_transform_keys", ",", "\n", "split", "=", "\"test\"", ",", "\n", "image_size", "=", "self", ".", "image_size", ",", "\n", "max_text_len", "=", "self", ".", "max_text_len", ",", "\n", "draw_false_image", "=", "self", ".", "draw_false_image", ",", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datamodules.datamodule_base.BaseDataModule.setup": [[154, 165], ["datamodule_base.BaseDataModule.set_train_dataset", "datamodule_base.BaseDataModule.set_val_dataset", "datamodule_base.BaseDataModule.set_test_dataset"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.image.datamodule_base.BaseDataModule.set_train_dataset", "home.repos.pwc.inspect_result.showlab_all-in-one.image.datamodule_base.BaseDataModule.set_val_dataset", "home.repos.pwc.inspect_result.showlab_all-in-one.image.datamodule_base.BaseDataModule.set_test_dataset"], ["draw_false_text", "=", "self", ".", "draw_false_text", ",", "\n", "image_only", "=", "self", ".", "image_only", ",", "\n", "num_frames", "=", "self", ".", "num_frames", ",", "\n", "draw_options_text", "=", "self", ".", "draw_options_text", ",", "\n", "backend", "=", "self", ".", "backend", "\n", ")", "\n", "\n", "", "def", "setup", "(", "self", ",", "stage", ")", ":", "\n", "        ", "if", "not", "self", ".", "setup_flag", ":", "\n", "            ", "self", ".", "set_train_dataset", "(", ")", "\n", "self", ".", "set_val_dataset", "(", ")", "\n", "self", ".", "set_test_dataset", "(", ")", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datamodules.datamodule_base.BaseDataModule.train_dataloader": [[166, 176], ["torch.utils.data.DataLoader"], "methods", ["None"], ["\n", "self", ".", "train_dataset", ".", "tokenizer", "=", "self", ".", "tokenizer", "\n", "self", ".", "val_dataset", ".", "tokenizer", "=", "self", ".", "tokenizer", "\n", "self", ".", "test_dataset", ".", "tokenizer", "=", "self", ".", "tokenizer", "\n", "\n", "self", ".", "setup_flag", "=", "True", "\n", "\n", "", "", "def", "train_dataloader", "(", "self", ")", ":", "\n", "        ", "loader", "=", "DataLoader", "(", "\n", "self", ".", "train_dataset", ",", "\n", "batch_size", "=", "self", ".", "batch_size", ",", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datamodules.datamodule_base.BaseDataModule.val_dataloader": [[177, 187], ["torch.utils.data.DataLoader"], "methods", ["None"], ["shuffle", "=", "True", ",", "\n", "num_workers", "=", "self", ".", "num_workers", ",", "\n", "pin_memory", "=", "True", ",", "\n", "collate_fn", "=", "self", ".", "train_dataset", ".", "collate", ",", "\n", ")", "\n", "return", "loader", "\n", "\n", "", "def", "val_dataloader", "(", "self", ")", ":", "\n", "        ", "loader", "=", "DataLoader", "(", "\n", "self", ".", "val_dataset", ",", "\n", "batch_size", "=", "self", ".", "eval_batch_size", ",", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datamodules.datamodule_base.BaseDataModule.test_dataloader": [[188, 198], ["torch.utils.data.DataLoader"], "methods", ["None"], ["shuffle", "=", "False", ",", "\n", "num_workers", "=", "self", ".", "num_workers", ",", "\n", "pin_memory", "=", "True", ",", "\n", "collate_fn", "=", "self", ".", "val_dataset", ".", "collate", ",", "\n", ")", "\n", "return", "loader", "\n", "\n", "", "def", "test_dataloader", "(", "self", ")", ":", "\n", "        ", "loader", "=", "DataLoader", "(", "\n", "self", ".", "test_dataset", ",", "\n", "batch_size", "=", "self", ".", "eval_batch_size", ",", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datamodules.datamodule_base.get_pretrained_tokenizer": [[12, 21], ["torch.distributed.is_initialized", "transformers.BertTokenizer.from_pretrained", "torch.distributed.barrier", "torch.distributed.get_rank", "transformers.BertTokenizer.from_pretrained"], "function", ["home.repos.pwc.inspect_result.showlab_all-in-one.modules.dist_utils.get_rank"], ["def", "get_pretrained_tokenizer", "(", "from_pretrained", ")", ":", "\n", "    ", "if", "torch", ".", "distributed", ".", "is_initialized", "(", ")", ":", "\n", "        ", "if", "torch", ".", "distributed", ".", "get_rank", "(", ")", "==", "0", ":", "\n", "            ", "BertTokenizer", ".", "from_pretrained", "(", "\n", "from_pretrained", ",", "do_lower_case", "=", "\"uncased\"", "in", "from_pretrained", "\n", ")", "\n", "", "torch", ".", "distributed", ".", "barrier", "(", ")", "\n", "", "return", "BertTokenizer", ".", "from_pretrained", "(", "\n", "from_pretrained", ",", "do_lower_case", "=", "\"uncased\"", "in", "from_pretrained", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datamodules.f30k_caption_karpathy_datamodule.F30KCaptionKarpathyDataModule.__init__": [[6, 8], ["datamodule_base.BaseDataModule.__init__"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.transforms.utils.UnNormalize.__init__"], ["    ", "def", "__init__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datamodules.f30k_caption_karpathy_datamodule.F30KCaptionKarpathyDataModule.dataset_cls": [[9, 12], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "dataset_cls", "(", "self", ")", ":", "\n", "        ", "return", "F30KCaptionKarpathyDataset", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datamodules.f30k_caption_karpathy_datamodule.F30KCaptionKarpathyDataModule.dataset_cls_no_false": [[13, 16], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "dataset_cls_no_false", "(", "self", ")", ":", "\n", "        ", "return", "F30KCaptionKarpathyDataset", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datamodules.f30k_caption_karpathy_datamodule.F30KCaptionKarpathyDataModule.dataset_name": [[17, 20], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "dataset_name", "(", "self", ")", ":", "\n", "        ", "return", "\"f30k\"", "\n", "", "", ""]], "home.repos.pwc.inspect_result.showlab_all-in-one.datamodules.howto100m_datamodule.HT100MDataModule.__init__": [[6, 8], ["datamodule_base.BaseDataModule.__init__"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.transforms.utils.UnNormalize.__init__"], ["    ", "def", "__init__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datamodules.howto100m_datamodule.HT100MDataModule.dataset_cls": [[9, 12], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "dataset_cls", "(", "self", ")", ":", "\n", "        ", "return", "HT100MDataset", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datamodules.howto100m_datamodule.HT100MDataModule.dataset_cls_no_false": [[13, 16], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "dataset_cls_no_false", "(", "self", ")", ":", "\n", "        ", "return", "HT100MDataset", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datamodules.howto100m_datamodule.HT100MDataModule.dataset_name": [[17, 20], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "dataset_name", "(", "self", ")", ":", "\n", "        ", "return", "\"howto100m\"", "\n", "", "", ""]], "home.repos.pwc.inspect_result.showlab_all-in-one.datamodules.ego4d_choice_datamodule.EGO4DChoiceDataModule.__init__": [[6, 8], ["datamodule_base.BaseDataModule.__init__"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.transforms.utils.UnNormalize.__init__"], ["    ", "def", "__init__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datamodules.ego4d_choice_datamodule.EGO4DChoiceDataModule.dataset_cls": [[9, 12], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "dataset_cls", "(", "self", ")", ":", "\n", "        ", "return", "EGO4DChoiceDataset", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datamodules.ego4d_choice_datamodule.EGO4DChoiceDataModule.dataset_cls_no_false": [[13, 16], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "dataset_cls_no_false", "(", "self", ")", ":", "\n", "        ", "return", "EGO4DChoiceDataset", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datamodules.ego4d_choice_datamodule.EGO4DChoiceDataModule.dataset_name": [[17, 20], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "dataset_name", "(", "self", ")", ":", "\n", "        ", "return", "\"ego4d_choice\"", "\n", "", "", ""]], "home.repos.pwc.inspect_result.showlab_all-in-one.datamodules.cc3m_datamodule.CC3MDataModule.__init__": [[6, 8], ["datamodule_base.BaseDataModule.__init__"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.transforms.utils.UnNormalize.__init__"], ["    ", "def", "__init__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datamodules.cc3m_datamodule.CC3MDataModule.dataset_cls": [[9, 12], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "dataset_cls", "(", "self", ")", ":", "\n", "        ", "return", "CC3MDataset", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datamodules.cc3m_datamodule.CC3MDataModule.dataset_name": [[13, 16], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "dataset_name", "(", "self", ")", ":", "\n", "        ", "return", "\"cc3m\"", "\n", "", "", ""]], "home.repos.pwc.inspect_result.showlab_all-in-one.datamodules.vcr_datamodule.VCRDataModule.__init__": [[6, 8], ["datamodule_base.BaseDataModule.__init__"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.transforms.utils.UnNormalize.__init__"], ["    ", "def", "__init__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datamodules.vcr_datamodule.VCRDataModule.dataset_cls": [[9, 12], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "dataset_cls", "(", "self", ")", ":", "\n", "        ", "return", "VCRDataset", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datamodules.vcr_datamodule.VCRDataModule.dataset_name": [[13, 16], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "dataset_name", "(", "self", ")", ":", "\n", "        ", "return", "\"vcr\"", "\n", "", "", ""]], "home.repos.pwc.inspect_result.showlab_all-in-one.datamodules.k400_datamodule.K400DataModule.__init__": [[6, 8], ["datamodule_base.BaseDataModule.__init__"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.transforms.utils.UnNormalize.__init__"], ["    ", "def", "__init__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datamodules.k400_datamodule.K400DataModule.dataset_cls": [[9, 12], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "dataset_cls", "(", "self", ")", ":", "\n", "        ", "return", "K400Dataset", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datamodules.k400_datamodule.K400DataModule.dataset_cls_no_false": [[13, 16], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "dataset_cls_no_false", "(", "self", ")", ":", "\n", "        ", "return", "K400Dataset", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datamodules.k400_datamodule.K400DataModule.dataset_name": [[17, 20], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "dataset_name", "(", "self", ")", ":", "\n", "        ", "return", "\"k400\"", "\n", "", "", ""]], "home.repos.pwc.inspect_result.showlab_all-in-one.datamodules.lsmdc_choice_datamodule.LSMDCChoiceDataModule.__init__": [[6, 8], ["datamodule_base.BaseDataModule.__init__"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.transforms.utils.UnNormalize.__init__"], ["    ", "def", "__init__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datamodules.lsmdc_choice_datamodule.LSMDCChoiceDataModule.dataset_cls": [[9, 12], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "dataset_cls", "(", "self", ")", ":", "\n", "        ", "return", "LSMDCChoiceDataset", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datamodules.lsmdc_choice_datamodule.LSMDCChoiceDataModule.dataset_cls_no_false": [[13, 16], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "dataset_cls_no_false", "(", "self", ")", ":", "\n", "        ", "return", "LSMDCChoiceDataset", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datamodules.lsmdc_choice_datamodule.LSMDCChoiceDataModule.dataset_name": [[17, 20], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "dataset_name", "(", "self", ")", ":", "\n", "        ", "return", "\"lsmdc_choice\"", "\n", "", "", ""]], "home.repos.pwc.inspect_result.showlab_all-in-one.datamodules.msvdqa_datamodule.MSVDQADataModule.__init__": [[7, 9], ["datamodule_base.BaseDataModule.__init__"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.transforms.utils.UnNormalize.__init__"], ["    ", "def", "__init__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datamodules.msvdqa_datamodule.MSVDQADataModule.dataset_cls": [[10, 13], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "dataset_cls", "(", "self", ")", ":", "\n", "        ", "return", "MSVDQADataset", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datamodules.msvdqa_datamodule.MSVDQADataModule.dataset_name": [[14, 17], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "dataset_name", "(", "self", ")", ":", "\n", "        ", "return", "\"msvdqa\"", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datamodules.msvdqa_datamodule.MSVDQADataModule.setup": [[18, 26], ["super().setup", "sorted", "collections.defaultdict", "msvdqa_datamodule.MSVDQADataModule.answer2id.items", "max", "msvdqa_datamodule.MSVDQADataModule.answer2id.values"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.image.vqav2_datamodule.VQAv2DataModule.setup"], ["", "def", "setup", "(", "self", ",", "stage", ")", ":", "\n", "        ", "super", "(", ")", ".", "setup", "(", "stage", ")", "\n", "self", ".", "answer2id", "=", "self", ".", "train_dataset", ".", "ans_lab_dict", "\n", "sorted_a2i", "=", "sorted", "(", "self", ".", "answer2id", ".", "items", "(", ")", ",", "key", "=", "lambda", "x", ":", "x", "[", "1", "]", ")", "\n", "self", ".", "num_class", "=", "max", "(", "self", ".", "answer2id", ".", "values", "(", ")", ")", "+", "1", "\n", "self", ".", "id2answer", "=", "defaultdict", "(", "lambda", ":", "\"unknown\"", ")", "\n", "for", "k", ",", "v", "in", "sorted_a2i", ":", "\n", "            ", "self", ".", "id2answer", "[", "v", "]", "=", "k", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.showlab_all-in-one.datamodules.msrvtt_choice_datamodule.MSRVTTChoiceDataModule.__init__": [[6, 8], ["datamodule_base.BaseDataModule.__init__"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.transforms.utils.UnNormalize.__init__"], ["    ", "def", "__init__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datamodules.msrvtt_choice_datamodule.MSRVTTChoiceDataModule.dataset_cls": [[9, 12], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "dataset_cls", "(", "self", ")", ":", "\n", "        ", "return", "MSRVTTChoiceDataset", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datamodules.msrvtt_choice_datamodule.MSRVTTChoiceDataModule.dataset_cls_no_false": [[13, 16], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "dataset_cls_no_false", "(", "self", ")", ":", "\n", "        ", "return", "MSRVTTChoiceDataset", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datamodules.msrvtt_choice_datamodule.MSRVTTChoiceDataModule.dataset_name": [[17, 20], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "dataset_name", "(", "self", ")", ":", "\n", "        ", "return", "\"msrvtt_choice\"", "\n", "", "", ""]], "home.repos.pwc.inspect_result.showlab_all-in-one.datamodules.vqav2_datamodule.VQAv2DataModule.__init__": [[7, 9], ["datamodule_base.BaseDataModule.__init__"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.transforms.utils.UnNormalize.__init__"], ["    ", "def", "__init__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datamodules.vqav2_datamodule.VQAv2DataModule.dataset_cls": [[10, 13], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "dataset_cls", "(", "self", ")", ":", "\n", "        ", "return", "VQAv2Dataset", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datamodules.vqav2_datamodule.VQAv2DataModule.dataset_name": [[14, 17], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "dataset_name", "(", "self", ")", ":", "\n", "        ", "return", "\"vqa\"", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datamodules.vqav2_datamodule.VQAv2DataModule.setup": [[18, 37], ["super().setup", "vqav2_datamodule.VQAv2DataModule.train_dataset.table[].to_pandas().tolist", "vqav2_datamodule.VQAv2DataModule.val_dataset.table[].to_pandas().tolist", "vqav2_datamodule.VQAv2DataModule.train_dataset.table[].to_pandas().tolist", "vqav2_datamodule.VQAv2DataModule.val_dataset.table[].to_pandas().tolist", "sorted", "collections.defaultdict", "vqav2_datamodule.VQAv2DataModule.answer2id.items", "max", "vqav2_datamodule.VQAv2DataModule.train_dataset.table[].to_pandas", "vqav2_datamodule.VQAv2DataModule.val_dataset.table[].to_pandas", "vqav2_datamodule.VQAv2DataModule.train_dataset.table[].to_pandas", "vqav2_datamodule.VQAv2DataModule.val_dataset.table[].to_pandas", "zip", "vqav2_datamodule.VQAv2DataModule.answer2id.values"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.image.vqav2_datamodule.VQAv2DataModule.setup"], ["", "def", "setup", "(", "self", ",", "stage", ")", ":", "\n", "        ", "super", "(", ")", ".", "setup", "(", "stage", ")", "\n", "\n", "train_answers", "=", "self", ".", "train_dataset", ".", "table", "[", "\"answers\"", "]", ".", "to_pandas", "(", ")", ".", "tolist", "(", ")", "\n", "val_answers", "=", "self", ".", "val_dataset", ".", "table", "[", "\"answers\"", "]", ".", "to_pandas", "(", ")", ".", "tolist", "(", ")", "\n", "train_labels", "=", "self", ".", "train_dataset", ".", "table", "[", "\"answer_labels\"", "]", ".", "to_pandas", "(", ")", ".", "tolist", "(", ")", "\n", "val_labels", "=", "self", ".", "val_dataset", ".", "table", "[", "\"answer_labels\"", "]", ".", "to_pandas", "(", ")", ".", "tolist", "(", ")", "\n", "\n", "all_answers", "=", "[", "c", "for", "c", "in", "train_answers", "+", "val_answers", "if", "c", "is", "not", "None", "]", "\n", "all_answers", "=", "[", "l", "for", "lll", "in", "all_answers", "for", "ll", "in", "lll", "for", "l", "in", "ll", "]", "\n", "all_labels", "=", "[", "c", "for", "c", "in", "train_labels", "+", "val_labels", "if", "c", "is", "not", "None", "]", "\n", "all_labels", "=", "[", "l", "for", "lll", "in", "all_labels", "for", "ll", "in", "lll", "for", "l", "in", "ll", "]", "\n", "\n", "self", ".", "answer2id", "=", "{", "k", ":", "v", "for", "k", ",", "v", "in", "zip", "(", "all_answers", ",", "all_labels", ")", "}", "\n", "sorted_a2i", "=", "sorted", "(", "self", ".", "answer2id", ".", "items", "(", ")", ",", "key", "=", "lambda", "x", ":", "x", "[", "1", "]", ")", "\n", "self", ".", "num_class", "=", "max", "(", "self", ".", "answer2id", ".", "values", "(", ")", ")", "+", "1", "\n", "self", ".", "id2answer", "=", "defaultdict", "(", "lambda", ":", "\"unknown\"", ")", "\n", "for", "k", ",", "v", "in", "sorted_a2i", ":", "\n", "            ", "self", ".", "id2answer", "[", "v", "]", "=", "k", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.showlab_all-in-one.datamodules.ego4d_datamodule.Ego4DDataModule.__init__": [[6, 8], ["datamodule_base.BaseDataModule.__init__"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.transforms.utils.UnNormalize.__init__"], ["    ", "def", "__init__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datamodules.ego4d_datamodule.Ego4DDataModule.dataset_cls": [[9, 12], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "dataset_cls", "(", "self", ")", ":", "\n", "        ", "return", "Ego4DDataset", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datamodules.ego4d_datamodule.Ego4DDataModule.dataset_cls_no_false": [[13, 16], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "dataset_cls_no_false", "(", "self", ")", ":", "\n", "        ", "return", "Ego4DDataset", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datamodules.ego4d_datamodule.Ego4DDataModule.dataset_name": [[17, 20], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "dataset_name", "(", "self", ")", ":", "\n", "        ", "return", "\"ego4d\"", "\n", "", "", ""]], "home.repos.pwc.inspect_result.showlab_all-in-one.datamodules.sbu_datamodule.SBUCaptionDataModule.__init__": [[6, 8], ["datamodule_base.BaseDataModule.__init__"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.transforms.utils.UnNormalize.__init__"], ["    ", "def", "__init__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datamodules.sbu_datamodule.SBUCaptionDataModule.dataset_cls": [[9, 12], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "dataset_cls", "(", "self", ")", ":", "\n", "        ", "return", "SBUCaptionDataset", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datamodules.sbu_datamodule.SBUCaptionDataModule.dataset_name": [[13, 16], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "dataset_name", "(", "self", ")", ":", "\n", "        ", "return", "\"sbu\"", "\n", "", "", ""]], "home.repos.pwc.inspect_result.showlab_all-in-one.datamodules.yttemporal_datamodule.YTTemporalMDataModule.__init__": [[6, 8], ["datamodule_base.BaseDataModule.__init__"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.transforms.utils.UnNormalize.__init__"], ["    ", "def", "__init__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datamodules.yttemporal_datamodule.YTTemporalMDataModule.dataset_cls": [[9, 12], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "dataset_cls", "(", "self", ")", ":", "\n", "        ", "return", "YTTemporalDataset", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datamodules.yttemporal_datamodule.YTTemporalMDataModule.dataset_cls_no_false": [[13, 16], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "dataset_cls_no_false", "(", "self", ")", ":", "\n", "        ", "return", "YTTemporalDataset", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datamodules.yttemporal_datamodule.YTTemporalMDataModule.dataset_name": [[17, 20], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "dataset_name", "(", "self", ")", ":", "\n", "        ", "return", "\"yttemporal\"", "\n", "", "", ""]], "home.repos.pwc.inspect_result.showlab_all-in-one.datamodules.tgif_datamodule.TGIFDataModule.__init__": [[6, 8], ["datamodule_base.BaseDataModule.__init__"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.transforms.utils.UnNormalize.__init__"], ["    ", "def", "__init__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datamodules.tgif_datamodule.TGIFDataModule.dataset_cls": [[9, 12], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "dataset_cls", "(", "self", ")", ":", "\n", "        ", "return", "TGIFDataset", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datamodules.tgif_datamodule.TGIFDataModule.dataset_cls_no_false": [[13, 16], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "dataset_cls_no_false", "(", "self", ")", ":", "\n", "        ", "return", "TGIFDataset", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datamodules.tgif_datamodule.TGIFDataModule.dataset_name": [[17, 20], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "dataset_name", "(", "self", ")", ":", "\n", "        ", "return", "\"tgif\"", "\n", "", "", ""]], "home.repos.pwc.inspect_result.showlab_all-in-one.datamodules.nlvr2_datamodule.NLVR2DataModule.__init__": [[6, 8], ["datamodule_base.BaseDataModule.__init__"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.transforms.utils.UnNormalize.__init__"], ["    ", "def", "__init__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datamodules.nlvr2_datamodule.NLVR2DataModule.dataset_cls": [[9, 12], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "dataset_cls", "(", "self", ")", ":", "\n", "        ", "return", "NLVR2Dataset", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datamodules.nlvr2_datamodule.NLVR2DataModule.dataset_name": [[13, 16], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "dataset_name", "(", "self", ")", ":", "\n", "        ", "return", "\"nlvr2\"", "\n", "", "", ""]], "home.repos.pwc.inspect_result.showlab_all-in-one.datamodules.lsmdc_datamodule.LSMDCDataModule.__init__": [[6, 8], ["datamodule_base.BaseDataModule.__init__"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.transforms.utils.UnNormalize.__init__"], ["    ", "def", "__init__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datamodules.lsmdc_datamodule.LSMDCDataModule.dataset_cls": [[9, 12], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "dataset_cls", "(", "self", ")", ":", "\n", "        ", "return", "LSMDCDataset", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datamodules.lsmdc_datamodule.LSMDCDataModule.dataset_cls_no_false": [[13, 16], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "dataset_cls_no_false", "(", "self", ")", ":", "\n", "        ", "return", "LSMDCDataset", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datamodules.lsmdc_datamodule.LSMDCDataModule.dataset_name": [[17, 20], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "dataset_name", "(", "self", ")", ":", "\n", "        ", "return", "\"lsmdc\"", "\n", "", "", ""]], "home.repos.pwc.inspect_result.showlab_all-in-one.datamodules.activitynet_datamodule.ActivityNetDataModule.__init__": [[6, 8], ["datamodule_base.BaseDataModule.__init__"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.transforms.utils.UnNormalize.__init__"], ["    ", "def", "__init__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datamodules.activitynet_datamodule.ActivityNetDataModule.dataset_cls": [[9, 12], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "dataset_cls", "(", "self", ")", ":", "\n", "        ", "return", "ActivityNetDataset", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datamodules.activitynet_datamodule.ActivityNetDataModule.dataset_name": [[13, 16], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "dataset_name", "(", "self", ")", ":", "\n", "        ", "return", "\"activitynet\"", "\n", "", "", ""]], "home.repos.pwc.inspect_result.showlab_all-in-one.datamodules.hmdb51_datamodule.HMDB51DataModule.__init__": [[6, 8], ["datamodule_base.BaseDataModule.__init__"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.transforms.utils.UnNormalize.__init__"], ["    ", "def", "__init__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datamodules.hmdb51_datamodule.HMDB51DataModule.dataset_cls": [[9, 12], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "dataset_cls", "(", "self", ")", ":", "\n", "        ", "return", "HMDB51Dataset", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datamodules.hmdb51_datamodule.HMDB51DataModule.dataset_cls_no_false": [[13, 16], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "dataset_cls_no_false", "(", "self", ")", ":", "\n", "        ", "return", "HMDB51Dataset", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datamodules.hmdb51_datamodule.HMDB51DataModule.dataset_name": [[17, 20], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "dataset_name", "(", "self", ")", ":", "\n", "        ", "return", "\"hmdb51\"", "\n", "", "", ""]], "home.repos.pwc.inspect_result.showlab_all-in-one.datamodules.msrvttqa_datamodule.MSRVTTQADataModule.__init__": [[7, 9], ["datamodule_base.BaseDataModule.__init__"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.transforms.utils.UnNormalize.__init__"], ["    ", "def", "__init__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datamodules.msrvttqa_datamodule.MSRVTTQADataModule.dataset_cls": [[10, 13], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "dataset_cls", "(", "self", ")", ":", "\n", "        ", "return", "MSRVTTQADataset", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datamodules.msrvttqa_datamodule.MSRVTTQADataModule.dataset_name": [[14, 17], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "dataset_name", "(", "self", ")", ":", "\n", "        ", "return", "\"msrvttqa\"", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datamodules.msrvttqa_datamodule.MSRVTTQADataModule.setup": [[18, 26], ["super().setup", "sorted", "collections.defaultdict", "msrvttqa_datamodule.MSRVTTQADataModule.answer2id.items", "max", "msrvttqa_datamodule.MSRVTTQADataModule.answer2id.values"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.image.vqav2_datamodule.VQAv2DataModule.setup"], ["", "def", "setup", "(", "self", ",", "stage", ")", ":", "\n", "        ", "super", "(", ")", ".", "setup", "(", "stage", ")", "\n", "self", ".", "answer2id", "=", "self", ".", "train_dataset", ".", "ans_lab_dict", "\n", "sorted_a2i", "=", "sorted", "(", "self", ".", "answer2id", ".", "items", "(", ")", ",", "key", "=", "lambda", "x", ":", "x", "[", "1", "]", ")", "\n", "self", ".", "num_class", "=", "max", "(", "self", ".", "answer2id", ".", "values", "(", ")", ")", "+", "1", "\n", "self", ".", "id2answer", "=", "defaultdict", "(", "lambda", ":", "\"unknown\"", ")", "\n", "for", "k", ",", "v", "in", "sorted_a2i", ":", "\n", "            ", "self", ".", "id2answer", "[", "v", "]", "=", "k", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.showlab_all-in-one.datamodules.webvid_datamodule.WEBVIDDataModule.__init__": [[6, 8], ["datamodule_base.BaseDataModule.__init__"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.transforms.utils.UnNormalize.__init__"], ["    ", "def", "__init__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datamodules.webvid_datamodule.WEBVIDDataModule.dataset_cls": [[9, 12], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "dataset_cls", "(", "self", ")", ":", "\n", "        ", "return", "WEBVIDDataset", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datamodules.webvid_datamodule.WEBVIDDataModule.dataset_cls_no_false": [[13, 16], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "dataset_cls_no_false", "(", "self", ")", ":", "\n", "        ", "return", "WEBVIDDataset", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datamodules.webvid_datamodule.WEBVIDDataModule.dataset_name": [[17, 20], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "dataset_name", "(", "self", ")", ":", "\n", "        ", "return", "\"webvid\"", "\n", "", "", ""]], "home.repos.pwc.inspect_result.showlab_all-in-one.datamodules.msvd_datamodule.MSVDDataModule.__init__": [[6, 8], ["datamodule_base.BaseDataModule.__init__"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.transforms.utils.UnNormalize.__init__"], ["    ", "def", "__init__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datamodules.msvd_datamodule.MSVDDataModule.dataset_cls": [[9, 12], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "dataset_cls", "(", "self", ")", ":", "\n", "        ", "return", "MSVDDataset", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datamodules.msvd_datamodule.MSVDDataModule.dataset_cls_no_false": [[13, 16], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "dataset_cls_no_false", "(", "self", ")", ":", "\n", "        ", "return", "MSVDDataset", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datamodules.msvd_datamodule.MSVDDataModule.dataset_name": [[17, 20], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "dataset_name", "(", "self", ")", ":", "\n", "        ", "return", "\"msvd\"", "\n", "", "", ""]], "home.repos.pwc.inspect_result.showlab_all-in-one.datamodules.msrvtt_datamodule.MSRVTTDataModule.__init__": [[6, 8], ["datamodule_base.BaseDataModule.__init__"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.transforms.utils.UnNormalize.__init__"], ["    ", "def", "__init__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datamodules.msrvtt_datamodule.MSRVTTDataModule.dataset_cls": [[9, 12], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "dataset_cls", "(", "self", ")", ":", "\n", "        ", "return", "MSRVTTDataset", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datamodules.msrvtt_datamodule.MSRVTTDataModule.dataset_cls_no_false": [[13, 16], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "dataset_cls_no_false", "(", "self", ")", ":", "\n", "        ", "return", "MSRVTTDataset", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datamodules.msrvtt_datamodule.MSRVTTDataModule.dataset_name": [[17, 20], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "dataset_name", "(", "self", ")", ":", "\n", "        ", "return", "\"msrvtt\"", "\n", "", "", ""]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.multitask_datamodule.MTDataModule.__init__": [[13, 37], ["len", "len", "pytorch_lightning.LightningDataModule.__init__", "multitask_datamodule.MTDataModule.video_dm_dicts.items", "multitask_datamodule.MTDataModule.image_dm_dicts.items"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.transforms.utils.UnNormalize.__init__"], ["    ", "def", "__init__", "(", "self", ",", "_config", ",", "dist", "=", "False", ")", ":", "\n", "        ", "video_datamodule_keys", "=", "_config", "[", "\"video_datasets\"", "]", "\n", "image_datamodule_keys", "=", "_config", "[", "\"image_datasets\"", "]", "\n", "self", ".", "num_video_datasets", "=", "len", "(", "video_datamodule_keys", ")", "\n", "self", ".", "num_image_datasets", "=", "len", "(", "image_datamodule_keys", ")", "\n", "\n", "assert", "self", ".", "num_video_datasets", ">", "0", "or", "self", ".", "num_image_datasets", ">", "0", "\n", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "if", "self", ".", "num_video_datasets", ">", "0", ":", "\n", "            ", "self", ".", "video_dm_keys", "=", "video_datamodule_keys", "\n", "self", ".", "video_dm_dicts", "=", "{", "key", ":", "_datamodules", "[", "key", "]", "(", "_config", ")", "for", "key", "in", "video_datamodule_keys", "}", "\n", "self", ".", "video_dms", "=", "[", "v", "for", "k", ",", "v", "in", "self", ".", "video_dm_dicts", ".", "items", "(", ")", "]", "\n", "self", ".", "video_batch_size", "=", "self", ".", "video_dms", "[", "0", "]", ".", "batch_size", "\n", "self", ".", "video_vocab_size", "=", "self", ".", "video_dms", "[", "0", "]", ".", "vocab_size", "\n", "self", ".", "video_num_workers", "=", "self", ".", "video_dms", "[", "0", "]", ".", "num_workers", "\n", "", "if", "self", ".", "num_image_datasets", ":", "\n", "            ", "self", ".", "image_dm_keys", "=", "image_datamodule_keys", "\n", "self", ".", "image_dm_dicts", "=", "{", "key", ":", "_datamodules", "[", "key", "]", "(", "_config", ")", "for", "key", "in", "image_datamodule_keys", "}", "\n", "self", ".", "image_dms", "=", "[", "v", "for", "k", ",", "v", "in", "self", ".", "image_dm_dicts", ".", "items", "(", ")", "]", "\n", "self", ".", "image_batch_size", "=", "self", ".", "image_dms", "[", "0", "]", ".", "batch_size", "\n", "self", ".", "image_vocab_size", "=", "self", ".", "image_dms", "[", "0", "]", ".", "vocab_size", "\n", "self", ".", "image_num_workers", "=", "self", ".", "image_dms", "[", "0", "]", ".", "num_workers", "\n", "", "self", ".", "dist", "=", "dist", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.multitask_datamodule.MTDataModule.prepare_data": [[38, 45], ["dm.prepare_data", "dm.prepare_data"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.video.multitask_datamodule.MTDataModule.prepare_data", "home.repos.pwc.inspect_result.showlab_all-in-one.video.multitask_datamodule.MTDataModule.prepare_data"], ["", "def", "prepare_data", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "num_video_datasets", ":", "\n", "            ", "for", "dm", "in", "self", ".", "video_dms", ":", "\n", "                ", "dm", ".", "prepare_data", "(", ")", "\n", "", "", "if", "self", ".", "num_image_datasets", ":", "\n", "            ", "for", "dm", "in", "self", ".", "image_dms", ":", "\n", "                ", "dm", ".", "prepare_data", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.multitask_datamodule.MTDataModule.setup": [[46, 94], ["torch.utils.data.dataset.ConcatDataset", "torch.utils.data.dataset.ConcatDataset", "torch.utils.data.dataset.ConcatDataset", "torch.utils.data.dataset.ConcatDataset", "torch.utils.data.dataset.ConcatDataset", "torch.utils.data.dataset.ConcatDataset", "len", "functools.partial", "functools.partial", "dm.setup", "dm.setup", "torch.utils.data.distributed.DistributedSampler", "torch.utils.data.distributed.DistributedSampler", "torch.utils.data.distributed.DistributedSampler", "torch.utils.data.distributed.DistributedSampler", "torch.utils.data.distributed.DistributedSampler", "torch.utils.data.distributed.DistributedSampler"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.image.vqav2_datamodule.VQAv2DataModule.setup", "home.repos.pwc.inspect_result.showlab_all-in-one.image.vqav2_datamodule.VQAv2DataModule.setup"], ["", "", "", "def", "setup", "(", "self", ",", "stage", ")", ":", "\n", "        ", "if", "self", ".", "num_video_datasets", ":", "\n", "            ", "for", "dm", "in", "self", ".", "video_dms", ":", "\n", "                ", "dm", ".", "setup", "(", "stage", ")", "\n", "", "", "if", "self", ".", "num_image_datasets", ":", "\n", "            ", "for", "dm", "in", "self", ".", "image_dms", ":", "\n", "                ", "dm", ".", "setup", "(", "stage", ")", "\n", "\n", "", "", "if", "self", ".", "num_video_datasets", ":", "\n", "            ", "self", ".", "video_train_dataset", "=", "ConcatDataset", "(", "[", "dm", ".", "train_dataset", "for", "dm", "in", "self", ".", "video_dms", "]", ")", "\n", "self", ".", "video_val_dataset", "=", "ConcatDataset", "(", "[", "dm", ".", "val_dataset", "for", "dm", "in", "self", ".", "video_dms", "]", ")", "\n", "self", ".", "video_test_dataset", "=", "ConcatDataset", "(", "[", "dm", ".", "test_dataset", "for", "dm", "in", "self", ".", "video_dms", "]", ")", "\n", "\n", "", "if", "self", ".", "num_image_datasets", ":", "\n", "            ", "self", ".", "image_train_dataset", "=", "ConcatDataset", "(", "[", "dm", ".", "train_dataset", "for", "dm", "in", "self", ".", "image_dms", "]", ")", "\n", "self", ".", "image_val_dataset", "=", "ConcatDataset", "(", "[", "dm", ".", "val_dataset", "for", "dm", "in", "self", ".", "image_dms", "]", ")", "\n", "self", ".", "image_test_dataset", "=", "ConcatDataset", "(", "[", "dm", ".", "test_dataset", "for", "dm", "in", "self", ".", "image_dms", "]", ")", "\n", "\n", "", "if", "len", "(", "self", ".", "video_dms", ")", ">", "0", ":", "\n", "            ", "self", ".", "tokenizer", "=", "self", ".", "video_dms", "[", "0", "]", ".", "tokenizer", "\n", "", "else", ":", "\n", "            ", "self", ".", "tokenizer", "=", "self", ".", "image_dms", "[", "0", "]", ".", "tokenizer", "\n", "\n", "", "if", "self", ".", "num_video_datasets", ":", "\n", "            ", "self", ".", "video_collate", "=", "functools", ".", "partial", "(", "\n", "self", ".", "video_dms", "[", "0", "]", ".", "train_dataset", ".", "collate", ",", "mlm_collator", "=", "self", ".", "video_dms", "[", "0", "]", ".", "mlm_collator", ",", "\n", ")", "\n", "", "if", "self", ".", "num_image_datasets", ":", "\n", "            ", "self", ".", "image_collate", "=", "functools", ".", "partial", "(", "\n", "self", ".", "image_dms", "[", "0", "]", ".", "train_dataset", ".", "collate", ",", "mlm_collator", "=", "self", ".", "image_dms", "[", "0", "]", ".", "mlm_collator", ",", "\n", ")", "\n", "\n", "", "if", "self", ".", "dist", ":", "\n", "            ", "if", "self", ".", "num_video_datasets", ":", "\n", "                ", "self", ".", "video_train_sampler", "=", "DistributedSampler", "(", "self", ".", "video_train_dataset", ",", "shuffle", "=", "True", ")", "\n", "self", ".", "video_val_sampler", "=", "DistributedSampler", "(", "self", ".", "video_val_dataset", ",", "shuffle", "=", "True", ")", "\n", "self", ".", "video_test_sampler", "=", "DistributedSampler", "(", "self", ".", "video_test_dataset", ",", "shuffle", "=", "False", ")", "\n", "", "if", "self", ".", "num_image_datasets", ":", "\n", "                ", "self", ".", "image_train_sampler", "=", "DistributedSampler", "(", "self", ".", "image_train_dataset", ",", "shuffle", "=", "True", ")", "\n", "self", ".", "image_val_sampler", "=", "DistributedSampler", "(", "self", ".", "image_val_dataset", ",", "shuffle", "=", "True", ")", "\n", "self", ".", "image_test_sampler", "=", "DistributedSampler", "(", "self", ".", "image_test_dataset", ",", "shuffle", "=", "False", ")", "\n", "", "", "else", ":", "\n", "            ", "self", ".", "video_train_sampler", "=", "None", "\n", "self", ".", "video_val_sampler", "=", "None", "\n", "self", ".", "video_test_sampler", "=", "None", "\n", "self", ".", "image_train_sampler", "=", "None", "\n", "self", ".", "image_val_sampler", "=", "None", "\n", "self", ".", "image_test_sampler", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.multitask_datamodule.MTDataModule.train_dataloader": [[95, 121], ["torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "pytorch_lightning.trainer.supporters.CombinedLoader"], "methods", ["None"], ["", "", "def", "train_dataloader", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "num_video_datasets", ":", "\n", "            ", "video_loader", "=", "DataLoader", "(", "\n", "self", ".", "video_train_dataset", ",", "\n", "batch_size", "=", "self", ".", "video_batch_size", ",", "\n", "sampler", "=", "self", ".", "video_train_sampler", ",", "\n", "num_workers", "=", "self", ".", "video_num_workers", ",", "\n", "collate_fn", "=", "self", ".", "video_collate", ",", "\n", ")", "\n", "", "if", "self", ".", "num_image_datasets", ":", "\n", "            ", "image_loader", "=", "DataLoader", "(", "\n", "self", ".", "image_train_dataset", ",", "\n", "batch_size", "=", "self", ".", "image_batch_size", ",", "\n", "sampler", "=", "self", ".", "image_train_sampler", ",", "\n", "num_workers", "=", "self", ".", "image_num_workers", ",", "\n", "collate_fn", "=", "self", ".", "image_collate", ",", "\n", ")", "\n", "", "if", "self", ".", "num_video_datasets", "and", "self", ".", "num_image_datasets", ":", "\n", "            ", "loaders", "=", "{", "\"v\"", ":", "video_loader", ",", "\"i\"", ":", "image_loader", "}", "\n", "combined_loader", "=", "CombinedLoader", "(", "loaders", ",", "mode", "=", "\"min_size\"", ")", "# \"min_size\" / \"max_size_cycle\",", "\n", "", "else", ":", "\n", "            ", "if", "self", ".", "num_video_datasets", ":", "\n", "                ", "combined_loader", "=", "video_loader", "\n", "", "else", ":", "\n", "                ", "combined_loader", "=", "image_loader", "\n", "", "", "return", "combined_loader", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.multitask_datamodule.MTDataModule.val_dataloader": [[122, 148], ["torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "pytorch_lightning.trainer.supporters.CombinedLoader"], "methods", ["None"], ["", "def", "val_dataloader", "(", "self", ",", "batch_size", "=", "None", ")", ":", "\n", "        ", "if", "self", ".", "num_video_datasets", ":", "\n", "            ", "video_loader", "=", "DataLoader", "(", "\n", "self", ".", "video_val_dataset", ",", "\n", "batch_size", "=", "batch_size", "if", "batch_size", "is", "not", "None", "else", "self", ".", "video_batch_size", ",", "\n", "sampler", "=", "self", ".", "video_val_sampler", ",", "\n", "num_workers", "=", "self", ".", "video_num_workers", ",", "\n", "collate_fn", "=", "self", ".", "video_collate", ",", "\n", ")", "\n", "", "if", "self", ".", "num_image_datasets", ":", "\n", "            ", "image_loader", "=", "DataLoader", "(", "\n", "self", ".", "image_val_dataset", ",", "\n", "batch_size", "=", "batch_size", "if", "batch_size", "is", "not", "None", "else", "self", ".", "image_batch_size", ",", "\n", "sampler", "=", "self", ".", "image_val_sampler", ",", "\n", "num_workers", "=", "self", ".", "image_num_workers", ",", "\n", "collate_fn", "=", "self", ".", "image_collate", ",", "\n", ")", "\n", "", "if", "self", ".", "num_video_datasets", "and", "self", ".", "num_image_datasets", ":", "\n", "            ", "loaders", "=", "{", "\"v\"", ":", "video_loader", ",", "\"i\"", ":", "image_loader", "}", "\n", "combined_loader", "=", "CombinedLoader", "(", "loaders", ",", "mode", "=", "\"min_size\"", ")", "# min_size / max_size_cycle", "\n", "", "else", ":", "\n", "            ", "if", "self", ".", "num_video_datasets", ":", "\n", "                ", "combined_loader", "=", "video_loader", "\n", "", "else", ":", "\n", "                ", "combined_loader", "=", "image_loader", "\n", "", "", "return", "combined_loader", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.multitask_datamodule.MTDataModule.test_dataloader": [[150, 176], ["torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "pytorch_lightning.trainer.supporters.CombinedLoader"], "methods", ["None"], ["", "def", "test_dataloader", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "num_video_datasets", ":", "\n", "            ", "video_loader", "=", "DataLoader", "(", "\n", "self", ".", "video_test_dataset", ",", "\n", "batch_size", "=", "self", ".", "video_batch_size", ",", "\n", "sampler", "=", "self", ".", "video_test_sampler", ",", "\n", "num_workers", "=", "self", ".", "video_num_workers", ",", "\n", "collate_fn", "=", "self", ".", "video_collate", ",", "\n", ")", "\n", "", "if", "self", ".", "num_image_datasets", ":", "\n", "            ", "image_loader", "=", "DataLoader", "(", "\n", "self", ".", "image_test_dataset", ",", "\n", "batch_size", "=", "self", ".", "image_batch_size", ",", "\n", "sampler", "=", "self", ".", "image_test_sampler", ",", "\n", "num_workers", "=", "self", ".", "image_num_workers", ",", "\n", "collate_fn", "=", "self", ".", "image_collate", ",", "\n", ")", "\n", "", "if", "self", ".", "num_video_datasets", "and", "self", ".", "num_image_datasets", ":", "\n", "            ", "loaders", "=", "{", "\"v\"", ":", "video_loader", ",", "\"i\"", ":", "image_loader", "}", "\n", "combined_loader", "=", "CombinedLoader", "(", "loaders", ",", "mode", "=", "\"min_size\"", ")", "# min_size / max_size_cycle", "\n", "", "else", ":", "\n", "            ", "if", "self", ".", "num_video_datasets", ":", "\n", "                ", "combined_loader", "=", "video_loader", "\n", "", "else", ":", "\n", "                ", "combined_loader", "=", "image_loader", "\n", "", "", "return", "combined_loader", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.tgifqa_datamodule.TGIFQADataModule.__init__": [[6, 8], ["CoTrain.datamodules.image.datamodule_base.BaseDataModule.__init__"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.transforms.utils.UnNormalize.__init__"], ["    ", "def", "__init__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.tgifqa_datamodule.TGIFQADataModule.dataset_cls": [[9, 12], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "dataset_cls", "(", "self", ")", ":", "\n", "        ", "return", "TGIFQADataset", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.tgifqa_datamodule.TGIFQADataModule.dataset_cls_no_false": [[13, 16], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "dataset_cls_no_false", "(", "self", ")", ":", "\n", "        ", "return", "TGIFQADataset", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.tgifqa_datamodule.TGIFQADataModule.dataset_name": [[17, 20], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "dataset_name", "(", "self", ")", ":", "\n", "        ", "return", "\"tgifqa\"", "\n", "", "", ""]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.didemo_datamodule.DIDEMODataModule.__init__": [[6, 8], ["CoTrain.datamodules.image.datamodule_base.BaseDataModule.__init__"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.transforms.utils.UnNormalize.__init__"], ["    ", "def", "__init__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.didemo_datamodule.DIDEMODataModule.dataset_cls": [[9, 12], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "dataset_cls", "(", "self", ")", ":", "\n", "        ", "return", "DIDEMODataset", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.didemo_datamodule.DIDEMODataModule.dataset_cls_no_false": [[13, 16], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "dataset_cls_no_false", "(", "self", ")", ":", "\n", "        ", "return", "DIDEMODataset", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.didemo_datamodule.DIDEMODataModule.dataset_name": [[17, 20], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "dataset_name", "(", "self", ")", ":", "\n", "        ", "return", "\"didemo\"", "\n", "", "", ""]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.tvqa_datamodule.TVQADataModule.__init__": [[6, 8], ["CoTrain.datamodules.image.datamodule_base.BaseDataModule.__init__"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.transforms.utils.UnNormalize.__init__"], ["    ", "def", "__init__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.tvqa_datamodule.TVQADataModule.dataset_cls": [[9, 12], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "dataset_cls", "(", "self", ")", ":", "\n", "        ", "return", "TVQADataset", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.tvqa_datamodule.TVQADataModule.dataset_cls_no_false": [[13, 16], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "dataset_cls_no_false", "(", "self", ")", ":", "\n", "        ", "return", "TVQADataset", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.tvqa_datamodule.TVQADataModule.dataset_name": [[17, 20], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "dataset_name", "(", "self", ")", ":", "\n", "        ", "return", "\"tvqa\"", "\n", "", "", ""]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.howto100m_datamodule.HT100MDataModule.__init__": [[6, 8], ["CoTrain.datamodules.image.datamodule_base.BaseDataModule.__init__"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.transforms.utils.UnNormalize.__init__"], ["    ", "def", "__init__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.howto100m_datamodule.HT100MDataModule.dataset_cls": [[9, 12], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "dataset_cls", "(", "self", ")", ":", "\n", "        ", "return", "HT100MDataset", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.howto100m_datamodule.HT100MDataModule.dataset_cls_no_false": [[13, 16], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "dataset_cls_no_false", "(", "self", ")", ":", "\n", "        ", "return", "HT100MDataset", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.howto100m_datamodule.HT100MDataModule.dataset_name": [[17, 20], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "dataset_name", "(", "self", ")", ":", "\n", "        ", "return", "\"howto100m\"", "\n", "", "", ""]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.ego4d_choice_datamodule.EGO4DChoiceDataModule.__init__": [[6, 8], ["CoTrain.datamodules.image.datamodule_base.BaseDataModule.__init__"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.transforms.utils.UnNormalize.__init__"], ["    ", "def", "__init__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.ego4d_choice_datamodule.EGO4DChoiceDataModule.dataset_cls": [[9, 12], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "dataset_cls", "(", "self", ")", ":", "\n", "        ", "return", "EGO4DChoiceDataset", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.ego4d_choice_datamodule.EGO4DChoiceDataModule.dataset_cls_no_false": [[13, 16], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "dataset_cls_no_false", "(", "self", ")", ":", "\n", "        ", "return", "EGO4DChoiceDataset", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.ego4d_choice_datamodule.EGO4DChoiceDataModule.dataset_name": [[17, 20], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "dataset_name", "(", "self", ")", ":", "\n", "        ", "return", "\"ego4d_choice\"", "\n", "", "", ""]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.k400_datamodule.K400DataModule.__init__": [[6, 8], ["CoTrain.datamodules.image.datamodule_base.BaseDataModule.__init__"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.transforms.utils.UnNormalize.__init__"], ["    ", "def", "__init__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.k400_datamodule.K400DataModule.dataset_cls": [[9, 12], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "dataset_cls", "(", "self", ")", ":", "\n", "        ", "return", "K400Dataset", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.k400_datamodule.K400DataModule.dataset_cls_no_false": [[13, 16], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "dataset_cls_no_false", "(", "self", ")", ":", "\n", "        ", "return", "K400Dataset", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.k400_datamodule.K400DataModule.dataset_name": [[17, 20], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "dataset_name", "(", "self", ")", ":", "\n", "        ", "return", "\"k400\"", "\n", "", "", ""]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.lsmdc_choice_datamodule.LSMDCChoiceDataModule.__init__": [[6, 8], ["CoTrain.datamodules.image.datamodule_base.BaseDataModule.__init__"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.transforms.utils.UnNormalize.__init__"], ["    ", "def", "__init__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.lsmdc_choice_datamodule.LSMDCChoiceDataModule.dataset_cls": [[9, 12], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "dataset_cls", "(", "self", ")", ":", "\n", "        ", "return", "LSMDCChoiceDataset", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.lsmdc_choice_datamodule.LSMDCChoiceDataModule.dataset_cls_no_false": [[13, 16], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "dataset_cls_no_false", "(", "self", ")", ":", "\n", "        ", "return", "LSMDCChoiceDataset", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.lsmdc_choice_datamodule.LSMDCChoiceDataModule.dataset_name": [[17, 20], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "dataset_name", "(", "self", ")", ":", "\n", "        ", "return", "\"lsmdc_choice\"", "\n", "", "", ""]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.msvdqa_datamodule.MSVDQADataModule.__init__": [[7, 9], ["CoTrain.datamodules.image.datamodule_base.BaseDataModule.__init__"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.transforms.utils.UnNormalize.__init__"], ["    ", "def", "__init__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.msvdqa_datamodule.MSVDQADataModule.dataset_cls": [[10, 13], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "dataset_cls", "(", "self", ")", ":", "\n", "        ", "return", "MSVDQADataset", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.msvdqa_datamodule.MSVDQADataModule.dataset_name": [[14, 17], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "dataset_name", "(", "self", ")", ":", "\n", "        ", "return", "\"msvdqa\"", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.msvdqa_datamodule.MSVDQADataModule.setup": [[18, 26], ["super().setup", "sorted", "collections.defaultdict", "msvdqa_datamodule.MSVDQADataModule.answer2id.items", "max", "msvdqa_datamodule.MSVDQADataModule.answer2id.values"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.image.vqav2_datamodule.VQAv2DataModule.setup"], ["", "def", "setup", "(", "self", ",", "stage", ")", ":", "\n", "        ", "super", "(", ")", ".", "setup", "(", "stage", ")", "\n", "self", ".", "answer2id", "=", "self", ".", "train_dataset", ".", "ans_lab_dict", "\n", "sorted_a2i", "=", "sorted", "(", "self", ".", "answer2id", ".", "items", "(", ")", ",", "key", "=", "lambda", "x", ":", "x", "[", "1", "]", ")", "\n", "self", ".", "num_class", "=", "max", "(", "self", ".", "answer2id", ".", "values", "(", ")", ")", "+", "1", "\n", "self", ".", "id2answer", "=", "defaultdict", "(", "lambda", ":", "\"unknown\"", ")", "\n", "for", "k", ",", "v", "in", "sorted_a2i", ":", "\n", "            ", "self", ".", "id2answer", "[", "v", "]", "=", "k", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.msrvtt_choice_datamodule.MSRVTTChoiceDataModule.__init__": [[6, 8], ["CoTrain.datamodules.image.datamodule_base.BaseDataModule.__init__"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.transforms.utils.UnNormalize.__init__"], ["    ", "def", "__init__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.msrvtt_choice_datamodule.MSRVTTChoiceDataModule.dataset_cls": [[9, 12], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "dataset_cls", "(", "self", ")", ":", "\n", "        ", "return", "MSRVTTChoiceDataset", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.msrvtt_choice_datamodule.MSRVTTChoiceDataModule.dataset_cls_no_false": [[13, 16], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "dataset_cls_no_false", "(", "self", ")", ":", "\n", "        ", "return", "MSRVTTChoiceDataset", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.msrvtt_choice_datamodule.MSRVTTChoiceDataModule.dataset_name": [[17, 20], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "dataset_name", "(", "self", ")", ":", "\n", "        ", "return", "\"msrvtt_choice\"", "\n", "", "", ""]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.ucf101_datamodule.UCF101DataModule.__init__": [[6, 8], ["CoTrain.datamodules.image.datamodule_base.BaseDataModule.__init__"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.transforms.utils.UnNormalize.__init__"], ["    ", "def", "__init__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.ucf101_datamodule.UCF101DataModule.dataset_cls": [[9, 12], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "dataset_cls", "(", "self", ")", ":", "\n", "        ", "return", "UCF101Dataset", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.ucf101_datamodule.UCF101DataModule.dataset_cls_no_false": [[13, 16], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "dataset_cls_no_false", "(", "self", ")", ":", "\n", "        ", "return", "UCF101Dataset", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.ucf101_datamodule.UCF101DataModule.dataset_name": [[17, 20], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "dataset_name", "(", "self", ")", ":", "\n", "        ", "return", "\"ucf101\"", "\n", "", "", ""]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.ego4d_datamodule.Ego4DDataModule.__init__": [[6, 8], ["CoTrain.datamodules.image.datamodule_base.BaseDataModule.__init__"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.transforms.utils.UnNormalize.__init__"], ["    ", "def", "__init__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.ego4d_datamodule.Ego4DDataModule.dataset_cls": [[9, 12], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "dataset_cls", "(", "self", ")", ":", "\n", "        ", "return", "Ego4DDataset", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.ego4d_datamodule.Ego4DDataModule.dataset_cls_no_false": [[13, 16], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "dataset_cls_no_false", "(", "self", ")", ":", "\n", "        ", "return", "Ego4DDataset", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.ego4d_datamodule.Ego4DDataModule.dataset_name": [[17, 20], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "dataset_name", "(", "self", ")", ":", "\n", "        ", "return", "\"ego4d\"", "\n", "", "", ""]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.yttemporal_datamodule.YTTemporalMDataModule.__init__": [[6, 8], ["CoTrain.datamodules.image.datamodule_base.BaseDataModule.__init__"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.transforms.utils.UnNormalize.__init__"], ["    ", "def", "__init__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.yttemporal_datamodule.YTTemporalMDataModule.dataset_cls": [[9, 12], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "dataset_cls", "(", "self", ")", ":", "\n", "        ", "return", "YTTemporalDataset", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.yttemporal_datamodule.YTTemporalMDataModule.dataset_cls_no_false": [[13, 16], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "dataset_cls_no_false", "(", "self", ")", ":", "\n", "        ", "return", "YTTemporalDataset", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.yttemporal_datamodule.YTTemporalMDataModule.dataset_name": [[17, 20], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "dataset_name", "(", "self", ")", ":", "\n", "        ", "return", "\"yttemporal\"", "\n", "", "", ""]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.tgif_datamodule.TGIFDataModule.__init__": [[6, 8], ["CoTrain.datamodules.image.datamodule_base.BaseDataModule.__init__"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.transforms.utils.UnNormalize.__init__"], ["    ", "def", "__init__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.tgif_datamodule.TGIFDataModule.dataset_cls": [[9, 12], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "dataset_cls", "(", "self", ")", ":", "\n", "        ", "return", "TGIFDataset", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.tgif_datamodule.TGIFDataModule.dataset_cls_no_false": [[13, 16], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "dataset_cls_no_false", "(", "self", ")", ":", "\n", "        ", "return", "TGIFDataset", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.tgif_datamodule.TGIFDataModule.dataset_name": [[17, 20], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "dataset_name", "(", "self", ")", ":", "\n", "        ", "return", "\"tgif\"", "\n", "", "", ""]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.lsmdc_datamodule.LSMDCDataModule.__init__": [[6, 8], ["CoTrain.datamodules.image.datamodule_base.BaseDataModule.__init__"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.transforms.utils.UnNormalize.__init__"], ["    ", "def", "__init__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.lsmdc_datamodule.LSMDCDataModule.dataset_cls": [[9, 12], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "dataset_cls", "(", "self", ")", ":", "\n", "        ", "return", "LSMDCDataset", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.lsmdc_datamodule.LSMDCDataModule.dataset_cls_no_false": [[13, 16], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "dataset_cls_no_false", "(", "self", ")", ":", "\n", "        ", "return", "LSMDCDataset", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.lsmdc_datamodule.LSMDCDataModule.dataset_name": [[17, 20], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "dataset_name", "(", "self", ")", ":", "\n", "        ", "return", "\"lsmdc\"", "\n", "", "", ""]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.hmdb51_datamodule.HMDB51DataModule.__init__": [[6, 8], ["CoTrain.datamodules.image.datamodule_base.BaseDataModule.__init__"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.transforms.utils.UnNormalize.__init__"], ["    ", "def", "__init__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.hmdb51_datamodule.HMDB51DataModule.dataset_cls": [[9, 12], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "dataset_cls", "(", "self", ")", ":", "\n", "        ", "return", "HMDB51Dataset", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.hmdb51_datamodule.HMDB51DataModule.dataset_cls_no_false": [[13, 16], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "dataset_cls_no_false", "(", "self", ")", ":", "\n", "        ", "return", "HMDB51Dataset", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.hmdb51_datamodule.HMDB51DataModule.dataset_name": [[17, 20], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "dataset_name", "(", "self", ")", ":", "\n", "        ", "return", "\"hmdb51\"", "\n", "", "", ""]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.msrvttqa_datamodule.MSRVTTQADataModule.__init__": [[7, 9], ["CoTrain.datamodules.image.datamodule_base.BaseDataModule.__init__"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.transforms.utils.UnNormalize.__init__"], ["    ", "def", "__init__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.msrvttqa_datamodule.MSRVTTQADataModule.dataset_cls": [[10, 13], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "dataset_cls", "(", "self", ")", ":", "\n", "        ", "return", "MSRVTTQADataset", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.msrvttqa_datamodule.MSRVTTQADataModule.dataset_name": [[14, 17], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "dataset_name", "(", "self", ")", ":", "\n", "        ", "return", "\"msrvttqa\"", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.msrvttqa_datamodule.MSRVTTQADataModule.setup": [[18, 26], ["super().setup", "sorted", "collections.defaultdict", "msrvttqa_datamodule.MSRVTTQADataModule.answer2id.items", "max", "msrvttqa_datamodule.MSRVTTQADataModule.answer2id.values"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.image.vqav2_datamodule.VQAv2DataModule.setup"], ["", "def", "setup", "(", "self", ",", "stage", ")", ":", "\n", "        ", "super", "(", ")", ".", "setup", "(", "stage", ")", "\n", "self", ".", "answer2id", "=", "self", ".", "train_dataset", ".", "ans_lab_dict", "\n", "sorted_a2i", "=", "sorted", "(", "self", ".", "answer2id", ".", "items", "(", ")", ",", "key", "=", "lambda", "x", ":", "x", "[", "1", "]", ")", "\n", "self", ".", "num_class", "=", "max", "(", "self", ".", "answer2id", ".", "values", "(", ")", ")", "+", "1", "\n", "self", ".", "id2answer", "=", "defaultdict", "(", "lambda", ":", "\"unknown\"", ")", "\n", "for", "k", ",", "v", "in", "sorted_a2i", ":", "\n", "            ", "self", ".", "id2answer", "[", "v", "]", "=", "k", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.webvid_datamodule.WEBVIDDataModule.__init__": [[6, 8], ["CoTrain.datamodules.image.datamodule_base.BaseDataModule.__init__"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.transforms.utils.UnNormalize.__init__"], ["    ", "def", "__init__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.webvid_datamodule.WEBVIDDataModule.dataset_cls": [[9, 12], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "dataset_cls", "(", "self", ")", ":", "\n", "        ", "return", "WEBVIDDataset", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.webvid_datamodule.WEBVIDDataModule.dataset_cls_no_false": [[13, 16], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "dataset_cls_no_false", "(", "self", ")", ":", "\n", "        ", "return", "WEBVIDDataset", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.webvid_datamodule.WEBVIDDataModule.dataset_name": [[17, 20], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "dataset_name", "(", "self", ")", ":", "\n", "        ", "return", "\"webvid\"", "\n", "", "", ""]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.msvd_datamodule.MSVDDataModule.__init__": [[6, 8], ["CoTrain.datamodules.image.datamodule_base.BaseDataModule.__init__"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.transforms.utils.UnNormalize.__init__"], ["    ", "def", "__init__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.msvd_datamodule.MSVDDataModule.dataset_cls": [[9, 12], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "dataset_cls", "(", "self", ")", ":", "\n", "        ", "return", "MSVDDataset", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.msvd_datamodule.MSVDDataModule.dataset_cls_no_false": [[13, 16], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "dataset_cls_no_false", "(", "self", ")", ":", "\n", "        ", "return", "MSVDDataset", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.msvd_datamodule.MSVDDataModule.dataset_name": [[17, 20], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "dataset_name", "(", "self", ")", ":", "\n", "        ", "return", "\"msvd\"", "\n", "", "", ""]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.msrvtt_datamodule.MSRVTTDataModule.__init__": [[6, 8], ["CoTrain.datamodules.image.datamodule_base.BaseDataModule.__init__"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.transforms.utils.UnNormalize.__init__"], ["    ", "def", "__init__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.msrvtt_datamodule.MSRVTTDataModule.dataset_cls": [[9, 12], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "dataset_cls", "(", "self", ")", ":", "\n", "        ", "return", "MSRVTTDataset", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.msrvtt_datamodule.MSRVTTDataModule.dataset_cls_no_false": [[13, 16], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "dataset_cls_no_false", "(", "self", ")", ":", "\n", "        ", "return", "MSRVTTDataset", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.msrvtt_datamodule.MSRVTTDataModule.dataset_name": [[17, 20], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "dataset_name", "(", "self", ")", ":", "\n", "        ", "return", "\"msrvtt\"", "\n", "", "", ""]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.howto100m.HT100MDataset.__init__": [[13, 42], ["video_base_dataset.BaseDataset.__init__", "howto100m.HT100MDataset._load_metadata", "os.path.join", "print", "float", "len"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.transforms.utils.UnNormalize.__init__", "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_v2.Ego4DDataset._load_metadata"], ["def", "__init__", "(", "self", ",", "*", "args", ",", "split", "=", "\"\"", ",", "**", "kwargs", ")", ":", "\n", "        ", "assert", "split", "in", "[", "\"train\"", ",", "\"val\"", ",", "\"test\"", "]", "\n", "self", ".", "split", "=", "split", "\n", "\n", "if", "split", "==", "\"train\"", ":", "\n", "            ", "names", "=", "[", "\"howto100m_train\"", "]", "\n", "", "elif", "split", "==", "\"val\"", ":", "\n", "            ", "names", "=", "[", "\"howto100m_val\"", "]", "\n", "", "elif", "split", "==", "\"test\"", ":", "\n", "            ", "names", "=", "[", "\"howto100m_test\"", "]", "\n", "", "super", "(", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ",", "names", "=", "names", ",", "text_column_name", "=", "\"caption\"", ")", "\n", "\n", "self", ".", "metadata", "=", "None", "\n", "self", ".", "_load_metadata", "(", ")", "\n", "# for howto100", "\n", "self", ".", "min_time", "=", "4.0", "\n", "self", ".", "size", "=", "256", "\n", "self", ".", "fps", "=", "2", "\n", "self", ".", "num_sec", "=", "self", ".", "num_frames", "/", "float", "(", "self", ".", "fps", ")", "\n", "self", ".", "crop_only", "=", "True", "\n", "if", "self", ".", "split", "==", "'train'", ":", "\n", "            ", "self", ".", "center_crop", "=", "False", "\n", "", "else", ":", "\n", "            ", "self", ".", "center_crop", "=", "True", "\n", "", "self", ".", "benchmark", "=", "False", "\n", "self", ".", "num_candidates", "=", "1", "\n", "self", ".", "random_flip", "=", "True", "\n", "self", ".", "caption_dir", "=", "os", ".", "path", ".", "join", "(", "self", ".", "data_dir", ",", "'howto100m_csv'", ")", "\n", "print", "(", "names", ",", "\": \"", ",", "len", "(", "self", ".", "metadata", ")", ",", "\"samples in total.\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.howto100m.HT100MDataset._load_metadata": [[43, 53], ["pandas.read_csv", "os.path.join"], "methods", ["None"], ["", "def", "_load_metadata", "(", "self", ")", ":", "\n", "        ", "metadata_dir", "=", "'./meta_data/howto100m'", "\n", "split_files", "=", "{", "\n", "'train'", ":", "'ht100_videos_split.csv'", ",", "\n", "'val'", ":", "'ht100_videos_split_val.csv'", ",", "# there is no test", "\n", "'test'", ":", "'ht100_videos_split_val.csv'", "\n", "}", "\n", "target_split_fp", "=", "split_files", "[", "self", ".", "split", "]", "\n", "metadata", "=", "pd", ".", "read_csv", "(", "os", ".", "path", ".", "join", "(", "metadata_dir", ",", "target_split_fp", ")", ",", "sep", "=", "'\\t'", ")", "\n", "self", ".", "metadata", "=", "metadata", "[", "\"Name\"", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.howto100m.HT100MDataset.read_frames_ffmpeg": [[54, 92], ["random.randint", "ffmpeg.input().filter", "cmd.hflip.hflip.output().run", "numpy.frombuffer().reshape", "torch.from_numpy", "int", "int", "cmd.hflip.hflip.crop", "cmd.hflip.hflip.crop().filter", "cmd.hflip.hflip.hflip", "numpy.copy", "torch.cat.permute", "torch.ones", "torch.cat", "max", "ffmpeg.input", "random.uniform", "random.uniform", "str", "str", "random.uniform", "cmd.hflip.hflip.output", "numpy.frombuffer", "cmd.hflip.hflip.crop"], "methods", ["None"], ["", "def", "read_frames_ffmpeg", "(", "self", ",", "video_path", ",", "start", ",", "end", ")", ":", "\n", "        ", "start_seek", "=", "random", ".", "randint", "(", "int", "(", "start", ")", ",", "int", "(", "max", "(", "start", ",", "end", "-", "self", ".", "num_sec", ")", ")", ")", "\n", "cmd", "=", "(", "\n", "ffmpeg", "\n", ".", "input", "(", "video_path", ",", "ss", "=", "start_seek", ",", "t", "=", "self", ".", "num_sec", "+", "0.01", ")", "\n", ".", "filter", "(", "'fps'", ",", "fps", "=", "self", ".", "fps", ")", "\n", ")", "\n", "if", "self", ".", "center_crop", ":", "\n", "            ", "aw", ",", "ah", "=", "0.5", ",", "0.5", "\n", "", "else", ":", "\n", "            ", "aw", ",", "ah", "=", "random", ".", "uniform", "(", "0", ",", "1", ")", ",", "random", ".", "uniform", "(", "0", ",", "1", ")", "\n", "", "if", "self", ".", "crop_only", ":", "\n", "            ", "cmd", "=", "(", "\n", "cmd", ".", "crop", "(", "'(iw - {})*{}'", ".", "format", "(", "self", ".", "size", ",", "aw", ")", ",", "\n", "'(ih - {})*{}'", ".", "format", "(", "self", ".", "size", ",", "ah", ")", ",", "\n", "str", "(", "self", ".", "size", ")", ",", "str", "(", "self", ".", "size", ")", ")", "\n", ")", "\n", "", "else", ":", "\n", "            ", "cmd", "=", "(", "\n", "cmd", ".", "crop", "(", "'(iw - min(iw,ih))*{}'", ".", "format", "(", "aw", ")", ",", "\n", "'(ih - min(iw,ih))*{}'", ".", "format", "(", "ah", ")", ",", "\n", "'min(iw,ih)'", ",", "\n", "'min(iw,ih)'", ")", "\n", ".", "filter", "(", "'scale'", ",", "self", ".", "size", ",", "self", ".", "size", ")", "\n", ")", "\n", "", "if", "self", ".", "random_flip", "and", "random", ".", "uniform", "(", "0", ",", "1", ")", ">", "0.5", ":", "\n", "            ", "cmd", "=", "cmd", ".", "hflip", "(", ")", "\n", "", "out", ",", "_", "=", "(", "\n", "cmd", ".", "output", "(", "'pipe:'", ",", "format", "=", "'rawvideo'", ",", "pix_fmt", "=", "'rgb24'", ")", ".", "run", "(", "capture_stdout", "=", "True", ",", "quiet", "=", "True", ")", "\n", ")", "\n", "# print(np.frombuffer(out, np.uint8).shape)", "\n", "video", "=", "np", ".", "frombuffer", "(", "out", ",", "np", ".", "uint8", ")", ".", "reshape", "(", "[", "-", "1", ",", "self", ".", "size", ",", "self", ".", "size", ",", "3", "]", ")", "\n", "video_tensor", "=", "th", ".", "from_numpy", "(", "np", ".", "copy", "(", "video", ")", ")", "\n", "video_tensor", "=", "video_tensor", ".", "permute", "(", "3", ",", "0", ",", "1", ",", "2", ")", "+", "0.01", "# prevent all dark vide", "\n", "if", "video_tensor", ".", "shape", "[", "1", "]", "<", "self", ".", "num_frames", ":", "\n", "            ", "zeros", "=", "th", ".", "ones", "(", "(", "3", ",", "self", ".", "num_frames", "-", "video_tensor", ".", "shape", "[", "1", "]", ",", "self", ".", "size", ",", "self", ".", "size", ")", ",", "dtype", "=", "th", ".", "uint8", ")", "\n", "video_tensor", "=", "th", ".", "cat", "(", "(", "video_tensor", ",", "zeros", ")", ",", "axis", "=", "1", ")", "\n", "", "return", "video_tensor", "[", ":", ",", ":", "self", ".", "num_frames", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.howto100m.HT100MDataset.get_caption": [[94, 104], ["pandas.read_csv", "random.randint", "max", "len"], "methods", ["None"], ["", "def", "get_caption", "(", "self", ",", "caption", ")", ":", "\n", "        ", "cap", "=", "pd", ".", "read_csv", "(", "caption", ")", "\n", "ind", "=", "random", ".", "randint", "(", "0", ",", "len", "(", "cap", ")", "-", "1", ")", "\n", "text", "=", "cap", "[", "'text'", "]", ".", "values", "[", "ind", "]", "\n", "start", ",", "end", "=", "cap", "[", "'start'", "]", ".", "values", "[", "ind", "]", ",", "cap", "[", "'end'", "]", ".", "values", "[", "ind", "]", "\n", "if", "end", "-", "start", "<", "self", ".", "min_time", ":", "\n", "            ", "diff", "=", "self", ".", "min_time", "-", "end", "+", "start", "\n", "start", "=", "max", "(", "0", ",", "start", "-", "diff", "/", "2", ")", "\n", "end", "=", "start", "+", "self", ".", "min_time", "\n", "", "return", "text", ",", "start", ",", "end", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.howto100m.HT100MDataset.get_text": [[105, 118], ["howto100m.HT100MDataset.get_caption_path", "howto100m.HT100MDataset.get_caption", "howto100m.HT100MDataset.tokenizer", "int", "int"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.datasets.yttemporal.YTTemporalDataset.get_caption_path", "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.yttemporal.YTTemporalDataset.get_caption"], ["", "def", "get_text", "(", "self", ",", "sample", ")", ":", "\n", "        ", "caption_csv", "=", "self", ".", "get_caption_path", "(", "sample", ")", "\n", "text", ",", "start", ",", "end", "=", "self", ".", "get_caption", "(", "caption_csv", ")", "\n", "# print(text)", "\n", "# TODO: May need to be improved for edge cases.", "\n", "encoding", "=", "self", ".", "tokenizer", "(", "\n", "text", ",", "\n", "padding", "=", "\"max_length\"", ",", "\n", "truncation", "=", "True", ",", "\n", "max_length", "=", "self", ".", "max_text_len", ",", "\n", "return_special_tokens_mask", "=", "True", ",", "\n", ")", "\n", "return", "{", "\"text\"", ":", "(", "text", ",", "encoding", ")", "}", ",", "int", "(", "start", ")", ",", "int", "(", "end", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.howto100m.HT100MDataset.get_caption_path": [[119, 122], ["os.path.join", "[].split", "sample.split"], "methods", ["None"], ["", "def", "get_caption_path", "(", "self", ",", "sample", ")", ":", "\n", "# example xx/xx/xx.mp4 -> xx.csv", "\n", "        ", "return", "os", ".", "path", ".", "join", "(", "self", ".", "caption_dir", ",", "sample", ".", "split", "(", "'/'", ")", "[", "-", "1", "]", ".", "split", "(", "'.'", ")", "[", "0", "]", "+", "'.csv'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.howto100m.HT100MDataset.get_false_text": [[123, 135], ["random.randint", "howto100m.HT100MDataset.get_caption_path", "howto100m.HT100MDataset.get_caption", "howto100m.HT100MDataset.tokenizer", "len"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.datasets.yttemporal.YTTemporalDataset.get_caption_path", "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.yttemporal.YTTemporalDataset.get_caption"], ["", "def", "get_false_text", "(", "self", ",", "rep", ")", ":", "\n", "        ", "random_index", "=", "random", ".", "randint", "(", "0", ",", "len", "(", "self", ".", "metadata", ")", "-", "1", ")", "\n", "sample", "=", "self", ".", "metadata", ".", "iloc", "[", "random_index", "]", "\n", "caption_csv", "=", "self", ".", "get_caption_path", "(", "sample", ")", "\n", "text", ",", "start", ",", "end", "=", "self", ".", "get_caption", "(", "caption_csv", ")", "\n", "encoding", "=", "self", ".", "tokenizer", "(", "\n", "text", ",", "\n", "truncation", "=", "True", ",", "\n", "max_length", "=", "self", ".", "max_text_len", ",", "\n", "return_special_tokens_mask", "=", "True", ",", "\n", ")", "\n", "return", "{", "f\"false_text_{rep}\"", ":", "(", "text", ",", "encoding", ")", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.howto100m.HT100MDataset._get_video_path": [[136, 140], ["os.path.join"], "methods", ["None"], ["", "def", "_get_video_path", "(", "self", ",", "sample", ")", ":", "\n", "        ", "rel_video_fp", "=", "sample", "\n", "full_video_fp", "=", "os", ".", "path", ".", "join", "(", "self", ".", "data_dir", ",", "rel_video_fp", ")", "\n", "return", "full_video_fp", ",", "rel_video_fp", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.howto100m.HT100MDataset.get_raw_video": [[141, 148], ["howto100m.HT100MDataset._get_video_path", "howto100m.HT100MDataset.read_frames_ffmpeg().permute", "Exception", "howto100m.HT100MDataset.read_frames_ffmpeg"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_v2.Ego4DDataset._get_video_path", "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_v2.Ego4DDataset.read_frames_ffmpeg"], ["", "def", "get_raw_video", "(", "self", ",", "sample", ",", "begin", ",", "end", ")", ":", "\n", "        ", "abs_fp", ",", "rel_fp", "=", "self", ".", "_get_video_path", "(", "sample", ")", "\n", "videos", "=", "self", ".", "read_frames_ffmpeg", "(", "abs_fp", ",", "begin", ",", "end", ")", ".", "permute", "(", "1", ",", "0", ",", "2", ",", "3", ")", "\n", "if", "videos", "is", "None", ":", "\n", "            ", "raise", "Exception", "(", "\"Invalid img!\"", ",", "rel_fp", ")", "\n", "", "else", ":", "\n", "            ", "return", "videos", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.howto100m.HT100MDataset.get_video": [[149, 153], ["howto100m.HT100MDataset.get_raw_video", "howto100m.HT100MDataset.video_aug"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_v2.Ego4DDataset.get_raw_video", "home.repos.pwc.inspect_result.showlab_all-in-one.video.videoaug.video_aug"], ["", "", "def", "get_video", "(", "self", ",", "sample", ",", "start", ",", "end", ")", ":", "\n", "        ", "videos", "=", "self", ".", "get_raw_video", "(", "sample", ",", "start", ",", "end", ")", "\n", "videos_tensor", "=", "self", ".", "video_aug", "(", "videos", ",", "self", ".", "video_transform", ",", "byte", "=", "True", ")", "\n", "return", "videos_tensor", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.howto100m.HT100MDataset.get_false_video": [[154, 162], ["random.randint", "howto100m.HT100MDataset.get_caption_path", "howto100m.HT100MDataset.get_caption", "howto100m.HT100MDataset.get_raw_video", "howto100m.HT100MDataset.video_aug", "len"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.datasets.yttemporal.YTTemporalDataset.get_caption_path", "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.yttemporal.YTTemporalDataset.get_caption", "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_v2.Ego4DDataset.get_raw_video", "home.repos.pwc.inspect_result.showlab_all-in-one.video.videoaug.video_aug"], ["", "def", "get_false_video", "(", "self", ",", "rep", ")", ":", "\n", "        ", "random_index", "=", "random", ".", "randint", "(", "0", ",", "len", "(", "self", ".", "metadata", ")", "-", "1", ")", "\n", "sample", "=", "self", ".", "metadata", ".", "iloc", "[", "random_index", "]", "\n", "caption_csv", "=", "self", ".", "get_caption_path", "(", "sample", ")", "\n", "_", ",", "start", ",", "end", "=", "self", ".", "get_caption", "(", "caption_csv", ")", "\n", "videos", "=", "self", ".", "get_raw_video", "(", "sample", ",", "start", ",", "end", ")", "\n", "videos_tensor", "=", "self", ".", "video_aug", "(", "videos", ",", "self", ".", "video_transform", ",", "byte", "=", "True", ")", "\n", "return", "{", "f\"false_video_{rep}\"", ":", "videos_tensor", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.howto100m.HT100MDataset.get_suite": [[163, 193], ["dict", "howto100m.HT100MDataset.get_text", "dict.update", "howto100m.HT100MDataset.get_video", "dict.update", "dict.update", "range", "range", "dict.update", "dict.update", "howto100m.HT100MDataset.get_false_video", "howto100m.HT100MDataset.get_false_text"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_v2.Ego4DDataset.get_text", "home.repos.pwc.inspect_result.showlab_all-in-one.gadgets.my_metrics.VQAScore.update", "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_v2.Ego4DDataset.get_video", "home.repos.pwc.inspect_result.showlab_all-in-one.gadgets.my_metrics.VQAScore.update", "home.repos.pwc.inspect_result.showlab_all-in-one.gadgets.my_metrics.VQAScore.update", "home.repos.pwc.inspect_result.showlab_all-in-one.gadgets.my_metrics.VQAScore.update", "home.repos.pwc.inspect_result.showlab_all-in-one.gadgets.my_metrics.VQAScore.update", "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_v2.Ego4DDataset.get_false_video", "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_v2.Ego4DDataset.get_false_text"], ["", "def", "get_suite", "(", "self", ",", "index", ")", ":", "\n", "        ", "result", "=", "None", "\n", "max_try", "=", "5", "\n", "try_time", "=", "0", "\n", "# while result is None:", "\n", "try_time", "+=", "1", "\n", "sample", "=", "self", ".", "metadata", ".", "iloc", "[", "index", "]", "\n", "# try:", "\n", "ret", "=", "dict", "(", ")", "\n", "text", ",", "start", ",", "end", "=", "self", ".", "get_text", "(", "sample", ")", "\n", "ret", ".", "update", "(", "text", ")", "\n", "videos_tensor", "=", "self", ".", "get_video", "(", "sample", ",", "start", ",", "end", ")", "\n", "ret", ".", "update", "(", "{", "\n", "\"video\"", ":", "videos_tensor", ",", "\n", "\"vid_index\"", ":", "index", ",", "\n", "\"cap_index\"", ":", "index", ",", "\n", "\"raw_index\"", ":", "index", ",", "\n", "}", ")", "\n", "ret", ".", "update", "(", "{", "\"replica\"", ":", "True", "if", "ret", "[", "\"cap_index\"", "]", ">", "0", "else", "False", "}", ")", "\n", "for", "i", "in", "range", "(", "self", ".", "draw_false_video", ")", ":", "\n", "            ", "ret", ".", "update", "(", "self", ".", "get_false_video", "(", "i", ")", ")", "\n", "", "for", "i", "in", "range", "(", "self", ".", "draw_false_text", ")", ":", "\n", "            ", "ret", ".", "update", "(", "self", ".", "get_false_text", "(", "i", ")", ")", "\n", "", "result", "=", "True", "\n", "# except Exception as e:", "\n", "#     print(e)", "\n", "#     index = random.randint(0, len(self.metadata) - 1)", "\n", "# if try_time > max_try:", "\n", "#     print(f\"Exceed max time Error while read file idx {sample} in {self.names[0]}\")", "\n", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.howto100m.HT100MDataset.__len__": [[194, 196], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "metadata", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.howto100m.HT100MDataset.__getitem__": [[197, 199], ["howto100m.HT100MDataset.get_suite"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_v2.Ego4DDataset.get_suite"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "return", "self", ".", "get_suite", "(", "index", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.ego4d_choice.EGO4DChoiceDataset.__init__": [[7, 29], ["video_base_dataset.BaseDataset.__init__", "ego4d_choice.EGO4DChoiceDataset._load_metadata", "Exception"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.transforms.utils.UnNormalize.__init__", "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_v2.Ego4DDataset._load_metadata"], ["    ", "def", "__init__", "(", "self", ",", "*", "args", ",", "split", "=", "\"\"", ",", "**", "kwargs", ")", ":", "\n", "        ", "assert", "split", "in", "[", "\"train\"", ",", "\"val\"", ",", "\"test\"", "]", "\n", "self", ".", "split", "=", "split", "\n", "if", "self", ".", "split", "==", "\"train\"", ":", "\n", "            ", "Exception", "(", "\"no train data provided\"", ")", "\n", "", "self", ".", "metadata", "=", "None", "\n", "self", ".", "ans_lab_dict", "=", "None", "\n", "if", "split", "==", "\"train\"", ":", "\n", "            ", "names", "=", "[", "\"ego4d_choice_train\"", "]", "\n", "", "elif", "split", "==", "\"val\"", ":", "\n", "            ", "names", "=", "[", "\"ego4d_choice_val\"", "]", "\n", "", "elif", "split", "==", "\"test\"", ":", "\n", "            ", "names", "=", "[", "\"ego4d_choice_test\"", "]", "# vqav2_test-dev for test-dev", "\n", "\n", "", "super", "(", ")", ".", "__init__", "(", "\n", "*", "args", ",", "\n", "**", "kwargs", ",", "\n", "names", "=", "names", ",", "\n", "text_column_name", "=", "\"unknown\"", ",", "\n", "remove_duplicate", "=", "False", ",", "\n", ")", "\n", "self", ".", "_load_metadata", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.ego4d_choice.EGO4DChoiceDataset._load_metadata": [[30, 39], ["pandas.read_csv", "os.path.join"], "methods", ["None"], ["", "def", "_load_metadata", "(", "self", ")", ":", "\n", "        ", "metadata_dir", "=", "'./meta_data/ego4d'", "\n", "split_files", "=", "{", "\n", "'train'", ":", "'mc_val.csv'", ",", "# no train and test available, only for zero-shot testing", "\n", "'val'", ":", "'mc_val.csv'", ",", "\n", "'test'", ":", "'mc_val.csv'", "\n", "}", "\n", "target_split_fp", "=", "split_files", "[", "self", ".", "split", "]", "\n", "self", ".", "metadata", "=", "pd", ".", "read_csv", "(", "os", ".", "path", ".", "join", "(", "metadata_dir", ",", "target_split_fp", ")", ",", "sep", "=", "','", ",", "header", "=", "0", ",", "error_bad_lines", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.ego4d_choice.EGO4DChoiceDataset._get_video_path": [[40, 46], ["os.path.join", "os.path.exists", "Exception", "eval"], "methods", ["None"], ["", "def", "_get_video_path", "(", "self", ",", "sample", ")", ":", "\n", "        ", "rel_video_fp", "=", "eval", "(", "sample", "[", "\"question\"", "]", ")", "[", "0", "]", "+", "'.mp4'", "\n", "full_video_fp", "=", "os", ".", "path", ".", "join", "(", "self", ".", "data_dir", ",", "'videos'", ",", "rel_video_fp", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "full_video_fp", ")", ":", "\n", "            ", "Exception", "(", "IOError", ")", "\n", "", "return", "full_video_fp", ",", "rel_video_fp", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.ego4d_choice.EGO4DChoiceDataset.get_raw_video": [[47, 56], ["ego4d_choice.EGO4DChoiceDataset._get_video_path", "video_base_dataset.get_video_len", "video_base_dataset.read_large_frames_decord", "eval", "Exception"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_v2.Ego4DDataset._get_video_path", "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_v2.Ego4DDataset.get_video_len", "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.video_base_dataset.read_large_frames_decord"], ["", "def", "get_raw_video", "(", "self", ",", "sample", ")", ":", "\n", "        ", "abs_fp", ",", "rel_fp", "=", "self", ".", "_get_video_path", "(", "sample", ")", "\n", "frame_loc", "=", "eval", "(", "sample", "[", "\"question\"", "]", ")", "[", "1", "]", "\n", "frame_end", "=", "get_video_len", "(", "abs_fp", ")", "\n", "imgs", "=", "read_large_frames_decord", "(", "abs_fp", ",", "frame_loc", ",", "frame_end", ",", "self", ".", "num_frames", ",", "mode", "=", "self", ".", "split", ")", "\n", "if", "imgs", "is", "None", ":", "\n", "            ", "raise", "Exception", "(", "\"Invalid video!\"", ",", "rel_fp", ")", "\n", "", "else", ":", "\n", "            ", "return", "imgs", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.ego4d_choice.EGO4DChoiceDataset.get_text": [[57, 70], ["eval", "ego4d_choice.EGO4DChoiceDataset.tokenizer", "texts.append"], "methods", ["None"], ["", "", "def", "get_text", "(", "self", ",", "sample", ")", ":", "\n", "        ", "texts", "=", "[", "]", "\n", "for", "answer", "in", "eval", "(", "sample", "[", "\"answers\"", "]", ")", ":", "\n", "            ", "text", "=", "answer", "[", "-", "1", "]", "\n", "encoding", "=", "self", ".", "tokenizer", "(", "\n", "text", ",", "\n", "padding", "=", "\"max_length\"", ",", "\n", "truncation", "=", "True", ",", "\n", "max_length", "=", "self", ".", "max_text_len", ",", "\n", "return_special_tokens_mask", "=", "True", ",", "\n", ")", "\n", "texts", ".", "append", "(", "(", "text", ",", "encoding", ")", ")", "\n", "", "return", "texts", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.ego4d_choice.EGO4DChoiceDataset.get_answer_label": [[71, 78], ["enumerate", "eval", "eval"], "methods", ["None"], ["", "def", "get_answer_label", "(", "self", ",", "sample", ")", ":", "\n", "        ", "gt_text", "=", "eval", "(", "sample", "[", "\"question\"", "]", ")", "[", "-", "1", "]", "\n", "answer_label", "=", "0", "\n", "for", "index", ",", "answer", "in", "enumerate", "(", "eval", "(", "sample", "[", "\"answers\"", "]", ")", ")", ":", "\n", "            ", "if", "answer", "[", "-", "1", "]", "==", "gt_text", ":", "\n", "                ", "answer_label", "=", "index", "\n", "", "", "return", "answer_label", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.ego4d_choice.EGO4DChoiceDataset.__getitem__": [[79, 99], ["ego4d_choice.EGO4DChoiceDataset.get_video", "ego4d_choice.EGO4DChoiceDataset.get_answer_label", "ego4d_choice.EGO4DChoiceDataset.get_text", "range", "ret.update"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_v2.Ego4DDataset.get_video", "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.msvdqa.MSVDQADataset.get_answer_label", "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_v2.Ego4DDataset.get_text", "home.repos.pwc.inspect_result.showlab_all-in-one.gadgets.my_metrics.VQAScore.update"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "sample", "=", "self", ".", "metadata", ".", "iloc", "[", "index", "]", "\n", "# print(sample)", "\n", "video_tensor", "=", "self", ".", "get_video", "(", "sample", ")", "\n", "# index, question_index = self.index_mapper[index]", "\n", "qid", "=", "index", "\n", "answer", "=", "self", ".", "get_answer_label", "(", "sample", ")", "\n", "ret", "=", "{", "\n", "\"video\"", ":", "video_tensor", ",", "\n", "\"vid_index\"", ":", "index", ",", "\n", "\"cap_index\"", ":", "index", ",", "\n", "\"raw_index\"", ":", "index", ",", "\n", "'answer'", ":", "answer", "\n", "}", "\n", "texts", "=", "self", ".", "get_text", "(", "sample", ")", "\n", "ret", "[", "\"text\"", "]", "=", "texts", "[", "0", "]", "\n", "# print(len(texts))", "\n", "for", "i", "in", "range", "(", "self", ".", "draw_false_text", "-", "1", ")", ":", "\n", "            ", "ret", ".", "update", "(", "{", "f\"false_text_{i}\"", ":", "texts", "[", "i", "+", "1", "]", "}", ")", "\n", "", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.ego4d_choice.EGO4DChoiceDataset.__len__": [[100, 102], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "metadata", ")", "", "", "", ""]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.msrvtt_choice.MSRVTTChoiceDataset.__init__": [[7, 29], ["video_base_dataset.BaseDataset.__init__", "msrvtt_choice.MSRVTTChoiceDataset._load_metadata", "Exception"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.transforms.utils.UnNormalize.__init__", "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_v2.Ego4DDataset._load_metadata"], ["    ", "def", "__init__", "(", "self", ",", "*", "args", ",", "split", "=", "\"\"", ",", "**", "kwargs", ")", ":", "\n", "        ", "assert", "split", "in", "[", "\"train\"", ",", "\"val\"", ",", "\"test\"", "]", "\n", "self", ".", "split", "=", "split", "\n", "if", "self", ".", "split", "==", "\"train\"", ":", "\n", "            ", "Exception", "(", "\"no train data provided\"", ")", "\n", "", "self", ".", "metadata", "=", "None", "\n", "self", ".", "ans_lab_dict", "=", "None", "\n", "if", "split", "==", "\"train\"", ":", "\n", "            ", "names", "=", "[", "\"msrvtt_choice_train\"", "]", "\n", "", "elif", "split", "==", "\"val\"", ":", "\n", "            ", "names", "=", "[", "\"msrvtt_choice_val\"", "]", "\n", "", "elif", "split", "==", "\"test\"", ":", "\n", "            ", "names", "=", "[", "\"msrvtt_choice_test\"", "]", "# vqav2_test-dev for test-dev", "\n", "\n", "", "super", "(", ")", ".", "__init__", "(", "\n", "*", "args", ",", "\n", "**", "kwargs", ",", "\n", "names", "=", "names", ",", "\n", "text_column_name", "=", "\"unknown\"", ",", "\n", "remove_duplicate", "=", "False", ",", "\n", ")", "\n", "self", ".", "_load_metadata", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.msrvtt_choice.MSRVTTChoiceDataset._load_metadata": [[30, 40], ["pandas.read_json", "os.path.join"], "methods", ["None"], ["", "def", "_load_metadata", "(", "self", ")", ":", "\n", "        ", "metadata_dir", "=", "'./meta_data/msrvtt'", "\n", "split_files", "=", "{", "\n", "'train'", ":", "'msrvtt_mc_test.jsonl'", ",", "# no train and test available, only for zero-shot", "\n", "'val'", ":", "'msrvtt_mc_test.jsonl'", ",", "\n", "'test'", ":", "'msrvtt_mc_test.jsonl'", "\n", "}", "\n", "target_split_fp", "=", "split_files", "[", "self", ".", "split", "]", "\n", "metadata", "=", "pd", ".", "read_json", "(", "os", ".", "path", ".", "join", "(", "metadata_dir", ",", "target_split_fp", ")", ",", "lines", "=", "True", ")", "\n", "self", ".", "metadata", "=", "metadata", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.msrvtt_choice.MSRVTTChoiceDataset._get_video_path": [[41, 43], ["os.path.join"], "methods", ["None"], ["", "def", "_get_video_path", "(", "self", ",", "sample", ")", ":", "\n", "        ", "return", "os", ".", "path", ".", "join", "(", "self", ".", "data_dir", ",", "'videos'", ",", "'all'", ",", "sample", "[", "'clip_name'", "]", "+", "'.mp4'", ")", ",", "sample", "[", "'clip_name'", "]", "+", "'.mp4'", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.msrvtt_choice.MSRVTTChoiceDataset.get_text": [[44, 56], ["msrvtt_choice.MSRVTTChoiceDataset.tokenizer", "texts.append"], "methods", ["None"], ["", "def", "get_text", "(", "self", ",", "sample", ")", ":", "\n", "        ", "texts", "=", "[", "]", "\n", "for", "text", "in", "sample", "[", "'options'", "]", ":", "\n", "            ", "encoding", "=", "self", ".", "tokenizer", "(", "\n", "text", ",", "\n", "padding", "=", "\"max_length\"", ",", "\n", "truncation", "=", "True", ",", "\n", "max_length", "=", "self", ".", "max_text_len", ",", "\n", "return_special_tokens_mask", "=", "True", ",", "\n", ")", "\n", "texts", ".", "append", "(", "(", "text", ",", "encoding", ")", ")", "\n", "", "return", "texts", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.msrvtt_choice.MSRVTTChoiceDataset.get_answer_label": [[57, 60], ["None"], "methods", ["None"], ["", "def", "get_answer_label", "(", "self", ",", "sample", ")", ":", "\n", "        ", "answer", "=", "sample", "[", "'answer'", "]", "\n", "return", "answer", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.msrvtt_choice.MSRVTTChoiceDataset.__getitem__": [[61, 83], ["msrvtt_choice.MSRVTTChoiceDataset.get_video", "msrvtt_choice.MSRVTTChoiceDataset.get_answer_label", "msrvtt_choice.MSRVTTChoiceDataset.get_text", "range", "ret.update"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_v2.Ego4DDataset.get_video", "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.msvdqa.MSVDQADataset.get_answer_label", "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_v2.Ego4DDataset.get_text", "home.repos.pwc.inspect_result.showlab_all-in-one.gadgets.my_metrics.VQAScore.update"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "sample", "=", "self", ".", "metadata", ".", "iloc", "[", "index", "]", "\n", "video_tensor", "=", "self", ".", "get_video", "(", "sample", ")", "\n", "# index, question_index = self.index_mapper[index]", "\n", "qid", "=", "index", "\n", "answer", "=", "self", ".", "get_answer_label", "(", "sample", ")", "\n", "ret", "=", "{", "\n", "\"video\"", ":", "video_tensor", ",", "\n", "\"vid_index\"", ":", "index", ",", "\n", "\"cap_index\"", ":", "index", ",", "\n", "\"raw_index\"", ":", "index", ",", "\n", "'answer'", ":", "answer", "\n", "}", "\n", "texts", "=", "self", ".", "get_text", "(", "sample", ")", "\n", "ret", "[", "\"text\"", "]", "=", "texts", "[", "0", "]", "\n", "# print(len(texts))", "\n", "for", "i", "in", "range", "(", "self", ".", "draw_false_text", "-", "1", ")", ":", "\n", "            ", "ret", ".", "update", "(", "{", "f\"false_text_{i}\"", ":", "texts", "[", "i", "+", "1", "]", "}", ")", "\n", "# for i in range(self.draw_false_text-1):", "\n", "#     ret[f\"false_text_{i}\"] = texts[i+1]", "\n", "# print(ret.keys())", "\n", "", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.msrvtt_choice.MSRVTTChoiceDataset.__len__": [[84, 86], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "metadata", ")", "", "", "", ""]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.webvid.WEBVIDDataset.__init__": [[8, 23], ["webvid.WEBVIDDataset._load_metadata", "print", "video_base_dataset.BaseDataset.__init__", "len"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_v2.Ego4DDataset._load_metadata", "home.repos.pwc.inspect_result.showlab_all-in-one.transforms.utils.UnNormalize.__init__"], ["    ", "def", "__init__", "(", "self", ",", "*", "args", ",", "split", "=", "\"\"", ",", "**", "kwargs", ")", ":", "\n", "        ", "assert", "split", "in", "[", "\"train\"", ",", "\"val\"", ",", "\"test\"", "]", "\n", "self", ".", "split", "=", "split", "\n", "self", ".", "metadata", "=", "None", "\n", "self", ".", "cut", "=", "\"jsfusion\"", "\n", "if", "split", "==", "\"train\"", ":", "\n", "            ", "names", "=", "[", "\"webvid_train\"", "]", "\n", "", "elif", "split", "==", "\"val\"", ":", "\n", "            ", "names", "=", "[", "\"webvid_val\"", "]", "\n", "", "elif", "split", "==", "\"test\"", ":", "\n", "            ", "names", "=", "[", "\"webvid_val\"", "]", "\n", "", "self", ".", "_load_metadata", "(", ")", "\n", "\n", "print", "(", "names", ",", "\": \"", ",", "len", "(", "self", ".", "metadata", ")", ",", "\"samples in total.\"", ")", "\n", "super", "(", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ",", "names", "=", "names", ",", "text_column_name", "=", "\"caption\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.webvid.WEBVIDDataset._load_metadata": [[24, 34], ["pandas.read_csv", "os.path.join"], "methods", ["None"], ["", "def", "_load_metadata", "(", "self", ")", ":", "\n", "        ", "metadata_dir", "=", "'./meta_data/webvid'", "\n", "split_files", "=", "{", "\n", "'train'", ":", "'webvid_training_success_full.tsv'", ",", "\n", "'val'", ":", "'webvid_validation_success_full.tsv'", ",", "# there is no test", "\n", "'test'", ":", "'webvid_validation_success_full.tsv'", "\n", "}", "\n", "target_split_fp", "=", "split_files", "[", "self", ".", "split", "]", "\n", "metadata", "=", "pd", ".", "read_csv", "(", "os", ".", "path", ".", "join", "(", "metadata_dir", ",", "target_split_fp", ")", ",", "sep", "=", "'\\t'", ")", "\n", "self", ".", "metadata", "=", "metadata", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.webvid.WEBVIDDataset._get_video_path": [[35, 39], ["os.path.join"], "methods", ["None"], ["", "def", "_get_video_path", "(", "self", ",", "sample", ")", ":", "\n", "        ", "rel_video_fp", "=", "sample", "[", "1", "]", "+", "'.mp4'", "\n", "full_video_fp", "=", "os", ".", "path", ".", "join", "(", "self", ".", "data_dir", ",", "self", ".", "split", ",", "rel_video_fp", ")", "\n", "return", "full_video_fp", ",", "rel_video_fp", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.webvid.WEBVIDDataset._get_caption": [[40, 42], ["None"], "methods", ["None"], ["", "def", "_get_caption", "(", "self", ",", "sample", ")", ":", "\n", "        ", "return", "sample", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.webvid.WEBVIDDataset.get_raw_video": [[43, 50], ["webvid.WEBVIDDataset._get_video_path", "video_base_dataset.read_frames_decord", "Exception"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_v2.Ego4DDataset._get_video_path", "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.base_dataset.read_frames_decord"], ["", "def", "get_raw_video", "(", "self", ",", "sample", ")", ":", "\n", "        ", "abs_fp", ",", "rel_fp", "=", "self", ".", "_get_video_path", "(", "sample", ")", "\n", "videos", ",", "idxs", ",", "vlen", "=", "read_frames_decord", "(", "abs_fp", ",", "self", ".", "num_frames", ",", "mode", "=", "self", ".", "split", ")", "\n", "if", "videos", "is", "None", ":", "\n", "            ", "raise", "Exception", "(", "\"Invalid video!\"", ",", "rel_fp", ")", "\n", "", "else", ":", "\n", "            ", "return", "videos", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.webvid.WEBVIDDataset.get_video": [[51, 59], ["webvid.WEBVIDDataset.get_raw_video", "webvid.WEBVIDDataset.video_aug"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_v2.Ego4DDataset.get_raw_video", "home.repos.pwc.inspect_result.showlab_all-in-one.video.videoaug.video_aug"], ["", "", "def", "get_video", "(", "self", ",", "index", ",", "sample", ")", ":", "\n", "        ", "videos", "=", "self", ".", "get_raw_video", "(", "sample", ")", "\n", "videos_tensor", "=", "self", ".", "video_aug", "(", "videos", ",", "self", ".", "video_transform", ")", "\n", "return", "{", "\n", "\"video\"", ":", "videos_tensor", ",", "\n", "\"vid_index\"", ":", "index", ",", "\n", "\"cap_index\"", ":", "index", ",", "\n", "\"raw_index\"", ":", "index", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.webvid.WEBVIDDataset.get_false_video": [[61, 68], ["random.randint", "webvid.WEBVIDDataset.get_raw_video", "webvid.WEBVIDDataset.video_aug", "len"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_v2.Ego4DDataset.get_raw_video", "home.repos.pwc.inspect_result.showlab_all-in-one.video.videoaug.video_aug"], ["", "def", "get_false_video", "(", "self", ",", "rep", ")", ":", "\n", "        ", "random_index", "=", "random", ".", "randint", "(", "0", ",", "len", "(", "self", ".", "metadata", ")", "-", "1", ")", "\n", "sample", "=", "self", ".", "metadata", ".", "iloc", "[", "random_index", "]", "\n", "# can be different augmentation", "\n", "videos", "=", "self", ".", "get_raw_video", "(", "sample", ")", "\n", "videos_tensor", "=", "self", ".", "video_aug", "(", "videos", ",", "self", ".", "video_transform", ")", "\n", "return", "{", "f\"false_video_{rep}\"", ":", "videos_tensor", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.webvid.WEBVIDDataset.get_text": [[69, 85], ["webvid.WEBVIDDataset.tokenizer"], "methods", ["None"], ["", "def", "get_text", "(", "self", ",", "raw_index", ",", "sample", ")", ":", "\n", "        ", "text", "=", "sample", "[", "0", "]", "\n", "# print(text)", "\n", "encoding", "=", "self", ".", "tokenizer", "(", "\n", "text", ",", "\n", "padding", "=", "\"max_length\"", ",", "\n", "truncation", "=", "True", ",", "\n", "max_length", "=", "self", ".", "max_text_len", ",", "\n", "return_special_tokens_mask", "=", "True", ",", "\n", ")", "\n", "# print(encoding.size())", "\n", "return", "{", "\n", "\"text\"", ":", "(", "text", ",", "encoding", ")", ",", "\n", "\"vid_index\"", ":", "raw_index", ",", "\n", "\"cap_index\"", ":", "raw_index", ",", "\n", "\"raw_index\"", ":", "raw_index", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.webvid.WEBVIDDataset.get_false_text": [[87, 99], ["random.randint", "webvid.WEBVIDDataset.tokenizer", "len"], "methods", ["None"], ["", "def", "get_false_text", "(", "self", ",", "rep", ")", ":", "\n", "        ", "random_index", "=", "random", ".", "randint", "(", "0", ",", "len", "(", "self", ".", "metadata", ")", "-", "1", ")", "\n", "sample", "=", "self", ".", "metadata", ".", "iloc", "[", "random_index", "]", "\n", "text", "=", "sample", "[", "0", "]", "\n", "encoding", "=", "self", ".", "tokenizer", "(", "\n", "text", ",", "\n", "# padding=\"max_length\",", "\n", "truncation", "=", "True", ",", "\n", "max_length", "=", "self", ".", "max_text_len", ",", "\n", "return_special_tokens_mask", "=", "True", ",", "\n", ")", "\n", "return", "{", "f\"false_text_{rep}\"", ":", "(", "text", ",", "encoding", ")", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.webvid.WEBVIDDataset.get_suite": [[100, 121], ["dict", "dict.update", "range", "range", "webvid.WEBVIDDataset.get_video", "webvid.WEBVIDDataset.get_text", "dict.update", "dict.update", "dict.update", "dict.update", "print", "random.randint", "webvid.WEBVIDDataset.get_false_video", "webvid.WEBVIDDataset.get_false_text", "len"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.gadgets.my_metrics.VQAScore.update", "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_v2.Ego4DDataset.get_video", "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_v2.Ego4DDataset.get_text", "home.repos.pwc.inspect_result.showlab_all-in-one.gadgets.my_metrics.VQAScore.update", "home.repos.pwc.inspect_result.showlab_all-in-one.gadgets.my_metrics.VQAScore.update", "home.repos.pwc.inspect_result.showlab_all-in-one.gadgets.my_metrics.VQAScore.update", "home.repos.pwc.inspect_result.showlab_all-in-one.gadgets.my_metrics.VQAScore.update", "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_v2.Ego4DDataset.get_false_video", "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_v2.Ego4DDataset.get_false_text"], ["", "def", "get_suite", "(", "self", ",", "index", ")", ":", "\n", "        ", "result", "=", "None", "\n", "while", "result", "is", "None", ":", "\n", "            ", "sample", "=", "self", ".", "metadata", ".", "iloc", "[", "index", "]", "\n", "try", ":", "\n", "                ", "ret", "=", "dict", "(", ")", "\n", "ret", ".", "update", "(", "self", ".", "get_video", "(", "index", ",", "sample", ")", ")", "\n", "if", "not", "self", ".", "video_only", ":", "\n", "                    ", "txt", "=", "self", ".", "get_text", "(", "index", ",", "sample", ")", "\n", "ret", ".", "update", "(", "{", "\"replica\"", ":", "True", "if", "txt", "[", "\"cap_index\"", "]", ">", "0", "else", "False", "}", ")", "\n", "ret", ".", "update", "(", "txt", ")", "\n", "\n", "", "for", "i", "in", "range", "(", "self", ".", "draw_false_video", ")", ":", "\n", "                    ", "ret", ".", "update", "(", "self", ".", "get_false_video", "(", "i", ")", ")", "\n", "", "for", "i", "in", "range", "(", "self", ".", "draw_false_text", ")", ":", "\n", "                    ", "ret", ".", "update", "(", "self", ".", "get_false_text", "(", "i", ")", ")", "\n", "", "result", "=", "True", "\n", "", "except", "Exception", "as", "e", ":", "\n", "                ", "print", "(", "f\"Error while read file idx {sample.name} in {self.names[0]} -> {e}\"", ")", "\n", "index", "=", "random", ".", "randint", "(", "0", ",", "len", "(", "self", ".", "metadata", ")", "-", "1", ")", "\n", "", "", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.webvid.WEBVIDDataset.__len__": [[122, 124], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "metadata", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.webvid.WEBVIDDataset.__getitem__": [[125, 127], ["webvid.WEBVIDDataset.get_suite"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_v2.Ego4DDataset.get_suite"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "return", "self", ".", "get_suite", "(", "index", ")", "", "", "", ""]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.msvd.MSVDDataset.__init__": [[8, 21], ["msvd.MSVDDataset._load_metadata", "video_base_dataset.BaseDataset.__init__"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_v2.Ego4DDataset._load_metadata", "home.repos.pwc.inspect_result.showlab_all-in-one.transforms.utils.UnNormalize.__init__"], ["    ", "def", "__init__", "(", "self", ",", "*", "args", ",", "split", "=", "\"\"", ",", "**", "kwargs", ")", ":", "\n", "        ", "assert", "split", "in", "[", "\"train\"", ",", "\"val\"", ",", "\"test\"", "]", "\n", "self", ".", "split", "=", "split", "\n", "self", ".", "metadata", "=", "None", "\n", "if", "split", "==", "\"train\"", ":", "\n", "            ", "names", "=", "[", "\"msvd_train\"", "]", "\n", "", "elif", "split", "==", "\"val\"", ":", "\n", "            ", "names", "=", "[", "\"msvd_val\"", "]", "\n", "", "elif", "split", "==", "\"test\"", ":", "\n", "            ", "names", "=", "[", "\"msvd_test\"", "]", "\n", "", "self", ".", "_load_metadata", "(", ")", "\n", "# self.num_frames = kwargs['num_frames']", "\n", "super", "(", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ",", "names", "=", "names", ",", "text_column_name", "=", "\"caption\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.msvd.MSVDDataset._load_metadata": [[22, 33], ["pandas.read_csv", "print", "os.path.join", "len"], "methods", ["None"], ["", "def", "_load_metadata", "(", "self", ")", ":", "\n", "        ", "metadata_dir", "=", "'./meta_data/msvd'", "\n", "split_files", "=", "{", "\n", "'train'", ":", "'MSVD_train.tsv'", ",", "\n", "'val'", ":", "'MSVD_test.tsv'", ",", "# MSVD_val.tsv", "\n", "'test'", ":", "'MSVD_test.tsv'", "\n", "}", "\n", "target_split_fp", "=", "split_files", "[", "self", ".", "split", "]", "\n", "metadata", "=", "pd", ".", "read_csv", "(", "os", ".", "path", ".", "join", "(", "metadata_dir", ",", "target_split_fp", ")", ",", "sep", "=", "'\\t'", ")", "\n", "self", ".", "metadata", "=", "metadata", "\n", "print", "(", "\"load split {}, {} samples\"", ".", "format", "(", "self", ".", "split", ",", "len", "(", "metadata", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.msvd.MSVDDataset._get_video_path": [[34, 38], ["os.path.join"], "methods", ["None"], ["", "def", "_get_video_path", "(", "self", ",", "sample", ")", ":", "\n", "        ", "rel_video_fp", "=", "sample", "[", "1", "]", "+", "'.avi'", "\n", "full_video_fp", "=", "os", ".", "path", ".", "join", "(", "self", ".", "data_dir", ",", "'YouTubeClips'", ",", "rel_video_fp", ")", "\n", "return", "full_video_fp", ",", "rel_video_fp", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.msvd.MSVDDataset._get_caption": [[39, 52], ["sample[].split", "len", "random.randint", "sample[].split", "len", "random.randint"], "methods", ["None"], ["", "def", "_get_caption", "(", "self", ",", "sample", ")", ":", "\n", "        ", "if", "self", ".", "split", "==", "'train'", ":", "\n", "            ", "words", "=", "sample", "[", "0", "]", ".", "split", "(", "','", ")", "\n", "num_word", "=", "len", "(", "words", ")", "\n", "index", "=", "random", ".", "randint", "(", "0", ",", "num_word", "-", "1", ")", "\n", "caption", "=", "words", "[", "index", "]", "\n", "", "else", ":", "\n", "# caption = sample[0]", "\n", "            ", "words", "=", "sample", "[", "0", "]", ".", "split", "(", "','", ")", "\n", "num_word", "=", "len", "(", "words", ")", "\n", "index", "=", "random", ".", "randint", "(", "0", ",", "num_word", "-", "1", ")", "\n", "caption", "=", "words", "[", "index", "]", "\n", "", "return", "caption", "\n", "", "", ""]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.tgifqa.TGIFQADataset.__init__": [[16, 36], ["tgifqa.TGIFQADataset._load_metadata", "video_base_dataset.BaseDataset.__init__"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_v2.Ego4DDataset._load_metadata", "home.repos.pwc.inspect_result.showlab_all-in-one.transforms.utils.UnNormalize.__init__"], ["    ", "def", "__init__", "(", "self", ",", "*", "args", ",", "split", "=", "\"\"", ",", "**", "kwargs", ")", ":", "\n", "        ", "assert", "split", "in", "[", "\"train\"", ",", "\"val\"", ",", "\"test\"", "]", "\n", "self", ".", "split", "=", "split", "\n", "self", ".", "data_split", "=", "\"action\"", "# transition/action", "\n", "self", ".", "metadata", "=", "None", "\n", "self", ".", "_load_metadata", "(", ")", "\n", "if", "split", "==", "\"train\"", ":", "\n", "            ", "names", "=", "[", "\"tgifqa_train\"", "]", "\n", "", "elif", "split", "==", "\"val\"", ":", "\n", "            ", "names", "=", "[", "\"tgifqa_val\"", "]", "\n", "", "elif", "split", "==", "\"test\"", ":", "\n", "            ", "names", "=", "[", "\"tgifqa_test\"", "]", "\n", "\n", "", "super", "(", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ",", "names", "=", "names", ",", "text_column_name", "=", "\"caption\"", ")", "\n", "# for appear objects", "\n", "self", ".", "only_use_relevant_dets", "=", "True", "\n", "if", "self", ".", "only_use_relevant_dets", ":", "\n", "            ", "self", ".", "relevant_dets", "=", "[", "]", "# resort the detection numbers", "\n", "self", ".", "relevant_dets_classes", "=", "[", "]", "\n", "", "self", ".", "fps", "=", "3", "# tgif sample 3 frames per second", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.tgifqa.TGIFQADataset._load_metadata": [[37, 57], ["pandas.read_json", "os.path.join", "Exception"], "methods", ["None"], ["", "def", "_load_metadata", "(", "self", ")", ":", "\n", "# download specific", "\n", "        ", "metadata_dir", "=", "'./meta_data/tgif'", "\n", "if", "self", ".", "data_split", "==", "\"action\"", ":", "\n", "            ", "split_files", "=", "{", "\n", "'train'", ":", "'action_train.jsonl'", ",", "\n", "'val'", ":", "'action_test.jsonl'", ",", "# action_val.jsonl", "\n", "'test'", ":", "'action_test.jsonl'", "# no GT label for test set", "\n", "}", "\n", "", "elif", "self", ".", "data_split", "==", "\"transition\"", ":", "\n", "            ", "split_files", "=", "{", "\n", "'train'", ":", "'transition_train.jsonl'", ",", "\n", "'val'", ":", "'transition_test.jsonl'", ",", "# transition_val.jsonl", "\n", "'test'", ":", "'transition_test.jsonl'", "# no GT label for test set", "\n", "}", "\n", "", "else", ":", "\n", "            ", "Exception", "(", "\"not support split\"", ")", "\n", "", "target_split_fp", "=", "split_files", "[", "self", ".", "split", "]", "\n", "metadata", "=", "pd", ".", "read_json", "(", "os", ".", "path", ".", "join", "(", "metadata_dir", ",", "target_split_fp", ")", ",", "lines", "=", "True", ")", "\n", "self", ".", "metadata", "=", "metadata", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.tgifqa.TGIFQADataset._get_image_path": [[58, 65], ["os.path.join", "sample[].split", "os.path.join"], "methods", ["None"], ["", "def", "_get_image_path", "(", "self", ",", "sample", ")", ":", "\n", "# for example: tvqa/frames/raw_frames/frames_hq/met_frames/met_s06e22_seg01_clip_02", "\n", "        ", "dir_name", "=", "sample", "[", "'vid_name'", "]", ".", "split", "(", "'_'", ")", "[", "0", "]", "\n", "if", "dir_name", "not", "in", "[", "'bbt'", ",", "'castle'", ",", "'friends'", ",", "'grey'", ",", "'house'", ",", "'met'", "]", ":", "\n", "            ", "dir_name", "=", "'bbt'", "\n", "", "rel_fp", "=", "os", ".", "path", ".", "join", "(", "'frames/raw_frames/frames_hq/'", ",", "dir_name", "+", "'_frames'", ",", "sample", "[", "'vid_name'", "]", ")", "\n", "return", "os", ".", "path", ".", "join", "(", "self", ".", "data_dir", ",", "rel_fp", ")", ",", "rel_fp", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.tgifqa.TGIFQADataset._get_caption": [[66, 68], ["None"], "methods", ["None"], ["", "def", "_get_caption", "(", "self", ",", "sample", ")", ":", "\n", "        ", "return", "sample", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.tgifqa.TGIFQADataset._get_video_path": [[69, 71], ["os.path.join"], "methods", ["None"], ["", "def", "_get_video_path", "(", "self", ",", "sample", ")", ":", "\n", "        ", "return", "os", ".", "path", ".", "join", "(", "self", ".", "data_dir", ",", "'gifs'", ",", "sample", "[", "'gif_name'", "]", ")", "+", "'.gif'", ",", "sample", "[", "'gif_name'", "]", "+", "'.gif'", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.tgifqa.TGIFQADataset.get_raw_video": [[72, 79], ["tgifqa.TGIFQADataset._get_video_path", "video_base_dataset.read_frames_gif", "Exception"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_v2.Ego4DDataset._get_video_path", "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.video_base_dataset.read_frames_gif"], ["", "def", "get_raw_video", "(", "self", ",", "sample", ")", ":", "\n", "        ", "abs_fp", ",", "rel_fp", "=", "self", ".", "_get_video_path", "(", "sample", ")", "\n", "imgs", ",", "idxs", ",", "vlen", "=", "read_frames_gif", "(", "abs_fp", ",", "self", ".", "num_frames", ",", "mode", "=", "self", ".", "split", ")", "\n", "if", "imgs", "is", "None", ":", "\n", "            ", "raise", "Exception", "(", "\"Invalid img!\"", ",", "rel_fp", ")", "\n", "", "else", ":", "\n", "            ", "return", "imgs", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.tgifqa.TGIFQADataset.get_text": [[80, 98], ["tgifqa.TGIFQADataset.get_question", "range", "tgifqa.TGIFQADataset.tokenizer", "qa_texts.append", "range"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.datasets.vcr.VCRDataset.get_question"], ["", "", "def", "get_text", "(", "self", ",", "sample", ")", ":", "\n", "        ", "question", "=", "self", ".", "get_question", "(", "sample", ")", "\n", "qa_texts", "=", "[", "]", "\n", "# 5 choices # ClipBERT: \" \", Ours: [SEP]", "\n", "options", "=", "\" \"", ".", "join", "(", "sample", "[", "\"options\"", "]", "[", "i", "]", "for", "i", "in", "range", "(", "5", ")", ")", "\n", "for", "i", "in", "range", "(", "5", ")", ":", "\n", "            ", "raw_text", "=", "question", "+", "\"Options: \"", "+", "options", "+", "\"Answer: \"", "+", "sample", "[", "\"options\"", "]", "[", "i", "]", "\n", "# raw_text = question + \"[SEP]\" + sample[\"options\"][i]", "\n", "# print(raw_text)", "\n", "qa_encoding", "=", "self", ".", "tokenizer", "(", "\n", "raw_text", ",", "\n", "padding", "=", "\"max_length\"", ",", "\n", "truncation", "=", "True", ",", "\n", "max_length", "=", "self", ".", "max_text_len", ",", "\n", "return_special_tokens_mask", "=", "True", ",", "\n", ")", "\n", "qa_texts", ".", "append", "(", "(", "raw_text", ",", "qa_encoding", ")", ")", "\n", "", "return", "qa_texts", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.tgifqa.TGIFQADataset.get_answer_label": [[99, 102], ["int"], "methods", ["None"], ["", "def", "get_answer_label", "(", "self", ",", "sample", ")", ":", "\n", "        ", "answer", "=", "int", "(", "sample", "[", "'answer'", "]", ")", "\n", "return", "answer", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.tgifqa.TGIFQADataset.get_question": [[103, 105], ["None"], "methods", ["None"], ["", "def", "get_question", "(", "self", ",", "sample", ")", ":", "\n", "        ", "return", "sample", "[", "\"question\"", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.tgifqa.TGIFQADataset.__len__": [[106, 108], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "metadata", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.tgifqa.TGIFQADataset.__getitem__": [[109, 135], ["tgifqa.TGIFQADataset.get_answer_label", "tgifqa.TGIFQADataset.get_text", "range", "tgifqa.TGIFQADataset.get_video", "ret.update", "print", "print", "random.randint", "len"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.datasets.msvdqa.MSVDQADataset.get_answer_label", "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_v2.Ego4DDataset.get_text", "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_v2.Ego4DDataset.get_video", "home.repos.pwc.inspect_result.showlab_all-in-one.gadgets.my_metrics.VQAScore.update"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "result", "=", "None", "\n", "while", "result", "is", "None", ":", "\n", "            ", "sample", "=", "self", ".", "metadata", ".", "iloc", "[", "index", "]", "\n", "try", ":", "\n", "                ", "self", ".", "relevant_dets", "=", "[", "]", "# initalize", "\n", "self", ".", "relevant_dets_classes", "=", "[", "]", "\n", "answer", "=", "self", ".", "get_answer_label", "(", "sample", ")", "\n", "ret", "=", "{", "\n", "\"vid_index\"", ":", "index", ",", "\n", "\"cap_index\"", ":", "index", ",", "\n", "\"raw_index\"", ":", "index", ",", "\n", "'answer'", ":", "answer", "\n", "}", "\n", "qa_texts", "=", "self", ".", "get_text", "(", "sample", ")", "\n", "ret", "[", "\"text\"", "]", "=", "qa_texts", "[", "0", "]", "\n", "for", "i", "in", "range", "(", "self", ".", "draw_options_text", "-", "1", ")", ":", "\n", "                    ", "ret", ".", "update", "(", "{", "f\"options_text_{i}\"", ":", "qa_texts", "[", "i", "+", "1", "]", "}", ")", "\n", "", "video_tensor", "=", "self", ".", "get_video", "(", "sample", ")", "\n", "ret", "[", "\"image\"", "]", "=", "video_tensor", "\n", "result", "=", "True", "\n", "", "except", "Exception", "as", "e", ":", "\n", "                ", "print", "(", "f\"Error while read file idx {sample.name} in {self.names[0]} -> {e}\"", ")", "\n", "print", "(", "\"time stamp is: {}\"", ".", "format", "(", "sample", "[", "'ts'", "]", ")", ")", "\n", "index", "=", "random", ".", "randint", "(", "0", ",", "len", "(", "self", ".", "metadata", ")", "-", "1", ")", "\n", "", "", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.didemo.DIDEMODataset.__init__": [[9, 21], ["video_base_dataset.BaseDataset.__init__", "didemo.DIDEMODataset._load_metadata"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.transforms.utils.UnNormalize.__init__", "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_v2.Ego4DDataset._load_metadata"], ["    ", "def", "__init__", "(", "self", ",", "*", "args", ",", "split", "=", "\"\"", ",", "**", "kwargs", ")", ":", "\n", "        ", "assert", "split", "in", "[", "\"train\"", ",", "\"val\"", ",", "\"test\"", "]", "\n", "self", ".", "split", "=", "split", "\n", "self", ".", "metadata", "=", "None", "\n", "if", "split", "==", "\"train\"", ":", "\n", "            ", "names", "=", "[", "\"didemo_train\"", "]", "\n", "", "elif", "split", "==", "\"val\"", ":", "\n", "            ", "names", "=", "[", "\"didemo_val\"", "]", "\n", "", "elif", "split", "==", "\"test\"", ":", "\n", "            ", "names", "=", "[", "\"didemo_val\"", "]", "\n", "", "super", "(", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ",", "names", "=", "names", ",", "text_column_name", "=", "\"caption\"", ")", "\n", "self", ".", "_load_metadata", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.didemo.DIDEMODataset._load_metadata": [[22, 33], ["pandas.read_csv", "print", "os.path.join", "len"], "methods", ["None"], ["", "def", "_load_metadata", "(", "self", ")", ":", "\n", "        ", "metadata_dir", "=", "'./meta_data/didemo'", "\n", "split_files", "=", "{", "\n", "'train'", ":", "'DiDeMo_train.tsv'", ",", "\n", "'val'", ":", "'DiDeMo_val.tsv'", ",", "# there is no test", "\n", "'test'", ":", "'DiDeMo_test.tsv'", "\n", "}", "\n", "target_split_fp", "=", "split_files", "[", "self", ".", "split", "]", "\n", "metadata", "=", "pd", ".", "read_csv", "(", "os", ".", "path", ".", "join", "(", "metadata_dir", ",", "target_split_fp", ")", ",", "sep", "=", "'\\t'", ")", "\n", "self", ".", "metadata", "=", "metadata", "\n", "print", "(", "\"load split {}, {} samples\"", ".", "format", "(", "self", ".", "split", ",", "len", "(", "metadata", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.didemo.DIDEMODataset._get_video_path": [[34, 38], ["os.path.join"], "methods", ["None"], ["", "def", "_get_video_path", "(", "self", ",", "sample", ")", ":", "\n", "        ", "rel_video_fp", "=", "sample", "[", "1", "]", "\n", "full_video_fp", "=", "os", ".", "path", ".", "join", "(", "self", ".", "data_dir", ",", "''", ",", "rel_video_fp", ")", "\n", "return", "full_video_fp", ",", "rel_video_fp", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.didemo.DIDEMODataset._get_caption": [[39, 41], ["None"], "methods", ["None"], ["", "def", "_get_caption", "(", "self", ",", "sample", ")", ":", "\n", "        ", "return", "sample", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.hmdb51.HMDB51Dataset.__init__": [[7, 26], ["dict", "video_base_dataset.BaseDataset.__init__", "hmdb51.HMDB51Dataset._load_metadata"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.transforms.utils.UnNormalize.__init__", "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_v2.Ego4DDataset._load_metadata"], ["    ", "def", "__init__", "(", "self", ",", "*", "args", ",", "split", "=", "\"\"", ",", "**", "kwargs", ")", ":", "\n", "        ", "assert", "split", "in", "[", "\"train\"", ",", "\"val\"", ",", "\"test\"", "]", "\n", "self", ".", "split", "=", "split", "\n", "self", ".", "metadata", "=", "None", "\n", "self", ".", "ans_lab_dict", "=", "dict", "(", ")", "\n", "if", "split", "==", "\"train\"", ":", "\n", "            ", "names", "=", "[", "\"hmdb51_train\"", "]", "\n", "", "elif", "split", "==", "\"val\"", ":", "\n", "            ", "names", "=", "[", "\"hmdb51_val\"", "]", "\n", "", "elif", "split", "==", "\"test\"", ":", "\n", "            ", "names", "=", "[", "\"hmdb51_test\"", "]", "\n", "", "super", "(", ")", ".", "__init__", "(", "\n", "*", "args", ",", "\n", "**", "kwargs", ",", "\n", "names", "=", "names", ",", "\n", "text_column_name", "=", "\"questions\"", ",", "\n", "remove_duplicate", "=", "False", ",", "\n", ")", "\n", "self", ".", "_load_metadata", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.hmdb51.HMDB51Dataset._load_metadata": [[27, 41], ["os.path.join", "x.strip().split", "open", "f.readlines", "open", "x.strip", "os.path.join", "line.strip().split", "str", "line.strip", "int", "line.strip().split", "line.strip"], "methods", ["None"], ["", "def", "_load_metadata", "(", "self", ")", ":", "\n", "        ", "metadata_dir", "=", "'./meta_data/hmdb51'", "\n", "split_files", "=", "{", "\n", "'train'", ":", "'hmdb51_rgb_train_split_1.txt'", ",", "\n", "'val'", ":", "'hmdb51_rgb_val_split_1.txt'", ",", "\n", "'test'", ":", "'hmdb51_rgb_val_split_1.txt'", "\n", "}", "\n", "target_split_fp", "=", "split_files", "[", "self", ".", "split", "]", "\n", "self", ".", "metadata", "=", "[", "x", ".", "strip", "(", ")", ".", "split", "(", "' '", ")", "for", "x", "in", "open", "(", "os", ".", "path", ".", "join", "(", "metadata_dir", ",", "target_split_fp", ")", ")", "]", "\n", "answer_fp", "=", "os", ".", "path", ".", "join", "(", "metadata_dir", ",", "'hmdb51_classInd.txt'", ")", "\n", "with", "open", "(", "answer_fp", ",", "'r'", ")", "as", "f", ":", "\n", "            ", "lines", "=", "f", ".", "readlines", "(", ")", "\n", "for", "line", "in", "lines", ":", "\n", "                ", "self", ".", "ans_lab_dict", "[", "str", "(", "int", "(", "line", ".", "strip", "(", ")", ".", "split", "(", "' '", ")", "[", "0", "]", ")", "-", "1", ")", "]", "=", "line", ".", "strip", "(", ")", ".", "split", "(", "' '", ")", "[", "1", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.hmdb51.HMDB51Dataset._get_video_path": [[42, 45], ["os.path.join", "sample[].split", "sample[].split"], "methods", ["None"], ["", "", "", "def", "_get_video_path", "(", "self", ",", "sample", ")", ":", "\n", "# self.ans_lab_dict[sample[2]],", "\n", "        ", "return", "os", ".", "path", ".", "join", "(", "self", ".", "data_dir", ",", "sample", "[", "0", "]", ".", "split", "(", "'/'", ")", "[", "-", "1", "]", ")", "+", "'.avi'", ",", "sample", "[", "0", "]", ".", "split", "(", "'/'", ")", "[", "-", "1", "]", "+", "'.avi'", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.hmdb51.HMDB51Dataset.get_text": [[46, 56], ["hmdb51.HMDB51Dataset.tokenizer"], "methods", ["None"], ["", "def", "get_text", "(", "self", ",", "sample", ")", ":", "\n", "        ", "text", "=", "\"A person is doing [MASK]\"", "\n", "encoding", "=", "self", ".", "tokenizer", "(", "\n", "text", ",", "\n", "padding", "=", "\"max_length\"", ",", "\n", "truncation", "=", "True", ",", "\n", "max_length", "=", "self", ".", "max_text_len", ",", "\n", "return_special_tokens_mask", "=", "True", ",", "\n", ")", "\n", "return", "(", "text", ",", "encoding", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.hmdb51.HMDB51Dataset.get_answer_label": [[57, 64], ["int", "numpy.zeros().astype", "len", "numpy.zeros"], "methods", ["None"], ["", "def", "get_answer_label", "(", "self", ",", "sample", ")", ":", "\n", "        ", "text", "=", "\"None\"", "\n", "ans_total_len", "=", "len", "(", "self", ".", "ans_lab_dict", ")", "+", "1", "# one additional class", "\n", "ans_label", "=", "int", "(", "sample", "[", "2", "]", ")", "\n", "scores", "=", "np", ".", "zeros", "(", "ans_total_len", ")", ".", "astype", "(", "int", ")", "\n", "scores", "[", "ans_label", "]", "=", "1", "\n", "return", "text", ",", "ans_label", ",", "scores", "\n", "# return text, ans_label_vector, scores", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.hmdb51.HMDB51Dataset.__getitem__": [[66, 85], ["hmdb51.HMDB51Dataset.get_video", "hmdb51.HMDB51Dataset.get_text", "hmdb51.HMDB51Dataset.get_answer_label", "list", "list", "list"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_v2.Ego4DDataset.get_video", "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_v2.Ego4DDataset.get_text", "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.msvdqa.MSVDQADataset.get_answer_label"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "sample", "=", "self", ".", "metadata", "[", "index", "]", "# .split(' ')", "\n", "video_tensor", "=", "self", ".", "get_video", "(", "sample", ")", "\n", "text", "=", "self", ".", "get_text", "(", "sample", ")", "\n", "qid", "=", "index", "\n", "if", "self", ".", "split", "!=", "\"test\"", ":", "\n", "            ", "answers", ",", "labels", ",", "scores", "=", "self", ".", "get_answer_label", "(", "sample", ")", "\n", "", "else", ":", "\n", "            ", "answers", "=", "list", "(", ")", "\n", "labels", "=", "list", "(", ")", "\n", "scores", "=", "list", "(", ")", "\n", "\n", "", "return", "{", "\n", "\"video\"", ":", "video_tensor", ",", "\n", "\"text\"", ":", "text", ",", "\n", "\"vqa_answer\"", ":", "answers", ",", "\n", "\"vqa_labels\"", ":", "labels", ",", "\n", "\"vqa_scores\"", ":", "scores", ",", "\n", "\"qid\"", ":", "qid", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.hmdb51.HMDB51Dataset.__len__": [[87, 89], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "metadata", ")", "", "", "", ""]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.tvqa.TVQADataset.__init__": [[26, 45], ["tvqa.TVQADataset._load_metadata", "video_base_dataset.BaseDataset.__init__"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_v2.Ego4DDataset._load_metadata", "home.repos.pwc.inspect_result.showlab_all-in-one.transforms.utils.UnNormalize.__init__"], ["    ", "def", "__init__", "(", "self", ",", "*", "args", ",", "split", "=", "\"\"", ",", "**", "kwargs", ")", ":", "\n", "        ", "assert", "split", "in", "[", "\"train\"", ",", "\"val\"", ",", "\"test\"", "]", "\n", "self", ".", "split", "=", "split", "\n", "self", ".", "metadata", "=", "None", "\n", "self", ".", "_load_metadata", "(", ")", "\n", "if", "split", "==", "\"train\"", ":", "\n", "            ", "names", "=", "[", "\"tvqa_train\"", "]", "\n", "", "elif", "split", "==", "\"val\"", ":", "\n", "            ", "names", "=", "[", "\"tvqa_val\"", "]", "\n", "", "elif", "split", "==", "\"test\"", ":", "\n", "            ", "names", "=", "[", "\"tvqa_test\"", "]", "\n", "\n", "", "super", "(", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ",", "names", "=", "names", ",", "text_column_name", "=", "\"caption\"", ")", "\n", "# for appear objects", "\n", "self", ".", "only_use_relevant_dets", "=", "True", "\n", "if", "self", ".", "only_use_relevant_dets", ":", "\n", "            ", "self", ".", "relevant_dets", "=", "[", "]", "# resort the detection numbers", "\n", "self", ".", "relevant_dets_classes", "=", "[", "]", "\n", "", "self", ".", "fps", "=", "3", "# tvqa sample 3 frames per second", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.tvqa.TVQADataset._load_metadata": [[46, 57], ["pandas.read_json", "os.path.join"], "methods", ["None"], ["", "def", "_load_metadata", "(", "self", ")", ":", "\n", "# download specific", "\n", "        ", "metadata_dir", "=", "'./meta_data/tvqa'", "\n", "split_files", "=", "{", "\n", "'train'", ":", "'tvqa_train.jsonl'", ",", "\n", "'val'", ":", "'tvqa_val.jsonl'", ",", "\n", "'test'", ":", "'tvqa_test_public.jsonl'", "# no GT label for test set", "\n", "}", "\n", "target_split_fp", "=", "split_files", "[", "self", ".", "split", "]", "\n", "metadata", "=", "pd", ".", "read_json", "(", "os", ".", "path", ".", "join", "(", "metadata_dir", ",", "target_split_fp", ")", ",", "lines", "=", "True", ")", "\n", "self", ".", "metadata", "=", "metadata", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.tvqa.TVQADataset._get_image_path": [[58, 65], ["os.path.join", "sample[].split", "os.path.join"], "methods", ["None"], ["", "def", "_get_image_path", "(", "self", ",", "sample", ")", ":", "\n", "# for example: tvqa/frames/raw_frames/frames_hq/met_frames/met_s06e22_seg01_clip_02", "\n", "        ", "dir_name", "=", "sample", "[", "'vid_name'", "]", ".", "split", "(", "'_'", ")", "[", "0", "]", "\n", "if", "dir_name", "not", "in", "[", "'bbt'", ",", "'castle'", ",", "'friends'", ",", "'grey'", ",", "'house'", ",", "'met'", "]", ":", "\n", "            ", "dir_name", "=", "'bbt'", "\n", "", "rel_fp", "=", "os", ".", "path", ".", "join", "(", "'frames/raw_frames/frames_hq/'", ",", "dir_name", "+", "'_frames'", ",", "sample", "[", "'vid_name'", "]", ")", "\n", "return", "os", ".", "path", ".", "join", "(", "self", ".", "data_dir", ",", "rel_fp", ")", ",", "rel_fp", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.tvqa.TVQADataset._get_caption": [[66, 68], ["None"], "methods", ["None"], ["", "def", "_get_caption", "(", "self", ",", "sample", ")", ":", "\n", "        ", "return", "sample", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.tvqa.TVQADataset._get_video_len": [[70, 72], ["len", "os.listdir"], "methods", ["None"], ["", "def", "_get_video_len", "(", "self", ",", "dir", ")", ":", "\n", "        ", "return", "len", "(", "os", ".", "listdir", "(", "dir", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.tvqa.TVQADataset.get_raw_video": [[74, 104], ["tvqa.TVQADataset._get_image_path", "sample[].split", "int", "max", "CoTrain.datasets.video.video_base_dataset.sample_frames", "max", "tvqa.TVQADataset._get_video_len", "torch.stack().permute", "int", "min", "cv2.imread", "torch.from_numpy().byte", "frame.permute.permute.permute", "torch.stack().permute.append", "os.path.join", "print", "print", "torch.stack", "float", "float", "float", "os.path.join", "torch.from_numpy"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.datasets.vcr.VCRDataset._get_image_path", "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.base_dataset.sample_frames", "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.tvqa.TVQADataset._get_video_len"], ["", "def", "get_raw_video", "(", "self", ",", "sample", ")", ":", "\n", "        ", "abs_fp", ",", "rel_fp", "=", "self", ".", "_get_image_path", "(", "sample", ")", "\n", "[", "beg_time", ",", "end_time", "]", "=", "sample", "[", "'ts'", "]", ".", "split", "(", "'-'", ")", "\n", "clip_len", "=", "int", "(", "(", "float", "(", "end_time", ")", "-", "float", "(", "beg_time", ")", ")", "*", "self", ".", "fps", ")", "\n", "# try:", "\n", "#     clip_len = int((float(end_time) - float(beg_time)) * self.fps)", "\n", "# except ValueError:", "\n", "#     clip_len = 1", "\n", "# prevent short than 1 second", "\n", "clip_len", "=", "max", "(", "clip_len", ",", "2", "*", "self", ".", "num_frames", ")", "\n", "rel_frame_index", "=", "sample_frames", "(", "self", ".", "num_frames", ",", "clip_len", ")", "\n", "begin_frame_index", "=", "max", "(", "1", ",", "int", "(", "float", "(", "beg_time", ")", "*", "self", ".", "fps", ")", ")", "\n", "video_len", "=", "self", ".", "_get_video_len", "(", "abs_fp", ")", "\n", "# sample N frames here", "\n", "frames", "=", "[", "]", "\n", "for", "index", "in", "rel_frame_index", ":", "\n", "            ", "abs_index", "=", "begin_frame_index", "+", "index", "\n", "abs_index", "=", "min", "(", "video_len", ",", "abs_index", ")", "\n", "image_rel_path", "=", "f'{abs_index:05}'", "\n", "img", "=", "cv2", ".", "imread", "(", "os", ".", "path", ".", "join", "(", "abs_fp", ",", "'{}.jpg'", ".", "format", "(", "image_rel_path", ")", ")", ")", "\n", "# print(img)", "\n", "# print(os.path.join(abs_fp, '{}.jpg'.format(image_rel_path)))", "\n", "if", "img", "is", "None", ":", "\n", "                ", "print", "(", "sample", "[", "'vid_name'", "]", ")", "\n", "print", "(", "os", ".", "path", ".", "join", "(", "abs_fp", ",", "'{}.jpg'", ".", "format", "(", "image_rel_path", ")", ")", ")", "\n", "", "frame", "=", "torch", ".", "from_numpy", "(", "img", ")", ".", "byte", "(", ")", "\n", "frame", "=", "frame", ".", "permute", "(", "2", ",", "0", ",", "1", ")", "\n", "frames", ".", "append", "(", "frame", ")", "\n", "", "frames", "=", "torch", ".", "stack", "(", "frames", ")", ".", "permute", "(", "1", ",", "0", ",", "2", ",", "3", ")", "\n", "return", "frames", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.tvqa.TVQADataset.get_text": [[105, 124], ["tvqa.TVQADataset.get_question", "range", "tvqa.TVQADataset.tokenizer", "qa_texts.append", "range"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.datasets.vcr.VCRDataset.get_question"], ["", "def", "get_text", "(", "self", ",", "sample", ")", ":", "\n", "        ", "question", "=", "self", ".", "get_question", "(", "sample", ")", "\n", "qa_texts", "=", "[", "]", "\n", "# 5 choices # ClipBERT: \" \", Ours: [SEP]", "\n", "# if the length suppress than 40 ?", "\n", "options", "=", "\" \"", ".", "join", "(", "sample", "[", "\"a{}\"", ".", "format", "(", "i", ")", "]", "for", "i", "in", "range", "(", "5", ")", ")", "\n", "for", "i", "in", "range", "(", "5", ")", ":", "\n", "            ", "raw_text", "=", "question", "+", "\"Options: \"", "+", "options", "+", "\"Answer: \"", "+", "sample", "[", "\"a{}\"", ".", "format", "(", "i", ")", "]", "\n", "# raw_text = question + \"[SEP]\" + sample[\"a{}\".format(i)]", "\n", "# print(raw_text)", "\n", "qa_encoding", "=", "self", ".", "tokenizer", "(", "\n", "raw_text", ",", "\n", "padding", "=", "\"max_length\"", ",", "\n", "truncation", "=", "True", ",", "\n", "max_length", "=", "self", ".", "max_text_len", ",", "\n", "return_special_tokens_mask", "=", "True", ",", "\n", ")", "\n", "qa_texts", ".", "append", "(", "(", "raw_text", ",", "qa_encoding", ")", ")", "\n", "", "return", "qa_texts", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.tvqa.TVQADataset.get_answer_label": [[125, 128], ["int"], "methods", ["None"], ["", "def", "get_answer_label", "(", "self", ",", "sample", ")", ":", "\n", "        ", "answer", "=", "int", "(", "sample", "[", "'answer_idx'", "]", ")", "\n", "return", "answer", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.tvqa.TVQADataset.get_question": [[129, 131], ["None"], "methods", ["None"], ["", "def", "get_question", "(", "self", ",", "sample", ")", ":", "\n", "        ", "return", "sample", "[", "\"q\"", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.tvqa.TVQADataset.__len__": [[132, 134], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "metadata", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.tvqa.TVQADataset.__getitem__": [[135, 161], ["tvqa.TVQADataset.get_answer_label", "tvqa.TVQADataset.get_text", "range", "tvqa.TVQADataset.get_video", "ret.update", "print", "print", "random.randint", "len"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.datasets.msvdqa.MSVDQADataset.get_answer_label", "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_v2.Ego4DDataset.get_text", "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_v2.Ego4DDataset.get_video", "home.repos.pwc.inspect_result.showlab_all-in-one.gadgets.my_metrics.VQAScore.update"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "result", "=", "None", "\n", "while", "result", "is", "None", ":", "\n", "            ", "sample", "=", "self", ".", "metadata", ".", "iloc", "[", "index", "]", "\n", "try", ":", "\n", "                ", "self", ".", "relevant_dets", "=", "[", "]", "# initalize", "\n", "self", ".", "relevant_dets_classes", "=", "[", "]", "\n", "answer", "=", "self", ".", "get_answer_label", "(", "sample", ")", "\n", "ret", "=", "{", "\n", "\"vid_index\"", ":", "index", ",", "\n", "\"cap_index\"", ":", "index", ",", "\n", "\"raw_index\"", ":", "index", ",", "\n", "'answer'", ":", "answer", "\n", "}", "\n", "qa_texts", "=", "self", ".", "get_text", "(", "sample", ")", "\n", "ret", "[", "\"text\"", "]", "=", "qa_texts", "[", "0", "]", "\n", "for", "i", "in", "range", "(", "self", ".", "draw_options_text", "-", "1", ")", ":", "\n", "                    ", "ret", ".", "update", "(", "{", "f\"options_text_{i}\"", ":", "qa_texts", "[", "i", "+", "1", "]", "}", ")", "\n", "", "video_tensor", "=", "self", ".", "get_video", "(", "sample", ")", "\n", "ret", "[", "\"image\"", "]", "=", "video_tensor", "\n", "result", "=", "True", "\n", "", "except", "Exception", "as", "e", ":", "\n", "                ", "print", "(", "f\"Error while read file idx {sample.name} in {self.names[0]} -> {e}\"", ")", "\n", "print", "(", "\"time stamp is: {}\"", ".", "format", "(", "sample", "[", "'ts'", "]", ")", ")", "\n", "index", "=", "random", ".", "randint", "(", "0", ",", "len", "(", "self", ".", "metadata", ")", "-", "1", ")", "\n", "", "", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.k400.K400Dataset.__init__": [[9, 29], ["dict", "video_base_dataset.BaseDataset.__init__", "CoTrain.transforms.video.videoaug.VideoTransform", "k400.K400Dataset._load_metadata"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.transforms.utils.UnNormalize.__init__", "home.repos.pwc.inspect_result.showlab_all-in-one.transforms.videoaug.VideoTransform", "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_v2.Ego4DDataset._load_metadata"], ["    ", "def", "__init__", "(", "self", ",", "*", "args", ",", "split", "=", "\"\"", ",", "**", "kwargs", ")", ":", "\n", "        ", "assert", "split", "in", "[", "\"train\"", ",", "\"val\"", ",", "\"test\"", "]", "\n", "self", ".", "split", "=", "split", "\n", "self", ".", "metadata", "=", "None", "\n", "self", ".", "ans_lab_dict", "=", "dict", "(", ")", "\n", "if", "split", "==", "\"train\"", ":", "\n", "            ", "names", "=", "[", "\"k400_train\"", "]", "\n", "", "elif", "split", "==", "\"val\"", ":", "\n", "            ", "names", "=", "[", "\"k400_val\"", "]", "\n", "", "elif", "split", "==", "\"test\"", ":", "\n", "            ", "names", "=", "[", "\"k400_test\"", "]", "\n", "", "super", "(", ")", ".", "__init__", "(", "\n", "*", "args", ",", "\n", "**", "kwargs", ",", "\n", "names", "=", "names", ",", "\n", "text_column_name", "=", "\"questions\"", ",", "\n", "remove_duplicate", "=", "False", ",", "\n", ")", "\n", "self", ".", "video_transform", "=", "VideoTransform", "(", "mode", "=", "self", ".", "split", ")", "# train or val model", "\n", "self", ".", "_load_metadata", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.k400.K400Dataset._load_metadata": [[30, 47], ["os.path.join", "open", "f.readlines", "open", "f.readlines", "os.path.join", "str", "line.strip"], "methods", ["None"], ["", "def", "_load_metadata", "(", "self", ")", ":", "\n", "        ", "metadata_dir", "=", "'./meta_data/k400'", "\n", "split_files", "=", "{", "\n", "'train'", ":", "'k400_train_tsm.list'", ",", "\n", "'val'", ":", "'k400_test_tsm.list'", ",", "\n", "'test'", ":", "'k400_test_tsm.list'", "\n", "}", "\n", "target_split_fp", "=", "split_files", "[", "self", ".", "split", "]", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "metadata_dir", ",", "target_split_fp", ")", ")", "as", "f", ":", "\n", "            ", "self", ".", "metadata", "=", "f", ".", "readlines", "(", ")", "\n", "", "answer_fp", "=", "os", ".", "path", ".", "join", "(", "metadata_dir", ",", "'kinetics_label_map.txt'", ")", "\n", "count", "=", "0", "\n", "with", "open", "(", "answer_fp", ",", "'r'", ")", "as", "f", ":", "\n", "            ", "lines", "=", "f", ".", "readlines", "(", ")", "\n", "for", "line", "in", "lines", ":", "\n", "                ", "self", ".", "ans_lab_dict", "[", "str", "(", "line", ".", "strip", "(", ")", ")", "]", "=", "count", "\n", "count", "+=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.k400.K400Dataset._get_video_path": [[48, 66], ["os.path.join", "fake_path.split", "os.listdir", "os.path.join", "os.path.join"], "methods", ["None"], ["", "", "", "def", "_get_video_path", "(", "self", ",", "sample", ")", ":", "\n", "# find the name is os.listdir() e.g. abseiling/0wR5jVB-WPk.mp4", "\n", "# /data/algceph/arcdata/Kinetics-400/train_zips/snowboarding/MCgJO4s1qBA_000129_000139.zip", "\n", "# -> snowboarding/MCgJO4s1qBA_000129_000139.mp4", "\n", "        ", "if", "self", ".", "split", "==", "'train'", ":", "\n", "            ", "rel_path", "=", "sample", "[", "0", "]", "[", "46", ":", "-", "4", "]", "+", "'.mp4'", "\n", "", "else", ":", "\n", "# val maybe mkv. webm etc.", "\n", "            ", "fake_path", "=", "sample", "[", "0", "]", "[", "44", ":", "-", "4", "]", "\n", "sub_dir", ",", "video_name", "=", "fake_path", ".", "split", "(", "'/'", ")", "\n", "rel_path", "=", "sub_dir", "\n", "for", "video", "in", "os", ".", "listdir", "(", "os", ".", "path", ".", "join", "(", "self", ".", "data_dir", ",", "self", ".", "split", ",", "sub_dir", ")", ")", ":", "\n", "                ", "if", "video_name", "in", "video", ":", "\n", "                    ", "rel_path", "=", "os", ".", "path", ".", "join", "(", "rel_path", ",", "video", ")", "\n", "break", "\n", "", "", "", "full_path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "data_dir", ",", "self", ".", "split", ",", "rel_path", ")", "\n", "# print(full_path)", "\n", "return", "full_path", ",", "rel_path", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.k400.K400Dataset.get_text": [[67, 77], ["k400.K400Dataset.tokenizer"], "methods", ["None"], ["", "def", "get_text", "(", "self", ",", "sample", ")", ":", "\n", "        ", "text", "=", "\"A persion is doing [MASK]\"", "\n", "encoding", "=", "self", ".", "tokenizer", "(", "\n", "text", ",", "\n", "padding", "=", "\"max_length\"", ",", "\n", "truncation", "=", "True", ",", "\n", "max_length", "=", "self", ".", "max_text_len", ",", "\n", "return_special_tokens_mask", "=", "True", ",", "\n", ")", "\n", "return", "(", "text", ",", "encoding", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.k400.K400Dataset.get_answer_label": [[78, 86], ["int", "numpy.zeros().astype", "len", "numpy.zeros"], "methods", ["None"], ["", "def", "get_answer_label", "(", "self", ",", "sample", ")", ":", "\n", "        ", "text", "=", "\"None\"", "\n", "# print(len(self.ans_lab_dict))", "\n", "ans_total_len", "=", "len", "(", "self", ".", "ans_lab_dict", ")", "+", "1", "# one additional class", "\n", "ans_label", "=", "int", "(", "sample", "[", "1", "]", ")", "\n", "scores", "=", "np", ".", "zeros", "(", "ans_total_len", ")", ".", "astype", "(", "int", ")", "\n", "scores", "[", "ans_label", "]", "=", "1", "\n", "return", "text", ",", "ans_label", ",", "scores", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.k400.K400Dataset.__getitem__": [[87, 112], ["k400.K400Dataset.metadata[].split", "k400.K400Dataset.get_video", "k400.K400Dataset.get_text", "k400.K400Dataset.get_answer_label", "list", "list", "list", "print", "random.randint", "len"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_v2.Ego4DDataset.get_video", "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_v2.Ego4DDataset.get_text", "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.msvdqa.MSVDQADataset.get_answer_label"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "result", "=", "None", "\n", "while", "result", "is", "None", ":", "\n", "            ", "sample", "=", "self", ".", "metadata", "[", "index", "]", ".", "split", "(", "'\\t'", ")", "\n", "try", ":", "\n", "                ", "video_tensor", "=", "self", ".", "get_video", "(", "sample", ")", "\n", "text", "=", "self", ".", "get_text", "(", "sample", ")", "\n", "qid", "=", "index", "\n", "if", "self", ".", "split", "!=", "\"test\"", ":", "\n", "                    ", "answers", ",", "labels", ",", "scores", "=", "self", ".", "get_answer_label", "(", "sample", ")", "\n", "", "else", ":", "\n", "                    ", "answers", "=", "list", "(", ")", "\n", "labels", "=", "list", "(", ")", "\n", "scores", "=", "list", "(", ")", "\n", "", "result", "=", "True", "\n", "", "except", "Exception", "as", "e", ":", "\n", "                ", "print", "(", "f\"Error while read file idx {sample[0]} -> {e}\"", ")", "\n", "index", "=", "random", ".", "randint", "(", "0", ",", "len", "(", "self", ".", "metadata", ")", "-", "1", ")", "\n", "", "", "return", "{", "\n", "\"video\"", ":", "video_tensor", ",", "\n", "\"text\"", ":", "text", ",", "\n", "\"vqa_answer\"", ":", "answers", ",", "\n", "\"vqa_labels\"", ":", "labels", ",", "\n", "\"vqa_scores\"", ":", "scores", ",", "\n", "\"qid\"", ":", "qid", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.k400.K400Dataset.__len__": [[114, 116], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "metadata", ")", "", "", "", ""]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.msrvttqa.MSRVTTQADataset.__init__": [[9, 34], ["video_base_dataset.BaseDataset.__init__", "msrvttqa.MSRVTTQADataset._load_metadata"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.transforms.utils.UnNormalize.__init__", "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_v2.Ego4DDataset._load_metadata"], ["    ", "def", "__init__", "(", "self", ",", "*", "args", ",", "split", "=", "\"\"", ",", "**", "kwargs", ")", ":", "\n", "        ", "assert", "split", "in", "[", "\"train\"", ",", "\"val\"", ",", "\"test\"", "]", "\n", "#         if split == \"test\":", "\n", "#             split = \"val\"", "\n", "self", ".", "split", "=", "split", "\n", "self", ".", "metadata", "=", "None", "\n", "self", ".", "ans_lab_dict", "=", "None", "\n", "if", "split", "==", "\"train\"", ":", "\n", "            ", "names", "=", "[", "\"msrvtt_qa_train\"", "]", "\n", "# names = [\"msrvtt_qa_train\", \"msrvtt_qa_val\"]", "\n", "", "elif", "split", "==", "\"val\"", ":", "\n", "            ", "names", "=", "[", "\"msrvtt_qa_test\"", "]", "# [\"msrvtt_qa_val\"]", "\n", "", "elif", "split", "==", "\"test\"", ":", "\n", "            ", "names", "=", "[", "\"msrvtt_qa_test\"", "]", "# vqav2_test-dev for test-dev", "\n", "\n", "", "super", "(", ")", ".", "__init__", "(", "\n", "*", "args", ",", "\n", "**", "kwargs", ",", "\n", "names", "=", "names", ",", "\n", "text_column_name", "=", "\"questions\"", ",", "\n", "remove_duplicate", "=", "False", ",", "\n", ")", "\n", "self", ".", "names", "=", "names", "\n", "# self.num_frames = 4", "\n", "self", ".", "_load_metadata", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.msrvttqa.MSRVTTQADataset._load_metadata": [[35, 56], ["os.path.join", "print", "open", "json.load", "pandas.read_json", "name.split", "os.path.join", "msrvttqa.MSRVTTQADataset.metadata.update", "len"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.gadgets.my_metrics.VQAScore.update"], ["", "def", "_load_metadata", "(", "self", ")", ":", "\n", "        ", "metadata_dir", "=", "'./meta_data/msrvtt'", "\n", "split_files", "=", "{", "\n", "'train'", ":", "'msrvtt_qa_train.jsonl'", ",", "\n", "'val'", ":", "'msrvtt_qa_val.jsonl'", ",", "\n", "'test'", ":", "'msrvtt_qa_test.jsonl'", "\n", "}", "\n", "answer_fp", "=", "os", ".", "path", ".", "join", "(", "metadata_dir", ",", "'msrvtt_train_ans2label.json'", ")", "# 1500 in total (all classes in train)", "\n", "# answer_fp = os.path.join(metadata_dir, 'msrvtt_qa_ans2label.json')  # 4539 in total (all classes in train+val+test)", "\n", "with", "open", "(", "answer_fp", ",", "'r'", ")", "as", "JSON", ":", "\n", "            ", "self", ".", "ans_lab_dict", "=", "json", ".", "load", "(", "JSON", ")", "\n", "", "for", "name", "in", "self", ".", "names", ":", "\n", "            ", "split", "=", "name", ".", "split", "(", "'_'", ")", "[", "-", "1", "]", "\n", "target_split_fp", "=", "split_files", "[", "split", "]", "\n", "# path_or_buf=os.path.join(metadata_dir, target_split_fp)", "\n", "metadata", "=", "pd", ".", "read_json", "(", "os", ".", "path", ".", "join", "(", "metadata_dir", ",", "target_split_fp", ")", ",", "lines", "=", "True", ")", "\n", "if", "self", ".", "metadata", "is", "None", ":", "\n", "                ", "self", ".", "metadata", "=", "metadata", "\n", "", "else", ":", "\n", "                ", "self", ".", "metadata", ".", "update", "(", "metadata", ")", "\n", "", "", "print", "(", "\"total {} samples for {}\"", ".", "format", "(", "len", "(", "self", ".", "metadata", ")", ",", "self", ".", "names", ")", ")", "\n", "# data1.update(data2)", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.msrvttqa.MSRVTTQADataset.get_text": [[58, 68], ["msrvttqa.MSRVTTQADataset.tokenizer"], "methods", ["None"], ["", "def", "get_text", "(", "self", ",", "sample", ")", ":", "\n", "        ", "text", "=", "sample", "[", "'question'", "]", "\n", "encoding", "=", "self", ".", "tokenizer", "(", "\n", "text", ",", "\n", "padding", "=", "\"max_length\"", ",", "\n", "truncation", "=", "True", ",", "\n", "max_length", "=", "self", ".", "max_text_len", ",", "\n", "return_special_tokens_mask", "=", "True", ",", "\n", ")", "\n", "return", "(", "text", ",", "encoding", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.msrvttqa.MSRVTTQADataset.get_answer_label": [[69, 80], ["numpy.zeros().astype", "len", "numpy.zeros"], "methods", ["None"], ["", "def", "get_answer_label", "(", "self", ",", "sample", ")", ":", "\n", "        ", "text", "=", "sample", "[", "'answer'", "]", "\n", "ans_total_len", "=", "len", "(", "self", ".", "ans_lab_dict", ")", "+", "1", "# one additional class", "\n", "try", ":", "\n", "            ", "ans_label", "=", "self", ".", "ans_lab_dict", "[", "text", "]", "#", "\n", "", "except", "KeyError", ":", "\n", "            ", "ans_label", "=", "-", "100", "# ignore classes", "\n", "# ans_label = 1500 # other classes", "\n", "", "scores", "=", "np", ".", "zeros", "(", "ans_total_len", ")", ".", "astype", "(", "int", ")", "\n", "scores", "[", "ans_label", "]", "=", "1", "\n", "return", "text", ",", "ans_label", ",", "scores", "\n", "# return text, ans_label_vector, scores", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.msrvttqa.MSRVTTQADataset.__getitem__": [[82, 102], ["msrvttqa.MSRVTTQADataset.get_video", "msrvttqa.MSRVTTQADataset.get_text", "msrvttqa.MSRVTTQADataset.get_answer_label", "list", "list", "list"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_v2.Ego4DDataset.get_video", "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_v2.Ego4DDataset.get_text", "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.msvdqa.MSVDQADataset.get_answer_label"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "sample", "=", "self", ".", "metadata", ".", "iloc", "[", "index", "]", "\n", "video_tensor", "=", "self", ".", "get_video", "(", "sample", ")", "\n", "text", "=", "self", ".", "get_text", "(", "sample", ")", "\n", "# index, question_index = self.index_mapper[index]", "\n", "qid", "=", "index", "\n", "if", "self", ".", "split", "!=", "\"test\"", ":", "\n", "            ", "answers", ",", "labels", ",", "scores", "=", "self", ".", "get_answer_label", "(", "sample", ")", "\n", "", "else", ":", "\n", "            ", "answers", "=", "list", "(", ")", "\n", "labels", "=", "list", "(", ")", "\n", "scores", "=", "list", "(", ")", "\n", "\n", "", "return", "{", "\n", "\"video\"", ":", "video_tensor", ",", "\n", "\"text\"", ":", "text", ",", "\n", "\"vqa_answer\"", ":", "answers", ",", "\n", "\"vqa_labels\"", ":", "labels", ",", "\n", "\"vqa_scores\"", ":", "scores", ",", "\n", "\"qid\"", ":", "qid", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.msrvttqa.MSRVTTQADataset.__len__": [[104, 106], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "metadata", ")", "", "", "", ""]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.ucf101.UCF101Dataset.__init__": [[7, 26], ["dict", "video_base_dataset.BaseDataset.__init__", "ucf101.UCF101Dataset._load_metadata"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.transforms.utils.UnNormalize.__init__", "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_v2.Ego4DDataset._load_metadata"], ["    ", "def", "__init__", "(", "self", ",", "*", "args", ",", "split", "=", "\"\"", ",", "**", "kwargs", ")", ":", "\n", "        ", "assert", "split", "in", "[", "\"train\"", ",", "\"val\"", ",", "\"test\"", "]", "\n", "self", ".", "split", "=", "split", "\n", "self", ".", "metadata", "=", "None", "\n", "self", ".", "ans_lab_dict", "=", "dict", "(", ")", "\n", "if", "split", "==", "\"train\"", ":", "\n", "            ", "names", "=", "[", "\"ucf101_train\"", "]", "\n", "", "elif", "split", "==", "\"val\"", ":", "\n", "            ", "names", "=", "[", "\"ucf101_val\"", "]", "\n", "", "elif", "split", "==", "\"test\"", ":", "\n", "            ", "names", "=", "[", "\"ucf101_test\"", "]", "\n", "", "super", "(", ")", ".", "__init__", "(", "\n", "*", "args", ",", "\n", "**", "kwargs", ",", "\n", "names", "=", "names", ",", "\n", "text_column_name", "=", "\"questions\"", ",", "\n", "remove_duplicate", "=", "False", ",", "\n", ")", "\n", "self", ".", "_load_metadata", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.ucf101.UCF101Dataset._load_metadata": [[27, 41], ["os.path.join", "x.strip().split", "open", "f.readlines", "open", "x.strip", "os.path.join", "line.strip().split", "str", "line.strip", "int", "line.strip().split", "line.strip"], "methods", ["None"], ["", "def", "_load_metadata", "(", "self", ")", ":", "\n", "        ", "metadata_dir", "=", "'./meta_data/ucf101'", "\n", "split_files", "=", "{", "\n", "'train'", ":", "'hmdb51_rgb_train_split_1.txt'", ",", "\n", "'val'", ":", "'hmdb51_rgb_val_split_1.txt'", ",", "\n", "'test'", ":", "'hmdb51_rgb_val_split_1.txt'", "\n", "}", "\n", "target_split_fp", "=", "split_files", "[", "self", ".", "split", "]", "\n", "self", ".", "metadata", "=", "[", "x", ".", "strip", "(", ")", ".", "split", "(", "' '", ")", "for", "x", "in", "open", "(", "os", ".", "path", ".", "join", "(", "metadata_dir", ",", "target_split_fp", ")", ")", "]", "\n", "answer_fp", "=", "os", ".", "path", ".", "join", "(", "metadata_dir", ",", "'hmdb51_classInd.txt'", ")", "\n", "with", "open", "(", "answer_fp", ",", "'r'", ")", "as", "f", ":", "\n", "            ", "lines", "=", "f", ".", "readlines", "(", ")", "\n", "for", "line", "in", "lines", ":", "\n", "                ", "self", ".", "ans_lab_dict", "[", "str", "(", "int", "(", "line", ".", "strip", "(", ")", ".", "split", "(", "' '", ")", "[", "0", "]", ")", "-", "1", ")", "]", "=", "line", ".", "strip", "(", ")", ".", "split", "(", "' '", ")", "[", "1", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.ucf101.UCF101Dataset._get_video_path": [[42, 45], ["os.path.join", "sample[].split", "sample[].split"], "methods", ["None"], ["", "", "", "def", "_get_video_path", "(", "self", ",", "sample", ")", ":", "\n", "# self.ans_lab_dict[sample[2]],", "\n", "        ", "return", "os", ".", "path", ".", "join", "(", "self", ".", "data_dir", ",", "sample", "[", "0", "]", ".", "split", "(", "'/'", ")", "[", "-", "1", "]", ")", "+", "'.avi'", ",", "sample", "[", "0", "]", ".", "split", "(", "'/'", ")", "[", "-", "1", "]", "+", "'.avi'", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.ucf101.UCF101Dataset.get_text": [[46, 56], ["ucf101.UCF101Dataset.tokenizer"], "methods", ["None"], ["", "def", "get_text", "(", "self", ",", "sample", ")", ":", "\n", "        ", "text", "=", "\"A person is doing [MASK]\"", "\n", "encoding", "=", "self", ".", "tokenizer", "(", "\n", "text", ",", "\n", "padding", "=", "\"max_length\"", ",", "\n", "truncation", "=", "True", ",", "\n", "max_length", "=", "self", ".", "max_text_len", ",", "\n", "return_special_tokens_mask", "=", "True", ",", "\n", ")", "\n", "return", "(", "text", ",", "encoding", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.ucf101.UCF101Dataset.get_answer_label": [[57, 64], ["int", "numpy.zeros().astype", "len", "numpy.zeros"], "methods", ["None"], ["", "def", "get_answer_label", "(", "self", ",", "sample", ")", ":", "\n", "        ", "text", "=", "\"None\"", "\n", "ans_total_len", "=", "len", "(", "self", ".", "ans_lab_dict", ")", "+", "1", "# one additional class", "\n", "ans_label", "=", "int", "(", "sample", "[", "2", "]", ")", "\n", "scores", "=", "np", ".", "zeros", "(", "ans_total_len", ")", ".", "astype", "(", "int", ")", "\n", "scores", "[", "ans_label", "]", "=", "1", "\n", "return", "text", ",", "ans_label", ",", "scores", "\n", "# return text, ans_label_vector, scores", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.ucf101.UCF101Dataset.__getitem__": [[66, 85], ["ucf101.UCF101Dataset.get_video", "ucf101.UCF101Dataset.get_text", "ucf101.UCF101Dataset.get_answer_label", "list", "list", "list"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_v2.Ego4DDataset.get_video", "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_v2.Ego4DDataset.get_text", "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.msvdqa.MSVDQADataset.get_answer_label"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "sample", "=", "self", ".", "metadata", "[", "index", "]", "# .split(' ')", "\n", "video_tensor", "=", "self", ".", "get_video", "(", "sample", ")", "\n", "text", "=", "self", ".", "get_text", "(", "sample", ")", "\n", "qid", "=", "index", "\n", "if", "self", ".", "split", "!=", "\"test\"", ":", "\n", "            ", "answers", ",", "labels", ",", "scores", "=", "self", ".", "get_answer_label", "(", "sample", ")", "\n", "", "else", ":", "\n", "            ", "answers", "=", "list", "(", ")", "\n", "labels", "=", "list", "(", ")", "\n", "scores", "=", "list", "(", ")", "\n", "\n", "", "return", "{", "\n", "\"video\"", ":", "video_tensor", ",", "\n", "\"text\"", ":", "text", ",", "\n", "\"vqa_answer\"", ":", "answers", ",", "\n", "\"vqa_labels\"", ":", "labels", ",", "\n", "\"vqa_scores\"", ":", "scores", ",", "\n", "\"qid\"", ":", "qid", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.ucf101.UCF101Dataset.__len__": [[87, 89], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "metadata", ")", "", "", "", ""]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.video_base_dataset.BaseDataset.__init__": [[23, 77], ["super().__init__", "CoTrain.transforms.keys_to_transforms", "CoTrain.transforms.video.videoaug.VideoTransform", "len", "len", "os.path.join", "torch.distributed.get_rank", "print", "print", "torch.distributed.get_rank", "print", "print", "names[].split", "torch.distributed.get_rank", "print"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.transforms.utils.UnNormalize.__init__", "home.repos.pwc.inspect_result.showlab_all-in-one.transforms.__init__.keys_to_transforms", "home.repos.pwc.inspect_result.showlab_all-in-one.transforms.videoaug.VideoTransform", "home.repos.pwc.inspect_result.showlab_all-in-one.modules.dist_utils.get_rank", "home.repos.pwc.inspect_result.showlab_all-in-one.modules.dist_utils.get_rank", "home.repos.pwc.inspect_result.showlab_all-in-one.modules.dist_utils.get_rank"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "data_dir", ":", "str", ",", "\n", "transform_keys", ":", "list", ",", "\n", "image_size", ":", "int", ",", "\n", "names", ":", "list", ",", "\n", "text_column_name", ":", "str", "=", "\"\"", ",", "\n", "remove_duplicate", "=", "True", ",", "\n", "max_text_len", "=", "40", ",", "\n", "draw_false_image", "=", "0", ",", "\n", "draw_false_video", "=", "0", ",", "\n", "draw_false_text", "=", "0", ",", "\n", "image_only", "=", "False", ",", "\n", "video_only", "=", "False", ",", "\n", "num_frames", "=", "1", ",", "\n", "draw_options_text", "=", "0", ",", "\n", "backend", "=", "'v100'", "\n", ")", ":", "\n", "        ", "\"\"\"\n        data_dir : where dataset file *.arrow lives; existence should be guaranteed via DataModule.prepare_data\n        transform_keys : keys for generating augmented views of videos\n        text_column_name : pyarrow table column name that has list of strings as elements\n        \"\"\"", "\n", "assert", "len", "(", "transform_keys", ")", ">=", "1", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "transforms", "=", "keys_to_transforms", "(", "transform_keys", ",", "size", "=", "image_size", ")", "\n", "self", ".", "text_column_name", "=", "text_column_name", "\n", "self", ".", "names", "=", "names", "\n", "self", ".", "max_text_len", "=", "max_text_len", "\n", "self", ".", "draw_false_video", "=", "draw_false_video", "\n", "self", ".", "draw_false_text", "=", "draw_false_text", "\n", "self", ".", "video_only", "=", "video_only", "\n", "self", ".", "data_dir", "=", "data_dir", "\n", "if", "len", "(", "names", ")", "!=", "0", ":", "\n", "            ", "dataset_name", "=", "names", "[", "0", "]", ".", "split", "(", "'_'", ")", "[", "0", "]", "\n", "if", "dataset_name", "in", "[", "'tgif'", ",", "'tgifqa'", "]", ":", "\n", "                ", "dataset_name", "=", "'tgif'", "\n", "", "self", ".", "data_dir", "=", "os", ".", "path", ".", "join", "(", "self", ".", "data_dir", ",", "dataset_name", ")", "# e.g. webvid_train -> webvid", "\n", "split_name", "=", "dataset_name", "\n", "", "if", "torch", ".", "distributed", ".", "get_rank", "(", ")", "==", "0", ":", "\n", "            ", "print", "(", "'*'", "*", "100", ")", "\n", "print", "(", "\"video datasets: {}\"", ".", "format", "(", "names", ")", ")", "\n", "", "self", ".", "draw_options_text", "=", "draw_options_text", "\n", "self", ".", "num_frames", "=", "num_frames", "\n", "if", "torch", ".", "distributed", ".", "get_rank", "(", ")", "==", "0", ":", "\n", "            ", "print", "(", "\"# frames for base dataset is: {}\"", ".", "format", "(", "self", ".", "num_frames", ")", ")", "\n", "", "if", "split_name", "in", "[", "'msrvtt'", ",", "'cc3m'", ",", "'webvid'", ",", "'msvd'", ",", "'vcr'", ",", "'howto100m'", ",", "'ego4d'", ",", "'yttemporal'", ",", "'tgif'", ",", "'hmdb51'", ",", "'k400'", "]", ":", "\n", "            ", "if", "torch", ".", "distributed", ".", "get_rank", "(", ")", "==", "0", ":", "\n", "                ", "print", "(", "\"no arrow available for {}, load from disk\"", ".", "format", "(", "names", "[", "0", "]", ")", ")", "\n", "", "", "else", ":", "\n", "            ", "print", "(", "\"not support video dataset\"", ")", "\n", "", "self", ".", "video_transform", "=", "VideoTransform", "(", "mode", "=", "self", ".", "split", ",", "crop_size", "=", "image_size", ",", "backend", "=", "backend", ")", "\n", "self", ".", "video_aug", "=", "video_aug", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.video_base_dataset.BaseDataset.corpus": [[78, 81], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "corpus", "(", "self", ")", ":", "\n", "        ", "return", "[", "text", "for", "texts", "in", "self", ".", "all_texts", "for", "text", "in", "texts", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.video_base_dataset.BaseDataset.__len__": [[82, 84], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "metadata", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.video_base_dataset.BaseDataset.__getitem__": [[85, 87], ["video_base_dataset.BaseDataset.get_suite"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_v2.Ego4DDataset.get_suite"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "return", "self", ".", "get_suite", "(", "index", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.video_base_dataset.BaseDataset.get_raw_image": [[88, 93], ["io.BytesIO", "io.BytesIO.seek", "PIL.Image.open().convert", "[].as_py", "PIL.Image.open"], "methods", ["None"], ["", "def", "get_raw_image", "(", "self", ",", "index", ",", "image_key", "=", "\"image\"", ")", ":", "\n", "        ", "index", ",", "caption_index", "=", "self", ".", "index_mapper", "[", "index", "]", "\n", "image_bytes", "=", "io", ".", "BytesIO", "(", "self", ".", "table", "[", "image_key", "]", "[", "index", "]", ".", "as_py", "(", ")", ")", "\n", "image_bytes", ".", "seek", "(", "0", ")", "\n", "return", "Image", ".", "open", "(", "image_bytes", ")", ".", "convert", "(", "\"RGB\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.video_base_dataset.BaseDataset._get_video_path": [[94, 99], ["os.path.join", "os.path.join", "str", "str"], "methods", ["None"], ["", "def", "_get_video_path", "(", "self", ",", "sample", ")", ":", "\n", "        ", "if", "self", ".", "names", "[", "0", "]", "in", "[", "'msrvtt_train'", ",", "'msrvtt_test'", ",", "'msrvtt_val'", "]", ":", "\n", "            ", "return", "os", ".", "path", ".", "join", "(", "self", ".", "data_dir", ",", "'videos'", ",", "'all'", ",", "sample", ".", "name", "+", "'.mp4'", ")", ",", "sample", ".", "name", "+", "'.mp4'", "\n", "", "else", ":", "\n", "            ", "return", "os", ".", "path", ".", "join", "(", "self", ".", "data_dir", ",", "'videos'", ",", "'all'", ",", "str", "(", "sample", "[", "'video_id'", "]", ")", "+", "'.mp4'", ")", ",", "str", "(", "sample", "[", "'video_id'", "]", ")", "+", "'.mp4'", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.video_base_dataset.BaseDataset.get_raw_video": [[100, 107], ["video_base_dataset.BaseDataset._get_video_path", "video_base_dataset.read_frames_decord", "Exception"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_v2.Ego4DDataset._get_video_path", "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.base_dataset.read_frames_decord"], ["", "", "def", "get_raw_video", "(", "self", ",", "sample", ")", ":", "\n", "        ", "abs_fp", ",", "rel_fp", "=", "self", ".", "_get_video_path", "(", "sample", ")", "\n", "imgs", ",", "idxs", ",", "vlen", "=", "read_frames_decord", "(", "abs_fp", ",", "self", ".", "num_frames", ",", "mode", "=", "self", ".", "split", ")", "\n", "if", "imgs", "is", "None", ":", "\n", "            ", "raise", "Exception", "(", "\"Invalid img!\"", ",", "rel_fp", ")", "\n", "", "else", ":", "\n", "            ", "return", "imgs", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.video_base_dataset.BaseDataset.get_video": [[108, 112], ["video_base_dataset.BaseDataset.get_raw_video", "video_base_dataset.BaseDataset.video_aug"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_v2.Ego4DDataset.get_raw_video", "home.repos.pwc.inspect_result.showlab_all-in-one.video.videoaug.video_aug"], ["", "", "def", "get_video", "(", "self", ",", "sample", ")", ":", "\n", "        ", "videos", "=", "self", ".", "get_raw_video", "(", "sample", ")", "\n", "videos_tensor", "=", "self", ".", "video_aug", "(", "videos", ",", "self", ".", "video_transform", ")", "\n", "return", "videos_tensor", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.video_base_dataset.BaseDataset.get_false_video": [[113, 119], ["random.randint", "video_base_dataset.BaseDataset.get_raw_video", "video_base_dataset.BaseDataset.video_aug", "len"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_v2.Ego4DDataset.get_raw_video", "home.repos.pwc.inspect_result.showlab_all-in-one.video.videoaug.video_aug"], ["", "def", "get_false_video", "(", "self", ",", "rep", ")", ":", "\n", "        ", "random_index", "=", "random", ".", "randint", "(", "0", ",", "len", "(", "self", ".", "metadata", ")", "-", "1", ")", "\n", "sample", "=", "self", ".", "metadata", ".", "iloc", "[", "random_index", "]", "\n", "videos", "=", "self", ".", "get_raw_video", "(", "sample", ")", "\n", "videos_tensor", "=", "self", ".", "video_aug", "(", "videos", ",", "self", ".", "video_transform", ")", "\n", "return", "{", "f\"false_video_{rep}\"", ":", "videos_tensor", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.video_base_dataset.BaseDataset._get_caption": [[120, 126], ["random.choice"], "methods", ["None"], ["", "def", "_get_caption", "(", "self", ",", "sample", ")", ":", "\n", "        ", "if", "self", ".", "names", "[", "0", "]", "in", "[", "'msrvtt_train'", "]", ":", "\n", "            ", "caption", "=", "random", ".", "choice", "(", "sample", "[", "'captions'", "]", ")", "\n", "", "else", ":", "\n", "            ", "caption", "=", "sample", "[", "'captions'", "]", "[", "0", "]", "\n", "", "return", "caption", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.video_base_dataset.BaseDataset.get_text": [[127, 142], ["video_base_dataset.BaseDataset._get_caption", "video_base_dataset.BaseDataset.tokenizer"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.datasets.lsmdc_dataset.LSMDCDataset._get_caption"], ["", "def", "get_text", "(", "self", ",", "raw_index", ",", "sample", ")", ":", "\n", "        ", "text", "=", "self", ".", "_get_caption", "(", "sample", ")", "\n", "encoding", "=", "self", ".", "tokenizer", "(", "\n", "text", ",", "\n", "padding", "=", "\"max_length\"", ",", "\n", "truncation", "=", "True", ",", "\n", "max_length", "=", "self", ".", "max_text_len", ",", "\n", "return_special_tokens_mask", "=", "True", ",", "\n", ")", "\n", "# print(encoding.size())", "\n", "return", "{", "\n", "\"text\"", ":", "(", "text", ",", "encoding", ")", ",", "\n", "\"vid_index\"", ":", "raw_index", ",", "\n", "\"cap_index\"", ":", "raw_index", ",", "\n", "\"raw_index\"", ":", "raw_index", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.video_base_dataset.BaseDataset.get_false_text": [[144, 156], ["random.randint", "video_base_dataset.BaseDataset._get_caption", "video_base_dataset.BaseDataset.tokenizer", "len"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.datasets.lsmdc_dataset.LSMDCDataset._get_caption"], ["", "def", "get_false_text", "(", "self", ",", "rep", ")", ":", "\n", "        ", "random_index", "=", "random", ".", "randint", "(", "0", ",", "len", "(", "self", ".", "metadata", ")", "-", "1", ")", "\n", "sample", "=", "self", ".", "metadata", ".", "iloc", "[", "random_index", "]", "\n", "text", "=", "self", ".", "_get_caption", "(", "sample", ")", "\n", "encoding", "=", "self", ".", "tokenizer", "(", "\n", "text", ",", "\n", "# padding=\"max_length\",", "\n", "truncation", "=", "True", ",", "\n", "max_length", "=", "self", ".", "max_text_len", ",", "\n", "return_special_tokens_mask", "=", "True", ",", "\n", ")", "\n", "return", "{", "f\"false_text_{rep}\"", ":", "(", "text", ",", "encoding", ")", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.video_base_dataset.BaseDataset.get_suite": [[157, 185], ["video_base_dataset.BaseDataset.get_video", "range", "range", "video_base_dataset.BaseDataset.get_text", "ret.update", "ret.update", "ret.update", "ret.update", "print", "random.randint", "video_base_dataset.BaseDataset.get_false_video", "video_base_dataset.BaseDataset.get_false_text", "len"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_v2.Ego4DDataset.get_video", "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_v2.Ego4DDataset.get_text", "home.repos.pwc.inspect_result.showlab_all-in-one.gadgets.my_metrics.VQAScore.update", "home.repos.pwc.inspect_result.showlab_all-in-one.gadgets.my_metrics.VQAScore.update", "home.repos.pwc.inspect_result.showlab_all-in-one.gadgets.my_metrics.VQAScore.update", "home.repos.pwc.inspect_result.showlab_all-in-one.gadgets.my_metrics.VQAScore.update", "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_v2.Ego4DDataset.get_false_video", "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_v2.Ego4DDataset.get_false_text"], ["", "def", "get_suite", "(", "self", ",", "index", ")", ":", "\n", "        ", "result", "=", "None", "\n", "while", "result", "is", "None", ":", "\n", "# retry_times += 1", "\n", "            ", "sample", "=", "self", ".", "metadata", ".", "iloc", "[", "index", "]", "\n", "# print(sample[1])", "\n", "try", ":", "\n", "                ", "video_tensor", "=", "self", ".", "get_video", "(", "sample", ")", "\n", "ret", "=", "{", "\n", "\"video\"", ":", "video_tensor", ",", "\n", "\"vid_index\"", ":", "index", ",", "\n", "\"cap_index\"", ":", "index", ",", "\n", "\"raw_index\"", ":", "index", ",", "\n", "}", "\n", "if", "not", "self", ".", "video_only", ":", "\n", "                    ", "txt", "=", "self", ".", "get_text", "(", "index", ",", "sample", ")", "\n", "ret", ".", "update", "(", "{", "\"replica\"", ":", "True", "if", "txt", "[", "\"cap_index\"", "]", ">", "0", "else", "False", "}", ")", "\n", "ret", ".", "update", "(", "txt", ")", "\n", "\n", "", "for", "i", "in", "range", "(", "self", ".", "draw_false_video", ")", ":", "\n", "                    ", "ret", ".", "update", "(", "self", ".", "get_false_video", "(", "i", ")", ")", "\n", "", "for", "i", "in", "range", "(", "self", ".", "draw_false_text", ")", ":", "\n", "                    ", "ret", ".", "update", "(", "self", ".", "get_false_text", "(", "i", ")", ")", "\n", "", "result", "=", "True", "\n", "", "except", "Exception", "as", "e", ":", "\n", "                ", "print", "(", "f\"Error while read file idx {sample.name} in {self.names[0]} -> {e}\"", ")", "\n", "index", "=", "random", ".", "randint", "(", "0", ",", "len", "(", "self", ".", "metadata", ")", "-", "1", ")", "\n", "", "", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.video_base_dataset.BaseDataset.collate": [[186, 269], ["len", "set", "list", "len", "max", "max", "len", "range", "len", "len", "mlm_collator", "enumerate", "list", "len", "torch.zeros", "range", "list", "torch.zeros_like", "torch.zeros_like", "enumerate", "torch.full_like", "b.keys", "dict_batch.keys", "range", "dict_batch.keys", "torch.tensor", "torch.tensor", "len", "len"], "methods", ["None"], ["", "def", "collate", "(", "self", ",", "batch", ",", "mlm_collator", ")", ":", "\n", "        ", "batch_size", "=", "len", "(", "batch", ")", "\n", "keys", "=", "set", "(", "[", "key", "for", "b", "in", "batch", "for", "key", "in", "b", ".", "keys", "(", ")", "]", ")", "\n", "dict_batch", "=", "{", "k", ":", "[", "dic", "[", "k", "]", "if", "k", "in", "dic", "else", "None", "for", "dic", "in", "batch", "]", "for", "k", "in", "keys", "}", "\n", "\n", "video_keys", "=", "[", "k", "for", "k", "in", "list", "(", "dict_batch", ".", "keys", "(", ")", ")", "if", "\"video\"", "in", "k", "]", "\n", "video_sizes", "=", "list", "(", ")", "\n", "\n", "# global & local video", "\n", "for", "video_key", "in", "video_keys", ":", "\n", "            ", "video_sizes", "+=", "[", "ii", ".", "shape", "for", "i", "in", "dict_batch", "[", "video_key", "]", "if", "i", "is", "not", "None", "for", "ii", "in", "i", "]", "\n", "# print(global_video_sizes, local_video_sizes)", "\n", "\n", "", "for", "size", "in", "video_sizes", ":", "\n", "# print(size)", "\n", "            ", "assert", "(", "\n", "len", "(", "size", ")", "==", "4", "\n", ")", ",", "f\"Collate error, an video should be in shape of (T, N, H, W), instead of given {size}\"", "\n", "\n", "", "if", "len", "(", "video_keys", ")", "!=", "0", ":", "\n", "            ", "global_max_height", "=", "max", "(", "[", "i", "[", "2", "]", "for", "i", "in", "video_sizes", "]", ")", "\n", "global_max_width", "=", "max", "(", "[", "i", "[", "3", "]", "for", "i", "in", "video_sizes", "]", ")", "\n", "", "for", "video_key", "in", "video_keys", ":", "\n", "            ", "video", "=", "dict_batch", "[", "video_key", "]", "\n", "view_size", "=", "len", "(", "video", "[", "0", "]", ")", "\n", "# print(view_size)", "\n", "new_videos", "=", "[", "\n", "torch", ".", "zeros", "(", "batch_size", ",", "self", ".", "num_frames", ",", "3", ",", "global_max_height", ",", "global_max_width", ")", "\n", "for", "_", "in", "range", "(", "view_size", ")", "\n", "]", "\n", "# print(len(img))", "\n", "for", "bi", "in", "range", "(", "batch_size", ")", ":", "\n", "                ", "orig_batch", "=", "video", "[", "bi", "]", "\n", "for", "vi", "in", "range", "(", "view_size", ")", ":", "\n", "                    ", "if", "orig_batch", "is", "None", ":", "\n", "# new_videos[vi][bi] = None", "\n", "# modify by alex", "\n", "                        ", "continue", "\n", "", "else", ":", "\n", "                        ", "orig", "=", "video", "[", "bi", "]", "[", "vi", "]", "\n", "# print(orig.size())", "\n", "new_videos", "[", "vi", "]", "[", "bi", ",", ":", ",", ":", ",", ":", "orig", ".", "shape", "[", "-", "2", "]", ",", ":", "orig", ".", "shape", "[", "-", "1", "]", "]", "=", "orig", "\n", "\n", "", "", "", "dict_batch", "[", "video_key", "]", "=", "new_videos", "\n", "\n", "", "txt_keys", "=", "[", "k", "for", "k", "in", "list", "(", "dict_batch", ".", "keys", "(", ")", ")", "if", "\"text\"", "in", "k", "]", "\n", "# print(txt_keys)", "\n", "if", "len", "(", "txt_keys", ")", "!=", "0", ":", "\n", "            ", "texts", "=", "[", "[", "d", "[", "0", "]", "for", "d", "in", "dict_batch", "[", "txt_key", "]", "]", "for", "txt_key", "in", "txt_keys", "]", "\n", "encodings", "=", "[", "[", "d", "[", "1", "]", "for", "d", "in", "dict_batch", "[", "txt_key", "]", "]", "for", "txt_key", "in", "txt_keys", "]", "\n", "draw_text_len", "=", "len", "(", "encodings", ")", "\n", "flatten_encodings", "=", "[", "e", "for", "encoding", "in", "encodings", "for", "e", "in", "encoding", "]", "\n", "flatten_mlms", "=", "mlm_collator", "(", "flatten_encodings", ")", "\n", "\n", "for", "i", ",", "txt_key", "in", "enumerate", "(", "txt_keys", ")", ":", "\n", "                ", "texts", ",", "encodings", "=", "(", "\n", "[", "d", "[", "0", "]", "for", "d", "in", "dict_batch", "[", "txt_key", "]", "]", ",", "\n", "[", "d", "[", "1", "]", "for", "d", "in", "dict_batch", "[", "txt_key", "]", "]", ",", "\n", ")", "\n", "\n", "mlm_ids", ",", "mlm_labels", "=", "(", "\n", "flatten_mlms", "[", "\"input_ids\"", "]", "[", "batch_size", "*", "(", "i", ")", ":", "batch_size", "*", "(", "i", "+", "1", ")", "]", ",", "\n", "flatten_mlms", "[", "\"labels\"", "]", "[", "batch_size", "*", "(", "i", ")", ":", "batch_size", "*", "(", "i", "+", "1", ")", "]", ",", "\n", ")", "\n", "\n", "input_ids", "=", "torch", ".", "zeros_like", "(", "mlm_ids", ")", "\n", "attention_mask", "=", "torch", ".", "zeros_like", "(", "mlm_ids", ")", "\n", "for", "_i", ",", "encoding", "in", "enumerate", "(", "encodings", ")", ":", "\n", "                    ", "_input_ids", ",", "_attention_mask", "=", "(", "\n", "torch", ".", "tensor", "(", "encoding", "[", "\"input_ids\"", "]", ")", ",", "\n", "torch", ".", "tensor", "(", "encoding", "[", "\"attention_mask\"", "]", ")", ",", "\n", ")", "\n", "input_ids", "[", "_i", ",", ":", "len", "(", "_input_ids", ")", "]", "=", "_input_ids", "\n", "attention_mask", "[", "_i", ",", ":", "len", "(", "_attention_mask", ")", "]", "=", "_attention_mask", "\n", "\n", "", "dict_batch", "[", "txt_key", "]", "=", "texts", "\n", "dict_batch", "[", "f\"{txt_key}_ids\"", "]", "=", "input_ids", "\n", "dict_batch", "[", "f\"{txt_key}_labels\"", "]", "=", "torch", ".", "full_like", "(", "input_ids", ",", "-", "100", ")", "\n", "dict_batch", "[", "f\"{txt_key}_ids_mlm\"", "]", "=", "mlm_ids", "\n", "dict_batch", "[", "f\"{txt_key}_labels_mlm\"", "]", "=", "mlm_labels", "\n", "dict_batch", "[", "f\"{txt_key}_masks\"", "]", "=", "attention_mask", "\n", "\n", "", "", "return", "dict_batch", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.video_base_dataset.sample_frames": [[376, 392], ["min", "numpy.linspace().astype", "enumerate", "ranges.append", "numpy.linspace", "random.choice", "range"], "function", ["None"], ["", "", "def", "sample_frames", "(", "num_frames", ",", "vlen", ",", "sample", "=", "'rand'", ",", "fix_start", "=", "None", ")", ":", "\n", "    ", "acc_samples", "=", "min", "(", "num_frames", ",", "vlen", ")", "\n", "intervals", "=", "np", ".", "linspace", "(", "start", "=", "0", ",", "stop", "=", "vlen", ",", "num", "=", "acc_samples", "+", "1", ")", ".", "astype", "(", "int", ")", "\n", "ranges", "=", "[", "]", "\n", "for", "idx", ",", "interv", "in", "enumerate", "(", "intervals", "[", ":", "-", "1", "]", ")", ":", "\n", "        ", "ranges", ".", "append", "(", "(", "interv", ",", "intervals", "[", "idx", "+", "1", "]", "-", "1", ")", ")", "\n", "", "if", "sample", "==", "'rand'", ":", "\n", "        ", "frame_idxs", "=", "[", "random", ".", "choice", "(", "range", "(", "x", "[", "0", "]", ",", "x", "[", "1", "]", ")", ")", "for", "x", "in", "ranges", "]", "\n", "", "elif", "fix_start", "is", "not", "None", ":", "\n", "        ", "frame_idxs", "=", "[", "x", "[", "0", "]", "+", "fix_start", "for", "x", "in", "ranges", "]", "\n", "", "elif", "sample", "==", "'uniform'", ":", "\n", "        ", "frame_idxs", "=", "[", "(", "x", "[", "0", "]", "+", "x", "[", "1", "]", ")", "//", "2", "for", "x", "in", "ranges", "]", "\n", "", "else", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n", "", "return", "frame_idxs", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.video_base_dataset.read_frames_gif": [[394, 415], ["imageio.get_reader", "len", "video_base_dataset.sample_frames", "enumerate", "torch.stack", "cv2.cvtColor", "torch.from_numpy().byte", "frame.permute.permute", "torch.stack.append", "torch.from_numpy"], "function", ["home.repos.pwc.inspect_result.showlab_all-in-one.datasets.base_dataset.sample_frames"], ["", "def", "read_frames_gif", "(", "video_path", ",", "num_frames", ",", "mode", "=", "'train'", ",", "fix_start", "=", "None", ")", ":", "\n", "    ", "if", "mode", "==", "'train'", ":", "\n", "        ", "sample", "=", "'rand'", "\n", "", "else", ":", "\n", "        ", "sample", "=", "'uniform'", "\n", "", "gif", "=", "imageio", ".", "get_reader", "(", "video_path", ")", "\n", "vlen", "=", "len", "(", "gif", ")", "\n", "frame_idxs", "=", "sample_frames", "(", "num_frames", ",", "vlen", ",", "sample", "=", "sample", ",", "fix_start", "=", "fix_start", ")", "\n", "frames", "=", "[", "]", "\n", "for", "index", ",", "frame", "in", "enumerate", "(", "gif", ")", ":", "\n", "# for index in frame_idxs:", "\n", "        ", "if", "index", "in", "frame_idxs", ":", "\n", "            ", "frame", "=", "cv2", ".", "cvtColor", "(", "frame", ",", "cv2", ".", "COLOR_RGBA2RGB", ")", "\n", "frame", "=", "torch", ".", "from_numpy", "(", "frame", ")", ".", "byte", "(", ")", "\n", "# # (H x W x C) to (C x H x W)", "\n", "frame", "=", "frame", ".", "permute", "(", "2", ",", "0", ",", "1", ")", "\n", "# frame = Image.fromarray(frame)", "\n", "frames", ".", "append", "(", "frame", ")", "\n", "", "", "frames", "=", "torch", ".", "stack", "(", "frames", ")", "# .float() / 255", "\n", "# print(frames.size())", "\n", "return", "frames", ",", "frame_idxs", ",", "vlen", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.video_base_dataset.read_frames_cv2": [[417, 450], ["cv2.VideoCapture", "cv2.VideoCapture.isOpened", "int", "video_base_dataset.sample_frames", "torch.stack", "cv2.VideoCapture.release", "cv2.VideoCapture.get", "cv2.VideoCapture.set", "cv2.VideoCapture.read", "cv2.cvtColor", "torch.from_numpy().byte", "frame.permute.permute", "torch.stack.append", "success_idxs.append", "torch.from_numpy"], "function", ["home.repos.pwc.inspect_result.showlab_all-in-one.datasets.base_dataset.sample_frames"], ["", "def", "read_frames_cv2", "(", "video_path", ",", "num_frames", ",", "sample", "=", "'rand'", ",", "fix_start", "=", "None", ")", ":", "\n", "# print(video_path)", "\n", "    ", "cap", "=", "cv2", ".", "VideoCapture", "(", "video_path", ")", "\n", "assert", "(", "cap", ".", "isOpened", "(", ")", ")", "\n", "# for decord", "\n", "# cap.set(3, 256)", "\n", "# cap.set(4, 256)", "\n", "vlen", "=", "int", "(", "cap", ".", "get", "(", "cv2", ".", "CAP_PROP_FRAME_COUNT", ")", ")", "\n", "# get indexes of sampled frames", "\n", "frame_idxs", "=", "sample_frames", "(", "num_frames", ",", "vlen", ",", "sample", "=", "sample", ",", "fix_start", "=", "fix_start", ")", "\n", "frames", "=", "[", "]", "\n", "success_idxs", "=", "[", "]", "\n", "for", "index", "in", "frame_idxs", ":", "\n", "        ", "cap", ".", "set", "(", "cv2", ".", "CAP_PROP_POS_FRAMES", ",", "index", "-", "1", ")", "\n", "ret", ",", "frame", "=", "cap", ".", "read", "(", ")", "\n", "if", "ret", ":", "\n", "            ", "frame", "=", "cv2", ".", "cvtColor", "(", "frame", ",", "cv2", ".", "COLOR_BGR2RGB", ")", "\n", "frame", "=", "torch", ".", "from_numpy", "(", "frame", ")", ".", "byte", "(", ")", "\n", "# # (H x W x C) to (C x H x W)", "\n", "frame", "=", "frame", ".", "permute", "(", "2", ",", "0", ",", "1", ")", "\n", "# frame = Image.fromarray(frame)", "\n", "frames", ".", "append", "(", "frame", ")", "\n", "success_idxs", ".", "append", "(", "index", ")", "\n", "", "else", ":", "\n", "            ", "pass", "\n", "# print(frame_idxs, ' fail ', index, f'  (vlen {vlen})')", "\n", "# return frames tensor", "\n", "# convert cv to PIL", "\n", "# img = Image.fromarray(imgs[0])", "\n", "", "", "frames", "=", "torch", ".", "stack", "(", "frames", ")", "# .float() / 255", "\n", "# print(frames.size())", "\n", "cap", ".", "release", "(", ")", "\n", "return", "frames", ",", "success_idxs", ",", "vlen", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.video_base_dataset.read_frames_decord": [[452, 466], ["decord.VideoReader", "decord.bridge.set_bridge", "len", "video_base_dataset.sample_frames", "decord.VideoReader.get_batch().byte", "frames.permute.permute", "decord.cpu", "decord.VideoReader.get_batch"], "function", ["home.repos.pwc.inspect_result.showlab_all-in-one.datasets.base_dataset.sample_frames"], ["", "def", "read_frames_decord", "(", "video_path", ",", "num_frames", ",", "mode", "=", "'train'", ",", "fix_start", "=", "None", ")", ":", "\n", "# print(\"video path: {}\".format(video_path))", "\n", "    ", "if", "mode", "in", "[", "'train'", ",", "'val'", "]", ":", "\n", "        ", "sample", "=", "'rand'", "\n", "", "else", ":", "\n", "        ", "sample", "=", "'uniform'", "\n", "", "video_reader", "=", "decord", ".", "VideoReader", "(", "video_path", ",", "width", "=", "512", ",", "height", "=", "512", ",", "num_threads", "=", "1", ",", "ctx", "=", "cpu", "(", "0", ")", ")", "\n", "# video_reader = decord.VideoReader(video_path, width=256, height=256, num_threads=1, ctx=cpu(0))", "\n", "decord", ".", "bridge", ".", "set_bridge", "(", "'torch'", ")", "\n", "vlen", "=", "len", "(", "video_reader", ")", "\n", "frame_idxs", "=", "sample_frames", "(", "num_frames", ",", "vlen", ",", "sample", "=", "sample", ",", "fix_start", "=", "fix_start", ")", "\n", "frames", "=", "video_reader", ".", "get_batch", "(", "frame_idxs", ")", ".", "byte", "(", ")", "\n", "frames", "=", "frames", ".", "permute", "(", "0", ",", "3", ",", "1", ",", "2", ")", "\n", "return", "frames", ",", "frame_idxs", ",", "vlen", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.video_base_dataset.read_frames_from_img_dir": [[468, 483], ["len", "video_base_dataset.sample_frames", "frames.permute.permute", "os.listdir", "cv2.imread", "torch.from_numpy().byte", "frame.permute.permute", "frames.permute.append", "os.path.join", "torch.from_numpy", "string().zfill", "string"], "function", ["home.repos.pwc.inspect_result.showlab_all-in-one.datasets.base_dataset.sample_frames"], ["", "def", "read_frames_from_img_dir", "(", "video_path", ",", "num_frames", ",", "mode", "=", "'train'", ",", "fix_start", "=", "None", ",", "suffix", "=", "'.jpg'", ")", ":", "\n", "    ", "if", "mode", "in", "[", "'train'", ",", "'val'", "]", ":", "\n", "        ", "sample", "=", "'rand'", "\n", "", "else", ":", "\n", "        ", "sample", "=", "'uniform'", "\n", "", "vlen", "=", "len", "(", "os", ".", "listdir", "(", "video_path", ")", ")", "\n", "frame_idxs", "=", "sample_frames", "(", "num_frames", ",", "vlen", ",", "sample", "=", "sample", ",", "fix_start", "=", "fix_start", ")", "\n", "frames", "=", "[", "]", "\n", "for", "idx", "in", "frame_idxs", ":", "\n", "        ", "frame", "=", "cv2", ".", "imread", "(", "os", ".", "path", ".", "join", "(", "video_path", ",", "string", "(", "idx", ")", ".", "zfill", "(", "3", ")", "+", "suffix", ")", ")", "\n", "frame", "=", "torch", ".", "from_numpy", "(", "frame", ")", ".", "byte", "(", ")", "\n", "frame", "=", "frame", ".", "permute", "(", "2", ",", "0", ",", "1", ")", "\n", "frames", ".", "append", "(", "frame", ")", "\n", "", "frames", "=", "frames", ".", "permute", "(", "0", ",", "3", ",", "1", ",", "2", ")", "\n", "return", "frames", ",", "frame_idxs", ",", "vlen", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.video_base_dataset.sample_frames_2": [[485, 489], ["None"], "function", ["None"], ["", "def", "sample_frames_2", "(", "frame_loc", ",", "vlen", ",", "frame_end", ")", ":", "\n", "    ", "assert", "frame_loc", "<=", "frame_end", "\n", "frame_idxs", "=", "[", "frame_loc", "]", "\n", "return", "frame_idxs", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.video_base_dataset.read_large_frames_decord": [[491, 515], ["decord.VideoReader", "decord.bridge.set_bridge", "video_base_dataset.sample_frames", "range", "decord.VideoReader.get_batch().byte", "frames.permute.permute", "len", "min", "max", "decord.cpu", "decord.VideoReader.get_batch"], "function", ["home.repos.pwc.inspect_result.showlab_all-in-one.datasets.base_dataset.sample_frames"], ["", "def", "read_large_frames_decord", "(", "video_path", ",", "frame_loc", ",", "frame_end", ",", "num_frames", ",", "mode", "=", "'train'", ",", "fix_start", "=", "None", ")", ":", "\n", "# print('*'*100)", "\n", "# print(mode)", "\n", "    ", "if", "mode", "==", "'train'", ":", "\n", "        ", "sample", "=", "'rand'", "\n", "", "else", ":", "\n", "        ", "sample", "=", "'uniform'", "\n", "# video_reader = decord.VideoReader(video_path, width=256, height=256, num_threads=1, ctx=cpu(0))", "\n", "", "video_reader", "=", "decord", ".", "VideoReader", "(", "video_path", ",", "width", "=", "512", ",", "height", "=", "512", ",", "num_threads", "=", "1", ",", "ctx", "=", "cpu", "(", "0", ")", ")", "\n", "decord", ".", "bridge", ".", "set_bridge", "(", "'torch'", ")", "\n", "# vlen = len(video_reader)", "\n", "frame_idxs", "=", "sample_frames", "(", "num_frames", ",", "120", ",", "sample", "=", "sample", ",", "fix_start", "=", "fix_start", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "frame_idxs", ")", ")", ":", "\n", "# if random.random() < 0.5:", "\n", "#     frame_idxs[i] += frame_loc - 60", "\n", "# else:", "\n", "#     frame_idxs[i] += frame_loc", "\n", "        ", "frame_idxs", "[", "i", "]", "+=", "frame_loc", "-", "60", "\n", "frame_idxs", "[", "i", "]", "=", "min", "(", "frame_idxs", "[", "i", "]", ",", "frame_end", "-", "1", ")", "\n", "frame_idxs", "[", "i", "]", "=", "max", "(", "0", ",", "frame_idxs", "[", "i", "]", ")", "\n", "# print(frame_loc, frame_end, frame_idxs)", "\n", "", "frames", "=", "video_reader", ".", "get_batch", "(", "frame_idxs", ")", ".", "byte", "(", ")", "\n", "frames", "=", "frames", ".", "permute", "(", "0", ",", "3", ",", "1", ",", "2", ")", "\n", "return", "frames", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.video_base_dataset.video_clip_reader": [[517, 552], ["cv2.VideoCapture", "int", "video_base_dataset.sample_frames", "int", "max", "min", "torch.stack", "cv2.VideoCapture.release", "cv2.VideoCapture.get", "int", "cv2.VideoCapture.set", "cv2.VideoCapture.read", "torch.cat.size", "torch.ones().byte", "torch.cat", "torch.cat.size", "Exception", "cv2.cvtColor", "torch.from_numpy().byte", "frame.permute.permute", "torch.cat.append", "success_idxs.append", "torch.ones", "torch.from_numpy", "torch.cat.size", "torch.cat.size", "torch.cat.size"], "function", ["home.repos.pwc.inspect_result.showlab_all-in-one.datasets.base_dataset.sample_frames"], ["", "def", "video_clip_reader", "(", "video_path", ",", "begin_time", ",", "end_time", ",", "duration", ",", "num_frames", ")", ":", "\n", "    ", "cap", "=", "cv2", ".", "VideoCapture", "(", "video_path", ")", "\n", "# assert (cap.isOpened())", "\n", "vlen", "=", "int", "(", "cap", ".", "get", "(", "cv2", ".", "CAP_PROP_FRAME_COUNT", ")", ")", "\n", "# print(video_path, begin_time, end_time, duration, num_frames, vlen)", "\n", "average_fps", "=", "vlen", "/", "duration", "\n", "clip_len", "=", "(", "end_time", "-", "begin_time", ")", "*", "average_fps", "\n", "frame_idxs", "=", "sample_frames", "(", "num_frames", ",", "int", "(", "clip_len", ")", ",", "sample", "=", "'rand'", ")", "\n", "frames", "=", "[", "]", "\n", "success_idxs", "=", "[", "]", "\n", "rel_index", "=", "int", "(", "begin_time", "*", "average_fps", ")", "\n", "rel_index", "=", "max", "(", "rel_index", ",", "0", ")", "\n", "rel_index", "=", "min", "(", "rel_index", ",", "vlen", "-", "1", ")", "\n", "for", "index", "in", "frame_idxs", ":", "\n", "        ", "cap", ".", "set", "(", "cv2", ".", "CAP_PROP_POS_FRAMES", ",", "rel_index", "+", "index", ")", "\n", "ret", ",", "frame", "=", "cap", ".", "read", "(", ")", "\n", "if", "ret", ":", "\n", "            ", "frame", "=", "cv2", ".", "cvtColor", "(", "frame", ",", "cv2", ".", "COLOR_BGR2RGB", ")", "\n", "frame", "=", "torch", ".", "from_numpy", "(", "frame", ")", ".", "byte", "(", ")", "\n", "# # (H x W x C) to (C x H x W)", "\n", "frame", "=", "frame", ".", "permute", "(", "2", ",", "0", ",", "1", ")", "\n", "# frame = Image.fromarray(frame)", "\n", "frames", ".", "append", "(", "frame", ")", "\n", "success_idxs", ".", "append", "(", "index", ")", "\n", "", "else", ":", "\n", "            ", "pass", "\n", "# print(frame_idxs, ' fail ', index, f'  (vlen {vlen})')", "\n", "", "", "frames", "=", "torch", ".", "stack", "(", "frames", ")", "\n", "cap", ".", "release", "(", ")", "\n", "if", "frames", ".", "size", "(", "0", ")", "<", "num_frames", ":", "\n", "        ", "zeros", "=", "torch", ".", "ones", "(", "(", "num_frames", "-", "frames", ".", "size", "(", "1", ")", ",", "3", ",", "frames", ".", "size", "(", "-", "2", ")", ",", "frames", ".", "size", "(", "-", "1", ")", ")", ",", "dtype", "=", "torch", ".", "uint8", ")", ".", "byte", "(", ")", "\n", "frames", "=", "torch", ".", "cat", "(", "(", "frames", ",", "zeros", ")", ",", "axis", "=", "1", ")", "\n", "", "if", "frames", ".", "size", "(", "0", ")", "!=", "num_frames", ":", "\n", "        ", "Exception", "(", "RuntimeError", ")", "\n", "", "return", "frames", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.video_base_dataset.video_reader": [[554, 587], ["cv2.VideoCapture", "cv2.VideoCapture.isOpened", "int", "video_base_dataset.sample_frames", "torch.stack", "cv2.VideoCapture.release", "cv2.VideoCapture.get", "max", "min", "cv2.VideoCapture.set", "cv2.VideoCapture.read", "random.random", "cv2.cvtColor", "torch.from_numpy().byte", "frame.permute.permute", "torch.stack.append", "success_idxs.append", "torch.from_numpy"], "function", ["home.repos.pwc.inspect_result.showlab_all-in-one.datasets.base_dataset.sample_frames"], ["", "def", "video_reader", "(", "video_path", ",", "frame_loc", ",", "frame_end", ",", "num_frames", ")", ":", "\n", "    ", "cap", "=", "cv2", ".", "VideoCapture", "(", "video_path", ")", "\n", "assert", "(", "cap", ".", "isOpened", "(", ")", ")", "\n", "vlen", "=", "int", "(", "cap", ".", "get", "(", "cv2", ".", "CAP_PROP_FRAME_COUNT", ")", ")", "\n", "# get indexes of sampled frames fps is 30, 4s", "\n", "frame_idxs", "=", "sample_frames", "(", "num_frames", ",", "120", ",", "sample", "=", "'rand'", ")", "\n", "# frame_idxs = sample_frames_2(frame_loc, vlen, frame_end)", "\n", "frames", "=", "[", "]", "\n", "success_idxs", "=", "[", "]", "\n", "\n", "for", "index", "in", "frame_idxs", ":", "\n", "        ", "if", "random", ".", "random", "(", ")", "<", "0.5", ":", "\n", "            ", "rel_index", "=", "index", "+", "frame_loc", "-", "120", "\n", "", "else", ":", "\n", "            ", "rel_index", "=", "index", "+", "frame_loc", "\n", "", "rel_index", "=", "max", "(", "rel_index", ",", "0", ")", "\n", "rel_index", "=", "min", "(", "rel_index", ",", "frame_end", ")", "\n", "cap", ".", "set", "(", "cv2", ".", "CAP_PROP_POS_FRAMES", ",", "rel_index", ")", "\n", "ret", ",", "frame", "=", "cap", ".", "read", "(", ")", "\n", "if", "ret", ":", "\n", "            ", "frame", "=", "cv2", ".", "cvtColor", "(", "frame", ",", "cv2", ".", "COLOR_BGR2RGB", ")", "\n", "frame", "=", "torch", ".", "from_numpy", "(", "frame", ")", ".", "byte", "(", ")", "\n", "# # (H x W x C) to (C x H x W)", "\n", "frame", "=", "frame", ".", "permute", "(", "2", ",", "0", ",", "1", ")", "\n", "# frame = Image.fromarray(frame)", "\n", "frames", ".", "append", "(", "frame", ")", "\n", "success_idxs", ".", "append", "(", "index", ")", "\n", "", "else", ":", "\n", "            ", "pass", "\n", "# print(frame_idxs, ' fail ', index, f'  (vlen {vlen})')", "\n", "", "", "frames", "=", "torch", ".", "stack", "(", "frames", ")", "\n", "cap", ".", "release", "(", ")", "\n", "return", "frames", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.video_base_dataset.fast_decode": [[589, 632], ["cv2.VideoCapture", "int", "cv2.VideoCapture.release", "random.randint", "ffmpeg.input().filter", "cmd.hflip.output().run", "numpy.frombuffer().reshape", "torch.from_numpy", "video.permute.permute", "cv2.VideoCapture.get", "float", "int", "cmd.hflip.crop", "cmd.hflip.crop().filter", "cmd.hflip.hflip", "max", "ffmpeg.input", "random.uniform", "random.uniform", "str", "str", "random.uniform", "cmd.hflip.output", "numpy.frombuffer", "cmd.hflip.crop"], "function", ["None"], ["", "def", "fast_decode", "(", "video_path", ",", "num_frames", ",", "mode", "=", "'train'", ",", "fix_start", "=", "None", ",", "fps", "=", "30", ")", ":", "\n", "    ", "cap", "=", "cv2", ".", "VideoCapture", "(", "video_path", ")", "\n", "vlen", "=", "int", "(", "cap", ".", "get", "(", "cv2", ".", "CAP_PROP_FRAME_COUNT", ")", ")", "\n", "cap", ".", "release", "(", ")", "\n", "max_len", "=", "vlen", "/", "30", "\n", "num_sec", "=", "num_frames", "/", "float", "(", "fps", ")", "\n", "size", "=", "224", "\n", "crop_only", "=", "True", "\n", "random_flip", "=", "True", "\n", "start_seek", "=", "random", ".", "randint", "(", "0", ",", "int", "(", "max", "(", "max_len", ",", "max_len", "-", "num_sec", ")", ")", ")", "\n", "cmd", "=", "(", "\n", "ffmpeg", "\n", ".", "input", "(", "video_path", ",", "ss", "=", "start_seek", ",", "t", "=", "num_sec", "+", "0.1", ")", "\n", ".", "filter", "(", "'fps'", ",", "fps", "=", "fps", ")", "\n", ")", "\n", "if", "mode", "==", "'train'", ":", "\n", "        ", "aw", ",", "ah", "=", "random", ".", "uniform", "(", "0", ",", "1", ")", ",", "random", ".", "uniform", "(", "0", ",", "1", ")", "\n", "", "else", ":", "\n", "        ", "aw", ",", "ah", "=", "0.5", ",", "0.5", "\n", "", "if", "crop_only", ":", "\n", "        ", "cmd", "=", "(", "\n", "cmd", ".", "crop", "(", "'(iw - {})*{}'", ".", "format", "(", "size", ",", "aw", ")", ",", "\n", "'(ih - {})*{}'", ".", "format", "(", "size", ",", "ah", ")", ",", "\n", "str", "(", "size", ")", ",", "str", "(", "size", ")", ")", "\n", ")", "\n", "", "else", ":", "\n", "        ", "cmd", "=", "(", "\n", "cmd", ".", "crop", "(", "'(iw - min(iw,ih))*{}'", ".", "format", "(", "aw", ")", ",", "\n", "'(ih - min(iw,ih))*{}'", ".", "format", "(", "ah", ")", ",", "\n", "'min(iw,ih)'", ",", "\n", "'min(iw,ih)'", ")", "\n", ".", "filter", "(", "'scale'", ",", "size", ",", "size", ")", "\n", ")", "\n", "", "if", "random_flip", "and", "random", ".", "uniform", "(", "0", ",", "1", ")", ">", "0.5", ":", "\n", "        ", "cmd", "=", "cmd", ".", "hflip", "(", ")", "\n", "", "out", ",", "_", "=", "(", "\n", "cmd", ".", "output", "(", "'pipe:'", ",", "format", "=", "'rawvideo'", ",", "pix_fmt", "=", "'rgb24'", ")", "\n", ".", "run", "(", "capture_stdout", "=", "True", ",", "quiet", "=", "True", ")", "\n", ")", "\n", "video", "=", "np", ".", "frombuffer", "(", "out", ",", "np", ".", "uint8", ")", ".", "reshape", "(", "[", "-", "1", ",", "size", ",", "size", ",", "3", "]", ")", "\n", "video", "=", "torch", ".", "from_numpy", "(", "video", ")", "\n", "video", "=", "video", ".", "permute", "(", "3", ",", "0", ",", "1", ",", "2", ")", "\n", "return", "video", ",", "_", ",", "_", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.video_base_dataset.color_img": [[645, 674], ["range", "len", "cv2.addWeighted", "cv2.rectangle", "boxes.append", "numpy.ones", "int", "int", "int", "int", "int", "int", "int", "int", "int", "int", "int", "int"], "function", ["None"], ["def", "color_img", "(", "im", ",", "object_meta", ",", "relevant_dets", ",", "only_use_relevant_dets", "=", "True", ")", ":", "\n", "# mask detected region", "\n", "# only_use_relevant_dets: if true, we only mask regions that mentioned in question & answers", "\n", "# print(relevant_dets)", "\n", "    ", "if", "only_use_relevant_dets", ":", "\n", "        ", "boxes", "=", "[", "]", "\n", "for", "index", "in", "relevant_dets", ":", "\n", "            ", "boxes", ".", "append", "(", "object_meta", "[", "'boxes'", "]", "[", "index", "]", ")", "\n", "# print(object_meta['names'][index])", "\n", "# object_index = relevant_dets", "\n", "", "", "else", ":", "\n", "        ", "boxes", "=", "object_meta", "[", "'boxes'", "]", "\n", "# print(len(boxes))", "\n", "# range(len(boxes))", "\n", "", "for", "i", "in", "range", "(", "len", "(", "boxes", ")", ")", ":", "\n", "        ", "if", "i", ">", "20", ":", "\n", "            ", "break", "\n", "", "bbox", "=", "boxes", "[", "i", "]", "\n", "# white_rect = cv2.applyColorMap(white_rect, i)", "\n", "# only considering bounding box here (wo fine-grained segmentation)", "\n", "sub_img", "=", "im", "[", "int", "(", "bbox", "[", "1", "]", ")", ":", "int", "(", "bbox", "[", "3", "]", ")", ",", "int", "(", "bbox", "[", "0", "]", ")", ":", "int", "(", "bbox", "[", "2", "]", ")", "]", "\n", "white_rect", "=", "np", ".", "ones", "(", "sub_img", ".", "shape", ",", "dtype", "=", "np", ".", "uint8", ")", "*", "255", "\n", "white_rect", "[", ":", ",", ":", ",", "0", "]", "=", "colormaps", "[", "i", "]", "[", "0", "]", "\n", "white_rect", "[", ":", ",", ":", ",", "1", "]", "=", "colormaps", "[", "i", "]", "[", "1", "]", "\n", "white_rect", "[", ":", ",", ":", ",", "2", "]", "=", "colormaps", "[", "i", "]", "[", "2", "]", "\n", "res", "=", "cv2", ".", "addWeighted", "(", "sub_img", ",", "0.7", ",", "white_rect", ",", "0.3", ",", "1.0", ")", "\n", "im", "[", "int", "(", "bbox", "[", "1", "]", ")", ":", "int", "(", "bbox", "[", "3", "]", ")", ",", "int", "(", "bbox", "[", "0", "]", ")", ":", "int", "(", "bbox", "[", "2", "]", ")", "]", "=", "res", "\n", "cv2", ".", "rectangle", "(", "im", ",", "(", "int", "(", "bbox", "[", "0", "]", ")", ",", "int", "(", "bbox", "[", "1", "]", ")", ")", ",", "(", "int", "(", "bbox", "[", "2", "]", ")", ",", "int", "(", "bbox", "[", "3", "]", ")", ")", ",", "colormaps", "[", "i", "]", ",", "3", ")", "\n", "", "return", "im", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.video_base_dataset.get_video_len": [[676, 681], ["cv2.VideoCapture", "int", "cv2.VideoCapture.release", "cv2.VideoCapture.get"], "function", ["None"], ["", "def", "get_video_len", "(", "video_src", ")", ":", "\n", "    ", "cap", "=", "cv2", ".", "VideoCapture", "(", "video_src", ")", "\n", "vlen", "=", "int", "(", "cap", ".", "get", "(", "cv2", ".", "CAP_PROP_FRAME_COUNT", ")", ")", "\n", "cap", ".", "release", "(", ")", "\n", "return", "vlen", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.video_base_dataset.align_using_dtw": [[683, 728], ["int", "enumerate", "tslearn.metrics.dtw_path_from_metric", "max", "len", "len", "numpy.zeros", "x.translate().strip().lower", "video_base_dataset.align_using_dtw._preprocess_text"], "function", ["None"], ["", "def", "align_using_dtw", "(", "input_asr", ",", "grover_output", ",", "radius_perc", "=", "0.1", ",", "radius_abs", "=", "32", ")", ":", "\n", "  ", "\"\"\"\n  :param input_asr: List of words\n  :param grover_output: List of words also, could be different size\n  :param radius_perc: Percent of input ASR\n  :param radius_abs: Absolute ntokens\n  :return:\n  \"\"\"", "\n", "max_radius", "=", "int", "(", "max", "(", "len", "(", "input_asr", ")", "*", "radius_perc", ",", "radius_abs", ")", ")", "\n", "# sometimes grover just keeps going", "\n", "if", "len", "(", "grover_output", ")", ">", "len", "(", "input_asr", ")", ":", "\n", "    ", "grover_output", "=", "grover_output", "[", ":", "len", "(", "input_asr", ")", "+", "max_radius", "]", "\n", "\n", "# DONT give the alignment freedom if it's at the end of a sequence to just \"give up\" by padding with zeros", "\n", "# Default value is high", "\n", "", "auto2other", "=", "np", ".", "zeros", "(", "(", "len", "(", "input_asr", ")", ",", "len", "(", "grover_output", ")", ")", ",", "dtype", "=", "np", ".", "float32", ")", "+", "9999.0", "\n", "\n", "def", "_preprocess_text", "(", "x", ")", ":", "\n", "    ", "return", "x", ".", "translate", "(", "str", ".", "maketrans", "(", "''", ",", "''", ",", "string", ".", "punctuation", ")", ")", ".", "strip", "(", ")", ".", "lower", "(", ")", "\n", "\n", "", "input_asr_pre", "=", "[", "_preprocess_text", "(", "x", ")", "for", "x", "in", "input_asr", "]", "\n", "input_gro_pre", "=", "[", "_preprocess_text", "(", "x", ")", "for", "x", "in", "grover_output", "]", "\n", "for", "a_idx", ",", "a", "in", "enumerate", "(", "input_asr_pre", ")", ":", "\n", "    ", "start", "=", "max", "(", "a_idx", "-", "max_radius", ",", "0", ")", "\n", "end", "=", "min", "(", "a_idx", "+", "max_radius", ",", "len", "(", "input_gro_pre", ")", ")", "\n", "for", "o_idx", "in", "range", "(", "start", ",", "end", ")", ":", "\n", "      ", "o", "=", "input_gro_pre", "[", "o_idx", "]", "\n", "auto2other", "[", "a_idx", ",", "o_idx", "]", "=", "editdistance", ".", "eval", "(", "a", ",", "o", ")", "\n", "\n", "", "", "idxs", ",", "score", "=", "tslearn", ".", "metrics", ".", "dtw_path_from_metric", "(", "auto2other", ",", "metric", "=", "'precomputed'", ")", "\n", "denoised_out", "=", "[", "[", "]", "for", "x", "in", "input_asr", "]", "\n", "has_seen", "=", "-", "1", "\n", "for", "idx1", ",", "idx2", "in", "idxs", ":", "\n", "    ", "if", "(", "idx1", ">=", "len", "(", "input_asr", ")", ")", "or", "(", "idx2", ">=", "len", "(", "grover_output", ")", ")", ":", "\n", "      ", "break", "\n", "", "if", "idx2", ">", "has_seen", ":", "\n", "# Basically don't add if it's a duplicate -- a grover output that matches to 2 things", "\n", "# This often leads to slightly weird results because we really should match the next thing, but we instead matched the first thing", "\n", "# e.g.", "\n", "# input_asr_pre = ['much', 'of', 'a', 'pancake', 'waffle', 'person', 'so', 'i', 'love', 'a']", "\n", "# input_gro_pre = ['much', 'of', 'a', 'pancakewaffle', 'person', 'so', 'i', 'love', 'a', 'good']", "\n", "# but we align pancakewaffle-> pancake and person -> waffle AND person -> person", "\n", "      ", "denoised_out", "[", "idx1", "]", ".", "append", "(", "grover_output", "[", "idx2", "]", ")", "\n", "", "has_seen", "=", "idx2", "\n", "", "return", "[", "' '", ".", "join", "(", "x", ")", "for", "x", "in", "denoised_out", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.video_base_dataset.clean_subtitles": [[730, 746], ["ftfy.ftfy", "new_dicts.append", "x[].startswith", "x[].endswith", "len"], "function", ["None"], ["", "def", "clean_subtitles", "(", "subtitle_dicts", ")", ":", "\n", "  ", "\"\"\"\n  :param subtitle_dicts: {'word': X, 'time': Y}\n  :return:\n  \"\"\"", "\n", "# Remove &gt;&gt; maybe using ftfy or something", "\n", "new_dicts", "=", "[", "]", "\n", "for", "x", "in", "subtitle_dicts", ":", "\n", "    ", "if", "x", "[", "'word'", "]", ".", "startswith", "(", "'&'", ")", "or", "x", "[", "'word'", "]", ".", "endswith", "(", "';'", ")", ":", "\n", "      ", "continue", "\n", "", "fixed_word", "=", "ftfy", ".", "ftfy", "(", "x", "[", "'word'", "]", ")", "\n", "if", "len", "(", "fixed_word", ")", "==", "0", ":", "\n", "      ", "continue", "\n", "", "x", "[", "'word'", "]", "=", "fixed_word", "\n", "new_dicts", ".", "append", "(", "x", ")", "\n", "", "return", "new_dicts", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.video_base_dataset.clean_description": [[748, 765], ["demoji.findall", "demoji.findall.items", "text.replace.strip", "regex.sub", "regex.sub", "regex.sub", "text.replace.strip", "text.replace.replace"], "function", ["None"], ["", "def", "clean_description", "(", "text", ")", ":", "\n", "# Strip emojis first", "\n", "  ", "all_emojis", "=", "demoji", ".", "findall", "(", "text", ")", "\n", "for", "k", ",", "v", "in", "all_emojis", ".", "items", "(", ")", ":", "\n", "    ", "text", "=", "text", ".", "replace", "(", "k", ",", "f'[{v}]'", ".", "replace", "(", "' '", ",", "''", ")", ")", "\n", "", "text", "=", "text", ".", "strip", "(", ")", "\n", "\n", "# Remove URLs", "\n", "# https://stackoverflow.com/questions/11331982/how-to-remove-any-url-within-a-string-in-python/11332580", "\n", "text", "=", "re", ".", "sub", "(", "\n", "r'''(?i)\\b((?:https?://|www\\d{0,3}[.]|[a-z0-9.\\-]+[.][a-z]{2,4}/)(?:[^\\s()<>]+|\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\))+(?:\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\)|[^\\s`!()\\[\\]{};:'\".,<>?\u00ab\u00bb\u201c\u201d\u2018\u2019]))'''", ",", "\n", "\"%\"", ",", "text", ")", "\n", "\n", "text", "=", "re", ".", "sub", "(", "' +'", ",", "' '", ",", "text", ")", "# Probably should have done", "\n", "text", "=", "re", ".", "sub", "(", "'\\s*\\n+'", ",", "'\\n'", ",", "text", ")", "\n", "text", "=", "text", ".", "strip", "(", ")", "\n", "return", "text", "", "", ""]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.ego4d.Ego4DDataset.__init__": [[12, 25], ["video_base_dataset.BaseDataset.__init__", "ego4d.Ego4DDataset._load_metadata"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.transforms.utils.UnNormalize.__init__", "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_v2.Ego4DDataset._load_metadata"], ["def", "__init__", "(", "self", ",", "*", "args", ",", "split", "=", "\"\"", ",", "**", "kwargs", ")", ":", "\n", "        ", "assert", "split", "in", "[", "\"train\"", ",", "\"val\"", ",", "\"test\"", "]", "\n", "self", ".", "split", "=", "split", "\n", "\n", "if", "split", "==", "\"train\"", ":", "\n", "            ", "names", "=", "[", "\"ego4d_train\"", "]", "\n", "", "elif", "split", "==", "\"val\"", ":", "\n", "            ", "names", "=", "[", "\"ego4d_val\"", "]", "\n", "", "elif", "split", "==", "\"test\"", ":", "\n", "            ", "names", "=", "[", "\"ego4d_test\"", "]", "\n", "", "super", "(", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ",", "names", "=", "names", ",", "text_column_name", "=", "\"caption\"", ")", "\n", "\n", "self", ".", "_load_metadata", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.ego4d.Ego4DDataset._load_metadata": [[26, 35], ["pandas.read_csv", "os.path.join"], "methods", ["None"], ["", "def", "_load_metadata", "(", "self", ")", ":", "\n", "        ", "metadata_dir", "=", "'./meta_data/ego4d'", "\n", "split_files", "=", "{", "\n", "'train'", ":", "'ego4d_train_subset.csv'", ",", "\n", "'val'", ":", "'ego4d_val_ts_clean.csv'", ",", "\n", "'test'", ":", "'ego4d_val_ts_clean.csv'", "# there is no test", "\n", "}", "\n", "target_split_fp", "=", "split_files", "[", "self", ".", "split", "]", "\n", "self", ".", "metadata", "=", "pd", ".", "read_csv", "(", "os", ".", "path", ".", "join", "(", "metadata_dir", ",", "target_split_fp", ")", ",", "sep", "=", "'\\t'", ",", "header", "=", "None", ",", "error_bad_lines", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.ego4d.Ego4DDataset._get_video_path": [[36, 42], ["os.path.join", "os.path.exists", "Exception"], "methods", ["None"], ["", "def", "_get_video_path", "(", "self", ",", "sample", ")", ":", "\n", "        ", "rel_video_fp", "=", "sample", "[", "0", "]", "+", "'.mp4'", "\n", "full_video_fp", "=", "os", ".", "path", ".", "join", "(", "self", ".", "data_dir", ",", "'videos'", ",", "rel_video_fp", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "full_video_fp", ")", ":", "\n", "            ", "Exception", "(", "IOError", ")", "\n", "", "return", "full_video_fp", ",", "rel_video_fp", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.ego4d.Ego4DDataset._get_caption": [[43, 45], ["None"], "methods", ["None"], ["", "def", "_get_caption", "(", "self", ",", "sample", ")", ":", "\n", "        ", "return", "sample", "[", "6", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.ego4d.Ego4DDataset.get_raw_video": [[46, 57], ["ego4d.Ego4DDataset._get_video_path", "video_base_dataset.read_large_frames_decord", "int", "int", "Exception"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_v2.Ego4DDataset._get_video_path", "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.video_base_dataset.read_large_frames_decord"], ["", "def", "get_raw_video", "(", "self", ",", "sample", ")", ":", "\n", "        ", "abs_fp", ",", "rel_fp", "=", "self", ".", "_get_video_path", "(", "sample", ")", "\n", "# if int(sample[2]) > 600:", "\n", "#     raise Exception(\"Video is longer than 10m!\", rel_fp)", "\n", "frame_end", ",", "frame_loc", "=", "int", "(", "sample", "[", "3", "]", ")", ",", "int", "(", "sample", "[", "5", "]", ")", "\n", "# imgs = video_reader(abs_fp, frame_loc, frame_end, self.num_frames)", "\n", "imgs", "=", "read_large_frames_decord", "(", "abs_fp", ",", "frame_loc", ",", "frame_end", ",", "self", ".", "num_frames", ")", "\n", "if", "imgs", "is", "None", ":", "\n", "            ", "raise", "Exception", "(", "\"Invalid video!\"", ",", "rel_fp", ")", "\n", "", "else", ":", "\n", "            ", "return", "imgs", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.activitynet.ActivityNetDataset.__init__": [[8, 20], ["activitynet.ActivityNetDataset._load_metadata", "video_base_dataset.BaseDataset.__init__"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_v2.Ego4DDataset._load_metadata", "home.repos.pwc.inspect_result.showlab_all-in-one.transforms.utils.UnNormalize.__init__"], ["    ", "def", "__init__", "(", "self", ",", "*", "args", ",", "split", "=", "\"\"", ",", "**", "kwargs", ")", ":", "\n", "        ", "assert", "split", "in", "[", "\"train\"", ",", "\"val\"", ",", "\"test\"", "]", "\n", "self", ".", "split", "=", "split", "\n", "self", ".", "metadata", "=", "None", "\n", "if", "split", "==", "\"train\"", ":", "\n", "            ", "names", "=", "[", "\"activitynet_train\"", "]", "\n", "", "elif", "split", "==", "\"val\"", ":", "\n", "            ", "names", "=", "[", "\"activitynet_val\"", "]", "\n", "", "elif", "split", "==", "\"test\"", ":", "\n", "            ", "names", "=", "[", "\"activitynet_val\"", "]", "\n", "", "self", ".", "_load_metadata", "(", ")", "\n", "super", "(", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ",", "names", "=", "names", ",", "text_column_name", "=", "\"caption\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.activitynet.ActivityNetDataset._load_metadata": [[21, 31], ["pandas.read_json", "os.path.join"], "methods", ["None"], ["", "def", "_load_metadata", "(", "self", ")", ":", "\n", "        ", "metadata_dir", "=", "'./meta_data/activitynet'", "\n", "split_files", "=", "{", "\n", "'train'", ":", "'train.jsonl'", ",", "\n", "'val'", ":", "'val1.jsonl'", ",", "\n", "'test'", ":", "'val2.jsonl'", "\n", "}", "\n", "target_split_fp", "=", "split_files", "[", "self", ".", "split", "]", "\n", "metadata", "=", "pd", ".", "read_json", "(", "os", ".", "path", ".", "join", "(", "metadata_dir", ",", "target_split_fp", ")", ",", "lines", "=", "True", ")", "\n", "self", ".", "metadata", "=", "metadata", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.activitynet.ActivityNetDataset._get_video_path": [[32, 36], ["os.path.join"], "methods", ["None"], ["", "def", "_get_video_path", "(", "self", ",", "sample", ")", ":", "\n", "        ", "rel_video_fp", "=", "sample", "[", "'clip_name'", "]", "\n", "full_video_fp", "=", "os", ".", "path", ".", "join", "(", "self", ".", "data_dir", ",", "'activitynet_frames'", ",", "rel_video_fp", ")", "\n", "return", "full_video_fp", ",", "rel_video_fp", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.activitynet.ActivityNetDataset.get_raw_video": [[37, 44], ["activitynet.ActivityNetDataset._get_video_path", "video_base_dataset.read_frames_from_img_dir", "Exception"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_v2.Ego4DDataset._get_video_path", "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.video_base_dataset.read_frames_from_img_dir"], ["", "def", "get_raw_video", "(", "self", ",", "sample", ")", ":", "\n", "        ", "abs_fp", ",", "rel_fp", "=", "self", ".", "_get_video_path", "(", "sample", ")", "\n", "imgs", ",", "idxs", ",", "vlen", "=", "read_frames_from_img_dir", "(", "abs_fp", ",", "self", ".", "num_frames", ",", "mode", "=", "self", ".", "split", ")", "\n", "if", "imgs", "is", "None", ":", "\n", "            ", "raise", "Exception", "(", "\"Invalid img!\"", ",", "rel_fp", ")", "\n", "", "else", ":", "\n", "            ", "return", "imgs", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.activitynet.ActivityNetDataset.get_video": [[45, 53], ["activitynet.ActivityNetDataset.get_raw_video", "activitynet.ActivityNetDataset.video_aug"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_v2.Ego4DDataset.get_raw_video", "home.repos.pwc.inspect_result.showlab_all-in-one.video.videoaug.video_aug"], ["", "", "def", "get_video", "(", "self", ",", "index", ",", "sample", ",", "image_key", "=", "\"image\"", ")", ":", "\n", "        ", "videos", "=", "self", ".", "get_raw_video", "(", "sample", ")", "\n", "videos_tensor", "=", "self", ".", "video_aug", "(", "videos", ",", "self", ".", "video_transform", ")", "\n", "return", "{", "\n", "\"video\"", ":", "videos_tensor", ",", "\n", "\"vid_index\"", ":", "index", ",", "\n", "\"cap_index\"", ":", "index", ",", "\n", "\"raw_index\"", ":", "index", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.activitynet.ActivityNetDataset.get_false_video": [[55, 61], ["random.randint", "activitynet.ActivityNetDataset.get_raw_video", "activitynet.ActivityNetDataset.video_aug", "len"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_v2.Ego4DDataset.get_raw_video", "home.repos.pwc.inspect_result.showlab_all-in-one.video.videoaug.video_aug"], ["", "def", "get_false_video", "(", "self", ",", "rep", ",", "image_key", "=", "\"image\"", ")", ":", "\n", "        ", "random_index", "=", "random", ".", "randint", "(", "0", ",", "len", "(", "self", ".", "metadata", ")", "-", "1", ")", "\n", "sample", "=", "self", ".", "metadata", ".", "iloc", "[", "random_index", "]", "\n", "videos", "=", "self", ".", "get_raw_video", "(", "sample", ")", "\n", "videos_tensor", "=", "self", ".", "video_aug", "(", "videos", ",", "self", ".", "video_transform", ")", "\n", "return", "{", "f\"false_video_{rep}\"", ":", "videos_tensor", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.activitynet.ActivityNetDataset.get_text": [[62, 78], ["activitynet.ActivityNetDataset.tokenizer"], "methods", ["None"], ["", "def", "get_text", "(", "self", ",", "raw_index", ",", "sample", ")", ":", "\n", "        ", "text", "=", "sample", "[", "'caption'", "]", "\n", "# print(text)", "\n", "encoding", "=", "self", ".", "tokenizer", "(", "\n", "text", ",", "\n", "padding", "=", "\"max_length\"", ",", "\n", "truncation", "=", "True", ",", "\n", "max_length", "=", "self", ".", "max_text_len", ",", "\n", "return_special_tokens_mask", "=", "True", ",", "\n", ")", "\n", "# print(encoding.size())", "\n", "return", "{", "\n", "\"text\"", ":", "(", "text", ",", "encoding", ")", ",", "\n", "\"img_index\"", ":", "raw_index", ",", "\n", "\"cap_index\"", ":", "raw_index", ",", "\n", "\"raw_index\"", ":", "raw_index", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.activitynet.ActivityNetDataset.get_false_text": [[80, 92], ["random.randint", "activitynet.ActivityNetDataset.tokenizer", "len"], "methods", ["None"], ["", "def", "get_false_text", "(", "self", ",", "rep", ")", ":", "\n", "        ", "random_index", "=", "random", ".", "randint", "(", "0", ",", "len", "(", "self", ".", "metadata", ")", "-", "1", ")", "\n", "sample", "=", "self", ".", "metadata", ".", "iloc", "[", "random_index", "]", "\n", "text", "=", "sample", "[", "'caption'", "]", "\n", "encoding", "=", "self", ".", "tokenizer", "(", "\n", "text", ",", "\n", "# padding=\"max_length\",", "\n", "truncation", "=", "True", ",", "\n", "max_length", "=", "self", ".", "max_text_len", ",", "\n", "return_special_tokens_mask", "=", "True", ",", "\n", ")", "\n", "return", "{", "f\"false_text_{rep}\"", ":", "(", "text", ",", "encoding", ")", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.activitynet.ActivityNetDataset.get_suite": [[93, 114], ["dict", "dict.update", "range", "range", "activitynet.ActivityNetDataset.get_video", "activitynet.ActivityNetDataset.get_text", "dict.update", "dict.update", "dict.update", "dict.update", "print", "random.randint", "activitynet.ActivityNetDataset.get_false_video", "activitynet.ActivityNetDataset.get_false_text", "len"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.gadgets.my_metrics.VQAScore.update", "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_v2.Ego4DDataset.get_video", "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_v2.Ego4DDataset.get_text", "home.repos.pwc.inspect_result.showlab_all-in-one.gadgets.my_metrics.VQAScore.update", "home.repos.pwc.inspect_result.showlab_all-in-one.gadgets.my_metrics.VQAScore.update", "home.repos.pwc.inspect_result.showlab_all-in-one.gadgets.my_metrics.VQAScore.update", "home.repos.pwc.inspect_result.showlab_all-in-one.gadgets.my_metrics.VQAScore.update", "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_v2.Ego4DDataset.get_false_video", "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_v2.Ego4DDataset.get_false_text"], ["", "def", "get_suite", "(", "self", ",", "index", ")", ":", "\n", "        ", "result", "=", "None", "\n", "while", "result", "is", "None", ":", "\n", "            ", "sample", "=", "self", ".", "metadata", ".", "iloc", "[", "index", "]", "\n", "try", ":", "\n", "                ", "ret", "=", "dict", "(", ")", "\n", "ret", ".", "update", "(", "self", ".", "get_video", "(", "index", ",", "sample", ")", ")", "\n", "if", "not", "self", ".", "image_only", ":", "\n", "                    ", "txt", "=", "self", ".", "get_text", "(", "index", ",", "sample", ")", "\n", "ret", ".", "update", "(", "{", "\"replica\"", ":", "True", "if", "txt", "[", "\"cap_index\"", "]", ">", "0", "else", "False", "}", ")", "\n", "ret", ".", "update", "(", "txt", ")", "\n", "\n", "", "for", "i", "in", "range", "(", "self", ".", "draw_false_image", ")", ":", "\n", "                    ", "ret", ".", "update", "(", "self", ".", "get_false_video", "(", "i", ")", ")", "\n", "", "for", "i", "in", "range", "(", "self", ".", "draw_false_text", ")", ":", "\n", "                    ", "ret", ".", "update", "(", "self", ".", "get_false_text", "(", "i", ")", ")", "\n", "", "result", "=", "True", "\n", "", "except", "Exception", "as", "e", ":", "\n", "                ", "print", "(", "f\"Error while read file idx {sample.name} in {self.names[0]} -> {e}\"", ")", "\n", "index", "=", "random", ".", "randint", "(", "0", ",", "len", "(", "self", ".", "metadata", ")", "-", "1", ")", "\n", "", "", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.activitynet.ActivityNetDataset.__len__": [[115, 117], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "metadata", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.activitynet.ActivityNetDataset.__getitem__": [[118, 120], ["activitynet.ActivityNetDataset.get_suite"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_v2.Ego4DDataset.get_suite"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "return", "self", ".", "get_suite", "(", "index", ")", "", "", "", ""]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.yttemporal.YTTemporalDataset.__init__": [[15, 42], ["video_base_dataset.BaseDataset.__init__", "yttemporal.YTTemporalDataset._load_metadata", "yttemporal.YTTemporalDataset._load_metadata", "float"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.transforms.utils.UnNormalize.__init__", "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_v2.Ego4DDataset._load_metadata", "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_v2.Ego4DDataset._load_metadata"], ["def", "__init__", "(", "self", ",", "*", "args", ",", "split", "=", "\"\"", ",", "**", "kwargs", ")", ":", "\n", "        ", "assert", "split", "in", "[", "\"train\"", ",", "\"val\"", ",", "\"test\"", "]", "\n", "self", ".", "split", "=", "split", "\n", "\n", "if", "split", "==", "\"train\"", ":", "\n", "            ", "names", "=", "[", "\"yttemporal_train\"", "]", "\n", "", "elif", "split", "==", "\"val\"", ":", "\n", "            ", "names", "=", "[", "\"yttemporal_val\"", "]", "\n", "", "elif", "split", "==", "\"test\"", ":", "\n", "            ", "names", "=", "[", "\"yttemporal_test\"", "]", "\n", "", "super", "(", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ",", "names", "=", "names", ",", "text_column_name", "=", "\"caption\"", ")", "\n", "\n", "self", ".", "metadata", "=", "None", "\n", "self", ".", "_load_metadata", "(", ")", "\n", "self", ".", "min_time", "=", "4.0", "\n", "self", ".", "size", "=", "224", "\n", "self", ".", "fps", "=", "2", "\n", "self", ".", "num_sec", "=", "self", ".", "num_frames", "/", "float", "(", "self", ".", "fps", ")", "\n", "self", ".", "crop_only", "=", "True", "\n", "if", "self", ".", "split", "==", "'train'", ":", "\n", "            ", "self", ".", "center_crop", "=", "False", "\n", "", "else", ":", "\n", "            ", "self", ".", "center_crop", "=", "True", "\n", "", "self", ".", "benchmark", "=", "False", "\n", "self", ".", "num_candidates", "=", "1", "\n", "self", ".", "random_flip", "=", "True", "\n", "self", ".", "_load_metadata", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.yttemporal.YTTemporalDataset._load_metadata": [[43, 53], ["pandas.read_csv", "os.path.join"], "methods", ["None"], ["", "def", "_load_metadata", "(", "self", ")", ":", "\n", "        ", "metadata_dir", "=", "'./meta_data/yttemporal'", "\n", "split_files", "=", "{", "\n", "'train'", ":", "'train_success_2000000.csv'", ",", "# _1000000", "\n", "'val'", ":", "'val_success.csv'", ",", "# there is no test", "\n", "'test'", ":", "'val_success.csv'", "\n", "}", "\n", "target_split_fp", "=", "split_files", "[", "self", ".", "split", "]", "\n", "metadata", "=", "pd", ".", "read_csv", "(", "os", ".", "path", ".", "join", "(", "metadata_dir", ",", "target_split_fp", ")", ",", "sep", "=", "'\\t'", ")", "\n", "self", ".", "metadata", "=", "metadata", "[", "\"Name\"", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.yttemporal.YTTemporalDataset.read_frames_ffmpeg": [[54, 101], ["ffmpeg.input().filter", "cmd.hflip.hflip.output().run", "numpy.frombuffer().reshape", "torch.from_numpy", "cmd.hflip.hflip.crop", "cmd.hflip.hflip.crop().filter", "cmd.hflip.hflip.hflip", "numpy.copy", "torch.cat.permute", "torch.ones", "torch.cat", "ffmpeg.input", "random.uniform", "random.uniform", "str", "str", "random.uniform", "cmd.hflip.hflip.output", "numpy.frombuffer", "cmd.hflip.hflip.crop"], "methods", ["None"], ["", "def", "read_frames_ffmpeg", "(", "self", ",", "video_path", ",", "start", ",", "end", ")", ":", "\n", "        ", "start_seek", "=", "start", "\n", "cmd", "=", "(", "\n", "ffmpeg", "\n", ".", "input", "(", "video_path", ",", "ss", "=", "start_seek", ",", "t", "=", "end", "-", "start", "+", "0.01", ")", "\n", ".", "filter", "(", "'fps'", ",", "fps", "=", "self", ".", "fps", ")", "\n", ")", "\n", "if", "self", ".", "center_crop", ":", "\n", "            ", "aw", ",", "ah", "=", "0.5", ",", "0.5", "\n", "", "else", ":", "\n", "            ", "aw", ",", "ah", "=", "random", ".", "uniform", "(", "0", ",", "1", ")", ",", "random", ".", "uniform", "(", "0", ",", "1", ")", "\n", "", "if", "self", ".", "crop_only", ":", "\n", "            ", "cmd", "=", "(", "\n", "cmd", ".", "crop", "(", "'(iw - {})*{}'", ".", "format", "(", "self", ".", "size", ",", "aw", ")", ",", "\n", "'(ih - {})*{}'", ".", "format", "(", "self", ".", "size", ",", "ah", ")", ",", "\n", "str", "(", "self", ".", "size", ")", ",", "str", "(", "self", ".", "size", ")", ")", "\n", ")", "\n", "", "else", ":", "\n", "            ", "cmd", "=", "(", "\n", "cmd", ".", "crop", "(", "'(iw - min(iw,ih))*{}'", ".", "format", "(", "aw", ")", ",", "\n", "'(ih - min(iw,ih))*{}'", ".", "format", "(", "ah", ")", ",", "\n", "'min(iw,ih)'", ",", "\n", "'min(iw,ih)'", ")", "\n", ".", "filter", "(", "'scale'", ",", "self", ".", "size", ",", "self", ".", "size", ")", "\n", ")", "\n", "", "if", "self", ".", "random_flip", "and", "random", ".", "uniform", "(", "0", ",", "1", ")", ">", "0.5", ":", "\n", "            ", "cmd", "=", "cmd", ".", "hflip", "(", ")", "\n", "", "out", ",", "_", "=", "(", "\n", "cmd", ".", "output", "(", "'pipe:'", ",", "format", "=", "'rawvideo'", ",", "pix_fmt", "=", "'rgb24'", ")", "\n", ".", "run", "(", "capture_stdout", "=", "True", ",", "quiet", "=", "True", ")", "\n", ")", "\n", "video", "=", "np", ".", "frombuffer", "(", "out", ",", "np", ".", "uint8", ")", ".", "reshape", "(", "[", "-", "1", ",", "self", ".", "size", ",", "self", ".", "size", ",", "3", "]", ")", "\n", "video_tensor", "=", "th", ".", "from_numpy", "(", "np", ".", "copy", "(", "video", ")", ")", "\n", "video_tensor", "=", "video_tensor", ".", "permute", "(", "3", ",", "0", ",", "1", ",", "2", ")", "+", "0.01", "\n", "# print(video_tensor.size())", "\n", "# print(video_tensor)", "\n", "if", "video_tensor", ".", "shape", "[", "1", "]", "<", "self", ".", "num_frames", ":", "\n", "            ", "zeros", "=", "th", ".", "ones", "(", "(", "3", ",", "self", ".", "num_frames", "-", "video_tensor", ".", "shape", "[", "1", "]", ",", "self", ".", "size", ",", "self", ".", "size", ")", ",", "dtype", "=", "th", ".", "uint8", ")", "\n", "video_tensor", "=", "th", ".", "cat", "(", "(", "video_tensor", ",", "zeros", ")", ",", "axis", "=", "1", ")", "\n", "# # uniform n frames", "\n", "# frame_indexs = sample_frames(self.num_frames, video_tensor.size(1))", "\n", "# out_tensors = th.ones((3, self.num_frames, self.size, self.size), dtype=th.uint8)", "\n", "# for i in range(self.num_frames):", "\n", "#     out_tensors[:, i] = video_tensor[:, frame_indexs[i]]", "\n", "# print(out_tensors)", "\n", "# return out_tensors", "\n", "", "return", "video_tensor", "[", ":", ",", ":", "self", ".", "num_frames", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.yttemporal.YTTemporalDataset.get_caption": [[132, 166], ["int", "random.randint", "min", "video_base_dataset.clean_subtitles", "pandas.DataFrame", "video_base_dataset.align_using_dtw", "enumerate", "open", "json.load", "random.randint", "random.random", "ftfy.ftfy", "ftfy.ftfy.split", "len", "Exception", "max", "max", "float", "float"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.datasets.video_base_dataset.clean_subtitles", "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.video_base_dataset.align_using_dtw"], ["", "def", "get_caption", "(", "self", ",", "caption_csv", ")", ":", "\n", "        ", "with", "open", "(", "caption_csv", ",", "'r'", ")", "as", "f", ":", "\n", "            ", "cap", "=", "json", ".", "load", "(", "f", ")", "\n", "# random choice 10s-15s video clips", "\n", "", "video_len", "=", "int", "(", "cap", "[", "\"info\"", "]", "[", "\"duration\"", "]", ")", "\n", "start", "=", "random", ".", "randint", "(", "0", ",", "max", "(", "1", ",", "video_len", "-", "15", ")", ")", "+", "random", ".", "random", "(", ")", "\n", "clip_len", "=", "random", ".", "randint", "(", "10", ",", "15", ")", "\n", "end", "=", "min", "(", "video_len", "-", "1", ",", "start", "+", "clip_len", ")", "\n", "all_text", "=", "cap", "[", "\"subtitles\"", "]", "# [{'word': 'hey', 'time': 0.0}, {'word': 'guys', 'time': 0.149}]", "\n", "# clean noisy asr text", "\n", "all_text", "=", "clean_subtitles", "(", "all_text", ")", "\n", "vtt", "=", "pd", ".", "DataFrame", "(", "all_text", ")", "\n", "denoised_word_by_word", "=", "[", "]", "\n", "for", "x", "in", "cap", "[", "'denoised'", "]", ":", "\n", "# Ftfy just in case", "\n", "            ", "cleanasr", "=", "ftfy", ".", "ftfy", "(", "x", "[", "'cleanasr'", "]", ")", "\n", "denoised_word_by_word", "+=", "cleanasr", ".", "split", "(", "' '", ")", "\n", "# Align", "\n", "", "vtt", "[", "'denoised'", "]", "=", "align_using_dtw", "(", "vtt", "[", "'word'", "]", ",", "denoised_word_by_word", ")", "\n", "text", "=", "\"\"", "\n", "origin_text", "=", "\"\"", "\n", "for", "index", ",", "item", "in", "enumerate", "(", "all_text", ")", ":", "\n", "            ", "if", "float", "(", "item", "[", "'time'", "]", ")", ">", "start", "and", "float", "(", "item", "[", "'time'", "]", ")", "<", "end", ":", "\n", "                ", "text", "+=", "vtt", "[", "'denoised'", "]", "[", "index", "]", "+", "\" \"", "\n", "origin_text", "+=", "item", "[", "'word'", "]", "+", "\" \"", "\n", "# print(text)", "\n", "# print(origin_text)", "\n", "", "", "if", "len", "(", "text", ")", "<", "10", ":", "\n", "            ", "Exception", "(", "IndexError", ")", "\n", "", "if", "end", "-", "start", "<", "self", ".", "min_time", ":", "\n", "            ", "diff", "=", "self", ".", "min_time", "-", "end", "+", "start", "\n", "start", "=", "max", "(", "0", ",", "start", "-", "diff", "/", "2", ")", "\n", "end", "=", "start", "+", "self", ".", "min_time", "\n", "", "return", "text", ",", "start", ",", "end", ",", "video_len", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.yttemporal.YTTemporalDataset.get_text": [[167, 181], ["yttemporal.YTTemporalDataset.get_caption_path", "yttemporal.YTTemporalDataset.get_caption", "yttemporal.YTTemporalDataset.tokenizer"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.datasets.yttemporal.YTTemporalDataset.get_caption_path", "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.yttemporal.YTTemporalDataset.get_caption"], ["", "def", "get_text", "(", "self", ",", "sample", ")", ":", "\n", "        ", "caption_csv", "=", "self", ".", "get_caption_path", "(", "sample", ")", "\n", "text", ",", "start", ",", "end", ",", "duration", "=", "self", ".", "get_caption", "(", "caption_csv", ")", "\n", "# print(text, start, end)", "\n", "# print(text)", "\n", "# TODO: May need to be improved for edge cases.", "\n", "encoding", "=", "self", ".", "tokenizer", "(", "\n", "text", ",", "\n", "padding", "=", "\"max_length\"", ",", "\n", "truncation", "=", "True", ",", "\n", "max_length", "=", "self", ".", "max_text_len", ",", "\n", "return_special_tokens_mask", "=", "True", ",", "\n", ")", "\n", "return", "{", "\"text\"", ":", "(", "text", ",", "encoding", ")", "}", ",", "start", ",", "end", ",", "duration", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.yttemporal.YTTemporalDataset.get_caption_path": [[182, 185], ["os.path.join", "sample.split", "sample.split"], "methods", ["None"], ["", "def", "get_caption_path", "(", "self", ",", "sample", ")", ":", "\n", "# YTTemporal/videos/subset_87/data/xx.mp4 -> YTTemporal/videos/subset_87/annotations/xx.csv", "\n", "        ", "return", "os", ".", "path", ".", "join", "(", "self", ".", "data_dir", ",", "'videos'", ",", "sample", ".", "split", "(", "'/'", ")", "[", "0", "]", ",", "'annotations'", ",", "sample", ".", "split", "(", "'/'", ")", "[", "-", "1", "]", "[", ":", "-", "4", "]", "+", "'.json'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.yttemporal.YTTemporalDataset.get_false_text": [[186, 199], ["random.randint", "yttemporal.YTTemporalDataset.get_caption_path", "yttemporal.YTTemporalDataset.get_caption", "yttemporal.YTTemporalDataset.tokenizer", "len"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.datasets.yttemporal.YTTemporalDataset.get_caption_path", "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.yttemporal.YTTemporalDataset.get_caption"], ["", "def", "get_false_text", "(", "self", ",", "rep", ")", ":", "\n", "        ", "random_index", "=", "random", ".", "randint", "(", "0", ",", "len", "(", "self", ".", "metadata", ")", "-", "1", ")", "\n", "sample", "=", "self", ".", "metadata", ".", "iloc", "[", "random_index", "]", "\n", "caption_csv", "=", "self", ".", "get_caption_path", "(", "sample", ")", "\n", "text", ",", "start", ",", "end", "=", "self", ".", "get_caption", "(", "caption_csv", ")", "\n", "encoding", "=", "self", ".", "tokenizer", "(", "\n", "text", ",", "\n", "# padding=\"max_length\",", "\n", "truncation", "=", "True", ",", "\n", "max_length", "=", "self", ".", "max_text_len", ",", "\n", "return_special_tokens_mask", "=", "True", ",", "\n", ")", "\n", "return", "{", "f\"false_text_{rep}\"", ":", "(", "text", ",", "encoding", ")", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.yttemporal.YTTemporalDataset._get_video_path": [[200, 204], ["os.path.join"], "methods", ["None"], ["", "def", "_get_video_path", "(", "self", ",", "sample", ")", ":", "\n", "        ", "rel_video_fp", "=", "sample", "\n", "full_video_fp", "=", "os", ".", "path", ".", "join", "(", "self", ".", "data_dir", ",", "'videos'", ",", "rel_video_fp", ")", "\n", "return", "full_video_fp", ",", "rel_video_fp", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.yttemporal.YTTemporalDataset.get_raw_video": [[205, 216], ["yttemporal.YTTemporalDataset._get_video_path", "video_base_dataset.video_clip_reader", "video_base_dataset.video_clip_reader.size", "Exception", "Exception"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_v2.Ego4DDataset._get_video_path", "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.video_base_dataset.video_clip_reader"], ["", "def", "get_raw_video", "(", "self", ",", "sample", ",", "begin", ",", "end", ",", "duration", ")", ":", "\n", "        ", "abs_fp", ",", "rel_fp", "=", "self", ".", "_get_video_path", "(", "sample", ")", "\n", "# print(abs_fp, rel_fp)", "\n", "# imgs = self.read_frames_ffmpeg(abs_fp, begin, end).permute(1, 0, 2, 3)", "\n", "videos", "=", "video_clip_reader", "(", "abs_fp", ",", "begin", ",", "end", ",", "duration", ",", "self", ".", "num_frames", ")", "\n", "if", "videos", ".", "size", "(", "0", ")", "!=", "self", ".", "num_frames", ":", "\n", "            ", "raise", "Exception", "(", "\"video length not enough!\"", ",", "rel_fp", ")", "\n", "", "if", "videos", "is", "None", ":", "\n", "            ", "raise", "Exception", "(", "\"Invalid img!\"", ",", "rel_fp", ")", "\n", "", "else", ":", "\n", "            ", "return", "videos", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.yttemporal.YTTemporalDataset.get_video": [[217, 221], ["yttemporal.YTTemporalDataset.get_raw_video", "yttemporal.YTTemporalDataset.video_aug"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_v2.Ego4DDataset.get_raw_video", "home.repos.pwc.inspect_result.showlab_all-in-one.video.videoaug.video_aug"], ["", "", "def", "get_video", "(", "self", ",", "sample", ",", "start", ",", "end", ",", "duration", ")", ":", "\n", "        ", "videos", "=", "self", ".", "get_raw_video", "(", "sample", ",", "start", ",", "end", ",", "duration", ")", "\n", "videos_tensor", "=", "self", ".", "video_aug", "(", "videos", ",", "self", ".", "video_transform", ")", "\n", "return", "videos_tensor", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.yttemporal.YTTemporalDataset.get_false_video": [[222, 230], ["random.randint", "yttemporal.YTTemporalDataset.get_caption_path", "yttemporal.YTTemporalDataset.get_caption", "yttemporal.YTTemporalDataset.get_raw_video", "yttemporal.YTTemporalDataset.video_aug", "len"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.datasets.yttemporal.YTTemporalDataset.get_caption_path", "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.yttemporal.YTTemporalDataset.get_caption", "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_v2.Ego4DDataset.get_raw_video", "home.repos.pwc.inspect_result.showlab_all-in-one.video.videoaug.video_aug"], ["", "def", "get_false_video", "(", "self", ",", "rep", ")", ":", "\n", "        ", "random_index", "=", "random", ".", "randint", "(", "0", ",", "len", "(", "self", ".", "metadata", ")", "-", "1", ")", "\n", "sample", "=", "self", ".", "metadata", ".", "iloc", "[", "random_index", "]", "\n", "caption_csv", "=", "self", ".", "get_caption_path", "(", "sample", ")", "\n", "_", ",", "start", ",", "end", ",", "duration", "=", "self", ".", "get_caption", "(", "caption_csv", ")", "\n", "videos", "=", "self", ".", "get_raw_video", "(", "sample", ",", "start", ",", "end", ",", "duration", ")", "\n", "videos_tensor", "=", "self", ".", "video_aug", "(", "videos", ",", "self", ".", "video_transform", ")", "\n", "return", "{", "f\"false_video_{rep}\"", ":", "videos_tensor", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.yttemporal.YTTemporalDataset.get_suite": [[231, 262], ["dict", "yttemporal.YTTemporalDataset.get_text", "dict.update", "yttemporal.YTTemporalDataset.get_video", "dict.update", "dict.update", "range", "range", "dict.update", "dict.update", "print", "yttemporal.YTTemporalDataset.get_false_video", "yttemporal.YTTemporalDataset.get_false_text"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_v2.Ego4DDataset.get_text", "home.repos.pwc.inspect_result.showlab_all-in-one.gadgets.my_metrics.VQAScore.update", "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_v2.Ego4DDataset.get_video", "home.repos.pwc.inspect_result.showlab_all-in-one.gadgets.my_metrics.VQAScore.update", "home.repos.pwc.inspect_result.showlab_all-in-one.gadgets.my_metrics.VQAScore.update", "home.repos.pwc.inspect_result.showlab_all-in-one.gadgets.my_metrics.VQAScore.update", "home.repos.pwc.inspect_result.showlab_all-in-one.gadgets.my_metrics.VQAScore.update", "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_v2.Ego4DDataset.get_false_video", "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_v2.Ego4DDataset.get_false_text"], ["", "def", "get_suite", "(", "self", ",", "index", ")", ":", "\n", "        ", "result", "=", "None", "\n", "max_try", "=", "5", "\n", "try_time", "=", "0", "\n", "while", "result", "is", "None", ":", "\n", "            ", "try_time", "+=", "1", "\n", "sample", "=", "self", ".", "metadata", ".", "iloc", "[", "index", "]", "\n", "# try:", "\n", "ret", "=", "dict", "(", ")", "\n", "text", ",", "start", ",", "end", ",", "duration", "=", "self", ".", "get_text", "(", "sample", ")", "\n", "ret", ".", "update", "(", "text", ")", "\n", "videos_tensor", "=", "self", ".", "get_video", "(", "sample", ",", "start", ",", "end", ",", "duration", ")", "\n", "# print(imgs_tensor.size())", "\n", "ret", ".", "update", "(", "{", "\n", "\"video\"", ":", "videos_tensor", ",", "\n", "\"vid_index\"", ":", "index", ",", "\n", "\"cap_index\"", ":", "index", ",", "\n", "\"raw_index\"", ":", "index", ",", "\n", "}", ")", "\n", "ret", ".", "update", "(", "{", "\"replica\"", ":", "True", "if", "ret", "[", "\"cap_index\"", "]", ">", "0", "else", "False", "}", ")", "\n", "for", "i", "in", "range", "(", "self", ".", "draw_false_video", ")", ":", "\n", "                ", "ret", ".", "update", "(", "self", ".", "get_false_video", "(", "i", ")", ")", "\n", "", "for", "i", "in", "range", "(", "self", ".", "draw_false_text", ")", ":", "\n", "                ", "ret", ".", "update", "(", "self", ".", "get_false_text", "(", "i", ")", ")", "\n", "", "result", "=", "True", "\n", "# except Exception as e:", "\n", "#     # print(f\"Error while read file idx {sample} in {self.names[0]} -> {e}\")", "\n", "#     index = random.randint(0, len(self.metadata) - 1)", "\n", "if", "try_time", ">", "max_try", ":", "\n", "                ", "print", "(", "f\"Exceed max time Error while read file idx {sample} in {self.names[0]}\"", ")", "\n", "", "", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.yttemporal.YTTemporalDataset.__len__": [[263, 265], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "metadata", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.yttemporal.YTTemporalDataset.__getitem__": [[266, 268], ["yttemporal.YTTemporalDataset.get_suite"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_v2.Ego4DDataset.get_suite"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "return", "self", ".", "get_suite", "(", "index", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.tvqaplus.TVQAPLUSDataset.__init__": [[49, 67], ["tvqaplus.TVQAPLUSDataset._load_metadata", "video_base_dataset.BaseDataset.__init__"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_v2.Ego4DDataset._load_metadata", "home.repos.pwc.inspect_result.showlab_all-in-one.transforms.utils.UnNormalize.__init__"], ["    ", "def", "__init__", "(", "self", ",", "*", "args", ",", "split", "=", "\"\"", ",", "**", "kwargs", ")", ":", "\n", "        ", "assert", "split", "in", "[", "\"train\"", ",", "\"val\"", ",", "\"test\"", "]", "\n", "self", ".", "split", "=", "split", "\n", "self", ".", "metadata", "=", "None", "\n", "self", ".", "_load_metadata", "(", ")", "\n", "if", "split", "==", "\"train\"", ":", "\n", "            ", "names", "=", "[", "\"tvqaplus_train\"", "]", "\n", "", "elif", "split", "==", "\"val\"", ":", "\n", "            ", "names", "=", "[", "\"tvqaplus_val\"", "]", "\n", "", "elif", "split", "==", "\"test\"", ":", "\n", "            ", "names", "=", "[", "\"tvqaplus_test\"", "]", "\n", "\n", "", "super", "(", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ",", "names", "=", "names", ",", "text_column_name", "=", "\"caption\"", ")", "\n", "# for appear objects", "\n", "self", ".", "only_use_relevant_dets", "=", "True", "\n", "if", "self", ".", "only_use_relevant_dets", ":", "\n", "            ", "self", ".", "relevant_dets", "=", "[", "]", "# resort the detection numbers", "\n", "self", ".", "relevant_dets_classes", "=", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.tvqaplus.TVQAPLUSDataset._load_metadata": [[68, 79], ["pandas.read_json", "os.path.join"], "methods", ["None"], ["", "", "def", "_load_metadata", "(", "self", ")", ":", "\n", "# download specific", "\n", "        ", "metadata_dir", "=", "'./meta_data/tvqa'", "\n", "split_files", "=", "{", "\n", "'train'", ":", "'tvqa_plus_train.jsonl'", ",", "\n", "'val'", ":", "'tvqa_plus_val.jsonl'", ",", "\n", "'test'", ":", "'tvqa_plus_test_public.jsonl'", "# no GT label for test set", "\n", "}", "\n", "target_split_fp", "=", "split_files", "[", "self", ".", "split", "]", "\n", "metadata", "=", "pd", ".", "read_json", "(", "os", ".", "path", ".", "join", "(", "metadata_dir", ",", "target_split_fp", ")", ",", "lines", "=", "True", ")", "\n", "self", ".", "metadata", "=", "metadata", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.tvqaplus.TVQAPLUSDataset._get_image_path": [[80, 83], ["os.path.join"], "methods", ["None"], ["", "def", "_get_image_path", "(", "self", ",", "sample", ")", ":", "\n", "        ", "rel_fp", "=", "sample", "[", "'vid_name'", "]", "\n", "return", "os", ".", "path", ".", "join", "(", "self", ".", "data_dir", ",", "rel_fp", ")", ",", "rel_fp", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.tvqaplus.TVQAPLUSDataset._get_caption": [[84, 86], ["None"], "methods", ["None"], ["", "def", "_get_caption", "(", "self", ",", "sample", ")", ":", "\n", "        ", "return", "sample", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.tvqaplus.TVQAPLUSDataset.get_raw_video": [[89, 103], ["tvqaplus.TVQAPLUSDataset._get_image_path", "int", "CoTrain.datasets.video.video_base_dataset.sample_frames", "torch.stack().permute", "cv2.imread", "torch.from_numpy().byte", "frame.permute.permute.permute", "torch.stack().permute.append", "torch.stack", "float", "float", "torch.from_numpy"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.datasets.vcr.VCRDataset._get_image_path", "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.base_dataset.sample_frames"], ["", "def", "get_raw_video", "(", "self", ",", "sample", ")", ":", "\n", "        ", "abs_fp", ",", "rel_fp", "=", "self", ".", "_get_image_path", "(", "sample", ")", "\n", "[", "beg_time", ",", "end_time", "]", "=", "sample", "[", "'ts'", "]", "\n", "clip_len", "=", "int", "(", "(", "float", "(", "end_time", ")", "-", "float", "(", "beg_time", ")", ")", "*", "3", ")", "\n", "rel_frame_index", "=", "sample_frames", "(", "self", ".", "num_frames", ",", "clip_len", ")", "\n", "# sample N frames here", "\n", "frames", "=", "[", "]", "\n", "for", "index", "in", "rel_frame_index", ":", "\n", "            ", "img", "=", "cv2", ".", "imread", "(", "abs_fp", "+", "'{}.jpg'", ".", "format", "(", "index", ")", ")", "\n", "frame", "=", "torch", ".", "from_numpy", "(", "img", ")", ".", "byte", "(", ")", "\n", "frame", "=", "frame", ".", "permute", "(", "2", ",", "0", ",", "1", ")", "\n", "frames", ".", "append", "(", "frame", ")", "\n", "", "frames", "=", "torch", ".", "stack", "(", "frames", ")", ".", "permute", "(", "1", ",", "0", ",", "2", ",", "3", ")", "\n", "return", "frames", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.tvqaplus.TVQAPLUSDataset.get_text": [[104, 119], ["tvqaplus.TVQAPLUSDataset.get_question", "range", "tvqaplus.TVQAPLUSDataset.tokenizer", "qa_texts.append"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.datasets.vcr.VCRDataset.get_question"], ["", "def", "get_text", "(", "self", ",", "sample", ")", ":", "\n", "        ", "question", "=", "self", ".", "get_question", "(", "sample", ")", "\n", "qa_texts", "=", "[", "]", "\n", "# 5 choices", "\n", "for", "i", "in", "range", "(", "5", ")", ":", "\n", "            ", "raw_text", "=", "question", "+", "\"[SEP]\"", "+", "sample", "[", "\"a{}\"", ".", "format", "(", "i", ")", "]", "\n", "qa_encoding", "=", "self", ".", "tokenizer", "(", "\n", "raw_text", ",", "\n", "padding", "=", "\"max_length\"", ",", "\n", "truncation", "=", "True", ",", "\n", "max_length", "=", "self", ".", "max_text_len", ",", "\n", "return_special_tokens_mask", "=", "True", ",", "\n", ")", "\n", "qa_texts", ".", "append", "(", "(", "raw_text", ",", "qa_encoding", ")", ")", "\n", "", "return", "qa_texts", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.tvqaplus.TVQAPLUSDataset.get_answer_label": [[120, 123], ["int"], "methods", ["None"], ["", "def", "get_answer_label", "(", "self", ",", "sample", ")", ":", "\n", "        ", "answer", "=", "int", "(", "sample", "[", "'answer_idx'", "]", ")", "\n", "return", "answer", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.tvqaplus.TVQAPLUSDataset.get_question": [[124, 126], ["None"], "methods", ["None"], ["", "def", "get_question", "(", "self", ",", "sample", ")", ":", "\n", "        ", "return", "sample", "[", "\"q\"", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.tvqaplus.TVQAPLUSDataset.__len__": [[127, 129], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "metadata", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.tvqaplus.TVQAPLUSDataset.__getitem__": [[130, 148], ["tvqaplus.TVQAPLUSDataset.get_answer_label", "tvqaplus.TVQAPLUSDataset.get_text", "range", "tvqaplus.TVQAPLUSDataset.get_video", "ret.update"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.datasets.msvdqa.MSVDQADataset.get_answer_label", "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_v2.Ego4DDataset.get_text", "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_v2.Ego4DDataset.get_video", "home.repos.pwc.inspect_result.showlab_all-in-one.gadgets.my_metrics.VQAScore.update"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "sample", "=", "self", ".", "metadata", ".", "iloc", "[", "index", "]", "\n", "self", ".", "relevant_dets", "=", "[", "]", "# initalize", "\n", "self", ".", "relevant_dets_classes", "=", "[", "]", "\n", "answer", "=", "self", ".", "get_answer_label", "(", "sample", ")", "\n", "ret", "=", "{", "\n", "\"vid_index\"", ":", "index", ",", "\n", "\"cap_index\"", ":", "index", ",", "\n", "\"raw_index\"", ":", "index", ",", "\n", "'answer'", ":", "answer", "\n", "}", "\n", "qa_texts", "=", "self", ".", "get_text", "(", "sample", ")", "\n", "ret", "[", "\"text\"", "]", "=", "qa_texts", "[", "0", "]", "\n", "for", "i", "in", "range", "(", "self", ".", "draw_options_text", "-", "1", ")", ":", "\n", "            ", "ret", ".", "update", "(", "{", "f\"options_text_{i}\"", ":", "qa_texts", "[", "i", "+", "1", "]", "}", ")", "\n", "", "video_tensor", "=", "self", ".", "get_video", "(", "sample", ")", "\n", "ret", "[", "\"video\"", "]", "=", "video_tensor", "\n", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.tgif.TGIFDataset.__init__": [[12, 33], ["video_base_dataset.BaseDataset.__init__", "tgif.TGIFDataset._load_metadata"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.transforms.utils.UnNormalize.__init__", "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_v2.Ego4DDataset._load_metadata"], ["    ", "def", "__init__", "(", "self", ",", "*", "args", ",", "split", "=", "\"\"", ",", "**", "kwargs", ")", ":", "\n", "        ", "assert", "split", "in", "[", "\"train\"", ",", "\"val\"", ",", "\"test\"", "]", "\n", "self", ".", "split", "=", "split", "\n", "self", ".", "metadata", "=", "None", "\n", "self", ".", "ans_lab_dict", "=", "None", "\n", "if", "split", "==", "\"train\"", ":", "\n", "            ", "names", "=", "[", "\"tgif_train\"", "]", "\n", "", "elif", "split", "==", "\"val\"", ":", "\n", "            ", "names", "=", "[", "\"tgif_val\"", "]", "\n", "", "elif", "split", "==", "\"test\"", ":", "\n", "            ", "names", "=", "[", "\"tgif_test\"", "]", "\n", "\n", "", "super", "(", ")", ".", "__init__", "(", "\n", "*", "args", ",", "\n", "**", "kwargs", ",", "\n", "names", "=", "names", ",", "\n", "text_column_name", "=", "\"questions\"", ",", "\n", "remove_duplicate", "=", "False", ",", "\n", ")", "\n", "# self.num_frames = 4", "\n", "self", ".", "_load_metadata", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.tgif.TGIFDataset._load_metadata": [[34, 49], ["os.path.join", "pandas.read_json", "open", "json.load", "os.path.join"], "methods", ["None"], ["", "def", "_load_metadata", "(", "self", ")", ":", "\n", "        ", "metadata_dir", "=", "'./meta_data/tgif'", "\n", "split_files", "=", "{", "\n", "'train'", ":", "'frameqa_train.jsonl'", ",", "\n", "'val'", ":", "'frameqa_test.jsonl'", ",", "# frameqa_val.jsonl", "\n", "'test'", ":", "'frameqa_test.jsonl'", "\n", "}", "\n", "target_split_fp", "=", "split_files", "[", "self", ".", "split", "]", "\n", "answer_fp", "=", "os", ".", "path", ".", "join", "(", "metadata_dir", ",", "'frameqa_trainval_ans2label.json'", ")", "\n", "# answer_fp = os.path.join(metadata_dir, 'msrvtt_qa_ans2label.json')", "\n", "with", "open", "(", "answer_fp", ",", "'r'", ")", "as", "JSON", ":", "\n", "            ", "self", ".", "ans_lab_dict", "=", "json", ".", "load", "(", "JSON", ")", "\n", "# path_or_buf=os.path.join(metadata_dir, target_split_fp)", "\n", "", "metadata", "=", "pd", ".", "read_json", "(", "os", ".", "path", ".", "join", "(", "metadata_dir", ",", "target_split_fp", ")", ",", "lines", "=", "True", ")", "\n", "self", ".", "metadata", "=", "metadata", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.tgif.TGIFDataset._get_video_path": [[50, 52], ["os.path.join"], "methods", ["None"], ["", "def", "_get_video_path", "(", "self", ",", "sample", ")", ":", "\n", "        ", "return", "os", ".", "path", ".", "join", "(", "self", ".", "data_dir", ",", "'gifs'", ",", "sample", "[", "'gif_name'", "]", ")", "+", "'.gif'", ",", "sample", "[", "'gif_name'", "]", "+", "'.gif'", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.tgif.TGIFDataset.get_raw_video": [[53, 60], ["tgif.TGIFDataset._get_video_path", "video_base_dataset.read_frames_gif", "Exception"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_v2.Ego4DDataset._get_video_path", "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.video_base_dataset.read_frames_gif"], ["", "def", "get_raw_video", "(", "self", ",", "sample", ")", ":", "\n", "        ", "abs_fp", ",", "rel_fp", "=", "self", ".", "_get_video_path", "(", "sample", ")", "\n", "imgs", ",", "idxs", ",", "vlen", "=", "read_frames_gif", "(", "abs_fp", ",", "self", ".", "num_frames", ",", "mode", "=", "self", ".", "split", ")", "\n", "if", "imgs", "is", "None", ":", "\n", "            ", "raise", "Exception", "(", "\"Invalid img!\"", ",", "rel_fp", ")", "\n", "", "else", ":", "\n", "            ", "return", "imgs", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.tgif.TGIFDataset.get_text": [[61, 71], ["tgif.TGIFDataset.tokenizer"], "methods", ["None"], ["", "", "def", "get_text", "(", "self", ",", "sample", ")", ":", "\n", "        ", "text", "=", "sample", "[", "'question'", "]", "\n", "encoding", "=", "self", ".", "tokenizer", "(", "\n", "text", ",", "\n", "padding", "=", "\"max_length\"", ",", "\n", "truncation", "=", "True", ",", "\n", "max_length", "=", "self", ".", "max_text_len", ",", "\n", "return_special_tokens_mask", "=", "True", ",", "\n", ")", "\n", "return", "(", "text", ",", "encoding", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.tgif.TGIFDataset.get_answer_label": [[72, 83], ["numpy.zeros().astype", "len", "numpy.zeros"], "methods", ["None"], ["", "def", "get_answer_label", "(", "self", ",", "sample", ")", ":", "\n", "        ", "text", "=", "sample", "[", "'answer'", "]", "\n", "ans_total_len", "=", "len", "(", "self", ".", "ans_lab_dict", ")", "+", "1", "# one additional class", "\n", "try", ":", "\n", "            ", "ans_label", "=", "self", ".", "ans_lab_dict", "[", "text", "]", "#", "\n", "", "except", "KeyError", ":", "\n", "            ", "ans_label", "=", "-", "100", "# ignore classes", "\n", "# ans_label = 1500 # other classes", "\n", "", "scores", "=", "np", ".", "zeros", "(", "ans_total_len", ")", ".", "astype", "(", "int", ")", "\n", "scores", "[", "ans_label", "]", "=", "1", "\n", "return", "text", ",", "ans_label", ",", "scores", "\n", "# return text, ans_label_vector, scores", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.tgif.TGIFDataset.__getitem__": [[85, 105], ["tgif.TGIFDataset.get_video", "tgif.TGIFDataset.get_text", "tgif.TGIFDataset.get_answer_label", "list", "list", "list"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_v2.Ego4DDataset.get_video", "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_v2.Ego4DDataset.get_text", "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.msvdqa.MSVDQADataset.get_answer_label"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "sample", "=", "self", ".", "metadata", ".", "iloc", "[", "index", "]", "\n", "video_tensor", "=", "self", ".", "get_video", "(", "sample", ")", "\n", "text", "=", "self", ".", "get_text", "(", "sample", ")", "\n", "# index, question_index = self.index_mapper[index]", "\n", "qid", "=", "index", "\n", "if", "self", ".", "split", "!=", "\"test\"", ":", "\n", "            ", "answers", ",", "labels", ",", "scores", "=", "self", ".", "get_answer_label", "(", "sample", ")", "\n", "", "else", ":", "\n", "            ", "answers", "=", "list", "(", ")", "\n", "labels", "=", "list", "(", ")", "\n", "scores", "=", "list", "(", ")", "\n", "\n", "", "return", "{", "\n", "\"video\"", ":", "video_tensor", ",", "\n", "\"text\"", ":", "text", ",", "\n", "\"vqa_answer\"", ":", "answers", ",", "\n", "\"vqa_labels\"", ":", "labels", ",", "\n", "\"vqa_scores\"", ":", "scores", ",", "\n", "\"qid\"", ":", "qid", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.tgif.TGIFDataset.__len__": [[107, 109], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "metadata", ")", "", "", "", ""]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.msrvtt.MSRVTTDataset.__init__": [[10, 24], ["video_base_dataset.BaseDataset.__init__", "msrvtt.MSRVTTDataset._load_metadata"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.transforms.utils.UnNormalize.__init__", "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_v2.Ego4DDataset._load_metadata"], ["    ", "def", "__init__", "(", "self", ",", "*", "args", ",", "split", "=", "\"\"", ",", "**", "kwargs", ")", ":", "\n", "        ", "assert", "split", "in", "[", "\"train\"", ",", "\"val\"", ",", "\"test\"", "]", "\n", "self", ".", "split", "=", "split", "\n", "self", ".", "metadata", "=", "None", "\n", "self", ".", "cut", "=", "\"jsfusion\"", "\n", "if", "split", "==", "\"train\"", ":", "\n", "            ", "names", "=", "[", "\"msrvtt_train\"", "]", "\n", "", "elif", "split", "==", "\"val\"", ":", "\n", "            ", "names", "=", "[", "\"msrvtt_val\"", "]", "\n", "", "elif", "split", "==", "\"test\"", ":", "\n", "            ", "names", "=", "[", "\"msrvtt_val\"", "]", "\n", "", "super", "(", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ",", "names", "=", "names", ",", "text_column_name", "=", "\"caption\"", ")", "\n", "\n", "self", ".", "_load_metadata", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.msrvtt.MSRVTTDataset._load_metadata": [[25, 75], ["os.path.join", "pandas.DataFrame", "os.path.join", "pandas.read_csv", "pandas.read_csv", "[].apply", "pandas.DataFrame", "print", "open", "json.load", "os.path.join", "os.path.join", "len", "len", "len", "pandas.Series", "pandas.DataFrame", "pandas.DataFrame.apply", "numpy.load", "len", "df[].isin", "df[].isin", "pandas.DataFrame.groupby", "os.path.join", "ValueError", "msg.format"], "methods", ["None"], ["", "def", "_load_metadata", "(", "self", ")", ":", "\n", "        ", "json_fp", "=", "os", ".", "path", ".", "join", "(", "self", ".", "data_dir", ",", "'annotation'", ",", "'MSR_VTT.json'", ")", "\n", "with", "open", "(", "json_fp", ",", "'r'", ")", "as", "fid", ":", "\n", "            ", "data", "=", "json", ".", "load", "(", "fid", ")", "\n", "", "df", "=", "pd", ".", "DataFrame", "(", "data", "[", "'annotations'", "]", ")", "\n", "\n", "split_dir", "=", "os", ".", "path", ".", "join", "(", "self", ".", "data_dir", ",", "'high-quality'", ",", "'structured-symlinks'", ")", "\n", "js_test_cap_idx_path", "=", "None", "\n", "challenge_splits", "=", "{", "\"val\"", ",", "\"public_server_val\"", ",", "\"public_server_test\"", "}", "\n", "if", "self", ".", "cut", "==", "\"miech\"", ":", "# 7k", "\n", "            ", "train_list_path", "=", "\"train_list_miech.txt\"", "\n", "test_list_path", "=", "\"test_list_miech.txt\"", "# 1k", "\n", "", "elif", "self", ".", "cut", "==", "\"jsfusion\"", ":", "# 9k", "\n", "            ", "train_list_path", "=", "\"train_list_jsfusion.txt\"", "\n", "test_list_path", "=", "\"val_list_jsfusion.txt\"", "# 1k", "\n", "js_test_cap_idx_path", "=", "\"jsfusion_val_caption_idx.pkl\"", "\n", "", "elif", "self", ".", "cut", "in", "{", "\"full-val\"", ",", "\"full-test\"", "}", ":", "\n", "            ", "train_list_path", "=", "\"train_list_full.txt\"", "\n", "if", "self", ".", "cut", "==", "\"full-val\"", ":", "\n", "                ", "test_list_path", "=", "\"val_list_full.txt\"", "\n", "", "else", ":", "\n", "                ", "test_list_path", "=", "\"test_list_full.txt\"", "\n", "", "", "elif", "self", ".", "cut", "in", "challenge_splits", ":", "\n", "            ", "train_list_path", "=", "\"train_list.txt\"", "\n", "if", "self", ".", "cut", "==", "\"val\"", ":", "\n", "                ", "test_list_path", "=", "f\"{self.cut}_list.txt\"", "\n", "", "else", ":", "\n", "                ", "test_list_path", "=", "f\"{self.cut}.txt\"", "\n", "", "", "else", ":", "\n", "            ", "msg", "=", "\"unrecognised MSRVTT split: {}\"", "\n", "raise", "ValueError", "(", "msg", ".", "format", "(", "self", ".", "cut", ")", ")", "\n", "\n", "", "train_df", "=", "pd", ".", "read_csv", "(", "os", ".", "path", ".", "join", "(", "split_dir", ",", "train_list_path", ")", ",", "names", "=", "[", "'videoid'", "]", ")", "\n", "test_df", "=", "pd", ".", "read_csv", "(", "os", ".", "path", ".", "join", "(", "split_dir", ",", "test_list_path", ")", ",", "names", "=", "[", "'videoid'", "]", ")", "\n", "self", ".", "split_sizes", "=", "{", "'train'", ":", "len", "(", "train_df", ")", ",", "'val'", ":", "len", "(", "test_df", ")", ",", "'test'", ":", "len", "(", "test_df", ")", "}", "\n", "\n", "if", "self", ".", "split", "==", "'train'", ":", "\n", "            ", "df", "=", "df", "[", "df", "[", "'image_id'", "]", ".", "isin", "(", "train_df", "[", "'videoid'", "]", ")", "]", "\n", "", "else", ":", "\n", "            ", "df", "=", "df", "[", "df", "[", "'image_id'", "]", ".", "isin", "(", "test_df", "[", "'videoid'", "]", ")", "]", "\n", "\n", "", "self", ".", "metadata", "=", "df", ".", "groupby", "(", "[", "'image_id'", "]", ")", "[", "'caption'", "]", ".", "apply", "(", "list", ")", "\n", "if", "js_test_cap_idx_path", "is", "not", "None", "and", "self", ".", "split", "!=", "'train'", ":", "\n", "            ", "caps", "=", "pd", ".", "Series", "(", "np", ".", "load", "(", "os", ".", "path", ".", "join", "(", "split_dir", ",", "js_test_cap_idx_path", ")", ",", "allow_pickle", "=", "True", ")", ")", "\n", "new_res", "=", "pd", ".", "DataFrame", "(", "{", "'caps'", ":", "self", ".", "metadata", ",", "'cap_idx'", ":", "caps", "}", ")", "\n", "new_res", "[", "'test_caps'", "]", "=", "new_res", ".", "apply", "(", "lambda", "x", ":", "[", "x", "[", "'caps'", "]", "[", "x", "[", "'cap_idx'", "]", "]", "]", ",", "axis", "=", "1", ")", "\n", "self", ".", "metadata", "=", "new_res", "[", "'test_caps'", "]", "\n", "\n", "", "self", ".", "metadata", "=", "pd", ".", "DataFrame", "(", "{", "'captions'", ":", "self", ".", "metadata", "}", ")", "\n", "print", "(", "\"load split {}, {} samples\"", ".", "format", "(", "self", ".", "split", ",", "len", "(", "self", ".", "metadata", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.msrvtt.MSRVTTDataset._get_caption": [[77, 84], ["random.choice"], "methods", ["None"], ["", "def", "_get_caption", "(", "self", ",", "sample", ")", ":", "\n", "        ", "caption_sample", "=", "\"rand\"", "\n", "if", "self", ".", "split", "in", "[", "'train'", ",", "'val'", "]", "and", "caption_sample", "==", "\"rand\"", ":", "\n", "            ", "caption", "=", "random", ".", "choice", "(", "sample", "[", "'captions'", "]", ")", "\n", "", "else", ":", "\n", "            ", "caption", "=", "sample", "[", "'captions'", "]", "[", "0", "]", "\n", "", "return", "caption", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.lsmdc_choice.LSMDCChoiceDataset.__init__": [[8, 28], ["video_base_dataset.BaseDataset.__init__", "lsmdc_choice.LSMDCChoiceDataset._load_metadata"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.transforms.utils.UnNormalize.__init__", "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_v2.Ego4DDataset._load_metadata"], ["    ", "def", "__init__", "(", "self", ",", "*", "args", ",", "split", "=", "\"\"", ",", "**", "kwargs", ")", ":", "\n", "        ", "assert", "split", "in", "[", "\"train\"", ",", "\"val\"", ",", "\"test\"", "]", "\n", "self", ".", "split", "=", "split", "\n", "self", ".", "metadata", "=", "None", "\n", "self", ".", "ans_lab_dict", "=", "None", "\n", "if", "split", "==", "\"train\"", ":", "\n", "            ", "names", "=", "[", "\"lsmdc_choice_train\"", "]", "\n", "", "elif", "split", "==", "\"val\"", ":", "\n", "            ", "names", "=", "[", "\"lsmdc_choice_val\"", "]", "\n", "", "elif", "split", "==", "\"test\"", ":", "\n", "            ", "names", "=", "[", "\"lsmdc_choice_test\"", "]", "# vqav2_test-dev for test-dev", "\n", "\n", "", "super", "(", ")", ".", "__init__", "(", "\n", "*", "args", ",", "\n", "**", "kwargs", ",", "\n", "names", "=", "names", ",", "\n", "text_column_name", "=", "\"unknown\"", ",", "\n", "remove_duplicate", "=", "False", ",", "\n", ")", "\n", "self", ".", "_load_metadata", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.lsmdc_choice.LSMDCChoiceDataset._load_metadata": [[29, 58], ["print", "pandas.read_csv", "range", "print", "os.path.join", "os.path.join", "len", "sub_path.replace.replace.replace", "dict", "datalist.append", "video_fp.split", "sub_path.replace.replace.split", "len", "range"], "methods", ["None"], ["", "def", "_load_metadata", "(", "self", ")", ":", "\n", "        ", "metadata_dir", "=", "'./meta_data/lsmdc'", "\n", "split_files", "=", "{", "\n", "'train'", ":", "'LSMDC16_multiple_choice_train.csv'", ",", "\n", "'val'", ":", "'LSMDC16_multiple_choice_test_randomized.csv'", ",", "# 'LSMDC16_multiple_choice_valid.csv',", "\n", "'test'", ":", "'LSMDC16_multiple_choice_test_randomized.csv'", "\n", "}", "\n", "target_split_fp", "=", "split_files", "[", "self", ".", "split", "]", "\n", "print", "(", "os", ".", "path", ".", "join", "(", "metadata_dir", ",", "target_split_fp", ")", ")", "\n", "metadata", "=", "pd", ".", "read_csv", "(", "os", ".", "path", ".", "join", "(", "metadata_dir", ",", "target_split_fp", ")", ",", "sep", "=", "'\\t'", ",", "header", "=", "None", ",", "error_bad_lines", "=", "False", ")", "\n", "self", ".", "metadata", "=", "metadata", "\n", "datalist", "=", "[", "]", "\n", "for", "raw_id", "in", "range", "(", "len", "(", "metadata", ")", ")", ":", "\n", "            ", "raw_d", "=", "metadata", ".", "iloc", "[", "raw_id", "]", "\n", "video_fp", "=", "raw_d", "[", "0", "]", "\n", "sub_path", "=", "video_fp", ".", "split", "(", "'.'", ")", "[", "0", "]", "\n", "remove", "=", "sub_path", ".", "split", "(", "'_'", ")", "[", "-", "1", "]", "\n", "sub_path", "=", "sub_path", ".", "replace", "(", "'_'", "+", "remove", ",", "'/'", ")", "\n", "rel_video_fp", "=", "sub_path", "+", "video_fp", "+", "'.avi'", "\n", "options", "=", "[", "raw_d", "[", "idx", "]", "for", "idx", "in", "range", "(", "5", ",", "10", ")", "]", "\n", "d", "=", "dict", "(", "\n", "id", "=", "video_fp", ",", "\n", "vid_id", "=", "rel_video_fp", ",", "\n", "answer", "=", "raw_d", "[", "10", "]", "-", "1", "if", "self", ".", "split", "in", "[", "'val'", ",", "'test'", "]", "else", "0", ",", "\n", "options", "=", "options", ",", "\n", ")", "\n", "datalist", ".", "append", "(", "d", ")", "\n", "", "self", ".", "metadata", "=", "datalist", "\n", "print", "(", "\"load split {}, {} samples\"", ".", "format", "(", "self", ".", "split", ",", "len", "(", "self", ".", "metadata", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.lsmdc_choice.LSMDCChoiceDataset._get_video_path": [[59, 65], ["os.path.join"], "methods", ["None"], ["", "def", "_get_video_path", "(", "self", ",", "sample", ")", ":", "\n", "        ", "rel_video_fp", "=", "sample", "[", "'vid_id'", "]", "\n", "full_video_fp", "=", "os", ".", "path", ".", "join", "(", "self", ".", "data_dir", ",", "rel_video_fp", ")", "\n", "# print(full_video_fp)", "\n", "# assert os.path.exists(full_video_fp)", "\n", "return", "full_video_fp", ",", "rel_video_fp", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.lsmdc_choice.LSMDCChoiceDataset.get_text": [[66, 78], ["lsmdc_choice.LSMDCChoiceDataset.tokenizer", "texts.append"], "methods", ["None"], ["", "def", "get_text", "(", "self", ",", "sample", ")", ":", "\n", "        ", "texts", "=", "[", "]", "\n", "for", "text", "in", "sample", "[", "'options'", "]", ":", "\n", "            ", "encoding", "=", "self", ".", "tokenizer", "(", "\n", "text", ",", "\n", "padding", "=", "\"max_length\"", ",", "\n", "truncation", "=", "True", ",", "\n", "max_length", "=", "self", ".", "max_text_len", ",", "\n", "return_special_tokens_mask", "=", "True", ",", "\n", ")", "\n", "texts", ".", "append", "(", "(", "text", ",", "encoding", ")", ")", "\n", "", "return", "texts", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.lsmdc_choice.LSMDCChoiceDataset.get_answer_label": [[79, 82], ["None"], "methods", ["None"], ["", "def", "get_answer_label", "(", "self", ",", "sample", ")", ":", "\n", "        ", "answer", "=", "sample", "[", "'answer'", "]", "\n", "return", "answer", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.lsmdc_choice.LSMDCChoiceDataset.__getitem__": [[83, 107], ["lsmdc_choice.LSMDCChoiceDataset.get_video", "lsmdc_choice.LSMDCChoiceDataset.get_answer_label", "lsmdc_choice.LSMDCChoiceDataset.get_text", "range", "ret.update", "print", "random.randint", "len"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_v2.Ego4DDataset.get_video", "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.msvdqa.MSVDQADataset.get_answer_label", "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_v2.Ego4DDataset.get_text", "home.repos.pwc.inspect_result.showlab_all-in-one.gadgets.my_metrics.VQAScore.update"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "result", "=", "False", "\n", "while", "not", "result", ":", "\n", "            ", "try", ":", "\n", "                ", "sample", "=", "self", ".", "metadata", "[", "index", "]", "\n", "video_tensor", "=", "self", ".", "get_video", "(", "sample", ")", "\n", "qid", "=", "index", "\n", "answer", "=", "self", ".", "get_answer_label", "(", "sample", ")", "\n", "ret", "=", "{", "\n", "\"video\"", ":", "video_tensor", ",", "\n", "\"vid_index\"", ":", "index", ",", "\n", "\"cap_index\"", ":", "index", ",", "\n", "\"raw_index\"", ":", "index", ",", "\n", "'answer'", ":", "answer", "\n", "}", "\n", "texts", "=", "self", ".", "get_text", "(", "sample", ")", "\n", "ret", "[", "\"text\"", "]", "=", "texts", "[", "0", "]", "\n", "for", "i", "in", "range", "(", "self", ".", "draw_false_text", "-", "1", ")", ":", "\n", "                    ", "ret", ".", "update", "(", "{", "f\"false_text_{i}\"", ":", "texts", "[", "i", "+", "1", "]", "}", ")", "\n", "", "result", "=", "True", "\n", "", "except", "Exception", "as", "e", ":", "\n", "                ", "print", "(", "f\"Error while read file idx {sample['vid_id']} in {self.names[0]} -> {e}\"", ")", "\n", "index", "=", "random", ".", "randint", "(", "0", ",", "len", "(", "self", ".", "metadata", ")", "-", "1", ")", "\n", "", "", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.lsmdc_choice.LSMDCChoiceDataset.__len__": [[108, 110], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "metadata", ")", "", "", "", ""]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.msvdqa.MSVDQADataset.__init__": [[8, 29], ["video_base_dataset.BaseDataset.__init__", "msvdqa.MSVDQADataset._load_metadata"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.transforms.utils.UnNormalize.__init__", "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_v2.Ego4DDataset._load_metadata"], ["    ", "def", "__init__", "(", "self", ",", "*", "args", ",", "split", "=", "\"\"", ",", "**", "kwargs", ")", ":", "\n", "        ", "assert", "split", "in", "[", "\"train\"", ",", "\"val\"", ",", "\"test\"", "]", "\n", "self", ".", "split", "=", "split", "\n", "self", ".", "metadata", "=", "None", "\n", "self", ".", "ans_lab_dict", "=", "None", "\n", "if", "split", "==", "\"train\"", ":", "\n", "            ", "names", "=", "[", "\"msvd_qa_train\"", "]", "\n", "", "elif", "split", "==", "\"val\"", ":", "\n", "            ", "names", "=", "[", "\"msvd_qa_test\"", "]", "# test: directly output test result", "\n", "# [\"msvd_qa_val\"]", "\n", "", "elif", "split", "==", "\"test\"", ":", "\n", "            ", "names", "=", "[", "\"msvd_qa_test\"", "]", "# vqav2_test-dev for test-dev", "\n", "\n", "", "super", "(", ")", ".", "__init__", "(", "\n", "*", "args", ",", "\n", "**", "kwargs", ",", "\n", "names", "=", "names", ",", "\n", "text_column_name", "=", "\"questions\"", ",", "\n", "remove_duplicate", "=", "False", ",", "\n", ")", "\n", "self", ".", "_load_metadata", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.msvdqa.MSVDQADataset._load_metadata": [[30, 61], ["os.path.join", "dict", "print", "open", "f.readlines", "open", "f.readlines", "pandas.read_json", "os.path.join", "line.strip().split", "name.split", "os.path.join", "msvdqa.MSVDQADataset.metadata.update", "len", "line.strip", "str", "line.strip"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.gadgets.my_metrics.VQAScore.update"], ["", "def", "_load_metadata", "(", "self", ")", ":", "\n", "        ", "metadata_dir", "=", "'./meta_data/msvd'", "\n", "split_files", "=", "{", "\n", "'train'", ":", "'msvd_train_qa_encode.json'", ",", "\n", "'val'", ":", "'msvd_val_qa_encode.json'", ",", "\n", "'test'", ":", "'msvd_test_qa_encode.json'", "\n", "}", "\n", "# read ans dict", "\n", "self", ".", "ans_lab_dict", "=", "{", "}", "\n", "answer_fp", "=", "os", ".", "path", ".", "join", "(", "metadata_dir", ",", "'msvd_answer_set.txt'", ")", "\n", "self", ".", "youtube_mapping_dict", "=", "dict", "(", ")", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "metadata_dir", ",", "'msvd_youtube_mapping.txt'", ")", ")", "as", "f", ":", "\n", "            ", "lines", "=", "f", ".", "readlines", "(", ")", "\n", "for", "line", "in", "lines", ":", "\n", "                ", "info", "=", "line", ".", "strip", "(", ")", ".", "split", "(", "' '", ")", "\n", "self", ".", "youtube_mapping_dict", "[", "info", "[", "1", "]", "]", "=", "info", "[", "0", "]", "\n", "", "", "with", "open", "(", "answer_fp", ",", "'r'", ")", "as", "f", ":", "\n", "            ", "lines", "=", "f", ".", "readlines", "(", ")", "\n", "count", "=", "0", "\n", "for", "line", "in", "lines", ":", "\n", "                ", "self", ".", "ans_lab_dict", "[", "str", "(", "line", ".", "strip", "(", ")", ")", "]", "=", "count", "\n", "count", "+=", "1", "\n", "", "", "for", "name", "in", "self", ".", "names", ":", "\n", "            ", "split", "=", "name", ".", "split", "(", "'_'", ")", "[", "-", "1", "]", "\n", "target_split_fp", "=", "split_files", "[", "split", "]", "\n", "metadata", "=", "pd", ".", "read_json", "(", "os", ".", "path", ".", "join", "(", "metadata_dir", ",", "target_split_fp", ")", ",", "lines", "=", "True", ")", "\n", "if", "self", ".", "metadata", "is", "None", ":", "\n", "                ", "self", ".", "metadata", "=", "metadata", "\n", "", "else", ":", "\n", "                ", "self", ".", "metadata", ".", "update", "(", "metadata", ")", "\n", "", "", "print", "(", "\"total {} samples for {}\"", ".", "format", "(", "len", "(", "self", ".", "metadata", ")", ",", "self", ".", "names", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.msvdqa.MSVDQADataset._get_video_path": [[62, 67], ["os.path.join", "str"], "methods", ["None"], ["", "def", "_get_video_path", "(", "self", ",", "sample", ")", ":", "\n", "        ", "rel_video_fp", "=", "self", ".", "youtube_mapping_dict", "[", "'vid'", "+", "str", "(", "sample", "[", "\"video_id\"", "]", ")", "]", "+", "'.avi'", "\n", "# print(rel_video_fp)", "\n", "full_video_fp", "=", "os", ".", "path", ".", "join", "(", "self", ".", "data_dir", ",", "'YouTubeClips'", ",", "rel_video_fp", ")", "\n", "return", "full_video_fp", ",", "rel_video_fp", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.msvdqa.MSVDQADataset.get_text": [[68, 78], ["msvdqa.MSVDQADataset.tokenizer"], "methods", ["None"], ["", "def", "get_text", "(", "self", ",", "sample", ")", ":", "\n", "        ", "text", "=", "sample", "[", "'question'", "]", "\n", "encoding", "=", "self", ".", "tokenizer", "(", "\n", "text", ",", "\n", "padding", "=", "\"max_length\"", ",", "\n", "truncation", "=", "True", ",", "\n", "max_length", "=", "self", ".", "max_text_len", ",", "\n", "return_special_tokens_mask", "=", "True", ",", "\n", ")", "\n", "return", "(", "text", ",", "encoding", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.msvdqa.MSVDQADataset.get_answer_label": [[79, 90], ["numpy.zeros().astype", "len", "numpy.zeros"], "methods", ["None"], ["", "def", "get_answer_label", "(", "self", ",", "sample", ")", ":", "\n", "        ", "text", "=", "sample", "[", "'answer'", "]", "\n", "ans_total_len", "=", "len", "(", "self", ".", "ans_lab_dict", ")", "+", "1", "# one additional class", "\n", "try", ":", "\n", "            ", "ans_label", "=", "self", ".", "ans_lab_dict", "[", "text", "]", "#", "\n", "", "except", "KeyError", ":", "\n", "            ", "ans_label", "=", "-", "100", "# ignore classes", "\n", "# ans_label = 1500 # other classes", "\n", "", "scores", "=", "np", ".", "zeros", "(", "ans_total_len", ")", ".", "astype", "(", "int", ")", "\n", "scores", "[", "ans_label", "]", "=", "1", "\n", "return", "text", ",", "ans_label", ",", "scores", "\n", "# return text, ans_label_vector, scores", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.msvdqa.MSVDQADataset.__getitem__": [[92, 112], ["msvdqa.MSVDQADataset.get_video", "msvdqa.MSVDQADataset.get_text", "msvdqa.MSVDQADataset.get_answer_label", "list", "list", "list"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_v2.Ego4DDataset.get_video", "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_v2.Ego4DDataset.get_text", "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.msvdqa.MSVDQADataset.get_answer_label"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "sample", "=", "self", ".", "metadata", "[", "index", "]", ".", "iloc", "[", "0", "]", "\n", "video_tensor", "=", "self", ".", "get_video", "(", "sample", ")", "\n", "text", "=", "self", ".", "get_text", "(", "sample", ")", "\n", "# index, question_index = self.index_mapper[index]", "\n", "qid", "=", "index", "\n", "if", "self", ".", "split", "!=", "\"test\"", ":", "\n", "            ", "answers", ",", "labels", ",", "scores", "=", "self", ".", "get_answer_label", "(", "sample", ")", "\n", "", "else", ":", "\n", "            ", "answers", "=", "list", "(", ")", "\n", "labels", "=", "list", "(", ")", "\n", "scores", "=", "list", "(", ")", "\n", "\n", "", "return", "{", "\n", "\"video\"", ":", "video_tensor", ",", "\n", "\"text\"", ":", "text", ",", "\n", "\"vqa_answer\"", ":", "answers", ",", "\n", "\"vqa_labels\"", ":", "labels", ",", "\n", "\"vqa_scores\"", ":", "scores", ",", "\n", "\"qid\"", ":", "qid", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.msvdqa.MSVDQADataset.__len__": [[114, 116], ["sum"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "sum", "(", "1", "for", "line", "in", "self", ".", "metadata", ")", "# count # json lines", "", "", "", ""]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.lsmdc_dataset.LSMDCDataset.__init__": [[8, 21], ["lsmdc_dataset.LSMDCDataset._load_metadata", "video_base_dataset.BaseDataset.__init__"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_v2.Ego4DDataset._load_metadata", "home.repos.pwc.inspect_result.showlab_all-in-one.transforms.utils.UnNormalize.__init__"], ["    ", "def", "__init__", "(", "self", ",", "*", "args", ",", "split", "=", "\"\"", ",", "**", "kwargs", ")", ":", "\n", "        ", "assert", "split", "in", "[", "\"train\"", ",", "\"val\"", ",", "\"test\"", "]", "\n", "self", ".", "split", "=", "split", "\n", "self", ".", "metadata", "=", "None", "\n", "if", "split", "==", "\"train\"", ":", "\n", "            ", "names", "=", "[", "\"lsmdc_train\"", "]", "\n", "", "elif", "split", "==", "\"val\"", ":", "\n", "            ", "names", "=", "[", "\"lsmdc_val\"", "]", "\n", "", "elif", "split", "==", "\"test\"", ":", "\n", "            ", "names", "=", "[", "\"lsmdc_test\"", "]", "\n", "", "self", ".", "_load_metadata", "(", ")", "\n", "# self.num_frames = kwargs['num_frames']", "\n", "super", "(", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ",", "names", "=", "names", ",", "text_column_name", "=", "\"caption\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.lsmdc_dataset.LSMDCDataset._load_metadata": [[22, 33], ["pandas.read_csv", "print", "os.path.join", "len"], "methods", ["None"], ["", "def", "_load_metadata", "(", "self", ")", ":", "\n", "        ", "metadata_dir", "=", "'./meta_data/lsmdc'", "\n", "split_files", "=", "{", "\n", "'train'", ":", "'LSMDC16_annos_training.csv'", ",", "\n", "'val'", ":", "'LSMDC16_challenge_1000_publictect.csv'", ",", "# LSMDC16_annos_val.csv", "\n", "'test'", ":", "'LSMDC16_challenge_1000_publictect.csv'", "\n", "}", "\n", "target_split_fp", "=", "split_files", "[", "self", ".", "split", "]", "\n", "metadata", "=", "pd", ".", "read_csv", "(", "os", ".", "path", ".", "join", "(", "metadata_dir", ",", "target_split_fp", ")", ",", "sep", "=", "'\\t'", ",", "header", "=", "None", ",", "error_bad_lines", "=", "False", ")", "\n", "self", ".", "metadata", "=", "metadata", "\n", "print", "(", "\"load split {}, {} samples\"", ".", "format", "(", "self", ".", "split", ",", "len", "(", "metadata", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.lsmdc_dataset.LSMDCDataset._get_video_path": [[34, 40], ["os.path.join", "sample[].split"], "methods", ["None"], ["", "def", "_get_video_path", "(", "self", ",", "sample", ")", ":", "\n", "# e.g. 3009_BATTLE_LOS_ANGELES_00.03.07.170-00.03.09.675 -> 3009_BATTLE_LOS_ANGELES/3009_BATTLE_LOS_ANGELES_00.03.07.170-00.03.09.675", "\n", "        ", "sub_dir", "=", "'_'", ".", "join", "(", "sample", "[", "0", "]", ".", "split", "(", "'_'", ")", "[", ":", "-", "1", "]", ")", "\n", "rel_video_fp", "=", "sample", "[", "0", "]", "+", "'.avi'", "\n", "full_video_fp", "=", "os", ".", "path", ".", "join", "(", "self", ".", "data_dir", ",", "sub_dir", ",", "rel_video_fp", ")", "\n", "return", "full_video_fp", ",", "rel_video_fp", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.lsmdc_dataset.LSMDCDataset._get_caption": [[41, 54], ["sample[].split", "len", "random.randint", "sample[].split", "len", "random.randint"], "methods", ["None"], ["", "def", "_get_caption", "(", "self", ",", "sample", ")", ":", "\n", "        ", "if", "self", ".", "split", "==", "'train'", ":", "\n", "            ", "words", "=", "sample", "[", "0", "]", ".", "split", "(", "','", ")", "\n", "num_word", "=", "len", "(", "words", ")", "\n", "index", "=", "random", ".", "randint", "(", "0", ",", "num_word", "-", "1", ")", "\n", "caption", "=", "words", "[", "index", "]", "\n", "", "else", ":", "\n", "# caption = sample[0]", "\n", "            ", "words", "=", "sample", "[", "0", "]", ".", "split", "(", "','", ")", "\n", "num_word", "=", "len", "(", "words", ")", "\n", "index", "=", "random", ".", "randint", "(", "0", ",", "num_word", "-", "1", ")", "\n", "caption", "=", "words", "[", "index", "]", "\n", "", "return", "caption", "\n", "", "", ""]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.ego4d_v2.Ego4DDataset.__init__": [[17, 66], ["video_base_dataset.BaseDataset.__init__", "ego4d_v2.Ego4DDataset._load_metadata", "ego4d_v2.Ego4DDataset._load_metadata", "transforms.video.videoaug.VideoTransform", "float"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.transforms.utils.UnNormalize.__init__", "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_v2.Ego4DDataset._load_metadata", "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_v2.Ego4DDataset._load_metadata", "home.repos.pwc.inspect_result.showlab_all-in-one.transforms.videoaug.VideoTransform"], ["def", "__init__", "(", "self", ",", "*", "args", ",", "split", "=", "\"\"", ",", "**", "kwargs", ")", ":", "\n", "# def __init__(", "\n", "#         self,", "\n", "#         csv,", "\n", "#         video_root='',", "\n", "#         caption_root='',", "\n", "#         min_time=4.0,", "\n", "#         fps=16,", "\n", "#         num_frames=16,", "\n", "#         size=224,", "\n", "#         crop_only=False,", "\n", "#         center_crop=True,", "\n", "#         benchmark=False,", "\n", "#         token_to_word_path='data/dict.npy',", "\n", "#         max_words=20,", "\n", "#         num_candidates=1,", "\n", "#         random_left_right_flip=False,", "\n", "# ):", "\n", "#     \"\"\"", "\n", "#     Args:", "\n", "#     \"\"\"", "\n", "        ", "assert", "split", "in", "[", "\"train\"", ",", "\"val\"", ",", "\"test\"", "]", "\n", "self", ".", "split", "=", "split", "\n", "\n", "if", "split", "==", "\"train\"", ":", "\n", "            ", "names", "=", "[", "\"ego4d_train\"", "]", "\n", "", "elif", "split", "==", "\"val\"", ":", "\n", "            ", "names", "=", "[", "\"ego4d_val\"", "]", "\n", "", "elif", "split", "==", "\"test\"", ":", "\n", "            ", "names", "=", "[", "\"ego4d_test\"", "]", "\n", "", "super", "(", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ",", "names", "=", "names", ",", "text_column_name", "=", "\"caption\"", ")", "\n", "\n", "self", ".", "_load_metadata", "(", ")", "\n", "# for howto100", "\n", "self", ".", "min_time", "=", "2.0", "\n", "self", ".", "size", "=", "224", "\n", "self", ".", "fps", "=", "5", "\n", "self", ".", "num_sec", "=", "self", ".", "video_num_frames", "/", "float", "(", "self", ".", "fps", ")", "\n", "self", ".", "crop_only", "=", "False", "\n", "self", ".", "center_crop", "=", "False", "\n", "self", ".", "benchmark", "=", "False", "\n", "self", ".", "num_candidates", "=", "1", "\n", "self", ".", "random_flip", "=", "True", "\n", "# print(self.data_dir)", "\n", "# for howto caption dir", "\n", "self", ".", "_load_metadata", "(", ")", "\n", "# print(kwargs)", "\n", "# self.num_frames = kwargs['num_frames']", "\n", "self", ".", "video_transform", "=", "VideoTransform", "(", "mode", "=", "self", ".", "split", ",", "num_frames", "=", "self", ".", "num_frames", ")", "# train or val model", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.ego4d_v2.Ego4DDataset._load_metadata": [[67, 80], ["list", "open", "json.load", "json.load.keys", "os.path.join"], "methods", ["None"], ["", "def", "_load_metadata", "(", "self", ")", ":", "\n", "        ", "metadata_dir", "=", "'./meta_data'", "\n", "split_files", "=", "{", "\n", "'train'", ":", "'ego4d/narration.json'", ",", "\n", "'val'", ":", "'ego4d/narration.json'", ",", "# there is no test", "\n", "'test'", ":", "'ego4d/narration.json'", "\n", "}", "\n", "target_split_fp", "=", "split_files", "[", "self", ".", "split", "]", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "metadata_dir", ",", "target_split_fp", ")", ",", "'r'", ")", "as", "jsonfile", ":", "\n", "            ", "metadata", "=", "json", ".", "load", "(", "jsonfile", ")", "\n", "# metadata = pd.read_csv(os.path.join(metadata_dir, target_split_fp), sep='\\t')", "\n", "", "self", ".", "metadata", "=", "metadata", "\n", "self", ".", "meta_keys", "=", "list", "(", "metadata", ".", "keys", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.ego4d_v2.Ego4DDataset.__len__": [[263, 265], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "metadata", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.ego4d_v2.Ego4DDataset.get_video_len": [[84, 91], ["subprocess.check_output", "float", "str"], "methods", ["None"], ["", "def", "get_video_len", "(", "self", ",", "video_path", ")", ":", "\n", "        ", "duration", "=", "subprocess", ".", "check_output", "(", "\n", "[", "'ffprobe'", ",", "'-i'", ",", "video_path", ",", "'-show_entries'", ",", "'format=duration'", ",", "'-v'", ",", "'quiet'", ",", "'-of'", ",", "\n", "'csv=%s'", "%", "(", "\"p=0\"", ")", "]", ")", "\n", "# print(\"ffmpeg duration is: {}\".format(duration))", "\n", "duration", "=", "float", "(", "str", "(", "duration", ")", "[", "2", ":", "-", "3", "]", ")", "# b'1027.806000\\n' -> 1027.806", "\n", "return", "duration", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.ego4d_v2.Ego4DDataset.read_frames_ffmpeg": [[92, 144], ["int", "int", "random.randint", "max", "ffmpeg.input().filter", "cmd.hflip.hflip.output().run", "numpy.frombuffer().reshape", "torch.from_numpy", "max", "min", "int", "cmd.hflip.hflip.crop", "cmd.hflip.hflip.crop().filter", "cmd.hflip.hflip.hflip", "numpy.copy", "torch.cat.permute", "print", "torch.ones", "torch.cat", "max", "ffmpeg.input", "random.uniform", "random.uniform", "str", "str", "random.uniform", "cmd.hflip.hflip.output", "numpy.frombuffer", "torch.cat.size", "torch.cat.size", "cmd.hflip.hflip.crop"], "methods", ["None"], ["", "def", "read_frames_ffmpeg", "(", "self", ",", "video_path", ",", "center", ",", "video_len", ")", ":", "\n", "        ", "if", "center", ">", "video_len", ":", "\n", "            ", "center", "=", "video_len", "-", "2", "*", "self", ".", "num_sec", "\n", "", "start", "=", "int", "(", "max", "(", "0", ",", "center", "-", "self", ".", "min_time", ")", ")", "\n", "end", "=", "int", "(", "min", "(", "video_len", ",", "center", "+", "self", ".", "min_time", ")", ")", "\n", "start_seek", "=", "random", ".", "randint", "(", "start", ",", "int", "(", "max", "(", "start", ",", "end", "-", "self", ".", "num_sec", ")", ")", ")", "\n", "# video is too short", "\n", "if", "video_len", "<", "1", ":", "\n", "            ", "start_seek", "=", "0", "\n", "", "if", "start_seek", "+", "self", ".", "num_sec", "+", "0.1", ">", "video_len", ":", "\n", "            ", "start_seek", "=", "video_len", "-", "self", ".", "num_sec", "-", "0.1", "\n", "", "start_seek", "=", "max", "(", "start_seek", ",", "0", ")", "\n", "cmd", "=", "(", "\n", "ffmpeg", "\n", ".", "input", "(", "video_path", ",", "ss", "=", "start_seek", ",", "t", "=", "self", ".", "num_sec", "+", "0.01", ")", "\n", ".", "filter", "(", "'fps'", ",", "fps", "=", "self", ".", "fps", ")", "\n", ")", "\n", "if", "self", ".", "center_crop", ":", "\n", "            ", "aw", ",", "ah", "=", "0.5", ",", "0.5", "\n", "", "else", ":", "\n", "            ", "aw", ",", "ah", "=", "random", ".", "uniform", "(", "0", ",", "1", ")", ",", "random", ".", "uniform", "(", "0", ",", "1", ")", "\n", "", "if", "self", ".", "crop_only", ":", "\n", "            ", "cmd", "=", "(", "\n", "cmd", ".", "crop", "(", "'(iw - {})*{}'", ".", "format", "(", "self", ".", "size", ",", "aw", ")", ",", "\n", "'(ih - {})*{}'", ".", "format", "(", "self", ".", "size", ",", "ah", ")", ",", "\n", "str", "(", "self", ".", "size", ")", ",", "str", "(", "self", ".", "size", ")", ")", "\n", ")", "\n", "", "else", ":", "\n", "            ", "cmd", "=", "(", "\n", "cmd", ".", "crop", "(", "'(iw - min(iw,ih))*{}'", ".", "format", "(", "aw", ")", ",", "\n", "'(ih - min(iw,ih))*{}'", ".", "format", "(", "ah", ")", ",", "\n", "'min(iw,ih)'", ",", "\n", "'min(iw,ih)'", ")", "\n", ".", "filter", "(", "'scale'", ",", "self", ".", "size", ",", "self", ".", "size", ")", "\n", ")", "\n", "", "if", "self", ".", "random_flip", "and", "random", ".", "uniform", "(", "0", ",", "1", ")", ">", "0.5", ":", "\n", "            ", "cmd", "=", "cmd", ".", "hflip", "(", ")", "\n", "", "out", ",", "_", "=", "(", "\n", "cmd", ".", "output", "(", "'pipe:'", ",", "format", "=", "'rawvideo'", ",", "pix_fmt", "=", "'rgb24'", ")", "\n", ".", "run", "(", "capture_stdout", "=", "True", ",", "quiet", "=", "True", ")", "\n", ")", "\n", "video", "=", "np", ".", "frombuffer", "(", "out", ",", "np", ".", "uint8", ")", ".", "reshape", "(", "[", "-", "1", ",", "self", ".", "size", ",", "self", ".", "size", ",", "3", "]", ")", "\n", "video_tensor", "=", "th", ".", "from_numpy", "(", "np", ".", "copy", "(", "video", ")", ")", "\n", "video_tensor", "=", "video_tensor", ".", "permute", "(", "3", ",", "0", ",", "1", ",", "2", ")", "+", "0.01", "\n", "if", "video_tensor", ".", "size", "(", ")", "[", "1", "]", "!=", "self", ".", "num_frames", ":", "\n", "            ", "print", "(", "video_tensor", ".", "size", "(", ")", ",", "start", ",", "end", ",", "start_seek", ",", "video_len", ")", "\n", "# print(\"video length: {}\".format(self.get_video_len_from_timestammp()))", "\n", "# add gausian noise here to prevent all blank boxez", "\n", "", "if", "video_tensor", ".", "shape", "[", "1", "]", "<", "self", ".", "num_frames", ":", "\n", "            ", "zeros", "=", "th", ".", "ones", "(", "(", "3", ",", "self", ".", "num_frames", "-", "video_tensor", ".", "shape", "[", "1", "]", ",", "self", ".", "size", ",", "self", ".", "size", ")", ",", "dtype", "=", "th", ".", "uint8", ")", "\n", "video_tensor", "=", "th", ".", "cat", "(", "(", "video_tensor", ",", "zeros", ")", ",", "axis", "=", "1", ")", "\n", "", "return", "video_tensor", "[", ":", ",", ":", "self", ".", "num_frames", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.ego4d_v2.Ego4DDataset._zero_pad_tensor_token": [[145, 151], ["len", "torch.zeros().long", "torch.cat", "torch.zeros", "len"], "methods", ["None"], ["", "def", "_zero_pad_tensor_token", "(", "self", ",", "tensor", ",", "size", ")", ":", "\n", "        ", "if", "len", "(", "tensor", ")", ">=", "size", ":", "\n", "            ", "return", "tensor", "[", ":", "size", "]", "\n", "", "else", ":", "\n", "            ", "zero", "=", "th", ".", "zeros", "(", "size", "-", "len", "(", "tensor", ")", ")", ".", "long", "(", ")", "\n", "return", "th", ".", "cat", "(", "(", "tensor", ",", "zero", ")", ",", "dim", "=", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.ego4d_v2.Ego4DDataset.get_text": [[152, 167], ["ego4d_v2.Ego4DDataset.tokenizer"], "methods", ["None"], ["", "", "def", "get_text", "(", "self", ",", "sample", ",", "index", ")", ":", "\n", "        ", "text", "=", "sample", "[", "'narration_text'", "]", "\n", "# TODO: May need to be improved for edge cases.", "\n", "encoding", "=", "self", ".", "tokenizer", "(", "\n", "text", ",", "\n", "padding", "=", "\"max_length\"", ",", "\n", "truncation", "=", "True", ",", "\n", "max_length", "=", "self", ".", "max_text_len", ",", "\n", "return_special_tokens_mask", "=", "True", ",", "\n", ")", "\n", "return", "{", "\n", "\"text\"", ":", "(", "text", ",", "encoding", ")", ",", "\n", "\"img_index\"", ":", "index", ",", "\n", "\"cap_index\"", ":", "index", ",", "\n", "\"raw_index\"", ":", "index", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.ego4d_v2.Ego4DDataset.get_false_text": [[169, 186], ["random.randint", "ego4d_v2.Ego4DDataset.tokenizer", "random.random", "len", "random.randint", "len"], "methods", ["None"], ["", "def", "get_false_text", "(", "self", ",", "rep", ")", ":", "\n", "        ", "random_index", "=", "random", ".", "randint", "(", "0", ",", "len", "(", "self", ".", "metadata", ")", "-", "1", ")", "\n", "# two annotations", "\n", "if", "random", ".", "random", "(", ")", "<", "0.5", ":", "\n", "            ", "meta", "=", "self", ".", "metadata", "[", "self", ".", "meta_keys", "[", "random_index", "]", "]", "[", "'narration_pass_1'", "]", "\n", "", "else", ":", "\n", "            ", "meta", "=", "self", ".", "metadata", "[", "self", ".", "meta_keys", "[", "random_index", "]", "]", "[", "'narration_pass_2'", "]", "\n", "", "sample", "=", "meta", "[", "random", ".", "randint", "(", "0", ",", "len", "(", "meta", ")", "-", "1", ")", "]", "# random choice one sample", "\n", "text", "=", "sample", "[", "'narration_text'", "]", "\n", "encoding", "=", "self", ".", "tokenizer", "(", "\n", "text", ",", "\n", "# padding=\"max_length\",", "\n", "truncation", "=", "True", ",", "\n", "max_length", "=", "self", ".", "max_text_len", ",", "\n", "return_special_tokens_mask", "=", "True", ",", "\n", ")", "\n", "return", "{", "f\"false_text_{rep}\"", ":", "(", "text", ",", "encoding", ")", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.ego4d_v2.Ego4DDataset._get_video_path": [[187, 193], ["os.path.join", "os.path.exists", "Exception"], "methods", ["None"], ["", "def", "_get_video_path", "(", "self", ",", "sample", ")", ":", "\n", "        ", "rel_video_fp", "=", "sample", "[", "\"video_path\"", "]", "+", "'.mp4'", "\n", "full_video_fp", "=", "os", ".", "path", ".", "join", "(", "self", ".", "data_dir", ",", "rel_video_fp", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "full_video_fp", ")", ":", "\n", "            ", "Exception", "(", "IOError", ")", "\n", "", "return", "full_video_fp", ",", "rel_video_fp", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.ego4d_v2.Ego4DDataset.get_raw_video": [[194, 206], ["ego4d_v2.Ego4DDataset._get_video_path", "ego4d_v2.Ego4DDataset.get_video_len", "ego4d_v2.Ego4DDataset.read_frames_ffmpeg().permute", "Exception", "ego4d_v2.Ego4DDataset.read_frames_ffmpeg"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_v2.Ego4DDataset._get_video_path", "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_v2.Ego4DDataset.get_video_len", "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_v2.Ego4DDataset.read_frames_ffmpeg"], ["", "def", "get_raw_video", "(", "self", ",", "sample", ")", ":", "\n", "        ", "abs_fp", ",", "rel_fp", "=", "self", ".", "_get_video_path", "(", "sample", ")", "\n", "# in four seconds", "\n", "# print(sample)", "\n", "sample", "[", "\"video_len\"", "]", "=", "self", ".", "get_video_len", "(", "abs_fp", ")", "\n", "center", "=", "sample", "[", "'timestamp_sec'", "]", "\n", "imgs", "=", "self", ".", "read_frames_ffmpeg", "(", "abs_fp", ",", "center", ",", "sample", "[", "\"video_len\"", "]", ")", ".", "permute", "(", "1", ",", "0", ",", "2", ",", "3", ")", "\n", "# print(imgs.size())", "\n", "if", "imgs", "is", "None", ":", "\n", "            ", "raise", "Exception", "(", "\"Invalid video!\"", ",", "rel_fp", ")", "\n", "", "else", ":", "\n", "            ", "return", "imgs", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.ego4d_v2.Ego4DDataset.get_video": [[207, 210], ["ego4d_v2.Ego4DDataset.get_raw_video"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_v2.Ego4DDataset.get_raw_video"], ["", "", "def", "get_video", "(", "self", ",", "sample", ")", ":", "\n", "        ", "imgs_tensor", "=", "self", ".", "get_raw_video", "(", "sample", ")", "\n", "return", "imgs_tensor", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.ego4d_v2.Ego4DDataset.get_false_video": [[211, 224], ["random.randint", "ego4d_v2.Ego4DDataset.get_raw_video", "random.random", "len", "ego4d_v2.Ego4DDataset.get_false_video", "len", "random.randint", "len"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_v2.Ego4DDataset.get_raw_video", "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_v2.Ego4DDataset.get_false_video"], ["", "def", "get_false_video", "(", "self", ",", "rep", ")", ":", "\n", "        ", "random_index", "=", "random", ".", "randint", "(", "0", ",", "len", "(", "self", ".", "metadata", ")", "-", "1", ")", "\n", "# two annotations", "\n", "if", "random", ".", "random", "(", ")", "<", "0.5", ":", "\n", "            ", "meta", "=", "self", ".", "metadata", "[", "self", ".", "meta_keys", "[", "random_index", "]", "]", "[", "'narration_pass_1'", "]", "\n", "", "else", ":", "\n", "            ", "meta", "=", "self", ".", "metadata", "[", "self", ".", "meta_keys", "[", "random_index", "]", "]", "[", "'narration_pass_2'", "]", "\n", "", "if", "len", "(", "meta", ")", "<", "1", ":", "\n", "            ", "return", "self", ".", "get_false_video", "(", "rep", ")", "\n", "", "sample", "=", "meta", "[", "random", ".", "randint", "(", "0", ",", "len", "(", "meta", ")", "-", "1", ")", "]", "# random choice one sample", "\n", "sample", "[", "\"video_path\"", "]", "=", "self", ".", "meta_keys", "[", "random_index", "]", "# video path", "\n", "imgs_tensor", "=", "self", ".", "get_raw_video", "(", "sample", ")", "\n", "return", "{", "f\"false_image_{rep}\"", ":", "imgs_tensor", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.ego4d_v2.Ego4DDataset.get_suite": [[225, 262], ["dict", "ego4d_v2.Ego4DDataset.get_text", "dict.update", "dict.update", "ego4d_v2.Ego4DDataset.get_video", "dict.update", "dict.update", "range", "range", "random.random", "len", "random.randint", "ego4d_v2.Ego4DDataset.get_suite", "dict.update", "dict.update", "random.randint", "random.randint", "ego4d_v2.Ego4DDataset.get_false_video", "ego4d_v2.Ego4DDataset.get_false_text", "len", "len", "len"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_v2.Ego4DDataset.get_text", "home.repos.pwc.inspect_result.showlab_all-in-one.gadgets.my_metrics.VQAScore.update", "home.repos.pwc.inspect_result.showlab_all-in-one.gadgets.my_metrics.VQAScore.update", "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_v2.Ego4DDataset.get_video", "home.repos.pwc.inspect_result.showlab_all-in-one.gadgets.my_metrics.VQAScore.update", "home.repos.pwc.inspect_result.showlab_all-in-one.gadgets.my_metrics.VQAScore.update", "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_v2.Ego4DDataset.get_suite", "home.repos.pwc.inspect_result.showlab_all-in-one.gadgets.my_metrics.VQAScore.update", "home.repos.pwc.inspect_result.showlab_all-in-one.gadgets.my_metrics.VQAScore.update", "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_v2.Ego4DDataset.get_false_video", "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_v2.Ego4DDataset.get_false_text"], ["", "def", "get_suite", "(", "self", ",", "index", ")", ":", "\n", "        ", "result", "=", "None", "\n", "while", "result", "is", "None", ":", "\n", "# two annotations", "\n", "            ", "try", ":", "\n", "                ", "if", "random", ".", "random", "(", ")", "<", "0.5", ":", "\n", "                    ", "meta", "=", "self", ".", "metadata", "[", "self", ".", "meta_keys", "[", "index", "]", "]", "[", "'narration_pass_1'", "]", "\n", "", "else", ":", "\n", "                    ", "meta", "=", "self", ".", "metadata", "[", "self", ".", "meta_keys", "[", "index", "]", "]", "[", "'narration_pass_2'", "]", "\n", "", "if", "len", "(", "meta", ")", "<", "2", ":", "\n", "                    ", "random_index", "=", "random", ".", "randint", "(", "0", ",", "len", "(", "self", ".", "metadata", ")", "-", "1", ")", "\n", "return", "self", ".", "get_suite", "(", "random_index", ")", "\n", "", "sample", "=", "meta", "[", "random", ".", "randint", "(", "0", ",", "len", "(", "meta", ")", "-", "1", ")", "]", "# random choice one sample", "\n", "sample", "[", "\"video_path\"", "]", "=", "self", ".", "meta_keys", "[", "index", "]", "# video path", "\n", "# print(sample)", "\n", "ret", "=", "dict", "(", ")", "\n", "text", "=", "self", ".", "get_text", "(", "sample", ",", "index", ")", "\n", "ret", ".", "update", "(", "{", "\"replica\"", ":", "True", "if", "text", "[", "\"cap_index\"", "]", ">", "0", "else", "False", "}", ")", "\n", "ret", ".", "update", "(", "text", ")", "\n", "imgs_tensor", "=", "self", ".", "get_video", "(", "sample", ")", "\n", "# print(imgs_tensor.size())", "\n", "ret", ".", "update", "(", "{", "\n", "\"image\"", ":", "imgs_tensor", ",", "\n", "\"img_index\"", ":", "index", ",", "\n", "\"cap_index\"", ":", "index", ",", "\n", "\"raw_index\"", ":", "index", ",", "\n", "}", ")", "\n", "ret", ".", "update", "(", "{", "\"replica\"", ":", "True", "if", "ret", "[", "\"cap_index\"", "]", ">", "0", "else", "False", "}", ")", "\n", "for", "i", "in", "range", "(", "self", ".", "draw_false_image", ")", ":", "\n", "                    ", "ret", ".", "update", "(", "self", ".", "get_false_video", "(", "i", ")", ")", "\n", "", "for", "i", "in", "range", "(", "self", ".", "draw_false_text", ")", ":", "\n", "                    ", "ret", ".", "update", "(", "self", ".", "get_false_text", "(", "i", ")", ")", "\n", "", "result", "=", "True", "\n", "", "except", "Exception", "as", "e", ":", "\n", "# print(e)", "\n", "                ", "index", "=", "random", ".", "randint", "(", "0", ",", "len", "(", "self", ".", "metadata", ")", "-", "1", ")", "\n", "", "", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.ego4d_v2.Ego4DDataset.__getitem__": [[266, 268], ["ego4d_v2.Ego4DDataset.get_suite"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_v2.Ego4DDataset.get_suite"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "return", "self", ".", "get_suite", "(", "index", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.video_transform.ClipToTensor.__init__": [[29, 33], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "channel_nb", "=", "3", ",", "div_255", "=", "True", ",", "numpy", "=", "False", ")", ":", "\n", "        ", "self", ".", "channel_nb", "=", "channel_nb", "\n", "self", ".", "div_255", "=", "div_255", "\n", "self", ".", "numpy", "=", "numpy", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.video_transform.ClipToTensor.__call__": [[34, 76], ["isinstance", "numpy.zeros", "enumerate", "isinstance", "isinstance", "video_transform.convert_img", "torch.from_numpy", "TypeError", "len", "int", "int", "isinstance", "isinstance", "tensor_clip.div.div.float", "tensor_clip.div.div.div", "numpy.array", "TypeError", "type", "type"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.transforms.video_transform.convert_img"], ["", "def", "__call__", "(", "self", ",", "clip", ")", ":", "\n", "        ", "\"\"\"\n        Args: clip_test (list of numpy.ndarray): clip_test (list of images)\n        to be converted to tensor.\n        \"\"\"", "\n", "# Retrieve shape", "\n", "if", "isinstance", "(", "clip", "[", "0", "]", ",", "np", ".", "ndarray", ")", ":", "\n", "            ", "h", ",", "w", ",", "ch", "=", "clip", "[", "0", "]", ".", "shape", "\n", "assert", "ch", "==", "self", ".", "channel_nb", ",", "'Got {0} instead of 3 channels'", ".", "format", "(", "\n", "ch", ")", "\n", "", "elif", "isinstance", "(", "clip", "[", "0", "]", ",", "Image", ".", "Image", ")", ":", "\n", "            ", "w", ",", "h", "=", "clip", "[", "0", "]", ".", "size", "\n", "", "else", ":", "\n", "            ", "raise", "TypeError", "(", "'Expected numpy.ndarray or PIL.Image\\\n            but got list of {0}'", ".", "format", "(", "type", "(", "clip", "[", "0", "]", ")", ")", ")", "\n", "\n", "", "np_clip", "=", "np", ".", "zeros", "(", "[", "self", ".", "channel_nb", ",", "len", "(", "clip", ")", ",", "int", "(", "h", ")", ",", "int", "(", "w", ")", "]", ")", "\n", "\n", "# Convert", "\n", "for", "img_idx", ",", "img", "in", "enumerate", "(", "clip", ")", ":", "\n", "            ", "if", "isinstance", "(", "img", ",", "np", ".", "ndarray", ")", ":", "\n", "                ", "pass", "\n", "", "elif", "isinstance", "(", "img", ",", "Image", ".", "Image", ")", ":", "\n", "                ", "img", "=", "np", ".", "array", "(", "img", ",", "copy", "=", "False", ")", "\n", "", "else", ":", "\n", "                ", "raise", "TypeError", "(", "'Expected numpy.ndarray or PIL.Image\\\n                but got list of {0}'", ".", "format", "(", "type", "(", "clip", "[", "0", "]", ")", ")", ")", "\n", "", "img", "=", "convert_img", "(", "img", ")", "\n", "np_clip", "[", ":", ",", "img_idx", ",", ":", ",", ":", "]", "=", "img", "\n", "", "if", "self", ".", "numpy", ":", "\n", "            ", "if", "self", ".", "div_255", ":", "\n", "                ", "np_clip", "=", "np_clip", "/", "255", "\n", "", "return", "np_clip", "\n", "\n", "", "else", ":", "\n", "            ", "tensor_clip", "=", "torch", ".", "from_numpy", "(", "np_clip", ")", "\n", "\n", "if", "not", "isinstance", "(", "tensor_clip", ",", "torch", ".", "FloatTensor", ")", ":", "\n", "                ", "tensor_clip", "=", "tensor_clip", ".", "float", "(", ")", "\n", "", "if", "self", ".", "div_255", ":", "\n", "                ", "tensor_clip", "=", "tensor_clip", ".", "div", "(", "255", ")", "\n", "", "return", "tensor_clip", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.video_transform.ToTensor.__call__": [[82, 85], ["torch.from_numpy"], "methods", ["None"], ["def", "__call__", "(", "self", ",", "array", ")", ":", "\n", "        ", "tensor", "=", "torch", ".", "from_numpy", "(", "array", ")", "\n", "return", "tensor", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.video_transform.ColorDistortion.__init__": [[87, 92], ["torchvision.transforms.ColorJitter", "torchvision.transforms.RandomApply", "torchvision.transforms.RandomGrayscale"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "s", "=", "1.0", ")", ":", "\n", "        ", "self", ".", "s", "=", "s", "\n", "self", ".", "color_jitter", "=", "transforms", ".", "ColorJitter", "(", "0.8", "*", "s", ",", "0.8", "*", "s", ",", "0.8", "*", "s", ",", "0.2", "*", "s", ")", "\n", "self", ".", "rnd_color_jitter", "=", "transforms", ".", "RandomApply", "(", "[", "self", ".", "color_jitter", "]", ",", "p", "=", "0.8", ")", "\n", "self", ".", "rnd_gray", "=", "transforms", ".", "RandomGrayscale", "(", "p", "=", "0.2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.video_transform.ColorDistortion.__call__": [[93, 96], ["torchvision.transforms.Compose", "torchvision.transforms.Compose."], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "video", ")", ":", "\n", "        ", "color_distort", "=", "transforms", ".", "Compose", "(", "[", "self", ".", "rnd_color_jitter", ",", "self", ".", "rnd_gray", "]", ")", "\n", "return", "color_distort", "(", "video", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.video_transform.Compose.__init__": [[105, 107], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "transforms", ")", ":", "\n", "        ", "self", ".", "transforms", "=", "transforms", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.video_transform.Compose.__call__": [[108, 112], ["t"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "clip", ")", ":", "\n", "        ", "for", "t", "in", "self", ".", "transforms", ":", "\n", "            ", "clip", "=", "t", "(", "clip", ")", "\n", "", "return", "clip", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.video_transform.RandomHorizontalFlip.__call__": [[119, 138], ["random.random", "isinstance", "isinstance", "numpy.fliplr", "TypeError", "img.transpose", "type"], "methods", ["None"], ["def", "__call__", "(", "self", ",", "clip", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n        img (PIL.Image or numpy.ndarray): List of images to be cropped\n        in format (h, w, c) in numpy.ndarray\n        Returns:\n        PIL.Image or numpy.ndarray: Randomly flipped clip_test\n        \"\"\"", "\n", "if", "random", ".", "random", "(", ")", "<", "0.5", ":", "\n", "            ", "if", "isinstance", "(", "clip", "[", "0", "]", ",", "np", ".", "ndarray", ")", ":", "\n", "                ", "return", "[", "np", ".", "fliplr", "(", "img", ")", "for", "img", "in", "clip", "]", "\n", "", "elif", "isinstance", "(", "clip", "[", "0", "]", ",", "PIL", ".", "Image", ".", "Image", ")", ":", "\n", "                ", "return", "[", "\n", "img", ".", "transpose", "(", "PIL", ".", "Image", ".", "FLIP_LEFT_RIGHT", ")", "for", "img", "in", "clip", "\n", "]", "\n", "", "else", ":", "\n", "                ", "raise", "TypeError", "(", "'Expected numpy.ndarray or PIL.Image'", "+", "\n", "' but got list of {0}'", ".", "format", "(", "type", "(", "clip", "[", "0", "]", ")", ")", ")", "\n", "", "", "return", "clip", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.video_transform.RandomResize.__init__": [[150, 153], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "ratio", "=", "(", "3.", "/", "4.", ",", "4.", "/", "3.", ")", ",", "interpolation", "=", "'nearest'", ")", ":", "\n", "        ", "self", ".", "ratio", "=", "ratio", "\n", "self", ".", "interpolation", "=", "interpolation", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.video_transform.RandomResize.__call__": [[154, 168], ["random.uniform", "isinstance", "int", "int", "CoTrain.transforms.image.functional.resize_clip", "isinstance"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.transforms.functional.resize_clip"], ["", "def", "__call__", "(", "self", ",", "clip", ")", ":", "\n", "        ", "scaling_factor", "=", "random", ".", "uniform", "(", "self", ".", "ratio", "[", "0", "]", ",", "self", ".", "ratio", "[", "1", "]", ")", "\n", "\n", "if", "isinstance", "(", "clip", "[", "0", "]", ",", "np", ".", "ndarray", ")", ":", "\n", "            ", "im_h", ",", "im_w", ",", "im_c", "=", "clip", "[", "0", "]", ".", "shape", "\n", "", "elif", "isinstance", "(", "clip", "[", "0", "]", ",", "PIL", ".", "Image", ".", "Image", ")", ":", "\n", "            ", "im_w", ",", "im_h", "=", "clip", "[", "0", "]", ".", "size", "\n", "\n", "", "new_w", "=", "int", "(", "im_w", "*", "scaling_factor", ")", "\n", "new_h", "=", "int", "(", "im_h", "*", "scaling_factor", ")", "\n", "new_size", "=", "(", "new_w", ",", "new_h", ")", "\n", "resized", "=", "F", ".", "resize_clip", "(", "\n", "clip", ",", "new_size", ",", "interpolation", "=", "self", ".", "interpolation", ")", "\n", "return", "resized", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.video_transform.Resize.__init__": [[180, 183], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "size", ",", "interpolation", "=", "'nearest'", ")", ":", "\n", "        ", "self", ".", "size", "=", "size", "\n", "self", ".", "interpolation", "=", "interpolation", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.video_transform.Resize.__call__": [[184, 188], ["CoTrain.transforms.image.functional.resize_clip"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.transforms.functional.resize_clip"], ["", "def", "__call__", "(", "self", ",", "clip", ")", ":", "\n", "        ", "resized", "=", "F", ".", "resize_clip", "(", "\n", "clip", ",", "self", ".", "size", ",", "interpolation", "=", "self", ".", "interpolation", ")", "\n", "return", "resized", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.video_transform.RandomCrop.__init__": [[197, 202], ["isinstance"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "size", ")", ":", "\n", "        ", "if", "isinstance", "(", "size", ",", "numbers", ".", "Number", ")", ":", "\n", "            ", "size", "=", "(", "size", ",", "size", ")", "\n", "\n", "", "self", ".", "size", "=", "size", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.video_transform.RandomCrop.__call__": [[203, 232], ["isinstance", "random.randint", "random.randint", "CoTrain.transforms.image.functional.crop_clip", "isinstance", "ValueError", "TypeError", "type"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.transforms.functional.crop_clip"], ["", "def", "__call__", "(", "self", ",", "clip", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n        img (PIL.Image or numpy.ndarray): List of images to be cropped\n        in format (h, w, c) in numpy.ndarray\n        Returns:\n        PIL.Image or numpy.ndarray: Cropped list of images\n        \"\"\"", "\n", "h", ",", "w", "=", "self", ".", "size", "\n", "if", "isinstance", "(", "clip", "[", "0", "]", ",", "np", ".", "ndarray", ")", ":", "\n", "            ", "im_h", ",", "im_w", ",", "im_c", "=", "clip", "[", "0", "]", ".", "shape", "\n", "", "elif", "isinstance", "(", "clip", "[", "0", "]", ",", "PIL", ".", "Image", ".", "Image", ")", ":", "\n", "            ", "im_w", ",", "im_h", "=", "clip", "[", "0", "]", ".", "size", "\n", "", "else", ":", "\n", "            ", "raise", "TypeError", "(", "'Expected numpy.ndarray or PIL.Image'", "+", "\n", "'but got list of {0}'", ".", "format", "(", "type", "(", "clip", "[", "0", "]", ")", ")", ")", "\n", "", "if", "w", ">", "im_w", "or", "h", ">", "im_h", ":", "\n", "            ", "error_msg", "=", "(", "\n", "'Initial image size should be larger then '", "\n", "'cropped size but got cropped sizes : ({w}, {h}) while '", "\n", "'initial image is ({im_w}, {im_h})'", ".", "format", "(", "\n", "im_w", "=", "im_w", ",", "im_h", "=", "im_h", ",", "w", "=", "w", ",", "h", "=", "h", ")", ")", "\n", "raise", "ValueError", "(", "error_msg", ")", "\n", "\n", "", "x1", "=", "random", ".", "randint", "(", "0", ",", "im_w", "-", "w", ")", "\n", "y1", "=", "random", ".", "randint", "(", "0", ",", "im_h", "-", "h", ")", "\n", "cropped", "=", "F", ".", "crop_clip", "(", "clip", ",", "y1", ",", "x1", ",", "h", ",", "w", ")", "\n", "\n", "return", "cropped", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.video_transform.CornerCrop.__init__": [[236, 244], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "size", ",", "crop_position", "=", "None", ")", ":", "\n", "        ", "self", ".", "size", "=", "size", "\n", "if", "crop_position", "is", "None", ":", "\n", "            ", "self", ".", "randomize", "=", "True", "\n", "", "else", ":", "\n", "            ", "self", ".", "randomize", "=", "False", "\n", "", "self", ".", "crop_position", "=", "crop_position", "\n", "self", ".", "crop_positions", "=", "[", "'c'", ",", "'tl'", ",", "'tr'", ",", "'bl'", ",", "'br'", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.video_transform.CornerCrop.__call__": [[245, 278], ["list", "list.append", "int", "int", "round", "round"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "imgs", ")", ":", "\n", "        ", "t", ",", "h", ",", "w", ",", "c", "=", "imgs", ".", "shape", "\n", "corner_imgs", "=", "list", "(", ")", "\n", "for", "n", "in", "self", ".", "crop_positions", ":", "\n", "#print(n)", "\n", "            ", "if", "n", "==", "'c'", ":", "\n", "                ", "th", ",", "tw", "=", "(", "self", ".", "size", ",", "self", ".", "size", ")", "\n", "x1", "=", "int", "(", "round", "(", "(", "w", "-", "tw", ")", "/", "2.", ")", ")", "\n", "y1", "=", "int", "(", "round", "(", "(", "h", "-", "th", ")", "/", "2.", ")", ")", "\n", "x2", "=", "x1", "+", "tw", "\n", "y2", "=", "y1", "+", "th", "\n", "", "elif", "n", "==", "'tl'", ":", "\n", "                ", "x1", "=", "0", "\n", "y1", "=", "0", "\n", "x2", "=", "self", ".", "size", "\n", "y2", "=", "self", ".", "size", "\n", "", "elif", "n", "==", "'tr'", ":", "\n", "                ", "x1", "=", "w", "-", "self", ".", "size", "\n", "y1", "=", "0", "\n", "x2", "=", "w", "\n", "y2", "=", "self", ".", "size", "\n", "", "elif", "n", "==", "'bl'", ":", "\n", "                ", "x1", "=", "0", "\n", "y1", "=", "h", "-", "self", ".", "size", "\n", "x2", "=", "self", ".", "size", "\n", "y2", "=", "h", "\n", "", "elif", "n", "==", "'br'", ":", "\n", "                ", "x1", "=", "w", "-", "self", ".", "size", "\n", "y1", "=", "h", "-", "self", ".", "size", "\n", "x2", "=", "w", "\n", "y2", "=", "h", "\n", "", "corner_imgs", ".", "append", "(", "imgs", "[", ":", ",", "y1", ":", "y2", ",", "x1", ":", "x2", ",", ":", "]", ")", "\n", "", "return", "corner_imgs", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.video_transform.CornerCrop.randomize_parameters": [[279, 284], ["random.randint", "len"], "methods", ["None"], ["", "def", "randomize_parameters", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "randomize", ":", "\n", "            ", "self", ".", "crop_position", "=", "self", ".", "crop_positions", "[", "random", ".", "randint", "(", "\n", "0", ",", "\n", "len", "(", "self", ".", "crop_positions", ")", "-", "1", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.video_transform.RandomRotation.__init__": [[295, 307], ["isinstance", "ValueError", "len", "ValueError"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "degrees", ")", ":", "\n", "        ", "if", "isinstance", "(", "degrees", ",", "numbers", ".", "Number", ")", ":", "\n", "            ", "if", "degrees", "<", "0", ":", "\n", "                ", "raise", "ValueError", "(", "'If degrees is a single number,'", "\n", "'must be positive'", ")", "\n", "", "degrees", "=", "(", "-", "degrees", ",", "degrees", ")", "\n", "", "else", ":", "\n", "            ", "if", "len", "(", "degrees", ")", "!=", "2", ":", "\n", "                ", "raise", "ValueError", "(", "'If degrees is a sequence,'", "\n", "'it must be of len 2.'", ")", "\n", "\n", "", "", "self", ".", "degrees", "=", "degrees", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.video_transform.RandomRotation.__call__": [[308, 326], ["random.uniform", "isinstance", "isinstance", "skimage.transform.rotate", "skimage.transform.rotate", "skimage.transform.rotate", "skimage.transform.rotate", "TypeError", "img.rotate", "type"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "clip", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n        img (PIL.Image or numpy.ndarray): List of images to be cropped\n        in format (h, w, c) in numpy.ndarray\n        Returns:\n        PIL.Image or numpy.ndarray: Cropped list of images\n        \"\"\"", "\n", "angle", "=", "random", ".", "uniform", "(", "self", ".", "degrees", "[", "0", "]", ",", "self", ".", "degrees", "[", "1", "]", ")", "\n", "if", "isinstance", "(", "clip", "[", "0", "]", ",", "np", ".", "ndarray", ")", ":", "\n", "            ", "rotated", "=", "[", "skimage", ".", "transform", ".", "rotate", "(", "img", ",", "angle", ")", "for", "img", "in", "clip", "]", "\n", "", "elif", "isinstance", "(", "clip", "[", "0", "]", ",", "PIL", ".", "Image", ".", "Image", ")", ":", "\n", "            ", "rotated", "=", "[", "img", ".", "rotate", "(", "angle", ")", "for", "img", "in", "clip", "]", "\n", "", "else", ":", "\n", "            ", "raise", "TypeError", "(", "'Expected numpy.ndarray or PIL.Image'", "+", "\n", "'but got list of {0}'", ".", "format", "(", "type", "(", "clip", "[", "0", "]", ")", ")", ")", "\n", "\n", "", "return", "rotated", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.video_transform.STA_RandomRotation.__init__": [[337, 349], ["isinstance", "ValueError", "len", "ValueError"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "degrees", ")", ":", "\n", "        ", "if", "isinstance", "(", "degrees", ",", "numbers", ".", "Number", ")", ":", "\n", "            ", "if", "degrees", "<", "0", ":", "\n", "                ", "raise", "ValueError", "(", "'If degrees is a single number,'", "\n", "'must be positive'", ")", "\n", "", "degrees", "=", "(", "-", "degrees", ",", "degrees", ")", "\n", "", "else", ":", "\n", "            ", "if", "len", "(", "degrees", ")", "!=", "2", ":", "\n", "                ", "raise", "ValueError", "(", "'If degrees is a sequence,'", "\n", "'it must be of len 2.'", ")", "\n", "\n", "", "", "self", ".", "degrees", "=", "degrees", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.video_transform.STA_RandomRotation.__call__": [[350, 370], ["len", "random.uniform", "isinstance", "isinstance", "range", "skimage.transform.rotate", "skimage.transform.rotate", "skimage.transform.rotate", "skimage.transform.rotate", "TypeError", "enumerate", "img.rotate", "enumerate", "type"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "clip", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n        img (PIL.Image or numpy.ndarray): List of images to be cropped\n        in format (h, w, c) in numpy.ndarray\n        Returns:\n        PIL.Image or numpy.ndarray: Cropped list of images\n        \"\"\"", "\n", "bsz", "=", "len", "(", "clip", ")", "\n", "angle", "=", "random", ".", "uniform", "(", "self", ".", "degrees", "[", "0", "]", ",", "self", ".", "degrees", "[", "1", "]", ")", "\n", "angles", "=", "[", "(", "i", "+", "1", ")", "/", "(", "bsz", "+", "1", ")", "*", "angle", "for", "i", "in", "range", "(", "bsz", ")", "]", "\n", "if", "isinstance", "(", "clip", "[", "0", "]", ",", "np", ".", "ndarray", ")", ":", "\n", "            ", "rotated", "=", "[", "skimage", ".", "transform", ".", "rotate", "(", "img", ",", "angles", "[", "i", "]", ")", "for", "i", ",", "img", "in", "enumerate", "(", "clip", ")", "]", "\n", "", "elif", "isinstance", "(", "clip", "[", "0", "]", ",", "PIL", ".", "Image", ".", "Image", ")", ":", "\n", "            ", "rotated", "=", "[", "img", ".", "rotate", "(", "angles", "[", "i", "]", ")", "for", "i", ",", "img", "in", "enumerate", "(", "clip", ")", "]", "\n", "", "else", ":", "\n", "            ", "raise", "TypeError", "(", "'Expected numpy.ndarray or PIL.Image'", "+", "\n", "'but got list of {0}'", ".", "format", "(", "type", "(", "clip", "[", "0", "]", ")", ")", ")", "\n", "\n", "", "return", "rotated", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.video_transform.Each_RandomRotation.__init__": [[381, 393], ["isinstance", "ValueError", "len", "ValueError"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "degrees", ")", ":", "\n", "        ", "if", "isinstance", "(", "degrees", ",", "numbers", ".", "Number", ")", ":", "\n", "            ", "if", "degrees", "<", "0", ":", "\n", "                ", "raise", "ValueError", "(", "'If degrees is a single number,'", "\n", "'must be positive'", ")", "\n", "", "degrees", "=", "(", "-", "degrees", ",", "degrees", ")", "\n", "", "else", ":", "\n", "            ", "if", "len", "(", "degrees", ")", "!=", "2", ":", "\n", "                ", "raise", "ValueError", "(", "'If degrees is a sequence,'", "\n", "'it must be of len 2.'", ")", "\n", "\n", "", "", "self", ".", "degrees", "=", "degrees", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.video_transform.Each_RandomRotation.__call__": [[394, 414], ["len", "isinstance", "random.uniform", "isinstance", "range", "skimage.transform.rotate", "skimage.transform.rotate", "skimage.transform.rotate", "skimage.transform.rotate", "TypeError", "enumerate", "img.rotate", "enumerate", "type"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "clip", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n        img (PIL.Image or numpy.ndarray): List of images to be cropped\n        in format (h, w, c) in numpy.ndarray\n        Returns:\n        PIL.Image or numpy.ndarray: Cropped list of images\n        \"\"\"", "\n", "bsz", "=", "len", "(", "clip", ")", "\n", "angles", "=", "[", "random", ".", "uniform", "(", "self", ".", "degrees", "[", "0", "]", ",", "self", ".", "degrees", "[", "1", "]", ")", "for", "i", "in", "range", "(", "bsz", ")", "]", "\n", "# print(angles)", "\n", "if", "isinstance", "(", "clip", "[", "0", "]", ",", "np", ".", "ndarray", ")", ":", "\n", "            ", "rotated", "=", "[", "skimage", ".", "transform", ".", "rotate", "(", "img", ",", "angles", "[", "i", "]", ")", "for", "i", ",", "img", "in", "enumerate", "(", "clip", ")", "]", "\n", "", "elif", "isinstance", "(", "clip", "[", "0", "]", ",", "PIL", ".", "Image", ".", "Image", ")", ":", "\n", "            ", "rotated", "=", "[", "img", ".", "rotate", "(", "angles", "[", "i", "]", ")", "for", "i", ",", "img", "in", "enumerate", "(", "clip", ")", "]", "\n", "", "else", ":", "\n", "            ", "raise", "TypeError", "(", "'Expected numpy.ndarray or PIL.Image'", "+", "\n", "'but got list of {0}'", ".", "format", "(", "type", "(", "clip", "[", "0", "]", ")", ")", ")", "\n", "\n", "", "return", "rotated", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.video_transform.CenterCrop.__init__": [[423, 428], ["isinstance"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "size", ")", ":", "\n", "        ", "if", "isinstance", "(", "size", ",", "numbers", ".", "Number", ")", ":", "\n", "            ", "size", "=", "(", "size", ",", "size", ")", "\n", "\n", "", "self", ".", "size", "=", "size", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.video_transform.CenterCrop.__call__": [[429, 458], ["isinstance", "int", "int", "CoTrain.transforms.image.functional.crop_clip", "isinstance", "ValueError", "round", "round", "TypeError", "type"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.transforms.functional.crop_clip"], ["", "def", "__call__", "(", "self", ",", "clip", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n        img (PIL.Image or numpy.ndarray): List of images to be cropped\n        in format (h, w, c) in numpy.ndarray\n        Returns:\n        PIL.Image or numpy.ndarray: Cropped list of images\n        \"\"\"", "\n", "h", ",", "w", "=", "self", ".", "size", "\n", "if", "isinstance", "(", "clip", "[", "0", "]", ",", "np", ".", "ndarray", ")", ":", "\n", "            ", "im_h", ",", "im_w", ",", "im_c", "=", "clip", "[", "0", "]", ".", "shape", "\n", "", "elif", "isinstance", "(", "clip", "[", "0", "]", ",", "PIL", ".", "Image", ".", "Image", ")", ":", "\n", "            ", "im_w", ",", "im_h", "=", "clip", "[", "0", "]", ".", "size", "\n", "", "else", ":", "\n", "            ", "raise", "TypeError", "(", "'Expected numpy.ndarray or PIL.Image'", "+", "\n", "'but got list of {0}'", ".", "format", "(", "type", "(", "clip", "[", "0", "]", ")", ")", ")", "\n", "", "if", "w", ">", "im_w", "or", "h", ">", "im_h", ":", "\n", "            ", "error_msg", "=", "(", "\n", "'Initial image size should be larger then '", "\n", "'cropped size but got cropped sizes : ({w}, {h}) while '", "\n", "'initial image is ({im_w}, {im_h})'", ".", "format", "(", "\n", "im_w", "=", "im_w", ",", "im_h", "=", "im_h", ",", "w", "=", "w", ",", "h", "=", "h", ")", ")", "\n", "raise", "ValueError", "(", "error_msg", ")", "\n", "\n", "", "x1", "=", "int", "(", "round", "(", "(", "im_w", "-", "w", ")", "/", "2.", ")", ")", "\n", "y1", "=", "int", "(", "round", "(", "(", "im_h", "-", "h", ")", "/", "2.", ")", ")", "\n", "cropped", "=", "F", ".", "crop_clip", "(", "clip", ",", "y1", ",", "x1", ",", "h", ",", "w", ")", "\n", "\n", "return", "cropped", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.video_transform.ColorJitter.__init__": [[473, 478], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "brightness", "=", "0", ",", "contrast", "=", "0", ",", "saturation", "=", "0", ",", "hue", "=", "0", ")", ":", "\n", "        ", "self", ".", "brightness", "=", "brightness", "\n", "self", ".", "contrast", "=", "contrast", "\n", "self", ".", "saturation", "=", "saturation", "\n", "self", ".", "hue", "=", "hue", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.video_transform.ColorJitter.get_params": [[479, 503], ["random.uniform", "random.uniform", "random.uniform", "random.uniform", "max", "max", "max"], "methods", ["None"], ["", "def", "get_params", "(", "self", ",", "brightness", ",", "contrast", ",", "saturation", ",", "hue", ")", ":", "\n", "        ", "if", "brightness", ">", "0", ":", "\n", "            ", "brightness_factor", "=", "random", ".", "uniform", "(", "\n", "max", "(", "0", ",", "1", "-", "brightness", ")", ",", "1", "+", "brightness", ")", "\n", "", "else", ":", "\n", "            ", "brightness_factor", "=", "None", "\n", "\n", "", "if", "contrast", ">", "0", ":", "\n", "            ", "contrast_factor", "=", "random", ".", "uniform", "(", "\n", "max", "(", "0", ",", "1", "-", "contrast", ")", ",", "1", "+", "contrast", ")", "\n", "", "else", ":", "\n", "            ", "contrast_factor", "=", "None", "\n", "\n", "", "if", "saturation", ">", "0", ":", "\n", "            ", "saturation_factor", "=", "random", ".", "uniform", "(", "\n", "max", "(", "0", ",", "1", "-", "saturation", ")", ",", "1", "+", "saturation", ")", "\n", "", "else", ":", "\n", "            ", "saturation_factor", "=", "None", "\n", "\n", "", "if", "hue", ">", "0", ":", "\n", "            ", "hue_factor", "=", "random", ".", "uniform", "(", "-", "hue", ",", "hue", ")", "\n", "", "else", ":", "\n", "            ", "hue_factor", "=", "None", "\n", "", "return", "brightness_factor", ",", "contrast_factor", ",", "saturation_factor", ",", "hue_factor", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.video_transform.ColorJitter.__call__": [[504, 541], ["isinstance", "TypeError", "isinstance", "video_transform.ColorJitter.get_params", "random.shuffle", "TypeError", "img_transforms.append", "img_transforms.append", "img_transforms.append", "img_transforms.append", "jittered_clip.append", "func", "torchvision.transforms.functional.adjust_brightness", "torchvision.transforms.functional.adjust_saturation", "torchvision.transforms.functional.adjust_hue", "torchvision.transforms.functional.adjust_contrast", "type"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.transforms.video_transform.EachColorJitter.get_params"], ["", "def", "__call__", "(", "self", ",", "clip", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n        clip_test (list): list of PIL.Image\n        Returns:\n        list PIL.Image : list of transformed PIL.Image\n        \"\"\"", "\n", "if", "isinstance", "(", "clip", "[", "0", "]", ",", "np", ".", "ndarray", ")", ":", "\n", "            ", "raise", "TypeError", "(", "\n", "'Color jitter not yet implemented for numpy arrays'", ")", "\n", "", "elif", "isinstance", "(", "clip", "[", "0", "]", ",", "PIL", ".", "Image", ".", "Image", ")", ":", "\n", "            ", "brightness", ",", "contrast", ",", "saturation", ",", "hue", "=", "self", ".", "get_params", "(", "\n", "self", ".", "brightness", ",", "self", ".", "contrast", ",", "self", ".", "saturation", ",", "self", ".", "hue", ")", "\n", "\n", "# Create img sync_dir function sequence", "\n", "img_transforms", "=", "[", "]", "\n", "if", "brightness", "is", "not", "None", ":", "\n", "                ", "img_transforms", ".", "append", "(", "lambda", "img", ":", "torchvision", ".", "transforms", ".", "functional", ".", "adjust_brightness", "(", "img", ",", "brightness", ")", ")", "\n", "", "if", "saturation", "is", "not", "None", ":", "\n", "                ", "img_transforms", ".", "append", "(", "lambda", "img", ":", "torchvision", ".", "transforms", ".", "functional", ".", "adjust_saturation", "(", "img", ",", "saturation", ")", ")", "\n", "", "if", "hue", "is", "not", "None", ":", "\n", "                ", "img_transforms", ".", "append", "(", "lambda", "img", ":", "torchvision", ".", "transforms", ".", "functional", ".", "adjust_hue", "(", "img", ",", "hue", ")", ")", "\n", "", "if", "contrast", "is", "not", "None", ":", "\n", "                ", "img_transforms", ".", "append", "(", "lambda", "img", ":", "torchvision", ".", "transforms", ".", "functional", ".", "adjust_contrast", "(", "img", ",", "contrast", ")", ")", "\n", "", "random", ".", "shuffle", "(", "img_transforms", ")", "\n", "\n", "# Apply to all images", "\n", "jittered_clip", "=", "[", "]", "\n", "for", "img", "in", "clip", ":", "\n", "                ", "for", "func", "in", "img_transforms", ":", "\n", "                    ", "jittered_img", "=", "func", "(", "img", ")", "\n", "", "jittered_clip", ".", "append", "(", "jittered_img", ")", "\n", "\n", "", "", "else", ":", "\n", "            ", "raise", "TypeError", "(", "'Expected numpy.ndarray or PIL.Image'", "+", "\n", "'but got list of {0}'", ".", "format", "(", "type", "(", "clip", "[", "0", "]", ")", ")", ")", "\n", "", "return", "jittered_clip", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.video_transform.EachColorJitter.__init__": [[556, 561], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "brightness", "=", "0", ",", "contrast", "=", "0", ",", "saturation", "=", "0", ",", "hue", "=", "0", ")", ":", "\n", "        ", "self", ".", "brightness", "=", "brightness", "\n", "self", ".", "contrast", "=", "contrast", "\n", "self", ".", "saturation", "=", "saturation", "\n", "self", ".", "hue", "=", "hue", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.video_transform.EachColorJitter.get_params": [[562, 586], ["random.uniform", "random.uniform", "random.uniform", "random.uniform", "max", "max", "max"], "methods", ["None"], ["", "def", "get_params", "(", "self", ",", "brightness", ",", "contrast", ",", "saturation", ",", "hue", ")", ":", "\n", "        ", "if", "brightness", ">", "0", ":", "\n", "            ", "brightness_factor", "=", "random", ".", "uniform", "(", "\n", "max", "(", "0", ",", "1", "-", "brightness", ")", ",", "1", "+", "brightness", ")", "\n", "", "else", ":", "\n", "            ", "brightness_factor", "=", "None", "\n", "\n", "", "if", "contrast", ">", "0", ":", "\n", "            ", "contrast_factor", "=", "random", ".", "uniform", "(", "\n", "max", "(", "0", ",", "1", "-", "contrast", ")", ",", "1", "+", "contrast", ")", "\n", "", "else", ":", "\n", "            ", "contrast_factor", "=", "None", "\n", "\n", "", "if", "saturation", ">", "0", ":", "\n", "            ", "saturation_factor", "=", "random", ".", "uniform", "(", "\n", "max", "(", "0", ",", "1", "-", "saturation", ")", ",", "1", "+", "saturation", ")", "\n", "", "else", ":", "\n", "            ", "saturation_factor", "=", "None", "\n", "\n", "", "if", "hue", ">", "0", ":", "\n", "            ", "hue_factor", "=", "random", ".", "uniform", "(", "-", "hue", ",", "hue", ")", "\n", "", "else", ":", "\n", "            ", "hue_factor", "=", "None", "\n", "", "return", "brightness_factor", ",", "contrast_factor", ",", "saturation_factor", ",", "hue_factor", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.video_transform.EachColorJitter.__call__": [[587, 624], ["isinstance", "TypeError", "isinstance", "video_transform.EachColorJitter.get_params", "random.shuffle", "TypeError", "img_transforms.append", "img_transforms.append", "img_transforms.append", "img_transforms.append", "jittered_clip.append", "func", "torchvision.transforms.functional.adjust_brightness", "torchvision.transforms.functional.adjust_saturation", "torchvision.transforms.functional.adjust_hue", "torchvision.transforms.functional.adjust_contrast", "type"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.transforms.video_transform.EachColorJitter.get_params"], ["", "def", "__call__", "(", "self", ",", "clip", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n        clip_test (list): list of PIL.Image\n        Returns:\n        list PIL.Image : list of transformed PIL.Image\n        \"\"\"", "\n", "if", "isinstance", "(", "clip", "[", "0", "]", ",", "np", ".", "ndarray", ")", ":", "\n", "            ", "raise", "TypeError", "(", "\n", "'Color jitter not yet implemented for numpy arrays'", ")", "\n", "", "elif", "isinstance", "(", "clip", "[", "0", "]", ",", "PIL", ".", "Image", ".", "Image", ")", ":", "\n", "            ", "brightness", ",", "contrast", ",", "saturation", ",", "hue", "=", "self", ".", "get_params", "(", "\n", "self", ".", "brightness", ",", "self", ".", "contrast", ",", "self", ".", "saturation", ",", "self", ".", "hue", ")", "\n", "\n", "# Create img sync_dir function sequence", "\n", "img_transforms", "=", "[", "]", "\n", "if", "brightness", "is", "not", "None", ":", "\n", "                ", "img_transforms", ".", "append", "(", "lambda", "img", ":", "torchvision", ".", "transforms", ".", "functional", ".", "adjust_brightness", "(", "img", ",", "brightness", ")", ")", "\n", "", "if", "saturation", "is", "not", "None", ":", "\n", "                ", "img_transforms", ".", "append", "(", "lambda", "img", ":", "torchvision", ".", "transforms", ".", "functional", ".", "adjust_saturation", "(", "img", ",", "saturation", ")", ")", "\n", "", "if", "hue", "is", "not", "None", ":", "\n", "                ", "img_transforms", ".", "append", "(", "lambda", "img", ":", "torchvision", ".", "transforms", ".", "functional", ".", "adjust_hue", "(", "img", ",", "hue", ")", ")", "\n", "", "if", "contrast", "is", "not", "None", ":", "\n", "                ", "img_transforms", ".", "append", "(", "lambda", "img", ":", "torchvision", ".", "transforms", ".", "functional", ".", "adjust_contrast", "(", "img", ",", "contrast", ")", ")", "\n", "", "random", ".", "shuffle", "(", "img_transforms", ")", "\n", "\n", "# Apply to all images", "\n", "jittered_clip", "=", "[", "]", "\n", "for", "img", "in", "clip", ":", "\n", "                ", "for", "func", "in", "img_transforms", ":", "\n", "                    ", "jittered_img", "=", "func", "(", "img", ")", "\n", "", "jittered_clip", ".", "append", "(", "jittered_img", ")", "\n", "\n", "", "", "else", ":", "\n", "            ", "raise", "TypeError", "(", "'Expected numpy.ndarray or PIL.Image'", "+", "\n", "'but got list of {0}'", ".", "format", "(", "type", "(", "clip", "[", "0", "]", ")", ")", ")", "\n", "", "return", "jittered_clip", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.video_transform.Normalize.__init__": [[638, 641], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "mean", ",", "std", ")", ":", "\n", "        ", "self", ".", "mean", "=", "mean", "\n", "self", ".", "std", "=", "std", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.video_transform.Normalize.__call__": [[642, 650], ["CoTrain.transforms.image.functional.normalize"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.transforms.functional.normalize"], ["", "def", "__call__", "(", "self", ",", "clip", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            clip (Tensor): Tensor clip_test of size (T, C, H, W) to be normalized.\n        Returns:\n            Tensor: Normalized Tensor clip_test.\n        \"\"\"", "\n", "return", "F", ".", "normalize", "(", "clip", ",", "self", ".", "mean", ",", "self", ".", "std", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.video_transform.Normalize.__repr__": [[651, 653], ["None"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "__class__", ".", "__name__", "+", "'(mean={0}, std={1})'", ".", "format", "(", "self", ".", "mean", ",", "self", ".", "std", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.video_transform.TensorToNumpy.__init__": [[657, 659], ["print"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "print", "(", "\"convert to numpy\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.video_transform.TensorToNumpy.__call__": [[660, 664], ["clip.permute().cpu().detach().numpy", "PIL.Image.fromarray().convert", "clip.permute().cpu().detach", "PIL.Image.fromarray", "clip.permute().cpu", "numpy.uint8", "clip.permute"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "clip", ")", ":", "\n", "        ", "np_clip", "=", "clip", ".", "permute", "(", "1", ",", "2", ",", "3", ",", "0", ")", ".", "cpu", "(", ")", ".", "detach", "(", ")", ".", "numpy", "(", ")", "\n", "pil_clip", "=", "[", "Image", ".", "fromarray", "(", "np", ".", "uint8", "(", "numpy_image", ")", ")", ".", "convert", "(", "'RGB'", ")", "for", "numpy_image", "in", "np_clip", "]", "\n", "return", "pil_clip", "\n", "", "", ""]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.video_transform.convert_img": [[14, 22], ["len", "np.expand_dims.transpose", "len", "numpy.expand_dims"], "function", ["None"], ["def", "convert_img", "(", "img", ")", ":", "\n", "    ", "\"\"\"Converts (H, W, C) numpy.ndarray to (C, W, H) format\n    \"\"\"", "\n", "if", "len", "(", "img", ".", "shape", ")", "==", "3", ":", "\n", "        ", "img", "=", "img", ".", "transpose", "(", "2", ",", "0", ",", "1", ")", "\n", "", "if", "len", "(", "img", ".", "shape", ")", "==", "2", ":", "\n", "        ", "img", "=", "np", ".", "expand_dims", "(", "img", ",", "0", ")", "\n", "", "return", "img", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.videoaug.VideoTransform": [[2, 56], ["print", "video_transforms.create_video_transform", "video_transforms.create_video_transform", "transforms.Compose", "transforms.Compose", "transforms.Compose", "transforms.Compose", "int", "int", "int", "video_transform.TensorToNumpy", "video_transform.Resize", "video_transform.RandomCrop", "video_transform.ClipToTensor", "video_transform.Normalize", "video_transform.TensorToNumpy", "video_transform.Resize", "video_transform.RandomCrop", "video_transform.ClipToTensor", "video_transform.Normalize", "video_transform.TensorToNumpy", "video_transform.Resize", "video_transform.CenterCrop", "video_transform.ClipToTensor", "video_transform.Normalize", "video_transform.TensorToNumpy", "video_transform.Resize", "video_transform.CenterCrop", "video_transform.ClipToTensor", "video_transform.Normalize", "int", "int"], "function", ["None"], ["def", "VideoTransform", "(", "mode", "=", "'train'", ",", "crop_size", "=", "224", ",", "backend", "=", "'v100'", ")", ":", "\n", "    ", "if", "backend", "==", "'a100'", ":", "\n", "        ", "print", "(", "\"initalize data augmentation for a100 gpus\"", ")", "\n", "import", "CoTrain", ".", "transforms", ".", "video", ".", "video_transform", "as", "video_transform", "\n", "from", "torchvision", "import", "transforms", "\n", "# https://github.com/FingerRec/BE/blob/main/src/Contrastive/augment/video_transformations/volume_transforms.py", "\n", "if", "mode", "==", "'train'", ":", "\n", "            ", "global_transforms", "=", "transforms", ".", "Compose", "(", "[", "\n", "video_transform", ".", "TensorToNumpy", "(", ")", ",", "\n", "video_transform", ".", "Resize", "(", "int", "(", "crop_size", "*", "1.2", ")", ")", ",", "# 256/224 = 1.14", "\n", "video_transform", ".", "RandomCrop", "(", "crop_size", ")", ",", "\n", "# video_transform.ColorJitter(0.5, 0.5, 0.25, 0.5),  # color operation perimitted, damage attribute", "\n", "video_transform", ".", "ClipToTensor", "(", "channel_nb", "=", "3", ")", ",", "\n", "video_transform", ".", "Normalize", "(", "mean", "=", "[", "0.485", ",", "0.456", ",", "0.406", "]", ",", "std", "=", "[", "0.229", ",", "0.224", ",", "0.225", "]", ")", "\n", "]", ")", "\n", "local_transforms", "=", "transforms", ".", "Compose", "(", "[", "\n", "video_transform", ".", "TensorToNumpy", "(", ")", ",", "\n", "video_transform", ".", "Resize", "(", "crop_size", ")", ",", "# 256/224 = 1.14", "\n", "video_transform", ".", "RandomCrop", "(", "96", ")", ",", "\n", "# video_transform.ColorJitter(0.5, 0.5, 0.25, 0.5),  # color operation perimitted, damage attribute", "\n", "video_transform", ".", "ClipToTensor", "(", "channel_nb", "=", "3", ")", ",", "\n", "video_transform", ".", "Normalize", "(", "mean", "=", "[", "0.485", ",", "0.456", ",", "0.406", "]", ",", "std", "=", "[", "0.229", ",", "0.224", ",", "0.225", "]", ")", "\n", "]", ")", "\n", "", "else", ":", "\n", "            ", "global_transforms", "=", "transforms", ".", "Compose", "(", "[", "\n", "video_transform", ".", "TensorToNumpy", "(", ")", ",", "\n", "video_transform", ".", "Resize", "(", "int", "(", "crop_size", "*", "1.2", ")", ")", ",", "# 256", "\n", "video_transform", ".", "CenterCrop", "(", "crop_size", ")", ",", "# 224", "\n", "video_transform", ".", "ClipToTensor", "(", "channel_nb", "=", "3", ")", ",", "\n", "video_transform", ".", "Normalize", "(", "mean", "=", "[", "0.485", ",", "0.456", ",", "0.406", "]", ",", "std", "=", "[", "0.229", ",", "0.224", ",", "0.225", "]", ")", "\n", "]", ")", "\n", "local_transforms", "=", "transforms", ".", "Compose", "(", "[", "\n", "video_transform", ".", "TensorToNumpy", "(", ")", ",", "\n", "video_transform", ".", "Resize", "(", "crop_size", ")", ",", "# 256", "\n", "video_transform", ".", "CenterCrop", "(", "96", ")", ",", "# 224", "\n", "video_transform", ".", "ClipToTensor", "(", "channel_nb", "=", "3", ")", ",", "\n", "video_transform", ".", "Normalize", "(", "mean", "=", "[", "0.485", ",", "0.456", ",", "0.406", "]", ",", "std", "=", "[", "0.229", ",", "0.224", ",", "0.225", "]", ")", "\n", "]", ")", "\n", "", "return", "[", "global_transforms", ",", "local_transforms", "]", "\n", "", "else", ":", "\n", "# for pytorch > 1.9.0, V100", "\n", "        ", "import", "pytorchvideo", ".", "transforms", "as", "video_transforms", "\n", "# https://pytorchvideo.readthedocs.io/en/latest/api/transforms/transforms.html", "\n", "global_transform", "=", "video_transforms", ".", "create_video_transform", "(", "mode", "=", "mode", ",", "min_size", "=", "int", "(", "crop_size", "*", "1.2", ")", ",", "\n", "max_size", "=", "int", "(", "crop_size", "*", "1.5", ")", ",", "\n", "crop_size", "=", "crop_size", ",", "\n", "aug_type", "=", "'randaug'", ",", "# randaug/augmix", "\n", "num_samples", "=", "None", ")", "# not use temporal sub sampling", "\n", "local_transform", "=", "video_transforms", ".", "create_video_transform", "(", "mode", "=", "mode", ",", "min_size", "=", "crop_size", ",", "\n", "max_size", "=", "int", "(", "crop_size", "*", "1.5", ")", ",", "\n", "crop_size", "=", "96", ",", "\n", "aug_type", "=", "'randaug'", ",", "# randaug/augmix", "\n", "num_samples", "=", "None", ")", "# not use temporal sub sampling", "\n", "return", "[", "global_transform", ",", "local_transform", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.video.videoaug.video_aug": [[58, 77], ["range", "videos.permute.permute().byte", "videos.permute.permute", "global_videos_tensor.append", "global_transform().permute", "videos.permute.permute", "global_transform"], "function", ["None"], ["", "", "def", "video_aug", "(", "videos", ",", "video_transform", ",", "byte", "=", "False", ")", ":", "\n", "    ", "if", "byte", ":", "\n", "        ", "videos", "=", "videos", ".", "permute", "(", "1", ",", "0", ",", "2", ",", "3", ")", ".", "byte", "(", ")", "# tchw -> cthw", "\n", "", "else", ":", "\n", "        ", "videos", "=", "videos", ".", "permute", "(", "1", ",", "0", ",", "2", ",", "3", ")", "\n", "# normal", "\n", "# videos_tensor = [video_transform(videos).permute(1, 0, 2, 3)]  # -> tchw", "\n", "# dino", "\n", "", "global_videos_tensor", "=", "[", "]", "\n", "global_transform", ",", "local_transform", "=", "video_transform", "\n", "# print(videos.type())", "\n", "# 2 GLOBAL views", "\n", "for", "i", "in", "range", "(", "2", ")", ":", "\n", "        ", "global_videos_tensor", ".", "append", "(", "global_transform", "(", "videos", ")", ".", "permute", "(", "1", ",", "0", ",", "2", ",", "3", ")", ")", "\n", "# 3 LOCAL VIEWS", "\n", "# local_videos_tensor = []", "\n", "# for i in range(0):", "\n", "#     local_videos_tensor.append(local_transform(videos).permute(1, 0, 2, 3))", "\n", "", "return", "global_videos_tensor", "\n", "# return [global_videos_tensor, local_videos_tensor]", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.image.vg_caption_datamodule.VisualGenomeCaptionDataModule.__init__": [[6, 8], ["datamodule_base.BaseDataModule.__init__"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.transforms.utils.UnNormalize.__init__"], ["    ", "def", "__init__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.image.vg_caption_datamodule.VisualGenomeCaptionDataModule.dataset_cls": [[9, 12], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "dataset_cls", "(", "self", ")", ":", "\n", "        ", "return", "VisualGenomeCaptionDataset", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.image.vg_caption_datamodule.VisualGenomeCaptionDataModule.dataset_name": [[13, 16], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "dataset_name", "(", "self", ")", ":", "\n", "        ", "return", "\"vg\"", "\n", "", "", ""]], "home.repos.pwc.inspect_result.showlab_all-in-one.image.coco_caption_karpathy_datamodule.CocoCaptionKarpathyDataModule.__init__": [[6, 8], ["datamodule_base.BaseDataModule.__init__"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.transforms.utils.UnNormalize.__init__"], ["    ", "def", "__init__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.image.coco_caption_karpathy_datamodule.CocoCaptionKarpathyDataModule.dataset_cls": [[9, 12], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "dataset_cls", "(", "self", ")", ":", "\n", "        ", "return", "CocoCaptionKarpathyDataset", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.image.coco_caption_karpathy_datamodule.CocoCaptionKarpathyDataModule.dataset_cls_no_false": [[13, 16], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "dataset_cls_no_false", "(", "self", ")", ":", "\n", "        ", "return", "CocoCaptionKarpathyDataset", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.image.coco_caption_karpathy_datamodule.CocoCaptionKarpathyDataModule.dataset_name": [[17, 20], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "dataset_name", "(", "self", ")", ":", "\n", "        ", "return", "\"coco\"", "\n", "", "", ""]], "home.repos.pwc.inspect_result.showlab_all-in-one.image.datamodule_base.BaseDataModule.__init__": [[25, 72], ["pytorch_lightning.LightningDataModule.__init__", "datamodule_base.get_pretrained_tokenizer", "collator", "len", "len"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.transforms.utils.UnNormalize.__init__", "home.repos.pwc.inspect_result.showlab_all-in-one.image.datamodule_base.get_pretrained_tokenizer"], ["    ", "def", "__init__", "(", "self", ",", "_config", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "data_dir", "=", "_config", "[", "\"data_root\"", "]", "\n", "\n", "self", ".", "num_workers", "=", "_config", "[", "\"num_workers\"", "]", "\n", "self", ".", "batch_size", "=", "_config", "[", "\"per_gpu_batchsize\"", "]", "\n", "self", ".", "eval_batch_size", "=", "self", ".", "batch_size", "\n", "\n", "self", ".", "image_size", "=", "_config", "[", "\"image_size\"", "]", "\n", "self", ".", "max_text_len", "=", "_config", "[", "\"max_text_len\"", "]", "\n", "self", ".", "draw_false_video", "=", "_config", "[", "\"draw_false_video\"", "]", "\n", "self", ".", "draw_false_image", "=", "_config", "[", "\"draw_false_image\"", "]", "\n", "self", ".", "draw_false_text", "=", "_config", "[", "\"draw_false_text\"", "]", "\n", "self", ".", "image_only", "=", "_config", "[", "\"video_only\"", "]", "\n", "\n", "\n", "self", ".", "num_frames", "=", "_config", "[", "\"num_frames\"", "]", "\n", "self", ".", "draw_options_text", "=", "_config", "[", "\"draw_options_text\"", "]", "\n", "self", ".", "backend", "=", "_config", "[", "\"backend\"", "]", "\n", "\n", "self", ".", "train_transform_keys", "=", "(", "\n", "[", "\"default_train\"", "]", "\n", "if", "len", "(", "_config", "[", "\"train_transform_keys\"", "]", ")", "==", "0", "\n", "else", "_config", "[", "\"train_transform_keys\"", "]", "\n", ")", "\n", "\n", "self", ".", "val_transform_keys", "=", "(", "\n", "[", "\"default_val\"", "]", "\n", "if", "len", "(", "_config", "[", "\"val_transform_keys\"", "]", ")", "==", "0", "\n", "else", "_config", "[", "\"val_transform_keys\"", "]", "\n", ")", "\n", "\n", "tokenizer", "=", "_config", "[", "\"tokenizer\"", "]", "\n", "self", ".", "tokenizer", "=", "get_pretrained_tokenizer", "(", "tokenizer", ")", "\n", "self", ".", "vocab_size", "=", "self", ".", "tokenizer", ".", "vocab_size", "\n", "\n", "collator", "=", "(", "\n", "DataCollatorForWholeWordMask", "\n", "if", "_config", "[", "\"whole_word_masking\"", "]", "\n", "else", "DataCollatorForLanguageModeling", "\n", ")", "\n", "\n", "self", ".", "mlm_collator", "=", "collator", "(", "\n", "tokenizer", "=", "self", ".", "tokenizer", ",", "mlm", "=", "True", ",", "mlm_probability", "=", "_config", "[", "\"mlm_prob\"", "]", "\n", ")", "\n", "self", ".", "setup_flag", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.image.datamodule_base.BaseDataModule.dataset_cls": [[73, 76], ["NotImplementedError"], "methods", ["None"], ["", "@", "property", "\n", "def", "dataset_cls", "(", "self", ")", ":", "\n", "        ", "raise", "NotImplementedError", "(", "\"return tuple of dataset class\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.image.datamodule_base.BaseDataModule.dataset_name": [[77, 80], ["NotImplementedError"], "methods", ["None"], ["", "@", "property", "\n", "def", "dataset_name", "(", "self", ")", ":", "\n", "        ", "raise", "NotImplementedError", "(", "\"return name of dataset\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.image.datamodule_base.BaseDataModule.set_train_dataset": [[81, 95], ["datamodule_base.BaseDataModule.dataset_cls"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.image.conceptual_caption_datamodule.ConceptualCaptionDataModule.dataset_cls"], ["", "def", "set_train_dataset", "(", "self", ")", ":", "\n", "        ", "self", ".", "train_dataset", "=", "self", ".", "dataset_cls", "(", "\n", "self", ".", "data_dir", ",", "\n", "self", ".", "train_transform_keys", ",", "\n", "split", "=", "\"train\"", ",", "\n", "image_size", "=", "self", ".", "image_size", ",", "\n", "max_text_len", "=", "self", ".", "max_text_len", ",", "\n", "draw_false_image", "=", "self", ".", "draw_false_image", ",", "\n", "draw_false_video", "=", "self", ".", "draw_false_video", ",", "\n", "draw_false_text", "=", "self", ".", "draw_false_text", ",", "\n", "image_only", "=", "self", ".", "image_only", ",", "\n", "num_frames", "=", "self", ".", "num_frames", ",", "\n", "draw_options_text", "=", "self", ".", "draw_options_text", ",", "\n", "backend", "=", "self", ".", "backend", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.image.datamodule_base.BaseDataModule.set_val_dataset": [[97, 127], ["datamodule_base.BaseDataModule.dataset_cls", "hasattr", "datamodule_base.BaseDataModule.dataset_cls_no_false"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.image.conceptual_caption_datamodule.ConceptualCaptionDataModule.dataset_cls", "home.repos.pwc.inspect_result.showlab_all-in-one.image.f30k_caption_karpathy_datamodule.F30KCaptionKarpathyDataModule.dataset_cls_no_false"], ["", "def", "set_val_dataset", "(", "self", ")", ":", "\n", "        ", "self", ".", "val_dataset", "=", "self", ".", "dataset_cls", "(", "\n", "self", ".", "data_dir", ",", "\n", "self", ".", "val_transform_keys", ",", "\n", "split", "=", "\"val\"", ",", "\n", "image_size", "=", "self", ".", "image_size", ",", "\n", "max_text_len", "=", "self", ".", "max_text_len", ",", "\n", "draw_false_image", "=", "self", ".", "draw_false_image", ",", "\n", "draw_false_video", "=", "self", ".", "draw_false_video", ",", "\n", "draw_false_text", "=", "self", ".", "draw_false_text", ",", "\n", "image_only", "=", "self", ".", "image_only", ",", "\n", "num_frames", "=", "self", ".", "num_frames", ",", "\n", "draw_options_text", "=", "self", ".", "draw_options_text", ",", "\n", "backend", "=", "self", ".", "backend", "\n", ")", "\n", "\n", "if", "hasattr", "(", "self", ",", "\"dataset_cls_no_false\"", ")", ":", "\n", "            ", "self", ".", "val_dataset_no_false", "=", "self", ".", "dataset_cls_no_false", "(", "\n", "self", ".", "data_dir", ",", "\n", "self", ".", "val_transform_keys", ",", "\n", "split", "=", "\"val\"", ",", "\n", "image_size", "=", "self", ".", "image_size", ",", "\n", "max_text_len", "=", "self", ".", "max_text_len", ",", "\n", "draw_false_image", "=", "0", ",", "\n", "draw_false_video", "=", "0", ",", "\n", "draw_false_text", "=", "0", ",", "\n", "image_only", "=", "self", ".", "image_only", ",", "\n", "num_frames", "=", "self", ".", "num_frames", ",", "\n", "draw_options_text", "=", "self", ".", "draw_options_text", ",", "\n", "backend", "=", "self", ".", "backend", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.image.datamodule_base.BaseDataModule.make_no_false_val_dset": [[129, 143], ["datamodule_base.BaseDataModule.dataset_cls_no_false"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.image.f30k_caption_karpathy_datamodule.F30KCaptionKarpathyDataModule.dataset_cls_no_false"], ["", "", "def", "make_no_false_val_dset", "(", "self", ",", "image_only", "=", "False", ")", ":", "\n", "        ", "return", "self", ".", "dataset_cls_no_false", "(", "\n", "self", ".", "data_dir", ",", "\n", "self", ".", "val_transform_keys", ",", "\n", "split", "=", "\"val\"", ",", "\n", "image_size", "=", "self", ".", "image_size", ",", "\n", "max_text_len", "=", "self", ".", "max_text_len", ",", "\n", "draw_false_image", "=", "0", ",", "\n", "draw_false_video", "=", "0", ",", "\n", "draw_false_text", "=", "0", ",", "\n", "image_only", "=", "image_only", ",", "\n", "num_frames", "=", "self", ".", "num_frames", ",", "\n", "draw_options_text", "=", "self", ".", "draw_options_text", ",", "\n", "backend", "=", "self", ".", "backend", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.image.datamodule_base.BaseDataModule.set_test_dataset": [[145, 159], ["datamodule_base.BaseDataModule.dataset_cls"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.image.conceptual_caption_datamodule.ConceptualCaptionDataModule.dataset_cls"], ["", "def", "set_test_dataset", "(", "self", ")", ":", "\n", "        ", "self", ".", "test_dataset", "=", "self", ".", "dataset_cls", "(", "\n", "self", ".", "data_dir", ",", "\n", "self", ".", "val_transform_keys", ",", "\n", "split", "=", "\"test\"", ",", "\n", "image_size", "=", "self", ".", "image_size", ",", "\n", "max_text_len", "=", "self", ".", "max_text_len", ",", "\n", "draw_false_image", "=", "self", ".", "draw_false_image", ",", "\n", "draw_false_video", "=", "self", ".", "draw_false_video", ",", "\n", "draw_false_text", "=", "self", ".", "draw_false_text", ",", "\n", "image_only", "=", "self", ".", "image_only", ",", "\n", "num_frames", "=", "self", ".", "num_frames", ",", "\n", "draw_options_text", "=", "self", ".", "draw_options_text", ",", "\n", "backend", "=", "self", ".", "backend", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.image.datamodule_base.BaseDataModule.setup": [[161, 172], ["datamodule_base.BaseDataModule.set_train_dataset", "datamodule_base.BaseDataModule.set_val_dataset", "datamodule_base.BaseDataModule.set_test_dataset"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.image.datamodule_base.BaseDataModule.set_train_dataset", "home.repos.pwc.inspect_result.showlab_all-in-one.image.datamodule_base.BaseDataModule.set_val_dataset", "home.repos.pwc.inspect_result.showlab_all-in-one.image.datamodule_base.BaseDataModule.set_test_dataset"], ["", "def", "setup", "(", "self", ",", "stage", ")", ":", "\n", "        ", "if", "not", "self", ".", "setup_flag", ":", "\n", "            ", "self", ".", "set_train_dataset", "(", ")", "\n", "self", ".", "set_val_dataset", "(", ")", "\n", "self", ".", "set_test_dataset", "(", ")", "\n", "\n", "self", ".", "train_dataset", ".", "tokenizer", "=", "self", ".", "tokenizer", "\n", "self", ".", "val_dataset", ".", "tokenizer", "=", "self", ".", "tokenizer", "\n", "self", ".", "test_dataset", ".", "tokenizer", "=", "self", ".", "tokenizer", "\n", "\n", "self", ".", "setup_flag", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.image.datamodule_base.BaseDataModule.train_dataloader": [[173, 183], ["torch.utils.data.DataLoader"], "methods", ["None"], ["", "", "def", "train_dataloader", "(", "self", ")", ":", "\n", "        ", "loader", "=", "DataLoader", "(", "\n", "self", ".", "train_dataset", ",", "\n", "batch_size", "=", "self", ".", "batch_size", ",", "\n", "shuffle", "=", "True", ",", "\n", "num_workers", "=", "self", ".", "num_workers", ",", "\n", "pin_memory", "=", "True", ",", "\n", "collate_fn", "=", "self", ".", "train_dataset", ".", "collate", ",", "\n", ")", "\n", "return", "loader", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.image.datamodule_base.BaseDataModule.val_dataloader": [[184, 194], ["torch.utils.data.DataLoader"], "methods", ["None"], ["", "def", "val_dataloader", "(", "self", ")", ":", "\n", "        ", "loader", "=", "DataLoader", "(", "\n", "self", ".", "val_dataset", ",", "\n", "batch_size", "=", "self", ".", "eval_batch_size", ",", "\n", "shuffle", "=", "False", ",", "\n", "num_workers", "=", "self", ".", "num_workers", ",", "\n", "pin_memory", "=", "True", ",", "\n", "collate_fn", "=", "self", ".", "val_dataset", ".", "collate", ",", "\n", ")", "\n", "return", "loader", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.image.datamodule_base.BaseDataModule.test_dataloader": [[195, 205], ["torch.utils.data.DataLoader"], "methods", ["None"], ["", "def", "test_dataloader", "(", "self", ")", ":", "\n", "        ", "loader", "=", "DataLoader", "(", "\n", "self", ".", "test_dataset", ",", "\n", "batch_size", "=", "self", ".", "eval_batch_size", ",", "\n", "shuffle", "=", "False", ",", "\n", "num_workers", "=", "self", ".", "num_workers", ",", "\n", "pin_memory", "=", "True", ",", "\n", "collate_fn", "=", "self", ".", "test_dataset", ".", "collate", ",", "\n", ")", "\n", "return", "loader", "\n", "", "", ""]], "home.repos.pwc.inspect_result.showlab_all-in-one.image.datamodule_base.get_pretrained_tokenizer": [[12, 21], ["torch.distributed.is_initialized", "transformers.BertTokenizer.from_pretrained", "torch.distributed.barrier", "torch.distributed.get_rank", "transformers.BertTokenizer.from_pretrained"], "function", ["home.repos.pwc.inspect_result.showlab_all-in-one.modules.dist_utils.get_rank"], ["def", "get_pretrained_tokenizer", "(", "from_pretrained", ")", ":", "\n", "    ", "if", "torch", ".", "distributed", ".", "is_initialized", "(", ")", ":", "\n", "        ", "if", "torch", ".", "distributed", ".", "get_rank", "(", ")", "==", "0", ":", "\n", "            ", "BertTokenizer", ".", "from_pretrained", "(", "\n", "from_pretrained", ",", "do_lower_case", "=", "\"uncased\"", "in", "from_pretrained", "\n", ")", "\n", "", "torch", ".", "distributed", ".", "barrier", "(", ")", "\n", "", "return", "BertTokenizer", ".", "from_pretrained", "(", "\n", "from_pretrained", ",", "do_lower_case", "=", "\"uncased\"", "in", "from_pretrained", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.image.f30k_caption_karpathy_datamodule.F30KCaptionKarpathyDataModule.__init__": [[6, 8], ["datamodule_base.BaseDataModule.__init__"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.transforms.utils.UnNormalize.__init__"], ["    ", "def", "__init__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.image.f30k_caption_karpathy_datamodule.F30KCaptionKarpathyDataModule.dataset_cls": [[9, 12], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "dataset_cls", "(", "self", ")", ":", "\n", "        ", "return", "F30KCaptionKarpathyDataset", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.image.f30k_caption_karpathy_datamodule.F30KCaptionKarpathyDataModule.dataset_cls_no_false": [[13, 16], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "dataset_cls_no_false", "(", "self", ")", ":", "\n", "        ", "return", "F30KCaptionKarpathyDataset", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.image.f30k_caption_karpathy_datamodule.F30KCaptionKarpathyDataModule.dataset_name": [[17, 20], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "dataset_name", "(", "self", ")", ":", "\n", "        ", "return", "\"f30k\"", "\n", "", "", ""]], "home.repos.pwc.inspect_result.showlab_all-in-one.image.cc3m_datamodule.CC3MDataModule.__init__": [[6, 8], ["datamodule_base.BaseDataModule.__init__"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.transforms.utils.UnNormalize.__init__"], ["    ", "def", "__init__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.image.cc3m_datamodule.CC3MDataModule.dataset_cls": [[9, 12], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "dataset_cls", "(", "self", ")", ":", "\n", "        ", "return", "CC3MDataset", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.image.cc3m_datamodule.CC3MDataModule.dataset_name": [[13, 16], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "dataset_name", "(", "self", ")", ":", "\n", "        ", "return", "\"cc3m\"", "\n", "", "", ""]], "home.repos.pwc.inspect_result.showlab_all-in-one.image.vcr_datamodule.VCRDataModule.__init__": [[6, 8], ["datamodule_base.BaseDataModule.__init__"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.transforms.utils.UnNormalize.__init__"], ["    ", "def", "__init__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.image.vcr_datamodule.VCRDataModule.dataset_cls": [[9, 12], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "dataset_cls", "(", "self", ")", ":", "\n", "        ", "return", "VCRDataset", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.image.vcr_datamodule.VCRDataModule.dataset_name": [[13, 16], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "dataset_name", "(", "self", ")", ":", "\n", "        ", "return", "\"vcr\"", "\n", "", "", ""]], "home.repos.pwc.inspect_result.showlab_all-in-one.image.cc12m_datamodule.CC12MDataModule.__init__": [[6, 8], ["datamodule_base.BaseDataModule.__init__"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.transforms.utils.UnNormalize.__init__"], ["    ", "def", "__init__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.image.cc12m_datamodule.CC12MDataModule.dataset_cls": [[9, 12], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "dataset_cls", "(", "self", ")", ":", "\n", "        ", "return", "CC12MDataset", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.image.cc12m_datamodule.CC12MDataModule.dataset_name": [[13, 16], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "dataset_name", "(", "self", ")", ":", "\n", "        ", "return", "\"cc3m\"", "\n", "", "", ""]], "home.repos.pwc.inspect_result.showlab_all-in-one.image.vqav2_datamodule.VQAv2DataModule.__init__": [[7, 9], ["CoTrain.datamodules.image.datamodule_base.BaseDataModule.__init__"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.transforms.utils.UnNormalize.__init__"], ["    ", "def", "__init__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.image.vqav2_datamodule.VQAv2DataModule.dataset_cls": [[10, 13], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "dataset_cls", "(", "self", ")", ":", "\n", "        ", "return", "VQAv2Dataset", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.image.vqav2_datamodule.VQAv2DataModule.dataset_name": [[14, 17], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "dataset_name", "(", "self", ")", ":", "\n", "        ", "return", "\"vqa\"", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.image.vqav2_datamodule.VQAv2DataModule.setup": [[18, 37], ["super().setup", "vqav2_datamodule.VQAv2DataModule.train_dataset.table[].to_pandas().tolist", "vqav2_datamodule.VQAv2DataModule.val_dataset.table[].to_pandas().tolist", "vqav2_datamodule.VQAv2DataModule.train_dataset.table[].to_pandas().tolist", "vqav2_datamodule.VQAv2DataModule.val_dataset.table[].to_pandas().tolist", "sorted", "collections.defaultdict", "vqav2_datamodule.VQAv2DataModule.answer2id.items", "max", "vqav2_datamodule.VQAv2DataModule.train_dataset.table[].to_pandas", "vqav2_datamodule.VQAv2DataModule.val_dataset.table[].to_pandas", "vqav2_datamodule.VQAv2DataModule.train_dataset.table[].to_pandas", "vqav2_datamodule.VQAv2DataModule.val_dataset.table[].to_pandas", "zip", "vqav2_datamodule.VQAv2DataModule.answer2id.values"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.image.vqav2_datamodule.VQAv2DataModule.setup"], ["", "def", "setup", "(", "self", ",", "stage", ")", ":", "\n", "        ", "super", "(", ")", ".", "setup", "(", "stage", ")", "\n", "\n", "train_answers", "=", "self", ".", "train_dataset", ".", "table", "[", "\"answers\"", "]", ".", "to_pandas", "(", ")", ".", "tolist", "(", ")", "\n", "val_answers", "=", "self", ".", "val_dataset", ".", "table", "[", "\"answers\"", "]", ".", "to_pandas", "(", ")", ".", "tolist", "(", ")", "\n", "train_labels", "=", "self", ".", "train_dataset", ".", "table", "[", "\"answer_labels\"", "]", ".", "to_pandas", "(", ")", ".", "tolist", "(", ")", "\n", "val_labels", "=", "self", ".", "val_dataset", ".", "table", "[", "\"answer_labels\"", "]", ".", "to_pandas", "(", ")", ".", "tolist", "(", ")", "\n", "\n", "all_answers", "=", "[", "c", "for", "c", "in", "train_answers", "+", "val_answers", "if", "c", "is", "not", "None", "]", "\n", "all_answers", "=", "[", "l", "for", "lll", "in", "all_answers", "for", "ll", "in", "lll", "for", "l", "in", "ll", "]", "\n", "all_labels", "=", "[", "c", "for", "c", "in", "train_labels", "+", "val_labels", "if", "c", "is", "not", "None", "]", "\n", "all_labels", "=", "[", "l", "for", "lll", "in", "all_labels", "for", "ll", "in", "lll", "for", "l", "in", "ll", "]", "\n", "\n", "self", ".", "answer2id", "=", "{", "k", ":", "v", "for", "k", ",", "v", "in", "zip", "(", "all_answers", ",", "all_labels", ")", "}", "\n", "sorted_a2i", "=", "sorted", "(", "self", ".", "answer2id", ".", "items", "(", ")", ",", "key", "=", "lambda", "x", ":", "x", "[", "1", "]", ")", "\n", "self", ".", "num_class", "=", "max", "(", "self", ".", "answer2id", ".", "values", "(", ")", ")", "+", "1", "\n", "self", ".", "id2answer", "=", "defaultdict", "(", "lambda", ":", "\"unknown\"", ")", "\n", "for", "k", ",", "v", "in", "sorted_a2i", ":", "\n", "            ", "self", ".", "id2answer", "[", "v", "]", "=", "k", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.showlab_all-in-one.image.sbu_datamodule.SBUCaptionDataModule.__init__": [[6, 8], ["datamodule_base.BaseDataModule.__init__"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.transforms.utils.UnNormalize.__init__"], ["    ", "def", "__init__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.image.sbu_datamodule.SBUCaptionDataModule.dataset_cls": [[9, 12], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "dataset_cls", "(", "self", ")", ":", "\n", "        ", "return", "SBUCaptionDataset", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.image.sbu_datamodule.SBUCaptionDataModule.dataset_name": [[13, 16], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "dataset_name", "(", "self", ")", ":", "\n", "        ", "return", "\"sbu\"", "\n", "", "", ""]], "home.repos.pwc.inspect_result.showlab_all-in-one.image.nlvr2_datamodule.NLVR2DataModule.__init__": [[6, 8], ["datamodule_base.BaseDataModule.__init__"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.transforms.utils.UnNormalize.__init__"], ["    ", "def", "__init__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.image.nlvr2_datamodule.NLVR2DataModule.dataset_cls": [[9, 12], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "dataset_cls", "(", "self", ")", ":", "\n", "        ", "return", "NLVR2Dataset", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.image.nlvr2_datamodule.NLVR2DataModule.dataset_name": [[13, 16], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "dataset_name", "(", "self", ")", ":", "\n", "        ", "return", "\"nlvr2\"", "\n", "", "", ""]], "home.repos.pwc.inspect_result.showlab_all-in-one.image.activitynet_datamodule.ActivityNetDataModule.__init__": [[6, 8], ["datamodule_base.BaseDataModule.__init__"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.transforms.utils.UnNormalize.__init__"], ["    ", "def", "__init__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.image.activitynet_datamodule.ActivityNetDataModule.dataset_cls": [[9, 12], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "dataset_cls", "(", "self", ")", ":", "\n", "        ", "return", "ActivityNetDataset", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.image.activitynet_datamodule.ActivityNetDataModule.dataset_name": [[13, 16], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "dataset_name", "(", "self", ")", ":", "\n", "        ", "return", "\"activitynet\"", "\n", "", "", ""]], "home.repos.pwc.inspect_result.showlab_all-in-one.image.conceptual_caption_datamodule.ConceptualCaptionDataModule.__init__": [[6, 8], ["datamodule_base.BaseDataModule.__init__"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.transforms.utils.UnNormalize.__init__"], ["    ", "def", "__init__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.image.conceptual_caption_datamodule.ConceptualCaptionDataModule.dataset_cls": [[9, 12], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "dataset_cls", "(", "self", ")", ":", "\n", "        ", "return", "ConceptualCaptionDataset", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.image.conceptual_caption_datamodule.ConceptualCaptionDataModule.dataset_name": [[13, 16], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "dataset_name", "(", "self", ")", ":", "\n", "        ", "return", "\"gcc\"", "\n", "", "", ""]], "home.repos.pwc.inspect_result.showlab_all-in-one.image.vqav2_dataset.VQAv2Dataset.__init__": [[5, 22], ["base_dataset.BaseDataset.__init__"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.transforms.utils.UnNormalize.__init__"], ["    ", "def", "__init__", "(", "self", ",", "*", "args", ",", "split", "=", "\"\"", ",", "**", "kwargs", ")", ":", "\n", "        ", "assert", "split", "in", "[", "\"train\"", ",", "\"val\"", ",", "\"test\"", "]", "\n", "self", ".", "split", "=", "split", "\n", "\n", "if", "split", "==", "\"train\"", ":", "\n", "            ", "names", "=", "[", "\"vqav2_train\"", ",", "\"vqav2_trainable_val\"", "]", "\n", "", "elif", "split", "==", "\"val\"", ":", "\n", "            ", "names", "=", "[", "\"vqav2_rest_val\"", "]", "\n", "", "elif", "split", "==", "\"test\"", ":", "\n", "            ", "names", "=", "[", "\"vqav2_test\"", "]", "# vqav2_test-dev for test-dev", "\n", "\n", "", "super", "(", ")", ".", "__init__", "(", "\n", "*", "args", ",", "\n", "**", "kwargs", ",", "\n", "names", "=", "names", ",", "\n", "text_column_name", "=", "\"questions\"", ",", "\n", "remove_duplicate", "=", "False", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.image.vqav2_dataset.VQAv2Dataset.__getitem__": [[24, 47], ["[].as_py", "vqav2_dataset.VQAv2Dataset.get_image", "vqav2_dataset.VQAv2Dataset.get_text", "[].as_py", "[].as_py", "[].as_py", "list", "list", "list"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.datasets.vcr.VCRDataset.get_image", "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_v2.Ego4DDataset.get_text"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "image_tensor", "=", "self", ".", "get_image", "(", "index", ")", "[", "\"image\"", "]", "\n", "text", "=", "self", ".", "get_text", "(", "index", ")", "[", "\"text\"", "]", "\n", "\n", "index", ",", "question_index", "=", "self", ".", "index_mapper", "[", "index", "]", "\n", "qid", "=", "self", ".", "table", "[", "\"question_id\"", "]", "[", "index", "]", "[", "question_index", "]", ".", "as_py", "(", ")", "\n", "\n", "if", "self", ".", "split", "!=", "\"test\"", ":", "\n", "            ", "answers", "=", "self", ".", "table", "[", "\"answers\"", "]", "[", "index", "]", "[", "question_index", "]", ".", "as_py", "(", ")", "\n", "labels", "=", "self", ".", "table", "[", "\"answer_labels\"", "]", "[", "index", "]", "[", "question_index", "]", ".", "as_py", "(", ")", "\n", "scores", "=", "self", ".", "table", "[", "\"answer_scores\"", "]", "[", "index", "]", "[", "question_index", "]", ".", "as_py", "(", ")", "\n", "", "else", ":", "\n", "            ", "answers", "=", "list", "(", ")", "\n", "labels", "=", "list", "(", ")", "\n", "scores", "=", "list", "(", ")", "\n", "\n", "", "return", "{", "\n", "\"image\"", ":", "image_tensor", ",", "\n", "\"text\"", ":", "text", ",", "\n", "\"vqa_answer\"", ":", "answers", ",", "\n", "\"vqa_labels\"", ":", "labels", ",", "\n", "\"vqa_scores\"", ":", "scores", ",", "\n", "\"qid\"", ":", "qid", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.image.cc12m.CC12MDataset.__init__": [[9, 22], ["cc12m.CC12MDataset._load_metadata", "print", "base_dataset.BaseDataset.__init__", "len"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_v2.Ego4DDataset._load_metadata", "home.repos.pwc.inspect_result.showlab_all-in-one.transforms.utils.UnNormalize.__init__"], ["    ", "def", "__init__", "(", "self", ",", "*", "args", ",", "split", "=", "\"\"", ",", "**", "kwargs", ")", ":", "\n", "        ", "assert", "split", "in", "[", "\"train\"", ",", "\"val\"", ",", "\"test\"", "]", "\n", "self", ".", "split", "=", "split", "\n", "self", ".", "metadata", "=", "None", "\n", "self", ".", "_load_metadata", "(", ")", "\n", "if", "split", "==", "\"train\"", ":", "\n", "            ", "names", "=", "[", "\"cc12m_train\"", "]", "\n", "", "elif", "split", "==", "\"val\"", ":", "\n", "            ", "names", "=", "[", "\"cc12m_val\"", "]", "\n", "", "elif", "split", "==", "\"test\"", ":", "\n", "            ", "names", "=", "[", "\"cc12m_val\"", "]", "\n", "", "print", "(", "names", ",", "\": \"", ",", "len", "(", "self", ".", "metadata", ")", ",", "\"samples in total.\"", ")", "\n", "super", "(", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ",", "names", "=", "names", ",", "text_column_name", "=", "\"caption\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.image.cc12m.CC12MDataset._load_metadata": [[23, 34], ["pandas.read_csv", "os.path.join"], "methods", ["None"], ["", "def", "_load_metadata", "(", "self", ")", ":", "\n", "# download specific", "\n", "        ", "metadata_dir", "=", "'./meta_data/cc12m'", "\n", "split_files", "=", "{", "\n", "'train'", ":", "'train.tsv'", ",", "\n", "'val'", ":", "'val.tsv'", ",", "\n", "'test'", ":", "'test.tsv'", "\n", "}", "\n", "target_split_fp", "=", "split_files", "[", "self", ".", "split", "]", "\n", "metadata", "=", "pd", ".", "read_csv", "(", "os", ".", "path", ".", "join", "(", "metadata_dir", ",", "target_split_fp", ")", ",", "sep", "=", "'\\t'", ")", "\n", "self", ".", "metadata", "=", "metadata", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.image.cc12m.CC12MDataset._get_image_path": [[35, 40], ["str().split", "os.path.join", "str"], "methods", ["None"], ["", "def", "_get_image_path", "(", "self", ",", "sample", ")", ":", "\n", "# print(sample[1])", "\n", "        ", "rel_fp", "=", "str", "(", "sample", "[", "1", "]", ")", ".", "split", "(", "'/'", ")", "[", "-", "1", "]", "\n", "# print(os.path.join(self.data_dir, rel_fp))", "\n", "return", "os", ".", "path", ".", "join", "(", "self", ".", "data_dir", ",", "rel_fp", ")", ",", "rel_fp", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.image.cc12m.CC12MDataset._get_caption": [[41, 43], ["None"], "methods", ["None"], ["", "def", "_get_caption", "(", "self", ",", "sample", ")", ":", "\n", "        ", "return", "sample", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.image.cc12m.CC12MDataset.get_raw_image": [[44, 52], ["cc12m.CC12MDataset._get_image_path", "PIL.Image.open().convert", "Exception", "PIL.Image.open"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.datasets.vcr.VCRDataset._get_image_path"], ["", "def", "get_raw_image", "(", "self", ",", "sample", ")", ":", "\n", "# print(sample)", "\n", "        ", "abs_fp", ",", "rel_fp", "=", "self", ".", "_get_image_path", "(", "sample", ")", "\n", "img", "=", "Image", ".", "open", "(", "abs_fp", ")", ".", "convert", "(", "\"RGB\"", ")", "\n", "if", "img", "is", "None", ":", "\n", "            ", "raise", "Exception", "(", "\"Invalid img!\"", ",", "rel_fp", ")", "\n", "", "else", ":", "\n", "            ", "return", "img", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.image.cc12m.CC12MDataset._get_object_path": [[53, 64], ["os.path.join", "os.path.join", "os.path.join"], "methods", ["None"], ["", "", "def", "_get_object_path", "(", "self", ",", "sample", ")", ":", "\n", "        ", "\"\"\"\n        get the object npy path\n        Args:\n            sample (dict):\n        Returns:\n            abs path\n        \"\"\"", "\n", "rel_object_fp", "=", "os", ".", "path", ".", "join", "(", "sample", "[", "1", "]", ",", "'1.npz'", ")", "\n", "full_object_fp", "=", "os", ".", "path", ".", "join", "(", "self", ".", "object_dir", ",", "self", ".", "split", ",", "rel_object_fp", ")", "\n", "return", "os", ".", "path", ".", "join", "(", "self", ".", "split", ",", "rel_object_fp", ")", ",", "full_object_fp", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.image.cc12m.CC12MDataset.get_image": [[65, 74], ["cc12m.CC12MDataset.get_raw_image", "cc12m.CC12MDataset.image_aug"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.datasets.vcr.VCRDataset.get_raw_image", "home.repos.pwc.inspect_result.showlab_all-in-one.image.imageaug.image_aug"], ["", "def", "get_image", "(", "self", ",", "index", ",", "sample", ",", "image_key", "=", "\"image\"", ")", ":", "\n", "        ", "image", "=", "self", ".", "get_raw_image", "(", "sample", ")", "\n", "image_tensor", "=", "self", ".", "image_aug", "(", "image", ",", "self", ".", "transforms", ")", "\n", "# image_tensor = [tr(image).unsqueeze(0) for tr in self.transforms]", "\n", "return", "{", "\n", "\"video\"", ":", "image_tensor", ",", "\n", "\"vid_index\"", ":", "sample", "[", "1", "]", ",", "\n", "\"cap_index\"", ":", "index", ",", "\n", "\"raw_index\"", ":", "index", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.image.cc12m.CC12MDataset.get_false_image": [[76, 83], ["random.randint", "cc12m.CC12MDataset.get_raw_image", "cc12m.CC12MDataset.image_aug", "len"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.datasets.vcr.VCRDataset.get_raw_image", "home.repos.pwc.inspect_result.showlab_all-in-one.image.imageaug.image_aug"], ["", "def", "get_false_image", "(", "self", ",", "rep", ",", "image_key", "=", "\"image\"", ")", ":", "\n", "        ", "random_index", "=", "random", ".", "randint", "(", "0", ",", "len", "(", "self", ".", "metadata", ")", "-", "1", ")", "\n", "sample", "=", "self", ".", "metadata", ".", "iloc", "[", "random_index", "]", "\n", "image", "=", "self", ".", "get_raw_image", "(", "sample", ")", "\n", "#image_tensor = [tr(image).unsqueeze(0) for tr in self.transforms]", "\n", "image_tensor", "=", "self", ".", "image_aug", "(", "image", ",", "self", ".", "transforms", ")", "\n", "return", "{", "f\"false_video_{rep}\"", ":", "image_tensor", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.image.cc12m.CC12MDataset.get_text": [[84, 98], ["cc12m.CC12MDataset.tokenizer"], "methods", ["None"], ["", "def", "get_text", "(", "self", ",", "raw_index", ",", "sample", ")", ":", "\n", "        ", "text", "=", "sample", "[", "0", "]", "\n", "encoding", "=", "self", ".", "tokenizer", "(", "\n", "text", ",", "\n", "padding", "=", "\"max_length\"", ",", "\n", "truncation", "=", "True", ",", "\n", "max_length", "=", "self", ".", "max_text_len", ",", "\n", "return_special_tokens_mask", "=", "True", ",", "\n", ")", "\n", "return", "{", "\n", "\"text\"", ":", "(", "text", ",", "encoding", ")", ",", "\n", "\"vid_index\"", ":", "sample", "[", "1", "]", ",", "\n", "\"cap_index\"", ":", "raw_index", ",", "\n", "\"raw_index\"", ":", "raw_index", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.image.cc12m.CC12MDataset.get_false_text": [[100, 111], ["random.randint", "cc12m.CC12MDataset.tokenizer", "len"], "methods", ["None"], ["", "def", "get_false_text", "(", "self", ",", "rep", ")", ":", "\n", "        ", "random_index", "=", "random", ".", "randint", "(", "0", ",", "len", "(", "self", ".", "metadata", ")", "-", "1", ")", "\n", "sample", "=", "self", ".", "metadata", ".", "iloc", "[", "random_index", "]", "\n", "text", "=", "sample", "[", "0", "]", "\n", "encoding", "=", "self", ".", "tokenizer", "(", "\n", "text", ",", "\n", "truncation", "=", "True", ",", "\n", "max_length", "=", "self", ".", "max_text_len", ",", "\n", "return_special_tokens_mask", "=", "True", ",", "\n", ")", "\n", "return", "{", "f\"false_text_{rep}\"", ":", "(", "text", ",", "encoding", ")", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.image.cc12m.CC12MDataset.get_suite": [[112, 136], ["dict", "dict.update", "range", "range", "cc12m.CC12MDataset.get_image", "cc12m.CC12MDataset.get_text", "dict.update", "dict.update", "dict.update", "dict.update", "print", "random.randint", "cc12m.CC12MDataset.get_false_image", "cc12m.CC12MDataset.get_false_text", "len"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.gadgets.my_metrics.VQAScore.update", "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.vcr.VCRDataset.get_image", "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_v2.Ego4DDataset.get_text", "home.repos.pwc.inspect_result.showlab_all-in-one.gadgets.my_metrics.VQAScore.update", "home.repos.pwc.inspect_result.showlab_all-in-one.gadgets.my_metrics.VQAScore.update", "home.repos.pwc.inspect_result.showlab_all-in-one.gadgets.my_metrics.VQAScore.update", "home.repos.pwc.inspect_result.showlab_all-in-one.gadgets.my_metrics.VQAScore.update", "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.vcr.VCRDataset.get_false_image", "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_v2.Ego4DDataset.get_false_text"], ["", "def", "get_suite", "(", "self", ",", "index", ")", ":", "\n", "        ", "result", "=", "None", "\n", "# print(self.draw_false_image) # 1", "\n", "while", "result", "is", "None", ":", "\n", "            ", "sample", "=", "self", ".", "metadata", ".", "iloc", "[", "index", "]", "\n", "# print(sample)", "\n", "try", ":", "\n", "                ", "ret", "=", "dict", "(", ")", "\n", "ret", ".", "update", "(", "self", ".", "get_image", "(", "index", ",", "sample", ")", ")", "\n", "if", "not", "self", ".", "image_only", ":", "\n", "                    ", "txt", "=", "self", ".", "get_text", "(", "index", ",", "sample", ")", "\n", "ret", ".", "update", "(", "{", "\"replica\"", ":", "True", "if", "txt", "[", "\"cap_index\"", "]", ">", "0", "else", "False", "}", ")", "\n", "ret", ".", "update", "(", "txt", ")", "\n", "\n", "", "for", "i", "in", "range", "(", "self", ".", "draw_false_image", ")", ":", "\n", "                    ", "ret", ".", "update", "(", "self", ".", "get_false_image", "(", "i", ")", ")", "\n", "", "for", "i", "in", "range", "(", "self", ".", "draw_false_text", ")", ":", "\n", "                    ", "ret", ".", "update", "(", "self", ".", "get_false_text", "(", "i", ")", ")", "\n", "", "result", "=", "True", "\n", "", "except", "Exception", "as", "e", ":", "\n", "                ", "print", "(", "f\"Error while read file idx {sample[1]} in {self.names[0]} -> {e}\"", ")", "\n", "index", "=", "random", ".", "randint", "(", "0", ",", "len", "(", "self", ".", "metadata", ")", "-", "1", ")", "\n", "# ret[\"image\"] = ret[\"image\"].unsqueeze(1)", "\n", "", "", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.image.cc12m.CC12MDataset.__len__": [[137, 139], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "metadata", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.image.cc12m.CC12MDataset.__getitem__": [[140, 142], ["cc12m.CC12MDataset.get_suite"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_v2.Ego4DDataset.get_suite"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "return", "self", ".", "get_suite", "(", "index", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.image.coco_caption_karpathy_dataset.CocoCaptionKarpathyDataset.__init__": [[5, 20], ["base_dataset.BaseDataset.__init__"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.transforms.utils.UnNormalize.__init__"], ["    ", "def", "__init__", "(", "self", ",", "*", "args", ",", "split", "=", "\"\"", ",", "**", "kwargs", ")", ":", "\n", "        ", "assert", "split", "in", "[", "\"train\"", ",", "\"val\"", ",", "\"test\"", "]", "\n", "self", ".", "split", "=", "split", "\n", "\n", "if", "split", "==", "\"train\"", ":", "\n", "            ", "names", "=", "[", "\"coco_caption_karpathy_train\"", "]", "# , \"coco_caption_karpathy_restval\"", "\n", "", "elif", "split", "==", "\"val\"", ":", "\n", "            ", "names", "=", "[", "\"coco_caption_karpathy_val\"", "]", "\n", "# names = [\"coco_caption_karpathy_test\"]", "\n", "# names = []  # for fast train", "\n", "", "elif", "split", "==", "\"test\"", ":", "\n", "            ", "names", "=", "[", "\"coco_caption_karpathy_test\"", "]", "\n", "# names = []", "\n", "\n", "", "super", "(", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ",", "names", "=", "names", ",", "text_column_name", "=", "\"caption\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.image.coco_caption_karpathy_dataset.CocoCaptionKarpathyDataset.__getitem__": [[21, 31], ["coco_caption_karpathy_dataset.CocoCaptionKarpathyDataset.get_suite", "[].as_py", "int", "coco_caption_karpathy_dataset.CocoCaptionKarpathyDataset.update", "[].split", "int.split"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_v2.Ego4DDataset.get_suite", "home.repos.pwc.inspect_result.showlab_all-in-one.gadgets.my_metrics.VQAScore.update"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "suite", "=", "self", ".", "get_suite", "(", "index", ")", "\n", "\n", "if", "\"test\"", "in", "self", ".", "split", ":", "\n", "            ", "_index", ",", "_question_index", "=", "self", ".", "index_mapper", "[", "index", "]", "\n", "iid", "=", "self", ".", "table", "[", "\"image_id\"", "]", "[", "_index", "]", ".", "as_py", "(", ")", "\n", "iid", "=", "int", "(", "iid", ".", "split", "(", "\".\"", ")", "[", "0", "]", ".", "split", "(", "\"_\"", ")", "[", "-", "1", "]", ")", "\n", "suite", ".", "update", "(", "{", "\"iid\"", ":", "iid", "}", ")", "\n", "\n", "", "return", "suite", "\n", "", "", ""]], "home.repos.pwc.inspect_result.showlab_all-in-one.image.sbu_caption_dataset.SBUCaptionDataset.__init__": [[6, 17], ["base_dataset.BaseDataset.__init__", "range"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.transforms.utils.UnNormalize.__init__"], ["    ", "def", "__init__", "(", "self", ",", "*", "args", ",", "split", "=", "\"\"", ",", "**", "kwargs", ")", ":", "\n", "        ", "assert", "split", "in", "[", "\"train\"", ",", "\"val\"", ",", "\"test\"", "]", "\n", "if", "split", "==", "\"test\"", ":", "\n", "            ", "split", "=", "\"val\"", "\n", "\n", "", "if", "split", "==", "\"train\"", ":", "\n", "            ", "names", "=", "[", "f\"sbu_{i}\"", "for", "i", "in", "range", "(", "9", ")", "]", "\n", "", "elif", "split", "==", "\"val\"", ":", "\n", "            ", "names", "=", "[", "]", "\n", "\n", "", "super", "(", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ",", "names", "=", "names", ",", "text_column_name", "=", "\"caption\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.image.sbu_caption_dataset.SBUCaptionDataset.__getitem__": [[18, 20], ["sbu_caption_dataset.SBUCaptionDataset.get_suite"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_v2.Ego4DDataset.get_suite"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "return", "self", ".", "get_suite", "(", "index", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.showlab_all-in-one.image.base_dataset.BaseDataset.__init__": [[15, 102], ["super().__init__", "CoTrain.transforms.keys_to_transforms", "len", "torch.distributed.get_rank", "print", "print", "len", "os.path.join", "torch.distributed.get_rank", "print", "dict", "names[].split", "torch.distributed.get_rank", "print", "len", "list", "enumerate", "pyarrow.concat_tables", "list", "enumerate", "range", "names[].split", "pyarrow.ipc.RecordBatchFileReader().read_all", "base_dataset.BaseDataset.table[].to_pandas().tolist", "list", "range", "len", "os.path.isfile", "len", "len", "pyarrow.ipc.RecordBatchFileReader", "base_dataset.BaseDataset.table[].to_pandas", "list", "pyarrow.memory_map", "set"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.transforms.utils.UnNormalize.__init__", "home.repos.pwc.inspect_result.showlab_all-in-one.transforms.__init__.keys_to_transforms", "home.repos.pwc.inspect_result.showlab_all-in-one.modules.dist_utils.get_rank", "home.repos.pwc.inspect_result.showlab_all-in-one.modules.dist_utils.get_rank", "home.repos.pwc.inspect_result.showlab_all-in-one.modules.dist_utils.get_rank"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "data_dir", ":", "str", ",", "\n", "transform_keys", ":", "list", ",", "\n", "image_size", ":", "int", ",", "\n", "names", ":", "list", ",", "\n", "text_column_name", ":", "str", "=", "\"\"", ",", "\n", "remove_duplicate", "=", "True", ",", "\n", "max_text_len", "=", "40", ",", "\n", "draw_false_image", "=", "0", ",", "\n", "draw_false_video", "=", "0", ",", "\n", "draw_false_text", "=", "0", ",", "\n", "image_only", "=", "False", ",", "\n", "num_frames", "=", "1", ",", "\n", "draw_options_text", "=", "0", ",", "\n", "backend", "=", "'v100'", "\n", ")", ":", "\n", "        ", "\"\"\"\n        data_dir : where dataset file *.arrow lives; existence should be guaranteed via DataModule.prepare_data\n        transform_keys : keys for generating augmented views of images\n        text_column_name : pyarrow table column name that has list of strings as elements\n        \"\"\"", "\n", "assert", "len", "(", "transform_keys", ")", ">=", "1", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "transforms", "=", "keys_to_transforms", "(", "transform_keys", ",", "size", "=", "image_size", ")", "\n", "self", ".", "image_aug", "=", "image_aug", "\n", "self", ".", "text_column_name", "=", "text_column_name", "\n", "self", ".", "names", "=", "names", "\n", "self", ".", "max_text_len", "=", "max_text_len", "\n", "self", ".", "draw_false_image", "=", "draw_false_image", "\n", "self", ".", "draw_false_text", "=", "draw_false_text", "\n", "self", ".", "image_only", "=", "image_only", "\n", "self", ".", "data_dir", "=", "data_dir", "\n", "self", ".", "draw_options_text", "=", "draw_options_text", "\n", "if", "torch", ".", "distributed", ".", "get_rank", "(", ")", "==", "0", ":", "\n", "            ", "print", "(", "'*'", "*", "100", ")", "\n", "print", "(", "\"image sub datasets: {}\"", ".", "format", "(", "names", ")", ")", "\n", "# print(names)", "\n", "", "split_name", "=", "None", "\n", "if", "len", "(", "names", ")", "!=", "0", ":", "\n", "            ", "self", ".", "data_dir", "=", "os", ".", "path", ".", "join", "(", "self", ".", "data_dir", ",", "names", "[", "0", "]", ".", "split", "(", "'_'", ")", "[", "0", "]", ")", "# e.g. coco_train -> coco", "\n", "split_name", "=", "names", "[", "0", "]", ".", "split", "(", "'_'", ")", "[", "0", "]", "\n", "", "if", "torch", ".", "distributed", ".", "get_rank", "(", ")", "==", "0", ":", "\n", "            ", "print", "(", "self", ".", "data_dir", ")", "\n", "", "if", "split_name", "and", "split_name", "in", "[", "'msrvtt'", ",", "'cc3m'", ",", "'vcr'", ",", "'cc12m'", "]", ":", "\n", "            ", "if", "torch", ".", "distributed", ".", "get_rank", "(", ")", "==", "0", ":", "\n", "                ", "print", "(", "\"no arrow available for {}, load from disk\"", ".", "format", "(", "names", "[", "0", "]", ")", ")", "\n", "", "", "else", ":", "\n", "            ", "if", "len", "(", "names", ")", "!=", "0", ":", "\n", "                ", "tables", "=", "[", "\n", "pa", ".", "ipc", ".", "RecordBatchFileReader", "(", "\n", "pa", ".", "memory_map", "(", "f\"{self.data_dir}/{name}.arrow\"", ",", "\"r\"", ")", "\n", ")", ".", "read_all", "(", ")", "\n", "for", "name", "in", "names", "\n", "if", "os", ".", "path", ".", "isfile", "(", "f\"{self.data_dir}/{name}.arrow\"", ")", "\n", "]", "\n", "# print(names, tables)", "\n", "self", ".", "table_names", "=", "list", "(", ")", "\n", "for", "i", ",", "name", "in", "enumerate", "(", "names", ")", ":", "\n", "                    ", "self", ".", "table_names", "+=", "[", "name", "]", "*", "len", "(", "tables", "[", "i", "]", ")", "\n", "\n", "", "self", ".", "table", "=", "pa", ".", "concat_tables", "(", "tables", ",", "promote", "=", "True", ")", "\n", "if", "text_column_name", "!=", "\"\"", ":", "\n", "                    ", "self", ".", "text_column_name", "=", "text_column_name", "\n", "self", ".", "all_texts", "=", "self", ".", "table", "[", "text_column_name", "]", ".", "to_pandas", "(", ")", ".", "tolist", "(", ")", "\n", "self", ".", "all_texts", "=", "(", "\n", "[", "list", "(", "set", "(", "texts", ")", ")", "for", "texts", "in", "self", ".", "all_texts", "]", "\n", "if", "remove_duplicate", "\n", "else", "self", ".", "all_texts", "\n", ")", "\n", "", "else", ":", "\n", "                    ", "self", ".", "all_texts", "=", "list", "(", ")", "\n", "", "", "else", ":", "\n", "                ", "self", ".", "all_texts", "=", "list", "(", ")", "\n", "\n", "", "self", ".", "index_mapper", "=", "dict", "(", ")", "\n", "\n", "if", "text_column_name", "!=", "\"\"", "and", "not", "self", ".", "image_only", ":", "\n", "                ", "j", "=", "0", "\n", "for", "i", ",", "texts", "in", "enumerate", "(", "self", ".", "all_texts", ")", ":", "\n", "                    ", "for", "_j", "in", "range", "(", "len", "(", "texts", ")", ")", ":", "\n", "                        ", "self", ".", "index_mapper", "[", "j", "]", "=", "(", "i", ",", "_j", ")", "\n", "j", "+=", "1", "\n", "", "", "", "else", ":", "\n", "                ", "for", "i", "in", "range", "(", "len", "(", "self", ".", "table", ")", ")", ":", "\n", "                    ", "self", ".", "index_mapper", "[", "i", "]", "=", "(", "i", ",", "None", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.image.base_dataset.BaseDataset.corpus": [[143, 146], ["None"], "methods", ["None"], ["", "", "", "", "@", "property", "\n", "def", "corpus", "(", "self", ")", ":", "\n", "        ", "return", "[", "text", "for", "texts", "in", "self", ".", "all_texts", "for", "text", "in", "texts", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.image.base_dataset.BaseDataset.__len__": [[147, 149], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "index_mapper", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.image.base_dataset.BaseDataset.get_raw_image": [[150, 155], ["io.BytesIO", "io.BytesIO.seek", "PIL.Image.open().convert", "[].as_py", "PIL.Image.open"], "methods", ["None"], ["", "def", "get_raw_image", "(", "self", ",", "index", ",", "image_key", "=", "\"image\"", ")", ":", "\n", "        ", "index", ",", "caption_index", "=", "self", ".", "index_mapper", "[", "index", "]", "\n", "image_bytes", "=", "io", ".", "BytesIO", "(", "self", ".", "table", "[", "image_key", "]", "[", "index", "]", ".", "as_py", "(", ")", ")", "\n", "image_bytes", ".", "seek", "(", "0", ")", "\n", "return", "Image", ".", "open", "(", "image_bytes", ")", ".", "convert", "(", "\"RGB\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.image.base_dataset.BaseDataset.get_image": [[156, 165], ["base_dataset.BaseDataset.get_raw_image", "base_dataset.BaseDataset.image_aug"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.datasets.vcr.VCRDataset.get_raw_image", "home.repos.pwc.inspect_result.showlab_all-in-one.image.imageaug.image_aug"], ["", "def", "get_image", "(", "self", ",", "index", ",", "image_key", "=", "\"image\"", ")", ":", "\n", "        ", "image", "=", "self", ".", "get_raw_image", "(", "index", ",", "image_key", "=", "image_key", ")", "\n", "# image_tensor = [tr(image).unsqueeze(0) for tr in self.transforms]", "\n", "image_tensor", "=", "self", ".", "image_aug", "(", "image", ",", "self", ".", "transforms", ")", "\n", "return", "{", "\n", "\"video\"", ":", "image_tensor", ",", "\n", "\"vid_index\"", ":", "self", ".", "index_mapper", "[", "index", "]", "[", "0", "]", ",", "\n", "\"cap_index\"", ":", "self", ".", "index_mapper", "[", "index", "]", "[", "1", "]", ",", "\n", "\"raw_index\"", ":", "index", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.image.base_dataset.BaseDataset.get_false_image": [[167, 173], ["random.randint", "base_dataset.BaseDataset.get_raw_image", "base_dataset.BaseDataset.image_aug", "len"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.datasets.vcr.VCRDataset.get_raw_image", "home.repos.pwc.inspect_result.showlab_all-in-one.image.imageaug.image_aug"], ["", "def", "get_false_image", "(", "self", ",", "rep", ",", "image_key", "=", "\"image\"", ")", ":", "\n", "        ", "random_index", "=", "random", ".", "randint", "(", "0", ",", "len", "(", "self", ".", "index_mapper", ")", "-", "1", ")", "\n", "image", "=", "self", ".", "get_raw_image", "(", "random_index", ",", "image_key", "=", "image_key", ")", "\n", "# image_tensor = [tr(image).unsqueeze(0) for tr in self.transforms]", "\n", "image_tensor", "=", "self", ".", "image_aug", "(", "image", ",", "self", ".", "transforms", ")", "\n", "return", "{", "f\"false_video_{rep}\"", ":", "image_tensor", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.image.base_dataset.BaseDataset.get_text": [[174, 190], ["base_dataset.BaseDataset.tokenizer"], "methods", ["None"], ["", "def", "get_text", "(", "self", ",", "raw_index", ")", ":", "\n", "        ", "index", ",", "caption_index", "=", "self", ".", "index_mapper", "[", "raw_index", "]", "\n", "\n", "text", "=", "self", ".", "all_texts", "[", "index", "]", "[", "caption_index", "]", "\n", "encoding", "=", "self", ".", "tokenizer", "(", "\n", "text", ",", "\n", "padding", "=", "\"max_length\"", ",", "\n", "truncation", "=", "True", ",", "\n", "max_length", "=", "self", ".", "max_text_len", ",", "\n", "return_special_tokens_mask", "=", "True", ",", "\n", ")", "\n", "return", "{", "\n", "\"text\"", ":", "(", "text", ",", "encoding", ")", ",", "\n", "\"vid_index\"", ":", "index", ",", "\n", "\"cap_index\"", ":", "caption_index", ",", "\n", "\"raw_index\"", ":", "raw_index", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.image.base_dataset.BaseDataset.get_false_text": [[192, 203], ["random.randint", "base_dataset.BaseDataset.tokenizer", "len"], "methods", ["None"], ["", "def", "get_false_text", "(", "self", ",", "rep", ")", ":", "\n", "        ", "random_index", "=", "random", ".", "randint", "(", "0", ",", "len", "(", "self", ".", "index_mapper", ")", "-", "1", ")", "\n", "index", ",", "caption_index", "=", "self", ".", "index_mapper", "[", "random_index", "]", "\n", "text", "=", "self", ".", "all_texts", "[", "index", "]", "[", "caption_index", "]", "\n", "encoding", "=", "self", ".", "tokenizer", "(", "\n", "text", ",", "\n", "truncation", "=", "True", ",", "\n", "max_length", "=", "self", ".", "max_text_len", ",", "\n", "return_special_tokens_mask", "=", "True", ",", "\n", ")", "\n", "return", "{", "f\"false_text_{rep}\"", ":", "(", "text", ",", "encoding", ")", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.image.base_dataset.BaseDataset.get_suite": [[204, 224], ["dict", "dict.update", "range", "range", "base_dataset.BaseDataset.get_image", "base_dataset.BaseDataset.get_text", "dict.update", "dict.update", "dict.update", "dict.update", "print", "random.randint", "base_dataset.BaseDataset.get_false_image", "base_dataset.BaseDataset.get_false_text", "len"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.gadgets.my_metrics.VQAScore.update", "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.vcr.VCRDataset.get_image", "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_v2.Ego4DDataset.get_text", "home.repos.pwc.inspect_result.showlab_all-in-one.gadgets.my_metrics.VQAScore.update", "home.repos.pwc.inspect_result.showlab_all-in-one.gadgets.my_metrics.VQAScore.update", "home.repos.pwc.inspect_result.showlab_all-in-one.gadgets.my_metrics.VQAScore.update", "home.repos.pwc.inspect_result.showlab_all-in-one.gadgets.my_metrics.VQAScore.update", "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.vcr.VCRDataset.get_false_image", "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_v2.Ego4DDataset.get_false_text"], ["", "def", "get_suite", "(", "self", ",", "index", ")", ":", "\n", "        ", "result", "=", "None", "\n", "while", "result", "is", "None", ":", "\n", "            ", "try", ":", "\n", "                ", "ret", "=", "dict", "(", ")", "\n", "ret", ".", "update", "(", "self", ".", "get_image", "(", "index", ")", ")", "\n", "if", "not", "self", ".", "image_only", ":", "\n", "                    ", "txt", "=", "self", ".", "get_text", "(", "index", ")", "\n", "ret", ".", "update", "(", "{", "\"replica\"", ":", "True", "if", "txt", "[", "\"cap_index\"", "]", ">", "0", "else", "False", "}", ")", "\n", "ret", ".", "update", "(", "txt", ")", "\n", "\n", "", "for", "i", "in", "range", "(", "self", ".", "draw_false_image", ")", ":", "\n", "                    ", "ret", ".", "update", "(", "self", ".", "get_false_image", "(", "i", ")", ")", "\n", "", "for", "i", "in", "range", "(", "self", ".", "draw_false_text", ")", ":", "\n", "                    ", "ret", ".", "update", "(", "self", ".", "get_false_text", "(", "i", ")", ")", "\n", "", "result", "=", "True", "\n", "", "except", "Exception", "as", "e", ":", "\n", "                ", "print", "(", "f\"Error while read file idx {index} in {self.names[0]} -> {e}\"", ")", "\n", "index", "=", "random", ".", "randint", "(", "0", ",", "len", "(", "self", ".", "index_mapper", ")", "-", "1", ")", "\n", "", "", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.image.base_dataset.BaseDataset.collate": [[225, 302], ["len", "set", "list", "len", "max", "max", "len", "range", "len", "len", "mlm_collator", "enumerate", "list", "len", "torch.zeros", "range", "list", "torch.zeros_like", "torch.zeros_like", "enumerate", "torch.full_like", "b.keys", "dict_batch.keys", "range", "dict_batch.keys", "torch.tensor", "torch.tensor", "len", "len"], "methods", ["None"], ["", "def", "collate", "(", "self", ",", "batch", ",", "mlm_collator", ")", ":", "\n", "        ", "batch_size", "=", "len", "(", "batch", ")", "\n", "keys", "=", "set", "(", "[", "key", "for", "b", "in", "batch", "for", "key", "in", "b", ".", "keys", "(", ")", "]", ")", "\n", "dict_batch", "=", "{", "k", ":", "[", "dic", "[", "k", "]", "if", "k", "in", "dic", "else", "None", "for", "dic", "in", "batch", "]", "for", "k", "in", "keys", "}", "\n", "# print(dict_batch)", "\n", "\n", "img_keys", "=", "[", "k", "for", "k", "in", "list", "(", "dict_batch", ".", "keys", "(", ")", ")", "if", "\"video\"", "in", "k", "]", "\n", "img_sizes", "=", "list", "(", ")", "\n", "\n", "for", "img_key", "in", "img_keys", ":", "\n", "            ", "img_sizes", "+=", "[", "ii", ".", "shape", "for", "i", "in", "dict_batch", "[", "img_key", "]", "if", "i", "is", "not", "None", "for", "ii", "in", "i", "]", "\n", "\n", "", "for", "size", "in", "img_sizes", ":", "\n", "            ", "assert", "(", "\n", "len", "(", "size", ")", "==", "4", "\n", ")", ",", "f\"Collate error, an image should be in shape of (N, 3,  H, W), instead of given {size}\"", "\n", "\n", "", "if", "len", "(", "img_keys", ")", "!=", "0", ":", "\n", "            ", "global_max_height", "=", "max", "(", "[", "i", "[", "2", "]", "for", "i", "in", "img_sizes", "]", ")", "\n", "global_max_width", "=", "max", "(", "[", "i", "[", "3", "]", "for", "i", "in", "img_sizes", "]", ")", "\n", "", "for", "img_key", "in", "img_keys", ":", "\n", "            ", "img", "=", "dict_batch", "[", "img_key", "]", "\n", "view_size", "=", "len", "(", "dict_batch", "[", "img_key", "]", "[", "0", "]", ")", "\n", "new_images", "=", "[", "\n", "torch", ".", "zeros", "(", "batch_size", ",", "1", ",", "3", ",", "global_max_height", ",", "global_max_width", ")", "\n", "for", "_", "in", "range", "(", "view_size", ")", "\n", "]", "\n", "# print(len(img))", "\n", "for", "bi", "in", "range", "(", "batch_size", ")", ":", "\n", "                ", "orig_batch", "=", "img", "[", "bi", "]", "\n", "for", "vi", "in", "range", "(", "view_size", ")", ":", "\n", "                    ", "if", "orig_batch", "is", "None", ":", "\n", "                        ", "continue", "\n", "", "else", ":", "\n", "                        ", "orig", "=", "img", "[", "bi", "]", "[", "vi", "]", "\n", "new_images", "[", "vi", "]", "[", "bi", ",", ":", ",", ":", ",", ":", "orig", ".", "shape", "[", "2", "]", ",", ":", "orig", ".", "shape", "[", "3", "]", "]", "=", "orig", "\n", "\n", "", "", "", "dict_batch", "[", "img_key", "]", "=", "new_images", "\n", "\n", "", "txt_keys", "=", "[", "k", "for", "k", "in", "list", "(", "dict_batch", ".", "keys", "(", ")", ")", "if", "\"text\"", "in", "k", "]", "\n", "\n", "if", "len", "(", "txt_keys", ")", "!=", "0", ":", "\n", "            ", "texts", "=", "[", "[", "d", "[", "0", "]", "for", "d", "in", "dict_batch", "[", "txt_key", "]", "]", "for", "txt_key", "in", "txt_keys", "]", "\n", "encodings", "=", "[", "[", "d", "[", "1", "]", "for", "d", "in", "dict_batch", "[", "txt_key", "]", "]", "for", "txt_key", "in", "txt_keys", "]", "\n", "draw_text_len", "=", "len", "(", "encodings", ")", "\n", "flatten_encodings", "=", "[", "e", "for", "encoding", "in", "encodings", "for", "e", "in", "encoding", "]", "\n", "flatten_mlms", "=", "mlm_collator", "(", "flatten_encodings", ")", "\n", "\n", "for", "i", ",", "txt_key", "in", "enumerate", "(", "txt_keys", ")", ":", "\n", "                ", "texts", ",", "encodings", "=", "(", "\n", "[", "d", "[", "0", "]", "for", "d", "in", "dict_batch", "[", "txt_key", "]", "]", ",", "\n", "[", "d", "[", "1", "]", "for", "d", "in", "dict_batch", "[", "txt_key", "]", "]", ",", "\n", ")", "\n", "\n", "mlm_ids", ",", "mlm_labels", "=", "(", "\n", "flatten_mlms", "[", "\"input_ids\"", "]", "[", "batch_size", "*", "(", "i", ")", ":", "batch_size", "*", "(", "i", "+", "1", ")", "]", ",", "\n", "flatten_mlms", "[", "\"labels\"", "]", "[", "batch_size", "*", "(", "i", ")", ":", "batch_size", "*", "(", "i", "+", "1", ")", "]", ",", "\n", ")", "\n", "\n", "input_ids", "=", "torch", ".", "zeros_like", "(", "mlm_ids", ")", "\n", "attention_mask", "=", "torch", ".", "zeros_like", "(", "mlm_ids", ")", "\n", "for", "_i", ",", "encoding", "in", "enumerate", "(", "encodings", ")", ":", "\n", "                    ", "_input_ids", ",", "_attention_mask", "=", "(", "\n", "torch", ".", "tensor", "(", "encoding", "[", "\"input_ids\"", "]", ")", ",", "\n", "torch", ".", "tensor", "(", "encoding", "[", "\"attention_mask\"", "]", ")", ",", "\n", ")", "\n", "input_ids", "[", "_i", ",", ":", "len", "(", "_input_ids", ")", "]", "=", "_input_ids", "\n", "attention_mask", "[", "_i", ",", ":", "len", "(", "_attention_mask", ")", "]", "=", "_attention_mask", "\n", "\n", "", "dict_batch", "[", "txt_key", "]", "=", "texts", "\n", "dict_batch", "[", "f\"{txt_key}_ids\"", "]", "=", "input_ids", "\n", "dict_batch", "[", "f\"{txt_key}_labels\"", "]", "=", "torch", ".", "full_like", "(", "input_ids", ",", "-", "100", ")", "\n", "dict_batch", "[", "f\"{txt_key}_ids_mlm\"", "]", "=", "mlm_ids", "\n", "dict_batch", "[", "f\"{txt_key}_labels_mlm\"", "]", "=", "mlm_labels", "\n", "dict_batch", "[", "f\"{txt_key}_masks\"", "]", "=", "attention_mask", "\n", "\n", "", "", "return", "dict_batch", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.image.base_dataset.sample_frames": [[402, 418], ["min", "numpy.linspace().astype", "enumerate", "ranges.append", "numpy.linspace", "random.choice", "range"], "function", ["None"], ["", "", "def", "sample_frames", "(", "num_frames", ",", "vlen", ",", "sample", "=", "'rand'", ",", "fix_start", "=", "None", ")", ":", "\n", "    ", "acc_samples", "=", "min", "(", "num_frames", ",", "vlen", ")", "\n", "intervals", "=", "np", ".", "linspace", "(", "start", "=", "0", ",", "stop", "=", "vlen", ",", "num", "=", "acc_samples", "+", "1", ")", ".", "astype", "(", "int", ")", "\n", "ranges", "=", "[", "]", "\n", "for", "idx", ",", "interv", "in", "enumerate", "(", "intervals", "[", ":", "-", "1", "]", ")", ":", "\n", "        ", "ranges", ".", "append", "(", "(", "interv", ",", "intervals", "[", "idx", "+", "1", "]", "-", "1", ")", ")", "\n", "", "if", "sample", "==", "'rand'", ":", "\n", "        ", "frame_idxs", "=", "[", "random", ".", "choice", "(", "range", "(", "x", "[", "0", "]", ",", "x", "[", "1", "]", ")", ")", "for", "x", "in", "ranges", "]", "\n", "", "elif", "fix_start", "is", "not", "None", ":", "\n", "        ", "frame_idxs", "=", "[", "x", "[", "0", "]", "+", "fix_start", "for", "x", "in", "ranges", "]", "\n", "", "elif", "sample", "==", "'uniform'", ":", "\n", "        ", "frame_idxs", "=", "[", "(", "x", "[", "0", "]", "+", "x", "[", "1", "]", ")", "//", "2", "for", "x", "in", "ranges", "]", "\n", "", "else", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n", "", "return", "frame_idxs", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.image.base_dataset.read_frames_cv2": [[420, 446], ["cv2.VideoCapture", "cv2.VideoCapture.isOpened", "int", "base_dataset.sample_frames", "torch.stack", "cv2.VideoCapture.release", "cv2.VideoCapture.get", "cv2.VideoCapture.set", "cv2.VideoCapture.read", "cv2.cvtColor", "torch.from_numpy().byte", "frame.permute.permute", "torch.stack.append", "success_idxs.append", "torch.from_numpy"], "function", ["home.repos.pwc.inspect_result.showlab_all-in-one.datasets.base_dataset.sample_frames"], ["", "def", "read_frames_cv2", "(", "video_path", ",", "num_frames", ",", "sample", "=", "'rand'", ",", "fix_start", "=", "None", ")", ":", "\n", "    ", "cap", "=", "cv2", ".", "VideoCapture", "(", "video_path", ")", "\n", "assert", "(", "cap", ".", "isOpened", "(", ")", ")", "\n", "vlen", "=", "int", "(", "cap", ".", "get", "(", "cv2", ".", "CAP_PROP_FRAME_COUNT", ")", ")", "\n", "# get indexes of sampled frames", "\n", "frame_idxs", "=", "sample_frames", "(", "num_frames", ",", "vlen", ",", "sample", "=", "sample", ",", "fix_start", "=", "fix_start", ")", "\n", "frames", "=", "[", "]", "\n", "success_idxs", "=", "[", "]", "\n", "for", "index", "in", "frame_idxs", ":", "\n", "        ", "cap", ".", "set", "(", "cv2", ".", "CAP_PROP_POS_FRAMES", ",", "index", "-", "1", ")", "\n", "ret", ",", "frame", "=", "cap", ".", "read", "(", ")", "\n", "if", "ret", ":", "\n", "            ", "frame", "=", "cv2", ".", "cvtColor", "(", "frame", ",", "cv2", ".", "COLOR_BGR2RGB", ")", "\n", "frame", "=", "torch", ".", "from_numpy", "(", "frame", ")", ".", "byte", "(", ")", "\n", "# # (H x W x C) to (C x H x W)", "\n", "frame", "=", "frame", ".", "permute", "(", "2", ",", "0", ",", "1", ")", "\n", "frames", ".", "append", "(", "frame", ")", "\n", "success_idxs", ".", "append", "(", "index", ")", "\n", "", "else", ":", "\n", "            ", "pass", "\n", "# print(frame_idxs, ' fail ', index, f'  (vlen {vlen})')", "\n", "# return frames tensor", "\n", "", "", "frames", "=", "torch", ".", "stack", "(", "frames", ")", "# .float() / 255", "\n", "# print(frames.size())", "\n", "cap", ".", "release", "(", ")", "\n", "return", "frames", ",", "success_idxs", ",", "vlen", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.image.base_dataset.read_frames_decord": [[448, 456], ["decord.VideoReader", "len", "base_dataset.sample_frames", "decord.VideoReader.get_batch", "frames.permute.permute", "frames.permute.float"], "function", ["home.repos.pwc.inspect_result.showlab_all-in-one.datasets.base_dataset.sample_frames"], ["", "def", "read_frames_decord", "(", "video_path", ",", "num_frames", ",", "sample", "=", "'rand'", ",", "fix_start", "=", "None", ")", ":", "\n", "    ", "video_reader", "=", "decord", ".", "VideoReader", "(", "video_path", ",", "num_threads", "=", "1", ")", "\n", "vlen", "=", "len", "(", "video_reader", ")", "\n", "frame_idxs", "=", "sample_frames", "(", "num_frames", ",", "vlen", ",", "sample", "=", "sample", ",", "fix_start", "=", "fix_start", ")", "\n", "frames", "=", "video_reader", ".", "get_batch", "(", "frame_idxs", ")", "\n", "frames", "=", "frames", ".", "float", "(", ")", "/", "255", "\n", "frames", "=", "frames", ".", "permute", "(", "0", ",", "3", ",", "1", ",", "2", ")", "\n", "return", "frames", ",", "frame_idxs", ",", "vlen", "", "", ""]], "home.repos.pwc.inspect_result.showlab_all-in-one.image.cc3m.CC3MDataset.__init__": [[11, 25], ["cc3m.CC3MDataset._load_metadata", "print", "base_dataset.BaseDataset.__init__", "len"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_v2.Ego4DDataset._load_metadata", "home.repos.pwc.inspect_result.showlab_all-in-one.transforms.utils.UnNormalize.__init__"], ["    ", "def", "__init__", "(", "self", ",", "*", "args", ",", "split", "=", "\"\"", ",", "**", "kwargs", ")", ":", "\n", "        ", "assert", "split", "in", "[", "\"train\"", ",", "\"val\"", ",", "\"test\"", "]", "\n", "self", ".", "split", "=", "split", "\n", "self", ".", "metadata", "=", "None", "\n", "self", ".", "_load_metadata", "(", ")", "\n", "if", "split", "==", "\"train\"", ":", "\n", "            ", "names", "=", "[", "\"cc3m_train\"", "]", "\n", "", "elif", "split", "==", "\"val\"", ":", "\n", "            ", "names", "=", "[", "\"cc3m_val\"", "]", "\n", "", "elif", "split", "==", "\"test\"", ":", "\n", "            ", "names", "=", "[", "\"cc3m_val\"", "]", "\n", "\n", "", "print", "(", "names", ",", "\": \"", ",", "len", "(", "self", ".", "metadata", ")", ",", "\"samples in total.\"", ")", "\n", "super", "(", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ",", "names", "=", "names", ",", "text_column_name", "=", "\"caption\"", ")", "\n", "# self.data_dir = os.path.join(self.data_dir, 'cc3m')", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.image.cc3m.CC3MDataset._load_metadata": [[27, 41], ["pandas.read_csv", "os.path.join"], "methods", ["None"], ["", "def", "_load_metadata", "(", "self", ")", ":", "\n", "# download specific", "\n", "        ", "metadata_dir", "=", "'./meta_data/cc3m'", "\n", "split_files", "=", "{", "\n", "'train'", ":", "'cc3m_training_success_full.tsv'", ",", "\n", "'val'", ":", "'cc3m_validation_success_full.tsv'", ",", "# there is no test", "\n", "'test'", ":", "'cc3m_validation_success_full.tsv'", "\n", "}", "\n", "target_split_fp", "=", "split_files", "[", "self", ".", "split", "]", "\n", "metadata", "=", "pd", ".", "read_csv", "(", "os", ".", "path", ".", "join", "(", "metadata_dir", ",", "target_split_fp", ")", ",", "sep", "=", "'\\t'", ")", "\n", "# elif self.split == 'val':", "\n", "#     metadata = metadata.sample(1000, random_state=0)  # 15k val is unnecessarily large, downsample.", "\n", "\n", "self", ".", "metadata", "=", "metadata", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.image.cc3m.CC3MDataset._get_image_path": [[42, 51], ["os.path.join", "os.path.join"], "methods", ["None"], ["", "def", "_get_image_path", "(", "self", ",", "sample", ")", ":", "\n", "# conceptual captions uses this hashing to create the filename", "\n", "        ", "rel_dir", "=", "'training'", "\n", "if", "self", ".", "split", "!=", "'train'", ":", "\n", "            ", "rel_dir", "=", "'validation'", "\n", "", "rel_fp", "=", "os", ".", "path", ".", "join", "(", "rel_dir", ",", "sample", "[", "1", "]", ")", "\n", "#rel_fp = os.path.join(rel_dir, str(zlib.crc32(sample['thumbnailUrl'].encode('utf-8')) & 0xffffffff))", "\n", "# print(rel_fp)", "\n", "return", "os", ".", "path", ".", "join", "(", "self", ".", "data_dir", ",", "rel_fp", ")", ",", "rel_fp", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.image.cc3m.CC3MDataset._get_caption": [[52, 54], ["None"], "methods", ["None"], ["", "def", "_get_caption", "(", "self", ",", "sample", ")", ":", "\n", "        ", "return", "sample", "[", "0", "]", "\n", "#return sample['caption']", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.image.cc3m.CC3MDataset.get_raw_image": [[56, 64], ["cc3m.CC3MDataset._get_image_path", "PIL.Image.open().convert", "Exception", "PIL.Image.open"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.datasets.vcr.VCRDataset._get_image_path"], ["", "def", "get_raw_image", "(", "self", ",", "sample", ")", ":", "\n", "# print(sample)", "\n", "        ", "abs_fp", ",", "rel_fp", "=", "self", ".", "_get_image_path", "(", "sample", ")", "\n", "img", "=", "Image", ".", "open", "(", "abs_fp", ")", ".", "convert", "(", "\"RGB\"", ")", "\n", "if", "img", "is", "None", ":", "\n", "            ", "raise", "Exception", "(", "\"Invalid img!\"", ",", "rel_fp", ")", "\n", "", "else", ":", "\n", "            ", "return", "img", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.image.cc3m.CC3MDataset.get_image": [[65, 77], ["cc3m.CC3MDataset.get_raw_image", "cc3m.CC3MDataset.image_aug"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.datasets.vcr.VCRDataset.get_raw_image", "home.repos.pwc.inspect_result.showlab_all-in-one.image.imageaug.image_aug"], ["", "", "def", "get_image", "(", "self", ",", "index", ",", "sample", ",", "image_key", "=", "\"image\"", ")", ":", "\n", "        ", "image", "=", "self", ".", "get_raw_image", "(", "sample", ")", "\n", "# image_tensor = [tr(image).unsqueeze(0) for tr in global_transforms]", "\n", "image_tensor", "=", "self", ".", "image_aug", "(", "image", ",", "self", ".", "transforms", ")", "\n", "# image_tensor[0] = image_tensor[0].unsqueeze(0)", "\n", "# print(len(image_tensor))", "\n", "# print(image_tensor[0].size())", "\n", "return", "{", "\n", "\"video\"", ":", "image_tensor", ",", "\n", "\"vid_index\"", ":", "sample", "[", "1", "]", ",", "\n", "\"cap_index\"", ":", "index", ",", "\n", "\"raw_index\"", ":", "index", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.image.cc3m.CC3MDataset.get_false_image": [[79, 86], ["random.randint", "cc3m.CC3MDataset.get_raw_image", "cc3m.CC3MDataset.image_aug", "len"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.datasets.vcr.VCRDataset.get_raw_image", "home.repos.pwc.inspect_result.showlab_all-in-one.image.imageaug.image_aug"], ["", "def", "get_false_image", "(", "self", ",", "rep", ",", "image_key", "=", "\"image\"", ")", ":", "\n", "        ", "random_index", "=", "random", ".", "randint", "(", "0", ",", "len", "(", "self", ".", "metadata", ")", "-", "1", ")", "\n", "sample", "=", "self", ".", "metadata", ".", "iloc", "[", "random_index", "]", "\n", "image", "=", "self", ".", "get_raw_image", "(", "sample", ")", "\n", "# image_tensor = [tr(image).unsqueeze(0) for tr in global_transforms]", "\n", "image_tensor", "=", "self", ".", "image_aug", "(", "image", ",", "self", ".", "transforms", ")", "\n", "return", "{", "f\"false_video_{rep}\"", ":", "image_tensor", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.image.cc3m.CC3MDataset.get_text": [[87, 102], ["cc3m.CC3MDataset.tokenizer"], "methods", ["None"], ["", "def", "get_text", "(", "self", ",", "raw_index", ",", "sample", ")", ":", "\n", "        ", "text", "=", "sample", "[", "0", "]", "\n", "encoding", "=", "self", ".", "tokenizer", "(", "\n", "text", ",", "\n", "padding", "=", "\"max_length\"", ",", "\n", "truncation", "=", "True", ",", "\n", "max_length", "=", "self", ".", "max_text_len", ",", "\n", "return_special_tokens_mask", "=", "True", ",", "\n", ")", "\n", "# print(encoding.size())", "\n", "return", "{", "\n", "\"text\"", ":", "(", "text", ",", "encoding", ")", ",", "\n", "\"vid_index\"", ":", "sample", "[", "1", "]", ",", "\n", "\"cap_index\"", ":", "raw_index", ",", "\n", "\"raw_index\"", ":", "raw_index", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.image.cc3m.CC3MDataset.get_false_text": [[104, 115], ["random.randint", "cc3m.CC3MDataset.tokenizer", "len"], "methods", ["None"], ["", "def", "get_false_text", "(", "self", ",", "rep", ")", ":", "\n", "        ", "random_index", "=", "random", ".", "randint", "(", "0", ",", "len", "(", "self", ".", "metadata", ")", "-", "1", ")", "\n", "sample", "=", "self", ".", "metadata", ".", "iloc", "[", "random_index", "]", "\n", "text", "=", "sample", "[", "0", "]", "\n", "encoding", "=", "self", ".", "tokenizer", "(", "\n", "text", ",", "\n", "truncation", "=", "True", ",", "\n", "max_length", "=", "self", ".", "max_text_len", ",", "\n", "return_special_tokens_mask", "=", "True", ",", "\n", ")", "\n", "return", "{", "f\"false_text_{rep}\"", ":", "(", "text", ",", "encoding", ")", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.image.cc3m.CC3MDataset.get_suite": [[116, 140], ["dict", "dict.update", "range", "range", "cc3m.CC3MDataset.get_image", "cc3m.CC3MDataset.get_text", "dict.update", "dict.update", "dict.update", "dict.update", "cc3m.CC3MDataset.get_false_image", "cc3m.CC3MDataset.get_false_text"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.gadgets.my_metrics.VQAScore.update", "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.vcr.VCRDataset.get_image", "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_v2.Ego4DDataset.get_text", "home.repos.pwc.inspect_result.showlab_all-in-one.gadgets.my_metrics.VQAScore.update", "home.repos.pwc.inspect_result.showlab_all-in-one.gadgets.my_metrics.VQAScore.update", "home.repos.pwc.inspect_result.showlab_all-in-one.gadgets.my_metrics.VQAScore.update", "home.repos.pwc.inspect_result.showlab_all-in-one.gadgets.my_metrics.VQAScore.update", "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.vcr.VCRDataset.get_false_image", "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_v2.Ego4DDataset.get_false_text"], ["", "def", "get_suite", "(", "self", ",", "index", ")", ":", "\n", "        ", "result", "=", "None", "\n", "# print(self.draw_false_image) # 1", "\n", "while", "result", "is", "None", ":", "\n", "            ", "sample", "=", "self", ".", "metadata", ".", "iloc", "[", "index", "]", "\n", "# print(sample)", "\n", "# try:", "\n", "ret", "=", "dict", "(", ")", "\n", "ret", ".", "update", "(", "self", ".", "get_image", "(", "index", ",", "sample", ")", ")", "\n", "if", "not", "self", ".", "image_only", ":", "\n", "                ", "txt", "=", "self", ".", "get_text", "(", "index", ",", "sample", ")", "\n", "ret", ".", "update", "(", "{", "\"replica\"", ":", "True", "if", "txt", "[", "\"cap_index\"", "]", ">", "0", "else", "False", "}", ")", "\n", "ret", ".", "update", "(", "txt", ")", "\n", "\n", "", "for", "i", "in", "range", "(", "self", ".", "draw_false_image", ")", ":", "\n", "                ", "ret", ".", "update", "(", "self", ".", "get_false_image", "(", "i", ")", ")", "\n", "", "for", "i", "in", "range", "(", "self", ".", "draw_false_text", ")", ":", "\n", "                ", "ret", ".", "update", "(", "self", ".", "get_false_text", "(", "i", ")", ")", "\n", "", "result", "=", "True", "\n", "# except Exception as e:", "\n", "#     print(f\"Error while read file idx {sample[1]} in {self.names[0]} -> {e}\")", "\n", "#     index = random.randint(0, len(self.metadata) - 1)", "\n", "# ret[\"image\"] = ret[\"image\"].unsqueeze(1)", "\n", "", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.image.cc3m.CC3MDataset.__len__": [[141, 143], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "metadata", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.image.cc3m.CC3MDataset.__getitem__": [[144, 146], ["cc3m.CC3MDataset.get_suite"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_v2.Ego4DDataset.get_suite"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "return", "self", ".", "get_suite", "(", "index", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.image.nlvr2_dataset.NLVR2Dataset.__init__": [[7, 24], ["base_dataset.BaseDataset.__init__"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.transforms.utils.UnNormalize.__init__"], ["    ", "def", "__init__", "(", "self", ",", "*", "args", ",", "split", "=", "\"\"", ",", "**", "kwargs", ")", ":", "\n", "        ", "assert", "split", "in", "[", "\"train\"", ",", "\"val\"", ",", "\"test\"", "]", "\n", "self", ".", "split", "=", "split", "\n", "\n", "if", "split", "==", "\"train\"", ":", "\n", "            ", "names", "=", "[", "\"nlvr2_train\"", "]", "\n", "", "elif", "split", "==", "\"val\"", ":", "\n", "            ", "names", "=", "[", "\"nlvr2_dev\"", ",", "\"nlvr2_test1\"", "]", "\n", "", "elif", "split", "==", "\"test\"", ":", "\n", "            ", "names", "=", "[", "\"nlvr2_dev\"", ",", "\"nlvr2_test1\"", "]", "\n", "\n", "", "super", "(", ")", ".", "__init__", "(", "\n", "*", "args", ",", "\n", "**", "kwargs", ",", "\n", "names", "=", "names", ",", "\n", "text_column_name", "=", "\"questions\"", ",", "\n", "remove_duplicate", "=", "False", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.image.nlvr2_dataset.NLVR2Dataset.__getitem__": [[26, 51], ["[].as_py", "nlvr2_dataset.NLVR2Dataset.get_image", "nlvr2_dataset.NLVR2Dataset.get_image", "nlvr2_dataset.NLVR2Dataset.get_text", "print", "random.randint", "len"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.datasets.vcr.VCRDataset.get_image", "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.vcr.VCRDataset.get_image", "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_v2.Ego4DDataset.get_text"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "result", "=", "None", "\n", "while", "result", "is", "None", ":", "\n", "            ", "try", ":", "\n", "                ", "image_tensor_0", "=", "self", ".", "get_image", "(", "index", ",", "image_key", "=", "\"image_0\"", ")", "[", "\"image\"", "]", "\n", "image_tensor_1", "=", "self", ".", "get_image", "(", "index", ",", "image_key", "=", "\"image_1\"", ")", "[", "\"image\"", "]", "\n", "text", "=", "self", ".", "get_text", "(", "index", ")", "[", "\"text\"", "]", "\n", "result", "=", "True", "\n", "", "except", ":", "\n", "                ", "print", "(", "\n", "f\"error while read file idx {index} in {self.names[0]}\"", ",", "\n", "file", "=", "sys", ".", "stderr", ",", "\n", ")", "\n", "index", "=", "random", ".", "randint", "(", "0", ",", "len", "(", "self", ".", "index_mapper", ")", "-", "1", ")", "\n", "\n", "", "", "index", ",", "question_index", "=", "self", ".", "index_mapper", "[", "index", "]", "\n", "answers", "=", "self", ".", "table", "[", "\"answers\"", "]", "[", "index", "]", "[", "question_index", "]", ".", "as_py", "(", ")", "\n", "answers", "=", "answers", "==", "\"True\"", "\n", "\n", "return", "{", "\n", "\"image_0\"", ":", "image_tensor_0", ",", "\n", "\"image_1\"", ":", "image_tensor_1", ",", "\n", "\"text\"", ":", "text", ",", "\n", "\"answers\"", ":", "answers", ",", "\n", "\"table_name\"", ":", "self", ".", "table_names", "[", "index", "]", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.image.f30k_caption_karpathy_dataset.F30KCaptionKarpathyDataset.__init__": [[5, 16], ["base_dataset.BaseDataset.__init__"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.transforms.utils.UnNormalize.__init__"], ["    ", "def", "__init__", "(", "self", ",", "*", "args", ",", "split", "=", "\"\"", ",", "**", "kwargs", ")", ":", "\n", "        ", "assert", "split", "in", "[", "\"train\"", ",", "\"val\"", ",", "\"test\"", "]", "\n", "\n", "if", "split", "==", "\"train\"", ":", "\n", "            ", "names", "=", "[", "\"f30k_caption_karpathy_train\"", ",", "\"f30k_caption_karpathy_val\"", "]", "\n", "", "elif", "split", "==", "\"val\"", ":", "\n", "            ", "names", "=", "[", "\"f30k_caption_karpathy_test\"", "]", "\n", "", "elif", "split", "==", "\"test\"", ":", "\n", "            ", "names", "=", "[", "\"f30k_caption_karpathy_test\"", "]", "\n", "\n", "", "super", "(", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ",", "names", "=", "names", ",", "text_column_name", "=", "\"caption\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.image.f30k_caption_karpathy_dataset.F30KCaptionKarpathyDataset.__getitem__": [[17, 19], ["f30k_caption_karpathy_dataset.F30KCaptionKarpathyDataset.get_suite"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_v2.Ego4DDataset.get_suite"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "return", "self", ".", "get_suite", "(", "index", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.showlab_all-in-one.image.vcr.VCRDataset.__init__": [[50, 69], ["vcr.VCRDataset._load_metadata", "CoTrain.datasets.video.video_base_dataset.BaseDataset.__init__", "CoTrain.transforms.video.videoaug.VideoTransform"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_v2.Ego4DDataset._load_metadata", "home.repos.pwc.inspect_result.showlab_all-in-one.transforms.utils.UnNormalize.__init__", "home.repos.pwc.inspect_result.showlab_all-in-one.transforms.videoaug.VideoTransform"], ["    ", "def", "__init__", "(", "self", ",", "*", "args", ",", "split", "=", "\"\"", ",", "**", "kwargs", ")", ":", "\n", "        ", "assert", "split", "in", "[", "\"train\"", ",", "\"val\"", ",", "\"test\"", "]", "\n", "self", ".", "split", "=", "split", "\n", "self", ".", "metadata", "=", "None", "\n", "self", ".", "_load_metadata", "(", ")", "\n", "if", "split", "==", "\"train\"", ":", "\n", "            ", "names", "=", "[", "\"vcr_train\"", "]", "\n", "", "elif", "split", "==", "\"val\"", ":", "\n", "            ", "names", "=", "[", "\"vcr_val\"", "]", "\n", "", "elif", "split", "==", "\"test\"", ":", "\n", "            ", "names", "=", "[", "\"vcr_test\"", "]", "\n", "\n", "", "super", "(", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ",", "names", "=", "names", ",", "text_column_name", "=", "\"caption\"", ")", "\n", "self", ".", "video_transform", "=", "VideoTransform", "(", "mode", "=", "split", ",", "num_frames", "=", "self", ".", "num_frames", ")", "# train or val model", "\n", "# for appear objects", "\n", "self", ".", "only_use_relevant_dets", "=", "True", "\n", "if", "self", ".", "only_use_relevant_dets", ":", "\n", "            ", "self", ".", "relevant_dets", "=", "[", "]", "# resort the detection numbers", "\n", "self", ".", "relevant_dets_classes", "=", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.image.vcr.VCRDataset._load_metadata": [[70, 81], ["pandas.read_json", "os.path.join"], "methods", ["None"], ["", "", "def", "_load_metadata", "(", "self", ")", ":", "\n", "# download specific", "\n", "        ", "metadata_dir", "=", "'./meta_data/vcr1annots'", "\n", "split_files", "=", "{", "\n", "'train'", ":", "'train.jsonl'", ",", "\n", "'val'", ":", "'val.jsonl'", ",", "# there is no test", "\n", "'test'", ":", "'test.jsonl'", "\n", "}", "\n", "target_split_fp", "=", "split_files", "[", "self", ".", "split", "]", "\n", "metadata", "=", "pd", ".", "read_json", "(", "os", ".", "path", ".", "join", "(", "metadata_dir", ",", "target_split_fp", ")", ",", "lines", "=", "True", ")", "\n", "self", ".", "metadata", "=", "metadata", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.image.vcr.VCRDataset._get_image_path": [[82, 88], ["os.path.join"], "methods", ["None"], ["", "def", "_get_image_path", "(", "self", ",", "sample", ")", ":", "\n", "# print(sample.keys())", "\n", "# print(sample['img_fn'])", "\n", "# VCR/vcr1images", "\n", "        ", "rel_fp", "=", "sample", "[", "'img_fn'", "]", "\n", "return", "os", ".", "path", ".", "join", "(", "self", ".", "data_dir", ",", "'vcr1images'", ",", "rel_fp", ")", ",", "rel_fp", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.image.vcr.VCRDataset.get_objects": [[89, 94], ["pandas.read_json", "os.path.join"], "methods", ["None"], ["", "def", "get_objects", "(", "self", ",", "sample", ")", ":", "\n", "        ", "metadata2", "=", "pd", ".", "read_json", "(", "os", ".", "path", ".", "join", "(", "self", ".", "data_dir", ",", "'vcr1images'", ",", "\n", "sample", "[", "'metadata_fn'", "]", ")", ",", "lines", "=", "True", ")", "\n", "object_meta", "=", "metadata2", ".", "iloc", "[", "0", "]", "\n", "return", "object_meta", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.image.vcr.VCRDataset._get_caption": [[95, 97], ["None"], "methods", ["None"], ["", "def", "_get_caption", "(", "self", ",", "sample", ")", ":", "\n", "        ", "return", "sample", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.image.vcr.VCRDataset.get_raw_image": [[104, 116], ["vcr.VCRDataset._get_image_path", "cv2.imread", "CoTrain.datasets.video.video_base_dataset.color_img", "Exception"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.datasets.vcr.VCRDataset._get_image_path", "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.video_base_dataset.color_img"], ["", "def", "get_raw_image", "(", "self", ",", "sample", ",", "object_meta", ",", "img_color_mask", "=", "True", ")", ":", "\n", "# print(sample)", "\n", "        ", "abs_fp", ",", "rel_fp", "=", "self", ".", "_get_image_path", "(", "sample", ")", "\n", "# img = Image.open(abs_fp)", "\n", "img", "=", "cv2", ".", "imread", "(", "abs_fp", ")", "\n", "# add bbox annotation here", "\n", "if", "img_color_mask", ":", "\n", "            ", "img", "=", "color_img", "(", "img", ",", "object_meta", ",", "self", ".", "relevant_dets", ",", "self", ".", "only_use_relevant_dets", ")", "\n", "", "if", "img", "is", "None", ":", "\n", "            ", "raise", "Exception", "(", "\"Invalid img!\"", ",", "rel_fp", ")", "\n", "", "else", ":", "\n", "            ", "return", "img", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.image.vcr.VCRDataset.get_image": [[117, 131], ["vcr.VCRDataset.get_raw_image", "torch.from_numpy().byte", "frame.permute.permute.permute", "torch.stack().permute.append", "torch.stack().permute", "vcr.VCRDataset.video_transform().permute", "torch.from_numpy", "torch.stack", "vcr.VCRDataset.video_transform"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.datasets.vcr.VCRDataset.get_raw_image"], ["", "", "def", "get_image", "(", "self", ",", "index", ",", "sample", ",", "object_meta", ",", "image_key", "=", "\"image\"", ")", ":", "\n", "        ", "frames", "=", "[", "]", "\n", "image", "=", "self", ".", "get_raw_image", "(", "sample", ",", "object_meta", ")", "\n", "frame", "=", "torch", ".", "from_numpy", "(", "image", ")", ".", "byte", "(", ")", "\n", "frame", "=", "frame", ".", "permute", "(", "2", ",", "0", ",", "1", ")", "\n", "frames", ".", "append", "(", "frame", ")", "\n", "frames", "=", "torch", ".", "stack", "(", "frames", ")", ".", "permute", "(", "1", ",", "0", ",", "2", ",", "3", ")", "\n", "# print(frames.size())", "\n", "image_tensor", "=", "[", "self", ".", "video_transform", "(", "frames", ")", ".", "permute", "(", "1", ",", "0", ",", "2", ",", "3", ")", "]", "# to tchw", "\n", "# image = self.get_raw_image(sample)", "\n", "# image_tensor = [tr(image) for tr in self.transforms]", "\n", "# print(image_tensor.size())", "\n", "# image_tensor.unsqueeze(0)", "\n", "return", "image_tensor", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.image.vcr.VCRDataset.get_false_image": [[132, 138], ["random.randint", "vcr.VCRDataset.get_raw_image", "tr", "len"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.datasets.vcr.VCRDataset.get_raw_image"], ["", "def", "get_false_image", "(", "self", ",", "rep", ",", "image_key", "=", "\"image\"", ")", ":", "\n", "        ", "random_index", "=", "random", ".", "randint", "(", "0", ",", "len", "(", "self", ".", "metadata", ")", "-", "1", ")", "\n", "sample", "=", "self", ".", "metadata", ".", "iloc", "[", "random_index", "]", "\n", "image", "=", "self", ".", "get_raw_image", "(", "sample", ")", "\n", "image_tensor", "=", "[", "tr", "(", "image", ")", "for", "tr", "in", "self", ".", "transforms", "]", "\n", "return", "{", "f\"false_image_{rep}\"", ":", "image_tensor", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.image.vcr.VCRDataset.update_rele_det": [[167, 191], ["range", "range", "range", "len", "text.append", "len", "range", "len", "range", "isinstance", "vcr.VCRDataset.relevant_dets_classes.append", "len", "text.append", "len", "text.append", "vcr.VCRDataset.relevant_dets.append"], "methods", ["None"], ["", "def", "update_rele_det", "(", "self", ",", "sample", ",", "object_meta", ",", "index", ")", ":", "\n", "        ", "text", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "sample", "[", "'question'", "]", ")", ")", ":", "\n", "            ", "text", ".", "append", "(", "sample", "[", "'question'", "]", "[", "i", "]", ")", "\n", "", "for", "i", "in", "range", "(", "len", "(", "sample", "[", "'answer_choices'", "]", ")", ")", ":", "\n", "            ", "for", "j", "in", "range", "(", "len", "(", "sample", "[", "'answer_choices'", "]", "[", "i", "]", ")", ")", ":", "\n", "                ", "text", ".", "append", "(", "sample", "[", "'answer_choices'", "]", "[", "i", "]", "[", "j", "]", ")", "\n", "", "", "for", "i", "in", "range", "(", "len", "(", "sample", "[", "'rationale_choices'", "]", ")", ")", ":", "\n", "            ", "for", "j", "in", "range", "(", "len", "(", "sample", "[", "'rationale_choices'", "]", "[", "i", "]", ")", ")", ":", "\n", "                ", "text", ".", "append", "(", "sample", "[", "'rationale_choices'", "]", "[", "i", "]", "[", "j", "]", ")", "\n", "# update relevant detes", "\n", "", "", "for", "word", "in", "text", ":", "\n", "            ", "if", "isinstance", "(", "word", ",", "list", ")", ":", "\n", "                ", "for", "object_idx", "in", "word", ":", "\n", "# self.relevant_dets.add(object_idx)", "\n", "                    ", "if", "object_idx", "not", "in", "self", ".", "relevant_dets", ":", "\n", "                        ", "self", ".", "relevant_dets", ".", "append", "(", "object_idx", ")", "\n", "", "", "", "", "for", "object", "in", "self", ".", "relevant_dets", ":", "\n", "            ", "self", ".", "relevant_dets_classes", ".", "append", "(", "object_meta", "[", "'names'", "]", "[", "object", "]", ")", "\n", "# print(index, text)", "\n", "# print(index, self.relevant_dets)", "\n", "# print(index, self.relevant_dets_classes)", "\n", "#", "\n", "", "return", "text", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.image.vcr.VCRDataset.get_text": [[192, 263], ["vcr.VCRDataset.get_question", "vcr.VCRDataset.update_rele_det", "vcr.VCRDataset.tokenizer", "qa_texts.append", "isinstance", "vcr.VCRDataset.tokenizer", "qar_texts.append", "isinstance", "isinstance", "str", "str", "str", "str", "vcr.VCRDataset.relevant_dets.index", "str", "str", "vcr.VCRDataset.relevant_dets.index", "vcr.VCRDataset.relevant_dets.index"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.datasets.vcr.VCRDataset.get_question", "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.vcr.VCRDataset.update_rele_det"], ["", "def", "get_text", "(", "self", ",", "sample", ",", "object_meta", ",", "index", ")", ":", "\n", "# detect all object index and sort these items", "\n", "        ", "if", "self", ".", "only_use_relevant_dets", ":", "\n", "            ", "self", ".", "update_rele_det", "(", "sample", ",", "object_meta", ",", "index", ")", "\n", "", "question", "=", "self", ".", "get_question", "(", "sample", ",", "object_meta", ")", "\n", "qa_texts", "=", "[", "]", "\n", "# image size: 384 x 384", "\n", "# prompt: [START] + \"answer_question:\"", "\n", "# prompt: [START] + ' provide rationale:'),", "\n", "# add all text tokens into this model.", "\n", "for", "answer", "in", "sample", "[", "'answer_choices'", "]", ":", "\n", "            ", "raw_text", "=", "question", "+", "'answer question: '", "\n", "for", "word", "in", "answer", ":", "\n", "                ", "if", "isinstance", "(", "word", ",", "list", ")", ":", "\n", "                    ", "for", "object_idx", "in", "word", ":", "\n", "                        ", "raw_text", "+=", "' '", "+", "object_meta", "[", "'names'", "]", "[", "object_idx", "]", "+", "' '", "\n", "# rename the object index, for example", "\n", "if", "self", ".", "only_use_relevant_dets", ":", "\n", "                            ", "raw_text", "+=", "str", "(", "self", ".", "relevant_dets", ".", "index", "(", "object_idx", ")", ")", "\n", "", "else", ":", "\n", "                            ", "raw_text", "+=", "str", "(", "object_idx", ")", "\n", "", "", "", "else", ":", "\n", "                    ", "raw_text", "+=", "' '", "+", "word", "\n", "", "", "raw_text", "+=", "'[END]'", "\n", "# print(index, raw_text)", "\n", "qa_encoding", "=", "self", ".", "tokenizer", "(", "\n", "raw_text", ",", "\n", "padding", "=", "\"max_length\"", ",", "\n", "truncation", "=", "True", ",", "\n", "max_length", "=", "self", ".", "max_text_len", ",", "\n", "return_special_tokens_mask", "=", "True", ",", "\n", ")", "\n", "qa_texts", ".", "append", "(", "(", "raw_text", ",", "qa_encoding", ")", ")", "\n", "\n", "", "gt_ans", "=", "sample", "[", "'answer_choices'", "]", "[", "sample", "[", "'answer_label'", "]", "]", "\n", "gt_ans_text", "=", "\"\"", "\n", "for", "word", "in", "gt_ans", ":", "\n", "            ", "if", "isinstance", "(", "word", ",", "list", ")", ":", "\n", "                ", "for", "object_idx", "in", "word", ":", "\n", "                    ", "gt_ans_text", "+=", "' '", "+", "object_meta", "[", "'names'", "]", "[", "object_idx", "]", "+", "' '", "\n", "# rename the object index, for example", "\n", "if", "self", ".", "only_use_relevant_dets", ":", "\n", "                        ", "gt_ans_text", "+=", "str", "(", "self", ".", "relevant_dets", ".", "index", "(", "object_idx", ")", ")", "\n", "", "else", ":", "\n", "                        ", "gt_ans_text", "+=", "str", "(", "object_idx", ")", "\n", "", "", "", "else", ":", "\n", "                ", "gt_ans_text", "+=", "' '", "+", "word", "\n", "", "", "qar_texts", "=", "[", "]", "\n", "for", "reason", "in", "sample", "[", "'rationale_choices'", "]", ":", "\n", "            ", "raw_text", "=", "question", "+", "gt_ans_text", "+", "'provide rationale: '", "\n", "for", "word", "in", "reason", ":", "\n", "                ", "if", "isinstance", "(", "word", ",", "list", ")", ":", "\n", "                    ", "for", "object_idx", "in", "word", ":", "\n", "                        ", "raw_text", "+=", "' '", "+", "object_meta", "[", "'names'", "]", "[", "object_idx", "]", "+", "' '", "\n", "if", "self", ".", "only_use_relevant_dets", ":", "\n", "                            ", "raw_text", "+=", "str", "(", "self", ".", "relevant_dets", ".", "index", "(", "object_idx", ")", ")", "\n", "", "else", ":", "\n", "                            ", "raw_text", "+=", "str", "(", "object_idx", ")", "\n", "", "", "", "else", ":", "\n", "                    ", "raw_text", "+=", "' '", "+", "word", "\n", "# print(index, raw_text)", "\n", "", "", "raw_text", "+=", "'[END]'", "\n", "encoding", "=", "self", ".", "tokenizer", "(", "\n", "raw_text", ",", "\n", "padding", "=", "\"max_length\"", ",", "\n", "truncation", "=", "True", ",", "\n", "max_length", "=", "self", ".", "max_text_len", ",", "\n", "return_special_tokens_mask", "=", "True", ",", "\n", ")", "\n", "qar_texts", ".", "append", "(", "(", "raw_text", ",", "encoding", ")", ")", "\n", "", "return", "[", "qa_texts", ",", "qar_texts", "]", "\n", "#", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.image.vcr.VCRDataset.get_answer_label": [[309, 312], ["int"], "methods", ["None"], ["", "def", "get_answer_label", "(", "self", ",", "sample", ")", ":", "\n", "        ", "answer", "=", "int", "(", "sample", "[", "'answer_label'", "]", ")", "\n", "return", "answer", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.image.vcr.VCRDataset.get_reason_answer_label": [[313, 316], ["int"], "methods", ["None"], ["", "def", "get_reason_answer_label", "(", "self", ",", "sample", ")", ":", "\n", "        ", "answer", "=", "int", "(", "sample", "[", "'rationale_label'", "]", ")", "\n", "return", "answer", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.image.vcr.VCRDataset.get_question": [[317, 330], ["range", "len", "isinstance", "str", "str", "str", "vcr.VCRDataset.relevant_dets.index"], "methods", ["None"], ["", "def", "get_question", "(", "self", ",", "sample", ",", "object_meta", ")", ":", "\n", "        ", "raw_text", "=", "\"\"", "\n", "for", "index", "in", "range", "(", "len", "(", "sample", "[", "'question'", "]", ")", ")", ":", "\n", "            ", "if", "isinstance", "(", "sample", "[", "'question'", "]", "[", "index", "]", ",", "list", ")", ":", "\n", "                ", "for", "object_idx", "in", "sample", "[", "'question'", "]", "[", "index", "]", ":", "\n", "                    ", "raw_text", "+=", "' '", "+", "object_meta", "[", "'names'", "]", "[", "object_idx", "]", "+", "' '", "\n", "if", "self", ".", "only_use_relevant_dets", ":", "\n", "                        ", "raw_text", "+=", "str", "(", "self", ".", "relevant_dets", ".", "index", "(", "object_idx", ")", ")", "\n", "", "else", ":", "\n", "                        ", "raw_text", "+=", "str", "(", "object_idx", ")", "\n", "", "", "", "else", ":", "\n", "                ", "raw_text", "+=", "' '", "+", "str", "(", "sample", "[", "'question'", "]", "[", "index", "]", ")", "\n", "", "", "return", "raw_text", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.image.vcr.VCRDataset.__len__": [[331, 333], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "metadata", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.image.vcr.VCRDataset.__getitem__": [[334, 362], ["vcr.VCRDataset.get_objects", "vcr.VCRDataset.get_answer_label", "vcr.VCRDataset.get_reason_answer_label", "vcr.VCRDataset.get_text", "range", "range", "vcr.VCRDataset.get_image", "ret.update", "ret.update"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.datasets.vcr.VCRDataset.get_objects", "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.msvdqa.MSVDQADataset.get_answer_label", "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.vcr.VCRDataset.get_reason_answer_label", "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_v2.Ego4DDataset.get_text", "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.vcr.VCRDataset.get_image", "home.repos.pwc.inspect_result.showlab_all-in-one.gadgets.my_metrics.VQAScore.update", "home.repos.pwc.inspect_result.showlab_all-in-one.gadgets.my_metrics.VQAScore.update"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "sample", "=", "self", ".", "metadata", ".", "iloc", "[", "index", "]", "\n", "object_meta", "=", "self", ".", "get_objects", "(", "sample", ")", "\n", "self", ".", "relevant_dets", "=", "[", "]", "# initalize", "\n", "self", ".", "relevant_dets_classes", "=", "[", "]", "\n", "answer", "=", "self", ".", "get_answer_label", "(", "sample", ")", "\n", "reason_answer", "=", "self", ".", "get_reason_answer_label", "(", "sample", ")", "\n", "ret", "=", "{", "\n", "\"img_index\"", ":", "index", ",", "\n", "\"cap_index\"", ":", "index", ",", "\n", "\"raw_index\"", ":", "index", ",", "\n", "'answer'", ":", "answer", ",", "\n", "'reason_answer'", ":", "reason_answer", "\n", "}", "\n", "# texts = self.get_text(sample, object_meta)", "\n", "# qar_texts = self.get_qar(sample, object_meta)", "\n", "[", "qa_texts", ",", "qar_texts", "]", "=", "self", ".", "get_text", "(", "sample", ",", "object_meta", ",", "index", ")", "\n", "ret", "[", "\"text\"", "]", "=", "qa_texts", "[", "0", "]", "\n", "# print(texts[0])", "\n", "# update other answers as false text", "\n", "for", "i", "in", "range", "(", "self", ".", "draw_options_text", "-", "1", ")", ":", "\n", "            ", "ret", ".", "update", "(", "{", "f\"options_text_{i}\"", ":", "qa_texts", "[", "i", "+", "1", "]", "}", ")", "\n", "", "for", "j", "in", "range", "(", "self", ".", "draw_options_text", ")", ":", "\n", "            ", "ret", ".", "update", "(", "{", "f\"qar_text_{j}\"", ":", "qar_texts", "[", "j", "]", "}", ")", "\n", "# print(ret.keys())", "\n", "", "image_tensor", "=", "self", ".", "get_image", "(", "index", ",", "sample", ",", "object_meta", ")", "\n", "ret", "[", "\"image\"", "]", "=", "image_tensor", "\n", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.image.conceptual_caption_dataset.ConceptualCaptionDataset.__init__": [[6, 17], ["base_dataset.BaseDataset.__init__", "range"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.transforms.utils.UnNormalize.__init__"], ["    ", "def", "__init__", "(", "self", ",", "*", "args", ",", "split", "=", "\"\"", ",", "**", "kwargs", ")", ":", "\n", "        ", "assert", "split", "in", "[", "\"train\"", ",", "\"val\"", ",", "\"test\"", "]", "\n", "if", "split", "==", "\"test\"", ":", "\n", "            ", "split", "=", "\"val\"", "\n", "\n", "", "if", "split", "==", "\"train\"", ":", "\n", "            ", "names", "=", "[", "f\"conceptual_caption_train_{i}\"", "for", "i", "in", "range", "(", "30", ")", "]", "\n", "", "elif", "split", "==", "\"val\"", ":", "\n", "            ", "names", "=", "[", "\"conceptual_caption_val_0\"", "]", "\n", "\n", "", "super", "(", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ",", "names", "=", "names", ",", "text_column_name", "=", "\"caption\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.image.conceptual_caption_dataset.ConceptualCaptionDataset.__getitem__": [[18, 20], ["conceptual_caption_dataset.ConceptualCaptionDataset.get_suite"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_v2.Ego4DDataset.get_suite"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "return", "self", ".", "get_suite", "(", "index", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.showlab_all-in-one.image.vg_caption_dataset.VisualGenomeCaptionDataset.__init__": [[5, 17], ["base_dataset.BaseDataset.__init__"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.transforms.utils.UnNormalize.__init__"], ["    ", "def", "__init__", "(", "self", ",", "*", "args", ",", "split", "=", "\"\"", ",", "**", "kwargs", ")", ":", "\n", "        ", "assert", "split", "in", "[", "\"train\"", ",", "\"val\"", ",", "\"test\"", "]", "\n", "if", "split", "==", "\"test\"", ":", "\n", "            ", "split", "=", "\"val\"", "\n", "\n", "", "if", "split", "==", "\"train\"", ":", "\n", "            ", "names", "=", "[", "\"vg_train\"", "]", "\n", "", "elif", "split", "==", "\"val\"", ":", "\n", "            ", "names", "=", "[", "]", "\n", "", "elif", "split", "==", "\"test\"", ":", "\n", "            ", "names", "=", "[", "]", "\n", "", "super", "(", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ",", "names", "=", "names", ",", "text_column_name", "=", "\"caption\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.image.vg_caption_dataset.VisualGenomeCaptionDataset.__getitem__": [[18, 20], ["vg_caption_dataset.VisualGenomeCaptionDataset.get_suite"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_v2.Ego4DDataset.get_suite"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "return", "self", ".", "get_suite", "(", "index", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.showlab_all-in-one.image.pixelbert.pixelbert_transform": [[9, 16], ["int", "torchvision.transforms.Compose", "utils.MinMaxResize", "torchvision.transforms.ToTensor"], "function", ["None"], ["def", "pixelbert_transform", "(", "size", "=", "800", ")", ":", "\n", "    ", "longer", "=", "int", "(", "(", "1333", "/", "800", ")", "*", "size", ")", "\n", "return", "transforms", ".", "Compose", "(", "\n", "[", "\n", "MinMaxResize", "(", "shorter", "=", "size", ",", "longer", "=", "longer", ")", ",", "\n", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "inception_normalize", ",", "\n", "]", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.image.pixelbert.pixelbert_transform_randaug": [[20, 31], ["int", "torchvision.transforms.Compose", "transforms.Compose.transforms.insert", "randaug.RandAugment", "utils.MinMaxResize", "torchvision.transforms.ToTensor"], "function", ["None"], ["", "def", "pixelbert_transform_randaug", "(", "size", "=", "800", ")", ":", "\n", "    ", "longer", "=", "int", "(", "(", "1333", "/", "800", ")", "*", "size", ")", "\n", "trs", "=", "transforms", ".", "Compose", "(", "\n", "[", "\n", "MinMaxResize", "(", "shorter", "=", "size", ",", "longer", "=", "longer", ")", ",", "\n", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "inception_normalize", ",", "\n", "]", "\n", ")", "\n", "trs", ".", "transforms", ".", "insert", "(", "0", ",", "RandAugment", "(", "2", ",", "9", ")", ")", "\n", "return", "trs", "", "", ""]], "home.repos.pwc.inspect_result.showlab_all-in-one.image.functional._is_tensor_clip": [[8, 10], ["torch.is_tensor", "clip.ndimension"], "function", ["None"], ["def", "_is_tensor_clip", "(", "clip", ")", ":", "\n", "    ", "return", "torch", ".", "is_tensor", "(", "clip", ")", "and", "clip", ".", "ndimension", "(", ")", "==", "4", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.image.functional.crop_clip": [[12, 24], ["isinstance", "isinstance", "TypeError", "img.crop", "type"], "function", ["None"], ["", "def", "crop_clip", "(", "clip", ",", "min_h", ",", "min_w", ",", "h", ",", "w", ")", ":", "\n", "    ", "if", "isinstance", "(", "clip", "[", "0", "]", ",", "np", ".", "ndarray", ")", ":", "\n", "        ", "cropped", "=", "[", "img", "[", "min_h", ":", "min_h", "+", "h", ",", "min_w", ":", "min_w", "+", "w", ",", ":", "]", "for", "img", "in", "clip", "]", "\n", "\n", "", "elif", "isinstance", "(", "clip", "[", "0", "]", ",", "PIL", ".", "Image", ".", "Image", ")", ":", "\n", "        ", "cropped", "=", "[", "\n", "img", ".", "crop", "(", "(", "min_w", ",", "min_h", ",", "min_w", "+", "w", ",", "min_h", "+", "h", ")", ")", "for", "img", "in", "clip", "\n", "]", "\n", "", "else", ":", "\n", "        ", "raise", "TypeError", "(", "'Expected numpy.ndarray or PIL.Image'", "+", "\n", "'but got list of {0}'", ".", "format", "(", "type", "(", "clip", "[", "0", "]", ")", ")", ")", "\n", "", "return", "cropped", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.image.functional.resize_clip": [[26, 65], ["isinstance", "isinstance", "isinstance", "functional.get_resize_sizes", "cv2.resize", "isinstance", "TypeError", "functional.get_resize_sizes", "img.resize", "type"], "function", ["home.repos.pwc.inspect_result.showlab_all-in-one.transforms.functional.get_resize_sizes", "home.repos.pwc.inspect_result.showlab_all-in-one.transforms.functional.get_resize_sizes"], ["", "def", "resize_clip", "(", "clip", ",", "size", ",", "interpolation", "=", "'bilinear'", ")", ":", "\n", "    ", "if", "isinstance", "(", "clip", "[", "0", "]", ",", "np", ".", "ndarray", ")", ":", "\n", "        ", "if", "isinstance", "(", "size", ",", "numbers", ".", "Number", ")", ":", "\n", "            ", "im_h", ",", "im_w", ",", "im_c", "=", "clip", "[", "0", "]", ".", "shape", "\n", "# Min spatial dim already matches minimal size", "\n", "if", "(", "im_w", "<=", "im_h", "and", "im_w", "==", "size", ")", "or", "(", "im_h", "<=", "im_w", "\n", "and", "im_h", "==", "size", ")", ":", "\n", "                ", "return", "clip", "\n", "", "new_h", ",", "new_w", "=", "get_resize_sizes", "(", "im_h", ",", "im_w", ",", "size", ")", "\n", "size", "=", "(", "new_w", ",", "new_h", ")", "\n", "", "else", ":", "\n", "            ", "size", "=", "size", "[", "1", "]", ",", "size", "[", "0", "]", "\n", "", "if", "interpolation", "==", "'bilinear'", ":", "\n", "            ", "np_inter", "=", "cv2", ".", "INTER_LINEAR", "\n", "", "else", ":", "\n", "            ", "np_inter", "=", "cv2", ".", "INTER_NEAREST", "\n", "", "scaled", "=", "[", "\n", "cv2", ".", "resize", "(", "img", ",", "size", ",", "interpolation", "=", "np_inter", ")", "for", "img", "in", "clip", "\n", "]", "\n", "", "elif", "isinstance", "(", "clip", "[", "0", "]", ",", "PIL", ".", "Image", ".", "Image", ")", ":", "\n", "        ", "if", "isinstance", "(", "size", ",", "numbers", ".", "Number", ")", ":", "\n", "            ", "im_w", ",", "im_h", "=", "clip", "[", "0", "]", ".", "size", "\n", "# Min spatial dim already matches minimal size", "\n", "if", "(", "im_w", "<=", "im_h", "and", "im_w", "==", "size", ")", "or", "(", "im_h", "<=", "im_w", "\n", "and", "im_h", "==", "size", ")", ":", "\n", "                ", "return", "clip", "\n", "", "new_h", ",", "new_w", "=", "get_resize_sizes", "(", "im_h", ",", "im_w", ",", "size", ")", "\n", "size", "=", "(", "new_w", ",", "new_h", ")", "\n", "", "else", ":", "\n", "            ", "size", "=", "size", "[", "1", "]", ",", "size", "[", "0", "]", "\n", "", "if", "interpolation", "==", "'bilinear'", ":", "\n", "            ", "pil_inter", "=", "PIL", ".", "Image", ".", "NEAREST", "\n", "", "else", ":", "\n", "            ", "pil_inter", "=", "PIL", ".", "Image", ".", "BILINEAR", "\n", "", "scaled", "=", "[", "img", ".", "resize", "(", "size", ",", "pil_inter", ")", "for", "img", "in", "clip", "]", "\n", "", "else", ":", "\n", "        ", "raise", "TypeError", "(", "'Expected numpy.ndarray or PIL.Image'", "+", "\n", "'but got list of {0}'", ".", "format", "(", "type", "(", "clip", "[", "0", "]", ")", ")", ")", "\n", "", "return", "scaled", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.image.functional.get_resize_sizes": [[67, 75], ["int", "int"], "function", ["None"], ["", "def", "get_resize_sizes", "(", "im_h", ",", "im_w", ",", "size", ")", ":", "\n", "    ", "if", "im_w", "<", "im_h", ":", "\n", "        ", "ow", "=", "size", "\n", "oh", "=", "int", "(", "size", "*", "im_h", "/", "im_w", ")", "\n", "", "else", ":", "\n", "        ", "oh", "=", "size", "\n", "ow", "=", "int", "(", "size", "*", "im_w", "/", "im_h", ")", "\n", "", "return", "oh", ",", "ow", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.image.functional.normalize": [[77, 94], ["len", "torch.as_tensor", "torch.as_tensor", "clip.clone.sub_().div_", "functional._is_tensor_clip", "TypeError", "clip.clone.clone", "clip.clone.sub_"], "function", ["home.repos.pwc.inspect_result.showlab_all-in-one.transforms.functional._is_tensor_clip"], ["", "def", "normalize", "(", "clip", ",", "mean", ",", "std", ",", "inplace", "=", "False", ")", ":", "\n", "    ", "if", "not", "_is_tensor_clip", "(", "clip", ")", ":", "\n", "        ", "raise", "TypeError", "(", "'tensor is not a torch clip_test.'", ")", "\n", "\n", "", "if", "not", "inplace", ":", "\n", "        ", "clip", "=", "clip", ".", "clone", "(", ")", "\n", "\n", "", "dtype", "=", "clip", ".", "dtype", "\n", "dim", "=", "len", "(", "mean", ")", "\n", "mean", "=", "torch", ".", "as_tensor", "(", "mean", ",", "dtype", "=", "dtype", ",", "device", "=", "clip", ".", "device", ")", "\n", "std", "=", "torch", ".", "as_tensor", "(", "std", ",", "dtype", "=", "dtype", ",", "device", "=", "clip", ".", "device", ")", "\n", "# print(clip_test.size())", "\n", "# if dim == 3:", "\n", "clip", ".", "sub_", "(", "mean", "[", ":", ",", "None", ",", "None", ",", "None", "]", ")", ".", "div_", "(", "std", "[", ":", ",", "None", ",", "None", ",", "None", "]", ")", "\n", "# else:", "\n", "#     clip_test.sub_(mean[:, None, None]).div_(std[:, None, None])", "\n", "return", "clip", "", "", ""]], "home.repos.pwc.inspect_result.showlab_all-in-one.image.imageaug.image_aug": [[1, 10], ["range", "global_images_tensor.append", "global_transform().unsqueeze", "global_transform"], "function", ["None"], ["def", "image_aug", "(", "images", ",", "image_transform", ")", ":", "\n", "# print(image_transform)", "\n", "    ", "global_transform", "=", "image_transform", "[", "0", "]", "[", "0", "]", "\n", "local_transform", "=", "image_transform", "[", "0", "]", "[", "1", "]", "\n", "global_images_tensor", "=", "[", "]", "\n", "# 2 GLOBAL views", "\n", "for", "i", "in", "range", "(", "2", ")", ":", "\n", "        ", "global_images_tensor", ".", "append", "(", "global_transform", "(", "images", ")", ".", "unsqueeze", "(", "0", ")", ")", "\n", "", "return", "global_images_tensor", "\n", "# # 3 LOCAL VIEWS", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.image.randaug.Lighting.__init__": [[209, 213], ["torch.Tensor", "torch.Tensor"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "alphastd", ",", "eigval", ",", "eigvec", ")", ":", "\n", "        ", "self", ".", "alphastd", "=", "alphastd", "\n", "self", ".", "eigval", "=", "torch", ".", "Tensor", "(", "eigval", ")", "\n", "self", ".", "eigvec", "=", "torch", ".", "Tensor", "(", "eigvec", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.image.randaug.Lighting.__call__": [[214, 229], ["img.new().resize_().normal_", "randaug.Lighting.eigvec.type_as().clone().mul().mul().sum().squeeze", "img.add", "randaug.Lighting.view().expand_as", "img.new().resize_", "randaug.Lighting.eigvec.type_as().clone().mul().mul().sum", "randaug.Lighting.view", "img.new", "randaug.Lighting.eigvec.type_as().clone().mul().mul", "randaug.Lighting.eigval.view().expand", "randaug.Lighting.eigvec.type_as().clone().mul", "img.new().resize_().normal_.view().expand", "randaug.Lighting.eigval.view", "randaug.Lighting.eigvec.type_as().clone", "img.new().resize_().normal_.view", "randaug.Lighting.eigvec.type_as"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "img", ")", ":", "\n", "        ", "if", "self", ".", "alphastd", "==", "0", ":", "\n", "            ", "return", "img", "\n", "\n", "", "alpha", "=", "img", ".", "new", "(", ")", ".", "resize_", "(", "3", ")", ".", "normal_", "(", "0", ",", "self", ".", "alphastd", ")", "\n", "rgb", "=", "(", "\n", "self", ".", "eigvec", ".", "type_as", "(", "img", ")", "\n", ".", "clone", "(", ")", "\n", ".", "mul", "(", "alpha", ".", "view", "(", "1", ",", "3", ")", ".", "expand", "(", "3", ",", "3", ")", ")", "\n", ".", "mul", "(", "self", ".", "eigval", ".", "view", "(", "1", ",", "3", ")", ".", "expand", "(", "3", ",", "3", ")", ")", "\n", ".", "sum", "(", "1", ")", "\n", ".", "squeeze", "(", ")", "\n", ")", "\n", "\n", "return", "img", ".", "add", "(", "rgb", ".", "view", "(", "3", ",", "1", ",", "1", ")", ".", "expand_as", "(", "img", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.image.randaug.CutoutDefault.__init__": [[236, 238], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "length", ")", ":", "\n", "        ", "self", ".", "length", "=", "length", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.image.randaug.CutoutDefault.__call__": [[239, 255], ["numpy.ones", "numpy.random.randint", "numpy.random.randint", "numpy.clip", "numpy.clip", "numpy.clip", "numpy.clip", "torch.from_numpy", "mask.expand_as.expand_as.expand_as", "img.size", "img.size"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "img", ")", ":", "\n", "        ", "h", ",", "w", "=", "img", ".", "size", "(", "1", ")", ",", "img", ".", "size", "(", "2", ")", "\n", "mask", "=", "np", ".", "ones", "(", "(", "h", ",", "w", ")", ",", "np", ".", "float32", ")", "\n", "y", "=", "np", ".", "random", ".", "randint", "(", "h", ")", "\n", "x", "=", "np", ".", "random", ".", "randint", "(", "w", ")", "\n", "\n", "y1", "=", "np", ".", "clip", "(", "y", "-", "self", ".", "length", "//", "2", ",", "0", ",", "h", ")", "\n", "y2", "=", "np", ".", "clip", "(", "y", "+", "self", ".", "length", "//", "2", ",", "0", ",", "h", ")", "\n", "x1", "=", "np", ".", "clip", "(", "x", "-", "self", ".", "length", "//", "2", ",", "0", ",", "w", ")", "\n", "x2", "=", "np", ".", "clip", "(", "x", "+", "self", ".", "length", "//", "2", ",", "0", ",", "w", ")", "\n", "\n", "mask", "[", "y1", ":", "y2", ",", "x1", ":", "x2", "]", "=", "0.0", "\n", "mask", "=", "torch", ".", "from_numpy", "(", "mask", ")", "\n", "mask", "=", "mask", ".", "expand_as", "(", "img", ")", "\n", "img", "*=", "mask", "\n", "return", "img", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.image.randaug.RandAugment.__init__": [[258, 262], ["randaug.augment_list"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.transforms.randaug.augment_list"], ["    ", "def", "__init__", "(", "self", ",", "n", ",", "m", ")", ":", "\n", "        ", "self", ".", "n", "=", "n", "\n", "self", ".", "m", "=", "m", "# [0, 30]", "\n", "self", ".", "augment_list", "=", "augment_list", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.image.randaug.RandAugment.__call__": [[263, 270], ["random.choices", "op", "float", "float"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "img", ")", ":", "\n", "        ", "ops", "=", "random", ".", "choices", "(", "self", ".", "augment_list", ",", "k", "=", "self", ".", "n", ")", "\n", "for", "op", ",", "minval", ",", "maxval", "in", "ops", ":", "\n", "            ", "val", "=", "(", "float", "(", "self", ".", "m", ")", "/", "30", ")", "*", "float", "(", "maxval", "-", "minval", ")", "+", "minval", "\n", "img", "=", "op", "(", "img", ",", "val", ")", "\n", "\n", "", "return", "img", "\n", "", "", ""]], "home.repos.pwc.inspect_result.showlab_all-in-one.image.randaug.ShearX": [[11, 16], ["img.transform", "random.random"], "function", ["None"], ["def", "ShearX", "(", "img", ",", "v", ")", ":", "# [-0.3, 0.3]", "\n", "    ", "assert", "-", "0.3", "<=", "v", "<=", "0.3", "\n", "if", "random", ".", "random", "(", ")", ">", "0.5", ":", "\n", "        ", "v", "=", "-", "v", "\n", "", "return", "img", ".", "transform", "(", "img", ".", "size", ",", "PIL", ".", "Image", ".", "AFFINE", ",", "(", "1", ",", "v", ",", "0", ",", "0", ",", "1", ",", "0", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.image.randaug.ShearY": [[18, 23], ["img.transform", "random.random"], "function", ["None"], ["", "def", "ShearY", "(", "img", ",", "v", ")", ":", "# [-0.3, 0.3]", "\n", "    ", "assert", "-", "0.3", "<=", "v", "<=", "0.3", "\n", "if", "random", ".", "random", "(", ")", ">", "0.5", ":", "\n", "        ", "v", "=", "-", "v", "\n", "", "return", "img", ".", "transform", "(", "img", ".", "size", ",", "PIL", ".", "Image", ".", "AFFINE", ",", "(", "1", ",", "0", ",", "0", ",", "v", ",", "1", ",", "0", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.image.randaug.TranslateX": [[25, 31], ["img.transform", "random.random"], "function", ["None"], ["", "def", "TranslateX", "(", "img", ",", "v", ")", ":", "# [-150, 150] => percentage: [-0.45, 0.45]", "\n", "    ", "assert", "-", "0.45", "<=", "v", "<=", "0.45", "\n", "if", "random", ".", "random", "(", ")", ">", "0.5", ":", "\n", "        ", "v", "=", "-", "v", "\n", "", "v", "=", "v", "*", "img", ".", "size", "[", "0", "]", "\n", "return", "img", ".", "transform", "(", "img", ".", "size", ",", "PIL", ".", "Image", ".", "AFFINE", ",", "(", "1", ",", "0", ",", "v", ",", "0", ",", "1", ",", "0", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.image.randaug.TranslateXabs": [[33, 38], ["img.transform", "random.random"], "function", ["None"], ["", "def", "TranslateXabs", "(", "img", ",", "v", ")", ":", "# [-150, 150] => percentage: [-0.45, 0.45]", "\n", "    ", "assert", "0", "<=", "v", "\n", "if", "random", ".", "random", "(", ")", ">", "0.5", ":", "\n", "        ", "v", "=", "-", "v", "\n", "", "return", "img", ".", "transform", "(", "img", ".", "size", ",", "PIL", ".", "Image", ".", "AFFINE", ",", "(", "1", ",", "0", ",", "v", ",", "0", ",", "1", ",", "0", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.image.randaug.TranslateY": [[40, 46], ["img.transform", "random.random"], "function", ["None"], ["", "def", "TranslateY", "(", "img", ",", "v", ")", ":", "# [-150, 150] => percentage: [-0.45, 0.45]", "\n", "    ", "assert", "-", "0.45", "<=", "v", "<=", "0.45", "\n", "if", "random", ".", "random", "(", ")", ">", "0.5", ":", "\n", "        ", "v", "=", "-", "v", "\n", "", "v", "=", "v", "*", "img", ".", "size", "[", "1", "]", "\n", "return", "img", ".", "transform", "(", "img", ".", "size", ",", "PIL", ".", "Image", ".", "AFFINE", ",", "(", "1", ",", "0", ",", "0", ",", "0", ",", "1", ",", "v", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.image.randaug.TranslateYabs": [[48, 53], ["img.transform", "random.random"], "function", ["None"], ["", "def", "TranslateYabs", "(", "img", ",", "v", ")", ":", "# [-150, 150] => percentage: [-0.45, 0.45]", "\n", "    ", "assert", "0", "<=", "v", "\n", "if", "random", ".", "random", "(", ")", ">", "0.5", ":", "\n", "        ", "v", "=", "-", "v", "\n", "", "return", "img", ".", "transform", "(", "img", ".", "size", ",", "PIL", ".", "Image", ".", "AFFINE", ",", "(", "1", ",", "0", ",", "0", ",", "0", ",", "1", ",", "v", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.image.randaug.Rotate": [[55, 60], ["img.rotate", "random.random"], "function", ["None"], ["", "def", "Rotate", "(", "img", ",", "v", ")", ":", "# [-30, 30]", "\n", "    ", "assert", "-", "30", "<=", "v", "<=", "30", "\n", "if", "random", ".", "random", "(", ")", ">", "0.5", ":", "\n", "        ", "v", "=", "-", "v", "\n", "", "return", "img", ".", "rotate", "(", "v", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.image.randaug.AutoContrast": [[62, 64], ["PIL.ImageOps.autocontrast", "PIL.ImageOps.autocontrast", "PIL.ImageOps.autocontrast", "PIL.ImageOps.autocontrast"], "function", ["None"], ["", "def", "AutoContrast", "(", "img", ",", "_", ")", ":", "\n", "    ", "return", "PIL", ".", "ImageOps", ".", "autocontrast", "(", "img", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.image.randaug.Invert": [[66, 68], ["PIL.ImageOps.invert", "PIL.ImageOps.invert", "PIL.ImageOps.invert", "PIL.ImageOps.invert"], "function", ["None"], ["", "def", "Invert", "(", "img", ",", "_", ")", ":", "\n", "    ", "return", "PIL", ".", "ImageOps", ".", "invert", "(", "img", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.image.randaug.Equalize": [[70, 72], ["PIL.ImageOps.equalize", "PIL.ImageOps.equalize", "PIL.ImageOps.equalize", "PIL.ImageOps.equalize"], "function", ["None"], ["", "def", "Equalize", "(", "img", ",", "_", ")", ":", "\n", "    ", "return", "PIL", ".", "ImageOps", ".", "equalize", "(", "img", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.image.randaug.Flip": [[74, 76], ["PIL.ImageOps.mirror", "PIL.ImageOps.mirror", "PIL.ImageOps.mirror", "PIL.ImageOps.mirror"], "function", ["None"], ["", "def", "Flip", "(", "img", ",", "_", ")", ":", "# not from the paper", "\n", "    ", "return", "PIL", ".", "ImageOps", ".", "mirror", "(", "img", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.image.randaug.Solarize": [[78, 81], ["PIL.ImageOps.solarize", "PIL.ImageOps.solarize", "PIL.ImageOps.solarize", "PIL.ImageOps.solarize"], "function", ["None"], ["", "def", "Solarize", "(", "img", ",", "v", ")", ":", "# [0, 256]", "\n", "    ", "assert", "0", "<=", "v", "<=", "256", "\n", "return", "PIL", ".", "ImageOps", ".", "solarize", "(", "img", ",", "v", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.image.randaug.SolarizeAdd": [[83, 90], ["numpy.array().astype", "numpy.clip", "img_np.astype.astype", "PIL.Image.fromarray", "PIL.ImageOps.solarize", "PIL.ImageOps.solarize", "PIL.ImageOps.solarize", "PIL.ImageOps.solarize", "numpy.array"], "function", ["None"], ["", "def", "SolarizeAdd", "(", "img", ",", "addition", "=", "0", ",", "threshold", "=", "128", ")", ":", "\n", "    ", "img_np", "=", "np", ".", "array", "(", "img", ")", ".", "astype", "(", "np", ".", "int", ")", "\n", "img_np", "=", "img_np", "+", "addition", "\n", "img_np", "=", "np", ".", "clip", "(", "img_np", ",", "0", ",", "255", ")", "\n", "img_np", "=", "img_np", ".", "astype", "(", "np", ".", "uint8", ")", "\n", "img", "=", "Image", ".", "fromarray", "(", "img_np", ")", "\n", "return", "PIL", ".", "ImageOps", ".", "solarize", "(", "img", ",", "threshold", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.image.randaug.Posterize": [[92, 96], ["int", "max", "PIL.ImageOps.posterize", "PIL.ImageOps.posterize", "PIL.ImageOps.posterize", "PIL.ImageOps.posterize"], "function", ["None"], ["", "def", "Posterize", "(", "img", ",", "v", ")", ":", "# [4, 8]", "\n", "    ", "v", "=", "int", "(", "v", ")", "\n", "v", "=", "max", "(", "1", ",", "v", ")", "\n", "return", "PIL", ".", "ImageOps", ".", "posterize", "(", "img", ",", "v", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.image.randaug.Contrast": [[98, 101], ["PIL.ImageEnhance.Contrast().enhance", "PIL.ImageEnhance.Contrast().enhance", "PIL.ImageEnhance.Contrast().enhance", "PIL.ImageEnhance.Contrast().enhance", "PIL.ImageEnhance.Contrast", "PIL.ImageEnhance.Contrast", "PIL.ImageEnhance.Contrast", "PIL.ImageEnhance.Contrast"], "function", ["home.repos.pwc.inspect_result.showlab_all-in-one.transforms.randaug.Contrast", "home.repos.pwc.inspect_result.showlab_all-in-one.transforms.randaug.Contrast", "home.repos.pwc.inspect_result.showlab_all-in-one.transforms.randaug.Contrast", "home.repos.pwc.inspect_result.showlab_all-in-one.transforms.randaug.Contrast"], ["", "def", "Contrast", "(", "img", ",", "v", ")", ":", "# [0.1,1.9]", "\n", "    ", "assert", "0.1", "<=", "v", "<=", "1.9", "\n", "return", "PIL", ".", "ImageEnhance", ".", "Contrast", "(", "img", ")", ".", "enhance", "(", "v", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.image.randaug.Color": [[103, 106], ["PIL.ImageEnhance.Color().enhance", "PIL.ImageEnhance.Color().enhance", "PIL.ImageEnhance.Color().enhance", "PIL.ImageEnhance.Color().enhance", "PIL.ImageEnhance.Color", "PIL.ImageEnhance.Color", "PIL.ImageEnhance.Color", "PIL.ImageEnhance.Color"], "function", ["home.repos.pwc.inspect_result.showlab_all-in-one.transforms.randaug.Color", "home.repos.pwc.inspect_result.showlab_all-in-one.transforms.randaug.Color", "home.repos.pwc.inspect_result.showlab_all-in-one.transforms.randaug.Color", "home.repos.pwc.inspect_result.showlab_all-in-one.transforms.randaug.Color"], ["", "def", "Color", "(", "img", ",", "v", ")", ":", "# [0.1,1.9]", "\n", "    ", "assert", "0.1", "<=", "v", "<=", "1.9", "\n", "return", "PIL", ".", "ImageEnhance", ".", "Color", "(", "img", ")", ".", "enhance", "(", "v", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.image.randaug.Brightness": [[108, 111], ["PIL.ImageEnhance.Brightness().enhance", "PIL.ImageEnhance.Brightness().enhance", "PIL.ImageEnhance.Brightness().enhance", "PIL.ImageEnhance.Brightness().enhance", "PIL.ImageEnhance.Brightness", "PIL.ImageEnhance.Brightness", "PIL.ImageEnhance.Brightness", "PIL.ImageEnhance.Brightness"], "function", ["home.repos.pwc.inspect_result.showlab_all-in-one.transforms.randaug.Brightness", "home.repos.pwc.inspect_result.showlab_all-in-one.transforms.randaug.Brightness", "home.repos.pwc.inspect_result.showlab_all-in-one.transforms.randaug.Brightness", "home.repos.pwc.inspect_result.showlab_all-in-one.transforms.randaug.Brightness"], ["", "def", "Brightness", "(", "img", ",", "v", ")", ":", "# [0.1,1.9]", "\n", "    ", "assert", "0.1", "<=", "v", "<=", "1.9", "\n", "return", "PIL", ".", "ImageEnhance", ".", "Brightness", "(", "img", ")", ".", "enhance", "(", "v", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.image.randaug.Sharpness": [[113, 116], ["PIL.ImageEnhance.Sharpness().enhance", "PIL.ImageEnhance.Sharpness().enhance", "PIL.ImageEnhance.Sharpness().enhance", "PIL.ImageEnhance.Sharpness().enhance", "PIL.ImageEnhance.Sharpness", "PIL.ImageEnhance.Sharpness", "PIL.ImageEnhance.Sharpness", "PIL.ImageEnhance.Sharpness"], "function", ["home.repos.pwc.inspect_result.showlab_all-in-one.transforms.randaug.Sharpness", "home.repos.pwc.inspect_result.showlab_all-in-one.transforms.randaug.Sharpness", "home.repos.pwc.inspect_result.showlab_all-in-one.transforms.randaug.Sharpness", "home.repos.pwc.inspect_result.showlab_all-in-one.transforms.randaug.Sharpness"], ["", "def", "Sharpness", "(", "img", ",", "v", ")", ":", "# [0.1,1.9]", "\n", "    ", "assert", "0.1", "<=", "v", "<=", "1.9", "\n", "return", "PIL", ".", "ImageEnhance", ".", "Sharpness", "(", "img", ")", ".", "enhance", "(", "v", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.image.randaug.Cutout": [[118, 125], ["randaug.CutoutAbs"], "function", ["home.repos.pwc.inspect_result.showlab_all-in-one.transforms.randaug.CutoutAbs"], ["", "def", "Cutout", "(", "img", ",", "v", ")", ":", "# [0, 60] => percentage: [0, 0.2]", "\n", "    ", "assert", "0.0", "<=", "v", "<=", "0.2", "\n", "if", "v", "<=", "0.0", ":", "\n", "        ", "return", "img", "\n", "\n", "", "v", "=", "v", "*", "img", ".", "size", "[", "0", "]", "\n", "return", "CutoutAbs", "(", "img", ",", "v", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.image.randaug.CutoutAbs": [[127, 146], ["numpy.random.uniform", "numpy.random.uniform", "int", "int", "min", "min", "img.copy.copy", "PIL.ImageDraw.Draw().rectangle", "PIL.ImageDraw.Draw().rectangle", "PIL.ImageDraw.Draw().rectangle", "PIL.ImageDraw.Draw().rectangle", "max", "max", "PIL.ImageDraw.Draw", "PIL.ImageDraw.Draw", "PIL.ImageDraw.Draw", "PIL.ImageDraw.Draw"], "function", ["None"], ["", "def", "CutoutAbs", "(", "img", ",", "v", ")", ":", "# [0, 60] => percentage: [0, 0.2]", "\n", "# assert 0 <= v <= 20", "\n", "    ", "if", "v", "<", "0", ":", "\n", "        ", "return", "img", "\n", "", "w", ",", "h", "=", "img", ".", "size", "\n", "x0", "=", "np", ".", "random", ".", "uniform", "(", "w", ")", "\n", "y0", "=", "np", ".", "random", ".", "uniform", "(", "h", ")", "\n", "\n", "x0", "=", "int", "(", "max", "(", "0", ",", "x0", "-", "v", "/", "2.0", ")", ")", "\n", "y0", "=", "int", "(", "max", "(", "0", ",", "y0", "-", "v", "/", "2.0", ")", ")", "\n", "x1", "=", "min", "(", "w", ",", "x0", "+", "v", ")", "\n", "y1", "=", "min", "(", "h", ",", "y0", "+", "v", ")", "\n", "\n", "xy", "=", "(", "x0", ",", "y0", ",", "x1", ",", "y1", ")", "\n", "color", "=", "(", "125", ",", "123", ",", "114", ")", "\n", "# color = (0, 0, 0)", "\n", "img", "=", "img", ".", "copy", "(", ")", "\n", "PIL", ".", "ImageDraw", ".", "Draw", "(", "img", ")", ".", "rectangle", "(", "xy", ",", "color", ")", "\n", "return", "img", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.image.randaug.SamplePairing": [[148, 155], ["numpy.random.choice", "PIL.Image.fromarray", "PIL.Image.fromarray", "PIL.Image.fromarray", "PIL.Image.fromarray", "PIL.Image.blend", "PIL.Image.blend", "PIL.Image.blend", "PIL.Image.blend", "len"], "function", ["None"], ["", "def", "SamplePairing", "(", "imgs", ")", ":", "# [0, 0.4]", "\n", "    ", "def", "f", "(", "img1", ",", "v", ")", ":", "\n", "        ", "i", "=", "np", ".", "random", ".", "choice", "(", "len", "(", "imgs", ")", ")", "\n", "img2", "=", "PIL", ".", "Image", ".", "fromarray", "(", "imgs", "[", "i", "]", ")", "\n", "return", "PIL", ".", "Image", ".", "blend", "(", "img1", ",", "img2", ",", "v", ")", "\n", "\n", "", "return", "f", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.image.randaug.Identity": [[157, 159], ["None"], "function", ["None"], ["", "def", "Identity", "(", "img", ",", "v", ")", ":", "\n", "    ", "return", "img", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.image.randaug.augment_list": [[161, 204], ["None"], "function", ["None"], ["", "def", "augment_list", "(", ")", ":", "# 16 oeprations and their ranges", "\n", "# https://github.com/google-research/uda/blob/master/image/randaugment/policies.py#L57", "\n", "# l = [", "\n", "#     (Identity, 0., 1.0),", "\n", "#     (ShearX, 0., 0.3),  # 0", "\n", "#     (ShearY, 0., 0.3),  # 1", "\n", "#     (TranslateX, 0., 0.33),  # 2", "\n", "#     (TranslateY, 0., 0.33),  # 3", "\n", "#     (Rotate, 0, 30),  # 4", "\n", "#     (AutoContrast, 0, 1),  # 5", "\n", "#     (Invert, 0, 1),  # 6", "\n", "#     (Equalize, 0, 1),  # 7", "\n", "#     (Solarize, 0, 110),  # 8", "\n", "#     (Posterize, 4, 8),  # 9", "\n", "#     # (Contrast, 0.1, 1.9),  # 10", "\n", "#     (Color, 0.1, 1.9),  # 11", "\n", "#     (Brightness, 0.1, 1.9),  # 12", "\n", "#     (Sharpness, 0.1, 1.9),  # 13", "\n", "#     # (Cutout, 0, 0.2),  # 14", "\n", "#     # (SamplePairing(imgs), 0, 0.4),  # 15", "\n", "# ]", "\n", "\n", "# https://github.com/tensorflow/tpu/blob/8462d083dd89489a79e3200bcc8d4063bf362186/models/official/efficientnet/autoaugment.py#L505", "\n", "    ", "l", "=", "[", "\n", "(", "AutoContrast", ",", "0", ",", "1", ")", ",", "\n", "(", "Equalize", ",", "0", ",", "1", ")", ",", "\n", "# (Invert, 0, 1),", "\n", "(", "Rotate", ",", "0", ",", "30", ")", ",", "\n", "(", "Posterize", ",", "0", ",", "4", ")", ",", "\n", "(", "Solarize", ",", "0", ",", "256", ")", ",", "\n", "(", "SolarizeAdd", ",", "0", ",", "110", ")", ",", "\n", "(", "Color", ",", "0.1", ",", "1.9", ")", ",", "\n", "(", "Contrast", ",", "0.1", ",", "1.9", ")", ",", "\n", "(", "Brightness", ",", "0.1", ",", "1.9", ")", ",", "\n", "(", "Sharpness", ",", "0.1", ",", "1.9", ")", ",", "\n", "(", "ShearX", ",", "0.0", ",", "0.3", ")", ",", "\n", "(", "ShearY", ",", "0.0", ",", "0.3", ")", ",", "\n", "# (CutoutAbs, 0, 40),", "\n", "(", "TranslateXabs", ",", "0.0", ",", "100", ")", ",", "\n", "(", "TranslateYabs", ",", "0.0", ",", "100", ")", ",", "\n", "]", "\n", "\n", "return", "l", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.image.utils.MinMaxResize.__init__": [[6, 9], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "shorter", "=", "800", ",", "longer", "=", "1333", ")", ":", "\n", "        ", "self", ".", "min", "=", "shorter", "\n", "self", ".", "max", "=", "longer", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.image.utils.MinMaxResize.__call__": [[10, 27], ["x.resize", "min", "max", "int", "int", "max"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "x", ")", ":", "\n", "        ", "w", ",", "h", "=", "x", ".", "size", "\n", "scale", "=", "self", ".", "min", "/", "min", "(", "w", ",", "h", ")", "\n", "if", "h", "<", "w", ":", "\n", "            ", "newh", ",", "neww", "=", "self", ".", "min", ",", "scale", "*", "w", "\n", "", "else", ":", "\n", "            ", "newh", ",", "neww", "=", "scale", "*", "h", ",", "self", ".", "min", "\n", "\n", "", "if", "max", "(", "newh", ",", "neww", ")", ">", "self", ".", "max", ":", "\n", "            ", "scale", "=", "self", ".", "max", "/", "max", "(", "newh", ",", "neww", ")", "\n", "newh", "=", "newh", "*", "scale", "\n", "neww", "=", "neww", "*", "scale", "\n", "\n", "", "newh", ",", "neww", "=", "int", "(", "newh", "+", "0.5", ")", ",", "int", "(", "neww", "+", "0.5", ")", "\n", "newh", ",", "neww", "=", "newh", "//", "32", "*", "32", ",", "neww", "//", "32", "*", "32", "\n", "\n", "return", "x", ".", "resize", "(", "(", "neww", ",", "newh", ")", ",", "resample", "=", "Image", ".", "BICUBIC", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.image.utils.UnNormalize.__init__": [[30, 33], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "mean", ",", "std", ")", ":", "\n", "        ", "self", ".", "mean", "=", "mean", "\n", "self", ".", "std", "=", "std", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.image.utils.UnNormalize.__call__": [[34, 45], ["zip", "t.mul_().add_", "t.mul_"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "tensor", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            tensor (Tensor): Tensor image of size (C, H, W) to be normalized.\n        Returns:\n            Tensor: Normalized image.\n        \"\"\"", "\n", "for", "t", ",", "m", ",", "s", "in", "zip", "(", "tensor", ",", "self", ".", "mean", ",", "self", ".", "std", ")", ":", "\n", "            ", "t", ".", "mul_", "(", "s", ")", ".", "add_", "(", "m", ")", "\n", "# The normalize code -> t.sub_(m).div_(s)", "\n", "", "return", "tensor", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.howto100m.HT100MDataset.__init__": [[13, 42], ["video_base_dataset.BaseDataset.__init__", "howto100m.HT100MDataset._load_metadata", "os.path.join", "howto100m.HT100MDataset._load_metadata", "float"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.transforms.utils.UnNormalize.__init__", "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_v2.Ego4DDataset._load_metadata", "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_v2.Ego4DDataset._load_metadata"], ["def", "__init__", "(", "self", ",", "*", "args", ",", "split", "=", "\"\"", ",", "**", "kwargs", ")", ":", "\n", "        ", "assert", "split", "in", "[", "\"train\"", ",", "\"val\"", ",", "\"test\"", "]", "\n", "self", ".", "split", "=", "split", "\n", "\n", "if", "split", "==", "\"train\"", ":", "\n", "            ", "names", "=", "[", "\"howto100m_train\"", "]", "\n", "", "elif", "split", "==", "\"val\"", ":", "\n", "            ", "names", "=", "[", "\"howto100m_val\"", "]", "\n", "", "elif", "split", "==", "\"test\"", ":", "\n", "            ", "names", "=", "[", "\"howto100m_test\"", "]", "\n", "", "super", "(", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ",", "names", "=", "names", ",", "text_column_name", "=", "\"caption\"", ")", "\n", "\n", "self", ".", "metadata", "=", "None", "\n", "self", ".", "_load_metadata", "(", ")", "\n", "# for howto100", "\n", "self", ".", "min_time", "=", "4.0", "\n", "self", ".", "size", "=", "256", "\n", "self", ".", "fps", "=", "2", "\n", "self", ".", "num_sec", "=", "self", ".", "num_frames", "/", "float", "(", "self", ".", "fps", ")", "\n", "self", ".", "crop_only", "=", "True", "\n", "if", "self", ".", "split", "==", "'train'", ":", "\n", "            ", "self", ".", "center_crop", "=", "False", "\n", "", "else", ":", "\n", "            ", "self", ".", "center_crop", "=", "True", "\n", "", "self", ".", "benchmark", "=", "False", "\n", "self", ".", "num_candidates", "=", "1", "\n", "self", ".", "random_flip", "=", "True", "\n", "self", ".", "caption_dir", "=", "os", ".", "path", ".", "join", "(", "self", ".", "data_dir", ",", "'howto100m_csv'", ")", "\n", "print", "(", "names", ",", "\": \"", ",", "len", "(", "self", ".", "metadata", ")", ",", "\"samples in total.\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.howto100m.HT100MDataset._load_metadata": [[43, 53], ["pandas.read_csv", "os.path.join"], "methods", ["None"], ["", "def", "_load_metadata", "(", "self", ")", ":", "\n", "        ", "metadata_dir", "=", "'./meta_data/howto100m'", "\n", "split_files", "=", "{", "\n", "'train'", ":", "'ht100_videos_split.csv'", ",", "\n", "'val'", ":", "'ht100_videos_split_val.csv'", ",", "# there is no test", "\n", "'test'", ":", "'ht100_videos_split_val.csv'", "\n", "}", "\n", "target_split_fp", "=", "split_files", "[", "self", ".", "split", "]", "\n", "metadata", "=", "pd", ".", "read_csv", "(", "os", ".", "path", ".", "join", "(", "metadata_dir", ",", "target_split_fp", ")", ",", "sep", "=", "'\\t'", ")", "\n", "self", ".", "metadata", "=", "metadata", "[", "\"Name\"", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.howto100m.HT100MDataset.read_frames_ffmpeg": [[54, 92], ["random.randint", "ffmpeg.input().filter", "cmd.hflip.hflip.output().run", "numpy.frombuffer().reshape", "torch.from_numpy", "int", "int", "cmd.hflip.hflip.crop", "cmd.hflip.hflip.crop().filter", "cmd.hflip.hflip.hflip", "numpy.copy", "torch.cat.permute", "torch.ones", "torch.cat", "max", "ffmpeg.input", "random.uniform", "random.uniform", "str", "str", "random.uniform", "cmd.hflip.hflip.output", "numpy.frombuffer", "cmd.hflip.hflip.crop"], "methods", ["None"], ["", "def", "read_frames_ffmpeg", "(", "self", ",", "video_path", ",", "start", ",", "end", ")", ":", "\n", "        ", "start_seek", "=", "random", ".", "randint", "(", "int", "(", "start", ")", ",", "int", "(", "max", "(", "start", ",", "end", "-", "self", ".", "num_sec", ")", ")", ")", "\n", "cmd", "=", "(", "\n", "ffmpeg", "\n", ".", "input", "(", "video_path", ",", "ss", "=", "start_seek", ",", "t", "=", "self", ".", "num_sec", "+", "0.01", ")", "\n", ".", "filter", "(", "'fps'", ",", "fps", "=", "self", ".", "fps", ")", "\n", ")", "\n", "if", "self", ".", "center_crop", ":", "\n", "            ", "aw", ",", "ah", "=", "0.5", ",", "0.5", "\n", "", "else", ":", "\n", "            ", "aw", ",", "ah", "=", "random", ".", "uniform", "(", "0", ",", "1", ")", ",", "random", ".", "uniform", "(", "0", ",", "1", ")", "\n", "", "if", "self", ".", "crop_only", ":", "\n", "            ", "cmd", "=", "(", "\n", "cmd", ".", "crop", "(", "'(iw - {})*{}'", ".", "format", "(", "self", ".", "size", ",", "aw", ")", ",", "\n", "'(ih - {})*{}'", ".", "format", "(", "self", ".", "size", ",", "ah", ")", ",", "\n", "str", "(", "self", ".", "size", ")", ",", "str", "(", "self", ".", "size", ")", ")", "\n", ")", "\n", "", "else", ":", "\n", "            ", "cmd", "=", "(", "\n", "cmd", ".", "crop", "(", "'(iw - min(iw,ih))*{}'", ".", "format", "(", "aw", ")", ",", "\n", "'(ih - min(iw,ih))*{}'", ".", "format", "(", "ah", ")", ",", "\n", "'min(iw,ih)'", ",", "\n", "'min(iw,ih)'", ")", "\n", ".", "filter", "(", "'scale'", ",", "self", ".", "size", ",", "self", ".", "size", ")", "\n", ")", "\n", "", "if", "self", ".", "random_flip", "and", "random", ".", "uniform", "(", "0", ",", "1", ")", ">", "0.5", ":", "\n", "            ", "cmd", "=", "cmd", ".", "hflip", "(", ")", "\n", "", "out", ",", "_", "=", "(", "\n", "cmd", ".", "output", "(", "'pipe:'", ",", "format", "=", "'rawvideo'", ",", "pix_fmt", "=", "'rgb24'", ")", ".", "run", "(", "capture_stdout", "=", "True", ",", "quiet", "=", "True", ")", "\n", ")", "\n", "# print(np.frombuffer(out, np.uint8).shape)", "\n", "video", "=", "np", ".", "frombuffer", "(", "out", ",", "np", ".", "uint8", ")", ".", "reshape", "(", "[", "-", "1", ",", "self", ".", "size", ",", "self", ".", "size", ",", "3", "]", ")", "\n", "video_tensor", "=", "th", ".", "from_numpy", "(", "np", ".", "copy", "(", "video", ")", ")", "\n", "video_tensor", "=", "video_tensor", ".", "permute", "(", "3", ",", "0", ",", "1", ",", "2", ")", "+", "0.01", "# prevent all dark vide", "\n", "if", "video_tensor", ".", "shape", "[", "1", "]", "<", "self", ".", "num_frames", ":", "\n", "            ", "zeros", "=", "th", ".", "ones", "(", "(", "3", ",", "self", ".", "num_frames", "-", "video_tensor", ".", "shape", "[", "1", "]", ",", "self", ".", "size", ",", "self", ".", "size", ")", ",", "dtype", "=", "th", ".", "uint8", ")", "\n", "video_tensor", "=", "th", ".", "cat", "(", "(", "video_tensor", ",", "zeros", ")", ",", "axis", "=", "1", ")", "\n", "", "return", "video_tensor", "[", ":", ",", ":", "self", ".", "num_frames", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.howto100m.HT100MDataset.get_caption": [[94, 104], ["pandas.read_csv", "random.randint", "max", "len"], "methods", ["None"], ["", "def", "get_caption", "(", "self", ",", "caption", ")", ":", "\n", "        ", "cap", "=", "pd", ".", "read_csv", "(", "caption", ")", "\n", "ind", "=", "random", ".", "randint", "(", "0", ",", "len", "(", "cap", ")", "-", "1", ")", "\n", "text", "=", "cap", "[", "'text'", "]", ".", "values", "[", "ind", "]", "\n", "start", ",", "end", "=", "cap", "[", "'start'", "]", ".", "values", "[", "ind", "]", ",", "cap", "[", "'end'", "]", ".", "values", "[", "ind", "]", "\n", "if", "end", "-", "start", "<", "self", ".", "min_time", ":", "\n", "            ", "diff", "=", "self", ".", "min_time", "-", "end", "+", "start", "\n", "start", "=", "max", "(", "0", ",", "start", "-", "diff", "/", "2", ")", "\n", "end", "=", "start", "+", "self", ".", "min_time", "\n", "", "return", "text", ",", "start", ",", "end", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.howto100m.HT100MDataset.get_text": [[105, 118], ["howto100m.HT100MDataset.get_caption_path", "howto100m.HT100MDataset.get_caption", "howto100m.HT100MDataset.tokenizer", "int", "int"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.datasets.yttemporal.YTTemporalDataset.get_caption_path", "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.yttemporal.YTTemporalDataset.get_caption"], ["", "def", "get_text", "(", "self", ",", "sample", ")", ":", "\n", "        ", "caption_csv", "=", "self", ".", "get_caption_path", "(", "sample", ")", "\n", "text", ",", "start", ",", "end", "=", "self", ".", "get_caption", "(", "caption_csv", ")", "\n", "# print(text)", "\n", "# TODO: May need to be improved for edge cases.", "\n", "encoding", "=", "self", ".", "tokenizer", "(", "\n", "text", ",", "\n", "padding", "=", "\"max_length\"", ",", "\n", "truncation", "=", "True", ",", "\n", "max_length", "=", "self", ".", "max_text_len", ",", "\n", "return_special_tokens_mask", "=", "True", ",", "\n", ")", "\n", "return", "{", "\"text\"", ":", "(", "text", ",", "encoding", ")", "}", ",", "int", "(", "start", ")", ",", "int", "(", "end", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.howto100m.HT100MDataset.get_caption_path": [[119, 122], ["os.path.join", "[].split", "sample.split"], "methods", ["None"], ["", "def", "get_caption_path", "(", "self", ",", "sample", ")", ":", "\n", "# example xx/xx/xx.mp4 -> xx.csv", "\n", "        ", "return", "os", ".", "path", ".", "join", "(", "self", ".", "caption_dir", ",", "sample", ".", "split", "(", "'/'", ")", "[", "-", "1", "]", ".", "split", "(", "'.'", ")", "[", "0", "]", "+", "'.csv'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.howto100m.HT100MDataset.get_false_text": [[123, 135], ["random.randint", "howto100m.HT100MDataset.get_caption_path", "howto100m.HT100MDataset.get_caption", "howto100m.HT100MDataset.tokenizer", "len"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.datasets.yttemporal.YTTemporalDataset.get_caption_path", "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.yttemporal.YTTemporalDataset.get_caption"], ["", "def", "get_false_text", "(", "self", ",", "rep", ")", ":", "\n", "        ", "random_index", "=", "random", ".", "randint", "(", "0", ",", "len", "(", "self", ".", "metadata", ")", "-", "1", ")", "\n", "sample", "=", "self", ".", "metadata", ".", "iloc", "[", "random_index", "]", "\n", "caption_csv", "=", "self", ".", "get_caption_path", "(", "sample", ")", "\n", "text", ",", "start", ",", "end", "=", "self", ".", "get_caption", "(", "caption_csv", ")", "\n", "encoding", "=", "self", ".", "tokenizer", "(", "\n", "text", ",", "\n", "truncation", "=", "True", ",", "\n", "max_length", "=", "self", ".", "max_text_len", ",", "\n", "return_special_tokens_mask", "=", "True", ",", "\n", ")", "\n", "return", "{", "f\"false_text_{rep}\"", ":", "(", "text", ",", "encoding", ")", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.howto100m.HT100MDataset._get_video_path": [[136, 140], ["os.path.join"], "methods", ["None"], ["", "def", "_get_video_path", "(", "self", ",", "sample", ")", ":", "\n", "        ", "rel_video_fp", "=", "sample", "\n", "full_video_fp", "=", "os", ".", "path", ".", "join", "(", "self", ".", "data_dir", ",", "rel_video_fp", ")", "\n", "return", "full_video_fp", ",", "rel_video_fp", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.howto100m.HT100MDataset.get_raw_video": [[141, 148], ["howto100m.HT100MDataset._get_video_path", "howto100m.HT100MDataset.read_frames_ffmpeg().permute", "Exception", "howto100m.HT100MDataset.read_frames_ffmpeg"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_v2.Ego4DDataset._get_video_path", "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_v2.Ego4DDataset.read_frames_ffmpeg"], ["", "def", "get_raw_video", "(", "self", ",", "sample", ",", "begin", ",", "end", ")", ":", "\n", "        ", "abs_fp", ",", "rel_fp", "=", "self", ".", "_get_video_path", "(", "sample", ")", "\n", "videos", "=", "self", ".", "read_frames_ffmpeg", "(", "abs_fp", ",", "begin", ",", "end", ")", ".", "permute", "(", "1", ",", "0", ",", "2", ",", "3", ")", "\n", "if", "videos", "is", "None", ":", "\n", "            ", "raise", "Exception", "(", "\"Invalid img!\"", ",", "rel_fp", ")", "\n", "", "else", ":", "\n", "            ", "return", "videos", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.howto100m.HT100MDataset.get_video": [[149, 154], ["howto100m.HT100MDataset.get_raw_video().permute().byte", "howto100m.HT100MDataset.video_transform().permute", "howto100m.HT100MDataset.get_raw_video().permute", "howto100m.HT100MDataset.video_transform", "howto100m.HT100MDataset.get_raw_video"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_v2.Ego4DDataset.get_raw_video"], ["", "", "def", "get_video", "(", "self", ",", "sample", ",", "start", ",", "end", ")", ":", "\n", "        ", "videos", "=", "self", ".", "get_raw_video", "(", "sample", ",", "start", ",", "end", ")", "\n", "videos_tensor", "=", "self", ".", "video_aug", "(", "videos", ",", "self", ".", "video_transform", ",", "byte", "=", "True", ")", "\n", "return", "videos_tensor", "\n", "\n", "", "def", "get_false_video", "(", "self", ",", "rep", ")", ":", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.howto100m.HT100MDataset.get_false_video": [[155, 163], ["random.randint", "howto100m.HT100MDataset.get_caption_path", "howto100m.HT100MDataset.get_caption", "howto100m.HT100MDataset.get_raw_video().permute().byte", "howto100m.HT100MDataset.video_transform().permute", "len", "howto100m.HT100MDataset.get_raw_video().permute", "howto100m.HT100MDataset.video_transform", "howto100m.HT100MDataset.get_raw_video"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.datasets.yttemporal.YTTemporalDataset.get_caption_path", "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.yttemporal.YTTemporalDataset.get_caption", "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_v2.Ego4DDataset.get_raw_video"], ["        ", "random_index", "=", "random", ".", "randint", "(", "0", ",", "len", "(", "self", ".", "metadata", ")", "-", "1", ")", "\n", "sample", "=", "self", ".", "metadata", ".", "iloc", "[", "random_index", "]", "\n", "caption_csv", "=", "self", ".", "get_caption_path", "(", "sample", ")", "\n", "_", ",", "start", ",", "end", "=", "self", ".", "get_caption", "(", "caption_csv", ")", "\n", "videos", "=", "self", ".", "get_raw_video", "(", "sample", ",", "start", ",", "end", ")", "\n", "videos_tensor", "=", "self", ".", "video_aug", "(", "videos", ",", "self", ".", "video_transform", ",", "byte", "=", "True", ")", "\n", "return", "{", "f\"false_video_{rep}\"", ":", "videos_tensor", "}", "\n", "\n", "", "def", "get_suite", "(", "self", ",", "index", ")", ":", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.howto100m.HT100MDataset.get_suite": [[164, 193], ["dict", "howto100m.HT100MDataset.get_text", "dict.update", "howto100m.HT100MDataset.get_video", "dict.update", "dict.update", "range", "range", "print", "dict.update", "dict.update", "random.randint", "howto100m.HT100MDataset.get_false_video", "howto100m.HT100MDataset.get_false_text", "len"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_v2.Ego4DDataset.get_text", "home.repos.pwc.inspect_result.showlab_all-in-one.gadgets.my_metrics.VQAScore.update", "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_v2.Ego4DDataset.get_video", "home.repos.pwc.inspect_result.showlab_all-in-one.gadgets.my_metrics.VQAScore.update", "home.repos.pwc.inspect_result.showlab_all-in-one.gadgets.my_metrics.VQAScore.update", "home.repos.pwc.inspect_result.showlab_all-in-one.gadgets.my_metrics.VQAScore.update", "home.repos.pwc.inspect_result.showlab_all-in-one.gadgets.my_metrics.VQAScore.update", "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_v2.Ego4DDataset.get_false_video", "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_v2.Ego4DDataset.get_false_text"], ["        ", "result", "=", "None", "\n", "max_try", "=", "5", "\n", "try_time", "=", "0", "\n", "# while result is None:", "\n", "try_time", "+=", "1", "\n", "sample", "=", "self", ".", "metadata", ".", "iloc", "[", "index", "]", "\n", "# try:", "\n", "ret", "=", "dict", "(", ")", "\n", "text", ",", "start", ",", "end", "=", "self", ".", "get_text", "(", "sample", ")", "\n", "ret", ".", "update", "(", "text", ")", "\n", "videos_tensor", "=", "self", ".", "get_video", "(", "sample", ",", "start", ",", "end", ")", "\n", "ret", ".", "update", "(", "{", "\n", "\"video\"", ":", "videos_tensor", ",", "\n", "\"vid_index\"", ":", "index", ",", "\n", "\"cap_index\"", ":", "index", ",", "\n", "\"raw_index\"", ":", "index", ",", "\n", "}", ")", "\n", "ret", ".", "update", "(", "{", "\"replica\"", ":", "True", "if", "ret", "[", "\"cap_index\"", "]", ">", "0", "else", "False", "}", ")", "\n", "for", "i", "in", "range", "(", "self", ".", "draw_false_video", ")", ":", "\n", "            ", "ret", ".", "update", "(", "self", ".", "get_false_video", "(", "i", ")", ")", "\n", "", "for", "i", "in", "range", "(", "self", ".", "draw_false_text", ")", ":", "\n", "            ", "ret", ".", "update", "(", "self", ".", "get_false_text", "(", "i", ")", ")", "\n", "", "result", "=", "True", "\n", "# except Exception as e:", "\n", "#     print(e)", "\n", "#     index = random.randint(0, len(self.metadata) - 1)", "\n", "# if try_time > max_try:", "\n", "#     print(f\"Exceed max time Error while read file idx {sample} in {self.names[0]}\")", "\n", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.howto100m.HT100MDataset.__len__": [[194, 196], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "metadata", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.howto100m.HT100MDataset.__getitem__": [[197, 199], ["howto100m.HT100MDataset.get_suite"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_v2.Ego4DDataset.get_suite"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "return", "self", ".", "get_suite", "(", "index", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_choice.EGO4DChoiceDataset.__init__": [[7, 29], ["video_base_dataset.BaseDataset.__init__", "ego4d_choice.EGO4DChoiceDataset._load_metadata", "Exception"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.transforms.utils.UnNormalize.__init__", "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_v2.Ego4DDataset._load_metadata"], ["    ", "def", "__init__", "(", "self", ",", "*", "args", ",", "split", "=", "\"\"", ",", "**", "kwargs", ")", ":", "\n", "        ", "assert", "split", "in", "[", "\"train\"", ",", "\"val\"", ",", "\"test\"", "]", "\n", "self", ".", "split", "=", "split", "\n", "if", "self", ".", "split", "==", "\"train\"", ":", "\n", "            ", "Exception", "(", "\"no train data provided\"", ")", "\n", "", "self", ".", "metadata", "=", "None", "\n", "self", ".", "ans_lab_dict", "=", "None", "\n", "if", "split", "==", "\"train\"", ":", "\n", "            ", "names", "=", "[", "\"ego4d_choice_train\"", "]", "\n", "", "elif", "split", "==", "\"val\"", ":", "\n", "            ", "names", "=", "[", "\"ego4d_choice_val\"", "]", "\n", "", "elif", "split", "==", "\"test\"", ":", "\n", "            ", "names", "=", "[", "\"ego4d_choice_test\"", "]", "# vqav2_test-dev for test-dev", "\n", "\n", "", "super", "(", ")", ".", "__init__", "(", "\n", "*", "args", ",", "\n", "**", "kwargs", ",", "\n", "names", "=", "names", ",", "\n", "text_column_name", "=", "\"unknown\"", ",", "\n", "remove_duplicate", "=", "False", ",", "\n", ")", "\n", "self", ".", "_load_metadata", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_choice.EGO4DChoiceDataset._load_metadata": [[30, 39], ["pandas.read_csv", "os.path.join"], "methods", ["None"], ["", "def", "_load_metadata", "(", "self", ")", ":", "\n", "        ", "metadata_dir", "=", "'./meta_data/ego4d'", "\n", "split_files", "=", "{", "\n", "'train'", ":", "'mc_val.csv'", ",", "# no train and test available, only for zero-shot testing", "\n", "'val'", ":", "'mc_val.csv'", ",", "\n", "'test'", ":", "'mc_val.csv'", "\n", "}", "\n", "target_split_fp", "=", "split_files", "[", "self", ".", "split", "]", "\n", "self", ".", "metadata", "=", "pd", ".", "read_csv", "(", "os", ".", "path", ".", "join", "(", "metadata_dir", ",", "target_split_fp", ")", ",", "sep", "=", "','", ",", "header", "=", "0", ",", "error_bad_lines", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_choice.EGO4DChoiceDataset._get_video_path": [[40, 46], ["os.path.join", "os.path.exists", "Exception", "eval"], "methods", ["None"], ["", "def", "_get_video_path", "(", "self", ",", "sample", ")", ":", "\n", "        ", "rel_video_fp", "=", "eval", "(", "sample", "[", "\"question\"", "]", ")", "[", "0", "]", "+", "'.mp4'", "\n", "full_video_fp", "=", "os", ".", "path", ".", "join", "(", "self", ".", "data_dir", ",", "'videos'", ",", "rel_video_fp", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "full_video_fp", ")", ":", "\n", "            ", "Exception", "(", "IOError", ")", "\n", "", "return", "full_video_fp", ",", "rel_video_fp", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_choice.EGO4DChoiceDataset.get_raw_video": [[47, 56], ["ego4d_choice.EGO4DChoiceDataset._get_video_path", "video_base_dataset.get_video_len", "video_base_dataset.read_large_frames_decord", "eval", "Exception"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_v2.Ego4DDataset._get_video_path", "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_v2.Ego4DDataset.get_video_len", "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.video_base_dataset.read_large_frames_decord"], ["", "def", "get_raw_video", "(", "self", ",", "sample", ")", ":", "\n", "        ", "abs_fp", ",", "rel_fp", "=", "self", ".", "_get_video_path", "(", "sample", ")", "\n", "frame_loc", "=", "eval", "(", "sample", "[", "\"question\"", "]", ")", "[", "1", "]", "\n", "frame_end", "=", "get_video_len", "(", "abs_fp", ")", "\n", "imgs", "=", "read_large_frames_decord", "(", "abs_fp", ",", "frame_loc", ",", "frame_end", ",", "self", ".", "num_frames", ",", "mode", "=", "self", ".", "split", ")", "\n", "if", "imgs", "is", "None", ":", "\n", "            ", "raise", "Exception", "(", "\"Invalid video!\"", ",", "rel_fp", ")", "\n", "", "else", ":", "\n", "            ", "return", "imgs", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_choice.EGO4DChoiceDataset.get_text": [[57, 70], ["eval", "ego4d_choice.EGO4DChoiceDataset.tokenizer", "texts.append"], "methods", ["None"], ["", "", "def", "get_text", "(", "self", ",", "sample", ")", ":", "\n", "        ", "texts", "=", "[", "]", "\n", "for", "answer", "in", "eval", "(", "sample", "[", "\"answers\"", "]", ")", ":", "\n", "            ", "text", "=", "answer", "[", "-", "1", "]", "\n", "encoding", "=", "self", ".", "tokenizer", "(", "\n", "text", ",", "\n", "padding", "=", "\"max_length\"", ",", "\n", "truncation", "=", "True", ",", "\n", "max_length", "=", "self", ".", "max_text_len", ",", "\n", "return_special_tokens_mask", "=", "True", ",", "\n", ")", "\n", "texts", ".", "append", "(", "(", "text", ",", "encoding", ")", ")", "\n", "", "return", "texts", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_choice.EGO4DChoiceDataset.get_answer_label": [[71, 78], ["enumerate", "eval", "eval"], "methods", ["None"], ["", "def", "get_answer_label", "(", "self", ",", "sample", ")", ":", "\n", "        ", "gt_text", "=", "eval", "(", "sample", "[", "\"question\"", "]", ")", "[", "-", "1", "]", "\n", "answer_label", "=", "0", "\n", "for", "index", ",", "answer", "in", "enumerate", "(", "eval", "(", "sample", "[", "\"answers\"", "]", ")", ")", ":", "\n", "            ", "if", "answer", "[", "-", "1", "]", "==", "gt_text", ":", "\n", "                ", "answer_label", "=", "index", "\n", "", "", "return", "answer_label", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_choice.EGO4DChoiceDataset.__getitem__": [[79, 99], ["ego4d_choice.EGO4DChoiceDataset.get_video", "ego4d_choice.EGO4DChoiceDataset.get_answer_label", "ego4d_choice.EGO4DChoiceDataset.get_text", "range", "ret.update"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_v2.Ego4DDataset.get_video", "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.msvdqa.MSVDQADataset.get_answer_label", "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_v2.Ego4DDataset.get_text", "home.repos.pwc.inspect_result.showlab_all-in-one.gadgets.my_metrics.VQAScore.update"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "sample", "=", "self", ".", "metadata", ".", "iloc", "[", "index", "]", "\n", "# print(sample)", "\n", "video_tensor", "=", "self", ".", "get_video", "(", "sample", ")", "\n", "# index, question_index = self.index_mapper[index]", "\n", "qid", "=", "index", "\n", "answer", "=", "self", ".", "get_answer_label", "(", "sample", ")", "\n", "ret", "=", "{", "\n", "\"video\"", ":", "video_tensor", ",", "\n", "\"vid_index\"", ":", "index", ",", "\n", "\"cap_index\"", ":", "index", ",", "\n", "\"raw_index\"", ":", "index", ",", "\n", "'answer'", ":", "answer", "\n", "}", "\n", "texts", "=", "self", ".", "get_text", "(", "sample", ")", "\n", "ret", "[", "\"text\"", "]", "=", "texts", "[", "0", "]", "\n", "# print(len(texts))", "\n", "for", "i", "in", "range", "(", "self", ".", "draw_false_text", "-", "1", ")", ":", "\n", "            ", "ret", ".", "update", "(", "{", "f\"false_text_{i}\"", ":", "texts", "[", "i", "+", "1", "]", "}", ")", "\n", "", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_choice.EGO4DChoiceDataset.__len__": [[100, 102], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "metadata", ")", "", "", "", ""]], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.msrvtt_choice.MSRVTTChoiceDataset.__init__": [[7, 29], ["video_base_dataset.BaseDataset.__init__", "msrvtt_choice.MSRVTTChoiceDataset._load_metadata", "Exception"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.transforms.utils.UnNormalize.__init__", "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_v2.Ego4DDataset._load_metadata"], ["    ", "def", "__init__", "(", "self", ",", "*", "args", ",", "split", "=", "\"\"", ",", "**", "kwargs", ")", ":", "\n", "        ", "assert", "split", "in", "[", "\"train\"", ",", "\"val\"", ",", "\"test\"", "]", "\n", "self", ".", "split", "=", "split", "\n", "if", "self", ".", "split", "==", "\"train\"", ":", "\n", "            ", "Exception", "(", "\"no train data provided\"", ")", "\n", "", "self", ".", "metadata", "=", "None", "\n", "self", ".", "ans_lab_dict", "=", "None", "\n", "if", "split", "==", "\"train\"", ":", "\n", "            ", "names", "=", "[", "\"msrvtt_choice_train\"", "]", "\n", "", "elif", "split", "==", "\"val\"", ":", "\n", "            ", "names", "=", "[", "\"msrvtt_choice_val\"", "]", "\n", "", "elif", "split", "==", "\"test\"", ":", "\n", "            ", "names", "=", "[", "\"msrvtt_choice_test\"", "]", "# vqav2_test-dev for test-dev", "\n", "\n", "", "super", "(", ")", ".", "__init__", "(", "\n", "*", "args", ",", "\n", "**", "kwargs", ",", "\n", "names", "=", "names", ",", "\n", "text_column_name", "=", "\"unknown\"", ",", "\n", "remove_duplicate", "=", "False", ",", "\n", ")", "\n", "self", ".", "_load_metadata", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.msrvtt_choice.MSRVTTChoiceDataset._load_metadata": [[30, 40], ["pandas.read_json", "os.path.join"], "methods", ["None"], ["", "def", "_load_metadata", "(", "self", ")", ":", "\n", "        ", "metadata_dir", "=", "'./meta_data/msrvtt'", "\n", "split_files", "=", "{", "\n", "'train'", ":", "'msrvtt_mc_test.jsonl'", ",", "# no train and test available, only for zero-shot", "\n", "'val'", ":", "'msrvtt_mc_test.jsonl'", ",", "\n", "'test'", ":", "'msrvtt_mc_test.jsonl'", "\n", "}", "\n", "target_split_fp", "=", "split_files", "[", "self", ".", "split", "]", "\n", "metadata", "=", "pd", ".", "read_json", "(", "os", ".", "path", ".", "join", "(", "metadata_dir", ",", "target_split_fp", ")", ",", "lines", "=", "True", ")", "\n", "self", ".", "metadata", "=", "metadata", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.msrvtt_choice.MSRVTTChoiceDataset._get_video_path": [[41, 43], ["os.path.join"], "methods", ["None"], ["", "def", "_get_video_path", "(", "self", ",", "sample", ")", ":", "\n", "        ", "return", "os", ".", "path", ".", "join", "(", "self", ".", "data_dir", ",", "'videos'", ",", "'all'", ",", "sample", "[", "'clip_name'", "]", "+", "'.mp4'", ")", ",", "sample", "[", "'clip_name'", "]", "+", "'.mp4'", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.msrvtt_choice.MSRVTTChoiceDataset.get_text": [[44, 56], ["msrvtt_choice.MSRVTTChoiceDataset.tokenizer", "texts.append"], "methods", ["None"], ["", "def", "get_text", "(", "self", ",", "sample", ")", ":", "\n", "        ", "texts", "=", "[", "]", "\n", "for", "text", "in", "sample", "[", "'options'", "]", ":", "\n", "            ", "encoding", "=", "self", ".", "tokenizer", "(", "\n", "text", ",", "\n", "padding", "=", "\"max_length\"", ",", "\n", "truncation", "=", "True", ",", "\n", "max_length", "=", "self", ".", "max_text_len", ",", "\n", "return_special_tokens_mask", "=", "True", ",", "\n", ")", "\n", "texts", ".", "append", "(", "(", "text", ",", "encoding", ")", ")", "\n", "", "return", "texts", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.msrvtt_choice.MSRVTTChoiceDataset.get_answer_label": [[57, 60], ["None"], "methods", ["None"], ["", "def", "get_answer_label", "(", "self", ",", "sample", ")", ":", "\n", "        ", "answer", "=", "sample", "[", "'answer'", "]", "\n", "return", "answer", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.msrvtt_choice.MSRVTTChoiceDataset.__getitem__": [[61, 83], ["msrvtt_choice.MSRVTTChoiceDataset.get_video", "msrvtt_choice.MSRVTTChoiceDataset.get_answer_label", "msrvtt_choice.MSRVTTChoiceDataset.get_text", "range", "ret.update"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_v2.Ego4DDataset.get_video", "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.msvdqa.MSVDQADataset.get_answer_label", "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_v2.Ego4DDataset.get_text", "home.repos.pwc.inspect_result.showlab_all-in-one.gadgets.my_metrics.VQAScore.update"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "sample", "=", "self", ".", "metadata", ".", "iloc", "[", "index", "]", "\n", "video_tensor", "=", "self", ".", "get_video", "(", "sample", ")", "\n", "# index, question_index = self.index_mapper[index]", "\n", "qid", "=", "index", "\n", "answer", "=", "self", ".", "get_answer_label", "(", "sample", ")", "\n", "ret", "=", "{", "\n", "\"video\"", ":", "video_tensor", ",", "\n", "\"vid_index\"", ":", "index", ",", "\n", "\"cap_index\"", ":", "index", ",", "\n", "\"raw_index\"", ":", "index", ",", "\n", "'answer'", ":", "answer", "\n", "}", "\n", "texts", "=", "self", ".", "get_text", "(", "sample", ")", "\n", "ret", "[", "\"text\"", "]", "=", "texts", "[", "0", "]", "\n", "# print(len(texts))", "\n", "for", "i", "in", "range", "(", "self", ".", "draw_false_text", "-", "1", ")", ":", "\n", "            ", "ret", ".", "update", "(", "{", "f\"false_text_{i}\"", ":", "texts", "[", "i", "+", "1", "]", "}", ")", "\n", "# for i in range(self.draw_false_text-1):", "\n", "#     ret[f\"false_text_{i}\"] = texts[i+1]", "\n", "# print(ret.keys())", "\n", "", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.msrvtt_choice.MSRVTTChoiceDataset.__len__": [[84, 86], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "metadata", ")", "", "", "", ""]], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.webvid.WEBVIDDataset.__init__": [[8, 21], ["webvid.WEBVIDDataset._load_metadata", "video_base_dataset.BaseDataset.__init__"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_v2.Ego4DDataset._load_metadata", "home.repos.pwc.inspect_result.showlab_all-in-one.transforms.utils.UnNormalize.__init__"], ["    ", "def", "__init__", "(", "self", ",", "*", "args", ",", "split", "=", "\"\"", ",", "**", "kwargs", ")", ":", "\n", "        ", "assert", "split", "in", "[", "\"train\"", ",", "\"val\"", ",", "\"test\"", "]", "\n", "self", ".", "split", "=", "split", "\n", "self", ".", "metadata", "=", "None", "\n", "self", ".", "cut", "=", "\"jsfusion\"", "\n", "if", "split", "==", "\"train\"", ":", "\n", "            ", "names", "=", "[", "\"webvid_train\"", "]", "\n", "", "elif", "split", "==", "\"val\"", ":", "\n", "            ", "names", "=", "[", "\"webvid_val\"", "]", "\n", "", "elif", "split", "==", "\"test\"", ":", "\n", "            ", "names", "=", "[", "\"webvid_val\"", "]", "\n", "", "self", ".", "_load_metadata", "(", ")", "\n", "\n", "print", "(", "names", ",", "\": \"", ",", "len", "(", "self", ".", "metadata", ")", ",", "\"samples in total.\"", ")", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.webvid.WEBVIDDataset._load_metadata": [[22, 32], ["pandas.read_csv", "os.path.join"], "methods", ["None"], ["super", "(", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ",", "names", "=", "names", ",", "text_column_name", "=", "\"caption\"", ")", "\n", "\n", "", "def", "_load_metadata", "(", "self", ")", ":", "\n", "        ", "metadata_dir", "=", "'./meta_data/webvid'", "\n", "split_files", "=", "{", "\n", "'train'", ":", "'webvid_training_success_full.tsv'", ",", "\n", "'val'", ":", "'webvid_validation_success_full.tsv'", ",", "# there is no test", "\n", "'test'", ":", "'webvid_validation_success_full.tsv'", "\n", "}", "\n", "target_split_fp", "=", "split_files", "[", "self", ".", "split", "]", "\n", "metadata", "=", "pd", ".", "read_csv", "(", "os", ".", "path", ".", "join", "(", "metadata_dir", ",", "target_split_fp", ")", ",", "sep", "=", "'\\t'", ")", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.webvid.WEBVIDDataset._get_video_path": [[33, 37], ["os.path.join"], "methods", ["None"], ["self", ".", "metadata", "=", "metadata", "\n", "\n", "", "def", "_get_video_path", "(", "self", ",", "sample", ")", ":", "\n", "        ", "rel_video_fp", "=", "sample", "[", "1", "]", "+", "'.mp4'", "\n", "full_video_fp", "=", "os", ".", "path", ".", "join", "(", "self", ".", "data_dir", ",", "self", ".", "split", ",", "rel_video_fp", ")", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.webvid.WEBVIDDataset._get_caption": [[38, 40], ["None"], "methods", ["None"], ["return", "full_video_fp", ",", "rel_video_fp", "\n", "\n", "", "def", "_get_caption", "(", "self", ",", "sample", ")", ":", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.webvid.WEBVIDDataset.get_raw_video": [[41, 48], ["webvid.WEBVIDDataset._get_video_path", "video_base_dataset.read_frames_decord", "Exception"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_v2.Ego4DDataset._get_video_path", "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.base_dataset.read_frames_decord"], ["        ", "return", "sample", "[", "0", "]", "\n", "\n", "", "def", "get_raw_video", "(", "self", ",", "sample", ")", ":", "\n", "        ", "abs_fp", ",", "rel_fp", "=", "self", ".", "_get_video_path", "(", "sample", ")", "\n", "videos", ",", "idxs", ",", "vlen", "=", "read_frames_decord", "(", "abs_fp", ",", "self", ".", "num_frames", ",", "mode", "=", "self", ".", "split", ")", "\n", "if", "videos", "is", "None", ":", "\n", "            ", "raise", "Exception", "(", "\"Invalid video!\"", ",", "rel_fp", ")", "\n", "", "else", ":", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.webvid.WEBVIDDataset.get_video": [[49, 57], ["webvid.WEBVIDDataset.get_raw_video().permute", "webvid.WEBVIDDataset.video_transform().permute", "webvid.WEBVIDDataset.get_raw_video", "webvid.WEBVIDDataset.video_transform"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_v2.Ego4DDataset.get_raw_video"], ["            ", "return", "videos", "\n", "\n", "", "", "def", "get_video", "(", "self", ",", "index", ",", "sample", ")", ":", "\n", "        ", "videos", "=", "self", ".", "get_raw_video", "(", "sample", ")", "\n", "videos_tensor", "=", "self", ".", "video_aug", "(", "videos", ",", "self", ".", "video_transform", ")", "\n", "return", "{", "\n", "\"video\"", ":", "videos_tensor", ",", "\n", "\"vid_index\"", ":", "index", ",", "\n", "\"cap_index\"", ":", "index", ",", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.webvid.WEBVIDDataset.get_false_video": [[59, 66], ["random.randint", "webvid.WEBVIDDataset.get_raw_video().permute", "webvid.WEBVIDDataset.video_transform().permute", "len", "webvid.WEBVIDDataset.get_raw_video", "webvid.WEBVIDDataset.video_transform"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_v2.Ego4DDataset.get_raw_video"], ["}", "\n", "\n", "", "def", "get_false_video", "(", "self", ",", "rep", ")", ":", "\n", "        ", "random_index", "=", "random", ".", "randint", "(", "0", ",", "len", "(", "self", ".", "metadata", ")", "-", "1", ")", "\n", "sample", "=", "self", ".", "metadata", ".", "iloc", "[", "random_index", "]", "\n", "# can be different augmentation", "\n", "videos", "=", "self", ".", "get_raw_video", "(", "sample", ")", "\n", "videos_tensor", "=", "self", ".", "video_aug", "(", "videos", ",", "self", ".", "video_transform", ")", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.webvid.WEBVIDDataset.get_text": [[67, 83], ["webvid.WEBVIDDataset.tokenizer"], "methods", ["None"], ["return", "{", "f\"false_video_{rep}\"", ":", "videos_tensor", "}", "\n", "\n", "", "def", "get_text", "(", "self", ",", "raw_index", ",", "sample", ")", ":", "\n", "        ", "text", "=", "sample", "[", "0", "]", "\n", "# print(text)", "\n", "encoding", "=", "self", ".", "tokenizer", "(", "\n", "text", ",", "\n", "padding", "=", "\"max_length\"", ",", "\n", "truncation", "=", "True", ",", "\n", "max_length", "=", "self", ".", "max_text_len", ",", "\n", "return_special_tokens_mask", "=", "True", ",", "\n", ")", "\n", "# print(encoding.size())", "\n", "return", "{", "\n", "\"text\"", ":", "(", "text", ",", "encoding", ")", ",", "\n", "\"vid_index\"", ":", "raw_index", ",", "\n", "\"cap_index\"", ":", "raw_index", ",", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.webvid.WEBVIDDataset.get_false_text": [[85, 97], ["random.randint", "webvid.WEBVIDDataset.tokenizer", "len"], "methods", ["None"], ["}", "\n", "\n", "", "def", "get_false_text", "(", "self", ",", "rep", ")", ":", "\n", "        ", "random_index", "=", "random", ".", "randint", "(", "0", ",", "len", "(", "self", ".", "metadata", ")", "-", "1", ")", "\n", "sample", "=", "self", ".", "metadata", ".", "iloc", "[", "random_index", "]", "\n", "text", "=", "sample", "[", "0", "]", "\n", "encoding", "=", "self", ".", "tokenizer", "(", "\n", "text", ",", "\n", "# padding=\"max_length\",", "\n", "truncation", "=", "True", ",", "\n", "max_length", "=", "self", ".", "max_text_len", ",", "\n", "return_special_tokens_mask", "=", "True", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.webvid.WEBVIDDataset.get_suite": [[98, 119], ["dict", "dict.update", "range", "range", "webvid.WEBVIDDataset.get_video", "webvid.WEBVIDDataset.get_text", "dict.update", "dict.update", "dict.update", "dict.update", "print", "random.randint", "webvid.WEBVIDDataset.get_false_video", "webvid.WEBVIDDataset.get_false_text", "len"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.gadgets.my_metrics.VQAScore.update", "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_v2.Ego4DDataset.get_video", "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_v2.Ego4DDataset.get_text", "home.repos.pwc.inspect_result.showlab_all-in-one.gadgets.my_metrics.VQAScore.update", "home.repos.pwc.inspect_result.showlab_all-in-one.gadgets.my_metrics.VQAScore.update", "home.repos.pwc.inspect_result.showlab_all-in-one.gadgets.my_metrics.VQAScore.update", "home.repos.pwc.inspect_result.showlab_all-in-one.gadgets.my_metrics.VQAScore.update", "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_v2.Ego4DDataset.get_false_video", "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_v2.Ego4DDataset.get_false_text"], ["return", "{", "f\"false_text_{rep}\"", ":", "(", "text", ",", "encoding", ")", "}", "\n", "\n", "", "def", "get_suite", "(", "self", ",", "index", ")", ":", "\n", "        ", "result", "=", "None", "\n", "while", "result", "is", "None", ":", "\n", "            ", "sample", "=", "self", ".", "metadata", ".", "iloc", "[", "index", "]", "\n", "try", ":", "\n", "                ", "ret", "=", "dict", "(", ")", "\n", "ret", ".", "update", "(", "self", ".", "get_video", "(", "index", ",", "sample", ")", ")", "\n", "if", "not", "self", ".", "video_only", ":", "\n", "                    ", "txt", "=", "self", ".", "get_text", "(", "index", ",", "sample", ")", "\n", "ret", ".", "update", "(", "{", "\"replica\"", ":", "True", "if", "txt", "[", "\"cap_index\"", "]", ">", "0", "else", "False", "}", ")", "\n", "ret", ".", "update", "(", "txt", ")", "\n", "\n", "", "for", "i", "in", "range", "(", "self", ".", "draw_false_video", ")", ":", "\n", "                    ", "ret", ".", "update", "(", "self", ".", "get_false_video", "(", "i", ")", ")", "\n", "", "for", "i", "in", "range", "(", "self", ".", "draw_false_text", ")", ":", "\n", "                    ", "ret", ".", "update", "(", "self", ".", "get_false_text", "(", "i", ")", ")", "\n", "", "result", "=", "True", "\n", "", "except", "Exception", "as", "e", ":", "\n", "                ", "print", "(", "f\"Error while read file idx {sample.name} in {self.names[0]} -> {e}\"", ")", "\n", "index", "=", "random", ".", "randint", "(", "0", ",", "len", "(", "self", ".", "metadata", ")", "-", "1", ")", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.webvid.WEBVIDDataset.__len__": [[120, 122], ["len"], "methods", ["None"], ["", "", "return", "ret", "\n", "\n", "", "def", "__len__", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.webvid.WEBVIDDataset.__getitem__": [[123, 125], ["webvid.WEBVIDDataset.get_suite"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_v2.Ego4DDataset.get_suite"], ["        ", "return", "len", "(", "self", ".", "metadata", ")", "\n", "\n", "", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.msvd.MSVDDataset.__init__": [[8, 21], ["msvd.MSVDDataset._load_metadata", "video_base_dataset.BaseDataset.__init__"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_v2.Ego4DDataset._load_metadata", "home.repos.pwc.inspect_result.showlab_all-in-one.transforms.utils.UnNormalize.__init__"], ["    ", "def", "__init__", "(", "self", ",", "*", "args", ",", "split", "=", "\"\"", ",", "**", "kwargs", ")", ":", "\n", "        ", "assert", "split", "in", "[", "\"train\"", ",", "\"val\"", ",", "\"test\"", "]", "\n", "self", ".", "split", "=", "split", "\n", "self", ".", "metadata", "=", "None", "\n", "if", "split", "==", "\"train\"", ":", "\n", "            ", "names", "=", "[", "\"msvd_train\"", "]", "\n", "", "elif", "split", "==", "\"val\"", ":", "\n", "            ", "names", "=", "[", "\"msvd_val\"", "]", "\n", "", "elif", "split", "==", "\"test\"", ":", "\n", "            ", "names", "=", "[", "\"msvd_test\"", "]", "\n", "", "self", ".", "_load_metadata", "(", ")", "\n", "# self.num_frames = kwargs['num_frames']", "\n", "super", "(", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ",", "names", "=", "names", ",", "text_column_name", "=", "\"caption\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.msvd.MSVDDataset._load_metadata": [[22, 33], ["pandas.read_csv", "print", "os.path.join", "len"], "methods", ["None"], ["", "def", "_load_metadata", "(", "self", ")", ":", "\n", "        ", "metadata_dir", "=", "'./meta_data/msvd'", "\n", "split_files", "=", "{", "\n", "'train'", ":", "'MSVD_train.tsv'", ",", "\n", "'val'", ":", "'MSVD_test.tsv'", ",", "# MSVD_val.tsv", "\n", "'test'", ":", "'MSVD_test.tsv'", "\n", "}", "\n", "target_split_fp", "=", "split_files", "[", "self", ".", "split", "]", "\n", "metadata", "=", "pd", ".", "read_csv", "(", "os", ".", "path", ".", "join", "(", "metadata_dir", ",", "target_split_fp", ")", ",", "sep", "=", "'\\t'", ")", "\n", "self", ".", "metadata", "=", "metadata", "\n", "print", "(", "\"load split {}, {} samples\"", ".", "format", "(", "self", ".", "split", ",", "len", "(", "metadata", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.msvd.MSVDDataset._get_video_path": [[34, 38], ["os.path.join"], "methods", ["None"], ["", "def", "_get_video_path", "(", "self", ",", "sample", ")", ":", "\n", "        ", "rel_video_fp", "=", "sample", "[", "1", "]", "+", "'.avi'", "\n", "full_video_fp", "=", "os", ".", "path", ".", "join", "(", "self", ".", "data_dir", ",", "'YouTubeClips'", ",", "rel_video_fp", ")", "\n", "return", "full_video_fp", ",", "rel_video_fp", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.msvd.MSVDDataset._get_caption": [[39, 52], ["sample[].split", "len", "random.randint", "sample[].split", "len", "random.randint"], "methods", ["None"], ["", "def", "_get_caption", "(", "self", ",", "sample", ")", ":", "\n", "        ", "if", "self", ".", "split", "==", "'train'", ":", "\n", "            ", "words", "=", "sample", "[", "0", "]", ".", "split", "(", "','", ")", "\n", "num_word", "=", "len", "(", "words", ")", "\n", "index", "=", "random", ".", "randint", "(", "0", ",", "num_word", "-", "1", ")", "\n", "caption", "=", "words", "[", "index", "]", "\n", "", "else", ":", "\n", "# caption = sample[0]", "\n", "            ", "words", "=", "sample", "[", "0", "]", ".", "split", "(", "','", ")", "\n", "num_word", "=", "len", "(", "words", ")", "\n", "index", "=", "random", ".", "randint", "(", "0", ",", "num_word", "-", "1", ")", "\n", "caption", "=", "words", "[", "index", "]", "\n", "", "return", "caption", "\n", "", "", ""]], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.tgifqa.TGIFQADataset.__init__": [[16, 36], ["tgifqa.TGIFQADataset._load_metadata", "video_base_dataset.BaseDataset.__init__"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_v2.Ego4DDataset._load_metadata", "home.repos.pwc.inspect_result.showlab_all-in-one.transforms.utils.UnNormalize.__init__"], ["    ", "def", "__init__", "(", "self", ",", "*", "args", ",", "split", "=", "\"\"", ",", "**", "kwargs", ")", ":", "\n", "        ", "assert", "split", "in", "[", "\"train\"", ",", "\"val\"", ",", "\"test\"", "]", "\n", "self", ".", "split", "=", "split", "\n", "self", ".", "data_split", "=", "\"action\"", "# transition/action", "\n", "self", ".", "metadata", "=", "None", "\n", "self", ".", "_load_metadata", "(", ")", "\n", "if", "split", "==", "\"train\"", ":", "\n", "            ", "names", "=", "[", "\"tgifqa_train\"", "]", "\n", "", "elif", "split", "==", "\"val\"", ":", "\n", "            ", "names", "=", "[", "\"tgifqa_val\"", "]", "\n", "", "elif", "split", "==", "\"test\"", ":", "\n", "            ", "names", "=", "[", "\"tgifqa_test\"", "]", "\n", "\n", "", "super", "(", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ",", "names", "=", "names", ",", "text_column_name", "=", "\"caption\"", ")", "\n", "# for appear objects", "\n", "self", ".", "only_use_relevant_dets", "=", "True", "\n", "if", "self", ".", "only_use_relevant_dets", ":", "\n", "            ", "self", ".", "relevant_dets", "=", "[", "]", "# resort the detection numbers", "\n", "self", ".", "relevant_dets_classes", "=", "[", "]", "\n", "", "self", ".", "fps", "=", "3", "# tgif sample 3 frames per second", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.tgifqa.TGIFQADataset._load_metadata": [[37, 57], ["pandas.read_json", "os.path.join", "Exception"], "methods", ["None"], ["", "def", "_load_metadata", "(", "self", ")", ":", "\n", "# download specific", "\n", "        ", "metadata_dir", "=", "'./meta_data/tgif'", "\n", "if", "self", ".", "data_split", "==", "\"action\"", ":", "\n", "            ", "split_files", "=", "{", "\n", "'train'", ":", "'action_train.jsonl'", ",", "\n", "'val'", ":", "'action_test.jsonl'", ",", "# action_val.jsonl", "\n", "'test'", ":", "'action_test.jsonl'", "# no GT label for test set", "\n", "}", "\n", "", "elif", "self", ".", "data_split", "==", "\"transition\"", ":", "\n", "            ", "split_files", "=", "{", "\n", "'train'", ":", "'transition_train.jsonl'", ",", "\n", "'val'", ":", "'transition_test.jsonl'", ",", "# transition_val.jsonl", "\n", "'test'", ":", "'transition_test.jsonl'", "# no GT label for test set", "\n", "}", "\n", "", "else", ":", "\n", "            ", "Exception", "(", "\"not support split\"", ")", "\n", "", "target_split_fp", "=", "split_files", "[", "self", ".", "split", "]", "\n", "metadata", "=", "pd", ".", "read_json", "(", "os", ".", "path", ".", "join", "(", "metadata_dir", ",", "target_split_fp", ")", ",", "lines", "=", "True", ")", "\n", "self", ".", "metadata", "=", "metadata", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.tgifqa.TGIFQADataset._get_image_path": [[58, 65], ["os.path.join", "sample[].split", "os.path.join"], "methods", ["None"], ["", "def", "_get_image_path", "(", "self", ",", "sample", ")", ":", "\n", "# for example: tvqa/frames/raw_frames/frames_hq/met_frames/met_s06e22_seg01_clip_02", "\n", "        ", "dir_name", "=", "sample", "[", "'vid_name'", "]", ".", "split", "(", "'_'", ")", "[", "0", "]", "\n", "if", "dir_name", "not", "in", "[", "'bbt'", ",", "'castle'", ",", "'friends'", ",", "'grey'", ",", "'house'", ",", "'met'", "]", ":", "\n", "            ", "dir_name", "=", "'bbt'", "\n", "", "rel_fp", "=", "os", ".", "path", ".", "join", "(", "'frames/raw_frames/frames_hq/'", ",", "dir_name", "+", "'_frames'", ",", "sample", "[", "'vid_name'", "]", ")", "\n", "return", "os", ".", "path", ".", "join", "(", "self", ".", "data_dir", ",", "rel_fp", ")", ",", "rel_fp", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.tgifqa.TGIFQADataset._get_caption": [[66, 68], ["None"], "methods", ["None"], ["", "def", "_get_caption", "(", "self", ",", "sample", ")", ":", "\n", "        ", "return", "sample", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.tgifqa.TGIFQADataset._get_video_path": [[69, 71], ["os.path.join"], "methods", ["None"], ["", "def", "_get_video_path", "(", "self", ",", "sample", ")", ":", "\n", "        ", "return", "os", ".", "path", ".", "join", "(", "self", ".", "data_dir", ",", "'gifs'", ",", "sample", "[", "'gif_name'", "]", ")", "+", "'.gif'", ",", "sample", "[", "'gif_name'", "]", "+", "'.gif'", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.tgifqa.TGIFQADataset.get_raw_video": [[72, 79], ["tgifqa.TGIFQADataset._get_video_path", "video_base_dataset.read_frames_gif", "Exception"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_v2.Ego4DDataset._get_video_path", "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.video_base_dataset.read_frames_gif"], ["", "def", "get_raw_video", "(", "self", ",", "sample", ")", ":", "\n", "        ", "abs_fp", ",", "rel_fp", "=", "self", ".", "_get_video_path", "(", "sample", ")", "\n", "imgs", ",", "idxs", ",", "vlen", "=", "read_frames_gif", "(", "abs_fp", ",", "self", ".", "num_frames", ",", "mode", "=", "self", ".", "split", ")", "\n", "if", "imgs", "is", "None", ":", "\n", "            ", "raise", "Exception", "(", "\"Invalid img!\"", ",", "rel_fp", ")", "\n", "", "else", ":", "\n", "            ", "return", "imgs", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.tgifqa.TGIFQADataset.get_text": [[80, 98], ["tgifqa.TGIFQADataset.get_question", "range", "tgifqa.TGIFQADataset.tokenizer", "qa_texts.append", "range"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.datasets.vcr.VCRDataset.get_question"], ["", "", "def", "get_text", "(", "self", ",", "sample", ")", ":", "\n", "        ", "question", "=", "self", ".", "get_question", "(", "sample", ")", "\n", "qa_texts", "=", "[", "]", "\n", "# 5 choices # ClipBERT: \" \", Ours: [SEP]", "\n", "options", "=", "\" \"", ".", "join", "(", "sample", "[", "\"options\"", "]", "[", "i", "]", "for", "i", "in", "range", "(", "5", ")", ")", "\n", "for", "i", "in", "range", "(", "5", ")", ":", "\n", "            ", "raw_text", "=", "question", "+", "\"Options: \"", "+", "options", "+", "\"Answer: \"", "+", "sample", "[", "\"options\"", "]", "[", "i", "]", "\n", "# raw_text = question + \"[SEP]\" + sample[\"options\"][i]", "\n", "# print(raw_text)", "\n", "qa_encoding", "=", "self", ".", "tokenizer", "(", "\n", "raw_text", ",", "\n", "padding", "=", "\"max_length\"", ",", "\n", "truncation", "=", "True", ",", "\n", "max_length", "=", "self", ".", "max_text_len", ",", "\n", "return_special_tokens_mask", "=", "True", ",", "\n", ")", "\n", "qa_texts", ".", "append", "(", "(", "raw_text", ",", "qa_encoding", ")", ")", "\n", "", "return", "qa_texts", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.tgifqa.TGIFQADataset.get_answer_label": [[99, 102], ["int"], "methods", ["None"], ["", "def", "get_answer_label", "(", "self", ",", "sample", ")", ":", "\n", "        ", "answer", "=", "int", "(", "sample", "[", "'answer'", "]", ")", "\n", "return", "answer", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.tgifqa.TGIFQADataset.get_question": [[103, 105], ["None"], "methods", ["None"], ["", "def", "get_question", "(", "self", ",", "sample", ")", ":", "\n", "        ", "return", "sample", "[", "\"question\"", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.tgifqa.TGIFQADataset.__len__": [[106, 108], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "metadata", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.tgifqa.TGIFQADataset.__getitem__": [[109, 135], ["tgifqa.TGIFQADataset.get_answer_label", "tgifqa.TGIFQADataset.get_text", "range", "tgifqa.TGIFQADataset.get_video", "ret.update", "print", "print", "random.randint", "len"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.datasets.msvdqa.MSVDQADataset.get_answer_label", "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_v2.Ego4DDataset.get_text", "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_v2.Ego4DDataset.get_video", "home.repos.pwc.inspect_result.showlab_all-in-one.gadgets.my_metrics.VQAScore.update"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "result", "=", "None", "\n", "while", "result", "is", "None", ":", "\n", "            ", "sample", "=", "self", ".", "metadata", ".", "iloc", "[", "index", "]", "\n", "try", ":", "\n", "                ", "self", ".", "relevant_dets", "=", "[", "]", "# initalize", "\n", "self", ".", "relevant_dets_classes", "=", "[", "]", "\n", "answer", "=", "self", ".", "get_answer_label", "(", "sample", ")", "\n", "ret", "=", "{", "\n", "\"vid_index\"", ":", "index", ",", "\n", "\"cap_index\"", ":", "index", ",", "\n", "\"raw_index\"", ":", "index", ",", "\n", "'answer'", ":", "answer", "\n", "}", "\n", "qa_texts", "=", "self", ".", "get_text", "(", "sample", ")", "\n", "ret", "[", "\"text\"", "]", "=", "qa_texts", "[", "0", "]", "\n", "for", "i", "in", "range", "(", "self", ".", "draw_options_text", "-", "1", ")", ":", "\n", "                    ", "ret", ".", "update", "(", "{", "f\"options_text_{i}\"", ":", "qa_texts", "[", "i", "+", "1", "]", "}", ")", "\n", "", "video_tensor", "=", "self", ".", "get_video", "(", "sample", ")", "\n", "ret", "[", "\"image\"", "]", "=", "video_tensor", "\n", "result", "=", "True", "\n", "", "except", "Exception", "as", "e", ":", "\n", "                ", "print", "(", "f\"Error while read file idx {sample.name} in {self.names[0]} -> {e}\"", ")", "\n", "print", "(", "\"time stamp is: {}\"", ".", "format", "(", "sample", "[", "'ts'", "]", ")", ")", "\n", "index", "=", "random", ".", "randint", "(", "0", ",", "len", "(", "self", ".", "metadata", ")", "-", "1", ")", "\n", "", "", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.didemo.DIDEMODataset.__init__": [[9, 21], ["video_base_dataset.BaseDataset.__init__", "didemo.DIDEMODataset._load_metadata"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.transforms.utils.UnNormalize.__init__", "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_v2.Ego4DDataset._load_metadata"], ["    ", "def", "__init__", "(", "self", ",", "*", "args", ",", "split", "=", "\"\"", ",", "**", "kwargs", ")", ":", "\n", "        ", "assert", "split", "in", "[", "\"train\"", ",", "\"val\"", ",", "\"test\"", "]", "\n", "self", ".", "split", "=", "split", "\n", "self", ".", "metadata", "=", "None", "\n", "if", "split", "==", "\"train\"", ":", "\n", "            ", "names", "=", "[", "\"didemo_train\"", "]", "\n", "", "elif", "split", "==", "\"val\"", ":", "\n", "            ", "names", "=", "[", "\"didemo_val\"", "]", "\n", "", "elif", "split", "==", "\"test\"", ":", "\n", "            ", "names", "=", "[", "\"didemo_val\"", "]", "\n", "", "super", "(", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ",", "names", "=", "names", ",", "text_column_name", "=", "\"caption\"", ")", "\n", "self", ".", "_load_metadata", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.didemo.DIDEMODataset._load_metadata": [[22, 33], ["pandas.read_csv", "print", "os.path.join", "len"], "methods", ["None"], ["", "def", "_load_metadata", "(", "self", ")", ":", "\n", "        ", "metadata_dir", "=", "'./meta_data/didemo'", "\n", "split_files", "=", "{", "\n", "'train'", ":", "'DiDeMo_train.tsv'", ",", "\n", "'val'", ":", "'DiDeMo_val.tsv'", ",", "# there is no test", "\n", "'test'", ":", "'DiDeMo_test.tsv'", "\n", "}", "\n", "target_split_fp", "=", "split_files", "[", "self", ".", "split", "]", "\n", "metadata", "=", "pd", ".", "read_csv", "(", "os", ".", "path", ".", "join", "(", "metadata_dir", ",", "target_split_fp", ")", ",", "sep", "=", "'\\t'", ")", "\n", "self", ".", "metadata", "=", "metadata", "\n", "print", "(", "\"load split {}, {} samples\"", ".", "format", "(", "self", ".", "split", ",", "len", "(", "metadata", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.didemo.DIDEMODataset._get_video_path": [[34, 38], ["os.path.join"], "methods", ["None"], ["", "def", "_get_video_path", "(", "self", ",", "sample", ")", ":", "\n", "        ", "rel_video_fp", "=", "sample", "[", "1", "]", "\n", "full_video_fp", "=", "os", ".", "path", ".", "join", "(", "self", ".", "data_dir", ",", "''", ",", "rel_video_fp", ")", "\n", "return", "full_video_fp", ",", "rel_video_fp", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.didemo.DIDEMODataset._get_caption": [[39, 41], ["None"], "methods", ["None"], ["", "def", "_get_caption", "(", "self", ",", "sample", ")", ":", "\n", "        ", "return", "sample", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.hmdb51.HMDB51Dataset.__init__": [[7, 26], ["dict", "video_base_dataset.BaseDataset.__init__", "hmdb51.HMDB51Dataset._load_metadata"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.transforms.utils.UnNormalize.__init__", "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_v2.Ego4DDataset._load_metadata"], ["    ", "def", "__init__", "(", "self", ",", "*", "args", ",", "split", "=", "\"\"", ",", "**", "kwargs", ")", ":", "\n", "        ", "assert", "split", "in", "[", "\"train\"", ",", "\"val\"", ",", "\"test\"", "]", "\n", "self", ".", "split", "=", "split", "\n", "self", ".", "metadata", "=", "None", "\n", "self", ".", "ans_lab_dict", "=", "dict", "(", ")", "\n", "if", "split", "==", "\"train\"", ":", "\n", "            ", "names", "=", "[", "\"hmdb51_train\"", "]", "\n", "", "elif", "split", "==", "\"val\"", ":", "\n", "            ", "names", "=", "[", "\"hmdb51_val\"", "]", "\n", "", "elif", "split", "==", "\"test\"", ":", "\n", "            ", "names", "=", "[", "\"hmdb51_test\"", "]", "\n", "", "super", "(", ")", ".", "__init__", "(", "\n", "*", "args", ",", "\n", "**", "kwargs", ",", "\n", "names", "=", "names", ",", "\n", "text_column_name", "=", "\"questions\"", ",", "\n", "remove_duplicate", "=", "False", ",", "\n", ")", "\n", "self", ".", "_load_metadata", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.hmdb51.HMDB51Dataset._load_metadata": [[27, 41], ["os.path.join", "x.strip().split", "open", "f.readlines", "open", "x.strip", "os.path.join", "line.strip().split", "str", "line.strip", "int", "line.strip().split", "line.strip"], "methods", ["None"], ["", "def", "_load_metadata", "(", "self", ")", ":", "\n", "        ", "metadata_dir", "=", "'./meta_data/hmdb51'", "\n", "split_files", "=", "{", "\n", "'train'", ":", "'hmdb51_rgb_train_split_1.txt'", ",", "\n", "'val'", ":", "'hmdb51_rgb_val_split_1.txt'", ",", "\n", "'test'", ":", "'hmdb51_rgb_val_split_1.txt'", "\n", "}", "\n", "target_split_fp", "=", "split_files", "[", "self", ".", "split", "]", "\n", "self", ".", "metadata", "=", "[", "x", ".", "strip", "(", ")", ".", "split", "(", "' '", ")", "for", "x", "in", "open", "(", "os", ".", "path", ".", "join", "(", "metadata_dir", ",", "target_split_fp", ")", ")", "]", "\n", "answer_fp", "=", "os", ".", "path", ".", "join", "(", "metadata_dir", ",", "'hmdb51_classInd.txt'", ")", "\n", "with", "open", "(", "answer_fp", ",", "'r'", ")", "as", "f", ":", "\n", "            ", "lines", "=", "f", ".", "readlines", "(", ")", "\n", "for", "line", "in", "lines", ":", "\n", "                ", "self", ".", "ans_lab_dict", "[", "str", "(", "int", "(", "line", ".", "strip", "(", ")", ".", "split", "(", "' '", ")", "[", "0", "]", ")", "-", "1", ")", "]", "=", "line", ".", "strip", "(", ")", ".", "split", "(", "' '", ")", "[", "1", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.hmdb51.HMDB51Dataset._get_video_path": [[42, 45], ["os.path.join", "sample[].split", "sample[].split"], "methods", ["None"], ["", "", "", "def", "_get_video_path", "(", "self", ",", "sample", ")", ":", "\n", "# self.ans_lab_dict[sample[2]],", "\n", "        ", "return", "os", ".", "path", ".", "join", "(", "self", ".", "data_dir", ",", "sample", "[", "0", "]", ".", "split", "(", "'/'", ")", "[", "-", "1", "]", ")", "+", "'.avi'", ",", "sample", "[", "0", "]", ".", "split", "(", "'/'", ")", "[", "-", "1", "]", "+", "'.avi'", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.hmdb51.HMDB51Dataset.get_text": [[46, 56], ["hmdb51.HMDB51Dataset.tokenizer"], "methods", ["None"], ["", "def", "get_text", "(", "self", ",", "sample", ")", ":", "\n", "        ", "text", "=", "\"A person is doing [MASK]\"", "\n", "encoding", "=", "self", ".", "tokenizer", "(", "\n", "text", ",", "\n", "padding", "=", "\"max_length\"", ",", "\n", "truncation", "=", "True", ",", "\n", "max_length", "=", "self", ".", "max_text_len", ",", "\n", "return_special_tokens_mask", "=", "True", ",", "\n", ")", "\n", "return", "(", "text", ",", "encoding", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.hmdb51.HMDB51Dataset.get_answer_label": [[57, 64], ["int", "numpy.zeros().astype", "len", "numpy.zeros"], "methods", ["None"], ["", "def", "get_answer_label", "(", "self", ",", "sample", ")", ":", "\n", "        ", "text", "=", "\"None\"", "\n", "ans_total_len", "=", "len", "(", "self", ".", "ans_lab_dict", ")", "+", "1", "# one additional class", "\n", "ans_label", "=", "int", "(", "sample", "[", "2", "]", ")", "\n", "scores", "=", "np", ".", "zeros", "(", "ans_total_len", ")", ".", "astype", "(", "int", ")", "\n", "scores", "[", "ans_label", "]", "=", "1", "\n", "return", "text", ",", "ans_label", ",", "scores", "\n", "# return text, ans_label_vector, scores", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.hmdb51.HMDB51Dataset.__getitem__": [[66, 85], ["hmdb51.HMDB51Dataset.get_video", "hmdb51.HMDB51Dataset.get_text", "hmdb51.HMDB51Dataset.get_answer_label", "list", "list", "list"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_v2.Ego4DDataset.get_video", "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_v2.Ego4DDataset.get_text", "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.msvdqa.MSVDQADataset.get_answer_label"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "sample", "=", "self", ".", "metadata", "[", "index", "]", "# .split(' ')", "\n", "video_tensor", "=", "self", ".", "get_video", "(", "sample", ")", "\n", "text", "=", "self", ".", "get_text", "(", "sample", ")", "\n", "qid", "=", "index", "\n", "if", "self", ".", "split", "!=", "\"test\"", ":", "\n", "            ", "answers", ",", "labels", ",", "scores", "=", "self", ".", "get_answer_label", "(", "sample", ")", "\n", "", "else", ":", "\n", "            ", "answers", "=", "list", "(", ")", "\n", "labels", "=", "list", "(", ")", "\n", "scores", "=", "list", "(", ")", "\n", "\n", "", "return", "{", "\n", "\"video\"", ":", "video_tensor", ",", "\n", "\"text\"", ":", "text", ",", "\n", "\"vqa_answer\"", ":", "answers", ",", "\n", "\"vqa_labels\"", ":", "labels", ",", "\n", "\"vqa_scores\"", ":", "scores", ",", "\n", "\"qid\"", ":", "qid", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.hmdb51.HMDB51Dataset.__len__": [[87, 89], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "metadata", ")", "", "", "", ""]], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.tvqa.TVQADataset.__init__": [[26, 45], ["tvqa.TVQADataset._load_metadata", "video_base_dataset.BaseDataset.__init__"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_v2.Ego4DDataset._load_metadata", "home.repos.pwc.inspect_result.showlab_all-in-one.transforms.utils.UnNormalize.__init__"], ["    ", "def", "__init__", "(", "self", ",", "*", "args", ",", "split", "=", "\"\"", ",", "**", "kwargs", ")", ":", "\n", "        ", "assert", "split", "in", "[", "\"train\"", ",", "\"val\"", ",", "\"test\"", "]", "\n", "self", ".", "split", "=", "split", "\n", "self", ".", "metadata", "=", "None", "\n", "self", ".", "_load_metadata", "(", ")", "\n", "if", "split", "==", "\"train\"", ":", "\n", "            ", "names", "=", "[", "\"tvqa_train\"", "]", "\n", "", "elif", "split", "==", "\"val\"", ":", "\n", "            ", "names", "=", "[", "\"tvqa_val\"", "]", "\n", "", "elif", "split", "==", "\"test\"", ":", "\n", "            ", "names", "=", "[", "\"tvqa_test\"", "]", "\n", "\n", "", "super", "(", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ",", "names", "=", "names", ",", "text_column_name", "=", "\"caption\"", ")", "\n", "# for appear objects", "\n", "self", ".", "only_use_relevant_dets", "=", "True", "\n", "if", "self", ".", "only_use_relevant_dets", ":", "\n", "            ", "self", ".", "relevant_dets", "=", "[", "]", "# resort the detection numbers", "\n", "self", ".", "relevant_dets_classes", "=", "[", "]", "\n", "", "self", ".", "fps", "=", "3", "# tvqa sample 3 frames per second", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.tvqa.TVQADataset._load_metadata": [[46, 57], ["pandas.read_json", "os.path.join"], "methods", ["None"], ["", "def", "_load_metadata", "(", "self", ")", ":", "\n", "# download specific", "\n", "        ", "metadata_dir", "=", "'./meta_data/tvqa'", "\n", "split_files", "=", "{", "\n", "'train'", ":", "'tvqa_train.jsonl'", ",", "\n", "'val'", ":", "'tvqa_val.jsonl'", ",", "\n", "'test'", ":", "'tvqa_test_public.jsonl'", "# no GT label for test set", "\n", "}", "\n", "target_split_fp", "=", "split_files", "[", "self", ".", "split", "]", "\n", "metadata", "=", "pd", ".", "read_json", "(", "os", ".", "path", ".", "join", "(", "metadata_dir", ",", "target_split_fp", ")", ",", "lines", "=", "True", ")", "\n", "self", ".", "metadata", "=", "metadata", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.tvqa.TVQADataset._get_image_path": [[58, 65], ["os.path.join", "sample[].split", "os.path.join"], "methods", ["None"], ["", "def", "_get_image_path", "(", "self", ",", "sample", ")", ":", "\n", "# for example: tvqa/frames/raw_frames/frames_hq/met_frames/met_s06e22_seg01_clip_02", "\n", "        ", "dir_name", "=", "sample", "[", "'vid_name'", "]", ".", "split", "(", "'_'", ")", "[", "0", "]", "\n", "if", "dir_name", "not", "in", "[", "'bbt'", ",", "'castle'", ",", "'friends'", ",", "'grey'", ",", "'house'", ",", "'met'", "]", ":", "\n", "            ", "dir_name", "=", "'bbt'", "\n", "", "rel_fp", "=", "os", ".", "path", ".", "join", "(", "'frames/raw_frames/frames_hq/'", ",", "dir_name", "+", "'_frames'", ",", "sample", "[", "'vid_name'", "]", ")", "\n", "return", "os", ".", "path", ".", "join", "(", "self", ".", "data_dir", ",", "rel_fp", ")", ",", "rel_fp", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.tvqa.TVQADataset._get_caption": [[66, 68], ["None"], "methods", ["None"], ["", "def", "_get_caption", "(", "self", ",", "sample", ")", ":", "\n", "        ", "return", "sample", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.tvqa.TVQADataset._get_video_len": [[70, 72], ["len", "os.listdir"], "methods", ["None"], ["", "def", "_get_video_len", "(", "self", ",", "dir", ")", ":", "\n", "        ", "return", "len", "(", "os", ".", "listdir", "(", "dir", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.tvqa.TVQADataset.get_raw_video": [[74, 104], ["tvqa.TVQADataset._get_image_path", "sample[].split", "int", "max", "AllInOne.datasets.video_base_dataset.sample_frames", "max", "tvqa.TVQADataset._get_video_len", "torch.stack().permute", "int", "min", "cv2.imread", "torch.from_numpy().byte", "frame.permute.permute.permute", "torch.stack().permute.append", "os.path.join", "print", "print", "torch.stack", "float", "float", "float", "os.path.join", "torch.from_numpy"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.datasets.vcr.VCRDataset._get_image_path", "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.base_dataset.sample_frames", "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.tvqa.TVQADataset._get_video_len"], ["", "def", "get_raw_video", "(", "self", ",", "sample", ")", ":", "\n", "        ", "abs_fp", ",", "rel_fp", "=", "self", ".", "_get_image_path", "(", "sample", ")", "\n", "[", "beg_time", ",", "end_time", "]", "=", "sample", "[", "'ts'", "]", ".", "split", "(", "'-'", ")", "\n", "clip_len", "=", "int", "(", "(", "float", "(", "end_time", ")", "-", "float", "(", "beg_time", ")", ")", "*", "self", ".", "fps", ")", "\n", "# try:", "\n", "#     clip_len = int((float(end_time) - float(beg_time)) * self.fps)", "\n", "# except ValueError:", "\n", "#     clip_len = 1", "\n", "# prevent short than 1 second", "\n", "clip_len", "=", "max", "(", "clip_len", ",", "2", "*", "self", ".", "num_frames", ")", "\n", "rel_frame_index", "=", "sample_frames", "(", "self", ".", "num_frames", ",", "clip_len", ")", "\n", "begin_frame_index", "=", "max", "(", "1", ",", "int", "(", "float", "(", "beg_time", ")", "*", "self", ".", "fps", ")", ")", "\n", "video_len", "=", "self", ".", "_get_video_len", "(", "abs_fp", ")", "\n", "# sample N frames here", "\n", "frames", "=", "[", "]", "\n", "for", "index", "in", "rel_frame_index", ":", "\n", "            ", "abs_index", "=", "begin_frame_index", "+", "index", "\n", "abs_index", "=", "min", "(", "video_len", ",", "abs_index", ")", "\n", "image_rel_path", "=", "f'{abs_index:05}'", "\n", "img", "=", "cv2", ".", "imread", "(", "os", ".", "path", ".", "join", "(", "abs_fp", ",", "'{}.jpg'", ".", "format", "(", "image_rel_path", ")", ")", ")", "\n", "# print(img)", "\n", "# print(os.path.join(abs_fp, '{}.jpg'.format(image_rel_path)))", "\n", "if", "img", "is", "None", ":", "\n", "                ", "print", "(", "sample", "[", "'vid_name'", "]", ")", "\n", "print", "(", "os", ".", "path", ".", "join", "(", "abs_fp", ",", "'{}.jpg'", ".", "format", "(", "image_rel_path", ")", ")", ")", "\n", "", "frame", "=", "torch", ".", "from_numpy", "(", "img", ")", ".", "byte", "(", ")", "\n", "frame", "=", "frame", ".", "permute", "(", "2", ",", "0", ",", "1", ")", "\n", "frames", ".", "append", "(", "frame", ")", "\n", "", "frames", "=", "torch", ".", "stack", "(", "frames", ")", ".", "permute", "(", "1", ",", "0", ",", "2", ",", "3", ")", "\n", "return", "frames", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.tvqa.TVQADataset.get_text": [[105, 124], ["tvqa.TVQADataset.get_question", "range", "tvqa.TVQADataset.tokenizer", "qa_texts.append", "range"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.datasets.vcr.VCRDataset.get_question"], ["", "def", "get_text", "(", "self", ",", "sample", ")", ":", "\n", "        ", "question", "=", "self", ".", "get_question", "(", "sample", ")", "\n", "qa_texts", "=", "[", "]", "\n", "# 5 choices # ClipBERT: \" \", Ours: [SEP]", "\n", "# if the length suppress than 40 ?", "\n", "options", "=", "\" \"", ".", "join", "(", "sample", "[", "\"a{}\"", ".", "format", "(", "i", ")", "]", "for", "i", "in", "range", "(", "5", ")", ")", "\n", "for", "i", "in", "range", "(", "5", ")", ":", "\n", "            ", "raw_text", "=", "question", "+", "\"Options: \"", "+", "options", "+", "\"Answer: \"", "+", "sample", "[", "\"a{}\"", ".", "format", "(", "i", ")", "]", "\n", "# raw_text = question + \"[SEP]\" + sample[\"a{}\".format(i)]", "\n", "# print(raw_text)", "\n", "qa_encoding", "=", "self", ".", "tokenizer", "(", "\n", "raw_text", ",", "\n", "padding", "=", "\"max_length\"", ",", "\n", "truncation", "=", "True", ",", "\n", "max_length", "=", "self", ".", "max_text_len", ",", "\n", "return_special_tokens_mask", "=", "True", ",", "\n", ")", "\n", "qa_texts", ".", "append", "(", "(", "raw_text", ",", "qa_encoding", ")", ")", "\n", "", "return", "qa_texts", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.tvqa.TVQADataset.get_answer_label": [[125, 128], ["int"], "methods", ["None"], ["", "def", "get_answer_label", "(", "self", ",", "sample", ")", ":", "\n", "        ", "answer", "=", "int", "(", "sample", "[", "'answer_idx'", "]", ")", "\n", "return", "answer", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.tvqa.TVQADataset.get_question": [[129, 131], ["None"], "methods", ["None"], ["", "def", "get_question", "(", "self", ",", "sample", ")", ":", "\n", "        ", "return", "sample", "[", "\"q\"", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.tvqa.TVQADataset.__len__": [[132, 134], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "metadata", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.tvqa.TVQADataset.__getitem__": [[135, 161], ["tvqa.TVQADataset.get_answer_label", "tvqa.TVQADataset.get_text", "range", "tvqa.TVQADataset.get_video", "ret.update", "print", "print", "random.randint", "len"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.datasets.msvdqa.MSVDQADataset.get_answer_label", "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_v2.Ego4DDataset.get_text", "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_v2.Ego4DDataset.get_video", "home.repos.pwc.inspect_result.showlab_all-in-one.gadgets.my_metrics.VQAScore.update"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "result", "=", "None", "\n", "while", "result", "is", "None", ":", "\n", "            ", "sample", "=", "self", ".", "metadata", ".", "iloc", "[", "index", "]", "\n", "try", ":", "\n", "                ", "self", ".", "relevant_dets", "=", "[", "]", "# initalize", "\n", "self", ".", "relevant_dets_classes", "=", "[", "]", "\n", "answer", "=", "self", ".", "get_answer_label", "(", "sample", ")", "\n", "ret", "=", "{", "\n", "\"vid_index\"", ":", "index", ",", "\n", "\"cap_index\"", ":", "index", ",", "\n", "\"raw_index\"", ":", "index", ",", "\n", "'answer'", ":", "answer", "\n", "}", "\n", "qa_texts", "=", "self", ".", "get_text", "(", "sample", ")", "\n", "ret", "[", "\"text\"", "]", "=", "qa_texts", "[", "0", "]", "\n", "for", "i", "in", "range", "(", "self", ".", "draw_options_text", "-", "1", ")", ":", "\n", "                    ", "ret", ".", "update", "(", "{", "f\"options_text_{i}\"", ":", "qa_texts", "[", "i", "+", "1", "]", "}", ")", "\n", "", "video_tensor", "=", "self", ".", "get_video", "(", "sample", ")", "\n", "ret", "[", "\"image\"", "]", "=", "video_tensor", "\n", "result", "=", "True", "\n", "", "except", "Exception", "as", "e", ":", "\n", "                ", "print", "(", "f\"Error while read file idx {sample.name} in {self.names[0]} -> {e}\"", ")", "\n", "print", "(", "\"time stamp is: {}\"", ".", "format", "(", "sample", "[", "'ts'", "]", ")", ")", "\n", "index", "=", "random", ".", "randint", "(", "0", ",", "len", "(", "self", ".", "metadata", ")", "-", "1", ")", "\n", "", "", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.k400.K400Dataset.__init__": [[10, 30], ["dict", "video_base_dataset.BaseDataset.__init__", "AllInOne.transforms.videoaug.VideoTransform", "k400.K400Dataset._load_metadata"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.transforms.utils.UnNormalize.__init__", "home.repos.pwc.inspect_result.showlab_all-in-one.transforms.videoaug.VideoTransform", "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_v2.Ego4DDataset._load_metadata"], ["        ", "assert", "split", "in", "[", "\"train\"", ",", "\"val\"", ",", "\"test\"", "]", "\n", "self", ".", "split", "=", "split", "\n", "self", ".", "metadata", "=", "None", "\n", "self", ".", "ans_lab_dict", "=", "dict", "(", ")", "\n", "if", "split", "==", "\"train\"", ":", "\n", "            ", "names", "=", "[", "\"k400_train\"", "]", "\n", "", "elif", "split", "==", "\"val\"", ":", "\n", "            ", "names", "=", "[", "\"k400_val\"", "]", "\n", "", "elif", "split", "==", "\"test\"", ":", "\n", "            ", "names", "=", "[", "\"k400_test\"", "]", "\n", "", "super", "(", ")", ".", "__init__", "(", "\n", "*", "args", ",", "\n", "**", "kwargs", ",", "\n", "names", "=", "names", ",", "\n", "text_column_name", "=", "\"questions\"", ",", "\n", "remove_duplicate", "=", "False", ",", "\n", ")", "\n", "self", ".", "video_transform", "=", "VideoTransform", "(", "mode", "=", "self", ".", "split", ")", "# train or val model", "\n", "self", ".", "_load_metadata", "(", ")", "\n", "\n", "", "def", "_load_metadata", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.k400.K400Dataset._load_metadata": [[31, 48], ["os.path.join", "open", "f.readlines", "open", "f.readlines", "os.path.join", "str", "line.strip"], "methods", ["None"], ["        ", "metadata_dir", "=", "'./meta_data/k400'", "\n", "split_files", "=", "{", "\n", "'train'", ":", "'k400_train_tsm.list'", ",", "\n", "'val'", ":", "'k400_test_tsm.list'", ",", "\n", "'test'", ":", "'k400_test_tsm.list'", "\n", "}", "\n", "target_split_fp", "=", "split_files", "[", "self", ".", "split", "]", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "metadata_dir", ",", "target_split_fp", ")", ")", "as", "f", ":", "\n", "            ", "self", ".", "metadata", "=", "f", ".", "readlines", "(", ")", "\n", "", "answer_fp", "=", "os", ".", "path", ".", "join", "(", "metadata_dir", ",", "'kinetics_label_map.txt'", ")", "\n", "count", "=", "0", "\n", "with", "open", "(", "answer_fp", ",", "'r'", ")", "as", "f", ":", "\n", "            ", "lines", "=", "f", ".", "readlines", "(", ")", "\n", "for", "line", "in", "lines", ":", "\n", "                ", "self", ".", "ans_lab_dict", "[", "str", "(", "line", ".", "strip", "(", ")", ")", "]", "=", "count", "\n", "count", "+=", "1", "\n", "\n", "", "", "", "def", "_get_video_path", "(", "self", ",", "sample", ")", ":", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.k400.K400Dataset._get_video_path": [[49, 67], ["os.path.join", "fake_path.split", "os.listdir", "os.path.join", "os.path.join"], "methods", ["None"], ["# find the name is os.listdir() e.g. abseiling/0wR5jVB-WPk.mp4", "\n", "# /data/algceph/arcdata/Kinetics-400/train_zips/snowboarding/MCgJO4s1qBA_000129_000139.zip", "\n", "# -> snowboarding/MCgJO4s1qBA_000129_000139.mp4", "\n", "        ", "if", "self", ".", "split", "==", "'train'", ":", "\n", "            ", "rel_path", "=", "sample", "[", "0", "]", "[", "46", ":", "-", "4", "]", "+", "'.mp4'", "\n", "", "else", ":", "\n", "# val maybe mkv. webm etc.", "\n", "            ", "fake_path", "=", "sample", "[", "0", "]", "[", "44", ":", "-", "4", "]", "\n", "sub_dir", ",", "video_name", "=", "fake_path", ".", "split", "(", "'/'", ")", "\n", "rel_path", "=", "sub_dir", "\n", "for", "video", "in", "os", ".", "listdir", "(", "os", ".", "path", ".", "join", "(", "self", ".", "data_dir", ",", "self", ".", "split", ",", "sub_dir", ")", ")", ":", "\n", "                ", "if", "video_name", "in", "video", ":", "\n", "                    ", "rel_path", "=", "os", ".", "path", ".", "join", "(", "rel_path", ",", "video", ")", "\n", "break", "\n", "", "", "", "full_path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "data_dir", ",", "self", ".", "split", ",", "rel_path", ")", "\n", "# print(full_path)", "\n", "return", "full_path", ",", "rel_path", "\n", "\n", "", "def", "get_text", "(", "self", ",", "sample", ")", ":", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.k400.K400Dataset.get_text": [[68, 78], ["k400.K400Dataset.tokenizer"], "methods", ["None"], ["        ", "text", "=", "\"A persion is doing [MASK]\"", "\n", "encoding", "=", "self", ".", "tokenizer", "(", "\n", "text", ",", "\n", "padding", "=", "\"max_length\"", ",", "\n", "truncation", "=", "True", ",", "\n", "max_length", "=", "self", ".", "max_text_len", ",", "\n", "return_special_tokens_mask", "=", "True", ",", "\n", ")", "\n", "return", "(", "text", ",", "encoding", ")", "\n", "\n", "", "def", "get_answer_label", "(", "self", ",", "sample", ")", ":", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.k400.K400Dataset.get_answer_label": [[79, 87], ["int", "numpy.zeros().astype", "len", "numpy.zeros"], "methods", ["None"], ["        ", "text", "=", "\"None\"", "\n", "# print(len(self.ans_lab_dict))", "\n", "ans_total_len", "=", "len", "(", "self", ".", "ans_lab_dict", ")", "+", "1", "# one additional class", "\n", "ans_label", "=", "int", "(", "sample", "[", "1", "]", ")", "\n", "scores", "=", "np", ".", "zeros", "(", "ans_total_len", ")", ".", "astype", "(", "int", ")", "\n", "scores", "[", "ans_label", "]", "=", "1", "\n", "return", "text", ",", "ans_label", ",", "scores", "\n", "\n", "", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.k400.K400Dataset.__getitem__": [[88, 113], ["k400.K400Dataset.metadata[].split", "k400.K400Dataset.get_video", "k400.K400Dataset.get_text", "k400.K400Dataset.get_answer_label", "list", "list", "list", "print", "random.randint", "len"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_v2.Ego4DDataset.get_video", "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_v2.Ego4DDataset.get_text", "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.msvdqa.MSVDQADataset.get_answer_label"], ["        ", "result", "=", "None", "\n", "while", "result", "is", "None", ":", "\n", "            ", "sample", "=", "self", ".", "metadata", "[", "index", "]", ".", "split", "(", "'\\t'", ")", "\n", "try", ":", "\n", "                ", "video_tensor", "=", "self", ".", "get_video", "(", "sample", ")", "\n", "text", "=", "self", ".", "get_text", "(", "sample", ")", "\n", "qid", "=", "index", "\n", "if", "self", ".", "split", "!=", "\"test\"", ":", "\n", "                    ", "answers", ",", "labels", ",", "scores", "=", "self", ".", "get_answer_label", "(", "sample", ")", "\n", "", "else", ":", "\n", "                    ", "answers", "=", "list", "(", ")", "\n", "labels", "=", "list", "(", ")", "\n", "scores", "=", "list", "(", ")", "\n", "", "result", "=", "True", "\n", "", "except", "Exception", "as", "e", ":", "\n", "                ", "print", "(", "f\"Error while read file idx {sample[0]} -> {e}\"", ")", "\n", "index", "=", "random", ".", "randint", "(", "0", ",", "len", "(", "self", ".", "metadata", ")", "-", "1", ")", "\n", "", "", "return", "{", "\n", "\"video\"", ":", "video_tensor", ",", "\n", "\"text\"", ":", "text", ",", "\n", "\"vqa_answer\"", ":", "answers", ",", "\n", "\"vqa_labels\"", ":", "labels", ",", "\n", "\"vqa_scores\"", ":", "scores", ",", "\n", "\"qid\"", ":", "qid", ",", "\n", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.k400.K400Dataset.__len__": [[115, 117], ["len"], "methods", ["None"], ["        ", "return", "len", "(", "self", ".", "metadata", ")", "", "", "", ""]], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.hmdb51_zero_shot.HMDB51Dataset.__init__": [[7, 26], ["dict", "video_base_dataset.BaseDataset.__init__", "hmdb51_zero_shot.HMDB51Dataset._load_metadata"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.transforms.utils.UnNormalize.__init__", "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_v2.Ego4DDataset._load_metadata"], ["    ", "def", "__init__", "(", "self", ",", "*", "args", ",", "split", "=", "\"\"", ",", "**", "kwargs", ")", ":", "\n", "        ", "assert", "split", "in", "[", "\"train\"", ",", "\"val\"", ",", "\"test\"", "]", "\n", "self", ".", "split", "=", "split", "\n", "self", ".", "metadata", "=", "None", "\n", "self", ".", "ans_lab_dict", "=", "dict", "(", ")", "\n", "if", "split", "==", "\"train\"", ":", "\n", "            ", "names", "=", "[", "\"hmdb51_train\"", "]", "\n", "", "elif", "split", "==", "\"val\"", ":", "\n", "            ", "names", "=", "[", "\"hmdb51_val\"", "]", "\n", "", "elif", "split", "==", "\"test\"", ":", "\n", "            ", "names", "=", "[", "\"hmdb51_test\"", "]", "\n", "", "super", "(", ")", ".", "__init__", "(", "\n", "*", "args", ",", "\n", "**", "kwargs", ",", "\n", "names", "=", "names", ",", "\n", "text_column_name", "=", "\"questions\"", ",", "\n", "remove_duplicate", "=", "False", ",", "\n", ")", "\n", "self", ".", "_load_metadata", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.hmdb51_zero_shot.HMDB51Dataset._load_metadata": [[27, 41], ["os.path.join", "x.strip().split", "open", "f.readlines", "open", "x.strip", "os.path.join", "line.strip().split", "str", "line.strip", "int", "line.strip().split", "line.strip"], "methods", ["None"], ["", "def", "_load_metadata", "(", "self", ")", ":", "\n", "        ", "metadata_dir", "=", "'./meta_data/hmdb51'", "\n", "split_files", "=", "{", "\n", "'train'", ":", "'hmdb51_rgb_train_split_1.txt'", ",", "\n", "'val'", ":", "'hmdb51_rgb_val_split_1.txt'", ",", "\n", "'test'", ":", "'hmdb51_rgb_val_split_1.txt'", "\n", "}", "\n", "target_split_fp", "=", "split_files", "[", "self", ".", "split", "]", "\n", "self", ".", "metadata", "=", "[", "x", ".", "strip", "(", ")", ".", "split", "(", "' '", ")", "for", "x", "in", "open", "(", "os", ".", "path", ".", "join", "(", "metadata_dir", ",", "target_split_fp", ")", ")", "]", "\n", "answer_fp", "=", "os", ".", "path", ".", "join", "(", "metadata_dir", ",", "'hmdb51_classInd.txt'", ")", "\n", "with", "open", "(", "answer_fp", ",", "'r'", ")", "as", "f", ":", "\n", "            ", "lines", "=", "f", ".", "readlines", "(", ")", "\n", "for", "line", "in", "lines", ":", "\n", "                ", "self", ".", "ans_lab_dict", "[", "str", "(", "int", "(", "line", ".", "strip", "(", ")", ".", "split", "(", "' '", ")", "[", "0", "]", ")", "-", "1", ")", "]", "=", "line", ".", "strip", "(", ")", ".", "split", "(", "' '", ")", "[", "1", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.hmdb51_zero_shot.HMDB51Dataset._get_video_path": [[42, 45], ["os.path.join", "sample[].split", "sample[].split"], "methods", ["None"], ["", "", "", "def", "_get_video_path", "(", "self", ",", "sample", ")", ":", "\n", "# self.ans_lab_dict[sample[2]],", "\n", "        ", "return", "os", ".", "path", ".", "join", "(", "self", ".", "data_dir", ",", "sample", "[", "0", "]", ".", "split", "(", "'/'", ")", "[", "-", "1", "]", ")", "+", "'.avi'", ",", "sample", "[", "0", "]", ".", "split", "(", "'/'", ")", "[", "-", "1", "]", "+", "'.avi'", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.hmdb51_zero_shot.HMDB51Dataset.get_text": [[46, 56], ["hmdb51_zero_shot.HMDB51Dataset.tokenizer"], "methods", ["None"], ["", "def", "get_text", "(", "self", ",", "sample", ")", ":", "\n", "        ", "text", "=", "\"A\"", "\n", "encoding", "=", "self", ".", "tokenizer", "(", "\n", "text", ",", "\n", "padding", "=", "\"max_length\"", ",", "\n", "truncation", "=", "True", ",", "\n", "max_length", "=", "self", ".", "max_text_len", ",", "\n", "return_special_tokens_mask", "=", "True", ",", "\n", ")", "\n", "return", "(", "text", ",", "encoding", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.hmdb51_zero_shot.HMDB51Dataset.get_answer_label": [[57, 64], ["int", "numpy.zeros().astype", "len", "numpy.zeros"], "methods", ["None"], ["", "def", "get_answer_label", "(", "self", ",", "sample", ")", ":", "\n", "        ", "text", "=", "\"None\"", "\n", "ans_total_len", "=", "len", "(", "self", ".", "ans_lab_dict", ")", "+", "1", "# one additional class", "\n", "ans_label", "=", "int", "(", "sample", "[", "2", "]", ")", "\n", "scores", "=", "np", ".", "zeros", "(", "ans_total_len", ")", ".", "astype", "(", "int", ")", "\n", "scores", "[", "ans_label", "]", "=", "1", "\n", "return", "text", ",", "ans_label", ",", "scores", "\n", "# return text, ans_label_vector, scores", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.hmdb51_zero_shot.HMDB51Dataset.__getitem__": [[66, 85], ["hmdb51_zero_shot.HMDB51Dataset.get_video", "hmdb51_zero_shot.HMDB51Dataset.get_text", "hmdb51_zero_shot.HMDB51Dataset.get_answer_label", "list", "list", "list"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_v2.Ego4DDataset.get_video", "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_v2.Ego4DDataset.get_text", "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.msvdqa.MSVDQADataset.get_answer_label"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "sample", "=", "self", ".", "metadata", "[", "index", "]", "# .split(' ')", "\n", "image_tensor", "=", "self", ".", "get_video", "(", "sample", ")", "\n", "text", "=", "self", ".", "get_text", "(", "sample", ")", "\n", "qid", "=", "index", "\n", "if", "self", ".", "split", "!=", "\"test\"", ":", "\n", "            ", "answers", ",", "labels", ",", "scores", "=", "self", ".", "get_answer_label", "(", "sample", ")", "\n", "", "else", ":", "\n", "            ", "answers", "=", "list", "(", ")", "\n", "labels", "=", "list", "(", ")", "\n", "scores", "=", "list", "(", ")", "\n", "\n", "", "return", "{", "\n", "\"image\"", ":", "image_tensor", ",", "\n", "\"text\"", ":", "text", ",", "\n", "\"vqa_answer\"", ":", "answers", ",", "\n", "\"vqa_labels\"", ":", "labels", ",", "\n", "\"vqa_scores\"", ":", "scores", ",", "\n", "\"qid\"", ":", "qid", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.hmdb51_zero_shot.HMDB51Dataset.__len__": [[87, 89], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "metadata", ")", "", "", "", ""]], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.vqav2_dataset.VQAv2Dataset.__init__": [[5, 22], ["base_dataset.BaseDataset.__init__"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.transforms.utils.UnNormalize.__init__"], ["    ", "def", "__init__", "(", "self", ",", "*", "args", ",", "split", "=", "\"\"", ",", "**", "kwargs", ")", ":", "\n", "        ", "assert", "split", "in", "[", "\"train\"", ",", "\"val\"", ",", "\"test\"", "]", "\n", "self", ".", "split", "=", "split", "\n", "\n", "if", "split", "==", "\"train\"", ":", "\n", "            ", "names", "=", "[", "\"vqav2_train\"", ",", "\"vqav2_trainable_val\"", "]", "\n", "", "elif", "split", "==", "\"val\"", ":", "\n", "            ", "names", "=", "[", "\"vqav2_rest_val\"", "]", "\n", "", "elif", "split", "==", "\"test\"", ":", "\n", "            ", "names", "=", "[", "\"vqav2_test\"", "]", "# vqav2_test-dev for test-dev", "\n", "\n", "", "super", "(", ")", ".", "__init__", "(", "\n", "*", "args", ",", "\n", "**", "kwargs", ",", "\n", "names", "=", "names", ",", "\n", "text_column_name", "=", "\"questions\"", ",", "\n", "remove_duplicate", "=", "False", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.vqav2_dataset.VQAv2Dataset.__getitem__": [[24, 47], ["[].as_py", "vqav2_dataset.VQAv2Dataset.get_image", "vqav2_dataset.VQAv2Dataset.get_text", "[].as_py", "[].as_py", "[].as_py", "list", "list", "list"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.datasets.vcr.VCRDataset.get_image", "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_v2.Ego4DDataset.get_text"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "image_tensor", "=", "self", ".", "get_image", "(", "index", ")", "[", "\"image\"", "]", "\n", "text", "=", "self", ".", "get_text", "(", "index", ")", "[", "\"text\"", "]", "\n", "\n", "index", ",", "question_index", "=", "self", ".", "index_mapper", "[", "index", "]", "\n", "qid", "=", "self", ".", "table", "[", "\"question_id\"", "]", "[", "index", "]", "[", "question_index", "]", ".", "as_py", "(", ")", "\n", "\n", "if", "self", ".", "split", "!=", "\"test\"", ":", "\n", "            ", "answers", "=", "self", ".", "table", "[", "\"answers\"", "]", "[", "index", "]", "[", "question_index", "]", ".", "as_py", "(", ")", "\n", "labels", "=", "self", ".", "table", "[", "\"answer_labels\"", "]", "[", "index", "]", "[", "question_index", "]", ".", "as_py", "(", ")", "\n", "scores", "=", "self", ".", "table", "[", "\"answer_scores\"", "]", "[", "index", "]", "[", "question_index", "]", ".", "as_py", "(", ")", "\n", "", "else", ":", "\n", "            ", "answers", "=", "list", "(", ")", "\n", "labels", "=", "list", "(", ")", "\n", "scores", "=", "list", "(", ")", "\n", "\n", "", "return", "{", "\n", "\"image\"", ":", "image_tensor", ",", "\n", "\"text\"", ":", "text", ",", "\n", "\"vqa_answer\"", ":", "answers", ",", "\n", "\"vqa_labels\"", ":", "labels", ",", "\n", "\"vqa_scores\"", ":", "scores", ",", "\n", "\"qid\"", ":", "qid", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.msrvttqa.MSRVTTQADataset.__init__": [[9, 34], ["video_base_dataset.BaseDataset.__init__", "msrvttqa.MSRVTTQADataset._load_metadata"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.transforms.utils.UnNormalize.__init__", "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_v2.Ego4DDataset._load_metadata"], ["    ", "def", "__init__", "(", "self", ",", "*", "args", ",", "split", "=", "\"\"", ",", "**", "kwargs", ")", ":", "\n", "        ", "assert", "split", "in", "[", "\"train\"", ",", "\"val\"", ",", "\"test\"", "]", "\n", "#         if split == \"test\":", "\n", "#             split = \"val\"", "\n", "self", ".", "split", "=", "split", "\n", "self", ".", "metadata", "=", "None", "\n", "self", ".", "ans_lab_dict", "=", "None", "\n", "if", "split", "==", "\"train\"", ":", "\n", "            ", "names", "=", "[", "\"msrvtt_qa_train\"", "]", "\n", "# names = [\"msrvtt_qa_train\", \"msrvtt_qa_val\"]", "\n", "", "elif", "split", "==", "\"val\"", ":", "\n", "            ", "names", "=", "[", "\"msrvtt_qa_test\"", "]", "# [\"msrvtt_qa_val\"]", "\n", "", "elif", "split", "==", "\"test\"", ":", "\n", "            ", "names", "=", "[", "\"msrvtt_qa_test\"", "]", "# vqav2_test-dev for test-dev", "\n", "\n", "", "super", "(", ")", ".", "__init__", "(", "\n", "*", "args", ",", "\n", "**", "kwargs", ",", "\n", "names", "=", "names", ",", "\n", "text_column_name", "=", "\"questions\"", ",", "\n", "remove_duplicate", "=", "False", ",", "\n", ")", "\n", "self", ".", "names", "=", "names", "\n", "# self.num_frames = 4", "\n", "self", ".", "_load_metadata", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.msrvttqa.MSRVTTQADataset._load_metadata": [[35, 56], ["os.path.join", "print", "open", "json.load", "pandas.read_json", "name.split", "os.path.join", "msrvttqa.MSRVTTQADataset.metadata.update", "len"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.gadgets.my_metrics.VQAScore.update"], ["", "def", "_load_metadata", "(", "self", ")", ":", "\n", "        ", "metadata_dir", "=", "'./meta_data/msrvtt'", "\n", "split_files", "=", "{", "\n", "'train'", ":", "'msrvtt_qa_train.jsonl'", ",", "\n", "'val'", ":", "'msrvtt_qa_val.jsonl'", ",", "\n", "'test'", ":", "'msrvtt_qa_test.jsonl'", "\n", "}", "\n", "answer_fp", "=", "os", ".", "path", ".", "join", "(", "metadata_dir", ",", "'msrvtt_train_ans2label.json'", ")", "# 1500 in total (all classes in train)", "\n", "# answer_fp = os.path.join(metadata_dir, 'msrvtt_qa_ans2label.json')  # 4539 in total (all classes in train+val+test)", "\n", "with", "open", "(", "answer_fp", ",", "'r'", ")", "as", "JSON", ":", "\n", "            ", "self", ".", "ans_lab_dict", "=", "json", ".", "load", "(", "JSON", ")", "\n", "", "for", "name", "in", "self", ".", "names", ":", "\n", "            ", "split", "=", "name", ".", "split", "(", "'_'", ")", "[", "-", "1", "]", "\n", "target_split_fp", "=", "split_files", "[", "split", "]", "\n", "# path_or_buf=os.path.join(metadata_dir, target_split_fp)", "\n", "metadata", "=", "pd", ".", "read_json", "(", "os", ".", "path", ".", "join", "(", "metadata_dir", ",", "target_split_fp", ")", ",", "lines", "=", "True", ")", "\n", "if", "self", ".", "metadata", "is", "None", ":", "\n", "                ", "self", ".", "metadata", "=", "metadata", "\n", "", "else", ":", "\n", "                ", "self", ".", "metadata", ".", "update", "(", "metadata", ")", "\n", "", "", "print", "(", "\"total {} samples for {}\"", ".", "format", "(", "len", "(", "self", ".", "metadata", ")", ",", "self", ".", "names", ")", ")", "\n", "# data1.update(data2)", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.msrvttqa.MSRVTTQADataset.get_text": [[58, 68], ["msrvttqa.MSRVTTQADataset.tokenizer"], "methods", ["None"], ["", "def", "get_text", "(", "self", ",", "sample", ")", ":", "\n", "        ", "text", "=", "sample", "[", "'question'", "]", "\n", "encoding", "=", "self", ".", "tokenizer", "(", "\n", "text", ",", "\n", "padding", "=", "\"max_length\"", ",", "\n", "truncation", "=", "True", ",", "\n", "max_length", "=", "self", ".", "max_text_len", ",", "\n", "return_special_tokens_mask", "=", "True", ",", "\n", ")", "\n", "return", "(", "text", ",", "encoding", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.msrvttqa.MSRVTTQADataset.get_answer_label": [[69, 80], ["numpy.zeros().astype", "len", "numpy.zeros"], "methods", ["None"], ["", "def", "get_answer_label", "(", "self", ",", "sample", ")", ":", "\n", "        ", "text", "=", "sample", "[", "'answer'", "]", "\n", "ans_total_len", "=", "len", "(", "self", ".", "ans_lab_dict", ")", "+", "1", "# one additional class", "\n", "try", ":", "\n", "            ", "ans_label", "=", "self", ".", "ans_lab_dict", "[", "text", "]", "#", "\n", "", "except", "KeyError", ":", "\n", "            ", "ans_label", "=", "-", "100", "# ignore classes", "\n", "# ans_label = 1500 # other classes", "\n", "", "scores", "=", "np", ".", "zeros", "(", "ans_total_len", ")", ".", "astype", "(", "int", ")", "\n", "scores", "[", "ans_label", "]", "=", "1", "\n", "return", "text", ",", "ans_label", ",", "scores", "\n", "# return text, ans_label_vector, scores", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.msrvttqa.MSRVTTQADataset.__getitem__": [[82, 102], ["msrvttqa.MSRVTTQADataset.get_video", "msrvttqa.MSRVTTQADataset.get_text", "msrvttqa.MSRVTTQADataset.get_answer_label", "list", "list", "list"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_v2.Ego4DDataset.get_video", "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_v2.Ego4DDataset.get_text", "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.msvdqa.MSVDQADataset.get_answer_label"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "sample", "=", "self", ".", "metadata", ".", "iloc", "[", "index", "]", "\n", "video_tensor", "=", "self", ".", "get_video", "(", "sample", ")", "\n", "text", "=", "self", ".", "get_text", "(", "sample", ")", "\n", "# index, question_index = self.index_mapper[index]", "\n", "qid", "=", "index", "\n", "if", "self", ".", "split", "!=", "\"test\"", ":", "\n", "            ", "answers", ",", "labels", ",", "scores", "=", "self", ".", "get_answer_label", "(", "sample", ")", "\n", "", "else", ":", "\n", "            ", "answers", "=", "list", "(", ")", "\n", "labels", "=", "list", "(", ")", "\n", "scores", "=", "list", "(", ")", "\n", "\n", "", "return", "{", "\n", "\"video\"", ":", "video_tensor", ",", "\n", "\"text\"", ":", "text", ",", "\n", "\"vqa_answer\"", ":", "answers", ",", "\n", "\"vqa_labels\"", ":", "labels", ",", "\n", "\"vqa_scores\"", ":", "scores", ",", "\n", "\"qid\"", ":", "qid", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.msrvttqa.MSRVTTQADataset.__len__": [[104, 106], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "metadata", ")", "", "", "", ""]], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.coco_caption_karpathy_dataset.CocoCaptionKarpathyDataset.__init__": [[5, 20], ["base_dataset.BaseDataset.__init__"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.transforms.utils.UnNormalize.__init__"], ["    ", "def", "__init__", "(", "self", ",", "*", "args", ",", "split", "=", "\"\"", ",", "**", "kwargs", ")", ":", "\n", "        ", "assert", "split", "in", "[", "\"train\"", ",", "\"val\"", ",", "\"test\"", "]", "\n", "self", ".", "split", "=", "split", "\n", "\n", "if", "split", "==", "\"train\"", ":", "\n", "            ", "names", "=", "[", "\"coco_caption_karpathy_train\"", "]", "# , \"coco_caption_karpathy_restval\"", "\n", "", "elif", "split", "==", "\"val\"", ":", "\n", "            ", "names", "=", "[", "\"coco_caption_karpathy_val\"", "]", "\n", "# names = [\"coco_caption_karpathy_test\"]", "\n", "# names = []  # for fast train", "\n", "", "elif", "split", "==", "\"test\"", ":", "\n", "            ", "names", "=", "[", "\"coco_caption_karpathy_test\"", "]", "\n", "# names = []", "\n", "\n", "", "super", "(", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ",", "names", "=", "names", ",", "text_column_name", "=", "\"caption\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.coco_caption_karpathy_dataset.CocoCaptionKarpathyDataset.__getitem__": [[21, 31], ["coco_caption_karpathy_dataset.CocoCaptionKarpathyDataset.get_suite", "[].as_py", "int", "coco_caption_karpathy_dataset.CocoCaptionKarpathyDataset.update", "[].split", "int.split"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_v2.Ego4DDataset.get_suite", "home.repos.pwc.inspect_result.showlab_all-in-one.gadgets.my_metrics.VQAScore.update"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "suite", "=", "self", ".", "get_suite", "(", "index", ")", "\n", "\n", "if", "\"test\"", "in", "self", ".", "split", ":", "\n", "            ", "_index", ",", "_question_index", "=", "self", ".", "index_mapper", "[", "index", "]", "\n", "iid", "=", "self", ".", "table", "[", "\"image_id\"", "]", "[", "_index", "]", ".", "as_py", "(", ")", "\n", "iid", "=", "int", "(", "iid", ".", "split", "(", "\".\"", ")", "[", "0", "]", ".", "split", "(", "\"_\"", ")", "[", "-", "1", "]", ")", "\n", "suite", ".", "update", "(", "{", "\"iid\"", ":", "iid", "}", ")", "\n", "\n", "", "return", "suite", "\n", "", "", ""]], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.video_base_dataset.BaseDataset.__init__": [[23, 74], ["super().__init__", "AllInOne.transforms.keys_to_transforms", "AllInOne.transforms.videoaug.VideoTransform", "len", "len", "os.path.join", "torch.distributed.get_rank", "print", "print", "torch.distributed.get_rank", "print", "print", "names[].split", "torch.distributed.get_rank", "print"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.transforms.utils.UnNormalize.__init__", "home.repos.pwc.inspect_result.showlab_all-in-one.transforms.__init__.keys_to_transforms", "home.repos.pwc.inspect_result.showlab_all-in-one.transforms.videoaug.VideoTransform", "home.repos.pwc.inspect_result.showlab_all-in-one.modules.dist_utils.get_rank", "home.repos.pwc.inspect_result.showlab_all-in-one.modules.dist_utils.get_rank", "home.repos.pwc.inspect_result.showlab_all-in-one.modules.dist_utils.get_rank"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "data_dir", ":", "str", ",", "\n", "transform_keys", ":", "list", ",", "\n", "image_size", ":", "int", ",", "\n", "names", ":", "list", ",", "\n", "text_column_name", ":", "str", "=", "\"\"", ",", "\n", "remove_duplicate", "=", "True", ",", "\n", "max_text_len", "=", "40", ",", "\n", "draw_false_image", "=", "0", ",", "\n", "draw_false_video", "=", "0", ",", "\n", "draw_false_text", "=", "0", ",", "\n", "image_only", "=", "False", ",", "\n", "video_only", "=", "False", ",", "\n", "num_frames", "=", "1", ",", "\n", "draw_options_text", "=", "0", ",", "\n", "backend", "=", "'v100'", "\n", ")", ":", "\n", "        ", "\"\"\"\n        data_dir : where dataset file *.arrow lives; existence should be guaranteed via DataModule.prepare_data\n        transform_keys : keys for generating augmented views of videos\n        text_column_name : pyarrow table column name that has list of strings as elements\n        \"\"\"", "\n", "assert", "len", "(", "transform_keys", ")", ">=", "1", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "transforms", "=", "keys_to_transforms", "(", "transform_keys", ",", "size", "=", "image_size", ")", "\n", "self", ".", "text_column_name", "=", "text_column_name", "\n", "self", ".", "names", "=", "names", "\n", "self", ".", "max_text_len", "=", "max_text_len", "\n", "self", ".", "draw_false_video", "=", "draw_false_video", "\n", "self", ".", "draw_false_text", "=", "draw_false_text", "\n", "self", ".", "video_only", "=", "video_only", "\n", "self", ".", "data_dir", "=", "data_dir", "\n", "if", "len", "(", "names", ")", "!=", "0", ":", "\n", "            ", "dataset_name", "=", "names", "[", "0", "]", ".", "split", "(", "'_'", ")", "[", "0", "]", "\n", "if", "dataset_name", "in", "[", "'tgif'", ",", "'tgifqa'", "]", ":", "\n", "                ", "dataset_name", "=", "'tgif'", "\n", "", "self", ".", "data_dir", "=", "os", ".", "path", ".", "join", "(", "self", ".", "data_dir", ",", "dataset_name", ")", "# e.g. webvid_train -> webvid", "\n", "split_name", "=", "dataset_name", "\n", "", "if", "torch", ".", "distributed", ".", "get_rank", "(", ")", "==", "0", ":", "\n", "            ", "print", "(", "'*'", "*", "100", ")", "\n", "print", "(", "\"video datasets: {}\"", ".", "format", "(", "names", ")", ")", "\n", "", "self", ".", "draw_options_text", "=", "draw_options_text", "\n", "self", ".", "num_frames", "=", "num_frames", "\n", "if", "torch", ".", "distributed", ".", "get_rank", "(", ")", "==", "0", ":", "\n", "            ", "print", "(", "\"# frames for base dataset is: {}\"", ".", "format", "(", "self", ".", "num_frames", ")", ")", "\n", "", "if", "split_name", "in", "[", "'msrvtt'", ",", "'cc3m'", ",", "'webvid'", ",", "'msvd'", ",", "'vcr'", ",", "'howto100m'", ",", "'ego4d'", ",", "'yttemporal'", ",", "'tgif'", ",", "'hmdb51'", ",", "'k400'", "]", ":", "\n", "            ", "if", "torch", ".", "distributed", ".", "get_rank", "(", ")", "==", "0", ":", "\n", "                ", "print", "(", "\"no arrow available for {}, load from disk\"", ".", "format", "(", "names", "[", "0", "]", ")", ")", "\n", "", "", "else", ":", "\n", "            ", "print", "(", "\"not support video dataset\"", ")", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.video_base_dataset.BaseDataset.corpus": [[76, 79], ["None"], "methods", ["None"], ["self", ".", "video_aug", "=", "video_aug", "\n", "\n", "", "@", "property", "\n", "def", "corpus", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.video_base_dataset.BaseDataset.__len__": [[80, 82], ["len"], "methods", ["None"], ["        ", "return", "[", "text", "for", "texts", "in", "self", ".", "all_texts", "for", "text", "in", "texts", "]", "\n", "\n", "", "def", "__len__", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.video_base_dataset.BaseDataset.__getitem__": [[83, 85], ["video_base_dataset.BaseDataset.get_suite"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_v2.Ego4DDataset.get_suite"], ["        ", "return", "len", "(", "self", ".", "metadata", ")", "\n", "\n", "", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.video_base_dataset.BaseDataset.get_raw_image": [[86, 91], ["io.BytesIO", "io.BytesIO.seek", "PIL.Image.open().convert", "[].as_py", "PIL.Image.open"], "methods", ["None"], ["        ", "return", "self", ".", "get_suite", "(", "index", ")", "\n", "\n", "", "def", "get_raw_image", "(", "self", ",", "index", ",", "image_key", "=", "\"image\"", ")", ":", "\n", "        ", "index", ",", "caption_index", "=", "self", ".", "index_mapper", "[", "index", "]", "\n", "image_bytes", "=", "io", ".", "BytesIO", "(", "self", ".", "table", "[", "image_key", "]", "[", "index", "]", ".", "as_py", "(", ")", ")", "\n", "image_bytes", ".", "seek", "(", "0", ")", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.video_base_dataset.BaseDataset._get_video_path": [[92, 97], ["os.path.join", "os.path.join", "str", "str"], "methods", ["None"], ["return", "Image", ".", "open", "(", "image_bytes", ")", ".", "convert", "(", "\"RGB\"", ")", "\n", "\n", "", "def", "_get_video_path", "(", "self", ",", "sample", ")", ":", "\n", "        ", "if", "self", ".", "names", "[", "0", "]", "in", "[", "'msrvtt_train'", ",", "'msrvtt_test'", ",", "'msrvtt_val'", "]", ":", "\n", "            ", "return", "os", ".", "path", ".", "join", "(", "self", ".", "data_dir", ",", "'videos'", ",", "'all'", ",", "sample", ".", "name", "+", "'.mp4'", ")", ",", "sample", ".", "name", "+", "'.mp4'", "\n", "", "else", ":", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.video_base_dataset.BaseDataset.get_raw_video": [[98, 105], ["video_base_dataset.BaseDataset._get_video_path", "video_base_dataset.read_frames_decord", "Exception"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_v2.Ego4DDataset._get_video_path", "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.base_dataset.read_frames_decord"], ["            ", "return", "os", ".", "path", ".", "join", "(", "self", ".", "data_dir", ",", "'videos'", ",", "'all'", ",", "str", "(", "sample", "[", "'video_id'", "]", ")", "+", "'.mp4'", ")", ",", "str", "(", "sample", "[", "'video_id'", "]", ")", "+", "'.mp4'", "\n", "\n", "", "", "def", "get_raw_video", "(", "self", ",", "sample", ")", ":", "\n", "        ", "abs_fp", ",", "rel_fp", "=", "self", ".", "_get_video_path", "(", "sample", ")", "\n", "imgs", ",", "idxs", ",", "vlen", "=", "read_frames_decord", "(", "abs_fp", ",", "self", ".", "num_frames", ",", "mode", "=", "self", ".", "split", ")", "\n", "if", "imgs", "is", "None", ":", "\n", "            ", "raise", "Exception", "(", "\"Invalid img!\"", ",", "rel_fp", ")", "\n", "", "else", ":", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.video_base_dataset.BaseDataset.get_video": [[106, 110], ["video_base_dataset.BaseDataset.get_raw_video().permute", "video_base_dataset.BaseDataset.video_transform().permute", "video_base_dataset.BaseDataset.get_raw_video", "video_base_dataset.BaseDataset.video_transform"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_v2.Ego4DDataset.get_raw_video"], ["            ", "return", "imgs", "\n", "\n", "", "", "def", "get_video", "(", "self", ",", "sample", ")", ":", "\n", "        ", "videos", "=", "self", ".", "get_raw_video", "(", "sample", ")", "\n", "videos_tensor", "=", "self", ".", "video_aug", "(", "videos", ",", "self", ".", "video_transform", ")", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.video_base_dataset.BaseDataset.get_false_video": [[111, 118], ["random.randint", "video_base_dataset.BaseDataset.get_raw_video().permute", "video_base_dataset.BaseDataset.size", "video_base_dataset.BaseDataset.video_transform().permute", "len", "video_base_dataset.BaseDataset.get_raw_video", "video_base_dataset.BaseDataset.video_transform"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_v2.Ego4DDataset.get_raw_video"], ["return", "videos_tensor", "\n", "\n", "", "def", "get_false_video", "(", "self", ",", "rep", ")", ":", "\n", "        ", "random_index", "=", "random", ".", "randint", "(", "0", ",", "len", "(", "self", ".", "metadata", ")", "-", "1", ")", "\n", "sample", "=", "self", ".", "metadata", ".", "iloc", "[", "random_index", "]", "\n", "videos", "=", "self", ".", "get_raw_video", "(", "sample", ")", "\n", "videos_tensor", "=", "self", ".", "video_aug", "(", "videos", ",", "self", ".", "video_transform", ")", "\n", "return", "{", "f\"false_video_{rep}\"", ":", "videos_tensor", "}", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.video_base_dataset.BaseDataset._get_caption": [[119, 125], ["random.choice"], "methods", ["None"], ["\n", "", "def", "_get_caption", "(", "self", ",", "sample", ")", ":", "\n", "        ", "if", "self", ".", "names", "[", "0", "]", "in", "[", "'msrvtt_train'", "]", ":", "\n", "            ", "caption", "=", "random", ".", "choice", "(", "sample", "[", "'captions'", "]", ")", "\n", "", "else", ":", "\n", "            ", "caption", "=", "sample", "[", "'captions'", "]", "[", "0", "]", "\n", "", "return", "caption", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.video_base_dataset.BaseDataset.get_text": [[126, 141], ["video_base_dataset.BaseDataset._get_caption", "video_base_dataset.BaseDataset.tokenizer"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.datasets.lsmdc_dataset.LSMDCDataset._get_caption"], ["\n", "", "def", "get_text", "(", "self", ",", "raw_index", ",", "sample", ")", ":", "\n", "        ", "text", "=", "self", ".", "_get_caption", "(", "sample", ")", "\n", "encoding", "=", "self", ".", "tokenizer", "(", "\n", "text", ",", "\n", "padding", "=", "\"max_length\"", ",", "\n", "truncation", "=", "True", ",", "\n", "max_length", "=", "self", ".", "max_text_len", ",", "\n", "return_special_tokens_mask", "=", "True", ",", "\n", ")", "\n", "# print(encoding.size())", "\n", "return", "{", "\n", "\"text\"", ":", "(", "text", ",", "encoding", ")", ",", "\n", "\"vid_index\"", ":", "raw_index", ",", "\n", "\"cap_index\"", ":", "raw_index", ",", "\n", "\"raw_index\"", ":", "raw_index", ",", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.video_base_dataset.BaseDataset.get_false_text": [[143, 155], ["random.randint", "video_base_dataset.BaseDataset._get_caption", "video_base_dataset.BaseDataset.tokenizer", "len"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.datasets.lsmdc_dataset.LSMDCDataset._get_caption"], ["\n", "", "def", "get_false_text", "(", "self", ",", "rep", ")", ":", "\n", "        ", "random_index", "=", "random", ".", "randint", "(", "0", ",", "len", "(", "self", ".", "metadata", ")", "-", "1", ")", "\n", "sample", "=", "self", ".", "metadata", ".", "iloc", "[", "random_index", "]", "\n", "text", "=", "self", ".", "_get_caption", "(", "sample", ")", "\n", "encoding", "=", "self", ".", "tokenizer", "(", "\n", "text", ",", "\n", "# padding=\"max_length\",", "\n", "truncation", "=", "True", ",", "\n", "max_length", "=", "self", ".", "max_text_len", ",", "\n", "return_special_tokens_mask", "=", "True", ",", "\n", ")", "\n", "return", "{", "f\"false_text_{rep}\"", ":", "(", "text", ",", "encoding", ")", "}", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.video_base_dataset.BaseDataset.get_suite": [[156, 184], ["video_base_dataset.BaseDataset.get_video", "range", "range", "video_base_dataset.BaseDataset.get_text", "ret.update", "ret.update", "ret.update", "ret.update", "print", "random.randint", "video_base_dataset.BaseDataset.get_false_video", "video_base_dataset.BaseDataset.get_false_text", "len"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_v2.Ego4DDataset.get_video", "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_v2.Ego4DDataset.get_text", "home.repos.pwc.inspect_result.showlab_all-in-one.gadgets.my_metrics.VQAScore.update", "home.repos.pwc.inspect_result.showlab_all-in-one.gadgets.my_metrics.VQAScore.update", "home.repos.pwc.inspect_result.showlab_all-in-one.gadgets.my_metrics.VQAScore.update", "home.repos.pwc.inspect_result.showlab_all-in-one.gadgets.my_metrics.VQAScore.update", "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_v2.Ego4DDataset.get_false_video", "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_v2.Ego4DDataset.get_false_text"], ["\n", "", "def", "get_suite", "(", "self", ",", "index", ")", ":", "\n", "        ", "result", "=", "None", "\n", "while", "result", "is", "None", ":", "\n", "# retry_times += 1", "\n", "            ", "sample", "=", "self", ".", "metadata", ".", "iloc", "[", "index", "]", "\n", "# print(sample[1])", "\n", "try", ":", "\n", "                ", "video_tensor", "=", "self", ".", "get_video", "(", "sample", ")", "\n", "ret", "=", "{", "\n", "\"video\"", ":", "video_tensor", ",", "\n", "\"vid_index\"", ":", "index", ",", "\n", "\"cap_index\"", ":", "index", ",", "\n", "\"raw_index\"", ":", "index", ",", "\n", "}", "\n", "if", "not", "self", ".", "video_only", ":", "\n", "                    ", "txt", "=", "self", ".", "get_text", "(", "index", ",", "sample", ")", "\n", "ret", ".", "update", "(", "{", "\"replica\"", ":", "True", "if", "txt", "[", "\"cap_index\"", "]", ">", "0", "else", "False", "}", ")", "\n", "ret", ".", "update", "(", "txt", ")", "\n", "\n", "", "for", "i", "in", "range", "(", "self", ".", "draw_false_video", ")", ":", "\n", "                    ", "ret", ".", "update", "(", "self", ".", "get_false_video", "(", "i", ")", ")", "\n", "", "for", "i", "in", "range", "(", "self", ".", "draw_false_text", ")", ":", "\n", "                    ", "ret", ".", "update", "(", "self", ".", "get_false_text", "(", "i", ")", ")", "\n", "", "result", "=", "True", "\n", "", "except", "Exception", "as", "e", ":", "\n", "                ", "print", "(", "f\"Error while read file idx {sample.name} in {self.names[0]} -> {e}\"", ")", "\n", "index", "=", "random", ".", "randint", "(", "0", ",", "len", "(", "self", ".", "metadata", ")", "-", "1", ")", "\n", "", "", "return", "ret", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.video_base_dataset.BaseDataset.collate": [[185, 267], ["len", "set", "list", "len", "max", "max", "len", "range", "len", "len", "mlm_collator", "enumerate", "list", "len", "torch.zeros", "range", "list", "torch.zeros_like", "torch.zeros_like", "enumerate", "torch.full_like", "b.keys", "dict_batch.keys", "range", "dict_batch.keys", "torch.tensor", "torch.tensor", "len", "len"], "methods", ["None"], ["\n", "", "def", "collate", "(", "self", ",", "batch", ",", "mlm_collator", ")", ":", "\n", "        ", "batch_size", "=", "len", "(", "batch", ")", "\n", "keys", "=", "set", "(", "[", "key", "for", "b", "in", "batch", "for", "key", "in", "b", ".", "keys", "(", ")", "]", ")", "\n", "dict_batch", "=", "{", "k", ":", "[", "dic", "[", "k", "]", "if", "k", "in", "dic", "else", "None", "for", "dic", "in", "batch", "]", "for", "k", "in", "keys", "}", "\n", "\n", "video_keys", "=", "[", "k", "for", "k", "in", "list", "(", "dict_batch", ".", "keys", "(", ")", ")", "if", "\"video\"", "in", "k", "]", "\n", "video_sizes", "=", "list", "(", ")", "\n", "\n", "# global & local video", "\n", "for", "video_key", "in", "video_keys", ":", "\n", "            ", "video_sizes", "+=", "[", "ii", ".", "shape", "for", "i", "in", "dict_batch", "[", "video_key", "]", "if", "i", "is", "not", "None", "for", "ii", "in", "i", "]", "\n", "# print(global_video_sizes, local_video_sizes)", "\n", "\n", "", "for", "size", "in", "video_sizes", ":", "\n", "# print(size)", "\n", "            ", "assert", "(", "\n", "len", "(", "size", ")", "==", "4", "\n", ")", ",", "f\"Collate error, an video should be in shape of (T, N, H, W), instead of given {size}\"", "\n", "\n", "", "if", "len", "(", "video_keys", ")", "!=", "0", ":", "\n", "            ", "global_max_height", "=", "max", "(", "[", "i", "[", "2", "]", "for", "i", "in", "video_sizes", "]", ")", "\n", "global_max_width", "=", "max", "(", "[", "i", "[", "3", "]", "for", "i", "in", "video_sizes", "]", ")", "\n", "", "for", "video_key", "in", "video_keys", ":", "\n", "            ", "video", "=", "dict_batch", "[", "video_key", "]", "\n", "view_size", "=", "len", "(", "video", "[", "0", "]", ")", "\n", "# print(view_size)", "\n", "new_videos", "=", "[", "\n", "torch", ".", "zeros", "(", "batch_size", ",", "self", ".", "num_frames", ",", "3", ",", "global_max_height", ",", "global_max_width", ")", "\n", "for", "_", "in", "range", "(", "view_size", ")", "\n", "]", "\n", "# print(len(img))", "\n", "for", "bi", "in", "range", "(", "batch_size", ")", ":", "\n", "                ", "orig_batch", "=", "video", "[", "bi", "]", "\n", "for", "vi", "in", "range", "(", "view_size", ")", ":", "\n", "                    ", "if", "orig_batch", "is", "None", ":", "\n", "# new_videos[vi][bi] = None", "\n", "# modify by alex", "\n", "                        ", "continue", "\n", "", "else", ":", "\n", "                        ", "orig", "=", "video", "[", "bi", "]", "[", "vi", "]", "\n", "# print(orig.size())", "\n", "new_videos", "[", "vi", "]", "[", "bi", ",", ":", ",", ":", ",", ":", "orig", ".", "shape", "[", "-", "2", "]", ",", ":", "orig", ".", "shape", "[", "-", "1", "]", "]", "=", "orig", "\n", "\n", "", "", "", "dict_batch", "[", "video_key", "]", "=", "new_videos", "\n", "\n", "", "txt_keys", "=", "[", "k", "for", "k", "in", "list", "(", "dict_batch", ".", "keys", "(", ")", ")", "if", "\"text\"", "in", "k", "]", "\n", "# print(txt_keys)", "\n", "if", "len", "(", "txt_keys", ")", "!=", "0", ":", "\n", "            ", "texts", "=", "[", "[", "d", "[", "0", "]", "for", "d", "in", "dict_batch", "[", "txt_key", "]", "]", "for", "txt_key", "in", "txt_keys", "]", "\n", "encodings", "=", "[", "[", "d", "[", "1", "]", "for", "d", "in", "dict_batch", "[", "txt_key", "]", "]", "for", "txt_key", "in", "txt_keys", "]", "\n", "draw_text_len", "=", "len", "(", "encodings", ")", "\n", "flatten_encodings", "=", "[", "e", "for", "encoding", "in", "encodings", "for", "e", "in", "encoding", "]", "\n", "flatten_mlms", "=", "mlm_collator", "(", "flatten_encodings", ")", "\n", "\n", "for", "i", ",", "txt_key", "in", "enumerate", "(", "txt_keys", ")", ":", "\n", "                ", "texts", ",", "encodings", "=", "(", "\n", "[", "d", "[", "0", "]", "for", "d", "in", "dict_batch", "[", "txt_key", "]", "]", ",", "\n", "[", "d", "[", "1", "]", "for", "d", "in", "dict_batch", "[", "txt_key", "]", "]", ",", "\n", ")", "\n", "\n", "mlm_ids", ",", "mlm_labels", "=", "(", "\n", "flatten_mlms", "[", "\"input_ids\"", "]", "[", "batch_size", "*", "(", "i", ")", ":", "batch_size", "*", "(", "i", "+", "1", ")", "]", ",", "\n", "flatten_mlms", "[", "\"labels\"", "]", "[", "batch_size", "*", "(", "i", ")", ":", "batch_size", "*", "(", "i", "+", "1", ")", "]", ",", "\n", ")", "\n", "\n", "input_ids", "=", "torch", ".", "zeros_like", "(", "mlm_ids", ")", "\n", "attention_mask", "=", "torch", ".", "zeros_like", "(", "mlm_ids", ")", "\n", "for", "_i", ",", "encoding", "in", "enumerate", "(", "encodings", ")", ":", "\n", "                    ", "_input_ids", ",", "_attention_mask", "=", "(", "\n", "torch", ".", "tensor", "(", "encoding", "[", "\"input_ids\"", "]", ")", ",", "\n", "torch", ".", "tensor", "(", "encoding", "[", "\"attention_mask\"", "]", ")", ",", "\n", ")", "\n", "input_ids", "[", "_i", ",", ":", "len", "(", "_input_ids", ")", "]", "=", "_input_ids", "\n", "attention_mask", "[", "_i", ",", ":", "len", "(", "_attention_mask", ")", "]", "=", "_attention_mask", "\n", "\n", "", "dict_batch", "[", "txt_key", "]", "=", "texts", "\n", "dict_batch", "[", "f\"{txt_key}_ids\"", "]", "=", "input_ids", "\n", "dict_batch", "[", "f\"{txt_key}_labels\"", "]", "=", "torch", ".", "full_like", "(", "input_ids", ",", "-", "100", ")", "\n", "dict_batch", "[", "f\"{txt_key}_ids_mlm\"", "]", "=", "mlm_ids", "\n", "dict_batch", "[", "f\"{txt_key}_labels_mlm\"", "]", "=", "mlm_labels", "\n", "dict_batch", "[", "f\"{txt_key}_masks\"", "]", "=", "attention_mask", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.video_base_dataset.sample_frames": [[269, 285], ["min", "numpy.linspace().astype", "enumerate", "ranges.append", "numpy.linspace", "random.choice", "range"], "function", ["None"], ["\n", "# def collate(self, batch, mlm_collator):", "\n", "#     batch_size = len(batch)", "\n", "#     keys = set([key for b in batch for key in b.keys()])", "\n", "#     dict_batch = {k: [dic[k] if k in dic else None for dic in batch] for k in keys}", "\n", "#", "\n", "#     video_keys = [k for k in list(dict_batch.keys()) if \"video\" in k]", "\n", "#     video_sizes = list()", "\n", "#", "\n", "#     # global & local video", "\n", "#     for video_key in video_keys:", "\n", "#         video_sizes += [ii.shape for i in dict_batch[video_key][0] if i is not None for ii in i]", "\n", "#         # print(global_video_sizes, local_video_sizes)", "\n", "#", "\n", "#     for size in video_sizes:", "\n", "#         # print(size)", "\n", "#         assert (", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.video_base_dataset.read_frames_gif": [[287, 308], ["imageio.get_reader", "len", "video_base_dataset.sample_frames", "enumerate", "torch.stack", "cv2.cvtColor", "torch.from_numpy().byte", "frame.permute.permute", "torch.stack.append", "torch.from_numpy"], "function", ["home.repos.pwc.inspect_result.showlab_all-in-one.datasets.base_dataset.sample_frames"], ["#         ), f\"Collate error, an video should be in shape of (T, N, H, W), instead of given {size}\"", "\n", "#", "\n", "#     if len(video_keys) != 0:", "\n", "#         global_max_height = max([i[2] for i in video_sizes])", "\n", "#         global_max_width = max([i[3] for i in video_sizes])", "\n", "#         local_max_height = min([i[2] for i in video_sizes])", "\n", "#         local_max_width = min([i[3] for i in video_sizes])", "\n", "#     for video_key in video_keys:", "\n", "#         video = dict_batch[video_key]", "\n", "#         global_view_size = len(dict_batch[video_key][0][0])", "\n", "#         local_view_size = len(dict_batch[video_key][0][1])", "\n", "#         # print(global_view_size, local_view_size)", "\n", "#", "\n", "#         new_videos = [", "\n", "#         [", "\n", "#             torch.zeros(batch_size, self.num_frames, 3, global_max_height, global_max_width)", "\n", "#             for _ in range(global_view_size)", "\n", "#         ],", "\n", "#         [", "\n", "#             torch.zeros(batch_size, self.num_frames, 3, local_max_height, local_max_width)", "\n", "#             for _ in range(local_view_size)", "\n", "#         ]", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.video_base_dataset.read_frames_cv2": [[310, 343], ["cv2.VideoCapture", "cv2.VideoCapture.isOpened", "int", "video_base_dataset.sample_frames", "torch.stack", "cv2.VideoCapture.release", "cv2.VideoCapture.get", "cv2.VideoCapture.set", "cv2.VideoCapture.read", "cv2.cvtColor", "torch.from_numpy().byte", "frame.permute.permute", "torch.stack.append", "success_idxs.append", "torch.from_numpy"], "function", ["home.repos.pwc.inspect_result.showlab_all-in-one.datasets.base_dataset.sample_frames"], ["#         # print(len(img))", "\n", "#         for bi in range(batch_size):", "\n", "#             orig_batch = video[bi]", "\n", "#             for vi in range(global_view_size):", "\n", "#                 if orig_batch is None:", "\n", "#                     # new_videos[vi][bi] = None", "\n", "#                     # modify by alex", "\n", "#                     continue", "\n", "#                 else:", "\n", "#                     orig = video[bi][0][vi]", "\n", "#                     # print(orig.size())", "\n", "#                     new_videos[0][vi][bi, :, :, : orig.shape[-2], : orig.shape[-1]] = orig", "\n", "#", "\n", "#         for bi in range(batch_size):", "\n", "#             orig_batch = video[bi]", "\n", "#             for vi in range(local_view_size):", "\n", "#                 if orig_batch is None:", "\n", "#                     # new_videos[vi][bi] = None", "\n", "#                     # modify by alex", "\n", "#                     continue", "\n", "#                 else:", "\n", "#                     orig = video[bi][1][vi]", "\n", "#                     # print(orig.size())", "\n", "#                     new_videos[1][vi][bi, :, :, : orig.shape[-2], : orig.shape[-1]] = orig", "\n", "#         dict_batch[video_key] = new_videos", "\n", "#", "\n", "#     txt_keys = [k for k in list(dict_batch.keys()) if \"text\" in k]", "\n", "#     # print(txt_keys)", "\n", "#     if len(txt_keys) != 0:", "\n", "#         texts = [[d[0] for d in dict_batch[txt_key]] for txt_key in txt_keys]", "\n", "#         encodings = [[d[1] for d in dict_batch[txt_key]] for txt_key in txt_keys]", "\n", "#         draw_text_len = len(encodings)", "\n", "#         flatten_encodings = [e for encoding in encodings for e in encoding]", "\n", "#         flatten_mlms = mlm_collator(flatten_encodings)", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.video_base_dataset.read_frames_decord": [[345, 359], ["decord.VideoReader", "decord.bridge.set_bridge", "len", "video_base_dataset.sample_frames", "decord.VideoReader.get_batch().byte", "frames.permute.permute", "decord.cpu", "decord.VideoReader.get_batch"], "function", ["home.repos.pwc.inspect_result.showlab_all-in-one.datasets.base_dataset.sample_frames"], ["#         for i, txt_key in enumerate(txt_keys):", "\n", "#             texts, encodings = (", "\n", "#                 [d[0] for d in dict_batch[txt_key]],", "\n", "#                 [d[1] for d in dict_batch[txt_key]],", "\n", "#             )", "\n", "#", "\n", "#             mlm_ids, mlm_labels = (", "\n", "#                 flatten_mlms[\"input_ids\"][batch_size * (i) : batch_size * (i + 1)],", "\n", "#                 flatten_mlms[\"labels\"][batch_size * (i) : batch_size * (i + 1)],", "\n", "#             )", "\n", "#", "\n", "#             input_ids = torch.zeros_like(mlm_ids)", "\n", "#             attention_mask = torch.zeros_like(mlm_ids)", "\n", "#             for _i, encoding in enumerate(encodings):", "\n", "#                 _input_ids, _attention_mask = (", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.video_base_dataset.read_frames_from_img_dir": [[361, 376], ["len", "video_base_dataset.sample_frames", "frames.permute.permute", "os.listdir", "cv2.imread", "torch.from_numpy().byte", "frame.permute.permute", "frames.permute.append", "os.path.join", "torch.from_numpy", "string().zfill", "string"], "function", ["home.repos.pwc.inspect_result.showlab_all-in-one.datasets.base_dataset.sample_frames"], ["#                     torch.tensor(encoding[\"attention_mask\"]),", "\n", "#                 )", "\n", "#                 input_ids[_i, : len(_input_ids)] = _input_ids", "\n", "#                 attention_mask[_i, : len(_attention_mask)] = _attention_mask", "\n", "#", "\n", "#             dict_batch[txt_key] = texts", "\n", "#             dict_batch[f\"{txt_key}_ids\"] = input_ids", "\n", "#             dict_batch[f\"{txt_key}_labels\"] = torch.full_like(input_ids, -100)", "\n", "#             dict_batch[f\"{txt_key}_ids_mlm\"] = mlm_ids", "\n", "#             dict_batch[f\"{txt_key}_labels_mlm\"] = mlm_labels", "\n", "#             dict_batch[f\"{txt_key}_masks\"] = attention_mask", "\n", "#", "\n", "#     return dict_batch", "\n", "\n", "\n", "", "", "def", "sample_frames", "(", "num_frames", ",", "vlen", ",", "sample", "=", "'rand'", ",", "fix_start", "=", "None", ")", ":", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.video_base_dataset.sample_frames_2": [[378, 382], ["None"], "function", ["None"], ["intervals", "=", "np", ".", "linspace", "(", "start", "=", "0", ",", "stop", "=", "vlen", ",", "num", "=", "acc_samples", "+", "1", ")", ".", "astype", "(", "int", ")", "\n", "ranges", "=", "[", "]", "\n", "for", "idx", ",", "interv", "in", "enumerate", "(", "intervals", "[", ":", "-", "1", "]", ")", ":", "\n", "        ", "ranges", ".", "append", "(", "(", "interv", ",", "intervals", "[", "idx", "+", "1", "]", "-", "1", ")", ")", "\n", "", "if", "sample", "==", "'rand'", ":", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.video_base_dataset.read_large_frames_decord": [[384, 408], ["decord.VideoReader", "decord.bridge.set_bridge", "video_base_dataset.sample_frames", "range", "decord.VideoReader.get_batch().byte", "frames.permute.permute", "len", "min", "max", "decord.cpu", "decord.VideoReader.get_batch"], "function", ["home.repos.pwc.inspect_result.showlab_all-in-one.datasets.base_dataset.sample_frames"], ["", "elif", "fix_start", "is", "not", "None", ":", "\n", "        ", "frame_idxs", "=", "[", "x", "[", "0", "]", "+", "fix_start", "for", "x", "in", "ranges", "]", "\n", "", "elif", "sample", "==", "'uniform'", ":", "\n", "        ", "frame_idxs", "=", "[", "(", "x", "[", "0", "]", "+", "x", "[", "1", "]", ")", "//", "2", "for", "x", "in", "ranges", "]", "\n", "", "else", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n", "", "return", "frame_idxs", "\n", "\n", "\n", "", "def", "read_frames_gif", "(", "video_path", ",", "num_frames", ",", "mode", "=", "'train'", ",", "fix_start", "=", "None", ")", ":", "\n", "    ", "if", "mode", "==", "'train'", ":", "\n", "        ", "sample", "=", "'rand'", "\n", "", "else", ":", "\n", "        ", "sample", "=", "'uniform'", "\n", "", "gif", "=", "imageio", ".", "get_reader", "(", "video_path", ")", "\n", "vlen", "=", "len", "(", "gif", ")", "\n", "frame_idxs", "=", "sample_frames", "(", "num_frames", ",", "vlen", ",", "sample", "=", "sample", ",", "fix_start", "=", "fix_start", ")", "\n", "frames", "=", "[", "]", "\n", "for", "index", ",", "frame", "in", "enumerate", "(", "gif", ")", ":", "\n", "# for index in frame_idxs:", "\n", "        ", "if", "index", "in", "frame_idxs", ":", "\n", "            ", "frame", "=", "cv2", ".", "cvtColor", "(", "frame", ",", "cv2", ".", "COLOR_RGBA2RGB", ")", "\n", "frame", "=", "torch", ".", "from_numpy", "(", "frame", ")", ".", "byte", "(", ")", "\n", "# # (H x W x C) to (C x H x W)", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.video_base_dataset.video_clip_reader": [[410, 445], ["cv2.VideoCapture", "int", "video_base_dataset.sample_frames", "int", "max", "min", "torch.stack", "cv2.VideoCapture.release", "cv2.VideoCapture.get", "int", "cv2.VideoCapture.set", "cv2.VideoCapture.read", "torch.cat.size", "torch.ones().byte", "torch.cat", "torch.cat.size", "Exception", "cv2.cvtColor", "torch.from_numpy().byte", "frame.permute.permute", "torch.cat.append", "success_idxs.append", "torch.ones", "torch.from_numpy", "torch.cat.size", "torch.cat.size", "torch.cat.size"], "function", ["home.repos.pwc.inspect_result.showlab_all-in-one.datasets.base_dataset.sample_frames"], ["# frame = Image.fromarray(frame)", "\n", "frames", ".", "append", "(", "frame", ")", "\n", "", "", "frames", "=", "torch", ".", "stack", "(", "frames", ")", "# .float() / 255", "\n", "# print(frames.size())", "\n", "return", "frames", ",", "frame_idxs", ",", "vlen", "\n", "\n", "\n", "", "def", "read_frames_cv2", "(", "video_path", ",", "num_frames", ",", "sample", "=", "'rand'", ",", "fix_start", "=", "None", ")", ":", "\n", "# print(video_path)", "\n", "    ", "cap", "=", "cv2", ".", "VideoCapture", "(", "video_path", ")", "\n", "assert", "(", "cap", ".", "isOpened", "(", ")", ")", "\n", "# for decord", "\n", "# cap.set(3, 256)", "\n", "# cap.set(4, 256)", "\n", "vlen", "=", "int", "(", "cap", ".", "get", "(", "cv2", ".", "CAP_PROP_FRAME_COUNT", ")", ")", "\n", "# get indexes of sampled frames", "\n", "frame_idxs", "=", "sample_frames", "(", "num_frames", ",", "vlen", ",", "sample", "=", "sample", ",", "fix_start", "=", "fix_start", ")", "\n", "frames", "=", "[", "]", "\n", "success_idxs", "=", "[", "]", "\n", "for", "index", "in", "frame_idxs", ":", "\n", "        ", "cap", ".", "set", "(", "cv2", ".", "CAP_PROP_POS_FRAMES", ",", "index", "-", "1", ")", "\n", "ret", ",", "frame", "=", "cap", ".", "read", "(", ")", "\n", "if", "ret", ":", "\n", "            ", "frame", "=", "cv2", ".", "cvtColor", "(", "frame", ",", "cv2", ".", "COLOR_BGR2RGB", ")", "\n", "frame", "=", "torch", ".", "from_numpy", "(", "frame", ")", ".", "byte", "(", ")", "\n", "# # (H x W x C) to (C x H x W)", "\n", "frame", "=", "frame", ".", "permute", "(", "2", ",", "0", ",", "1", ")", "\n", "# frame = Image.fromarray(frame)", "\n", "frames", ".", "append", "(", "frame", ")", "\n", "success_idxs", ".", "append", "(", "index", ")", "\n", "", "else", ":", "\n", "            ", "pass", "\n", "# print(frame_idxs, ' fail ', index, f'  (vlen {vlen})')", "\n", "# return frames tensor", "\n", "# convert cv to PIL", "\n", "# img = Image.fromarray(imgs[0])", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.video_base_dataset.video_reader": [[447, 480], ["cv2.VideoCapture", "cv2.VideoCapture.isOpened", "int", "video_base_dataset.sample_frames", "torch.stack", "cv2.VideoCapture.release", "cv2.VideoCapture.get", "max", "min", "cv2.VideoCapture.set", "cv2.VideoCapture.read", "random.random", "cv2.cvtColor", "torch.from_numpy().byte", "frame.permute.permute", "torch.stack.append", "success_idxs.append", "torch.from_numpy"], "function", ["home.repos.pwc.inspect_result.showlab_all-in-one.datasets.base_dataset.sample_frames"], ["# print(frames.size())", "\n", "cap", ".", "release", "(", ")", "\n", "return", "frames", ",", "success_idxs", ",", "vlen", "\n", "\n", "\n", "", "def", "read_frames_decord", "(", "video_path", ",", "num_frames", ",", "mode", "=", "'train'", ",", "fix_start", "=", "None", ")", ":", "\n", "# print(\"video path: {}\".format(video_path))", "\n", "    ", "if", "mode", "in", "[", "'train'", ",", "'val'", "]", ":", "\n", "        ", "sample", "=", "'rand'", "\n", "", "else", ":", "\n", "        ", "sample", "=", "'uniform'", "\n", "", "video_reader", "=", "decord", ".", "VideoReader", "(", "video_path", ",", "width", "=", "512", ",", "height", "=", "512", ",", "num_threads", "=", "1", ",", "ctx", "=", "cpu", "(", "0", ")", ")", "\n", "# video_reader = decord.VideoReader(video_path, width=256, height=256, num_threads=1, ctx=cpu(0))", "\n", "decord", ".", "bridge", ".", "set_bridge", "(", "'torch'", ")", "\n", "vlen", "=", "len", "(", "video_reader", ")", "\n", "frame_idxs", "=", "sample_frames", "(", "num_frames", ",", "vlen", ",", "sample", "=", "sample", ",", "fix_start", "=", "fix_start", ")", "\n", "frames", "=", "video_reader", ".", "get_batch", "(", "frame_idxs", ")", ".", "byte", "(", ")", "\n", "frames", "=", "frames", ".", "permute", "(", "0", ",", "3", ",", "1", ",", "2", ")", "\n", "return", "frames", ",", "frame_idxs", ",", "vlen", "\n", "\n", "\n", "", "def", "read_frames_from_img_dir", "(", "video_path", ",", "num_frames", ",", "mode", "=", "'train'", ",", "fix_start", "=", "None", ",", "suffix", "=", "'.jpg'", ")", ":", "\n", "    ", "if", "mode", "in", "[", "'train'", ",", "'val'", "]", ":", "\n", "        ", "sample", "=", "'rand'", "\n", "", "else", ":", "\n", "        ", "sample", "=", "'uniform'", "\n", "", "vlen", "=", "len", "(", "os", ".", "listdir", "(", "video_path", ")", ")", "\n", "frame_idxs", "=", "sample_frames", "(", "num_frames", ",", "vlen", ",", "sample", "=", "sample", ",", "fix_start", "=", "fix_start", ")", "\n", "frames", "=", "[", "]", "\n", "for", "idx", "in", "frame_idxs", ":", "\n", "        ", "frame", "=", "cv2", ".", "imread", "(", "os", ".", "path", ".", "join", "(", "video_path", ",", "string", "(", "idx", ")", ".", "zfill", "(", "3", ")", "+", "suffix", ")", ")", "\n", "frame", "=", "torch", ".", "from_numpy", "(", "frame", ")", ".", "byte", "(", ")", "\n", "frame", "=", "frame", ".", "permute", "(", "2", ",", "0", ",", "1", ")", "\n", "frames", ".", "append", "(", "frame", ")", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.video_base_dataset.fast_decode": [[482, 525], ["cv2.VideoCapture", "int", "cv2.VideoCapture.release", "random.randint", "ffmpeg.input().filter", "cmd.hflip.output().run", "numpy.frombuffer().reshape", "torch.from_numpy", "video.permute.permute", "cv2.VideoCapture.get", "float", "int", "cmd.hflip.crop", "cmd.hflip.crop().filter", "cmd.hflip.hflip", "max", "ffmpeg.input", "random.uniform", "random.uniform", "str", "str", "random.uniform", "cmd.hflip.output", "numpy.frombuffer", "cmd.hflip.crop"], "function", ["None"], ["return", "frames", ",", "frame_idxs", ",", "vlen", "\n", "\n", "\n", "", "def", "sample_frames_2", "(", "frame_loc", ",", "vlen", ",", "frame_end", ")", ":", "\n", "    ", "assert", "frame_loc", "<=", "frame_end", "\n", "frame_idxs", "=", "[", "frame_loc", "]", "\n", "return", "frame_idxs", "\n", "\n", "\n", "", "def", "read_large_frames_decord", "(", "video_path", ",", "frame_loc", ",", "frame_end", ",", "num_frames", ",", "mode", "=", "'train'", ",", "fix_start", "=", "None", ")", ":", "\n", "# print('*'*100)", "\n", "# print(mode)", "\n", "    ", "if", "mode", "==", "'train'", ":", "\n", "        ", "sample", "=", "'rand'", "\n", "", "else", ":", "\n", "        ", "sample", "=", "'uniform'", "\n", "# video_reader = decord.VideoReader(video_path, width=256, height=256, num_threads=1, ctx=cpu(0))", "\n", "", "video_reader", "=", "decord", ".", "VideoReader", "(", "video_path", ",", "width", "=", "512", ",", "height", "=", "512", ",", "num_threads", "=", "1", ",", "ctx", "=", "cpu", "(", "0", ")", ")", "\n", "decord", ".", "bridge", ".", "set_bridge", "(", "'torch'", ")", "\n", "# vlen = len(video_reader)", "\n", "frame_idxs", "=", "sample_frames", "(", "num_frames", ",", "120", ",", "sample", "=", "sample", ",", "fix_start", "=", "fix_start", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "frame_idxs", ")", ")", ":", "\n", "# if random.random() < 0.5:", "\n", "#     frame_idxs[i] += frame_loc - 60", "\n", "# else:", "\n", "#     frame_idxs[i] += frame_loc", "\n", "        ", "frame_idxs", "[", "i", "]", "+=", "frame_loc", "-", "60", "\n", "frame_idxs", "[", "i", "]", "=", "min", "(", "frame_idxs", "[", "i", "]", ",", "frame_end", "-", "1", ")", "\n", "frame_idxs", "[", "i", "]", "=", "max", "(", "0", ",", "frame_idxs", "[", "i", "]", ")", "\n", "# print(frame_loc, frame_end, frame_idxs)", "\n", "", "frames", "=", "video_reader", ".", "get_batch", "(", "frame_idxs", ")", ".", "byte", "(", ")", "\n", "frames", "=", "frames", ".", "permute", "(", "0", ",", "3", ",", "1", ",", "2", ")", "\n", "return", "frames", "\n", "\n", "\n", "", "def", "video_clip_reader", "(", "video_path", ",", "begin_time", ",", "end_time", ",", "duration", ",", "num_frames", ")", ":", "\n", "    ", "cap", "=", "cv2", ".", "VideoCapture", "(", "video_path", ")", "\n", "# assert (cap.isOpened())", "\n", "vlen", "=", "int", "(", "cap", ".", "get", "(", "cv2", ".", "CAP_PROP_FRAME_COUNT", ")", ")", "\n", "# print(video_path, begin_time, end_time, duration, num_frames, vlen)", "\n", "average_fps", "=", "vlen", "/", "duration", "\n", "clip_len", "=", "(", "end_time", "-", "begin_time", ")", "*", "average_fps", "\n", "frame_idxs", "=", "sample_frames", "(", "num_frames", ",", "int", "(", "clip_len", ")", ",", "sample", "=", "'rand'", ")", "\n", "frames", "=", "[", "]", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.video_base_dataset.color_img": [[538, 567], ["range", "len", "cv2.addWeighted", "cv2.rectangle", "boxes.append", "numpy.ones", "int", "int", "int", "int", "int", "int", "int", "int", "int", "int", "int", "int"], "function", ["None"], ["# frame = Image.fromarray(frame)", "\n", "frames", ".", "append", "(", "frame", ")", "\n", "success_idxs", ".", "append", "(", "index", ")", "\n", "", "else", ":", "\n", "            ", "pass", "\n", "# print(frame_idxs, ' fail ', index, f'  (vlen {vlen})')", "\n", "", "", "frames", "=", "torch", ".", "stack", "(", "frames", ")", "\n", "cap", ".", "release", "(", ")", "\n", "if", "frames", ".", "size", "(", "0", ")", "<", "num_frames", ":", "\n", "        ", "zeros", "=", "torch", ".", "ones", "(", "(", "num_frames", "-", "frames", ".", "size", "(", "1", ")", ",", "3", ",", "frames", ".", "size", "(", "-", "2", ")", ",", "frames", ".", "size", "(", "-", "1", ")", ")", ",", "dtype", "=", "torch", ".", "uint8", ")", ".", "byte", "(", ")", "\n", "frames", "=", "torch", ".", "cat", "(", "(", "frames", ",", "zeros", ")", ",", "axis", "=", "1", ")", "\n", "", "if", "frames", ".", "size", "(", "0", ")", "!=", "num_frames", ":", "\n", "        ", "Exception", "(", "RuntimeError", ")", "\n", "", "return", "frames", "\n", "\n", "\n", "", "def", "video_reader", "(", "video_path", ",", "frame_loc", ",", "frame_end", ",", "num_frames", ")", ":", "\n", "    ", "cap", "=", "cv2", ".", "VideoCapture", "(", "video_path", ")", "\n", "assert", "(", "cap", ".", "isOpened", "(", ")", ")", "\n", "vlen", "=", "int", "(", "cap", ".", "get", "(", "cv2", ".", "CAP_PROP_FRAME_COUNT", ")", ")", "\n", "# get indexes of sampled frames fps is 30, 4s", "\n", "frame_idxs", "=", "sample_frames", "(", "num_frames", ",", "120", ",", "sample", "=", "'rand'", ")", "\n", "# frame_idxs = sample_frames_2(frame_loc, vlen, frame_end)", "\n", "frames", "=", "[", "]", "\n", "success_idxs", "=", "[", "]", "\n", "\n", "for", "index", "in", "frame_idxs", ":", "\n", "        ", "if", "random", ".", "random", "(", ")", "<", "0.5", ":", "\n", "            ", "rel_index", "=", "index", "+", "frame_loc", "-", "120", "\n", "", "else", ":", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.video_base_dataset.get_video_len": [[569, 574], ["cv2.VideoCapture", "int", "cv2.VideoCapture.release", "cv2.VideoCapture.get"], "function", ["None"], ["", "rel_index", "=", "max", "(", "rel_index", ",", "0", ")", "\n", "rel_index", "=", "min", "(", "rel_index", ",", "frame_end", ")", "\n", "cap", ".", "set", "(", "cv2", ".", "CAP_PROP_POS_FRAMES", ",", "rel_index", ")", "\n", "ret", ",", "frame", "=", "cap", ".", "read", "(", ")", "\n", "if", "ret", ":", "\n", "            ", "frame", "=", "cv2", ".", "cvtColor", "(", "frame", ",", "cv2", ".", "COLOR_BGR2RGB", ")", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.video_base_dataset.align_using_dtw": [[576, 621], ["int", "enumerate", "tslearn.metrics.dtw_path_from_metric", "max", "len", "len", "numpy.zeros", "x.translate().strip().lower", "video_base_dataset.align_using_dtw._preprocess_text"], "function", ["None"], ["# # (H x W x C) to (C x H x W)", "\n", "frame", "=", "frame", ".", "permute", "(", "2", ",", "0", ",", "1", ")", "\n", "# frame = Image.fromarray(frame)", "\n", "frames", ".", "append", "(", "frame", ")", "\n", "success_idxs", ".", "append", "(", "index", ")", "\n", "", "else", ":", "\n", "            ", "pass", "\n", "# print(frame_idxs, ' fail ', index, f'  (vlen {vlen})')", "\n", "", "", "frames", "=", "torch", ".", "stack", "(", "frames", ")", "\n", "cap", ".", "release", "(", ")", "\n", "return", "frames", "\n", "\n", "\n", "", "def", "fast_decode", "(", "video_path", ",", "num_frames", ",", "mode", "=", "'train'", ",", "fix_start", "=", "None", ",", "fps", "=", "30", ")", ":", "\n", "    ", "cap", "=", "cv2", ".", "VideoCapture", "(", "video_path", ")", "\n", "vlen", "=", "int", "(", "cap", ".", "get", "(", "cv2", ".", "CAP_PROP_FRAME_COUNT", ")", ")", "\n", "cap", ".", "release", "(", ")", "\n", "max_len", "=", "vlen", "/", "30", "\n", "num_sec", "=", "num_frames", "/", "float", "(", "fps", ")", "\n", "size", "=", "224", "\n", "crop_only", "=", "True", "\n", "random_flip", "=", "True", "\n", "start_seek", "=", "random", ".", "randint", "(", "0", ",", "int", "(", "max", "(", "max_len", ",", "max_len", "-", "num_sec", ")", ")", ")", "\n", "cmd", "=", "(", "\n", "ffmpeg", "\n", ".", "input", "(", "video_path", ",", "ss", "=", "start_seek", ",", "t", "=", "num_sec", "+", "0.1", ")", "\n", ".", "filter", "(", "'fps'", ",", "fps", "=", "fps", ")", "\n", ")", "\n", "if", "mode", "==", "'train'", ":", "\n", "        ", "aw", ",", "ah", "=", "random", ".", "uniform", "(", "0", ",", "1", ")", ",", "random", ".", "uniform", "(", "0", ",", "1", ")", "\n", "", "else", ":", "\n", "        ", "aw", ",", "ah", "=", "0.5", ",", "0.5", "\n", "", "if", "crop_only", ":", "\n", "        ", "cmd", "=", "(", "\n", "cmd", ".", "crop", "(", "'(iw - {})*{}'", ".", "format", "(", "size", ",", "aw", ")", ",", "\n", "'(ih - {})*{}'", ".", "format", "(", "size", ",", "ah", ")", ",", "\n", "str", "(", "size", ")", ",", "str", "(", "size", ")", ")", "\n", ")", "\n", "", "else", ":", "\n", "        ", "cmd", "=", "(", "\n", "cmd", ".", "crop", "(", "'(iw - min(iw,ih))*{}'", ".", "format", "(", "aw", ")", ",", "\n", "'(ih - min(iw,ih))*{}'", ".", "format", "(", "ah", ")", ",", "\n", "'min(iw,ih)'", ",", "\n", "'min(iw,ih)'", ")", "\n", ".", "filter", "(", "'scale'", ",", "size", ",", "size", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.video_base_dataset.clean_subtitles": [[623, 639], ["ftfy.ftfy", "new_dicts.append", "x[].startswith", "x[].endswith", "len"], "function", ["None"], ["        ", "cmd", "=", "cmd", ".", "hflip", "(", ")", "\n", "", "out", ",", "_", "=", "(", "\n", "cmd", ".", "output", "(", "'pipe:'", ",", "format", "=", "'rawvideo'", ",", "pix_fmt", "=", "'rgb24'", ")", "\n", ".", "run", "(", "capture_stdout", "=", "True", ",", "quiet", "=", "True", ")", "\n", ")", "\n", "video", "=", "np", ".", "frombuffer", "(", "out", ",", "np", ".", "uint8", ")", ".", "reshape", "(", "[", "-", "1", ",", "size", ",", "size", ",", "3", "]", ")", "\n", "video", "=", "torch", ".", "from_numpy", "(", "video", ")", "\n", "video", "=", "video", ".", "permute", "(", "3", ",", "0", ",", "1", ",", "2", ")", "\n", "return", "video", ",", "_", ",", "_", "\n", "\n", "\n", "# 21", "\n", "", "colormaps", "=", "[", "(", "255", ",", "0", ",", "0", ")", ",", "(", "0", ",", "255", ",", "0", ")", ",", "\n", "(", "0", ",", "0", ",", "255", ")", ",", "(", "61", ",", "145", ",", "64", ")", ",", "(", "127", ",", "255", ",", "212", ")", ",", "(", "0", ",", "201", ",", "87", ")", ",", "\n", "(", "218", ",", "112", ",", "214", ")", ",", "(", "255", ",", "0", ",", "255", ")", ",", "(", "112", ",", "128", ",", "105", ")", ",", "(", "250", ",", "235", ",", "215", ")", ",", "\n", "(", "240", ",", "255", ",", "255", ")", ",", "(", "252", ",", "230", ",", "201", ")", ",", "(", "255", ",", "255", ",", "0", ")", ",", "(", "235", ",", "142", ",", "85", ")", ",", "\n", "(", "255", ",", "97", ",", "0", ")", ",", "(", "176", ",", "224", ",", "230", ")", ",", "(", "65", ",", "106", ",", "225", ",", ")", ",", "(", "0", ",", "255", ",", "255", ")", ",", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.video_base_dataset.clean_description": [[641, 658], ["demoji.findall", "demoji.findall.items", "text.replace.strip", "regex.sub", "regex.sub", "regex.sub", "text.replace.strip", "text.replace.replace"], "function", ["None"], ["\n", "\n", "# only_use_relevant_dets ?", "\n", "\n", "def", "color_img", "(", "im", ",", "object_meta", ",", "relevant_dets", ",", "only_use_relevant_dets", "=", "True", ")", ":", "\n", "# mask detected region", "\n", "# only_use_relevant_dets: if true, we only mask regions that mentioned in question & answers", "\n", "# print(relevant_dets)", "\n", "    ", "if", "only_use_relevant_dets", ":", "\n", "        ", "boxes", "=", "[", "]", "\n", "for", "index", "in", "relevant_dets", ":", "\n", "            ", "boxes", ".", "append", "(", "object_meta", "[", "'boxes'", "]", "[", "index", "]", ")", "\n", "# print(object_meta['names'][index])", "\n", "# object_index = relevant_dets", "\n", "", "", "else", ":", "\n", "        ", "boxes", "=", "object_meta", "[", "'boxes'", "]", "\n", "# print(len(boxes))", "\n", "# range(len(boxes))", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.sbu_caption_dataset.SBUCaptionDataset.__init__": [[6, 17], ["base_dataset.BaseDataset.__init__", "range"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.transforms.utils.UnNormalize.__init__"], ["    ", "def", "__init__", "(", "self", ",", "*", "args", ",", "split", "=", "\"\"", ",", "**", "kwargs", ")", ":", "\n", "        ", "assert", "split", "in", "[", "\"train\"", ",", "\"val\"", ",", "\"test\"", "]", "\n", "if", "split", "==", "\"test\"", ":", "\n", "            ", "split", "=", "\"val\"", "\n", "\n", "", "if", "split", "==", "\"train\"", ":", "\n", "            ", "names", "=", "[", "f\"sbu_{i}\"", "for", "i", "in", "range", "(", "9", ")", "]", "\n", "", "elif", "split", "==", "\"val\"", ":", "\n", "            ", "names", "=", "[", "]", "\n", "\n", "", "super", "(", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ",", "names", "=", "names", ",", "text_column_name", "=", "\"caption\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.sbu_caption_dataset.SBUCaptionDataset.__getitem__": [[18, 20], ["sbu_caption_dataset.SBUCaptionDataset.get_suite"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_v2.Ego4DDataset.get_suite"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "return", "self", ".", "get_suite", "(", "index", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d.Ego4DDataset.__init__": [[22, 35], ["video_base_dataset.BaseDataset.__init__", "ego4d.Ego4DDataset._load_metadata"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.transforms.utils.UnNormalize.__init__", "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_v2.Ego4DDataset._load_metadata"], ["", "super", "(", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ",", "names", "=", "names", ",", "text_column_name", "=", "\"caption\"", ")", "\n", "\n", "self", ".", "_load_metadata", "(", ")", "\n", "\n", "", "def", "_load_metadata", "(", "self", ")", ":", "\n", "        ", "metadata_dir", "=", "'./meta_data/ego4d'", "\n", "split_files", "=", "{", "\n", "'train'", ":", "'ego4d_train_subset.csv'", ",", "\n", "'val'", ":", "'ego4d_val_ts_clean.csv'", ",", "\n", "'test'", ":", "'ego4d_val_ts_clean.csv'", "# there is no test", "\n", "}", "\n", "target_split_fp", "=", "split_files", "[", "self", ".", "split", "]", "\n", "self", ".", "metadata", "=", "pd", ".", "read_csv", "(", "os", ".", "path", ".", "join", "(", "metadata_dir", ",", "target_split_fp", ")", ",", "sep", "=", "'\\t'", ",", "header", "=", "None", ",", "error_bad_lines", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d.Ego4DDataset._load_metadata": [[36, 45], ["pandas.read_csv", "os.path.join"], "methods", ["None"], ["", "def", "_get_video_path", "(", "self", ",", "sample", ")", ":", "\n", "        ", "rel_video_fp", "=", "sample", "[", "0", "]", "+", "'.mp4'", "\n", "full_video_fp", "=", "os", ".", "path", ".", "join", "(", "self", ".", "data_dir", ",", "'videos'", ",", "rel_video_fp", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "full_video_fp", ")", ":", "\n", "            ", "Exception", "(", "IOError", ")", "\n", "", "return", "full_video_fp", ",", "rel_video_fp", "\n", "\n", "", "def", "_get_caption", "(", "self", ",", "sample", ")", ":", "\n", "        ", "return", "sample", "[", "6", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d.Ego4DDataset._get_video_path": [[46, 52], ["os.path.join", "os.path.exists", "Exception"], "methods", ["None"], ["", "def", "get_raw_video", "(", "self", ",", "sample", ")", ":", "\n", "        ", "abs_fp", ",", "rel_fp", "=", "self", ".", "_get_video_path", "(", "sample", ")", "\n", "# if int(sample[2]) > 600:", "\n", "#     raise Exception(\"Video is longer than 10m!\", rel_fp)", "\n", "frame_end", ",", "frame_loc", "=", "int", "(", "sample", "[", "3", "]", ")", ",", "int", "(", "sample", "[", "5", "]", ")", "\n", "# imgs = video_reader(abs_fp, frame_loc, frame_end, self.num_frames)", "\n", "imgs", "=", "read_large_frames_decord", "(", "abs_fp", ",", "frame_loc", ",", "frame_end", ",", "self", ".", "num_frames", ")", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d.Ego4DDataset._get_caption": [[53, 55], ["None"], "methods", ["None"], ["if", "imgs", "is", "None", ":", "\n", "            ", "raise", "Exception", "(", "\"Invalid video!\"", ",", "rel_fp", ")", "\n", "", "else", ":", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d.Ego4DDataset.get_raw_video": [[56, 67], ["ego4d.Ego4DDataset._get_video_path", "video_base_dataset.read_large_frames_decord", "int", "int", "Exception"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_v2.Ego4DDataset._get_video_path", "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.video_base_dataset.read_large_frames_decord"], ["            ", "return", "imgs", "\n", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.activitynet.ActivityNetDataset.__init__": [[8, 20], ["activitynet.ActivityNetDataset._load_metadata", "video_base_dataset.BaseDataset.__init__"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_v2.Ego4DDataset._load_metadata", "home.repos.pwc.inspect_result.showlab_all-in-one.transforms.utils.UnNormalize.__init__"], ["    ", "def", "__init__", "(", "self", ",", "*", "args", ",", "split", "=", "\"\"", ",", "**", "kwargs", ")", ":", "\n", "        ", "assert", "split", "in", "[", "\"train\"", ",", "\"val\"", ",", "\"test\"", "]", "\n", "self", ".", "split", "=", "split", "\n", "self", ".", "metadata", "=", "None", "\n", "if", "split", "==", "\"train\"", ":", "\n", "            ", "names", "=", "[", "\"activitynet_train\"", "]", "\n", "", "elif", "split", "==", "\"val\"", ":", "\n", "            ", "names", "=", "[", "\"activitynet_val\"", "]", "\n", "", "elif", "split", "==", "\"test\"", ":", "\n", "            ", "names", "=", "[", "\"activitynet_val\"", "]", "\n", "", "self", ".", "_load_metadata", "(", ")", "\n", "super", "(", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ",", "names", "=", "names", ",", "text_column_name", "=", "\"caption\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.activitynet.ActivityNetDataset._load_metadata": [[21, 31], ["pandas.read_json", "os.path.join"], "methods", ["None"], ["", "def", "_load_metadata", "(", "self", ")", ":", "\n", "        ", "metadata_dir", "=", "'./meta_data/activitynet'", "\n", "split_files", "=", "{", "\n", "'train'", ":", "'train.jsonl'", ",", "\n", "'val'", ":", "'val1.jsonl'", ",", "\n", "'test'", ":", "'val2.jsonl'", "\n", "}", "\n", "target_split_fp", "=", "split_files", "[", "self", ".", "split", "]", "\n", "metadata", "=", "pd", ".", "read_json", "(", "os", ".", "path", ".", "join", "(", "metadata_dir", ",", "target_split_fp", ")", ",", "lines", "=", "True", ")", "\n", "self", ".", "metadata", "=", "metadata", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.activitynet.ActivityNetDataset._get_video_path": [[32, 36], ["os.path.join"], "methods", ["None"], ["", "def", "_get_video_path", "(", "self", ",", "sample", ")", ":", "\n", "        ", "rel_video_fp", "=", "sample", "[", "'clip_name'", "]", "\n", "full_video_fp", "=", "os", ".", "path", ".", "join", "(", "self", ".", "data_dir", ",", "'activitynet_frames'", ",", "rel_video_fp", ")", "\n", "return", "full_video_fp", ",", "rel_video_fp", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.activitynet.ActivityNetDataset.get_raw_video": [[37, 44], ["activitynet.ActivityNetDataset._get_video_path", "video_base_dataset.read_frames_from_img_dir", "Exception"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_v2.Ego4DDataset._get_video_path", "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.video_base_dataset.read_frames_from_img_dir"], ["", "def", "get_raw_video", "(", "self", ",", "sample", ")", ":", "\n", "        ", "abs_fp", ",", "rel_fp", "=", "self", ".", "_get_video_path", "(", "sample", ")", "\n", "imgs", ",", "idxs", ",", "vlen", "=", "read_frames_from_img_dir", "(", "abs_fp", ",", "self", ".", "num_frames", ",", "mode", "=", "self", ".", "split", ")", "\n", "if", "imgs", "is", "None", ":", "\n", "            ", "raise", "Exception", "(", "\"Invalid img!\"", ",", "rel_fp", ")", "\n", "", "else", ":", "\n", "            ", "return", "imgs", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.activitynet.ActivityNetDataset.get_video": [[45, 53], ["activitynet.ActivityNetDataset.get_raw_video().permute", "activitynet.ActivityNetDataset.video_transform().permute", "activitynet.ActivityNetDataset.get_raw_video", "activitynet.ActivityNetDataset.video_transform"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_v2.Ego4DDataset.get_raw_video"], ["", "", "def", "get_video", "(", "self", ",", "index", ",", "sample", ",", "image_key", "=", "\"image\"", ")", ":", "\n", "        ", "videos", "=", "self", ".", "get_raw_video", "(", "sample", ")", "\n", "videos_tensor", "=", "self", ".", "video_aug", "(", "videos", ",", "self", ".", "video_transform", ")", "\n", "return", "{", "\n", "\"video\"", ":", "videos_tensor", ",", "\n", "\"vid_index\"", ":", "index", ",", "\n", "\"cap_index\"", ":", "index", ",", "\n", "\"raw_index\"", ":", "index", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.activitynet.ActivityNetDataset.get_false_video": [[55, 62], ["random.randint", "activitynet.ActivityNetDataset.get_raw_video().permute", "activitynet.ActivityNetDataset.video_transform().permute", "len", "activitynet.ActivityNetDataset.get_raw_video", "activitynet.ActivityNetDataset.video_transform"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_v2.Ego4DDataset.get_raw_video"], ["", "def", "get_false_video", "(", "self", ",", "rep", ",", "image_key", "=", "\"image\"", ")", ":", "\n", "        ", "random_index", "=", "random", ".", "randint", "(", "0", ",", "len", "(", "self", ".", "metadata", ")", "-", "1", ")", "\n", "sample", "=", "self", ".", "metadata", ".", "iloc", "[", "random_index", "]", "\n", "videos", "=", "self", ".", "get_raw_video", "(", "sample", ")", "\n", "videos_tensor", "=", "self", ".", "video_aug", "(", "videos", ",", "self", ".", "video_transform", ")", "\n", "return", "{", "f\"false_video_{rep}\"", ":", "videos_tensor", "}", "\n", "\n", "", "def", "get_text", "(", "self", ",", "raw_index", ",", "sample", ")", ":", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.activitynet.ActivityNetDataset.get_text": [[63, 79], ["activitynet.ActivityNetDataset.tokenizer"], "methods", ["None"], ["        ", "text", "=", "sample", "[", "'caption'", "]", "\n", "# print(text)", "\n", "encoding", "=", "self", ".", "tokenizer", "(", "\n", "text", ",", "\n", "padding", "=", "\"max_length\"", ",", "\n", "truncation", "=", "True", ",", "\n", "max_length", "=", "self", ".", "max_text_len", ",", "\n", "return_special_tokens_mask", "=", "True", ",", "\n", ")", "\n", "# print(encoding.size())", "\n", "return", "{", "\n", "\"text\"", ":", "(", "text", ",", "encoding", ")", ",", "\n", "\"img_index\"", ":", "raw_index", ",", "\n", "\"cap_index\"", ":", "raw_index", ",", "\n", "\"raw_index\"", ":", "raw_index", ",", "\n", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.activitynet.ActivityNetDataset.get_false_text": [[81, 93], ["random.randint", "activitynet.ActivityNetDataset.tokenizer", "len"], "methods", ["None"], ["        ", "random_index", "=", "random", ".", "randint", "(", "0", ",", "len", "(", "self", ".", "metadata", ")", "-", "1", ")", "\n", "sample", "=", "self", ".", "metadata", ".", "iloc", "[", "random_index", "]", "\n", "text", "=", "sample", "[", "'caption'", "]", "\n", "encoding", "=", "self", ".", "tokenizer", "(", "\n", "text", ",", "\n", "# padding=\"max_length\",", "\n", "truncation", "=", "True", ",", "\n", "max_length", "=", "self", ".", "max_text_len", ",", "\n", "return_special_tokens_mask", "=", "True", ",", "\n", ")", "\n", "return", "{", "f\"false_text_{rep}\"", ":", "(", "text", ",", "encoding", ")", "}", "\n", "\n", "", "def", "get_suite", "(", "self", ",", "index", ")", ":", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.activitynet.ActivityNetDataset.get_suite": [[94, 115], ["dict", "dict.update", "range", "range", "activitynet.ActivityNetDataset.get_video", "activitynet.ActivityNetDataset.get_text", "dict.update", "dict.update", "dict.update", "dict.update", "print", "random.randint", "activitynet.ActivityNetDataset.get_false_video", "activitynet.ActivityNetDataset.get_false_text", "len"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.gadgets.my_metrics.VQAScore.update", "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_v2.Ego4DDataset.get_video", "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_v2.Ego4DDataset.get_text", "home.repos.pwc.inspect_result.showlab_all-in-one.gadgets.my_metrics.VQAScore.update", "home.repos.pwc.inspect_result.showlab_all-in-one.gadgets.my_metrics.VQAScore.update", "home.repos.pwc.inspect_result.showlab_all-in-one.gadgets.my_metrics.VQAScore.update", "home.repos.pwc.inspect_result.showlab_all-in-one.gadgets.my_metrics.VQAScore.update", "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_v2.Ego4DDataset.get_false_video", "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_v2.Ego4DDataset.get_false_text"], ["        ", "result", "=", "None", "\n", "while", "result", "is", "None", ":", "\n", "            ", "sample", "=", "self", ".", "metadata", ".", "iloc", "[", "index", "]", "\n", "try", ":", "\n", "                ", "ret", "=", "dict", "(", ")", "\n", "ret", ".", "update", "(", "self", ".", "get_video", "(", "index", ",", "sample", ")", ")", "\n", "if", "not", "self", ".", "image_only", ":", "\n", "                    ", "txt", "=", "self", ".", "get_text", "(", "index", ",", "sample", ")", "\n", "ret", ".", "update", "(", "{", "\"replica\"", ":", "True", "if", "txt", "[", "\"cap_index\"", "]", ">", "0", "else", "False", "}", ")", "\n", "ret", ".", "update", "(", "txt", ")", "\n", "\n", "", "for", "i", "in", "range", "(", "self", ".", "draw_false_image", ")", ":", "\n", "                    ", "ret", ".", "update", "(", "self", ".", "get_false_video", "(", "i", ")", ")", "\n", "", "for", "i", "in", "range", "(", "self", ".", "draw_false_text", ")", ":", "\n", "                    ", "ret", ".", "update", "(", "self", ".", "get_false_text", "(", "i", ")", ")", "\n", "", "result", "=", "True", "\n", "", "except", "Exception", "as", "e", ":", "\n", "                ", "print", "(", "f\"Error while read file idx {sample.name} in {self.names[0]} -> {e}\"", ")", "\n", "index", "=", "random", ".", "randint", "(", "0", ",", "len", "(", "self", ".", "metadata", ")", "-", "1", ")", "\n", "", "", "return", "ret", "\n", "\n", "", "def", "__len__", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.activitynet.ActivityNetDataset.__len__": [[116, 118], ["len"], "methods", ["None"], ["        ", "return", "len", "(", "self", ".", "metadata", ")", "\n", "\n", "", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.activitynet.ActivityNetDataset.__getitem__": [[119, 121], ["activitynet.ActivityNetDataset.get_suite"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_v2.Ego4DDataset.get_suite"], ["        ", "return", "self", ".", "get_suite", "(", "index", ")", "", "", "", ""]], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.yttemporal.YTTemporalDataset.__init__": [[15, 42], ["video_base_dataset.BaseDataset.__init__", "yttemporal.YTTemporalDataset._load_metadata", "yttemporal.YTTemporalDataset._load_metadata", "float"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.transforms.utils.UnNormalize.__init__", "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_v2.Ego4DDataset._load_metadata", "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_v2.Ego4DDataset._load_metadata"], ["def", "__init__", "(", "self", ",", "*", "args", ",", "split", "=", "\"\"", ",", "**", "kwargs", ")", ":", "\n", "        ", "assert", "split", "in", "[", "\"train\"", ",", "\"val\"", ",", "\"test\"", "]", "\n", "self", ".", "split", "=", "split", "\n", "\n", "if", "split", "==", "\"train\"", ":", "\n", "            ", "names", "=", "[", "\"yttemporal_train\"", "]", "\n", "", "elif", "split", "==", "\"val\"", ":", "\n", "            ", "names", "=", "[", "\"yttemporal_val\"", "]", "\n", "", "elif", "split", "==", "\"test\"", ":", "\n", "            ", "names", "=", "[", "\"yttemporal_test\"", "]", "\n", "", "super", "(", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ",", "names", "=", "names", ",", "text_column_name", "=", "\"caption\"", ")", "\n", "\n", "self", ".", "metadata", "=", "None", "\n", "self", ".", "_load_metadata", "(", ")", "\n", "self", ".", "min_time", "=", "4.0", "\n", "self", ".", "size", "=", "224", "\n", "self", ".", "fps", "=", "2", "\n", "self", ".", "num_sec", "=", "self", ".", "num_frames", "/", "float", "(", "self", ".", "fps", ")", "\n", "self", ".", "crop_only", "=", "True", "\n", "if", "self", ".", "split", "==", "'train'", ":", "\n", "            ", "self", ".", "center_crop", "=", "False", "\n", "", "else", ":", "\n", "            ", "self", ".", "center_crop", "=", "True", "\n", "", "self", ".", "benchmark", "=", "False", "\n", "self", ".", "num_candidates", "=", "1", "\n", "self", ".", "random_flip", "=", "True", "\n", "self", ".", "_load_metadata", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.yttemporal.YTTemporalDataset._load_metadata": [[43, 53], ["pandas.read_csv", "os.path.join"], "methods", ["None"], ["", "def", "_load_metadata", "(", "self", ")", ":", "\n", "        ", "metadata_dir", "=", "'./meta_data/yttemporal'", "\n", "split_files", "=", "{", "\n", "'train'", ":", "'train_success_2000000.csv'", ",", "# _1000000", "\n", "'val'", ":", "'val_success.csv'", ",", "# there is no test", "\n", "'test'", ":", "'val_success.csv'", "\n", "}", "\n", "target_split_fp", "=", "split_files", "[", "self", ".", "split", "]", "\n", "metadata", "=", "pd", ".", "read_csv", "(", "os", ".", "path", ".", "join", "(", "metadata_dir", ",", "target_split_fp", ")", ",", "sep", "=", "'\\t'", ")", "\n", "self", ".", "metadata", "=", "metadata", "[", "\"Name\"", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.yttemporal.YTTemporalDataset.read_frames_ffmpeg": [[54, 101], ["ffmpeg.input().filter", "cmd.hflip.hflip.output().run", "numpy.frombuffer().reshape", "torch.from_numpy", "cmd.hflip.hflip.crop", "cmd.hflip.hflip.crop().filter", "cmd.hflip.hflip.hflip", "numpy.copy", "torch.cat.permute", "torch.ones", "torch.cat", "ffmpeg.input", "random.uniform", "random.uniform", "str", "str", "random.uniform", "cmd.hflip.hflip.output", "numpy.frombuffer", "cmd.hflip.hflip.crop"], "methods", ["None"], ["", "def", "read_frames_ffmpeg", "(", "self", ",", "video_path", ",", "start", ",", "end", ")", ":", "\n", "        ", "start_seek", "=", "start", "\n", "cmd", "=", "(", "\n", "ffmpeg", "\n", ".", "input", "(", "video_path", ",", "ss", "=", "start_seek", ",", "t", "=", "end", "-", "start", "+", "0.01", ")", "\n", ".", "filter", "(", "'fps'", ",", "fps", "=", "self", ".", "fps", ")", "\n", ")", "\n", "if", "self", ".", "center_crop", ":", "\n", "            ", "aw", ",", "ah", "=", "0.5", ",", "0.5", "\n", "", "else", ":", "\n", "            ", "aw", ",", "ah", "=", "random", ".", "uniform", "(", "0", ",", "1", ")", ",", "random", ".", "uniform", "(", "0", ",", "1", ")", "\n", "", "if", "self", ".", "crop_only", ":", "\n", "            ", "cmd", "=", "(", "\n", "cmd", ".", "crop", "(", "'(iw - {})*{}'", ".", "format", "(", "self", ".", "size", ",", "aw", ")", ",", "\n", "'(ih - {})*{}'", ".", "format", "(", "self", ".", "size", ",", "ah", ")", ",", "\n", "str", "(", "self", ".", "size", ")", ",", "str", "(", "self", ".", "size", ")", ")", "\n", ")", "\n", "", "else", ":", "\n", "            ", "cmd", "=", "(", "\n", "cmd", ".", "crop", "(", "'(iw - min(iw,ih))*{}'", ".", "format", "(", "aw", ")", ",", "\n", "'(ih - min(iw,ih))*{}'", ".", "format", "(", "ah", ")", ",", "\n", "'min(iw,ih)'", ",", "\n", "'min(iw,ih)'", ")", "\n", ".", "filter", "(", "'scale'", ",", "self", ".", "size", ",", "self", ".", "size", ")", "\n", ")", "\n", "", "if", "self", ".", "random_flip", "and", "random", ".", "uniform", "(", "0", ",", "1", ")", ">", "0.5", ":", "\n", "            ", "cmd", "=", "cmd", ".", "hflip", "(", ")", "\n", "", "out", ",", "_", "=", "(", "\n", "cmd", ".", "output", "(", "'pipe:'", ",", "format", "=", "'rawvideo'", ",", "pix_fmt", "=", "'rgb24'", ")", "\n", ".", "run", "(", "capture_stdout", "=", "True", ",", "quiet", "=", "True", ")", "\n", ")", "\n", "video", "=", "np", ".", "frombuffer", "(", "out", ",", "np", ".", "uint8", ")", ".", "reshape", "(", "[", "-", "1", ",", "self", ".", "size", ",", "self", ".", "size", ",", "3", "]", ")", "\n", "video_tensor", "=", "th", ".", "from_numpy", "(", "np", ".", "copy", "(", "video", ")", ")", "\n", "video_tensor", "=", "video_tensor", ".", "permute", "(", "3", ",", "0", ",", "1", ",", "2", ")", "+", "0.01", "\n", "# print(video_tensor.size())", "\n", "# print(video_tensor)", "\n", "if", "video_tensor", ".", "shape", "[", "1", "]", "<", "self", ".", "num_frames", ":", "\n", "            ", "zeros", "=", "th", ".", "ones", "(", "(", "3", ",", "self", ".", "num_frames", "-", "video_tensor", ".", "shape", "[", "1", "]", ",", "self", ".", "size", ",", "self", ".", "size", ")", ",", "dtype", "=", "th", ".", "uint8", ")", "\n", "video_tensor", "=", "th", ".", "cat", "(", "(", "video_tensor", ",", "zeros", ")", ",", "axis", "=", "1", ")", "\n", "# # uniform n frames", "\n", "# frame_indexs = sample_frames(self.num_frames, video_tensor.size(1))", "\n", "# out_tensors = th.ones((3, self.num_frames, self.size, self.size), dtype=th.uint8)", "\n", "# for i in range(self.num_frames):", "\n", "#     out_tensors[:, i] = video_tensor[:, frame_indexs[i]]", "\n", "# print(out_tensors)", "\n", "# return out_tensors", "\n", "", "return", "video_tensor", "[", ":", ",", ":", "self", ".", "num_frames", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.yttemporal.YTTemporalDataset.get_caption": [[132, 166], ["int", "random.randint", "min", "video_base_dataset.clean_subtitles", "pandas.DataFrame", "video_base_dataset.align_using_dtw", "enumerate", "open", "json.load", "random.randint", "random.random", "ftfy.ftfy", "ftfy.ftfy.split", "len", "Exception", "max", "max", "float", "float"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.datasets.video_base_dataset.clean_subtitles", "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.video_base_dataset.align_using_dtw"], ["", "def", "get_caption", "(", "self", ",", "caption_csv", ")", ":", "\n", "        ", "with", "open", "(", "caption_csv", ",", "'r'", ")", "as", "f", ":", "\n", "            ", "cap", "=", "json", ".", "load", "(", "f", ")", "\n", "# random choice 10s-15s video clips", "\n", "", "video_len", "=", "int", "(", "cap", "[", "\"info\"", "]", "[", "\"duration\"", "]", ")", "\n", "start", "=", "random", ".", "randint", "(", "0", ",", "max", "(", "1", ",", "video_len", "-", "15", ")", ")", "+", "random", ".", "random", "(", ")", "\n", "clip_len", "=", "random", ".", "randint", "(", "10", ",", "15", ")", "\n", "end", "=", "min", "(", "video_len", "-", "1", ",", "start", "+", "clip_len", ")", "\n", "all_text", "=", "cap", "[", "\"subtitles\"", "]", "# [{'word': 'hey', 'time': 0.0}, {'word': 'guys', 'time': 0.149}]", "\n", "# clean noisy asr text", "\n", "all_text", "=", "clean_subtitles", "(", "all_text", ")", "\n", "vtt", "=", "pd", ".", "DataFrame", "(", "all_text", ")", "\n", "denoised_word_by_word", "=", "[", "]", "\n", "for", "x", "in", "cap", "[", "'denoised'", "]", ":", "\n", "# Ftfy just in case", "\n", "            ", "cleanasr", "=", "ftfy", ".", "ftfy", "(", "x", "[", "'cleanasr'", "]", ")", "\n", "denoised_word_by_word", "+=", "cleanasr", ".", "split", "(", "' '", ")", "\n", "# Align", "\n", "", "vtt", "[", "'denoised'", "]", "=", "align_using_dtw", "(", "vtt", "[", "'word'", "]", ",", "denoised_word_by_word", ")", "\n", "text", "=", "\"\"", "\n", "origin_text", "=", "\"\"", "\n", "for", "index", ",", "item", "in", "enumerate", "(", "all_text", ")", ":", "\n", "            ", "if", "float", "(", "item", "[", "'time'", "]", ")", ">", "start", "and", "float", "(", "item", "[", "'time'", "]", ")", "<", "end", ":", "\n", "                ", "text", "+=", "vtt", "[", "'denoised'", "]", "[", "index", "]", "+", "\" \"", "\n", "origin_text", "+=", "item", "[", "'word'", "]", "+", "\" \"", "\n", "# print(text)", "\n", "# print(origin_text)", "\n", "", "", "if", "len", "(", "text", ")", "<", "10", ":", "\n", "            ", "Exception", "(", "IndexError", ")", "\n", "", "if", "end", "-", "start", "<", "self", ".", "min_time", ":", "\n", "            ", "diff", "=", "self", ".", "min_time", "-", "end", "+", "start", "\n", "start", "=", "max", "(", "0", ",", "start", "-", "diff", "/", "2", ")", "\n", "end", "=", "start", "+", "self", ".", "min_time", "\n", "", "return", "text", ",", "start", ",", "end", ",", "video_len", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.yttemporal.YTTemporalDataset.get_text": [[167, 181], ["yttemporal.YTTemporalDataset.get_caption_path", "yttemporal.YTTemporalDataset.get_caption", "yttemporal.YTTemporalDataset.tokenizer"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.datasets.yttemporal.YTTemporalDataset.get_caption_path", "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.yttemporal.YTTemporalDataset.get_caption"], ["", "def", "get_text", "(", "self", ",", "sample", ")", ":", "\n", "        ", "caption_csv", "=", "self", ".", "get_caption_path", "(", "sample", ")", "\n", "text", ",", "start", ",", "end", ",", "duration", "=", "self", ".", "get_caption", "(", "caption_csv", ")", "\n", "# print(text, start, end)", "\n", "# print(text)", "\n", "# TODO: May need to be improved for edge cases.", "\n", "encoding", "=", "self", ".", "tokenizer", "(", "\n", "text", ",", "\n", "padding", "=", "\"max_length\"", ",", "\n", "truncation", "=", "True", ",", "\n", "max_length", "=", "self", ".", "max_text_len", ",", "\n", "return_special_tokens_mask", "=", "True", ",", "\n", ")", "\n", "return", "{", "\"text\"", ":", "(", "text", ",", "encoding", ")", "}", ",", "start", ",", "end", ",", "duration", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.yttemporal.YTTemporalDataset.get_caption_path": [[182, 185], ["os.path.join", "sample.split", "sample.split"], "methods", ["None"], ["", "def", "get_caption_path", "(", "self", ",", "sample", ")", ":", "\n", "# YTTemporal/videos/subset_87/data/xx.mp4 -> YTTemporal/videos/subset_87/annotations/xx.csv", "\n", "        ", "return", "os", ".", "path", ".", "join", "(", "self", ".", "data_dir", ",", "'videos'", ",", "sample", ".", "split", "(", "'/'", ")", "[", "0", "]", ",", "'annotations'", ",", "sample", ".", "split", "(", "'/'", ")", "[", "-", "1", "]", "[", ":", "-", "4", "]", "+", "'.json'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.yttemporal.YTTemporalDataset.get_false_text": [[186, 199], ["random.randint", "yttemporal.YTTemporalDataset.get_caption_path", "yttemporal.YTTemporalDataset.get_caption", "yttemporal.YTTemporalDataset.tokenizer", "len"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.datasets.yttemporal.YTTemporalDataset.get_caption_path", "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.yttemporal.YTTemporalDataset.get_caption"], ["", "def", "get_false_text", "(", "self", ",", "rep", ")", ":", "\n", "        ", "random_index", "=", "random", ".", "randint", "(", "0", ",", "len", "(", "self", ".", "metadata", ")", "-", "1", ")", "\n", "sample", "=", "self", ".", "metadata", ".", "iloc", "[", "random_index", "]", "\n", "caption_csv", "=", "self", ".", "get_caption_path", "(", "sample", ")", "\n", "text", ",", "start", ",", "end", "=", "self", ".", "get_caption", "(", "caption_csv", ")", "\n", "encoding", "=", "self", ".", "tokenizer", "(", "\n", "text", ",", "\n", "# padding=\"max_length\",", "\n", "truncation", "=", "True", ",", "\n", "max_length", "=", "self", ".", "max_text_len", ",", "\n", "return_special_tokens_mask", "=", "True", ",", "\n", ")", "\n", "return", "{", "f\"false_text_{rep}\"", ":", "(", "text", ",", "encoding", ")", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.yttemporal.YTTemporalDataset._get_video_path": [[200, 204], ["os.path.join"], "methods", ["None"], ["", "def", "_get_video_path", "(", "self", ",", "sample", ")", ":", "\n", "        ", "rel_video_fp", "=", "sample", "\n", "full_video_fp", "=", "os", ".", "path", ".", "join", "(", "self", ".", "data_dir", ",", "'videos'", ",", "rel_video_fp", ")", "\n", "return", "full_video_fp", ",", "rel_video_fp", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.yttemporal.YTTemporalDataset.get_raw_video": [[205, 216], ["yttemporal.YTTemporalDataset._get_video_path", "video_base_dataset.video_clip_reader", "video_base_dataset.video_clip_reader.size", "Exception", "Exception"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_v2.Ego4DDataset._get_video_path", "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.video_base_dataset.video_clip_reader"], ["", "def", "get_raw_video", "(", "self", ",", "sample", ",", "begin", ",", "end", ",", "duration", ")", ":", "\n", "        ", "abs_fp", ",", "rel_fp", "=", "self", ".", "_get_video_path", "(", "sample", ")", "\n", "# print(abs_fp, rel_fp)", "\n", "# imgs = self.read_frames_ffmpeg(abs_fp, begin, end).permute(1, 0, 2, 3)", "\n", "videos", "=", "video_clip_reader", "(", "abs_fp", ",", "begin", ",", "end", ",", "duration", ",", "self", ".", "num_frames", ")", "\n", "if", "videos", ".", "size", "(", "0", ")", "!=", "self", ".", "num_frames", ":", "\n", "            ", "raise", "Exception", "(", "\"video length not enough!\"", ",", "rel_fp", ")", "\n", "", "if", "videos", "is", "None", ":", "\n", "            ", "raise", "Exception", "(", "\"Invalid img!\"", ",", "rel_fp", ")", "\n", "", "else", ":", "\n", "            ", "return", "videos", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.yttemporal.YTTemporalDataset.get_video": [[217, 223], ["yttemporal.YTTemporalDataset.get_raw_video().permute", "yttemporal.YTTemporalDataset.video_transform().permute", "yttemporal.YTTemporalDataset.get_raw_video", "yttemporal.YTTemporalDataset.video_transform"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_v2.Ego4DDataset.get_raw_video"], ["", "", "def", "get_video", "(", "self", ",", "sample", ",", "start", ",", "end", ",", "duration", ")", ":", "\n", "        ", "videos", "=", "self", ".", "get_raw_video", "(", "sample", ",", "start", ",", "end", ",", "duration", ")", "\n", "videos_tensor", "=", "self", ".", "video_aug", "(", "videos", ",", "self", ".", "video_transform", ")", "\n", "return", "videos_tensor", "\n", "\n", "", "def", "get_false_video", "(", "self", ",", "rep", ")", ":", "\n", "        ", "random_index", "=", "random", ".", "randint", "(", "0", ",", "len", "(", "self", ".", "metadata", ")", "-", "1", ")", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.yttemporal.YTTemporalDataset.get_false_video": [[224, 233], ["random.randint", "yttemporal.YTTemporalDataset.get_caption_path", "yttemporal.YTTemporalDataset.get_caption", "yttemporal.YTTemporalDataset.get_raw_video().permute", "yttemporal.YTTemporalDataset.video_transform().permute", "len", "yttemporal.YTTemporalDataset.get_raw_video", "yttemporal.YTTemporalDataset.video_transform"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.datasets.yttemporal.YTTemporalDataset.get_caption_path", "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.yttemporal.YTTemporalDataset.get_caption", "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_v2.Ego4DDataset.get_raw_video"], ["sample", "=", "self", ".", "metadata", ".", "iloc", "[", "random_index", "]", "\n", "caption_csv", "=", "self", ".", "get_caption_path", "(", "sample", ")", "\n", "_", ",", "start", ",", "end", ",", "duration", "=", "self", ".", "get_caption", "(", "caption_csv", ")", "\n", "videos", "=", "self", ".", "get_raw_video", "(", "sample", ",", "start", ",", "end", ",", "duration", ")", "\n", "videos_tensor", "=", "self", ".", "video_aug", "(", "videos", ",", "self", ".", "video_transform", ")", "\n", "return", "{", "f\"false_video_{rep}\"", ":", "videos_tensor", "}", "\n", "\n", "", "def", "get_suite", "(", "self", ",", "index", ")", ":", "\n", "        ", "result", "=", "None", "\n", "max_try", "=", "5", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.yttemporal.YTTemporalDataset.get_suite": [[234, 265], ["dict", "yttemporal.YTTemporalDataset.get_text", "dict.update", "yttemporal.YTTemporalDataset.get_video", "dict.update", "dict.update", "range", "range", "dict.update", "dict.update", "print", "yttemporal.YTTemporalDataset.get_false_video", "yttemporal.YTTemporalDataset.get_false_text"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_v2.Ego4DDataset.get_text", "home.repos.pwc.inspect_result.showlab_all-in-one.gadgets.my_metrics.VQAScore.update", "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_v2.Ego4DDataset.get_video", "home.repos.pwc.inspect_result.showlab_all-in-one.gadgets.my_metrics.VQAScore.update", "home.repos.pwc.inspect_result.showlab_all-in-one.gadgets.my_metrics.VQAScore.update", "home.repos.pwc.inspect_result.showlab_all-in-one.gadgets.my_metrics.VQAScore.update", "home.repos.pwc.inspect_result.showlab_all-in-one.gadgets.my_metrics.VQAScore.update", "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_v2.Ego4DDataset.get_false_video", "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_v2.Ego4DDataset.get_false_text"], ["try_time", "=", "0", "\n", "while", "result", "is", "None", ":", "\n", "            ", "try_time", "+=", "1", "\n", "sample", "=", "self", ".", "metadata", ".", "iloc", "[", "index", "]", "\n", "# try:", "\n", "ret", "=", "dict", "(", ")", "\n", "text", ",", "start", ",", "end", ",", "duration", "=", "self", ".", "get_text", "(", "sample", ")", "\n", "ret", ".", "update", "(", "text", ")", "\n", "videos_tensor", "=", "self", ".", "get_video", "(", "sample", ",", "start", ",", "end", ",", "duration", ")", "\n", "# print(imgs_tensor.size())", "\n", "ret", ".", "update", "(", "{", "\n", "\"video\"", ":", "videos_tensor", ",", "\n", "\"vid_index\"", ":", "index", ",", "\n", "\"cap_index\"", ":", "index", ",", "\n", "\"raw_index\"", ":", "index", ",", "\n", "}", ")", "\n", "ret", ".", "update", "(", "{", "\"replica\"", ":", "True", "if", "ret", "[", "\"cap_index\"", "]", ">", "0", "else", "False", "}", ")", "\n", "for", "i", "in", "range", "(", "self", ".", "draw_false_video", ")", ":", "\n", "                ", "ret", ".", "update", "(", "self", ".", "get_false_video", "(", "i", ")", ")", "\n", "", "for", "i", "in", "range", "(", "self", ".", "draw_false_text", ")", ":", "\n", "                ", "ret", ".", "update", "(", "self", ".", "get_false_text", "(", "i", ")", ")", "\n", "", "result", "=", "True", "\n", "# except Exception as e:", "\n", "#     # print(f\"Error while read file idx {sample} in {self.names[0]} -> {e}\")", "\n", "#     index = random.randint(0, len(self.metadata) - 1)", "\n", "if", "try_time", ">", "max_try", ":", "\n", "                ", "print", "(", "f\"Exceed max time Error while read file idx {sample} in {self.names[0]}\"", ")", "\n", "", "", "return", "ret", "\n", "\n", "", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "metadata", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.yttemporal.YTTemporalDataset.__len__": [[266, 268], ["len"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "return", "self", ".", "get_suite", "(", "index", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.yttemporal.YTTemporalDataset.__getitem__": [[269, 271], ["yttemporal.YTTemporalDataset.get_suite"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_v2.Ego4DDataset.get_suite"], []], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.base_dataset.BaseDataset.__init__": [[14, 99], ["super().__init__", "AllInOne.transforms.keys_to_transforms", "len", "torch.distributed.get_rank", "print", "print", "len", "os.path.join", "torch.distributed.get_rank", "print", "dict", "names[].split", "torch.distributed.get_rank", "print", "len", "list", "enumerate", "pyarrow.concat_tables", "list", "enumerate", "range", "names[].split", "pyarrow.ipc.RecordBatchFileReader().read_all", "base_dataset.BaseDataset.table[].to_pandas().tolist", "list", "range", "len", "os.path.isfile", "len", "len", "pyarrow.ipc.RecordBatchFileReader", "base_dataset.BaseDataset.table[].to_pandas", "list", "pyarrow.memory_map", "set"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.transforms.utils.UnNormalize.__init__", "home.repos.pwc.inspect_result.showlab_all-in-one.transforms.__init__.keys_to_transforms", "home.repos.pwc.inspect_result.showlab_all-in-one.modules.dist_utils.get_rank", "home.repos.pwc.inspect_result.showlab_all-in-one.modules.dist_utils.get_rank", "home.repos.pwc.inspect_result.showlab_all-in-one.modules.dist_utils.get_rank"], ["class", "BaseDataset", "(", "torch", ".", "utils", ".", "data", ".", "Dataset", ")", ":", "\n", "    ", "def", "__init__", "(", "\n", "self", ",", "\n", "data_dir", ":", "str", ",", "\n", "transform_keys", ":", "list", ",", "\n", "image_size", ":", "int", ",", "\n", "names", ":", "list", ",", "\n", "text_column_name", ":", "str", "=", "\"\"", ",", "\n", "remove_duplicate", "=", "True", ",", "\n", "max_text_len", "=", "40", ",", "\n", "draw_false_image", "=", "0", ",", "\n", "draw_false_video", "=", "0", ",", "\n", "draw_false_text", "=", "0", ",", "\n", "image_only", "=", "False", ",", "\n", "num_frames", "=", "1", ",", "\n", "draw_options_text", "=", "0", ",", "\n", "backend", "=", "'v100'", "\n", ")", ":", "\n", "        ", "\"\"\"\n        data_dir : where dataset file *.arrow lives; existence should be guaranteed via DataModule.prepare_data\n        transform_keys : keys for generating augmented views of images\n        text_column_name : pyarrow table column name that has list of strings as elements\n        \"\"\"", "\n", "assert", "len", "(", "transform_keys", ")", ">=", "1", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "transforms", "=", "keys_to_transforms", "(", "transform_keys", ",", "size", "=", "image_size", ")", "\n", "self", ".", "image_aug", "=", "image_aug", "\n", "self", ".", "text_column_name", "=", "text_column_name", "\n", "self", ".", "names", "=", "names", "\n", "self", ".", "max_text_len", "=", "max_text_len", "\n", "self", ".", "draw_false_image", "=", "draw_false_image", "\n", "self", ".", "draw_false_text", "=", "draw_false_text", "\n", "self", ".", "image_only", "=", "image_only", "\n", "self", ".", "data_dir", "=", "data_dir", "\n", "self", ".", "draw_options_text", "=", "draw_options_text", "\n", "if", "torch", ".", "distributed", ".", "get_rank", "(", ")", "==", "0", ":", "\n", "            ", "print", "(", "'*'", "*", "100", ")", "\n", "print", "(", "\"image sub datasets: {}\"", ".", "format", "(", "names", ")", ")", "\n", "# print(names)", "\n", "", "split_name", "=", "None", "\n", "if", "len", "(", "names", ")", "!=", "0", ":", "\n", "            ", "self", ".", "data_dir", "=", "os", ".", "path", ".", "join", "(", "self", ".", "data_dir", ",", "names", "[", "0", "]", ".", "split", "(", "'_'", ")", "[", "0", "]", ")", "# e.g. coco_train -> coco", "\n", "split_name", "=", "names", "[", "0", "]", ".", "split", "(", "'_'", ")", "[", "0", "]", "\n", "", "if", "torch", ".", "distributed", ".", "get_rank", "(", ")", "==", "0", ":", "\n", "            ", "print", "(", "self", ".", "data_dir", ")", "\n", "", "if", "split_name", "and", "split_name", "in", "[", "'msrvtt'", ",", "'cc3m'", ",", "'vcr'", ",", "'cc12m'", "]", ":", "\n", "            ", "if", "torch", ".", "distributed", ".", "get_rank", "(", ")", "==", "0", ":", "\n", "                ", "print", "(", "\"no arrow available for {}, load from disk\"", ".", "format", "(", "names", "[", "0", "]", ")", ")", "\n", "", "", "else", ":", "\n", "            ", "if", "len", "(", "names", ")", "!=", "0", ":", "\n", "                ", "tables", "=", "[", "\n", "pa", ".", "ipc", ".", "RecordBatchFileReader", "(", "\n", "pa", ".", "memory_map", "(", "f\"{self.data_dir}/{name}.arrow\"", ",", "\"r\"", ")", "\n", ")", ".", "read_all", "(", ")", "\n", "for", "name", "in", "names", "\n", "if", "os", ".", "path", ".", "isfile", "(", "f\"{self.data_dir}/{name}.arrow\"", ")", "\n", "]", "\n", "# print(names, tables)", "\n", "self", ".", "table_names", "=", "list", "(", ")", "\n", "for", "i", ",", "name", "in", "enumerate", "(", "names", ")", ":", "\n", "                    ", "self", ".", "table_names", "+=", "[", "name", "]", "*", "len", "(", "tables", "[", "i", "]", ")", "\n", "\n", "", "self", ".", "table", "=", "pa", ".", "concat_tables", "(", "tables", ",", "promote", "=", "True", ")", "\n", "if", "text_column_name", "!=", "\"\"", ":", "\n", "                    ", "self", ".", "text_column_name", "=", "text_column_name", "\n", "self", ".", "all_texts", "=", "self", ".", "table", "[", "text_column_name", "]", ".", "to_pandas", "(", ")", ".", "tolist", "(", ")", "\n", "self", ".", "all_texts", "=", "(", "\n", "[", "list", "(", "set", "(", "texts", ")", ")", "for", "texts", "in", "self", ".", "all_texts", "]", "\n", "if", "remove_duplicate", "\n", "else", "self", ".", "all_texts", "\n", ")", "\n", "", "else", ":", "\n", "                    ", "self", ".", "all_texts", "=", "list", "(", ")", "\n", "", "", "else", ":", "\n", "                ", "self", ".", "all_texts", "=", "list", "(", ")", "\n", "\n", "", "self", ".", "index_mapper", "=", "dict", "(", ")", "\n", "\n", "if", "text_column_name", "!=", "\"\"", "and", "not", "self", ".", "image_only", ":", "\n", "                ", "j", "=", "0", "\n", "for", "i", ",", "texts", "in", "enumerate", "(", "self", ".", "all_texts", ")", ":", "\n", "                    ", "for", "_j", "in", "range", "(", "len", "(", "texts", ")", ")", ":", "\n", "                        ", "self", ".", "index_mapper", "[", "j", "]", "=", "(", "i", ",", "_j", ")", "\n", "j", "+=", "1", "\n", "", "", "", "else", ":", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.base_dataset.BaseDataset.corpus": [[140, 143], ["None"], "methods", ["None"], ["#     for i in range(len(self.table)):", "\n", "#         self.index_mapper[i] = (i, None)", "\n", "\n", "", "", "", "", "@", "property", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.base_dataset.BaseDataset.__len__": [[144, 146], ["len"], "methods", ["None"], ["def", "corpus", "(", "self", ")", ":", "\n", "        ", "return", "[", "text", "for", "texts", "in", "self", ".", "all_texts", "for", "text", "in", "texts", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.base_dataset.BaseDataset.get_raw_image": [[147, 152], ["io.BytesIO", "io.BytesIO.seek", "PIL.Image.open().convert", "[].as_py", "PIL.Image.open"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "index_mapper", ")", "\n", "\n", "", "def", "get_raw_image", "(", "self", ",", "index", ",", "image_key", "=", "\"image\"", ")", ":", "\n", "        ", "index", ",", "caption_index", "=", "self", ".", "index_mapper", "[", "index", "]", "\n", "image_bytes", "=", "io", ".", "BytesIO", "(", "self", ".", "table", "[", "image_key", "]", "[", "index", "]", ".", "as_py", "(", ")", ")", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.base_dataset.BaseDataset.get_image": [[153, 161], ["base_dataset.BaseDataset.get_raw_image", "tr().unsqueeze", "tr"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.datasets.vcr.VCRDataset.get_raw_image"], ["image_bytes", ".", "seek", "(", "0", ")", "\n", "return", "Image", ".", "open", "(", "image_bytes", ")", ".", "convert", "(", "\"RGB\"", ")", "\n", "\n", "", "def", "get_image", "(", "self", ",", "index", ",", "image_key", "=", "\"image\"", ")", ":", "\n", "        ", "image", "=", "self", ".", "get_raw_image", "(", "index", ",", "image_key", "=", "image_key", ")", "\n", "# image_tensor = [tr(image).unsqueeze(0) for tr in self.transforms]", "\n", "image_tensor", "=", "self", ".", "image_aug", "(", "image", ",", "self", ".", "transforms", ")", "\n", "return", "{", "\n", "\"video\"", ":", "image_tensor", ",", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.base_dataset.BaseDataset.get_false_image": [[163, 168], ["random.randint", "base_dataset.BaseDataset.get_raw_image", "tr().unsqueeze", "len", "tr"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.datasets.vcr.VCRDataset.get_raw_image"], ["\"cap_index\"", ":", "self", ".", "index_mapper", "[", "index", "]", "[", "1", "]", ",", "\n", "\"raw_index\"", ":", "index", ",", "\n", "}", "\n", "\n", "", "def", "get_false_image", "(", "self", ",", "rep", ",", "image_key", "=", "\"image\"", ")", ":", "\n", "        ", "random_index", "=", "random", ".", "randint", "(", "0", ",", "len", "(", "self", ".", "index_mapper", ")", "-", "1", ")", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.base_dataset.BaseDataset.get_text": [[169, 185], ["base_dataset.BaseDataset.tokenizer"], "methods", ["None"], ["image", "=", "self", ".", "get_raw_image", "(", "random_index", ",", "image_key", "=", "image_key", ")", "\n", "# image_tensor = [tr(image).unsqueeze(0) for tr in self.transforms]", "\n", "image_tensor", "=", "self", ".", "image_aug", "(", "image", ",", "self", ".", "transforms", ")", "\n", "return", "{", "f\"false_video_{rep}\"", ":", "image_tensor", "}", "\n", "\n", "", "def", "get_text", "(", "self", ",", "raw_index", ")", ":", "\n", "        ", "index", ",", "caption_index", "=", "self", ".", "index_mapper", "[", "raw_index", "]", "\n", "\n", "text", "=", "self", ".", "all_texts", "[", "index", "]", "[", "caption_index", "]", "\n", "encoding", "=", "self", ".", "tokenizer", "(", "\n", "text", ",", "\n", "padding", "=", "\"max_length\"", ",", "\n", "truncation", "=", "True", ",", "\n", "max_length", "=", "self", ".", "max_text_len", ",", "\n", "return_special_tokens_mask", "=", "True", ",", "\n", ")", "\n", "return", "{", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.base_dataset.BaseDataset.get_false_text": [[187, 198], ["random.randint", "base_dataset.BaseDataset.tokenizer", "len"], "methods", ["None"], ["\"vid_index\"", ":", "index", ",", "\n", "\"cap_index\"", ":", "caption_index", ",", "\n", "\"raw_index\"", ":", "raw_index", ",", "\n", "}", "\n", "\n", "", "def", "get_false_text", "(", "self", ",", "rep", ")", ":", "\n", "        ", "random_index", "=", "random", ".", "randint", "(", "0", ",", "len", "(", "self", ".", "index_mapper", ")", "-", "1", ")", "\n", "index", ",", "caption_index", "=", "self", ".", "index_mapper", "[", "random_index", "]", "\n", "text", "=", "self", ".", "all_texts", "[", "index", "]", "[", "caption_index", "]", "\n", "encoding", "=", "self", ".", "tokenizer", "(", "\n", "text", ",", "\n", "truncation", "=", "True", ",", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.base_dataset.BaseDataset.get_suite": [[199, 219], ["dict", "dict.update", "range", "range", "base_dataset.BaseDataset.get_image", "base_dataset.BaseDataset.get_text", "dict.update", "dict.update", "dict.update", "dict.update", "print", "random.randint", "base_dataset.BaseDataset.get_false_image", "base_dataset.BaseDataset.get_false_text", "len"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.gadgets.my_metrics.VQAScore.update", "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.vcr.VCRDataset.get_image", "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_v2.Ego4DDataset.get_text", "home.repos.pwc.inspect_result.showlab_all-in-one.gadgets.my_metrics.VQAScore.update", "home.repos.pwc.inspect_result.showlab_all-in-one.gadgets.my_metrics.VQAScore.update", "home.repos.pwc.inspect_result.showlab_all-in-one.gadgets.my_metrics.VQAScore.update", "home.repos.pwc.inspect_result.showlab_all-in-one.gadgets.my_metrics.VQAScore.update", "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.vcr.VCRDataset.get_false_image", "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_v2.Ego4DDataset.get_false_text"], ["max_length", "=", "self", ".", "max_text_len", ",", "\n", "return_special_tokens_mask", "=", "True", ",", "\n", ")", "\n", "return", "{", "f\"false_text_{rep}\"", ":", "(", "text", ",", "encoding", ")", "}", "\n", "\n", "", "def", "get_suite", "(", "self", ",", "index", ")", ":", "\n", "        ", "result", "=", "None", "\n", "while", "result", "is", "None", ":", "\n", "            ", "try", ":", "\n", "                ", "ret", "=", "dict", "(", ")", "\n", "ret", ".", "update", "(", "self", ".", "get_image", "(", "index", ")", ")", "\n", "if", "not", "self", ".", "image_only", ":", "\n", "                    ", "txt", "=", "self", ".", "get_text", "(", "index", ")", "\n", "ret", ".", "update", "(", "{", "\"replica\"", ":", "True", "if", "txt", "[", "\"cap_index\"", "]", ">", "0", "else", "False", "}", ")", "\n", "ret", ".", "update", "(", "txt", ")", "\n", "\n", "", "for", "i", "in", "range", "(", "self", ".", "draw_false_image", ")", ":", "\n", "                    ", "ret", ".", "update", "(", "self", ".", "get_false_image", "(", "i", ")", ")", "\n", "", "for", "i", "in", "range", "(", "self", ".", "draw_false_text", ")", ":", "\n", "                    ", "ret", ".", "update", "(", "self", ".", "get_false_text", "(", "i", ")", ")", "\n", "", "result", "=", "True", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.base_dataset.BaseDataset.collate": [[220, 304], ["len", "set", "list", "len", "max", "max", "len", "range", "len", "len", "mlm_collator", "enumerate", "list", "len", "torch.zeros", "range", "list", "torch.zeros_like", "torch.zeros_like", "enumerate", "torch.full_like", "b.keys", "dict_batch.keys", "range", "dict_batch.keys", "torch.tensor", "torch.tensor", "len", "len"], "methods", ["None"], ["", "except", "Exception", "as", "e", ":", "\n", "                ", "print", "(", "f\"Error while read file idx {index} in {self.names[0]} -> {e}\"", ")", "\n", "index", "=", "random", ".", "randint", "(", "0", ",", "len", "(", "self", ".", "index_mapper", ")", "-", "1", ")", "\n", "", "", "return", "ret", "\n", "\n", "", "def", "collate", "(", "self", ",", "batch", ",", "mlm_collator", ")", ":", "\n", "        ", "batch_size", "=", "len", "(", "batch", ")", "\n", "keys", "=", "set", "(", "[", "key", "for", "b", "in", "batch", "for", "key", "in", "b", ".", "keys", "(", ")", "]", ")", "\n", "dict_batch", "=", "{", "k", ":", "[", "dic", "[", "k", "]", "if", "k", "in", "dic", "else", "None", "for", "dic", "in", "batch", "]", "for", "k", "in", "keys", "}", "\n", "# print(dict_batch)", "\n", "\n", "img_keys", "=", "[", "k", "for", "k", "in", "list", "(", "dict_batch", ".", "keys", "(", ")", ")", "if", "\"video\"", "in", "k", "]", "\n", "img_sizes", "=", "list", "(", ")", "\n", "\n", "for", "img_key", "in", "img_keys", ":", "\n", "            ", "img_sizes", "+=", "[", "ii", ".", "shape", "for", "i", "in", "dict_batch", "[", "img_key", "]", "if", "i", "is", "not", "None", "for", "ii", "in", "i", "]", "\n", "\n", "", "for", "size", "in", "img_sizes", ":", "\n", "            ", "assert", "(", "\n", "len", "(", "size", ")", "==", "4", "\n", ")", ",", "f\"Collate error, an image should be in shape of (N, 3,  H, W), instead of given {size}\"", "\n", "\n", "", "if", "len", "(", "img_keys", ")", "!=", "0", ":", "\n", "            ", "global_max_height", "=", "max", "(", "[", "i", "[", "2", "]", "for", "i", "in", "img_sizes", "]", ")", "\n", "global_max_width", "=", "max", "(", "[", "i", "[", "3", "]", "for", "i", "in", "img_sizes", "]", ")", "\n", "", "for", "img_key", "in", "img_keys", ":", "\n", "            ", "img", "=", "dict_batch", "[", "img_key", "]", "\n", "view_size", "=", "len", "(", "dict_batch", "[", "img_key", "]", "[", "0", "]", ")", "\n", "new_images", "=", "[", "\n", "torch", ".", "zeros", "(", "batch_size", ",", "1", ",", "3", ",", "global_max_height", ",", "global_max_width", ")", "\n", "for", "_", "in", "range", "(", "view_size", ")", "\n", "]", "\n", "# print(len(img))", "\n", "for", "bi", "in", "range", "(", "batch_size", ")", ":", "\n", "                ", "orig_batch", "=", "img", "[", "bi", "]", "\n", "for", "vi", "in", "range", "(", "view_size", ")", ":", "\n", "                    ", "if", "orig_batch", "is", "None", ":", "\n", "                        ", "continue", "\n", "", "else", ":", "\n", "                        ", "orig", "=", "img", "[", "bi", "]", "[", "vi", "]", "\n", "new_images", "[", "vi", "]", "[", "bi", ",", ":", ",", ":", ",", ":", "orig", ".", "shape", "[", "2", "]", ",", ":", "orig", ".", "shape", "[", "3", "]", "]", "=", "orig", "\n", "\n", "", "", "", "dict_batch", "[", "img_key", "]", "=", "new_images", "\n", "\n", "", "txt_keys", "=", "[", "k", "for", "k", "in", "list", "(", "dict_batch", ".", "keys", "(", ")", ")", "if", "\"text\"", "in", "k", "]", "\n", "\n", "if", "len", "(", "txt_keys", ")", "!=", "0", ":", "\n", "            ", "texts", "=", "[", "[", "d", "[", "0", "]", "for", "d", "in", "dict_batch", "[", "txt_key", "]", "]", "for", "txt_key", "in", "txt_keys", "]", "\n", "encodings", "=", "[", "[", "d", "[", "1", "]", "for", "d", "in", "dict_batch", "[", "txt_key", "]", "]", "for", "txt_key", "in", "txt_keys", "]", "\n", "draw_text_len", "=", "len", "(", "encodings", ")", "\n", "flatten_encodings", "=", "[", "e", "for", "encoding", "in", "encodings", "for", "e", "in", "encoding", "]", "\n", "flatten_mlms", "=", "mlm_collator", "(", "flatten_encodings", ")", "\n", "\n", "for", "i", ",", "txt_key", "in", "enumerate", "(", "txt_keys", ")", ":", "\n", "                ", "texts", ",", "encodings", "=", "(", "\n", "[", "d", "[", "0", "]", "for", "d", "in", "dict_batch", "[", "txt_key", "]", "]", ",", "\n", "[", "d", "[", "1", "]", "for", "d", "in", "dict_batch", "[", "txt_key", "]", "]", ",", "\n", ")", "\n", "\n", "mlm_ids", ",", "mlm_labels", "=", "(", "\n", "flatten_mlms", "[", "\"input_ids\"", "]", "[", "batch_size", "*", "(", "i", ")", ":", "batch_size", "*", "(", "i", "+", "1", ")", "]", ",", "\n", "flatten_mlms", "[", "\"labels\"", "]", "[", "batch_size", "*", "(", "i", ")", ":", "batch_size", "*", "(", "i", "+", "1", ")", "]", ",", "\n", ")", "\n", "\n", "input_ids", "=", "torch", ".", "zeros_like", "(", "mlm_ids", ")", "\n", "attention_mask", "=", "torch", ".", "zeros_like", "(", "mlm_ids", ")", "\n", "for", "_i", ",", "encoding", "in", "enumerate", "(", "encodings", ")", ":", "\n", "                    ", "_input_ids", ",", "_attention_mask", "=", "(", "\n", "torch", ".", "tensor", "(", "encoding", "[", "\"input_ids\"", "]", ")", ",", "\n", "torch", ".", "tensor", "(", "encoding", "[", "\"attention_mask\"", "]", ")", ",", "\n", ")", "\n", "input_ids", "[", "_i", ",", ":", "len", "(", "_input_ids", ")", "]", "=", "_input_ids", "\n", "attention_mask", "[", "_i", ",", ":", "len", "(", "_attention_mask", ")", "]", "=", "_attention_mask", "\n", "\n", "", "dict_batch", "[", "txt_key", "]", "=", "texts", "\n", "dict_batch", "[", "f\"{txt_key}_ids\"", "]", "=", "input_ids", "\n", "dict_batch", "[", "f\"{txt_key}_labels\"", "]", "=", "torch", ".", "full_like", "(", "input_ids", ",", "-", "100", ")", "\n", "dict_batch", "[", "f\"{txt_key}_ids_mlm\"", "]", "=", "mlm_ids", "\n", "dict_batch", "[", "f\"{txt_key}_labels_mlm\"", "]", "=", "mlm_labels", "\n", "dict_batch", "[", "f\"{txt_key}_masks\"", "]", "=", "attention_mask", "\n", "\n", "", "", "return", "dict_batch", "\n", "\n", "\n", "# def collate(self, batch, mlm_collator):", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.base_dataset.sample_frames": [[306, 322], ["min", "numpy.linspace().astype", "enumerate", "ranges.append", "numpy.linspace", "random.choice", "range"], "function", ["None"], ["#     keys = set([key for b in batch for key in b.keys()])", "\n", "#     dict_batch = {k: [dic[k] if k in dic else None for dic in batch] for k in keys}", "\n", "#     # print(dict_batch)", "\n", "#", "\n", "#     img_keys = [k for k in list(dict_batch.keys()) if \"video\" in k]", "\n", "#     img_sizes = list()", "\n", "#", "\n", "#     for img_key in img_keys:", "\n", "#         img_sizes += [ii.shape for i in dict_batch[img_key][0] if i is not None for ii in i]", "\n", "#", "\n", "#     for size in img_sizes:", "\n", "#         assert (", "\n", "#             len(size) == 4", "\n", "#         ), f\"Collate error, an image should be in shape of (N, 3,  H, W), instead of given {size}\"", "\n", "#", "\n", "#     if len(img_keys) != 0:", "\n", "#         global_max_height = max([i[2] for i in img_sizes])", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.base_dataset.read_frames_cv2": [[324, 350], ["cv2.VideoCapture", "cv2.VideoCapture.isOpened", "int", "base_dataset.sample_frames", "torch.stack", "cv2.VideoCapture.release", "cv2.VideoCapture.get", "cv2.VideoCapture.set", "cv2.VideoCapture.read", "cv2.cvtColor", "torch.from_numpy().byte", "frame.permute.permute", "torch.stack.append", "success_idxs.append", "torch.from_numpy"], "function", ["home.repos.pwc.inspect_result.showlab_all-in-one.datasets.base_dataset.sample_frames"], ["#         local_max_height = min([i[2] for i in img_sizes])", "\n", "#         local_max_width = min([i[3] for i in img_sizes])", "\n", "#     for img_key in img_keys:", "\n", "#         img = dict_batch[img_key]", "\n", "#         global_view_size = len(dict_batch[img_key][0][0])", "\n", "#         local_view_size = len(dict_batch[img_key][0][1])", "\n", "#         # for image, padding one time dimension", "\n", "#         new_images = [", "\n", "#             [", "\n", "#                 torch.zeros(batch_size, 1, 3, global_max_height, global_max_width)", "\n", "#                 for _ in range(global_view_size)", "\n", "#             ],", "\n", "#             [", "\n", "#                 torch.zeros(batch_size, 1, 3, local_max_height, local_max_width)", "\n", "#                 for _ in range(local_view_size)", "\n", "#             ]", "\n", "#         ]", "\n", "#         # print(len(img))", "\n", "#         for bi in range(batch_size):", "\n", "#             orig_batch = img[bi]", "\n", "#             for vi in range(global_view_size):", "\n", "#                 if orig_batch is None:", "\n", "#                     continue", "\n", "#                 else:", "\n", "#                     orig = img[bi][0][vi]", "\n", "#                     new_images[0][vi][bi, :, :, : orig.shape[2], : orig.shape[3]] = orig", "\n", "#", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.base_dataset.read_frames_decord": [[352, 360], ["decord.VideoReader", "len", "base_dataset.sample_frames", "decord.VideoReader.get_batch", "frames.permute.permute", "frames.permute.float"], "function", ["home.repos.pwc.inspect_result.showlab_all-in-one.datasets.base_dataset.sample_frames"], ["#             orig_batch = img[bi]", "\n", "#             for vi in range(local_view_size):", "\n", "#                 if orig_batch is None:", "\n", "#                     continue", "\n", "#                 else:", "\n", "#                     orig = img[bi][1][vi]", "\n", "#                     new_images[1][vi][bi, :, :, : orig.shape[2], : orig.shape[3]] = orig", "\n", "#", "\n", "#         dict_batch[img_key] = new_images", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.cc3m.CC3MDataset.__init__": [[11, 24], ["cc3m.CC3MDataset._load_metadata", "base_dataset.BaseDataset.__init__"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_v2.Ego4DDataset._load_metadata", "home.repos.pwc.inspect_result.showlab_all-in-one.transforms.utils.UnNormalize.__init__"], ["    ", "def", "__init__", "(", "self", ",", "*", "args", ",", "split", "=", "\"\"", ",", "**", "kwargs", ")", ":", "\n", "        ", "assert", "split", "in", "[", "\"train\"", ",", "\"val\"", ",", "\"test\"", "]", "\n", "self", ".", "split", "=", "split", "\n", "self", ".", "metadata", "=", "None", "\n", "self", ".", "_load_metadata", "(", ")", "\n", "if", "split", "==", "\"train\"", ":", "\n", "            ", "names", "=", "[", "\"cc3m_train\"", "]", "\n", "", "elif", "split", "==", "\"val\"", ":", "\n", "            ", "names", "=", "[", "\"cc3m_val\"", "]", "\n", "", "elif", "split", "==", "\"test\"", ":", "\n", "            ", "names", "=", "[", "\"cc3m_val\"", "]", "\n", "\n", "", "print", "(", "names", ",", "\": \"", ",", "len", "(", "self", ".", "metadata", ")", ",", "\"samples in total.\"", ")", "\n", "super", "(", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ",", "names", "=", "names", ",", "text_column_name", "=", "\"caption\"", ")", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.cc3m.CC3MDataset._load_metadata": [[26, 40], ["pandas.read_csv", "os.path.join"], "methods", ["None"], ["\n", "", "def", "_load_metadata", "(", "self", ")", ":", "\n", "# download specific", "\n", "        ", "metadata_dir", "=", "'./meta_data/cc3m'", "\n", "split_files", "=", "{", "\n", "'train'", ":", "'cc3m_training_success_full.tsv'", ",", "\n", "'val'", ":", "'cc3m_validation_success_full.tsv'", ",", "# there is no test", "\n", "'test'", ":", "'cc3m_validation_success_full.tsv'", "\n", "}", "\n", "target_split_fp", "=", "split_files", "[", "self", ".", "split", "]", "\n", "metadata", "=", "pd", ".", "read_csv", "(", "os", ".", "path", ".", "join", "(", "metadata_dir", ",", "target_split_fp", ")", ",", "sep", "=", "'\\t'", ")", "\n", "# elif self.split == 'val':", "\n", "#     metadata = metadata.sample(1000, random_state=0)  # 15k val is unnecessarily large, downsample.", "\n", "\n", "self", ".", "metadata", "=", "metadata", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.cc3m.CC3MDataset._get_image_path": [[41, 50], ["os.path.join", "os.path.join"], "methods", ["None"], ["\n", "", "def", "_get_image_path", "(", "self", ",", "sample", ")", ":", "\n", "# conceptual captions uses this hashing to create the filename", "\n", "        ", "rel_dir", "=", "'training'", "\n", "if", "self", ".", "split", "!=", "'train'", ":", "\n", "            ", "rel_dir", "=", "'validation'", "\n", "", "rel_fp", "=", "os", ".", "path", ".", "join", "(", "rel_dir", ",", "sample", "[", "1", "]", ")", "\n", "#rel_fp = os.path.join(rel_dir, str(zlib.crc32(sample['thumbnailUrl'].encode('utf-8')) & 0xffffffff))", "\n", "# print(rel_fp)", "\n", "return", "os", ".", "path", ".", "join", "(", "self", ".", "data_dir", ",", "rel_fp", ")", ",", "rel_fp", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.cc3m.CC3MDataset._get_caption": [[51, 53], ["None"], "methods", ["None"], ["\n", "", "def", "_get_caption", "(", "self", ",", "sample", ")", ":", "\n", "        ", "return", "sample", "[", "0", "]", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.cc3m.CC3MDataset.get_raw_image": [[55, 63], ["cc3m.CC3MDataset._get_image_path", "PIL.Image.open().convert", "Exception", "PIL.Image.open"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.datasets.vcr.VCRDataset._get_image_path"], ["\n", "", "def", "get_raw_image", "(", "self", ",", "sample", ")", ":", "\n", "# print(sample)", "\n", "        ", "abs_fp", ",", "rel_fp", "=", "self", ".", "_get_image_path", "(", "sample", ")", "\n", "img", "=", "Image", ".", "open", "(", "abs_fp", ")", ".", "convert", "(", "\"RGB\"", ")", "\n", "if", "img", "is", "None", ":", "\n", "            ", "raise", "Exception", "(", "\"Invalid img!\"", ",", "rel_fp", ")", "\n", "", "else", ":", "\n", "            ", "return", "img", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.cc3m.CC3MDataset._get_object_path": [[64, 75], ["os.path.join", "os.path.join", "os.path.join"], "methods", ["None"], ["\n", "", "", "def", "get_image", "(", "self", ",", "index", ",", "sample", ",", "image_key", "=", "\"image\"", ")", ":", "\n", "        ", "image", "=", "self", ".", "get_raw_image", "(", "sample", ")", "\n", "# image_tensor = [tr(image).unsqueeze(0) for tr in global_transforms]", "\n", "image_tensor", "=", "self", ".", "image_aug", "(", "image", ",", "self", ".", "transforms", ")", "\n", "# image_tensor[0] = image_tensor[0].unsqueeze(0)", "\n", "# print(len(image_tensor))", "\n", "# print(image_tensor[0].size())", "\n", "return", "{", "\n", "\"video\"", ":", "image_tensor", ",", "\n", "\"vid_index\"", ":", "sample", "[", "1", "]", ",", "\n", "\"cap_index\"", ":", "index", ",", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.cc3m.CC3MDataset.get_image": [[76, 87], ["cc3m.CC3MDataset.get_raw_image", "tr().unsqueeze", "tr"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.datasets.vcr.VCRDataset.get_raw_image"], ["\"raw_index\"", ":", "index", ",", "\n", "}", "\n", "\n", "", "def", "get_false_image", "(", "self", ",", "rep", ",", "image_key", "=", "\"image\"", ")", ":", "\n", "        ", "random_index", "=", "random", ".", "randint", "(", "0", ",", "len", "(", "self", ".", "metadata", ")", "-", "1", ")", "\n", "sample", "=", "self", ".", "metadata", ".", "iloc", "[", "random_index", "]", "\n", "image", "=", "self", ".", "get_raw_image", "(", "sample", ")", "\n", "# image_tensor = [tr(image).unsqueeze(0) for tr in global_transforms]", "\n", "image_tensor", "=", "self", ".", "image_aug", "(", "image", ",", "self", ".", "transforms", ")", "\n", "return", "{", "f\"false_video_{rep}\"", ":", "image_tensor", "}", "\n", "\n", "", "def", "get_text", "(", "self", ",", "raw_index", ",", "sample", ")", ":", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.cc3m.CC3MDataset.get_false_image": [[89, 95], ["random.randint", "cc3m.CC3MDataset.get_raw_image", "tr().unsqueeze", "len", "tr"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.datasets.vcr.VCRDataset.get_raw_image"], ["encoding", "=", "self", ".", "tokenizer", "(", "\n", "text", ",", "\n", "padding", "=", "\"max_length\"", ",", "\n", "truncation", "=", "True", ",", "\n", "max_length", "=", "self", ".", "max_text_len", ",", "\n", "return_special_tokens_mask", "=", "True", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.cc3m.CC3MDataset.get_text": [[96, 111], ["cc3m.CC3MDataset.tokenizer"], "methods", ["None"], ["# print(encoding.size())", "\n", "return", "{", "\n", "\"text\"", ":", "(", "text", ",", "encoding", ")", ",", "\n", "\"vid_index\"", ":", "sample", "[", "1", "]", ",", "\n", "\"cap_index\"", ":", "raw_index", ",", "\n", "\"raw_index\"", ":", "raw_index", ",", "\n", "}", "\n", "\n", "", "def", "get_false_text", "(", "self", ",", "rep", ")", ":", "\n", "        ", "random_index", "=", "random", ".", "randint", "(", "0", ",", "len", "(", "self", ".", "metadata", ")", "-", "1", ")", "\n", "sample", "=", "self", ".", "metadata", ".", "iloc", "[", "random_index", "]", "\n", "text", "=", "sample", "[", "0", "]", "\n", "encoding", "=", "self", ".", "tokenizer", "(", "\n", "text", ",", "\n", "truncation", "=", "True", ",", "\n", "max_length", "=", "self", ".", "max_text_len", ",", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.cc3m.CC3MDataset.get_false_text": [[113, 124], ["random.randint", "cc3m.CC3MDataset.tokenizer", "len"], "methods", ["None"], [")", "\n", "return", "{", "f\"false_text_{rep}\"", ":", "(", "text", ",", "encoding", ")", "}", "\n", "\n", "", "def", "get_suite", "(", "self", ",", "index", ")", ":", "\n", "        ", "result", "=", "None", "\n", "# print(self.draw_false_image) # 1", "\n", "while", "result", "is", "None", ":", "\n", "            ", "sample", "=", "self", ".", "metadata", ".", "iloc", "[", "index", "]", "\n", "# print(sample)", "\n", "# try:", "\n", "ret", "=", "dict", "(", ")", "\n", "ret", ".", "update", "(", "self", ".", "get_image", "(", "index", ",", "sample", ")", ")", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.cc3m.CC3MDataset.get_suite": [[125, 149], ["dict", "dict.update", "range", "range", "cc3m.CC3MDataset.get_image", "cc3m.CC3MDataset.get_text", "dict.update", "dict.update", "dict.update", "dict.update", "print", "random.randint", "cc3m.CC3MDataset.get_false_image", "cc3m.CC3MDataset.get_false_text", "len"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.gadgets.my_metrics.VQAScore.update", "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.vcr.VCRDataset.get_image", "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_v2.Ego4DDataset.get_text", "home.repos.pwc.inspect_result.showlab_all-in-one.gadgets.my_metrics.VQAScore.update", "home.repos.pwc.inspect_result.showlab_all-in-one.gadgets.my_metrics.VQAScore.update", "home.repos.pwc.inspect_result.showlab_all-in-one.gadgets.my_metrics.VQAScore.update", "home.repos.pwc.inspect_result.showlab_all-in-one.gadgets.my_metrics.VQAScore.update", "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.vcr.VCRDataset.get_false_image", "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_v2.Ego4DDataset.get_false_text"], ["if", "not", "self", ".", "image_only", ":", "\n", "                ", "txt", "=", "self", ".", "get_text", "(", "index", ",", "sample", ")", "\n", "ret", ".", "update", "(", "{", "\"replica\"", ":", "True", "if", "txt", "[", "\"cap_index\"", "]", ">", "0", "else", "False", "}", ")", "\n", "ret", ".", "update", "(", "txt", ")", "\n", "\n", "", "for", "i", "in", "range", "(", "self", ".", "draw_false_image", ")", ":", "\n", "                ", "ret", ".", "update", "(", "self", ".", "get_false_image", "(", "i", ")", ")", "\n", "", "for", "i", "in", "range", "(", "self", ".", "draw_false_text", ")", ":", "\n", "                ", "ret", ".", "update", "(", "self", ".", "get_false_text", "(", "i", ")", ")", "\n", "", "result", "=", "True", "\n", "# except Exception as e:", "\n", "#     print(f\"Error while read file idx {sample[1]} in {self.names[0]} -> {e}\")", "\n", "#     index = random.randint(0, len(self.metadata) - 1)", "\n", "# ret[\"image\"] = ret[\"image\"].unsqueeze(1)", "\n", "", "return", "ret", "\n", "\n", "", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "metadata", ")", "\n", "\n", "", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "return", "self", ".", "get_suite", "(", "index", ")", "\n", "\n", "", "", ""]], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.cc3m.CC3MDataset.__len__": [[150, 152], ["len"], "methods", ["None"], []], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.cc3m.CC3MDataset.__getitem__": [[153, 155], ["cc3m.CC3MDataset.get_suite"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_v2.Ego4DDataset.get_suite"], []], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.tvqaplus.TVQAPLUSDataset.__init__": [[49, 67], ["tvqaplus.TVQAPLUSDataset._load_metadata", "video_base_dataset.BaseDataset.__init__"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_v2.Ego4DDataset._load_metadata", "home.repos.pwc.inspect_result.showlab_all-in-one.transforms.utils.UnNormalize.__init__"], ["    ", "def", "__init__", "(", "self", ",", "*", "args", ",", "split", "=", "\"\"", ",", "**", "kwargs", ")", ":", "\n", "        ", "assert", "split", "in", "[", "\"train\"", ",", "\"val\"", ",", "\"test\"", "]", "\n", "self", ".", "split", "=", "split", "\n", "self", ".", "metadata", "=", "None", "\n", "self", ".", "_load_metadata", "(", ")", "\n", "if", "split", "==", "\"train\"", ":", "\n", "            ", "names", "=", "[", "\"tvqaplus_train\"", "]", "\n", "", "elif", "split", "==", "\"val\"", ":", "\n", "            ", "names", "=", "[", "\"tvqaplus_val\"", "]", "\n", "", "elif", "split", "==", "\"test\"", ":", "\n", "            ", "names", "=", "[", "\"tvqaplus_test\"", "]", "\n", "\n", "", "super", "(", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ",", "names", "=", "names", ",", "text_column_name", "=", "\"caption\"", ")", "\n", "# for appear objects", "\n", "self", ".", "only_use_relevant_dets", "=", "True", "\n", "if", "self", ".", "only_use_relevant_dets", ":", "\n", "            ", "self", ".", "relevant_dets", "=", "[", "]", "# resort the detection numbers", "\n", "self", ".", "relevant_dets_classes", "=", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.tvqaplus.TVQAPLUSDataset._load_metadata": [[68, 79], ["pandas.read_json", "os.path.join"], "methods", ["None"], ["", "", "def", "_load_metadata", "(", "self", ")", ":", "\n", "# download specific", "\n", "        ", "metadata_dir", "=", "'./meta_data/tvqa'", "\n", "split_files", "=", "{", "\n", "'train'", ":", "'tvqa_plus_train.jsonl'", ",", "\n", "'val'", ":", "'tvqa_plus_val.jsonl'", ",", "\n", "'test'", ":", "'tvqa_plus_test_public.jsonl'", "# no GT label for test set", "\n", "}", "\n", "target_split_fp", "=", "split_files", "[", "self", ".", "split", "]", "\n", "metadata", "=", "pd", ".", "read_json", "(", "os", ".", "path", ".", "join", "(", "metadata_dir", ",", "target_split_fp", ")", ",", "lines", "=", "True", ")", "\n", "self", ".", "metadata", "=", "metadata", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.tvqaplus.TVQAPLUSDataset._get_image_path": [[80, 83], ["os.path.join"], "methods", ["None"], ["", "def", "_get_image_path", "(", "self", ",", "sample", ")", ":", "\n", "        ", "rel_fp", "=", "sample", "[", "'vid_name'", "]", "\n", "return", "os", ".", "path", ".", "join", "(", "self", ".", "data_dir", ",", "rel_fp", ")", ",", "rel_fp", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.tvqaplus.TVQAPLUSDataset._get_caption": [[84, 86], ["None"], "methods", ["None"], ["", "def", "_get_caption", "(", "self", ",", "sample", ")", ":", "\n", "        ", "return", "sample", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.tvqaplus.TVQAPLUSDataset.get_raw_video": [[89, 103], ["tvqaplus.TVQAPLUSDataset._get_image_path", "int", "AllInOne.datasets.video_base_dataset.sample_frames", "torch.stack().permute", "cv2.imread", "torch.from_numpy().byte", "frame.permute.permute.permute", "torch.stack().permute.append", "torch.stack", "float", "float", "torch.from_numpy"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.datasets.vcr.VCRDataset._get_image_path", "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.base_dataset.sample_frames"], ["", "def", "get_raw_video", "(", "self", ",", "sample", ")", ":", "\n", "        ", "abs_fp", ",", "rel_fp", "=", "self", ".", "_get_image_path", "(", "sample", ")", "\n", "[", "beg_time", ",", "end_time", "]", "=", "sample", "[", "'ts'", "]", "\n", "clip_len", "=", "int", "(", "(", "float", "(", "end_time", ")", "-", "float", "(", "beg_time", ")", ")", "*", "3", ")", "\n", "rel_frame_index", "=", "sample_frames", "(", "self", ".", "num_frames", ",", "clip_len", ")", "\n", "# sample N frames here", "\n", "frames", "=", "[", "]", "\n", "for", "index", "in", "rel_frame_index", ":", "\n", "            ", "img", "=", "cv2", ".", "imread", "(", "abs_fp", "+", "'{}.jpg'", ".", "format", "(", "index", ")", ")", "\n", "frame", "=", "torch", ".", "from_numpy", "(", "img", ")", ".", "byte", "(", ")", "\n", "frame", "=", "frame", ".", "permute", "(", "2", ",", "0", ",", "1", ")", "\n", "frames", ".", "append", "(", "frame", ")", "\n", "", "frames", "=", "torch", ".", "stack", "(", "frames", ")", ".", "permute", "(", "1", ",", "0", ",", "2", ",", "3", ")", "\n", "return", "frames", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.tvqaplus.TVQAPLUSDataset.get_text": [[104, 119], ["tvqaplus.TVQAPLUSDataset.get_question", "range", "tvqaplus.TVQAPLUSDataset.tokenizer", "qa_texts.append"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.datasets.vcr.VCRDataset.get_question"], ["", "def", "get_text", "(", "self", ",", "sample", ")", ":", "\n", "        ", "question", "=", "self", ".", "get_question", "(", "sample", ")", "\n", "qa_texts", "=", "[", "]", "\n", "# 5 choices", "\n", "for", "i", "in", "range", "(", "5", ")", ":", "\n", "            ", "raw_text", "=", "question", "+", "\"[SEP]\"", "+", "sample", "[", "\"a{}\"", ".", "format", "(", "i", ")", "]", "\n", "qa_encoding", "=", "self", ".", "tokenizer", "(", "\n", "raw_text", ",", "\n", "padding", "=", "\"max_length\"", ",", "\n", "truncation", "=", "True", ",", "\n", "max_length", "=", "self", ".", "max_text_len", ",", "\n", "return_special_tokens_mask", "=", "True", ",", "\n", ")", "\n", "qa_texts", ".", "append", "(", "(", "raw_text", ",", "qa_encoding", ")", ")", "\n", "", "return", "qa_texts", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.tvqaplus.TVQAPLUSDataset.get_answer_label": [[120, 123], ["int"], "methods", ["None"], ["", "def", "get_answer_label", "(", "self", ",", "sample", ")", ":", "\n", "        ", "answer", "=", "int", "(", "sample", "[", "'answer_idx'", "]", ")", "\n", "return", "answer", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.tvqaplus.TVQAPLUSDataset.get_question": [[124, 126], ["None"], "methods", ["None"], ["", "def", "get_question", "(", "self", ",", "sample", ")", ":", "\n", "        ", "return", "sample", "[", "\"q\"", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.tvqaplus.TVQAPLUSDataset.__len__": [[127, 129], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "metadata", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.tvqaplus.TVQAPLUSDataset.__getitem__": [[130, 148], ["tvqaplus.TVQAPLUSDataset.get_answer_label", "tvqaplus.TVQAPLUSDataset.get_text", "range", "tvqaplus.TVQAPLUSDataset.get_video", "ret.update"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.datasets.msvdqa.MSVDQADataset.get_answer_label", "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_v2.Ego4DDataset.get_text", "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_v2.Ego4DDataset.get_video", "home.repos.pwc.inspect_result.showlab_all-in-one.gadgets.my_metrics.VQAScore.update"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "sample", "=", "self", ".", "metadata", ".", "iloc", "[", "index", "]", "\n", "self", ".", "relevant_dets", "=", "[", "]", "# initalize", "\n", "self", ".", "relevant_dets_classes", "=", "[", "]", "\n", "answer", "=", "self", ".", "get_answer_label", "(", "sample", ")", "\n", "ret", "=", "{", "\n", "\"vid_index\"", ":", "index", ",", "\n", "\"cap_index\"", ":", "index", ",", "\n", "\"raw_index\"", ":", "index", ",", "\n", "'answer'", ":", "answer", "\n", "}", "\n", "qa_texts", "=", "self", ".", "get_text", "(", "sample", ")", "\n", "ret", "[", "\"text\"", "]", "=", "qa_texts", "[", "0", "]", "\n", "for", "i", "in", "range", "(", "self", ".", "draw_options_text", "-", "1", ")", ":", "\n", "            ", "ret", ".", "update", "(", "{", "f\"options_text_{i}\"", ":", "qa_texts", "[", "i", "+", "1", "]", "}", ")", "\n", "", "video_tensor", "=", "self", ".", "get_video", "(", "sample", ")", "\n", "ret", "[", "\"video\"", "]", "=", "video_tensor", "\n", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.tgif.TGIFDataset.__init__": [[12, 33], ["video_base_dataset.BaseDataset.__init__", "tgif.TGIFDataset._load_metadata"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.transforms.utils.UnNormalize.__init__", "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_v2.Ego4DDataset._load_metadata"], ["    ", "def", "__init__", "(", "self", ",", "*", "args", ",", "split", "=", "\"\"", ",", "**", "kwargs", ")", ":", "\n", "        ", "assert", "split", "in", "[", "\"train\"", ",", "\"val\"", ",", "\"test\"", "]", "\n", "self", ".", "split", "=", "split", "\n", "self", ".", "metadata", "=", "None", "\n", "self", ".", "ans_lab_dict", "=", "None", "\n", "if", "split", "==", "\"train\"", ":", "\n", "            ", "names", "=", "[", "\"tgif_train\"", "]", "\n", "", "elif", "split", "==", "\"val\"", ":", "\n", "            ", "names", "=", "[", "\"tgif_val\"", "]", "\n", "", "elif", "split", "==", "\"test\"", ":", "\n", "            ", "names", "=", "[", "\"tgif_test\"", "]", "\n", "\n", "", "super", "(", ")", ".", "__init__", "(", "\n", "*", "args", ",", "\n", "**", "kwargs", ",", "\n", "names", "=", "names", ",", "\n", "text_column_name", "=", "\"questions\"", ",", "\n", "remove_duplicate", "=", "False", ",", "\n", ")", "\n", "# self.num_frames = 4", "\n", "self", ".", "_load_metadata", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.tgif.TGIFDataset._load_metadata": [[34, 49], ["os.path.join", "pandas.read_json", "open", "json.load", "os.path.join"], "methods", ["None"], ["", "def", "_load_metadata", "(", "self", ")", ":", "\n", "        ", "metadata_dir", "=", "'./meta_data/tgif'", "\n", "split_files", "=", "{", "\n", "'train'", ":", "'frameqa_train.jsonl'", ",", "\n", "'val'", ":", "'frameqa_test.jsonl'", ",", "# frameqa_val.jsonl", "\n", "'test'", ":", "'frameqa_test.jsonl'", "\n", "}", "\n", "target_split_fp", "=", "split_files", "[", "self", ".", "split", "]", "\n", "answer_fp", "=", "os", ".", "path", ".", "join", "(", "metadata_dir", ",", "'frameqa_trainval_ans2label.json'", ")", "\n", "# answer_fp = os.path.join(metadata_dir, 'msrvtt_qa_ans2label.json')", "\n", "with", "open", "(", "answer_fp", ",", "'r'", ")", "as", "JSON", ":", "\n", "            ", "self", ".", "ans_lab_dict", "=", "json", ".", "load", "(", "JSON", ")", "\n", "# path_or_buf=os.path.join(metadata_dir, target_split_fp)", "\n", "", "metadata", "=", "pd", ".", "read_json", "(", "os", ".", "path", ".", "join", "(", "metadata_dir", ",", "target_split_fp", ")", ",", "lines", "=", "True", ")", "\n", "self", ".", "metadata", "=", "metadata", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.tgif.TGIFDataset._get_video_path": [[50, 52], ["os.path.join"], "methods", ["None"], ["", "def", "_get_video_path", "(", "self", ",", "sample", ")", ":", "\n", "        ", "return", "os", ".", "path", ".", "join", "(", "self", ".", "data_dir", ",", "'gifs'", ",", "sample", "[", "'gif_name'", "]", ")", "+", "'.gif'", ",", "sample", "[", "'gif_name'", "]", "+", "'.gif'", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.tgif.TGIFDataset.get_raw_video": [[53, 60], ["tgif.TGIFDataset._get_video_path", "video_base_dataset.read_frames_gif", "Exception"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_v2.Ego4DDataset._get_video_path", "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.video_base_dataset.read_frames_gif"], ["", "def", "get_raw_video", "(", "self", ",", "sample", ")", ":", "\n", "        ", "abs_fp", ",", "rel_fp", "=", "self", ".", "_get_video_path", "(", "sample", ")", "\n", "imgs", ",", "idxs", ",", "vlen", "=", "read_frames_gif", "(", "abs_fp", ",", "self", ".", "num_frames", ",", "mode", "=", "self", ".", "split", ")", "\n", "if", "imgs", "is", "None", ":", "\n", "            ", "raise", "Exception", "(", "\"Invalid img!\"", ",", "rel_fp", ")", "\n", "", "else", ":", "\n", "            ", "return", "imgs", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.tgif.TGIFDataset.get_text": [[61, 71], ["tgif.TGIFDataset.tokenizer"], "methods", ["None"], ["", "", "def", "get_text", "(", "self", ",", "sample", ")", ":", "\n", "        ", "text", "=", "sample", "[", "'question'", "]", "\n", "encoding", "=", "self", ".", "tokenizer", "(", "\n", "text", ",", "\n", "padding", "=", "\"max_length\"", ",", "\n", "truncation", "=", "True", ",", "\n", "max_length", "=", "self", ".", "max_text_len", ",", "\n", "return_special_tokens_mask", "=", "True", ",", "\n", ")", "\n", "return", "(", "text", ",", "encoding", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.tgif.TGIFDataset.get_answer_label": [[72, 83], ["numpy.zeros().astype", "len", "numpy.zeros"], "methods", ["None"], ["", "def", "get_answer_label", "(", "self", ",", "sample", ")", ":", "\n", "        ", "text", "=", "sample", "[", "'answer'", "]", "\n", "ans_total_len", "=", "len", "(", "self", ".", "ans_lab_dict", ")", "+", "1", "# one additional class", "\n", "try", ":", "\n", "            ", "ans_label", "=", "self", ".", "ans_lab_dict", "[", "text", "]", "#", "\n", "", "except", "KeyError", ":", "\n", "            ", "ans_label", "=", "-", "100", "# ignore classes", "\n", "# ans_label = 1500 # other classes", "\n", "", "scores", "=", "np", ".", "zeros", "(", "ans_total_len", ")", ".", "astype", "(", "int", ")", "\n", "scores", "[", "ans_label", "]", "=", "1", "\n", "return", "text", ",", "ans_label", ",", "scores", "\n", "# return text, ans_label_vector, scores", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.tgif.TGIFDataset.__getitem__": [[85, 105], ["tgif.TGIFDataset.get_video", "tgif.TGIFDataset.get_text", "tgif.TGIFDataset.get_answer_label", "list", "list", "list"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_v2.Ego4DDataset.get_video", "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_v2.Ego4DDataset.get_text", "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.msvdqa.MSVDQADataset.get_answer_label"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "sample", "=", "self", ".", "metadata", ".", "iloc", "[", "index", "]", "\n", "video_tensor", "=", "self", ".", "get_video", "(", "sample", ")", "\n", "text", "=", "self", ".", "get_text", "(", "sample", ")", "\n", "# index, question_index = self.index_mapper[index]", "\n", "qid", "=", "index", "\n", "if", "self", ".", "split", "!=", "\"test\"", ":", "\n", "            ", "answers", ",", "labels", ",", "scores", "=", "self", ".", "get_answer_label", "(", "sample", ")", "\n", "", "else", ":", "\n", "            ", "answers", "=", "list", "(", ")", "\n", "labels", "=", "list", "(", ")", "\n", "scores", "=", "list", "(", ")", "\n", "\n", "", "return", "{", "\n", "\"video\"", ":", "video_tensor", ",", "\n", "\"text\"", ":", "text", ",", "\n", "\"vqa_answer\"", ":", "answers", ",", "\n", "\"vqa_labels\"", ":", "labels", ",", "\n", "\"vqa_scores\"", ":", "scores", ",", "\n", "\"qid\"", ":", "qid", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.tgif.TGIFDataset.__len__": [[107, 109], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "metadata", ")", "", "", "", ""]], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.nlvr2_dataset.NLVR2Dataset.__init__": [[7, 24], ["base_dataset.BaseDataset.__init__"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.transforms.utils.UnNormalize.__init__"], ["    ", "def", "__init__", "(", "self", ",", "*", "args", ",", "split", "=", "\"\"", ",", "**", "kwargs", ")", ":", "\n", "        ", "assert", "split", "in", "[", "\"train\"", ",", "\"val\"", ",", "\"test\"", "]", "\n", "self", ".", "split", "=", "split", "\n", "\n", "if", "split", "==", "\"train\"", ":", "\n", "            ", "names", "=", "[", "\"nlvr2_train\"", "]", "\n", "", "elif", "split", "==", "\"val\"", ":", "\n", "            ", "names", "=", "[", "\"nlvr2_dev\"", ",", "\"nlvr2_test1\"", "]", "\n", "", "elif", "split", "==", "\"test\"", ":", "\n", "            ", "names", "=", "[", "\"nlvr2_dev\"", ",", "\"nlvr2_test1\"", "]", "\n", "\n", "", "super", "(", ")", ".", "__init__", "(", "\n", "*", "args", ",", "\n", "**", "kwargs", ",", "\n", "names", "=", "names", ",", "\n", "text_column_name", "=", "\"questions\"", ",", "\n", "remove_duplicate", "=", "False", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.nlvr2_dataset.NLVR2Dataset.__getitem__": [[26, 51], ["[].as_py", "nlvr2_dataset.NLVR2Dataset.get_image", "nlvr2_dataset.NLVR2Dataset.get_image", "nlvr2_dataset.NLVR2Dataset.get_text", "print", "random.randint", "len"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.datasets.vcr.VCRDataset.get_image", "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.vcr.VCRDataset.get_image", "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_v2.Ego4DDataset.get_text"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "result", "=", "None", "\n", "while", "result", "is", "None", ":", "\n", "            ", "try", ":", "\n", "                ", "image_tensor_0", "=", "self", ".", "get_image", "(", "index", ",", "image_key", "=", "\"image_0\"", ")", "[", "\"image\"", "]", "\n", "image_tensor_1", "=", "self", ".", "get_image", "(", "index", ",", "image_key", "=", "\"image_1\"", ")", "[", "\"image\"", "]", "\n", "text", "=", "self", ".", "get_text", "(", "index", ")", "[", "\"text\"", "]", "\n", "result", "=", "True", "\n", "", "except", ":", "\n", "                ", "print", "(", "\n", "f\"error while read file idx {index} in {self.names[0]}\"", ",", "\n", "file", "=", "sys", ".", "stderr", ",", "\n", ")", "\n", "index", "=", "random", ".", "randint", "(", "0", ",", "len", "(", "self", ".", "index_mapper", ")", "-", "1", ")", "\n", "\n", "", "", "index", ",", "question_index", "=", "self", ".", "index_mapper", "[", "index", "]", "\n", "answers", "=", "self", ".", "table", "[", "\"answers\"", "]", "[", "index", "]", "[", "question_index", "]", ".", "as_py", "(", ")", "\n", "answers", "=", "answers", "==", "\"True\"", "\n", "\n", "return", "{", "\n", "\"image_0\"", ":", "image_tensor_0", ",", "\n", "\"image_1\"", ":", "image_tensor_1", ",", "\n", "\"text\"", ":", "text", ",", "\n", "\"answers\"", ":", "answers", ",", "\n", "\"table_name\"", ":", "self", ".", "table_names", "[", "index", "]", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.f30k_caption_karpathy_dataset.F30KCaptionKarpathyDataset.__init__": [[5, 16], ["base_dataset.BaseDataset.__init__"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.transforms.utils.UnNormalize.__init__"], ["    ", "def", "__init__", "(", "self", ",", "*", "args", ",", "split", "=", "\"\"", ",", "**", "kwargs", ")", ":", "\n", "        ", "assert", "split", "in", "[", "\"train\"", ",", "\"val\"", ",", "\"test\"", "]", "\n", "\n", "if", "split", "==", "\"train\"", ":", "\n", "            ", "names", "=", "[", "\"f30k_caption_karpathy_train\"", ",", "\"f30k_caption_karpathy_val\"", "]", "\n", "", "elif", "split", "==", "\"val\"", ":", "\n", "            ", "names", "=", "[", "\"f30k_caption_karpathy_test\"", "]", "\n", "", "elif", "split", "==", "\"test\"", ":", "\n", "            ", "names", "=", "[", "\"f30k_caption_karpathy_test\"", "]", "\n", "\n", "", "super", "(", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ",", "names", "=", "names", ",", "text_column_name", "=", "\"caption\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.f30k_caption_karpathy_dataset.F30KCaptionKarpathyDataset.__getitem__": [[17, 19], ["f30k_caption_karpathy_dataset.F30KCaptionKarpathyDataset.get_suite"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_v2.Ego4DDataset.get_suite"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "return", "self", ".", "get_suite", "(", "index", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.msrvtt.MSRVTTDataset.__init__": [[10, 24], ["video_base_dataset.BaseDataset.__init__", "msrvtt.MSRVTTDataset._load_metadata"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.transforms.utils.UnNormalize.__init__", "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_v2.Ego4DDataset._load_metadata"], ["    ", "def", "__init__", "(", "self", ",", "*", "args", ",", "split", "=", "\"\"", ",", "**", "kwargs", ")", ":", "\n", "        ", "assert", "split", "in", "[", "\"train\"", ",", "\"val\"", ",", "\"test\"", "]", "\n", "self", ".", "split", "=", "split", "\n", "self", ".", "metadata", "=", "None", "\n", "self", ".", "cut", "=", "\"jsfusion\"", "\n", "if", "split", "==", "\"train\"", ":", "\n", "            ", "names", "=", "[", "\"msrvtt_train\"", "]", "\n", "", "elif", "split", "==", "\"val\"", ":", "\n", "            ", "names", "=", "[", "\"msrvtt_val\"", "]", "\n", "", "elif", "split", "==", "\"test\"", ":", "\n", "            ", "names", "=", "[", "\"msrvtt_val\"", "]", "\n", "", "super", "(", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ",", "names", "=", "names", ",", "text_column_name", "=", "\"caption\"", ")", "\n", "\n", "self", ".", "_load_metadata", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.msrvtt.MSRVTTDataset._load_metadata": [[25, 75], ["os.path.join", "pandas.DataFrame", "os.path.join", "pandas.read_csv", "pandas.read_csv", "[].apply", "pandas.DataFrame", "print", "open", "json.load", "os.path.join", "os.path.join", "len", "len", "len", "pandas.Series", "pandas.DataFrame", "pandas.DataFrame.apply", "numpy.load", "len", "df[].isin", "df[].isin", "pandas.DataFrame.groupby", "os.path.join", "ValueError", "msg.format"], "methods", ["None"], ["", "def", "_load_metadata", "(", "self", ")", ":", "\n", "        ", "json_fp", "=", "os", ".", "path", ".", "join", "(", "self", ".", "data_dir", ",", "'annotation'", ",", "'MSR_VTT.json'", ")", "\n", "with", "open", "(", "json_fp", ",", "'r'", ")", "as", "fid", ":", "\n", "            ", "data", "=", "json", ".", "load", "(", "fid", ")", "\n", "", "df", "=", "pd", ".", "DataFrame", "(", "data", "[", "'annotations'", "]", ")", "\n", "\n", "split_dir", "=", "os", ".", "path", ".", "join", "(", "self", ".", "data_dir", ",", "'high-quality'", ",", "'structured-symlinks'", ")", "\n", "js_test_cap_idx_path", "=", "None", "\n", "challenge_splits", "=", "{", "\"val\"", ",", "\"public_server_val\"", ",", "\"public_server_test\"", "}", "\n", "if", "self", ".", "cut", "==", "\"miech\"", ":", "# 7k", "\n", "            ", "train_list_path", "=", "\"train_list_miech.txt\"", "\n", "test_list_path", "=", "\"test_list_miech.txt\"", "# 1k", "\n", "", "elif", "self", ".", "cut", "==", "\"jsfusion\"", ":", "# 9k", "\n", "            ", "train_list_path", "=", "\"train_list_jsfusion.txt\"", "\n", "test_list_path", "=", "\"val_list_jsfusion.txt\"", "# 1k", "\n", "js_test_cap_idx_path", "=", "\"jsfusion_val_caption_idx.pkl\"", "\n", "", "elif", "self", ".", "cut", "in", "{", "\"full-val\"", ",", "\"full-test\"", "}", ":", "\n", "            ", "train_list_path", "=", "\"train_list_full.txt\"", "\n", "if", "self", ".", "cut", "==", "\"full-val\"", ":", "\n", "                ", "test_list_path", "=", "\"val_list_full.txt\"", "\n", "", "else", ":", "\n", "                ", "test_list_path", "=", "\"test_list_full.txt\"", "\n", "", "", "elif", "self", ".", "cut", "in", "challenge_splits", ":", "\n", "            ", "train_list_path", "=", "\"train_list.txt\"", "\n", "if", "self", ".", "cut", "==", "\"val\"", ":", "\n", "                ", "test_list_path", "=", "f\"{self.cut}_list.txt\"", "\n", "", "else", ":", "\n", "                ", "test_list_path", "=", "f\"{self.cut}.txt\"", "\n", "", "", "else", ":", "\n", "            ", "msg", "=", "\"unrecognised MSRVTT split: {}\"", "\n", "raise", "ValueError", "(", "msg", ".", "format", "(", "self", ".", "cut", ")", ")", "\n", "\n", "", "train_df", "=", "pd", ".", "read_csv", "(", "os", ".", "path", ".", "join", "(", "split_dir", ",", "train_list_path", ")", ",", "names", "=", "[", "'videoid'", "]", ")", "\n", "test_df", "=", "pd", ".", "read_csv", "(", "os", ".", "path", ".", "join", "(", "split_dir", ",", "test_list_path", ")", ",", "names", "=", "[", "'videoid'", "]", ")", "\n", "self", ".", "split_sizes", "=", "{", "'train'", ":", "len", "(", "train_df", ")", ",", "'val'", ":", "len", "(", "test_df", ")", ",", "'test'", ":", "len", "(", "test_df", ")", "}", "\n", "\n", "if", "self", ".", "split", "==", "'train'", ":", "\n", "            ", "df", "=", "df", "[", "df", "[", "'image_id'", "]", ".", "isin", "(", "train_df", "[", "'videoid'", "]", ")", "]", "\n", "", "else", ":", "\n", "            ", "df", "=", "df", "[", "df", "[", "'image_id'", "]", ".", "isin", "(", "test_df", "[", "'videoid'", "]", ")", "]", "\n", "\n", "", "self", ".", "metadata", "=", "df", ".", "groupby", "(", "[", "'image_id'", "]", ")", "[", "'caption'", "]", ".", "apply", "(", "list", ")", "\n", "if", "js_test_cap_idx_path", "is", "not", "None", "and", "self", ".", "split", "!=", "'train'", ":", "\n", "            ", "caps", "=", "pd", ".", "Series", "(", "np", ".", "load", "(", "os", ".", "path", ".", "join", "(", "split_dir", ",", "js_test_cap_idx_path", ")", ",", "allow_pickle", "=", "True", ")", ")", "\n", "new_res", "=", "pd", ".", "DataFrame", "(", "{", "'caps'", ":", "self", ".", "metadata", ",", "'cap_idx'", ":", "caps", "}", ")", "\n", "new_res", "[", "'test_caps'", "]", "=", "new_res", ".", "apply", "(", "lambda", "x", ":", "[", "x", "[", "'caps'", "]", "[", "x", "[", "'cap_idx'", "]", "]", "]", ",", "axis", "=", "1", ")", "\n", "self", ".", "metadata", "=", "new_res", "[", "'test_caps'", "]", "\n", "\n", "", "self", ".", "metadata", "=", "pd", ".", "DataFrame", "(", "{", "'captions'", ":", "self", ".", "metadata", "}", ")", "\n", "print", "(", "\"load split {}, {} samples\"", ".", "format", "(", "self", ".", "split", ",", "len", "(", "self", ".", "metadata", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.msrvtt.MSRVTTDataset._get_caption": [[77, 84], ["random.choice"], "methods", ["None"], ["", "def", "_get_caption", "(", "self", ",", "sample", ")", ":", "\n", "        ", "caption_sample", "=", "\"rand\"", "\n", "if", "self", ".", "split", "in", "[", "'train'", ",", "'val'", "]", "and", "caption_sample", "==", "\"rand\"", ":", "\n", "            ", "caption", "=", "random", ".", "choice", "(", "sample", "[", "'captions'", "]", ")", "\n", "", "else", ":", "\n", "            ", "caption", "=", "sample", "[", "'captions'", "]", "[", "0", "]", "\n", "", "return", "caption", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.lsmdc_choice.LSMDCChoiceDataset.__init__": [[9, 29], ["video_base_dataset.BaseDataset.__init__", "lsmdc_choice.LSMDCChoiceDataset._load_metadata"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.transforms.utils.UnNormalize.__init__", "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_v2.Ego4DDataset._load_metadata"], ["        ", "assert", "split", "in", "[", "\"train\"", ",", "\"val\"", ",", "\"test\"", "]", "\n", "self", ".", "split", "=", "split", "\n", "self", ".", "metadata", "=", "None", "\n", "self", ".", "ans_lab_dict", "=", "None", "\n", "if", "split", "==", "\"train\"", ":", "\n", "            ", "names", "=", "[", "\"lsmdc_choice_train\"", "]", "\n", "", "elif", "split", "==", "\"val\"", ":", "\n", "            ", "names", "=", "[", "\"lsmdc_choice_val\"", "]", "\n", "", "elif", "split", "==", "\"test\"", ":", "\n", "            ", "names", "=", "[", "\"lsmdc_choice_test\"", "]", "# vqav2_test-dev for test-dev", "\n", "\n", "", "super", "(", ")", ".", "__init__", "(", "\n", "*", "args", ",", "\n", "**", "kwargs", ",", "\n", "names", "=", "names", ",", "\n", "text_column_name", "=", "\"unknown\"", ",", "\n", "remove_duplicate", "=", "False", ",", "\n", ")", "\n", "self", ".", "_load_metadata", "(", ")", "\n", "\n", "", "def", "_load_metadata", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.lsmdc_choice.LSMDCChoiceDataset._load_metadata": [[30, 59], ["print", "pandas.read_csv", "range", "print", "os.path.join", "os.path.join", "len", "sub_path.replace.replace.replace", "dict", "datalist.append", "video_fp.split", "sub_path.replace.replace.split", "len", "range"], "methods", ["None"], ["        ", "metadata_dir", "=", "'./meta_data/lsmdc'", "\n", "split_files", "=", "{", "\n", "'train'", ":", "'LSMDC16_multiple_choice_train.csv'", ",", "\n", "'val'", ":", "'LSMDC16_multiple_choice_test_randomized.csv'", ",", "# 'LSMDC16_multiple_choice_valid.csv',", "\n", "'test'", ":", "'LSMDC16_multiple_choice_test_randomized.csv'", "\n", "}", "\n", "target_split_fp", "=", "split_files", "[", "self", ".", "split", "]", "\n", "print", "(", "os", ".", "path", ".", "join", "(", "metadata_dir", ",", "target_split_fp", ")", ")", "\n", "metadata", "=", "pd", ".", "read_csv", "(", "os", ".", "path", ".", "join", "(", "metadata_dir", ",", "target_split_fp", ")", ",", "sep", "=", "'\\t'", ",", "header", "=", "None", ",", "error_bad_lines", "=", "False", ")", "\n", "self", ".", "metadata", "=", "metadata", "\n", "datalist", "=", "[", "]", "\n", "for", "raw_id", "in", "range", "(", "len", "(", "metadata", ")", ")", ":", "\n", "            ", "raw_d", "=", "metadata", ".", "iloc", "[", "raw_id", "]", "\n", "video_fp", "=", "raw_d", "[", "0", "]", "\n", "sub_path", "=", "video_fp", ".", "split", "(", "'.'", ")", "[", "0", "]", "\n", "remove", "=", "sub_path", ".", "split", "(", "'_'", ")", "[", "-", "1", "]", "\n", "sub_path", "=", "sub_path", ".", "replace", "(", "'_'", "+", "remove", ",", "'/'", ")", "\n", "rel_video_fp", "=", "sub_path", "+", "video_fp", "+", "'.avi'", "\n", "options", "=", "[", "raw_d", "[", "idx", "]", "for", "idx", "in", "range", "(", "5", ",", "10", ")", "]", "\n", "d", "=", "dict", "(", "\n", "id", "=", "video_fp", ",", "\n", "vid_id", "=", "rel_video_fp", ",", "\n", "answer", "=", "raw_d", "[", "10", "]", "-", "1", "if", "self", ".", "split", "in", "[", "'val'", ",", "'test'", "]", "else", "0", ",", "\n", "options", "=", "options", ",", "\n", ")", "\n", "datalist", ".", "append", "(", "d", ")", "\n", "", "self", ".", "metadata", "=", "datalist", "\n", "print", "(", "\"load split {}, {} samples\"", ".", "format", "(", "self", ".", "split", ",", "len", "(", "self", ".", "metadata", ")", ")", ")", "\n", "\n", "", "def", "_get_video_path", "(", "self", ",", "sample", ")", ":", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.lsmdc_choice.LSMDCChoiceDataset._get_video_path": [[60, 66], ["os.path.join"], "methods", ["None"], ["        ", "rel_video_fp", "=", "sample", "[", "'vid_id'", "]", "\n", "full_video_fp", "=", "os", ".", "path", ".", "join", "(", "self", ".", "data_dir", ",", "rel_video_fp", ")", "\n", "# print(full_video_fp)", "\n", "# assert os.path.exists(full_video_fp)", "\n", "return", "full_video_fp", ",", "rel_video_fp", "\n", "\n", "", "def", "get_text", "(", "self", ",", "sample", ")", ":", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.lsmdc_choice.LSMDCChoiceDataset.get_text": [[67, 79], ["lsmdc_choice.LSMDCChoiceDataset.tokenizer", "texts.append"], "methods", ["None"], ["        ", "texts", "=", "[", "]", "\n", "for", "text", "in", "sample", "[", "'options'", "]", ":", "\n", "            ", "encoding", "=", "self", ".", "tokenizer", "(", "\n", "text", ",", "\n", "padding", "=", "\"max_length\"", ",", "\n", "truncation", "=", "True", ",", "\n", "max_length", "=", "self", ".", "max_text_len", ",", "\n", "return_special_tokens_mask", "=", "True", ",", "\n", ")", "\n", "texts", ".", "append", "(", "(", "text", ",", "encoding", ")", ")", "\n", "", "return", "texts", "\n", "\n", "", "def", "get_answer_label", "(", "self", ",", "sample", ")", ":", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.lsmdc_choice.LSMDCChoiceDataset.get_answer_label": [[80, 83], ["None"], "methods", ["None"], ["        ", "answer", "=", "sample", "[", "'answer'", "]", "\n", "return", "answer", "\n", "\n", "", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.lsmdc_choice.LSMDCChoiceDataset.__getitem__": [[84, 108], ["lsmdc_choice.LSMDCChoiceDataset.get_video", "lsmdc_choice.LSMDCChoiceDataset.get_answer_label", "lsmdc_choice.LSMDCChoiceDataset.get_text", "range", "ret.update", "print", "random.randint", "len"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_v2.Ego4DDataset.get_video", "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.msvdqa.MSVDQADataset.get_answer_label", "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_v2.Ego4DDataset.get_text", "home.repos.pwc.inspect_result.showlab_all-in-one.gadgets.my_metrics.VQAScore.update"], ["        ", "result", "=", "False", "\n", "while", "not", "result", ":", "\n", "            ", "try", ":", "\n", "                ", "sample", "=", "self", ".", "metadata", "[", "index", "]", "\n", "video_tensor", "=", "self", ".", "get_video", "(", "sample", ")", "\n", "qid", "=", "index", "\n", "answer", "=", "self", ".", "get_answer_label", "(", "sample", ")", "\n", "ret", "=", "{", "\n", "\"video\"", ":", "video_tensor", ",", "\n", "\"vid_index\"", ":", "index", ",", "\n", "\"cap_index\"", ":", "index", ",", "\n", "\"raw_index\"", ":", "index", ",", "\n", "'answer'", ":", "answer", "\n", "}", "\n", "texts", "=", "self", ".", "get_text", "(", "sample", ")", "\n", "ret", "[", "\"text\"", "]", "=", "texts", "[", "0", "]", "\n", "for", "i", "in", "range", "(", "self", ".", "draw_false_text", "-", "1", ")", ":", "\n", "                    ", "ret", ".", "update", "(", "{", "f\"false_text_{i}\"", ":", "texts", "[", "i", "+", "1", "]", "}", ")", "\n", "", "result", "=", "True", "\n", "", "except", "Exception", "as", "e", ":", "\n", "                ", "print", "(", "f\"Error while read file idx {sample['vid_id']} in {self.names[0]} -> {e}\"", ")", "\n", "index", "=", "random", ".", "randint", "(", "0", ",", "len", "(", "self", ".", "metadata", ")", "-", "1", ")", "\n", "", "", "return", "ret", "\n", "\n", "", "def", "__len__", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.lsmdc_choice.LSMDCChoiceDataset.__len__": [[109, 111], ["len"], "methods", ["None"], ["        ", "return", "len", "(", "self", ".", "metadata", ")", "", "", "", ""]], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.vcr.VCRDataset.__init__": [[55, 74], ["vcr.VCRDataset._load_metadata", "video_base_dataset.BaseDataset.__init__", "AllInOne.transforms.videoaug.VideoTransform"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_v2.Ego4DDataset._load_metadata", "home.repos.pwc.inspect_result.showlab_all-in-one.transforms.utils.UnNormalize.__init__", "home.repos.pwc.inspect_result.showlab_all-in-one.transforms.videoaug.VideoTransform"], ["if", "split", "==", "\"train\"", ":", "\n", "            ", "names", "=", "[", "\"vcr_train\"", "]", "\n", "", "elif", "split", "==", "\"val\"", ":", "\n", "            ", "names", "=", "[", "\"vcr_val\"", "]", "\n", "", "elif", "split", "==", "\"test\"", ":", "\n", "            ", "names", "=", "[", "\"vcr_test\"", "]", "\n", "\n", "", "super", "(", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ",", "names", "=", "names", ",", "text_column_name", "=", "\"caption\"", ")", "\n", "self", ".", "video_transform", "=", "VideoTransform", "(", "mode", "=", "split", ",", "num_frames", "=", "self", ".", "num_frames", ")", "# train or val model", "\n", "# for appear objects", "\n", "self", ".", "only_use_relevant_dets", "=", "True", "\n", "if", "self", ".", "only_use_relevant_dets", ":", "\n", "            ", "self", ".", "relevant_dets", "=", "[", "]", "# resort the detection numbers", "\n", "self", ".", "relevant_dets_classes", "=", "[", "]", "\n", "\n", "", "", "def", "_load_metadata", "(", "self", ")", ":", "\n", "# download specific", "\n", "        ", "metadata_dir", "=", "'./meta_data/vcr1annots'", "\n", "split_files", "=", "{", "\n", "'train'", ":", "'train.jsonl'", ",", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.vcr.VCRDataset._load_metadata": [[75, 86], ["pandas.read_json", "os.path.join"], "methods", ["None"], ["'val'", ":", "'val.jsonl'", ",", "# there is no test", "\n", "'test'", ":", "'test.jsonl'", "\n", "}", "\n", "target_split_fp", "=", "split_files", "[", "self", ".", "split", "]", "\n", "metadata", "=", "pd", ".", "read_json", "(", "os", ".", "path", ".", "join", "(", "metadata_dir", ",", "target_split_fp", ")", ",", "lines", "=", "True", ")", "\n", "self", ".", "metadata", "=", "metadata", "\n", "\n", "", "def", "_get_image_path", "(", "self", ",", "sample", ")", ":", "\n", "# print(sample.keys())", "\n", "# print(sample['img_fn'])", "\n", "# VCR/vcr1images", "\n", "        ", "rel_fp", "=", "sample", "[", "'img_fn'", "]", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.vcr.VCRDataset._get_image_path": [[87, 93], ["os.path.join"], "methods", ["None"], ["return", "os", ".", "path", ".", "join", "(", "self", ".", "data_dir", ",", "'vcr1images'", ",", "rel_fp", ")", ",", "rel_fp", "\n", "\n", "", "def", "get_objects", "(", "self", ",", "sample", ")", ":", "\n", "        ", "metadata2", "=", "pd", ".", "read_json", "(", "os", ".", "path", ".", "join", "(", "self", ".", "data_dir", ",", "'vcr1images'", ",", "\n", "sample", "[", "'metadata_fn'", "]", ")", ",", "lines", "=", "True", ")", "\n", "object_meta", "=", "metadata2", ".", "iloc", "[", "0", "]", "\n", "return", "object_meta", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.vcr.VCRDataset.get_objects": [[94, 99], ["pandas.read_json", "os.path.join"], "methods", ["None"], ["\n", "", "def", "_get_caption", "(", "self", ",", "sample", ")", ":", "\n", "        ", "return", "sample", "[", "0", "]", "\n", "\n", "# def _get_objects(self, sample):", "\n", "#     metadata2 = pd.read_json(os.path.join(self.data_dir,", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.vcr.VCRDataset._get_caption": [[100, 102], ["None"], "methods", ["None"], ["#                                           sample['metadata_fn']), lines=True)", "\n", "#     sample = metadata2.iloc[0]", "\n", "#     return sample['boxes']", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.vcr.VCRDataset.get_raw_image": [[109, 121], ["vcr.VCRDataset._get_image_path", "cv2.imread", "video_base_dataset.color_img", "Exception"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.datasets.vcr.VCRDataset._get_image_path", "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.video_base_dataset.color_img"], ["# add bbox annotation here", "\n", "if", "img_color_mask", ":", "\n", "            ", "img", "=", "color_img", "(", "img", ",", "object_meta", ",", "self", ".", "relevant_dets", ",", "self", ".", "only_use_relevant_dets", ")", "\n", "", "if", "img", "is", "None", ":", "\n", "            ", "raise", "Exception", "(", "\"Invalid img!\"", ",", "rel_fp", ")", "\n", "", "else", ":", "\n", "            ", "return", "img", "\n", "\n", "", "", "def", "get_image", "(", "self", ",", "index", ",", "sample", ",", "object_meta", ",", "image_key", "=", "\"image\"", ")", ":", "\n", "        ", "frames", "=", "[", "]", "\n", "image", "=", "self", ".", "get_raw_image", "(", "sample", ",", "object_meta", ")", "\n", "frame", "=", "torch", ".", "from_numpy", "(", "image", ")", ".", "byte", "(", ")", "\n", "frame", "=", "frame", ".", "permute", "(", "2", ",", "0", ",", "1", ")", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.vcr.VCRDataset.get_image": [[122, 136], ["vcr.VCRDataset.get_raw_image", "torch.from_numpy().byte", "frame.permute.permute.permute", "torch.stack().permute.append", "torch.stack().permute", "vcr.VCRDataset.video_transform().permute", "torch.from_numpy", "torch.stack", "vcr.VCRDataset.video_transform"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.datasets.vcr.VCRDataset.get_raw_image"], ["frames", ".", "append", "(", "frame", ")", "\n", "frames", "=", "torch", ".", "stack", "(", "frames", ")", ".", "permute", "(", "1", ",", "0", ",", "2", ",", "3", ")", "\n", "# print(frames.size())", "\n", "image_tensor", "=", "[", "self", ".", "video_transform", "(", "frames", ")", ".", "permute", "(", "1", ",", "0", ",", "2", ",", "3", ")", "]", "# to tchw", "\n", "# image = self.get_raw_image(sample)", "\n", "# image_tensor = [tr(image) for tr in self.transforms]", "\n", "# print(image_tensor.size())", "\n", "# image_tensor.unsqueeze(0)", "\n", "return", "image_tensor", "\n", "\n", "", "def", "get_false_image", "(", "self", ",", "rep", ",", "image_key", "=", "\"image\"", ")", ":", "\n", "        ", "random_index", "=", "random", ".", "randint", "(", "0", ",", "len", "(", "self", ".", "metadata", ")", "-", "1", ")", "\n", "sample", "=", "self", ".", "metadata", ".", "iloc", "[", "random_index", "]", "\n", "image", "=", "self", ".", "get_raw_image", "(", "sample", ")", "\n", "image_tensor", "=", "[", "tr", "(", "image", ")", "for", "tr", "in", "self", ".", "transforms", "]", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.vcr.VCRDataset.get_false_image": [[137, 143], ["random.randint", "vcr.VCRDataset.get_raw_image", "tr", "len"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.datasets.vcr.VCRDataset.get_raw_image"], ["return", "{", "f\"false_image_{rep}\"", ":", "image_tensor", "}", "\n", "\n", "# def get_text(self, sample, object_meta):", "\n", "#     question = self.get_question(sample, object_meta)", "\n", "#     texts = []", "\n", "#     for answer in sample['answer_choices']:", "\n", "#         raw_text = question + '[SEP]'", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.vcr.VCRDataset.update_rele_det": [[172, 196], ["range", "range", "range", "len", "text.append", "len", "range", "len", "range", "isinstance", "vcr.VCRDataset.relevant_dets_classes.append", "len", "text.append", "len", "text.append", "vcr.VCRDataset.relevant_dets.append"], "methods", ["None"], ["            ", "for", "j", "in", "range", "(", "len", "(", "sample", "[", "'answer_choices'", "]", "[", "i", "]", ")", ")", ":", "\n", "                ", "text", ".", "append", "(", "sample", "[", "'answer_choices'", "]", "[", "i", "]", "[", "j", "]", ")", "\n", "", "", "for", "i", "in", "range", "(", "len", "(", "sample", "[", "'rationale_choices'", "]", ")", ")", ":", "\n", "            ", "for", "j", "in", "range", "(", "len", "(", "sample", "[", "'rationale_choices'", "]", "[", "i", "]", ")", ")", ":", "\n", "                ", "text", ".", "append", "(", "sample", "[", "'rationale_choices'", "]", "[", "i", "]", "[", "j", "]", ")", "\n", "# update relevant detes", "\n", "", "", "for", "word", "in", "text", ":", "\n", "            ", "if", "isinstance", "(", "word", ",", "list", ")", ":", "\n", "                ", "for", "object_idx", "in", "word", ":", "\n", "# self.relevant_dets.add(object_idx)", "\n", "                    ", "if", "object_idx", "not", "in", "self", ".", "relevant_dets", ":", "\n", "                        ", "self", ".", "relevant_dets", ".", "append", "(", "object_idx", ")", "\n", "", "", "", "", "for", "object", "in", "self", ".", "relevant_dets", ":", "\n", "            ", "self", ".", "relevant_dets_classes", ".", "append", "(", "object_meta", "[", "'names'", "]", "[", "object", "]", ")", "\n", "# print(index, text)", "\n", "# print(index, self.relevant_dets)", "\n", "# print(index, self.relevant_dets_classes)", "\n", "#", "\n", "", "return", "text", "\n", "\n", "", "def", "get_text", "(", "self", ",", "sample", ",", "object_meta", ",", "index", ")", ":", "\n", "# detect all object index and sort these items", "\n", "        ", "if", "self", ".", "only_use_relevant_dets", ":", "\n", "            ", "self", ".", "update_rele_det", "(", "sample", ",", "object_meta", ",", "index", ")", "\n", "", "question", "=", "self", ".", "get_question", "(", "sample", ",", "object_meta", ")", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.vcr.VCRDataset.get_text": [[197, 266], ["vcr.VCRDataset.get_question", "vcr.VCRDataset.update_rele_det", "vcr.VCRDataset.tokenizer", "qa_texts.append", "isinstance", "vcr.VCRDataset.tokenizer", "qar_texts.append", "isinstance", "isinstance", "str", "str", "str", "str", "vcr.VCRDataset.relevant_dets.index", "str", "str", "vcr.VCRDataset.relevant_dets.index", "vcr.VCRDataset.relevant_dets.index"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.datasets.vcr.VCRDataset.get_question", "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.vcr.VCRDataset.update_rele_det"], ["qa_texts", "=", "[", "]", "\n", "# image size: 384 x 384", "\n", "# prompt: [START] + \"answer_question:\"", "\n", "# prompt: [START] + ' provide rationale:'),", "\n", "# add all text tokens into this model.", "\n", "for", "answer", "in", "sample", "[", "'answer_choices'", "]", ":", "\n", "            ", "raw_text", "=", "question", "+", "'answer question: '", "\n", "for", "word", "in", "answer", ":", "\n", "                ", "if", "isinstance", "(", "word", ",", "list", ")", ":", "\n", "                    ", "for", "object_idx", "in", "word", ":", "\n", "                        ", "raw_text", "+=", "' '", "+", "object_meta", "[", "'names'", "]", "[", "object_idx", "]", "+", "' '", "\n", "# rename the object index, for example", "\n", "if", "self", ".", "only_use_relevant_dets", ":", "\n", "                            ", "raw_text", "+=", "str", "(", "self", ".", "relevant_dets", ".", "index", "(", "object_idx", ")", ")", "\n", "", "else", ":", "\n", "                            ", "raw_text", "+=", "str", "(", "object_idx", ")", "\n", "", "", "", "else", ":", "\n", "                    ", "raw_text", "+=", "' '", "+", "word", "\n", "", "", "raw_text", "+=", "'[END]'", "\n", "# print(index, raw_text)", "\n", "qa_encoding", "=", "self", ".", "tokenizer", "(", "\n", "raw_text", ",", "\n", "padding", "=", "\"max_length\"", ",", "\n", "truncation", "=", "True", ",", "\n", "max_length", "=", "self", ".", "max_text_len", ",", "\n", "return_special_tokens_mask", "=", "True", ",", "\n", ")", "\n", "qa_texts", ".", "append", "(", "(", "raw_text", ",", "qa_encoding", ")", ")", "\n", "\n", "", "gt_ans", "=", "sample", "[", "'answer_choices'", "]", "[", "sample", "[", "'answer_label'", "]", "]", "\n", "gt_ans_text", "=", "\"\"", "\n", "for", "word", "in", "gt_ans", ":", "\n", "            ", "if", "isinstance", "(", "word", ",", "list", ")", ":", "\n", "                ", "for", "object_idx", "in", "word", ":", "\n", "                    ", "gt_ans_text", "+=", "' '", "+", "object_meta", "[", "'names'", "]", "[", "object_idx", "]", "+", "' '", "\n", "# rename the object index, for example", "\n", "if", "self", ".", "only_use_relevant_dets", ":", "\n", "                        ", "gt_ans_text", "+=", "str", "(", "self", ".", "relevant_dets", ".", "index", "(", "object_idx", ")", ")", "\n", "", "else", ":", "\n", "                        ", "gt_ans_text", "+=", "str", "(", "object_idx", ")", "\n", "", "", "", "else", ":", "\n", "                ", "gt_ans_text", "+=", "' '", "+", "word", "\n", "", "", "qar_texts", "=", "[", "]", "\n", "for", "reason", "in", "sample", "[", "'rationale_choices'", "]", ":", "\n", "            ", "raw_text", "=", "question", "+", "gt_ans_text", "+", "'provide rationale: '", "\n", "for", "word", "in", "reason", ":", "\n", "                ", "if", "isinstance", "(", "word", ",", "list", ")", ":", "\n", "                    ", "for", "object_idx", "in", "word", ":", "\n", "                        ", "raw_text", "+=", "' '", "+", "object_meta", "[", "'names'", "]", "[", "object_idx", "]", "+", "' '", "\n", "if", "self", ".", "only_use_relevant_dets", ":", "\n", "                            ", "raw_text", "+=", "str", "(", "self", ".", "relevant_dets", ".", "index", "(", "object_idx", ")", ")", "\n", "", "else", ":", "\n", "                            ", "raw_text", "+=", "str", "(", "object_idx", ")", "\n", "", "", "", "else", ":", "\n", "                    ", "raw_text", "+=", "' '", "+", "word", "\n", "# print(index, raw_text)", "\n", "", "", "raw_text", "+=", "'[END]'", "\n", "encoding", "=", "self", ".", "tokenizer", "(", "\n", "raw_text", ",", "\n", "padding", "=", "\"max_length\"", ",", "\n", "truncation", "=", "True", ",", "\n", "max_length", "=", "self", ".", "max_text_len", ",", "\n", "return_special_tokens_mask", "=", "True", ",", "\n", ")", "\n", "qar_texts", ".", "append", "(", "(", "raw_text", ",", "encoding", ")", ")", "\n", "", "return", "[", "qa_texts", ",", "qar_texts", "]", "\n", "#", "\n", "# def get_qar(self, sample, object_meta):", "\n", "#     question = self.get_question(sample, object_meta) + '[SEP]' # '[MIDDLE]'", "\n", "#     gt_ans = sample['answer_choices'][sample['answer_label']]", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.vcr.VCRDataset.get_answer_label": [[312, 315], ["int"], "methods", ["None"], ["\n", "", "def", "get_reason_answer_label", "(", "self", ",", "sample", ")", ":", "\n", "        ", "answer", "=", "int", "(", "sample", "[", "'rationale_label'", "]", ")", "\n", "return", "answer", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.vcr.VCRDataset.get_reason_answer_label": [[316, 319], ["int"], "methods", ["None"], ["\n", "", "def", "get_question", "(", "self", ",", "sample", ",", "object_meta", ")", ":", "\n", "        ", "raw_text", "=", "\"\"", "\n", "for", "index", "in", "range", "(", "len", "(", "sample", "[", "'question'", "]", ")", ")", ":", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.vcr.VCRDataset.get_question": [[320, 333], ["range", "len", "isinstance", "str", "str", "str", "vcr.VCRDataset.relevant_dets.index"], "methods", ["None"], ["            ", "if", "isinstance", "(", "sample", "[", "'question'", "]", "[", "index", "]", ",", "list", ")", ":", "\n", "                ", "for", "object_idx", "in", "sample", "[", "'question'", "]", "[", "index", "]", ":", "\n", "                    ", "raw_text", "+=", "' '", "+", "object_meta", "[", "'names'", "]", "[", "object_idx", "]", "+", "' '", "\n", "if", "self", ".", "only_use_relevant_dets", ":", "\n", "                        ", "raw_text", "+=", "str", "(", "self", ".", "relevant_dets", ".", "index", "(", "object_idx", ")", ")", "\n", "", "else", ":", "\n", "                        ", "raw_text", "+=", "str", "(", "object_idx", ")", "\n", "", "", "", "else", ":", "\n", "                ", "raw_text", "+=", "' '", "+", "str", "(", "sample", "[", "'question'", "]", "[", "index", "]", ")", "\n", "", "", "return", "raw_text", "\n", "\n", "", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "metadata", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.vcr.VCRDataset.__len__": [[334, 336], ["len"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "sample", "=", "self", ".", "metadata", ".", "iloc", "[", "index", "]", "\n", "object_meta", "=", "self", ".", "get_objects", "(", "sample", ")", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.vcr.VCRDataset.__getitem__": [[337, 365], ["vcr.VCRDataset.get_objects", "vcr.VCRDataset.get_answer_label", "vcr.VCRDataset.get_reason_answer_label", "vcr.VCRDataset.get_text", "range", "range", "vcr.VCRDataset.get_image", "ret.update", "ret.update"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.datasets.vcr.VCRDataset.get_objects", "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.msvdqa.MSVDQADataset.get_answer_label", "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.vcr.VCRDataset.get_reason_answer_label", "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_v2.Ego4DDataset.get_text", "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.vcr.VCRDataset.get_image", "home.repos.pwc.inspect_result.showlab_all-in-one.gadgets.my_metrics.VQAScore.update", "home.repos.pwc.inspect_result.showlab_all-in-one.gadgets.my_metrics.VQAScore.update"], ["self", ".", "relevant_dets", "=", "[", "]", "# initalize", "\n", "self", ".", "relevant_dets_classes", "=", "[", "]", "\n", "answer", "=", "self", ".", "get_answer_label", "(", "sample", ")", "\n", "reason_answer", "=", "self", ".", "get_reason_answer_label", "(", "sample", ")", "\n", "ret", "=", "{", "\n", "\"img_index\"", ":", "index", ",", "\n", "\"cap_index\"", ":", "index", ",", "\n", "\"raw_index\"", ":", "index", ",", "\n", "'answer'", ":", "answer", ",", "\n", "'reason_answer'", ":", "reason_answer", "\n", "}", "\n", "# texts = self.get_text(sample, object_meta)", "\n", "# qar_texts = self.get_qar(sample, object_meta)", "\n", "[", "qa_texts", ",", "qar_texts", "]", "=", "self", ".", "get_text", "(", "sample", ",", "object_meta", ",", "index", ")", "\n", "ret", "[", "\"text\"", "]", "=", "qa_texts", "[", "0", "]", "\n", "# print(texts[0])", "\n", "# update other answers as false text", "\n", "for", "i", "in", "range", "(", "self", ".", "draw_options_text", "-", "1", ")", ":", "\n", "            ", "ret", ".", "update", "(", "{", "f\"options_text_{i}\"", ":", "qa_texts", "[", "i", "+", "1", "]", "}", ")", "\n", "", "for", "j", "in", "range", "(", "self", ".", "draw_options_text", ")", ":", "\n", "            ", "ret", ".", "update", "(", "{", "f\"qar_text_{j}\"", ":", "qar_texts", "[", "j", "]", "}", ")", "\n", "# print(ret.keys())", "\n", "", "image_tensor", "=", "self", ".", "get_image", "(", "index", ",", "sample", ",", "object_meta", ")", "\n", "ret", "[", "\"image\"", "]", "=", "image_tensor", "\n", "return", "ret", "\n", "\n", "", "", ""]], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.msvdqa.MSVDQADataset.__init__": [[8, 29], ["video_base_dataset.BaseDataset.__init__", "msvdqa.MSVDQADataset._load_metadata"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.transforms.utils.UnNormalize.__init__", "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_v2.Ego4DDataset._load_metadata"], ["    ", "def", "__init__", "(", "self", ",", "*", "args", ",", "split", "=", "\"\"", ",", "**", "kwargs", ")", ":", "\n", "        ", "assert", "split", "in", "[", "\"train\"", ",", "\"val\"", ",", "\"test\"", "]", "\n", "self", ".", "split", "=", "split", "\n", "self", ".", "metadata", "=", "None", "\n", "self", ".", "ans_lab_dict", "=", "None", "\n", "if", "split", "==", "\"train\"", ":", "\n", "            ", "names", "=", "[", "\"msvd_qa_train\"", "]", "\n", "", "elif", "split", "==", "\"val\"", ":", "\n", "            ", "names", "=", "[", "\"msvd_qa_test\"", "]", "# test: directly output test result", "\n", "# [\"msvd_qa_val\"]", "\n", "", "elif", "split", "==", "\"test\"", ":", "\n", "            ", "names", "=", "[", "\"msvd_qa_test\"", "]", "# vqav2_test-dev for test-dev", "\n", "\n", "", "super", "(", ")", ".", "__init__", "(", "\n", "*", "args", ",", "\n", "**", "kwargs", ",", "\n", "names", "=", "names", ",", "\n", "text_column_name", "=", "\"questions\"", ",", "\n", "remove_duplicate", "=", "False", ",", "\n", ")", "\n", "self", ".", "_load_metadata", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.msvdqa.MSVDQADataset._load_metadata": [[30, 61], ["os.path.join", "dict", "print", "open", "f.readlines", "open", "f.readlines", "pandas.read_json", "os.path.join", "line.strip().split", "name.split", "os.path.join", "msvdqa.MSVDQADataset.metadata.update", "len", "line.strip", "str", "line.strip"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.gadgets.my_metrics.VQAScore.update"], ["", "def", "_load_metadata", "(", "self", ")", ":", "\n", "        ", "metadata_dir", "=", "'./meta_data/msvd'", "\n", "split_files", "=", "{", "\n", "'train'", ":", "'msvd_train_qa_encode.json'", ",", "\n", "'val'", ":", "'msvd_val_qa_encode.json'", ",", "\n", "'test'", ":", "'msvd_test_qa_encode.json'", "\n", "}", "\n", "# read ans dict", "\n", "self", ".", "ans_lab_dict", "=", "{", "}", "\n", "answer_fp", "=", "os", ".", "path", ".", "join", "(", "metadata_dir", ",", "'msvd_answer_set.txt'", ")", "\n", "self", ".", "youtube_mapping_dict", "=", "dict", "(", ")", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "metadata_dir", ",", "'msvd_youtube_mapping.txt'", ")", ")", "as", "f", ":", "\n", "            ", "lines", "=", "f", ".", "readlines", "(", ")", "\n", "for", "line", "in", "lines", ":", "\n", "                ", "info", "=", "line", ".", "strip", "(", ")", ".", "split", "(", "' '", ")", "\n", "self", ".", "youtube_mapping_dict", "[", "info", "[", "1", "]", "]", "=", "info", "[", "0", "]", "\n", "", "", "with", "open", "(", "answer_fp", ",", "'r'", ")", "as", "f", ":", "\n", "            ", "lines", "=", "f", ".", "readlines", "(", ")", "\n", "count", "=", "0", "\n", "for", "line", "in", "lines", ":", "\n", "                ", "self", ".", "ans_lab_dict", "[", "str", "(", "line", ".", "strip", "(", ")", ")", "]", "=", "count", "\n", "count", "+=", "1", "\n", "", "", "for", "name", "in", "self", ".", "names", ":", "\n", "            ", "split", "=", "name", ".", "split", "(", "'_'", ")", "[", "-", "1", "]", "\n", "target_split_fp", "=", "split_files", "[", "split", "]", "\n", "metadata", "=", "pd", ".", "read_json", "(", "os", ".", "path", ".", "join", "(", "metadata_dir", ",", "target_split_fp", ")", ",", "lines", "=", "True", ")", "\n", "if", "self", ".", "metadata", "is", "None", ":", "\n", "                ", "self", ".", "metadata", "=", "metadata", "\n", "", "else", ":", "\n", "                ", "self", ".", "metadata", ".", "update", "(", "metadata", ")", "\n", "", "", "print", "(", "\"total {} samples for {}\"", ".", "format", "(", "len", "(", "self", ".", "metadata", ")", ",", "self", ".", "names", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.msvdqa.MSVDQADataset._get_video_path": [[62, 67], ["os.path.join", "str"], "methods", ["None"], ["", "def", "_get_video_path", "(", "self", ",", "sample", ")", ":", "\n", "        ", "rel_video_fp", "=", "self", ".", "youtube_mapping_dict", "[", "'vid'", "+", "str", "(", "sample", "[", "\"video_id\"", "]", ")", "]", "+", "'.avi'", "\n", "# print(rel_video_fp)", "\n", "full_video_fp", "=", "os", ".", "path", ".", "join", "(", "self", ".", "data_dir", ",", "'YouTubeClips'", ",", "rel_video_fp", ")", "\n", "return", "full_video_fp", ",", "rel_video_fp", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.msvdqa.MSVDQADataset.get_text": [[68, 78], ["msvdqa.MSVDQADataset.tokenizer"], "methods", ["None"], ["", "def", "get_text", "(", "self", ",", "sample", ")", ":", "\n", "        ", "text", "=", "sample", "[", "'question'", "]", "\n", "encoding", "=", "self", ".", "tokenizer", "(", "\n", "text", ",", "\n", "padding", "=", "\"max_length\"", ",", "\n", "truncation", "=", "True", ",", "\n", "max_length", "=", "self", ".", "max_text_len", ",", "\n", "return_special_tokens_mask", "=", "True", ",", "\n", ")", "\n", "return", "(", "text", ",", "encoding", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.msvdqa.MSVDQADataset.get_answer_label": [[79, 90], ["numpy.zeros().astype", "len", "numpy.zeros"], "methods", ["None"], ["", "def", "get_answer_label", "(", "self", ",", "sample", ")", ":", "\n", "        ", "text", "=", "sample", "[", "'answer'", "]", "\n", "ans_total_len", "=", "len", "(", "self", ".", "ans_lab_dict", ")", "+", "1", "# one additional class", "\n", "try", ":", "\n", "            ", "ans_label", "=", "self", ".", "ans_lab_dict", "[", "text", "]", "#", "\n", "", "except", "KeyError", ":", "\n", "            ", "ans_label", "=", "-", "100", "# ignore classes", "\n", "# ans_label = 1500 # other classes", "\n", "", "scores", "=", "np", ".", "zeros", "(", "ans_total_len", ")", ".", "astype", "(", "int", ")", "\n", "scores", "[", "ans_label", "]", "=", "1", "\n", "return", "text", ",", "ans_label", ",", "scores", "\n", "# return text, ans_label_vector, scores", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.msvdqa.MSVDQADataset.__getitem__": [[92, 112], ["msvdqa.MSVDQADataset.get_video", "msvdqa.MSVDQADataset.get_text", "msvdqa.MSVDQADataset.get_answer_label", "list", "list", "list"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_v2.Ego4DDataset.get_video", "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_v2.Ego4DDataset.get_text", "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.msvdqa.MSVDQADataset.get_answer_label"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "sample", "=", "self", ".", "metadata", "[", "index", "]", ".", "iloc", "[", "0", "]", "\n", "video_tensor", "=", "self", ".", "get_video", "(", "sample", ")", "\n", "text", "=", "self", ".", "get_text", "(", "sample", ")", "\n", "# index, question_index = self.index_mapper[index]", "\n", "qid", "=", "index", "\n", "if", "self", ".", "split", "!=", "\"test\"", ":", "\n", "            ", "answers", ",", "labels", ",", "scores", "=", "self", ".", "get_answer_label", "(", "sample", ")", "\n", "", "else", ":", "\n", "            ", "answers", "=", "list", "(", ")", "\n", "labels", "=", "list", "(", ")", "\n", "scores", "=", "list", "(", ")", "\n", "\n", "", "return", "{", "\n", "\"video\"", ":", "video_tensor", ",", "\n", "\"text\"", ":", "text", ",", "\n", "\"vqa_answer\"", ":", "answers", ",", "\n", "\"vqa_labels\"", ":", "labels", ",", "\n", "\"vqa_scores\"", ":", "scores", ",", "\n", "\"qid\"", ":", "qid", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.msvdqa.MSVDQADataset.__len__": [[114, 116], ["sum"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "sum", "(", "1", "for", "line", "in", "self", ".", "metadata", ")", "# count # json lines", "", "", "", ""]], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.lsmdc_dataset.LSMDCDataset.__init__": [[9, 22], ["lsmdc_dataset.LSMDCDataset._load_metadata", "video_base_dataset.BaseDataset.__init__"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_v2.Ego4DDataset._load_metadata", "home.repos.pwc.inspect_result.showlab_all-in-one.transforms.utils.UnNormalize.__init__"], ["        ", "assert", "split", "in", "[", "\"train\"", ",", "\"val\"", ",", "\"test\"", "]", "\n", "self", ".", "split", "=", "split", "\n", "self", ".", "metadata", "=", "None", "\n", "if", "split", "==", "\"train\"", ":", "\n", "            ", "names", "=", "[", "\"lsmdc_train\"", "]", "\n", "", "elif", "split", "==", "\"val\"", ":", "\n", "            ", "names", "=", "[", "\"lsmdc_val\"", "]", "\n", "", "elif", "split", "==", "\"test\"", ":", "\n", "            ", "names", "=", "[", "\"lsmdc_test\"", "]", "\n", "", "self", ".", "_load_metadata", "(", ")", "\n", "# self.num_frames = kwargs['num_frames']", "\n", "super", "(", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ",", "names", "=", "names", ",", "text_column_name", "=", "\"caption\"", ")", "\n", "\n", "", "def", "_load_metadata", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.lsmdc_dataset.LSMDCDataset._load_metadata": [[23, 34], ["pandas.read_csv", "print", "os.path.join", "len"], "methods", ["None"], ["        ", "metadata_dir", "=", "'./meta_data/lsmdc'", "\n", "split_files", "=", "{", "\n", "'train'", ":", "'LSMDC16_annos_training.csv'", ",", "\n", "'val'", ":", "'LSMDC16_challenge_1000_publictect.csv'", ",", "# LSMDC16_annos_val.csv", "\n", "'test'", ":", "'LSMDC16_challenge_1000_publictect.csv'", "\n", "}", "\n", "target_split_fp", "=", "split_files", "[", "self", ".", "split", "]", "\n", "metadata", "=", "pd", ".", "read_csv", "(", "os", ".", "path", ".", "join", "(", "metadata_dir", ",", "target_split_fp", ")", ",", "sep", "=", "'\\t'", ",", "header", "=", "None", ",", "error_bad_lines", "=", "False", ")", "\n", "self", ".", "metadata", "=", "metadata", "\n", "print", "(", "\"load split {}, {} samples\"", ".", "format", "(", "self", ".", "split", ",", "len", "(", "metadata", ")", ")", ")", "\n", "\n", "", "def", "_get_video_path", "(", "self", ",", "sample", ")", ":", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.lsmdc_dataset.LSMDCDataset._get_video_path": [[35, 41], ["os.path.join", "sample[].split"], "methods", ["None"], ["# e.g. 3009_BATTLE_LOS_ANGELES_00.03.07.170-00.03.09.675 -> 3009_BATTLE_LOS_ANGELES/3009_BATTLE_LOS_ANGELES_00.03.07.170-00.03.09.675", "\n", "        ", "sub_dir", "=", "'_'", ".", "join", "(", "sample", "[", "0", "]", ".", "split", "(", "'_'", ")", "[", ":", "-", "1", "]", ")", "\n", "rel_video_fp", "=", "sample", "[", "0", "]", "+", "'.avi'", "\n", "full_video_fp", "=", "os", ".", "path", ".", "join", "(", "self", ".", "data_dir", ",", "sub_dir", ",", "rel_video_fp", ")", "\n", "return", "full_video_fp", ",", "rel_video_fp", "\n", "\n", "", "def", "_get_caption", "(", "self", ",", "sample", ")", ":", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.lsmdc_dataset.LSMDCDataset._get_caption": [[42, 55], ["sample[].split", "len", "random.randint", "sample[].split", "len", "random.randint"], "methods", ["None"], ["        ", "if", "self", ".", "split", "==", "'train'", ":", "\n", "            ", "words", "=", "sample", "[", "0", "]", ".", "split", "(", "','", ")", "\n", "num_word", "=", "len", "(", "words", ")", "\n", "index", "=", "random", ".", "randint", "(", "0", ",", "num_word", "-", "1", ")", "\n", "caption", "=", "words", "[", "index", "]", "\n", "", "else", ":", "\n", "# caption = sample[0]", "\n", "            ", "words", "=", "sample", "[", "0", "]", ".", "split", "(", "','", ")", "\n", "num_word", "=", "len", "(", "words", ")", "\n", "index", "=", "random", ".", "randint", "(", "0", ",", "num_word", "-", "1", ")", "\n", "caption", "=", "words", "[", "index", "]", "\n", "", "return", "caption", "\n", "", "", ""]], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_v2.Ego4DDataset.__init__": [[22, 71], ["video_base_dataset.BaseDataset.__init__", "ego4d_v2.Ego4DDataset._load_metadata", "ego4d_v2.Ego4DDataset._load_metadata", "AllInOne.transforms.videoaug.VideoTransform", "float"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.transforms.utils.UnNormalize.__init__", "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_v2.Ego4DDataset._load_metadata", "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_v2.Ego4DDataset._load_metadata", "home.repos.pwc.inspect_result.showlab_all-in-one.transforms.videoaug.VideoTransform"], ["#         caption_root='',", "\n", "#         min_time=4.0,", "\n", "#         fps=16,", "\n", "#         num_frames=16,", "\n", "#         size=224,", "\n", "#         crop_only=False,", "\n", "#         center_crop=True,", "\n", "#         benchmark=False,", "\n", "#         token_to_word_path='data/dict.npy',", "\n", "#         max_words=20,", "\n", "#         num_candidates=1,", "\n", "#         random_left_right_flip=False,", "\n", "# ):", "\n", "#     \"\"\"", "\n", "#     Args:", "\n", "#     \"\"\"", "\n", "        ", "assert", "split", "in", "[", "\"train\"", ",", "\"val\"", ",", "\"test\"", "]", "\n", "self", ".", "split", "=", "split", "\n", "\n", "if", "split", "==", "\"train\"", ":", "\n", "            ", "names", "=", "[", "\"ego4d_train\"", "]", "\n", "", "elif", "split", "==", "\"val\"", ":", "\n", "            ", "names", "=", "[", "\"ego4d_val\"", "]", "\n", "", "elif", "split", "==", "\"test\"", ":", "\n", "            ", "names", "=", "[", "\"ego4d_test\"", "]", "\n", "", "super", "(", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ",", "names", "=", "names", ",", "text_column_name", "=", "\"caption\"", ")", "\n", "\n", "self", ".", "_load_metadata", "(", ")", "\n", "# for howto100", "\n", "self", ".", "min_time", "=", "2.0", "\n", "self", ".", "size", "=", "224", "\n", "self", ".", "fps", "=", "5", "\n", "self", ".", "num_sec", "=", "self", ".", "video_num_frames", "/", "float", "(", "self", ".", "fps", ")", "\n", "self", ".", "crop_only", "=", "False", "\n", "self", ".", "center_crop", "=", "False", "\n", "self", ".", "benchmark", "=", "False", "\n", "self", ".", "num_candidates", "=", "1", "\n", "self", ".", "random_flip", "=", "True", "\n", "# print(self.data_dir)", "\n", "# for howto caption dir", "\n", "self", ".", "_load_metadata", "(", ")", "\n", "# print(kwargs)", "\n", "# self.num_frames = kwargs['num_frames']", "\n", "self", ".", "video_transform", "=", "VideoTransform", "(", "mode", "=", "self", ".", "split", ",", "num_frames", "=", "self", ".", "num_frames", ")", "# train or val model", "\n", "\n", "", "def", "_load_metadata", "(", "self", ")", ":", "\n", "        ", "metadata_dir", "=", "'./meta_data'", "\n", "split_files", "=", "{", "\n", "'train'", ":", "'ego4d/narration.json'", ",", "\n", "'val'", ":", "'ego4d/narration.json'", ",", "# there is no test", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_v2.Ego4DDataset._load_metadata": [[72, 85], ["list", "open", "json.load", "json.load.keys", "os.path.join"], "methods", ["None"], ["'test'", ":", "'ego4d/narration.json'", "\n", "}", "\n", "target_split_fp", "=", "split_files", "[", "self", ".", "split", "]", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "metadata_dir", ",", "target_split_fp", ")", ",", "'r'", ")", "as", "jsonfile", ":", "\n", "            ", "metadata", "=", "json", ".", "load", "(", "jsonfile", ")", "\n", "# metadata = pd.read_csv(os.path.join(metadata_dir, target_split_fp), sep='\\t')", "\n", "", "self", ".", "metadata", "=", "metadata", "\n", "self", ".", "meta_keys", "=", "list", "(", "metadata", ".", "keys", "(", ")", ")", "\n", "\n", "", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "meta_keys", ")", "\n", "\n", "", "def", "get_video_len", "(", "self", ",", "video_path", ")", ":", "\n", "        ", "duration", "=", "subprocess", ".", "check_output", "(", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_v2.Ego4DDataset.__len__": [[268, 270], ["len"], "methods", ["None"], ["", "", ""]], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_v2.Ego4DDataset.get_video_len": [[89, 96], ["subprocess.check_output", "float", "str"], "methods", ["None"], ["duration", "=", "float", "(", "str", "(", "duration", ")", "[", "2", ":", "-", "3", "]", ")", "# b'1027.806000\\n' -> 1027.806", "\n", "return", "duration", "\n", "\n", "", "def", "read_frames_ffmpeg", "(", "self", ",", "video_path", ",", "center", ",", "video_len", ")", ":", "\n", "        ", "if", "center", ">", "video_len", ":", "\n", "            ", "center", "=", "video_len", "-", "2", "*", "self", ".", "num_sec", "\n", "", "start", "=", "int", "(", "max", "(", "0", ",", "center", "-", "self", ".", "min_time", ")", ")", "\n", "end", "=", "int", "(", "min", "(", "video_len", ",", "center", "+", "self", ".", "min_time", ")", ")", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_v2.Ego4DDataset.read_frames_ffmpeg": [[97, 149], ["int", "int", "random.randint", "max", "ffmpeg.input().filter", "cmd.hflip.hflip.output().run", "numpy.frombuffer().reshape", "torch.from_numpy", "max", "min", "int", "cmd.hflip.hflip.crop", "cmd.hflip.hflip.crop().filter", "cmd.hflip.hflip.hflip", "numpy.copy", "torch.cat.permute", "print", "torch.ones", "torch.cat", "max", "ffmpeg.input", "random.uniform", "random.uniform", "str", "str", "random.uniform", "cmd.hflip.hflip.output", "numpy.frombuffer", "torch.cat.size", "torch.cat.size", "cmd.hflip.hflip.crop"], "methods", ["None"], ["start_seek", "=", "random", ".", "randint", "(", "start", ",", "int", "(", "max", "(", "start", ",", "end", "-", "self", ".", "num_sec", ")", ")", ")", "\n", "# video is too short", "\n", "if", "video_len", "<", "1", ":", "\n", "            ", "start_seek", "=", "0", "\n", "", "if", "start_seek", "+", "self", ".", "num_sec", "+", "0.1", ">", "video_len", ":", "\n", "            ", "start_seek", "=", "video_len", "-", "self", ".", "num_sec", "-", "0.1", "\n", "", "start_seek", "=", "max", "(", "start_seek", ",", "0", ")", "\n", "cmd", "=", "(", "\n", "ffmpeg", "\n", ".", "input", "(", "video_path", ",", "ss", "=", "start_seek", ",", "t", "=", "self", ".", "num_sec", "+", "0.01", ")", "\n", ".", "filter", "(", "'fps'", ",", "fps", "=", "self", ".", "fps", ")", "\n", ")", "\n", "if", "self", ".", "center_crop", ":", "\n", "            ", "aw", ",", "ah", "=", "0.5", ",", "0.5", "\n", "", "else", ":", "\n", "            ", "aw", ",", "ah", "=", "random", ".", "uniform", "(", "0", ",", "1", ")", ",", "random", ".", "uniform", "(", "0", ",", "1", ")", "\n", "", "if", "self", ".", "crop_only", ":", "\n", "            ", "cmd", "=", "(", "\n", "cmd", ".", "crop", "(", "'(iw - {})*{}'", ".", "format", "(", "self", ".", "size", ",", "aw", ")", ",", "\n", "'(ih - {})*{}'", ".", "format", "(", "self", ".", "size", ",", "ah", ")", ",", "\n", "str", "(", "self", ".", "size", ")", ",", "str", "(", "self", ".", "size", ")", ")", "\n", ")", "\n", "", "else", ":", "\n", "            ", "cmd", "=", "(", "\n", "cmd", ".", "crop", "(", "'(iw - min(iw,ih))*{}'", ".", "format", "(", "aw", ")", ",", "\n", "'(ih - min(iw,ih))*{}'", ".", "format", "(", "ah", ")", ",", "\n", "'min(iw,ih)'", ",", "\n", "'min(iw,ih)'", ")", "\n", ".", "filter", "(", "'scale'", ",", "self", ".", "size", ",", "self", ".", "size", ")", "\n", ")", "\n", "", "if", "self", ".", "random_flip", "and", "random", ".", "uniform", "(", "0", ",", "1", ")", ">", "0.5", ":", "\n", "            ", "cmd", "=", "cmd", ".", "hflip", "(", ")", "\n", "", "out", ",", "_", "=", "(", "\n", "cmd", ".", "output", "(", "'pipe:'", ",", "format", "=", "'rawvideo'", ",", "pix_fmt", "=", "'rgb24'", ")", "\n", ".", "run", "(", "capture_stdout", "=", "True", ",", "quiet", "=", "True", ")", "\n", ")", "\n", "video", "=", "np", ".", "frombuffer", "(", "out", ",", "np", ".", "uint8", ")", ".", "reshape", "(", "[", "-", "1", ",", "self", ".", "size", ",", "self", ".", "size", ",", "3", "]", ")", "\n", "video_tensor", "=", "th", ".", "from_numpy", "(", "np", ".", "copy", "(", "video", ")", ")", "\n", "video_tensor", "=", "video_tensor", ".", "permute", "(", "3", ",", "0", ",", "1", ",", "2", ")", "+", "0.01", "\n", "if", "video_tensor", ".", "size", "(", ")", "[", "1", "]", "!=", "self", ".", "num_frames", ":", "\n", "            ", "print", "(", "video_tensor", ".", "size", "(", ")", ",", "start", ",", "end", ",", "start_seek", ",", "video_len", ")", "\n", "# print(\"video length: {}\".format(self.get_video_len_from_timestammp()))", "\n", "# add gausian noise here to prevent all blank boxez", "\n", "", "if", "video_tensor", ".", "shape", "[", "1", "]", "<", "self", ".", "num_frames", ":", "\n", "            ", "zeros", "=", "th", ".", "ones", "(", "(", "3", ",", "self", ".", "num_frames", "-", "video_tensor", ".", "shape", "[", "1", "]", ",", "self", ".", "size", ",", "self", ".", "size", ")", ",", "dtype", "=", "th", ".", "uint8", ")", "\n", "video_tensor", "=", "th", ".", "cat", "(", "(", "video_tensor", ",", "zeros", ")", ",", "axis", "=", "1", ")", "\n", "", "return", "video_tensor", "[", ":", ",", ":", "self", ".", "num_frames", "]", "\n", "\n", "", "def", "_zero_pad_tensor_token", "(", "self", ",", "tensor", ",", "size", ")", ":", "\n", "        ", "if", "len", "(", "tensor", ")", ">=", "size", ":", "\n", "            ", "return", "tensor", "[", ":", "size", "]", "\n", "", "else", ":", "\n", "            ", "zero", "=", "th", ".", "zeros", "(", "size", "-", "len", "(", "tensor", ")", ")", ".", "long", "(", ")", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_v2.Ego4DDataset._zero_pad_tensor_token": [[150, 156], ["len", "torch.zeros().long", "torch.cat", "torch.zeros", "len"], "methods", ["None"], ["return", "th", ".", "cat", "(", "(", "tensor", ",", "zero", ")", ",", "dim", "=", "0", ")", "\n", "\n", "", "", "def", "get_text", "(", "self", ",", "sample", ",", "index", ")", ":", "\n", "        ", "text", "=", "sample", "[", "'narration_text'", "]", "\n", "# TODO: May need to be improved for edge cases.", "\n", "encoding", "=", "self", ".", "tokenizer", "(", "\n", "text", ",", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_v2.Ego4DDataset.get_text": [[157, 172], ["ego4d_v2.Ego4DDataset.tokenizer"], "methods", ["None"], ["padding", "=", "\"max_length\"", ",", "\n", "truncation", "=", "True", ",", "\n", "max_length", "=", "self", ".", "max_text_len", ",", "\n", "return_special_tokens_mask", "=", "True", ",", "\n", ")", "\n", "return", "{", "\n", "\"text\"", ":", "(", "text", ",", "encoding", ")", ",", "\n", "\"img_index\"", ":", "index", ",", "\n", "\"cap_index\"", ":", "index", ",", "\n", "\"raw_index\"", ":", "index", ",", "\n", "}", "\n", "\n", "", "def", "get_false_text", "(", "self", ",", "rep", ")", ":", "\n", "        ", "random_index", "=", "random", ".", "randint", "(", "0", ",", "len", "(", "self", ".", "metadata", ")", "-", "1", ")", "\n", "# two annotations", "\n", "if", "random", ".", "random", "(", ")", "<", "0.5", ":", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_v2.Ego4DDataset.get_false_text": [[174, 191], ["random.randint", "ego4d_v2.Ego4DDataset.tokenizer", "random.random", "len", "random.randint", "len"], "methods", ["None"], ["", "else", ":", "\n", "            ", "meta", "=", "self", ".", "metadata", "[", "self", ".", "meta_keys", "[", "random_index", "]", "]", "[", "'narration_pass_2'", "]", "\n", "", "sample", "=", "meta", "[", "random", ".", "randint", "(", "0", ",", "len", "(", "meta", ")", "-", "1", ")", "]", "# random choice one sample", "\n", "text", "=", "sample", "[", "'narration_text'", "]", "\n", "encoding", "=", "self", ".", "tokenizer", "(", "\n", "text", ",", "\n", "# padding=\"max_length\",", "\n", "truncation", "=", "True", ",", "\n", "max_length", "=", "self", ".", "max_text_len", ",", "\n", "return_special_tokens_mask", "=", "True", ",", "\n", ")", "\n", "return", "{", "f\"false_text_{rep}\"", ":", "(", "text", ",", "encoding", ")", "}", "\n", "\n", "", "def", "_get_video_path", "(", "self", ",", "sample", ")", ":", "\n", "        ", "rel_video_fp", "=", "sample", "[", "\"video_path\"", "]", "+", "'.mp4'", "\n", "full_video_fp", "=", "os", ".", "path", ".", "join", "(", "self", ".", "data_dir", ",", "rel_video_fp", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "full_video_fp", ")", ":", "\n", "            ", "Exception", "(", "IOError", ")", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_v2.Ego4DDataset._get_video_path": [[192, 198], ["os.path.join", "os.path.exists", "Exception"], "methods", ["None"], ["", "return", "full_video_fp", ",", "rel_video_fp", "\n", "\n", "", "def", "get_raw_video", "(", "self", ",", "sample", ")", ":", "\n", "        ", "abs_fp", ",", "rel_fp", "=", "self", ".", "_get_video_path", "(", "sample", ")", "\n", "# in four seconds", "\n", "# print(sample)", "\n", "sample", "[", "\"video_len\"", "]", "=", "self", ".", "get_video_len", "(", "abs_fp", ")", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_v2.Ego4DDataset.get_raw_video": [[199, 211], ["ego4d_v2.Ego4DDataset._get_video_path", "ego4d_v2.Ego4DDataset.get_video_len", "ego4d_v2.Ego4DDataset.read_frames_ffmpeg().permute", "Exception", "ego4d_v2.Ego4DDataset.read_frames_ffmpeg"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_v2.Ego4DDataset._get_video_path", "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_v2.Ego4DDataset.get_video_len", "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_v2.Ego4DDataset.read_frames_ffmpeg"], ["center", "=", "sample", "[", "'timestamp_sec'", "]", "\n", "imgs", "=", "self", ".", "read_frames_ffmpeg", "(", "abs_fp", ",", "center", ",", "sample", "[", "\"video_len\"", "]", ")", ".", "permute", "(", "1", ",", "0", ",", "2", ",", "3", ")", "\n", "# print(imgs.size())", "\n", "if", "imgs", "is", "None", ":", "\n", "            ", "raise", "Exception", "(", "\"Invalid video!\"", ",", "rel_fp", ")", "\n", "", "else", ":", "\n", "            ", "return", "imgs", "\n", "\n", "", "", "def", "get_video", "(", "self", ",", "sample", ")", ":", "\n", "        ", "imgs_tensor", "=", "self", ".", "get_raw_video", "(", "sample", ")", "\n", "return", "imgs_tensor", "\n", "\n", "", "def", "get_false_video", "(", "self", ",", "rep", ")", ":", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_v2.Ego4DDataset.get_video": [[212, 215], ["ego4d_v2.Ego4DDataset.get_raw_video"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_v2.Ego4DDataset.get_raw_video"], ["        ", "random_index", "=", "random", ".", "randint", "(", "0", ",", "len", "(", "self", ".", "metadata", ")", "-", "1", ")", "\n", "# two annotations", "\n", "if", "random", ".", "random", "(", ")", "<", "0.5", ":", "\n", "            ", "meta", "=", "self", ".", "metadata", "[", "self", ".", "meta_keys", "[", "random_index", "]", "]", "[", "'narration_pass_1'", "]", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_v2.Ego4DDataset.get_false_video": [[216, 229], ["random.randint", "ego4d_v2.Ego4DDataset.get_raw_video", "random.random", "len", "ego4d_v2.Ego4DDataset.get_false_video", "len", "random.randint", "len"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_v2.Ego4DDataset.get_raw_video", "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_v2.Ego4DDataset.get_false_video"], ["", "else", ":", "\n", "            ", "meta", "=", "self", ".", "metadata", "[", "self", ".", "meta_keys", "[", "random_index", "]", "]", "[", "'narration_pass_2'", "]", "\n", "", "if", "len", "(", "meta", ")", "<", "1", ":", "\n", "            ", "return", "self", ".", "get_false_video", "(", "rep", ")", "\n", "", "sample", "=", "meta", "[", "random", ".", "randint", "(", "0", ",", "len", "(", "meta", ")", "-", "1", ")", "]", "# random choice one sample", "\n", "sample", "[", "\"video_path\"", "]", "=", "self", ".", "meta_keys", "[", "random_index", "]", "# video path", "\n", "imgs_tensor", "=", "self", ".", "get_raw_video", "(", "sample", ")", "\n", "return", "{", "f\"false_image_{rep}\"", ":", "imgs_tensor", "}", "\n", "\n", "", "def", "get_suite", "(", "self", ",", "index", ")", ":", "\n", "        ", "result", "=", "None", "\n", "while", "result", "is", "None", ":", "\n", "# two annotations", "\n", "            ", "try", ":", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_v2.Ego4DDataset.get_suite": [[230, 267], ["dict", "ego4d_v2.Ego4DDataset.get_text", "dict.update", "dict.update", "ego4d_v2.Ego4DDataset.get_video", "dict.update", "dict.update", "range", "range", "random.random", "len", "random.randint", "ego4d_v2.Ego4DDataset.get_suite", "dict.update", "dict.update", "random.randint", "random.randint", "ego4d_v2.Ego4DDataset.get_false_video", "ego4d_v2.Ego4DDataset.get_false_text", "len", "len", "len"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_v2.Ego4DDataset.get_text", "home.repos.pwc.inspect_result.showlab_all-in-one.gadgets.my_metrics.VQAScore.update", "home.repos.pwc.inspect_result.showlab_all-in-one.gadgets.my_metrics.VQAScore.update", "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_v2.Ego4DDataset.get_video", "home.repos.pwc.inspect_result.showlab_all-in-one.gadgets.my_metrics.VQAScore.update", "home.repos.pwc.inspect_result.showlab_all-in-one.gadgets.my_metrics.VQAScore.update", "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_v2.Ego4DDataset.get_suite", "home.repos.pwc.inspect_result.showlab_all-in-one.gadgets.my_metrics.VQAScore.update", "home.repos.pwc.inspect_result.showlab_all-in-one.gadgets.my_metrics.VQAScore.update", "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_v2.Ego4DDataset.get_false_video", "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_v2.Ego4DDataset.get_false_text"], ["                ", "if", "random", ".", "random", "(", ")", "<", "0.5", ":", "\n", "                    ", "meta", "=", "self", ".", "metadata", "[", "self", ".", "meta_keys", "[", "index", "]", "]", "[", "'narration_pass_1'", "]", "\n", "", "else", ":", "\n", "                    ", "meta", "=", "self", ".", "metadata", "[", "self", ".", "meta_keys", "[", "index", "]", "]", "[", "'narration_pass_2'", "]", "\n", "", "if", "len", "(", "meta", ")", "<", "2", ":", "\n", "                    ", "random_index", "=", "random", ".", "randint", "(", "0", ",", "len", "(", "self", ".", "metadata", ")", "-", "1", ")", "\n", "return", "self", ".", "get_suite", "(", "random_index", ")", "\n", "", "sample", "=", "meta", "[", "random", ".", "randint", "(", "0", ",", "len", "(", "meta", ")", "-", "1", ")", "]", "# random choice one sample", "\n", "sample", "[", "\"video_path\"", "]", "=", "self", ".", "meta_keys", "[", "index", "]", "# video path", "\n", "# print(sample)", "\n", "ret", "=", "dict", "(", ")", "\n", "text", "=", "self", ".", "get_text", "(", "sample", ",", "index", ")", "\n", "ret", ".", "update", "(", "{", "\"replica\"", ":", "True", "if", "text", "[", "\"cap_index\"", "]", ">", "0", "else", "False", "}", ")", "\n", "ret", ".", "update", "(", "text", ")", "\n", "imgs_tensor", "=", "self", ".", "get_video", "(", "sample", ")", "\n", "# print(imgs_tensor.size())", "\n", "ret", ".", "update", "(", "{", "\n", "\"image\"", ":", "imgs_tensor", ",", "\n", "\"img_index\"", ":", "index", ",", "\n", "\"cap_index\"", ":", "index", ",", "\n", "\"raw_index\"", ":", "index", ",", "\n", "}", ")", "\n", "ret", ".", "update", "(", "{", "\"replica\"", ":", "True", "if", "ret", "[", "\"cap_index\"", "]", ">", "0", "else", "False", "}", ")", "\n", "for", "i", "in", "range", "(", "self", ".", "draw_false_image", ")", ":", "\n", "                    ", "ret", ".", "update", "(", "self", ".", "get_false_video", "(", "i", ")", ")", "\n", "", "for", "i", "in", "range", "(", "self", ".", "draw_false_text", ")", ":", "\n", "                    ", "ret", ".", "update", "(", "self", ".", "get_false_text", "(", "i", ")", ")", "\n", "", "result", "=", "True", "\n", "", "except", "Exception", "as", "e", ":", "\n", "# print(e)", "\n", "                ", "index", "=", "random", ".", "randint", "(", "0", ",", "len", "(", "self", ".", "metadata", ")", "-", "1", ")", "\n", "", "", "return", "ret", "\n", "\n", "", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "metadata", ")", "\n", "\n", "", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "return", "self", ".", "get_suite", "(", "index", ")", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_v2.Ego4DDataset.__getitem__": [[271, 273], ["ego4d_v2.Ego4DDataset.get_suite"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_v2.Ego4DDataset.get_suite"], []], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.vg_caption_dataset.VisualGenomeCaptionDataset.__init__": [[5, 17], ["base_dataset.BaseDataset.__init__"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.transforms.utils.UnNormalize.__init__"], ["    ", "def", "__init__", "(", "self", ",", "*", "args", ",", "split", "=", "\"\"", ",", "**", "kwargs", ")", ":", "\n", "        ", "assert", "split", "in", "[", "\"train\"", ",", "\"val\"", ",", "\"test\"", "]", "\n", "if", "split", "==", "\"test\"", ":", "\n", "            ", "split", "=", "\"val\"", "\n", "\n", "", "if", "split", "==", "\"train\"", ":", "\n", "            ", "names", "=", "[", "\"vg_train\"", "]", "\n", "", "elif", "split", "==", "\"val\"", ":", "\n", "            ", "names", "=", "[", "]", "\n", "", "elif", "split", "==", "\"test\"", ":", "\n", "            ", "names", "=", "[", "]", "\n", "", "super", "(", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ",", "names", "=", "names", ",", "text_column_name", "=", "\"caption\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.datasets.vg_caption_dataset.VisualGenomeCaptionDataset.__getitem__": [[18, 20], ["vg_caption_dataset.VisualGenomeCaptionDataset.get_suite"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.datasets.ego4d_v2.Ego4DDataset.get_suite"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "return", "self", ".", "get_suite", "(", "index", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.showlab_all-in-one.gadgets.my_metrics.Accuracy.__init__": [[17, 21], ["pytorch_lightning.metrics.Metric.__init__", "my_metrics.Accuracy.add_state", "my_metrics.Accuracy.add_state", "torch.tensor", "torch.tensor"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.transforms.utils.UnNormalize.__init__"], ["        ", "super", "(", ")", ".", "__init__", "(", "dist_sync_on_step", "=", "dist_sync_on_step", ")", "\n", "self", ".", "add_state", "(", "\"correct\"", ",", "default", "=", "torch", ".", "tensor", "(", "0.0", ")", ",", "dist_reduce_fx", "=", "\"sum\"", ")", "\n", "self", ".", "add_state", "(", "\"total\"", ",", "default", "=", "torch", ".", "tensor", "(", "0.0", ")", ",", "dist_reduce_fx", "=", "\"sum\"", ")", "\n", "\n", "", "def", "update", "(", "self", ",", "logits", ",", "target", ",", "unfilterd", "=", "False", ")", ":", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.gadgets.my_metrics.Accuracy.update": [[22, 42], ["logits.argmax", "target.numel", "torch.sum", "logits.detach().to", "target.detach().to", "target.numel", "target.numel", "logits.detach", "target.detach"], "methods", ["None"], ["        ", "logits", ",", "target", "=", "(", "\n", "logits", ".", "detach", "(", ")", ".", "to", "(", "self", ".", "correct", ".", "device", ")", ",", "\n", "target", ".", "detach", "(", ")", ".", "to", "(", "self", ".", "correct", ".", "device", ")", ",", "\n", ")", "\n", "preds", "=", "logits", ".", "argmax", "(", "dim", "=", "-", "1", ")", "\n", "preds", "=", "preds", "[", "target", "!=", "-", "100", "]", "\n", "unfilter_num", "=", "target", ".", "numel", "(", ")", "\n", "target", "=", "target", "[", "target", "!=", "-", "100", "]", "\n", "if", "target", ".", "numel", "(", ")", "==", "0", ":", "\n", "            ", "return", "1", "\n", "\n", "", "assert", "preds", ".", "shape", "==", "target", ".", "shape", "\n", "\n", "self", ".", "correct", "+=", "torch", ".", "sum", "(", "preds", "==", "target", ")", "\n", "if", "unfilterd", ":", "\n", "# print(\"no filter\")", "\n", "            ", "self", ".", "total", "+=", "unfilter_num", "\n", "", "else", ":", "\n", "            ", "self", ".", "total", "+=", "target", ".", "numel", "(", ")", "\n", "\n", "", "", "def", "compute", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.gadgets.my_metrics.Accuracy.compute": [[43, 45], ["None"], "methods", ["None"], ["        ", "return", "self", ".", "correct", "/", "self", ".", "total", "\n", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.gadgets.my_metrics.Scalar.__init__": [[48, 52], ["pytorch_lightning.metrics.Metric.__init__", "my_metrics.Scalar.add_state", "my_metrics.Scalar.add_state", "torch.tensor", "torch.tensor"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.transforms.utils.UnNormalize.__init__"], ["        ", "super", "(", ")", ".", "__init__", "(", "dist_sync_on_step", "=", "dist_sync_on_step", ")", "\n", "self", ".", "add_state", "(", "\"scalar\"", ",", "default", "=", "torch", ".", "tensor", "(", "0.0", ")", ",", "dist_reduce_fx", "=", "\"sum\"", ")", "\n", "self", ".", "add_state", "(", "\"total\"", ",", "default", "=", "torch", ".", "tensor", "(", "0.0", ")", ",", "dist_reduce_fx", "=", "\"sum\"", ")", "\n", "\n", "", "def", "update", "(", "self", ",", "scalar", ")", ":", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.gadgets.my_metrics.Scalar.update": [[53, 60], ["isinstance", "torch.tensor().float().to.detach().to", "torch.tensor().float().to", "torch.tensor().float().to.detach", "torch.tensor().float", "torch.tensor"], "methods", ["None"], ["        ", "if", "isinstance", "(", "scalar", ",", "torch", ".", "Tensor", ")", ":", "\n", "            ", "scalar", "=", "scalar", ".", "detach", "(", ")", ".", "to", "(", "self", ".", "scalar", ".", "device", ")", "\n", "", "else", ":", "\n", "            ", "scalar", "=", "torch", ".", "tensor", "(", "scalar", ")", ".", "float", "(", ")", ".", "to", "(", "self", ".", "scalar", ".", "device", ")", "\n", "", "self", ".", "scalar", "+=", "scalar", "\n", "self", ".", "total", "+=", "1", "\n", "\n", "", "def", "compute", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.gadgets.my_metrics.Scalar.compute": [[61, 63], ["None"], "methods", ["None"], ["        ", "return", "self", ".", "scalar", "/", "self", ".", "total", "\n", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.gadgets.my_metrics.VQAScore.__init__": [[66, 70], ["pytorch_lightning.metrics.Metric.__init__", "my_metrics.VQAScore.add_state", "my_metrics.VQAScore.add_state", "torch.tensor", "torch.tensor"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.transforms.utils.UnNormalize.__init__"], ["        ", "super", "(", ")", ".", "__init__", "(", "dist_sync_on_step", "=", "dist_sync_on_step", ")", "\n", "self", ".", "add_state", "(", "\"score\"", ",", "default", "=", "torch", ".", "tensor", "(", "0.0", ")", ",", "dist_reduce_fx", "=", "\"sum\"", ")", "\n", "self", ".", "add_state", "(", "\"total\"", ",", "default", "=", "torch", ".", "tensor", "(", "0.0", ")", ",", "dist_reduce_fx", "=", "\"sum\"", ")", "\n", "\n", "", "def", "update", "(", "self", ",", "logits", ",", "target", ")", ":", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.gadgets.my_metrics.VQAScore.update": [[71, 83], ["torch.zeros().to", "torch.zeros().to.scatter_", "scores.sum", "len", "logits.detach().float().to", "target.detach().float().to", "torch.max", "logits.view", "torch.zeros", "logits.detach().float", "target.detach().float", "target.size", "logits.detach", "target.detach"], "methods", ["None"], ["        ", "logits", ",", "target", "=", "(", "\n", "logits", ".", "detach", "(", ")", ".", "float", "(", ")", ".", "to", "(", "self", ".", "score", ".", "device", ")", ",", "\n", "target", ".", "detach", "(", ")", ".", "float", "(", ")", ".", "to", "(", "self", ".", "score", ".", "device", ")", ",", "\n", ")", "\n", "logits", "=", "torch", ".", "max", "(", "logits", ",", "1", ")", "[", "1", "]", "\n", "one_hots", "=", "torch", ".", "zeros", "(", "*", "target", ".", "size", "(", ")", ")", ".", "to", "(", "target", ")", "\n", "one_hots", ".", "scatter_", "(", "1", ",", "logits", ".", "view", "(", "-", "1", ",", "1", ")", ",", "1", ")", "\n", "scores", "=", "one_hots", "*", "target", "\n", "\n", "self", ".", "score", "+=", "scores", ".", "sum", "(", ")", "\n", "self", ".", "total", "+=", "len", "(", "logits", ")", "\n", "\n", "", "def", "compute", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.gadgets.my_metrics.VQAScore.compute": [[84, 86], ["None"], "methods", ["None"], ["        ", "return", "self", ".", "score", "/", "self", ".", "total", "\n", "", "", ""]], "home.repos.pwc.inspect_result.showlab_all-in-one.gadgets.my_metrics.order_class_index": [[6, 14], ["list", "list.index", "itertools.permutations", "tuple", "list", "order.tolist", "range", "len"], "function", ["None"], ["    ", "\"\"\"Return the index of the order in its full permutation.\n\n    Args:\n        order (tensor): e.g. [0,1,2]\n    \"\"\"", "\n", "classes", "=", "list", "(", "itertools", ".", "permutations", "(", "list", "(", "range", "(", "len", "(", "order", ")", ")", ")", ")", ")", "\n", "return", "classes", ".", "index", "(", "tuple", "(", "order", ".", "tolist", "(", ")", ")", ")", "\n", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.modules.temporal_roll.TemporalRoll.__init__": [[7, 12], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.transforms.utils.UnNormalize.__init__"], ["    ", "def", "__init__", "(", "self", ",", "n_segment", "=", "3", ",", "n_div", "=", "8", ",", "v", "=", "0", ")", ":", "\n", "        ", "super", "(", "TemporalRoll", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "n_segment", "=", "n_segment", "\n", "self", ".", "fold_div", "=", "n_div", "\n", "self", ".", "v", "=", "v", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.modules.temporal_roll.TemporalRoll.forward": [[13, 64], ["x.view.view.size", "x.view.view.view", "torch.zeros_like.view", "torch.zeros_like.view", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.roll", "torch.roll", "torch.roll", "torch.roll", "torch.roll", "torch.roll", "torch.roll", "torch.roll", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "random.sample", "torch.roll", "torch.roll", "torch.roll", "torch.roll", "range", "min", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.roll", "torch.roll", "torch.roll", "torch.roll", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "layer", "=", "1", ")", ":", "\n", "# return x", "\n", "        ", "nt", ",", "l", ",", "c", "=", "x", ".", "size", "(", ")", "\n", "n_batch", "=", "nt", "//", "self", ".", "n_segment", "\n", "x", "=", "x", ".", "view", "(", "n_batch", ",", "self", ".", "n_segment", ",", "l", ",", "c", ")", "\n", "if", "self", ".", "v", "==", "0", ":", "\n", "# 16, 3, 197, 768", "\n", "            ", "fold", "=", "l", "//", "self", ".", "fold_div", "\n", "out", "=", "torch", ".", "zeros_like", "(", "x", ")", "\n", "# keep cls token", "\n", "out", "[", ":", ",", ":", ",", "0", "]", "=", "x", "[", ":", ",", ":", ",", "0", "]", "\n", "#  roll left step 1 along time dimension (1)", "\n", "out", "[", ":", ",", ":", ",", "1", ":", "fold", "+", "1", "]", "=", "torch", ".", "roll", "(", "x", "[", ":", ",", ":", ",", "1", ":", "fold", "+", "1", "]", ",", "1", ",", "1", ")", "\n", "# roll right step 1 along time dimension (1)", "\n", "out", "[", ":", ",", ":", ",", "-", "fold", ":", "]", "=", "torch", ".", "roll", "(", "x", "[", ":", ",", ":", ",", "-", "fold", ":", "]", ",", "-", "1", ",", "1", ")", "\n", "# not roll", "\n", "out", "[", ":", ",", ":", ",", "1", "+", "fold", ":", "-", "fold", "]", "=", "x", "[", ":", ",", ":", ",", "1", "+", "fold", ":", "-", "fold", "]", "\n", "# # 16, 3, 197, 768", "\n", "# fold = l // self.fold_div", "\n", "# out = torch.zeros_like(x)", "\n", "# #  roll left step 1 along time dimension (1)", "\n", "# out[:, :, :fold] = torch.roll(x[:, :, :fold], 1, 1)", "\n", "# # roll right step 1 along time dimension (1)", "\n", "# out[:, :, -fold:] = torch.roll(x[:, :, -fold:], -1, 1)", "\n", "# # not roll", "\n", "# out[:, :, fold:-fold] = x[:, :, fold: -fold]", "\n", "# random sampling", "\n", "", "elif", "self", ".", "v", "==", "1", ":", "\n", "            ", "out", "=", "torch", ".", "zeros_like", "(", "x", ")", "\n", "roll_token_idexs", "=", "random", ".", "sample", "(", "range", "(", "1", ",", "l", ")", ",", "l", "//", "2", ")", "\n", "# print(roll_token_idexs)", "\n", "out", "=", "x", "\n", "out", "[", ":", ",", ":", ",", "roll_token_idexs", "]", "=", "torch", ".", "roll", "(", "x", "[", ":", ",", ":", ",", "roll_token_idexs", "]", ",", "1", ",", "1", ")", "\n", "# roll different tokens for different blocks", "\n", "", "elif", "self", ".", "v", "==", "2", ":", "\n", "            ", "rolled_token_len", "=", "l", "//", "self", ".", "fold_div", "\n", "fold", "=", "rolled_token_len", "*", "(", "layer", "%", "self", ".", "fold_div", ")", "\n", "begin_index", "=", "1", "+", "fold", "\n", "end_index", "=", "min", "(", "1", "+", "fold", "+", "rolled_token_len", ",", "l", ")", "\n", "out", "=", "torch", ".", "zeros_like", "(", "x", ")", "\n", "out", "[", ":", ",", ":", ",", "0", "]", "=", "x", "[", ":", ",", ":", ",", "0", "]", "# cls token unchanged", "\n", "out", "[", ":", ",", ":", ",", "begin_index", ":", "]", "=", "x", "[", ":", ",", ":", ",", "begin_index", ":", "]", "\n", "out", "[", ":", ",", ":", ",", "begin_index", ":", "end_index", "]", "=", "torch", ".", "roll", "(", "x", "[", ":", ",", ":", ",", "begin_index", ":", "end_index", "]", ",", "1", ",", "1", ")", "\n", "out", "[", ":", ",", ":", ",", "end_index", ":", "]", "=", "x", "[", ":", ",", ":", ",", "end_index", ":", "]", "\n", "", "else", ":", "# not roll", "\n", "            ", "fold", "=", "c", "//", "self", ".", "fold_div", "\n", "out", "=", "torch", ".", "zeros_like", "(", "x", ")", "\n", "out", "[", ":", ",", ":", "-", "1", ",", ":", "fold", "]", "=", "x", "[", ":", ",", "1", ":", ",", ":", "fold", "]", "# shift left tokens", "\n", "out", "[", ":", ",", "1", ":", ",", "fold", ":", "2", "*", "fold", "]", "=", "x", "[", ":", ",", ":", "-", "1", ",", "fold", ":", "2", "*", "fold", "]", "# shift right tokens", "\n", "out", "[", ":", ",", ":", ",", "2", "*", "fold", ":", "]", "=", "x", "[", ":", ",", ":", ",", "2", "*", "fold", ":", "]", "# not shift", "\n", "", "return", "out", ".", "view", "(", "nt", ",", "l", ",", "c", ")", "", "", "", ""]], "home.repos.pwc.inspect_result.showlab_all-in-one.modules.forzen_param.forzen_param": [[13, 20], ["model.named_parameters"], "function", ["None"], ["def", "forzen_param", "(", "model", ")", ":", "\n", "    ", "flag", "=", "False", "\n", "for", "name", ",", "param", "in", "model", ".", "named_parameters", "(", ")", ":", "\n", "        ", "if", "'10'", "in", "name", ":", "\n", "            ", "flag", "=", "True", "\n", "", "param", ".", "requires_grad", "=", "flag", "\n", "", "return", "True", "", "", ""]], "home.repos.pwc.inspect_result.showlab_all-in-one.modules.dist_utils.get_world_size": [[23, 29], ["torch.get_world_size", "torch.is_available", "torch.is_initialized"], "function", ["home.repos.pwc.inspect_result.showlab_all-in-one.modules.dist_utils.get_world_size"], ["def", "get_world_size", "(", ")", "->", "int", ":", "\n", "    ", "if", "not", "dist", ".", "is_available", "(", ")", ":", "\n", "        ", "return", "1", "\n", "", "if", "not", "dist", ".", "is_initialized", "(", ")", ":", "\n", "        ", "return", "1", "\n", "", "return", "dist", ".", "get_world_size", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.modules.dist_utils.get_rank": [[31, 37], ["torch.get_rank", "torch.is_available", "torch.is_initialized"], "function", ["home.repos.pwc.inspect_result.showlab_all-in-one.modules.dist_utils.get_rank"], ["", "def", "get_rank", "(", ")", "->", "int", ":", "\n", "    ", "if", "not", "dist", ".", "is_available", "(", ")", ":", "\n", "        ", "return", "0", "\n", "", "if", "not", "dist", ".", "is_initialized", "(", ")", ":", "\n", "        ", "return", "0", "\n", "", "return", "dist", ".", "get_rank", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.modules.dist_utils.get_local_rank": [[39, 50], ["torch.get_rank", "torch.is_available", "torch.is_initialized"], "function", ["home.repos.pwc.inspect_result.showlab_all-in-one.modules.dist_utils.get_rank"], ["", "def", "get_local_rank", "(", ")", "->", "int", ":", "\n", "    ", "\"\"\"\n    Returns:\n        The rank of the current process within the local (per-machine) process group.\n    \"\"\"", "\n", "if", "not", "dist", ".", "is_available", "(", ")", ":", "\n", "        ", "return", "0", "\n", "", "if", "not", "dist", ".", "is_initialized", "(", ")", ":", "\n", "        ", "return", "0", "\n", "", "assert", "_LOCAL_PROCESS_GROUP", "is", "not", "None", "\n", "return", "dist", ".", "get_rank", "(", "group", "=", "_LOCAL_PROCESS_GROUP", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.modules.dist_utils.get_local_size": [[52, 63], ["torch.get_world_size", "torch.is_available", "torch.is_initialized"], "function", ["home.repos.pwc.inspect_result.showlab_all-in-one.modules.dist_utils.get_world_size"], ["", "def", "get_local_size", "(", ")", "->", "int", ":", "\n", "    ", "\"\"\"\n    Returns:\n        The size of the per-machine process group,\n        i.e. the number of processes per machine.\n    \"\"\"", "\n", "if", "not", "dist", ".", "is_available", "(", ")", ":", "\n", "        ", "return", "1", "\n", "", "if", "not", "dist", ".", "is_initialized", "(", ")", ":", "\n", "        ", "return", "1", "\n", "", "return", "dist", ".", "get_world_size", "(", "group", "=", "_LOCAL_PROCESS_GROUP", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.modules.dist_utils.is_main_process": [[65, 67], ["dist_utils.get_rank"], "function", ["home.repos.pwc.inspect_result.showlab_all-in-one.modules.dist_utils.get_rank"], ["", "def", "is_main_process", "(", ")", "->", "bool", ":", "\n", "    ", "return", "get_rank", "(", ")", "==", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.modules.dist_utils.synchronize": [[69, 82], ["torch.get_world_size", "torch.barrier", "torch.is_available", "torch.is_initialized"], "function", ["home.repos.pwc.inspect_result.showlab_all-in-one.modules.dist_utils.get_world_size"], ["", "def", "synchronize", "(", ")", ":", "\n", "    ", "\"\"\"\n    Helper function to synchronize (barrier) among all processes when\n    using distributed training\n    \"\"\"", "\n", "if", "not", "dist", ".", "is_available", "(", ")", ":", "\n", "        ", "return", "\n", "", "if", "not", "dist", ".", "is_initialized", "(", ")", ":", "\n", "        ", "return", "\n", "", "world_size", "=", "dist", ".", "get_world_size", "(", ")", "\n", "if", "world_size", "==", "1", ":", "\n", "        ", "return", "\n", "", "dist", ".", "barrier", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.modules.dist_utils._get_global_gloo_group": [[84, 94], ["functools.lru_cache", "torch.get_backend", "torch.new_group"], "function", ["None"], ["", "@", "functools", ".", "lru_cache", "(", ")", "\n", "def", "_get_global_gloo_group", "(", ")", ":", "\n", "    ", "\"\"\"\n    Return a process group based on gloo backend, containing all the ranks\n    The result is cached.\n    \"\"\"", "\n", "if", "dist", ".", "get_backend", "(", ")", "==", "\"nccl\"", ":", "\n", "        ", "return", "dist", ".", "new_group", "(", "backend", "=", "\"gloo\"", ")", "\n", "", "else", ":", "\n", "        ", "return", "dist", ".", "group", ".", "WORLD", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.modules.dist_utils._serialize_to_tensor": [[96, 112], ["torch.get_backend", "torch.device", "torch.device", "torch.device", "pickle.dumps", "torch.ByteStorage.from_buffer", "torch.ByteStorage.from_buffer", "torch.ByteStorage.from_buffer", "torch.ByteTensor().to", "torch.ByteTensor().to", "torch.ByteTensor().to", "len", "logging.getLogger", "logging.getLogger.warning", "torch.ByteTensor", "torch.ByteTensor", "torch.ByteTensor", "dist_utils.get_rank", "len"], "function", ["home.repos.pwc.inspect_result.showlab_all-in-one.modules.dist_utils.get_rank"], ["", "", "def", "_serialize_to_tensor", "(", "data", ",", "group", ")", ":", "\n", "    ", "backend", "=", "dist", ".", "get_backend", "(", "group", ")", "\n", "assert", "backend", "in", "[", "\"gloo\"", ",", "\"nccl\"", "]", "\n", "device", "=", "torch", ".", "device", "(", "\"cpu\"", "if", "backend", "==", "\"gloo\"", "else", "\"cuda\"", ")", "\n", "\n", "buffer", "=", "pickle", ".", "dumps", "(", "data", ")", "\n", "if", "len", "(", "buffer", ")", ">", "1024", "**", "3", ":", "\n", "        ", "logger", "=", "logging", ".", "getLogger", "(", "__name__", ")", "\n", "logger", ".", "warning", "(", "\n", "\"Rank {} trying to all-gather {:.2f} GB of data on device {}\"", ".", "format", "(", "\n", "get_rank", "(", ")", ",", "len", "(", "buffer", ")", "/", "(", "1024", "**", "3", ")", ",", "device", "\n", ")", "\n", ")", "\n", "", "storage", "=", "torch", ".", "ByteStorage", ".", "from_buffer", "(", "buffer", ")", "\n", "tensor", "=", "torch", ".", "ByteTensor", "(", "storage", ")", ".", "to", "(", "device", "=", "device", ")", "\n", "return", "tensor", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.modules.dist_utils._pad_to_largest_tensor": [[114, 142], ["torch.get_world_size", "torch.tensor", "torch.tensor", "torch.tensor", "torch.all_gather", "max", "torch.zeros", "torch.zeros", "torch.zeros", "int", "torch.zeros", "torch.zeros", "torch.zeros", "torch.cat", "torch.cat", "torch.cat", "torch.cat.numel", "range", "size.item"], "function", ["home.repos.pwc.inspect_result.showlab_all-in-one.modules.dist_utils.get_world_size", "home.repos.pwc.inspect_result.showlab_all-in-one.modules.dist_utils.all_gather"], ["", "def", "_pad_to_largest_tensor", "(", "tensor", ",", "group", ")", ":", "\n", "    ", "\"\"\"\n    Returns:\n        list[int]: size of the tensor, on each rank\n        Tensor: padded tensor that has the max size\n    \"\"\"", "\n", "world_size", "=", "dist", ".", "get_world_size", "(", "group", "=", "group", ")", "\n", "assert", "(", "\n", "world_size", ">=", "1", "\n", ")", ",", "\"comm.gather/all_gather must be called from ranks within the given group!\"", "\n", "local_size", "=", "torch", ".", "tensor", "(", "[", "tensor", ".", "numel", "(", ")", "]", ",", "dtype", "=", "torch", ".", "int64", ",", "device", "=", "tensor", ".", "device", ")", "\n", "size_list", "=", "[", "\n", "torch", ".", "zeros", "(", "[", "1", "]", ",", "dtype", "=", "torch", ".", "int64", ",", "device", "=", "tensor", ".", "device", ")", "\n", "for", "_", "in", "range", "(", "world_size", ")", "\n", "]", "\n", "dist", ".", "all_gather", "(", "size_list", ",", "local_size", ",", "group", "=", "group", ")", "\n", "size_list", "=", "[", "int", "(", "size", ".", "item", "(", ")", ")", "for", "size", "in", "size_list", "]", "\n", "\n", "max_size", "=", "max", "(", "size_list", ")", "\n", "\n", "# we pad the tensor because torch all_gather does not support", "\n", "# gathering tensors of different shapes", "\n", "if", "local_size", "!=", "max_size", ":", "\n", "        ", "padding", "=", "torch", ".", "zeros", "(", "\n", "(", "max_size", "-", "local_size", ",", ")", ",", "dtype", "=", "torch", ".", "uint8", ",", "device", "=", "tensor", ".", "device", "\n", ")", "\n", "tensor", "=", "torch", ".", "cat", "(", "(", "tensor", ",", "padding", ")", ",", "dim", "=", "0", ")", "\n", "", "return", "size_list", ",", "tensor", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.modules.dist_utils.all_gather": [[144, 181], ["dist_utils._serialize_to_tensor", "dist_utils._pad_to_largest_tensor", "max", "torch.all_gather", "zip", "dist_utils.get_world_size", "dist_utils._get_global_gloo_group", "torch.get_world_size", "torch.empty", "torch.empty", "torch.empty", "data_list.append", "_serialize_to_tensor.cpu().numpy().tobytes", "pickle.loads", "_serialize_to_tensor.cpu().numpy", "_serialize_to_tensor.cpu"], "function", ["home.repos.pwc.inspect_result.showlab_all-in-one.modules.dist_utils._serialize_to_tensor", "home.repos.pwc.inspect_result.showlab_all-in-one.modules.dist_utils._pad_to_largest_tensor", "home.repos.pwc.inspect_result.showlab_all-in-one.modules.dist_utils.all_gather", "home.repos.pwc.inspect_result.showlab_all-in-one.modules.dist_utils.get_world_size", "home.repos.pwc.inspect_result.showlab_all-in-one.modules.dist_utils._get_global_gloo_group", "home.repos.pwc.inspect_result.showlab_all-in-one.modules.dist_utils.get_world_size"], ["", "def", "all_gather", "(", "data", ",", "group", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    Run all_gather on arbitrary picklable data (not necessarily tensors).\n\n    Args:\n        data: any picklable object\n        group: a torch process group. By default, will use a group which\n            contains all ranks on gloo backend.\n\n    Returns:\n        list[data]: list of data gathered from each rank\n    \"\"\"", "\n", "if", "get_world_size", "(", ")", "==", "1", ":", "\n", "        ", "return", "[", "data", "]", "\n", "", "if", "group", "is", "None", ":", "\n", "        ", "group", "=", "_get_global_gloo_group", "(", ")", "\n", "", "if", "dist", ".", "get_world_size", "(", "group", ")", "==", "1", ":", "\n", "        ", "return", "[", "data", "]", "\n", "\n", "", "tensor", "=", "_serialize_to_tensor", "(", "data", ",", "group", ")", "\n", "\n", "size_list", ",", "tensor", "=", "_pad_to_largest_tensor", "(", "tensor", ",", "group", ")", "\n", "max_size", "=", "max", "(", "size_list", ")", "\n", "\n", "# receiving Tensor from all ranks", "\n", "tensor_list", "=", "[", "\n", "torch", ".", "empty", "(", "(", "max_size", ",", ")", ",", "dtype", "=", "torch", ".", "uint8", ",", "device", "=", "tensor", ".", "device", ")", "\n", "for", "_", "in", "size_list", "\n", "]", "\n", "dist", ".", "all_gather", "(", "tensor_list", ",", "tensor", ",", "group", "=", "group", ")", "\n", "\n", "data_list", "=", "[", "]", "\n", "for", "size", ",", "tensor", "in", "zip", "(", "size_list", ",", "tensor_list", ")", ":", "\n", "        ", "buffer", "=", "tensor", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "tobytes", "(", ")", "[", ":", "size", "]", "\n", "data_list", ".", "append", "(", "pickle", ".", "loads", "(", "buffer", ")", ")", "\n", "\n", "", "return", "data_list", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.modules.dist_utils.gather": [[183, 225], ["torch.get_rank", "dist_utils._serialize_to_tensor", "dist_utils._pad_to_largest_tensor", "dist_utils.get_world_size", "dist_utils._get_global_gloo_group", "torch.get_world_size", "max", "torch.gather", "zip", "torch.gather", "torch.empty", "torch.empty", "torch.empty", "data_list.append", "_serialize_to_tensor.cpu().numpy().tobytes", "pickle.loads", "_serialize_to_tensor.cpu().numpy", "_serialize_to_tensor.cpu"], "function", ["home.repos.pwc.inspect_result.showlab_all-in-one.modules.dist_utils.get_rank", "home.repos.pwc.inspect_result.showlab_all-in-one.modules.dist_utils._serialize_to_tensor", "home.repos.pwc.inspect_result.showlab_all-in-one.modules.dist_utils._pad_to_largest_tensor", "home.repos.pwc.inspect_result.showlab_all-in-one.modules.dist_utils.get_world_size", "home.repos.pwc.inspect_result.showlab_all-in-one.modules.dist_utils._get_global_gloo_group", "home.repos.pwc.inspect_result.showlab_all-in-one.modules.dist_utils.get_world_size", "home.repos.pwc.inspect_result.showlab_all-in-one.modules.dist_utils.gather", "home.repos.pwc.inspect_result.showlab_all-in-one.modules.dist_utils.gather"], ["", "def", "gather", "(", "data", ",", "dst", "=", "0", ",", "group", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    Run gather on arbitrary picklable data (not necessarily tensors).\n\n    Args:\n        data: any picklable object\n        dst (int): destination rank\n        group: a torch process group. By default, will use a group which\n            contains all ranks on gloo backend.\n\n    Returns:\n        list[data]: on dst, a list of data gathered from each rank. Otherwise,\n            an empty list.\n    \"\"\"", "\n", "if", "get_world_size", "(", ")", "==", "1", ":", "\n", "        ", "return", "[", "data", "]", "\n", "", "if", "group", "is", "None", ":", "\n", "        ", "group", "=", "_get_global_gloo_group", "(", ")", "\n", "", "if", "dist", ".", "get_world_size", "(", "group", "=", "group", ")", "==", "1", ":", "\n", "        ", "return", "[", "data", "]", "\n", "", "rank", "=", "dist", ".", "get_rank", "(", "group", "=", "group", ")", "\n", "\n", "tensor", "=", "_serialize_to_tensor", "(", "data", ",", "group", ")", "\n", "size_list", ",", "tensor", "=", "_pad_to_largest_tensor", "(", "tensor", ",", "group", ")", "\n", "\n", "# receiving Tensor from all ranks", "\n", "if", "rank", "==", "dst", ":", "\n", "        ", "max_size", "=", "max", "(", "size_list", ")", "\n", "tensor_list", "=", "[", "\n", "torch", ".", "empty", "(", "(", "max_size", ",", ")", ",", "dtype", "=", "torch", ".", "uint8", ",", "device", "=", "tensor", ".", "device", ")", "\n", "for", "_", "in", "size_list", "\n", "]", "\n", "dist", ".", "gather", "(", "tensor", ",", "tensor_list", ",", "dst", "=", "dst", ",", "group", "=", "group", ")", "\n", "\n", "data_list", "=", "[", "]", "\n", "for", "size", ",", "tensor", "in", "zip", "(", "size_list", ",", "tensor_list", ")", ":", "\n", "            ", "buffer", "=", "tensor", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "tobytes", "(", ")", "[", ":", "size", "]", "\n", "data_list", ".", "append", "(", "pickle", ".", "loads", "(", "buffer", ")", ")", "\n", "", "return", "data_list", "\n", "", "else", ":", "\n", "        ", "dist", ".", "gather", "(", "tensor", ",", "[", "]", ",", "dst", "=", "dst", ",", "group", "=", "group", ")", "\n", "return", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.modules.dist_utils.shared_random_seed": [[227, 239], ["numpy.random.randint", "dist_utils.all_gather"], "function", ["home.repos.pwc.inspect_result.showlab_all-in-one.modules.dist_utils.all_gather"], ["", "", "def", "shared_random_seed", "(", ")", ":", "\n", "    ", "\"\"\"\n    Returns:\n        int: a random number that is the same across all workers.\n            If workers need a shared RNG, they can use this shared seed to\n            create one.\n\n    All workers must call this function, otherwise it will deadlock.\n    \"\"\"", "\n", "ints", "=", "np", ".", "random", ".", "randint", "(", "2", "**", "31", ")", "\n", "all_ints", "=", "all_gather", "(", "ints", ")", "\n", "return", "all_ints", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.modules.dist_utils.reduce_dict": [[241, 271], ["dist_utils.get_world_size", "torch.no_grad", "torch.no_grad", "torch.no_grad", "sorted", "torch.stack", "torch.stack", "torch.stack", "torch.reduce", "input_dict.keys", "names.append", "torch.stack.append", "torch.get_rank", "zip"], "function", ["home.repos.pwc.inspect_result.showlab_all-in-one.modules.dist_utils.get_world_size", "home.repos.pwc.inspect_result.showlab_all-in-one.modules.dist_utils.get_rank"], ["", "def", "reduce_dict", "(", "input_dict", ",", "average", "=", "True", ")", ":", "\n", "    ", "\"\"\"\n    Reduce the values in the dictionary from all processes so that process with rank\n    0 has the reduced results.\n\n    Args:\n        input_dict (dict): inputs to be reduced. All the values must be scalar CUDA Tensor.\n        average (bool): whether to do average or sum\n\n    Returns:\n        a dict with the same keys as input_dict, after reduction.\n    \"\"\"", "\n", "world_size", "=", "get_world_size", "(", ")", "\n", "if", "world_size", "<", "2", ":", "\n", "        ", "return", "input_dict", "\n", "", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "names", "=", "[", "]", "\n", "values", "=", "[", "]", "\n", "# sort the keys so that they are consistent across processes", "\n", "for", "k", "in", "sorted", "(", "input_dict", ".", "keys", "(", ")", ")", ":", "\n", "            ", "names", ".", "append", "(", "k", ")", "\n", "values", ".", "append", "(", "input_dict", "[", "k", "]", ")", "\n", "", "values", "=", "torch", ".", "stack", "(", "values", ",", "dim", "=", "0", ")", "\n", "dist", ".", "reduce", "(", "values", ",", "dst", "=", "0", ")", "\n", "if", "dist", ".", "get_rank", "(", ")", "==", "0", "and", "average", ":", "\n", "# only main process gets accumulated, so only divide by", "\n", "# world_size in this case", "\n", "            ", "values", "/=", "world_size", "\n", "", "reduced_dict", "=", "{", "k", ":", "v", "for", "k", ",", "v", "in", "zip", "(", "names", ",", "values", ")", "}", "\n", "", "return", "reduced_dict", "\n", "", ""]], "home.repos.pwc.inspect_result.showlab_all-in-one.modules.retrieval_metrics.t2v_metrics": [[13, 118], ["numpy.sort", "numpy.array", "numpy.where", "retrieval_metrics.cols2metrics", "dists.reshape", "ipdb.set_trace", "ipdb.set_trace", "print", "numpy.zeros_like", "np.zeros_like.sum", "numpy.diag", "numpy.where", "numpy.array_equal", "numpy.ravel_multi_index", "range", "np.array.reshape", "numpy.unique", "np.zeros_like.sum", "range", "numpy.unique", "numpy.argwhere", "numpy.diff", "numpy.insert", "numpy.add.reduceat", "numpy.diff", "np.zeros_like.reshape().astype", "numpy.append", "print", "numpy.array_equal", "print", "numpy.nonzero", "numpy.mean", "np.zeros_like.reshape", "range"], "function", ["home.repos.pwc.inspect_result.showlab_all-in-one.modules.retrieval_metrics.cols2metrics"], ["def", "t2v_metrics", "(", "sims", ",", "query_masks", "=", "None", ")", ":", "\n", "    ", "\"\"\"Compute retrieval metrics from a similiarity matrix.\n\n    Args:\n        sims (th.Tensor): N x M matrix of similarities between embeddings, where\n             x_{i,j} = <text_embd[i], vid_embed[j]>\n        query_masks (th.Tensor): mask any missing queries from the dataset (two videos\n             in MSRVTT only have 19, rather than 20 captions)\n\n    Returns:\n        (dict[str:float]): retrieval metrics\n    \"\"\"", "\n", "assert", "sims", ".", "ndim", "==", "2", ",", "\"expected a matrix\"", "\n", "num_queries", ",", "num_vids", "=", "sims", ".", "shape", "\n", "dists", "=", "-", "sims", "\n", "sorted_dists", "=", "np", ".", "sort", "(", "dists", ",", "axis", "=", "1", ")", "\n", "\n", "# The indices are computed such that they slice out the ground truth distances", "\n", "# from the psuedo-rectangular dist matrix", "\n", "queries_per_video", "=", "num_queries", "//", "num_vids", "\n", "gt_idx", "=", "[", "[", "np", ".", "ravel_multi_index", "(", "[", "ii", ",", "jj", "]", ",", "(", "num_queries", ",", "num_vids", ")", ")", "\n", "for", "ii", "in", "range", "(", "jj", "*", "queries_per_video", ",", "(", "jj", "+", "1", ")", "*", "queries_per_video", ")", "]", "\n", "for", "jj", "in", "range", "(", "num_vids", ")", "]", "\n", "gt_idx", "=", "np", ".", "array", "(", "gt_idx", ")", "\n", "gt_dists", "=", "dists", ".", "reshape", "(", "-", "1", ")", "[", "gt_idx", ".", "reshape", "(", "-", "1", ")", "]", "\n", "gt_dists", "=", "gt_dists", "[", ":", ",", "np", ".", "newaxis", "]", "\n", "rows", ",", "cols", "=", "np", ".", "where", "(", "(", "sorted_dists", "-", "gt_dists", ")", "==", "0", ")", "# find column position of GT", "\n", "\n", "# --------------------------------", "\n", "# NOTE: Breaking ties", "\n", "# --------------------------------", "\n", "# We sometimes need to break ties (in general, these should occur extremely rarely,", "\n", "# but there are pathological cases when they can distort the scores, such as when", "\n", "# the similarity matrix is all zeros). Previous implementations (e.g. the t2i", "\n", "# evaluation function used", "\n", "# here: https://github.com/niluthpol/multimodal_vtt/blob/master/evaluation.py and", "\n", "# here: https://github.com/linxd5/VSE_Pytorch/blob/master/evaluation.py#L87) generally", "\n", "# break ties \"optimistically\".  However, if the similarity matrix is constant this", "\n", "# can evaluate to a perfect ranking. A principled option is to average over all", "\n", "# possible partial orderings implied by the ties. See # this paper for a discussion:", "\n", "#    McSherry, Frank, and Marc Najork,", "\n", "#    \"Computing information retrieval performance measures efficiently in the presence", "\n", "#    of tied scores.\" European conference on information retrieval. Springer, Berlin,", "\n", "#    Heidelberg, 2008.", "\n", "# http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.145.8892&rep=rep1&type=pdf", "\n", "\n", "break_ties", "=", "\"optimistically\"", "\n", "#break_ties = \"averaging\"", "\n", "\n", "if", "rows", ".", "size", ">", "num_queries", ":", "\n", "        ", "assert", "np", ".", "unique", "(", "rows", ")", ".", "size", "==", "num_queries", ",", "\"issue in metric evaluation\"", "\n", "if", "break_ties", "==", "\"optimistically\"", ":", "\n", "            ", "_", ",", "idx", "=", "np", ".", "unique", "(", "rows", ",", "return_index", "=", "True", ")", "\n", "cols", "=", "cols", "[", "idx", "]", "\n", "", "elif", "break_ties", "==", "\"averaging\"", ":", "\n", "# fast implementation, based on this code:", "\n", "# https://stackoverflow.com/a/49239335", "\n", "            ", "locs", "=", "np", ".", "argwhere", "(", "(", "sorted_dists", "-", "gt_dists", ")", "==", "0", ")", "\n", "\n", "# Find the split indices", "\n", "steps", "=", "np", ".", "diff", "(", "locs", "[", ":", ",", "0", "]", ")", "\n", "splits", "=", "np", ".", "nonzero", "(", "steps", ")", "[", "0", "]", "+", "1", "\n", "splits", "=", "np", ".", "insert", "(", "splits", ",", "0", ",", "0", ")", "\n", "\n", "# Compute the result columns", "\n", "summed_cols", "=", "np", ".", "add", ".", "reduceat", "(", "locs", "[", ":", ",", "1", "]", ",", "splits", ")", "\n", "counts", "=", "np", ".", "diff", "(", "np", ".", "append", "(", "splits", ",", "locs", ".", "shape", "[", "0", "]", ")", ")", "\n", "avg_cols", "=", "summed_cols", "/", "counts", "\n", "if", "False", ":", "\n", "                ", "print", "(", "\"Running slower code to verify rank averaging across ties\"", ")", "\n", "# slow, but more interpretable version, used for testing", "\n", "avg_cols_slow", "=", "[", "np", ".", "mean", "(", "cols", "[", "rows", "==", "idx", "]", ")", "for", "idx", "in", "range", "(", "num_queries", ")", "]", "\n", "assert", "np", ".", "array_equal", "(", "avg_cols", ",", "avg_cols_slow", ")", ",", "\"slow vs fast difference\"", "\n", "print", "(", "\"passed num check\"", ")", "\n", "", "cols", "=", "avg_cols", "\n", "\n", "", "", "msg", "=", "\"expected ranks to match queries ({} vs {}) \"", "\n", "if", "cols", ".", "size", "!=", "num_queries", ":", "\n", "        ", "import", "ipdb", ";", "\n", "ipdb", ".", "set_trace", "(", ")", "\n", "", "assert", "cols", ".", "size", "==", "num_queries", ",", "msg", "\n", "\n", "if", "False", ":", "\n", "# overload mask to check that we can recover the scores for single-query", "\n", "# retrieval", "\n", "        ", "print", "(", "\"DEBUGGING MODE\"", ")", "\n", "query_masks", "=", "np", ".", "zeros_like", "(", "query_masks", ")", "\n", "query_masks", "[", ":", ",", "0", "]", "=", "1", "# recover single query score", "\n", "\n", "", "if", "query_masks", "is", "not", "None", ":", "\n", "# remove invalid queries", "\n", "        ", "assert", "query_masks", ".", "size", "==", "num_queries", ",", "\"invalid query mask shape\"", "\n", "cols", "=", "cols", "[", "query_masks", ".", "reshape", "(", "-", "1", ")", ".", "astype", "(", "np", ".", "bool", ")", "]", "\n", "assert", "cols", ".", "size", "==", "query_masks", ".", "sum", "(", ")", ",", "\"masking was not applied correctly\"", "\n", "# update number of queries to account for those that were missing", "\n", "num_queries", "=", "query_masks", ".", "sum", "(", ")", "\n", "\n", "", "if", "False", ":", "\n", "# sanity check against old logic for square matrices", "\n", "        ", "gt_dists_old", "=", "np", ".", "diag", "(", "dists", ")", "\n", "gt_dists_old", "=", "gt_dists_old", "[", ":", ",", "np", ".", "newaxis", "]", "\n", "_", ",", "cols_old", "=", "np", ".", "where", "(", "(", "sorted_dists", "-", "gt_dists_old", ")", "==", "0", ")", "\n", "assert", "np", ".", "array_equal", "(", "cols_old", ",", "cols", ")", ",", "\"new metric doesn't match\"", "\n", "\n", "", "return", "cols2metrics", "(", "cols", ",", "num_queries", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.modules.retrieval_metrics.v2t_metrics": [[120, 210], ["range", "numpy.array", "retrieval_metrics.cols2metrics", "numpy.ones", "numpy.sort", "range", "np.array.append", "numpy.sort", "numpy.diag", "numpy.where", "numpy.array_equal", "matplotlib.use", "sys.path.insert", "plt.matshow", "zs_dispFig", "numpy.unique", "str", "numpy.where", "numpy.logical_not", "ranks.mean", "pathlib.Path.home", "query_masks.reshape"], "function", ["home.repos.pwc.inspect_result.showlab_all-in-one.modules.retrieval_metrics.cols2metrics"], ["", "def", "v2t_metrics", "(", "sims", ",", "query_masks", "=", "None", ")", ":", "\n", "    ", "\"\"\"Compute retrieval metrics from a similiarity matrix.\n\n    Args:\n        sims (th.Tensor): N x M matrix of similarities between embeddings, where\n             x_{i,j} = <text_embd[i], vid_embed[j]>\n        query_masks (th.Tensor): mask any missing captions from the dataset\n\n    Returns:\n        (dict[str:float]): retrieval metrics\n\n    NOTES: We find the closest \"GT caption\" in the style of VSE, which corresponds\n    to finding the rank of the closest relevant caption in embedding space:\n    github.com/ryankiros/visual-semantic-embedding/blob/master/evaluation.py#L52-L56\n    \"\"\"", "\n", "# switch axes of text and video", "\n", "sims", "=", "sims", ".", "T", "\n", "\n", "if", "False", ":", "\n", "# experiment with toy example", "\n", "        ", "sims", "=", "np", ".", "ones", "(", "(", "3", ",", "3", ")", ")", "\n", "sims", "[", "0", ",", "0", "]", "=", "2", "\n", "sims", "[", "1", ",", "1", ":", "2", "]", "=", "2", "\n", "sims", "[", "2", ",", ":", "]", "=", "2", "\n", "query_masks", "=", "None", "\n", "\n", "", "assert", "sims", ".", "ndim", "==", "2", ",", "\"expected a matrix\"", "\n", "num_queries", ",", "num_caps", "=", "sims", ".", "shape", "\n", "dists", "=", "-", "sims", "\n", "caps_per_video", "=", "num_caps", "//", "num_queries", "\n", "break_ties", "=", "\"averaging\"", "\n", "\n", "MISSING_VAL", "=", "1E8", "\n", "query_ranks", "=", "[", "]", "\n", "for", "ii", "in", "range", "(", "num_queries", ")", ":", "\n", "        ", "row_dists", "=", "dists", "[", "ii", ",", ":", "]", "\n", "if", "query_masks", "is", "not", "None", ":", "\n", "# Set missing queries to have a distance of infinity.  A missing query", "\n", "# refers to a query position `n` for a video that had less than `n`", "\n", "# captions (for example, a few MSRVTT videos only have 19 queries)", "\n", "            ", "row_dists", "[", "np", ".", "logical_not", "(", "query_masks", ".", "reshape", "(", "-", "1", ")", ")", "]", "=", "MISSING_VAL", "\n", "\n", "# NOTE: Using distance subtraction to perform the ranking is easier to make", "\n", "# deterministic than using argsort, which suffers from the issue of defining", "\n", "# \"stability\" for equal distances.  Example of distance subtraction code:", "\n", "# github.com/antoine77340/Mixture-of-Embedding-Experts/blob/master/train.py", "\n", "", "sorted_dists", "=", "np", ".", "sort", "(", "row_dists", ")", "\n", "\n", "min_rank", "=", "np", ".", "inf", "\n", "for", "jj", "in", "range", "(", "ii", "*", "caps_per_video", ",", "(", "ii", "+", "1", ")", "*", "caps_per_video", ")", ":", "\n", "            ", "if", "row_dists", "[", "jj", "]", "==", "MISSING_VAL", ":", "\n", "# skip rankings of missing captions", "\n", "                ", "continue", "\n", "", "ranks", "=", "np", ".", "where", "(", "(", "sorted_dists", "-", "row_dists", "[", "jj", "]", ")", "==", "0", ")", "[", "0", "]", "\n", "if", "break_ties", "==", "\"optimistically\"", ":", "\n", "                ", "rank", "=", "ranks", "[", "0", "]", "\n", "", "elif", "break_ties", "==", "\"averaging\"", ":", "\n", "# NOTE: If there is more than one caption per video, its possible for the", "\n", "# method to do \"worse than chance\" in the degenerate case when all", "\n", "# similarities are tied.  TODO(Samuel): Address this case.", "\n", "                ", "rank", "=", "ranks", ".", "mean", "(", ")", "\n", "", "if", "rank", "<", "min_rank", ":", "\n", "                ", "min_rank", "=", "rank", "\n", "", "", "query_ranks", ".", "append", "(", "min_rank", ")", "\n", "", "query_ranks", "=", "np", ".", "array", "(", "query_ranks", ")", "\n", "\n", "# sanity check against old version of code", "\n", "if", "False", ":", "\n", "        ", "sorted_dists", "=", "np", ".", "sort", "(", "dists", ",", "axis", "=", "1", ")", "\n", "gt_dists_old", "=", "np", ".", "diag", "(", "dists", ")", "\n", "gt_dists_old", "=", "gt_dists_old", "[", ":", ",", "np", ".", "newaxis", "]", "\n", "rows_old", ",", "cols_old", "=", "np", ".", "where", "(", "(", "sorted_dists", "-", "gt_dists_old", ")", "==", "0", ")", "\n", "if", "rows_old", ".", "size", ">", "num_queries", ":", "\n", "            ", "_", ",", "idx", "=", "np", ".", "unique", "(", "rows_old", ",", "return_index", "=", "True", ")", "\n", "cols_old", "=", "cols_old", "[", "idx", "]", "\n", "", "num_diffs", "=", "(", "1", "-", "(", "cols_old", "==", "query_ranks", ")", ")", ".", "sum", "(", ")", "\n", "msg", "=", "f\"new metric doesn't match in {num_diffs} places\"", "\n", "assert", "np", ".", "array_equal", "(", "cols_old", ",", "query_ranks", ")", ",", "msg", "\n", "\n", "# visualise the distance matrix", "\n", "import", "sys", "\n", "import", "matplotlib", "\n", "matplotlib", ".", "use", "(", "\"Agg\"", ")", "\n", "import", "matplotlib", ".", "pyplot", "as", "plt", "\n", "sys", ".", "path", ".", "insert", "(", "0", ",", "str", "(", "Path", ".", "home", "(", ")", "/", "\"coding/src/zsvision/python\"", ")", ")", "\n", "from", "zsvision", ".", "zs_iterm", "import", "zs_dispFig", "# NOQA", "\n", "plt", ".", "matshow", "(", "dists", ")", "\n", "zs_dispFig", "(", ")", "\n", "\n", "", "return", "cols2metrics", "(", "query_ranks", ",", "num_queries", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.modules.retrieval_metrics.retrieval_as_classification": [[212, 276], ["range", "numpy.array", "retrieval_metrics.cols2metrics", "numpy.sort", "np.array.extend", "matplotlib.use", "sys.path.insert", "plt.hist", "plt.grid", "zs_dispFig", "ipdb.set_trace", "ipdb.set_trace", "numpy.where", "label_ranks.append", "str", "len", "numpy.where", "enumerate", "ranks.mean", "ValueError", "pathlib.Path.home"], "function", ["home.repos.pwc.inspect_result.showlab_all-in-one.modules.retrieval_metrics.cols2metrics"], ["", "def", "retrieval_as_classification", "(", "sims", ",", "query_masks", "=", "None", ")", ":", "\n", "    ", "\"\"\"Compute classification metrics from a similiarity matrix.\n    \"\"\"", "\n", "assert", "sims", ".", "ndim", "==", "2", ",", "\"expected a matrix\"", "\n", "\n", "# switch axes of query-labels and video", "\n", "sims", "=", "sims", ".", "T", "\n", "query_masks", "=", "query_masks", ".", "T", "\n", "dists", "=", "-", "sims", "\n", "num_queries", ",", "num_labels", "=", "sims", ".", "shape", "\n", "break_ties", "=", "\"averaging\"", "\n", "\n", "query_ranks", "=", "[", "]", "\n", "for", "ii", "in", "range", "(", "num_queries", ")", ":", "\n", "        ", "row_dists", "=", "dists", "[", "ii", ",", ":", "]", "\n", "\n", "# NOTE: Using distance subtraction to perform the ranking is easier to make", "\n", "# deterministic than using argsort, which suffers from the issue of defining", "\n", "# \"stability\" for equal distances.  Example of distance subtraction code:", "\n", "# github.com/antoine77340/Mixture-of-Embedding-Experts/blob/master/train.py", "\n", "sorted_dists", "=", "np", ".", "sort", "(", "row_dists", ")", "\n", "\n", "# min_rank = np.inf", "\n", "label_ranks", "=", "[", "]", "\n", "for", "gt_label", "in", "np", ".", "where", "(", "query_masks", "[", "ii", ",", ":", "]", ")", "[", "0", "]", ":", "\n", "            ", "ranks", "=", "np", ".", "where", "(", "(", "sorted_dists", "-", "row_dists", "[", "gt_label", "]", ")", "==", "0", ")", "[", "0", "]", "\n", "if", "break_ties", "==", "\"optimistically\"", ":", "\n", "                ", "rank", "=", "ranks", "[", "0", "]", "\n", "", "elif", "break_ties", "==", "\"averaging\"", ":", "\n", "# NOTE: If there is more than one caption per video, its possible for the", "\n", "# method to do \"worse than chance\" in the degenerate case when all", "\n", "# similarities are tied.  TODO(Samuel): Address this case.", "\n", "                ", "rank", "=", "ranks", ".", "mean", "(", ")", "\n", "", "else", ":", "\n", "                ", "raise", "ValueError", "(", "f\"unknown tie-breaking method: {break_ties}\"", ")", "\n", "", "label_ranks", ".", "append", "(", "rank", ")", "\n", "# Avoid penalising for assigning higher similarity to other gt labels. This is", "\n", "# done by subtracting out the better ranked query labels.  Note that this step", "\n", "# introduces a slight skew in favour of videos with lots of labels.  We can", "\n", "# address this later with a normalisation step if needed.", "\n", "", "label_ranks", "=", "[", "x", "-", "idx", "for", "idx", ",", "x", "in", "enumerate", "(", "label_ranks", ")", "]", "\n", "\n", "# Include all labels in the final calculation", "\n", "query_ranks", ".", "extend", "(", "label_ranks", ")", "\n", "", "query_ranks", "=", "np", ".", "array", "(", "query_ranks", ")", "\n", "\n", "# sanity check against old version of code", "\n", "if", "False", ":", "\n", "# visualise the distance matrix", "\n", "        ", "import", "sys", "\n", "import", "matplotlib", "\n", "matplotlib", ".", "use", "(", "\"Agg\"", ")", "\n", "import", "matplotlib", ".", "pyplot", "as", "plt", "\n", "sys", ".", "path", ".", "insert", "(", "0", ",", "str", "(", "Path", ".", "home", "(", ")", "/", "\"coding/src/zsvision/python\"", ")", ")", "\n", "from", "zsvision", ".", "zs_iterm", "import", "zs_dispFig", "# NOQA", "\n", "# plt.matshow(dists)", "\n", "# zs_dispFig()", "\n", "plt", ".", "hist", "(", "query_ranks", ",", "bins", "=", "313", ",", "alpha", "=", "0.5", ")", "\n", "plt", ".", "grid", "(", ")", "\n", "zs_dispFig", "(", ")", "\n", "import", "ipdb", ";", "\n", "ipdb", ".", "set_trace", "(", ")", "\n", "\n", "", "return", "cols2metrics", "(", "query_ranks", ",", "num_queries", "=", "len", "(", "query_ranks", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.modules.retrieval_metrics.cols2metrics": [[278, 289], ["scipy.stats.mstats.gmean", "numpy.median", "numpy.mean", "float", "float", "float", "float", "numpy.sum", "numpy.sum", "numpy.sum", "numpy.sum"], "function", ["None"], ["", "def", "cols2metrics", "(", "cols", ",", "num_queries", ")", ":", "\n", "    ", "metrics", "=", "{", "}", "\n", "metrics", "[", "\"R1\"", "]", "=", "100", "*", "float", "(", "np", ".", "sum", "(", "cols", "==", "0", ")", ")", "/", "num_queries", "\n", "metrics", "[", "\"R5\"", "]", "=", "100", "*", "float", "(", "np", ".", "sum", "(", "cols", "<", "5", ")", ")", "/", "num_queries", "\n", "metrics", "[", "\"R10\"", "]", "=", "100", "*", "float", "(", "np", ".", "sum", "(", "cols", "<", "10", ")", ")", "/", "num_queries", "\n", "metrics", "[", "\"R50\"", "]", "=", "100", "*", "float", "(", "np", ".", "sum", "(", "cols", "<", "50", ")", ")", "/", "num_queries", "\n", "metrics", "[", "\"MedR\"", "]", "=", "np", ".", "median", "(", "cols", ")", "+", "1", "\n", "metrics", "[", "\"MeanR\"", "]", "=", "np", ".", "mean", "(", "cols", ")", "+", "1", "\n", "stats", "=", "[", "metrics", "[", "x", "]", "for", "x", "in", "(", "\"R1\"", ",", "\"R5\"", ",", "\"R10\"", ")", "]", "\n", "metrics", "[", "\"geometric_mean_R1-R5-R10\"", "]", "=", "scipy", ".", "stats", ".", "mstats", ".", "gmean", "(", "stats", ")", "\n", "return", "metrics", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.modules.retrieval_metrics.mean_average_precision": [[291, 295], ["APMeter", "APMeter.add", "APMeter.value().mean", "APMeter.value"], "function", ["None"], ["", "def", "mean_average_precision", "(", "sims", ",", "query_masks", "=", "None", ")", ":", "\n", "    ", "ap_meter", "=", "APMeter", "(", ")", "\n", "ap_meter", ".", "add", "(", "output", "=", "sims", ".", "T", ",", "target", "=", "query_masks", ".", "T", ")", "\n", "return", "{", "\"mAP\"", ":", "ap_meter", ".", "value", "(", ")", ".", "mean", "(", ")", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.modules.retrieval_metrics.acc": [[296, 303], ["torch.no_grad", "torch.argmax", "torch.sum().item", "len", "len", "torch.sum"], "function", ["None"], ["", "def", "acc", "(", "output", ",", "target", ")", ":", "\n", "    ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "pred", "=", "torch", ".", "argmax", "(", "output", ",", "dim", "=", "1", ")", "\n", "assert", "pred", ".", "shape", "[", "0", "]", "==", "len", "(", "target", ")", "\n", "correct", "=", "0", "\n", "correct", "+=", "torch", ".", "sum", "(", "pred", "==", "target", ")", ".", "item", "(", ")", "\n", "", "return", "correct", "/", "len", "(", "target", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.modules.retrieval_metrics.my_metric2": [[305, 313], ["torch.no_grad", "range", "len", "torch.topk", "len", "torch.sum().item", "torch.sum"], "function", ["None"], ["", "def", "my_metric2", "(", "output", ",", "target", ",", "k", "=", "3", ")", ":", "\n", "    ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "pred", "=", "torch", ".", "topk", "(", "output", ",", "k", ",", "dim", "=", "1", ")", "[", "1", "]", "\n", "assert", "pred", ".", "shape", "[", "0", "]", "==", "len", "(", "target", ")", "\n", "correct", "=", "0", "\n", "for", "i", "in", "range", "(", "k", ")", ":", "\n", "            ", "correct", "+=", "torch", ".", "sum", "(", "pred", "[", ":", ",", "i", "]", "==", "target", ")", ".", "item", "(", ")", "\n", "", "", "return", "correct", "/", "len", "(", "target", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.modules.retrieval_metrics.video_precision": [[315, 327], ["zip", "torch.eq", "torch.logical_and().any", "torch.logical_and"], "function", ["None"], ["", "def", "video_precision", "(", "output", ",", "target", ")", ":", "\n", "    ", "\"\"\" percentage of videos which have been aligned to a matching text pair\"\"\"", "\n", "assert", "output", ".", "shape", "[", "0", "]", "==", "target", ".", "shape", "[", "0", "]", "\n", "assert", "output", ".", "shape", "[", "2", "]", "==", "target", ".", "shape", "[", "2", "]", "==", "2", "\n", "\n", "correct", "=", "0", "\n", "for", "bout", ",", "btarg", "in", "zip", "(", "output", ",", "target", ")", ":", "\n", "        ", "for", "pair", "in", "bout", ":", "\n", "            ", "eq", "=", "torch", ".", "eq", "(", "pair", ",", "btarg", ")", "\n", "if", "torch", ".", "logical_and", "(", "eq", "[", ":", ",", "0", "]", ",", "eq", "[", ":", ",", "1", "]", ")", ".", "any", "(", ")", ":", "\n", "                ", "correct", "+=", "1", "\n", "", "", "", "return", "correct", "/", "(", "target", ".", "shape", "[", "0", "]", "*", "target", ".", "shape", "[", "1", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.modules.retrieval_metrics.video_precision_adj": [[346, 363], ["zip", "len", "target[].unique", "torch.eq", "torch.logical_and().any", "torch.logical_and"], "function", ["None"], ["", "def", "video_precision_adj", "(", "output", ",", "target", ")", ":", "\n", "    ", "\"\"\" adjusts the video precision metric by ignoring videos which have no aligning text.\"\"\"", "\n", "assert", "output", ".", "shape", "[", "0", "]", "==", "target", ".", "shape", "[", "0", "]", "\n", "assert", "output", ".", "shape", "[", "2", "]", "==", "target", ".", "shape", "[", "2", "]", "==", "2", "\n", "\n", "assert", "output", ".", "shape", "[", "0", "]", "==", "target", ".", "shape", "[", "0", "]", "\n", "assert", "output", ".", "shape", "[", "2", "]", "==", "target", ".", "shape", "[", "2", "]", "==", "2", "\n", "\n", "correct", "=", "0", "\n", "for", "bout", ",", "btarg", "in", "zip", "(", "output", ",", "target", ")", ":", "\n", "        ", "for", "pair", "in", "bout", ":", "\n", "            ", "eq", "=", "torch", ".", "eq", "(", "pair", ",", "btarg", ")", "\n", "if", "torch", ".", "logical_and", "(", "eq", "[", ":", ",", "0", "]", ",", "eq", "[", ":", ",", "1", "]", ")", ".", "any", "(", ")", ":", "\n", "                ", "correct", "+=", "1", "\n", "", "", "", "denom", "=", "len", "(", "target", "[", ":", ",", ":", ",", "0", "]", ".", "unique", "(", ")", ")", "\n", "\n", "return", "correct", "/", "denom", "\n", "", ""]], "home.repos.pwc.inspect_result.showlab_all-in-one.modules.heads.Pooler.__init__": [[9, 13], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Tanh", "torch.Tanh", "torch.Tanh"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.transforms.utils.UnNormalize.__init__"], ["    ", "def", "__init__", "(", "self", ",", "hidden_size", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dense", "=", "nn", ".", "Linear", "(", "hidden_size", ",", "hidden_size", ")", "\n", "self", ".", "activation", "=", "nn", ".", "Tanh", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.modules.heads.Pooler.forward": [[14, 20], ["heads.Pooler.dense", "heads.Pooler.activation"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "hidden_states", ")", ":", "\n", "# print(hidden_states.size()) # 64 x 237 x 768", "\n", "        ", "first_token_tensor", "=", "hidden_states", "[", ":", ",", "0", "]", "\n", "pooled_output", "=", "self", ".", "dense", "(", "first_token_tensor", ")", "\n", "pooled_output", "=", "self", ".", "activation", "(", "pooled_output", ")", "\n", "return", "pooled_output", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.modules.heads.vtmHead.__init__": [[23, 26], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.transforms.utils.UnNormalize.__init__"], ["    ", "def", "__init__", "(", "self", ",", "hidden_size", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "fc", "=", "nn", ".", "Linear", "(", "hidden_size", ",", "2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.modules.heads.vtmHead.forward": [[27, 30], ["heads.vtmHead.fc"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "fc", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.modules.heads.MLMHead.__init__": [[33, 40], ["torch.Module.__init__", "transformers.models.bert.modeling_bert.BertPredictionHeadTransform", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.transforms.utils.UnNormalize.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ",", "weight", "=", "None", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "transform", "=", "BertPredictionHeadTransform", "(", "config", ")", "\n", "self", ".", "decoder", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "config", ".", "vocab_size", ",", "bias", "=", "False", ")", "\n", "self", ".", "bias", "=", "nn", ".", "Parameter", "(", "torch", ".", "zeros", "(", "config", ".", "vocab_size", ")", ")", "\n", "if", "weight", "is", "not", "None", ":", "\n", "            ", "self", ".", "decoder", ".", "weight", "=", "weight", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.modules.heads.MLMHead.forward": [[41, 45], ["heads.MLMHead.transform", "heads.MLMHead.decoder"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "transform", "(", "x", ")", "\n", "x", "=", "self", ".", "decoder", "(", "x", ")", "+", "self", ".", "bias", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.modules.heads.MPPHead.__init__": [[48, 52], ["torch.Module.__init__", "transformers.models.bert.modeling_bert.BertPredictionHeadTransform", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.transforms.utils.UnNormalize.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "transform", "=", "BertPredictionHeadTransform", "(", "config", ")", "\n", "self", ".", "decoder", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "256", "*", "3", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.modules.heads.MPPHead.forward": [[53, 57], ["heads.MPPHead.transform", "heads.MPPHead.decoder"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "transform", "(", "x", ")", "\n", "x", "=", "self", ".", "decoder", "(", "x", ")", "\n", "return", "x", "\n", "", "", ""]], "home.repos.pwc.inspect_result.showlab_all-in-one.modules.base_vision_transformer.UnNormalize.__init__": [[97, 100], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "mean", ",", "std", ")", ":", "\n", "        ", "self", ".", "mean", "=", "mean", "\n", "self", ".", "std", "=", "std", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.modules.base_vision_transformer.UnNormalize.__call__": [[101, 105], ["zip", "t.mul_().add_", "t.mul_"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "tensor", ")", ":", "\n", "        ", "for", "t", ",", "m", ",", "s", "in", "zip", "(", "tensor", ",", "self", ".", "mean", ",", "self", ".", "std", ")", ":", "\n", "            ", "t", ".", "mul_", "(", "s", ")", ".", "add_", "(", "m", ")", "\n", "", "return", "tensor", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.modules.base_vision_transformer.Mlp.__init__": [[268, 283], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear", "act_layer", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Dropout", "torch.Dropout", "torch.Dropout"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.transforms.utils.UnNormalize.__init__"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "in_features", ",", "\n", "hidden_features", "=", "None", ",", "\n", "out_features", "=", "None", ",", "\n", "act_layer", "=", "nn", ".", "GELU", ",", "\n", "drop", "=", "0.0", ",", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "out_features", "=", "out_features", "or", "in_features", "\n", "hidden_features", "=", "hidden_features", "or", "in_features", "\n", "self", ".", "fc1", "=", "nn", ".", "Linear", "(", "in_features", ",", "hidden_features", ")", "\n", "self", ".", "act", "=", "act_layer", "(", ")", "\n", "self", ".", "fc2", "=", "nn", ".", "Linear", "(", "hidden_features", ",", "out_features", ")", "\n", "self", ".", "drop", "=", "nn", ".", "Dropout", "(", "drop", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.modules.base_vision_transformer.Mlp.forward": [[284, 291], ["base_vision_transformer.Mlp.fc1", "base_vision_transformer.Mlp.act", "base_vision_transformer.Mlp.drop", "base_vision_transformer.Mlp.fc2", "base_vision_transformer.Mlp.drop"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "fc1", "(", "x", ")", "\n", "x", "=", "self", ".", "act", "(", "x", ")", "\n", "x", "=", "self", ".", "drop", "(", "x", ")", "\n", "x", "=", "self", ".", "fc2", "(", "x", ")", "\n", "x", "=", "self", ".", "drop", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.modules.base_vision_transformer.VarAttention.__init__": [[300, 318], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Dropout", "base_vision_transformer.VarAttention.qkv.weight.data.fill_", "base_vision_transformer.VarAttention.qkv.bias.data.fill_", "base_vision_transformer.VarAttention.proj.weight.data.fill_", "base_vision_transformer.VarAttention.proj.bias.data.fill_"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.transforms.utils.UnNormalize.__init__"], ["    ", "def", "__init__", "(", "self", ",", "dim", ",", "num_heads", "=", "8", ",", "qkv_bias", "=", "False", ",", "qk_scale", "=", "None", ",", "attn_drop", "=", "0.", ",", "proj_drop", "=", "0.", ",", "\n", "initialize", "=", "'random'", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "num_heads", "=", "num_heads", "\n", "head_dim", "=", "dim", "//", "num_heads", "\n", "# NOTE scale factor was wrong in my original version, can set manually to be compat with prev weights", "\n", "self", ".", "scale", "=", "qk_scale", "or", "head_dim", "**", "-", "0.5", "\n", "self", ".", "qkv", "=", "nn", ".", "Linear", "(", "dim", ",", "dim", "*", "3", ",", "bias", "=", "qkv_bias", ")", "\n", "self", ".", "proj", "=", "nn", ".", "Linear", "(", "dim", ",", "dim", ")", "\n", "if", "initialize", "==", "'zeros'", ":", "\n", "            ", "self", ".", "qkv", ".", "weight", ".", "data", ".", "fill_", "(", "0", ")", "\n", "self", ".", "qkv", ".", "bias", ".", "data", ".", "fill_", "(", "0", ")", "\n", "# fill proj weight with 1 here to improve training dynamics. Otherwise temporal attention inputs", "\n", "# are multiplied by 0*0, which is hard for the model to move out of.", "\n", "self", ".", "proj", ".", "weight", ".", "data", ".", "fill_", "(", "1", ")", "\n", "self", ".", "proj", ".", "bias", ".", "data", ".", "fill_", "(", "0", ")", "\n", "", "self", ".", "attn_drop", "=", "nn", ".", "Dropout", "(", "attn_drop", ")", "\n", "self", ".", "proj_drop", "=", "nn", ".", "Dropout", "(", "proj_drop", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.modules.base_vision_transformer.VarAttention.forward": [[319, 357], ["base_vision_transformer.VarAttention.qkv().chunk", "map", "map", "base_vision_transformer.attn", "map", "map", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "base_vision_transformer.attn", "einops.rearrange", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "einops.rearrange", "base_vision_transformer.VarAttention.proj", "base_vision_transformer.VarAttention.proj_drop", "base_vision_transformer.VarAttention.qkv", "einops.rearrange", "einops.rearrange", "einops.repeat"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.modules.base_vision_transformer.attn", "home.repos.pwc.inspect_result.showlab_all-in-one.modules.base_vision_transformer.attn"], ["", "def", "forward", "(", "self", ",", "x", ",", "einops_from", ",", "einops_to", ",", "**", "einops_dims", ")", ":", "\n", "        ", "h", "=", "self", ".", "num_heads", "\n", "# project x to q, k, v vaalues", "\n", "q", ",", "k", ",", "v", "=", "self", ".", "qkv", "(", "x", ")", ".", "chunk", "(", "3", ",", "dim", "=", "-", "1", ")", "\n", "q", ",", "k", ",", "v", "=", "map", "(", "lambda", "t", ":", "rearrange", "(", "t", ",", "'b n (h d) -> (b h) n d'", ",", "h", "=", "h", ")", ",", "(", "q", ",", "k", ",", "v", ")", ")", "\n", "\n", "q", "*=", "self", ".", "scale", "\n", "\n", "# splice out CLS token at index 1", "\n", "(", "cls_q", ",", "q_", ")", ",", "(", "cls_k", ",", "k_", ")", ",", "(", "cls_v", ",", "v_", ")", "=", "map", "(", "lambda", "t", ":", "(", "t", "[", ":", ",", "0", ":", "1", "]", ",", "t", "[", ":", ",", "1", ":", "]", ")", ",", "(", "q", ",", "k", ",", "v", ")", ")", "\n", "\n", "# let CLS token attend to key / values of all patches across time and space", "\n", "cls_out", "=", "attn", "(", "cls_q", ",", "k", ",", "v", ")", "\n", "# rearrange across time or space", "\n", "q_", ",", "k_", ",", "v_", "=", "map", "(", "lambda", "t", ":", "rearrange", "(", "t", ",", "f'{einops_from} -> {einops_to}'", ",", "**", "einops_dims", ")", ",", "(", "q_", ",", "k_", ",", "v_", ")", ")", "\n", "\n", "# expand cls token keys and values across time or space and concat", "\n", "r", "=", "q_", ".", "shape", "[", "0", "]", "//", "cls_k", ".", "shape", "[", "0", "]", "\n", "cls_k", ",", "cls_v", "=", "map", "(", "lambda", "t", ":", "repeat", "(", "t", ",", "'b () d -> (b r) () d'", ",", "r", "=", "r", ")", ",", "(", "cls_k", ",", "cls_v", ")", ")", "\n", "\n", "k_", "=", "torch", ".", "cat", "(", "(", "cls_k", ",", "k_", ")", ",", "dim", "=", "1", ")", "\n", "v_", "=", "torch", ".", "cat", "(", "(", "cls_v", ",", "v_", ")", ",", "dim", "=", "1", ")", "\n", "\n", "# attention", "\n", "out", "=", "attn", "(", "q_", ",", "k_", ",", "v_", ")", "\n", "\n", "# merge back time or space", "\n", "out", "=", "rearrange", "(", "out", ",", "f'{einops_to} -> {einops_from}'", ",", "**", "einops_dims", ")", "\n", "\n", "# concat back the cls token", "\n", "out", "=", "torch", ".", "cat", "(", "(", "cls_out", ",", "out", ")", ",", "dim", "=", "1", ")", "\n", "\n", "# merge back the heads", "\n", "out", "=", "rearrange", "(", "out", ",", "'(b h) n d -> b n (h d)'", ",", "h", "=", "h", ")", "\n", "## to out", "\n", "x", "=", "self", ".", "proj", "(", "out", ")", "\n", "x", "=", "self", ".", "proj_drop", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.modules.base_vision_transformer.Attention.__init__": [[360, 379], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Dropout", "torch.Dropout", "torch.Dropout"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.transforms.utils.UnNormalize.__init__"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "dim", ",", "\n", "num_heads", "=", "8", ",", "\n", "qkv_bias", "=", "False", ",", "\n", "qk_scale", "=", "None", ",", "\n", "attn_drop", "=", "0.0", ",", "\n", "proj_drop", "=", "0.0", ",", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "num_heads", "=", "num_heads", "\n", "head_dim", "=", "dim", "//", "num_heads", "\n", "# NOTE scale factor was wrong in my original version, can set manually to be compat with prev weights", "\n", "self", ".", "scale", "=", "qk_scale", "or", "head_dim", "**", "-", "0.5", "\n", "\n", "self", ".", "qkv", "=", "nn", ".", "Linear", "(", "dim", ",", "dim", "*", "3", ",", "bias", "=", "qkv_bias", ")", "\n", "self", ".", "attn_drop", "=", "nn", ".", "Dropout", "(", "attn_drop", ")", "\n", "self", ".", "proj", "=", "nn", ".", "Linear", "(", "dim", ",", "dim", ")", "\n", "self", ".", "proj_drop", "=", "nn", ".", "Dropout", "(", "proj_drop", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.modules.base_vision_transformer.Attention.forward": [[380, 404], ["base_vision_transformer.Attention.qkv().reshape().permute", "attn.masked_fill.masked_fill.softmax", "base_vision_transformer.Attention.attn_drop", "base_vision_transformer.Attention.proj", "base_vision_transformer.Attention.proj_drop", "mask.bool.bool.bool", "attn.masked_fill.masked_fill.masked_fill", "base_vision_transformer.Attention.qkv().reshape", "k.transpose", "float", "base_vision_transformer.Attention.qkv"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "mask", "=", "None", ")", ":", "\n", "        ", "B", ",", "N", ",", "C", "=", "x", ".", "shape", "\n", "qkv", "=", "(", "\n", "self", ".", "qkv", "(", "x", ")", "\n", ".", "reshape", "(", "B", ",", "N", ",", "3", ",", "self", ".", "num_heads", ",", "C", "//", "self", ".", "num_heads", ")", "\n", ".", "permute", "(", "2", ",", "0", ",", "3", ",", "1", ",", "4", ")", "\n", ")", "\n", "q", ",", "k", ",", "v", "=", "(", "\n", "qkv", "[", "0", "]", ",", "\n", "qkv", "[", "1", "]", ",", "\n", "qkv", "[", "2", "]", ",", "\n", ")", "# make torchscript happy (cannot use tensor as tuple)", "\n", "\n", "attn", "=", "(", "q", "@", "k", ".", "transpose", "(", "-", "2", ",", "-", "1", ")", ")", "*", "self", ".", "scale", "\n", "if", "mask", "is", "not", "None", ":", "\n", "            ", "mask", "=", "mask", ".", "bool", "(", ")", "\n", "attn", "=", "attn", ".", "masked_fill", "(", "~", "mask", "[", ":", ",", "None", ",", "None", ",", ":", "]", ",", "float", "(", "\"-inf\"", ")", ")", "\n", "", "attn", "=", "attn", ".", "softmax", "(", "dim", "=", "-", "1", ")", "\n", "attn", "=", "self", ".", "attn_drop", "(", "attn", ")", "\n", "\n", "x", "=", "(", "attn", "@", "v", ")", ".", "transpose", "(", "1", ",", "2", ")", ".", "reshape", "(", "B", ",", "N", ",", "C", ")", "\n", "x", "=", "self", ".", "proj", "(", "x", ")", "\n", "x", "=", "self", ".", "proj_drop", "(", "x", ")", "\n", "return", "x", ",", "attn", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.modules.base_vision_transformer.Block.__init__": [[407, 439], ["torch.Module.__init__", "norm_layer", "base_vision_transformer.Attention", "norm_layer", "int", "base_vision_transformer.Mlp", "timm.models.layers.DropPath", "torch.Identity", "torch.Identity", "torch.Identity"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.transforms.utils.UnNormalize.__init__", "home.repos.pwc.inspect_result.showlab_all-in-one.transforms.randaug.Identity", "home.repos.pwc.inspect_result.showlab_all-in-one.transforms.randaug.Identity", "home.repos.pwc.inspect_result.showlab_all-in-one.transforms.randaug.Identity"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "dim", ",", "\n", "num_heads", ",", "\n", "mlp_ratio", "=", "4.0", ",", "\n", "qkv_bias", "=", "False", ",", "\n", "qk_scale", "=", "None", ",", "\n", "drop", "=", "0.0", ",", "\n", "attn_drop", "=", "0.0", ",", "\n", "drop_path", "=", "0.0", ",", "\n", "act_layer", "=", "nn", ".", "GELU", ",", "\n", "norm_layer", "=", "nn", ".", "LayerNorm", ",", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "norm1", "=", "norm_layer", "(", "dim", ")", "\n", "self", ".", "attn", "=", "Attention", "(", "\n", "dim", ",", "\n", "num_heads", "=", "num_heads", ",", "\n", "qkv_bias", "=", "qkv_bias", ",", "\n", "qk_scale", "=", "qk_scale", ",", "\n", "attn_drop", "=", "attn_drop", ",", "\n", "proj_drop", "=", "drop", ",", "\n", ")", "\n", "# NOTE: drop path for stochastic depth, we shall see if this is better than dropout here", "\n", "self", ".", "drop_path", "=", "DropPath", "(", "drop_path", ")", "if", "drop_path", ">", "0.0", "else", "nn", ".", "Identity", "(", ")", "\n", "self", ".", "norm2", "=", "norm_layer", "(", "dim", ")", "\n", "mlp_hidden_dim", "=", "int", "(", "dim", "*", "mlp_ratio", ")", "\n", "self", ".", "mlp", "=", "Mlp", "(", "\n", "in_features", "=", "dim", ",", "\n", "hidden_features", "=", "mlp_hidden_dim", ",", "\n", "act_layer", "=", "act_layer", ",", "\n", "drop", "=", "drop", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.modules.base_vision_transformer.Block.forward": [[441, 446], ["base_vision_transformer.Block.attn", "base_vision_transformer.Block.norm1", "base_vision_transformer.Block.drop_path", "base_vision_transformer.Block.drop_path", "base_vision_transformer.Block.mlp", "base_vision_transformer.Block.norm2"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.modules.base_vision_transformer.attn"], ["", "def", "forward", "(", "self", ",", "x", ",", "mask", "=", "None", ")", ":", "\n", "        ", "_x", ",", "attn", "=", "self", ".", "attn", "(", "self", ".", "norm1", "(", "x", ")", ",", "mask", "=", "mask", ")", "\n", "x", "=", "x", "+", "self", ".", "drop_path", "(", "_x", ")", "\n", "x", "=", "x", "+", "self", ".", "drop_path", "(", "self", ".", "mlp", "(", "self", ".", "norm2", "(", "x", ")", ")", ")", "\n", "return", "x", ",", "attn", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.modules.base_vision_transformer.PatchEmbed.__init__": [[451, 473], ["torch.Module.__init__", "timm.models.layers.to_2tuple", "timm.models.layers.to_2tuple", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.transforms.utils.UnNormalize.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "img_size", "=", "224", ",", "\n", "patch_size", "=", "16", ",", "\n", "in_chans", "=", "3", ",", "\n", "embed_dim", "=", "768", ",", "\n", "no_patch_embed_bias", "=", "False", ",", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "img_size", "=", "to_2tuple", "(", "img_size", ")", "\n", "patch_size", "=", "to_2tuple", "(", "patch_size", ")", "\n", "num_patches", "=", "(", "img_size", "[", "1", "]", "//", "patch_size", "[", "1", "]", ")", "*", "(", "img_size", "[", "0", "]", "//", "patch_size", "[", "0", "]", ")", "\n", "self", ".", "img_size", "=", "img_size", "\n", "self", ".", "patch_size", "=", "patch_size", "\n", "self", ".", "num_patches", "=", "num_patches", "\n", "\n", "self", ".", "proj", "=", "nn", ".", "Conv2d", "(", "\n", "in_chans", ",", "\n", "embed_dim", ",", "\n", "kernel_size", "=", "patch_size", ",", "\n", "stride", "=", "patch_size", ",", "\n", "bias", "=", "False", "if", "no_patch_embed_bias", "else", "True", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.modules.base_vision_transformer.PatchEmbed.forward": [[475, 481], ["base_vision_transformer.PatchEmbed.proj"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "# print(x.size())", "\n", "        ", "B", ",", "C", ",", "H", ",", "W", "=", "x", ".", "shape", "\n", "# FIXME look at relaxing size constraints", "\n", "x", "=", "self", ".", "proj", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.modules.base_vision_transformer.PatchEmbed3D.__init__": [[493, 505], ["torch.Module.__init__", "torch.Conv3d", "torch.Conv3d", "torch.Conv3d", "norm_layer"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.transforms.utils.UnNormalize.__init__"], ["def", "__init__", "(", "self", ",", "patch_size", "=", "(", "3", ",", "16", ",", "16", ")", ",", "in_chans", "=", "3", ",", "embed_dim", "=", "768", ",", "norm_layer", "=", "None", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "patch_size", "=", "patch_size", "\n", "\n", "self", ".", "in_chans", "=", "in_chans", "\n", "self", ".", "embed_dim", "=", "embed_dim", "\n", "\n", "self", ".", "proj", "=", "nn", ".", "Conv3d", "(", "in_chans", ",", "embed_dim", ",", "kernel_size", "=", "patch_size", ",", "stride", "=", "patch_size", ")", "\n", "if", "norm_layer", "is", "not", "None", ":", "\n", "            ", "self", ".", "norm", "=", "norm_layer", "(", "embed_dim", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "norm", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.modules.base_vision_transformer.PatchEmbed3D.forward": [[506, 525], ["x.transpose().view.transpose().view.size", "base_vision_transformer.PatchEmbed3D.proj", "torch.pad", "torch.pad", "torch.pad", "torch.pad", "torch.pad", "torch.pad", "torch.pad", "torch.pad", "torch.pad", "x.transpose().view.transpose().view.flatten().transpose", "base_vision_transformer.PatchEmbed3D.norm", "x.transpose().view.transpose().view.transpose().view", "x.transpose().view.transpose().view.size", "x.transpose().view.transpose().view.size", "x.transpose().view.transpose().view.size", "x.transpose().view.transpose().view.flatten", "x.transpose().view.transpose().view.transpose"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "\"\"\"Forward function.\"\"\"", "\n", "# padding", "\n", "_", ",", "_", ",", "D", ",", "H", ",", "W", "=", "x", ".", "size", "(", ")", "\n", "if", "W", "%", "self", ".", "patch_size", "[", "2", "]", "!=", "0", ":", "\n", "            ", "x", "=", "F", ".", "pad", "(", "x", ",", "(", "0", ",", "self", ".", "patch_size", "[", "2", "]", "-", "W", "%", "self", ".", "patch_size", "[", "2", "]", ")", ")", "\n", "", "if", "H", "%", "self", ".", "patch_size", "[", "1", "]", "!=", "0", ":", "\n", "            ", "x", "=", "F", ".", "pad", "(", "x", ",", "(", "0", ",", "0", ",", "0", ",", "self", ".", "patch_size", "[", "1", "]", "-", "H", "%", "self", ".", "patch_size", "[", "1", "]", ")", ")", "\n", "", "if", "D", "%", "self", ".", "patch_size", "[", "0", "]", "!=", "0", ":", "\n", "            ", "x", "=", "F", ".", "pad", "(", "x", ",", "(", "0", ",", "0", ",", "0", ",", "0", ",", "0", ",", "self", ".", "patch_size", "[", "0", "]", "-", "D", "%", "self", ".", "patch_size", "[", "0", "]", ")", ")", "\n", "\n", "", "x", "=", "self", ".", "proj", "(", "x", ")", "# B C D Wh Ww", "\n", "if", "self", ".", "norm", "is", "not", "None", ":", "\n", "            ", "D", ",", "Wh", ",", "Ww", "=", "x", ".", "size", "(", "2", ")", ",", "x", ".", "size", "(", "3", ")", ",", "x", ".", "size", "(", "4", ")", "\n", "x", "=", "x", ".", "flatten", "(", "2", ")", ".", "transpose", "(", "1", ",", "2", ")", "\n", "x", "=", "self", ".", "norm", "(", "x", ")", "\n", "x", "=", "x", ".", "transpose", "(", "1", ",", "2", ")", ".", "view", "(", "-", "1", ",", "self", ".", "embed_dim", ",", "D", ",", "Wh", ",", "Ww", ")", "\n", "\n", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.modules.base_vision_transformer.VisionTransformer.__init__": [[534, 632], ["torch.Module.__init__", "base_vision_transformer.PatchEmbed", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Dropout", "torch.Dropout", "torch.Dropout", "print", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "norm_layer", "timm.models.layers.trunc_normal_", "timm.models.layers.trunc_normal_", "base_vision_transformer.VisionTransformer.apply", "functools.partial", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "norm_layer", "x.item", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "base_vision_transformer.Block", "range"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.transforms.utils.UnNormalize.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "img_size", "=", "224", ",", "\n", "patch_size", "=", "16", ",", "\n", "in_chans", "=", "3", ",", "\n", "num_classes", "=", "1000", ",", "\n", "embed_dim", "=", "768", ",", "\n", "depth", "=", "12", ",", "\n", "num_heads", "=", "12", ",", "\n", "mlp_ratio", "=", "4.0", ",", "\n", "qkv_bias", "=", "True", ",", "\n", "qk_scale", "=", "None", ",", "\n", "representation_size", "=", "None", ",", "\n", "drop_rate", "=", "0.0", ",", "\n", "attn_drop_rate", "=", "0.0", ",", "\n", "drop_path_rate", "=", "0.1", ",", "\n", "norm_layer", "=", "None", ",", "\n", "add_norm_before_transformer", "=", "False", ",", "\n", "no_patch_embed_bias", "=", "False", ",", "\n", "config", "=", "None", ",", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            img_size (int, tuple): input image size\n            patch_size (int, tuple): patch size\n            in_chans (int): number of input channels\n            num_classes (int): number of classes for classification head\n            embed_dim (int): embedding dimension\n            depth (int): depth of transformer\n            num_heads (int): number of attention heads\n            mlp_ratio (int): ratio of mlp hidden dim to embedding dim\n            qkv_bias (bool): enable bias for qkv if True\n            qk_scale (float): override default qk scale of head_dim ** -0.5 if set\n            representation_size (Optional[int]): enable and set representation layer (pre-logits) to this value if set\n            drop_rate (float): dropout rate\n            attn_drop_rate (float): attention dropout rate\n            drop_path_rate (float): stochastic depth rate\n            hybrid_backbone (nn.Module): CNN backbone to use in-place of PatchEmbed module\n            norm_layer: (nn.Module): normalization layer\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "drop_rate", "=", "drop_rate", "if", "config", "is", "None", "else", "config", "[", "\"drop_rate\"", "]", "\n", "\n", "self", ".", "num_classes", "=", "num_classes", "\n", "self", ".", "num_features", "=", "(", "\n", "self", ".", "embed_dim", "\n", ")", "=", "embed_dim", "# num_features for consistency with other models", "\n", "norm_layer", "=", "norm_layer", "or", "partial", "(", "nn", ".", "LayerNorm", ",", "eps", "=", "1e-6", ")", "\n", "self", ".", "add_norm_before_transformer", "=", "add_norm_before_transformer", "\n", "\n", "self", ".", "patch_embed", "=", "PatchEmbed", "(", "\n", "img_size", "=", "img_size", ",", "\n", "patch_size", "=", "patch_size", ",", "\n", "in_chans", "=", "in_chans", ",", "\n", "embed_dim", "=", "embed_dim", ",", "\n", ")", "\n", "num_patches", "=", "self", ".", "patch_embed", ".", "num_patches", "\n", "\n", "self", ".", "patch_size", "=", "patch_size", "\n", "self", ".", "patch_dim", "=", "img_size", "//", "patch_size", "\n", "self", ".", "cls_token", "=", "nn", ".", "Parameter", "(", "torch", ".", "zeros", "(", "1", ",", "1", ",", "embed_dim", ")", ")", "\n", "self", ".", "pos_embed", "=", "nn", ".", "Parameter", "(", "torch", ".", "zeros", "(", "1", ",", "num_patches", "+", "1", ",", "embed_dim", ")", ")", "\n", "self", ".", "pos_drop", "=", "nn", ".", "Dropout", "(", "p", "=", "drop_rate", ")", "\n", "# print(img_size, patch_size, self.patch_dim)", "\n", "# # =================== temporal embedding ======================", "\n", "self", ".", "num_frames", "=", "config", "[", "'num_frames'", "]", "\n", "print", "(", "\"# frames for module is: {}\"", ".", "format", "(", "self", ".", "num_frames", ")", ")", "\n", "self", ".", "temporal_embed", "=", "nn", ".", "Parameter", "(", "torch", ".", "zeros", "(", "1", ",", "config", "[", "'num_frames'", "]", ",", "embed_dim", ")", ")", "\n", "# self.patches_per_frame = 49 # 7x7 for patch with 32 resolution", "\n", "self", ".", "patches_per_frame", "=", "self", ".", "patch_dim", "**", "2", "# 7x7 for patch with 32 resolution", "\n", "# # ===", "\n", "if", "add_norm_before_transformer", ":", "\n", "            ", "self", ".", "pre_norm", "=", "norm_layer", "(", "embed_dim", ")", "\n", "\n", "", "dpr", "=", "[", "\n", "x", ".", "item", "(", ")", "for", "x", "in", "torch", ".", "linspace", "(", "0", ",", "drop_path_rate", ",", "depth", ")", "\n", "]", "# stochastic depth decay rule", "\n", "self", ".", "blocks", "=", "nn", ".", "ModuleList", "(", "\n", "[", "\n", "Block", "(", "\n", "dim", "=", "embed_dim", ",", "\n", "num_heads", "=", "num_heads", ",", "\n", "mlp_ratio", "=", "mlp_ratio", ",", "\n", "qkv_bias", "=", "qkv_bias", ",", "\n", "qk_scale", "=", "qk_scale", ",", "\n", "drop", "=", "drop_rate", ",", "\n", "attn_drop", "=", "attn_drop_rate", ",", "\n", "drop_path", "=", "dpr", "[", "i", "]", ",", "\n", "norm_layer", "=", "norm_layer", ",", "\n", ")", "\n", "for", "i", "in", "range", "(", "depth", ")", "\n", "]", "\n", ")", "\n", "self", ".", "norm", "=", "norm_layer", "(", "embed_dim", ")", "\n", "\n", "trunc_normal_", "(", "self", ".", "pos_embed", ",", "std", "=", "0.02", ")", "\n", "trunc_normal_", "(", "self", ".", "cls_token", ",", "std", "=", "0.02", ")", "\n", "self", ".", "apply", "(", "self", ".", "_init_weights", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.modules.base_vision_transformer.VisionTransformer._init_weights": [[633, 641], ["isinstance", "timm.models.layers.trunc_normal_", "isinstance", "isinstance", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_"], "methods", ["None"], ["", "def", "_init_weights", "(", "self", ",", "m", ")", ":", "\n", "        ", "if", "isinstance", "(", "m", ",", "nn", ".", "Linear", ")", ":", "\n", "            ", "trunc_normal_", "(", "m", ".", "weight", ",", "std", "=", "0.02", ")", "\n", "if", "isinstance", "(", "m", ",", "nn", ".", "Linear", ")", "and", "m", ".", "bias", "is", "not", "None", ":", "\n", "                ", "nn", ".", "init", ".", "constant_", "(", "m", ".", "bias", ",", "0", ")", "\n", "", "", "elif", "isinstance", "(", "m", ",", "nn", ".", "LayerNorm", ")", ":", "\n", "            ", "nn", ".", "init", ".", "constant_", "(", "m", ".", "bias", ",", "0", ")", "\n", "nn", ".", "init", ".", "constant_", "(", "m", ".", "weight", ",", "1.0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.modules.base_vision_transformer.VisionTransformer.no_weight_decay": [[642, 645], ["None"], "methods", ["None"], ["", "", "@", "torch", ".", "jit", ".", "ignore", "\n", "def", "no_weight_decay", "(", "self", ")", ":", "\n", "        ", "return", "{", "\"pos_embed\"", ",", "\"cls_token\"", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.modules.base_vision_transformer.VisionTransformer.mask_tokens": [[646, 679], ["torch.full", "torch.full", "torch.full", "torch.full", "torch.full", "torch.full", "torch.full", "torch.full", "torch.full", "torch.bernoulli().bool", "torch.bernoulli().bool", "torch.bernoulli().bool", "torch.bernoulli().bool", "torch.bernoulli().bool", "torch.bernoulli().bool", "torch.bernoulli().bool", "torch.bernoulli().bool", "torch.bernoulli().bool", "base_vision_transformer.VisionTransformer.mask_token.to", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.conv2d", "torch.conv2d", "torch.conv2d", "torch.bernoulli().bool", "torch.bernoulli().bool", "torch.bernoulli().bool", "torch.bernoulli().bool", "torch.bernoulli().bool", "torch.bernoulli().bool", "torch.bernoulli().bool", "torch.bernoulli().bool", "torch.bernoulli().bool", "torch.bernoulli", "torch.bernoulli", "torch.bernoulli", "torch.bernoulli", "torch.bernoulli", "torch.bernoulli", "torch.bernoulli", "torch.bernoulli", "torch.bernoulli", "torch.bernoulli", "torch.bernoulli", "torch.bernoulli", "torch.bernoulli", "torch.bernoulli", "torch.bernoulli", "torch.bernoulli", "torch.bernoulli", "torch.bernoulli", "torch.ones().to", "torch.ones().to", "torch.ones().to", "torch.ones().to", "torch.ones().to", "torch.ones().to", "torch.ones().to", "torch.ones().to", "torch.ones().to", "torch.full", "torch.full", "torch.full", "torch.full", "torch.full", "torch.full", "torch.full", "torch.full", "torch.full", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones"], "methods", ["None"], ["", "def", "mask_tokens", "(", "self", ",", "orig_image", ",", "feats", ")", ":", "\n", "        ", "\"\"\"\n        Prepare masked tokens inputs/labels for masked patch prediction: 80% MASK, 10% random, 10% original.\n        \"\"\"", "\n", "img_unnorm", "=", "orig_image", "*", "0.5", "+", "0.5", "\n", "_", ",", "_", ",", "ph", ",", "pw", "=", "self", ".", "patch_embed", ".", "proj", ".", "weight", ".", "shape", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "img_unnorm_patch", "=", "F", ".", "conv2d", "(", "\n", "img_unnorm", ",", "\n", "weight", "=", "torch", ".", "ones", "(", "3", ",", "1", ",", "ph", ",", "pw", ")", ".", "to", "(", "img_unnorm", ")", "/", "(", "ph", "*", "pw", ")", ",", "\n", "bias", "=", "None", ",", "\n", "stride", "=", "(", "ph", ",", "pw", ")", ",", "\n", "padding", "=", "0", ",", "\n", "groups", "=", "3", ",", "\n", ")", "\n", "", "labels", "=", "(", "\n", "(", "(", "img_unnorm_patch", "*", "255", ")", ".", "long", "(", ")", ".", "flatten", "(", "start_dim", "=", "2", ",", "end_dim", "=", "3", ")", ")", "\n", ".", "permute", "(", "0", ",", "2", ",", "1", ")", "\n", ".", "contiguous", "(", ")", "\n", ")", "\n", "\n", "# We sample a few tokens in each sequence for MLM training (with probability `self.mlm_probability`)", "\n", "probability_matrix", "=", "torch", ".", "full", "(", "labels", ".", "shape", "[", ":", "-", "1", "]", ",", "0.15", ")", "\n", "masked_indices", "=", "torch", ".", "bernoulli", "(", "probability_matrix", ")", ".", "bool", "(", ")", "\n", "labels", "[", "~", "masked_indices", "]", "=", "-", "100", "# We only compute loss on masked tokens", "\n", "\n", "# 80% of the time, we replace masked input tokens with tokenizer.mask_token ([MASK])", "\n", "indices_replaced", "=", "(", "\n", "torch", ".", "bernoulli", "(", "torch", ".", "full", "(", "labels", ".", "shape", "[", ":", "-", "1", "]", ",", "0.8", ")", ")", ".", "bool", "(", ")", "&", "masked_indices", "\n", ")", "\n", "feats", "[", "indices_replaced", "]", "=", "self", ".", "mask_token", ".", "to", "(", "feats", ")", "\n", "\n", "return", "feats", ",", "labels", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.modules.base_vision_transformer.VisionTransformer.visual_embed": [[680, 828], ["base_vision_transformer.VisionTransformer.patch_embed", "torch.interpolate().long", "torch.interpolate().long", "torch.interpolate().long", "base_vision_transformer.VisionTransformer.pos_embed[].transpose().view", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat.flatten().transpose", "torch.cat.flatten().transpose", "torch.cat.flatten().transpose", "base_vision_transformer.VisionTransformer.flatten().transpose", "[].expand().flatten", "torch.cat.flatten", "torch.cat.flatten", "torch.cat.flatten", "torch.cat.nonzero", "torch.cat.nonzero", "torch.cat.nonzero", "valid_idx[].unique", "list", "enumerate", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "x[].view", "x_mask[].view", "patch_index[].view", "pos_embed[].view", "base_vision_transformer.VisionTransformer.temporal_embed.repeat_interleave", "torch.cat.view", "torch.cat.view", "torch.cat.view", "torch.cat.view", "torch.cat.view", "torch.cat.view", "base_vision_transformer.VisionTransformer.cls_token.expand", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "base_vision_transformer.VisionTransformer.pos_drop", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "len", "_x.contiguous().view.contiguous().view.contiguous().view", "x_mask[].sum", "x_mask[].sum", "base_vision_transformer.VisionTransformer.mask_tokens", "eff.max", "min", "v.size", "v.size", "zip", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.cat.size", "label[].view", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "base_vision_transformer.VisionTransformer.pre_norm", "_x.contiguous().view.contiguous().view.size", "_x.contiguous().view.contiguous().view.size", "_x.contiguous().view.contiguous().view.size", "_x.contiguous().view.contiguous().view.size", "torch.interpolate", "torch.interpolate", "torch.interpolate", "base_vision_transformer.VisionTransformer.pos_embed[].transpose", "torch.pad", "torch.pad", "torch.pad", "torch.cat.flatten", "torch.cat.flatten", "torch.cat.flatten", "base_vision_transformer.VisionTransformer.flatten", "[].expand", "isinstance", "eff.max", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.cat.append", "torch.cat.append", "torch.cat.append", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.cat.append", "torch.cat.append", "torch.cat.append", "torch.cat.size", "torch.cat.size", "torch.cat.size", "[].expand", "torch.ones().to", "torch.ones().to", "torch.ones().to", "torch.ones().to", "torch.ones().to", "torch.ones().to", "torch.ones().to", "torch.ones().to", "torch.ones().to", "_x.contiguous().view.contiguous().view.contiguous", "torch.interpolate", "torch.interpolate", "torch.interpolate", "zip", "torch.ones().float", "torch.ones().float", "torch.ones().float", "torch.ones().float", "torch.ones().float", "torch.ones().float", "torch.ones().float", "torch.ones().float", "torch.ones().float", "torch.ones().float", "torch.ones().float", "torch.ones().float", "torch.ones().float", "torch.ones().float", "torch.ones().float", "torch.ones().float", "torch.ones().float", "torch.ones().float", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.full().to", "torch.full().to", "torch.full().to", "torch.full().to", "torch.full().to", "torch.full().to", "torch.full().to", "torch.full().to", "torch.full().to", "_x.contiguous().view.contiguous().view.sum", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.full", "torch.full", "torch.full", "torch.full", "torch.full", "torch.full", "torch.full", "torch.full", "torch.full", "torch.meshgrid", "torch.meshgrid", "torch.meshgrid", "torch.meshgrid", "torch.meshgrid", "torch.meshgrid", "torch.meshgrid", "torch.meshgrid", "torch.meshgrid", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.modules.base_vision_transformer.VisionTransformer.mask_tokens"], ["", "def", "visual_embed", "(", "self", ",", "_x", ",", "max_image_len", "=", "200", ",", "mask_it", "=", "False", ",", "mode", "=", "'video'", ")", ":", "\n", "# for special case of irtr_recall", "\n", "        ", "if", "len", "(", "_x", ".", "size", "(", ")", ")", "==", "5", ":", "\n", "            ", "_x", "=", "_x", ".", "contiguous", "(", ")", ".", "view", "(", "-", "1", ",", "_x", ".", "size", "(", "2", ")", ",", "_x", ".", "size", "(", "3", ")", ",", "_x", ".", "size", "(", "4", ")", ")", "\n", "", "_", ",", "_", ",", "ph", ",", "pw", "=", "self", ".", "patch_embed", ".", "proj", ".", "weight", ".", "shape", "\n", "# print(_x.size())", "\n", "# if len(_x.size()) == 4:", "\n", "#     _x = _x.unsqueeze(1)", "\n", "# # print(_x.size()) # 64x4x3x224x224", "\n", "# # _b = _x.size(0)", "\n", "# # print(_x)", "\n", "# _x = _x.contiguous().view(-1, _x.size(2), _x.size(3), _x.size(4))", "\n", "# print(_x.size())", "\n", "x", "=", "self", ".", "patch_embed", "(", "_x", ")", "\n", "# # average along time dimension", "\n", "# x = x.view(_b, -1, x.size(1), x.size(2), x.size(3))", "\n", "# x = torch.mean(x, dim=1)", "\n", "# x = x.view(_b, x.size(1), x.size(2), -1)", "\n", "# print(x.size())", "\n", "x_mask", "=", "(", "_x", ".", "sum", "(", "dim", "=", "1", ")", "!=", "0", ")", ".", "float", "(", ")", "[", ":", ",", "None", ",", ":", ",", ":", "]", "# only use first image", "\n", "# print(x_mask.size())", "\n", "x_mask", "=", "F", ".", "interpolate", "(", "x_mask", ",", "size", "=", "(", "x", ".", "shape", "[", "2", "]", ",", "x", ".", "shape", "[", "3", "]", ")", ")", ".", "long", "(", ")", "\n", "x_h", "=", "x_mask", "[", ":", ",", "0", "]", ".", "sum", "(", "dim", "=", "1", ")", "[", ":", ",", "0", "]", "\n", "x_w", "=", "x_mask", "[", ":", ",", "0", "]", ".", "sum", "(", "dim", "=", "2", ")", "[", ":", ",", "0", "]", "\n", "\n", "B", ",", "C", ",", "H", ",", "W", "=", "x", ".", "shape", "\n", "B", "=", "B", "\n", "spatial_pos", "=", "(", "\n", "self", ".", "pos_embed", "[", ":", ",", "1", ":", ",", ":", "]", "\n", ".", "transpose", "(", "1", ",", "2", ")", "\n", ".", "view", "(", "1", ",", "C", ",", "self", ".", "patch_dim", ",", "self", ".", "patch_dim", ")", "\n", ")", "\n", "pos_embed", "=", "torch", ".", "cat", "(", "\n", "[", "\n", "F", ".", "pad", "(", "\n", "F", ".", "interpolate", "(", "\n", "spatial_pos", ",", "size", "=", "(", "h", ",", "w", ")", ",", "mode", "=", "\"bilinear\"", ",", "align_corners", "=", "True", ",", "\n", ")", ",", "\n", "(", "0", ",", "W", "-", "w", ",", "0", ",", "H", "-", "h", ")", ",", "\n", ")", "\n", "for", "h", ",", "w", "in", "zip", "(", "x_h", ",", "x_w", ")", "\n", "]", ",", "\n", "dim", "=", "0", ",", "\n", ")", "\n", "\n", "pos_embed", "=", "pos_embed", ".", "flatten", "(", "2", ")", ".", "transpose", "(", "1", ",", "2", ")", "\n", "x", "=", "x", ".", "flatten", "(", "2", ")", ".", "transpose", "(", "1", ",", "2", ")", "\n", "patch_index", "=", "(", "\n", "torch", ".", "stack", "(", "\n", "torch", ".", "meshgrid", "(", "\n", "torch", ".", "arange", "(", "x_mask", ".", "shape", "[", "-", "2", "]", ")", ",", "torch", ".", "arange", "(", "x_mask", ".", "shape", "[", "-", "1", "]", ")", "\n", ")", ",", "\n", "dim", "=", "-", "1", ",", "\n", ")", "[", "None", ",", "None", ",", ":", ",", ":", ",", ":", "]", "\n", ".", "expand", "(", "x_mask", ".", "shape", "[", "0", "]", ",", "x_mask", ".", "shape", "[", "1", "]", ",", "-", "1", ",", "-", "1", ",", "-", "1", ")", "\n", ".", "flatten", "(", "1", ",", "3", ")", "\n", ")", "\n", "x_mask", "=", "x_mask", ".", "flatten", "(", "1", ")", "\n", "\n", "if", "mask_it", ":", "\n", "            ", "x", ",", "label", "=", "self", ".", "mask_tokens", "(", "_x", ",", "x", ")", "\n", "\n", "", "if", "(", "\n", "max_image_len", "<", "0", "\n", "or", "max_image_len", "is", "None", "\n", "or", "not", "isinstance", "(", "max_image_len", ",", "int", ")", "\n", ")", ":", "\n", "# suppose aug is 800 x 1333, then, maximum effective res is 800 x 1333 (if one side gets bigger, the other will be constrained and be shrinked)", "\n", "# (800 // self.patch_size) * (1333 // self.patch_size) is the maximum number of patches that single image can get.", "\n", "# if self.patch_size = 32, 25 * 41 = 1025", "\n", "# if res is 384 x 640, 12 * 20 = 240", "\n", "            ", "eff", "=", "x_h", "*", "x_w", "\n", "max_image_len", "=", "eff", ".", "max", "(", ")", "\n", "", "else", ":", "\n", "            ", "eff", "=", "x_h", "*", "x_w", "\n", "max_image_len", "=", "min", "(", "eff", ".", "max", "(", ")", ",", "max_image_len", ")", "\n", "\n", "", "valid_idx", "=", "x_mask", ".", "nonzero", "(", "as_tuple", "=", "False", ")", "\n", "non_valid_idx", "=", "(", "1", "-", "x_mask", ")", ".", "nonzero", "(", "as_tuple", "=", "False", ")", "\n", "unique_rows", "=", "valid_idx", "[", ":", ",", "0", "]", ".", "unique", "(", ")", "\n", "valid_row_idx", "=", "[", "valid_idx", "[", "valid_idx", "[", ":", ",", "0", "]", "==", "u", "]", "for", "u", "in", "unique_rows", "]", "\n", "non_valid_row_idx", "=", "[", "\n", "non_valid_idx", "[", "non_valid_idx", "[", ":", ",", "0", "]", "==", "u", "]", "for", "u", "in", "unique_rows", "\n", "]", "\n", "\n", "valid_nums", "=", "[", "v", ".", "size", "(", "0", ")", "for", "v", "in", "valid_row_idx", "]", "\n", "non_valid_nums", "=", "[", "v", ".", "size", "(", "0", ")", "for", "v", "in", "non_valid_row_idx", "]", "\n", "pad_nums", "=", "[", "max_image_len", "-", "v", "for", "v", "in", "valid_nums", "]", "\n", "\n", "select", "=", "list", "(", ")", "\n", "for", "i", ",", "(", "v", ",", "nv", ",", "p", ")", "in", "enumerate", "(", "zip", "(", "valid_nums", ",", "non_valid_nums", ",", "pad_nums", ")", ")", ":", "\n", "            ", "if", "p", "<=", "0", ":", "\n", "                ", "valid_choice", "=", "torch", ".", "multinomial", "(", "torch", ".", "ones", "(", "v", ")", ".", "float", "(", ")", ",", "max_image_len", ")", "\n", "select", ".", "append", "(", "valid_row_idx", "[", "i", "]", "[", "valid_choice", "]", ")", "\n", "", "else", ":", "\n", "                ", "pad_choice", "=", "torch", ".", "multinomial", "(", "\n", "torch", ".", "ones", "(", "nv", ")", ".", "float", "(", ")", ",", "p", ",", "replacement", "=", "True", "\n", ")", "\n", "select", ".", "append", "(", "\n", "torch", ".", "cat", "(", "\n", "[", "valid_row_idx", "[", "i", "]", ",", "non_valid_row_idx", "[", "i", "]", "[", "pad_choice", "]", "]", ",", "dim", "=", "0", ",", "\n", ")", "\n", ")", "\n", "\n", "", "", "select", "=", "torch", ".", "cat", "(", "select", ",", "dim", "=", "0", ")", "\n", "x", "=", "x", "[", "select", "[", ":", ",", "0", "]", ",", "select", "[", ":", ",", "1", "]", "]", ".", "view", "(", "B", ",", "-", "1", ",", "C", ")", "\n", "x_mask", "=", "x_mask", "[", "select", "[", ":", ",", "0", "]", ",", "select", "[", ":", ",", "1", "]", "]", ".", "view", "(", "B", ",", "-", "1", ")", "\n", "patch_index", "=", "patch_index", "[", "select", "[", ":", ",", "0", "]", ",", "select", "[", ":", ",", "1", "]", "]", ".", "view", "(", "B", ",", "-", "1", ",", "2", ")", "\n", "pos_embed", "=", "pos_embed", "[", "select", "[", ":", ",", "0", "]", ",", "select", "[", ":", ",", "1", "]", "]", ".", "view", "(", "B", ",", "-", "1", ",", "C", ")", "# 48, 196, 768", "\n", "# # === alex: add temporal pos embed here", "\n", "# temporal embed needs to be repeated within each frame (this does [1,2,3] --> [1,1,1,2,2,2,3,3,3]...)", "\n", "if", "mode", "==", "'video'", ":", "\n", "            ", "self", ".", "patches_per_frame", "=", "x", ".", "size", "(", "1", ")", "\n", "tile_temporal_embed", "=", "self", ".", "temporal_embed", ".", "repeat_interleave", "(", "self", ".", "patches_per_frame", ",", "1", ")", "\n", "# tile_temporal_embed = tile_temporal_embed.view(-1, self.num_frames, tile_temporal_embed.size(-1))", "\n", "# print(pos_embed.size(), tile_temporal_embed.size())", "\n", "pos_embed", "=", "pos_embed", ".", "view", "(", "pos_embed", ".", "size", "(", "0", ")", "//", "self", ".", "num_frames", ",", "-", "1", ",", "pos_embed", ".", "size", "(", "-", "1", ")", ")", "\n", "pos_embed", "=", "pos_embed", "+", "tile_temporal_embed", "\n", "pos_embed", "=", "pos_embed", ".", "view", "(", "-", "1", ",", "self", ".", "patches_per_frame", ",", "pos_embed", ".", "size", "(", "-", "1", ")", ")", "\n", "# =======", "\n", "", "if", "mask_it", ":", "\n", "            ", "label", "=", "label", "[", "select", "[", ":", ",", "0", "]", ",", "select", "[", ":", ",", "1", "]", "]", ".", "view", "(", "B", ",", "-", "1", ",", "3", ")", "\n", "\n", "label", "[", "x_mask", "==", "0", "]", "=", "-", "100", "\n", "label", "=", "torch", ".", "cat", "(", "\n", "[", "torch", ".", "full", "(", "(", "label", ".", "shape", "[", "0", "]", ",", "1", ",", "3", ")", ",", "-", "100", ")", ".", "to", "(", "label", ")", ",", "label", ",", "]", ",", "dim", "=", "1", ",", "\n", ")", "\n", "\n", "", "cls_tokens", "=", "self", ".", "cls_token", ".", "expand", "(", "B", ",", "-", "1", ",", "-", "1", ")", "\n", "# print(cls_tokens.size(), x.size())", "\n", "x", "=", "torch", ".", "cat", "(", "(", "cls_tokens", ",", "x", ")", ",", "dim", "=", "1", ")", "\n", "pos_embed", "=", "torch", ".", "cat", "(", "\n", "(", "self", ".", "pos_embed", "[", ":", ",", "0", ",", ":", "]", "[", ":", ",", "None", ",", ":", "]", ".", "expand", "(", "B", ",", "-", "1", ",", "-", "1", ")", ",", "pos_embed", ")", ",", "dim", "=", "1", "\n", ")", "\n", "# print(x.size(), pos_embed.size())", "\n", "x", "=", "x", "+", "pos_embed", "\n", "x", "=", "self", ".", "pos_drop", "(", "x", ")", "\n", "\n", "if", "self", ".", "add_norm_before_transformer", ":", "\n", "            ", "x", "=", "self", ".", "pre_norm", "(", "x", ")", "\n", "\n", "", "x_mask", "=", "torch", ".", "cat", "(", "[", "torch", ".", "ones", "(", "x_mask", ".", "shape", "[", "0", "]", ",", "1", ")", ".", "to", "(", "x_mask", ")", ",", "x_mask", "]", ",", "dim", "=", "1", ")", "\n", "# print(x_mask)", "\n", "# print(x_mask.size())", "\n", "# print(x.size())", "\n", "\n", "if", "mask_it", ":", "\n", "            ", "return", "x", ",", "x_mask", ",", "(", "patch_index", ",", "(", "H", ",", "W", ")", ")", ",", "label", "\n", "", "else", ":", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.modules.base_vision_transformer.VisionTransformer.forward_features": [[829, 839], ["base_vision_transformer.VisionTransformer.visual_embed", "base_vision_transformer.VisionTransformer.norm", "blk"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.modules.base_vision_transformer.DistilledVisionTransformer.visual_embed"], ["            ", "return", "x", ",", "x_mask", ",", "(", "patch_index", ",", "(", "H", ",", "W", ")", ")", ",", "None", "\n", "\n", "", "", "def", "forward_features", "(", "self", ",", "_x", ",", "max_image_len", "=", "144", ",", "mask_it", "=", "False", ")", ":", "\n", "        ", "x", ",", "x_mask", ",", "patch_index", ",", "label", "=", "self", ".", "visual_embed", "(", "\n", "_x", ",", "max_image_len", "=", "max_image_len", ",", "mask_it", "=", "mask_it", "\n", ")", "\n", "\n", "for", "blk", "in", "self", ".", "blocks", ":", "\n", "            ", "x", ",", "_", "=", "blk", "(", "x", ",", "mask", "=", "x_mask", ")", "\n", "\n", "", "x", "=", "self", ".", "norm", "(", "x", ")", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.modules.base_vision_transformer.VisionTransformer.forward": [[840, 845], ["base_vision_transformer.VisionTransformer.forward_features", "base_vision_transformer.VisionTransformer.head"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.modules.base_vision_transformer.DistilledVisionTransformer.forward_features"], ["return", "x", ",", "x_mask", ",", "label", "\n", "\n", "", "def", "forward", "(", "self", ",", "x", ",", "max_image_len", "=", "-", "1", ")", ":", "\n", "        ", "x", ",", "_", ",", "_", "=", "self", ".", "forward_features", "(", "x", ",", "max_image_len", "=", "max_image_len", ")", "\n", "x", "=", "x", "[", ":", ",", "0", "]", "\n", "x", "=", "self", ".", "head", "(", "x", ")", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.modules.base_vision_transformer.DistilledVisionTransformer.__init__": [[856, 864], ["base_vision_transformer.VisionTransformer.__init__", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "timm.models.layers.trunc_normal_", "timm.models.layers.trunc_normal_", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.transforms.utils.UnNormalize.__init__"], ["\n", "\n", "def", "__init__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "self", ".", "dist_token", "=", "nn", ".", "Parameter", "(", "torch", ".", "zeros", "(", "1", ",", "1", ",", "self", ".", "embed_dim", ")", ")", "\n", "num_patches", "=", "self", ".", "patch_embed", ".", "num_patches", "\n", "self", ".", "pos_embed", "=", "nn", ".", "Parameter", "(", "torch", ".", "zeros", "(", "1", ",", "num_patches", "+", "2", ",", "self", ".", "embed_dim", ")", ")", "\n", "\n", "trunc_normal_", "(", "self", ".", "dist_token", ",", "std", "=", "0.02", ")", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.modules.base_vision_transformer.DistilledVisionTransformer.visual_embed": [[865, 982], ["base_vision_transformer.DistilledVisionTransformer.patch_embed", "torch.interpolate().long", "torch.interpolate().long", "torch.interpolate().long", "base_vision_transformer.DistilledVisionTransformer.pos_embed[].transpose().view", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat.flatten().transpose", "torch.cat.flatten().transpose", "torch.cat.flatten().transpose", "base_vision_transformer.DistilledVisionTransformer.flatten().transpose", "[].expand().flatten", "torch.cat.flatten", "torch.cat.flatten", "torch.cat.flatten", "torch.cat.nonzero", "torch.cat.nonzero", "torch.cat.nonzero", "valid_idx[].unique", "list", "enumerate", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "x[].view", "x_mask[].view", "patch_index[].view", "pos_embed[].view", "base_vision_transformer.DistilledVisionTransformer.cls_token.expand", "base_vision_transformer.DistilledVisionTransformer.dist_token.expand", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "base_vision_transformer.DistilledVisionTransformer.pos_drop", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "x_mask[].sum", "x_mask[].sum", "base_vision_transformer.DistilledVisionTransformer.mask_tokens", "eff.max", "min", "v.size", "v.size", "zip", "label[].view", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "base_vision_transformer.DistilledVisionTransformer.pre_norm", "torch.interpolate", "torch.interpolate", "torch.interpolate", "base_vision_transformer.DistilledVisionTransformer.pos_embed[].transpose", "torch.pad", "torch.pad", "torch.pad", "torch.cat.flatten", "torch.cat.flatten", "torch.cat.flatten", "base_vision_transformer.DistilledVisionTransformer.flatten", "[].expand", "isinstance", "eff.max", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.cat.append", "torch.cat.append", "torch.cat.append", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.cat.append", "torch.cat.append", "torch.cat.append", "base_vision_transformer.DistilledVisionTransformer.pos_embed[].expand", "torch.ones().to", "torch.ones().to", "torch.ones().to", "torch.ones().to", "torch.ones().to", "torch.ones().to", "torch.ones().to", "torch.ones().to", "torch.ones().to", "torch.interpolate", "torch.interpolate", "torch.interpolate", "zip", "torch.ones().float", "torch.ones().float", "torch.ones().float", "torch.ones().float", "torch.ones().float", "torch.ones().float", "torch.ones().float", "torch.ones().float", "torch.ones().float", "torch.ones().float", "torch.ones().float", "torch.ones().float", "torch.ones().float", "torch.ones().float", "torch.ones().float", "torch.ones().float", "torch.ones().float", "torch.ones().float", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.full().to", "torch.full().to", "torch.full().to", "torch.full().to", "torch.full().to", "torch.full().to", "torch.full().to", "torch.full().to", "torch.full().to", "_x.sum", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.full", "torch.full", "torch.full", "torch.full", "torch.full", "torch.full", "torch.full", "torch.full", "torch.full", "torch.meshgrid", "torch.meshgrid", "torch.meshgrid", "torch.meshgrid", "torch.meshgrid", "torch.meshgrid", "torch.meshgrid", "torch.meshgrid", "torch.meshgrid", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.modules.base_vision_transformer.VisionTransformer.mask_tokens"], ["trunc_normal_", "(", "self", ".", "pos_embed", ",", "std", "=", "0.02", ")", "\n", "\n", "", "def", "visual_embed", "(", "self", ",", "_x", ",", "max_image_len", "=", "200", ",", "mask_it", "=", "False", ")", ":", "\n", "        ", "_", ",", "_", ",", "ph", ",", "pw", "=", "self", ".", "patch_embed", ".", "proj", ".", "weight", ".", "shape", "\n", "\n", "x", "=", "self", ".", "patch_embed", "(", "_x", ")", "\n", "x_mask", "=", "(", "_x", ".", "sum", "(", "dim", "=", "1", ")", "!=", "0", ")", ".", "float", "(", ")", "[", ":", ",", "None", ",", ":", ",", ":", "]", "\n", "x_mask", "=", "F", ".", "interpolate", "(", "x_mask", ",", "size", "=", "(", "x", ".", "shape", "[", "2", "]", ",", "x", ".", "shape", "[", "3", "]", ")", ")", ".", "long", "(", ")", "\n", "x_h", "=", "x_mask", "[", ":", ",", "0", "]", ".", "sum", "(", "dim", "=", "1", ")", "[", ":", ",", "0", "]", "\n", "x_w", "=", "x_mask", "[", ":", ",", "0", "]", ".", "sum", "(", "dim", "=", "2", ")", "[", ":", ",", "0", "]", "\n", "\n", "B", ",", "C", ",", "H", ",", "W", "=", "x", ".", "shape", "\n", "spatial_pos", "=", "(", "\n", "self", ".", "pos_embed", "[", ":", ",", "2", ":", ",", ":", "]", "\n", ".", "transpose", "(", "1", ",", "2", ")", "\n", ".", "view", "(", "1", ",", "C", ",", "self", ".", "patch_dim", ",", "self", ".", "patch_dim", ")", "\n", ")", "\n", "pos_embed", "=", "torch", ".", "cat", "(", "\n", "[", "\n", "F", ".", "pad", "(", "\n", "F", ".", "interpolate", "(", "\n", "spatial_pos", ",", "size", "=", "(", "h", ",", "w", ")", ",", "mode", "=", "\"bilinear\"", ",", "align_corners", "=", "True", ",", "\n", ")", ",", "\n", "(", "0", ",", "W", "-", "w", ",", "0", ",", "H", "-", "h", ")", ",", "\n", ")", "\n", "for", "h", ",", "w", "in", "zip", "(", "x_h", ",", "x_w", ")", "\n", "]", ",", "\n", "dim", "=", "0", ",", "\n", ")", "\n", "\n", "pos_embed", "=", "pos_embed", ".", "flatten", "(", "2", ")", ".", "transpose", "(", "1", ",", "2", ")", "\n", "x", "=", "x", ".", "flatten", "(", "2", ")", ".", "transpose", "(", "1", ",", "2", ")", "\n", "patch_index", "=", "(", "\n", "torch", ".", "stack", "(", "\n", "torch", ".", "meshgrid", "(", "\n", "torch", ".", "arange", "(", "x_mask", ".", "shape", "[", "-", "2", "]", ")", ",", "torch", ".", "arange", "(", "x_mask", ".", "shape", "[", "-", "1", "]", ")", "\n", ")", ",", "\n", "dim", "=", "-", "1", ",", "\n", ")", "[", "None", ",", "None", ",", ":", ",", ":", ",", ":", "]", "\n", ".", "expand", "(", "x_mask", ".", "shape", "[", "0", "]", ",", "x_mask", ".", "shape", "[", "1", "]", ",", "-", "1", ",", "-", "1", ",", "-", "1", ")", "\n", ".", "flatten", "(", "1", ",", "3", ")", "\n", ")", "\n", "x_mask", "=", "x_mask", ".", "flatten", "(", "1", ")", "\n", "\n", "if", "mask_it", ":", "\n", "            ", "x", ",", "label", "=", "self", ".", "mask_tokens", "(", "_x", ",", "x", ")", "\n", "\n", "", "if", "(", "\n", "max_image_len", "<", "0", "\n", "or", "max_image_len", "is", "None", "\n", "or", "not", "isinstance", "(", "max_image_len", ",", "int", ")", "\n", ")", ":", "\n", "# suppose aug is 800 x 1333, then, maximum effective res is 800 x 1333 (if one side gets bigger, the other will be constrained and be shrinked)", "\n", "# (800 // self.patch_size) * (1333 // self.patch_size) is the maximum number of patches that single image can get.", "\n", "# if self.patch_size = 32, 25 * 41 = 1025", "\n", "# if res is 384 x 640, 12 * 20 = 240", "\n", "            ", "eff", "=", "x_h", "*", "x_w", "\n", "max_image_len", "=", "eff", ".", "max", "(", ")", "\n", "", "else", ":", "\n", "            ", "eff", "=", "x_h", "*", "x_w", "\n", "max_image_len", "=", "min", "(", "eff", ".", "max", "(", ")", ",", "max_image_len", ")", "\n", "\n", "", "valid_idx", "=", "x_mask", ".", "nonzero", "(", "as_tuple", "=", "False", ")", "\n", "non_valid_idx", "=", "(", "1", "-", "x_mask", ")", ".", "nonzero", "(", "as_tuple", "=", "False", ")", "\n", "unique_rows", "=", "valid_idx", "[", ":", ",", "0", "]", ".", "unique", "(", ")", "\n", "valid_row_idx", "=", "[", "valid_idx", "[", "valid_idx", "[", ":", ",", "0", "]", "==", "u", "]", "for", "u", "in", "unique_rows", "]", "\n", "non_valid_row_idx", "=", "[", "\n", "non_valid_idx", "[", "non_valid_idx", "[", ":", ",", "0", "]", "==", "u", "]", "for", "u", "in", "unique_rows", "\n", "]", "\n", "\n", "valid_nums", "=", "[", "v", ".", "size", "(", "0", ")", "for", "v", "in", "valid_row_idx", "]", "\n", "non_valid_nums", "=", "[", "v", ".", "size", "(", "0", ")", "for", "v", "in", "non_valid_row_idx", "]", "\n", "pad_nums", "=", "[", "max_image_len", "-", "v", "for", "v", "in", "valid_nums", "]", "\n", "\n", "select", "=", "list", "(", ")", "\n", "for", "i", ",", "(", "v", ",", "nv", ",", "p", ")", "in", "enumerate", "(", "zip", "(", "valid_nums", ",", "non_valid_nums", ",", "pad_nums", ")", ")", ":", "\n", "            ", "if", "p", "<=", "0", ":", "\n", "                ", "valid_choice", "=", "torch", ".", "multinomial", "(", "torch", ".", "ones", "(", "v", ")", ".", "float", "(", ")", ",", "max_image_len", ")", "\n", "select", ".", "append", "(", "valid_row_idx", "[", "i", "]", "[", "valid_choice", "]", ")", "\n", "", "else", ":", "\n", "                ", "pad_choice", "=", "torch", ".", "multinomial", "(", "\n", "torch", ".", "ones", "(", "nv", ")", ".", "float", "(", ")", ",", "p", ",", "replacement", "=", "True", "\n", ")", "\n", "select", ".", "append", "(", "\n", "torch", ".", "cat", "(", "\n", "[", "valid_row_idx", "[", "i", "]", ",", "non_valid_row_idx", "[", "i", "]", "[", "pad_choice", "]", "]", ",", "dim", "=", "0", ",", "\n", ")", "\n", ")", "\n", "\n", "", "", "select", "=", "torch", ".", "cat", "(", "select", ",", "dim", "=", "0", ")", "\n", "x", "=", "x", "[", "select", "[", ":", ",", "0", "]", ",", "select", "[", ":", ",", "1", "]", "]", ".", "view", "(", "B", ",", "-", "1", ",", "C", ")", "\n", "x_mask", "=", "x_mask", "[", "select", "[", ":", ",", "0", "]", ",", "select", "[", ":", ",", "1", "]", "]", ".", "view", "(", "B", ",", "-", "1", ")", "\n", "patch_index", "=", "patch_index", "[", "select", "[", ":", ",", "0", "]", ",", "select", "[", ":", ",", "1", "]", "]", ".", "view", "(", "B", ",", "-", "1", ",", "2", ")", "\n", "pos_embed", "=", "pos_embed", "[", "select", "[", ":", ",", "0", "]", ",", "select", "[", ":", ",", "1", "]", "]", ".", "view", "(", "B", ",", "-", "1", ",", "C", ")", "\n", "if", "mask_it", ":", "\n", "            ", "label", "=", "label", "[", "select", "[", ":", ",", "0", "]", ",", "select", "[", ":", ",", "1", "]", "]", ".", "view", "(", "B", ",", "-", "1", ",", "3", ")", "\n", "\n", "label", "[", "x_mask", "==", "0", "]", "=", "-", "100", "\n", "label", "=", "torch", ".", "cat", "(", "\n", "[", "torch", ".", "full", "(", "(", "label", ".", "shape", "[", "0", "]", ",", "1", ",", "3", ")", ",", "-", "100", ")", ".", "to", "(", "label", ")", ",", "label", ",", "]", ",", "dim", "=", "1", ",", "\n", ")", "\n", "\n", "", "cls_tokens", "=", "self", ".", "cls_token", ".", "expand", "(", "B", ",", "-", "1", ",", "-", "1", ")", "\n", "dist_token", "=", "self", ".", "dist_token", ".", "expand", "(", "B", ",", "-", "1", ",", "-", "1", ")", "\n", "x", "=", "torch", ".", "cat", "(", "(", "cls_tokens", ",", "dist_token", ",", "x", ")", ",", "dim", "=", "1", ")", "\n", "pos_embed", "=", "torch", ".", "cat", "(", "\n", "(", "self", ".", "pos_embed", "[", ":", ",", ":", "2", ",", ":", "]", ".", "expand", "(", "B", ",", "-", "1", ",", "-", "1", ")", ",", "pos_embed", ")", ",", "dim", "=", "1", "\n", ")", "\n", "x", "=", "x", "+", "pos_embed", "\n", "x", "=", "self", ".", "pos_drop", "(", "x", ")", "\n", "\n", "if", "self", ".", "add_norm_before_transformer", ":", "\n", "            ", "x", "=", "self", ".", "pre_norm", "(", "x", ")", "\n", "\n", "", "x_mask", "=", "torch", ".", "cat", "(", "[", "torch", ".", "ones", "(", "x_mask", ".", "shape", "[", "0", "]", ",", "2", ")", ".", "to", "(", "x_mask", ")", ",", "x_mask", "]", ",", "dim", "=", "1", ")", "\n", "if", "mask_it", ":", "\n", "            ", "return", "x", ",", "x_mask", ",", "(", "patch_index", ",", "(", "H", ",", "W", ")", ")", ",", "label", "\n", "", "else", ":", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.modules.base_vision_transformer.DistilledVisionTransformer.forward_features": [[983, 993], ["base_vision_transformer.DistilledVisionTransformer.visual_embed", "base_vision_transformer.DistilledVisionTransformer.norm", "blk"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.modules.base_vision_transformer.DistilledVisionTransformer.visual_embed"], ["            ", "return", "x", ",", "x_mask", ",", "(", "patch_index", ",", "(", "H", ",", "W", ")", ")", ",", "None", "\n", "\n", "", "", "def", "forward_features", "(", "self", ",", "_x", ",", "max_image_len", "=", "144", ",", "mask_it", "=", "False", ")", ":", "\n", "        ", "x", ",", "x_mask", ",", "patch_index", ",", "label", "=", "self", ".", "visual_embed", "(", "\n", "_x", ",", "max_image_len", "=", "max_image_len", ",", "mask_it", "=", "mask_it", "\n", ")", "\n", "\n", "for", "blk", "in", "self", ".", "blocks", ":", "\n", "            ", "x", ",", "_", "=", "blk", "(", "x", ",", "mask", "=", "x_mask", ")", "\n", "\n", "", "x", "=", "self", ".", "norm", "(", "x", ")", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.modules.base_vision_transformer.DistilledVisionTransformer.forward": [[994, 999], ["base_vision_transformer.DistilledVisionTransformer.forward_features", "base_vision_transformer.DistilledVisionTransformer.head"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.modules.base_vision_transformer.DistilledVisionTransformer.forward_features"], ["return", "x", ",", "x_mask", ",", "label", "\n", "\n", "", "def", "forward", "(", "self", ",", "x", ",", "max_image_len", "=", "-", "1", ")", ":", "\n", "        ", "x", ",", "_", ",", "_", "=", "self", ".", "forward_features", "(", "x", ",", "max_image_len", "=", "max_image_len", ")", "\n", "x", "=", "x", "[", ":", ",", "0", "]", "\n", "x", "=", "self", ".", "head", "(", "x", ")", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.modules.base_vision_transformer.download_clip": [[51, 94], ["os.path.expanduser", "os.makedirs", "os.path.basename", "os.path.join", "os.path.isfile", "url.split", "os.path.exists", "RuntimeError", "urllib.request.urlopen", "open", "hashlib.sha256().hexdigest", "RuntimeError", "os.path.isfile", "hashlib.sha256().hexdigest", "warnings.warn", "tqdm.tqdm", "source.read", "output.write", "loop.update", "hashlib.sha256", "hashlib.sha256", "int", "len", "open().read", "open().read", "source.info().get", "open", "open", "source.info"], "function", ["home.repos.pwc.inspect_result.showlab_all-in-one.gadgets.my_metrics.VQAScore.update"], ["def", "download_clip", "(", "\n", "url", ":", "str", "=", "\"https://openaipublic.azureedge.net/clip/models/40d365715913c9da98579312b702a82c18be219cc2a73407c4526f58eba950af/ViT-B-32.pt\"", ",", "\n", "root", ":", "str", "=", "os", ".", "path", ".", "expanduser", "(", "\"../../pretrained/torch/hub/checkpoints\"", ")", ",", "\n", ")", ":", "\n", "    ", "os", ".", "makedirs", "(", "root", ",", "exist_ok", "=", "True", ")", "\n", "filename", "=", "os", ".", "path", ".", "basename", "(", "url", ")", "\n", "\n", "expected_sha256", "=", "url", ".", "split", "(", "\"/\"", ")", "[", "-", "2", "]", "\n", "download_target", "=", "os", ".", "path", ".", "join", "(", "root", ",", "filename", ")", "\n", "\n", "if", "os", ".", "path", ".", "exists", "(", "download_target", ")", "and", "not", "os", ".", "path", ".", "isfile", "(", "download_target", ")", ":", "\n", "        ", "raise", "RuntimeError", "(", "f\"{download_target} exists and is not a regular file\"", ")", "\n", "\n", "", "if", "os", ".", "path", ".", "isfile", "(", "download_target", ")", ":", "\n", "        ", "if", "(", "\n", "hashlib", ".", "sha256", "(", "open", "(", "download_target", ",", "\"rb\"", ")", ".", "read", "(", ")", ")", ".", "hexdigest", "(", ")", "\n", "==", "expected_sha256", "\n", ")", ":", "\n", "            ", "return", "download_target", "\n", "", "else", ":", "\n", "            ", "warnings", ".", "warn", "(", "\n", "f\"{download_target} exists, but the SHA256 checksum does not match; re-downloading the file\"", "\n", ")", "\n", "\n", "", "", "with", "urllib", ".", "request", ".", "urlopen", "(", "url", ")", "as", "source", ",", "open", "(", "download_target", ",", "\"wb\"", ")", "as", "output", ":", "\n", "        ", "with", "tqdm", "(", "total", "=", "int", "(", "source", ".", "info", "(", ")", ".", "get", "(", "\"Content-Length\"", ")", ")", ",", "ncols", "=", "80", ")", "as", "loop", ":", "\n", "            ", "while", "True", ":", "\n", "                ", "buffer", "=", "source", ".", "read", "(", "8192", ")", "\n", "if", "not", "buffer", ":", "\n", "                    ", "break", "\n", "\n", "", "output", ".", "write", "(", "buffer", ")", "\n", "loop", ".", "update", "(", "len", "(", "buffer", ")", ")", "\n", "\n", "", "", "", "if", "(", "\n", "hashlib", ".", "sha256", "(", "open", "(", "download_target", ",", "\"rb\"", ")", ".", "read", "(", ")", ")", ".", "hexdigest", "(", ")", "\n", "!=", "expected_sha256", "\n", ")", ":", "\n", "        ", "raise", "RuntimeError", "(", "\n", "f\"Model has been downloaded but the SHA256 checksum does not not match\"", "\n", ")", "\n", "\n", "", "return", "download_target", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.modules.base_vision_transformer._cfg": [[112, 125], ["None"], "function", ["None"], ["def", "_cfg", "(", "url", "=", "\"\"", ",", "**", "kwargs", ")", ":", "\n", "    ", "return", "{", "\n", "\"url\"", ":", "url", ",", "\n", "\"num_classes\"", ":", "1000", ",", "\n", "\"input_size\"", ":", "(", "3", ",", "224", ",", "224", ")", ",", "\n", "\"pool_size\"", ":", "None", ",", "\n", "\"crop_pct\"", ":", "0.9", ",", "\n", "\"interpolation\"", ":", "\"bicubic\"", ",", "\n", "\"mean\"", ":", "IMAGENET_DEFAULT_MEAN", ",", "\n", "\"std\"", ":", "IMAGENET_DEFAULT_STD", ",", "\n", "\"first_conv\"", ":", "\"patch_embed.proj\"", ",", "\n", "\"classifier\"", ":", "\"head\"", ",", "\n", "**", "kwargs", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.modules.base_vision_transformer.attn": [[292, 297], ["torch.einsum", "torch.einsum.softmax", "torch.einsum"], "function", ["None"], ["", "", "def", "attn", "(", "q", ",", "k", ",", "v", ")", ":", "\n", "    ", "sim", "=", "einsum", "(", "'b i d, b j d -> b i j'", ",", "q", ",", "k", ")", "\n", "attn", "=", "sim", ".", "softmax", "(", "dim", "=", "-", "1", ")", "\n", "out", "=", "einsum", "(", "'b i j, b j d -> b i d'", ",", "attn", ",", "v", ")", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.modules.base_vision_transformer.resize_pos_embed": [[1001, 1019], ["_logger.info", "int", "int", "_logger.info", "posemb_grid.permute().reshape.reshape().permute", "torch.interpolate", "posemb_grid.permute().reshape.permute().reshape", "torch.cat", "torch.cat", "torch.cat", "math.sqrt", "math.sqrt", "len", "posemb_grid.permute().reshape.reshape", "posemb_grid.permute().reshape.permute"], "function", ["None"], ["\n", "\n", "", "", "def", "resize_pos_embed", "(", "posemb", ",", "posemb_new", ")", ":", "\n", "# Rescale the grid of position embeddings when loading from state_dict. Adapted from", "\n", "# https://github.com/google-research/vision_transformer/blob/00883dd691c63a6830751563748663526e811cee/vit_jax/checkpoint.py#L224", "\n", "    ", "_logger", ".", "info", "(", "\"Resized position embedding: %s to %s\"", ",", "posemb", ".", "shape", ",", "posemb_new", ".", "shape", ")", "\n", "ntok_new", "=", "posemb_new", ".", "shape", "[", "1", "]", "\n", "if", "True", ":", "\n", "        ", "posemb_tok", ",", "posemb_grid", "=", "posemb", "[", ":", ",", ":", "1", "]", ",", "posemb", "[", "0", ",", "1", ":", "]", "\n", "ntok_new", "-=", "1", "\n", "", "else", ":", "\n", "        ", "posemb_tok", ",", "posemb_grid", "=", "posemb", "[", ":", ",", ":", "0", "]", ",", "posemb", "[", "0", "]", "\n", "", "gs_old", "=", "int", "(", "math", ".", "sqrt", "(", "len", "(", "posemb_grid", ")", ")", ")", "\n", "gs_new", "=", "int", "(", "math", ".", "sqrt", "(", "ntok_new", ")", ")", "\n", "_logger", ".", "info", "(", "\"Position embedding grid-size from %s to %s\"", ",", "gs_old", ",", "gs_new", ")", "\n", "posemb_grid", "=", "posemb_grid", ".", "reshape", "(", "1", ",", "gs_old", ",", "gs_old", ",", "-", "1", ")", ".", "permute", "(", "0", ",", "3", ",", "1", ",", "2", ")", "\n", "posemb_grid", "=", "F", ".", "interpolate", "(", "posemb_grid", ",", "size", "=", "(", "gs_new", ",", "gs_new", ")", ",", "mode", "=", "\"bilinear\"", ")", "\n", "posemb_grid", "=", "posemb_grid", ".", "permute", "(", "0", ",", "2", ",", "3", ",", "1", ")", ".", "reshape", "(", "1", ",", "gs_new", "*", "gs_new", ",", "-", "1", ")", "\n", "posemb", "=", "torch", ".", "cat", "(", "[", "posemb_tok", ",", "posemb_grid", "]", ",", "dim", "=", "1", ")", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.modules.base_vision_transformer.checkpoint_filter_fn": [[1021, 1037], ["state_dict.items", "resize_pos_embed.reshape", "len", "base_vision_transformer.resize_pos_embed"], "function", ["home.repos.pwc.inspect_result.showlab_all-in-one.modules.base_vision_transformer.resize_pos_embed"], ["\n", "\n", "", "def", "checkpoint_filter_fn", "(", "state_dict", ",", "model", ")", ":", "\n", "    ", "\"\"\" convert patch embedding weight from manual patchify + linear proj to conv\"\"\"", "\n", "out_dict", "=", "{", "}", "\n", "if", "\"model\"", "in", "state_dict", ":", "\n", "# For deit models", "\n", "        ", "state_dict", "=", "state_dict", "[", "\"model\"", "]", "\n", "", "for", "k", ",", "v", "in", "state_dict", ".", "items", "(", ")", ":", "\n", "        ", "if", "\"patch_embed.proj.weight\"", "in", "k", "and", "len", "(", "v", ".", "shape", ")", "<", "4", ":", "\n", "# For old models that I trained prior to conv based patchification", "\n", "            ", "O", ",", "I", ",", "H", ",", "W", "=", "model", ".", "patch_embed", ".", "proj", ".", "weight", ".", "shape", "\n", "v", "=", "v", ".", "reshape", "(", "O", ",", "-", "1", ",", "H", ",", "W", ")", "\n", "", "elif", "k", "==", "\"pos_embed\"", "and", "v", ".", "shape", "!=", "model", ".", "pos_embed", ".", "shape", ":", "\n", "# To resize pos embedding when using model at different size from pretrained weights", "\n", "            ", "v", "=", "resize_pos_embed", "(", "v", ",", "model", ".", "pos_embed", ")", "\n", "", "out_dict", "[", "k", "]", "=", "v", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.modules.base_vision_transformer._create_vision_transformer": [[1039, 1071], ["kwargs.pop", "kwargs.pop", "kwargs.pop", "model_cls", "_logger.warning", "timm.models.helpers.load_pretrained", "kwargs.get", "functools.partial"], "function", ["None"], ["\n", "\n", "", "def", "_create_vision_transformer", "(", "variant", ",", "pretrained", "=", "False", ",", "distilled", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "default_cfg", "=", "default_cfgs", "[", "variant", "]", "\n", "default_num_classes", "=", "default_cfg", "[", "\"num_classes\"", "]", "\n", "default_img_size", "=", "default_cfg", "[", "\"input_size\"", "]", "[", "-", "1", "]", "\n", "\n", "num_classes", "=", "kwargs", ".", "pop", "(", "\"num_classes\"", ",", "default_num_classes", ")", "\n", "img_size", "=", "kwargs", ".", "pop", "(", "\"img_size\"", ",", "default_img_size", ")", "\n", "repr_size", "=", "kwargs", ".", "pop", "(", "\"representation_size\"", ",", "None", ")", "\n", "if", "repr_size", "is", "not", "None", "and", "num_classes", "!=", "default_num_classes", ":", "\n", "# Remove representation layer if fine-tuning. This may not always be the desired action,", "\n", "# but I feel better than doing nothing by default for fine-tuning. Perhaps a better interface?", "\n", "        ", "_logger", ".", "warning", "(", "\"Removing representation layer for fine-tuning.\"", ")", "\n", "repr_size", "=", "None", "\n", "\n", "", "model_cls", "=", "DistilledVisionTransformer", "if", "distilled", "else", "VisionTransformer", "\n", "model", "=", "model_cls", "(", "\n", "img_size", "=", "img_size", ",", "\n", "num_classes", "=", "num_classes", ",", "\n", "representation_size", "=", "repr_size", ",", "\n", "**", "kwargs", ",", "\n", ")", "\n", "model", ".", "default_cfg", "=", "default_cfg", "\n", "\n", "if", "pretrained", ":", "\n", "        ", "load_pretrained", "(", "\n", "model", ",", "\n", "num_classes", "=", "num_classes", ",", "\n", "in_chans", "=", "kwargs", ".", "get", "(", "\"in_chans\"", ",", "3", ")", ",", "\n", "filter_fn", "=", "partial", "(", "checkpoint_filter_fn", ",", "model", "=", "model", ")", ",", "\n", "strict", "=", "False", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.modules.base_vision_transformer.vit_small_patch16_224": [[1073, 1093], ["dict", "base_vision_transformer._create_vision_transformer", "dict.setdefault"], "function", ["home.repos.pwc.inspect_result.showlab_all-in-one.modules.base_vision_transformer._create_vision_transformer"], ["\n", "\n", "", "@", "register_model", "\n", "def", "vit_small_patch16_224", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" My custom 'small' ViT model. Depth=8, heads=8= mlp_ratio=3.\"\"\"", "\n", "model_kwargs", "=", "dict", "(", "\n", "patch_size", "=", "16", ",", "\n", "embed_dim", "=", "768", ",", "\n", "depth", "=", "8", ",", "\n", "num_heads", "=", "8", ",", "\n", "mlp_ratio", "=", "3.0", ",", "\n", "qkv_bias", "=", "False", ",", "\n", "norm_layer", "=", "nn", ".", "LayerNorm", ",", "\n", "**", "kwargs", ",", "\n", ")", "\n", "if", "pretrained", ":", "\n", "# NOTE my scale was wrong for original weights, leaving this here until I have better ones for this model", "\n", "        ", "model_kwargs", ".", "setdefault", "(", "\"qk_scale\"", ",", "768", "**", "-", "0.5", ")", "\n", "", "model", "=", "_create_vision_transformer", "(", "\n", "\"vit_small_patch16_224\"", ",", "pretrained", "=", "pretrained", ",", "**", "model_kwargs", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.modules.base_vision_transformer.vit_base_patch16_224": [[1095, 1105], ["dict", "base_vision_transformer._create_vision_transformer"], "function", ["home.repos.pwc.inspect_result.showlab_all-in-one.modules.base_vision_transformer._create_vision_transformer"], ["\n", "\n", "", "@", "register_model", "\n", "def", "vit_base_patch16_224", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" ViT-Base (ViT-B/16) from original paper (https://arxiv.org/abs/2010.11929).\n    ImageNet-1k weights fine-tuned from in21k @ 224x224, source https://github.com/google-research/vision_transformer.\n    \"\"\"", "\n", "model_kwargs", "=", "dict", "(", "patch_size", "=", "16", ",", "embed_dim", "=", "768", ",", "depth", "=", "12", ",", "num_heads", "=", "12", ",", "**", "kwargs", ")", "\n", "model", "=", "_create_vision_transformer", "(", "\n", "\"vit_base_patch16_224\"", ",", "pretrained", "=", "pretrained", ",", "**", "model_kwargs", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.modules.base_vision_transformer.vit_base_patch32_224": [[1107, 1116], ["dict", "base_vision_transformer._create_vision_transformer"], "function", ["home.repos.pwc.inspect_result.showlab_all-in-one.modules.base_vision_transformer._create_vision_transformer"], ["\n", "\n", "", "@", "register_model", "\n", "def", "vit_base_patch32_224", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" ViT-Base (ViT-B/32) from original paper (https://arxiv.org/abs/2010.11929). No pretrained weights.\n    \"\"\"", "\n", "model_kwargs", "=", "dict", "(", "patch_size", "=", "32", ",", "embed_dim", "=", "768", ",", "depth", "=", "12", ",", "num_heads", "=", "12", ",", "**", "kwargs", ")", "\n", "model", "=", "_create_vision_transformer", "(", "\n", "\"vit_base_patch32_224\"", ",", "pretrained", "=", "pretrained", ",", "**", "model_kwargs", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.modules.base_vision_transformer.vit_base_patch16_384": [[1118, 1128], ["dict", "base_vision_transformer._create_vision_transformer"], "function", ["home.repos.pwc.inspect_result.showlab_all-in-one.modules.base_vision_transformer._create_vision_transformer"], ["\n", "\n", "", "@", "register_model", "\n", "def", "vit_base_patch16_384", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" ViT-Base model (ViT-B/16) from original paper (https://arxiv.org/abs/2010.11929).\n    ImageNet-1k weights fine-tuned from in21k @ 384x384, source https://github.com/google-research/vision_transformer.\n    \"\"\"", "\n", "model_kwargs", "=", "dict", "(", "patch_size", "=", "16", ",", "embed_dim", "=", "768", ",", "depth", "=", "12", ",", "num_heads", "=", "12", ",", "**", "kwargs", ")", "\n", "model", "=", "_create_vision_transformer", "(", "\n", "\"vit_base_patch16_384\"", ",", "pretrained", "=", "pretrained", ",", "**", "model_kwargs", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.modules.base_vision_transformer.vit_base_patch32_384": [[1130, 1140], ["dict", "base_vision_transformer._create_vision_transformer"], "function", ["home.repos.pwc.inspect_result.showlab_all-in-one.modules.base_vision_transformer._create_vision_transformer"], ["\n", "\n", "", "@", "register_model", "\n", "def", "vit_base_patch32_384", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" ViT-Base model (ViT-B/32) from original paper (https://arxiv.org/abs/2010.11929).\n    ImageNet-1k weights fine-tuned from in21k @ 384x384, source https://github.com/google-research/vision_transformer.\n    \"\"\"", "\n", "model_kwargs", "=", "dict", "(", "patch_size", "=", "32", ",", "embed_dim", "=", "768", ",", "depth", "=", "12", ",", "num_heads", "=", "12", ",", "**", "kwargs", ")", "\n", "model", "=", "_create_vision_transformer", "(", "\n", "\"vit_base_patch32_384\"", ",", "pretrained", "=", "pretrained", ",", "**", "model_kwargs", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.modules.base_vision_transformer.vit_large_patch16_224": [[1142, 1152], ["dict", "base_vision_transformer._create_vision_transformer"], "function", ["home.repos.pwc.inspect_result.showlab_all-in-one.modules.base_vision_transformer._create_vision_transformer"], ["\n", "\n", "", "@", "register_model", "\n", "def", "vit_large_patch16_224", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" ViT-Large model (ViT-L/32) from original paper (https://arxiv.org/abs/2010.11929).\n    ImageNet-1k weights fine-tuned from in21k @ 224x224, source https://github.com/google-research/vision_transformer.\n    \"\"\"", "\n", "model_kwargs", "=", "dict", "(", "patch_size", "=", "16", ",", "embed_dim", "=", "1024", ",", "depth", "=", "24", ",", "num_heads", "=", "16", ",", "**", "kwargs", ")", "\n", "model", "=", "_create_vision_transformer", "(", "\n", "\"vit_large_patch16_224\"", ",", "pretrained", "=", "pretrained", ",", "**", "model_kwargs", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.modules.base_vision_transformer.vit_large_patch32_224": [[1154, 1163], ["dict", "base_vision_transformer._create_vision_transformer"], "function", ["home.repos.pwc.inspect_result.showlab_all-in-one.modules.base_vision_transformer._create_vision_transformer"], ["\n", "\n", "", "@", "register_model", "\n", "def", "vit_large_patch32_224", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" ViT-Large model (ViT-L/32) from original paper (https://arxiv.org/abs/2010.11929). No pretrained weights.\n    \"\"\"", "\n", "model_kwargs", "=", "dict", "(", "patch_size", "=", "32", ",", "embed_dim", "=", "1024", ",", "depth", "=", "24", ",", "num_heads", "=", "16", ",", "**", "kwargs", ")", "\n", "model", "=", "_create_vision_transformer", "(", "\n", "\"vit_large_patch32_224\"", ",", "pretrained", "=", "pretrained", ",", "**", "model_kwargs", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.modules.base_vision_transformer.vit_large_patch16_384": [[1165, 1175], ["dict", "base_vision_transformer._create_vision_transformer"], "function", ["home.repos.pwc.inspect_result.showlab_all-in-one.modules.base_vision_transformer._create_vision_transformer"], ["\n", "\n", "", "@", "register_model", "\n", "def", "vit_large_patch16_384", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" ViT-Large model (ViT-L/16) from original paper (https://arxiv.org/abs/2010.11929).\n    ImageNet-1k weights fine-tuned from in21k @ 384x384, source https://github.com/google-research/vision_transformer.\n    \"\"\"", "\n", "model_kwargs", "=", "dict", "(", "patch_size", "=", "16", ",", "embed_dim", "=", "1024", ",", "depth", "=", "24", ",", "num_heads", "=", "16", ",", "**", "kwargs", ")", "\n", "model", "=", "_create_vision_transformer", "(", "\n", "\"vit_large_patch16_384\"", ",", "pretrained", "=", "pretrained", ",", "**", "model_kwargs", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.modules.base_vision_transformer.vit_large_patch32_384": [[1177, 1187], ["dict", "base_vision_transformer._create_vision_transformer"], "function", ["home.repos.pwc.inspect_result.showlab_all-in-one.modules.base_vision_transformer._create_vision_transformer"], ["\n", "\n", "", "@", "register_model", "\n", "def", "vit_large_patch32_384", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" ViT-Large model (ViT-L/32) from original paper (https://arxiv.org/abs/2010.11929).\n    ImageNet-1k weights fine-tuned from in21k @ 384x384, source https://github.com/google-research/vision_transformer.\n    \"\"\"", "\n", "model_kwargs", "=", "dict", "(", "patch_size", "=", "32", ",", "embed_dim", "=", "1024", ",", "depth", "=", "24", ",", "num_heads", "=", "16", ",", "**", "kwargs", ")", "\n", "model", "=", "_create_vision_transformer", "(", "\n", "\"vit_large_patch32_384\"", ",", "pretrained", "=", "pretrained", ",", "**", "model_kwargs", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.modules.base_vision_transformer.vit_base_patch16_224_in21k": [[1189, 1206], ["dict", "base_vision_transformer._create_vision_transformer"], "function", ["home.repos.pwc.inspect_result.showlab_all-in-one.modules.base_vision_transformer._create_vision_transformer"], ["\n", "\n", "", "@", "register_model", "\n", "def", "vit_base_patch16_224_in21k", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" ViT-Base model (ViT-B/16) from original paper (https://arxiv.org/abs/2010.11929).\n    ImageNet-21k weights @ 224x224, source https://github.com/google-research/vision_transformer.\n    \"\"\"", "\n", "model_kwargs", "=", "dict", "(", "\n", "patch_size", "=", "16", ",", "\n", "embed_dim", "=", "768", ",", "\n", "depth", "=", "12", ",", "\n", "num_heads", "=", "12", ",", "\n", "representation_size", "=", "768", ",", "\n", "**", "kwargs", ",", "\n", ")", "\n", "model", "=", "_create_vision_transformer", "(", "\n", "\"vit_base_patch16_224_in21k\"", ",", "pretrained", "=", "pretrained", ",", "**", "model_kwargs", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.modules.base_vision_transformer.vit_base_patch32_224_in21k": [[1208, 1225], ["dict", "base_vision_transformer._create_vision_transformer"], "function", ["home.repos.pwc.inspect_result.showlab_all-in-one.modules.base_vision_transformer._create_vision_transformer"], ["\n", "\n", "", "@", "register_model", "\n", "def", "vit_base_patch32_224_in21k", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" ViT-Base model (ViT-B/32) from original paper (https://arxiv.org/abs/2010.11929).\n    ImageNet-21k weights @ 224x224, source https://github.com/google-research/vision_transformer.\n    \"\"\"", "\n", "model_kwargs", "=", "dict", "(", "\n", "patch_size", "=", "32", ",", "\n", "embed_dim", "=", "768", ",", "\n", "depth", "=", "12", ",", "\n", "num_heads", "=", "12", ",", "\n", "representation_size", "=", "768", ",", "\n", "**", "kwargs", ",", "\n", ")", "\n", "model", "=", "_create_vision_transformer", "(", "\n", "\"vit_base_patch32_224_in21k\"", ",", "pretrained", "=", "pretrained", ",", "**", "model_kwargs", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.modules.base_vision_transformer.vit_large_patch16_224_in21k": [[1227, 1244], ["dict", "base_vision_transformer._create_vision_transformer"], "function", ["home.repos.pwc.inspect_result.showlab_all-in-one.modules.base_vision_transformer._create_vision_transformer"], ["\n", "\n", "", "@", "register_model", "\n", "def", "vit_large_patch16_224_in21k", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" ViT-Large model (ViT-L/16) from original paper (https://arxiv.org/abs/2010.11929).\n    ImageNet-21k weights @ 224x224, source https://github.com/google-research/vision_transformer.\n    \"\"\"", "\n", "model_kwargs", "=", "dict", "(", "\n", "patch_size", "=", "16", ",", "\n", "embed_dim", "=", "1024", ",", "\n", "depth", "=", "24", ",", "\n", "num_heads", "=", "16", ",", "\n", "representation_size", "=", "1024", ",", "\n", "**", "kwargs", ",", "\n", ")", "\n", "model", "=", "_create_vision_transformer", "(", "\n", "\"vit_large_patch16_224_in21k\"", ",", "pretrained", "=", "pretrained", ",", "**", "model_kwargs", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.modules.base_vision_transformer.vit_large_patch32_224_in21k": [[1246, 1263], ["dict", "base_vision_transformer._create_vision_transformer"], "function", ["home.repos.pwc.inspect_result.showlab_all-in-one.modules.base_vision_transformer._create_vision_transformer"], ["\n", "\n", "", "@", "register_model", "\n", "def", "vit_large_patch32_224_in21k", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" ViT-Large model (ViT-L/32) from original paper (https://arxiv.org/abs/2010.11929).\n    ImageNet-21k weights @ 224x224, source https://github.com/google-research/vision_transformer.\n    \"\"\"", "\n", "model_kwargs", "=", "dict", "(", "\n", "patch_size", "=", "32", ",", "\n", "embed_dim", "=", "1024", ",", "\n", "depth", "=", "24", ",", "\n", "num_heads", "=", "16", ",", "\n", "representation_size", "=", "1024", ",", "\n", "**", "kwargs", ",", "\n", ")", "\n", "model", "=", "_create_vision_transformer", "(", "\n", "\"vit_large_patch32_224_in21k\"", ",", "pretrained", "=", "pretrained", ",", "**", "model_kwargs", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.modules.base_vision_transformer.vit_huge_patch14_224_in21k": [[1265, 1283], ["dict", "base_vision_transformer._create_vision_transformer"], "function", ["home.repos.pwc.inspect_result.showlab_all-in-one.modules.base_vision_transformer._create_vision_transformer"], ["\n", "\n", "", "@", "register_model", "\n", "def", "vit_huge_patch14_224_in21k", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" ViT-Huge model (ViT-H/14) from original paper (https://arxiv.org/abs/2010.11929).\n    ImageNet-21k weights @ 224x224, source https://github.com/google-research/vision_transformer.\n    NOTE: converted weights not currently available, too large for github release hosting.\n    \"\"\"", "\n", "model_kwargs", "=", "dict", "(", "\n", "patch_size", "=", "14", ",", "\n", "embed_dim", "=", "1280", ",", "\n", "depth", "=", "32", ",", "\n", "num_heads", "=", "16", ",", "\n", "representation_size", "=", "1280", ",", "\n", "**", "kwargs", ",", "\n", ")", "\n", "model", "=", "_create_vision_transformer", "(", "\n", "\"vit_huge_patch14_224_in21k\"", ",", "pretrained", "=", "pretrained", ",", "**", "model_kwargs", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.modules.base_vision_transformer.vit_base_resnet50_224_in21k": [[1285, 1312], ["timm.models.resnetv2.ResNetV2", "dict", "base_vision_transformer._create_vision_transformer", "kwargs.get"], "function", ["home.repos.pwc.inspect_result.showlab_all-in-one.modules.base_vision_transformer._create_vision_transformer"], ["\n", "\n", "", "@", "register_model", "\n", "def", "vit_base_resnet50_224_in21k", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" R50+ViT-B/16 hybrid model from original paper (https://arxiv.org/abs/2010.11929).\n    ImageNet-21k weights @ 224x224, source https://github.com/google-research/vision_transformer.\n    \"\"\"", "\n", "# create a ResNetV2 w/o pre-activation, that uses StdConv and GroupNorm and has 3 stages, no head", "\n", "backbone", "=", "ResNetV2", "(", "\n", "layers", "=", "(", "3", ",", "4", ",", "9", ")", ",", "\n", "num_classes", "=", "0", ",", "\n", "global_pool", "=", "\"\"", ",", "\n", "in_chans", "=", "kwargs", ".", "get", "(", "\"in_chans\"", ",", "3", ")", ",", "\n", "preact", "=", "False", ",", "\n", "stem_type", "=", "\"same\"", ",", "\n", "conv_layer", "=", "StdConv2dSame", ",", "\n", ")", "\n", "model_kwargs", "=", "dict", "(", "\n", "embed_dim", "=", "768", ",", "\n", "depth", "=", "12", ",", "\n", "num_heads", "=", "12", ",", "\n", "hybrid_backbone", "=", "backbone", ",", "\n", "representation_size", "=", "768", ",", "\n", "**", "kwargs", ",", "\n", ")", "\n", "model", "=", "_create_vision_transformer", "(", "\n", "\"vit_base_resnet50_224_in21k\"", ",", "pretrained", "=", "pretrained", ",", "**", "model_kwargs", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.modules.base_vision_transformer.vit_base_resnet50_384": [[1314, 1336], ["timm.models.resnetv2.ResNetV2", "dict", "base_vision_transformer._create_vision_transformer", "kwargs.get"], "function", ["home.repos.pwc.inspect_result.showlab_all-in-one.modules.base_vision_transformer._create_vision_transformer"], ["\n", "\n", "", "@", "register_model", "\n", "def", "vit_base_resnet50_384", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" R50+ViT-B/16 hybrid from original paper (https://arxiv.org/abs/2010.11929).\n    ImageNet-1k weights fine-tuned from in21k @ 384x384, source https://github.com/google-research/vision_transformer.\n    \"\"\"", "\n", "# create a ResNetV2 w/o pre-activation, that uses StdConv and GroupNorm and has 3 stages, no head", "\n", "backbone", "=", "ResNetV2", "(", "\n", "layers", "=", "(", "3", ",", "4", ",", "9", ")", ",", "\n", "num_classes", "=", "0", ",", "\n", "global_pool", "=", "\"\"", ",", "\n", "in_chans", "=", "kwargs", ".", "get", "(", "\"in_chans\"", ",", "3", ")", ",", "\n", "preact", "=", "False", ",", "\n", "stem_type", "=", "\"same\"", ",", "\n", "conv_layer", "=", "StdConv2dSame", ",", "\n", ")", "\n", "model_kwargs", "=", "dict", "(", "\n", "embed_dim", "=", "768", ",", "depth", "=", "12", ",", "num_heads", "=", "12", ",", "hybrid_backbone", "=", "backbone", ",", "**", "kwargs", "\n", ")", "\n", "model", "=", "_create_vision_transformer", "(", "\n", "\"vit_base_resnet50_384\"", ",", "pretrained", "=", "pretrained", ",", "**", "model_kwargs", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.modules.base_vision_transformer.vit_small_resnet26d_224": [[1338, 1360], ["timm.models.resnet.resnet26d", "dict", "base_vision_transformer._create_vision_transformer", "kwargs.get"], "function", ["home.repos.pwc.inspect_result.showlab_all-in-one.modules.base_vision_transformer._create_vision_transformer"], ["\n", "\n", "", "@", "register_model", "\n", "def", "vit_small_resnet26d_224", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" Custom ViT small hybrid w/ ResNet26D stride 32. No pretrained weights.\n    \"\"\"", "\n", "backbone", "=", "resnet26d", "(", "\n", "pretrained", "=", "pretrained", ",", "\n", "in_chans", "=", "kwargs", ".", "get", "(", "\"in_chans\"", ",", "3", ")", ",", "\n", "features_only", "=", "True", ",", "\n", "out_indices", "=", "[", "4", "]", ",", "\n", ")", "\n", "model_kwargs", "=", "dict", "(", "\n", "embed_dim", "=", "768", ",", "\n", "depth", "=", "8", ",", "\n", "num_heads", "=", "8", ",", "\n", "mlp_ratio", "=", "3", ",", "\n", "hybrid_backbone", "=", "backbone", ",", "\n", "**", "kwargs", ",", "\n", ")", "\n", "model", "=", "_create_vision_transformer", "(", "\n", "\"vit_small_resnet26d_224\"", ",", "pretrained", "=", "pretrained", ",", "**", "model_kwargs", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.modules.base_vision_transformer.vit_small_resnet50d_s3_224": [[1362, 1384], ["timm.models.resnet.resnet50d", "dict", "base_vision_transformer._create_vision_transformer", "kwargs.get"], "function", ["home.repos.pwc.inspect_result.showlab_all-in-one.modules.base_vision_transformer._create_vision_transformer"], ["\n", "\n", "", "@", "register_model", "\n", "def", "vit_small_resnet50d_s3_224", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" Custom ViT small hybrid w/ ResNet50D 3-stages, stride 16. No pretrained weights.\n    \"\"\"", "\n", "backbone", "=", "resnet50d", "(", "\n", "pretrained", "=", "pretrained", ",", "\n", "in_chans", "=", "kwargs", ".", "get", "(", "\"in_chans\"", ",", "3", ")", ",", "\n", "features_only", "=", "True", ",", "\n", "out_indices", "=", "[", "3", "]", ",", "\n", ")", "\n", "model_kwargs", "=", "dict", "(", "\n", "embed_dim", "=", "768", ",", "\n", "depth", "=", "8", ",", "\n", "num_heads", "=", "8", ",", "\n", "mlp_ratio", "=", "3", ",", "\n", "hybrid_backbone", "=", "backbone", ",", "\n", "**", "kwargs", ",", "\n", ")", "\n", "model", "=", "_create_vision_transformer", "(", "\n", "\"vit_small_resnet50d_s3_224\"", ",", "pretrained", "=", "pretrained", ",", "**", "model_kwargs", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.modules.base_vision_transformer.vit_base_resnet26d_224": [[1386, 1403], ["timm.models.resnet.resnet26d", "dict", "base_vision_transformer._create_vision_transformer", "kwargs.get"], "function", ["home.repos.pwc.inspect_result.showlab_all-in-one.modules.base_vision_transformer._create_vision_transformer"], ["\n", "\n", "", "@", "register_model", "\n", "def", "vit_base_resnet26d_224", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" Custom ViT base hybrid w/ ResNet26D stride 32. No pretrained weights.\n    \"\"\"", "\n", "backbone", "=", "resnet26d", "(", "\n", "pretrained", "=", "pretrained", ",", "\n", "in_chans", "=", "kwargs", ".", "get", "(", "\"in_chans\"", ",", "3", ")", ",", "\n", "features_only", "=", "True", ",", "\n", "out_indices", "=", "[", "4", "]", ",", "\n", ")", "\n", "model_kwargs", "=", "dict", "(", "\n", "embed_dim", "=", "768", ",", "depth", "=", "12", ",", "num_heads", "=", "12", ",", "hybrid_backbone", "=", "backbone", ",", "**", "kwargs", "\n", ")", "\n", "model", "=", "_create_vision_transformer", "(", "\n", "\"vit_base_resnet26d_224\"", ",", "pretrained", "=", "pretrained", ",", "**", "model_kwargs", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.modules.base_vision_transformer.vit_base_resnet50d_224": [[1405, 1422], ["timm.models.resnet.resnet50d", "dict", "base_vision_transformer._create_vision_transformer", "kwargs.get"], "function", ["home.repos.pwc.inspect_result.showlab_all-in-one.modules.base_vision_transformer._create_vision_transformer"], ["\n", "\n", "", "@", "register_model", "\n", "def", "vit_base_resnet50d_224", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" Custom ViT base hybrid w/ ResNet50D stride 32. No pretrained weights.\n    \"\"\"", "\n", "backbone", "=", "resnet50d", "(", "\n", "pretrained", "=", "pretrained", ",", "\n", "in_chans", "=", "kwargs", ".", "get", "(", "\"in_chans\"", ",", "3", ")", ",", "\n", "features_only", "=", "True", ",", "\n", "out_indices", "=", "[", "4", "]", ",", "\n", ")", "\n", "model_kwargs", "=", "dict", "(", "\n", "embed_dim", "=", "768", ",", "depth", "=", "12", ",", "num_heads", "=", "12", ",", "hybrid_backbone", "=", "backbone", ",", "**", "kwargs", "\n", ")", "\n", "model", "=", "_create_vision_transformer", "(", "\n", "\"vit_base_resnet50d_224\"", ",", "pretrained", "=", "pretrained", ",", "**", "model_kwargs", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.modules.base_vision_transformer.vit_deit_tiny_patch16_224": [[1424, 1434], ["dict", "base_vision_transformer._create_vision_transformer"], "function", ["home.repos.pwc.inspect_result.showlab_all-in-one.modules.base_vision_transformer._create_vision_transformer"], ["\n", "\n", "", "@", "register_model", "\n", "def", "vit_deit_tiny_patch16_224", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" DeiT-tiny model @ 224x224 from paper (https://arxiv.org/abs/2012.12877).\n    ImageNet-1k weights from https://github.com/facebookresearch/deit.\n    \"\"\"", "\n", "model_kwargs", "=", "dict", "(", "patch_size", "=", "16", ",", "embed_dim", "=", "192", ",", "depth", "=", "12", ",", "num_heads", "=", "3", ",", "**", "kwargs", ")", "\n", "model", "=", "_create_vision_transformer", "(", "\n", "\"vit_deit_tiny_patch16_224\"", ",", "pretrained", "=", "pretrained", ",", "**", "model_kwargs", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.modules.base_vision_transformer.vit_deit_small_patch16_224": [[1436, 1446], ["dict", "base_vision_transformer._create_vision_transformer"], "function", ["home.repos.pwc.inspect_result.showlab_all-in-one.modules.base_vision_transformer._create_vision_transformer"], ["\n", "\n", "", "@", "register_model", "\n", "def", "vit_deit_small_patch16_224", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" DeiT-small model @ 224x224 from paper (https://arxiv.org/abs/2012.12877).\n    ImageNet-1k weights from https://github.com/facebookresearch/deit.\n    \"\"\"", "\n", "model_kwargs", "=", "dict", "(", "patch_size", "=", "16", ",", "embed_dim", "=", "384", ",", "depth", "=", "12", ",", "num_heads", "=", "6", ",", "**", "kwargs", ")", "\n", "model", "=", "_create_vision_transformer", "(", "\n", "\"vit_deit_small_patch16_224\"", ",", "pretrained", "=", "pretrained", ",", "**", "model_kwargs", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.modules.base_vision_transformer.vit_deit_base_patch16_224": [[1448, 1458], ["dict", "base_vision_transformer._create_vision_transformer"], "function", ["home.repos.pwc.inspect_result.showlab_all-in-one.modules.base_vision_transformer._create_vision_transformer"], ["\n", "\n", "", "@", "register_model", "\n", "def", "vit_deit_base_patch16_224", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" DeiT base model @ 224x224 from paper (https://arxiv.org/abs/2012.12877).\n    ImageNet-1k weights from https://github.com/facebookresearch/deit.\n    \"\"\"", "\n", "model_kwargs", "=", "dict", "(", "patch_size", "=", "16", ",", "embed_dim", "=", "768", ",", "depth", "=", "12", ",", "num_heads", "=", "12", ",", "**", "kwargs", ")", "\n", "model", "=", "_create_vision_transformer", "(", "\n", "\"vit_deit_base_patch16_224\"", ",", "pretrained", "=", "pretrained", ",", "**", "model_kwargs", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.modules.base_vision_transformer.vit_deit_base_patch16_384": [[1460, 1470], ["dict", "base_vision_transformer._create_vision_transformer"], "function", ["home.repos.pwc.inspect_result.showlab_all-in-one.modules.base_vision_transformer._create_vision_transformer"], ["\n", "\n", "", "@", "register_model", "\n", "def", "vit_deit_base_patch16_384", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" DeiT base model @ 384x384 from paper (https://arxiv.org/abs/2012.12877).\n    ImageNet-1k weights from https://github.com/facebookresearch/deit.\n    \"\"\"", "\n", "model_kwargs", "=", "dict", "(", "patch_size", "=", "16", ",", "embed_dim", "=", "768", ",", "depth", "=", "12", ",", "num_heads", "=", "12", ",", "**", "kwargs", ")", "\n", "model", "=", "_create_vision_transformer", "(", "\n", "\"vit_deit_base_patch16_384\"", ",", "pretrained", "=", "pretrained", ",", "**", "model_kwargs", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.modules.base_vision_transformer.vit_deit_tiny_distilled_patch16_224": [[1472, 1485], ["dict", "base_vision_transformer._create_vision_transformer"], "function", ["home.repos.pwc.inspect_result.showlab_all-in-one.modules.base_vision_transformer._create_vision_transformer"], ["\n", "\n", "", "@", "register_model", "\n", "def", "vit_deit_tiny_distilled_patch16_224", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" DeiT-tiny distilled model @ 224x224 from paper (https://arxiv.org/abs/2012.12877).\n    ImageNet-1k weights from https://github.com/facebookresearch/deit.\n    \"\"\"", "\n", "model_kwargs", "=", "dict", "(", "patch_size", "=", "16", ",", "embed_dim", "=", "192", ",", "depth", "=", "12", ",", "num_heads", "=", "3", ",", "**", "kwargs", ")", "\n", "model", "=", "_create_vision_transformer", "(", "\n", "\"vit_deit_tiny_distilled_patch16_224\"", ",", "\n", "pretrained", "=", "pretrained", ",", "\n", "distilled", "=", "True", ",", "\n", "**", "model_kwargs", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.modules.base_vision_transformer.vit_deit_small_distilled_patch16_224": [[1487, 1500], ["dict", "base_vision_transformer._create_vision_transformer"], "function", ["home.repos.pwc.inspect_result.showlab_all-in-one.modules.base_vision_transformer._create_vision_transformer"], ["\n", "\n", "", "@", "register_model", "\n", "def", "vit_deit_small_distilled_patch16_224", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" DeiT-small distilled model @ 224x224 from paper (https://arxiv.org/abs/2012.12877).\n    ImageNet-1k weights from https://github.com/facebookresearch/deit.\n    \"\"\"", "\n", "model_kwargs", "=", "dict", "(", "patch_size", "=", "16", ",", "embed_dim", "=", "384", ",", "depth", "=", "12", ",", "num_heads", "=", "6", ",", "**", "kwargs", ")", "\n", "model", "=", "_create_vision_transformer", "(", "\n", "\"vit_deit_small_distilled_patch16_224\"", ",", "\n", "pretrained", "=", "pretrained", ",", "\n", "distilled", "=", "True", ",", "\n", "**", "model_kwargs", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.modules.base_vision_transformer.vit_deit_base_distilled_patch16_224": [[1502, 1515], ["dict", "base_vision_transformer._create_vision_transformer"], "function", ["home.repos.pwc.inspect_result.showlab_all-in-one.modules.base_vision_transformer._create_vision_transformer"], ["\n", "\n", "", "@", "register_model", "\n", "def", "vit_deit_base_distilled_patch16_224", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" DeiT-base distilled model @ 224x224 from paper (https://arxiv.org/abs/2012.12877).\n    ImageNet-1k weights from https://github.com/facebookresearch/deit.\n    \"\"\"", "\n", "model_kwargs", "=", "dict", "(", "patch_size", "=", "16", ",", "embed_dim", "=", "768", ",", "depth", "=", "12", ",", "num_heads", "=", "12", ",", "**", "kwargs", ")", "\n", "model", "=", "_create_vision_transformer", "(", "\n", "\"vit_deit_base_distilled_patch16_224\"", ",", "\n", "pretrained", "=", "pretrained", ",", "\n", "distilled", "=", "True", ",", "\n", "**", "model_kwargs", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.modules.base_vision_transformer.vit_deit_base_distilled_patch16_384": [[1517, 1530], ["dict", "base_vision_transformer._create_vision_transformer"], "function", ["home.repos.pwc.inspect_result.showlab_all-in-one.modules.base_vision_transformer._create_vision_transformer"], ["\n", "\n", "", "@", "register_model", "\n", "def", "vit_deit_base_distilled_patch16_384", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" DeiT-base distilled model @ 384x384 from paper (https://arxiv.org/abs/2012.12877).\n    ImageNet-1k weights from https://github.com/facebookresearch/deit.\n    \"\"\"", "\n", "model_kwargs", "=", "dict", "(", "patch_size", "=", "16", ",", "embed_dim", "=", "768", ",", "depth", "=", "12", ",", "num_heads", "=", "12", ",", "**", "kwargs", ")", "\n", "model", "=", "_create_vision_transformer", "(", "\n", "\"vit_deit_base_distilled_patch16_384\"", ",", "\n", "pretrained", "=", "pretrained", ",", "\n", "distilled", "=", "True", ",", "\n", "**", "model_kwargs", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.modules.cotrain_utils.set_metrics": [[14, 70], ["pl_module.hparams.config[].items", "setattr", "setattr", "CoTrain.gadgets.my_metrics.VQAScore", "CoTrain.gadgets.my_metrics.Scalar", "setattr", "setattr", "setattr", "setattr", "CoTrain.gadgets.my_metrics.Scalar", "CoTrain.gadgets.my_metrics.Accuracy", "CoTrain.gadgets.my_metrics.Scalar", "CoTrain.gadgets.my_metrics.Accuracy", "setattr", "setattr", "CoTrain.gadgets.my_metrics.Scalar", "CoTrain.gadgets.my_metrics.Accuracy", "setattr", "setattr", "setattr", "setattr", "CoTrain.gadgets.my_metrics.VQAScore", "CoTrain.gadgets.my_metrics.Scalar", "CoTrain.gadgets.my_metrics.Scalar", "CoTrain.gadgets.my_metrics.Accuracy", "setattr", "setattr", "setattr", "setattr", "CoTrain.gadgets.my_metrics.VQAScore", "CoTrain.gadgets.my_metrics.Scalar", "CoTrain.gadgets.my_metrics.Scalar", "CoTrain.gadgets.my_metrics.Accuracy", "setattr", "setattr", "CoTrain.gadgets.my_metrics.Accuracy", "CoTrain.gadgets.my_metrics.Scalar", "setattr", "setattr", "setattr", "setattr", "setattr", "setattr", "setattr", "CoTrain.gadgets.my_metrics.Accuracy", "CoTrain.gadgets.my_metrics.Scalar", "CoTrain.gadgets.my_metrics.Accuracy", "CoTrain.gadgets.my_metrics.Scalar", "CoTrain.gadgets.my_metrics.Accuracy", "CoTrain.gadgets.my_metrics.Scalar", "CoTrain.gadgets.my_metrics.Scalar", "setattr", "CoTrain.gadgets.my_metrics.Scalar", "setattr", "setattr", "setattr", "setattr", "CoTrain.gadgets.my_metrics.Accuracy", "CoTrain.gadgets.my_metrics.Scalar", "CoTrain.gadgets.my_metrics.Scalar", "CoTrain.gadgets.my_metrics.Scalar", "setattr", "CoTrain.gadgets.my_metrics.Scalar", "setattr", "setattr", "setattr", "CoTrain.gadgets.my_metrics.Scalar", "CoTrain.gadgets.my_metrics.Accuracy", "CoTrain.gadgets.my_metrics.Scalar"], "function", ["None"], ["def", "set_metrics", "(", "pl_module", ")", ":", "\n", "    ", "for", "split", "in", "[", "\"train\"", ",", "\"val\"", "]", ":", "\n", "        ", "for", "k", ",", "v", "in", "pl_module", ".", "hparams", ".", "config", "[", "\"loss_names\"", "]", ".", "items", "(", ")", ":", "\n", "            ", "if", "v", "<", "1", ":", "\n", "                ", "continue", "\n", "", "if", "k", "==", "\"vqa\"", ":", "\n", "                ", "setattr", "(", "pl_module", ",", "f\"{split}_vqa_score\"", ",", "VQAScore", "(", ")", ")", "\n", "setattr", "(", "pl_module", ",", "f\"{split}_{k}_loss\"", ",", "Scalar", "(", ")", ")", "\n", "# vcr", "\n", "", "elif", "k", "==", "\"vcr_q2a\"", ":", "\n", "                ", "setattr", "(", "pl_module", ",", "f\"{split}_{k}_loss\"", ",", "Scalar", "(", ")", ")", "\n", "setattr", "(", "pl_module", ",", "f\"{split}_{k}_accuracy\"", ",", "Accuracy", "(", ")", ")", "\n", "setattr", "(", "pl_module", ",", "f\"{split}_vcr_qar_loss\"", ",", "Scalar", "(", ")", ")", "\n", "setattr", "(", "pl_module", ",", "f\"{split}_vcr_qar_accuracy\"", ",", "Accuracy", "(", ")", ")", "\n", "", "elif", "k", "==", "\"mc_vqa\"", ":", "\n", "                ", "setattr", "(", "pl_module", ",", "f\"{split}_{k}_loss\"", ",", "Scalar", "(", ")", ")", "\n", "setattr", "(", "pl_module", ",", "f\"{split}_{k}_accuracy\"", ",", "Accuracy", "(", ")", ")", "\n", "", "elif", "k", "==", "\"openend_vqa\"", ":", "\n", "                ", "setattr", "(", "pl_module", ",", "f\"{split}_vqa_score\"", ",", "VQAScore", "(", ")", ")", "\n", "setattr", "(", "pl_module", ",", "f\"{split}_vqa_loss\"", ",", "Scalar", "(", ")", ")", "\n", "setattr", "(", "pl_module", ",", "f\"{split}_{k}_loss\"", ",", "Scalar", "(", ")", ")", "\n", "setattr", "(", "pl_module", ",", "f\"{split}_{k}_accuracy\"", ",", "Accuracy", "(", ")", ")", "\n", "", "elif", "k", "==", "\"vcop\"", ":", "\n", "                ", "setattr", "(", "pl_module", ",", "f\"{split}_vcop_score\"", ",", "VQAScore", "(", ")", ")", "\n", "setattr", "(", "pl_module", ",", "f\"{split}_vcop_loss\"", ",", "Scalar", "(", ")", ")", "\n", "setattr", "(", "pl_module", ",", "f\"{split}_{k}_loss\"", ",", "Scalar", "(", ")", ")", "\n", "setattr", "(", "pl_module", ",", "f\"{split}_{k}_accuracy\"", ",", "Accuracy", "(", ")", ")", "\n", "", "elif", "k", "==", "\"multiple_choice\"", ":", "\n", "                ", "setattr", "(", "pl_module", ",", "f\"{split}_{k}_accuracy\"", ",", "Accuracy", "(", ")", ")", "\n", "setattr", "(", "pl_module", ",", "f\"{split}_{k}_loss\"", ",", "Scalar", "(", ")", ")", "\n", "", "elif", "k", "==", "\"nlvr2\"", ":", "\n", "                ", "if", "split", "==", "\"train\"", ":", "\n", "                    ", "setattr", "(", "pl_module", ",", "f\"train_{k}_accuracy\"", ",", "Accuracy", "(", ")", ")", "\n", "setattr", "(", "pl_module", ",", "f\"train_{k}_loss\"", ",", "Scalar", "(", ")", ")", "\n", "", "else", ":", "\n", "                    ", "setattr", "(", "pl_module", ",", "f\"dev_{k}_accuracy\"", ",", "Accuracy", "(", ")", ")", "\n", "setattr", "(", "pl_module", ",", "f\"dev_{k}_loss\"", ",", "Scalar", "(", ")", ")", "\n", "setattr", "(", "pl_module", ",", "f\"test_{k}_accuracy\"", ",", "Accuracy", "(", ")", ")", "\n", "setattr", "(", "pl_module", ",", "f\"test_{k}_loss\"", ",", "Scalar", "(", ")", ")", "\n", "", "", "elif", "k", "==", "\"irtr\"", ":", "\n", "                ", "setattr", "(", "pl_module", ",", "f\"{split}_irtr_loss\"", ",", "Scalar", "(", ")", ")", "\n", "", "elif", "k", "==", "\"mppd\"", "or", "k", "==", "\"mpfr\"", ":", "\n", "                ", "setattr", "(", "pl_module", ",", "f\"{split}_{k}_loss\"", ",", "Scalar", "(", ")", ")", "\n", "", "elif", "k", "==", "\"vtm\"", ":", "\n", "                ", "setattr", "(", "pl_module", ",", "f\"{split}_{k}_accuracy\"", ",", "Accuracy", "(", ")", ")", "\n", "setattr", "(", "pl_module", ",", "f\"{split}_{k}_loss\"", ",", "Scalar", "(", ")", ")", "\n", "setattr", "(", "pl_module", ",", "f\"{split}_{k}_dino_loss\"", ",", "Scalar", "(", ")", ")", "\n", "setattr", "(", "pl_module", ",", "f\"{split}_{k}_wpa_loss\"", ",", "Scalar", "(", ")", ")", "\n", "# add for image text contrastive learning", "\n", "", "elif", "k", "==", "\"itc\"", ":", "\n", "                ", "setattr", "(", "pl_module", ",", "f\"{split}_{k}_loss\"", ",", "Scalar", "(", ")", ")", "\n", "", "elif", "k", "==", "\"dino\"", ":", "\n", "                ", "setattr", "(", "pl_module", ",", "f\"{split}_{k}_loss\"", ",", "Scalar", "(", ")", ")", "\n", "", "else", ":", "\n", "                ", "setattr", "(", "pl_module", ",", "f\"{split}_{k}_accuracy\"", ",", "Accuracy", "(", ")", ")", "\n", "setattr", "(", "pl_module", ",", "f\"{split}_{k}_loss\"", ",", "Scalar", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.modules.cotrain_utils.epoch_wrapup": [[72, 291], ["pl_module.hparams.config[].items", "pl_module.log", "CoTrain.modules.objectives.compute_irtr_recall", "pl_module.logger.experiment.add_scalar", "pl_module.logger.experiment.add_scalar", "pl_module.logger.experiment.add_scalar", "pl_module.logger.experiment.add_scalar", "pl_module.logger.experiment.add_scalar", "pl_module.logger.experiment.add_scalar", "CoTrain.modules.objectives.compute_ind_irtr_recall", "print", "pl_module.logger.experiment.add_scalar", "pl_module.logger.experiment.add_scalar", "pl_module.logger.experiment.add_scalar", "pl_module.logger.experiment.add_scalar", "pl_module.logger.experiment.add_scalar", "pl_module.logger.experiment.add_scalar", "torch.distributed.get_rank", "print", "ir_r1.item", "tr_r1.item", "getattr().compute", "pl_module.log", "getattr().reset", "pl_module.log", "getattr().reset", "getattr().compute", "pl_module.log", "getattr().reset", "getattr().compute", "pl_module.log", "getattr().reset", "pl_module.log", "getattr().reset", "getattr().compute", "pl_module.log", "getattr().reset", "getattr", "getattr", "getattr", "getattr().compute", "getattr().compute", "pl_module.log", "getattr().reset", "getattr().compute", "pl_module.log", "getattr().reset", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr().compute", "pl_module.log", "getattr().reset", "getattr().compute", "pl_module.log", "getattr().reset", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr().compute", "pl_module.log", "getattr().reset", "getattr().compute", "pl_module.log", "getattr().reset", "getattr", "getattr", "getattr", "getattr", "getattr().compute", "pl_module.log", "getattr().reset", "getattr().compute", "pl_module.log", "getattr().reset", "getattr", "getattr", "getattr", "getattr", "getattr().compute", "getattr", "getattr", "getattr", "getattr", "getattr().compute", "pl_module.log", "getattr().reset", "pl_module.log", "getattr().reset", "getattr().compute", "pl_module.log", "getattr().reset", "pl_module.log", "getattr().reset", "getattr().compute", "pl_module.log", "getattr().reset", "pl_module.log", "getattr().reset", "pl_module.log", "getattr().reset", "getattr", "getattr().compute", "getattr().compute", "getattr().compute", "getattr().compute", "pl_module.log", "getattr().reset", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr().compute", "getattr().compute", "pl_module.log", "getattr().reset", "pl_module.log", "getattr().reset", "pl_module.log", "getattr().reset", "pl_module.log", "getattr().reset", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr().compute", "getattr().compute", "getattr().compute", "pl_module.log", "getattr().reset", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr().compute", "pl_module.log", "getattr().reset", "getattr().compute", "pl_module.log", "getattr().reset", "pl_module.log", "getattr().reset", "getattr", "getattr", "getattr", "getattr", "getattr().compute", "getattr().compute", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr"], "function", ["home.repos.pwc.inspect_result.showlab_all-in-one.modules.objectives.compute_irtr_recall", "home.repos.pwc.inspect_result.showlab_all-in-one.modules.objectives.compute_ind_irtr_recall", "home.repos.pwc.inspect_result.showlab_all-in-one.modules.dist_utils.get_rank", "home.repos.pwc.inspect_result.showlab_all-in-one.gadgets.my_metrics.VQAScore.compute", "home.repos.pwc.inspect_result.showlab_all-in-one.gadgets.my_metrics.VQAScore.compute", "home.repos.pwc.inspect_result.showlab_all-in-one.gadgets.my_metrics.VQAScore.compute", "home.repos.pwc.inspect_result.showlab_all-in-one.gadgets.my_metrics.VQAScore.compute", "home.repos.pwc.inspect_result.showlab_all-in-one.gadgets.my_metrics.VQAScore.compute", "home.repos.pwc.inspect_result.showlab_all-in-one.gadgets.my_metrics.VQAScore.compute", "home.repos.pwc.inspect_result.showlab_all-in-one.gadgets.my_metrics.VQAScore.compute", "home.repos.pwc.inspect_result.showlab_all-in-one.gadgets.my_metrics.VQAScore.compute", "home.repos.pwc.inspect_result.showlab_all-in-one.gadgets.my_metrics.VQAScore.compute", "home.repos.pwc.inspect_result.showlab_all-in-one.gadgets.my_metrics.VQAScore.compute", "home.repos.pwc.inspect_result.showlab_all-in-one.gadgets.my_metrics.VQAScore.compute", "home.repos.pwc.inspect_result.showlab_all-in-one.gadgets.my_metrics.VQAScore.compute", "home.repos.pwc.inspect_result.showlab_all-in-one.gadgets.my_metrics.VQAScore.compute", "home.repos.pwc.inspect_result.showlab_all-in-one.gadgets.my_metrics.VQAScore.compute", "home.repos.pwc.inspect_result.showlab_all-in-one.gadgets.my_metrics.VQAScore.compute", "home.repos.pwc.inspect_result.showlab_all-in-one.gadgets.my_metrics.VQAScore.compute", "home.repos.pwc.inspect_result.showlab_all-in-one.gadgets.my_metrics.VQAScore.compute", "home.repos.pwc.inspect_result.showlab_all-in-one.gadgets.my_metrics.VQAScore.compute", "home.repos.pwc.inspect_result.showlab_all-in-one.gadgets.my_metrics.VQAScore.compute", "home.repos.pwc.inspect_result.showlab_all-in-one.gadgets.my_metrics.VQAScore.compute", "home.repos.pwc.inspect_result.showlab_all-in-one.gadgets.my_metrics.VQAScore.compute", "home.repos.pwc.inspect_result.showlab_all-in-one.gadgets.my_metrics.VQAScore.compute", "home.repos.pwc.inspect_result.showlab_all-in-one.gadgets.my_metrics.VQAScore.compute", "home.repos.pwc.inspect_result.showlab_all-in-one.gadgets.my_metrics.VQAScore.compute", "home.repos.pwc.inspect_result.showlab_all-in-one.gadgets.my_metrics.VQAScore.compute", "home.repos.pwc.inspect_result.showlab_all-in-one.gadgets.my_metrics.VQAScore.compute", "home.repos.pwc.inspect_result.showlab_all-in-one.gadgets.my_metrics.VQAScore.compute", "home.repos.pwc.inspect_result.showlab_all-in-one.gadgets.my_metrics.VQAScore.compute", "home.repos.pwc.inspect_result.showlab_all-in-one.gadgets.my_metrics.VQAScore.compute", "home.repos.pwc.inspect_result.showlab_all-in-one.gadgets.my_metrics.VQAScore.compute"], ["", "", "", "", "def", "epoch_wrapup", "(", "pl_module", ")", ":", "\n", "    ", "phase", "=", "\"train\"", "if", "pl_module", ".", "training", "else", "\"val\"", "\n", "the_metric", "=", "0", "\n", "the_metric_qar", "=", "0", "\n", "if", "pl_module", ".", "hparams", ".", "config", "[", "\"get_recall_metric\"", "]", "and", "not", "pl_module", ".", "training", ":", "\n", "        ", "(", "ir_r1", ",", "ir_r5", ",", "ir_r10", ",", "tr_r1", ",", "tr_r5", ",", "tr_r10", ")", "=", "compute_irtr_recall", "(", "pl_module", ")", "\n", "if", "torch", ".", "distributed", ".", "get_rank", "(", ")", "==", "0", ":", "\n", "            ", "print", "(", "(", "ir_r1", ",", "ir_r5", ",", "ir_r10", ",", "tr_r1", ",", "tr_r5", ",", "tr_r10", ")", ",", "pl_module", ".", "global_step", ")", "\n", "", "pl_module", ".", "logger", ".", "experiment", ".", "add_scalar", "(", "\n", "\"recalls/ir_r1\"", ",", "ir_r1", ",", "pl_module", ".", "global_step", "\n", ")", "\n", "pl_module", ".", "logger", ".", "experiment", ".", "add_scalar", "(", "\n", "\"recalls/ir_r5\"", ",", "ir_r5", ",", "pl_module", ".", "global_step", "\n", ")", "\n", "pl_module", ".", "logger", ".", "experiment", ".", "add_scalar", "(", "\n", "\"recalls/ir_r10\"", ",", "ir_r10", ",", "pl_module", ".", "global_step", "\n", ")", "\n", "pl_module", ".", "logger", ".", "experiment", ".", "add_scalar", "(", "\n", "\"recalls/tr_r1\"", ",", "tr_r1", ",", "pl_module", ".", "global_step", "\n", ")", "\n", "pl_module", ".", "logger", ".", "experiment", ".", "add_scalar", "(", "\n", "\"recalls/tr_r5\"", ",", "tr_r5", ",", "pl_module", ".", "global_step", "\n", ")", "\n", "pl_module", ".", "logger", ".", "experiment", ".", "add_scalar", "(", "\n", "\"recalls/tr_r10\"", ",", "tr_r10", ",", "pl_module", ".", "global_step", "\n", ")", "\n", "the_metric", "+=", "ir_r1", ".", "item", "(", ")", "+", "tr_r1", ".", "item", "(", ")", "\n", "\n", "# add for ind irtr", "\n", "", "if", "pl_module", ".", "hparams", ".", "config", "[", "\"get_ind_recall_metric\"", "]", "and", "not", "pl_module", ".", "training", ":", "\n", "        ", "(", "ir_r1", ",", "ir_r5", ",", "ir_r10", ",", "tr_r1", ",", "tr_r5", ",", "tr_r10", ")", "=", "compute_ind_irtr_recall", "(", "pl_module", ")", "\n", "print", "(", "(", "ir_r1", ",", "ir_r5", ",", "ir_r10", ",", "tr_r1", ",", "tr_r5", ",", "tr_r10", ")", ",", "pl_module", ".", "global_step", ")", "\n", "pl_module", ".", "logger", ".", "experiment", ".", "add_scalar", "(", "\n", "\"recalls/ir_r1\"", ",", "ir_r1", ",", "pl_module", ".", "global_step", "\n", ")", "\n", "pl_module", ".", "logger", ".", "experiment", ".", "add_scalar", "(", "\n", "\"recalls/ir_r5\"", ",", "ir_r5", ",", "pl_module", ".", "global_step", "\n", ")", "\n", "pl_module", ".", "logger", ".", "experiment", ".", "add_scalar", "(", "\n", "\"recalls/ir_r10\"", ",", "ir_r10", ",", "pl_module", ".", "global_step", "\n", ")", "\n", "pl_module", ".", "logger", ".", "experiment", ".", "add_scalar", "(", "\n", "\"recalls/tr_r1\"", ",", "tr_r1", ",", "pl_module", ".", "global_step", "\n", ")", "\n", "pl_module", ".", "logger", ".", "experiment", ".", "add_scalar", "(", "\n", "\"recalls/tr_r5\"", ",", "tr_r5", ",", "pl_module", ".", "global_step", "\n", ")", "\n", "pl_module", ".", "logger", ".", "experiment", ".", "add_scalar", "(", "\n", "\"recalls/tr_r10\"", ",", "tr_r10", ",", "pl_module", ".", "global_step", "\n", ")", "\n", "# the_metric += ir_r1.item() + tr_r1.item()", "\n", "the_metric", "+=", "ir_r1", "+", "tr_r1", "\n", "# == end", "\n", "\n", "", "for", "loss_name", ",", "v", "in", "pl_module", ".", "hparams", ".", "config", "[", "\"loss_names\"", "]", ".", "items", "(", ")", ":", "\n", "        ", "if", "v", "<", "1", ":", "\n", "            ", "continue", "\n", "\n", "", "value", "=", "0", "\n", "qar_value", "=", "0", "\n", "if", "loss_name", "==", "\"vqa\"", ":", "\n", "            ", "value", "=", "getattr", "(", "pl_module", ",", "f\"{phase}_{loss_name}_score\"", ")", ".", "compute", "(", ")", "\n", "pl_module", ".", "log", "(", "f\"{loss_name}/{phase}/score_epoch\"", ",", "value", ")", "\n", "getattr", "(", "pl_module", ",", "f\"{phase}_{loss_name}_score\"", ")", ".", "reset", "(", ")", "\n", "pl_module", ".", "log", "(", "\n", "f\"{loss_name}/{phase}/loss_epoch\"", ",", "\n", "getattr", "(", "pl_module", ",", "f\"{phase}_{loss_name}_loss\"", ")", ".", "compute", "(", ")", ",", "\n", ")", "\n", "getattr", "(", "pl_module", ",", "f\"{phase}_{loss_name}_loss\"", ")", ".", "reset", "(", ")", "\n", "", "elif", "loss_name", "==", "\"vcr_q2a\"", ":", "\n", "# q2a", "\n", "            ", "pl_module", ".", "log", "(", "\n", "f\"{loss_name}/{phase}/loss_epoch\"", ",", "\n", "getattr", "(", "pl_module", ",", "f\"{phase}_{loss_name}_loss\"", ")", ".", "compute", "(", ")", ",", "\n", ")", "\n", "getattr", "(", "pl_module", ",", "f\"{phase}_{loss_name}_loss\"", ")", ".", "reset", "(", ")", "\n", "value", "=", "getattr", "(", "pl_module", ",", "f\"{phase}_{loss_name}_accuracy\"", ")", ".", "compute", "(", ")", "\n", "pl_module", ".", "log", "(", "f\"{loss_name}/{phase}/accuracy_epoch\"", ",", "value", ")", "\n", "getattr", "(", "pl_module", ",", "f\"{phase}_{loss_name}_accuracy\"", ")", ".", "reset", "(", ")", "\n", "# qar", "\n", "pl_module", ".", "log", "(", "\n", "f\"vcr_qar/{phase}/loss_epoch\"", ",", "\n", "getattr", "(", "pl_module", ",", "f\"{phase}_vcr_qar_loss\"", ")", ".", "compute", "(", ")", ",", "\n", ")", "\n", "getattr", "(", "pl_module", ",", "f\"{phase}_vcr_qar_loss\"", ")", ".", "reset", "(", ")", "\n", "qar_value", "=", "getattr", "(", "pl_module", ",", "f\"{phase}_vcr_qar_accuracy\"", ")", ".", "compute", "(", ")", "\n", "pl_module", ".", "log", "(", "f\"vcr_qar/{phase}/accuracy_epoch\"", ",", "qar_value", ")", "\n", "getattr", "(", "pl_module", ",", "f\"{phase}_vcr_qar_accuracy\"", ")", ".", "reset", "(", ")", "\n", "# mc_vqa", "\n", "", "elif", "loss_name", "==", "\"mc_vqa\"", ":", "\n", "            ", "pl_module", ".", "log", "(", "\n", "f\"{loss_name}/{phase}/loss_epoch\"", ",", "\n", "getattr", "(", "pl_module", ",", "f\"{phase}_{loss_name}_loss\"", ")", ".", "compute", "(", ")", ",", "\n", ")", "\n", "getattr", "(", "pl_module", ",", "f\"{phase}_{loss_name}_loss\"", ")", ".", "reset", "(", ")", "\n", "value", "=", "getattr", "(", "pl_module", ",", "f\"{phase}_{loss_name}_accuracy\"", ")", ".", "compute", "(", ")", "\n", "pl_module", ".", "log", "(", "f\"{loss_name}/{phase}/accuracy_epoch\"", ",", "value", ")", "\n", "getattr", "(", "pl_module", ",", "f\"{phase}_{loss_name}_accuracy\"", ")", ".", "reset", "(", ")", "\n", "", "elif", "loss_name", "==", "\"openend_vqa\"", ":", "\n", "            ", "pl_module", ".", "log", "(", "\n", "f\"{loss_name}/{phase}/loss_epoch\"", ",", "\n", "getattr", "(", "pl_module", ",", "f\"{phase}_vqa_loss\"", ")", ".", "compute", "(", ")", ",", "\n", ")", "\n", "getattr", "(", "pl_module", ",", "f\"{phase}_vqa_loss\"", ")", ".", "reset", "(", ")", "\n", "value", "=", "getattr", "(", "pl_module", ",", "f\"{phase}_{loss_name}_accuracy\"", ")", ".", "compute", "(", ")", "\n", "pl_module", ".", "log", "(", "f\"{loss_name}/{phase}/accuracy_epoch\"", ",", "value", ")", "\n", "getattr", "(", "pl_module", ",", "f\"{phase}_{loss_name}_accuracy\"", ")", ".", "reset", "(", ")", "\n", "# multiple_choice", "\n", "", "elif", "loss_name", "==", "\"multiple_choice\"", ":", "\n", "            ", "pl_module", ".", "log", "(", "\n", "f\"{loss_name}/{phase}/loss_epoch\"", ",", "\n", "getattr", "(", "pl_module", ",", "f\"{phase}_{loss_name}_loss\"", ")", ".", "compute", "(", ")", ",", "\n", ")", "\n", "getattr", "(", "pl_module", ",", "f\"{phase}_{loss_name}_loss\"", ")", ".", "reset", "(", ")", "\n", "value", "=", "getattr", "(", "pl_module", ",", "f\"{phase}_{loss_name}_accuracy\"", ")", ".", "compute", "(", ")", "\n", "pl_module", ".", "log", "(", "f\"{loss_name}/{phase}/accuracy_epoch\"", ",", "value", ")", "\n", "getattr", "(", "pl_module", ",", "f\"{phase}_{loss_name}_accuracy\"", ")", ".", "reset", "(", ")", "\n", "# vcop", "\n", "", "elif", "loss_name", "==", "\"vcop\"", ":", "\n", "            ", "pl_module", ".", "log", "(", "\n", "f\"{loss_name}/{phase}/loss_epoch\"", ",", "\n", "getattr", "(", "pl_module", ",", "f\"{phase}_{loss_name}_loss\"", ")", ".", "compute", "(", ")", ",", "\n", ")", "\n", "\n", "getattr", "(", "pl_module", ",", "f\"{phase}_{loss_name}_loss\"", ")", ".", "reset", "(", ")", "\n", "value", "=", "getattr", "(", "pl_module", ",", "f\"{phase}_{loss_name}_accuracy\"", ")", ".", "compute", "(", ")", "\n", "pl_module", ".", "log", "(", "f\"{loss_name}/{phase}/accuracy_epoch\"", ",", "value", ")", "\n", "getattr", "(", "pl_module", ",", "f\"{phase}_{loss_name}_accuracy\"", ")", ".", "reset", "(", ")", "\n", "", "elif", "loss_name", "==", "\"nlvr2\"", ":", "\n", "            ", "if", "phase", "==", "\"train\"", ":", "\n", "                ", "value", "=", "getattr", "(", "pl_module", ",", "f\"train_{loss_name}_accuracy\"", ")", ".", "compute", "(", ")", "\n", "pl_module", ".", "log", "(", "f\"{loss_name}/train/accuracy_epoch\"", ",", "value", ")", "\n", "getattr", "(", "pl_module", ",", "f\"train_{loss_name}_accuracy\"", ")", ".", "reset", "(", ")", "\n", "pl_module", ".", "log", "(", "\n", "f\"{loss_name}/train/loss_epoch\"", ",", "\n", "getattr", "(", "pl_module", ",", "f\"train_{loss_name}_loss\"", ")", ".", "compute", "(", ")", ",", "\n", ")", "\n", "getattr", "(", "pl_module", ",", "f\"train_{loss_name}_loss\"", ")", ".", "reset", "(", ")", "\n", "", "else", ":", "\n", "                ", "value", "=", "getattr", "(", "pl_module", ",", "f\"dev_{loss_name}_accuracy\"", ")", ".", "compute", "(", ")", "\n", "pl_module", ".", "log", "(", "f\"{loss_name}/dev/accuracy_epoch\"", ",", "value", ")", "\n", "getattr", "(", "pl_module", ",", "f\"dev_{loss_name}_accuracy\"", ")", ".", "reset", "(", ")", "\n", "pl_module", ".", "log", "(", "\n", "f\"{loss_name}/dev/loss_epoch\"", ",", "\n", "getattr", "(", "pl_module", ",", "f\"dev_{loss_name}_loss\"", ")", ".", "compute", "(", ")", ",", "\n", ")", "\n", "getattr", "(", "pl_module", ",", "f\"dev_{loss_name}_loss\"", ")", ".", "reset", "(", ")", "\n", "\n", "value", "=", "getattr", "(", "pl_module", ",", "f\"test_{loss_name}_accuracy\"", ")", ".", "compute", "(", ")", "\n", "pl_module", ".", "log", "(", "f\"{loss_name}/test/accuracy_epoch\"", ",", "value", ")", "\n", "getattr", "(", "pl_module", ",", "f\"test_{loss_name}_accuracy\"", ")", ".", "reset", "(", ")", "\n", "pl_module", ".", "log", "(", "\n", "f\"{loss_name}/test/loss_epoch\"", ",", "\n", "getattr", "(", "pl_module", ",", "f\"test_{loss_name}_loss\"", ")", ".", "compute", "(", ")", ",", "\n", ")", "\n", "getattr", "(", "pl_module", ",", "f\"test_{loss_name}_loss\"", ")", ".", "reset", "(", ")", "\n", "", "", "elif", "loss_name", "==", "\"irtr\"", ":", "\n", "            ", "pl_module", ".", "log", "(", "\n", "f\"{loss_name}/{phase}/irtr_loss_epoch\"", ",", "\n", "getattr", "(", "pl_module", ",", "f\"{phase}_irtr_loss\"", ")", ".", "compute", "(", ")", ",", "\n", ")", "\n", "getattr", "(", "pl_module", ",", "f\"{phase}_irtr_loss\"", ")", ".", "reset", "(", ")", "\n", "", "elif", "loss_name", "==", "\"mppd\"", "or", "loss_name", "==", "\"mpfr\"", ":", "\n", "            ", "pl_module", ".", "log", "(", "\n", "f\"{loss_name}/{phase}/loss_epoch\"", ",", "\n", "getattr", "(", "pl_module", ",", "f\"{phase}_{loss_name}_loss\"", ")", ".", "compute", "(", ")", ",", "\n", ")", "\n", "getattr", "(", "pl_module", ",", "f\"{phase}_{loss_name}_loss\"", ")", ".", "reset", "(", ")", "\n", "", "elif", "loss_name", "==", "\"vtm\"", ":", "\n", "            ", "value", "=", "getattr", "(", "pl_module", ",", "f\"{phase}_{loss_name}_accuracy\"", ")", ".", "compute", "(", ")", "\n", "pl_module", ".", "log", "(", "f\"{loss_name}/{phase}/accuracy_epoch\"", ",", "value", ")", "\n", "getattr", "(", "pl_module", ",", "f\"{phase}_{loss_name}_accuracy\"", ")", ".", "reset", "(", ")", "\n", "pl_module", ".", "log", "(", "\n", "f\"{loss_name}/{phase}/loss_epoch\"", ",", "\n", "getattr", "(", "pl_module", ",", "f\"{phase}_{loss_name}_loss\"", ")", ".", "compute", "(", ")", ",", "\n", ")", "\n", "getattr", "(", "pl_module", ",", "f\"{phase}_{loss_name}_loss\"", ")", ".", "reset", "(", ")", "\n", "pl_module", ".", "log", "(", "\n", "f\"{loss_name}/{phase}/wpa_loss_epoch\"", ",", "\n", "getattr", "(", "pl_module", ",", "f\"{phase}_{loss_name}_wpa_loss\"", ")", ".", "compute", "(", ")", ",", "\n", ")", "\n", "getattr", "(", "pl_module", ",", "f\"{phase}_{loss_name}_wpa_loss\"", ")", ".", "reset", "(", ")", "\n", "# add dino loss", "\n", "pl_module", ".", "log", "(", "\n", "f\"{loss_name}/{phase}/dino_loss_epoch\"", ",", "\n", "getattr", "(", "pl_module", ",", "f\"{phase}_{loss_name}_dino_loss\"", ")", ".", "compute", "(", ")", ",", "\n", ")", "\n", "getattr", "(", "pl_module", ",", "f\"{phase}_{loss_name}_dino_loss\"", ")", ".", "reset", "(", ")", "\n", "", "elif", "loss_name", "==", "\"dino\"", ":", "\n", "            ", "pl_module", ".", "log", "(", "\n", "f\"{loss_name}/{phase}/loss_epoch\"", ",", "\n", "getattr", "(", "pl_module", ",", "f\"{phase}_{loss_name}_loss\"", ")", ".", "compute", "(", ")", ",", "\n", ")", "\n", "# value = f\"{loss_name}/{phase}/loss_epoch\",", "\n", "getattr", "(", "pl_module", ",", "f\"{phase}_{loss_name}_loss\"", ")", ".", "reset", "(", ")", "\n", "", "elif", "loss_name", "==", "\"vtc\"", ":", "\n", "            ", "pl_module", ".", "log", "(", "\n", "f\"{loss_name}/{phase}/loss_epoch\"", ",", "\n", "getattr", "(", "pl_module", ",", "f\"{phase}_{loss_name}_loss\"", ")", ".", "compute", "(", ")", ",", "\n", ")", "\n", "# value = f\"{loss_name}/{phase}/loss_epoch\",", "\n", "getattr", "(", "pl_module", ",", "f\"{phase}_{loss_name}_loss\"", ")", ".", "reset", "(", ")", "\n", "", "else", ":", "\n", "            ", "value", "=", "getattr", "(", "pl_module", ",", "f\"{phase}_{loss_name}_accuracy\"", ")", ".", "compute", "(", ")", "\n", "pl_module", ".", "log", "(", "f\"{loss_name}/{phase}/accuracy_epoch\"", ",", "value", ")", "\n", "getattr", "(", "pl_module", ",", "f\"{phase}_{loss_name}_accuracy\"", ")", ".", "reset", "(", ")", "\n", "pl_module", ".", "log", "(", "\n", "f\"{loss_name}/{phase}/loss_epoch\"", ",", "\n", "getattr", "(", "pl_module", ",", "f\"{phase}_{loss_name}_loss\"", ")", ".", "compute", "(", ")", ",", "\n", ")", "\n", "getattr", "(", "pl_module", ",", "f\"{phase}_{loss_name}_loss\"", ")", ".", "reset", "(", ")", "\n", "\n", "", "if", "loss_name", "==", "\"vcr_q2a\"", ":", "\n", "# print(value, qar_value)", "\n", "            ", "the_metric", "+=", "qar_value", "/", "2", "+", "value", "/", "2", "\n", "", "else", ":", "\n", "            ", "the_metric", "+=", "value", "\n", "\n", "", "", "pl_module", ".", "log", "(", "f\"{phase}/the_metric\"", ",", "the_metric", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.modules.cotrain_utils.check_non_acc_grad": [[293, 299], ["grad.sum"], "function", ["None"], ["", "def", "check_non_acc_grad", "(", "pl_module", ")", ":", "\n", "    ", "if", "pl_module", ".", "token_type_embeddings", ".", "weight", ".", "grad", "is", "None", ":", "\n", "        ", "return", "True", "\n", "", "else", ":", "\n", "        ", "grad", "=", "pl_module", ".", "token_type_embeddings", ".", "weight", ".", "grad", "\n", "return", "(", "grad", ".", "sum", "(", ")", "==", "0", ")", ".", "item", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.modules.cotrain_utils.set_task": [[301, 306], ["pl_module.hparams.config[].items"], "function", ["None"], ["", "", "def", "set_task", "(", "pl_module", ")", ":", "\n", "    ", "pl_module", ".", "current_tasks", "=", "[", "\n", "k", "for", "k", ",", "v", "in", "pl_module", ".", "hparams", ".", "config", "[", "\"loss_names\"", "]", ".", "items", "(", ")", "if", "v", ">=", "1", "\n", "]", "\n", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.modules.cotrain_utils.set_schedule": [[308, 413], ["isinstance", "transformers.optimization.AdamW", "int", "transformers.get_cosine_schedule_with_warmup", "transformers.get_polynomial_decay_schedule_with_warmup", "pl_module.named_parameters", "torch.optim.Adam", "torch.optim.SGD", "len", "pl_module.named_parameters", "pl_module.named_parameters", "pl_module.named_parameters", "pl_module.named_parameters", "pl_module.trainer.datamodule.train_dataloader", "any", "any", "any", "any", "any", "any", "any", "any"], "function", ["home.repos.pwc.inspect_result.showlab_all-in-one.image.datamodule_base.BaseDataModule.train_dataloader"], ["", "def", "set_schedule", "(", "pl_module", ")", ":", "\n", "    ", "lr", "=", "pl_module", ".", "hparams", ".", "config", "[", "\"learning_rate\"", "]", "\n", "wd", "=", "pl_module", ".", "hparams", ".", "config", "[", "\"weight_decay\"", "]", "\n", "\n", "no_decay", "=", "[", "\n", "\"bias\"", ",", "\n", "\"LayerNorm.bias\"", ",", "\n", "\"LayerNorm.weight\"", ",", "\n", "\"norm.bias\"", ",", "\n", "\"norm.weight\"", ",", "\n", "\"norm1.bias\"", ",", "\n", "\"norm1.weight\"", ",", "\n", "\"norm2.bias\"", ",", "\n", "\"norm2.weight\"", ",", "\n", "]", "\n", "head_names", "=", "[", "\"vqa_classifier\"", ",", "\"nlvr2_classifier\"", "]", "\n", "lr_mult", "=", "pl_module", ".", "hparams", ".", "config", "[", "\"lr_mult\"", "]", "\n", "end_lr", "=", "pl_module", ".", "hparams", ".", "config", "[", "\"end_lr\"", "]", "\n", "decay_power", "=", "pl_module", ".", "hparams", ".", "config", "[", "\"decay_power\"", "]", "\n", "optim_type", "=", "pl_module", ".", "hparams", ".", "config", "[", "\"optim_type\"", "]", "\n", "\n", "names", "=", "[", "n", "for", "n", ",", "p", "in", "pl_module", ".", "named_parameters", "(", ")", "]", "\n", "optimizer_grouped_parameters", "=", "[", "\n", "{", "\n", "\"params\"", ":", "[", "\n", "p", "\n", "for", "n", ",", "p", "in", "pl_module", ".", "named_parameters", "(", ")", "\n", "if", "not", "any", "(", "nd", "in", "n", "for", "nd", "in", "no_decay", ")", "\n", "and", "not", "any", "(", "bb", "in", "n", "for", "bb", "in", "head_names", ")", "\n", "]", ",", "\n", "\"weight_decay\"", ":", "wd", ",", "\n", "\"lr\"", ":", "lr", ",", "\n", "}", ",", "\n", "{", "\n", "\"params\"", ":", "[", "\n", "p", "\n", "for", "n", ",", "p", "in", "pl_module", ".", "named_parameters", "(", ")", "\n", "if", "any", "(", "nd", "in", "n", "for", "nd", "in", "no_decay", ")", "\n", "and", "not", "any", "(", "bb", "in", "n", "for", "bb", "in", "head_names", ")", "\n", "]", ",", "\n", "\"weight_decay\"", ":", "0.0", ",", "\n", "\"lr\"", ":", "lr", ",", "\n", "}", ",", "\n", "{", "\n", "\"params\"", ":", "[", "\n", "p", "\n", "for", "n", ",", "p", "in", "pl_module", ".", "named_parameters", "(", ")", "\n", "if", "not", "any", "(", "nd", "in", "n", "for", "nd", "in", "no_decay", ")", "\n", "and", "any", "(", "bb", "in", "n", "for", "bb", "in", "head_names", ")", "\n", "]", ",", "\n", "\"weight_decay\"", ":", "wd", ",", "\n", "\"lr\"", ":", "lr", "*", "lr_mult", ",", "\n", "}", ",", "\n", "{", "\n", "\"params\"", ":", "[", "\n", "p", "\n", "for", "n", ",", "p", "in", "pl_module", ".", "named_parameters", "(", ")", "\n", "if", "any", "(", "nd", "in", "n", "for", "nd", "in", "no_decay", ")", "and", "any", "(", "bb", "in", "n", "for", "bb", "in", "head_names", ")", "\n", "]", ",", "\n", "\"weight_decay\"", ":", "0.0", ",", "\n", "\"lr\"", ":", "lr", "*", "lr_mult", ",", "\n", "}", ",", "\n", "]", "\n", "\n", "if", "optim_type", "==", "\"adamw\"", ":", "\n", "        ", "optimizer", "=", "AdamW", "(", "\n", "optimizer_grouped_parameters", ",", "lr", "=", "lr", ",", "eps", "=", "1e-8", ",", "betas", "=", "(", "0.9", ",", "0.98", ")", "\n", ")", "\n", "", "elif", "optim_type", "==", "\"adam\"", ":", "\n", "        ", "optimizer", "=", "torch", ".", "optim", ".", "Adam", "(", "optimizer_grouped_parameters", ",", "lr", "=", "lr", ")", "\n", "", "elif", "optim_type", "==", "\"sgd\"", ":", "\n", "        ", "optimizer", "=", "torch", ".", "optim", ".", "SGD", "(", "optimizer_grouped_parameters", ",", "lr", "=", "lr", ",", "momentum", "=", "0.9", ")", "\n", "\n", "", "if", "pl_module", ".", "trainer", ".", "max_steps", "is", "None", ":", "\n", "        ", "max_steps", "=", "(", "\n", "len", "(", "pl_module", ".", "trainer", ".", "datamodule", ".", "train_dataloader", "(", ")", ")", "\n", "*", "pl_module", ".", "trainer", ".", "max_epochs", "\n", "//", "pl_module", ".", "trainer", ".", "accumulate_grad_batches", "\n", ")", "\n", "", "else", ":", "\n", "        ", "max_steps", "=", "pl_module", ".", "trainer", ".", "max_steps", "\n", "\n", "", "warmup_steps", "=", "pl_module", ".", "hparams", ".", "config", "[", "\"warmup_steps\"", "]", "\n", "if", "isinstance", "(", "pl_module", ".", "hparams", ".", "config", "[", "\"warmup_steps\"", "]", ",", "float", ")", ":", "\n", "        ", "warmup_steps", "=", "int", "(", "max_steps", "*", "warmup_steps", ")", "\n", "\n", "", "if", "decay_power", "==", "\"cosine\"", ":", "\n", "        ", "scheduler", "=", "get_cosine_schedule_with_warmup", "(", "\n", "optimizer", ",", "\n", "num_warmup_steps", "=", "warmup_steps", ",", "\n", "num_training_steps", "=", "max_steps", ",", "\n", ")", "\n", "", "else", ":", "\n", "        ", "scheduler", "=", "get_polynomial_decay_schedule_with_warmup", "(", "\n", "optimizer", ",", "\n", "num_warmup_steps", "=", "warmup_steps", ",", "\n", "num_training_steps", "=", "max_steps", ",", "\n", "lr_end", "=", "end_lr", ",", "\n", "power", "=", "decay_power", ",", "\n", ")", "\n", "", "sched", "=", "{", "\"scheduler\"", ":", "scheduler", ",", "\"interval\"", ":", "\"step\"", "}", "\n", "\n", "return", "(", "\n", "[", "optimizer", "]", ",", "\n", "[", "sched", "]", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.modules.cotrain_utils.state_dict_data_parallel_fix": [[416, 443], ["list", "list", "load_state_dict.keys", "curr_state_dict.keys", "load_keys[].startswith", "OrderedDict", "load_state_dict.items", "curr_keys[].startswith", "curr_keys[].startswith", "OrderedDict", "load_state_dict.items", "load_keys[].startswith"], "function", ["None"], ["", "def", "state_dict_data_parallel_fix", "(", "load_state_dict", ",", "curr_state_dict", ")", ":", "\n", "    ", "load_keys", "=", "list", "(", "load_state_dict", ".", "keys", "(", ")", ")", "\n", "curr_keys", "=", "list", "(", "curr_state_dict", ".", "keys", "(", ")", ")", "\n", "\n", "redo_dp", "=", "False", "\n", "undo_dp", "=", "False", "\n", "if", "not", "curr_keys", "[", "0", "]", ".", "startswith", "(", "'module.'", ")", "and", "load_keys", "[", "0", "]", ".", "startswith", "(", "'module.'", ")", ":", "\n", "        ", "undo_dp", "=", "True", "\n", "", "elif", "curr_keys", "[", "0", "]", ".", "startswith", "(", "'module.'", ")", "and", "not", "load_keys", "[", "0", "]", ".", "startswith", "(", "'module.'", ")", ":", "\n", "        ", "redo_dp", "=", "True", "\n", "\n", "", "if", "undo_dp", ":", "\n", "        ", "from", "collections", "import", "OrderedDict", "\n", "new_state_dict", "=", "OrderedDict", "(", ")", "\n", "for", "k", ",", "v", "in", "load_state_dict", ".", "items", "(", ")", ":", "\n", "            ", "name", "=", "k", "[", "7", ":", "]", "# remove `module.`", "\n", "new_state_dict", "[", "name", "]", "=", "v", "\n", "# load params", "\n", "", "", "elif", "redo_dp", ":", "\n", "        ", "from", "collections", "import", "OrderedDict", "\n", "new_state_dict", "=", "OrderedDict", "(", ")", "\n", "for", "k", ",", "v", "in", "load_state_dict", ".", "items", "(", ")", ":", "\n", "            ", "name", "=", "'module.'", "+", "k", "# remove `module.`", "\n", "new_state_dict", "[", "name", "]", "=", "v", "\n", "", "", "else", ":", "\n", "        ", "new_state_dict", "=", "load_state_dict", "\n", "", "return", "new_state_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.modules.cotrain_utils.state_dict_dino_fix": [[445, 501], ["list", "list", "print", "print", "print", "print", "OrderedDict.items", "load_state_dict.keys", "curr_state_dict.keys", "load_keys[].startswith", "OrderedDict", "load_state_dict.items", "print", "curr_keys[].startswith", "curr_keys[].startswith", "OrderedDict", "load_state_dict.items", "load_keys[].startswith", "load_keys[].startswith", "load_keys[].startswith", "OrderedDict", "load_state_dict.items", "load_state_dict.items", "print"], "function", ["None"], ["", "def", "state_dict_dino_fix", "(", "load_state_dict", ",", "curr_state_dict", ")", ":", "\n", "    ", "load_keys", "=", "list", "(", "load_state_dict", ".", "keys", "(", ")", ")", "\n", "curr_keys", "=", "list", "(", "curr_state_dict", ".", "keys", "(", ")", ")", "\n", "\n", "# for k in curr_state_dict.keys():", "\n", "#     print(k)", "\n", "print", "(", "'*'", "*", "50", ")", "\n", "redo_dp", "=", "False", "\n", "undo_dp", "=", "False", "\n", "dino_dp", "=", "False", "\n", "if", "not", "curr_keys", "[", "0", "]", ".", "startswith", "(", "'module.'", ")", "and", "load_keys", "[", "0", "]", ".", "startswith", "(", "'module.'", ")", ":", "\n", "        ", "undo_dp", "=", "True", "\n", "", "elif", "curr_keys", "[", "0", "]", ".", "startswith", "(", "'module.'", ")", "and", "not", "load_keys", "[", "0", "]", ".", "startswith", "(", "'module.'", ")", ":", "\n", "        ", "redo_dp", "=", "True", "\n", "", "elif", "load_keys", "[", "10", "]", ".", "startswith", "(", "'teacher.'", ")", "or", "load_keys", "[", "10", "]", ".", "startswith", "(", "'student.'", ")", ":", "\n", "        ", "dino_dp", "=", "True", "\n", "", "if", "undo_dp", ":", "\n", "        ", "from", "collections", "import", "OrderedDict", "\n", "new_state_dict", "=", "OrderedDict", "(", ")", "\n", "for", "k", ",", "v", "in", "load_state_dict", ".", "items", "(", ")", ":", "\n", "# print(k)", "\n", "            ", "name", "=", "k", "[", "7", ":", "]", "# remove `module.`", "\n", "new_state_dict", "[", "name", "]", "=", "v", "\n", "# load params", "\n", "", "", "elif", "redo_dp", ":", "\n", "        ", "from", "collections", "import", "OrderedDict", "\n", "new_state_dict", "=", "OrderedDict", "(", ")", "\n", "for", "k", ",", "v", "in", "load_state_dict", ".", "items", "(", ")", ":", "\n", "# print(k)", "\n", "            ", "name", "=", "'module.'", "+", "k", "# remove `module.`", "\n", "new_state_dict", "[", "name", "]", "=", "v", "\n", "", "", "elif", "dino_dp", ":", "\n", "        ", "from", "collections", "import", "OrderedDict", "\n", "new_state_dict", "=", "OrderedDict", "(", ")", "\n", "for", "k", ",", "v", "in", "load_state_dict", ".", "items", "(", ")", ":", "\n", "# print(k)", "\n", "            ", "if", "k", "[", ":", "8", "]", "==", "\"student.\"", ":", "\n", "                ", "name", "=", "\"transformer.\"", "+", "k", "[", "8", ":", "]", "# remove `student.`", "\n", "new_state_dict", "[", "name", "]", "=", "v", "\n", "# continue", "\n", "", "elif", "k", "[", ":", "8", "]", "==", "\"teacher.\"", ":", "\n", "# name = \"transformer.\" + k[8:]  # remove `teacher.`", "\n", "# new_state_dict[name] = v", "\n", "                ", "continue", "\n", "", "else", ":", "\n", "                ", "new_state_dict", "[", "k", "]", "=", "v", "\n", "", "", "", "else", ":", "\n", "        ", "for", "k", ",", "v", "in", "load_state_dict", ".", "items", "(", ")", ":", "\n", "            ", "print", "(", "k", ")", "\n", "", "new_state_dict", "=", "load_state_dict", "\n", "", "print", "(", "'*'", "*", "30", ")", "\n", "print", "(", "\"new state dict\"", ")", "\n", "print", "(", "'*'", "*", "30", ")", "\n", "for", "k", ",", "v", "in", "new_state_dict", ".", "items", "(", ")", ":", "\n", "        ", "print", "(", "k", ")", "\n", "", "return", "new_state_dict", "", "", ""]], "home.repos.pwc.inspect_result.showlab_all-in-one.modules.objectives.cost_matrix_cosine": [[20, 31], ["torch.normalize", "torch.normalize", "F.normalize.matmul", "x.dim", "y.dim", "x.size", "y.size", "x.size", "y.size", "F.normalize.transpose"], "function", ["home.repos.pwc.inspect_result.showlab_all-in-one.transforms.functional.normalize", "home.repos.pwc.inspect_result.showlab_all-in-one.transforms.functional.normalize"], ["def", "cost_matrix_cosine", "(", "x", ",", "y", ",", "eps", "=", "1e-5", ")", ":", "\n", "    ", "\"\"\"Compute cosine distnace across every pairs of x, y (batched)\n    [B, L_x, D] [B, L_y, D] -> [B, Lx, Ly]\"\"\"", "\n", "assert", "x", ".", "dim", "(", ")", "==", "y", ".", "dim", "(", ")", "\n", "assert", "x", ".", "size", "(", "0", ")", "==", "y", ".", "size", "(", "0", ")", "\n", "assert", "x", ".", "size", "(", "2", ")", "==", "y", ".", "size", "(", "2", ")", "\n", "x_norm", "=", "F", ".", "normalize", "(", "x", ",", "p", "=", "2", ",", "dim", "=", "-", "1", ",", "eps", "=", "eps", ")", "\n", "y_norm", "=", "F", ".", "normalize", "(", "y", ",", "p", "=", "2", ",", "dim", "=", "-", "1", ",", "eps", "=", "eps", ")", "\n", "cosine_sim", "=", "x_norm", ".", "matmul", "(", "y_norm", ".", "transpose", "(", "1", ",", "2", ")", ")", "\n", "cosine_dist", "=", "1", "-", "cosine_sim", "\n", "return", "cosine_dist", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.modules.objectives.trace": [[33, 40], ["x.size", "torch.eye().unsqueeze().expand_as", "torch.eye().unsqueeze().expand_as", "torch.eye().unsqueeze().expand_as", "x.masked_select().contiguous().view().sum", "torch.eye().unsqueeze", "torch.eye().unsqueeze", "torch.eye().unsqueeze", "x.masked_select().contiguous().view", "torch.eye", "torch.eye", "torch.eye", "x.masked_select().contiguous", "x.masked_select"], "function", ["None"], ["", "def", "trace", "(", "x", ")", ":", "\n", "    ", "\"\"\" compute trace of input tensor (batched) \"\"\"", "\n", "b", ",", "m", ",", "n", "=", "x", ".", "size", "(", ")", "\n", "assert", "m", "==", "n", "\n", "mask", "=", "torch", ".", "eye", "(", "n", ",", "dtype", "=", "torch", ".", "bool", ",", "device", "=", "x", ".", "device", ")", ".", "unsqueeze", "(", "0", ")", ".", "expand_as", "(", "x", ")", "\n", "trace", "=", "x", ".", "masked_select", "(", "mask", ")", ".", "contiguous", "(", ")", ".", "view", "(", "b", ",", "n", ")", ".", "sum", "(", "dim", "=", "-", "1", ",", "keepdim", "=", "False", ")", "\n", "return", "trace", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.modules.objectives.ipot": [[42, 73], ["torch.no_grad", "torch.no_grad", "torch.no_grad", "C.size", "torch.ones", "torch.ones", "torch.ones", "torch.exp", "torch.exp", "torch.exp", "sigma.view.masked_fill_", "joint_pad.transpose.transpose", "torch.ones.masked_fill_", "torch.exp.masked_fill_", "x_len.unsqueeze().unsqueeze.unsqueeze().unsqueeze", "y_len.unsqueeze().unsqueeze.unsqueeze().unsqueeze", "range", "torch.ones.masked_fill_", "torch.ones", "torch.ones", "torch.ones", "x_len.unsqueeze().unsqueeze.unsqueeze", "sigma.view.view", "range", "x_len.unsqueeze().unsqueeze.unsqueeze", "y_len.unsqueeze().unsqueeze.unsqueeze", "C.transpose", "x_pad.to", "y_pad.to", "delta.view", "Q.matmul().view", "delta.matmul", "Q.matmul"], "function", ["None"], ["", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "ipot", "(", "C", ",", "x_len", ",", "x_pad", ",", "y_len", ",", "y_pad", ",", "joint_pad", ",", "beta", ",", "iteration", ",", "k", ")", ":", "\n", "    ", "\"\"\" [B, M, N], [B], [B, M], [B], [B, N], [B, M, N]\"\"\"", "\n", "b", ",", "m", ",", "n", "=", "C", ".", "size", "(", ")", "\n", "sigma", "=", "torch", ".", "ones", "(", "b", ",", "m", ",", "dtype", "=", "C", ".", "dtype", ",", "device", "=", "C", ".", "device", ")", "/", "x_len", ".", "unsqueeze", "(", "1", ")", "\n", "T", "=", "torch", ".", "ones", "(", "b", ",", "n", ",", "m", ",", "dtype", "=", "C", ".", "dtype", ",", "device", "=", "C", ".", "device", ")", "\n", "A", "=", "torch", ".", "exp", "(", "-", "C", ".", "transpose", "(", "1", ",", "2", ")", "/", "beta", ")", "\n", "\n", "# mask padded positions", "\n", "sigma", ".", "masked_fill_", "(", "x_pad", ",", "0", ")", "\n", "joint_pad", "=", "joint_pad", ".", "transpose", "(", "1", ",", "2", ")", "\n", "T", ".", "masked_fill_", "(", "joint_pad", ",", "0", ")", "\n", "A", ".", "masked_fill_", "(", "joint_pad", ",", "0", ")", "\n", "\n", "# broadcastable lengths", "\n", "x_len", "=", "x_len", ".", "unsqueeze", "(", "1", ")", ".", "unsqueeze", "(", "2", ")", "\n", "y_len", "=", "y_len", ".", "unsqueeze", "(", "1", ")", ".", "unsqueeze", "(", "2", ")", "\n", "\n", "# mask to zero out padding in delta and sigma", "\n", "x_mask", "=", "(", "x_pad", ".", "to", "(", "C", ".", "dtype", ")", "*", "1e4", ")", ".", "unsqueeze", "(", "1", ")", "\n", "y_mask", "=", "(", "y_pad", ".", "to", "(", "C", ".", "dtype", ")", "*", "1e4", ")", ".", "unsqueeze", "(", "1", ")", "\n", "\n", "for", "_", "in", "range", "(", "iteration", ")", ":", "\n", "        ", "Q", "=", "A", "*", "T", "# bs * n * m", "\n", "sigma", "=", "sigma", ".", "view", "(", "b", ",", "m", ",", "1", ")", "\n", "for", "_", "in", "range", "(", "k", ")", ":", "\n", "            ", "delta", "=", "1", "/", "(", "y_len", "*", "Q", ".", "matmul", "(", "sigma", ")", ".", "view", "(", "b", ",", "1", ",", "n", ")", "+", "y_mask", ")", "\n", "sigma", "=", "1", "/", "(", "x_len", "*", "delta", ".", "matmul", "(", "Q", ")", "+", "x_mask", ")", "\n", "", "T", "=", "delta", ".", "view", "(", "b", ",", "n", ",", "1", ")", "*", "Q", "*", "sigma", "\n", "", "T", ".", "masked_fill_", "(", "joint_pad", ",", "0", ")", "\n", "return", "T", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.modules.objectives.optimal_transport_dist": [[75, 92], ["objectives.cost_matrix_cosine", "cost_matrix_cosine.masked_fill_", "objectives.ipot", "objectives.trace", "txt_pad.unsqueeze", "img_pad.unsqueeze", "cost_matrix_cosine.detach", "cost_matrix_cosine.matmul", "ipot.detach", "txt_pad.size", "txt_pad.sum", "img_pad.size", "img_pad.sum"], "function", ["home.repos.pwc.inspect_result.showlab_all-in-one.modules.objectives.cost_matrix_cosine", "home.repos.pwc.inspect_result.showlab_all-in-one.modules.objectives.ipot", "home.repos.pwc.inspect_result.showlab_all-in-one.modules.objectives.trace"], ["", "def", "optimal_transport_dist", "(", "\n", "txt_emb", ",", "img_emb", ",", "txt_pad", ",", "img_pad", ",", "beta", "=", "0.5", ",", "iteration", "=", "50", ",", "k", "=", "1", "\n", ")", ":", "\n", "    ", "\"\"\" [B, M, D], [B, N, D], [B, M], [B, N]\"\"\"", "\n", "cost", "=", "cost_matrix_cosine", "(", "txt_emb", ",", "img_emb", ")", "\n", "# mask the padded inputs", "\n", "joint_pad", "=", "txt_pad", ".", "unsqueeze", "(", "-", "1", ")", "|", "img_pad", ".", "unsqueeze", "(", "-", "2", ")", "\n", "cost", ".", "masked_fill_", "(", "joint_pad", ",", "0", ")", "\n", "\n", "txt_len", "=", "(", "txt_pad", ".", "size", "(", "1", ")", "-", "txt_pad", ".", "sum", "(", "dim", "=", "1", ",", "keepdim", "=", "False", ")", ")", ".", "to", "(", "dtype", "=", "cost", ".", "dtype", ")", "\n", "img_len", "=", "(", "img_pad", ".", "size", "(", "1", ")", "-", "img_pad", ".", "sum", "(", "dim", "=", "1", ",", "keepdim", "=", "False", ")", ")", ".", "to", "(", "dtype", "=", "cost", ".", "dtype", ")", "\n", "\n", "T", "=", "ipot", "(", "\n", "cost", ".", "detach", "(", ")", ",", "txt_len", ",", "txt_pad", ",", "img_len", ",", "img_pad", ",", "joint_pad", ",", "beta", ",", "iteration", ",", "k", "\n", ")", "\n", "distance", "=", "trace", "(", "cost", ".", "matmul", "(", "T", ".", "detach", "(", ")", ")", ")", "\n", "return", "distance", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.modules.objectives.compute_mlm": [[94, 121], ["pl_module.infer", "pl_module.mlm_score", "torch.cross_entropy", "pl_module.log", "pl_module.log", "pl_module.mlm_score.view", "mlm_labels.view", "getattr", "getattr"], "function", ["home.repos.pwc.inspect_result.showlab_all-in-one.modules.allinone_module.AllinoneTransformerSS.infer"], ["", "def", "compute_mlm", "(", "pl_module", ",", "batch", ",", "mode", "=", "\"video\"", ")", ":", "\n", "    ", "infer", "=", "pl_module", ".", "infer", "(", "batch", ",", "mask_text", "=", "True", ",", "mask_video", "=", "False", ",", "mode", "=", "mode", ")", "\n", "mlm_logits", "=", "pl_module", ".", "mlm_score", "(", "infer", "[", "\"text_feats\"", "]", ")", "\n", "mlm_labels", "=", "infer", "[", "\"text_labels\"", "]", "\n", "\n", "mlm_loss", "=", "F", ".", "cross_entropy", "(", "\n", "mlm_logits", ".", "view", "(", "-", "1", ",", "pl_module", ".", "hparams", ".", "config", "[", "\"vocab_size\"", "]", ")", ",", "\n", "mlm_labels", ".", "view", "(", "-", "1", ")", ",", "\n", "ignore_index", "=", "-", "100", ",", "\n", ")", "\n", "\n", "ret", "=", "{", "\n", "\"mlm_loss\"", ":", "mlm_loss", ",", "\n", "\"mlm_logits\"", ":", "mlm_logits", ",", "\n", "\"mlm_labels\"", ":", "mlm_labels", ",", "\n", "\"mlm_ids\"", ":", "infer", "[", "\"text_ids\"", "]", ",", "\n", "}", "\n", "\n", "phase", "=", "\"train\"", "if", "pl_module", ".", "training", "else", "\"val\"", "\n", "loss", "=", "getattr", "(", "pl_module", ",", "f\"{phase}_mlm_loss\"", ")", "(", "ret", "[", "\"mlm_loss\"", "]", ")", "\n", "acc", "=", "getattr", "(", "pl_module", ",", "f\"{phase}_mlm_accuracy\"", ")", "(", "\n", "ret", "[", "\"mlm_logits\"", "]", ",", "ret", "[", "\"mlm_labels\"", "]", "\n", ")", "\n", "pl_module", ".", "log", "(", "f\"mlm/{phase}/loss\"", ",", "loss", ")", "\n", "pl_module", ".", "log", "(", "f\"mlm/{phase}/accuracy\"", ",", "acc", ")", "\n", "\n", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.modules.objectives.sim_matrix": [[205, 214], ["torch.mm", "torch.mm", "torch.mm", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "b_norm.transpose", "a.norm", "b.norm", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like"], "function", ["None"], ["            ", "img_mask", "[", ":", ",", "1", "]", "=", "False", "\n", "", "txt_pad", ",", "img_pad", "=", "~", "txt_mask", ",", "~", "img_mask", "\n", "\n", "cost", "=", "cost_matrix_cosine", "(", "txt_emb", ".", "float", "(", ")", ",", "img_emb", ".", "float", "(", ")", ")", "\n", "joint_pad", "=", "txt_pad", ".", "unsqueeze", "(", "-", "1", ")", "|", "img_pad", ".", "unsqueeze", "(", "-", "2", ")", "\n", "cost", ".", "masked_fill_", "(", "joint_pad", ",", "0", ")", "\n", "\n", "txt_len", "=", "(", "txt_pad", ".", "size", "(", "1", ")", "-", "txt_pad", ".", "sum", "(", "dim", "=", "1", ",", "keepdim", "=", "False", ")", ")", ".", "to", "(", "\n", "dtype", "=", "cost", ".", "dtype", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.modules.objectives.compute_vtc": [[137, 169], ["pl_module.infer", "pl_module.infer", "objectives.sim_matrix", "torch.log_softmax", "torch.log_softmax", "torch.diag", "torch.diag", "torch.diag", "torch.diag", "torch.diag", "torch.diag", "pl_module.log", "torch.cuda.amp.autocast", "torch.cuda.amp.autocast", "torch.cuda.amp.autocast", "torch.cuda.amp.autocast", "torch.cuda.amp.autocast", "torch.cuda.amp.autocast", "torch.diag.sum", "len", "torch.diag.sum", "len", "getattr", "sim_matrix.t"], "function", ["home.repos.pwc.inspect_result.showlab_all-in-one.modules.allinone_module.AllinoneTransformerSS.infer", "home.repos.pwc.inspect_result.showlab_all-in-one.modules.allinone_module.AllinoneTransformerSS.infer", "home.repos.pwc.inspect_result.showlab_all-in-one.modules.objectives.sim_matrix"], ["", "def", "compute_vtc", "(", "pl_module", ",", "batch", ",", "mode", "=", "\"video\"", ")", ":", "\n", "    ", "infer_text", "=", "pl_module", ".", "infer", "(", "batch", ",", "mask_text", "=", "False", ",", "mask_video", "=", "False", ",", "input_text_only", "=", "True", ",", "mode", "=", "mode", ")", "\n", "with", "torch", ".", "cuda", ".", "amp", ".", "autocast", "(", "enabled", "=", "False", ")", ":", "\n", "        ", "txt_emb", "=", "infer_text", "[", "\"text_feats\"", "]", "\n", "", "infer_vision", "=", "pl_module", ".", "infer", "(", "batch", ",", "mask_text", "=", "False", ",", "mask_video", "=", "False", ",", "input_video_only", "=", "True", ",", "mode", "=", "mode", ")", "\n", "with", "torch", ".", "cuda", ".", "amp", ".", "autocast", "(", "enabled", "=", "False", ")", ":", "\n", "        ", "img_emb", "=", "infer_vision", "[", "\"video_feats\"", "]", "\n", "# print(txt_emb.size(), img_emb.size())", "\n", "", "x", "=", "sim_matrix", "(", "txt_emb", "[", ":", ",", "0", "]", ",", "img_emb", "[", ":", ",", "0", "]", ")", "\n", "temperature", "=", "0.05", "\n", "\"Assumes input x is similarity matrix of N x M \\in [-1, 1], computed using the cosine similarity between normalised vectors\"", "\n", "i_logsm", "=", "F", ".", "log_softmax", "(", "x", "/", "temperature", ",", "dim", "=", "1", ")", "\n", "j_logsm", "=", "F", ".", "log_softmax", "(", "x", ".", "t", "(", ")", "/", "temperature", ",", "dim", "=", "1", ")", "\n", "\n", "# sum over positives", "\n", "idiag", "=", "torch", ".", "diag", "(", "i_logsm", ")", "\n", "loss_i", "=", "idiag", ".", "sum", "(", ")", "/", "len", "(", "idiag", ")", "\n", "\n", "jdiag", "=", "torch", ".", "diag", "(", "j_logsm", ")", "\n", "loss_j", "=", "jdiag", ".", "sum", "(", ")", "/", "len", "(", "jdiag", ")", "\n", "\n", "itc_loss", "=", "-", "loss_i", "-", "loss_j", "\n", "\n", "ret", "=", "{", "\n", "\"vtc_loss\"", ":", "itc_loss", ",", "\n", "}", "\n", "\n", "phase", "=", "\"train\"", "if", "pl_module", ".", "training", "else", "\"val\"", "\n", "loss", "=", "getattr", "(", "pl_module", ",", "f\"{phase}_vtc_loss\"", ")", "(", "ret", "[", "\"vtc_loss\"", "]", ")", "\n", "pl_module", ".", "log", "(", "f\"vtc/{phase}/loss\"", ",", "loss", ")", "\n", "\n", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.modules.objectives.compute_vtm_wpa": [[172, 248], ["torch.cat().to", "torch.cat().to", "torch.cat().to", "pl_module.infer", "trace.masked_select", "trace.masked_select", "pl_module.vtm_score", "torch.cross_entropy", "pl_module.log", "pl_module.log", "pl_module.log", "len", "len", "torch.stack", "torch.stack", "torch.stack", "torch.cuda.amp.autocast", "torch.cuda.amp.autocast", "torch.cuda.amp.autocast", "enumerate", "objectives.cost_matrix_cosine", "cost_matrix_cosine.masked_fill_", "objectives.ipot", "objectives.trace", "torch.cat().to.long", "getattr", "getattr", "getattr", "torch.cat", "torch.cat", "torch.cat", "torch.randperm", "torch.randperm", "torch.randperm", "zip", "batch.items", "infer[].bool", "infer[].bool", "txt_mask.sum", "txt_emb.float", "img_emb.float", "txt_pad.unsqueeze", "img_pad.unsqueeze", "cost_matrix_cosine.detach", "cost_matrix_cosine.matmul", "distance.masked_select.sum", "distance.masked_select.sum", "distance.masked_select.size", "distance.masked_select.size", "torch.cat().to.size", "ipot.detach", "torch.ones", "torch.ones", "torch.ones", "torch.zeros", "torch.zeros", "torch.zeros", "enumerate", "txt_pad.size", "txt_pad.sum", "img_pad.size", "img_pad.sum", "zip"], "function", ["home.repos.pwc.inspect_result.showlab_all-in-one.modules.allinone_module.AllinoneTransformerSS.infer", "home.repos.pwc.inspect_result.showlab_all-in-one.modules.objectives.cost_matrix_cosine", "home.repos.pwc.inspect_result.showlab_all-in-one.modules.objectives.ipot", "home.repos.pwc.inspect_result.showlab_all-in-one.modules.objectives.trace"], ["", "def", "compute_vtm_wpa", "(", "pl_module", ",", "batch", ",", "mode", "=", "\"video\"", ")", ":", "\n", "    ", "pos_len", "=", "len", "(", "batch", "[", "\"text\"", "]", ")", "//", "2", "\n", "neg_len", "=", "len", "(", "batch", "[", "\"text\"", "]", ")", "-", "pos_len", "\n", "vtm_labels", "=", "torch", ".", "cat", "(", "[", "torch", ".", "ones", "(", "pos_len", ")", ",", "torch", ".", "zeros", "(", "neg_len", ")", "]", ")", ".", "to", "(", "\n", "pl_module", ".", "device", "\n", ")", "\n", "vtm_labels", "=", "vtm_labels", "[", "torch", ".", "randperm", "(", "vtm_labels", ".", "size", "(", "0", ")", ")", "]", "\n", "\n", "# print(batch.keys())", "\n", "\n", "vtm_videos", "=", "[", "\n", "torch", ".", "stack", "(", "\n", "[", "\n", "ti", "if", "vtm_labels", "[", "i", "]", "==", "1", "else", "fi", "\n", "for", "i", ",", "(", "ti", ",", "fi", ")", "in", "enumerate", "(", "zip", "(", "bti", ",", "bfi", ")", ")", "\n", "]", "\n", ")", "\n", "for", "bti", ",", "bfi", "in", "zip", "(", "batch", "[", "\"video\"", "]", ",", "batch", "[", "\"false_video_0\"", "]", ")", "\n", "]", "\n", "\n", "batch", "=", "{", "k", ":", "v", "for", "k", ",", "v", "in", "batch", ".", "items", "(", ")", "}", "\n", "batch", "[", "\"video\"", "]", "=", "vtm_videos", "\n", "\n", "infer", "=", "pl_module", ".", "infer", "(", "batch", ",", "mask_text", "=", "False", ",", "mask_video", "=", "False", ",", "mode", "=", "mode", ")", "\n", "\n", "with", "torch", ".", "cuda", ".", "amp", ".", "autocast", "(", "enabled", "=", "False", ")", ":", "\n", "        ", "txt_emb", ",", "img_emb", "=", "infer", "[", "\"text_feats\"", "]", ",", "infer", "[", "\"video_feats\"", "]", "\n", "txt_mask", ",", "img_mask", "=", "infer", "[", "\"text_masks\"", "]", ".", "bool", "(", ")", ",", "infer", "[", "\"video_masks\"", "]", ".", "bool", "(", ")", "\n", "for", "i", ",", "_len", "in", "enumerate", "(", "txt_mask", ".", "sum", "(", "dim", "=", "1", ")", ")", ":", "\n", "            ", "txt_mask", "[", "i", ",", "_len", "-", "1", "]", "=", "False", "\n", "", "txt_mask", "[", ":", ",", "0", "]", "=", "False", "\n", "img_mask", "[", ":", ",", "0", "]", "=", "False", "\n", "if", "\"deit\"", "in", "pl_module", ".", "hparams", ".", "config", "[", "\"vit\"", "]", ":", "\n", "            ", "img_mask", "[", ":", ",", "1", "]", "=", "False", "\n", "", "txt_pad", ",", "img_pad", "=", "~", "txt_mask", ",", "~", "img_mask", "\n", "\n", "cost", "=", "cost_matrix_cosine", "(", "txt_emb", ".", "float", "(", ")", ",", "img_emb", ".", "float", "(", ")", ")", "\n", "joint_pad", "=", "txt_pad", ".", "unsqueeze", "(", "-", "1", ")", "|", "img_pad", ".", "unsqueeze", "(", "-", "2", ")", "\n", "cost", ".", "masked_fill_", "(", "joint_pad", ",", "0", ")", "\n", "\n", "txt_len", "=", "(", "txt_pad", ".", "size", "(", "1", ")", "-", "txt_pad", ".", "sum", "(", "dim", "=", "1", ",", "keepdim", "=", "False", ")", ")", ".", "to", "(", "\n", "dtype", "=", "cost", ".", "dtype", "\n", ")", "\n", "img_len", "=", "(", "img_pad", ".", "size", "(", "1", ")", "-", "img_pad", ".", "sum", "(", "dim", "=", "1", ",", "keepdim", "=", "False", ")", ")", ".", "to", "(", "\n", "dtype", "=", "cost", ".", "dtype", "\n", ")", "\n", "T", "=", "ipot", "(", "\n", "cost", ".", "detach", "(", ")", ",", "txt_len", ",", "txt_pad", ",", "img_len", ",", "img_pad", ",", "joint_pad", ",", "0.5", ",", "50", ",", "1", "\n", ")", "\n", "distance", "=", "trace", "(", "cost", ".", "matmul", "(", "T", ".", "detach", "(", ")", ")", ")", "\n", "\n", "", "dist_pos", "=", "distance", ".", "masked_select", "(", "vtm_labels", "==", "1", ")", "\n", "dist_neg", "=", "distance", ".", "masked_select", "(", "vtm_labels", "==", "0", ")", "\n", "ot_loss", "=", "(", "dist_pos", ".", "sum", "(", ")", "-", "dist_neg", ".", "sum", "(", ")", ")", "/", "(", "dist_pos", ".", "size", "(", "0", ")", "+", "dist_neg", ".", "size", "(", "0", ")", ")", "\n", "\n", "vtm_logits", "=", "pl_module", ".", "vtm_score", "(", "infer", "[", "\"cls_feats\"", "]", ")", "\n", "vtm_loss", "=", "F", ".", "cross_entropy", "(", "vtm_logits", ",", "vtm_labels", ".", "long", "(", ")", ")", "\n", "\n", "ret", "=", "{", "\n", "\"vtm_loss\"", ":", "vtm_loss", ",", "\n", "\"vtm_wpa_loss\"", ":", "0.1", "*", "ot_loss", ",", "\n", "\"vtm_logits\"", ":", "vtm_logits", ",", "\n", "\"vtm_labels\"", ":", "vtm_labels", ",", "\n", "}", "\n", "\n", "phase", "=", "\"train\"", "if", "pl_module", ".", "training", "else", "\"val\"", "\n", "loss", "=", "getattr", "(", "pl_module", ",", "f\"{phase}_vtm_loss\"", ")", "(", "ret", "[", "\"vtm_loss\"", "]", ")", "\n", "wpa_loss", "=", "getattr", "(", "pl_module", ",", "f\"{phase}_vtm_wpa_loss\"", ")", "(", "ret", "[", "\"vtm_wpa_loss\"", "]", ")", "\n", "acc", "=", "getattr", "(", "pl_module", ",", "f\"{phase}_vtm_accuracy\"", ")", "(", "\n", "ret", "[", "\"vtm_logits\"", "]", ",", "ret", "[", "\"vtm_labels\"", "]", "\n", ")", "\n", "pl_module", ".", "log", "(", "f\"vtm/{phase}/loss\"", ",", "loss", ")", "\n", "pl_module", ".", "log", "(", "f\"vtm/{phase}/wpa_loss\"", ",", "wpa_loss", ")", "\n", "pl_module", ".", "log", "(", "f\"vtm/{phase}/accuracy\"", ",", "acc", ")", "\n", "\n", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.modules.objectives.compute_imgcls": [[363, 385], ["pl_module.infer", "pl_module.img_classifier", "torch.tensor().to().long", "torch.tensor().to().long", "torch.tensor().to().long", "torch.cross_entropy", "pl_module.log", "pl_module.log", "getattr", "getattr", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor", "torch.tensor", "torch.tensor"], "function", ["home.repos.pwc.inspect_result.showlab_all-in-one.modules.allinone_module.AllinoneTransformerSS.infer"], ["# vcr qa -> r", "\n", "", "def", "compute_vcr_qa2r", "(", "pl_module", ",", "batch", ")", ":", "\n", "    ", "false_len", "=", "pl_module", ".", "hparams", ".", "config", "[", "\"draw_false_text\"", "]", "-", "1", "\n", "# stack video multiple times", "\n", "# print(batch[\"answer\"])", "\n", "vtm_labels", "=", "torch", ".", "tensor", "(", "batch", "[", "\"answer\"", "]", ")", ".", "to", "(", "pl_module", ".", "device", ")", ".", "long", "(", ")", "\n", "_bs", ",", "_t", ",", "_c", ",", "_h", ",", "_w", "=", "batch", "[", "\"video\"", "]", "[", "0", "]", ".", "shape", "\n", "# print(batch.keys())", "\n", "\n", "text_ids", "=", "torch", ".", "stack", "(", "\n", "[", "batch", "[", "f\"false_text_{i}_ids\"", "]", "for", "i", "in", "range", "(", "false_len", ")", "]", ",", "dim", "=", "1", "\n", ")", "\n", "text_masks", "=", "torch", ".", "stack", "(", "\n", "[", "batch", "[", "f\"false_text_{i}_masks\"", "]", "for", "i", "in", "range", "(", "false_len", ")", "]", ",", "dim", "=", "1", "\n", ")", "\n", "text_labels", "=", "torch", ".", "stack", "(", "\n", "[", "batch", "[", "f\"false_text_{i}_labels\"", "]", "for", "i", "in", "range", "(", "false_len", ")", "]", ",", "dim", "=", "1", "\n", ")", "\n", "\n", "# concat first option and other options", "\n", "text_ids", "=", "torch", ".", "cat", "(", "[", "batch", "[", "\"text_ids\"", "]", ".", "unsqueeze", "(", "1", ")", ",", "text_ids", "]", ",", "dim", "=", "1", ")", "\n", "text_masks", "=", "torch", ".", "cat", "(", "[", "batch", "[", "\"text_masks\"", "]", ".", "unsqueeze", "(", "1", ")", ",", "text_masks", "]", ",", "dim", "=", "1", ")", "\n", "text_labels", "=", "torch", ".", "cat", "(", "[", "batch", "[", "\"text_labels\"", "]", ".", "unsqueeze", "(", "1", ")", ",", "text_labels", "]", ",", "dim", "=", "1", ")", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.modules.objectives.compute_vcr_q2a": [[388, 474], ["torch.tensor().to().long", "torch.tensor().to().long", "torch.tensor().to().long", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "[].unsqueeze().expand", "pl_module.infer", "einops.rearrange", "torch.cross_entropy", "torch.tensor().to().long", "torch.tensor().to().long", "torch.tensor().to().long", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "[].unsqueeze().expand", "pl_module.infer", "einops.rearrange", "torch.cross_entropy", "pl_module.log", "pl_module.log", "pl_module.log", "pl_module.log", "pl_module.rank_output", "pl_module.rank_output_2", "getattr", "getattr", "getattr", "getattr", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "batch[].unsqueeze", "batch[].unsqueeze", "batch[].unsqueeze", "[].unsqueeze", "einops.rearrange", "einops.rearrange", "einops.rearrange", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "[].unsqueeze", "einops.rearrange", "einops.rearrange", "einops.rearrange", "range", "range", "range", "einops.rearrange", "range", "range", "range", "einops.rearrange", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor"], "function", ["home.repos.pwc.inspect_result.showlab_all-in-one.modules.allinone_module.AllinoneTransformerSS.infer", "home.repos.pwc.inspect_result.showlab_all-in-one.modules.allinone_module.AllinoneTransformerSS.infer"], ["infer", "=", "pl_module", ".", "infer", "(", "\n", "{", "\n", "\"video\"", ":", "[", "rearrange", "(", "videos", ",", "\"bs fs t c h w -> (bs fs) t c h w\"", ")", "]", ",", "\n", "\"text_ids\"", ":", "rearrange", "(", "text_ids", ",", "\"bs fs tl -> (bs fs) tl\"", ")", ",", "\n", "\"text_masks\"", ":", "rearrange", "(", "text_masks", ",", "\"bs fs tl -> (bs fs) tl\"", ")", ",", "\n", "\"text_labels\"", ":", "rearrange", "(", "text_labels", ",", "\"bs fs tl -> (bs fs) tl\"", ")", ",", "\n", "}", "\n", ")", "\n", "score", "=", "pl_module", ".", "rank_output", "(", "infer", "[", "\"cls_feats\"", "]", ")", "[", ":", ",", "0", "]", "\n", "score", "=", "rearrange", "(", "score", ",", "\"(bs fs) -> bs fs\"", ",", "bs", "=", "_bs", ",", "fs", "=", "false_len", "+", "1", ")", "\n", "loss", "=", "F", ".", "cross_entropy", "(", "score", ",", "vtm_labels", ")", "\n", "\n", "# print(score, vtm_labels)", "\n", "\n", "phase", "=", "\"train\"", "if", "pl_module", ".", "training", "else", "\"val\"", "\n", "acc", "=", "getattr", "(", "pl_module", ",", "f\"{phase}_multiple_choice_accuracy\"", ")", "(", "\n", "score", ",", "vtm_labels", "\n", ")", "\n", "\n", "ret", "=", "{", "\n", "\"multiple_choice_loss\"", ":", "loss", ",", "\n", "}", "\n", "\n", "phase", "=", "\"train\"", "if", "pl_module", ".", "training", "else", "\"val\"", "\n", "loss", "=", "getattr", "(", "pl_module", ",", "f\"{phase}_multiple_choice_loss\"", ")", "(", "ret", "[", "\"multiple_choice_loss\"", "]", ")", "\n", "\n", "pl_module", ".", "log", "(", "f\"multiple_choice/{phase}/loss\"", ",", "loss", ")", "\n", "pl_module", ".", "log", "(", "f\"multiple_choice/{phase}/accuracy\"", ",", "acc", ")", "\n", "return", "ret", "\n", "\n", "\n", "# mc_vqa", "\n", "", "def", "compute_mc_vqa_q2a", "(", "pl_module", ",", "batch", ")", ":", "\n", "    ", "false_len", "=", "pl_module", ".", "hparams", ".", "config", "[", "\"draw_options_text\"", "]", "-", "1", "\n", "vtm_labels", "=", "torch", ".", "tensor", "(", "batch", "[", "\"answer\"", "]", ")", ".", "to", "(", "pl_module", ".", "device", ")", ".", "long", "(", ")", "\n", "_bs", ",", "_t", ",", "_c", ",", "_h", ",", "_w", "=", "batch", "[", "\"video\"", "]", "[", "0", "]", ".", "shape", "\n", "# for qa", "\n", "text_ids", "=", "torch", ".", "stack", "(", "\n", "[", "batch", "[", "f\"options_text_{i}_ids\"", "]", "for", "i", "in", "range", "(", "false_len", ")", "]", ",", "dim", "=", "1", "\n", ")", "\n", "text_masks", "=", "torch", ".", "stack", "(", "\n", "[", "batch", "[", "f\"options_text_{i}_masks\"", "]", "for", "i", "in", "range", "(", "false_len", ")", "]", ",", "dim", "=", "1", "\n", ")", "\n", "text_labels", "=", "torch", ".", "stack", "(", "\n", "[", "batch", "[", "f\"options_text_{i}_labels\"", "]", "for", "i", "in", "range", "(", "false_len", ")", "]", ",", "dim", "=", "1", "\n", ")", "\n", "\n", "# concat first option and other options", "\n", "text_ids", "=", "torch", ".", "cat", "(", "[", "batch", "[", "\"text_ids\"", "]", ".", "unsqueeze", "(", "1", ")", ",", "text_ids", "]", ",", "dim", "=", "1", ")", "\n", "text_masks", "=", "torch", ".", "cat", "(", "[", "batch", "[", "\"text_masks\"", "]", ".", "unsqueeze", "(", "1", ")", ",", "text_masks", "]", ",", "dim", "=", "1", ")", "\n", "text_labels", "=", "torch", ".", "cat", "(", "[", "batch", "[", "\"text_labels\"", "]", ".", "unsqueeze", "(", "1", ")", ",", "text_labels", "]", ",", "dim", "=", "1", ")", "\n", "videos", "=", "batch", "[", "\"video\"", "]", "[", "0", "]", ".", "unsqueeze", "(", "1", ")", ".", "expand", "(", "_bs", ",", "false_len", "+", "1", ",", "_t", ",", "_c", ",", "_h", ",", "_w", ")", "\n", "\n", "infer", "=", "pl_module", ".", "infer", "(", "\n", "{", "\n", "\"video\"", ":", "[", "rearrange", "(", "videos", ",", "\"bs fs t c h w -> (bs fs) t c h w\"", ")", "]", ",", "\n", "\"text_ids\"", ":", "rearrange", "(", "text_ids", ",", "\"bs fs tl -> (bs fs) tl\"", ")", ",", "\n", "\"text_masks\"", ":", "rearrange", "(", "text_masks", ",", "\"bs fs tl -> (bs fs) tl\"", ")", ",", "\n", "\"text_labels\"", ":", "rearrange", "(", "text_labels", ",", "\"bs fs tl -> (bs fs) tl\"", ")", ",", "\n", "}", "\n", ")", "\n", "##  v0: use rank output", "\n", "# score = pl_module.rank_output(infer[\"cls_feats\"])[:, 0]", "\n", "## v1: use classification head", "\n", "# print(infer[\"cls_feats\"].size()) # 40, 768", "\n", "score", "=", "pl_module", ".", "mc_vqa_classifier", "(", "infer", "[", "\"cls_feats\"", "]", ")", "[", ":", ",", "0", "]", "\n", "score", "=", "rearrange", "(", "score", ",", "\"(bs fs) -> bs fs\"", ",", "bs", "=", "_bs", ",", "fs", "=", "false_len", "+", "1", ")", "\n", "qa_loss", "=", "F", ".", "cross_entropy", "(", "score", ",", "vtm_labels", ")", "\n", "# print(score, vtm_labels)", "\n", "phase", "=", "\"train\"", "if", "pl_module", ".", "training", "else", "\"val\"", "\n", "qa_acc", "=", "getattr", "(", "pl_module", ",", "f\"{phase}_mc_vqa_accuracy\"", ")", "(", "\n", "score", ",", "vtm_labels", "\n", ")", "\n", "ret", "=", "{", "\n", "\"mc_vqa_loss\"", ":", "qa_loss", ",", "\n", "}", "\n", "\n", "phase", "=", "\"train\"", "if", "pl_module", ".", "training", "else", "\"val\"", "\n", "qa_loss", "=", "getattr", "(", "pl_module", ",", "f\"{phase}_mc_vqa_loss\"", ")", "(", "ret", "[", "\"mc_vqa_loss\"", "]", ")", "\n", "pl_module", ".", "log", "(", "f\"mc_vqa/{phase}/loss\"", ",", "qa_loss", ")", "\n", "pl_module", ".", "log", "(", "f\"mc_vqa/{phase}/accuracy\"", ",", "qa_acc", ")", "\n", "return", "ret", "\n", "\n", "\n", "# msrvtt multiple choice", "\n", "", "def", "compute_multiple_choice", "(", "pl_module", ",", "batch", ")", ":", "\n", "    ", "false_len", "=", "pl_module", ".", "hparams", ".", "config", "[", "\"draw_false_text\"", "]", "-", "1", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.modules.objectives.compute_vcr_qa2r": [[477, 530], ["torch.tensor().to().long", "torch.tensor().to().long", "torch.tensor().to().long", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "[].unsqueeze().expand", "pl_module.infer", "einops.rearrange", "torch.cross_entropy", "pl_module.log", "pl_module.log", "pl_module.rank_output", "getattr", "getattr", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "batch[].unsqueeze", "batch[].unsqueeze", "batch[].unsqueeze", "[].unsqueeze", "einops.rearrange", "einops.rearrange", "einops.rearrange", "range", "range", "range", "einops.rearrange", "torch.tensor", "torch.tensor", "torch.tensor"], "function", ["home.repos.pwc.inspect_result.showlab_all-in-one.modules.allinone_module.AllinoneTransformerSS.infer"], ["vtm_labels", "=", "torch", ".", "tensor", "(", "batch", "[", "\"answer\"", "]", ")", ".", "to", "(", "pl_module", ".", "device", ")", ".", "long", "(", ")", "\n", "_bs", ",", "_t", ",", "_c", ",", "_h", ",", "_w", "=", "batch", "[", "\"video\"", "]", "[", "0", "]", "[", "0", "]", ".", "shape", "\n", "# print(batch.keys())", "\n", "\n", "text_ids", "=", "torch", ".", "stack", "(", "\n", "[", "batch", "[", "f\"false_text_{i}_ids\"", "]", "for", "i", "in", "range", "(", "false_len", ")", "]", ",", "dim", "=", "1", "\n", ")", "\n", "text_masks", "=", "torch", ".", "stack", "(", "\n", "[", "batch", "[", "f\"false_text_{i}_masks\"", "]", "for", "i", "in", "range", "(", "false_len", ")", "]", ",", "dim", "=", "1", "\n", ")", "\n", "text_labels", "=", "torch", ".", "stack", "(", "\n", "[", "batch", "[", "f\"false_text_{i}_labels\"", "]", "for", "i", "in", "range", "(", "false_len", ")", "]", ",", "dim", "=", "1", "\n", ")", "\n", "\n", "# concat first option and other options", "\n", "text_ids", "=", "torch", ".", "cat", "(", "[", "batch", "[", "\"text_ids\"", "]", ".", "unsqueeze", "(", "1", ")", ",", "text_ids", "]", ",", "dim", "=", "1", ")", "\n", "text_masks", "=", "torch", ".", "cat", "(", "[", "batch", "[", "\"text_masks\"", "]", ".", "unsqueeze", "(", "1", ")", ",", "text_masks", "]", ",", "dim", "=", "1", ")", "\n", "text_labels", "=", "torch", ".", "cat", "(", "[", "batch", "[", "\"text_labels\"", "]", ".", "unsqueeze", "(", "1", ")", ",", "text_labels", "]", ",", "dim", "=", "1", ")", "\n", "videos", "=", "batch", "[", "\"video\"", "]", "[", "0", "]", "[", "0", "]", ".", "unsqueeze", "(", "1", ")", ".", "expand", "(", "_bs", ",", "false_len", "+", "1", ",", "_t", ",", "_c", ",", "_h", ",", "_w", ")", "\n", "\n", "infer", "=", "pl_module", ".", "infer", "(", "\n", "{", "\n", "\"video\"", ":", "[", "rearrange", "(", "videos", ",", "\"bs fs t c h w -> (bs fs) t c h w\"", ")", "]", ",", "\n", "\"text_ids\"", ":", "rearrange", "(", "text_ids", ",", "\"bs fs tl -> (bs fs) tl\"", ")", ",", "\n", "\"text_masks\"", ":", "rearrange", "(", "text_masks", ",", "\"bs fs tl -> (bs fs) tl\"", ")", ",", "\n", "\"text_labels\"", ":", "rearrange", "(", "text_labels", ",", "\"bs fs tl -> (bs fs) tl\"", ")", ",", "\n", "}", "\n", ")", "\n", "score", "=", "pl_module", ".", "rank_output", "(", "infer", "[", "\"cls_feats\"", "]", ")", "[", ":", ",", "0", "]", "\n", "score", "=", "rearrange", "(", "score", ",", "\"(bs fs) -> bs fs\"", ",", "bs", "=", "_bs", ",", "fs", "=", "false_len", "+", "1", ")", "\n", "loss", "=", "F", ".", "cross_entropy", "(", "score", ",", "vtm_labels", ")", "\n", "\n", "# print(score, vtm_labels)", "\n", "\n", "phase", "=", "\"train\"", "if", "pl_module", ".", "training", "else", "\"val\"", "\n", "acc", "=", "getattr", "(", "pl_module", ",", "f\"{phase}_multiple_choice_accuracy\"", ")", "(", "\n", "score", ",", "vtm_labels", "\n", ")", "\n", "# print(acc)", "\n", "ret", "=", "{", "\n", "\"multiple_choice_loss\"", ":", "loss", ",", "\n", "}", "\n", "\n", "phase", "=", "\"train\"", "if", "pl_module", ".", "training", "else", "\"val\"", "\n", "loss", "=", "getattr", "(", "pl_module", ",", "f\"{phase}_multiple_choice_loss\"", ")", "(", "ret", "[", "\"multiple_choice_loss\"", "]", ")", "\n", "\n", "pl_module", ".", "log", "(", "f\"multiple_choice/{phase}/loss\"", ",", "loss", ")", "\n", "pl_module", ".", "log", "(", "f\"multiple_choice/{phase}/accuracy\"", ",", "acc", ")", "\n", "return", "ret", "\n", "\n", "\n", "", "def", "compute_vqa", "(", "pl_module", ",", "batch", ")", ":", "\n", "    ", "infer", "=", "pl_module", ".", "infer", "(", "batch", ",", "mask_text", "=", "False", ",", "mask_video", "=", "False", ")", "\n", "vqa_logits", "=", "pl_module", ".", "vqa_classifier", "(", "infer", "[", "\"cls_feats\"", "]", ")", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.modules.objectives.compute_mc_vqa_q2a": [[533, 583], ["torch.tensor().to().long", "torch.tensor().to().long", "torch.tensor().to().long", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "[].unsqueeze().expand", "pl_module.infer", "einops.rearrange", "torch.cross_entropy", "pl_module.log", "pl_module.log", "pl_module.mc_vqa_classifier", "getattr", "getattr", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "batch[].unsqueeze", "batch[].unsqueeze", "batch[].unsqueeze", "[].unsqueeze", "einops.rearrange", "einops.rearrange", "einops.rearrange", "range", "range", "range", "einops.rearrange", "torch.tensor", "torch.tensor", "torch.tensor"], "function", ["home.repos.pwc.inspect_result.showlab_all-in-one.modules.allinone_module.AllinoneTransformerSS.infer"], [")", ".", "to", "(", "pl_module", ".", "device", ")", "\n", "\n", "vqa_labels", "=", "batch", "[", "\"vqa_labels\"", "]", "\n", "vqa_scores", "=", "batch", "[", "\"vqa_scores\"", "]", "\n", "\n", "for", "i", ",", "(", "_label", ",", "_score", ")", "in", "enumerate", "(", "zip", "(", "vqa_labels", ",", "vqa_scores", ")", ")", ":", "\n", "        ", "for", "l", ",", "s", "in", "zip", "(", "_label", ",", "_score", ")", ":", "\n", "            ", "vqa_targets", "[", "i", ",", "l", "]", "=", "s", "\n", "\n", "", "", "vqa_loss", "=", "(", "\n", "F", ".", "binary_cross_entropy_with_logits", "(", "vqa_logits", ",", "vqa_targets", ")", "\n", "*", "vqa_targets", ".", "shape", "[", "1", "]", "\n", ")", "# https://github.com/jnhwkim/ban-vqa/blob/master/train.py#L19", "\n", "\n", "ret", "=", "{", "\n", "\"vqa_loss\"", ":", "vqa_loss", ",", "\n", "\"vqa_logits\"", ":", "vqa_logits", ",", "\n", "\"vqa_targets\"", ":", "vqa_targets", ",", "\n", "\"vqa_labels\"", ":", "vqa_labels", ",", "\n", "\"vqa_scores\"", ":", "vqa_scores", ",", "\n", "}", "\n", "\n", "phase", "=", "\"train\"", "if", "pl_module", ".", "training", "else", "\"val\"", "\n", "loss", "=", "getattr", "(", "pl_module", ",", "f\"{phase}_vqa_loss\"", ")", "(", "ret", "[", "\"vqa_loss\"", "]", ")", "\n", "score", "=", "getattr", "(", "pl_module", ",", "f\"{phase}_vqa_score\"", ")", "(", "\n", "ret", "[", "\"vqa_logits\"", "]", ",", "ret", "[", "\"vqa_targets\"", "]", "\n", ")", "\n", "pl_module", ".", "log", "(", "f\"vqa/{phase}/loss\"", ",", "loss", ")", "\n", "pl_module", ".", "log", "(", "f\"vqa/{phase}/score\"", ",", "score", ")", "\n", "\n", "return", "ret", "\n", "\n", "\n", "# add by vcop", "\n", "", "def", "compute_vcop", "(", "pl_module", ",", "batch", ")", ":", "\n", "    ", "infer", "=", "pl_module", ".", "infer", "(", "batch", ",", "mask_text", "=", "False", ",", "mask_video", "=", "False", ")", "\n", "x", "=", "infer", "[", "\"vcop_features\"", "]", "# BTLC", "\n", "b", "=", "x", ".", "size", "(", "0", ")", "\n", "# # v1: simple concat", "\n", "# gt_labels = torch.ones(b)", "\n", "# idx = torch.randperm(pl_module.hparams.config[\"num_frames\"])  # get random order", "\n", "# classes = list(itertools.permutations(list(range(len(idx.tolist())))))", "\n", "# label = classes.index(tuple(idx.tolist()))", "\n", "# h = x[0, idx, 0].view(1, -1)", "\n", "# gt_labels[0] = label", "\n", "# for index in range(1, b):", "\n", "#     idx = torch.randperm(pl_module.hparams.config[\"num_frames\"])  # get random order", "\n", "#     classes = list(itertools.permutations(list(range(len(idx.tolist())))))", "\n", "#     label = classes.index(tuple(idx.tolist()))", "\n", "#     gt_labels[index] = label", "\n", "#     h = torch.cat((h, x[index, idx, 0].view(1, -1)), dim=0)", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.modules.objectives.compute_multiple_choice": [[586, 639], ["torch.tensor().to().long", "torch.tensor().to().long", "torch.tensor().to().long", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "[].unsqueeze().expand", "pl_module.infer", "einops.rearrange", "torch.cross_entropy", "pl_module.log", "pl_module.log", "pl_module.rank_output", "getattr", "getattr", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "batch[].unsqueeze", "batch[].unsqueeze", "batch[].unsqueeze", "[].unsqueeze", "einops.rearrange", "einops.rearrange", "einops.rearrange", "range", "range", "range", "einops.rearrange", "torch.tensor", "torch.tensor", "torch.tensor"], "function", ["home.repos.pwc.inspect_result.showlab_all-in-one.modules.allinone_module.AllinoneTransformerSS.infer"], ["gt_labels", "=", "torch", ".", "ones", "(", "b", ")", "\n", "idx", "=", "torch", ".", "randperm", "(", "pl_module", ".", "hparams", ".", "config", "[", "\"num_frames\"", "]", ")", "# get random order", "\n", "classes", "=", "list", "(", "itertools", ".", "permutations", "(", "list", "(", "range", "(", "len", "(", "idx", ".", "tolist", "(", ")", ")", ")", ")", ")", ")", "\n", "label", "=", "classes", ".", "index", "(", "tuple", "(", "idx", ".", "tolist", "(", ")", ")", ")", "\n", "h", "=", "x", "[", "0", ",", "idx", ",", "0", "]", ".", "unsqueeze", "(", "0", ")", "\n", "gt_labels", "[", "0", "]", "=", "label", "\n", "for", "index", "in", "range", "(", "1", ",", "b", ")", ":", "\n", "        ", "idx", "=", "torch", ".", "randperm", "(", "pl_module", ".", "hparams", ".", "config", "[", "\"num_frames\"", "]", ")", "# get random order", "\n", "classes", "=", "list", "(", "itertools", ".", "permutations", "(", "list", "(", "range", "(", "len", "(", "idx", ".", "tolist", "(", ")", ")", ")", ")", ")", ")", "\n", "label", "=", "classes", ".", "index", "(", "tuple", "(", "idx", ".", "tolist", "(", ")", ")", ")", "\n", "gt_labels", "[", "index", "]", "=", "label", "\n", "h", "=", "torch", ".", "cat", "(", "(", "h", ",", "x", "[", "index", ",", "idx", ",", "0", "]", ".", "unsqueeze", "(", "0", ")", ")", ",", "dim", "=", "0", ")", "\n", "", "vcop_logits", "=", "pl_module", ".", "vcop_classifier", "(", "h", ")", "\n", "vcop_labels", "=", "gt_labels", ".", "to", "(", "pl_module", ".", "device", ")", ".", "long", "(", ")", "\n", "m", "=", "nn", ".", "Softmax", "(", "dim", "=", "1", ")", "\n", "if", "random", ".", "random", "(", ")", "<", "0.01", ":", "\n", "        ", "print", "(", "m", "(", "vcop_logits", ")", "[", "0", "]", ",", "vcop_labels", "[", "0", "]", ")", "\n", "# print(vcop_labels)", "\n", "", "vcop_loss", "=", "F", ".", "cross_entropy", "(", "vcop_logits", ",", "vcop_labels", ")", "\n", "ret", "=", "{", "\n", "\"vcop_loss\"", ":", "vcop_loss", ",", "\n", "\"vcop_logits\"", ":", "vcop_logits", ",", "\n", "\"vcop_labels\"", ":", "vcop_labels", ",", "\n", "}", "\n", "phase", "=", "\"train\"", "if", "pl_module", ".", "training", "else", "\"val\"", "\n", "loss", "=", "getattr", "(", "pl_module", ",", "f\"{phase}_vcop_loss\"", ")", "(", "ret", "[", "\"vcop_loss\"", "]", ")", "\n", "pl_module", ".", "log", "(", "f\"vcop/{phase}/loss\"", ",", "loss", ")", "\n", "acc", "=", "getattr", "(", "pl_module", ",", "f\"{phase}_vcop_accuracy\"", ")", "(", "\n", "ret", "[", "\"vcop_logits\"", "]", ",", "ret", "[", "\"vcop_labels\"", "]", ",", "unfilterd", "=", "False", "# if remove unknown classes", "\n", ")", "\n", "# print(acc)", "\n", "pl_module", ".", "log", "(", "f\"vcop/{phase}/accuracy\"", ",", "acc", ")", "\n", "return", "ret", "\n", "\n", "\n", "# add for dino", "\n", "", "def", "compute_dino", "(", "pl_module", ",", "batch", ")", ":", "\n", "    ", "infer", "=", "pl_module", ".", "infer", "(", "batch", ",", "mask_text", "=", "False", ",", "mask_video", "=", "False", ")", "\n", "x", "=", "infer", "[", "\"dino_features\"", "]", "# BTLC", "\n", "b", "=", "x", ".", "size", "(", "0", ")", "\n", "dino_loss", "=", "pl_module", ".", "dino_loss", "\n", "ret", "=", "{", "\n", "\"dino_loss\"", ":", "dino_loss", ",", "\n", "\"dino_logits\"", ":", "dino_logits", ",", "\n", "\"dino_labels\"", ":", "dino_labels", ",", "\n", "}", "\n", "phase", "=", "\"train\"", "if", "pl_module", ".", "training", "else", "\"val\"", "\n", "loss", "=", "getattr", "(", "pl_module", ",", "f\"{phase}_dino_loss\"", ")", "(", "ret", "[", "\"dino_loss\"", "]", ")", "\n", "pl_module", ".", "log", "(", "f\"dino/{phase}/loss\"", ",", "loss", ")", "\n", "acc", "=", "getattr", "(", "pl_module", ",", "f\"{phase}_dino_accuracy\"", ")", "(", "\n", "ret", "[", "\"dino_logits\"", "]", ",", "ret", "[", "\"dino_labels\"", "]", ",", "unfilterd", "=", "False", "# if remove unknown classes", "\n", ")", "\n", "pl_module", ".", "log", "(", "f\"dino/{phase}/accuracy\"", ",", "acc", ")", "\n", "return", "ret", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.modules.objectives.compute_vqa": [[641, 677], ["pl_module.infer", "pl_module.vqa_classifier", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "enumerate", "pl_module.log", "pl_module.log", "zip", "zip", "torch.binary_cross_entropy_with_logits", "getattr", "getattr", "torch.zeros", "torch.zeros", "torch.zeros", "len"], "function", ["home.repos.pwc.inspect_result.showlab_all-in-one.modules.allinone_module.AllinoneTransformerSS.infer"], ["# add by msrvtt qa", "\n", "", "def", "compute_openend_vqa", "(", "pl_module", ",", "batch", ")", ":", "\n", "    ", "phase", "=", "\"train\"", "if", "pl_module", ".", "training", "else", "\"val\"", "\n", "batch", "[", "\"video\"", "]", "=", "batch", "[", "\"video\"", "]", "[", "0", "]", "\n", "# batch[\"false_video_0\"] = batch[\"false_video_0\"][0]", "\n", "infer", "=", "pl_module", ".", "infer", "(", "batch", ",", "mask_text", "=", "False", ",", "mask_video", "=", "False", ",", "mode", "=", "phase", ")", "\n", "vqa_logits", "=", "pl_module", ".", "vqa_classifier", "(", "infer", "[", "\"cls_feats\"", "]", ")", "\n", "vqa_labels", "=", "torch", ".", "tensor", "(", "batch", "[", "\"vqa_labels\"", "]", ")", ".", "to", "(", "pl_module", ".", "device", ")", ".", "long", "(", ")", "\n", "# print(vqa_logits.size())", "\n", "# print(vqa_labels)", "\n", "vqa_loss", "=", "F", ".", "cross_entropy", "(", "vqa_logits", ",", "vqa_labels", ")", "\n", "ret", "=", "{", "\n", "\"vqa_loss\"", ":", "vqa_loss", ",", "\n", "\"vqa_logits\"", ":", "vqa_logits", ",", "\n", "\"vqa_labels\"", ":", "vqa_labels", ",", "\n", "}", "\n", "loss", "=", "getattr", "(", "pl_module", ",", "f\"{phase}_vqa_loss\"", ")", "(", "ret", "[", "\"vqa_loss\"", "]", ")", "\n", "pl_module", ".", "log", "(", "f\"vqa/{phase}/loss\"", ",", "loss", ")", "\n", "# print(ret[\"vqa_logits\"])", "\n", "# print(ret[\"vqa_labels\"])", "\n", "# print(ret[\"vqa_logits\"].size(), vqa_labels.size())", "\n", "acc", "=", "getattr", "(", "pl_module", ",", "f\"{phase}_openend_vqa_accuracy\"", ")", "(", "\n", "ret", "[", "\"vqa_logits\"", "]", ",", "ret", "[", "\"vqa_labels\"", "]", ",", "unfilterd", "=", "False", "# if remove unknown classes", "\n", ")", "\n", "pl_module", ".", "log", "(", "f\"vqa/{phase}/accuracy\"", ",", "acc", ")", "\n", "return", "ret", "\n", "\n", "\n", "", "def", "compute_nlvr2", "(", "pl_module", ",", "batch", ")", ":", "\n", "    ", "infer1", "=", "pl_module", ".", "infer", "(", "\n", "batch", ",", "mask_text", "=", "False", ",", "mask_video", "=", "False", ",", "video_token_type_idx", "=", "1", "\n", ")", "\n", "infer2", "=", "pl_module", ".", "infer", "(", "\n", "batch", ",", "mask_text", "=", "False", ",", "mask_video", "=", "False", ",", "video_token_type_idx", "=", "2", "\n", ")", "\n", "\n", "cls_feats", "=", "torch", ".", "cat", "(", "[", "infer1", "[", "\"cls_feats\"", "]", ",", "infer2", "[", "\"cls_feats\"", "]", "]", ",", "dim", "=", "-", "1", ")", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.modules.objectives.compute_vcop": [[680, 738], ["pl_module.infer", "x.size", "torch.ones", "torch.ones", "torch.ones", "torch.randperm", "torch.randperm", "torch.randperm", "list", "list.index", "x[].unsqueeze", "range", "pl_module.vcop_classifier", "torch.ones.to().long", "torch.Softmax", "torch.cross_entropy", "pl_module.log", "pl_module.log", "itertools.permutations", "tuple", "torch.randperm", "torch.randperm", "torch.randperm", "list", "list.index", "torch.cat", "torch.cat", "torch.cat", "random.random", "print", "getattr", "getattr", "list", "torch.randperm.tolist", "itertools.permutations", "tuple", "torch.ones.to", "range", "list", "torch.randperm.tolist", "x[].unsqueeze", "nn.Softmax.", "len", "range", "torch.randperm.tolist", "len", "torch.randperm.tolist"], "function", ["home.repos.pwc.inspect_result.showlab_all-in-one.modules.allinone_module.AllinoneTransformerSS.infer"], ["nlvr2_labels", "=", "batch", "[", "\"answers\"", "]", "\n", "nlvr2_labels", "=", "torch", ".", "tensor", "(", "nlvr2_labels", ")", ".", "to", "(", "pl_module", ".", "device", ")", ".", "long", "(", ")", "\n", "nlvr2_loss", "=", "F", ".", "cross_entropy", "(", "nlvr2_logits", ",", "nlvr2_labels", ")", "\n", "\n", "ret", "=", "{", "\n", "\"nlvr2_loss\"", ":", "nlvr2_loss", ",", "\n", "\"nlvr2_logits\"", ":", "nlvr2_logits", ",", "\n", "\"nlvr2_labels\"", ":", "nlvr2_labels", ",", "\n", "}", "\n", "\n", "phase", "=", "\"train\"", "if", "pl_module", ".", "training", "else", "\"val\"", "\n", "\n", "if", "phase", "==", "\"train\"", ":", "\n", "        ", "loss", "=", "getattr", "(", "pl_module", ",", "f\"{phase}_nlvr2_loss\"", ")", "(", "ret", "[", "\"nlvr2_loss\"", "]", ")", "\n", "acc", "=", "getattr", "(", "pl_module", ",", "f\"{phase}_nlvr2_accuracy\"", ")", "(", "\n", "ret", "[", "\"nlvr2_logits\"", "]", ",", "ret", "[", "\"nlvr2_labels\"", "]", "\n", ")", "\n", "pl_module", ".", "log", "(", "f\"nlvr2/{phase}/loss\"", ",", "loss", ")", "\n", "pl_module", ".", "log", "(", "f\"nlvr2/{phase}/accuracy\"", ",", "acc", ")", "\n", "", "else", ":", "\n", "        ", "dev_batches", "=", "[", "i", "for", "i", ",", "n", "in", "enumerate", "(", "batch", "[", "\"table_name\"", "]", ")", "if", "\"dev\"", "in", "n", "]", "\n", "test_batches", "=", "[", "i", "for", "i", ",", "n", "in", "enumerate", "(", "batch", "[", "\"table_name\"", "]", ")", "if", "\"test\"", "in", "n", "]", "\n", "\n", "if", "dev_batches", ":", "\n", "            ", "dev_loss", "=", "getattr", "(", "pl_module", ",", "f\"dev_nlvr2_loss\"", ")", "(", "\n", "F", ".", "cross_entropy", "(", "\n", "ret", "[", "\"nlvr2_logits\"", "]", "[", "dev_batches", "]", ",", "ret", "[", "\"nlvr2_labels\"", "]", "[", "dev_batches", "]", "\n", ")", "\n", ")", "\n", "dev_acc", "=", "getattr", "(", "pl_module", ",", "f\"dev_nlvr2_accuracy\"", ")", "(", "\n", "ret", "[", "\"nlvr2_logits\"", "]", "[", "dev_batches", "]", ",", "ret", "[", "\"nlvr2_labels\"", "]", "[", "dev_batches", "]", "\n", ")", "\n", "pl_module", ".", "log", "(", "f\"nlvr2/dev/loss\"", ",", "dev_loss", ")", "\n", "pl_module", ".", "log", "(", "f\"nlvr2/dev/accuracy\"", ",", "dev_acc", ")", "\n", "", "if", "test_batches", ":", "\n", "            ", "test_loss", "=", "getattr", "(", "pl_module", ",", "f\"test_nlvr2_loss\"", ")", "(", "\n", "F", ".", "cross_entropy", "(", "\n", "ret", "[", "\"nlvr2_logits\"", "]", "[", "test_batches", "]", ",", "ret", "[", "\"nlvr2_labels\"", "]", "[", "test_batches", "]", "\n", ")", "\n", ")", "\n", "test_acc", "=", "getattr", "(", "pl_module", ",", "f\"test_nlvr2_accuracy\"", ")", "(", "\n", "ret", "[", "\"nlvr2_logits\"", "]", "[", "test_batches", "]", ",", "ret", "[", "\"nlvr2_labels\"", "]", "[", "test_batches", "]", "\n", ")", "\n", "pl_module", ".", "log", "(", "f\"nlvr2/test/loss\"", ",", "test_loss", ")", "\n", "pl_module", ".", "log", "(", "f\"nlvr2/test/accuracy\"", ",", "test_acc", ")", "\n", "\n", "", "", "return", "ret", "\n", "\n", "\n", "", "def", "compute_irtr", "(", "pl_module", ",", "batch", ")", ":", "\n", "    ", "is_training_phase", "=", "pl_module", ".", "training", "\n", "# modify to module", "\n", "_bs", ",", "_t", ",", "_c", ",", "_h", ",", "_w", "=", "batch", "[", "\"video\"", "]", "[", "0", "]", ".", "shape", "\n", "false_len", "=", "pl_module", ".", "hparams", ".", "config", "[", "\"draw_false_text\"", "]", "\n", "text_ids", "=", "torch", ".", "stack", "(", "\n", "[", "batch", "[", "f\"false_text_{i}_ids\"", "]", "for", "i", "in", "range", "(", "false_len", ")", "]", ",", "dim", "=", "1", "\n", ")", "\n", "text_masks", "=", "torch", ".", "stack", "(", "\n", "[", "batch", "[", "f\"false_text_{i}_masks\"", "]", "for", "i", "in", "range", "(", "false_len", ")", "]", ",", "dim", "=", "1", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.modules.objectives.compute_dino": [[622, 640], ["pl_module.infer", "x.size", "pl_module.log", "pl_module.log", "getattr", "getattr"], "function", ["home.repos.pwc.inspect_result.showlab_all-in-one.modules.allinone_module.AllinoneTransformerSS.infer"], ["", "def", "compute_dino", "(", "pl_module", ",", "batch", ")", ":", "\n", "    ", "infer", "=", "pl_module", ".", "infer", "(", "batch", ",", "mask_text", "=", "False", ",", "mask_video", "=", "False", ")", "\n", "x", "=", "infer", "[", "\"dino_features\"", "]", "# BTLC", "\n", "b", "=", "x", ".", "size", "(", "0", ")", "\n", "dino_loss", "=", "pl_module", ".", "dino_loss", "\n", "ret", "=", "{", "\n", "\"dino_loss\"", ":", "dino_loss", ",", "\n", "\"dino_logits\"", ":", "dino_logits", ",", "\n", "\"dino_labels\"", ":", "dino_labels", ",", "\n", "}", "\n", "phase", "=", "\"train\"", "if", "pl_module", ".", "training", "else", "\"val\"", "\n", "loss", "=", "getattr", "(", "pl_module", ",", "f\"{phase}_dino_loss\"", ")", "(", "ret", "[", "\"dino_loss\"", "]", ")", "\n", "pl_module", ".", "log", "(", "f\"dino/{phase}/loss\"", ",", "loss", ")", "\n", "acc", "=", "getattr", "(", "pl_module", ",", "f\"{phase}_dino_accuracy\"", ")", "(", "\n", "ret", "[", "\"dino_logits\"", "]", ",", "ret", "[", "\"dino_labels\"", "]", ",", "unfilterd", "=", "False", "# if remove unknown classes", "\n", ")", "\n", "pl_module", ".", "log", "(", "f\"dino/{phase}/accuracy\"", ",", "acc", ")", "\n", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.modules.objectives.compute_openend_vqa": [[741, 764], ["pl_module.infer", "pl_module.vqa_classifier", "torch.tensor().to().long", "torch.tensor().to().long", "torch.tensor().to().long", "torch.cross_entropy", "pl_module.log", "pl_module.log", "getattr", "getattr", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor", "torch.tensor", "torch.tensor"], "function", ["home.repos.pwc.inspect_result.showlab_all-in-one.modules.allinone_module.AllinoneTransformerSS.infer"], ["[", "batch", "[", "f\"false_text_{i}_labels\"", "]", "for", "i", "in", "range", "(", "false_len", ")", "]", ",", "dim", "=", "1", "\n", ")", "\n", "\n", "text_ids", "=", "torch", ".", "cat", "(", "[", "batch", "[", "\"text_ids\"", "]", ".", "unsqueeze", "(", "1", ")", ",", "text_ids", "]", ",", "dim", "=", "1", ")", "\n", "text_masks", "=", "torch", ".", "cat", "(", "[", "batch", "[", "\"text_masks\"", "]", ".", "unsqueeze", "(", "1", ")", ",", "text_masks", "]", ",", "dim", "=", "1", ")", "\n", "text_labels", "=", "torch", ".", "cat", "(", "[", "batch", "[", "\"text_labels\"", "]", ".", "unsqueeze", "(", "1", ")", ",", "text_labels", "]", ",", "dim", "=", "1", ")", "\n", "videos", "=", "batch", "[", "\"video\"", "]", "[", "0", "]", ".", "unsqueeze", "(", "1", ")", ".", "expand", "(", "_bs", ",", "false_len", "+", "1", ",", "_t", ",", "_c", ",", "_h", ",", "_w", ")", "\n", "\n", "infer", "=", "pl_module", ".", "infer", "(", "\n", "{", "\n", "\"video\"", ":", "[", "rearrange", "(", "videos", ",", "\"bs fs t c h w -> (bs fs) t c h w\"", ")", "]", ",", "\n", "\"text_ids\"", ":", "rearrange", "(", "text_ids", ",", "\"bs fs tl -> (bs fs) tl\"", ")", ",", "\n", "\"text_masks\"", ":", "rearrange", "(", "text_masks", ",", "\"bs fs tl -> (bs fs) tl\"", ")", ",", "\n", "\"text_labels\"", ":", "rearrange", "(", "text_labels", ",", "\"bs fs tl -> (bs fs) tl\"", ")", ",", "\n", "}", "\n", ")", "\n", "score", "=", "pl_module", ".", "rank_output", "(", "infer", "[", "\"cls_feats\"", "]", ")", "[", ":", ",", "0", "]", "\n", "score", "=", "rearrange", "(", "score", ",", "\"(bs fs) -> bs fs\"", ",", "bs", "=", "_bs", ",", "fs", "=", "false_len", "+", "1", ")", "\n", "answer", "=", "torch", ".", "zeros", "(", "_bs", ")", ".", "to", "(", "score", ")", ".", "long", "(", ")", "\n", "irtr_loss", "=", "F", ".", "cross_entropy", "(", "score", ",", "answer", ")", "\n", "\n", "ret", "=", "{", "\n", "\"irtr_loss\"", ":", "irtr_loss", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.modules.objectives.compute_nlvr2": [[766, 824], ["pl_module.infer", "pl_module.infer", "torch.cat", "torch.cat", "torch.cat", "pl_module.nlvr2_classifier", "torch.tensor().to().long", "torch.tensor().to().long", "torch.tensor().to().long", "torch.cross_entropy", "pl_module.log", "pl_module.log", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "getattr", "getattr", "pl_module.log", "pl_module.log", "pl_module.log", "pl_module.log", "enumerate", "enumerate", "getattr", "torch.cross_entropy", "getattr", "getattr", "torch.cross_entropy", "getattr", "torch.tensor", "torch.tensor", "torch.tensor"], "function", ["home.repos.pwc.inspect_result.showlab_all-in-one.modules.allinone_module.AllinoneTransformerSS.infer", "home.repos.pwc.inspect_result.showlab_all-in-one.modules.allinone_module.AllinoneTransformerSS.infer"], ["phase", "=", "\"train\"", "if", "pl_module", ".", "training", "else", "\"val\"", "\n", "irtr_loss", "=", "getattr", "(", "pl_module", ",", "f\"{phase}_irtr_loss\"", ")", "(", "ret", "[", "\"irtr_loss\"", "]", ")", "\n", "\n", "pl_module", ".", "log", "(", "f\"irtr/{phase}/irtr_loss\"", ",", "irtr_loss", ")", "\n", "\n", "return", "ret", "\n", "\n", "\n", "# use this method to achievt multiple view testing", "\n", "", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "compute_irtr_recall", "(", "pl_module", ")", ":", "\n", "    ", "text_dset", "=", "pl_module", ".", "trainer", ".", "datamodule", ".", "dms", "[", "0", "]", ".", "make_no_false_val_dset", "(", ")", "\n", "text_dset", ".", "tokenizer", "=", "pl_module", ".", "trainer", ".", "datamodule", ".", "dms", "[", "0", "]", ".", "tokenizer", "\n", "text_loader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "\n", "text_dset", ",", "\n", "batch_size", "=", "64", ",", "\n", "num_workers", "=", "pl_module", ".", "hparams", ".", "config", "[", "\"num_workers\"", "]", ",", "\n", "pin_memory", "=", "True", ",", "\n", "collate_fn", "=", "functools", ".", "partial", "(", "\n", "text_dset", ".", "collate", ",", "\n", "mlm_collator", "=", "pl_module", ".", "trainer", ".", "datamodule", ".", "dms", "[", "0", "]", ".", "mlm_collator", ",", "\n", ")", ",", "\n", ")", "\n", "\n", "video_dset", "=", "pl_module", ".", "trainer", ".", "datamodule", ".", "dms", "[", "0", "]", ".", "make_no_false_val_dset", "(", "\n", "video_only", "=", "True", "\n", ")", "\n", "video_dset", ".", "tokenizer", "=", "pl_module", ".", "trainer", ".", "datamodule", ".", "dms", "[", "0", "]", ".", "tokenizer", "\n", "dist_sampler", "=", "DistributedSampler", "(", "video_dset", ",", "shuffle", "=", "False", ")", "\n", "video_loader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "\n", "video_dset", ",", "\n", "batch_size", "=", "1", ",", "\n", "num_workers", "=", "pl_module", ".", "hparams", ".", "config", "[", "\"num_workers\"", "]", ",", "\n", "sampler", "=", "dist_sampler", ",", "\n", "pin_memory", "=", "True", ",", "\n", "collate_fn", "=", "functools", ".", "partial", "(", "\n", "video_dset", ".", "collate", ",", "\n", "mlm_collator", "=", "pl_module", ".", "trainer", ".", "datamodule", ".", "dms", "[", "0", "]", ".", "mlm_collator", ",", "\n", ")", ",", "\n", ")", "\n", "\n", "text_preload", "=", "list", "(", ")", "\n", "for", "_b", "in", "tqdm", ".", "tqdm", "(", "text_loader", ",", "desc", "=", "\"text prefetch loop\"", ")", ":", "\n", "        ", "text_preload", ".", "append", "(", "\n", "{", "\n", "\"text_ids\"", ":", "_b", "[", "\"text_ids\"", "]", ".", "to", "(", "pl_module", ".", "device", ")", ",", "\n", "\"text_masks\"", ":", "_b", "[", "\"text_masks\"", "]", ".", "to", "(", "pl_module", ".", "device", ")", ",", "\n", "\"text_labels\"", ":", "_b", "[", "\"text_labels\"", "]", ".", "to", "(", "pl_module", ".", "device", ")", ",", "\n", "\"img_index\"", ":", "_b", "[", "\"img_index\"", "]", ",", "\n", "}", "\n", ")", "\n", "\n", "", "tiids", "=", "list", "(", ")", "\n", "for", "pre", "in", "text_preload", ":", "\n", "        ", "tiids", "+=", "pre", "[", "\"img_index\"", "]", "\n", "", "tiids", "=", "torch", ".", "tensor", "(", "tiids", ")", "\n", "\n", "video_preload", "=", "list", "(", ")", "\n", "for", "_b", "in", "tqdm", ".", "tqdm", "(", "video_loader", ",", "desc", "=", "\"video prefetch loop\"", ")", ":", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.modules.objectives.compute_irtr": [[826, 869], ["torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "[].unsqueeze().expand", "pl_module.infer", "einops.rearrange", "torch.zeros().to().long", "torch.zeros().to().long", "torch.zeros().to().long", "torch.cross_entropy", "pl_module.log", "pl_module.rank_output", "getattr", "batch[].unsqueeze", "batch[].unsqueeze", "batch[].unsqueeze", "[].unsqueeze", "einops.rearrange", "einops.rearrange", "einops.rearrange", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "range", "range", "range", "einops.rearrange", "torch.zeros", "torch.zeros", "torch.zeros"], "function", ["home.repos.pwc.inspect_result.showlab_all-in-one.modules.allinone_module.AllinoneTransformerSS.infer"], ["# print(video.size())", "\n", "(", "ie", ",", "im", ",", "_", ",", "_", ")", "=", "pl_module", ".", "transformer", ".", "visual_embed", "(", "\n", "video", ".", "to", "(", "pl_module", ".", "device", ")", ",", "\n", "max_video_len", "=", "pl_module", ".", "hparams", ".", "config", "[", "\"max_video_len\"", "]", ",", "\n", "mask_it", "=", "False", ",", "\n", ")", "\n", "video_preload", ".", "append", "(", "(", "ie", ",", "im", ",", "_b", "[", "\"img_index\"", "]", "[", "0", "]", ")", ")", "\n", "\n", "", "rank_scores", "=", "list", "(", ")", "\n", "rank_iids", "=", "list", "(", ")", "\n", "\n", "for", "img_batch", "in", "tqdm", ".", "tqdm", "(", "video_preload", ",", "desc", "=", "\"rank loop\"", ")", ":", "\n", "        ", "_ie", ",", "_im", ",", "_iid", "=", "img_batch", "\n", "num_frames", ",", "l", ",", "c", "=", "_ie", ".", "shape", "\n", "\n", "# print(_ie.size())  # 1x197x168", "\n", "# print(_im.size())  # 1x197", "\n", "_ie", ".", "unsqueeze", "(", "0", ")", "\n", "_im", ".", "unsqueeze", "(", "0", ")", "\n", "img_batch_score", "=", "list", "(", ")", "\n", "for", "txt_batch", "in", "text_preload", ":", "\n", "            ", "fblen", "=", "len", "(", "txt_batch", "[", "\"text_ids\"", "]", ")", "\n", "ie", "=", "_ie", ".", "expand", "(", "fblen", ",", "num_frames", ",", "l", ",", "c", ")", "\n", "# print(ie.size())", "\n", "im", "=", "_im", ".", "expand", "(", "fblen", ",", "num_frames", ",", "l", ")", "\n", "ie", "=", "ie", ".", "contiguous", "(", ")", ".", "view", "(", "-", "1", ",", "l", ",", "c", ")", "\n", "im", "=", "im", ".", "contiguous", "(", ")", ".", "view", "(", "-", "1", ",", "l", ")", "\n", "\n", "with", "torch", ".", "cuda", ".", "amp", ".", "autocast", "(", ")", ":", "\n", "                ", "score", "=", "pl_module", ".", "rank_output", "(", "\n", "pl_module", ".", "infer", "(", "\n", "{", "\n", "\"text_ids\"", ":", "txt_batch", "[", "\"text_ids\"", "]", ",", "\n", "\"text_masks\"", ":", "txt_batch", "[", "\"text_masks\"", "]", ",", "\n", "\"text_labels\"", ":", "txt_batch", "[", "\"text_labels\"", "]", ",", "\n", "}", ",", "\n", "video_embeds", "=", "ie", ",", "\n", "v_masks", "=", "im", ",", "\n", ")", "[", "\"cls_feats\"", "]", "\n", ")", "[", ":", ",", "0", "]", "\n", "\n", "", "img_batch_score", ".", "append", "(", "score", ")", "\n", "\n", "", "img_batch_score", "=", "torch", ".", "cat", "(", "img_batch_score", ")", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.modules.objectives.compute_irtr_recall": [[872, 1002], ["torch.no_grad", "torch.no_grad", "torch.no_grad", "pl_module.trainer.datamodule.dms[].make_no_false_val_dset", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "pl_module.trainer.datamodule.dms[].make_no_false_val_dset", "torch.utils.data.distributed.DistributedSampler", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "list", "tqdm.tqdm", "list", "torch.tensor", "torch.tensor", "torch.tensor", "list", "tqdm.tqdm", "list", "list", "tqdm.tqdm", "torch.distributed.barrier", "torch.distributed.barrier", "torch.distributed.barrier", "AllInOne.modules.dist_utils.all_gather", "AllInOne.modules.dist_utils.all_gather", "torch.tensor", "torch.tensor", "torch.tensor", "iids.view.view", "torch.tensor", "torch.tensor", "torch.tensor", "scores.view.view", "scores.view.topk", "scores.view.topk", "scores.view.topk", "[].mean", "[].mean", "[].mean", "scores.view.topk", "scores.view.topk", "scores.view.topk", "[].mean", "[].mean", "[].mean", "list.append", "pl_module.transformer.visual_embed", "list.append", "_ie.unsqueeze", "_im.unsqueeze", "list", "torch.cat", "torch.cat", "torch.cat", "list.append", "list.append", "len", "functools.partial", "functools.partial", "video.to", "len", "_ie.expand", "_im.expand", "ie.contiguous().view.contiguous().view", "im.contiguous().view.contiguous().view", "torch.cat.append", "torch.cat.cpu().tolist", "_b[].to", "_b[].to", "_b[].to", "torch.cuda.amp.autocast", "torch.cuda.amp.autocast", "torch.cuda.amp.autocast", "ie.contiguous().view.contiguous", "im.contiguous().view.contiguous", "pl_module.rank_output", "torch.cat.cpu", "pl_module.infer", "iids.view.unsqueeze", "iids.view.unsqueeze", "iids.view.unsqueeze", "torch.tensor.unsqueeze", "torch.tensor.unsqueeze", "torch.tensor.unsqueeze"], "function", ["home.repos.pwc.inspect_result.showlab_all-in-one.image.datamodule_base.BaseDataModule.make_no_false_val_dset", "home.repos.pwc.inspect_result.showlab_all-in-one.image.datamodule_base.BaseDataModule.make_no_false_val_dset", "home.repos.pwc.inspect_result.showlab_all-in-one.modules.dist_utils.all_gather", "home.repos.pwc.inspect_result.showlab_all-in-one.modules.dist_utils.all_gather", "home.repos.pwc.inspect_result.showlab_all-in-one.modules.base_vision_transformer.DistilledVisionTransformer.visual_embed", "home.repos.pwc.inspect_result.showlab_all-in-one.modules.allinone_module.AllinoneTransformerSS.infer"], ["\n", "", "torch", ".", "distributed", ".", "barrier", "(", ")", "\n", "gather_rank_scores", "=", "all_gather", "(", "rank_scores", ")", "\n", "gather_rank_iids", "=", "all_gather", "(", "rank_iids", ")", "\n", "\n", "iids", "=", "torch", ".", "tensor", "(", "gather_rank_iids", ")", "\n", "iids", "=", "iids", ".", "view", "(", "-", "1", ")", "\n", "scores", "=", "torch", ".", "tensor", "(", "gather_rank_scores", ")", "\n", "scores", "=", "scores", ".", "view", "(", "len", "(", "iids", ")", ",", "-", "1", ")", "\n", "\n", "topk10", "=", "scores", ".", "topk", "(", "10", ",", "dim", "=", "1", ")", "\n", "topk5", "=", "scores", ".", "topk", "(", "5", ",", "dim", "=", "1", ")", "\n", "topk1", "=", "scores", ".", "topk", "(", "1", ",", "dim", "=", "1", ")", "\n", "topk10_iids", "=", "tiids", "[", "topk10", ".", "indices", "]", "\n", "topk5_iids", "=", "tiids", "[", "topk5", ".", "indices", "]", "\n", "topk1_iids", "=", "tiids", "[", "topk1", ".", "indices", "]", "\n", "\n", "tr_r10", "=", "(", "iids", ".", "unsqueeze", "(", "1", ")", "==", "topk10_iids", ")", ".", "float", "(", ")", ".", "max", "(", "dim", "=", "1", ")", "[", "0", "]", ".", "mean", "(", ")", "\n", "tr_r5", "=", "(", "iids", ".", "unsqueeze", "(", "1", ")", "==", "topk5_iids", ")", ".", "float", "(", ")", ".", "max", "(", "dim", "=", "1", ")", "[", "0", "]", ".", "mean", "(", ")", "\n", "tr_r1", "=", "(", "iids", ".", "unsqueeze", "(", "1", ")", "==", "topk1_iids", ")", ".", "float", "(", ")", ".", "max", "(", "dim", "=", "1", ")", "[", "0", "]", ".", "mean", "(", ")", "\n", "\n", "topk10", "=", "scores", ".", "topk", "(", "10", ",", "dim", "=", "0", ")", "\n", "topk5", "=", "scores", ".", "topk", "(", "5", ",", "dim", "=", "0", ")", "\n", "topk1", "=", "scores", ".", "topk", "(", "1", ",", "dim", "=", "0", ")", "\n", "topk10_iids", "=", "iids", "[", "topk10", ".", "indices", "]", "\n", "topk5_iids", "=", "iids", "[", "topk5", ".", "indices", "]", "\n", "topk1_iids", "=", "iids", "[", "topk1", ".", "indices", "]", "\n", "\n", "ir_r10", "=", "(", "tiids", ".", "unsqueeze", "(", "0", ")", "==", "topk10_iids", ")", ".", "float", "(", ")", ".", "max", "(", "dim", "=", "0", ")", "[", "0", "]", ".", "mean", "(", ")", "\n", "ir_r5", "=", "(", "tiids", ".", "unsqueeze", "(", "0", ")", "==", "topk5_iids", ")", ".", "float", "(", ")", ".", "max", "(", "dim", "=", "0", ")", "[", "0", "]", ".", "mean", "(", ")", "\n", "ir_r1", "=", "(", "tiids", ".", "unsqueeze", "(", "0", ")", "==", "topk1_iids", ")", ".", "float", "(", ")", ".", "max", "(", "dim", "=", "0", ")", "[", "0", "]", ".", "mean", "(", ")", "\n", "\n", "return", "(", "ir_r1", ",", "ir_r5", ",", "ir_r10", ",", "tr_r1", ",", "tr_r5", ",", "tr_r10", ")", "\n", "\n", "\n", "", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "compute_decouple_irtr_recall", "(", "pl_module", ")", ":", "\n", "    ", "sample_dset", "=", "pl_module", ".", "trainer", ".", "datamodule", ".", "dms", "[", "0", "]", ".", "make_no_false_val_dset", "(", "\n", ")", "\n", "sample_dset", ".", "tokenizer", "=", "pl_module", ".", "trainer", ".", "datamodule", ".", "dms", "[", "0", "]", ".", "tokenizer", "\n", "dist_sampler", "=", "DistributedSampler", "(", "sample_dset", ",", "shuffle", "=", "False", ")", "\n", "sample_loader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "\n", "sample_dset", ",", "\n", "batch_size", "=", "1", ",", "\n", "num_workers", "=", "pl_module", ".", "hparams", ".", "config", "[", "\"num_workers\"", "]", ",", "\n", "sampler", "=", "dist_sampler", ",", "\n", "pin_memory", "=", "True", ",", "\n", "collate_fn", "=", "functools", ".", "partial", "(", "\n", "sample_dset", ".", "collate", ",", "\n", "mlm_collator", "=", "pl_module", ".", "trainer", ".", "datamodule", ".", "dms", "[", "0", "]", ".", "mlm_collator", ",", "\n", ")", ",", "\n", ")", "\n", "\n", "text_preload", "=", "list", "(", ")", "\n", "text_embed_arr", "=", "[", "]", "\n", "vid_embed_arr", "=", "[", "]", "\n", "count", "=", "0", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "for", "_b", "in", "tqdm", ".", "tqdm", "(", "sample_loader", ",", "desc", "=", "\"text&video prefetch loop\"", ")", ":", "\n", "# print(_b)", "\n", "# print(_b.keys())", "\n", "            ", "_b", "[", "\"text_ids\"", "]", "=", "_b", "[", "\"text_ids\"", "]", ".", "to", "(", "pl_module", ".", "device", ")", "\n", "_b", "[", "\"text_masks\"", "]", "=", "_b", "[", "\"text_masks\"", "]", ".", "to", "(", "pl_module", ".", "device", ")", "\n", "_b", "[", "\"text_labels\"", "]", "=", "_b", "[", "\"text_labels\"", "]", ".", "to", "(", "pl_module", ".", "device", ")", "\n", "_b", "[", "\"video\"", "]", "[", "0", "]", "=", "_b", "[", "\"video\"", "]", "[", "0", "]", ".", "to", "(", "pl_module", ".", "device", ")", "\n", "\n", "infer", "=", "pl_module", ".", "infer", "(", "_b", ",", "mask_text", "=", "False", ",", "mask_video", "=", "False", ")", "\n", "with", "torch", ".", "cuda", ".", "amp", ".", "autocast", "(", "enabled", "=", "False", ")", ":", "\n", "                ", "text_embed", ",", "vid_embed", "=", "infer", "[", "\"text_retrieval_feats\"", "]", ",", "infer", "[", "\"video_retrieval_feats\"", "]", "\n", "if", "vid_embed", "is", "not", "None", ":", "\n", "                    ", "vid_embed_all", "=", "[", "torch", ".", "zeros_like", "(", "vid_embed", ")", "for", "_", "in", "range", "(", "pl_module", ".", "hparams", ".", "config", "[", "\"num_gpus\"", "]", ")", "]", "\n", "torch", ".", "distributed", ".", "all_gather", "(", "vid_embed_all", ",", "vid_embed", ")", "\n", "vid_embed_all", "=", "torch", ".", "cat", "(", "vid_embed_all", ",", "dim", "=", "0", ")", "\n", "", "if", "text_embed", "is", "not", "None", ":", "\n", "                    ", "text_embed_all", "=", "[", "torch", ".", "zeros_like", "(", "text_embed", ")", "for", "_", "in", "range", "(", "pl_module", ".", "hparams", ".", "config", "[", "\"num_gpus\"", "]", ")", "]", "\n", "torch", ".", "distributed", ".", "all_gather", "(", "text_embed_all", ",", "text_embed", ")", "\n", "text_embed_all", "=", "torch", ".", "cat", "(", "text_embed_all", ",", "dim", "=", "0", ")", "\n", "", "text_embed_arr", ".", "append", "(", "text_embed_all", ".", "cpu", "(", ")", ")", "\n", "vid_embed_arr", ".", "append", "(", "vid_embed_all", ".", "cpu", "(", ")", ")", "\n", "count", "+=", "1", "\n", "", "", "", "text_embeds", "=", "torch", ".", "cat", "(", "text_embed_arr", ")", "\n", "vid_embeds", "=", "torch", ".", "cat", "(", "vid_embed_arr", ")", "\n", "# print(text_embeds.size(), vid_embeds.size())", "\n", "st2sv_sims", "=", "sim_matrix", "(", "text_embeds", ",", "vid_embeds", ")", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "for", "metric", "in", "[", "t2v_metrics", ",", "v2t_metrics", "]", ":", "\n", "        ", "metric_name", "=", "metric", ".", "__name__", "\n", "metrics", "=", "metric", "(", "st2sv_sims", ")", "\n", "if", "metric", "==", "t2v_metrics", ":", "\n", "            ", "tr_r1", ",", "tr_r5", ",", "tr_r10", ",", "tr_r50", "=", "metrics", "[", "\"R1\"", "]", ",", "metrics", "[", "\"R5\"", "]", ",", "metrics", "[", "\"R10\"", "]", ",", "metrics", "[", "\"R50\"", "]", "\n", "", "else", ":", "\n", "            ", "ir_r1", ",", "ir_r5", ",", "ir_r10", ",", "ir_r50", "=", "metrics", "[", "\"R1\"", "]", ",", "metrics", "[", "\"R5\"", "]", ",", "metrics", "[", "\"R10\"", "]", ",", "metrics", "[", "\"R50\"", "]", "\n", "# msg += f\"MedR: {metrics['MedR']:g}, MeanR: {metrics['MeanR']:.1f}\"", "\n", "", "", "return", "(", "ir_r1", ",", "ir_r5", ",", "ir_r10", ",", "tr_r1", ",", "tr_r5", ",", "tr_r10", ")", "\n", "\n", "\n", "", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "compute_zero_shot_classify_recall", "(", "pl_module", ",", "batch", ")", ":", "\n", "# process all prompt action label into text representations", "\n", "    ", "false_len", "=", "pl_module", ".", "hparams", ".", "config", "[", "\"draw_false_text\"", "]", "-", "1", "\n", "# stack video multiple times", "\n", "# print(batch[\"answer\"])", "\n", "vtm_labels", "=", "torch", ".", "tensor", "(", "batch", "[", "\"answer\"", "]", ")", ".", "to", "(", "pl_module", ".", "device", ")", ".", "long", "(", ")", "\n", "_bs", ",", "_t", ",", "_c", ",", "_h", ",", "_w", "=", "batch", "[", "\"video\"", "]", "[", "0", "]", ".", "shape", "\n", "# print(batch.keys())", "\n", "\n", "text_ids", "=", "torch", ".", "stack", "(", "\n", "[", "batch", "[", "f\"false_text_{i}_ids\"", "]", "for", "i", "in", "range", "(", "false_len", ")", "]", ",", "dim", "=", "1", "\n", ")", "\n", "text_masks", "=", "torch", ".", "stack", "(", "\n", "[", "batch", "[", "f\"false_text_{i}_masks\"", "]", "for", "i", "in", "range", "(", "false_len", ")", "]", ",", "dim", "=", "1", "\n", ")", "\n", "text_labels", "=", "torch", ".", "stack", "(", "\n", "[", "batch", "[", "f\"false_text_{i}_labels\"", "]", "for", "i", "in", "range", "(", "false_len", ")", "]", ",", "dim", "=", "1", "\n", ")", "\n", "\n", "# concat first option and other options", "\n", "text_ids", "=", "torch", ".", "cat", "(", "[", "batch", "[", "\"text_ids\"", "]", ".", "unsqueeze", "(", "1", ")", ",", "text_ids", "]", ",", "dim", "=", "1", ")", "\n", "text_masks", "=", "torch", ".", "cat", "(", "[", "batch", "[", "\"text_masks\"", "]", ".", "unsqueeze", "(", "1", ")", ",", "text_masks", "]", ",", "dim", "=", "1", ")", "\n", "text_labels", "=", "torch", ".", "cat", "(", "[", "batch", "[", "\"text_labels\"", "]", ".", "unsqueeze", "(", "1", ")", ",", "text_labels", "]", ",", "dim", "=", "1", ")", "\n", "videos", "=", "batch", "[", "\"video\"", "]", "[", "0", "]", ".", "unsqueeze", "(", "1", ")", ".", "expand", "(", "_bs", ",", "false_len", "+", "1", ",", "_t", ",", "_c", ",", "_h", ",", "_w", ")", "\n", "\n", "infer", "=", "pl_module", ".", "infer", "(", "\n", "{", "\n", "\"video\"", ":", "[", "rearrange", "(", "videos", ",", "\"bs fs t c h w -> (bs fs) t c h w\"", ")", "]", ",", "\n", "\"text_ids\"", ":", "rearrange", "(", "text_ids", ",", "\"bs fs tl -> (bs fs) tl\"", ")", ",", "\n", "\"text_masks\"", ":", "rearrange", "(", "text_masks", ",", "\"bs fs tl -> (bs fs) tl\"", ")", ",", "\n", "\"text_labels\"", ":", "rearrange", "(", "text_labels", ",", "\"bs fs tl -> (bs fs) tl\"", ")", ",", "\n", "}", "\n", ")", "\n", "score", "=", "pl_module", ".", "rank_output", "(", "infer", "[", "\"cls_feats\"", "]", ")", "[", ":", ",", "0", "]", "\n", "score", "=", "rearrange", "(", "score", ",", "\"(bs fs) -> bs fs\"", ",", "bs", "=", "_bs", ",", "fs", "=", "false_len", "+", "1", ")", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.modules.objectives.compute_decouple_irtr_recall": [[1004, 1062], ["torch.no_grad", "torch.no_grad", "torch.no_grad", "pl_module.trainer.datamodule.dms[].make_no_false_val_dset", "torch.utils.data.distributed.DistributedSampler", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "list", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "sim_matrix().detach().cpu().numpy", "torch.no_grad", "torch.no_grad", "torch.no_grad", "tqdm.tqdm", "metric", "functools.partial", "_b[].to", "_b[].to", "_b[].to", "[].to", "pl_module.infer", "sim_matrix().detach().cpu", "torch.cuda.amp.autocast", "torch.cuda.amp.autocast", "torch.cuda.amp.autocast", "text_embed_arr.append", "vid_embed_arr.append", "torch.distributed.all_gather", "torch.distributed.all_gather", "torch.distributed.all_gather", "torch.cat", "torch.cat", "torch.cat", "torch.distributed.all_gather", "torch.distributed.all_gather", "torch.distributed.all_gather", "torch.cat", "torch.cat", "torch.cat", "torch.cat.cpu", "torch.cat.cpu", "sim_matrix().detach", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "range", "range", "objectives.sim_matrix"], "function", ["home.repos.pwc.inspect_result.showlab_all-in-one.image.datamodule_base.BaseDataModule.make_no_false_val_dset", "home.repos.pwc.inspect_result.showlab_all-in-one.modules.allinone_module.AllinoneTransformerSS.infer", "home.repos.pwc.inspect_result.showlab_all-in-one.modules.dist_utils.all_gather", "home.repos.pwc.inspect_result.showlab_all-in-one.modules.dist_utils.all_gather", "home.repos.pwc.inspect_result.showlab_all-in-one.modules.dist_utils.all_gather", "home.repos.pwc.inspect_result.showlab_all-in-one.modules.dist_utils.all_gather", "home.repos.pwc.inspect_result.showlab_all-in-one.modules.dist_utils.all_gather", "home.repos.pwc.inspect_result.showlab_all-in-one.modules.dist_utils.all_gather", "home.repos.pwc.inspect_result.showlab_all-in-one.modules.objectives.sim_matrix"], ["\n", "# print(score, vtm_labels)", "\n", "\n", "phase", "=", "\"train\"", "if", "pl_module", ".", "training", "else", "\"val\"", "\n", "acc", "=", "getattr", "(", "pl_module", ",", "f\"{phase}_zero_shot_accuracy\"", ")", "(", "\n", "score", ",", "vtm_labels", "\n", ")", "\n", "# print(acc)", "\n", "ret", "=", "{", "\n", "\"multiple_choice_loss\"", ":", "loss", ",", "\n", "}", "\n", "\n", "phase", "=", "\"train\"", "if", "pl_module", ".", "training", "else", "\"val\"", "\n", "loss", "=", "getattr", "(", "pl_module", ",", "f\"{phase}_multiple_choice_loss\"", ")", "(", "ret", "[", "\"multiple_choice_loss\"", "]", ")", "\n", "\n", "pl_module", ".", "log", "(", "f\"multiple_choice/{phase}/loss\"", ",", "loss", ")", "\n", "pl_module", ".", "log", "(", "f\"multiple_choice/{phase}/accuracy\"", ",", "acc", ")", "\n", "return", "acc", "\n", "\n", "\n", "# for ind itc", "\n", "", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "compute_ind_irtr_recall", "(", "pl_module", ")", ":", "\n", "    ", "num_views", "=", "pl_module", ".", "hparams", ".", "config", "[", "\"retrieval_views\"", "]", "\n", "text_embed_arr_multi", "=", "[", "]", "\n", "vid_embed_arr_multi", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "num_views", ")", ":", "\n", "        ", "sample_dset", "=", "pl_module", ".", "trainer", ".", "datamodule", ".", "video_dms", "[", "0", "]", ".", "make_no_false_val_dset", "(", "\n", ")", "\n", "sample_dset", ".", "tokenizer", "=", "pl_module", ".", "trainer", ".", "datamodule", ".", "video_dms", "[", "0", "]", ".", "tokenizer", "\n", "dist_sampler", "=", "DistributedSampler", "(", "sample_dset", ",", "shuffle", "=", "False", ")", "\n", "sample_loader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "\n", "sample_dset", ",", "\n", "batch_size", "=", "1", ",", "\n", "num_workers", "=", "pl_module", ".", "hparams", ".", "config", "[", "\"num_workers\"", "]", ",", "\n", "sampler", "=", "dist_sampler", ",", "\n", "pin_memory", "=", "True", ",", "\n", "collate_fn", "=", "functools", ".", "partial", "(", "\n", "sample_dset", ".", "collate", ",", "\n", "mlm_collator", "=", "pl_module", ".", "trainer", ".", "datamodule", ".", "video_dms", "[", "0", "]", ".", "mlm_collator", ",", "\n", ")", ",", "\n", ")", "\n", "text_preload", "=", "list", "(", ")", "\n", "text_embed_arr", "=", "[", "]", "\n", "vid_embed_arr", "=", "[", "]", "\n", "count", "=", "0", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "for", "_b", "in", "tqdm", ".", "tqdm", "(", "sample_loader", ",", "desc", "=", "\"text&video prefetch loop\"", ")", ":", "\n", "# print(_b)", "\n", "# print(_b.keys())", "\n", "                ", "_b", "[", "\"text_ids\"", "]", "=", "_b", "[", "\"text_ids\"", "]", ".", "to", "(", "pl_module", ".", "device", ")", "\n", "_b", "[", "\"text_masks\"", "]", "=", "_b", "[", "\"text_masks\"", "]", ".", "to", "(", "pl_module", ".", "device", ")", "\n", "_b", "[", "\"text_labels\"", "]", "=", "_b", "[", "\"text_labels\"", "]", ".", "to", "(", "pl_module", ".", "device", ")", "\n", "_b", "[", "\"video\"", "]", "[", "0", "]", "=", "_b", "[", "\"video\"", "]", "[", "0", "]", ".", "to", "(", "pl_module", ".", "device", ")", "\n", "\n", "# infer = pl_module.infer(_b, mask_text=False, mask_video=False)", "\n", "\n", "infer_text", "=", "pl_module", ".", "infer", "(", "_b", ",", "mask_text", "=", "False", ",", "mask_video", "=", "False", ",", "input_text_only", "=", "True", ")", "\n", "infer_vision", "=", "pl_module", ".", "infer", "(", "_b", ",", "mask_text", "=", "False", ",", "mask_video", "=", "False", ",", "input_video_only", "=", "True", ")", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.modules.objectives.compute_zero_shot_classify_recall": [[1064, 1119], ["torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.tensor().to().long", "torch.tensor().to().long", "torch.tensor().to().long", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "[].unsqueeze().expand", "pl_module.infer", "einops.rearrange", "torch.cross_entropy", "pl_module.log", "pl_module.log", "pl_module.rank_output", "getattr", "getattr", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "batch[].unsqueeze", "batch[].unsqueeze", "batch[].unsqueeze", "[].unsqueeze", "einops.rearrange", "einops.rearrange", "einops.rearrange", "range", "range", "range", "einops.rearrange", "torch.tensor", "torch.tensor", "torch.tensor"], "function", ["home.repos.pwc.inspect_result.showlab_all-in-one.modules.allinone_module.AllinoneTransformerSS.infer"], ["with", "torch", ".", "cuda", ".", "amp", ".", "autocast", "(", "enabled", "=", "False", ")", ":", "\n", "# text_embed, vid_embed = infer_text[\"raw_cls_feats\"], infer_vision[\"raw_cls_feats\"]", "\n", "                    ", "text_embed", ",", "vid_embed", "=", "infer_text", "[", "\"text_feats\"", "]", "[", ":", ",", "0", "]", ",", "infer_vision", "[", "\"video_feats\"", "]", "[", ":", ",", "0", "]", "\n", "if", "vid_embed", "is", "not", "None", ":", "\n", "                        ", "vid_embed_all", "=", "[", "torch", ".", "zeros_like", "(", "vid_embed", ")", "for", "_", "in", "range", "(", "pl_module", ".", "hparams", ".", "config", "[", "\"num_gpus\"", "]", ")", "]", "\n", "torch", ".", "distributed", ".", "all_gather", "(", "vid_embed_all", ",", "vid_embed", ")", "\n", "vid_embed_all", "=", "torch", ".", "cat", "(", "vid_embed_all", ",", "dim", "=", "0", ")", "\n", "", "if", "text_embed", "is", "not", "None", ":", "\n", "                        ", "text_embed_all", "=", "[", "torch", ".", "zeros_like", "(", "text_embed", ")", "for", "_", "in", "range", "(", "pl_module", ".", "hparams", ".", "config", "[", "\"num_gpus\"", "]", ")", "]", "\n", "torch", ".", "distributed", ".", "all_gather", "(", "text_embed_all", ",", "text_embed", ")", "\n", "text_embed_all", "=", "torch", ".", "cat", "(", "text_embed_all", ",", "dim", "=", "0", ")", "\n", "", "text_embed_arr", ".", "append", "(", "text_embed_all", ".", "cpu", "(", ")", ")", "\n", "vid_embed_arr", ".", "append", "(", "vid_embed_all", ".", "cpu", "(", ")", ")", "\n", "count", "+=", "1", "\n", "", "", "", "text_embeds", "=", "torch", ".", "cat", "(", "text_embed_arr", ")", "\n", "vid_embeds", "=", "torch", ".", "cat", "(", "vid_embed_arr", ")", "\n", "# append for multi view", "\n", "text_embed_arr_multi", ".", "append", "(", "text_embeds", ")", "\n", "vid_embed_arr_multi", ".", "append", "(", "vid_embeds", ")", "\n", "# print(text_embeds.size(), vid_embeds.size())", "\n", "", "for", "j", "in", "range", "(", "len", "(", "text_embed_arr_multi", ")", ")", ":", "\n", "        ", "if", "j", "==", "0", ":", "\n", "            ", "st2sv_sims", "=", "sim_matrix", "(", "text_embed_arr_multi", "[", "j", "]", ",", "vid_embed_arr_multi", "[", "j", "]", ")", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "/", "len", "(", "text_embed_arr_multi", ")", "\n", "", "else", ":", "\n", "            ", "st2sv_sims", "+=", "sim_matrix", "(", "text_embed_arr_multi", "[", "j", "]", ",", "vid_embed_arr_multi", "[", "j", "]", ")", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "/", "len", "(", "text_embed_arr_multi", ")", "\n", "# st2sv_sims = sim_matrix(text_embeds, vid_embeds).detach().cpu().numpy()", "\n", "", "", "for", "metric", "in", "[", "t2v_metrics", ",", "v2t_metrics", "]", ":", "\n", "        ", "metric_name", "=", "metric", ".", "__name__", "\n", "metrics", "=", "metric", "(", "st2sv_sims", ")", "\n", "if", "metric", "==", "t2v_metrics", ":", "\n", "            ", "tr_r1", ",", "tr_r5", ",", "tr_r10", ",", "tr_r50", "=", "metrics", "[", "\"R1\"", "]", ",", "metrics", "[", "\"R5\"", "]", ",", "metrics", "[", "\"R10\"", "]", ",", "metrics", "[", "\"R50\"", "]", "\n", "", "else", ":", "\n", "            ", "ir_r1", ",", "ir_r5", ",", "ir_r10", ",", "ir_r50", "=", "metrics", "[", "\"R1\"", "]", ",", "metrics", "[", "\"R5\"", "]", ",", "metrics", "[", "\"R10\"", "]", ",", "metrics", "[", "\"R50\"", "]", "\n", "# msg += f\"MedR: {metrics['MedR']:g}, MeanR: {metrics['MeanR']:.1f}\"", "\n", "", "", "return", "(", "ir_r1", ",", "ir_r5", ",", "ir_r10", ",", "tr_r1", ",", "tr_r5", ",", "tr_r10", ")", "\n", "\n", "\n", "", "def", "init_weights", "(", "module", ")", ":", "\n", "    ", "if", "isinstance", "(", "module", ",", "(", "nn", ".", "Linear", ",", "nn", ".", "Embedding", ")", ")", ":", "\n", "        ", "module", ".", "weight", ".", "data", ".", "normal_", "(", "mean", "=", "0.0", ",", "std", "=", "0.02", ")", "\n", "", "elif", "isinstance", "(", "module", ",", "nn", ".", "LayerNorm", ")", ":", "\n", "        ", "module", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "module", ".", "weight", ".", "data", ".", "fill_", "(", "1.0", ")", "\n", "\n", "", "if", "isinstance", "(", "module", ",", "nn", ".", "Linear", ")", "and", "module", ".", "bias", "is", "not", "None", ":", "\n", "        ", "module", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "\n", "\n", "", "", "def", "vqa_test_step", "(", "pl_module", ",", "batch", ",", "output", ")", ":", "\n", "    ", "id2answer", "=", "(", "\n", "pl_module", ".", "trainer", ".", "datamodule", ".", "dm_dicts", "[", "\"vqa_trainval\"", "]", ".", "id2answer", "\n", "if", "\"vqa_trainval\"", "in", "pl_module", ".", "trainer", ".", "datamodule", ".", "dm_dicts", "\n", "else", "pl_module", ".", "trainer", ".", "datamodule", ".", "dm_dicts", "[", "\"vqa\"", "]", ".", "id2answer", "\n", ")", "\n", "vqa_logits", "=", "output", "[", "\"vqa_logits\"", "]", "\n", "vqa_preds", "=", "vqa_logits", ".", "argmax", "(", "dim", "=", "-", "1", ")", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.modules.objectives.compute_ind_irtr_recall": [[1122, 1196], ["torch.no_grad", "torch.no_grad", "torch.no_grad", "range", "range", "pl_module.trainer.datamodule.dms[].make_no_false_val_dset", "torch.utils.data.distributed.DistributedSampler", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "list", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "text_embed_arr_multi.append", "vid_embed_arr_multi.append", "len", "metric", "torch.no_grad", "torch.no_grad", "torch.no_grad", "tqdm.tqdm", "functools.partial", "_b[].to", "_b[].to", "_b[].to", "[].to", "pl_module.infer", "pl_module.infer", "sim_matrix().detach().cpu().numpy", "len", "sim_matrix().detach().cpu().numpy", "len", "torch.cuda.amp.autocast", "torch.cuda.amp.autocast", "torch.cuda.amp.autocast", "text_embed_arr.append", "vid_embed_arr.append", "torch.distributed.all_gather", "torch.distributed.all_gather", "torch.distributed.all_gather", "torch.cat", "torch.cat", "torch.cat", "torch.distributed.all_gather", "torch.distributed.all_gather", "torch.distributed.all_gather", "torch.cat", "torch.cat", "torch.cat", "torch.cat.cpu", "torch.cat.cpu", "sim_matrix().detach().cpu", "sim_matrix().detach().cpu", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "range", "range", "sim_matrix().detach", "sim_matrix().detach", "objectives.sim_matrix", "objectives.sim_matrix"], "function", ["home.repos.pwc.inspect_result.showlab_all-in-one.image.datamodule_base.BaseDataModule.make_no_false_val_dset", "home.repos.pwc.inspect_result.showlab_all-in-one.modules.allinone_module.AllinoneTransformerSS.infer", "home.repos.pwc.inspect_result.showlab_all-in-one.modules.allinone_module.AllinoneTransformerSS.infer", "home.repos.pwc.inspect_result.showlab_all-in-one.modules.dist_utils.all_gather", "home.repos.pwc.inspect_result.showlab_all-in-one.modules.dist_utils.all_gather", "home.repos.pwc.inspect_result.showlab_all-in-one.modules.dist_utils.all_gather", "home.repos.pwc.inspect_result.showlab_all-in-one.modules.dist_utils.all_gather", "home.repos.pwc.inspect_result.showlab_all-in-one.modules.dist_utils.all_gather", "home.repos.pwc.inspect_result.showlab_all-in-one.modules.dist_utils.all_gather", "home.repos.pwc.inspect_result.showlab_all-in-one.modules.objectives.sim_matrix", "home.repos.pwc.inspect_result.showlab_all-in-one.modules.objectives.sim_matrix"], ["qids", "=", "batch", "[", "\"qid\"", "]", "\n", "return", "{", "\"qids\"", ":", "qids", ",", "\"preds\"", ":", "vqa_preds", "}", "\n", "\n", "\n", "", "def", "openend_vqa_test_step", "(", "pl_module", ",", "batch", ",", "output", ")", ":", "\n", "    ", "id2answer", "=", "(", "\n", "pl_module", ".", "trainer", ".", "datamodule", ".", "dm_dicts", "[", "\"vqa_trainval\"", "]", ".", "id2answer", "\n", "if", "\"vqa_trainval\"", "in", "pl_module", ".", "trainer", ".", "datamodule", ".", "dm_dicts", "\n", "else", "pl_module", ".", "trainer", ".", "datamodule", ".", "dm_dicts", "[", "\"msrvttqa\"", "]", ".", "id2answer", "\n", ")", "\n", "vqa_logits", "=", "output", "[", "\"vqa_logits\"", "]", "\n", "vqa_preds", "=", "vqa_logits", ".", "argmax", "(", "dim", "=", "-", "1", ")", "\n", "vqa_preds", "=", "[", "id2answer", "[", "pred", ".", "item", "(", ")", "]", "for", "pred", "in", "vqa_preds", "]", "\n", "questions", "=", "batch", "[", "\"text\"", "]", "\n", "qids", "=", "batch", "[", "\"qid\"", "]", "\n", "return", "{", "\"qids\"", ":", "qids", ",", "\"preds\"", ":", "vqa_preds", "}", "\n", "\n", "\n", "", "def", "arc_test_step", "(", "pl_module", ",", "batch", ",", "output", ")", ":", "\n", "    ", "return", "output", "\n", "\n", "\n", "", "def", "vqa_test_wrapup", "(", "outs", ",", "model_name", ")", ":", "\n", "    ", "rank", "=", "torch", ".", "distributed", ".", "get_rank", "(", ")", "\n", "qids", ",", "preds", "=", "list", "(", ")", ",", "list", "(", ")", "\n", "for", "out", "in", "outs", ":", "\n", "        ", "qids", "+=", "out", "[", "\"qids\"", "]", "\n", "preds", "+=", "out", "[", "\"preds\"", "]", "\n", "\n", "", "rets", "=", "list", "(", ")", "\n", "for", "qid", ",", "pred", "in", "zip", "(", "qids", ",", "preds", ")", ":", "\n", "        ", "rets", ".", "append", "(", "{", "\"question_id\"", ":", "qid", ",", "\"answer\"", ":", "pred", "}", ")", "\n", "", "with", "open", "(", "f\"vqa_submit_{rank}.json\"", ",", "\"w\"", ")", "as", "fp", ":", "\n", "        ", "json", ".", "dump", "(", "rets", ",", "fp", ",", "indent", "=", "4", ")", "\n", "\n", "", "torch", ".", "distributed", ".", "barrier", "(", ")", "\n", "\n", "if", "rank", "==", "0", ":", "\n", "        ", "jsons", "=", "list", "(", ")", "\n", "paths", "=", "list", "(", "glob", ".", "glob", "(", "\"vqa_submit_*.json\"", ")", ")", "\n", "for", "path", "in", "paths", ":", "\n", "            ", "with", "open", "(", "path", ",", "\"r\"", ")", "as", "fp", ":", "\n", "                ", "jsons", "+=", "json", ".", "load", "(", "fp", ")", "\n", "", "", "os", ".", "makedirs", "(", "\"result\"", ",", "exist_ok", "=", "True", ")", "\n", "with", "open", "(", "f\"result/vqa_submit_{model_name}.json\"", ",", "\"w\"", ")", "as", "fp", ":", "\n", "            ", "json", ".", "dump", "(", "jsons", ",", "fp", ",", "indent", "=", "4", ")", "\n", "\n", "", "", "torch", ".", "distributed", ".", "barrier", "(", ")", "\n", "os", ".", "remove", "(", "f\"vqa_submit_{rank}.json\"", ")", "\n", "\n", "\n", "", "def", "arc_test_wrapup", "(", "outs", ",", "caplen", ",", "model_name", ")", ":", "\n", "    ", "rank", "=", "torch", ".", "distributed", ".", "get_rank", "(", ")", "\n", "iids", ",", "captions", "=", "list", "(", ")", ",", "list", "(", ")", "\n", "for", "out", "in", "outs", ":", "\n", "        ", "iids", "+=", "out", "[", "\"iid\"", "]", "\n", "captions", "+=", "out", "[", "\"captions\"", "]", "\n", "\n", "", "rets", "=", "list", "(", ")", "\n", "for", "iid", ",", "caption", "in", "zip", "(", "iids", ",", "captions", ")", ":", "\n", "        ", "rets", ".", "append", "(", "{", "\"video_id\"", ":", "iid", ",", "\"caption\"", ":", "caption", "}", ")", "\n", "", "with", "open", "(", "f\"coco_cap_len{caplen}_{rank}.json\"", ",", "\"w\"", ")", "as", "fp", ":", "\n", "        ", "json", ".", "dump", "(", "rets", ",", "fp", ",", "indent", "=", "4", ")", "\n", "\n", "", "torch", ".", "distributed", ".", "barrier", "(", ")", "\n", "\n", "if", "rank", "==", "0", ":", "\n", "        ", "jsons", "=", "list", "(", ")", "\n", "paths", "=", "list", "(", "glob", ".", "glob", "(", "f\"coco_cap_len{caplen}_*.json\"", ")", ")", "\n", "for", "path", "in", "paths", ":", "\n", "            ", "with", "open", "(", "path", ",", "\"r\"", ")", "as", "fp", ":", "\n", "                ", "jsons", "+=", "json", ".", "load", "(", "fp", ")", "\n", "", "", "os", ".", "makedirs", "(", "\"result/arc\"", ",", "exist_ok", "=", "True", ")", "\n", "jsons", "=", "sorted", "(", "jsons", ",", "key", "=", "lambda", "x", ":", "x", "[", "\"video_id\"", "]", ")", "\n", "with", "open", "(", "f\"result/arc/coco_cap_{model_name}_len{caplen}.json\"", ",", "\"w\"", ")", "as", "fp", ":", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.modules.objectives.init_weights": [[1198, 1207], ["isinstance", "module.weight.data.normal_", "isinstance", "isinstance", "module.bias.data.zero_", "module.bias.data.zero_", "module.weight.data.fill_"], "function", ["None"], ["\n", "", "", "torch", ".", "distributed", ".", "barrier", "(", ")", "\n", "os", ".", "remove", "(", "f\"coco_cap_len{caplen}_{rank}.json\"", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.showlab_all-in-one.modules.objectives.vqa_test_step": [[1209, 1221], ["vqa_logits.argmax", "pred.item"], "function", ["None"], []], "home.repos.pwc.inspect_result.showlab_all-in-one.modules.objectives.openend_vqa_test_step": [[1223, 1235], ["vqa_logits.argmax", "pred.item"], "function", ["None"], []], "home.repos.pwc.inspect_result.showlab_all-in-one.modules.objectives.arc_test_step": [[1237, 1239], ["None"], "function", ["None"], []], "home.repos.pwc.inspect_result.showlab_all-in-one.modules.objectives.vqa_test_wrapup": [[1241, 1268], ["torch.distributed.get_rank", "torch.distributed.get_rank", "torch.distributed.get_rank", "list", "zip", "torch.distributed.barrier", "torch.distributed.barrier", "torch.distributed.barrier", "torch.distributed.barrier", "torch.distributed.barrier", "torch.distributed.barrier", "os.remove", "list", "list", "list.append", "open", "json.dump", "list", "list", "os.makedirs", "glob.glob", "open", "json.dump", "open", "json.load"], "function", ["home.repos.pwc.inspect_result.showlab_all-in-one.modules.dist_utils.get_rank", "home.repos.pwc.inspect_result.showlab_all-in-one.modules.dist_utils.get_rank", "home.repos.pwc.inspect_result.showlab_all-in-one.modules.dist_utils.get_rank"], []], "home.repos.pwc.inspect_result.showlab_all-in-one.modules.objectives.arc_test_wrapup": [[1270, 1298], ["torch.distributed.get_rank", "torch.distributed.get_rank", "torch.distributed.get_rank", "list", "zip", "torch.distributed.barrier", "torch.distributed.barrier", "torch.distributed.barrier", "torch.distributed.barrier", "torch.distributed.barrier", "torch.distributed.barrier", "os.remove", "list", "list", "list.append", "open", "json.dump", "list", "list", "os.makedirs", "sorted", "glob.glob", "open", "json.dump", "open", "json.load"], "function", ["home.repos.pwc.inspect_result.showlab_all-in-one.modules.dist_utils.get_rank", "home.repos.pwc.inspect_result.showlab_all-in-one.modules.dist_utils.get_rank", "home.repos.pwc.inspect_result.showlab_all-in-one.modules.dist_utils.get_rank"], []], "home.repos.pwc.inspect_result.showlab_all-in-one.modules.cotrain_module.VCOPHeader.__init__": [[15, 29], ["super().__init__", "torch.Linear", "torch.Linear", "torch.Linear", "int", "math.factorial", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.ReLU", "torch.ReLU", "torch.ReLU"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.transforms.utils.UnNormalize.__init__"], ["    ", "def", "__init__", "(", "self", ",", "tuple_len", "=", "3", ",", "feature_size", "=", "768", ")", ":", "\n", "        ", "\"\"\"\n        In the constructor we instantiate two nn.Linear modules and assign them as\n        member variables.\n        \"\"\"", "\n", "super", "(", "VCOPHeader", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "feature_size", "=", "feature_size", "\n", "self", ".", "fc7", "=", "nn", ".", "Linear", "(", "self", ".", "feature_size", "*", "2", ",", "512", ")", "\n", "self", ".", "tuple_len", "=", "tuple_len", "\n", "pair_num", "=", "int", "(", "tuple_len", "*", "(", "tuple_len", "-", "1", ")", "/", "2", ")", "\n", "self", ".", "class_num", "=", "math", ".", "factorial", "(", "tuple_len", ")", "\n", "self", ".", "fc8", "=", "nn", ".", "Linear", "(", "512", "*", "pair_num", ",", "self", ".", "class_num", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "p", "=", "0.5", ")", "\n", "self", ".", "relu", "=", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.modules.cotrain_module.VCOPHeader.forward": [[30, 43], ["range", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "cotrain_module.VCOPHeader.dropout", "cotrain_module.VCOPHeader.fc8", "range", "cotrain_module.VCOPHeader.fc7", "cotrain_module.VCOPHeader.relu", "pf.append", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "\"\"\"\n        \"\"\"", "\n", "pf", "=", "[", "]", "# pairwise concat", "\n", "for", "i", "in", "range", "(", "self", ".", "tuple_len", ")", ":", "\n", "            ", "for", "j", "in", "range", "(", "i", "+", "1", ",", "self", ".", "tuple_len", ")", ":", "\n", "                ", "pf", ".", "append", "(", "torch", ".", "cat", "(", "[", "x", "[", ":", ",", "i", "]", ",", "x", "[", ":", ",", "j", "]", "]", ",", "dim", "=", "1", ")", ")", "\n", "", "", "pf", "=", "[", "self", ".", "fc7", "(", "i", ")", "for", "i", "in", "pf", "]", "\n", "pf", "=", "[", "self", ".", "relu", "(", "i", ")", "for", "i", "in", "pf", "]", "\n", "h", "=", "torch", ".", "cat", "(", "pf", ",", "dim", "=", "1", ")", "\n", "h", "=", "self", ".", "dropout", "(", "h", ")", "\n", "h", "=", "self", ".", "fc8", "(", "h", ")", "# logits", "\n", "return", "h", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.modules.cotrain_module.CoTrainTransformerSS.__init__": [[46, 290], ["pytorch_lightning.LightningModule.__init__", "cotrain_module.CoTrainTransformerSS.save_hyperparameters", "transformers.models.bert.modeling_bert.BertConfig", "transformers.models.bert.modeling_bert.BertEmbeddings", "cotrain_module.CoTrainTransformerSS.text_embeddings.apply", "torch.Embedding", "torch.Embedding", "torch.Embedding", "cotrain_module.CoTrainTransformerSS.token_type_embeddings.apply", "CoTrain.modules.heads.Pooler", "cotrain_module.CoTrainTransformerSS.pooler.apply", "CoTrain.modules.cotrain_utils.set_metrics", "list", "CoTrain.modules.temporal_roll.TemporalRoll", "CoTrain.modules.heads.MLMHead", "cotrain_module.CoTrainTransformerSS.mlm_score.apply", "CoTrain.modules.heads.vtmHead", "cotrain_module.CoTrainTransformerSS.vtm_score.apply", "CoTrain.modules.heads.MPPHead", "cotrain_module.CoTrainTransformerSS.mpp_score.apply", "print", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "cotrain_module.CoTrainTransformerSS.txt_proj.apply", "cotrain_module.CoTrainTransformerSS.vid_proj.apply", "print", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "CoTrain.modules.cotrain_utils.state_dict_dino_fix", "cotrain_module.CoTrainTransformerSS.load_state_dict", "cotrain_module.CoTrainTransformerSS.named_parameters", "CoTrain.modules.heads.vtmHead", "cotrain_module.CoTrainTransformerSS.vtm_score.apply", "CoTrain.modules.heads.vtmHead", "cotrain_module.CoTrainTransformerSS.vtm_score.apply", "CoTrain.modules.heads.vtmHead", "cotrain_module.CoTrainTransformerSS.vtm_score.apply", "torch.Sequential", "torch.Sequential", "torch.Sequential", "cotrain_module.CoTrainTransformerSS.vqa_classifier.apply", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "cotrain_module.VCOPHeader", "torch.Sequential", "torch.Sequential", "torch.Sequential", "cotrain_module.CoTrainTransformerSS.mc_vqa_classifier.apply", "torch.Sequential", "torch.Sequential", "torch.Sequential", "cotrain_module.CoTrainTransformerSS.vqa_classifier.apply", "torch.Sequential", "torch.Sequential", "torch.Sequential", "cotrain_module.CoTrainTransformerSS.nlvr2_classifier.apply", "torch.Embedding", "torch.Embedding", "torch.Embedding", "cotrain_module.CoTrainTransformerSS.token_type_embeddings.apply", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "print", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "print", "print", "print", "cotrain_module.CoTrainTransformerSS.state_dict().items", "CoTrain.modules.cotrain_utils.state_dict_dino_fix", "cotrain_module.CoTrainTransformerSS.load_state_dict", "getattr", "cotrain_module.CoTrainTransformerSS.text_embeddings.position_embeddings.weight.size", "state_dict[].size", "state_dict.pop", "state_dict.pop", "cotrain_module.CoTrainTransformerSS.state_dict", "torch.Linear", "torch.Linear", "torch.Linear", "torch.LayerNorm", "torch.LayerNorm", "torch.LayerNorm", "torch.GELU", "torch.GELU", "torch.GELU", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Linear", "torch.Linear", "torch.Linear", "torch.LayerNorm", "torch.LayerNorm", "torch.LayerNorm", "torch.GELU", "torch.GELU", "torch.GELU", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Linear", "torch.Linear", "torch.Linear", "torch.LayerNorm", "torch.LayerNorm", "torch.LayerNorm", "torch.GELU", "torch.GELU", "torch.GELU", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.LayerNorm", "torch.LayerNorm", "torch.LayerNorm", "torch.GELU", "torch.GELU", "torch.GELU", "torch.Linear", "torch.Linear", "torch.Linear", "print", "cotrain_module.CoTrainTransformerSS.state_dict", "cotrain_module.CoTrainTransformerSS.state_dict", "getattr", "print"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.transforms.utils.UnNormalize.__init__", "home.repos.pwc.inspect_result.showlab_all-in-one.modules.allinone_utils.set_metrics", "home.repos.pwc.inspect_result.showlab_all-in-one.modules.cotrain_utils.state_dict_dino_fix", "home.repos.pwc.inspect_result.showlab_all-in-one.modules.cotrain_utils.state_dict_dino_fix"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "save_hyperparameters", "(", ")", "\n", "\n", "bert_config", "=", "BertConfig", "(", "\n", "vocab_size", "=", "config", "[", "\"vocab_size\"", "]", ",", "\n", "hidden_size", "=", "config", "[", "\"hidden_size\"", "]", ",", "\n", "num_hidden_layers", "=", "config", "[", "\"num_layers\"", "]", ",", "\n", "num_attention_heads", "=", "config", "[", "\"num_heads\"", "]", ",", "\n", "intermediate_size", "=", "config", "[", "\"hidden_size\"", "]", "*", "config", "[", "\"mlp_ratio\"", "]", ",", "\n", "max_position_embeddings", "=", "config", "[", "\"max_text_len\"", "]", ",", "\n", "hidden_dropout_prob", "=", "config", "[", "\"drop_rate\"", "]", ",", "\n", "attention_probs_dropout_prob", "=", "config", "[", "\"drop_rate\"", "]", ",", "\n", ")", "\n", "\n", "self", ".", "text_embeddings", "=", "BertEmbeddings", "(", "bert_config", ")", "\n", "self", ".", "text_embeddings", ".", "apply", "(", "objectives", ".", "init_weights", ")", "\n", "\n", "self", ".", "token_type_embeddings", "=", "nn", ".", "Embedding", "(", "2", ",", "config", "[", "\"hidden_size\"", "]", ")", "\n", "self", ".", "token_type_embeddings", ".", "apply", "(", "objectives", ".", "init_weights", ")", "\n", "\n", "flag", "=", "0", "\n", "if", "self", ".", "hparams", ".", "config", "[", "\"load_path\"", "]", "==", "\"\"", ":", "\n", "            ", "while", "not", "flag", "==", "1", ":", "\n", "                ", "try", ":", "\n", "                    ", "self", ".", "transformer", "=", "getattr", "(", "vit", ",", "self", ".", "hparams", ".", "config", "[", "\"vit\"", "]", ")", "(", "\n", "pretrained", "=", "True", ",", "config", "=", "self", ".", "hparams", ".", "config", "\n", ")", "\n", "flag", "=", "1", "\n", "", "except", ":", "\n", "                    ", "print", "(", "\"load pretrained failed, try again\"", ")", "\n", "flag", "=", "0", "\n", "", "", "", "else", ":", "\n", "            ", "self", ".", "transformer", "=", "getattr", "(", "vit", ",", "self", ".", "hparams", ".", "config", "[", "\"vit\"", "]", ")", "(", "\n", "pretrained", "=", "False", ",", "config", "=", "self", ".", "hparams", ".", "config", "\n", ")", "\n", "\n", "", "self", ".", "pooler", "=", "heads", ".", "Pooler", "(", "config", "[", "\"hidden_size\"", "]", ")", "\n", "self", ".", "pooler", ".", "apply", "(", "objectives", ".", "init_weights", ")", "\n", "\n", "# num frames", "\n", "self", ".", "num_frames", "=", "config", "[", "\"num_frames\"", "]", "# a global variable to identify if image/video", "\n", "\n", "if", "config", "[", "\"loss_names\"", "]", "[", "\"mlm\"", "]", ">", "0", ":", "\n", "            ", "self", ".", "mlm_score", "=", "heads", ".", "MLMHead", "(", "bert_config", ")", "\n", "self", ".", "mlm_score", ".", "apply", "(", "objectives", ".", "init_weights", ")", "\n", "\n", "", "if", "config", "[", "\"loss_names\"", "]", "[", "\"vtm\"", "]", ">", "0", ":", "\n", "            ", "self", ".", "vtm_score", "=", "heads", ".", "vtmHead", "(", "config", "[", "\"hidden_size\"", "]", ")", "\n", "self", ".", "vtm_score", ".", "apply", "(", "objectives", ".", "init_weights", ")", "\n", "\n", "", "if", "config", "[", "\"loss_names\"", "]", "[", "\"mpp\"", "]", ">", "0", ":", "\n", "            ", "self", ".", "mpp_score", "=", "heads", ".", "MPPHead", "(", "bert_config", ")", "\n", "self", ".", "mpp_score", ".", "apply", "(", "objectives", ".", "init_weights", ")", "\n", "\n", "# vtc may also used for pretrain", "\n", "# == for video text contrastive learning", "\n", "", "if", "config", "[", "\"loss_names\"", "]", "[", "\"vtc\"", "]", ">", "0", ":", "\n", "            ", "print", "(", "\"initalize video project and txt projection\"", ")", "\n", "# v1", "\n", "self", ".", "txt_proj", "=", "nn", ".", "Linear", "(", "config", "[", "\"hidden_size\"", "]", ",", "config", "[", "\"shared_embedding_dim\"", "]", ")", "\n", "self", ".", "vid_proj", "=", "nn", ".", "Linear", "(", "config", "[", "\"hidden_size\"", "]", ",", "config", "[", "\"shared_embedding_dim\"", "]", ")", "\n", "# v2", "\n", "# self.vid_proj = nn.Sequential(", "\n", "#     nn.Dropout(0.5),", "\n", "#     nn.Linear(config[\"hidden_size\"], config[\"hidden_size\"] // 2),", "\n", "#     nn.LayerNorm(config[\"hidden_size\"] // 2),", "\n", "#     nn.GELU(),", "\n", "#     nn.Linear(config[\"hidden_size\"] // 2, config[\"shared_embedding_dim\"]),", "\n", "# )", "\n", "# self.txt_proj = nn.Sequential(", "\n", "#     nn.Dropout(0.5),", "\n", "#     nn.Linear(config[\"hidden_size\"], config[\"hidden_size\"] // 2),", "\n", "#     nn.LayerNorm(config[\"hidden_size\"] // 2),", "\n", "#     nn.GELU(),", "\n", "#     nn.Linear(config[\"hidden_size\"] // 2, config[\"shared_embedding_dim\"]),", "\n", "# )", "\n", "self", ".", "txt_proj", ".", "apply", "(", "objectives", ".", "init_weights", ")", "\n", "self", ".", "vid_proj", ".", "apply", "(", "objectives", ".", "init_weights", ")", "\n", "# == end", "\n", "", "if", "(", "\n", "self", ".", "hparams", ".", "config", "[", "\"load_path\"", "]", "!=", "\"\"", "\n", "and", "not", "self", ".", "hparams", ".", "config", "[", "\"test_only\"", "]", "\n", ")", ":", "\n", "            ", "print", "(", "\"0\"", "*", "200", ")", "\n", "ckpt", "=", "torch", ".", "load", "(", "self", ".", "hparams", ".", "config", "[", "\"load_path\"", "]", ",", "map_location", "=", "\"cpu\"", ")", "\n", "state_dict", "=", "ckpt", "[", "\"state_dict\"", "]", "\n", "# if downstream max text token length not consistent with pretrain", "\n", "if", "self", ".", "text_embeddings", ".", "position_embeddings", ".", "weight", ".", "size", "(", ")", "!=", "state_dict", "[", "'text_embeddings.position_embeddings.weight'", "]", ".", "size", "(", ")", ":", "\n", "                ", "state_dict", ".", "pop", "(", "'text_embeddings.position_embeddings.weight'", ",", "None", ")", "\n", "state_dict", ".", "pop", "(", "'text_embeddings.position_ids'", ",", "None", ")", "\n", "", "new_state_dict", "=", "state_dict_dino_fix", "(", "state_dict", ",", "self", ".", "state_dict", "(", ")", ")", "\n", "# new_state_dict = self._inflate_positional_embeds(state_dict)", "\n", "self", ".", "load_state_dict", "(", "new_state_dict", ",", "strict", "=", "False", ")", "\n", "# self.load_state_dict(state_dict, strict=False)", "\n", "", "if", "self", ".", "hparams", ".", "config", "[", "\"linear_evaluation\"", "]", ":", "\n", "            ", "for", "name", ",", "param", "in", "self", ".", "named_parameters", "(", ")", ":", "\n", "# only train project layer", "\n", "                ", "if", "'mlm_score'", "in", "name", "or", "'vtm_score'", "in", "name", "or", "'mpp_score'", "in", "name", ":", "\n", "                    ", "param", ".", "requires_grad", "=", "True", "\n", "", "elif", "'txt_proj'", "in", "name", "or", "'vid_proj'", "in", "name", ":", "\n", "                    ", "param", ".", "requires_grad", "=", "True", "\n", "", "elif", "'pooler'", "in", "name", ":", "\n", "                    ", "param", ".", "requires_grad", "=", "True", "\n", "", "else", ":", "\n", "                    ", "param", ".", "requires_grad", "=", "False", "\n", "# flag = False", "\n", "# for name, param in self.named_parameters():", "\n", "#     if '20' in name:", "\n", "#         flag = True", "\n", "#     param.requires_grad = flag", "\n", "# trainable_params = filter(lambda p: p.requires_grad, self.parameters())", "\n", "# ===================== Downstream ===================== #", "\n", "\n", "", "", "", "hs", "=", "self", ".", "hparams", ".", "config", "[", "\"hidden_size\"", "]", "\n", "# print(config[\"loss_names\"])", "\n", "if", "config", "[", "\"loss_names\"", "]", "[", "\"multiple_choice\"", "]", ">", "0", ":", "\n", "            ", "self", ".", "vtm_score", "=", "heads", ".", "vtmHead", "(", "config", "[", "\"hidden_size\"", "]", ")", "\n", "self", ".", "vtm_score", ".", "apply", "(", "objectives", ".", "init_weights", ")", "\n", "\n", "# alex:  vcr q2a task", "\n", "", "if", "config", "[", "\"loss_names\"", "]", "[", "\"vcr_q2a\"", "]", ">", "0", ":", "\n", "            ", "self", ".", "vtm_score", "=", "heads", ".", "vtmHead", "(", "config", "[", "\"hidden_size\"", "]", ")", "\n", "self", ".", "vtm_score", ".", "apply", "(", "objectives", ".", "init_weights", ")", "\n", "\n", "# alex:  tvqa", "\n", "", "if", "config", "[", "\"loss_names\"", "]", "[", "\"mc_vqa\"", "]", ">", "0", ":", "\n", "            ", "self", ".", "vtm_score", "=", "heads", ".", "vtmHead", "(", "config", "[", "\"hidden_size\"", "]", ")", "\n", "self", ".", "vtm_score", ".", "apply", "(", "objectives", ".", "init_weights", ")", "\n", "\n", "", "if", "self", ".", "hparams", ".", "config", "[", "\"loss_names\"", "]", "[", "\"vqa\"", "]", ">", "0", ":", "\n", "            ", "vs", "=", "self", ".", "hparams", ".", "config", "[", "\"vqav2_label_size\"", "]", "\n", "self", ".", "vqa_classifier", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "hs", ",", "hs", "*", "2", ")", ",", "\n", "nn", ".", "LayerNorm", "(", "hs", "*", "2", ")", ",", "\n", "nn", ".", "GELU", "(", ")", ",", "\n", "nn", ".", "Linear", "(", "hs", "*", "2", ",", "vs", ")", ",", "\n", ")", "\n", "self", ".", "vqa_classifier", ".", "apply", "(", "objectives", ".", "init_weights", ")", "\n", "\n", "# alex: add for vcr: q2a", "\n", "", "if", "self", ".", "hparams", ".", "config", "[", "\"loss_names\"", "]", "[", "\"vcr_q2a\"", "]", ">", "0", ":", "\n", "# for q2a", "\n", "            ", "self", ".", "rank_output", "=", "nn", ".", "Linear", "(", "hs", ",", "1", ")", "\n", "self", ".", "rank_output", ".", "weight", ".", "data", "=", "self", ".", "vtm_score", ".", "fc", ".", "weight", ".", "data", "[", "1", ":", ",", ":", "]", "\n", "self", ".", "rank_output", ".", "bias", ".", "data", "=", "self", ".", "vtm_score", ".", "fc", ".", "bias", ".", "data", "[", "1", ":", "]", "\n", "# for qa2r", "\n", "self", ".", "rank_output_2", "=", "nn", ".", "Linear", "(", "hs", ",", "1", ")", "\n", "self", ".", "rank_output_2", ".", "weight", ".", "data", "=", "self", ".", "vtm_score", ".", "fc", ".", "weight", ".", "data", "[", "1", ":", ",", ":", "]", "\n", "self", ".", "rank_output_2", ".", "bias", ".", "data", "=", "self", ".", "vtm_score", ".", "fc", ".", "bias", ".", "data", "[", "1", ":", "]", "\n", "\n", "self", ".", "margin", "=", "0.2", "\n", "\n", "# add for vcop prediction", "\n", "", "if", "self", ".", "hparams", ".", "config", "[", "\"loss_names\"", "]", "[", "\"vcop\"", "]", ">", "0", ":", "\n", "            ", "self", ".", "vcop_classifier", "=", "VCOPHeader", "(", "tuple_len", "=", "self", ".", "num_frames", ",", "feature_size", "=", "hs", ")", "\n", "\n", "# add for tvqa", "\n", "", "if", "self", ".", "hparams", ".", "config", "[", "\"loss_names\"", "]", "[", "\"mc_vqa\"", "]", ">", "0", ":", "\n", "# # v1: for q2a with vtm_score", "\n", "# self.rank_output = nn.Linear(hs, 1)", "\n", "# self.rank_output.weight.data = self.vtm_score.fc.weight.data[1:, :]", "\n", "# self.rank_output.bias.data = self.vtm_score.fc.bias.data[1:]", "\n", "# self.dropout = nn.Dropout(0.1)", "\n", "            ", "self", ".", "mc_vqa_classifier", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Dropout", "(", "0.1", ")", ",", "\n", "nn", ".", "Linear", "(", "hs", ",", "256", ")", ",", "\n", "nn", ".", "LayerNorm", "(", "256", ")", ",", "\n", "nn", ".", "GELU", "(", ")", ",", "\n", "nn", ".", "Linear", "(", "256", ",", "1", ")", ",", "\n", ")", "\n", "self", ".", "mc_vqa_classifier", ".", "apply", "(", "objectives", ".", "init_weights", ")", "\n", "\n", "# alex: add for openend_vqa", "\n", "", "if", "self", ".", "hparams", ".", "config", "[", "\"loss_names\"", "]", "[", "\"openend_vqa\"", "]", ">", "0", ":", "\n", "            ", "vs", "=", "self", ".", "hparams", ".", "config", "[", "\"msrvttqa_label_size\"", "]", "\n", "# self.vqa_classifier = nn.Sequential(", "\n", "#     nn.Dropout(0.5),", "\n", "#     nn.Linear(hs, hs * 2),", "\n", "#     nn.LayerNorm(hs * 2),", "\n", "#     nn.GELU(),", "\n", "#     nn.Linear(hs * 2, vs),", "\n", "# )", "\n", "# small dataset", "\n", "self", ".", "vqa_classifier", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Dropout", "(", "0.5", ")", ",", "\n", "nn", ".", "Linear", "(", "hs", ",", "hs", "//", "2", ")", ",", "\n", "nn", ".", "LayerNorm", "(", "hs", "//", "2", ")", ",", "\n", "nn", ".", "GELU", "(", ")", ",", "\n", "nn", ".", "Linear", "(", "hs", "//", "2", ",", "vs", ")", ",", "\n", ")", "\n", "self", ".", "vqa_classifier", ".", "apply", "(", "objectives", ".", "init_weights", ")", "\n", "\n", "", "if", "self", ".", "hparams", ".", "config", "[", "\"loss_names\"", "]", "[", "\"nlvr2\"", "]", ">", "0", ":", "\n", "            ", "self", ".", "nlvr2_classifier", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "hs", "*", "2", ",", "hs", "*", "2", ")", ",", "\n", "nn", ".", "LayerNorm", "(", "hs", "*", "2", ")", ",", "\n", "nn", ".", "GELU", "(", ")", ",", "\n", "nn", ".", "Linear", "(", "hs", "*", "2", ",", "2", ")", ",", "\n", ")", "\n", "self", ".", "nlvr2_classifier", ".", "apply", "(", "objectives", ".", "init_weights", ")", "\n", "emb_data", "=", "self", ".", "token_type_embeddings", ".", "weight", ".", "data", "\n", "self", ".", "token_type_embeddings", "=", "nn", ".", "Embedding", "(", "3", ",", "hs", ")", "\n", "self", ".", "token_type_embeddings", ".", "apply", "(", "objectives", ".", "init_weights", ")", "\n", "self", ".", "token_type_embeddings", ".", "weight", ".", "data", "[", "0", ",", ":", "]", "=", "emb_data", "[", "0", ",", ":", "]", "\n", "self", ".", "token_type_embeddings", ".", "weight", ".", "data", "[", "1", ",", ":", "]", "=", "emb_data", "[", "1", ",", ":", "]", "\n", "self", ".", "token_type_embeddings", ".", "weight", ".", "data", "[", "2", ",", ":", "]", "=", "emb_data", "[", "1", ",", ":", "]", "\n", "\n", "", "if", "self", ".", "hparams", ".", "config", "[", "\"loss_names\"", "]", "[", "\"irtr\"", "]", ">", "0", ":", "\n", "            ", "self", ".", "rank_output", "=", "nn", ".", "Linear", "(", "hs", ",", "1", ")", "\n", "self", ".", "rank_output", ".", "weight", ".", "data", "=", "self", ".", "vtm_score", ".", "fc", ".", "weight", ".", "data", "[", "1", ":", ",", ":", "]", "\n", "self", ".", "rank_output", ".", "bias", ".", "data", "=", "self", ".", "vtm_score", ".", "fc", ".", "bias", ".", "data", "[", "1", ":", "]", "\n", "self", ".", "margin", "=", "0.2", "\n", "# for p in self.vtm_score.parameters(): # alex: requires_grad = true?", "\n", "#     p.requires_grad = False", "\n", "\n", "# test msrvtt multiple choice without finetune", "\n", "", "if", "self", ".", "hparams", ".", "config", "[", "\"loss_names\"", "]", "[", "\"multiple_choice\"", "]", ">", "0", ":", "\n", "            ", "self", ".", "rank_output", "=", "nn", ".", "Linear", "(", "hs", ",", "1", ")", "\n", "self", ".", "rank_output", ".", "weight", ".", "data", "=", "self", ".", "vtm_score", ".", "fc", ".", "weight", ".", "data", "[", "1", ":", ",", ":", "]", "\n", "self", ".", "rank_output", ".", "bias", ".", "data", "=", "self", ".", "vtm_score", ".", "fc", ".", "bias", ".", "data", "[", "1", ":", "]", "\n", "self", ".", "margin", "=", "0.2", "\n", "\n", "", "cotrain_utils", ".", "set_metrics", "(", "self", ")", "\n", "self", ".", "current_tasks", "=", "list", "(", ")", "\n", "\n", "self", ".", "temporal_roll_module", "=", "TemporalRoll", "(", "n_segment", "=", "self", ".", "num_frames", ",", "v", "=", "0", ")", "\n", "\n", "# ===================== load downstream (test_only) ======================", "\n", "\n", "if", "self", ".", "hparams", ".", "config", "[", "\"load_path\"", "]", "!=", "\"\"", "and", "self", ".", "hparams", ".", "config", "[", "\"test_only\"", "]", ":", "\n", "            ", "print", "(", "\"====load checkpoint=====\"", ")", "\n", "ckpt", "=", "torch", ".", "load", "(", "self", ".", "hparams", ".", "config", "[", "\"load_path\"", "]", ",", "map_location", "=", "\"cpu\"", ")", "\n", "state_dict", "=", "ckpt", "[", "\"state_dict\"", "]", "\n", "print", "(", "'*'", "*", "30", ")", "\n", "print", "(", "\"current state dict\"", ")", "\n", "print", "(", "'*'", "*", "30", ")", "\n", "for", "k", ",", "v", "in", "self", ".", "state_dict", "(", ")", ".", "items", "(", ")", ":", "\n", "                ", "print", "(", "k", ")", "\n", "# temporal embed and fix model ?", "\n", "# new_state_dict = state_dict_data_parallel_fix(state_dict, self.state_dict())", "\n", "", "new_state_dict", "=", "state_dict_dino_fix", "(", "state_dict", ",", "self", ".", "state_dict", "(", ")", ")", "\n", "# new_state_dict = self._inflate_positional_embeds(state_dict)", "\n", "self", ".", "load_state_dict", "(", "new_state_dict", ",", "strict", "=", "False", ")", "\n", "# self.load_state_dict(state_dict, strict=False)", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.modules.cotrain_module.CoTrainTransformerSS.infer": [[296, 416], ["[].size", "enumerate", "cotrain_module.CoTrainTransformerSS.transformer.norm", "torch.cat.view", "torch.cat.view", "torch.cat.view", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "cotrain_module.CoTrainTransformerSS.pooler", "cotrain_module.CoTrainTransformerSS.text_embeddings", "torch.repeat_interleave", "torch.repeat_interleave", "torch.repeat_interleave", "torch.repeat_interleave", "torch.repeat_interleave", "torch.repeat_interleave", "torch.repeat_interleave", "torch.repeat_interleave", "torch.repeat_interleave", "torch.repeat_interleave", "torch.repeat_interleave", "torch.repeat_interleave", "torch.repeat_interleave", "torch.repeat_interleave", "torch.repeat_interleave", "torch.repeat_interleave", "torch.repeat_interleave", "torch.repeat_interleave", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "blk", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.cat.size", "text_masks[].contiguous", "video_masks[].contiguous", "img.contiguous().view.contiguous().view.contiguous().view", "cotrain_module.CoTrainTransformerSS.transformer.visual_embed", "cotrain_module.CoTrainTransformerSS.token_type_embeddings", "cotrain_module.CoTrainTransformerSS.token_type_embeddings", "cotrain_module.CoTrainTransformerSS.temporal_roll_module", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat.size", "torch.cat.size", "torch.cat.size", "cotrain_module.CoTrainTransformerSS.txt_proj", "cotrain_module.CoTrainTransformerSS.vid_proj", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.full_like", "torch.full_like", "torch.full_like", "torch.full_like", "torch.full_like", "torch.full_like", "torch.full_like", "torch.full_like", "torch.full_like", "img.contiguous().view.contiguous().view.contiguous", "img.contiguous().view.contiguous().view.size", "img.contiguous().view.contiguous().view.size", "img.contiguous().view.contiguous().view.size"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.modules.base_vision_transformer.DistilledVisionTransformer.visual_embed"], ["", "", "def", "infer", "(", "\n", "self", ",", "\n", "batch", ",", "\n", "mask_text", "=", "False", ",", "\n", "mask_video", "=", "False", ",", "\n", "video_token_type_idx", "=", "1", ",", "\n", "video_embeds", "=", "None", ",", "\n", "video_masks", "=", "None", ",", "\n", "input_video_only", "=", "False", ",", "\n", "input_text_only", "=", "False", ",", "\n", "mode", "=", "\"video\"", "\n", ")", ":", "\n", "# if text: process in normal video", "\n", "# if video: repeat the text tensor for K times", "\n", "        ", "if", "f\"video_{video_token_type_idx - 1}\"", "in", "batch", ":", "\n", "            ", "imgkey", "=", "f\"video_{video_token_type_idx - 1}\"", "\n", "", "else", ":", "\n", "            ", "imgkey", "=", "\"video\"", "\n", "", "do_mlm", "=", "\"_mlm\"", "if", "mask_text", "else", "\"\"", "\n", "text_ids", "=", "batch", "[", "f\"text_ids{do_mlm}\"", "]", "\n", "text_labels", "=", "batch", "[", "f\"text_labels{do_mlm}\"", "]", "\n", "text_masks", "=", "batch", "[", "f\"text_masks\"", "]", "\n", "# print(batch[imgkey])", "\n", "self", ".", "num_frames", "=", "batch", "[", "imgkey", "]", "[", "0", "]", ".", "size", "(", "1", ")", "\n", "if", "not", "input_video_only", ":", "\n", "            ", "text_embeds", "=", "self", ".", "text_embeddings", "(", "text_ids", ")", "\n", "video_labels", "=", "None", "\n", "patch_index", "=", "None", "\n", "", "if", "not", "input_text_only", ":", "\n", "            ", "if", "video_embeds", "is", "None", "and", "video_masks", "is", "None", ":", "\n", "                ", "img", "=", "batch", "[", "imgkey", "]", "[", "0", "]", "\n", "img", "=", "img", ".", "contiguous", "(", ")", ".", "view", "(", "-", "1", ",", "img", ".", "size", "(", ")", "[", "2", "]", ",", "img", ".", "size", "(", ")", "[", "3", "]", ",", "img", ".", "size", "(", ")", "[", "4", "]", ")", "# btchw to [bt]chw", "\n", "(", "\n", "video_embeds", ",", "\n", "video_masks", ",", "\n", "patch_index", ",", "\n", "video_labels", ",", "\n", ")", "=", "self", ".", "transformer", ".", "visual_embed", "(", "\n", "img", ",", "\n", "max_image_len", "=", "self", ".", "hparams", ".", "config", "[", "\"max_image_len\"", "]", ",", "\n", "mask_it", "=", "mask_video", ",", "\n", "mode", "=", "mode", "\n", ")", "\n", "", "else", ":", "\n", "                ", "patch_index", ",", "video_labels", "=", "(", "\n", "None", ",", "\n", "None", ",", "\n", ")", "\n", "", "", "if", "not", "input_video_only", ":", "\n", "            ", "text_embeds", "=", "text_embeds", "+", "self", ".", "token_type_embeddings", "(", "torch", ".", "zeros_like", "(", "text_masks", ")", ")", "\n", "text_embeds", "=", "torch", ".", "repeat_interleave", "(", "text_embeds", ",", "self", ".", "num_frames", ",", "dim", "=", "0", ")", "\n", "text_masks", "=", "torch", ".", "repeat_interleave", "(", "text_masks", ",", "self", ".", "num_frames", ",", "dim", "=", "0", ")", "\n", "", "if", "not", "input_text_only", ":", "\n", "            ", "video_embeds", "=", "video_embeds", "+", "self", ".", "token_type_embeddings", "(", "torch", ".", "full_like", "(", "video_masks", ",", "video_token_type_idx", ")", ")", "\n", "\n", "# print(text_embeds.size(), video_embeds.size())", "\n", "", "if", "not", "input_text_only", "and", "not", "input_video_only", ":", "\n", "            ", "co_embeds", "=", "torch", ".", "cat", "(", "[", "text_embeds", ",", "video_embeds", "]", ",", "dim", "=", "1", ")", "\n", "co_masks", "=", "torch", ".", "cat", "(", "[", "text_masks", ",", "video_masks", "]", ",", "dim", "=", "1", ")", "\n", "x", "=", "co_embeds", "\n", "", "if", "input_text_only", ":", "\n", "            ", "x", "=", "text_embeds", "\n", "co_masks", "=", "text_masks", "\n", "", "if", "input_video_only", ":", "\n", "            ", "x", "=", "video_embeds", "\n", "co_masks", "=", "video_masks", "\n", "\n", "", "for", "i", ",", "blk", "in", "enumerate", "(", "self", ".", "transformer", ".", "blocks", ")", ":", "\n", "# perform temporal roll operation for temporal modeling [video only]", "\n", "            ", "if", "self", ".", "num_frames", ">", "1", "and", "not", "input_video_only", "and", "not", "input_text_only", ":", "\n", "                ", "text_feats", ",", "image_feats", "=", "(", "\n", "x", "[", ":", ",", ":", "text_embeds", ".", "shape", "[", "1", "]", "]", ",", "\n", "x", "[", ":", ",", "text_embeds", ".", "shape", "[", "1", "]", ":", "]", ",", "\n", ")", "\n", "image_feats", "=", "self", ".", "temporal_roll_module", "(", "image_feats", ",", "i", ")", "\n", "x", "=", "torch", ".", "cat", "(", "(", "text_feats", ",", "image_feats", ")", ",", "dim", "=", "1", ")", "\n", "", "x", ",", "_attn", "=", "blk", "(", "x", ",", "mask", "=", "co_masks", ")", "\n", "", "x", "=", "self", ".", "transformer", ".", "norm", "(", "x", ")", "\n", "# reshape to video tensor", "\n", "x", "=", "x", ".", "view", "(", "x", ".", "size", "(", "0", ")", "//", "self", ".", "num_frames", ",", "-", "1", ",", "x", ".", "size", "(", "-", "2", ")", ",", "\n", "x", ".", "size", "(", "-", "1", ")", ")", "\n", "# add vcop here", "\n", "h", "=", "None", "\n", "if", "self", ".", "hparams", ".", "config", "[", "\"loss_names\"", "]", "[", "\"vcop\"", "]", ">", "0", "and", "mode", "==", "\"video\"", ":", "\n", "            ", "h", "=", "x", "\n", "", "x", "=", "torch", ".", "mean", "(", "x", ",", "dim", "=", "1", ")", "\n", "if", "input_text_only", ":", "\n", "            ", "text_feats", "=", "x", "\n", "if", "\"vtc\"", "in", "self", ".", "current_tasks", ":", "\n", "                ", "text_feats", "=", "self", ".", "txt_proj", "(", "text_feats", ")", "\n", "", "video_feats", "=", "None", "\n", "", "if", "input_video_only", ":", "\n", "            ", "video_feats", "=", "x", "\n", "if", "\"vtc\"", "in", "self", ".", "current_tasks", ":", "\n", "                ", "video_feats", "=", "self", ".", "vid_proj", "(", "video_feats", ")", "\n", "", "text_feats", "=", "None", "\n", "", "if", "not", "input_text_only", "and", "not", "input_video_only", ":", "\n", "            ", "text_feats", ",", "video_feats", "=", "(", "\n", "x", "[", ":", ",", ":", "text_embeds", ".", "shape", "[", "1", "]", "]", ",", "\n", "x", "[", ":", ",", "text_embeds", ".", "shape", "[", "1", "]", ":", "]", ",", "\n", ")", "\n", "", "cls_feats", "=", "self", ".", "pooler", "(", "x", ")", "\n", "if", "not", "input_video_only", ":", "\n", "            ", "text_masks", "=", "text_masks", "[", ":", ":", "self", ".", "num_frames", "]", ".", "contiguous", "(", ")", "\n", "", "if", "not", "input_text_only", ":", "\n", "            ", "video_masks", "=", "video_masks", "[", ":", ":", "self", ".", "num_frames", "]", ".", "contiguous", "(", ")", "\n", "", "ret", "=", "{", "\n", "\"text_feats\"", ":", "text_feats", ",", "\n", "\"video_feats\"", ":", "video_feats", ",", "\n", "\"cls_feats\"", ":", "cls_feats", ",", "\n", "\"raw_cls_feats\"", ":", "x", "[", ":", ",", "0", "]", ",", "\n", "\"video_labels\"", ":", "video_labels", ",", "\n", "\"video_masks\"", ":", "video_masks", ",", "\n", "\"text_labels\"", ":", "text_labels", ",", "\n", "\"text_ids\"", ":", "text_ids", ",", "\n", "\"text_masks\"", ":", "text_masks", ",", "\n", "\"patch_index\"", ":", "patch_index", ",", "\n", "\"vcop_features\"", ":", "h", "\n", "}", "\n", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.modules.cotrain_module.CoTrainTransformerSS.forward": [[417, 465], ["dict", "len", "dict.update", "dict.update", "dict.update", "dict.update", "dict.update", "dict.update", "dict.update", "dict.update", "dict.update", "dict.update", "dict.update", "cotrain_module.CoTrainTransformerSS.infer", "CoTrain.modules.objectives.compute_mlm", "CoTrain.modules.objectives.compute_vtm_wpa", "CoTrain.modules.objectives.compute_vtc", "CoTrain.modules.objectives.compute_vqa", "CoTrain.modules.objectives.compute_openend_vqa", "CoTrain.modules.objectives.compute_vcop", "CoTrain.modules.objectives.compute_vcr_q2a", "CoTrain.modules.objectives.compute_mc_vqa_q2a", "CoTrain.modules.objectives.compute_multiple_choice", "CoTrain.modules.objectives.compute_irtr"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.gadgets.my_metrics.VQAScore.update", "home.repos.pwc.inspect_result.showlab_all-in-one.gadgets.my_metrics.VQAScore.update", "home.repos.pwc.inspect_result.showlab_all-in-one.gadgets.my_metrics.VQAScore.update", "home.repos.pwc.inspect_result.showlab_all-in-one.gadgets.my_metrics.VQAScore.update", "home.repos.pwc.inspect_result.showlab_all-in-one.gadgets.my_metrics.VQAScore.update", "home.repos.pwc.inspect_result.showlab_all-in-one.gadgets.my_metrics.VQAScore.update", "home.repos.pwc.inspect_result.showlab_all-in-one.gadgets.my_metrics.VQAScore.update", "home.repos.pwc.inspect_result.showlab_all-in-one.gadgets.my_metrics.VQAScore.update", "home.repos.pwc.inspect_result.showlab_all-in-one.gadgets.my_metrics.VQAScore.update", "home.repos.pwc.inspect_result.showlab_all-in-one.gadgets.my_metrics.VQAScore.update", "home.repos.pwc.inspect_result.showlab_all-in-one.gadgets.my_metrics.VQAScore.update", "home.repos.pwc.inspect_result.showlab_all-in-one.modules.allinone_module.AllinoneTransformerSS.infer", "home.repos.pwc.inspect_result.showlab_all-in-one.modules.objectives.compute_mlm", "home.repos.pwc.inspect_result.showlab_all-in-one.modules.objectives.compute_vtm_wpa", "home.repos.pwc.inspect_result.showlab_all-in-one.modules.objectives.compute_vtc", "home.repos.pwc.inspect_result.showlab_all-in-one.modules.objectives.compute_vqa", "home.repos.pwc.inspect_result.showlab_all-in-one.modules.objectives.compute_openend_vqa", "home.repos.pwc.inspect_result.showlab_all-in-one.modules.objectives.compute_vcop", "home.repos.pwc.inspect_result.showlab_all-in-one.modules.objectives.compute_vcr_q2a", "home.repos.pwc.inspect_result.showlab_all-in-one.modules.objectives.compute_mc_vqa_q2a", "home.repos.pwc.inspect_result.showlab_all-in-one.modules.objectives.compute_multiple_choice", "home.repos.pwc.inspect_result.showlab_all-in-one.modules.objectives.compute_irtr"], ["", "def", "forward", "(", "self", ",", "batch", ",", "mode", "=", "\"video\"", ")", ":", "\n", "        ", "ret", "=", "dict", "(", ")", "\n", "if", "len", "(", "self", ".", "current_tasks", ")", "==", "0", ":", "\n", "            ", "ret", ".", "update", "(", "self", ".", "infer", "(", "batch", ",", "mode", "=", "mode", ")", ")", "\n", "return", "ret", "\n", "\n", "# Masked Language Modeling", "\n", "", "if", "\"mlm\"", "in", "self", ".", "current_tasks", ":", "\n", "            ", "ret", ".", "update", "(", "objectives", ".", "compute_mlm", "(", "self", ",", "batch", ",", "mode", "=", "mode", ")", ")", "\n", "\n", "# video Text Matching", "\n", "", "if", "\"vtm\"", "in", "self", ".", "current_tasks", ":", "\n", "            ", "ret", ".", "update", "(", "objectives", ".", "compute_vtm_wpa", "(", "self", ",", "batch", ",", "mode", "=", "mode", ")", ")", "\n", "# ret.update(objectives.compute_vtm_wpa_dino(self, batch, mode=mode))", "\n", "\n", "# video Text Contrastive", "\n", "", "if", "\"vtc\"", "in", "self", ".", "current_tasks", ":", "\n", "            ", "ret", ".", "update", "(", "objectives", ".", "compute_vtc", "(", "self", ",", "batch", ",", "mode", "=", "mode", ")", ")", "\n", "\n", "# Visual Question Answering", "\n", "", "if", "\"vqa\"", "in", "self", ".", "current_tasks", ":", "\n", "            ", "ret", ".", "update", "(", "objectives", ".", "compute_vqa", "(", "self", ",", "batch", ")", ")", "\n", "\n", "# alex: msrvtt Visual Question Answering", "\n", "", "if", "\"openend_vqa\"", "in", "self", ".", "current_tasks", ":", "\n", "            ", "ret", ".", "update", "(", "objectives", ".", "compute_openend_vqa", "(", "self", ",", "batch", ")", ")", "\n", "\n", "# alex: vcop only for video", "\n", "", "if", "\"vcop\"", "in", "self", ".", "current_tasks", "and", "mode", "==", "\"video\"", ":", "\n", "            ", "ret", ".", "update", "(", "objectives", ".", "compute_vcop", "(", "self", ",", "batch", ")", ")", "\n", "\n", "# alex: vcr qa", "\n", "", "if", "\"vcr_q2a\"", "in", "self", ".", "current_tasks", ":", "\n", "            ", "ret", ".", "update", "(", "objectives", ".", "compute_vcr_q2a", "(", "self", ",", "batch", ")", ")", "\n", "\n", "# alex: mc_vqa", "\n", "", "if", "\"mc_vqa\"", "in", "self", ".", "current_tasks", ":", "\n", "            ", "ret", ".", "update", "(", "objectives", ".", "compute_mc_vqa_q2a", "(", "self", ",", "batch", ")", ")", "\n", "\n", "# alex: msrvtt multiple choice setting", "\n", "", "if", "\"multiple_choice\"", "in", "self", ".", "current_tasks", ":", "\n", "            ", "ret", ".", "update", "(", "objectives", ".", "compute_multiple_choice", "(", "self", ",", "batch", ")", ")", "\n", "\n", "# video Retrieval and Text Retrieval", "\n", "", "if", "\"irtr\"", "in", "self", ".", "current_tasks", ":", "\n", "            ", "ret", ".", "update", "(", "objectives", ".", "compute_irtr", "(", "self", ",", "batch", ")", ")", "\n", "\n", "", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.modules.cotrain_module.CoTrainTransformerSS.training_step": [[466, 477], ["CoTrain.modules.cotrain_utils.set_task", "cotrain_module.CoTrainTransformerSS.", "cotrain_module.CoTrainTransformerSS.", "cotrain_module.CoTrainTransformerSS.", "sum", "sum", "sum", "cotrain_module.CoTrainTransformerSS.items", "cotrain_module.CoTrainTransformerSS.items", "cotrain_module.CoTrainTransformerSS.items"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.modules.allinone_utils.set_task"], ["", "def", "training_step", "(", "self", ",", "batch", ",", "batch_idx", ")", ":", "\n", "        ", "cotrain_utils", ".", "set_task", "(", "self", ")", "\n", "# co-training", "\n", "if", "\"v\"", "in", "batch", "and", "\"i\"", "in", "batch", ":", "\n", "            ", "video_output", "=", "self", "(", "batch", "[", "\"v\"", "]", ",", "mode", "=", "\"video\"", ")", "\n", "image_output", "=", "self", "(", "batch", "[", "\"i\"", "]", ",", "mode", "=", "\"image\"", ")", "\n", "total_loss", "=", "sum", "(", "[", "v", "for", "k", ",", "v", "in", "video_output", ".", "items", "(", ")", "if", "\"loss\"", "in", "k", "]", ")", "+", "sum", "(", "[", "v", "for", "k", ",", "v", "in", "image_output", ".", "items", "(", ")", "if", "\"loss\"", "in", "k", "]", ")", "\n", "", "else", ":", "\n", "            ", "output", "=", "self", "(", "batch", ",", "mode", "=", "\"video\"", ")", "\n", "total_loss", "=", "sum", "(", "[", "v", "for", "k", ",", "v", "in", "output", ".", "items", "(", ")", "if", "\"loss\"", "in", "k", "]", ")", "\n", "", "return", "total_loss", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.modules.cotrain_module.CoTrainTransformerSS.training_epoch_end": [[478, 480], ["CoTrain.modules.cotrain_utils.epoch_wrapup"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.modules.allinone_utils.epoch_wrapup"], ["", "def", "training_epoch_end", "(", "self", ",", "outs", ")", ":", "\n", "        ", "cotrain_utils", ".", "epoch_wrapup", "(", "self", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.modules.cotrain_module.CoTrainTransformerSS.validation_step": [[481, 488], ["CoTrain.modules.cotrain_utils.set_task", "cotrain_module.CoTrainTransformerSS.", "cotrain_module.CoTrainTransformerSS.", "cotrain_module.CoTrainTransformerSS."], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.modules.allinone_utils.set_task"], ["", "def", "validation_step", "(", "self", ",", "batch", ",", "batch_idx", ")", ":", "\n", "        ", "cotrain_utils", ".", "set_task", "(", "self", ")", "\n", "if", "\"v\"", "in", "batch", "and", "\"i\"", "in", "batch", ":", "\n", "            ", "video_output", "=", "self", "(", "batch", "[", "\"v\"", "]", ",", "mode", "=", "\"video\"", ")", "\n", "image_output", "=", "self", "(", "batch", "[", "\"i\"", "]", ",", "mode", "=", "\"image\"", ")", "\n", "", "else", ":", "\n", "            ", "output", "=", "self", "(", "batch", ",", "mode", "=", "\"video\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.modules.cotrain_module.CoTrainTransformerSS.validation_epoch_end": [[489, 491], ["CoTrain.modules.cotrain_utils.epoch_wrapup"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.modules.allinone_utils.epoch_wrapup"], ["", "", "def", "validation_epoch_end", "(", "self", ",", "outs", ")", ":", "\n", "        ", "cotrain_utils", ".", "epoch_wrapup", "(", "self", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.modules.cotrain_module.CoTrainTransformerSS.test_step": [[492, 505], ["CoTrain.modules.cotrain_utils.set_task", "dict", "cotrain_module.CoTrainTransformerSS.", "cotrain_module.CoTrainTransformerSS.", "cotrain_module.CoTrainTransformerSS.", "dict.update", "CoTrain.modules.objectives.vqa_test_step"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.modules.allinone_utils.set_task", "home.repos.pwc.inspect_result.showlab_all-in-one.gadgets.my_metrics.VQAScore.update", "home.repos.pwc.inspect_result.showlab_all-in-one.modules.objectives.vqa_test_step"], ["", "def", "test_step", "(", "self", ",", "batch", ",", "batch_idx", ")", ":", "\n", "        ", "cotrain_utils", ".", "set_task", "(", "self", ")", "\n", "if", "\"v\"", "in", "batch", "and", "\"i\"", "in", "batch", ":", "\n", "            ", "video_output", "=", "self", "(", "batch", "[", "\"v\"", "]", ",", "mode", "=", "\"video\"", ")", "\n", "image_output", "=", "self", "(", "batch", "[", "\"i\"", "]", ",", "mode", "=", "\"image\"", ")", "\n", "", "else", ":", "\n", "            ", "output", "=", "self", "(", "batch", ",", "mode", "=", "\"video\"", ")", "\n", "", "ret", "=", "dict", "(", ")", "\n", "\n", "if", "self", ".", "hparams", ".", "config", "[", "\"loss_names\"", "]", "[", "\"vqa\"", "]", ">", "0", ":", "\n", "            ", "ret", ".", "update", "(", "objectives", ".", "vqa_test_step", "(", "self", ",", "batch", ",", "image_output", ")", ")", "\n", "\n", "", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.modules.cotrain_module.CoTrainTransformerSS.test_epoch_end": [[506, 512], ["CoTrain.modules.cotrain_utils.epoch_wrapup", "CoTrain.modules.objectives.vqa_test_wrapup", "cotrain_module.CoTrainTransformerSS.hparams.config[].split"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.modules.allinone_utils.epoch_wrapup", "home.repos.pwc.inspect_result.showlab_all-in-one.modules.objectives.vqa_test_wrapup"], ["", "def", "test_epoch_end", "(", "self", ",", "outs", ")", ":", "\n", "        ", "model_name", "=", "self", ".", "hparams", ".", "config", "[", "\"load_path\"", "]", ".", "split", "(", "\"/\"", ")", "[", "-", "1", "]", "[", ":", "-", "5", "]", "\n", "\n", "if", "self", ".", "hparams", ".", "config", "[", "\"loss_names\"", "]", "[", "\"vqa\"", "]", ">", "0", ":", "\n", "            ", "objectives", ".", "vqa_test_wrapup", "(", "outs", ",", "model_name", ")", "\n", "", "cotrain_utils", ".", "epoch_wrapup", "(", "self", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.modules.cotrain_module.CoTrainTransformerSS.configure_optimizers": [[513, 515], ["CoTrain.modules.cotrain_utils.set_schedule"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.modules.allinone_utils.set_schedule"], ["", "def", "configure_optimizers", "(", "self", ")", ":", "\n", "        ", "return", "cotrain_utils", ".", "set_schedule", "(", "self", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.modules.cotrain_module.CoTrainTransformerSS._inflate_positional_embeds": [[516, 559], ["list", "cotrain_module.CoTrainTransformerSS.state_dict().keys", "cotrain_module.CoTrainTransformerSS.state_dict", "NotImplementedError", "cotrain_module.CoTrainTransformerSS.state_dict", "print", "print", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "load_temporal_embed.unsqueeze.unsqueeze.unsqueeze", "torch.interpolate().squeeze", "torch.interpolate().squeeze", "torch.interpolate().squeeze", "torch.interpolate", "torch.interpolate", "torch.interpolate"], "methods", ["None"], ["", "def", "_inflate_positional_embeds", "(", "self", ",", "new_state_dict", ",", "load_temporal_fix", "=", "'zeros'", ")", ":", "\n", "# allow loading of timesformer with fewer num_frames", "\n", "        ", "curr_keys", "=", "list", "(", "self", ".", "state_dict", "(", ")", ".", "keys", "(", ")", ")", "\n", "if", "'transformer.temporal_embed'", "in", "new_state_dict", "and", "'transformer.temporal_embed'", "in", "curr_keys", ":", "\n", "            ", "load_temporal_embed", "=", "new_state_dict", "[", "'transformer.temporal_embed'", "]", "\n", "load_num_frames", "=", "load_temporal_embed", ".", "shape", "[", "1", "]", "\n", "curr_num_frames", "=", "self", ".", "hparams", ".", "config", "[", "'num_frames'", "]", "\n", "embed_dim", "=", "load_temporal_embed", ".", "shape", "[", "2", "]", "\n", "\n", "if", "load_num_frames", "!=", "curr_num_frames", ":", "\n", "                ", "if", "load_num_frames", ">", "curr_num_frames", ":", "\n", "                    ", "print", "(", "f'### loaded {self.hparams.config[\"vit\"]} model has MORE frames than current...'", "\n", "f'### loading weights, filling in the extras via {load_temporal_fix}'", ")", "\n", "new_temporal_embed", "=", "load_temporal_embed", "[", ":", ",", ":", "curr_num_frames", ",", ":", "]", "\n", "", "else", ":", "\n", "                    ", "print", "(", "f'### loaded {self.hparams.config[\"vit\"]} model has FEWER frames than current...'", "\n", "f'### loading weights, filling in the extras via {load_temporal_fix}'", ")", "\n", "if", "load_temporal_fix", "==", "'zeros'", ":", "\n", "                        ", "new_temporal_embed", "=", "torch", ".", "zeros", "(", "[", "load_temporal_embed", ".", "shape", "[", "0", "]", ",", "curr_num_frames", ",", "embed_dim", "]", ")", "\n", "new_temporal_embed", "[", ":", ",", ":", "load_num_frames", "]", "=", "load_temporal_embed", "\n", "", "elif", "load_temporal_fix", "in", "[", "'interp'", ",", "'bilinear'", "]", ":", "\n", "# interpolate", "\n", "# unsqueeze so pytorch thinks its an image", "\n", "                        ", "mode", "=", "'nearest'", "\n", "if", "load_temporal_fix", "==", "'bilinear'", ":", "\n", "                            ", "mode", "=", "'bilinear'", "\n", "", "load_temporal_embed", "=", "load_temporal_embed", ".", "unsqueeze", "(", "0", ")", "\n", "new_temporal_embed", "=", "F", ".", "interpolate", "(", "load_temporal_embed", ",", "\n", "(", "curr_num_frames", ",", "embed_dim", ")", ",", "mode", "=", "mode", ")", ".", "squeeze", "(", "0", ")", "\n", "", "else", ":", "\n", "                        ", "raise", "NotImplementedError", "\n", "", "", "new_state_dict", "[", "'transformer.temporal_embed'", "]", "=", "new_temporal_embed", "\n", "# allow loading with smaller spatial patches. assumes custom border crop, to append the", "\n", "# border patches to the input sequence", "\n", "", "", "if", "'transformer.pos_embed'", "in", "new_state_dict", "and", "'transformer.pos_embed'", "in", "curr_keys", ":", "\n", "            ", "load_pos_embed", "=", "new_state_dict", "[", "'transformer.pos_embed'", "]", "\n", "load_num_patches", "=", "load_pos_embed", ".", "shape", "[", "1", "]", "\n", "curr_pos_embed", "=", "self", ".", "state_dict", "(", ")", "[", "'transformer.pos_embed'", "]", "\n", "if", "load_num_patches", "!=", "curr_pos_embed", ".", "shape", "[", "1", "]", ":", "\n", "                ", "raise", "NotImplementedError", "(", "\n", "'Loading models with different spatial resolution / patch number not yet implemented, sorry.'", ")", "\n", "\n", "", "", "return", "new_state_dict", "", "", "", ""]], "home.repos.pwc.inspect_result.showlab_all-in-one.modules.allinone_utils.set_metrics": [[14, 67], ["pl_module.hparams.config[].items", "setattr", "setattr", "AllInOne.gadgets.my_metrics.VQAScore", "AllInOne.gadgets.my_metrics.Scalar", "setattr", "setattr", "setattr", "setattr", "AllInOne.gadgets.my_metrics.Scalar", "AllInOne.gadgets.my_metrics.Accuracy", "AllInOne.gadgets.my_metrics.Scalar", "AllInOne.gadgets.my_metrics.Accuracy", "setattr", "setattr", "AllInOne.gadgets.my_metrics.Scalar", "AllInOne.gadgets.my_metrics.Accuracy", "setattr", "setattr", "setattr", "setattr", "AllInOne.gadgets.my_metrics.VQAScore", "AllInOne.gadgets.my_metrics.Scalar", "AllInOne.gadgets.my_metrics.Scalar", "AllInOne.gadgets.my_metrics.Accuracy", "setattr", "setattr", "setattr", "setattr", "AllInOne.gadgets.my_metrics.VQAScore", "AllInOne.gadgets.my_metrics.Scalar", "AllInOne.gadgets.my_metrics.Scalar", "AllInOne.gadgets.my_metrics.Accuracy", "setattr", "setattr", "AllInOne.gadgets.my_metrics.Accuracy", "AllInOne.gadgets.my_metrics.Scalar", "setattr", "setattr", "setattr", "setattr", "setattr", "setattr", "setattr", "AllInOne.gadgets.my_metrics.Accuracy", "AllInOne.gadgets.my_metrics.Scalar", "AllInOne.gadgets.my_metrics.Accuracy", "AllInOne.gadgets.my_metrics.Scalar", "AllInOne.gadgets.my_metrics.Accuracy", "AllInOne.gadgets.my_metrics.Scalar", "AllInOne.gadgets.my_metrics.Scalar", "setattr", "AllInOne.gadgets.my_metrics.Scalar", "setattr", "setattr", "setattr", "AllInOne.gadgets.my_metrics.Accuracy", "AllInOne.gadgets.my_metrics.Scalar", "AllInOne.gadgets.my_metrics.Scalar", "setattr", "setattr", "setattr", "AllInOne.gadgets.my_metrics.Scalar", "AllInOne.gadgets.my_metrics.Accuracy", "AllInOne.gadgets.my_metrics.Scalar"], "function", ["None"], ["def", "set_metrics", "(", "pl_module", ")", ":", "\n", "    ", "for", "split", "in", "[", "\"train\"", ",", "\"val\"", "]", ":", "\n", "        ", "for", "k", ",", "v", "in", "pl_module", ".", "hparams", ".", "config", "[", "\"loss_names\"", "]", ".", "items", "(", ")", ":", "\n", "            ", "if", "v", "<", "1", ":", "\n", "                ", "continue", "\n", "", "if", "k", "==", "\"vqa\"", ":", "\n", "                ", "setattr", "(", "pl_module", ",", "f\"{split}_vqa_score\"", ",", "VQAScore", "(", ")", ")", "\n", "setattr", "(", "pl_module", ",", "f\"{split}_{k}_loss\"", ",", "Scalar", "(", ")", ")", "\n", "# vcr", "\n", "", "elif", "k", "==", "\"vcr_q2a\"", ":", "\n", "                ", "setattr", "(", "pl_module", ",", "f\"{split}_{k}_loss\"", ",", "Scalar", "(", ")", ")", "\n", "setattr", "(", "pl_module", ",", "f\"{split}_{k}_accuracy\"", ",", "Accuracy", "(", ")", ")", "\n", "setattr", "(", "pl_module", ",", "f\"{split}_vcr_qar_loss\"", ",", "Scalar", "(", ")", ")", "\n", "setattr", "(", "pl_module", ",", "f\"{split}_vcr_qar_accuracy\"", ",", "Accuracy", "(", ")", ")", "\n", "", "elif", "k", "==", "\"mc_vqa\"", ":", "\n", "                ", "setattr", "(", "pl_module", ",", "f\"{split}_{k}_loss\"", ",", "Scalar", "(", ")", ")", "\n", "setattr", "(", "pl_module", ",", "f\"{split}_{k}_accuracy\"", ",", "Accuracy", "(", ")", ")", "\n", "", "elif", "k", "==", "\"openend_vqa\"", ":", "\n", "                ", "setattr", "(", "pl_module", ",", "f\"{split}_vqa_score\"", ",", "VQAScore", "(", ")", ")", "\n", "setattr", "(", "pl_module", ",", "f\"{split}_vqa_loss\"", ",", "Scalar", "(", ")", ")", "\n", "setattr", "(", "pl_module", ",", "f\"{split}_{k}_loss\"", ",", "Scalar", "(", ")", ")", "\n", "setattr", "(", "pl_module", ",", "f\"{split}_{k}_accuracy\"", ",", "Accuracy", "(", ")", ")", "\n", "", "elif", "k", "==", "\"vcop\"", ":", "\n", "                ", "setattr", "(", "pl_module", ",", "f\"{split}_vcop_score\"", ",", "VQAScore", "(", ")", ")", "\n", "setattr", "(", "pl_module", ",", "f\"{split}_vcop_loss\"", ",", "Scalar", "(", ")", ")", "\n", "setattr", "(", "pl_module", ",", "f\"{split}_{k}_loss\"", ",", "Scalar", "(", ")", ")", "\n", "setattr", "(", "pl_module", ",", "f\"{k}_accuracy\"", ",", "Accuracy", "(", ")", ")", "\n", "", "elif", "k", "==", "\"multiple_choice\"", ":", "\n", "                ", "setattr", "(", "pl_module", ",", "f\"{split}_{k}_accuracy\"", ",", "Accuracy", "(", ")", ")", "\n", "setattr", "(", "pl_module", ",", "f\"{split}_{k}_loss\"", ",", "Scalar", "(", ")", ")", "\n", "", "elif", "k", "==", "\"nlvr2\"", ":", "\n", "                ", "if", "split", "==", "\"train\"", ":", "\n", "                    ", "setattr", "(", "pl_module", ",", "f\"train_{k}_accuracy\"", ",", "Accuracy", "(", ")", ")", "\n", "setattr", "(", "pl_module", ",", "f\"train_{k}_loss\"", ",", "Scalar", "(", ")", ")", "\n", "", "else", ":", "\n", "                    ", "setattr", "(", "pl_module", ",", "f\"dev_{k}_accuracy\"", ",", "Accuracy", "(", ")", ")", "\n", "setattr", "(", "pl_module", ",", "f\"dev_{k}_loss\"", ",", "Scalar", "(", ")", ")", "\n", "setattr", "(", "pl_module", ",", "f\"test_{k}_accuracy\"", ",", "Accuracy", "(", ")", ")", "\n", "setattr", "(", "pl_module", ",", "f\"test_{k}_loss\"", ",", "Scalar", "(", ")", ")", "\n", "", "", "elif", "k", "==", "\"irtr\"", ":", "\n", "                ", "setattr", "(", "pl_module", ",", "f\"{split}_irtr_loss\"", ",", "Scalar", "(", ")", ")", "\n", "", "elif", "k", "==", "\"mppd\"", "or", "k", "==", "\"mpfr\"", ":", "\n", "                ", "setattr", "(", "pl_module", ",", "f\"{split}_{k}_loss\"", ",", "Scalar", "(", ")", ")", "\n", "", "elif", "k", "==", "\"itm\"", ":", "\n", "                ", "setattr", "(", "pl_module", ",", "f\"{split}_{k}_accuracy\"", ",", "Accuracy", "(", ")", ")", "\n", "setattr", "(", "pl_module", ",", "f\"{split}_{k}_loss\"", ",", "Scalar", "(", ")", ")", "\n", "setattr", "(", "pl_module", ",", "f\"{split}_{k}_wpa_loss\"", ",", "Scalar", "(", ")", ")", "\n", "# add for image text contrastive learning", "\n", "", "elif", "k", "==", "\"itc\"", ":", "\n", "                ", "setattr", "(", "pl_module", ",", "f\"{split}_{k}_loss\"", ",", "Scalar", "(", ")", ")", "\n", "", "else", ":", "\n", "                ", "setattr", "(", "pl_module", ",", "f\"{split}_{k}_accuracy\"", ",", "Accuracy", "(", ")", ")", "\n", "setattr", "(", "pl_module", ",", "f\"{split}_{k}_loss\"", ",", "Scalar", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.modules.allinone_utils.epoch_wrapup": [[69, 309], ["pl_module.hparams.config[].items", "pl_module.log", "AllInOne.modules.objectives.compute_irtr_recall", "pl_module.logger.experiment.add_scalar", "pl_module.logger.experiment.add_scalar", "pl_module.logger.experiment.add_scalar", "pl_module.logger.experiment.add_scalar", "pl_module.logger.experiment.add_scalar", "pl_module.logger.experiment.add_scalar", "AllInOne.modules.objectives.compute_decouple_irtr_recall", "print", "pl_module.logger.experiment.add_scalar", "pl_module.logger.experiment.add_scalar", "pl_module.logger.experiment.add_scalar", "pl_module.logger.experiment.add_scalar", "pl_module.logger.experiment.add_scalar", "pl_module.logger.experiment.add_scalar", "AllInOne.modules.objectives.compute_ind_irtr_recall", "print", "pl_module.logger.experiment.add_scalar", "pl_module.logger.experiment.add_scalar", "pl_module.logger.experiment.add_scalar", "pl_module.logger.experiment.add_scalar", "pl_module.logger.experiment.add_scalar", "pl_module.logger.experiment.add_scalar", "torch.distributed.get_rank", "print", "ir_r1.item", "tr_r1.item", "getattr().compute", "pl_module.log", "getattr().reset", "pl_module.log", "getattr().reset", "getattr().compute", "pl_module.log", "getattr().reset", "getattr().compute", "pl_module.log", "getattr().reset", "pl_module.log", "getattr().reset", "getattr().compute", "pl_module.log", "getattr().reset", "getattr", "getattr", "getattr", "getattr().compute", "getattr().compute", "pl_module.log", "getattr().reset", "getattr().compute", "pl_module.log", "getattr().reset", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr().compute", "pl_module.log", "getattr().reset", "getattr().compute", "pl_module.log", "getattr().reset", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr().compute", "pl_module.log", "getattr().reset", "getattr().compute", "pl_module.log", "getattr().reset", "getattr", "getattr", "getattr", "getattr", "getattr().compute", "pl_module.log", "getattr().reset", "getattr().compute", "pl_module.log", "getattr().reset", "getattr", "getattr", "getattr", "getattr", "getattr().compute", "getattr", "getattr", "getattr", "getattr", "getattr().compute", "pl_module.log", "getattr().reset", "pl_module.log", "getattr().reset", "getattr().compute", "pl_module.log", "getattr().reset", "pl_module.log", "getattr().reset", "getattr().compute", "pl_module.log", "getattr().reset", "pl_module.log", "getattr().reset", "pl_module.log", "getattr().reset", "getattr", "getattr().compute", "getattr().compute", "getattr().compute", "getattr().compute", "pl_module.log", "getattr().reset", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr().compute", "getattr().compute", "pl_module.log", "getattr().reset", "pl_module.log", "getattr().reset", "pl_module.log", "getattr().reset", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr().compute", "getattr().compute", "pl_module.log", "getattr().reset", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr().compute", "pl_module.log", "getattr().reset", "getattr().compute", "pl_module.log", "getattr().reset", "pl_module.log", "getattr().reset", "getattr", "getattr", "getattr", "getattr().compute", "getattr().compute", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr"], "function", ["home.repos.pwc.inspect_result.showlab_all-in-one.modules.objectives.compute_irtr_recall", "home.repos.pwc.inspect_result.showlab_all-in-one.modules.objectives.compute_decouple_irtr_recall", "home.repos.pwc.inspect_result.showlab_all-in-one.modules.objectives.compute_ind_irtr_recall", "home.repos.pwc.inspect_result.showlab_all-in-one.modules.dist_utils.get_rank", "home.repos.pwc.inspect_result.showlab_all-in-one.gadgets.my_metrics.VQAScore.compute", "home.repos.pwc.inspect_result.showlab_all-in-one.gadgets.my_metrics.VQAScore.compute", "home.repos.pwc.inspect_result.showlab_all-in-one.gadgets.my_metrics.VQAScore.compute", "home.repos.pwc.inspect_result.showlab_all-in-one.gadgets.my_metrics.VQAScore.compute", "home.repos.pwc.inspect_result.showlab_all-in-one.gadgets.my_metrics.VQAScore.compute", "home.repos.pwc.inspect_result.showlab_all-in-one.gadgets.my_metrics.VQAScore.compute", "home.repos.pwc.inspect_result.showlab_all-in-one.gadgets.my_metrics.VQAScore.compute", "home.repos.pwc.inspect_result.showlab_all-in-one.gadgets.my_metrics.VQAScore.compute", "home.repos.pwc.inspect_result.showlab_all-in-one.gadgets.my_metrics.VQAScore.compute", "home.repos.pwc.inspect_result.showlab_all-in-one.gadgets.my_metrics.VQAScore.compute", "home.repos.pwc.inspect_result.showlab_all-in-one.gadgets.my_metrics.VQAScore.compute", "home.repos.pwc.inspect_result.showlab_all-in-one.gadgets.my_metrics.VQAScore.compute", "home.repos.pwc.inspect_result.showlab_all-in-one.gadgets.my_metrics.VQAScore.compute", "home.repos.pwc.inspect_result.showlab_all-in-one.gadgets.my_metrics.VQAScore.compute", "home.repos.pwc.inspect_result.showlab_all-in-one.gadgets.my_metrics.VQAScore.compute", "home.repos.pwc.inspect_result.showlab_all-in-one.gadgets.my_metrics.VQAScore.compute", "home.repos.pwc.inspect_result.showlab_all-in-one.gadgets.my_metrics.VQAScore.compute", "home.repos.pwc.inspect_result.showlab_all-in-one.gadgets.my_metrics.VQAScore.compute", "home.repos.pwc.inspect_result.showlab_all-in-one.gadgets.my_metrics.VQAScore.compute", "home.repos.pwc.inspect_result.showlab_all-in-one.gadgets.my_metrics.VQAScore.compute", "home.repos.pwc.inspect_result.showlab_all-in-one.gadgets.my_metrics.VQAScore.compute", "home.repos.pwc.inspect_result.showlab_all-in-one.gadgets.my_metrics.VQAScore.compute", "home.repos.pwc.inspect_result.showlab_all-in-one.gadgets.my_metrics.VQAScore.compute", "home.repos.pwc.inspect_result.showlab_all-in-one.gadgets.my_metrics.VQAScore.compute", "home.repos.pwc.inspect_result.showlab_all-in-one.gadgets.my_metrics.VQAScore.compute", "home.repos.pwc.inspect_result.showlab_all-in-one.gadgets.my_metrics.VQAScore.compute", "home.repos.pwc.inspect_result.showlab_all-in-one.gadgets.my_metrics.VQAScore.compute", "home.repos.pwc.inspect_result.showlab_all-in-one.gadgets.my_metrics.VQAScore.compute", "home.repos.pwc.inspect_result.showlab_all-in-one.gadgets.my_metrics.VQAScore.compute"], ["", "", "", "", "def", "epoch_wrapup", "(", "pl_module", ")", ":", "\n", "    ", "phase", "=", "\"train\"", "if", "pl_module", ".", "training", "else", "\"val\"", "\n", "the_metric", "=", "0", "\n", "the_metric_qar", "=", "0", "\n", "if", "pl_module", ".", "hparams", ".", "config", "[", "\"get_recall_metric\"", "]", "and", "not", "pl_module", ".", "training", ":", "\n", "        ", "(", "ir_r1", ",", "ir_r5", ",", "ir_r10", ",", "tr_r1", ",", "tr_r5", ",", "tr_r10", ")", "=", "compute_irtr_recall", "(", "pl_module", ")", "\n", "if", "torch", ".", "distributed", ".", "get_rank", "(", ")", "==", "0", ":", "\n", "            ", "print", "(", "(", "ir_r1", ",", "ir_r5", ",", "ir_r10", ",", "tr_r1", ",", "tr_r5", ",", "tr_r10", ")", ",", "pl_module", ".", "global_step", ")", "\n", "", "pl_module", ".", "logger", ".", "experiment", ".", "add_scalar", "(", "\n", "\"recalls/ir_r1\"", ",", "ir_r1", ",", "pl_module", ".", "global_step", "\n", ")", "\n", "pl_module", ".", "logger", ".", "experiment", ".", "add_scalar", "(", "\n", "\"recalls/ir_r5\"", ",", "ir_r5", ",", "pl_module", ".", "global_step", "\n", ")", "\n", "pl_module", ".", "logger", ".", "experiment", ".", "add_scalar", "(", "\n", "\"recalls/ir_r10\"", ",", "ir_r10", ",", "pl_module", ".", "global_step", "\n", ")", "\n", "pl_module", ".", "logger", ".", "experiment", ".", "add_scalar", "(", "\n", "\"recalls/tr_r1\"", ",", "tr_r1", ",", "pl_module", ".", "global_step", "\n", ")", "\n", "pl_module", ".", "logger", ".", "experiment", ".", "add_scalar", "(", "\n", "\"recalls/tr_r5\"", ",", "tr_r5", ",", "pl_module", ".", "global_step", "\n", ")", "\n", "pl_module", ".", "logger", ".", "experiment", ".", "add_scalar", "(", "\n", "\"recalls/tr_r10\"", ",", "tr_r10", ",", "pl_module", ".", "global_step", "\n", ")", "\n", "the_metric", "+=", "ir_r1", ".", "item", "(", ")", "+", "tr_r1", ".", "item", "(", ")", "\n", "\n", "# add for decouple irtr", "\n", "", "if", "pl_module", ".", "hparams", ".", "config", "[", "\"get_itc_recall_metric\"", "]", "and", "not", "pl_module", ".", "training", ":", "\n", "        ", "(", "ir_r1", ",", "ir_r5", ",", "ir_r10", ",", "tr_r1", ",", "tr_r5", ",", "tr_r10", ")", "=", "compute_decouple_irtr_recall", "(", "pl_module", ")", "\n", "print", "(", "(", "ir_r1", ",", "ir_r5", ",", "ir_r10", ",", "tr_r1", ",", "tr_r5", ",", "tr_r10", ")", ",", "pl_module", ".", "global_step", ")", "\n", "pl_module", ".", "logger", ".", "experiment", ".", "add_scalar", "(", "\n", "\"recalls/ir_r1\"", ",", "ir_r1", ",", "pl_module", ".", "global_step", "\n", ")", "\n", "pl_module", ".", "logger", ".", "experiment", ".", "add_scalar", "(", "\n", "\"recalls/ir_r5\"", ",", "ir_r5", ",", "pl_module", ".", "global_step", "\n", ")", "\n", "pl_module", ".", "logger", ".", "experiment", ".", "add_scalar", "(", "\n", "\"recalls/ir_r10\"", ",", "ir_r10", ",", "pl_module", ".", "global_step", "\n", ")", "\n", "pl_module", ".", "logger", ".", "experiment", ".", "add_scalar", "(", "\n", "\"recalls/tr_r1\"", ",", "tr_r1", ",", "pl_module", ".", "global_step", "\n", ")", "\n", "pl_module", ".", "logger", ".", "experiment", ".", "add_scalar", "(", "\n", "\"recalls/tr_r5\"", ",", "tr_r5", ",", "pl_module", ".", "global_step", "\n", ")", "\n", "pl_module", ".", "logger", ".", "experiment", ".", "add_scalar", "(", "\n", "\"recalls/tr_r10\"", ",", "tr_r10", ",", "pl_module", ".", "global_step", "\n", ")", "\n", "# the_metric += ir_r1.item() + tr_r1.item()", "\n", "the_metric", "+=", "ir_r1", "+", "tr_r1", "\n", "# == end", "\n", "\n", "# add for ind irtr", "\n", "", "if", "pl_module", ".", "hparams", ".", "config", "[", "\"get_ind_recall_metric\"", "]", "and", "not", "pl_module", ".", "training", ":", "\n", "        ", "(", "ir_r1", ",", "ir_r5", ",", "ir_r10", ",", "tr_r1", ",", "tr_r5", ",", "tr_r10", ")", "=", "compute_ind_irtr_recall", "(", "pl_module", ")", "\n", "print", "(", "(", "ir_r1", ",", "ir_r5", ",", "ir_r10", ",", "tr_r1", ",", "tr_r5", ",", "tr_r10", ")", ",", "pl_module", ".", "global_step", ")", "\n", "pl_module", ".", "logger", ".", "experiment", ".", "add_scalar", "(", "\n", "\"recalls/ir_r1\"", ",", "ir_r1", ",", "pl_module", ".", "global_step", "\n", ")", "\n", "pl_module", ".", "logger", ".", "experiment", ".", "add_scalar", "(", "\n", "\"recalls/ir_r5\"", ",", "ir_r5", ",", "pl_module", ".", "global_step", "\n", ")", "\n", "pl_module", ".", "logger", ".", "experiment", ".", "add_scalar", "(", "\n", "\"recalls/ir_r10\"", ",", "ir_r10", ",", "pl_module", ".", "global_step", "\n", ")", "\n", "pl_module", ".", "logger", ".", "experiment", ".", "add_scalar", "(", "\n", "\"recalls/tr_r1\"", ",", "tr_r1", ",", "pl_module", ".", "global_step", "\n", ")", "\n", "pl_module", ".", "logger", ".", "experiment", ".", "add_scalar", "(", "\n", "\"recalls/tr_r5\"", ",", "tr_r5", ",", "pl_module", ".", "global_step", "\n", ")", "\n", "pl_module", ".", "logger", ".", "experiment", ".", "add_scalar", "(", "\n", "\"recalls/tr_r10\"", ",", "tr_r10", ",", "pl_module", ".", "global_step", "\n", ")", "\n", "# the_metric += ir_r1.item() + tr_r1.item()", "\n", "the_metric", "+=", "ir_r1", "+", "tr_r1", "\n", "# == end", "\n", "\n", "", "for", "loss_name", ",", "v", "in", "pl_module", ".", "hparams", ".", "config", "[", "\"loss_names\"", "]", ".", "items", "(", ")", ":", "\n", "        ", "if", "v", "<", "1", ":", "\n", "            ", "continue", "\n", "\n", "", "value", "=", "0", "\n", "qar_value", "=", "0", "\n", "if", "loss_name", "==", "\"vqa\"", ":", "\n", "            ", "value", "=", "getattr", "(", "pl_module", ",", "f\"{phase}_{loss_name}_score\"", ")", ".", "compute", "(", ")", "\n", "pl_module", ".", "log", "(", "f\"{loss_name}/{phase}/score_epoch\"", ",", "value", ")", "\n", "getattr", "(", "pl_module", ",", "f\"{phase}_{loss_name}_score\"", ")", ".", "reset", "(", ")", "\n", "pl_module", ".", "log", "(", "\n", "f\"{loss_name}/{phase}/loss_epoch\"", ",", "\n", "getattr", "(", "pl_module", ",", "f\"{phase}_{loss_name}_loss\"", ")", ".", "compute", "(", ")", ",", "\n", ")", "\n", "getattr", "(", "pl_module", ",", "f\"{phase}_{loss_name}_loss\"", ")", ".", "reset", "(", ")", "\n", "", "elif", "loss_name", "==", "\"vcr_q2a\"", ":", "\n", "#q2a", "\n", "            ", "pl_module", ".", "log", "(", "\n", "f\"{loss_name}/{phase}/loss_epoch\"", ",", "\n", "getattr", "(", "pl_module", ",", "f\"{phase}_{loss_name}_loss\"", ")", ".", "compute", "(", ")", ",", "\n", ")", "\n", "getattr", "(", "pl_module", ",", "f\"{phase}_{loss_name}_loss\"", ")", ".", "reset", "(", ")", "\n", "value", "=", "getattr", "(", "pl_module", ",", "f\"{phase}_{loss_name}_accuracy\"", ")", ".", "compute", "(", ")", "\n", "pl_module", ".", "log", "(", "f\"{loss_name}/{phase}/accuracy_epoch\"", ",", "value", ")", "\n", "getattr", "(", "pl_module", ",", "f\"{phase}_{loss_name}_accuracy\"", ")", ".", "reset", "(", ")", "\n", "# qar", "\n", "pl_module", ".", "log", "(", "\n", "f\"vcr_qar/{phase}/loss_epoch\"", ",", "\n", "getattr", "(", "pl_module", ",", "f\"{phase}_vcr_qar_loss\"", ")", ".", "compute", "(", ")", ",", "\n", ")", "\n", "getattr", "(", "pl_module", ",", "f\"{phase}_vcr_qar_loss\"", ")", ".", "reset", "(", ")", "\n", "qar_value", "=", "getattr", "(", "pl_module", ",", "f\"{phase}_vcr_qar_accuracy\"", ")", ".", "compute", "(", ")", "\n", "pl_module", ".", "log", "(", "f\"vcr_qar/{phase}/accuracy_epoch\"", ",", "qar_value", ")", "\n", "getattr", "(", "pl_module", ",", "f\"{phase}_vcr_qar_accuracy\"", ")", ".", "reset", "(", ")", "\n", "# mc_vqa", "\n", "", "elif", "loss_name", "==", "\"mc_vqa\"", ":", "\n", "            ", "pl_module", ".", "log", "(", "\n", "f\"{loss_name}/{phase}/loss_epoch\"", ",", "\n", "getattr", "(", "pl_module", ",", "f\"{phase}_{loss_name}_loss\"", ")", ".", "compute", "(", ")", ",", "\n", ")", "\n", "getattr", "(", "pl_module", ",", "f\"{phase}_{loss_name}_loss\"", ")", ".", "reset", "(", ")", "\n", "value", "=", "getattr", "(", "pl_module", ",", "f\"{phase}_{loss_name}_accuracy\"", ")", ".", "compute", "(", ")", "\n", "pl_module", ".", "log", "(", "f\"{loss_name}/{phase}/accuracy_epoch\"", ",", "value", ")", "\n", "getattr", "(", "pl_module", ",", "f\"{phase}_{loss_name}_accuracy\"", ")", ".", "reset", "(", ")", "\n", "", "elif", "loss_name", "==", "\"openend_vqa\"", ":", "\n", "            ", "pl_module", ".", "log", "(", "\n", "f\"{loss_name}/{phase}/loss_epoch\"", ",", "\n", "getattr", "(", "pl_module", ",", "f\"{phase}_vqa_loss\"", ")", ".", "compute", "(", ")", ",", "\n", ")", "\n", "getattr", "(", "pl_module", ",", "f\"{phase}_vqa_loss\"", ")", ".", "reset", "(", ")", "\n", "value", "=", "getattr", "(", "pl_module", ",", "f\"{phase}_{loss_name}_accuracy\"", ")", ".", "compute", "(", ")", "\n", "pl_module", ".", "log", "(", "f\"{loss_name}/{phase}/accuracy_epoch\"", ",", "value", ")", "\n", "getattr", "(", "pl_module", ",", "f\"{phase}_{loss_name}_accuracy\"", ")", ".", "reset", "(", ")", "\n", "# multiple_choice", "\n", "", "elif", "loss_name", "==", "\"multiple_choice\"", ":", "\n", "            ", "pl_module", ".", "log", "(", "\n", "f\"{loss_name}/{phase}/loss_epoch\"", ",", "\n", "getattr", "(", "pl_module", ",", "f\"{phase}_{loss_name}_loss\"", ")", ".", "compute", "(", ")", ",", "\n", ")", "\n", "getattr", "(", "pl_module", ",", "f\"{phase}_{loss_name}_loss\"", ")", ".", "reset", "(", ")", "\n", "value", "=", "getattr", "(", "pl_module", ",", "f\"{phase}_{loss_name}_accuracy\"", ")", ".", "compute", "(", ")", "\n", "pl_module", ".", "log", "(", "f\"{loss_name}/{phase}/accuracy_epoch\"", ",", "value", ")", "\n", "getattr", "(", "pl_module", ",", "f\"{phase}_{loss_name}_accuracy\"", ")", ".", "reset", "(", ")", "\n", "# vcop", "\n", "", "elif", "loss_name", "==", "\"vcop\"", ":", "\n", "            ", "pl_module", ".", "log", "(", "\n", "f\"{loss_name}/{phase}/loss_epoch\"", ",", "\n", "getattr", "(", "pl_module", ",", "f\"{phase}_{loss_name}_loss\"", ")", ".", "compute", "(", ")", ",", "\n", ")", "\n", "\n", "getattr", "(", "pl_module", ",", "f\"{phase}_{loss_name}_loss\"", ")", ".", "reset", "(", ")", "\n", "value", "=", "getattr", "(", "pl_module", ",", "f\"{phase}_{loss_name}_accuracy\"", ")", ".", "compute", "(", ")", "\n", "pl_module", ".", "log", "(", "f\"{loss_name}/{phase}/accuracy_epoch\"", ",", "value", ")", "\n", "getattr", "(", "pl_module", ",", "f\"{phase}_{loss_name}_accuracy\"", ")", ".", "reset", "(", ")", "\n", "", "elif", "loss_name", "==", "\"nlvr2\"", ":", "\n", "            ", "if", "phase", "==", "\"train\"", ":", "\n", "                ", "value", "=", "getattr", "(", "pl_module", ",", "f\"train_{loss_name}_accuracy\"", ")", ".", "compute", "(", ")", "\n", "pl_module", ".", "log", "(", "f\"{loss_name}/train/accuracy_epoch\"", ",", "value", ")", "\n", "getattr", "(", "pl_module", ",", "f\"train_{loss_name}_accuracy\"", ")", ".", "reset", "(", ")", "\n", "pl_module", ".", "log", "(", "\n", "f\"{loss_name}/train/loss_epoch\"", ",", "\n", "getattr", "(", "pl_module", ",", "f\"train_{loss_name}_loss\"", ")", ".", "compute", "(", ")", ",", "\n", ")", "\n", "getattr", "(", "pl_module", ",", "f\"train_{loss_name}_loss\"", ")", ".", "reset", "(", ")", "\n", "", "else", ":", "\n", "                ", "value", "=", "getattr", "(", "pl_module", ",", "f\"dev_{loss_name}_accuracy\"", ")", ".", "compute", "(", ")", "\n", "pl_module", ".", "log", "(", "f\"{loss_name}/dev/accuracy_epoch\"", ",", "value", ")", "\n", "getattr", "(", "pl_module", ",", "f\"dev_{loss_name}_accuracy\"", ")", ".", "reset", "(", ")", "\n", "pl_module", ".", "log", "(", "\n", "f\"{loss_name}/dev/loss_epoch\"", ",", "\n", "getattr", "(", "pl_module", ",", "f\"dev_{loss_name}_loss\"", ")", ".", "compute", "(", ")", ",", "\n", ")", "\n", "getattr", "(", "pl_module", ",", "f\"dev_{loss_name}_loss\"", ")", ".", "reset", "(", ")", "\n", "\n", "value", "=", "getattr", "(", "pl_module", ",", "f\"test_{loss_name}_accuracy\"", ")", ".", "compute", "(", ")", "\n", "pl_module", ".", "log", "(", "f\"{loss_name}/test/accuracy_epoch\"", ",", "value", ")", "\n", "getattr", "(", "pl_module", ",", "f\"test_{loss_name}_accuracy\"", ")", ".", "reset", "(", ")", "\n", "pl_module", ".", "log", "(", "\n", "f\"{loss_name}/test/loss_epoch\"", ",", "\n", "getattr", "(", "pl_module", ",", "f\"test_{loss_name}_loss\"", ")", ".", "compute", "(", ")", ",", "\n", ")", "\n", "getattr", "(", "pl_module", ",", "f\"test_{loss_name}_loss\"", ")", ".", "reset", "(", ")", "\n", "", "", "elif", "loss_name", "==", "\"irtr\"", ":", "\n", "            ", "pl_module", ".", "log", "(", "\n", "f\"{loss_name}/{phase}/irtr_loss_epoch\"", ",", "\n", "getattr", "(", "pl_module", ",", "f\"{phase}_irtr_loss\"", ")", ".", "compute", "(", ")", ",", "\n", ")", "\n", "getattr", "(", "pl_module", ",", "f\"{phase}_irtr_loss\"", ")", ".", "reset", "(", ")", "\n", "", "elif", "loss_name", "==", "\"mppd\"", "or", "loss_name", "==", "\"mpfr\"", ":", "\n", "            ", "pl_module", ".", "log", "(", "\n", "f\"{loss_name}/{phase}/loss_epoch\"", ",", "\n", "getattr", "(", "pl_module", ",", "f\"{phase}_{loss_name}_loss\"", ")", ".", "compute", "(", ")", ",", "\n", ")", "\n", "getattr", "(", "pl_module", ",", "f\"{phase}_{loss_name}_loss\"", ")", ".", "reset", "(", ")", "\n", "", "elif", "loss_name", "==", "\"itm\"", ":", "\n", "            ", "value", "=", "getattr", "(", "pl_module", ",", "f\"{phase}_{loss_name}_accuracy\"", ")", ".", "compute", "(", ")", "\n", "pl_module", ".", "log", "(", "f\"{loss_name}/{phase}/accuracy_epoch\"", ",", "value", ")", "\n", "getattr", "(", "pl_module", ",", "f\"{phase}_{loss_name}_accuracy\"", ")", ".", "reset", "(", ")", "\n", "pl_module", ".", "log", "(", "\n", "f\"{loss_name}/{phase}/loss_epoch\"", ",", "\n", "getattr", "(", "pl_module", ",", "f\"{phase}_{loss_name}_loss\"", ")", ".", "compute", "(", ")", ",", "\n", ")", "\n", "getattr", "(", "pl_module", ",", "f\"{phase}_{loss_name}_loss\"", ")", ".", "reset", "(", ")", "\n", "pl_module", ".", "log", "(", "\n", "f\"{loss_name}/{phase}/wpa_loss_epoch\"", ",", "\n", "getattr", "(", "pl_module", ",", "f\"{phase}_{loss_name}_wpa_loss\"", ")", ".", "compute", "(", ")", ",", "\n", ")", "\n", "getattr", "(", "pl_module", ",", "f\"{phase}_{loss_name}_wpa_loss\"", ")", ".", "reset", "(", ")", "\n", "# add for itc", "\n", "", "elif", "loss_name", "==", "\"itc\"", ":", "\n", "            ", "pl_module", ".", "log", "(", "\n", "f\"{loss_name}/{phase}/loss_epoch\"", ",", "\n", "getattr", "(", "pl_module", ",", "f\"{phase}_{loss_name}_loss\"", ")", ".", "compute", "(", ")", ",", "\n", ")", "\n", "getattr", "(", "pl_module", ",", "f\"{phase}_{loss_name}_loss\"", ")", ".", "reset", "(", ")", "\n", "# add for ind_itc", "\n", "", "elif", "loss_name", "==", "\"ind_itc\"", ":", "\n", "            ", "pl_module", ".", "log", "(", "\n", "f\"{loss_name}/{phase}/loss_epoch\"", ",", "\n", "getattr", "(", "pl_module", ",", "f\"{phase}_{loss_name}_loss\"", ")", ".", "compute", "(", ")", ",", "\n", ")", "\n", "# value = f\"{loss_name}/{phase}/loss_epoch\",", "\n", "getattr", "(", "pl_module", ",", "f\"{phase}_{loss_name}_loss\"", ")", ".", "reset", "(", ")", "\n", "", "else", ":", "\n", "            ", "value", "=", "getattr", "(", "pl_module", ",", "f\"{phase}_{loss_name}_accuracy\"", ")", ".", "compute", "(", ")", "\n", "pl_module", ".", "log", "(", "f\"{loss_name}/{phase}/accuracy_epoch\"", ",", "value", ")", "\n", "getattr", "(", "pl_module", ",", "f\"{phase}_{loss_name}_accuracy\"", ")", ".", "reset", "(", ")", "\n", "pl_module", ".", "log", "(", "\n", "f\"{loss_name}/{phase}/loss_epoch\"", ",", "\n", "getattr", "(", "pl_module", ",", "f\"{phase}_{loss_name}_loss\"", ")", ".", "compute", "(", ")", ",", "\n", ")", "\n", "getattr", "(", "pl_module", ",", "f\"{phase}_{loss_name}_loss\"", ")", ".", "reset", "(", ")", "\n", "\n", "", "if", "loss_name", "==", "\"vcr_q2a\"", ":", "\n", "# print(value, qar_value)", "\n", "            ", "the_metric", "+=", "qar_value", "/", "2", "+", "value", "/", "2", "\n", "", "else", ":", "\n", "            ", "the_metric", "+=", "value", "\n", "\n", "", "", "pl_module", ".", "log", "(", "f\"{phase}/the_metric\"", ",", "the_metric", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.modules.allinone_utils.check_non_acc_grad": [[311, 317], ["grad.sum"], "function", ["None"], ["", "def", "check_non_acc_grad", "(", "pl_module", ")", ":", "\n", "    ", "if", "pl_module", ".", "token_type_embeddings", ".", "weight", ".", "grad", "is", "None", ":", "\n", "        ", "return", "True", "\n", "", "else", ":", "\n", "        ", "grad", "=", "pl_module", ".", "token_type_embeddings", ".", "weight", ".", "grad", "\n", "return", "(", "grad", ".", "sum", "(", ")", "==", "0", ")", ".", "item", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.modules.allinone_utils.set_task": [[319, 324], ["pl_module.hparams.config[].items"], "function", ["None"], ["", "", "def", "set_task", "(", "pl_module", ")", ":", "\n", "    ", "pl_module", ".", "current_tasks", "=", "[", "\n", "k", "for", "k", ",", "v", "in", "pl_module", ".", "hparams", ".", "config", "[", "\"loss_names\"", "]", ".", "items", "(", ")", "if", "v", ">=", "1", "\n", "]", "\n", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.modules.allinone_utils.set_schedule": [[326, 431], ["isinstance", "transformers.optimization.AdamW", "int", "transformers.get_cosine_schedule_with_warmup", "transformers.get_polynomial_decay_schedule_with_warmup", "pl_module.named_parameters", "torch.optim.Adam", "torch.optim.SGD", "len", "pl_module.named_parameters", "pl_module.named_parameters", "pl_module.named_parameters", "pl_module.named_parameters", "pl_module.trainer.datamodule.train_dataloader", "any", "any", "any", "any", "any", "any", "any", "any"], "function", ["home.repos.pwc.inspect_result.showlab_all-in-one.image.datamodule_base.BaseDataModule.train_dataloader"], ["", "def", "set_schedule", "(", "pl_module", ")", ":", "\n", "    ", "lr", "=", "pl_module", ".", "hparams", ".", "config", "[", "\"learning_rate\"", "]", "\n", "wd", "=", "pl_module", ".", "hparams", ".", "config", "[", "\"weight_decay\"", "]", "\n", "\n", "no_decay", "=", "[", "\n", "\"bias\"", ",", "\n", "\"LayerNorm.bias\"", ",", "\n", "\"LayerNorm.weight\"", ",", "\n", "\"norm.bias\"", ",", "\n", "\"norm.weight\"", ",", "\n", "\"norm1.bias\"", ",", "\n", "\"norm1.weight\"", ",", "\n", "\"norm2.bias\"", ",", "\n", "\"norm2.weight\"", ",", "\n", "]", "\n", "head_names", "=", "[", "\"vqa_classifier\"", ",", "\"nlvr2_classifier\"", "]", "\n", "lr_mult", "=", "pl_module", ".", "hparams", ".", "config", "[", "\"lr_mult\"", "]", "\n", "end_lr", "=", "pl_module", ".", "hparams", ".", "config", "[", "\"end_lr\"", "]", "\n", "decay_power", "=", "pl_module", ".", "hparams", ".", "config", "[", "\"decay_power\"", "]", "\n", "optim_type", "=", "pl_module", ".", "hparams", ".", "config", "[", "\"optim_type\"", "]", "\n", "\n", "names", "=", "[", "n", "for", "n", ",", "p", "in", "pl_module", ".", "named_parameters", "(", ")", "]", "\n", "optimizer_grouped_parameters", "=", "[", "\n", "{", "\n", "\"params\"", ":", "[", "\n", "p", "\n", "for", "n", ",", "p", "in", "pl_module", ".", "named_parameters", "(", ")", "\n", "if", "not", "any", "(", "nd", "in", "n", "for", "nd", "in", "no_decay", ")", "\n", "and", "not", "any", "(", "bb", "in", "n", "for", "bb", "in", "head_names", ")", "\n", "]", ",", "\n", "\"weight_decay\"", ":", "wd", ",", "\n", "\"lr\"", ":", "lr", ",", "\n", "}", ",", "\n", "{", "\n", "\"params\"", ":", "[", "\n", "p", "\n", "for", "n", ",", "p", "in", "pl_module", ".", "named_parameters", "(", ")", "\n", "if", "any", "(", "nd", "in", "n", "for", "nd", "in", "no_decay", ")", "\n", "and", "not", "any", "(", "bb", "in", "n", "for", "bb", "in", "head_names", ")", "\n", "]", ",", "\n", "\"weight_decay\"", ":", "0.0", ",", "\n", "\"lr\"", ":", "lr", ",", "\n", "}", ",", "\n", "{", "\n", "\"params\"", ":", "[", "\n", "p", "\n", "for", "n", ",", "p", "in", "pl_module", ".", "named_parameters", "(", ")", "\n", "if", "not", "any", "(", "nd", "in", "n", "for", "nd", "in", "no_decay", ")", "\n", "and", "any", "(", "bb", "in", "n", "for", "bb", "in", "head_names", ")", "\n", "]", ",", "\n", "\"weight_decay\"", ":", "wd", ",", "\n", "\"lr\"", ":", "lr", "*", "lr_mult", ",", "\n", "}", ",", "\n", "{", "\n", "\"params\"", ":", "[", "\n", "p", "\n", "for", "n", ",", "p", "in", "pl_module", ".", "named_parameters", "(", ")", "\n", "if", "any", "(", "nd", "in", "n", "for", "nd", "in", "no_decay", ")", "and", "any", "(", "bb", "in", "n", "for", "bb", "in", "head_names", ")", "\n", "]", ",", "\n", "\"weight_decay\"", ":", "0.0", ",", "\n", "\"lr\"", ":", "lr", "*", "lr_mult", ",", "\n", "}", ",", "\n", "]", "\n", "\n", "if", "optim_type", "==", "\"adamw\"", ":", "\n", "        ", "optimizer", "=", "AdamW", "(", "\n", "optimizer_grouped_parameters", ",", "lr", "=", "lr", ",", "eps", "=", "1e-8", ",", "betas", "=", "(", "0.9", ",", "0.98", ")", "\n", ")", "\n", "", "elif", "optim_type", "==", "\"adam\"", ":", "\n", "        ", "optimizer", "=", "torch", ".", "optim", ".", "Adam", "(", "optimizer_grouped_parameters", ",", "lr", "=", "lr", ")", "\n", "", "elif", "optim_type", "==", "\"sgd\"", ":", "\n", "        ", "optimizer", "=", "torch", ".", "optim", ".", "SGD", "(", "optimizer_grouped_parameters", ",", "lr", "=", "lr", ",", "momentum", "=", "0.9", ")", "\n", "\n", "", "if", "pl_module", ".", "trainer", ".", "max_steps", "is", "None", ":", "\n", "        ", "max_steps", "=", "(", "\n", "len", "(", "pl_module", ".", "trainer", ".", "datamodule", ".", "train_dataloader", "(", ")", ")", "\n", "*", "pl_module", ".", "trainer", ".", "max_epochs", "\n", "//", "pl_module", ".", "trainer", ".", "accumulate_grad_batches", "\n", ")", "\n", "", "else", ":", "\n", "        ", "max_steps", "=", "pl_module", ".", "trainer", ".", "max_steps", "\n", "\n", "", "warmup_steps", "=", "pl_module", ".", "hparams", ".", "config", "[", "\"warmup_steps\"", "]", "\n", "if", "isinstance", "(", "pl_module", ".", "hparams", ".", "config", "[", "\"warmup_steps\"", "]", ",", "float", ")", ":", "\n", "        ", "warmup_steps", "=", "int", "(", "max_steps", "*", "warmup_steps", ")", "\n", "\n", "", "if", "decay_power", "==", "\"cosine\"", ":", "\n", "        ", "scheduler", "=", "get_cosine_schedule_with_warmup", "(", "\n", "optimizer", ",", "\n", "num_warmup_steps", "=", "warmup_steps", ",", "\n", "num_training_steps", "=", "max_steps", ",", "\n", ")", "\n", "", "else", ":", "\n", "        ", "scheduler", "=", "get_polynomial_decay_schedule_with_warmup", "(", "\n", "optimizer", ",", "\n", "num_warmup_steps", "=", "warmup_steps", ",", "\n", "num_training_steps", "=", "max_steps", ",", "\n", "lr_end", "=", "end_lr", ",", "\n", "power", "=", "decay_power", ",", "\n", ")", "\n", "", "sched", "=", "{", "\"scheduler\"", ":", "scheduler", ",", "\"interval\"", ":", "\"step\"", "}", "\n", "\n", "return", "(", "\n", "[", "optimizer", "]", ",", "\n", "[", "sched", "]", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.modules.allinone_utils.state_dict_data_parallel_fix": [[434, 461], ["list", "list", "load_state_dict.keys", "curr_state_dict.keys", "load_keys[].startswith", "OrderedDict", "load_state_dict.items", "curr_keys[].startswith", "curr_keys[].startswith", "OrderedDict", "load_state_dict.items", "load_keys[].startswith"], "function", ["None"], ["", "def", "state_dict_data_parallel_fix", "(", "load_state_dict", ",", "curr_state_dict", ")", ":", "\n", "    ", "load_keys", "=", "list", "(", "load_state_dict", ".", "keys", "(", ")", ")", "\n", "curr_keys", "=", "list", "(", "curr_state_dict", ".", "keys", "(", ")", ")", "\n", "\n", "redo_dp", "=", "False", "\n", "undo_dp", "=", "False", "\n", "if", "not", "curr_keys", "[", "0", "]", ".", "startswith", "(", "'module.'", ")", "and", "load_keys", "[", "0", "]", ".", "startswith", "(", "'module.'", ")", ":", "\n", "        ", "undo_dp", "=", "True", "\n", "", "elif", "curr_keys", "[", "0", "]", ".", "startswith", "(", "'module.'", ")", "and", "not", "load_keys", "[", "0", "]", ".", "startswith", "(", "'module.'", ")", ":", "\n", "        ", "redo_dp", "=", "True", "\n", "\n", "", "if", "undo_dp", ":", "\n", "        ", "from", "collections", "import", "OrderedDict", "\n", "new_state_dict", "=", "OrderedDict", "(", ")", "\n", "for", "k", ",", "v", "in", "load_state_dict", ".", "items", "(", ")", ":", "\n", "            ", "name", "=", "k", "[", "7", ":", "]", "# remove `module.`", "\n", "new_state_dict", "[", "name", "]", "=", "v", "\n", "# load params", "\n", "", "", "elif", "redo_dp", ":", "\n", "        ", "from", "collections", "import", "OrderedDict", "\n", "new_state_dict", "=", "OrderedDict", "(", ")", "\n", "for", "k", ",", "v", "in", "load_state_dict", ".", "items", "(", ")", ":", "\n", "            ", "name", "=", "'module.'", "+", "k", "# remove `module.`", "\n", "new_state_dict", "[", "name", "]", "=", "v", "\n", "", "", "else", ":", "\n", "        ", "new_state_dict", "=", "load_state_dict", "\n", "", "return", "new_state_dict", "", "", ""]], "home.repos.pwc.inspect_result.showlab_all-in-one.modules.heads.ITMHead.__init__": [[23, 26], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.transforms.utils.UnNormalize.__init__"], ["    ", "def", "__init__", "(", "self", ",", "hidden_size", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "fc", "=", "nn", ".", "Linear", "(", "hidden_size", ",", "2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.modules.heads.ITMHead.forward": [[27, 30], ["heads.ITMHead.fc"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "fc", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.modules.allinone_module.VCOPHeader.__init__": [[16, 30], ["super().__init__", "torch.Linear", "torch.Linear", "torch.Linear", "int", "math.factorial", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.ReLU", "torch.ReLU", "torch.ReLU"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.transforms.utils.UnNormalize.__init__"], ["    ", "def", "__init__", "(", "self", ",", "tuple_len", "=", "3", ",", "feature_size", "=", "768", ")", ":", "\n", "        ", "\"\"\"\n        In the constructor we instantiate two nn.Linear modules and assign them as\n        member variables.\n        \"\"\"", "\n", "super", "(", "VCOPHeader", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "feature_size", "=", "feature_size", "\n", "self", ".", "fc7", "=", "nn", ".", "Linear", "(", "self", ".", "feature_size", "*", "2", ",", "512", ")", "\n", "self", ".", "tuple_len", "=", "tuple_len", "\n", "pair_num", "=", "int", "(", "tuple_len", "*", "(", "tuple_len", "-", "1", ")", "/", "2", ")", "\n", "self", ".", "class_num", "=", "math", ".", "factorial", "(", "tuple_len", ")", "\n", "self", ".", "fc8", "=", "nn", ".", "Linear", "(", "512", "*", "pair_num", ",", "self", ".", "class_num", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "p", "=", "0.5", ")", "\n", "self", ".", "relu", "=", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.modules.allinone_module.VCOPHeader.forward": [[31, 44], ["range", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "allinone_module.VCOPHeader.dropout", "allinone_module.VCOPHeader.fc8", "range", "allinone_module.VCOPHeader.fc7", "allinone_module.VCOPHeader.relu", "pf.append", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "\"\"\"\n        \"\"\"", "\n", "pf", "=", "[", "]", "# pairwise concat", "\n", "for", "i", "in", "range", "(", "self", ".", "tuple_len", ")", ":", "\n", "            ", "for", "j", "in", "range", "(", "i", "+", "1", ",", "self", ".", "tuple_len", ")", ":", "\n", "                ", "pf", ".", "append", "(", "torch", ".", "cat", "(", "[", "x", "[", ":", ",", "i", "]", ",", "x", "[", ":", ",", "j", "]", "]", ",", "dim", "=", "1", ")", ")", "\n", "", "", "pf", "=", "[", "self", ".", "fc7", "(", "i", ")", "for", "i", "in", "pf", "]", "\n", "pf", "=", "[", "self", ".", "relu", "(", "i", ")", "for", "i", "in", "pf", "]", "\n", "h", "=", "torch", ".", "cat", "(", "pf", ",", "dim", "=", "1", ")", "\n", "h", "=", "self", ".", "dropout", "(", "h", ")", "\n", "h", "=", "self", ".", "fc8", "(", "h", ")", "# logits", "\n", "return", "h", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.modules.allinone_module.AllinoneTransformerSS.__init__": [[47, 288], ["pytorch_lightning.LightningModule.__init__", "allinone_module.AllinoneTransformerSS.save_hyperparameters", "transformers.models.bert.modeling_bert.BertConfig", "transformers.models.bert.modeling_bert.BertEmbeddings", "allinone_module.AllinoneTransformerSS.text_embeddings.apply", "torch.Embedding", "torch.Embedding", "torch.Embedding", "allinone_module.AllinoneTransformerSS.token_type_embeddings.apply", "AllInOne.modules.heads.Pooler", "allinone_module.AllinoneTransformerSS.pooler.apply", "AllInOne.modules.allinone_utils.set_metrics", "list", "AllInOne.modules.temporal_roll.TemporalRoll", "allinone_module.AllinoneTransformerSS.named_parameters", "AllInOne.transforms.mix.SpatialMixup", "AllInOne.modules.heads.MLMHead", "allinone_module.AllinoneTransformerSS.mlm_score.apply", "AllInOne.modules.heads.ITMHead", "allinone_module.AllinoneTransformerSS.itm_score.apply", "AllInOne.modules.heads.MPPHead", "allinone_module.AllinoneTransformerSS.mpp_score.apply", "print", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "allinone_module.AllinoneTransformerSS.txt_proj.apply", "allinone_module.AllinoneTransformerSS.vid_proj.apply", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "allinone_module.AllinoneTransformerSS._inflate_positional_embeds", "allinone_module.AllinoneTransformerSS.load_state_dict", "allinone_module.AllinoneTransformerSS.named_parameters", "AllInOne.modules.heads.ITMHead", "allinone_module.AllinoneTransformerSS.itm_score.apply", "AllInOne.modules.heads.ITMHead", "allinone_module.AllinoneTransformerSS.itm_score.apply", "AllInOne.modules.heads.ITMHead", "allinone_module.AllinoneTransformerSS.itm_score.apply", "torch.Sequential", "torch.Sequential", "torch.Sequential", "allinone_module.AllinoneTransformerSS.vqa_classifier.apply", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "allinone_module.VCOPHeader", "torch.Sequential", "torch.Sequential", "torch.Sequential", "allinone_module.AllinoneTransformerSS.mc_vqa_classifier.apply", "torch.Sequential", "torch.Sequential", "torch.Sequential", "allinone_module.AllinoneTransformerSS.vqa_classifier.apply", "torch.Sequential", "torch.Sequential", "torch.Sequential", "allinone_module.AllinoneTransformerSS.nlvr2_classifier.apply", "torch.Embedding", "torch.Embedding", "torch.Embedding", "allinone_module.AllinoneTransformerSS.token_type_embeddings.apply", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "print", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "allinone_module.AllinoneTransformerSS._inflate_positional_embeds", "allinone_module.AllinoneTransformerSS.load_state_dict", "getattr", "allinone_module.AllinoneTransformerSS.text_embeddings.position_embeddings.weight.size", "state_dict[].size", "allinone_module.AllinoneTransformerSS.pop", "allinone_module.AllinoneTransformerSS.pop", "torch.Linear", "torch.Linear", "torch.Linear", "torch.LayerNorm", "torch.LayerNorm", "torch.LayerNorm", "torch.GELU", "torch.GELU", "torch.GELU", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Linear", "torch.Linear", "torch.Linear", "torch.LayerNorm", "torch.LayerNorm", "torch.LayerNorm", "torch.GELU", "torch.GELU", "torch.GELU", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Linear", "torch.Linear", "torch.Linear", "torch.LayerNorm", "torch.LayerNorm", "torch.LayerNorm", "torch.GELU", "torch.GELU", "torch.GELU", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.LayerNorm", "torch.LayerNorm", "torch.LayerNorm", "torch.GELU", "torch.GELU", "torch.GELU", "torch.Linear", "torch.Linear", "torch.Linear", "print", "getattr", "print"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.transforms.utils.UnNormalize.__init__", "home.repos.pwc.inspect_result.showlab_all-in-one.modules.allinone_utils.set_metrics", "home.repos.pwc.inspect_result.showlab_all-in-one.modules.allinone_module.AllinoneTransformerSS._inflate_positional_embeds", "home.repos.pwc.inspect_result.showlab_all-in-one.modules.allinone_module.AllinoneTransformerSS._inflate_positional_embeds"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "save_hyperparameters", "(", ")", "\n", "\n", "bert_config", "=", "BertConfig", "(", "\n", "vocab_size", "=", "config", "[", "\"vocab_size\"", "]", ",", "\n", "hidden_size", "=", "config", "[", "\"hidden_size\"", "]", ",", "\n", "num_hidden_layers", "=", "config", "[", "\"num_layers\"", "]", ",", "\n", "num_attention_heads", "=", "config", "[", "\"num_heads\"", "]", ",", "\n", "intermediate_size", "=", "config", "[", "\"hidden_size\"", "]", "*", "config", "[", "\"mlp_ratio\"", "]", ",", "\n", "max_position_embeddings", "=", "config", "[", "\"max_text_len\"", "]", ",", "\n", "hidden_dropout_prob", "=", "config", "[", "\"drop_rate\"", "]", ",", "\n", "attention_probs_dropout_prob", "=", "config", "[", "\"drop_rate\"", "]", ",", "\n", ")", "\n", "\n", "self", ".", "text_embeddings", "=", "BertEmbeddings", "(", "bert_config", ")", "\n", "self", ".", "text_embeddings", ".", "apply", "(", "objectives", ".", "init_weights", ")", "\n", "\n", "self", ".", "token_type_embeddings", "=", "nn", ".", "Embedding", "(", "2", ",", "config", "[", "\"hidden_size\"", "]", ")", "\n", "self", ".", "token_type_embeddings", ".", "apply", "(", "objectives", ".", "init_weights", ")", "\n", "\n", "flag", "=", "0", "\n", "if", "self", ".", "hparams", ".", "config", "[", "\"load_path\"", "]", "==", "\"\"", ":", "\n", "            ", "while", "not", "flag", "==", "1", ":", "\n", "                ", "try", ":", "\n", "                    ", "self", ".", "transformer", "=", "getattr", "(", "vit", ",", "self", ".", "hparams", ".", "config", "[", "\"vit\"", "]", ")", "(", "\n", "pretrained", "=", "True", ",", "config", "=", "self", ".", "hparams", ".", "config", "\n", ")", "\n", "flag", "=", "1", "\n", "", "except", ":", "\n", "                    ", "print", "(", "\"load pretrained failed, try again\"", ")", "\n", "flag", "=", "0", "\n", "", "", "", "else", ":", "\n", "            ", "self", ".", "transformer", "=", "getattr", "(", "vit", ",", "self", ".", "hparams", ".", "config", "[", "\"vit\"", "]", ")", "(", "\n", "pretrained", "=", "False", ",", "config", "=", "self", ".", "hparams", ".", "config", "\n", ")", "\n", "\n", "", "self", ".", "pooler", "=", "heads", ".", "Pooler", "(", "config", "[", "\"hidden_size\"", "]", ")", "\n", "self", ".", "pooler", ".", "apply", "(", "objectives", ".", "init_weights", ")", "\n", "\n", "# num frames", "\n", "self", ".", "num_frames", "=", "config", "[", "\"num_frames\"", "]", "# a global variable to identify if image/video", "\n", "\n", "if", "config", "[", "\"loss_names\"", "]", "[", "\"mlm\"", "]", ">", "0", ":", "\n", "            ", "self", ".", "mlm_score", "=", "heads", ".", "MLMHead", "(", "bert_config", ")", "\n", "self", ".", "mlm_score", ".", "apply", "(", "objectives", ".", "init_weights", ")", "\n", "\n", "", "if", "config", "[", "\"loss_names\"", "]", "[", "\"itm\"", "]", ">", "0", ":", "\n", "            ", "self", ".", "itm_score", "=", "heads", ".", "ITMHead", "(", "config", "[", "\"hidden_size\"", "]", ")", "\n", "self", ".", "itm_score", ".", "apply", "(", "objectives", ".", "init_weights", ")", "\n", "\n", "", "if", "config", "[", "\"loss_names\"", "]", "[", "\"mpp\"", "]", ">", "0", ":", "\n", "            ", "self", ".", "mpp_score", "=", "heads", ".", "MPPHead", "(", "bert_config", ")", "\n", "self", ".", "mpp_score", ".", "apply", "(", "objectives", ".", "init_weights", ")", "\n", "\n", "# ind_itc may also used for pretrain", "\n", "# == for video text contrastive learning", "\n", "", "if", "config", "[", "\"loss_names\"", "]", "[", "\"ind_itc\"", "]", ">", "0", ":", "\n", "            ", "print", "(", "\"initalize video project and txt projection\"", ")", "\n", "# v1", "\n", "self", ".", "txt_proj", "=", "nn", ".", "Linear", "(", "config", "[", "\"hidden_size\"", "]", ",", "config", "[", "\"shared_embedding_dim\"", "]", ")", "\n", "self", ".", "vid_proj", "=", "nn", ".", "Linear", "(", "config", "[", "\"hidden_size\"", "]", ",", "config", "[", "\"shared_embedding_dim\"", "]", ")", "\n", "# v2", "\n", "# self.vid_proj = nn.Sequential(", "\n", "#     nn.Dropout(0.5),", "\n", "#     nn.Linear(config[\"hidden_size\"], config[\"hidden_size\"] // 2),", "\n", "#     nn.LayerNorm(config[\"hidden_size\"] // 2),", "\n", "#     nn.GELU(),", "\n", "#     nn.Linear(config[\"hidden_size\"] // 2, config[\"shared_embedding_dim\"]),", "\n", "# )", "\n", "# self.txt_proj = nn.Sequential(", "\n", "#     nn.Dropout(0.5),", "\n", "#     nn.Linear(config[\"hidden_size\"], config[\"hidden_size\"] // 2),", "\n", "#     nn.LayerNorm(config[\"hidden_size\"] // 2),", "\n", "#     nn.GELU(),", "\n", "#     nn.Linear(config[\"hidden_size\"] // 2, config[\"shared_embedding_dim\"]),", "\n", "# )", "\n", "self", ".", "txt_proj", ".", "apply", "(", "objectives", ".", "init_weights", ")", "\n", "self", ".", "vid_proj", ".", "apply", "(", "objectives", ".", "init_weights", ")", "\n", "# == end", "\n", "", "if", "(", "\n", "self", ".", "hparams", ".", "config", "[", "\"load_path\"", "]", "!=", "\"\"", "\n", "and", "not", "self", ".", "hparams", ".", "config", "[", "\"test_only\"", "]", "\n", ")", ":", "\n", "            ", "ckpt", "=", "torch", ".", "load", "(", "self", ".", "hparams", ".", "config", "[", "\"load_path\"", "]", ",", "map_location", "=", "\"cpu\"", ")", "\n", "state_dict", "=", "ckpt", "[", "\"state_dict\"", "]", "\n", "if", "self", ".", "text_embeddings", ".", "position_embeddings", ".", "weight", ".", "size", "(", ")", "!=", "state_dict", "[", "'text_embeddings.position_embeddings.weight'", "]", ".", "size", "(", ")", ":", "\n", "                ", "state_dict", ".", "pop", "(", "'text_embeddings.position_embeddings.weight'", ",", "None", ")", "\n", "state_dict", ".", "pop", "(", "'text_embeddings.position_ids'", ",", "None", ")", "\n", "", "state_dict", "=", "self", ".", "_inflate_positional_embeds", "(", "state_dict", ")", "\n", "self", ".", "load_state_dict", "(", "state_dict", ",", "strict", "=", "False", ")", "\n", "", "if", "self", ".", "hparams", ".", "config", "[", "\"linear_evaluation\"", "]", ":", "\n", "            ", "for", "name", ",", "param", "in", "self", ".", "named_parameters", "(", ")", ":", "\n", "# only train project layer", "\n", "                ", "if", "'mlm_score'", "in", "name", "or", "'itm_score'", "in", "name", "or", "'mpp_score'", "in", "name", ":", "\n", "                    ", "param", ".", "requires_grad", "=", "True", "\n", "", "elif", "'txt_proj'", "in", "name", "or", "'vid_proj'", "in", "name", ":", "\n", "                    ", "param", ".", "requires_grad", "=", "True", "\n", "", "elif", "'pooler'", "in", "name", ":", "\n", "                    ", "param", ".", "requires_grad", "=", "True", "\n", "", "else", ":", "\n", "                    ", "param", ".", "requires_grad", "=", "False", "\n", "# flag = False", "\n", "# for name, param in self.named_parameters():", "\n", "#     if '20' in name:", "\n", "#         flag = True", "\n", "#     param.requires_grad = flag", "\n", "# trainable_params = filter(lambda p: p.requires_grad, self.parameters())", "\n", "# ===================== Downstream ===================== #", "\n", "\n", "", "", "", "hs", "=", "self", ".", "hparams", ".", "config", "[", "\"hidden_size\"", "]", "\n", "# print(config[\"loss_names\"])", "\n", "if", "config", "[", "\"loss_names\"", "]", "[", "\"multiple_choice\"", "]", ">", "0", ":", "\n", "            ", "self", ".", "itm_score", "=", "heads", ".", "ITMHead", "(", "config", "[", "\"hidden_size\"", "]", ")", "\n", "self", ".", "itm_score", ".", "apply", "(", "objectives", ".", "init_weights", ")", "\n", "\n", "# :  vcr q2a task", "\n", "", "if", "config", "[", "\"loss_names\"", "]", "[", "\"vcr_q2a\"", "]", ">", "0", ":", "\n", "            ", "self", ".", "itm_score", "=", "heads", ".", "ITMHead", "(", "config", "[", "\"hidden_size\"", "]", ")", "\n", "self", ".", "itm_score", ".", "apply", "(", "objectives", ".", "init_weights", ")", "\n", "\n", "# :  tvqa", "\n", "", "if", "config", "[", "\"loss_names\"", "]", "[", "\"mc_vqa\"", "]", ">", "0", ":", "\n", "            ", "self", ".", "itm_score", "=", "heads", ".", "ITMHead", "(", "config", "[", "\"hidden_size\"", "]", ")", "\n", "self", ".", "itm_score", ".", "apply", "(", "objectives", ".", "init_weights", ")", "\n", "\n", "", "if", "self", ".", "hparams", ".", "config", "[", "\"loss_names\"", "]", "[", "\"vqa\"", "]", ">", "0", ":", "\n", "            ", "vs", "=", "self", ".", "hparams", ".", "config", "[", "\"vqav2_label_size\"", "]", "\n", "self", ".", "vqa_classifier", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "hs", ",", "hs", "*", "2", ")", ",", "\n", "nn", ".", "LayerNorm", "(", "hs", "*", "2", ")", ",", "\n", "nn", ".", "GELU", "(", ")", ",", "\n", "nn", ".", "Linear", "(", "hs", "*", "2", ",", "vs", ")", ",", "\n", ")", "\n", "self", ".", "vqa_classifier", ".", "apply", "(", "objectives", ".", "init_weights", ")", "\n", "\n", "# : add for vcr: q2a", "\n", "", "if", "self", ".", "hparams", ".", "config", "[", "\"loss_names\"", "]", "[", "\"vcr_q2a\"", "]", ">", "0", ":", "\n", "# for q2a", "\n", "            ", "self", ".", "rank_output", "=", "nn", ".", "Linear", "(", "hs", ",", "1", ")", "\n", "self", ".", "rank_output", ".", "weight", ".", "data", "=", "self", ".", "itm_score", ".", "fc", ".", "weight", ".", "data", "[", "1", ":", ",", ":", "]", "\n", "self", ".", "rank_output", ".", "bias", ".", "data", "=", "self", ".", "itm_score", ".", "fc", ".", "bias", ".", "data", "[", "1", ":", "]", "\n", "# for qa2r", "\n", "self", ".", "rank_output_2", "=", "nn", ".", "Linear", "(", "hs", ",", "1", ")", "\n", "self", ".", "rank_output_2", ".", "weight", ".", "data", "=", "self", ".", "itm_score", ".", "fc", ".", "weight", ".", "data", "[", "1", ":", ",", ":", "]", "\n", "self", ".", "rank_output_2", ".", "bias", ".", "data", "=", "self", ".", "itm_score", ".", "fc", ".", "bias", ".", "data", "[", "1", ":", "]", "\n", "\n", "self", ".", "margin", "=", "0.2", "\n", "\n", "# add for vcop prediction", "\n", "", "if", "self", ".", "hparams", ".", "config", "[", "\"loss_names\"", "]", "[", "\"vcop\"", "]", ">", "0", ":", "\n", "            ", "self", ".", "vcop_classifier", "=", "VCOPHeader", "(", "tuple_len", "=", "self", ".", "num_frames", ",", "feature_size", "=", "hs", ")", "\n", "\n", "# add for tvqa", "\n", "", "if", "self", ".", "hparams", ".", "config", "[", "\"loss_names\"", "]", "[", "\"mc_vqa\"", "]", ">", "0", ":", "\n", "# # v1: for q2a with itm_score", "\n", "# self.rank_output = nn.Linear(hs, 1)", "\n", "# self.rank_output.weight.data = self.itm_score.fc.weight.data[1:, :]", "\n", "# self.rank_output.bias.data = self.itm_score.fc.bias.data[1:]", "\n", "# self.dropout = nn.Dropout(0.1)", "\n", "            ", "self", ".", "mc_vqa_classifier", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Dropout", "(", "0.1", ")", ",", "\n", "nn", ".", "Linear", "(", "hs", ",", "256", ")", ",", "\n", "nn", ".", "LayerNorm", "(", "256", ")", ",", "\n", "nn", ".", "GELU", "(", ")", ",", "\n", "nn", ".", "Linear", "(", "256", ",", "1", ")", ",", "\n", ")", "\n", "self", ".", "mc_vqa_classifier", ".", "apply", "(", "objectives", ".", "init_weights", ")", "\n", "\n", "# : add for openend_vqa", "\n", "", "if", "self", ".", "hparams", ".", "config", "[", "\"loss_names\"", "]", "[", "\"openend_vqa\"", "]", ">", "0", ":", "\n", "            ", "vs", "=", "self", ".", "hparams", ".", "config", "[", "\"msrvttqa_label_size\"", "]", "\n", "# self.vqa_classifier = nn.Sequential(", "\n", "#     nn.Dropout(0.5),", "\n", "#     nn.Linear(hs, hs * 2),", "\n", "#     nn.LayerNorm(hs * 2),", "\n", "#     nn.GELU(),", "\n", "#     nn.Linear(hs * 2, vs),", "\n", "# )", "\n", "# small dataset", "\n", "self", ".", "vqa_classifier", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Dropout", "(", "0.5", ")", ",", "\n", "nn", ".", "Linear", "(", "hs", ",", "hs", "//", "2", ")", ",", "\n", "nn", ".", "LayerNorm", "(", "hs", "//", "2", ")", ",", "\n", "nn", ".", "GELU", "(", ")", ",", "\n", "nn", ".", "Linear", "(", "hs", "//", "2", ",", "vs", ")", ",", "\n", ")", "\n", "self", ".", "vqa_classifier", ".", "apply", "(", "objectives", ".", "init_weights", ")", "\n", "\n", "", "if", "self", ".", "hparams", ".", "config", "[", "\"loss_names\"", "]", "[", "\"nlvr2\"", "]", ">", "0", ":", "\n", "            ", "self", ".", "nlvr2_classifier", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "hs", "*", "2", ",", "hs", "*", "2", ")", ",", "\n", "nn", ".", "LayerNorm", "(", "hs", "*", "2", ")", ",", "\n", "nn", ".", "GELU", "(", ")", ",", "\n", "nn", ".", "Linear", "(", "hs", "*", "2", ",", "2", ")", ",", "\n", ")", "\n", "self", ".", "nlvr2_classifier", ".", "apply", "(", "objectives", ".", "init_weights", ")", "\n", "emb_data", "=", "self", ".", "token_type_embeddings", ".", "weight", ".", "data", "\n", "self", ".", "token_type_embeddings", "=", "nn", ".", "Embedding", "(", "3", ",", "hs", ")", "\n", "self", ".", "token_type_embeddings", ".", "apply", "(", "objectives", ".", "init_weights", ")", "\n", "self", ".", "token_type_embeddings", ".", "weight", ".", "data", "[", "0", ",", ":", "]", "=", "emb_data", "[", "0", ",", ":", "]", "\n", "self", ".", "token_type_embeddings", ".", "weight", ".", "data", "[", "1", ",", ":", "]", "=", "emb_data", "[", "1", ",", ":", "]", "\n", "self", ".", "token_type_embeddings", ".", "weight", ".", "data", "[", "2", ",", ":", "]", "=", "emb_data", "[", "1", ",", ":", "]", "\n", "\n", "", "if", "self", ".", "hparams", ".", "config", "[", "\"loss_names\"", "]", "[", "\"irtr\"", "]", ">", "0", ":", "\n", "            ", "self", ".", "rank_output", "=", "nn", ".", "Linear", "(", "hs", ",", "1", ")", "\n", "self", ".", "rank_output", ".", "weight", ".", "data", "=", "self", ".", "itm_score", ".", "fc", ".", "weight", ".", "data", "[", "1", ":", ",", ":", "]", "\n", "self", ".", "rank_output", ".", "bias", ".", "data", "=", "self", ".", "itm_score", ".", "fc", ".", "bias", ".", "data", "[", "1", ":", "]", "\n", "self", ".", "margin", "=", "0.2", "\n", "# for p in self.itm_score.parameters(): # : requires_grad = true?", "\n", "#     p.requires_grad = False", "\n", "\n", "# test msrvtt multiple choice without finetune", "\n", "", "if", "self", ".", "hparams", ".", "config", "[", "\"loss_names\"", "]", "[", "\"multiple_choice\"", "]", ">", "0", ":", "\n", "            ", "self", ".", "rank_output", "=", "nn", ".", "Linear", "(", "hs", ",", "1", ")", "\n", "self", ".", "rank_output", ".", "weight", ".", "data", "=", "self", ".", "itm_score", ".", "fc", ".", "weight", ".", "data", "[", "1", ":", ",", ":", "]", "\n", "self", ".", "rank_output", ".", "bias", ".", "data", "=", "self", ".", "itm_score", ".", "fc", ".", "bias", ".", "data", "[", "1", ":", "]", "\n", "self", ".", "margin", "=", "0.2", "\n", "\n", "", "allinone_utils", ".", "set_metrics", "(", "self", ")", "\n", "self", ".", "current_tasks", "=", "list", "(", ")", "\n", "\n", "# ===================== load downstream (test_only) ======================", "\n", "\n", "if", "self", ".", "hparams", ".", "config", "[", "\"load_path\"", "]", "!=", "\"\"", "and", "self", ".", "hparams", ".", "config", "[", "\"test_only\"", "]", ":", "\n", "            ", "print", "(", "\"====load checkpoint=====\"", ")", "\n", "ckpt", "=", "torch", ".", "load", "(", "self", ".", "hparams", ".", "config", "[", "\"load_path\"", "]", ",", "map_location", "=", "\"cpu\"", ")", "\n", "state_dict", "=", "ckpt", "[", "\"state_dict\"", "]", "\n", "# temporal embed and fix model ?", "\n", "# new_state_dict = state_dict_data_parallel_fix(state_dict, self.state_dict())", "\n", "# new_state_dict = self._inflate_positional_embeds(new_state_dict)", "\n", "# self.load_state_dict(new_state_dict, strict=False)", "\n", "state_dict", "=", "self", ".", "_inflate_positional_embeds", "(", "state_dict", ")", "\n", "self", ".", "load_state_dict", "(", "state_dict", ",", "strict", "=", "False", ")", "\n", "", "self", ".", "temporal_roll_module", "=", "TemporalRoll", "(", "n_segment", "=", "self", ".", "num_frames", ",", "v", "=", "0", ")", "\n", "# # print learnable param", "\n", "for", "name", ",", "param", "in", "self", ".", "named_parameters", "(", ")", ":", "\n", "            ", "if", "param", ".", "requires_grad", ":", "\n", "                ", "print", "(", "\"learned param: \"", ",", "name", ")", "\n", "# ==== for linear evaluation action recognition", "\n", "", "", "self", ".", "spatial_mix", "=", "SpatialMixup", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.modules.allinone_module.AllinoneTransformerSS.infer": [[289, 410], ["enumerate", "allinone_module.AllinoneTransformerSS.transformer.norm", "torch.cat.view", "torch.cat.view", "torch.cat.view", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "allinone_module.AllinoneTransformerSS.pooler", "allinone_module.AllinoneTransformerSS.text_embeddings", "torch.repeat_interleave", "torch.repeat_interleave", "torch.repeat_interleave", "torch.repeat_interleave", "torch.repeat_interleave", "torch.repeat_interleave", "torch.repeat_interleave", "torch.repeat_interleave", "torch.repeat_interleave", "torch.repeat_interleave", "torch.repeat_interleave", "torch.repeat_interleave", "torch.repeat_interleave", "torch.repeat_interleave", "torch.repeat_interleave", "torch.repeat_interleave", "torch.repeat_interleave", "torch.repeat_interleave", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "blk", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.cat.size", "text_masks[].contiguous", "image_masks[].contiguous", "img.contiguous().view.contiguous().view.contiguous().view", "allinone_module.AllinoneTransformerSS.transformer.visual_embed", "allinone_module.AllinoneTransformerSS.token_type_embeddings", "allinone_module.AllinoneTransformerSS.token_type_embeddings", "allinone_module.AllinoneTransformerSS.temporal_roll_module", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat.size", "torch.cat.size", "torch.cat.size", "allinone_module.AllinoneTransformerSS.txt_proj", "allinone_module.AllinoneTransformerSS.vid_proj", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.full_like", "torch.full_like", "torch.full_like", "torch.full_like", "torch.full_like", "torch.full_like", "torch.full_like", "torch.full_like", "torch.full_like", "img.contiguous().view.contiguous().view.contiguous", "img.contiguous().view.contiguous().view.size", "img.contiguous().view.contiguous().view.size", "img.contiguous().view.contiguous().view.size"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.modules.base_vision_transformer.DistilledVisionTransformer.visual_embed"], ["", "def", "infer", "(", "\n", "self", ",", "\n", "batch", ",", "\n", "mask_text", "=", "False", ",", "\n", "mask_image", "=", "False", ",", "\n", "image_token_type_idx", "=", "1", ",", "\n", "image_embeds", "=", "None", ",", "\n", "image_masks", "=", "None", ",", "\n", "input_image_only", "=", "False", ",", "\n", "input_text_only", "=", "False", ",", "\n", "mode", "=", "'train'", "\n", ")", ":", "\n", "# if text: process in normal video", "\n", "# if video: repeat the text tensor for K times", "\n", "        ", "if", "f\"image_{image_token_type_idx - 1}\"", "in", "batch", ":", "\n", "            ", "imgkey", "=", "f\"image_{image_token_type_idx - 1}\"", "\n", "", "else", ":", "\n", "            ", "imgkey", "=", "\"image\"", "\n", "", "do_mlm", "=", "\"_mlm\"", "if", "mask_text", "else", "\"\"", "\n", "text_ids", "=", "batch", "[", "f\"text_ids{do_mlm}\"", "]", "\n", "text_labels", "=", "batch", "[", "f\"text_labels{do_mlm}\"", "]", "\n", "text_masks", "=", "batch", "[", "f\"text_masks\"", "]", "\n", "if", "not", "input_image_only", ":", "\n", "            ", "text_embeds", "=", "self", ".", "text_embeddings", "(", "text_ids", ")", "\n", "image_labels", "=", "None", "\n", "patch_index", "=", "None", "\n", "", "if", "not", "input_text_only", ":", "\n", "            ", "if", "image_embeds", "is", "None", "and", "image_masks", "is", "None", ":", "\n", "                ", "img", "=", "batch", "[", "imgkey", "]", "[", "0", "]", "\n", "# for action recognition", "\n", "# img = self.spatial_mix.mixup_data(img)", "\n", "img", "=", "img", ".", "contiguous", "(", ")", ".", "view", "(", "-", "1", ",", "img", ".", "size", "(", ")", "[", "2", "]", ",", "img", ".", "size", "(", ")", "[", "3", "]", ",", "img", ".", "size", "(", ")", "[", "4", "]", ")", "# btchw to [bt]chw", "\n", "(", "\n", "image_embeds", ",", "\n", "image_masks", ",", "\n", "patch_index", ",", "\n", "image_labels", ",", "\n", ")", "=", "self", ".", "transformer", ".", "visual_embed", "(", "\n", "img", ",", "\n", "max_image_len", "=", "self", ".", "hparams", ".", "config", "[", "\"max_image_len\"", "]", ",", "\n", "mask_it", "=", "mask_image", ",", "\n", ")", "\n", "", "else", ":", "\n", "                ", "patch_index", ",", "image_labels", "=", "(", "\n", "None", ",", "\n", "None", ",", "\n", ")", "\n", "", "", "if", "not", "input_image_only", ":", "\n", "            ", "text_embeds", "=", "text_embeds", "+", "self", ".", "token_type_embeddings", "(", "torch", ".", "zeros_like", "(", "text_masks", ")", ")", "\n", "text_embeds", "=", "torch", ".", "repeat_interleave", "(", "text_embeds", ",", "self", ".", "num_frames", ",", "dim", "=", "0", ")", "\n", "text_masks", "=", "torch", ".", "repeat_interleave", "(", "text_masks", ",", "self", ".", "num_frames", ",", "dim", "=", "0", ")", "\n", "", "if", "not", "input_text_only", ":", "\n", "            ", "image_embeds", "=", "image_embeds", "+", "self", ".", "token_type_embeddings", "(", "torch", ".", "full_like", "(", "image_masks", ",", "image_token_type_idx", ")", ")", "\n", "\n", "", "if", "not", "input_text_only", "and", "not", "input_image_only", ":", "\n", "            ", "co_embeds", "=", "torch", ".", "cat", "(", "[", "text_embeds", ",", "image_embeds", "]", ",", "dim", "=", "1", ")", "\n", "co_masks", "=", "torch", ".", "cat", "(", "[", "text_masks", ",", "image_masks", "]", ",", "dim", "=", "1", ")", "\n", "x", "=", "co_embeds", "\n", "", "if", "input_text_only", ":", "\n", "            ", "x", "=", "text_embeds", "\n", "co_masks", "=", "text_masks", "\n", "", "if", "input_image_only", ":", "\n", "            ", "x", "=", "image_embeds", "\n", "co_masks", "=", "image_masks", "\n", "\n", "", "for", "i", ",", "blk", "in", "enumerate", "(", "self", ".", "transformer", ".", "blocks", ")", ":", "\n", "# skip the first K blocks", "\n", "# if i > 0:", "\n", "# perform temporal roll operation for temporal modeling", "\n", "            ", "if", "not", "input_image_only", "and", "not", "input_text_only", ":", "\n", "                ", "text_feats", ",", "image_feats", "=", "(", "\n", "x", "[", ":", ",", ":", "text_embeds", ".", "shape", "[", "1", "]", "]", ",", "\n", "x", "[", ":", ",", "text_embeds", ".", "shape", "[", "1", "]", ":", "]", ",", "\n", ")", "\n", "image_feats", "=", "self", ".", "temporal_roll_module", "(", "image_feats", ",", "i", ")", "\n", "x", "=", "torch", ".", "cat", "(", "(", "text_feats", ",", "image_feats", ")", ",", "dim", "=", "1", ")", "\n", "", "x", ",", "_attn", "=", "blk", "(", "x", ",", "mask", "=", "co_masks", ")", "\n", "", "x", "=", "self", ".", "transformer", ".", "norm", "(", "x", ")", "\n", "# reshape to image tensor", "\n", "x", "=", "x", ".", "view", "(", "x", ".", "size", "(", "0", ")", "//", "self", ".", "num_frames", ",", "-", "1", ",", "x", ".", "size", "(", "-", "2", ")", ",", "\n", "x", ".", "size", "(", "-", "1", ")", ")", "\n", "# add vcop here", "\n", "h", "=", "None", "\n", "if", "self", ".", "hparams", ".", "config", "[", "\"loss_names\"", "]", "[", "\"vcop\"", "]", ">", "0", ":", "\n", "            ", "h", "=", "x", "\n", "", "x", "=", "torch", ".", "mean", "(", "x", ",", "dim", "=", "1", ")", "\n", "if", "input_text_only", ":", "\n", "            ", "text_feats", "=", "x", "\n", "if", "\"ind_itc\"", "in", "self", ".", "current_tasks", ":", "\n", "                ", "text_feats", "=", "self", ".", "txt_proj", "(", "text_feats", ")", "\n", "", "image_feats", "=", "None", "\n", "", "if", "input_image_only", ":", "\n", "            ", "image_feats", "=", "x", "\n", "if", "\"ind_itc\"", "in", "self", ".", "current_tasks", ":", "\n", "                ", "image_feats", "=", "self", ".", "vid_proj", "(", "image_feats", ")", "\n", "", "text_feats", "=", "None", "\n", "", "if", "not", "input_text_only", "and", "not", "input_image_only", ":", "\n", "            ", "text_feats", ",", "image_feats", "=", "(", "\n", "x", "[", ":", ",", ":", "text_embeds", ".", "shape", "[", "1", "]", "]", ",", "\n", "x", "[", ":", ",", "text_embeds", ".", "shape", "[", "1", "]", ":", "]", ",", "\n", ")", "\n", "", "cls_feats", "=", "self", ".", "pooler", "(", "x", ")", "\n", "if", "not", "input_image_only", ":", "\n", "            ", "text_masks", "=", "text_masks", "[", ":", ":", "self", ".", "num_frames", "]", ".", "contiguous", "(", ")", "\n", "", "if", "not", "input_text_only", ":", "\n", "            ", "image_masks", "=", "image_masks", "[", ":", ":", "self", ".", "num_frames", "]", ".", "contiguous", "(", ")", "\n", "", "ret", "=", "{", "\n", "\"text_feats\"", ":", "text_feats", ",", "\n", "\"image_feats\"", ":", "image_feats", ",", "\n", "\"cls_feats\"", ":", "cls_feats", ",", "\n", "\"raw_cls_feats\"", ":", "x", "[", ":", ",", "0", "]", ",", "\n", "\"image_labels\"", ":", "image_labels", ",", "\n", "\"image_masks\"", ":", "image_masks", ",", "\n", "\"text_labels\"", ":", "text_labels", ",", "\n", "\"text_ids\"", ":", "text_ids", ",", "\n", "\"text_masks\"", ":", "text_masks", ",", "\n", "\"patch_index\"", ":", "patch_index", ",", "\n", "\"vcop_features\"", ":", "h", "\n", "}", "\n", "\n", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.modules.allinone_module.AllinoneTransformerSS.forward": [[411, 466], ["dict", "len", "dict.update", "dict.update", "dict.update", "dict.update", "dict.update", "dict.update", "dict.update", "dict.update", "dict.update", "dict.update", "dict.update", "dict.update", "dict.update", "allinone_module.AllinoneTransformerSS.infer", "AllInOne.modules.objectives.compute_mlm", "AllInOne.modules.objectives.compute_mpp", "AllInOne.modules.objectives.compute_itm_wpa", "AllInOne.modules.objectives.compute_ind_itc", "AllInOne.modules.objectives.compute_vqa", "AllInOne.modules.objectives.compute_openend_vqa", "AllInOne.modules.objectives.compute_vcop", "AllInOne.modules.objectives.compute_vcr_q2a", "AllInOne.modules.objectives.compute_mc_vqa_q2a", "AllInOne.modules.objectives.compute_multiple_choice", "AllInOne.modules.objectives.compute_nlvr2", "AllInOne.modules.objectives.compute_irtr"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.gadgets.my_metrics.VQAScore.update", "home.repos.pwc.inspect_result.showlab_all-in-one.gadgets.my_metrics.VQAScore.update", "home.repos.pwc.inspect_result.showlab_all-in-one.gadgets.my_metrics.VQAScore.update", "home.repos.pwc.inspect_result.showlab_all-in-one.gadgets.my_metrics.VQAScore.update", "home.repos.pwc.inspect_result.showlab_all-in-one.gadgets.my_metrics.VQAScore.update", "home.repos.pwc.inspect_result.showlab_all-in-one.gadgets.my_metrics.VQAScore.update", "home.repos.pwc.inspect_result.showlab_all-in-one.gadgets.my_metrics.VQAScore.update", "home.repos.pwc.inspect_result.showlab_all-in-one.gadgets.my_metrics.VQAScore.update", "home.repos.pwc.inspect_result.showlab_all-in-one.gadgets.my_metrics.VQAScore.update", "home.repos.pwc.inspect_result.showlab_all-in-one.gadgets.my_metrics.VQAScore.update", "home.repos.pwc.inspect_result.showlab_all-in-one.gadgets.my_metrics.VQAScore.update", "home.repos.pwc.inspect_result.showlab_all-in-one.gadgets.my_metrics.VQAScore.update", "home.repos.pwc.inspect_result.showlab_all-in-one.gadgets.my_metrics.VQAScore.update", "home.repos.pwc.inspect_result.showlab_all-in-one.modules.allinone_module.AllinoneTransformerSS.infer", "home.repos.pwc.inspect_result.showlab_all-in-one.modules.objectives.compute_mlm", "home.repos.pwc.inspect_result.showlab_all-in-one.modules.objectives.compute_mpp", "home.repos.pwc.inspect_result.showlab_all-in-one.modules.objectives.compute_itm_wpa", "home.repos.pwc.inspect_result.showlab_all-in-one.modules.objectives.compute_ind_itc", "home.repos.pwc.inspect_result.showlab_all-in-one.modules.objectives.compute_vqa", "home.repos.pwc.inspect_result.showlab_all-in-one.modules.objectives.compute_openend_vqa", "home.repos.pwc.inspect_result.showlab_all-in-one.modules.objectives.compute_vcop", "home.repos.pwc.inspect_result.showlab_all-in-one.modules.objectives.compute_vcr_q2a", "home.repos.pwc.inspect_result.showlab_all-in-one.modules.objectives.compute_mc_vqa_q2a", "home.repos.pwc.inspect_result.showlab_all-in-one.modules.objectives.compute_multiple_choice", "home.repos.pwc.inspect_result.showlab_all-in-one.modules.objectives.compute_nlvr2", "home.repos.pwc.inspect_result.showlab_all-in-one.modules.objectives.compute_irtr"], ["", "def", "forward", "(", "self", ",", "batch", ")", ":", "\n", "        ", "ret", "=", "dict", "(", ")", "\n", "if", "len", "(", "self", ".", "current_tasks", ")", "==", "0", ":", "\n", "            ", "ret", ".", "update", "(", "self", ".", "infer", "(", "batch", ")", ")", "\n", "return", "ret", "\n", "\n", "# Masked Language Modeling", "\n", "", "if", "\"mlm\"", "in", "self", ".", "current_tasks", ":", "\n", "            ", "ret", ".", "update", "(", "objectives", ".", "compute_mlm", "(", "self", ",", "batch", ")", ")", "\n", "\n", "# Masked Patch Prediction", "\n", "", "if", "\"mpp\"", "in", "self", ".", "current_tasks", ":", "\n", "            ", "ret", ".", "update", "(", "objectives", ".", "compute_mpp", "(", "self", ",", "batch", ")", ")", "\n", "\n", "# Image Text Matching", "\n", "", "if", "\"itm\"", "in", "self", ".", "current_tasks", ":", "\n", "            ", "ret", ".", "update", "(", "objectives", ".", "compute_itm_wpa", "(", "self", ",", "batch", ")", ")", "\n", "\n", "# Image Text Contrastive", "\n", "", "if", "\"ind_itc\"", "in", "self", ".", "current_tasks", ":", "\n", "            ", "ret", ".", "update", "(", "objectives", ".", "compute_ind_itc", "(", "self", ",", "batch", ")", ")", "\n", "\n", "# Visual Question Answering", "\n", "", "if", "\"vqa\"", "in", "self", ".", "current_tasks", ":", "\n", "            ", "ret", ".", "update", "(", "objectives", ".", "compute_vqa", "(", "self", ",", "batch", ")", ")", "\n", "\n", "# : msrvtt Visual Question Answering", "\n", "", "if", "\"openend_vqa\"", "in", "self", ".", "current_tasks", ":", "\n", "            ", "ret", ".", "update", "(", "objectives", ".", "compute_openend_vqa", "(", "self", ",", "batch", ")", ")", "\n", "\n", "#  vcop", "\n", "", "if", "\"vcop\"", "in", "self", ".", "current_tasks", ":", "\n", "            ", "ret", ".", "update", "(", "objectives", ".", "compute_vcop", "(", "self", ",", "batch", ")", ")", "\n", "\n", "# : vcr qa", "\n", "", "if", "\"vcr_q2a\"", "in", "self", ".", "current_tasks", ":", "\n", "            ", "ret", ".", "update", "(", "objectives", ".", "compute_vcr_q2a", "(", "self", ",", "batch", ")", ")", "\n", "\n", "# : mc_vqa", "\n", "", "if", "\"mc_vqa\"", "in", "self", ".", "current_tasks", ":", "\n", "            ", "ret", ".", "update", "(", "objectives", ".", "compute_mc_vqa_q2a", "(", "self", ",", "batch", ")", ")", "\n", "\n", "# : msrvtt multiple choice setting", "\n", "", "if", "\"multiple_choice\"", "in", "self", ".", "current_tasks", ":", "\n", "            ", "ret", ".", "update", "(", "objectives", ".", "compute_multiple_choice", "(", "self", ",", "batch", ")", ")", "\n", "\n", "# Natural Language for Visual Reasoning 2", "\n", "", "if", "\"nlvr2\"", "in", "self", ".", "current_tasks", ":", "\n", "            ", "ret", ".", "update", "(", "objectives", ".", "compute_nlvr2", "(", "self", ",", "batch", ")", ")", "\n", "\n", "# Image Retrieval and Text Retrieval", "\n", "", "if", "\"irtr\"", "in", "self", ".", "current_tasks", ":", "\n", "            ", "ret", ".", "update", "(", "objectives", ".", "compute_irtr", "(", "self", ",", "batch", ")", ")", "\n", "\n", "", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.modules.allinone_module.AllinoneTransformerSS.training_step": [[467, 477], ["AllInOne.modules.allinone_utils.set_task", "allinone_module.AllinoneTransformerSS.", "sum", "allinone_module.AllinoneTransformerSS.items"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.modules.allinone_utils.set_task"], ["", "def", "training_step", "(", "self", ",", "batch", ",", "batch_idx", ")", ":", "\n", "        ", "allinone_utils", ".", "set_task", "(", "self", ")", "\n", "output", "=", "self", "(", "batch", ")", "\n", "total_loss", "=", "sum", "(", "[", "v", "for", "k", ",", "v", "in", "output", ".", "items", "(", ")", "if", "\"loss\"", "in", "k", "]", ")", "\n", "# for debug", "\n", "# self.log(\"train_loss\", loss, on_step=True, on_epoch=True, sync_dist=True)", "\n", "# if random.random() < 0.01:", "\n", "#     print(\"\\n\")", "\n", "#     print(\"train loss for current batch: {}\".format(total_loss.item()))", "\n", "return", "total_loss", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.modules.allinone_module.AllinoneTransformerSS.training_epoch_end": [[478, 480], ["AllInOne.modules.allinone_utils.epoch_wrapup"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.modules.allinone_utils.epoch_wrapup"], ["", "def", "training_epoch_end", "(", "self", ",", "outs", ")", ":", "\n", "        ", "allinone_utils", ".", "epoch_wrapup", "(", "self", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.modules.allinone_module.AllinoneTransformerSS.validation_step": [[481, 484], ["AllInOne.modules.allinone_utils.set_task", "allinone_module.AllinoneTransformerSS."], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.modules.allinone_utils.set_task"], ["", "def", "validation_step", "(", "self", ",", "batch", ",", "batch_idx", ")", ":", "\n", "        ", "allinone_utils", ".", "set_task", "(", "self", ")", "\n", "output", "=", "self", "(", "batch", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.modules.allinone_module.AllinoneTransformerSS.validation_epoch_end": [[485, 487], ["AllInOne.modules.allinone_utils.epoch_wrapup"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.modules.allinone_utils.epoch_wrapup"], ["", "def", "validation_epoch_end", "(", "self", ",", "outs", ")", ":", "\n", "        ", "allinone_utils", ".", "epoch_wrapup", "(", "self", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.modules.allinone_module.AllinoneTransformerSS.test_step": [[488, 500], ["AllInOne.modules.allinone_utils.set_task", "allinone_module.AllinoneTransformerSS.", "dict", "dict.update", "AllInOne.modules.objectives.vqa_test_step"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.modules.allinone_utils.set_task", "home.repos.pwc.inspect_result.showlab_all-in-one.gadgets.my_metrics.VQAScore.update", "home.repos.pwc.inspect_result.showlab_all-in-one.modules.objectives.vqa_test_step"], ["", "def", "test_step", "(", "self", ",", "batch", ",", "batch_idx", ")", ":", "\n", "        ", "allinone_utils", ".", "set_task", "(", "self", ")", "\n", "output", "=", "self", "(", "batch", ")", "\n", "ret", "=", "dict", "(", ")", "\n", "\n", "# #: for debug", "\n", "# total_loss = sum([v for k, v in output.items() if \"loss\" in k])", "\n", "# print(total_loss.item())", "\n", "if", "self", ".", "hparams", ".", "config", "[", "\"loss_names\"", "]", "[", "\"vqa\"", "]", ">", "0", ":", "\n", "            ", "ret", ".", "update", "(", "objectives", ".", "vqa_test_step", "(", "self", ",", "batch", ",", "output", ")", ")", "\n", "\n", "", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.modules.allinone_module.AllinoneTransformerSS.test_epoch_end": [[501, 507], ["AllInOne.modules.allinone_utils.epoch_wrapup", "AllInOne.modules.objectives.vqa_test_wrapup", "allinone_module.AllinoneTransformerSS.hparams.config[].split"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.modules.allinone_utils.epoch_wrapup", "home.repos.pwc.inspect_result.showlab_all-in-one.modules.objectives.vqa_test_wrapup"], ["", "def", "test_epoch_end", "(", "self", ",", "outs", ")", ":", "\n", "        ", "model_name", "=", "self", ".", "hparams", ".", "config", "[", "\"load_path\"", "]", ".", "split", "(", "\"/\"", ")", "[", "-", "1", "]", "[", ":", "-", "5", "]", "\n", "\n", "if", "self", ".", "hparams", ".", "config", "[", "\"loss_names\"", "]", "[", "\"vqa\"", "]", ">", "0", ":", "\n", "            ", "objectives", ".", "vqa_test_wrapup", "(", "outs", ",", "model_name", ")", "\n", "", "allinone_utils", ".", "epoch_wrapup", "(", "self", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.modules.allinone_module.AllinoneTransformerSS.configure_optimizers": [[508, 510], ["AllInOne.modules.allinone_utils.set_schedule"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.modules.allinone_utils.set_schedule"], ["", "def", "configure_optimizers", "(", "self", ")", ":", "\n", "        ", "return", "allinone_utils", ".", "set_schedule", "(", "self", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.modules.allinone_module.AllinoneTransformerSS._inflate_positional_embeds": [[511, 554], ["list", "allinone_module.AllinoneTransformerSS.state_dict().keys", "allinone_module.AllinoneTransformerSS.state_dict", "NotImplementedError", "allinone_module.AllinoneTransformerSS.state_dict", "print", "print", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "load_temporal_embed.unsqueeze.unsqueeze.unsqueeze", "torch.interpolate().squeeze", "torch.interpolate().squeeze", "torch.interpolate().squeeze", "torch.interpolate", "torch.interpolate", "torch.interpolate"], "methods", ["None"], ["", "def", "_inflate_positional_embeds", "(", "self", ",", "new_state_dict", ",", "load_temporal_fix", "=", "'zeros'", ")", ":", "\n", "# allow loading of timesformer with fewer num_frames", "\n", "        ", "curr_keys", "=", "list", "(", "self", ".", "state_dict", "(", ")", ".", "keys", "(", ")", ")", "\n", "if", "'transformer.temporal_embed'", "in", "new_state_dict", "and", "'transformer.temporal_embed'", "in", "curr_keys", ":", "\n", "            ", "load_temporal_embed", "=", "new_state_dict", "[", "'transformer.temporal_embed'", "]", "\n", "load_num_frames", "=", "load_temporal_embed", ".", "shape", "[", "1", "]", "\n", "curr_num_frames", "=", "self", ".", "hparams", ".", "config", "[", "'num_frames'", "]", "\n", "embed_dim", "=", "load_temporal_embed", ".", "shape", "[", "2", "]", "\n", "\n", "if", "load_num_frames", "!=", "curr_num_frames", ":", "\n", "                ", "if", "load_num_frames", ">", "curr_num_frames", ":", "\n", "                    ", "print", "(", "f'### loaded {self.hparams.config[\"vit\"]} model has MORE frames than current...'", "\n", "f'### loading weights, filling in the extras via {load_temporal_fix}'", ")", "\n", "new_temporal_embed", "=", "load_temporal_embed", "[", ":", ",", ":", "curr_num_frames", ",", ":", "]", "\n", "", "else", ":", "\n", "                    ", "print", "(", "f'### loaded {self.hparams.config[\"vit\"]} model has FEWER frames than current...'", "\n", "f'### loading weights, filling in the extras via {load_temporal_fix}'", ")", "\n", "if", "load_temporal_fix", "==", "'zeros'", ":", "\n", "                        ", "new_temporal_embed", "=", "torch", ".", "zeros", "(", "[", "load_temporal_embed", ".", "shape", "[", "0", "]", ",", "curr_num_frames", ",", "embed_dim", "]", ")", "\n", "new_temporal_embed", "[", ":", ",", ":", "load_num_frames", "]", "=", "load_temporal_embed", "\n", "", "elif", "load_temporal_fix", "in", "[", "'interp'", ",", "'bilinear'", "]", ":", "\n", "# interpolate", "\n", "# unsqueeze so pytorch thinks its an image", "\n", "                        ", "mode", "=", "'nearest'", "\n", "if", "load_temporal_fix", "==", "'bilinear'", ":", "\n", "                            ", "mode", "=", "'bilinear'", "\n", "", "load_temporal_embed", "=", "load_temporal_embed", ".", "unsqueeze", "(", "0", ")", "\n", "new_temporal_embed", "=", "F", ".", "interpolate", "(", "load_temporal_embed", ",", "\n", "(", "curr_num_frames", ",", "embed_dim", ")", ",", "mode", "=", "mode", ")", ".", "squeeze", "(", "0", ")", "\n", "", "else", ":", "\n", "                        ", "raise", "NotImplementedError", "\n", "", "", "new_state_dict", "[", "'transformer.temporal_embed'", "]", "=", "new_temporal_embed", "\n", "# allow loading with smaller spatial patches. assumes custom border crop, to append the", "\n", "# border patches to the input sequence", "\n", "", "", "if", "'transformer.pos_embed'", "in", "new_state_dict", "and", "'transformer.pos_embed'", "in", "curr_keys", ":", "\n", "            ", "load_pos_embed", "=", "new_state_dict", "[", "'transformer.pos_embed'", "]", "\n", "load_num_patches", "=", "load_pos_embed", ".", "shape", "[", "1", "]", "\n", "curr_pos_embed", "=", "self", ".", "state_dict", "(", ")", "[", "'transformer.pos_embed'", "]", "\n", "if", "load_num_patches", "!=", "curr_pos_embed", ".", "shape", "[", "1", "]", ":", "\n", "                ", "raise", "NotImplementedError", "(", "\n", "'Loading models with different spatial resolution / patch number not yet implemented, sorry.'", ")", "\n", "\n", "", "", "return", "new_state_dict", "", "", "", ""]], "home.repos.pwc.inspect_result.showlab_all-in-one.modules.objectives.compute_mpp": [[123, 157], ["pl_module.infer", "pl_module.mpp_score", "torch.stack", "torch.stack", "torch.stack", "torch.cross_entropy", "pl_module.log", "pl_module.log", "torch.stack.view", "mpp_labels.view", "getattr", "getattr"], "function", ["home.repos.pwc.inspect_result.showlab_all-in-one.modules.allinone_module.AllinoneTransformerSS.infer"], ["    ", "\"\"\"\n    added eps for numerical stability\n    \"\"\"", "\n", "a_n", ",", "b_n", "=", "a", ".", "norm", "(", "dim", "=", "1", ")", "[", ":", ",", "None", "]", ",", "b", ".", "norm", "(", "dim", "=", "1", ")", "[", ":", ",", "None", "]", "\n", "a_norm", "=", "a", "/", "torch", ".", "max", "(", "a_n", ",", "eps", "*", "torch", ".", "ones_like", "(", "a_n", ")", ")", "\n", "b_norm", "=", "b", "/", "torch", ".", "max", "(", "b_n", ",", "eps", "*", "torch", ".", "ones_like", "(", "b_n", ")", ")", "\n", "sim_mt", "=", "torch", ".", "mm", "(", "a_norm", ",", "b_norm", ".", "transpose", "(", "0", ",", "1", ")", ")", "\n", "return", "sim_mt", "\n", "\n", "# == end", "\n", "\n", "\n", "# add independent contrastive loss for retrieval", "\n", "\n", "", "def", "compute_vtc", "(", "pl_module", ",", "batch", ",", "mode", "=", "\"video\"", ")", ":", "\n", "    ", "infer_text", "=", "pl_module", ".", "infer", "(", "batch", ",", "mask_text", "=", "False", ",", "mask_video", "=", "False", ",", "input_text_only", "=", "True", ",", "mode", "=", "mode", ")", "\n", "with", "torch", ".", "cuda", ".", "amp", ".", "autocast", "(", "enabled", "=", "False", ")", ":", "\n", "        ", "txt_emb", "=", "infer_text", "[", "\"text_feats\"", "]", "\n", "", "infer_vision", "=", "pl_module", ".", "infer", "(", "batch", ",", "mask_text", "=", "False", ",", "mask_video", "=", "False", ",", "input_video_only", "=", "True", ",", "mode", "=", "mode", ")", "\n", "with", "torch", ".", "cuda", ".", "amp", ".", "autocast", "(", "enabled", "=", "False", ")", ":", "\n", "        ", "img_emb", "=", "infer_vision", "[", "\"video_feats\"", "]", "\n", "# print(txt_emb.size(), img_emb.size())", "\n", "", "x", "=", "sim_matrix", "(", "txt_emb", "[", ":", ",", "0", "]", ",", "img_emb", "[", ":", ",", "0", "]", ")", "\n", "temperature", "=", "0.05", "\n", "\"Assumes input x is similarity matrix of N x M \\in [-1, 1], computed using the cosine similarity between normalised vectors\"", "\n", "i_logsm", "=", "F", ".", "log_softmax", "(", "x", "/", "temperature", ",", "dim", "=", "1", ")", "\n", "j_logsm", "=", "F", ".", "log_softmax", "(", "x", ".", "t", "(", ")", "/", "temperature", ",", "dim", "=", "1", ")", "\n", "\n", "# sum over positives", "\n", "idiag", "=", "torch", ".", "diag", "(", "i_logsm", ")", "\n", "loss_i", "=", "idiag", ".", "sum", "(", ")", "/", "len", "(", "idiag", ")", "\n", "\n", "jdiag", "=", "torch", ".", "diag", "(", "j_logsm", ")", "\n", "loss_j", "=", "jdiag", ".", "sum", "(", ")", "/", "len", "(", "jdiag", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.modules.objectives.compute_mppd": [[159, 180], ["pl_module.infer", "pl_module.mppd_score", "torch.mse_loss", "pl_module.log", "infer[].float().mean", "getattr", "infer[].float"], "function", ["home.repos.pwc.inspect_result.showlab_all-in-one.modules.allinone_module.AllinoneTransformerSS.infer"], ["\n", "ret", "=", "{", "\n", "\"vtc_loss\"", ":", "itc_loss", ",", "\n", "}", "\n", "\n", "phase", "=", "\"train\"", "if", "pl_module", ".", "training", "else", "\"val\"", "\n", "loss", "=", "getattr", "(", "pl_module", ",", "f\"{phase}_vtc_loss\"", ")", "(", "ret", "[", "\"vtc_loss\"", "]", ")", "\n", "pl_module", ".", "log", "(", "f\"vtc/{phase}/loss\"", ",", "loss", ")", "\n", "\n", "return", "ret", "\n", "\n", "# == end", "\n", "\n", "", "def", "compute_vtm_wpa", "(", "pl_module", ",", "batch", ",", "mode", "=", "\"video\"", ")", ":", "\n", "    ", "pos_len", "=", "len", "(", "batch", "[", "\"text\"", "]", ")", "//", "2", "\n", "neg_len", "=", "len", "(", "batch", "[", "\"text\"", "]", ")", "-", "pos_len", "\n", "vtm_labels", "=", "torch", ".", "cat", "(", "[", "torch", ".", "ones", "(", "pos_len", ")", ",", "torch", ".", "zeros", "(", "neg_len", ")", "]", ")", ".", "to", "(", "\n", "pl_module", ".", "device", "\n", ")", "\n", "vtm_labels", "=", "vtm_labels", "[", "torch", ".", "randperm", "(", "vtm_labels", ".", "size", "(", "0", ")", ")", "]", "\n", "\n", "# print(batch.keys())", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.modules.objectives.compute_mpfr": [[182, 203], ["pl_module.infer", "pl_module.mpfr_score", "torch.mse_loss", "pl_module.log", "infer[].float().mean", "getattr", "infer[].float"], "function", ["home.repos.pwc.inspect_result.showlab_all-in-one.modules.allinone_module.AllinoneTransformerSS.infer"], ["vtm_videos", "=", "[", "\n", "torch", ".", "stack", "(", "\n", "[", "\n", "ti", "if", "vtm_labels", "[", "i", "]", "==", "1", "else", "fi", "\n", "for", "i", ",", "(", "ti", ",", "fi", ")", "in", "enumerate", "(", "zip", "(", "bti", ",", "bfi", ")", ")", "\n", "]", "\n", ")", "\n", "for", "bti", ",", "bfi", "in", "zip", "(", "batch", "[", "\"video\"", "]", ",", "batch", "[", "\"false_video_0\"", "]", ")", "\n", "]", "\n", "\n", "batch", "=", "{", "k", ":", "v", "for", "k", ",", "v", "in", "batch", ".", "items", "(", ")", "}", "\n", "batch", "[", "\"video\"", "]", "=", "vtm_videos", "\n", "\n", "infer", "=", "pl_module", ".", "infer", "(", "batch", ",", "mask_text", "=", "False", ",", "mask_video", "=", "False", ",", "mode", "=", "mode", ")", "\n", "\n", "with", "torch", ".", "cuda", ".", "amp", ".", "autocast", "(", "enabled", "=", "False", ")", ":", "\n", "        ", "txt_emb", ",", "img_emb", "=", "infer", "[", "\"text_feats\"", "]", ",", "infer", "[", "\"video_feats\"", "]", "\n", "txt_mask", ",", "img_mask", "=", "infer", "[", "\"text_masks\"", "]", ".", "bool", "(", ")", ",", "infer", "[", "\"video_masks\"", "]", ".", "bool", "(", ")", "\n", "for", "i", ",", "_len", "in", "enumerate", "(", "txt_mask", ".", "sum", "(", "dim", "=", "1", ")", ")", ":", "\n", "            ", "txt_mask", "[", "i", ",", "_len", "-", "1", "]", "=", "False", "\n", "", "txt_mask", "[", ":", ",", "0", "]", "=", "False", "\n", "img_mask", "[", ":", ",", "0", "]", "=", "False", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.modules.objectives.compute_itc": [[218, 246], ["pl_module.infer", "objectives.sim_matrix", "torch.log_softmax", "torch.log_softmax", "torch.diag", "torch.diag", "torch.diag", "torch.diag", "torch.diag", "torch.diag", "pl_module.log", "torch.cuda.amp.autocast", "torch.cuda.amp.autocast", "torch.cuda.amp.autocast", "torch.diag.sum", "len", "torch.diag.sum", "len", "getattr", "sim_matrix.t"], "function", ["home.repos.pwc.inspect_result.showlab_all-in-one.modules.allinone_module.AllinoneTransformerSS.infer", "home.repos.pwc.inspect_result.showlab_all-in-one.modules.objectives.sim_matrix"], ["T", "=", "ipot", "(", "\n", "cost", ".", "detach", "(", ")", ",", "txt_len", ",", "txt_pad", ",", "img_len", ",", "img_pad", ",", "joint_pad", ",", "0.5", ",", "50", ",", "1", "\n", ")", "\n", "distance", "=", "trace", "(", "cost", ".", "matmul", "(", "T", ".", "detach", "(", ")", ")", ")", "\n", "\n", "", "dist_pos", "=", "distance", ".", "masked_select", "(", "vtm_labels", "==", "1", ")", "\n", "dist_neg", "=", "distance", ".", "masked_select", "(", "vtm_labels", "==", "0", ")", "\n", "ot_loss", "=", "(", "dist_pos", ".", "sum", "(", ")", "-", "dist_neg", ".", "sum", "(", ")", ")", "/", "(", "dist_pos", ".", "size", "(", "0", ")", "+", "dist_neg", ".", "size", "(", "0", ")", ")", "\n", "\n", "vtm_logits", "=", "pl_module", ".", "vtm_score", "(", "infer", "[", "\"cls_feats\"", "]", ")", "\n", "vtm_loss", "=", "F", ".", "cross_entropy", "(", "vtm_logits", ",", "vtm_labels", ".", "long", "(", ")", ")", "\n", "\n", "ret", "=", "{", "\n", "\"vtm_loss\"", ":", "vtm_loss", ",", "\n", "\"vtm_wpa_loss\"", ":", "0.1", "*", "ot_loss", ",", "\n", "\"vtm_logits\"", ":", "vtm_logits", ",", "\n", "\"vtm_labels\"", ":", "vtm_labels", ",", "\n", "}", "\n", "\n", "phase", "=", "\"train\"", "if", "pl_module", ".", "training", "else", "\"val\"", "\n", "loss", "=", "getattr", "(", "pl_module", ",", "f\"{phase}_vtm_loss\"", ")", "(", "ret", "[", "\"vtm_loss\"", "]", ")", "\n", "wpa_loss", "=", "getattr", "(", "pl_module", ",", "f\"{phase}_vtm_wpa_loss\"", ")", "(", "ret", "[", "\"vtm_wpa_loss\"", "]", ")", "\n", "acc", "=", "getattr", "(", "pl_module", ",", "f\"{phase}_vtm_accuracy\"", ")", "(", "\n", "ret", "[", "\"vtm_logits\"", "]", ",", "ret", "[", "\"vtm_labels\"", "]", "\n", ")", "\n", "pl_module", ".", "log", "(", "f\"vtm/{phase}/loss\"", ",", "loss", ")", "\n", "pl_module", ".", "log", "(", "f\"vtm/{phase}/wpa_loss\"", ",", "wpa_loss", ")", "\n", "pl_module", ".", "log", "(", "f\"vtm/{phase}/accuracy\"", ",", "acc", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.modules.objectives.compute_ind_itc": [[252, 284], ["pl_module.infer", "pl_module.infer", "objectives.sim_matrix", "torch.log_softmax", "torch.log_softmax", "torch.diag", "torch.diag", "torch.diag", "torch.diag", "torch.diag", "torch.diag", "pl_module.log", "torch.cuda.amp.autocast", "torch.cuda.amp.autocast", "torch.cuda.amp.autocast", "torch.cuda.amp.autocast", "torch.cuda.amp.autocast", "torch.cuda.amp.autocast", "torch.diag.sum", "len", "torch.diag.sum", "len", "getattr", "sim_matrix.t"], "function", ["home.repos.pwc.inspect_result.showlab_all-in-one.modules.allinone_module.AllinoneTransformerSS.infer", "home.repos.pwc.inspect_result.showlab_all-in-one.modules.allinone_module.AllinoneTransformerSS.infer", "home.repos.pwc.inspect_result.showlab_all-in-one.modules.objectives.sim_matrix"], ["imgcls_logits", "=", "pl_module", ".", "img_classifier", "(", "infer", "[", "\"cls_feats\"", "]", ")", "\n", "imgcls_labels", "=", "batch", "[", "\"label\"", "]", "\n", "imgcls_labels", "=", "torch", ".", "tensor", "(", "imgcls_labels", ")", ".", "to", "(", "pl_module", ".", "device", ")", ".", "long", "(", ")", "\n", "imgcls_loss", "=", "F", ".", "cross_entropy", "(", "imgcls_logits", ",", "imgcls_labels", ")", "\n", "\n", "ret", "=", "{", "\n", "\"imgcls_loss\"", ":", "imgcls_loss", ",", "\n", "\"imgcls_logits\"", ":", "imgcls_logits", ",", "\n", "\"imgcls_labels\"", ":", "imgcls_labels", ",", "\n", "}", "\n", "\n", "phase", "=", "\"train\"", "if", "pl_module", ".", "training", "else", "\"val\"", "\n", "loss", "=", "getattr", "(", "pl_module", ",", "f\"{phase}_imgcls_loss\"", ")", "(", "ret", "[", "\"imgcls_loss\"", "]", ")", "\n", "acc", "=", "getattr", "(", "pl_module", ",", "f\"{phase}_imgcls_accuracy\"", ")", "(", "\n", "ret", "[", "\"imgcls_logits\"", "]", ",", "ret", "[", "\"imgcls_labels\"", "]", "\n", ")", "\n", "pl_module", ".", "log", "(", "f\"imgcls/{phase}/loss\"", ",", "loss", ")", "\n", "pl_module", ".", "log", "(", "f\"imgcls/{phase}/accuracy\"", ",", "acc", ")", "\n", "\n", "return", "ret", "\n", "\n", "\n", "# vcr q -> a", "\n", "", "def", "compute_vcr_q2a", "(", "pl_module", ",", "batch", ")", ":", "\n", "    ", "false_len", "=", "pl_module", ".", "hparams", ".", "config", "[", "\"draw_options_text\"", "]", "-", "1", "\n", "vtm_labels", "=", "torch", ".", "tensor", "(", "batch", "[", "\"answer\"", "]", ")", ".", "to", "(", "pl_module", ".", "device", ")", ".", "long", "(", ")", "\n", "_bs", ",", "_t", ",", "_c", ",", "_h", ",", "_w", "=", "batch", "[", "\"video\"", "]", "[", "0", "]", ".", "shape", "\n", "# for qa", "\n", "text_ids", "=", "torch", ".", "stack", "(", "\n", "[", "batch", "[", "f\"options_text_{i}_ids\"", "]", "for", "i", "in", "range", "(", "false_len", ")", "]", ",", "dim", "=", "1", "\n", ")", "\n", "text_masks", "=", "torch", ".", "stack", "(", "\n", "[", "batch", "[", "f\"options_text_{i}_masks\"", "]", "for", "i", "in", "range", "(", "false_len", ")", "]", ",", "dim", "=", "1", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.modules.objectives.compute_itm_wpa": [[287, 361], ["torch.cat().to", "torch.cat().to", "torch.cat().to", "pl_module.infer", "trace.masked_select", "trace.masked_select", "pl_module.itm_score", "torch.cross_entropy", "pl_module.log", "pl_module.log", "pl_module.log", "len", "len", "torch.stack", "torch.stack", "torch.stack", "torch.cuda.amp.autocast", "torch.cuda.amp.autocast", "torch.cuda.amp.autocast", "enumerate", "objectives.cost_matrix_cosine", "cost_matrix_cosine.masked_fill_", "objectives.ipot", "objectives.trace", "torch.cat().to.long", "getattr", "getattr", "getattr", "torch.cat", "torch.cat", "torch.cat", "torch.randperm", "torch.randperm", "torch.randperm", "zip", "batch.items", "infer[].bool", "infer[].bool", "txt_mask.sum", "txt_emb.float", "img_emb.float", "txt_pad.unsqueeze", "img_pad.unsqueeze", "cost_matrix_cosine.detach", "cost_matrix_cosine.matmul", "distance.masked_select.sum", "distance.masked_select.sum", "distance.masked_select.size", "distance.masked_select.size", "torch.cat().to.size", "ipot.detach", "torch.ones", "torch.ones", "torch.ones", "torch.zeros", "torch.zeros", "torch.zeros", "enumerate", "txt_pad.size", "txt_pad.sum", "img_pad.size", "img_pad.sum", "zip"], "function", ["home.repos.pwc.inspect_result.showlab_all-in-one.modules.allinone_module.AllinoneTransformerSS.infer", "home.repos.pwc.inspect_result.showlab_all-in-one.modules.objectives.cost_matrix_cosine", "home.repos.pwc.inspect_result.showlab_all-in-one.modules.objectives.ipot", "home.repos.pwc.inspect_result.showlab_all-in-one.modules.objectives.trace"], ["[", "batch", "[", "f\"options_text_{i}_labels\"", "]", "for", "i", "in", "range", "(", "false_len", ")", "]", ",", "dim", "=", "1", "\n", ")", "\n", "\n", "# concat first option and other options", "\n", "text_ids", "=", "torch", ".", "cat", "(", "[", "batch", "[", "\"text_ids\"", "]", ".", "unsqueeze", "(", "1", ")", ",", "text_ids", "]", ",", "dim", "=", "1", ")", "\n", "text_masks", "=", "torch", ".", "cat", "(", "[", "batch", "[", "\"text_masks\"", "]", ".", "unsqueeze", "(", "1", ")", ",", "text_masks", "]", ",", "dim", "=", "1", ")", "\n", "text_labels", "=", "torch", ".", "cat", "(", "[", "batch", "[", "\"text_labels\"", "]", ".", "unsqueeze", "(", "1", ")", ",", "text_labels", "]", ",", "dim", "=", "1", ")", "\n", "videos", "=", "batch", "[", "\"video\"", "]", "[", "0", "]", ".", "unsqueeze", "(", "1", ")", ".", "expand", "(", "_bs", ",", "false_len", "+", "1", ",", "_t", ",", "_c", ",", "_h", ",", "_w", ")", "\n", "\n", "infer", "=", "pl_module", ".", "infer", "(", "\n", "{", "\n", "\"video\"", ":", "[", "rearrange", "(", "videos", ",", "\"bs fs t c h w -> (bs fs) t c h w\"", ")", "]", ",", "\n", "\"text_ids\"", ":", "rearrange", "(", "text_ids", ",", "\"bs fs tl -> (bs fs) tl\"", ")", ",", "\n", "\"text_masks\"", ":", "rearrange", "(", "text_masks", ",", "\"bs fs tl -> (bs fs) tl\"", ")", ",", "\n", "\"text_labels\"", ":", "rearrange", "(", "text_labels", ",", "\"bs fs tl -> (bs fs) tl\"", ")", ",", "\n", "}", "\n", ")", "\n", "score", "=", "pl_module", ".", "rank_output", "(", "infer", "[", "\"cls_feats\"", "]", ")", "[", ":", ",", "0", "]", "\n", "score", "=", "rearrange", "(", "score", ",", "\"(bs fs) -> bs fs\"", ",", "bs", "=", "_bs", ",", "fs", "=", "false_len", "+", "1", ")", "\n", "qa_loss", "=", "F", ".", "cross_entropy", "(", "score", ",", "vtm_labels", ")", "\n", "# for qa->r", "\n", "\n", "reason_len", "=", "pl_module", ".", "hparams", ".", "config", "[", "\"draw_options_text\"", "]", "\n", "qar_labels", "=", "torch", ".", "tensor", "(", "batch", "[", "\"reason_answer\"", "]", ")", ".", "to", "(", "pl_module", ".", "device", ")", ".", "long", "(", ")", "\n", "_bs", ",", "_t", ",", "_c", ",", "_h", ",", "_w", "=", "batch", "[", "\"video\"", "]", "[", "0", "]", ".", "shape", "\n", "# for qar", "\n", "qar_text_ids", "=", "torch", ".", "stack", "(", "\n", "[", "batch", "[", "f\"qar_text_{i}_ids\"", "]", "for", "i", "in", "range", "(", "reason_len", ")", "]", ",", "dim", "=", "1", "\n", ")", "\n", "qar_text_masks", "=", "torch", ".", "stack", "(", "\n", "[", "batch", "[", "f\"qar_text_{i}_masks\"", "]", "for", "i", "in", "range", "(", "reason_len", ")", "]", ",", "dim", "=", "1", "\n", ")", "\n", "qar_text_labels", "=", "torch", ".", "stack", "(", "\n", "[", "batch", "[", "f\"qar_text_{i}_labels\"", "]", "for", "i", "in", "range", "(", "reason_len", ")", "]", ",", "dim", "=", "1", "\n", ")", "\n", "\n", "# concat first option and other options", "\n", "videos", "=", "batch", "[", "\"video\"", "]", "[", "0", "]", ".", "unsqueeze", "(", "1", ")", ".", "expand", "(", "_bs", ",", "reason_len", ",", "_t", ",", "_c", ",", "_h", ",", "_w", ")", "\n", "\n", "qar_infer", "=", "pl_module", ".", "infer", "(", "\n", "{", "\n", "\"video\"", ":", "[", "rearrange", "(", "videos", ",", "\"bs fs t c h w -> (bs fs) t c h w\"", ")", "]", ",", "\n", "\"text_ids\"", ":", "rearrange", "(", "qar_text_ids", ",", "\"bs fs tl -> (bs fs) tl\"", ")", ",", "\n", "\"text_masks\"", ":", "rearrange", "(", "qar_text_masks", ",", "\"bs fs tl -> (bs fs) tl\"", ")", ",", "\n", "\"text_labels\"", ":", "rearrange", "(", "qar_text_labels", ",", "\"bs fs tl -> (bs fs) tl\"", ")", ",", "\n", "}", "\n", ")", "\n", "qar_score", "=", "pl_module", ".", "rank_output_2", "(", "qar_infer", "[", "\"cls_feats\"", "]", ")", "[", ":", ",", "0", "]", "\n", "qar_score", "=", "rearrange", "(", "qar_score", ",", "\"(bs fs) -> bs fs\"", ",", "bs", "=", "_bs", ",", "fs", "=", "reason_len", ")", "\n", "qar_loss", "=", "F", ".", "cross_entropy", "(", "qar_score", ",", "qar_labels", ")", "\n", "\n", "# print(score, vtm_labels)", "\n", "phase", "=", "\"train\"", "if", "pl_module", ".", "training", "else", "\"val\"", "\n", "qa_acc", "=", "getattr", "(", "pl_module", ",", "f\"{phase}_vcr_q2a_accuracy\"", ")", "(", "\n", "score", ",", "vtm_labels", "\n", ")", "\n", "qar_acc", "=", "getattr", "(", "pl_module", ",", "f\"{phase}_vcr_qar_accuracy\"", ")", "(", "\n", "qar_score", ",", "qar_labels", "\n", ")", "\n", "\n", "ret", "=", "{", "\n", "\"vcr_q2a_loss\"", ":", "qa_loss", ",", "\n", "\"vcr_qar_loss\"", ":", "qar_loss", "\n", "}", "\n", "\n", "phase", "=", "\"train\"", "if", "pl_module", ".", "training", "else", "\"val\"", "\n", "qa_loss", "=", "getattr", "(", "pl_module", ",", "f\"{phase}_vcr_q2a_loss\"", ")", "(", "ret", "[", "\"vcr_q2a_loss\"", "]", ")", "\n", "qar_loss", "=", "getattr", "(", "pl_module", ",", "f\"{phase}_vcr_qar_loss\"", ")", "(", "ret", "[", "\"vcr_qar_loss\"", "]", ")", "\n", "\n", "pl_module", ".", "log", "(", "f\"vcr_q2a/{phase}/loss\"", ",", "qa_loss", ")", "\n", "pl_module", ".", "log", "(", "f\"vcr_qar/{phase}/loss\"", ",", "qar_loss", ")", "\n", "pl_module", ".", "log", "(", "f\"vcr_q2a/{phase}/accuracy\"", ",", "qa_acc", ")", "\n", "pl_module", ".", "log", "(", "f\"vcr_qar/{phase}/accuracy\"", ",", "qar_acc", ")", "\n", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.transforms.__init__.keys_to_transforms": [[12, 14], ["None"], "function", ["None"], []], "home.repos.pwc.inspect_result.showlab_all-in-one.transforms.pixelbert.pixelbert_transform": [[9, 16], ["int", "torchvision.transforms.Compose", "utils.MinMaxResize", "torchvision.transforms.ToTensor"], "function", ["None"], ["def", "pixelbert_transform", "(", "size", "=", "800", ")", ":", "\n", "    ", "longer", "=", "int", "(", "(", "1333", "/", "800", ")", "*", "size", ")", "\n", "return", "transforms", ".", "Compose", "(", "\n", "[", "\n", "MinMaxResize", "(", "shorter", "=", "size", ",", "longer", "=", "longer", ")", ",", "\n", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "inception_normalize", ",", "\n", "]", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.transforms.pixelbert.pixelbert_transform_randaug": [[20, 31], ["int", "torchvision.transforms.Compose", "transforms.Compose.transforms.insert", "randaug.RandAugment", "utils.MinMaxResize", "torchvision.transforms.ToTensor"], "function", ["None"], ["", "def", "pixelbert_transform_randaug", "(", "size", "=", "800", ")", ":", "\n", "    ", "longer", "=", "int", "(", "(", "1333", "/", "800", ")", "*", "size", ")", "\n", "trs", "=", "transforms", ".", "Compose", "(", "\n", "[", "\n", "MinMaxResize", "(", "shorter", "=", "size", ",", "longer", "=", "longer", ")", ",", "\n", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "inception_normalize", ",", "\n", "]", "\n", ")", "\n", "trs", ".", "transforms", ".", "insert", "(", "0", ",", "RandAugment", "(", "2", ",", "9", ")", ")", "\n", "return", "trs", "", "", ""]], "home.repos.pwc.inspect_result.showlab_all-in-one.transforms.mix.SpatialMixup.__init__": [[6, 10], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "alpha", "=", "0.2", ",", "trace", "=", "True", ",", "version", "=", "2", ")", ":", "\n", "        ", "self", ".", "alpha", "=", "alpha", "\n", "self", ".", "trace", "=", "trace", "\n", "self", ".", "version", "=", "version", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.transforms.mix.SpatialMixup.mixup_data": [[11, 27], ["x.size", "range", "random.random", "torch.zeros_like", "random.randint", "range"], "methods", ["None"], ["", "def", "mixup_data", "(", "self", ",", "x", ")", ":", "\n", "        ", "\"\"\"\n        return mixed inputs. pairs of targets\n        \"\"\"", "\n", "b", ",", "t", ",", "c", ",", "h", ",", "w", "=", "x", ".", "size", "(", ")", "\n", "loss_prob", "=", "random", ".", "random", "(", ")", "*", "self", ".", "alpha", "\n", "if", "self", ".", "trace", ":", "\n", "            ", "mixed_x", "=", "x", "\n", "", "else", ":", "\n", "            ", "mixed_x", "=", "torch", ".", "zeros_like", "(", "x", ")", "\n", "", "for", "i", "in", "range", "(", "b", ")", ":", "\n", "            ", "tmp", "=", "(", "i", "+", "1", ")", "%", "b", "\n", "img_index", "=", "random", ".", "randint", "(", "0", ",", "t", "-", "1", ")", "\n", "for", "j", "in", "range", "(", "t", ")", ":", "\n", "                ", "mixed_x", "[", "i", ",", "j", ",", ":", ",", ":", ",", ":", "]", "=", "(", "1", "-", "loss_prob", ")", "*", "x", "[", "i", ",", "j", ",", ":", ",", ":", ",", ":", "]", "+", "loss_prob", "*", "x", "[", "tmp", ",", "img_index", ",", ":", ",", ":", ",", ":", "]", "\n", "", "", "return", "mixed_x", "\n", "", "", ""]], "home.repos.pwc.inspect_result.showlab_all-in-one.transforms.video_transform.ClipToTensor.__init__": [[29, 33], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "channel_nb", "=", "3", ",", "div_255", "=", "True", ",", "numpy", "=", "False", ")", ":", "\n", "        ", "self", ".", "channel_nb", "=", "channel_nb", "\n", "self", ".", "div_255", "=", "div_255", "\n", "self", ".", "numpy", "=", "numpy", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.transforms.video_transform.ClipToTensor.__call__": [[34, 76], ["isinstance", "numpy.zeros", "enumerate", "isinstance", "isinstance", "video_transform.convert_img", "torch.from_numpy", "TypeError", "len", "int", "int", "isinstance", "isinstance", "tensor_clip.div.div.float", "tensor_clip.div.div.div", "numpy.array", "TypeError", "type", "type"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.transforms.video_transform.convert_img"], ["", "def", "__call__", "(", "self", ",", "clip", ")", ":", "\n", "        ", "\"\"\"\n        Args: clip_test (list of numpy.ndarray): clip_test (list of images)\n        to be converted to tensor.\n        \"\"\"", "\n", "# Retrieve shape", "\n", "if", "isinstance", "(", "clip", "[", "0", "]", ",", "np", ".", "ndarray", ")", ":", "\n", "            ", "h", ",", "w", ",", "ch", "=", "clip", "[", "0", "]", ".", "shape", "\n", "assert", "ch", "==", "self", ".", "channel_nb", ",", "'Got {0} instead of 3 channels'", ".", "format", "(", "\n", "ch", ")", "\n", "", "elif", "isinstance", "(", "clip", "[", "0", "]", ",", "Image", ".", "Image", ")", ":", "\n", "            ", "w", ",", "h", "=", "clip", "[", "0", "]", ".", "size", "\n", "", "else", ":", "\n", "            ", "raise", "TypeError", "(", "'Expected numpy.ndarray or PIL.Image\\\n            but got list of {0}'", ".", "format", "(", "type", "(", "clip", "[", "0", "]", ")", ")", ")", "\n", "\n", "", "np_clip", "=", "np", ".", "zeros", "(", "[", "self", ".", "channel_nb", ",", "len", "(", "clip", ")", ",", "int", "(", "h", ")", ",", "int", "(", "w", ")", "]", ")", "\n", "\n", "# Convert", "\n", "for", "img_idx", ",", "img", "in", "enumerate", "(", "clip", ")", ":", "\n", "            ", "if", "isinstance", "(", "img", ",", "np", ".", "ndarray", ")", ":", "\n", "                ", "pass", "\n", "", "elif", "isinstance", "(", "img", ",", "Image", ".", "Image", ")", ":", "\n", "                ", "img", "=", "np", ".", "array", "(", "img", ",", "copy", "=", "False", ")", "\n", "", "else", ":", "\n", "                ", "raise", "TypeError", "(", "'Expected numpy.ndarray or PIL.Image\\\n                but got list of {0}'", ".", "format", "(", "type", "(", "clip", "[", "0", "]", ")", ")", ")", "\n", "", "img", "=", "convert_img", "(", "img", ")", "\n", "np_clip", "[", ":", ",", "img_idx", ",", ":", ",", ":", "]", "=", "img", "\n", "", "if", "self", ".", "numpy", ":", "\n", "            ", "if", "self", ".", "div_255", ":", "\n", "                ", "np_clip", "=", "np_clip", "/", "255", "\n", "", "return", "np_clip", "\n", "\n", "", "else", ":", "\n", "            ", "tensor_clip", "=", "torch", ".", "from_numpy", "(", "np_clip", ")", "\n", "\n", "if", "not", "isinstance", "(", "tensor_clip", ",", "torch", ".", "FloatTensor", ")", ":", "\n", "                ", "tensor_clip", "=", "tensor_clip", ".", "float", "(", ")", "\n", "", "if", "self", ".", "div_255", ":", "\n", "                ", "tensor_clip", "=", "tensor_clip", ".", "div", "(", "255", ")", "\n", "", "return", "tensor_clip", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.transforms.video_transform.ToTensor.__call__": [[82, 85], ["torch.from_numpy"], "methods", ["None"], ["def", "__call__", "(", "self", ",", "array", ")", ":", "\n", "        ", "tensor", "=", "torch", ".", "from_numpy", "(", "array", ")", "\n", "return", "tensor", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.transforms.video_transform.ColorDistortion.__init__": [[87, 92], ["torchvision.transforms.ColorJitter", "torchvision.transforms.RandomApply", "torchvision.transforms.RandomGrayscale"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "s", "=", "1.0", ")", ":", "\n", "        ", "self", ".", "s", "=", "s", "\n", "self", ".", "color_jitter", "=", "transforms", ".", "ColorJitter", "(", "0.8", "*", "s", ",", "0.8", "*", "s", ",", "0.8", "*", "s", ",", "0.2", "*", "s", ")", "\n", "self", ".", "rnd_color_jitter", "=", "transforms", ".", "RandomApply", "(", "[", "self", ".", "color_jitter", "]", ",", "p", "=", "0.8", ")", "\n", "self", ".", "rnd_gray", "=", "transforms", ".", "RandomGrayscale", "(", "p", "=", "0.2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.transforms.video_transform.ColorDistortion.__call__": [[93, 96], ["torchvision.transforms.Compose", "torchvision.transforms.Compose."], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "video", ")", ":", "\n", "        ", "color_distort", "=", "transforms", ".", "Compose", "(", "[", "self", ".", "rnd_color_jitter", ",", "self", ".", "rnd_gray", "]", ")", "\n", "return", "color_distort", "(", "video", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.transforms.video_transform.Compose.__init__": [[105, 107], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "transforms", ")", ":", "\n", "        ", "self", ".", "transforms", "=", "transforms", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.transforms.video_transform.Compose.__call__": [[108, 112], ["t"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "clip", ")", ":", "\n", "        ", "for", "t", "in", "self", ".", "transforms", ":", "\n", "            ", "clip", "=", "t", "(", "clip", ")", "\n", "", "return", "clip", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.transforms.video_transform.RandomHorizontalFlip.__call__": [[119, 138], ["random.random", "isinstance", "isinstance", "numpy.fliplr", "TypeError", "img.transpose", "type"], "methods", ["None"], ["def", "__call__", "(", "self", ",", "clip", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n        img (PIL.Image or numpy.ndarray): List of images to be cropped\n        in format (h, w, c) in numpy.ndarray\n        Returns:\n        PIL.Image or numpy.ndarray: Randomly flipped clip_test\n        \"\"\"", "\n", "if", "random", ".", "random", "(", ")", "<", "0.5", ":", "\n", "            ", "if", "isinstance", "(", "clip", "[", "0", "]", ",", "np", ".", "ndarray", ")", ":", "\n", "                ", "return", "[", "np", ".", "fliplr", "(", "img", ")", "for", "img", "in", "clip", "]", "\n", "", "elif", "isinstance", "(", "clip", "[", "0", "]", ",", "PIL", ".", "Image", ".", "Image", ")", ":", "\n", "                ", "return", "[", "\n", "img", ".", "transpose", "(", "PIL", ".", "Image", ".", "FLIP_LEFT_RIGHT", ")", "for", "img", "in", "clip", "\n", "]", "\n", "", "else", ":", "\n", "                ", "raise", "TypeError", "(", "'Expected numpy.ndarray or PIL.Image'", "+", "\n", "' but got list of {0}'", ".", "format", "(", "type", "(", "clip", "[", "0", "]", ")", ")", ")", "\n", "", "", "return", "clip", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.transforms.video_transform.RandomResize.__init__": [[150, 153], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "ratio", "=", "(", "3.", "/", "4.", ",", "4.", "/", "3.", ")", ",", "interpolation", "=", "'nearest'", ")", ":", "\n", "        ", "self", ".", "ratio", "=", "ratio", "\n", "self", ".", "interpolation", "=", "interpolation", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.transforms.video_transform.RandomResize.__call__": [[154, 168], ["random.uniform", "isinstance", "int", "int", "functional.resize_clip", "isinstance"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.transforms.functional.resize_clip"], ["", "def", "__call__", "(", "self", ",", "clip", ")", ":", "\n", "        ", "scaling_factor", "=", "random", ".", "uniform", "(", "self", ".", "ratio", "[", "0", "]", ",", "self", ".", "ratio", "[", "1", "]", ")", "\n", "\n", "if", "isinstance", "(", "clip", "[", "0", "]", ",", "np", ".", "ndarray", ")", ":", "\n", "            ", "im_h", ",", "im_w", ",", "im_c", "=", "clip", "[", "0", "]", ".", "shape", "\n", "", "elif", "isinstance", "(", "clip", "[", "0", "]", ",", "PIL", ".", "Image", ".", "Image", ")", ":", "\n", "            ", "im_w", ",", "im_h", "=", "clip", "[", "0", "]", ".", "size", "\n", "\n", "", "new_w", "=", "int", "(", "im_w", "*", "scaling_factor", ")", "\n", "new_h", "=", "int", "(", "im_h", "*", "scaling_factor", ")", "\n", "new_size", "=", "(", "new_w", ",", "new_h", ")", "\n", "resized", "=", "F", ".", "resize_clip", "(", "\n", "clip", ",", "new_size", ",", "interpolation", "=", "self", ".", "interpolation", ")", "\n", "return", "resized", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.transforms.video_transform.Resize.__init__": [[180, 183], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "size", ",", "interpolation", "=", "'nearest'", ")", ":", "\n", "        ", "self", ".", "size", "=", "size", "\n", "self", ".", "interpolation", "=", "interpolation", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.transforms.video_transform.Resize.__call__": [[184, 188], ["functional.resize_clip"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.transforms.functional.resize_clip"], ["", "def", "__call__", "(", "self", ",", "clip", ")", ":", "\n", "        ", "resized", "=", "F", ".", "resize_clip", "(", "\n", "clip", ",", "self", ".", "size", ",", "interpolation", "=", "self", ".", "interpolation", ")", "\n", "return", "resized", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.transforms.video_transform.RandomCrop.__init__": [[197, 202], ["isinstance"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "size", ")", ":", "\n", "        ", "if", "isinstance", "(", "size", ",", "numbers", ".", "Number", ")", ":", "\n", "            ", "size", "=", "(", "size", ",", "size", ")", "\n", "\n", "", "self", ".", "size", "=", "size", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.transforms.video_transform.RandomCrop.__call__": [[203, 232], ["isinstance", "random.randint", "random.randint", "functional.crop_clip", "isinstance", "ValueError", "TypeError", "type"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.transforms.functional.crop_clip"], ["", "def", "__call__", "(", "self", ",", "clip", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n        img (PIL.Image or numpy.ndarray): List of images to be cropped\n        in format (h, w, c) in numpy.ndarray\n        Returns:\n        PIL.Image or numpy.ndarray: Cropped list of images\n        \"\"\"", "\n", "h", ",", "w", "=", "self", ".", "size", "\n", "if", "isinstance", "(", "clip", "[", "0", "]", ",", "np", ".", "ndarray", ")", ":", "\n", "            ", "im_h", ",", "im_w", ",", "im_c", "=", "clip", "[", "0", "]", ".", "shape", "\n", "", "elif", "isinstance", "(", "clip", "[", "0", "]", ",", "PIL", ".", "Image", ".", "Image", ")", ":", "\n", "            ", "im_w", ",", "im_h", "=", "clip", "[", "0", "]", ".", "size", "\n", "", "else", ":", "\n", "            ", "raise", "TypeError", "(", "'Expected numpy.ndarray or PIL.Image'", "+", "\n", "'but got list of {0}'", ".", "format", "(", "type", "(", "clip", "[", "0", "]", ")", ")", ")", "\n", "", "if", "w", ">", "im_w", "or", "h", ">", "im_h", ":", "\n", "            ", "error_msg", "=", "(", "\n", "'Initial image size should be larger then '", "\n", "'cropped size but got cropped sizes : ({w}, {h}) while '", "\n", "'initial image is ({im_w}, {im_h})'", ".", "format", "(", "\n", "im_w", "=", "im_w", ",", "im_h", "=", "im_h", ",", "w", "=", "w", ",", "h", "=", "h", ")", ")", "\n", "raise", "ValueError", "(", "error_msg", ")", "\n", "\n", "", "x1", "=", "random", ".", "randint", "(", "0", ",", "im_w", "-", "w", ")", "\n", "y1", "=", "random", ".", "randint", "(", "0", ",", "im_h", "-", "h", ")", "\n", "cropped", "=", "F", ".", "crop_clip", "(", "clip", ",", "y1", ",", "x1", ",", "h", ",", "w", ")", "\n", "\n", "return", "cropped", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.transforms.video_transform.CornerCrop.__init__": [[236, 244], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "size", ",", "crop_position", "=", "None", ")", ":", "\n", "        ", "self", ".", "size", "=", "size", "\n", "if", "crop_position", "is", "None", ":", "\n", "            ", "self", ".", "randomize", "=", "True", "\n", "", "else", ":", "\n", "            ", "self", ".", "randomize", "=", "False", "\n", "", "self", ".", "crop_position", "=", "crop_position", "\n", "self", ".", "crop_positions", "=", "[", "'c'", ",", "'tl'", ",", "'tr'", ",", "'bl'", ",", "'br'", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.transforms.video_transform.CornerCrop.__call__": [[245, 278], ["list", "list.append", "int", "int", "round", "round"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "imgs", ")", ":", "\n", "        ", "t", ",", "h", ",", "w", ",", "c", "=", "imgs", ".", "shape", "\n", "corner_imgs", "=", "list", "(", ")", "\n", "for", "n", "in", "self", ".", "crop_positions", ":", "\n", "#print(n)", "\n", "            ", "if", "n", "==", "'c'", ":", "\n", "                ", "th", ",", "tw", "=", "(", "self", ".", "size", ",", "self", ".", "size", ")", "\n", "x1", "=", "int", "(", "round", "(", "(", "w", "-", "tw", ")", "/", "2.", ")", ")", "\n", "y1", "=", "int", "(", "round", "(", "(", "h", "-", "th", ")", "/", "2.", ")", ")", "\n", "x2", "=", "x1", "+", "tw", "\n", "y2", "=", "y1", "+", "th", "\n", "", "elif", "n", "==", "'tl'", ":", "\n", "                ", "x1", "=", "0", "\n", "y1", "=", "0", "\n", "x2", "=", "self", ".", "size", "\n", "y2", "=", "self", ".", "size", "\n", "", "elif", "n", "==", "'tr'", ":", "\n", "                ", "x1", "=", "w", "-", "self", ".", "size", "\n", "y1", "=", "0", "\n", "x2", "=", "w", "\n", "y2", "=", "self", ".", "size", "\n", "", "elif", "n", "==", "'bl'", ":", "\n", "                ", "x1", "=", "0", "\n", "y1", "=", "h", "-", "self", ".", "size", "\n", "x2", "=", "self", ".", "size", "\n", "y2", "=", "h", "\n", "", "elif", "n", "==", "'br'", ":", "\n", "                ", "x1", "=", "w", "-", "self", ".", "size", "\n", "y1", "=", "h", "-", "self", ".", "size", "\n", "x2", "=", "w", "\n", "y2", "=", "h", "\n", "", "corner_imgs", ".", "append", "(", "imgs", "[", ":", ",", "y1", ":", "y2", ",", "x1", ":", "x2", ",", ":", "]", ")", "\n", "", "return", "corner_imgs", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.transforms.video_transform.CornerCrop.randomize_parameters": [[279, 284], ["random.randint", "len"], "methods", ["None"], ["", "def", "randomize_parameters", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "randomize", ":", "\n", "            ", "self", ".", "crop_position", "=", "self", ".", "crop_positions", "[", "random", ".", "randint", "(", "\n", "0", ",", "\n", "len", "(", "self", ".", "crop_positions", ")", "-", "1", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.transforms.video_transform.RandomRotation.__init__": [[295, 307], ["isinstance", "ValueError", "len", "ValueError"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "degrees", ")", ":", "\n", "        ", "if", "isinstance", "(", "degrees", ",", "numbers", ".", "Number", ")", ":", "\n", "            ", "if", "degrees", "<", "0", ":", "\n", "                ", "raise", "ValueError", "(", "'If degrees is a single number,'", "\n", "'must be positive'", ")", "\n", "", "degrees", "=", "(", "-", "degrees", ",", "degrees", ")", "\n", "", "else", ":", "\n", "            ", "if", "len", "(", "degrees", ")", "!=", "2", ":", "\n", "                ", "raise", "ValueError", "(", "'If degrees is a sequence,'", "\n", "'it must be of len 2.'", ")", "\n", "\n", "", "", "self", ".", "degrees", "=", "degrees", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.transforms.video_transform.RandomRotation.__call__": [[308, 326], ["random.uniform", "isinstance", "isinstance", "skimage.transform.rotate", "skimage.transform.rotate", "skimage.transform.rotate", "skimage.transform.rotate", "TypeError", "img.rotate", "type"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "clip", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n        img (PIL.Image or numpy.ndarray): List of images to be cropped\n        in format (h, w, c) in numpy.ndarray\n        Returns:\n        PIL.Image or numpy.ndarray: Cropped list of images\n        \"\"\"", "\n", "angle", "=", "random", ".", "uniform", "(", "self", ".", "degrees", "[", "0", "]", ",", "self", ".", "degrees", "[", "1", "]", ")", "\n", "if", "isinstance", "(", "clip", "[", "0", "]", ",", "np", ".", "ndarray", ")", ":", "\n", "            ", "rotated", "=", "[", "skimage", ".", "transform", ".", "rotate", "(", "img", ",", "angle", ")", "for", "img", "in", "clip", "]", "\n", "", "elif", "isinstance", "(", "clip", "[", "0", "]", ",", "PIL", ".", "Image", ".", "Image", ")", ":", "\n", "            ", "rotated", "=", "[", "img", ".", "rotate", "(", "angle", ")", "for", "img", "in", "clip", "]", "\n", "", "else", ":", "\n", "            ", "raise", "TypeError", "(", "'Expected numpy.ndarray or PIL.Image'", "+", "\n", "'but got list of {0}'", ".", "format", "(", "type", "(", "clip", "[", "0", "]", ")", ")", ")", "\n", "\n", "", "return", "rotated", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.transforms.video_transform.STA_RandomRotation.__init__": [[337, 349], ["isinstance", "ValueError", "len", "ValueError"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "degrees", ")", ":", "\n", "        ", "if", "isinstance", "(", "degrees", ",", "numbers", ".", "Number", ")", ":", "\n", "            ", "if", "degrees", "<", "0", ":", "\n", "                ", "raise", "ValueError", "(", "'If degrees is a single number,'", "\n", "'must be positive'", ")", "\n", "", "degrees", "=", "(", "-", "degrees", ",", "degrees", ")", "\n", "", "else", ":", "\n", "            ", "if", "len", "(", "degrees", ")", "!=", "2", ":", "\n", "                ", "raise", "ValueError", "(", "'If degrees is a sequence,'", "\n", "'it must be of len 2.'", ")", "\n", "\n", "", "", "self", ".", "degrees", "=", "degrees", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.transforms.video_transform.STA_RandomRotation.__call__": [[350, 370], ["len", "random.uniform", "isinstance", "isinstance", "range", "skimage.transform.rotate", "skimage.transform.rotate", "skimage.transform.rotate", "skimage.transform.rotate", "TypeError", "enumerate", "img.rotate", "enumerate", "type"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "clip", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n        img (PIL.Image or numpy.ndarray): List of images to be cropped\n        in format (h, w, c) in numpy.ndarray\n        Returns:\n        PIL.Image or numpy.ndarray: Cropped list of images\n        \"\"\"", "\n", "bsz", "=", "len", "(", "clip", ")", "\n", "angle", "=", "random", ".", "uniform", "(", "self", ".", "degrees", "[", "0", "]", ",", "self", ".", "degrees", "[", "1", "]", ")", "\n", "angles", "=", "[", "(", "i", "+", "1", ")", "/", "(", "bsz", "+", "1", ")", "*", "angle", "for", "i", "in", "range", "(", "bsz", ")", "]", "\n", "if", "isinstance", "(", "clip", "[", "0", "]", ",", "np", ".", "ndarray", ")", ":", "\n", "            ", "rotated", "=", "[", "skimage", ".", "transform", ".", "rotate", "(", "img", ",", "angles", "[", "i", "]", ")", "for", "i", ",", "img", "in", "enumerate", "(", "clip", ")", "]", "\n", "", "elif", "isinstance", "(", "clip", "[", "0", "]", ",", "PIL", ".", "Image", ".", "Image", ")", ":", "\n", "            ", "rotated", "=", "[", "img", ".", "rotate", "(", "angles", "[", "i", "]", ")", "for", "i", ",", "img", "in", "enumerate", "(", "clip", ")", "]", "\n", "", "else", ":", "\n", "            ", "raise", "TypeError", "(", "'Expected numpy.ndarray or PIL.Image'", "+", "\n", "'but got list of {0}'", ".", "format", "(", "type", "(", "clip", "[", "0", "]", ")", ")", ")", "\n", "\n", "", "return", "rotated", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.transforms.video_transform.Each_RandomRotation.__init__": [[381, 393], ["isinstance", "ValueError", "len", "ValueError"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "degrees", ")", ":", "\n", "        ", "if", "isinstance", "(", "degrees", ",", "numbers", ".", "Number", ")", ":", "\n", "            ", "if", "degrees", "<", "0", ":", "\n", "                ", "raise", "ValueError", "(", "'If degrees is a single number,'", "\n", "'must be positive'", ")", "\n", "", "degrees", "=", "(", "-", "degrees", ",", "degrees", ")", "\n", "", "else", ":", "\n", "            ", "if", "len", "(", "degrees", ")", "!=", "2", ":", "\n", "                ", "raise", "ValueError", "(", "'If degrees is a sequence,'", "\n", "'it must be of len 2.'", ")", "\n", "\n", "", "", "self", ".", "degrees", "=", "degrees", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.transforms.video_transform.Each_RandomRotation.__call__": [[394, 414], ["len", "isinstance", "random.uniform", "isinstance", "range", "skimage.transform.rotate", "skimage.transform.rotate", "skimage.transform.rotate", "skimage.transform.rotate", "TypeError", "enumerate", "img.rotate", "enumerate", "type"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "clip", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n        img (PIL.Image or numpy.ndarray): List of images to be cropped\n        in format (h, w, c) in numpy.ndarray\n        Returns:\n        PIL.Image or numpy.ndarray: Cropped list of images\n        \"\"\"", "\n", "bsz", "=", "len", "(", "clip", ")", "\n", "angles", "=", "[", "random", ".", "uniform", "(", "self", ".", "degrees", "[", "0", "]", ",", "self", ".", "degrees", "[", "1", "]", ")", "for", "i", "in", "range", "(", "bsz", ")", "]", "\n", "# print(angles)", "\n", "if", "isinstance", "(", "clip", "[", "0", "]", ",", "np", ".", "ndarray", ")", ":", "\n", "            ", "rotated", "=", "[", "skimage", ".", "transform", ".", "rotate", "(", "img", ",", "angles", "[", "i", "]", ")", "for", "i", ",", "img", "in", "enumerate", "(", "clip", ")", "]", "\n", "", "elif", "isinstance", "(", "clip", "[", "0", "]", ",", "PIL", ".", "Image", ".", "Image", ")", ":", "\n", "            ", "rotated", "=", "[", "img", ".", "rotate", "(", "angles", "[", "i", "]", ")", "for", "i", ",", "img", "in", "enumerate", "(", "clip", ")", "]", "\n", "", "else", ":", "\n", "            ", "raise", "TypeError", "(", "'Expected numpy.ndarray or PIL.Image'", "+", "\n", "'but got list of {0}'", ".", "format", "(", "type", "(", "clip", "[", "0", "]", ")", ")", ")", "\n", "\n", "", "return", "rotated", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.transforms.video_transform.CenterCrop.__init__": [[423, 428], ["isinstance"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "size", ")", ":", "\n", "        ", "if", "isinstance", "(", "size", ",", "numbers", ".", "Number", ")", ":", "\n", "            ", "size", "=", "(", "size", ",", "size", ")", "\n", "\n", "", "self", ".", "size", "=", "size", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.transforms.video_transform.CenterCrop.__call__": [[429, 458], ["isinstance", "int", "int", "functional.crop_clip", "isinstance", "ValueError", "round", "round", "TypeError", "type"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.transforms.functional.crop_clip"], ["", "def", "__call__", "(", "self", ",", "clip", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n        img (PIL.Image or numpy.ndarray): List of images to be cropped\n        in format (h, w, c) in numpy.ndarray\n        Returns:\n        PIL.Image or numpy.ndarray: Cropped list of images\n        \"\"\"", "\n", "h", ",", "w", "=", "self", ".", "size", "\n", "if", "isinstance", "(", "clip", "[", "0", "]", ",", "np", ".", "ndarray", ")", ":", "\n", "            ", "im_h", ",", "im_w", ",", "im_c", "=", "clip", "[", "0", "]", ".", "shape", "\n", "", "elif", "isinstance", "(", "clip", "[", "0", "]", ",", "PIL", ".", "Image", ".", "Image", ")", ":", "\n", "            ", "im_w", ",", "im_h", "=", "clip", "[", "0", "]", ".", "size", "\n", "", "else", ":", "\n", "            ", "raise", "TypeError", "(", "'Expected numpy.ndarray or PIL.Image'", "+", "\n", "'but got list of {0}'", ".", "format", "(", "type", "(", "clip", "[", "0", "]", ")", ")", ")", "\n", "", "if", "w", ">", "im_w", "or", "h", ">", "im_h", ":", "\n", "            ", "error_msg", "=", "(", "\n", "'Initial image size should be larger then '", "\n", "'cropped size but got cropped sizes : ({w}, {h}) while '", "\n", "'initial image is ({im_w}, {im_h})'", ".", "format", "(", "\n", "im_w", "=", "im_w", ",", "im_h", "=", "im_h", ",", "w", "=", "w", ",", "h", "=", "h", ")", ")", "\n", "raise", "ValueError", "(", "error_msg", ")", "\n", "\n", "", "x1", "=", "int", "(", "round", "(", "(", "im_w", "-", "w", ")", "/", "2.", ")", ")", "\n", "y1", "=", "int", "(", "round", "(", "(", "im_h", "-", "h", ")", "/", "2.", ")", ")", "\n", "cropped", "=", "F", ".", "crop_clip", "(", "clip", ",", "y1", ",", "x1", ",", "h", ",", "w", ")", "\n", "\n", "return", "cropped", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.transforms.video_transform.ColorJitter.__init__": [[473, 478], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "brightness", "=", "0", ",", "contrast", "=", "0", ",", "saturation", "=", "0", ",", "hue", "=", "0", ")", ":", "\n", "        ", "self", ".", "brightness", "=", "brightness", "\n", "self", ".", "contrast", "=", "contrast", "\n", "self", ".", "saturation", "=", "saturation", "\n", "self", ".", "hue", "=", "hue", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.transforms.video_transform.ColorJitter.get_params": [[479, 503], ["random.uniform", "random.uniform", "random.uniform", "random.uniform", "max", "max", "max"], "methods", ["None"], ["", "def", "get_params", "(", "self", ",", "brightness", ",", "contrast", ",", "saturation", ",", "hue", ")", ":", "\n", "        ", "if", "brightness", ">", "0", ":", "\n", "            ", "brightness_factor", "=", "random", ".", "uniform", "(", "\n", "max", "(", "0", ",", "1", "-", "brightness", ")", ",", "1", "+", "brightness", ")", "\n", "", "else", ":", "\n", "            ", "brightness_factor", "=", "None", "\n", "\n", "", "if", "contrast", ">", "0", ":", "\n", "            ", "contrast_factor", "=", "random", ".", "uniform", "(", "\n", "max", "(", "0", ",", "1", "-", "contrast", ")", ",", "1", "+", "contrast", ")", "\n", "", "else", ":", "\n", "            ", "contrast_factor", "=", "None", "\n", "\n", "", "if", "saturation", ">", "0", ":", "\n", "            ", "saturation_factor", "=", "random", ".", "uniform", "(", "\n", "max", "(", "0", ",", "1", "-", "saturation", ")", ",", "1", "+", "saturation", ")", "\n", "", "else", ":", "\n", "            ", "saturation_factor", "=", "None", "\n", "\n", "", "if", "hue", ">", "0", ":", "\n", "            ", "hue_factor", "=", "random", ".", "uniform", "(", "-", "hue", ",", "hue", ")", "\n", "", "else", ":", "\n", "            ", "hue_factor", "=", "None", "\n", "", "return", "brightness_factor", ",", "contrast_factor", ",", "saturation_factor", ",", "hue_factor", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.transforms.video_transform.ColorJitter.__call__": [[504, 541], ["isinstance", "TypeError", "isinstance", "video_transform.ColorJitter.get_params", "random.shuffle", "TypeError", "img_transforms.append", "img_transforms.append", "img_transforms.append", "img_transforms.append", "jittered_clip.append", "func", "torchvision.transforms.functional.adjust_brightness", "torchvision.transforms.functional.adjust_saturation", "torchvision.transforms.functional.adjust_hue", "torchvision.transforms.functional.adjust_contrast", "type"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.transforms.video_transform.EachColorJitter.get_params"], ["", "def", "__call__", "(", "self", ",", "clip", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n        clip_test (list): list of PIL.Image\n        Returns:\n        list PIL.Image : list of transformed PIL.Image\n        \"\"\"", "\n", "if", "isinstance", "(", "clip", "[", "0", "]", ",", "np", ".", "ndarray", ")", ":", "\n", "            ", "raise", "TypeError", "(", "\n", "'Color jitter not yet implemented for numpy arrays'", ")", "\n", "", "elif", "isinstance", "(", "clip", "[", "0", "]", ",", "PIL", ".", "Image", ".", "Image", ")", ":", "\n", "            ", "brightness", ",", "contrast", ",", "saturation", ",", "hue", "=", "self", ".", "get_params", "(", "\n", "self", ".", "brightness", ",", "self", ".", "contrast", ",", "self", ".", "saturation", ",", "self", ".", "hue", ")", "\n", "\n", "# Create img sync_dir function sequence", "\n", "img_transforms", "=", "[", "]", "\n", "if", "brightness", "is", "not", "None", ":", "\n", "                ", "img_transforms", ".", "append", "(", "lambda", "img", ":", "torchvision", ".", "transforms", ".", "functional", ".", "adjust_brightness", "(", "img", ",", "brightness", ")", ")", "\n", "", "if", "saturation", "is", "not", "None", ":", "\n", "                ", "img_transforms", ".", "append", "(", "lambda", "img", ":", "torchvision", ".", "transforms", ".", "functional", ".", "adjust_saturation", "(", "img", ",", "saturation", ")", ")", "\n", "", "if", "hue", "is", "not", "None", ":", "\n", "                ", "img_transforms", ".", "append", "(", "lambda", "img", ":", "torchvision", ".", "transforms", ".", "functional", ".", "adjust_hue", "(", "img", ",", "hue", ")", ")", "\n", "", "if", "contrast", "is", "not", "None", ":", "\n", "                ", "img_transforms", ".", "append", "(", "lambda", "img", ":", "torchvision", ".", "transforms", ".", "functional", ".", "adjust_contrast", "(", "img", ",", "contrast", ")", ")", "\n", "", "random", ".", "shuffle", "(", "img_transforms", ")", "\n", "\n", "# Apply to all images", "\n", "jittered_clip", "=", "[", "]", "\n", "for", "img", "in", "clip", ":", "\n", "                ", "for", "func", "in", "img_transforms", ":", "\n", "                    ", "jittered_img", "=", "func", "(", "img", ")", "\n", "", "jittered_clip", ".", "append", "(", "jittered_img", ")", "\n", "\n", "", "", "else", ":", "\n", "            ", "raise", "TypeError", "(", "'Expected numpy.ndarray or PIL.Image'", "+", "\n", "'but got list of {0}'", ".", "format", "(", "type", "(", "clip", "[", "0", "]", ")", ")", ")", "\n", "", "return", "jittered_clip", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.transforms.video_transform.EachColorJitter.__init__": [[556, 561], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "brightness", "=", "0", ",", "contrast", "=", "0", ",", "saturation", "=", "0", ",", "hue", "=", "0", ")", ":", "\n", "        ", "self", ".", "brightness", "=", "brightness", "\n", "self", ".", "contrast", "=", "contrast", "\n", "self", ".", "saturation", "=", "saturation", "\n", "self", ".", "hue", "=", "hue", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.transforms.video_transform.EachColorJitter.get_params": [[562, 586], ["random.uniform", "random.uniform", "random.uniform", "random.uniform", "max", "max", "max"], "methods", ["None"], ["", "def", "get_params", "(", "self", ",", "brightness", ",", "contrast", ",", "saturation", ",", "hue", ")", ":", "\n", "        ", "if", "brightness", ">", "0", ":", "\n", "            ", "brightness_factor", "=", "random", ".", "uniform", "(", "\n", "max", "(", "0", ",", "1", "-", "brightness", ")", ",", "1", "+", "brightness", ")", "\n", "", "else", ":", "\n", "            ", "brightness_factor", "=", "None", "\n", "\n", "", "if", "contrast", ">", "0", ":", "\n", "            ", "contrast_factor", "=", "random", ".", "uniform", "(", "\n", "max", "(", "0", ",", "1", "-", "contrast", ")", ",", "1", "+", "contrast", ")", "\n", "", "else", ":", "\n", "            ", "contrast_factor", "=", "None", "\n", "\n", "", "if", "saturation", ">", "0", ":", "\n", "            ", "saturation_factor", "=", "random", ".", "uniform", "(", "\n", "max", "(", "0", ",", "1", "-", "saturation", ")", ",", "1", "+", "saturation", ")", "\n", "", "else", ":", "\n", "            ", "saturation_factor", "=", "None", "\n", "\n", "", "if", "hue", ">", "0", ":", "\n", "            ", "hue_factor", "=", "random", ".", "uniform", "(", "-", "hue", ",", "hue", ")", "\n", "", "else", ":", "\n", "            ", "hue_factor", "=", "None", "\n", "", "return", "brightness_factor", ",", "contrast_factor", ",", "saturation_factor", ",", "hue_factor", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.transforms.video_transform.EachColorJitter.__call__": [[587, 624], ["isinstance", "TypeError", "isinstance", "video_transform.EachColorJitter.get_params", "random.shuffle", "TypeError", "img_transforms.append", "img_transforms.append", "img_transforms.append", "img_transforms.append", "jittered_clip.append", "func", "torchvision.transforms.functional.adjust_brightness", "torchvision.transforms.functional.adjust_saturation", "torchvision.transforms.functional.adjust_hue", "torchvision.transforms.functional.adjust_contrast", "type"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.transforms.video_transform.EachColorJitter.get_params"], ["", "def", "__call__", "(", "self", ",", "clip", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n        clip_test (list): list of PIL.Image\n        Returns:\n        list PIL.Image : list of transformed PIL.Image\n        \"\"\"", "\n", "if", "isinstance", "(", "clip", "[", "0", "]", ",", "np", ".", "ndarray", ")", ":", "\n", "            ", "raise", "TypeError", "(", "\n", "'Color jitter not yet implemented for numpy arrays'", ")", "\n", "", "elif", "isinstance", "(", "clip", "[", "0", "]", ",", "PIL", ".", "Image", ".", "Image", ")", ":", "\n", "            ", "brightness", ",", "contrast", ",", "saturation", ",", "hue", "=", "self", ".", "get_params", "(", "\n", "self", ".", "brightness", ",", "self", ".", "contrast", ",", "self", ".", "saturation", ",", "self", ".", "hue", ")", "\n", "\n", "# Create img sync_dir function sequence", "\n", "img_transforms", "=", "[", "]", "\n", "if", "brightness", "is", "not", "None", ":", "\n", "                ", "img_transforms", ".", "append", "(", "lambda", "img", ":", "torchvision", ".", "transforms", ".", "functional", ".", "adjust_brightness", "(", "img", ",", "brightness", ")", ")", "\n", "", "if", "saturation", "is", "not", "None", ":", "\n", "                ", "img_transforms", ".", "append", "(", "lambda", "img", ":", "torchvision", ".", "transforms", ".", "functional", ".", "adjust_saturation", "(", "img", ",", "saturation", ")", ")", "\n", "", "if", "hue", "is", "not", "None", ":", "\n", "                ", "img_transforms", ".", "append", "(", "lambda", "img", ":", "torchvision", ".", "transforms", ".", "functional", ".", "adjust_hue", "(", "img", ",", "hue", ")", ")", "\n", "", "if", "contrast", "is", "not", "None", ":", "\n", "                ", "img_transforms", ".", "append", "(", "lambda", "img", ":", "torchvision", ".", "transforms", ".", "functional", ".", "adjust_contrast", "(", "img", ",", "contrast", ")", ")", "\n", "", "random", ".", "shuffle", "(", "img_transforms", ")", "\n", "\n", "# Apply to all images", "\n", "jittered_clip", "=", "[", "]", "\n", "for", "img", "in", "clip", ":", "\n", "                ", "for", "func", "in", "img_transforms", ":", "\n", "                    ", "jittered_img", "=", "func", "(", "img", ")", "\n", "", "jittered_clip", ".", "append", "(", "jittered_img", ")", "\n", "\n", "", "", "else", ":", "\n", "            ", "raise", "TypeError", "(", "'Expected numpy.ndarray or PIL.Image'", "+", "\n", "'but got list of {0}'", ".", "format", "(", "type", "(", "clip", "[", "0", "]", ")", ")", ")", "\n", "", "return", "jittered_clip", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.transforms.video_transform.Normalize.__init__": [[638, 641], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "mean", ",", "std", ")", ":", "\n", "        ", "self", ".", "mean", "=", "mean", "\n", "self", ".", "std", "=", "std", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.transforms.video_transform.Normalize.__call__": [[642, 650], ["functional.normalize"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.transforms.functional.normalize"], ["", "def", "__call__", "(", "self", ",", "clip", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            clip (Tensor): Tensor clip_test of size (T, C, H, W) to be normalized.\n        Returns:\n            Tensor: Normalized Tensor clip_test.\n        \"\"\"", "\n", "return", "F", ".", "normalize", "(", "clip", ",", "self", ".", "mean", ",", "self", ".", "std", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.transforms.video_transform.Normalize.__repr__": [[651, 653], ["None"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "__class__", ".", "__name__", "+", "'(mean={0}, std={1})'", ".", "format", "(", "self", ".", "mean", ",", "self", ".", "std", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.transforms.video_transform.TensorToNumpy.__init__": [[657, 659], ["print"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "print", "(", "\"convert to numpy\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.transforms.video_transform.TensorToNumpy.__call__": [[660, 664], ["clip.permute().cpu().detach().numpy", "PIL.Image.fromarray().convert", "clip.permute().cpu().detach", "PIL.Image.fromarray", "clip.permute().cpu", "numpy.uint8", "clip.permute"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "clip", ")", ":", "\n", "        ", "np_clip", "=", "clip", ".", "permute", "(", "1", ",", "2", ",", "3", ",", "0", ")", ".", "cpu", "(", ")", ".", "detach", "(", ")", ".", "numpy", "(", ")", "\n", "pil_clip", "=", "[", "Image", ".", "fromarray", "(", "np", ".", "uint8", "(", "numpy_image", ")", ")", ".", "convert", "(", "'RGB'", ")", "for", "numpy_image", "in", "np_clip", "]", "\n", "return", "pil_clip", "\n", "", "", ""]], "home.repos.pwc.inspect_result.showlab_all-in-one.transforms.video_transform.convert_img": [[14, 22], ["len", "np.expand_dims.transpose", "len", "numpy.expand_dims"], "function", ["None"], ["def", "convert_img", "(", "img", ")", ":", "\n", "    ", "\"\"\"Converts (H, W, C) numpy.ndarray to (C, W, H) format\n    \"\"\"", "\n", "if", "len", "(", "img", ".", "shape", ")", "==", "3", ":", "\n", "        ", "img", "=", "img", ".", "transpose", "(", "2", ",", "0", ",", "1", ")", "\n", "", "if", "len", "(", "img", ".", "shape", ")", "==", "2", ":", "\n", "        ", "img", "=", "np", ".", "expand_dims", "(", "img", ",", "0", ")", "\n", "", "return", "img", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.transforms.videoaug.VideoTransform": [[2, 35], ["print", "video_transforms.create_video_transform", "transforms.Compose", "transforms.Compose", "int", "int", "video_transform.TensorToNumpy", "video_transform.Resize", "video_transform.RandomCrop", "video_transform.ClipToTensor", "video_transform.Normalize", "video_transform.TensorToNumpy", "video_transform.Resize", "video_transform.CenterCrop", "video_transform.ClipToTensor", "video_transform.Normalize", "int", "int"], "function", ["None"], ["def", "VideoTransform", "(", "mode", "=", "'train'", ",", "crop_size", "=", "224", ",", "backend", "=", "'v100'", ")", ":", "\n", "    ", "if", "backend", "==", "'a100'", ":", "\n", "        ", "print", "(", "\"initalize data augmentation for a100 gpus\"", ")", "\n", "import", "CoTrain", ".", "transforms", ".", "video", ".", "video_transform", "as", "video_transform", "\n", "from", "torchvision", "import", "transforms", "\n", "# https://github.com/FingerRec/BE/blob/main/src/Contrastive/augment/video_transformations/volume_transforms.py", "\n", "if", "mode", "==", "'train'", ":", "\n", "            ", "global_transforms", "=", "transforms", ".", "Compose", "(", "[", "\n", "video_transform", ".", "TensorToNumpy", "(", ")", ",", "\n", "video_transform", ".", "Resize", "(", "int", "(", "crop_size", "*", "1.2", ")", ")", ",", "# 256/224 = 1.14", "\n", "video_transform", ".", "RandomCrop", "(", "crop_size", ")", ",", "\n", "# video_transform.ColorJitter(0.5, 0.5, 0.25, 0.5),  # color operation perimitted, damage attribute", "\n", "video_transform", ".", "ClipToTensor", "(", "channel_nb", "=", "3", ")", ",", "\n", "video_transform", ".", "Normalize", "(", "mean", "=", "[", "0.485", ",", "0.456", ",", "0.406", "]", ",", "std", "=", "[", "0.229", ",", "0.224", ",", "0.225", "]", ")", "\n", "]", ")", "\n", "local_transforms", "=", "transforms", ".", "Compose", "(", "[", "\n", "video_transform", ".", "TensorToNumpy", "(", ")", ",", "\n", "video_transform", ".", "Resize", "(", "crop_size", ")", ",", "# 256/224 = 1.14", "\n", "video_transform", ".", "RandomCrop", "(", "96", ")", ",", "\n", "# video_transform.ColorJitter(0.5, 0.5, 0.25, 0.5),  # color operation perimitted, damage attribute", "\n", "video_transform", ".", "ClipToTensor", "(", "channel_nb", "=", "3", ")", ",", "\n", "video_transform", ".", "Normalize", "(", "mean", "=", "[", "0.485", ",", "0.456", ",", "0.406", "]", ",", "std", "=", "[", "0.229", ",", "0.224", ",", "0.225", "]", ")", "\n", "]", ")", "\n", "", "else", ":", "\n", "            ", "global_transforms", "=", "transforms", ".", "Compose", "(", "[", "\n", "video_transform", ".", "TensorToNumpy", "(", ")", ",", "\n", "video_transform", ".", "Resize", "(", "int", "(", "crop_size", "*", "1.2", ")", ")", ",", "# 256", "\n", "video_transform", ".", "CenterCrop", "(", "crop_size", ")", ",", "# 224", "\n", "video_transform", ".", "ClipToTensor", "(", "channel_nb", "=", "3", ")", ",", "\n", "video_transform", ".", "Normalize", "(", "mean", "=", "[", "0.485", ",", "0.456", ",", "0.406", "]", ",", "std", "=", "[", "0.229", ",", "0.224", ",", "0.225", "]", ")", "\n", "]", ")", "\n", "local_transforms", "=", "transforms", ".", "Compose", "(", "[", "\n", "video_transform", ".", "TensorToNumpy", "(", ")", ",", "\n", "video_transform", ".", "Resize", "(", "crop_size", ")", ",", "# 256", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.transforms.functional._is_tensor_clip": [[8, 10], ["torch.is_tensor", "clip.ndimension"], "function", ["None"], ["def", "_is_tensor_clip", "(", "clip", ")", ":", "\n", "    ", "return", "torch", ".", "is_tensor", "(", "clip", ")", "and", "clip", ".", "ndimension", "(", ")", "==", "4", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.transforms.functional.crop_clip": [[12, 24], ["isinstance", "isinstance", "TypeError", "img.crop", "type"], "function", ["None"], ["", "def", "crop_clip", "(", "clip", ",", "min_h", ",", "min_w", ",", "h", ",", "w", ")", ":", "\n", "    ", "if", "isinstance", "(", "clip", "[", "0", "]", ",", "np", ".", "ndarray", ")", ":", "\n", "        ", "cropped", "=", "[", "img", "[", "min_h", ":", "min_h", "+", "h", ",", "min_w", ":", "min_w", "+", "w", ",", ":", "]", "for", "img", "in", "clip", "]", "\n", "\n", "", "elif", "isinstance", "(", "clip", "[", "0", "]", ",", "PIL", ".", "Image", ".", "Image", ")", ":", "\n", "        ", "cropped", "=", "[", "\n", "img", ".", "crop", "(", "(", "min_w", ",", "min_h", ",", "min_w", "+", "w", ",", "min_h", "+", "h", ")", ")", "for", "img", "in", "clip", "\n", "]", "\n", "", "else", ":", "\n", "        ", "raise", "TypeError", "(", "'Expected numpy.ndarray or PIL.Image'", "+", "\n", "'but got list of {0}'", ".", "format", "(", "type", "(", "clip", "[", "0", "]", ")", ")", ")", "\n", "", "return", "cropped", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.transforms.functional.resize_clip": [[26, 65], ["isinstance", "isinstance", "isinstance", "functional.get_resize_sizes", "cv2.resize", "isinstance", "TypeError", "functional.get_resize_sizes", "img.resize", "type"], "function", ["home.repos.pwc.inspect_result.showlab_all-in-one.transforms.functional.get_resize_sizes", "home.repos.pwc.inspect_result.showlab_all-in-one.transforms.functional.get_resize_sizes"], ["", "def", "resize_clip", "(", "clip", ",", "size", ",", "interpolation", "=", "'bilinear'", ")", ":", "\n", "    ", "if", "isinstance", "(", "clip", "[", "0", "]", ",", "np", ".", "ndarray", ")", ":", "\n", "        ", "if", "isinstance", "(", "size", ",", "numbers", ".", "Number", ")", ":", "\n", "            ", "im_h", ",", "im_w", ",", "im_c", "=", "clip", "[", "0", "]", ".", "shape", "\n", "# Min spatial dim already matches minimal size", "\n", "if", "(", "im_w", "<=", "im_h", "and", "im_w", "==", "size", ")", "or", "(", "im_h", "<=", "im_w", "\n", "and", "im_h", "==", "size", ")", ":", "\n", "                ", "return", "clip", "\n", "", "new_h", ",", "new_w", "=", "get_resize_sizes", "(", "im_h", ",", "im_w", ",", "size", ")", "\n", "size", "=", "(", "new_w", ",", "new_h", ")", "\n", "", "else", ":", "\n", "            ", "size", "=", "size", "[", "1", "]", ",", "size", "[", "0", "]", "\n", "", "if", "interpolation", "==", "'bilinear'", ":", "\n", "            ", "np_inter", "=", "cv2", ".", "INTER_LINEAR", "\n", "", "else", ":", "\n", "            ", "np_inter", "=", "cv2", ".", "INTER_NEAREST", "\n", "", "scaled", "=", "[", "\n", "cv2", ".", "resize", "(", "img", ",", "size", ",", "interpolation", "=", "np_inter", ")", "for", "img", "in", "clip", "\n", "]", "\n", "", "elif", "isinstance", "(", "clip", "[", "0", "]", ",", "PIL", ".", "Image", ".", "Image", ")", ":", "\n", "        ", "if", "isinstance", "(", "size", ",", "numbers", ".", "Number", ")", ":", "\n", "            ", "im_w", ",", "im_h", "=", "clip", "[", "0", "]", ".", "size", "\n", "# Min spatial dim already matches minimal size", "\n", "if", "(", "im_w", "<=", "im_h", "and", "im_w", "==", "size", ")", "or", "(", "im_h", "<=", "im_w", "\n", "and", "im_h", "==", "size", ")", ":", "\n", "                ", "return", "clip", "\n", "", "new_h", ",", "new_w", "=", "get_resize_sizes", "(", "im_h", ",", "im_w", ",", "size", ")", "\n", "size", "=", "(", "new_w", ",", "new_h", ")", "\n", "", "else", ":", "\n", "            ", "size", "=", "size", "[", "1", "]", ",", "size", "[", "0", "]", "\n", "", "if", "interpolation", "==", "'bilinear'", ":", "\n", "            ", "pil_inter", "=", "PIL", ".", "Image", ".", "NEAREST", "\n", "", "else", ":", "\n", "            ", "pil_inter", "=", "PIL", ".", "Image", ".", "BILINEAR", "\n", "", "scaled", "=", "[", "img", ".", "resize", "(", "size", ",", "pil_inter", ")", "for", "img", "in", "clip", "]", "\n", "", "else", ":", "\n", "        ", "raise", "TypeError", "(", "'Expected numpy.ndarray or PIL.Image'", "+", "\n", "'but got list of {0}'", ".", "format", "(", "type", "(", "clip", "[", "0", "]", ")", ")", ")", "\n", "", "return", "scaled", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.transforms.functional.get_resize_sizes": [[67, 75], ["int", "int"], "function", ["None"], ["", "def", "get_resize_sizes", "(", "im_h", ",", "im_w", ",", "size", ")", ":", "\n", "    ", "if", "im_w", "<", "im_h", ":", "\n", "        ", "ow", "=", "size", "\n", "oh", "=", "int", "(", "size", "*", "im_h", "/", "im_w", ")", "\n", "", "else", ":", "\n", "        ", "oh", "=", "size", "\n", "ow", "=", "int", "(", "size", "*", "im_w", "/", "im_h", ")", "\n", "", "return", "oh", ",", "ow", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.transforms.functional.normalize": [[77, 94], ["len", "torch.as_tensor", "torch.as_tensor", "clip.clone.sub_().div_", "functional._is_tensor_clip", "TypeError", "clip.clone.clone", "clip.clone.sub_"], "function", ["home.repos.pwc.inspect_result.showlab_all-in-one.transforms.functional._is_tensor_clip"], ["", "def", "normalize", "(", "clip", ",", "mean", ",", "std", ",", "inplace", "=", "False", ")", ":", "\n", "    ", "if", "not", "_is_tensor_clip", "(", "clip", ")", ":", "\n", "        ", "raise", "TypeError", "(", "'tensor is not a torch clip_test.'", ")", "\n", "\n", "", "if", "not", "inplace", ":", "\n", "        ", "clip", "=", "clip", ".", "clone", "(", ")", "\n", "\n", "", "dtype", "=", "clip", ".", "dtype", "\n", "dim", "=", "len", "(", "mean", ")", "\n", "mean", "=", "torch", ".", "as_tensor", "(", "mean", ",", "dtype", "=", "dtype", ",", "device", "=", "clip", ".", "device", ")", "\n", "std", "=", "torch", ".", "as_tensor", "(", "std", ",", "dtype", "=", "dtype", ",", "device", "=", "clip", ".", "device", ")", "\n", "# print(clip_test.size())", "\n", "# if dim == 3:", "\n", "clip", ".", "sub_", "(", "mean", "[", ":", ",", "None", ",", "None", ",", "None", "]", ")", ".", "div_", "(", "std", "[", ":", ",", "None", ",", "None", ",", "None", "]", ")", "\n", "# else:", "\n", "#     clip_test.sub_(mean[:, None, None]).div_(std[:, None, None])", "\n", "return", "clip", "", "", ""]], "home.repos.pwc.inspect_result.showlab_all-in-one.transforms.randaug.Lighting.__init__": [[209, 213], ["torch.Tensor", "torch.Tensor"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "alphastd", ",", "eigval", ",", "eigvec", ")", ":", "\n", "        ", "self", ".", "alphastd", "=", "alphastd", "\n", "self", ".", "eigval", "=", "torch", ".", "Tensor", "(", "eigval", ")", "\n", "self", ".", "eigvec", "=", "torch", ".", "Tensor", "(", "eigvec", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.transforms.randaug.Lighting.__call__": [[214, 229], ["img.new().resize_().normal_", "randaug.Lighting.eigvec.type_as().clone().mul().mul().sum().squeeze", "img.add", "randaug.Lighting.view().expand_as", "img.new().resize_", "randaug.Lighting.eigvec.type_as().clone().mul().mul().sum", "randaug.Lighting.view", "img.new", "randaug.Lighting.eigvec.type_as().clone().mul().mul", "randaug.Lighting.eigval.view().expand", "randaug.Lighting.eigvec.type_as().clone().mul", "img.new().resize_().normal_.view().expand", "randaug.Lighting.eigval.view", "randaug.Lighting.eigvec.type_as().clone", "img.new().resize_().normal_.view", "randaug.Lighting.eigvec.type_as"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "img", ")", ":", "\n", "        ", "if", "self", ".", "alphastd", "==", "0", ":", "\n", "            ", "return", "img", "\n", "\n", "", "alpha", "=", "img", ".", "new", "(", ")", ".", "resize_", "(", "3", ")", ".", "normal_", "(", "0", ",", "self", ".", "alphastd", ")", "\n", "rgb", "=", "(", "\n", "self", ".", "eigvec", ".", "type_as", "(", "img", ")", "\n", ".", "clone", "(", ")", "\n", ".", "mul", "(", "alpha", ".", "view", "(", "1", ",", "3", ")", ".", "expand", "(", "3", ",", "3", ")", ")", "\n", ".", "mul", "(", "self", ".", "eigval", ".", "view", "(", "1", ",", "3", ")", ".", "expand", "(", "3", ",", "3", ")", ")", "\n", ".", "sum", "(", "1", ")", "\n", ".", "squeeze", "(", ")", "\n", ")", "\n", "\n", "return", "img", ".", "add", "(", "rgb", ".", "view", "(", "3", ",", "1", ",", "1", ")", ".", "expand_as", "(", "img", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.transforms.randaug.CutoutDefault.__init__": [[236, 238], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "length", ")", ":", "\n", "        ", "self", ".", "length", "=", "length", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.transforms.randaug.CutoutDefault.__call__": [[239, 255], ["numpy.ones", "numpy.random.randint", "numpy.random.randint", "numpy.clip", "numpy.clip", "numpy.clip", "numpy.clip", "torch.from_numpy", "mask.expand_as.expand_as.expand_as", "img.size", "img.size"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "img", ")", ":", "\n", "        ", "h", ",", "w", "=", "img", ".", "size", "(", "1", ")", ",", "img", ".", "size", "(", "2", ")", "\n", "mask", "=", "np", ".", "ones", "(", "(", "h", ",", "w", ")", ",", "np", ".", "float32", ")", "\n", "y", "=", "np", ".", "random", ".", "randint", "(", "h", ")", "\n", "x", "=", "np", ".", "random", ".", "randint", "(", "w", ")", "\n", "\n", "y1", "=", "np", ".", "clip", "(", "y", "-", "self", ".", "length", "//", "2", ",", "0", ",", "h", ")", "\n", "y2", "=", "np", ".", "clip", "(", "y", "+", "self", ".", "length", "//", "2", ",", "0", ",", "h", ")", "\n", "x1", "=", "np", ".", "clip", "(", "x", "-", "self", ".", "length", "//", "2", ",", "0", ",", "w", ")", "\n", "x2", "=", "np", ".", "clip", "(", "x", "+", "self", ".", "length", "//", "2", ",", "0", ",", "w", ")", "\n", "\n", "mask", "[", "y1", ":", "y2", ",", "x1", ":", "x2", "]", "=", "0.0", "\n", "mask", "=", "torch", ".", "from_numpy", "(", "mask", ")", "\n", "mask", "=", "mask", ".", "expand_as", "(", "img", ")", "\n", "img", "*=", "mask", "\n", "return", "img", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.transforms.randaug.RandAugment.__init__": [[258, 262], ["randaug.augment_list"], "methods", ["home.repos.pwc.inspect_result.showlab_all-in-one.transforms.randaug.augment_list"], ["    ", "def", "__init__", "(", "self", ",", "n", ",", "m", ")", ":", "\n", "        ", "self", ".", "n", "=", "n", "\n", "self", ".", "m", "=", "m", "# [0, 30]", "\n", "self", ".", "augment_list", "=", "augment_list", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.transforms.randaug.RandAugment.__call__": [[263, 270], ["random.choices", "op", "float", "float"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "img", ")", ":", "\n", "        ", "ops", "=", "random", ".", "choices", "(", "self", ".", "augment_list", ",", "k", "=", "self", ".", "n", ")", "\n", "for", "op", ",", "minval", ",", "maxval", "in", "ops", ":", "\n", "            ", "val", "=", "(", "float", "(", "self", ".", "m", ")", "/", "30", ")", "*", "float", "(", "maxval", "-", "minval", ")", "+", "minval", "\n", "img", "=", "op", "(", "img", ",", "val", ")", "\n", "\n", "", "return", "img", "\n", "", "", ""]], "home.repos.pwc.inspect_result.showlab_all-in-one.transforms.randaug.ShearX": [[11, 16], ["img.transform", "random.random"], "function", ["None"], ["def", "ShearX", "(", "img", ",", "v", ")", ":", "# [-0.3, 0.3]", "\n", "    ", "assert", "-", "0.3", "<=", "v", "<=", "0.3", "\n", "if", "random", ".", "random", "(", ")", ">", "0.5", ":", "\n", "        ", "v", "=", "-", "v", "\n", "", "return", "img", ".", "transform", "(", "img", ".", "size", ",", "PIL", ".", "Image", ".", "AFFINE", ",", "(", "1", ",", "v", ",", "0", ",", "0", ",", "1", ",", "0", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.transforms.randaug.ShearY": [[18, 23], ["img.transform", "random.random"], "function", ["None"], ["", "def", "ShearY", "(", "img", ",", "v", ")", ":", "# [-0.3, 0.3]", "\n", "    ", "assert", "-", "0.3", "<=", "v", "<=", "0.3", "\n", "if", "random", ".", "random", "(", ")", ">", "0.5", ":", "\n", "        ", "v", "=", "-", "v", "\n", "", "return", "img", ".", "transform", "(", "img", ".", "size", ",", "PIL", ".", "Image", ".", "AFFINE", ",", "(", "1", ",", "0", ",", "0", ",", "v", ",", "1", ",", "0", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.transforms.randaug.TranslateX": [[25, 31], ["img.transform", "random.random"], "function", ["None"], ["", "def", "TranslateX", "(", "img", ",", "v", ")", ":", "# [-150, 150] => percentage: [-0.45, 0.45]", "\n", "    ", "assert", "-", "0.45", "<=", "v", "<=", "0.45", "\n", "if", "random", ".", "random", "(", ")", ">", "0.5", ":", "\n", "        ", "v", "=", "-", "v", "\n", "", "v", "=", "v", "*", "img", ".", "size", "[", "0", "]", "\n", "return", "img", ".", "transform", "(", "img", ".", "size", ",", "PIL", ".", "Image", ".", "AFFINE", ",", "(", "1", ",", "0", ",", "v", ",", "0", ",", "1", ",", "0", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.transforms.randaug.TranslateXabs": [[33, 38], ["img.transform", "random.random"], "function", ["None"], ["", "def", "TranslateXabs", "(", "img", ",", "v", ")", ":", "# [-150, 150] => percentage: [-0.45, 0.45]", "\n", "    ", "assert", "0", "<=", "v", "\n", "if", "random", ".", "random", "(", ")", ">", "0.5", ":", "\n", "        ", "v", "=", "-", "v", "\n", "", "return", "img", ".", "transform", "(", "img", ".", "size", ",", "PIL", ".", "Image", ".", "AFFINE", ",", "(", "1", ",", "0", ",", "v", ",", "0", ",", "1", ",", "0", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.transforms.randaug.TranslateY": [[40, 46], ["img.transform", "random.random"], "function", ["None"], ["", "def", "TranslateY", "(", "img", ",", "v", ")", ":", "# [-150, 150] => percentage: [-0.45, 0.45]", "\n", "    ", "assert", "-", "0.45", "<=", "v", "<=", "0.45", "\n", "if", "random", ".", "random", "(", ")", ">", "0.5", ":", "\n", "        ", "v", "=", "-", "v", "\n", "", "v", "=", "v", "*", "img", ".", "size", "[", "1", "]", "\n", "return", "img", ".", "transform", "(", "img", ".", "size", ",", "PIL", ".", "Image", ".", "AFFINE", ",", "(", "1", ",", "0", ",", "0", ",", "0", ",", "1", ",", "v", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.transforms.randaug.TranslateYabs": [[48, 53], ["img.transform", "random.random"], "function", ["None"], ["", "def", "TranslateYabs", "(", "img", ",", "v", ")", ":", "# [-150, 150] => percentage: [-0.45, 0.45]", "\n", "    ", "assert", "0", "<=", "v", "\n", "if", "random", ".", "random", "(", ")", ">", "0.5", ":", "\n", "        ", "v", "=", "-", "v", "\n", "", "return", "img", ".", "transform", "(", "img", ".", "size", ",", "PIL", ".", "Image", ".", "AFFINE", ",", "(", "1", ",", "0", ",", "0", ",", "0", ",", "1", ",", "v", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.transforms.randaug.Rotate": [[55, 60], ["img.rotate", "random.random"], "function", ["None"], ["", "def", "Rotate", "(", "img", ",", "v", ")", ":", "# [-30, 30]", "\n", "    ", "assert", "-", "30", "<=", "v", "<=", "30", "\n", "if", "random", ".", "random", "(", ")", ">", "0.5", ":", "\n", "        ", "v", "=", "-", "v", "\n", "", "return", "img", ".", "rotate", "(", "v", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.transforms.randaug.AutoContrast": [[62, 64], ["PIL.ImageOps.autocontrast", "PIL.ImageOps.autocontrast", "PIL.ImageOps.autocontrast", "PIL.ImageOps.autocontrast"], "function", ["None"], ["", "def", "AutoContrast", "(", "img", ",", "_", ")", ":", "\n", "    ", "return", "PIL", ".", "ImageOps", ".", "autocontrast", "(", "img", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.transforms.randaug.Invert": [[66, 68], ["PIL.ImageOps.invert", "PIL.ImageOps.invert", "PIL.ImageOps.invert", "PIL.ImageOps.invert"], "function", ["None"], ["", "def", "Invert", "(", "img", ",", "_", ")", ":", "\n", "    ", "return", "PIL", ".", "ImageOps", ".", "invert", "(", "img", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.transforms.randaug.Equalize": [[70, 72], ["PIL.ImageOps.equalize", "PIL.ImageOps.equalize", "PIL.ImageOps.equalize", "PIL.ImageOps.equalize"], "function", ["None"], ["", "def", "Equalize", "(", "img", ",", "_", ")", ":", "\n", "    ", "return", "PIL", ".", "ImageOps", ".", "equalize", "(", "img", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.transforms.randaug.Flip": [[74, 76], ["PIL.ImageOps.mirror", "PIL.ImageOps.mirror", "PIL.ImageOps.mirror", "PIL.ImageOps.mirror"], "function", ["None"], ["", "def", "Flip", "(", "img", ",", "_", ")", ":", "# not from the paper", "\n", "    ", "return", "PIL", ".", "ImageOps", ".", "mirror", "(", "img", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.transforms.randaug.Solarize": [[78, 81], ["PIL.ImageOps.solarize", "PIL.ImageOps.solarize", "PIL.ImageOps.solarize", "PIL.ImageOps.solarize"], "function", ["None"], ["", "def", "Solarize", "(", "img", ",", "v", ")", ":", "# [0, 256]", "\n", "    ", "assert", "0", "<=", "v", "<=", "256", "\n", "return", "PIL", ".", "ImageOps", ".", "solarize", "(", "img", ",", "v", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.transforms.randaug.SolarizeAdd": [[83, 90], ["numpy.array().astype", "numpy.clip", "img_np.astype.astype", "PIL.Image.fromarray", "PIL.ImageOps.solarize", "PIL.ImageOps.solarize", "PIL.ImageOps.solarize", "PIL.ImageOps.solarize", "numpy.array"], "function", ["None"], ["", "def", "SolarizeAdd", "(", "img", ",", "addition", "=", "0", ",", "threshold", "=", "128", ")", ":", "\n", "    ", "img_np", "=", "np", ".", "array", "(", "img", ")", ".", "astype", "(", "np", ".", "int", ")", "\n", "img_np", "=", "img_np", "+", "addition", "\n", "img_np", "=", "np", ".", "clip", "(", "img_np", ",", "0", ",", "255", ")", "\n", "img_np", "=", "img_np", ".", "astype", "(", "np", ".", "uint8", ")", "\n", "img", "=", "Image", ".", "fromarray", "(", "img_np", ")", "\n", "return", "PIL", ".", "ImageOps", ".", "solarize", "(", "img", ",", "threshold", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.transforms.randaug.Posterize": [[92, 96], ["int", "max", "PIL.ImageOps.posterize", "PIL.ImageOps.posterize", "PIL.ImageOps.posterize", "PIL.ImageOps.posterize"], "function", ["None"], ["", "def", "Posterize", "(", "img", ",", "v", ")", ":", "# [4, 8]", "\n", "    ", "v", "=", "int", "(", "v", ")", "\n", "v", "=", "max", "(", "1", ",", "v", ")", "\n", "return", "PIL", ".", "ImageOps", ".", "posterize", "(", "img", ",", "v", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.transforms.randaug.Contrast": [[98, 101], ["PIL.ImageEnhance.Contrast().enhance", "PIL.ImageEnhance.Contrast().enhance", "PIL.ImageEnhance.Contrast().enhance", "PIL.ImageEnhance.Contrast().enhance", "PIL.ImageEnhance.Contrast", "PIL.ImageEnhance.Contrast", "PIL.ImageEnhance.Contrast", "PIL.ImageEnhance.Contrast"], "function", ["home.repos.pwc.inspect_result.showlab_all-in-one.transforms.randaug.Contrast", "home.repos.pwc.inspect_result.showlab_all-in-one.transforms.randaug.Contrast", "home.repos.pwc.inspect_result.showlab_all-in-one.transforms.randaug.Contrast", "home.repos.pwc.inspect_result.showlab_all-in-one.transforms.randaug.Contrast"], ["", "def", "Contrast", "(", "img", ",", "v", ")", ":", "# [0.1,1.9]", "\n", "    ", "assert", "0.1", "<=", "v", "<=", "1.9", "\n", "return", "PIL", ".", "ImageEnhance", ".", "Contrast", "(", "img", ")", ".", "enhance", "(", "v", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.transforms.randaug.Color": [[103, 106], ["PIL.ImageEnhance.Color().enhance", "PIL.ImageEnhance.Color().enhance", "PIL.ImageEnhance.Color().enhance", "PIL.ImageEnhance.Color().enhance", "PIL.ImageEnhance.Color", "PIL.ImageEnhance.Color", "PIL.ImageEnhance.Color", "PIL.ImageEnhance.Color"], "function", ["home.repos.pwc.inspect_result.showlab_all-in-one.transforms.randaug.Color", "home.repos.pwc.inspect_result.showlab_all-in-one.transforms.randaug.Color", "home.repos.pwc.inspect_result.showlab_all-in-one.transforms.randaug.Color", "home.repos.pwc.inspect_result.showlab_all-in-one.transforms.randaug.Color"], ["", "def", "Color", "(", "img", ",", "v", ")", ":", "# [0.1,1.9]", "\n", "    ", "assert", "0.1", "<=", "v", "<=", "1.9", "\n", "return", "PIL", ".", "ImageEnhance", ".", "Color", "(", "img", ")", ".", "enhance", "(", "v", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.transforms.randaug.Brightness": [[108, 111], ["PIL.ImageEnhance.Brightness().enhance", "PIL.ImageEnhance.Brightness().enhance", "PIL.ImageEnhance.Brightness().enhance", "PIL.ImageEnhance.Brightness().enhance", "PIL.ImageEnhance.Brightness", "PIL.ImageEnhance.Brightness", "PIL.ImageEnhance.Brightness", "PIL.ImageEnhance.Brightness"], "function", ["home.repos.pwc.inspect_result.showlab_all-in-one.transforms.randaug.Brightness", "home.repos.pwc.inspect_result.showlab_all-in-one.transforms.randaug.Brightness", "home.repos.pwc.inspect_result.showlab_all-in-one.transforms.randaug.Brightness", "home.repos.pwc.inspect_result.showlab_all-in-one.transforms.randaug.Brightness"], ["", "def", "Brightness", "(", "img", ",", "v", ")", ":", "# [0.1,1.9]", "\n", "    ", "assert", "0.1", "<=", "v", "<=", "1.9", "\n", "return", "PIL", ".", "ImageEnhance", ".", "Brightness", "(", "img", ")", ".", "enhance", "(", "v", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.transforms.randaug.Sharpness": [[113, 116], ["PIL.ImageEnhance.Sharpness().enhance", "PIL.ImageEnhance.Sharpness().enhance", "PIL.ImageEnhance.Sharpness().enhance", "PIL.ImageEnhance.Sharpness().enhance", "PIL.ImageEnhance.Sharpness", "PIL.ImageEnhance.Sharpness", "PIL.ImageEnhance.Sharpness", "PIL.ImageEnhance.Sharpness"], "function", ["home.repos.pwc.inspect_result.showlab_all-in-one.transforms.randaug.Sharpness", "home.repos.pwc.inspect_result.showlab_all-in-one.transforms.randaug.Sharpness", "home.repos.pwc.inspect_result.showlab_all-in-one.transforms.randaug.Sharpness", "home.repos.pwc.inspect_result.showlab_all-in-one.transforms.randaug.Sharpness"], ["", "def", "Sharpness", "(", "img", ",", "v", ")", ":", "# [0.1,1.9]", "\n", "    ", "assert", "0.1", "<=", "v", "<=", "1.9", "\n", "return", "PIL", ".", "ImageEnhance", ".", "Sharpness", "(", "img", ")", ".", "enhance", "(", "v", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.transforms.randaug.Cutout": [[118, 125], ["randaug.CutoutAbs"], "function", ["home.repos.pwc.inspect_result.showlab_all-in-one.transforms.randaug.CutoutAbs"], ["", "def", "Cutout", "(", "img", ",", "v", ")", ":", "# [0, 60] => percentage: [0, 0.2]", "\n", "    ", "assert", "0.0", "<=", "v", "<=", "0.2", "\n", "if", "v", "<=", "0.0", ":", "\n", "        ", "return", "img", "\n", "\n", "", "v", "=", "v", "*", "img", ".", "size", "[", "0", "]", "\n", "return", "CutoutAbs", "(", "img", ",", "v", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.transforms.randaug.CutoutAbs": [[127, 146], ["numpy.random.uniform", "numpy.random.uniform", "int", "int", "min", "min", "img.copy.copy", "PIL.ImageDraw.Draw().rectangle", "PIL.ImageDraw.Draw().rectangle", "PIL.ImageDraw.Draw().rectangle", "PIL.ImageDraw.Draw().rectangle", "max", "max", "PIL.ImageDraw.Draw", "PIL.ImageDraw.Draw", "PIL.ImageDraw.Draw", "PIL.ImageDraw.Draw"], "function", ["None"], ["", "def", "CutoutAbs", "(", "img", ",", "v", ")", ":", "# [0, 60] => percentage: [0, 0.2]", "\n", "# assert 0 <= v <= 20", "\n", "    ", "if", "v", "<", "0", ":", "\n", "        ", "return", "img", "\n", "", "w", ",", "h", "=", "img", ".", "size", "\n", "x0", "=", "np", ".", "random", ".", "uniform", "(", "w", ")", "\n", "y0", "=", "np", ".", "random", ".", "uniform", "(", "h", ")", "\n", "\n", "x0", "=", "int", "(", "max", "(", "0", ",", "x0", "-", "v", "/", "2.0", ")", ")", "\n", "y0", "=", "int", "(", "max", "(", "0", ",", "y0", "-", "v", "/", "2.0", ")", ")", "\n", "x1", "=", "min", "(", "w", ",", "x0", "+", "v", ")", "\n", "y1", "=", "min", "(", "h", ",", "y0", "+", "v", ")", "\n", "\n", "xy", "=", "(", "x0", ",", "y0", ",", "x1", ",", "y1", ")", "\n", "color", "=", "(", "125", ",", "123", ",", "114", ")", "\n", "# color = (0, 0, 0)", "\n", "img", "=", "img", ".", "copy", "(", ")", "\n", "PIL", ".", "ImageDraw", ".", "Draw", "(", "img", ")", ".", "rectangle", "(", "xy", ",", "color", ")", "\n", "return", "img", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.transforms.randaug.SamplePairing": [[148, 155], ["numpy.random.choice", "PIL.Image.fromarray", "PIL.Image.fromarray", "PIL.Image.fromarray", "PIL.Image.fromarray", "PIL.Image.blend", "PIL.Image.blend", "PIL.Image.blend", "PIL.Image.blend", "len"], "function", ["None"], ["", "def", "SamplePairing", "(", "imgs", ")", ":", "# [0, 0.4]", "\n", "    ", "def", "f", "(", "img1", ",", "v", ")", ":", "\n", "        ", "i", "=", "np", ".", "random", ".", "choice", "(", "len", "(", "imgs", ")", ")", "\n", "img2", "=", "PIL", ".", "Image", ".", "fromarray", "(", "imgs", "[", "i", "]", ")", "\n", "return", "PIL", ".", "Image", ".", "blend", "(", "img1", ",", "img2", ",", "v", ")", "\n", "\n", "", "return", "f", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.transforms.randaug.Identity": [[157, 159], ["None"], "function", ["None"], ["", "def", "Identity", "(", "img", ",", "v", ")", ":", "\n", "    ", "return", "img", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.transforms.randaug.augment_list": [[161, 204], ["None"], "function", ["None"], ["", "def", "augment_list", "(", ")", ":", "# 16 oeprations and their ranges", "\n", "# https://github.com/google-research/uda/blob/master/image/randaugment/policies.py#L57", "\n", "# l = [", "\n", "#     (Identity, 0., 1.0),", "\n", "#     (ShearX, 0., 0.3),  # 0", "\n", "#     (ShearY, 0., 0.3),  # 1", "\n", "#     (TranslateX, 0., 0.33),  # 2", "\n", "#     (TranslateY, 0., 0.33),  # 3", "\n", "#     (Rotate, 0, 30),  # 4", "\n", "#     (AutoContrast, 0, 1),  # 5", "\n", "#     (Invert, 0, 1),  # 6", "\n", "#     (Equalize, 0, 1),  # 7", "\n", "#     (Solarize, 0, 110),  # 8", "\n", "#     (Posterize, 4, 8),  # 9", "\n", "#     # (Contrast, 0.1, 1.9),  # 10", "\n", "#     (Color, 0.1, 1.9),  # 11", "\n", "#     (Brightness, 0.1, 1.9),  # 12", "\n", "#     (Sharpness, 0.1, 1.9),  # 13", "\n", "#     # (Cutout, 0, 0.2),  # 14", "\n", "#     # (SamplePairing(imgs), 0, 0.4),  # 15", "\n", "# ]", "\n", "\n", "# https://github.com/tensorflow/tpu/blob/8462d083dd89489a79e3200bcc8d4063bf362186/models/official/efficientnet/autoaugment.py#L505", "\n", "    ", "l", "=", "[", "\n", "(", "AutoContrast", ",", "0", ",", "1", ")", ",", "\n", "(", "Equalize", ",", "0", ",", "1", ")", ",", "\n", "# (Invert, 0, 1),", "\n", "(", "Rotate", ",", "0", ",", "30", ")", ",", "\n", "(", "Posterize", ",", "0", ",", "4", ")", ",", "\n", "(", "Solarize", ",", "0", ",", "256", ")", ",", "\n", "(", "SolarizeAdd", ",", "0", ",", "110", ")", ",", "\n", "(", "Color", ",", "0.1", ",", "1.9", ")", ",", "\n", "(", "Contrast", ",", "0.1", ",", "1.9", ")", ",", "\n", "(", "Brightness", ",", "0.1", ",", "1.9", ")", ",", "\n", "(", "Sharpness", ",", "0.1", ",", "1.9", ")", ",", "\n", "(", "ShearX", ",", "0.0", ",", "0.3", ")", ",", "\n", "(", "ShearY", ",", "0.0", ",", "0.3", ")", ",", "\n", "# (CutoutAbs, 0, 40),", "\n", "(", "TranslateXabs", ",", "0.0", ",", "100", ")", ",", "\n", "(", "TranslateYabs", ",", "0.0", ",", "100", ")", ",", "\n", "]", "\n", "\n", "return", "l", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.transforms.utils.MinMaxResize.__init__": [[6, 9], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "shorter", "=", "800", ",", "longer", "=", "1333", ")", ":", "\n", "        ", "self", ".", "min", "=", "shorter", "\n", "self", ".", "max", "=", "longer", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.transforms.utils.MinMaxResize.__call__": [[10, 27], ["x.resize", "min", "max", "int", "int", "max"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "x", ")", ":", "\n", "        ", "w", ",", "h", "=", "x", ".", "size", "\n", "scale", "=", "self", ".", "min", "/", "min", "(", "w", ",", "h", ")", "\n", "if", "h", "<", "w", ":", "\n", "            ", "newh", ",", "neww", "=", "self", ".", "min", ",", "scale", "*", "w", "\n", "", "else", ":", "\n", "            ", "newh", ",", "neww", "=", "scale", "*", "h", ",", "self", ".", "min", "\n", "\n", "", "if", "max", "(", "newh", ",", "neww", ")", ">", "self", ".", "max", ":", "\n", "            ", "scale", "=", "self", ".", "max", "/", "max", "(", "newh", ",", "neww", ")", "\n", "newh", "=", "newh", "*", "scale", "\n", "neww", "=", "neww", "*", "scale", "\n", "\n", "", "newh", ",", "neww", "=", "int", "(", "newh", "+", "0.5", ")", ",", "int", "(", "neww", "+", "0.5", ")", "\n", "newh", ",", "neww", "=", "newh", "//", "32", "*", "32", ",", "neww", "//", "32", "*", "32", "\n", "\n", "return", "x", ".", "resize", "(", "(", "neww", ",", "newh", ")", ",", "resample", "=", "Image", ".", "BICUBIC", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.transforms.utils.UnNormalize.__init__": [[30, 33], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "mean", ",", "std", ")", ":", "\n", "        ", "self", ".", "mean", "=", "mean", "\n", "self", ".", "std", "=", "std", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.transforms.utils.UnNormalize.__call__": [[34, 45], ["zip", "t.mul_().add_", "t.mul_"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "tensor", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            tensor (Tensor): Tensor image of size (C, H, W) to be normalized.\n        Returns:\n            Tensor: Normalized image.\n        \"\"\"", "\n", "for", "t", ",", "m", ",", "s", "in", "zip", "(", "tensor", ",", "self", ".", "mean", ",", "self", ".", "std", ")", ":", "\n", "            ", "t", ".", "mul_", "(", "s", ")", ".", "add_", "(", "m", ")", "\n", "# The normalize code -> t.sub_(m).div_(s)", "\n", "", "return", "tensor", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.AllInOne.config._loss_names": [[6, 27], ["ret.update"], "function", ["home.repos.pwc.inspect_result.showlab_all-in-one.gadgets.my_metrics.VQAScore.update"], ["def", "_loss_names", "(", "d", ")", ":", "\n", "    ", "ret", "=", "{", "\n", "# pretrain", "\n", "\"vtm\"", ":", "0", ",", "\n", "\"mlm\"", ":", "0", ",", "\n", "\"mpp\"", ":", "0", ",", "\n", "\"vtc\"", ":", "0", ",", "\n", "\"vcop\"", ":", "0", ",", "\n", "\"dino\"", ":", "0", ",", "\n", "# downstream", "\n", "\"vqa\"", ":", "0", ",", "\n", "\"openend_vqa\"", ":", "0", ",", "\n", "\"mc_vqa\"", ":", "0", ",", "\n", "\"nlvr2\"", ":", "0", ",", "\n", "\"irtr\"", ":", "0", ",", "\n", "\"multiple_choice\"", ":", "0", ",", "\n", "'vcr_q2a'", ":", "0", ",", "\n", "'zs_classify'", ":", "0", "\n", "}", "\n", "ret", ".", "update", "(", "d", ")", "\n", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.AllInOne.config.config": [[29, 105], ["config._loss_names"], "function", ["home.repos.pwc.inspect_result.showlab_all-in-one.AllInOne.config._loss_names"], ["", "@", "ex", ".", "config", "\n", "def", "config", "(", ")", ":", "\n", "    ", "exp_name", "=", "\"CoTrain\"", "\n", "seed", "=", "0", "\n", "video_datasets", "=", "[", "\"wevid\"", ",", "\"howto100m\"", ",", "\"yttemporal\"", "]", "\n", "image_datasets", "=", "[", "\"cc3m\"", ",", "\"cc12m\"", "]", "\n", "loss_names", "=", "_loss_names", "(", "{", "\"vtm\"", ":", "1", ",", "\"mlm\"", ":", "1", "}", ")", "\n", "batch_size", "=", "4096", "# 128 x 32", "\n", "# this is a desired batch size; pl trainer will accumulate gradients when per step batch is smaller.", "\n", "linear_evaluation", "=", "False", "\n", "\n", "draw_false_image", "=", "1", "\n", "# video setting", "\n", "train_transform_keys", "=", "[", "\"pixelbert\"", "]", "\n", "val_transform_keys", "=", "[", "\"pixelbert\"", "]", "\n", "image_size", "=", "224", "# 384/224", "\n", "patch_size", "=", "16", "# 16/32", "\n", "max_image_len", "=", "-", "1", "\n", "draw_false_video", "=", "1", "\n", "video_only", "=", "False", "\n", "num_frames", "=", "3", "# input video frames", "\n", "\n", "# Text Setting", "\n", "vqav2_label_size", "=", "3129", "\n", "msrvttqa_label_size", "=", "1501", "\n", "max_text_len", "=", "40", "# original: 40, 200: for long sentences/paragraph", "\n", "tokenizer", "=", "\"pretrained/bert-base-uncased\"", "\n", "vocab_size", "=", "30522", "\n", "whole_word_masking", "=", "False", "\n", "mlm_prob", "=", "0.15", "\n", "draw_false_text", "=", "0", "\n", "\n", "draw_options_text", "=", "0", "\n", "# Transformer Setting", "\n", "vit", "=", "\"vit_base_patch16_224\"", "# \"vit_base_patch32_384\" / \"vit_base_patch16_224\"", "\n", "hidden_size", "=", "768", "\n", "num_heads", "=", "12", "\n", "num_layers", "=", "12", "\n", "mlp_ratio", "=", "4", "\n", "drop_rate", "=", "0.1", "\n", "shared_embedding_dim", "=", "512", "#  add for contrastive learning 512/256", "\n", "# model_temporal_frames = 4  #  add for model define\uff0c may not consistent with input data", "\n", "\n", "save_checkpoints_interval", "=", "1", "# save each 5 epochs", "\n", "\n", "# Optimizer Setting", "\n", "optim_type", "=", "\"adamw\"", "\n", "learning_rate", "=", "1e-4", "\n", "weight_decay", "=", "0.01", "\n", "decay_power", "=", "1", "\n", "max_epoch", "=", "100", "\n", "max_steps", "=", "25000", "\n", "warmup_steps", "=", "2500", "\n", "end_lr", "=", "0", "\n", "lr_mult", "=", "1", "# multiply lr for downstream heads", "\n", "backend", "=", "'a100'", "# gpu: a100/v100/others", "\n", "\n", "# Downstream Setting", "\n", "get_recall_metric", "=", "False", "\n", "get_ind_recall_metric", "=", "False", "\n", "retrieval_views", "=", "3", "# how many views for retrieval", "\n", "\n", "# PL Trainer Setting", "\n", "resume_from", "=", "None", "\n", "fast_dev_run", "=", "False", "\n", "val_check_interval", "=", "1.0", "\n", "test_only", "=", "False", "\n", "\n", "# below params varies with the environment", "\n", "data_root", "=", "\"\"", "\n", "log_dir", "=", "\"result\"", "\n", "per_gpu_batchsize", "=", "0", "# you should define this manually with per_gpu_batch_size=#", "\n", "num_gpus", "=", "1", "\n", "num_nodes", "=", "1", "\n", "load_path", "=", "\"\"", "\n", "num_workers", "=", "16", "# 0 will not lead to unstable memory usage but slow training ?", "\n", "precision", "=", "16", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.AllInOne.config.env_dandelin": [[108, 114], ["None"], "function", ["None"], ["# Named configs for \"environment\" which define gpus and nodes, and paths", "\n", "", "@", "ex", ".", "named_config", "\n", "def", "env_dandelin", "(", ")", ":", "\n", "    ", "data_root", "=", "\"/data2/dsets/dataset\"", "\n", "log_dir", "=", "\"/data2/CoTrain/result\"", "\n", "num_gpus", "=", "8", "\n", "num_nodes", "=", "1", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.AllInOne.config.task_mlm_itm_webvid": [[116, 124], ["config._loss_names"], "function", ["home.repos.pwc.inspect_result.showlab_all-in-one.AllInOne.config._loss_names"], ["# ================================ begin: pretrain ======================", "\n", "", "@", "ex", ".", "named_config", "\n", "def", "task_mlm_vtm_cotrain", "(", ")", ":", "\n", "    ", "exp_name", "=", "\"mlm_vtm\"", "\n", "video_datasets", "=", "[", "\"webvid\"", "]", "# \"howto100m\",", "\n", "image_datasets", "=", "[", "\"cc3m\"", "]", "\n", "loss_names", "=", "_loss_names", "(", "{", "\"vtm\"", ":", "1", ",", "\"mlm\"", ":", "1", "}", ")", "\n", "batch_size", "=", "2048", "\n", "max_epoch", "=", "30", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.AllInOne.config.task_mlm_itm_vcop_webvid": [[127, 135], ["config._loss_names"], "function", ["home.repos.pwc.inspect_result.showlab_all-in-one.AllInOne.config._loss_names"], ["save_checkpoints_interval", "=", "3", "# save each 5 epochs", "\n", "\n", "", "@", "ex", ".", "named_config", "\n", "def", "task_mlm_vtm_cotrain_seven", "(", ")", ":", "\n", "    ", "exp_name", "=", "\"mlm_vtm\"", "\n", "video_datasets", "=", "[", "\"webvid\"", ",", "'yttemporal'", ",", "\"howto100m\"", "]", "# 'yttemporal', \"howto100m\",", "\n", "image_datasets", "=", "[", "\"cc3m\"", ",", "\"cc12m\"", ",", "\"vg\"", ",", "'coco'", "]", "# ,  \"vg\", 'coco'", "\n", "loss_names", "=", "_loss_names", "(", "{", "\"vtm\"", ":", "1", ",", "\"mlm\"", ":", "1", "}", ")", "\n", "batch_size", "=", "2048", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.AllInOne.config.task_mlm_itm_howto100m": [[137, 146], ["config._loss_names"], "function", ["home.repos.pwc.inspect_result.showlab_all-in-one.AllInOne.config._loss_names"], ["max_image_len", "=", "-", "1", "\n", "val_check_interval", "=", "1.0", "\n", "save_checkpoints_interval", "=", "1", "# save each 5 epochs", "\n", "\n", "", "@", "ex", ".", "named_config", "\n", "def", "task_mlm_vtm_vcop_cotrain", "(", ")", ":", "\n", "    ", "exp_name", "=", "\"mlm_vtm\"", "\n", "video_datasets", "=", "[", "\"howto100m\"", ",", "\"webvid\"", "]", "\n", "image_datasets", "=", "[", "\"cc3m\"", "]", "\n", "loss_names", "=", "_loss_names", "(", "{", "\"vtm\"", ":", "1", ",", "\"mlm\"", ":", "1", ",", "\"vcop\"", ":", "1", "}", ")", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.AllInOne.config.task_mlm_itm_yttemporal": [[148, 157], ["config._loss_names"], "function", ["home.repos.pwc.inspect_result.showlab_all-in-one.AllInOne.config._loss_names"], ["max_epoch", "=", "30", "\n", "max_image_len", "=", "-", "1", "\n", "val_check_interval", "=", "1.0", "\n", "save_checkpoints_interval", "=", "5", "# save each 5 epochs", "\n", "\n", "", "@", "ex", ".", "named_config", "\n", "def", "task_mlm_vtm_dino_cotrain", "(", ")", ":", "\n", "    ", "exp_name", "=", "\"mlm_vtm_dino_1f\"", "\n", "video_datasets", "=", "[", "\"webvid\"", "]", "# \"howto100m\",", "\n", "image_datasets", "=", "[", "\"cc3m\"", "]", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.AllInOne.config.task_mlm_itm_webvid_howto": [[159, 168], ["config._loss_names"], "function", ["home.repos.pwc.inspect_result.showlab_all-in-one.AllInOne.config._loss_names"], ["train_transform_keys", "=", "[", "\"pixelbert_randaug\"", "]", "\n", "val_transform_keys", "=", "[", "\"pixelbert_randaug\"", "]", "\n", "batch_size", "=", "1024", "\n", "max_epoch", "=", "100", "\n", "max_image_len", "=", "-", "1", "\n", "val_check_interval", "=", "1.0", "\n", "save_checkpoints_interval", "=", "1", "# save each 5 epochs", "\n", "# ================================ end: pretrain ======================", "\n", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.AllInOne.config.task_mlm_ind_itc_webvid_howto": [[170, 179], ["config._loss_names"], "function", ["home.repos.pwc.inspect_result.showlab_all-in-one.AllInOne.config._loss_names"], ["# ========== begin: multiple choice ================", "\n", "# = for lsmdc multiple choice", "\n", "", "@", "ex", ".", "named_config", "\n", "def", "task_finetune_lsmdcchoice", "(", ")", ":", "\n", "    ", "exp_name", "=", "\"finetune_lsmdc_choice\"", "\n", "video_datasets", "=", "[", "\"lsmdc_choice\"", "]", "\n", "image_datasets", "=", "[", "]", "\n", "loss_names", "=", "_loss_names", "(", "{", "\"multiple_choice\"", ":", "1", "}", ")", "\n", "batch_size", "=", "256", "\n", "max_epoch", "=", "20", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.AllInOne.config.task_mlm_itm_webvid_howto_ytt": [[181, 190], ["config._loss_names"], "function", ["home.repos.pwc.inspect_result.showlab_all-in-one.AllInOne.config._loss_names"], ["warmup_steps", "=", "0.1", "\n", "draw_false_text", "=", "5", "# 5 choices", "\n", "learning_rate", "=", "1e-5", "\n", "val_check_interval", "=", "0.5", "\n", "lr_mult", "=", "10", "\n", "\n", "# = for msrvtt multiple choice", "\n", "", "@", "ex", ".", "named_config", "\n", "def", "task_finetune_msrvttchoice", "(", ")", ":", "\n", "    ", "exp_name", "=", "\"finetune_msrvtt_choice\"", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.AllInOne.config.task_mlm_itm_image_joint": [[191, 200], ["config._loss_names"], "function", ["home.repos.pwc.inspect_result.showlab_all-in-one.AllInOne.config._loss_names"], ["video_datasets", "=", "[", "\"msrvtt_choice\"", "]", "\n", "image_datasets", "=", "[", "]", "\n", "loss_names", "=", "_loss_names", "(", "{", "\"multiple_choice\"", ":", "1", "}", ")", "\n", "batch_size", "=", "256", "\n", "max_epoch", "=", "10", "\n", "max_steps", "=", "None", "\n", "warmup_steps", "=", "0.1", "\n", "draw_false_text", "=", "5", "# 5 choices", "\n", "learning_rate", "=", "1e-4", "\n", "val_check_interval", "=", "0.5", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.AllInOne.config.task_mlm_itm_vcop_webvid_howto": [[202, 211], ["config._loss_names"], "function", ["home.repos.pwc.inspect_result.showlab_all-in-one.AllInOne.config._loss_names"], ["# ========== end: multiple choice ================", "\n", "# ind itc", "\n", "# ========== begin: retrieval ================", "\n", "", "@", "ex", ".", "named_config", "\n", "def", "task_finetune_vtc_irtr_msrvtt", "(", ")", ":", "\n", "    ", "exp_name", "=", "\"finetune_vtc_irtr_msrvtt\"", "\n", "video_datasets", "=", "[", "\"msrvtt\"", "]", "\n", "image_datasets", "=", "[", "]", "\n", "train_transform_keys", "=", "[", "\"pixelbert_randaug\"", "]", "\n", "loss_names", "=", "_loss_names", "(", "{", "\"vtc\"", ":", "1", "}", ")", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.AllInOne.config.task_mlm_itm_ind_itc_webvid_howto": [[213, 222], ["config._loss_names"], "function", ["home.repos.pwc.inspect_result.showlab_all-in-one.AllInOne.config._loss_names"], ["max_epoch", "=", "50", "\n", "max_steps", "=", "None", "\n", "warmup_steps", "=", "0.1", "# 0.1/0.3", "\n", "retrieval_views", "=", "1", "# use 5 views", "\n", "get_recall_metric", "=", "False", "\n", "get_ind_recall_metric", "=", "True", "\n", "draw_false_text", "=", "15", "\n", "learning_rate", "=", "6e-4", "# 1/3e-4", "\n", "# ========== end: retrieval ================", "\n", "# ========== begin: vqa ================", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.AllInOne.config.task_mlm_itm_cc_webvid_howto": [[223, 232], ["config._loss_names"], "function", ["home.repos.pwc.inspect_result.showlab_all-in-one.AllInOne.config._loss_names"], ["# for msvd qa", "\n", "", "@", "ex", ".", "named_config", "\n", "def", "task_finetune_msvdqa", "(", ")", ":", "\n", "    ", "exp_name", "=", "\"finetune_msvd_qa\"", "\n", "video_datasets", "=", "[", "\"msvdqa\"", "]", "\n", "image_datasets", "=", "[", "]", "\n", "loss_names", "=", "_loss_names", "(", "{", "\"openend_vqa\"", ":", "1", "}", ")", "# msvd have same number of answers with msrvtt", "\n", "batch_size", "=", "512", "\n", "msrvttqa_label_size", "=", "1001", "# vqa voculbary length 1000 + 1 background", "\n", "max_epoch", "=", "20", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.AllInOne.config.task_ind_mlm_itm_cc_webvid_howto": [[234, 243], ["config._loss_names"], "function", ["home.repos.pwc.inspect_result.showlab_all-in-one.AllInOne.config._loss_names"], ["warmup_steps", "=", "0.1", "\n", "draw_false_image", "=", "0", "\n", "learning_rate", "=", "1e-4", "# 1e-4", "\n", "val_check_interval", "=", "1.0", "\n", "lr_mult", "=", "10", "\n", "\n", "# = add by  for msrvtt qa", "\n", "", "@", "ex", ".", "named_config", "\n", "def", "task_finetune_msrvttqa", "(", ")", ":", "\n", "    ", "exp_name", "=", "\"finetune_msrvtt_qa\"", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.AllInOne.config.task_mlm_itm_ego4d": [[244, 252], ["config._loss_names"], "function", ["home.repos.pwc.inspect_result.showlab_all-in-one.AllInOne.config._loss_names"], ["video_datasets", "=", "[", "\"msrvttqa\"", "]", "\n", "image_datasets", "=", "[", "]", "\n", "loss_names", "=", "_loss_names", "(", "{", "\"openend_vqa\"", ":", "1", "}", ")", "\n", "batch_size", "=", "512", "\n", "msrvttqa_label_size", "=", "1501", "# 1501 / 4540", "\n", "max_epoch", "=", "20", "\n", "max_steps", "=", "None", "\n", "warmup_steps", "=", "0.1", "# 0.1", "\n", "draw_false_image", "=", "1", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.AllInOne.config.task_mlm_itm_itc_webvid": [[254, 262], ["config._loss_names"], "function", ["home.repos.pwc.inspect_result.showlab_all-in-one.AllInOne.config._loss_names"], ["learning_rate", "=", "1e-4", "# 1e-4 normal", "\n", "val_check_interval", "=", "1.0", "\n", "lr_mult", "=", "10", "\n", "\n", "\n", "\n", "# = for tgif qa on frameqa", "\n", "", "@", "ex", ".", "named_config", "\n", "def", "task_finetune_tgifqa", "(", ")", ":", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.AllInOne.config.task_mlm_itm_ind_itc_webvid": [[265, 273], ["config._loss_names"], "function", ["home.repos.pwc.inspect_result.showlab_all-in-one.AllInOne.config._loss_names"], ["image_datasets", "=", "[", "]", "\n", "loss_names", "=", "_loss_names", "(", "{", "\"openend_vqa\"", ":", "1", "}", ")", "\n", "batch_size", "=", "512", "\n", "msrvttqa_label_size", "=", "1541", "# vqa voculbary length 1540 + 1 background", "\n", "max_epoch", "=", "20", "\n", "max_steps", "=", "None", "\n", "warmup_steps", "=", "0.1", "\n", "draw_false_image", "=", "0", "\n", "learning_rate", "=", "1e-4", "# 1e-4", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.AllInOne.config.task_itm_itc_webvid": [[276, 284], ["config._loss_names"], "function", ["home.repos.pwc.inspect_result.showlab_all-in-one.AllInOne.config._loss_names"], ["\n", "# = for tgif qa on action/trans", "\n", "", "@", "ex", ".", "named_config", "\n", "def", "task_finetune_tgif_action_trans", "(", ")", ":", "\n", "    ", "exp_name", "=", "\"finetune_tgif_action_trans\"", "\n", "video_datasets", "=", "[", "\"tgifqa\"", "]", "\n", "image_datasets", "=", "[", "]", "\n", "loss_names", "=", "_loss_names", "(", "{", "\"mc_vqa\"", ":", "1", "}", ")", "\n", "batch_size", "=", "512", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.AllInOne.config.task_ind_itc_webvid": [[287, 296], ["config._loss_names"], "function", ["home.repos.pwc.inspect_result.showlab_all-in-one.AllInOne.config._loss_names"], ["warmup_steps", "=", "0.1", "\n", "draw_false_image", "=", "0", "\n", "draw_options_text", "=", "5", "# 5 choices", "\n", "learning_rate", "=", "1e-4", "# 1e-4", "\n", "val_check_interval", "=", "1.0", "\n", "lr_mult", "=", "10", "\n", "\n", "# ========== end: vqa ================", "\n", "\n", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.AllInOne.config.task_mlm_itm": [[307, 315], ["config._loss_names"], "function", ["home.repos.pwc.inspect_result.showlab_all-in-one.AllInOne.config._loss_names"], ["max_steps", "=", "None", "\n", "warmup_steps", "=", "0.1", "\n", "draw_false_text", "=", "15", "\n", "learning_rate", "=", "1e-4", "\n", "\n", "\n", "", "@", "ex", ".", "named_config", "\n", "def", "task_finetune_action_recognition_k400", "(", ")", ":", "\n", "    ", "exp_name", "=", "\"finetune_action_recognition_k400\"", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.AllInOne.config.task_mlm_itm_randaug": [[317, 326], ["config._loss_names"], "function", ["home.repos.pwc.inspect_result.showlab_all-in-one.AllInOne.config._loss_names"], ["image_datasets", "=", "[", "]", "\n", "loss_names", "=", "_loss_names", "(", "{", "\"openend_vqa\"", ":", "1", "}", ")", "# have", "\n", "msrvttqa_label_size", "=", "401", "# 400 + 1", "\n", "batch_size", "=", "256", "\n", "max_epoch", "=", "50", "\n", "max_steps", "=", "None", "\n", "warmup_steps", "=", "0.1", "\n", "draw_false_text", "=", "15", "\n", "learning_rate", "=", "3e-4", "\n", "val_check_interval", "=", "1.0", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.AllInOne.config.task_mlm_itm_mpp": [[328, 336], ["config._loss_names"], "function", ["home.repos.pwc.inspect_result.showlab_all-in-one.AllInOne.config._loss_names"], ["\n", "# ================================ end: finetune ======================", "\n", "", "@", "ex", ".", "named_config", "\n", "def", "step25k", "(", ")", ":", "\n", "    ", "max_epoch", "=", "100", "\n", "max_steps", "=", "25000", "\n", "\n", "\n", "", "@", "ex", ".", "named_config", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.AllInOne.config.task_finetune_nlvr2": [[338, 349], ["config._loss_names"], "function", ["home.repos.pwc.inspect_result.showlab_all-in-one.AllInOne.config._loss_names"], ["    ", "max_epoch", "=", "100", "\n", "max_steps", "=", "50000", "\n", "\n", "\n", "", "@", "ex", ".", "named_config", "\n", "def", "step100k", "(", ")", ":", "\n", "    ", "max_epoch", "=", "100", "\n", "max_steps", "=", "100000", "\n", "\n", "\n", "", "@", "ex", ".", "named_config", "\n", "def", "step200k", "(", ")", ":", "\n"]], "home.repos.pwc.inspect_result.showlab_all-in-one.AllInOne.config.task_finetune_nlvr2_randaug": [[351, 363], ["config._loss_names"], "function", ["home.repos.pwc.inspect_result.showlab_all-in-one.AllInOne.config._loss_names"], ["max_steps", "=", "200000", "\n", "\n", "\n", "", "@", "ex", ".", "named_config", "\n", "def", "vit32_base", "(", ")", ":", "\n", "    ", "vit", "=", "\"vit_base_patch32_384\"", "\n", "patch_size", "=", "32", "\n", "hidden_size", "=", "768", "\n", "num_heads", "=", "12", "\n", "num_layers", "=", "12", "\n", "", ""]], "home.repos.pwc.inspect_result.showlab_all-in-one.AllInOne.config.task_finetune_vqa": [[365, 378], ["config._loss_names"], "function", ["home.repos.pwc.inspect_result.showlab_all-in-one.AllInOne.config._loss_names"], []], "home.repos.pwc.inspect_result.showlab_all-in-one.AllInOne.config.task_finetune_vqa_randaug": [[380, 394], ["config._loss_names"], "function", ["home.repos.pwc.inspect_result.showlab_all-in-one.AllInOne.config._loss_names"], []], "home.repos.pwc.inspect_result.showlab_all-in-one.AllInOne.config.task_finetune_msrvttqa": [[397, 412], ["config._loss_names"], "function", ["home.repos.pwc.inspect_result.showlab_all-in-one.AllInOne.config._loss_names"], []], "home.repos.pwc.inspect_result.showlab_all-in-one.AllInOne.config.task_finetune_msvdqa": [[414, 428], ["config._loss_names"], "function", ["home.repos.pwc.inspect_result.showlab_all-in-one.AllInOne.config._loss_names"], []], "home.repos.pwc.inspect_result.showlab_all-in-one.AllInOne.config.task_finetune_tgifqa": [[430, 444], ["config._loss_names"], "function", ["home.repos.pwc.inspect_result.showlab_all-in-one.AllInOne.config._loss_names"], []], "home.repos.pwc.inspect_result.showlab_all-in-one.AllInOne.config.task_finetune_tgif_action_trans": [[446, 460], ["config._loss_names"], "function", ["home.repos.pwc.inspect_result.showlab_all-in-one.AllInOne.config._loss_names"], []], "home.repos.pwc.inspect_result.showlab_all-in-one.AllInOne.config.task_finetune_msrvttchoice": [[462, 475], ["config._loss_names"], "function", ["home.repos.pwc.inspect_result.showlab_all-in-one.AllInOne.config._loss_names"], []], "home.repos.pwc.inspect_result.showlab_all-in-one.AllInOne.config.task_finetune_lsmdcchoice": [[478, 491], ["config._loss_names"], "function", ["home.repos.pwc.inspect_result.showlab_all-in-one.AllInOne.config._loss_names"], []], "home.repos.pwc.inspect_result.showlab_all-in-one.AllInOne.config.task_finetune_ego4dchoice": [[494, 507], ["config._loss_names"], "function", ["home.repos.pwc.inspect_result.showlab_all-in-one.AllInOne.config._loss_names"], []], "home.repos.pwc.inspect_result.showlab_all-in-one.AllInOne.config.task_finetune_vcrq2a": [[509, 523], ["config._loss_names"], "function", ["home.repos.pwc.inspect_result.showlab_all-in-one.AllInOne.config._loss_names"], []], "home.repos.pwc.inspect_result.showlab_all-in-one.AllInOne.config.task_finetune_tvqa": [[525, 540], ["config._loss_names"], "function", ["home.repos.pwc.inspect_result.showlab_all-in-one.AllInOne.config._loss_names"], []], "home.repos.pwc.inspect_result.showlab_all-in-one.AllInOne.config.task_finetune_irtr_coco": [[542, 554], ["config._loss_names"], "function", ["home.repos.pwc.inspect_result.showlab_all-in-one.AllInOne.config._loss_names"], []], "home.repos.pwc.inspect_result.showlab_all-in-one.AllInOne.config.task_finetune_irtr_coco_randaug": [[556, 569], ["config._loss_names"], "function", ["home.repos.pwc.inspect_result.showlab_all-in-one.AllInOne.config._loss_names"], []], "home.repos.pwc.inspect_result.showlab_all-in-one.AllInOne.config.task_finetune_ind_itc_irtr_coco_randaug": [[570, 585], ["config._loss_names"], "function", ["home.repos.pwc.inspect_result.showlab_all-in-one.AllInOne.config._loss_names"], []], "home.repos.pwc.inspect_result.showlab_all-in-one.AllInOne.config.task_finetune_irtr_msvd": [[587, 601], ["config._loss_names"], "function", ["home.repos.pwc.inspect_result.showlab_all-in-one.AllInOne.config._loss_names"], []], "home.repos.pwc.inspect_result.showlab_all-in-one.AllInOne.config.task_finetune_irtr_msrvtt": [[603, 615], ["config._loss_names"], "function", ["home.repos.pwc.inspect_result.showlab_all-in-one.AllInOne.config._loss_names"], []], "home.repos.pwc.inspect_result.showlab_all-in-one.AllInOne.config.task_finetune_itc_irtr_msrvtt_randaug": [[618, 632], ["config._loss_names"], "function", ["home.repos.pwc.inspect_result.showlab_all-in-one.AllInOne.config._loss_names"], []], "home.repos.pwc.inspect_result.showlab_all-in-one.AllInOne.config.task_finetune_only_ind_itc_msrvtt_randaug": [[635, 651], ["config._loss_names"], "function", ["home.repos.pwc.inspect_result.showlab_all-in-one.AllInOne.config._loss_names"], []], "home.repos.pwc.inspect_result.showlab_all-in-one.AllInOne.config.task_finetune_ind_itc_irtr_msrvtt_randaug": [[654, 670], ["config._loss_names"], "function", ["home.repos.pwc.inspect_result.showlab_all-in-one.AllInOne.config._loss_names"], []], "home.repos.pwc.inspect_result.showlab_all-in-one.AllInOne.config.task_finetune_ind_itc_irtr_activitynet_randaug": [[673, 689], ["config._loss_names"], "function", ["home.repos.pwc.inspect_result.showlab_all-in-one.AllInOne.config._loss_names"], []], "home.repos.pwc.inspect_result.showlab_all-in-one.AllInOne.config.task_finetune_ind_itc_irtr_didemo_randaug": [[692, 709], ["config._loss_names"], "function", ["home.repos.pwc.inspect_result.showlab_all-in-one.AllInOne.config._loss_names"], []], "home.repos.pwc.inspect_result.showlab_all-in-one.AllInOne.config.task_finetune_ind_itc_irtr_lsmdc_randaug": [[711, 728], ["config._loss_names"], "function", ["home.repos.pwc.inspect_result.showlab_all-in-one.AllInOne.config._loss_names"], []], "home.repos.pwc.inspect_result.showlab_all-in-one.AllInOne.config.task_finetune_irtr_msrvtt_randaug": [[730, 743], ["config._loss_names"], "function", ["home.repos.pwc.inspect_result.showlab_all-in-one.AllInOne.config._loss_names"], []], "home.repos.pwc.inspect_result.showlab_all-in-one.AllInOne.config.task_finetune_irtr_f30k": [[746, 758], ["config._loss_names"], "function", ["home.repos.pwc.inspect_result.showlab_all-in-one.AllInOne.config._loss_names"], []], "home.repos.pwc.inspect_result.showlab_all-in-one.AllInOne.config.task_finetune_irtr_f30k_randaug": [[760, 773], ["config._loss_names"], "function", ["home.repos.pwc.inspect_result.showlab_all-in-one.AllInOne.config._loss_names"], []], "home.repos.pwc.inspect_result.showlab_all-in-one.AllInOne.config.task_finetune_action_recognition_hmdb51": [[777, 789], ["config._loss_names"], "function", ["home.repos.pwc.inspect_result.showlab_all-in-one.AllInOne.config._loss_names"], []], "home.repos.pwc.inspect_result.showlab_all-in-one.AllInOne.config.task_finetune_action_recognition_k400": [[791, 804], ["config._loss_names"], "function", ["home.repos.pwc.inspect_result.showlab_all-in-one.AllInOne.config._loss_names"], []], "home.repos.pwc.inspect_result.showlab_all-in-one.AllInOne.config.step25k": [[813, 817], ["None"], "function", ["None"], []], "home.repos.pwc.inspect_result.showlab_all-in-one.AllInOne.config.step50k": [[819, 823], ["None"], "function", ["None"], []], "home.repos.pwc.inspect_result.showlab_all-in-one.AllInOne.config.step100k": [[825, 829], ["None"], "function", ["None"], []], "home.repos.pwc.inspect_result.showlab_all-in-one.AllInOne.config.step200k": [[831, 835], ["None"], "function", ["None"], []], "home.repos.pwc.inspect_result.showlab_all-in-one.AllInOne.config.vit32_base": [[837, 844], ["None"], "function", ["None"], []]}