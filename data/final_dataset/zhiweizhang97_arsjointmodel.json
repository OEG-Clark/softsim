{"home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.src.oracleMain.SciFactJointPredictionData.__init__": [[59, 88], ["jsonlines.open", "list", "zip", "oracleMain.SciFactJointPredictionData.rationale_label.items", "oracleMain.SciFactJointPredictionData.abstract_label.items", "jsonlines.open", "jsonlines.open", "oracleMain.clean_invalid_sentence", "oracleMain.clean_num", "oracleMain.SciFactJointPredictionData.samples.append", "sentence.strip", "oracleMain.clean_url", "int"], "methods", ["home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.dataset.loader.clean_invalid_sentence", "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.util.clean_num", "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.util.clean_url"], ["    ", "def", "__init__", "(", "self", ",", "corpus", ":", "str", ",", "claims", ":", "str", ",", "retrieval", ":", "str", ",", "sep_token", "=", "\"</s>\"", ")", ":", "\n", "# sep_token = ''", "\n", "        ", "self", ".", "rationale_label", "=", "{", "'NOT_ENOUGH_INFO'", ":", "0", ",", "'RATIONALE'", ":", "1", "}", "\n", "self", ".", "rev_rationale_label", "=", "{", "i", ":", "l", "for", "(", "l", ",", "i", ")", "in", "self", ".", "rationale_label", ".", "items", "(", ")", "}", "\n", "# self.abstract_label = {'CONTRADICT': 0, 'NOT_ENOUGH_INFO': 1, 'SUPPORT': 2}", "\n", "self", ".", "abstract_label", "=", "{", "'NOT_ENOUGH_INFO'", ":", "0", ",", "'CONTRADICT'", ":", "1", ",", "'SUPPORT'", ":", "2", "}", "\n", "self", ".", "rev_abstract_label", "=", "{", "i", ":", "l", "for", "(", "l", ",", "i", ")", "in", "self", ".", "abstract_label", ".", "items", "(", ")", "}", "\n", "\n", "self", ".", "samples", "=", "[", "]", "\n", "self", ".", "excluded_pairs", "=", "[", "]", "\n", "corpus", "=", "{", "doc", "[", "'doc_id'", "]", ":", "doc", "for", "doc", "in", "jsonlines", ".", "open", "(", "corpus", ")", "}", "\n", "abstract_retrieval", "=", "jsonlines", ".", "open", "(", "retrieval", ")", "\n", "for", "claim", ",", "retrieval", "in", "list", "(", "zip", "(", "jsonlines", ".", "open", "(", "claims", ")", ",", "abstract_retrieval", ")", ")", ":", "\n", "            ", "for", "doc_id", "in", "retrieval", "[", "'doc_ids'", "]", ":", "\n", "                ", "doc", "=", "corpus", "[", "int", "(", "doc_id", ")", "]", "\n", "# doc_id = str(doc_id)", "\n", "abstract_sentences", "=", "[", "sentence", ".", "strip", "(", ")", "for", "sentence", "in", "doc", "[", "'abstract'", "]", "]", "\n", "abstract_sentences", "=", "clean_invalid_sentence", "(", "abstract_sentences", ")", "# #", "\n", "concat_sentences", "=", "(", "' '", "+", "sep_token", "+", "' '", ")", ".", "join", "(", "abstract_sentences", ")", "\n", "title", "=", "clean_num", "(", "clean_url", "(", "doc", "[", "'title'", "]", ")", ")", "\n", "concat_sentences", "=", "title", "+", "' '", "+", "sep_token", "+", "' '", "+", "concat_sentences", "\n", "\n", "self", ".", "samples", ".", "append", "(", "{", "\n", "'claim'", ":", "claim", "[", "'claim'", "]", ",", "\n", "'claim_id'", ":", "claim", "[", "'id'", "]", ",", "\n", "'doc_id'", ":", "doc", "[", "'doc_id'", "]", ",", "\n", "'abstract'", ":", "concat_sentences", ",", "\n", "# 'paragraph': ' '.join(abstract_sentences),", "\n", "'title'", ":", "' '", "+", "sep_token", "+", "' '", ".", "join", "(", "doc", "[", "'title'", "]", ")", ",", "\n", "}", ")", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.src.oracleMain.SciFactJointPredictionData.__len__": [[90, 92], ["len"], "methods", ["None"], ["", "", "", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "samples", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.src.oracleMain.SciFactJointPredictionData.__getitem__": [[93, 95], ["None"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "idx", ")", ":", "\n", "        ", "return", "self", ".", "samples", "[", "idx", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.src.oracleMain.merge": [[27, 56], ["print", "numpy.set_printoptions", "pd.set_option", "pd.set_option", "pd.set_option", "evaluation.data.GoldDataset", "evaluation.data.PredictedDataset", "evaluation.metrics.compute_metrics", "print", "print", "open", "json.dump", "evaluation.metrics.compute_metrics.to_dict"], "function", ["home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.lib.metrics.compute_metrics", "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.lib.data.Document.dump"], ["def", "merge", "(", "args", ",", "state", "=", "'valid'", ",", "gold", "=", "''", ")", ":", "\n", "    ", "'''\n    # ================================================================================================================ #\n    # merge rationale and label predictions and abstract retrieval results.\n    # evaluate final predictions.\n    # ================================================================================================================ #\n    '''", "\n", "print", "(", "'evaluate final predictions result...'", ")", "\n", "\n", "if", "state", "==", "'valid'", ":", "\n", "        ", "import", "pandas", "as", "pd", "\n", "import", "numpy", "as", "np", "\n", "np", ".", "set_printoptions", "(", "threshold", "=", "np", ".", "inf", ")", "\n", "\n", "pd", ".", "set_option", "(", "'display.width'", ",", "300", ")", "# \u8bbe\u7f6e\u5b57\u7b26\u663e\u793a\u5bbd\u5ea6", "\n", "pd", ".", "set_option", "(", "'display.max_rows'", ",", "None", ")", "# \u8bbe\u7f6e\u663e\u793a\u6700\u5927\u884c", "\n", "pd", ".", "set_option", "(", "'display.max_columns'", ",", "None", ")", "# \u8bbe\u7f6e\u663e\u793a\u6700\u5927\u5217\uff0cNone\u4e3a\u663e\u793a\u6240\u6709\u5217", "\n", "\n", "data", "=", "GoldDataset", "(", "args", ".", "corpus_path", ",", "gold", ")", "\n", "predictions", "=", "PredictedDataset", "(", "data", ",", "args", ".", "merge_results", ")", "\n", "res", "=", "compute_metrics", "(", "predictions", ")", "\n", "if", "args", ".", "output", "is", "not", "None", ":", "\n", "            ", "with", "open", "(", "args", ".", "output", ",", "\"w\"", ")", "as", "f", ":", "\n", "                ", "json", ".", "dump", "(", "res", ".", "to_dict", "(", ")", ",", "f", ",", "indent", "=", "2", ")", "\n", "", "", "print", "(", "res", ")", "\n", "return", "res", "\n", "", "else", ":", "\n", "        ", "print", "(", "''", ")", "\n", "return", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.src.oracleMain.predictions2jsonl": [[97, 162], ["zip", "zip", "zip", "jsonlines.open", "rationale_claim.sort", "label_claim.sort", "len", "len", "len", "len", "claim_ids.append", "enumerate", "jsonlines.open.get", "claim_ids.append", "jsonlines.open.get", "len", "len", "rationale[].items", "open", "open", "sorted", "sorted", "rationale_claim.append", "label_claim.append", "print", "print", "rationale_sentence.append", "list", "list", "len", "r_c.values", "i.get", "i.get", "json.dumps", "json.dumps", "set", "set"], "function", ["None"], ["", "", "def", "predictions2jsonl", "(", "args", ",", "claims_file", ",", "abstract_results", ",", "rationale_results", ")", ":", "\n", "    ", "claim_ids", "=", "[", "]", "\n", "claims", "=", "{", "}", "\n", "output_rationale", "=", "\"prediction/rationale_selection.jsonl\"", "\n", "output_labels", "=", "\"prediction/label_predictions.jsonl\"", "\n", "assert", "(", "len", "(", "claims_file", ")", "==", "len", "(", "abstract_results", ")", ")", "\n", "assert", "(", "len", "(", "claims_file", ")", "==", "len", "(", "rationale_results", ")", ")", "\n", "\n", "for", "claim", ",", "rationale", "in", "zip", "(", "claims_file", ",", "rationale_results", ")", ":", "\n", "        ", "claim_id", "=", "claim", "[", "'claim_id'", "]", "\n", "claim_ids", ".", "append", "(", "claim_id", ")", "\n", "\n", "rationale_sentence", "=", "[", "]", "\n", "for", "i", ",", "sen", "in", "enumerate", "(", "rationale", ")", ":", "\n", "            ", "if", "sen", "==", "1", ":", "\n", "                ", "rationale_sentence", ".", "append", "(", "i", ")", "\n", "", "", "curr_claim", "=", "claims", ".", "get", "(", "claim_id", ",", "{", "'claim_id'", ":", "claim_id", ",", "'evidence'", ":", "{", "}", "}", ")", "\n", "curr_claim", "[", "'evidence'", "]", "[", "claim", "[", "'doc_id'", "]", "]", "=", "rationale_sentence", "\n", "claims", "[", "claim_id", "]", "=", "curr_claim", "\n", "", "rationale_claim", "=", "[", "claims", "[", "claim_id", "]", "for", "claim_id", "in", "sorted", "(", "list", "(", "set", "(", "claim_ids", ")", ")", ")", "]", "\n", "\n", "claim_ids", "=", "[", "]", "\n", "claims", "=", "{", "}", "\n", "# LABELS = ['CONTRADICT', 'NOT_ENOUGH_INFO', 'SUPPORT']", "\n", "LABELS", "=", "[", "'NOT_ENOUGH_INFO'", ",", "'CONTRADICT'", ",", "'SUPPORT'", "]", "\n", "for", "claim", ",", "abstract", "in", "zip", "(", "claims_file", ",", "abstract_results", ")", ":", "\n", "        ", "claim_id", "=", "claim", "[", "'claim_id'", "]", "\n", "claim_ids", ".", "append", "(", "claim_id", ")", "\n", "\n", "curr_claim", "=", "claims", ".", "get", "(", "claim_id", ",", "{", "'claim_id'", ":", "claim_id", ",", "'labels'", ":", "{", "}", "}", ")", "\n", "curr_claim", "[", "'labels'", "]", "=", "curr_claim", "[", "'labels'", "]", "\n", "curr_claim", "[", "'labels'", "]", "[", "claim", "[", "'doc_id'", "]", "]", "=", "{", "'label'", ":", "LABELS", "[", "abstract", "]", ",", "'confidence'", ":", "1", "}", "\n", "claims", "[", "claim_id", "]", "=", "curr_claim", "\n", "", "label_claim", "=", "[", "claims", "[", "claim_id", "]", "for", "claim_id", "in", "sorted", "(", "list", "(", "set", "(", "claim_ids", ")", ")", ")", "]", "\n", "\n", "assert", "(", "len", "(", "rationale_claim", ")", "==", "len", "(", "label_claim", ")", ")", "\n", "for", "abstract", ",", "rationale", "in", "zip", "(", "label_claim", ",", "rationale_claim", ")", ":", "\n", "        ", "assert", "(", "abstract", "[", "\"claim_id\"", "]", "==", "rationale", "[", "\"claim_id\"", "]", ")", "\n", "for", "doc_id", ",", "pred", "in", "rationale", "[", "\"evidence\"", "]", ".", "items", "(", ")", ":", "\n", "            ", "if", "len", "(", "pred", ")", "==", "0", ":", "\n", "                ", "abstract", "[", "\"labels\"", "]", "[", "doc_id", "]", "[", "\"label\"", "]", "=", "\"NOT_ENOUGH_INFO\"", "\n", "\n", "", "", "", "claims", "=", "jsonlines", ".", "open", "(", "args", ".", "gold", ")", "\n", "for", "claim", "in", "claims", ":", "\n", "        ", "claim_id", "=", "claim", "[", "'id'", "]", "\n", "is_present", "=", "False", "\n", "for", "r_c", "in", "rationale_claim", ":", "\n", "            ", "if", "claim_id", "in", "r_c", ".", "values", "(", ")", ":", "\n", "                ", "is_present", "=", "True", "\n", "", "", "if", "not", "is_present", ":", "\n", "            ", "rationale_claim", ".", "append", "(", "{", "'claim_id'", ":", "claim_id", ",", "'evidence'", ":", "{", "}", "}", ")", "\n", "label_claim", ".", "append", "(", "{", "'claim_id'", ":", "claim_id", ",", "'labels'", ":", "{", "}", "}", ")", "\n", "# print(rationale_claim)", "\n", "", "", "rationale_claim", ".", "sort", "(", "key", "=", "lambda", "i", ":", "i", ".", "get", "(", "'claim_id'", ",", "0", ")", ")", "\n", "label_claim", ".", "sort", "(", "key", "=", "lambda", "i", ":", "i", ".", "get", "(", "'claim_id'", ",", "0", ")", ")", "\n", "\n", "with", "open", "(", "output_rationale", ",", "\"w\"", ")", "as", "f", ":", "\n", "        ", "for", "entry", "in", "rationale_claim", ":", "\n", "            ", "print", "(", "json", ".", "dumps", "(", "entry", ")", ",", "file", "=", "f", ")", "\n", "\n", "", "", "with", "open", "(", "output_labels", ",", "\"w\"", ")", "as", "f", ":", "\n", "        ", "for", "entry", "in", "label_claim", ":", "\n", "            ", "print", "(", "json", ".", "dumps", "(", "entry", ")", ",", "file", "=", "f", ")", "\n", "\n", "", "", "return", "rationale_claim", ",", "label_claim", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.src.oracleMain.clean_url": [[164, 172], ["re.sub", "re.sub"], "function", ["None"], ["", "def", "clean_url", "(", "word", ")", ":", "\n", "    ", "\"\"\"\n        Clean specific data format from social media\n    \"\"\"", "\n", "# clean urls", "\n", "word", "=", "re", ".", "sub", "(", "r'https? : \\/\\/.*[\\r\\n]*'", ",", "'<URL>'", ",", "word", ")", "\n", "word", "=", "re", ".", "sub", "(", "r'exlink'", ",", "'<URL>'", ",", "word", ")", "\n", "return", "word", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.src.oracleMain.clean_num": [[174, 184], ["any", "char.isdigit", "float", "word.replace", "any", "char.isalpha"], "function", ["None"], ["", "def", "clean_num", "(", "word", ")", ":", "\n", "# check if the word contain number and no letters", "\n", "    ", "if", "any", "(", "char", ".", "isdigit", "(", ")", "for", "char", "in", "word", ")", ":", "\n", "        ", "try", ":", "\n", "            ", "num", "=", "float", "(", "word", ".", "replace", "(", "','", ",", "''", ")", ")", "\n", "return", "'@'", "\n", "", "except", ":", "\n", "            ", "if", "not", "any", "(", "char", ".", "isalpha", "(", ")", "for", "char", "in", "word", ")", ":", "\n", "                ", "return", "'@'", "\n", "", "", "", "return", "word", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.src.oracleMain.clean_invalid_sentence": [[186, 193], ["re.sub().strip", "sentences.append", "re.sub"], "function", ["None"], ["", "def", "clean_invalid_sentence", "(", "abstract", ")", ":", "\n", "    ", "sentences", "=", "[", "]", "\n", "for", "sen", "in", "abstract", ":", "\n", "        ", "sen", "=", "re", ".", "sub", "(", "r'[?\\.?\\s]'", ",", "' '", ",", "sen", ")", ".", "strip", "(", ")", "\n", "if", "sen", "!=", "''", ":", "\n", "            ", "sentences", ".", "append", "(", "sen", ")", "\n", "", "", "return", "sentences", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.src.oracleMain.get_oracle_result": [[195, 241], ["jsonlines.open", "jsonlines.open", "torch.device", "transformers.AutoTokenizer.from_pretrained", "embedding.jointmodel.JointModelClassifier().to", "JointModelClassifier().to.load_state_dict", "JointModelClassifier().to.eval", "jsonlines.open", "tqdm.tqdm", "torch.load", "list", "result.append", "open", "jsonlines.open", "torch.cuda.is_available", "embedding.jointmodel.JointModelClassifier", "zip", "oracleMain.clean_invalid_sentence", "oracleMain.clean_num", "dataset.encode.encode_paragraph", "utils.token_idx_by_sentence", "JointModelClassifier().to.", "enumerate", "print", "sentence.strip", "oracleMain.clean_url", "tensor.to", "tensor.to", "json.dumps", "dataset.encode.encode_paragraph.items", "rationale_sentence.append"], "function", ["home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.dataset.loader.clean_invalid_sentence", "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.util.clean_num", "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.dataset.encode.encode_paragraph", "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.FEVER_stance_paragraph.token_idx_by_sentence", "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.util.clean_url"], ["", "def", "get_oracle_result", "(", "args", ",", "input_set", ",", "checkpoint", ")", ":", "\n", "    ", "corpus", "=", "{", "doc", "[", "'doc_id'", "]", ":", "doc", "for", "doc", "in", "jsonlines", ".", "open", "(", "args", ".", "corpus_path", ")", "}", "\n", "dataset", "=", "jsonlines", ".", "open", "(", "input_set", ")", "\n", "abstract_retrieval", "=", "jsonlines", ".", "open", "(", "args", ".", "abstract_retrieval", ")", "\n", "\n", "device", "=", "torch", ".", "device", "(", "'cuda'", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "else", "'cpu'", ")", "\n", "tokenizer", "=", "AutoTokenizer", ".", "from_pretrained", "(", "args", ".", "model", ")", "\n", "model", "=", "JointModelClassifier", "(", "args", ")", ".", "to", "(", "device", ")", "\n", "model", ".", "load_state_dict", "(", "torch", ".", "load", "(", "checkpoint", ")", ")", "\n", "model", ".", "eval", "(", ")", "\n", "LABELS", "=", "[", "'NOT_ENOUGH_INFO'", ",", "'CONTRADICT'", ",", "'SUPPORT'", "]", "\n", "result", "=", "[", "]", "\n", "output", "=", "jsonlines", ".", "open", "(", "args", ".", "merge_results", ",", "'w'", ")", "\n", "for", "data", ",", "retrieval", "in", "tqdm", "(", "list", "(", "zip", "(", "dataset", ",", "abstract_retrieval", ")", ")", ")", ":", "\n", "        ", "assert", "data", "[", "'id'", "]", "==", "retrieval", "[", "'id'", "]", "\n", "claim", "=", "data", "[", "'claim'", "]", "\n", "evidence", "=", "{", "}", "\n", "for", "doc_id", "in", "retrieval", "[", "'doc_ids'", "]", ":", "\n", "            ", "doc", "=", "corpus", "[", "doc_id", "]", "\n", "abstract_sentences", "=", "[", "sentence", ".", "strip", "(", ")", "for", "sentence", "in", "doc", "[", "'abstract'", "]", "]", "\n", "abstract_sentences", "=", "clean_invalid_sentence", "(", "abstract_sentences", ")", "\n", "concat_sentences", "=", "(", "' '", "+", "tokenizer", ".", "sep_token", "+", "' '", ")", ".", "join", "(", "abstract_sentences", ")", "\n", "title", "=", "clean_num", "(", "clean_url", "(", "doc", "[", "'title'", "]", ")", ")", "\n", "abstract", "=", "title", "+", "' '", "+", "tokenizer", ".", "sep_token", "+", "' '", "+", "concat_sentences", "\n", "encoded_dict", "=", "encode_paragraph", "(", "tokenizer", ",", "[", "claim", "]", ",", "[", "abstract", "]", ")", "\n", "# print(encoded_dict)", "\n", "transformation_indices", "=", "token_idx_by_sentence", "(", "encoded_dict", "[", "'input_ids'", "]", ",", "tokenizer", ".", "sep_token_id", ",", "\n", "args", ".", "model", ")", "\n", "encoded_dict", "=", "{", "key", ":", "tensor", ".", "to", "(", "device", ")", "for", "key", ",", "tensor", "in", "encoded_dict", ".", "items", "(", ")", "}", "\n", "transformation_indices", "=", "[", "tensor", ".", "to", "(", "device", ")", "for", "tensor", "in", "transformation_indices", "]", "\n", "abstract_out", ",", "rationale_out", ",", "_", "=", "model", "(", "encoded_dict", ",", "transformation_indices", ")", "\n", "rationale_sentence", "=", "[", "]", "\n", "for", "i", ",", "sen", "in", "enumerate", "(", "rationale_out", "[", "0", "]", ")", ":", "\n", "                ", "if", "sen", "==", "1", ":", "\n", "                    ", "rationale_sentence", ".", "append", "(", "i", ")", "\n", "", "", "label", "=", "LABELS", "[", "abstract_out", "[", "0", "]", "]", "\n", "if", "label", "!=", "'NOT_ENOUGH_INFO'", ":", "\n", "                ", "evidence", "[", "doc_id", "]", "=", "{", "'sentences'", ":", "rationale_sentence", ",", "'label'", ":", "label", "}", "\n", "", "", "result", ".", "append", "(", "{", "\n", "'id'", ":", "retrieval", "[", "'id'", "]", ",", "\n", "'evidence'", ":", "evidence", ",", "\n", "}", ")", "\n", "", "with", "open", "(", "args", ".", "merge_results", ",", "'w'", ")", "as", "f", ":", "\n", "        ", "for", "entry", "in", "result", ":", "\n", "            ", "print", "(", "json", ".", "dumps", "(", "entry", ")", ",", "file", "=", "f", ")", "\n", "", "", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.src.oracleMain.parse_args": [[243, 294], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args"], "function", ["home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.src.JointAbstractRetrieval.parse_args"], ["", "def", "parse_args", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "\n", "description", "=", "'Evaluate SciFact predictions.'", "\n", ")", "\n", "# dataset parameters.", "\n", "parser", ".", "add_argument", "(", "'--corpus_path'", ",", "type", "=", "str", ",", "default", "=", "'../data/corpus.jsonl'", ",", "\n", "help", "=", "'The corpus of documents.'", ")", "\n", "parser", ".", "add_argument", "(", "'--claim_train_path'", ",", "type", "=", "str", ",", "\n", "default", "=", "'../data/claims_train_retrieved.jsonl'", ")", "\n", "parser", ".", "add_argument", "(", "'--claim_dev_path'", ",", "type", "=", "str", ",", "\n", "default", "=", "'../data/claims_dev_retrieved.jsonl'", ")", "\n", "parser", ".", "add_argument", "(", "'--claim_test_path'", ",", "type", "=", "str", ",", "\n", "default", "=", "'../data/claims_dev_retrieved.jsonl'", ")", "\n", "parser", ".", "add_argument", "(", "'--gold'", ",", "type", "=", "str", ",", "default", "=", "'../data/claims_dev.jsonl'", ")", "\n", "parser", ".", "add_argument", "(", "'--abstract_retrieval'", ",", "type", "=", "str", ",", "\n", "default", "=", "'prediction/abstract_retrieval1.jsonl'", ")", "\n", "parser", ".", "add_argument", "(", "'--rationale_selection'", ",", "type", "=", "str", ",", "\n", "default", "=", "'prediction/rationale_selection.jsonl'", ")", "\n", "parser", ".", "add_argument", "(", "'--save'", ",", "type", "=", "str", ",", "default", "=", "'model/'", ",", "\n", "help", "=", "'Folder to save the weights'", ")", "\n", "parser", ".", "add_argument", "(", "'--output_label'", ",", "type", "=", "str", ",", "default", "=", "'prediction/label_predictions.jsonl'", ")", "\n", "parser", ".", "add_argument", "(", "'--merge_results'", ",", "type", "=", "str", ",", "default", "=", "'prediction/merged_predictions.jsonl'", ")", "\n", "parser", ".", "add_argument", "(", "'--output'", ",", "type", "=", "str", ",", "default", "=", "'prediction/result_evaluation.json'", ",", "\n", "help", "=", "'The predictions.'", ")", "\n", "parser", ".", "add_argument", "(", "'--pre_trained_model'", ",", "type", "=", "str", ")", "\n", "\n", "# model parameters.", "\n", "parser", ".", "add_argument", "(", "'--model'", ",", "type", "=", "str", ",", "default", "=", "''", ")", "\n", "parser", ".", "add_argument", "(", "'--epochs'", ",", "type", "=", "int", ",", "default", "=", "20", ")", "\n", "parser", ".", "add_argument", "(", "'--threshold'", ",", "type", "=", "float", ",", "default", "=", "0.5", ",", "required", "=", "False", ")", "\n", "parser", ".", "add_argument", "(", "'--only_rationale'", ",", "action", "=", "'store_true'", ")", "\n", "parser", ".", "add_argument", "(", "'--batch_size_gpu'", ",", "type", "=", "int", ",", "default", "=", "8", ",", "\n", "help", "=", "'The batch size to send through GPU'", ")", "\n", "parser", ".", "add_argument", "(", "'--batch-size-accumulated'", ",", "type", "=", "int", ",", "default", "=", "256", ",", "\n", "help", "=", "'The batch size for each gradient update'", ")", "\n", "parser", ".", "add_argument", "(", "'--bert-lr'", ",", "type", "=", "float", ",", "default", "=", "1e-5", ")", "\n", "parser", ".", "add_argument", "(", "'--lr'", ",", "type", "=", "float", ",", "default", "=", "5e-6", ")", "\n", "parser", ".", "add_argument", "(", "'--mode'", ",", "type", "=", "str", ",", "default", "=", "'claim_and_rationale'", ",", "\n", "choices", "=", "[", "'claim_and_rationale'", ",", "'only_claim'", ",", "'only_rationale'", "]", ")", "\n", "parser", ".", "add_argument", "(", "'--filter'", ",", "type", "=", "str", ",", "default", "=", "'structured'", ",", "\n", "choices", "=", "[", "'structured'", ",", "'unstructured'", "]", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--hidden_dim\"", ",", "type", "=", "int", ",", "default", "=", "1024", ",", "\n", "help", "=", "\"Hidden dimension\"", ")", "\n", "parser", ".", "add_argument", "(", "'--vocab_size'", ",", "type", "=", "int", ",", "default", "=", "31116", ")", "\n", "parser", ".", "add_argument", "(", "\"--dropout\"", ",", "type", "=", "float", ",", "default", "=", "0.5", ",", "help", "=", "\"drop rate\"", ")", "\n", "parser", ".", "add_argument", "(", "'--k'", ",", "type", "=", "int", ",", "default", "=", "10", ",", "help", "=", "\"number of abstract retrieval(training)\"", ")", "\n", "parser", ".", "add_argument", "(", "'--alpha'", ",", "type", "=", "float", ",", "default", "=", "0.0", ")", "\n", "parser", ".", "add_argument", "(", "'--lambdas'", ",", "type", "=", "float", ",", "default", "=", "[", "1", ",", "2", ",", "12", "]", ")", "\n", "\n", "return", "parser", ".", "parse_args", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.src.oracleMain.printf": [[296, 304], ["list", "print", "vars().keys", "print", "print", "print", "vars", "vars"], "function", ["None"], ["", "def", "printf", "(", "args", ",", "split", ")", ":", "\n", "    ", "for", "k", "in", "list", "(", "vars", "(", "args", ")", ".", "keys", "(", ")", ")", ":", "\n", "        ", "print", "(", "'%s: %s'", "%", "(", "k", ",", "vars", "(", "args", ")", "[", "k", "]", ")", ")", "\n", "", "if", "split", ":", "\n", "        ", "print", "(", "'split: True'", ")", "\n", "", "else", ":", "\n", "        ", "print", "(", "'split: False'", ")", "\n", "", "print", "(", "'-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.src.oracleMain.main": [[306, 388], ["numpy.random.seed", "random.seed", "torch.manual_seed", "oracleMain.parse_args", "torch.device", "oracleMain.printf", "transformers.AutoTokenizer.from_pretrained", "oracleMain.SciFactJointPredictionData", "oracleMain.get_oracle_result", "oracleMain.merge", "torch.cuda.is_available"], "function", ["home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.src.JointAbstractRetrieval.parse_args", "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.src.JointAbstractRetrieval.printf", "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.src.oracleMain.get_oracle_result", "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.dataset.utils.merge"], ["", "def", "main", "(", ")", ":", "\n", "    ", "seed", "=", "12345", "\n", "np", ".", "random", ".", "seed", "(", "seed", ")", "\n", "random", ".", "seed", "(", "seed", ")", "\n", "torch", ".", "manual_seed", "(", "seed", ")", "\n", "args", "=", "parse_args", "(", ")", "\n", "device", "=", "torch", ".", "device", "(", "'cuda'", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "else", "'cpu'", ")", "\n", "# loader dataset", "\n", "split", "=", "False", "\n", "prediction", "=", "False", "\n", "if", "split", ":", "\n", "# split_dataset('../data/claims_train_retrieval.jsonl')", "\n", "        ", "claim_train_path", "=", "'../data/train_data_Bio.jsonl'", "\n", "claim_dev_path", "=", "'../data/dev_data_Bio.jsonl'", "\n", "claim_test_path", "=", "'../data/claims_dev_retrieved.jsonl'", "\n", "# print(claim_test_path)", "\n", "", "else", ":", "\n", "        ", "claim_train_path", "=", "args", ".", "claim_train_path", "\n", "claim_dev_path", "=", "args", ".", "claim_dev_path", "\n", "claim_test_path", "=", "args", ".", "claim_dev_path", "\n", "\n", "# args.model = 'allenai/scibert_scivocab_cased'", "\n", "# args.model = 'model/SciBert_checkpoint'", "\n", "# args.pre_trained_model = 'model/pre-train.model'", "\n", "", "args", ".", "model", "=", "'dmis-lab/biobert-large-cased-v1.1-mnli'", "\n", "# args.model = 'roberta-large'", "\n", "args", ".", "epochs", "=", "40", "\n", "args", ".", "bert_lr", "=", "1e-5", "\n", "args", ".", "lr", "=", "5e-6", "\n", "args", ".", "batch_size_gpu", "=", "8", "\n", "args", ".", "dropout", "=", "0", "\n", "args", ".", "k", "=", "30", "\n", "args", ".", "hidden_dim", "=", "1024", "# 768/1024", "\n", "# args.alpha = 1.9  # BioBert-large", "\n", "args", ".", "alpha", "=", "2.2", "# RoBerta-large", "\n", "# args.lambdas = [0.2, 1.1, 12.0]  # BioBert-large w   /get", "\n", "args", ".", "lambdas", "=", "[", "0.9", ",", "2.6", ",", "11.1", "]", "# RoBerta-large w", "\n", "# args.lambdas = [0.1, 4.7, 10.8]  # BioBert-large w/o /get", "\n", "# args.lambdas = [2.7, 2.2, 11.7]  # RoBerta-large w/o", "\n", "printf", "(", "args", ",", "split", ")", "\n", "# k_train = 12", "\n", "claim_test_path", "=", "'prediction/abstract_retrieval.jsonl'", "\n", "tokenizer", "=", "AutoTokenizer", ".", "from_pretrained", "(", "args", ".", "model", ")", "\n", "test_set", "=", "SciFactJointPredictionData", "(", "args", ".", "corpus_path", ",", "claim_test_path", ",", "args", ".", "abstract_retrieval", ",", "sep_token", "=", "tokenizer", ".", "sep_token", ")", "\n", "# checkpoint = 'model/BioBert_large_w.model'", "\n", "# print('BioBert-large w:')", "\n", "# abstract_result, rationale_result, retrieval_result = get_predictions(args, test_set, checkpoint)", "\n", "# rationales, labels = predictions2jsonl(args, test_set.samples, abstract_result, rationale_result)", "\n", "# get_oracle_result(args, claim_test_path, checkpoint)", "\n", "# merge_rationale_label(rationales, labels, args, state='valid', gold=args.gold)", "\n", "# merge_results = loader.loader_json(args.merge_results)", "\n", "# abstract = loader.loader_json(\"prediction/abstract_retrieval.jsonl\")", "\n", "#", "\n", "# merge_retrieval(merge_results, abstract, 'prediction/mergeresult.jsonl')", "\n", "#", "\n", "# merge(args, state='valid', gold=args.gold)", "\n", "\n", "checkpoint", "=", "'model/BioBert_large_w.model'", "\n", "# print('BioBert-large w/o:')", "\n", "# abstract_result, rationale_result, retrieval_result = get_predictions(args, test_set, checkpoint)", "\n", "# rationales, labels = predictions2jsonl(args, test_set.samples, abstract_result, rationale_result)", "\n", "get_oracle_result", "(", "args", ",", "claim_test_path", ",", "checkpoint", ")", "\n", "# merge_rationale_label(rationales, labels, args, state='valid', gold=args.gold)", "\n", "merge", "(", "args", ",", "state", "=", "'valid'", ",", "gold", "=", "args", ".", "gold", ")", "\n", "'''\n    args.model = 'roberta-large'\n    checkpoint = 'model/RoBerta_large_w.model'\n    print('RoBerta-large w:')\n    # abstract_result, rationale_result, retrieval_result = get_predictions(args, test_set, checkpoint)\n    # rationales, labels = predictions2jsonl(args, test_set.samples, abstract_result, rationale_result)\n    get_oracle_result(args, claim_test_path, checkpoint)\n    # merge_rationale_label(rationales, labels, args, state='valid', gold=args.gold)\n    merge(args, state='valid', gold=args.gold)\n\n    checkpoint = 'model/RoBerta_large_wo.model'\n    print('RoBerta-large w/o:')\n    # abstract_result, rationale_result, retrieval_result = get_predictions(args, test_set, checkpoint)\n    # rationales, labels = predictions2jsonl(args, test_set.samples, abstract_result, rationale_result)\n    get_oracle_result(args, claim_test_path, checkpoint)\n    # merge_rationale_label(rationales, labels, args, state='valid', gold=args.gold)\n    merge(args, state='valid', gold=args.gold)\n    '''", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.src.TFIDFAbstractRetrieval.parse_args": [[8, 18], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args"], "function", ["home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.src.JointAbstractRetrieval.parse_args"], ["def", "parse_args", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "\n", "description", "=", "\"TFIDF abstract retrieval\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "'--claim_file'", ",", "type", "=", "str", ",", "default", "=", "'../data/claims_dev.jsonl'", ")", "\n", "parser", ".", "add_argument", "(", "'--corpus_file'", ",", "type", "=", "str", ",", "default", "=", "'../data/corpus.jsonl'", ")", "\n", "parser", ".", "add_argument", "(", "'--k'", ",", "type", "=", "int", ",", "default", "=", "150", ")", "\n", "parser", ".", "add_argument", "(", "'--claim_retrieved_file'", ",", "type", "=", "str", ",", "default", "=", "'../data/claims_dev_retrieved_tfidf.jsonl'", ")", "\n", "\n", "return", "parser", ".", "parse_args", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.src.TFIDFAbstractRetrieval.main": [[20, 63], ["TFIDFAbstractRetrieval.parse_args", "corpus.items", "sklearn.feature_extraction.text.TfidfVectorizer", "numpy.array", "sklearn.feature_extraction.text.TfidfVectorizer.fit_transform", "sklearn.feature_extraction.text.TfidfVectorizer.transform", "numpy.dot().todense", "numpy.argsort", "open", "open", "corpus_texts.append", "np.array.append", "corpus_ids[].squeeze", "jsonlines.open", "sorted", "json.loads", "json.loads", "claims.append", "numpy.dot", "enumerate", "list", "retrieved_corpus[].tolist", "output.write", "claims_by_id.keys", "str"], "function", ["home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.src.JointAbstractRetrieval.parse_args"], ["", "def", "main", "(", ")", ":", "\n", "\n", "    ", "args", "=", "parse_args", "(", ")", "\n", "\n", "claim_file", "=", "args", ".", "claim_file", "\n", "corpus_file", "=", "args", ".", "corpus_file", "\n", "\n", "corpus", "=", "{", "}", "\n", "with", "open", "(", "corpus_file", ")", "as", "f", ":", "\n", "        ", "for", "line", "in", "f", ":", "\n", "            ", "abstract", "=", "json", ".", "loads", "(", "line", ")", "\n", "corpus", "[", "str", "(", "abstract", "[", "\"doc_id\"", "]", ")", "]", "=", "abstract", "\n", "\n", "", "", "claims", "=", "[", "]", "\n", "with", "open", "(", "claim_file", ")", "as", "f", ":", "\n", "        ", "for", "line", "in", "f", ":", "\n", "            ", "claim", "=", "json", ".", "loads", "(", "line", ")", "\n", "claims", ".", "append", "(", "claim", ")", "\n", "", "", "claims_by_id", "=", "{", "claim", "[", "'id'", "]", ":", "claim", "for", "claim", "in", "claims", "}", "\n", "\n", "corpus_texts", "=", "[", "]", "\n", "corpus_ids", "=", "[", "]", "\n", "for", "k", ",", "v", "in", "corpus", ".", "items", "(", ")", ":", "\n", "        ", "original_sentences", "=", "[", "v", "[", "'title'", "]", "]", "+", "v", "[", "'abstract'", "]", "\n", "processed_paragraph", "=", "\" \"", ".", "join", "(", "original_sentences", ")", "\n", "corpus_texts", ".", "append", "(", "processed_paragraph", ")", "\n", "corpus_ids", ".", "append", "(", "k", ")", "\n", "", "vectorizer", "=", "TfidfVectorizer", "(", "stop_words", "=", "'english'", ",", "\n", "ngram_range", "=", "(", "1", ",", "2", ")", ")", "\n", "corpus_ids", "=", "np", ".", "array", "(", "corpus_ids", ")", "\n", "corpus_vectors", "=", "vectorizer", ".", "fit_transform", "(", "corpus_texts", ")", "\n", "\n", "claim_vectors", "=", "vectorizer", ".", "transform", "(", "[", "claim", "[", "'claim'", "]", "for", "claim", "in", "claims", "]", ")", "\n", "similarity_matrix", "=", "np", ".", "dot", "(", "corpus_vectors", ",", "claim_vectors", ".", "T", ")", ".", "todense", "(", ")", "\n", "\n", "k", "=", "args", ".", "k", "\n", "orders", "=", "np", ".", "argsort", "(", "similarity_matrix", ",", "axis", "=", "0", ")", "\n", "retrieved_corpus", "=", "{", "claim", "[", "\"id\"", "]", ":", "corpus_ids", "[", "orders", "[", ":", ",", "i", "]", "[", ":", ":", "-", "1", "]", "[", ":", "k", "]", "]", ".", "squeeze", "(", ")", "for", "i", ",", "claim", "in", "enumerate", "(", "claims", ")", "}", "\n", "with", "jsonlines", ".", "open", "(", "args", ".", "claim_retrieved_file", ",", "'w'", ")", "as", "output", ":", "\n", "        ", "claim_ids", "=", "sorted", "(", "list", "(", "claims_by_id", ".", "keys", "(", ")", ")", ")", "\n", "for", "id", "in", "claim_ids", ":", "\n", "            ", "claims_by_id", "[", "id", "]", "[", "\"doc_ids\"", "]", "=", "retrieved_corpus", "[", "id", "]", ".", "tolist", "(", ")", "\n", "output", ".", "write", "(", "claims_by_id", "[", "id", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.src.get_prediction.get_predictions": [[12, 45], ["torch.device", "transformers.AutoTokenizer.from_pretrained", "embedding.jointmodel.JointModelClassifier().to", "JointModelClassifier().to.load_state_dict", "JointModelClassifier().to.eval", "torch.load", "torch.no_grad", "tqdm.tqdm", "torch.cuda.is_available", "embedding.jointmodel.JointModelClassifier", "torch.utils.data.DataLoader", "dataset.encode.encode_paragraph", "utils.token_idx_by_sentence", "JointModelClassifier().to.", "abstract_result.extend", "rationale_result.extend", "retrieval_result.extend", "tensor.to", "tensor.to", "dataset.encode.encode_paragraph.items"], "function", ["home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.dataset.encode.encode_paragraph", "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.FEVER_stance_paragraph.token_idx_by_sentence"], ["def", "get_predictions", "(", "args", ",", "input_set", ",", "checkpoint", ")", ":", "\n", "    ", "device", "=", "torch", ".", "device", "(", "'cuda'", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "else", "'cpu'", ")", "\n", "# args.batch_size_gpu = 8", "\n", "tokenizer", "=", "AutoTokenizer", ".", "from_pretrained", "(", "args", ".", "model", ")", "\n", "model", "=", "JointModelClassifier", "(", "args", ")", ".", "to", "(", "device", ")", "\n", "# model = JointParagraphClassifier(args.model, args.hidden_dim, args.dropout).to(device)", "\n", "model", ".", "load_state_dict", "(", "torch", ".", "load", "(", "checkpoint", ")", ")", "\n", "model", ".", "eval", "(", ")", "\n", "# for m in model.state_dict().keys():", "\n", "#     print(m)", "\n", "# p", "\n", "abstract_result", "=", "[", "]", "\n", "rationale_result", "=", "[", "]", "\n", "retrieval_result", "=", "[", "]", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "for", "batch", "in", "tqdm", "(", "DataLoader", "(", "input_set", ",", "batch_size", "=", "1", ",", "shuffle", "=", "False", ")", ")", ":", "\n", "            ", "encoded_dict", "=", "encode_paragraph", "(", "tokenizer", ",", "batch", "[", "'claim'", "]", ",", "batch", "[", "'abstract'", "]", ")", "\n", "# encoded = encode_paragraph(tokenizer, batch['claim'], batch['paragraph'])", "\n", "# encoded = {key: tensor.to(device) for key, tensor in encoded.items()}", "\n", "transformation_indices", "=", "token_idx_by_sentence", "(", "encoded_dict", "[", "'input_ids'", "]", ",", "tokenizer", ".", "sep_token_id", ",", "\n", "args", ".", "model", ")", "\n", "# match_indices = token_idx_by_sentence(encoded_dict[\"input_ids\"], tokenizer.sep_token_id,", "\n", "#                                       args.model, match=True)", "\n", "encoded_dict", "=", "{", "key", ":", "tensor", ".", "to", "(", "device", ")", "for", "key", ",", "tensor", "in", "encoded_dict", ".", "items", "(", ")", "}", "\n", "transformation_indices", "=", "[", "tensor", ".", "to", "(", "device", ")", "for", "tensor", "in", "transformation_indices", "]", "\n", "# match_indices = [tensor.to(device) for tensor in match_indices]", "\n", "# abstract_out, rationale_out = model(encoded_dict, transformation_indices, match_indices)", "\n", "abstract_out", ",", "rationale_out", ",", "retrieval_out", "=", "model", "(", "encoded_dict", ",", "transformation_indices", ")", "\n", "abstract_result", ".", "extend", "(", "abstract_out", ")", "\n", "rationale_result", ".", "extend", "(", "rationale_out", ")", "\n", "retrieval_result", ".", "extend", "(", "retrieval_out", ")", "\n", "\n", "", "", "return", "abstract_result", ",", "rationale_result", ",", "retrieval_result", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.src.get_prediction.get_abstract_retrieval": [[47, 66], ["torch.device", "transformers.AutoTokenizer.from_pretrained", "embedding.jointmodel.JointModelClassifier().to", "JointModelClassifier().to.load_state_dict", "JointModelClassifier().to.eval", "torch.load", "torch.no_grad", "tqdm.tqdm", "torch.cuda.is_available", "embedding.jointmodel.JointModelClassifier", "torch.utils.data.DataLoader", "dataset.encode.encode_paragraph", "utils.token_idx_by_sentence", "JointModelClassifier().to.", "retrieval_result.extend", "tensor.to", "tensor.to", "dataset.encode.encode_paragraph.items"], "function", ["home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.dataset.encode.encode_paragraph", "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.FEVER_stance_paragraph.token_idx_by_sentence"], ["", "def", "get_abstract_retrieval", "(", "args", ",", "input_set", ",", "checkpoint", ")", ":", "\n", "    ", "device", "=", "torch", ".", "device", "(", "'cuda'", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "else", "'cpu'", ")", "\n", "tokenizer", "=", "AutoTokenizer", ".", "from_pretrained", "(", "args", ".", "model", ")", "\n", "model", "=", "JointModelClassifier", "(", "args", ")", ".", "to", "(", "device", ")", "\n", "model", ".", "load_state_dict", "(", "torch", ".", "load", "(", "checkpoint", ")", ")", "\n", "model", ".", "eval", "(", ")", "\n", "retrieval_result", "=", "[", "]", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "for", "batch", "in", "tqdm", "(", "DataLoader", "(", "input_set", ",", "batch_size", "=", "1", ",", "shuffle", "=", "False", ")", ")", ":", "\n", "            ", "encoded_dict", "=", "encode_paragraph", "(", "tokenizer", ",", "batch", "[", "'claim'", "]", ",", "batch", "[", "'abstract'", "]", ")", "\n", "transformation_indices", "=", "token_idx_by_sentence", "(", "encoded_dict", "[", "'input_ids'", "]", ",", "tokenizer", ".", "sep_token_id", ",", "\n", "args", ".", "model", ")", "\n", "encoded_dict", "=", "{", "key", ":", "tensor", ".", "to", "(", "device", ")", "for", "key", ",", "tensor", "in", "encoded_dict", ".", "items", "(", ")", "}", "\n", "transformation_indices", "=", "[", "tensor", ".", "to", "(", "device", ")", "for", "tensor", "in", "transformation_indices", "]", "\n", "retrieval_out", ",", "_", "=", "model", "(", "encoded_dict", ",", "transformation_indices", ",", "\n", "retrieval_only", "=", "True", ")", "\n", "retrieval_result", ".", "extend", "(", "retrieval_out", ")", "\n", "\n", "", "", "return", "retrieval_result", "\n", "", ""]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.src.main.parse_args": [[15, 68], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args"], "function", ["home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.src.JointAbstractRetrieval.parse_args"], ["def", "parse_args", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "\n", "description", "=", "'Evaluate SciFact predictions.'", "\n", ")", "\n", "# dataset parameters.", "\n", "parser", ".", "add_argument", "(", "'--corpus_path'", ",", "type", "=", "str", ",", "default", "=", "'../data/corpus.jsonl'", ",", "\n", "help", "=", "'The corpus of documents.'", ")", "\n", "parser", ".", "add_argument", "(", "'--claim_train_path'", ",", "type", "=", "str", ",", "\n", "default", "=", "'../data/claims_train_retrieved.jsonl'", ")", "\n", "parser", ".", "add_argument", "(", "'--claim_dev_path'", ",", "type", "=", "str", ",", "\n", "default", "=", "'../data/claims_dev_retrieved.jsonl'", ")", "\n", "parser", ".", "add_argument", "(", "'--claim_test_path'", ",", "type", "=", "str", ",", "\n", "default", "=", "'../data/claims_dev_retrieved.jsonl'", ")", "\n", "parser", ".", "add_argument", "(", "'--gold'", ",", "type", "=", "str", ",", "default", "=", "'../data/claims_dev.jsonl'", ")", "\n", "parser", ".", "add_argument", "(", "'--abstract_retrieval'", ",", "type", "=", "str", ",", "\n", "default", "=", "'prediction/abstract_retrieval.jsonl'", ")", "\n", "parser", ".", "add_argument", "(", "'--rationale_selection'", ",", "type", "=", "str", ",", "\n", "default", "=", "'prediction/rationale_selection.jsonl'", ")", "\n", "parser", ".", "add_argument", "(", "'--save'", ",", "type", "=", "str", ",", "default", "=", "'model/'", ",", "\n", "help", "=", "'Folder to save the weights'", ")", "\n", "parser", ".", "add_argument", "(", "'--output_label'", ",", "type", "=", "str", ",", "default", "=", "'prediction/label_predictions.jsonl'", ")", "\n", "parser", ".", "add_argument", "(", "'--merge_results'", ",", "type", "=", "str", ",", "default", "=", "'prediction/merged_predictions.jsonl'", ")", "\n", "parser", ".", "add_argument", "(", "'--output'", ",", "type", "=", "str", ",", "default", "=", "'prediction/result_evaluation.json'", ",", "\n", "help", "=", "'The predictions.'", ")", "\n", "parser", ".", "add_argument", "(", "'--pre_trained_model'", ",", "type", "=", "str", ")", "\n", "parser", ".", "add_argument", "(", "'--checkpoint'", ",", "type", "=", "str", ")", "\n", "\n", "# model parameters.", "\n", "parser", ".", "add_argument", "(", "'--model'", ",", "type", "=", "str", ",", "default", "=", "''", ")", "\n", "parser", ".", "add_argument", "(", "'--epochs'", ",", "type", "=", "int", ",", "default", "=", "20", ")", "\n", "parser", ".", "add_argument", "(", "'--threshold'", ",", "type", "=", "float", ",", "default", "=", "0.5", ",", "required", "=", "False", ")", "\n", "parser", ".", "add_argument", "(", "'--only_rationale'", ",", "action", "=", "'store_true'", ")", "\n", "parser", ".", "add_argument", "(", "'--batch_size_gpu'", ",", "type", "=", "int", ",", "default", "=", "8", ",", "\n", "help", "=", "'The batch size to send through GPU'", ")", "\n", "parser", ".", "add_argument", "(", "'--batch-size-accumulated'", ",", "type", "=", "int", ",", "default", "=", "256", ",", "\n", "help", "=", "'The batch size for each gradient update'", ")", "\n", "parser", ".", "add_argument", "(", "'--bert-lr'", ",", "type", "=", "float", ",", "default", "=", "1e-5", ")", "\n", "parser", ".", "add_argument", "(", "'--lr'", ",", "type", "=", "float", ",", "default", "=", "5e-6", ")", "\n", "parser", ".", "add_argument", "(", "'--mode'", ",", "type", "=", "str", ",", "default", "=", "'claim_and_rationale'", ",", "\n", "choices", "=", "[", "'claim_and_rationale'", ",", "'only_claim'", ",", "'only_rationale'", "]", ")", "\n", "parser", ".", "add_argument", "(", "'--filter'", ",", "type", "=", "str", ",", "default", "=", "'structured'", ",", "\n", "choices", "=", "[", "'structured'", ",", "'unstructured'", "]", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--hidden_dim\"", ",", "type", "=", "int", ",", "default", "=", "1024", ",", "\n", "help", "=", "\"Hidden dimension\"", ")", "\n", "parser", ".", "add_argument", "(", "'--vocab_size'", ",", "type", "=", "int", ",", "default", "=", "31116", ")", "\n", "parser", ".", "add_argument", "(", "\"--dropout\"", ",", "type", "=", "float", ",", "default", "=", "0.5", ",", "help", "=", "\"drop rate\"", ")", "\n", "parser", ".", "add_argument", "(", "'--k'", ",", "type", "=", "int", ",", "default", "=", "10", ",", "help", "=", "\"number of abstract retrieval(training)\"", ")", "\n", "parser", ".", "add_argument", "(", "'--alpha'", ",", "type", "=", "float", ",", "default", "=", "0.0", ")", "\n", "parser", ".", "add_argument", "(", "'--lambdas'", ",", "type", "=", "float", ",", "default", "=", "[", "1", ",", "2", ",", "12", "]", ")", "\n", "parser", ".", "add_argument", "(", "'--state'", ",", "type", "=", "str", ",", "default", "=", "'train'", ",", "choices", "=", "[", "'train'", ",", "'prediction'", "]", ")", "\n", "\n", "return", "parser", ".", "parse_args", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.src.main.printf": [[70, 78], ["list", "print", "vars().keys", "print", "print", "print", "vars", "vars"], "function", ["None"], ["", "def", "printf", "(", "args", ",", "split", ")", ":", "\n", "    ", "for", "k", "in", "list", "(", "vars", "(", "args", ")", ".", "keys", "(", ")", ")", ":", "\n", "        ", "print", "(", "'%s: %s'", "%", "(", "k", ",", "vars", "(", "args", ")", "[", "k", "]", ")", ")", "\n", "", "if", "split", ":", "\n", "        ", "print", "(", "'split: True'", ")", "\n", "", "else", ":", "\n", "        ", "print", "(", "'split: False'", ")", "\n", "", "print", "(", "'-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.src.main.main": [[80, 150], ["numpy.random.seed", "random.seed", "torch.manual_seed", "main.parse_args", "torch.device", "main.printf", "transformers.AutoTokenizer.from_pretrained", "dataset.loader.SciFactJointDataset", "dataset.loader.SciFactJointDataset", "dataset.loader.SciFactJointDataset", "get_prediction.get_predictions", "utils.predictions2jsonl", "train_model.train_base", "dataset.utils.merge", "dataset.utils.merge", "print", "evaluation.evaluation_model.evaluate_rationale_selection", "print", "evaluation.evaluation_model.evaluate_label_predictions", "print", "evaluation.evaluation_model.merge_rationale_label", "torch.cuda.is_available"], "function", ["home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.src.JointAbstractRetrieval.parse_args", "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.src.JointAbstractRetrieval.printf", "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.src.optunaMain.get_predictions", "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.src.utils.predictions2jsonl", "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.src.PreTraining.train_base", "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.dataset.utils.merge", "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.dataset.utils.merge", "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.evaluation.evaluation_model.evaluate_rationale_selection", "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.evaluation.evaluation_model.evaluate_label_predictions", "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.evaluation.evaluation_model.merge_rationale_label"], ["", "def", "main", "(", ")", ":", "\n", "    ", "seed", "=", "12345", "\n", "np", ".", "random", ".", "seed", "(", "seed", ")", "\n", "random", ".", "seed", "(", "seed", ")", "\n", "torch", ".", "manual_seed", "(", "seed", ")", "\n", "args", "=", "parse_args", "(", ")", "\n", "device", "=", "torch", ".", "device", "(", "'cuda'", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "else", "'cpu'", ")", "\n", "# loader dataset", "\n", "split", "=", "False", "\n", "eval_prediction", "=", "True", "\n", "if", "split", ":", "\n", "# split_dataset('../data/claims_train_retrieval.jsonl')", "\n", "        ", "claim_train_path", "=", "'../data/train_data_Bio.jsonl'", "\n", "claim_dev_path", "=", "'../data/dev_data_Bio.jsonl'", "\n", "claim_test_path", "=", "'../data/claims_dev_retrieved.jsonl'", "\n", "# print(claim_test_path)", "\n", "", "else", ":", "\n", "        ", "claim_train_path", "=", "args", ".", "claim_train_path", "\n", "claim_dev_path", "=", "args", ".", "claim_dev_path", "\n", "claim_test_path", "=", "args", ".", "claim_dev_path", "\n", "\n", "# args.model = 'allenai/scibert_scivocab_cased'", "\n", "# args.model = 'model/SciBert_checkpoint'", "\n", "# args.pre_trained_model = 'model/pre-train.model'", "\n", "", "args", ".", "model", "=", "'dmis-lab/biobert-large-cased-v1.1-mnli'", "\n", "# args.model = 'roberta-large'", "\n", "args", ".", "epochs", "=", "40", "\n", "args", ".", "bert_lr", "=", "1e-5", "\n", "args", ".", "lr", "=", "5e-6", "\n", "args", ".", "batch_size_gpu", "=", "8", "\n", "args", ".", "dropout", "=", "0", "\n", "args", ".", "k", "=", "30", "\n", "args", ".", "hidden_dim", "=", "1024", "# 768/1024", "\n", "# args.alpha = 1.9  # BioBert-large", "\n", "# args.alpha = 2.2  # RoBerta-large", "\n", "args", ".", "alpha", "=", "6.7", "# BioBert-large share", "\n", "# args.lambdas = [0.2, 1.1, 12.0]  # BioBert-large w   /get", "\n", "# args.lambdas = [0.9, 2.6, 11.1]  # RoBerta-large w", "\n", "# args.lambdas = [0.1, 4.7, 10.8]  # BioBert-large w/o /get", "\n", "# args.lambdas = [2.7, 2.2, 11.7]  # RoBerta-large w/o", "\n", "args", ".", "lambdas", "=", "[", "1.6", ",", "2.5", ",", "9.5", "]", "# # BioBert-large share w", "\n", "printf", "(", "args", ",", "split", ")", "\n", "k_train", "=", "12", "\n", "tokenizer", "=", "AutoTokenizer", ".", "from_pretrained", "(", "args", ".", "model", ")", "\n", "train_set", "=", "SciFactJointDataset", "(", "args", ".", "corpus_path", ",", "claim_train_path", ",", "sep_token", "=", "tokenizer", ".", "sep_token", ",", "k", "=", "k_train", ")", "\n", "dev_set", "=", "SciFactJointDataset", "(", "args", ".", "corpus_path", ",", "claim_dev_path", ",", "sep_token", "=", "tokenizer", ".", "sep_token", ",", "k", "=", "k_train", ",", "\n", "down_sampling", "=", "False", ")", "\n", "test_set", "=", "SciFactJointDataset", "(", "args", ".", "corpus_path", ",", "claim_test_path", ",", "\n", "sep_token", "=", "tokenizer", ".", "sep_token", ",", "k", "=", "args", ".", "k", ",", "train", "=", "False", ",", "down_sampling", "=", "False", ")", "\n", "# test_set = SciFactJointPredictionData(args.corpus_path, claim_test_path, sep_token=tokenizer.sep_token)", "\n", "if", "args", ".", "state", "==", "'train'", ":", "\n", "        ", "args", ".", "checkpoint", "=", "train_base", "(", "train_set", ",", "dev_set", ",", "args", ")", "\n", "", "if", "args", ".", "state", "==", "'prediction'", ":", "\n", "        ", "args", ".", "checkpoint", "=", "'model/RoBerta_large_w.model'", "\n", "# checkpoint = 'tmp-runs/162030701614073-abstract_f1-6925-rationale_f1-6753.model'", "\n", "# print(checkpoint)", "\n", "", "abstract_result", ",", "rationale_result", ",", "retrieval_result", "=", "get_predictions", "(", "args", ",", "test_set", ",", "args", ".", "checkpoint", ")", "\n", "rationales", ",", "labels", "=", "predictions2jsonl", "(", "test_set", ".", "samples", ",", "abstract_result", ",", "rationale_result", ")", "\n", "# retrieval2jsonl(test_set.samples, retrieval_result)", "\n", "# merge(rationales, labels, args.merge_results)", "\n", "if", "not", "eval_prediction", ":", "\n", "        ", "merge", "(", "rationales", ",", "labels", ",", "args", ".", "merge_results", ")", "\n", "", "else", ":", "\n", "        ", "merge", "(", "rationales", ",", "labels", ",", "args", ".", "merge_results", ")", "\n", "print", "(", "'rationale selection...'", ")", "\n", "evaluate_rationale_selection", "(", "args", ",", "\"prediction/rationale_selection.jsonl\"", ")", "\n", "print", "(", "'label predictions...'", ")", "\n", "evaluate_label_predictions", "(", "args", ",", "\"prediction/label_predictions.jsonl\"", ")", "\n", "print", "(", "'merging predictions...'", ")", "\n", "merge_rationale_label", "(", "rationales", ",", "labels", ",", "args", ",", "state", "=", "'valid'", ",", "gold", "=", "args", ".", "gold", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.src.train_model.schedule_sample_p": [[19, 26], ["numpy.sin", "numpy.tanh"], "function", ["None"], ["def", "schedule_sample_p", "(", "epoch", ",", "total", ")", ":", "\n", "    ", "if", "epoch", "==", "total", "-", "1", ":", "\n", "        ", "abstract_sample", "=", "1.0", "\n", "", "else", ":", "\n", "        ", "abstract_sample", "=", "np", ".", "tanh", "(", "0.5", "*", "np", ".", "pi", "*", "epoch", "/", "(", "total", "-", "1", "-", "epoch", ")", ")", "\n", "", "rationale_sample", "=", "np", ".", "sin", "(", "0.5", "*", "np", ".", "pi", "*", "epoch", "/", "(", "total", "-", "1", ")", ")", "\n", "return", "abstract_sample", ",", "rationale_sample", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.src.train_model.train_base": [[28, 97], ["torch.device", "torch.device", "os.path.join", "transformers.AutoTokenizer.from_pretrained", "embedding.jointmodel.JointModelClassifier", "model.to.to", "torch.optim.Adam", "torch.optim.Adam", "transformers.get_cosine_schedule_with_warmup", "model.to.train", "os.path.join", "range", "torch.save", "torch.save", "model.to.load_state_dict", "model.to.reinitialize", "parameters.append", "train_model.schedule_sample_p", "model.to.train", "tqdm.tqdm", "enumerate", "transformers.get_cosine_schedule_with_warmup.step", "evaluation.evaluation_model.evaluation_joint", "print", "evaluation.evaluation_model.evaluation_joint", "print", "best_model.state_dict", "torch.cuda.is_available", "torch.cuda.is_available", "torch.load", "torch.load", "model.to.bert.parameters", "model.to.abstract_retrieval.parameters", "torch.utils.data.DataLoader", "dataset.encode.encode_paragraph", "utils.token_idx_by_sentence", "utils.get_rationale_label", "model.to.", "loss.backward", "module.parameters", "tensor.to", "tensor.to", "torch.optim.Adam.step", "torch.optim.Adam.zero_grad", "tqdm.tqdm.set_description", "dataset.encode.encode_paragraph.items", "batch[].to", "padded_label.to", "batch[].to", "round", "round", "round", "round", "round", "loss.item", "abstract_loss.item", "rationale_loss.item", "sim_loss.item", "bce_loss.item"], "function", ["home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.paragraph_model_kgat.JointParagraphKGATClassifier.reinitialize", "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.domain_adaptation_joint_paragraph_fine_tune.schedule_sample_p", "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.evaluation.evaluation_model.evaluation_joint", "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.evaluation.evaluation_model.evaluation_joint", "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.dataset.encode.encode_paragraph", "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.FEVER_stance_paragraph.token_idx_by_sentence", "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.src.utils.get_rationale_label"], ["", "def", "train_base", "(", "train_set", ",", "dev_set", ",", "args", ")", ":", "\n", "# awl = AutomaticWeightedLoss(3)", "\n", "    ", "device", "=", "torch", ".", "device", "(", "'cuda'", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "else", "'cpu'", ")", "\n", "tmp_dir", "=", "os", ".", "path", ".", "join", "(", "os", ".", "path", ".", "curdir", ",", "'tmp-runs/'", ")", "\n", "tokenizer", "=", "AutoTokenizer", ".", "from_pretrained", "(", "args", ".", "model", ")", "\n", "model", "=", "JointModelClassifier", "(", "args", ")", "\n", "if", "args", ".", "pre_trained_model", "is", "not", "None", ":", "\n", "        ", "model", ".", "load_state_dict", "(", "torch", ".", "load", "(", "args", ".", "pre_trained_model", ")", ")", "\n", "model", ".", "reinitialize", "(", ")", "\n", "", "model", "=", "model", ".", "to", "(", "device", ")", "\n", "parameters", "=", "[", "{", "'params'", ":", "model", ".", "bert", ".", "parameters", "(", ")", ",", "'lr'", ":", "args", ".", "bert_lr", "}", ",", "\n", "{", "'params'", ":", "model", ".", "abstract_retrieval", ".", "parameters", "(", ")", ",", "'lr'", ":", "5e-6", "}", "]", "\n", "for", "module", "in", "model", ".", "extra_modules", ":", "\n", "        ", "parameters", ".", "append", "(", "{", "'params'", ":", "module", ".", "parameters", "(", ")", ",", "'lr'", ":", "args", ".", "lr", "}", ")", "\n", "", "optimizer", "=", "torch", ".", "optim", ".", "Adam", "(", "parameters", ")", "\n", "scheduler", "=", "get_cosine_schedule_with_warmup", "(", "optimizer", ",", "0", ",", "args", ".", "epochs", ")", "\n", "\"\"\"\n    \"\"\"", "\n", "best_f1", "=", "0", "\n", "best_model", "=", "model", "\n", "model", ".", "train", "(", ")", "\n", "checkpoint", "=", "os", ".", "path", ".", "join", "(", "args", ".", "save", ",", "f'JointModel.model'", ")", "\n", "for", "epoch", "in", "range", "(", "args", ".", "epochs", ")", ":", "\n", "        ", "abstract_sample", ",", "rationale_sample", "=", "schedule_sample_p", "(", "epoch", ",", "args", ".", "epochs", ")", "\n", "model", ".", "train", "(", ")", "# cudnn RNN backward can only be called in training mode", "\n", "t", "=", "tqdm", "(", "DataLoader", "(", "train_set", ",", "batch_size", "=", "1", ",", "shuffle", "=", "True", ")", ")", "\n", "for", "i", ",", "batch", "in", "enumerate", "(", "t", ")", ":", "\n", "            ", "encoded_dict", "=", "encode_paragraph", "(", "tokenizer", ",", "batch", "[", "'claim'", "]", ",", "batch", "[", "'abstract'", "]", ")", "\n", "transformation_indices", "=", "token_idx_by_sentence", "(", "encoded_dict", "[", "\"input_ids\"", "]", ",", "tokenizer", ".", "sep_token_id", ",", "\n", "args", ".", "model", ")", "\n", "encoded_dict", "=", "{", "key", ":", "tensor", ".", "to", "(", "device", ")", "for", "key", ",", "tensor", "in", "encoded_dict", ".", "items", "(", ")", "}", "\n", "transformation_indices", "=", "[", "tensor", ".", "to", "(", "device", ")", "for", "tensor", "in", "transformation_indices", "]", "\n", "padded_label", ",", "rationale_label", "=", "get_rationale_label", "(", "batch", "[", "\"sentence_label\"", "]", ",", "padding_idx", "=", "2", ")", "\n", "_", ",", "_", ",", "abstract_loss", ",", "rationale_loss", ",", "sim_loss", ",", "bce_loss", "=", "model", "(", "encoded_dict", ",", "transformation_indices", ",", "\n", "abstract_label", "=", "batch", "[", "'abstract_label'", "]", ".", "to", "(", "device", ")", ",", "\n", "rationale_label", "=", "padded_label", ".", "to", "(", "device", ")", ",", "\n", "retrieval_label", "=", "batch", "[", "'sim_label'", "]", ".", "to", "(", "device", ")", ",", "\n", "train", "=", "True", ",", "rationale_sample", "=", "rationale_sample", ")", "\n", "rationale_loss", "*=", "args", ".", "lambdas", "[", "2", "]", "\n", "abstract_loss", "*=", "args", ".", "lambdas", "[", "1", "]", "\n", "sim_loss", "*=", "args", ".", "lambdas", "[", "0", "]", "\n", "bce_loss", "=", "args", ".", "alpha", "*", "bce_loss", "\n", "loss", "=", "abstract_loss", "+", "rationale_loss", "+", "sim_loss", "+", "bce_loss", "\n", "loss", ".", "backward", "(", ")", "\n", "if", "(", "i", "+", "1", ")", "%", "(", "args", ".", "batch_size_accumulated", "//", "args", ".", "batch_size_gpu", ")", "==", "0", ":", "\n", "                ", "optimizer", ".", "step", "(", ")", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "t", ".", "set_description", "(", "f'Epoch {epoch}, iter {i}, loss: {round(loss.item(), 4)},'", "\n", "f' abstract loss: {round(abstract_loss.item(), 4)},'", "\n", "f' rationale loss: {round(rationale_loss.item(), 4)},'", "\n", "f' retrieval loss: {round(sim_loss.item(), 4)},'", "\n", "f' BCE loss: {round(bce_loss.item(), 4)}'", ")", "\n", "", "", "scheduler", ".", "step", "(", ")", "\n", "train_score", "=", "evaluation_joint", "(", "model", ",", "train_set", ",", "args", ",", "tokenizer", ")", "\n", "print", "(", "f'Epoch {epoch} train abstract score:'", ",", "train_score", "[", "0", "]", ",", "\n", "f'Epoch {epoch} train rationale score:'", ",", "train_score", "[", "1", "]", ")", "\n", "dev_score", "=", "evaluation_joint", "(", "model", ",", "dev_set", ",", "args", ",", "tokenizer", ")", "\n", "print", "(", "f'Epoch {epoch} dev abstract score:'", ",", "dev_score", "[", "0", "]", ",", "\n", "f'Epoch {epoch} dev rationale score:'", ",", "dev_score", "[", "1", "]", ")", "\n", "# save", "\n", "# save_path = os.path.join(tmp_dir, str(int(time.time() * 1e5))", "\n", "#                          + f'-abstract_f1-{int(dev_score[0][\"f1\"]*1e4)}'", "\n", "#                          + f'-rationale_f1-{int(dev_score[1][\"f1\"]*1e4)}.model')", "\n", "# torch.save(model.state_dict(), save_path)", "\n", "if", "(", "dev_score", "[", "0", "]", "[", "'f1'", "]", "+", "dev_score", "[", "1", "]", "[", "'f1'", "]", ")", "/", "2", ">=", "best_f1", ":", "\n", "            ", "best_f1", "=", "(", "dev_score", "[", "0", "]", "[", "'f1'", "]", "+", "dev_score", "[", "1", "]", "[", "'f1'", "]", ")", "/", "2", "\n", "best_model", "=", "model", "\n", "", "", "torch", ".", "save", "(", "best_model", ".", "state_dict", "(", ")", ",", "checkpoint", ")", "\n", "return", "checkpoint", "\n", "", ""]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.src.PreTraining.parse_args": [[20, 85], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args"], "function", ["home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.src.JointAbstractRetrieval.parse_args"], ["def", "parse_args", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "\n", "description", "=", "'Evaluate SciFact predictions.'", "\n", ")", "\n", "# dataset parameters.", "\n", "parser", ".", "add_argument", "(", "'--corpus_path'", ",", "type", "=", "str", ",", "default", "=", "'../data/corpus.jsonl'", ",", "\n", "help", "=", "'The corpus of documents.'", ")", "\n", "parser", ".", "add_argument", "(", "'--claim_train_path'", ",", "type", "=", "str", ",", "\n", "default", "=", "'../data/fever_train_retrieved_15.jsonl'", ")", "\n", "parser", ".", "add_argument", "(", "'--claim_dev_path'", ",", "type", "=", "str", ",", "\n", "default", "=", "'../data/fever_dev_retrieved_15.jsonl'", ")", "\n", "parser", ".", "add_argument", "(", "'--claim_test_path'", ",", "type", "=", "str", ",", "\n", "default", "=", "'../data/claims_test.jsonl'", ")", "\n", "parser", ".", "add_argument", "(", "'--gold'", ",", "type", "=", "str", ",", "default", "=", "'../data/claims_dev.jsonl'", ")", "\n", "parser", ".", "add_argument", "(", "'--abstract_retrieval'", ",", "type", "=", "str", ",", "\n", "default", "=", "'prediction/abstract_retrieval.jsonl'", ")", "\n", "parser", ".", "add_argument", "(", "'--rationale_selection'", ",", "type", "=", "str", ",", "\n", "default", "=", "'prediction/rationale_selection.jsonl'", ")", "\n", "parser", ".", "add_argument", "(", "'--save'", ",", "type", "=", "str", ",", "default", "=", "'model/'", ",", "\n", "help", "=", "'Folder to save the weights'", ")", "\n", "parser", ".", "add_argument", "(", "'--output_label'", ",", "type", "=", "str", ",", "default", "=", "'prediction/label_predictions.jsonl'", ")", "\n", "parser", ".", "add_argument", "(", "'--merge_results'", ",", "type", "=", "str", ",", "default", "=", "'prediction/merged_predictions.jsonl'", ")", "\n", "parser", ".", "add_argument", "(", "'--output'", ",", "type", "=", "str", ",", "default", "=", "'prediction/result_evaluation.json'", ",", "\n", "help", "=", "'The predictions.'", ")", "\n", "parser", ".", "add_argument", "(", "'--rationale_selection_tfidf'", ",", "type", "=", "str", ",", "default", "=", "'prediction/rationale_selection_tfidf.jsonl'", ")", "\n", "\n", "# model parameters.", "\n", "parser", ".", "add_argument", "(", "'--model'", ",", "type", "=", "str", ",", "default", "=", "''", ")", "\n", "parser", ".", "add_argument", "(", "'--rationale_model'", ",", "type", "=", "str", ",", "default", "=", "''", ")", "\n", "parser", ".", "add_argument", "(", "'--label_model'", ",", "type", "=", "str", ",", "default", "=", "''", ")", "\n", "parser", ".", "add_argument", "(", "'--epochs'", ",", "type", "=", "int", ",", "default", "=", "20", ")", "\n", "parser", ".", "add_argument", "(", "'--threshold'", ",", "type", "=", "float", ",", "default", "=", "0.5", ",", "required", "=", "False", ")", "\n", "parser", ".", "add_argument", "(", "'--only_rationale'", ",", "action", "=", "'store_true'", ")", "\n", "parser", ".", "add_argument", "(", "'--batch_size_gpu'", ",", "type", "=", "int", ",", "default", "=", "8", ",", "\n", "help", "=", "'The batch size to send through GPU'", ")", "\n", "parser", ".", "add_argument", "(", "'--batch-size-accumulated'", ",", "type", "=", "int", ",", "default", "=", "256", ",", "\n", "help", "=", "'The batch size for each gradient update'", ")", "\n", "parser", ".", "add_argument", "(", "'--bert-lr'", ",", "type", "=", "float", ",", "default", "=", "1e-5", ")", "\n", "parser", ".", "add_argument", "(", "'--lr'", ",", "type", "=", "float", ",", "default", "=", "5e-6", ")", "\n", "parser", ".", "add_argument", "(", "'--mode'", ",", "type", "=", "str", ",", "default", "=", "'claim_and_rationale'", ",", "\n", "choices", "=", "[", "'claim_and_rationale'", ",", "'only_claim'", ",", "'only_rationale'", "]", ")", "\n", "parser", ".", "add_argument", "(", "'--filter'", ",", "type", "=", "str", ",", "default", "=", "'structured'", ",", "\n", "choices", "=", "[", "'structured'", ",", "'unstructured'", "]", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--embedding'", ",", "type", "=", "str", ",", "default", "=", "'roberta'", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--hidden_dim\"", ",", "type", "=", "int", ",", "default", "=", "1024", ",", "\n", "help", "=", "\"Hidden dimension\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--output_size\"", ",", "type", "=", "int", ",", "default", "=", "1", ")", "\n", "parser", ".", "add_argument", "(", "\"--num_label\"", ",", "type", "=", "int", ",", "default", "=", "2", ",", "help", "=", "\"numbers of the label\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--class_num_label\"", ",", "type", "=", "int", ",", "default", "=", "1", ",", "\n", "help", "=", "\"max number of the label for one class\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--embed_size\"", ",", "type", "=", "int", ",", "default", "=", "768", ",", "help", "=", "\"embedding size\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--cnn_num_filters\"", ",", "type", "=", "int", ",", "default", "=", "128", ",", "\n", "help", "=", "\"Num of filters per filter size [default: 50]\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--cnn_filter_sizes\"", ",", "type", "=", "int", ",", "nargs", "=", "\"+\"", ",", "\n", "default", "=", "[", "3", ",", "4", ",", "5", "]", ",", "\n", "help", "=", "\"Filter sizes [default: 3]\"", ")", "\n", "parser", ".", "add_argument", "(", "'--vocab_size'", ",", "type", "=", "int", ",", "default", "=", "31116", ")", "\n", "parser", ".", "add_argument", "(", "\"--dropout\"", ",", "type", "=", "float", ",", "default", "=", "0.5", ",", "help", "=", "\"drop rate\"", ")", "\n", "parser", ".", "add_argument", "(", "'--k'", ",", "type", "=", "int", ",", "default", "=", "10", ",", "help", "=", "\"number of abstract retrieval(training)\"", ")", "\n", "parser", ".", "add_argument", "(", "'--alpha'", ",", "type", "=", "float", ",", "default", "=", "0.1", ")", "\n", "parser", ".", "add_argument", "(", "'--lambdas'", ",", "type", "=", "float", ",", "default", "=", "[", "1", ",", "2", ",", "12", "]", ")", "\n", "\n", "return", "parser", ".", "parse_args", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.src.PreTraining.printf": [[87, 91], ["list", "print", "vars().keys", "print", "vars", "vars"], "function", ["None"], ["", "def", "printf", "(", "args", ")", ":", "\n", "    ", "for", "k", "in", "list", "(", "vars", "(", "args", ")", ".", "keys", "(", ")", ")", ":", "\n", "        ", "print", "(", "'%s: %s'", "%", "(", "k", ",", "vars", "(", "args", ")", "[", "k", "]", ")", ")", "\n", "", "print", "(", "'-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.src.PreTraining.schedule_sample_p": [[93, 100], ["numpy.sin", "numpy.tanh"], "function", ["None"], ["", "def", "schedule_sample_p", "(", "epoch", ",", "total", ")", ":", "\n", "    ", "if", "epoch", "==", "total", "-", "1", ":", "\n", "        ", "abstract_sample", "=", "1.0", "\n", "", "else", ":", "\n", "        ", "abstract_sample", "=", "np", ".", "tanh", "(", "0.5", "*", "np", ".", "pi", "*", "epoch", "/", "(", "total", "-", "1", "-", "epoch", ")", ")", "\n", "", "rationale_sample", "=", "np", ".", "sin", "(", "0.5", "*", "np", ".", "pi", "*", "epoch", "/", "(", "total", "-", "1", ")", ")", "\n", "return", "abstract_sample", ",", "rationale_sample", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.src.PreTraining.evaluation": [[102, 133], ["torch.device", "model.eval", "sklearn.metrics.f1_score", "sklearn.metrics.precision_score", "sklearn.metrics.recall_score", "sklearn.metrics.f1_score", "sklearn.metrics.precision_score", "sklearn.metrics.recall_score", "torch.no_grad", "tqdm.tqdm", "utils.flatten", "utils.flatten", "utils.flatten", "utils.flatten", "utils.flatten", "utils.flatten", "torch.cuda.is_available", "torch.utils.data.DataLoader", "dataset.encode.encode_paragraph", "utils.token_idx_by_sentence", "utils.get_rationale_label", "tensor.to", "tensor.to", "padded_label.size", "model", "abstract_preds.extend", "abstract_labels.extend", "rationale_predictions.extend", "rationale_labels.extend", "dataset.encode.encode_paragraph.items", "transformation_indices[].size"], "function", ["home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.util.flatten", "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.util.flatten", "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.util.flatten", "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.util.flatten", "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.util.flatten", "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.util.flatten", "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.dataset.encode.encode_paragraph", "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.FEVER_stance_paragraph.token_idx_by_sentence", "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.src.utils.get_rationale_label"], ["", "def", "evaluation", "(", "model", ",", "dataset", ",", "args", ",", "tokenizer", ")", ":", "\n", "    ", "device", "=", "torch", ".", "device", "(", "'cuda'", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "else", "'cpu'", ")", "\n", "model", ".", "eval", "(", ")", "\n", "rationale_predictions", "=", "[", "]", "\n", "rationale_labels", "=", "[", "]", "\n", "abstract_preds", "=", "[", "]", "\n", "abstract_labels", "=", "[", "]", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "for", "batch", "in", "tqdm", "(", "DataLoader", "(", "dataset", ",", "batch_size", "=", "1", ",", "shuffle", "=", "False", ")", ")", ":", "\n", "            ", "encoded_dict", "=", "encode_paragraph", "(", "tokenizer", ",", "batch", "[", "'claim'", "]", ",", "batch", "[", "'abstract'", "]", ")", "\n", "transformation_indices", "=", "token_idx_by_sentence", "(", "encoded_dict", "[", "\"input_ids\"", "]", ",", "tokenizer", ".", "sep_token_id", ",", "\n", "args", ".", "model", ")", "\n", "encoded_dict", "=", "{", "key", ":", "tensor", ".", "to", "(", "device", ")", "for", "key", ",", "tensor", "in", "encoded_dict", ".", "items", "(", ")", "}", "\n", "transformation_indices", "=", "[", "tensor", ".", "to", "(", "device", ")", "for", "tensor", "in", "transformation_indices", "]", "\n", "padded_label", ",", "rationale_label", "=", "get_rationale_label", "(", "batch", "[", "\"sentence_label\"", "]", ",", "padding_idx", "=", "2", ")", "\n", "if", "padded_label", ".", "size", "(", "1", ")", "==", "transformation_indices", "[", "-", "1", "]", ".", "size", "(", "1", ")", "-", "1", ":", "\n", "                ", "abstract_out", ",", "rationale_out", ",", "retrieval_out", "=", "model", "(", "encoded_dict", ",", "transformation_indices", ")", "\n", "abstract_preds", ".", "extend", "(", "abstract_out", ")", "\n", "abstract_labels", ".", "extend", "(", "batch", "[", "'abstract_label'", "]", ")", "\n", "\n", "rationale_predictions", ".", "extend", "(", "rationale_out", ")", "\n", "rationale_labels", ".", "extend", "(", "rationale_label", ")", "\n", "\n", "", "", "", "stance_f1", "=", "f1_score", "(", "abstract_labels", ",", "abstract_preds", ",", "average", "=", "\"micro\"", ",", "labels", "=", "[", "1", ",", "2", "]", ")", "\n", "stance_precision", "=", "precision_score", "(", "abstract_labels", ",", "abstract_preds", ",", "average", "=", "\"micro\"", ",", "labels", "=", "[", "1", ",", "2", "]", ")", "\n", "stance_recall", "=", "recall_score", "(", "abstract_labels", ",", "abstract_preds", ",", "average", "=", "\"micro\"", ",", "labels", "=", "[", "1", ",", "2", "]", ")", "\n", "rationale_f1", "=", "f1_score", "(", "flatten", "(", "rationale_labels", ")", ",", "flatten", "(", "rationale_predictions", ")", ")", "\n", "rationale_precision", "=", "precision_score", "(", "flatten", "(", "rationale_labels", ")", ",", "flatten", "(", "rationale_predictions", ")", ")", "\n", "rationale_recall", "=", "recall_score", "(", "flatten", "(", "rationale_labels", ")", ",", "flatten", "(", "rationale_predictions", ")", ")", "\n", "return", "stance_f1", ",", "stance_precision", ",", "stance_recall", ",", "rationale_f1", ",", "rationale_precision", ",", "rationale_recall", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.src.PreTraining.train_base": [[135, 200], ["os.path.join", "torch.device", "transformers.AutoTokenizer.from_pretrained", "embedding.jointmodel.JointModelClassifier", "model.to.to", "torch.optim.Adam", "transformers.get_cosine_schedule_with_warmup", "model.to.train", "os.path.join", "range", "torch.save", "parameters.append", "PreTraining.schedule_sample_p", "model.to.train", "tqdm.tqdm", "enumerate", "transformers.get_cosine_schedule_with_warmup.step", "torch.utils.data.Subset", "PreTraining.evaluation", "print", "torch.utils.data.Subset", "PreTraining.evaluation", "print", "os.path.join", "torch.save", "model.to.state_dict", "torch.cuda.is_available", "model.to.bert.parameters", "model.to.abstract_retrieval.parameters", "torch.utils.data.DataLoader", "dataset.encode.encode_paragraph", "utils.token_idx_by_sentence", "utils.get_rationale_label", "range", "range", "model.to.state_dict", "module.parameters", "tensor.to", "tensor.to", "padded_label.size", "model.to.", "loss.backward", "dataset.encode.encode_paragraph.items", "transformation_indices[].size", "torch.optim.Adam.step", "torch.optim.Adam.zero_grad", "tqdm.tqdm.set_description", "str", "batch[].to", "padded_label.to", "batch[].to", "int", "int", "int", "round", "round", "round", "round", "time.time", "loss.item", "abstract_loss.item", "rationale_loss.item", "sim_loss.item"], "function", ["home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.domain_adaptation_joint_paragraph_fine_tune.schedule_sample_p", "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.FEVER_stance_paragraph.evaluation", "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.FEVER_stance_paragraph.evaluation", "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.dataset.encode.encode_paragraph", "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.FEVER_stance_paragraph.token_idx_by_sentence", "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.src.utils.get_rationale_label"], ["", "def", "train_base", "(", "train_set", ",", "dev_set", ",", "args", ")", ":", "\n", "    ", "tmp_dir", "=", "os", ".", "path", ".", "join", "(", "os", ".", "path", ".", "curdir", ",", "'tmp-runs/'", ")", "\n", "device", "=", "torch", ".", "device", "(", "'cuda'", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "else", "'cpu'", ")", "\n", "tokenizer", "=", "AutoTokenizer", ".", "from_pretrained", "(", "args", ".", "model", ")", "\n", "# model = JointModelClassifier(args)", "\n", "model", "=", "JointModelClassifier", "(", "args", ")", "\n", "model", "=", "model", ".", "to", "(", "device", ")", "\n", "parameters", "=", "[", "{", "'params'", ":", "model", ".", "bert", ".", "parameters", "(", ")", ",", "'lr'", ":", "args", ".", "bert_lr", "}", ",", "\n", "{", "'params'", ":", "model", ".", "abstract_retrieval", ".", "parameters", "(", ")", ",", "'lr'", ":", "5e-6", "}", "]", "\n", "for", "module", "in", "model", ".", "extra_modules", ":", "\n", "        ", "parameters", ".", "append", "(", "{", "'params'", ":", "module", ".", "parameters", "(", ")", ",", "'lr'", ":", "args", ".", "lr", "}", ")", "\n", "", "optimizer", "=", "torch", ".", "optim", ".", "Adam", "(", "parameters", ")", "\n", "scheduler", "=", "get_cosine_schedule_with_warmup", "(", "optimizer", ",", "0", ",", "args", ".", "epochs", ")", "\n", "\"\"\"\n    \"\"\"", "\n", "model", ".", "train", "(", ")", "\n", "checkpoint", "=", "os", ".", "path", ".", "join", "(", "args", ".", "save", ",", "f'PreTrainingJointModel.model'", ")", "\n", "\n", "for", "epoch", "in", "range", "(", "args", ".", "epochs", ")", ":", "\n", "        ", "abstract_sample", ",", "rationale_sample", "=", "schedule_sample_p", "(", "epoch", ",", "args", ".", "epochs", "+", "10", ")", "\n", "model", ".", "train", "(", ")", "# cudnn RNN backward can only be called in training mode", "\n", "t", "=", "tqdm", "(", "DataLoader", "(", "train_set", ",", "batch_size", "=", "1", ",", "shuffle", "=", "True", ")", ")", "\n", "for", "i", ",", "batch", "in", "enumerate", "(", "t", ")", ":", "\n", "            ", "encoded_dict", "=", "encode_paragraph", "(", "tokenizer", ",", "batch", "[", "'claim'", "]", ",", "batch", "[", "'abstract'", "]", ")", "\n", "transformation_indices", "=", "token_idx_by_sentence", "(", "encoded_dict", "[", "\"input_ids\"", "]", ",", "tokenizer", ".", "sep_token_id", ",", "\n", "args", ".", "model", ")", "\n", "encoded_dict", "=", "{", "key", ":", "tensor", ".", "to", "(", "device", ")", "for", "key", ",", "tensor", "in", "encoded_dict", ".", "items", "(", ")", "}", "\n", "transformation_indices", "=", "[", "tensor", ".", "to", "(", "device", ")", "for", "tensor", "in", "transformation_indices", "]", "\n", "padded_label", ",", "rationale_label", "=", "get_rationale_label", "(", "batch", "[", "\"sentence_label\"", "]", ",", "padding_idx", "=", "2", ")", "\n", "if", "padded_label", ".", "size", "(", "1", ")", "==", "transformation_indices", "[", "-", "1", "]", ".", "size", "(", "1", ")", "-", "1", ":", "\n", "                ", "_", ",", "_", ",", "abstract_loss", ",", "rationale_loss", ",", "sim_loss", ",", "bce_loss", "=", "model", "(", "encoded_dict", ",", "transformation_indices", ",", "\n", "abstract_label", "=", "batch", "[", "'abstract_label'", "]", ".", "to", "(", "device", ")", ",", "\n", "rationale_label", "=", "padded_label", ".", "to", "(", "device", ")", ",", "\n", "retrieval_label", "=", "batch", "[", "'sim_label'", "]", ".", "to", "(", "device", ")", ",", "\n", "train", "=", "True", ",", "rationale_sample", "=", "rationale_sample", ")", "\n", "# [0.2, 1.1, 12.0]", "\n", "rationale_loss", "*=", "12", "\n", "abstract_loss", "*=", "1.1", "\n", "sim_loss", "*=", "0.2", "\n", "bce_loss", "*=", "1.9", "\n", "loss", "=", "abstract_loss", "+", "rationale_loss", "+", "sim_loss", "\n", "loss", ".", "backward", "(", ")", "\n", "if", "(", "i", "+", "1", ")", "%", "(", "args", ".", "batch_size_accumulated", "//", "args", ".", "batch_size_gpu", ")", "==", "0", ":", "\n", "                    ", "optimizer", ".", "step", "(", ")", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "t", ".", "set_description", "(", "f'Epoch {epoch}, iter {i}, loss: {round(loss.item(), 4)},'", "\n", "f' abstract loss: {round(abstract_loss.item(), 4)},'", "\n", "f' rationale loss: {round(rationale_loss.item(), 4)},'", "\n", "f' retrieval loss: {round(sim_loss.item(), 4)}'", ")", "\n", "", "", "", "scheduler", ".", "step", "(", ")", "\n", "subset_train", "=", "Subset", "(", "train_set", ",", "range", "(", "0", ",", "10000", ")", ")", "\n", "train_score", "=", "evaluation", "(", "model", ",", "subset_train", ",", "args", ",", "tokenizer", ")", "\n", "print", "(", "\n", "f'Epoch {epoch}, train abstract f1 p r: %.4f, %.4f, %.4f, rationale f1 p r: %.4f, %.4f, %.4f'", "%", "train_score", ")", "\n", "\n", "subset_dev", "=", "Subset", "(", "dev_set", ",", "range", "(", "0", ",", "10000", ")", ")", "\n", "dev_score", "=", "evaluation", "(", "model", ",", "subset_dev", ",", "args", ",", "tokenizer", ")", "\n", "print", "(", "\n", "f'Epoch {epoch}, train abstract f1 p r: %.4f, %.4f, %.4f, rationale f1 p r: %.4f, %.4f, %.4f'", "%", "dev_score", ")", "\n", "save_path", "=", "os", ".", "path", ".", "join", "(", "tmp_dir", ",", "str", "(", "int", "(", "time", ".", "time", "(", ")", "*", "1e5", ")", ")", "\n", "+", "f'-abstract_f1-{int(dev_score[0] * 1e4)}'", "\n", "+", "f'-rationale_f1-{int(dev_score[3] * 1e4)}.model'", ")", "\n", "torch", ".", "save", "(", "model", ".", "state_dict", "(", ")", ",", "save_path", ")", "\n", "", "torch", ".", "save", "(", "model", ".", "state_dict", "(", ")", ",", "checkpoint", ")", "\n", "return", "checkpoint", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.src.PreTraining.main": [[202, 232], ["numpy.random.seed", "random.seed", "torch.manual_seed", "PreTraining.parse_args", "PreTraining.printf", "transformers.AutoTokenizer.from_pretrained", "dataset.loader.FEVERParagraphBatchDataset", "dataset.loader.FEVERParagraphBatchDataset", "PreTraining.train_base", "embedding.jointmodel.JointModelClassifier", "transformers.AutoTokenizer.from_pretrained", "embedding.jointmodel.JointModelClassifier.load_state_dict", "torch.utils.data.Subset", "PreTraining.evaluation", "print", "torch.load", "range"], "function", ["home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.src.JointAbstractRetrieval.parse_args", "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.src.JointAbstractRetrieval.printf", "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.src.PreTraining.train_base", "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.FEVER_stance_paragraph.evaluation"], ["", "def", "main", "(", ")", ":", "\n", "    ", "seed", "=", "12345", "\n", "np", ".", "random", ".", "seed", "(", "seed", ")", "\n", "random", ".", "seed", "(", "seed", ")", "\n", "torch", ".", "manual_seed", "(", "seed", ")", "\n", "args", "=", "parse_args", "(", ")", "\n", "claim_train_path", "=", "args", ".", "claim_train_path", "\n", "claim_dev_path", "=", "args", ".", "claim_dev_path", "\n", "\n", "args", ".", "model", "=", "'dmis-lab/biobert-large-cased-v1.1-mnli'", "\n", "args", ".", "epochs", "=", "10", "\n", "args", ".", "bert_lr", "=", "1e-5", "\n", "args", ".", "lr", "=", "5e-6", "\n", "args", ".", "batch_size_gpu", "=", "8", "\n", "args", ".", "dropout", "=", "0", "\n", "args", ".", "k", "=", "30", "\n", "args", ".", "hidden_dim", "=", "1024", "# 768", "\n", "printf", "(", "args", ")", "\n", "k_train", "=", "5", "\n", "tokenizer", "=", "AutoTokenizer", ".", "from_pretrained", "(", "args", ".", "model", ")", "\n", "train_set", "=", "FEVERParagraphBatchDataset", "(", "claim_train_path", ",", "sep_token", "=", "tokenizer", ".", "sep_token", ",", "k", "=", "k_train", ")", "\n", "dev_set", "=", "FEVERParagraphBatchDataset", "(", "claim_dev_path", ",", "sep_token", "=", "tokenizer", ".", "sep_token", ",", "k", "=", "k_train", ")", "\n", "\n", "checkpoint", "=", "train_base", "(", "train_set", ",", "dev_set", ",", "args", ")", "\n", "model", "=", "JointModelClassifier", "(", "args", ")", "\n", "tokenizer", "=", "AutoTokenizer", ".", "from_pretrained", "(", "args", ".", "model", ")", "\n", "model", ".", "load_state_dict", "(", "torch", ".", "load", "(", "checkpoint", ")", ")", "\n", "subset_dev", "=", "Subset", "(", "dev_set", ",", "range", "(", "0", ",", "10000", ")", ")", "\n", "dev_score", "=", "evaluation", "(", "model", ",", "subset_dev", ",", "args", ",", "tokenizer", ")", "\n", "print", "(", "f'Test abstract f1 p r: %.4f, %.4f, %.4f, rationale f1 p r: %.4f, %.4f, %.4f'", "%", "dev_score", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.src.BM25AbstractRetrieval.parse_args": [[9, 19], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args"], "function", ["home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.src.JointAbstractRetrieval.parse_args"], ["def", "parse_args", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "\n", "description", "=", "\"BM25 abstract retrieval\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "'--claim_file'", ",", "type", "=", "str", ",", "default", "=", "'../data/claims_test.jsonl'", ")", "\n", "parser", ".", "add_argument", "(", "'--corpus_file'", ",", "type", "=", "str", ",", "default", "=", "'../data/corpus.jsonl'", ")", "\n", "parser", ".", "add_argument", "(", "'--k'", ",", "type", "=", "int", ",", "default", "=", "150", ")", "\n", "parser", ".", "add_argument", "(", "'--claim_retrieved_file'", ",", "type", "=", "str", ",", "default", "=", "'../data/claims_test_retrieved_BM25.jsonl'", ")", "\n", "\n", "return", "parser", ".", "parse_args", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.src.BM25AbstractRetrieval.main": [[21, 65], ["BM25AbstractRetrieval.parse_args", "corpus.items", "numpy.array", "gensim.corpora.Dictionary", "gensim.summarization.bm25.BM25", "open", "open", "corpus_texts.append", "np.array.append", "doc.split", "corpora.Dictionary.doc2bow", "corpora.Dictionary.doc2bow", "gensim.summarization.bm25.BM25.get_scores", "jsonlines.open", "sorted", "json.loads", "json.loads", "claims.append", "int", "claim[].split", "sorted", "list", "retrieved_corpus[].tolist", "output.write", "range", "claims_by_id.keys", "str", "len"], "function", ["home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.src.JointAbstractRetrieval.parse_args"], ["", "def", "main", "(", ")", ":", "\n", "\n", "    ", "args", "=", "parse_args", "(", ")", "\n", "\n", "claim_file", "=", "args", ".", "claim_file", "\n", "corpus_file", "=", "args", ".", "corpus_file", "\n", "\n", "corpus", "=", "{", "}", "\n", "with", "open", "(", "corpus_file", ")", "as", "f", ":", "\n", "        ", "for", "line", "in", "f", ":", "\n", "            ", "abstract", "=", "json", ".", "loads", "(", "line", ")", "\n", "corpus", "[", "str", "(", "abstract", "[", "\"doc_id\"", "]", ")", "]", "=", "abstract", "\n", "\n", "", "", "claims", "=", "[", "]", "\n", "with", "open", "(", "claim_file", ")", "as", "f", ":", "\n", "        ", "for", "line", "in", "f", ":", "\n", "            ", "claim", "=", "json", ".", "loads", "(", "line", ")", "\n", "claims", ".", "append", "(", "claim", ")", "\n", "", "", "claims_by_id", "=", "{", "claim", "[", "'id'", "]", ":", "claim", "for", "claim", "in", "claims", "}", "\n", "\n", "corpus_texts", "=", "[", "]", "\n", "corpus_ids", "=", "[", "]", "\n", "for", "k", ",", "v", "in", "corpus", ".", "items", "(", ")", ":", "\n", "        ", "original_sentences", "=", "[", "v", "[", "'title'", "]", "]", "+", "v", "[", "'abstract'", "]", "\n", "processed_paragraph", "=", "\" \"", ".", "join", "(", "original_sentences", ")", "\n", "corpus_texts", ".", "append", "(", "processed_paragraph", ")", "\n", "corpus_ids", ".", "append", "(", "k", ")", "\n", "", "corpus_ids", "=", "np", ".", "array", "(", "[", "int", "(", "ids", ")", "for", "ids", "in", "corpus_ids", "]", ")", "\n", "texts", "=", "[", "doc", ".", "split", "(", ")", "for", "doc", "in", "corpus_texts", "]", "# you can do preprocessing as removing stopwords", "\n", "dictionary", "=", "corpora", ".", "Dictionary", "(", "texts", ")", "\n", "corpus", "=", "[", "dictionary", ".", "doc2bow", "(", "text", ")", "for", "text", "in", "texts", "]", "\n", "bm25_obj", "=", "BM25", "(", "corpus", ")", "\n", "retrieved_corpus", "=", "{", "}", "\n", "for", "claim", "in", "claims", ":", "\n", "        ", "claims_doc", "=", "dictionary", ".", "doc2bow", "(", "claim", "[", "'claim'", "]", ".", "split", "(", ")", ")", "\n", "scores", "=", "bm25_obj", ".", "get_scores", "(", "claims_doc", ")", "\n", "idx", "=", "sorted", "(", "range", "(", "len", "(", "scores", ")", ")", ",", "key", "=", "lambda", "i", ":", "scores", "[", "i", "]", ",", "reverse", "=", "True", ")", "[", ":", "args", ".", "k", "]", "\n", "retrieved_corpus", "[", "claim", "[", "'id'", "]", "]", "=", "corpus_ids", "[", "idx", "]", "\n", "\n", "", "with", "jsonlines", ".", "open", "(", "args", ".", "claim_retrieved_file", ",", "'w'", ")", "as", "output", ":", "\n", "        ", "claim_ids", "=", "sorted", "(", "list", "(", "claims_by_id", ".", "keys", "(", ")", ")", ")", "\n", "for", "id", "in", "claim_ids", ":", "\n", "            ", "claims_by_id", "[", "id", "]", "[", "\"doc_ids\"", "]", "=", "retrieved_corpus", "[", "id", "]", ".", "tolist", "(", ")", "\n", "output", ".", "write", "(", "claims_by_id", "[", "id", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.src.ComputeBioSentVecAbstractractEmbedding.preprocess_sentence": [[12, 22], ["text.lower.replace", "text.lower.replace", "text.lower.replace", "text.lower.replace", "text.lower.lower", "nltk.word_tokenize"], "function", ["None"], ["def", "preprocess_sentence", "(", "text", ")", ":", "\n", "    ", "text", "=", "text", ".", "replace", "(", "'/'", ",", "' / '", ")", "\n", "text", "=", "text", ".", "replace", "(", "'.-'", ",", "' .- '", ")", "\n", "text", "=", "text", ".", "replace", "(", "'.'", ",", "' . '", ")", "\n", "text", "=", "text", ".", "replace", "(", "'\\''", ",", "' \\' '", ")", "\n", "text", "=", "text", ".", "lower", "(", ")", "\n", "\n", "tokens", "=", "[", "token", "for", "token", "in", "word_tokenize", "(", "text", ")", "if", "token", "not", "in", "punctuation", "and", "token", "not", "in", "stop_words", "]", "\n", "\n", "return", "' '", ".", "join", "(", "tokens", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.src.optunaMain.schedule_sample_p": [[24, 31], ["numpy.sin", "numpy.tanh"], "function", ["None"], ["def", "schedule_sample_p", "(", "epoch", ",", "total", ")", ":", "\n", "    ", "if", "epoch", "==", "total", "-", "1", ":", "\n", "        ", "abstract_sample", "=", "1.0", "\n", "", "else", ":", "\n", "        ", "abstract_sample", "=", "np", ".", "tanh", "(", "0.5", "*", "np", ".", "pi", "*", "epoch", "/", "(", "total", "-", "1", "-", "epoch", ")", ")", "\n", "", "rationale_sample", "=", "np", ".", "sin", "(", "0.5", "*", "np", ".", "pi", "*", "epoch", "/", "(", "total", "-", "1", ")", ")", "\n", "return", "abstract_sample", ",", "rationale_sample", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.src.optunaMain.get_predictions": [[33, 63], ["torch.device", "transformers.AutoTokenizer.from_pretrained", "model.eval", "torch.no_grad", "tqdm.tqdm", "torch.cuda.is_available", "torch.utils.data.DataLoader", "dataset.encode.encode_paragraph", "utils.token_idx_by_sentence", "model", "abstract_result.extend", "rationale_result.extend", "retrieval_result.extend", "tensor.to", "tensor.to", "dataset.encode.encode_paragraph.items"], "function", ["home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.dataset.encode.encode_paragraph", "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.FEVER_stance_paragraph.token_idx_by_sentence"], ["", "def", "get_predictions", "(", "args", ",", "input_set", ",", "model", ")", ":", "\n", "    ", "device", "=", "torch", ".", "device", "(", "'cuda'", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "else", "'cpu'", ")", "\n", "# args.batch_size_gpu = 8", "\n", "tokenizer", "=", "AutoTokenizer", ".", "from_pretrained", "(", "args", ".", "model", ")", "\n", "model", ".", "eval", "(", ")", "\n", "# for m in model.state_dict().keys():", "\n", "#     print(m)", "\n", "# p", "\n", "abstract_result", "=", "[", "]", "\n", "rationale_result", "=", "[", "]", "\n", "retrieval_result", "=", "[", "]", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "for", "batch", "in", "tqdm", "(", "DataLoader", "(", "input_set", ",", "batch_size", "=", "1", ",", "shuffle", "=", "False", ")", ")", ":", "\n", "            ", "encoded_dict", "=", "encode_paragraph", "(", "tokenizer", ",", "batch", "[", "'claim'", "]", ",", "batch", "[", "'abstract'", "]", ")", "\n", "# encoded = encode_paragraph(tokenizer, batch['claim'], batch['paragraph'])", "\n", "# encoded = {key: tensor.to(device) for key, tensor in encoded.items()}", "\n", "transformation_indices", "=", "token_idx_by_sentence", "(", "encoded_dict", "[", "'input_ids'", "]", ",", "tokenizer", ".", "sep_token_id", ",", "\n", "args", ".", "model", ")", "\n", "# match_indices = token_idx_by_sentence(encoded_dict[\"input_ids\"], tokenizer.sep_token_id,", "\n", "#                                       args.model, match=True)", "\n", "encoded_dict", "=", "{", "key", ":", "tensor", ".", "to", "(", "device", ")", "for", "key", ",", "tensor", "in", "encoded_dict", ".", "items", "(", ")", "}", "\n", "transformation_indices", "=", "[", "tensor", ".", "to", "(", "device", ")", "for", "tensor", "in", "transformation_indices", "]", "\n", "# match_indices = [tensor.to(device) for tensor in match_indices]", "\n", "# abstract_out, rationale_out = model(encoded_dict, transformation_indices, match_indices)", "\n", "abstract_out", ",", "rationale_out", ",", "retrieval_out", "=", "model", "(", "encoded_dict", ",", "transformation_indices", ")", "\n", "abstract_result", ".", "extend", "(", "abstract_out", ")", "\n", "rationale_result", ".", "extend", "(", "rationale_out", ")", "\n", "retrieval_result", ".", "extend", "(", "retrieval_out", ")", "\n", "\n", "", "", "return", "abstract_result", ",", "rationale_result", ",", "retrieval_result", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.src.optunaMain.parse_args": [[65, 115], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args"], "function", ["home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.src.JointAbstractRetrieval.parse_args"], ["", "def", "parse_args", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "\n", "description", "=", "'Evaluate SciFact predictions.'", "\n", ")", "\n", "# dataset parameters.", "\n", "parser", ".", "add_argument", "(", "'--corpus_path'", ",", "type", "=", "str", ",", "default", "=", "'../data/corpus.jsonl'", ",", "\n", "help", "=", "'The corpus of documents.'", ")", "\n", "parser", ".", "add_argument", "(", "'--claim_train_path'", ",", "type", "=", "str", ",", "\n", "default", "=", "'../data/optuna_train_data.jsonl'", ")", "\n", "parser", ".", "add_argument", "(", "'--claim_dev_path'", ",", "type", "=", "str", ",", "\n", "default", "=", "'../data/optuna_dev_data.jsonl'", ")", "\n", "parser", ".", "add_argument", "(", "'--claim_test_path'", ",", "type", "=", "str", ",", "\n", "default", "=", "'../data/optuna_dev_data.jsonl'", ")", "\n", "parser", ".", "add_argument", "(", "'--gold'", ",", "type", "=", "str", ",", "default", "=", "'../data/optuna_dev_data.jsonl'", ")", "\n", "parser", ".", "add_argument", "(", "'--abstract_retrieval'", ",", "type", "=", "str", ",", "\n", "default", "=", "'prediction/abstract_retrieval.jsonl'", ")", "\n", "parser", ".", "add_argument", "(", "'--rationale_selection'", ",", "type", "=", "str", ",", "\n", "default", "=", "'prediction/rationale_selection.jsonl'", ")", "\n", "parser", ".", "add_argument", "(", "'--save'", ",", "type", "=", "str", ",", "default", "=", "'model/'", ",", "\n", "help", "=", "'Folder to save the weights'", ")", "\n", "parser", ".", "add_argument", "(", "'--output_label'", ",", "type", "=", "str", ",", "default", "=", "'prediction/label_predictions.jsonl'", ")", "\n", "parser", ".", "add_argument", "(", "'--merge_results'", ",", "type", "=", "str", ",", "default", "=", "'prediction/merged_predictions.jsonl'", ")", "\n", "parser", ".", "add_argument", "(", "'--output'", ",", "type", "=", "str", ",", "default", "=", "'prediction/result_evaluation.json'", ",", "\n", "help", "=", "'The predictions.'", ")", "\n", "\n", "# model parameters.", "\n", "parser", ".", "add_argument", "(", "'--model'", ",", "type", "=", "str", ",", "default", "=", "''", ")", "\n", "parser", ".", "add_argument", "(", "'--epochs'", ",", "type", "=", "int", ",", "default", "=", "20", ")", "\n", "parser", ".", "add_argument", "(", "'--threshold'", ",", "type", "=", "float", ",", "default", "=", "0.5", ",", "required", "=", "False", ")", "\n", "parser", ".", "add_argument", "(", "'--only_rationale'", ",", "action", "=", "'store_true'", ")", "\n", "parser", ".", "add_argument", "(", "'--batch_size_gpu'", ",", "type", "=", "int", ",", "default", "=", "8", ",", "\n", "help", "=", "'The batch size to send through GPU'", ")", "\n", "parser", ".", "add_argument", "(", "'--batch-size-accumulated'", ",", "type", "=", "int", ",", "default", "=", "256", ",", "\n", "help", "=", "'The batch size for each gradient update'", ")", "\n", "parser", ".", "add_argument", "(", "'--bert-lr'", ",", "type", "=", "float", ",", "default", "=", "1e-5", ")", "\n", "parser", ".", "add_argument", "(", "'--lr'", ",", "type", "=", "float", ",", "default", "=", "5e-6", ")", "\n", "parser", ".", "add_argument", "(", "'--mode'", ",", "type", "=", "str", ",", "default", "=", "'claim_and_rationale'", ",", "\n", "choices", "=", "[", "'claim_and_rationale'", ",", "'only_claim'", ",", "'only_rationale'", "]", ")", "\n", "parser", ".", "add_argument", "(", "'--filter'", ",", "type", "=", "str", ",", "default", "=", "'structured'", ",", "\n", "choices", "=", "[", "'structured'", ",", "'unstructured'", "]", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--hidden_dim\"", ",", "type", "=", "int", ",", "default", "=", "1024", ",", "\n", "help", "=", "\"Hidden dimension\"", ")", "\n", "parser", ".", "add_argument", "(", "'--vocab_size'", ",", "type", "=", "int", ",", "default", "=", "31116", ")", "\n", "parser", ".", "add_argument", "(", "\"--dropout\"", ",", "type", "=", "float", ",", "default", "=", "0.5", ",", "help", "=", "\"drop rate\"", ")", "\n", "parser", ".", "add_argument", "(", "'--k'", ",", "type", "=", "int", ",", "default", "=", "10", ",", "help", "=", "\"number of abstract retrieval(training)\"", ")", "\n", "parser", ".", "add_argument", "(", "'--alpha'", ",", "type", "=", "int", ",", "default", "=", "0.1", ")", "\n", "parser", ".", "add_argument", "(", "'-lambdas'", ",", "type", "=", "int", ",", "default", "=", "[", "1", ",", "2", ",", "12", "]", ")", "\n", "\n", "return", "parser", ".", "parse_args", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.src.optunaMain.printf": [[117, 121], ["list", "print", "vars().keys", "print", "vars", "vars"], "function", ["None"], ["", "def", "printf", "(", "args", ")", ":", "\n", "    ", "for", "k", "in", "list", "(", "vars", "(", "args", ")", ".", "keys", "(", ")", ")", ":", "\n", "        ", "print", "(", "'%s: %s'", "%", "(", "k", ",", "vars", "(", "args", ")", "[", "k", "]", ")", ")", "\n", "", "print", "(", "'-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.src.optunaMain.main": [[123, 229], ["numpy.random.seed", "random.seed", "torch.manual_seed", "optunaMain.parse_args", "trial.suggest_float", "trial.suggest_float", "trial.suggest_float", "trial.suggest_float", "optunaMain.printf", "transformers.AutoTokenizer.from_pretrained", "dataset.loader.SciFactJointDataset", "dataset.loader.SciFactJointDataset", "dataset.loader.SciFactJointDataset", "torch.device", "transformers.AutoTokenizer.from_pretrained", "embedding.model.JointModelClassifier", "model.to.to", "torch.optim.Adam", "transformers.get_cosine_schedule_with_warmup", "model.to.train", "range", "optunaMain.get_predictions", "utils.predictions2jsonl", "print", "evaluation.evaluation_model.evaluate_rationale_selection", "print", "evaluation.evaluation_model.evaluate_label_predictions", "print", "evaluation.evaluation_model.merge_rationale_label", "res.to_dict.to_dict", "parameters.append", "optunaMain.schedule_sample_p", "model.to.train", "tqdm.tqdm", "enumerate", "transformers.get_cosine_schedule_with_warmup.step", "evaluation.evaluation_model.evaluation_abstract_retrieval", "print", "evaluation.evaluation_model.evaluation_abstract_retrieval", "print", "torch.cuda.is_available", "model.to.bert.parameters", "model.to.abstract_retrieval.parameters", "torch.utils.data.DataLoader", "dataset.encode.encode_paragraph", "utils.token_idx_by_sentence", "utils.get_rationale_label", "model.to.", "loss.backward", "module.parameters", "tensor.to", "tensor.to", "torch.optim.Adam.step", "torch.optim.Adam.zero_grad", "tqdm.tqdm.set_description", "dataset.encode.encode_paragraph.items", "batch[].to", "padded_label.to", "batch[].to", "round", "round", "round", "round", "round", "loss.item", "abstract_loss.item", "rationale_loss.item", "sim_loss.item", "bce_loss.item"], "function", ["home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.src.JointAbstractRetrieval.parse_args", "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.src.JointAbstractRetrieval.printf", "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.src.optunaMain.get_predictions", "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.src.utils.predictions2jsonl", "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.evaluation.evaluation_model.evaluate_rationale_selection", "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.evaluation.evaluation_model.evaluate_label_predictions", "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.evaluation.evaluation_model.merge_rationale_label", "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.domain_adaptation_joint_paragraph_fine_tune.schedule_sample_p", "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.evaluation.evaluation_model.evaluation_abstract_retrieval", "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.evaluation.evaluation_model.evaluation_abstract_retrieval", "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.dataset.encode.encode_paragraph", "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.FEVER_stance_paragraph.token_idx_by_sentence", "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.src.utils.get_rationale_label"], ["", "def", "main", "(", "trial", ")", ":", "\n", "    ", "seed", "=", "12345", "\n", "np", ".", "random", ".", "seed", "(", "seed", ")", "\n", "random", ".", "seed", "(", "seed", ")", "\n", "torch", ".", "manual_seed", "(", "seed", ")", "\n", "args", "=", "parse_args", "(", ")", "\n", "# loader dataset", "\n", "split", "=", "True", "\n", "if", "split", ":", "\n", "# split_dataset('../data/claims_train_retrieval.jsonl')", "\n", "        ", "claim_train_path", "=", "'../data/optuna_train_data.jsonl'", "\n", "claim_dev_path", "=", "'../data/optuna_dev_data.jsonl'", "\n", "claim_test_path", "=", "'../data/optuna_dev_data.jsonl'", "\n", "# print(claim_test_path)", "\n", "", "else", ":", "\n", "        ", "claim_train_path", "=", "args", ".", "claim_train_path", "\n", "claim_dev_path", "=", "args", ".", "claim_dev_path", "\n", "claim_test_path", "=", "args", ".", "claim_dev_path", "\n", "\n", "# args.model = 'allenai/scibert_scivocab_cased'", "\n", "# args.model = 'model/SciBert_checkpoint'", "\n", "", "args", ".", "model", "=", "'dmis-lab/biobert-large-cased-v1.1-mnli'", "\n", "# args.model = 'roberta-large'", "\n", "args", ".", "epochs", "=", "20", "\n", "args", ".", "bert_lr", "=", "1e-5", "\n", "args", ".", "lr", "=", "5e-6", "\n", "args", ".", "batch_size_gpu", "=", "8", "\n", "args", ".", "dropout", "=", "0", "\n", "args", ".", "k", "=", "30", "\n", "args", ".", "hidden_dim", "=", "1024", "# 768", "\n", "args", ".", "alpha", "=", "trial", ".", "suggest_float", "(", "'alpha'", ",", "0.0", ",", "1", ")", "\n", "args", ".", "lambdas", "[", "0", "]", "=", "trial", ".", "suggest_float", "(", "'retrieval_lambda'", ",", "0.0", ",", "1.0", ")", "\n", "args", ".", "lambdas", "[", "1", "]", "=", "trial", ".", "suggest_float", "(", "'abstract_lambda'", ",", "0.0", ",", "1.0", "-", "args", ".", "lambdas", "[", "0", "]", ")", "\n", "args", ".", "lambdas", "[", "2", "]", "=", "trial", ".", "suggest_float", "(", "'rationale_lambda'", ",", "1.0", "-", "args", ".", "lambdas", "[", "0", "]", "-", "args", ".", "lambdas", "[", "1", "]", ",", "1.0", "-", "args", ".", "lambdas", "[", "0", "]", "-", "args", ".", "lambdas", "[", "1", "]", ")", "\n", "printf", "(", "args", ")", "\n", "k_train", "=", "12", "\n", "tokenizer", "=", "AutoTokenizer", ".", "from_pretrained", "(", "args", ".", "model", ")", "\n", "train_set", "=", "SciFactJointDataset", "(", "args", ".", "corpus_path", ",", "claim_train_path", ",", "sep_token", "=", "tokenizer", ".", "sep_token", ",", "k", "=", "k_train", ")", "\n", "dev_set", "=", "SciFactJointDataset", "(", "args", ".", "corpus_path", ",", "claim_dev_path", ",", "sep_token", "=", "tokenizer", ".", "sep_token", ",", "k", "=", "k_train", ",", "\n", "down_sampling", "=", "False", ")", "\n", "test_set", "=", "SciFactJointDataset", "(", "args", ".", "corpus_path", ",", "claim_test_path", ",", "\n", "sep_token", "=", "tokenizer", ".", "sep_token", ",", "k", "=", "args", ".", "k", ",", "train", "=", "False", ",", "down_sampling", "=", "False", ")", "\n", "\n", "# _, test_set = train_test_split(test_set, test_size=0.1)", "\n", "\n", "# test_set = Subset(test_set, range(0, 900))", "\n", "device", "=", "torch", ".", "device", "(", "'cuda'", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "else", "'cpu'", ")", "\n", "tokenizer", "=", "AutoTokenizer", ".", "from_pretrained", "(", "args", ".", "model", ")", "\n", "model", "=", "JointModelClassifier", "(", "args", ")", "\n", "model", "=", "model", ".", "to", "(", "device", ")", "\n", "parameters", "=", "[", "{", "'params'", ":", "model", ".", "bert", ".", "parameters", "(", ")", ",", "'lr'", ":", "args", ".", "bert_lr", "}", ",", "\n", "{", "'params'", ":", "model", ".", "abstract_retrieval", ".", "parameters", "(", ")", ",", "'lr'", ":", "5e-6", "}", "]", "\n", "for", "module", "in", "model", ".", "extra_modules", ":", "\n", "        ", "parameters", ".", "append", "(", "{", "'params'", ":", "module", ".", "parameters", "(", ")", ",", "'lr'", ":", "args", ".", "lr", "}", ")", "\n", "", "optimizer", "=", "torch", ".", "optim", ".", "Adam", "(", "parameters", ")", "\n", "scheduler", "=", "get_cosine_schedule_with_warmup", "(", "optimizer", ",", "0", ",", "args", ".", "epochs", ")", "\n", "model", ".", "train", "(", ")", "\n", "for", "epoch", "in", "range", "(", "args", ".", "epochs", ")", ":", "\n", "        ", "abstract_sample", ",", "rationale_sample", "=", "schedule_sample_p", "(", "epoch", ",", "args", ".", "epochs", "+", "10", ")", "\n", "model", ".", "train", "(", ")", "# cudnn RNN backward can only be called in training mode", "\n", "t", "=", "tqdm", "(", "DataLoader", "(", "train_set", ",", "batch_size", "=", "1", ",", "shuffle", "=", "True", ")", ")", "\n", "for", "i", ",", "batch", "in", "enumerate", "(", "t", ")", ":", "\n", "            ", "encoded_dict", "=", "encode_paragraph", "(", "tokenizer", ",", "batch", "[", "'claim'", "]", ",", "batch", "[", "'abstract'", "]", ")", "\n", "transformation_indices", "=", "token_idx_by_sentence", "(", "encoded_dict", "[", "\"input_ids\"", "]", ",", "tokenizer", ".", "sep_token_id", ",", "\n", "args", ".", "model", ")", "\n", "encoded_dict", "=", "{", "key", ":", "tensor", ".", "to", "(", "device", ")", "for", "key", ",", "tensor", "in", "encoded_dict", ".", "items", "(", ")", "}", "\n", "transformation_indices", "=", "[", "tensor", ".", "to", "(", "device", ")", "for", "tensor", "in", "transformation_indices", "]", "\n", "padded_label", ",", "rationale_label", "=", "get_rationale_label", "(", "batch", "[", "\"sentence_label\"", "]", ",", "padding_idx", "=", "2", ")", "\n", "_", ",", "_", ",", "abstract_loss", ",", "rationale_loss", ",", "sim_loss", ",", "bce_loss", "=", "model", "(", "encoded_dict", ",", "transformation_indices", ",", "\n", "abstract_label", "=", "batch", "[", "'abstract_label'", "]", ".", "to", "(", "device", ")", ",", "\n", "rationale_label", "=", "padded_label", ".", "to", "(", "device", ")", ",", "\n", "retrieval_label", "=", "batch", "[", "'sim_label'", "]", ".", "to", "(", "device", ")", ",", "\n", "train", "=", "True", ",", "rationale_sample", "=", "rationale_sample", ")", "\n", "rationale_loss", "*=", "args", ".", "lambdas", "[", "2", "]", "\n", "abstract_loss", "*=", "args", ".", "lambdas", "[", "1", "]", "\n", "sim_loss", "*=", "args", ".", "lambdas", "[", "0", "]", "\n", "bce_loss", "=", "args", ".", "alpha", "*", "bce_loss", "\n", "loss", "=", "abstract_loss", "+", "rationale_loss", "+", "sim_loss", "+", "bce_loss", "\n", "loss", ".", "backward", "(", ")", "\n", "if", "(", "i", "+", "1", ")", "%", "(", "args", ".", "batch_size_accumulated", "//", "args", ".", "batch_size_gpu", ")", "==", "0", ":", "\n", "                ", "optimizer", ".", "step", "(", ")", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "t", ".", "set_description", "(", "f'Epoch {epoch}, iter {i}, loss: {round(loss.item(), 4)},'", "\n", "f' abstract loss: {round(abstract_loss.item(), 4)},'", "\n", "f' rationale loss: {round(rationale_loss.item(), 4)},'", "\n", "f' retrieval loss: {round(sim_loss.item(), 4)},'", "\n", "f' BCE loss: {round(bce_loss.item(), 4)}'", ")", "\n", "", "", "scheduler", ".", "step", "(", ")", "\n", "train_score", "=", "evaluation_abstract_retrieval", "(", "model", ",", "train_set", ",", "args", ",", "tokenizer", ")", "\n", "print", "(", "f'Epoch {epoch} train retrieval score:'", ",", "train_score", ")", "\n", "dev_score", "=", "evaluation_abstract_retrieval", "(", "model", ",", "dev_set", ",", "args", ",", "tokenizer", ")", "\n", "print", "(", "f'Epoch {epoch} dev abstract score:'", ",", "dev_score", ")", "\n", "# test_score = evaluation_abstract_retrieval(model, dev_set, args, tokenizer)", "\n", "# return test_score['abstract_recall']", "\n", "", "abstract_result", ",", "rationale_result", ",", "retrieval_result", "=", "get_predictions", "(", "args", ",", "test_set", ",", "model", ")", "\n", "rationales", ",", "labels", "=", "predictions2jsonl", "(", "test_set", ",", "abstract_result", ",", "rationale_result", ")", "\n", "# # merge(rationales, labels, args.merge_results)", "\n", "print", "(", "'rationale selection...'", ")", "\n", "evaluate_rationale_selection", "(", "args", ",", "\"prediction/rationale_selection.jsonl\"", ")", "\n", "print", "(", "'label predictions...'", ")", "\n", "evaluate_label_predictions", "(", "args", ",", "\"prediction/label_predictions.jsonl\"", ")", "\n", "print", "(", "'merging predictions...'", ")", "\n", "res", "=", "merge_rationale_label", "(", "rationales", ",", "labels", ",", "args", ",", "state", "=", "'valid'", ",", "gold", "=", "args", ".", "gold", ")", "\n", "res", "=", "res", ".", "to_dict", "(", ")", "\n", "return", "res", "[", "'sentence_selection'", "]", "[", "'f1'", "]", ",", "res", "[", "'sentence_label'", "]", "[", "'f1'", "]", ",", "res", "[", "'abstract_label_only'", "]", "[", "'f1'", "]", ",", "res", "[", "'abstract_rationalized'", "]", "[", "'f1'", "]", "\n", "# return (res['sentence_selection']['f1'] + res['sentence_label']['f1'] + res['abstract_label_only']['f1'] + res['abstract_rationalized']['f1']) / 4", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.src.JointAbstractRetrieval.parse_args": [[15, 66], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args"], "function", ["home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.src.JointAbstractRetrieval.parse_args"], ["def", "parse_args", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "\n", "description", "=", "'Evaluate SciFact predictions.'", "\n", ")", "\n", "# dataset parameters.", "\n", "parser", ".", "add_argument", "(", "'--corpus_path'", ",", "type", "=", "str", ",", "default", "=", "'../data/corpus.jsonl'", ",", "\n", "help", "=", "'The corpus of documents.'", ")", "\n", "parser", ".", "add_argument", "(", "'--claim_train_path'", ",", "type", "=", "str", ",", "\n", "default", "=", "'../data/claims_train_retrieved.jsonl'", ")", "\n", "parser", ".", "add_argument", "(", "'--claim_dev_path'", ",", "type", "=", "str", ",", "\n", "default", "=", "'../data/claims_dev_retrieved.jsonl'", ")", "\n", "parser", ".", "add_argument", "(", "'--claim_test_path'", ",", "type", "=", "str", ",", "\n", "default", "=", "'../data/claims_dev_retrieved.jsonl'", ")", "\n", "parser", ".", "add_argument", "(", "'--gold'", ",", "type", "=", "str", ",", "default", "=", "'../data/claims_dev.jsonl'", ")", "\n", "parser", ".", "add_argument", "(", "'--abstract_retrieval'", ",", "type", "=", "str", ",", "\n", "default", "=", "'prediction/abstract_retrieval.jsonl'", ")", "\n", "parser", ".", "add_argument", "(", "'--rationale_selection'", ",", "type", "=", "str", ",", "\n", "default", "=", "'prediction/rationale_selection.jsonl'", ")", "\n", "parser", ".", "add_argument", "(", "'--save'", ",", "type", "=", "str", ",", "default", "=", "'model/'", ",", "\n", "help", "=", "'Folder to save the weights'", ")", "\n", "parser", ".", "add_argument", "(", "'--output_label'", ",", "type", "=", "str", ",", "default", "=", "'prediction/label_predictions.jsonl'", ")", "\n", "parser", ".", "add_argument", "(", "'--merge_results'", ",", "type", "=", "str", ",", "default", "=", "'prediction/merged_predictions.jsonl'", ")", "\n", "parser", ".", "add_argument", "(", "'--output'", ",", "type", "=", "str", ",", "default", "=", "'prediction/result_evaluation.json'", ",", "\n", "help", "=", "'The predictions.'", ")", "\n", "parser", ".", "add_argument", "(", "'--pre_trained_model'", ",", "type", "=", "str", ")", "\n", "\n", "# model parameters.", "\n", "parser", ".", "add_argument", "(", "'--model'", ",", "type", "=", "str", ",", "default", "=", "''", ")", "\n", "parser", ".", "add_argument", "(", "'--epochs'", ",", "type", "=", "int", ",", "default", "=", "20", ")", "\n", "parser", ".", "add_argument", "(", "'--threshold'", ",", "type", "=", "float", ",", "default", "=", "0.5", ",", "required", "=", "False", ")", "\n", "parser", ".", "add_argument", "(", "'--only_rationale'", ",", "action", "=", "'store_true'", ")", "\n", "parser", ".", "add_argument", "(", "'--batch_size_gpu'", ",", "type", "=", "int", ",", "default", "=", "8", ",", "\n", "help", "=", "'The batch size to send through GPU'", ")", "\n", "parser", ".", "add_argument", "(", "'--batch-size-accumulated'", ",", "type", "=", "int", ",", "default", "=", "256", ",", "\n", "help", "=", "'The batch size for each gradient update'", ")", "\n", "parser", ".", "add_argument", "(", "'--bert-lr'", ",", "type", "=", "float", ",", "default", "=", "1e-5", ")", "\n", "parser", ".", "add_argument", "(", "'--lr'", ",", "type", "=", "float", ",", "default", "=", "5e-6", ")", "\n", "parser", ".", "add_argument", "(", "'--mode'", ",", "type", "=", "str", ",", "default", "=", "'claim_and_rationale'", ",", "\n", "choices", "=", "[", "'claim_and_rationale'", ",", "'only_claim'", ",", "'only_rationale'", "]", ")", "\n", "parser", ".", "add_argument", "(", "'--filter'", ",", "type", "=", "str", ",", "default", "=", "'structured'", ",", "\n", "choices", "=", "[", "'structured'", ",", "'unstructured'", "]", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--hidden_dim\"", ",", "type", "=", "int", ",", "default", "=", "1024", ",", "\n", "help", "=", "\"Hidden dimension\"", ")", "\n", "parser", ".", "add_argument", "(", "'--vocab_size'", ",", "type", "=", "int", ",", "default", "=", "31116", ")", "\n", "parser", ".", "add_argument", "(", "\"--dropout\"", ",", "type", "=", "float", ",", "default", "=", "0.5", ",", "help", "=", "\"drop rate\"", ")", "\n", "parser", ".", "add_argument", "(", "'--k'", ",", "type", "=", "int", ",", "default", "=", "10", ",", "help", "=", "\"number of abstract retrieval(training)\"", ")", "\n", "parser", ".", "add_argument", "(", "'--alpha'", ",", "type", "=", "float", ",", "default", "=", "0.0", ")", "\n", "parser", ".", "add_argument", "(", "'--lambdas'", ",", "type", "=", "float", ",", "default", "=", "[", "1", ",", "2", ",", "12", "]", ")", "\n", "\n", "return", "parser", ".", "parse_args", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.src.JointAbstractRetrieval.printf": [[68, 76], ["list", "print", "vars().keys", "print", "print", "print", "vars", "vars"], "function", ["None"], ["", "def", "printf", "(", "args", ",", "split", ")", ":", "\n", "    ", "for", "k", "in", "list", "(", "vars", "(", "args", ")", ".", "keys", "(", ")", ")", ":", "\n", "        ", "print", "(", "'%s: %s'", "%", "(", "k", ",", "vars", "(", "args", ")", "[", "k", "]", ")", ")", "\n", "", "if", "split", ":", "\n", "        ", "print", "(", "'split: True'", ")", "\n", "", "else", ":", "\n", "        ", "print", "(", "'split: False'", ")", "\n", "", "print", "(", "'-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.src.JointAbstractRetrieval.main": [[78, 135], ["numpy.random.seed", "random.seed", "torch.manual_seed", "JointAbstractRetrieval.parse_args", "torch.device", "JointAbstractRetrieval.printf", "transformers.AutoTokenizer.from_pretrained", "dataset.loader.SciFactJointDataset", "dataset.loader.SciFactJointDataset", "dataset.loader.SciFactJointDataset", "get_prediction.get_predictions", "utils.predictions2jsonl", "utils.retrieval2jsonl", "torch.cuda.is_available"], "function", ["home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.src.JointAbstractRetrieval.parse_args", "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.src.JointAbstractRetrieval.printf", "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.src.optunaMain.get_predictions", "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.src.utils.predictions2jsonl", "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.src.utils.retrieval2jsonl"], ["", "def", "main", "(", ")", ":", "\n", "    ", "seed", "=", "12345", "\n", "np", ".", "random", ".", "seed", "(", "seed", ")", "\n", "random", ".", "seed", "(", "seed", ")", "\n", "torch", ".", "manual_seed", "(", "seed", ")", "\n", "args", "=", "parse_args", "(", ")", "\n", "device", "=", "torch", ".", "device", "(", "'cuda'", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "else", "'cpu'", ")", "\n", "# loader dataset", "\n", "split", "=", "False", "\n", "if", "split", ":", "\n", "# split_dataset('../data/claims_train_retrieval.jsonl')", "\n", "        ", "claim_train_path", "=", "'../data/train_data_Bio.jsonl'", "\n", "claim_dev_path", "=", "'../data/dev_data_Bio.jsonl'", "\n", "claim_test_path", "=", "'../data/claims_dev_retrieved.jsonl'", "\n", "# print(claim_test_path)", "\n", "", "else", ":", "\n", "        ", "claim_train_path", "=", "args", ".", "claim_train_path", "\n", "claim_dev_path", "=", "args", ".", "claim_dev_path", "\n", "claim_test_path", "=", "args", ".", "claim_dev_path", "\n", "\n", "# args.model = 'allenai/scibert_scivocab_cased'", "\n", "# args.model = 'model/SciBert_checkpoint'", "\n", "# args.pre_trained_model = 'model/pre-train.model'", "\n", "", "args", ".", "model", "=", "'dmis-lab/biobert-large-cased-v1.1-mnli'", "\n", "# args.model = 'roberta-large'", "\n", "args", ".", "epochs", "=", "40", "\n", "args", ".", "bert_lr", "=", "1e-5", "\n", "args", ".", "lr", "=", "5e-6", "\n", "args", ".", "batch_size_gpu", "=", "8", "\n", "args", ".", "dropout", "=", "0", "\n", "args", ".", "k", "=", "30", "\n", "args", ".", "hidden_dim", "=", "1024", "# 768/1024", "\n", "# args.alpha = 1.9  # BioBert-large", "\n", "# args.alpha = 2.2  # RoBerta-large", "\n", "args", ".", "alpha", "=", "2.7", "# BioBert-large share", "\n", "# args.lambdas = [0.2, 1.1, 12.0]  # BioBert-large w   /get", "\n", "# args.lambdas = [0.9, 2.6, 11.1]  # RoBerta-large w", "\n", "# args.lambdas = [0.1, 4.7, 10.8]  # BioBert-large w/o /get", "\n", "# args.lambdas = [2.7, 2.2, 11.7]  # RoBerta-large w/o", "\n", "args", ".", "lambdas", "=", "[", "1.6", ",", "2.5", ",", "9.5", "]", "# # BioBert-large share w", "\n", "printf", "(", "args", ",", "split", ")", "\n", "k_train", "=", "12", "\n", "tokenizer", "=", "AutoTokenizer", ".", "from_pretrained", "(", "args", ".", "model", ")", "\n", "train_set", "=", "SciFactJointDataset", "(", "args", ".", "corpus_path", ",", "claim_train_path", ",", "sep_token", "=", "tokenizer", ".", "sep_token", ",", "k", "=", "k_train", ")", "\n", "dev_set", "=", "SciFactJointDataset", "(", "args", ".", "corpus_path", ",", "claim_dev_path", ",", "sep_token", "=", "tokenizer", ".", "sep_token", ",", "k", "=", "k_train", ",", "\n", "down_sampling", "=", "False", ")", "\n", "test_set", "=", "SciFactJointDataset", "(", "args", ".", "corpus_path", ",", "claim_test_path", ",", "\n", "sep_token", "=", "tokenizer", ".", "sep_token", ",", "k", "=", "args", ".", "k", ",", "train", "=", "False", ",", "down_sampling", "=", "False", ")", "\n", "# test_set = SciFactJointPredictionData(args.corpus_path, claim_test_path, sep_token=tokenizer.sep_token)", "\n", "# print(test_set.samples[0])", "\n", "# checkpoint = train_base(train_set, dev_set, args)", "\n", "checkpoint", "=", "'model/BioBert_large_w.model'", "\n", "# checkpoint = 'tmp-runs/162030701614073-abstract_f1-6925-rationale_f1-6753.model'", "\n", "# print(checkpoint)", "\n", "abstract_result", ",", "rationale_result", ",", "retrieval_result", "=", "get_predictions", "(", "args", ",", "test_set", ",", "checkpoint", ")", "\n", "rationales", ",", "labels", "=", "predictions2jsonl", "(", "test_set", ".", "samples", ",", "abstract_result", ",", "rationale_result", ")", "\n", "retrieval2jsonl", "(", "test_set", ".", "samples", ",", "retrieval_result", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.src.utils.token_idx_by_sentence": [[9, 58], ["torch.sum().numpy().tolist", "torch.sum().numpy().tolist", "torch.arange().unsqueeze().expand", "torch.arange().unsqueeze().expand", "torch.split", "torch.split", "torch.utils.rnn.pad_sequence", "torch.split", "torch.split", "torch.utils.rnn.pad_sequence", "torch.arange().unsqueeze().unsqueeze().expand", "torch.arange().unsqueeze().unsqueeze().expand", "sep_tokens.size", "range", "range", "torch.sum().numpy().tolist.append", "all_word_indices.extend", "nn.utils.rnn.pad_sequence.size", "nn.utils.rnn.pad_sequence.size", "torch.arange().unsqueeze().unsqueeze().expand.long", "nn.utils.rnn.pad_sequence.long", "mask.long", "torch.sum().numpy", "torch.sum().numpy", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "len", "len", "torch.arange", "torch.arange", "len", "torch.arange().unsqueeze().unsqueeze", "torch.arange().unsqueeze().unsqueeze", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "range", "torch.sum", "torch.sum", "torch.arange", "torch.arange", "[].tolist", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "sep_tokens.size", "[].tolist", "paragraph.size", "torch.arange", "torch.arange", "numpy.array", "sep_tokens.size", "numpy.array"], "function", ["None"], ["def", "token_idx_by_sentence", "(", "input_ids", ",", "sep_token_id", ",", "model_name", ",", "match", "=", "False", ")", ":", "\n", "    ", "\"\"\"\n    Compute the token indices matrix of the BERT output.\n    input_ids: (batch_size, paragraph_len)\n    batch_indices, indices_by_batch, mask: (batch_size, N_sentence, N_token)\n    bert_out: (batch_size, paragraph_len,BERT_dim)\n    bert_out[batch_indices,indices_by_batch,:]: (batch_size, N_sentence, N_token, BERT_dim)\n    \"\"\"", "\n", "padding_idx", "=", "-", "1", "\n", "sep_tokens", "=", "(", "input_ids", "==", "sep_token_id", ")", ".", "bool", "(", ")", "\n", "paragraph_lens", "=", "torch", ".", "sum", "(", "sep_tokens", ",", "1", ")", ".", "numpy", "(", ")", ".", "tolist", "(", ")", "\n", "indices", "=", "torch", ".", "arange", "(", "sep_tokens", ".", "size", "(", "-", "1", ")", ")", ".", "unsqueeze", "(", "0", ")", ".", "expand", "(", "sep_tokens", ".", "size", "(", "0", ")", ",", "-", "1", ")", "\n", "sep_indices", "=", "torch", ".", "split", "(", "indices", "[", "sep_tokens", "]", ",", "paragraph_lens", ")", "\n", "if", "match", ":", "\n", "        ", "tmp_indices", "=", "(", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "sep_indices", ")", ")", ":", "\n", "            ", "tmp_indices", "+=", "(", "torch", ".", "tensor", "(", "np", ".", "array", "(", "sep_indices", "[", "i", "]", ")", "[", "[", "0", ",", "-", "1", "]", "]", ".", "tolist", "(", ")", ")", ",", ")", "\n", "", "sep_indices", "=", "tmp_indices", "\n", "", "else", ":", "\n", "        ", "tmp_indices", "=", "(", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "sep_indices", ")", ")", ":", "\n", "            ", "tmp_indices", "+=", "(", "torch", ".", "tensor", "(", "[", "0", "]", "+", "np", ".", "array", "(", "sep_indices", "[", "i", "]", ")", "[", ":", "]", ".", "tolist", "(", ")", ")", ",", ")", "\n", "", "sep_indices", "=", "tmp_indices", "\n", "# else:", "\n", "#     tmp_indices = ()", "\n", "#     for i in range(len(sep_indices)):", "\n", "#         tmp_indices += (torch.tensor(np.array(sep_indices[i])[1: len(sep_indices[i])].tolist()),)  # del title", "\n", "#     sep_indices = tmp_indices", "\n", "", "paragraph_lens", "=", "[", "]", "\n", "all_word_indices", "=", "[", "]", "\n", "for", "paragraph", "in", "sep_indices", ":", "\n", "        ", "if", "\"large\"", "in", "model_name", "and", "(", "'biobert'", "not", "in", "model_name", ")", ":", "\n", "            ", "paragraph", "=", "paragraph", "[", "1", ":", "]", "\n", "", "word_indices", "=", "[", "torch", ".", "arange", "(", "paragraph", "[", "i", "]", "+", "1", ",", "paragraph", "[", "i", "+", "1", "]", "+", "1", ")", "for", "i", "in", "range", "(", "paragraph", ".", "size", "(", "0", ")", "-", "1", ")", "]", "\n", "paragraph_lens", ".", "append", "(", "len", "(", "word_indices", ")", ")", "\n", "all_word_indices", ".", "extend", "(", "word_indices", ")", "\n", "# pad_sequence: stacks a list of Tensors along a new dimension, and pads them to equal length.", "\n", "", "indices_by_sentence", "=", "nn", ".", "utils", ".", "rnn", ".", "pad_sequence", "(", "all_word_indices", ",", "batch_first", "=", "True", ",", "padding_value", "=", "padding_idx", ")", "\n", "indices_by_sentence_split", "=", "torch", ".", "split", "(", "indices_by_sentence", ",", "paragraph_lens", ")", "\n", "indices_by_batch", "=", "nn", ".", "utils", ".", "rnn", ".", "pad_sequence", "(", "indices_by_sentence_split", ",", "batch_first", "=", "True", ",", "padding_value", "=", "padding_idx", ")", "\n", "# if match:", "\n", "#     padd2maxlen = torch.tensor([[-1 for _ in range(indices_by_batch.shape[2], 512)] for _ in range(2)]).unsqueeze(0)", "\n", "#     indices_by_batch = torch.cat([indices_by_batch, padd2maxlen], 2)", "\n", "batch_indices", "=", "torch", ".", "arange", "(", "sep_tokens", ".", "size", "(", "0", ")", ")", ".", "unsqueeze", "(", "-", "1", ")", ".", "unsqueeze", "(", "-", "1", ")", ".", "expand", "(", "-", "1", ",", "\n", "indices_by_batch", ".", "size", "(", "1", ")", ",", "\n", "indices_by_batch", ".", "size", "(", "-", "1", ")", ")", "\n", "mask", "=", "(", "indices_by_batch", ">=", "0", ")", "\n", "\n", "return", "batch_indices", ".", "long", "(", ")", ",", "indices_by_batch", ".", "long", "(", ")", ",", "mask", ".", "long", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.src.utils.get_rationale_label": [[60, 75], ["max", "enumerate", "torch.ones", "torch.ones", "enumerate", "label_list.append", "label_matrix.long", "len", "len", "int", "int"], "function", ["None"], ["", "def", "get_rationale_label", "(", "labels", ",", "padding_idx", "=", "2", ")", ":", "\n", "    ", "'''\n    \"padding label\"\n    :param labels: sentence labels\n    :param padding_idx: padding id\n    :return: label after padding and original label\n    '''", "\n", "max_label_len", "=", "max", "(", "[", "len", "(", "label", ")", "for", "label", "in", "labels", "]", ")", "\n", "label_matrix", "=", "torch", ".", "ones", "(", "len", "(", "labels", ")", ",", "max_label_len", ")", "*", "padding_idx", "\n", "label_list", "=", "[", "]", "\n", "for", "i", ",", "label", "in", "enumerate", "(", "labels", ")", ":", "\n", "        ", "for", "j", ",", "e", "in", "enumerate", "(", "label", ")", ":", "\n", "            ", "label_matrix", "[", "i", ",", "j", "]", "=", "int", "(", "e", ")", "\n", "", "label_list", ".", "append", "(", "[", "int", "(", "e", ")", "for", "e", "in", "label", "]", ")", "\n", "", "return", "label_matrix", ".", "long", "(", ")", ",", "label_list", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.src.utils.flatten": [[77, 82], ["fla.extend"], "function", ["None"], ["", "def", "flatten", "(", "array", ")", ":", "\n", "    ", "fla", "=", "[", "]", "\n", "for", "arr", "in", "array", ":", "\n", "        ", "fla", ".", "extend", "(", "arr", ")", "\n", "", "return", "fla", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.src.utils.predictions2jsonl": [[84, 137], ["jsonlines.jsonlines.open", "jsonlines.jsonlines.open", "zip", "zip", "zip", "len", "len", "len", "len", "claim_ids.append", "enumerate", "claims.get", "jsonlines.open.write", "claim_ids.append", "claims.get", "len", "len", "rationale[].items", "jsonlines.open.write", "sorted", "sorted", "rationale_sentence.append", "list", "list", "len", "set", "set"], "function", ["None"], ["", "def", "predictions2jsonl", "(", "claims_file", ",", "abstract_results", ",", "rationale_results", ")", ":", "\n", "    ", "claim_ids", "=", "[", "]", "\n", "claims", "=", "{", "}", "\n", "output_rationale", "=", "jsonlines", ".", "open", "(", "\"prediction/rationale_selection.jsonl\"", ",", "'w'", ")", "\n", "output_labels", "=", "jsonlines", ".", "open", "(", "\"prediction/label_predictions.jsonl\"", ",", "'w'", ")", "\n", "assert", "(", "len", "(", "claims_file", ")", "==", "len", "(", "abstract_results", ")", ")", "\n", "assert", "(", "len", "(", "claims_file", ")", "==", "len", "(", "rationale_results", ")", ")", "\n", "\n", "for", "claim", ",", "rationale", "in", "zip", "(", "claims_file", ",", "rationale_results", ")", ":", "\n", "        ", "claim_id", "=", "claim", "[", "'claim_id'", "]", "\n", "claim_ids", ".", "append", "(", "claim_id", ")", "\n", "\n", "rationale_sentence", "=", "[", "]", "\n", "for", "i", ",", "sen", "in", "enumerate", "(", "rationale", ")", ":", "\n", "            ", "if", "sen", "==", "1", ":", "\n", "                ", "rationale_sentence", ".", "append", "(", "i", ")", "\n", "", "", "curr_claim", "=", "claims", ".", "get", "(", "claim_id", ",", "{", "'claim_id'", ":", "claim_id", ",", "'evidence'", ":", "{", "}", "}", ")", "\n", "curr_claim", "[", "'evidence'", "]", "[", "claim", "[", "'doc_id'", "]", "]", "=", "rationale_sentence", "\n", "claims", "[", "claim_id", "]", "=", "curr_claim", "\n", "", "rationale_claim", "=", "[", "claims", "[", "claim_id", "]", "for", "claim_id", "in", "sorted", "(", "list", "(", "set", "(", "claim_ids", ")", ")", ")", "]", "\n", "for", "rationale", "in", "rationale_claim", ":", "\n", "        ", "output_rationale", ".", "write", "(", "{", "\n", "'claim_id'", ":", "rationale", "[", "'claim_id'", "]", ",", "\n", "'evidence'", ":", "rationale", "[", "'evidence'", "]", "\n", "}", ")", "\n", "\n", "", "claim_ids", "=", "[", "]", "\n", "claims", "=", "{", "}", "\n", "# LABELS = ['CONTRADICT', 'NOT_ENOUGH_INFO', 'SUPPORT']", "\n", "LABELS", "=", "[", "'NOT_ENOUGH_INFO'", ",", "'CONTRADICT'", ",", "'SUPPORT'", "]", "\n", "for", "claim", ",", "abstract", "in", "zip", "(", "claims_file", ",", "abstract_results", ")", ":", "\n", "        ", "claim_id", "=", "claim", "[", "'claim_id'", "]", "\n", "claim_ids", ".", "append", "(", "claim_id", ")", "\n", "\n", "curr_claim", "=", "claims", ".", "get", "(", "claim_id", ",", "{", "'claim_id'", ":", "claim_id", ",", "'labels'", ":", "{", "}", "}", ")", "\n", "curr_claim", "[", "'labels'", "]", "[", "claim", "[", "'doc_id'", "]", "]", "=", "{", "'label'", ":", "LABELS", "[", "abstract", "]", ",", "'confidence'", ":", "1", "}", "\n", "claims", "[", "claim_id", "]", "=", "curr_claim", "\n", "", "label_claim", "=", "[", "claims", "[", "claim_id", "]", "for", "claim_id", "in", "sorted", "(", "list", "(", "set", "(", "claim_ids", ")", ")", ")", "]", "\n", "\n", "assert", "(", "len", "(", "rationale_claim", ")", "==", "len", "(", "label_claim", ")", ")", "\n", "for", "abstract", ",", "rationale", "in", "zip", "(", "label_claim", ",", "rationale_claim", ")", ":", "\n", "        ", "assert", "(", "abstract", "[", "\"claim_id\"", "]", "==", "rationale", "[", "\"claim_id\"", "]", ")", "\n", "for", "doc_id", ",", "pred", "in", "rationale", "[", "\"evidence\"", "]", ".", "items", "(", ")", ":", "\n", "            ", "if", "len", "(", "pred", ")", "==", "0", ":", "\n", "                ", "abstract", "[", "\"labels\"", "]", "[", "doc_id", "]", "[", "\"label\"", "]", "=", "\"NOT_ENOUGH_INFO\"", "\n", "\n", "", "", "", "for", "label", "in", "label_claim", ":", "\n", "        ", "output_labels", ".", "write", "(", "{", "\n", "'claim_id'", ":", "label", "[", "'claim_id'", "]", ",", "\n", "'labels'", ":", "label", "[", "'labels'", "]", "\n", "}", ")", "\n", "\n", "", "return", "rationale_claim", ",", "label_claim", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.src.utils.remove_dummy": [[139, 141], ["None"], "function", ["None"], ["", "def", "remove_dummy", "(", "rationale_out", ")", ":", "\n", "    ", "return", "[", "out", "[", "1", ":", "]", "for", "out", "in", "rationale_out", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.src.utils.retrieval2jsonl": [[143, 173], ["zip", "len", "len", "claim_ids.append", "claims.get", "open", "curr_claim[].append", "sorted", "print", "list", "json.dumps", "set"], "function", ["None"], ["", "def", "retrieval2jsonl", "(", "claims_file", ",", "retrieval_result", ")", ":", "\n", "    ", "claim_ids", "=", "[", "]", "\n", "claims", "=", "{", "}", "\n", "# output_retrieval = jsonlines.open(\"prediction/abstract_retrieval.jsonl\", 'w')", "\n", "output_retrieval", "=", "\"prediction/abstract_retrieval.jsonl\"", "\n", "assert", "(", "len", "(", "claims_file", ")", "==", "len", "(", "retrieval_result", ")", ")", "\n", "\n", "# LABELS = ['NOT_RELATED', 'RELATED']", "\n", "for", "claim", ",", "retrieval", "in", "zip", "(", "claims_file", ",", "retrieval_result", ")", ":", "\n", "# retrieval_abstract = []", "\n", "        ", "claim_id", "=", "claim", "[", "'claim_id'", "]", "\n", "claim_ids", ".", "append", "(", "claim_id", ")", "\n", "curr_claim", "=", "claims", ".", "get", "(", "claim_id", ",", "{", "'id'", ":", "claim_id", ",", "'claim'", ":", "claim", "[", "'claim'", "]", ",", "'doc_ids'", ":", "[", "]", "}", ")", "\n", "curr_claim", "[", "'doc_ids'", "]", "=", "curr_claim", "[", "'doc_ids'", "]", "\n", "if", "retrieval", "==", "1", ":", "\n", "            ", "curr_claim", "[", "'doc_ids'", "]", ".", "append", "(", "claim", "[", "'doc_id'", "]", ")", "\n", "", "claims", "[", "claim_id", "]", "=", "curr_claim", "\n", "", "abstract_claim", "=", "[", "claims", "[", "claim_id", "]", "for", "claim_id", "in", "sorted", "(", "list", "(", "set", "(", "claim_ids", ")", ")", ")", "]", "\n", "# print(abstract_claim)", "\n", "retrieval_abstract", "=", "{", "}", "\n", "with", "open", "(", "output_retrieval", ",", "\"w\"", ")", "as", "f", ":", "\n", "        ", "for", "entry", "in", "abstract_claim", ":", "\n", "            ", "print", "(", "json", ".", "dumps", "(", "entry", ")", ",", "file", "=", "f", ")", "\n", "# for abstract in abstract_claim:", "\n", "#     output_retrieval.write({", "\n", "#         'id': abstract['claim_id'],", "\n", "#         'claim': abstract['claim'],", "\n", "#         'doc_ids': abstract['doc_ids']", "\n", "#     })", "\n", "", "", "return", "\"prediction/abstract_retrieval.jsonl\"", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.dataset.encode.encode_sen_pair": [[6, 22], ["tokenizer.batch_encode_plus", "list", "encoded_dict[].size", "tokenizer.batch_encode_plus", "zip", "list", "zip"], "function", ["None"], ["def", "encode_sen_pair", "(", "tokenizer", ",", "claims", ":", "List", "[", "str", "]", ",", "sentences", ":", "List", "[", "str", "]", ")", ":", "\n", "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')", "\n", "    ", "encoded_dict", "=", "tokenizer", ".", "batch_encode_plus", "(", "\n", "list", "(", "zip", "(", "claims", ",", "sentences", ")", ")", ",", "\n", "padding", "=", "True", ",", "\n", "return_tensors", "=", "'pt'", ")", "\n", "if", "encoded_dict", "[", "'input_ids'", "]", ".", "size", "(", "1", ")", ">", "512", ":", "\n", "# Too long for the model. Truncate it", "\n", "        ", "encoded_dict", "=", "tokenizer", ".", "batch_encode_plus", "(", "\n", "list", "(", "zip", "(", "claims", ",", "sentences", ")", ")", ",", "\n", "max_length", "=", "512", ",", "\n", "truncation_strategy", "=", "'only_first'", ",", "\n", "padding", "=", "True", ",", "\n", "return_tensors", "=", "'pt'", ")", "\n", "# encoded_dict = {key: tensor.to(device) for key, tensor in encoded_dict.items()}", "\n", "", "return", "encoded_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.dataset.encode.encode_sentence": [[24, 40], ["tokenizer.batch_encode_plus", "encoded_dict[].size", "tokenizer.batch_encode_plus"], "function", ["None"], ["", "def", "encode_sentence", "(", "tokenizer", ",", "sentences", ":", "List", "[", "str", "]", ")", ":", "\n", "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')", "\n", "    ", "encoded_dict", "=", "tokenizer", ".", "batch_encode_plus", "(", "\n", "sentences", ",", "\n", "padding", "=", "True", ",", "\n", "return_tensors", "=", "'pt'", ")", "\n", "if", "encoded_dict", "[", "'input_ids'", "]", ".", "size", "(", "1", ")", ">", "512", ":", "\n", "# Too long for the model. Truncate it", "\n", "        ", "encoded_dict", "=", "tokenizer", ".", "batch_encode_plus", "(", "\n", "sentences", ",", "\n", "max_length", "=", "512", ",", "\n", "truncation_strategy", "=", "'only_first'", ",", "\n", "padding", "=", "True", ",", "\n", "return_tensors", "=", "'pt'", ")", "\n", "# encoded_dict = {key: tensor.to(device) for key, tensor in encoded_dict.items()}", "\n", "", "return", "encoded_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.dataset.encode.longest_first_truncation": [[42, 53], ["len", "numpy.sum", "numpy.argmax", "zip"], "function", ["None"], ["", "def", "longest_first_truncation", "(", "sentences", ",", "truncate_length", ")", ":", "\n", "    ", "'''\n    :param sentences: sentence to be truncated\n    :param truncate_length: truncate length\n    :return: sentence after truncation\n    '''", "\n", "sent_lens", "=", "[", "len", "(", "sent", ")", "for", "sent", "in", "sentences", "]", "\n", "while", "np", ".", "sum", "(", "sent_lens", ")", ">", "truncate_length", ":", "# truncation the longest sentence", "\n", "        ", "max_position", "=", "np", ".", "argmax", "(", "sent_lens", ")", "\n", "sent_lens", "[", "max_position", "]", "-=", "1", "\n", "", "return", "[", "sentence", "[", ":", "length", "]", "for", "sentence", ",", "length", "in", "zip", "(", "sentences", ",", "sent_lens", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.dataset.encode.truncate": [[55, 77], ["torch.cat", "valid_paragraph.size", "all_paragraphs.append", "encode.longest_first_truncation", "torch.cat", "all_paragraphs.append", "paragraph[].unsqueeze", "numpy.arange", "idx_by_sentence.append", "len", "torch.cat.unsqueeze", "valid_paragraph.size", "torch.tensor"], "function", ["home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.dataset.encode.longest_first_truncation"], ["", "def", "truncate", "(", "input_ids", ",", "max_length", ",", "sep_token_id", ",", "pad_token_id", ")", ":", "\n", "    ", "all_paragraphs", "=", "[", "]", "\n", "for", "paragraph", "in", "input_ids", ":", "\n", "        ", "valid_paragraph", "=", "paragraph", "[", "paragraph", "!=", "pad_token_id", "]", "\n", "if", "valid_paragraph", ".", "size", "(", "0", ")", "<=", "max_length", ":", "\n", "            ", "all_paragraphs", ".", "append", "(", "paragraph", "[", ":", "max_length", "]", ".", "unsqueeze", "(", "0", ")", ")", "\n", "", "else", ":", "\n", "# position of sep_token", "\n", "            ", "sep_token_idx", "=", "np", ".", "arange", "(", "valid_paragraph", ".", "size", "(", "0", ")", ")", "[", "(", "valid_paragraph", "==", "sep_token_id", ")", ".", "numpy", "(", ")", "]", "\n", "idx_by_sentence", "=", "[", "]", "\n", "prev_idx", "=", "0", "\n", "for", "idx", "in", "sep_token_idx", ":", "# delineate the sentence in the Claim&Abstract", "\n", "                ", "idx_by_sentence", ".", "append", "(", "paragraph", "[", "prev_idx", ":", "idx", "]", ")", "\n", "prev_idx", "=", "idx", "\n", "# The last sep_token left out. the first sentence is Claim.", "\n", "", "truncate_length", "=", "max_length", "-", "1", "-", "len", "(", "idx_by_sentence", "[", "0", "]", ")", "\n", "# truncate abstract(paragraph).", "\n", "truncated_sentences", "=", "longest_first_truncation", "(", "idx_by_sentence", "[", "1", ":", "]", ",", "truncate_length", ")", "\n", "truncated_paragraph", "=", "torch", ".", "cat", "(", "[", "idx_by_sentence", "[", "0", "]", "]", "\n", "+", "truncated_sentences", "+", "[", "torch", ".", "tensor", "(", "[", "sep_token_id", "]", ")", "]", ",", "0", ")", "\n", "all_paragraphs", ".", "append", "(", "truncated_paragraph", ".", "unsqueeze", "(", "0", ")", ")", "\n", "", "", "return", "torch", ".", "cat", "(", "all_paragraphs", ",", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.dataset.encode.encode_paragraph": [[79, 104], ["tokenizer.batch_encode_plus", "list", "encoded_dict[].size", "zip", "encode.truncate", "encode.truncate"], "function", ["home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.dataset.encode.truncate", "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.dataset.encode.truncate"], ["", "def", "encode_paragraph", "(", "tokenizer", ",", "claim", ",", "abstract", ",", "max_sent_len", "=", "512", ")", ":", "\n", "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')", "\n", "    ", "encoded_dict", "=", "tokenizer", ".", "batch_encode_plus", "(", "\n", "list", "(", "zip", "(", "claim", ",", "abstract", ")", ")", ",", "\n", "# padding=True,", "\n", "padding", "=", "True", ",", "\n", "add_special_tokens", "=", "True", ",", "\n", "return_tensors", "=", "'pt'", ")", "\n", "if", "encoded_dict", "[", "'input_ids'", "]", ".", "size", "(", "1", ")", ">", "max_sent_len", ":", "\n", "# Too long for the model. Truncate it", "\n", "        ", "if", "'token_type_ids'", "in", "encoded_dict", ":", "\n", "            ", "encoded_dict", "=", "{", "\n", "\"input_ids\"", ":", "truncate", "(", "encoded_dict", "[", "'input_ids'", "]", ",", "max_sent_len", ",", "\n", "tokenizer", ".", "sep_token_id", ",", "tokenizer", ".", "pad_token_id", ")", ",", "\n", "'token_type_ids'", ":", "encoded_dict", "[", "'token_type_ids'", "]", "[", ":", ",", ":", "max_sent_len", "]", ",", "\n", "'attention_mask'", ":", "encoded_dict", "[", "'attention_mask'", "]", "[", ":", ",", ":", "max_sent_len", "]", "\n", "}", "\n", "", "else", ":", "\n", "            ", "encoded_dict", "=", "{", "\n", "\"input_ids\"", ":", "truncate", "(", "encoded_dict", "[", "'input_ids'", "]", ",", "max_sent_len", ",", "\n", "tokenizer", ".", "sep_token_id", ",", "tokenizer", ".", "pad_token_id", ")", ",", "\n", "'attention_mask'", ":", "encoded_dict", "[", "'attention_mask'", "]", "[", ":", ",", ":", "max_sent_len", "]", "\n", "}", "\n", "# encoded_dict = {key: tensor.to(device) for key, tensor in encoded_dict.items()}", "\n", "", "", "return", "encoded_dict", "\n", "", ""]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.dataset.utils.save_rationale_selection": [[11, 28], ["jsonlines.open", "jsonlines.open.write"], "function", ["None"], ["\n", "padding_idx", "=", "-", "1", "\n", "sep_tokens", "=", "(", "input_ids", "==", "sep_token_id", ")", ".", "bool", "(", ")", "\n", "paragraph_lens", "=", "torch", ".", "sum", "(", "sep_tokens", ",", "1", ")", ".", "numpy", "(", ")", ".", "tolist", "(", ")", "\n", "indices", "=", "torch", ".", "arange", "(", "sep_tokens", ".", "size", "(", "-", "1", ")", ")", ".", "unsqueeze", "(", "0", ")", ".", "expand", "(", "sep_tokens", ".", "size", "(", "0", ")", ",", "-", "1", ")", "\n", "sep_indices", "=", "torch", ".", "split", "(", "indices", "[", "sep_tokens", "]", ",", "paragraph_lens", ")", "\n", "if", "match", ":", "\n", "        ", "tmp_indices", "=", "(", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "sep_indices", ")", ")", ":", "\n", "            ", "tmp_indices", "+=", "(", "torch", ".", "tensor", "(", "np", ".", "array", "(", "sep_indices", "[", "i", "]", ")", "[", "[", "0", ",", "-", "1", "]", "]", ".", "tolist", "(", ")", ")", ",", ")", "\n", "", "sep_indices", "=", "tmp_indices", "\n", "", "else", ":", "\n", "        ", "tmp_indices", "=", "(", ")", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.dataset.utils.label_prediction": [[31, 54], ["torch.device", "tokenizer.batch_encode_plus", "encoded_dict[].size", "print", "tokenizer.batch_encode_plus", "tensor.to", "torch.cuda.is_available", "list", "encoded_dict[].size", "tokenizer.batch_encode_plus.items", "zip"], "function", ["None"], ["", "sep_indices", "=", "tmp_indices", "\n", "# else:", "\n", "#     tmp_indices = ()", "\n", "#     for i in range(len(sep_indices)):", "\n", "#         tmp_indices += (torch.tensor(np.array(sep_indices[i])[1: len(sep_indices[i])].tolist()),)  # del title", "\n", "#     sep_indices = tmp_indices", "\n", "", "paragraph_lens", "=", "[", "]", "\n", "all_word_indices", "=", "[", "]", "\n", "for", "paragraph", "in", "sep_indices", ":", "\n", "        ", "if", "\"large\"", "in", "model_name", "and", "(", "'biobert'", "not", "in", "model_name", ")", ":", "\n", "            ", "paragraph", "=", "paragraph", "[", "1", ":", "]", "\n", "", "word_indices", "=", "[", "torch", ".", "arange", "(", "paragraph", "[", "i", "]", "+", "1", ",", "paragraph", "[", "i", "+", "1", "]", "+", "1", ")", "for", "i", "in", "range", "(", "paragraph", ".", "size", "(", "0", ")", "-", "1", ")", "]", "\n", "paragraph_lens", ".", "append", "(", "len", "(", "word_indices", ")", ")", "\n", "all_word_indices", ".", "extend", "(", "word_indices", ")", "\n", "# pad_sequence: stacks a list of Tensors along a new dimension, and pads them to equal length.", "\n", "", "indices_by_sentence", "=", "nn", ".", "utils", ".", "rnn", ".", "pad_sequence", "(", "all_word_indices", ",", "batch_first", "=", "True", ",", "padding_value", "=", "padding_idx", ")", "\n", "indices_by_sentence_split", "=", "torch", ".", "split", "(", "indices_by_sentence", ",", "paragraph_lens", ")", "\n", "indices_by_batch", "=", "nn", ".", "utils", ".", "rnn", ".", "pad_sequence", "(", "indices_by_sentence_split", ",", "batch_first", "=", "True", ",", "padding_value", "=", "padding_idx", ")", "\n", "# if match:", "\n", "#     padd2maxlen = torch.tensor([[-1 for _ in range(indices_by_batch.shape[2], 512)] for _ in range(2)]).unsqueeze(0)", "\n", "#     indices_by_batch = torch.cat([indices_by_batch, padd2maxlen], 2)", "\n", "batch_indices", "=", "torch", ".", "arange", "(", "sep_tokens", ".", "size", "(", "0", ")", ")", ".", "unsqueeze", "(", "-", "1", ")", ".", "unsqueeze", "(", "-", "1", ")", ".", "expand", "(", "-", "1", ",", "\n", "indices_by_batch", ".", "size", "(", "1", ")", ",", "\n", "indices_by_batch", ".", "size", "(", "-", "1", ")", ")", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.dataset.utils.save_label_predictions": [[56, 62], ["jsonlines.open", "jsonlines.open.write"], "function", ["None"], ["\n", "return", "batch_indices", ".", "long", "(", ")", ",", "indices_by_batch", ".", "long", "(", ")", ",", "mask", ".", "long", "(", ")", "\n", "\n", "\n", "", "def", "get_rationale_label", "(", "labels", ",", "padding_idx", "=", "2", ")", ":", "\n", "    "]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.dataset.utils.merge_one": [[65, 92], ["sorted", "evidence.keys", "labels.keys", "ValueError", "evidence.keys"], "function", ["None"], ["\n", "max_label_len", "=", "max", "(", "[", "len", "(", "label", ")", "for", "label", "in", "labels", "]", ")", "\n", "label_matrix", "=", "torch", ".", "ones", "(", "len", "(", "labels", ")", ",", "max_label_len", ")", "*", "padding_idx", "\n", "label_list", "=", "[", "]", "\n", "for", "i", ",", "label", "in", "enumerate", "(", "labels", ")", ":", "\n", "        ", "for", "j", ",", "e", "in", "enumerate", "(", "label", ")", ":", "\n", "            ", "label_matrix", "[", "i", ",", "j", "]", "=", "int", "(", "e", ")", "\n", "", "label_list", ".", "append", "(", "[", "int", "(", "e", ")", "for", "e", "in", "label", "]", ")", "\n", "", "return", "label_matrix", ".", "long", "(", ")", ",", "label_list", "\n", "\n", "\n", "", "def", "flatten", "(", "array", ")", ":", "\n", "    ", "fla", "=", "[", "]", "\n", "for", "arr", "in", "array", ":", "\n", "        ", "fla", ".", "extend", "(", "arr", ")", "\n", "", "return", "fla", "\n", "\n", "\n", "", "def", "predictions2jsonl", "(", "claims_file", ",", "abstract_results", ",", "rationale_results", ")", ":", "\n", "    ", "claim_ids", "=", "[", "]", "\n", "claims", "=", "{", "}", "\n", "output_rationale", "=", "jsonlines", ".", "open", "(", "\"prediction/rationale_selection.jsonl\"", ",", "'w'", ")", "\n", "output_labels", "=", "jsonlines", ".", "open", "(", "\"prediction/label_predictions.jsonl\"", ",", "'w'", ")", "\n", "assert", "(", "len", "(", "claims_file", ")", "==", "len", "(", "abstract_results", ")", ")", "\n", "assert", "(", "len", "(", "claims_file", ")", "==", "len", "(", "rationale_results", ")", ")", "\n", "\n", "for", "claim", ",", "rationale", "in", "zip", "(", "claims_file", ",", "rationale_results", ")", ":", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.dataset.utils.merge": [[94, 113], ["ValueError", "utils.merge_one", "open", "zip", "print", "json.dumps"], "function", ["home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.dataset.utils.merge_one"], ["claim_ids", ".", "append", "(", "claim_id", ")", "\n", "\n", "rationale_sentence", "=", "[", "]", "\n", "for", "i", ",", "sen", "in", "enumerate", "(", "rationale", ")", ":", "\n", "            ", "if", "sen", "==", "1", ":", "\n", "                ", "rationale_sentence", ".", "append", "(", "i", ")", "\n", "", "", "curr_claim", "=", "claims", ".", "get", "(", "claim_id", ",", "{", "'claim_id'", ":", "claim_id", ",", "'evidence'", ":", "{", "}", "}", ")", "\n", "curr_claim", "[", "'evidence'", "]", "[", "claim", "[", "'doc_id'", "]", "]", "=", "rationale_sentence", "\n", "claims", "[", "claim_id", "]", "=", "curr_claim", "\n", "", "rationale_claim", "=", "[", "claims", "[", "claim_id", "]", "for", "claim_id", "in", "sorted", "(", "list", "(", "set", "(", "claim_ids", ")", ")", ")", "]", "\n", "for", "rationale", "in", "rationale_claim", ":", "\n", "        ", "output_rationale", ".", "write", "(", "{", "\n", "'claim_id'", ":", "rationale", "[", "'claim_id'", "]", ",", "\n", "'evidence'", ":", "rationale", "[", "'evidence'", "]", "\n", "}", ")", "\n", "\n", "", "claim_ids", "=", "[", "]", "\n", "claims", "=", "{", "}", "\n", "# LABELS = ['CONTRADICT', 'NOT_ENOUGH_INFO', 'SUPPORT']", "\n", "LABELS", "=", "[", "'NOT_ENOUGH_INFO'", ",", "'CONTRADICT'", ",", "'SUPPORT'", "]", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.dataset.utils.merge_json": [[115, 132], ["str", "str", "results.append", "jsonlines.open", "rationale[].items", "output.write", "int", "len", "int", "int"], "function", ["None"], ["        ", "claim_id", "=", "claim", "[", "'claim_id'", "]", "\n", "claim_ids", ".", "append", "(", "claim_id", ")", "\n", "\n", "curr_claim", "=", "claims", ".", "get", "(", "claim_id", ",", "{", "'claim_id'", ":", "claim_id", ",", "'labels'", ":", "{", "}", "}", ")", "\n", "curr_claim", "[", "'labels'", "]", "[", "claim", "[", "'doc_id'", "]", "]", "=", "{", "'label'", ":", "LABELS", "[", "abstract", "]", ",", "'confidence'", ":", "1", "}", "\n", "claims", "[", "claim_id", "]", "=", "curr_claim", "\n", "", "label_claim", "=", "[", "claims", "[", "claim_id", "]", "for", "claim_id", "in", "sorted", "(", "list", "(", "set", "(", "claim_ids", ")", ")", ")", "]", "\n", "\n", "assert", "(", "len", "(", "rationale_claim", ")", "==", "len", "(", "label_claim", ")", ")", "\n", "for", "abstract", ",", "rationale", "in", "zip", "(", "label_claim", ",", "rationale_claim", ")", ":", "\n", "        ", "assert", "(", "abstract", "[", "\"claim_id\"", "]", "==", "rationale", "[", "\"claim_id\"", "]", ")", "\n", "for", "doc_id", ",", "pred", "in", "rationale", "[", "\"evidence\"", "]", ".", "items", "(", ")", ":", "\n", "            ", "if", "len", "(", "pred", ")", "==", "0", ":", "\n", "                ", "abstract", "[", "\"labels\"", "]", "[", "doc_id", "]", "[", "\"label\"", "]", "=", "\"NOT_ENOUGH_INFO\"", "\n", "\n", "", "", "", "for", "label", "in", "label_claim", ":", "\n", "        ", "output_labels", ".", "write", "(", "{", "\n", "'claim_id'", ":", "label", "[", "'claim_id'", "]", ",", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.dataset.utils.merge_retrieval": [[134, 151], ["zip", "ValueError", "open", "print", "json.dumps"], "function", ["None"], ["}", ")", "\n", "\n", "", "return", "rationale_claim", ",", "label_claim", "\n", "\n", "\n", "", "def", "remove_dummy", "(", "rationale_out", ")", ":", "\n", "    ", "return", "[", "out", "[", "1", ":", "]", "for", "out", "in", "rationale_out", "]", "\n", "\n", "\n", "", "def", "retrieval2jsonl", "(", "claims_file", ",", "retrieval_result", ")", ":", "\n", "    ", "claim_ids", "=", "[", "]", "\n", "claims", "=", "{", "}", "\n", "# output_retrieval = jsonlines.open(\"prediction/abstract_retrieval.jsonl\", 'w')", "\n", "output_retrieval", "=", "\"prediction/abstract_retrieval.jsonl\"", "\n", "assert", "(", "len", "(", "claims_file", ")", "==", "len", "(", "retrieval_result", ")", ")", "\n", "\n", "# LABELS = ['NOT_RELATED', 'RELATED']", "\n", "for", "claim", ",", "retrieval", "in", "zip", "(", "claims_file", ",", "retrieval_result", ")", ":", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.dataset.utils.abstract_retrieval": [[153, 173], ["jsonlines.open", "jsonlines.open", "jsonlines.open.write", "jsonlines.open", "list", "map", "data[].keys"], "function", ["None"], ["        ", "claim_id", "=", "claim", "[", "'claim_id'", "]", "\n", "claim_ids", ".", "append", "(", "claim_id", ")", "\n", "curr_claim", "=", "claims", ".", "get", "(", "claim_id", ",", "{", "'id'", ":", "claim_id", ",", "'claim'", ":", "claim", "[", "'claim'", "]", ",", "'doc_ids'", ":", "[", "]", "}", ")", "\n", "curr_claim", "[", "'doc_ids'", "]", "=", "curr_claim", "[", "'doc_ids'", "]", "\n", "if", "retrieval", "==", "1", ":", "\n", "            ", "curr_claim", "[", "'doc_ids'", "]", ".", "append", "(", "claim", "[", "'doc_id'", "]", ")", "\n", "", "claims", "[", "claim_id", "]", "=", "curr_claim", "\n", "", "abstract_claim", "=", "[", "claims", "[", "claim_id", "]", "for", "claim_id", "in", "sorted", "(", "list", "(", "set", "(", "claim_ids", ")", ")", ")", "]", "\n", "# print(abstract_claim)", "\n", "retrieval_abstract", "=", "{", "}", "\n", "with", "open", "(", "output_retrieval", ",", "\"w\"", ")", "as", "f", ":", "\n", "        ", "for", "entry", "in", "abstract_claim", ":", "\n", "            ", "print", "(", "json", ".", "dumps", "(", "entry", ")", ",", "file", "=", "f", ")", "\n", "# for abstract in abstract_claim:", "\n", "#     output_retrieval.write({", "\n", "#         'id': abstract['claim_id'],", "\n", "#         'claim': abstract['claim'],", "\n", "#         'doc_ids': abstract['doc_ids']", "\n", "#     })", "\n", "", "", "return", "\"prediction/abstract_retrieval.jsonl\"", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.dataset.utils.oracle_rationale": [[176, 196], ["jsonlines.open", "zip", "output.write", "str", "data[].get", "data[].get"], "function", ["None"], []], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.dataset.utils.oracle_tfidf_rationale": [[199, 230], ["jsonlines.open", "jsonlines.open", "jsonlines.open", "zip", "jsonlines.open.write", "jsonlines.open", "data[].get", "str", "sklearn.feature_extraction.text.TfidfVectorizer", "sklearn.feature_extraction.text.TfidfVectorizer.fit_transform", "sklearn.feature_extraction.text.TfidfVectorizer.transform().todense", "numpy.asarray().squeeze", "[].tolist", "[].tolist.sort", "sklearn.feature_extraction.text.TfidfVectorizer.transform", "numpy.asarray", "str", "np.asarray().squeeze.argsort"], "function", ["None"], []], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.dataset.utils.tfidf_abstract": [[233, 257], ["list", "list", "jsonlines.open", "sklearn.feature_extraction.text.TfidfVectorizer", "sklearn.feature_extraction.text.TfidfVectorizer.fit_transform", "jsonlines.open", "jsonlines.open", "sklearn.feature_extraction.text.TfidfVectorizer.transform().todense", "numpy.asarray().squeeze", "[].tolist", "jsonlines.open.write", "sklearn.feature_extraction.text.TfidfVectorizer.transform", "numpy.asarray", "np.asarray().squeeze.argsort"], "function", ["None"], []], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.dataset.utils.split_dataset": [[260, 285], ["sklearn.model_selection.train_test_split", "jsonlines.open", "jsonlines.open", "print", "jsonlines.open.write", "jsonlines.open.write", "jsonlines.open"], "function", ["None"], []], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.dataset.loader.SciFactRationaleSelectionDataset.__init__": [[211, 246], ["jsonlines.open", "sorted", "jsonlines.open", "int", "int", "list", "enumerate", "list", "set", "str", "claim[].keys", "loader.SciFactRationaleSelectionDataset.samples.append", "claim[].keys", "int", "str"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "corpus", ":", "str", ",", "claims", ":", "str", ",", "train", "=", "True", ",", "k", "=", "3", ")", ":", "\n", "        ", "self", ".", "samples", "=", "[", "]", "\n", "corpus", "=", "{", "doc", "[", "'doc_id'", "]", ":", "doc", "for", "doc", "in", "jsonlines", ".", "open", "(", "corpus", ")", "}", "\n", "# for claim in jsonlines.open(claims):", "\n", "#     for doc_id, evidence in claim['evidence'].items():", "\n", "#         doc = corpus[int(doc_id)]", "\n", "#         evidence_sentence_idx = {s for es in evidence for s in es['sentences']}", "\n", "#         for i, sentence in enumerate(doc['abstract']):", "\n", "#             self.samples.append({", "\n", "#                 'claim': claim['claim'],", "\n", "#                 'sentence': sentence,", "\n", "#                 'evidence': i in evidence_sentence_idx", "\n", "#             })", "\n", "for", "claim", "in", "jsonlines", ".", "open", "(", "claims", ")", ":", "\n", "            ", "if", "\"doc_ids\"", "in", "claim", ":", "\n", "                ", "candidates", "=", "claim", "[", "\"doc_ids\"", "]", "[", ":", "k", "]", "# Add negative samples", "\n", "", "else", ":", "\n", "                ", "candidates", "=", "claim", "[", "\"cited_doc_ids\"", "]", "\n", "", "candidates", "=", "[", "int", "(", "cand", ")", "for", "cand", "in", "candidates", "]", "\n", "evidence_doc_ids", "=", "[", "int", "(", "ID", ")", "for", "ID", "in", "list", "(", "claim", "[", "'evidence'", "]", ".", "keys", "(", ")", ")", "]", "\n", "all_candidates", "=", "sorted", "(", "list", "(", "set", "(", "candidates", "+", "evidence_doc_ids", ")", ")", ")", "\n", "if", "not", "train", ":", "\n", "                ", "all_candidates", "=", "candidates", "\n", "", "for", "doc_id", "in", "all_candidates", ":", "\n", "                ", "if", "str", "(", "doc_id", ")", "in", "claim", "[", "'evidence'", "]", ".", "keys", "(", ")", ":", "\n", "                    ", "evidence", "=", "claim", "[", "'evidence'", "]", "[", "str", "(", "doc_id", ")", "]", "\n", "", "else", ":", "\n", "                    ", "evidence", "=", "{", "}", "\n", "", "doc", "=", "corpus", "[", "int", "(", "doc_id", ")", "]", "\n", "evidence_sentence_idx", "=", "{", "s", "for", "es", "in", "evidence", "for", "s", "in", "es", "[", "'sentences'", "]", "}", "\n", "for", "i", ",", "sentence", "in", "enumerate", "(", "doc", "[", "'abstract'", "]", ")", ":", "\n", "                    ", "self", ".", "samples", ".", "append", "(", "{", "\n", "'claim'", ":", "claim", "[", "'claim'", "]", ",", "\n", "'sentence'", ":", "sentence", ",", "\n", "'evidence'", ":", "i", "in", "evidence_sentence_idx", "\n", "}", ")", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.dataset.loader.SciFactRationaleSelectionDataset.__len__": [[248, 250], ["len"], "methods", ["None"], ["", "", "", "", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "samples", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.dataset.loader.SciFactRationaleSelectionDataset.__getitem__": [[251, 253], ["None"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "idx", ")", ":", "\n", "        ", "return", "self", ".", "samples", "[", "idx", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.dataset.loader.SciFactLabelPredictionDataset.__init__": [[256, 307], ["jsonlines.open", "jsonlines.open", "claim[].items", "loader.SciFactLabelPredictionDataset.samples.append", "random.sample", "loader.SciFactLabelPredictionDataset.samples.append", "random.sample", "loader.SciFactLabelPredictionDataset.samples.append", "loader.SciFactLabelPredictionDataset.samples.append", "[].strip", "set", "[].strip", "range", "[].strip", "int", "[].strip", "sorted", "range", "min", "sorted", "int", "len", "random.randint", "list", "len", "random.randint", "len", "list"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "corpus", ":", "str", ",", "claims", ":", "str", ")", ":", "\n", "        ", "self", ".", "samples", "=", "[", "]", "\n", "\n", "corpus", "=", "{", "doc", "[", "'doc_id'", "]", ":", "doc", "for", "doc", "in", "jsonlines", ".", "open", "(", "corpus", ")", "}", "\n", "label_encodings", "=", "{", "'CONTRADICT'", ":", "0", ",", "'NOT_ENOUGH_INFO'", ":", "1", ",", "'SUPPORT'", ":", "2", "}", "\n", "\n", "for", "claim", "in", "jsonlines", ".", "open", "(", "claims", ")", ":", "\n", "            ", "if", "claim", "[", "'evidence'", "]", ":", "\n", "                ", "for", "doc_id", ",", "evidence_sets", "in", "claim", "[", "'evidence'", "]", ".", "items", "(", ")", ":", "\n", "                    ", "doc", "=", "corpus", "[", "int", "(", "doc_id", ")", "]", "\n", "\n", "# Add individual evidence set as samples:", "\n", "for", "evidence_set", "in", "evidence_sets", ":", "\n", "                        ", "rationale", "=", "[", "doc", "[", "'abstract'", "]", "[", "i", "]", ".", "strip", "(", ")", "for", "i", "in", "evidence_set", "[", "'sentences'", "]", "]", "\n", "self", ".", "samples", ".", "append", "(", "{", "\n", "'claim'", ":", "claim", "[", "'claim'", "]", ",", "\n", "'rationale'", ":", "' '", ".", "join", "(", "rationale", ")", ",", "\n", "'label'", ":", "label_encodings", "[", "evidence_set", "[", "'label'", "]", "]", "\n", "}", ")", "\n", "\n", "# Add all evidence sets as positive samples", "\n", "", "rationale_idx", "=", "{", "s", "for", "es", "in", "evidence_sets", "for", "s", "in", "es", "[", "'sentences'", "]", "}", "\n", "rationale_sentences", "=", "[", "doc", "[", "'abstract'", "]", "[", "i", "]", ".", "strip", "(", ")", "for", "i", "in", "sorted", "(", "list", "(", "rationale_idx", ")", ")", "]", "\n", "self", ".", "samples", ".", "append", "(", "{", "\n", "'claim'", ":", "claim", "[", "'claim'", "]", ",", "\n", "'rationale'", ":", "' '", ".", "join", "(", "rationale_sentences", ")", ",", "\n", "'label'", ":", "label_encodings", "[", "evidence_sets", "[", "0", "]", "[", "'label'", "]", "]", "# directly use the first evidence set label", "\n", "# because currently all evidence sets have", "\n", "# the same label", "\n", "}", ")", "\n", "\n", "# Add negative samples", "\n", "non_rationale_idx", "=", "set", "(", "range", "(", "len", "(", "doc", "[", "'abstract'", "]", ")", ")", ")", "-", "rationale_idx", "\n", "non_rationale_idx", "=", "random", ".", "sample", "(", "non_rationale_idx", ",", "\n", "k", "=", "min", "(", "random", ".", "randint", "(", "2", ",", "3", ")", ",", "len", "(", "non_rationale_idx", ")", ")", ")", "\n", "non_rationale_sentences", "=", "[", "doc", "[", "'abstract'", "]", "[", "i", "]", ".", "strip", "(", ")", "for", "i", "in", "sorted", "(", "list", "(", "non_rationale_idx", ")", ")", "]", "\n", "self", ".", "samples", ".", "append", "(", "{", "\n", "'claim'", ":", "claim", "[", "'claim'", "]", ",", "\n", "'rationale'", ":", "' '", ".", "join", "(", "non_rationale_sentences", ")", ",", "\n", "'label'", ":", "label_encodings", "[", "'NOT_ENOUGH_INFO'", "]", "\n", "}", ")", "\n", "", "", "else", ":", "\n", "# Add negative samples", "\n", "                ", "for", "doc_id", "in", "claim", "[", "'cited_doc_ids'", "]", ":", "\n", "                    ", "doc", "=", "corpus", "[", "int", "(", "doc_id", ")", "]", "\n", "non_rationale_idx", "=", "random", ".", "sample", "(", "range", "(", "len", "(", "doc", "[", "'abstract'", "]", ")", ")", ",", "k", "=", "random", ".", "randint", "(", "2", ",", "3", ")", ")", "\n", "non_rationale_sentences", "=", "[", "doc", "[", "'abstract'", "]", "[", "i", "]", ".", "strip", "(", ")", "for", "i", "in", "non_rationale_idx", "]", "\n", "self", ".", "samples", ".", "append", "(", "{", "\n", "'claim'", ":", "claim", "[", "'claim'", "]", ",", "\n", "'rationale'", ":", "' '", ".", "join", "(", "non_rationale_sentences", ")", ",", "\n", "'label'", ":", "label_encodings", "[", "'NOT_ENOUGH_INFO'", "]", "\n", "}", ")", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.dataset.loader.SciFactLabelPredictionDataset.__len__": [[309, 311], ["len"], "methods", ["None"], ["", "", "", "", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "samples", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.dataset.loader.SciFactLabelPredictionDataset.__getitem__": [[312, 314], ["None"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "idx", ")", ":", "\n", "        ", "return", "self", ".", "samples", "[", "idx", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.dataset.loader.SciFactAbstractRetrievalDataset.__init__": [[317, 329], ["jsonlines.open", "sorted", "jsonlines.open", "list", "loader.SciFactAbstractRetrievalDataset.samples.append", "set", "int"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "corpus", ":", "str", ",", "claims", ":", "str", ")", ":", "\n", "        ", "self", ".", "samples", "=", "[", "]", "\n", "corpus", "=", "{", "doc", "[", "'doc_id'", "]", ":", "doc", "for", "doc", "in", "jsonlines", ".", "open", "(", "corpus", ")", "}", "\n", "for", "claim", "in", "jsonlines", ".", "open", "(", "claims", ")", ":", "\n", "            ", "cited_doc_ids", "=", "claim", "[", "'cited_doc_ids'", "]", "\n", "doc_ids", "=", "sorted", "(", "list", "(", "set", "(", "cited_doc_ids", "+", "claim", "[", "'doc_ids'", "]", "[", ":", "10", "]", ")", ")", ")", "\n", "for", "doc_id", "in", "doc_ids", ":", "\n", "                ", "doc", "=", "corpus", "[", "int", "(", "doc_id", ")", "]", "\n", "self", ".", "samples", ".", "append", "(", "{", "\n", "'claim'", ":", "claim", "[", "'claim'", "]", ",", "\n", "'abstract'", ":", "''", ".", "join", "(", "doc", "[", "'abstract'", "]", ")", ",", "\n", "'related'", ":", "doc_id", "in", "cited_doc_ids", "\n", "}", ")", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.dataset.loader.SciFactAbstractRetrievalDataset.__len__": [[331, 333], ["len"], "methods", ["None"], ["", "", "", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "samples", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.dataset.loader.SciFactAbstractRetrievalDataset.__getitem__": [[334, 336], ["None"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "idx", ")", ":", "\n", "        ", "return", "self", ".", "samples", "[", "idx", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.dataset.loader.SciFactJointDataset.__init__": [[390, 500], ["jsonlines.open", "loader.SciFactJointDataset.rationale_label.items", "loader.SciFactJointDataset.abstract_label.items", "jsonlines.open", "int", "sorted", "loader.clean_invalid_sentence", "int", "list", "sentence.strip", "loader.clean_num", "loader.clean_num", "loader.SciFactJointDataset.samples.append", "loader.clean_num", "loader.SciFactJointDataset.samples.append", "list", "set", "int", "str", "set", "loader.clean_url", "loader.clean_url", "loader.clean_url", "claim[].keys", "loader.down_sample", "str", "loader.clean_num", "loader.clean_num", "loader.SciFactJointDataset.samples.append", "range", "loader.clean_url", "loader.clean_url", "len", "range", "len"], "methods", ["home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.dataset.loader.clean_invalid_sentence", "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.util.clean_num", "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.util.clean_num", "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.util.clean_num", "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.util.clean_url", "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.util.clean_url", "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.util.clean_url", "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.dataset.loader.down_sample", "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.util.clean_num", "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.util.clean_num", "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.util.clean_url", "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.util.clean_url"], ["    ", "def", "__init__", "(", "self", ",", "corpus", ":", "str", ",", "claims", ":", "str", ",", "sep_token", "=", "\"</s>\"", ",", "k", "=", "0", ",", "train", "=", "True", ",", "down_sampling", "=", "True", ")", ":", "\n", "# sep_token = ''", "\n", "        ", "self", ".", "rationale_label", "=", "{", "'NOT_ENOUGH_INFO'", ":", "0", ",", "'RATIONALE'", ":", "1", "}", "\n", "self", ".", "rev_rationale_label", "=", "{", "i", ":", "l", "for", "(", "l", ",", "i", ")", "in", "self", ".", "rationale_label", ".", "items", "(", ")", "}", "\n", "# self.abstract_label = {'CONTRADICT': 0, 'NOT_ENOUGH_INFO': 1, 'SUPPORT': 2}", "\n", "self", ".", "abstract_label", "=", "{", "'NOT_ENOUGH_INFO'", ":", "0", ",", "'CONTRADICT'", ":", "1", ",", "'SUPPORT'", ":", "2", "}", "\n", "self", ".", "rev_abstract_label", "=", "{", "i", ":", "l", "for", "(", "l", ",", "i", ")", "in", "self", ".", "abstract_label", ".", "items", "(", ")", "}", "\n", "\n", "self", ".", "samples", "=", "[", "]", "\n", "self", ".", "excluded_pairs", "=", "[", "]", "\n", "corpus", "=", "{", "doc", "[", "'doc_id'", "]", ":", "doc", "for", "doc", "in", "jsonlines", ".", "open", "(", "corpus", ")", "}", "\n", "\n", "for", "claim", "in", "jsonlines", ".", "open", "(", "claims", ")", ":", "\n", "            ", "if", "k", ">", "0", "and", "'doc_ids'", "in", "claim", ":", "\n", "                ", "candidate_abstract", "=", "claim", "[", "'doc_ids'", "]", "[", ":", "k", "]", "\n", "", "else", ":", "\n", "                ", "candidate_abstract", "=", "claim", "[", "'cited_doc_ids'", "]", "\n", "", "candidate_abstract", "=", "[", "int", "(", "c", ")", "for", "c", "in", "candidate_abstract", "]", "\n", "if", "train", ":", "\n", "                ", "evidence_doc_ids", "=", "[", "int", "(", "id", ")", "for", "id", "in", "list", "(", "claim", "[", "'evidence'", "]", ".", "keys", "(", ")", ")", "]", "\n", "all_candidates", "=", "sorted", "(", "(", "list", "(", "set", "(", "candidate_abstract", "+", "evidence_doc_ids", ")", ")", ")", ")", "\n", "# elif oracle:", "\n", "#     if claim['evidence'] != {}:", "\n", "#         all_candidates = [int(id) for id in list(claim['evidence'].keys())]", "\n", "#     else:", "\n", "#         all_candidates = []", "\n", "", "else", ":", "\n", "                ", "all_candidates", "=", "candidate_abstract", "\n", "", "for", "doc_id", "in", "all_candidates", ":", "\n", "                ", "doc", "=", "corpus", "[", "int", "(", "doc_id", ")", "]", "\n", "# doc_id = str(doc_id)", "\n", "abstract_sentences", "=", "[", "sentence", ".", "strip", "(", ")", "for", "sentence", "in", "doc", "[", "'abstract'", "]", "]", "\n", "abstract_sentences", "=", "clean_invalid_sentence", "(", "abstract_sentences", ")", "# #", "\n", "if", "train", ":", "\n", "                    ", "if", "str", "(", "doc_id", ")", "in", "claim", "[", "'evidence'", "]", ":", "# cited_doc is evidence", "\n", "                        ", "evidence", "=", "claim", "[", "'evidence'", "]", "[", "str", "(", "doc_id", ")", "]", "\n", "# print(str(doc_id), evidence)", "\n", "evidence_sentence_idx", "=", "{", "s", "for", "es", "in", "evidence", "for", "s", "in", "es", "[", "'sentences'", "]", "}", "\n", "# print(evidence_sentence_idx)", "\n", "labels", "=", "set", "(", "e", "[", "'label'", "]", "for", "e", "in", "evidence", ")", "\n", "if", "'SUPPORT'", "in", "labels", ":", "\n", "                            ", "label", "=", "'SUPPORT'", "\n", "", "elif", "'CONTRADICT'", "in", "labels", ":", "\n", "                            ", "label", "=", "'CONTRADICT'", "\n", "", "else", ":", "\n", "                            ", "label", "=", "'NOT_ENOUGH_INFO'", "\n", "\n", "", "if", "down_sampling", ":", "\n", "# down samples. Augment the data set, extract sentences from the evidence abstract.", "\n", "                            ", "kept_sentences", ",", "kept_evidence_idx", ",", "kept_label", "=", "down_sample", "(", "abstract_sentences", ",", "\n", "evidence_sentence_idx", ",", "\n", "label", ",", "0.5", ",", "sep_token", ")", "\n", "if", "kept_sentences", "is", "not", "None", ":", "\n", "                                ", "concat_sentences", "=", "(", "' '", "+", "sep_token", "+", "' '", ")", ".", "join", "(", "kept_sentences", ")", "\n", "concat_sentences", "=", "clean_num", "(", "clean_url", "(", "concat_sentences", ")", ")", "# clean the url in the sentence", "\n", "rationale_label_str", "=", "''", ".", "join", "(", "\n", "[", "'1'", "if", "i", "in", "kept_evidence_idx", "else", "'0'", "for", "i", "in", "range", "(", "len", "(", "kept_sentences", ")", ")", "]", ")", "\n", "title", "=", "clean_num", "(", "clean_url", "(", "doc", "[", "'title'", "]", ")", ")", "\n", "concat_sentences", "=", "title", "+", "' '", "+", "sep_token", "+", "' '", "+", "concat_sentences", "\n", "# concat_sentences = concat_sentences + ' ' + sep_token + ' ' + doc['title']", "\n", "# rationale_label_str = \"1\" + rationale_label_str", "\n", "\n", "self", ".", "samples", ".", "append", "(", "{", "\n", "'claim'", ":", "claim", "[", "'claim'", "]", ",", "\n", "'claim_id'", ":", "claim", "[", "'id'", "]", ",", "\n", "'doc_id'", ":", "doc", "[", "'doc_id'", "]", ",", "\n", "'abstract'", ":", "concat_sentences", ",", "\n", "# 'paragraph': ' '.join(kept_sentences),", "\n", "'title'", ":", "' '", "+", "sep_token", "+", "' '", ".", "join", "(", "doc", "[", "'title'", "]", ")", ",", "\n", "'sentence_label'", ":", "rationale_label_str", ",", "\n", "'abstract_label'", ":", "self", ".", "abstract_label", "[", "kept_label", "]", ",", "\n", "'sim_label'", ":", "1", "if", "doc", "[", "'doc_id'", "]", "in", "claim", "[", "'cited_doc_ids'", "]", "else", "0", ",", "\n", "}", ")", "\n", "\n", "", "", "", "else", ":", "# cited doc is not evidence", "\n", "                        ", "evidence_sentence_idx", "=", "{", "}", "\n", "label", "=", "'NOT_ENOUGH_INFO'", "\n", "", "concat_sentences", "=", "(", "' '", "+", "sep_token", "+", "\n", "' '", ")", ".", "join", "(", "abstract_sentences", ")", "# concat sentences in the abstract", "\n", "concat_sentences", "=", "clean_num", "(", "clean_url", "(", "concat_sentences", ")", ")", "# clean the url in the sentence", "\n", "rationale_label_str", "=", "''", ".", "join", "(", "\n", "[", "'1'", "if", "i", "in", "evidence_sentence_idx", "else", "'0'", "for", "i", "in", "range", "(", "len", "(", "abstract_sentences", ")", ")", "]", ")", "\n", "# print(rationale_label_str)", "\n", "title", "=", "clean_num", "(", "clean_url", "(", "doc", "[", "'title'", "]", ")", ")", "\n", "concat_sentences", "=", "title", "+", "' '", "+", "sep_token", "+", "' '", "+", "concat_sentences", "\n", "# rationale_label_str = \"1\" + rationale_label_str", "\n", "\n", "self", ".", "samples", ".", "append", "(", "{", "\n", "'claim'", ":", "claim", "[", "'claim'", "]", ",", "\n", "'claim_id'", ":", "claim", "[", "'id'", "]", ",", "\n", "'doc_id'", ":", "doc", "[", "'doc_id'", "]", ",", "\n", "'abstract'", ":", "concat_sentences", ",", "\n", "# 'paragraph': ' '.join(abstract_sentences),", "\n", "'title'", ":", "' '", "+", "sep_token", "+", "' '", ".", "join", "(", "doc", "[", "'title'", "]", ")", ",", "\n", "'sentence_label'", ":", "rationale_label_str", ",", "\n", "'abstract_label'", ":", "self", ".", "abstract_label", "[", "label", "]", ",", "\n", "'sim_label'", ":", "1", "if", "doc", "[", "'doc_id'", "]", "in", "claim", "[", "'cited_doc_ids'", "]", "else", "0", ",", "\n", "}", ")", "\n", "", "else", ":", "\n", "                    ", "concat_sentences", "=", "(", "' '", "+", "sep_token", "+", "' '", ")", ".", "join", "(", "abstract_sentences", ")", "\n", "title", "=", "clean_num", "(", "clean_url", "(", "doc", "[", "'title'", "]", ")", ")", "\n", "concat_sentences", "=", "title", "+", "' '", "+", "sep_token", "+", "' '", "+", "concat_sentences", "\n", "\n", "self", ".", "samples", ".", "append", "(", "{", "\n", "'claim'", ":", "claim", "[", "'claim'", "]", ",", "\n", "'claim_id'", ":", "claim", "[", "'id'", "]", ",", "\n", "'doc_id'", ":", "doc", "[", "'doc_id'", "]", ",", "\n", "'abstract'", ":", "concat_sentences", ",", "\n", "# 'paragraph': ' '.join(abstract_sentences),", "\n", "'title'", ":", "' '", "+", "sep_token", "+", "' '", ".", "join", "(", "doc", "[", "'title'", "]", ")", ",", "\n", "}", ")", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.dataset.loader.SciFactJointDataset.__len__": [[502, 504], ["len"], "methods", ["None"], ["", "", "", "", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "samples", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.dataset.loader.SciFactJointDataset.__getitem__": [[505, 507], ["None"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "idx", ")", ":", "\n", "        ", "return", "self", ".", "samples", "[", "idx", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.dataset.loader.SciFactJointPredictionData.__init__": [[510, 538], ["jsonlines.open", "corpus.keys", "loader.SciFactJointPredictionData.rationale_label.items", "loader.SciFactJointPredictionData.abstract_label.items", "jsonlines.open", "loader.clean_invalid_sentence", "loader.clean_num", "loader.SciFactJointPredictionData.samples.append", "sentence.strip", "loader.clean_url", "int"], "methods", ["home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.dataset.loader.clean_invalid_sentence", "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.util.clean_num", "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.util.clean_url"], ["    ", "def", "__init__", "(", "self", ",", "corpus", ":", "str", ",", "claims", ":", "str", ",", "sep_token", "=", "\"</s>\"", ")", ":", "\n", "# sep_token = ''", "\n", "        ", "self", ".", "rationale_label", "=", "{", "'NOT_ENOUGH_INFO'", ":", "0", ",", "'RATIONALE'", ":", "1", "}", "\n", "self", ".", "rev_rationale_label", "=", "{", "i", ":", "l", "for", "(", "l", ",", "i", ")", "in", "self", ".", "rationale_label", ".", "items", "(", ")", "}", "\n", "# self.abstract_label = {'CONTRADICT': 0, 'NOT_ENOUGH_INFO': 1, 'SUPPORT': 2}", "\n", "self", ".", "abstract_label", "=", "{", "'NOT_ENOUGH_INFO'", ":", "0", ",", "'CONTRADICT'", ":", "1", ",", "'SUPPORT'", ":", "2", "}", "\n", "self", ".", "rev_abstract_label", "=", "{", "i", ":", "l", "for", "(", "l", ",", "i", ")", "in", "self", ".", "abstract_label", ".", "items", "(", ")", "}", "\n", "\n", "self", ".", "samples", "=", "[", "]", "\n", "self", ".", "excluded_pairs", "=", "[", "]", "\n", "corpus", "=", "{", "doc", "[", "'doc_id'", "]", ":", "doc", "for", "doc", "in", "jsonlines", ".", "open", "(", "corpus", ")", "}", "\n", "for", "claim", "in", "jsonlines", ".", "open", "(", "claims", ")", ":", "\n", "            ", "for", "doc_id", "in", "corpus", ".", "keys", "(", ")", ":", "\n", "                ", "doc", "=", "corpus", "[", "int", "(", "doc_id", ")", "]", "\n", "# doc_id = str(doc_id)", "\n", "abstract_sentences", "=", "[", "sentence", ".", "strip", "(", ")", "for", "sentence", "in", "doc", "[", "'abstract'", "]", "]", "\n", "abstract_sentences", "=", "clean_invalid_sentence", "(", "abstract_sentences", ")", "# #", "\n", "concat_sentences", "=", "(", "' '", "+", "sep_token", "+", "' '", ")", ".", "join", "(", "abstract_sentences", ")", "\n", "title", "=", "clean_num", "(", "clean_url", "(", "doc", "[", "'title'", "]", ")", ")", "\n", "concat_sentences", "=", "title", "+", "' '", "+", "sep_token", "+", "' '", "+", "concat_sentences", "\n", "\n", "self", ".", "samples", ".", "append", "(", "{", "\n", "'claim'", ":", "claim", "[", "'claim'", "]", ",", "\n", "'claim_id'", ":", "claim", "[", "'id'", "]", ",", "\n", "'doc_id'", ":", "doc", "[", "'doc_id'", "]", ",", "\n", "'abstract'", ":", "concat_sentences", ",", "\n", "# 'paragraph': ' '.join(abstract_sentences),", "\n", "'title'", ":", "' '", "+", "sep_token", "+", "' '", ".", "join", "(", "doc", "[", "'title'", "]", ")", ",", "\n", "}", ")", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.dataset.loader.SciFactJointPredictionData.__len__": [[540, 542], ["len"], "methods", ["None"], ["", "", "", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "samples", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.dataset.loader.SciFactJointPredictionData.__getitem__": [[543, 545], ["None"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "idx", ")", ":", "\n", "        ", "return", "self", ".", "samples", "[", "idx", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.dataset.loader.FEVERParagraphBatchDataset.__init__": [[552, 627], ["jsonlines.open", "max", "loader.FEVERParagraphBatchDataset.label_ind.items", "loader.FEVERParagraphBatchDataset.stance_ind.items", "len", "len", "loader.clean_num", "len", "sent.split", "loader.clean_url", "set", "loader.FEVERParagraphBatchDataset.samples.append", "loader.clean_num", "loader.FEVERParagraphBatchDataset.__init__.max_sent_len"], "methods", ["home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.util.clean_num", "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.util.clean_url", "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.util.clean_num"], ["def", "__init__", "(", "self", ",", "datapath", ":", "str", ",", "sep_token", "=", "\"</s>\"", ",", "train", "=", "True", ",", "k", "=", "0", ")", ":", "\n", "        ", "self", ".", "label_ind", "=", "{", "\"NEI\"", ":", "0", ",", "\"rationale\"", ":", "1", "}", "\n", "self", ".", "rev_label_ind", "=", "{", "i", ":", "l", "for", "(", "l", ",", "i", ")", "in", "self", ".", "label_ind", ".", "items", "(", ")", "}", "\n", "self", ".", "stance_ind", "=", "{", "\"NOT ENOUGH INFO\"", ":", "0", ",", "\"CONTRADICT\"", ":", "1", ",", "\"SUPPORTS\"", ":", "2", "}", "\n", "self", ".", "rev_stance_ind", "=", "{", "i", ":", "l", "for", "(", "l", ",", "i", ")", "in", "self", ".", "stance_ind", ".", "items", "(", ")", "}", "\n", "\n", "self", ".", "samples", "=", "[", "]", "\n", "self", ".", "excluded_pairs", "=", "[", "]", "\n", "\n", "def", "max_sent_len", "(", "sentences", ")", ":", "\n", "            ", "return", "max", "(", "[", "len", "(", "sent", ".", "split", "(", ")", ")", "for", "sent", "in", "sentences", "]", ")", "\n", "\n", "", "for", "data", "in", "jsonlines", ".", "open", "(", "datapath", ")", ":", "\n", "            ", "try", ":", "\n", "                ", "if", "len", "(", "data", "[", "\"sentences\"", "]", ")", ">", "0", ":", "\n", "                    ", "sentences", "=", "data", "[", "\"sentences\"", "]", "\n", "if", "max_sent_len", "(", "sentences", ")", ">", "100", "or", "len", "(", "sentences", ")", ">", "100", ":", "\n", "                        ", "continue", "\n", "", "concat_sentences", "=", "(", "\" \"", "+", "sep_token", "+", "\" \"", ")", ".", "join", "(", "sentences", ")", "\n", "concat_sentences", "=", "clean_num", "(", "clean_url", "(", "concat_sentences", ")", ")", "\n", "if", "train", ":", "\n", "                        ", "rationales", "=", "[", "]", "\n", "for", "evid", "in", "data", "[", "\"evidence_sets\"", "]", ":", "\n", "                            ", "rationales", ".", "extend", "(", "evid", ")", "\n", "", "evidence_idx", "=", "set", "(", "rationales", ")", "\n", "rationale_label_string", "=", "\"\"", ".", "join", "(", "\n", "[", "\"1\"", "if", "i", "in", "evidence_idx", "else", "\"0\"", "for", "i", "in", "range", "(", "len", "(", "sentences", ")", ")", "]", ")", "\n", "\n", "self", ".", "samples", ".", "append", "(", "{", "\n", "'claim'", ":", "data", "[", "'claim'", "]", ",", "\n", "'claim_id'", ":", "data", "[", "'id'", "]", ",", "\n", "'abstract'", ":", "concat_sentences", ",", "\n", "'sentence_label'", ":", "rationale_label_string", ",", "\n", "'abstract_label'", ":", "self", ".", "stance_ind", "[", "data", "[", "\"label\"", "]", "]", ",", "\n", "'sim_label'", ":", "1", "if", "int", "(", "self", ".", "stance_ind", "[", "data", "[", "\"label\"", "]", "]", ")", "==", "1", "or", "int", "(", "\n", "self", ".", "stance_ind", "[", "data", "[", "\"label\"", "]", "]", ")", "==", "2", "else", "0", "\n", "}", ")", "\n", "", "elif", "data", "[", "\"hit\"", "]", ":", "# The retrieved pages hit the gold page.", "\n", "                        ", "self", ".", "samples", ".", "append", "(", "{", "\n", "'claim'", ":", "data", "[", "'claim'", "]", ",", "\n", "'claim_id'", ":", "data", "[", "'id'", "]", ",", "\n", "'abstract'", ":", "concat_sentences", "\n", "}", ")", "\n", "", "", "", "except", ":", "\n", "                ", "pass", "\n", "", "try", ":", "\n", "                ", "if", "len", "(", "data", "[", "\"negative_sentences\"", "]", ")", ">", "0", ":", "\n", "                    ", "for", "sentences", "in", "data", "[", "\"negative_sentences\"", "]", "[", ":", "k", "]", ":", "\n", "                        ", "if", "max_sent_len", "(", "sentences", ")", ">", "100", "or", "len", "(", "sentences", ")", ">", "100", ":", "\n", "                            ", "continue", "\n", "\n", "", "concat_sentences", "=", "(", "\" \"", "+", "sep_token", "+", "\" \"", ")", ".", "join", "(", "sentences", ")", "\n", "concat_sentences", "=", "clean_num", "(", "clean_url", "(", "concat_sentences", ")", ")", "\n", "\n", "if", "train", ":", "\n", "                            ", "rationale_label_string", "=", "\"0\"", "*", "len", "(", "sentences", ")", "\n", "\n", "self", ".", "samples", ".", "append", "(", "{", "\n", "'claim'", ":", "data", "[", "'claim'", "]", ",", "\n", "'claim_id'", ":", "data", "[", "'id'", "]", ",", "\n", "'abstract'", ":", "concat_sentences", ",", "\n", "'sentence_label'", ":", "rationale_label_string", ",", "\n", "'abstract_label'", ":", "self", ".", "stance_ind", "[", "\"NOT ENOUGH INFO\"", "]", ",", "\n", "'sim_label'", ":", "1", "if", "int", "(", "self", ".", "stance_ind", "[", "\"NOT ENOUGH INFO\"", "]", ")", "==", "1", "or", "int", "(", "\n", "self", ".", "stance_ind", "[", "\"NOT ENOUGH INFO\"", "]", ")", "==", "2", "else", "0", "\n", "}", ")", "\n", "", "else", ":", "\n", "\n", "                            ", "self", ".", "samples", ".", "append", "(", "{", "\n", "'claim'", ":", "data", "[", "'claim'", "]", ",", "\n", "'claim_id'", ":", "data", "[", "'id'", "]", ",", "\n", "'abstract'", ":", "concat_sentences", "\n", "}", ")", "\n", "", "", "", "", "except", ":", "\n", "                ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.dataset.loader.FEVERParagraphBatchDataset.__len__": [[628, 630], ["len"], "methods", ["None"], ["", "", "", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "samples", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.dataset.loader.FEVERParagraphBatchDataset.__getitem__": [[631, 633], ["None"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "idx", ")", ":", "\n", "        ", "return", "self", ".", "samples", "[", "idx", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.dataset.loader.loader_json": [[31, 34], ["json.loads", "open"], "function", ["None"], ["def", "loader_json", "(", "file_name", ")", ":", "\n", "# return jsonlines.open(file_name)", "\n", "    ", "return", "[", "json", ".", "loads", "(", "line", ")", "for", "line", "in", "open", "(", "file_name", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.dataset.loader.get_corpus": [[36, 38], ["jsonlines.open"], "function", ["None"], ["", "def", "get_corpus", "(", "corpus_path", ")", ":", "\n", "    ", "return", "{", "doc", "[", "'doc_id'", "]", ":", "doc", "for", "doc", "in", "jsonlines", ".", "open", "(", "corpus_path", ")", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.dataset.loader._read_words": [[40, 53], ["None"], "function", ["None"], ["", "def", "_read_words", "(", "data", ")", ":", "\n", "    ", "'''\n        Count the occurrences of all words\n        @param data: list of examples\n        @return words: list of words (with duplicates)\n    '''", "\n", "words", "=", "[", "]", "\n", "for", "example", "in", "data", ":", "\n", "        ", "if", "'sentence'", "in", "example", ":", "\n", "            ", "words", "+=", "example", "[", "'sentence'", "]", "\n", "", "else", ":", "\n", "            ", "words", "+=", "example", "[", "'rationale'", "]", "\n", "", "", "return", "words", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.dataset.loader._sentence_to_words": [[55, 69], ["range", "new_text.append", "nltk.tokenize.word_tokenize", "nltk.tokenize.word_tokenize", "len", "len"], "function", ["None"], ["", "def", "_sentence_to_words", "(", "text", ",", "is_abstract", "=", "False", ")", ":", "\n", "    ", "if", "is_abstract", ":", "\n", "        ", "new_text", "=", "[", "]", "\n", "for", "sentences", "in", "text", ":", "\n", "            ", "sentence2words", "=", "[", "word_tokenize", "(", "word", ")", "for", "word", "in", "sentences", "]", "\n", "tmp", "=", "[", "]", "\n", "for", "word_id", "in", "range", "(", "len", "(", "sentence2words", ")", ")", ":", "\n", "                ", "tmp", "+=", "sentence2words", "[", "word_id", "]", "\n", "if", "word_id", "<", "len", "(", "sentence2words", ")", "-", "1", ":", "\n", "                    ", "tmp", "+=", "\"\\\"\"", "\n", "", "", "new_text", ".", "append", "(", "tmp", ")", "\n", "", "", "else", ":", "\n", "        ", "new_text", "=", "[", "word_tokenize", "(", "word", ")", "for", "word", "in", "text", "]", "\n", "", "return", "new_text", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.dataset.loader._data_to_array": [[71, 91], ["None"], "function", ["None"], ["", "def", "_data_to_array", "(", "data", ",", "is_corpus", "=", "False", ")", ":", "\n", "    ", "if", "is_corpus", ":", "\n", "        ", "doc_ids", "=", "[", "x", "[", "'doc_id'", "]", "for", "x", "in", "data", "]", "\n", "title", "=", "[", "x", "[", "'title'", "]", "for", "x", "in", "data", "]", "\n", "abstract", "=", "[", "x", "[", "'abstract'", "]", "for", "x", "in", "data", "]", "\n", "structured", "=", "[", "x", "[", "'structured'", "]", "for", "x", "in", "data", "]", "\n", "new_data", "=", "{", "'doc_id'", ":", "doc_ids", ",", "\n", "'title'", ":", "title", ",", "\n", "'abstract'", ":", "abstract", ",", "\n", "'structured'", ":", "structured", "}", "\n", "", "else", ":", "\n", "        ", "claim_id", "=", "[", "x", "[", "'id'", "]", "for", "x", "in", "data", "]", "\n", "claims", "=", "[", "x", "[", "'claim'", "]", "for", "x", "in", "data", "]", "\n", "evidences", "=", "[", "x", "[", "'evidence'", "]", "for", "x", "in", "data", "]", "\n", "cited_doc_ids", "=", "[", "x", "[", "'cited_doc_ids'", "]", "for", "x", "in", "data", "]", "\n", "new_data", "=", "{", "'id'", ":", "claim_id", ",", "\n", "'claim'", ":", "claims", ",", "\n", "'evidence'", ":", "evidences", ",", "\n", "'cited_doc_ids'", ":", "cited_doc_ids", "}", "\n", "", "return", "new_data", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.dataset.loader._data_encode": [[93, 164], ["numpy.array", "numpy.array", "max", "range", "numpy.array", "max", "range", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.ones", "len", "numpy.ones", "len", "range", "range", "len", "numpy.max", "del_idx.append", "len", "numpy.max", "del_idx.append", "len", "new_data.append", "len", "new_data.append", "len", "min", "len", "min", "len", "len", "min", "len"], "function", ["None"], ["", "def", "_data_encode", "(", "data", ",", "vocab", ",", "state", "=", "'rationale'", ")", ":", "\n", "    ", "claims", "=", "np", ".", "array", "(", "[", "doc", "[", "'claim'", "]", "for", "doc", "in", "data", "]", ",", "dtype", "=", "object", ")", "\n", "if", "state", "==", "'rationale'", ":", "\n", "        ", "sentences", "=", "np", ".", "array", "(", "[", "doc", "[", "'sentence'", "]", "for", "doc", "in", "data", "]", ",", "dtype", "=", "object", ")", "\n", "evidences", "=", "np", ".", "array", "(", "[", "doc", "[", "'evidence'", "]", "for", "doc", "in", "data", "]", ")", "\n", "", "else", ":", "\n", "        ", "sentences", "=", "np", ".", "array", "(", "[", "doc", "[", "'rationale'", "]", "for", "doc", "in", "data", "]", ",", "dtype", "=", "object", ")", "\n", "evidences", "=", "np", ".", "array", "(", "[", "doc", "[", "'label'", "]", "for", "doc", "in", "data", "]", ")", "\n", "############################################################################", "\n", "# compute the max text length", "\n", "", "claim_len", "=", "np", ".", "array", "(", "[", "len", "(", "e", ")", "for", "e", "in", "claims", "]", ")", "\n", "max_claim_len", "=", "max", "(", "claim_len", ")", "\n", "\n", "# initialize the big numpy array by <pad>", "\n", "claim_ids", "=", "vocab", ".", "stoi", "[", "'<pad>'", "]", "*", "np", ".", "ones", "(", "[", "len", "(", "data", ")", ",", "min", "(", "max_claim_len", ",", "512", ")", "]", ",", "\n", "dtype", "=", "np", ".", "int64", ")", "\n", "\n", "del_idx", "=", "[", "]", "\n", "# convert each token to its corresponding id", "\n", "for", "i", "in", "range", "(", "len", "(", "data", ")", ")", ":", "\n", "        ", "claim_ids", "[", "i", ",", ":", "len", "(", "claims", "[", "i", "]", ")", "]", "=", "[", "\n", "vocab", ".", "stoi", "[", "x", "]", "if", "x", "in", "vocab", ".", "stoi", "else", "vocab", ".", "stoi", "[", "'<unk>'", "]", "\n", "for", "x", "in", "claims", "[", "i", "]", "]", "\n", "\n", "# filter out document with only unk and pad", "\n", "if", "np", ".", "max", "(", "claim_ids", "[", "i", "]", ")", "<", "2", ":", "\n", "            ", "del_idx", ".", "append", "(", "i", ")", "\n", "############################################################################", "\n", "# compute the max text length", "\n", "", "", "sentence_len", "=", "np", ".", "array", "(", "[", "len", "(", "e", ")", "for", "e", "in", "sentences", "]", ")", "\n", "max_sentence_len", "=", "max", "(", "sentence_len", ")", "\n", "\n", "# initialize the big numpy array by <pad>", "\n", "sentence_ids", "=", "vocab", ".", "stoi", "[", "'<pad>'", "]", "*", "np", ".", "ones", "(", "[", "len", "(", "data", ")", ",", "min", "(", "max_sentence_len", ",", "512", ")", "]", ",", "\n", "dtype", "=", "np", ".", "int64", ")", "\n", "\n", "del_idx", "=", "[", "]", "\n", "# convert each token to its corresponding id", "\n", "for", "i", "in", "range", "(", "len", "(", "data", ")", ")", ":", "\n", "        ", "sentence_ids", "[", "i", ",", ":", "len", "(", "sentences", "[", "i", "]", ")", "]", "=", "[", "\n", "vocab", ".", "stoi", "[", "x", "]", "if", "x", "in", "vocab", ".", "stoi", "else", "vocab", ".", "stoi", "[", "'<unk>'", "]", "\n", "for", "x", "in", "sentences", "[", "i", "]", "[", ":", "min", "(", "len", "(", "sentences", ")", ",", "512", ")", "]", "]", "\n", "\n", "# filter out document with only unk and pad", "\n", "if", "np", ".", "max", "(", "claim_ids", "[", "i", "]", ")", "<", "2", ":", "\n", "            ", "del_idx", ".", "append", "(", "i", ")", "\n", "\n", "", "", "new_data", "=", "[", "]", "\n", "if", "state", "==", "'rationale'", ":", "\n", "        ", "for", "ids", "in", "range", "(", "len", "(", "claim_ids", ")", ")", ":", "\n", "            ", "new_data", ".", "append", "(", "{", "\n", "'claim_ids'", ":", "claim_ids", "[", "ids", "]", ",", "\n", "'claim'", ":", "claims", "[", "ids", "]", ",", "\n", "'claim_len'", ":", "claim_len", "[", "ids", "]", ",", "\n", "'sentence_ids'", ":", "sentence_ids", "[", "ids", "]", ",", "\n", "'sentence'", ":", "sentences", "[", "ids", "]", ",", "\n", "'sentence_len'", ":", "sentence_len", "[", "ids", "]", ",", "\n", "'evidence'", ":", "evidences", "[", "ids", "]", ",", "\n", "}", ")", "\n", "", "", "else", ":", "\n", "        ", "for", "ids", "in", "range", "(", "len", "(", "claim_ids", ")", ")", ":", "\n", "            ", "new_data", ".", "append", "(", "{", "\n", "'claim_ids'", ":", "claim_ids", "[", "ids", "]", ",", "\n", "'claim'", ":", "claims", "[", "ids", "]", ",", "\n", "'claim_len'", ":", "claim_len", "[", "ids", "]", ",", "\n", "'rationale_ids'", ":", "sentence_ids", "[", "ids", "]", ",", "\n", "'rationale'", ":", "sentences", "[", "ids", "]", ",", "\n", "'rationale_len'", ":", "sentence_len", "[", "ids", "]", ",", "\n", "'label'", ":", "evidences", "[", "ids", "]", ",", "\n", "}", ")", "\n", "", "", "return", "new_data", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.dataset.loader.clean_url": [[338, 346], ["re.sub", "re.sub"], "function", ["None"], ["", "", "def", "clean_url", "(", "word", ")", ":", "\n", "    ", "\"\"\"\n        Clean specific data format from social media\n    \"\"\"", "\n", "# clean urls", "\n", "word", "=", "re", ".", "sub", "(", "r'https? : \\/\\/.*[\\r\\n]*'", ",", "'<URL>'", ",", "word", ")", "\n", "word", "=", "re", ".", "sub", "(", "r'exlink'", ",", "'<URL>'", ",", "word", ")", "\n", "return", "word", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.dataset.loader.clean_num": [[348, 358], ["any", "char.isdigit", "float", "word.replace", "any", "char.isalpha"], "function", ["None"], ["", "def", "clean_num", "(", "word", ")", ":", "\n", "# check if the word contain number and no letters", "\n", "    ", "if", "any", "(", "char", ".", "isdigit", "(", ")", "for", "char", "in", "word", ")", ":", "\n", "        ", "try", ":", "\n", "            ", "num", "=", "float", "(", "word", ".", "replace", "(", "','", ",", "''", ")", ")", "\n", "return", "'@'", "\n", "", "except", ":", "\n", "            ", "if", "not", "any", "(", "char", ".", "isalpha", "(", ")", "for", "char", "in", "word", ")", ":", "\n", "                ", "return", "'@'", "\n", "", "", "", "return", "word", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.dataset.loader.clean_invalid_sentence": [[360, 367], ["re.sub().strip", "sentences.append", "re.sub"], "function", ["None"], ["", "def", "clean_invalid_sentence", "(", "abstract", ")", ":", "\n", "    ", "sentences", "=", "[", "]", "\n", "for", "sen", "in", "abstract", ":", "\n", "        ", "sen", "=", "re", ".", "sub", "(", "r'[?\\.?\\s]'", ",", "' '", ",", "sen", ")", ".", "strip", "(", ")", "\n", "if", "sen", "!=", "''", ":", "\n", "            ", "sentences", ".", "append", "(", "sen", ")", "\n", "", "", "return", "sentences", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.dataset.loader.down_sample": [[369, 387], ["enumerate", "enumerate", "len", "set", "random.random", "kept_sentences.append", "kept_evidence_idx.append", "len", "evidence_map.append", "evidence_map.append"], "function", ["None"], ["", "def", "down_sample", "(", "abstract_sentences", ",", "evidence_sentence_idx", ",", "label", ",", "p", ",", "sep_token", ")", ":", "\n", "    ", "kept_sentences", "=", "[", "]", "\n", "evidence_map", "=", "[", "]", "\n", "for", "i", ",", "sentence", "in", "enumerate", "(", "abstract_sentences", ")", ":", "\n", "        ", "if", "random", ".", "random", "(", ")", "<", "p", ":", "\n", "            ", "kept_sentences", ".", "append", "(", "sentence", ")", "\n", "if", "i", "in", "evidence_sentence_idx", ":", "\n", "                ", "evidence_map", ".", "append", "(", "True", ")", "# i is evidence", "\n", "", "else", ":", "\n", "                ", "evidence_map", ".", "append", "(", "False", ")", "\n", "", "", "", "if", "len", "(", "kept_sentences", ")", "==", "0", ":", "\n", "        ", "return", "None", ",", "None", ",", "None", "\n", "", "kept_evidence_idx", "=", "[", "]", "\n", "for", "i", ",", "e", "in", "enumerate", "(", "evidence_map", ")", ":", "\n", "        ", "if", "e", ":", "\n", "            ", "kept_evidence_idx", ".", "append", "(", "i", ")", "\n", "", "", "kept_label", "=", "label", "if", "len", "(", "kept_evidence_idx", ")", ">", "0", "else", "\"NOT_ENOUGH_INFO\"", "\n", "return", "kept_sentences", ",", "set", "(", "kept_evidence_idx", ")", ",", "kept_label", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.embedding.jointmodel.TimeDistributed.__init__": [[42, 46], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.label_prediction.transformer_scifact.SciFactLabelPredictionDataset.__init__"], ["    ", "def", "__init__", "(", "self", ",", "input_size", ",", "output_size", ",", "batch_first", "=", "False", ")", ":", "\n", "        ", "super", "(", "TimeDistributed", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "module", "=", "nn", ".", "Linear", "(", "input_size", ",", "output_size", ",", "bias", "=", "True", ")", "\n", "self", ".", "batch_first", "=", "batch_first", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.embedding.jointmodel.TimeDistributed.forward": [[47, 65], ["x.contiguous().view", "jointmodel.TimeDistributed.module", "len", "jointmodel.TimeDistributed.module", "x.size", "y.view.view.contiguous().view", "y.view.view.view", "x.size", "x.contiguous", "x.size", "y.view.view.size", "x.size", "y.view.view.size", "y.view.view.contiguous"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "\n", "        ", "if", "len", "(", "x", ".", "size", "(", ")", ")", "<=", "2", ":", "\n", "            ", "return", "self", ".", "module", "(", "x", ")", "\n", "\n", "# reshape input data --> (samples * timesteps, input_size)", "\n", "# Squash samples and timesteps into a single axis", "\n", "", "x_reshape", "=", "x", ".", "contiguous", "(", ")", ".", "view", "(", "-", "1", ",", "x", ".", "size", "(", "-", "1", ")", ")", "# (samples * timesteps, input_size)", "\n", "\n", "y", "=", "self", ".", "module", "(", "x_reshape", ")", "\n", "\n", "# We have to reshape Y", "\n", "if", "self", ".", "batch_first", ":", "\n", "            ", "y", "=", "y", ".", "contiguous", "(", ")", ".", "view", "(", "x", ".", "size", "(", "0", ")", ",", "-", "1", ",", "y", ".", "size", "(", "-", "1", ")", ")", "# (samples, timesteps, output_size)", "\n", "", "else", ":", "\n", "            ", "y", "=", "y", ".", "view", "(", "-", "1", ",", "x", ".", "size", "(", "1", ")", ",", "y", ".", "size", "(", "-", "1", ")", ")", "# (timesteps, samples, output_size)", "\n", "\n", "", "return", "y", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.embedding.jointmodel.ConvLayer.__init__": [[68, 81], ["torch.Module.__init__", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d"], "methods", ["home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.label_prediction.transformer_scifact.SciFactLabelPredictionDataset.__init__"], ["    ", "def", "__init__", "(", "self", ",", "hidden_size", ",", "dropout", "=", "0.1", ")", ":", "\n", "        ", "super", "(", "ConvLayer", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "dropout", ")", "\n", "self", ".", "num_channels", "=", "hidden_size", "//", "3", "\n", "self", ".", "max_position_embeddings", "=", "512", "\n", "self", ".", "hidden_size", "=", "hidden_size", "\n", "\n", "self", ".", "conv1", "=", "nn", ".", "Conv2d", "(", "in_channels", "=", "1", ",", "out_channels", "=", "self", ".", "num_channels", ",", "kernel_size", "=", "(", "1", ",", "hidden_size", ")", ",", "\n", "stride", "=", "1", ",", "padding", "=", "0", ",", "dilation", "=", "1", ",", "groups", "=", "1", ",", "bias", "=", "True", ")", "\n", "self", ".", "conv2", "=", "nn", ".", "Conv2d", "(", "in_channels", "=", "1", ",", "out_channels", "=", "self", ".", "num_channels", ",", "kernel_size", "=", "(", "5", ",", "hidden_size", ")", ",", "\n", "stride", "=", "1", ",", "padding", "=", "(", "2", ",", "0", ")", ",", "dilation", "=", "1", ",", "groups", "=", "1", ",", "bias", "=", "True", ")", "\n", "self", ".", "conv3", "=", "nn", ".", "Conv2d", "(", "in_channels", "=", "1", ",", "out_channels", "=", "self", ".", "num_channels", ",", "kernel_size", "=", "(", "9", ",", "hidden_size", ")", ",", "\n", "stride", "=", "1", ",", "padding", "=", "(", "4", ",", "0", ")", ",", "dilation", "=", "1", ",", "groups", "=", "1", ",", "bias", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.embedding.jointmodel.ConvLayer.convlution": [[82, 87], ["conv", "torch.relu", "torch.relu", "torch.relu", "conv.squeeze"], "methods", ["None"], ["", "def", "convlution", "(", "self", ",", "x", ",", "conv", ")", ":", "\n", "        ", "out", "=", "conv", "(", "x", ")", "# [batch_size, hidden_dim // 3, sequence_len]", "\n", "activation", "=", "F", ".", "relu", "(", "out", ".", "squeeze", "(", "3", ")", ")", "\n", "out", "=", "activation", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.embedding.jointmodel.ConvLayer.forward": [[88, 98], ["x.unsqueeze", "jointmodel.ConvLayer.convlution", "jointmodel.ConvLayer.convlution", "jointmodel.ConvLayer.convlution", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "jointmodel.ConvLayer.dropout", "pooled_output.permute.permute.permute"], "methods", ["home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.embedding.jointmodel.ConvLayer.convlution", "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.embedding.jointmodel.ConvLayer.convlution", "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.embedding.jointmodel.ConvLayer.convlution"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "pooled_output", "=", "x", ".", "unsqueeze", "(", "1", ")", "\n", "h1", "=", "self", ".", "convlution", "(", "pooled_output", ",", "self", ".", "conv1", ")", "\n", "h2", "=", "self", ".", "convlution", "(", "pooled_output", ",", "self", ".", "conv2", ")", "\n", "h3", "=", "self", ".", "convlution", "(", "pooled_output", ",", "self", ".", "conv3", ")", "\n", "\n", "pooled_output", "=", "torch", ".", "cat", "(", "[", "h1", ",", "h2", ",", "h3", "]", ",", "1", ")", "\n", "pooled_output", "=", "self", ".", "dropout", "(", "pooled_output", ")", "\n", "pooled_output", "=", "pooled_output", ".", "permute", "(", "0", ",", "2", ",", "1", ")", "# [batch_size, sequence_len, hidden_dim]", "\n", "return", "pooled_output", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.embedding.jointmodel.LSTM.__init__": [[101, 117], ["torch.Module.__init__", "torch.LSTM", "torch.LSTM", "torch.LSTM"], "methods", ["home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.label_prediction.transformer_scifact.SciFactLabelPredictionDataset.__init__"], ["    ", "def", "__init__", "(", "self", ",", "hidden_size", ",", "dropout", "=", "0.1", ")", ":", "\n", "        ", "super", "(", "LSTM", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "embed_dim", "=", "hidden_size", "\n", "self", ".", "hidden_size", "=", "hidden_size", "//", "2", "\n", "self", ".", "layer_size", "=", "1", "\n", "self", ".", "bidirectional", "=", "True", "\n", "self", ".", "lstm", "=", "nn", ".", "LSTM", "(", "self", ".", "embed_dim", ",", "\n", "self", ".", "hidden_size", ",", "\n", "self", ".", "layer_size", ",", "\n", "dropout", "=", "dropout", ",", "\n", "bidirectional", "=", "self", ".", "bidirectional", ")", "\n", "\n", "if", "self", ".", "bidirectional", ":", "\n", "            ", "self", ".", "layer_size", "=", "self", ".", "layer_size", "*", "2", "\n", "", "else", ":", "\n", "            ", "self", ".", "layer_size", "=", "self", ".", "layer_size", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.embedding.jointmodel.LSTM.forward": [[118, 124], ["x.permute.permute.permute", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "jointmodel.LSTM.lstm", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "x.permute.permute.size", "x.permute.permute.size"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "x", ".", "permute", "(", "1", ",", "0", ",", "2", ")", "\n", "h_0", "=", "Variable", "(", "torch", ".", "zeros", "(", "self", ".", "layer_size", ",", "x", ".", "size", "(", "1", ")", ",", "self", ".", "hidden_size", ")", ".", "cuda", "(", ")", ")", "\n", "c_0", "=", "Variable", "(", "torch", ".", "zeros", "(", "self", ".", "layer_size", ",", "x", ".", "size", "(", "1", ")", ",", "self", ".", "hidden_size", ")", ".", "cuda", "(", ")", ")", "\n", "lstm_output", ",", "(", "_", ",", "_", ")", "=", "self", ".", "lstm", "(", "x", ",", "(", "h_0", ",", "c_0", ")", ")", "\n", "return", "lstm_output", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.embedding.jointmodel.WordAttention.__init__": [[130, 135], ["torch.Module.__init__", "jointmodel.TimeDistributed", "torch.Dropout", "torch.Dropout", "torch.Dropout", "jointmodel.TimeDistributed"], "methods", ["home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.label_prediction.transformer_scifact.SciFactLabelPredictionDataset.__init__"], ["def", "__init__", "(", "self", ",", "input_size", ",", "output_size", ",", "dropout", "=", "0.1", ")", ":", "\n", "        ", "super", "(", "WordAttention", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "word_attention", "=", "TimeDistributed", "(", "input_size", ",", "output_size", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "dropout", ")", "\n", "self", ".", "att_scorer", "=", "TimeDistributed", "(", "output_size", ",", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.embedding.jointmodel.WordAttention.forward": [[136, 167], ["jointmodel.WordAttention.dropout", "jointmodel.WordAttention.word_attention", "jointmodel.WordAttention.dropout", "jointmodel.WordAttention.att_scorer().squeeze().view", "jointmodel.WordAttention.masked_fill", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where.view", "torch.where.view", "torch.where.view", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "out.view.view.view", "x.view", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "x.size", "x.size", "x.size", "float", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.where.size", "torch.where.size", "torch.where.size", "x.size", "x.size", "x.size", "x.size", "jointmodel.WordAttention.att_scorer().squeeze", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.where.view.unsqueeze", "x.view", "jointmodel.WordAttention.att_scorer", "x.size", "x.size"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "token_mask", ")", ":", "\n", "# valid_abstract = valid_abstract.repeat(token_mask.shape[1], 1).transpose(0, 1).unsqueeze(2)", "\n", "        ", "att_s", "=", "self", ".", "dropout", "(", "x", ".", "view", "(", "-", "1", ",", "x", ".", "size", "(", "-", "1", ")", ")", ")", "\n", "att_s", "=", "self", ".", "word_attention", "(", "att_s", ")", "\n", "att_s", "=", "self", ".", "dropout", "(", "torch", ".", "tanh", "(", "att_s", ")", ")", "# [batch_size * num_sentence * num_token, hidden_dim]  # nan", "\n", "raw_att_scores", "=", "self", ".", "att_scorer", "(", "att_s", ")", ".", "squeeze", "(", "-", "1", ")", ".", "view", "(", "x", ".", "size", "(", "0", ")", ",", "x", ".", "size", "(", "1", ")", ",", "\n", "x", ".", "size", "(", "2", ")", ")", "# [batch_size, num_sentence, num_token]", "\n", "# raw_att_scores = raw_att_scores.masked_fill(~valid_abstract, -1e4)", "\n", "u_w", "=", "raw_att_scores", ".", "masked_fill", "(", "(", "1", "-", "token_mask", ")", ".", "bool", "(", ")", ",", "float", "(", "'-inf'", ")", ")", "\n", "# val = u_w.max()", "\n", "# att_scores = torch.exp(u_w - val)", "\n", "# att_scores = u_w", "\n", "# att_scores = att_scores / torch.sum(att_scores, dim=1, keepdim=True)", "\n", "att_scores", "=", "torch", ".", "softmax", "(", "u_w", ",", "dim", "=", "-", "1", ")", "\n", "# att_scores = torch.mul(sentence_att_score.unsqueeze(2), att_scores)", "\n", "# att_scores = att_scores / torch.sum(att_scores, dim=1, keepdim=True)", "\n", "att_scores", "=", "torch", ".", "where", "(", "torch", ".", "isnan", "(", "att_scores", ")", ",", "torch", ".", "zeros_like", "(", "att_scores", ")", ",", "\n", "att_scores", ")", "# replace NaN with 0", "\n", "# batch_att_scores: word attention scores. [batch_size * num_sentence, num_token]", "\n", "batch_att_scores", "=", "att_scores", ".", "view", "(", "-", "1", ",", "att_scores", ".", "size", "(", "-", "1", ")", ")", "# word attention weight matrix.", "\n", "# print('batch_att_scores: ', batch_att_scores)", "\n", "# print('batch_att_scores*att_scores:', torch.mul(sentence_att_score.unsqueeze(2), batch_att_scores))", "\n", "# out:  # sentence_representations. [batch_size, num_sentence, hidden_dim]", "\n", "out", "=", "torch", ".", "bmm", "(", "batch_att_scores", ".", "unsqueeze", "(", "1", ")", ",", "x", ".", "view", "(", "-", "1", ",", "x", ".", "size", "(", "2", ")", ",", "x", ".", "size", "(", "3", ")", ")", ")", ".", "squeeze", "(", "1", ")", "\n", "out", "=", "out", ".", "view", "(", "x", ".", "size", "(", "0", ")", ",", "x", ".", "size", "(", "1", ")", ",", "x", ".", "size", "(", "-", "1", ")", ")", "# [batch_size, num_sentence, hidden_dim]", "\n", "# print('sentence_reps: ', out)", "\n", "# out = torch.mul(sentence_att_score.unsqueeze(2), out)", "\n", "# print('sentence_reps*att_scores: ', out)", "\n", "# print(100*'-*=')", "\n", "mask", "=", "token_mask", "[", ":", ",", ":", ",", "0", "]", "# [batch_size, num_sentence]", "\n", "return", "out", ",", "mask", ",", "att_scores", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.embedding.jointmodel.SentenceAttention.__init__": [[173, 182], ["torch.Module.__init__", "jointmodel.TimeDistributed", "torch.Dropout", "torch.Dropout", "torch.Dropout", "jointmodel.TimeDistributed", "torch.LSTM", "torch.LSTM", "torch.LSTM"], "methods", ["home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.label_prediction.transformer_scifact.SciFactLabelPredictionDataset.__init__"], ["def", "__init__", "(", "self", ",", "input_size", ",", "output_size", ",", "dropout", "=", "0.1", ")", ":", "\n", "        ", "super", "(", "SentenceAttention", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "sentence_attention", "=", "TimeDistributed", "(", "input_size", ",", "output_size", ")", "\n", "self", ".", "activation", "=", "torch", ".", "tanh", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "dropout", ")", "\n", "self", ".", "att_scorer", "=", "TimeDistributed", "(", "output_size", ",", "1", ")", "\n", "self", ".", "contextualized", "=", "False", "\n", "self", ".", "hidden_size", "=", "input_size", "//", "2", "\n", "self", ".", "lstm", "=", "nn", ".", "LSTM", "(", "input_size", ",", "self", ".", "hidden_size", ",", "1", ",", "dropout", "=", "dropout", ",", "bidirectional", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.embedding.jointmodel.SentenceAttention.forward": [[183, 202], ["torch.logical_and", "torch.logical_and", "torch.logical_and", "torch.logical_and", "torch.logical_and", "torch.logical_and", "torch.logical_and", "torch.logical_and", "torch.logical_and", "jointmodel.SentenceAttention.dropout", "jointmodel.SentenceAttention.sentence_attention", "jointmodel.SentenceAttention.dropout", "jointmodel.SentenceAttention.att_scorer().squeeze().view", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "u_w.masked_fill.masked_fill.masked_fill", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "sentence_reps.size", "sentence_reps.size", "u_w.masked_fill.masked_fill.masked_fill", "jointmodel.SentenceAttention.att_scorer().squeeze", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.softmax.unsqueeze", "torch.softmax.unsqueeze", "torch.softmax.unsqueeze", "jointmodel.SentenceAttention.att_scorer"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "sentence_reps", ",", "sentence_mask", ",", "valid_scores", ")", ":", "\n", "        ", "sentence_masks", "=", "torch", ".", "logical_and", "(", "sentence_mask", ",", "valid_scores", ")", "\n", "# h_0 = Variable(torch.zeros(2, sentence_reps.size(1), self.hidden_size).cuda())", "\n", "# c_0 = Variable(torch.zeros(2, sentence_reps.size(1), self.hidden_size).cuda())", "\n", "# print(sentence_reps.shape)", "\n", "sent_embeddings", "=", "self", ".", "dropout", "(", "sentence_reps", ")", "\n", "# sentence_embedding, (_, _) = self.lstm(sent_embeddings, (h_0, c_0))", "\n", "att_s", "=", "self", ".", "sentence_attention", "(", "sent_embeddings", ")", "# [batch_size, num_sentence, hidden_size,]", "\n", "u_i", "=", "self", ".", "dropout", "(", "torch", ".", "tanh", "(", "att_s", ")", ")", "# u_i = tanh(W_s * h_i + b). [batch_size, num_sentence, hidden_size,]", "\n", "u_w", "=", "self", ".", "att_scorer", "(", "u_i", ")", ".", "squeeze", "(", "-", "1", ")", ".", "view", "(", "sentence_reps", ".", "size", "(", "0", ")", ",", "sentence_reps", ".", "size", "(", "1", ")", ")", "# [batch_size, num_sentence]", "\n", "# print('u_w: ', u_w)", "\n", "att_weights", "=", "torch", ".", "softmax", "(", "u_w", ".", "masked_fill", "(", "(", "~", "sentence_mask", ")", ".", "bool", "(", ")", ",", "-", "1e4", ")", ",", "dim", "=", "-", "1", ")", "\n", "# print('att_weights: ', att_weights)", "\n", "u_w", "=", "u_w", ".", "masked_fill", "(", "(", "~", "sentence_masks", ")", ".", "bool", "(", ")", ",", "-", "1e4", ")", "\n", "# # att_scores: sentence attention scores. [batch_size, num_sentence]", "\n", "att_scores", "=", "torch", ".", "softmax", "(", "u_w", ",", "dim", "=", "-", "1", ")", "\n", "# result: abstract representations. [batch_size, hidden_dim]", "\n", "result", "=", "torch", ".", "bmm", "(", "att_scores", ".", "unsqueeze", "(", "1", ")", ",", "sentence_reps", ")", ".", "squeeze", "(", "1", ")", "\n", "return", "result", ",", "att_weights", "\n", "# if sentence_reps.size(0) > 0:", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.embedding.jointmodel.AbstractAttention.__init__": [[217, 225], ["torch.Module.__init__", "jointmodel.TimeDistributed", "torch.Dropout", "torch.Dropout", "torch.Dropout", "jointmodel.ClassificationHead", "jointmodel.TimeDistributed", "torch.LSTM", "torch.LSTM", "torch.LSTM"], "methods", ["home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.label_prediction.transformer_scifact.SciFactLabelPredictionDataset.__init__"], ["def", "__init__", "(", "self", ",", "hidden_size", ",", "num_labels", ",", "dropout", "=", "0.1", ")", ":", "\n", "        ", "super", "(", "AbstractAttention", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dense", "=", "TimeDistributed", "(", "hidden_size", ",", "hidden_size", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "dropout", ")", "\n", "self", ".", "classifier", "=", "ClassificationHead", "(", "hidden_size", ",", "num_labels", ",", "dropout", "=", "dropout", ")", "\n", "self", ".", "hidden_size", "=", "hidden_size", "\n", "self", ".", "att_scorer", "=", "TimeDistributed", "(", "hidden_size", ",", "1", ")", "\n", "self", ".", "lstm", "=", "nn", ".", "LSTM", "(", "hidden_size", ",", "self", ".", "hidden_size", "//", "2", ",", "1", ",", "dropout", "=", "dropout", ",", "bidirectional", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.embedding.jointmodel.AbstractAttention.forward": [[226, 266], ["jointmodel.AbstractAttention.dropout", "jointmodel.AbstractAttention.dense", "jointmodel.AbstractAttention.dropout", "jointmodel.AbstractAttention.att_scorer().squeeze().view", "jointmodel.AbstractAttention.masked_fill", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where.view", "torch.where.view", "torch.where.view", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze.view", "torch.bmm().squeeze.view", "torch.bmm().squeeze.view", "torch.logical_and", "torch.logical_and", "torch.logical_and", "torch.logical_and", "torch.logical_and", "torch.logical_and", "torch.logical_and", "torch.logical_and", "torch.logical_and", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "jointmodel.AbstractAttention.dropout", "jointmodel.AbstractAttention.lstm", "jointmodel.AbstractAttention.dense", "jointmodel.AbstractAttention.dropout", "jointmodel.AbstractAttention.att_scorer().squeeze().view", "u_w.masked_fill.masked_fill.masked_fill", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "jointmodel.AbstractAttention.classifier", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "x.view", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "x.size", "x.size", "x.size", "float", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.where.size", "torch.where.size", "torch.where.size", "x.size", "x.size", "x.size", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.bmm().squeeze.view.size", "torch.bmm().squeeze.view.size", "x.size", "jointmodel.AbstractAttention.att_scorer().squeeze", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "jointmodel.AbstractAttention.att_scorer().squeeze", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.where.view.unsqueeze", "x.view", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.softmax.unsqueeze", "torch.softmax.unsqueeze", "torch.softmax.unsqueeze", "range", "jointmodel.AbstractAttention.att_scorer", "x.size", "x.size", "torch.bmm().squeeze.view.size", "torch.bmm().squeeze.view.size", "jointmodel.AbstractAttention.att_scorer"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "token_mask", ",", "claim_reps", ")", ":", "\n", "        ", "att_s", "=", "self", ".", "dropout", "(", "x", ".", "view", "(", "-", "1", ",", "x", ".", "size", "(", "-", "1", ")", ")", ")", "\n", "att_s", "=", "self", ".", "dense", "(", "att_s", ")", "\n", "att_s", "=", "self", ".", "dropout", "(", "torch", ".", "tanh", "(", "att_s", ")", ")", "# [batch_size * num_sentence * num_token, hidden_dim]  # nan", "\n", "raw_att_scores", "=", "self", ".", "att_scorer", "(", "att_s", ")", ".", "squeeze", "(", "-", "1", ")", ".", "view", "(", "x", ".", "size", "(", "0", ")", ",", "x", ".", "size", "(", "1", ")", ",", "\n", "x", ".", "size", "(", "2", ")", ")", "# [batch_size, num_sentence, num_token]", "\n", "u_w", "=", "raw_att_scores", ".", "masked_fill", "(", "(", "1", "-", "token_mask", ")", ".", "bool", "(", ")", ",", "float", "(", "'-inf'", ")", ")", "\n", "att_scores", "=", "torch", ".", "softmax", "(", "u_w", ",", "dim", "=", "-", "1", ")", "\n", "att_scores", "=", "torch", ".", "where", "(", "torch", ".", "isnan", "(", "att_scores", ")", ",", "torch", ".", "zeros_like", "(", "att_scores", ")", ",", "\n", "att_scores", ")", "# replace NaN with 0", "\n", "# batch_att_scores: word attention scores. [batch_size * num_sentence, num_token]", "\n", "word_att_scores", "=", "att_scores", ".", "view", "(", "-", "1", ",", "att_scores", ".", "size", "(", "-", "1", ")", ")", "# word attention weight matrix.", "\n", "# out:  # sentence_representations. [batch_size, num_sentence, hidden_dim]", "\n", "out", "=", "torch", ".", "bmm", "(", "word_att_scores", ".", "unsqueeze", "(", "1", ")", ",", "x", ".", "view", "(", "-", "1", ",", "x", ".", "size", "(", "2", ")", ",", "x", ".", "size", "(", "3", ")", ")", ")", ".", "squeeze", "(", "1", ")", "\n", "sentence_reps", "=", "out", ".", "view", "(", "x", ".", "size", "(", "0", ")", ",", "x", ".", "size", "(", "1", ")", ",", "x", ".", "size", "(", "-", "1", ")", ")", "# [batch_size, num_sentence, hidden_dim]", "\n", "# sentence_reps = torch.mul(claim_reps.unsqueeze(1), sentence_reps)", "\n", "sentence_mask", "=", "token_mask", "[", ":", ",", ":", ",", "0", "]", "\n", "\n", "sentence_mask", "=", "torch", ".", "logical_and", "(", "sentence_mask", ",", "sentence_mask", ")", "\n", "h_0", "=", "Variable", "(", "torch", ".", "zeros", "(", "2", ",", "sentence_reps", ".", "size", "(", "1", ")", ",", "self", ".", "hidden_size", "//", "2", ")", ".", "cuda", "(", ")", ")", "\n", "c_0", "=", "Variable", "(", "torch", ".", "zeros", "(", "2", ",", "sentence_reps", ".", "size", "(", "1", ")", ",", "self", ".", "hidden_size", "//", "2", ")", ".", "cuda", "(", ")", ")", "\n", "# print(sentence_reps.shape)", "\n", "sent_embeddings", "=", "self", ".", "dropout", "(", "sentence_reps", ")", "\n", "sentence_embedding", ",", "(", "_", ",", "_", ")", "=", "self", ".", "lstm", "(", "sent_embeddings", ",", "(", "h_0", ",", "c_0", ")", ")", "\n", "att_s", "=", "self", ".", "dense", "(", "sentence_embedding", ")", "# [batch_size, num_sentence, hidden_size,]", "\n", "u_i", "=", "self", ".", "dropout", "(", "torch", ".", "tanh", "(", "att_s", ")", ")", "# u_i = tanh(W_s * h_i + b). [batch_size, num_sentence, hidden_size,]", "\n", "u_w", "=", "self", ".", "att_scorer", "(", "u_i", ")", ".", "squeeze", "(", "-", "1", ")", ".", "view", "(", "sentence_reps", ".", "size", "(", "0", ")", ",", "\n", "sentence_reps", ".", "size", "(", "1", ")", ")", "# [batch_size, num_sentence]", "\n", "u_w", "=", "u_w", ".", "masked_fill", "(", "(", "~", "sentence_mask", ")", ".", "bool", "(", ")", ",", "-", "1e4", ")", "\n", "# sentence_att_scores: sentence attention scores. [batch_size, num_sentence]", "\n", "# print('u_w: ', u_w)", "\n", "sentence_att_scores", "=", "torch", ".", "softmax", "(", "u_w", ",", "dim", "=", "-", "1", ")", "\n", "# result: abstract representations. [batch_size, hidden_dim]", "\n", "paragraph_reps", "=", "torch", ".", "bmm", "(", "sentence_att_scores", ".", "unsqueeze", "(", "1", ")", ",", "sentence_reps", ")", ".", "squeeze", "(", "1", ")", "\n", "claim_paragraph", "=", "torch", ".", "mul", "(", "claim_reps", ",", "paragraph_reps", ")", "\n", "output", "=", "self", ".", "classifier", "(", "claim_paragraph", ")", "\n", "sentence_att_scores", "=", "sentence_att_scores", "[", ":", ",", "range", "(", "1", ",", "sentence_att_scores", ".", "shape", "[", "1", "]", ")", "]", "\n", "sentence_att_scores", "=", "torch", ".", "softmax", "(", "sentence_att_scores", ",", "dim", "=", "-", "1", ")", "\n", "# print('abstract_sentence_reps: ', sentence_reps)", "\n", "return", "output", ",", "sentence_att_scores", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.embedding.jointmodel.ClassificationHead.__init__": [[271, 276], ["torch.Module.__init__", "jointmodel.TimeDistributed", "torch.Dropout", "torch.Dropout", "torch.Dropout", "jointmodel.TimeDistributed"], "methods", ["home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.label_prediction.transformer_scifact.SciFactLabelPredictionDataset.__init__"], ["def", "__init__", "(", "self", ",", "hidden_size", ",", "num_labels", ",", "dropout", "=", "0.1", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dense", "=", "TimeDistributed", "(", "hidden_size", ",", "hidden_size", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "dropout", ")", "\n", "self", ".", "output", "=", "TimeDistributed", "(", "hidden_size", ",", "num_labels", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.embedding.jointmodel.ClassificationHead.forward": [[277, 284], ["jointmodel.ClassificationHead.dropout", "jointmodel.ClassificationHead.dense", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "jointmodel.ClassificationHead.dropout", "jointmodel.ClassificationHead.output"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "dropout", "(", "x", ")", "\n", "x", "=", "self", ".", "dense", "(", "x", ")", "\n", "x", "=", "torch", ".", "tanh", "(", "x", ")", "\n", "x", "=", "self", ".", "dropout", "(", "x", ")", "\n", "x", "=", "self", ".", "output", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.embedding.jointmodel.SelfAttentionNetwork.__init__": [[288, 293], ["torch.Module.__init__", "jointmodel.TimeDistributed", "jointmodel.TimeDistributed", "torch.Dropout", "torch.Dropout", "torch.Dropout"], "methods", ["home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.label_prediction.transformer_scifact.SciFactLabelPredictionDataset.__init__"], ["    ", "def", "__init__", "(", "self", ",", "hidden_dim", ",", "dropout", "=", "0.1", ")", ":", "\n", "        ", "super", "(", "SelfAttentionNetwork", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dense", "=", "TimeDistributed", "(", "hidden_dim", ",", "hidden_dim", ")", "\n", "self", ".", "att_scorer", "=", "TimeDistributed", "(", "hidden_dim", ",", "1", ")", "\n", "self", ".", "dropout_layer", "=", "nn", ".", "Dropout", "(", "dropout", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.embedding.jointmodel.SelfAttentionNetwork.forward": [[294, 305], ["jointmodel.SelfAttentionNetwork.dropout_layer", "jointmodel.SelfAttentionNetwork.dense", "jointmodel.SelfAttentionNetwork.dropout_layer", "jointmodel.SelfAttentionNetwork.att_scorer().squeeze().view", "u_w.masked_fill.masked_fill.masked_fill", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "x.size", "x.size", "float", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "jointmodel.SelfAttentionNetwork.att_scorer().squeeze", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.where.unsqueeze", "torch.where.unsqueeze", "torch.where.unsqueeze", "jointmodel.SelfAttentionNetwork.att_scorer"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "token_mask", ")", ":", "\n", "        ", "att_s", "=", "self", ".", "dropout_layer", "(", "x", ")", "\n", "att_s", "=", "self", ".", "dense", "(", "att_s", ")", "\n", "u_i", "=", "self", ".", "dropout_layer", "(", "torch", ".", "tanh", "(", "att_s", ")", ")", "\n", "u_w", "=", "self", ".", "att_scorer", "(", "u_i", ")", ".", "squeeze", "(", "-", "1", ")", ".", "view", "(", "x", ".", "size", "(", "0", ")", ",", "x", ".", "size", "(", "1", ")", ")", "\n", "u_w", "=", "u_w", ".", "masked_fill", "(", "(", "1", "-", "token_mask", ")", ".", "bool", "(", ")", ",", "float", "(", "'-inf'", ")", ")", "\n", "att_scores", "=", "torch", ".", "softmax", "(", "u_w", ",", "dim", "=", "-", "1", ")", "\n", "att_scores", "=", "torch", ".", "where", "(", "torch", ".", "isnan", "(", "att_scores", ")", ",", "torch", ".", "zeros_like", "(", "att_scores", ")", ",", "\n", "att_scores", ")", "\n", "out", "=", "torch", ".", "bmm", "(", "att_scores", ".", "unsqueeze", "(", "1", ")", ",", "x", ")", ".", "squeeze", "(", "1", ")", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.embedding.jointmodel.JointModelClassifier.__init__": [[332, 362], ["torch.Module.__init__", "transformers.AutoModel.from_pretrained", "torch.CrossEntropyLoss", "torch.CrossEntropyLoss", "torch.CrossEntropyLoss", "torch.CrossEntropyLoss", "torch.CrossEntropyLoss", "torch.CrossEntropyLoss", "torch.CrossEntropyLoss", "torch.CrossEntropyLoss", "torch.CrossEntropyLoss", "torch.BCELoss", "torch.BCELoss", "torch.BCELoss", "jointmodel.WordAttention", "jointmodel.SentenceAttention", "jointmodel.ClassificationHead", "jointmodel.ClassificationHead", "jointmodel.AbstractAttention", "jointmodel.SelfAttentionNetwork"], "methods", ["home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.label_prediction.transformer_scifact.SciFactLabelPredictionDataset.__init__"], ["    ", "def", "__init__", "(", "self", ",", "args", ")", ":", "\n", "        ", "super", "(", "JointModelClassifier", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "num_abstract_label", "=", "3", "\n", "self", ".", "num_rationale_label", "=", "2", "\n", "self", ".", "sim_label", "=", "2", "\n", "self", ".", "bert", "=", "AutoModel", ".", "from_pretrained", "(", "args", ".", "model", ")", "\n", "self", ".", "abstract_criterion", "=", "nn", ".", "CrossEntropyLoss", "(", ")", "\n", "self", ".", "rationale_criterion", "=", "nn", ".", "CrossEntropyLoss", "(", "ignore_index", "=", "2", ")", "\n", "self", ".", "retrieval_criterion", "=", "nn", ".", "CrossEntropyLoss", "(", ")", "\n", "# self.abstract_criterion = MultiFocalLoss(3, alpha=[0.1, 0.6, 0.3])", "\n", "# self.rationale_criterion = FocalLoss(weight=torch.tensor([0.25, 0.75]), reduction='mean')", "\n", "# self.retrieval_criterion = FocalLoss(weight=torch.tensor([0.25, 0.75]), reduction='mean')", "\n", "self", ".", "retrieval_rationale_criterion", "=", "nn", ".", "BCELoss", "(", ")", "\n", "self", ".", "dropout", "=", "args", ".", "dropout", "\n", "self", ".", "hidden_dim", "=", "args", ".", "hidden_dim", "\n", "self", ".", "word_attention", "=", "WordAttention", "(", "self", ".", "hidden_dim", ",", "self", ".", "hidden_dim", ",", "dropout", "=", "self", ".", "dropout", ")", "\n", "self", ".", "sentence_attention", "=", "SentenceAttention", "(", "self", ".", "hidden_dim", ",", "self", ".", "hidden_dim", ",", "dropout", "=", "self", ".", "dropout", ")", "\n", "self", ".", "rationale_linear", "=", "ClassificationHead", "(", "self", ".", "hidden_dim", ",", "self", ".", "num_rationale_label", ",", "dropout", "=", "self", ".", "dropout", ")", "\n", "self", ".", "abstract_linear", "=", "ClassificationHead", "(", "self", ".", "hidden_dim", ",", "self", ".", "num_abstract_label", ",", "dropout", "=", "self", ".", "dropout", ")", "\n", "self", ".", "abstract_retrieval", "=", "AbstractAttention", "(", "self", ".", "hidden_dim", ",", "self", ".", "sim_label", ",", "dropout", "=", "self", ".", "dropout", ")", "\n", "self", ".", "self_attention", "=", "SelfAttentionNetwork", "(", "self", ".", "hidden_dim", ",", "dropout", "=", "self", ".", "dropout", ")", "\n", "\n", "self", ".", "extra_modules", "=", "[", "\n", "self", ".", "word_attention", ",", "\n", "self", ".", "sentence_attention", ",", "\n", "self", ".", "abstract_linear", ",", "\n", "self", ".", "rationale_linear", ",", "\n", "self", ".", "abstract_criterion", ",", "\n", "self", ".", "rationale_criterion", ",", "\n", "self", ".", "retrieval_criterion", ",", "\n", "]", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.embedding.jointmodel.JointModelClassifier.reinitialize": [[364, 379], ["jointmodel.WordAttention", "jointmodel.SentenceAttention", "jointmodel.ClassificationHead", "jointmodel.ClassificationHead", "jointmodel.AbstractAttention", "jointmodel.SelfAttentionNetwork"], "methods", ["None"], ["", "def", "reinitialize", "(", "self", ")", ":", "\n", "        ", "self", ".", "word_attention", "=", "WordAttention", "(", "self", ".", "hidden_dim", ",", "self", ".", "hidden_dim", ",", "dropout", "=", "self", ".", "dropout", ")", "\n", "self", ".", "sentence_attention", "=", "SentenceAttention", "(", "self", ".", "hidden_dim", ",", "self", ".", "hidden_dim", ",", "dropout", "=", "self", ".", "dropout", ")", "\n", "self", ".", "rationale_linear", "=", "ClassificationHead", "(", "self", ".", "hidden_dim", ",", "self", ".", "num_rationale_label", ",", "dropout", "=", "self", ".", "dropout", ")", "\n", "self", ".", "abstract_linear", "=", "ClassificationHead", "(", "self", ".", "hidden_dim", ",", "self", ".", "num_abstract_label", ",", "dropout", "=", "self", ".", "dropout", ")", "\n", "self", ".", "abstract_retrieval", "=", "AbstractAttention", "(", "self", ".", "hidden_dim", ",", "self", ".", "sim_label", ",", "dropout", "=", "self", ".", "dropout", ")", "\n", "self", ".", "self_attention", "=", "SelfAttentionNetwork", "(", "self", ".", "hidden_dim", ",", "dropout", "=", "self", ".", "dropout", ")", "\n", "self", ".", "extra_modules", "=", "[", "\n", "self", ".", "word_attention", ",", "\n", "self", ".", "sentence_attention", ",", "\n", "self", ".", "abstract_linear", ",", "\n", "self", ".", "rationale_linear", ",", "\n", "self", ".", "abstract_criterion", ",", "\n", "self", ".", "rationale_criterion", ",", "\n", "self", ".", "retrieval_criterion", ",", "\n", "]", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.embedding.jointmodel.JointModelClassifier.forward": [[381, 489], ["range", "jointmodel.JointModelClassifier.self_attention", "range", "jointmodel.JointModelClassifier.abstract_retrieval", "torch.argmax().detach().numpy().tolist", "torch.argmax().detach().numpy().tolist", "torch.argmax().detach().numpy().tolist", "torch.argmax().detach().numpy().tolist", "torch.argmax().detach().numpy().tolist", "torch.argmax().detach().numpy().tolist", "torch.argmax().detach().numpy().tolist", "torch.argmax().detach().numpy().tolist", "torch.argmax().detach().numpy().tolist", "jointmodel.JointModelClassifier.word_attention", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "jointmodel.JointModelClassifier.rationale_linear", "bool", "jointmodel.JointModelClassifier.sentence_attention", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "jointmodel.JointModelClassifier.abstract_linear", "torch.argmax().detach().numpy().tolist", "torch.argmax().detach().numpy().tolist", "torch.argmax().detach().numpy().tolist", "torch.argmax().detach().numpy().tolist", "torch.argmax().detach().numpy().tolist", "torch.argmax().detach().numpy().tolist", "torch.argmax().detach().numpy().tolist", "torch.argmax().detach().numpy().tolist", "torch.argmax().detach().numpy().tolist", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "jointmodel.JointModelClassifier.bert", "jointmodel.JointModelClassifier.unsqueeze", "jointmodel.JointModelClassifier.cpu", "rationale_pred_paragraph[].detach().numpy().tolist", "jointmodel.JointModelClassifier.abstract_criterion", "torch.where().float().cuda", "torch.where().float().cuda", "torch.where().float().cuda", "torch.where().float().cuda", "torch.where().float().cuda", "torch.where().float().cuda", "torch.where().float().cuda", "torch.where().float().cuda", "torch.where().float().cuda", "jointmodel.JointModelClassifier.rationale_criterion", "jointmodel.JointModelClassifier.retrieval_rationale_criterion", "jointmodel.JointModelClassifier.retrieval_rationale_criterion", "jointmodel.JointModelClassifier.retrieval_criterion", "torch.argmax().detach().numpy", "torch.argmax().detach().numpy", "torch.argmax().detach().numpy", "torch.argmax().detach().numpy", "torch.argmax().detach().numpy", "torch.argmax().detach().numpy", "torch.argmax().detach().numpy", "torch.argmax().detach().numpy", "torch.argmax().detach().numpy", "jointmodel.JointModelClassifier.retrieval_criterion", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.argmax().detach().numpy", "torch.argmax().detach().numpy", "torch.argmax().detach().numpy", "torch.argmax().detach().numpy", "torch.argmax().detach().numpy", "torch.argmax().detach().numpy", "torch.argmax().detach().numpy", "torch.argmax().detach().numpy", "torch.argmax().detach().numpy", "zip", "jointmodel.JointModelClassifier.view", "rationale_label.view", "sentence_att_scores.view", "torch.where().float().cuda.view().detach", "torch.where().float().cuda.view().detach", "torch.where().float().cuda.view().detach", "torch.where().float().cuda.view", "torch.where().float().cuda.view", "torch.where().float().cuda.view", "sentence_att_scores.view().detach", "rationale_pred_paragraph[].detach().numpy", "sentence_mask.bool", "torch.where().float", "torch.where().float", "torch.where().float", "torch.where().float", "torch.where().float", "torch.where().float", "torch.where().float", "torch.where().float", "torch.where().float", "torch.argmax().detach", "torch.argmax().detach", "torch.argmax().detach", "torch.argmax().detach", "torch.argmax().detach", "torch.argmax().detach", "torch.argmax().detach", "torch.argmax().detach", "torch.argmax().detach", "torch.argmax().detach", "torch.argmax().detach", "torch.argmax().detach", "torch.argmax().detach", "torch.argmax().detach", "torch.argmax().detach", "torch.argmax().detach", "torch.argmax().detach", "torch.argmax().detach", "torch.where().float().cuda.view", "torch.where().float().cuda.view", "torch.where().float().cuda.view", "sentence_att_scores.view", "rationale_pred_paragraph[].detach", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "abstract_retrieval.cpu", "jointmodel.JointModelClassifier.cpu"], "methods", ["home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.dataset.utils.abstract_retrieval"], ["", "def", "forward", "(", "self", ",", "encoded_dict", ",", "transformation_indices", ",", "abstract_label", "=", "None", ",", "rationale_label", "=", "None", ",", "\n", "retrieval_label", "=", "None", ",", "train", "=", "False", ",", "retrieval_only", "=", "False", ",", "rationale_sample", "=", "1", ")", ":", "\n", "        ", "batch_indices", ",", "indices_by_batch", ",", "mask", "=", "transformation_indices", "\n", "# match_batch_indices, match_indices_by_batch, match_mask = match_indices", "\n", "# (batch_size, num_sep, num_token)", "\n", "# print(encoded_dict['input_ids'].shape, batch_indices.shape, indices_by_batch.shape, mask.shape)", "\n", "bert_out", "=", "self", ".", "bert", "(", "**", "encoded_dict", ")", "[", "0", "]", "# [batch_size, sequence_len, hidden_dim]", "\n", "\n", "title_abstract_token", "=", "range", "(", "1", ",", "batch_indices", ".", "shape", "[", "1", "]", ")", "\n", "title_abstract_tokens", "=", "bert_out", "[", "batch_indices", "[", ":", ",", "title_abstract_token", ",", ":", "]", ",", "\n", "indices_by_batch", "[", ":", ",", "title_abstract_token", ",", ":", "]", ",", ":", "]", "\n", "title_abstract_mask", "=", "mask", "[", ":", ",", "title_abstract_token", ",", ":", "]", "\n", "\n", "claim_token", "=", "bert_out", "[", "batch_indices", "[", ":", ",", "0", ",", ":", "]", ",", "indices_by_batch", "[", ":", ",", "0", ",", ":", "]", ",", ":", "]", "\n", "claim_mask", "=", "mask", "[", ":", ",", "0", ",", ":", "]", "\n", "claim_representation", "=", "self", ".", "self_attention", "(", "claim_token", ",", "claim_mask", ")", "\n", "\n", "sentence_token", "=", "range", "(", "2", ",", "batch_indices", ".", "shape", "[", "1", "]", ")", "\n", "batch_indices", ",", "indices_by_batch", ",", "mask", "=", "batch_indices", "[", ":", ",", "sentence_token", ",", ":", "]", ",", "indices_by_batch", "[", ":", ",", "sentence_token", ",", ":", "]", ",", "mask", "[", ":", ",", "sentence_token", ",", ":", "]", "\n", "\n", "# corpus_tokens = bert_out[match_batch_indices, match_indices_by_batch, :]", "\n", "# claim_token = bert_out[match_batch_indices[:, 0, :], match_indices_by_batch[:, 0, :], :]", "\n", "# corpus_tokens = corpus_tokens.squeeze(1)  # [batch_size, sequence_len, hidden_dim]", "\n", "# claim_token = claim_token.squeeze(1)", "\n", "# # cnn_out = self.conv_layer(corpus_tokens)", "\n", "# # classifier_out = output[1]  # [batch_size, hidden_dim]", "\n", "bert_tokens", "=", "bert_out", "[", "batch_indices", ",", "indices_by_batch", ",", ":", "]", "# get Bert tokens(sentences level)", "\n", "# bert_tokens: [batch_size, num_sentence, num_token, hidden_dim]", "\n", "# abstract_retrieval = self.abstract_retrieval(corpus_tokens, cnn_out)", "\n", "abstract_retrieval", ",", "sentence_att_scores", "=", "self", ".", "abstract_retrieval", "(", "title_abstract_tokens", ",", "\n", "title_abstract_mask", ",", "claim_representation", ")", "\n", "# print('abstract: ', abstract_label, 'retrieval: ', retrieval_label)", "\n", "# print('rationale_label: ', rationale_label)", "\n", "# print('abstract_sentence_att_scores: ', sentence_att_scores)", "\n", "# if abstract_retrieval[:, 1] > abstract_retrieval[:, 0]:", "\n", "#     print('True')", "\n", "# else:", "\n", "#     print('False')", "\n", "\n", "retrieval_out", "=", "torch", ".", "argmax", "(", "abstract_retrieval", ".", "cpu", "(", ")", ",", "dim", "=", "-", "1", ")", ".", "detach", "(", ")", ".", "numpy", "(", ")", ".", "tolist", "(", ")", "\n", "if", "retrieval_only", ":", "\n", "            ", "retrieval_loss", "=", "self", ".", "retrieval_criterion", "(", "abstract_retrieval", ",", "\n", "retrieval_label", ")", "if", "retrieval_label", "is", "not", "None", "else", "None", "\n", "return", "retrieval_out", ",", "retrieval_loss", "\n", "\n", "", "sentence_representations", ",", "sentence_mask", ",", "word_att_score", "=", "self", ".", "word_attention", "(", "bert_tokens", ",", "mask", ")", "\n", "# print('word_att_score: ', word_att_score)", "\n", "\n", "claim_sentence", "=", "torch", ".", "mul", "(", "claim_representation", ".", "unsqueeze", "(", "1", ")", ",", "sentence_representations", ")", "\n", "rationale_score", "=", "self", ".", "rationale_linear", "(", "claim_sentence", ")", "\n", "# att_scores = rationale_score[:, :, 1]", "\n", "# print('rationale_score: ', rationale_score[:, :, 1])", "\n", "\n", "if", "bool", "(", "torch", ".", "rand", "(", "1", ")", "<", "rationale_sample", ")", ":", "# Choose sentence according to predicted rationale", "\n", "            ", "valid_scores", "=", "rationale_score", "[", ":", ",", ":", ",", "1", "]", ">", "rationale_score", "[", ":", ",", ":", ",", "0", "]", "\n", "", "else", ":", "\n", "            ", "valid_scores", "=", "rationale_label", "==", "1", "# Ground truth", "\n", "\n", "", "paragraph_representations", ",", "sen_att_score", "=", "self", ".", "sentence_attention", "(", "sentence_representations", ",", "\n", "sentence_mask", ",", "valid_scores", ")", "\n", "# print('sen_att_score: ', sen_att_score)", "\n", "# print(100 * '-*=')", "\n", "\n", "claim_paragraph", "=", "torch", ".", "mul", "(", "claim_representation", ",", "paragraph_representations", ")", "\n", "abstract_score", "=", "self", ".", "abstract_linear", "(", "claim_paragraph", ")", "\n", "\n", "abstract_out", "=", "torch", ".", "argmax", "(", "abstract_score", ".", "cpu", "(", ")", ",", "dim", "=", "-", "1", ")", ".", "detach", "(", ")", ".", "numpy", "(", ")", ".", "tolist", "(", ")", "\n", "rationale_pred", "=", "torch", ".", "argmax", "(", "rationale_score", ".", "cpu", "(", ")", ",", "dim", "=", "-", "1", ")", "\n", "rationale_out", "=", "[", "rationale_pred_paragraph", "[", "mask", "]", ".", "detach", "(", ")", ".", "numpy", "(", ")", ".", "tolist", "(", ")", "for", "rationale_pred_paragraph", ",", "mask", "in", "\n", "zip", "(", "rationale_pred", ",", "sentence_mask", ".", "bool", "(", ")", ")", "]", "\n", "\n", "# if bool(torch.rand(1) < rationale_sample):  # Choose sentence according to predicted rationale", "\n", "#     rationale_pred_label = torch.where(rationale_pred == 2, torch.zeros_like(rationale_pred),", "\n", "#                                        rationale_pred).float().cuda()", "\n", "# else:", "\n", "#     rationale_pred_label = rationale_label.float()  # Ground samples", "\n", "\n", "if", "abstract_label", "is", "not", "None", ":", "\n", "            ", "abstract_loss", "=", "self", ".", "abstract_criterion", "(", "abstract_score", ",", "abstract_label", ")", "\n", "", "else", ":", "\n", "            ", "abstract_loss", "=", "None", "\n", "\n", "", "if", "rationale_label", "is", "not", "None", ":", "\n", "            ", "rationale_pred_label", "=", "torch", ".", "where", "(", "rationale_pred", "==", "2", ",", "torch", ".", "zeros_like", "(", "rationale_pred", ")", ",", "\n", "rationale_pred", ")", ".", "float", "(", ")", ".", "cuda", "(", ")", "\n", "# output, target = ignore_padding(rationale_score, rationale_label)", "\n", "# rationale_loss = self.rationale_criterion(output, target.unsqueeze(1))", "\n", "rationale_loss", "=", "self", ".", "rationale_criterion", "(", "rationale_score", ".", "view", "(", "-", "1", ",", "self", ".", "num_rationale_label", ")", ",", "\n", "rationale_label", ".", "view", "(", "-", "1", ")", ")", "\n", "sentence_loss1", "=", "self", ".", "retrieval_rationale_criterion", "(", "sentence_att_scores", ".", "view", "(", "-", "1", ")", ",", "\n", "rationale_pred_label", ".", "view", "(", "-", "1", ")", ".", "detach", "(", ")", ")", "\n", "sentence_loss2", "=", "self", ".", "retrieval_rationale_criterion", "(", "rationale_pred_label", ".", "view", "(", "-", "1", ")", ",", "\n", "sentence_att_scores", ".", "view", "(", "-", "1", ")", ".", "detach", "(", ")", ")", "\n", "bce_loss", "=", "sentence_loss1", "+", "sentence_loss2", "\n", "# rationale_loss = rationale_loss + (alpha * sentence_loss) / 10", "\n", "", "else", ":", "\n", "            ", "rationale_loss", "=", "None", "\n", "bce_loss", "=", "None", "\n", "\n", "", "if", "retrieval_label", "is", "not", "None", ":", "\n", "            ", "retrieval_loss", "=", "self", ".", "retrieval_criterion", "(", "abstract_retrieval", ",", "retrieval_label", ")", "\n", "# retrieval_loss = self.retrieval_criterion(abstract_retrieval, retrieval_label.unsqueeze(1))", "\n", "", "else", ":", "\n", "            ", "retrieval_loss", "=", "None", "\n", "", "if", "train", ":", "\n", "            ", "return", "abstract_out", ",", "rationale_out", ",", "abstract_loss", ",", "rationale_loss", ",", "retrieval_loss", ",", "bce_loss", "\n", "", "return", "abstract_out", ",", "rationale_out", ",", "retrieval_out", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.embedding.jointmodel.get_index": [[12, 39], ["mask.view.view", "range", "range", "mask.view.size", "len", "torch.where", "torch.where", "torch.where", "index.append", "[].tolist", "len", "len", "token_index.append", "mask.view.size", "range", "len", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "mask.view.size", "mask.view.size", "len", "len", "[].tolist", "numpy.zeros().tolist", "mask.view.size", "numpy.ones", "torch.where.tolist", "numpy.zeros"], "function", ["None"], ["def", "get_index", "(", "mask", ")", ":", "\n", "    ", "mask", "=", "mask", ".", "view", "(", "mask", ".", "size", "(", "0", ")", ",", "mask", ".", "size", "(", "1", ")", "*", "mask", ".", "size", "(", "2", ")", ")", "\n", "index", "=", "[", "]", "\n", "max_len", "=", "0", "\n", "max_len_idx", "=", "0", "\n", "for", "i", "in", "range", "(", "len", "(", "mask", ")", ")", ":", "\n", "        ", "tmp", "=", "torch", ".", "where", "(", "mask", "[", "i", "]", "!=", "0", ")", "\n", "index", ".", "append", "(", "tmp", ")", "\n", "if", "max_len", "<", "len", "(", "tmp", "[", "0", "]", ")", ":", "\n", "            ", "max_len", "=", "len", "(", "tmp", "[", "0", "]", ")", "\n", "max_len_idx", "=", "i", "\n", "", "", "token_index", "=", "[", "]", "\n", "max_sentence", "=", "index", "[", "max_len_idx", "]", "[", "0", "]", ".", "tolist", "(", ")", "[", ":", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "index", ")", ")", ":", "\n", "        ", "i_len", "=", "len", "(", "index", "[", "i", "]", "[", "0", "]", ")", "\n", "tmp", "=", "index", "[", "i", "]", "[", "0", "]", ".", "tolist", "(", ")", "+", "max_sentence", "[", "i_len", ":", "max_len", "]", "\n", "token_index", ".", "append", "(", "tmp", ")", "\n", "", "if", "mask", ".", "size", "(", "0", ")", "==", "1", ":", "\n", "        ", "batch_indices", "=", "[", "np", ".", "zeros", "(", "max_len", ",", "dtype", "=", "int", ")", ".", "tolist", "(", ")", "]", "\n", "", "else", ":", "\n", "        ", "batch_indices", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "mask", ".", "size", "(", "0", ")", ")", ":", "\n", "            ", "tmp", "=", "np", ".", "ones", "(", "max_len", ",", "dtype", "=", "int", ")", "*", "i", "\n", "batch_indices", "+=", "[", "tmp", ".", "tolist", "(", ")", "]", "\n", "", "", "if", "len", "(", "token_index", ")", ">", "512", ":", "\n", "        ", "token_index", "=", "token_index", "[", "0", ":", "512", "]", "\n", "", "return", "torch", ".", "tensor", "(", "token_index", ")", ",", "torch", ".", "tensor", "(", "batch_indices", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.embedding.jointmodel.ignore_padding": [[307, 323], ["torch.device", "torch.device", "torch.device", "target.view.view", "output.view.view", "len", "range", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "enumerate", "torch.tensor.to", "torch.tensor.to", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "idxs.append", "range", "range", "len", "len"], "function", ["None"], ["", "", "def", "ignore_padding", "(", "output", ",", "target", ",", "padding_idx", "=", "2", ")", ":", "\n", "    ", "\"\"\" Remove padded sentences and label(2). \"\"\"", "\n", "device", "=", "torch", ".", "device", "(", "'cuda'", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "else", "'cpu'", ")", "\n", "target", "=", "target", ".", "view", "(", "-", "1", ")", "\n", "output", "=", "output", ".", "view", "(", "-", "1", ",", "2", ")", "\n", "idxs", "=", "[", "]", "\n", "n", "=", "len", "(", "target", ")", "\n", "for", "i", "in", "range", "(", "n", ")", ":", "\n", "        ", "if", "target", "[", "i", "]", "!=", "padding_idx", ":", "\n", "            ", "idxs", ".", "append", "(", "i", ")", "\n", "", "", "new_output", "=", "torch", ".", "tensor", "(", "[", "[", "0.0", ",", "0.0", "]", "for", "_", "in", "range", "(", "len", "(", "idxs", ")", ")", "]", ")", "\n", "new_target", "=", "torch", ".", "tensor", "(", "[", "0", "for", "_", "in", "range", "(", "len", "(", "idxs", ")", ")", "]", ")", "\n", "for", "i", ",", "idx", "in", "enumerate", "(", "idxs", ")", ":", "\n", "        ", "new_output", "[", "i", "]", "=", "output", "[", "idx", "]", "\n", "new_target", "[", "i", "]", "=", "target", "[", "idx", "]", "\n", "", "return", "new_output", ".", "to", "(", "device", ")", ",", "new_target", ".", "to", "(", "device", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.embedding.jointmodel.get_att_label": [[325, 329], ["torch.device", "torch.device", "torch.device", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.tensor", "torch.tensor", "torch.tensor"], "function", ["None"], ["", "def", "get_att_label", "(", "att_score", ")", ":", "\n", "    ", "device", "=", "torch", ".", "device", "(", "'cuda'", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "else", "'cpu'", ")", "\n", "return", "torch", ".", "tensor", "(", "[", "[", "0", "if", "i", "<", "0.25", "else", "1", "for", "i", "in", "score", "]", "for", "score", "\n", "in", "att_score", "]", ")", ".", "to", "(", "device", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.embedding.AutomaticWeightedLoss.AutomaticWeightedLoss.__init__": [[16, 20], ["torch.Module.__init__", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter"], "methods", ["home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.label_prediction.transformer_scifact.SciFactLabelPredictionDataset.__init__"], ["def", "__init__", "(", "self", ",", "num", "=", "2", ")", ":", "\n", "        ", "super", "(", "AutomaticWeightedLoss", ",", "self", ")", ".", "__init__", "(", ")", "\n", "params", "=", "torch", ".", "ones", "(", "num", ",", "requires_grad", "=", "True", ")", "\n", "self", ".", "params", "=", "torch", ".", "nn", ".", "Parameter", "(", "params", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.embedding.AutomaticWeightedLoss.AutomaticWeightedLoss.forward": [[21, 26], ["enumerate", "torch.log", "torch.log", "torch.log", "torch.log"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "*", "x", ")", ":", "\n", "        ", "loss_sum", "=", "0", "\n", "for", "i", ",", "loss", "in", "enumerate", "(", "x", ")", ":", "\n", "            ", "loss_sum", "+=", "0.5", "/", "(", "self", ".", "params", "[", "i", "]", "**", "2", ")", "*", "loss", "+", "torch", ".", "log", "(", "1", "+", "self", ".", "params", "[", "i", "]", "**", "2", ")", "\n", "", "return", "loss_sum", "\n", "", "", ""]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.embedding.Attention.WordAttention.__init__": [[8, 26], ["super().__init__", "transformers.BertModel.from_pretrained", "torch.nn.Linear", "torch.nn.Linear"], "methods", ["home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.label_prediction.transformer_scifact.SciFactLabelPredictionDataset.__init__"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "# device: str,", "\n", "recurrent_size", ":", "int", ",", "\n", "attention_dim", ":", "int", ",", "\n", "bert_model", ":", "str", "=", "'allenai/scibert_scivocab_cased'", ",", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "attention_dim", "=", "attention_dim", "\n", "self", ".", "recurrent_size", "=", "recurrent_size", "\n", "# self._device = device", "\n", "self", ".", "bert_model", "=", "BertModel", ".", "from_pretrained", "(", "bert_model", ")", "\n", "\n", "# Maps BERT output to `attention_dim` sized tensor", "\n", "self", ".", "word_weight", "=", "nn", ".", "Linear", "(", "self", ".", "recurrent_size", ",", "self", ".", "attention_dim", ")", "\n", "\n", "# Word context vector (u_w) to take dot-product with", "\n", "self", ".", "context_weight", "=", "nn", ".", "Linear", "(", "self", ".", "attention_dim", ",", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.embedding.Attention.WordAttention.recurrent_size": [[27, 29], ["None"], "methods", ["None"], ["", "def", "recurrent_size", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "recurrent_size", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.embedding.Attention.WordAttention.forward": [[30, 106], ["doc_lengths.sort", "torch.nn.utils.rnn.pack_padded_sequence", "print", "torch.nn.utils.rnn.pack_padded_sequence", "torch.nn.utils.rnn.pack_padded_sequence", "torch.nn.utils.rnn.pack_padded_sequence", "sent_lengths.sort", "print", "Attention.WordAttention.bert_model", "torch.nn.utils.rnn.pack_padded_sequence", "torch.tanh", "Attention.WordAttention.context_weight().squeeze", "Attention.WordAttention.max", "torch.exp", "torch.nn.utils.rnn.pad_packed_sequence", "torch.nn.utils.rnn.pad_packed_sequence", "sents.sum.sum.sum", "sent_perm_idx.sort", "Attention.WordAttention.word_weight", "torch.nn.utils.rnn.PackedSequence", "torch.sum", "att_weights.unsqueeze", "doc_lengths.tolist", "doc_lengths.tolist", "doc_lengths.tolist", "doc_lengths.tolist", "sent_lengths.tolist", "Attention.WordAttention.context_weight"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "docs", ",", "doc_lengths", ",", "sent_lengths", ",", "attention_masks", ",", "token_type_ids", ",", "bert_embedding", ")", ":", "\n", "        ", "\"\"\"\n        :param docs: encoded document-level data; LongTensor (num_docs, padded_doc_length, padded_sent_length)\n        :param doc_lengths: unpadded document lengths; LongTensor (num_docs)\n        :param sent_lengths: unpadded sentence lengths; LongTensor (num_docs, max_sent_len)\n        :param attention_masks: BERT attention masks; LongTensor (num_docs, padded_doc_length, padded_sent_length)\n        :param token_type_ids: BERT token type IDs; LongTensor (num_docs, padded_doc_length, padded_sent_length)\n        :return: sentences embeddings, docs permutation indices, docs batch sizes, word attention weights\n        \"\"\"", "\n", "\n", "# Sort documents by decreasing order in length", "\n", "doc_lengths", ",", "doc_perm_idx", "=", "doc_lengths", ".", "sort", "(", "dim", "=", "0", ",", "descending", "=", "True", ")", "\n", "docs", "=", "docs", "[", "doc_perm_idx", "]", "\n", "sent_lengths", "=", "sent_lengths", "[", "doc_perm_idx", "]", "\n", "\n", "# Make a long batch of sentences by removing pad-sentences", "\n", "# i.e. `docs` was of size (num_docs, padded_doc_length, padded_sent_length)", "\n", "# -> `packed_sents.data` is now of size (num_sents, padded_sent_length)", "\n", "packed_sents", "=", "pack_padded_sequence", "(", "docs", ",", "lengths", "=", "doc_lengths", ".", "tolist", "(", ")", ",", "batch_first", "=", "True", ")", "\n", "\n", "# effective batch size at each timestep", "\n", "docs_valid_bsz", "=", "packed_sents", ".", "batch_sizes", "\n", "print", "(", "docs_valid_bsz", ")", "\n", "# Make a long batch of sentence lengths by removing pad-sentences", "\n", "# i.e. `sent_lengths` was of size (num_docs, padded_doc_length)", "\n", "# -> `packed_sent_lengths.data` is now of size (num_sents)", "\n", "packed_sent_lengths", "=", "pack_padded_sequence", "(", "sent_lengths", ",", "lengths", "=", "doc_lengths", ".", "tolist", "(", ")", ",", "batch_first", "=", "True", ")", "\n", "\n", "# Make a long batch of attention masks by removing pad-sentences", "\n", "# i.e. `docs` was of size (num_docs, padded_doc_length, padded_sent_length)", "\n", "# -> `packed_attention_masks.data` is now of size (num_sents, padded_sent_length)", "\n", "packed_attention_masks", "=", "pack_padded_sequence", "(", "attention_masks", ",", "lengths", "=", "doc_lengths", ".", "tolist", "(", ")", ",", "batch_first", "=", "True", ")", "\n", "\n", "# Make a long batch of token_type_ids by removing pad-sentences", "\n", "# i.e. `docs` was of size (num_docs, padded_doc_length, padded_sent_length)", "\n", "# -> `token_type_ids.data` is now of size (num_sents, padded_sent_length)", "\n", "packed_token_type_ids", "=", "pack_padded_sequence", "(", "token_type_ids", ",", "lengths", "=", "doc_lengths", ".", "tolist", "(", ")", ",", "batch_first", "=", "True", ")", "\n", "\n", "sents", ",", "sent_lengths", ",", "attn_masks", ",", "token_types", "=", "(", "\n", "packed_sents", ".", "data", ",", "packed_sent_lengths", ".", "data", ",", "packed_attention_masks", ".", "data", ",", "packed_token_type_ids", ".", "data", "\n", ")", "\n", "\n", "# Sort sents by decreasing order in sentence lengths", "\n", "sent_lengths", ",", "sent_perm_idx", "=", "sent_lengths", ".", "sort", "(", "dim", "=", "0", ",", "descending", "=", "True", ")", "\n", "sents", "=", "sents", "[", "sent_perm_idx", "]", "\n", "print", "(", "bert_embedding", ")", "\n", "bert_embedding", "=", "self", ".", "bert_model", "(", "sents", ",", "attention_mask", "=", "attn_masks", ",", "token_type_ids", "=", "token_types", ")", "\n", "\n", "packed_words", "=", "pack_padded_sequence", "(", "bert_embedding", ",", "lengths", "=", "sent_lengths", ".", "tolist", "(", ")", ",", "batch_first", "=", "True", ")", "\n", "\n", "# effective batch size at each timestep", "\n", "sentences_valid_bsz", "=", "packed_words", ".", "batch_sizes", "\n", "\n", "u_i", "=", "torch", ".", "tanh", "(", "self", ".", "word_weight", "(", "packed_words", ".", "data", ")", ")", "\n", "u_w", "=", "self", ".", "context_weight", "(", "u_i", ")", ".", "squeeze", "(", "1", ")", "\n", "val", "=", "u_w", ".", "max", "(", ")", "\n", "att", "=", "torch", ".", "exp", "(", "u_w", "-", "val", ")", "\n", "\n", "# Restore as sentences by repadding", "\n", "att", ",", "_", "=", "pad_packed_sequence", "(", "PackedSequence", "(", "att", ",", "sentences_valid_bsz", ")", ",", "batch_first", "=", "True", ")", "\n", "\n", "att_weights", "=", "att", "/", "torch", ".", "sum", "(", "att", ",", "dim", "=", "1", ",", "keepdim", "=", "True", ")", "\n", "\n", "# Restore as sentences by repadding", "\n", "sents", ",", "_", "=", "pad_packed_sequence", "(", "packed_words", ",", "batch_first", "=", "True", ")", "\n", "\n", "sents", "=", "sents", "*", "att_weights", ".", "unsqueeze", "(", "2", ")", "\n", "sents", "=", "sents", ".", "sum", "(", "dim", "=", "1", ")", "\n", "\n", "# Restore the original order of sentences (undo the first sorting)", "\n", "_", ",", "sent_unperm_idx", "=", "sent_perm_idx", ".", "sort", "(", "dim", "=", "0", ",", "descending", "=", "False", ")", "\n", "sents", "=", "sents", "[", "sent_unperm_idx", "]", "\n", "\n", "att_weights", "=", "att_weights", "[", "sent_unperm_idx", "]", "\n", "\n", "return", "sents", ",", "doc_perm_idx", ",", "docs_valid_bsz", ",", "att_weights", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.embedding.Attention.SentenceAttention.__init__": [[109, 135], ["super().__init__", "torch.nn.LSTM", "torch.nn.Dropout", "torch.nn.Linear", "torch.nn.Linear", "Attention.WordAttention"], "methods", ["home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.label_prediction.transformer_scifact.SciFactLabelPredictionDataset.__init__"], ["    ", "def", "__init__", "(", "self", ",", "dropout", ":", "float", ",", "word_recurrent_size", ":", "int", ",", "recurrent_size", ":", "int", ",", "attention_dim", ":", "int", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "# self._device = device", "\n", "self", ".", "word_recurrent_size", "=", "word_recurrent_size", "\n", "self", ".", "recurrent_size", "=", "recurrent_size", "\n", "self", ".", "dropout", "=", "dropout", "\n", "self", ".", "attention_dim", "=", "attention_dim", "\n", "\n", "assert", "self", ".", "recurrent_size", "%", "2", "==", "0", "\n", "\n", "self", ".", "encoder", "=", "nn", ".", "LSTM", "(", "\n", "input_size", "=", "self", ".", "word_recurrent_size", ",", "\n", "hidden_size", "=", "self", ".", "recurrent_size", "//", "2", ",", "\n", "dropout", "=", "self", ".", "dropout", ",", "\n", "bidirectional", "=", "True", ",", "\n", "batch_first", "=", "True", ",", "\n", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "dropout", ")", "\n", "\n", "# Maps LSTM output to `attention_dim` sized tensor", "\n", "self", ".", "sentence_weight", "=", "nn", ".", "Linear", "(", "self", ".", "recurrent_size", ",", "self", ".", "attention_dim", ")", "\n", "\n", "# Word context vector (u_w) to take dot-product with", "\n", "self", ".", "sentence_context_weight", "=", "nn", ".", "Linear", "(", "self", ".", "attention_dim", ",", "1", ")", "\n", "\n", "self", ".", "word_attention", "=", "WordAttention", "(", "recurrent_size", ",", "attention_dim", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.embedding.Attention.SentenceAttention.recurrent_size": [[136, 138], ["None"], "methods", ["None"], ["", "def", "recurrent_size", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "recurrent_size", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.embedding.Attention.SentenceAttention.forward": [[139, 187], ["Attention.SentenceAttention.word_attention", "Attention.SentenceAttention.dropout", "Attention.SentenceAttention.encoder", "torch.tanh", "Attention.SentenceAttention.sentence_context_weight().squeeze", "Attention.SentenceAttention.max", "torch.exp", "torch.nn.utils.rnn.pad_packed_sequence", "torch.nn.utils.rnn.pad_packed_sequence", "docs.sum.sum.sum", "torch.nn.utils.rnn.pad_packed_sequence", "doc_perm_idx.sort", "torch.nn.utils.rnn.PackedSequence", "Attention.SentenceAttention.sentence_weight", "torch.nn.utils.rnn.PackedSequence", "torch.sum", "sent_att_weights.unsqueeze", "torch.nn.utils.rnn.PackedSequence", "Attention.SentenceAttention.sentence_context_weight"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "docs", ",", "doc_lengths", ",", "sent_lengths", ",", "attention_masks", ",", "token_type_ids", ",", "bert_embedding", ")", ":", "\n", "        ", "\"\"\"\n        :param sent_embeddings: LongTensor (batch_size * padded_doc_length, sentence recurrent dim)\n        :param doc_perm_idx: LongTensor (batch_size)\n        :param doc_valid_bsz: LongTensor (max_doc_len)\n        :param word_att_weights: LongTensor (batch_size * padded_doc_length, max_sent_len)\n        :return: docs embeddings, word attention weights, sentence attention weights\n        \"\"\"", "\n", "sent_embeddings", ",", "doc_perm_idx", ",", "doc_valid_bsz", ",", "word_att_weights", "=", "self", ".", "word_attention", "(", "docs", ",", "\n", "doc_lengths", ",", "\n", "sent_lengths", ",", "\n", "attention_masks", ",", "\n", "token_type_ids", ",", "\n", "bert_embedding", ")", "\n", "\n", "sent_embeddings", "=", "self", ".", "dropout", "(", "sent_embeddings", ")", "\n", "\n", "# Sentence-level LSTM over sentence embeddings", "\n", "packed_sentences", ",", "_", "=", "self", ".", "encoder", "(", "PackedSequence", "(", "sent_embeddings", ",", "doc_valid_bsz", ")", ")", "\n", "\n", "u_i", "=", "torch", ".", "tanh", "(", "self", ".", "sentence_weight", "(", "packed_sentences", ".", "data", ")", ")", "\n", "u_w", "=", "self", ".", "sentence_context_weight", "(", "u_i", ")", ".", "squeeze", "(", "1", ")", "\n", "val", "=", "u_w", ".", "max", "(", ")", "\n", "att", "=", "torch", ".", "exp", "(", "u_w", "-", "val", ")", "\n", "\n", "# Restore as sentences by repadding", "\n", "att", ",", "_", "=", "pad_packed_sequence", "(", "PackedSequence", "(", "att", ",", "doc_valid_bsz", ")", ",", "batch_first", "=", "True", ")", "\n", "\n", "sent_att_weights", "=", "att", "/", "torch", ".", "sum", "(", "att", ",", "dim", "=", "1", ",", "keepdim", "=", "True", ")", "\n", "\n", "# Restore as documents by repadding", "\n", "docs", ",", "_", "=", "pad_packed_sequence", "(", "packed_sentences", ",", "batch_first", "=", "True", ")", "\n", "\n", "# Compute document vectors", "\n", "docs", "=", "docs", "*", "sent_att_weights", ".", "unsqueeze", "(", "2", ")", "\n", "docs", "=", "docs", ".", "sum", "(", "dim", "=", "1", ")", "\n", "\n", "# Restore as documents by repadding", "\n", "word_att_weights", ",", "_", "=", "pad_packed_sequence", "(", "PackedSequence", "(", "word_att_weights", ",", "doc_valid_bsz", ")", ",", "batch_first", "=", "True", ")", "\n", "\n", "# Restore the original order of documents (undo the first sorting)", "\n", "_", ",", "doc_unperm_idx", "=", "doc_perm_idx", ".", "sort", "(", "dim", "=", "0", ",", "descending", "=", "False", ")", "\n", "docs", "=", "docs", "[", "doc_unperm_idx", "]", "\n", "\n", "word_att_weights", "=", "word_att_weights", "[", "doc_unperm_idx", "]", "\n", "sent_att_weights", "=", "sent_att_weights", "[", "doc_unperm_idx", "]", "\n", "\n", "return", "docs", ",", "word_att_weights", ",", "sent_att_weights", "\n", "", "", ""]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.embedding.loss.FocalLoss.__init__": [[18, 39], ["torch.nn.modules.loss._WeightedLoss.__init__"], "methods", ["home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.label_prediction.transformer_scifact.SciFactLabelPredictionDataset.__init__"], ["def", "__init__", "(", "self", ",", "gamma", ":", "float", "=", "2.0", ",", "weight", ":", "Optional", "[", "torch", ".", "Tensor", "]", "=", "None", ",", "reduction", ":", "str", "=", "\"mean\"", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            gamma: value of the exponent gamma in the definition of the Focal loss.\n            weight (tensor): weights to apply to the voxels of each class. If None no weights are applied.\n                This corresponds to the weights `\\alpha` in [1].\n        reduction: {``\"none\"``, ``\"mean\"``, ``\"sum\"``}\n            Specifies the reduction to apply to the output. Defaults to ``\"mean\"``.\n            - ``\"none\"``: no reduction will be applied.\n            - ``\"mean\"``: the sum of the output will be divided by the number of elements in the output.\n            - ``\"sum\"``: the output will be summed.\n        Example:\n            .. code-block::\n                pred = torch.tensor([[1, 0], [0, 1], [1, 0]], dtype=torch.float32)\n                grnd = torch.tensor([[0], [1], [0]], dtype=torch.int64)\n                fl = FocalLoss()\n                fl(pred, grnd)\n        \"\"\"", "\n", "super", "(", "FocalLoss", ",", "self", ")", ".", "__init__", "(", "weight", "=", "weight", ",", "reduction", "=", "reduction", ")", "\n", "self", ".", "gamma", "=", "gamma", "\n", "self", ".", "weight", "=", "weight", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.embedding.loss.FocalLoss.forward": [[40, 107], ["torch.log_softmax", "torch.log_softmax", "torch.log_softmax", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "ValueError", "ValueError", "ValueError", "input.dim", "i.unsqueeze.unsqueeze.view", "t.unsqueeze.unsqueeze.view", "i.unsqueeze.unsqueeze.unsqueeze", "t.unsqueeze.unsqueeze.unsqueeze", "torch.squeeze.gather", "torch.squeeze.gather", "torch.squeeze.gather", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.mean.FocalLoss.weight.to", "torch.squeeze.expand", "torch.squeeze.expand", "torch.squeeze.expand", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean.sum", "torch.mean.sum", "torch.mean.sum", "torch.mean.mean", "torch.mean.mean", "torch.mean.mean", "i.unsqueeze.unsqueeze.size", "i.unsqueeze.unsqueeze.size", "t.unsqueeze.unsqueeze.size", "t.unsqueeze.unsqueeze.size", "t.unsqueeze.unsqueeze.long", "torch.squeeze.gather", "torch.squeeze.gather", "torch.squeeze.gather", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "t.unsqueeze.unsqueeze.size", "t.unsqueeze.unsqueeze.size", "t.unsqueeze.unsqueeze.long"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input", ",", "target", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            input: (tensor): the shape should be BCH[WD].\n                where C is the number of classes.\n            target: (tensor): the shape should be B1H[WD] or BCH[WD].\n                If the target's shape is B1H[WD], the target that this loss expects should be a class index\n                in the range [0, C-1] where C is the number of classes.\n        \"\"\"", "\n", "i", "=", "input", "\n", "t", "=", "target", "\n", "\n", "if", "i", ".", "ndim", "!=", "t", ".", "ndim", ":", "\n", "            ", "raise", "ValueError", "(", "f\"input and target must have the same number of dimensions, got {i.ndim} and {t.ndim}\"", ")", "\n", "\n", "", "if", "target", ".", "shape", "[", "1", "]", "!=", "1", "and", "target", ".", "shape", "[", "1", "]", "!=", "i", ".", "shape", "[", "1", "]", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "\"target must have one channel or have the same shape as the input. \"", "\n", "\"If it has one channel, it should be a class index in the range [0, C-1] \"", "\n", "f\"where C is the number of classes inferred from 'input': C={i.shape[1]}. \"", "\n", ")", "\n", "# Change the shape of input and target to", "\n", "# num_batch x num_class x num_voxels.", "\n", "", "if", "input", ".", "dim", "(", ")", ">", "2", ":", "\n", "            ", "i", "=", "i", ".", "view", "(", "i", ".", "size", "(", "0", ")", ",", "i", ".", "size", "(", "1", ")", ",", "-", "1", ")", "# N,C,H,W => N,C,H*W", "\n", "t", "=", "t", ".", "view", "(", "t", ".", "size", "(", "0", ")", ",", "t", ".", "size", "(", "1", ")", ",", "-", "1", ")", "# N,1,H,W => N,1,H*W or N,C,H*W", "\n", "", "else", ":", "# Compatibility with classification.", "\n", "            ", "i", "=", "i", ".", "unsqueeze", "(", "2", ")", "# N,C => N,C,1", "\n", "t", "=", "t", ".", "unsqueeze", "(", "2", ")", "# N,1 => N,1,1 or N,C,1", "\n", "\n", "# Compute the log proba (more stable numerically than softmax).", "\n", "", "logpt", "=", "F", ".", "log_softmax", "(", "i", ",", "dim", "=", "1", ")", "# N,C,H*W", "\n", "# Keep only log proba values of the ground truth class for each voxel.", "\n", "if", "target", ".", "shape", "[", "1", "]", "==", "1", ":", "\n", "            ", "logpt", "=", "logpt", ".", "gather", "(", "1", ",", "t", ".", "long", "(", ")", ")", "# N,C,H*W => N,1,H*W", "\n", "logpt", "=", "torch", ".", "squeeze", "(", "logpt", ",", "dim", "=", "1", ")", "# N,1,H*W => N,H*W", "\n", "\n", "# Get the proba", "\n", "", "pt", "=", "torch", ".", "exp", "(", "logpt", ")", "# N,H*W or N,C,H*W", "\n", "\n", "if", "self", ".", "weight", "is", "not", "None", ":", "\n", "            ", "self", ".", "weight", "=", "self", ".", "weight", ".", "to", "(", "i", ")", "\n", "# Convert the weight to a map in which each voxel", "\n", "# has the weight associated with the ground-truth label", "\n", "# associated with this voxel in target.", "\n", "at", "=", "self", ".", "weight", "[", "None", ",", ":", ",", "None", "]", "# C => 1,C,1", "\n", "at", "=", "at", ".", "expand", "(", "(", "t", ".", "size", "(", "0", ")", ",", "-", "1", ",", "t", ".", "size", "(", "2", ")", ")", ")", "# 1,C,1 => N,C,H*W", "\n", "if", "target", ".", "shape", "[", "1", "]", "==", "1", ":", "\n", "                ", "at", "=", "at", ".", "gather", "(", "1", ",", "t", ".", "long", "(", ")", ")", "# selection of the weights  => N,1,H*W", "\n", "at", "=", "torch", ".", "squeeze", "(", "at", ",", "dim", "=", "1", ")", "# N,1,H*W => N,H*W", "\n", "# Multiply the log proba by their weights.", "\n", "", "logpt", "=", "logpt", "*", "at", "\n", "\n", "# Compute the loss mini-batch.", "\n", "", "weight", "=", "torch", ".", "pow", "(", "-", "pt", "+", "1.0", ",", "self", ".", "gamma", ")", "\n", "if", "target", ".", "shape", "[", "1", "]", "==", "1", ":", "\n", "            ", "loss", "=", "torch", ".", "mean", "(", "-", "weight", "*", "logpt", ",", "dim", "=", "1", ")", "# N", "\n", "", "else", ":", "\n", "            ", "loss", "=", "torch", ".", "mean", "(", "-", "weight", "*", "t", "*", "logpt", ",", "dim", "=", "-", "1", ")", "# N,C", "\n", "\n", "", "if", "self", ".", "reduction", "==", "\"sum\"", ":", "\n", "            ", "return", "loss", ".", "sum", "(", ")", "\n", "", "if", "self", ".", "reduction", "==", "\"none\"", ":", "\n", "            ", "return", "loss", "\n", "", "if", "self", ".", "reduction", "==", "\"mean\"", ":", "\n", "            ", "return", "loss", ".", "mean", "(", ")", "\n", "", "raise", "ValueError", "(", "f\"reduction={self.reduction} is invalid.\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.embedding.loss.MultiFocalLoss.__init__": [[122, 147], ["torch.Module.__init__", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "isinstance", "torch.FloatTensor().view", "torch.FloatTensor().view", "torch.FloatTensor().view", "torch.FloatTensor().view", "torch.FloatTensor().view", "torch.FloatTensor().view", "torch.FloatTensor().view", "torch.FloatTensor().view", "torch.FloatTensor().view", "isinstance", "ValueError", "len", "loss.MultiFocalLoss.alpha.sum", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "TypeError", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor"], "methods", ["home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.label_prediction.transformer_scifact.SciFactLabelPredictionDataset.__init__"], ["def", "__init__", "(", "self", ",", "num_class", ",", "alpha", "=", "None", ",", "gamma", "=", "2", ",", "balance_index", "=", "-", "1", ",", "smooth", "=", "None", ",", "size_average", "=", "True", ")", ":", "\n", "        ", "super", "(", "MultiFocalLoss", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "num_class", "=", "num_class", "\n", "self", ".", "alpha", "=", "alpha", "\n", "self", ".", "gamma", "=", "gamma", "\n", "self", ".", "smooth", "=", "smooth", "\n", "self", ".", "size_average", "=", "size_average", "\n", "\n", "if", "self", ".", "alpha", "is", "None", ":", "\n", "            ", "self", ".", "alpha", "=", "torch", ".", "ones", "(", "self", ".", "num_class", ",", "1", ")", "\n", "", "elif", "isinstance", "(", "self", ".", "alpha", ",", "(", "list", ",", "np", ".", "ndarray", ")", ")", ":", "\n", "            ", "assert", "len", "(", "self", ".", "alpha", ")", "==", "self", ".", "num_class", "\n", "self", ".", "alpha", "=", "torch", ".", "FloatTensor", "(", "alpha", ")", ".", "view", "(", "self", ".", "num_class", ",", "1", ")", "\n", "self", ".", "alpha", "=", "self", ".", "alpha", "/", "self", ".", "alpha", ".", "sum", "(", ")", "\n", "", "elif", "isinstance", "(", "self", ".", "alpha", ",", "float", ")", ":", "\n", "            ", "alpha", "=", "torch", ".", "ones", "(", "self", ".", "num_class", ",", "1", ")", "\n", "alpha", "=", "alpha", "*", "(", "1", "-", "self", ".", "alpha", ")", "\n", "alpha", "[", "balance_index", "]", "=", "self", ".", "alpha", "\n", "self", ".", "alpha", "=", "alpha", "\n", "", "else", ":", "\n", "            ", "raise", "TypeError", "(", "'Not support alpha type'", ")", "\n", "\n", "", "if", "self", ".", "smooth", "is", "not", "None", ":", "\n", "            ", "if", "self", ".", "smooth", "<", "0", "or", "self", ".", "smooth", ">", "1.0", ":", "\n", "                ", "raise", "ValueError", "(", "'smooth value should be in [0,1]'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.embedding.loss.MultiFocalLoss.forward": [[148, 189], ["torch.softmax", "torch.softmax", "torch.softmax", "target.view.view.view", "target.view.view.cpu().long", "torch.FloatTensor().zero_", "torch.FloatTensor().zero_", "torch.FloatTensor().zero_", "torch.FloatTensor().zero_", "torch.FloatTensor().zero_", "torch.FloatTensor().zero_", "torch.FloatTensor().zero_", "torch.FloatTensor().zero_", "torch.FloatTensor().zero_", "torch.clamp.scatter_", "torch.clamp.scatter_", "torch.clamp.scatter_", "pt.log", "logit.view.view.dim", "logit.view.view.view", "logit.view.view.permute().contiguous", "logit.view.view.view", "alpha.to.to.to", "torch.clamp.to", "torch.clamp.to", "torch.clamp.to", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "loss.sum.sum.mean", "loss.sum.sum.sum", "logit.view.view.size", "logit.view.view.size", "logit.view.view.size", "target.view.view.cpu", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "logit.view.view.permute", "target.view.view.size"], "methods", ["None"], ["", "", "", "def", "forward", "(", "self", ",", "input", ",", "target", ")", ":", "\n", "        ", "logit", "=", "F", ".", "softmax", "(", "input", ",", "dim", "=", "1", ")", "\n", "\n", "if", "logit", ".", "dim", "(", ")", ">", "2", ":", "\n", "# N,C,d1,d2 -> N,C,m (m=d1*d2*...)", "\n", "            ", "logit", "=", "logit", ".", "view", "(", "logit", ".", "size", "(", "0", ")", ",", "logit", ".", "size", "(", "1", ")", ",", "-", "1", ")", "\n", "logit", "=", "logit", ".", "permute", "(", "0", ",", "2", ",", "1", ")", ".", "contiguous", "(", ")", "\n", "logit", "=", "logit", ".", "view", "(", "-", "1", ",", "logit", ".", "size", "(", "-", "1", ")", ")", "\n", "", "target", "=", "target", ".", "view", "(", "-", "1", ",", "1", ")", "\n", "\n", "# N = input.size(0)", "\n", "# alpha = torch.ones(N, self.num_class)", "\n", "# alpha = alpha * (1 - self.alpha)", "\n", "# alpha = alpha.scatter_(1, target.long(), self.alpha)", "\n", "epsilon", "=", "1e-10", "\n", "alpha", "=", "self", ".", "alpha", "\n", "if", "alpha", ".", "device", "!=", "input", ".", "device", ":", "\n", "            ", "alpha", "=", "alpha", ".", "to", "(", "input", ".", "device", ")", "\n", "\n", "", "idx", "=", "target", ".", "cpu", "(", ")", ".", "long", "(", ")", "\n", "one_hot_key", "=", "torch", ".", "FloatTensor", "(", "target", ".", "size", "(", "0", ")", ",", "self", ".", "num_class", ")", ".", "zero_", "(", ")", "\n", "one_hot_key", "=", "one_hot_key", ".", "scatter_", "(", "1", ",", "idx", ",", "1", ")", "\n", "if", "one_hot_key", ".", "device", "!=", "logit", ".", "device", ":", "\n", "            ", "one_hot_key", "=", "one_hot_key", ".", "to", "(", "logit", ".", "device", ")", "\n", "\n", "", "if", "self", ".", "smooth", ":", "\n", "            ", "one_hot_key", "=", "torch", ".", "clamp", "(", "\n", "one_hot_key", ",", "self", ".", "smooth", ",", "1.0", "-", "self", ".", "smooth", ")", "\n", "", "pt", "=", "(", "one_hot_key", "*", "logit", ")", ".", "sum", "(", "1", ")", "+", "epsilon", "\n", "logpt", "=", "pt", ".", "log", "(", ")", "\n", "\n", "gamma", "=", "self", ".", "gamma", "\n", "\n", "alpha", "=", "alpha", "[", "idx", "]", "\n", "loss", "=", "-", "1", "*", "alpha", "*", "torch", ".", "pow", "(", "(", "1", "-", "pt", ")", ",", "gamma", ")", "*", "logpt", "\n", "\n", "if", "self", ".", "size_average", ":", "\n", "            ", "loss", "=", "loss", ".", "mean", "(", ")", "\n", "", "else", ":", "\n", "            ", "loss", "=", "loss", ".", "sum", "(", ")", "\n", "", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.embedding.loss.DiceLoss.__init__": [[223, 240], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.label_prediction.transformer_scifact.SciFactLabelPredictionDataset.__init__"], ["def", "__init__", "(", "self", ",", "\n", "smooth", ":", "Optional", "[", "float", "]", "=", "1e-4", ",", "\n", "square_denominator", ":", "Optional", "[", "bool", "]", "=", "False", ",", "\n", "with_logits", ":", "Optional", "[", "bool", "]", "=", "True", ",", "\n", "ohem_ratio", ":", "float", "=", "0.0", ",", "\n", "alpha", ":", "float", "=", "0.0", ",", "\n", "reduction", ":", "Optional", "[", "str", "]", "=", "\"mean\"", ",", "\n", "index_label_position", "=", "True", ")", "->", "None", ":", "\n", "        ", "super", "(", "DiceLoss", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "reduction", "=", "reduction", "\n", "self", ".", "with_logits", "=", "with_logits", "\n", "self", ".", "smooth", "=", "smooth", "\n", "self", ".", "square_denominator", "=", "square_denominator", "\n", "self", ".", "ohem_ratio", "=", "ohem_ratio", "\n", "self", ".", "alpha", "=", "alpha", "\n", "self", ".", "index_label_position", "=", "index_label_position", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.embedding.loss.DiceLoss.forward": [[241, 254], ["loss.DiceLoss.DiceLoss._multiple_class", "loss.DiceLoss.DiceLoss._binary_class", "loss.DiceLoss.DiceLoss.mean", "loss.DiceLoss.DiceLoss.sum"], "methods", ["home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.embedding.loss.DiceLoss._multiple_class", "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.embedding.loss.DiceLoss._binary_class"], ["", "def", "forward", "(", "self", ",", "input", ":", "Tensor", ",", "target", ":", "Tensor", ",", "mask", ":", "Optional", "[", "Tensor", "]", "=", "None", ")", "->", "Tensor", ":", "\n", "        ", "logits_size", "=", "input", ".", "shape", "[", "-", "1", "]", "\n", "\n", "if", "logits_size", "!=", "1", ":", "\n", "            ", "loss", "=", "self", ".", "_multiple_class", "(", "input", ",", "target", ",", "logits_size", ",", "mask", "=", "mask", ")", "\n", "", "else", ":", "\n", "            ", "loss", "=", "self", ".", "_binary_class", "(", "input", ",", "target", ",", "mask", "=", "mask", ")", "\n", "\n", "", "if", "self", ".", "reduction", "==", "\"mean\"", ":", "\n", "            ", "return", "loss", ".", "mean", "(", ")", "\n", "", "if", "self", ".", "reduction", "==", "\"sum\"", ":", "\n", "            ", "return", "loss", ".", "sum", "(", ")", "\n", "", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.embedding.loss.DiceLoss._compute_dice_loss": [[255, 266], ["torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "flat_input.sum", "flat_target.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.square", "torch.square", "torch.square", "torch.square", "torch.square", "torch.square", "torch.square", "torch.square", "torch.square", "torch.square", "torch.square", "torch.square", "torch.square", "torch.square", "torch.square", "torch.square", "torch.square", "torch.square"], "methods", ["None"], ["", "def", "_compute_dice_loss", "(", "self", ",", "flat_input", ",", "flat_target", ")", ":", "\n", "        ", "flat_input", "=", "(", "(", "1", "-", "flat_input", ")", "**", "self", ".", "alpha", ")", "*", "flat_input", "\n", "interection", "=", "torch", ".", "sum", "(", "flat_input", "*", "flat_target", ",", "-", "1", ")", "\n", "if", "not", "self", ".", "square_denominator", ":", "\n", "            ", "loss", "=", "1", "-", "(", "(", "2", "*", "interection", "+", "self", ".", "smooth", ")", "/", "\n", "(", "flat_input", ".", "sum", "(", ")", "+", "flat_target", ".", "sum", "(", ")", "+", "self", ".", "smooth", ")", ")", "\n", "", "else", ":", "\n", "            ", "loss", "=", "1", "-", "(", "(", "2", "*", "interection", "+", "self", ".", "smooth", ")", "/", "\n", "(", "torch", ".", "sum", "(", "torch", ".", "square", "(", "flat_input", ",", ")", ",", "-", "1", ")", "+", "torch", ".", "sum", "(", "torch", ".", "square", "(", "flat_target", ")", ",", "-", "1", ")", "+", "self", ".", "smooth", ")", ")", "\n", "\n", "", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.embedding.loss.DiceLoss._multiple_class": [[267, 329], ["torch.one_hot().float", "torch.one_hot().float", "torch.one_hot().float", "target.float", "torch.ones_like.float", "torch.ones_like.float", "torch.ones_like.float", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.logical_not", "torch.logical_not", "torch.logical_not", "torch.logical_not", "torch.logical_not", "torch.logical_not", "torch.logical_not", "torch.logical_not", "torch.logical_not", "range", "range", "torch.nn.Softmax", "torch.nn.Softmax", "torch.nn.Softmax", "torch.nn.Softmax", "torch.nn.Softmax", "torch.nn.Softmax", "torch.nn.Softmax", "torch.nn.Softmax", "torch.nn.Softmax", "pos_example.sum", "min", "loss.DiceLoss._compute_dice_loss", "loss.DiceLoss._compute_dice_loss", "torch.one_hot", "torch.one_hot", "torch.one_hot", "torch.ones_like.sum", "torch.ones_like.sum", "torch.ones_like.sum", "int", "torch.masked_select().view", "torch.masked_select().view", "torch.masked_select().view", "torch.masked_select().view", "torch.masked_select().view", "torch.masked_select().view", "torch.masked_select().view", "torch.masked_select().view", "torch.masked_select().view", "torch.sort", "torch.sort", "torch.sort", "torch.sort", "torch.sort", "torch.sort", "torch.sort", "torch.sort", "torch.sort", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "flat_input_idx.view", "flat_target_idx.view", "flat_input_idx.view", "flat_target_idx.view", "pos_example.view", "torch.tensor().cuda", "torch.tensor().cuda", "torch.tensor().cuda", "torch.tensor().cuda", "torch.tensor().cuda", "torch.tensor().cuda", "torch.tensor().cuda", "torch.tensor().cuda", "torch.tensor().cuda", "torch.tensor().cuda", "torch.tensor().cuda", "torch.tensor().cuda", "torch.tensor().cuda", "torch.tensor().cuda", "torch.tensor().cuda", "torch.tensor().cuda", "torch.tensor().cuda", "torch.tensor().cuda", "torch.masked_select", "torch.masked_select", "torch.masked_select", "torch.masked_select", "torch.masked_select", "torch.masked_select", "torch.masked_select", "torch.masked_select", "torch.masked_select", "neg_example.view().bool", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "neg_example.view"], "methods", ["home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.embedding.loss.DiceLoss._compute_dice_loss", "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.embedding.loss.DiceLoss._compute_dice_loss"], ["", "def", "_multiple_class", "(", "self", ",", "input", ",", "target", ",", "logits_size", ",", "mask", "=", "None", ")", ":", "\n", "        ", "flat_input", "=", "input", "\n", "flat_target", "=", "F", ".", "one_hot", "(", "target", ",", "num_classes", "=", "logits_size", ")", ".", "float", "(", ")", "if", "self", ".", "index_label_position", "else", "target", ".", "float", "(", ")", "\n", "flat_input", "=", "torch", ".", "nn", ".", "Softmax", "(", "dim", "=", "1", ")", "(", "flat_input", ")", "if", "self", ".", "with_logits", "else", "flat_input", "\n", "\n", "if", "mask", "is", "not", "None", ":", "\n", "            ", "mask", "=", "mask", ".", "float", "(", ")", "\n", "flat_input", "=", "flat_input", "*", "mask", "\n", "flat_target", "=", "flat_target", "*", "mask", "\n", "", "else", ":", "\n", "            ", "mask", "=", "torch", ".", "ones_like", "(", "target", ")", "\n", "\n", "", "loss", "=", "None", "\n", "if", "self", ".", "ohem_ratio", ">", "0", ":", "\n", "            ", "mask_neg", "=", "torch", ".", "logical_not", "(", "mask", ")", "\n", "for", "label_idx", "in", "range", "(", "logits_size", ")", ":", "\n", "                ", "pos_example", "=", "target", "==", "label_idx", "\n", "neg_example", "=", "target", "!=", "label_idx", "\n", "\n", "pos_num", "=", "pos_example", ".", "sum", "(", ")", "\n", "neg_num", "=", "mask", ".", "sum", "(", ")", "-", "(", "pos_num", "-", "(", "mask_neg", "&", "pos_example", ")", ".", "sum", "(", ")", ")", "\n", "keep_num", "=", "min", "(", "int", "(", "pos_num", "*", "self", ".", "ohem_ratio", "/", "logits_size", ")", ",", "neg_num", ")", "\n", "\n", "if", "keep_num", ">", "0", ":", "\n", "                    ", "neg_scores", "=", "torch", ".", "masked_select", "(", "flat_input", ",", "neg_example", ".", "view", "(", "-", "1", ",", "1", ")", ".", "bool", "(", ")", ")", ".", "view", "(", "-", "1", ",", "logits_size", ")", "\n", "neg_scores_idx", "=", "neg_scores", "[", ":", ",", "label_idx", "]", "\n", "neg_scores_sort", ",", "_", "=", "torch", ".", "sort", "(", "neg_scores_idx", ",", ")", "\n", "threshold", "=", "neg_scores_sort", "[", "-", "keep_num", "+", "1", "]", "\n", "# cond = (torch.argmax(flat_input, dim=1) == label_idx & flat_input[:, label_idx] >= threshold) | pos_example.view(-1)", "\n", "cond", "=", "(", "(", "torch", ".", "argmax", "(", "flat_input", ",", "dim", "=", "1", ")", "==", "label_idx", ")", "&", "(", "\n", "flat_input", "[", ":", ",", "label_idx", "]", ">=", "threshold", ")", ")", "|", "pos_example", ".", "view", "(", "-", "1", ")", "\n", "# ohem_mask_idx = torch.where(cond, 1, 0)", "\n", "ohem_mask_idx", "=", "torch", ".", "where", "(", "cond", ",", "torch", ".", "tensor", "(", "1", ")", ".", "cuda", "(", ")", ",", "torch", ".", "tensor", "(", "0", ")", ".", "cuda", "(", ")", ")", "\n", "\n", "flat_input_idx", "=", "flat_input", "[", ":", ",", "label_idx", "]", "\n", "flat_target_idx", "=", "flat_target", "[", ":", ",", "label_idx", "]", "\n", "\n", "flat_input_idx", "=", "flat_input_idx", "*", "ohem_mask_idx", "\n", "flat_target_idx", "=", "flat_target_idx", "*", "ohem_mask_idx", "\n", "", "else", ":", "\n", "                    ", "flat_input_idx", "=", "flat_input", "[", ":", ",", "label_idx", "]", "\n", "flat_target_idx", "=", "flat_target", "[", ":", ",", "label_idx", "]", "\n", "\n", "", "loss_idx", "=", "self", ".", "_compute_dice_loss", "(", "flat_input_idx", ".", "view", "(", "-", "1", ",", "1", ")", ",", "flat_target_idx", ".", "view", "(", "-", "1", ",", "1", ")", ")", "\n", "if", "loss", "is", "None", ":", "\n", "                    ", "loss", "=", "loss_idx", "\n", "", "else", ":", "\n", "                    ", "loss", "+=", "loss_idx", "\n", "", "", "return", "loss", "\n", "\n", "", "else", ":", "\n", "            ", "for", "label_idx", "in", "range", "(", "logits_size", ")", ":", "\n", "                ", "pos_example", "=", "target", "==", "label_idx", "\n", "flat_input_idx", "=", "flat_input", "[", ":", ",", "label_idx", "]", "\n", "flat_target_idx", "=", "flat_target", "[", ":", ",", "label_idx", "]", "\n", "\n", "loss_idx", "=", "self", ".", "_compute_dice_loss", "(", "flat_input_idx", ".", "view", "(", "-", "1", ",", "1", ")", ",", "flat_target_idx", ".", "view", "(", "-", "1", ",", "1", ")", ")", "\n", "if", "loss", "is", "None", ":", "\n", "                    ", "loss", "=", "loss_idx", "\n", "", "else", ":", "\n", "                    ", "loss", "+=", "loss_idx", "\n", "", "", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.embedding.loss.DiceLoss._binary_class": [[330, 360], ["input.view", "target.view().float", "loss.DiceLoss._compute_dice_loss", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.ones_like.float", "torch.ones_like.float", "torch.ones_like.float", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "neg_example.sum", "min", "torch.masked_select", "torch.masked_select", "torch.masked_select", "torch.masked_select", "torch.masked_select", "torch.masked_select", "torch.masked_select", "torch.masked_select", "torch.masked_select", "torch.sort", "torch.sort", "torch.sort", "torch.sort", "torch.sort", "torch.sort", "torch.sort", "torch.sort", "torch.sort", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "target.view", "pos_example.sum", "int", "neg_example.bool", "pos_example.view"], "methods", ["home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.embedding.loss.DiceLoss._compute_dice_loss"], ["", "", "def", "_binary_class", "(", "self", ",", "input", ",", "target", ",", "mask", "=", "None", ")", ":", "\n", "        ", "flat_input", "=", "input", ".", "view", "(", "-", "1", ")", "\n", "flat_target", "=", "target", ".", "view", "(", "-", "1", ")", ".", "float", "(", ")", "\n", "flat_input", "=", "torch", ".", "sigmoid", "(", "flat_input", ")", "if", "self", ".", "with_logits", "else", "flat_input", "\n", "\n", "if", "mask", "is", "not", "None", ":", "\n", "            ", "mask", "=", "mask", ".", "float", "(", ")", "\n", "flat_input", "=", "flat_input", "*", "mask", "\n", "flat_target", "=", "flat_target", "*", "mask", "\n", "", "else", ":", "\n", "            ", "mask", "=", "torch", ".", "ones_like", "(", "target", ")", "\n", "\n", "", "if", "self", ".", "ohem_ratio", ">", "0", ":", "\n", "            ", "pos_example", "=", "target", ">", "0.5", "\n", "neg_example", "=", "target", "<=", "0.5", "\n", "mask_neg_num", "=", "mask", "<=", "0.5", "\n", "\n", "pos_num", "=", "pos_example", ".", "sum", "(", ")", "-", "(", "pos_example", "&", "mask_neg_num", ")", ".", "sum", "(", ")", "\n", "neg_num", "=", "neg_example", ".", "sum", "(", ")", "\n", "keep_num", "=", "min", "(", "int", "(", "pos_num", "*", "self", ".", "ohem_ratio", ")", ",", "neg_num", ")", "\n", "\n", "neg_scores", "=", "torch", ".", "masked_select", "(", "flat_input", ",", "neg_example", ".", "bool", "(", ")", ")", "\n", "neg_scores_sort", ",", "_", "=", "torch", ".", "sort", "(", "neg_scores", ",", ")", "\n", "threshold", "=", "neg_scores_sort", "[", "-", "keep_num", "+", "1", "]", "\n", "cond", "=", "(", "flat_input", ">", "threshold", ")", "|", "pos_example", ".", "view", "(", "-", "1", ")", "\n", "ohem_mask", "=", "torch", ".", "where", "(", "cond", ",", "1", ",", "0", ")", "\n", "flat_input", "=", "flat_input", "*", "ohem_mask", "\n", "flat_target", "=", "flat_target", "*", "ohem_mask", "\n", "\n", "", "return", "self", ".", "_compute_dice_loss", "(", "flat_input", ",", "flat_target", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.embedding.loss.DiceLoss.__str__": [[361, 363], ["None"], "methods", ["None"], ["", "def", "__str__", "(", "self", ")", ":", "\n", "        ", "return", "f\"Dice Loss smooth:{self.smooth}, ohem: {self.ohem_ratio}, alpha: {self.alpha}\"", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.embedding.loss.DiceLoss.__repr__": [[364, 366], ["str"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "return", "str", "(", "self", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.evaluation.metrics.safe_divide": [[17, 22], ["None"], "function", ["None"], ["def", "safe_divide", "(", "num", ",", "denom", ")", ":", "\n", "    ", "if", "denom", "==", "0", ":", "\n", "        ", "return", "0", "\n", "", "else", ":", "\n", "        ", "return", "num", "/", "denom", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.evaluation.metrics.compute_f1": [[24, 30], ["metrics.safe_divide", "metrics.safe_divide", "metrics.safe_divide"], "function", ["home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.lib.metrics.safe_divide", "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.lib.metrics.safe_divide", "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.lib.metrics.safe_divide"], ["", "", "def", "compute_f1", "(", "counts", ",", "difficulty", "=", "None", ")", ":", "\n", "    ", "correct_key", "=", "\"correct\"", "if", "difficulty", "is", "None", "else", "f\"correct_{difficulty}\"", "\n", "precision", "=", "safe_divide", "(", "counts", "[", "correct_key", "]", ",", "counts", "[", "\"retrieved\"", "]", ")", "\n", "recall", "=", "safe_divide", "(", "counts", "[", "correct_key", "]", ",", "counts", "[", "\"relevant\"", "]", ")", "\n", "f1", "=", "safe_divide", "(", "2", "*", "precision", "*", "recall", ",", "precision", "+", "recall", ")", "\n", "return", "{", "\"precision\"", ":", "precision", ",", "\"recall\"", ":", "recall", ",", "\"f1\"", ":", "f1", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.evaluation.metrics.contains_evidence": [[39, 46], ["gold_rat.issubset"], "function", ["None"], ["def", "contains_evidence", "(", "predicted", ",", "gold", ")", ":", "\n", "# If any of gold are contained in predicted, we're good.", "\n", "    ", "for", "gold_rat", "in", "gold", ":", "\n", "        ", "if", "gold_rat", ".", "issubset", "(", "predicted", ")", ":", "\n", "            ", "return", "True", "\n", "# If we get to the end, didn't find one.", "\n", "", "", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.evaluation.metrics.is_correct": [[48, 64], ["metrics.contains_evidence", "set", "set"], "function", ["home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.lib.metrics.contains_evidence"], ["", "def", "is_correct", "(", "doc_id", ",", "doc_pred", ",", "gold", ")", ":", "\n", "    ", "pred_rationales", "=", "doc_pred", ".", "rationale", "[", ":", "MAX_ABSTRACT_SENTS", "]", "\n", "\n", "# If it's not an evidence document, we lose.", "\n", "if", "doc_id", "not", "in", "gold", ".", "evidence", ":", "\n", "        ", "return", "False", ",", "False", "\n", "\n", "# If the label's wrong, we lose.", "\n", "", "gold_label", "=", "gold", ".", "evidence", "[", "doc_id", "]", ".", "label", "\n", "if", "doc_pred", ".", "label", "!=", "gold_label", ":", "\n", "        ", "return", "False", ",", "False", "\n", "\n", "", "gold_rationales", "=", "[", "set", "(", "x", ")", "for", "x", "in", "gold", ".", "evidence", "[", "doc_id", "]", ".", "rationales", "]", "\n", "good_rationalized", "=", "contains_evidence", "(", "set", "(", "pred_rationales", ")", ",", "gold_rationales", ")", "\n", "good_label_only", "=", "True", "\n", "return", "good_label_only", ",", "good_rationalized", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.evaluation.metrics.update_counts_abstract": [[66, 81], ["len", "pred.predictions.items", "metrics.is_correct"], "function", ["home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.lib.metrics.is_correct"], ["", "def", "update_counts_abstract", "(", "pred", ",", "gold", ",", "counts_abstract", ")", ":", "\n", "    ", "counts_abstract", "[", "\"relevant\"", "]", "+=", "len", "(", "gold", ".", "evidence", ")", "\n", "for", "doc_id", ",", "doc_pred", "in", "pred", ".", "predictions", ".", "items", "(", ")", ":", "\n", "# If it's NEI, doesn't count one way or the other.", "\n", "        ", "if", "doc_pred", ".", "label", "==", "Label", ".", "NEI", ":", "\n", "            ", "continue", "\n", "", "counts_abstract", "[", "\"retrieved\"", "]", "+=", "1", "\n", "\n", "good_label_only", ",", "good_rationalized", "=", "is_correct", "(", "doc_id", ",", "doc_pred", ",", "gold", ")", "\n", "if", "good_label_only", ":", "\n", "            ", "counts_abstract", "[", "\"correct_label_only\"", "]", "+=", "1", "\n", "", "if", "good_rationalized", ":", "\n", "            ", "counts_abstract", "[", "\"correct_rationalized\"", "]", "+=", "1", "\n", "\n", "", "", "return", "counts_abstract", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.evaluation.metrics.count_rationale_sents": [[90, 105], ["gold_set.issubset", "len", "len"], "function", ["None"], ["def", "count_rationale_sents", "(", "predicted", ",", "gold", ")", ":", "\n", "    ", "n_correct", "=", "0", "\n", "\n", "for", "ix", "in", "predicted", ":", "\n", "        ", "gold_sets", "=", "[", "entry", "for", "entry", "in", "gold", "if", "ix", "in", "entry", "]", "\n", "assert", "len", "(", "gold_sets", ")", "<", "2", "# Can't be in two rationales.", "\n", "# If it's not in a gold set, no dice.", "\n", "if", "len", "(", "gold_sets", ")", "==", "0", ":", "\n", "            ", "continue", "\n", "# If it's in a gold set, make sure the rest got retrieved.", "\n", "", "gold_set", "=", "gold_sets", "[", "0", "]", "\n", "if", "gold_set", ".", "issubset", "(", "predicted", ")", ":", "\n", "            ", "n_correct", "+=", "1", "\n", "\n", "", "", "return", "n_correct", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.evaluation.metrics.count_correct": [[107, 123], ["metrics.count_rationale_sents", "int", "set", "set"], "function", ["home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.lib.metrics.count_rationale_sents"], ["", "def", "count_correct", "(", "doc_id", ",", "doc_pred", ",", "gold", ")", ":", "\n", "# If not an evidence doc, no good.", "\n", "    ", "if", "doc_id", "not", "in", "gold", ".", "evidence", ":", "\n", "        ", "return", "0", ",", "0", "\n", "\n", "# Count the number of rationale sentences we get credit for.", "\n", "", "gold_rationales", "=", "[", "set", "(", "x", ")", "for", "x", "in", "gold", ".", "evidence", "[", "doc_id", "]", ".", "rationales", "]", "\n", "n_correct", "=", "count_rationale_sents", "(", "set", "(", "doc_pred", ".", "rationale", ")", ",", "gold_rationales", ")", "\n", "\n", "gold_label", "=", "gold", ".", "evidence", "[", "doc_id", "]", ".", "label", "\n", "\n", "n_correct_selection", "=", "n_correct", "\n", "correct_label", "=", "int", "(", "doc_pred", ".", "label", "==", "gold_label", ")", "\n", "n_correct_label", "=", "correct_label", "*", "n_correct", "\n", "\n", "return", "n_correct_selection", ",", "n_correct_label", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.evaluation.metrics.update_counts_sentence": [[125, 141], ["gold.evidence.values", "pred.predictions.items", "sum", "len", "metrics.count_correct", "len"], "function", ["home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.lib.metrics.count_correct"], ["", "def", "update_counts_sentence", "(", "pred", ",", "gold", ",", "counts_sentence", ")", ":", "\n", "# Update the gold evidence sentences.", "\n", "    ", "for", "gold_doc", "in", "gold", ".", "evidence", ".", "values", "(", ")", ":", "\n", "        ", "counts_sentence", "[", "\"relevant\"", "]", "+=", "sum", "(", "[", "len", "(", "x", ")", "for", "x", "in", "gold_doc", ".", "rationales", "]", ")", "\n", "\n", "", "for", "doc_id", ",", "doc_pred", "in", "pred", ".", "predictions", ".", "items", "(", ")", ":", "\n", "# If it's NEI, skip it.", "\n", "        ", "if", "doc_pred", ".", "label", "==", "Label", ".", "NEI", ":", "\n", "            ", "continue", "\n", "\n", "", "counts_sentence", "[", "\"retrieved\"", "]", "+=", "len", "(", "doc_pred", ".", "rationale", ")", "\n", "n_correct_selection", ",", "n_correct_label", "=", "count_correct", "(", "doc_id", ",", "doc_pred", ",", "gold", ")", "\n", "counts_sentence", "[", "\"correct_selection\"", "]", "+=", "n_correct_selection", "\n", "counts_sentence", "[", "\"correct_label\"", "]", "+=", "n_correct_label", "\n", "\n", "", "return", "counts_sentence", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.evaluation.metrics.check_rationale_lengths": [[150, 167], ["predictions.items", "pandas.DataFrame", "warnings.warn", "print", "len", "pd.DataFrame.append", "pd.DataFrame.__repr__"], "function", ["home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.lib.data.ClaimPredictions.__repr__"], ["def", "check_rationale_lengths", "(", "preds", ")", ":", "\n", "    ", "bad", "=", "[", "]", "\n", "for", "pred", "in", "preds", ":", "\n", "        ", "claim_id", "=", "pred", ".", "claim_id", "\n", "predictions", "=", "pred", ".", "predictions", "\n", "for", "doc_key", ",", "prediction", "in", "predictions", ".", "items", "(", ")", ":", "\n", "            ", "n_rationales", "=", "len", "(", "prediction", ".", "rationale", ")", "\n", "if", "n_rationales", ">", "MAX_ABSTRACT_SENTS", ":", "\n", "                ", "to_append", "=", "{", "\"claim_id\"", ":", "claim_id", ",", "\"abstract\"", ":", "doc_key", ",", "\"n_rationales\"", ":", "n_rationales", "}", "\n", "bad", ".", "append", "(", "to_append", ")", "\n", "", "", "", "if", "bad", ":", "\n", "        ", "bad", "=", "pd", ".", "DataFrame", "(", "bad", ")", "\n", "msg", "=", "(", "f\"\\nRationales with more than {MAX_ABSTRACT_SENTS} sentences found.\\n\"", "\n", "f\"The first 3 will be used for abstract-level evaluation\\n\\n\"", "\n", "f\"{bad.__repr__()}\"", ")", "\n", "warnings", ".", "warn", "(", "msg", ")", "\n", "print", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.evaluation.metrics.compute_metrics": [[175, 194], ["collections.Counter", "collections.Counter", "pandas.DataFrame", "preds.gold.get_claim", "metrics.update_counts_abstract", "metrics.update_counts_sentence", "metrics.compute_f1", "metrics.compute_f1", "metrics.compute_f1", "metrics.compute_f1"], "function", ["home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.lib.data.GoldDataset.get_claim", "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.lib.metrics.update_counts_abstract", "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.lib.metrics.update_counts_sentence", "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.lib.metrics.compute_f1", "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.lib.metrics.compute_f1", "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.lib.metrics.compute_f1", "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.lib.metrics.compute_f1"], ["def", "compute_metrics", "(", "preds", ")", ":", "\n", "    ", "\"\"\"\n    Compute pipeline metrics based on dataset of predictions.\n    \"\"\"", "\n", "counts_abstract", "=", "Counter", "(", ")", "\n", "counts_sentence", "=", "Counter", "(", ")", "\n", "\n", "# check_rationale_lengths(preds)", "\n", "\n", "for", "pred", "in", "preds", ":", "\n", "        ", "gold", "=", "preds", ".", "gold", ".", "get_claim", "(", "pred", ".", "claim_id", ")", "\n", "counts_abstract", "=", "update_counts_abstract", "(", "pred", ",", "gold", ",", "counts_abstract", ")", "\n", "counts_sentence", "=", "update_counts_sentence", "(", "pred", ",", "gold", ",", "counts_sentence", ")", "\n", "\n", "", "return", "pd", ".", "DataFrame", "(", "\n", "{", "\"sentence_selection\"", ":", "compute_f1", "(", "counts_sentence", ",", "\"selection\"", ")", ",", "\n", "\"sentence_label\"", ":", "compute_f1", "(", "counts_sentence", ",", "\"label\"", ")", ",", "\n", "\"abstract_label_only\"", ":", "compute_f1", "(", "counts_abstract", ",", "\"label_only\"", ")", ",", "\n", "\"abstract_rationalized\"", ":", "compute_f1", "(", "counts_abstract", ",", "\"rationalized\"", ")", "\n", "}", ")", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.evaluation.data.Document.__repr__": [[48, 50], ["data.Document.title.upper"], "methods", ["None"], ["def", "__repr__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "title", ".", "upper", "(", ")", "+", "\"\\n\"", "+", "\"\\n\"", ".", "join", "(", "[", "\"- \"", "+", "entry", "for", "entry", "in", "self", ".", "sentences", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.evaluation.data.Document.__lt__": [[51, 53], ["data.Document.title.__lt__"], "methods", ["home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.lib.data.Document.__lt__"], ["", "def", "__lt__", "(", "self", ",", "other", ")", ":", "\n", "        ", "return", "self", ".", "title", ".", "__lt__", "(", "other", ".", "title", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.evaluation.data.Document.dump": [[54, 60], ["json.dumps", "data.Document.is_structured"], "methods", ["None"], ["", "def", "dump", "(", "self", ")", ":", "\n", "        ", "res", "=", "{", "\"doc_id\"", ":", "self", ".", "id", ",", "\n", "\"title\"", ":", "self", ".", "title", ",", "\n", "\"abstract\"", ":", "self", ".", "sentences", ",", "\n", "\"structured\"", ":", "self", ".", "is_structured", "(", ")", "}", "\n", "return", "json", ".", "dumps", "(", "res", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.evaluation.data.Corpus.__repr__": [[70, 72], ["len"], "methods", ["None"], ["def", "__repr__", "(", "self", ")", ":", "\n", "        ", "return", "f\"Corpus of {len(self.documents)} documents.\"", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.evaluation.data.Corpus.__getitem__": [[73, 76], ["None"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "i", ")", ":", "\n", "        ", "\"Get document by index in list.\"", "\n", "return", "self", ".", "documents", "[", "i", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.evaluation.data.Corpus.get_document": [[77, 82], ["len"], "methods", ["None"], ["", "def", "get_document", "(", "self", ",", "doc_id", ")", ":", "\n", "        ", "\"Get document by ID.\"", "\n", "res", "=", "[", "x", "for", "x", "in", "self", ".", "documents", "if", "x", ".", "id", "==", "doc_id", "]", "\n", "assert", "len", "(", "res", ")", "==", "1", "\n", "return", "res", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.evaluation.data.Corpus.from_jsonl": [[83, 92], ["data.load_jsonl", "cls", "data.Document", "documents.append"], "methods", ["home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.lib.data.load_jsonl"], ["", "@", "classmethod", "\n", "def", "from_jsonl", "(", "cls", ",", "corpus_file", ")", ":", "\n", "        ", "corpus", "=", "load_jsonl", "(", "corpus_file", ")", "\n", "documents", "=", "[", "]", "\n", "for", "entry", "in", "corpus", ":", "\n", "            ", "doc", "=", "Document", "(", "entry", "[", "\"doc_id\"", "]", ",", "entry", "[", "\"title\"", "]", ",", "entry", "[", "\"abstract\"", "]", ")", "\n", "documents", ".", "append", "(", "doc", ")", "\n", "\n", "", "return", "cls", "(", "documents", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.evaluation.data.GoldDataset.__init__": [[102, 105], ["data.Corpus.from_jsonl", "data.GoldDataset._read_claims"], "methods", ["home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.lib.data.Corpus.from_jsonl", "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.lib.data.GoldDataset._read_claims"], ["def", "__init__", "(", "self", ",", "corpus_file", ",", "data_file", ")", ":", "\n", "        ", "self", ".", "corpus", "=", "Corpus", ".", "from_jsonl", "(", "corpus_file", ")", "\n", "self", ".", "claims", "=", "self", ".", "_read_claims", "(", "data_file", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.evaluation.data.GoldDataset.__repr__": [[106, 109], ["data.GoldDataset.corpus.__repr__", "len"], "methods", ["home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.lib.data.ClaimPredictions.__repr__"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "msg", "=", "f\"{self.corpus.__repr__()} {len(self.claims)} claims.\"", "\n", "return", "msg", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.evaluation.data.GoldDataset.__getitem__": [[110, 112], ["None"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "i", ")", ":", "\n", "        ", "return", "self", ".", "claims", "[", "i", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.evaluation.data.GoldDataset._read_claims": [[113, 130], ["data.load_jsonl", "sorted", "copy.deepcopy", "sorted.append", "data.GoldDataset.corpus.get_document", "len", "len", "data.Claim"], "methods", ["home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.lib.data.load_jsonl", "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.lib.data.Corpus.get_document"], ["", "def", "_read_claims", "(", "self", ",", "data_file", ")", ":", "\n", "        ", "\"Read claims from file.\"", "\n", "examples", "=", "load_jsonl", "(", "data_file", ")", "\n", "res", "=", "[", "]", "\n", "for", "this_example", "in", "examples", ":", "\n", "            ", "entry", "=", "copy", ".", "deepcopy", "(", "this_example", ")", "\n", "entry", "[", "\"release\"", "]", "=", "self", "\n", "entry", "[", "\"cited_docs\"", "]", "=", "[", "self", ".", "corpus", ".", "get_document", "(", "doc", ")", "\n", "for", "doc", "in", "entry", "[", "\"cited_doc_ids\"", "]", "]", "\n", "assert", "len", "(", "entry", "[", "\"cited_docs\"", "]", ")", "==", "len", "(", "entry", "[", "\"cited_doc_ids\"", "]", ")", "\n", "del", "entry", "[", "\"cited_doc_ids\"", "]", "\n", "if", "'doc_ids'", "in", "entry", ":", "\n", "                ", "del", "entry", "[", "'doc_ids'", "]", "\n", "", "res", ".", "append", "(", "Claim", "(", "**", "entry", ")", ")", "\n", "\n", "", "res", "=", "sorted", "(", "res", ",", "key", "=", "lambda", "x", ":", "x", ".", "id", ")", "\n", "return", "res", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.evaluation.data.GoldDataset.get_claim": [[131, 136], ["len"], "methods", ["None"], ["", "def", "get_claim", "(", "self", ",", "example_id", ")", ":", "\n", "        ", "\"Get a single claim by ID.\"", "\n", "keep", "=", "[", "x", "for", "x", "in", "self", ".", "claims", "if", "x", ".", "id", "==", "example_id", "]", "\n", "assert", "len", "(", "keep", ")", "==", "1", "\n", "return", "keep", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.evaluation.data.Claim.__post_init__": [[157, 159], ["data.Claim._format_evidence"], "methods", ["home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.lib.data.Claim._format_evidence"], ["def", "__post_init__", "(", "self", ")", ":", "\n", "        ", "self", ".", "evidence", "=", "self", ".", "_format_evidence", "(", "self", ".", "evidence", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.evaluation.data.Claim._format_evidence": [[160, 181], ["evidence_dict.items", "int", "data.make_label", "data.EvidenceAbstract", "len", "Exception", "set"], "methods", ["home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.lib.data.make_label"], ["", "@", "staticmethod", "\n", "def", "_format_evidence", "(", "evidence_dict", ")", ":", "\n", "# This function is needed because the data schema is designed so that", "\n", "# each rationale can have its own support label. But, in the dataset,", "\n", "# all rationales for a given claim / abstract pair all have the same", "\n", "# label. So, we store the label at the \"abstract level\" rather than the", "\n", "# \"rationale level\".", "\n", "        ", "res", "=", "{", "}", "\n", "for", "doc_id", ",", "rationales", "in", "evidence_dict", ".", "items", "(", ")", ":", "\n", "            ", "doc_id", "=", "int", "(", "doc_id", ")", "\n", "labels", "=", "[", "x", "[", "\"label\"", "]", "for", "x", "in", "rationales", "]", "\n", "if", "len", "(", "set", "(", "labels", ")", ")", ">", "1", ":", "\n", "                ", "msg", "=", "(", "\"In this SciFact release, each claim / abstract pair \"", "\n", "\"should only have one label.\"", ")", "\n", "raise", "Exception", "(", "msg", ")", "\n", "", "label", "=", "make_label", "(", "labels", "[", "0", "]", ")", "\n", "rationale_sents", "=", "[", "x", "[", "\"sentences\"", "]", "for", "x", "in", "rationales", "]", "\n", "this_abstract", "=", "EvidenceAbstract", "(", "doc_id", ",", "label", ",", "rationale_sents", ")", "\n", "res", "[", "doc_id", "]", "=", "this_abstract", "\n", "\n", "", "return", "res", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.evaluation.data.Claim.__repr__": [[182, 185], ["None"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "msg", "=", "f\"Example {self.id}: {self.claim}\"", "\n", "return", "msg", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.evaluation.data.Claim.pretty_print": [[186, 204], ["data.Claim.__repr__", "print", "print", "data.Claim.evidence.items", "print", "data.Claim.release.corpus.get_document", "print", "enumerate", "print", "print", "enumerate"], "methods", ["home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.lib.data.ClaimPredictions.__repr__", "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.lib.data.Corpus.get_document"], ["", "def", "pretty_print", "(", "self", ",", "evidence_doc_id", "=", "None", ",", "file", "=", "None", ")", ":", "\n", "        ", "\"Pretty-print the claim, together with all evidence.\"", "\n", "msg", "=", "self", ".", "__repr__", "(", ")", "\n", "print", "(", "msg", ",", "file", "=", "file", ")", "\n", "# Print the evidence", "\n", "print", "(", "\"\\nEvidence sets:\"", ",", "file", "=", "file", ")", "\n", "for", "doc_id", ",", "evidence", "in", "self", ".", "evidence", ".", "items", "(", ")", ":", "\n", "# If asked for a specific evidence doc, only show that one.", "\n", "            ", "if", "evidence_doc_id", "is", "not", "None", "and", "doc_id", "!=", "evidence_doc_id", ":", "\n", "                ", "continue", "\n", "", "print", "(", "\"\\n\"", "+", "20", "*", "\"#\"", "+", "\"\\n\"", ",", "file", "=", "file", ")", "\n", "ev_doc", "=", "self", ".", "release", ".", "corpus", ".", "get_document", "(", "doc_id", ")", "\n", "print", "(", "f\"{doc_id}: {evidence.label.name}\"", ",", "file", "=", "file", ")", "\n", "for", "i", ",", "sents", "in", "enumerate", "(", "evidence", ".", "rationales", ")", ":", "\n", "                ", "print", "(", "f\"Set {i}:\"", ",", "file", "=", "file", ")", "\n", "kept", "=", "[", "sent", "for", "i", ",", "sent", "in", "enumerate", "(", "ev_doc", ".", "sentences", ")", "if", "i", "in", "sents", "]", "\n", "for", "entry", "in", "kept", ":", "\n", "                    ", "print", "(", "f\"\\t- {entry}\"", ",", "file", "=", "file", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.evaluation.data.PredictedDataset.__init__": [[214, 221], ["data.PredictedDataset._read_predictions"], "methods", ["home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.lib.data.PredictedDataset._read_predictions"], ["def", "__init__", "(", "self", ",", "gold", ",", "prediction_file", ")", ":", "\n", "        ", "\"\"\"\n        Takes a GoldDataset, as well as files with rationale and label\n        predictions.\n        \"\"\"", "\n", "self", ".", "gold", "=", "gold", "\n", "self", ".", "predictions", "=", "self", ".", "_read_predictions", "(", "prediction_file", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.evaluation.data.PredictedDataset.__getitem__": [[222, 224], ["None"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "i", ")", ":", "\n", "        ", "return", "self", ".", "predictions", "[", "i", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.evaluation.data.PredictedDataset.__repr__": [[225, 228], ["len"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "msg", "=", "f\"Predictions for {len(self.predictions)} claims.\"", "\n", "return", "msg", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.evaluation.data.PredictedDataset._read_predictions": [[229, 238], ["data.load_jsonl", "data.PredictedDataset._parse_prediction", "res.append"], "methods", ["home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.lib.data.load_jsonl", "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.lib.data.PredictedDataset._parse_prediction"], ["", "def", "_read_predictions", "(", "self", ",", "prediction_file", ")", ":", "\n", "        ", "res", "=", "[", "]", "\n", "\n", "predictions", "=", "load_jsonl", "(", "prediction_file", ")", "\n", "for", "pred", "in", "predictions", ":", "\n", "            ", "prediction", "=", "self", ".", "_parse_prediction", "(", "pred", ")", "\n", "res", ".", "append", "(", "prediction", ")", "\n", "\n", "", "return", "res", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.evaluation.data.PredictedDataset._parse_prediction": [[239, 257], ["predicted_evidence.items", "data.PredictedDataset.gold.get_claim", "data.ClaimPredictions", "data.PredictedAbstract", "int", "data.make_label", "int"], "methods", ["home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.lib.data.GoldDataset.get_claim", "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.lib.data.make_label"], ["", "def", "_parse_prediction", "(", "self", ",", "pred_dict", ")", ":", "\n", "        ", "claim_id", "=", "pred_dict", "[", "\"id\"", "]", "\n", "predicted_evidence", "=", "pred_dict", "[", "\"evidence\"", "]", "\n", "\n", "res", "=", "{", "}", "\n", "\n", "# Predictions should never be NEI; there should only be predictions for", "\n", "# the abstracts that contain evidence.", "\n", "for", "key", ",", "this_prediction", "in", "predicted_evidence", ".", "items", "(", ")", ":", "\n", "            ", "label", "=", "this_prediction", "[", "\"label\"", "]", "\n", "evidence", "=", "this_prediction", "[", "\"sentences\"", "]", "\n", "pred", "=", "PredictedAbstract", "(", "int", "(", "key", ")", ",", "\n", "make_label", "(", "label", ",", "allow_NEI", "=", "False", ")", ",", "\n", "evidence", ")", "\n", "res", "[", "int", "(", "key", ")", "]", "=", "pred", "\n", "\n", "", "gold_claim", "=", "self", ".", "gold", ".", "get_claim", "(", "claim_id", ")", "\n", "return", "ClaimPredictions", "(", "claim_id", ",", "res", ",", "gold_claim", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.evaluation.data.ClaimPredictions.__repr__": [[274, 277], ["None"], "methods", ["None"], ["def", "__repr__", "(", "self", ")", ":", "\n", "        ", "msg", "=", "f\"Predictions for {self.claim_id}: {self.gold.claim}\"", "\n", "return", "msg", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.evaluation.data.ClaimPredictions.pretty_print": [[278, 295], ["data.ClaimPredictions.__repr__", "print", "print", "data.ClaimPredictions.predictions.items", "print", "data.ClaimPredictions.gold.release.corpus.get_document", "print", "print", "enumerate"], "methods", ["home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.lib.data.ClaimPredictions.__repr__", "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.lib.data.Corpus.get_document"], ["", "def", "pretty_print", "(", "self", ",", "evidence_doc_id", "=", "None", ",", "file", "=", "None", ")", ":", "\n", "        ", "msg", "=", "self", ".", "__repr__", "(", ")", "\n", "print", "(", "msg", ",", "file", "=", "file", ")", "\n", "# Print the evidence", "\n", "print", "(", "\"\\nEvidence sets:\"", ",", "file", "=", "file", ")", "\n", "for", "doc_id", ",", "prediction", "in", "self", ".", "predictions", ".", "items", "(", ")", ":", "\n", "# If asked for a specific evidence doc, only show that one.", "\n", "            ", "if", "evidence_doc_id", "is", "not", "None", "and", "doc_id", "!=", "evidence_doc_id", ":", "\n", "                ", "continue", "\n", "", "print", "(", "\"\\n\"", "+", "20", "*", "\"#\"", "+", "\"\\n\"", ",", "file", "=", "file", ")", "\n", "ev_doc", "=", "self", ".", "gold", ".", "release", ".", "corpus", ".", "get_document", "(", "doc_id", ")", "\n", "print", "(", "f\"{doc_id}: {prediction.label.name}\"", ",", "file", "=", "file", ")", "\n", "# Print the predicted rationale.", "\n", "sents", "=", "prediction", ".", "rationale", "\n", "kept", "=", "[", "sent", "for", "i", ",", "sent", "in", "enumerate", "(", "ev_doc", ".", "sentences", ")", "if", "i", "in", "sents", "]", "\n", "for", "entry", "in", "kept", ":", "\n", "                ", "print", "(", "f\"\\t- {entry}\"", ",", "file", "=", "file", ")", "\n", "", "", "", "", ""]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.evaluation.data.load_jsonl": [[16, 18], ["json.loads", "open"], "function", ["None"], ["def", "load_jsonl", "(", "fname", ")", ":", "\n", "    ", "return", "[", "json", ".", "loads", "(", "line", ")", "for", "line", "in", "open", "(", "fname", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.evaluation.data.make_label": [[26, 36], ["ValueError"], "function", ["None"], ["", "def", "make_label", "(", "label_str", ",", "allow_NEI", "=", "True", ")", ":", "\n", "    ", "lookup", "=", "{", "\"SUPPORT\"", ":", "Label", ".", "SUPPORTS", ",", "\n", "\"NOT_ENOUGH_INFO\"", ":", "Label", ".", "NEI", ",", "\n", "\"CONTRADICT\"", ":", "Label", ".", "REFUTES", "}", "\n", "\n", "res", "=", "lookup", "[", "label_str", "]", "\n", "if", "(", "not", "allow_NEI", ")", "and", "(", "res", "is", "Label", ".", "NEI", ")", ":", "\n", "        ", "raise", "ValueError", "(", "\"An NEI was given.\"", ")", "\n", "\n", "", "return", "res", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.evaluation.evaluation_model.is_correct": [[16, 31], ["all"], "function", ["None"], ["def", "is_correct", "(", "pred_sentence", ",", "pred_sentences", ",", "gold_sets", ")", ":", "\n", "    ", "\"\"\"\n    A predicted sentence is correctly identified if it is part of a gold\n    rationale, and all other sentences in the gold rationale are also\n    predicted rationale sentences.\n    \"\"\"", "\n", "for", "gold_set", "in", "gold_sets", ":", "\n", "        ", "gold_sents", "=", "gold_set", "[", "\"sentences\"", "]", "\n", "if", "pred_sentence", "in", "gold_sents", ":", "\n", "            ", "if", "all", "(", "[", "x", "in", "pred_sentences", "for", "x", "in", "gold_sents", "]", ")", ":", "\n", "                ", "return", "True", "\n", "", "else", ":", "\n", "                ", "return", "False", "\n", "\n", "", "", "", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.evaluation.evaluation_model.evaluate_rationale_selection": [[33, 64], ["dataset.loader_json", "dataset.loader_json", "collections.Counter", "zip", "evaluation.metrics.compute_f1", "print", "print", "print", "print", "data[].items", "retrieval[].items", "len", "data[].get", "evaluation_model.is_correct", "round", "round", "round"], "function", ["home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.dataset.loader.loader_json", "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.dataset.loader.loader_json", "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.lib.metrics.compute_f1", "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.lib.metrics.is_correct"], ["", "def", "evaluate_rationale_selection", "(", "args", ",", "rationale_results", ")", ":", "\n", "    ", "'''\n    # ================================================================================================================ #\n    # evaluate rationale selection results.\n    # ================================================================================================================ #\n    '''", "\n", "evaluation_set", "=", "args", ".", "claim_test_path", "\n", "dataset", "=", "loader", ".", "loader_json", "(", "evaluation_set", ")", "\n", "rationale_results", "=", "loader", ".", "loader_json", "(", "rationale_results", ")", "\n", "counts", "=", "Counter", "(", ")", "\n", "for", "data", ",", "retrieval", "in", "zip", "(", "dataset", ",", "rationale_results", ")", ":", "\n", "        ", "assert", "data", "[", "'id'", "]", "==", "retrieval", "[", "'claim_id'", "]", "\n", "\n", "# Count all the gold evidence sentences.", "\n", "for", "doc_key", ",", "gold_rationales", "in", "data", "[", "\"evidence\"", "]", ".", "items", "(", ")", ":", "\n", "            ", "for", "entry", "in", "gold_rationales", ":", "\n", "                ", "counts", "[", "\"relevant\"", "]", "+=", "len", "(", "entry", "[", "\"sentences\"", "]", ")", "\n", "\n", "", "", "for", "doc_id", ",", "pred_sentences", "in", "retrieval", "[", "'evidence'", "]", ".", "items", "(", ")", ":", "\n", "            ", "true_evidence_sets", "=", "data", "[", "'evidence'", "]", ".", "get", "(", "doc_id", ")", "or", "[", "]", "\n", "\n", "for", "pred_sentence", "in", "pred_sentences", ":", "\n", "                ", "counts", "[", "\"retrieved\"", "]", "+=", "1", "\n", "if", "is_correct", "(", "pred_sentence", ",", "pred_sentences", ",", "true_evidence_sets", ")", ":", "\n", "                    ", "counts", "[", "\"correct\"", "]", "+=", "1", "\n", "\n", "", "", "", "", "rationale_metrics", "=", "compute_f1", "(", "counts", ")", "\n", "print", "(", "f'F1:                {round(rationale_metrics[\"f1\"], 4)}'", ")", "\n", "print", "(", "f'Precision:         {round(rationale_metrics[\"precision\"], 4)}'", ")", "\n", "print", "(", "f'Recall:            {round(rationale_metrics[\"recall\"], 4)}'", ")", "\n", "print", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.evaluation.evaluation_model.evaluate_label_predictions": [[66, 116], ["dataset.get_corpus", "dataset.loader_json", "dataset.loader_json", "zip", "print", "print", "print", "print", "print", "print", "print", "print", "print", "print", "print", "print", "prediction[].items", "sklearn.metrics.confusion_matrix", "pred_labels.append", "true_labels.append", "len", "next", "round", "sklearn.metrics.f1_score().round", "sklearn.metrics.f1_score().round", "sklearn.metrics.f1_score().round", "sklearn.metrics.precision_score().round", "sklearn.metrics.recall_score().round", "prediction[].items", "iter", "data[].get", "sum", "len", "sklearn.metrics.f1_score", "sklearn.metrics.f1_score", "sklearn.metrics.f1_score", "sklearn.metrics.precision_score", "sklearn.metrics.recall_score", "int", "range", "len"], "function", ["home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.dataset.loader.get_corpus", "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.dataset.loader.loader_json", "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.dataset.loader.loader_json"], ["", "def", "evaluate_label_predictions", "(", "args", ",", "label_results", ")", ":", "\n", "    ", "'''\n    # ================================================================================================================ #\n    # evaluate label predictions results.\n    # ================================================================================================================ #\n    '''", "\n", "evaluation_set", "=", "args", ".", "claim_test_path", "\n", "# evaluation", "\n", "corpus", "=", "loader", ".", "get_corpus", "(", "args", ".", "corpus_path", ")", "\n", "dataset", "=", "loader", ".", "loader_json", "(", "evaluation_set", ")", "\n", "label_results", "=", "loader", ".", "loader_json", "(", "label_results", ")", "\n", "pred_labels", "=", "[", "]", "\n", "true_labels", "=", "[", "]", "\n", "\n", "# LABELS = {'CONTRADICT': 0, 'NOT_ENOUGH_INFO': 1, 'SUPPORT': 2}", "\n", "LABELS", "=", "{", "'NOT_ENOUGH_INFO'", ":", "0", ",", "'CONTRADICT'", ":", "1", ",", "'SUPPORT'", ":", "2", "}", "\n", "\n", "for", "data", ",", "prediction", "in", "zip", "(", "dataset", ",", "label_results", ")", ":", "\n", "        ", "assert", "data", "[", "'id'", "]", "==", "prediction", "[", "'claim_id'", "]", "\n", "\n", "if", "args", ".", "filter", ":", "\n", "            ", "prediction", "[", "'labels'", "]", "=", "{", "doc_id", ":", "pred", "for", "doc_id", ",", "pred", "in", "prediction", "[", "'labels'", "]", ".", "items", "(", ")", "\n", "if", "corpus", "[", "int", "(", "doc_id", ")", "]", "[", "'structured'", "]", "is", "(", "args", ".", "filter", "==", "'structured'", ")", "}", "\n", "", "if", "not", "prediction", "[", "'labels'", "]", ":", "\n", "            ", "continue", "\n", "\n", "# claim_id = data['id']", "\n", "", "for", "doc_id", ",", "pred", "in", "prediction", "[", "'labels'", "]", ".", "items", "(", ")", ":", "\n", "            ", "pred_label", "=", "pred", "[", "'label'", "]", "\n", "true_label", "=", "{", "es", "[", "'label'", "]", "for", "es", "in", "data", "[", "'evidence'", "]", ".", "get", "(", "doc_id", ")", "or", "[", "]", "}", "\n", "assert", "len", "(", "true_label", ")", "<=", "1", ",", "'Currently support only one label per doc'", "\n", "true_label", "=", "next", "(", "iter", "(", "true_label", ")", ")", "if", "true_label", "else", "'NOT_ENOUGH_INFO'", "\n", "pred_labels", ".", "append", "(", "LABELS", "[", "pred_label", "]", ")", "\n", "true_labels", ".", "append", "(", "LABELS", "[", "true_label", "]", ")", "\n", "# sentence_labels = [0, 1, 2] if include_nei else [0, 2]", "\n", "", "", "print", "(", "\n", "f'Accuracy           '", "\n", "f'{round(sum([pred_labels[i] == true_labels[i] for i in range(len(pred_labels))]) / len(pred_labels), 4)}'", ")", "\n", "print", "(", "f'Macro F1:          {f1_score(true_labels, pred_labels, average=\"macro\").round(4)}'", ")", "\n", "print", "(", "f'Macro F1 w/o NEI:  {f1_score(true_labels, pred_labels, average=\"macro\", labels=[0, 2]).round(4)}'", ")", "\n", "print", "(", ")", "\n", "print", "(", "'                   [N      C      S     ]'", ")", "# C: CONTRADICT; N: NOT_ENOUGH_INFO; S: SUPPORT", "\n", "# print('                   [C      S     ]')", "\n", "print", "(", "f'F1:                {f1_score(true_labels, pred_labels, average=None, labels=[0, 1, 2]).round(4)}'", ")", "\n", "print", "(", "f'Precision:         {precision_score(true_labels, pred_labels, average=None, labels=[0, 1, 2]).round(4)}'", ")", "\n", "print", "(", "f'Recall:            {recall_score(true_labels, pred_labels, average=None, labels=[0, 1, 2]).round(4)}'", ")", "\n", "print", "(", ")", "\n", "print", "(", "'Confusion Matrix:'", ")", "\n", "print", "(", "confusion_matrix", "(", "true_labels", ",", "pred_labels", ")", ")", "\n", "print", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.evaluation.evaluation_model.merge_rationale_label": [[118, 150], ["print", "dataset.utils.merge", "np.set_printoptions", "pd.set_option", "pd.set_option", "pd.set_option", "evaluation.data.GoldDataset", "evaluation.data.PredictedDataset", "evaluation.metrics.compute_metrics", "print", "print", "open", "json.dump", "evaluation.metrics.compute_metrics.to_dict"], "function", ["home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.dataset.utils.merge", "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.lib.metrics.compute_metrics", "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.lib.data.Document.dump"], ["", "def", "merge_rationale_label", "(", "rationale_results", ",", "label_results", ",", "args", ",", "state", "=", "'valid'", ",", "gold", "=", "''", ")", ":", "\n", "    ", "'''\n    # ================================================================================================================ #\n    # merge rationale and label predictions and abstract retrieval results.\n    # evaluate final predictions.\n    # ================================================================================================================ #\n    '''", "\n", "print", "(", "'evaluate final predictions result...'", ")", "\n", "res", "=", "merge", "(", "rationale_results", ",", "label_results", ",", "args", ".", "merge_results", ")", "\n", "# merge_retrieval(res, abstract_results, args.merge_results)", "\n", "# merge_json(rationale_results, label_results, args.merge_results)", "\n", "\n", "if", "state", "==", "'valid'", ":", "\n", "        ", "import", "pandas", "as", "pd", "\n", "import", "numpy", "as", "np", "\n", "np", ".", "set_printoptions", "(", "threshold", "=", "np", ".", "inf", ")", "\n", "\n", "pd", ".", "set_option", "(", "'display.width'", ",", "300", ")", "# \u8bbe\u7f6e\u5b57\u7b26\u663e\u793a\u5bbd\u5ea6", "\n", "pd", ".", "set_option", "(", "'display.max_rows'", ",", "None", ")", "# \u8bbe\u7f6e\u663e\u793a\u6700\u5927\u884c", "\n", "pd", ".", "set_option", "(", "'display.max_columns'", ",", "None", ")", "# \u8bbe\u7f6e\u663e\u793a\u6700\u5927\u5217\uff0cNone\u4e3a\u663e\u793a\u6240\u6709\u5217", "\n", "\n", "data", "=", "GoldDataset", "(", "args", ".", "corpus_path", ",", "gold", ")", "\n", "predictions", "=", "PredictedDataset", "(", "data", ",", "args", ".", "merge_results", ")", "\n", "res", "=", "compute_metrics", "(", "predictions", ")", "\n", "if", "args", ".", "output", "is", "not", "None", ":", "\n", "            ", "with", "open", "(", "args", ".", "output", ",", "\"w\"", ")", "as", "f", ":", "\n", "                ", "json", ".", "dump", "(", "res", ".", "to_dict", "(", ")", ",", "f", ",", "indent", "=", "2", ")", "\n", "", "", "print", "(", "res", ")", "\n", "return", "res", "\n", "", "else", ":", "\n", "        ", "print", "(", "''", ")", "\n", "return", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.evaluation.evaluation_model.evaluation_joint": [[152, 210], ["model.eval", "torch.device", "torch.no_grad", "tqdm.tqdm", "enumerate", "torch.cuda.is_available", "torch.utils.data.DataLoader", "dataset.encode.encode_paragraph", "utils.token_idx_by_sentence", "utils.get_rationale_label", "model", "abstract_targets.extend", "abstract_outputs.extend", "rationale_targets.extend", "rationale_output.extend", "sklearn.metrics.f1_score", "sklearn.metrics.precision_score", "sklearn.metrics.recall_score", "tensor.to", "tensor.to", "sklearn.metrics.f1_score", "sklearn.metrics.precision_score", "sklearn.metrics.recall_score", "dataset.encode.encode_paragraph.items", "utils.flatten", "utils.flatten", "utils.flatten", "utils.flatten", "utils.flatten", "utils.flatten", "sklearn.metrics.f1_score", "sklearn.metrics.precision_score", "sklearn.metrics.recall_score", "sklearn.metrics.f1_score", "sklearn.metrics.precision_score", "sklearn.metrics.recall_score", "utils.flatten", "utils.flatten", "utils.flatten", "utils.flatten", "utils.flatten", "utils.flatten"], "function", ["home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.dataset.encode.encode_paragraph", "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.FEVER_stance_paragraph.token_idx_by_sentence", "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.src.utils.get_rationale_label", "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.util.flatten", "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.util.flatten", "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.util.flatten", "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.util.flatten", "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.util.flatten", "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.util.flatten", "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.util.flatten", "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.util.flatten", "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.util.flatten", "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.util.flatten", "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.util.flatten", "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.util.flatten"], ["", "", "def", "evaluation_joint", "(", "model", ",", "dataset", ",", "args", ",", "tokenizer", ",", "mode", "=", "'rationale&label'", ")", ":", "\n", "    ", "model", ".", "eval", "(", ")", "\n", "abstract_targets", "=", "[", "]", "\n", "rationale_targets", "=", "[", "]", "\n", "abstract_outputs", "=", "[", "]", "\n", "rationale_output", "=", "[", "]", "\n", "device", "=", "torch", ".", "device", "(", "'cuda'", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "else", "'cpu'", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "t", "=", "tqdm", "(", "DataLoader", "(", "dataset", ",", "batch_size", "=", "args", ".", "batch_size_gpu", ",", "shuffle", "=", "False", ")", ")", "\n", "for", "i", ",", "batch", "in", "enumerate", "(", "t", ")", ":", "\n", "            ", "encoded_dict", "=", "encode_paragraph", "(", "tokenizer", ",", "batch", "[", "'claim'", "]", ",", "batch", "[", "'abstract'", "]", ")", "\n", "# encoded = encode_paragraph(tokenizer, batch['claim'], batch['paragraph'])", "\n", "# encoded = {key: tensor.to(device) for key, tensor in encoded.items()}", "\n", "transformation_indices", "=", "token_idx_by_sentence", "(", "encoded_dict", "[", "\"input_ids\"", "]", ",", "tokenizer", ".", "sep_token_id", ",", "\n", "args", ".", "model", ")", "\n", "# match_indices = token_idx_by_sentence(encoded_dict[\"input_ids\"], tokenizer.sep_token_id,", "\n", "#                                       args.model, match=True)", "\n", "encoded_dict", "=", "{", "key", ":", "tensor", ".", "to", "(", "device", ")", "for", "key", ",", "tensor", "in", "encoded_dict", ".", "items", "(", ")", "}", "\n", "transformation_indices", "=", "[", "tensor", ".", "to", "(", "device", ")", "for", "tensor", "in", "transformation_indices", "]", "\n", "# match_indices = [tensor.to(device) for tensor in match_indices]", "\n", "padded_label", ",", "rationale_label", "=", "get_rationale_label", "(", "batch", "[", "\"sentence_label\"", "]", ",", "padding_idx", "=", "2", ")", "\n", "abstract_out", ",", "rationale_out", ",", "retrieval_out", "=", "model", "(", "encoded_dict", ",", "transformation_indices", ")", "\n", "# loss = abstract_loss + rationale_loss + retrieval_loss", "\n", "# if (i + 1) % (args.batch_size_accumulated // args.batch_size_gpu) == 0:", "\n", "#     t.set_description(f'iter {i}, loss: {round(loss.item(), 4)},'", "\n", "#                       f' abstract loss: {round(abstract_loss.item(), 4)},'", "\n", "#                       f' rationale loss: {round(rationale_loss.item(), 4)},'", "\n", "#                       f' retrieval loss: {round(retrieval_loss.item(), 4)}')", "\n", "# abstract_out = torch.argmax(abstract_score.cpu(), dim=-1).detach().numpy().tolist()", "\n", "# rationale_out = torch.argmax(rationale_score.cpu(), dim=-1).detach().numpy().tolist()", "\n", "\n", "abstract_targets", ".", "extend", "(", "batch", "[", "'abstract_label'", "]", ")", "\n", "abstract_outputs", ".", "extend", "(", "abstract_out", ")", "\n", "\n", "rationale_targets", ".", "extend", "(", "rationale_label", ")", "\n", "rationale_output", ".", "extend", "(", "rationale_out", ")", "\n", "", "", "if", "mode", "==", "'label'", ":", "\n", "        ", "return", "{", "\n", "'f1'", ":", "f1_score", "(", "abstract_targets", ",", "abstract_outputs", ",", "zero_division", "=", "0", ",", "average", "=", "'micro'", ",", "labels", "=", "[", "1", ",", "2", "]", ")", ",", "\n", "'p'", ":", "precision_score", "(", "abstract_targets", ",", "abstract_outputs", ",", "zero_division", "=", "0", ",", "average", "=", "'micro'", ",", "labels", "=", "[", "1", ",", "2", "]", ")", ",", "\n", "'r'", ":", "recall_score", "(", "abstract_targets", ",", "abstract_outputs", ",", "zero_division", "=", "0", ",", "average", "=", "'micro'", ",", "labels", "=", "[", "1", ",", "2", "]", ")", ",", "\n", "}", "\n", "", "elif", "mode", "==", "'rationale'", ":", "\n", "        ", "return", "{", "\n", "'f1'", ":", "f1_score", "(", "flatten", "(", "rationale_targets", ")", ",", "flatten", "(", "rationale_output", ")", ",", "zero_division", "=", "0", ")", ",", "\n", "'p'", ":", "precision_score", "(", "flatten", "(", "rationale_targets", ")", ",", "flatten", "(", "rationale_output", ")", ",", "zero_division", "=", "0", ")", ",", "\n", "'r'", ":", "recall_score", "(", "flatten", "(", "rationale_targets", ")", ",", "flatten", "(", "rationale_output", ")", ",", "zero_division", "=", "0", ")", "\n", "}", "\n", "", "else", ":", "\n", "        ", "return", "{", "\n", "'f1'", ":", "f1_score", "(", "abstract_targets", ",", "abstract_outputs", ",", "zero_division", "=", "0", ",", "average", "=", "'micro'", ",", "labels", "=", "[", "1", ",", "2", "]", ")", ",", "\n", "# 'abstract_f1': tuple(f1_score(abstract_targets, abstract_outputs, zero_division=0, average=None)),", "\n", "'p'", ":", "precision_score", "(", "abstract_targets", ",", "abstract_outputs", ",", "zero_division", "=", "0", ",", "average", "=", "'micro'", ",", "labels", "=", "[", "1", ",", "2", "]", ")", ",", "\n", "'r'", ":", "recall_score", "(", "abstract_targets", ",", "abstract_outputs", ",", "zero_division", "=", "0", ",", "average", "=", "'micro'", ",", "labels", "=", "[", "1", ",", "2", "]", ")", ",", "\n", "}", ",", "{", "\n", "'f1'", ":", "f1_score", "(", "flatten", "(", "rationale_targets", ")", ",", "flatten", "(", "rationale_output", ")", ",", "zero_division", "=", "0", ")", ",", "\n", "'p'", ":", "precision_score", "(", "flatten", "(", "rationale_targets", ")", ",", "flatten", "(", "rationale_output", ")", ",", "zero_division", "=", "0", ")", ",", "\n", "'r'", ":", "recall_score", "(", "flatten", "(", "rationale_targets", ")", ",", "flatten", "(", "rationale_output", ")", ",", "zero_division", "=", "0", ")", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.evaluation.evaluation_model.evaluation_abstract_retrieval": [[213, 242], ["model.eval", "torch.device", "torch.no_grad", "tqdm.tqdm", "sklearn.metrics.f1_score", "tuple", "sklearn.metrics.precision_score", "sklearn.metrics.recall_score", "torch.cuda.is_available", "torch.utils.data.DataLoader", "dataset.encode.encode_paragraph", "utils.token_idx_by_sentence", "model", "abstract_targets.extend", "abstract_outputs.extend", "sklearn.metrics.f1_score", "tensor.to", "tensor.to", "dataset.encode.encode_paragraph.items", "batch[].to"], "function", ["home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.dataset.encode.encode_paragraph", "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.FEVER_stance_paragraph.token_idx_by_sentence"], ["", "", "def", "evaluation_abstract_retrieval", "(", "model", ",", "dataset", ",", "args", ",", "tokenizer", ")", ":", "\n", "    ", "model", ".", "eval", "(", ")", "\n", "abstract_targets", "=", "[", "]", "\n", "abstract_outputs", "=", "[", "]", "\n", "device", "=", "torch", ".", "device", "(", "'cuda'", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "else", "'cpu'", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "for", "batch", "in", "tqdm", "(", "DataLoader", "(", "dataset", ",", "batch_size", "=", "args", ".", "batch_size_gpu", ",", "shuffle", "=", "False", ")", ")", ":", "\n", "            ", "encoded_dict", "=", "encode_paragraph", "(", "tokenizer", ",", "batch", "[", "'claim'", "]", ",", "batch", "[", "'abstract'", "]", ")", "\n", "# encoded = encode_paragraph(tokenizer, batch['claim'], batch['paragraph'])", "\n", "# encoded = {key: tensor.to(device) for key, tensor in encoded.items()}", "\n", "transformation_indices", "=", "token_idx_by_sentence", "(", "encoded_dict", "[", "\"input_ids\"", "]", ",", "tokenizer", ".", "sep_token_id", ",", "\n", "args", ".", "model", ")", "\n", "# match_indices = token_idx_by_sentence(encoded_dict[\"input_ids\"], tokenizer.sep_token_id,", "\n", "#                                       args.model, match=True)", "\n", "encoded_dict", "=", "{", "key", ":", "tensor", ".", "to", "(", "device", ")", "for", "key", ",", "tensor", "in", "encoded_dict", ".", "items", "(", ")", "}", "\n", "transformation_indices", "=", "[", "tensor", ".", "to", "(", "device", ")", "for", "tensor", "in", "transformation_indices", "]", "\n", "# match_indices = [tensor.to(device) for tensor in match_indices]", "\n", "retrieval_out", ",", "_", "=", "model", "(", "encoded_dict", ",", "transformation_indices", ",", "\n", "retrieval_label", "=", "batch", "[", "'sim_label'", "]", ".", "to", "(", "device", ")", ",", "retrieval_only", "=", "True", ")", "\n", "# abstract_out = torch.argmax(abstract_score.cpu(), dim=-1).detach().numpy().tolist()", "\n", "# rationale_out = torch.argmax(rationale_score.cpu(), dim=-1).detach().numpy().tolist()", "\n", "\n", "abstract_targets", ".", "extend", "(", "batch", "[", "'sim_label'", "]", ")", "\n", "abstract_outputs", ".", "extend", "(", "retrieval_out", ")", "\n", "", "", "return", "{", "\n", "'abstract_micro_f1'", ":", "f1_score", "(", "abstract_targets", ",", "abstract_outputs", ",", "zero_division", "=", "0", ",", "average", "=", "'micro'", ")", ",", "\n", "'abstract_f1'", ":", "tuple", "(", "f1_score", "(", "abstract_targets", ",", "abstract_outputs", ",", "zero_division", "=", "0", ",", "average", "=", "None", ")", ")", ",", "\n", "'abstract_precision'", ":", "precision_score", "(", "abstract_targets", ",", "abstract_outputs", ",", "zero_division", "=", "0", ",", "average", "=", "'micro'", ")", ",", "\n", "'abstract_recall'", ":", "recall_score", "(", "abstract_targets", ",", "abstract_outputs", ",", "zero_division", "=", "0", ",", "average", "=", "'micro'", ")", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.ComputeBioSentVecAbstractEmbedding.preprocess_sentence": [[12, 22], ["text.lower.replace", "text.lower.replace", "text.lower.replace", "text.lower.replace", "text.lower.lower", "nltk.word_tokenize"], "function", ["None"], ["def", "preprocess_sentence", "(", "text", ")", ":", "\n", "    ", "text", "=", "text", ".", "replace", "(", "'/'", ",", "' / '", ")", "\n", "text", "=", "text", ".", "replace", "(", "'.-'", ",", "' .- '", ")", "\n", "text", "=", "text", ".", "replace", "(", "'.'", ",", "' . '", ")", "\n", "text", "=", "text", ".", "replace", "(", "'\\''", ",", "' \\' '", ")", "\n", "text", "=", "text", ".", "lower", "(", ")", "\n", "\n", "tokens", "=", "[", "token", "for", "token", "in", "word_tokenize", "(", "text", ")", "if", "token", "not", "in", "punctuation", "and", "token", "not", "in", "stop_words", "]", "\n", "\n", "return", "' '", ".", "join", "(", "tokens", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.domain_adaptation_joint_paragraph_kgat_prediction.reset_random_seed": [[33, 37], ["numpy.random.seed", "random.seed", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed"], "function", ["None"], ["def", "reset_random_seed", "(", "seed", ")", ":", "\n", "    ", "np", ".", "random", ".", "seed", "(", "seed", ")", "\n", "random", ".", "seed", "(", "seed", ")", "\n", "torch", ".", "manual_seed", "(", "seed", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.domain_adaptation_joint_paragraph_kgat_prediction.batch_rationale_label": [[38, 47], ["max", "enumerate", "torch.ones", "torch.ones", "torch.ones", "enumerate", "label_list.append", "label_matrix.long", "len", "len", "int", "int"], "function", ["None"], ["", "def", "batch_rationale_label", "(", "labels", ",", "padding_idx", "=", "2", ")", ":", "\n", "    ", "max_sent_len", "=", "max", "(", "[", "len", "(", "label", ")", "for", "label", "in", "labels", "]", ")", "\n", "label_matrix", "=", "torch", ".", "ones", "(", "len", "(", "labels", ")", ",", "max_sent_len", ")", "*", "padding_idx", "\n", "label_list", "=", "[", "]", "\n", "for", "i", ",", "label", "in", "enumerate", "(", "labels", ")", ":", "\n", "        ", "for", "j", ",", "evid", "in", "enumerate", "(", "label", ")", ":", "\n", "            ", "label_matrix", "[", "i", ",", "j", "]", "=", "int", "(", "evid", ")", "\n", "", "label_list", ".", "append", "(", "[", "int", "(", "evid", ")", "for", "evid", "in", "label", "]", ")", "\n", "", "return", "label_matrix", ".", "long", "(", ")", ",", "label_list", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.domain_adaptation_joint_paragraph_kgat_prediction.predict": [[48, 69], ["model.eval", "torch.no_grad", "torch.no_grad", "torch.no_grad", "tqdm.tqdm", "torch.utils.data.DataLoader", "domain_adaptation_joint_paragraph_kgat_prediction.encode", "domain_adaptation_joint_paragraph_kgat_prediction.token_idx_by_sentence", "batch[].to", "model", "stance_preds.extend", "rationale_predictions.extend", "tensor.to", "tensor.to", "domain_adaptation_joint_paragraph_kgat_prediction.predict.remove_dummy"], "function", ["home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.label_prediction.transformer_scifact.encode", "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.FEVER_stance_paragraph.token_idx_by_sentence", "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.src.utils.remove_dummy"], ["", "def", "predict", "(", "model", ",", "dataset", ")", ":", "\n", "    ", "model", ".", "eval", "(", ")", "\n", "rationale_predictions", "=", "[", "]", "\n", "stance_preds", "=", "[", "]", "\n", "\n", "def", "remove_dummy", "(", "rationale_out", ")", ":", "\n", "        ", "return", "[", "out", "[", "1", ":", "]", "for", "out", "in", "rationale_out", "]", "\n", "\n", "", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "for", "batch", "in", "tqdm", "(", "DataLoader", "(", "dataset", ",", "batch_size", "=", "args", ".", "batch_size", ",", "shuffle", "=", "False", ")", ")", ":", "\n", "            ", "encoded_dict", "=", "encode", "(", "tokenizer", ",", "batch", ")", "\n", "transformation_indices", "=", "token_idx_by_sentence", "(", "encoded_dict", "[", "\"input_ids\"", "]", ",", "\n", "tokenizer", ".", "sep_token_id", ",", "args", ".", "repfile", ")", "\n", "encoded_dict", "=", "{", "key", ":", "tensor", ".", "to", "(", "device", ")", "for", "key", ",", "tensor", "in", "encoded_dict", ".", "items", "(", ")", "}", "\n", "transformation_indices", "=", "[", "tensor", ".", "to", "(", "device", ")", "for", "tensor", "in", "transformation_indices", "]", "\n", "domain_indices", "=", "batch", "[", "\"dataset\"", "]", ".", "to", "(", "device", ")", "\n", "rationale_out", ",", "stance_out", ",", "_", ",", "_", "=", "model", "(", "encoded_dict", ",", "transformation_indices", ",", "domain_indices", ")", "\n", "stance_preds", ".", "extend", "(", "stance_out", ")", "\n", "rationale_predictions", ".", "extend", "(", "remove_dummy", "(", "rationale_out", ")", ")", "\n", "\n", "", "", "return", "rationale_predictions", ",", "stance_preds", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.domain_adaptation_joint_paragraph_kgat_prediction.encode": [[70, 119], ["zip", "tokenizer.batch_encode_plus", "torch.cat", "torch.cat", "torch.cat", "encoded_dict[].size", "len", "numpy.sum", "numpy.argmax", "valid_paragraph.size", "all_paragraphs.append", "longest_first_truncation"], "function", ["home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.dataset.encode.longest_first_truncation"], ["", "def", "encode", "(", "tokenizer", ",", "batch", ",", "max_sent_len", "=", "512", ")", ":", "\n", "    ", "def", "truncate", "(", "input_ids", ",", "max_length", ",", "sep_token_id", ",", "pad_token_id", ")", ":", "\n", "        ", "def", "longest_first_truncation", "(", "sentences", ",", "objective", ")", ":", "\n", "            ", "sent_lens", "=", "[", "len", "(", "sent", ")", "for", "sent", "in", "sentences", "]", "\n", "while", "np", ".", "sum", "(", "sent_lens", ")", ">", "objective", ":", "\n", "                ", "max_position", "=", "np", ".", "argmax", "(", "sent_lens", ")", "\n", "sent_lens", "[", "max_position", "]", "-=", "1", "\n", "", "return", "[", "sentence", "[", ":", "length", "]", "for", "sentence", ",", "length", "in", "zip", "(", "sentences", ",", "sent_lens", ")", "]", "\n", "\n", "", "all_paragraphs", "=", "[", "]", "\n", "for", "paragraph", "in", "input_ids", ":", "\n", "            ", "valid_paragraph", "=", "paragraph", "[", "paragraph", "!=", "pad_token_id", "]", "\n", "if", "valid_paragraph", ".", "size", "(", "0", ")", "<=", "max_length", ":", "\n", "                ", "all_paragraphs", ".", "append", "(", "paragraph", "[", ":", "max_length", "]", ".", "unsqueeze", "(", "0", ")", ")", "\n", "", "else", ":", "\n", "                ", "sep_token_idx", "=", "np", ".", "arange", "(", "valid_paragraph", ".", "size", "(", "0", ")", ")", "[", "(", "valid_paragraph", "==", "sep_token_id", ")", ".", "numpy", "(", ")", "]", "\n", "idx_by_sentence", "=", "[", "]", "\n", "prev_idx", "=", "0", "\n", "for", "idx", "in", "sep_token_idx", ":", "\n", "                    ", "idx_by_sentence", ".", "append", "(", "paragraph", "[", "prev_idx", ":", "idx", "]", ")", "\n", "prev_idx", "=", "idx", "\n", "", "objective", "=", "max_length", "-", "1", "-", "len", "(", "idx_by_sentence", "[", "0", "]", ")", "# The last sep_token left out", "\n", "truncated_sentences", "=", "longest_first_truncation", "(", "idx_by_sentence", "[", "1", ":", "]", ",", "objective", ")", "\n", "truncated_paragraph", "=", "torch", ".", "cat", "(", "[", "idx_by_sentence", "[", "0", "]", "]", "+", "truncated_sentences", "+", "[", "torch", ".", "tensor", "(", "[", "sep_token_id", "]", ")", "]", ",", "0", ")", "\n", "all_paragraphs", ".", "append", "(", "truncated_paragraph", ".", "unsqueeze", "(", "0", ")", ")", "\n", "\n", "", "", "return", "torch", ".", "cat", "(", "all_paragraphs", ",", "0", ")", "\n", "\n", "", "inputs", "=", "zip", "(", "batch", "[", "\"claim\"", "]", ",", "batch", "[", "\"paragraph\"", "]", ")", "\n", "encoded_dict", "=", "tokenizer", ".", "batch_encode_plus", "(", "\n", "inputs", ",", "\n", "pad_to_max_length", "=", "True", ",", "add_special_tokens", "=", "True", ",", "\n", "return_tensors", "=", "'pt'", ")", "\n", "if", "encoded_dict", "[", "'input_ids'", "]", ".", "size", "(", "1", ")", ">", "max_sent_len", ":", "\n", "        ", "if", "'token_type_ids'", "in", "encoded_dict", ":", "\n", "            ", "encoded_dict", "=", "{", "\n", "\"input_ids\"", ":", "truncate", "(", "encoded_dict", "[", "'input_ids'", "]", ",", "max_sent_len", ",", "\n", "tokenizer", ".", "sep_token_id", ",", "tokenizer", ".", "pad_token_id", ")", ",", "\n", "'token_type_ids'", ":", "encoded_dict", "[", "'token_type_ids'", "]", "[", ":", ",", ":", "max_sent_len", "]", ",", "\n", "'attention_mask'", ":", "encoded_dict", "[", "'attention_mask'", "]", "[", ":", ",", ":", "max_sent_len", "]", "\n", "}", "\n", "", "else", ":", "\n", "            ", "encoded_dict", "=", "{", "\n", "\"input_ids\"", ":", "truncate", "(", "encoded_dict", "[", "'input_ids'", "]", ",", "max_sent_len", ",", "\n", "tokenizer", ".", "sep_token_id", ",", "tokenizer", ".", "pad_token_id", ")", ",", "\n", "'attention_mask'", ":", "encoded_dict", "[", "'attention_mask'", "]", "[", ":", ",", ":", "max_sent_len", "]", "\n", "}", "\n", "\n", "", "", "return", "encoded_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.domain_adaptation_joint_paragraph_kgat_prediction.token_idx_by_sentence": [[120, 155], ["torch.sum().numpy().tolist", "torch.sum().numpy().tolist", "torch.sum().numpy().tolist", "torch.arange().unsqueeze().expand", "torch.arange().unsqueeze().expand", "torch.arange().unsqueeze().expand", "torch.split", "torch.split", "torch.split", "torch.utils.rnn.pad_sequence", "torch.split", "torch.split", "torch.split", "torch.utils.rnn.pad_sequence", "torch.arange().unsqueeze().unsqueeze().expand", "torch.arange().unsqueeze().unsqueeze().expand", "torch.arange().unsqueeze().unsqueeze().expand", "sep_tokens.size", "torch.arange", "torch.arange", "torch.arange", "torch.sum().numpy().tolist.append", "all_word_indices.extend", "nn.utils.rnn.pad_sequence.size", "nn.utils.rnn.pad_sequence.size", "torch.arange().unsqueeze().unsqueeze().expand.long", "nn.utils.rnn.pad_sequence.long", "mask.long", "torch.sum().numpy", "torch.sum().numpy", "torch.sum().numpy", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange", "torch.arange", "torch.arange", "len", "torch.arange().unsqueeze().unsqueeze", "torch.arange().unsqueeze().unsqueeze", "torch.arange().unsqueeze().unsqueeze", "range", "torch.sum", "torch.sum", "torch.sum", "torch.arange", "torch.arange", "torch.arange", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "sep_tokens.size", "paragraph.size", "torch.arange", "torch.arange", "torch.arange", "sep_tokens.size"], "function", ["None"], ["", "def", "token_idx_by_sentence", "(", "input_ids", ",", "sep_token_id", ",", "model_name", ")", ":", "\n", "    ", "\"\"\"\n    Advanced indexing: Compute the token indices matrix of the BERT output.\n    input_ids: (batch_size, paragraph_len)\n    batch_indices, indices_by_batch, mask: (batch_size, N_sentence, N_token)\n    bert_out: (batch_size, paragraph_len,BERT_dim)\n    bert_out[batch_indices,indices_by_batch,:]: (batch_size, N_sentence, N_token, BERT_dim)\n    \"\"\"", "\n", "padding_idx", "=", "-", "1", "\n", "sep_tokens", "=", "(", "input_ids", "==", "sep_token_id", ")", ".", "bool", "(", ")", "\n", "paragraph_lens", "=", "torch", ".", "sum", "(", "sep_tokens", ",", "1", ")", ".", "numpy", "(", ")", ".", "tolist", "(", ")", "# i.e. N_sentences per paragraph", "\n", "indices", "=", "torch", ".", "arange", "(", "sep_tokens", ".", "size", "(", "-", "1", ")", ")", ".", "unsqueeze", "(", "0", ")", ".", "expand", "(", "sep_tokens", ".", "size", "(", "0", ")", ",", "-", "1", ")", "# 0,1,2,3,....,511 for each sentence", "\n", "sep_indices", "=", "torch", ".", "split", "(", "indices", "[", "sep_tokens", "]", ",", "paragraph_lens", ")", "# indices of SEP tokens per paragraph", "\n", "paragraph_lens", "=", "[", "]", "\n", "all_word_indices", "=", "[", "]", "\n", "for", "paragraph", "in", "sep_indices", ":", "\n", "# claim sentence: [CLS] token1 token2 ... tokenk", "\n", "        ", "claim_word_indices", "=", "torch", ".", "arange", "(", "0", ",", "paragraph", "[", "0", "]", ")", "\n", "if", "\"roberta\"", "in", "model_name", ":", "# Huggingface Roberta has <s>..</s></s>..</s>..</s>", "\n", "            ", "paragraph", "=", "paragraph", "[", "1", ":", "]", "\n", "# each sentence: [SEP] token1 token2 ... tokenk, the last [SEP] in the paragraph is ditched.", "\n", "", "sentence_word_indices", "=", "[", "torch", ".", "arange", "(", "paragraph", "[", "i", "]", ",", "paragraph", "[", "i", "+", "1", "]", ")", "for", "i", "in", "range", "(", "paragraph", ".", "size", "(", "0", ")", "-", "1", ")", "]", "\n", "\n", "# KGAT requires claim sentence, so add it back.", "\n", "word_indices", "=", "[", "claim_word_indices", "]", "+", "sentence_word_indices", "\n", "\n", "paragraph_lens", ".", "append", "(", "len", "(", "word_indices", ")", ")", "\n", "all_word_indices", ".", "extend", "(", "word_indices", ")", "\n", "", "indices_by_sentence", "=", "nn", ".", "utils", ".", "rnn", ".", "pad_sequence", "(", "all_word_indices", ",", "batch_first", "=", "True", ",", "padding_value", "=", "padding_idx", ")", "\n", "indices_by_sentence_split", "=", "torch", ".", "split", "(", "indices_by_sentence", ",", "paragraph_lens", ")", "\n", "indices_by_batch", "=", "nn", ".", "utils", ".", "rnn", ".", "pad_sequence", "(", "indices_by_sentence_split", ",", "batch_first", "=", "True", ",", "padding_value", "=", "padding_idx", ")", "\n", "batch_indices", "=", "torch", ".", "arange", "(", "sep_tokens", ".", "size", "(", "0", ")", ")", ".", "unsqueeze", "(", "-", "1", ")", ".", "unsqueeze", "(", "-", "1", ")", ".", "expand", "(", "-", "1", ",", "indices_by_batch", ".", "size", "(", "1", ")", ",", "indices_by_batch", ".", "size", "(", "-", "1", ")", ")", "\n", "mask", "=", "(", "indices_by_batch", ">=", "0", ")", "\n", "\n", "return", "batch_indices", ".", "long", "(", ")", ",", "indices_by_batch", ".", "long", "(", ")", ",", "mask", ".", "long", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.domain_adaptation_joint_paragraph_kgat_prediction.post_process_stance": [[156, 164], ["zip", "len", "len", "rationale_pred[].items", "len"], "function", ["None"], ["", "def", "post_process_stance", "(", "rationale_json", ",", "stance_json", ")", ":", "\n", "    ", "assert", "(", "len", "(", "rationale_json", ")", "==", "len", "(", "stance_json", ")", ")", "\n", "for", "stance_pred", ",", "rationale_pred", "in", "zip", "(", "stance_json", ",", "rationale_json", ")", ":", "\n", "        ", "assert", "(", "stance_pred", "[", "\"claim_id\"", "]", "==", "rationale_pred", "[", "\"claim_id\"", "]", ")", "\n", "for", "doc_id", ",", "pred", "in", "rationale_pred", "[", "\"evidence\"", "]", ".", "items", "(", ")", ":", "\n", "            ", "if", "len", "(", "pred", ")", "==", "0", ":", "\n", "                ", "stance_pred", "[", "\"labels\"", "]", "[", "doc_id", "]", "[", "\"label\"", "]", "=", "\"NOT_ENOUGH_INFO\"", "\n", "", "", "", "return", "stance_json", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.scifact_joint_paragraph_dynamic.schedule_sample_p": [[28, 30], ["numpy.sin"], "function", ["None"], ["def", "schedule_sample_p", "(", "epoch", ",", "total", ")", ":", "\n", "    ", "return", "np", ".", "sin", "(", "0.5", "*", "np", ".", "pi", "*", "epoch", "/", "(", "total", "-", "1", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.scifact_joint_paragraph_dynamic.reset_random_seed": [[31, 35], ["numpy.random.seed", "random.seed", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed"], "function", ["None"], ["", "def", "reset_random_seed", "(", "seed", ")", ":", "\n", "    ", "np", ".", "random", ".", "seed", "(", "seed", ")", "\n", "random", ".", "seed", "(", "seed", ")", "\n", "torch", ".", "manual_seed", "(", "seed", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.scifact_joint_paragraph_dynamic.batch_rationale_label": [[36, 45], ["max", "enumerate", "torch.ones", "torch.ones", "torch.ones", "enumerate", "label_list.append", "label_matrix.long", "len", "len", "int", "int"], "function", ["None"], ["", "def", "batch_rationale_label", "(", "labels", ",", "padding_idx", "=", "2", ")", ":", "\n", "    ", "max_sent_len", "=", "max", "(", "[", "len", "(", "label", ")", "for", "label", "in", "labels", "]", ")", "\n", "label_matrix", "=", "torch", ".", "ones", "(", "len", "(", "labels", ")", ",", "max_sent_len", ")", "*", "padding_idx", "\n", "label_list", "=", "[", "]", "\n", "for", "i", ",", "label", "in", "enumerate", "(", "labels", ")", ":", "\n", "        ", "for", "j", ",", "evid", "in", "enumerate", "(", "label", ")", ":", "\n", "            ", "label_matrix", "[", "i", ",", "j", "]", "=", "int", "(", "evid", ")", "\n", "", "label_list", ".", "append", "(", "[", "int", "(", "evid", ")", "for", "evid", "in", "label", "]", ")", "\n", "", "return", "label_matrix", ".", "long", "(", ")", ",", "label_list", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.scifact_joint_paragraph_dynamic.predict": [[46, 66], ["model.eval", "torch.no_grad", "torch.no_grad", "torch.no_grad", "tqdm.tqdm", "torch.utils.data.DataLoader", "scifact_joint_paragraph_dynamic.encode", "scifact_joint_paragraph_dynamic.token_idx_by_sentence", "model", "stance_preds.extend", "rationale_predictions.extend", "tensor.to", "tensor.to", "scifact_joint_paragraph_dynamic.predict.remove_dummy"], "function", ["home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.label_prediction.transformer_scifact.encode", "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.FEVER_stance_paragraph.token_idx_by_sentence", "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.src.utils.remove_dummy"], ["", "def", "predict", "(", "model", ",", "dataset", ")", ":", "\n", "    ", "model", ".", "eval", "(", ")", "\n", "rationale_predictions", "=", "[", "]", "\n", "stance_preds", "=", "[", "]", "\n", "\n", "def", "remove_dummy", "(", "rationale_out", ")", ":", "\n", "        ", "return", "[", "out", "[", "1", ":", "]", "for", "out", "in", "rationale_out", "]", "\n", "\n", "", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "for", "batch", "in", "tqdm", "(", "DataLoader", "(", "dataset", ",", "batch_size", "=", "args", ".", "batch_size", ",", "shuffle", "=", "False", ")", ")", ":", "\n", "            ", "encoded_dict", "=", "encode", "(", "tokenizer", ",", "batch", ")", "\n", "transformation_indices", "=", "token_idx_by_sentence", "(", "encoded_dict", "[", "\"input_ids\"", "]", ",", "\n", "tokenizer", ".", "sep_token_id", ",", "args", ".", "repfile", ")", "\n", "encoded_dict", "=", "{", "key", ":", "tensor", ".", "to", "(", "device", ")", "for", "key", ",", "tensor", "in", "encoded_dict", ".", "items", "(", ")", "}", "\n", "transformation_indices", "=", "[", "tensor", ".", "to", "(", "device", ")", "for", "tensor", "in", "transformation_indices", "]", "\n", "rationale_out", ",", "stance_out", ",", "_", ",", "_", "=", "model", "(", "encoded_dict", ",", "transformation_indices", ")", "\n", "stance_preds", ".", "extend", "(", "stance_out", ")", "\n", "rationale_predictions", ".", "extend", "(", "remove_dummy", "(", "rationale_out", ")", ")", "\n", "\n", "", "", "return", "rationale_predictions", ",", "stance_preds", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.scifact_joint_paragraph_dynamic.evaluation": [[67, 103], ["model.eval", "sklearn.metrics.f1_score", "sklearn.metrics.precision_score", "sklearn.metrics.recall_score", "sklearn.metrics.f1_score", "sklearn.metrics.precision_score", "sklearn.metrics.recall_score", "torch.no_grad", "torch.no_grad", "torch.no_grad", "tqdm.tqdm", "util.flatten", "util.flatten", "util.flatten", "util.flatten", "util.flatten", "util.flatten", "torch.utils.data.DataLoader", "scifact_joint_paragraph_dynamic.encode", "scifact_joint_paragraph_dynamic.token_idx_by_sentence", "batch[].to", "scifact_joint_paragraph_dynamic.batch_rationale_label", "model", "stance_preds.extend", "stance_labels.extend", "rationale_predictions.extend", "rationale_labels.extend", "tensor.to", "tensor.to", "batch[].to.cpu().numpy().tolist", "scifact_joint_paragraph_dynamic.predict.remove_dummy"], "function", ["home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.util.flatten", "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.util.flatten", "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.util.flatten", "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.util.flatten", "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.util.flatten", "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.util.flatten", "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.label_prediction.transformer_scifact.encode", "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.FEVER_stance_paragraph.token_idx_by_sentence", "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.domain_adaptation_joint_paragraph_fine_tune.batch_rationale_label", "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.src.utils.remove_dummy"], ["", "def", "evaluation", "(", "model", ",", "dataset", ",", "dummy", "=", "True", ")", ":", "\n", "    ", "model", ".", "eval", "(", ")", "\n", "rationale_predictions", "=", "[", "]", "\n", "rationale_labels", "=", "[", "]", "\n", "stance_preds", "=", "[", "]", "\n", "stance_labels", "=", "[", "]", "\n", "\n", "def", "remove_dummy", "(", "rationale_out", ")", ":", "\n", "        ", "return", "[", "out", "[", "1", ":", "]", "for", "out", "in", "rationale_out", "]", "\n", "\n", "\n", "", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "for", "batch", "in", "tqdm", "(", "DataLoader", "(", "dataset", ",", "batch_size", "=", "args", ".", "batch_size", "*", "5", ",", "shuffle", "=", "False", ")", ")", ":", "\n", "            ", "encoded_dict", "=", "encode", "(", "tokenizer", ",", "batch", ")", "\n", "transformation_indices", "=", "token_idx_by_sentence", "(", "encoded_dict", "[", "\"input_ids\"", "]", ",", "\n", "tokenizer", ".", "sep_token_id", ",", "args", ".", "repfile", ")", "\n", "encoded_dict", "=", "{", "key", ":", "tensor", ".", "to", "(", "device", ")", "for", "key", ",", "tensor", "in", "encoded_dict", ".", "items", "(", ")", "}", "\n", "transformation_indices", "=", "[", "tensor", ".", "to", "(", "device", ")", "for", "tensor", "in", "transformation_indices", "]", "\n", "stance_label", "=", "batch", "[", "\"stance\"", "]", ".", "to", "(", "device", ")", "\n", "padded_rationale_label", ",", "rationale_label", "=", "batch_rationale_label", "(", "batch", "[", "\"label\"", "]", ",", "padding_idx", "=", "2", ")", "\n", "rationale_out", ",", "stance_out", ",", "rationale_loss", ",", "stance_loss", "=", "model", "(", "encoded_dict", ",", "transformation_indices", ",", "stance_label", "=", "stance_label", ",", "\n", "rationale_label", "=", "padded_rationale_label", ".", "to", "(", "device", ")", ")", "\n", "stance_preds", ".", "extend", "(", "stance_out", ")", "\n", "stance_labels", ".", "extend", "(", "stance_label", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "tolist", "(", ")", ")", "\n", "\n", "rationale_predictions", ".", "extend", "(", "remove_dummy", "(", "rationale_out", ")", ")", "\n", "rationale_labels", ".", "extend", "(", "remove_dummy", "(", "rationale_label", ")", ")", "\n", "\n", "", "", "stance_f1", "=", "f1_score", "(", "stance_labels", ",", "stance_preds", ",", "average", "=", "\"micro\"", ",", "labels", "=", "[", "1", ",", "2", "]", ")", "\n", "stance_precision", "=", "precision_score", "(", "stance_labels", ",", "stance_preds", ",", "average", "=", "\"micro\"", ",", "labels", "=", "[", "1", ",", "2", "]", ")", "\n", "stance_recall", "=", "recall_score", "(", "stance_labels", ",", "stance_preds", ",", "average", "=", "\"micro\"", ",", "labels", "=", "[", "1", ",", "2", "]", ")", "\n", "rationale_f1", "=", "f1_score", "(", "flatten", "(", "rationale_labels", ")", ",", "flatten", "(", "rationale_predictions", ")", ")", "\n", "rationale_precision", "=", "precision_score", "(", "flatten", "(", "rationale_labels", ")", ",", "flatten", "(", "rationale_predictions", ")", ")", "\n", "rationale_recall", "=", "recall_score", "(", "flatten", "(", "rationale_labels", ")", ",", "flatten", "(", "rationale_predictions", ")", ")", "\n", "return", "stance_f1", ",", "stance_precision", ",", "stance_recall", ",", "rationale_f1", ",", "rationale_precision", ",", "rationale_recall", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.scifact_joint_paragraph_dynamic.encode": [[106, 155], ["zip", "tokenizer.batch_encode_plus", "torch.cat", "torch.cat", "torch.cat", "encoded_dict[].size", "len", "numpy.sum", "numpy.argmax", "valid_paragraph.size", "all_paragraphs.append", "longest_first_truncation"], "function", ["home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.dataset.encode.longest_first_truncation"], ["", "def", "encode", "(", "tokenizer", ",", "batch", ",", "max_sent_len", "=", "512", ")", ":", "\n", "    ", "def", "truncate", "(", "input_ids", ",", "max_length", ",", "sep_token_id", ",", "pad_token_id", ")", ":", "\n", "        ", "def", "longest_first_truncation", "(", "sentences", ",", "objective", ")", ":", "\n", "            ", "sent_lens", "=", "[", "len", "(", "sent", ")", "for", "sent", "in", "sentences", "]", "\n", "while", "np", ".", "sum", "(", "sent_lens", ")", ">", "objective", ":", "\n", "                ", "max_position", "=", "np", ".", "argmax", "(", "sent_lens", ")", "\n", "sent_lens", "[", "max_position", "]", "-=", "1", "\n", "", "return", "[", "sentence", "[", ":", "length", "]", "for", "sentence", ",", "length", "in", "zip", "(", "sentences", ",", "sent_lens", ")", "]", "\n", "\n", "", "all_paragraphs", "=", "[", "]", "\n", "for", "paragraph", "in", "input_ids", ":", "\n", "            ", "valid_paragraph", "=", "paragraph", "[", "paragraph", "!=", "pad_token_id", "]", "\n", "if", "valid_paragraph", ".", "size", "(", "0", ")", "<=", "max_length", ":", "\n", "                ", "all_paragraphs", ".", "append", "(", "paragraph", "[", ":", "max_length", "]", ".", "unsqueeze", "(", "0", ")", ")", "\n", "", "else", ":", "\n", "                ", "sep_token_idx", "=", "np", ".", "arange", "(", "valid_paragraph", ".", "size", "(", "0", ")", ")", "[", "(", "valid_paragraph", "==", "sep_token_id", ")", ".", "numpy", "(", ")", "]", "\n", "idx_by_sentence", "=", "[", "]", "\n", "prev_idx", "=", "0", "\n", "for", "idx", "in", "sep_token_idx", ":", "\n", "                    ", "idx_by_sentence", ".", "append", "(", "paragraph", "[", "prev_idx", ":", "idx", "]", ")", "\n", "prev_idx", "=", "idx", "\n", "", "objective", "=", "max_length", "-", "1", "-", "len", "(", "idx_by_sentence", "[", "0", "]", ")", "# The last sep_token left out", "\n", "truncated_sentences", "=", "longest_first_truncation", "(", "idx_by_sentence", "[", "1", ":", "]", ",", "objective", ")", "\n", "truncated_paragraph", "=", "torch", ".", "cat", "(", "[", "idx_by_sentence", "[", "0", "]", "]", "+", "truncated_sentences", "+", "[", "torch", ".", "tensor", "(", "[", "sep_token_id", "]", ")", "]", ",", "0", ")", "\n", "all_paragraphs", ".", "append", "(", "truncated_paragraph", ".", "unsqueeze", "(", "0", ")", ")", "\n", "\n", "", "", "return", "torch", ".", "cat", "(", "all_paragraphs", ",", "0", ")", "\n", "\n", "", "inputs", "=", "zip", "(", "batch", "[", "\"claim\"", "]", ",", "batch", "[", "\"paragraph\"", "]", ")", "\n", "encoded_dict", "=", "tokenizer", ".", "batch_encode_plus", "(", "\n", "inputs", ",", "\n", "pad_to_max_length", "=", "True", ",", "add_special_tokens", "=", "True", ",", "\n", "return_tensors", "=", "'pt'", ")", "\n", "if", "encoded_dict", "[", "'input_ids'", "]", ".", "size", "(", "1", ")", ">", "max_sent_len", ":", "\n", "        ", "if", "'token_type_ids'", "in", "encoded_dict", ":", "\n", "            ", "encoded_dict", "=", "{", "\n", "\"input_ids\"", ":", "truncate", "(", "encoded_dict", "[", "'input_ids'", "]", ",", "max_sent_len", ",", "\n", "tokenizer", ".", "sep_token_id", ",", "tokenizer", ".", "pad_token_id", ")", ",", "\n", "'token_type_ids'", ":", "encoded_dict", "[", "'token_type_ids'", "]", "[", ":", ",", ":", "max_sent_len", "]", ",", "\n", "'attention_mask'", ":", "encoded_dict", "[", "'attention_mask'", "]", "[", ":", ",", ":", "max_sent_len", "]", "\n", "}", "\n", "", "else", ":", "\n", "            ", "encoded_dict", "=", "{", "\n", "\"input_ids\"", ":", "truncate", "(", "encoded_dict", "[", "'input_ids'", "]", ",", "max_sent_len", ",", "\n", "tokenizer", ".", "sep_token_id", ",", "tokenizer", ".", "pad_token_id", ")", ",", "\n", "'attention_mask'", ":", "encoded_dict", "[", "'attention_mask'", "]", "[", ":", ",", ":", "max_sent_len", "]", "\n", "}", "\n", "\n", "", "", "return", "encoded_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.scifact_joint_paragraph_dynamic.sent_rep_indices": [[156, 178], ["torch.sum().numpy().tolist", "torch.sum().numpy().tolist", "torch.sum().numpy().tolist", "torch.arange().unsqueeze().expand", "torch.arange().unsqueeze().expand", "torch.arange().unsqueeze().expand", "torch.split", "torch.split", "torch.split", "torch.utils.rnn.pad_sequence", "torch.arange().unsqueeze().expand", "torch.arange().unsqueeze().expand", "torch.arange().unsqueeze().expand", "sep_tokens.size", "nn.utils.rnn.pad_sequence.size", "torch.sum().numpy", "torch.sum().numpy", "torch.sum().numpy", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.sum", "torch.sum", "torch.sum", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "sep_tokens.size", "nn.utils.rnn.pad_sequence.size"], "function", ["None"], ["", "def", "sent_rep_indices", "(", "input_ids", ",", "sep_token_id", ",", "model_name", ")", ":", "\n", "\n", "    ", "\"\"\"\n    Compute the [SEP] indices matrix of the BERT output.\n    input_ids: (batch_size, paragraph_len)\n    batch_indices, indices_by_batch, mask: (batch_size, N_sentence)\n    bert_out: (batch_size, paragraph_len,BERT_dim)\n    bert_out[batch_indices,indices_by_batch,:]: (batch_size, N_sentence, BERT_dim)\n    \"\"\"", "\n", "\n", "sep_tokens", "=", "(", "input_ids", "==", "sep_token_id", ")", ".", "bool", "(", ")", "\n", "paragraph_lens", "=", "torch", ".", "sum", "(", "sep_tokens", ",", "1", ")", ".", "numpy", "(", ")", ".", "tolist", "(", ")", "\n", "indices", "=", "torch", ".", "arange", "(", "sep_tokens", ".", "size", "(", "-", "1", ")", ")", ".", "unsqueeze", "(", "0", ")", ".", "expand", "(", "sep_tokens", ".", "size", "(", "0", ")", ",", "-", "1", ")", "\n", "sep_indices", "=", "torch", ".", "split", "(", "indices", "[", "sep_tokens", "]", ",", "paragraph_lens", ")", "\n", "padded_sep_indices", "=", "nn", ".", "utils", ".", "rnn", ".", "pad_sequence", "(", "sep_indices", ",", "batch_first", "=", "True", ",", "padding_value", "=", "-", "1", ")", "\n", "batch_indices", "=", "torch", ".", "arange", "(", "padded_sep_indices", ".", "size", "(", "0", ")", ")", ".", "unsqueeze", "(", "-", "1", ")", ".", "expand", "(", "-", "1", ",", "padded_sep_indices", ".", "size", "(", "-", "1", ")", ")", "\n", "mask", "=", "(", "padded_sep_indices", ">=", "0", ")", ".", "long", "(", ")", "\n", "\n", "if", "\"roberta\"", "in", "model_name", ":", "\n", "        ", "return", "batch_indices", "[", ":", ",", "2", ":", "]", ",", "padded_sep_indices", "[", ":", ",", "2", ":", "]", ",", "mask", "[", ":", ",", "2", ":", "]", "\n", "", "else", ":", "\n", "        ", "return", "batch_indices", "[", ":", ",", "1", ":", "]", ",", "padded_sep_indices", "[", ":", ",", "1", ":", "]", ",", "mask", "[", ":", ",", "1", ":", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.scifact_joint_paragraph_dynamic.token_idx_by_sentence": [[179, 207], ["torch.sum().numpy().tolist", "torch.sum().numpy().tolist", "torch.sum().numpy().tolist", "torch.arange().unsqueeze().expand", "torch.arange().unsqueeze().expand", "torch.arange().unsqueeze().expand", "torch.split", "torch.split", "torch.split", "torch.utils.rnn.pad_sequence", "torch.split", "torch.split", "torch.split", "torch.utils.rnn.pad_sequence", "torch.arange().unsqueeze().unsqueeze().expand", "torch.arange().unsqueeze().unsqueeze().expand", "torch.arange().unsqueeze().unsqueeze().expand", "sep_tokens.size", "torch.sum().numpy().tolist.append", "all_word_indices.extend", "nn.utils.rnn.pad_sequence.size", "nn.utils.rnn.pad_sequence.size", "torch.arange().unsqueeze().unsqueeze().expand.long", "nn.utils.rnn.pad_sequence.long", "mask.long", "torch.sum().numpy", "torch.sum().numpy", "torch.sum().numpy", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange", "torch.arange", "torch.arange", "len", "torch.arange().unsqueeze().unsqueeze", "torch.arange().unsqueeze().unsqueeze", "torch.arange().unsqueeze().unsqueeze", "range", "torch.sum", "torch.sum", "torch.sum", "torch.arange", "torch.arange", "torch.arange", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "sep_tokens.size", "paragraph.size", "torch.arange", "torch.arange", "torch.arange", "sep_tokens.size"], "function", ["None"], ["", "", "def", "token_idx_by_sentence", "(", "input_ids", ",", "sep_token_id", ",", "model_name", ")", ":", "\n", "    ", "\"\"\"\n    Compute the token indices matrix of the BERT output.\n    input_ids: (batch_size, paragraph_len)\n    batch_indices, indices_by_batch, mask: (batch_size, N_sentence, N_token)\n    bert_out: (batch_size, paragraph_len,BERT_dim)\n    bert_out[batch_indices,indices_by_batch,:]: (batch_size, N_sentence, N_token, BERT_dim)\n    \"\"\"", "\n", "padding_idx", "=", "-", "1", "\n", "sep_tokens", "=", "(", "input_ids", "==", "sep_token_id", ")", ".", "bool", "(", ")", "\n", "paragraph_lens", "=", "torch", ".", "sum", "(", "sep_tokens", ",", "1", ")", ".", "numpy", "(", ")", ".", "tolist", "(", ")", "\n", "indices", "=", "torch", ".", "arange", "(", "sep_tokens", ".", "size", "(", "-", "1", ")", ")", ".", "unsqueeze", "(", "0", ")", ".", "expand", "(", "sep_tokens", ".", "size", "(", "0", ")", ",", "-", "1", ")", "\n", "sep_indices", "=", "torch", ".", "split", "(", "indices", "[", "sep_tokens", "]", ",", "paragraph_lens", ")", "\n", "paragraph_lens", "=", "[", "]", "\n", "all_word_indices", "=", "[", "]", "\n", "for", "paragraph", "in", "sep_indices", ":", "\n", "        ", "if", "\"large\"", "in", "model_name", ":", "\n", "            ", "paragraph", "=", "paragraph", "[", "1", ":", "]", "\n", "", "word_indices", "=", "[", "torch", ".", "arange", "(", "paragraph", "[", "i", "]", "+", "1", ",", "paragraph", "[", "i", "+", "1", "]", "+", "1", ")", "for", "i", "in", "range", "(", "paragraph", ".", "size", "(", "0", ")", "-", "1", ")", "]", "\n", "paragraph_lens", ".", "append", "(", "len", "(", "word_indices", ")", ")", "\n", "all_word_indices", ".", "extend", "(", "word_indices", ")", "\n", "", "indices_by_sentence", "=", "nn", ".", "utils", ".", "rnn", ".", "pad_sequence", "(", "all_word_indices", ",", "batch_first", "=", "True", ",", "padding_value", "=", "padding_idx", ")", "\n", "indices_by_sentence_split", "=", "torch", ".", "split", "(", "indices_by_sentence", ",", "paragraph_lens", ")", "\n", "indices_by_batch", "=", "nn", ".", "utils", ".", "rnn", ".", "pad_sequence", "(", "indices_by_sentence_split", ",", "batch_first", "=", "True", ",", "padding_value", "=", "padding_idx", ")", "\n", "batch_indices", "=", "torch", ".", "arange", "(", "sep_tokens", ".", "size", "(", "0", ")", ")", ".", "unsqueeze", "(", "-", "1", ")", ".", "unsqueeze", "(", "-", "1", ")", ".", "expand", "(", "-", "1", ",", "indices_by_batch", ".", "size", "(", "1", ")", ",", "indices_by_batch", ".", "size", "(", "-", "1", ")", ")", "\n", "mask", "=", "(", "indices_by_batch", ">=", "0", ")", "\n", "\n", "return", "batch_indices", ".", "long", "(", ")", ",", "indices_by_batch", ".", "long", "(", ")", ",", "mask", ".", "long", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.scifact_joint_paragraph_dynamic.post_process_stance": [[208, 216], ["zip", "len", "len", "rationale_pred[].items", "len"], "function", ["None"], ["", "def", "post_process_stance", "(", "rationale_json", ",", "stance_json", ")", ":", "\n", "    ", "assert", "(", "len", "(", "rationale_json", ")", "==", "len", "(", "stance_json", ")", ")", "\n", "for", "stance_pred", ",", "rationale_pred", "in", "zip", "(", "stance_json", ",", "rationale_json", ")", ":", "\n", "        ", "assert", "(", "stance_pred", "[", "\"claim_id\"", "]", "==", "rationale_pred", "[", "\"claim_id\"", "]", ")", "\n", "for", "doc_id", ",", "pred", "in", "rationale_pred", "[", "\"evidence\"", "]", ".", "items", "(", ")", ":", "\n", "            ", "if", "len", "(", "pred", ")", "==", "0", ":", "\n", "                ", "stance_pred", "[", "\"labels\"", "]", "[", "doc_id", "]", "[", "\"label\"", "]", "=", "\"NOT_ENOUGH_INFO\"", "\n", "", "", "", "return", "stance_json", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.FEVER_joint_paragraph_dynamic.schedule_sample_p": [[30, 32], ["numpy.sin"], "function", ["None"], ["def", "schedule_sample_p", "(", "epoch", ",", "total", ")", ":", "\n", "    ", "return", "np", ".", "sin", "(", "0.5", "*", "np", ".", "pi", "*", "epoch", "/", "(", "total", "-", "1", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.FEVER_joint_paragraph_dynamic.reset_random_seed": [[33, 37], ["numpy.random.seed", "random.seed", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed"], "function", ["None"], ["", "def", "reset_random_seed", "(", "seed", ")", ":", "\n", "    ", "np", ".", "random", ".", "seed", "(", "seed", ")", "\n", "random", ".", "seed", "(", "seed", ")", "\n", "torch", ".", "manual_seed", "(", "seed", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.FEVER_joint_paragraph_dynamic.batch_rationale_label": [[38, 47], ["max", "enumerate", "torch.ones", "torch.ones", "torch.ones", "enumerate", "label_list.append", "label_matrix.long", "len", "len", "int", "int"], "function", ["None"], ["", "def", "batch_rationale_label", "(", "labels", ",", "padding_idx", "=", "2", ")", ":", "\n", "    ", "max_sent_len", "=", "max", "(", "[", "len", "(", "label", ")", "for", "label", "in", "labels", "]", ")", "\n", "label_matrix", "=", "torch", ".", "ones", "(", "len", "(", "labels", ")", ",", "max_sent_len", ")", "*", "padding_idx", "\n", "label_list", "=", "[", "]", "\n", "for", "i", ",", "label", "in", "enumerate", "(", "labels", ")", ":", "\n", "        ", "for", "j", ",", "evid", "in", "enumerate", "(", "label", ")", ":", "\n", "            ", "label_matrix", "[", "i", ",", "j", "]", "=", "int", "(", "evid", ")", "\n", "", "label_list", ".", "append", "(", "[", "int", "(", "evid", ")", "for", "evid", "in", "label", "]", ")", "\n", "", "return", "label_matrix", ".", "long", "(", ")", ",", "label_list", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.FEVER_joint_paragraph_dynamic.evaluation": [[48, 84], ["model.eval", "sklearn.metrics.f1_score", "sklearn.metrics.precision_score", "sklearn.metrics.recall_score", "sklearn.metrics.f1_score", "sklearn.metrics.precision_score", "sklearn.metrics.recall_score", "torch.no_grad", "torch.no_grad", "torch.no_grad", "tqdm.tqdm", "util.flatten", "util.flatten", "util.flatten", "util.flatten", "util.flatten", "util.flatten", "torch.utils.data.DataLoader", "FEVER_joint_paragraph_dynamic.encode", "FEVER_joint_paragraph_dynamic.token_idx_by_sentence", "batch[].to", "FEVER_joint_paragraph_dynamic.batch_rationale_label", "tensor.to", "tensor.to", "padded_rationale_label.size", "transformation_indices[].size", "model", "stance_preds.extend", "stance_labels.extend", "rationale_predictions.extend", "rationale_labels.extend", "encode.items", "batch[].to.cpu().numpy().tolist", "FEVER_joint_paragraph_dynamic.evaluation.remove_dummy"], "function", ["home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.util.flatten", "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.util.flatten", "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.util.flatten", "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.util.flatten", "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.util.flatten", "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.util.flatten", "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.label_prediction.transformer_scifact.encode", "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.FEVER_stance_paragraph.token_idx_by_sentence", "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.domain_adaptation_joint_paragraph_fine_tune.batch_rationale_label", "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.src.utils.remove_dummy"], ["", "def", "evaluation", "(", "model", ",", "dataset", ")", ":", "\n", "    ", "model", ".", "eval", "(", ")", "\n", "rationale_predictions", "=", "[", "]", "\n", "rationale_labels", "=", "[", "]", "\n", "stance_preds", "=", "[", "]", "\n", "stance_labels", "=", "[", "]", "\n", "\n", "def", "remove_dummy", "(", "rationale_out", ")", ":", "\n", "        ", "return", "[", "out", "[", "1", ":", "]", "for", "out", "in", "rationale_out", "]", "\n", "\n", "", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "for", "batch", "in", "tqdm", "(", "DataLoader", "(", "dataset", ",", "batch_size", "=", "args", ".", "batch_size", ",", "shuffle", "=", "False", ")", ")", ":", "\n", "            ", "encoded_dict", "=", "encode", "(", "tokenizer", ",", "batch", ")", "\n", "transformation_indices", "=", "token_idx_by_sentence", "(", "encoded_dict", "[", "\"input_ids\"", "]", ",", "\n", "tokenizer", ".", "sep_token_id", ",", "args", ".", "repfile", ")", "\n", "encoded_dict", "=", "{", "key", ":", "tensor", ".", "to", "(", "device", ")", "for", "key", ",", "tensor", "in", "encoded_dict", ".", "items", "(", ")", "}", "\n", "transformation_indices", "=", "[", "tensor", ".", "to", "(", "device", ")", "for", "tensor", "in", "transformation_indices", "]", "\n", "stance_label", "=", "batch", "[", "\"stance\"", "]", ".", "to", "(", "device", ")", "\n", "padded_rationale_label", ",", "rationale_label", "=", "batch_rationale_label", "(", "batch", "[", "\"label\"", "]", ",", "padding_idx", "=", "2", ")", "\n", "if", "padded_rationale_label", ".", "size", "(", "1", ")", "==", "transformation_indices", "[", "-", "1", "]", ".", "size", "(", "1", ")", ":", "\n", "                ", "rationale_out", ",", "stance_out", ",", "rationale_loss", ",", "stance_loss", "=", "model", "(", "encoded_dict", ",", "transformation_indices", ",", "stance_label", "=", "stance_label", ",", "\n", "rationale_label", "=", "padded_rationale_label", ".", "to", "(", "device", ")", ")", "\n", "stance_preds", ".", "extend", "(", "stance_out", ")", "\n", "stance_labels", ".", "extend", "(", "stance_label", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "tolist", "(", ")", ")", "\n", "\n", "rationale_predictions", ".", "extend", "(", "remove_dummy", "(", "rationale_out", ")", ")", "\n", "rationale_labels", ".", "extend", "(", "remove_dummy", "(", "rationale_label", ")", ")", "\n", "\n", "", "", "", "stance_f1", "=", "f1_score", "(", "stance_labels", ",", "stance_preds", ",", "average", "=", "\"micro\"", ",", "labels", "=", "[", "1", ",", "2", "]", ")", "\n", "stance_precision", "=", "precision_score", "(", "stance_labels", ",", "stance_preds", ",", "average", "=", "\"micro\"", ",", "labels", "=", "[", "1", ",", "2", "]", ")", "\n", "stance_recall", "=", "recall_score", "(", "stance_labels", ",", "stance_preds", ",", "average", "=", "\"micro\"", ",", "labels", "=", "[", "1", ",", "2", "]", ")", "\n", "rationale_f1", "=", "f1_score", "(", "flatten", "(", "rationale_labels", ")", ",", "flatten", "(", "rationale_predictions", ")", ")", "\n", "rationale_precision", "=", "precision_score", "(", "flatten", "(", "rationale_labels", ")", ",", "flatten", "(", "rationale_predictions", ")", ")", "\n", "rationale_recall", "=", "recall_score", "(", "flatten", "(", "rationale_labels", ")", ",", "flatten", "(", "rationale_predictions", ")", ")", "\n", "return", "stance_f1", ",", "stance_precision", ",", "stance_recall", ",", "rationale_f1", ",", "rationale_precision", ",", "rationale_recall", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.FEVER_joint_paragraph_dynamic.encode": [[87, 136], ["zip", "tokenizer.batch_encode_plus", "torch.cat", "torch.cat", "torch.cat", "encoded_dict[].size", "len", "numpy.sum", "numpy.argmax", "valid_paragraph.size", "all_paragraphs.append", "longest_first_truncation"], "function", ["home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.dataset.encode.longest_first_truncation"], ["", "def", "encode", "(", "tokenizer", ",", "batch", ",", "max_sent_len", "=", "512", ")", ":", "\n", "    ", "def", "truncate", "(", "input_ids", ",", "max_length", ",", "sep_token_id", ",", "pad_token_id", ")", ":", "\n", "        ", "def", "longest_first_truncation", "(", "sentences", ",", "objective", ")", ":", "\n", "            ", "sent_lens", "=", "[", "len", "(", "sent", ")", "for", "sent", "in", "sentences", "]", "\n", "while", "np", ".", "sum", "(", "sent_lens", ")", ">", "objective", ":", "\n", "                ", "max_position", "=", "np", ".", "argmax", "(", "sent_lens", ")", "\n", "sent_lens", "[", "max_position", "]", "-=", "1", "\n", "", "return", "[", "sentence", "[", ":", "length", "]", "for", "sentence", ",", "length", "in", "zip", "(", "sentences", ",", "sent_lens", ")", "]", "\n", "\n", "", "all_paragraphs", "=", "[", "]", "\n", "for", "paragraph", "in", "input_ids", ":", "\n", "            ", "valid_paragraph", "=", "paragraph", "[", "paragraph", "!=", "pad_token_id", "]", "\n", "if", "valid_paragraph", ".", "size", "(", "0", ")", "<=", "max_length", ":", "\n", "                ", "all_paragraphs", ".", "append", "(", "paragraph", "[", ":", "max_length", "]", ".", "unsqueeze", "(", "0", ")", ")", "\n", "", "else", ":", "\n", "                ", "sep_token_idx", "=", "np", ".", "arange", "(", "valid_paragraph", ".", "size", "(", "0", ")", ")", "[", "(", "valid_paragraph", "==", "sep_token_id", ")", ".", "numpy", "(", ")", "]", "\n", "idx_by_sentence", "=", "[", "]", "\n", "prev_idx", "=", "0", "\n", "for", "idx", "in", "sep_token_idx", ":", "\n", "                    ", "idx_by_sentence", ".", "append", "(", "paragraph", "[", "prev_idx", ":", "idx", "]", ")", "\n", "prev_idx", "=", "idx", "\n", "", "objective", "=", "max_length", "-", "1", "-", "len", "(", "idx_by_sentence", "[", "0", "]", ")", "# The last sep_token left out", "\n", "truncated_sentences", "=", "longest_first_truncation", "(", "idx_by_sentence", "[", "1", ":", "]", ",", "objective", ")", "\n", "truncated_paragraph", "=", "torch", ".", "cat", "(", "[", "idx_by_sentence", "[", "0", "]", "]", "+", "truncated_sentences", "+", "[", "torch", ".", "tensor", "(", "[", "sep_token_id", "]", ")", "]", ",", "0", ")", "\n", "all_paragraphs", ".", "append", "(", "truncated_paragraph", ".", "unsqueeze", "(", "0", ")", ")", "\n", "\n", "", "", "return", "torch", ".", "cat", "(", "all_paragraphs", ",", "0", ")", "\n", "\n", "", "inputs", "=", "zip", "(", "batch", "[", "\"claim\"", "]", ",", "batch", "[", "\"paragraph\"", "]", ")", "\n", "encoded_dict", "=", "tokenizer", ".", "batch_encode_plus", "(", "\n", "inputs", ",", "\n", "pad_to_max_length", "=", "True", ",", "add_special_tokens", "=", "True", ",", "\n", "return_tensors", "=", "'pt'", ")", "\n", "if", "encoded_dict", "[", "'input_ids'", "]", ".", "size", "(", "1", ")", ">", "max_sent_len", ":", "\n", "        ", "if", "'token_type_ids'", "in", "encoded_dict", ":", "\n", "            ", "encoded_dict", "=", "{", "\n", "\"input_ids\"", ":", "truncate", "(", "encoded_dict", "[", "'input_ids'", "]", ",", "max_sent_len", ",", "\n", "tokenizer", ".", "sep_token_id", ",", "tokenizer", ".", "pad_token_id", ")", ",", "\n", "'token_type_ids'", ":", "encoded_dict", "[", "'token_type_ids'", "]", "[", ":", ",", ":", "max_sent_len", "]", ",", "\n", "'attention_mask'", ":", "encoded_dict", "[", "'attention_mask'", "]", "[", ":", ",", ":", "max_sent_len", "]", "\n", "}", "\n", "", "else", ":", "\n", "            ", "encoded_dict", "=", "{", "\n", "\"input_ids\"", ":", "truncate", "(", "encoded_dict", "[", "'input_ids'", "]", ",", "max_sent_len", ",", "\n", "tokenizer", ".", "sep_token_id", ",", "tokenizer", ".", "pad_token_id", ")", ",", "\n", "'attention_mask'", ":", "encoded_dict", "[", "'attention_mask'", "]", "[", ":", ",", ":", "max_sent_len", "]", "\n", "}", "\n", "\n", "", "", "return", "encoded_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.FEVER_joint_paragraph_dynamic.token_idx_by_sentence": [[137, 165], ["torch.sum().numpy().tolist", "torch.sum().numpy().tolist", "torch.sum().numpy().tolist", "torch.arange().unsqueeze().expand", "torch.arange().unsqueeze().expand", "torch.arange().unsqueeze().expand", "torch.split", "torch.split", "torch.split", "torch.utils.rnn.pad_sequence", "torch.split", "torch.split", "torch.split", "torch.utils.rnn.pad_sequence", "torch.arange().unsqueeze().unsqueeze().expand", "torch.arange().unsqueeze().unsqueeze().expand", "torch.arange().unsqueeze().unsqueeze().expand", "sep_tokens.size", "torch.sum().numpy().tolist.append", "all_word_indices.extend", "nn.utils.rnn.pad_sequence.size", "nn.utils.rnn.pad_sequence.size", "torch.arange().unsqueeze().unsqueeze().expand.long", "nn.utils.rnn.pad_sequence.long", "mask.long", "torch.sum().numpy", "torch.sum().numpy", "torch.sum().numpy", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange", "torch.arange", "torch.arange", "len", "torch.arange().unsqueeze().unsqueeze", "torch.arange().unsqueeze().unsqueeze", "torch.arange().unsqueeze().unsqueeze", "range", "torch.sum", "torch.sum", "torch.sum", "torch.arange", "torch.arange", "torch.arange", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "sep_tokens.size", "paragraph.size", "torch.arange", "torch.arange", "torch.arange", "sep_tokens.size"], "function", ["None"], ["", "def", "token_idx_by_sentence", "(", "input_ids", ",", "sep_token_id", ",", "model_name", ")", ":", "\n", "    ", "\"\"\"\n    Compute the token indices matrix of the BERT output.\n    input_ids: (batch_size, paragraph_len)\n    batch_indices, indices_by_batch, mask: (batch_size, N_sentence, N_token)\n    bert_out: (batch_size, paragraph_len,BERT_dim)\n    bert_out[batch_indices,indices_by_batch,:]: (batch_size, N_sentence, N_token, BERT_dim)\n    \"\"\"", "\n", "padding_idx", "=", "-", "1", "\n", "sep_tokens", "=", "(", "input_ids", "==", "sep_token_id", ")", ".", "bool", "(", ")", "\n", "paragraph_lens", "=", "torch", ".", "sum", "(", "sep_tokens", ",", "1", ")", ".", "numpy", "(", ")", ".", "tolist", "(", ")", "\n", "indices", "=", "torch", ".", "arange", "(", "sep_tokens", ".", "size", "(", "-", "1", ")", ")", ".", "unsqueeze", "(", "0", ")", ".", "expand", "(", "sep_tokens", ".", "size", "(", "0", ")", ",", "-", "1", ")", "\n", "sep_indices", "=", "torch", ".", "split", "(", "indices", "[", "sep_tokens", "]", ",", "paragraph_lens", ")", "\n", "paragraph_lens", "=", "[", "]", "\n", "all_word_indices", "=", "[", "]", "\n", "for", "paragraph", "in", "sep_indices", ":", "\n", "        ", "if", "\"roberta\"", "in", "model_name", ":", "\n", "            ", "paragraph", "=", "paragraph", "[", "1", ":", "]", "\n", "", "word_indices", "=", "[", "torch", ".", "arange", "(", "paragraph", "[", "i", "]", "+", "1", ",", "paragraph", "[", "i", "+", "1", "]", "+", "1", ")", "for", "i", "in", "range", "(", "paragraph", ".", "size", "(", "0", ")", "-", "1", ")", "]", "\n", "paragraph_lens", ".", "append", "(", "len", "(", "word_indices", ")", ")", "\n", "all_word_indices", ".", "extend", "(", "word_indices", ")", "\n", "", "indices_by_sentence", "=", "nn", ".", "utils", ".", "rnn", ".", "pad_sequence", "(", "all_word_indices", ",", "batch_first", "=", "True", ",", "padding_value", "=", "padding_idx", ")", "\n", "indices_by_sentence_split", "=", "torch", ".", "split", "(", "indices_by_sentence", ",", "paragraph_lens", ")", "\n", "indices_by_batch", "=", "nn", ".", "utils", ".", "rnn", ".", "pad_sequence", "(", "indices_by_sentence_split", ",", "batch_first", "=", "True", ",", "padding_value", "=", "padding_idx", ")", "\n", "batch_indices", "=", "torch", ".", "arange", "(", "sep_tokens", ".", "size", "(", "0", ")", ")", ".", "unsqueeze", "(", "-", "1", ")", ".", "unsqueeze", "(", "-", "1", ")", ".", "expand", "(", "-", "1", ",", "indices_by_batch", ".", "size", "(", "1", ")", ",", "indices_by_batch", ".", "size", "(", "-", "1", ")", ")", "\n", "mask", "=", "(", "indices_by_batch", ">=", "0", ")", "\n", "\n", "return", "batch_indices", ".", "long", "(", ")", ",", "indices_by_batch", ".", "long", "(", ")", ",", "mask", ".", "long", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.scifact_rationale_paragraph.reset_random_seed": [[25, 29], ["numpy.random.seed", "random.seed", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed"], "function", ["None"], ["def", "reset_random_seed", "(", "seed", ")", ":", "\n", "    ", "np", ".", "random", ".", "seed", "(", "seed", ")", "\n", "random", ".", "seed", "(", "seed", ")", "\n", "torch", ".", "manual_seed", "(", "seed", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.scifact_rationale_paragraph.batch_rationale_label": [[30, 39], ["max", "enumerate", "torch.ones", "torch.ones", "torch.ones", "enumerate", "label_list.append", "label_matrix.long", "len", "len", "int", "int"], "function", ["None"], ["", "def", "batch_rationale_label", "(", "labels", ",", "padding_idx", "=", "2", ")", ":", "\n", "    ", "max_sent_len", "=", "max", "(", "[", "len", "(", "label", ")", "for", "label", "in", "labels", "]", ")", "\n", "label_matrix", "=", "torch", ".", "ones", "(", "len", "(", "labels", ")", ",", "max_sent_len", ")", "*", "padding_idx", "\n", "label_list", "=", "[", "]", "\n", "for", "i", ",", "label", "in", "enumerate", "(", "labels", ")", ":", "\n", "        ", "for", "j", ",", "evid", "in", "enumerate", "(", "label", ")", ":", "\n", "            ", "label_matrix", "[", "i", ",", "j", "]", "=", "int", "(", "evid", ")", "\n", "", "label_list", ".", "append", "(", "[", "int", "(", "evid", ")", "for", "evid", "in", "label", "]", ")", "\n", "", "return", "label_matrix", ".", "long", "(", ")", ",", "label_list", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.scifact_rationale_paragraph.predict": [[40, 55], ["model.eval", "torch.no_grad", "torch.no_grad", "torch.no_grad", "tqdm.tqdm", "torch.utils.data.DataLoader", "scifact_rationale_paragraph.encode", "scifact_rationale_paragraph.token_idx_by_sentence", "model", "rationale_predictions.extend", "tensor.to", "tensor.to", "encode.items"], "function", ["home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.label_prediction.transformer_scifact.encode", "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.FEVER_stance_paragraph.token_idx_by_sentence"], ["", "def", "predict", "(", "model", ",", "dataset", ")", ":", "\n", "    ", "model", ".", "eval", "(", ")", "\n", "rationale_predictions", "=", "[", "]", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "for", "batch", "in", "tqdm", "(", "DataLoader", "(", "dataset", ",", "batch_size", "=", "args", ".", "batch_size", ",", "shuffle", "=", "False", ")", ")", ":", "\n", "            ", "encoded_dict", "=", "encode", "(", "tokenizer", ",", "batch", ")", "\n", "transformation_indices", "=", "token_idx_by_sentence", "(", "encoded_dict", "[", "\"input_ids\"", "]", ",", "\n", "tokenizer", ".", "sep_token_id", ",", "args", ".", "repfile", ")", "\n", "encoded_dict", "=", "{", "key", ":", "tensor", ".", "to", "(", "device", ")", "for", "key", ",", "tensor", "in", "encoded_dict", ".", "items", "(", ")", "}", "\n", "transformation_indices", "=", "[", "tensor", ".", "to", "(", "device", ")", "for", "tensor", "in", "transformation_indices", "]", "\n", "rationale_out", ",", "_", "=", "model", "(", "encoded_dict", ",", "transformation_indices", ")", "\n", "rationale_predictions", ".", "extend", "(", "rationale_out", ")", "\n", "\n", "", "", "return", "rationale_predictions", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.scifact_rationale_paragraph.evaluation": [[56, 80], ["model.eval", "sklearn.metrics.f1_score", "sklearn.metrics.precision_score", "sklearn.metrics.recall_score", "torch.no_grad", "torch.no_grad", "torch.no_grad", "tqdm.tqdm", "util.flatten", "util.flatten", "util.flatten", "util.flatten", "util.flatten", "util.flatten", "torch.utils.data.DataLoader", "scifact_rationale_paragraph.encode", "scifact_rationale_paragraph.token_idx_by_sentence", "scifact_rationale_paragraph.batch_rationale_label", "model", "rationale_predictions.extend", "rationale_labels.extend", "tensor.to", "tensor.to", "encode.items", "padded_rationale_label.to"], "function", ["home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.util.flatten", "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.util.flatten", "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.util.flatten", "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.util.flatten", "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.util.flatten", "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.util.flatten", "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.label_prediction.transformer_scifact.encode", "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.FEVER_stance_paragraph.token_idx_by_sentence", "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.domain_adaptation_joint_paragraph_fine_tune.batch_rationale_label"], ["", "def", "evaluation", "(", "model", ",", "dataset", ")", ":", "\n", "    ", "model", ".", "eval", "(", ")", "\n", "rationale_predictions", "=", "[", "]", "\n", "rationale_labels", "=", "[", "]", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "for", "batch", "in", "tqdm", "(", "DataLoader", "(", "dataset", ",", "batch_size", "=", "args", ".", "batch_size", "*", "5", ",", "shuffle", "=", "False", ")", ")", ":", "\n", "            ", "encoded_dict", "=", "encode", "(", "tokenizer", ",", "batch", ")", "\n", "transformation_indices", "=", "token_idx_by_sentence", "(", "encoded_dict", "[", "\"input_ids\"", "]", ",", "\n", "tokenizer", ".", "sep_token_id", ",", "args", ".", "repfile", ")", "\n", "encoded_dict", "=", "{", "key", ":", "tensor", ".", "to", "(", "device", ")", "for", "key", ",", "tensor", "in", "encoded_dict", ".", "items", "(", ")", "}", "\n", "transformation_indices", "=", "[", "tensor", ".", "to", "(", "device", ")", "for", "tensor", "in", "transformation_indices", "]", "\n", "padded_rationale_label", ",", "rationale_label", "=", "batch_rationale_label", "(", "batch", "[", "\"label\"", "]", ",", "padding_idx", "=", "2", ")", "\n", "rationale_out", ",", "rationale_loss", "=", "model", "(", "encoded_dict", ",", "transformation_indices", ",", "\n", "rationale_label", "=", "padded_rationale_label", ".", "to", "(", "device", ")", ")", "\n", "\n", "rationale_predictions", ".", "extend", "(", "rationale_out", ")", "\n", "rationale_labels", ".", "extend", "(", "rationale_label", ")", "\n", "\n", "", "", "rationale_f1", "=", "f1_score", "(", "flatten", "(", "rationale_labels", ")", ",", "flatten", "(", "rationale_predictions", ")", ")", "\n", "rationale_precision", "=", "precision_score", "(", "flatten", "(", "rationale_labels", ")", ",", "flatten", "(", "rationale_predictions", ")", ")", "\n", "rationale_recall", "=", "recall_score", "(", "flatten", "(", "rationale_labels", ")", ",", "flatten", "(", "rationale_predictions", ")", ")", "\n", "return", "rationale_f1", ",", "rationale_precision", ",", "rationale_recall", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.scifact_rationale_paragraph.encode": [[83, 132], ["zip", "tokenizer.batch_encode_plus", "torch.cat", "torch.cat", "torch.cat", "encoded_dict[].size", "len", "numpy.sum", "numpy.argmax", "valid_paragraph.size", "all_paragraphs.append", "longest_first_truncation"], "function", ["home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.dataset.encode.longest_first_truncation"], ["", "def", "encode", "(", "tokenizer", ",", "batch", ",", "max_sent_len", "=", "512", ")", ":", "\n", "    ", "def", "truncate", "(", "input_ids", ",", "max_length", ",", "sep_token_id", ",", "pad_token_id", ")", ":", "\n", "        ", "def", "longest_first_truncation", "(", "sentences", ",", "objective", ")", ":", "\n", "            ", "sent_lens", "=", "[", "len", "(", "sent", ")", "for", "sent", "in", "sentences", "]", "\n", "while", "np", ".", "sum", "(", "sent_lens", ")", ">", "objective", ":", "\n", "                ", "max_position", "=", "np", ".", "argmax", "(", "sent_lens", ")", "\n", "sent_lens", "[", "max_position", "]", "-=", "1", "\n", "", "return", "[", "sentence", "[", ":", "length", "]", "for", "sentence", ",", "length", "in", "zip", "(", "sentences", ",", "sent_lens", ")", "]", "\n", "\n", "", "all_paragraphs", "=", "[", "]", "\n", "for", "paragraph", "in", "input_ids", ":", "\n", "            ", "valid_paragraph", "=", "paragraph", "[", "paragraph", "!=", "pad_token_id", "]", "\n", "if", "valid_paragraph", ".", "size", "(", "0", ")", "<=", "max_length", ":", "\n", "                ", "all_paragraphs", ".", "append", "(", "paragraph", "[", ":", "max_length", "]", ".", "unsqueeze", "(", "0", ")", ")", "\n", "", "else", ":", "\n", "                ", "sep_token_idx", "=", "np", ".", "arange", "(", "valid_paragraph", ".", "size", "(", "0", ")", ")", "[", "(", "valid_paragraph", "==", "sep_token_id", ")", ".", "numpy", "(", ")", "]", "\n", "idx_by_sentence", "=", "[", "]", "\n", "prev_idx", "=", "0", "\n", "for", "idx", "in", "sep_token_idx", ":", "\n", "                    ", "idx_by_sentence", ".", "append", "(", "paragraph", "[", "prev_idx", ":", "idx", "]", ")", "\n", "prev_idx", "=", "idx", "\n", "", "objective", "=", "max_length", "-", "1", "-", "len", "(", "idx_by_sentence", "[", "0", "]", ")", "# The last sep_token left out", "\n", "truncated_sentences", "=", "longest_first_truncation", "(", "idx_by_sentence", "[", "1", ":", "]", ",", "objective", ")", "\n", "truncated_paragraph", "=", "torch", ".", "cat", "(", "[", "idx_by_sentence", "[", "0", "]", "]", "+", "truncated_sentences", "+", "[", "torch", ".", "tensor", "(", "[", "sep_token_id", "]", ")", "]", ",", "0", ")", "\n", "all_paragraphs", ".", "append", "(", "truncated_paragraph", ".", "unsqueeze", "(", "0", ")", ")", "\n", "\n", "", "", "return", "torch", ".", "cat", "(", "all_paragraphs", ",", "0", ")", "\n", "\n", "", "inputs", "=", "zip", "(", "batch", "[", "\"claim\"", "]", ",", "batch", "[", "\"paragraph\"", "]", ")", "\n", "encoded_dict", "=", "tokenizer", ".", "batch_encode_plus", "(", "\n", "inputs", ",", "\n", "pad_to_max_length", "=", "True", ",", "add_special_tokens", "=", "True", ",", "\n", "return_tensors", "=", "'pt'", ")", "\n", "if", "encoded_dict", "[", "'input_ids'", "]", ".", "size", "(", "1", ")", ">", "max_sent_len", ":", "\n", "        ", "if", "'token_type_ids'", "in", "encoded_dict", ":", "\n", "            ", "encoded_dict", "=", "{", "\n", "\"input_ids\"", ":", "truncate", "(", "encoded_dict", "[", "'input_ids'", "]", ",", "max_sent_len", ",", "\n", "tokenizer", ".", "sep_token_id", ",", "tokenizer", ".", "pad_token_id", ")", ",", "\n", "'token_type_ids'", ":", "encoded_dict", "[", "'token_type_ids'", "]", "[", ":", ",", ":", "max_sent_len", "]", ",", "\n", "'attention_mask'", ":", "encoded_dict", "[", "'attention_mask'", "]", "[", ":", ",", ":", "max_sent_len", "]", "\n", "}", "\n", "", "else", ":", "\n", "            ", "encoded_dict", "=", "{", "\n", "\"input_ids\"", ":", "truncate", "(", "encoded_dict", "[", "'input_ids'", "]", ",", "max_sent_len", ",", "\n", "tokenizer", ".", "sep_token_id", ",", "tokenizer", ".", "pad_token_id", ")", ",", "\n", "'attention_mask'", ":", "encoded_dict", "[", "'attention_mask'", "]", "[", ":", ",", ":", "max_sent_len", "]", "\n", "}", "\n", "\n", "", "", "return", "encoded_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.scifact_rationale_paragraph.sent_rep_indices": [[133, 155], ["torch.sum().numpy().tolist", "torch.sum().numpy().tolist", "torch.sum().numpy().tolist", "torch.arange().unsqueeze().expand", "torch.arange().unsqueeze().expand", "torch.arange().unsqueeze().expand", "torch.split", "torch.split", "torch.split", "torch.utils.rnn.pad_sequence", "torch.arange().unsqueeze().expand", "torch.arange().unsqueeze().expand", "torch.arange().unsqueeze().expand", "sep_tokens.size", "nn.utils.rnn.pad_sequence.size", "torch.sum().numpy", "torch.sum().numpy", "torch.sum().numpy", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.sum", "torch.sum", "torch.sum", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "sep_tokens.size", "nn.utils.rnn.pad_sequence.size"], "function", ["None"], ["", "def", "sent_rep_indices", "(", "input_ids", ",", "sep_token_id", ",", "model_name", ")", ":", "\n", "\n", "    ", "\"\"\"\n    Compute the [SEP] indices matrix of the BERT output.\n    input_ids: (batch_size, paragraph_len)\n    batch_indices, indices_by_batch, mask: (batch_size, N_sentence)\n    bert_out: (batch_size, paragraph_len,BERT_dim)\n    bert_out[batch_indices,indices_by_batch,:]: (batch_size, N_sentence, BERT_dim)\n    \"\"\"", "\n", "\n", "sep_tokens", "=", "(", "input_ids", "==", "sep_token_id", ")", ".", "bool", "(", ")", "\n", "paragraph_lens", "=", "torch", ".", "sum", "(", "sep_tokens", ",", "1", ")", ".", "numpy", "(", ")", ".", "tolist", "(", ")", "\n", "indices", "=", "torch", ".", "arange", "(", "sep_tokens", ".", "size", "(", "-", "1", ")", ")", ".", "unsqueeze", "(", "0", ")", ".", "expand", "(", "sep_tokens", ".", "size", "(", "0", ")", ",", "-", "1", ")", "\n", "sep_indices", "=", "torch", ".", "split", "(", "indices", "[", "sep_tokens", "]", ",", "paragraph_lens", ")", "\n", "padded_sep_indices", "=", "nn", ".", "utils", ".", "rnn", ".", "pad_sequence", "(", "sep_indices", ",", "batch_first", "=", "True", ",", "padding_value", "=", "-", "1", ")", "\n", "batch_indices", "=", "torch", ".", "arange", "(", "padded_sep_indices", ".", "size", "(", "0", ")", ")", ".", "unsqueeze", "(", "-", "1", ")", ".", "expand", "(", "-", "1", ",", "padded_sep_indices", ".", "size", "(", "-", "1", ")", ")", "\n", "mask", "=", "(", "padded_sep_indices", ">=", "0", ")", ".", "long", "(", ")", "\n", "\n", "if", "\"roberta\"", "in", "model_name", ":", "\n", "        ", "return", "batch_indices", "[", ":", ",", "2", ":", "]", ",", "padded_sep_indices", "[", ":", ",", "2", ":", "]", ",", "mask", "[", ":", ",", "2", ":", "]", "\n", "", "else", ":", "\n", "        ", "return", "batch_indices", "[", ":", ",", "1", ":", "]", ",", "padded_sep_indices", "[", ":", ",", "1", ":", "]", ",", "mask", "[", ":", ",", "1", ":", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.scifact_rationale_paragraph.token_idx_by_sentence": [[156, 184], ["torch.sum().numpy().tolist", "torch.sum().numpy().tolist", "torch.sum().numpy().tolist", "torch.arange().unsqueeze().expand", "torch.arange().unsqueeze().expand", "torch.arange().unsqueeze().expand", "torch.split", "torch.split", "torch.split", "torch.utils.rnn.pad_sequence", "torch.split", "torch.split", "torch.split", "torch.utils.rnn.pad_sequence", "torch.arange().unsqueeze().unsqueeze().expand", "torch.arange().unsqueeze().unsqueeze().expand", "torch.arange().unsqueeze().unsqueeze().expand", "sep_tokens.size", "torch.sum().numpy().tolist.append", "all_word_indices.extend", "nn.utils.rnn.pad_sequence.size", "nn.utils.rnn.pad_sequence.size", "torch.arange().unsqueeze().unsqueeze().expand.long", "nn.utils.rnn.pad_sequence.long", "mask.long", "torch.sum().numpy", "torch.sum().numpy", "torch.sum().numpy", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange", "torch.arange", "torch.arange", "len", "torch.arange().unsqueeze().unsqueeze", "torch.arange().unsqueeze().unsqueeze", "torch.arange().unsqueeze().unsqueeze", "range", "torch.sum", "torch.sum", "torch.sum", "torch.arange", "torch.arange", "torch.arange", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "sep_tokens.size", "paragraph.size", "torch.arange", "torch.arange", "torch.arange", "sep_tokens.size"], "function", ["None"], ["", "", "def", "token_idx_by_sentence", "(", "input_ids", ",", "sep_token_id", ",", "model_name", ")", ":", "\n", "    ", "\"\"\"\n    Compute the token indices matrix of the BERT output.\n    input_ids: (batch_size, paragraph_len)\n    batch_indices, indices_by_batch, mask: (batch_size, N_sentence, N_token)\n    bert_out: (batch_size, paragraph_len,BERT_dim)\n    bert_out[batch_indices,indices_by_batch,:]: (batch_size, N_sentence, N_token, BERT_dim)\n    \"\"\"", "\n", "padding_idx", "=", "-", "1", "\n", "sep_tokens", "=", "(", "input_ids", "==", "sep_token_id", ")", ".", "bool", "(", ")", "\n", "paragraph_lens", "=", "torch", ".", "sum", "(", "sep_tokens", ",", "1", ")", ".", "numpy", "(", ")", ".", "tolist", "(", ")", "\n", "indices", "=", "torch", ".", "arange", "(", "sep_tokens", ".", "size", "(", "-", "1", ")", ")", ".", "unsqueeze", "(", "0", ")", ".", "expand", "(", "sep_tokens", ".", "size", "(", "0", ")", ",", "-", "1", ")", "\n", "sep_indices", "=", "torch", ".", "split", "(", "indices", "[", "sep_tokens", "]", ",", "paragraph_lens", ")", "\n", "paragraph_lens", "=", "[", "]", "\n", "all_word_indices", "=", "[", "]", "\n", "for", "paragraph", "in", "sep_indices", ":", "\n", "        ", "if", "\"large\"", "in", "model_name", ":", "\n", "            ", "paragraph", "=", "paragraph", "[", "1", ":", "]", "\n", "", "word_indices", "=", "[", "torch", ".", "arange", "(", "paragraph", "[", "i", "]", "+", "1", ",", "paragraph", "[", "i", "+", "1", "]", "+", "1", ")", "for", "i", "in", "range", "(", "paragraph", ".", "size", "(", "0", ")", "-", "1", ")", "]", "\n", "paragraph_lens", ".", "append", "(", "len", "(", "word_indices", ")", ")", "\n", "all_word_indices", ".", "extend", "(", "word_indices", ")", "\n", "", "indices_by_sentence", "=", "nn", ".", "utils", ".", "rnn", ".", "pad_sequence", "(", "all_word_indices", ",", "batch_first", "=", "True", ",", "padding_value", "=", "padding_idx", ")", "\n", "indices_by_sentence_split", "=", "torch", ".", "split", "(", "indices_by_sentence", ",", "paragraph_lens", ")", "\n", "indices_by_batch", "=", "nn", ".", "utils", ".", "rnn", ".", "pad_sequence", "(", "indices_by_sentence_split", ",", "batch_first", "=", "True", ",", "padding_value", "=", "padding_idx", ")", "\n", "batch_indices", "=", "torch", ".", "arange", "(", "sep_tokens", ".", "size", "(", "0", ")", ")", ".", "unsqueeze", "(", "-", "1", ")", ".", "unsqueeze", "(", "-", "1", ")", ".", "expand", "(", "-", "1", ",", "indices_by_batch", ".", "size", "(", "1", ")", ",", "indices_by_batch", ".", "size", "(", "-", "1", ")", ")", "\n", "mask", "=", "(", "indices_by_batch", ">=", "0", ")", "\n", "\n", "return", "batch_indices", ".", "long", "(", ")", ",", "indices_by_batch", ".", "long", "(", ")", ",", "mask", ".", "long", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.paragraph_model_dynamic.TimeDistributed.__init__": [[21, 25], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.label_prediction.transformer_scifact.SciFactLabelPredictionDataset.__init__"], ["    ", "def", "__init__", "(", "self", ",", "module", ",", "batch_first", "=", "False", ")", ":", "\n", "        ", "super", "(", "TimeDistributed", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "module", "=", "module", "\n", "self", ".", "batch_first", "=", "batch_first", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.paragraph_model_dynamic.TimeDistributed.forward": [[26, 43], ["x.contiguous().view", "paragraph_model_dynamic.TimeDistributed.module", "len", "paragraph_model_dynamic.TimeDistributed.module", "x.size", "y.view.view.contiguous().view", "y.view.view.view", "x.size", "x.contiguous", "x.size", "y.view.view.size", "x.size", "y.view.view.size", "y.view.view.contiguous"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "\n", "        ", "if", "len", "(", "x", ".", "size", "(", ")", ")", "<=", "2", ":", "\n", "            ", "return", "self", ".", "module", "(", "x", ")", "\n", "\n", "# Squash samples and timesteps into a single axis", "\n", "", "x_reshape", "=", "x", ".", "contiguous", "(", ")", ".", "view", "(", "-", "1", ",", "x", ".", "size", "(", "-", "1", ")", ")", "# (samples * timesteps, input_size)", "\n", "\n", "y", "=", "self", ".", "module", "(", "x_reshape", ")", "\n", "\n", "# We have to reshape Y", "\n", "if", "self", ".", "batch_first", ":", "\n", "            ", "y", "=", "y", ".", "contiguous", "(", ")", ".", "view", "(", "x", ".", "size", "(", "0", ")", ",", "-", "1", ",", "y", ".", "size", "(", "-", "1", ")", ")", "# (samples, timesteps, output_size)", "\n", "", "else", ":", "\n", "            ", "y", "=", "y", ".", "view", "(", "-", "1", ",", "x", ".", "size", "(", "1", ")", ",", "y", ".", "size", "(", "-", "1", ")", ")", "# (timesteps, samples, output_size)", "\n", "\n", "", "return", "y", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.paragraph_model_dynamic.TimeDistributedDense.__init__": [[45, 51], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear", "paragraph_model_dynamic.TimeDistributed"], "methods", ["home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.label_prediction.transformer_scifact.SciFactLabelPredictionDataset.__init__"], ["    ", "def", "__init__", "(", "self", ",", "INPUT_SIZE", ",", "OUTPUT_SIZE", ")", ":", "\n", "        ", "super", "(", "TimeDistributedDense", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "input_size", "=", "INPUT_SIZE", "\n", "self", ".", "output_size", "=", "OUTPUT_SIZE", "\n", "self", ".", "linear", "=", "nn", ".", "Linear", "(", "INPUT_SIZE", ",", "OUTPUT_SIZE", ",", "bias", "=", "True", ")", "\n", "self", ".", "timedistributedlayer", "=", "TimeDistributed", "(", "self", ".", "linear", ")", "\n", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.paragraph_model_dynamic.TimeDistributedDense.forward": [[51, 55], ["paragraph_model_dynamic.TimeDistributedDense.timedistributedlayer"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "# x: (BATCH_SIZE, ARRAY_LEN, INPUT_SIZE)", "\n", "\n", "        ", "return", "self", ".", "timedistributedlayer", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.paragraph_model_dynamic.ClassificationHead.__init__": [[59, 64], ["torch.Module.__init__", "paragraph_model_dynamic.TimeDistributedDense", "torch.Dropout", "torch.Dropout", "torch.Dropout", "paragraph_model_dynamic.TimeDistributedDense"], "methods", ["home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.label_prediction.transformer_scifact.SciFactLabelPredictionDataset.__init__"], ["def", "__init__", "(", "self", ",", "hidden_size", ",", "num_labels", ",", "hidden_dropout_prob", "=", "0.1", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dense", "=", "TimeDistributedDense", "(", "hidden_size", ",", "hidden_size", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "hidden_dropout_prob", ")", "\n", "self", ".", "out_proj", "=", "TimeDistributedDense", "(", "hidden_size", ",", "num_labels", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.paragraph_model_dynamic.ClassificationHead.forward": [[65, 72], ["paragraph_model_dynamic.ClassificationHead.dropout", "paragraph_model_dynamic.ClassificationHead.dense", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "paragraph_model_dynamic.ClassificationHead.dropout", "paragraph_model_dynamic.ClassificationHead.out_proj"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "**", "kwargs", ")", ":", "\n", "        ", "x", "=", "self", ".", "dropout", "(", "x", ")", "\n", "x", "=", "self", ".", "dense", "(", "x", ")", "\n", "x", "=", "torch", ".", "tanh", "(", "x", ")", "\n", "x", "=", "self", ".", "dropout", "(", "x", ")", "\n", "x", "=", "self", ".", "out_proj", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.paragraph_model_dynamic.WordAttention.__init__": [[81, 87], ["torch.Module.__init__", "paragraph_model_dynamic.TimeDistributedDense", "torch.Dropout", "torch.Dropout", "torch.Dropout", "paragraph_model_dynamic.TimeDistributedDense"], "methods", ["home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.label_prediction.transformer_scifact.SciFactLabelPredictionDataset.__init__"], ["def", "__init__", "(", "self", ",", "INPUT_SIZE", ",", "PROJ_SIZE", ",", "dropout", "=", "0.1", ")", ":", "\n", "        ", "super", "(", "WordAttention", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "activation", "=", "torch", ".", "tanh", "\n", "self", ".", "att_proj", "=", "TimeDistributedDense", "(", "INPUT_SIZE", ",", "PROJ_SIZE", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "dropout", ")", "\n", "self", ".", "att_scorer", "=", "TimeDistributedDense", "(", "PROJ_SIZE", ",", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.paragraph_model_dynamic.WordAttention.forward": [[88, 100], ["paragraph_model_dynamic.WordAttention.att_proj", "paragraph_model_dynamic.WordAttention.dropout", "paragraph_model_dynamic.WordAttention.att_scorer().squeeze().view", "torch.softmax", "torch.softmax", "torch.softmax", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where.view", "torch.where.view", "torch.where.view", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "out.view.view.view", "paragraph_model_dynamic.WordAttention.dropout", "paragraph_model_dynamic.WordAttention.activation", "x.size", "x.size", "x.size", "paragraph_model_dynamic.WordAttention.masked_fill", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.where.size", "torch.where.size", "torch.where.size", "x.size", "x.size", "x.size", "x.view", "paragraph_model_dynamic.WordAttention.att_scorer().squeeze", "float", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "x.size", "torch.where.view.unsqueeze", "x.view", "paragraph_model_dynamic.WordAttention.att_scorer", "x.size", "x.size"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "token_mask", ")", ":", "\n", "        ", "proj_input", "=", "self", ".", "att_proj", "(", "self", ".", "dropout", "(", "x", ".", "view", "(", "-", "1", ",", "x", ".", "size", "(", "-", "1", ")", ")", ")", ")", "\n", "proj_input", "=", "self", ".", "dropout", "(", "self", ".", "activation", "(", "proj_input", ")", ")", "\n", "raw_att_scores", "=", "self", ".", "att_scorer", "(", "proj_input", ")", ".", "squeeze", "(", "-", "1", ")", ".", "view", "(", "x", ".", "size", "(", "0", ")", ",", "x", ".", "size", "(", "1", ")", ",", "x", ".", "size", "(", "2", ")", ")", "# (Batch_size, N_sentence, N_token)", "\n", "att_scores", "=", "F", ".", "softmax", "(", "raw_att_scores", ".", "masked_fill", "(", "(", "1", "-", "token_mask", ")", ".", "bool", "(", ")", ",", "float", "(", "'-inf'", ")", ")", ",", "dim", "=", "-", "1", ")", "\n", "att_scores", "=", "torch", ".", "where", "(", "torch", ".", "isnan", "(", "att_scores", ")", ",", "torch", ".", "zeros_like", "(", "att_scores", ")", ",", "att_scores", ")", "# Replace NaN with 0", "\n", "batch_att_scores", "=", "att_scores", ".", "view", "(", "-", "1", ",", "att_scores", ".", "size", "(", "-", "1", ")", ")", "# (Batch_size * N_sentence, N_token)", "\n", "out", "=", "torch", ".", "bmm", "(", "batch_att_scores", ".", "unsqueeze", "(", "1", ")", ",", "x", ".", "view", "(", "-", "1", ",", "x", ".", "size", "(", "2", ")", ",", "x", ".", "size", "(", "3", ")", ")", ")", ".", "squeeze", "(", "1", ")", "\n", "# (Batch_size * N_sentence, INPUT_SIZE)", "\n", "out", "=", "out", ".", "view", "(", "x", ".", "size", "(", "0", ")", ",", "x", ".", "size", "(", "1", ")", ",", "x", ".", "size", "(", "-", "1", ")", ")", "\n", "mask", "=", "token_mask", "[", ":", ",", ":", ",", "0", "]", "\n", "return", "out", ",", "mask", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.paragraph_model_dynamic.DynamicSentenceAttention.__init__": [[106, 119], ["torch.Module.__init__", "paragraph_model_dynamic.TimeDistributedDense", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.LSTM", "torch.LSTM", "torch.LSTM", "paragraph_model_dynamic.TimeDistributedDense", "paragraph_model_dynamic.TimeDistributedDense"], "methods", ["home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.label_prediction.transformer_scifact.SciFactLabelPredictionDataset.__init__"], ["def", "__init__", "(", "self", ",", "INPUT_SIZE", ",", "PROJ_SIZE", ",", "REC_HID_SIZE", "=", "None", ",", "dropout", "=", "0.1", ")", ":", "\n", "        ", "super", "(", "DynamicSentenceAttention", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "activation", "=", "torch", ".", "tanh", "\n", "self", ".", "att_proj", "=", "TimeDistributedDense", "(", "INPUT_SIZE", ",", "PROJ_SIZE", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "dropout", ")", "\n", "\n", "if", "REC_HID_SIZE", "is", "not", "None", ":", "\n", "            ", "self", ".", "contextualized", "=", "True", "\n", "self", ".", "lstm", "=", "nn", ".", "LSTM", "(", "PROJ_SIZE", ",", "REC_HID_SIZE", ",", "bidirectional", "=", "False", ",", "batch_first", "=", "True", ")", "\n", "self", ".", "att_scorer", "=", "TimeDistributedDense", "(", "REC_HID_SIZE", ",", "2", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "contextualized", "=", "False", "\n", "self", ".", "att_scorer", "=", "TimeDistributedDense", "(", "PROJ_SIZE", ",", "2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.paragraph_model_dynamic.DynamicSentenceAttention.forward": [[120, 140], ["torch.logical_and", "torch.logical_and", "torch.logical_and", "torch.logical_and", "torch.logical_and", "torch.logical_and", "torch.logical_and", "torch.logical_and", "torch.logical_and", "sentence_reps.size", "torch.softmax", "torch.softmax", "torch.softmax", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.softmax.masked_fill", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.softmax.unsqueeze"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "sentence_reps", ",", "sentence_mask", ",", "att_scores", ",", "valid_scores", ")", ":", "\n", "# sentence_reps: (BATCH_SIZE, N_sentence, INPUT_SIZE)", "\n", "# sentence_mask: (BATCH_SIZE, N_sentence)", "\n", "# att_scores: (BATCH_SIZE, N_sentence)", "\n", "# valid_scores: (BATCH_SIZE, N_sentence)", "\n", "# result: (BATCH_SIZE, INPUT_SIZE)", "\n", "#att_scores = rationale_out[:,:,1] # (BATCH_SIZE, N_sentence)", "\n", "#valid_scores = rationale_out[:,:,1] > rationale_out[:,:,0] # Only consider sentences predicted as rationales", "\n", "        ", "sentence_mask", "=", "torch", ".", "logical_and", "(", "sentence_mask", ",", "valid_scores", ")", "\n", "\n", "# Force those sentence representations in paragraph without rationale to be 0. ", "\n", "#NEI_mask = (torch.sum(sentence_mask, axis=1) > 0).long().unsqueeze(-1).expand(-1, sentence_reps.size(-1))", "\n", "\n", "if", "sentence_reps", ".", "size", "(", "0", ")", ">", "0", ":", "\n", "            ", "att_scores", "=", "F", ".", "softmax", "(", "att_scores", ".", "masked_fill", "(", "(", "~", "sentence_mask", ")", ".", "bool", "(", ")", ",", "-", "1e4", ")", ",", "dim", "=", "-", "1", ")", "\n", "#att_scores = torch.where(torch.isnan(att_scores), torch.zeros_like(att_scores), att_scores) # Replace NaN with 0", "\n", "result", "=", "torch", ".", "bmm", "(", "att_scores", ".", "unsqueeze", "(", "1", ")", ",", "sentence_reps", ")", ".", "squeeze", "(", "1", ")", "\n", "return", "result", "# * NEI_mask ", "\n", "", "else", ":", "\n", "            ", "return", "sentence_reps", "[", ":", ",", "0", ",", ":", "]", "# * NEI_mask", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.paragraph_model_dynamic.JointParagraphClassifier.__init__": [[143, 164], ["torch.Module.__init__", "transformers.AutoModel.from_pretrained", "torch.CrossEntropyLoss", "torch.CrossEntropyLoss", "torch.CrossEntropyLoss", "torch.CrossEntropyLoss", "torch.CrossEntropyLoss", "torch.CrossEntropyLoss", "paragraph_model_dynamic.DynamicSentenceAttention", "paragraph_model_dynamic.WordAttention", "paragraph_model_dynamic.ClassificationHead", "paragraph_model_dynamic.ClassificationHead"], "methods", ["home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.label_prediction.transformer_scifact.SciFactLabelPredictionDataset.__init__"], ["    ", "def", "__init__", "(", "self", ",", "bert_path", ",", "bert_dim", ",", "dropout", "=", "0.1", ",", "ignore_index", "=", "2", ")", ":", "\n", "        ", "super", "(", "JointParagraphClassifier", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "stance_label_size", "=", "3", "\n", "self", ".", "rationale_label_size", "=", "2", "\n", "self", ".", "ignore_index", "=", "2", "\n", "self", ".", "bert", "=", "AutoModel", ".", "from_pretrained", "(", "bert_path", ")", "\n", "self", ".", "stance_criterion", "=", "nn", ".", "CrossEntropyLoss", "(", ")", "\n", "self", ".", "rationale_criterion", "=", "nn", ".", "CrossEntropyLoss", "(", "ignore_index", "=", "2", ")", "\n", "self", ".", "dropout", "=", "dropout", "\n", "self", ".", "bert_dim", "=", "bert_dim", "\n", "self", ".", "sentence_attention", "=", "DynamicSentenceAttention", "(", "bert_dim", ",", "bert_dim", ",", "dropout", "=", "dropout", ")", "\n", "self", ".", "word_attention", "=", "WordAttention", "(", "bert_dim", ",", "bert_dim", ",", "dropout", "=", "dropout", ")", "\n", "self", ".", "rationale_linear", "=", "ClassificationHead", "(", "bert_dim", ",", "self", ".", "rationale_label_size", ",", "hidden_dropout_prob", "=", "dropout", ")", "\n", "self", ".", "stance_linear", "=", "ClassificationHead", "(", "bert_dim", ",", "self", ".", "stance_label_size", ",", "hidden_dropout_prob", "=", "dropout", ")", "\n", "self", ".", "extra_modules", "=", "[", "\n", "self", ".", "sentence_attention", ",", "\n", "self", ".", "word_attention", ",", "\n", "self", ".", "rationale_linear", ",", "\n", "self", ".", "stance_linear", ",", "\n", "self", ".", "stance_criterion", ",", "\n", "self", ".", "rationale_criterion", "\n", "]", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.paragraph_model_dynamic.JointParagraphClassifier.reinitialize": [[166, 178], ["paragraph_model_dynamic.ClassificationHead", "paragraph_model_dynamic.ClassificationHead", "paragraph_model_dynamic.DynamicSentenceAttention"], "methods", ["None"], ["", "def", "reinitialize", "(", "self", ")", ":", "\n", "        ", "self", ".", "extra_modules", "=", "[", "]", "\n", "self", ".", "rationale_linear", "=", "ClassificationHead", "(", "self", ".", "bert_dim", ",", "self", ".", "rationale_label_size", ",", "hidden_dropout_prob", "=", "self", ".", "dropout", ")", "\n", "self", ".", "stance_linear", "=", "ClassificationHead", "(", "self", ".", "bert_dim", ",", "self", ".", "stance_label_size", ",", "hidden_dropout_prob", "=", "self", ".", "dropout", ")", "\n", "self", ".", "sentence_attention", "=", "DynamicSentenceAttention", "(", "self", ".", "bert_dim", ",", "self", ".", "bert_dim", ",", "dropout", "=", "self", ".", "dropout", ")", "\n", "self", ".", "extra_modules", "=", "[", "\n", "self", ".", "rationale_linear", ",", "\n", "self", ".", "stance_linear", ",", "\n", "self", ".", "stance_criterion", ",", "\n", "self", ".", "rationale_criterion", ",", "\n", "self", ".", "word_attention", ",", "\n", "self", ".", "sentence_attention", "\n", "]", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.paragraph_model_dynamic.JointParagraphClassifier.forward": [[180, 217], ["paragraph_model_dynamic.JointParagraphClassifier.word_attention", "paragraph_model_dynamic.JointParagraphClassifier.rationale_linear", "bool", "paragraph_model_dynamic.JointParagraphClassifier.sentence_attention", "paragraph_model_dynamic.JointParagraphClassifier.stance_linear", "torch.argmax().detach().numpy().tolist", "torch.argmax().detach().numpy().tolist", "torch.argmax().detach().numpy().tolist", "torch.argmax().detach().numpy().tolist", "torch.argmax().detach().numpy().tolist", "torch.argmax().detach().numpy().tolist", "torch.argmax().detach().numpy().tolist", "torch.argmax().detach().numpy().tolist", "torch.argmax().detach().numpy().tolist", "paragraph_model_dynamic.JointParagraphClassifier.bert", "paragraph_model_dynamic.JointParagraphClassifier.stance_criterion", "paragraph_model_dynamic.JointParagraphClassifier.rationale_criterion", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "rationale_pred_paragraph[].detach().numpy().tolist", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "paragraph_model_dynamic.JointParagraphClassifier.view", "rationale_label.view", "torch.argmax().detach().numpy", "torch.argmax().detach().numpy", "torch.argmax().detach().numpy", "torch.argmax().detach().numpy", "torch.argmax().detach().numpy", "torch.argmax().detach().numpy", "torch.argmax().detach().numpy", "torch.argmax().detach().numpy", "torch.argmax().detach().numpy", "paragraph_model_dynamic.JointParagraphClassifier.cpu", "paragraph_model_dynamic.JointParagraphClassifier.cpu", "zip", "rationale_pred_paragraph[].detach().numpy", "sentence_mask.bool", "torch.argmax().detach", "torch.argmax().detach", "torch.argmax().detach", "torch.argmax().detach", "torch.argmax().detach", "torch.argmax().detach", "torch.argmax().detach", "torch.argmax().detach", "torch.argmax().detach", "rationale_pred_paragraph[].detach", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax().detach().numpy().tolist.cpu", "torch.argmax().detach().numpy().tolist.cpu", "torch.argmax().detach().numpy().tolist.cpu"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "encoded_dict", ",", "transformation_indices", ",", "stance_label", "=", "None", ",", "rationale_label", "=", "None", ",", "sample_p", "=", "1", ",", "rationale_score", "=", "False", ")", ":", "\n", "        ", "batch_indices", ",", "indices_by_batch", ",", "mask", "=", "transformation_indices", "# (batch_size, N_sep, N_token)", "\n", "bert_out", "=", "self", ".", "bert", "(", "**", "encoded_dict", ")", "[", "0", "]", "# (BATCH_SIZE, sequence_len, BERT_DIM)", "\n", "bert_tokens", "=", "bert_out", "[", "batch_indices", ",", "indices_by_batch", ",", ":", "]", "\n", "# bert_tokens: (batch_size, N_sep, N_token, BERT_dim)", "\n", "sentence_reps", ",", "sentence_mask", "=", "self", ".", "word_attention", "(", "bert_tokens", ",", "mask", ")", "\n", "# (Batch_size, N_sep, BERT_DIM), (Batch_size, N_sep)", "\n", "#print(bert_out.shape, bert_tokens.shape, sentence_reps.shape, sentence_mask.shape, rationale_label.shape)", "\n", "rationale_out", "=", "self", ".", "rationale_linear", "(", "sentence_reps", ")", "# (Batch_size, N_sep, 2)", "\n", "att_scores", "=", "rationale_out", "[", ":", ",", ":", ",", "1", "]", "# (BATCH_SIZE, N_sentence)", "\n", "\n", "if", "bool", "(", "torch", ".", "rand", "(", "1", ")", "<", "sample_p", ")", ":", "# Choose sentence according to predicted rationale", "\n", "            ", "valid_scores", "=", "rationale_out", "[", ":", ",", ":", ",", "1", "]", ">", "rationale_out", "[", ":", ",", ":", ",", "0", "]", "\n", "", "else", ":", "\n", "            ", "valid_scores", "=", "rationale_label", "==", "1", "# Ground truth", "\n", "", "paragraph_rep", "=", "self", ".", "sentence_attention", "(", "sentence_reps", ",", "sentence_mask", ",", "att_scores", ",", "valid_scores", ")", "\n", "# (BATCH_SIZE, BERT_DIM) ", "\n", "\n", "stance_out", "=", "self", ".", "stance_linear", "(", "paragraph_rep", ")", "# (Batch_size, 3)", "\n", "\n", "if", "stance_label", "is", "not", "None", ":", "\n", "            ", "stance_loss", "=", "self", ".", "stance_criterion", "(", "stance_out", ",", "stance_label", ")", "\n", "", "else", ":", "\n", "            ", "stance_loss", "=", "None", "\n", "", "if", "rationale_label", "is", "not", "None", ":", "\n", "            ", "rationale_loss", "=", "self", ".", "rationale_criterion", "(", "rationale_out", ".", "view", "(", "-", "1", ",", "self", ".", "rationale_label_size", ")", ",", "\n", "rationale_label", ".", "view", "(", "-", "1", ")", ")", "# ignore index 2", "\n", "", "else", ":", "\n", "            ", "rationale_loss", "=", "None", "\n", "\n", "", "stance_out", "=", "torch", ".", "argmax", "(", "stance_out", ".", "cpu", "(", ")", ",", "dim", "=", "-", "1", ")", ".", "detach", "(", ")", ".", "numpy", "(", ")", ".", "tolist", "(", ")", "\n", "if", "rationale_score", ":", "\n", "            ", "rationale_pred", "=", "rationale_out", ".", "cpu", "(", ")", "[", ":", ",", ":", ",", "1", "]", "# (Batch_size, N_sep)", "\n", "", "else", ":", "\n", "            ", "rationale_pred", "=", "torch", ".", "argmax", "(", "rationale_out", ".", "cpu", "(", ")", ",", "dim", "=", "-", "1", ")", "# (Batch_size, N_sep)", "\n", "", "rationale_out", "=", "[", "rationale_pred_paragraph", "[", "mask", "]", ".", "detach", "(", ")", ".", "numpy", "(", ")", ".", "tolist", "(", ")", "for", "rationale_pred_paragraph", ",", "mask", "in", "zip", "(", "rationale_pred", ",", "sentence_mask", ".", "bool", "(", ")", ")", "]", "\n", "return", "rationale_out", ",", "stance_out", ",", "rationale_loss", ",", "stance_loss", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.paragraph_model_dynamic.DomainAdaptationJointParagraphClassifier.__init__": [[219, 246], ["torch.Module.__init__", "transformers.AutoModel.from_pretrained", "torch.CrossEntropyLoss", "torch.CrossEntropyLoss", "torch.CrossEntropyLoss", "torch.CrossEntropyLoss", "torch.CrossEntropyLoss", "torch.CrossEntropyLoss", "paragraph_model_dynamic.ClassificationHead", "paragraph_model_dynamic.ClassificationHead", "paragraph_model_dynamic.ClassificationHead", "paragraph_model_dynamic.ClassificationHead", "paragraph_model_dynamic.DynamicSentenceAttention", "paragraph_model_dynamic.DynamicSentenceAttention", "paragraph_model_dynamic.WordAttention"], "methods", ["home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.label_prediction.transformer_scifact.SciFactLabelPredictionDataset.__init__"], ["    ", "def", "__init__", "(", "self", ",", "bert_path", ",", "bert_dim", ",", "dropout", "=", "0.1", ",", "ignore_index", "=", "2", ")", ":", "\n", "        ", "super", "(", "DomainAdaptationJointParagraphClassifier", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "stance_label_size", "=", "3", "\n", "self", ".", "rationale_label_size", "=", "2", "\n", "self", ".", "ignore_index", "=", "2", "\n", "self", ".", "bert", "=", "AutoModel", ".", "from_pretrained", "(", "bert_path", ")", "\n", "self", ".", "stance_criterion", "=", "nn", ".", "CrossEntropyLoss", "(", ")", "\n", "self", ".", "rationale_criterion", "=", "nn", ".", "CrossEntropyLoss", "(", "ignore_index", "=", "2", ")", "\n", "self", ".", "rationale_linear_fever", "=", "ClassificationHead", "(", "bert_dim", ",", "self", ".", "rationale_label_size", ",", "hidden_dropout_prob", "=", "dropout", ")", "\n", "self", ".", "rationale_linear_scifact", "=", "ClassificationHead", "(", "bert_dim", ",", "self", ".", "rationale_label_size", ",", "hidden_dropout_prob", "=", "dropout", ")", "\n", "self", ".", "stance_linear_scifact", "=", "ClassificationHead", "(", "bert_dim", ",", "self", ".", "stance_label_size", ",", "hidden_dropout_prob", "=", "dropout", ")", "\n", "self", ".", "stance_linear_fever", "=", "ClassificationHead", "(", "bert_dim", ",", "self", ".", "stance_label_size", ",", "hidden_dropout_prob", "=", "dropout", ")", "\n", "\n", "self", ".", "sentence_attention_scifact", "=", "DynamicSentenceAttention", "(", "bert_dim", ",", "bert_dim", ",", "dropout", "=", "dropout", ")", "\n", "self", ".", "sentence_attention_fever", "=", "DynamicSentenceAttention", "(", "bert_dim", ",", "bert_dim", ",", "dropout", "=", "dropout", ")", "\n", "self", ".", "word_attention", "=", "WordAttention", "(", "bert_dim", ",", "bert_dim", ",", "dropout", "=", "dropout", ")", "\n", "\n", "self", ".", "extra_modules", "=", "[", "\n", "self", ".", "word_attention", ",", "\n", "self", ".", "sentence_attention_scifact", ",", "\n", "self", ".", "sentence_attention_fever", ",", "\n", "self", ".", "stance_linear_fever", ",", "\n", "self", ".", "stance_linear_scifact", ",", "\n", "self", ".", "rationale_linear_fever", ",", "\n", "self", ".", "rationale_linear_scifact", ",", "\n", "self", ".", "stance_criterion", ",", "\n", "self", ".", "rationale_criterion", "\n", "]", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.paragraph_model_dynamic.DomainAdaptationJointParagraphClassifier.forward": [[248, 325], ["paragraph_model_dynamic.DomainAdaptationJointParagraphClassifier.word_attention", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "paragraph_model_dynamic.DomainAdaptationJointParagraphClassifier.rationale_linear_fever", "paragraph_model_dynamic.DomainAdaptationJointParagraphClassifier.rationale_linear_scifact", "bool", "paragraph_model_dynamic.DomainAdaptationJointParagraphClassifier.sentence_attention_fever", "paragraph_model_dynamic.DomainAdaptationJointParagraphClassifier.sentence_attention_scifact", "paragraph_model_dynamic.DomainAdaptationJointParagraphClassifier.stance_linear_fever", "paragraph_model_dynamic.DomainAdaptationJointParagraphClassifier.stance_linear_scifact", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.argmax().detach().numpy().tolist", "torch.argmax().detach().numpy().tolist", "torch.argmax().detach().numpy().tolist", "torch.argmax().detach().numpy().tolist", "torch.argmax().detach().numpy().tolist", "torch.argmax().detach().numpy().tolist", "torch.argmax().detach().numpy().tolist", "torch.argmax().detach().numpy().tolist", "torch.argmax().detach().numpy().tolist", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "paragraph_model_dynamic.DomainAdaptationJointParagraphClassifier.bert", "domain_indices.size", "paragraph_model_dynamic.DomainAdaptationJointParagraphClassifier.stance_criterion", "paragraph_model_dynamic.DomainAdaptationJointParagraphClassifier.rationale_criterion", "torch.cat.cpu", "torch.cat.cpu", "torch.cat.cpu", "rationale_pred_paragraph[].detach().numpy().tolist", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.cat.view", "torch.cat.view", "torch.cat.view", "rationale_label.view", "torch.argmax().detach().numpy", "torch.argmax().detach().numpy", "torch.argmax().detach().numpy", "torch.argmax().detach().numpy", "torch.argmax().detach().numpy", "torch.argmax().detach().numpy", "torch.argmax().detach().numpy", "torch.argmax().detach().numpy", "torch.argmax().detach().numpy", "zip", "rationale_pred_paragraph[].detach().numpy", "sentence_mask.bool", "torch.argmax().detach", "torch.argmax().detach", "torch.argmax().detach", "torch.argmax().detach", "torch.argmax().detach", "torch.argmax().detach", "torch.argmax().detach", "torch.argmax().detach", "torch.argmax().detach", "rationale_pred_paragraph[].detach", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax().detach().numpy().tolist.cpu", "torch.argmax().detach().numpy().tolist.cpu", "torch.argmax().detach().numpy().tolist.cpu"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "encoded_dict", ",", "transformation_indices", ",", "domain_indices", ",", "stance_label", "=", "None", ",", "rationale_label", "=", "None", ",", "sample_p", "=", "1", ")", ":", "\n", "        ", "batch_indices", ",", "indices_by_batch", ",", "mask", "=", "transformation_indices", "# (batch_size, N_sep, N_token)", "\n", "bert_out", "=", "self", ".", "bert", "(", "**", "encoded_dict", ")", "[", "0", "]", "# (BATCH_SIZE, sequence_len, BERT_DIM)", "\n", "bert_tokens", "=", "bert_out", "[", "batch_indices", ",", "indices_by_batch", ",", ":", "]", "\n", "# bert_tokens: (batch_size, N_sep, N_token, BERT_dim)", "\n", "sentence_reps", ",", "sentence_mask", "=", "self", ".", "word_attention", "(", "bert_tokens", ",", "mask", ")", "\n", "# (Batch_size, N_sep, BERT_DIM), (Batch_size, N_sep)", "\n", "\n", "# Prepare splitting", "\n", "indices", "=", "torch", ".", "arange", "(", "domain_indices", ".", "size", "(", "0", ")", ")", "\n", "select_fever", "=", "domain_indices", "==", "0", "\n", "select_scifact", "=", "domain_indices", "==", "1", "\n", "\n", "fever_indices", "=", "indices", "[", "select_fever", "]", "\n", "scifact_indices", "=", "indices", "[", "select_scifact", "]", "\n", "original_indices", "=", "torch", ".", "cat", "(", "[", "fever_indices", ",", "scifact_indices", "]", ")", "\n", "\n", "# Split sentence_reps and sentence_mask", "\n", "fever_sentence_reps", "=", "sentence_reps", "[", "select_fever", "]", "\n", "fever_sentence_mask", "=", "sentence_mask", "[", "select_fever", "]", "\n", "\n", "scifact_sentence_reps", "=", "sentence_reps", "[", "select_scifact", "]", "\n", "scifact_sentence_mask", "=", "sentence_mask", "[", "select_scifact", "]", "\n", "\n", "if", "rationale_label", "is", "not", "None", ":", "\n", "            ", "fever_rationale_label", "=", "rationale_label", "[", "select_fever", "]", "\n", "scifact_rationale_label", "=", "rationale_label", "[", "select_scifact", "]", "\n", "\n", "# Compute rationale_out", "\n", "", "fever_rationale_out", "=", "self", ".", "rationale_linear_fever", "(", "fever_sentence_reps", ")", "# (Batch_size, N_sep, 2)", "\n", "scifact_rationale_out", "=", "self", ".", "rationale_linear_scifact", "(", "scifact_sentence_reps", ")", "\n", "\n", "fever_att_scores", "=", "fever_rationale_out", "[", ":", ",", ":", ",", "1", "]", "# (BATCH_SIZE, N_sentence)", "\n", "scifact_att_scores", "=", "scifact_rationale_out", "[", ":", ",", ":", ",", "1", "]", "# (BATCH_SIZE, N_sentence)", "\n", "\n", "if", "bool", "(", "torch", ".", "rand", "(", "1", ")", "<", "sample_p", ")", ":", "# Choose sentence according to predicted rationale", "\n", "            ", "fever_valid_scores", "=", "fever_rationale_out", "[", ":", ",", ":", ",", "1", "]", ">", "fever_rationale_out", "[", ":", ",", ":", ",", "0", "]", "\n", "scifact_valid_scores", "=", "scifact_rationale_out", "[", ":", ",", ":", ",", "1", "]", ">", "scifact_rationale_out", "[", ":", ",", ":", ",", "0", "]", "\n", "", "else", ":", "\n", "            ", "fever_valid_scores", "=", "fever_rationale_label", "==", "1", "# Ground truth", "\n", "scifact_valid_scores", "=", "scifact_rationale_label", "==", "1", "\n", "\n", "", "fever_paragraph_rep", "=", "self", ".", "sentence_attention_fever", "(", "fever_sentence_reps", ",", "\n", "fever_sentence_mask", ",", "fever_att_scores", ",", "fever_valid_scores", ")", "\n", "# (BATCH_SIZE, BERT_DIM) ", "\n", "\n", "scifact_paragraph_rep", "=", "self", ".", "sentence_attention_scifact", "(", "scifact_sentence_reps", ",", "\n", "scifact_sentence_mask", ",", "scifact_att_scores", ",", "scifact_valid_scores", ")", "\n", "# (BATCH_SIZE, BERT_DIM)", "\n", "\n", "fever_stance_out", "=", "self", ".", "stance_linear_fever", "(", "fever_paragraph_rep", ")", "# (Batch_size, 3)", "\n", "scifact_stance_out", "=", "self", ".", "stance_linear_scifact", "(", "scifact_paragraph_rep", ")", "# (Batch_size, 3)", "\n", "\n", "# Combine splitted ones to the original order", "\n", "stance_out", "=", "torch", ".", "cat", "(", "[", "fever_stance_out", ",", "scifact_stance_out", "]", ")", "\n", "stance_out", "=", "stance_out", "[", "original_indices", "]", "\n", "\n", "rationale_out", "=", "torch", ".", "cat", "(", "[", "fever_rationale_out", ",", "scifact_rationale_out", "]", ")", "\n", "rationale_out", "=", "rationale_out", "[", "original_indices", "]", "\n", "\n", "if", "stance_label", "is", "not", "None", ":", "\n", "            ", "stance_loss", "=", "self", ".", "stance_criterion", "(", "stance_out", ",", "stance_label", ")", "\n", "", "else", ":", "\n", "            ", "stance_loss", "=", "None", "\n", "", "if", "rationale_label", "is", "not", "None", ":", "\n", "            ", "rationale_loss", "=", "self", ".", "rationale_criterion", "(", "rationale_out", ".", "view", "(", "-", "1", ",", "self", ".", "rationale_label_size", ")", ",", "\n", "rationale_label", ".", "view", "(", "-", "1", ")", ")", "# ignore index 2", "\n", "", "else", ":", "\n", "            ", "rationale_loss", "=", "None", "\n", "\n", "", "stance_out", "=", "torch", ".", "argmax", "(", "stance_out", ".", "cpu", "(", ")", ",", "dim", "=", "-", "1", ")", ".", "detach", "(", ")", ".", "numpy", "(", ")", ".", "tolist", "(", ")", "\n", "\n", "rationale_pred", "=", "torch", ".", "argmax", "(", "rationale_out", ".", "cpu", "(", ")", ",", "dim", "=", "-", "1", ")", "# (Batch_size, N_sep)", "\n", "rationale_out", "=", "[", "rationale_pred_paragraph", "[", "mask", "]", ".", "detach", "(", ")", ".", "numpy", "(", ")", ".", "tolist", "(", ")", "for", "rationale_pred_paragraph", ",", "mask", "in", "zip", "(", "rationale_pred", ",", "sentence_mask", ".", "bool", "(", ")", ")", "]", "\n", "\n", "\n", "return", "rationale_out", ",", "stance_out", ",", "rationale_loss", ",", "stance_loss", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.paragraph_model_dynamic.StanceParagraphClassifier.__init__": [[327, 343], ["torch.Module.__init__", "transformers.AutoModel.from_pretrained", "torch.CrossEntropyLoss", "torch.CrossEntropyLoss", "torch.CrossEntropyLoss", "paragraph_model_dynamic.DynamicSentenceAttention", "paragraph_model_dynamic.WordAttention", "paragraph_model_dynamic.ClassificationHead"], "methods", ["home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.label_prediction.transformer_scifact.SciFactLabelPredictionDataset.__init__"], ["    ", "def", "__init__", "(", "self", ",", "bert_path", ",", "bert_dim", ",", "dropout", "=", "0.1", ",", "ignore_index", "=", "2", ")", ":", "\n", "        ", "super", "(", "StanceParagraphClassifier", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "stance_label_size", "=", "3", "\n", "self", ".", "ignore_index", "=", "2", "\n", "self", ".", "bert", "=", "AutoModel", ".", "from_pretrained", "(", "bert_path", ")", "\n", "self", ".", "stance_criterion", "=", "nn", ".", "CrossEntropyLoss", "(", ")", "\n", "self", ".", "dropout", "=", "dropout", "\n", "self", ".", "bert_dim", "=", "bert_dim", "\n", "self", ".", "sentence_attention", "=", "DynamicSentenceAttention", "(", "bert_dim", ",", "bert_dim", ",", "dropout", "=", "dropout", ")", "\n", "self", ".", "word_attention", "=", "WordAttention", "(", "bert_dim", ",", "bert_dim", ",", "dropout", "=", "dropout", ")", "\n", "self", ".", "stance_linear", "=", "ClassificationHead", "(", "bert_dim", ",", "self", ".", "stance_label_size", ",", "hidden_dropout_prob", "=", "dropout", ")", "\n", "self", ".", "extra_modules", "=", "[", "\n", "self", ".", "sentence_attention", ",", "\n", "self", ".", "word_attention", ",", "\n", "self", ".", "stance_linear", ",", "\n", "self", ".", "stance_criterion", ",", "\n", "]", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.paragraph_model_dynamic.StanceParagraphClassifier.reinitialize": [[345, 354], ["paragraph_model_dynamic.ClassificationHead", "paragraph_model_dynamic.DynamicSentenceAttention"], "methods", ["None"], ["", "def", "reinitialize", "(", "self", ")", ":", "\n", "        ", "self", ".", "extra_modules", "=", "[", "]", "\n", "self", ".", "stance_linear", "=", "ClassificationHead", "(", "self", ".", "bert_dim", ",", "self", ".", "stance_label_size", ",", "hidden_dropout_prob", "=", "self", ".", "dropout", ")", "\n", "self", ".", "sentence_attention", "=", "DynamicSentenceAttention", "(", "self", ".", "bert_dim", ",", "self", ".", "bert_dim", ",", "dropout", "=", "self", ".", "dropout", ")", "\n", "self", ".", "extra_modules", "=", "[", "\n", "self", ".", "stance_linear", ",", "\n", "self", ".", "stance_criterion", ",", "\n", "self", ".", "word_attention", ",", "\n", "self", ".", "sentence_attention", "\n", "]", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.paragraph_model_dynamic.StanceParagraphClassifier.forward": [[356, 377], ["paragraph_model_dynamic.StanceParagraphClassifier.word_attention", "paragraph_model_dynamic.StanceParagraphClassifier.sentence_attention", "paragraph_model_dynamic.StanceParagraphClassifier.stance_linear", "torch.argmax().detach().numpy().tolist", "torch.argmax().detach().numpy().tolist", "torch.argmax().detach().numpy().tolist", "torch.argmax().detach().numpy().tolist", "torch.argmax().detach().numpy().tolist", "torch.argmax().detach().numpy().tolist", "torch.argmax().detach().numpy().tolist", "torch.argmax().detach().numpy().tolist", "torch.argmax().detach().numpy().tolist", "paragraph_model_dynamic.StanceParagraphClassifier.bert", "sentence_mask.float", "paragraph_model_dynamic.StanceParagraphClassifier.stance_criterion", "torch.argmax().detach().numpy", "torch.argmax().detach().numpy", "torch.argmax().detach().numpy", "torch.argmax().detach().numpy", "torch.argmax().detach().numpy", "torch.argmax().detach().numpy", "torch.argmax().detach().numpy", "torch.argmax().detach().numpy", "torch.argmax().detach().numpy", "torch.argmax().detach", "torch.argmax().detach", "torch.argmax().detach", "torch.argmax().detach", "torch.argmax().detach", "torch.argmax().detach", "torch.argmax().detach", "torch.argmax().detach", "torch.argmax().detach", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax().detach().numpy().tolist.cpu", "torch.argmax().detach().numpy().tolist.cpu", "torch.argmax().detach().numpy().tolist.cpu"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "encoded_dict", ",", "transformation_indices", ",", "stance_label", "=", "None", ")", ":", "\n", "        ", "batch_indices", ",", "indices_by_batch", ",", "mask", "=", "transformation_indices", "# (batch_size, N_sep, N_token)", "\n", "bert_out", "=", "self", ".", "bert", "(", "**", "encoded_dict", ")", "[", "0", "]", "# (BATCH_SIZE, sequence_len, BERT_DIM)", "\n", "bert_tokens", "=", "bert_out", "[", "batch_indices", ",", "indices_by_batch", ",", ":", "]", "\n", "# bert_tokens: (batch_size, N_sep, N_token, BERT_dim)", "\n", "sentence_reps", ",", "sentence_mask", "=", "self", ".", "word_attention", "(", "bert_tokens", ",", "mask", ")", "\n", "# (Batch_size, N_sep, BERT_DIM), (Batch_size, N_sep)", "\n", "\n", "paragraph_rep", "=", "self", ".", "sentence_attention", "(", "sentence_reps", ",", "sentence_mask", ",", "sentence_mask", ".", "float", "(", ")", ",", "sentence_mask", ")", "\n", "# (BATCH_SIZE, BERT_DIM) ", "\n", "\n", "stance_out", "=", "self", ".", "stance_linear", "(", "paragraph_rep", ")", "# (Batch_size, 3)", "\n", "\n", "if", "stance_label", "is", "not", "None", ":", "\n", "            ", "stance_loss", "=", "self", ".", "stance_criterion", "(", "stance_out", ",", "stance_label", ")", "\n", "", "else", ":", "\n", "            ", "stance_loss", "=", "None", "\n", "\n", "", "stance_out", "=", "torch", ".", "argmax", "(", "stance_out", ".", "cpu", "(", ")", ",", "dim", "=", "-", "1", ")", ".", "detach", "(", ")", ".", "numpy", "(", ")", ".", "tolist", "(", ")", "\n", "\n", "return", "stance_out", ",", "stance_loss", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.paragraph_model_dynamic.RationaleParagraphClassifier.__init__": [[379, 395], ["torch.Module.__init__", "transformers.AutoModel.from_pretrained", "torch.CrossEntropyLoss", "torch.CrossEntropyLoss", "torch.CrossEntropyLoss", "paragraph_model_dynamic.DynamicSentenceAttention", "paragraph_model_dynamic.WordAttention", "paragraph_model_dynamic.ClassificationHead"], "methods", ["home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.label_prediction.transformer_scifact.SciFactLabelPredictionDataset.__init__"], ["    ", "def", "__init__", "(", "self", ",", "bert_path", ",", "bert_dim", ",", "dropout", "=", "0.1", ",", "ignore_index", "=", "2", ")", ":", "\n", "        ", "super", "(", "RationaleParagraphClassifier", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "rationale_label_size", "=", "2", "\n", "self", ".", "ignore_index", "=", "2", "\n", "self", ".", "bert", "=", "AutoModel", ".", "from_pretrained", "(", "bert_path", ")", "\n", "self", ".", "rationale_criterion", "=", "nn", ".", "CrossEntropyLoss", "(", "ignore_index", "=", "2", ")", "\n", "self", ".", "dropout", "=", "dropout", "\n", "self", ".", "bert_dim", "=", "bert_dim", "\n", "self", ".", "sentence_attention", "=", "DynamicSentenceAttention", "(", "bert_dim", ",", "bert_dim", ",", "dropout", "=", "dropout", ")", "\n", "self", ".", "word_attention", "=", "WordAttention", "(", "bert_dim", ",", "bert_dim", ",", "dropout", "=", "dropout", ")", "\n", "self", ".", "rationale_linear", "=", "ClassificationHead", "(", "bert_dim", ",", "self", ".", "rationale_label_size", ",", "hidden_dropout_prob", "=", "dropout", ")", "\n", "self", ".", "extra_modules", "=", "[", "\n", "self", ".", "sentence_attention", ",", "\n", "self", ".", "word_attention", ",", "\n", "self", ".", "rationale_linear", ",", "\n", "self", ".", "rationale_criterion", "\n", "]", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.paragraph_model_dynamic.RationaleParagraphClassifier.reinitialize": [[397, 406], ["paragraph_model_dynamic.ClassificationHead", "paragraph_model_dynamic.DynamicSentenceAttention"], "methods", ["None"], ["", "def", "reinitialize", "(", "self", ")", ":", "\n", "        ", "self", ".", "extra_modules", "=", "[", "]", "\n", "self", ".", "rationale_linear", "=", "ClassificationHead", "(", "self", ".", "bert_dim", ",", "self", ".", "rationale_label_size", ",", "hidden_dropout_prob", "=", "self", ".", "dropout", ")", "\n", "self", ".", "sentence_attention", "=", "DynamicSentenceAttention", "(", "self", ".", "bert_dim", ",", "self", ".", "bert_dim", ",", "dropout", "=", "self", ".", "dropout", ")", "\n", "self", ".", "extra_modules", "=", "[", "\n", "self", ".", "rationale_linear", ",", "\n", "self", ".", "rationale_criterion", ",", "\n", "self", ".", "word_attention", ",", "\n", "self", ".", "sentence_attention", "\n", "]", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.paragraph_model_dynamic.RationaleParagraphClassifier.forward": [[408, 438], ["paragraph_model_dynamic.RationaleParagraphClassifier.word_attention", "paragraph_model_dynamic.RationaleParagraphClassifier.rationale_linear", "bool", "paragraph_model_dynamic.RationaleParagraphClassifier.sentence_attention", "paragraph_model_dynamic.RationaleParagraphClassifier.bert", "paragraph_model_dynamic.RationaleParagraphClassifier.rationale_criterion", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "rationale_pred_paragraph[].detach().numpy().tolist", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "paragraph_model_dynamic.RationaleParagraphClassifier.view", "rationale_label.view", "paragraph_model_dynamic.RationaleParagraphClassifier.cpu", "paragraph_model_dynamic.RationaleParagraphClassifier.cpu", "zip", "rationale_pred_paragraph[].detach().numpy", "sentence_mask.bool", "rationale_pred_paragraph[].detach"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "encoded_dict", ",", "transformation_indices", ",", "rationale_label", "=", "None", ",", "sample_p", "=", "1", ",", "rationale_score", "=", "False", ")", ":", "\n", "        ", "batch_indices", ",", "indices_by_batch", ",", "mask", "=", "transformation_indices", "# (batch_size, N_sep, N_token)", "\n", "bert_out", "=", "self", ".", "bert", "(", "**", "encoded_dict", ")", "[", "0", "]", "# (BATCH_SIZE, sequence_len, BERT_DIM)", "\n", "bert_tokens", "=", "bert_out", "[", "batch_indices", ",", "indices_by_batch", ",", ":", "]", "\n", "# bert_tokens: (batch_size, N_sep, N_token, BERT_dim)", "\n", "sentence_reps", ",", "sentence_mask", "=", "self", ".", "word_attention", "(", "bert_tokens", ",", "mask", ")", "\n", "# (Batch_size, N_sep, BERT_DIM), (Batch_size, N_sep)", "\n", "#print(bert_out.shape, bert_tokens.shape, sentence_reps.shape, sentence_mask.shape, rationale_label.shape)", "\n", "rationale_out", "=", "self", ".", "rationale_linear", "(", "sentence_reps", ")", "# (Batch_size, N_sep, 2)", "\n", "att_scores", "=", "rationale_out", "[", ":", ",", ":", ",", "1", "]", "# (BATCH_SIZE, N_sentence)", "\n", "\n", "if", "bool", "(", "torch", ".", "rand", "(", "1", ")", "<", "sample_p", ")", ":", "# Choose sentence according to predicted rationale", "\n", "            ", "valid_scores", "=", "rationale_out", "[", ":", ",", ":", ",", "1", "]", ">", "rationale_out", "[", ":", ",", ":", ",", "0", "]", "\n", "", "else", ":", "\n", "            ", "valid_scores", "=", "rationale_label", "==", "1", "# Ground truth", "\n", "", "paragraph_rep", "=", "self", ".", "sentence_attention", "(", "sentence_reps", ",", "sentence_mask", ",", "att_scores", ",", "valid_scores", ")", "\n", "# (BATCH_SIZE, BERT_DIM) ", "\n", "\n", "if", "rationale_label", "is", "not", "None", ":", "\n", "            ", "rationale_loss", "=", "self", ".", "rationale_criterion", "(", "rationale_out", ".", "view", "(", "-", "1", ",", "self", ".", "rationale_label_size", ")", ",", "\n", "rationale_label", ".", "view", "(", "-", "1", ")", ")", "# ignore index 2", "\n", "", "else", ":", "\n", "            ", "rationale_loss", "=", "None", "\n", "\n", "", "if", "rationale_score", ":", "\n", "            ", "rationale_pred", "=", "rationale_out", ".", "cpu", "(", ")", "[", ":", ",", ":", ",", "1", "]", "# (Batch_size, N_sep)", "\n", "", "else", ":", "\n", "            ", "rationale_pred", "=", "torch", ".", "argmax", "(", "rationale_out", ".", "cpu", "(", ")", ",", "dim", "=", "-", "1", ")", "# (Batch_size, N_sep)", "\n", "", "rationale_out", "=", "[", "rationale_pred_paragraph", "[", "mask", "]", ".", "detach", "(", ")", ".", "numpy", "(", ")", ".", "tolist", "(", ")", "for", "rationale_pred_paragraph", ",", "mask", "in", "zip", "(", "rationale_pred", ",", "sentence_mask", ".", "bool", "(", ")", ")", "]", "\n", "return", "rationale_out", ",", "rationale_loss", "", "", "", ""]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.FEVER_stance_paragraph_kgat.reset_random_seed": [[29, 33], ["numpy.random.seed", "random.seed", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed"], "function", ["None"], ["def", "reset_random_seed", "(", "seed", ")", ":", "\n", "    ", "np", ".", "random", ".", "seed", "(", "seed", ")", "\n", "random", ".", "seed", "(", "seed", ")", "\n", "torch", ".", "manual_seed", "(", "seed", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.FEVER_stance_paragraph_kgat.evaluation": [[34, 56], ["model.eval", "sklearn.metrics.f1_score", "sklearn.metrics.precision_score", "sklearn.metrics.recall_score", "torch.no_grad", "torch.no_grad", "torch.no_grad", "tqdm.tqdm", "torch.utils.data.DataLoader", "FEVER_stance_paragraph_kgat.encode", "FEVER_stance_paragraph_kgat.token_idx_by_sentence", "batch[].to", "model", "stance_preds.extend", "stance_labels.extend", "tensor.to", "tensor.to", "batch[].to.cpu().numpy().tolist", "encode.items", "batch[].to.cpu().numpy", "batch[].to.cpu"], "function", ["home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.label_prediction.transformer_scifact.encode", "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.FEVER_stance_paragraph.token_idx_by_sentence"], ["", "def", "evaluation", "(", "model", ",", "dataset", ")", ":", "\n", "    ", "model", ".", "eval", "(", ")", "\n", "stance_preds", "=", "[", "]", "\n", "stance_labels", "=", "[", "]", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "for", "batch", "in", "tqdm", "(", "DataLoader", "(", "dataset", ",", "batch_size", "=", "args", ".", "batch_size", ",", "shuffle", "=", "False", ")", ")", ":", "\n", "            ", "encoded_dict", "=", "encode", "(", "tokenizer", ",", "batch", ")", "\n", "transformation_indices", "=", "token_idx_by_sentence", "(", "encoded_dict", "[", "\"input_ids\"", "]", ",", "\n", "tokenizer", ".", "sep_token_id", ",", "args", ".", "repfile", ")", "\n", "encoded_dict", "=", "{", "key", ":", "tensor", ".", "to", "(", "device", ")", "for", "key", ",", "tensor", "in", "encoded_dict", ".", "items", "(", ")", "}", "\n", "transformation_indices", "=", "[", "tensor", ".", "to", "(", "device", ")", "for", "tensor", "in", "transformation_indices", "]", "\n", "stance_label", "=", "batch", "[", "\"stance\"", "]", ".", "to", "(", "device", ")", "\n", "stance_out", ",", "stance_loss", "=", "model", "(", "encoded_dict", ",", "transformation_indices", ",", "stance_label", "=", "stance_label", ")", "\n", "stance_preds", ".", "extend", "(", "stance_out", ")", "\n", "stance_labels", ".", "extend", "(", "stance_label", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "tolist", "(", ")", ")", "\n", "\n", "", "", "stance_f1", "=", "f1_score", "(", "stance_labels", ",", "stance_preds", ",", "average", "=", "\"micro\"", ",", "labels", "=", "[", "1", ",", "2", "]", ")", "\n", "stance_precision", "=", "precision_score", "(", "stance_labels", ",", "stance_preds", ",", "average", "=", "\"micro\"", ",", "labels", "=", "[", "1", ",", "2", "]", ")", "\n", "stance_recall", "=", "recall_score", "(", "stance_labels", ",", "stance_preds", ",", "average", "=", "\"micro\"", ",", "labels", "=", "[", "1", ",", "2", "]", ")", "\n", "return", "stance_f1", ",", "stance_precision", ",", "stance_recall", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.FEVER_stance_paragraph_kgat.encode": [[58, 107], ["zip", "tokenizer.batch_encode_plus", "torch.cat", "torch.cat", "torch.cat", "encoded_dict[].size", "len", "numpy.sum", "numpy.argmax", "valid_paragraph.size", "all_paragraphs.append", "longest_first_truncation"], "function", ["home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.dataset.encode.longest_first_truncation"], ["", "def", "encode", "(", "tokenizer", ",", "batch", ",", "max_sent_len", "=", "512", ")", ":", "\n", "    ", "def", "truncate", "(", "input_ids", ",", "max_length", ",", "sep_token_id", ",", "pad_token_id", ")", ":", "\n", "        ", "def", "longest_first_truncation", "(", "sentences", ",", "objective", ")", ":", "\n", "            ", "sent_lens", "=", "[", "len", "(", "sent", ")", "for", "sent", "in", "sentences", "]", "\n", "while", "np", ".", "sum", "(", "sent_lens", ")", ">", "objective", ":", "\n", "                ", "max_position", "=", "np", ".", "argmax", "(", "sent_lens", ")", "\n", "sent_lens", "[", "max_position", "]", "-=", "1", "\n", "", "return", "[", "sentence", "[", ":", "length", "]", "for", "sentence", ",", "length", "in", "zip", "(", "sentences", ",", "sent_lens", ")", "]", "\n", "\n", "", "all_paragraphs", "=", "[", "]", "\n", "for", "paragraph", "in", "input_ids", ":", "\n", "            ", "valid_paragraph", "=", "paragraph", "[", "paragraph", "!=", "pad_token_id", "]", "\n", "if", "valid_paragraph", ".", "size", "(", "0", ")", "<=", "max_length", ":", "\n", "                ", "all_paragraphs", ".", "append", "(", "paragraph", "[", ":", "max_length", "]", ".", "unsqueeze", "(", "0", ")", ")", "\n", "", "else", ":", "\n", "                ", "sep_token_idx", "=", "np", ".", "arange", "(", "valid_paragraph", ".", "size", "(", "0", ")", ")", "[", "(", "valid_paragraph", "==", "sep_token_id", ")", ".", "numpy", "(", ")", "]", "\n", "idx_by_sentence", "=", "[", "]", "\n", "prev_idx", "=", "0", "\n", "for", "idx", "in", "sep_token_idx", ":", "\n", "                    ", "idx_by_sentence", ".", "append", "(", "paragraph", "[", "prev_idx", ":", "idx", "]", ")", "\n", "prev_idx", "=", "idx", "\n", "", "objective", "=", "max_length", "-", "1", "-", "len", "(", "idx_by_sentence", "[", "0", "]", ")", "# The last sep_token left out", "\n", "truncated_sentences", "=", "longest_first_truncation", "(", "idx_by_sentence", "[", "1", ":", "]", ",", "objective", ")", "\n", "truncated_paragraph", "=", "torch", ".", "cat", "(", "[", "idx_by_sentence", "[", "0", "]", "]", "+", "truncated_sentences", "+", "[", "torch", ".", "tensor", "(", "[", "sep_token_id", "]", ")", "]", ",", "0", ")", "\n", "all_paragraphs", ".", "append", "(", "truncated_paragraph", ".", "unsqueeze", "(", "0", ")", ")", "\n", "\n", "", "", "return", "torch", ".", "cat", "(", "all_paragraphs", ",", "0", ")", "\n", "\n", "", "inputs", "=", "zip", "(", "batch", "[", "\"claim\"", "]", ",", "batch", "[", "\"paragraph\"", "]", ")", "\n", "encoded_dict", "=", "tokenizer", ".", "batch_encode_plus", "(", "\n", "inputs", ",", "\n", "pad_to_max_length", "=", "True", ",", "add_special_tokens", "=", "True", ",", "\n", "return_tensors", "=", "'pt'", ")", "\n", "if", "encoded_dict", "[", "'input_ids'", "]", ".", "size", "(", "1", ")", ">", "max_sent_len", ":", "\n", "        ", "if", "'token_type_ids'", "in", "encoded_dict", ":", "\n", "            ", "encoded_dict", "=", "{", "\n", "\"input_ids\"", ":", "truncate", "(", "encoded_dict", "[", "'input_ids'", "]", ",", "max_sent_len", ",", "\n", "tokenizer", ".", "sep_token_id", ",", "tokenizer", ".", "pad_token_id", ")", ",", "\n", "'token_type_ids'", ":", "encoded_dict", "[", "'token_type_ids'", "]", "[", ":", ",", ":", "max_sent_len", "]", ",", "\n", "'attention_mask'", ":", "encoded_dict", "[", "'attention_mask'", "]", "[", ":", ",", ":", "max_sent_len", "]", "\n", "}", "\n", "", "else", ":", "\n", "            ", "encoded_dict", "=", "{", "\n", "\"input_ids\"", ":", "truncate", "(", "encoded_dict", "[", "'input_ids'", "]", ",", "max_sent_len", ",", "\n", "tokenizer", ".", "sep_token_id", ",", "tokenizer", ".", "pad_token_id", ")", ",", "\n", "'attention_mask'", ":", "encoded_dict", "[", "'attention_mask'", "]", "[", ":", ",", ":", "max_sent_len", "]", "\n", "}", "\n", "\n", "", "", "return", "encoded_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.FEVER_stance_paragraph_kgat.token_idx_by_sentence": [[108, 136], ["torch.sum().numpy().tolist", "torch.sum().numpy().tolist", "torch.sum().numpy().tolist", "torch.arange().unsqueeze().expand", "torch.arange().unsqueeze().expand", "torch.arange().unsqueeze().expand", "torch.split", "torch.split", "torch.split", "torch.utils.rnn.pad_sequence", "torch.split", "torch.split", "torch.split", "torch.utils.rnn.pad_sequence", "torch.arange().unsqueeze().unsqueeze().expand", "torch.arange().unsqueeze().unsqueeze().expand", "torch.arange().unsqueeze().unsqueeze().expand", "sep_tokens.size", "torch.sum().numpy().tolist.append", "all_word_indices.extend", "nn.utils.rnn.pad_sequence.size", "nn.utils.rnn.pad_sequence.size", "torch.arange().unsqueeze().unsqueeze().expand.long", "nn.utils.rnn.pad_sequence.long", "mask.long", "torch.sum().numpy", "torch.sum().numpy", "torch.sum().numpy", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange", "torch.arange", "torch.arange", "len", "torch.arange().unsqueeze().unsqueeze", "torch.arange().unsqueeze().unsqueeze", "torch.arange().unsqueeze().unsqueeze", "range", "torch.sum", "torch.sum", "torch.sum", "torch.arange", "torch.arange", "torch.arange", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "sep_tokens.size", "paragraph.size", "torch.arange", "torch.arange", "torch.arange", "sep_tokens.size"], "function", ["None"], ["", "def", "token_idx_by_sentence", "(", "input_ids", ",", "sep_token_id", ",", "model_name", ")", ":", "\n", "    ", "\"\"\"\n    Compute the token indices matrix of the BERT output.\n    input_ids: (batch_size, paragraph_len)\n    batch_indices, indices_by_batch, mask: (batch_size, N_sentence, N_token)\n    bert_out: (batch_size, paragraph_len,BERT_dim)\n    bert_out[batch_indices,indices_by_batch,:]: (batch_size, N_sentence, N_token, BERT_dim)\n    \"\"\"", "\n", "padding_idx", "=", "-", "1", "\n", "sep_tokens", "=", "(", "input_ids", "==", "sep_token_id", ")", ".", "bool", "(", ")", "\n", "paragraph_lens", "=", "torch", ".", "sum", "(", "sep_tokens", ",", "1", ")", ".", "numpy", "(", ")", ".", "tolist", "(", ")", "\n", "indices", "=", "torch", ".", "arange", "(", "sep_tokens", ".", "size", "(", "-", "1", ")", ")", ".", "unsqueeze", "(", "0", ")", ".", "expand", "(", "sep_tokens", ".", "size", "(", "0", ")", ",", "-", "1", ")", "\n", "sep_indices", "=", "torch", ".", "split", "(", "indices", "[", "sep_tokens", "]", ",", "paragraph_lens", ")", "\n", "paragraph_lens", "=", "[", "]", "\n", "all_word_indices", "=", "[", "]", "\n", "for", "paragraph", "in", "sep_indices", ":", "\n", "        ", "if", "\"roberta\"", "in", "model_name", ":", "\n", "            ", "paragraph", "=", "paragraph", "[", "1", ":", "]", "\n", "", "word_indices", "=", "[", "torch", ".", "arange", "(", "paragraph", "[", "i", "]", "+", "1", ",", "paragraph", "[", "i", "+", "1", "]", "+", "1", ")", "for", "i", "in", "range", "(", "paragraph", ".", "size", "(", "0", ")", "-", "1", ")", "]", "\n", "paragraph_lens", ".", "append", "(", "len", "(", "word_indices", ")", ")", "\n", "all_word_indices", ".", "extend", "(", "word_indices", ")", "\n", "", "indices_by_sentence", "=", "nn", ".", "utils", ".", "rnn", ".", "pad_sequence", "(", "all_word_indices", ",", "batch_first", "=", "True", ",", "padding_value", "=", "padding_idx", ")", "\n", "indices_by_sentence_split", "=", "torch", ".", "split", "(", "indices_by_sentence", ",", "paragraph_lens", ")", "\n", "indices_by_batch", "=", "nn", ".", "utils", ".", "rnn", ".", "pad_sequence", "(", "indices_by_sentence_split", ",", "batch_first", "=", "True", ",", "padding_value", "=", "padding_idx", ")", "\n", "batch_indices", "=", "torch", ".", "arange", "(", "sep_tokens", ".", "size", "(", "0", ")", ")", ".", "unsqueeze", "(", "-", "1", ")", ".", "unsqueeze", "(", "-", "1", ")", ".", "expand", "(", "-", "1", ",", "indices_by_batch", ".", "size", "(", "1", ")", ",", "indices_by_batch", ".", "size", "(", "-", "1", ")", ")", "\n", "mask", "=", "(", "indices_by_batch", ">=", "0", ")", "\n", "\n", "return", "batch_indices", ".", "long", "(", ")", ",", "indices_by_batch", ".", "long", "(", ")", ",", "mask", ".", "long", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.domain_adaptation_joint_paragraph_dynamic.schedule_sample_p": [[30, 32], ["numpy.sin"], "function", ["None"], ["def", "schedule_sample_p", "(", "epoch", ",", "total", ")", ":", "\n", "    ", "return", "np", ".", "sin", "(", "0.5", "*", "np", ".", "pi", "*", "epoch", "/", "(", "total", "-", "1", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.domain_adaptation_joint_paragraph_dynamic.reset_random_seed": [[33, 37], ["numpy.random.seed", "random.seed", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed"], "function", ["None"], ["", "def", "reset_random_seed", "(", "seed", ")", ":", "\n", "    ", "np", ".", "random", ".", "seed", "(", "seed", ")", "\n", "random", ".", "seed", "(", "seed", ")", "\n", "torch", ".", "manual_seed", "(", "seed", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.domain_adaptation_joint_paragraph_dynamic.batch_rationale_label": [[38, 47], ["max", "enumerate", "torch.ones", "torch.ones", "torch.ones", "enumerate", "label_list.append", "label_matrix.long", "len", "len", "int", "int"], "function", ["None"], ["", "def", "batch_rationale_label", "(", "labels", ",", "padding_idx", "=", "2", ")", ":", "\n", "    ", "max_sent_len", "=", "max", "(", "[", "len", "(", "label", ")", "for", "label", "in", "labels", "]", ")", "\n", "label_matrix", "=", "torch", ".", "ones", "(", "len", "(", "labels", ")", ",", "max_sent_len", ")", "*", "padding_idx", "\n", "label_list", "=", "[", "]", "\n", "for", "i", ",", "label", "in", "enumerate", "(", "labels", ")", ":", "\n", "        ", "for", "j", ",", "evid", "in", "enumerate", "(", "label", ")", ":", "\n", "            ", "label_matrix", "[", "i", ",", "j", "]", "=", "int", "(", "evid", ")", "\n", "", "label_list", ".", "append", "(", "[", "int", "(", "evid", ")", "for", "evid", "in", "label", "]", ")", "\n", "", "return", "label_matrix", ".", "long", "(", ")", ",", "label_list", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.domain_adaptation_joint_paragraph_dynamic.evaluation": [[48, 85], ["model.eval", "sklearn.metrics.f1_score", "sklearn.metrics.precision_score", "sklearn.metrics.recall_score", "sklearn.metrics.f1_score", "sklearn.metrics.precision_score", "sklearn.metrics.recall_score", "torch.no_grad", "torch.no_grad", "torch.no_grad", "tqdm.tqdm", "util.flatten", "util.flatten", "util.flatten", "util.flatten", "util.flatten", "util.flatten", "torch.utils.data.DataLoader", "domain_adaptation_joint_paragraph_dynamic.encode", "domain_adaptation_joint_paragraph_dynamic.token_idx_by_sentence", "batch[].to", "batch[].to", "domain_adaptation_joint_paragraph_dynamic.batch_rationale_label", "tensor.to", "tensor.to", "padded_rationale_label.size", "transformation_indices[].size", "model", "stance_preds.extend", "stance_labels.extend", "rationale_predictions.extend", "rationale_labels.extend", "encode.items", "batch[].to.cpu().numpy().tolist", "domain_adaptation_joint_paragraph_dynamic.evaluation.remove_dummy"], "function", ["home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.util.flatten", "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.util.flatten", "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.util.flatten", "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.util.flatten", "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.util.flatten", "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.util.flatten", "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.label_prediction.transformer_scifact.encode", "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.FEVER_stance_paragraph.token_idx_by_sentence", "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.domain_adaptation_joint_paragraph_fine_tune.batch_rationale_label", "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.src.utils.remove_dummy"], ["", "def", "evaluation", "(", "model", ",", "dataset", ")", ":", "\n", "    ", "model", ".", "eval", "(", ")", "\n", "rationale_predictions", "=", "[", "]", "\n", "rationale_labels", "=", "[", "]", "\n", "stance_preds", "=", "[", "]", "\n", "stance_labels", "=", "[", "]", "\n", "\n", "def", "remove_dummy", "(", "rationale_out", ")", ":", "\n", "        ", "return", "[", "out", "[", "1", ":", "]", "for", "out", "in", "rationale_out", "]", "\n", "\n", "", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "for", "batch", "in", "tqdm", "(", "DataLoader", "(", "dataset", ",", "batch_size", "=", "args", ".", "batch_size", ",", "shuffle", "=", "False", ")", ")", ":", "\n", "            ", "encoded_dict", "=", "encode", "(", "tokenizer", ",", "batch", ")", "\n", "transformation_indices", "=", "token_idx_by_sentence", "(", "encoded_dict", "[", "\"input_ids\"", "]", ",", "\n", "tokenizer", ".", "sep_token_id", ",", "args", ".", "repfile", ")", "\n", "encoded_dict", "=", "{", "key", ":", "tensor", ".", "to", "(", "device", ")", "for", "key", ",", "tensor", "in", "encoded_dict", ".", "items", "(", ")", "}", "\n", "transformation_indices", "=", "[", "tensor", ".", "to", "(", "device", ")", "for", "tensor", "in", "transformation_indices", "]", "\n", "stance_label", "=", "batch", "[", "\"stance\"", "]", ".", "to", "(", "device", ")", "\n", "domain_indices", "=", "batch", "[", "\"dataset\"", "]", ".", "to", "(", "device", ")", "\n", "padded_rationale_label", ",", "rationale_label", "=", "batch_rationale_label", "(", "batch", "[", "\"label\"", "]", ",", "padding_idx", "=", "2", ")", "\n", "if", "padded_rationale_label", ".", "size", "(", "1", ")", "==", "transformation_indices", "[", "-", "1", "]", ".", "size", "(", "1", ")", ":", "\n", "                ", "rationale_out", ",", "stance_out", ",", "rationale_loss", ",", "stance_loss", "=", "model", "(", "encoded_dict", ",", "transformation_indices", ",", "domain_indices", ",", "stance_label", "=", "stance_label", ",", "\n", "rationale_label", "=", "padded_rationale_label", ".", "to", "(", "device", ")", ")", "\n", "stance_preds", ".", "extend", "(", "stance_out", ")", "\n", "stance_labels", ".", "extend", "(", "stance_label", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "tolist", "(", ")", ")", "\n", "\n", "rationale_predictions", ".", "extend", "(", "remove_dummy", "(", "rationale_out", ")", ")", "\n", "rationale_labels", ".", "extend", "(", "remove_dummy", "(", "rationale_label", ")", ")", "\n", "\n", "", "", "", "stance_f1", "=", "f1_score", "(", "stance_labels", ",", "stance_preds", ",", "average", "=", "\"micro\"", ",", "labels", "=", "[", "1", ",", "2", "]", ")", "\n", "stance_precision", "=", "precision_score", "(", "stance_labels", ",", "stance_preds", ",", "average", "=", "\"micro\"", ",", "labels", "=", "[", "1", ",", "2", "]", ")", "\n", "stance_recall", "=", "recall_score", "(", "stance_labels", ",", "stance_preds", ",", "average", "=", "\"micro\"", ",", "labels", "=", "[", "1", ",", "2", "]", ")", "\n", "rationale_f1", "=", "f1_score", "(", "flatten", "(", "rationale_labels", ")", ",", "flatten", "(", "rationale_predictions", ")", ")", "\n", "rationale_precision", "=", "precision_score", "(", "flatten", "(", "rationale_labels", ")", ",", "flatten", "(", "rationale_predictions", ")", ")", "\n", "rationale_recall", "=", "recall_score", "(", "flatten", "(", "rationale_labels", ")", ",", "flatten", "(", "rationale_predictions", ")", ")", "\n", "return", "stance_f1", ",", "stance_precision", ",", "stance_recall", ",", "rationale_f1", ",", "rationale_precision", ",", "rationale_recall", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.domain_adaptation_joint_paragraph_dynamic.run_evaluation": [[86, 114], ["domain_adaptation_joint_paragraph_dynamic.evaluation", "print", "domain_adaptation_joint_paragraph_dynamic.evaluation", "print", "domain_adaptation_joint_paragraph_dynamic.evaluation", "print", "domain_adaptation_joint_paragraph_dynamic.evaluation", "print", "len", "torch.utils.data.Subset", "len", "torch.utils.data.Subset", "len", "torch.utils.data.Subset", "range", "range", "range"], "function", ["home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.FEVER_stance_paragraph.evaluation", "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.FEVER_stance_paragraph.evaluation", "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.FEVER_stance_paragraph.evaluation", "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.FEVER_stance_paragraph.evaluation"], ["", "def", "run_evaluation", "(", ")", ":", "\n", "# Evaluation", "\n", "    ", "if", "args", ".", "N_evaluation_sample", "<", "len", "(", "train_fever", ")", ":", "\n", "        ", "subset_train_fever", "=", "Subset", "(", "train_fever", ",", "range", "(", "0", ",", "args", ".", "N_evaluation_sample", ")", ")", "\n", "", "else", ":", "\n", "        ", "subset_train_fever", "=", "train_fever", "\n", "", "train_score", "=", "evaluation", "(", "model", ",", "subset_train_fever", ")", "\n", "print", "(", "f'Epoch {epoch}, iteration {i}, FEVER train stance f1 p r: %.4f, %.4f, %.4f, rationale f1 p r: %.4f, %.4f, %.4f'", "%", "train_score", ")", "\n", "if", "args", ".", "N_evaluation_sample", "<", "len", "(", "train_scifact", ")", ":", "\n", "        ", "subset_train_scifact", "=", "Subset", "(", "train_scifact", ",", "range", "(", "0", ",", "args", ".", "N_evaluation_sample", ")", ")", "\n", "", "else", ":", "\n", "        ", "subset_train_scifact", "=", "train_scifact", "\n", "", "train_score", "=", "evaluation", "(", "model", ",", "subset_train_scifact", ")", "\n", "print", "(", "f'Epoch {epoch}, iteration {i}, SciFact train stance f1 p r: %.4f, %.4f, %.4f, rationale f1 p r: %.4f, %.4f, %.4f'", "%", "train_score", ")", "\n", "\n", "if", "args", ".", "N_evaluation_sample", "<", "len", "(", "dev_fever", ")", ":", "\n", "        ", "subset_dev_fever", "=", "Subset", "(", "dev_fever", ",", "range", "(", "0", ",", "args", ".", "N_evaluation_sample", ")", ")", "\n", "", "else", ":", "\n", "        ", "subset_dev_fever", "=", "dev_fever", "\n", "", "dev_score", "=", "evaluation", "(", "model", ",", "subset_dev_fever", ")", "\n", "print", "(", "f'Epoch {epoch}, iteration {i}, FEVER dev stance f1 p r: %.4f, %.4f, %.4f, rationale f1 p r: %.4f, %.4f, %.4f'", "%", "dev_score", ")", "\n", "#if args.N_evaluation_sample < len(dev_scifact):", "\n", "#    subset_dev_scifact = Subset(dev_scifact, range(0, args.N_evaluation_sample))", "\n", "#else:", "\n", "#    subset_dev_scifact = dev_scifact", "\n", "#dev_score = evaluation(model, subset_dev_scifact)", "\n", "dev_score", "=", "evaluation", "(", "model", ",", "dev_scifact", ")", "\n", "print", "(", "f'Epoch {epoch}, iteration {i}, SciFact dev stance f1 p r: %.4f, %.4f, %.4f, rationale f1 p r: %.4f, %.4f, %.4f'", "%", "dev_score", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.domain_adaptation_joint_paragraph_dynamic.encode": [[115, 164], ["zip", "tokenizer.batch_encode_plus", "torch.cat", "torch.cat", "torch.cat", "encoded_dict[].size", "len", "numpy.sum", "numpy.argmax", "valid_paragraph.size", "all_paragraphs.append", "longest_first_truncation"], "function", ["home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.dataset.encode.longest_first_truncation"], ["", "def", "encode", "(", "tokenizer", ",", "batch", ",", "max_sent_len", "=", "512", ")", ":", "\n", "    ", "def", "truncate", "(", "input_ids", ",", "max_length", ",", "sep_token_id", ",", "pad_token_id", ")", ":", "\n", "        ", "def", "longest_first_truncation", "(", "sentences", ",", "objective", ")", ":", "\n", "            ", "sent_lens", "=", "[", "len", "(", "sent", ")", "for", "sent", "in", "sentences", "]", "\n", "while", "np", ".", "sum", "(", "sent_lens", ")", ">", "objective", ":", "\n", "                ", "max_position", "=", "np", ".", "argmax", "(", "sent_lens", ")", "\n", "sent_lens", "[", "max_position", "]", "-=", "1", "\n", "", "return", "[", "sentence", "[", ":", "length", "]", "for", "sentence", ",", "length", "in", "zip", "(", "sentences", ",", "sent_lens", ")", "]", "\n", "\n", "", "all_paragraphs", "=", "[", "]", "\n", "for", "paragraph", "in", "input_ids", ":", "\n", "            ", "valid_paragraph", "=", "paragraph", "[", "paragraph", "!=", "pad_token_id", "]", "\n", "if", "valid_paragraph", ".", "size", "(", "0", ")", "<=", "max_length", ":", "\n", "                ", "all_paragraphs", ".", "append", "(", "paragraph", "[", ":", "max_length", "]", ".", "unsqueeze", "(", "0", ")", ")", "\n", "", "else", ":", "\n", "                ", "sep_token_idx", "=", "np", ".", "arange", "(", "valid_paragraph", ".", "size", "(", "0", ")", ")", "[", "(", "valid_paragraph", "==", "sep_token_id", ")", ".", "numpy", "(", ")", "]", "\n", "idx_by_sentence", "=", "[", "]", "\n", "prev_idx", "=", "0", "\n", "for", "idx", "in", "sep_token_idx", ":", "\n", "                    ", "idx_by_sentence", ".", "append", "(", "paragraph", "[", "prev_idx", ":", "idx", "]", ")", "\n", "prev_idx", "=", "idx", "\n", "", "objective", "=", "max_length", "-", "1", "-", "len", "(", "idx_by_sentence", "[", "0", "]", ")", "# The last sep_token left out", "\n", "truncated_sentences", "=", "longest_first_truncation", "(", "idx_by_sentence", "[", "1", ":", "]", ",", "objective", ")", "\n", "truncated_paragraph", "=", "torch", ".", "cat", "(", "[", "idx_by_sentence", "[", "0", "]", "]", "+", "truncated_sentences", "+", "[", "torch", ".", "tensor", "(", "[", "sep_token_id", "]", ")", "]", ",", "0", ")", "\n", "all_paragraphs", ".", "append", "(", "truncated_paragraph", ".", "unsqueeze", "(", "0", ")", ")", "\n", "\n", "", "", "return", "torch", ".", "cat", "(", "all_paragraphs", ",", "0", ")", "\n", "\n", "", "inputs", "=", "zip", "(", "batch", "[", "\"claim\"", "]", ",", "batch", "[", "\"paragraph\"", "]", ")", "\n", "encoded_dict", "=", "tokenizer", ".", "batch_encode_plus", "(", "\n", "inputs", ",", "\n", "pad_to_max_length", "=", "True", ",", "add_special_tokens", "=", "True", ",", "\n", "return_tensors", "=", "'pt'", ")", "\n", "if", "encoded_dict", "[", "'input_ids'", "]", ".", "size", "(", "1", ")", ">", "max_sent_len", ":", "\n", "        ", "if", "'token_type_ids'", "in", "encoded_dict", ":", "\n", "            ", "encoded_dict", "=", "{", "\n", "\"input_ids\"", ":", "truncate", "(", "encoded_dict", "[", "'input_ids'", "]", ",", "max_sent_len", ",", "\n", "tokenizer", ".", "sep_token_id", ",", "tokenizer", ".", "pad_token_id", ")", ",", "\n", "'token_type_ids'", ":", "encoded_dict", "[", "'token_type_ids'", "]", "[", ":", ",", ":", "max_sent_len", "]", ",", "\n", "'attention_mask'", ":", "encoded_dict", "[", "'attention_mask'", "]", "[", ":", ",", ":", "max_sent_len", "]", "\n", "}", "\n", "", "else", ":", "\n", "            ", "encoded_dict", "=", "{", "\n", "\"input_ids\"", ":", "truncate", "(", "encoded_dict", "[", "'input_ids'", "]", ",", "max_sent_len", ",", "\n", "tokenizer", ".", "sep_token_id", ",", "tokenizer", ".", "pad_token_id", ")", ",", "\n", "'attention_mask'", ":", "encoded_dict", "[", "'attention_mask'", "]", "[", ":", ",", ":", "max_sent_len", "]", "\n", "}", "\n", "\n", "", "", "return", "encoded_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.domain_adaptation_joint_paragraph_dynamic.token_idx_by_sentence": [[166, 194], ["torch.sum().numpy().tolist", "torch.sum().numpy().tolist", "torch.sum().numpy().tolist", "torch.arange().unsqueeze().expand", "torch.arange().unsqueeze().expand", "torch.arange().unsqueeze().expand", "torch.split", "torch.split", "torch.split", "torch.utils.rnn.pad_sequence", "torch.split", "torch.split", "torch.split", "torch.utils.rnn.pad_sequence", "torch.arange().unsqueeze().unsqueeze().expand", "torch.arange().unsqueeze().unsqueeze().expand", "torch.arange().unsqueeze().unsqueeze().expand", "sep_tokens.size", "torch.sum().numpy().tolist.append", "all_word_indices.extend", "nn.utils.rnn.pad_sequence.size", "nn.utils.rnn.pad_sequence.size", "torch.arange().unsqueeze().unsqueeze().expand.long", "nn.utils.rnn.pad_sequence.long", "mask.long", "torch.sum().numpy", "torch.sum().numpy", "torch.sum().numpy", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange", "torch.arange", "torch.arange", "len", "torch.arange().unsqueeze().unsqueeze", "torch.arange().unsqueeze().unsqueeze", "torch.arange().unsqueeze().unsqueeze", "range", "torch.sum", "torch.sum", "torch.sum", "torch.arange", "torch.arange", "torch.arange", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "sep_tokens.size", "paragraph.size", "torch.arange", "torch.arange", "torch.arange", "sep_tokens.size"], "function", ["None"], ["", "def", "token_idx_by_sentence", "(", "input_ids", ",", "sep_token_id", ",", "model_name", ")", ":", "\n", "    ", "\"\"\"\n    Compute the token indices matrix of the BERT output.\n    input_ids: (batch_size, paragraph_len)\n    batch_indices, indices_by_batch, mask: (batch_size, N_sentence, N_token)\n    bert_out: (batch_size, paragraph_len,BERT_dim)\n    bert_out[batch_indices,indices_by_batch,:]: (batch_size, N_sentence, N_token, BERT_dim)\n    \"\"\"", "\n", "padding_idx", "=", "-", "1", "\n", "sep_tokens", "=", "(", "input_ids", "==", "sep_token_id", ")", ".", "bool", "(", ")", "\n", "paragraph_lens", "=", "torch", ".", "sum", "(", "sep_tokens", ",", "1", ")", ".", "numpy", "(", ")", ".", "tolist", "(", ")", "\n", "indices", "=", "torch", ".", "arange", "(", "sep_tokens", ".", "size", "(", "-", "1", ")", ")", ".", "unsqueeze", "(", "0", ")", ".", "expand", "(", "sep_tokens", ".", "size", "(", "0", ")", ",", "-", "1", ")", "\n", "sep_indices", "=", "torch", ".", "split", "(", "indices", "[", "sep_tokens", "]", ",", "paragraph_lens", ")", "\n", "paragraph_lens", "=", "[", "]", "\n", "all_word_indices", "=", "[", "]", "\n", "for", "paragraph", "in", "sep_indices", ":", "\n", "        ", "if", "\"roberta\"", "in", "model_name", ":", "\n", "            ", "paragraph", "=", "paragraph", "[", "1", ":", "]", "\n", "", "word_indices", "=", "[", "torch", ".", "arange", "(", "paragraph", "[", "i", "]", "+", "1", ",", "paragraph", "[", "i", "+", "1", "]", "+", "1", ")", "for", "i", "in", "range", "(", "paragraph", ".", "size", "(", "0", ")", "-", "1", ")", "]", "\n", "paragraph_lens", ".", "append", "(", "len", "(", "word_indices", ")", ")", "\n", "all_word_indices", ".", "extend", "(", "word_indices", ")", "\n", "", "indices_by_sentence", "=", "nn", ".", "utils", ".", "rnn", ".", "pad_sequence", "(", "all_word_indices", ",", "batch_first", "=", "True", ",", "padding_value", "=", "padding_idx", ")", "\n", "indices_by_sentence_split", "=", "torch", ".", "split", "(", "indices_by_sentence", ",", "paragraph_lens", ")", "\n", "indices_by_batch", "=", "nn", ".", "utils", ".", "rnn", ".", "pad_sequence", "(", "indices_by_sentence_split", ",", "batch_first", "=", "True", ",", "padding_value", "=", "padding_idx", ")", "\n", "batch_indices", "=", "torch", ".", "arange", "(", "sep_tokens", ".", "size", "(", "0", ")", ")", ".", "unsqueeze", "(", "-", "1", ")", ".", "unsqueeze", "(", "-", "1", ")", ".", "expand", "(", "-", "1", ",", "indices_by_batch", ".", "size", "(", "1", ")", ",", "indices_by_batch", ".", "size", "(", "-", "1", ")", ")", "\n", "mask", "=", "(", "indices_by_batch", ">=", "0", ")", "\n", "\n", "return", "batch_indices", ".", "long", "(", ")", ",", "indices_by_batch", ".", "long", "(", ")", ",", "mask", ".", "long", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.FEVER_joint_paragraph_kgat.schedule_sample_p": [[30, 32], ["numpy.sin"], "function", ["None"], ["def", "schedule_sample_p", "(", "epoch", ",", "total", ")", ":", "\n", "    ", "return", "np", ".", "sin", "(", "0.5", "*", "np", ".", "pi", "*", "epoch", "/", "(", "total", "-", "1", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.FEVER_joint_paragraph_kgat.reset_random_seed": [[33, 37], ["numpy.random.seed", "random.seed", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed"], "function", ["None"], ["", "def", "reset_random_seed", "(", "seed", ")", ":", "\n", "    ", "np", ".", "random", ".", "seed", "(", "seed", ")", "\n", "random", ".", "seed", "(", "seed", ")", "\n", "torch", ".", "manual_seed", "(", "seed", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.FEVER_joint_paragraph_kgat.batch_rationale_label": [[38, 47], ["max", "enumerate", "torch.ones", "torch.ones", "torch.ones", "enumerate", "label_list.append", "label_matrix.long", "len", "len", "int", "int"], "function", ["None"], ["", "def", "batch_rationale_label", "(", "labels", ",", "padding_idx", "=", "2", ")", ":", "\n", "    ", "max_sent_len", "=", "max", "(", "[", "len", "(", "label", ")", "for", "label", "in", "labels", "]", ")", "\n", "label_matrix", "=", "torch", ".", "ones", "(", "len", "(", "labels", ")", ",", "max_sent_len", ")", "*", "padding_idx", "\n", "label_list", "=", "[", "]", "\n", "for", "i", ",", "label", "in", "enumerate", "(", "labels", ")", ":", "\n", "        ", "for", "j", ",", "evid", "in", "enumerate", "(", "label", ")", ":", "\n", "            ", "label_matrix", "[", "i", ",", "j", "]", "=", "int", "(", "evid", ")", "\n", "", "label_list", ".", "append", "(", "[", "int", "(", "evid", ")", "for", "evid", "in", "label", "]", ")", "\n", "", "return", "label_matrix", ".", "long", "(", ")", ",", "label_list", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.FEVER_joint_paragraph_kgat.evaluation": [[48, 83], ["model.eval", "sklearn.metrics.f1_score", "sklearn.metrics.precision_score", "sklearn.metrics.recall_score", "sklearn.metrics.f1_score", "sklearn.metrics.precision_score", "sklearn.metrics.recall_score", "torch.no_grad", "torch.no_grad", "torch.no_grad", "tqdm.tqdm", "util.flatten", "util.flatten", "util.flatten", "util.flatten", "util.flatten", "util.flatten", "torch.utils.data.DataLoader", "FEVER_joint_paragraph_kgat.encode", "FEVER_joint_paragraph_kgat.token_idx_by_sentence", "batch[].to", "FEVER_joint_paragraph_kgat.batch_rationale_label", "model", "stance_preds.extend", "stance_labels.extend", "rationale_predictions.extend", "rationale_labels.extend", "tensor.to", "tensor.to", "batch[].to.cpu().numpy().tolist", "FEVER_joint_paragraph_kgat.evaluation.remove_dummy"], "function", ["home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.util.flatten", "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.util.flatten", "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.util.flatten", "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.util.flatten", "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.util.flatten", "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.util.flatten", "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.label_prediction.transformer_scifact.encode", "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.FEVER_stance_paragraph.token_idx_by_sentence", "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.domain_adaptation_joint_paragraph_fine_tune.batch_rationale_label", "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.src.utils.remove_dummy"], ["", "def", "evaluation", "(", "model", ",", "dataset", ")", ":", "\n", "    ", "model", ".", "eval", "(", ")", "\n", "rationale_predictions", "=", "[", "]", "\n", "rationale_labels", "=", "[", "]", "\n", "stance_preds", "=", "[", "]", "\n", "stance_labels", "=", "[", "]", "\n", "\n", "def", "remove_dummy", "(", "rationale_out", ")", ":", "\n", "        ", "return", "[", "out", "[", "1", ":", "]", "for", "out", "in", "rationale_out", "]", "\n", "\n", "", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "for", "batch", "in", "tqdm", "(", "DataLoader", "(", "dataset", ",", "batch_size", "=", "args", ".", "batch_size", ",", "shuffle", "=", "False", ")", ")", ":", "\n", "            ", "encoded_dict", "=", "encode", "(", "tokenizer", ",", "batch", ")", "\n", "transformation_indices", "=", "token_idx_by_sentence", "(", "encoded_dict", "[", "\"input_ids\"", "]", ",", "\n", "tokenizer", ".", "sep_token_id", ",", "args", ".", "repfile", ")", "\n", "encoded_dict", "=", "{", "key", ":", "tensor", ".", "to", "(", "device", ")", "for", "key", ",", "tensor", "in", "encoded_dict", ".", "items", "(", ")", "}", "\n", "transformation_indices", "=", "[", "tensor", ".", "to", "(", "device", ")", "for", "tensor", "in", "transformation_indices", "]", "\n", "stance_label", "=", "batch", "[", "\"stance\"", "]", ".", "to", "(", "device", ")", "\n", "padded_rationale_label", ",", "rationale_label", "=", "batch_rationale_label", "(", "batch", "[", "\"label\"", "]", ",", "padding_idx", "=", "2", ")", "\n", "rationale_out", ",", "stance_out", ",", "rationale_loss", ",", "stance_loss", "=", "model", "(", "encoded_dict", ",", "transformation_indices", ",", "stance_label", "=", "stance_label", ",", "\n", "rationale_label", "=", "padded_rationale_label", ".", "to", "(", "device", ")", ")", "\n", "stance_preds", ".", "extend", "(", "stance_out", ")", "\n", "stance_labels", ".", "extend", "(", "stance_label", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "tolist", "(", ")", ")", "\n", "\n", "rationale_predictions", ".", "extend", "(", "remove_dummy", "(", "rationale_out", ")", ")", "\n", "rationale_labels", ".", "extend", "(", "remove_dummy", "(", "rationale_label", ")", ")", "\n", "\n", "", "", "stance_f1", "=", "f1_score", "(", "stance_labels", ",", "stance_preds", ",", "average", "=", "\"micro\"", ",", "labels", "=", "[", "1", ",", "2", "]", ")", "\n", "stance_precision", "=", "precision_score", "(", "stance_labels", ",", "stance_preds", ",", "average", "=", "\"micro\"", ",", "labels", "=", "[", "1", ",", "2", "]", ")", "\n", "stance_recall", "=", "recall_score", "(", "stance_labels", ",", "stance_preds", ",", "average", "=", "\"micro\"", ",", "labels", "=", "[", "1", ",", "2", "]", ")", "\n", "rationale_f1", "=", "f1_score", "(", "flatten", "(", "rationale_labels", ")", ",", "flatten", "(", "rationale_predictions", ")", ")", "\n", "rationale_precision", "=", "precision_score", "(", "flatten", "(", "rationale_labels", ")", ",", "flatten", "(", "rationale_predictions", ")", ")", "\n", "rationale_recall", "=", "recall_score", "(", "flatten", "(", "rationale_labels", ")", ",", "flatten", "(", "rationale_predictions", ")", ")", "\n", "return", "stance_f1", ",", "stance_precision", ",", "stance_recall", ",", "rationale_f1", ",", "rationale_precision", ",", "rationale_recall", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.FEVER_joint_paragraph_kgat.encode": [[86, 135], ["zip", "tokenizer.batch_encode_plus", "torch.cat", "torch.cat", "torch.cat", "encoded_dict[].size", "len", "numpy.sum", "numpy.argmax", "valid_paragraph.size", "all_paragraphs.append", "longest_first_truncation"], "function", ["home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.dataset.encode.longest_first_truncation"], ["", "def", "encode", "(", "tokenizer", ",", "batch", ",", "max_sent_len", "=", "512", ")", ":", "\n", "    ", "def", "truncate", "(", "input_ids", ",", "max_length", ",", "sep_token_id", ",", "pad_token_id", ")", ":", "\n", "        ", "def", "longest_first_truncation", "(", "sentences", ",", "objective", ")", ":", "\n", "            ", "sent_lens", "=", "[", "len", "(", "sent", ")", "for", "sent", "in", "sentences", "]", "\n", "while", "np", ".", "sum", "(", "sent_lens", ")", ">", "objective", ":", "\n", "                ", "max_position", "=", "np", ".", "argmax", "(", "sent_lens", ")", "\n", "sent_lens", "[", "max_position", "]", "-=", "1", "\n", "", "return", "[", "sentence", "[", ":", "length", "]", "for", "sentence", ",", "length", "in", "zip", "(", "sentences", ",", "sent_lens", ")", "]", "\n", "\n", "", "all_paragraphs", "=", "[", "]", "\n", "for", "paragraph", "in", "input_ids", ":", "\n", "            ", "valid_paragraph", "=", "paragraph", "[", "paragraph", "!=", "pad_token_id", "]", "\n", "if", "valid_paragraph", ".", "size", "(", "0", ")", "<=", "max_length", ":", "\n", "                ", "all_paragraphs", ".", "append", "(", "paragraph", "[", ":", "max_length", "]", ".", "unsqueeze", "(", "0", ")", ")", "\n", "", "else", ":", "\n", "                ", "sep_token_idx", "=", "np", ".", "arange", "(", "valid_paragraph", ".", "size", "(", "0", ")", ")", "[", "(", "valid_paragraph", "==", "sep_token_id", ")", ".", "numpy", "(", ")", "]", "\n", "idx_by_sentence", "=", "[", "]", "\n", "prev_idx", "=", "0", "\n", "for", "idx", "in", "sep_token_idx", ":", "\n", "                    ", "idx_by_sentence", ".", "append", "(", "paragraph", "[", "prev_idx", ":", "idx", "]", ")", "\n", "prev_idx", "=", "idx", "\n", "", "objective", "=", "max_length", "-", "1", "-", "len", "(", "idx_by_sentence", "[", "0", "]", ")", "# The last sep_token left out", "\n", "truncated_sentences", "=", "longest_first_truncation", "(", "idx_by_sentence", "[", "1", ":", "]", ",", "objective", ")", "\n", "truncated_paragraph", "=", "torch", ".", "cat", "(", "[", "idx_by_sentence", "[", "0", "]", "]", "+", "truncated_sentences", "+", "[", "torch", ".", "tensor", "(", "[", "sep_token_id", "]", ")", "]", ",", "0", ")", "\n", "all_paragraphs", ".", "append", "(", "truncated_paragraph", ".", "unsqueeze", "(", "0", ")", ")", "\n", "\n", "", "", "return", "torch", ".", "cat", "(", "all_paragraphs", ",", "0", ")", "\n", "\n", "", "inputs", "=", "zip", "(", "batch", "[", "\"claim\"", "]", ",", "batch", "[", "\"paragraph\"", "]", ")", "\n", "encoded_dict", "=", "tokenizer", ".", "batch_encode_plus", "(", "\n", "inputs", ",", "\n", "pad_to_max_length", "=", "True", ",", "add_special_tokens", "=", "True", ",", "\n", "return_tensors", "=", "'pt'", ")", "\n", "if", "encoded_dict", "[", "'input_ids'", "]", ".", "size", "(", "1", ")", ">", "max_sent_len", ":", "\n", "        ", "if", "'token_type_ids'", "in", "encoded_dict", ":", "\n", "            ", "encoded_dict", "=", "{", "\n", "\"input_ids\"", ":", "truncate", "(", "encoded_dict", "[", "'input_ids'", "]", ",", "max_sent_len", ",", "\n", "tokenizer", ".", "sep_token_id", ",", "tokenizer", ".", "pad_token_id", ")", ",", "\n", "'token_type_ids'", ":", "encoded_dict", "[", "'token_type_ids'", "]", "[", ":", ",", ":", "max_sent_len", "]", ",", "\n", "'attention_mask'", ":", "encoded_dict", "[", "'attention_mask'", "]", "[", ":", ",", ":", "max_sent_len", "]", "\n", "}", "\n", "", "else", ":", "\n", "            ", "encoded_dict", "=", "{", "\n", "\"input_ids\"", ":", "truncate", "(", "encoded_dict", "[", "'input_ids'", "]", ",", "max_sent_len", ",", "\n", "tokenizer", ".", "sep_token_id", ",", "tokenizer", ".", "pad_token_id", ")", ",", "\n", "'attention_mask'", ":", "encoded_dict", "[", "'attention_mask'", "]", "[", ":", ",", ":", "max_sent_len", "]", "\n", "}", "\n", "\n", "", "", "return", "encoded_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.FEVER_joint_paragraph_kgat.token_idx_by_sentence": [[136, 171], ["torch.sum().numpy().tolist", "torch.sum().numpy().tolist", "torch.sum().numpy().tolist", "torch.arange().unsqueeze().expand", "torch.arange().unsqueeze().expand", "torch.arange().unsqueeze().expand", "torch.split", "torch.split", "torch.split", "torch.utils.rnn.pad_sequence", "torch.split", "torch.split", "torch.split", "torch.utils.rnn.pad_sequence", "torch.arange().unsqueeze().unsqueeze().expand", "torch.arange().unsqueeze().unsqueeze().expand", "torch.arange().unsqueeze().unsqueeze().expand", "sep_tokens.size", "torch.arange", "torch.arange", "torch.arange", "torch.sum().numpy().tolist.append", "all_word_indices.extend", "nn.utils.rnn.pad_sequence.size", "nn.utils.rnn.pad_sequence.size", "torch.arange().unsqueeze().unsqueeze().expand.long", "nn.utils.rnn.pad_sequence.long", "mask.long", "torch.sum().numpy", "torch.sum().numpy", "torch.sum().numpy", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange", "torch.arange", "torch.arange", "len", "torch.arange().unsqueeze().unsqueeze", "torch.arange().unsqueeze().unsqueeze", "torch.arange().unsqueeze().unsqueeze", "range", "torch.sum", "torch.sum", "torch.sum", "torch.arange", "torch.arange", "torch.arange", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "sep_tokens.size", "paragraph.size", "torch.arange", "torch.arange", "torch.arange", "sep_tokens.size"], "function", ["None"], ["", "def", "token_idx_by_sentence", "(", "input_ids", ",", "sep_token_id", ",", "model_name", ")", ":", "\n", "    ", "\"\"\"\n    Advanced indexing: Compute the token indices matrix of the BERT output.\n    input_ids: (batch_size, paragraph_len)\n    batch_indices, indices_by_batch, mask: (batch_size, N_sentence, N_token)\n    bert_out: (batch_size, paragraph_len,BERT_dim)\n    bert_out[batch_indices,indices_by_batch,:]: (batch_size, N_sentence, N_token, BERT_dim)\n    \"\"\"", "\n", "padding_idx", "=", "-", "1", "\n", "sep_tokens", "=", "(", "input_ids", "==", "sep_token_id", ")", ".", "bool", "(", ")", "\n", "paragraph_lens", "=", "torch", ".", "sum", "(", "sep_tokens", ",", "1", ")", ".", "numpy", "(", ")", ".", "tolist", "(", ")", "# i.e. N_sentences per paragraph", "\n", "indices", "=", "torch", ".", "arange", "(", "sep_tokens", ".", "size", "(", "-", "1", ")", ")", ".", "unsqueeze", "(", "0", ")", ".", "expand", "(", "sep_tokens", ".", "size", "(", "0", ")", ",", "-", "1", ")", "# 0,1,2,3,....,511 for each sentence", "\n", "sep_indices", "=", "torch", ".", "split", "(", "indices", "[", "sep_tokens", "]", ",", "paragraph_lens", ")", "# indices of SEP tokens per paragraph", "\n", "paragraph_lens", "=", "[", "]", "\n", "all_word_indices", "=", "[", "]", "\n", "for", "paragraph", "in", "sep_indices", ":", "\n", "# claim sentence: [CLS] token1 token2 ... tokenk", "\n", "        ", "claim_word_indices", "=", "torch", ".", "arange", "(", "0", ",", "paragraph", "[", "0", "]", ")", "\n", "if", "\"roberta\"", "in", "model_name", ":", "# Huggingface Roberta has <s>..</s></s>..</s>..</s>", "\n", "            ", "paragraph", "=", "paragraph", "[", "1", ":", "]", "\n", "# each sentence: [SEP] token1 token2 ... tokenk, the last [SEP] in the paragraph is ditched.", "\n", "", "sentence_word_indices", "=", "[", "torch", ".", "arange", "(", "paragraph", "[", "i", "]", ",", "paragraph", "[", "i", "+", "1", "]", ")", "for", "i", "in", "range", "(", "paragraph", ".", "size", "(", "0", ")", "-", "1", ")", "]", "\n", "\n", "# KGAT requires claim sentence, so add it back.", "\n", "word_indices", "=", "[", "claim_word_indices", "]", "+", "sentence_word_indices", "\n", "\n", "paragraph_lens", ".", "append", "(", "len", "(", "word_indices", ")", ")", "\n", "all_word_indices", ".", "extend", "(", "word_indices", ")", "\n", "", "indices_by_sentence", "=", "nn", ".", "utils", ".", "rnn", ".", "pad_sequence", "(", "all_word_indices", ",", "batch_first", "=", "True", ",", "padding_value", "=", "padding_idx", ")", "\n", "indices_by_sentence_split", "=", "torch", ".", "split", "(", "indices_by_sentence", ",", "paragraph_lens", ")", "\n", "indices_by_batch", "=", "nn", ".", "utils", ".", "rnn", ".", "pad_sequence", "(", "indices_by_sentence_split", ",", "batch_first", "=", "True", ",", "padding_value", "=", "padding_idx", ")", "\n", "batch_indices", "=", "torch", ".", "arange", "(", "sep_tokens", ".", "size", "(", "0", ")", ")", ".", "unsqueeze", "(", "-", "1", ")", ".", "unsqueeze", "(", "-", "1", ")", ".", "expand", "(", "-", "1", ",", "indices_by_batch", ".", "size", "(", "1", ")", ",", "indices_by_batch", ".", "size", "(", "-", "1", ")", ")", "\n", "mask", "=", "(", "indices_by_batch", ">=", "0", ")", "\n", "\n", "return", "batch_indices", ".", "long", "(", ")", ",", "indices_by_batch", ".", "long", "(", ")", ",", "mask", ".", "long", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.domain_adaptation_joint_paragraph_kgat.schedule_sample_p": [[30, 32], ["numpy.sin"], "function", ["None"], ["def", "schedule_sample_p", "(", "epoch", ",", "total", ")", ":", "\n", "    ", "return", "np", ".", "sin", "(", "0.5", "*", "np", ".", "pi", "*", "epoch", "/", "(", "total", "-", "1", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.domain_adaptation_joint_paragraph_kgat.reset_random_seed": [[33, 37], ["numpy.random.seed", "random.seed", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed"], "function", ["None"], ["", "def", "reset_random_seed", "(", "seed", ")", ":", "\n", "    ", "np", ".", "random", ".", "seed", "(", "seed", ")", "\n", "random", ".", "seed", "(", "seed", ")", "\n", "torch", ".", "manual_seed", "(", "seed", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.domain_adaptation_joint_paragraph_kgat.batch_rationale_label": [[38, 47], ["max", "enumerate", "torch.ones", "torch.ones", "torch.ones", "enumerate", "label_list.append", "label_matrix.long", "len", "len", "int", "int"], "function", ["None"], ["", "def", "batch_rationale_label", "(", "labels", ",", "padding_idx", "=", "2", ")", ":", "\n", "    ", "max_sent_len", "=", "max", "(", "[", "len", "(", "label", ")", "for", "label", "in", "labels", "]", ")", "\n", "label_matrix", "=", "torch", ".", "ones", "(", "len", "(", "labels", ")", ",", "max_sent_len", ")", "*", "padding_idx", "\n", "label_list", "=", "[", "]", "\n", "for", "i", ",", "label", "in", "enumerate", "(", "labels", ")", ":", "\n", "        ", "for", "j", ",", "evid", "in", "enumerate", "(", "label", ")", ":", "\n", "            ", "label_matrix", "[", "i", ",", "j", "]", "=", "int", "(", "evid", ")", "\n", "", "label_list", ".", "append", "(", "[", "int", "(", "evid", ")", "for", "evid", "in", "label", "]", ")", "\n", "", "return", "label_matrix", ".", "long", "(", ")", ",", "label_list", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.domain_adaptation_joint_paragraph_kgat.evaluation": [[48, 84], ["model.eval", "sklearn.metrics.f1_score", "sklearn.metrics.precision_score", "sklearn.metrics.recall_score", "sklearn.metrics.f1_score", "sklearn.metrics.precision_score", "sklearn.metrics.recall_score", "torch.no_grad", "torch.no_grad", "torch.no_grad", "tqdm.tqdm", "util.flatten", "util.flatten", "util.flatten", "util.flatten", "util.flatten", "util.flatten", "torch.utils.data.DataLoader", "domain_adaptation_joint_paragraph_kgat.encode", "domain_adaptation_joint_paragraph_kgat.token_idx_by_sentence", "batch[].to", "batch[].to", "domain_adaptation_joint_paragraph_kgat.batch_rationale_label", "model", "stance_preds.extend", "stance_labels.extend", "rationale_predictions.extend", "rationale_labels.extend", "tensor.to", "tensor.to", "batch[].to.cpu().numpy().tolist", "domain_adaptation_joint_paragraph_kgat.evaluation.remove_dummy"], "function", ["home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.util.flatten", "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.util.flatten", "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.util.flatten", "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.util.flatten", "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.util.flatten", "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.util.flatten", "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.label_prediction.transformer_scifact.encode", "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.FEVER_stance_paragraph.token_idx_by_sentence", "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.domain_adaptation_joint_paragraph_fine_tune.batch_rationale_label", "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.src.utils.remove_dummy"], ["", "def", "evaluation", "(", "model", ",", "dataset", ")", ":", "\n", "    ", "model", ".", "eval", "(", ")", "\n", "rationale_predictions", "=", "[", "]", "\n", "rationale_labels", "=", "[", "]", "\n", "stance_preds", "=", "[", "]", "\n", "stance_labels", "=", "[", "]", "\n", "\n", "def", "remove_dummy", "(", "rationale_out", ")", ":", "\n", "        ", "return", "[", "out", "[", "1", ":", "]", "for", "out", "in", "rationale_out", "]", "\n", "\n", "", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "for", "batch", "in", "tqdm", "(", "DataLoader", "(", "dataset", ",", "batch_size", "=", "args", ".", "batch_size", ",", "shuffle", "=", "False", ")", ")", ":", "\n", "            ", "encoded_dict", "=", "encode", "(", "tokenizer", ",", "batch", ")", "\n", "transformation_indices", "=", "token_idx_by_sentence", "(", "encoded_dict", "[", "\"input_ids\"", "]", ",", "\n", "tokenizer", ".", "sep_token_id", ",", "args", ".", "repfile", ")", "\n", "encoded_dict", "=", "{", "key", ":", "tensor", ".", "to", "(", "device", ")", "for", "key", ",", "tensor", "in", "encoded_dict", ".", "items", "(", ")", "}", "\n", "transformation_indices", "=", "[", "tensor", ".", "to", "(", "device", ")", "for", "tensor", "in", "transformation_indices", "]", "\n", "stance_label", "=", "batch", "[", "\"stance\"", "]", ".", "to", "(", "device", ")", "\n", "domain_indices", "=", "batch", "[", "\"dataset\"", "]", ".", "to", "(", "device", ")", "\n", "padded_rationale_label", ",", "rationale_label", "=", "batch_rationale_label", "(", "batch", "[", "\"label\"", "]", ",", "padding_idx", "=", "2", ")", "\n", "rationale_out", ",", "stance_out", ",", "rationale_loss", ",", "stance_loss", "=", "model", "(", "encoded_dict", ",", "transformation_indices", ",", "domain_indices", ",", "stance_label", "=", "stance_label", ",", "\n", "rationale_label", "=", "padded_rationale_label", ".", "to", "(", "device", ")", ")", "\n", "stance_preds", ".", "extend", "(", "stance_out", ")", "\n", "stance_labels", ".", "extend", "(", "stance_label", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "tolist", "(", ")", ")", "\n", "\n", "rationale_predictions", ".", "extend", "(", "remove_dummy", "(", "rationale_out", ")", ")", "\n", "rationale_labels", ".", "extend", "(", "remove_dummy", "(", "rationale_label", ")", ")", "\n", "\n", "", "", "stance_f1", "=", "f1_score", "(", "stance_labels", ",", "stance_preds", ",", "average", "=", "\"micro\"", ",", "labels", "=", "[", "1", ",", "2", "]", ")", "\n", "stance_precision", "=", "precision_score", "(", "stance_labels", ",", "stance_preds", ",", "average", "=", "\"micro\"", ",", "labels", "=", "[", "1", ",", "2", "]", ")", "\n", "stance_recall", "=", "recall_score", "(", "stance_labels", ",", "stance_preds", ",", "average", "=", "\"micro\"", ",", "labels", "=", "[", "1", ",", "2", "]", ")", "\n", "rationale_f1", "=", "f1_score", "(", "flatten", "(", "rationale_labels", ")", ",", "flatten", "(", "rationale_predictions", ")", ")", "\n", "rationale_precision", "=", "precision_score", "(", "flatten", "(", "rationale_labels", ")", ",", "flatten", "(", "rationale_predictions", ")", ")", "\n", "rationale_recall", "=", "recall_score", "(", "flatten", "(", "rationale_labels", ")", ",", "flatten", "(", "rationale_predictions", ")", ")", "\n", "return", "stance_f1", ",", "stance_precision", ",", "stance_recall", ",", "rationale_f1", ",", "rationale_precision", ",", "rationale_recall", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.domain_adaptation_joint_paragraph_kgat.run_evaluation": [[85, 113], ["domain_adaptation_joint_paragraph_kgat.evaluation", "print", "domain_adaptation_joint_paragraph_kgat.evaluation", "print", "domain_adaptation_joint_paragraph_kgat.evaluation", "print", "domain_adaptation_joint_paragraph_kgat.evaluation", "print", "len", "torch.utils.data.Subset", "len", "torch.utils.data.Subset", "len", "torch.utils.data.Subset", "range", "range", "range"], "function", ["home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.FEVER_stance_paragraph.evaluation", "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.FEVER_stance_paragraph.evaluation", "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.FEVER_stance_paragraph.evaluation", "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.FEVER_stance_paragraph.evaluation"], ["", "def", "run_evaluation", "(", ")", ":", "\n", "# Evaluation", "\n", "    ", "if", "args", ".", "N_evaluation_sample", "<", "len", "(", "train_fever", ")", ":", "\n", "        ", "subset_train_fever", "=", "Subset", "(", "train_fever", ",", "range", "(", "0", ",", "args", ".", "N_evaluation_sample", ")", ")", "\n", "", "else", ":", "\n", "        ", "subset_train_fever", "=", "train_fever", "\n", "", "train_score", "=", "evaluation", "(", "model", ",", "subset_train_fever", ")", "\n", "print", "(", "f'Epoch {epoch}, iteration {i}, FEVER train stance f1 p r: %.4f, %.4f, %.4f, rationale f1 p r: %.4f, %.4f, %.4f'", "%", "train_score", ")", "\n", "if", "args", ".", "N_evaluation_sample", "<", "len", "(", "train_scifact", ")", ":", "\n", "        ", "subset_train_scifact", "=", "Subset", "(", "train_scifact", ",", "range", "(", "0", ",", "args", ".", "N_evaluation_sample", ")", ")", "\n", "", "else", ":", "\n", "        ", "subset_train_scifact", "=", "train_scifact", "\n", "", "train_score", "=", "evaluation", "(", "model", ",", "subset_train_scifact", ")", "\n", "print", "(", "f'Epoch {epoch}, iteration {i}, SciFact train stance f1 p r: %.4f, %.4f, %.4f, rationale f1 p r: %.4f, %.4f, %.4f'", "%", "train_score", ")", "\n", "\n", "if", "args", ".", "N_evaluation_sample", "<", "len", "(", "dev_fever", ")", ":", "\n", "        ", "subset_dev_fever", "=", "Subset", "(", "dev_fever", ",", "range", "(", "0", ",", "args", ".", "N_evaluation_sample", ")", ")", "\n", "", "else", ":", "\n", "        ", "subset_dev_fever", "=", "dev_fever", "\n", "", "dev_score", "=", "evaluation", "(", "model", ",", "subset_dev_fever", ")", "\n", "print", "(", "f'Epoch {epoch}, iteration {i}, FEVER dev stance f1 p r: %.4f, %.4f, %.4f, rationale f1 p r: %.4f, %.4f, %.4f'", "%", "dev_score", ")", "\n", "#if args.N_evaluation_sample < len(dev_scifact):", "\n", "#    subset_dev_scifact = Subset(dev_scifact, range(0, args.N_evaluation_sample))", "\n", "#else:", "\n", "#    subset_dev_scifact = dev_scifact", "\n", "#dev_score = evaluation(model, subset_dev_scifact)", "\n", "dev_score", "=", "evaluation", "(", "model", ",", "dev_scifact", ")", "\n", "print", "(", "f'Epoch {epoch}, iteration {i}, SciFact dev stance f1 p r: %.4f, %.4f, %.4f, rationale f1 p r: %.4f, %.4f, %.4f'", "%", "dev_score", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.domain_adaptation_joint_paragraph_kgat.encode": [[114, 163], ["zip", "tokenizer.batch_encode_plus", "torch.cat", "torch.cat", "torch.cat", "encoded_dict[].size", "len", "numpy.sum", "numpy.argmax", "valid_paragraph.size", "all_paragraphs.append", "longest_first_truncation"], "function", ["home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.dataset.encode.longest_first_truncation"], ["", "def", "encode", "(", "tokenizer", ",", "batch", ",", "max_sent_len", "=", "512", ")", ":", "\n", "    ", "def", "truncate", "(", "input_ids", ",", "max_length", ",", "sep_token_id", ",", "pad_token_id", ")", ":", "\n", "        ", "def", "longest_first_truncation", "(", "sentences", ",", "objective", ")", ":", "\n", "            ", "sent_lens", "=", "[", "len", "(", "sent", ")", "for", "sent", "in", "sentences", "]", "\n", "while", "np", ".", "sum", "(", "sent_lens", ")", ">", "objective", ":", "\n", "                ", "max_position", "=", "np", ".", "argmax", "(", "sent_lens", ")", "\n", "sent_lens", "[", "max_position", "]", "-=", "1", "\n", "", "return", "[", "sentence", "[", ":", "length", "]", "for", "sentence", ",", "length", "in", "zip", "(", "sentences", ",", "sent_lens", ")", "]", "\n", "\n", "", "all_paragraphs", "=", "[", "]", "\n", "for", "paragraph", "in", "input_ids", ":", "\n", "            ", "valid_paragraph", "=", "paragraph", "[", "paragraph", "!=", "pad_token_id", "]", "\n", "if", "valid_paragraph", ".", "size", "(", "0", ")", "<=", "max_length", ":", "\n", "                ", "all_paragraphs", ".", "append", "(", "paragraph", "[", ":", "max_length", "]", ".", "unsqueeze", "(", "0", ")", ")", "\n", "", "else", ":", "\n", "                ", "sep_token_idx", "=", "np", ".", "arange", "(", "valid_paragraph", ".", "size", "(", "0", ")", ")", "[", "(", "valid_paragraph", "==", "sep_token_id", ")", ".", "numpy", "(", ")", "]", "\n", "idx_by_sentence", "=", "[", "]", "\n", "prev_idx", "=", "0", "\n", "for", "idx", "in", "sep_token_idx", ":", "\n", "                    ", "idx_by_sentence", ".", "append", "(", "paragraph", "[", "prev_idx", ":", "idx", "]", ")", "\n", "prev_idx", "=", "idx", "\n", "", "objective", "=", "max_length", "-", "1", "-", "len", "(", "idx_by_sentence", "[", "0", "]", ")", "# The last sep_token left out", "\n", "truncated_sentences", "=", "longest_first_truncation", "(", "idx_by_sentence", "[", "1", ":", "]", ",", "objective", ")", "\n", "truncated_paragraph", "=", "torch", ".", "cat", "(", "[", "idx_by_sentence", "[", "0", "]", "]", "+", "truncated_sentences", "+", "[", "torch", ".", "tensor", "(", "[", "sep_token_id", "]", ")", "]", ",", "0", ")", "\n", "all_paragraphs", ".", "append", "(", "truncated_paragraph", ".", "unsqueeze", "(", "0", ")", ")", "\n", "\n", "", "", "return", "torch", ".", "cat", "(", "all_paragraphs", ",", "0", ")", "\n", "\n", "", "inputs", "=", "zip", "(", "batch", "[", "\"claim\"", "]", ",", "batch", "[", "\"paragraph\"", "]", ")", "\n", "encoded_dict", "=", "tokenizer", ".", "batch_encode_plus", "(", "\n", "inputs", ",", "\n", "pad_to_max_length", "=", "True", ",", "add_special_tokens", "=", "True", ",", "\n", "return_tensors", "=", "'pt'", ")", "\n", "if", "encoded_dict", "[", "'input_ids'", "]", ".", "size", "(", "1", ")", ">", "max_sent_len", ":", "\n", "        ", "if", "'token_type_ids'", "in", "encoded_dict", ":", "\n", "            ", "encoded_dict", "=", "{", "\n", "\"input_ids\"", ":", "truncate", "(", "encoded_dict", "[", "'input_ids'", "]", ",", "max_sent_len", ",", "\n", "tokenizer", ".", "sep_token_id", ",", "tokenizer", ".", "pad_token_id", ")", ",", "\n", "'token_type_ids'", ":", "encoded_dict", "[", "'token_type_ids'", "]", "[", ":", ",", ":", "max_sent_len", "]", ",", "\n", "'attention_mask'", ":", "encoded_dict", "[", "'attention_mask'", "]", "[", ":", ",", ":", "max_sent_len", "]", "\n", "}", "\n", "", "else", ":", "\n", "            ", "encoded_dict", "=", "{", "\n", "\"input_ids\"", ":", "truncate", "(", "encoded_dict", "[", "'input_ids'", "]", ",", "max_sent_len", ",", "\n", "tokenizer", ".", "sep_token_id", ",", "tokenizer", ".", "pad_token_id", ")", ",", "\n", "'attention_mask'", ":", "encoded_dict", "[", "'attention_mask'", "]", "[", ":", ",", ":", "max_sent_len", "]", "\n", "}", "\n", "\n", "", "", "return", "encoded_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.domain_adaptation_joint_paragraph_kgat.token_idx_by_sentence": [[164, 199], ["torch.sum().numpy().tolist", "torch.sum().numpy().tolist", "torch.sum().numpy().tolist", "torch.arange().unsqueeze().expand", "torch.arange().unsqueeze().expand", "torch.arange().unsqueeze().expand", "torch.split", "torch.split", "torch.split", "torch.utils.rnn.pad_sequence", "torch.split", "torch.split", "torch.split", "torch.utils.rnn.pad_sequence", "torch.arange().unsqueeze().unsqueeze().expand", "torch.arange().unsqueeze().unsqueeze().expand", "torch.arange().unsqueeze().unsqueeze().expand", "sep_tokens.size", "torch.arange", "torch.arange", "torch.arange", "torch.sum().numpy().tolist.append", "all_word_indices.extend", "nn.utils.rnn.pad_sequence.size", "nn.utils.rnn.pad_sequence.size", "torch.arange().unsqueeze().unsqueeze().expand.long", "nn.utils.rnn.pad_sequence.long", "mask.long", "torch.sum().numpy", "torch.sum().numpy", "torch.sum().numpy", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange", "torch.arange", "torch.arange", "len", "torch.arange().unsqueeze().unsqueeze", "torch.arange().unsqueeze().unsqueeze", "torch.arange().unsqueeze().unsqueeze", "range", "torch.sum", "torch.sum", "torch.sum", "torch.arange", "torch.arange", "torch.arange", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "sep_tokens.size", "paragraph.size", "torch.arange", "torch.arange", "torch.arange", "sep_tokens.size"], "function", ["None"], ["", "def", "token_idx_by_sentence", "(", "input_ids", ",", "sep_token_id", ",", "model_name", ")", ":", "\n", "    ", "\"\"\"\n    Advanced indexing: Compute the token indices matrix of the BERT output.\n    input_ids: (batch_size, paragraph_len)\n    batch_indices, indices_by_batch, mask: (batch_size, N_sentence, N_token)\n    bert_out: (batch_size, paragraph_len,BERT_dim)\n    bert_out[batch_indices,indices_by_batch,:]: (batch_size, N_sentence, N_token, BERT_dim)\n    \"\"\"", "\n", "padding_idx", "=", "-", "1", "\n", "sep_tokens", "=", "(", "input_ids", "==", "sep_token_id", ")", ".", "bool", "(", ")", "\n", "paragraph_lens", "=", "torch", ".", "sum", "(", "sep_tokens", ",", "1", ")", ".", "numpy", "(", ")", ".", "tolist", "(", ")", "# i.e. N_sentences per paragraph", "\n", "indices", "=", "torch", ".", "arange", "(", "sep_tokens", ".", "size", "(", "-", "1", ")", ")", ".", "unsqueeze", "(", "0", ")", ".", "expand", "(", "sep_tokens", ".", "size", "(", "0", ")", ",", "-", "1", ")", "# 0,1,2,3,....,511 for each sentence", "\n", "sep_indices", "=", "torch", ".", "split", "(", "indices", "[", "sep_tokens", "]", ",", "paragraph_lens", ")", "# indices of SEP tokens per paragraph", "\n", "paragraph_lens", "=", "[", "]", "\n", "all_word_indices", "=", "[", "]", "\n", "for", "paragraph", "in", "sep_indices", ":", "\n", "# claim sentence: [CLS] token1 token2 ... tokenk", "\n", "        ", "claim_word_indices", "=", "torch", ".", "arange", "(", "0", ",", "paragraph", "[", "0", "]", ")", "\n", "if", "\"roberta\"", "in", "model_name", ":", "# Huggingface Roberta has <s>..</s></s>..</s>..</s>", "\n", "            ", "paragraph", "=", "paragraph", "[", "1", ":", "]", "\n", "# each sentence: [SEP] token1 token2 ... tokenk, the last [SEP] in the paragraph is ditched.", "\n", "", "sentence_word_indices", "=", "[", "torch", ".", "arange", "(", "paragraph", "[", "i", "]", ",", "paragraph", "[", "i", "+", "1", "]", ")", "for", "i", "in", "range", "(", "paragraph", ".", "size", "(", "0", ")", "-", "1", ")", "]", "\n", "\n", "# KGAT requires claim sentence, so add it back.", "\n", "word_indices", "=", "[", "claim_word_indices", "]", "+", "sentence_word_indices", "\n", "\n", "paragraph_lens", ".", "append", "(", "len", "(", "word_indices", ")", ")", "\n", "all_word_indices", ".", "extend", "(", "word_indices", ")", "\n", "", "indices_by_sentence", "=", "nn", ".", "utils", ".", "rnn", ".", "pad_sequence", "(", "all_word_indices", ",", "batch_first", "=", "True", ",", "padding_value", "=", "padding_idx", ")", "\n", "indices_by_sentence_split", "=", "torch", ".", "split", "(", "indices_by_sentence", ",", "paragraph_lens", ")", "\n", "indices_by_batch", "=", "nn", ".", "utils", ".", "rnn", ".", "pad_sequence", "(", "indices_by_sentence_split", ",", "batch_first", "=", "True", ",", "padding_value", "=", "padding_idx", ")", "\n", "batch_indices", "=", "torch", ".", "arange", "(", "sep_tokens", ".", "size", "(", "0", ")", ")", ".", "unsqueeze", "(", "-", "1", ")", ".", "unsqueeze", "(", "-", "1", ")", ".", "expand", "(", "-", "1", ",", "indices_by_batch", ".", "size", "(", "1", ")", ",", "indices_by_batch", ".", "size", "(", "-", "1", ")", ")", "\n", "mask", "=", "(", "indices_by_batch", ">=", "0", ")", "\n", "\n", "return", "batch_indices", ".", "long", "(", ")", ",", "indices_by_batch", ".", "long", "(", ")", ",", "mask", ".", "long", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.dataset.SciDTdataset.__init__": [[8, 74], ["util.read_passages", "enumerate", "util.clean_words", "enumerate", "dataset.SciDTdataset.true_pairs.append", "util.to_BIO", "len", "zip", "range", "dataset.SciDTdataset.label_ind.items", "len", "range", "enumerate", "len", "len", "dataset.SciDTdataset.samples.append", "range", "range", "len", "len"], "methods", ["home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.util.read_passages", "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.util.clean_words", "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.util.to_BIO"], ["    ", "def", "__init__", "(", "self", ",", "path", ":", "str", ",", "MAX_SEQ_LEN", ":", "int", ",", "CHUNK_SIZE", ":", "int", ",", "label_ind", "=", "None", ",", "train", "=", "False", ",", "shuffle", "=", "False", ",", "BIO", "=", "True", ")", ":", "\n", "        ", "self", ".", "shuffle", "=", "shuffle", "\n", "self", ".", "n_paragraph_slices", "=", "0", "\n", "self", ".", "MAX_SEQ_LEN", "=", "MAX_SEQ_LEN", "\n", "self", ".", "CHUNK_SIZE", "=", "CHUNK_SIZE", "\n", "n_pieces", "=", "MAX_SEQ_LEN", "//", "CHUNK_SIZE", "\n", "n_pieces", "+=", "1", "if", "MAX_SEQ_LEN", "%", "CHUNK_SIZE", ">", "0", "else", "0", "\n", "self", ".", "samples", "=", "[", "]", "\n", "self", ".", "true_pairs", "=", "[", "]", "# The unprocessed paragraph - tag pairs.", "\n", "str_seqs", ",", "label_seqs", "=", "read_passages", "(", "path", ",", "is_labeled", "=", "train", ")", "\n", "self", ".", "str_seqs", "=", "str_seqs", "\n", "self", ".", "label_seqs", "=", "label_seqs", "\n", "for", "pi", ",", "str_seq", "in", "enumerate", "(", "str_seqs", ")", ":", "\n", "            ", "self", ".", "true_pairs", ".", "append", "(", "{", "\n", "'paragraph_id'", ":", "pi", ",", "\n", "'paragraph'", ":", "str_seq", ",", "\n", "'label'", ":", "label_seqs", "[", "pi", "]", "\n", "}", ")", "\n", "\n", "", "str_seqs", "=", "clean_words", "(", "str_seqs", ")", "\n", "if", "BIO", ":", "\n", "            ", "label_seqs", "=", "to_BIO", "(", "label_seqs", ")", "\n", "\n", "", "if", "not", "label_ind", ":", "\n", "            ", "self", ".", "label_ind", "=", "{", "\"none\"", ":", "0", "}", "\n", "", "else", ":", "\n", "            ", "self", ".", "label_ind", "=", "label_ind", "\n", "\n", "", "if", "len", "(", "self", ".", "label_ind", ")", "<=", "1", ":", "\n", "            ", "for", "str_seq", ",", "label_seq", "in", "zip", "(", "str_seqs", ",", "label_seqs", ")", ":", "\n", "                ", "for", "label", "in", "label_seq", ":", "\n", "                    ", "if", "label", "not", "in", "self", ".", "label_ind", ":", "\n", "# Add new labels with values 0,1,2,....", "\n", "                        ", "self", ".", "label_ind", "[", "label", "]", "=", "len", "(", "self", ".", "label_ind", ")", "\n", "\n", "", "", "", "", "self", ".", "rev_label_ind", "=", "{", "i", ":", "l", "for", "(", "l", ",", "i", ")", "in", "self", ".", "label_ind", ".", "items", "(", ")", "}", "\n", "\n", "for", "pi", ",", "str_seq", "in", "enumerate", "(", "str_seqs", ")", ":", "\n", "            ", "n_paragraph_slices", "=", "len", "(", "str_seq", ")", "//", "MAX_SEQ_LEN", "\n", "n_paragraph_slices", "+=", "1", "if", "len", "(", "str_seq", ")", "%", "MAX_SEQ_LEN", ">", "0", "else", "0", "\n", "self", ".", "n_paragraph_slices", "+=", "n_paragraph_slices", "\n", "for", "p_slice", "in", "range", "(", "n_paragraph_slices", ")", ":", "\n", "                ", "this_slice", "=", "str_seq", "[", "p_slice", "*", "MAX_SEQ_LEN", ":", "(", "p_slice", "+", "1", ")", "*", "MAX_SEQ_LEN", "]", "\n", "padded_paragraph", "=", "this_slice", "+", "[", "\"\"", "for", "i", "in", "range", "(", "CHUNK_SIZE", "*", "n_pieces", "-", "len", "(", "this_slice", ")", ")", "]", "\n", "\n", "if", "train", ":", "\n", "                    ", "this_slice_tag", "=", "label_seqs", "[", "pi", "]", "[", "p_slice", "*", "MAX_SEQ_LEN", ":", "(", "p_slice", "+", "1", ")", "*", "MAX_SEQ_LEN", "]", "\n", "padded_tag", "=", "this_slice_tag", "+", "[", "\"none\"", "for", "i", "in", "range", "(", "CHUNK_SIZE", "*", "n_pieces", "-", "len", "(", "this_slice", ")", ")", "]", "\n", "\n", "", "for", "p", "in", "range", "(", "n_pieces", ")", ":", "\n", "                    ", "this_piece", "=", "padded_paragraph", "[", "p", "*", "CHUNK_SIZE", ":", "(", "p", "+", "1", ")", "*", "CHUNK_SIZE", "]", "\n", "if", "train", ":", "\n", "                        ", "this_piece_tag", "=", "padded_tag", "[", "p", "*", "CHUNK_SIZE", ":", "(", "p", "+", "1", ")", "*", "CHUNK_SIZE", "]", "\n", "\n", "", "for", "i", ",", "sentence", "in", "enumerate", "(", "this_piece", ")", ":", "\n", "                        ", "sentence_id", "=", "i", "+", "p", "*", "CHUNK_SIZE", "+", "p_slice", "*", "MAX_SEQ_LEN", "\n", "this_sample", "=", "{", "\n", "'paragraph_id'", ":", "pi", ",", "\n", "'sentence'", ":", "sentence", ",", "\n", "'sentence_id'", ":", "sentence_id", ",", "\n", "}", "\n", "\n", "if", "train", ":", "\n", "                            ", "this_sample", "[", "'label'", "]", "=", "self", ".", "label_ind", "[", "this_piece_tag", "[", "i", "]", "]", "\n", "\n", "", "self", ".", "samples", ".", "append", "(", "this_sample", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.dataset.SciDTdataset.__make_shuffle_idx": [[75, 78], ["random.shuffle", "range"], "methods", ["None"], ["", "", "", "", "", "def", "__make_shuffle_idx", "(", "self", ")", ":", "\n", "        ", "self", ".", "paragraph_indices", "=", "[", "i", "for", "i", "in", "range", "(", "self", ".", "n_paragraph_slices", ")", "]", "\n", "random", ".", "shuffle", "(", "self", ".", "paragraph_indices", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.dataset.SciDTdataset.__len__": [[79, 81], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "samples", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.dataset.SciDTdataset.__getitem__": [[82, 96], ["dataset.SciDTdataset.__make_shuffle_idx"], "methods", ["home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.dataset.SciFactSubParagraphDataset.__make_shuffle_idx"], ["", "def", "__getitem__", "(", "self", ",", "idx", ")", ":", "\n", "        ", "if", "self", ".", "shuffle", ":", "\n", "            ", "if", "idx", "==", "0", ":", "\n", "                ", "self", ".", "__make_shuffle_idx", "(", ")", "\n", "\n", "", "paragraph_idx", "=", "idx", "//", "self", ".", "MAX_SEQ_LEN", "\n", "offset", "=", "idx", "%", "self", ".", "MAX_SEQ_LEN", "\n", "\n", "original_idx", "=", "self", ".", "paragraph_indices", "[", "paragraph_idx", "]", "*", "self", ".", "MAX_SEQ_LEN", "+", "offset", "\n", "\n", "", "else", ":", "\n", "            ", "original_idx", "=", "idx", "\n", "\n", "", "return", "self", ".", "samples", "[", "original_idx", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.dataset.SciFactSubParagraphDataset.__init__": [[99, 207], ["jsonlines.open", "len", "enumerate", "dataset.SciFactSubParagraphDataset.label_ind.items", "dataset.SciFactSubParagraphDataset.stance_ind.items", "jsonlines.open", "str", "set", "dataset.SciFactSubParagraphDataset.__init__.sample_negative_sentence"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "corpus", ":", "str", ",", "claims", ":", "str", ",", "MAX_SEQ_LEN", ":", "int", ",", "CHUNK_SIZE", ":", "int", ",", "train", "=", "False", ",", "shuffle", "=", "False", ",", "negative_paragraph_sample_ratio", "=", "1", ",", "negative_sentence_sample_ratio", "=", "1", ")", ":", "\n", "\n", "\n", "        ", "def", "sample_negative_sentence", "(", "sentences", ",", "rationale_labels", ",", "negative_paragraph_sample_ratio", ")", ":", "\n", "            ", "kept_sentences", "=", "[", "]", "\n", "kept_labels", "=", "[", "]", "\n", "while", "len", "(", "kept_sentences", ")", "==", "0", ":", "# Avoid empty sentences returned", "\n", "                ", "for", "i", ",", "sentence", "in", "enumerate", "(", "sentences", ")", ":", "\n", "                    ", "if", "i", "in", "rationale_labels", "or", "random", ".", "random", "(", ")", "<", "negative_paragraph_sample_ratio", ":", "\n", "                        ", "kept_sentences", ".", "append", "(", "sentence", ")", "\n", "kept_labels", ".", "append", "(", "i", "in", "rationale_labels", ")", "\n", "", "", "", "return", "kept_sentences", ",", "kept_labels", "\n", "\n", "\n", "\n", "", "self", ".", "shuffle", "=", "shuffle", "\n", "self", ".", "n_paragraph_slices", "=", "0", "\n", "self", ".", "MAX_SEQ_LEN", "=", "MAX_SEQ_LEN", "\n", "self", ".", "CHUNK_SIZE", "=", "CHUNK_SIZE", "\n", "n_pieces", "=", "MAX_SEQ_LEN", "//", "CHUNK_SIZE", "\n", "n_pieces", "+=", "1", "if", "MAX_SEQ_LEN", "%", "CHUNK_SIZE", ">", "0", "else", "0", "\n", "self", ".", "label_ind", "=", "{", "\"NEI\"", ":", "0", ",", "\"rationale\"", ":", "1", "}", "\n", "self", ".", "rev_label_ind", "=", "{", "i", ":", "l", "for", "(", "l", ",", "i", ")", "in", "self", ".", "label_ind", ".", "items", "(", ")", "}", "\n", "self", ".", "stance_ind", "=", "{", "\"NEI\"", ":", "0", ",", "\"SUPPORT\"", ":", "1", ",", "\"CONTRADICT\"", ":", "2", "}", "\n", "self", ".", "rev_stance_ind", "=", "{", "i", ":", "l", "for", "(", "l", ",", "i", ")", "in", "self", ".", "stance_ind", ".", "items", "(", ")", "}", "\n", "\n", "self", ".", "samples", "=", "[", "]", "\n", "self", ".", "true_pairs", "=", "[", "]", "# The unprocessed claim - abstract pairs.", "\n", "self", ".", "excluded_pairs", "=", "[", "]", "\n", "corpus", "=", "{", "doc", "[", "'doc_id'", "]", ":", "doc", "for", "doc", "in", "jsonlines", ".", "open", "(", "corpus", ")", "}", "\n", "\n", "for", "claim", "in", "jsonlines", ".", "open", "(", "claims", ")", ":", "\n", "            ", "for", "doc_id", "in", "claim", "[", "\"cited_doc_ids\"", "]", ":", "\n", "                ", "doc", "=", "corpus", "[", "int", "(", "doc_id", ")", "]", "\n", "doc_id", "=", "str", "(", "doc_id", ")", "\n", "if", "doc_id", "in", "claim", "[", "'evidence'", "]", ":", "\n", "                    ", "evidence", "=", "claim", "[", "'evidence'", "]", "[", "doc_id", "]", "\n", "evidence_sentence_idx", "=", "{", "s", "for", "es", "in", "evidence", "for", "s", "in", "es", "[", "'sentences'", "]", "}", "\n", "stances", "=", "set", "(", "[", "es", "[", "\"label\"", "]", "for", "es", "in", "evidence", "]", ")", "\n", "still_include", "=", "False", "\n", "if", "\"SUPPORT\"", "in", "stances", ":", "\n", "                        ", "stance", "=", "\"SUPPORT\"", "\n", "", "elif", "\"CONTRADICT\"", "in", "stances", ":", "\n", "                        ", "stance", "=", "\"CONTRADICT\"", "\n", "", "else", ":", "\n", "                        ", "stance", "=", "\"NEI\"", "\n", "", "", "else", ":", "\n", "                    ", "evidence_sentence_idx", "=", "{", "}", "\n", "stance", "=", "\"NEI\"", "\n", "still_include", "=", "random", ".", "random", "(", ")", "<", "negative_paragraph_sample_ratio", "\n", "\n", "", "if", "stance", "!=", "\"NEI\"", "or", "still_include", ":", "\n", "                    ", "sentences", ",", "labels", "=", "sample_negative_sentence", "(", "doc", "[", "'abstract'", "]", ",", "evidence_sentence_idx", ",", "\n", "negative_paragraph_sample_ratio", ")", "\n", "\n", "self", ".", "true_pairs", ".", "append", "(", "{", "\n", "'dataset'", ":", "1", ",", "\n", "'claim'", ":", "claim", "[", "'claim'", "]", ",", "\n", "'claim_id'", ":", "claim", "[", "'id'", "]", ",", "\n", "'doc_id'", ":", "doc", "[", "'doc_id'", "]", ",", "\n", "'paragraph'", ":", "sentences", ",", "\n", "'label'", ":", "labels", ",", "\n", "'stance'", ":", "stance", "\n", "}", ")", "\n", "\n", "\n", "\n", "n_paragraph_slices", "=", "len", "(", "sentences", ")", "//", "MAX_SEQ_LEN", "\n", "n_paragraph_slices", "+=", "1", "if", "len", "(", "sentences", ")", "%", "MAX_SEQ_LEN", ">", "0", "else", "0", "\n", "self", ".", "n_paragraph_slices", "+=", "n_paragraph_slices", "\n", "\n", "for", "p_slice", "in", "range", "(", "n_paragraph_slices", ")", ":", "\n", "                        ", "this_slice", "=", "sentences", "[", "p_slice", "*", "MAX_SEQ_LEN", ":", "(", "p_slice", "+", "1", ")", "*", "MAX_SEQ_LEN", "]", "\n", "padded_paragraph", "=", "this_slice", "+", "[", "\"\"", "for", "i", "in", "range", "(", "CHUNK_SIZE", "*", "n_pieces", "-", "len", "(", "this_slice", ")", ")", "]", "\n", "for", "p", "in", "range", "(", "n_pieces", ")", ":", "\n", "                            ", "this_piece", "=", "padded_paragraph", "[", "p", "*", "CHUNK_SIZE", ":", "(", "p", "+", "1", ")", "*", "CHUNK_SIZE", "]", "\n", "for", "i", ",", "sentence", "in", "enumerate", "(", "this_piece", ")", ":", "\n", "                                ", "sentence_id", "=", "i", "+", "p", "*", "CHUNK_SIZE", "+", "p_slice", "*", "MAX_SEQ_LEN", "\n", "if", "len", "(", "sentence", ")", ">", "0", ":", "\n", "                                    ", "label", "=", "1", "if", "sentence_id", "in", "evidence_sentence_idx", "else", "0", "\n", "mask", "=", "1", "\n", "sentence_stance", "=", "self", ".", "stance_ind", "[", "stance", "]", "if", "label", "==", "1", "else", "self", ".", "stance_ind", "[", "\"NEI\"", "]", "\n", "", "else", ":", "\n", "                                    ", "label", "=", "0", "\n", "mask", "=", "0", "\n", "sentence_stance", "=", "self", ".", "stance_ind", "[", "\"NEI\"", "]", "\n", "", "self", ".", "samples", ".", "append", "(", "{", "\n", "'dataset'", ":", "1", ",", "\n", "'claim'", ":", "claim", "[", "'claim'", "]", ",", "\n", "'claim_id'", ":", "claim", "[", "'id'", "]", ",", "\n", "'sentence'", ":", "sentence", ",", "\n", "'doc_id'", ":", "doc", "[", "'doc_id'", "]", ",", "\n", "'sentence_id'", ":", "sentence_id", ",", "\n", "'label'", ":", "label", ",", "\n", "'sentence_stance'", ":", "sentence_stance", ",", "\n", "'stance'", ":", "self", ".", "stance_ind", "[", "stance", "]", ",", "\n", "'mask'", ":", "mask", "\n", "}", ")", "\n", "\n", "", "", "", "", "else", ":", "\n", "                    ", "self", ".", "excluded_pairs", ".", "append", "(", "{", "\n", "'dataset'", ":", "1", ",", "\n", "'claim'", ":", "claim", "[", "'claim'", "]", ",", "\n", "'claim_id'", ":", "claim", "[", "'id'", "]", ",", "\n", "'doc_id'", ":", "doc", "[", "'doc_id'", "]", ",", "\n", "'paragraph'", ":", "doc", "[", "'abstract'", "]", ",", "\n", "'label'", ":", "[", "1", "if", "i", "in", "evidence_sentence_idx", "else", "0", "for", "i", "in", "range", "(", "len", "(", "doc", "[", "'abstract'", "]", ")", ")", "]", ",", "\n", "'stance'", ":", "stance", "\n", "}", ")", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.dataset.SciFactSubParagraphDataset.__make_shuffle_idx": [[209, 212], ["random.shuffle", "range"], "methods", ["None"], ["", "", "", "", "def", "__make_shuffle_idx", "(", "self", ")", ":", "\n", "        ", "self", ".", "paragraph_indices", "=", "[", "i", "for", "i", "in", "range", "(", "self", ".", "n_paragraph_slices", ")", "]", "\n", "random", ".", "shuffle", "(", "self", ".", "paragraph_indices", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.dataset.SciFactSubParagraphDataset.__len__": [[213, 215], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "samples", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.dataset.SciFactSubParagraphDataset.__getitem__": [[216, 230], ["dataset.SciFactSubParagraphDataset.__make_shuffle_idx"], "methods", ["home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.dataset.SciFactSubParagraphDataset.__make_shuffle_idx"], ["", "def", "__getitem__", "(", "self", ",", "idx", ")", ":", "\n", "        ", "if", "self", ".", "shuffle", ":", "\n", "            ", "if", "idx", "==", "0", ":", "\n", "                ", "self", ".", "__make_shuffle_idx", "(", ")", "\n", "\n", "", "paragraph_idx", "=", "idx", "//", "self", ".", "MAX_SEQ_LEN", "\n", "offset", "=", "idx", "%", "self", ".", "MAX_SEQ_LEN", "\n", "\n", "original_idx", "=", "self", ".", "paragraph_indices", "[", "paragraph_idx", "]", "*", "self", ".", "MAX_SEQ_LEN", "+", "offset", "\n", "\n", "", "else", ":", "\n", "            ", "original_idx", "=", "idx", "\n", "\n", "", "return", "self", ".", "samples", "[", "original_idx", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.dataset.SciFactParagraphDataset.__init__": [[235, 308], ["range", "jsonlines.open", "len", "enumerate", "dataset.SciFactParagraphDataset.label_ind.items", "dataset.SciFactParagraphDataset.stance_ind.items", "jsonlines.open", "str", "kept_sentences.append", "kept_labels.append", "set", "dataset.SciFactParagraphDataset.__init__.sample_negative_sentence"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "corpus", ":", "str", ",", "claims", ":", "str", ",", "train", "=", "False", ",", "negative_paragraph_sample_ratio", "=", "1", ",", "negative_sentence_sample_ratio", "=", "1", ",", "N_sample", "=", "1", ")", ":", "\n", "\n", "        ", "def", "sample_negative_sentence", "(", "sentences", ",", "rationale_labels", ",", "negative_paragraph_sample_ratio", ")", ":", "\n", "            ", "kept_sentences", "=", "[", "]", "\n", "kept_labels", "=", "[", "]", "\n", "while", "len", "(", "kept_sentences", ")", "==", "0", ":", "# Avoid empty sentences returned", "\n", "                ", "for", "i", ",", "sentence", "in", "enumerate", "(", "sentences", ")", ":", "\n", "                    ", "if", "i", "in", "rationale_labels", "or", "random", ".", "random", "(", ")", "<", "negative_paragraph_sample_ratio", ":", "\n", "                        ", "kept_sentences", ".", "append", "(", "sentence", ")", "\n", "kept_labels", ".", "append", "(", "i", "in", "rationale_labels", ")", "\n", "", "", "", "return", "kept_sentences", ",", "kept_labels", "\n", "\n", "", "self", ".", "label_ind", "=", "{", "\"NEI\"", ":", "0", ",", "\"rationale\"", ":", "1", "}", "\n", "self", ".", "rev_label_ind", "=", "{", "i", ":", "l", "for", "(", "l", ",", "i", ")", "in", "self", ".", "label_ind", ".", "items", "(", ")", "}", "\n", "self", ".", "stance_ind", "=", "{", "\"NEI\"", ":", "0", ",", "\"SUPPORT\"", ":", "1", ",", "\"CONTRADICT\"", ":", "2", "}", "\n", "self", ".", "rev_stance_ind", "=", "{", "i", ":", "l", "for", "(", "l", ",", "i", ")", "in", "self", ".", "stance_ind", ".", "items", "(", ")", "}", "\n", "\n", "self", ".", "samples", "=", "[", "]", "\n", "self", ".", "excluded_pairs", "=", "[", "]", "\n", "corpus", "=", "{", "doc", "[", "'doc_id'", "]", ":", "doc", "for", "doc", "in", "jsonlines", ".", "open", "(", "corpus", ")", "}", "\n", "\n", "for", "N", "in", "range", "(", "N_sample", ")", ":", "\n", "            ", "for", "claim", "in", "jsonlines", ".", "open", "(", "claims", ")", ":", "\n", "                ", "for", "doc_id", "in", "claim", "[", "\"cited_doc_ids\"", "]", ":", "\n", "                    ", "doc", "=", "corpus", "[", "int", "(", "doc_id", ")", "]", "\n", "doc_id", "=", "str", "(", "doc_id", ")", "\n", "\n", "if", "\"discourse\"", "in", "doc", ":", "\n", "                        ", "abstract_sentences", "=", "[", "discourse", "+", "\" \"", "+", "sentence", "for", "discourse", ",", "sentence", "in", "zip", "(", "doc", "[", "'discourse'", "]", ",", "doc", "[", "'abstract'", "]", ")", "]", "\n", "", "else", ":", "\n", "                        ", "abstract_sentences", "=", "doc", "[", "'abstract'", "]", "\n", "\n", "", "if", "doc_id", "in", "claim", "[", "'evidence'", "]", ":", "\n", "                        ", "evidence", "=", "claim", "[", "'evidence'", "]", "[", "doc_id", "]", "\n", "evidence_sentence_idx", "=", "{", "s", "for", "es", "in", "evidence", "for", "s", "in", "es", "[", "'sentences'", "]", "}", "\n", "stances", "=", "set", "(", "[", "es", "[", "\"label\"", "]", "for", "es", "in", "evidence", "]", ")", "\n", "still_include", "=", "False", "\n", "if", "\"SUPPORT\"", "in", "stances", ":", "\n", "                            ", "stance", "=", "\"SUPPORT\"", "\n", "", "elif", "\"CONTRADICT\"", "in", "stances", ":", "\n", "                            ", "stance", "=", "\"CONTRADICT\"", "\n", "", "else", ":", "\n", "                            ", "stance", "=", "\"NEI\"", "\n", "", "", "else", ":", "\n", "                        ", "evidence_sentence_idx", "=", "{", "}", "\n", "stance", "=", "\"NEI\"", "\n", "still_include", "=", "random", ".", "random", "(", ")", "<", "negative_paragraph_sample_ratio", "\n", "\n", "", "if", "stance", "!=", "\"NEI\"", "or", "still_include", ":", "\n", "                        ", "selected_sentences", ",", "selected_labels", "=", "sample_negative_sentence", "(", "\n", "abstract_sentences", ",", "evidence_sentence_idx", ",", "negative_sentence_sample_ratio", ")", "\n", "\n", "\n", "self", ".", "samples", ".", "append", "(", "{", "\n", "'dataset'", ":", "1", ",", "\n", "'claim'", ":", "claim", "[", "'claim'", "]", ",", "\n", "'claim_id'", ":", "claim", "[", "'id'", "]", ",", "\n", "'doc_id'", ":", "doc", "[", "'doc_id'", "]", ",", "\n", "'paragraph'", ":", "selected_sentences", ",", "\n", "'label'", ":", "selected_labels", ",", "\n", "'stance'", ":", "self", ".", "stance_ind", "[", "stance", "]", "\n", "}", ")", "\n", "\n", "", "else", ":", "\n", "                        ", "self", ".", "excluded_pairs", ".", "append", "(", "{", "\n", "'dataset'", ":", "1", ",", "\n", "'claim'", ":", "claim", "[", "'claim'", "]", ",", "\n", "'claim_id'", ":", "claim", "[", "'id'", "]", ",", "\n", "'doc_id'", ":", "doc", "[", "'doc_id'", "]", ",", "\n", "'paragraph'", ":", "abstract_sentences", ",", "\n", "'label'", ":", "[", "1", "if", "i", "in", "evidence_sentence_idx", "else", "0", "for", "i", "in", "range", "(", "len", "(", "doc", "[", "'abstract'", "]", ")", ")", "]", ",", "\n", "'stance'", ":", "self", ".", "stance_ind", "[", "stance", "]", "\n", "}", ")", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.dataset.SciFactParagraphDataset.__len__": [[310, 312], ["len"], "methods", ["None"], ["", "", "", "", "", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "samples", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.dataset.SciFactParagraphDataset.__getitem__": [[313, 315], ["None"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "idx", ")", ":", "\n", "        ", "return", "self", ".", "samples", "[", "idx", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.dataset.SciFactStancePredictionDataset.__init__": [[320, 358], ["zip", "jsonlines.open", "jsonlines.open", "sum", "dataset.SciFactStancePredictionDataset.label_ind.items", "dataset.SciFactStancePredictionDataset.stance_ind.items", "jsonlines.open", "dataset.SciFactStancePredictionDataset.excluded_pairs.append", "len", "str", "rationale[].items", "len", "enumerate", "util.clean_num", "dataset.SciFactStancePredictionDataset.samples.append", "int", "util.clean_url", "selected_sentences.append"], "methods", ["home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.util.clean_num", "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.util.clean_url"], ["def", "__init__", "(", "self", ",", "corpus", ":", "str", ",", "claims", ":", "str", ",", "rationales", ":", "str", ",", "sep_token", "=", "\"</s>\"", ")", ":", "\n", "        ", "self", ".", "label_ind", "=", "{", "\"NEI\"", ":", "0", ",", "\"rationale\"", ":", "1", "}", "\n", "self", ".", "rev_label_ind", "=", "{", "i", ":", "l", "for", "(", "l", ",", "i", ")", "in", "self", ".", "label_ind", ".", "items", "(", ")", "}", "\n", "self", ".", "stance_ind", "=", "{", "\"NEI\"", ":", "0", ",", "\"SUPPORT\"", ":", "1", ",", "\"CONTRADICT\"", ":", "2", "}", "\n", "self", ".", "rev_stance_ind", "=", "{", "i", ":", "l", "for", "(", "l", ",", "i", ")", "in", "self", ".", "stance_ind", ".", "items", "(", ")", "}", "\n", "\n", "self", ".", "samples", "=", "[", "]", "\n", "self", ".", "excluded_pairs", "=", "[", "]", "\n", "corpus", "=", "{", "doc", "[", "'doc_id'", "]", ":", "doc", "for", "doc", "in", "jsonlines", ".", "open", "(", "corpus", ")", "}", "\n", "\n", "for", "claim", ",", "rationale", "in", "zip", "(", "jsonlines", ".", "open", "(", "claims", ")", ",", "jsonlines", ".", "open", "(", "rationales", ")", ")", ":", "\n", "            ", "N_rationale", "=", "sum", "(", "[", "len", "(", "v", ")", "for", "k", ",", "v", "in", "rationale", "[", "\"evidence\"", "]", ".", "items", "(", ")", "]", ")", "\n", "if", "N_rationale", ">", "0", ":", "\n", "                ", "for", "doc_id", "in", "rationale", "[", "\"evidence\"", "]", ":", "\n", "                    ", "doc", "=", "corpus", "[", "int", "(", "doc_id", ")", "]", "\n", "doc_id", "=", "str", "(", "doc_id", ")", "\n", "evidence_sentence_idx", "=", "rationale", "[", "\"evidence\"", "]", "[", "doc_id", "]", "\n", "if", "len", "(", "evidence_sentence_idx", ")", ">", "0", ":", "\n", "                        ", "selected_sentences", "=", "[", "]", "\n", "for", "i", ",", "sentence", "in", "enumerate", "(", "doc", "[", "'abstract'", "]", ")", ":", "\n", "                            ", "if", "i", "in", "evidence_sentence_idx", ":", "\n", "                                ", "selected_sentences", ".", "append", "(", "sentence", ")", "\n", "\n", "", "", "concat_sentences", "=", "(", "\" \"", "+", "sep_token", "+", "\" \"", ")", ".", "join", "(", "selected_sentences", ")", "\n", "concat_sentences", "=", "clean_num", "(", "clean_url", "(", "concat_sentences", ")", ")", "\n", "\n", "self", ".", "samples", ".", "append", "(", "{", "\n", "'dataset'", ":", "1", ",", "\n", "'claim'", ":", "claim", "[", "'claim'", "]", ",", "\n", "'claim_id'", ":", "claim", "[", "'id'", "]", ",", "\n", "'doc_id'", ":", "doc", "[", "'doc_id'", "]", ",", "\n", "'paragraph'", ":", "concat_sentences", "\n", "}", ")", "\n", "", "", "", "else", ":", "\n", "                ", "self", ".", "excluded_pairs", ".", "append", "(", "{", "\n", "'dataset'", ":", "1", ",", "\n", "'claim'", ":", "claim", "[", "'claim'", "]", ",", "\n", "'claim_id'", ":", "claim", "[", "'id'", "]", "\n", "}", ")", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.dataset.SciFactStancePredictionDataset.__len__": [[361, 363], ["len"], "methods", ["None"], ["", "", "", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "samples", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.dataset.SciFactStancePredictionDataset.__getitem__": [[364, 366], ["None"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "idx", ")", ":", "\n", "        ", "return", "self", ".", "samples", "[", "idx", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.dataset.FEVERParagraphDataset.__init__": [[371, 400], ["jsonlines.open", "dataset.FEVERParagraphDataset.label_ind.items", "dataset.FEVERParagraphDataset.stance_ind.items", "len", "set", "dataset.FEVERParagraphDataset.samples.append", "dataset.FEVERParagraphDataset.nei_pairs.append", "rationales.extend", "range", "len"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "data_path", ")", ":", "\n", "        ", "self", ".", "label_ind", "=", "{", "\"NEI\"", ":", "0", ",", "\"rationale\"", ":", "1", "}", "\n", "self", ".", "rev_label_ind", "=", "{", "i", ":", "l", "for", "(", "l", ",", "i", ")", "in", "self", ".", "label_ind", ".", "items", "(", ")", "}", "\n", "self", ".", "stance_ind", "=", "{", "\"NOT ENOUGH INFO\"", ":", "0", ",", "\"SUPPORTS\"", ":", "1", ",", "\"REFUTES\"", ":", "2", "}", "\n", "self", ".", "rev_stance_ind", "=", "{", "i", ":", "l", "for", "(", "l", ",", "i", ")", "in", "self", ".", "stance_ind", ".", "items", "(", ")", "}", "\n", "\n", "self", ".", "samples", "=", "[", "]", "\n", "self", ".", "nei_pairs", "=", "[", "]", "\n", "\n", "for", "data", "in", "jsonlines", ".", "open", "(", "data_path", ")", ":", "\n", "            ", "if", "len", "(", "data", "[", "\"sentences\"", "]", ")", ">", "0", ":", "\n", "                ", "rationales", "=", "[", "]", "\n", "for", "evid", "in", "data", "[", "\"evidence_sets\"", "]", ":", "\n", "                    ", "rationales", ".", "extend", "(", "evid", ")", "\n", "", "evidence_idx", "=", "set", "(", "rationales", ")", "\n", "self", ".", "samples", ".", "append", "(", "{", "\n", "'dataset'", ":", "0", ",", "\n", "'claim'", ":", "data", "[", "'claim'", "]", ",", "\n", "'claim_id'", ":", "data", "[", "'id'", "]", ",", "\n", "'paragraph'", ":", "data", "[", "\"sentences\"", "]", ",", "\n", "'label'", ":", "[", "1", "if", "i", "in", "evidence_idx", "else", "0", "for", "i", "in", "range", "(", "len", "(", "data", "[", "\"sentences\"", "]", ")", ")", "]", ",", "\n", "'stance'", ":", "self", ".", "stance_ind", "[", "data", "[", "\"label\"", "]", "]", "\n", "}", ")", "\n", "\n", "", "else", ":", "\n", "                ", "self", ".", "nei_pairs", ".", "append", "(", "{", "\n", "'dataset'", ":", "0", ",", "\n", "'claim'", ":", "data", "[", "'claim'", "]", ",", "\n", "'claim_id'", ":", "data", "[", "'id'", "]", "\n", "}", ")", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.dataset.FEVERParagraphDataset.__len__": [[402, 404], ["len"], "methods", ["None"], ["", "", "", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "samples", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.dataset.FEVERParagraphDataset.__getitem__": [[405, 407], ["None"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "idx", ")", ":", "\n", "        ", "return", "self", ".", "samples", "[", "idx", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.dataset.SciFact_FEVER_Dataset.__init__": [[409, 416], ["len", "len", "len", "len"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "dataset1", ",", "dataset2", ",", "multiplier", "=", "1", ")", ":", "\n", "        ", "if", "len", "(", "dataset1", ")", "<", "len", "(", "dataset2", ")", ":", "\n", "            ", "self", ".", "samples", "=", "dataset1", ".", "samples", "*", "multiplier", "+", "dataset2", ".", "samples", "\n", "", "elif", "len", "(", "dataset1", ")", ">", "len", "(", "dataset2", ")", ":", "\n", "            ", "self", ".", "samples", "=", "dataset1", ".", "samples", "+", "dataset2", ".", "samples", "*", "multiplier", "\n", "", "else", ":", "\n", "            ", "self", ".", "samples", "=", "dataset1", ".", "samples", "+", "dataset2", ".", "samples", "\n", "", "", "def", "__len__", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.dataset.SciFact_FEVER_Dataset.__len__": [[416, 418], ["len"], "methods", ["None"], ["", "", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "samples", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.dataset.SciFact_FEVER_Dataset.__getitem__": [[419, 421], ["None"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "idx", ")", ":", "\n", "        ", "return", "self", ".", "samples", "[", "idx", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.dataset.Multiple_SciFact_Dataset.__init__": [[423, 425], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "dataset", ",", "multiplier", "=", "1", ")", ":", "\n", "        ", "self", ".", "samples", "=", "dataset", ".", "samples", "*", "multiplier", "\n", "", "def", "__len__", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.dataset.Multiple_SciFact_Dataset.__len__": [[425, 427], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "samples", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.dataset.Multiple_SciFact_Dataset.__getitem__": [[428, 430], ["None"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "idx", ")", ":", "\n", "        ", "return", "self", ".", "samples", "[", "idx", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.dataset.SciFactParagraphBatchDataset.__init__": [[435, 525], ["jsonlines.open", "dataset.SciFactParagraphBatchDataset.label_ind.items", "dataset.SciFactParagraphBatchDataset.stance_ind.items", "jsonlines.open", "int", "sorted", "str", "int", "list", "range", "dataset.SciFactParagraphBatchDataset.samples.append", "list", "set", "int", "sent.strip", "util.clean_num", "dataset.SciFactParagraphBatchDataset.samples.append", "claim[].keys", "sentence.strip", "zip", "set", "util.clean_url", "dataset.SciFactParagraphBatchDataset.downsample", "len", "range", "len"], "methods", ["home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.util.clean_num", "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.util.clean_url", "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.dataset.SciFactParagraphBatchDataset.downsample"], ["def", "__init__", "(", "self", ",", "corpus", ":", "str", ",", "claims", ":", "str", ",", "sep_token", "=", "\"</s>\"", ",", "k", "=", "0", ",", "train", "=", "True", ",", "dummy", "=", "True", ",", "\n", "downsample_n", "=", "0", ",", "downsample_p", "=", "0.5", ")", ":", "\n", "        ", "self", ".", "label_ind", "=", "{", "\"NEI\"", ":", "0", ",", "\"rationale\"", ":", "1", "}", "\n", "self", ".", "rev_label_ind", "=", "{", "i", ":", "l", "for", "(", "l", ",", "i", ")", "in", "self", ".", "label_ind", ".", "items", "(", ")", "}", "\n", "self", ".", "stance_ind", "=", "{", "\"NEI\"", ":", "0", ",", "\"SUPPORT\"", ":", "1", ",", "\"CONTRADICT\"", ":", "2", "}", "\n", "self", ".", "rev_stance_ind", "=", "{", "i", ":", "l", "for", "(", "l", ",", "i", ")", "in", "self", ".", "stance_ind", ".", "items", "(", ")", "}", "\n", "\n", "self", ".", "samples", "=", "[", "]", "\n", "self", ".", "excluded_pairs", "=", "[", "]", "\n", "corpus", "=", "{", "doc", "[", "'doc_id'", "]", ":", "doc", "for", "doc", "in", "jsonlines", ".", "open", "(", "corpus", ")", "}", "\n", "\n", "for", "claim", "in", "jsonlines", ".", "open", "(", "claims", ")", ":", "\n", "            ", "if", "k", ">", "0", "and", "\"retrieved_doc_ids\"", "in", "claim", ":", "\n", "                ", "candidates", "=", "claim", "[", "\"retrieved_doc_ids\"", "]", "[", ":", "k", "]", "\n", "", "else", ":", "\n", "                ", "candidates", "=", "claim", "[", "\"cited_doc_ids\"", "]", "\n", "", "candidates", "=", "[", "int", "(", "cand", ")", "for", "cand", "in", "candidates", "]", "\n", "if", "train", ":", "\n", "                ", "evidence_doc_ids", "=", "[", "int", "(", "ID", ")", "for", "ID", "in", "list", "(", "claim", "[", "'evidence'", "]", ".", "keys", "(", ")", ")", "]", "\n", "all_candidates", "=", "sorted", "(", "list", "(", "set", "(", "candidates", "+", "evidence_doc_ids", ")", ")", ")", "\n", "", "else", ":", "\n", "                ", "all_candidates", "=", "candidates", "\n", "\n", "", "for", "doc_id", "in", "all_candidates", ":", "\n", "                ", "doc", "=", "corpus", "[", "int", "(", "doc_id", ")", "]", "\n", "doc_id", "=", "str", "(", "doc_id", ")", "\n", "\n", "if", "\"discourse\"", "in", "doc", ":", "\n", "                    ", "abstract_sentences", "=", "[", "discourse", "+", "\" \"", "+", "sentence", ".", "strip", "(", ")", "for", "discourse", ",", "sentence", "in", "zip", "(", "doc", "[", "'discourse'", "]", ",", "doc", "[", "'abstract'", "]", ")", "]", "\n", "", "else", ":", "\n", "                    ", "abstract_sentences", "=", "[", "sent", ".", "strip", "(", ")", "for", "sent", "in", "doc", "[", "'abstract'", "]", "]", "\n", "\n", "", "if", "train", ":", "\n", "                    ", "for", "down_n", "in", "range", "(", "downsample_n", "+", "1", ")", ":", "\n", "                        ", "if", "doc_id", "in", "claim", "[", "'evidence'", "]", ":", "\n", "                            ", "evidence", "=", "claim", "[", "'evidence'", "]", "[", "doc_id", "]", "\n", "evidence_sentence_idx", "=", "{", "s", "for", "es", "in", "evidence", "for", "s", "in", "es", "[", "'sentences'", "]", "}", "\n", "stances", "=", "set", "(", "[", "es", "[", "\"label\"", "]", "for", "es", "in", "evidence", "]", ")", "\n", "\n", "if", "\"SUPPORT\"", "in", "stances", ":", "\n", "                                ", "stance", "=", "\"SUPPORT\"", "\n", "", "elif", "\"CONTRADICT\"", "in", "stances", ":", "\n", "                                ", "stance", "=", "\"CONTRADICT\"", "\n", "", "else", ":", "\n", "                                ", "stance", "=", "\"NEI\"", "\n", "\n", "", "if", "down_n", ">", "0", ":", "\n", "                                ", "abstract_sentences", ",", "evidence_sentence_idx", ",", "stance", "=", "self", ".", "downsample", "(", "abstract_sentences", ",", "evidence_sentence_idx", ",", "stance", ",", "downsample_p", ")", "\n", "if", "len", "(", "abstract_sentences", ")", "==", "0", ":", "\n", "                                    ", "break", "\n", "\n", "", "", "", "else", ":", "\n", "                            ", "evidence_sentence_idx", "=", "{", "}", "\n", "stance", "=", "\"NEI\"", "\n", "\n", "", "concat_sentences", "=", "(", "\" \"", "+", "sep_token", "+", "\" \"", ")", ".", "join", "(", "abstract_sentences", ")", "\n", "concat_sentences", "=", "clean_num", "(", "clean_url", "(", "concat_sentences", ")", ")", "\n", "rationale_label_string", "=", "\"\"", ".", "join", "(", "[", "\"1\"", "if", "i", "in", "evidence_sentence_idx", "else", "\"0\"", "for", "i", "in", "range", "(", "len", "(", "abstract_sentences", ")", ")", "]", ")", "\n", "\n", "if", "dummy", ":", "\n", "                            ", "concat_sentences", "=", "\"@ \"", "+", "sep_token", "+", "\" \"", "+", "concat_sentences", "\n", "rationale_label_string", "=", "\"0\"", "+", "rationale_label_string", "\n", "\n", "", "self", ".", "samples", ".", "append", "(", "{", "\n", "'dataset'", ":", "1", ",", "\n", "'claim'", ":", "claim", "[", "'claim'", "]", ",", "\n", "'claim_id'", ":", "claim", "[", "'id'", "]", ",", "\n", "'doc_id'", ":", "doc", "[", "'doc_id'", "]", ",", "\n", "'paragraph'", ":", "concat_sentences", ",", "\n", "'label'", ":", "rationale_label_string", ",", "\n", "'stance'", ":", "self", ".", "stance_ind", "[", "stance", "]", "\n", "}", ")", "\n", "\n", "if", "doc_id", "not", "in", "claim", "[", "'evidence'", "]", ":", "\n", "                            ", "break", "# Do not downsample if contain no evidence", "\n", "", "", "", "else", ":", "\n", "                    ", "concat_sentences", "=", "(", "\" \"", "+", "sep_token", "+", "\" \"", ")", ".", "join", "(", "abstract_sentences", ")", "\n", "\n", "if", "dummy", ":", "\n", "                        ", "concat_sentences", "=", "\"@ \"", "+", "sep_token", "+", "\" \"", "+", "concat_sentences", "\n", "\n", "", "self", ".", "samples", ".", "append", "(", "{", "\n", "'dataset'", ":", "1", ",", "\n", "'claim'", ":", "claim", "[", "'claim'", "]", ",", "\n", "'claim_id'", ":", "claim", "[", "'id'", "]", ",", "\n", "'doc_id'", ":", "doc", "[", "'doc_id'", "]", ",", "\n", "'paragraph'", ":", "concat_sentences", ",", "\n", "}", ")", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.dataset.SciFactParagraphBatchDataset.downsample": [[527, 543], ["enumerate", "enumerate", "set", "random.random", "kept_sentences.append", "kept_evidence_idx.append", "len", "evidence_bitmap.append", "evidence_bitmap.append"], "methods", ["None"], ["", "", "", "", "def", "downsample", "(", "self", ",", "abstract_sentences", ",", "evidence_sentence_idx", ",", "stance", ",", "downsample_p", ")", ":", "\n", "        ", "kept_sentences", "=", "[", "]", "\n", "evidence_bitmap", "=", "[", "]", "\n", "for", "i", ",", "sentence", "in", "enumerate", "(", "abstract_sentences", ")", ":", "\n", "            ", "if", "random", ".", "random", "(", ")", "<", "downsample_p", ":", "\n", "                ", "kept_sentences", ".", "append", "(", "sentence", ")", "\n", "if", "i", "in", "evidence_sentence_idx", ":", "\n", "                    ", "evidence_bitmap", ".", "append", "(", "True", ")", "\n", "", "else", ":", "\n", "                    ", "evidence_bitmap", ".", "append", "(", "False", ")", "\n", "", "", "", "kept_evidence_idx", "=", "[", "]", "\n", "for", "i", ",", "e", "in", "enumerate", "(", "evidence_bitmap", ")", ":", "\n", "            ", "if", "e", ":", "\n", "                ", "kept_evidence_idx", ".", "append", "(", "i", ")", "\n", "", "", "kept_stance", "=", "stance", "if", "len", "(", "kept_evidence_idx", ")", ">", "0", "else", "\"NEI\"", "\n", "return", "kept_sentences", ",", "set", "(", "kept_evidence_idx", ")", ",", "kept_stance", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.dataset.SciFactParagraphBatchDataset.__len__": [[544, 546], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "samples", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.dataset.SciFactParagraphBatchDataset.__getitem__": [[547, 549], ["None"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "idx", ")", ":", "\n", "        ", "return", "self", ".", "samples", "[", "idx", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.dataset.FEVERParagraphBatchDataset.__init__": [[554, 640], ["jsonlines.open", "max", "dataset.FEVERParagraphBatchDataset.label_ind.items", "dataset.FEVERParagraphBatchDataset.stance_ind.items", "len", "len", "util.clean_num", "len", "sent.split", "util.clean_url", "set", "dataset.FEVERParagraphBatchDataset.samples.append", "util.clean_num", "dataset.FEVERParagraphBatchDataset.__init__.max_sent_len"], "methods", ["home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.util.clean_num", "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.util.clean_url", "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.util.clean_num"], ["def", "__init__", "(", "self", ",", "datapath", ":", "str", ",", "sep_token", "=", "\"</s>\"", ",", "train", "=", "True", ",", "k", "=", "0", ",", "dummy", "=", "True", ")", ":", "\n", "        ", "self", ".", "label_ind", "=", "{", "\"NEI\"", ":", "0", ",", "\"rationale\"", ":", "1", "}", "\n", "self", ".", "rev_label_ind", "=", "{", "i", ":", "l", "for", "(", "l", ",", "i", ")", "in", "self", ".", "label_ind", ".", "items", "(", ")", "}", "\n", "self", ".", "stance_ind", "=", "{", "\"NOT ENOUGH INFO\"", ":", "0", ",", "\"SUPPORTS\"", ":", "1", ",", "\"REFUTES\"", ":", "2", "}", "\n", "self", ".", "rev_stance_ind", "=", "{", "i", ":", "l", "for", "(", "l", ",", "i", ")", "in", "self", ".", "stance_ind", ".", "items", "(", ")", "}", "\n", "\n", "self", ".", "samples", "=", "[", "]", "\n", "self", ".", "excluded_pairs", "=", "[", "]", "\n", "\n", "def", "max_sent_len", "(", "sentences", ")", ":", "\n", "            ", "return", "max", "(", "[", "len", "(", "sent", ".", "split", "(", ")", ")", "for", "sent", "in", "sentences", "]", ")", "\n", "\n", "", "for", "data", "in", "jsonlines", ".", "open", "(", "datapath", ")", ":", "\n", "            ", "try", ":", "\n", "                ", "if", "len", "(", "data", "[", "\"sentences\"", "]", ")", ">", "0", ":", "\n", "                    ", "sentences", "=", "data", "[", "\"sentences\"", "]", "\n", "if", "max_sent_len", "(", "sentences", ")", ">", "100", "or", "len", "(", "sentences", ")", ">", "100", ":", "\n", "                        ", "continue", "\n", "", "concat_sentences", "=", "(", "\" \"", "+", "sep_token", "+", "\" \"", ")", ".", "join", "(", "sentences", ")", "\n", "concat_sentences", "=", "clean_num", "(", "clean_url", "(", "concat_sentences", ")", ")", "\n", "if", "train", ":", "\n", "                        ", "rationales", "=", "[", "]", "\n", "for", "evid", "in", "data", "[", "\"evidence_sets\"", "]", ":", "\n", "                            ", "rationales", ".", "extend", "(", "evid", ")", "\n", "", "evidence_idx", "=", "set", "(", "rationales", ")", "\n", "rationale_label_string", "=", "\"\"", ".", "join", "(", "[", "\"1\"", "if", "i", "in", "evidence_idx", "else", "\"0\"", "for", "i", "in", "range", "(", "len", "(", "sentences", ")", ")", "]", ")", "\n", "\n", "if", "dummy", ":", "\n", "                            ", "concat_sentences", "=", "\"@ \"", "+", "sep_token", "+", "\" \"", "+", "concat_sentences", "\n", "rationale_label_string", "=", "\"0\"", "+", "rationale_label_string", "\n", "\n", "", "self", ".", "samples", ".", "append", "(", "{", "\n", "'dataset'", ":", "0", ",", "\n", "'claim'", ":", "data", "[", "'claim'", "]", ",", "\n", "'claim_id'", ":", "data", "[", "'id'", "]", ",", "\n", "'paragraph'", ":", "concat_sentences", ",", "\n", "'label'", ":", "rationale_label_string", ",", "\n", "'stance'", ":", "self", ".", "stance_ind", "[", "data", "[", "\"label\"", "]", "]", "\n", "}", ")", "\n", "", "elif", "data", "[", "\"hit\"", "]", ":", "# The retrieved pages hit the gold page.", "\n", "                        ", "if", "dummy", ":", "\n", "                            ", "concat_sentences", "=", "\"@ \"", "+", "sep_token", "+", "\" \"", "+", "concat_sentences", "\n", "", "self", ".", "samples", ".", "append", "(", "{", "\n", "'dataset'", ":", "0", ",", "\n", "'claim'", ":", "data", "[", "'claim'", "]", ",", "\n", "'claim_id'", ":", "data", "[", "'id'", "]", ",", "\n", "'paragraph'", ":", "concat_sentences", "\n", "}", ")", "\n", "", "", "", "except", ":", "\n", "                ", "pass", "\n", "", "try", ":", "\n", "                ", "if", "len", "(", "data", "[", "\"negative_sentences\"", "]", ")", ">", "0", ":", "\n", "                    ", "for", "sentences", "in", "data", "[", "\"negative_sentences\"", "]", "[", ":", "k", "]", ":", "\n", "                        ", "if", "max_sent_len", "(", "sentences", ")", ">", "100", "or", "len", "(", "sentences", ")", ">", "100", ":", "\n", "                            ", "continue", "\n", "\n", "", "concat_sentences", "=", "(", "\" \"", "+", "sep_token", "+", "\" \"", ")", ".", "join", "(", "sentences", ")", "\n", "concat_sentences", "=", "clean_num", "(", "clean_url", "(", "concat_sentences", ")", ")", "\n", "\n", "if", "train", ":", "\n", "                            ", "rationale_label_string", "=", "\"0\"", "*", "len", "(", "sentences", ")", "\n", "\n", "if", "dummy", ":", "\n", "                                ", "concat_sentences", "=", "\"@ \"", "+", "sep_token", "+", "\" \"", "+", "concat_sentences", "\n", "rationale_label_string", "=", "\"0\"", "+", "rationale_label_string", "\n", "\n", "", "self", ".", "samples", ".", "append", "(", "{", "\n", "'dataset'", ":", "0", ",", "\n", "'claim'", ":", "data", "[", "'claim'", "]", ",", "\n", "'claim_id'", ":", "data", "[", "'id'", "]", ",", "\n", "'paragraph'", ":", "concat_sentences", ",", "\n", "'label'", ":", "rationale_label_string", ",", "\n", "'stance'", ":", "self", ".", "stance_ind", "[", "\"NOT ENOUGH INFO\"", "]", "\n", "}", ")", "\n", "", "else", ":", "\n", "                            ", "if", "dummy", ":", "\n", "                                ", "concat_sentences", "=", "\"@ \"", "+", "sep_token", "+", "\" \"", "+", "concat_sentences", "\n", "\n", "", "self", ".", "samples", ".", "append", "(", "{", "\n", "'dataset'", ":", "0", ",", "\n", "'claim'", ":", "data", "[", "'claim'", "]", ",", "\n", "'claim_id'", ":", "data", "[", "'id'", "]", ",", "\n", "'paragraph'", ":", "concat_sentences", "\n", "}", ")", "\n", "", "", "", "", "except", ":", "\n", "                ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.dataset.FEVERParagraphBatchDataset.__len__": [[641, 643], ["len"], "methods", ["None"], ["", "", "", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "samples", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.dataset.FEVERParagraphBatchDataset.__getitem__": [[644, 646], ["None"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "idx", ")", ":", "\n", "        ", "return", "self", ".", "samples", "[", "idx", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.dataset.SciFactStanceDataset.__init__": [[651, 792], ["jsonlines.open", "sorted", "dataset.SciFactStanceDataset.label_ind.items", "dataset.SciFactStanceDataset.stance_ind.items", "jsonlines.open", "int", "int", "list", "set().difference", "str", "list", "set", "set", "random.sample", "util.clean_num", "dataset.SciFactStanceDataset.samples.append", "dataset.SciFactStanceDataset.samples.append", "claim[].keys", "set", "int", "sent.strip", "set", "set", "len", "dataset.SciFactStanceDataset.samples.append", "range", "util.clean_num", "dataset.SciFactStanceDataset.samples.append", "set", "abstract_sentences[].strip", "util.clean_url", "len", "len", "range", "util.clean_num", "zip", "set", "len", "util.clean_url", "len", "range", "util.clean_num", "dataset.SciFactStanceDataset.samples.append", "range", "min", "sorted", "len", "util.clean_url", "evidence_sentences.append", "len", "util.clean_url", "len", "len", "random.randint", "len", "list", "evidence_sentences.append", "evidence_sentences.append"], "methods", ["home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.util.clean_num", "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.util.clean_num", "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.util.clean_url", "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.util.clean_num", "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.util.clean_url", "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.util.clean_num", "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.util.clean_url", "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.util.clean_url"], ["def", "__init__", "(", "self", ",", "corpus", ":", "str", ",", "claims", ":", "str", ",", "sep_token", "=", "\"</s>\"", ",", "k", "=", "0", ",", "train", "=", "True", ")", ":", "\n", "        ", "self", ".", "label_ind", "=", "{", "\"NEI\"", ":", "0", ",", "\"rationale\"", ":", "1", "}", "\n", "self", ".", "rev_label_ind", "=", "{", "i", ":", "l", "for", "(", "l", ",", "i", ")", "in", "self", ".", "label_ind", ".", "items", "(", ")", "}", "\n", "self", ".", "stance_ind", "=", "{", "\"NEI\"", ":", "0", ",", "\"SUPPORT\"", ":", "1", ",", "\"CONTRADICT\"", ":", "2", "}", "\n", "self", ".", "rev_stance_ind", "=", "{", "i", ":", "l", "for", "(", "l", ",", "i", ")", "in", "self", ".", "stance_ind", ".", "items", "(", ")", "}", "\n", "\n", "self", ".", "samples", "=", "[", "]", "\n", "self", ".", "excluded_pairs", "=", "[", "]", "\n", "corpus", "=", "{", "doc", "[", "'doc_id'", "]", ":", "doc", "for", "doc", "in", "jsonlines", ".", "open", "(", "corpus", ")", "}", "\n", "\n", "for", "claim", "in", "jsonlines", ".", "open", "(", "claims", ")", ":", "\n", "            ", "if", "k", ">", "0", "and", "\"retrieved_doc_ids\"", "in", "claim", ":", "\n", "                ", "candidates", "=", "claim", "[", "\"retrieved_doc_ids\"", "]", "[", ":", "k", "]", "\n", "", "else", ":", "\n", "                ", "candidates", "=", "claim", "[", "\"cited_doc_ids\"", "]", "\n", "\n", "", "candidates", "=", "[", "int", "(", "cand", ")", "for", "cand", "in", "candidates", "]", "\n", "evidence_doc_ids", "=", "[", "int", "(", "ID", ")", "for", "ID", "in", "list", "(", "claim", "[", "'evidence'", "]", ".", "keys", "(", ")", ")", "]", "\n", "all_candidates", "=", "sorted", "(", "list", "(", "set", "(", "candidates", "+", "evidence_doc_ids", ")", ")", ")", "\n", "if", "not", "train", ":", "\n", "                ", "missed_doc_ids", "=", "set", "(", "all_candidates", ")", ".", "difference", "(", "set", "(", "candidates", ")", ")", "\n", "all_candidates", "=", "candidates", "\n", "# Add missed_candidate to excluded_pairs?", "\n", "\n", "", "for", "doc_id", "in", "all_candidates", ":", "\n", "                ", "doc", "=", "corpus", "[", "int", "(", "doc_id", ")", "]", "\n", "doc_id", "=", "str", "(", "doc_id", ")", "\n", "\n", "if", "\"discourse\"", "in", "doc", ":", "\n", "                    ", "abstract_sentences", "=", "[", "discourse", "+", "\" \"", "+", "sentence", "for", "discourse", ",", "sentence", "in", "zip", "(", "doc", "[", "'discourse'", "]", ",", "doc", "[", "'abstract'", "]", ")", "]", "\n", "", "else", ":", "\n", "                    ", "abstract_sentences", "=", "[", "sent", ".", "strip", "(", ")", "for", "sent", "in", "doc", "[", "'abstract'", "]", "]", "\n", "\n", "", "if", "train", ":", "\n", "                    ", "if", "doc_id", "in", "claim", "[", "'evidence'", "]", ":", "\n", "                        ", "evidence", "=", "claim", "[", "'evidence'", "]", "[", "doc_id", "]", "\n", "evidence_sentence_idx", "=", "{", "s", "for", "es", "in", "evidence", "for", "s", "in", "es", "[", "'sentences'", "]", "}", "\n", "evidence_sentence_idx_sets", "=", "[", "set", "(", "es", "[", "'sentences'", "]", ")", "for", "es", "in", "evidence", "]", "\n", "stances", "=", "set", "(", "[", "es", "[", "\"label\"", "]", "for", "es", "in", "evidence", "]", ")", "\n", "if", "\"SUPPORT\"", "in", "stances", ":", "\n", "                            ", "stance", "=", "\"SUPPORT\"", "\n", "", "elif", "\"CONTRADICT\"", "in", "stances", ":", "\n", "                            ", "stance", "=", "\"CONTRADICT\"", "\n", "", "else", ":", "\n", "                            ", "stance", "=", "\"NEI\"", "\n", "", "", "else", ":", "\n", "                        ", "evidence_sentence_idx", "=", "set", "(", "[", "]", ")", "\n", "stance", "=", "\"NEI\"", "\n", "\n", "", "if", "len", "(", "evidence_sentence_idx", ")", "==", "0", ":", "\n", "                        ", "concat_sentences", "=", "\"@\"", "\n", "rationale_label_string", "=", "\"0\"", "\n", "\n", "self", ".", "samples", ".", "append", "(", "{", "\n", "'dataset'", ":", "1", ",", "\n", "'claim'", ":", "claim", "[", "'claim'", "]", ",", "\n", "'claim_id'", ":", "claim", "[", "'id'", "]", ",", "\n", "'doc_id'", ":", "doc", "[", "'doc_id'", "]", ",", "\n", "'paragraph'", ":", "concat_sentences", ",", "\n", "'label'", ":", "rationale_label_string", ",", "\n", "'stance'", ":", "self", ".", "stance_ind", "[", "\"NEI\"", "]", "\n", "}", ")", "\n", "\n", "", "else", ":", "\n", "# Full-evidence sentences", "\n", "                        ", "evidence_sentences", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "abstract_sentences", ")", ")", ":", "\n", "                            ", "if", "i", "in", "evidence_sentence_idx", ":", "\n", "                                ", "evidence_sentences", ".", "append", "(", "abstract_sentences", "[", "i", "]", ")", "\n", "", "", "concat_sentences", "=", "(", "\" \"", "+", "sep_token", "+", "\" \"", ")", ".", "join", "(", "evidence_sentences", ")", "\n", "concat_sentences", "=", "clean_num", "(", "clean_url", "(", "concat_sentences", ")", ")", "\n", "rationale_label_string", "=", "\"1\"", "*", "len", "(", "evidence_sentence_idx", ")", "\n", "\n", "self", ".", "samples", ".", "append", "(", "{", "\n", "'dataset'", ":", "1", ",", "\n", "'claim'", ":", "claim", "[", "'claim'", "]", ",", "\n", "'claim_id'", ":", "claim", "[", "'id'", "]", ",", "\n", "'doc_id'", ":", "doc", "[", "'doc_id'", "]", ",", "\n", "'paragraph'", ":", "concat_sentences", ",", "\n", "'label'", ":", "rationale_label_string", ",", "\n", "'stance'", ":", "self", ".", "stance_ind", "[", "stance", "]", "\n", "}", ")", "\n", "\n", "# Each evidence sentence set", "\n", "for", "es_idx", "in", "evidence_sentence_idx_sets", ":", "\n", "                            ", "evidence_sentences", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "abstract_sentences", ")", ")", ":", "\n", "                                ", "if", "i", "in", "es_idx", ":", "\n", "                                    ", "evidence_sentences", ".", "append", "(", "abstract_sentences", "[", "i", "]", ")", "\n", "", "", "concat_sentences", "=", "(", "\" \"", "+", "sep_token", "+", "\" \"", ")", ".", "join", "(", "evidence_sentences", ")", "\n", "concat_sentences", "=", "clean_num", "(", "clean_url", "(", "concat_sentences", ")", ")", "\n", "rationale_label_string", "=", "\"1\"", "*", "len", "(", "evidence_sentence_idx", ")", "\n", "\n", "self", ".", "samples", ".", "append", "(", "{", "\n", "'dataset'", ":", "1", ",", "\n", "'claim'", ":", "claim", "[", "'claim'", "]", ",", "\n", "'claim_id'", ":", "claim", "[", "'id'", "]", ",", "\n", "'doc_id'", ":", "doc", "[", "'doc_id'", "]", ",", "\n", "'paragraph'", ":", "concat_sentences", ",", "\n", "'label'", ":", "rationale_label_string", ",", "\n", "'stance'", ":", "self", ".", "stance_ind", "[", "stance", "]", "\n", "}", ")", "\n", "\n", "# Negative sentences for both positive and negative paragraphs", "\n", "", "", "non_rationale_idx", "=", "set", "(", "range", "(", "len", "(", "abstract_sentences", ")", ")", ")", "-", "evidence_sentence_idx", "\n", "non_rationale_idx", "=", "random", ".", "sample", "(", "non_rationale_idx", ",", "\n", "k", "=", "min", "(", "random", ".", "randint", "(", "1", ",", "3", ")", ",", "len", "(", "non_rationale_idx", ")", ")", ")", "\n", "non_rationale_sentences", "=", "[", "abstract_sentences", "[", "i", "]", ".", "strip", "(", ")", "for", "i", "in", "sorted", "(", "list", "(", "non_rationale_idx", ")", ")", "]", "\n", "\n", "concat_sentences", "=", "(", "\" \"", "+", "sep_token", "+", "\" \"", ")", ".", "join", "(", "non_rationale_sentences", ")", "\n", "concat_sentences", "=", "clean_num", "(", "clean_url", "(", "concat_sentences", ")", ")", "\n", "rationale_label_string", "=", "\"0\"", "*", "len", "(", "non_rationale_sentences", ")", "\n", "\n", "self", ".", "samples", ".", "append", "(", "{", "\n", "'dataset'", ":", "1", ",", "\n", "'claim'", ":", "claim", "[", "'claim'", "]", ",", "\n", "'claim_id'", ":", "claim", "[", "'id'", "]", ",", "\n", "'doc_id'", ":", "doc", "[", "'doc_id'", "]", ",", "\n", "'paragraph'", ":", "concat_sentences", ",", "\n", "'label'", ":", "rationale_label_string", ",", "\n", "'stance'", ":", "self", ".", "stance_ind", "[", "\"NEI\"", "]", "\n", "}", ")", "\n", "\n", "", "else", ":", "\n", "                    ", "if", "len", "(", "evidence_sentence_idx", ")", "==", "0", ":", "\n", "                        ", "concat_sentences", "=", "\"@\"", "\n", "", "else", ":", "\n", "                        ", "evidence_sentences", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "abstract_sentences", ")", ")", ":", "\n", "                            ", "if", "i", "in", "evidence_sentence_idx", ":", "\n", "                                ", "evidence_sentences", ".", "append", "(", "abstract_sentences", "[", "i", "]", ")", "\n", "", "", "concat_sentences", "=", "(", "\" \"", "+", "sep_token", "+", "\" \"", ")", ".", "join", "(", "evidence_sentences", ")", "\n", "concat_sentences", "=", "clean_num", "(", "clean_url", "(", "concat_sentences", ")", ")", "\n", "\n", "", "self", ".", "samples", ".", "append", "(", "{", "\n", "'dataset'", ":", "1", ",", "\n", "'claim'", ":", "claim", "[", "'claim'", "]", ",", "\n", "'claim_id'", ":", "claim", "[", "'id'", "]", ",", "\n", "'doc_id'", ":", "doc", "[", "'doc_id'", "]", ",", "\n", "'paragraph'", ":", "concat_sentences", ",", "\n", "}", ")", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.dataset.SciFactStanceDataset.__len__": [[795, 797], ["len"], "methods", ["None"], ["", "", "", "", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "samples", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.dataset.SciFactStanceDataset.__getitem__": [[798, 800], ["None"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "idx", ")", ":", "\n", "        ", "return", "self", ".", "samples", "[", "idx", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.dataset.FEVERStanceDataset.__init__": [[805, 897], ["jsonlines.open", "max", "dataset.FEVERStanceDataset.label_ind.items", "dataset.FEVERStanceDataset.stance_ind.items", "len", "len", "sent.strip().split", "sent.strip", "set", "range", "util.clean_num", "dataset.FEVERStanceDataset.samples.append", "random.sample", "util.clean_num", "dataset.FEVERStanceDataset.samples.append", "dataset.FEVERStanceDataset.__init__.max_sent_len"], "methods", ["home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.util.clean_num", "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.util.clean_num"], ["def", "__init__", "(", "self", ",", "datapath", ":", "str", ",", "sep_token", "=", "\"</s>\"", ",", "train", "=", "True", ",", "k", "=", "0", ")", ":", "\n", "        ", "self", ".", "label_ind", "=", "{", "\"NEI\"", ":", "0", ",", "\"rationale\"", ":", "1", "}", "\n", "self", ".", "rev_label_ind", "=", "{", "i", ":", "l", "for", "(", "l", ",", "i", ")", "in", "self", ".", "label_ind", ".", "items", "(", ")", "}", "\n", "self", ".", "stance_ind", "=", "{", "\"NOT ENOUGH INFO\"", ":", "0", ",", "\"SUPPORTS\"", ":", "1", ",", "\"REFUTES\"", ":", "2", "}", "\n", "self", ".", "rev_stance_ind", "=", "{", "i", ":", "l", "for", "(", "l", ",", "i", ")", "in", "self", ".", "stance_ind", ".", "items", "(", ")", "}", "\n", "\n", "self", ".", "samples", "=", "[", "]", "\n", "self", ".", "excluded_pairs", "=", "[", "]", "\n", "\n", "def", "max_sent_len", "(", "sentences", ")", ":", "\n", "            ", "return", "max", "(", "[", "len", "(", "sent", ".", "strip", "(", ")", ".", "split", "(", ")", ")", "for", "sent", "in", "sentences", "]", ")", "\n", "\n", "", "for", "data", "in", "jsonlines", ".", "open", "(", "datapath", ")", ":", "\n", "            ", "try", ":", "\n", "                ", "if", "len", "(", "data", "[", "\"sentences\"", "]", ")", ">", "0", ":", "\n", "                    ", "sentences", "=", "[", "sent", ".", "strip", "(", ")", "for", "sent", "in", "data", "[", "\"sentences\"", "]", "]", "\n", "if", "max_sent_len", "(", "sentences", ")", ">", "100", "or", "len", "(", "sentences", ")", ">", "100", ":", "\n", "                        ", "continue", "\n", "\n", "", "if", "train", ":", "\n", "                        ", "rationales", "=", "[", "]", "\n", "rationale_sets", "=", "[", "]", "\n", "for", "evid", "in", "data", "[", "\"evidence_sets\"", "]", ":", "\n", "                            ", "rationales", ".", "extend", "(", "evid", ")", "\n", "rationale_sets", ".", "append", "(", "set", "(", "evid", ")", ")", "\n", "", "evidence_idx", "=", "set", "(", "rationales", ")", "\n", "evidence_sentences", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "sentences", ")", ")", ":", "\n", "                            ", "if", "i", "in", "evidence_idx", ":", "\n", "                                ", "evidence_sentences", ".", "append", "(", "sentences", "[", "i", "]", ")", "\n", "\n", "# Full evidence sentencees", "\n", "", "", "concat_sentences", "=", "(", "\" \"", "+", "sep_token", "+", "\" \"", ")", ".", "join", "(", "evidence_sentences", ")", "\n", "concat_sentences", "=", "clean_num", "(", "clean_url", "(", "concat_sentences", ")", ")", "\n", "\n", "self", ".", "samples", ".", "append", "(", "{", "\n", "'dataset'", ":", "0", ",", "\n", "'claim'", ":", "data", "[", "'claim'", "]", ",", "\n", "'claim_id'", ":", "data", "[", "'id'", "]", ",", "\n", "'paragraph'", ":", "concat_sentences", ",", "\n", "'stance'", ":", "self", ".", "stance_ind", "[", "data", "[", "\"label\"", "]", "]", "\n", "}", ")", "\n", "\n", "# For each evidence set", "\n", "for", "evidence_set_idx", "in", "rationale_sets", ":", "\n", "                            ", "evidence_idx", "=", "set", "(", "evidence_set_idx", ")", "\n", "evidence_sentences", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "sentences", ")", ")", ":", "\n", "                                ", "if", "i", "in", "evidence_idx", ":", "\n", "                                    ", "evidence_sentences", ".", "append", "(", "sentences", "[", "i", "]", ")", "\n", "\n", "", "", "concat_sentences", "=", "(", "\" \"", "+", "sep_token", "+", "\" \"", ")", ".", "join", "(", "evidence_sentences", ")", "\n", "concat_sentences", "=", "clean_num", "(", "clean_url", "(", "concat_sentences", ")", ")", "\n", "\n", "self", ".", "samples", ".", "append", "(", "{", "\n", "'dataset'", ":", "0", ",", "\n", "'claim'", ":", "data", "[", "'claim'", "]", ",", "\n", "'claim_id'", ":", "data", "[", "'id'", "]", ",", "\n", "'paragraph'", ":", "concat_sentences", ",", "\n", "'stance'", ":", "self", ".", "stance_ind", "[", "data", "[", "\"label\"", "]", "]", "\n", "}", ")", "\n", "\n", "# Negative sentences for both positive and negative paragraphs", "\n", "", "non_rationale_idx", "=", "set", "(", "range", "(", "len", "(", "sentences", ")", ")", ")", "-", "evidence_idx", "\n", "non_rationale_idx", "=", "random", ".", "sample", "(", "non_rationale_idx", ",", "\n", "k", "=", "min", "(", "random", ".", "randint", "(", "1", ",", "3", ")", ",", "len", "(", "non_rationale_idx", ")", ")", ")", "\n", "non_rationale_sentences", "=", "[", "sentences", "[", "i", "]", ".", "strip", "(", ")", "for", "i", "in", "sorted", "(", "list", "(", "non_rationale_idx", ")", ")", "]", "\n", "\n", "concat_sentences", "=", "(", "\" \"", "+", "sep_token", "+", "\" \"", ")", ".", "join", "(", "non_rationale_sentences", ")", "\n", "concat_sentences", "=", "clean_num", "(", "clean_url", "(", "concat_sentences", ")", ")", "\n", "\n", "self", ".", "samples", ".", "append", "(", "{", "\n", "'dataset'", ":", "1", ",", "\n", "'claim'", ":", "claim", "[", "'claim'", "]", ",", "\n", "'claim_id'", ":", "claim", "[", "'id'", "]", ",", "\n", "'doc_id'", ":", "doc", "[", "'doc_id'", "]", ",", "\n", "'paragraph'", ":", "concat_sentences", ",", "\n", "'label'", ":", "rationale_label_string", ",", "\n", "'stance'", ":", "self", ".", "stance_ind", "[", "\"NOT ENOUGH INFO\"", "]", "\n", "}", ")", "\n", "\n", "", "elif", "data", "[", "\"hit\"", "]", ":", "# The retrieved pages hit the gold page.", "\n", "                        ", "concat_sentences", "=", "(", "\" \"", "+", "sep_token", "+", "\" \"", ")", ".", "join", "(", "sentences", ")", "\n", "concat_sentences", "=", "clean_num", "(", "clean_url", "(", "concat_sentences", ")", ")", "\n", "self", ".", "samples", ".", "append", "(", "{", "\n", "'dataset'", ":", "0", ",", "\n", "'claim'", ":", "data", "[", "'claim'", "]", ",", "\n", "'claim_id'", ":", "data", "[", "'id'", "]", ",", "\n", "'paragraph'", ":", "concat_sentences", "\n", "}", ")", "\n", "", "", "", "except", ":", "\n", "                ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.dataset.FEVERStanceDataset.__len__": [[900, 902], ["len"], "methods", ["None"], ["", "", "", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "samples", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.dataset.FEVERStanceDataset.__getitem__": [[903, 905], ["None"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "idx", ")", ":", "\n", "        ", "return", "self", ".", "samples", "[", "idx", "]", "", "", "", ""]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.scifact_joint_paragraph_kgat.schedule_sample_p": [[29, 31], ["numpy.sin"], "function", ["None"], ["def", "schedule_sample_p", "(", "epoch", ",", "total", ")", ":", "\n", "    ", "return", "np", ".", "sin", "(", "0.5", "*", "np", ".", "pi", "*", "epoch", "/", "(", "total", "-", "1", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.scifact_joint_paragraph_kgat.reset_random_seed": [[32, 36], ["numpy.random.seed", "random.seed", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed"], "function", ["None"], ["", "def", "reset_random_seed", "(", "seed", ")", ":", "\n", "    ", "np", ".", "random", ".", "seed", "(", "seed", ")", "\n", "random", ".", "seed", "(", "seed", ")", "\n", "torch", ".", "manual_seed", "(", "seed", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.scifact_joint_paragraph_kgat.predict": [[37, 57], ["model.eval", "torch.no_grad", "torch.no_grad", "torch.no_grad", "tqdm.tqdm", "torch.utils.data.DataLoader", "scifact_joint_paragraph_kgat.encode", "scifact_joint_paragraph_kgat.token_idx_by_sentence", "model", "stance_preds.extend", "rationale_predictions.extend", "tensor.to", "tensor.to", "scifact_joint_paragraph_kgat.predict.remove_dummy"], "function", ["home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.label_prediction.transformer_scifact.encode", "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.FEVER_stance_paragraph.token_idx_by_sentence", "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.src.utils.remove_dummy"], ["", "def", "predict", "(", "model", ",", "dataset", ")", ":", "\n", "    ", "model", ".", "eval", "(", ")", "\n", "rationale_predictions", "=", "[", "]", "\n", "stance_preds", "=", "[", "]", "\n", "\n", "def", "remove_dummy", "(", "rationale_out", ")", ":", "\n", "        ", "return", "[", "out", "[", "1", ":", "]", "for", "out", "in", "rationale_out", "]", "\n", "\n", "", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "for", "batch", "in", "tqdm", "(", "DataLoader", "(", "dataset", ",", "batch_size", "=", "args", ".", "batch_size", ",", "shuffle", "=", "False", ")", ")", ":", "\n", "            ", "encoded_dict", "=", "encode", "(", "tokenizer", ",", "batch", ")", "\n", "transformation_indices", "=", "token_idx_by_sentence", "(", "encoded_dict", "[", "\"input_ids\"", "]", ",", "\n", "tokenizer", ".", "sep_token_id", ",", "args", ".", "repfile", ")", "\n", "encoded_dict", "=", "{", "key", ":", "tensor", ".", "to", "(", "device", ")", "for", "key", ",", "tensor", "in", "encoded_dict", ".", "items", "(", ")", "}", "\n", "transformation_indices", "=", "[", "tensor", ".", "to", "(", "device", ")", "for", "tensor", "in", "transformation_indices", "]", "\n", "rationale_out", ",", "stance_out", ",", "_", ",", "_", "=", "model", "(", "encoded_dict", ",", "transformation_indices", ")", "\n", "stance_preds", ".", "extend", "(", "stance_out", ")", "\n", "rationale_predictions", ".", "extend", "(", "remove_dummy", "(", "rationale_out", ")", ")", "\n", "\n", "", "", "return", "rationale_predictions", ",", "stance_preds", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.scifact_joint_paragraph_kgat.batch_rationale_label": [[58, 67], ["max", "enumerate", "torch.ones", "torch.ones", "torch.ones", "enumerate", "label_list.append", "label_matrix.long", "len", "len", "int", "int"], "function", ["None"], ["", "def", "batch_rationale_label", "(", "labels", ",", "padding_idx", "=", "2", ")", ":", "\n", "    ", "max_sent_len", "=", "max", "(", "[", "len", "(", "label", ")", "for", "label", "in", "labels", "]", ")", "\n", "label_matrix", "=", "torch", ".", "ones", "(", "len", "(", "labels", ")", ",", "max_sent_len", ")", "*", "padding_idx", "\n", "label_list", "=", "[", "]", "\n", "for", "i", ",", "label", "in", "enumerate", "(", "labels", ")", ":", "\n", "        ", "for", "j", ",", "evid", "in", "enumerate", "(", "label", ")", ":", "\n", "            ", "label_matrix", "[", "i", ",", "j", "]", "=", "int", "(", "evid", ")", "\n", "", "label_list", ".", "append", "(", "[", "int", "(", "evid", ")", "for", "evid", "in", "label", "]", ")", "\n", "", "return", "label_matrix", ".", "long", "(", ")", ",", "label_list", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.scifact_joint_paragraph_kgat.evaluation": [[68, 103], ["model.eval", "sklearn.metrics.f1_score", "sklearn.metrics.precision_score", "sklearn.metrics.recall_score", "sklearn.metrics.f1_score", "sklearn.metrics.precision_score", "sklearn.metrics.recall_score", "torch.no_grad", "torch.no_grad", "torch.no_grad", "tqdm.tqdm", "util.flatten", "util.flatten", "util.flatten", "util.flatten", "util.flatten", "util.flatten", "torch.utils.data.DataLoader", "scifact_joint_paragraph_kgat.encode", "scifact_joint_paragraph_kgat.token_idx_by_sentence", "batch[].to", "scifact_joint_paragraph_kgat.batch_rationale_label", "model", "stance_preds.extend", "stance_labels.extend", "rationale_predictions.extend", "rationale_labels.extend", "tensor.to", "tensor.to", "batch[].to.cpu().numpy().tolist", "scifact_joint_paragraph_kgat.predict.remove_dummy"], "function", ["home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.util.flatten", "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.util.flatten", "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.util.flatten", "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.util.flatten", "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.util.flatten", "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.util.flatten", "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.label_prediction.transformer_scifact.encode", "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.FEVER_stance_paragraph.token_idx_by_sentence", "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.domain_adaptation_joint_paragraph_fine_tune.batch_rationale_label", "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.src.utils.remove_dummy"], ["", "def", "evaluation", "(", "model", ",", "dataset", ")", ":", "\n", "    ", "model", ".", "eval", "(", ")", "\n", "rationale_predictions", "=", "[", "]", "\n", "rationale_labels", "=", "[", "]", "\n", "stance_preds", "=", "[", "]", "\n", "stance_labels", "=", "[", "]", "\n", "\n", "def", "remove_dummy", "(", "rationale_out", ")", ":", "\n", "        ", "return", "[", "out", "[", "1", ":", "]", "for", "out", "in", "rationale_out", "]", "\n", "\n", "", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "for", "batch", "in", "tqdm", "(", "DataLoader", "(", "dataset", ",", "batch_size", "=", "args", ".", "batch_size", "*", "5", ",", "shuffle", "=", "False", ")", ")", ":", "\n", "            ", "encoded_dict", "=", "encode", "(", "tokenizer", ",", "batch", ")", "\n", "transformation_indices", "=", "token_idx_by_sentence", "(", "encoded_dict", "[", "\"input_ids\"", "]", ",", "\n", "tokenizer", ".", "sep_token_id", ",", "args", ".", "repfile", ")", "\n", "encoded_dict", "=", "{", "key", ":", "tensor", ".", "to", "(", "device", ")", "for", "key", ",", "tensor", "in", "encoded_dict", ".", "items", "(", ")", "}", "\n", "transformation_indices", "=", "[", "tensor", ".", "to", "(", "device", ")", "for", "tensor", "in", "transformation_indices", "]", "\n", "stance_label", "=", "batch", "[", "\"stance\"", "]", ".", "to", "(", "device", ")", "\n", "padded_rationale_label", ",", "rationale_label", "=", "batch_rationale_label", "(", "batch", "[", "\"label\"", "]", ",", "padding_idx", "=", "2", ")", "\n", "rationale_out", ",", "stance_out", ",", "rationale_loss", ",", "stance_loss", "=", "model", "(", "encoded_dict", ",", "transformation_indices", ",", "stance_label", "=", "stance_label", ",", "\n", "rationale_label", "=", "padded_rationale_label", ".", "to", "(", "device", ")", ")", "\n", "stance_preds", ".", "extend", "(", "stance_out", ")", "\n", "stance_labels", ".", "extend", "(", "stance_label", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "tolist", "(", ")", ")", "\n", "\n", "rationale_predictions", ".", "extend", "(", "remove_dummy", "(", "rationale_out", ")", ")", "\n", "rationale_labels", ".", "extend", "(", "remove_dummy", "(", "rationale_label", ")", ")", "\n", "\n", "", "", "stance_f1", "=", "f1_score", "(", "stance_labels", ",", "stance_preds", ",", "average", "=", "\"micro\"", ",", "labels", "=", "[", "1", ",", "2", "]", ")", "\n", "stance_precision", "=", "precision_score", "(", "stance_labels", ",", "stance_preds", ",", "average", "=", "\"micro\"", ",", "labels", "=", "[", "1", ",", "2", "]", ")", "\n", "stance_recall", "=", "recall_score", "(", "stance_labels", ",", "stance_preds", ",", "average", "=", "\"micro\"", ",", "labels", "=", "[", "1", ",", "2", "]", ")", "\n", "rationale_f1", "=", "f1_score", "(", "flatten", "(", "rationale_labels", ")", ",", "flatten", "(", "rationale_predictions", ")", ")", "\n", "rationale_precision", "=", "precision_score", "(", "flatten", "(", "rationale_labels", ")", ",", "flatten", "(", "rationale_predictions", ")", ")", "\n", "rationale_recall", "=", "recall_score", "(", "flatten", "(", "rationale_labels", ")", ",", "flatten", "(", "rationale_predictions", ")", ")", "\n", "return", "stance_f1", ",", "stance_precision", ",", "stance_recall", ",", "rationale_f1", ",", "rationale_precision", ",", "rationale_recall", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.scifact_joint_paragraph_kgat.encode": [[106, 155], ["zip", "tokenizer.batch_encode_plus", "torch.cat", "torch.cat", "torch.cat", "encoded_dict[].size", "len", "numpy.sum", "numpy.argmax", "valid_paragraph.size", "all_paragraphs.append", "longest_first_truncation"], "function", ["home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.dataset.encode.longest_first_truncation"], ["", "def", "encode", "(", "tokenizer", ",", "batch", ",", "max_sent_len", "=", "512", ")", ":", "\n", "    ", "def", "truncate", "(", "input_ids", ",", "max_length", ",", "sep_token_id", ",", "pad_token_id", ")", ":", "\n", "        ", "def", "longest_first_truncation", "(", "sentences", ",", "objective", ")", ":", "\n", "            ", "sent_lens", "=", "[", "len", "(", "sent", ")", "for", "sent", "in", "sentences", "]", "\n", "while", "np", ".", "sum", "(", "sent_lens", ")", ">", "objective", ":", "\n", "                ", "max_position", "=", "np", ".", "argmax", "(", "sent_lens", ")", "\n", "sent_lens", "[", "max_position", "]", "-=", "1", "\n", "", "return", "[", "sentence", "[", ":", "length", "]", "for", "sentence", ",", "length", "in", "zip", "(", "sentences", ",", "sent_lens", ")", "]", "\n", "\n", "", "all_paragraphs", "=", "[", "]", "\n", "for", "paragraph", "in", "input_ids", ":", "\n", "            ", "valid_paragraph", "=", "paragraph", "[", "paragraph", "!=", "pad_token_id", "]", "\n", "if", "valid_paragraph", ".", "size", "(", "0", ")", "<=", "max_length", ":", "\n", "                ", "all_paragraphs", ".", "append", "(", "paragraph", "[", ":", "max_length", "]", ".", "unsqueeze", "(", "0", ")", ")", "\n", "", "else", ":", "\n", "                ", "sep_token_idx", "=", "np", ".", "arange", "(", "valid_paragraph", ".", "size", "(", "0", ")", ")", "[", "(", "valid_paragraph", "==", "sep_token_id", ")", ".", "numpy", "(", ")", "]", "\n", "idx_by_sentence", "=", "[", "]", "\n", "prev_idx", "=", "0", "\n", "for", "idx", "in", "sep_token_idx", ":", "\n", "                    ", "idx_by_sentence", ".", "append", "(", "paragraph", "[", "prev_idx", ":", "idx", "]", ")", "\n", "prev_idx", "=", "idx", "\n", "", "objective", "=", "max_length", "-", "1", "-", "len", "(", "idx_by_sentence", "[", "0", "]", ")", "# The last sep_token left out", "\n", "truncated_sentences", "=", "longest_first_truncation", "(", "idx_by_sentence", "[", "1", ":", "]", ",", "objective", ")", "\n", "truncated_paragraph", "=", "torch", ".", "cat", "(", "[", "idx_by_sentence", "[", "0", "]", "]", "+", "truncated_sentences", "+", "[", "torch", ".", "tensor", "(", "[", "sep_token_id", "]", ")", "]", ",", "0", ")", "\n", "all_paragraphs", ".", "append", "(", "truncated_paragraph", ".", "unsqueeze", "(", "0", ")", ")", "\n", "\n", "", "", "return", "torch", ".", "cat", "(", "all_paragraphs", ",", "0", ")", "\n", "\n", "", "inputs", "=", "zip", "(", "batch", "[", "\"claim\"", "]", ",", "batch", "[", "\"paragraph\"", "]", ")", "\n", "encoded_dict", "=", "tokenizer", ".", "batch_encode_plus", "(", "\n", "inputs", ",", "\n", "pad_to_max_length", "=", "True", ",", "add_special_tokens", "=", "True", ",", "\n", "return_tensors", "=", "'pt'", ")", "\n", "if", "encoded_dict", "[", "'input_ids'", "]", ".", "size", "(", "1", ")", ">", "max_sent_len", ":", "\n", "        ", "if", "'token_type_ids'", "in", "encoded_dict", ":", "\n", "            ", "encoded_dict", "=", "{", "\n", "\"input_ids\"", ":", "truncate", "(", "encoded_dict", "[", "'input_ids'", "]", ",", "max_sent_len", ",", "\n", "tokenizer", ".", "sep_token_id", ",", "tokenizer", ".", "pad_token_id", ")", ",", "\n", "'token_type_ids'", ":", "encoded_dict", "[", "'token_type_ids'", "]", "[", ":", ",", ":", "max_sent_len", "]", ",", "\n", "'attention_mask'", ":", "encoded_dict", "[", "'attention_mask'", "]", "[", ":", ",", ":", "max_sent_len", "]", "\n", "}", "\n", "", "else", ":", "\n", "            ", "encoded_dict", "=", "{", "\n", "\"input_ids\"", ":", "truncate", "(", "encoded_dict", "[", "'input_ids'", "]", ",", "max_sent_len", ",", "\n", "tokenizer", ".", "sep_token_id", ",", "tokenizer", ".", "pad_token_id", ")", ",", "\n", "'attention_mask'", ":", "encoded_dict", "[", "'attention_mask'", "]", "[", ":", ",", ":", "max_sent_len", "]", "\n", "}", "\n", "\n", "", "", "return", "encoded_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.scifact_joint_paragraph_kgat.token_idx_by_sentence": [[156, 191], ["torch.sum().numpy().tolist", "torch.sum().numpy().tolist", "torch.sum().numpy().tolist", "torch.arange().unsqueeze().expand", "torch.arange().unsqueeze().expand", "torch.arange().unsqueeze().expand", "torch.split", "torch.split", "torch.split", "torch.utils.rnn.pad_sequence", "torch.split", "torch.split", "torch.split", "torch.utils.rnn.pad_sequence", "torch.arange().unsqueeze().unsqueeze().expand", "torch.arange().unsqueeze().unsqueeze().expand", "torch.arange().unsqueeze().unsqueeze().expand", "sep_tokens.size", "torch.arange", "torch.arange", "torch.arange", "torch.sum().numpy().tolist.append", "all_word_indices.extend", "nn.utils.rnn.pad_sequence.size", "nn.utils.rnn.pad_sequence.size", "torch.arange().unsqueeze().unsqueeze().expand.long", "nn.utils.rnn.pad_sequence.long", "mask.long", "torch.sum().numpy", "torch.sum().numpy", "torch.sum().numpy", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange", "torch.arange", "torch.arange", "len", "torch.arange().unsqueeze().unsqueeze", "torch.arange().unsqueeze().unsqueeze", "torch.arange().unsqueeze().unsqueeze", "range", "torch.sum", "torch.sum", "torch.sum", "torch.arange", "torch.arange", "torch.arange", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "sep_tokens.size", "paragraph.size", "torch.arange", "torch.arange", "torch.arange", "sep_tokens.size"], "function", ["None"], ["", "def", "token_idx_by_sentence", "(", "input_ids", ",", "sep_token_id", ",", "model_name", ")", ":", "\n", "    ", "\"\"\"\n    Advanced indexing: Compute the token indices matrix of the BERT output.\n    input_ids: (batch_size, paragraph_len)\n    batch_indices, indices_by_batch, mask: (batch_size, N_sentence, N_token)\n    bert_out: (batch_size, paragraph_len,BERT_dim)\n    bert_out[batch_indices,indices_by_batch,:]: (batch_size, N_sentence, N_token, BERT_dim)\n    \"\"\"", "\n", "padding_idx", "=", "-", "1", "\n", "sep_tokens", "=", "(", "input_ids", "==", "sep_token_id", ")", ".", "bool", "(", ")", "\n", "paragraph_lens", "=", "torch", ".", "sum", "(", "sep_tokens", ",", "1", ")", ".", "numpy", "(", ")", ".", "tolist", "(", ")", "# i.e. N_sentences per paragraph", "\n", "indices", "=", "torch", ".", "arange", "(", "sep_tokens", ".", "size", "(", "-", "1", ")", ")", ".", "unsqueeze", "(", "0", ")", ".", "expand", "(", "sep_tokens", ".", "size", "(", "0", ")", ",", "-", "1", ")", "# 0,1,2,3,....,511 for each sentence", "\n", "sep_indices", "=", "torch", ".", "split", "(", "indices", "[", "sep_tokens", "]", ",", "paragraph_lens", ")", "# indices of SEP tokens per paragraph", "\n", "paragraph_lens", "=", "[", "]", "\n", "all_word_indices", "=", "[", "]", "\n", "for", "paragraph", "in", "sep_indices", ":", "\n", "# claim sentence: [CLS] token1 token2 ... tokenk", "\n", "        ", "claim_word_indices", "=", "torch", ".", "arange", "(", "0", ",", "paragraph", "[", "0", "]", ")", "\n", "if", "\"roberta\"", "in", "model_name", ":", "# Huggingface Roberta has <s>..</s></s>..</s>..</s>", "\n", "            ", "paragraph", "=", "paragraph", "[", "1", ":", "]", "\n", "# each sentence: [SEP] token1 token2 ... tokenk, the last [SEP] in the paragraph is ditched.", "\n", "", "sentence_word_indices", "=", "[", "torch", ".", "arange", "(", "paragraph", "[", "i", "]", ",", "paragraph", "[", "i", "+", "1", "]", ")", "for", "i", "in", "range", "(", "paragraph", ".", "size", "(", "0", ")", "-", "1", ")", "]", "\n", "\n", "# KGAT requires claim sentence, so add it back.", "\n", "word_indices", "=", "[", "claim_word_indices", "]", "+", "sentence_word_indices", "\n", "\n", "paragraph_lens", ".", "append", "(", "len", "(", "word_indices", ")", ")", "\n", "all_word_indices", ".", "extend", "(", "word_indices", ")", "\n", "", "indices_by_sentence", "=", "nn", ".", "utils", ".", "rnn", ".", "pad_sequence", "(", "all_word_indices", ",", "batch_first", "=", "True", ",", "padding_value", "=", "padding_idx", ")", "\n", "indices_by_sentence_split", "=", "torch", ".", "split", "(", "indices_by_sentence", ",", "paragraph_lens", ")", "\n", "indices_by_batch", "=", "nn", ".", "utils", ".", "rnn", ".", "pad_sequence", "(", "indices_by_sentence_split", ",", "batch_first", "=", "True", ",", "padding_value", "=", "padding_idx", ")", "\n", "batch_indices", "=", "torch", ".", "arange", "(", "sep_tokens", ".", "size", "(", "0", ")", ")", ".", "unsqueeze", "(", "-", "1", ")", ".", "unsqueeze", "(", "-", "1", ")", ".", "expand", "(", "-", "1", ",", "indices_by_batch", ".", "size", "(", "1", ")", ",", "indices_by_batch", ".", "size", "(", "-", "1", ")", ")", "\n", "mask", "=", "(", "indices_by_batch", ">=", "0", ")", "\n", "\n", "return", "batch_indices", ".", "long", "(", ")", ",", "indices_by_batch", ".", "long", "(", ")", ",", "mask", ".", "long", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.scifact_joint_paragraph_kgat.post_process_stance": [[192, 200], ["zip", "len", "len", "rationale_pred[].items", "len"], "function", ["None"], ["", "def", "post_process_stance", "(", "rationale_json", ",", "stance_json", ")", ":", "\n", "    ", "assert", "(", "len", "(", "rationale_json", ")", "==", "len", "(", "stance_json", ")", ")", "\n", "for", "stance_pred", ",", "rationale_pred", "in", "zip", "(", "stance_json", ",", "rationale_json", ")", ":", "\n", "        ", "assert", "(", "stance_pred", "[", "\"claim_id\"", "]", "==", "rationale_pred", "[", "\"claim_id\"", "]", ")", "\n", "for", "doc_id", ",", "pred", "in", "rationale_pred", "[", "\"evidence\"", "]", ".", "items", "(", ")", ":", "\n", "            ", "if", "len", "(", "pred", ")", "==", "0", ":", "\n", "                ", "stance_pred", "[", "\"labels\"", "]", "[", "doc_id", "]", "[", "\"label\"", "]", "=", "\"NOT_ENOUGH_INFO\"", "\n", "", "", "", "return", "stance_json", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.paragraph_model_kgat.TimeDistributed.__init__": [[20, 24], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.label_prediction.transformer_scifact.SciFactLabelPredictionDataset.__init__"], ["    ", "def", "__init__", "(", "self", ",", "module", ",", "batch_first", "=", "False", ")", ":", "\n", "        ", "super", "(", "TimeDistributed", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "module", "=", "module", "\n", "self", ".", "batch_first", "=", "batch_first", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.paragraph_model_kgat.TimeDistributed.forward": [[25, 42], ["x.contiguous().view", "paragraph_model_kgat.TimeDistributed.module", "len", "paragraph_model_kgat.TimeDistributed.module", "x.size", "y.view.view.contiguous().view", "y.view.view.view", "x.size", "x.contiguous", "x.size", "y.view.view.size", "x.size", "y.view.view.size", "y.view.view.contiguous"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "\n", "        ", "if", "len", "(", "x", ".", "size", "(", ")", ")", "<=", "2", ":", "\n", "            ", "return", "self", ".", "module", "(", "x", ")", "\n", "\n", "# Squash samples and timesteps into a single axis", "\n", "", "x_reshape", "=", "x", ".", "contiguous", "(", ")", ".", "view", "(", "-", "1", ",", "x", ".", "size", "(", "-", "1", ")", ")", "# (samples * timesteps, input_size)", "\n", "\n", "y", "=", "self", ".", "module", "(", "x_reshape", ")", "\n", "\n", "# We have to reshape Y", "\n", "if", "self", ".", "batch_first", ":", "\n", "            ", "y", "=", "y", ".", "contiguous", "(", ")", ".", "view", "(", "x", ".", "size", "(", "0", ")", ",", "-", "1", ",", "y", ".", "size", "(", "-", "1", ")", ")", "# (samples, timesteps, output_size)", "\n", "", "else", ":", "\n", "            ", "y", "=", "y", ".", "view", "(", "-", "1", ",", "x", ".", "size", "(", "1", ")", ",", "y", ".", "size", "(", "-", "1", ")", ")", "# (timesteps, samples, output_size)", "\n", "\n", "", "return", "y", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.paragraph_model_kgat.TimeDistributedDense.__init__": [[44, 50], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear", "paragraph_model_kgat.TimeDistributed"], "methods", ["home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.label_prediction.transformer_scifact.SciFactLabelPredictionDataset.__init__"], ["    ", "def", "__init__", "(", "self", ",", "INPUT_SIZE", ",", "OUTPUT_SIZE", ")", ":", "\n", "        ", "super", "(", "TimeDistributedDense", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "input_size", "=", "INPUT_SIZE", "\n", "self", ".", "output_size", "=", "OUTPUT_SIZE", "\n", "self", ".", "linear", "=", "nn", ".", "Linear", "(", "INPUT_SIZE", ",", "OUTPUT_SIZE", ",", "bias", "=", "True", ")", "\n", "self", ".", "timedistributedlayer", "=", "TimeDistributed", "(", "self", ".", "linear", ")", "\n", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.paragraph_model_kgat.TimeDistributedDense.forward": [[50, 54], ["paragraph_model_kgat.TimeDistributedDense.timedistributedlayer"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "# x: (BATCH_SIZE, ARRAY_LEN, INPUT_SIZE)", "\n", "\n", "        ", "return", "self", ".", "timedistributedlayer", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.paragraph_model_kgat.ClassificationHead.__init__": [[58, 63], ["torch.Module.__init__", "paragraph_model_kgat.TimeDistributedDense", "torch.Dropout", "torch.Dropout", "torch.Dropout", "paragraph_model_kgat.TimeDistributedDense"], "methods", ["home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.label_prediction.transformer_scifact.SciFactLabelPredictionDataset.__init__"], ["def", "__init__", "(", "self", ",", "hidden_size", ",", "num_labels", ",", "hidden_dropout_prob", "=", "0.1", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dense", "=", "TimeDistributedDense", "(", "hidden_size", ",", "hidden_size", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "hidden_dropout_prob", ")", "\n", "self", ".", "out_proj", "=", "TimeDistributedDense", "(", "hidden_size", ",", "num_labels", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.paragraph_model_kgat.ClassificationHead.forward": [[64, 71], ["paragraph_model_kgat.ClassificationHead.dropout", "paragraph_model_kgat.ClassificationHead.dense", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "paragraph_model_kgat.ClassificationHead.dropout", "paragraph_model_kgat.ClassificationHead.out_proj"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "**", "kwargs", ")", ":", "\n", "        ", "x", "=", "self", ".", "dropout", "(", "x", ")", "\n", "x", "=", "self", ".", "dense", "(", "x", ")", "\n", "x", "=", "torch", ".", "tanh", "(", "x", ")", "\n", "x", "=", "self", ".", "dropout", "(", "x", ")", "\n", "x", "=", "self", ".", "out_proj", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.paragraph_model_kgat.WordAttention.__init__": [[80, 86], ["torch.Module.__init__", "paragraph_model_kgat.TimeDistributedDense", "torch.Dropout", "torch.Dropout", "torch.Dropout", "paragraph_model_kgat.TimeDistributedDense"], "methods", ["home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.label_prediction.transformer_scifact.SciFactLabelPredictionDataset.__init__"], ["def", "__init__", "(", "self", ",", "INPUT_SIZE", ",", "PROJ_SIZE", ",", "dropout", "=", "0.1", ")", ":", "\n", "        ", "super", "(", "WordAttention", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "activation", "=", "torch", ".", "tanh", "\n", "self", ".", "att_proj", "=", "TimeDistributedDense", "(", "INPUT_SIZE", ",", "PROJ_SIZE", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "dropout", ")", "\n", "self", ".", "att_scorer", "=", "TimeDistributedDense", "(", "PROJ_SIZE", ",", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.paragraph_model_kgat.WordAttention.forward": [[87, 99], ["paragraph_model_kgat.WordAttention.att_proj", "paragraph_model_kgat.WordAttention.dropout", "paragraph_model_kgat.WordAttention.att_scorer().squeeze().view", "torch.softmax", "torch.softmax", "torch.softmax", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where.view", "torch.where.view", "torch.where.view", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "out.view.view.view", "paragraph_model_kgat.WordAttention.dropout", "paragraph_model_kgat.WordAttention.activation", "x.size", "x.size", "x.size", "paragraph_model_kgat.WordAttention.masked_fill", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.where.size", "torch.where.size", "torch.where.size", "x.size", "x.size", "x.size", "x.view", "paragraph_model_kgat.WordAttention.att_scorer().squeeze", "float", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "x.size", "torch.where.view.unsqueeze", "x.view", "paragraph_model_kgat.WordAttention.att_scorer", "x.size", "x.size"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "token_mask", ")", ":", "\n", "        ", "proj_input", "=", "self", ".", "att_proj", "(", "self", ".", "dropout", "(", "x", ".", "view", "(", "-", "1", ",", "x", ".", "size", "(", "-", "1", ")", ")", ")", ")", "\n", "proj_input", "=", "self", ".", "dropout", "(", "self", ".", "activation", "(", "proj_input", ")", ")", "\n", "raw_att_scores", "=", "self", ".", "att_scorer", "(", "proj_input", ")", ".", "squeeze", "(", "-", "1", ")", ".", "view", "(", "x", ".", "size", "(", "0", ")", ",", "x", ".", "size", "(", "1", ")", ",", "x", ".", "size", "(", "2", ")", ")", "# (Batch_size, N_sentence, N_token)", "\n", "att_scores", "=", "F", ".", "softmax", "(", "raw_att_scores", ".", "masked_fill", "(", "(", "1", "-", "token_mask", ")", ".", "bool", "(", ")", ",", "float", "(", "'-inf'", ")", ")", ",", "dim", "=", "-", "1", ")", "\n", "att_scores", "=", "torch", ".", "where", "(", "torch", ".", "isnan", "(", "att_scores", ")", ",", "torch", ".", "zeros_like", "(", "att_scores", ")", ",", "att_scores", ")", "# Replace NaN with 0", "\n", "batch_att_scores", "=", "att_scores", ".", "view", "(", "-", "1", ",", "att_scores", ".", "size", "(", "-", "1", ")", ")", "# (Batch_size * N_sentence, N_token)", "\n", "out", "=", "torch", ".", "bmm", "(", "batch_att_scores", ".", "unsqueeze", "(", "1", ")", ",", "x", ".", "view", "(", "-", "1", ",", "x", ".", "size", "(", "2", ")", ",", "x", ".", "size", "(", "3", ")", ")", ")", ".", "squeeze", "(", "1", ")", "\n", "# (Batch_size * N_sentence, INPUT_SIZE)", "\n", "out", "=", "out", ".", "view", "(", "x", ".", "size", "(", "0", ")", ",", "x", ".", "size", "(", "1", ")", ",", "x", ".", "size", "(", "-", "1", ")", ")", "\n", "mask", "=", "token_mask", "[", ":", ",", ":", ",", "0", "]", "\n", "return", "out", ",", "mask", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.paragraph_model_kgat.SelectRationale.__init__": [[105, 108], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.label_prediction.transformer_scifact.SciFactLabelPredictionDataset.__init__"], ["def", "__init__", "(", "self", ",", "hard_k", ")", ":", "\n", "        ", "super", "(", "SelectRationale", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "hard_k", "=", "hard_k", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.paragraph_model_kgat.SelectRationale.forward": [[109, 120], ["token_reps.size", "torch.topk", "torch.topk", "torch.topk", "torch.topk", "torch.topk", "torch.topk", "torch.topk", "torch.topk", "torch.topk", "torch.arange().unsqueeze().expand", "torch.arange().unsqueeze().expand", "torch.arange().unsqueeze().expand", "torch.arange().unsqueeze().expand", "torch.arange().unsqueeze().expand", "torch.arange().unsqueeze().expand", "torch.arange().unsqueeze().expand", "torch.arange().unsqueeze().expand", "torch.arange().unsqueeze().expand", "att_scores.size", "top_idx.size", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "top_idx.size"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "token_reps", ",", "token_mask", ",", "rationale_out", ")", ":", "\n", "# token_reps: (BATCH_SIZE, N_sentence, N_token, INPUT_SIZE)", "\n", "# token_mask: (BATCH_SIZE, N_sentence, N_token)", "\n", "# rationale_out: (BATCH_SIZE, N_sentence, 2)", "\n", "        ", "att_scores", "=", "rationale_out", "[", ":", ",", ":", ",", "1", "]", "# (BATCH_SIZE, N_sentence)", "\n", "if", "token_reps", ".", "size", "(", "0", ")", ">", "0", ":", "\n", "            ", "if", "self", ".", "hard_k", ">", "0", "and", "self", ".", "hard_k", "<=", "att_scores", ".", "size", "(", "1", ")", ":", "\n", "                ", "top_att_scores", ",", "top_idx", "=", "torch", ".", "topk", "(", "att_scores", ",", "self", ".", "hard_k", ")", "\n", "batch_indices", "=", "torch", ".", "arange", "(", "top_idx", ".", "size", "(", "0", ")", ")", ".", "unsqueeze", "(", "-", "1", ")", ".", "expand", "(", "-", "1", ",", "top_idx", ".", "size", "(", "1", ")", ")", "\n", "return", "token_reps", "[", "batch_indices", ",", "top_idx", ",", ":", ",", ":", "]", ",", "token_mask", "[", "batch_indices", ",", "top_idx", ",", ":", "]", "\n", "", "", "return", "token_reps", ",", "token_mask", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.paragraph_model_kgat.DynamicRationale.__init__": [[126, 128], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.label_prediction.transformer_scifact.SciFactLabelPredictionDataset.__init__"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", "DynamicRationale", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.paragraph_model_kgat.DynamicRationale.forward": [[129, 141], ["token_reps[].unsqueeze", "token_mask[].unsqueeze", "len", "token_reps[].unsqueeze.size"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "token_reps", ",", "token_mask", ",", "valid_sentences", ")", ":", "\n", "# token_reps: (BATCH_SIZE, N_sentence, N_token, INPUT_SIZE)", "\n", "# token_mask: (BATCH_SIZE, N_sentence, N_token)", "\n", "# valid_sentences: (BATCH_SIZE, N_sentence)", "\n", "\n", "#valid_sentences = rationale_out[:,:,1] > rationale_out[:,:,0] # Only consider sentences predicted as rationales", "\n", "        ", "rationale_reps", "=", "token_reps", "[", ":", ",", "1", ":", ",", ":", ",", ":", "]", "[", "valid_sentences", "]", "\n", "rationale_token_mask", "=", "token_mask", "[", ":", ",", "1", ":", ",", ":", "]", "[", "valid_sentences", "]", "\n", "if", "len", "(", "rationale_reps", ".", "shape", ")", "==", "3", "or", "rationale_reps", ".", "size", "(", "1", ")", "==", "0", ":", "\n", "            ", "rationale_reps", "=", "token_reps", "[", ":", ",", "1", ",", ":", ",", ":", "]", ".", "unsqueeze", "(", "1", ")", "# First sentence is claim; second is dummy", "\n", "rationale_token_mask", "=", "token_mask", "[", ":", ",", "1", ",", ":", "]", ".", "unsqueeze", "(", "1", ")", "\n", "", "return", "rationale_reps", ",", "rationale_token_mask", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.paragraph_model_kgat.KernelGraphAttentionNetwork.__init__": [[143, 158], ["torch.Module.__init__", "torch.tensor().cuda", "torch.tensor().cuda", "torch.tensor().cuda", "torch.tensor().cuda", "torch.tensor().cuda", "torch.tensor().cuda", "torch.tensor().cuda", "torch.tensor().cuda", "torch.tensor().cuda", "torch.tensor().cuda", "torch.tensor().cuda", "torch.tensor().cuda", "torch.tensor().cuda", "torch.tensor().cuda", "torch.tensor().cuda", "torch.tensor().cuda", "torch.tensor().cuda", "torch.tensor().cuda", "torch.CosineSimilarity", "torch.CosineSimilarity", "torch.CosineSimilarity", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Linear", "torch.Linear", "torch.Linear", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "paragraph_model_kgat.KernelGraphAttentionNetwork.kernal_mus", "paragraph_model_kgat.KernelGraphAttentionNetwork.kernel_sigmas"], "methods", ["home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.label_prediction.transformer_scifact.SciFactLabelPredictionDataset.__init__", "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.paragraph_model_kgat.KernelGraphAttentionNetwork.kernal_mus", "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.paragraph_model_kgat.KernelGraphAttentionNetwork.kernel_sigmas"], ["    ", "def", "__init__", "(", "self", ",", "bert_dim", ",", "kernel", ")", ":", "\n", "        ", "super", "(", "KernelGraphAttentionNetwork", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "stance_label_size", "=", "3", "\n", "\n", "self", ".", "mu", "=", "torch", ".", "tensor", "(", "self", ".", "kernal_mus", "(", "kernel", ")", ",", "requires_grad", "=", "False", ")", ".", "cuda", "(", ")", "#to(device)", "\n", "self", ".", "sigma", "=", "torch", ".", "tensor", "(", "self", ".", "kernel_sigmas", "(", "kernel", ")", ",", "requires_grad", "=", "False", ")", ".", "cuda", "(", ")", "\n", "self", ".", "cos_similarity", "=", "nn", ".", "CosineSimilarity", "(", "dim", "=", "-", "1", ",", "eps", "=", "1e-6", ")", "\n", "self", ".", "proj_select", "=", "nn", ".", "Linear", "(", "kernel", ",", "1", ")", "\n", "self", ".", "proj_gat", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "bert_dim", "*", "2", ",", "128", ")", ",", "\n", "nn", ".", "ReLU", "(", "True", ")", ",", "\n", "nn", ".", "Linear", "(", "128", ",", "1", ")", "\n", ")", "\n", "self", ".", "proj_rationale", "=", "nn", ".", "Linear", "(", "kernel", ",", "1", ")", "\n", "self", ".", "proj_label", "=", "nn", ".", "Linear", "(", "bert_dim", "*", "2", ",", "self", ".", "stance_label_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.paragraph_model_kgat.KernelGraphAttentionNetwork.kernal_mus": [[159, 174], ["l_mu.append", "range", "l_mu.append"], "methods", ["None"], ["", "def", "kernal_mus", "(", "self", ",", "n_kernels", ")", ":", "\n", "        ", "\"\"\"\n        get the mu for each guassian kernel. Mu is the middle of each bin\n        :param n_kernels: number of kernels (including exact match). first one is exact match\n        :return: l_mu, a list of mu.\n        \"\"\"", "\n", "l_mu", "=", "[", "1", "]", "\n", "if", "n_kernels", "==", "1", ":", "\n", "            ", "return", "l_mu", "\n", "\n", "", "bin_size", "=", "2.0", "/", "(", "n_kernels", "-", "1", ")", "# score range from [-1, 1]", "\n", "l_mu", ".", "append", "(", "1", "-", "bin_size", "/", "2", ")", "# mu: middle of the bin", "\n", "for", "i", "in", "range", "(", "1", ",", "n_kernels", "-", "1", ")", ":", "\n", "            ", "l_mu", ".", "append", "(", "l_mu", "[", "i", "]", "-", "bin_size", ")", "\n", "", "return", "l_mu", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.paragraph_model_kgat.KernelGraphAttentionNetwork.kernel_sigmas": [[176, 191], ["None"], "methods", ["None"], ["", "def", "kernel_sigmas", "(", "self", ",", "n_kernels", ")", ":", "\n", "        ", "\"\"\"\n        get sigmas for each guassian kernel.\n        :param n_kernels: number of kernels (including exactmath.)\n        :param lamb:\n        :param use_exact:\n        :return: l_sigma, a list of simga\n        \"\"\"", "\n", "bin_size", "=", "2.0", "/", "(", "n_kernels", "-", "1", ")", "\n", "l_sigma", "=", "[", "0.001", "]", "# for exact match. small variance -> exact match", "\n", "if", "n_kernels", "==", "1", ":", "\n", "            ", "return", "l_sigma", "\n", "\n", "", "l_sigma", "+=", "[", "0.1", "]", "*", "(", "n_kernels", "-", "1", ")", "\n", "return", "l_sigma", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.paragraph_model_kgat.KernelGraphAttentionNetwork.kernel_computation": [[192, 206], ["paragraph_model_kgat.KernelGraphAttentionNetwork.cos_similarity", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "input1.float", "input2.float", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "mask.unsqueeze().float", "paragraph_model_kgat.KernelGraphAttentionNetwork.unsqueeze", "mask.unsqueeze"], "methods", ["None"], ["", "def", "kernel_computation", "(", "self", ",", "input1", ",", "input2", ",", "mask", ",", "mu", ",", "sigma", ")", ":", "\n", "        ", "\"\"\"\n        RBF kernel computation.\n        intput1, input2: (batch_size, n_sentence, [n_sentence, ], n_token, n_token, bert_dim)\n        mask: (batch_size, n_sentence, [n_sentence, ], n_token, n_token)\n        mu: (1,1,[1,],1,1,kernel_size)\n        sigma: (1,1,[1,],1,1,kernel_size)\n        K: (batch_size, n_sentence, [n_sentence, ], n_token, kernel_size)\n        \"\"\"", "\n", "similarity", "=", "self", ".", "cos_similarity", "(", "input1", ".", "float", "(", ")", ",", "input2", ".", "float", "(", ")", ")", "\n", "normalized_similarity", "=", "-", "0.5", "*", "(", "(", "similarity", ".", "unsqueeze", "(", "-", "1", ")", "-", "mu", ")", "/", "sigma", ")", "**", "2", "\n", "pooling_sum", "=", "torch", ".", "sum", "(", "torch", ".", "exp", "(", "normalized_similarity", ")", "*", "mask", ".", "unsqueeze", "(", "-", "1", ")", ".", "float", "(", ")", ",", "axis", "=", "-", "2", ")", "\n", "K", "=", "torch", ".", "log", "(", "torch", ".", "clamp", "(", "pooling_sum", ",", "min", "=", "1e-6", ")", ")", "\n", "return", "K", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.paragraph_model_kgat.KernelGraphAttentionNetwork.edge_kernel": [[207, 234], ["sentence_token_reps.unsqueeze().unsqueeze().expand", "sentence_token_reps.unsqueeze().unsqueeze().expand", "paragraph_model_kgat.KernelGraphAttentionNetwork.mu.view", "paragraph_model_kgat.KernelGraphAttentionNetwork.sigma.view", "token_mask.unsqueeze().unsqueeze().expand", "paragraph_model_kgat.KernelGraphAttentionNetwork.kernel_computation", "token_mask.unsqueeze().expand().unsqueeze", "paragraph_model_kgat.KernelGraphAttentionNetwork.proj_select", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "sentence_token_reps.unsqueeze().expand", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "z.unsqueeze().expand", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "paragraph_model_kgat.KernelGraphAttentionNetwork.masked_fill", "paragraph_model_kgat.KernelGraphAttentionNetwork.proj_gat", "paragraph_model_kgat.KernelGraphAttentionNetwork.proj_label", "sentence_token_reps.unsqueeze().unsqueeze", "sentence_token_reps.unsqueeze().unsqueeze", "token_mask.unsqueeze().unsqueeze", "token_mask.unsqueeze().expand", "sentence_token_reps.unsqueeze", "z.unsqueeze", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "sentence_token_reps.unsqueeze", "sentence_token_reps.unsqueeze", "token_mask.unsqueeze", "token_mask.unsqueeze"], "methods", ["home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.paragraph_model_kgat.KernelGraphAttentionNetwork.kernel_computation"], ["", "def", "edge_kernel", "(", "self", ",", "sentence_token_reps", ",", "token_mask", ")", ":", "\n", "        ", "\"\"\"\n        Computs the stance prediction for each sentence.\n        sentence_label_pred: (batch_size, n_sentence, label_size)\n        \"\"\"", "\n", "batch_size", ",", "n_sentence", ",", "n_token", ",", "n_rep", "=", "sentence_token_reps", ".", "shape", "\n", "z", "=", "sentence_token_reps", "[", ":", ",", ":", ",", "0", ",", ":", "]", "\n", "\n", "input1_exp", "=", "sentence_token_reps", ".", "unsqueeze", "(", "2", ")", ".", "unsqueeze", "(", "4", ")", ".", "expand", "(", "-", "1", ",", "-", "1", ",", "n_sentence", ",", "-", "1", ",", "n_token", ",", "-", "1", ")", "\n", "input2_exp", "=", "sentence_token_reps", ".", "unsqueeze", "(", "1", ")", ".", "unsqueeze", "(", "3", ")", ".", "expand", "(", "-", "1", ",", "n_sentence", ",", "-", "1", ",", "n_token", ",", "-", "1", ",", "-", "1", ")", "\n", "mu", "=", "self", ".", "mu", ".", "view", "(", "1", ",", "1", ",", "1", ",", "1", ",", "1", ",", "-", "1", ")", "\n", "sigma", "=", "self", ".", "sigma", ".", "view", "(", "1", ",", "1", ",", "1", ",", "1", ",", "1", ",", "-", "1", ")", "\n", "token_mask_exp", "=", "token_mask", ".", "unsqueeze", "(", "1", ")", ".", "unsqueeze", "(", "-", "1", ")", ".", "expand", "(", "-", "1", ",", "n_sentence", ",", "-", "1", ",", "-", "1", ",", "n_token", ")", "# (batch_size, n_sentence, n_sentence, n_token, n_token)", "\n", "K", "=", "self", ".", "kernel_computation", "(", "input1_exp", ",", "input2_exp", ",", "token_mask_exp", ",", "mu", ",", "sigma", ")", "\n", "\n", "token_mask_exp2", "=", "token_mask", ".", "unsqueeze", "(", "1", ")", ".", "expand", "(", "-", "1", ",", "n_sentence", ",", "-", "1", ",", "-", "1", ")", ".", "unsqueeze", "(", "-", "1", ")", "# (batch_size, n_sentence, n_sentence, n_token, 1)", "\n", "proj_K", "=", "self", ".", "proj_select", "(", "K", ")", "\n", "token_attention", "=", "torch", ".", "softmax", "(", "proj_K", ".", "masked_fill", "(", "(", "~", "token_mask_exp2", ")", ".", "bool", "(", ")", ",", "-", "1e4", ")", ",", "dim", "=", "-", "2", ")", "\n", "sentence_token_reps_exp", "=", "sentence_token_reps", ".", "unsqueeze", "(", "1", ")", ".", "expand", "(", "-", "1", ",", "n_sentence", ",", "-", "1", ",", "-", "1", ",", "-", "1", ")", "\n", "z_hat", "=", "torch", ".", "sum", "(", "sentence_token_reps_exp", "*", "token_attention", ",", "axis", "=", "-", "2", ")", "\n", "z_exp", "=", "z", ".", "unsqueeze", "(", "1", ")", ".", "expand", "(", "-", "1", ",", "n_sentence", ",", "-", "1", ",", "-", "1", ")", "\n", "z_cat", "=", "torch", ".", "cat", "(", "[", "z_exp", ",", "z_hat", "]", ",", "axis", "=", "-", "1", ")", "# (batch_size, n_sentence, n_sentence, 2 * bert_dim)", "\n", "beta", "=", "torch", ".", "softmax", "(", "self", ".", "proj_gat", "(", "z_cat", ")", ",", "axis", "=", "1", ")", "\n", "v", "=", "torch", ".", "cat", "(", "[", "torch", ".", "sum", "(", "beta", "*", "z_hat", ",", "axis", "=", "1", ")", ",", "z", "]", ",", "axis", "=", "-", "1", ")", "\n", "sentence_label_pred", "=", "torch", ".", "softmax", "(", "self", ".", "proj_label", "(", "v", ")", ",", "axis", "=", "-", "1", ")", "\n", "\n", "return", "sentence_label_pred", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.paragraph_model_kgat.KernelGraphAttentionNetwork.node_kernel": [[235, 250], ["claim_reps.unsqueeze().unsqueeze().expand", "sentence_token_reps.unsqueeze().expand", "paragraph_model_kgat.KernelGraphAttentionNetwork.mu.view", "paragraph_model_kgat.KernelGraphAttentionNetwork.sigma.view", "token_mask.unsqueeze().expand", "paragraph_model_kgat.KernelGraphAttentionNetwork.kernel_computation", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "paragraph_model_kgat.KernelGraphAttentionNetwork.proj_rationale", "claim_reps.unsqueeze().unsqueeze", "sentence_token_reps.unsqueeze", "token_mask.unsqueeze", "claim_reps.unsqueeze"], "methods", ["home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.paragraph_model_kgat.KernelGraphAttentionNetwork.kernel_computation"], ["", "def", "node_kernel", "(", "self", ",", "claim_reps", ",", "sentence_token_reps", ",", "token_mask", ")", ":", "\n", "        ", "\"\"\"\n        Computes the weight of each rationale to the final stance prediction.\n        rationale_out: (batch_size, n_sentence, 1)\n        \"\"\"", "\n", "batch_size", ",", "n_sentence", ",", "n_token", ",", "n_rep", "=", "sentence_token_reps", ".", "shape", "\n", "claim_reps_exp", "=", "claim_reps", ".", "unsqueeze", "(", "1", ")", ".", "unsqueeze", "(", "3", ")", ".", "expand", "(", "-", "1", ",", "n_sentence", ",", "-", "1", ",", "n_token", ",", "-", "1", ")", "\n", "sentence_token_reps_exp", "=", "sentence_token_reps", ".", "unsqueeze", "(", "3", ")", ".", "expand", "(", "-", "1", ",", "-", "1", ",", "-", "1", ",", "n_token", ",", "-", "1", ")", "\n", "mu", "=", "self", ".", "mu", ".", "view", "(", "1", ",", "1", ",", "1", ",", "1", ",", "-", "1", ")", "\n", "sigma", "=", "self", ".", "sigma", ".", "view", "(", "1", ",", "1", ",", "1", ",", "1", ",", "-", "1", ")", "\n", "token_mask_exp", "=", "token_mask", ".", "unsqueeze", "(", "-", "1", ")", ".", "expand", "(", "-", "1", ",", "-", "1", ",", "-", "1", ",", "n_token", ")", "# (batch_size, n_sentence, n_token, n_token)", "\n", "K", "=", "self", ".", "kernel_computation", "(", "claim_reps_exp", ",", "sentence_token_reps_exp", ",", "token_mask_exp", ",", "mu", ",", "sigma", ")", "\n", "phi", "=", "torch", ".", "mean", "(", "K", ",", "axis", "=", "-", "2", ")", "\n", "rationale_out", "=", "torch", ".", "softmax", "(", "self", ".", "proj_rationale", "(", "phi", ")", ",", "axis", "=", "1", ")", "\n", "return", "rationale_out", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.paragraph_model_kgat.KernelGraphAttentionNetwork.forward": [[251, 267], ["paragraph_model_kgat.KernelGraphAttentionNetwork.edge_kernel", "paragraph_model_kgat.KernelGraphAttentionNetwork.node_kernel", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum"], "methods", ["home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.paragraph_model_kgat.KernelGraphAttentionNetwork.edge_kernel", "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.paragraph_model_kgat.KernelGraphAttentionNetwork.node_kernel"], ["", "def", "forward", "(", "self", ",", "claim_reps", ",", "sentence_token_reps", ",", "claim_token_mask", ",", "token_mask", ")", ":", "\n", "        ", "\"\"\"\n        claim_reps: (batch_size, n_token, bert_dim)\n        sentence_token_reps: (batch_size, n_sentence, n_token, bert_dim)\n        claim_token_mask: (batch_size, n_token)\n        token_mask: (batch_size, n_sentence, n_token)\n        stance_pred: (batch_size, label_size)\n        \"\"\"", "\n", "#claim_reps = F.normalize(claim_reps, p=2, dim=-1)", "\n", "#sentence_token_reps = F.normalize(sentence_token_reps, p=2, dim=-1)", "\n", "\n", "sentence_label_pred", "=", "self", ".", "edge_kernel", "(", "sentence_token_reps", ",", "token_mask", ")", "\n", "rationale_out", "=", "self", ".", "node_kernel", "(", "claim_reps", ",", "sentence_token_reps", ",", "token_mask", ")", "\n", "\n", "stance_pred", "=", "torch", ".", "sum", "(", "sentence_label_pred", "*", "rationale_out", ",", "axis", "=", "1", ")", "\n", "return", "stance_pred", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.paragraph_model_kgat.JointParagraphKGATClassifier.__init__": [[269, 294], ["torch.Module.__init__", "transformers.AutoModel.from_pretrained", "torch.CrossEntropyLoss", "torch.CrossEntropyLoss", "torch.CrossEntropyLoss", "torch.CrossEntropyLoss", "torch.CrossEntropyLoss", "torch.CrossEntropyLoss", "paragraph_model_kgat.DynamicRationale", "paragraph_model_kgat.ClassificationHead", "paragraph_model_kgat.KernelGraphAttentionNetwork", "paragraph_model_kgat.WordAttention"], "methods", ["home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.label_prediction.transformer_scifact.SciFactLabelPredictionDataset.__init__"], ["    ", "def", "__init__", "(", "self", ",", "bert_path", ",", "bert_dim", ",", "dropout", "=", "0.1", ",", "ignore_index", "=", "2", ",", "kernel", "=", "6", ")", ":", "\n", "        ", "super", "(", "JointParagraphKGATClassifier", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "stance_label_size", "=", "3", "\n", "self", ".", "rationale_label_size", "=", "2", "\n", "self", ".", "ignore_index", "=", "2", "\n", "self", ".", "kernel", "=", "kernel", "\n", "self", ".", "bert", "=", "AutoModel", ".", "from_pretrained", "(", "bert_path", ")", "\n", "self", ".", "stance_criterion", "=", "nn", ".", "CrossEntropyLoss", "(", ")", "\n", "self", ".", "rationale_criterion", "=", "nn", ".", "CrossEntropyLoss", "(", "ignore_index", "=", "2", ")", "\n", "self", ".", "dropout", "=", "dropout", "\n", "self", ".", "bert_dim", "=", "bert_dim", "\n", "#self.reduced_bert_dim = 128", "\n", "#self.rationale_selector =  SelectRationale(3)", "\n", "self", ".", "rationale_selector", "=", "DynamicRationale", "(", ")", "\n", "#self.kgat_linear = nn.Linear(self.bert_dim, self.reduced_bert_dim)", "\n", "self", ".", "rationale_linear", "=", "ClassificationHead", "(", "self", ".", "bert_dim", ",", "self", ".", "rationale_label_size", ",", "hidden_dropout_prob", "=", "dropout", ")", "\n", "self", ".", "kgat", "=", "KernelGraphAttentionNetwork", "(", "bert_dim", ",", "self", ".", "kernel", ")", "\n", "self", ".", "word_attention", "=", "WordAttention", "(", "bert_dim", ",", "bert_dim", ",", "dropout", "=", "dropout", ")", "\n", "self", ".", "extra_modules", "=", "[", "\n", "#self.kgat_linear,", "\n", "self", ".", "rationale_linear", ",", "\n", "self", ".", "stance_criterion", ",", "\n", "self", ".", "rationale_criterion", ",", "\n", "self", ".", "kgat", ",", "\n", "self", ".", "word_attention", "\n", "]", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.paragraph_model_kgat.JointParagraphKGATClassifier.reinitialize": [[296, 307], ["paragraph_model_kgat.KernelGraphAttentionNetwork"], "methods", ["None"], ["", "def", "reinitialize", "(", "self", ")", ":", "\n", "        ", "self", ".", "extra_modules", "=", "[", "]", "\n", "#self.kgat_linear = nn.Linear(self.bert_dim, self.reduced_bert_dim)", "\n", "self", ".", "kgat", "=", "KernelGraphAttentionNetwork", "(", "self", ".", "bert_dim", ",", "self", ".", "kernel", ")", "\n", "\n", "self", ".", "extra_modules", "=", "[", "\n", "#self.kgat_linear,", "\n", "self", ".", "stance_criterion", ",", "\n", "self", ".", "rationale_criterion", ",", "\n", "self", ".", "word_attention", ",", "\n", "self", ".", "kgat", "\n", "]", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.paragraph_model_kgat.JointParagraphKGATClassifier.forward": [[309, 346], ["paragraph_model_kgat.JointParagraphKGATClassifier.word_attention", "paragraph_model_kgat.JointParagraphKGATClassifier.rationale_linear", "bool", "paragraph_model_kgat.JointParagraphKGATClassifier.rationale_selector", "paragraph_model_kgat.JointParagraphKGATClassifier.kgat", "torch.argmax().detach().numpy().tolist", "torch.argmax().detach().numpy().tolist", "torch.argmax().detach().numpy().tolist", "torch.argmax().detach().numpy().tolist", "torch.argmax().detach().numpy().tolist", "torch.argmax().detach().numpy().tolist", "torch.argmax().detach().numpy().tolist", "torch.argmax().detach().numpy().tolist", "torch.argmax().detach().numpy().tolist", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "paragraph_model_kgat.JointParagraphKGATClassifier.bert", "paragraph_model_kgat.JointParagraphKGATClassifier.stance_criterion", "paragraph_model_kgat.JointParagraphKGATClassifier.rationale_criterion", "paragraph_model_kgat.JointParagraphKGATClassifier.cpu", "rationale_pred_paragraph[].detach().numpy().tolist", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "paragraph_model_kgat.JointParagraphKGATClassifier.view", "rationale_label.view", "torch.argmax().detach().numpy", "torch.argmax().detach().numpy", "torch.argmax().detach().numpy", "torch.argmax().detach().numpy", "torch.argmax().detach().numpy", "torch.argmax().detach().numpy", "torch.argmax().detach().numpy", "torch.argmax().detach().numpy", "torch.argmax().detach().numpy", "zip", "rationale_pred_paragraph[].detach().numpy", "sentence_mask.bool", "torch.argmax().detach", "torch.argmax().detach", "torch.argmax().detach", "torch.argmax().detach", "torch.argmax().detach", "torch.argmax().detach", "torch.argmax().detach", "torch.argmax().detach", "torch.argmax().detach", "rationale_pred_paragraph[].detach", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax().detach().numpy().tolist.cpu", "torch.argmax().detach().numpy().tolist.cpu", "torch.argmax().detach().numpy().tolist.cpu"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "encoded_dict", ",", "transformation_indices", ",", "stance_label", "=", "None", ",", "rationale_label", "=", "None", ",", "sample_p", "=", "1", ")", ":", "\n", "        ", "batch_indices", ",", "indices_by_batch", ",", "mask", "=", "transformation_indices", "# (batch_size, N_sep, N_token)", "\n", "bert_out", "=", "self", ".", "bert", "(", "**", "encoded_dict", ")", "[", "0", "]", "# (BATCH_SIZE, sequence_len, BERT_DIM)", "\n", "bert_tokens", "=", "bert_out", "[", "batch_indices", ",", "indices_by_batch", ",", ":", "]", "\n", "# bert_tokens: (batch_size, N_sep, N_token, BERT_dim)", "\n", "sentence_reps", ",", "sentence_mask", "=", "self", ".", "word_attention", "(", "bert_tokens", ",", "mask", ")", "\n", "# (Batch_size, N_sep, BERT_DIM), (Batch_size, N_sep)", "\n", "\n", "rationale_out", "=", "self", ".", "rationale_linear", "(", "sentence_reps", "[", ":", ",", "1", ":", ",", ":", "]", ")", "# (Batch_size, N_sep, 2) remove claim", "\n", "if", "bool", "(", "torch", ".", "rand", "(", "1", ")", "<", "sample_p", ")", ":", "# Choose sentence according to predicted rationale", "\n", "            ", "valid_sentences", "=", "rationale_out", "[", ":", ",", ":", ",", "1", "]", ">", "rationale_out", "[", ":", ",", ":", ",", "0", "]", "\n", "", "else", ":", "\n", "            ", "valid_sentences", "=", "rationale_label", "==", "1", "# Ground truth", "\n", "#kgat_token_reps = self.kgat_linear(bert_tokens.view(-1, bert_tokens.size(-1))).view(bert_tokens.size(0), bert_tokens.size(1), bert_tokens.size(2), -1)", "\n", "", "kgat_token_reps", "=", "bert_tokens", "\n", "top_reps", ",", "top_mask", "=", "self", ".", "rationale_selector", "(", "kgat_token_reps", ",", "mask", ",", "valid_sentences", ")", "\n", "\n", "claim_reps", "=", "kgat_token_reps", "[", ":", ",", "0", ",", ":", ",", ":", "]", "\n", "stance_out", "=", "self", ".", "kgat", "(", "claim_reps", ",", "top_reps", ",", "mask", "[", ":", ",", "0", ",", ":", "]", ",", "top_mask", ")", "# (Batch_size, 3)", "\n", "\n", "if", "stance_label", "is", "not", "None", ":", "\n", "            ", "stance_loss", "=", "self", ".", "stance_criterion", "(", "stance_out", ",", "stance_label", ")", "\n", "", "else", ":", "\n", "            ", "stance_loss", "=", "None", "\n", "", "if", "rationale_label", "is", "not", "None", ":", "\n", "            ", "rationale_loss", "=", "self", ".", "rationale_criterion", "(", "rationale_out", ".", "view", "(", "-", "1", ",", "self", ".", "rationale_label_size", ")", ",", "\n", "rationale_label", ".", "view", "(", "-", "1", ")", ")", "# ignore index 2", "\n", "", "else", ":", "\n", "            ", "rationale_loss", "=", "None", "\n", "\n", "", "stance_out", "=", "torch", ".", "argmax", "(", "stance_out", ".", "cpu", "(", ")", ",", "dim", "=", "-", "1", ")", ".", "detach", "(", ")", ".", "numpy", "(", ")", ".", "tolist", "(", ")", "\n", "\n", "rationale_pred", "=", "torch", ".", "argmax", "(", "rationale_out", ".", "cpu", "(", ")", ",", "dim", "=", "-", "1", ")", "# (Batch_size, N_sep)", "\n", "rationale_out", "=", "[", "rationale_pred_paragraph", "[", "mask", "[", "1", ":", "]", "]", ".", "detach", "(", ")", ".", "numpy", "(", ")", ".", "tolist", "(", ")", "for", "rationale_pred_paragraph", ",", "mask", "in", "zip", "(", "rationale_pred", ",", "sentence_mask", ".", "bool", "(", ")", ")", "]", "# Exclude claim mask", "\n", "\n", "\n", "return", "rationale_out", ",", "stance_out", ",", "rationale_loss", ",", "stance_loss", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.paragraph_model_kgat.DomainAdaptationJointParagraphKGATClassifier.__init__": [[348, 380], ["torch.Module.__init__", "transformers.AutoModel.from_pretrained", "torch.CrossEntropyLoss", "torch.CrossEntropyLoss", "torch.CrossEntropyLoss", "torch.CrossEntropyLoss", "torch.CrossEntropyLoss", "torch.CrossEntropyLoss", "paragraph_model_kgat.DynamicRationale", "paragraph_model_kgat.DynamicRationale", "paragraph_model_kgat.KernelGraphAttentionNetwork", "paragraph_model_kgat.KernelGraphAttentionNetwork", "paragraph_model_kgat.ClassificationHead", "paragraph_model_kgat.ClassificationHead", "paragraph_model_kgat.WordAttention"], "methods", ["home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.label_prediction.transformer_scifact.SciFactLabelPredictionDataset.__init__"], ["    ", "def", "__init__", "(", "self", ",", "bert_path", ",", "bert_dim", ",", "dropout", "=", "0.1", ",", "ignore_index", "=", "2", ",", "kernel", "=", "6", ")", ":", "\n", "        ", "super", "(", "DomainAdaptationJointParagraphKGATClassifier", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "stance_label_size", "=", "3", "\n", "self", ".", "rationale_label_size", "=", "2", "\n", "self", ".", "ignore_index", "=", "2", "\n", "self", ".", "kernel", "=", "kernel", "\n", "\n", "self", ".", "bert", "=", "AutoModel", ".", "from_pretrained", "(", "bert_path", ")", "\n", "self", ".", "stance_criterion", "=", "nn", ".", "CrossEntropyLoss", "(", ")", "\n", "self", ".", "rationale_criterion", "=", "nn", ".", "CrossEntropyLoss", "(", "ignore_index", "=", "2", ")", "\n", "\n", "self", ".", "rationale_selector_fever", "=", "DynamicRationale", "(", ")", "\n", "self", ".", "rationale_selector_scifact", "=", "DynamicRationale", "(", ")", "\n", "\n", "self", ".", "kgat_fever", "=", "KernelGraphAttentionNetwork", "(", "bert_dim", ",", "self", ".", "kernel", ")", "\n", "self", ".", "kgat_scifact", "=", "KernelGraphAttentionNetwork", "(", "bert_dim", ",", "self", ".", "kernel", ")", "\n", "\n", "self", ".", "rationale_linear_fever", "=", "ClassificationHead", "(", "bert_dim", ",", "self", ".", "rationale_label_size", ",", "hidden_dropout_prob", "=", "dropout", ")", "\n", "self", ".", "rationale_linear_scifact", "=", "ClassificationHead", "(", "bert_dim", ",", "self", ".", "rationale_label_size", ",", "hidden_dropout_prob", "=", "dropout", ")", "\n", "\n", "self", ".", "word_attention", "=", "WordAttention", "(", "bert_dim", ",", "bert_dim", ",", "dropout", "=", "dropout", ")", "\n", "\n", "self", ".", "extra_modules", "=", "[", "\n", "self", ".", "word_attention", ",", "\n", "self", ".", "rationale_selector_fever", ",", "\n", "self", ".", "rationale_selector_scifact", ",", "\n", "self", ".", "kgat_fever", ",", "\n", "self", ".", "kgat_scifact", ",", "\n", "self", ".", "rationale_linear_fever", ",", "\n", "self", ".", "rationale_linear_scifact", ",", "\n", "self", ".", "stance_criterion", ",", "\n", "self", ".", "rationale_criterion", "\n", "]", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.paragraph_model_kgat.DomainAdaptationJointParagraphKGATClassifier.forward": [[382, 458], ["paragraph_model_kgat.DomainAdaptationJointParagraphKGATClassifier.word_attention", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "paragraph_model_kgat.DomainAdaptationJointParagraphKGATClassifier.rationale_linear_fever", "paragraph_model_kgat.DomainAdaptationJointParagraphKGATClassifier.rationale_linear_scifact", "bool", "paragraph_model_kgat.DomainAdaptationJointParagraphKGATClassifier.rationale_selector_fever", "paragraph_model_kgat.DomainAdaptationJointParagraphKGATClassifier.rationale_selector_fever", "paragraph_model_kgat.DomainAdaptationJointParagraphKGATClassifier.kgat_fever", "paragraph_model_kgat.DomainAdaptationJointParagraphKGATClassifier.kgat_scifact", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.argmax().detach().numpy().tolist", "torch.argmax().detach().numpy().tolist", "torch.argmax().detach().numpy().tolist", "torch.argmax().detach().numpy().tolist", "torch.argmax().detach().numpy().tolist", "torch.argmax().detach().numpy().tolist", "torch.argmax().detach().numpy().tolist", "torch.argmax().detach().numpy().tolist", "torch.argmax().detach().numpy().tolist", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "paragraph_model_kgat.DomainAdaptationJointParagraphKGATClassifier.bert", "domain_indices.size", "paragraph_model_kgat.DomainAdaptationJointParagraphKGATClassifier.stance_criterion", "paragraph_model_kgat.DomainAdaptationJointParagraphKGATClassifier.rationale_criterion", "torch.cat.cpu", "torch.cat.cpu", "torch.cat.cpu", "rationale_pred_paragraph[].detach().numpy().tolist", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.cat.view", "torch.cat.view", "torch.cat.view", "rationale_label.view", "torch.argmax().detach().numpy", "torch.argmax().detach().numpy", "torch.argmax().detach().numpy", "torch.argmax().detach().numpy", "torch.argmax().detach().numpy", "torch.argmax().detach().numpy", "torch.argmax().detach().numpy", "torch.argmax().detach().numpy", "torch.argmax().detach().numpy", "zip", "rationale_pred_paragraph[].detach().numpy", "sentence_mask.bool", "torch.argmax().detach", "torch.argmax().detach", "torch.argmax().detach", "torch.argmax().detach", "torch.argmax().detach", "torch.argmax().detach", "torch.argmax().detach", "torch.argmax().detach", "torch.argmax().detach", "rationale_pred_paragraph[].detach", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax().detach().numpy().tolist.cpu", "torch.argmax().detach().numpy().tolist.cpu", "torch.argmax().detach().numpy().tolist.cpu"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "encoded_dict", ",", "transformation_indices", ",", "domain_indices", ",", "stance_label", "=", "None", ",", "rationale_label", "=", "None", ",", "sample_p", "=", "1", ")", ":", "\n", "        ", "batch_indices", ",", "indices_by_batch", ",", "mask", "=", "transformation_indices", "# (batch_size, N_sep, N_token)", "\n", "bert_out", "=", "self", ".", "bert", "(", "**", "encoded_dict", ")", "[", "0", "]", "# (BATCH_SIZE, sequence_len, BERT_DIM)", "\n", "bert_tokens", "=", "bert_out", "[", "batch_indices", ",", "indices_by_batch", ",", ":", "]", "\n", "# bert_tokens: (batch_size, N_sep, N_token, BERT_dim)", "\n", "sentence_reps", ",", "sentence_mask", "=", "self", ".", "word_attention", "(", "bert_tokens", ",", "mask", ")", "\n", "# (Batch_size, N_sep, BERT_DIM), (Batch_size, N_sep)", "\n", "\n", "# Prepare splitting", "\n", "indices", "=", "torch", ".", "arange", "(", "domain_indices", ".", "size", "(", "0", ")", ")", "\n", "select_fever", "=", "domain_indices", "==", "0", "\n", "select_scifact", "=", "domain_indices", "==", "1", "\n", "\n", "fever_indices", "=", "indices", "[", "select_fever", "]", "\n", "scifact_indices", "=", "indices", "[", "select_scifact", "]", "\n", "original_indices", "=", "torch", ".", "cat", "(", "[", "fever_indices", ",", "scifact_indices", "]", ")", "\n", "\n", "# Split sentence_reps and sentence_mask", "\n", "fever_bert_tokens", "=", "bert_tokens", "[", "select_fever", "]", "\n", "fever_mask", "=", "mask", "[", "select_fever", "]", "\n", "fever_sentence_reps", "=", "sentence_reps", "[", "select_fever", "]", "\n", "fever_sentence_mask", "=", "sentence_mask", "[", "select_fever", "]", "\n", "\n", "scifact_bert_tokens", "=", "bert_tokens", "[", "select_scifact", "]", "\n", "scifact_mask", "=", "mask", "[", "select_scifact", "]", "\n", "scifact_sentence_reps", "=", "sentence_reps", "[", "select_scifact", "]", "\n", "scifact_sentence_mask", "=", "sentence_mask", "[", "select_scifact", "]", "\n", "\n", "if", "rationale_label", "is", "not", "None", ":", "\n", "            ", "fever_rationale_label", "=", "rationale_label", "[", "select_fever", "]", "\n", "scifact_rationale_label", "=", "rationale_label", "[", "select_scifact", "]", "\n", "\n", "# Compute rationale_out", "\n", "", "fever_rationale_out", "=", "self", ".", "rationale_linear_fever", "(", "fever_sentence_reps", "[", ":", ",", "1", ":", ",", ":", "]", ")", "# (Batch_size, N_sep, 2)", "\n", "scifact_rationale_out", "=", "self", ".", "rationale_linear_scifact", "(", "scifact_sentence_reps", "[", ":", ",", "1", ":", ",", ":", "]", ")", "\n", "\n", "fever_att_scores", "=", "fever_rationale_out", "[", ":", ",", ":", ",", "1", "]", "# (BATCH_SIZE, N_sentence)", "\n", "scifact_att_scores", "=", "scifact_rationale_out", "[", ":", ",", ":", ",", "1", "]", "# (BATCH_SIZE, N_sentence)", "\n", "\n", "if", "bool", "(", "torch", ".", "rand", "(", "1", ")", "<", "sample_p", ")", ":", "# Choose sentence according to predicted rationale", "\n", "            ", "fever_valid_scores", "=", "fever_rationale_out", "[", ":", ",", ":", ",", "1", "]", ">", "fever_rationale_out", "[", ":", ",", ":", ",", "0", "]", "\n", "scifact_valid_scores", "=", "scifact_rationale_out", "[", ":", ",", ":", ",", "1", "]", ">", "scifact_rationale_out", "[", ":", ",", ":", ",", "0", "]", "\n", "", "else", ":", "\n", "            ", "fever_valid_scores", "=", "fever_rationale_label", "==", "1", "# Ground truth", "\n", "scifact_valid_scores", "=", "scifact_rationale_label", "==", "1", "\n", "\n", "", "fever_top_reps", ",", "fever_top_mask", "=", "self", ".", "rationale_selector_fever", "(", "fever_bert_tokens", ",", "fever_mask", ",", "fever_valid_scores", ")", "\n", "scifact_top_reps", ",", "scifact_top_mask", "=", "self", ".", "rationale_selector_fever", "(", "scifact_bert_tokens", ",", "scifact_mask", ",", "scifact_valid_scores", ")", "\n", "\n", "fever_stance_out", "=", "self", ".", "kgat_fever", "(", "fever_bert_tokens", "[", ":", ",", "0", ",", ":", ",", ":", "]", ",", "fever_top_reps", ",", "fever_mask", "[", ":", ",", "0", ",", ":", "]", ",", "fever_top_mask", ")", "# (Batch_size, 3)", "\n", "scifact_stance_out", "=", "self", ".", "kgat_scifact", "(", "scifact_bert_tokens", "[", ":", ",", "0", ",", ":", ",", ":", "]", ",", "scifact_top_reps", ",", "scifact_mask", "[", ":", ",", "0", ",", ":", "]", ",", "scifact_top_mask", ")", "# (Batch_size, 3)", "\n", "\n", "# Combine splitted ones to the original order", "\n", "stance_out", "=", "torch", ".", "cat", "(", "[", "fever_stance_out", ",", "scifact_stance_out", "]", ")", "\n", "stance_out", "=", "stance_out", "[", "original_indices", "]", "\n", "\n", "rationale_out", "=", "torch", ".", "cat", "(", "[", "fever_rationale_out", ",", "scifact_rationale_out", "]", ")", "\n", "rationale_out", "=", "rationale_out", "[", "original_indices", "]", "\n", "\n", "if", "stance_label", "is", "not", "None", ":", "\n", "            ", "stance_loss", "=", "self", ".", "stance_criterion", "(", "stance_out", ",", "stance_label", ")", "\n", "", "else", ":", "\n", "            ", "stance_loss", "=", "None", "\n", "", "if", "rationale_label", "is", "not", "None", ":", "\n", "            ", "rationale_loss", "=", "self", ".", "rationale_criterion", "(", "rationale_out", ".", "view", "(", "-", "1", ",", "self", ".", "rationale_label_size", ")", ",", "\n", "rationale_label", ".", "view", "(", "-", "1", ")", ")", "# ignore index 2", "\n", "", "else", ":", "\n", "            ", "rationale_loss", "=", "None", "\n", "\n", "", "stance_out", "=", "torch", ".", "argmax", "(", "stance_out", ".", "cpu", "(", ")", ",", "dim", "=", "-", "1", ")", ".", "detach", "(", ")", ".", "numpy", "(", ")", ".", "tolist", "(", ")", "\n", "\n", "rationale_pred", "=", "torch", ".", "argmax", "(", "rationale_out", ".", "cpu", "(", ")", ",", "dim", "=", "-", "1", ")", "# (Batch_size, N_sep)", "\n", "rationale_out", "=", "[", "rationale_pred_paragraph", "[", "mask", "[", "1", ":", "]", "]", ".", "detach", "(", ")", ".", "numpy", "(", ")", ".", "tolist", "(", ")", "for", "rationale_pred_paragraph", ",", "mask", "in", "zip", "(", "rationale_pred", ",", "sentence_mask", ".", "bool", "(", ")", ")", "]", "\n", "\n", "\n", "return", "rationale_out", ",", "stance_out", ",", "rationale_loss", ",", "stance_loss", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.paragraph_model_kgat.KGATClassifier.__init__": [[460, 475], ["torch.Module.__init__", "transformers.AutoModel.from_pretrained", "torch.CrossEntropyLoss", "torch.CrossEntropyLoss", "torch.CrossEntropyLoss", "paragraph_model_kgat.KernelGraphAttentionNetwork"], "methods", ["home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.label_prediction.transformer_scifact.SciFactLabelPredictionDataset.__init__"], ["    ", "def", "__init__", "(", "self", ",", "bert_path", ",", "bert_dim", ",", "dropout", "=", "0.1", ",", "kernel", "=", "5", ")", ":", "\n", "        ", "super", "(", "KGATClassifier", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "stance_label_size", "=", "3", "\n", "self", ".", "kernel", "=", "kernel", "\n", "self", ".", "bert", "=", "AutoModel", ".", "from_pretrained", "(", "bert_path", ")", "\n", "self", ".", "stance_criterion", "=", "nn", ".", "CrossEntropyLoss", "(", ")", "\n", "self", ".", "dropout", "=", "dropout", "\n", "self", ".", "bert_dim", "=", "bert_dim", "\n", "#self.reduced_bert_dim = 128", "\n", "#self.kgat_linear = nn.Linear(self.bert_dim, self.reduced_bert_dim)", "\n", "self", ".", "kgat", "=", "KernelGraphAttentionNetwork", "(", "1024", ",", "self", ".", "kernel", ")", "########", "\n", "self", ".", "extra_modules", "=", "[", "\n", "#self.kgat_linear,", "\n", "self", ".", "stance_criterion", ",", "\n", "self", ".", "kgat", "\n", "]", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.paragraph_model_kgat.KGATClassifier.forward": [[477, 497], ["paragraph_model_kgat.KGATClassifier.kgat", "torch.argmax().detach().numpy().tolist", "torch.argmax().detach().numpy().tolist", "torch.argmax().detach().numpy().tolist", "torch.argmax().detach().numpy().tolist", "torch.argmax().detach().numpy().tolist", "torch.argmax().detach().numpy().tolist", "torch.argmax().detach().numpy().tolist", "torch.argmax().detach().numpy().tolist", "torch.argmax().detach().numpy().tolist", "paragraph_model_kgat.KGATClassifier.bert", "paragraph_model_kgat.KGATClassifier.stance_criterion", "torch.argmax().detach().numpy", "torch.argmax().detach().numpy", "torch.argmax().detach().numpy", "torch.argmax().detach().numpy", "torch.argmax().detach().numpy", "torch.argmax().detach().numpy", "torch.argmax().detach().numpy", "torch.argmax().detach().numpy", "torch.argmax().detach().numpy", "torch.argmax().detach", "torch.argmax().detach", "torch.argmax().detach", "torch.argmax().detach", "torch.argmax().detach", "torch.argmax().detach", "torch.argmax().detach", "torch.argmax().detach", "torch.argmax().detach", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax().detach().numpy().tolist.cpu", "torch.argmax().detach().numpy().tolist.cpu", "torch.argmax().detach().numpy().tolist.cpu"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "encoded_dict", ",", "transformation_indices", ",", "stance_label", "=", "None", ")", ":", "\n", "        ", "batch_indices", ",", "indices_by_batch", ",", "mask", "=", "transformation_indices", "# (batch_size, N_sep, N_token)", "\n", "bert_out", "=", "self", ".", "bert", "(", "**", "encoded_dict", ")", "[", "0", "]", "# (BATCH_SIZE, sequence_len, BERT_DIM)", "\n", "bert_tokens", "=", "bert_out", "[", "batch_indices", ",", "indices_by_batch", ",", ":", "]", "\n", "# bert_tokens: (batch_size, N_sep, N_token, BERT_dim)", "\n", "\n", "kgat_token_reps", "=", "bert_tokens", "\n", "#kgat_token_reps = self.kgat_linear(bert_tokens.view(-1, bert_tokens.size(-1))).view(bert_tokens.size(0), bert_tokens.size(1), bert_tokens.size(2), -1)", "\n", "\n", "claim_reps", "=", "kgat_token_reps", "[", ":", ",", "0", ",", ":", ",", ":", "]", "\n", "stance_out", "=", "self", ".", "kgat", "(", "claim_reps", ",", "kgat_token_reps", "[", ":", ",", "1", ":", ",", ":", ",", ":", "]", ",", "mask", "[", ":", ",", "0", ",", ":", "]", ",", "mask", "[", ":", ",", "1", ":", ",", ":", "]", ")", "# (Batch_size, 3)", "\n", "\n", "if", "stance_label", "is", "not", "None", ":", "\n", "            ", "stance_loss", "=", "self", ".", "stance_criterion", "(", "stance_out", ",", "stance_label", ")", "\n", "", "else", ":", "\n", "            ", "stance_loss", "=", "None", "\n", "\n", "", "stance_out", "=", "torch", ".", "argmax", "(", "stance_out", ".", "cpu", "(", ")", ",", "dim", "=", "-", "1", ")", ".", "detach", "(", ")", ".", "numpy", "(", ")", ".", "tolist", "(", ")", "\n", "\n", "return", "stance_out", ",", "stance_loss", "", "", "", ""]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.domain_adaptation_joint_paragraph_predict.reset_random_seed": [[34, 38], ["numpy.random.seed", "random.seed", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed"], "function", ["None"], ["def", "reset_random_seed", "(", "seed", ")", ":", "\n", "    ", "np", ".", "random", ".", "seed", "(", "seed", ")", "\n", "random", ".", "seed", "(", "seed", ")", "\n", "torch", ".", "manual_seed", "(", "seed", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.domain_adaptation_joint_paragraph_predict.batch_rationale_label": [[39, 48], ["max", "enumerate", "torch.ones", "torch.ones", "torch.ones", "enumerate", "label_list.append", "label_matrix.long", "len", "len", "int", "int"], "function", ["None"], ["", "def", "batch_rationale_label", "(", "labels", ",", "padding_idx", "=", "2", ")", ":", "\n", "    ", "max_sent_len", "=", "max", "(", "[", "len", "(", "label", ")", "for", "label", "in", "labels", "]", ")", "\n", "label_matrix", "=", "torch", ".", "ones", "(", "len", "(", "labels", ")", ",", "max_sent_len", ")", "*", "padding_idx", "\n", "label_list", "=", "[", "]", "\n", "for", "i", ",", "label", "in", "enumerate", "(", "labels", ")", ":", "\n", "        ", "for", "j", ",", "evid", "in", "enumerate", "(", "label", ")", ":", "\n", "            ", "label_matrix", "[", "i", ",", "j", "]", "=", "int", "(", "evid", ")", "\n", "", "label_list", ".", "append", "(", "[", "int", "(", "evid", ")", "for", "evid", "in", "label", "]", ")", "\n", "", "return", "label_matrix", ".", "long", "(", ")", ",", "label_list", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.domain_adaptation_joint_paragraph_predict.predict": [[49, 70], ["model.eval", "torch.no_grad", "torch.no_grad", "torch.no_grad", "tqdm.tqdm", "torch.utils.data.DataLoader", "domain_adaptation_joint_paragraph_predict.encode", "batch[].to", "domain_adaptation_joint_paragraph_predict.token_idx_by_sentence", "model", "stance_preds.extend", "rationale_predictions.extend", "tensor.to", "tensor.to", "domain_adaptation_joint_paragraph_predict.predict.remove_dummy"], "function", ["home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.label_prediction.transformer_scifact.encode", "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.FEVER_stance_paragraph.token_idx_by_sentence", "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.src.utils.remove_dummy"], ["", "def", "predict", "(", "model", ",", "dataset", ")", ":", "\n", "    ", "model", ".", "eval", "(", ")", "\n", "rationale_predictions", "=", "[", "]", "\n", "stance_preds", "=", "[", "]", "\n", "\n", "def", "remove_dummy", "(", "rationale_out", ")", ":", "\n", "        ", "return", "[", "out", "[", "1", ":", "]", "for", "out", "in", "rationale_out", "]", "\n", "\n", "", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "for", "batch", "in", "tqdm", "(", "DataLoader", "(", "dataset", ",", "batch_size", "=", "args", ".", "batch_size", ",", "shuffle", "=", "False", ")", ")", ":", "\n", "            ", "encoded_dict", "=", "encode", "(", "tokenizer", ",", "batch", ")", "\n", "domain_indices", "=", "batch", "[", "\"dataset\"", "]", ".", "to", "(", "device", ")", "\n", "transformation_indices", "=", "token_idx_by_sentence", "(", "encoded_dict", "[", "\"input_ids\"", "]", ",", "\n", "tokenizer", ".", "sep_token_id", ",", "args", ".", "repfile", ")", "\n", "encoded_dict", "=", "{", "key", ":", "tensor", ".", "to", "(", "device", ")", "for", "key", ",", "tensor", "in", "encoded_dict", ".", "items", "(", ")", "}", "\n", "transformation_indices", "=", "[", "tensor", ".", "to", "(", "device", ")", "for", "tensor", "in", "transformation_indices", "]", "\n", "rationale_out", ",", "stance_out", ",", "_", ",", "_", "=", "model", "(", "encoded_dict", ",", "transformation_indices", ",", "domain_indices", ")", "\n", "stance_preds", ".", "extend", "(", "stance_out", ")", "\n", "rationale_predictions", ".", "extend", "(", "remove_dummy", "(", "rationale_out", ")", ")", "\n", "\n", "", "", "return", "rationale_predictions", ",", "stance_preds", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.domain_adaptation_joint_paragraph_predict.encode": [[71, 120], ["zip", "tokenizer.batch_encode_plus", "torch.cat", "torch.cat", "torch.cat", "encoded_dict[].size", "len", "numpy.sum", "numpy.argmax", "valid_paragraph.size", "all_paragraphs.append", "longest_first_truncation"], "function", ["home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.dataset.encode.longest_first_truncation"], ["", "def", "encode", "(", "tokenizer", ",", "batch", ",", "max_sent_len", "=", "512", ")", ":", "\n", "    ", "def", "truncate", "(", "input_ids", ",", "max_length", ",", "sep_token_id", ",", "pad_token_id", ")", ":", "\n", "        ", "def", "longest_first_truncation", "(", "sentences", ",", "objective", ")", ":", "\n", "            ", "sent_lens", "=", "[", "len", "(", "sent", ")", "for", "sent", "in", "sentences", "]", "\n", "while", "np", ".", "sum", "(", "sent_lens", ")", ">", "objective", ":", "\n", "                ", "max_position", "=", "np", ".", "argmax", "(", "sent_lens", ")", "\n", "sent_lens", "[", "max_position", "]", "-=", "1", "\n", "", "return", "[", "sentence", "[", ":", "length", "]", "for", "sentence", ",", "length", "in", "zip", "(", "sentences", ",", "sent_lens", ")", "]", "\n", "\n", "", "all_paragraphs", "=", "[", "]", "\n", "for", "paragraph", "in", "input_ids", ":", "\n", "            ", "valid_paragraph", "=", "paragraph", "[", "paragraph", "!=", "pad_token_id", "]", "\n", "if", "valid_paragraph", ".", "size", "(", "0", ")", "<=", "max_length", ":", "\n", "                ", "all_paragraphs", ".", "append", "(", "paragraph", "[", ":", "max_length", "]", ".", "unsqueeze", "(", "0", ")", ")", "\n", "", "else", ":", "\n", "                ", "sep_token_idx", "=", "np", ".", "arange", "(", "valid_paragraph", ".", "size", "(", "0", ")", ")", "[", "(", "valid_paragraph", "==", "sep_token_id", ")", ".", "numpy", "(", ")", "]", "\n", "idx_by_sentence", "=", "[", "]", "\n", "prev_idx", "=", "0", "\n", "for", "idx", "in", "sep_token_idx", ":", "\n", "                    ", "idx_by_sentence", ".", "append", "(", "paragraph", "[", "prev_idx", ":", "idx", "]", ")", "\n", "prev_idx", "=", "idx", "\n", "", "objective", "=", "max_length", "-", "1", "-", "len", "(", "idx_by_sentence", "[", "0", "]", ")", "# The last sep_token left out", "\n", "truncated_sentences", "=", "longest_first_truncation", "(", "idx_by_sentence", "[", "1", ":", "]", ",", "objective", ")", "\n", "truncated_paragraph", "=", "torch", ".", "cat", "(", "[", "idx_by_sentence", "[", "0", "]", "]", "+", "truncated_sentences", "+", "[", "torch", ".", "tensor", "(", "[", "sep_token_id", "]", ")", "]", ",", "0", ")", "\n", "all_paragraphs", ".", "append", "(", "truncated_paragraph", ".", "unsqueeze", "(", "0", ")", ")", "\n", "\n", "", "", "return", "torch", ".", "cat", "(", "all_paragraphs", ",", "0", ")", "\n", "\n", "", "inputs", "=", "zip", "(", "batch", "[", "\"claim\"", "]", ",", "batch", "[", "\"paragraph\"", "]", ")", "\n", "encoded_dict", "=", "tokenizer", ".", "batch_encode_plus", "(", "\n", "inputs", ",", "\n", "pad_to_max_length", "=", "True", ",", "add_special_tokens", "=", "True", ",", "\n", "return_tensors", "=", "'pt'", ")", "\n", "if", "encoded_dict", "[", "'input_ids'", "]", ".", "size", "(", "1", ")", ">", "max_sent_len", ":", "\n", "        ", "if", "'token_type_ids'", "in", "encoded_dict", ":", "\n", "            ", "encoded_dict", "=", "{", "\n", "\"input_ids\"", ":", "truncate", "(", "encoded_dict", "[", "'input_ids'", "]", ",", "max_sent_len", ",", "\n", "tokenizer", ".", "sep_token_id", ",", "tokenizer", ".", "pad_token_id", ")", ",", "\n", "'token_type_ids'", ":", "encoded_dict", "[", "'token_type_ids'", "]", "[", ":", ",", ":", "max_sent_len", "]", ",", "\n", "'attention_mask'", ":", "encoded_dict", "[", "'attention_mask'", "]", "[", ":", ",", ":", "max_sent_len", "]", "\n", "}", "\n", "", "else", ":", "\n", "            ", "encoded_dict", "=", "{", "\n", "\"input_ids\"", ":", "truncate", "(", "encoded_dict", "[", "'input_ids'", "]", ",", "max_sent_len", ",", "\n", "tokenizer", ".", "sep_token_id", ",", "tokenizer", ".", "pad_token_id", ")", ",", "\n", "'attention_mask'", ":", "encoded_dict", "[", "'attention_mask'", "]", "[", ":", ",", ":", "max_sent_len", "]", "\n", "}", "\n", "\n", "", "", "return", "encoded_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.domain_adaptation_joint_paragraph_predict.token_idx_by_sentence": [[122, 150], ["torch.sum().numpy().tolist", "torch.sum().numpy().tolist", "torch.sum().numpy().tolist", "torch.arange().unsqueeze().expand", "torch.arange().unsqueeze().expand", "torch.arange().unsqueeze().expand", "torch.split", "torch.split", "torch.split", "torch.utils.rnn.pad_sequence", "torch.split", "torch.split", "torch.split", "torch.utils.rnn.pad_sequence", "torch.arange().unsqueeze().unsqueeze().expand", "torch.arange().unsqueeze().unsqueeze().expand", "torch.arange().unsqueeze().unsqueeze().expand", "sep_tokens.size", "torch.sum().numpy().tolist.append", "all_word_indices.extend", "nn.utils.rnn.pad_sequence.size", "nn.utils.rnn.pad_sequence.size", "torch.arange().unsqueeze().unsqueeze().expand.long", "nn.utils.rnn.pad_sequence.long", "mask.long", "torch.sum().numpy", "torch.sum().numpy", "torch.sum().numpy", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange", "torch.arange", "torch.arange", "len", "torch.arange().unsqueeze().unsqueeze", "torch.arange().unsqueeze().unsqueeze", "torch.arange().unsqueeze().unsqueeze", "range", "torch.sum", "torch.sum", "torch.sum", "torch.arange", "torch.arange", "torch.arange", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "sep_tokens.size", "paragraph.size", "torch.arange", "torch.arange", "torch.arange", "sep_tokens.size"], "function", ["None"], ["", "def", "token_idx_by_sentence", "(", "input_ids", ",", "sep_token_id", ",", "model_name", ")", ":", "\n", "    ", "\"\"\"\n    Compute the token indices matrix of the BERT output.\n    input_ids: (batch_size, paragraph_len)\n    batch_indices, indices_by_batch, mask: (batch_size, N_sentence, N_token)\n    bert_out: (batch_size, paragraph_len,BERT_dim)\n    bert_out[batch_indices,indices_by_batch,:]: (batch_size, N_sentence, N_token, BERT_dim)\n    \"\"\"", "\n", "padding_idx", "=", "-", "1", "\n", "sep_tokens", "=", "(", "input_ids", "==", "sep_token_id", ")", ".", "bool", "(", ")", "\n", "paragraph_lens", "=", "torch", ".", "sum", "(", "sep_tokens", ",", "1", ")", ".", "numpy", "(", ")", ".", "tolist", "(", ")", "\n", "indices", "=", "torch", ".", "arange", "(", "sep_tokens", ".", "size", "(", "-", "1", ")", ")", ".", "unsqueeze", "(", "0", ")", ".", "expand", "(", "sep_tokens", ".", "size", "(", "0", ")", ",", "-", "1", ")", "\n", "sep_indices", "=", "torch", ".", "split", "(", "indices", "[", "sep_tokens", "]", ",", "paragraph_lens", ")", "\n", "paragraph_lens", "=", "[", "]", "\n", "all_word_indices", "=", "[", "]", "\n", "for", "paragraph", "in", "sep_indices", ":", "\n", "        ", "if", "\"roberta\"", "in", "model_name", ":", "\n", "            ", "paragraph", "=", "paragraph", "[", "1", ":", "]", "\n", "", "word_indices", "=", "[", "torch", ".", "arange", "(", "paragraph", "[", "i", "]", "+", "1", ",", "paragraph", "[", "i", "+", "1", "]", "+", "1", ")", "for", "i", "in", "range", "(", "paragraph", ".", "size", "(", "0", ")", "-", "1", ")", "]", "\n", "paragraph_lens", ".", "append", "(", "len", "(", "word_indices", ")", ")", "\n", "all_word_indices", ".", "extend", "(", "word_indices", ")", "\n", "", "indices_by_sentence", "=", "nn", ".", "utils", ".", "rnn", ".", "pad_sequence", "(", "all_word_indices", ",", "batch_first", "=", "True", ",", "padding_value", "=", "padding_idx", ")", "\n", "indices_by_sentence_split", "=", "torch", ".", "split", "(", "indices_by_sentence", ",", "paragraph_lens", ")", "\n", "indices_by_batch", "=", "nn", ".", "utils", ".", "rnn", ".", "pad_sequence", "(", "indices_by_sentence_split", ",", "batch_first", "=", "True", ",", "padding_value", "=", "padding_idx", ")", "\n", "batch_indices", "=", "torch", ".", "arange", "(", "sep_tokens", ".", "size", "(", "0", ")", ")", ".", "unsqueeze", "(", "-", "1", ")", ".", "unsqueeze", "(", "-", "1", ")", ".", "expand", "(", "-", "1", ",", "indices_by_batch", ".", "size", "(", "1", ")", ",", "indices_by_batch", ".", "size", "(", "-", "1", ")", ")", "\n", "mask", "=", "(", "indices_by_batch", ">=", "0", ")", "\n", "\n", "return", "batch_indices", ".", "long", "(", ")", ",", "indices_by_batch", ".", "long", "(", ")", ",", "mask", ".", "long", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.domain_adaptation_joint_paragraph_predict.post_process_stance": [[151, 159], ["zip", "len", "len", "rationale_pred[].items", "len"], "function", ["None"], ["", "def", "post_process_stance", "(", "rationale_json", ",", "stance_json", ")", ":", "\n", "    ", "assert", "(", "len", "(", "rationale_json", ")", "==", "len", "(", "stance_json", ")", ")", "\n", "for", "stance_pred", ",", "rationale_pred", "in", "zip", "(", "stance_json", ",", "rationale_json", ")", ":", "\n", "        ", "assert", "(", "stance_pred", "[", "\"claim_id\"", "]", "==", "rationale_pred", "[", "\"claim_id\"", "]", ")", "\n", "for", "doc_id", ",", "pred", "in", "rationale_pred", "[", "\"evidence\"", "]", ".", "items", "(", ")", ":", "\n", "            ", "if", "len", "(", "pred", ")", "==", "0", ":", "\n", "                ", "stance_pred", "[", "\"labels\"", "]", "[", "doc_id", "]", "[", "\"label\"", "]", "=", "\"NOT_ENOUGH_INFO\"", "\n", "", "", "", "return", "stance_json", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.domain_adaptation_joint_paragraph_fine_tune.schedule_sample_p": [[33, 35], ["numpy.sin"], "function", ["None"], ["def", "schedule_sample_p", "(", "epoch", ",", "total", ")", ":", "\n", "    ", "return", "np", ".", "sin", "(", "0.5", "*", "np", ".", "pi", "*", "epoch", "/", "(", "total", "-", "1", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.domain_adaptation_joint_paragraph_fine_tune.reset_random_seed": [[36, 40], ["numpy.random.seed", "random.seed", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed"], "function", ["None"], ["", "def", "reset_random_seed", "(", "seed", ")", ":", "\n", "    ", "np", ".", "random", ".", "seed", "(", "seed", ")", "\n", "random", ".", "seed", "(", "seed", ")", "\n", "torch", ".", "manual_seed", "(", "seed", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.domain_adaptation_joint_paragraph_fine_tune.batch_rationale_label": [[41, 50], ["max", "enumerate", "torch.ones", "torch.ones", "torch.ones", "enumerate", "label_list.append", "label_matrix.long", "len", "len", "int", "int"], "function", ["None"], ["", "def", "batch_rationale_label", "(", "labels", ",", "padding_idx", "=", "2", ")", ":", "\n", "    ", "max_sent_len", "=", "max", "(", "[", "len", "(", "label", ")", "for", "label", "in", "labels", "]", ")", "\n", "label_matrix", "=", "torch", ".", "ones", "(", "len", "(", "labels", ")", ",", "max_sent_len", ")", "*", "padding_idx", "\n", "label_list", "=", "[", "]", "\n", "for", "i", ",", "label", "in", "enumerate", "(", "labels", ")", ":", "\n", "        ", "for", "j", ",", "evid", "in", "enumerate", "(", "label", ")", ":", "\n", "            ", "label_matrix", "[", "i", ",", "j", "]", "=", "int", "(", "evid", ")", "\n", "", "label_list", ".", "append", "(", "[", "int", "(", "evid", ")", "for", "evid", "in", "label", "]", ")", "\n", "", "return", "label_matrix", ".", "long", "(", ")", ",", "label_list", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.domain_adaptation_joint_paragraph_fine_tune.predict": [[51, 72], ["model.eval", "torch.no_grad", "torch.no_grad", "torch.no_grad", "tqdm.tqdm", "torch.utils.data.DataLoader", "domain_adaptation_joint_paragraph_fine_tune.encode", "batch[].to", "domain_adaptation_joint_paragraph_fine_tune.token_idx_by_sentence", "model", "stance_preds.extend", "rationale_predictions.extend", "tensor.to", "tensor.to", "domain_adaptation_joint_paragraph_fine_tune.predict.remove_dummy"], "function", ["home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.label_prediction.transformer_scifact.encode", "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.FEVER_stance_paragraph.token_idx_by_sentence", "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.src.utils.remove_dummy"], ["", "def", "predict", "(", "model", ",", "dataset", ")", ":", "\n", "    ", "model", ".", "eval", "(", ")", "\n", "rationale_predictions", "=", "[", "]", "\n", "stance_preds", "=", "[", "]", "\n", "\n", "def", "remove_dummy", "(", "rationale_out", ")", ":", "\n", "        ", "return", "[", "out", "[", "1", ":", "]", "for", "out", "in", "rationale_out", "]", "\n", "\n", "", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "for", "batch", "in", "tqdm", "(", "DataLoader", "(", "dataset", ",", "batch_size", "=", "args", ".", "batch_size", ",", "shuffle", "=", "False", ")", ")", ":", "\n", "            ", "encoded_dict", "=", "encode", "(", "tokenizer", ",", "batch", ")", "\n", "domain_indices", "=", "batch", "[", "\"dataset\"", "]", ".", "to", "(", "device", ")", "\n", "transformation_indices", "=", "token_idx_by_sentence", "(", "encoded_dict", "[", "\"input_ids\"", "]", ",", "\n", "tokenizer", ".", "sep_token_id", ",", "args", ".", "repfile", ")", "\n", "encoded_dict", "=", "{", "key", ":", "tensor", ".", "to", "(", "device", ")", "for", "key", ",", "tensor", "in", "encoded_dict", ".", "items", "(", ")", "}", "\n", "transformation_indices", "=", "[", "tensor", ".", "to", "(", "device", ")", "for", "tensor", "in", "transformation_indices", "]", "\n", "rationale_out", ",", "stance_out", ",", "_", ",", "_", "=", "model", "(", "encoded_dict", ",", "transformation_indices", ",", "domain_indices", ")", "\n", "stance_preds", ".", "extend", "(", "stance_out", ")", "\n", "rationale_predictions", ".", "extend", "(", "remove_dummy", "(", "rationale_out", ")", ")", "\n", "\n", "", "", "return", "rationale_predictions", ",", "stance_preds", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.domain_adaptation_joint_paragraph_fine_tune.evaluation": [[73, 109], ["model.eval", "sklearn.metrics.f1_score", "sklearn.metrics.precision_score", "sklearn.metrics.recall_score", "sklearn.metrics.f1_score", "sklearn.metrics.precision_score", "sklearn.metrics.recall_score", "torch.no_grad", "torch.no_grad", "torch.no_grad", "tqdm.tqdm", "util.flatten", "util.flatten", "util.flatten", "util.flatten", "util.flatten", "util.flatten", "torch.utils.data.DataLoader", "domain_adaptation_joint_paragraph_fine_tune.encode", "domain_adaptation_joint_paragraph_fine_tune.token_idx_by_sentence", "batch[].to", "batch[].to", "domain_adaptation_joint_paragraph_fine_tune.batch_rationale_label", "model", "stance_preds.extend", "stance_labels.extend", "rationale_predictions.extend", "rationale_labels.extend", "tensor.to", "tensor.to", "batch[].to.cpu().numpy().tolist", "domain_adaptation_joint_paragraph_fine_tune.predict.remove_dummy"], "function", ["home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.util.flatten", "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.util.flatten", "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.util.flatten", "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.util.flatten", "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.util.flatten", "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.util.flatten", "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.label_prediction.transformer_scifact.encode", "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.FEVER_stance_paragraph.token_idx_by_sentence", "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.domain_adaptation_joint_paragraph_fine_tune.batch_rationale_label", "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.src.utils.remove_dummy"], ["", "def", "evaluation", "(", "model", ",", "dataset", ")", ":", "\n", "    ", "model", ".", "eval", "(", ")", "\n", "rationale_predictions", "=", "[", "]", "\n", "rationale_labels", "=", "[", "]", "\n", "stance_preds", "=", "[", "]", "\n", "stance_labels", "=", "[", "]", "\n", "\n", "def", "remove_dummy", "(", "rationale_out", ")", ":", "\n", "        ", "return", "[", "out", "[", "1", ":", "]", "for", "out", "in", "rationale_out", "]", "\n", "\n", "", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "for", "batch", "in", "tqdm", "(", "DataLoader", "(", "dataset", ",", "batch_size", "=", "args", ".", "batch_size", ",", "shuffle", "=", "False", ")", ")", ":", "\n", "            ", "encoded_dict", "=", "encode", "(", "tokenizer", ",", "batch", ")", "\n", "transformation_indices", "=", "token_idx_by_sentence", "(", "encoded_dict", "[", "\"input_ids\"", "]", ",", "\n", "tokenizer", ".", "sep_token_id", ",", "args", ".", "repfile", ")", "\n", "encoded_dict", "=", "{", "key", ":", "tensor", ".", "to", "(", "device", ")", "for", "key", ",", "tensor", "in", "encoded_dict", ".", "items", "(", ")", "}", "\n", "transformation_indices", "=", "[", "tensor", ".", "to", "(", "device", ")", "for", "tensor", "in", "transformation_indices", "]", "\n", "stance_label", "=", "batch", "[", "\"stance\"", "]", ".", "to", "(", "device", ")", "\n", "domain_indices", "=", "batch", "[", "\"dataset\"", "]", ".", "to", "(", "device", ")", "\n", "padded_rationale_label", ",", "rationale_label", "=", "batch_rationale_label", "(", "batch", "[", "\"label\"", "]", ",", "padding_idx", "=", "2", ")", "\n", "rationale_out", ",", "stance_out", ",", "rationale_loss", ",", "stance_loss", "=", "model", "(", "encoded_dict", ",", "transformation_indices", ",", "domain_indices", ",", "stance_label", "=", "stance_label", ",", "\n", "rationale_label", "=", "padded_rationale_label", ".", "to", "(", "device", ")", ")", "\n", "stance_preds", ".", "extend", "(", "stance_out", ")", "\n", "stance_labels", ".", "extend", "(", "stance_label", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "tolist", "(", ")", ")", "\n", "\n", "rationale_predictions", ".", "extend", "(", "remove_dummy", "(", "rationale_out", ")", ")", "\n", "rationale_labels", ".", "extend", "(", "remove_dummy", "(", "rationale_label", ")", ")", "\n", "\n", "", "", "stance_f1", "=", "f1_score", "(", "stance_labels", ",", "stance_preds", ",", "average", "=", "\"micro\"", ",", "labels", "=", "[", "1", ",", "2", "]", ")", "\n", "stance_precision", "=", "precision_score", "(", "stance_labels", ",", "stance_preds", ",", "average", "=", "\"micro\"", ",", "labels", "=", "[", "1", ",", "2", "]", ")", "\n", "stance_recall", "=", "recall_score", "(", "stance_labels", ",", "stance_preds", ",", "average", "=", "\"micro\"", ",", "labels", "=", "[", "1", ",", "2", "]", ")", "\n", "rationale_f1", "=", "f1_score", "(", "flatten", "(", "rationale_labels", ")", ",", "flatten", "(", "rationale_predictions", ")", ")", "\n", "rationale_precision", "=", "precision_score", "(", "flatten", "(", "rationale_labels", ")", ",", "flatten", "(", "rationale_predictions", ")", ")", "\n", "rationale_recall", "=", "recall_score", "(", "flatten", "(", "rationale_labels", ")", ",", "flatten", "(", "rationale_predictions", ")", ")", "\n", "return", "stance_f1", ",", "stance_precision", ",", "stance_recall", ",", "rationale_f1", ",", "rationale_precision", ",", "rationale_recall", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.domain_adaptation_joint_paragraph_fine_tune.encode": [[110, 159], ["zip", "tokenizer.batch_encode_plus", "torch.cat", "torch.cat", "torch.cat", "encoded_dict[].size", "len", "numpy.sum", "numpy.argmax", "valid_paragraph.size", "all_paragraphs.append", "longest_first_truncation"], "function", ["home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.dataset.encode.longest_first_truncation"], ["", "def", "encode", "(", "tokenizer", ",", "batch", ",", "max_sent_len", "=", "512", ")", ":", "\n", "    ", "def", "truncate", "(", "input_ids", ",", "max_length", ",", "sep_token_id", ",", "pad_token_id", ")", ":", "\n", "        ", "def", "longest_first_truncation", "(", "sentences", ",", "objective", ")", ":", "\n", "            ", "sent_lens", "=", "[", "len", "(", "sent", ")", "for", "sent", "in", "sentences", "]", "\n", "while", "np", ".", "sum", "(", "sent_lens", ")", ">", "objective", ":", "\n", "                ", "max_position", "=", "np", ".", "argmax", "(", "sent_lens", ")", "\n", "sent_lens", "[", "max_position", "]", "-=", "1", "\n", "", "return", "[", "sentence", "[", ":", "length", "]", "for", "sentence", ",", "length", "in", "zip", "(", "sentences", ",", "sent_lens", ")", "]", "\n", "\n", "", "all_paragraphs", "=", "[", "]", "\n", "for", "paragraph", "in", "input_ids", ":", "\n", "            ", "valid_paragraph", "=", "paragraph", "[", "paragraph", "!=", "pad_token_id", "]", "\n", "if", "valid_paragraph", ".", "size", "(", "0", ")", "<=", "max_length", ":", "\n", "                ", "all_paragraphs", ".", "append", "(", "paragraph", "[", ":", "max_length", "]", ".", "unsqueeze", "(", "0", ")", ")", "\n", "", "else", ":", "\n", "                ", "sep_token_idx", "=", "np", ".", "arange", "(", "valid_paragraph", ".", "size", "(", "0", ")", ")", "[", "(", "valid_paragraph", "==", "sep_token_id", ")", ".", "numpy", "(", ")", "]", "\n", "idx_by_sentence", "=", "[", "]", "\n", "prev_idx", "=", "0", "\n", "for", "idx", "in", "sep_token_idx", ":", "\n", "                    ", "idx_by_sentence", ".", "append", "(", "paragraph", "[", "prev_idx", ":", "idx", "]", ")", "\n", "prev_idx", "=", "idx", "\n", "", "objective", "=", "max_length", "-", "1", "-", "len", "(", "idx_by_sentence", "[", "0", "]", ")", "# The last sep_token left out", "\n", "truncated_sentences", "=", "longest_first_truncation", "(", "idx_by_sentence", "[", "1", ":", "]", ",", "objective", ")", "\n", "truncated_paragraph", "=", "torch", ".", "cat", "(", "[", "idx_by_sentence", "[", "0", "]", "]", "+", "truncated_sentences", "+", "[", "torch", ".", "tensor", "(", "[", "sep_token_id", "]", ")", "]", ",", "0", ")", "\n", "all_paragraphs", ".", "append", "(", "truncated_paragraph", ".", "unsqueeze", "(", "0", ")", ")", "\n", "\n", "", "", "return", "torch", ".", "cat", "(", "all_paragraphs", ",", "0", ")", "\n", "\n", "", "inputs", "=", "zip", "(", "batch", "[", "\"claim\"", "]", ",", "batch", "[", "\"paragraph\"", "]", ")", "\n", "encoded_dict", "=", "tokenizer", ".", "batch_encode_plus", "(", "\n", "inputs", ",", "\n", "pad_to_max_length", "=", "True", ",", "add_special_tokens", "=", "True", ",", "\n", "return_tensors", "=", "'pt'", ")", "\n", "if", "encoded_dict", "[", "'input_ids'", "]", ".", "size", "(", "1", ")", ">", "max_sent_len", ":", "\n", "        ", "if", "'token_type_ids'", "in", "encoded_dict", ":", "\n", "            ", "encoded_dict", "=", "{", "\n", "\"input_ids\"", ":", "truncate", "(", "encoded_dict", "[", "'input_ids'", "]", ",", "max_sent_len", ",", "\n", "tokenizer", ".", "sep_token_id", ",", "tokenizer", ".", "pad_token_id", ")", ",", "\n", "'token_type_ids'", ":", "encoded_dict", "[", "'token_type_ids'", "]", "[", ":", ",", ":", "max_sent_len", "]", ",", "\n", "'attention_mask'", ":", "encoded_dict", "[", "'attention_mask'", "]", "[", ":", ",", ":", "max_sent_len", "]", "\n", "}", "\n", "", "else", ":", "\n", "            ", "encoded_dict", "=", "{", "\n", "\"input_ids\"", ":", "truncate", "(", "encoded_dict", "[", "'input_ids'", "]", ",", "max_sent_len", ",", "\n", "tokenizer", ".", "sep_token_id", ",", "tokenizer", ".", "pad_token_id", ")", ",", "\n", "'attention_mask'", ":", "encoded_dict", "[", "'attention_mask'", "]", "[", ":", ",", ":", "max_sent_len", "]", "\n", "}", "\n", "\n", "", "", "return", "encoded_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.domain_adaptation_joint_paragraph_fine_tune.token_idx_by_sentence": [[161, 189], ["torch.sum().numpy().tolist", "torch.sum().numpy().tolist", "torch.sum().numpy().tolist", "torch.arange().unsqueeze().expand", "torch.arange().unsqueeze().expand", "torch.arange().unsqueeze().expand", "torch.split", "torch.split", "torch.split", "torch.utils.rnn.pad_sequence", "torch.split", "torch.split", "torch.split", "torch.utils.rnn.pad_sequence", "torch.arange().unsqueeze().unsqueeze().expand", "torch.arange().unsqueeze().unsqueeze().expand", "torch.arange().unsqueeze().unsqueeze().expand", "sep_tokens.size", "torch.sum().numpy().tolist.append", "all_word_indices.extend", "nn.utils.rnn.pad_sequence.size", "nn.utils.rnn.pad_sequence.size", "torch.arange().unsqueeze().unsqueeze().expand.long", "nn.utils.rnn.pad_sequence.long", "mask.long", "torch.sum().numpy", "torch.sum().numpy", "torch.sum().numpy", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange", "torch.arange", "torch.arange", "len", "torch.arange().unsqueeze().unsqueeze", "torch.arange().unsqueeze().unsqueeze", "torch.arange().unsqueeze().unsqueeze", "range", "torch.sum", "torch.sum", "torch.sum", "torch.arange", "torch.arange", "torch.arange", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "sep_tokens.size", "paragraph.size", "torch.arange", "torch.arange", "torch.arange", "sep_tokens.size"], "function", ["None"], ["", "def", "token_idx_by_sentence", "(", "input_ids", ",", "sep_token_id", ",", "model_name", ")", ":", "\n", "    ", "\"\"\"\n    Compute the token indices matrix of the BERT output.\n    input_ids: (batch_size, paragraph_len)\n    batch_indices, indices_by_batch, mask: (batch_size, N_sentence, N_token)\n    bert_out: (batch_size, paragraph_len,BERT_dim)\n    bert_out[batch_indices,indices_by_batch,:]: (batch_size, N_sentence, N_token, BERT_dim)\n    \"\"\"", "\n", "padding_idx", "=", "-", "1", "\n", "sep_tokens", "=", "(", "input_ids", "==", "sep_token_id", ")", ".", "bool", "(", ")", "\n", "paragraph_lens", "=", "torch", ".", "sum", "(", "sep_tokens", ",", "1", ")", ".", "numpy", "(", ")", ".", "tolist", "(", ")", "\n", "indices", "=", "torch", ".", "arange", "(", "sep_tokens", ".", "size", "(", "-", "1", ")", ")", ".", "unsqueeze", "(", "0", ")", ".", "expand", "(", "sep_tokens", ".", "size", "(", "0", ")", ",", "-", "1", ")", "\n", "sep_indices", "=", "torch", ".", "split", "(", "indices", "[", "sep_tokens", "]", ",", "paragraph_lens", ")", "\n", "paragraph_lens", "=", "[", "]", "\n", "all_word_indices", "=", "[", "]", "\n", "for", "paragraph", "in", "sep_indices", ":", "\n", "        ", "if", "\"roberta\"", "in", "model_name", ":", "\n", "            ", "paragraph", "=", "paragraph", "[", "1", ":", "]", "\n", "", "word_indices", "=", "[", "torch", ".", "arange", "(", "paragraph", "[", "i", "]", "+", "1", ",", "paragraph", "[", "i", "+", "1", "]", "+", "1", ")", "for", "i", "in", "range", "(", "paragraph", ".", "size", "(", "0", ")", "-", "1", ")", "]", "\n", "paragraph_lens", ".", "append", "(", "len", "(", "word_indices", ")", ")", "\n", "all_word_indices", ".", "extend", "(", "word_indices", ")", "\n", "", "indices_by_sentence", "=", "nn", ".", "utils", ".", "rnn", ".", "pad_sequence", "(", "all_word_indices", ",", "batch_first", "=", "True", ",", "padding_value", "=", "padding_idx", ")", "\n", "indices_by_sentence_split", "=", "torch", ".", "split", "(", "indices_by_sentence", ",", "paragraph_lens", ")", "\n", "indices_by_batch", "=", "nn", ".", "utils", ".", "rnn", ".", "pad_sequence", "(", "indices_by_sentence_split", ",", "batch_first", "=", "True", ",", "padding_value", "=", "padding_idx", ")", "\n", "batch_indices", "=", "torch", ".", "arange", "(", "sep_tokens", ".", "size", "(", "0", ")", ")", ".", "unsqueeze", "(", "-", "1", ")", ".", "unsqueeze", "(", "-", "1", ")", ".", "expand", "(", "-", "1", ",", "indices_by_batch", ".", "size", "(", "1", ")", ",", "indices_by_batch", ".", "size", "(", "-", "1", ")", ")", "\n", "mask", "=", "(", "indices_by_batch", ">=", "0", ")", "\n", "\n", "return", "batch_indices", ".", "long", "(", ")", ",", "indices_by_batch", ".", "long", "(", ")", ",", "mask", ".", "long", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.domain_adaptation_joint_paragraph_fine_tune.post_process_stance": [[190, 198], ["zip", "len", "len", "rationale_pred[].items", "len"], "function", ["None"], ["", "def", "post_process_stance", "(", "rationale_json", ",", "stance_json", ")", ":", "\n", "    ", "assert", "(", "len", "(", "rationale_json", ")", "==", "len", "(", "stance_json", ")", ")", "\n", "for", "stance_pred", ",", "rationale_pred", "in", "zip", "(", "stance_json", ",", "rationale_json", ")", ":", "\n", "        ", "assert", "(", "stance_pred", "[", "\"claim_id\"", "]", "==", "rationale_pred", "[", "\"claim_id\"", "]", ")", "\n", "for", "doc_id", ",", "pred", "in", "rationale_pred", "[", "\"evidence\"", "]", ".", "items", "(", ")", ":", "\n", "            ", "if", "len", "(", "pred", ")", "==", "0", ":", "\n", "                ", "stance_pred", "[", "\"labels\"", "]", "[", "doc_id", "]", "[", "\"label\"", "]", "=", "\"NOT_ENOUGH_INFO\"", "\n", "", "", "", "return", "stance_json", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.scifact_stance_paragraph.reset_random_seed": [[25, 29], ["numpy.random.seed", "random.seed", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed"], "function", ["None"], ["def", "reset_random_seed", "(", "seed", ")", ":", "\n", "    ", "np", ".", "random", ".", "seed", "(", "seed", ")", "\n", "random", ".", "seed", "(", "seed", ")", "\n", "torch", ".", "manual_seed", "(", "seed", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.scifact_stance_paragraph.predict": [[30, 44], ["model.eval", "torch.no_grad", "torch.no_grad", "torch.no_grad", "tqdm.tqdm", "torch.utils.data.DataLoader", "scifact_stance_paragraph.encode", "scifact_stance_paragraph.token_idx_by_sentence", "model", "stance_preds.extend", "tensor.to", "tensor.to", "encode.items"], "function", ["home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.label_prediction.transformer_scifact.encode", "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.FEVER_stance_paragraph.token_idx_by_sentence"], ["", "def", "predict", "(", "model", ",", "dataset", ")", ":", "\n", "    ", "model", ".", "eval", "(", ")", "\n", "stance_preds", "=", "[", "]", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "for", "batch", "in", "tqdm", "(", "DataLoader", "(", "dataset", ",", "batch_size", "=", "args", ".", "batch_size", ",", "shuffle", "=", "False", ")", ")", ":", "\n", "            ", "encoded_dict", "=", "encode", "(", "tokenizer", ",", "batch", ")", "\n", "transformation_indices", "=", "token_idx_by_sentence", "(", "encoded_dict", "[", "\"input_ids\"", "]", ",", "\n", "tokenizer", ".", "sep_token_id", ",", "args", ".", "repfile", ")", "\n", "encoded_dict", "=", "{", "key", ":", "tensor", ".", "to", "(", "device", ")", "for", "key", ",", "tensor", "in", "encoded_dict", ".", "items", "(", ")", "}", "\n", "transformation_indices", "=", "[", "tensor", ".", "to", "(", "device", ")", "for", "tensor", "in", "transformation_indices", "]", "\n", "stance_out", ",", "_", "=", "model", "(", "encoded_dict", ",", "transformation_indices", ")", "\n", "stance_preds", ".", "extend", "(", "stance_out", ")", "\n", "\n", "", "", "return", "stance_preds", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.scifact_stance_paragraph.evaluation": [[45, 67], ["model.eval", "sklearn.metrics.f1_score", "sklearn.metrics.precision_score", "sklearn.metrics.recall_score", "torch.no_grad", "torch.no_grad", "torch.no_grad", "tqdm.tqdm", "torch.utils.data.DataLoader", "scifact_stance_paragraph.encode", "scifact_stance_paragraph.token_idx_by_sentence", "batch[].to", "model", "stance_preds.extend", "stance_labels.extend", "tensor.to", "tensor.to", "batch[].to.cpu().numpy().tolist", "encode.items", "batch[].to.cpu().numpy", "batch[].to.cpu"], "function", ["home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.label_prediction.transformer_scifact.encode", "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.FEVER_stance_paragraph.token_idx_by_sentence"], ["", "def", "evaluation", "(", "model", ",", "dataset", ",", "dummy", "=", "True", ")", ":", "\n", "    ", "model", ".", "eval", "(", ")", "\n", "stance_preds", "=", "[", "]", "\n", "stance_labels", "=", "[", "]", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "for", "batch", "in", "tqdm", "(", "DataLoader", "(", "dataset", ",", "batch_size", "=", "args", ".", "batch_size", "*", "5", ",", "shuffle", "=", "False", ")", ")", ":", "\n", "            ", "encoded_dict", "=", "encode", "(", "tokenizer", ",", "batch", ")", "\n", "transformation_indices", "=", "token_idx_by_sentence", "(", "encoded_dict", "[", "\"input_ids\"", "]", ",", "\n", "tokenizer", ".", "sep_token_id", ",", "args", ".", "repfile", ")", "\n", "encoded_dict", "=", "{", "key", ":", "tensor", ".", "to", "(", "device", ")", "for", "key", ",", "tensor", "in", "encoded_dict", ".", "items", "(", ")", "}", "\n", "transformation_indices", "=", "[", "tensor", ".", "to", "(", "device", ")", "for", "tensor", "in", "transformation_indices", "]", "\n", "stance_label", "=", "batch", "[", "\"stance\"", "]", ".", "to", "(", "device", ")", "\n", "stance_out", ",", "loss", "=", "model", "(", "encoded_dict", ",", "transformation_indices", ",", "stance_label", "=", "stance_label", ")", "\n", "stance_preds", ".", "extend", "(", "stance_out", ")", "\n", "stance_labels", ".", "extend", "(", "stance_label", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "tolist", "(", ")", ")", "\n", "\n", "", "", "stance_f1", "=", "f1_score", "(", "stance_labels", ",", "stance_preds", ",", "average", "=", "\"micro\"", ",", "labels", "=", "[", "1", ",", "2", "]", ")", "\n", "stance_precision", "=", "precision_score", "(", "stance_labels", ",", "stance_preds", ",", "average", "=", "\"micro\"", ",", "labels", "=", "[", "1", ",", "2", "]", ")", "\n", "stance_recall", "=", "recall_score", "(", "stance_labels", ",", "stance_preds", ",", "average", "=", "\"micro\"", ",", "labels", "=", "[", "1", ",", "2", "]", ")", "\n", "return", "stance_f1", ",", "stance_precision", ",", "stance_recall", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.scifact_stance_paragraph.encode": [[70, 119], ["zip", "tokenizer.batch_encode_plus", "torch.cat", "torch.cat", "torch.cat", "encoded_dict[].size", "len", "numpy.sum", "numpy.argmax", "valid_paragraph.size", "all_paragraphs.append", "longest_first_truncation"], "function", ["home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.dataset.encode.longest_first_truncation"], ["", "def", "encode", "(", "tokenizer", ",", "batch", ",", "max_sent_len", "=", "512", ")", ":", "\n", "    ", "def", "truncate", "(", "input_ids", ",", "max_length", ",", "sep_token_id", ",", "pad_token_id", ")", ":", "\n", "        ", "def", "longest_first_truncation", "(", "sentences", ",", "objective", ")", ":", "\n", "            ", "sent_lens", "=", "[", "len", "(", "sent", ")", "for", "sent", "in", "sentences", "]", "\n", "while", "np", ".", "sum", "(", "sent_lens", ")", ">", "objective", ":", "\n", "                ", "max_position", "=", "np", ".", "argmax", "(", "sent_lens", ")", "\n", "sent_lens", "[", "max_position", "]", "-=", "1", "\n", "", "return", "[", "sentence", "[", ":", "length", "]", "for", "sentence", ",", "length", "in", "zip", "(", "sentences", ",", "sent_lens", ")", "]", "\n", "\n", "", "all_paragraphs", "=", "[", "]", "\n", "for", "paragraph", "in", "input_ids", ":", "\n", "            ", "valid_paragraph", "=", "paragraph", "[", "paragraph", "!=", "pad_token_id", "]", "\n", "if", "valid_paragraph", ".", "size", "(", "0", ")", "<=", "max_length", ":", "\n", "                ", "all_paragraphs", ".", "append", "(", "paragraph", "[", ":", "max_length", "]", ".", "unsqueeze", "(", "0", ")", ")", "\n", "", "else", ":", "\n", "                ", "sep_token_idx", "=", "np", ".", "arange", "(", "valid_paragraph", ".", "size", "(", "0", ")", ")", "[", "(", "valid_paragraph", "==", "sep_token_id", ")", ".", "numpy", "(", ")", "]", "\n", "idx_by_sentence", "=", "[", "]", "\n", "prev_idx", "=", "0", "\n", "for", "idx", "in", "sep_token_idx", ":", "\n", "                    ", "idx_by_sentence", ".", "append", "(", "paragraph", "[", "prev_idx", ":", "idx", "]", ")", "\n", "prev_idx", "=", "idx", "\n", "", "objective", "=", "max_length", "-", "1", "-", "len", "(", "idx_by_sentence", "[", "0", "]", ")", "# The last sep_token left out", "\n", "truncated_sentences", "=", "longest_first_truncation", "(", "idx_by_sentence", "[", "1", ":", "]", ",", "objective", ")", "\n", "truncated_paragraph", "=", "torch", ".", "cat", "(", "[", "idx_by_sentence", "[", "0", "]", "]", "+", "truncated_sentences", "+", "[", "torch", ".", "tensor", "(", "[", "sep_token_id", "]", ")", "]", ",", "0", ")", "\n", "all_paragraphs", ".", "append", "(", "truncated_paragraph", ".", "unsqueeze", "(", "0", ")", ")", "\n", "\n", "", "", "return", "torch", ".", "cat", "(", "all_paragraphs", ",", "0", ")", "\n", "\n", "", "inputs", "=", "zip", "(", "batch", "[", "\"claim\"", "]", ",", "batch", "[", "\"paragraph\"", "]", ")", "\n", "encoded_dict", "=", "tokenizer", ".", "batch_encode_plus", "(", "\n", "inputs", ",", "\n", "pad_to_max_length", "=", "True", ",", "add_special_tokens", "=", "True", ",", "\n", "return_tensors", "=", "'pt'", ")", "\n", "if", "encoded_dict", "[", "'input_ids'", "]", ".", "size", "(", "1", ")", ">", "max_sent_len", ":", "\n", "        ", "if", "'token_type_ids'", "in", "encoded_dict", ":", "\n", "            ", "encoded_dict", "=", "{", "\n", "\"input_ids\"", ":", "truncate", "(", "encoded_dict", "[", "'input_ids'", "]", ",", "max_sent_len", ",", "\n", "tokenizer", ".", "sep_token_id", ",", "tokenizer", ".", "pad_token_id", ")", ",", "\n", "'token_type_ids'", ":", "encoded_dict", "[", "'token_type_ids'", "]", "[", ":", ",", ":", "max_sent_len", "]", ",", "\n", "'attention_mask'", ":", "encoded_dict", "[", "'attention_mask'", "]", "[", ":", ",", ":", "max_sent_len", "]", "\n", "}", "\n", "", "else", ":", "\n", "            ", "encoded_dict", "=", "{", "\n", "\"input_ids\"", ":", "truncate", "(", "encoded_dict", "[", "'input_ids'", "]", ",", "max_sent_len", ",", "\n", "tokenizer", ".", "sep_token_id", ",", "tokenizer", ".", "pad_token_id", ")", ",", "\n", "'attention_mask'", ":", "encoded_dict", "[", "'attention_mask'", "]", "[", ":", ",", ":", "max_sent_len", "]", "\n", "}", "\n", "\n", "", "", "return", "encoded_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.scifact_stance_paragraph.sent_rep_indices": [[120, 142], ["torch.sum().numpy().tolist", "torch.sum().numpy().tolist", "torch.sum().numpy().tolist", "torch.arange().unsqueeze().expand", "torch.arange().unsqueeze().expand", "torch.arange().unsqueeze().expand", "torch.split", "torch.split", "torch.split", "torch.utils.rnn.pad_sequence", "torch.arange().unsqueeze().expand", "torch.arange().unsqueeze().expand", "torch.arange().unsqueeze().expand", "sep_tokens.size", "nn.utils.rnn.pad_sequence.size", "torch.sum().numpy", "torch.sum().numpy", "torch.sum().numpy", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.sum", "torch.sum", "torch.sum", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "sep_tokens.size", "nn.utils.rnn.pad_sequence.size"], "function", ["None"], ["", "def", "sent_rep_indices", "(", "input_ids", ",", "sep_token_id", ",", "model_name", ")", ":", "\n", "\n", "    ", "\"\"\"\n    Compute the [SEP] indices matrix of the BERT output.\n    input_ids: (batch_size, paragraph_len)\n    batch_indices, indices_by_batch, mask: (batch_size, N_sentence)\n    bert_out: (batch_size, paragraph_len,BERT_dim)\n    bert_out[batch_indices,indices_by_batch,:]: (batch_size, N_sentence, BERT_dim)\n    \"\"\"", "\n", "\n", "sep_tokens", "=", "(", "input_ids", "==", "sep_token_id", ")", ".", "bool", "(", ")", "\n", "paragraph_lens", "=", "torch", ".", "sum", "(", "sep_tokens", ",", "1", ")", ".", "numpy", "(", ")", ".", "tolist", "(", ")", "\n", "indices", "=", "torch", ".", "arange", "(", "sep_tokens", ".", "size", "(", "-", "1", ")", ")", ".", "unsqueeze", "(", "0", ")", ".", "expand", "(", "sep_tokens", ".", "size", "(", "0", ")", ",", "-", "1", ")", "\n", "sep_indices", "=", "torch", ".", "split", "(", "indices", "[", "sep_tokens", "]", ",", "paragraph_lens", ")", "\n", "padded_sep_indices", "=", "nn", ".", "utils", ".", "rnn", ".", "pad_sequence", "(", "sep_indices", ",", "batch_first", "=", "True", ",", "padding_value", "=", "-", "1", ")", "\n", "batch_indices", "=", "torch", ".", "arange", "(", "padded_sep_indices", ".", "size", "(", "0", ")", ")", ".", "unsqueeze", "(", "-", "1", ")", ".", "expand", "(", "-", "1", ",", "padded_sep_indices", ".", "size", "(", "-", "1", ")", ")", "\n", "mask", "=", "(", "padded_sep_indices", ">=", "0", ")", ".", "long", "(", ")", "\n", "\n", "if", "\"roberta\"", "in", "model_name", ":", "\n", "        ", "return", "batch_indices", "[", ":", ",", "2", ":", "]", ",", "padded_sep_indices", "[", ":", ",", "2", ":", "]", ",", "mask", "[", ":", ",", "2", ":", "]", "\n", "", "else", ":", "\n", "        ", "return", "batch_indices", "[", ":", ",", "1", ":", "]", ",", "padded_sep_indices", "[", ":", ",", "1", ":", "]", ",", "mask", "[", ":", ",", "1", ":", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.scifact_stance_paragraph.token_idx_by_sentence": [[143, 171], ["torch.sum().numpy().tolist", "torch.sum().numpy().tolist", "torch.sum().numpy().tolist", "torch.arange().unsqueeze().expand", "torch.arange().unsqueeze().expand", "torch.arange().unsqueeze().expand", "torch.split", "torch.split", "torch.split", "torch.utils.rnn.pad_sequence", "torch.split", "torch.split", "torch.split", "torch.utils.rnn.pad_sequence", "torch.arange().unsqueeze().unsqueeze().expand", "torch.arange().unsqueeze().unsqueeze().expand", "torch.arange().unsqueeze().unsqueeze().expand", "sep_tokens.size", "torch.sum().numpy().tolist.append", "all_word_indices.extend", "nn.utils.rnn.pad_sequence.size", "nn.utils.rnn.pad_sequence.size", "torch.arange().unsqueeze().unsqueeze().expand.long", "nn.utils.rnn.pad_sequence.long", "mask.long", "torch.sum().numpy", "torch.sum().numpy", "torch.sum().numpy", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange", "torch.arange", "torch.arange", "len", "torch.arange().unsqueeze().unsqueeze", "torch.arange().unsqueeze().unsqueeze", "torch.arange().unsqueeze().unsqueeze", "range", "torch.sum", "torch.sum", "torch.sum", "torch.arange", "torch.arange", "torch.arange", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "sep_tokens.size", "paragraph.size", "torch.arange", "torch.arange", "torch.arange", "sep_tokens.size"], "function", ["None"], ["", "", "def", "token_idx_by_sentence", "(", "input_ids", ",", "sep_token_id", ",", "model_name", ")", ":", "\n", "    ", "\"\"\"\n    Compute the token indices matrix of the BERT output.\n    input_ids: (batch_size, paragraph_len)\n    batch_indices, indices_by_batch, mask: (batch_size, N_sentence, N_token)\n    bert_out: (batch_size, paragraph_len,BERT_dim)\n    bert_out[batch_indices,indices_by_batch,:]: (batch_size, N_sentence, N_token, BERT_dim)\n    \"\"\"", "\n", "padding_idx", "=", "-", "1", "\n", "sep_tokens", "=", "(", "input_ids", "==", "sep_token_id", ")", ".", "bool", "(", ")", "\n", "paragraph_lens", "=", "torch", ".", "sum", "(", "sep_tokens", ",", "1", ")", ".", "numpy", "(", ")", ".", "tolist", "(", ")", "\n", "indices", "=", "torch", ".", "arange", "(", "sep_tokens", ".", "size", "(", "-", "1", ")", ")", ".", "unsqueeze", "(", "0", ")", ".", "expand", "(", "sep_tokens", ".", "size", "(", "0", ")", ",", "-", "1", ")", "\n", "sep_indices", "=", "torch", ".", "split", "(", "indices", "[", "sep_tokens", "]", ",", "paragraph_lens", ")", "\n", "paragraph_lens", "=", "[", "]", "\n", "all_word_indices", "=", "[", "]", "\n", "for", "paragraph", "in", "sep_indices", ":", "\n", "        ", "if", "\"large\"", "in", "model_name", ":", "\n", "            ", "paragraph", "=", "paragraph", "[", "1", ":", "]", "\n", "", "word_indices", "=", "[", "torch", ".", "arange", "(", "paragraph", "[", "i", "]", "+", "1", ",", "paragraph", "[", "i", "+", "1", "]", "+", "1", ")", "for", "i", "in", "range", "(", "paragraph", ".", "size", "(", "0", ")", "-", "1", ")", "]", "\n", "paragraph_lens", ".", "append", "(", "len", "(", "word_indices", ")", ")", "\n", "all_word_indices", ".", "extend", "(", "word_indices", ")", "\n", "", "indices_by_sentence", "=", "nn", ".", "utils", ".", "rnn", ".", "pad_sequence", "(", "all_word_indices", ",", "batch_first", "=", "True", ",", "padding_value", "=", "padding_idx", ")", "\n", "indices_by_sentence_split", "=", "torch", ".", "split", "(", "indices_by_sentence", ",", "paragraph_lens", ")", "\n", "indices_by_batch", "=", "nn", ".", "utils", ".", "rnn", ".", "pad_sequence", "(", "indices_by_sentence_split", ",", "batch_first", "=", "True", ",", "padding_value", "=", "padding_idx", ")", "\n", "batch_indices", "=", "torch", ".", "arange", "(", "sep_tokens", ".", "size", "(", "0", ")", ")", ".", "unsqueeze", "(", "-", "1", ")", ".", "unsqueeze", "(", "-", "1", ")", ".", "expand", "(", "-", "1", ",", "indices_by_batch", ".", "size", "(", "1", ")", ",", "indices_by_batch", ".", "size", "(", "-", "1", ")", ")", "\n", "mask", "=", "(", "indices_by_batch", ">=", "0", ")", "\n", "\n", "return", "batch_indices", ".", "long", "(", ")", ",", "indices_by_batch", ".", "long", "(", ")", ",", "mask", ".", "long", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.util.flatten": [[8, 16], ["array.extend", "array.append"], "function", ["None"], ["def", "flatten", "(", "arrayOfArray", ")", ":", "\n", "    ", "array", "=", "[", "]", "\n", "for", "arr", "in", "arrayOfArray", ":", "\n", "        ", "try", ":", "\n", "            ", "array", ".", "extend", "(", "arr", ")", "\n", "", "except", ":", "\n", "            ", "array", ".", "append", "(", "arr", ")", "\n", "", "", "return", "array", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.util.read_passages": [[17, 43], ["codecs.open", "line.strip", "len", "str_seqs.append", "label_seqs.append", "str_seq.append", "len", "str_seqs.append", "label_seqs.append", "line.strip.split", "label_seq.append", "label.strip"], "function", ["None"], ["", "def", "read_passages", "(", "filename", ",", "is_labeled", ")", ":", "\n", "    ", "str_seqs", "=", "[", "]", "\n", "str_seq", "=", "[", "]", "\n", "label_seqs", "=", "[", "]", "\n", "label_seq", "=", "[", "]", "\n", "for", "line", "in", "codecs", ".", "open", "(", "filename", ",", "\"r\"", ",", "\"utf-8\"", ")", ":", "\n", "        ", "lnstrp", "=", "line", ".", "strip", "(", ")", "\n", "if", "lnstrp", "==", "\"\"", ":", "\n", "            ", "if", "len", "(", "str_seq", ")", "!=", "0", ":", "\n", "                ", "str_seqs", ".", "append", "(", "str_seq", ")", "\n", "str_seq", "=", "[", "]", "\n", "label_seqs", ".", "append", "(", "label_seq", ")", "\n", "label_seq", "=", "[", "]", "\n", "", "", "else", ":", "\n", "            ", "if", "is_labeled", ":", "\n", "                ", "clause", ",", "label", "=", "lnstrp", ".", "split", "(", "\"\\t\"", ")", "\n", "label_seq", ".", "append", "(", "label", ".", "strip", "(", ")", ")", "\n", "", "else", ":", "\n", "                ", "clause", "=", "lnstrp", "\n", "", "str_seq", ".", "append", "(", "clause", ")", "\n", "", "", "if", "len", "(", "str_seq", ")", "!=", "0", ":", "\n", "        ", "str_seqs", ".", "append", "(", "str_seq", ")", "\n", "str_seq", "=", "[", "]", "\n", "label_seqs", ".", "append", "(", "label_seq", ")", "\n", "label_seq", "=", "[", "]", "\n", "", "return", "str_seqs", ",", "label_seqs", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.util.from_BIO_ind": [[44, 61], ["indices.items", "original_labels.index", "len", "original_labels.append"], "function", ["None"], ["", "def", "from_BIO_ind", "(", "BIO_pred", ",", "BIO_target", ",", "indices", ")", ":", "\n", "    ", "table", "=", "{", "}", "# Make a mapping between the indices of BIO_labels and temporary original label indices", "\n", "original_labels", "=", "[", "]", "\n", "for", "BIO_label", ",", "BIO_index", "in", "indices", ".", "items", "(", ")", ":", "\n", "        ", "if", "BIO_label", "[", ":", "2", "]", "==", "\"I_\"", "or", "BIO_label", "[", ":", "2", "]", "==", "\"B_\"", ":", "\n", "            ", "label", "=", "BIO_label", "[", "2", ":", "]", "\n", "", "else", ":", "\n", "            ", "label", "=", "BIO_label", "\n", "", "if", "label", "in", "original_labels", ":", "\n", "            ", "table", "[", "BIO_index", "]", "=", "original_labels", ".", "index", "(", "label", ")", "\n", "", "else", ":", "\n", "            ", "table", "[", "BIO_index", "]", "=", "len", "(", "original_labels", ")", "\n", "original_labels", ".", "append", "(", "label", ")", "\n", "\n", "", "", "original_pred", "=", "[", "table", "[", "label", "]", "for", "label", "in", "BIO_pred", "]", "\n", "original_target", "=", "[", "table", "[", "label", "]", "for", "label", "in", "BIO_target", "]", "\n", "return", "original_pred", ",", "original_target", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.util.to_BIO": [[62, 79], ["new_label_seqs.append", "new_label_para.append"], "function", ["None"], ["", "def", "to_BIO", "(", "label_seqs", ")", ":", "\n", "    ", "new_label_seqs", "=", "[", "]", "\n", "for", "label_para", "in", "label_seqs", ":", "\n", "        ", "new_label_para", "=", "[", "]", "\n", "prev", "=", "\"\"", "\n", "for", "label", "in", "label_para", ":", "\n", "            ", "if", "label", "!=", "\"none\"", ":", "# \"none\" is O, remain unchanged.", "\n", "                ", "if", "label", "==", "prev", ":", "\n", "                    ", "new_label", "=", "\"I_\"", "+", "label", "\n", "", "else", ":", "\n", "                    ", "new_label", "=", "\"B_\"", "+", "label", "\n", "", "", "else", ":", "\n", "                ", "new_label", "=", "label", "# \"none\"", "\n", "", "prev", "=", "label", "\n", "new_label_para", ".", "append", "(", "new_label", ")", "\n", "", "new_label_seqs", ".", "append", "(", "new_label_para", ")", "\n", "", "return", "new_label_seqs", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.util.from_BIO": [[80, 92], ["new_label_seqs.append", "new_label_para.append"], "function", ["None"], ["", "def", "from_BIO", "(", "label_seqs", ")", ":", "\n", "    ", "new_label_seqs", "=", "[", "]", "\n", "for", "label_para", "in", "label_seqs", ":", "\n", "        ", "new_label_para", "=", "[", "]", "\n", "for", "label", "in", "label_para", ":", "\n", "            ", "if", "label", "[", ":", "2", "]", "==", "\"I_\"", "or", "label", "[", ":", "2", "]", "==", "\"B_\"", ":", "\n", "                ", "new_label", "=", "label", "[", "2", ":", "]", "\n", "", "else", ":", "\n", "                ", "new_label", "=", "label", "\n", "", "new_label_para", ".", "append", "(", "new_label", ")", "\n", "", "new_label_seqs", ".", "append", "(", "new_label_para", ")", "\n", "", "return", "new_label_seqs", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.util.clean_url": [[93, 101], ["re.sub", "re.sub"], "function", ["None"], ["", "def", "clean_url", "(", "word", ")", ":", "\n", "    ", "\"\"\"\n        Clean specific data format from social media\n    \"\"\"", "\n", "# clean urls", "\n", "word", "=", "re", ".", "sub", "(", "r'https? : \\/\\/.*[\\r\\n]*'", ",", "'<URL>'", ",", "word", ")", "\n", "word", "=", "re", ".", "sub", "(", "r'exlink'", ",", "'<URL>'", ",", "word", ")", "\n", "return", "word", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.util.clean_num": [[102, 112], ["any", "char.isdigit", "float", "word.replace", "any", "char.isalpha"], "function", ["None"], ["", "def", "clean_num", "(", "word", ")", ":", "\n", "# check if the word contain number and no letters", "\n", "    ", "if", "any", "(", "char", ".", "isdigit", "(", ")", "for", "char", "in", "word", ")", ":", "\n", "        ", "try", ":", "\n", "            ", "num", "=", "float", "(", "word", ".", "replace", "(", "','", ",", "''", ")", ")", "\n", "return", "'@'", "\n", "", "except", ":", "\n", "            ", "if", "not", "any", "(", "char", ".", "isalpha", "(", ")", "for", "char", "in", "word", ")", ":", "\n", "                ", "return", "'@'", "\n", "", "", "", "return", "word", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.util.clean_words": [[114, 129], ["processed_seqs.append", "clause.split", "processed_clauses.append", "util.clean_url", "util.clean_num", "filtered.append"], "function", ["home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.util.clean_url", "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.util.clean_num"], ["", "def", "clean_words", "(", "str_seqs", ")", ":", "\n", "    ", "processed_seqs", "=", "[", "]", "\n", "for", "str_seq", "in", "str_seqs", ":", "\n", "        ", "processed_clauses", "=", "[", "]", "\n", "for", "clause", "in", "str_seq", ":", "\n", "            ", "filtered", "=", "[", "]", "\n", "tokens", "=", "clause", ".", "split", "(", ")", "\n", "for", "word", "in", "tokens", ":", "\n", "                ", "word", "=", "clean_url", "(", "word", ")", "\n", "word", "=", "clean_num", "(", "word", ")", "\n", "filtered", ".", "append", "(", "word", ")", "\n", "", "filtered_clause", "=", "\" \"", ".", "join", "(", "filtered", ")", "\n", "processed_clauses", ".", "append", "(", "filtered_clause", ")", "\n", "", "processed_seqs", ".", "append", "(", "processed_clauses", ")", "\n", "", "return", "processed_seqs", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.util.test_f1": [[130, 144], ["read_passages_original", "util.test_f1.linearize"], "function", ["None"], ["", "def", "test_f1", "(", "test_file", ",", "pred_label_seqs", ")", ":", "\n", "    ", "def", "linearize", "(", "labels", ")", ":", "\n", "        ", "linearized", "=", "[", "]", "\n", "for", "paper", "in", "labels", ":", "\n", "            ", "for", "label", "in", "paper", ":", "\n", "                ", "linearized", ".", "append", "(", "label", ")", "\n", "", "", "return", "linearized", "\n", "", "_", ",", "label_seqs", "=", "read_passages_original", "(", "test_file", ",", "True", ")", "\n", "true_label", "=", "linearize", "(", "label_seqs", ")", "\n", "pred_label", "=", "linearize", "(", "pred_label_seqs", ")", "\n", "\n", "f1", "=", "f1_score", "(", "true_label", ",", "pred_label", ",", "average", "=", "\"weighted\"", ")", "\n", "print", "(", "\"F1 score:\"", ",", "f1", ")", "\n", "return", "f1", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.util.postprocess": [[145, 184], ["raw_flattened_output.tolist.tolist", "raw_flattened_labels.tolist.tolist", "util.from_BIO", "util.from_BIO", "paragraph_lens.append", "ground_truth_labels.append", "predict_idx.extend", "gt_tag.extend", "from_BIO.append", "gt_tags.append", "len", "predict_idx.extend", "gt_tag.extend"], "function", ["home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.util.from_BIO", "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.util.from_BIO"], ["", "def", "postprocess", "(", "dataset", ",", "raw_flattened_output", ",", "raw_flattened_labels", ",", "MAX_SEQ_LEN", ")", ":", "\n", "    ", "ground_truth_labels", "=", "[", "]", "\n", "paragraph_lens", "=", "[", "]", "\n", "for", "para", "in", "dataset", ".", "true_pairs", ":", "\n", "        ", "paragraph_lens", ".", "append", "(", "len", "(", "para", "[", "\"paragraph\"", "]", ")", ")", "\n", "ground_truth_labels", ".", "append", "(", "para", "[", "\"label\"", "]", ")", "\n", "\n", "", "raw_flattened_output", "=", "raw_flattened_output", ".", "tolist", "(", ")", "\n", "raw_flattened_labels", "=", "raw_flattened_labels", ".", "tolist", "(", ")", "\n", "batch_i", "=", "0", "\n", "predicted_tags", "=", "[", "]", "\n", "gt_tags", "=", "[", "]", "\n", "for", "length", "in", "paragraph_lens", ":", "\n", "        ", "remaining_len", "=", "length", "\n", "predict_idx", "=", "[", "]", "\n", "gt_tag", "=", "[", "]", "\n", "while", "remaining_len", ">", "MAX_SEQ_LEN", ":", "\n", "            ", "this_batch", "=", "raw_flattened_output", "[", "batch_i", "*", "MAX_SEQ_LEN", ":", "(", "batch_i", "+", "1", ")", "*", "MAX_SEQ_LEN", "]", "\n", "this_batch_label", "=", "raw_flattened_labels", "[", "batch_i", "*", "MAX_SEQ_LEN", ":", "(", "batch_i", "+", "1", ")", "*", "MAX_SEQ_LEN", "]", "\n", "predict_idx", ".", "extend", "(", "this_batch", ")", "\n", "gt_tag", ".", "extend", "(", "this_batch_label", ")", "\n", "batch_i", "+=", "1", "\n", "remaining_len", "-=", "MAX_SEQ_LEN", "\n", "\n", "", "this_batch", "=", "raw_flattened_output", "[", "batch_i", "*", "MAX_SEQ_LEN", ":", "(", "batch_i", "+", "1", ")", "*", "MAX_SEQ_LEN", "]", "\n", "this_batch_label", "=", "raw_flattened_labels", "[", "batch_i", "*", "MAX_SEQ_LEN", ":", "(", "batch_i", "+", "1", ")", "*", "MAX_SEQ_LEN", "]", "\n", "predict_idx", ".", "extend", "(", "this_batch", "[", ":", "remaining_len", "]", ")", "\n", "gt_tag", ".", "extend", "(", "this_batch_label", "[", ":", "remaining_len", "]", ")", "\n", "predict_tag", "=", "[", "dataset", ".", "rev_label_ind", "[", "idx", "]", "for", "idx", "in", "predict_idx", "]", "\n", "gt_tag", "=", "[", "dataset", ".", "rev_label_ind", "[", "idx", "]", "for", "idx", "in", "gt_tag", "]", "\n", "batch_i", "+=", "1", "\n", "predicted_tags", ".", "append", "(", "predict_tag", ")", "\n", "gt_tags", ".", "append", "(", "gt_tag", ")", "\n", "\n", "\n", "", "predicted_tags", "=", "from_BIO", "(", "predicted_tags", ")", "\n", "final_gt", "=", "from_BIO", "(", "gt_tags", ")", "\n", "\n", "return", "predicted_tags", ",", "final_gt", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.util.stance_postprocess": [[185, 232], ["raw_output.tolist.tolist", "raw_labels.tolist.tolist", "set", "paragraph_lens.append", "ground_truth_labels.append", "predict_idx.append", "combine.append", "util.stance_postprocess.combine"], "function", ["None"], ["", "def", "stance_postprocess", "(", "dataset", ",", "raw_output", ",", "raw_labels", ",", "MAX_SEQ_LEN", ")", ":", "\n", "\n", "    ", "def", "combine", "(", "candidates", ")", ":", "\n", "        ", "assert", "(", "len", "(", "candidates", ")", ">", "0", ")", "\n", "types", "=", "set", "(", "candidates", ")", "\n", "if", "len", "(", "types", ")", "==", "1", ":", "\n", "            ", "return", "list", "(", "types", ")", "[", "0", "]", "\n", "", "elif", "2", "in", "types", ":", "\n", "            ", "return", "2", "\n", "", "else", ":", "\n", "            ", "return", "1", "\n", "\n", "\n", "", "", "ground_truth_labels", "=", "[", "]", "\n", "paragraph_lens", "=", "[", "]", "\n", "for", "para", "in", "dataset", ".", "true_pairs", ":", "\n", "        ", "paragraph_lens", ".", "append", "(", "len", "(", "para", "[", "\"paragraph\"", "]", ")", ")", "\n", "ground_truth_labels", ".", "append", "(", "para", "[", "\"label\"", "]", ")", "\n", "\n", "", "raw_output", "=", "raw_output", ".", "tolist", "(", ")", "\n", "raw_labels", "=", "raw_labels", ".", "tolist", "(", ")", "\n", "batch_i", "=", "0", "\n", "predicted_tags", "=", "[", "]", "\n", "gt_tags", "=", "[", "]", "\n", "for", "length", "in", "paragraph_lens", ":", "\n", "        ", "remaining_len", "=", "length", "\n", "predict_idx", "=", "[", "]", "\n", "gt_tag", "=", "[", "]", "\n", "while", "remaining_len", ">", "MAX_SEQ_LEN", ":", "\n", "            ", "this_batch", "=", "raw_output", "[", "batch_i", "]", "\n", "this_batch_label", "=", "raw_labels", "[", "batch_i", "]", "\n", "predict_idx", ".", "append", "(", "this_batch", ")", "\n", "gt_tag", ".", "append", "(", "this_batch_label", ")", "\n", "batch_i", "+=", "1", "\n", "remaining_len", "-=", "MAX_SEQ_LEN", "\n", "\n", "", "this_batch", "=", "raw_output", "[", "batch_i", "]", "\n", "this_batch_label", "=", "raw_labels", "[", "batch_i", "]", "\n", "predict_idx", ".", "append", "(", "this_batch", ")", "\n", "gt_tag", ".", "append", "(", "this_batch_label", ")", "\n", "predict_tag", "=", "combine", "(", "predict_idx", ")", "\n", "gt_tag", "=", "combine", "(", "gt_tag", ")", "\n", "batch_i", "+=", "1", "\n", "predicted_tags", ".", "append", "(", "predict_tag", ")", "\n", "gt_tags", ".", "append", "(", "gt_tag", ")", "\n", "\n", "", "return", "predicted_tags", ",", "gt_tags", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.util.rationale2json": [[233, 255], ["zip", "len", "len", "claim_ids.append", "enumerate", "claims.get", "claim_ids.append", "sorted", "predicted_sentences.append", "list", "set"], "function", ["None"], ["", "def", "rationale2json", "(", "true_pairs", ",", "predictions", ",", "excluded_pairs", "=", "None", ")", ":", "\n", "    ", "claim_ids", "=", "[", "]", "\n", "claims", "=", "{", "}", "\n", "assert", "(", "len", "(", "true_pairs", ")", "==", "len", "(", "predictions", ")", ")", "\n", "for", "pair", ",", "prediction", "in", "zip", "(", "true_pairs", ",", "predictions", ")", ":", "\n", "        ", "claim_id", "=", "pair", "[", "\"claim_id\"", "]", "\n", "claim_ids", ".", "append", "(", "claim_id", ")", "\n", "\n", "predicted_sentences", "=", "[", "]", "\n", "for", "i", ",", "pred", "in", "enumerate", "(", "prediction", ")", ":", "\n", "            ", "if", "pred", "==", "\"rationale\"", "or", "pred", "==", "1", ":", "\n", "                ", "predicted_sentences", ".", "append", "(", "i", ")", "\n", "\n", "", "", "this_claim", "=", "claims", ".", "get", "(", "claim_id", ",", "{", "\"claim_id\"", ":", "claim_id", ",", "\"evidence\"", ":", "{", "}", "}", ")", "\n", "#if len(predicted_sentences) > 0:", "\n", "this_claim", "[", "\"evidence\"", "]", "[", "pair", "[", "\"doc_id\"", "]", "]", "=", "predicted_sentences", "\n", "claims", "[", "claim_id", "]", "=", "this_claim", "\n", "", "if", "excluded_pairs", "is", "not", "None", ":", "\n", "        ", "for", "pair", "in", "excluded_pairs", ":", "\n", "            ", "claims", "[", "pair", "[", "\"claim_id\"", "]", "]", "=", "{", "\"claim_id\"", ":", "pair", "[", "\"claim_id\"", "]", ",", "\"evidence\"", ":", "{", "}", "}", "\n", "claim_ids", ".", "append", "(", "pair", "[", "\"claim_id\"", "]", ")", "\n", "", "", "return", "[", "claims", "[", "claim_id", "]", "for", "claim_id", "in", "sorted", "(", "list", "(", "set", "(", "claim_ids", ")", ")", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.util.stance2json": [[256, 273], ["zip", "len", "len", "claim_ids.append", "claims.get", "claim_ids.append", "sorted", "list", "set"], "function", ["None"], ["", "def", "stance2json", "(", "true_pairs", ",", "predictions", ",", "excluded_pairs", "=", "None", ")", ":", "\n", "    ", "claim_ids", "=", "[", "]", "\n", "claims", "=", "{", "}", "\n", "idx2stance", "=", "[", "\"NOT_ENOUGH_INFO\"", ",", "\"SUPPORT\"", ",", "\"CONTRADICT\"", "]", "\n", "assert", "(", "len", "(", "true_pairs", ")", "==", "len", "(", "predictions", ")", ")", "\n", "for", "pair", ",", "prediction", "in", "zip", "(", "true_pairs", ",", "predictions", ")", ":", "\n", "        ", "claim_id", "=", "pair", "[", "\"claim_id\"", "]", "\n", "claim_ids", ".", "append", "(", "claim_id", ")", "\n", "\n", "this_claim", "=", "claims", ".", "get", "(", "claim_id", ",", "{", "\"claim_id\"", ":", "claim_id", ",", "\"labels\"", ":", "{", "}", "}", ")", "\n", "this_claim", "[", "\"labels\"", "]", "[", "pair", "[", "\"doc_id\"", "]", "]", "=", "{", "\"label\"", ":", "idx2stance", "[", "prediction", "]", ",", "'confidence'", ":", "1", "}", "\n", "claims", "[", "claim_id", "]", "=", "this_claim", "\n", "", "if", "excluded_pairs", "is", "not", "None", ":", "\n", "        ", "for", "pair", "in", "excluded_pairs", ":", "\n", "            ", "claims", "[", "pair", "[", "\"claim_id\"", "]", "]", "=", "{", "\"claim_id\"", ":", "pair", "[", "\"claim_id\"", "]", ",", "\"labels\"", ":", "{", "}", "}", "\n", "claim_ids", ".", "append", "(", "pair", "[", "\"claim_id\"", "]", ")", "\n", "", "", "return", "[", "claims", "[", "claim_id", "]", "for", "claim_id", "in", "sorted", "(", "list", "(", "set", "(", "claim_ids", ")", ")", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.util.merge_json": [[274, 289], ["str", "str", "jsons.append", "rationale_json[].items", "int", "len", "int", "int"], "function", ["None"], ["", "def", "merge_json", "(", "rationale_jsons", ",", "stance_jsons", ")", ":", "\n", "    ", "stance_json_dict", "=", "{", "str", "(", "stance_json", "[", "\"claim_id\"", "]", ")", ":", "stance_json", "for", "stance_json", "in", "stance_jsons", "}", "\n", "jsons", "=", "[", "]", "\n", "for", "rationale_json", "in", "rationale_jsons", ":", "\n", "        ", "id", "=", "str", "(", "rationale_json", "[", "\"claim_id\"", "]", ")", "\n", "result", "=", "{", "}", "\n", "if", "id", "in", "stance_json_dict", ":", "\n", "            ", "for", "k", ",", "v", "in", "rationale_json", "[", "\"evidence\"", "]", ".", "items", "(", ")", ":", "\n", "                ", "if", "len", "(", "v", ")", ">", "0", "and", "stance_json_dict", "[", "id", "]", "[", "\"labels\"", "]", "[", "int", "(", "k", ")", "]", "[", "\"label\"", "]", "is", "not", "\"NOT_ENOUGH_INFO\"", ":", "\n", "                    ", "result", "[", "k", "]", "=", "{", "\n", "\"sentences\"", ":", "v", ",", "\n", "\"label\"", ":", "stance_json_dict", "[", "id", "]", "[", "\"labels\"", "]", "[", "int", "(", "k", ")", "]", "[", "\"label\"", "]", "\n", "}", "\n", "", "", "", "jsons", ".", "append", "(", "{", "\"id\"", ":", "int", "(", "id", ")", ",", "\"evidence\"", ":", "result", "}", ")", "\n", "", "return", "jsons", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.util.arg2param": [[290, 298], ["vars"], "function", ["None"], ["", "def", "arg2param", "(", "args", ")", ":", "\n", "    ", "params", "=", "vars", "(", "args", ")", "\n", "params", "[", "\"MAX_SEQ_LEN\"", "]", "=", "params", "[", "\"CHUNK_SIZE\"", "]", "*", "params", "[", "\"CHUNK_PER_SEQ\"", "]", "\n", "params", "[", "\"MINIBATCH_SIZE\"", "]", "=", "params", "[", "\"CHUNK_PER_SEQ\"", "]", "\n", "params", "[", "\"SENTENCE_BATCH_SIZE\"", "]", "=", "params", "[", "\"CHUNK_SIZE\"", "]", "\n", "params", "[", "\"CHUNK_PER_STEP\"", "]", "=", "params", "[", "\"PARAGRAPH_PER_STEP\"", "]", "*", "params", "[", "\"CHUNK_PER_SEQ\"", "]", "\n", "\n", "return", "params", "\n", "", ""]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.scifact_joint_paragraph_kgat_prediction.reset_random_seed": [[29, 33], ["numpy.random.seed", "random.seed", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed"], "function", ["None"], ["def", "reset_random_seed", "(", "seed", ")", ":", "\n", "    ", "np", ".", "random", ".", "seed", "(", "seed", ")", "\n", "random", ".", "seed", "(", "seed", ")", "\n", "torch", ".", "manual_seed", "(", "seed", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.scifact_joint_paragraph_kgat_prediction.predict": [[34, 54], ["model.eval", "torch.no_grad", "torch.no_grad", "torch.no_grad", "tqdm.tqdm", "torch.utils.data.DataLoader", "scifact_joint_paragraph_kgat_prediction.encode", "scifact_joint_paragraph_kgat_prediction.token_idx_by_sentence", "model", "stance_preds.extend", "rationale_predictions.extend", "tensor.to", "tensor.to", "scifact_joint_paragraph_kgat_prediction.predict.remove_dummy"], "function", ["home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.label_prediction.transformer_scifact.encode", "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.FEVER_stance_paragraph.token_idx_by_sentence", "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.src.utils.remove_dummy"], ["", "def", "predict", "(", "model", ",", "dataset", ")", ":", "\n", "    ", "model", ".", "eval", "(", ")", "\n", "rationale_predictions", "=", "[", "]", "\n", "stance_preds", "=", "[", "]", "\n", "\n", "def", "remove_dummy", "(", "rationale_out", ")", ":", "\n", "        ", "return", "[", "out", "[", "1", ":", "]", "for", "out", "in", "rationale_out", "]", "\n", "\n", "", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "for", "batch", "in", "tqdm", "(", "DataLoader", "(", "dataset", ",", "batch_size", "=", "args", ".", "batch_size", ",", "shuffle", "=", "False", ")", ")", ":", "\n", "            ", "encoded_dict", "=", "encode", "(", "tokenizer", ",", "batch", ")", "\n", "transformation_indices", "=", "token_idx_by_sentence", "(", "encoded_dict", "[", "\"input_ids\"", "]", ",", "\n", "tokenizer", ".", "sep_token_id", ",", "args", ".", "repfile", ")", "\n", "encoded_dict", "=", "{", "key", ":", "tensor", ".", "to", "(", "device", ")", "for", "key", ",", "tensor", "in", "encoded_dict", ".", "items", "(", ")", "}", "\n", "transformation_indices", "=", "[", "tensor", ".", "to", "(", "device", ")", "for", "tensor", "in", "transformation_indices", "]", "\n", "rationale_out", ",", "stance_out", ",", "_", ",", "_", "=", "model", "(", "encoded_dict", ",", "transformation_indices", ")", "\n", "stance_preds", ".", "extend", "(", "stance_out", ")", "\n", "rationale_predictions", ".", "extend", "(", "remove_dummy", "(", "rationale_out", ")", ")", "\n", "\n", "", "", "return", "rationale_predictions", ",", "stance_preds", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.scifact_joint_paragraph_kgat_prediction.encode": [[57, 105], ["zip", "tokenizer.batch_encode_plus", "torch.cat", "torch.cat", "torch.cat", "encoded_dict[].size", "len", "numpy.sum", "numpy.argmax", "valid_paragraph.size", "all_paragraphs.append", "longest_first_truncation"], "function", ["home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.dataset.encode.longest_first_truncation"], ["", "def", "encode", "(", "tokenizer", ",", "batch", ",", "max_sent_len", "=", "512", ")", ":", "\n", "    ", "def", "truncate", "(", "input_ids", ",", "max_length", ",", "sep_token_id", ",", "pad_token_id", ")", ":", "\n", "        ", "def", "longest_first_truncation", "(", "sentences", ",", "objective", ")", ":", "\n", "            ", "sent_lens", "=", "[", "len", "(", "sent", ")", "for", "sent", "in", "sentences", "]", "\n", "while", "np", ".", "sum", "(", "sent_lens", ")", ">", "objective", ":", "\n", "                ", "max_position", "=", "np", ".", "argmax", "(", "sent_lens", ")", "\n", "sent_lens", "[", "max_position", "]", "-=", "1", "\n", "", "return", "[", "sentence", "[", ":", "length", "]", "for", "sentence", ",", "length", "in", "zip", "(", "sentences", ",", "sent_lens", ")", "]", "\n", "\n", "", "all_paragraphs", "=", "[", "]", "\n", "for", "paragraph", "in", "input_ids", ":", "\n", "            ", "valid_paragraph", "=", "paragraph", "[", "paragraph", "!=", "pad_token_id", "]", "\n", "if", "valid_paragraph", ".", "size", "(", "0", ")", "<=", "max_length", ":", "\n", "                ", "all_paragraphs", ".", "append", "(", "paragraph", "[", ":", "max_length", "]", ".", "unsqueeze", "(", "0", ")", ")", "\n", "", "else", ":", "\n", "                ", "sep_token_idx", "=", "np", ".", "arange", "(", "valid_paragraph", ".", "size", "(", "0", ")", ")", "[", "(", "valid_paragraph", "==", "sep_token_id", ")", ".", "numpy", "(", ")", "]", "\n", "idx_by_sentence", "=", "[", "]", "\n", "prev_idx", "=", "0", "\n", "for", "idx", "in", "sep_token_idx", ":", "\n", "                    ", "idx_by_sentence", ".", "append", "(", "paragraph", "[", "prev_idx", ":", "idx", "]", ")", "\n", "prev_idx", "=", "idx", "\n", "", "objective", "=", "max_length", "-", "1", "-", "len", "(", "idx_by_sentence", "[", "0", "]", ")", "# The last sep_token left out", "\n", "truncated_sentences", "=", "longest_first_truncation", "(", "idx_by_sentence", "[", "1", ":", "]", ",", "objective", ")", "\n", "truncated_paragraph", "=", "torch", ".", "cat", "(", "[", "idx_by_sentence", "[", "0", "]", "]", "+", "truncated_sentences", "+", "[", "torch", ".", "tensor", "(", "[", "sep_token_id", "]", ")", "]", ",", "0", ")", "\n", "all_paragraphs", ".", "append", "(", "truncated_paragraph", ".", "unsqueeze", "(", "0", ")", ")", "\n", "\n", "", "", "return", "torch", ".", "cat", "(", "all_paragraphs", ",", "0", ")", "\n", "\n", "", "inputs", "=", "zip", "(", "batch", "[", "\"claim\"", "]", ",", "batch", "[", "\"paragraph\"", "]", ")", "\n", "encoded_dict", "=", "tokenizer", ".", "batch_encode_plus", "(", "\n", "inputs", ",", "\n", "pad_to_max_length", "=", "True", ",", "add_special_tokens", "=", "True", ",", "\n", "return_tensors", "=", "'pt'", ")", "\n", "if", "encoded_dict", "[", "'input_ids'", "]", ".", "size", "(", "1", ")", ">", "max_sent_len", ":", "\n", "        ", "if", "'token_type_ids'", "in", "encoded_dict", ":", "\n", "            ", "encoded_dict", "=", "{", "\n", "\"input_ids\"", ":", "truncate", "(", "encoded_dict", "[", "'input_ids'", "]", ",", "max_sent_len", ",", "\n", "tokenizer", ".", "sep_token_id", ",", "tokenizer", ".", "pad_token_id", ")", ",", "\n", "'token_type_ids'", ":", "encoded_dict", "[", "'token_type_ids'", "]", "[", ":", ",", ":", "max_sent_len", "]", ",", "\n", "'attention_mask'", ":", "encoded_dict", "[", "'attention_mask'", "]", "[", ":", ",", ":", "max_sent_len", "]", "\n", "}", "\n", "", "else", ":", "\n", "            ", "encoded_dict", "=", "{", "\n", "\"input_ids\"", ":", "truncate", "(", "encoded_dict", "[", "'input_ids'", "]", ",", "max_sent_len", ",", "\n", "tokenizer", ".", "sep_token_id", ",", "tokenizer", ".", "pad_token_id", ")", ",", "\n", "'attention_mask'", ":", "encoded_dict", "[", "'attention_mask'", "]", "[", ":", ",", ":", "max_sent_len", "]", "\n", "}", "\n", "", "", "return", "encoded_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.scifact_joint_paragraph_kgat_prediction.token_idx_by_sentence": [[106, 141], ["torch.sum().numpy().tolist", "torch.sum().numpy().tolist", "torch.sum().numpy().tolist", "torch.arange().unsqueeze().expand", "torch.arange().unsqueeze().expand", "torch.arange().unsqueeze().expand", "torch.split", "torch.split", "torch.split", "torch.utils.rnn.pad_sequence", "torch.split", "torch.split", "torch.split", "torch.utils.rnn.pad_sequence", "torch.arange().unsqueeze().unsqueeze().expand", "torch.arange().unsqueeze().unsqueeze().expand", "torch.arange().unsqueeze().unsqueeze().expand", "sep_tokens.size", "torch.arange", "torch.arange", "torch.arange", "torch.sum().numpy().tolist.append", "all_word_indices.extend", "nn.utils.rnn.pad_sequence.size", "nn.utils.rnn.pad_sequence.size", "torch.arange().unsqueeze().unsqueeze().expand.long", "nn.utils.rnn.pad_sequence.long", "mask.long", "torch.sum().numpy", "torch.sum().numpy", "torch.sum().numpy", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange", "torch.arange", "torch.arange", "len", "torch.arange().unsqueeze().unsqueeze", "torch.arange().unsqueeze().unsqueeze", "torch.arange().unsqueeze().unsqueeze", "range", "torch.sum", "torch.sum", "torch.sum", "torch.arange", "torch.arange", "torch.arange", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "sep_tokens.size", "paragraph.size", "torch.arange", "torch.arange", "torch.arange", "sep_tokens.size"], "function", ["None"], ["", "def", "token_idx_by_sentence", "(", "input_ids", ",", "sep_token_id", ",", "model_name", ")", ":", "\n", "    ", "\"\"\"\n    Advanced indexing: Compute the token indices matrix of the BERT output.\n    input_ids: (batch_size, paragraph_len)\n    batch_indices, indices_by_batch, mask: (batch_size, N_sentence, N_token)\n    bert_out: (batch_size, paragraph_len,BERT_dim)\n    bert_out[batch_indices,indices_by_batch,:]: (batch_size, N_sentence, N_token, BERT_dim)\n    \"\"\"", "\n", "padding_idx", "=", "-", "1", "\n", "sep_tokens", "=", "(", "input_ids", "==", "sep_token_id", ")", ".", "bool", "(", ")", "\n", "paragraph_lens", "=", "torch", ".", "sum", "(", "sep_tokens", ",", "1", ")", ".", "numpy", "(", ")", ".", "tolist", "(", ")", "# i.e. N_sentences per paragraph", "\n", "indices", "=", "torch", ".", "arange", "(", "sep_tokens", ".", "size", "(", "-", "1", ")", ")", ".", "unsqueeze", "(", "0", ")", ".", "expand", "(", "sep_tokens", ".", "size", "(", "0", ")", ",", "-", "1", ")", "# 0,1,2,3,....,511 for each sentence", "\n", "sep_indices", "=", "torch", ".", "split", "(", "indices", "[", "sep_tokens", "]", ",", "paragraph_lens", ")", "# indices of SEP tokens per paragraph", "\n", "paragraph_lens", "=", "[", "]", "\n", "all_word_indices", "=", "[", "]", "\n", "for", "paragraph", "in", "sep_indices", ":", "\n", "# claim sentence: [CLS] token1 token2 ... tokenk", "\n", "        ", "claim_word_indices", "=", "torch", ".", "arange", "(", "0", ",", "paragraph", "[", "0", "]", ")", "\n", "if", "\"roberta\"", "in", "model_name", ":", "# Huggingface Roberta has <s>..</s></s>..</s>..</s>", "\n", "            ", "paragraph", "=", "paragraph", "[", "1", ":", "]", "\n", "# each sentence: [SEP] token1 token2 ... tokenk, the last [SEP] in the paragraph is ditched.", "\n", "", "sentence_word_indices", "=", "[", "torch", ".", "arange", "(", "paragraph", "[", "i", "]", ",", "paragraph", "[", "i", "+", "1", "]", ")", "for", "i", "in", "range", "(", "paragraph", ".", "size", "(", "0", ")", "-", "1", ")", "]", "\n", "\n", "# KGAT requires claim sentence, so add it back.", "\n", "word_indices", "=", "[", "claim_word_indices", "]", "+", "sentence_word_indices", "\n", "\n", "paragraph_lens", ".", "append", "(", "len", "(", "word_indices", ")", ")", "\n", "all_word_indices", ".", "extend", "(", "word_indices", ")", "\n", "", "indices_by_sentence", "=", "nn", ".", "utils", ".", "rnn", ".", "pad_sequence", "(", "all_word_indices", ",", "batch_first", "=", "True", ",", "padding_value", "=", "padding_idx", ")", "\n", "indices_by_sentence_split", "=", "torch", ".", "split", "(", "indices_by_sentence", ",", "paragraph_lens", ")", "\n", "indices_by_batch", "=", "nn", ".", "utils", ".", "rnn", ".", "pad_sequence", "(", "indices_by_sentence_split", ",", "batch_first", "=", "True", ",", "padding_value", "=", "padding_idx", ")", "\n", "batch_indices", "=", "torch", ".", "arange", "(", "sep_tokens", ".", "size", "(", "0", ")", ")", ".", "unsqueeze", "(", "-", "1", ")", ".", "unsqueeze", "(", "-", "1", ")", ".", "expand", "(", "-", "1", ",", "indices_by_batch", ".", "size", "(", "1", ")", ",", "indices_by_batch", ".", "size", "(", "-", "1", ")", ")", "\n", "mask", "=", "(", "indices_by_batch", ">=", "0", ")", "\n", "\n", "return", "batch_indices", ".", "long", "(", ")", ",", "indices_by_batch", ".", "long", "(", ")", ",", "mask", ".", "long", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.scifact_joint_paragraph_kgat_prediction.post_process_stance": [[142, 150], ["zip", "len", "len", "rationale_pred[].items", "len"], "function", ["None"], ["", "def", "post_process_stance", "(", "rationale_json", ",", "stance_json", ")", ":", "\n", "    ", "assert", "(", "len", "(", "rationale_json", ")", "==", "len", "(", "stance_json", ")", ")", "\n", "for", "stance_pred", ",", "rationale_pred", "in", "zip", "(", "stance_json", ",", "rationale_json", ")", ":", "\n", "        ", "assert", "(", "stance_pred", "[", "\"claim_id\"", "]", "==", "rationale_pred", "[", "\"claim_id\"", "]", ")", "\n", "for", "doc_id", ",", "pred", "in", "rationale_pred", "[", "\"evidence\"", "]", ".", "items", "(", ")", ":", "\n", "            ", "if", "len", "(", "pred", ")", "==", "0", ":", "\n", "                ", "stance_pred", "[", "\"labels\"", "]", "[", "doc_id", "]", "[", "\"label\"", "]", "=", "\"NOT_ENOUGH_INFO\"", "\n", "", "", "", "return", "stance_json", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.scifact_joint_paragraph_dynamic_prediction.reset_random_seed": [[29, 33], ["numpy.random.seed", "random.seed", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed"], "function", ["None"], ["def", "reset_random_seed", "(", "seed", ")", ":", "\n", "    ", "np", ".", "random", ".", "seed", "(", "seed", ")", "\n", "random", ".", "seed", "(", "seed", ")", "\n", "torch", ".", "manual_seed", "(", "seed", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.scifact_joint_paragraph_dynamic_prediction.predict": [[34, 54], ["model.eval", "torch.no_grad", "torch.no_grad", "torch.no_grad", "tqdm.tqdm", "torch.utils.data.DataLoader", "scifact_joint_paragraph_dynamic_prediction.encode", "scifact_joint_paragraph_dynamic_prediction.token_idx_by_sentence", "model", "stance_preds.extend", "rationale_predictions.extend", "tensor.to", "tensor.to", "scifact_joint_paragraph_dynamic_prediction.predict.remove_dummy"], "function", ["home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.label_prediction.transformer_scifact.encode", "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.FEVER_stance_paragraph.token_idx_by_sentence", "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.src.utils.remove_dummy"], ["", "def", "predict", "(", "model", ",", "dataset", ")", ":", "\n", "    ", "model", ".", "eval", "(", ")", "\n", "rationale_predictions", "=", "[", "]", "\n", "stance_preds", "=", "[", "]", "\n", "\n", "def", "remove_dummy", "(", "rationale_out", ")", ":", "\n", "        ", "return", "[", "out", "[", "1", ":", "]", "for", "out", "in", "rationale_out", "]", "\n", "\n", "", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "for", "batch", "in", "tqdm", "(", "DataLoader", "(", "dataset", ",", "batch_size", "=", "args", ".", "batch_size", ",", "shuffle", "=", "False", ")", ")", ":", "\n", "            ", "encoded_dict", "=", "encode", "(", "tokenizer", ",", "batch", ")", "\n", "transformation_indices", "=", "token_idx_by_sentence", "(", "encoded_dict", "[", "\"input_ids\"", "]", ",", "\n", "tokenizer", ".", "sep_token_id", ",", "args", ".", "repfile", ")", "\n", "encoded_dict", "=", "{", "key", ":", "tensor", ".", "to", "(", "device", ")", "for", "key", ",", "tensor", "in", "encoded_dict", ".", "items", "(", ")", "}", "\n", "transformation_indices", "=", "[", "tensor", ".", "to", "(", "device", ")", "for", "tensor", "in", "transformation_indices", "]", "\n", "rationale_out", ",", "stance_out", ",", "_", ",", "_", "=", "model", "(", "encoded_dict", ",", "transformation_indices", ")", "\n", "stance_preds", ".", "extend", "(", "stance_out", ")", "\n", "rationale_predictions", ".", "extend", "(", "remove_dummy", "(", "rationale_out", ")", ")", "\n", "\n", "", "", "return", "rationale_predictions", ",", "stance_preds", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.scifact_joint_paragraph_dynamic_prediction.encode": [[56, 104], ["zip", "tokenizer.batch_encode_plus", "torch.cat", "torch.cat", "torch.cat", "encoded_dict[].size", "len", "numpy.sum", "numpy.argmax", "valid_paragraph.size", "all_paragraphs.append", "longest_first_truncation"], "function", ["home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.dataset.encode.longest_first_truncation"], ["", "def", "encode", "(", "tokenizer", ",", "batch", ",", "max_sent_len", "=", "512", ")", ":", "\n", "    ", "def", "truncate", "(", "input_ids", ",", "max_length", ",", "sep_token_id", ",", "pad_token_id", ")", ":", "\n", "        ", "def", "longest_first_truncation", "(", "sentences", ",", "objective", ")", ":", "\n", "            ", "sent_lens", "=", "[", "len", "(", "sent", ")", "for", "sent", "in", "sentences", "]", "\n", "while", "np", ".", "sum", "(", "sent_lens", ")", ">", "objective", ":", "\n", "                ", "max_position", "=", "np", ".", "argmax", "(", "sent_lens", ")", "\n", "sent_lens", "[", "max_position", "]", "-=", "1", "\n", "", "return", "[", "sentence", "[", ":", "length", "]", "for", "sentence", ",", "length", "in", "zip", "(", "sentences", ",", "sent_lens", ")", "]", "\n", "\n", "", "all_paragraphs", "=", "[", "]", "\n", "for", "paragraph", "in", "input_ids", ":", "\n", "            ", "valid_paragraph", "=", "paragraph", "[", "paragraph", "!=", "pad_token_id", "]", "\n", "if", "valid_paragraph", ".", "size", "(", "0", ")", "<=", "max_length", ":", "\n", "                ", "all_paragraphs", ".", "append", "(", "paragraph", "[", ":", "max_length", "]", ".", "unsqueeze", "(", "0", ")", ")", "\n", "", "else", ":", "\n", "                ", "sep_token_idx", "=", "np", ".", "arange", "(", "valid_paragraph", ".", "size", "(", "0", ")", ")", "[", "(", "valid_paragraph", "==", "sep_token_id", ")", ".", "numpy", "(", ")", "]", "\n", "idx_by_sentence", "=", "[", "]", "\n", "prev_idx", "=", "0", "\n", "for", "idx", "in", "sep_token_idx", ":", "\n", "                    ", "idx_by_sentence", ".", "append", "(", "paragraph", "[", "prev_idx", ":", "idx", "]", ")", "\n", "prev_idx", "=", "idx", "\n", "", "objective", "=", "max_length", "-", "1", "-", "len", "(", "idx_by_sentence", "[", "0", "]", ")", "# The last sep_token left out", "\n", "truncated_sentences", "=", "longest_first_truncation", "(", "idx_by_sentence", "[", "1", ":", "]", ",", "objective", ")", "\n", "truncated_paragraph", "=", "torch", ".", "cat", "(", "[", "idx_by_sentence", "[", "0", "]", "]", "+", "truncated_sentences", "+", "[", "torch", ".", "tensor", "(", "[", "sep_token_id", "]", ")", "]", ",", "0", ")", "\n", "all_paragraphs", ".", "append", "(", "truncated_paragraph", ".", "unsqueeze", "(", "0", ")", ")", "\n", "\n", "", "", "return", "torch", ".", "cat", "(", "all_paragraphs", ",", "0", ")", "\n", "\n", "", "inputs", "=", "zip", "(", "batch", "[", "\"claim\"", "]", ",", "batch", "[", "\"paragraph\"", "]", ")", "\n", "encoded_dict", "=", "tokenizer", ".", "batch_encode_plus", "(", "\n", "inputs", ",", "\n", "pad_to_max_length", "=", "True", ",", "add_special_tokens", "=", "True", ",", "\n", "return_tensors", "=", "'pt'", ")", "\n", "if", "encoded_dict", "[", "'input_ids'", "]", ".", "size", "(", "1", ")", ">", "max_sent_len", ":", "\n", "        ", "if", "'token_type_ids'", "in", "encoded_dict", ":", "\n", "            ", "encoded_dict", "=", "{", "\n", "\"input_ids\"", ":", "truncate", "(", "encoded_dict", "[", "'input_ids'", "]", ",", "max_sent_len", ",", "\n", "tokenizer", ".", "sep_token_id", ",", "tokenizer", ".", "pad_token_id", ")", ",", "\n", "'token_type_ids'", ":", "encoded_dict", "[", "'token_type_ids'", "]", "[", ":", ",", ":", "max_sent_len", "]", ",", "\n", "'attention_mask'", ":", "encoded_dict", "[", "'attention_mask'", "]", "[", ":", ",", ":", "max_sent_len", "]", "\n", "}", "\n", "", "else", ":", "\n", "            ", "encoded_dict", "=", "{", "\n", "\"input_ids\"", ":", "truncate", "(", "encoded_dict", "[", "'input_ids'", "]", ",", "max_sent_len", ",", "\n", "tokenizer", ".", "sep_token_id", ",", "tokenizer", ".", "pad_token_id", ")", ",", "\n", "'attention_mask'", ":", "encoded_dict", "[", "'attention_mask'", "]", "[", ":", ",", ":", "max_sent_len", "]", "\n", "}", "\n", "", "", "return", "encoded_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.scifact_joint_paragraph_dynamic_prediction.token_idx_by_sentence": [[105, 133], ["torch.sum().numpy().tolist", "torch.sum().numpy().tolist", "torch.sum().numpy().tolist", "torch.arange().unsqueeze().expand", "torch.arange().unsqueeze().expand", "torch.arange().unsqueeze().expand", "torch.split", "torch.split", "torch.split", "torch.utils.rnn.pad_sequence", "torch.split", "torch.split", "torch.split", "torch.utils.rnn.pad_sequence", "torch.arange().unsqueeze().unsqueeze().expand", "torch.arange().unsqueeze().unsqueeze().expand", "torch.arange().unsqueeze().unsqueeze().expand", "sep_tokens.size", "torch.sum().numpy().tolist.append", "all_word_indices.extend", "nn.utils.rnn.pad_sequence.size", "nn.utils.rnn.pad_sequence.size", "torch.arange().unsqueeze().unsqueeze().expand.long", "nn.utils.rnn.pad_sequence.long", "mask.long", "torch.sum().numpy", "torch.sum().numpy", "torch.sum().numpy", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange", "torch.arange", "torch.arange", "len", "torch.arange().unsqueeze().unsqueeze", "torch.arange().unsqueeze().unsqueeze", "torch.arange().unsqueeze().unsqueeze", "range", "torch.sum", "torch.sum", "torch.sum", "torch.arange", "torch.arange", "torch.arange", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "sep_tokens.size", "paragraph.size", "torch.arange", "torch.arange", "torch.arange", "sep_tokens.size"], "function", ["None"], ["", "def", "token_idx_by_sentence", "(", "input_ids", ",", "sep_token_id", ",", "model_name", ")", ":", "\n", "    ", "\"\"\"\n    Compute the token indices matrix of the BERT output.\n    input_ids: (batch_size, paragraph_len)\n    batch_indices, indices_by_batch, mask: (batch_size, N_sentence, N_token)\n    bert_out: (batch_size, paragraph_len,BERT_dim)\n    bert_out[batch_indices,indices_by_batch,:]: (batch_size, N_sentence, N_token, BERT_dim)\n    \"\"\"", "\n", "padding_idx", "=", "-", "1", "\n", "sep_tokens", "=", "(", "input_ids", "==", "sep_token_id", ")", ".", "bool", "(", ")", "\n", "paragraph_lens", "=", "torch", ".", "sum", "(", "sep_tokens", ",", "1", ")", ".", "numpy", "(", ")", ".", "tolist", "(", ")", "\n", "indices", "=", "torch", ".", "arange", "(", "sep_tokens", ".", "size", "(", "-", "1", ")", ")", ".", "unsqueeze", "(", "0", ")", ".", "expand", "(", "sep_tokens", ".", "size", "(", "0", ")", ",", "-", "1", ")", "\n", "sep_indices", "=", "torch", ".", "split", "(", "indices", "[", "sep_tokens", "]", ",", "paragraph_lens", ")", "\n", "paragraph_lens", "=", "[", "]", "\n", "all_word_indices", "=", "[", "]", "\n", "for", "paragraph", "in", "sep_indices", ":", "\n", "        ", "if", "\"roberta\"", "in", "model_name", ":", "\n", "            ", "paragraph", "=", "paragraph", "[", "1", ":", "]", "\n", "", "word_indices", "=", "[", "torch", ".", "arange", "(", "paragraph", "[", "i", "]", "+", "1", ",", "paragraph", "[", "i", "+", "1", "]", "+", "1", ")", "for", "i", "in", "range", "(", "paragraph", ".", "size", "(", "0", ")", "-", "1", ")", "]", "\n", "paragraph_lens", ".", "append", "(", "len", "(", "word_indices", ")", ")", "\n", "all_word_indices", ".", "extend", "(", "word_indices", ")", "\n", "", "indices_by_sentence", "=", "nn", ".", "utils", ".", "rnn", ".", "pad_sequence", "(", "all_word_indices", ",", "batch_first", "=", "True", ",", "padding_value", "=", "padding_idx", ")", "\n", "indices_by_sentence_split", "=", "torch", ".", "split", "(", "indices_by_sentence", ",", "paragraph_lens", ")", "\n", "indices_by_batch", "=", "nn", ".", "utils", ".", "rnn", ".", "pad_sequence", "(", "indices_by_sentence_split", ",", "batch_first", "=", "True", ",", "padding_value", "=", "padding_idx", ")", "\n", "batch_indices", "=", "torch", ".", "arange", "(", "sep_tokens", ".", "size", "(", "0", ")", ")", ".", "unsqueeze", "(", "-", "1", ")", ".", "unsqueeze", "(", "-", "1", ")", ".", "expand", "(", "-", "1", ",", "indices_by_batch", ".", "size", "(", "1", ")", ",", "indices_by_batch", ".", "size", "(", "-", "1", ")", ")", "\n", "mask", "=", "(", "indices_by_batch", ">=", "0", ")", "\n", "\n", "return", "batch_indices", ".", "long", "(", ")", ",", "indices_by_batch", ".", "long", "(", ")", ",", "mask", ".", "long", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.scifact_joint_paragraph_dynamic_prediction.post_process_stance": [[134, 142], ["zip", "len", "len", "rationale_pred[].items", "len"], "function", ["None"], ["", "def", "post_process_stance", "(", "rationale_json", ",", "stance_json", ")", ":", "\n", "    ", "assert", "(", "len", "(", "rationale_json", ")", "==", "len", "(", "stance_json", ")", ")", "\n", "for", "stance_pred", ",", "rationale_pred", "in", "zip", "(", "stance_json", ",", "rationale_json", ")", ":", "\n", "        ", "assert", "(", "stance_pred", "[", "\"claim_id\"", "]", "==", "rationale_pred", "[", "\"claim_id\"", "]", ")", "\n", "for", "doc_id", ",", "pred", "in", "rationale_pred", "[", "\"evidence\"", "]", ".", "items", "(", ")", ":", "\n", "            ", "if", "len", "(", "pred", ")", "==", "0", ":", "\n", "                ", "stance_pred", "[", "\"labels\"", "]", "[", "doc_id", "]", "[", "\"label\"", "]", "=", "\"NOT_ENOUGH_INFO\"", "\n", "", "", "", "return", "stance_json", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.scifact_joint_paragraph_dynamic_prediction.post_process_rationale_score": [[143, 154], ["numpy.array", "np.zeros.tolist", "scifact_joint_paragraph_dynamic_prediction.post_process_rationale_score.process_rationale_score"], "function", ["None"], ["", "def", "post_process_rationale_score", "(", "rationale_scores", ",", "max_positive", "=", "3", ")", ":", "### Doesn't seem to be helpful?", "\n", "    ", "def", "process_rationale_score", "(", "paragraph_rationale_scores", ")", ":", "\n", "        ", "paragraph_rationale_scores", "=", "np", ".", "array", "(", "paragraph_rationale_scores", ")", "\n", "if", "np", ".", "sum", "(", "paragraph_rationale_scores", ">", "0.5", ")", ">", "max_positive", ":", "\n", "            ", "output", "=", "np", ".", "zeros", "(", "paragraph_rationale_scores", ".", "shape", ")", "\n", "positive_indices", "=", "np", ".", "argsort", "(", "paragraph_rationale_scores", ")", "[", ":", ":", "-", "1", "]", "[", ":", "max_positive", "]", "\n", "output", "[", "positive_indices", "]", "=", "1", "\n", "", "else", ":", "\n", "            ", "output", "=", "(", "paragraph_rationale_scores", ">", "0.5", ")", ".", "astype", "(", "int", ")", "\n", "", "return", "output", ".", "tolist", "(", ")", "\n", "", "return", "[", "process_rationale_score", "(", "paragraph_rationale_scores", ")", "for", "paragraph_rationale_scores", "in", "rationale_scores", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.FEVER_stance_paragraph.reset_random_seed": [[29, 33], ["numpy.random.seed", "random.seed", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed"], "function", ["None"], ["def", "reset_random_seed", "(", "seed", ")", ":", "\n", "    ", "np", ".", "random", ".", "seed", "(", "seed", ")", "\n", "random", ".", "seed", "(", "seed", ")", "\n", "torch", ".", "manual_seed", "(", "seed", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.FEVER_stance_paragraph.evaluation": [[34, 56], ["model.eval", "sklearn.metrics.f1_score", "sklearn.metrics.precision_score", "sklearn.metrics.recall_score", "torch.no_grad", "torch.no_grad", "torch.no_grad", "tqdm.tqdm", "torch.utils.data.DataLoader", "FEVER_stance_paragraph.encode", "FEVER_stance_paragraph.token_idx_by_sentence", "batch[].to", "model", "stance_preds.extend", "stance_labels.extend", "tensor.to", "tensor.to", "batch[].to.cpu().numpy().tolist", "encode.items", "batch[].to.cpu().numpy", "batch[].to.cpu"], "function", ["home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.label_prediction.transformer_scifact.encode", "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.FEVER_stance_paragraph.token_idx_by_sentence"], ["", "def", "evaluation", "(", "model", ",", "dataset", ")", ":", "\n", "    ", "model", ".", "eval", "(", ")", "\n", "stance_preds", "=", "[", "]", "\n", "stance_labels", "=", "[", "]", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "for", "batch", "in", "tqdm", "(", "DataLoader", "(", "dataset", ",", "batch_size", "=", "args", ".", "batch_size", ",", "shuffle", "=", "False", ")", ")", ":", "\n", "            ", "encoded_dict", "=", "encode", "(", "tokenizer", ",", "batch", ")", "\n", "transformation_indices", "=", "token_idx_by_sentence", "(", "encoded_dict", "[", "\"input_ids\"", "]", ",", "\n", "tokenizer", ".", "sep_token_id", ",", "args", ".", "repfile", ")", "\n", "encoded_dict", "=", "{", "key", ":", "tensor", ".", "to", "(", "device", ")", "for", "key", ",", "tensor", "in", "encoded_dict", ".", "items", "(", ")", "}", "\n", "transformation_indices", "=", "[", "tensor", ".", "to", "(", "device", ")", "for", "tensor", "in", "transformation_indices", "]", "\n", "stance_label", "=", "batch", "[", "\"stance\"", "]", ".", "to", "(", "device", ")", "\n", "stance_out", ",", "stance_loss", "=", "model", "(", "encoded_dict", ",", "transformation_indices", ",", "stance_label", "=", "stance_label", ")", "\n", "stance_preds", ".", "extend", "(", "stance_out", ")", "\n", "stance_labels", ".", "extend", "(", "stance_label", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "tolist", "(", ")", ")", "\n", "\n", "", "", "stance_f1", "=", "f1_score", "(", "stance_labels", ",", "stance_preds", ",", "average", "=", "\"micro\"", ",", "labels", "=", "[", "1", ",", "2", "]", ")", "\n", "stance_precision", "=", "precision_score", "(", "stance_labels", ",", "stance_preds", ",", "average", "=", "\"micro\"", ",", "labels", "=", "[", "1", ",", "2", "]", ")", "\n", "stance_recall", "=", "recall_score", "(", "stance_labels", ",", "stance_preds", ",", "average", "=", "\"micro\"", ",", "labels", "=", "[", "1", ",", "2", "]", ")", "\n", "return", "stance_f1", ",", "stance_precision", ",", "stance_recall", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.FEVER_stance_paragraph.encode": [[58, 107], ["zip", "tokenizer.batch_encode_plus", "torch.cat", "torch.cat", "torch.cat", "encoded_dict[].size", "len", "numpy.sum", "numpy.argmax", "valid_paragraph.size", "all_paragraphs.append", "longest_first_truncation"], "function", ["home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.dataset.encode.longest_first_truncation"], ["", "def", "encode", "(", "tokenizer", ",", "batch", ",", "max_sent_len", "=", "512", ")", ":", "\n", "    ", "def", "truncate", "(", "input_ids", ",", "max_length", ",", "sep_token_id", ",", "pad_token_id", ")", ":", "\n", "        ", "def", "longest_first_truncation", "(", "sentences", ",", "objective", ")", ":", "\n", "            ", "sent_lens", "=", "[", "len", "(", "sent", ")", "for", "sent", "in", "sentences", "]", "\n", "while", "np", ".", "sum", "(", "sent_lens", ")", ">", "objective", ":", "\n", "                ", "max_position", "=", "np", ".", "argmax", "(", "sent_lens", ")", "\n", "sent_lens", "[", "max_position", "]", "-=", "1", "\n", "", "return", "[", "sentence", "[", ":", "length", "]", "for", "sentence", ",", "length", "in", "zip", "(", "sentences", ",", "sent_lens", ")", "]", "\n", "\n", "", "all_paragraphs", "=", "[", "]", "\n", "for", "paragraph", "in", "input_ids", ":", "\n", "            ", "valid_paragraph", "=", "paragraph", "[", "paragraph", "!=", "pad_token_id", "]", "\n", "if", "valid_paragraph", ".", "size", "(", "0", ")", "<=", "max_length", ":", "\n", "                ", "all_paragraphs", ".", "append", "(", "paragraph", "[", ":", "max_length", "]", ".", "unsqueeze", "(", "0", ")", ")", "\n", "", "else", ":", "\n", "                ", "sep_token_idx", "=", "np", ".", "arange", "(", "valid_paragraph", ".", "size", "(", "0", ")", ")", "[", "(", "valid_paragraph", "==", "sep_token_id", ")", ".", "numpy", "(", ")", "]", "\n", "idx_by_sentence", "=", "[", "]", "\n", "prev_idx", "=", "0", "\n", "for", "idx", "in", "sep_token_idx", ":", "\n", "                    ", "idx_by_sentence", ".", "append", "(", "paragraph", "[", "prev_idx", ":", "idx", "]", ")", "\n", "prev_idx", "=", "idx", "\n", "", "objective", "=", "max_length", "-", "1", "-", "len", "(", "idx_by_sentence", "[", "0", "]", ")", "# The last sep_token left out", "\n", "truncated_sentences", "=", "longest_first_truncation", "(", "idx_by_sentence", "[", "1", ":", "]", ",", "objective", ")", "\n", "truncated_paragraph", "=", "torch", ".", "cat", "(", "[", "idx_by_sentence", "[", "0", "]", "]", "+", "truncated_sentences", "+", "[", "torch", ".", "tensor", "(", "[", "sep_token_id", "]", ")", "]", ",", "0", ")", "\n", "all_paragraphs", ".", "append", "(", "truncated_paragraph", ".", "unsqueeze", "(", "0", ")", ")", "\n", "\n", "", "", "return", "torch", ".", "cat", "(", "all_paragraphs", ",", "0", ")", "\n", "\n", "", "inputs", "=", "zip", "(", "batch", "[", "\"claim\"", "]", ",", "batch", "[", "\"paragraph\"", "]", ")", "\n", "encoded_dict", "=", "tokenizer", ".", "batch_encode_plus", "(", "\n", "inputs", ",", "\n", "pad_to_max_length", "=", "True", ",", "add_special_tokens", "=", "True", ",", "\n", "return_tensors", "=", "'pt'", ")", "\n", "if", "encoded_dict", "[", "'input_ids'", "]", ".", "size", "(", "1", ")", ">", "max_sent_len", ":", "\n", "        ", "if", "'token_type_ids'", "in", "encoded_dict", ":", "\n", "            ", "encoded_dict", "=", "{", "\n", "\"input_ids\"", ":", "truncate", "(", "encoded_dict", "[", "'input_ids'", "]", ",", "max_sent_len", ",", "\n", "tokenizer", ".", "sep_token_id", ",", "tokenizer", ".", "pad_token_id", ")", ",", "\n", "'token_type_ids'", ":", "encoded_dict", "[", "'token_type_ids'", "]", "[", ":", ",", ":", "max_sent_len", "]", ",", "\n", "'attention_mask'", ":", "encoded_dict", "[", "'attention_mask'", "]", "[", ":", ",", ":", "max_sent_len", "]", "\n", "}", "\n", "", "else", ":", "\n", "            ", "encoded_dict", "=", "{", "\n", "\"input_ids\"", ":", "truncate", "(", "encoded_dict", "[", "'input_ids'", "]", ",", "max_sent_len", ",", "\n", "tokenizer", ".", "sep_token_id", ",", "tokenizer", ".", "pad_token_id", ")", ",", "\n", "'attention_mask'", ":", "encoded_dict", "[", "'attention_mask'", "]", "[", ":", ",", ":", "max_sent_len", "]", "\n", "}", "\n", "\n", "", "", "return", "encoded_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.ParagraphJointModel-main.FEVER_stance_paragraph.token_idx_by_sentence": [[108, 136], ["torch.sum().numpy().tolist", "torch.sum().numpy().tolist", "torch.sum().numpy().tolist", "torch.arange().unsqueeze().expand", "torch.arange().unsqueeze().expand", "torch.arange().unsqueeze().expand", "torch.split", "torch.split", "torch.split", "torch.utils.rnn.pad_sequence", "torch.split", "torch.split", "torch.split", "torch.utils.rnn.pad_sequence", "torch.arange().unsqueeze().unsqueeze().expand", "torch.arange().unsqueeze().unsqueeze().expand", "torch.arange().unsqueeze().unsqueeze().expand", "sep_tokens.size", "torch.sum().numpy().tolist.append", "all_word_indices.extend", "nn.utils.rnn.pad_sequence.size", "nn.utils.rnn.pad_sequence.size", "torch.arange().unsqueeze().unsqueeze().expand.long", "nn.utils.rnn.pad_sequence.long", "mask.long", "torch.sum().numpy", "torch.sum().numpy", "torch.sum().numpy", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange", "torch.arange", "torch.arange", "len", "torch.arange().unsqueeze().unsqueeze", "torch.arange().unsqueeze().unsqueeze", "torch.arange().unsqueeze().unsqueeze", "range", "torch.sum", "torch.sum", "torch.sum", "torch.arange", "torch.arange", "torch.arange", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "sep_tokens.size", "paragraph.size", "torch.arange", "torch.arange", "torch.arange", "sep_tokens.size"], "function", ["None"], ["", "def", "token_idx_by_sentence", "(", "input_ids", ",", "sep_token_id", ",", "model_name", ")", ":", "\n", "    ", "\"\"\"\n    Compute the token indices matrix of the BERT output.\n    input_ids: (batch_size, paragraph_len)\n    batch_indices, indices_by_batch, mask: (batch_size, N_sentence, N_token)\n    bert_out: (batch_size, paragraph_len,BERT_dim)\n    bert_out[batch_indices,indices_by_batch,:]: (batch_size, N_sentence, N_token, BERT_dim)\n    \"\"\"", "\n", "padding_idx", "=", "-", "1", "\n", "sep_tokens", "=", "(", "input_ids", "==", "sep_token_id", ")", ".", "bool", "(", ")", "\n", "paragraph_lens", "=", "torch", ".", "sum", "(", "sep_tokens", ",", "1", ")", ".", "numpy", "(", ")", ".", "tolist", "(", ")", "\n", "indices", "=", "torch", ".", "arange", "(", "sep_tokens", ".", "size", "(", "-", "1", ")", ")", ".", "unsqueeze", "(", "0", ")", ".", "expand", "(", "sep_tokens", ".", "size", "(", "0", ")", ",", "-", "1", ")", "\n", "sep_indices", "=", "torch", ".", "split", "(", "indices", "[", "sep_tokens", "]", ",", "paragraph_lens", ")", "\n", "paragraph_lens", "=", "[", "]", "\n", "all_word_indices", "=", "[", "]", "\n", "for", "paragraph", "in", "sep_indices", ":", "\n", "        ", "if", "\"roberta\"", "in", "model_name", ":", "\n", "            ", "paragraph", "=", "paragraph", "[", "1", ":", "]", "\n", "", "word_indices", "=", "[", "torch", ".", "arange", "(", "paragraph", "[", "i", "]", "+", "1", ",", "paragraph", "[", "i", "+", "1", "]", "+", "1", ")", "for", "i", "in", "range", "(", "paragraph", ".", "size", "(", "0", ")", "-", "1", ")", "]", "\n", "paragraph_lens", ".", "append", "(", "len", "(", "word_indices", ")", ")", "\n", "all_word_indices", ".", "extend", "(", "word_indices", ")", "\n", "", "indices_by_sentence", "=", "nn", ".", "utils", ".", "rnn", ".", "pad_sequence", "(", "all_word_indices", ",", "batch_first", "=", "True", ",", "padding_value", "=", "padding_idx", ")", "\n", "indices_by_sentence_split", "=", "torch", ".", "split", "(", "indices_by_sentence", ",", "paragraph_lens", ")", "\n", "indices_by_batch", "=", "nn", ".", "utils", ".", "rnn", ".", "pad_sequence", "(", "indices_by_sentence_split", ",", "batch_first", "=", "True", ",", "padding_value", "=", "padding_idx", ")", "\n", "batch_indices", "=", "torch", ".", "arange", "(", "sep_tokens", ".", "size", "(", "0", ")", ")", ".", "unsqueeze", "(", "-", "1", ")", ".", "unsqueeze", "(", "-", "1", ")", ".", "expand", "(", "-", "1", ",", "indices_by_batch", ".", "size", "(", "1", ")", ",", "indices_by_batch", ".", "size", "(", "-", "1", ")", ")", "\n", "mask", "=", "(", "indices_by_batch", ">=", "0", ")", "\n", "\n", "return", "batch_indices", ".", "long", "(", ")", ",", "indices_by_batch", ".", "long", "(", ")", ",", "mask", ".", "long", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.lib.metrics.safe_divide": [[17, 22], ["None"], "function", ["None"], ["def", "safe_divide", "(", "num", ",", "denom", ")", ":", "\n", "    ", "if", "denom", "==", "0", ":", "\n", "        ", "return", "0", "\n", "", "else", ":", "\n", "        ", "return", "num", "/", "denom", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.lib.metrics.compute_f1": [[24, 30], ["metrics.safe_divide", "metrics.safe_divide", "metrics.safe_divide"], "function", ["home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.lib.metrics.safe_divide", "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.lib.metrics.safe_divide", "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.lib.metrics.safe_divide"], ["", "", "def", "compute_f1", "(", "counts", ",", "difficulty", "=", "None", ")", ":", "\n", "    ", "correct_key", "=", "\"correct\"", "if", "difficulty", "is", "None", "else", "f\"correct_{difficulty}\"", "\n", "precision", "=", "safe_divide", "(", "counts", "[", "correct_key", "]", ",", "counts", "[", "\"retrieved\"", "]", ")", "\n", "recall", "=", "safe_divide", "(", "counts", "[", "correct_key", "]", ",", "counts", "[", "\"relevant\"", "]", ")", "\n", "f1", "=", "safe_divide", "(", "2", "*", "precision", "*", "recall", ",", "precision", "+", "recall", ")", "\n", "return", "{", "\"precision\"", ":", "precision", ",", "\"recall\"", ":", "recall", ",", "\"f1\"", ":", "f1", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.lib.metrics.contains_evidence": [[36, 43], ["gold_rat.issubset"], "function", ["None"], ["\n", "\n", "\n", "def", "contains_evidence", "(", "predicted", ",", "gold", ")", ":", "\n", "# If any of gold are contained in predicted, we're good.", "\n", "    ", "for", "gold_rat", "in", "gold", ":", "\n", "        ", "if", "gold_rat", ".", "issubset", "(", "predicted", ")", ":", "\n", "            ", "return", "True", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.lib.metrics.is_correct": [[45, 61], ["metrics.contains_evidence", "set", "set"], "function", ["home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.lib.metrics.contains_evidence"], ["", "", "return", "False", "\n", "\n", "\n", "", "def", "is_correct", "(", "doc_id", ",", "doc_pred", ",", "gold", ")", ":", "\n", "    ", "pred_rationales", "=", "doc_pred", ".", "rationale", "[", ":", "MAX_ABSTRACT_SENTS", "]", "\n", "\n", "# If it's not an evidence document, we lose.", "\n", "if", "doc_id", "not", "in", "gold", ".", "evidence", ":", "\n", "        ", "return", "False", ",", "False", "\n", "\n", "# If the label's wrong, we lose.", "\n", "", "gold_label", "=", "gold", ".", "evidence", "[", "doc_id", "]", ".", "label", "\n", "if", "doc_pred", ".", "label", "!=", "gold_label", ":", "\n", "        ", "return", "False", ",", "False", "\n", "\n", "", "gold_rationales", "=", "[", "set", "(", "x", ")", "for", "x", "in", "gold", ".", "evidence", "[", "doc_id", "]", ".", "rationales", "]", "\n", "good_rationalized", "=", "contains_evidence", "(", "set", "(", "pred_rationales", ")", ",", "gold_rationales", ")", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.lib.metrics.update_counts_abstract": [[63, 78], ["len", "pred.predictions.items", "metrics.is_correct"], "function", ["home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.lib.metrics.is_correct"], ["return", "good_label_only", ",", "good_rationalized", "\n", "\n", "\n", "", "def", "update_counts_abstract", "(", "pred", ",", "gold", ",", "counts_abstract", ")", ":", "\n", "    ", "counts_abstract", "[", "\"relevant\"", "]", "+=", "len", "(", "gold", ".", "evidence", ")", "\n", "for", "doc_id", ",", "doc_pred", "in", "pred", ".", "predictions", ".", "items", "(", ")", ":", "\n", "# If it's NEI, doesn't count one way or the other.", "\n", "        ", "if", "doc_pred", ".", "label", "==", "Label", ".", "NEI", ":", "\n", "            ", "continue", "\n", "", "counts_abstract", "[", "\"retrieved\"", "]", "+=", "1", "\n", "\n", "good_label_only", ",", "good_rationalized", "=", "is_correct", "(", "doc_id", ",", "doc_pred", ",", "gold", ")", "\n", "if", "good_label_only", ":", "\n", "            ", "counts_abstract", "[", "\"correct_label_only\"", "]", "+=", "1", "\n", "", "if", "good_rationalized", ":", "\n", "            ", "counts_abstract", "[", "\"correct_rationalized\"", "]", "+=", "1", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.lib.metrics.count_rationale_sents": [[84, 99], ["gold_set.issubset", "len", "len"], "function", ["None"], ["\n", "\n", "\n", "def", "count_rationale_sents", "(", "predicted", ",", "gold", ")", ":", "\n", "    ", "n_correct", "=", "0", "\n", "\n", "for", "ix", "in", "predicted", ":", "\n", "        ", "gold_sets", "=", "[", "entry", "for", "entry", "in", "gold", "if", "ix", "in", "entry", "]", "\n", "assert", "len", "(", "gold_sets", ")", "<", "2", "# Can't be in two rationales.", "\n", "# If it's not in a gold set, no dice.", "\n", "if", "len", "(", "gold_sets", ")", "==", "0", ":", "\n", "            ", "continue", "\n", "# If it's in a gold set, make sure the rest got retrieved.", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.lib.metrics.count_correct": [[101, 117], ["metrics.count_rationale_sents", "int", "set", "set"], "function", ["home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.lib.metrics.count_rationale_sents"], ["if", "gold_set", ".", "issubset", "(", "predicted", ")", ":", "\n", "            ", "n_correct", "+=", "1", "\n", "\n", "", "", "return", "n_correct", "\n", "\n", "\n", "", "def", "count_correct", "(", "doc_id", ",", "doc_pred", ",", "gold", ")", ":", "\n", "# If not an evidence doc, no good.", "\n", "    ", "if", "doc_id", "not", "in", "gold", ".", "evidence", ":", "\n", "        ", "return", "0", ",", "0", "\n", "\n", "# Count the number of rationale sentences we get credit for.", "\n", "", "gold_rationales", "=", "[", "set", "(", "x", ")", "for", "x", "in", "gold", ".", "evidence", "[", "doc_id", "]", ".", "rationales", "]", "\n", "n_correct", "=", "count_rationale_sents", "(", "set", "(", "doc_pred", ".", "rationale", ")", ",", "gold_rationales", ")", "\n", "\n", "gold_label", "=", "gold", ".", "evidence", "[", "doc_id", "]", ".", "label", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.lib.metrics.update_counts_sentence": [[119, 135], ["gold.evidence.values", "pred.predictions.items", "sum", "len", "metrics.count_correct", "len"], "function", ["home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.lib.metrics.count_correct"], ["correct_label", "=", "int", "(", "doc_pred", ".", "label", "==", "gold_label", ")", "\n", "n_correct_label", "=", "correct_label", "*", "n_correct", "\n", "\n", "return", "n_correct_selection", ",", "n_correct_label", "\n", "\n", "\n", "", "def", "update_counts_sentence", "(", "pred", ",", "gold", ",", "counts_sentence", ")", ":", "\n", "# Update the gold evidence sentences.", "\n", "    ", "for", "gold_doc", "in", "gold", ".", "evidence", ".", "values", "(", ")", ":", "\n", "        ", "counts_sentence", "[", "\"relevant\"", "]", "+=", "sum", "(", "[", "len", "(", "x", ")", "for", "x", "in", "gold_doc", ".", "rationales", "]", ")", "\n", "\n", "", "for", "doc_id", ",", "doc_pred", "in", "pred", ".", "predictions", ".", "items", "(", ")", ":", "\n", "# If it's NEI, skip it.", "\n", "        ", "if", "doc_pred", ".", "label", "==", "Label", ".", "NEI", ":", "\n", "            ", "continue", "\n", "\n", "", "counts_sentence", "[", "\"retrieved\"", "]", "+=", "len", "(", "doc_pred", ".", "rationale", ")", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.lib.metrics.check_rationale_lengths": [[141, 158], ["predictions.items", "pandas.DataFrame", "warnings.warn", "print", "len", "pd.DataFrame.append", "pd.DataFrame.__repr__"], "function", ["home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.lib.data.ClaimPredictions.__repr__"], ["\n", "\n", "", "'''\n# ==================================================================================================================== #\n# Make sure rationales aren't too long.\n# ==================================================================================================================== #\n'''", "\n", "\n", "\n", "def", "check_rationale_lengths", "(", "preds", ")", ":", "\n", "    ", "bad", "=", "[", "]", "\n", "for", "pred", "in", "preds", ":", "\n", "        ", "claim_id", "=", "pred", ".", "claim_id", "\n", "predictions", "=", "pred", ".", "predictions", "\n", "for", "doc_key", ",", "prediction", "in", "predictions", ".", "items", "(", ")", ":", "\n", "            ", "n_rationales", "=", "len", "(", "prediction", ".", "rationale", ")", "\n", "if", "n_rationales", ">", "MAX_ABSTRACT_SENTS", ":", "\n", "                ", "to_append", "=", "{", "\"claim_id\"", ":", "claim_id", ",", "\"abstract\"", ":", "doc_key", ",", "\"n_rationales\"", ":", "n_rationales", "}", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.lib.metrics.compute_metrics": [[162, 181], ["collections.Counter", "collections.Counter", "metrics.check_rationale_lengths", "pandas.DataFrame", "preds.gold.get_claim", "metrics.update_counts_abstract", "metrics.update_counts_sentence", "metrics.compute_f1", "metrics.compute_f1", "metrics.compute_f1", "metrics.compute_f1"], "function", ["home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.lib.metrics.check_rationale_lengths", "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.lib.data.GoldDataset.get_claim", "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.lib.metrics.update_counts_abstract", "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.lib.metrics.update_counts_sentence", "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.lib.metrics.compute_f1", "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.lib.metrics.compute_f1", "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.lib.metrics.compute_f1", "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.lib.metrics.compute_f1"], ["msg", "=", "(", "f\"\\nRationales with more than {MAX_ABSTRACT_SENTS} sentences found.\\n\"", "\n", "f\"The first 3 will be used for abstract-level evaluation\\n\\n\"", "\n", "f\"{bad.__repr__()}\"", ")", "\n", "warnings", ".", "warn", "(", "msg", ")", "\n", "print", "(", ")", "\n", "\n", "\n", "", "", "'''\n# ==================================================================================================================== #\n# ==================================================================================================================== #\n'''", "\n", "\n", "\n", "def", "compute_metrics", "(", "preds", ")", ":", "\n", "    ", "\"\"\"\n    Compute pipeline metrics based on dataset of predictions.\n    \"\"\"", "\n", "counts_abstract", "=", "Counter", "(", ")", "\n", "counts_sentence", "=", "Counter", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.lib.data.Document.__repr__": [[48, 50], ["data.Document.title.upper"], "methods", ["None"], ["def", "__repr__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "title", ".", "upper", "(", ")", "+", "\"\\n\"", "+", "\"\\n\"", ".", "join", "(", "[", "\"- \"", "+", "entry", "for", "entry", "in", "self", ".", "sentences", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.lib.data.Document.__lt__": [[51, 53], ["data.Document.title.__lt__"], "methods", ["home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.lib.data.Document.__lt__"], ["", "def", "__lt__", "(", "self", ",", "other", ")", ":", "\n", "        ", "return", "self", ".", "title", ".", "__lt__", "(", "other", ".", "title", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.lib.data.Document.dump": [[54, 60], ["json.dumps", "data.Document.is_structured"], "methods", ["None"], ["", "def", "dump", "(", "self", ")", ":", "\n", "        ", "res", "=", "{", "\"doc_id\"", ":", "self", ".", "id", ",", "\n", "\"title\"", ":", "self", ".", "title", ",", "\n", "\"abstract\"", ":", "self", ".", "sentences", ",", "\n", "\"structured\"", ":", "self", ".", "is_structured", "(", ")", "}", "\n", "return", "json", ".", "dumps", "(", "res", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.lib.data.Corpus.__repr__": [[70, 72], ["len"], "methods", ["None"], ["def", "__repr__", "(", "self", ")", ":", "\n", "        ", "return", "f\"Corpus of {len(self.documents)} documents.\"", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.lib.data.Corpus.__getitem__": [[73, 76], ["None"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "i", ")", ":", "\n", "        ", "\"Get document by index in list.\"", "\n", "return", "self", ".", "documents", "[", "i", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.lib.data.Corpus.get_document": [[77, 82], ["len"], "methods", ["None"], ["", "def", "get_document", "(", "self", ",", "doc_id", ")", ":", "\n", "        ", "\"Get document by ID.\"", "\n", "res", "=", "[", "x", "for", "x", "in", "self", ".", "documents", "if", "x", ".", "id", "==", "doc_id", "]", "\n", "assert", "len", "(", "res", ")", "==", "1", "\n", "return", "res", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.lib.data.Corpus.from_jsonl": [[83, 92], ["data.load_jsonl", "cls", "data.Document", "documents.append"], "methods", ["home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.lib.data.load_jsonl"], ["", "@", "classmethod", "\n", "def", "from_jsonl", "(", "cls", ",", "corpus_file", ")", ":", "\n", "        ", "corpus", "=", "load_jsonl", "(", "corpus_file", ")", "\n", "documents", "=", "[", "]", "\n", "for", "entry", "in", "corpus", ":", "\n", "            ", "doc", "=", "Document", "(", "entry", "[", "\"doc_id\"", "]", ",", "entry", "[", "\"title\"", "]", ",", "entry", "[", "\"abstract\"", "]", ")", "\n", "documents", ".", "append", "(", "doc", ")", "\n", "\n", "", "return", "cls", "(", "documents", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.lib.data.GoldDataset.__init__": [[102, 105], ["data.Corpus.from_jsonl", "data.GoldDataset._read_claims"], "methods", ["home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.lib.data.Corpus.from_jsonl", "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.lib.data.GoldDataset._read_claims"], ["def", "__init__", "(", "self", ",", "corpus_file", ",", "data_file", ")", ":", "\n", "        ", "self", ".", "corpus", "=", "Corpus", ".", "from_jsonl", "(", "corpus_file", ")", "\n", "self", ".", "claims", "=", "self", ".", "_read_claims", "(", "data_file", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.lib.data.GoldDataset.__repr__": [[106, 109], ["data.GoldDataset.corpus.__repr__", "len"], "methods", ["home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.lib.data.ClaimPredictions.__repr__"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "msg", "=", "f\"{self.corpus.__repr__()} {len(self.claims)} claims.\"", "\n", "return", "msg", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.lib.data.GoldDataset.__getitem__": [[110, 112], ["None"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "i", ")", ":", "\n", "        ", "return", "self", ".", "claims", "[", "i", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.lib.data.GoldDataset._read_claims": [[113, 128], ["data.load_jsonl", "sorted", "copy.deepcopy", "sorted.append", "data.GoldDataset.corpus.get_document", "len", "len", "data.Claim"], "methods", ["home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.lib.data.load_jsonl", "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.lib.data.Corpus.get_document"], ["", "def", "_read_claims", "(", "self", ",", "data_file", ")", ":", "\n", "        ", "\"Read claims from file.\"", "\n", "examples", "=", "load_jsonl", "(", "data_file", ")", "\n", "res", "=", "[", "]", "\n", "for", "this_example", "in", "examples", ":", "\n", "            ", "entry", "=", "copy", ".", "deepcopy", "(", "this_example", ")", "\n", "entry", "[", "\"release\"", "]", "=", "self", "\n", "entry", "[", "\"cited_docs\"", "]", "=", "[", "self", ".", "corpus", ".", "get_document", "(", "doc", ")", "\n", "for", "doc", "in", "entry", "[", "\"cited_doc_ids\"", "]", "]", "\n", "assert", "len", "(", "entry", "[", "\"cited_docs\"", "]", ")", "==", "len", "(", "entry", "[", "\"cited_doc_ids\"", "]", ")", "\n", "del", "entry", "[", "\"cited_doc_ids\"", "]", "\n", "if", "'doc_ids'", "in", "entry", ":", "\n", "                ", "del", "entry", "[", "'doc_ids'", "]", "\n", "", "res", ".", "append", "(", "Claim", "(", "**", "entry", ")", ")", "\n", "\n", "", "res", "=", "sorted", "(", "res", ",", "key", "=", "lambda", "x", ":", "x", ".", "id", ")", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.lib.data.GoldDataset.get_claim": [[129, 134], ["len"], "methods", ["None"], ["return", "res", "\n", "\n", "", "def", "get_claim", "(", "self", ",", "example_id", ")", ":", "\n", "        ", "\"Get a single claim by ID.\"", "\n", "keep", "=", "[", "x", "for", "x", "in", "self", ".", "claims", "if", "x", ".", "id", "==", "example_id", "]", "\n", "assert", "len", "(", "keep", ")", "==", "1", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.lib.data.Claim.__post_init__": [[155, 157], ["data.Claim._format_evidence"], "methods", ["home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.lib.data.Claim._format_evidence"], ["release", ":", "GoldDataset", "\n", "\n", "def", "__post_init__", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.lib.data.Claim._format_evidence": [[158, 179], ["evidence_dict.items", "int", "data.make_label", "data.EvidenceAbstract", "len", "Exception", "set"], "methods", ["home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.lib.data.make_label"], ["        ", "self", ".", "evidence", "=", "self", ".", "_format_evidence", "(", "self", ".", "evidence", ")", "\n", "\n", "", "@", "staticmethod", "\n", "def", "_format_evidence", "(", "evidence_dict", ")", ":", "\n", "# This function is needed because the data schema is designed so that", "\n", "# each rationale can have its own support label. But, in the dataset,", "\n", "# all rationales for a given claim / abstract pair all have the same", "\n", "# label. So, we store the label at the \"abstract level\" rather than the", "\n", "# \"rationale level\".", "\n", "        ", "res", "=", "{", "}", "\n", "for", "doc_id", ",", "rationales", "in", "evidence_dict", ".", "items", "(", ")", ":", "\n", "            ", "doc_id", "=", "int", "(", "doc_id", ")", "\n", "labels", "=", "[", "x", "[", "\"label\"", "]", "for", "x", "in", "rationales", "]", "\n", "if", "len", "(", "set", "(", "labels", ")", ")", ">", "1", ":", "\n", "                ", "msg", "=", "(", "\"In this SciFact release, each claim / abstract pair \"", "\n", "\"should only have one label.\"", ")", "\n", "raise", "Exception", "(", "msg", ")", "\n", "", "label", "=", "make_label", "(", "labels", "[", "0", "]", ")", "\n", "rationale_sents", "=", "[", "x", "[", "\"sentences\"", "]", "for", "x", "in", "rationales", "]", "\n", "this_abstract", "=", "EvidenceAbstract", "(", "doc_id", ",", "label", ",", "rationale_sents", ")", "\n", "res", "[", "doc_id", "]", "=", "this_abstract", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.lib.data.Claim.__repr__": [[180, 183], ["None"], "methods", ["None"], ["", "return", "res", "\n", "\n", "", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "msg", "=", "f\"Example {self.id}: {self.claim}\"", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.lib.data.Claim.pretty_print": [[184, 202], ["data.Claim.__repr__", "print", "print", "data.Claim.evidence.items", "print", "data.Claim.release.corpus.get_document", "print", "enumerate", "print", "print", "enumerate"], "methods", ["home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.lib.data.ClaimPredictions.__repr__", "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.lib.data.Corpus.get_document"], ["return", "msg", "\n", "\n", "", "def", "pretty_print", "(", "self", ",", "evidence_doc_id", "=", "None", ",", "file", "=", "None", ")", ":", "\n", "        ", "\"Pretty-print the claim, together with all evidence.\"", "\n", "msg", "=", "self", ".", "__repr__", "(", ")", "\n", "print", "(", "msg", ",", "file", "=", "file", ")", "\n", "# Print the evidence", "\n", "print", "(", "\"\\nEvidence sets:\"", ",", "file", "=", "file", ")", "\n", "for", "doc_id", ",", "evidence", "in", "self", ".", "evidence", ".", "items", "(", ")", ":", "\n", "# If asked for a specific evidence doc, only show that one.", "\n", "            ", "if", "evidence_doc_id", "is", "not", "None", "and", "doc_id", "!=", "evidence_doc_id", ":", "\n", "                ", "continue", "\n", "", "print", "(", "\"\\n\"", "+", "20", "*", "\"#\"", "+", "\"\\n\"", ",", "file", "=", "file", ")", "\n", "ev_doc", "=", "self", ".", "release", ".", "corpus", ".", "get_document", "(", "doc_id", ")", "\n", "print", "(", "f\"{doc_id}: {evidence.label.name}\"", ",", "file", "=", "file", ")", "\n", "for", "i", ",", "sents", "in", "enumerate", "(", "evidence", ".", "rationales", ")", ":", "\n", "                ", "print", "(", "f\"Set {i}:\"", ",", "file", "=", "file", ")", "\n", "kept", "=", "[", "sent", "for", "i", ",", "sent", "in", "enumerate", "(", "ev_doc", ".", "sentences", ")", "if", "i", "in", "sents", "]", "\n", "for", "entry", "in", "kept", ":", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.lib.data.PredictedDataset.__init__": [[212, 219], ["data.PredictedDataset._read_predictions"], "methods", ["home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.lib.data.PredictedDataset._read_predictions"], ["\n", "def", "__init__", "(", "self", ",", "gold", ",", "prediction_file", ")", ":", "\n", "        ", "\"\"\"\n        Takes a GoldDataset, as well as files with rationale and label\n        predictions.\n        \"\"\"", "\n", "self", ".", "gold", "=", "gold", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.lib.data.PredictedDataset.__getitem__": [[220, 222], ["None"], "methods", ["None"], ["self", ".", "predictions", "=", "self", ".", "_read_predictions", "(", "prediction_file", ")", "\n", "\n", "", "def", "__getitem__", "(", "self", ",", "i", ")", ":", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.lib.data.PredictedDataset.__repr__": [[223, 226], ["len"], "methods", ["None"], ["        ", "return", "self", ".", "predictions", "[", "i", "]", "\n", "\n", "", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "msg", "=", "f\"Predictions for {len(self.predictions)} claims.\"", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.lib.data.PredictedDataset._read_predictions": [[227, 236], ["data.load_jsonl", "data.PredictedDataset._parse_prediction", "res.append"], "methods", ["home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.lib.data.load_jsonl", "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.lib.data.PredictedDataset._parse_prediction"], ["return", "msg", "\n", "\n", "", "def", "_read_predictions", "(", "self", ",", "prediction_file", ")", ":", "\n", "        ", "res", "=", "[", "]", "\n", "\n", "predictions", "=", "load_jsonl", "(", "prediction_file", ")", "\n", "for", "pred", "in", "predictions", ":", "\n", "            ", "prediction", "=", "self", ".", "_parse_prediction", "(", "pred", ")", "\n", "res", ".", "append", "(", "prediction", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.lib.data.PredictedDataset._parse_prediction": [[237, 255], ["predicted_evidence.items", "data.PredictedDataset.gold.get_claim", "data.ClaimPredictions", "data.PredictedAbstract", "int", "data.make_label", "int"], "methods", ["home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.lib.data.GoldDataset.get_claim", "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.lib.data.make_label"], ["", "return", "res", "\n", "\n", "", "def", "_parse_prediction", "(", "self", ",", "pred_dict", ")", ":", "\n", "        ", "claim_id", "=", "pred_dict", "[", "\"id\"", "]", "\n", "predicted_evidence", "=", "pred_dict", "[", "\"evidence\"", "]", "\n", "\n", "res", "=", "{", "}", "\n", "\n", "# Predictions should never be NEI; there should only be predictions for", "\n", "# the abstracts that contain evidence.", "\n", "for", "key", ",", "this_prediction", "in", "predicted_evidence", ".", "items", "(", ")", ":", "\n", "            ", "label", "=", "this_prediction", "[", "\"label\"", "]", "\n", "evidence", "=", "this_prediction", "[", "\"sentences\"", "]", "\n", "pred", "=", "PredictedAbstract", "(", "int", "(", "key", ")", ",", "\n", "make_label", "(", "label", ",", "allow_NEI", "=", "False", ")", ",", "\n", "evidence", ")", "\n", "res", "[", "int", "(", "key", ")", "]", "=", "pred", "\n", "\n", "", "gold_claim", "=", "self", ".", "gold", ".", "get_claim", "(", "claim_id", ")", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.lib.data.ClaimPredictions.__repr__": [[272, 275], ["None"], "methods", ["None"], ["gold", ":", "Claim", "=", "None", "# For backward compatibility, default this to None.", "\n", "\n", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "msg", "=", "f\"Predictions for {self.claim_id}: {self.gold.claim}\"", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.lib.data.ClaimPredictions.pretty_print": [[276, 293], ["data.ClaimPredictions.__repr__", "print", "print", "data.ClaimPredictions.predictions.items", "print", "data.ClaimPredictions.gold.release.corpus.get_document", "print", "print", "enumerate"], "methods", ["home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.lib.data.ClaimPredictions.__repr__", "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.lib.data.Corpus.get_document"], ["return", "msg", "\n", "\n", "", "def", "pretty_print", "(", "self", ",", "evidence_doc_id", "=", "None", ",", "file", "=", "None", ")", ":", "\n", "        ", "msg", "=", "self", ".", "__repr__", "(", ")", "\n", "print", "(", "msg", ",", "file", "=", "file", ")", "\n", "# Print the evidence", "\n", "print", "(", "\"\\nEvidence sets:\"", ",", "file", "=", "file", ")", "\n", "for", "doc_id", ",", "prediction", "in", "self", ".", "predictions", ".", "items", "(", ")", ":", "\n", "# If asked for a specific evidence doc, only show that one.", "\n", "            ", "if", "evidence_doc_id", "is", "not", "None", "and", "doc_id", "!=", "evidence_doc_id", ":", "\n", "                ", "continue", "\n", "", "print", "(", "\"\\n\"", "+", "20", "*", "\"#\"", "+", "\"\\n\"", ",", "file", "=", "file", ")", "\n", "ev_doc", "=", "self", ".", "gold", ".", "release", ".", "corpus", ".", "get_document", "(", "doc_id", ")", "\n", "print", "(", "f\"{doc_id}: {prediction.label.name}\"", ",", "file", "=", "file", ")", "\n", "# Print the predicted rationale.", "\n", "sents", "=", "prediction", ".", "rationale", "\n", "kept", "=", "[", "sent", "for", "i", ",", "sent", "in", "enumerate", "(", "ev_doc", ".", "sentences", ")", "if", "i", "in", "sents", "]", "\n", "for", "entry", "in", "kept", ":", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.lib.data.load_jsonl": [[16, 18], ["json.loads", "open"], "function", ["None"], ["def", "load_jsonl", "(", "fname", ")", ":", "\n", "    ", "return", "[", "json", ".", "loads", "(", "line", ")", "for", "line", "in", "open", "(", "fname", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.lib.data.make_label": [[26, 36], ["ValueError"], "function", ["None"], ["", "def", "make_label", "(", "label_str", ",", "allow_NEI", "=", "True", ")", ":", "\n", "    ", "lookup", "=", "{", "\"SUPPORT\"", ":", "Label", ".", "SUPPORTS", ",", "\n", "\"NOT_ENOUGH_INFO\"", ":", "Label", ".", "NEI", ",", "\n", "\"CONTRADICT\"", ":", "Label", ".", "REFUTES", "}", "\n", "\n", "res", "=", "lookup", "[", "label_str", "]", "\n", "if", "(", "not", "allow_NEI", ")", "and", "(", "res", "is", "Label", ".", "NEI", ")", ":", "\n", "        ", "raise", "ValueError", "(", "\"An NEI was given.\"", ")", "\n", "\n", "", "return", "res", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.rationale_selection.transformer_snopes.SnopesRationaleSelectionDataset.__init__": [[31, 48], ["json.load", "jsonlines.open", "open", "enumerate", "s.replace().strip", "transformer_snopes.SnopesRationaleSelectionDataset.samples.append", "s.replace"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "corpus", ",", "dataset", ")", ":", "\n", "        ", "self", ".", "samples", "=", "[", "]", "\n", "corpus", "=", "json", ".", "load", "(", "open", "(", "corpus", ")", ")", "\n", "dataset", "=", "jsonlines", ".", "open", "(", "dataset", ")", "\n", "for", "data", "in", "dataset", ":", "\n", "            ", "claim", "=", "data", "[", "'claim'", "]", "\n", "for", "evidence", "in", "data", "[", "'evidence'", "]", ":", "\n", "                ", "if", "evidence", ":", "\n", "                    ", "doc_id", "=", "evidence", "[", "0", "]", "[", "0", "]", "\n", "sentences", "=", "[", "s", ".", "replace", "(", "'<p>'", ",", "''", ")", ".", "strip", "(", ")", "for", "s", "in", "corpus", "[", "doc_id", "]", "[", "'lines'", "]", "]", "\n", "evidence", "=", "{", "s", "[", "1", "]", "for", "s", "in", "evidence", "}", "\n", "for", "i", ",", "sentence", "in", "enumerate", "(", "sentences", ")", ":", "\n", "                        ", "if", "sentence", ":", "\n", "                            ", "self", ".", "samples", ".", "append", "(", "{", "\n", "'claim'", ":", "claim", ",", "\n", "'sentence'", ":", "sentence", ",", "\n", "'evidence'", ":", "i", "in", "evidence", "\n", "}", ")", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.rationale_selection.transformer_snopes.SnopesRationaleSelectionDataset.__len__": [[50, 52], ["len"], "methods", ["None"], ["", "", "", "", "", "", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "samples", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.rationale_selection.transformer_snopes.SnopesRationaleSelectionDataset.__getitem__": [[53, 55], ["None"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "return", "self", ".", "samples", "[", "index", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.rationale_selection.transformer_snopes.encode": [[69, 84], ["tokenizer.batch_encode_plus", "zip", "encoded_dict[].size", "tokenizer.batch_encode_plus", "tensor.to", "zip", "tokenizer.batch_encode_plus.items"], "function", ["None"], ["def", "encode", "(", "claims", ":", "List", "[", "str", "]", ",", "sentences", ":", "List", "[", "str", "]", ")", ":", "\n", "    ", "encoded_dict", "=", "tokenizer", ".", "batch_encode_plus", "(", "\n", "zip", "(", "sentences", ",", "claims", ")", ",", "\n", "pad_to_max_length", "=", "True", ",", "\n", "return_tensors", "=", "'pt'", ")", "\n", "if", "encoded_dict", "[", "'input_ids'", "]", ".", "size", "(", "1", ")", ">", "512", ":", "\n", "# Too long for the model. Truncate it", "\n", "        ", "encoded_dict", "=", "tokenizer", ".", "batch_encode_plus", "(", "\n", "zip", "(", "sentences", ",", "claims", ")", ",", "\n", "max_length", "=", "512", ",", "\n", "truncation_strategy", "=", "'only_first'", ",", "\n", "pad_to_max_length", "=", "True", ",", "\n", "return_tensors", "=", "'pt'", ")", "\n", "", "encoded_dict", "=", "{", "key", ":", "tensor", ".", "to", "(", "device", ")", "for", "key", ",", "tensor", "in", "encoded_dict", ".", "items", "(", ")", "}", "\n", "return", "encoded_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.rationale_selection.transformer_snopes.evaluate": [[86, 99], ["model.eval", "torch.no_grad", "tqdm.tqdm", "sklearn.metrics.f1_score", "sklearn.metrics.precision_score", "sklearn.metrics.recall_score", "torch.utils.data.DataLoader", "transformer_snopes.encode", "targets.extend", "outputs.extend", "model", "batch[].float().tolist", "logits.argmax().tolist", "batch[].float", "logits.argmax"], "function", ["home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.label_prediction.transformer_scifact.encode"], ["", "def", "evaluate", "(", "model", ",", "dataset", ")", ":", "\n", "    ", "model", ".", "eval", "(", ")", "\n", "targets", "=", "[", "]", "\n", "outputs", "=", "[", "]", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "for", "batch", "in", "tqdm", "(", "DataLoader", "(", "dataset", ",", "batch_size", "=", "args", ".", "batch_size_gpu", ")", ")", ":", "\n", "            ", "encoded_dict", "=", "encode", "(", "batch", "[", "'claim'", "]", ",", "batch", "[", "'sentence'", "]", ")", "\n", "logits", "=", "model", "(", "**", "encoded_dict", ")", "[", "0", "]", "\n", "targets", ".", "extend", "(", "batch", "[", "'evidence'", "]", ".", "float", "(", ")", ".", "tolist", "(", ")", ")", "\n", "outputs", ".", "extend", "(", "logits", ".", "argmax", "(", "dim", "=", "1", ")", ".", "tolist", "(", ")", ")", "\n", "", "", "return", "f1_score", "(", "targets", ",", "outputs", ",", "zero_division", "=", "0", ")", ",", "precision_score", "(", "targets", ",", "outputs", ",", "zero_division", "=", "0", ")", ",", "recall_score", "(", "targets", ",", "outputs", ",", "zero_division", "=", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.rationale_selection.transformer_fever.FeverRationaleSelectionDataset.__init__": [[26, 35], ["jsonlines.open", "transformer_fever.FeverRationaleSelectionDataset.samples.extend", "enumerate"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "file", ")", ":", "\n", "        ", "self", ".", "samples", "=", "[", "]", "\n", "for", "data", "in", "jsonlines", ".", "open", "(", "file", ")", ":", "\n", "            ", "evidence_indices", "=", "{", "s", "for", "es", "in", "data", "[", "'evidence_sets'", "]", "for", "s", "in", "es", "}", "\n", "self", ".", "samples", ".", "extend", "(", "[", "{", "\n", "'claim'", ":", "data", "[", "'claim'", "]", ",", "\n", "'sentence'", ":", "s", ",", "\n", "'evidence'", ":", "i", "in", "evidence_indices", "\n", "}", "for", "i", ",", "s", "in", "enumerate", "(", "data", "[", "'sentences'", "]", ")", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.rationale_selection.transformer_fever.FeverRationaleSelectionDataset.__len__": [[36, 38], ["len"], "methods", ["None"], ["", "", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "samples", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.rationale_selection.transformer_fever.FeverRationaleSelectionDataset.__getitem__": [[39, 41], ["None"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "return", "self", ".", "samples", "[", "index", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.rationale_selection.transformer_fever.encode": [[58, 73], ["tokenizer.batch_encode_plus", "zip", "encoded_dict[].size", "tokenizer.batch_encode_plus", "tensor.to", "zip", "tokenizer.batch_encode_plus.items"], "function", ["None"], ["def", "encode", "(", "claims", ":", "List", "[", "str", "]", ",", "sentences", ":", "List", "[", "str", "]", ")", ":", "\n", "    ", "encoded_dict", "=", "tokenizer", ".", "batch_encode_plus", "(", "\n", "zip", "(", "sentences", ",", "claims", ")", ",", "\n", "pad_to_max_length", "=", "True", ",", "\n", "return_tensors", "=", "'pt'", ")", "\n", "if", "encoded_dict", "[", "'input_ids'", "]", ".", "size", "(", "1", ")", ">", "512", ":", "\n", "# Too long for the model. Truncate it", "\n", "        ", "encoded_dict", "=", "tokenizer", ".", "batch_encode_plus", "(", "\n", "zip", "(", "sentences", ",", "claims", ")", ",", "\n", "max_length", "=", "512", ",", "\n", "truncation_strategy", "=", "'only_first'", ",", "\n", "pad_to_max_length", "=", "True", ",", "\n", "return_tensors", "=", "'pt'", ")", "\n", "", "encoded_dict", "=", "{", "key", ":", "tensor", ".", "to", "(", "device", ")", "for", "key", ",", "tensor", "in", "encoded_dict", ".", "items", "(", ")", "}", "\n", "return", "encoded_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.rationale_selection.transformer_fever.evaluate": [[75, 90], ["model.eval", "torch.utils.data.Subset", "torch.no_grad", "tqdm.tqdm", "sklearn.metrics.f1_score", "sklearn.metrics.precision_score", "sklearn.metrics.recall_score", "range", "torch.utils.data.DataLoader", "transformer_fever.encode", "targets.extend", "outputs.extend", "model", "batch[].float().tolist", "logits.argmax().tolist", "batch[].float", "logits.argmax"], "function", ["home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.label_prediction.transformer_scifact.encode"], ["", "def", "evaluate", "(", "model", ",", "dataset", ",", "full", "=", "False", ")", ":", "\n", "    ", "model", ".", "eval", "(", ")", "\n", "targets", "=", "[", "]", "\n", "outputs", "=", "[", "]", "\n", "if", "not", "full", ":", "\n", "        ", "dataset", "=", "Subset", "(", "dataset", ",", "range", "(", "0", ",", "200", "*", "16", ")", ")", "\n", "", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "for", "batch", "in", "tqdm", "(", "DataLoader", "(", "dataset", ",", "batch_size", "=", "16", ")", ")", ":", "\n", "            ", "encoded_dict", "=", "encode", "(", "batch", "[", "'claim'", "]", ",", "batch", "[", "'sentence'", "]", ")", "\n", "logits", "=", "model", "(", "**", "encoded_dict", ")", "[", "0", "]", "\n", "targets", ".", "extend", "(", "batch", "[", "'evidence'", "]", ".", "float", "(", ")", ".", "tolist", "(", ")", ")", "\n", "outputs", ".", "extend", "(", "logits", ".", "argmax", "(", "dim", "=", "1", ")", ".", "tolist", "(", ")", ")", "\n", "", "", "return", "f1_score", "(", "targets", ",", "outputs", ",", "zero_division", "=", "0", ")", ",", "precision_score", "(", "targets", ",", "outputs", ",", "zero_division", "=", "0", ")", ",", "recall_score", "(", "targets", ",", "outputs", ",", "zero_division", "=", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.rationale_selection.transformer_scifact.SciFactRationaleSelectionDataset.__init__": [[30, 42], ["jsonlines.open", "claim[].items", "jsonlines.open", "enumerate", "transformer_scifact.SciFactRationaleSelectionDataset.samples.append", "int"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "corpus", ":", "str", ",", "claims", ":", "str", ")", ":", "\n", "        ", "self", ".", "samples", "=", "[", "]", "\n", "corpus", "=", "{", "doc", "[", "'doc_id'", "]", ":", "doc", "for", "doc", "in", "jsonlines", ".", "open", "(", "corpus", ")", "}", "\n", "for", "claim", "in", "jsonlines", ".", "open", "(", "claims", ")", ":", "\n", "            ", "for", "doc_id", ",", "evidence", "in", "claim", "[", "'evidence'", "]", ".", "items", "(", ")", ":", "\n", "                ", "doc", "=", "corpus", "[", "int", "(", "doc_id", ")", "]", "\n", "evidence_sentence_idx", "=", "{", "s", "for", "es", "in", "evidence", "for", "s", "in", "es", "[", "'sentences'", "]", "}", "\n", "for", "i", ",", "sentence", "in", "enumerate", "(", "doc", "[", "'abstract'", "]", ")", ":", "\n", "                    ", "self", ".", "samples", ".", "append", "(", "{", "\n", "'claim'", ":", "claim", "[", "'claim'", "]", ",", "\n", "'sentence'", ":", "sentence", ",", "\n", "'evidence'", ":", "i", "in", "evidence_sentence_idx", "\n", "}", ")", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.rationale_selection.transformer_scifact.SciFactRationaleSelectionDataset.__len__": [[44, 46], ["len"], "methods", ["None"], ["", "", "", "", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "samples", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.rationale_selection.transformer_scifact.SciFactRationaleSelectionDataset.__getitem__": [[47, 49], ["None"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "idx", ")", ":", "\n", "        ", "return", "self", ".", "samples", "[", "idx", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.rationale_selection.transformer_scifact.encode": [[63, 78], ["tokenizer.batch_encode_plus", "zip", "encoded_dict[].size", "tokenizer.batch_encode_plus", "tensor.to", "zip", "tokenizer.batch_encode_plus.items"], "function", ["None"], ["def", "encode", "(", "claims", ":", "List", "[", "str", "]", ",", "sentences", ":", "List", "[", "str", "]", ")", ":", "\n", "    ", "encoded_dict", "=", "tokenizer", ".", "batch_encode_plus", "(", "\n", "zip", "(", "sentences", ",", "claims", ")", ",", "\n", "pad_to_max_length", "=", "True", ",", "\n", "return_tensors", "=", "'pt'", ")", "\n", "if", "encoded_dict", "[", "'input_ids'", "]", ".", "size", "(", "1", ")", ">", "512", ":", "\n", "# Too long for the model. Truncate it", "\n", "        ", "encoded_dict", "=", "tokenizer", ".", "batch_encode_plus", "(", "\n", "zip", "(", "sentences", ",", "claims", ")", ",", "\n", "max_length", "=", "512", ",", "\n", "truncation_strategy", "=", "'only_first'", ",", "\n", "pad_to_max_length", "=", "True", ",", "\n", "return_tensors", "=", "'pt'", ")", "\n", "", "encoded_dict", "=", "{", "key", ":", "tensor", ".", "to", "(", "device", ")", "for", "key", ",", "tensor", "in", "encoded_dict", ".", "items", "(", ")", "}", "\n", "return", "encoded_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.rationale_selection.transformer_scifact.evaluate": [[80, 93], ["model.eval", "torch.no_grad", "torch.utils.data.DataLoader", "sklearn.metrics.f1_score", "sklearn.metrics.precision_score", "sklearn.metrics.recall_score", "transformer_scifact.encode", "targets.extend", "outputs.extend", "model", "batch[].float().tolist", "logits.argmax().tolist", "batch[].float", "logits.argmax"], "function", ["home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.label_prediction.transformer_scifact.encode"], ["", "def", "evaluate", "(", "model", ",", "dataset", ")", ":", "\n", "    ", "model", ".", "eval", "(", ")", "\n", "targets", "=", "[", "]", "\n", "outputs", "=", "[", "]", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "for", "batch", "in", "DataLoader", "(", "dataset", ",", "batch_size", "=", "args", ".", "batch_size_gpu", ")", ":", "\n", "            ", "encoded_dict", "=", "encode", "(", "batch", "[", "'claim'", "]", ",", "batch", "[", "'sentence'", "]", ")", "\n", "logits", "=", "model", "(", "**", "encoded_dict", ")", "[", "0", "]", "\n", "targets", ".", "extend", "(", "batch", "[", "'evidence'", "]", ".", "float", "(", ")", ".", "tolist", "(", ")", ")", "\n", "outputs", ".", "extend", "(", "logits", ".", "argmax", "(", "dim", "=", "1", ")", ".", "tolist", "(", ")", ")", "\n", "", "", "return", "f1_score", "(", "targets", ",", "outputs", ",", "zero_division", "=", "0", ")", ",", "precision_score", "(", "targets", ",", "outputs", ",", "zero_division", "=", "0", ")", ",", "recall_score", "(", "targets", ",", "outputs", ",", "zero_division", "=", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.label_prediction.transformer_snopes.SnopesLabelPredictionDataset.__init__": [[31, 48], ["json.load", "jsonlines.open", "open", "[].replace().strip", "transformer_snopes.SnopesLabelPredictionDataset.samples.append", "[].replace"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "corpus", ",", "dataset", ")", ":", "\n", "        ", "self", ".", "samples", "=", "[", "]", "\n", "corpus", "=", "json", ".", "load", "(", "open", "(", "corpus", ")", ")", "\n", "dataset", "=", "jsonlines", ".", "open", "(", "dataset", ")", "\n", "for", "data", "in", "dataset", ":", "\n", "            ", "claim", "=", "data", "[", "'claim'", "]", "\n", "for", "evidence", "in", "data", "[", "'evidence'", "]", ":", "\n", "                ", "if", "evidence", ":", "\n", "                    ", "doc_id", "=", "evidence", "[", "0", "]", "[", "0", "]", "\n", "sentences", "=", "[", "s", ".", "replace", "(", "'<p>'", ",", "''", ")", ".", "strip", "(", ")", "for", "s", "in", "corpus", "[", "doc_id", "]", "[", "'lines'", "]", "]", "\n", "evidence", "=", "{", "s", "[", "1", "]", "for", "s", "in", "evidence", "}", "\n", "for", "i", ",", "sentence", "in", "enumerate", "(", "sentences", ")", ":", "\n", "                        ", "if", "sentence", ":", "\n", "                            ", "self", ".", "samples", ".", "append", "(", "{", "\n", "'claim'", ":", "claim", ",", "\n", "'sentence'", ":", "sentence", ",", "\n", "'evidence'", ":", "i", "in", "evidence", "\n", "}", ")", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.label_prediction.transformer_snopes.SnopesLabelPredictionDataset.__len__": [[50, 52], ["len"], "methods", ["None"], ["", "", "", "", "", "", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "samples", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.label_prediction.transformer_snopes.SnopesLabelPredictionDataset.__getitem__": [[53, 55], ["None"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "return", "self", ".", "samples", "[", "index", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.label_prediction.transformer_snopes.encode": [[71, 86], ["tokenizer.batch_encode_plus", "zip", "encoded_dict[].size", "tokenizer.batch_encode_plus", "tensor.to", "zip", "tokenizer.batch_encode_plus.items"], "function", ["None"], ["zip", "(", "sentences", ",", "claims", ")", ",", "\n", "pad_to_max_length", "=", "True", ",", "\n", "return_tensors", "=", "'pt'", ")", "\n", "if", "encoded_dict", "[", "'input_ids'", "]", ".", "size", "(", "1", ")", ">", "512", ":", "\n", "# Too long for the model. Truncate it", "\n", "        ", "encoded_dict", "=", "tokenizer", ".", "batch_encode_plus", "(", "\n", "zip", "(", "sentences", ",", "claims", ")", ",", "\n", "max_length", "=", "512", ",", "\n", "truncation_strategy", "=", "'only_first'", ",", "\n", "pad_to_max_length", "=", "True", ",", "\n", "return_tensors", "=", "'pt'", ")", "\n", "", "encoded_dict", "=", "{", "key", ":", "tensor", ".", "to", "(", "device", ")", "for", "key", ",", "tensor", "in", "encoded_dict", ".", "items", "(", ")", "}", "\n", "return", "encoded_dict", "\n", "\n", "\n", "", "def", "evaluate", "(", "model", ",", "dataset", ")", ":", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.label_prediction.transformer_snopes.evaluate": [[88, 103], ["model.eval", "torch.no_grad", "torch.utils.data.DataLoader", "sklearn.metrics.f1_score", "tuple", "tuple", "tuple", "transformer_snopes.encode", "targets.extend", "outputs.extend", "sklearn.metrics.f1_score", "sklearn.metrics.precision_score", "sklearn.metrics.recall_score", "model", "batch[].float().tolist", "logits.argmax().tolist", "batch[].float", "logits.argmax"], "function", ["home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.label_prediction.transformer_scifact.encode"], ["targets", "=", "[", "]", "\n", "outputs", "=", "[", "]", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "for", "batch", "in", "tqdm", "(", "DataLoader", "(", "dataset", ",", "batch_size", "=", "args", ".", "batch_size_gpu", ")", ")", ":", "\n", "            ", "encoded_dict", "=", "encode", "(", "batch", "[", "'claim'", "]", ",", "batch", "[", "'sentence'", "]", ")", "\n", "logits", "=", "model", "(", "**", "encoded_dict", ")", "[", "0", "]", "\n", "targets", ".", "extend", "(", "batch", "[", "'evidence'", "]", ".", "float", "(", ")", ".", "tolist", "(", ")", ")", "\n", "outputs", ".", "extend", "(", "logits", ".", "argmax", "(", "dim", "=", "1", ")", ".", "tolist", "(", ")", ")", "\n", "", "", "return", "f1_score", "(", "targets", ",", "outputs", ",", "zero_division", "=", "0", ")", ",", "precision_score", "(", "targets", ",", "outputs", ",", "zero_division", "=", "0", ")", ",", "recall_score", "(", "targets", ",", "outputs", ",", "zero_division", "=", "0", ")", "\n", "\n", "\n", "", "for", "e", "in", "range", "(", "args", ".", "epochs", ")", ":", "\n", "    ", "model", ".", "train", "(", ")", "\n", "t", "=", "tqdm", "(", "DataLoader", "(", "trainset", ",", "batch_size", "=", "args", ".", "batch_size_gpu", ",", "shuffle", "=", "True", ")", ")", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.label_prediction.transformer_fever.FeverLabelPredictionDataset.__init__": [[30, 61], ["jsonlines.open", "sorted", "transformer_fever.FeverLabelPredictionDataset.samples.append", "transformer_fever.FeverLabelPredictionDataset.samples.append", "set", "set", "random.sample", "transformer_fever.FeverLabelPredictionDataset.samples.append", "random.sample", "range", "range", "len", "random.randint", "len", "min", "len"], "methods", ["None"], ["self", ".", "samples", ".", "extend", "(", "[", "{", "\n", "'claim'", ":", "data", "[", "'claim'", "]", ",", "\n", "'sentence'", ":", "s", ",", "\n", "'evidence'", ":", "i", "in", "evidence_indices", "\n", "}", "for", "i", ",", "s", "in", "enumerate", "(", "data", "[", "'sentences'", "]", ")", "]", ")", "\n", "\n", "", "", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "samples", ")", "\n", "\n", "", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "return", "self", ".", "samples", "[", "index", "]", "\n", "\n", "\n", "", "", "device", "=", "torch", ".", "device", "(", "'cuda'", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "else", "'cpu'", ")", "\n", "print", "(", "f'Using device \"{device}\"'", ")", "\n", "\n", "trainset", "=", "FeverRationaleSelectionDataset", "(", "args", ".", "train", ")", "\n", "devset", "=", "FeverRationaleSelectionDataset", "(", "args", ".", "dev", ")", "\n", "\n", "tokenizer", "=", "AutoTokenizer", ".", "from_pretrained", "(", "args", ".", "model", ")", "\n", "model", "=", "AutoModelForSequenceClassification", ".", "from_pretrained", "(", "args", ".", "model", ")", ".", "to", "(", "device", ")", "\n", "optimizer", "=", "torch", ".", "optim", ".", "Adam", "(", "[", "\n", "{", "'params'", ":", "model", ".", "roberta", ".", "parameters", "(", ")", ",", "'lr'", ":", "args", ".", "lr_base", "}", ",", "# if using non-roberta model, change the base param path.", "\n", "{", "'params'", ":", "model", ".", "classifier", ".", "parameters", "(", ")", ",", "'lr'", ":", "args", ".", "lr_linear", "}", "\n", "]", ")", "\n", "scheduler", "=", "get_cosine_schedule_with_warmup", "(", "optimizer", ",", "0", ",", "20", ")", "\n", "\n", "\n", "def", "encode", "(", "claims", ":", "List", "[", "str", "]", ",", "sentences", ":", "List", "[", "str", "]", ")", ":", "\n", "    ", "encoded_dict", "=", "tokenizer", ".", "batch_encode_plus", "(", "\n", "zip", "(", "sentences", ",", "claims", ")", ",", "\n", "pad_to_max_length", "=", "True", ",", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.label_prediction.transformer_fever.FeverLabelPredictionDataset.__len__": [[63, 65], ["len"], "methods", ["None"], ["if", "encoded_dict", "[", "'input_ids'", "]", ".", "size", "(", "1", ")", ">", "512", ":", "\n", "# Too long for the model. Truncate it", "\n", "        ", "encoded_dict", "=", "tokenizer", ".", "batch_encode_plus", "(", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.label_prediction.transformer_fever.FeverLabelPredictionDataset.__getitem__": [[66, 68], ["None"], "methods", ["None"], ["zip", "(", "sentences", ",", "claims", ")", ",", "\n", "max_length", "=", "512", ",", "\n", "truncation_strategy", "=", "'only_first'", ",", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.label_prediction.transformer_fever.encode": [[84, 99], ["tokenizer.batch_encode_plus", "zip", "encoded_dict[].size", "tokenizer.batch_encode_plus", "tensor.to", "zip", "tokenizer.batch_encode_plus.items"], "function", ["None"], ["logits", "=", "model", "(", "**", "encoded_dict", ")", "[", "0", "]", "\n", "targets", ".", "extend", "(", "batch", "[", "'evidence'", "]", ".", "float", "(", ")", ".", "tolist", "(", ")", ")", "\n", "outputs", ".", "extend", "(", "logits", ".", "argmax", "(", "dim", "=", "1", ")", ".", "tolist", "(", ")", ")", "\n", "", "", "return", "f1_score", "(", "targets", ",", "outputs", ",", "zero_division", "=", "0", ")", ",", "precision_score", "(", "targets", ",", "outputs", ",", "zero_division", "=", "0", ")", ",", "recall_score", "(", "targets", ",", "outputs", ",", "zero_division", "=", "0", ")", "\n", "\n", "\n", "", "for", "e", "in", "range", "(", "args", ".", "epochs", ")", ":", "\n", "    ", "model", ".", "train", "(", ")", "\n", "t", "=", "tqdm", "(", "DataLoader", "(", "trainset", ",", "batch_size", "=", "args", ".", "batch_size_gpu", ",", "shuffle", "=", "True", ")", ")", "\n", "for", "i", ",", "batch", "in", "enumerate", "(", "t", ")", ":", "\n", "        ", "encoded_dict", "=", "encode", "(", "batch", "[", "'claim'", "]", ",", "batch", "[", "'sentence'", "]", ")", "\n", "loss", ",", "logits", "=", "model", "(", "**", "encoded_dict", ",", "labels", "=", "batch", "[", "'evidence'", "]", ".", "long", "(", ")", ".", "to", "(", "device", ")", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "if", "(", "i", "+", "1", ")", "%", "(", "args", ".", "batch_size_accumulated", "//", "args", ".", "batch_size_gpu", ")", "==", "0", ":", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.label_prediction.transformer_fever.evaluate": [[101, 116], ["model.eval", "torch.no_grad", "torch.utils.data.DataLoader", "sklearn.metrics.f1_score", "tuple", "tuple", "tuple", "transformer_fever.encode", "targets.extend", "outputs.extend", "sklearn.metrics.f1_score", "sklearn.metrics.precision_score", "sklearn.metrics.recall_score", "model", "batch[].float().tolist", "logits.argmax().tolist", "batch[].float", "logits.argmax"], "function", ["home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.label_prediction.transformer_scifact.encode"], ["optimizer", ".", "zero_grad", "(", ")", "\n", "t", ".", "set_description", "(", "f'Epoch {e}, iter {i}, loss: {round(loss.item(), 4)}'", ")", "\n", "", "", "scheduler", ".", "step", "(", ")", "\n", "train_score", "=", "evaluate", "(", "model", ",", "trainset", ")", "\n", "print", "(", "f'Epoch {e}, train f1: %.4f, precision: %.4f, recall: %.4f'", "%", "train_score", ")", "\n", "dev_score", "=", "evaluate", "(", "model", ",", "devset", ")", "\n", "print", "(", "f'Epoch {e}, dev f1: %.4f, precision: %.4f, recall: %.4f'", "%", "dev_score", ")", "\n", "# Save", "\n", "save_path", "=", "os", ".", "path", ".", "join", "(", "args", ".", "dest", ",", "f'epoch-{e}-f1-{int(dev_score[0] * 1e4)}'", ")", "\n", "os", ".", "makedirs", "(", "save_path", ")", "\n", "tokenizer", ".", "save_pretrained", "(", "save_path", ")", "\n", "model", ".", "save_pretrained", "(", "save_path", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.label_prediction.transformer_scifact.SciFactLabelPredictionDataset.__init__": [[31, 82], ["jsonlines.open", "jsonlines.open", "claim[].items", "transformer_scifact.SciFactLabelPredictionDataset.samples.append", "random.sample", "transformer_scifact.SciFactLabelPredictionDataset.samples.append", "random.sample", "transformer_scifact.SciFactLabelPredictionDataset.samples.append", "transformer_scifact.SciFactLabelPredictionDataset.samples.append", "[].strip", "set", "[].strip", "range", "[].strip", "int", "[].strip", "sorted", "range", "min", "sorted", "int", "len", "random.randint", "list", "len", "random.randint", "len", "list"], "methods", ["None"], ["        ", "self", ".", "samples", "=", "[", "]", "\n", "corpus", "=", "{", "doc", "[", "'doc_id'", "]", ":", "doc", "for", "doc", "in", "jsonlines", ".", "open", "(", "corpus", ")", "}", "\n", "for", "claim", "in", "jsonlines", ".", "open", "(", "claims", ")", ":", "\n", "            ", "for", "doc_id", ",", "evidence", "in", "claim", "[", "'evidence'", "]", ".", "items", "(", ")", ":", "\n", "                ", "doc", "=", "corpus", "[", "int", "(", "doc_id", ")", "]", "\n", "evidence_sentence_idx", "=", "{", "s", "for", "es", "in", "evidence", "for", "s", "in", "es", "[", "'sentences'", "]", "}", "\n", "for", "i", ",", "sentence", "in", "enumerate", "(", "doc", "[", "'abstract'", "]", ")", ":", "\n", "                    ", "self", ".", "samples", ".", "append", "(", "{", "\n", "'claim'", ":", "claim", "[", "'claim'", "]", ",", "\n", "'sentence'", ":", "sentence", ",", "\n", "'evidence'", ":", "i", "in", "evidence_sentence_idx", "\n", "}", ")", "\n", "\n", "", "", "", "", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "samples", ")", "\n", "\n", "", "def", "__getitem__", "(", "self", ",", "idx", ")", ":", "\n", "        ", "return", "self", ".", "samples", "[", "idx", "]", "\n", "\n", "\n", "", "", "trainset", "=", "SciFactRationaleSelectionDataset", "(", "args", ".", "corpus", ",", "args", ".", "claim_train", ")", "\n", "devset", "=", "SciFactRationaleSelectionDataset", "(", "args", ".", "corpus", ",", "args", ".", "claim_dev", ")", "\n", "\n", "tokenizer", "=", "AutoTokenizer", ".", "from_pretrained", "(", "args", ".", "model", ")", "\n", "model", "=", "AutoModelForSequenceClassification", ".", "from_pretrained", "(", "args", ".", "model", ")", ".", "to", "(", "device", ")", "\n", "optimizer", "=", "torch", ".", "optim", ".", "Adam", "(", "[", "\n", "{", "'params'", ":", "model", ".", "roberta", ".", "parameters", "(", ")", ",", "'lr'", ":", "args", ".", "lr_base", "}", ",", "# if using non-roberta model, change the base param path.", "\n", "{", "'params'", ":", "model", ".", "classifier", ".", "parameters", "(", ")", ",", "'lr'", ":", "args", ".", "lr_linear", "}", "\n", "]", ")", "\n", "scheduler", "=", "get_cosine_schedule_with_warmup", "(", "optimizer", ",", "0", ",", "20", ")", "\n", "\n", "\n", "def", "encode", "(", "claims", ":", "List", "[", "str", "]", ",", "sentences", ":", "List", "[", "str", "]", ")", ":", "\n", "    ", "encoded_dict", "=", "tokenizer", ".", "batch_encode_plus", "(", "\n", "zip", "(", "sentences", ",", "claims", ")", ",", "\n", "pad_to_max_length", "=", "True", ",", "\n", "return_tensors", "=", "'pt'", ")", "\n", "if", "encoded_dict", "[", "'input_ids'", "]", ".", "size", "(", "1", ")", ">", "512", ":", "\n", "# Too long for the model. Truncate it", "\n", "        ", "encoded_dict", "=", "tokenizer", ".", "batch_encode_plus", "(", "\n", "zip", "(", "sentences", ",", "claims", ")", ",", "\n", "max_length", "=", "512", ",", "\n", "truncation_strategy", "=", "'only_first'", ",", "\n", "pad_to_max_length", "=", "True", ",", "\n", "return_tensors", "=", "'pt'", ")", "\n", "", "encoded_dict", "=", "{", "key", ":", "tensor", ".", "to", "(", "device", ")", "for", "key", ",", "tensor", "in", "encoded_dict", ".", "items", "(", ")", "}", "\n", "return", "encoded_dict", "\n", "\n", "\n", "", "def", "evaluate", "(", "model", ",", "dataset", ")", ":", "\n", "    ", "model", ".", "eval", "(", ")", "\n", "targets", "=", "[", "]", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.label_prediction.transformer_scifact.SciFactLabelPredictionDataset.__len__": [[84, 86], ["len"], "methods", ["None"], ["with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "for", "batch", "in", "DataLoader", "(", "dataset", ",", "batch_size", "=", "args", ".", "batch_size_gpu", ")", ":", "\n", "            ", "encoded_dict", "=", "encode", "(", "batch", "[", "'claim'", "]", ",", "batch", "[", "'sentence'", "]", ")", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.label_prediction.transformer_scifact.SciFactLabelPredictionDataset.__getitem__": [[87, 89], ["None"], "methods", ["None"], ["logits", "=", "model", "(", "**", "encoded_dict", ")", "[", "0", "]", "\n", "targets", ".", "extend", "(", "batch", "[", "'evidence'", "]", ".", "float", "(", ")", ".", "tolist", "(", ")", ")", "\n", "outputs", ".", "extend", "(", "logits", ".", "argmax", "(", "dim", "=", "1", ")", ".", "tolist", "(", ")", ")", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.label_prediction.transformer_scifact.encode": [[105, 120], ["tokenizer.batch_encode_plus", "zip", "encoded_dict[].size", "tokenizer.batch_encode_plus", "tensor.to", "zip", "tokenizer.batch_encode_plus.items"], "function", ["None"], ["t", ".", "set_description", "(", "f'Epoch {e}, iter {i}, loss: {round(loss.item(), 4)}'", ")", "\n", "", "", "scheduler", ".", "step", "(", ")", "\n", "train_score", "=", "evaluate", "(", "model", ",", "trainset", ")", "\n", "print", "(", "f'Epoch {e}, train f1: %.4f, precision: %.4f, recall: %.4f'", "%", "train_score", ")", "\n", "dev_score", "=", "evaluate", "(", "model", ",", "devset", ")", "\n", "print", "(", "f'Epoch {e}, dev f1: %.4f, precision: %.4f, recall: %.4f'", "%", "dev_score", ")", "\n", "# Save", "\n", "save_path", "=", "os", ".", "path", ".", "join", "(", "args", ".", "dest", ",", "f'epoch-{e}-f1-{int(dev_score[0] * 1e4)}'", ")", "\n", "os", ".", "makedirs", "(", "save_path", ")", "\n", "tokenizer", ".", "save_pretrained", "(", "save_path", ")", "\n", "model", ".", "save_pretrained", "(", "save_path", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.label_prediction.transformer_scifact.evaluate": [[122, 137], ["model.eval", "torch.no_grad", "torch.utils.data.DataLoader", "sklearn.metrics.f1_score", "tuple", "tuple", "tuple", "transformer_scifact.encode", "targets.extend", "outputs.extend", "sklearn.metrics.f1_score", "sklearn.metrics.precision_score", "sklearn.metrics.recall_score", "model", "batch[].float().tolist", "logits.argmax().tolist", "batch[].float", "logits.argmax"], "function", ["home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.label_prediction.transformer_scifact.encode"], []], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.evaluate.pipeline.get_args": [[18, 32], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args"], "function", ["home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.src.JointAbstractRetrieval.parse_args"], ["def", "get_args", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "\n", "description", "=", "'Evaluate SciFact predictions.'", "\n", ")", "\n", "parser", ".", "add_argument", "(", "'--gold'", ",", "type", "=", "str", ",", "required", "=", "True", ",", "\n", "help", "=", "'The gold labels.'", ")", "\n", "parser", ".", "add_argument", "(", "'--corpus'", ",", "type", "=", "str", ",", "required", "=", "True", ",", "\n", "help", "=", "'The corpus of documents.'", ")", "\n", "parser", ".", "add_argument", "(", "'--prediction'", ",", "type", "=", "str", ",", "required", "=", "True", ",", "\n", "help", "=", "'The predictions.'", ")", "\n", "parser", ".", "add_argument", "(", "'--output'", ",", "type", "=", "str", ",", "default", "=", "None", ",", "\n", "help", "=", "'If provided, save metrics to this file.'", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "return", "args", "\n", "\n"]], "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.evaluate.pipeline.main": [[34, 46], ["pipeline.get_args", "lib.data.GoldDataset", "lib.data.PredictedDataset", "lib.metrics.compute_metrics", "print", "open", "json.dump", "metrics.compute_metrics.to_dict"], "function", ["home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.evaluate.pipeline.get_args", "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.lib.metrics.compute_metrics", "home.repos.pwc.inspect_result.zhiweizhang97_arsjointmodel.lib.data.Document.dump"], ["", "def", "main", "(", ")", ":", "\n", "    ", "args", "=", "get_args", "(", ")", "\n", "\n", "data", "=", "GoldDataset", "(", "args", ".", "corpus", ",", "args", ".", "gold", ")", "\n", "predictions", "=", "PredictedDataset", "(", "data", ",", "args", ".", "prediction", ")", "\n", "\n", "res", "=", "metrics", ".", "compute_metrics", "(", "predictions", ")", "\n", "if", "args", ".", "output", "is", "not", "None", ":", "\n", "        ", "with", "open", "(", "args", ".", "output", ",", "\"w\"", ")", "as", "f", ":", "\n", "            ", "json", ".", "dump", "(", "res", ".", "to_dict", "(", ")", ",", "f", ",", "indent", "=", "2", ")", "\n", "", "", "else", ":", "\n", "        ", "print", "(", "res", ")", "\n", "\n"]]}