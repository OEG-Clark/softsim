{"home.repos.pwc.inspect_result.allenai_scitldr.SciTLDR-Data.multiprocessing_bpe_encoder.MultiprocessingEncoder.__init__": [[91, 93], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "args", ")", ":", "\n", "        ", "self", ".", "args", "=", "args", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_scitldr.SciTLDR-Data.multiprocessing_bpe_encoder.MultiprocessingEncoder.initializer": [[94, 97], ["fairseq.data.encoders.gpt2_bpe.get_encoder"], "methods", ["None"], ["", "def", "initializer", "(", "self", ")", ":", "\n", "        ", "global", "bpe", "\n", "bpe", "=", "get_encoder", "(", "self", ".", "args", ".", "encoder_json", ",", "self", ".", "args", ".", "vocab_bpe", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_scitldr.SciTLDR-Data.multiprocessing_bpe_encoder.MultiprocessingEncoder.encode": [[98, 102], ["bpe.encode", "list", "map"], "methods", ["home.repos.pwc.inspect_result.allenai_scitldr.SciTLDR-Data.multiprocessing_bpe_encoder.MultiprocessingEncoder.encode"], ["", "def", "encode", "(", "self", ",", "line", ")", ":", "\n", "        ", "global", "bpe", "\n", "ids", "=", "bpe", ".", "encode", "(", "line", ")", "\n", "return", "list", "(", "map", "(", "str", ",", "ids", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_scitldr.SciTLDR-Data.multiprocessing_bpe_encoder.MultiprocessingEncoder.decode": [[103, 106], ["bpe.decode"], "methods", ["home.repos.pwc.inspect_result.allenai_scitldr.SciTLDR-Data.multiprocessing_bpe_encoder.MultiprocessingEncoder.decode"], ["", "def", "decode", "(", "self", ",", "tokens", ")", ":", "\n", "        ", "global", "bpe", "\n", "return", "bpe", ".", "decode", "(", "tokens", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_scitldr.SciTLDR-Data.multiprocessing_bpe_encoder.MultiprocessingEncoder.encode_lines": [[107, 119], ["line.strip.strip.strip", "multiprocessing_bpe_encoder.MultiprocessingEncoder.encode", "enc_lines.append", "len"], "methods", ["home.repos.pwc.inspect_result.allenai_scitldr.SciTLDR-Data.multiprocessing_bpe_encoder.MultiprocessingEncoder.encode"], ["", "def", "encode_lines", "(", "self", ",", "lines", ")", ":", "\n", "        ", "\"\"\"\n        Encode a set of lines. All lines will be encoded together.\n        \"\"\"", "\n", "enc_lines", "=", "[", "]", "\n", "for", "line", "in", "lines", ":", "\n", "            ", "line", "=", "line", ".", "strip", "(", ")", "\n", "if", "len", "(", "line", ")", "==", "0", "and", "not", "self", ".", "args", ".", "keep_empty", ":", "\n", "                ", "return", "[", "\"EMPTY\"", ",", "None", "]", "\n", "", "tokens", "=", "self", ".", "encode", "(", "line", ")", "\n", "enc_lines", ".", "append", "(", "\" \"", ".", "join", "(", "tokens", ")", ")", "\n", "", "return", "[", "\"PASS\"", ",", "enc_lines", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_scitldr.SciTLDR-Data.multiprocessing_bpe_encoder.MultiprocessingEncoder.decode_lines": [[120, 126], ["map", "dec_lines.append", "line.strip().split", "multiprocessing_bpe_encoder.MultiprocessingEncoder.decode", "line.strip"], "methods", ["home.repos.pwc.inspect_result.allenai_scitldr.SciTLDR-Data.multiprocessing_bpe_encoder.MultiprocessingEncoder.decode"], ["", "def", "decode_lines", "(", "self", ",", "lines", ")", ":", "\n", "        ", "dec_lines", "=", "[", "]", "\n", "for", "line", "in", "lines", ":", "\n", "            ", "tokens", "=", "map", "(", "int", ",", "line", ".", "strip", "(", ")", ".", "split", "(", ")", ")", "\n", "dec_lines", ".", "append", "(", "self", ".", "decode", "(", "tokens", ")", ")", "\n", "", "return", "[", "\"PASS\"", ",", "dec_lines", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_scitldr.SciTLDR-Data.multiprocessing_bpe_encoder.main": [[18, 87], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "len", "len", "contextlib.ExitStack", "multiprocessing_bpe_encoder.MultiprocessingEncoder", "multiprocessing.Pool", "multiprocessing.Pool.imap", "collections.Counter", "enumerate", "collections.Counter.most_common", "zip", "print", "stack.enter_context", "stack.enter_context", "zip", "print", "open", "open", "print"], "function", ["home.repos.pwc.inspect_result.allenai_scitldr.scripts.novelty_stats.parse_args"], ["def", "main", "(", ")", ":", "\n", "    ", "\"\"\"\n    Helper script to encode raw text with the GPT-2 BPE using multiple processes.\n\n    The encoder.json and vocab.bpe files can be obtained here:\n    - https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json\n    - https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe\n    \"\"\"", "\n", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--encoder-json\"", ",", "\n", "help", "=", "'path to encoder.json'", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--vocab-bpe\"", ",", "\n", "type", "=", "str", ",", "\n", "help", "=", "'path to vocab.bpe'", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--inputs\"", ",", "\n", "nargs", "=", "\"+\"", ",", "\n", "default", "=", "[", "'-'", "]", ",", "\n", "help", "=", "\"input files to filter/encode\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--outputs\"", ",", "\n", "nargs", "=", "\"+\"", ",", "\n", "default", "=", "[", "'-'", "]", ",", "\n", "help", "=", "\"path to save encoded outputs\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--keep-empty\"", ",", "\n", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"keep empty lines\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\"--workers\"", ",", "type", "=", "int", ",", "default", "=", "20", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "assert", "len", "(", "args", ".", "inputs", ")", "==", "len", "(", "args", ".", "outputs", ")", ",", "\"number of input and output paths should match\"", "\n", "\n", "with", "contextlib", ".", "ExitStack", "(", ")", "as", "stack", ":", "\n", "        ", "inputs", "=", "[", "\n", "stack", ".", "enter_context", "(", "open", "(", "input", ",", "\"r\"", ",", "encoding", "=", "\"utf-8\"", ")", ")", "\n", "if", "input", "!=", "\"-\"", "else", "sys", ".", "stdin", "\n", "for", "input", "in", "args", ".", "inputs", "\n", "]", "\n", "outputs", "=", "[", "\n", "stack", ".", "enter_context", "(", "open", "(", "output", ",", "\"w\"", ",", "encoding", "=", "\"utf-8\"", ")", ")", "\n", "if", "output", "!=", "\"-\"", "else", "sys", ".", "stdout", "\n", "for", "output", "in", "args", ".", "outputs", "\n", "]", "\n", "\n", "encoder", "=", "MultiprocessingEncoder", "(", "args", ")", "\n", "pool", "=", "Pool", "(", "args", ".", "workers", ",", "initializer", "=", "encoder", ".", "initializer", ")", "\n", "encoded_lines", "=", "pool", ".", "imap", "(", "encoder", ".", "encode_lines", ",", "zip", "(", "*", "inputs", ")", ",", "100", ")", "\n", "\n", "stats", "=", "Counter", "(", ")", "\n", "for", "i", ",", "(", "filt", ",", "enc_lines", ")", "in", "enumerate", "(", "encoded_lines", ",", "start", "=", "1", ")", ":", "\n", "            ", "if", "filt", "==", "\"PASS\"", ":", "\n", "                ", "for", "enc_line", ",", "output_h", "in", "zip", "(", "enc_lines", ",", "outputs", ")", ":", "\n", "                    ", "print", "(", "enc_line", ",", "file", "=", "output_h", ")", "\n", "", "", "else", ":", "\n", "                ", "stats", "[", "\"num_filtered_\"", "+", "filt", "]", "+=", "1", "\n", "", "if", "i", "%", "10000", "==", "0", ":", "\n", "                ", "print", "(", "\"processed {} lines\"", ".", "format", "(", "i", ")", ",", "file", "=", "sys", ".", "stderr", ")", "\n", "\n", "", "", "for", "k", ",", "v", "in", "stats", ".", "most_common", "(", ")", ":", "\n", "            ", "print", "(", "\"[{}] filtered {} lines\"", ".", "format", "(", "k", ",", "v", ")", ",", "file", "=", "sys", ".", "stderr", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_scitldr.SciTLDR-Data.build_ctrl_datasets.save_lines": [[8, 12], ["open", "fout.write", "json.dumps"], "function", ["None"], ["def", "save_lines", "(", "lines", ",", "outpath", ")", ":", "\n", "    ", "with", "open", "(", "outpath", ",", "'w'", ")", "as", "fout", ":", "\n", "        ", "for", "l", "in", "lines", ":", "\n", "            ", "fout", ".", "write", "(", "json", ".", "dumps", "(", "l", ")", "+", "'\\n'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_scitldr.SciTLDR-Data.build_ctrl_datasets.add_ctrl": [[13, 19], ["ctrl_added.append"], "function", ["None"], ["", "", "", "def", "add_ctrl", "(", "lines", ",", "ctrl", ")", ":", "\n", "    ", "ctrl_added", "=", "[", "]", "\n", "for", "l", "in", "lines", ":", "\n", "        ", "l", "[", "'source'", "]", "+=", "[", "ctrl", "]", "\n", "ctrl_added", ".", "append", "(", "l", ")", "\n", "", "return", "ctrl_added", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_scitldr.SciTLDR-Data.to_stories.build_batches": [[11, 14], ["open", "os.path.join", "json.loads", "line.strip"], "function", ["None"], ["def", "build_batches", "(", "args", ",", "file_name", ")", ":", "\n", "    ", "with", "open", "(", "join", "(", "args", ".", "data_dir", ",", "file_name", ")", ")", "as", "f", ":", "\n", "        ", "return", "[", "(", "args", ",", "json", ".", "loads", "(", "line", ".", "strip", "(", ")", ")", ")", "for", "line", "in", "f", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_scitldr.SciTLDR-Data.to_stories.format_story": [[15, 27], ["str().replace", "str().replace", "s.replace().strip", "open", "f.write", "f.write", "str", "str", "os.path.join", "s.replace"], "function", ["None"], ["", "", "def", "format_story", "(", "data", ")", ":", "\n", "    ", "args", ",", "j", "=", "data", "\n", "j", "[", "\"paper_id\"", "]", "=", "str", "(", "j", "[", "\"paper_id\"", "]", ")", ".", "replace", "(", "'/'", ",", "'_'", ")", "\n", "j", "[", "'source'", "]", "=", "[", "s", ".", "replace", "(", "'\\n'", ",", "' '", ")", ".", "strip", "(", ")", "for", "s", "in", "j", "[", "'source'", "]", "]", "\n", "story", "=", "\"\\n\\n\"", ".", "join", "(", "j", "[", "'source'", "]", ")", "+", "'\\n\\n'", "\n", "summary", "=", "'@highlight\\n\\n'", "+", "'\\n\\n@highlight\\n\\n'", ".", "join", "(", "j", "[", "\"target\"", "]", ")", "\n", "\n", "j", "[", "\"paper_id\"", "]", "=", "str", "(", "j", "[", "\"paper_id\"", "]", ")", ".", "replace", "(", "'/'", ",", "''", ")", "\n", "\n", "with", "open", "(", "join", "(", "args", ".", "out_dir", ",", "'stories'", ",", "f'{j[\"paper_id\"]}.story'", ")", ",", "'w'", ",", "encoding", "=", "'utf-8'", ")", "as", "f", ":", "\n", "        ", "f", ".", "write", "(", "story", ")", "\n", "f", ".", "write", "(", "summary", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_scitldr.SciTLDR-Data.to_stories.build_mapping": [[28, 34], ["open", "os.path.join", "f.write", "str"], "function", ["None"], ["", "", "def", "build_mapping", "(", "args", ",", "corpus_type", ",", "data", ")", ":", "\n", "    ", "if", "corpus_type", "==", "'dev'", ":", "\n", "        ", "corpus_type", "=", "'valid'", "\n", "", "with", "open", "(", "join", "(", "args", ".", "mapping_dir", ",", "f'mapping_{corpus_type}.txt'", ")", ",", "'w'", ")", "as", "f", ":", "\n", "        ", "for", "_", ",", "j", "in", "data", ":", "\n", "            ", "f", ".", "write", "(", "str", "(", "j", "[", "'paper_id'", "]", ")", "+", "'\\n'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_scitldr.SciTLDR-Data.to_stories.main": [[35, 73], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "logging.basicConfig", "time.time", "os.makedirs", "os.makedirs", "os.makedirs", "time.time", "logging.info", "os.path.join", "os.path.join", "os.path.exists", "multiprocessing.cpu_count", "os.path.join", "to_stories.build_batches", "to_stories.build_mapping", "multiprocessing.Pool", "mp.map", "tqdm.tqdm"], "function", ["home.repos.pwc.inspect_result.allenai_scitldr.scripts.novelty_stats.parse_args", "home.repos.pwc.inspect_result.allenai_scitldr.scripts.get_oracle_sents.build_batches", "home.repos.pwc.inspect_result.allenai_scitldr.SciTLDR-Data.to_stories.build_mapping"], ["", "", "", "def", "main", "(", "args", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "parser", ".", "add_argument", "(", "'data_dir'", ",", "type", "=", "str", ",", "help", "=", "'/path/to/*.jsonl'", ")", "\n", "parser", ".", "add_argument", "(", "'--mapping_dir'", ",", "type", "=", "str", ",", "help", "=", "'Default: args.data_dir/mapping'", ")", "\n", "parser", ".", "add_argument", "(", "'--out_dir'", ",", "type", "=", "str", ",", "help", "=", "'Default: args.data_dir'", ")", "\n", "parser", ".", "add_argument", "(", "'--num_cores'", ",", "default", "=", "-", "1", ",", "type", "=", "int", ",", "help", "=", "'Default: half of machine CPUS'", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "logging", ".", "basicConfig", "(", "level", "=", "logging", ".", "INFO", ",", "\n", "format", "=", "'%(message)s'", ")", "\n", "\n", "start", "=", "time", ".", "time", "(", ")", "\n", "\n", "if", "not", "args", ".", "out_dir", ":", "\n", "        ", "args", ".", "out_dir", "=", "args", ".", "data_dir", "\n", "\n", "", "if", "not", "args", ".", "mapping_dir", ":", "\n", "        ", "args", ".", "mapping_dir", "=", "join", "(", "args", ".", "data_dir", ",", "'mapping'", ")", "\n", "\n", "", "makedirs", "(", "args", ".", "out_dir", ",", "exist_ok", "=", "True", ")", "\n", "makedirs", "(", "join", "(", "args", ".", "out_dir", ",", "'stories'", ")", ",", "exist_ok", "=", "True", ")", "\n", "makedirs", "(", "args", ".", "mapping_dir", ",", "exist_ok", "=", "True", ")", "\n", "\n", "if", "args", ".", "num_cores", ">", "0", ":", "\n", "        ", "num_cores", "=", "args", ".", "num_cores", "\n", "", "else", ":", "\n", "        ", "num_cores", "=", "multiprocessing", ".", "cpu_count", "(", ")", "//", "2", "\n", "\n", "", "for", "fname", "in", "[", "'test'", ",", "'dev'", ",", "'train'", "]", ":", "\n", "        ", "if", "exists", "(", "join", "(", "args", ".", "data_dir", ",", "f'{fname}.jsonl'", ")", ")", ":", "\n", "            ", "batches", "=", "build_batches", "(", "args", ",", "f'{fname}.jsonl'", ")", "\n", "build_mapping", "(", "args", ",", "fname", ",", "batches", ")", "\n", "with", "multiprocessing", ".", "Pool", "(", "num_cores", ")", "as", "mp", ":", "\n", "                ", "mp", ".", "map", "(", "format_story", ",", "tqdm", ".", "tqdm", "(", "batches", ")", ")", "\n", "\n", "", "", "", "end", "=", "time", ".", "time", "(", ")", "\n", "\n", "logging", ".", "info", "(", "f'Times to run script: {(end-start)/60} min'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_scitldr.SciTLDR-Data.make_datafiles.read_text_file": [[15, 23], ["print", "open", "lines.append", "line.strip"], "function", ["None"], ["def", "read_text_file", "(", "text_file", ")", ":", "\n", "  ", "lines", "=", "[", "]", "\n", "with", "open", "(", "text_file", ",", "\"r\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "f", ":", "\n", "    ", "for", "line", "in", "f", ":", "\n", "      ", "lines", ".", "append", "(", "line", ".", "strip", "(", ")", ")", "\n", "# import ipdb; ipdb.set_trace()", "\n", "", "", "print", "(", "text_file", ")", "\n", "return", "lines", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_scitldr.SciTLDR-Data.make_datafiles.hashhex": [[25, 30], ["hashlib.sha1", "hashlib.sha1.update", "hashlib.sha1.hexdigest", "s.encode"], "function", ["home.repos.pwc.inspect_result.allenai_scitldr.SciTLDR-Data.multiprocessing_bpe_encoder.MultiprocessingEncoder.encode"], ["", "def", "hashhex", "(", "s", ")", ":", "\n", "  ", "\"\"\"Returns a heximal formated SHA1 hash of the input string.\"\"\"", "\n", "h", "=", "hashlib", ".", "sha1", "(", ")", "\n", "h", ".", "update", "(", "s", ".", "encode", "(", ")", ")", "\n", "return", "h", ".", "hexdigest", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_scitldr.SciTLDR-Data.make_datafiles.get_url_hashes": [[32, 34], ["make_datafiles.hashhex"], "function", ["home.repos.pwc.inspect_result.allenai_scitldr.SciTLDR-Data.make_datafiles.hashhex"], ["", "def", "get_url_hashes", "(", "url_list", ")", ":", "\n", "  ", "return", "[", "hashhex", "(", "url", ")", "for", "url", "in", "url_list", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_scitldr.SciTLDR-Data.make_datafiles.fix_missing_period": [[35, 42], ["None"], "function", ["None"], ["", "def", "fix_missing_period", "(", "line", ")", ":", "\n", "  ", "\"\"\"Adds a period to a line that is missing a period\"\"\"", "\n", "if", "\"@highlight\"", "in", "line", ":", "return", "line", "\n", "if", "line", "==", "\"\"", ":", "return", "line", "\n", "if", "line", "[", "-", "1", "]", "in", "END_TOKENS", ":", "return", "line", "\n", "# print line[-1]", "\n", "return", "line", "+", "\" .\"", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_scitldr.SciTLDR-Data.make_datafiles.get_art_abs": [[44, 71], ["make_datafiles.read_text_file", "enumerate", "make_datafiles.fix_missing_period", "line.startswith", "highlights.append", "article_lines.append"], "function", ["home.repos.pwc.inspect_result.allenai_scitldr.SciTLDR-Data.make_datafiles.read_text_file", "home.repos.pwc.inspect_result.allenai_scitldr.SciTLDR-Data.make_datafiles.fix_missing_period"], ["", "def", "get_art_abs", "(", "story_file", ")", ":", "\n", "  ", "lines", "=", "read_text_file", "(", "story_file", ")", "\n", "\n", "# Put periods on the ends of lines that are missing them (this is a problem in the dataset because many image captions don't end in periods; consequently they end up in the body of the article as run-on sentences)", "\n", "lines", "=", "[", "fix_missing_period", "(", "line", ")", "for", "line", "in", "lines", "]", "\n", "\n", "# Separate out article and abstract sentences", "\n", "article_lines", "=", "[", "]", "\n", "highlights", "=", "[", "]", "\n", "next_is_highlight", "=", "False", "\n", "for", "idx", ",", "line", "in", "enumerate", "(", "lines", ")", ":", "\n", "    ", "if", "line", "==", "\"\"", ":", "\n", "      ", "continue", "# empty line", "\n", "", "elif", "line", ".", "startswith", "(", "\"@highlight\"", ")", ":", "\n", "      ", "next_is_highlight", "=", "True", "\n", "", "elif", "next_is_highlight", ":", "\n", "      ", "highlights", ".", "append", "(", "line", ")", "\n", "", "else", ":", "\n", "      ", "article_lines", ".", "append", "(", "line", ")", "\n", "\n", "# Make article into a single string", "\n", "", "", "article", "=", "' '", ".", "join", "(", "article_lines", ")", "\n", "\n", "# Make abstract into a signle string", "\n", "abstract", "=", "' '", ".", "join", "(", "highlights", ")", "\n", "\n", "return", "article", ",", "abstract", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_scitldr.SciTLDR-Data.make_datafiles.write_to_bin": [[73, 99], ["print", "make_datafiles.read_text_file", "len", "print", "open", "open", "enumerate", "os.path.isfile", "make_datafiles.get_art_abs", "source_file.write", "target_file.write", "print", "os.path.join", "os.path.join", "print", "float", "float"], "function", ["home.repos.pwc.inspect_result.allenai_scitldr.SciTLDR-Data.make_datafiles.read_text_file", "home.repos.pwc.inspect_result.allenai_scitldr.SciTLDR-Data.make_datafiles.get_art_abs"], ["", "def", "write_to_bin", "(", "url_file", ",", "stories_dir", ",", "out_prefix", ")", ":", "\n", "  ", "\"\"\"Reads the .story files corresponding to the urls listed in the url_file and writes them to a out_file.\"\"\"", "\n", "print", "(", "\"Making bin file for URLs listed in %s...\"", "%", "url_file", ")", "\n", "url_list", "=", "read_text_file", "(", "url_file", ")", "\n", "# url_hashes = get_url_hashes(url_list)", "\n", "story_fnames", "=", "[", "s", "+", "\".story\"", "for", "s", "in", "url_list", "]", "\n", "num_stories", "=", "len", "(", "story_fnames", ")", "\n", "\n", "with", "open", "(", "out_prefix", "+", "'.source'", ",", "'wt'", ",", "encoding", "=", "\"utf-8\"", ")", "as", "source_file", ",", "open", "(", "out_prefix", "+", "'.target'", ",", "'wt'", ",", "encoding", "=", "\"utf-8\"", ")", "as", "target_file", ":", "\n", "    ", "for", "idx", ",", "s", "in", "enumerate", "(", "story_fnames", ")", ":", "\n", "      ", "if", "idx", "%", "1000", "==", "0", ":", "\n", "        ", "print", "(", "\"Writing story %i of %i; %.2f percent done\"", "%", "(", "idx", ",", "num_stories", ",", "float", "(", "idx", ")", "*", "100.0", "/", "float", "(", "num_stories", ")", ")", ")", "\n", "\n", "# Look in the story dirs to find the .story file corresponding to this url", "\n", "", "if", "os", ".", "path", ".", "isfile", "(", "os", ".", "path", ".", "join", "(", "stories_dir", ",", "s", ")", ")", ":", "\n", "        ", "story_file", "=", "os", ".", "path", ".", "join", "(", "stories_dir", ",", "s", ")", "\n", "", "else", ":", "\n", "        ", "print", "(", "\"Error: Couldn't find story file %s in either story directory %s\"", "%", "(", "s", ",", "stories_dir", ")", ")", "\n", "# Get the strings to write to .bin file", "\n", "", "article", ",", "abstract", "=", "get_art_abs", "(", "story_file", ")", "\n", "\n", "# Write article and abstract to files", "\n", "source_file", ".", "write", "(", "article", "+", "'\\n'", ")", "\n", "target_file", ".", "write", "(", "abstract", "+", "'\\n'", ")", "\n", "\n", "", "", "print", "(", "\"Finished writing files\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_scitldr.scripts.get_oracle_sents.build_batches": [[6, 25], ["open", "f.readlines", "map", "batches.append", "json.loads", "type", "x.strip"], "function", ["None"], ["def", "build_batches", "(", "datapath", ")", ":", "\n", "    ", "batches", "=", "[", "]", "\n", "with", "open", "(", "datapath", ")", "as", "f", ":", "\n", "        ", "lines", "=", "f", ".", "readlines", "(", ")", "\n", "lines", "=", "map", "(", "lambda", "x", ":", "json", ".", "loads", "(", "x", ".", "strip", "(", ")", ")", ",", "lines", ")", "\n", "for", "_j", "in", "lines", ":", "\n", "            ", "candidates", ",", "references", ",", "paper_ids", "=", "[", "]", ",", "[", "]", ",", "[", "]", "\n", "candidates", "=", "_j", "[", "'source'", "]", "\n", "if", "type", "(", "_j", "[", "'target'", "]", ")", "==", "list", ":", "\n", "                ", "references", "=", "_j", "[", "'target'", "]", "\n", "", "else", ":", "\n", "                ", "references", "=", "[", "j", "[", "'target'", "]", "]", "\n", "", "paper_id", "=", "_j", "[", "'paper_id'", "]", "\n", "batches", ".", "append", "(", "{", "\n", "'candidates'", ":", "candidates", ",", "\n", "'references'", ":", "references", ",", "\n", "'paper_ids'", ":", "paper_ids", "\n", "}", ")", "\n", "", "", "return", "batches", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_scitldr.scripts.get_oracle_sents.get_oracle_single_paper": [[26, 52], ["rouge.Rouge", "max_sent.replace().strip", "len", "c.strip", "rouge.Rouge.get_scores", "r1.index", "get_oracle_sents.get_oracle_single_paper.check_length"], "function", ["None"], ["", "def", "get_oracle_single_paper", "(", "batch", ")", ":", "\n", "    ", "candidates", "=", "batch", "[", "'candidates'", "]", "\n", "references", "=", "batch", "[", "'references'", "]", "\n", "\n", "evaluator", "=", "rouge", ".", "Rouge", "(", ")", "\n", "max_r1", "=", "0.", "\n", "max_score", "=", "None", "\n", "max_sent", "=", "''", "\n", "def", "check_length", "(", "c", ")", ":", "\n", "        ", "l", "=", "len", "(", "c", ")", "\n", "if", "l", "<", "5", "or", "l", ">", "2500", ":", "\n", "            ", "return", "0", "\n", "", "return", "1", "\n", "# sentences with too long or too short of characters will break the script", "\n", "", "candidates", "=", "[", "c", ".", "strip", "(", ")", "for", "c", "in", "candidates", "if", "check_length", "(", "c", ")", "]", "\n", "for", "tgt", "in", "references", ":", "\n", "        ", "ref", "=", "[", "tgt", "]", "*", "len", "(", "candidates", ")", "\n", "scores", "=", "evaluator", ".", "get_scores", "(", "candidates", ",", "ref", ")", "\n", "r1", "=", "[", "s", "[", "'rouge-1'", "]", "[", "'f'", "]", "for", "s", "in", "scores", "]", "\n", "max_idx", "=", "r1", ".", "index", "(", "max", "(", "r1", ")", ")", "\n", "if", "max_r1", "<", "r1", "[", "max_idx", "]", ":", "\n", "            ", "max_r1", "=", "r1", "[", "max_idx", "]", "\n", "max_score", "=", "scores", "[", "max_idx", "]", "\n", "max_sent", "=", "candidates", "[", "max_idx", "]", "\n", "\n", "", "", "return", "max_sent", ".", "replace", "(", "'\\n'", ",", "''", ")", ".", "strip", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_scitldr.scripts.convert_matchsum_predictions_to_files2rouge.main": [[4, 23], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "glob.glob", "glob.glob", "open", "open", "ref.append", "open", "res.append", "fout.write", "fout.write", "fin.read().strip", "fin.read().strip", "e.strip().replace", "fin.read", "fin.read", "e.strip"], "function", ["home.repos.pwc.inspect_result.allenai_scitldr.scripts.novelty_stats.parse_args"], ["def", "main", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "parser", ".", "add_argument", "(", "'input'", ",", "help", "=", "''", ")", "\n", "parser", ".", "add_argument", "(", "'output'", ",", "help", "=", "''", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "ref", "=", "[", "]", "\n", "for", "f", "in", "glob", ".", "glob", "(", "args", ".", "input", "+", "'/**/*.ref'", ",", "recursive", "=", "True", ")", ":", "\n", "        ", "with", "open", "(", "f", ")", "as", "fin", ":", "\n", "            ", "ref", ".", "append", "(", "fin", ".", "read", "(", ")", ".", "strip", "(", ")", ")", "\n", "", "", "res", "=", "[", "]", "\n", "i", "=", "0", "\n", "for", "f", "in", "glob", ".", "glob", "(", "args", ".", "input", "+", "'/**/*.dec'", ",", "recursive", "=", "True", ")", ":", "\n", "        ", "with", "open", "(", "f", ")", "as", "fin", ":", "\n", "            ", "res", ".", "append", "(", "fin", ".", "read", "(", ")", ".", "strip", "(", ")", ")", "\n", "", "", "with", "open", "(", "args", ".", "output", ",", "'w'", ")", "as", "fout", ":", "\n", "        ", "for", "e", "in", "res", ":", "\n", "            ", "fout", ".", "write", "(", "e", ".", "strip", "(", ")", ".", "replace", "(", "'\\n'", ",", "' '", ")", ")", "\n", "fout", ".", "write", "(", "'\\n'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_scitldr.scripts.convert_scitldr_to_matchsum.main": [[5, 24], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "open", "open", "open", "json.loads", "fout.write", "fout.write", "fout2.write", "fout2.write", "json.dumps", "json.dumps", "isinstance", "range", "len"], "function", ["home.repos.pwc.inspect_result.allenai_scitldr.scripts.novelty_stats.parse_args"], ["def", "main", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "parser", ".", "add_argument", "(", "'input'", ",", "help", "=", "''", ")", "\n", "parser", ".", "add_argument", "(", "'output'", ",", "help", "=", "''", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "sent_ids_file", "=", "args", ".", "output", "[", ":", "-", "6", "]", "+", "'-sent-ids.jsonl'", "\n", "indexes", "=", "[", "]", "\n", "with", "open", "(", "args", ".", "input", ")", "as", "fin", ",", "open", "(", "args", ".", "output", ",", "'w'", ")", "as", "fout", ",", "open", "(", "sent_ids_file", ",", "'w'", ")", "as", "fout2", ":", "\n", "            ", "for", "line", "in", "fin", ":", "\n", "                ", "obj", "=", "json", ".", "loads", "(", "line", ")", "\n", "new_obj", "=", "{", "'text'", ":", "obj", "[", "'source'", "]", ",", "\n", "'summary'", ":", "[", "obj", "[", "'target'", "]", "[", "0", "]", "]", "if", "isinstance", "(", "obj", "[", "'target'", "]", ",", "list", ")", "else", "[", "obj", "[", "'target'", "]", "]", ",", "\n", "'summary_id'", ":", "obj", "[", "'paper_id'", "]", "}", "\n", "fout", ".", "write", "(", "json", ".", "dumps", "(", "new_obj", ")", ")", "\n", "fout", ".", "write", "(", "'\\n'", ")", "\n", "sent_ids", "=", "{", "\"sent_id\"", ":", "[", "i", "for", "i", "in", "range", "(", "len", "(", "obj", "[", "'source'", "]", ")", ")", "]", "}", "\n", "fout2", ".", "write", "(", "json", ".", "dumps", "(", "sent_ids", ")", ")", "\n", "fout2", ".", "write", "(", "'\\n'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_scitldr.scripts.generate.generate_TLDRs": [[10, 52], ["fairseq.models.bart.BARTModel.from_pretrained", "torch.cuda.is_available", "BARTModel.from_pretrained.eval", "os.path.join", "os.path.join", "BARTModel.from_pretrained.cuda", "BARTModel.from_pretrained.half", "open", "open", "source.readline().strip", "tqdm.tqdm", "slines.append", "BARTModel.from_pretrained.sample", "source.readline", "source.readline().strip.strip", "fout.write", "fout.flush", "torch.no_grad", "BARTModel.from_pretrained.sample", "fout.write", "fout.flush", "hypothesis.replace"], "function", ["None"], ["def", "generate_TLDRs", "(", "bsz", ",", "count", ",", "datadir", ",", "outdir", ",", "\n", "checkpoint_dir", ",", "checkpoint_file", ",", "test_fname", ",", "\n", "beam", ",", "lenpen", ",", "max_len_b", ",", "min_len", ",", "no_repeat_ngram_size", ")", ":", "\n", "    ", "bart", "=", "BARTModel", ".", "from_pretrained", "(", "\n", "checkpoint_dir", ",", "\n", "checkpoint_file", "=", "checkpoint_file", ",", "\n", "data_name_or_path", "=", "datadir", "+", "'-bin'", ",", "\n", "task", "=", "'translation'", "\n", ")", "\n", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "        ", "bart", ".", "cuda", "(", ")", "\n", "bart", ".", "half", "(", ")", "\n", "", "bart", ".", "eval", "(", ")", "\n", "source_fname", "=", "join", "(", "datadir", ",", "'test.source'", ")", "\n", "pred_fname", "=", "join", "(", "outdir", ",", "test_fname", ")", "\n", "with", "open", "(", "source_fname", ",", "encoding", "=", "\"utf-8\"", ")", "as", "source", ",", "open", "(", "pred_fname", ",", "'w'", ",", "encoding", "=", "\"utf-8\"", ")", "as", "fout", ":", "\n", "        ", "sline", "=", "source", ".", "readline", "(", ")", ".", "strip", "(", ")", "\n", "slines", "=", "[", "sline", "]", "\n", "for", "sline", "in", "tqdm", "(", "source", ")", ":", "\n", "            ", "if", "count", "%", "bsz", "==", "0", ":", "\n", "                ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                    ", "hypotheses_batch", "=", "bart", ".", "sample", "(", "slines", ",", "beam", "=", "beam", ",", "\n", "lenpen", "=", "lenpen", ",", "\n", "max_len_b", "=", "max_len_b", ",", "\n", "min_len", "=", "min_len", ",", "\n", "no_repeat_ngram_size", "=", "no_repeat_ngram_size", ")", "\n", "", "for", "hypothesis", "in", "hypotheses_batch", ":", "\n", "                    ", "fout", ".", "write", "(", "hypothesis", "+", "'\\n'", ")", "\n", "fout", ".", "flush", "(", ")", "\n", "", "slines", "=", "[", "]", "\n", "\n", "", "slines", ".", "append", "(", "sline", ".", "strip", "(", ")", ")", "\n", "count", "+=", "1", "\n", "", "if", "slines", "!=", "[", "]", ":", "\n", "            ", "hypotheses_batch", "=", "bart", ".", "sample", "(", "slines", ",", "beam", "=", "beam", ",", "\n", "lenpen", "=", "lenpen", ",", "\n", "max_len_b", "=", "max_len_b", ",", "\n", "min_len", "=", "min_len", ",", "\n", "no_repeat_ngram_size", "=", "no_repeat_ngram_size", ")", "\n", "for", "hypothesis", "in", "hypotheses_batch", ":", "\n", "                ", "fout", ".", "write", "(", "hypothesis", ".", "replace", "(", "'\\n'", ",", "' '", ")", "+", "'\\n'", ")", "\n", "fout", ".", "flush", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_scitldr.scripts.generate.maybe_percentages": [[53, 60], ["None"], "function", ["None"], ["", "", "", "", "def", "maybe_percentages", "(", "r", ",", "percentages", ")", ":", "\n", "    ", "if", "percentages", ":", "\n", "        ", "for", "r_type", "in", "[", "'rouge-1'", ",", "'rouge-2'", ",", "'rouge-l'", "]", ":", "\n", "            ", "for", "m_type", "in", "[", "'f'", ",", "'p'", ",", "'r'", "]", ":", "\n", "                ", "x", "=", "r", "[", "r_type", "]", "[", "m_type", "]", "\n", "r", "[", "r_type", "]", "[", "m_type", "]", "=", "x", "*", "100", "\n", "", "", "", "return", "r", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_scitldr.scripts.cal-rouge.filter_rouge": [[26, 46], ["output_string.split", "re.search", "re.search", "re.search.group().lower", "eval", "re.search.group", "re.search.group", "re.search.group"], "function", ["None"], ["def", "filter_rouge", "(", "output_string", ")", ":", "\n", "    ", "reg", "=", "\"ROUGE-(1|2|L) Average_(R|P|F): (\\d.\\d+)\"", "\n", "lines", "=", "output_string", ".", "split", "(", "'\\n'", ")", "\n", "_j", "=", "{", "}", "\n", "for", "l", "in", "lines", ":", "\n", "        ", "if", "re", ".", "search", "(", "reg", ",", "l", ")", ":", "\n", "            ", "match", "=", "re", ".", "search", "(", "reg", ",", "l", ")", "\n", "r_type", "=", "f'rouge-{match.group(1)}'", ".", "lower", "(", ")", "# {1,2,L}", "\n", "m_type", "=", "match", ".", "group", "(", "2", ")", ".", "lower", "(", ")", "# {R, P, F}", "\n", "value", "=", "eval", "(", "match", ".", "group", "(", "3", ")", ")", "\n", "# import ipdb; ipdb.set_trace()", "\n", "if", "r_type", "not", "in", "_j", ":", "\n", "                ", "_j", "[", "r_type", "]", "=", "{", "}", "\n", "", "elif", "'f'", "==", "m_type", ":", "\n", "                ", "_j", "[", "r_type", "]", "=", "value", "\n", "# res = {}", "\n", "# for k, v in rouge.items():", "\n", "#     if 'f_score' in k:", "\n", "#         res[k] = v", "\n", "", "", "", "return", "_j", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_scitldr.scripts.cal-rouge.get_rouge": [[47, 49], ["cal-rouge._get_rouge"], "function", ["home.repos.pwc.inspect_result.allenai_scitldr.scripts.cal-rouge._get_rouge"], ["", "def", "get_rouge", "(", "args", ")", ":", "\n", "    ", "return", "_get_rouge", "(", "args", "[", "'pred'", "]", ",", "args", "[", "'data'", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_scitldr.scripts.cal-rouge._get_rouge": [[50, 88], ["collections.defaultdict", "collections.defaultdict.items", "tempfile.TemporaryDirectory", "os.path.join", "os.path.join", "enumerate", "open", "fh.write", "isinstance", "os.path.join", "files2rouge.files2rouge.run", "pathlib.Path().read_text", "cal-rouge.filter_rouge", "filter_rouge.items", "sum", "len", "pred.strip", "open", "fh.write", "rouge_multi_mean[].append", "gold_tldr.strip", "pathlib.Path"], "function", ["home.repos.pwc.inspect_result.allenai_scitldr.scripts.cal-rouge.filter_rouge"], ["", "def", "_get_rouge", "(", "pred", ",", "data", ")", ":", "\n", "    ", "\"\"\" given a prediction (pred) and a data object, calculate rouge scores \n    pred: str\n    data: {'target': str, '': ...}\n\n    returns (author rouge score, multi-target rouge score (by max), multi-target rouge score (by mean))\n    \"\"\"", "\n", "rouge_author_score", "=", "{", "}", "\n", "rouge_multi_mean", "=", "defaultdict", "(", "list", ")", "\n", "with", "tempfile", ".", "TemporaryDirectory", "(", ")", "as", "td", ":", "\n", "        ", "cand_file", "=", "os", ".", "path", ".", "join", "(", "td", ",", "'cand'", ")", "\n", "max_curr_rouge", "=", "-", "1000", "\n", "author_rouge_f1", "=", "0", "\n", "curr_rouge", "=", "{", "}", "\n", "with", "open", "(", "cand_file", ",", "'w'", ")", "as", "fh", ":", "\n", "            ", "fh", ".", "write", "(", "pred", ".", "strip", "(", ")", ")", "\n", "", "if", "not", "isinstance", "(", "data", "[", "'target'", "]", ",", "list", ")", ":", "# handle single target", "\n", "            ", "data", "[", "'target'", "]", "=", "[", "data", "[", "'target'", "]", "]", "\n", "", "log_file", "=", "os", ".", "path", ".", "join", "(", "td", ",", "'rouge.log'", ")", "\n", "for", "i", ",", "gold_tldr", "in", "enumerate", "(", "data", "[", "'target'", "]", ")", ":", "\n", "            ", "gold_file", "=", "os", ".", "path", ".", "join", "(", "td", ",", "'gold'", ")", "\n", "with", "open", "(", "gold_file", ",", "'w'", ")", "as", "fh", ":", "\n", "                ", "fh", ".", "write", "(", "gold_tldr", ".", "strip", "(", ")", ")", "\n", "", "files2rouge", ".", "run", "(", "cand_file", ",", "gold_file", ",", "ignore_empty", "=", "True", ",", "saveto", "=", "log_file", ")", "\n", "rouge_score", "=", "Path", "(", "log_file", ")", ".", "read_text", "(", ")", "\n", "rouge_score", "=", "filter_rouge", "(", "rouge_score", ")", "\n", "if", "max_curr_rouge", "<", "rouge_score", "[", "'rouge-1'", "]", ":", "\n", "                ", "curr_rouge", "=", "rouge_score", "\n", "max_curr_rouge", "=", "rouge_score", "[", "'rouge-1'", "]", "\n", "", "if", "i", "==", "0", ":", "\n", "                ", "rouge_author_score", "=", "rouge_score", "\n", "author_rouge_f1", "=", "rouge_score", "[", "'rouge-1'", "]", "\n", "", "for", "k", ",", "v", "in", "rouge_score", ".", "items", "(", ")", ":", "\n", "                ", "rouge_multi_mean", "[", "k", "]", ".", "append", "(", "v", ")", "\n", "", "", "", "for", "k", ",", "v", "in", "rouge_multi_mean", ".", "items", "(", ")", ":", "\n", "        ", "rouge_multi_mean", "[", "k", "]", "=", "sum", "(", "v", ")", "/", "len", "(", "v", ")", "\n", "", "rouge_multi_max", "=", "curr_rouge", "\n", "return", "rouge_author_score", ",", "rouge_multi_max", ",", "rouge_multi_mean", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_scitldr.scripts.cal-rouge.process": [[90, 125], ["print", "pandas.DataFrame", "pandas.DataFrame", "pandas.DataFrame", "pandas.DataFrame", "zip", "open", "open", "len", "pandas.concat", "all_dfs.rename.rename", "json.loads", "line.strip", "zip", "multiprocessing.pool.Pool", "list", "cal-rouge.get_rouge", "tqdm.auto.tqdm", "tqdm.auto.tqdm", "p.imap", "len", "zip"], "function", ["home.repos.pwc.inspect_result.allenai_scitldr.scripts.cal-rouge.get_rouge"], ["", "def", "process", "(", "gold_file", ",", "candidate_file", ",", "method_name", ",", "args", ")", ":", "\n", "    ", "with", "open", "(", "gold_file", ")", "as", "fin", ":", "\n", "        ", "all_data", "=", "[", "json", ".", "loads", "(", "line", ")", "for", "line", "in", "fin", "]", "\n", "", "with", "open", "(", "candidate_file", ")", "as", "fin", ":", "\n", "        ", "all_preds", "=", "[", "line", ".", "strip", "(", ")", "for", "line", "in", "fin", "]", "\n", "", "all_rouges", "=", "[", "]", "\n", "all_rouges_author", "=", "[", "]", "\n", "all_rouges_pr", "=", "[", "]", "\n", "count_diff_rouge", "=", "0", "\n", "\n", "data", "=", "[", "{", "'pred'", ":", "pred", ",", "'data'", ":", "data", "}", "for", "pred", ",", "data", "in", "zip", "(", "all_preds", ",", "all_data", ")", "]", "\n", "if", "args", ".", "workers", ">", "1", ":", "\n", "        ", "with", "Pool", "(", "args", ".", "workers", ")", "as", "p", ":", "\n", "            ", "results", "=", "list", "(", "tqdm", "(", "p", ".", "imap", "(", "get_rouge", ",", "data", ")", ",", "total", "=", "len", "(", "data", ")", ",", "unit_scale", "=", "1", ")", ")", "\n", "", "", "else", ":", "\n", "        ", "results", "=", "[", "get_rouge", "(", "d", ")", "for", "d", "in", "tqdm", "(", "data", ")", "]", "\n", "\n", "", "count_diff", "=", "0", "\n", "for", "e1", ",", "e2", ",", "e3", "in", "results", ":", "\n", "        ", "if", "e1", "[", "'rouge-1'", "]", "!=", "e2", "[", "'rouge-1'", "]", ":", "\n", "            ", "count_diff", "+=", "1", "\n", "", "", "print", "(", "count_diff", ",", "len", "(", "results", ")", ")", "\n", "\n", "df_author", "=", "pd", ".", "DataFrame", "(", "[", "e", "[", "0", "]", "for", "e", "in", "results", "]", ",", "columns", "=", "[", "'rouge-1'", ",", "'rouge-2'", ",", "'rouge-l'", "]", ")", "\n", "df_multi_max", "=", "pd", ".", "DataFrame", "(", "[", "e", "[", "1", "]", "for", "e", "in", "results", "]", ",", "columns", "=", "[", "'rouge-1'", ",", "'rouge-2'", ",", "'rouge-l'", "]", ")", "\n", "df_multi_mean", "=", "pd", ".", "DataFrame", "(", "[", "e", "[", "2", "]", "for", "e", "in", "results", "]", ",", "columns", "=", "[", "'rouge-1'", ",", "'rouge-2'", ",", "'rouge-l'", "]", ")", "\n", "\n", "columns", "=", "[", "'rouge-1'", ",", "'rouge-2'", ",", "'rouge-l'", "]", "\n", "all_dfs", "=", "pd", ".", "DataFrame", "(", ")", "\n", "for", "metric_type", ",", "df", "in", "zip", "(", "[", "'author'", ",", "'multi-max'", ",", "'multi-mean'", "]", ",", "(", "df_author", ",", "df_multi_max", ",", "df_multi_mean", ")", ")", ":", "\n", "        ", "new_columns", "=", "[", "f'R1||{metric_type}||{method_name}'", ",", "f'R2||{metric_type}||{method_name}'", ",", "f'RL||{metric_type}||{method_name}'", "]", "\n", "all_dfs", "=", "pd", ".", "concat", "(", "[", "all_dfs", ",", "df", "]", ",", "axis", "=", "1", ")", "\n", "all_dfs", "=", "all_dfs", ".", "rename", "(", "columns", "=", "{", "e1", ":", "e2", "for", "e1", ",", "e2", "in", "zip", "(", "columns", ",", "new_columns", ")", "}", ")", "\n", "\n", "", "return", "all_dfs", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_scitldr.scripts.cal-rouge.parse_args": [[128, 138], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args"], "function", ["home.repos.pwc.inspect_result.allenai_scitldr.scripts.novelty_stats.parse_args"], ["", "def", "parse_args", "(", ")", ":", "\n", "    ", "ap", "=", "ArgumentParser", "(", ")", "\n", "ap", ".", "add_argument", "(", "'candidate'", ")", "\n", "ap", ".", "add_argument", "(", "'gold'", ")", "\n", "ap", ".", "add_argument", "(", "'--output'", ")", "\n", "ap", ".", "add_argument", "(", "'--run-over-dir'", ",", "default", "=", "False", ",", "action", "=", "'store_true'", ",", "help", "=", "'run over all the methods in the directory'", ")", "\n", "ap", ".", "add_argument", "(", "'--workers'", ",", "default", "=", "1", ",", "type", "=", "int", ")", "\n", "ap", ".", "add_argument", "(", "'--regex'", ",", "default", "=", "None", ")", "\n", "args", "=", "ap", ".", "parse_args", "(", ")", "\n", "return", "args", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_scitldr.scripts.cal-rouge.main": [[139, 157], ["cal-rouge.parse_args", "glob.glob", "pandas.DataFrame", "tqdm.auto.tqdm", "cal-rouge.process", "print", "pathlib.Path().parent.mkdir", "pd.concat.to_csv", "cal-rouge.process", "pandas.concat", "pd.concat.mean", "f.split", "parse_args.candidate.split", "pathlib.Path"], "function", ["home.repos.pwc.inspect_result.allenai_scitldr.scripts.novelty_stats.parse_args", "home.repos.pwc.inspect_result.allenai_scitldr.scripts.cal-rouge.process", "home.repos.pwc.inspect_result.allenai_scitldr.scripts.cal-rouge.process"], ["", "def", "main", "(", ")", ":", "\n", "    ", "args", "=", "parse_args", "(", ")", "\n", "if", "args", ".", "run_over_dir", ":", "\n", "        ", "files", "=", "glob", ".", "glob", "(", "args", ".", "candidate", "+", "'/**/*.hypo'", ",", "recursive", "=", "True", ")", "\n", "all_dfs", "=", "pd", ".", "DataFrame", "(", ")", "\n", "for", "f", "in", "tqdm", "(", "files", ")", ":", "\n", "            ", "if", "args", ".", "regex", ":", "\n", "                ", "if", "args", ".", "regex", "not", "in", "f", ":", "\n", "                    ", "continue", "\n", "", "", "method_name", "=", "f", ".", "split", "(", "'/'", ")", "[", "-", "1", "]", "\n", "df", "=", "process", "(", "args", ".", "gold", ",", "f", ",", "method_name", ",", "args", ")", "\n", "all_dfs", "=", "pd", ".", "concat", "(", "[", "all_dfs", ",", "df", "]", ",", "axis", "=", "1", ")", "\n", "", "", "else", ":", "\n", "        ", "all_dfs", "=", "process", "(", "args", ".", "gold", ",", "args", ".", "candidate", ",", "args", ".", "candidate", ".", "split", "(", "'/'", ")", "[", "-", "1", "]", ",", "args", ")", "\n", "print", "(", "all_dfs", ".", "mean", "(", ")", ")", "\n", "", "if", "args", ".", "output", ":", "\n", "        ", "pathlib", ".", "Path", "(", "args", ".", "output", ")", ".", "parent", ".", "mkdir", "(", "parents", "=", "True", ",", "exist_ok", "=", "True", ")", "\n", "all_dfs", ".", "to_csv", "(", "args", ".", "output", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_scitldr.scripts.generation_stats.get_novelty": [[14, 20], ["list", "nltk.util.ngrams", "set", "nltk.util.ngrams", "len", "len", "len"], "function", ["None"], ["def", "get_novelty", "(", "summ", ",", "text", ",", "ngram", "=", "1", ")", ":", "\n", "    ", "summ_tokens", "=", "list", "(", "ngrams", "(", "summ", ",", "ngram", ")", ")", "\n", "text_tokens", "=", "ngrams", "(", "text", ",", "ngram", ")", "\n", "all_tokens", "=", "set", "(", "text_tokens", ")", "\n", "res", "=", "len", "(", "[", "e", "for", "e", "in", "summ_tokens", "if", "e", "not", "in", "all_tokens", "]", ")", "/", "len", "(", "summ_tokens", ")", "if", "len", "(", "summ_tokens", ")", ">", "0", "else", "0", "\n", "return", "res", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_scitldr.scripts.generation_stats.word_tokenize": [[22, 24], ["text.split"], "function", ["None"], ["", "def", "word_tokenize", "(", "text", ")", ":", "\n", "    ", "return", "text", ".", "split", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_scitldr.scripts.generation_stats.get_stats": [[26, 34], ["generation_stats.word_tokenize", "generation_stats.word_tokenize", "generation_stats.get_novelty", "generation_stats.get_novelty", "generation_stats.get_novelty", "len", "len"], "function", ["home.repos.pwc.inspect_result.allenai_scitldr.scripts.novelty_stats.word_tokenize", "home.repos.pwc.inspect_result.allenai_scitldr.scripts.novelty_stats.word_tokenize", "home.repos.pwc.inspect_result.allenai_scitldr.scripts.novelty_stats.get_novelty", "home.repos.pwc.inspect_result.allenai_scitldr.scripts.novelty_stats.get_novelty", "home.repos.pwc.inspect_result.allenai_scitldr.scripts.novelty_stats.get_novelty"], ["", "def", "get_stats", "(", "dataset_instance", ")", ":", "\n", "    ", "\"\"\" dataset_instance is a dict with two fields `summary` and `text` \"\"\"", "\n", "summ_tokens", "=", "word_tokenize", "(", "dataset_instance", "[", "'summary'", "]", ")", "\n", "text_tokens", "=", "word_tokenize", "(", "dataset_instance", "[", "'text'", "]", ")", "\n", "novelty1", "=", "get_novelty", "(", "summ_tokens", ",", "text_tokens", ",", "1", ")", "\n", "novelty2", "=", "get_novelty", "(", "summ_tokens", ",", "text_tokens", ",", "2", ")", "\n", "novelty3", "=", "get_novelty", "(", "summ_tokens", ",", "text_tokens", ",", "3", ")", "\n", "return", "novelty1", ",", "novelty2", ",", "novelty3", ",", "len", "(", "summ_tokens", ")", ",", "len", "(", "text_tokens", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_scitldr.scripts.generation_stats.main": [[36, 71], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "tqdm.auto.tqdm", "pandas.DataFrame", "pd.DataFrame.T.to_csv", "open", "open", "glob.glob", "numpy.array().mean", "open", "f.split", "data.append", "zip", "multiprocessing.pool.Pool", "list", "generation_stats.get_stats", "numpy.array", "json.loads", "json.loads", "line.strip", "tqdm.auto.tqdm", "tqdm.auto.tqdm", "p.imap", "len"], "function", ["home.repos.pwc.inspect_result.allenai_scitldr.scripts.novelty_stats.parse_args", "home.repos.pwc.inspect_result.allenai_scitldr.scripts.novelty_stats.get_stats"], ["", "def", "main", "(", ")", ":", "\n", "    ", "ap", "=", "ArgumentParser", "(", ")", "\n", "ap", ".", "add_argument", "(", "'file'", ")", "\n", "ap", ".", "add_argument", "(", "'--test-aic'", ")", "\n", "ap", ".", "add_argument", "(", "'--test-ao'", ")", "\n", "ap", ".", "add_argument", "(", "'--workers'", ",", "type", "=", "int", ",", "default", "=", "1", ")", "\n", "ap", ".", "add_argument", "(", "'--output'", ")", "\n", "args", "=", "ap", ".", "parse_args", "(", ")", "\n", "lenghts", "=", "[", "]", "\n", "methods", "=", "[", "]", "\n", "res", "=", "{", "}", "\n", "\n", "with", "open", "(", "args", ".", "test_aic", ")", "as", "mf", ":", "\n", "        ", "aic_corpus", "=", "[", "' '", ".", "join", "(", "json", ".", "loads", "(", "e", ")", "[", "'source'", "]", ")", "for", "e", "in", "mf", "]", "\n", "", "with", "open", "(", "args", ".", "test_ao", ")", "as", "mf", ":", "\n", "        ", "ao_corpus", "=", "[", "' '", ".", "join", "(", "json", ".", "loads", "(", "e", ")", "[", "'source'", "]", ")", "for", "e", "in", "mf", "]", "\n", "\n", "", "for", "f", "in", "tqdm", "(", "glob", ".", "glob", "(", "args", ".", "file", "+", "'/*.hypo'", ")", ")", ":", "\n", "        ", "data", "=", "[", "]", "\n", "with", "open", "(", "f", ")", "as", "fin", ":", "\n", "            ", "for", "line", "in", "fin", ":", "\n", "                ", "data", ".", "append", "(", "line", ".", "strip", "(", ")", ")", "\n", "", "", "method", "=", "f", ".", "split", "(", "'/'", ")", "[", "-", "1", "]", "\n", "text", "=", "aic_corpus", "if", "'aic'", "in", "f", "else", "ao_corpus", "\n", "dataset", "=", "[", "{", "'summary'", ":", "e1", ",", "'text'", ":", "e2", "}", "for", "e1", ",", "e2", "in", "zip", "(", "data", ",", "text", ")", "]", "\n", "\n", "if", "args", ".", "workers", ">", "1", ":", "\n", "            ", "with", "Pool", "(", "args", ".", "workers", ")", "as", "p", ":", "\n", "                ", "results", "=", "list", "(", "tqdm", "(", "p", ".", "imap", "(", "get_stats", ",", "dataset", ")", ",", "total", "=", "len", "(", "dataset", ")", ",", "unit_scale", "=", "1", ")", ")", "\n", "", "", "else", ":", "\n", "            ", "results", "=", "[", "get_stats", "(", "d", ")", "for", "d", "in", "tqdm", "(", "dataset", ")", "]", "\n", "", "res", "[", "method", "]", "=", "np", ".", "array", "(", "results", ")", ".", "mean", "(", "axis", "=", "0", ")", "\n", "\n", "", "df", "=", "pd", ".", "DataFrame", "(", "res", ")", "\n", "df", ".", "T", ".", "to_csv", "(", "args", ".", "output", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_scitldr.scripts.lexical_variation.get_ngrams": [[14, 26], ["nlp", "len", "orig_text.split", "set", "len", "set", "len", "range", "s.lower", "len"], "function", ["None"], ["def", "get_ngrams", "(", "orig_text", ")", ":", "\n", "    ", "doc", "=", "nlp", "(", "orig_text", ")", "\n", "if", "args", ".", "lemma", ":", "\n", "        ", "text", "=", "[", "word", ".", "lemma_", "for", "word", "in", "doc", "]", "\n", "", "else", ":", "\n", "        ", "text", "=", "[", "word", ".", "text", "for", "word", "in", "doc", "]", "\n", "\n", "", "if", "len", "(", "text", ")", "<", "args", ".", "n_gram", ":", "\n", "        ", "text", "=", "orig_text", ".", "split", "(", ")", "\n", "return", "set", "(", "text", ")", ",", "len", "(", "text", ")", "\n", "\n", "", "return", "set", "(", "[", "\" \"", ".", "join", "(", "[", "s", ".", "lower", "(", ")", "for", "s", "in", "text", "[", "i", ":", "i", "+", "args", ".", "n_gram", "]", "]", ")", "for", "i", "in", "range", "(", "len", "(", "text", ")", "-", "args", ".", "n_gram", "+", "1", ")", "]", ")", ",", "len", "(", "text", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_scitldr.scripts.lexical_variation.compare_docs": [[27, 46], ["lexical_variation.get_ngrams", "lexical_variation.get_ngrams", "pr.intersection", "pr.union", "min", "len", "len", "len", "len", "min", "len", "len", "len", "len"], "function", ["home.repos.pwc.inspect_result.allenai_scitldr.scripts.lexical_variation.get_ngrams", "home.repos.pwc.inspect_result.allenai_scitldr.scripts.lexical_variation.get_ngrams"], ["", "def", "compare_docs", "(", "batches", ")", ":", "\n", "    ", "auth", ",", "lauth", "=", "get_ngrams", "(", "batches", "[", "'auth'", "]", ")", "\n", "pr", ",", "lpr", "=", "get_ngrams", "(", "batches", "[", "'pr'", "]", ")", "\n", "\n", "# Tokens in pr not in auth", "\n", "intersection", "=", "pr", ".", "intersection", "(", "auth", ")", "\n", "union", "=", "pr", ".", "union", "(", "auth", ")", "\n", "\n", "if", "min", "(", "len", "(", "auth", ")", ",", "len", "(", "pr", ")", ")", "!=", "0", ":", "\n", "        ", "containment_jaccard", "=", "len", "(", "intersection", ")", "/", "min", "(", "len", "(", "auth", ")", ",", "len", "(", "pr", ")", ")", "\n", "", "else", ":", "\n", "        ", "containment_jaccard", "=", "0.", "\n", "\n", "", "if", "len", "(", "union", ")", "!=", "0", ":", "\n", "        ", "jaccard", "=", "len", "(", "intersection", ")", "/", "len", "(", "union", ")", "\n", "", "else", ":", "\n", "        ", "jaccard", "=", "0.", "\n", "\n", "", "return", "[", "jaccard", ",", "containment_jaccard", ",", "lauth", ",", "lpr", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_scitldr.scripts.novelty_stats.get_novelty": [[24, 30], ["list", "nltk.util.ngrams", "set", "nltk.util.ngrams", "len", "len", "len"], "function", ["None"], ["def", "get_novelty", "(", "summ", ",", "text", ",", "ngram", "=", "1", ")", ":", "\n", "    ", "summ_tokens", "=", "list", "(", "ngrams", "(", "summ", ",", "ngram", ")", ")", "\n", "text_tokens", "=", "ngrams", "(", "text", ",", "ngram", ")", "\n", "all_tokens", "=", "set", "(", "text_tokens", ")", "\n", "res", "=", "len", "(", "[", "e", "for", "e", "in", "summ_tokens", "if", "e", "not", "in", "all_tokens", "]", ")", "/", "len", "(", "summ_tokens", ")", "if", "len", "(", "summ_tokens", ")", ">", "0", "else", "0", "\n", "return", "res", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_scitldr.scripts.novelty_stats.word_tokenize": [[32, 34], ["text.split"], "function", ["None"], ["", "def", "word_tokenize", "(", "text", ")", ":", "\n", "    ", "return", "text", ".", "split", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_scitldr.scripts.novelty_stats.get_stats": [[36, 44], ["novelty_stats.word_tokenize", "novelty_stats.word_tokenize", "novelty_stats.get_novelty", "novelty_stats.get_novelty", "novelty_stats.get_novelty"], "function", ["home.repos.pwc.inspect_result.allenai_scitldr.scripts.novelty_stats.word_tokenize", "home.repos.pwc.inspect_result.allenai_scitldr.scripts.novelty_stats.word_tokenize", "home.repos.pwc.inspect_result.allenai_scitldr.scripts.novelty_stats.get_novelty", "home.repos.pwc.inspect_result.allenai_scitldr.scripts.novelty_stats.get_novelty", "home.repos.pwc.inspect_result.allenai_scitldr.scripts.novelty_stats.get_novelty"], ["", "def", "get_stats", "(", "dataset_instance", ")", ":", "\n", "    ", "\"\"\" dataset_instance is a dict with two fields `summary` and `text` \"\"\"", "\n", "summ_tokens", "=", "word_tokenize", "(", "dataset_instance", "[", "'summary'", "]", ")", "\n", "text_tokens", "=", "word_tokenize", "(", "dataset_instance", "[", "'text'", "]", ")", "\n", "novelty1", "=", "get_novelty", "(", "summ_tokens", ",", "text_tokens", ",", "1", ")", "\n", "novelty2", "=", "get_novelty", "(", "summ_tokens", ",", "text_tokens", ",", "2", ")", "\n", "novelty3", "=", "get_novelty", "(", "summ_tokens", ",", "text_tokens", ",", "3", ")", "\n", "return", "novelty1", ",", "novelty2", ",", "novelty3", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_scitldr.scripts.novelty_stats.parse_args": [[45, 52], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args"], "function", ["home.repos.pwc.inspect_result.allenai_scitldr.scripts.novelty_stats.parse_args"], ["", "def", "parse_args", "(", ")", ":", "\n", "    ", "ap", "=", "ArgumentParser", "(", ")", "\n", "ap", ".", "add_argument", "(", "'input'", ")", "\n", "ap", ".", "add_argument", "(", "'--workers'", ",", "default", "=", "1", ",", "type", "=", "int", ")", "\n", "ap", ".", "add_argument", "(", "'--dataset-type'", ",", "choices", "=", "{", "'newsroom'", ",", "'scisummnet'", ",", "'bigpatent'", ",", "'arxiv'", ",", "'clpubsumm'", ",", "'scitldr'", "}", ",", "default", "=", "'newsroom'", ")", "\n", "args", "=", "ap", ".", "parse_args", "(", ")", "\n", "return", "args", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_scitldr.scripts.novelty_stats.main": [[53, 138], ["novelty_stats.parse_args", "print", "print", "gzip.open", "multiprocessing.pool.Pool", "list", "novelty_stats.get_stats", "sum", "len", "sum", "len", "sum", "len", "json.loads", "open", "tqdm.auto.tqdm", "tqdm.auto.tqdm", "json.loads", "open", "p.imap", "dataset.append", "json.loads", "open", "dataset.append", "glob.glob", "tqdm.auto.tqdm", "len", "json.loads", "gzip.open", "glob.glob", "tqdm.auto.tqdm", "json.loads", "dataset.append", "ET.parse", "ET.parse.getroot", "dataset.append", "str", "open", "fh.read", "os.listdir", "print", "pathlib.Path", "tree.getroot.findall"], "function", ["home.repos.pwc.inspect_result.allenai_scitldr.scripts.novelty_stats.parse_args", "home.repos.pwc.inspect_result.allenai_scitldr.scripts.novelty_stats.get_stats"], ["", "def", "main", "(", ")", ":", "\n", "    ", "args", "=", "parse_args", "(", ")", "\n", "\n", "if", "args", ".", "dataset_type", "==", "'newsroom'", ":", "\n", "        ", "import", "gzip", "\n", "with", "gzip", ".", "open", "(", "args", ".", "input", ")", "as", "fin", ":", "\n", "            ", "dataset", "=", "[", "json", ".", "loads", "(", "e", ")", "for", "e", "in", "fin", "]", "\n", "dataset", "=", "[", "{", "'text'", ":", "e", "[", "'text'", "]", ",", "'summary'", ":", "e", "[", "'summary'", "]", "}", "for", "e", "in", "dataset", "]", "\n", "", "", "elif", "args", ".", "dataset_type", "==", "'scitldr'", ":", "\n", "        ", "import", "glob", "\n", "import", "gzip", "\n", "with", "open", "(", "args", ".", "input", ")", "as", "fin", ":", "\n", "            ", "dataset", "=", "[", "]", "\n", "for", "e", "in", "fin", ":", "\n", "                ", "obj", "=", "json", ".", "loads", "(", "e", ")", "\n", "# multitarget", "\n", "for", "ee", "in", "obj", "[", "'target'", "]", ":", "\n", "                    ", "new_obj", "=", "{", "}", "\n", "new_obj", "[", "'text'", "]", "=", "' '", ".", "join", "(", "obj", "[", "'source'", "]", ")", "\n", "new_obj", "[", "'summary'", "]", "=", "ee", "\n", "dataset", ".", "append", "(", "new_obj", ")", "\n", "", "", "", "", "elif", "args", ".", "dataset_type", "==", "'arxiv'", ":", "\n", "        ", "import", "glob", "\n", "import", "gzip", "\n", "with", "open", "(", "args", ".", "input", ")", "as", "fin", ":", "\n", "            ", "dataset", "=", "[", "json", ".", "loads", "(", "e", ")", "for", "e", "in", "fin", "]", "\n", "dataset", "=", "[", "{", "'text'", ":", "' '", ".", "join", "(", "e", "[", "'article_text'", "]", ")", ",", "\n", "'summary'", ":", "' '", ".", "join", "(", "e", "[", "'abstract_text'", "]", ")", ".", "replace", "(", "'<S>'", ",", "''", ")", ".", "replace", "(", "'</S>'", ",", "''", ")", "}", "for", "e", "in", "dataset", "]", "\n", "", "", "elif", "args", ".", "dataset_type", "==", "'clpubsumm'", ":", "\n", "# tmp/sci_sum/dev-complete.jsonl", "\n", "        ", "dataset", "=", "[", "]", "\n", "with", "open", "(", "args", ".", "input", ")", "as", "fin", ":", "\n", "            ", "for", "e", "in", "fin", ":", "\n", "                ", "obj", "=", "json", ".", "loads", "(", "e", ")", "\n", "new_obj", "=", "{", "}", "\n", "new_obj", "[", "'text'", "]", "=", "' '", ".", "join", "(", "obj", "[", "'sentences'", "]", ")", "\n", "summary", "=", "''", "\n", "for", "ee", "in", "obj", "[", "'abstract'", "]", ":", "\n", "                    ", "summary", "+=", "' '", ".", "join", "(", "ee", ")", "\n", "", "new_obj", "[", "'summary'", "]", "=", "summary", "\n", "", "dataset", ".", "append", "(", "new_obj", ")", "\n", "", "", "elif", "args", ".", "dataset_type", "==", "'bigpatent'", ":", "\n", "        ", "import", "glob", "\n", "import", "gzip", "\n", "files", "=", "glob", ".", "glob", "(", "args", ".", "input", "+", "'/**/*.gz'", ",", "recursive", "=", "True", ")", "\n", "dataset", "=", "[", "]", "\n", "for", "f", "in", "tqdm", "(", "files", ",", "desc", "=", "'reading files'", ")", ":", "\n", "            ", "for", "line", "in", "gzip", ".", "open", "(", "f", ",", "'rt'", ")", ":", "\n", "                ", "obj", "=", "json", ".", "loads", "(", "line", ")", "\n", "dataset", ".", "append", "(", "{", "'text'", ":", "obj", "[", "'description'", "]", ",", "'summary'", ":", "obj", "[", "'abstract'", "]", "}", ")", "\n", "", "", "", "elif", "args", ".", "dataset_type", "==", "'scisummnet'", ":", "\n", "        ", "import", "xml", ".", "etree", ".", "ElementTree", "as", "ET", "\n", "import", "glob", "\n", "import", "os", "\n", "import", "pathlib", "\n", "files", "=", "glob", ".", "glob", "(", "args", ".", "input", "+", "'/**/*.xml'", ",", "recursive", "=", "True", ")", "\n", "dataset", "=", "[", "]", "\n", "for", "f", "in", "tqdm", "(", "files", ",", "desc", "=", "'reading files'", ")", ":", "\n", "            ", "summary_dir", "=", "str", "(", "pathlib", ".", "Path", "(", "f", ")", ".", "parent", ".", "parent", ")", "+", "'/summary/'", "\n", "summary_fp", "=", "summary_dir", "+", "'/'", "+", "os", ".", "listdir", "(", "summary_dir", ")", "[", "0", "]", "\n", "with", "open", "(", "summary_fp", ")", "as", "fh", ":", "\n", "                ", "summary", "=", "fh", ".", "read", "(", ")", "\n", "", "tree", "=", "ET", ".", "parse", "(", "f", ")", "\n", "root", "=", "tree", ".", "getroot", "(", ")", "\n", "try", ":", "\n", "                ", "text", "=", "' '", ".", "join", "(", "[", "child", ".", "text", "for", "child", "in", "root", ".", "findall", "(", "'.//S'", ")", "]", ")", "\n", "", "except", "TypeError", ":", "\n", "                ", "print", "(", "'cant process'", ",", "f", ")", "\n", "continue", "\n", "", "dataset", ".", "append", "(", "{", "'text'", ":", "text", ",", "'summary'", ":", "summary", "}", ")", "\n", "\n", "\n", "", "", "if", "args", ".", "workers", ">", "1", ":", "\n", "        ", "with", "Pool", "(", "args", ".", "workers", ")", "as", "p", ":", "\n", "            ", "results", "=", "list", "(", "tqdm", "(", "p", ".", "imap", "(", "get_stats", ",", "dataset", ")", ",", "total", "=", "len", "(", "dataset", ")", ",", "unit_scale", "=", "1", ")", ")", "\n", "", "", "else", ":", "\n", "        ", "results", "=", "[", "get_stats", "(", "d", ")", "for", "d", "in", "tqdm", "(", "dataset", ")", "]", "\n", "", "novelty1", "=", "[", "e", "[", "0", "]", "for", "e", "in", "results", "]", "\n", "novelty2", "=", "[", "e", "[", "1", "]", "for", "e", "in", "results", "]", "\n", "novelty3", "=", "[", "e", "[", "2", "]", "for", "e", "in", "results", "]", "\n", "nov1", "=", "(", "sum", "(", "novelty1", ")", "/", "len", "(", "novelty1", ")", ")", "*", "100", "\n", "nov2", "=", "(", "sum", "(", "novelty2", ")", "/", "len", "(", "novelty2", ")", ")", "*", "100", "\n", "nov3", "=", "(", "sum", "(", "novelty3", ")", "/", "len", "(", "novelty3", ")", ")", "*", "100", "\n", "print", "(", "f\"1gram\\t2gram\\t3gram\"", ")", "\n", "print", "(", "f\"{nov1:.2f}\\t{nov2:.2f}\\t{nov3:.2f}\"", ")", "\n", "\n"]]}