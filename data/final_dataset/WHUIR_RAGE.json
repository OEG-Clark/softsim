{"home.repos.pwc.inspect_result.WHUIR_RAGE.None.Runner.zipAll": [[36, 54], ["zip", "item.append", "item.append", "item.append", "item.append", "item.append", "item.append", "item.append", "zipSet.append"], "function", ["None"], ["def", "zipAll", "(", "train_enc_input", ",", "train_dec_gt", ",", "train_dec_input", ",", "train_com", ",", "train_com_weight", ",", "train_enc_input_pos", ",", "\n", "train_dec_input_pos", ")", ":", "\n", "    ", "zipSet", "=", "[", "]", "\n", "for", "enc", ",", "dec_gt", ",", "dec_input", ",", "com", ",", "com_weight", ",", "enc_input_pos", ",", "dec_input_pos", "in", "zip", "(", "train_enc_input", ",", "train_dec_gt", ",", "\n", "train_dec_input", ",", "train_com", ",", "\n", "train_com_weight", ",", "\n", "train_enc_input_pos", ",", "\n", "train_dec_input_pos", ")", ":", "\n", "        ", "item", "=", "[", "]", "\n", "item", ".", "append", "(", "enc", ")", "\n", "item", ".", "append", "(", "dec_gt", ")", "\n", "item", ".", "append", "(", "dec_input", ")", "\n", "item", ".", "append", "(", "com", ")", "\n", "item", ".", "append", "(", "com_weight", ")", "\n", "item", ".", "append", "(", "enc_input_pos", ")", "\n", "item", ".", "append", "(", "dec_input_pos", ")", "\n", "zipSet", ".", "append", "(", "item", ")", "\n", "", "return", "zipSet", "\n", "\n"]], "home.repos.pwc.inspect_result.WHUIR_RAGE.None.Runner.shuffle": [[57, 76], ["np.random.shuffle", "train_enc_input.append", "train_dec_gt.append", "train_dec_input.append", "train_com.append", "train_com_weight.append", "train_enc_input_pos.append", "train_dec_input_pos.append"], "function", ["home.repos.pwc.inspect_result.WHUIR_RAGE.None.Runner.shuffle"], ["def", "shuffle", "(", "zipSet", ")", ":", "\n", "    ", "train_enc_input", "=", "[", "]", "\n", "train_dec_gt", "=", "[", "]", "\n", "train_dec_input", "=", "[", "]", "\n", "train_com", "=", "[", "]", "\n", "train_com_weight", "=", "[", "]", "\n", "train_enc_input_pos", "=", "[", "]", "\n", "train_dec_input_pos", "=", "[", "]", "\n", "\n", "np", ".", "random", ".", "shuffle", "(", "zipSet", ")", "\n", "for", "item", "in", "zipSet", ":", "\n", "        ", "train_enc_input", ".", "append", "(", "item", "[", "0", "]", ")", "\n", "train_dec_gt", ".", "append", "(", "item", "[", "1", "]", ")", "\n", "train_dec_input", ".", "append", "(", "item", "[", "2", "]", ")", "\n", "train_com", ".", "append", "(", "item", "[", "3", "]", ")", "\n", "train_com_weight", ".", "append", "(", "item", "[", "4", "]", ")", "\n", "train_enc_input_pos", ".", "append", "(", "item", "[", "5", "]", ")", "\n", "train_dec_input_pos", ".", "append", "(", "item", "[", "6", "]", ")", "\n", "", "return", "train_enc_input", ",", "train_dec_gt", ",", "train_dec_input", ",", "train_com", ",", "train_com_weight", ",", "train_enc_input_pos", ",", "train_dec_input_pos", "\n", "\n"]], "home.repos.pwc.inspect_result.WHUIR_RAGE.None.Runner.train": [[78, 133], ["tensorflow.device", "Runner.zipAll", "tensorflow.ConfigProto", "tensorflow.Session", "rage.RAGEModel.ConvSeq2seq", "rage.RAGEModel.ConvSeq2seq", "sess_train.run", "tensorflow.train.Saver", "range", "print", "tensorflow.global_variables_initializer", "Runner.shuffle", "time.localtime", "print", "zip", "print", "time.strftime", "range", "range", "sess_train.run", "print", "tf.train.Saver.save", "Runner.validation", "time.localtime", "len", "len"], "function", ["home.repos.pwc.inspect_result.WHUIR_RAGE.None.Runner.zipAll", "home.repos.pwc.inspect_result.WHUIR_RAGE.None.Runner.shuffle", "home.repos.pwc.inspect_result.WHUIR_RAGE.None.Runner.validation"], ["", "def", "train", "(", "emd_mtx", ",", "wordid2posid", ",", "train_enc", ",", "train_dec_gt", ",", "train_dec_input", ",", "train_com", ",", "train_com_weight", ",", "\n", "train_enc_input_pos", ",", "train_dec_input_pos", ",", "valid_enc_input", ",", "valid_enc_input_pos", ",", "valid_dec_gt", ",", "valid_com", ",", "\n", "valid_com_weight", ")", ":", "\n", "# init model", "\n", "    ", "with", "tf", ".", "device", "(", "\"/gpu:0\"", ")", ":", "\n", "        ", "zipSet", "=", "zipAll", "(", "train_enc", ",", "train_dec_gt", ",", "train_dec_input", ",", "train_com", ",", "train_com_weight", ",", "train_enc_input_pos", ",", "\n", "train_dec_input_pos", ")", "\n", "config", "=", "tf", ".", "ConfigProto", "(", "allow_soft_placement", "=", "True", ")", "\n", "config", ".", "gpu_options", ".", "allow_growth", "=", "True", "\n", "with", "tf", ".", "Session", "(", "config", "=", "config", ")", "as", "sess_train", ":", "\n", "            ", "train", "=", "ConvSeq2seq", "(", "BATCH_SIZE", ",", "True", ",", "LEARNING_RATE", ",", "emd_mtx", ",", "EMD_SIZE", ",", "VOCAB_SIZE", ",", "POS_SIZE", ",", "\n", "wordid2posid", ",", "START_TOKEN", ",", "EOS_TOKEN", ",", "EMD_KEEP_PROB", ",", "LAYER_KEEP_PROB", ",", "OUT_KEEP_PROB", ",", "\n", "MAX_COM_VOCAB", ",", "ENC_LAYER", ",", "DEC_LAYER", ",", "ENC_FM_LIST", ",", "DEC_FM_LIST", ",", "ENC_KWIDTH_LIST", ",", "\n", "DEC_KWIDTH_LIST", ",", "MAX_EN_LEN", ",", "MAX_DE_LEN", ",", "False", ")", "\n", "valid", "=", "ConvSeq2seq", "(", "BATCH_SIZE", ",", "False", ",", "LEARNING_RATE", ",", "emd_mtx", ",", "EMD_SIZE", ",", "VOCAB_SIZE", ",", "POS_SIZE", ",", "\n", "wordid2posid", ",", "START_TOKEN", ",", "EOS_TOKEN", ",", "EMD_KEEP_PROB", ",", "LAYER_KEEP_PROB", ",", "OUT_KEEP_PROB", ",", "\n", "MAX_COM_VOCAB", ",", "ENC_LAYER", ",", "DEC_LAYER", ",", "ENC_FM_LIST", ",", "DEC_FM_LIST", ",", "ENC_KWIDTH_LIST", ",", "\n", "DEC_KWIDTH_LIST", ",", "MAX_EN_LEN", ",", "MAX_DE_LEN", ",", "True", ")", "\n", "sess_train", ".", "run", "(", "tf", ".", "global_variables_initializer", "(", ")", ")", "\n", "saver", "=", "tf", ".", "train", ".", "Saver", "(", "max_to_keep", "=", "1000", ")", "\n", "\n", "for", "epoch", "in", "range", "(", "EPOCH", ")", ":", "\n", "                ", "train_enc", ",", "train_dec_gt", ",", "train_dec_input", ",", "train_com", ",", "train_com_weight", ",", "train_enc_input_pos", ",", "train_dec_input_pos", "=", "shuffle", "(", "\n", "zipSet", ")", "\n", "ISOTIMEFORMAT", "=", "\"%Y-%m-%d %X\"", "\n", "time", ".", "localtime", "(", ")", "\n", "print", "(", "time", ".", "strftime", "(", "ISOTIMEFORMAT", ",", "time", ".", "localtime", "(", ")", ")", ")", "\n", "epoch_cost", "=", "0.", "\n", "\n", "for", "start", ",", "end", "in", "zip", "(", "range", "(", "0", ",", "len", "(", "train_enc", ")", ",", "BATCH_SIZE", ")", ",", "\n", "range", "(", "BATCH_SIZE", ",", "len", "(", "train_enc", ")", ",", "BATCH_SIZE", ")", ")", ":", "\n", "                    ", "batch_enc_input", "=", "train_enc", "[", "start", ":", "end", "]", "\n", "batch_enc_input_pos", "=", "train_enc_input_pos", "[", "start", ":", "end", "]", "\n", "batch_dec_gt", "=", "train_dec_gt", "[", "start", ":", "end", "]", "\n", "batch_dec_input", "=", "train_dec_input", "[", "start", ":", "end", "]", "\n", "batch_dec_input_pos", "=", "train_dec_input_pos", "[", "start", ":", "end", "]", "\n", "batch_com", "=", "train_com", "[", "start", ":", "end", "]", "\n", "batch_com_weight", "=", "train_com_weight", "[", "start", ":", "end", "]", "\n", "_", ",", "batch_predict", ",", "batch_loss", "=", "sess_train", ".", "run", "(", "\n", "[", "train", ".", "train_op", ",", "train", ".", "train_predict", ",", "train", ".", "train_loss", "]", ",", "\n", "feed_dict", "=", "{", "train", ".", "enc_input", ":", "batch_enc_input", ",", "train", ".", "dec_input", ":", "batch_dec_input", ",", "\n", "train", ".", "dec_gt", ":", "batch_dec_gt", ",", "train", ".", "com", ":", "batch_com", ",", "\n", "train", ".", "raw_com_weight", ":", "batch_com_weight", ",", "train", ".", "enc_input_pos", ":", "batch_enc_input_pos", ",", "\n", "train", ".", "dec_input_pos", ":", "batch_dec_input_pos", "}", ")", "\n", "epoch_cost", "=", "epoch_cost", "+", "batch_loss", "\n", "\n", "", "print", "(", "\"Loss at train time :\"", ",", "'%04d'", "%", "(", "epoch", ")", ",", "\"cost=\"", ",", "\"{:.9f}\"", ".", "format", "(", "epoch_cost", ")", ")", "\n", "# save model, and validation", "\n", "if", "0", "==", "epoch", "%", "SAVE_STEP", ":", "\n", "                    ", "print", "(", "\"Save Model at Epoch: %d\"", "%", "(", "epoch", ")", ")", "\n", "save_path", "=", "SAVE_MODEL_PATH", "+", "\"model.ckpt\"", "\n", "saver", ".", "save", "(", "sess_train", ",", "save_path", ",", "global_step", "=", "epoch", ")", "\n", "validation", "(", "sess_train", ",", "valid", ",", "valid_enc_input", ",", "valid_enc_input_pos", ",", "valid_dec_gt", ",", "valid_com", ",", "\n", "valid_com_weight", ")", "\n", "", "", "print", "(", "\"Train Optimization Finished!\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.WHUIR_RAGE.None.Runner.validation": [[135, 159], ["time.localtime", "print", "print", "zip", "print", "time.strftime", "range", "range", "sess_infer.run", "time.localtime", "len", "len"], "function", ["None"], ["", "", "", "def", "validation", "(", "sess_infer", ",", "validation", ",", "valid_enc", ",", "valid_enc_input_pos", ",", "valid_dec_gt", ",", "valid_com", ",", "valid_com_weight", ")", ":", "\n", "    ", "epoch_cost", "=", "0.", "\n", "ISOTIMEFORMAT", "=", "\"%Y-%m-%d %X\"", "\n", "time", ".", "localtime", "(", ")", "\n", "print", "(", "time", ".", "strftime", "(", "ISOTIMEFORMAT", ",", "time", ".", "localtime", "(", ")", ")", ")", "\n", "print", "(", "\"Start Validation ..\"", ")", "\n", "index", "=", "0", "\n", "for", "start", ",", "end", "in", "zip", "(", "range", "(", "0", ",", "len", "(", "valid_enc", ")", ",", "BATCH_SIZE", ")", ",", "range", "(", "BATCH_SIZE", ",", "len", "(", "valid_enc", ")", ",", "BATCH_SIZE", ")", ")", ":", "\n", "        ", "index", "+=", "1", "\n", "batch_enc_input", "=", "valid_enc", "[", "start", ":", "end", "]", "\n", "batch_enc_input_pos", "=", "valid_enc_input_pos", "[", "start", ":", "end", "]", "\n", "batch_dec_gt", "=", "valid_dec_gt", "[", "start", ":", "end", "]", "\n", "batch_com", "=", "valid_com", "[", "start", ":", "end", "]", "\n", "batch_com_weight", "=", "valid_com_weight", "[", "start", ":", "end", "]", "\n", "# print(batch_dec_gt)", "\n", "batch_loss", ",", "batch_predict", "=", "sess_infer", ".", "run", "(", "[", "validation", ".", "loss", ",", "validation", ".", "infer_predict", "]", ",", "\n", "feed_dict", "=", "{", "validation", ".", "enc_input", ":", "batch_enc_input", ",", "\n", "validation", ".", "dec_gt", ":", "batch_dec_gt", ",", "\n", "validation", ".", "com", ":", "batch_com", ",", "\n", "validation", ".", "raw_com_weight", ":", "batch_com_weight", ",", "\n", "validation", ".", "enc_input_pos", ":", "batch_enc_input_pos", "}", ")", "\n", "epoch_cost", "=", "epoch_cost", "+", "batch_loss", "\n", "\n", "", "print", "(", "\"Loss at validation time =\"", ",", "\"{:.9f}\"", ".", "format", "(", "epoch_cost", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.WHUIR_RAGE.None.Runner.inference": [[161, 201], ["tensorflow.device", "tensorflow.ConfigProto", "tensorflow.Session", "rage.RAGEModel.ConvSeq2seq", "tensorflow.train.Saver", "os.path.exists", "time.localtime", "print", "print", "zip", "print", "print", "tf.train.Saver.restore", "print", "time.strftime", "range", "range", "sess_infer.run", "tensorflow.train.latest_checkpoint", "time.localtime", "len", "len"], "function", ["None"], ["", "def", "inference", "(", "emd_mtx", ",", "wordid2posid", ",", "infer_enc", ",", "infer_enc_pos", ",", "infer_dec_gt", ",", "infer_com", ",", "infer_com_weight", ")", ":", "\n", "# init model", "\n", "    ", "with", "tf", ".", "device", "(", "\"/gpu:0\"", ")", ":", "\n", "        ", "config", "=", "tf", ".", "ConfigProto", "(", "allow_soft_placement", "=", "True", ")", "\n", "config", ".", "gpu_options", ".", "allow_growth", "=", "True", "\n", "with", "tf", ".", "Session", "(", "config", "=", "config", ")", "as", "sess_infer", ":", "\n", "            ", "inference", "=", "ConvSeq2seq", "(", "BATCH_SIZE", ",", "False", ",", "LEARNING_RATE", ",", "emd_mtx", ",", "EMD_SIZE", ",", "VOCAB_SIZE", ",", "POS_SIZE", ",", "\n", "wordid2posid", ",", "START_TOKEN", ",", "EOS_TOKEN", ",", "EMD_KEEP_PROB", ",", "LAYER_KEEP_PROB", ",", "OUT_KEEP_PROB", ",", "\n", "MAX_COM_VOCAB", ",", "ENC_LAYER", ",", "DEC_LAYER", ",", "ENC_FM_LIST", ",", "DEC_FM_LIST", ",", "ENC_KWIDTH_LIST", ",", "\n", "DEC_KWIDTH_LIST", ",", "MAX_EN_LEN", ",", "MAX_DE_LEN", ",", "False", ")", "\n", "saver", "=", "tf", ".", "train", ".", "Saver", "(", ")", "\n", "if", "os", ".", "path", ".", "exists", "(", "SAVE_MODEL_PATH", "+", "\"checkpoint\"", ")", ":", "\n", "                ", "print", "(", "\"Restoring Variables from Checkpoint\"", ")", "\n", "saver", ".", "restore", "(", "sess_infer", ",", "tf", ".", "train", ".", "latest_checkpoint", "(", "SAVE_MODEL_PATH", ")", ")", "\n", "", "else", ":", "\n", "                ", "print", "(", "\"Can't find the checkpoint.going to stop\"", ")", "\n", "return", "\n", "", "epoch_cost", "=", "0.", "\n", "ISOTIMEFORMAT", "=", "\"%Y-%m-%d %X\"", "\n", "time", ".", "localtime", "(", ")", "\n", "print", "(", "time", ".", "strftime", "(", "ISOTIMEFORMAT", ",", "time", ".", "localtime", "(", ")", ")", ")", "\n", "print", "(", "\"Start Inference ..\"", ")", "\n", "index", "=", "0", "\n", "for", "start", ",", "end", "in", "zip", "(", "range", "(", "0", ",", "len", "(", "infer_enc", ")", ",", "BATCH_SIZE", ")", ",", "\n", "range", "(", "BATCH_SIZE", ",", "len", "(", "infer_dec_gt", ")", ",", "BATCH_SIZE", ")", ")", ":", "\n", "                ", "index", "+=", "1", "\n", "batch_enc_input", "=", "infer_enc", "[", "start", ":", "end", "]", "\n", "batch_enc_input_pos", "=", "infer_enc_pos", "[", "start", ":", "end", "]", "\n", "batch_dec_gt", "=", "infer_dec_gt", "[", "start", ":", "end", "]", "\n", "batch_com", "=", "infer_com", "[", "start", ":", "end", "]", "\n", "batch_com_weight", "=", "infer_com_weight", "[", "start", ":", "end", "]", "\n", "batch_loss", ",", "batch_predict", "=", "sess_infer", ".", "run", "(", "[", "inference", ".", "loss", ",", "inference", ".", "infer_predict", "]", ",", "\n", "feed_dict", "=", "{", "inference", ".", "enc_input", ":", "batch_enc_input", ",", "\n", "inference", ".", "dec_gt", ":", "batch_dec_gt", ",", "\n", "inference", ".", "com", ":", "batch_com", ",", "\n", "inference", ".", "raw_com_weight", ":", "batch_com_weight", ",", "\n", "inference", ".", "enc_input_pos", ":", "batch_enc_input_pos", "}", ")", "\n", "epoch_cost", "=", "epoch_cost", "+", "batch_loss", "\n", "\n", "", "print", "(", "\"Loss at inference time =\"", ",", "\"{:.9f}\"", ".", "format", "(", "epoch_cost", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.WHUIR_RAGE.None.RAGEModel.ConvSeq2seq.__init__": [[11, 109], ["tensorflow.variable_scope", "tensorflow.get_variable", "tensorflow.constant", "tensorflow.get_variable", "tensorflow.get_variable", "rage.RAGEEncoder.ConvEncoder", "rage.RAGEDecoder.ConvDecoder", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.nn.embedding_lookup", "tensorflow.placeholder", "tensorflow.expand_dims", "tensorflow.multiply", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.nn.embedding_lookup", "RAGEModel.ConvSeq2seq.encoder.encode", "tensorflow.nn.embedding_lookup", "tensorflow.train.MomentumOptimizer", "zip", "tensorflow.clip_by_global_norm", "RAGEModel.ConvSeq2seq.optimizer.apply_gradients", "tensorflow.get_variable_scope().reuse_variables", "tensorflow.nn.embedding_lookup", "RAGEModel.ConvSeq2seq.encoder.encode", "RAGEModel.ConvSeq2seq.decoder.conv_decoder_infer", "tensorflow.pad", "tensorflow.slice", "tensorflow.cast", "tensorflow.contrib.seq2seq.sequence_loss", "tensorflow.get_variable_scope().reuse_variables", "tensorflow.random_normal_initializer", "tensorflow.random_normal_initializer", "tensorflow.random_normal_initializer", "RAGEModel.ConvSeq2seq.length", "tensorflow.variable_scope", "RAGEModel.ConvSeq2seq.decoder.conv_decoder_train", "tensorflow.get_variable_scope().reuse_variables", "zip", "RAGEModel.ConvSeq2seq.length", "tensorflow.sign", "RAGEModel.ConvSeq2seq.length", "tensorflow.add_n", "RAGEModel.ConvSeq2seq.optimizer.compute_gradients", "tensorflow.get_variable_scope", "tensorflow.get_variable_scope", "tensorflow.get_variable_scope", "tensorflow.nn.l2_loss", "tensorflow.trainable_variables"], "methods", ["home.repos.pwc.inspect_result.WHUIR_RAGE.None.RAGEEncoder.ConvEncoder.encode", "home.repos.pwc.inspect_result.WHUIR_RAGE.None.RAGEEncoder.ConvEncoder.encode", "home.repos.pwc.inspect_result.WHUIR_RAGE.None.RAGEDecoder.ConvDecoder.conv_decoder_infer", "home.repos.pwc.inspect_result.WHUIR_RAGE.None.RAGEModel.ConvSeq2seq.length", "home.repos.pwc.inspect_result.WHUIR_RAGE.None.RAGEDecoder.ConvDecoder.conv_decoder_train", "home.repos.pwc.inspect_result.WHUIR_RAGE.None.RAGEModel.ConvSeq2seq.length", "home.repos.pwc.inspect_result.WHUIR_RAGE.None.RAGEModel.ConvSeq2seq.length"], ["    ", "def", "__init__", "(", "self", ",", "batchsize", ",", "is_train", ",", "learning_rate", ",", "word_emd", ",", "emd_size", ",", "vocab_size", ",", "POS_size", ",", "wordid2posid", ",", "start_token", ",", "eos_token", ",", "emd_keep_prob", ",", "layer_keep_prob", ",", "out_keep_prob", ",", "max_com_vocab", ",", "enc_layer", ",", "dec_layer", ",", "enc_fm_list", ",", "dec_fm_list", ",", "enc_kwidth_list", ",", "dec_kwidth_list", ",", "max_en_len", ",", "max_de_len", ",", "scope_reuse", "=", "False", ",", "decay_steps", "=", "100000", ",", "decay_rate", "=", "0.9", ")", ":", "\n", "        ", "with", "tf", ".", "variable_scope", "(", "\"RAGE\"", ",", "reuse", "=", "scope_reuse", ")", "as", "scope_model", ":", "\n", "#share param", "\n", "#True:training  False:inference", "\n", "            ", "self", ".", "is_train", "=", "is_train", "\n", "self", ".", "batchsize", "=", "batchsize", "\n", "self", ".", "learning_rate", "=", "learning_rate", "\n", "self", ".", "word_emd", "=", "word_emd", "\n", "#word embedding size, position embedding size, POS tag embedding size are equal, and here the size of hidden state is also equal with word embedding size", "\n", "self", ".", "emd_size", "=", "emd_size", "\n", "self", ".", "vocab_size", "=", "vocab_size", "\n", "self", ".", "start_token", "=", "start_token", "\n", "self", ".", "eos_token", "=", "eos_token", "\n", "self", ".", "emd_keep_prob", "=", "emd_keep_prob", "\n", "self", ".", "layer_keep_prob", "=", "layer_keep_prob", "\n", "self", ".", "out_keep_prob", "=", "out_keep_prob", "\n", "# the maximum size of weighted vocabulary of comments", "\n", "self", ".", "max_com_vocab", "=", "max_com_vocab", "\n", "self", ".", "POS_size", "=", "POS_size", "\n", "self", ".", "POS_emd", "=", "tf", ".", "get_variable", "(", "\"POS_emd\"", ",", "[", "self", ".", "POS_size", ",", "self", ".", "emd_size", "]", ",", "tf", ".", "float32", ",", "\n", "initializer", "=", "tf", ".", "random_normal_initializer", "(", "0.0", ",", "0.01", ")", ",", "trainable", "=", "True", ")", "\n", "self", ".", "wordid2posid", "=", "tf", ".", "constant", "(", "wordid2posid", ")", "\n", "\n", "#encoder param", "\n", "self", ".", "max_en_len", "=", "max_en_len", "\n", "self", ".", "enc_kwidth_list", "=", "enc_kwidth_list", "\n", "self", ".", "enc_fm_list", "=", "enc_fm_list", "\n", "self", ".", "enc_layer", "=", "enc_layer", "\n", "# encoder and decoder position embedding are not shared", "\n", "self", ".", "enc_pos_emd", "=", "tf", ".", "get_variable", "(", "\"enc_pos_emd\"", ",", "[", "self", ".", "max_en_len", ",", "self", ".", "emd_size", "]", ",", "tf", ".", "float32", ",", "initializer", "=", "tf", ".", "random_normal_initializer", "(", "0.0", ",", "0.01", ")", ",", "trainable", "=", "True", ")", "\n", "\n", "#decoder param", "\n", "self", ".", "max_de_len", "=", "max_de_len", "\n", "self", ".", "dec_layer", "=", "dec_layer", "\n", "self", ".", "dec_fm_list", "=", "dec_fm_list", "\n", "self", ".", "dec_kwidth_list", "=", "dec_kwidth_list", "\n", "self", ".", "dec_pos_emd", "=", "tf", ".", "get_variable", "(", "\"dec_pos_emd\"", ",", "[", "self", ".", "max_de_len", ",", "self", ".", "emd_size", "]", ",", "tf", ".", "float32", ",", "initializer", "=", "tf", ".", "random_normal_initializer", "(", "0.0", ",", "0.01", ")", ",", "trainable", "=", "True", ")", "\n", "\n", "#create encoder", "\n", "self", ".", "encoder", "=", "ConvEncoder", "(", "self", ".", "is_train", ",", "self", ".", "POS_emd", ",", "self", ".", "max_en_len", ",", "self", ".", "enc_pos_emd", ",", "self", ".", "enc_layer", ",", "self", ".", "enc_fm_list", ",", "self", ".", "enc_kwidth_list", ",", "self", ".", "emd_keep_prob", ",", "self", ".", "layer_keep_prob", ",", "scope_reuse", "=", "scope_reuse", ")", "\n", "#create decoder", "\n", "self", ".", "decoder", "=", "ConvDecoder", "(", "self", ".", "is_train", ",", "self", ".", "batchsize", ",", "self", ".", "start_token", ",", "self", ".", "eos_token", ",", "self", ".", "word_emd", ",", "self", ".", "POS_emd", ",", "self", ".", "wordid2posid", ",", "self", ".", "dec_pos_emd", ",", "self", ".", "dec_layer", ",", "self", ".", "dec_fm_list", ",", "self", ".", "dec_kwidth_list", ",", "self", ".", "layer_keep_prob", ",", "self", ".", "emd_keep_prob", ",", "self", ".", "max_de_len", ",", "self", ".", "emd_size", ",", "self", ".", "out_keep_prob", ",", "self", ".", "vocab_size", ",", "scope_reuse", "=", "scope_reuse", ")", "\n", "\n", "#placeholder", "\n", "self", ".", "enc_input", "=", "tf", ".", "placeholder", "(", "tf", ".", "int32", ",", "[", "None", ",", "self", ".", "max_en_len", "]", ",", "name", "=", "\"enc_input\"", ")", "\n", "self", ".", "dec_gt", "=", "tf", ".", "placeholder", "(", "tf", ".", "int32", ",", "[", "None", ",", "self", ".", "max_de_len", "]", ",", "name", "=", "\"dec_gt\"", ")", "\n", "\n", "self", ".", "enc_input_pos", "=", "tf", ".", "placeholder", "(", "tf", ".", "int32", ",", "[", "None", ",", "self", ".", "max_en_len", "]", ",", "name", "=", "\"enc_input_pos\"", ")", "\n", "#[batchsize,max_com_vocab]", "\n", "self", ".", "com", "=", "tf", ".", "placeholder", "(", "tf", ".", "int32", ",", "[", "None", ",", "self", ".", "max_com_vocab", "]", ",", "name", "=", "\"com\"", ")", "\n", "self", ".", "com_emd", "=", "tf", ".", "nn", ".", "embedding_lookup", "(", "self", ".", "word_emd", ",", "self", ".", "com", ")", "\n", "self", ".", "raw_com_weight", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "[", "None", ",", "self", ".", "max_com_vocab", "]", ",", "name", "=", "\"com_weight\"", ")", "\n", "#[batchsize,max_com_vocab,1]", "\n", "self", ".", "com_weight", "=", "tf", ".", "expand_dims", "(", "self", ".", "raw_com_weight", ",", "axis", "=", "-", "1", ")", "\n", "#[batchsize,max_com_vocab,emd_size]-->weight embedding", "\n", "self", ".", "wcom_emd", "=", "tf", ".", "multiply", "(", "self", ".", "com_emd", ",", "self", ".", "com_weight", ")", "\n", "\n", "#train", "\n", "if", "is_train", ":", "\n", "                ", "self", ".", "dec_input", "=", "tf", ".", "placeholder", "(", "tf", ".", "int32", ",", "[", "None", ",", "self", ".", "max_de_len", "]", ",", "name", "=", "\"dec_input\"", ")", "\n", "self", ".", "dec_input_pos", "=", "tf", ".", "placeholder", "(", "tf", ".", "int32", ",", "[", "None", ",", "self", ".", "max_de_len", "]", ",", "name", "=", "\"dec_input_pos\"", ")", "\n", "#[batchsize,max_en_len,emd_size]", "\n", "self", ".", "enc_input_emd", "=", "tf", ".", "nn", ".", "embedding_lookup", "(", "self", ".", "word_emd", ",", "self", ".", "enc_input", ")", "\n", "#enode", "\n", "self", ".", "enc_output", "=", "self", ".", "encoder", ".", "encode", "(", "self", ".", "enc_input_emd", ",", "self", ".", "enc_input_pos", ",", "self", ".", "length", "(", "self", ".", "enc_input_emd", ")", ")", "\n", "\n", "#decode", "\n", "self", ".", "dec_input_emd", "=", "tf", ".", "nn", ".", "embedding_lookup", "(", "self", ".", "word_emd", ",", "self", ".", "dec_input", ")", "\n", "with", "tf", ".", "variable_scope", "(", "\"decoder\"", ",", "reuse", "=", "scope_reuse", ")", "as", "scope", ":", "\n", "                    ", "self", ".", "train_logit", ",", "self", ".", "train_predict", ",", "self", ".", "train_loss", ",", "=", "self", ".", "decoder", ".", "conv_decoder_train", "(", "self", ".", "enc_output", ",", "self", ".", "dec_input_emd", ",", "self", ".", "dec_input_pos", ",", "self", ".", "dec_gt", ",", "self", ".", "length", "(", "self", ".", "dec_input_emd", ")", ",", "self", ".", "wcom_emd", ")", "\n", "self", ".", "l2", "=", "tf", ".", "add_n", "(", "[", "tf", ".", "nn", ".", "l2_loss", "(", "v", ")", "for", "v", "in", "tf", ".", "trainable_variables", "(", ")", "if", "'bias'", "not", "in", "v", ".", "name", "]", ")", "*", "0.01", "\n", "self", ".", "train_loss", "=", "self", ".", "train_loss", "+", "self", ".", "l2", "\n", "tf", ".", "get_variable_scope", "(", ")", ".", "reuse_variables", "(", ")", "\n", "\n", "#loss & optimize", "\n", "", "self", ".", "optimizer", "=", "tf", ".", "train", ".", "MomentumOptimizer", "(", "self", ".", "learning_rate", ",", "0.99", ",", "use_nesterov", "=", "True", ")", "\n", "self", ".", "gradients", ",", "self", ".", "variables", "=", "zip", "(", "*", "self", ".", "optimizer", ".", "compute_gradients", "(", "self", ".", "train_loss", ")", ")", "\n", "self", ".", "gradients", ",", "_", "=", "tf", ".", "clip_by_global_norm", "(", "self", ".", "gradients", ",", "0.1", ")", "\n", "self", ".", "train_op", "=", "self", ".", "optimizer", ".", "apply_gradients", "(", "zip", "(", "self", ".", "gradients", ",", "self", ".", "variables", ")", ")", "\n", "tf", ".", "get_variable_scope", "(", ")", ".", "reuse_variables", "(", ")", "\n", "\n", "\n", "#inference", "\n", "", "else", ":", "\n", "#encode", "\n", "                ", "self", ".", "enc_input_emd", "=", "tf", ".", "nn", ".", "embedding_lookup", "(", "self", ".", "word_emd", ",", "self", ".", "enc_input", ")", "\n", "self", ".", "enc_output", "=", "self", ".", "encoder", ".", "encode", "(", "self", ".", "enc_input_emd", ",", "self", ".", "enc_input_pos", ",", "self", ".", "length", "(", "self", ".", "enc_input_emd", ")", ")", "\n", "\n", "#decode", "\n", "self", ".", "infer_output", ",", "self", ".", "infer_state", "=", "self", ".", "decoder", ".", "conv_decoder_infer", "(", "self", ".", "enc_output", ",", "self", ".", "wcom_emd", ")", "\n", "#[batchsize,timestep,vocab_size]-->[batchsize,max_de_len,vocab_size]", "\n", "raw_infer_logit", "=", "self", ".", "infer_output", ".", "logits", "\n", "raw_infer_logit", "=", "tf", ".", "pad", "(", "raw_infer_logit", ",", "[", "[", "0", ",", "0", "]", ",", "[", "0", ",", "self", ".", "max_de_len", "]", ",", "[", "0", ",", "0", "]", "]", ",", "\"CONSTANT\"", ")", "\n", "self", ".", "infer_logit", "=", "tf", ".", "slice", "(", "raw_infer_logit", ",", "[", "0", ",", "0", ",", "0", "]", ",", "[", "self", ".", "batchsize", ",", "self", ".", "max_de_len", ",", "self", ".", "vocab_size", "]", ")", "\n", "self", ".", "infer_predict", "=", "self", ".", "infer_output", ".", "predicted_ids", "\n", "loss_weight", "=", "tf", ".", "cast", "(", "tf", ".", "sign", "(", "self", ".", "dec_gt", ")", ",", "tf", ".", "float32", ")", "\n", "self", ".", "loss", "=", "tf", ".", "contrib", ".", "seq2seq", ".", "sequence_loss", "(", "logits", "=", "self", ".", "infer_logit", ",", "targets", "=", "self", ".", "dec_gt", ",", "weights", "=", "loss_weight", ")", "\n", "tf", ".", "get_variable_scope", "(", ")", ".", "reuse_variables", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.WHUIR_RAGE.None.RAGEModel.ConvSeq2seq.length": [[112, 119], ["tensorflow.reduce_max", "tensorflow.sign", "tensorflow.reduce_sum", "tensorflow.cast", "tensorflow.abs"], "methods", ["None"], ["def", "length", "(", "self", ",", "input_emd", ")", ":", "\n", "#[batchsize,sen_len,emd_size]--->[batchsize,sen_len]", "\n", "        ", "input_0", "=", "tf", ".", "reduce_max", "(", "tf", ".", "abs", "(", "input_emd", ")", ",", "axis", "=", "2", ")", "\n", "input_1", "=", "tf", ".", "sign", "(", "input_0", ")", "\n", "#[batchsize]", "\n", "seq_len", "=", "tf", ".", "reduce_sum", "(", "input_1", ",", "axis", "=", "1", ")", "\n", "return", "tf", ".", "cast", "(", "seq_len", ",", "tf", ".", "int32", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.WHUIR_RAGE.None.RAGEModel.demo_train": [[123, 173], ["numpy.random.ranf", "numpy.array", "numpy.random.randint", "numpy.random.ranf", "numpy.random.randint", "numpy.random.randint", "numpy.random.randint", "numpy.random.randint", "print", "print", "numpy.random.randint", "tensorflow.device", "tensorflow.Session", "RAGEModel.ConvSeq2seq", "sess.run", "sess.run", "print", "print", "print", "tensorflow.train.Saver", "tf.train.Saver.save", "sess.close", "tensorflow.global_variables_initializer"], "function", ["None"], ["def", "demo_train", "(", ")", ":", "\n", "    ", "batchsize", "=", "2", "\n", "learning_rate", "=", "0.25", "\n", "is_train", "=", "True", "\n", "word_emd", "=", "np", ".", "random", ".", "ranf", "(", "[", "10", ",", "5", "]", ")", "\n", "word_emd", "=", "np", ".", "array", "(", "word_emd", ",", "dtype", "=", "'float32'", ")", "\n", "emd_size", "=", "5", "\n", "vocab_size", "=", "10", "\n", "start_token", "=", "1", "\n", "eos_token", "=", "0", "\n", "emd_keep_prob", "=", "0.9", "\n", "layer_keep_prob", "=", "0.9", "\n", "out_keep_prob", "=", "0.9", "\n", "enc_layer", "=", "2", "\n", "dec_layer", "=", "2", "\n", "enc_fm_list", "=", "[", "5", ",", "5", "]", "\n", "dec_fm_list", "=", "[", "5", ",", "5", "]", "\n", "enc_kwidth_list", "=", "[", "2", ",", "2", "]", "\n", "dec_kwidth_list", "=", "[", "2", ",", "2", "]", "\n", "max_en_len", "=", "4", "\n", "max_de_len", "=", "5", "\n", "POS_size", "=", "6", "\n", "wordid2posid", "=", "[", "2", ",", "3", ",", "0", ",", "0", ",", "1", ",", "5", ",", "4", ",", "3", ",", "2", ",", "5", "]", "\n", "max_com_vocab", "=", "7", "\n", "com", "=", "np", ".", "random", ".", "randint", "(", "0", ",", "9", ",", "[", "2", ",", "7", "]", ")", "\n", "com_weight", "=", "np", ".", "random", ".", "ranf", "(", "[", "2", ",", "7", "]", ")", "\n", "\n", "#placeholder", "\n", "encoder_input", "=", "np", ".", "random", ".", "randint", "(", "0", ",", "9", ",", "[", "2", ",", "4", "]", ")", "\n", "enc_input_pos", "=", "np", ".", "random", ".", "randint", "(", "0", ",", "6", ",", "[", "2", ",", "4", "]", ")", "\n", "decoder_input", "=", "np", ".", "random", ".", "randint", "(", "0", ",", "9", ",", "[", "2", ",", "5", "]", ")", "\n", "dec_input_pos", "=", "np", ".", "random", ".", "randint", "(", "0", ",", "6", ",", "[", "2", ",", "5", "]", ")", "\n", "print", "(", "\"decoder_input\"", ",", "decoder_input", ")", "\n", "print", "(", "\"dec_input_pos\"", ",", "dec_input_pos", ")", "\n", "\n", "decoder_groundtruth", "=", "np", ".", "random", ".", "randint", "(", "0", ",", "9", ",", "[", "2", ",", "5", "]", ")", "\n", "with", "tf", ".", "device", "(", "\"/cpu:0\"", ")", ":", "\n", "#config=tf.ConfigProto(allow_soft_placement=True)", "\n", "#config.gpu_options.allow_growth=True", "\n", "        ", "with", "tf", ".", "Session", "(", ")", "as", "sess", ":", "\n", "            ", "train", "=", "ConvSeq2seq", "(", "batchsize", ",", "is_train", ",", "learning_rate", ",", "word_emd", ",", "emd_size", ",", "vocab_size", ",", "POS_size", ",", "wordid2posid", ",", "start_token", ",", "eos_token", ",", "emd_keep_prob", ",", "layer_keep_prob", ",", "out_keep_prob", ",", "max_com_vocab", ",", "enc_layer", ",", "dec_layer", ",", "enc_fm_list", ",", "dec_fm_list", ",", "enc_kwidth_list", ",", "dec_kwidth_list", ",", "max_en_len", ",", "max_de_len", ")", "\n", "sess", ".", "run", "(", "tf", ".", "global_variables_initializer", "(", ")", ")", "\n", "_", ",", "batch_logit", ",", "batch_predict", ",", "batch_loss", "=", "sess", ".", "run", "(", "[", "train", ".", "train_op", ",", "train", ".", "train_logit", ",", "train", ".", "train_predict", ",", "train", ".", "train_loss", "]", ",", "feed_dict", "=", "{", "train", ".", "enc_input", ":", "encoder_input", ",", "train", ".", "dec_input", ":", "decoder_input", ",", "train", ".", "dec_gt", ":", "decoder_groundtruth", ",", "train", ".", "enc_input_pos", ":", "enc_input_pos", ",", "train", ".", "dec_input_pos", ":", "dec_input_pos", ",", "train", ".", "com", ":", "com", ",", "train", ".", "raw_com_weight", ":", "com_weight", "}", ")", "\n", "print", "(", "\"batch_logit\"", ",", "batch_logit", ")", "\n", "print", "(", "\"batch_predict\"", ",", "batch_predict", ")", "\n", "print", "(", "\"batch_loss\"", ",", "batch_loss", ")", "\n", "#save model", "\n", "saver", "=", "tf", ".", "train", ".", "Saver", "(", ")", "\n", "saver", ".", "save", "(", "sess", ",", "\"./model/check-final.cpkt\"", ")", "\n", "sess", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.WHUIR_RAGE.None.RAGEModel.demo_inference": [[175, 226], ["numpy.random.ranf", "numpy.array", "numpy.random.randint", "numpy.random.ranf", "numpy.random.randint", "numpy.random.randint", "numpy.random.randint", "numpy.random.randint", "print", "print", "numpy.random.randint", "tensorflow.Session", "RAGEModel.ConvSeq2seq", "tensorflow.train.Saver", "os.path.exists", "sess.run", "print", "print", "print", "sess.close", "print", "tf.train.Saver.restore", "print", "tensorflow.train.latest_checkpoint"], "function", ["None"], ["def", "demo_inference", "(", ")", ":", "\n", "    ", "batchsize", "=", "2", "\n", "learning_rate", "=", "0.001", "\n", "is_train", "=", "False", "\n", "word_emd", "=", "np", ".", "random", ".", "ranf", "(", "[", "10", ",", "5", "]", ")", "\n", "word_emd", "=", "np", ".", "array", "(", "word_emd", ",", "dtype", "=", "'float32'", ")", "\n", "emd_size", "=", "5", "\n", "vocab_size", "=", "10", "\n", "start_token", "=", "1", "\n", "eos_token", "=", "0", "\n", "emd_keep_prob", "=", "0.9", "\n", "layer_keep_prob", "=", "0.9", "\n", "out_keep_prob", "=", "0.9", "\n", "enc_layer", "=", "2", "\n", "dec_layer", "=", "2", "\n", "enc_fm_list", "=", "[", "5", ",", "5", "]", "\n", "dec_fm_list", "=", "[", "5", ",", "5", "]", "\n", "enc_kwidth_list", "=", "[", "2", ",", "2", "]", "\n", "dec_kwidth_list", "=", "[", "2", ",", "2", "]", "\n", "max_en_len", "=", "4", "\n", "max_de_len", "=", "5", "\n", "POS_size", "=", "6", "\n", "wordid2posid", "=", "[", "2", ",", "3", ",", "0", ",", "0", ",", "1", ",", "5", ",", "4", ",", "3", ",", "2", ",", "5", "]", "\n", "max_com_vocab", "=", "7", "\n", "com", "=", "np", ".", "random", ".", "randint", "(", "0", ",", "9", ",", "[", "2", ",", "7", "]", ")", "\n", "com_weight", "=", "np", ".", "random", ".", "ranf", "(", "[", "2", ",", "7", "]", ")", "\n", "\n", "#placeholder", "\n", "encoder_input", "=", "np", ".", "random", ".", "randint", "(", "0", ",", "9", ",", "[", "2", ",", "4", "]", ")", "\n", "enc_input_pos", "=", "np", ".", "random", ".", "randint", "(", "0", ",", "6", ",", "[", "2", ",", "4", "]", ")", "\n", "decoder_input", "=", "np", ".", "random", ".", "randint", "(", "0", ",", "9", ",", "[", "2", ",", "5", "]", ")", "\n", "dec_input_pos", "=", "np", ".", "random", ".", "randint", "(", "0", ",", "6", ",", "[", "2", ",", "5", "]", ")", "\n", "print", "(", "\"decoder_input\"", ",", "decoder_input", ")", "\n", "print", "(", "\"dec_input_pos\"", ",", "dec_input_pos", ")", "\n", "decoder_groundtruth", "=", "np", ".", "random", ".", "randint", "(", "0", ",", "9", ",", "[", "2", ",", "5", "]", ")", "\n", "\n", "with", "tf", ".", "Session", "(", ")", "as", "sess", ":", "\n", "        ", "inference", "=", "ConvSeq2seq", "(", "batchsize", ",", "is_train", ",", "learning_rate", ",", "word_emd", ",", "emd_size", ",", "vocab_size", ",", "POS_size", ",", "wordid2posid", ",", "start_token", ",", "eos_token", ",", "emd_keep_prob", ",", "layer_keep_prob", ",", "out_keep_prob", ",", "max_com_vocab", ",", "enc_layer", ",", "dec_layer", ",", "enc_fm_list", ",", "dec_fm_list", ",", "enc_kwidth_list", ",", "dec_kwidth_list", ",", "max_en_len", ",", "max_de_len", ")", "\n", "saver", "=", "tf", ".", "train", ".", "Saver", "(", ")", "\n", "if", "os", ".", "path", ".", "exists", "(", "\"./model/\"", "+", "\"checkpoint\"", ")", ":", "\n", "            ", "print", "(", "\"Restoring Variables from Checkpoint\"", ")", "\n", "saver", ".", "restore", "(", "sess", ",", "tf", ".", "train", ".", "latest_checkpoint", "(", "\"./model/\"", ")", ")", "\n", "", "else", ":", "\n", "            ", "print", "(", "\"Can't find the checkpoint.going to stop\"", ")", "\n", "return", "\n", "\n", "", "batch_logits", ",", "batch_predict", ",", "batch_loss", "=", "sess", ".", "run", "(", "[", "inference", ".", "infer_logit", ",", "inference", ".", "infer_predict", ",", "inference", ".", "loss", "]", ",", "feed_dict", "=", "{", "inference", ".", "enc_input", ":", "encoder_input", ",", "inference", ".", "enc_input_pos", ":", "enc_input_pos", ",", "inference", ".", "com", ":", "com", ",", "inference", ".", "raw_com_weight", ":", "com_weight", ",", "inference", ".", "dec_gt", ":", "decoder_groundtruth", "}", ")", "\n", "print", "(", "\"batch_output\"", ",", "batch_logits", ")", "\n", "print", "(", "\"batch_predict\"", ",", "batch_predict", ")", "\n", "print", "(", "\"batch_loss\"", ",", "batch_loss", ")", "\n", "sess", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.WHUIR_RAGE.None.RAGEEncoder.ConvEncoder.__init__": [[14, 35], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "is_train", ",", "POS_emd", ",", "max_en_len", ",", "encoder_pos_emd", ",", "encoder_layer", ",", "fm_list", ",", "kwidth_list", ",", "\n", "emd_keep_prob", ",", "layer_keep_prob", ",", "scope_reuse", ")", ":", "\n", "# position[max_en_len,emd_size]", "\n", "        ", "self", ".", "encoder_pos_emd", "=", "encoder_pos_emd", "\n", "# the layer number of encoder", "\n", "self", ".", "encoder_layer", "=", "encoder_layer", "\n", "# the feature map of each layer", "\n", "self", ".", "fm_list", "=", "fm_list", "\n", "# the window size of each layer", "\n", "self", ".", "kwidth_list", "=", "kwidth_list", "\n", "# the keep prob of embedding dropout", "\n", "self", ".", "emd_keep_prob", "=", "emd_keep_prob", "\n", "# the keep prob of dropout between layer and layer", "\n", "self", ".", "layer_keep_prob", "=", "layer_keep_prob", "\n", "self", ".", "is_train", "=", "is_train", "\n", "# [batchsize,max_en_len,emd_size]", "\n", "self", ".", "max_en_len", "=", "max_en_len", "\n", "self", ".", "scope_reuse", "=", "scope_reuse", "\n", "# POS tag embedding", "\n", "self", ".", "POS_emd", "=", "POS_emd", "\n", "self", ".", "POS_UNK", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.WHUIR_RAGE.None.RAGEEncoder.ConvEncoder.create_position_embedding": [[37, 46], ["tensorflow.tile", "tensorflow.sequence_mask", "tensorflow.shape", "tensorflow.expand_dims"], "methods", ["None"], ["def", "create_position_embedding", "(", "self", ",", "lengths", ")", ":", "\n", "        ", "pos_emd", "=", "self", ".", "encoder_pos_emd", "\n", "batch_size", "=", "tf", ".", "shape", "(", "lengths", ")", "[", "0", "]", "\n", "# [batchsize,max_en_len,emd_size]", "\n", "pe_batch", "=", "tf", ".", "tile", "(", "[", "pos_emd", "]", ",", "[", "batch_size", ",", "1", ",", "1", "]", ")", "\n", "# [batchsize,batch_max_len]", "\n", "positions_mask", "=", "tf", ".", "sequence_mask", "(", "lengths", "=", "lengths", ",", "maxlen", "=", "self", ".", "max_en_len", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "positions_embed", "=", "pe_batch", "*", "tf", ".", "expand_dims", "(", "positions_mask", ",", "2", ")", "\n", "return", "positions_embed", "\n", "\n"]], "home.repos.pwc.inspect_result.WHUIR_RAGE.None.RAGEEncoder.ConvEncoder.create_POS_embedding": [[48, 56], ["tensorflow.nn.embedding_lookup", "tensorflow.negative", "tensorflow.expand_dims", "tensorflow.cast", "tensorflow.equal"], "methods", ["None"], ["def", "create_POS_embedding", "(", "self", ",", "enc_input_pos", ")", ":", "\n", "# [batchsize,max_en_len,emd_size]", "\n", "        ", "enc_pos_emd", "=", "tf", ".", "nn", ".", "embedding_lookup", "(", "self", ".", "POS_emd", ",", "enc_input_pos", ")", "\n", "# [batchsize,max_en_len]", "\n", "enc_pos_mask", "=", "tf", ".", "negative", "(", "tf", ".", "cast", "(", "tf", ".", "equal", "(", "enc_input_pos", ",", "self", ".", "POS_UNK", ")", ",", "dtype", "=", "tf", ".", "float32", ")", ")", "+", "1.0", "\n", "self", ".", "enc_pos_mask", "=", "enc_pos_mask", "\n", "enc_pos_emd", "=", "enc_pos_emd", "*", "tf", ".", "expand_dims", "(", "enc_pos_mask", ",", "axis", "=", "2", ")", "\n", "return", "enc_pos_emd", "\n", "\n"]], "home.repos.pwc.inspect_result.WHUIR_RAGE.None.RAGEEncoder.ConvEncoder.encode": [[58, 82], ["RAGEEncoder.ConvEncoder.create_position_embedding", "RAGEEncoder.ConvEncoder.create_POS_embedding", "tensorflow.add", "tensorflow.contrib.layers.dropout", "RAGEEncoder.ConvEncoderOutput", "tensorflow.contrib.layers.dropout.get_shape().as_list", "tensorflow.add", "tensorflow.variable_scope", "linear_mapping_weightnorm", "conv_encoder_stack", "linear_mapping_weightnorm", "tensorflow.sqrt", "tensorflow.contrib.layers.dropout.get_shape"], "methods", ["home.repos.pwc.inspect_result.WHUIR_RAGE.None.RAGEDecoder.ConvDecoder.create_position_embedding", "home.repos.pwc.inspect_result.WHUIR_RAGE.None.RAGEDecoder.ConvDecoder.create_POS_embedding", "home.repos.pwc.inspect_result.WHUIR_RAGE.None.Unit.linear_mapping_weightnorm", "home.repos.pwc.inspect_result.WHUIR_RAGE.None.Unit.conv_encoder_stack", "home.repos.pwc.inspect_result.WHUIR_RAGE.None.Unit.linear_mapping_weightnorm"], ["def", "encode", "(", "self", ",", "inputs", ",", "input_pos", ",", "sequence_length", ")", ":", "\n", "# input[batchsize,max_en_len,emd_size]", "\n", "        ", "embed_size", "=", "inputs", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", "[", "-", "1", "]", "\n", "pos_emd", "=", "self", ".", "create_position_embedding", "(", "lengths", "=", "sequence_length", ")", "\n", "POS_emd", "=", "self", ".", "create_POS_embedding", "(", "input_pos", ")", "\n", "# input+pos_emd+POS", "\n", "inputs", "=", "tf", ".", "add", "(", "tf", ".", "add", "(", "inputs", ",", "pos_emd", ")", ",", "POS_emd", ")", "\n", "# Apply dropout to embeddings", "\n", "inputs", "=", "tf", ".", "contrib", ".", "layers", ".", "dropout", "(", "inputs", "=", "inputs", ",", "keep_prob", "=", "self", ".", "emd_keep_prob", ",", "is_training", "=", "self", ".", "is_train", ")", "\n", "with", "tf", ".", "variable_scope", "(", "\"encoder_cnn\"", ",", "reuse", "=", "self", ".", "scope_reuse", ")", ":", "\n", "            ", "next_layer", "=", "inputs", "\n", "fm_list", "=", "self", ".", "fm_list", "\n", "kwidth_list", "=", "self", ".", "kwidth_list", "\n", "# mapping emd dim to hid dim", "\n", "next_layer", "=", "linear_mapping_weightnorm", "(", "next_layer", ",", "fm_list", "[", "0", "]", ",", "dropout", "=", "self", ".", "emd_keep_prob", ",", "\n", "var_scope_name", "=", "\"linear_mapping_before_cnn\"", ",", "\n", "scope_reuse", "=", "self", ".", "scope_reuse", ")", "\n", "next_layer", "=", "conv_encoder_stack", "(", "next_layer", ",", "self", ".", "encoder_layer", ",", "fm_list", ",", "kwidth_list", ",", "self", ".", "layer_keep_prob", ",", "\n", "self", ".", "is_train", ",", "scope_reuse", "=", "self", ".", "scope_reuse", ")", "\n", "next_layer", "=", "linear_mapping_weightnorm", "(", "next_layer", ",", "embed_size", ",", "var_scope_name", "=", "\"linear_mapping_after_cnn\"", ",", "\n", "scope_reuse", "=", "self", ".", "scope_reuse", ")", "\n", "# residual connection", "\n", "res_connection", "=", "(", "next_layer", "+", "inputs", ")", "*", "tf", ".", "sqrt", "(", "0.5", ")", "\n", "", "return", "ConvEncoderOutput", "(", "next_layer", ",", "res_connection", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.WHUIR_RAGE.None.RAGEDecoder.ConvDecoder.__init__": [[20, 47], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "is_train", ",", "batchsize", ",", "start_token", ",", "eos_token", ",", "word_emd", ",", "POS_emd", ",", "wordid2posid", ",", "decoder_pos_emd", ",", "\n", "decoder_layer", ",", "fm_list", ",", "kwidth_list", ",", "layer_keep_prob", ",", "emd_keep_prob", ",", "max_de_len", ",", "emd_size", ",", "\n", "out_keep_prob", ",", "vocab_size", ",", "scope_reuse", ")", ":", "\n", "        ", "self", ".", "batchsize", "=", "batchsize", "\n", "self", ".", "is_train", "=", "is_train", "\n", "self", ".", "start_token", "=", "start_token", "\n", "self", ".", "eos_token", "=", "eos_token", "\n", "# position embedding", "\n", "self", ".", "decoder_pos_emd", "=", "decoder_pos_emd", "\n", "self", ".", "decoder_layer", "=", "decoder_layer", "\n", "self", ".", "fm_list", "=", "fm_list", "\n", "self", ".", "kwidth_list", "=", "kwidth_list", "\n", "self", ".", "layer_keep_prob", "=", "layer_keep_prob", "\n", "self", ".", "emd_keep_prob", "=", "emd_keep_prob", "\n", "self", ".", "out_keep_prob", "=", "out_keep_prob", "\n", "self", ".", "max_de_len", "=", "max_de_len", "\n", "self", ".", "emd_size", "=", "emd_size", "\n", "self", ".", "vocab_size", "=", "vocab_size", "\n", "self", ".", "word_emd", "=", "word_emd", "\n", "self", ".", "initial_state", "=", "None", "\n", "# scope reuse param", "\n", "self", ".", "scope_reuse", "=", "scope_reuse", "\n", "# POS tag embedding", "\n", "self", ".", "POS_emd", "=", "POS_emd", "\n", "self", ".", "wordid2posid", "=", "wordid2posid", "\n", "# unknown POS tag sign", "\n", "self", ".", "POS_UNK", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.WHUIR_RAGE.None.RAGEDecoder.ConvDecoder.create_position_embedding": [[49, 60], ["tensorflow.tile", "tensorflow.sequence_mask", "tensorflow.shape", "tensorflow.expand_dims"], "methods", ["None"], ["def", "create_position_embedding", "(", "self", ",", "lengths", ")", ":", "\n", "# [max_de_len,emd_size]", "\n", "        ", "pos_emd", "=", "self", ".", "decoder_pos_emd", "\n", "batch_size", "=", "tf", ".", "shape", "(", "lengths", ")", "[", "0", "]", "\n", "# [batchsize,max_de_len,emd_size]", "\n", "pe_batch", "=", "tf", ".", "tile", "(", "[", "pos_emd", "]", ",", "[", "batch_size", ",", "1", ",", "1", "]", ")", "\n", "# [batchsize,max_de_len]", "\n", "pos_mask", "=", "tf", ".", "sequence_mask", "(", "lengths", "=", "lengths", ",", "maxlen", "=", "self", ".", "max_de_len", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "# [batchsize,max_de_len,emd_size]*[batchsize,max_de_len,1]-->[batchsize,max_de_len,emd_size]", "\n", "pos_emd", "=", "pe_batch", "*", "tf", ".", "expand_dims", "(", "pos_mask", ",", "2", ")", "\n", "return", "pos_emd", "\n", "\n"]], "home.repos.pwc.inspect_result.WHUIR_RAGE.None.RAGEDecoder.ConvDecoder.create_POS_embedding": [[62, 69], ["tensorflow.nn.embedding_lookup", "tensorflow.negative", "tensorflow.expand_dims", "tensorflow.cast", "tensorflow.equal"], "methods", ["None"], ["def", "create_POS_embedding", "(", "self", ",", "dec_input_pos", ")", ":", "\n", "# [batchsize,max_de_len,emd_size]", "\n", "        ", "dec_pos_emd", "=", "tf", ".", "nn", ".", "embedding_lookup", "(", "self", ".", "POS_emd", ",", "dec_input_pos", ")", "\n", "# [batchsize,max_de_len]", "\n", "dec_pos_mask", "=", "tf", ".", "negative", "(", "tf", ".", "cast", "(", "tf", ".", "equal", "(", "dec_input_pos", ",", "self", ".", "POS_UNK", ")", ",", "dtype", "=", "tf", ".", "float32", ")", ")", "+", "1.0", "\n", "dec_pos_emd", "=", "dec_pos_emd", "*", "tf", ".", "expand_dims", "(", "dec_pos_mask", ",", "axis", "=", "2", ")", "\n", "return", "dec_pos_emd", "\n", "\n"]], "home.repos.pwc.inspect_result.WHUIR_RAGE.None.RAGEDecoder.ConvDecoder.conv_block": [[71, 107], ["tensorflow.variable_scope", "linear_mapping_weightnorm", "conv_decoder_stack", "tensorflow.get_variable_scope().reuse_variables", "tensorflow.variable_scope", "tensorflow.contrib.layers.dropout", "linear_mapping_weightnorm", "tensorflow.get_variable_scope().reuse_variables", "linear_mapping_weightnorm", "linear_mapping_weightnorm", "tensorflow.get_variable_scope", "tensorflow.get_variable_scope"], "methods", ["home.repos.pwc.inspect_result.WHUIR_RAGE.None.Unit.linear_mapping_weightnorm", "home.repos.pwc.inspect_result.WHUIR_RAGE.None.Unit.conv_decoder_stack", "home.repos.pwc.inspect_result.WHUIR_RAGE.None.Unit.linear_mapping_weightnorm", "home.repos.pwc.inspect_result.WHUIR_RAGE.None.Unit.linear_mapping_weightnorm", "home.repos.pwc.inspect_result.WHUIR_RAGE.None.Unit.linear_mapping_weightnorm"], ["def", "conv_block", "(", "self", ",", "enc_output", ",", "input_embed", ",", "wcom_emd", ")", ":", "\n", "        ", "with", "tf", ".", "variable_scope", "(", "\"decoder_cnn\"", ",", "reuse", "=", "self", ".", "scope_reuse", ")", ":", "\n", "# [batchsize,max_de_len,emd_size]", "\n", "            ", "next_layer", "=", "input_embed", "\n", "fm_list", "=", "self", ".", "fm_list", "\n", "kwidth_list", "=", "self", ".", "kwidth_list", "\n", "# mapping emb dim to hid dim", "\n", "next_layer", "=", "linear_mapping_weightnorm", "(", "next_layer", ",", "fm_list", "[", "0", "]", ",", "dropout", "=", "self", ".", "emd_keep_prob", ",", "\n", "var_scope_name", "=", "\"linear_mapping_before_cnn\"", ",", "\n", "scope_reuse", "=", "self", ".", "scope_reuse", ")", "\n", "# decoder hidden state[batchsize,max_de_len,fm]", "\n", "next_layer", ",", "final_com_att", "=", "conv_decoder_stack", "(", "input_embed", ",", "enc_output", ".", "outputs", ",", "enc_output", ".", "attention_values", ",", "\n", "next_layer", ",", "wcom_emd", ",", "fm_list", ",", "kwidth_list", ",", "\n", "self", ".", "layer_keep_prob", ",", "self", ".", "is_train", ",", "\n", "scope_reuse", "=", "self", ".", "scope_reuse", ")", "\n", "self", ".", "com_att_out", "=", "final_com_att", "\n", "tf", ".", "get_variable_scope", "(", ")", ".", "reuse_variables", "(", ")", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "\"softmax\"", ",", "reuse", "=", "self", ".", "scope_reuse", ")", ":", "\n", "            ", "if", "self", ".", "is_train", ":", "\n", "                ", "next_layer", "=", "linear_mapping_weightnorm", "(", "next_layer", ",", "self", ".", "emd_size", ",", "\n", "var_scope_name", "=", "\"linear_mapping_after_cnn\"", ",", "\n", "scope_reuse", "=", "self", ".", "scope_reuse", ")", "\n", "", "else", ":", "\n", "# [batchsize,1,emd_size]", "\n", "                ", "next_layer", "=", "linear_mapping_weightnorm", "(", "next_layer", "[", ":", ",", "-", "1", ":", ",", ":", "]", ",", "self", ".", "emd_size", ",", "\n", "var_scope_name", "=", "\"linear_mapping_after_cnn\"", ",", "\n", "scope_reuse", "=", "self", ".", "scope_reuse", ")", "\n", "", "next_layer", "=", "tf", ".", "contrib", ".", "layers", ".", "dropout", "(", "inputs", "=", "next_layer", ",", "keep_prob", "=", "self", ".", "out_keep_prob", ",", "\n", "is_training", "=", "self", ".", "is_train", ")", "\n", "# train [batchsize,max_de_len,vocab_size]", "\n", "# inference [batchsize,1,vocab_size]", "\n", "logits", "=", "linear_mapping_weightnorm", "(", "next_layer", ",", "self", ".", "vocab_size", ",", "dropout", "=", "self", ".", "out_keep_prob", ",", "\n", "var_scope_name", "=", "\"logits_before_softmax\"", ",", "scope_reuse", "=", "self", ".", "scope_reuse", ")", "\n", "tf", ".", "get_variable_scope", "(", ")", ".", "reuse_variables", "(", ")", "\n", "", "return", "logits", "\n", "\n"]], "home.repos.pwc.inspect_result.WHUIR_RAGE.None.RAGEDecoder.ConvDecoder.conv_decoder_train": [[109, 123], ["RAGEDecoder.ConvDecoder.create_position_embedding", "RAGEDecoder.ConvDecoder.create_POS_embedding", "tensorflow.add", "tensorflow.contrib.layers.dropout", "RAGEDecoder.ConvDecoder.conv_block", "tensorflow.arg_max", "tensorflow.cast", "tensorflow.contrib.seq2seq.sequence_loss", "tensorflow.add", "tensorflow.sign"], "methods", ["home.repos.pwc.inspect_result.WHUIR_RAGE.None.RAGEDecoder.ConvDecoder.create_position_embedding", "home.repos.pwc.inspect_result.WHUIR_RAGE.None.RAGEDecoder.ConvDecoder.create_POS_embedding", "home.repos.pwc.inspect_result.WHUIR_RAGE.None.RAGEDecoder.ConvDecoder.conv_block"], ["def", "conv_decoder_train", "(", "self", ",", "enc_output", ",", "dec_input", ",", "dec_input_pos", ",", "dec_groundtruth", ",", "seq_len", ",", "wcom_emd", ")", ":", "\n", "        ", "emd_size", "=", "self", ".", "emd_size", "\n", "pos_emd", "=", "self", ".", "create_position_embedding", "(", "lengths", "=", "seq_len", ")", "\n", "POS_emd", "=", "self", ".", "create_POS_embedding", "(", "dec_input_pos", ")", "\n", "# [batchsize,max_de_len,emd_size]", "\n", "dec_input", "=", "tf", ".", "add", "(", "tf", ".", "add", "(", "dec_input", ",", "pos_emd", ")", ",", "POS_emd", ")", "\n", "# Apply dropout to embeddings", "\n", "dec_input", "=", "tf", ".", "contrib", ".", "layers", ".", "dropout", "(", "inputs", "=", "dec_input", ",", "keep_prob", "=", "self", ".", "emd_keep_prob", ",", "is_training", "=", "self", ".", "is_train", ")", "\n", "\n", "logits", "=", "self", ".", "conv_block", "(", "enc_output", ",", "dec_input", ",", "wcom_emd", ")", "\n", "predict", "=", "tf", ".", "arg_max", "(", "logits", ",", "dimension", "=", "2", ")", "\n", "loss_weight", "=", "tf", ".", "cast", "(", "tf", ".", "sign", "(", "dec_groundtruth", ")", ",", "tf", ".", "float32", ")", "\n", "loss", "=", "tf", ".", "contrib", ".", "seq2seq", ".", "sequence_loss", "(", "logits", "=", "logits", ",", "targets", "=", "dec_groundtruth", ",", "weights", "=", "loss_weight", ")", "\n", "return", "logits", ",", "predict", ",", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.WHUIR_RAGE.None.RAGEDecoder.ConvDecoder.batch_size": [[124, 126], ["None"], "methods", ["None"], ["", "def", "batch_size", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "batchsize", "\n", "\n"]], "home.repos.pwc.inspect_result.WHUIR_RAGE.None.RAGEDecoder.ConvDecoder.output_size": [[127, 129], ["RAGEDecoder.ConvDecoderOutput", "tensorflow.TensorShape"], "methods", ["None"], ["", "def", "output_size", "(", "self", ")", ":", "\n", "        ", "return", "ConvDecoderOutput", "(", "logits", "=", "self", ".", "vocab_size", ",", "predicted_ids", "=", "tf", ".", "TensorShape", "(", "[", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.WHUIR_RAGE.None.RAGEDecoder.ConvDecoder.output_dtype": [[130, 132], ["RAGEDecoder.ConvDecoderOutput"], "methods", ["None"], ["", "def", "output_dtype", "(", "self", ")", ":", "\n", "        ", "return", "ConvDecoderOutput", "(", "logits", "=", "tf", ".", "float32", ",", "predicted_ids", "=", "tf", ".", "int32", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.WHUIR_RAGE.None.RAGEDecoder.ConvDecoder._setup": [[133, 135], ["None"], "methods", ["None"], ["", "def", "_setup", "(", "self", ",", "initial_state", ",", "helper", "=", "None", ")", ":", "\n", "        ", "self", ".", "initial_state", "=", "initial_state", "\n", "\n"]], "home.repos.pwc.inspect_result.WHUIR_RAGE.None.RAGEDecoder.ConvDecoder.initialize": [[136, 152], ["tensorflow.tile", "tensorflow.fill", "tensorflow.nn.embedding_lookup", "tensorflow.expand_dims", "tensorflow.zeros", "tensorflow.concat", "rage.RAGEEncoder.ConvEncoderOutput"], "methods", ["None"], ["", "def", "initialize", "(", "self", ",", "name", "=", "None", ")", ":", "\n", "# [False,False,....]", "\n", "        ", "finished", "=", "tf", ".", "tile", "(", "[", "False", "]", ",", "[", "self", ".", "batchsize", "]", ")", "\n", "# [Start,Start,....]", "\n", "start_tokens_batch", "=", "tf", ".", "fill", "(", "[", "self", ".", "batchsize", "]", ",", "self", ".", "start_token", ")", "\n", "# [batchsize,emd_size]", "\n", "first_inputs", "=", "tf", ".", "nn", ".", "embedding_lookup", "(", "self", ".", "word_emd", ",", "start_tokens_batch", ")", "\n", "# [batchsize,1,emd_size]", "\n", "first_inputs", "=", "tf", ".", "expand_dims", "(", "first_inputs", ",", "1", ")", "\n", "# a slot for START", "\n", "zeros_padding", "=", "tf", ".", "zeros", "(", "[", "self", ".", "batchsize", ",", "self", ".", "max_de_len", "-", "1", ",", "self", ".", "emd_size", "]", ")", "\n", "# [batchsize,max_de_len,emd_size]", "\n", "first_inputs", "=", "tf", ".", "concat", "(", "[", "first_inputs", ",", "zeros_padding", "]", ",", "axis", "=", "1", ")", "\n", "enc_output", "=", "ConvEncoderOutput", "(", "outputs", "=", "self", ".", "initial_state", ".", "outputs", ",", "\n", "attention_values", "=", "self", ".", "initial_state", ".", "attention_values", ")", "\n", "return", "finished", ",", "first_inputs", ",", "enc_output", "\n", "\n"]], "home.repos.pwc.inspect_result.WHUIR_RAGE.None.RAGEDecoder.ConvDecoder.finalize": [[153, 156], ["None"], "methods", ["None"], ["", "def", "finalize", "(", "self", ",", "outputs", ",", "final_state", ")", ":", "\n", "\n", "        ", "return", "outputs", ",", "final_state", "\n", "\n"]], "home.repos.pwc.inspect_result.WHUIR_RAGE.None.RAGEDecoder.ConvDecoder.next_inputs": [[157, 172], ["tensorflow.python.ops.math_ops.equal", "tensorflow.python.ops.math_ops.reduce_all", "tensorflow.nn.embedding_lookup", "tensorflow.nn.embedding_lookup", "tensorflow.python.ops.control_flow_ops.cond", "tensorflow.nn.embedding_lookup", "tensorflow.add", "tensorflow.tile", "tensorflow.nn.embedding_lookup"], "methods", ["None"], ["", "def", "next_inputs", "(", "self", ",", "sample_ids", ",", "name", "=", "None", ")", ":", "\n", "# [batchsize*1]", "\n", "        ", "finished", "=", "math_ops", ".", "equal", "(", "sample_ids", ",", "self", ".", "eos_token", ")", "\n", "# 1", "\n", "all_finished", "=", "math_ops", ".", "reduce_all", "(", "finished", ")", "\n", "# [batchsize]", "\n", "sample_pos", "=", "tf", ".", "nn", ".", "embedding_lookup", "(", "self", ".", "wordid2posid", ",", "sample_ids", ")", "\n", "# [batchsize,emd_size]", "\n", "sample_pos_emd", "=", "tf", ".", "nn", ".", "embedding_lookup", "(", "self", ".", "POS_emd", ",", "sample_pos", ")", "\n", "next_inputs", "=", "control_flow_ops", ".", "cond", "(", "\n", "all_finished", ",", "\n", "lambda", ":", "tf", ".", "nn", ".", "embedding_lookup", "(", "self", ".", "word_emd", ",", "tf", ".", "tile", "(", "[", "self", ".", "eos_token", "]", ",", "[", "self", ".", "batchsize", "]", ")", ")", ",", "\n", "# [batchsize*1,emd_size]", "\n", "lambda", ":", "tf", ".", "add", "(", "tf", ".", "nn", ".", "embedding_lookup", "(", "self", ".", "word_emd", ",", "sample_ids", ")", ",", "sample_pos_emd", ")", ")", "\n", "return", "all_finished", ",", "next_inputs", "\n", "\n"]], "home.repos.pwc.inspect_result.WHUIR_RAGE.None.RAGEDecoder.ConvDecoder.add_position_embedding": [[173, 179], ["tensorflow.expand_dims", "tensorflow.tile", "tensorflow.add"], "methods", ["None"], ["", "def", "add_position_embedding", "(", "self", ",", "inputs", ",", "time", ")", ":", "\n", "        ", "seq_pos_embed", "=", "self", ".", "decoder_pos_emd", "[", "0", ":", "time", "+", "1", ",", ":", "]", "\n", "seq_pos_embed", "=", "tf", ".", "expand_dims", "(", "seq_pos_embed", ",", "axis", "=", "0", ")", "\n", "# [batchsize,time,emd_size]", "\n", "seq_pos_embed_batch", "=", "tf", ".", "tile", "(", "seq_pos_embed", ",", "[", "self", ".", "batchsize", ",", "1", ",", "1", "]", ")", "\n", "return", "tf", ".", "add", "(", "inputs", ",", "seq_pos_embed_batch", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.WHUIR_RAGE.None.RAGEDecoder.ConvDecoder.step": [[180, 198], ["RAGEDecoder.ConvDecoder.add_position_embedding", "RAGEDecoder.ConvDecoder.infer_conv_block", "tensorflow.cast", "RAGEDecoder.ConvDecoder.next_inputs", "tensorflow.reshape", "tensorflow.concat", "tensorflow.concat", "tensorflow.concat.set_shape", "RAGEDecoder.ConvDecoderOutput", "tensorflow.argmax", "inputs.get_shape().as_list", "inputs.get_shape().as_list", "inputs.get_shape", "inputs.get_shape"], "methods", ["home.repos.pwc.inspect_result.WHUIR_RAGE.None.RAGEDecoder.ConvDecoder.add_position_embedding", "home.repos.pwc.inspect_result.WHUIR_RAGE.None.RAGEDecoder.ConvDecoder.infer_conv_block", "home.repos.pwc.inspect_result.WHUIR_RAGE.None.RAGEDecoder.ConvDecoder.next_inputs"], ["", "def", "step", "(", "self", ",", "time", ",", "inputs", ",", "state", ",", "context", ",", "name", "=", "None", ")", ":", "\n", "        ", "cur_inputs", "=", "inputs", "[", ":", ",", "0", ":", "time", "+", "1", ",", ":", "]", "\n", "zeros_padding", "=", "inputs", "[", ":", ",", "time", "+", "2", ":", ",", ":", "]", "\n", "cur_inputs_pos", "=", "self", ".", "add_position_embedding", "(", "cur_inputs", ",", "time", ")", "\n", "enc_output", "=", "state", "\n", "# [batchsize*1,vocab_size]", "\n", "logits", "=", "self", ".", "infer_conv_block", "(", "enc_output", ",", "cur_inputs_pos", ",", "context", ")", "\n", "# [batchsize*1]", "\n", "sample_ids", "=", "tf", ".", "cast", "(", "tf", ".", "argmax", "(", "logits", ",", "axis", "=", "-", "1", ")", ",", "dtypes", ".", "int32", ")", "\n", "# next_input[batchsize*1,emd_size]", "\n", "finished", ",", "next_inputs", "=", "self", ".", "next_inputs", "(", "sample_ids", "=", "sample_ids", ")", "\n", "# [batchsize,1,emd_size]", "\n", "next_inputs", "=", "tf", ".", "reshape", "(", "next_inputs", ",", "[", "self", ".", "batchsize", ",", "1", ",", "inputs", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", "[", "-", "1", "]", "]", ")", "\n", "next_inputs", "=", "tf", ".", "concat", "(", "[", "cur_inputs", ",", "next_inputs", "]", ",", "axis", "=", "1", ")", "\n", "next_inputs", "=", "tf", ".", "concat", "(", "[", "next_inputs", ",", "zeros_padding", "]", ",", "axis", "=", "1", ")", "\n", "next_inputs", ".", "set_shape", "(", "[", "self", ".", "batchsize", ",", "self", ".", "max_de_len", ",", "inputs", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", "[", "-", "1", "]", "]", ")", "\n", "outputs", "=", "ConvDecoderOutput", "(", "logits", "=", "logits", ",", "predicted_ids", "=", "sample_ids", ")", "\n", "return", "outputs", ",", "enc_output", ",", "next_inputs", ",", "finished", "\n", "\n"]], "home.repos.pwc.inspect_result.WHUIR_RAGE.None.RAGEDecoder.ConvDecoder.infer_conv_block": [[200, 211], ["tensorflow.contrib.layers.dropout", "RAGEDecoder.ConvDecoder.conv_block", "RAGEDecoder.ConvDecoder.get_shape().as_list", "tensorflow.reshape", "RAGEDecoder.ConvDecoder.get_shape"], "methods", ["home.repos.pwc.inspect_result.WHUIR_RAGE.None.RAGEDecoder.ConvDecoder.conv_block"], ["def", "infer_conv_block", "(", "self", ",", "enc_output", ",", "input_embed", ",", "wcom_emd", ")", ":", "\n", "# Apply dropout to embeddings", "\n", "# [batchsize,1,emd_size]", "\n", "        ", "input_embed", "=", "tf", ".", "contrib", ".", "layers", ".", "dropout", "(", "inputs", "=", "input_embed", ",", "keep_prob", "=", "self", ".", "emd_keep_prob", ",", "\n", "is_training", "=", "self", ".", "is_train", ")", "\n", "# [batchsize,1,vocab_size]", "\n", "next_layer", "=", "self", ".", "conv_block", "(", "enc_output", ",", "input_embed", ",", "wcom_emd", ")", "\n", "shape", "=", "next_layer", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", "\n", "# [batchsize*1,vocab_size]", "\n", "logits", "=", "tf", ".", "reshape", "(", "next_layer", ",", "[", "-", "1", ",", "shape", "[", "-", "1", "]", "]", ")", "\n", "return", "logits", "\n", "\n"]], "home.repos.pwc.inspect_result.WHUIR_RAGE.None.RAGEDecoder.ConvDecoder.init_params_in_loop": [[212, 218], ["tensorflow.variable_scope", "RAGEDecoder.ConvDecoder.initialize", "RAGEDecoder.ConvDecoder.infer_conv_block", "tensorflow.get_variable_scope().reuse_variables", "tensorflow.get_variable_scope"], "methods", ["home.repos.pwc.inspect_result.WHUIR_RAGE.seq2seq.decoder.Decoder.initialize", "home.repos.pwc.inspect_result.WHUIR_RAGE.None.RAGEDecoder.ConvDecoder.infer_conv_block"], ["", "def", "init_params_in_loop", "(", "self", ",", "wcom_emd", ")", ":", "\n", "        ", "with", "tf", ".", "variable_scope", "(", "\"decoder\"", ",", "reuse", "=", "self", ".", "scope_reuse", ")", ":", "\n", "            ", "initial_finished", ",", "initial_inputs", ",", "initial_state", "=", "self", ".", "initialize", "(", ")", "\n", "enc_output", "=", "initial_state", "\n", "logits", "=", "self", ".", "infer_conv_block", "(", "enc_output", ",", "initial_inputs", ",", "wcom_emd", ")", "\n", "tf", ".", "get_variable_scope", "(", ")", ".", "reuse_variables", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.WHUIR_RAGE.None.RAGEDecoder.ConvDecoder.conv_decoder_infer": [[220, 230], ["RAGEDecoder.ConvDecoder.init_params_in_loop", "tensorflow.get_variable_scope().reuse_variables", "dynamic_decode", "RAGEDecoder.ConvDecoder._setup", "tensorflow.get_variable_scope"], "methods", ["home.repos.pwc.inspect_result.WHUIR_RAGE.None.RAGEDecoder.ConvDecoder.init_params_in_loop", "home.repos.pwc.inspect_result.WHUIR_RAGE.seq2seq.decoder.dynamic_decode", "home.repos.pwc.inspect_result.WHUIR_RAGE.None.RAGEDecoder.ConvDecoder._setup"], ["def", "conv_decoder_infer", "(", "self", ",", "enc_output", ",", "wcom_emd", ")", ":", "\n", "        ", "if", "not", "self", ".", "initial_state", ":", "\n", "            ", "self", ".", "_setup", "(", "initial_state", "=", "enc_output", ")", "\n", "", "maximum_iterations", "=", "self", ".", "max_de_len", "\n", "self", ".", "init_params_in_loop", "(", "wcom_emd", ")", "\n", "tf", ".", "get_variable_scope", "(", ")", ".", "reuse_variables", "(", ")", "\n", "outputs", ",", "final_state", "=", "dynamic_decode", "(", "decoder", "=", "self", ",", "wcom_emd", "=", "wcom_emd", ",", "output_time_major", "=", "False", ",", "\n", "impute_finished", "=", "False", ",", "maximum_iterations", "=", "maximum_iterations", ",", "\n", "scope_reuse", "=", "self", ".", "scope_reuse", ")", "\n", "return", "outputs", ",", "final_state", "\n", "", "", ""]], "home.repos.pwc.inspect_result.WHUIR_RAGE.None.Unit.conv_encoder_stack": [[6, 26], ["range", "tensorflow.contrib.layers.dropout", "Unit.conv1d_weightnorm", "Unit.gate_linear_unit", "tensorflow.sqrt"], "function", ["home.repos.pwc.inspect_result.WHUIR_RAGE.None.Unit.conv1d_weightnorm", "home.repos.pwc.inspect_result.WHUIR_RAGE.None.Unit.gate_linear_unit"], ["def", "conv_encoder_stack", "(", "encoder_input_emd", ",", "layer_num", ",", "fm_list", ",", "kwidth_list", ",", "layer_keep_prob", ",", "is_train", ",", "scope_reuse", ")", ":", "\n", "# [batchsize,max_en_len,emd_size]", "\n", "    ", "next_layer", "=", "encoder_input_emd", "\n", "for", "layer_id", "in", "range", "(", "layer_num", ")", ":", "\n", "# residual Connection", "\n", "        ", "res_input", "=", "next_layer", "\n", "# featureMap num*2 for gate linear,feature num=embedding size", "\n", "fm_num", "=", "fm_list", "[", "layer_id", "]", "*", "2", "\n", "kwidth", "=", "kwidth_list", "[", "layer_id", "]", "\n", "\n", "# drop out before input to conv", "\n", "next_layer", "=", "tf", ".", "contrib", ".", "layers", ".", "dropout", "(", "inputs", "=", "next_layer", ",", "keep_prob", "=", "layer_keep_prob", ",", "is_training", "=", "is_train", ")", "\n", "\n", "# [batchsize,max_en_len,fm_num*2]", "\n", "next_layer", "=", "conv1d_weightnorm", "(", "next_layer", ",", "layer_id", ",", "fm_num", ",", "kwidth", ",", "dropout", "=", "layer_keep_prob", ",", "\n", "scope_reuse", "=", "scope_reuse", ")", "\n", "# [batchsize,max_en_len,fm_num]", "\n", "next_layer", "=", "gate_linear_unit", "(", "next_layer", ")", "\n", "next_layer", "=", "(", "next_layer", "+", "res_input", ")", "*", "tf", ".", "sqrt", "(", "0.5", ")", "\n", "", "return", "next_layer", "\n", "\n"]], "home.repos.pwc.inspect_result.WHUIR_RAGE.None.Unit.gate_linear_unit": [[28, 35], ["input.get_shape().as_list", "tensorflow.nn.sigmoid", "tensorflow.multiply", "input.get_shape", "int", "int"], "function", ["None"], ["def", "gate_linear_unit", "(", "input", ")", ":", "\n", "# [batchsize,max_en_len,fm_num*2]", "\n", "    ", "input_shape", "=", "input", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", "\n", "input_mes", "=", "input", "[", ":", ",", ":", ",", "0", ":", "int", "(", "input_shape", "[", "2", "]", "/", "2", ")", "]", "\n", "input_gate", "=", "tf", ".", "nn", ".", "sigmoid", "(", "input", "[", ":", ",", ":", ",", "int", "(", "input_shape", "[", "2", "]", "/", "2", ")", ":", "]", ")", "\n", "input_pass", "=", "tf", ".", "multiply", "(", "input_mes", ",", "input_gate", ")", "\n", "return", "input_pass", "\n", "\n"]], "home.repos.pwc.inspect_result.WHUIR_RAGE.None.Unit.conv1d_weightnorm": [[37, 56], ["tensorflow.variable_scope", "int", "tensorflow.get_variable", "tensorflow.norm", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.nn.bias_add", "tensorflow.get_variable_scope().reuse_variables", "tf.get_variable.initialized_value", "tensorflow.reshape", "tensorflow.nn.l2_normalize", "tensorflow.nn.conv1d", "str", "tf.nn.bias_add.get_shape().as_list", "tensorflow.random_normal_initializer", "tensorflow.zeros_initializer", "tensorflow.get_variable_scope", "tf.nn.bias_add.get_shape", "tensorflow.sqrt"], "function", ["None"], ["def", "conv1d_weightnorm", "(", "inputs", ",", "layer_id", ",", "out_dim", ",", "kernel_size", ",", "scope_reuse", ",", "dropout", "=", "1.0", ",", "padding", "=", "\"SAME\"", ")", ":", "\n", "    ", "with", "tf", ".", "variable_scope", "(", "\"conv_layer_\"", "+", "str", "(", "layer_id", ")", ",", "reuse", "=", "scope_reuse", ")", ":", "\n", "# input:[batch,max_en_len,emd_size]", "\n", "        ", "in_dim", "=", "int", "(", "inputs", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", "[", "-", "1", "]", ")", "\n", "V", "=", "tf", ".", "get_variable", "(", "'V'", ",", "shape", "=", "[", "kernel_size", ",", "in_dim", ",", "out_dim", "]", ",", "dtype", "=", "tf", ".", "float32", ",", "\n", "initializer", "=", "tf", ".", "random_normal_initializer", "(", "mean", "=", "0", ",", "stddev", "=", "tf", ".", "sqrt", "(", "\n", "4.0", "*", "dropout", "/", "(", "kernel_size", "*", "in_dim", ")", ")", ")", ",", "trainable", "=", "True", ")", "\n", "# V shape is M*N*k,  V_norm shape is k", "\n", "V_norm", "=", "tf", ".", "norm", "(", "V", ".", "initialized_value", "(", ")", ",", "axis", "=", "[", "0", ",", "1", "]", ")", "\n", "g", "=", "tf", ".", "get_variable", "(", "'g'", ",", "dtype", "=", "tf", ".", "float32", ",", "initializer", "=", "V_norm", ",", "trainable", "=", "True", ")", "\n", "b", "=", "tf", ".", "get_variable", "(", "'b'", ",", "shape", "=", "[", "out_dim", "]", ",", "dtype", "=", "tf", ".", "float32", ",", "initializer", "=", "tf", ".", "zeros_initializer", "(", ")", ",", "trainable", "=", "True", ")", "\n", "\n", "# use weight normalization (Salimans & Kingma, 2016)", "\n", "# [kwight,emd_size,out_dim]", "\n", "W", "=", "tf", ".", "reshape", "(", "g", ",", "[", "1", ",", "1", ",", "out_dim", "]", ")", "*", "tf", ".", "nn", ".", "l2_normalize", "(", "V", ",", "[", "0", ",", "1", "]", ")", "\n", "# [batch,max_en_len,out_dim]", "\n", "inputs", "=", "tf", ".", "nn", ".", "bias_add", "(", "tf", ".", "nn", ".", "conv1d", "(", "value", "=", "inputs", ",", "filters", "=", "W", ",", "stride", "=", "1", ",", "padding", "=", "padding", ")", ",", "b", ")", "\n", "tf", ".", "get_variable_scope", "(", ")", ".", "reuse_variables", "(", ")", "\n", "", "return", "inputs", "\n", "\n"]], "home.repos.pwc.inspect_result.WHUIR_RAGE.None.Unit.conv_decoder_stack": [[58, 105], ["range", "len", "tensorflow.contrib.layers.dropout", "tensorflow.pad", "Unit.conv1d_weightnorm", "Unit.gate_linear_unit", "Unit.make_attention", "Unit.make_com_attention_with_enc", "tensorflow.concat", "tensorflow.nn.tanh", "tensorflow.nn.tanh", "tensorflow.contrib.layers.fully_connected", "tensorflow.contrib.layers.fully_connected", "tensorflow.multiply", "tensorflow.sqrt", "tensorflow.multiply", "gate_linear_unit.get_shape().as_list", "gate_linear_unit.get_shape().as_list", "str", "str", "gate_linear_unit.get_shape", "gate_linear_unit.get_shape"], "function", ["home.repos.pwc.inspect_result.WHUIR_RAGE.None.Unit.conv1d_weightnorm", "home.repos.pwc.inspect_result.WHUIR_RAGE.None.Unit.gate_linear_unit", "home.repos.pwc.inspect_result.WHUIR_RAGE.None.Unit.make_attention", "home.repos.pwc.inspect_result.WHUIR_RAGE.None.Unit.make_com_attention_with_enc"], ["def", "conv_decoder_stack", "(", "previous_word", ",", "enc_output", ",", "enc_att_values", ",", "inputs", ",", "wcom_emd", ",", "fm_list", ",", "kwidth_list", ",", "\n", "layer_keep_prob", ",", "is_train", ",", "scope_reuse", ")", ":", "\n", "# [batchsize,max_de_len,emd_size]", "\n", "    ", "next_layer", "=", "inputs", "\n", "final_com_att", "=", "inputs", "\n", "for", "layer_id", "in", "range", "(", "len", "(", "fm_list", ")", ")", ":", "\n", "        ", "fm", "=", "fm_list", "[", "layer_id", "]", "\n", "kwidth", "=", "kwidth_list", "[", "layer_id", "]", "\n", "res_inputs", "=", "next_layer", "\n", "next_layer", "=", "tf", ".", "contrib", ".", "layers", ".", "dropout", "(", "inputs", "=", "next_layer", ",", "keep_prob", "=", "layer_keep_prob", ",", "is_training", "=", "is_train", ")", "\n", "# [batchsize,max_de_len+(kwidth-1)*2,emd_size]", "\n", "next_layer", "=", "tf", ".", "pad", "(", "next_layer", ",", "[", "[", "0", ",", "0", "]", ",", "[", "kwidth_list", "[", "layer_id", "]", "-", "1", ",", "kwidth_list", "[", "layer_id", "]", "-", "1", "]", ",", "[", "0", ",", "0", "]", "]", ",", "\n", "\"CONSTANT\"", ")", "\n", "next_layer", "=", "conv1d_weightnorm", "(", "inputs", "=", "next_layer", ",", "layer_id", "=", "layer_id", ",", "out_dim", "=", "fm", "*", "2", ",", "kernel_size", "=", "kwidth", ",", "\n", "dropout", "=", "layer_keep_prob", ",", "padding", "=", "\"VALID\"", ",", "scope_reuse", "=", "scope_reuse", ")", "\n", "\n", "# truncate", "\n", "# [batchsize,max_de_len,fm*2]", "\n", "next_layer", "=", "next_layer", "[", ":", ",", "0", ":", "-", "kwidth", "+", "1", ",", ":", "]", "\n", "# [batchsize,max_de_len,fm]", "\n", "next_layer", "=", "gate_linear_unit", "(", "next_layer", ")", "\n", "\n", "# make attention with question context", "\n", "# [batchsize,max_de_len,fm]", "\n", "enc_emd_att_out", ",", "enc_hid_att_out", "=", "make_attention", "(", "previous_word", ",", "enc_output", ",", "enc_att_values", ",", "next_layer", ",", "\n", "layer_id", ",", "scope_reuse", "=", "scope_reuse", ")", "\n", "\n", "# make attention with words in comments", "\n", "com_att_out", "=", "make_com_attention_with_enc", "(", "next_layer", ",", "wcom_emd", ",", "enc_emd_att_out", ",", "layer_id", ",", "\n", "scope_reuse", "=", "scope_reuse", ")", "\n", "final_com_att", "=", "com_att_out", "\n", "# [batchsize,max_de_len,fm*3]", "\n", "gate_input", "=", "tf", ".", "concat", "(", "[", "next_layer", ",", "enc_hid_att_out", ",", "com_att_out", "]", ",", "axis", "=", "-", "1", ")", "\n", "gate_one", "=", "tf", ".", "nn", ".", "tanh", "(", "\n", "tf", ".", "contrib", ".", "layers", ".", "fully_connected", "(", "gate_input", ",", "next_layer", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", "[", "-", "1", "]", ",", "trainable", "=", "True", ",", "\n", "reuse", "=", "scope_reuse", ",", "scope", "=", "\"gate_one_\"", "+", "str", "(", "layer_id", ")", ")", ")", "\n", "# [batchsize,max_de_len,fm]", "\n", "gate_two", "=", "tf", ".", "nn", ".", "tanh", "(", "\n", "tf", ".", "contrib", ".", "layers", ".", "fully_connected", "(", "gate_one", ",", "next_layer", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", "[", "-", "1", "]", ",", "trainable", "=", "True", ",", "\n", "reuse", "=", "scope_reuse", ",", "scope", "=", "\"gate_two_\"", "+", "str", "(", "layer_id", ")", ")", ")", "\n", "\n", "next_layer", "=", "next_layer", "+", "tf", ".", "multiply", "(", "gate_two", ",", "enc_hid_att_out", ")", "+", "tf", ".", "multiply", "(", "1", "-", "gate_two", ",", "com_att_out", ")", "\n", "\n", "# add residual connections", "\n", "# [batchsize,max_de_len,fm]", "\n", "next_layer", "+=", "(", "next_layer", "+", "res_inputs", ")", "*", "tf", ".", "sqrt", "(", "0.5", ")", "\n", "", "return", "next_layer", ",", "final_com_att", "\n", "\n"]], "home.repos.pwc.inspect_result.WHUIR_RAGE.None.Unit.make_attention": [[107, 132], ["tensorflow.variable_scope", "Unit.linear_mapping_weightnorm", "tensorflow.matmul", "tensorflow.nn.softmax", "tensorflow.cast", "Unit.linear_mapping_weightnorm", "tensorflow.get_variable_scope().reuse_variables", "previous_word.get_shape().as_list", "tensorflow.sqrt", "tensorflow.shape", "tensorflow.sqrt", "str", "tensorflow.matmul", "decoder_hidden.get_shape().as_list", "tensorflow.get_variable_scope", "previous_word.get_shape", "decoder_hidden.get_shape"], "function", ["home.repos.pwc.inspect_result.WHUIR_RAGE.None.Unit.linear_mapping_weightnorm", "home.repos.pwc.inspect_result.WHUIR_RAGE.None.Unit.linear_mapping_weightnorm"], ["def", "make_attention", "(", "previous_word", ",", "enc_output", ",", "enc_att_values", ",", "decoder_hidden", ",", "layer_idx", ",", "scope_reuse", ")", ":", "\n", "    ", "with", "tf", ".", "variable_scope", "(", "\"attention_layer_\"", "+", "str", "(", "layer_idx", ")", ",", "reuse", "=", "scope_reuse", ")", ":", "\n", "        ", "embed_size", "=", "previous_word", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", "[", "-", "1", "]", "\n", "dec_hidden_proj", "=", "linear_mapping_weightnorm", "(", "decoder_hidden", ",", "embed_size", ",", "\n", "var_scope_name", "=", "\"linear_mapping_att_query\"", ",", "\n", "scope_reuse", "=", "scope_reuse", ")", "# M*N1*k1 --> M*N1*k", "\n", "# [batchsize,max_de_len,fm]", "\n", "dec_rep", "=", "(", "dec_hidden_proj", "+", "previous_word", ")", "*", "tf", ".", "sqrt", "(", "0.5", ")", "\n", "\n", "# without residual connection[batchsize,max_en_len,emd_size]", "\n", "encoder_output_a", "=", "enc_output", "\n", "# with residual connection[batchsize,max_en_len,emd_size]", "\n", "encoder_output_c", "=", "enc_att_values", "\n", "\n", "# [batchsize,max_de_len,max_en_len]", "\n", "att_score", "=", "tf", ".", "matmul", "(", "dec_rep", ",", "encoder_output_a", ",", "transpose_b", "=", "True", ")", "\n", "att_score", "=", "tf", ".", "nn", ".", "softmax", "(", "att_score", ",", "dim", "=", "-", "1", ")", "\n", "\n", "length", "=", "tf", ".", "cast", "(", "tf", ".", "shape", "(", "encoder_output_c", ")", ",", "tf", ".", "float32", ")", "\n", "emd_att_out", "=", "tf", ".", "matmul", "(", "att_score", ",", "encoder_output_c", ")", "*", "length", "[", "1", "]", "*", "tf", ".", "sqrt", "(", "1.0", "/", "length", "[", "1", "]", ")", "\n", "hid_att_out", "=", "linear_mapping_weightnorm", "(", "emd_att_out", ",", "decoder_hidden", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", "[", "-", "1", "]", ",", "\n", "var_scope_name", "=", "\"linear_mapping_att_out\"", ",", "scope_reuse", "=", "scope_reuse", ")", "\n", "tf", ".", "get_variable_scope", "(", ")", ".", "reuse_variables", "(", ")", "\n", "\n", "return", "emd_att_out", ",", "hid_att_out", "\n", "\n"]], "home.repos.pwc.inspect_result.WHUIR_RAGE.None.Unit.make_com_attention_with_enc": [[134, 149], ["tensorflow.variable_scope", "tensorflow.matmul", "tensorflow.nn.softmax", "tensorflow.cast", "Unit.linear_mapping_weightnorm", "tensorflow.get_variable_scope().reuse_variables", "tensorflow.shape", "tensorflow.sqrt", "str", "tensorflow.matmul", "decoder_hidden.get_shape().as_list", "tensorflow.get_variable_scope", "decoder_hidden.get_shape"], "function", ["home.repos.pwc.inspect_result.WHUIR_RAGE.None.Unit.linear_mapping_weightnorm"], ["def", "make_com_attention_with_enc", "(", "decoder_hidden", ",", "wcom_emd", ",", "enc_emd_att_out", ",", "layer_idx", ",", "scope_reuse", "=", "False", ")", ":", "\n", "    ", "with", "tf", ".", "variable_scope", "(", "\"attention_layer_with_enc_\"", "+", "str", "(", "layer_idx", ")", ",", "reuse", "=", "scope_reuse", ")", ":", "\n", "# [batchsize,max_de_len,emd_size]*[batchsize,max_com_vocab,emd_size]-->[batchsize,max_de_len,max_com_vocab]", "\n", "        ", "att_score", "=", "tf", ".", "matmul", "(", "enc_emd_att_out", ",", "wcom_emd", ",", "transpose_b", "=", "True", ")", "\n", "\n", "att_score", "=", "tf", ".", "nn", ".", "softmax", "(", "att_score", ",", "dim", "=", "-", "1", ")", "\n", "length", "=", "tf", ".", "cast", "(", "tf", ".", "shape", "(", "wcom_emd", ")", ",", "tf", ".", "float32", ")", "\n", "# [batchsize,max_de_len,fm]", "\n", "att_out", "=", "tf", ".", "matmul", "(", "att_score", ",", "wcom_emd", ")", "*", "length", "[", "1", "]", "*", "tf", ".", "sqrt", "(", "1.0", "/", "length", "[", "1", "]", ")", "\n", "# emd-->hid", "\n", "att_out", "=", "linear_mapping_weightnorm", "(", "att_out", ",", "decoder_hidden", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", "[", "-", "1", "]", ",", "\n", "var_scope_name", "=", "\"linear_mapping_att_out\"", ",", "scope_reuse", "=", "scope_reuse", ")", "\n", "tf", ".", "get_variable_scope", "(", ")", ".", "reuse_variables", "(", ")", "\n", "\n", "return", "att_out", "\n", "\n"]], "home.repos.pwc.inspect_result.WHUIR_RAGE.None.Unit.linear_mapping_weightnorm": [[151, 172], ["tensorflow.variable_scope", "tf.reshape.get_shape().as_list", "tensorflow.shape", "tensorflow.get_variable", "tensorflow.norm", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.reshape", "tensorflow.matmul", "tensorflow.reshape", "tensorflow.div", "tensorflow.get_variable_scope().reuse_variables", "tf.get_variable.initialized_value", "tensorflow.norm", "tensorflow.reshape", "tf.reshape.get_shape", "tensorflow.random_normal_initializer", "tensorflow.zeros_initializer", "tensorflow.reshape", "tensorflow.get_variable_scope", "int", "tensorflow.sqrt", "int"], "function", ["None"], ["def", "linear_mapping_weightnorm", "(", "inputs", ",", "out_dim", ",", "scope_reuse", ",", "dropout", "=", "1.0", ",", "var_scope_name", "=", "\"linear_mapping\"", ")", ":", "\n", "    ", "with", "tf", ".", "variable_scope", "(", "var_scope_name", ",", "scope_reuse", ")", ":", "\n", "        ", "input_shape", "=", "inputs", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", "\n", "input_shape_tensor", "=", "tf", ".", "shape", "(", "inputs", ")", "\n", "\n", "# use weight normalization (Salimans & Kingma, 2016)  w = g* v/2-norm(v)", "\n", "V", "=", "tf", ".", "get_variable", "(", "'V'", ",", "shape", "=", "[", "int", "(", "input_shape", "[", "-", "1", "]", ")", ",", "out_dim", "]", ",", "dtype", "=", "tf", ".", "float32", ",", "\n", "initializer", "=", "tf", ".", "random_normal_initializer", "(", "mean", "=", "0", ",", "stddev", "=", "tf", ".", "sqrt", "(", "\n", "dropout", "*", "1.0", "/", "int", "(", "input_shape", "[", "-", "1", "]", ")", ")", ")", ",", "trainable", "=", "True", ")", "\n", "V_norm", "=", "tf", ".", "norm", "(", "V", ".", "initialized_value", "(", ")", ",", "axis", "=", "0", ")", "# V shape is M*N,  V_norm shape is N", "\n", "g", "=", "tf", ".", "get_variable", "(", "'g'", ",", "dtype", "=", "tf", ".", "float32", ",", "initializer", "=", "V_norm", ",", "trainable", "=", "True", ")", "\n", "b", "=", "tf", ".", "get_variable", "(", "'b'", ",", "shape", "=", "[", "out_dim", "]", ",", "dtype", "=", "tf", ".", "float32", ",", "initializer", "=", "tf", ".", "zeros_initializer", "(", ")", ",", "\n", "trainable", "=", "True", ")", "# weightnorm bias is init zero", "\n", "inputs", "=", "tf", ".", "reshape", "(", "inputs", ",", "[", "-", "1", ",", "input_shape", "[", "-", "1", "]", "]", ")", "\n", "inputs", "=", "tf", ".", "matmul", "(", "inputs", ",", "V", ")", "\n", "inputs", "=", "tf", ".", "reshape", "(", "inputs", ",", "[", "input_shape_tensor", "[", "0", "]", ",", "-", "1", ",", "out_dim", "]", ")", "\n", "scaler", "=", "tf", ".", "div", "(", "g", ",", "tf", ".", "norm", "(", "V", ",", "axis", "=", "0", ")", ")", "# g/2-norm(v)", "\n", "# [batchsize,max_de_len,out_dim]", "\n", "inputs", "=", "tf", ".", "reshape", "(", "scaler", ",", "[", "1", ",", "out_dim", "]", ")", "*", "inputs", "+", "tf", ".", "reshape", "(", "b", ",", "[", "1", ",", "out_dim", "]", ")", "# x*v g/2-norm(v) + b", "\n", "tf", ".", "get_variable_scope", "(", ")", ".", "reuse_variables", "(", ")", "\n", "", "return", "inputs", "\n", "", ""]], "home.repos.pwc.inspect_result.WHUIR_RAGE.None.DataProcess.load_stopword": [[11, 22], ["codecs.open", "print", "codecs.open.readline", "fr_sw.readline.replace", "stop_word.append", "codecs.open.readline", "fr_sw.readline.strip"], "function", ["None"], ["def", "load_stopword", "(", "stopword_path", ")", ":", "\n", "    ", "fr_sw", "=", "codecs", ".", "open", "(", "stopword_path", ",", "'r'", ",", "'utf-8'", ")", "\n", "# load stop word", "\n", "print", "(", "\"Load stop word \"", ")", "\n", "stop_word", "=", "[", "]", "\n", "sw", "=", "fr_sw", ".", "readline", "(", ")", "\n", "while", "sw", ":", "\n", "        ", "sw", "=", "sw", ".", "replace", "(", "\"\\n\"", ",", "\"\"", ")", "\n", "stop_word", ".", "append", "(", "sw", ".", "strip", "(", ")", ")", "\n", "sw", "=", "fr_sw", ".", "readline", "(", ")", "\n", "", "return", "stop_word", "\n", "\n"]], "home.repos.pwc.inspect_result.WHUIR_RAGE.None.DataProcess.load_vocab": [[25, 46], ["print", "codecs.open", "codecs.open.readline", "print", "fr.readline.replace", "fr.readline.split", "codecs.open.readline", "codecs.open.readline", "len", "word2id.items"], "function", ["None"], ["def", "load_vocab", "(", "vocab_path", ",", "vocab_size", ",", "PAD", "=", "0", ",", "START", "=", "1", ",", "EOS", "=", "2", ")", ":", "\n", "    ", "print", "(", "\"Load vocabulary as size %d..\"", "%", "vocab_size", ")", "\n", "word2id", "=", "{", "}", "\n", "word2id", "[", "\"PAD\"", "]", "=", "PAD", "\n", "word2id", "[", "\"START\"", "]", "=", "START", "\n", "word2id", "[", "\"EOS\"", "]", "=", "EOS", "\n", "fr", "=", "codecs", ".", "open", "(", "vocab_path", ",", "'r'", ",", "'utf-8'", ")", "\n", "index", "=", "3", "\n", "line", "=", "fr", ".", "readline", "(", ")", "\n", "while", "index", "<", "vocab_size", ":", "\n", "        ", "line", "=", "line", ".", "replace", "(", "\"\\n\"", ",", "\"\"", ")", "\n", "word", "=", "line", ".", "split", "(", "\":\"", ")", "\n", "if", "word", "[", "0", "]", "==", "\":\"", "or", "word", "[", "0", "]", "==", "\"\"", ":", "\n", "            ", "line", "=", "fr", ".", "readline", "(", ")", "\n", "continue", "\n", "", "word2id", "[", "word", "[", "0", "]", "]", "=", "index", "\n", "line", "=", "fr", ".", "readline", "(", ")", "\n", "index", "+=", "1", "\n", "", "print", "(", "\"Vocabulary size:%d\"", "%", "len", "(", "word2id", ")", ")", "\n", "id2word", "=", "{", "v", ":", "k", "for", "k", ",", "v", "in", "word2id", ".", "items", "(", ")", "}", "\n", "return", "word2id", ",", "id2word", "\n", "\n"]], "home.repos.pwc.inspect_result.WHUIR_RAGE.None.DataProcess.load_word_embedding": [[49, 86], ["print", "codecs.open", "codecs.open.readline", "codecs.open.readline", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "print", "numpy.array", "numpy.array", "emd_dict.items", "print", "fr.readline.replace", "fr.readline.split", "numpy.array", "numpy.array", "codecs.open.readline", "numpy.zeros", "numpy.zeros", "word2id.get", "range", "len", "codecs.open.readline", "word2id.keys", "codecs.open.readline", "print", "len", "len", "str", "len"], "function", ["None"], ["def", "load_word_embedding", "(", "word2id", ",", "emd_path", ",", "dimension", ")", ":", "\n", "    ", "print", "(", "\"Load Word Embedding\"", ")", "\n", "emd_dict", "=", "{", "}", "\n", "fr", "=", "codecs", ".", "open", "(", "emd_path", ",", "'r'", ",", "'utf-8'", ")", "\n", "\n", "# load vocab_size and dimension", "\n", "line", "=", "fr", ".", "readline", "(", ")", "\n", "line", "=", "fr", ".", "readline", "(", ")", "\n", "i", "=", "0", "\n", "while", "line", ":", "\n", "        ", "i", "+=", "1", "\n", "line", "=", "line", ".", "replace", "(", "\"\\n\"", ",", "\"\"", ")", "\n", "ves", "=", "line", ".", "split", "(", "\" \"", ")", "\n", "# ves[0] is word,ves[1:] is embedding", "\n", "if", "len", "(", "ves", "[", "1", ":", "]", ")", "<", "dimension", ":", "\n", "            ", "line", "=", "fr", ".", "readline", "(", ")", "\n", "continue", "\n", "", "if", "ves", "[", "0", "]", "not", "in", "word2id", ".", "keys", "(", ")", ":", "\n", "            ", "line", "=", "fr", ".", "readline", "(", ")", "\n", "continue", "\n", "", "emd_dict", "[", "ves", "[", "0", "]", "]", "=", "numpy", ".", "array", "(", "ves", "[", "1", ":", "]", ",", "dtype", "=", "\"float32\"", ")", "\n", "line", "=", "fr", ".", "readline", "(", ")", "\n", "if", "0", "==", "i", "%", "10000", ":", "\n", "            ", "print", "(", "\"%d word have been loaded....\"", "%", "i", ")", "\n", "", "", "emd_dict", "[", "\"PAD\"", "]", "=", "numpy", ".", "zeros", "(", "dimension", ",", "dtype", "=", "'float32'", ")", "\n", "emd_dict", "[", "\"START\"", "]", "=", "numpy", ".", "zeros", "(", "dimension", ",", "dtype", "=", "'float32'", ")", "\n", "emd_dict", "[", "\"EOS\"", "]", "=", "numpy", ".", "zeros", "(", "dimension", ",", "dtype", "=", "'float32'", ")", "\n", "print", "(", "\"Embedding Dictionary has been created as size:%d\"", "%", "len", "(", "emd_dict", ")", ")", "\n", "\n", "emd_mtx", "=", "numpy", ".", "array", "(", "numpy", ".", "zeros", "(", "[", "len", "(", "emd_dict", ")", ",", "dimension", "]", ")", ",", "dtype", "=", "\"float32\"", ")", "\n", "for", "key", ",", "value", "in", "emd_dict", ".", "items", "(", ")", ":", "\n", "        ", "index", "=", "word2id", ".", "get", "(", "key", ")", "\n", "vec", "=", "value", "\n", "for", "w", "in", "range", "(", "len", "(", "vec", ")", ")", ":", "\n", "            ", "emd_mtx", "[", "index", "]", "[", "w", "]", "=", "vec", "[", "w", "]", "\n", "", "", "print", "(", "\"Embedding Martix has been created as shape:\"", "+", "str", "(", "emd_mtx", ".", "shape", ")", ")", "\n", "return", "emd_dict", ",", "emd_mtx", "\n", "\n"]], "home.repos.pwc.inspect_result.WHUIR_RAGE.None.DataProcess.load_word2pos": [[89, 141], ["codecs.open", "codecs.open.readline", "print", "print", "word2id.keys", "numpy.array", "numpy.array", "wordid2posid.items", "print", "fr_word2pos.readline.replace", "fr_word2pos.readline.split", "codecs.open.readline", "len", "len", "word2id.get", "numpy.zeros", "numpy.zeros", "word2id.keys", "codecs.open.readline", "pos2id.keys", "word2pos.keys", "print", "pos2id.items", "word2pos.keys", "word2pos.get", "pos2id.get", "len"], "function", ["None"], ["def", "load_word2pos", "(", "word2id", ",", "word2pos_path", ")", ":", "\n", "    ", "pos2id", "=", "{", "}", "\n", "word2pos", "=", "{", "}", "\n", "word2pos", "[", "'PAD'", "]", "=", "\"UNK\"", "\n", "word2pos", "[", "'START'", "]", "=", "\"UNK\"", "\n", "word2pos", "[", "'EOS'", "]", "=", "\"UNK\"", "\n", "fr_word2pos", "=", "codecs", ".", "open", "(", "word2pos_path", ",", "'r'", ",", "'utf-8'", ")", "\n", "line_word2pos", "=", "fr_word2pos", ".", "readline", "(", ")", "\n", "pos_index", "=", "1", "\n", "word2pos_index", "=", "0", "\n", "while", "line_word2pos", ":", "\n", "        ", "line_word2pos", "=", "line_word2pos", ".", "replace", "(", "\"\\n\"", ",", "\"\"", ")", "\n", "columns", "=", "line_word2pos", ".", "split", "(", "\":\"", ")", "\n", "word", "=", "columns", "[", "0", "]", "\n", "pos", "=", "columns", "[", "1", "]", "\n", "word2pos_index", "+=", "1", "\n", "if", "word", "not", "in", "word2id", ".", "keys", "(", ")", ":", "\n", "            ", "line_word2pos", "=", "fr_word2pos", ".", "readline", "(", ")", "\n", "continue", "\n", "", "if", "pos", "not", "in", "pos2id", ".", "keys", "(", ")", ":", "\n", "            ", "pos2id", "[", "pos", "]", "=", "pos_index", "\n", "pos_index", "+=", "1", "\n", "", "if", "word", "not", "in", "word2pos", ".", "keys", "(", ")", ":", "\n", "            ", "word2pos", "[", "word", "]", "=", "pos", "\n", "", "if", "word2pos_index", "%", "10000", "==", "0", ":", "\n", "            ", "print", "(", "\"%d word2pos have been processed\"", "%", "word2pos_index", ")", "\n", "", "line_word2pos", "=", "fr_word2pos", ".", "readline", "(", ")", "\n", "", "print", "(", "\"word2pos size is\"", ",", "len", "(", "word2pos", ")", ")", "\n", "print", "(", "\"pos2id size is\"", ",", "len", "(", "pos2id", ")", ")", "\n", "id2pos", "=", "{", "v", ":", "k", "for", "k", ",", "v", "in", "pos2id", ".", "items", "(", ")", "}", "\n", "\n", "wordid2posid", "=", "{", "}", "\n", "nuk_num", "=", "0", "\n", "for", "word", "in", "word2id", ".", "keys", "(", ")", ":", "\n", "        ", "wordid", "=", "word2id", ".", "get", "(", "word", ")", "\n", "posid", "=", "0", "\n", "if", "word", "not", "in", "word2pos", ".", "keys", "(", ")", ":", "\n", "            ", "nuk_num", "+=", "1", "\n", "posid", "=", "0", "\n", "", "else", ":", "\n", "            ", "pos", "=", "word2pos", ".", "get", "(", "word", ")", "\n", "posid", "=", "pos2id", ".", "get", "(", "pos", ")", "\n", "", "wordid2posid", "[", "wordid", "]", "=", "posid", "\n", "", "wordid2posid", "[", "0", "]", "=", "0", "\n", "wordid2posid", "[", "1", "]", "=", "0", "\n", "wordid2posid", "[", "2", "]", "=", "0", "\n", "wordid2posid_vec", "=", "numpy", ".", "array", "(", "numpy", ".", "zeros", "(", "[", "len", "(", "wordid2posid", ")", "]", ")", ",", "dtype", "=", "\"int32\"", ")", "\n", "for", "key", ",", "value", "in", "wordid2posid", ".", "items", "(", ")", ":", "\n", "        ", "index", "=", "key", "\n", "wordid2posid_vec", "[", "index", "]", "=", "value", "\n", "", "print", "(", "\"valid vocab unknown pos num\"", ",", "nuk_num", ")", "\n", "return", "pos2id", ",", "id2pos", ",", "word2pos", ",", "wordid2posid", ",", "wordid2posid_vec", "\n", "\n"]], "home.repos.pwc.inspect_result.WHUIR_RAGE.None.DataProcess.read_QApair_withPos": [[144, 290], ["print", "codecs.open", "codecs.open.readline", "print", "print", "print", "print", "print", "print", "print", "print", "fr.readline.replace", "fr.readline.split", "qa[].split", "enc_input.append", "enc_input_pos.append", "qa[].split", "dec_gt.append", "dec_gt_pos.append", "qa[].split", "ans_in_word.append", "ans_in_pos.append", "dec_input.append", "dec_input_pos.append", "DataProcess.wordWeight", "gensim.corpora.Dictionary", "gensim.corpora.Dictionary.items", "gensim.corpora.Dictionary.id2token.items", "comments.append", "com_word_weight.append", "codecs.open.readline", "len", "codecs.open.readline", "quspos.split", "len", "len", "print", "len", "qus_word.extend", "len", "qus_pos.extend", "anspos.split", "len", "len", "print", "len", "ans_gt_word.extend", "ans_gt_word.extend", "ans_gt_word.extend", "len", "ans_gt_pos.extend", "ans_gt_pos.extend", "anspos.split", "len", "len", "print", "len", "ans_in_word.extend", "len", "ans_in_pos.extend", "dis_com.split.split", "dis_com[].split", "qa_com_list.append", "gensim.corpora.Dictionary.items", "oov_com.append", "word2id.get", "wordWeight.get", "len", "print", "com_index.extend", "len", "print", "com_weight.extend", "len", "len", "len", "len", "len", "len", "len", "len", "word2id.keys", "qus_word.append", "qus_pos.append", "word2id.keys", "ans_gt_word.append", "ans_gt_pos.append", "word2id.keys", "ans_in_word.append", "ans_in_pos.append", "word2id.keys", "word2id.get", "pos2id.get", "word2id.get", "word2id.get", "word2id.get", "pos2id.get", "len", "len", "len", "len", "len", "len", "len", "len"], "function", ["home.repos.pwc.inspect_result.WHUIR_RAGE.None.DataProcess.wordWeight"], ["def", "read_QApair_withPos", "(", "word2id", ",", "pos2id", ",", "qa_path", ",", "max_q_len", ",", "max_a_len", ",", "word_emd", ",", "stopword", ",", "max_com_vocab", "=", "100", ",", "PAD", "=", "0", ",", "START", "=", "1", ",", "EOS", "=", "2", ",", "UNK", "=", "0", ")", ":", "\n", "    ", "enc_input", "=", "[", "]", "\n", "enc_input_pos", "=", "[", "]", "\n", "dec_gt", "=", "[", "]", "\n", "dec_gt_pos", "=", "[", "]", "\n", "dec_input", "=", "[", "]", "\n", "dec_input_pos", "=", "[", "]", "\n", "comments", "=", "[", "]", "\n", "com_word_weight", "=", "[", "]", "\n", "\n", "print", "(", "\"QA processing..\"", ")", "\n", "fr", "=", "codecs", ".", "open", "(", "qa_path", ",", "'r'", ",", "'utf-8'", ")", "\n", "line", "=", "fr", ".", "readline", "(", ")", "\n", "bad_data", "=", "0", "\n", "qa_num", "=", "0", "\n", "while", "line", ":", "\n", "        ", "qa_num", "+=", "1", "\n", "line", "=", "line", ".", "replace", "(", "\"\\n\"", ",", "\"\"", ")", "\n", "qa", "=", "line", ".", "split", "(", "\"\\t\"", ")", "\n", "if", "len", "(", "qa", ")", "<", "4", ":", "\n", "            ", "bad_data", "+=", "1", "\n", "line", "=", "fr", ".", "readline", "(", ")", "\n", "continue", "\n", "# question", "\n", "", "question", "=", "qa", "[", "1", "]", ".", "split", "(", "\" \"", ")", "\n", "qus_word", "=", "[", "]", "\n", "qus_pos", "=", "[", "]", "\n", "for", "quspos", "in", "question", ":", "\n", "            ", "tmp", "=", "quspos", ".", "split", "(", "\"<pos>\"", ")", "\n", "if", "tmp", "[", "0", "]", "in", "word2id", ".", "keys", "(", ")", ":", "\n", "                ", "qus_word", ".", "append", "(", "word2id", ".", "get", "(", "tmp", "[", "0", "]", ")", ")", "\n", "qus_pos", ".", "append", "(", "pos2id", ".", "get", "(", "tmp", "[", "1", "]", ")", ")", "\n", "", "", "if", "len", "(", "qus_word", ")", "!=", "len", "(", "qus_pos", ")", ":", "\n", "            ", "print", "(", "\"qus word len is not equal with pos len\"", ")", "\n", "# truncate", "\n", "", "if", "len", "(", "qus_word", ")", ">=", "max_q_len", ":", "\n", "            ", "qus_word", "=", "qus_word", "[", "0", ":", "max_q_len", "]", "\n", "# padding", "\n", "", "else", ":", "\n", "            ", "qus_word", ".", "extend", "(", "[", "PAD", "]", "*", "(", "max_q_len", "-", "len", "(", "qus_word", ")", ")", ")", "\n", "", "enc_input", ".", "append", "(", "qus_word", ")", "\n", "\n", "if", "len", "(", "qus_pos", ")", ">=", "max_q_len", ":", "\n", "            ", "qus_pos", "=", "qus_pos", "[", "0", ":", "max_q_len", "]", "\n", "", "else", ":", "\n", "            ", "qus_pos", ".", "extend", "(", "[", "UNK", "]", "*", "(", "max_q_len", "-", "len", "(", "qus_pos", ")", ")", ")", "\n", "", "enc_input_pos", ".", "append", "(", "qus_pos", ")", "\n", "\n", "# answer", "\n", "answer_gt", "=", "qa", "[", "2", "]", ".", "split", "(", "\" \"", ")", "\n", "ans_gt_word", "=", "[", "]", "\n", "ans_gt_pos", "=", "[", "]", "\n", "for", "anspos", "in", "answer_gt", ":", "\n", "            ", "tmp", "=", "anspos", ".", "split", "(", "\"<pos>\"", ")", "\n", "if", "tmp", "[", "0", "]", "in", "word2id", ".", "keys", "(", ")", ":", "\n", "                ", "ans_gt_word", ".", "append", "(", "word2id", ".", "get", "(", "tmp", "[", "0", "]", ")", ")", "\n", "ans_gt_pos", ".", "append", "(", "word2id", ".", "get", "(", "tmp", "[", "1", "]", ")", ")", "\n", "", "", "if", "len", "(", "ans_gt_pos", ")", "!=", "len", "(", "ans_gt_word", ")", ":", "\n", "            ", "print", "(", "\"ans_gt word len is not equal with pos len\"", ")", "\n", "\n", "# add EOS and PAD", "\n", "", "if", "len", "(", "ans_gt_word", ")", ">=", "max_a_len", "-", "1", ":", "\n", "            ", "ans_gt_word", "=", "ans_gt_word", "[", "0", ":", "max_a_len", "-", "1", "]", "\n", "ans_gt_word", ".", "extend", "(", "[", "EOS", "]", ")", "\n", "", "else", ":", "\n", "            ", "ans_gt_word", ".", "extend", "(", "[", "EOS", "]", ")", "\n", "ans_gt_word", ".", "extend", "(", "[", "PAD", "]", "*", "(", "max_a_len", "-", "len", "(", "ans_gt_word", ")", ")", ")", "\n", "", "dec_gt", ".", "append", "(", "ans_gt_word", ")", "\n", "if", "len", "(", "ans_gt_pos", ")", ">=", "max_a_len", "-", "1", ":", "\n", "            ", "ans_gt_pos", "=", "ans_gt_pos", "[", "0", ":", "max_a_len", "-", "1", "]", "\n", "ans_gt_pos", ".", "extend", "(", "[", "UNK", "]", ")", "\n", "", "else", ":", "\n", "            ", "ans_gt_pos", ".", "extend", "(", "[", "UNK", "]", "*", "(", "max_a_len", "-", "len", "(", "ans_gt_pos", ")", ")", ")", "\n", "", "dec_gt_pos", ".", "append", "(", "ans_gt_pos", ")", "\n", "\n", "# add START and PAD", "\n", "answer", "=", "qa", "[", "2", "]", ".", "split", "(", "\" \"", ")", "\n", "ans_in_word", "=", "[", "]", "\n", "ans_in_pos", "=", "[", "]", "\n", "ans_in_word", ".", "append", "(", "START", ")", "\n", "ans_in_pos", ".", "append", "(", "UNK", ")", "\n", "for", "anspos", "in", "answer", ":", "\n", "            ", "tmp", "=", "anspos", ".", "split", "(", "\"<pos>\"", ")", "\n", "if", "tmp", "[", "0", "]", "in", "word2id", ".", "keys", "(", ")", ":", "\n", "                ", "ans_in_word", ".", "append", "(", "word2id", ".", "get", "(", "tmp", "[", "0", "]", ")", ")", "\n", "ans_in_pos", ".", "append", "(", "pos2id", ".", "get", "(", "tmp", "[", "1", "]", ")", ")", "\n", "", "", "if", "len", "(", "ans_in_word", ")", "!=", "len", "(", "ans_in_pos", ")", ":", "\n", "            ", "print", "(", "\"ans in word len is not equal with pos len\"", ")", "\n", "", "if", "len", "(", "ans_in_word", ")", ">=", "max_a_len", ":", "\n", "            ", "ans_in_word", "=", "ans_in_word", "[", "0", ":", "max_a_len", "]", "\n", "", "else", ":", "\n", "            ", "ans_in_word", ".", "extend", "(", "[", "PAD", "]", "*", "(", "max_a_len", "-", "len", "(", "ans_in_word", ")", ")", ")", "\n", "", "dec_input", ".", "append", "(", "ans_in_word", ")", "\n", "if", "len", "(", "ans_in_pos", ")", ">=", "max_a_len", ":", "\n", "            ", "ans_in_pos", "=", "ans_in_pos", "[", "0", ":", "max_a_len", "]", "\n", "", "else", ":", "\n", "            ", "ans_in_pos", ".", "extend", "(", "[", "UNK", "]", "*", "(", "max_a_len", "-", "len", "(", "ans_in_pos", ")", ")", ")", "\n", "", "dec_input_pos", ".", "append", "(", "ans_in_pos", ")", "\n", "\n", "# comments", "\n", "raw_com_list", "=", "qa", "[", "3", ":", "]", "\n", "qa_com_list", "=", "[", "]", "\n", "for", "dis_com", "in", "raw_com_list", ":", "\n", "            ", "if", "dis_com", "==", "\"\"", ":", "\n", "                ", "continue", "\n", "", "dis_com", "=", "dis_com", ".", "split", "(", "\"|\"", ")", "\n", "com", "=", "dis_com", "[", "1", "]", ".", "split", "(", "\" \"", ")", "\n", "qa_com_list", ".", "append", "(", "com", ")", "\n", "\n", "", "word_weight", "=", "wordWeight", "(", "word2id", ",", "qa_com_list", ",", "word_emd", ",", "stopword", ")", "\n", "com_dictionary", "=", "gensim", ".", "corpora", ".", "Dictionary", "(", "documents", "=", "qa_com_list", ")", "\n", "for", "i", ",", "t1", "in", "com_dictionary", ".", "items", "(", ")", ":", "\n", "            ", "for", "j", ",", "t2", "in", "com_dictionary", ".", "items", "(", ")", ":", "\n", "                ", "break", "\n", "", "break", "\n", "", "oov_com", "=", "[", "]", "\n", "for", "id", ",", "token", "in", "com_dictionary", ".", "id2token", ".", "items", "(", ")", ":", "\n", "            ", "if", "token", "not", "in", "word2id", ".", "keys", "(", ")", ":", "\n", "                ", "continue", "\n", "", "oov_com", ".", "append", "(", "token", ")", "\n", "", "com_index", "=", "[", "word2id", ".", "get", "(", "w", ")", "for", "w", "in", "oov_com", "]", "\n", "com_weight", "=", "[", "word_weight", ".", "get", "(", "w", ",", "0.0", ")", "for", "w", "in", "oov_com", "]", "\n", "if", "len", "(", "com_index", ")", ">=", "max_com_vocab", ":", "\n", "            ", "com_index", "=", "com_index", "[", "0", ":", "max_com_vocab", "]", "\n", "print", "(", "\"Wrong with max comments vocab\"", ")", "\n", "", "else", ":", "\n", "            ", "com_index", ".", "extend", "(", "[", "0", "]", "*", "(", "max_com_vocab", "-", "len", "(", "com_index", ")", ")", ")", "\n", "", "if", "len", "(", "com_weight", ")", ">=", "max_com_vocab", ":", "\n", "            ", "com_weight", "=", "com_weight", "[", "0", ":", "max_com_vocab", "]", "\n", "print", "(", "\"Wrong with max comments vocab\"", ")", "\n", "", "else", ":", "\n", "            ", "com_weight", ".", "extend", "(", "[", "0.0", "]", "*", "(", "max_com_vocab", "-", "len", "(", "com_weight", ")", ")", ")", "\n", "", "comments", ".", "append", "(", "com_index", ")", "\n", "com_word_weight", ".", "append", "(", "com_weight", ")", "\n", "\n", "line", "=", "fr", ".", "readline", "(", ")", "\n", "\n", "", "print", "(", "\"Question Set size:%d\"", "%", "len", "(", "enc_input", ")", ")", "\n", "print", "(", "\"Question pos Set size:%d\"", "%", "len", "(", "enc_input_pos", ")", ")", "\n", "print", "(", "\"Answer Set size:%d\"", "%", "len", "(", "dec_gt", ")", ")", "\n", "print", "(", "\"Answer pos Set size:%d\"", "%", "len", "(", "dec_gt_pos", ")", ")", "\n", "print", "(", "\"decoder input  Set:%d\"", "%", "len", "(", "dec_input", ")", ")", "\n", "print", "(", "\"decoder input  pos Set:%d\"", "%", "len", "(", "dec_input_pos", ")", ")", "\n", "print", "(", "\"Comment index size:%d\"", "%", "len", "(", "comments", ")", ")", "\n", "print", "(", "\"Comment weigth size:%d\"", "%", "len", "(", "com_word_weight", ")", ")", "\n", "return", "enc_input", ",", "enc_input_pos", ",", "dec_gt", ",", "dec_gt_pos", ",", "dec_input", ",", "dec_input_pos", ",", "comments", ",", "com_word_weight", "\n", "\n"]], "home.repos.pwc.inspect_result.WHUIR_RAGE.None.DataProcess.wordWeight": [[293, 361], ["gensim.corpora.Dictionary", "len", "len", "numpy.zeros", "gensim.corpora.Dictionary.items", "numpy.zeros", "gensim.corpora.Dictionary.id2token.items", "numpy.array", "numpy.multiply", "numpy.where", "zip", "OOV_com_list.append", "com_list.append", "gensim.corpora.Dictionary.items", "numpy.zeros", "gensim.corpora.Dictionary.doc2bow", "dictionary.doc2bow."], "function", ["None"], ["def", "wordWeight", "(", "word2id", ",", "raw_com_list", ",", "word_emd", ",", "stopword", ")", ":", "\n", "    ", "com_list", "=", "[", "]", "\n", "OOV_com_list", "=", "[", "]", "\n", "# remove OOV word", "\n", "for", "com", "in", "raw_com_list", ":", "\n", "        ", "com", "=", "[", "token", "for", "token", "in", "com", "if", "token", "in", "word2id", ".", "keys", "(", ")", "]", "\n", "OOV_com_list", ".", "append", "(", "com", ")", "\n", "# remove stop word", "\n", "", "for", "com", "in", "OOV_com_list", ":", "\n", "        ", "com", "=", "[", "token", "for", "token", "in", "com", "if", "token", "not", "in", "stopword", "]", "\n", "com_list", ".", "append", "(", "com", ")", "\n", "\n", "", "dictionary", "=", "gensim", ".", "corpora", ".", "Dictionary", "(", "documents", "=", "com_list", ")", "\n", "vocab_len", "=", "len", "(", "dictionary", ")", "\n", "nq", "=", "len", "(", "com_list", ")", "\n", "\n", "cos_matrix", "=", "np", ".", "zeros", "(", "(", "vocab_len", ",", "vocab_len", ")", ",", "dtype", "=", "'float32'", ")", "\n", "for", "i", ",", "t1", "in", "dictionary", ".", "items", "(", ")", ":", "\n", "        ", "for", "j", ",", "t2", "in", "dictionary", ".", "items", "(", ")", ":", "\n", "            ", "if", "t1", "==", "t2", ":", "\n", "                ", "continue", "\n", "", "cos_matrix", "[", "i", ",", "j", "]", "=", "0.5", "+", "0.5", "*", "np", ".", "dot", "(", "word_emd", "[", "t1", "]", ",", "word_emd", "[", "t2", "]", ")", "/", "(", "np", ".", "linalg", ".", "norm", "(", "word_emd", "[", "t1", "]", ")", "*", "np", ".", "linalg", ".", "norm", "(", "word_emd", "[", "t2", "]", ")", ")", "\n", "\n", "", "", "def", "nbow", "(", "document", ")", ":", "\n", "        ", "d", "=", "np", ".", "zeros", "(", "vocab_len", ",", "dtype", "=", "'float32'", ")", "\n", "nbow", "=", "dictionary", ".", "doc2bow", "(", "document", ")", "# Word frequencies.", "\n", "for", "idx", ",", "freq", "in", "nbow", ":", "\n", "            ", "if", "freq", "!=", "0", ":", "\n", "                ", "d", "[", "idx", "]", "=", "1", "\n", "", "", "return", "d", "\n", "\n", "# fs/nq", "\n", "", "fs", "=", "np", ".", "zeros", "(", "vocab_len", ",", "dtype", "=", "'float32'", ")", "\n", "one_hot_coms", "=", "[", "]", "\n", "for", "d", "in", "com_list", ":", "\n", "        ", "one_hot_d", "=", "nbow", "(", "d", ")", "\n", "one_hot_coms", ".", "append", "(", "one_hot_d", ")", "\n", "fs", "+=", "one_hot_d", "\n", "", "fs", "=", "fs", "/", "nq", "\n", "\n", "word2rel", "=", "[", "]", "\n", "for", "id", ",", "t", "in", "dictionary", ".", "id2token", ".", "items", "(", ")", ":", "\n", "        ", "total_rel", "=", "0.0", "\n", "for", "one_hot_com", "in", "one_hot_coms", ":", "\n", "            ", "if", "one_hot_com", "[", "id", "]", "!=", "0.0", ":", "\n", "                ", "rel", "=", "np", ".", "multiply", "(", "one_hot_com", ",", "cos_matrix", "[", "id", "]", ")", "\n", "max_id", "=", "np", ".", "where", "(", "rel", "==", "np", ".", "max", "(", "rel", ")", ")", "\n", "try", ":", "\n", "                    ", "total_rel", "+=", "rel", "[", "max_id", "]", "\n", "", "except", "ValueError", ":", "\n", "                    ", "max_id", "=", "max_id", "[", "0", "]", "[", "0", "]", "\n", "total_rel", "+=", "rel", "[", "max_id", "]", "\n", "print", "(", "\"There are more than one max similarity\"", ")", "\n", "", "", "", "word2rel", ".", "append", "(", "total_rel", "[", "0", "]", ")", "\n", "", "word2rel", "=", "np", ".", "array", "(", "word2rel", ")", "\n", "\n", "weight", "=", "np", ".", "multiply", "(", "fs", ",", "word2rel", ")", "\n", "max_weight_id", "=", "np", ".", "where", "(", "weight", "==", "np", ".", "max", "(", "weight", ")", ")", "\n", "max_weight", "=", "weight", "[", "max_weight_id", "]", "\n", "if", "max_weight", "[", "0", "]", "==", "float", "(", "\"nan\"", ")", ":", "\n", "        ", "max_weight", "[", "0", "]", "=", "1.0", "\n", "", "norm_weight", "=", "weight", "/", "max_weight", "[", "0", "]", "\n", "word_weight", "=", "{", "}", "\n", "for", "t", ",", "w", "in", "zip", "(", "dictionary", ".", "id2token", ".", "values", "(", ")", ",", "norm_weight", ")", ":", "\n", "        ", "if", "w", "==", "float", "(", "\"nan\"", ")", ":", "\n", "            ", "w", "=", "1.0", "\n", "", "word_weight", "[", "t", "]", "=", "w", "\n", "", "return", "word_weight", "\n", "\n"]], "home.repos.pwc.inspect_result.WHUIR_RAGE.None.DataProcess.SavedataSet": [[363, 371], ["codecs.open", "print", "codecs.open.write", "str"], "function", ["None"], ["", "def", "SavedataSet", "(", "dataset", ",", "output_path", ")", ":", "\n", "    ", "fout", "=", "codecs", ".", "open", "(", "output_path", ",", "'w'", ",", "'utf-8'", ")", "\n", "index", "=", "0", "\n", "for", "example", "in", "dataset", ":", "\n", "        ", "example_str", "=", "[", "str", "(", "w", ")", "for", "w", "in", "example", "]", "\n", "fout", ".", "write", "(", "\" \"", ".", "join", "(", "example_str", ")", "+", "\"\\n\"", ")", "\n", "index", "+=", "1", "\n", "", "print", "(", "\"Write Dataset size %d\"", "%", "index", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.WHUIR_RAGE.None.DataProcess.LoaddataSet": [[372, 384], ["codecs.open", "codecs.open.readline", "print", "fr.readline.replace", "fr.readline.split", "dataset.append", "codecs.open.readline", "int", "len"], "function", ["None"], ["", "def", "LoaddataSet", "(", "dataset_path", ")", ":", "\n", "    ", "fr", "=", "codecs", ".", "open", "(", "dataset_path", ",", "'r'", ",", "'utf-8'", ")", "\n", "dataset", "=", "[", "]", "\n", "line", "=", "fr", ".", "readline", "(", ")", "\n", "while", "line", ":", "\n", "        ", "line", "=", "line", ".", "replace", "(", "\"\\n\"", ",", "\"\"", ")", "\n", "example", "=", "line", ".", "split", "(", "\" \"", ")", "\n", "example_int", "=", "[", "int", "(", "w", ")", "for", "w", "in", "example", "]", "\n", "dataset", ".", "append", "(", "example_int", ")", "\n", "line", "=", "fr", ".", "readline", "(", ")", "\n", "", "print", "(", "\"Load Dataset size is %d\"", "%", "len", "(", "dataset", ")", ")", "\n", "return", "dataset", "\n", "\n"]], "home.repos.pwc.inspect_result.WHUIR_RAGE.None.DataProcess.LoaddataSetFloat": [[386, 402], ["codecs.open", "codecs.open.readline", "print", "line.replace.replace", "line.replace.split", "dataset.append", "codecs.open.readline", "print", "line.replace.replace", "print", "float", "len"], "function", ["None"], ["", "def", "LoaddataSetFloat", "(", "dataset_path", ")", ":", "\n", "    ", "fr", "=", "codecs", ".", "open", "(", "dataset_path", ",", "'r'", ",", "'utf-8'", ")", "\n", "dataset", "=", "[", "]", "\n", "line", "=", "fr", ".", "readline", "(", ")", "\n", "while", "line", ":", "\n", "        ", "line", "=", "line", ".", "replace", "(", "\"\\n\"", ",", "\"\"", ")", "\n", "if", "'nan'", "in", "line", ":", "\n", "            ", "print", "(", "\"Bad data\"", ")", "\n", "line", "=", "line", ".", "replace", "(", "\"nan\"", ",", "\"1.0\"", ")", "\n", "print", "(", "line", ")", "\n", "", "example", "=", "line", ".", "split", "(", "\" \"", ")", "\n", "example_int", "=", "[", "float", "(", "w", ")", "for", "w", "in", "example", "]", "\n", "dataset", ".", "append", "(", "example_int", ")", "\n", "line", "=", "fr", ".", "readline", "(", ")", "\n", "", "print", "(", "\"Load Dataset size is %d\"", "%", "len", "(", "dataset", ")", ")", "\n", "return", "dataset", "\n", "\n"]], "home.repos.pwc.inspect_result.WHUIR_RAGE.None.DataProcess.getposqa": [[403, 420], ["codecs.open", "codecs.open", "codecs.open.readline", "print", "fr.readline.replace", "fr.readline.split", "columns[].split", "columns[].split", "codecs.open.write", "codecs.open.readline"], "function", ["None"], ["", "def", "getposqa", "(", "data_path", ",", "out_path", ")", ":", "\n", "    ", "fr", "=", "codecs", ".", "open", "(", "data_path", ",", "'r'", ",", "'utf-8'", ")", "\n", "fout", "=", "codecs", ".", "open", "(", "out_path", ",", "'w'", ",", "'utf-8'", ")", "\n", "line", "=", "fr", ".", "readline", "(", ")", "\n", "while", "line", ":", "\n", "        ", "line", "=", "line", ".", "replace", "(", "\"\\n\"", ",", "\"\"", ")", "\n", "columns", "=", "line", ".", "split", "(", "\"\\t\"", ")", "\n", "sid", "=", "columns", "[", "0", "]", "\n", "question", "=", "columns", "[", "1", "]", ".", "split", "(", "\" \"", ")", "\n", "question", "=", "[", "w", "+", "\"<pos>n\"", "for", "w", "in", "question", "]", "\n", "answer", "=", "columns", "[", "2", "]", ".", "split", "(", "\" \"", ")", "\n", "answer", "=", "[", "w", "+", "\"<pos>n\"", "for", "w", "in", "answer", "]", "\n", "comments", "=", "columns", "[", "3", ":", "]", "\n", "line2", "=", "sid", "+", "\"\\t\"", "+", "\" \"", ".", "join", "(", "question", ")", "+", "\"\\t\"", "+", "\" \"", ".", "join", "(", "answer", ")", "+", "\"\\t\"", "+", "\"\\t\"", ".", "join", "(", "comments", ")", "+", "\"\\n\"", "\n", "fout", ".", "write", "(", "line2", ")", "\n", "line", "=", "fr", ".", "readline", "(", ")", "\n", "", "print", "(", "\"end\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.WHUIR_RAGE.contrib.rnn_cell.ExtendedMultiRNNCell.__init__": [[42, 73], ["tensorflow.contrib.rnn.MultiRNNCell.__init__"], "methods", ["home.repos.pwc.inspect_result.WHUIR_RAGE.contrib.experiment.Experiment.__init__"], ["def", "__init__", "(", "self", ",", "\n", "cells", ",", "\n", "residual_connections", "=", "False", ",", "\n", "residual_combiner", "=", "\"add\"", ",", "\n", "residual_dense", "=", "False", ")", ":", "\n", "    ", "\"\"\"Create a RNN cell composed sequentially of a number of RNNCells.\n\n    Args:\n      cells: list of RNNCells that will be composed in this order.\n      state_is_tuple: If True, accepted and returned states are n-tuples, where\n        `n = len(cells)`.  If False, the states are all\n        concatenated along the column axis.  This latter behavior will soon be\n        deprecated.\n      residual_connections: If true, add residual connections between all cells.\n        This requires all cells to have the same output_size. Also, iff the\n        input size is not equal to the cell output size, a linear transform\n        is added before the first layer.\n      residual_combiner: One of \"add\" or \"concat\". To create inputs for layer\n        t+1 either \"add\" the inputs from the prev layer or concat them.\n      residual_dense: Densely connect each layer to all other layers\n\n    Raises:\n      ValueError: if cells is empty (not allowed), or at least one of the cells\n        returns a state tuple but the flag `state_is_tuple` is `False`.\n    \"\"\"", "\n", "super", "(", "ExtendedMultiRNNCell", ",", "self", ")", ".", "__init__", "(", "cells", ",", "state_is_tuple", "=", "True", ")", "\n", "assert", "residual_combiner", "in", "[", "\"add\"", ",", "\"concat\"", ",", "\"mean\"", "]", "\n", "\n", "self", ".", "_residual_connections", "=", "residual_connections", "\n", "self", ".", "_residual_combiner", "=", "residual_combiner", "\n", "self", ".", "_residual_dense", "=", "residual_dense", "\n", "\n"]], "home.repos.pwc.inspect_result.WHUIR_RAGE.contrib.rnn_cell.ExtendedMultiRNNCell.__call__": [[74, 125], ["super().__call__", "tensorflow.variable_scope", "enumerate", "tuple", "tensorflow.python.ops.array_ops.concat", "tensorflow.contrib.layers.fully_connected", "tensorflow.variable_scope", "cell", "prev_inputs.append", "new_states.append", "tensorflow.contrib.layers.fully_connected.get_shape().as_list", "tensorflow.python.util.nest.is_sequence", "ValueError", "tensorflow.reduce_mean", "sum", "tensorflow.stack", "tensorflow.concat", "tensorflow.contrib.layers.fully_connected.get_shape", "len"], "methods", ["home.repos.pwc.inspect_result.WHUIR_RAGE.contrib.rnn_cell.ExtendedMultiRNNCell.__call__"], ["", "def", "__call__", "(", "self", ",", "inputs", ",", "state", ",", "scope", "=", "None", ")", ":", "\n", "    ", "\"\"\"Run this multi-layer cell on inputs, starting from state.\"\"\"", "\n", "if", "not", "self", ".", "_residual_connections", ":", "\n", "      ", "return", "super", "(", "ExtendedMultiRNNCell", ",", "self", ")", ".", "__call__", "(", "\n", "inputs", ",", "state", ",", "(", "scope", "or", "\"extended_multi_rnn_cell\"", ")", ")", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "scope", "or", "\"extended_multi_rnn_cell\"", ")", ":", "\n", "# Adding Residual connections are only possible when input and output", "\n", "# sizes are equal. Optionally transform the initial inputs to", "\n", "# `cell[0].output_size`", "\n", "      ", "if", "self", ".", "_cells", "[", "0", "]", ".", "output_size", "!=", "inputs", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", "[", "1", "]", "and", "(", "self", ".", "_residual_combiner", "in", "[", "\"add\"", ",", "\"mean\"", "]", ")", ":", "\n", "        ", "inputs", "=", "tf", ".", "contrib", ".", "layers", ".", "fully_connected", "(", "\n", "inputs", "=", "inputs", ",", "\n", "num_outputs", "=", "self", ".", "_cells", "[", "0", "]", ".", "output_size", ",", "\n", "activation_fn", "=", "None", ",", "\n", "scope", "=", "\"input_transform\"", ")", "\n", "\n", "# Iterate through all layers (code from MultiRNNCell)", "\n", "", "cur_inp", "=", "inputs", "\n", "prev_inputs", "=", "[", "cur_inp", "]", "\n", "new_states", "=", "[", "]", "\n", "for", "i", ",", "cell", "in", "enumerate", "(", "self", ".", "_cells", ")", ":", "\n", "        ", "with", "tf", ".", "variable_scope", "(", "\"cell_%d\"", "%", "i", ")", ":", "\n", "          ", "if", "not", "nest", ".", "is_sequence", "(", "state", ")", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "\"Expected state to be a tuple of length %d, but received: %s\"", "%", "\n", "(", "len", "(", "self", ".", "state_size", ")", ",", "state", ")", ")", "\n", "", "cur_state", "=", "state", "[", "i", "]", "\n", "next_input", ",", "new_state", "=", "cell", "(", "cur_inp", ",", "cur_state", ")", "\n", "\n", "# Either combine all previous inputs or only the current input", "\n", "input_to_combine", "=", "prev_inputs", "[", "-", "1", ":", "]", "\n", "if", "self", ".", "_residual_dense", ":", "\n", "            ", "input_to_combine", "=", "prev_inputs", "\n", "\n", "# Add Residual connection", "\n", "", "if", "self", ".", "_residual_combiner", "==", "\"add\"", ":", "\n", "            ", "next_input", "=", "next_input", "+", "sum", "(", "input_to_combine", ")", "\n", "", "if", "self", ".", "_residual_combiner", "==", "\"mean\"", ":", "\n", "            ", "combined_mean", "=", "tf", ".", "reduce_mean", "(", "tf", ".", "stack", "(", "input_to_combine", ")", ",", "0", ")", "\n", "next_input", "=", "next_input", "+", "combined_mean", "\n", "", "elif", "self", ".", "_residual_combiner", "==", "\"concat\"", ":", "\n", "            ", "next_input", "=", "tf", ".", "concat", "(", "[", "next_input", "]", "+", "input_to_combine", ",", "1", ")", "\n", "", "cur_inp", "=", "next_input", "\n", "prev_inputs", ".", "append", "(", "cur_inp", ")", "\n", "\n", "new_states", ".", "append", "(", "new_state", ")", "\n", "", "", "", "new_states", "=", "(", "tuple", "(", "new_states", ")", "\n", "if", "self", ".", "_state_is_tuple", "else", "array_ops", ".", "concat", "(", "new_states", ",", "1", ")", ")", "\n", "return", "cur_inp", ",", "new_states", "\n", "", "", ""]], "home.repos.pwc.inspect_result.WHUIR_RAGE.contrib.experiment.Experiment.__init__": [[25, 28], ["super().__init__"], "methods", ["home.repos.pwc.inspect_result.WHUIR_RAGE.contrib.experiment.Experiment.__init__"], ["def", "__init__", "(", "self", ",", "train_steps_per_iteration", "=", "None", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "    ", "super", "(", "Experiment", ",", "self", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "self", ".", "_train_steps_per_iteration", "=", "train_steps_per_iteration", "\n", "\n"]], "home.repos.pwc.inspect_result.WHUIR_RAGE.contrib.experiment.Experiment._has_training_stopped": [[29, 37], ["eval_result.get"], "methods", ["None"], ["", "def", "_has_training_stopped", "(", "self", ",", "eval_result", ")", ":", "\n", "    ", "\"\"\"Determines whether the training has stopped.\"\"\"", "\n", "if", "not", "eval_result", ":", "\n", "      ", "return", "False", "\n", "\n", "", "global_step", "=", "eval_result", ".", "get", "(", "tf", ".", "GraphKeys", ".", "GLOBAL_STEP", ")", "\n", "return", "global_step", "and", "self", ".", "_train_steps", "and", "(", "\n", "global_step", ">=", "self", ".", "_train_steps", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.WHUIR_RAGE.contrib.experiment.Experiment.continuous_train_and_eval": [[38, 115], ["ValueError", "continuous_eval_predicate_fn", "experiment.Experiment._has_training_stopped", "tensorflow.logging.info", "experiment.Experiment._estimator.fit", "tensorflow.logging.info", "experiment.Experiment._estimator.evaluate", "experiment.Experiment._maybe_export", "callable", "min", "tensorflow.logging.info"], "methods", ["home.repos.pwc.inspect_result.WHUIR_RAGE.contrib.experiment.Experiment._has_training_stopped"], ["", "def", "continuous_train_and_eval", "(", "self", ",", "\n", "continuous_eval_predicate_fn", "=", "None", ")", ":", "\n", "    ", "\"\"\"Interleaves training and evaluation.\n\n    The frequency of evaluation is controlled by the `train_steps_per_iteration`\n    (via constructor). The model will be first trained for\n    `train_steps_per_iteration`, and then be evaluated in turns.\n\n    This differs from `train_and_evaluate` as follows:\n      1. The procedure will have train and evaluation in turns. The model\n      will be trained for a number of steps (usuallly smaller than `train_steps`\n      if provided) and then be evaluated.  `train_and_evaluate` will train the\n      model for `train_steps` (no small training iteraions).\n\n      2. Due to the different approach this schedule takes, it leads to two\n      differences in resource control. First, the resources (e.g., memory) used\n      by training will be released before evaluation (`train_and_evaluate` takes\n      double resources). Second, more checkpoints will be saved as a checkpoint\n      is generated at the end of each small trainning iteration.\n\n    Args:\n      continuous_eval_predicate_fn: A predicate function determining whether to\n        continue after each iteration. `predicate_fn` takes the evaluation\n        results as its arguments. At the beginning of evaluation, the passed\n        eval results will be None so it's expected that the predicate function\n        handles that gracefully. When `predicate_fn` is not specified, this will\n        run in an infinite loop or exit when global_step reaches `train_steps`.\n\n    Returns:\n      A tuple of the result of the `evaluate` call to the `Estimator` and the\n      export results using the specified `ExportStrategy`.\n\n    Raises:\n      ValueError: if `continuous_eval_predicate_fn` is neither None nor\n        callable.\n    \"\"\"", "\n", "\n", "if", "(", "continuous_eval_predicate_fn", "is", "not", "None", "and", "\n", "not", "callable", "(", "continuous_eval_predicate_fn", ")", ")", ":", "\n", "      ", "raise", "ValueError", "(", "\n", "\"`continuous_eval_predicate_fn` must be a callable, or None.\"", ")", "\n", "\n", "", "eval_result", "=", "None", "\n", "\n", "# Set the default value for train_steps_per_iteration, which will be", "\n", "# overriden by other settings.", "\n", "train_steps_per_iteration", "=", "1000", "\n", "if", "self", ".", "_train_steps_per_iteration", "is", "not", "None", ":", "\n", "      ", "train_steps_per_iteration", "=", "self", ".", "_train_steps_per_iteration", "\n", "", "elif", "self", ".", "_train_steps", "is", "not", "None", ":", "\n", "# train_steps_per_iteration = int(self._train_steps / 10)", "\n", "      ", "train_steps_per_iteration", "=", "min", "(", "\n", "self", ".", "_min_eval_frequency", ",", "self", ".", "_train_steps", ")", "\n", "\n", "", "while", "(", "not", "continuous_eval_predicate_fn", "or", "\n", "continuous_eval_predicate_fn", "(", "eval_result", ")", ")", ":", "\n", "\n", "      ", "if", "self", ".", "_has_training_stopped", "(", "eval_result", ")", ":", "\n", "# Exits once max steps of training is satisfied.", "\n", "        ", "tf", ".", "logging", ".", "info", "(", "\"Stop training model as max steps reached\"", ")", "\n", "break", "\n", "\n", "", "tf", ".", "logging", ".", "info", "(", "\"Training model for %s steps\"", ",", "train_steps_per_iteration", ")", "\n", "self", ".", "_estimator", ".", "fit", "(", "\n", "input_fn", "=", "self", ".", "_train_input_fn", ",", "\n", "steps", "=", "train_steps_per_iteration", ",", "\n", "monitors", "=", "self", ".", "_train_monitors", ")", "\n", "\n", "tf", ".", "logging", ".", "info", "(", "\"Evaluating model now.\"", ")", "\n", "eval_result", "=", "self", ".", "_estimator", ".", "evaluate", "(", "\n", "input_fn", "=", "self", ".", "_eval_input_fn", ",", "\n", "steps", "=", "self", ".", "_eval_steps", ",", "\n", "metrics", "=", "self", ".", "_eval_metrics", ",", "\n", "name", "=", "\"one_pass\"", ",", "\n", "hooks", "=", "self", ".", "_eval_hooks", ")", "\n", "\n", "", "return", "eval_result", ",", "self", ".", "_maybe_export", "(", "eval_result", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.WHUIR_RAGE.seq2seq.decoder.Decoder.batch_size": [[84, 88], ["None"], "methods", ["None"], ["@", "property", "\n", "def", "batch_size", "(", "self", ")", ":", "\n", "    ", "\"\"\"The batch size of the inputs returned by `sample`.\"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.WHUIR_RAGE.seq2seq.decoder.Decoder.output_size": [[89, 93], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "output_size", "(", "self", ")", ":", "\n", "    ", "\"\"\"A (possibly nested tuple of...) integer[s] or `TensorShape` object[s].\"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.WHUIR_RAGE.seq2seq.decoder.Decoder.output_dtype": [[94, 98], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "output_dtype", "(", "self", ")", ":", "\n", "    ", "\"\"\"A (possibly nested tuple of...) dtype[s].\"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.WHUIR_RAGE.seq2seq.decoder.Decoder.initialize": [[99, 110], ["None"], "methods", ["None"], ["", "@", "abc", ".", "abstractmethod", "\n", "def", "initialize", "(", "self", ",", "name", "=", "None", ")", ":", "\n", "    ", "\"\"\"Called before any decoding iterations.\n\n    Args:\n      name: Name scope for any created operations.\n\n    Returns:\n      `(finished, first_inputs, initial_state)`.\n    \"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.WHUIR_RAGE.seq2seq.decoder.Decoder.step": [[111, 125], ["None"], "methods", ["None"], ["", "@", "abc", ".", "abstractmethod", "\n", "def", "step", "(", "self", ",", "time", ",", "inputs", ",", "state", ",", "context", ",", "name", "=", "None", ")", ":", "\n", "    ", "\"\"\"Called per step of decoding (but only once for dynamic decoding).\n\n    Args:\n      time: Scalar `int32` tensor.\n      inputs: Input (possibly nested tuple of) tensor[s] for this time step.\n      state: State (possibly nested tuple of) tensor[s] from previous time step.\n      name: Name scope for any created operations.\n\n    Returns:\n      `(outputs, next_state, next_inputs, finished)`.\n    \"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.WHUIR_RAGE.seq2seq.decoder._transpose_batch_time": [[50, 78], ["x.get_shape", "tensorflow.python.ops.array_ops.rank", "tensorflow.python.ops.array_ops.transpose", "array_ops.transpose.set_shape", "ValueError", "tensorflow.python.ops.array_ops.concat", "tensorflow.python.framework.tensor_shape.TensorShape().concatenate", "tensorflow.python.ops.math_ops.range", "tensorflow.python.framework.tensor_shape.TensorShape"], "function", ["None"], ["def", "_transpose_batch_time", "(", "x", ")", ":", "\n", "  ", "\"\"\"Transpose the batch and time dimensions of a Tensor.\n\n  Retains as much of the static shape information as possible.\n\n  Args:\n    x: A tensor of rank 2 or higher.\n\n  Returns:\n    x transposed along the first two dimensions.\n\n  Raises:\n    ValueError: if `x` is rank 1 or lower.\n  \"\"\"", "\n", "x_static_shape", "=", "x", ".", "get_shape", "(", ")", "\n", "if", "x_static_shape", ".", "ndims", "is", "not", "None", "and", "x_static_shape", ".", "ndims", "<", "2", ":", "\n", "    ", "raise", "ValueError", "(", "\n", "\"Expected input tensor %s to have rank at least 2, but saw shape: %s\"", "%", "\n", "(", "x", ",", "x_static_shape", ")", ")", "\n", "", "x_rank", "=", "array_ops", ".", "rank", "(", "x", ")", "\n", "x_t", "=", "array_ops", ".", "transpose", "(", "\n", "x", ",", "array_ops", ".", "concat", "(", "\n", "(", "[", "1", ",", "0", "]", ",", "math_ops", ".", "range", "(", "2", ",", "x_rank", ")", ")", ",", "axis", "=", "0", ")", ")", "\n", "x_t", ".", "set_shape", "(", "\n", "tensor_shape", ".", "TensorShape", "(", "[", "\n", "x_static_shape", "[", "1", "]", ".", "value", ",", "x_static_shape", "[", "0", "]", ".", "value", "\n", "]", ")", ".", "concatenate", "(", "x_static_shape", "[", "2", ":", "]", ")", ")", "\n", "return", "x_t", "\n", "\n"]], "home.repos.pwc.inspect_result.WHUIR_RAGE.seq2seq.decoder._create_zero_outputs": [[127, 141], ["tensorflow.python.util.nest.map_structure", "tensorflow.python.ops.array_ops.zeros", "isinstance", "tensorflow.python.framework.constant_op.constant", "tensorflow.python.ops.array_ops.concat", "tensorflow.python.framework.tensor_shape.TensorShape().as_list", "decoder._create_zero_outputs._t"], "function", ["None"], ["", "", "def", "_create_zero_outputs", "(", "size", ",", "dtype", ",", "batch_size", ")", ":", "\n", "  ", "\"\"\"Create a zero outputs Tensor structure.\"\"\"", "\n", "def", "_t", "(", "s", ")", ":", "\n", "    ", "return", "(", "s", "if", "isinstance", "(", "s", ",", "ops", ".", "Tensor", ")", "else", "constant_op", ".", "constant", "(", "\n", "tensor_shape", ".", "TensorShape", "(", "s", ")", ".", "as_list", "(", ")", ",", "\n", "dtype", "=", "dtypes", ".", "int32", ",", "\n", "name", "=", "\"zero_suffix_shape\"", ")", ")", "\n", "\n", "", "def", "_create", "(", "s", ",", "d", ")", ":", "\n", "    ", "return", "array_ops", ".", "zeros", "(", "\n", "array_ops", ".", "concat", "(", "\n", "(", "[", "batch_size", "]", ",", "_t", "(", "s", ")", ")", ",", "axis", "=", "0", ")", ",", "dtype", "=", "d", ")", "\n", "\n", "", "return", "nest", ".", "map_structure", "(", "_create", ",", "size", ",", "dtype", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.WHUIR_RAGE.seq2seq.decoder.dynamic_decode": [[143, 299], ["isinstance", "TypeError", "tensorflow.python.ops.variable_scope.variable_scope", "decoder.initialize", "decoder._create_zero_outputs", "tensorflow.python.framework.constant_op.constant", "tensorflow.python.util.nest.map_structure", "tensorflow.python.ops.control_flow_ops.while_loop", "tensorflow.python.util.nest.map_structure", "tensorflow.python.ops.variable_scope.get_variable_scope().reuse_variables", "varscope.set_caching_device", "tensorflow.python.framework.ops.convert_to_tensor", "decoder.output_size", "decoder.output_dtype", "decoder.batch_size", "tensorflow.python.ops.math_ops.logical_or", "tensorflow.python.ops.tensor_array_ops.TensorArray", "decoder.output_size", "decoder.output_dtype", "tensorflow.python.ops.math_ops.logical_not", "decoder.step", "tensorflow.python.ops.math_ops.logical_or", "tensorflow.python.util.nest.assert_same_structure", "tensorflow.python.util.nest.assert_same_structure", "tensorflow.python.util.nest.assert_same_structure", "tensorflow.python.util.nest.map_structure", "tensorflow.python.util.nest.map_structure", "type", "ValueError", "isinstance", "tensorflow.python.framework.tensor_shape.TensorShape", "tensorflow.python.framework.tensor_util.constant_value", "tensorflow.python.framework.tensor_shape.TensorShape().concatenate", "tensorflow.python.ops.math_ops.reduce_all", "tensorflow.python.ops.math_ops.logical_or", "tensorflow.python.util.nest.map_structure", "isinstance", "tensorflow.python.util.nest.map_structure", "ta.stack", "tensorflow.python.ops.variable_scope.get_variable_scope", "ops.convert_to_tensor.get_shape", "tensorflow.python.framework.ops.convert_to_tensor", "decoder.dynamic_decode._shape"], "function", ["home.repos.pwc.inspect_result.WHUIR_RAGE.seq2seq.decoder.Decoder.initialize", "home.repos.pwc.inspect_result.WHUIR_RAGE.seq2seq.decoder._create_zero_outputs", "home.repos.pwc.inspect_result.WHUIR_RAGE.seq2seq.decoder.Decoder.output_size", "home.repos.pwc.inspect_result.WHUIR_RAGE.seq2seq.decoder.Decoder.output_dtype", "home.repos.pwc.inspect_result.WHUIR_RAGE.seq2seq.decoder.Decoder.batch_size", "home.repos.pwc.inspect_result.WHUIR_RAGE.seq2seq.decoder.Decoder.output_size", "home.repos.pwc.inspect_result.WHUIR_RAGE.seq2seq.decoder.Decoder.output_dtype", "home.repos.pwc.inspect_result.WHUIR_RAGE.seq2seq.decoder.Decoder.step"], ["", "def", "dynamic_decode", "(", "decoder", ",", "\n", "wcom_emd", ",", "\n", "output_time_major", "=", "False", ",", "\n", "impute_finished", "=", "False", ",", "\n", "maximum_iterations", "=", "None", ",", "\n", "parallel_iterations", "=", "32", ",", "\n", "swap_memory", "=", "False", ",", "\n", "scope", "=", "None", ",", "\n", "scope_reuse", "=", "False", "\n", ")", ":", "\n", "  ", "\"\"\"Perform dynamic decoding with `decoder`.\n\n  Args:\n    decoder: A `Decoder` instance.\n    output_time_major: Python boolean.  Default: `False` (batch major).  If\n      `True`, outputs are returned as time major tensors (this mode is faster).\n      Otherwise, outputs are returned as batch major tensors (this adds extra\n      time to the computation).\n    impute_finished: Python boolean.  If `True`, then states for batch\n      entries which are marked as finished get copied through and the\n      corresponding outputs get zeroed out.  This causes some slowdown at\n      each time step, but ensures that the final state and outputs have\n      the correct values and that backprop ignores time steps that were\n      marked as finished.\n    maximum_iterations: `int32` scalar, maximum allowed number of decoding\n       steps.  Default is `None` (decode until the decoder is fully done).\n    parallel_iterations: Argument passed to `tf.while_loop`.\n    swap_memory: Argument passed to `tf.while_loop`.\n    scope: Optional variable scope to use.\n\n  Returns:\n    `(final_outputs, final_state)`.\n\n  Raises:\n    TypeError: if `decoder` is not an instance of `Decoder`.\n    ValueError: if maximum_iterations is provided but is not a scalar.\n  \"\"\"", "\n", "if", "not", "isinstance", "(", "decoder", ",", "Decoder", ")", ":", "\n", "    ", "raise", "TypeError", "(", "\"Expected decoder to be type Decoder, but saw: %s\"", "%", "\n", "type", "(", "decoder", ")", ")", "\n", "\n", "#TODO dynamic decode defined scope here! train has to do this too", "\n", "", "with", "variable_scope", ".", "variable_scope", "(", "scope", "or", "\"decoder\"", ",", "reuse", "=", "scope_reuse", ")", "as", "varscope", ":", "\n", "# Properly cache variable values inside the while_loop", "\n", "    ", "if", "varscope", ".", "caching_device", "is", "None", ":", "\n", "      ", "varscope", ".", "set_caching_device", "(", "lambda", "op", ":", "op", ".", "device", ")", "\n", "\n", "", "if", "maximum_iterations", "is", "not", "None", ":", "\n", "      ", "maximum_iterations", "=", "ops", ".", "convert_to_tensor", "(", "\n", "maximum_iterations", ",", "dtype", "=", "dtypes", ".", "int32", ",", "name", "=", "\"maximum_iterations\"", ")", "\n", "if", "maximum_iterations", ".", "get_shape", "(", ")", ".", "ndims", "!=", "0", ":", "\n", "        ", "raise", "ValueError", "(", "\"maximum_iterations must be a scalar\"", ")", "\n", "\n", "", "", "initial_finished", ",", "initial_inputs", ",", "initial_state", "=", "decoder", ".", "initialize", "(", ")", "\n", "\n", "zero_outputs", "=", "_create_zero_outputs", "(", "decoder", ".", "output_size", "(", ")", ",", "decoder", ".", "output_dtype", "(", ")", ",", "decoder", ".", "batch_size", "(", ")", ")", "\n", "\n", "if", "maximum_iterations", "is", "not", "None", ":", "\n", "      ", "initial_finished", "=", "math_ops", ".", "logical_or", "(", "\n", "initial_finished", ",", "0", ">=", "maximum_iterations", ")", "\n", "", "initial_time", "=", "constant_op", ".", "constant", "(", "0", ",", "dtype", "=", "dtypes", ".", "int32", ")", "\n", "\n", "def", "_shape", "(", "batch_size", ",", "from_shape", ")", ":", "\n", "      ", "if", "not", "isinstance", "(", "from_shape", ",", "tensor_shape", ".", "TensorShape", ")", ":", "\n", "        ", "return", "tensor_shape", ".", "TensorShape", "(", "None", ")", "\n", "", "else", ":", "\n", "        ", "batch_size", "=", "tensor_util", ".", "constant_value", "(", "\n", "ops", ".", "convert_to_tensor", "(", "\n", "batch_size", ",", "name", "=", "\"batch_size\"", ")", ")", "\n", "return", "tensor_shape", ".", "TensorShape", "(", "[", "batch_size", "]", ")", ".", "concatenate", "(", "from_shape", ")", "\n", "\n", "", "", "def", "_create_ta", "(", "s", ",", "d", ")", ":", "\n", "      ", "return", "tensor_array_ops", ".", "TensorArray", "(", "\n", "dtype", "=", "d", ",", "\n", "size", "=", "0", ",", "\n", "dynamic_size", "=", "True", ",", "\n", "element_shape", "=", "_shape", "(", "decoder", ".", "batch_size", "(", ")", ",", "s", ")", ")", "\n", "\n", "", "initial_outputs_ta", "=", "nest", ".", "map_structure", "(", "_create_ta", ",", "decoder", ".", "output_size", "(", ")", ",", "decoder", ".", "output_dtype", "(", ")", ")", "\n", "\n", "def", "condition", "(", "unused_time", ",", "unused_outputs_ta", ",", "unused_state", ",", "unused_inputs", ",", "\n", "finished", ",", "wcom_emd", ")", ":", "\n", "      ", "return", "math_ops", ".", "logical_not", "(", "math_ops", ".", "reduce_all", "(", "finished", ")", ")", "\n", "\n", "", "def", "body", "(", "time", ",", "outputs_ta", ",", "state", ",", "inputs", ",", "finished", ",", "wcom_emd", ")", ":", "\n", "      ", "\"\"\"Internal while_loop body.\n\n      Args:\n        time: scalar int32 tensor.\n        outputs_ta: structure of TensorArray.\n        state: (structure of) state tensors and TensorArrays.\n        inputs: (structure of) input tensors.\n        finished: 1-D bool tensor.\n\n      Returns:\n        `(time + 1, outputs_ta, next_state, next_inputs, next_finished)`.\n      \"\"\"", "\n", "(", "next_outputs", ",", "decoder_state", ",", "next_inputs", ",", "\n", "decoder_finished", ")", "=", "decoder", ".", "step", "(", "time", ",", "inputs", ",", "state", ",", "wcom_emd", ")", "\n", "next_finished", "=", "math_ops", ".", "logical_or", "(", "decoder_finished", ",", "finished", ")", "\n", "if", "maximum_iterations", "is", "not", "None", ":", "\n", "        ", "next_finished", "=", "math_ops", ".", "logical_or", "(", "\n", "next_finished", ",", "time", "+", "1", ">=", "maximum_iterations", ")", "\n", "\n", "", "nest", ".", "assert_same_structure", "(", "state", ",", "decoder_state", ")", "\n", "nest", ".", "assert_same_structure", "(", "outputs_ta", ",", "next_outputs", ")", "\n", "nest", ".", "assert_same_structure", "(", "inputs", ",", "next_inputs", ")", "\n", "\n", "# Zero out output values past finish", "\n", "if", "impute_finished", ":", "\n", "        ", "emit", "=", "nest", ".", "map_structure", "(", "\n", "lambda", "out", ",", "zero", ":", "array_ops", ".", "where", "(", "finished", ",", "zero", ",", "out", ")", ",", "\n", "next_outputs", ",", "\n", "zero_outputs", ")", "\n", "", "else", ":", "\n", "        ", "emit", "=", "next_outputs", "\n", "\n", "# Copy through states past finish", "\n", "", "def", "_maybe_copy_state", "(", "new", ",", "cur", ")", ":", "\n", "# TensorArrays and scalar states get passed through.", "\n", "        ", "if", "isinstance", "(", "cur", ",", "tensor_array_ops", ".", "TensorArray", ")", ":", "\n", "          ", "pass_through", "=", "True", "\n", "", "else", ":", "\n", "          ", "new", ".", "set_shape", "(", "cur", ".", "shape", ")", "\n", "pass_through", "=", "(", "new", ".", "shape", ".", "ndims", "==", "0", ")", "\n", "", "return", "new", "if", "pass_through", "else", "array_ops", ".", "where", "(", "finished", ",", "cur", ",", "new", ")", "\n", "\n", "", "if", "impute_finished", ":", "\n", "        ", "next_state", "=", "nest", ".", "map_structure", "(", "\n", "_maybe_copy_state", ",", "decoder_state", ",", "state", ")", "\n", "", "else", ":", "\n", "        ", "next_state", "=", "decoder_state", "\n", "\n", "", "outputs_ta", "=", "nest", ".", "map_structure", "(", "lambda", "ta", ",", "out", ":", "ta", ".", "write", "(", "time", ",", "out", ")", ",", "\n", "outputs_ta", ",", "emit", ")", "\n", "return", "(", "time", "+", "1", ",", "outputs_ta", ",", "next_state", ",", "next_inputs", ",", "next_finished", ",", "wcom_emd", ")", "\n", "\n", "", "res", "=", "control_flow_ops", ".", "while_loop", "(", "\n", "condition", ",", "\n", "body", ",", "\n", "loop_vars", "=", "[", "\n", "initial_time", ",", "initial_outputs_ta", ",", "initial_state", ",", "initial_inputs", ",", "\n", "initial_finished", ",", "wcom_emd", "\n", "]", ",", "\n", "parallel_iterations", "=", "parallel_iterations", ",", "\n", "swap_memory", "=", "swap_memory", ")", "\n", "\n", "final_outputs_ta", "=", "res", "[", "1", "]", "\n", "final_state", "=", "res", "[", "2", "]", "\n", "\n", "final_outputs", "=", "nest", ".", "map_structure", "(", "lambda", "ta", ":", "ta", ".", "stack", "(", ")", ",", "final_outputs_ta", ")", "\n", "\n", "if", "not", "output_time_major", ":", "\n", "      ", "final_outputs", "=", "nest", ".", "map_structure", "(", "_transpose_batch_time", ",", "final_outputs", ")", "\n", "", "variable_scope", ".", "get_variable_scope", "(", ")", ".", "reuse_variables", "(", ")", "\n", "return", "final_outputs", ",", "final_state", "\n", "", "", ""]]}