{"home.repos.pwc.inspect_result.Qualcomm-AI-research_FrameExit.None.inference.show_help": [[16, 72], ["print"], "function", ["None"], ["def", "show_help", "(", ")", ":", "\n", "    ", "print", "(", "\"\"\"Dataset preparation: \n            In this repository, we provide the evaluation script for two datasets: ActivityNet1.3 and Mini-kinetics. \n            You will need to first download the videos and then extract the frames as jpeg files using ffmpeg. \n            We use the following parameters to extract the frames:\n            \n            For ActivityNet1.3:\n            'format': 'image2', 'r': 1, 'qscale:v': 2, 'vf': 'scale=350:350:force_original_aspect_ratio=increase'\n            \n            For Mini-Kinetics:\n            'format': 'image2', 'r': 5, 'qscale:v': 2, 'vf': 'scale=256:256:force_original_aspect_ratio=increase'\n            \n            The data for both datasets should be structured as follows:\n            \n            |--path_frame \n              |--video1_name\n                |frame_name_0001.jpeg\n                |frame_name_0002.jpeg\n                 .\n              |--video2_name\n                |frame_name_0001.jpeg\n                |frame_name_0002.jpeg\n                 .\n                 \n            ====================================================================================================\n            \n            # Annotations:\n            For the ActivityNet1.3 download and place the following files under <data/activitynet> directory:\n            wget http://ec2-52-25-205-214.us-west-2.compute.amazonaws.com/files/activity_net.v1-3.min.json\n            wget https://raw.githubusercontent.com/antran89/ActivityNet/master/Crawler/classes.txt\n            \n            Next, Use the following script to extract the validation videos:\n            \n            > import json\n            > data = json.load(open('data/activitynet/activity_net.v1-3.min.json'))['database']\n            > with open('data/activitynet/split_val_v1.3.txt', 'w') as f:\n            >     for key, val in data.items():\n            >         if data[key]['subset'] == 'validation':\n            >             f.write('v_%s.mp4\\n' % key)\n            \n            -----------------------\n            \n            For Mini-kinetics download and place the following files under `<data/minikinetics>` directory:\n            wget https://raw.githubusercontent.com/Alvin-Zeng/GCM/master/anet_toolkit/Crawler/Kinetics/data/kinetics_val.csv\n            wget https://raw.githubusercontent.com/mengyuest/AdaFuse/master/data/kinetics/minik_classInd.txt\n            wget https://raw.githubusercontent.com/mengyuest/AdaFuse/master/data/kinetics/mini_val_videofolder.txt\n            \n            Next, Use the following script to extract the validation videos:\n            \n            > lines = [line.rsplit('/')[-1].rsplit(' ')[0]+'.mp4' for line in open('data/minikinetics/mini_val_videofolder.txt')]\n            > with open('data/minikinetics/split_val_minikinetics.txt', 'w') as f:\n            >     for line in lines:\n            >         f.write('%s\\n' % line)\n            \n            ====================================================================================================\n            \"\"\"", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.Qualcomm-AI-research_FrameExit.None.inference.inference": [[75, 146], ["utils.config.Config.load", "dataset.dataset.get_dataloader", "model.adaptive_models.ConditionalFrameExitInferenceModel", "torch.DataParallel", "torch.load", "torch.load", "nn.DataParallel.load_state_dict", "nn.DataParallel.eval", "print", "enumerate", "print", "metric.items", "numpy.histogram", "print", "print", "print", "print", "inference.show_help", "nn.DataParallel.cuda", "utils.metrics.Hitat1", "utils.metrics.AveragePrecision", "y.squeeze.squeeze", "torch.tensor", "torch.tensor", "torch.index_select", "torch.index_select", "x.to.to", "nn.DataParallel.eval", "metric.items", "print", "print", "numpy.array", "torch.no_grad", "torch.no_grad", "range", "m.update", "range", "numpy.mean", "utils.misc.map_output_transform", "utils.misc.map_output_transform", "nn.DataParallel.", "x[].unsqueeze", "exit_stats.append", "len", "numpy.nanmean", "numpy.array", "m.compute", "hist.sum", "torch.Softmax"], "function", ["home.repos.pwc.inspect_result.Qualcomm-AI-research_FrameExit.utils.config.Config.load", "home.repos.pwc.inspect_result.Qualcomm-AI-research_FrameExit.dataset.dataset.get_dataloader", "home.repos.pwc.inspect_result.Qualcomm-AI-research_FrameExit.utils.config.Config.load", "home.repos.pwc.inspect_result.Qualcomm-AI-research_FrameExit.utils.config.Config.load", "home.repos.pwc.inspect_result.Qualcomm-AI-research_FrameExit.None.inference.show_help", "home.repos.pwc.inspect_result.Qualcomm-AI-research_FrameExit.utils.metrics.AveragePrecision.update", "home.repos.pwc.inspect_result.Qualcomm-AI-research_FrameExit.utils.metrics.AveragePrecision.compute"], ["", "def", "inference", "(", "*", "config_paths", ",", "**", "kwargs", ")", ":", "\n", "# load config file", "\n", "    ", "config", "=", "Config", ".", "load", "(", "*", "config_paths", ",", "**", "kwargs", ")", "\n", "\n", "if", "config", ".", "help", ":", "\n", "        ", "show_help", "(", ")", "\n", "return", "\n", "\n", "", "num_class", "=", "config", ".", "model", ".", "num_class", "\n", "dataloader", "=", "get_dataloader", "(", "config", ".", "data", ")", "\n", "\n", "# load model", "\n", "model", "=", "ConditionalFrameExitInferenceModel", "(", "config", ")", "\n", "model", "=", "nn", ".", "DataParallel", "(", "model", ".", "cuda", "(", ")", ")", "\n", "state", "=", "torch", ".", "load", "(", "config", ".", "checkpoint", ".", "init", ")", "\n", "model", ".", "load_state_dict", "(", "state", ")", "\n", "model", ".", "eval", "(", ")", "\n", "print", "(", "\"Model loaded from: %s\"", "%", "config", ".", "checkpoint", ".", "init", ")", "\n", "\n", "# define metrics", "\n", "metric", "=", "{", "\n", "\"hit_1\"", ":", "Hitat1", "(", "\n", "output_transform", "=", "map_output_transform", "(", "video_level", "=", "True", ")", ",", "aggregation", "=", "\"mean\"", "\n", ")", ",", "\n", "\"map\"", ":", "AveragePrecision", "(", "\n", "output_transform", "=", "map_output_transform", "(", "video_level", "=", "True", ")", ",", "num_class", "=", "num_class", "\n", ")", ",", "\n", "}", "\n", "\n", "n_processed_video", "=", "0", "\n", "exit_stats", "=", "[", "]", "\n", "for", "itr", ",", "batch", "in", "enumerate", "(", "dataloader", ")", ":", "\n", "        ", "x", ",", "(", "y", ",", "metadata", ")", "=", "batch", "\n", "frame_ids", "=", "metadata", "[", "\"frame_ids\"", "]", "[", "0", "]", "\n", "y", "=", "y", ".", "squeeze", "(", "dim", "=", "1", ")", "\n", "index", "=", "torch", ".", "tensor", "(", "[", "5", ",", "0", ",", "9", ",", "2", ",", "7", ",", "4", ",", "6", ",", "3", ",", "8", ",", "1", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "x", "=", "torch", ".", "index_select", "(", "x", ",", "1", ",", "index", ")", "\n", "x", "=", "x", ".", "to", "(", "device", "=", "\"cuda\"", ")", "\n", "model", ".", "eval", "(", ")", "\n", "\n", "z_previous", "=", "None", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "for", "t", "in", "range", "(", "x", ".", "shape", "[", "1", "]", ")", ":", "\n", "                ", "y_pred", ",", "z_previous", "=", "model", "(", "x", "[", ":", ",", "t", "]", ".", "unsqueeze", "(", "dim", "=", "1", ")", ",", "z_previous", ",", "t", ")", "\n", "if", "y_pred", "is", "not", "None", ":", "# exit if true", "\n", "                    ", "exit_stats", ".", "append", "(", "t", ")", "\n", "break", "\n", "\n", "", "", "prob", "=", "nn", ".", "Softmax", "(", "dim", "=", "1", ")", "(", "y_pred", ")", ".", "detach", "(", ")", ".", "cpu", "(", ")", "\n", "\n", "# update metrics", "\n", "", "for", "k", ",", "m", "in", "metric", ".", "items", "(", ")", ":", "\n", "            ", "m", ".", "update", "(", "(", "prob", ",", "y", ",", "frame_ids", ")", ")", "\n", "\n", "", "n_processed_video", "+=", "x", ".", "shape", "[", "0", "]", "\n", "\n", "print", "(", "f\"test: iter:{itr}/{len(dataloader)}\"", ")", "\n", "\n", "", "print", "(", "\"number of processed videos: %d\"", "%", "n_processed_video", ")", "\n", "for", "name", ",", "m", "in", "metric", ".", "items", "(", ")", ":", "\n", "        ", "print", "(", "\"%s: %f\"", "%", "(", "name", ",", "np", ".", "nanmean", "(", "m", ".", "compute", "(", ")", ")", ")", ")", "\n", "\n", "", "arch_name", "=", "config", ".", "model", ".", "backbone", ".", "name", "\n", "single_frame_mac", "=", "(", "\n", "4.12", "if", "\"resnet50\"", "in", "arch_name", "else", "1.8", "if", "\"efficientnet\"", "in", "arch_name", "else", "0", "\n", ")", "\n", "hist", ",", "bin_edges", "=", "np", ".", "histogram", "(", "np", ".", "array", "(", "exit_stats", ")", ",", "bins", "=", "range", "(", "0", ",", "11", ")", ")", "\n", "print", "(", "\"Exiting statistics:\"", ")", "\n", "print", "(", "\", \"", ".", "join", "(", "\"  {:.0f}  \"", ".", "format", "(", "f", ")", "for", "f", "in", "bin_edges", "[", "1", ":", "]", ")", ")", "\n", "print", "(", "\", \"", ".", "join", "(", "\"{:.2f}%\"", ".", "format", "(", "f", ")", "for", "f", "in", "hist", "/", "hist", ".", "sum", "(", ")", "*", "100", ")", ")", "\n", "print", "(", "\"Model Mac: \"", ",", "np", ".", "mean", "(", "np", ".", "array", "(", "exit_stats", ")", "+", "1", ")", "*", "single_frame_mac", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Qualcomm-AI-research_FrameExit.utils.config.Config.__init__": [[17, 39], ["dictionary.items", "key.replace.replace.replace", "isinstance", "setattr", "config.Config"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "dictionary", ")", ":", "\n", "        ", "\"\"\"\n        Turns a dict into a namespace like config, recursively.\n\n        Parameters\n        ----------\n        dictionary : dict\n            Dictionary of configuration parameters.\n\n        Returns\n        -------\n        config : hermes.training.config.Config\n            Config instance.\n\n        \"\"\"", "\n", "for", "key", ",", "value", "in", "dictionary", ".", "items", "(", ")", ":", "\n", "            ", "key", "=", "key", ".", "replace", "(", "\"-\"", ",", "\"_\"", ")", "\n", "if", "isinstance", "(", "value", ",", "dict", ")", ":", "\n", "                ", "parsed_value", "=", "Config", "(", "value", ")", "\n", "", "else", ":", "\n", "                ", "parsed_value", "=", "value", "\n", "", "setattr", "(", "self", ",", "key", ",", "parsed_value", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Qualcomm-AI-research_FrameExit.utils.config.Config.get": [[40, 60], ["field_name.split", "getattr", "getattr().get", "getattr", "config.Config"], "methods", ["home.repos.pwc.inspect_result.Qualcomm-AI-research_FrameExit.utils.config.Config.get"], ["", "", "def", "get", "(", "self", ",", "field_name", ",", "default_value", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n\n        Parameters\n        ----------\n        field_name: str\n            field name to get (possibly nested)\n        default_value\n            value to return if the field (or any of the subfields) does not exist.\n\n        Returns\n        -------\n\n        \"\"\"", "\n", "field_name", ",", "*", "subfield_names", "=", "field_name", ".", "split", "(", "\".\"", ")", "\n", "if", "subfield_names", ":", "\n", "            ", "return", "getattr", "(", "self", ",", "field_name", ",", "Config", "(", "{", "}", ")", ")", ".", "get", "(", "\n", "\".\"", ".", "join", "(", "subfield_names", ")", ",", "default_value", "\n", ")", "\n", "", "return", "getattr", "(", "self", ",", "field_name", ",", "default_value", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Qualcomm-AI-research_FrameExit.utils.config.Config.load": [[61, 97], ["config.update", "ValueError", "print", "config.Config", "open", "yaml.load"], "methods", ["home.repos.pwc.inspect_result.Qualcomm-AI-research_FrameExit.utils.metrics.AveragePrecision.update", "home.repos.pwc.inspect_result.Qualcomm-AI-research_FrameExit.utils.config.Config.load"], ["", "@", "classmethod", "\n", "def", "load", "(", "cls", ",", "*", "filepaths", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"\n        Load config from YAML files into a namespace\n        like object called Config.\n\n        Parameters\n        ----------\n        *filepaths : str or list of str\n            List of filepaths. Order matters. Earlier\n            config will be overwritten by later config.\n        **kwargs : dict\n            Use it to manually update some entries in the config\n            files. Kwarg key has to exactly match one of the key\n            somewhere in the nested config. If multiple exact match,\n            each will be modified to the new value!\n\n\n        \"\"\"", "\n", "\n", "if", "not", "filepaths", ":", "\n", "            ", "raise", "ValueError", "(", "\"Please specify at least one or more filepaths\"", ")", "\n", "\n", "", "config", "=", "None", "\n", "for", "filepath", "in", "filepaths", ":", "\n", "            ", "print", "(", "\"Loading config @ '{}'\"", ".", "format", "(", "filepath", ")", ")", "\n", "with", "open", "(", "filepath", ",", "\"r\"", ")", "as", "handle", ":", "\n", "                ", "unparsed_config", "=", "yaml", ".", "load", "(", "handle", ",", "Loader", "=", "yaml", ".", "Loader", ")", "\n", "", "partial_config", "=", "Config", "(", "unparsed_config", ")", "\n", "if", "config", "is", "None", ":", "\n", "                ", "config", "=", "partial_config", "\n", "", "else", ":", "\n", "                ", "config", "+=", "partial_config", "\n", "\n", "", "", "config", ".", "update", "(", "**", "kwargs", ")", "\n", "return", "config", "\n", "\n"]], "home.repos.pwc.inspect_result.Qualcomm-AI-research_FrameExit.utils.config.Config.serialize": [[98, 116], ["config.Config.__dict__.items", "isinstance", "value.serialize"], "methods", ["home.repos.pwc.inspect_result.Qualcomm-AI-research_FrameExit.utils.config.Config.serialize"], ["", "def", "serialize", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Serialize the config namespace into a\n        nested dictionary.\n\n        Returns\n        -------\n        dictionary : dict\n            Dictionary of the config.\n\n        \"\"\"", "\n", "dictionary", "=", "{", "}", "\n", "for", "key", ",", "value", "in", "self", ".", "__dict__", ".", "items", "(", ")", ":", "\n", "            ", "if", "isinstance", "(", "value", ",", "Config", ")", ":", "\n", "                ", "dictionary", "[", "key", "]", "=", "value", ".", "serialize", "(", ")", "\n", "", "else", ":", "\n", "                ", "dictionary", "[", "key", "]", "=", "value", "\n", "", "", "return", "dictionary", "\n", "\n"]], "home.repos.pwc.inspect_result.Qualcomm-AI-research_FrameExit.utils.config.Config.save": [[117, 130], ["config.Config.serialize", "open", "yaml.dump"], "methods", ["home.repos.pwc.inspect_result.Qualcomm-AI-research_FrameExit.utils.config.Config.serialize"], ["", "def", "save", "(", "self", ",", "filepath", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"\n        Save the config to YAML file.\n\n        Parameters\n        ----------\n        filepath : str\n            Path where to write YAML file.\n\n        \"\"\"", "\n", "dictionary", "=", "self", ".", "serialize", "(", ")", "\n", "with", "open", "(", "filepath", ",", "\"w\"", ")", "as", "outfile", ":", "\n", "            ", "yaml", ".", "dump", "(", "dictionary", ",", "outfile", ",", "default_flow_style", "=", "False", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Qualcomm-AI-research_FrameExit.utils.config.Config.__add__": [[131, 156], ["copy.deepcopy", "other.__dict__.items", "setattr", "isinstance", "setattr", "getattr", "print", "setattr", "getattr"], "methods", ["None"], ["", "", "def", "__add__", "(", "self", ",", "other", ")", ":", "\n", "        ", "\"\"\"\n        Merge config 2 inside config 1, overwriting\n        already existing key: value pair from config 1 if\n        key: value pair exist in both. I repeat, config 2\n        overwrites config 1.\n\n        \"\"\"", "\n", "new", "=", "copy", ".", "deepcopy", "(", "self", ")", "\n", "for", "key", ",", "value", "in", "other", ".", "__dict__", ".", "items", "(", ")", ":", "\n", "            ", "if", "key", "not", "in", "self", ".", "__dict__", ":", "\n", "                ", "setattr", "(", "new", ",", "key", ",", "value", ")", "\n", "", "elif", "isinstance", "(", "value", ",", "Config", ")", ":", "\n", "# Note, this add the config `value` to self.key, and as such will invoke recursion", "\n", "                ", "setattr", "(", "new", ",", "key", ",", "getattr", "(", "self", ",", "key", ")", "+", "value", ")", "\n", "", "else", ":", "\n", "                ", "current_value", "=", "getattr", "(", "self", ",", "key", ")", "\n", "if", "current_value", "!=", "value", ":", "\n", "                    ", "print", "(", "\n", "\"  Overwriting {} from {} to {}.\"", ".", "format", "(", "\n", "key", ",", "current_value", ",", "value", "\n", ")", "\n", ")", "\n", "setattr", "(", "new", ",", "key", ",", "value", ")", "\n", "", "", "", "return", "new", "\n", "\n"]], "home.repos.pwc.inspect_result.Qualcomm-AI-research_FrameExit.utils.config.Config.update": [[157, 202], ["config.parse_hierarchical_kwargs", "parse_hierarchical_kwargs.items", "getattr", "isinstance", "config.Config.__dict__.values", "isinstance", "print", "setattr", "isinstance", "KeyError", "getattr.update", "isinstance", "getattr.update", "ValueError", "dict_value.update"], "methods", ["home.repos.pwc.inspect_result.Qualcomm-AI-research_FrameExit.utils.config.parse_hierarchical_kwargs", "home.repos.pwc.inspect_result.Qualcomm-AI-research_FrameExit.utils.metrics.AveragePrecision.update", "home.repos.pwc.inspect_result.Qualcomm-AI-research_FrameExit.utils.metrics.AveragePrecision.update", "home.repos.pwc.inspect_result.Qualcomm-AI-research_FrameExit.utils.metrics.AveragePrecision.update"], ["", "def", "update", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"\n        Update is used to update a key in the config,\n        anywhere in the nesting (has to be an exact match).\n\n        Limitations:\n          - If two keys would match exactly, both would be overwritten.\n          - Cannot create a new key.\n\n        \"\"\"", "\n", "\n", "kwargs", "=", "parse_hierarchical_kwargs", "(", "kwargs", ")", "\n", "\n", "# TODO: Raise if argument exists in duplo", "\n", "for", "key", ",", "value", "in", "kwargs", ".", "items", "(", ")", ":", "\n", "            ", "if", "key", "in", "self", ".", "__dict__", ":", "\n", "                ", "current_value", "=", "getattr", "(", "self", ",", "key", ")", "\n", "if", "isinstance", "(", "current_value", ",", "Config", ")", ":", "\n", "                    ", "if", "isinstance", "(", "value", ",", "dict", ")", ":", "\n", "                        ", "current_value", ".", "update", "(", "**", "value", ")", "\n", "", "elif", "isinstance", "(", "value", ",", "Config", ")", ":", "\n", "                        ", "current_value", ".", "update", "(", "**", "value", ".", "__dict__", ")", "\n", "", "else", ":", "\n", "                        ", "raise", "ValueError", "(", "\n", "\"Cannot overwrite the category {}.\"", ".", "format", "(", "current_value", ")", "\n", ")", "\n", "", "", "else", ":", "\n", "                    ", "print", "(", "\n", "\"  Overwriting '{}' from '{}' to '{}'.\"", ".", "format", "(", "\n", "key", ",", "current_value", ",", "value", "\n", ")", "\n", ")", "\n", "setattr", "(", "self", ",", "key", ",", "value", ")", "\n", "", "", "else", ":", "\n", "                ", "updated_any", "=", "False", "\n", "for", "dict_value", "in", "self", ".", "__dict__", ".", "values", "(", ")", ":", "\n", "                    ", "if", "isinstance", "(", "dict_value", ",", "Config", ")", ":", "\n", "                        ", "try", ":", "\n", "                            ", "dict_value", ".", "update", "(", "**", "{", "key", ":", "value", "}", ")", "\n", "", "except", "KeyError", ":", "\n", "                            ", "pass", "\n", "", "else", ":", "\n", "                            ", "updated_any", "=", "True", "\n", "", "", "", "if", "not", "updated_any", ":", "\n", "                    ", "raise", "KeyError", "(", "\"'{}' is not a key in Config\"", ".", "format", "(", "key", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Qualcomm-AI-research_FrameExit.utils.config.Config.pformat": [[203, 206], ["config.Config.serialize", "pprint.pformat"], "methods", ["home.repos.pwc.inspect_result.Qualcomm-AI-research_FrameExit.utils.config.Config.serialize", "home.repos.pwc.inspect_result.Qualcomm-AI-research_FrameExit.utils.config.Config.pformat"], ["", "", "", "", "def", "pformat", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "dictionary", "=", "self", ".", "serialize", "(", ")", "\n", "return", "pprint", ".", "pformat", "(", "dictionary", ",", "*", "args", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Qualcomm-AI-research_FrameExit.utils.config.Config.__repr__": [[207, 215], ["config.Config.pformat", "config.Config.split", "len", "len"], "methods", ["home.repos.pwc.inspect_result.Qualcomm-AI-research_FrameExit.utils.config.Config.pformat"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "cls_name", "=", "self", ".", "__class__", ".", "__name__", "\n", "prefix", "=", "cls_name", "+", "\"(\"", "\n", "postfix", "=", "\")\"", "\n", "# Format and indent the dict_str", "\n", "dict_str", "=", "self", ".", "pformat", "(", "width", "=", "80", "-", "len", "(", "prefix", ")", ")", "\n", "dict_str", "=", "(", "\"\\n\"", "+", "\" \"", "*", "len", "(", "prefix", ")", ")", ".", "join", "(", "dict_str", ".", "split", "(", "\"\\n\"", ")", ")", "\n", "return", "prefix", "+", "dict_str", "+", "postfix", "\n", "\n"]], "home.repos.pwc.inspect_result.Qualcomm-AI-research_FrameExit.utils.config.Config.__eq__": [[216, 218], ["None"], "methods", ["None"], ["", "def", "__eq__", "(", "self", ",", "other", ")", ":", "\n", "        ", "return", "self", ".", "__dict__", "==", "other", "\n", "\n"]], "home.repos.pwc.inspect_result.Qualcomm-AI-research_FrameExit.utils.config.Config.__contains__": [[219, 221], ["None"], "methods", ["None"], ["", "def", "__contains__", "(", "self", ",", "item", ")", ":", "\n", "        ", "return", "item", "in", "self", ".", "__dict__", "\n", "\n"]], "home.repos.pwc.inspect_result.Qualcomm-AI-research_FrameExit.utils.config.parse_hierarchical_kwargs": [[223, 264], ["kwargs.items", "key.split", "isinstance", "config.parse_hierarchical_kwargs"], "function", ["home.repos.pwc.inspect_result.Qualcomm-AI-research_FrameExit.utils.config.parse_hierarchical_kwargs"], ["", "", "def", "parse_hierarchical_kwargs", "(", "kwargs", ")", ":", "\n", "    ", "\"\"\"Parses a dict of kwargs by splitting the keys based on separator into\n    subdictionaries\n\n    Parameters\n    ----------\n    kwargs : dict\n        the kwargs to parse\n\n    Returns\n    -------\n    hierarchical_kwargs : dict\n\n    Example\n    -------\n    > parse_hierarchical_kwargs({'a.b.c': 2, 'a.d': 5, 'e': 10})\n    {'a': {'b': {'c': 2}, 'd': 5}, 'e': 10}\n\n\n    \"\"\"", "\n", "\n", "new_kwargs", "=", "{", "}", "\n", "\n", "for", "key", ",", "value", "in", "kwargs", ".", "items", "(", ")", ":", "\n", "        ", "k_split", "=", "key", ".", "split", "(", "\".\"", ")", "\n", "root_k", "=", "k_split", "[", "0", "]", "\n", "child_k", "=", "\".\"", ".", "join", "(", "k_split", "[", "1", ":", "]", ")", "\n", "\n", "if", "child_k", ":", "\n", "            ", "if", "root_k", "not", "in", "new_kwargs", ":", "\n", "                ", "new_kwargs", "[", "root_k", "]", "=", "{", "}", "\n", "\n", "", "new_kwargs", "[", "root_k", "]", "[", "child_k", "]", "=", "value", "\n", "", "else", ":", "\n", "            ", "new_kwargs", "[", "key", "]", "=", "value", "\n", "\n", "", "", "for", "key", "in", "new_kwargs", ":", "\n", "        ", "if", "isinstance", "(", "new_kwargs", "[", "key", "]", ",", "dict", ")", ":", "\n", "            ", "new_kwargs", "[", "key", "]", "=", "parse_hierarchical_kwargs", "(", "new_kwargs", "[", "key", "]", ")", "\n", "\n", "", "", "return", "new_kwargs", "\n", "\n"]], "home.repos.pwc.inspect_result.Qualcomm-AI-research_FrameExit.utils.config.embed_config": [[266, 268], ["config.Config.load"], "function", ["home.repos.pwc.inspect_result.Qualcomm-AI-research_FrameExit.utils.config.Config.load"], ["", "def", "embed_config", "(", "arg", ")", ":", "\n", "    ", "return", "Config", ".", "load", "(", "arg", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.Qualcomm-AI-research_FrameExit.utils.metrics.Hitat1.__init__": [[22, 36], ["ignite.metrics.Metric.__init__"], "methods", ["home.repos.pwc.inspect_result.Qualcomm-AI-research_FrameExit.model.adaptive_models.ConditionalFrameExitInferenceModel.__init__"], ["def", "__init__", "(", "\n", "self", ",", "aggregation", "=", "\"max\"", ",", "output_transform", "=", "lambda", "x", ":", "x", ",", "activation_fn", "=", "None", "\n", ")", ":", "\n", "        ", "self", ".", "predictions_dict", "=", "{", "}", "\n", "self", ".", "actuals_dict", "=", "{", "}", "\n", "self", ".", "aggregation", "=", "np", ".", "max", "if", "aggregation", "==", "\"max\"", "else", "np", ".", "mean", "\n", "self", ".", "apply_activation", "=", "(", "\n", "softmax", "\n", "if", "activation_fn", "==", "\"softmax\"", "\n", "else", "sigmoid", "\n", "if", "activation_fn", "==", "\"sigmoid\"", "\n", "else", "None", "\n", ")", "\n", "super", "(", "Hitat1", ",", "self", ")", ".", "__init__", "(", "output_transform", "=", "output_transform", ",", "device", "=", "None", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Qualcomm-AI-research_FrameExit.utils.metrics.Hitat1.reset": [[37, 40], ["None"], "methods", ["None"], ["", "def", "reset", "(", "self", ")", ":", "\n", "        ", "self", ".", "predictions_dict", "=", "{", "}", "\n", "self", ".", "actuals_dict", "=", "{", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.Qualcomm-AI-research_FrameExit.utils.metrics.Hitat1.update": [[41, 57], ["enumerate", "metrics.Hitat1.predictions_dict[].append", "metrics.Hitat1.actuals_dict[].append"], "methods", ["None"], ["", "def", "update", "(", "self", ",", "output", ",", "masks", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Parameters\n        ----------\n        # predictions is n * num_class numpy array of predictions where n is number of samples\n        # actuals is n * num_class numpy array of multihot labels where n is number of samples\n        \"\"\"", "\n", "predictions", ",", "actuals", ",", "ids", "=", "output", "\n", "\n", "for", "i", ",", "key", "in", "enumerate", "(", "ids", ")", ":", "\n", "            ", "if", "key", "in", "self", ".", "predictions_dict", ":", "\n", "                ", "self", ".", "predictions_dict", "[", "key", "]", ".", "append", "(", "predictions", "[", "i", "]", ")", "\n", "self", ".", "actuals_dict", "[", "key", "]", ".", "append", "(", "actuals", "[", "i", "]", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "predictions_dict", "[", "key", "]", "=", "[", "predictions", "[", "i", "]", "]", "\n", "self", ".", "actuals_dict", "[", "key", "]", "=", "[", "actuals", "[", "i", "]", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.Qualcomm-AI-research_FrameExit.utils.metrics.Hitat1.compute": [[58, 79], ["metrics.Hitat1.predictions_dict.keys", "numpy.stack", "numpy.stack", "numpy.any", "numpy.argmax", "numpy.average", "metrics.Hitat1.aggregation().squeeze", "numpy.stack.append", "numpy.stack.append", "keys.append", "metrics.Hitat1.apply_activation", "numpy.stack().max().squeeze", "metrics.Hitat1.aggregation", "numpy.arange", "numpy.stack", "numpy.stack().max", "numpy.stack"], "methods", ["None"], ["", "", "", "def", "compute", "(", "self", ")", ":", "\n", "        ", "preds", ",", "acts", ",", "keys", "=", "[", "]", ",", "[", "]", ",", "[", "]", "\n", "for", "key", "in", "self", ".", "predictions_dict", ".", "keys", "(", ")", ":", "\n", "            ", "pred_video", "=", "self", ".", "aggregation", "(", "\n", "np", ".", "stack", "(", "self", ".", "predictions_dict", "[", "key", "]", ")", ",", "axis", "=", "0", "\n", ")", ".", "squeeze", "(", ")", "\n", "if", "self", ".", "apply_activation", ":", "\n", "                ", "pred_video", "=", "self", ".", "apply_activation", "(", "pred_video", ")", "\n", "", "preds", ".", "append", "(", "pred_video", ")", "\n", "acts", ".", "append", "(", "np", ".", "stack", "(", "self", ".", "actuals_dict", "[", "key", "]", ")", ".", "max", "(", "axis", "=", "0", ")", ".", "squeeze", "(", ")", ")", "\n", "keys", ".", "append", "(", "key", ")", "\n", "", "preds", "=", "np", ".", "stack", "(", "preds", ")", "\n", "acts", "=", "np", ".", "stack", "(", "acts", ")", "\n", "\n", "non_negative", "=", "np", ".", "any", "(", "acts", ",", "axis", "=", "1", ")", "\n", "acts", "=", "acts", "[", "non_negative", "]", "\n", "preds", "=", "preds", "[", "non_negative", "]", "\n", "\n", "top_prediction", "=", "np", ".", "argmax", "(", "preds", ",", "1", ")", "\n", "hits", "=", "acts", "[", "np", ".", "arange", "(", "acts", ".", "shape", "[", "0", "]", ")", ",", "top_prediction", "]", "\n", "return", "np", ".", "average", "(", "hits", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Qualcomm-AI-research_FrameExit.utils.metrics.AveragePrecision.__init__": [[83, 109], ["ignite.metrics.Metric.__init__", "range", "range"], "methods", ["home.repos.pwc.inspect_result.Qualcomm-AI-research_FrameExit.model.adaptive_models.ConditionalFrameExitInferenceModel.__init__"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "num_class", "=", "1000", ",", "\n", "top_n", "=", "None", ",", "\n", "aggregation", "=", "\"max\"", ",", "\n", "filter_empty_classes", "=", "False", ",", "\n", "output_transform", "=", "lambda", "x", ":", "x", ",", "\n", "activation_fn", "=", "None", ",", "\n", ")", ":", "\n", "        ", "super", "(", "AveragePrecision", ",", "self", ")", ".", "__init__", "(", "\n", "output_transform", "=", "output_transform", ",", "device", "=", "None", "\n", ")", "\n", "self", ".", "num_class", "=", "num_class", "\n", "self", ".", "top_n", "=", "top_n", "\n", "self", ".", "filter_empty_classes", "=", "filter_empty_classes", "\n", "self", ".", "predictions", "=", "[", "[", "]", "for", "_", "in", "range", "(", "num_class", ")", "]", "\n", "self", ".", "actuals", "=", "[", "[", "]", "for", "_", "in", "range", "(", "num_class", ")", "]", "\n", "self", ".", "predictions_dict", "=", "{", "}", "\n", "self", ".", "actuals_dict", "=", "{", "}", "\n", "self", ".", "aggregation", "=", "np", ".", "max", "if", "aggregation", "==", "\"max\"", "else", "np", ".", "mean", "\n", "self", ".", "apply_activation", "=", "(", "\n", "softmax", "\n", "if", "activation_fn", "==", "\"softmax\"", "\n", "else", "sigmoid", "\n", "if", "activation_fn", "==", "\"sigmoid\"", "\n", "else", "None", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.Qualcomm-AI-research_FrameExit.utils.metrics.AveragePrecision.reset": [[111, 114], ["None"], "methods", ["None"], ["", "def", "reset", "(", "self", ")", ":", "\n", "        ", "self", ".", "predictions_dict", "=", "{", "}", "\n", "self", ".", "actuals_dict", "=", "{", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.Qualcomm-AI-research_FrameExit.utils.metrics.AveragePrecision.update": [[115, 131], ["enumerate", "metrics.AveragePrecision.predictions_dict[].append", "metrics.AveragePrecision.actuals_dict[].append"], "methods", ["None"], ["", "def", "update", "(", "self", ",", "output", ")", ":", "\n", "        ", "\"\"\"\n        Parameters\n        ----------\n        # predictions is n * num_class numpy array of predictions where n is number of samples\n        # actuals is n * num_class numpy array of multihot labels where n is number of samples\n        \"\"\"", "\n", "predictions", ",", "actuals", ",", "ids", "=", "output", "\n", "\n", "for", "i", ",", "key", "in", "enumerate", "(", "ids", ")", ":", "\n", "            ", "if", "key", "in", "self", ".", "predictions_dict", ":", "\n", "                ", "self", ".", "predictions_dict", "[", "key", "]", ".", "append", "(", "predictions", "[", "i", "]", ")", "\n", "self", ".", "actuals_dict", "[", "key", "]", ".", "append", "(", "actuals", "[", "i", "]", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "predictions_dict", "[", "key", "]", "=", "[", "predictions", "[", "i", "]", "]", "\n", "self", ".", "actuals_dict", "[", "key", "]", "=", "[", "actuals", "[", "i", "]", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.Qualcomm-AI-research_FrameExit.utils.metrics.AveragePrecision.compute": [[132, 144], ["metrics.AveragePrecision._arrange_predictions_by_class", "range", "numpy.concatenate", "numpy.concatenate", "metrics.AveragePrecision.ap", "res.append"], "methods", ["home.repos.pwc.inspect_result.Qualcomm-AI-research_FrameExit.utils.metrics.AveragePrecision._arrange_predictions_by_class", "home.repos.pwc.inspect_result.Qualcomm-AI-research_FrameExit.utils.metrics.AveragePrecision.ap"], ["", "", "", "def", "compute", "(", "self", ")", ":", "\n", "        ", "predictions", ",", "actuals", ",", "keys", "=", "self", ".", "_arrange_predictions_by_class", "(", ")", "\n", "\n", "res", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "self", ".", "num_class", ")", ":", "\n", "            ", "target", "=", "np", ".", "concatenate", "(", "actuals", "[", "i", "]", ")", "\n", "output", "=", "np", ".", "concatenate", "(", "predictions", "[", "i", "]", ")", "\n", "ap_class", ",", "num_pos", "=", "self", ".", "ap", "(", "output", ",", "target", ",", "top_n", "=", "self", ".", "top_n", ")", "\n", "if", "not", "self", ".", "filter_empty_classes", "or", "num_pos", ">", "0", ":", "\n", "                ", "res", ".", "append", "(", "ap_class", ")", "\n", "\n", "", "", "return", "res", "\n", "\n"]], "home.repos.pwc.inspect_result.Qualcomm-AI-research_FrameExit.utils.metrics.AveragePrecision._arrange_predictions_by_class": [[145, 165], ["metrics.AveragePrecision.predictions_dict.keys", "numpy.stack", "numpy.stack", "range", "metrics.AveragePrecision.aggregation().squeeze", "numpy.stack.append", "numpy.stack.append", "keys.append", "predictions[].append", "actuals[].append", "metrics.AveragePrecision.apply_activation", "numpy.stack().max().squeeze", "range", "range", "metrics.AveragePrecision.aggregation", "numpy.stack", "numpy.stack().max", "numpy.stack"], "methods", ["None"], ["", "def", "_arrange_predictions_by_class", "(", "self", ")", ":", "\n", "        ", "preds", ",", "acts", ",", "keys", "=", "[", "]", ",", "[", "]", ",", "[", "]", "\n", "for", "key", "in", "self", ".", "predictions_dict", ".", "keys", "(", ")", ":", "\n", "            ", "pred_video", "=", "self", ".", "aggregation", "(", "\n", "np", ".", "stack", "(", "self", ".", "predictions_dict", "[", "key", "]", ")", ",", "axis", "=", "0", "\n", ")", ".", "squeeze", "(", ")", "\n", "if", "self", ".", "apply_activation", ":", "\n", "                ", "pred_video", "=", "self", ".", "apply_activation", "(", "pred_video", ")", "\n", "", "preds", ".", "append", "(", "pred_video", ")", "\n", "acts", ".", "append", "(", "np", ".", "stack", "(", "self", ".", "actuals_dict", "[", "key", "]", ")", ".", "max", "(", "axis", "=", "0", ")", ".", "squeeze", "(", ")", ")", "\n", "keys", ".", "append", "(", "key", ")", "\n", "", "preds", "=", "np", ".", "stack", "(", "preds", ")", "\n", "acts", "=", "np", ".", "stack", "(", "acts", ")", "\n", "\n", "predictions", "=", "[", "[", "]", "for", "_", "in", "range", "(", "self", ".", "num_class", ")", "]", "\n", "actuals", "=", "[", "[", "]", "for", "_", "in", "range", "(", "self", ".", "num_class", ")", "]", "\n", "for", "i", "in", "range", "(", "self", ".", "num_class", ")", ":", "\n", "            ", "predictions", "[", "i", "]", ".", "append", "(", "preds", "[", ":", ",", "i", "]", ")", "\n", "actuals", "[", "i", "]", ".", "append", "(", "acts", "[", ":", ",", "i", "]", ")", "\n", "", "return", "predictions", ",", "actuals", ",", "keys", "\n", "\n"]], "home.repos.pwc.inspect_result.Qualcomm-AI-research_FrameExit.utils.metrics.AveragePrecision.ap": [[166, 182], ["actuals.sum", "actuals.sum", "numpy.argsort", "numpy.cumsum", "numpy.arange", "float", "float", "len"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "ap", "(", "predictions", ",", "actuals", ",", "top_n", "=", "None", ")", ":", "\n", "        ", "num_positive_total", "=", "actuals", ".", "sum", "(", ")", "\n", "if", "num_positive_total", "==", "0", ":", "\n", "            ", "return", "float", "(", "\"NaN\"", ")", ",", "0", "\n", "\n", "", "sorted_idx", "=", "np", ".", "argsort", "(", "predictions", ")", "[", ":", ":", "-", "1", "]", "\n", "if", "top_n", "is", "not", "None", ":", "\n", "            ", "sorted_idx", "=", "sorted_idx", "[", ":", "top_n", "]", "\n", "", "actuals", "=", "actuals", "[", "sorted_idx", "]", "\n", "num_pos", "=", "actuals", ".", "sum", "(", ")", "\n", "\n", "precisions", "=", "np", ".", "cumsum", "(", "actuals", ")", "/", "np", ".", "arange", "(", "1", ",", "len", "(", "actuals", ")", "+", "1", ")", "\n", "ap", "=", "(", "precisions", "*", "actuals", ")", ".", "sum", "(", ")", "/", "(", "float", "(", "num_pos", ")", "+", "1e-15", ")", "\n", "\n", "return", "ap", ",", "num_positive_total", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Qualcomm-AI-research_FrameExit.utils.metrics.softmax": [[8, 11], ["numpy.exp", "np.exp.sum", "numpy.max"], "function", ["None"], ["def", "softmax", "(", "logit", ")", ":", "\n", "    ", "e_x", "=", "np", ".", "exp", "(", "logit", "-", "np", ".", "max", "(", "logit", ")", ")", "\n", "return", "e_x", "/", "e_x", ".", "sum", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Qualcomm-AI-research_FrameExit.utils.metrics.sigmoid": [[13, 15], ["numpy.exp"], "function", ["None"], ["", "def", "sigmoid", "(", "logit", ")", ":", "\n", "    ", "return", "1", "/", "(", "1", "+", "np", ".", "exp", "(", "-", "logit", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Qualcomm-AI-research_FrameExit.utils.misc.map_output_transform.__init__": [[6, 8], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "video_level", "=", "False", ")", ":", "\n", "        ", "self", ".", "video_level", "=", "video_level", "\n", "\n"]], "home.repos.pwc.inspect_result.Qualcomm-AI-research_FrameExit.utils.misc.map_output_transform.__call__": [[9, 14], ["probs.squeeze", "x.rsplit"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "output", ")", ":", "\n", "        ", "probs", ",", "y_mh", ",", "ids", "=", "output", "\n", "if", "self", ".", "video_level", ":", "\n", "            ", "ids", "=", "[", "x", ".", "rsplit", "(", "\"_\"", ",", "1", ")", "[", "0", "]", "for", "x", "in", "ids", "]", "\n", "", "return", "probs", ".", "squeeze", "(", "dim", "=", "1", ")", ",", "y_mh", ",", "ids", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Qualcomm-AI-research_FrameExit.dataset.dataset.VideoLoader.__init__": [[48, 91], ["torch.Dataset.__init__", "len", "read_label_func", "dataset.VideoLoader.video_context.items", "dataset.sample_frames_uniform", "line.strip", "line.strip", "os.path.isdir", "open", "enumerate", "os.path.join", "glob.glob", "open", "len", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.Qualcomm-AI-research_FrameExit.model.adaptive_models.ConditionalFrameExitInferenceModel.__init__", "home.repos.pwc.inspect_result.Qualcomm-AI-research_FrameExit.dataset.dataset.sample_frames_uniform"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "path_split", ",", "\n", "path_frames", ",", "\n", "path_label", ",", "\n", "path_classid", ",", "\n", "read_label_func", "=", "None", ",", "\n", "clip_length", "=", "10", ",", "\n", "transform_spatial", "=", "None", ",", "\n", "transform_label", "=", "None", ",", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "path_split", "=", "path_split", "\n", "self", ".", "path_frames", "=", "path_frames", "\n", "self", ".", "path_label", "=", "path_label", "\n", "self", ".", "path_classid", "=", "path_classid", "\n", "\n", "self", ".", "transform_spatial", "=", "transform_spatial", "\n", "self", ".", "transform_label", "=", "transform_label", "\n", "self", ".", "clip_length", "=", "clip_length", "\n", "\n", "video_keys", "=", "[", "line", ".", "strip", "(", ")", "for", "line", "in", "open", "(", "path_split", ",", "\"r\"", ")", "]", "\n", "self", ".", "number_of_videos", "=", "len", "(", "video_keys", ")", "\n", "\n", "# label", "\n", "self", ".", "video_context", "=", "read_label_func", "(", "self", ".", "path_label", ")", "\n", "class_id", "=", "{", "line", ".", "strip", "(", ")", ":", "i", "for", "i", ",", "line", "in", "enumerate", "(", "open", "(", "path_classid", ",", "\"r\"", ")", ")", "}", "\n", "for", "vname", ",", "context", "in", "self", ".", "video_context", ".", "items", "(", ")", ":", "\n", "            ", "if", "vname", "in", "video_keys", ":", "\n", "                ", "self", ".", "video_context", "[", "vname", "]", "[", "\"label\"", "]", "=", "[", "\n", "class_id", "[", "line", "]", "for", "line", "in", "context", "[", "\"label\"", "]", "\n", "]", "\n", "\n", "# frame", "\n", "", "", "video_info", "=", "{", "}", "\n", "for", "vname", "in", "video_keys", ":", "\n", "            ", "if", "os", ".", "path", ".", "isdir", "(", "os", ".", "path", ".", "join", "(", "path_frames", ",", "vname", ")", ")", ":", "\n", "                ", "frame_names", "=", "glob", ".", "glob", "(", "os", ".", "path", ".", "join", "(", "path_frames", ",", "vname", ")", "+", "\"/*.jpeg\"", ")", "\n", "if", "len", "(", "frame_names", ")", ">", "0", ":", "\n", "                    ", "video_info", "[", "vname", "]", "=", "frame_names", "\n", "\n", "", "", "", "self", ".", "clip_indices", ",", "self", ".", "clip_names", "=", "sample_frames_uniform", "(", "\n", "video_info", ",", "clip_length", "=", "self", ".", "clip_length", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.Qualcomm-AI-research_FrameExit.dataset.dataset.VideoLoader.__getitem_label__": [[93, 106], ["torch.stack", "torch.stack", "torch.stack", "torch.stack", "metadata[].append", "metadata[].append", "dataset.VideoLoader.transform_label"], "methods", ["None"], ["", "def", "__getitem_label__", "(", "self", ",", "frame_list", ",", "vname", ")", ":", "\n", "        ", "metadata", "=", "{", "\"frame_ids\"", ":", "[", "]", ",", "\"labels\"", ":", "[", "]", "}", "\n", "for", "frame_name", "in", "frame_list", ":", "\n", "            ", "metadata", "[", "\"labels\"", "]", ".", "append", "(", "self", ".", "video_context", "[", "vname", "]", ")", "\n", "metadata", "[", "\"frame_ids\"", "]", ".", "append", "(", "frame_name", ")", "\n", "\n", "", "labels", "=", "metadata", "[", "\"labels\"", "]", "\n", "if", "self", ".", "transform_label", "is", "not", "None", ":", "\n", "            ", "labels", "=", "self", ".", "transform_label", "(", "labels", ")", "\n", "\n", "", "labels", "=", "torch", ".", "stack", "(", "labels", ")", "\n", "\n", "return", "labels", ",", "metadata", "\n", "\n"]], "home.repos.pwc.inspect_result.Qualcomm-AI-research_FrameExit.dataset.dataset.VideoLoader.__getitem__": [[107, 123], ["torch.stack", "torch.stack", "torch.stack", "torch.stack", "dataset.VideoLoader.__getitem_label__", "PIL.Image.open", "dataset.VideoLoader.append", "dataset.VideoLoader.transform_spatial"], "methods", ["home.repos.pwc.inspect_result.Qualcomm-AI-research_FrameExit.dataset.dataset.VideoLoader.__getitem_label__"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "frame_list", "=", "self", ".", "clip_indices", "[", "index", "]", "\n", "video_name", "=", "self", ".", "clip_names", "[", "index", "]", "\n", "\n", "clip", "=", "[", "]", "\n", "for", "frame_name", "in", "frame_list", ":", "\n", "            ", "frame", "=", "Image", ".", "open", "(", "frame_name", ")", "\n", "clip", ".", "append", "(", "frame", ")", "\n", "\n", "", "if", "self", ".", "transform_spatial", "is", "not", "None", ":", "\n", "            ", "clip", "=", "self", ".", "transform_spatial", "(", "clip", ")", "\n", "\n", "", "clip", "=", "torch", ".", "stack", "(", "clip", ")", "\n", "label", ",", "metadata", "=", "self", ".", "__getitem_label__", "(", "frame_list", ",", "video_name", ")", "\n", "\n", "return", "clip", ",", "(", "label", ",", "metadata", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Qualcomm-AI-research_FrameExit.dataset.dataset.VideoLoader.__len__": [[124, 126], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "clip_indices", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Qualcomm-AI-research_FrameExit.dataset.dataset.get_dataloader": [[16, 45], ["dataset.transform.__get_transforms", "dataset.VideoLoader", "torch.utils.data.DataLoader"], "function", ["home.repos.pwc.inspect_result.Qualcomm-AI-research_FrameExit.dataset.transform.__get_transforms"], ["def", "get_dataloader", "(", "c_data", ")", ":", "\n", "    ", "tfs_spatial", ",", "tfs_label", "=", "__get_transforms", "(", "c_data", ")", "\n", "\n", "read_label_func", "=", "None", "\n", "if", "c_data", ".", "name", "==", "\"activitynet1.3\"", ":", "\n", "        ", "read_label_func", "=", "read_label_activitynet", "\n", "", "elif", "c_data", ".", "name", "==", "\"minikinetics\"", ":", "\n", "        ", "read_label_func", "=", "read_label_minikinetics", "\n", "\n", "", "dataset", "=", "VideoLoader", "(", "\n", "c_data", ".", "path_split", ",", "\n", "c_data", ".", "path_frame", ",", "\n", "c_data", ".", "path_label", ",", "\n", "c_data", ".", "path_classid", ",", "\n", "read_label_func", "=", "read_label_func", ",", "\n", "transform_spatial", "=", "tfs_spatial", ",", "\n", "transform_label", "=", "tfs_label", ",", "\n", "clip_length", "=", "c_data", ".", "num_frames", ",", "\n", ")", "\n", "\n", "dataloader", "=", "DataLoader", "(", "\n", "dataset", ",", "\n", "pin_memory", "=", "True", ",", "\n", "batch_size", "=", "1", ",", "\n", "shuffle", "=", "c_data", ".", "shuffle", ",", "\n", "num_workers", "=", "c_data", ".", "num_workers", ",", "\n", ")", "\n", "\n", "return", "dataloader", "\n", "\n"]], "home.repos.pwc.inspect_result.Qualcomm-AI-research_FrameExit.dataset.dataset.sample_frames_uniform": [[128, 147], ["sorted", "video_indices.items", "numpy.array", "len", "numpy.clip().astype", "video_frames[].tolist", "splits.append", "split_names.append", "sorted", "numpy.clip", "numpy.linspace"], "function", ["None"], ["", "", "def", "sample_frames_uniform", "(", "video_indices", ",", "clip_length", ")", ":", "\n", "    ", "\"\"\"\n    selects one clip of length clip_length uniformly from a video\n    \"\"\"", "\n", "splits", ",", "split_names", "=", "[", "]", ",", "[", "]", "\n", "for", "video_name", ",", "frame_list", "in", "sorted", "(", "video_indices", ".", "items", "(", ")", ")", ":", "\n", "        ", "video_frames", "=", "np", ".", "array", "(", "sorted", "(", "frame_list", ")", ")", "\n", "video_length", "=", "len", "(", "video_frames", ")", "\n", "\n", "indices", "=", "np", ".", "clip", "(", "\n", "np", ".", "linspace", "(", "0", ",", "video_length", ",", "clip_length", ")", ",", "0", ",", "video_length", "-", "1", "\n", ")", ".", "astype", "(", "\"int\"", ")", "\n", "\n", "split", "=", "video_frames", "[", "indices", "]", ".", "tolist", "(", ")", "\n", "\n", "splits", ".", "append", "(", "split", ")", "\n", "split_names", ".", "append", "(", "video_name", ")", "\n", "\n", "", "return", "splits", ",", "split_names", "\n", "\n"]], "home.repos.pwc.inspect_result.Qualcomm-AI-research_FrameExit.dataset.dataset.read_label_activitynet": [[149, 164], ["json.load.items", "open", "json.load"], "function", ["home.repos.pwc.inspect_result.Qualcomm-AI-research_FrameExit.utils.config.Config.load"], ["", "def", "read_label_activitynet", "(", "path_labelfile", ")", ":", "\n", "# read label file", "\n", "    ", "with", "open", "(", "path_labelfile", ")", "as", "json_file", ":", "\n", "        ", "dataset", "=", "json", ".", "load", "(", "json_file", ")", "\n", "", "dataset", "=", "dataset", "[", "\"database\"", "]", "\n", "\n", "metadata", "=", "{", "}", "\n", "for", "key", ",", "val", "in", "dataset", ".", "items", "(", ")", ":", "\n", "        ", "vkey", "=", "\"v_%s.mp4\"", "%", "key", "\n", "labels", "=", "[", "ann", "[", "\"label\"", "]", "for", "ann", "in", "dataset", "[", "key", "]", "[", "\"annotations\"", "]", "]", "\n", "segments", "=", "[", "ann", "[", "\"segment\"", "]", "for", "ann", "in", "dataset", "[", "key", "]", "[", "\"annotations\"", "]", "]", "\n", "cur_cntx", "=", "{", "\"label\"", ":", "labels", ",", "\"segment\"", ":", "segments", ",", "\"set\"", ":", "dataset", "[", "key", "]", "[", "\"subset\"", "]", "}", "\n", "metadata", "[", "vkey", "]", "=", "cur_cntx", "\n", "\n", "", "return", "metadata", "\n", "\n"]], "home.repos.pwc.inspect_result.Qualcomm-AI-research_FrameExit.dataset.dataset.read_label_minikinetics": [[166, 184], ["enumerate", "line.strip().split", "x.strip", "open", "line.strip", "[].zfill", "[].zfill", "b.split", "e.split"], "function", ["None"], ["", "def", "read_label_minikinetics", "(", "path_labelfile", ")", ":", "\n", "# [1:] to skip csv header", "\n", "    ", "data", "=", "[", "x", ".", "strip", "(", ")", "for", "x", "in", "open", "(", "path_labelfile", ",", "\"r\"", ")", "]", "[", "1", ":", "]", "\n", "\n", "metadata", "=", "{", "}", "\n", "for", "i", ",", "line", "in", "enumerate", "(", "data", ")", ":", "\n", "        ", "label", ",", "ytname", ",", "b", ",", "e", ",", "split", ",", "cc", "=", "line", ".", "strip", "(", ")", ".", "split", "(", "\",\"", ")", "\n", "if", "label", "[", "0", "]", "==", "'\"'", ":", "\n", "            ", "label", "=", "label", "[", "1", ":", "-", "1", "]", "\n", "", "vkey", "=", "\"%s_%s_%s.mp4\"", "%", "(", "\n", "ytname", ",", "\n", "b", ".", "split", "(", "\".\"", ")", "[", "0", "]", ".", "zfill", "(", "6", ")", ",", "\n", "e", ".", "split", "(", "\".\"", ")", "[", "0", "]", ".", "zfill", "(", "6", ")", ",", "\n", ")", "\n", "cur_cntx", "=", "{", "\"label\"", ":", "[", "label", "]", ",", "\"cc\"", ":", "cc", "}", "\n", "metadata", "[", "vkey", "]", "=", "cur_cntx", "\n", "\n", "", "return", "metadata", "\n", "", ""]], "home.repos.pwc.inspect_result.Qualcomm-AI-research_FrameExit.dataset.transform.Resize.__init__": [[82, 88], ["isinstance", "len"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "size", ",", "method", "=", "\"bilinear\"", ")", ":", "\n", "        ", "assert", "isinstance", "(", "size", ",", "int", ")", "or", "len", "(", "size", ")", "==", "2", "\n", "assert", "method", "in", "[", "\"bilinear\"", ",", "\"nearest\"", "]", "\n", "\n", "self", ".", "size", "=", "size", "\n", "self", ".", "method", "=", "method", "\n", "\n"]], "home.repos.pwc.inspect_result.Qualcomm-AI-research_FrameExit.dataset.transform.Resize.__call__": [[89, 106], ["isinstance", "isinstance", "transform.Resize.__tensor_call__", "torchvision.resize"], "methods", ["home.repos.pwc.inspect_result.Qualcomm-AI-research_FrameExit.dataset.transform.RandomCrop.__tensor_call__"], ["", "def", "__call__", "(", "self", ",", "img", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            img (PIL Image or torch.Tensor): Image to be scaled.\n\n        Returns:\n            PIL Image or torch.Tensor: Rescaled image.\n        \"\"\"", "\n", "assert", "isinstance", "(", "img", ",", "(", "torch", ".", "Tensor", ",", "Image", ".", "Image", ")", ")", "\n", "\n", "if", "isinstance", "(", "img", ",", "torch", ".", "Tensor", ")", ":", "\n", "            ", "return", "self", ".", "__tensor_call__", "(", "img", ",", "self", ".", "method", ")", "\n", "", "else", ":", "\n", "            ", "return", "TF", ".", "resize", "(", "\n", "img", ",", "\n", "self", ".", "size", ",", "\n", "Image", ".", "BILINEAR", "if", "self", ".", "method", "==", "\"bilinear\"", "else", "Image", ".", "NEAREST", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.Qualcomm-AI-research_FrameExit.dataset.transform.Resize.__tensor_call__": [[108, 131], ["isinstance", "tensor.size", "int", "int", "torch.interpolate", "torch.interpolate", "torch.interpolate", "torch.interpolate", "torch.interpolate", "torch.interpolate", "tensor.unsqueeze", "tensor.unsqueeze", "tensor.unsqueeze"], "methods", ["None"], ["", "", "def", "__tensor_call__", "(", "self", ",", "tensor", ",", "method", "=", "\"bilinear\"", ")", ":", "\n", "        ", "if", "isinstance", "(", "self", ".", "size", ",", "int", ")", ":", "\n", "            ", "c", ",", "h", ",", "w", "=", "tensor", ".", "size", "(", ")", "\n", "assert", "c", "==", "3", "\n", "if", "(", "w", "<=", "h", "and", "w", "==", "self", ".", "size", ")", "or", "(", "h", "<=", "w", "and", "h", "==", "self", ".", "size", ")", ":", "\n", "                ", "return", "tensor", "\n", "", "if", "w", "<", "h", ":", "\n", "                ", "ow", "=", "self", ".", "size", "\n", "oh", "=", "int", "(", "self", ".", "size", "*", "h", "/", "w", ")", "\n", "return", "F", ".", "interpolate", "(", "\n", "tensor", ".", "unsqueeze", "(", "0", ")", ",", "(", "oh", ",", "ow", ")", ",", "mode", "=", "method", ",", "align_corners", "=", "False", "\n", ")", "[", "0", "]", "\n", "", "else", ":", "\n", "                ", "oh", "=", "self", ".", "size", "\n", "ow", "=", "int", "(", "self", ".", "size", "*", "w", "/", "h", ")", "\n", "return", "F", ".", "interpolate", "(", "\n", "tensor", ".", "unsqueeze", "(", "0", ")", ",", "(", "oh", ",", "ow", ")", ",", "mode", "=", "method", ",", "align_corners", "=", "False", "\n", ")", "[", "0", "]", "\n", "", "", "else", ":", "\n", "            ", "oh", ",", "ow", "=", "self", ".", "size", "\n", "return", "F", ".", "interpolate", "(", "\n", "tensor", ".", "unsqueeze", "(", "0", ")", ",", "(", "oh", ",", "ow", ")", ",", "mode", "=", "method", ",", "align_corners", "=", "False", "\n", ")", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.Qualcomm-AI-research_FrameExit.dataset.transform.Resize.__repr__": [[132, 135], ["None"], "methods", ["None"], ["", "", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "__class__", ".", "__name__", "+", "\"(size={0}, method={1})\"", ".", "format", "(", "\n", "self", ".", "size", ",", "self", ".", "method", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.Qualcomm-AI-research_FrameExit.dataset.transform.CenterCrop.__init__": [[147, 150], ["isinstance", "len"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "size", ")", ":", "\n", "        ", "assert", "isinstance", "(", "size", ",", "int", ")", "or", "len", "(", "size", ")", "==", "2", "\n", "self", ".", "size", "=", "size", "\n", "\n"]], "home.repos.pwc.inspect_result.Qualcomm-AI-research_FrameExit.dataset.transform.CenterCrop.__call__": [[151, 166], ["isinstance", "isinstance", "transform.CenterCrop.__tenosr_call__", "torchvision.center_crop"], "methods", ["home.repos.pwc.inspect_result.Qualcomm-AI-research_FrameExit.dataset.transform.CenterCrop.__tenosr_call__"], ["", "def", "__call__", "(", "self", ",", "img", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            img (PIL Image or torch.Tensor): Image to be cropped.\n\n        Returns:\n            img (PIL Image or torch.Tensor): Cropped image.\n        \"\"\"", "\n", "\n", "assert", "isinstance", "(", "img", ",", "(", "torch", ".", "Tensor", ",", "Image", ".", "Image", ")", ")", "\n", "\n", "if", "isinstance", "(", "img", ",", "torch", ".", "Tensor", ")", ":", "\n", "            ", "return", "self", ".", "__tenosr_call__", "(", "img", ")", "\n", "", "else", ":", "\n", "            ", "return", "TF", ".", "center_crop", "(", "img", ",", "self", ".", "size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Qualcomm-AI-research_FrameExit.dataset.transform.CenterCrop.__tenosr_call__": [[167, 181], ["isinstance", "tensor.size", "int", "int", "tuple", "round", "round"], "methods", ["None"], ["", "", "def", "__tenosr_call__", "(", "self", ",", "tensor", ")", ":", "\n", "        ", "if", "isinstance", "(", "self", ".", "size", ",", "int", ")", ":", "\n", "            ", "output_size", "=", "(", "self", ".", "size", ",", "self", ".", "size", ")", "\n", "", "else", ":", "\n", "            ", "output_size", "=", "tuple", "(", "self", ".", "size", ")", "\n", "\n", "", "c", ",", "h", ",", "w", "=", "tensor", ".", "size", "(", ")", "\n", "assert", "c", "==", "3", "\n", "\n", "th", ",", "tw", "=", "output_size", "\n", "i", "=", "int", "(", "round", "(", "(", "h", "-", "th", ")", "/", "2.0", ")", ")", "\n", "j", "=", "int", "(", "round", "(", "(", "w", "-", "tw", ")", "/", "2.0", ")", ")", "\n", "\n", "return", "tensor", "[", ":", ",", "i", ":", "i", "+", "th", ",", "j", ":", "j", "+", "tw", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.Qualcomm-AI-research_FrameExit.dataset.transform.CenterCrop.__repr__": [[182, 184], ["None"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "__class__", ".", "__name__", "+", "\"(size={0})\"", ".", "format", "(", "self", ".", "size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Qualcomm-AI-research_FrameExit.dataset.transform.ApplyImageTransform.__init__": [[191, 197], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "transform", ")", ":", "\n", "        ", "\"\"\"\n        :param transform: a transform object from \"torchvision.transforms.transforms.*\" such as Resize or GrayScale\n\n        \"\"\"", "\n", "self", ".", "transform", "=", "transform", "\n", "\n"]], "home.repos.pwc.inspect_result.Qualcomm-AI-research_FrameExit.dataset.transform.ApplyImageTransform.__call__": [[198, 211], ["transform.ApplyImageTransform.transform"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "frames", ")", ":", "\n", "        ", "\"\"\"\n        Parameters\n        ----------\n        frames: list of frames in PIL.Image or numpy.ndarray format\n\n        Returns\n        -------\n        List of transformed frames\n\n        \"\"\"", "\n", "transformed", "=", "[", "self", ".", "transform", "(", "frame", ")", "for", "frame", "in", "frames", "]", "\n", "return", "transformed", "\n", "\n"]], "home.repos.pwc.inspect_result.Qualcomm-AI-research_FrameExit.dataset.transform.ApplyImageTransform.__repr__": [[212, 214], ["None"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "return", "\"{}({})\"", ".", "format", "(", "self", ".", "__class__", ".", "__name__", ",", "self", ".", "transform", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Qualcomm-AI-research_FrameExit.dataset.transform.RandomCrop.__init__": [[221, 230], ["isinstance"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "size", ")", ":", "\n", "        ", "\"\"\"\n\n        Parameters\n        ----------\n        size: crop size in format (h, w)\n        \"\"\"", "\n", "\n", "self", ".", "size", "=", "(", "size", ",", "size", ")", "if", "isinstance", "(", "size", ",", "int", ")", "else", "size", "\n", "\n"]], "home.repos.pwc.inspect_result.Qualcomm-AI-research_FrameExit.dataset.transform.RandomCrop.__call__": [[231, 265], ["isinstance", "isinstance", "transform.RandomCrop.__tensor_call__", "isinstance", "random.randint", "random.randint", "isinstance", "frame.crop", "PIL.Image.fromarray", "numpy.asarray"], "methods", ["home.repos.pwc.inspect_result.Qualcomm-AI-research_FrameExit.dataset.transform.RandomCrop.__tensor_call__"], ["", "def", "__call__", "(", "self", ",", "frames", ")", ":", "\n", "        ", "\"\"\"\n\n        Parameters\n        ----------\n        frames list of frames in PIL.Image or numpy.ndarray format (HxWxC)\n\n        Returns\n        -------\n        List of cropped frames in the same format as input (PIL.Image or numpy.ndarray)\n\n        \"\"\"", "\n", "\n", "assert", "isinstance", "(", "frames", "[", "0", "]", ",", "(", "torch", ".", "Tensor", ",", "Image", ".", "Image", ",", "np", ".", "ndarray", ")", ")", "\n", "\n", "if", "isinstance", "(", "frames", "[", "0", "]", ",", "torch", ".", "Tensor", ")", ":", "\n", "            ", "return", "self", ".", "__tensor_call__", "(", "frames", ")", "\n", "", "else", ":", "\n", "            ", "crop_h", ",", "crop_w", "=", "self", ".", "size", "\n", "if", "isinstance", "(", "frames", "[", "0", "]", ",", "np", ".", "ndarray", ")", ":", "\n", "                ", "frames", "=", "[", "Image", ".", "fromarray", "(", "frame", ")", "for", "frame", "in", "frames", "]", "\n", "\n", "", "frame_w", ",", "frame_h", "=", "frames", "[", "0", "]", ".", "size", "\n", "crop_left", "=", "random", ".", "randint", "(", "0", ",", "frame_w", "-", "crop_w", ")", "\n", "crop_top", "=", "random", ".", "randint", "(", "0", ",", "frame_h", "-", "crop_h", ")", "\n", "transformed", "=", "[", "\n", "frame", ".", "crop", "(", "(", "crop_left", ",", "crop_top", ",", "crop_left", "+", "crop_w", ",", "crop_top", "+", "crop_h", ")", ")", "\n", "for", "frame", "in", "frames", "\n", "]", "\n", "\n", "if", "isinstance", "(", "frames", "[", "0", "]", ",", "np", ".", "ndarray", ")", ":", "\n", "                ", "transformed", "=", "[", "np", ".", "asarray", "(", "x", ")", "for", "x", "in", "transformed", "]", "\n", "\n", "", "return", "transformed", "\n", "\n"]], "home.repos.pwc.inspect_result.Qualcomm-AI-research_FrameExit.dataset.transform.RandomCrop.__tensor_call__": [[266, 286], ["frames[].size", "random.randint", "random.randint", "frames[].size", "frames[].size", "transform.ApplyImageTransform", "transform.ApplyImageTransform", "transform.Resize", "transform.Resize"], "methods", ["None"], ["", "", "def", "__tensor_call__", "(", "self", ",", "frames", ")", ":", "\n", "        ", "c", ",", "h", ",", "w", "=", "frames", "[", "0", "]", ".", "size", "(", ")", "\n", "assert", "c", "==", "3", "\n", "\n", "crop_h", ",", "crop_w", "=", "self", ".", "size", "\n", "if", "crop_w", ">", "w", ":", "\n", "            ", "frames", "=", "ApplyImageTransform", "(", "Resize", "(", "size", "=", "crop_w", ")", ")", "(", "frames", ")", "\n", "c", ",", "h", ",", "w", "=", "frames", "[", "0", "]", ".", "size", "(", ")", "\n", "\n", "", "if", "crop_h", ">", "h", ":", "\n", "            ", "frames", "=", "ApplyImageTransform", "(", "Resize", "(", "size", "=", "crop_h", ")", ")", "(", "frames", ")", "\n", "c", ",", "h", ",", "w", "=", "frames", "[", "0", "]", ".", "size", "(", ")", "\n", "\n", "", "left", "=", "random", ".", "randint", "(", "0", ",", "w", "-", "crop_w", ")", "\n", "top", "=", "random", ".", "randint", "(", "0", ",", "h", "-", "crop_h", ")", "\n", "\n", "transformed", "=", "[", "\n", "frame", "[", ":", ",", "top", ":", "top", "+", "crop_h", ",", "left", ":", "left", "+", "crop_w", "]", "for", "frame", "in", "frames", "\n", "]", "\n", "return", "transformed", "\n", "\n"]], "home.repos.pwc.inspect_result.Qualcomm-AI-research_FrameExit.dataset.transform.RandomCrop.__repr__": [[287, 289], ["None"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "return", "\"{}({})\"", ".", "format", "(", "self", ".", "__class__", ".", "__name__", ",", "self", ".", "size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Qualcomm-AI-research_FrameExit.dataset.transform.MultiHotEmbedding.__init__": [[296, 299], ["object.__init__"], "methods", ["home.repos.pwc.inspect_result.Qualcomm-AI-research_FrameExit.model.adaptive_models.ConditionalFrameExitInferenceModel.__init__"], ["def", "__init__", "(", "self", ",", "num_classes", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "num_classes", "=", "num_classes", "\n", "\n"]], "home.repos.pwc.inspect_result.Qualcomm-AI-research_FrameExit.dataset.transform.MultiHotEmbedding.__call__": [[300, 315], ["torch.zeros().scatter", "torch.zeros().scatter", "torch.zeros().scatter", "torch.zeros().scatter", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "label", ":", "list", ")", ":", "\n", "        ", "\"\"\"\n        Parameters\n        ----------\n        label: list\n            list of class indices to be embedded\n\n        Returns\n        ----------\n         torch.tensor: label tensor of length num_classes, where each element from label list is one-hot embedded\n        ----------\n        \"\"\"", "\n", "\n", "return", "torch", ".", "zeros", "(", "self", ".", "num_classes", ")", ".", "scatter", "(", "\n", "0", ",", "torch", ".", "tensor", "(", "label", ",", "dtype", "=", "torch", ".", "long", ")", ",", "torch", ".", "tensor", "(", "1", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.Qualcomm-AI-research_FrameExit.dataset.transform.MultiHotEmbedding.__repr__": [[317, 319], ["None"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "__class__", ".", "__name__", "+", "f\"for {self.num_classes} classes\"", "\n", "\n"]], "home.repos.pwc.inspect_result.Qualcomm-AI-research_FrameExit.dataset.transform.VideoMultiHotLabels.__init__": [[327, 329], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.Qualcomm-AI-research_FrameExit.dataset.transform.VideoMultiHotLabels.__call__": [[330, 333], ["None"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "context", ":", "dict", ")", ":", "\n", "        ", "labels", "=", "context", "[", "0", "]", "[", "\"label\"", "]", "\n", "return", "[", "labels", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.Qualcomm-AI-research_FrameExit.dataset.transform.LabelMapping.__init__": [[340, 344], ["int", "int", "open", "line.strip().split", "line.strip().split", "line.strip", "line.strip"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "mapping_path", ")", ":", "\n", "        ", "self", ".", "mapper", "=", "{", "\n", "int", "(", "line", ".", "strip", "(", ")", ".", "split", "(", "\" \"", ")", "[", "0", "]", ")", ":", "int", "(", "line", ".", "strip", "(", ")", ".", "split", "(", "\" \"", ")", "[", "1", "]", ")", "\n", "for", "line", "in", "open", "(", "mapping_path", ")", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.Qualcomm-AI-research_FrameExit.dataset.transform.LabelMapping.__call__": [[346, 349], ["None"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "label", ")", ":", "\n", "        ", "label", "=", "[", "self", ".", "mapper", "[", "line", "]", "for", "line", "in", "label", "]", "\n", "return", "label", "\n", "\n"]], "home.repos.pwc.inspect_result.Qualcomm-AI-research_FrameExit.dataset.transform.LabelMapping.__repr__": [[350, 352], ["None"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "return", "\"{}\"", ".", "format", "(", "self", ".", "__class__", ".", "__name__", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Qualcomm-AI-research_FrameExit.dataset.transform.__get_transforms_data_spatial": [[14, 42], ["vars", "torchvision.transforms.Compose", "transform.ApplyImageTransform", "transform.Resize", "transform.ApplyImageTransform", "transform.CenterCrop", "transform.RandomCrop", "transform.ApplyImageTransform", "Exception", "torchvision.transforms.ToTensor", "transform.ApplyImageTransform", "torchvision.transforms.Normalize"], "function", ["None"], ["def", "__get_transforms_data_spatial", "(", "c_preprocessing", ")", ":", "\n", "    ", "tfs", "=", "[", "]", "\n", "for", "preprocess", "in", "vars", "(", "c_preprocessing", ")", ":", "\n", "        ", "if", "preprocess", "==", "\"resize\"", ":", "\n", "            ", "tfs", "+=", "[", "ApplyImageTransform", "(", "Resize", "(", "c_preprocessing", ".", "resize", ")", ")", "]", "\n", "\n", "", "elif", "preprocess", "==", "\"crop_center\"", ":", "\n", "            ", "tfs", "+=", "[", "ApplyImageTransform", "(", "CenterCrop", "(", "c_preprocessing", ".", "crop_center", ")", ")", "]", "\n", "\n", "", "elif", "preprocess", "==", "\"crop_random\"", ":", "\n", "            ", "tfs", "+=", "[", "RandomCrop", "(", "c_preprocessing", ".", "crop_random", ")", "]", "\n", "\n", "", "elif", "preprocess", "==", "\"to_tensor\"", ":", "\n", "            ", "tfs", "+=", "[", "ApplyImageTransform", "(", "ToTensor", "(", ")", ")", "]", "\n", "\n", "", "elif", "preprocess", "==", "\"normalize\"", ":", "\n", "            ", "tfs", "+=", "[", "\n", "ApplyImageTransform", "(", "\n", "Normalize", "(", "\n", "c_preprocessing", ".", "normalize", ".", "mean", ",", "c_preprocessing", ".", "normalize", ".", "std", "\n", ")", "\n", ")", "\n", "]", "\n", "\n", "", "else", ":", "\n", "            ", "raise", "Exception", "(", "\"data pre-processing {} is unknown\"", ".", "format", "(", "preprocess", ")", ")", "\n", "\n", "", "", "return", "Compose", "(", "tfs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Qualcomm-AI-research_FrameExit.dataset.transform.__get_transforms_label": [[44, 62], ["vars", "torchvision.transforms.Compose", "transform.VideoMultiHotLabels", "transform.ApplyImageTransform", "Exception", "transform.MultiHotEmbedding", "transform.ApplyImageTransform", "transform.LabelMapping"], "function", ["None"], ["", "def", "__get_transforms_label", "(", "c_preprocessing", ")", ":", "\n", "    ", "tfs", "=", "[", "]", "\n", "for", "preprocess", "in", "vars", "(", "c_preprocessing", ")", ":", "\n", "        ", "if", "preprocess", "==", "\"video_multihot_labels\"", ":", "\n", "            ", "tfs", "+=", "[", "VideoMultiHotLabels", "(", ")", "]", "\n", "\n", "", "elif", "preprocess", "==", "\"one_hot_encoding\"", ":", "\n", "            ", "tfs", "+=", "[", "\n", "ApplyImageTransform", "(", "MultiHotEmbedding", "(", "c_preprocessing", ".", "one_hot_encoding", ")", ")", "\n", "]", "\n", "\n", "", "elif", "preprocess", "==", "\"mapping\"", ":", "\n", "            ", "tfs", "+=", "[", "ApplyImageTransform", "(", "LabelMapping", "(", "c_preprocessing", ".", "mapping", ")", ")", "]", "\n", "\n", "", "else", ":", "\n", "            ", "raise", "Exception", "(", "\"label pre-processing {} is unknown\"", ".", "format", "(", "preprocess", ")", ")", "\n", "\n", "", "", "return", "Compose", "(", "tfs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Qualcomm-AI-research_FrameExit.dataset.transform.__get_transforms": [[64, 69], ["transform.__get_transforms_data_spatial", "transform.__get_transforms_label"], "function", ["home.repos.pwc.inspect_result.Qualcomm-AI-research_FrameExit.dataset.transform.__get_transforms_data_spatial", "home.repos.pwc.inspect_result.Qualcomm-AI-research_FrameExit.dataset.transform.__get_transforms_label"], ["", "def", "__get_transforms", "(", "c_data", ")", ":", "\n", "    ", "tfs_spatial", "=", "__get_transforms_data_spatial", "(", "c_data", ".", "preprocessing", ")", "\n", "tfs_label", "=", "__get_transforms_label", "(", "c_data", ".", "preprocessing_label", ")", "\n", "\n", "return", "tfs_spatial", ",", "tfs_label", "\n", "\n"]], "home.repos.pwc.inspect_result.Qualcomm-AI-research_FrameExit.model.adaptive_models.MaxPooling.__init__": [[13, 15], ["super().__init__"], "methods", ["home.repos.pwc.inspect_result.Qualcomm-AI-research_FrameExit.model.adaptive_models.ConditionalFrameExitInferenceModel.__init__"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Qualcomm-AI-research_FrameExit.model.adaptive_models.MaxPooling.forward": [[16, 20], ["torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat.max", "torch.cat.max", "torch.cat.max", "torch.cat.unsqueeze", "torch.cat.unsqueeze", "torch.cat.unsqueeze", "y.unsqueeze"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "y", ")", ":", "\n", "        ", "x", "=", "torch", ".", "cat", "(", "(", "x", ".", "unsqueeze", "(", "dim", "=", "1", ")", ",", "y", ".", "unsqueeze", "(", "dim", "=", "1", ")", ")", ",", "dim", "=", "1", ")", "\n", "\n", "return", "x", ".", "max", "(", "dim", "=", "1", ")", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.Qualcomm-AI-research_FrameExit.model.adaptive_models.MultiLayerPerceptron.__init__": [[32, 46], ["torch.Module.__init__", "torch.Sequential", "torch.Sequential", "torch.Sequential", "layers.append", "layers.append", "layers.append", "torch.Linear", "torch.Linear", "torch.Linear", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.ReLU", "torch.ReLU", "torch.ReLU"], "methods", ["home.repos.pwc.inspect_result.Qualcomm-AI-research_FrameExit.model.adaptive_models.ConditionalFrameExitInferenceModel.__init__"], ["    ", "def", "__init__", "(", "self", ",", "input_dim", ",", "num_neurons", "=", "4096", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "input_dim", "=", "input_dim", "\n", "self", ".", "num_neurons", "=", "[", "num_neurons", "]", "\n", "\n", "layers", "=", "[", "]", "\n", "dim_input", "=", "input_dim", "\n", "for", "dim_output", "in", "self", ".", "num_neurons", ":", "\n", "            ", "layers", ".", "append", "(", "nn", ".", "Linear", "(", "dim_input", ",", "dim_output", ")", ")", "\n", "layers", ".", "append", "(", "nn", ".", "BatchNorm1d", "(", "dim_output", ")", ")", "\n", "layers", ".", "append", "(", "nn", ".", "ReLU", "(", ")", ")", "\n", "dim_input", "=", "dim_output", "\n", "\n", "", "self", ".", "layers", "=", "nn", ".", "Sequential", "(", "*", "layers", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Qualcomm-AI-research_FrameExit.model.adaptive_models.MultiLayerPerceptron.forward": [[47, 51], ["adaptive_models.MultiLayerPerceptron.layers"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "layers", "(", "x", ")", "\n", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.Qualcomm-AI-research_FrameExit.model.adaptive_models.ExitingGate.__init__": [[101, 110], ["torch.Module.__init__", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.Sigmoid", "torch.Sigmoid", "torch.Sigmoid", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.Qualcomm-AI-research_FrameExit.model.adaptive_models.ConditionalFrameExitInferenceModel.__init__"], ["    ", "def", "__init__", "(", "self", ",", "in_planes", ")", ":", "\n", "        ", "super", "(", "ExitingGate", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "relu", "=", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", "\n", "self", ".", "conv1", "=", "nn", ".", "Conv2d", "(", "in_planes", ",", "128", ",", "kernel_size", "=", "1", ",", "stride", "=", "1", ",", "bias", "=", "True", ")", "\n", "self", ".", "conv2", "=", "nn", ".", "Conv2d", "(", "128", ",", "64", ",", "kernel_size", "=", "1", ",", "stride", "=", "1", ",", "bias", "=", "True", ")", "\n", "self", ".", "bn1", "=", "nn", ".", "BatchNorm2d", "(", "128", ")", "\n", "self", ".", "bn2", "=", "nn", ".", "BatchNorm2d", "(", "64", ")", "\n", "self", ".", "sigmoid", "=", "nn", ".", "Sigmoid", "(", ")", "\n", "self", ".", "linear", "=", "nn", ".", "Linear", "(", "128", ",", "1", ",", "bias", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Qualcomm-AI-research_FrameExit.model.adaptive_models.ExitingGate.forward": [[111, 126], ["torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "adaptive_models.ExitingGate.linear", "adaptive_models.ExitingGate.sigmoid", "adaptive_models.ExitingGate.bn1", "adaptive_models.ExitingGate.bn2", "adaptive_models.ExitingGate.bn1", "adaptive_models.ExitingGate.bn2", "adaptive_models.ExitingGate.conv1", "adaptive_models.ExitingGate.conv2", "adaptive_models.ExitingGate.conv1", "adaptive_models.ExitingGate.conv2"], "methods", ["home.repos.pwc.inspect_result.Qualcomm-AI-research_FrameExit.utils.metrics.sigmoid"], ["", "def", "forward", "(", "self", ",", "x", ",", "force_hard", "=", "True", ",", "prev_features", "=", "None", ")", ":", "\n", "        ", "x0", ",", "x1", "=", "x", "[", "0", "]", ",", "x", "[", "1", "]", "\n", "x0", "=", "F", ".", "relu", "(", "self", ".", "bn1", "(", "self", ".", "conv1", "(", "x0", ")", ")", ")", "\n", "x0", "=", "F", ".", "relu", "(", "self", ".", "bn2", "(", "self", ".", "conv2", "(", "x0", ")", ")", ")", "\n", "x0", "=", "torch", ".", "flatten", "(", "x0", ",", "1", ")", "\n", "x1", "=", "F", ".", "relu", "(", "self", ".", "bn1", "(", "self", ".", "conv1", "(", "x1", ")", ")", ")", "\n", "x1", "=", "F", ".", "relu", "(", "self", ".", "bn2", "(", "self", ".", "conv2", "(", "x1", ")", ")", ")", "\n", "x1", "=", "torch", ".", "flatten", "(", "x1", ",", "1", ")", "\n", "x", "=", "torch", ".", "cat", "(", "[", "x0", ",", "x1", "]", ",", "dim", "=", "1", ")", "\n", "out", "=", "self", ".", "linear", "(", "x", ")", "\n", "out", "=", "self", ".", "sigmoid", "(", "out", ")", "\n", "out", "[", "out", ">=", "0.5", "]", "=", "1", "\n", "out", "[", "out", "<", "0.5", "]", "=", "0", "\n", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.Qualcomm-AI-research_FrameExit.model.adaptive_models.AdaptiveBase.__init__": [[129, 147], ["torch.Module.__init__", "adaptive_models.get_base_model", "adaptive_models.MultiLayerPerceptron", "torch.AdaptiveAvgPool2d", "torch.AdaptiveAvgPool2d", "torch.AdaptiveAvgPool2d"], "methods", ["home.repos.pwc.inspect_result.Qualcomm-AI-research_FrameExit.model.adaptive_models.ConditionalFrameExitInferenceModel.__init__", "home.repos.pwc.inspect_result.Qualcomm-AI-research_FrameExit.model.adaptive_models.get_base_model"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "backbone_type", "=", "config", ".", "model", ".", "backbone", ".", "type", "\n", "self", ".", "backbone_name", "=", "config", ".", "model", ".", "backbone", ".", "name", "\n", "\n", "# base model", "\n", "self", ".", "backbone", "=", "get_base_model", "(", "config", ".", "model", ".", "backbone", ".", "name", ",", "config", ")", "\n", "model_output_dim", "=", "config", ".", "model", ".", "backbone", ".", "output_dim", "\n", "\n", "# fully connected layer", "\n", "num_neurons", "=", "4096", "\n", "self", ".", "mlp", "=", "MultiLayerPerceptron", "(", "\n", "input_dim", "=", "model_output_dim", ",", "num_neurons", "=", "num_neurons", "\n", ")", "\n", "self", ".", "model_output_dim", "=", "num_neurons", "\n", "\n", "self", ".", "avg_pool_2d", "=", "nn", ".", "AdaptiveAvgPool2d", "(", "(", "1", ",", "1", ")", ")", "# in case of frame as input", "\n", "self", ".", "num_frames", "=", "config", ".", "data", ".", "num_frames", "\n", "\n"]], "home.repos.pwc.inspect_result.Qualcomm-AI-research_FrameExit.model.adaptive_models.AdaptiveBase.forward": [[148, 175], ["adaptive_models.AdaptiveBase.size", "adaptive_models.AdaptiveBase.size", "adaptive_models.AdaptiveBase.view", "adaptive_models.AdaptiveBase.backbone", "adaptive_models.AdaptiveBase.view", "adaptive_models.AdaptiveBase.flatten", "adaptive_models.AdaptiveBase.view", "adaptive_models.AdaptiveBase.mlp", "adaptive_models.AdaptiveBase.view", "len", "adaptive_models.AdaptiveBase.avg_pool_2d", "numpy.prod", "adaptive_models.AdaptiveBase.size", "adaptive_models.AdaptiveBase.size", "adaptive_models.AdaptiveBase.size"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "b", "=", "x", ".", "size", "(", "0", ")", "\n", "seq_len", "=", "x", ".", "size", "(", "1", ")", "\n", "\n", "# Mix batch and T", "\n", "x", "=", "x", ".", "view", "(", "(", "b", "*", "seq_len", ",", ")", "+", "x", ".", "size", "(", ")", "[", "2", ":", "]", ")", "\n", "\n", "x", "=", "self", ".", "backbone", "(", "x", ")", "\n", "\n", "# separate batch and T", "\n", "if", "len", "(", "x", ".", "shape", ")", ">", "2", ":", "\n", "            ", "x", "=", "self", ".", "avg_pool_2d", "(", "x", ")", "# remove spatial dim", "\n", "", "x", "=", "x", ".", "view", "(", "\n", "(", "\n", "b", ",", "\n", "seq_len", ",", "\n", ")", "\n", "+", "x", ".", "size", "(", ")", "[", "1", ":", "]", "\n", ")", "\n", "x", "=", "x", ".", "flatten", "(", "start_dim", "=", "2", ")", "\n", "\n", "# fc layer", "\n", "x", "=", "x", ".", "view", "(", "b", "*", "seq_len", ",", "np", ".", "prod", "(", "x", ".", "size", "(", ")", "[", "2", ":", "]", ")", ")", "\n", "x", "=", "self", ".", "mlp", "(", "x", ")", "\n", "x", "=", "x", ".", "view", "(", "b", ",", "seq_len", ",", "-", "1", ")", "\n", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.Qualcomm-AI-research_FrameExit.model.adaptive_models.ConditionalFrameExitInferenceModel.__init__": [[185, 199], ["adaptive_models.AdaptiveBase.__init__", "adaptive_models.MaxPooling", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "range", "adaptive_models.ConditionalFrameExitInferenceModel.classifiers.append", "torch.Linear", "torch.Linear", "torch.Linear", "adaptive_models.ConditionalFrameExitInferenceModel.exit_selector.append", "adaptive_models.ExitingGate"], "methods", ["home.repos.pwc.inspect_result.Qualcomm-AI-research_FrameExit.model.adaptive_models.ConditionalFrameExitInferenceModel.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "num_frames", "=", "config", ".", "data", ".", "num_frames", "\n", "self", ".", "num_class", "=", "config", ".", "model", ".", "num_class", "\n", "self", ".", "first_threshold", "=", "config", ".", "model", ".", "first_threshold", "\n", "self", ".", "max_pooling", "=", "MaxPooling", "(", ")", "\n", "self", ".", "exit_selector", "=", "nn", ".", "ModuleList", "(", ")", "\n", "self", ".", "exit_door", "=", "None", "\n", "self", ".", "exited_classifiers", "=", "None", "\n", "self", ".", "classifiers", "=", "nn", ".", "ModuleList", "(", ")", "\n", "for", "m", "in", "range", "(", "self", ".", "num_frames", ")", ":", "\n", "            ", "self", ".", "classifiers", ".", "append", "(", "nn", ".", "Linear", "(", "self", ".", "model_output_dim", ",", "self", ".", "num_class", ")", ")", "\n", "if", "m", ">", "0", ":", "\n", "                ", "self", ".", "exit_selector", ".", "append", "(", "ExitingGate", "(", "4096", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Qualcomm-AI-research_FrameExit.model.adaptive_models.ConditionalFrameExitInferenceModel.gate_selection": [[200, 204], ["adaptive_models.execute_exiting"], "methods", ["home.repos.pwc.inspect_result.Qualcomm-AI-research_FrameExit.model.adaptive_models.execute_exiting"], ["", "", "", "def", "gate_selection", "(", "self", ",", "idx", ",", "y_t", ")", ":", "\n", "        ", "exit_door", "=", "execute_exiting", "(", "self", ".", "exit_selector", "[", "idx", "]", ",", "y_t", ")", "\n", "\n", "return", "True", "if", "exit_door", "[", "0", "]", "==", "0", "else", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.Qualcomm-AI-research_FrameExit.model.adaptive_models.ConditionalFrameExitInferenceModel.forward": [[205, 237], ["torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "adaptive_models.AdaptiveBase.forward", "torch.flatten.squeeze", "torch.flatten.squeeze", "torch.flatten.squeeze", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "adaptive_models.ConditionalFrameExitInferenceModel.max_pooling.forward", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "adaptive_models.threshold_selection", "len", "adaptive_models.ConditionalFrameExitInferenceModel.gate_selection", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten.view", "torch.flatten.view", "torch.flatten.view", "z_previous.view"], "methods", ["home.repos.pwc.inspect_result.Qualcomm-AI-research_FrameExit.model.adaptive_models.ConditionalFrameExitInferenceModel.forward", "home.repos.pwc.inspect_result.Qualcomm-AI-research_FrameExit.model.adaptive_models.ConditionalFrameExitInferenceModel.forward", "home.repos.pwc.inspect_result.Qualcomm-AI-research_FrameExit.model.adaptive_models.threshold_selection", "home.repos.pwc.inspect_result.Qualcomm-AI-research_FrameExit.model.adaptive_models.ConditionalFrameExitInferenceModel.gate_selection"], ["", "def", "forward", "(", "self", ",", "x", ",", "z_previous", "=", "None", ",", "t", "=", "torch", ".", "tensor", "(", "0", ")", ")", ":", "\n", "        ", "y_t", "=", "None", "\n", "z_t", "=", "super", "(", ")", ".", "forward", "(", "x", ")", "\n", "z_t", "=", "z_t", ".", "squeeze", "(", "dim", "=", "1", ")", "\n", "b", "=", "z_t", ".", "shape", "[", "0", "]", "\n", "self", ".", "exit_door", "=", "torch", ".", "zeros", "(", "\n", "[", "x", ".", "shape", "[", "0", "]", ",", "len", "(", "self", ".", "classifiers", ")", "]", ",", "device", "=", "x", ".", "device", "\n", ")", "\n", "if", "t", ">", "0", ":", "\n", "            ", "z_t", "=", "self", ".", "max_pooling", ".", "forward", "(", "z_t", ",", "z_previous", ")", "\n", "\n", "# for the first frame, we use a simple confidence threshold to exit", "\n", "", "if", "t", "==", "0", ":", "\n", "            ", "z_t", "=", "torch", ".", "flatten", "(", "z_t", ",", "start_dim", "=", "1", ")", "\n", "y_t", "=", "self", ".", "classifiers", "[", "t", "]", "(", "z_t", ")", "\n", "exited", "=", "threshold_selection", "(", "y_t", ",", "threshold", "=", "self", ".", "first_threshold", ")", "\n", "", "elif", "t", "<", "self", ".", "num_frames", "-", "1", ":", "\n", "            ", "exited", "=", "self", ".", "gate_selection", "(", "\n", "t", "-", "1", ",", "[", "z_t", ".", "view", "(", "b", ",", "-", "1", ",", "1", ",", "1", ")", ",", "z_previous", ".", "view", "(", "b", ",", "-", "1", ",", "1", ",", "1", ")", "]", "\n", ")", "\n", "", "else", ":", "\n", "            ", "exited", "=", "True", "\n", "\n", "", "if", "exited", ":", "\n", "            ", "if", "t", ">", "0", ":", "\n", "                ", "z_t", "=", "torch", ".", "flatten", "(", "z_t", ",", "start_dim", "=", "1", ")", "\n", "y_t", "=", "self", ".", "classifiers", "[", "t", "]", "(", "z_t", ")", "\n", "", "self", ".", "exited_classifiers", "=", "t", "+", "1", "\n", "self", ".", "exit_door", "[", "0", "]", "[", "t", "]", "=", "1", "\n", "return", "y_t", ",", "None", "\n", "", "else", ":", "\n", "            ", "return", "None", ",", "z_t", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.Qualcomm-AI-research_FrameExit.model.adaptive_models.execute_exiting": [[22, 29], ["func", "func"], "function", ["None"], ["", "", "def", "execute_exiting", "(", "func", ",", "out_ave", ",", "pre_exit_features", "=", "None", ")", ":", "\n", "    ", "if", "pre_exit_features", "is", "not", "None", ":", "\n", "        ", "exit_door_val", "=", "func", "(", "out_ave", ",", "prev_features", "=", "pre_exit_features", "[", "-", "1", "]", ")", "\n", "", "else", ":", "\n", "        ", "exit_door_val", "=", "func", "(", "out_ave", ")", "\n", "\n", "", "return", "exit_door_val", "\n", "\n"]], "home.repos.pwc.inspect_result.Qualcomm-AI-research_FrameExit.model.adaptive_models.get_torchvision_model": [[53, 76], ["torch.nn.Sequential.parameters", "vars().keys", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential.eval", "vars().keys", "vars", "name.split", "name.split", "vars", "vars", "vars", "vars", "list", "torch.nn.Sequential.children"], "function", ["None"], ["", "", "def", "get_torchvision_model", "(", "\n", "name", ",", "pretrained", "=", "True", ",", "requires_grad", "=", "False", ",", "truncate_modules", "=", "None", "\n", ")", ":", "\n", "    ", "torchvision_models", "=", "models", "\n", "if", "\".\"", "in", "name", ":", "\n", "        ", "prefix", ",", "name", "=", "name", ".", "split", "(", "\".\"", ")", "[", "0", "]", ",", "name", ".", "split", "(", "\".\"", ")", "[", "1", "]", "\n", "assert", "prefix", "in", "vars", "(", "torchvision_models", ")", ".", "keys", "(", ")", "\n", "torchvision_models", "=", "vars", "(", "torchvision_models", ")", "[", "prefix", "]", "\n", "", "assert", "name", "in", "vars", "(", "torchvision_models", ")", ".", "keys", "(", ")", "\n", "\n", "if", "name", "==", "\"inception_v3\"", ":", "\n", "        ", "model", "=", "vars", "(", "torchvision_models", ")", "[", "name", "]", "(", "pretrained", "=", "pretrained", ",", "aux_logits", "=", "False", ")", "\n", "", "else", ":", "\n", "        ", "model", "=", "vars", "(", "torchvision_models", ")", "[", "name", "]", "(", "pretrained", "=", "pretrained", ")", "\n", "", "if", "truncate_modules", "is", "not", "None", ":", "\n", "        ", "model", "=", "torch", ".", "nn", ".", "Sequential", "(", "*", "list", "(", "model", ".", "children", "(", ")", ")", "[", ":", "truncate_modules", "]", ")", "\n", "", "for", "param", "in", "model", ".", "parameters", "(", ")", ":", "\n", "        ", "param", ".", "requires_grad", "=", "requires_grad", "\n", "\n", "", "if", "not", "requires_grad", ":", "\n", "        ", "model", ".", "eval", "(", ")", "\n", "\n", "", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.Qualcomm-AI-research_FrameExit.model.adaptive_models.get_base_model": [[78, 98], ["config.model.backbone.get", "name.lower", "adaptive_models.get_torchvision_model", "Exception", "name.split"], "function", ["home.repos.pwc.inspect_result.Qualcomm-AI-research_FrameExit.utils.config.Config.get", "home.repos.pwc.inspect_result.Qualcomm-AI-research_FrameExit.model.adaptive_models.get_torchvision_model"], ["", "def", "get_base_model", "(", "name", ",", "config", ")", ":", "\n", "    ", "truncate_modules", "=", "(", "\n", "config", ".", "model", ".", "backbone", ".", "truncate_modules", "\n", "if", "config", ".", "model", ".", "backbone", ".", "get", "(", "\"truncate_modules\"", ")", "\n", "else", "None", "\n", ")", "\n", "if", "name", "is", "None", ":", "\n", "        ", "return", "None", "\n", "", "if", "\"torchvision\"", "in", "name", ".", "lower", "(", ")", ":", "\n", "        ", "model_name", "=", "name", ".", "split", "(", "\".\"", ",", "1", ")", "[", "-", "1", "]", "\n", "model", "=", "get_torchvision_model", "(", "\n", "name", "=", "model_name", ",", "\n", "pretrained", "=", "config", ".", "model", ".", "backbone", ".", "pretrained", ",", "\n", "requires_grad", "=", "config", ".", "model", ".", "backbone", ".", "requires_grad", ",", "\n", "truncate_modules", "=", "truncate_modules", ",", "\n", ")", "\n", "", "else", ":", "\n", "        ", "raise", "Exception", "(", "\"couldn't find %s as a model name\"", "%", "name", ")", "\n", "\n", "", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.Qualcomm-AI-research_FrameExit.model.adaptive_models.threshold_selection": [[177, 182], ["torch.nn.Softmax", "torch.nn.Softmax", "torch.nn.Softmax", "torch.max", "torch.max", "torch.max"], "function", ["None"], ["", "", "def", "threshold_selection", "(", "y_t", ",", "threshold", "=", "0.99", ")", ":", "\n", "    ", "y_t_probs", "=", "torch", ".", "nn", ".", "Softmax", "(", "dim", "=", "1", ")", "(", "y_t", ")", "\n", "exit_door", "=", "torch", ".", "max", "(", "y_t_probs", ",", "dim", "=", "1", ")", "[", "0", "]", ">", "threshold", "\n", "\n", "return", "False", "if", "exit_door", "[", "0", "]", "==", "0", "else", "True", "\n", "\n"]]}